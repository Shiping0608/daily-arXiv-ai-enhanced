{"id": "2506.04375", "pdf": "https://arxiv.org/pdf/2506.04375", "abs": "https://arxiv.org/abs/2506.04375", "authors": ["Conor Rowan", "John Evans", "Kurt Maute", "Alireza Doostan"], "title": "Solving engineering eigenvalue problems with neural networks using the Rayleigh quotient", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "From characterizing the speed of a thermal system's response to computing\nnatural modes of vibration, eigenvalue analysis is ubiquitous in engineering.\nIn spite of this, eigenvalue problems have received relatively little treatment\ncompared to standard forward and inverse problems in the physics-informed\nmachine learning literature. In particular, neural network discretizations of\nsolutions to eigenvalue problems have seen only a handful of studies. Owing to\ntheir nonlinearity, neural network discretizations prevent the conversion of\nthe continuous eigenvalue differential equation into a standard discrete\neigenvalue problem. In this setting, eigenvalue analysis requires more\nspecialized techniques. Using a neural network discretization of the\neigenfunction, we show that a variational form of the eigenvalue problem called\nthe \"Rayleigh quotient\" in tandem with a Gram-Schmidt orthogonalization\nprocedure is a particularly simple and robust approach to find the eigenvalues\nand their corresponding eigenfunctions. This method is shown to be useful for\nfinding sets of harmonic functions on irregular domains, parametric and\nnonlinear eigenproblems, and high-dimensional eigenanalysis. We also discuss\nthe utility of harmonic functions as a spectral basis for approximating\nsolutions to partial differential equations. Through various examples from\nengineering mechanics, the combination of the Rayleigh quotient objective,\nGram-Schmidt procedure, and the neural network discretization of the\neigenfunction is shown to offer unique advantages for handling continuous\neigenvalue problems.", "AI": {"tldr": "The paper introduces a neural network-based method for solving eigenvalue problems using the Rayleigh quotient and Gram-Schmidt orthogonalization, demonstrating its effectiveness for complex domains and high-dimensional cases.", "motivation": "Eigenvalue problems are common in engineering but understudied in physics-informed machine learning, especially with neural network discretizations.", "method": "Uses neural networks to discretize eigenfunctions, combining the Rayleigh quotient and Gram-Schmidt orthogonalization for eigenvalue analysis.", "result": "The method is robust for irregular domains, parametric/nonlinear eigenproblems, and high-dimensional cases, and useful for spectral basis approximations.", "conclusion": "The approach offers unique advantages for continuous eigenvalue problems in engineering mechanics."}}
{"id": "2506.04416", "pdf": "https://arxiv.org/pdf/2506.04416", "abs": "https://arxiv.org/abs/2506.04416", "authors": ["Ziyao Xu", "Yong-Tao Zhang"], "title": "Exponential Time Differencing Runge-Kutta Discontinuous Galerkin (ETD-RKDG) Methods for Nonlinear Degenerate Parabolic Equations", "categories": ["math.NA", "cs.NA"], "comment": "34 pages", "summary": "In this paper, we study high-order exponential time differencing Runge-Kutta\n(ETD-RK) discontinuous Galerkin (DG) methods for nonlinear degenerate parabolic\nequations. This class of equations exhibits hyperbolic behavior in degenerate\nregions and parabolic behavior in non-degenerate regions, resulting in sharp\nwave fronts in the solution profiles and a parabolic-type time-step\nrestriction, $\\tau \\sim O(h^2)$, for explicit time integration. To address\nthese challenges and solve such equations in complex domains, we employ DG\nmethods with appropriate stabilizing limiters on unstructured meshes to capture\nthe wave fronts and use ETD-RK methods for time integration to resolve the\nstiffness of parabolic terms. We extract the system's stiffness using the\nJacobian matrix of the DG discretization for diffusion terms and adopt a nodal\nformulation to facilitate its computation. The algorithm is described in detail\nfor two-dimensional triangular meshes. We also conduct a linear stability\nanalysis in one spatial dimension and present computational results on\nthree-dimensional simplex meshes, demonstrating significant improvements in\nstability and large time-step sizes.", "AI": {"tldr": "High-order ETD-RK DG methods for nonlinear degenerate parabolic equations, addressing stiffness and wave fronts with stabilizing limiters and nodal formulations.", "motivation": "To solve nonlinear degenerate parabolic equations with hyperbolic and parabolic behaviors, overcoming stiffness and sharp wave fronts.", "method": "Uses DG methods with stabilizing limiters on unstructured meshes and ETD-RK for time integration, leveraging Jacobian matrix for stiffness.", "result": "Improved stability and larger time-step sizes demonstrated in 3D simplex meshes.", "conclusion": "ETD-RK DG methods effectively handle stiffness and wave fronts in degenerate parabolic equations."}}
{"id": "2506.04451", "pdf": "https://arxiv.org/pdf/2506.04451", "abs": "https://arxiv.org/abs/2506.04451", "authors": ["Santolo Leveque", "Yunhui He", "Maxim Olshanskii"], "title": "An Augmented Lagrangian Preconditioner for Navier--Stokes Equations with Runge--Kutta in Time", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We consider a Runge--Kutta method for the numerical time integration of the\nnonstationary incompressible Navier--Stokes equations. This yields a sequence\nof nonlinear problems to be solved for the stages of the Runge--Kutta method.\nThe resulting nonlinear system of differential equations is discretized using a\nfinite element method. To compute a numerical approximation of the stages at\neach time step, we employ Newton's method, which requires the solution of a\nlarge and sparse generalized saddle-point problem at each nonlinear iteration.\nWe devise an augmented Lagrangian preconditioner within the flexible GMRES\nmethod for solving the Newton systems at each time step. The preconditioner can\nbe applied inexactly with the help of a multigrid routine. We present numerical\nevidence of the robustness and efficiency of the proposed strategy for\ndifferent values of the viscosity, mesh size, time step, and number of stages\nof the Runge--Kutta method.", "AI": {"tldr": "A Runge-Kutta method is used for time integration of the incompressible Navier-Stokes equations, with nonlinear problems solved via Newton's method and a preconditioned GMRES solver.", "motivation": "To efficiently solve the nonlinear systems arising from the Runge-Kutta discretization of the Navier-Stokes equations.", "method": "Finite element discretization, Newton's method for nonlinear systems, and an augmented Lagrangian preconditioner with flexible GMRES.", "result": "Numerical results show robustness and efficiency across varying parameters like viscosity, mesh size, and time step.", "conclusion": "The proposed preconditioned solver is effective for the nonlinear systems in this context."}}
{"id": "2506.04710", "pdf": "https://arxiv.org/pdf/2506.04710", "abs": "https://arxiv.org/abs/2506.04710", "authors": ["Lucas \u00c5kerstedt", "Harald Hultin", "B. L. G. Jonsson"], "title": "An Array Decomposition Method for Finite Arrays with Electrically Connected Elements for fast Toeplitz Solvers", "categories": ["math.NA", "cs.NA", "eess.SP"], "comment": "12 pages, 17 figures", "summary": "A large part of the geometry of array antennas is often partially defined by\nfinite translational symmetries. Applying the method of moments (MoM) with the\nRWG-like element on an appropriately structured mesh to these arrays results in\nan impedance matrix where the main part exhibits a multilevel block Toeplitz\nstructure. This article introduces a memory-efficient construction method that\neffectively represents and reuses impedance calculations. The proposed method,\napplicable to electrically connected elements, also accounts for all\nnon-symmetric parts of the array. The core idea involves nine distinct\nelectrically connectable components from which the array can be assembled. The\nderived multilevel block Toeplitz matrix is further utilized by an in-house\ninverse solver to achieve faster and more memory-efficient MoM current vector\ncalculations. We demonstrate the method by computing the far-field of a 32x32\narray and the scattering parameters of two tightly coupled 9x9 arrays. This\napproach reduces the memory allocation from $\\mathcal{O}(N_x^2 N_y^2)$ to\n$\\mathcal{O}(N_x N_y)$, for an $N_x \\times N_y$ array.", "AI": {"tldr": "A memory-efficient method for constructing impedance matrices in array antennas using multilevel block Toeplitz structures, reducing memory usage and speeding up calculations.", "motivation": "Address the inefficiency in memory and computation for array antennas due to their finite translational symmetries.", "method": "Uses a multilevel block Toeplitz structure for the impedance matrix, with nine distinct electrically connectable components, and integrates an in-house inverse solver.", "result": "Demonstrated on a 32x32 array and two 9x9 arrays, reducing memory from O(N_x^2 N_y^2) to O(N_x N_y).", "conclusion": "The method efficiently handles non-symmetric parts of arrays and significantly improves memory and computational performance."}}
{"id": "2506.04826", "pdf": "https://arxiv.org/pdf/2506.04826", "abs": "https://arxiv.org/abs/2506.04826", "authors": ["Konstantinos Giotis", "Dimitrios Stefas", "Yanis Agha", "Hans H\u00f6ft", "Xavier Duten", "Panagiotis Svarnas", "Guillaume Lombardi", "Kristaq Gazeli"], "title": "Discharge dynamics in a cylindrical SDBD prototype reactor under ns-pulsed and sinusoidal AC operation", "categories": ["physics.plasm-ph"], "comment": null, "summary": "We developed a prototype reactor generating surface dielectric barrier\ndischarges (SDBDs) in ambient air, designed for consistent operation while\npreventing constructive material degradation. It features detachable stainless\nsteel electrodes and quartz dielectric to ensure precise fabrication. The\ngrounded electrode is fully immersed into transformer oil drastically\nsuppressing undesired parasitic discharges. The device efficiently sustains\nns-pulsed and AC discharges at 10 kHz, enabling fundamental studies of their\nelectrical characteristics (applied voltage, induced current, electric power)\nand spatiotemporal dynamics (morphology, propagation length and velocity). The\nelectric power (P) consumed exhibits a dissimilar non-linear increase with the\nrising peak voltage (Vp) in each case: P$\\approx$0.8-2.5 W for ns-pulsed\n(Vp=7-9 kV) and P$\\approx$0.9-5.3 W (Vp=7-10 kV) for AC operation. Using ICCD\nimaging, distinct ionization channels are recorded in the rising part of the\npulsed voltage being detached from the driven electrode; during the voltage\ndecrease, a glow-like discharge is formed remaining anchored on the driven\nelectrode. The rising part of the AC voltage is characterized by erratic,\nelongated ionization channels in a filamentary form, the voltage drop featuring\na glow-like behavior. During the rising and falling parts of the AC voltage,\nthe discharge reaches maximum propagation lengths (Lmax) of $\\approx$12 mm and\n$\\approx$7 mm, respectively, while remaining attached to the driven electrode.\nThe corresponding maximum discharge velocities (vmax) are about 5x10 2 m/s and\n3x10 2 m/s. For the ns-pulsed operation, Lmax$\\approx$5 mm (vmax$\\approx$5x10 5\nm/s) and Lmax$\\approx$3.5 mm (vmax$\\approx$1.5x10 5 m/s) during the rising and\nfalling parts of the voltage pulse, respectively. The SDBD dynamics generated\nwith a ns-pulsed voltage is more reproducible than for the AC case allowing for\nthe use of a 500 times smaller ICCD gate width (2 ns) and a more accurate\ndescription of the discharge's spatiotemporal development. This reactor is\nsuitable for performing fundamental studies and understanding key SDBD features\nfor various applications such as flow control, biomedicine and agriculture.", "AI": {"tldr": "A prototype reactor for surface dielectric barrier discharges (SDBDs) in air was developed, featuring detachable electrodes and quartz dielectric. It efficiently operates with ns-pulsed and AC discharges, enabling detailed study of electrical and spatiotemporal dynamics. The reactor shows distinct discharge behaviors and is suitable for fundamental research and applications like flow control and biomedicine.", "motivation": "To create a reliable SDBD reactor for consistent operation and material durability, enabling fundamental studies of discharge characteristics and dynamics for diverse applications.", "method": "The reactor uses detachable stainless steel electrodes and quartz dielectric, with the grounded electrode immersed in transformer oil to suppress parasitic discharges. It operates with ns-pulsed and AC discharges at 10 kHz, analyzed via electrical measurements and ICCD imaging.", "result": "The reactor exhibits non-linear power consumption with voltage, distinct discharge behaviors (ionization channels and glow-like discharges), and varying propagation lengths and velocities for ns-pulsed and AC operations. Ns-pulsed discharges are more reproducible.", "conclusion": "The reactor is effective for fundamental SDBD studies, offering insights into discharge dynamics and potential applications in fields like flow control, biomedicine, and agriculture."}}
{"id": "2506.04354", "pdf": "https://arxiv.org/pdf/2506.04354", "abs": "https://arxiv.org/abs/2506.04354", "authors": ["Elmira Mirzabeigi", "Rezvan Salehi", "Kourosh Parand"], "title": "BridgeNet: A Hybrid, Physics-Informed Machine Learning Framework for Solving High-Dimensional Fokker-Planck Equations", "categories": ["physics.comp-ph", "cs.LG", "math-ph", "math.AP", "math.MP"], "comment": null, "summary": "BridgeNet is a novel hybrid framework that integrates convolutional neural\nnetworks with physics-informed neural networks to efficiently solve non-linear,\nhigh-dimensional Fokker-Planck equations (FPEs). Traditional PINNs, which\ntypically rely on fully connected architectures, often struggle to capture\ncomplex spatial hierarchies and enforce intricate boundary conditions. In\ncontrast, BridgeNet leverages adaptive CNN layers for effective local feature\nextraction and incorporates a dynamically weighted loss function that\nrigorously enforces physical constraints. Extensive numerical experiments\nacross various test cases demonstrate that BridgeNet not only achieves\nsignificantly lower error metrics and faster convergence compared to\nconventional PINN approaches but also maintains robust stability in\nhigh-dimensional settings. This work represents a substantial advancement in\ncomputational physics, offering a scalable and accurate solution methodology\nwith promising applications in fields ranging from financial mathematics to\ncomplex system dynamics.", "AI": {"tldr": "BridgeNet combines CNNs and physics-informed neural networks to solve Fokker-Planck equations more efficiently than traditional PINNs, achieving lower errors and faster convergence.", "motivation": "Traditional PINNs struggle with complex spatial hierarchies and boundary conditions, motivating the need for a hybrid approach like BridgeNet.", "method": "BridgeNet uses adaptive CNN layers for local feature extraction and a dynamically weighted loss function to enforce physical constraints.", "result": "BridgeNet outperforms conventional PINNs with lower error metrics, faster convergence, and robust stability in high-dimensional settings.", "conclusion": "BridgeNet advances computational physics, offering scalable and accurate solutions for applications in finance and complex system dynamics."}}
{"id": "2506.04498", "pdf": "https://arxiv.org/pdf/2506.04498", "abs": "https://arxiv.org/abs/2506.04498", "authors": ["Nguyen Thanh Tung", "Le Xuan Truong", "Tan Duc Do", "Nguyen Ngoc Trong"], "title": "Existence, uniqueness and blow-up estimates for a reaction-diffusion equation with $p(x,t)$-exponents", "categories": ["math.AP"], "comment": null, "summary": "Let $d \\in \\{3,4,5,\\ldots\\}$ and $\\Omega \\subset \\Ri^d$ be open bounded with\nLipschitz boundary.\n  Let $Q = \\Omega \\times (0,\\infty)$ and $p \\in C(\\overline{Q})$ be such that\n  \\[\n  2 < p^- \\le p(\\cdot) \\le p^+ < 2^* := \\frac{2d}{d-2},\n  \\]\n  where\n  $\n  p^- := \\essinf_{(x,t) \\in Q} p(x,t)\n  $\n  and\n  $\n  p^+ := \\esssup_{(x,t) \\in Q} p(x,t).\n  $\n  Consider the reaction-diffusion parabolic problem\n  \\[\n  (P) \\quad \\left\\{\\begin{array}{ll}\n  \\displaystyle\\frac{u_t}{|x|^2} - \\Delta u = k(t) \\, |u|^{p(x,t)-2}u & (x,t)\n\\in \\Omega \\times (0,T),\n  u(x,t) = 0, & (x,t) \\in \\partial \\Omega \\times (0,T), \\smallskip\n  u(x,0) = u_0(x), & x \\in \\Omega,\n  \\end{array}\\right.\n  \\]\n  where $T > 0$ and $0 \\ne u_0 \\in W^{1,2}_0(\\Omega)$.\n  We investigate the existence and uniqueness of a weak solution to $(P)$.\n  The upper and lower bounds on the blow-up time of the weak solution are also\nconsidered.", "AI": {"tldr": "The paper studies the existence, uniqueness, and blow-up time bounds of weak solutions to a reaction-diffusion parabolic problem in a bounded domain with Lipschitz boundary.", "motivation": "To address the challenges of solving reaction-diffusion equations with variable exponents and understand the behavior of solutions, including blow-up phenomena.", "method": "Analysis of a parabolic problem with a variable exponent $p(x,t)$, using functional analysis and PDE techniques to establish weak solutions.", "result": "Existence and uniqueness of weak solutions are proven, along with upper and lower bounds for the blow-up time.", "conclusion": "The study provides rigorous results for the problem, contributing to the understanding of reaction-diffusion systems with variable exponents."}}
{"id": "2506.04237", "pdf": "https://arxiv.org/pdf/2506.04237", "abs": "https://arxiv.org/abs/2506.04237", "authors": ["Sanchit Sinha", "Aidong Zhang"], "title": "A Comprehensive Survey on the Risks and Limitations of Concept-based Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Concept-based Models are a class of inherently explainable networks that\nimprove upon standard Deep Neural Networks by providing a rationale behind\ntheir predictions using human-understandable `concepts'. With these models\nbeing highly successful in critical applications like medical diagnosis and\nfinancial risk prediction, there is a natural push toward their wider adoption\nin sensitive domains to instill greater trust among diverse stakeholders.\nHowever, recent research has uncovered significant limitations in the structure\nof such networks, their training procedure, underlying assumptions, and their\nsusceptibility to adversarial vulnerabilities. In particular, issues such as\nconcept leakage, entangled representations, and limited robustness to\nperturbations pose challenges to their reliability and generalization.\nAdditionally, the effectiveness of human interventions in these models remains\nan open question, raising concerns about their real-world applicability. In\nthis paper, we provide a comprehensive survey on the risks and limitations\nassociated with Concept-based Models. In particular, we focus on aggregating\ncommonly encountered challenges and the architecture choices mitigating these\nchallenges for Supervised and Unsupervised paradigms. We also examine recent\nadvances in improving their reliability and discuss open problems and promising\navenues of future research in this domain.", "AI": {"tldr": "A survey on risks and limitations of Concept-based Models, highlighting challenges like concept leakage and robustness, and discussing mitigation strategies and future research directions.", "motivation": "To address the growing adoption of Concept-based Models in sensitive domains by identifying their limitations and improving reliability.", "method": "Comprehensive survey aggregating challenges and architecture choices for Supervised and Unsupervised paradigms, along with recent advances.", "result": "Identified key issues like concept leakage and robustness, and explored mitigation strategies.", "conclusion": "Highlights open problems and promising future research to enhance the reliability and applicability of Concept-based Models."}}
{"id": "2506.04732", "pdf": "https://arxiv.org/pdf/2506.04732", "abs": "https://arxiv.org/abs/2506.04732", "authors": ["Nicola Cavallini", "Gianmarco Manzini", "Daniele Funaro", "Andrea Favalli"], "title": "A Fast, Accurate and Oscillation-free Spectral Collocation Solver for High-dimensional Transport Problems", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Transport phenomena-describing the movement of particles, energy, or other\nphysical quantities-are fundamental in various scientific disciplines,\nincluding nuclear physics, plasma physics, astrophysics, engineering, and the\nnatural sciences.\n  However, solving the associated seven-dimensional transport equations poses a\nsignificant computational challenge due to the curse of dimensionality.\n  We introduce the Tensor Train Superconsistent Spectral (T${^2}$S${^2}$)\nsolver to address this challenge, integrating Spectral Collocation for\nexponential convergence, Superconsistency for stabilization in\ntransport-dominated regimes, and Tensor Train format for substantial data\ncompression. T${^2}$S${^2}$ enforces a dimension-wise superconsistent condition\ncompatible with tensor structures, achieving extremely low compression ratios,\nin the order of $(10^{-12})$, while preserving spectral accuracy. Numerical\nexperiments on linear problems demonstrate that T${^2}$S${^2}$ can solve\nhigh-dimensional transport problems in minutes on standard hardware, making\npreviously intractable problems computationally feasible. This advancement\nopens new avenues for efficiently and accurately modeling complex transport\nphenomena.", "AI": {"tldr": "The paper introduces the T\u00b2S\u00b2 solver to tackle the computational challenge of solving high-dimensional transport equations, achieving efficient and accurate results.", "motivation": "Transport phenomena are fundamental in many fields, but solving their seven-dimensional equations is computationally challenging due to dimensionality.", "method": "The T\u00b2S\u00b2 solver combines Spectral Collocation, Superconsistency, and Tensor Train format for exponential convergence, stabilization, and data compression.", "result": "T\u00b2S\u00b2 achieves extremely low compression ratios (~10\u207b\u00b9\u00b2) and solves high-dimensional problems in minutes on standard hardware.", "conclusion": "This method makes previously intractable transport problems feasible, enabling efficient modeling of complex phenomena."}}
{"id": "2506.04827", "pdf": "https://arxiv.org/pdf/2506.04827", "abs": "https://arxiv.org/abs/2506.04827", "authors": ["Lorenzo Martelli", "Igor Andriyash", "Jonathan Wheeler", "Henri Kraft", "Xuan Quyen Dinh", "C\u00e9dric Thaury"], "title": "Empirical scaling laws for self-focused laser pulses in nitrogen plasmas", "categories": ["physics.plasm-ph"], "comment": "6 figures, 9 pages", "summary": "We investigate the interaction between a superintense laser pulse and a\nnitrogen plasma with densities exceeding $10^{19}\\,$cm$^{-3}$, using\nparticle-in-cell simulations. Such configurations have recently demonstrated\nthe capability to produce highly charged electron beams (i.e., $>10\\,$nC) with\n$1\\,$J-class lasers, a significant step toward high-average-current\nlaser-plasma accelerators. Our study focuses on analyzing the impact of laser\nself-focusing on laser dynamics, leading to scaling laws that characterize beam\ndiffraction, wakefield amplitude and plasma structures, providing important\ninsights of this interaction regime.", "AI": {"tldr": "Study of laser-plasma interaction in high-density nitrogen plasma, revealing scaling laws for laser self-focusing effects.", "motivation": "To understand how superintense lasers interact with dense nitrogen plasma, aiming to improve high-current laser-plasma accelerators.", "method": "Particle-in-cell simulations to analyze laser self-focusing and its effects on plasma dynamics.", "result": "Identified scaling laws for beam diffraction, wakefield amplitude, and plasma structures.", "conclusion": "Provides key insights for optimizing laser-plasma accelerators in high-density regimes."}}
{"id": "2506.04489", "pdf": "https://arxiv.org/pdf/2506.04489", "abs": "https://arxiv.org/abs/2506.04489", "authors": ["Lukas Exl", "Sebastian Schaffer"], "title": "Spectrally accurate and efficient convolution with the 3D free-space Laplace Green's function via the super-potential", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "65N35, 65N80"], "comment": "11 pages, 1 figure", "summary": "We present a high-accuracy spectral method for solving the unbounded\nthree-dimensional Poisson equation with smooth, compactly supported sources.\nThe approach is based on a super-potential formulation, where the solution is\nobtained by applying the Laplacian to a convolution with the biharmonic Green's\nfunction. A separable Gaussian-sum (GS) approximation enables efficient\nFFT-based computation with quasi-linear complexity. Owing to the improved\nregularity of the biharmonic kernel, the GS cutoff error is of order four,\neliminating the need for correction terms or Taylor expansions required in\nstandard GS or Ewald-type methods. Numerical benchmarks demonstrate that the\nmethod achieves machine-precision accuracy and outperforms existing GS-based\nschemes in both error and runtime, making it a robust and efficient tool for\nfree-space Poisson problems on uniform grids.", "AI": {"tldr": "A high-accuracy spectral method for solving the 3D Poisson equation with smooth, compactly supported sources, using a super-potential formulation and Gaussian-sum approximation for efficient FFT-based computation.", "motivation": "To address the challenges of solving the unbounded 3D Poisson equation with high accuracy and efficiency, avoiding the need for correction terms or Taylor expansions.", "method": "Uses a super-potential formulation with the biharmonic Green's function and a separable Gaussian-sum approximation for FFT-based computation.", "result": "Achieves machine-precision accuracy and outperforms existing Gaussian-sum-based methods in error and runtime.", "conclusion": "The method is robust and efficient for free-space Poisson problems on uniform grids."}}
{"id": "2506.04578", "pdf": "https://arxiv.org/pdf/2506.04578", "abs": "https://arxiv.org/abs/2506.04578", "authors": ["Weiming Shen", "Yue Wang", "Tong Yang"], "title": "Structural stability of three dimensional steady Prandtl equation", "categories": ["math.AP"], "comment": null, "summary": "The well-posedness of the three dimensional Prandtl equation is an\noutstanding open problem due to the appearance of the secondary flow even\nthough there are studies on analytic and Gevrey function spaces. This problem\nis raised as the third open problem in the classical book by Oleinik and\nSamokhin [43]. This paper aims to address this open problem in the steady case\nby introducing a new approach to study the structural stability of background\nprofile that includes the famous Blasius solutions. The key observations\ninclude the introduction of some intrinsic vector fields and new versions of\nmaximum principle. In particular, we overcome the difficulties caused by\nsymmetry breaking through the analysis on the curvature-type quantities\ngenerated by commutators of the vector fields.", "AI": {"tldr": "The paper addresses the open problem of the 3D Prandtl equation's well-posedness by introducing a new approach for structural stability, focusing on intrinsic vector fields and maximum principles.", "motivation": "The well-posedness of the 3D Prandtl equation remains unsolved, highlighted as the third open problem in Oleinik and Samokhin's book. The study aims to tackle this in the steady case.", "method": "A new approach using intrinsic vector fields and maximum principles is introduced, with analysis on curvature-type quantities from commutators to address symmetry breaking.", "result": "The paper overcomes symmetry-breaking challenges and provides insights into the structural stability of profiles like the Blasius solutions.", "conclusion": "The work advances understanding of the 3D Prandtl equation's well-posedness, particularly in the steady case, through innovative methods."}}
{"id": "2506.04241", "pdf": "https://arxiv.org/pdf/2506.04241", "abs": "https://arxiv.org/abs/2506.04241", "authors": ["Konstantin Kirchheim", "Frank Ortmeier"], "title": "Improving Out-of-Distribution Detection with Markov Logic Networks", "categories": ["cs.LG"], "comment": null, "summary": "Out-of-distribution (OOD) detection is essential for ensuring the reliability\nof deep learning models operating in open-world scenarios. Current OOD\ndetectors mainly rely on statistical models to identify unusual patterns in the\nlatent representations of a deep neural network. This work proposes to augment\nexisting OOD detectors with probabilistic reasoning, utilizing Markov logic\nnetworks (MLNs). MLNs connect first-order logic with probabilistic reasoning to\nassign probabilities to inputs based on weighted logical constraints defined\nover human-understandable concepts, which offers improved explainability.\nThrough extensive experiments on multiple datasets, we demonstrate that MLNs\ncan significantly enhance the performance of a wide range of existing OOD\ndetectors while maintaining computational efficiency. Furthermore, we introduce\na simple algorithm for learning logical constraints for OOD detection from a\ndataset and showcase its effectiveness.", "AI": {"tldr": "The paper proposes using Markov logic networks (MLNs) to enhance out-of-distribution (OOD) detection in deep learning, improving explainability and performance.", "motivation": "OOD detection is critical for reliable deep learning in open-world scenarios, but current methods lack explainability.", "method": "Augments existing OOD detectors with MLNs, combining probabilistic reasoning and first-order logic for better explainability. Introduces an algorithm for learning logical constraints.", "result": "MLNs significantly improve OOD detector performance across datasets while maintaining computational efficiency.", "conclusion": "MLNs offer a promising approach for enhancing OOD detection with explainability and efficiency."}}
{"id": "2506.04791", "pdf": "https://arxiv.org/pdf/2506.04791", "abs": "https://arxiv.org/abs/2506.04791", "authors": ["Athanasios C. Antoulas", "Ion Victor Gosea", "Charles Poussot-Vassal", "Pierre Vuillemin"], "title": "Tensor-based multivariate function approximation: methods benchmarking and comparison", "categories": ["math.NA", "cs.CE", "cs.NA", "cs.SE", "93A15, 93A30, 93B11, 93B15, 93C05, 93C80"], "comment": "Report with a collection of examples, aimed at being regularly\n  updated. Associated GIT: https://github.com/cpoussot/mLF", "summary": "In this note, we evaluate the performances, the features and the\nuser-experience of some methods (and their implementations) designed for\ntensor- (or data-) based multivariate function construction and approximation.\nTo this aim, a collection of multivariate functions extracted from contributive\nworks coming from different communities, is suggested. First, these functions\nwith varying complexity (e.g. number and degree of the variables) and nature\n(e.g. rational, irrational, differentiable or not, symmetric, etc.) are used to\nconstruct tensors, each of different dimension and size on the disk. Second,\ngrounded on this tensor, we inspect performances of each considered method\n(e.g. the accuracy, the computational time, the parameters tuning impact,\netc.). Finally, considering the \"best\" parameter tuning set, we compare each\nmethod using multiple evaluation criteria. The purpose of this note is not to\nrank the methods but rather to evaluate as fairly as possible the different\navailable strategies, with the idea in mind to guide users to understand the\nprocess, the possibilities, the advantages and the limits brought by each\ntools. The contribution claimed is to suggest a complete benchmark collection\nof some available tools for tensor approximation by surrogate models (e.g.\nrational functions, networks, etc.). In addition, as contributors of the\nmultivariate Loewner Framework (mLF) approach (and its side implementation in\nMDSPACK), attention and details of the latter are more explicitly given, in\norder to provide readers a digest of this contributive work and some details\nwith simple examples.", "AI": {"tldr": "The paper evaluates methods for tensor-based multivariate function approximation, comparing their performance, features, and user-experience without ranking them, while providing a benchmark collection and detailed insights into the mLF approach.", "motivation": "To fairly assess and compare various tensor-based multivariate function approximation methods, guiding users on their processes, advantages, and limitations.", "method": "Construct tensors from a diverse collection of multivariate functions, evaluate method performances (accuracy, computational time, parameter tuning), and compare methods using multiple criteria.", "result": "A benchmark collection of tools for tensor approximation is provided, with detailed insights into the mLF approach and its implementation.", "conclusion": "The paper aims to guide users in understanding and selecting appropriate tensor approximation methods, emphasizing fairness and practical utility over ranking."}}
{"id": "2506.05124", "pdf": "https://arxiv.org/pdf/2506.05124", "abs": "https://arxiv.org/abs/2506.05124", "authors": ["Florens Grimm", "Jan-Luca Gembus", "Jana Sch\u00f6ne", "Peter Awakowicz", "Lars Sch\u00fccke", "Andrew R. Gibson"], "title": "Electron and gas temperature-driven chemistry during microdischarges formed in water vapour bubbles", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Microdischarges formed in bubbles immersed in liquids are of interest for\nmaterials synthesis and chemical conversion applications in the frame of\nplasma-driven electrochemistry. A key challenge associated with controlling\nsuch processes is the limited understanding of the gas-phase chemical kinetics\nin these microdischarges. Due to their large electron densities, and high gas\ntemperatures, both electron and gas temperature driven chemistry are likely to\nbe important. Here, a 0-D modelling approach, informed by experimental\nmeasurements, is used to study the chemical kinetics in these systems. A new\nreaction scheme is developed for microdischarges in water vapour, including\nreactions for both high electron density, and high gas temperature regimes.\nMicrodischarges formed during plasma electrolytic oxidation are used as a test\ncase, however, the key results are expected to be transferable to other plasma\nelectrolysis systems with similar properties. Experimentally measured power\ndensities are used as input to the 0-D model, together with estimates of\ntemperatures and gas pressures within the gas bubble. Comparison of measured\nand simulated electron densities shows good agreement, given the limitations of\nboth model and experiment. In the base case microdischarge, H$_{2}$O is found\nto be highly dissociated during the period of peak power density, with H and O\nmaking up the majority of the neutral gas in the bubble. The maximum ionization\ndegree is around 0.31$\\,\\%$, and the electronegativity during the period of\npeak electron density is found to be low. Species formation and reaction\npathways are analysed under variation of the neutral gas temperature from\n2000$\\,$K to 6000$\\,$K. At all temperatures, electron, ion, and neutral\nreactions with high threshold energies are found to be important for the\noverall chemical kinetics.", "AI": {"tldr": "The paper studies chemical kinetics in microdischarges within bubbles in liquids, focusing on plasma-driven electrochemistry. A 0-D model, validated by experiments, reveals high dissociation of H2O and key reaction pathways under varying temperatures.", "motivation": "Understanding gas-phase chemical kinetics in microdischarges is crucial for controlling plasma-driven electrochemistry, but current knowledge is limited due to high electron densities and temperatures.", "method": "A 0-D modeling approach, informed by experimental measurements, is used to analyze chemical kinetics. A new reaction scheme for microdischarges in water vapor is developed, tested with plasma electrolytic oxidation.", "result": "H2O is highly dissociated during peak power density, with H and O dominating the neutral gas. Ionization degree is low (0.31%), and electronegativity is minimal. Key reactions are identified across 2000K\u20136000K.", "conclusion": "The findings provide insights into microdischarge chemistry, applicable to similar plasma electrolysis systems, highlighting the importance of high-threshold energy reactions."}}
{"id": "2506.04763", "pdf": "https://arxiv.org/pdf/2506.04763", "abs": "https://arxiv.org/abs/2506.04763", "authors": ["Shuai Lu"], "title": "A highly scalable numerical framework for reservoir simulation on UG4 platform", "categories": ["physics.comp-ph", "cs.DC"], "comment": null, "summary": "The modeling and simulation of multiphase fluid flow receive significant\nattention in reservoir engineering. Many time discretization schemes for\nmultiphase flow equations are either explicit or semi-implicit, relying on the\ndecoupling between the saturation equation and the pressure equation. In this\nstudy, we delve into a fully coupled and fully implicit framework for\nsimulating multiphase flow in heterogeneous porous media, considering gravity\nand capillary effects. We utilize the Vertex-Centered Finite Volume Method for\nspatial discretization and propose an efficient implementation of interface\nconditions for heterogeneous porous media within the current scheme. Notably,\nwe introduce the Linearly Implicit Extrapolation Method (LIMEX) with an error\nestimator, adapted for the first time to multiphase flow problems. To solve the\nresulting linear system, we employ the BiCGSTAB method with the Geometric\nMultigrid (GMG) preconditioner. The implementations of models and methods are\nbased on the open-source software: UG4. The results from parallel computations\non the supercomputer demonstrate that the scalability of our proposed framework\nis sufficient, supporting a scale of thousands of processors with Degrees of\nFreedom (DoF) extending up to billions.", "AI": {"tldr": "The paper presents a fully coupled, fully implicit framework for simulating multiphase flow in heterogeneous porous media, using advanced numerical methods and demonstrating scalability on supercomputers.", "motivation": "Existing time discretization schemes for multiphase flow often decouple saturation and pressure equations, limiting accuracy. This study aims to improve modeling by fully coupling these equations and incorporating gravity and capillary effects.", "method": "The study employs the Vertex-Centered Finite Volume Method for spatial discretization and introduces the Linearly Implicit Extrapolation Method (LIMEX) with an error estimator. The BiCGSTAB method with Geometric Multigrid preconditioner is used to solve the linear system.", "result": "The framework shows high scalability, supporting thousands of processors and billions of Degrees of Freedom (DoF) in parallel computations on a supercomputer.", "conclusion": "The proposed fully implicit framework is efficient and scalable, offering improved accuracy for multiphase flow simulations in heterogeneous porous media."}}
{"id": "2506.04591", "pdf": "https://arxiv.org/pdf/2506.04591", "abs": "https://arxiv.org/abs/2506.04591", "authors": ["Weiming Shen", "Yue Wang"], "title": "Asymptotic behavior of complete conformal metric near singular boundary", "categories": ["math.AP", "math.DG"], "comment": "Published in Advances in Mathematics 458 (2024), Paper No. 109977, 34\n  pp", "summary": "The boundary behavior of the singular Yamabe problem has been extensively\nstudied near sufficiently smooth boundaries, while less is known about the\nasymptotic behavior of solutions near singular boundaries. In this paper, we\nstudy the asymptotic behaviors of solutions to the singular Yamabe problem with\nnegative constant scalar curvature near singular boundaries and derive the\noptimal estimates for the background metric which is not necessarily\nconformally flat. In particular, we prove that the solutions are well\napproximated by the solutions in tangent cones at singular points on the\nboundaries.", "AI": {"tldr": "The paper studies the asymptotic behavior of solutions to the singular Yamabe problem near singular boundaries, deriving optimal estimates for non-conformally flat metrics and proving solutions approximate those in tangent cones at singular points.", "motivation": "To understand the asymptotic behavior of solutions near singular boundaries, which is less explored compared to smooth boundaries.", "method": "Analyzing solutions to the singular Yamabe problem with negative constant scalar curvature near singular boundaries and deriving optimal metric estimates.", "result": "Solutions are well approximated by solutions in tangent cones at singular boundary points.", "conclusion": "The study provides insights into the behavior of solutions near singular boundaries and confirms their approximation by tangent cone solutions."}}
{"id": "2506.04243", "pdf": "https://arxiv.org/pdf/2506.04243", "abs": "https://arxiv.org/abs/2506.04243", "authors": ["Warayut Dokduea", "Weerachart Tangchirapat", "Sompote Youwai"], "title": "Triple Attention Transformer Architecture for Time-Dependent Concrete Creep Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper presents a novel Triple Attention Transformer Architecture for\npredicting time-dependent concrete creep, addressing fundamental limitations in\ncurrent approaches that treat time as merely an input parameter rather than\nmodeling the sequential nature of deformation development. By transforming\nconcrete creep prediction into an autoregressive sequence modeling task similar\nto language processing, our architecture leverages the transformer's\nself-attention mechanisms to capture long-range dependencies in historical\ncreep patterns. The model implements a triple-stream attention framework\nincorporating temporal attention for sequential progression, feature attention\nfor material property interactions, and batch attention for inter-sample\nrelationships. Evaluated on experimental datasets with standardized daily\nmeasurements spanning 160 days, the architecture achieves exceptional\nperformance with mean absolute percentage error of 1.63% and R2 values of 0.999\nacross all datasets, substantially outperforming traditional empirical models\nand existing machine learning approaches. Ablation studies confirm the critical\nrole of attention mechanisms, with attention pooling contributing most\nsignificantly to model performance. SHAP analysis reveals Young's modulus as\nthe primary predictive feature, followed by density and compressive strength,\nproviding interpretability essential for engineering applications. A deployed\nweb-based interface facilitates practical implementation, enabling real-time\npredictions using standard laboratory parameters. This work establishes the\nviability of applying transformer architectures to materials science problems,\ndemonstrating the potential for data-driven approaches to revolutionize\nstructural behavior prediction and engineering design practices.", "AI": {"tldr": "A novel Triple Attention Transformer Architecture is introduced for predicting concrete creep, treating time as a sequence and outperforming traditional methods with high accuracy.", "motivation": "Current approaches treat time as an input parameter, ignoring the sequential nature of deformation development, which limits accuracy.", "method": "The model uses a triple-stream attention framework (temporal, feature, and batch attention) within a transformer architecture for autoregressive sequence modeling.", "result": "Achieves 1.63% mean absolute percentage error and R2 of 0.999, outperforming traditional models. SHAP analysis highlights key predictive features like Young's modulus.", "conclusion": "The work demonstrates transformers' viability in materials science, offering high accuracy and interpretability for engineering applications."}}
{"id": "2506.04809", "pdf": "https://arxiv.org/pdf/2506.04809", "abs": "https://arxiv.org/abs/2506.04809", "authors": ["Michael J. Carley"], "title": "Numerical solution of the wave equation outside a sphere", "categories": ["math.NA", "cs.NA", "math.AP", "physics.class-ph", "physics.comp-ph"], "comment": null, "summary": "A method is presented for the fast evaluation of the transient acoustic field\ngenerated outside a spherical surface by sources inside the surface. The method\nemploys Lebedev quadratures, which are the optimal method for spatial\nintegration, and Lagrange interpolation and differentiation in an advanced time\nalgorithm for the evaluation of the transient field. Numerical testing\ndemonstrates that the approach gives near machine-precision accuracy and a\nspeed-up in evaluation time which depends on the order of quadrature rule\nemployed but breaks even with direct evaluation at a number of field points\nabout 1.15 times the number of surface quadrature nodes.", "AI": {"tldr": "A method for fast evaluation of transient acoustic fields outside a spherical surface using Lebedev quadratures and Lagrange interpolation, achieving near machine-precision accuracy and speed-up.", "motivation": "To efficiently compute transient acoustic fields generated by internal sources outside a spherical surface.", "method": "Uses Lebedev quadratures for spatial integration and Lagrange interpolation in an advanced time algorithm.", "result": "Achieves near machine-precision accuracy; speed-up depends on quadrature order, breaking even at ~1.15 times surface nodes.", "conclusion": "The method is accurate and efficient for transient acoustic field evaluation."}}
{"id": "2506.05170", "pdf": "https://arxiv.org/pdf/2506.05170", "abs": "https://arxiv.org/abs/2506.05170", "authors": ["Dario Panici", "Eduardo Rodriguez", "Rory Conlin", "Daniel Dudt", "Egemen Kolemen"], "title": "Extending near-axis equilibria in DESC", "categories": ["physics.plasm-ph"], "comment": "30 pages, 7 figures", "summary": "The near-axis description of optimised stellarator fields has proven to be a\npowerful tool both for design and understanding of this magnetic confinement\nconcept. The description consists of an asymptotic model of the equilibrium in\nthe distance from its centermost axis, and is thus only approximate. Any\npractical application therefore requires the eventual construction of a global\nequilibrium. This paper presents a novel way of constructing global equilibria\nusing the \\texttt{DESC} code that guarantees the correct asymptotic behaviour\nimposed by a given near-axis construction. The theoretical underpinnings of\nthis construction are carefully presented, and benchmarking examples provided.\nThis opens the door to an efficient coupling of the near-axis framework and\nthat of global equilibria for future optimisation efforts.", "AI": {"tldr": "The paper introduces a method to construct global equilibria for stellarator fields using the DESC code, ensuring correct asymptotic behavior from near-axis models.", "motivation": "To bridge the gap between near-axis models and global equilibria for practical stellarator design and optimization.", "method": "Uses the DESC code to construct global equilibria with enforced asymptotic behavior from near-axis models, supported by theoretical foundations and benchmarking.", "result": "Demonstrates successful coupling of near-axis and global equilibrium frameworks, enabling efficient optimization.", "conclusion": "This method enhances stellarator design by integrating near-axis and global equilibrium approaches."}}
{"id": "2506.04835", "pdf": "https://arxiv.org/pdf/2506.04835", "abs": "https://arxiv.org/abs/2506.04835", "authors": ["Julien El Hajj", "Gilles Ledoux", "Samy Merabia"], "title": "Thermoplasmonics of Gold-Core Silica-Shell Colloidal Nanoparticles under Pulse Illumination", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci"], "comment": null, "summary": "Core-shell nanoparticles, particularly those having a gold core, have emerged\nas a highly promising class of materials due to their unique optical and\nthermal properties, which underpin a wide range of applications in photothermal\ntherapy, imaging, and biosensing. In this study, we present a comprehensive\nstudy of the thermal dynamics of gold-core silica-shell nanoparticles immersed\nin water under pulse illumination. The plasmonic response of the core-shell\nnanoparticle is described by incorporating Mie theory with electronic\ntemperature corrections to the refractive indices of gold, based on a Drude\nLorentz formulation. The thermal response of the core-shell nanoparticles is\nmodeled by coupling the two temperature model with molecular dynamics\nsimulations, providing an atomistic description of nanoscale heat transfer. We\ninvestigate nanoparticles with both dense and porous silica shells (with 50%\nporosity) under laser pulse durations of 100 fs, 10 ps, and 1 ns, and over a\nrange of fluences between 0.05 and 5mJ/cm2. We show that nanoparticles with a\nthin dense silica shell (5 nm) exhibit significantly faster water heating\ncompared to bare gold nanoparticles. This behavior is attributed to enhanced\nelectron-phonon coupling at the gold silica interface and to the relatively\nhigh thermal conductance between silica and water. These findings provide new\ninsights into optimizing nanoparticle design for efficient photothermal\napplications and establish a robust framework for understanding energy transfer\nmechanisms in heterogeneous metal dielectric nanostructures.", "AI": {"tldr": "Study explores thermal dynamics of gold-core silica-shell nanoparticles under pulse illumination, revealing faster water heating with thin dense silica shells due to enhanced electron-phonon coupling.", "motivation": "Core-shell nanoparticles, especially gold-core ones, are promising for photothermal therapy, imaging, and biosensing, but their thermal dynamics under pulse illumination need deeper understanding.", "method": "Combines Mie theory with electronic temperature corrections and couples the two-temperature model with molecular dynamics to simulate heat transfer in nanoparticles with dense/porous silica shells under varying laser pulses.", "result": "Nanoparticles with thin dense silica shells (5 nm) heat water faster than bare gold nanoparticles, due to enhanced electron-phonon coupling and high silica-water thermal conductance.", "conclusion": "Findings optimize nanoparticle design for photothermal applications and provide a framework for energy transfer in metal-dielectric nanostructures."}}
{"id": "2506.04655", "pdf": "https://arxiv.org/pdf/2506.04655", "abs": "https://arxiv.org/abs/2506.04655", "authors": ["Mengjiao Bai", "Huaian Diao", "Weisheng Zhou"], "title": "Inverse elastic obstacle scattering problems by monotonicity method", "categories": ["math.AP", "cs.NA", "math.NA"], "comment": null, "summary": "We consider the elastic wave scattering problem involving rigid obstacles.\nThis work addresses the inverse problem of reconstructing the position and\nshape of such obstacles using far-field measurements. A novel\nmonotonicity-based approach is developed for this purpose. By factorizing the\nfar-field operator and utilizing the existence of localized wave functions, we\nderive a shape characterization criterion for the obstacle boundary. The\nproposed method employs monotonicity tests to determine the geometric\nrelationship between any given test domain and the actual scatterer. As a\nresult, the shape and location of rigid elastic obstacles can be uniquely\nidentified without requiring any initial guesses or prior knowledge of the\nphysical parameters of the homogeneous background medium.", "AI": {"tldr": "A novel monotonicity-based method is proposed to uniquely identify the shape and location of rigid elastic obstacles using far-field measurements, without initial guesses or prior knowledge.", "motivation": "To solve the inverse problem of reconstructing rigid obstacles in elastic wave scattering using far-field data.", "method": "Develops a monotonicity-based approach, factorizing the far-field operator and using localized wave functions to derive a shape characterization criterion.", "result": "The method uniquely identifies obstacle shape and location without initial guesses or background medium knowledge.", "conclusion": "The approach effectively solves the inverse problem for rigid elastic obstacles, offering a robust and prior-free solution."}}
{"id": "2506.04250", "pdf": "https://arxiv.org/pdf/2506.04250", "abs": "https://arxiv.org/abs/2506.04250", "authors": ["Shaona Ghosh", "Amrita Bhattacharjee", "Yftah Ziser", "Christopher Parisien"], "title": "SafeSteer: Interpretable Safety Steering with Refusal-Evasion in LLMs", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2410.01174", "summary": "Fine-tuning large language models (LLMs) to adapt to evolving safety policies\nis costly and impractical. Mechanistic interpretability enables inference-time\ncontrol through latent activation steering, yet its potential for precise,\ncustomizable safety adjustments remains largely untapped. This paper\ninvestigates an approach called SafeSteer for guiding the outputs of LLMs by:\n(i) leveraging category-specific steering vectors for more precise control,\n(ii) employing a simple, gradient-free unsupervised method to enhance safety\nsteering while preserving text quality, topic relevance, and without explicit\nrefusal, and (iii) accomplishing this without a hard requirement of contrastive\npairwise safe data. We also highlight that our method, being simple and\neffective, aligns with recent studies suggesting that simple techniques often\noutperform more complex ones in activation steering. We showcase the\neffectiveness of our approach across various LLMs, datasets, and risk\ncategories, demonstrating its ability to provide precise control, prevent\nblanket refusals, and guide models toward generating safe content while\nmaintaining topic relevance.", "AI": {"tldr": "SafeSteer is a method for fine-tuning LLMs to enhance safety without costly retraining, using unsupervised activation steering for precise control while maintaining text quality.", "motivation": "Traditional fine-tuning for safety in LLMs is costly and impractical, prompting the need for simpler, inference-time control methods.", "method": "SafeSteer employs category-specific steering vectors and a gradient-free unsupervised approach to adjust model outputs without contrastive data.", "result": "The method effectively guides LLMs to generate safer content while preserving topic relevance and avoiding blanket refusals.", "conclusion": "SafeSteer offers a simple, effective solution for safety adjustments in LLMs, aligning with the trend favoring simplicity in activation steering."}}
{"id": "2506.04840", "pdf": "https://arxiv.org/pdf/2506.04840", "abs": "https://arxiv.org/abs/2506.04840", "authors": ["Maolin Che", "Yimin Wei", "Chong Wu", "Hong Yan"], "title": "Efficient randomized algorithms for the fixed Tucker-rank problem of Tucker decomposition with adaptive shifts", "categories": ["math.NA", "cs.NA", "65F55, 68W20, 15A18, 15A69"], "comment": "41 pages, 43 figures", "summary": "Randomized numerical linear algebra is proved to bridge theoretical\nadvancements to offer scalable solutions for approximating tensor\ndecomposition. This paper introduces fast randomized algorithms for solving the\nfixed Tucker-rank problem of Tucker decomposition, through the integration of\nadaptive shifted power iterations. The proposed algorithms enhance randomized\nvariants of truncated high-order singular value decomposition (T-HOSVD) and\nsequentially T-HOSVD (ST-HOSVD) by incorporating dynamic shift strategies,\nwhich accelerate convergence by refining the singular value gap and reduce the\nnumber of required power iterations while maintaining accuracy. Theoretical\nanalyses provide probabilistic error bounds, demonstrating that the proposed\nmethods achieve comparable or superior accuracy compared to deterministic\napproaches. Numerical experiments on synthetic and real-world datasets validate\nthe efficiency and robustness of the proposed algorithms, showing a significant\ndecline in runtime and approximation error over state-of-the-art techniques.", "AI": {"tldr": "The paper introduces fast randomized algorithms for Tucker decomposition using adaptive shifted power iterations, improving efficiency and accuracy over existing methods.", "motivation": "To bridge theoretical advancements with scalable solutions for tensor decomposition, addressing the fixed Tucker-rank problem.", "method": "Integration of adaptive shifted power iterations into randomized variants of T-HOSVD and ST-HOSVD, refining singular value gaps to accelerate convergence.", "result": "Theoretical error bounds show comparable or superior accuracy to deterministic methods, with numerical experiments confirming reduced runtime and approximation error.", "conclusion": "The proposed algorithms are efficient, robust, and outperform state-of-the-art techniques in both synthetic and real-world datasets."}}
{"id": "2506.05293", "pdf": "https://arxiv.org/pdf/2506.05293", "abs": "https://arxiv.org/abs/2506.05293", "authors": ["Mario Christopher Bedrunka", "Dirk Reith", "Holger Foysi", "\u0141ukasz \u0141aniewski-Wo\u0142\u0142k", "Travis Mitchell"], "title": "Reduction of Outflow Boundary Influence on Aerodynamic Performance using Neural Networks", "categories": ["physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "The accurate treatment of outflow boundary conditions remains a critical\nchallenge in computational fluid dynamics when predicting aerodynamic forces\nand/or acoustic emissions. This is particularly evident when employing the\nlattice Boltzmann method (LBM) as the numerical solution technique, which often\nsuffers from inaccuracies induced by artificial reflections from outflow\nboundaries. This paper investigates the use of neural networks (NN) to mitigate\nthese adverse boundary effects and enable truncated domain requirements. Two\ndistinct NN-based approaches are proposed: (1) direct reconstruction of unknown\nparticle distribution functions at the outflow boundary; and (2) enhancement of\nestablished characteristic boundary conditions (CBC) by dynamically tuning\ntheir parameters. The direct reconstruction model was trained on data generated\nfrom a 2D flow over a cylindrical obstruction. The drag, lift, and Strouhal\nnumber were used to test the new boundary condition. We analyzed results for\nvarious Reynolds numbers and restricted domain sizes where it demonstrated\nsignificantly improved predictions when compared with the traditional Zou & He\nboundary condition. To examine the robustness of the NN-based reconstruction,\nthe same condition was applied to the simulation of a NACA0012 airfoil, again\nproviding accurate aerodynamic performance predictions. The neural-enhanced CBC\nwere evaluated on a 2D convected vortex benchmark and showed superior\nperformance in minimizing density errors compared to CBCs with fixed\nparameters. These findings highlight the potential of NN-integrated boundary\nconditions to improve accuracy and reduce computational expense of aerodynamic\nand acoustic emissions simulations with the LBM.", "AI": {"tldr": "Neural networks (NN) improve outflow boundary conditions in LBM, reducing artificial reflections and computational costs.", "motivation": "Accurate outflow boundary conditions are critical in CFD for aerodynamic and acoustic predictions, but LBM suffers from artificial reflections.", "method": "Two NN-based approaches: (1) direct reconstruction of particle distribution functions, and (2) dynamic tuning of characteristic boundary conditions (CBC).", "result": "NN methods outperformed traditional Zou & He conditions in drag, lift, and Strouhal number predictions. NN-enhanced CBC also reduced density errors.", "conclusion": "NN-integrated boundary conditions enhance LBM accuracy and efficiency for aerodynamic and acoustic simulations."}}
{"id": "2506.04691", "pdf": "https://arxiv.org/pdf/2506.04691", "abs": "https://arxiv.org/abs/2506.04691", "authors": ["Pascal B\u00e9gout", "Jesus Ildefonso Diaz"], "title": "Solutions with expanding compact support of saturated Schr{\u00f6}dinger equations: self-similar solutions", "categories": ["math.AP"], "comment": null, "summary": "We prove the existence of solutions \\(u(t,x)\\) of the Schr{\\\"o}dinger\nequation with a saturation nonlinear term \\((u/|u|)\\) having compact support,\nfor each \\(t>0,\\) that expands with a growth law of the type \\(C\\sqrt{t}\\). The\nprimary tool is considering the self-similar solution of the associated\nequation. For more information see\nhttps://ejde.math.txstate.edu/Volumes/2025/53/abstr.html", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.04254", "pdf": "https://arxiv.org/pdf/2506.04254", "abs": "https://arxiv.org/abs/2506.04254", "authors": ["Nicolas Caron", "Christophe Guyeux", "Hassan Noura", "Benjamin Aynes"], "title": "Localized Forest Fire Risk Prediction: A Department-Aware Approach for Operational Decision Support", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 7 figures, 3 tables, submitted to ECAI2025", "summary": "Forest fire prediction involves estimating the likelihood of fire ignition or\nrelated risk levels in a specific area over a defined time period. With climate\nchange intensifying fire behavior and frequency, accurate prediction has become\none of the most pressing challenges in Artificial Intelligence (AI).\nTraditionally, fire ignition is approached as a binary classification task in\nthe literature. However, this formulation oversimplifies the problem,\nespecially from the perspective of end-users such as firefighters. In general,\nas is the case in France, firefighting units are organized by department, each\nwith its terrain, climate conditions, and historical experience with fire\nevents. Consequently, fire risk should be modeled in a way that is sensitive to\nlocal conditions and does not assume uniform risk across all regions. This\npaper proposes a new approach that tailors fire risk assessment to departmental\ncontexts, offering more actionable and region-specific predictions for\noperational use. With this, we present the first national-scale AI benchmark\nfor metropolitan France using state-of-the-art AI models on a relatively\nunexplored dataset. Finally, we offer a summary of important future works that\nshould be taken into account. Supplementary materials are available on GitHub.", "AI": {"tldr": "The paper introduces a localized approach to forest fire prediction, addressing the limitations of traditional binary classification by tailoring risk assessments to departmental contexts in France.", "motivation": "Climate change has increased fire frequency and intensity, making accurate prediction crucial. Traditional binary classification oversimplifies the problem for end-users like firefighters, necessitating a localized approach.", "method": "Proposes a new AI-based method for fire risk assessment tailored to departmental conditions, using state-of-the-art models on an unexplored dataset for metropolitan France.", "result": "Presents the first national-scale AI benchmark for France, providing region-specific and actionable fire risk predictions.", "conclusion": "Highlights the need for localized risk modeling and suggests future research directions, with supplementary materials available on GitHub."}}
{"id": "2506.04857", "pdf": "https://arxiv.org/pdf/2506.04857", "abs": "https://arxiv.org/abs/2506.04857", "authors": ["Junming Duan", "Praveen Chandrashekar", "Christian Klingenberg"], "title": "Active flux for ideal magnetohydrodynamics: A positivity-preserving scheme with the Godunov-Powell source term", "categories": ["math.NA", "cs.NA"], "comment": "27 pages, 12 figures", "summary": "The Active Flux (AF) is a compact, high-order finite volume scheme that\nallows more flexibility by introducing additional point value degrees of\nfreedom at cell interfaces. This paper proposes a positivity-preserving (PP) AF\nscheme for solving the ideal magnetohydrodynamics, where the Godunov-Powell\nsource term is employed to deal with the divergence-free constraint. For the\nevolution of the cell average, apart from the standard conservative finite\nvolume method for the flux derivative, the nonconservative source term is built\non the quadratic reconstruction in each cell, which maintains the compact\nstencil in the AF scheme. For the point value update, the local Lax-Friedrichs\n(LLF) flux vector splitting is adopted for the flux derivative, originally\nproposed in [Duan, Barsukow, and Klingenberg, SIAM Journal on Scientific\nComputing, 47(2), A811--A837, 2025], and a central difference is used to\ndiscretize the divergence in the source term. A parametrized flux limiter and a\nscaling limiter are presented to preserve the density and pressure positivity\nby blending the AF scheme with the first-order PP LLF scheme with the source\nterm. To suppress oscillations, a new shock sensor considering the divergence\nerror is proposed, which is used to compute the blending coefficients for the\ncell average. Several numerical tests are conducted to verify the third-order\naccuracy, PP property, and shock-capturing ability of the scheme. The key role\nof the Godunov-Powell source term and its suitable discretization in\ncontrolling divergence error is also validated.", "AI": {"tldr": "The paper introduces a positivity-preserving Active Flux (AF) scheme for ideal magnetohydrodynamics, using the Godunov-Powell source term to handle divergence-free constraints. It employs a compact stencil, LLF flux vector splitting, and limiters to ensure positivity and accuracy.", "motivation": "To develop a high-order, compact AF scheme that maintains positivity and handles divergence-free constraints in magnetohydrodynamics simulations.", "method": "Uses a quadratic reconstruction for nonconservative terms, LLF flux splitting for point values, and introduces limiters and a shock sensor for positivity and oscillation control.", "result": "Demonstrates third-order accuracy, preserves positivity, and effectively captures shocks while controlling divergence errors.", "conclusion": "The proposed AF scheme is effective for magnetohydrodynamics, balancing accuracy, positivity, and divergence control."}}
{"id": "2506.04491", "pdf": "https://arxiv.org/pdf/2506.04491", "abs": "https://arxiv.org/abs/2506.04491", "authors": ["IceCube Collaboration"], "title": "GollumFit: An IceCube Open-Source Framework for Binned-Likelihood Neutrino Telescope Analyses", "categories": ["hep-ex", "astro-ph.HE", "physics.comp-ph", "physics.data-an"], "comment": null, "summary": "We present GollumFit, a framework designed for performing binned-likelihood\nanalyses on neutrino telescope data. GollumFit incorporates model parameters\ncommon to any neutrino telescope and also model parameters specific to the\nIceCube Neutrino Observatory. We provide a high-level overview of its key\nfeatures and how the code is organized. We then discuss the performance of the\nfitting in a typical analysis scenario, highlighting the ability to fit over\ntens of nuisance parameters. We present some examples showing how to use the\npackage for likelihood minimization tasks. This framework uniquely incorporates\nthe particular model parameters necessary for neutrino telescopes, and solves\nan associated likelihood problem in a time-efficient manner.", "AI": {"tldr": "GollumFit is a framework for binned-likelihood analyses in neutrino telescope data, tailored for IceCube, with efficient handling of nuisance parameters.", "motivation": "To address the need for a specialized framework for neutrino telescope data analysis, particularly for IceCube, incorporating both general and specific model parameters.", "method": "The framework organizes code for binned-likelihood analyses, supports fitting over tens of nuisance parameters, and provides tools for likelihood minimization.", "result": "GollumFit efficiently solves likelihood problems and demonstrates performance in typical analysis scenarios.", "conclusion": "GollumFit is a unique and time-efficient solution for neutrino telescope data analysis, especially for IceCube."}}
{"id": "2506.04769", "pdf": "https://arxiv.org/pdf/2506.04769", "abs": "https://arxiv.org/abs/2506.04769", "authors": ["Tomasz D\u0119biec", "Piotr Gwiazda", "B\u0142a\u017cej Miasojedow", "Katarzyna Ryszewska", "Zuzanna Szyma\u0144ska", "Aneta Wr\u00f3blewska-Kami\u0144ska"], "title": "Lipschitz stability for Bayesian inference in porous medium tissue growth models", "categories": ["math.AP", "35B30, 35B35, 35B45, 35K57, 35K65, 35Q92"], "comment": null, "summary": "We consider a macroscopic model for the dynamics of living tissues\nincorporating pressure-driven dispersal and pressure-modulated proliferation.\nGiven a power-law constitutive relation between the pressure and cell density,\nthe model can be written as a porous medium equation with a growth term. We\nprove Lipschitz continuity of the mild solutions of the model with respect to\nthe diffusion parameter (the exponent $\\gamma$ in the pressure-density law) in\nthe $L_1$ norm. While of independent analytical interest, our motivation for\nthis result is to provide a vital step towards using Bayesian inverse problem\nmethodology for parameter estimation based on experimental data -- such\nstability estimates are indispensable for applying sampling algorithms which\nrely on the gradient of the likelihood function.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.04268", "pdf": "https://arxiv.org/pdf/2506.04268", "abs": "https://arxiv.org/abs/2506.04268", "authors": ["Jingyang Li", "Guoqiang Li"], "title": "MUC-G4: Minimal Unsat Core-Guided Incremental Verification for Deep Neural Network Compression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid development of deep learning has led to challenges in deploying\nneural networks on edge devices, mainly due to their high memory and runtime\ncomplexity. Network compression techniques, such as quantization and pruning,\naim to reduce this complexity while maintaining accuracy. However, existing\nincremental verification methods often focus only on quantization and struggle\nwith structural changes. This paper presents MUC-G4 (Minimal Unsat Core-Guided\nIncremental Verification), a novel framework for incremental verification of\ncompressed deep neural networks. It encodes both the original and compressed\nnetworks into SMT formulas, classifies changes, and use \\emph{Minimal Unsat\nCores (MUCs)} from the original network to guide efficient verification for the\ncompressed network. Experimental results show its effectiveness in handling\nquantization and pruning, with high proof reuse rates and significant speedup\nin verification time compared to traditional methods. MUC-G4 hence offers a\npromising solution for ensuring the safety and reliability of compressed neural\nnetworks in practical applications.", "AI": {"tldr": "MUC-G4 is a framework for incremental verification of compressed neural networks, using Minimal Unsat Cores for efficient verification.", "motivation": "Challenges in deploying neural networks on edge devices due to high complexity, and limitations of existing verification methods.", "method": "Encodes original and compressed networks into SMT formulas, classifies changes, and uses Minimal Unsat Cores for guided verification.", "result": "Effective in handling quantization and pruning, with high proof reuse and faster verification than traditional methods.", "conclusion": "MUC-G4 ensures safety and reliability of compressed networks, offering practical benefits."}}
{"id": "2506.04880", "pdf": "https://arxiv.org/pdf/2506.04880", "abs": "https://arxiv.org/abs/2506.04880", "authors": ["Heiko Gimperlein", "Ruma R. Maity"], "title": "Numerical analysis for constrained and unconstrained Q-tensor energies for liquid crystals", "categories": ["math.NA", "cs.NA", "65N12, 35J47, 65N30, 76A15"], "comment": null, "summary": "This paper introduces a comprehensive finite element approximation framework\nfor three-dimensional Landau-de Gennes $Q$-tensor energies for nematic liquid\ncrystals, with a particular focus on the anisotropy of the elastic energy and\nthe Ball-Majumdar singular potential. This potential imposes essential physical\nconstraints on the eigenvalues of the $Q$-tensor, ensuring realistic modeling.\nWe address the approximation of regular solutions to nonlinear elliptic partial\ndifferential equations with non-homogeneous boundary conditions associated with\nLandau-de Gennes energies. The well-posedness of the discrete linearized\nproblem is rigorously demonstrated. The existence and local uniqueness of the\ndiscrete solution is derived using the Newton-Kantorovich theorem. Furthermore,\nwe demonstrate an optimal order convergence rate in the energy norm and discuss\nthe impact of eigenvalue constraints on the a priori error analysis.", "AI": {"tldr": "A finite element framework for 3D Landau-de Gennes Q-tensor energies in nematic liquid crystals, focusing on anisotropic elastic energy and the Ball-Majumdar potential, with rigorous analysis of well-posedness, convergence, and eigenvalue constraints.", "motivation": "To model nematic liquid crystals realistically by addressing anisotropy and physical constraints on Q-tensor eigenvalues, ensuring accurate solutions to nonlinear elliptic PDEs.", "method": "Finite element approximation for nonlinear elliptic PDEs with non-homogeneous boundary conditions, using the Newton-Kantorovich theorem for discrete solution existence and uniqueness.", "result": "Well-posedness of the discrete problem, optimal convergence rate in energy norm, and analysis of eigenvalue constraints' impact on error.", "conclusion": "The framework effectively models nematic liquid crystals with rigorous theoretical backing, demonstrating practical and theoretical validity."}}
{"id": "2506.04523", "pdf": "https://arxiv.org/pdf/2506.04523", "abs": "https://arxiv.org/abs/2506.04523", "authors": ["Cliff B. Abbott", "Mark Elo", "Dmytro A. Bozhko"], "title": "Perturbative Gradient Training: A novel training paradigm for bridging the gap between deep neural networks and physical reservoir computing", "categories": ["cs.LG", "cond-mat.mes-hall", "cs.ET", "cs.NE", "physics.comp-ph"], "comment": "7 pages, 8 figures, submitted to IEEE Transactions on Neural Netowrks\n  and Learning Systems", "summary": "We introduce Perturbative Gradient Training (PGT), a novel training paradigm\nthat overcomes a critical limitation of physical reservoir computing: the\ninability to perform backpropagation due to the black-box nature of physical\nreservoirs. Drawing inspiration from perturbation theory in physics, PGT uses\nrandom perturbations in the network's parameter space to approximate gradient\nupdates using only forward passes. We demonstrate the feasibility of this\napproach on both simulated neural network architectures, including a dense\nnetwork and a transformer model with a reservoir layer, and on experimental\nhardware using a magnonic auto-oscillation ring as the physical reservoir. Our\nresults show that PGT can achieve performance comparable to that of standard\nbackpropagation methods in cases where backpropagation is impractical or\nimpossible. PGT represents a promising step toward integrating physical\nreservoirs into deeper neural network architectures and achieving significant\nenergy efficiency gains in AI training.", "AI": {"tldr": "PGT is a new training method using perturbations to approximate gradients, enabling backpropagation-free training for physical reservoirs, with comparable performance to backpropagation.", "motivation": "Overcome the limitation of physical reservoir computing, where backpropagation is impossible due to the black-box nature of physical reservoirs.", "method": "Uses random perturbations in parameter space to approximate gradient updates, requiring only forward passes. Tested on simulated networks and experimental hardware.", "result": "PGT achieves performance similar to backpropagation in cases where backpropagation is impractical.", "conclusion": "PGT enables deeper integration of physical reservoirs into neural networks, promising energy efficiency gains in AI training."}}
{"id": "2506.04927", "pdf": "https://arxiv.org/pdf/2506.04927", "abs": "https://arxiv.org/abs/2506.04927", "authors": ["Petru Jebelean", "Jean Mawhin", "Calin Serban"], "title": "Periodic solutions for p(t)-Lienard equations with a singular nonlinearity of attractive type", "categories": ["math.AP", "math.CA"], "comment": null, "summary": "We are concerned with the existence of $T$-periodic solutions to an equation\nof type $$\\left (|u'(t))|^{p(t)-2} u'(t) \\right\n)'+f(u(t))u'(t)+g(u(t))=h(t)\\quad \\mbox{ in }[0,T]$$ where\n$p:[0,T]\\to(1,\\infty)$ with $p(0)=p(T)$ and $h$ are continuous on $[0,T]$,\n$f,g$ are also continuous on $[0,\\infty)$, respectively $(0,\\infty)$. The\nmapping $g$ may have an attractive singularity (i.e. $g(x) \\to +\\infty$ as\n$x\\to 0+$). Our approach relies on a continuation theorem obtained in the\nrecent paper M. Garc\\'{i}a-Huidobro, R. Man\\'{a}sevich, J. Mawhin and S.\nTanaka, J. Differential Equations (2024), a priori estimates and method of\nlower and upper solutions.", "AI": {"tldr": "The paper investigates the existence of T-periodic solutions for a singular differential equation with variable exponent p(t) and an attractive singularity in g(x).", "motivation": "The study is motivated by the need to understand periodic solutions in equations with singularities and variable exponents, which are common in physical and engineering applications.", "method": "The approach uses a continuation theorem, a priori estimates, and the method of lower and upper solutions.", "result": "The paper establishes conditions under which T-periodic solutions exist for the given equation.", "conclusion": "The results extend understanding of periodic solutions in singular differential equations with variable exponents."}}
{"id": "2506.04272", "pdf": "https://arxiv.org/pdf/2506.04272", "abs": "https://arxiv.org/abs/2506.04272", "authors": ["Kyung Rok Kim", "Yumo Bai", "Chonghuan Wang", "Guanting Chen"], "title": "Understanding the Impact of Sampling Quality in Direct Preference Optimization", "categories": ["cs.LG"], "comment": "Submitted to NeurIPS2025", "summary": "We study the role of the sampling distribution in Direct Preference\nOptimization (DPO) and aim to understand its impact on DPO's training dynamics.\nOur analyses show that both the solution space and the convergence behavior of\nDPO depend on the support and quality of the generating distribution. We first\nanalyze how distribution of responses influences policy updates during gradient\ndescent, drawing connections to common phenomena found in practice. We then\ndesign a simplified yet well-structured alignment model as a proxy, and develop\nquantitative results showing how more frequent high-quality responses amplify\nthe gradient signal and improve the optimization landscape, leading to more\neffective policy learning. Our theoretical findings are supported by empirical\nexperiments and provide a principled justification for the online DPO framework\nin practice.", "AI": {"tldr": "The paper examines how the sampling distribution affects Direct Preference Optimization (DPO), showing its influence on training dynamics, solution space, and convergence. High-quality responses improve gradient signals and policy learning.", "motivation": "To understand the impact of the sampling distribution on DPO's training dynamics and optimization landscape.", "method": "Analyzed the influence of response distribution on policy updates, designed a simplified alignment model, and conducted empirical experiments.", "result": "High-quality responses amplify gradient signals, improving the optimization landscape and policy learning.", "conclusion": "The findings justify the online DPO framework, emphasizing the importance of sampling distribution quality."}}
{"id": "2506.04969", "pdf": "https://arxiv.org/pdf/2506.04969", "abs": "https://arxiv.org/abs/2506.04969", "authors": ["Yema Paul", "Emmanuel Delande", "Francois Vinet", "Francois Laporte", "Manuel Sanjurjo-Rivo", "Aldo Tonnini", "Joan-Pau Sanchez"], "title": "Probability of Collision with Tethered Spacecraft", "categories": ["math.NA", "cs.NA"], "comment": "13 pages, 2 figures, Engineering Note", "summary": "This Engineering Note addresses the challenge of estimating the probability\nof collision for tethered spacecraft during close encounters with other space\nobjects. Standard probability of collision methods, based on spherical\nhard-body assumptions, tend to be overly conservative when applied to long\ntether systems. We introduce a method that accounts for the tether's spatial\nextent and configuration uncertainty by maximizing the probability of collision\nover all physically admissible tether shapes. Applied to real-world conjunction\nevents involving a kilometer-scale flexible inextensible tether, the method\nyields more realistic risk estimates. This approach improves the ability to\ndistinguish hazardous from benign encounters, thereby supporting more informed\ncollision avoidance decisions.", "AI": {"tldr": "A method for estimating collision probability for tethered spacecraft, improving accuracy by accounting for tether shape and uncertainty.", "motivation": "Standard collision probability methods are overly conservative for tethered systems, leading to unrealistic risk estimates.", "method": "Maximizes collision probability over all physically admissible tether shapes to account for spatial extent and configuration uncertainty.", "result": "Applied to real-world events, the method provides more realistic risk estimates, distinguishing hazardous from benign encounters.", "conclusion": "This approach supports better-informed collision avoidance decisions for tethered spacecraft."}}
{"id": "2506.04781", "pdf": "https://arxiv.org/pdf/2506.04781", "abs": "https://arxiv.org/abs/2506.04781", "authors": ["Christoph Schirninger", "Robert Jarolim", "Astrid M. Veronig", "Christoph Kuckein"], "title": "Deep learning image burst stacking to reconstruct high-resolution ground-based solar observations", "categories": ["astro-ph.SR", "astro-ph.IM", "cs.CV", "physics.comp-ph"], "comment": null, "summary": "Large aperture ground based solar telescopes allow the solar atmosphere to be\nresolved in unprecedented detail. However, observations are limited by Earths\nturbulent atmosphere, requiring post image corrections. Current reconstruction\nmethods using short exposure bursts face challenges with strong turbulence and\nhigh computational costs. We introduce a deep learning approach that\nreconstructs 100 short exposure images into one high quality image in real\ntime. Using unpaired image to image translation, our model is trained on\ndegraded bursts with speckle reconstructions as references, improving\nrobustness and generalization. Our method shows an improved robustness in terms\nof perceptual quality, especially when speckle reconstructions show artifacts.\nAn evaluation with a varying number of images per burst demonstrates that our\nmethod makes efficient use of the combined image information and achieves the\nbest reconstructions when provided with the full image burst.", "AI": {"tldr": "A deep learning method reconstructs 100 short-exposure solar images into one high-quality image in real-time, outperforming traditional speckle reconstruction in robustness and perceptual quality.", "motivation": "Large ground-based solar telescopes face limitations due to Earth's atmospheric turbulence, requiring post-processing corrections. Current methods struggle with strong turbulence and high computational costs.", "method": "The approach uses unpaired image-to-image translation, training on degraded bursts with speckle reconstructions as references to improve robustness and generalization.", "result": "The method shows superior perceptual quality, especially when speckle reconstructions exhibit artifacts, and performs best with the full image burst.", "conclusion": "The deep learning approach efficiently combines image information, offering real-time, high-quality solar image reconstruction."}}
{"id": "2506.04967", "pdf": "https://arxiv.org/pdf/2506.04967", "abs": "https://arxiv.org/abs/2506.04967", "authors": ["Claudianor O. Alves", "Rui Ding", "Chao Ji"], "title": "Existence and multiplicity of normalized solutions for the generalized Kadomtsev-Petviashvili equation in $\\mathbb{R}^2$", "categories": ["math.AP", "35A15, 35A18"], "comment": "26 pages", "summary": "In this paper, we study the existence and {multiplicity} of nontrivial\nsolitary waves for the generalized Kadomtsev-Petviashvili equation with\nprescribed {$L^2$-norm} \\begin{equation*}\\label{Equation1}\n  \\left\\{\\begin{array}{l}\n  \\left(-u_{x x}+D_x^{-2} u_{y y}+\\lambda u-f(u)\\right)_x=0,{\\quad x \\in\n\\mathbb{R}^2, } \\\\[10pt]\n  \\displaystyle \\int_{\\mathbb{R}^2}u^2 d x=a^2,\n  \\end{array}\\right.%\\tag{$\\mathscr E_\\lambda$} \\end{equation*} where $a>0$ and\n$\\lambda \\in \\mathbb{R}$ is an unknown parameter that appears as a Lagrange\nmultiplier. For the case $f(t)=|t|^{q-2}t$, with $2<q<\\frac{10}{3}$\n($L^2$-subcritical case) and $\\frac{10}{3}<q<6$ ($L^2$-supercritical case), we\nestablish the existence of normalized ground state solutions for the above\nequation. Moreover, when $f(t)=\\mu|t|^{q-2}t+|t|^{p-2}t$, with\n$2<q<\\frac{10}{3}<p<6$ and $\\mu>0$, we prove the existence of normalized ground\nstate solutions which corresponds to a local minimum of the associated energy\nfunctional. In this case, we further show that there exists a sequence $(a_n)\n\\subset (0,a_0)$ with $a_n \\to 0$ as $n \\to+\\infty$, such that for each\n$a=a_n$, the problem admits a second solution with positive energy. To the best\nof our knowledge, this is the first work that studies the existence of\nsolutions for the generalized Kadomtsev-Petviashvili equations under the\n$L^2$-constraint, which we refer to them as the normalized solutions.", "AI": {"tldr": "The paper investigates the existence and multiplicity of nontrivial solitary waves for the generalized Kadomtsev-Petviashvili equation under an L\u00b2-norm constraint, proving normalized ground state solutions for subcritical and supercritical cases, and a second solution for specific conditions.", "motivation": "To address the existence of normalized solutions for the generalized Kadomtsev-Petviashvili equation with prescribed L\u00b2-norm, a problem not previously studied.", "method": "Analyzes the equation with Lagrange multiplier \u03bb, focusing on subcritical (2<q<10/3) and supercritical (10/3<q<6) cases, and extends to combined nonlinearities (f(t)=\u03bc|t|^{q-2}t+|t|^{p-2}t).", "result": "Existence of normalized ground state solutions is proven for both cases. For combined nonlinearities, a second solution with positive energy is shown for a sequence of norms approaching zero.", "conclusion": "This work pioneers the study of normalized solutions for the generalized Kadomtsev-Petviashvili equation, demonstrating existence and multiplicity under L\u00b2 constraints."}}
{"id": "2506.04281", "pdf": "https://arxiv.org/pdf/2506.04281", "abs": "https://arxiv.org/abs/2506.04281", "authors": ["Xu Zheng", "Chaohao Lin", "Sipeng Chen", "Zhuomin Chen", "Jimeng Shi", "Wei Cheng", "Jayantha Obeysekera", "Jason Liu", "Dongsheng Luo"], "title": "SF$^2$Bench: Evaluating Data-Driven Models for Compound Flood Forecasting in South Florida", "categories": ["cs.LG"], "comment": "60 Pages", "summary": "Forecasting compound floods presents a significant challenge due to the\nintricate interplay of meteorological, hydrological, and oceanographic factors.\nAnalyzing compound floods has become more critical as the global climate\nincreases flood risks. Traditional physics-based methods, such as the\nHydrologic Engineering Center's River Analysis System, are often\ntime-inefficient. Machine learning has recently demonstrated promise in both\nmodeling accuracy and computational efficiency. However, the scarcity of\ncomprehensive datasets currently hinders systematic analysis. Existing\nwater-related datasets are often limited by a sparse network of monitoring\nstations and incomplete coverage of relevant factors. To address this\nchallenge, we introduce SF2Bench, a comprehensive time series collection on\ncompound floods in South Florida, which integrates four key factors: tide,\nrainfall, groundwater, and human management activities (gate and pump\ncontrolling). This integration allows for a more detailed analysis of the\nindividual contributions of these drivers to compound flooding and informs the\ndevelopment of improved flood forecasting approaches. To comprehensively\nevaluate the potential of various modeling paradigms, we assess the performance\nof six categories of methods, encompassing Multilayer Perceptrons,\nConvolutional Neural Networks, Recurrent Neural Networks, Graph Neural\nNetworks, Transformers, and Large Language Models. We verified the impact of\ndifferent key features on flood forecasting through experiments. Our analysis\nexamines temporal and spatial aspects, providing insights into the influence of\nhistorical data and spatial dependencies. The varying performance across these\napproaches underscores the diverse capabilities of each in capturing complex\ntemporal and spatial dependencies inherent in compound floods.", "AI": {"tldr": "The paper introduces SF2Bench, a dataset for compound flood analysis in South Florida, and evaluates six machine learning methods to improve flood forecasting.", "motivation": "Compound flood forecasting is complex and traditional methods are inefficient. Machine learning shows promise, but data scarcity limits progress.", "method": "Introduces SF2Bench, integrating tide, rainfall, groundwater, and human activities. Evaluates six ML methods (e.g., CNNs, RNNs, Transformers) for flood forecasting.", "result": "Experiments show varying performance of methods, highlighting their strengths in capturing temporal and spatial dependencies.", "conclusion": "SF2Bench enables detailed analysis of flood drivers, and diverse ML methods offer insights for improved forecasting."}}
{"id": "2506.05174", "pdf": "https://arxiv.org/pdf/2506.05174", "abs": "https://arxiv.org/abs/2506.05174", "authors": ["Yifan Zhang", "Joe Kileel"], "title": "Norming Sets for Tensor and Polynomial Sketching", "categories": ["math.NA", "cs.IT", "cs.NA", "math.AG", "math.IT"], "comment": "16 pages", "summary": "This paper develops the sketching (i.e., randomized dimension reduction)\ntheory for real algebraic varieties and images of polynomial maps, including,\ne.g., the set of low rank tensors and tensor networks. Through the lens of\nnorming sets, we provide a framework for controlling the sketching dimension\nfor \\textit{any} sketch operator used to embed said sets, including\nsub-Gaussian, fast Johnson-Lindenstrauss, and tensor structured sketch\noperators. Leveraging norming set theory, we propose a new sketching method\ncalled the median sketch. It embeds such a set $V$ using only\n$\\widetilde{\\mathcal{O}}(\\dim V)$ tensor structured or sparse linear\nmeasurements.", "AI": {"tldr": "The paper introduces a sketching theory for real algebraic varieties and polynomial maps, focusing on low-rank tensors. It proposes a median sketch method using minimal measurements.", "motivation": "To develop a generalized framework for sketching dimension reduction applicable to various sketch operators and sets like low-rank tensors.", "method": "Uses norming set theory to control sketching dimensions and introduces the median sketch method, requiring only O\u0303(dim V) measurements.", "result": "The median sketch efficiently embeds sets like low-rank tensors with sparse or tensor-structured measurements.", "conclusion": "The framework and median sketch advance sketching theory for algebraic varieties and polynomial maps, offering practical efficiency."}}
{"id": "2506.05034", "pdf": "https://arxiv.org/pdf/2506.05034", "abs": "https://arxiv.org/abs/2506.05034", "authors": ["Boquan Fan", "Yuchen Wang", "Weicheng Zhan"], "title": "Remarks on radial symmetry of stationary and uniformly-rotating solutions for the 2D Euler equation", "categories": ["math.AP"], "comment": "arXiv admin note: text overlap with arXiv:2412.05973", "summary": "We prove that any uniformly rotating solution of the 2D incompressible Euler\nequation with compactly supported vorticity $\\omega$ must be radially symmetric\nwhenever its angular velocity satisfies $\\Omega \\in (-\\infty,\\inf \\omega / 2]\n\\cup \\, [ \\sup \\omega / 2, +\\infty )$, in both the patch and smooth settings.\nThis result extends the rigidity theorems established in\n\\cite{Gom2021MR4312192} (\\textit{Duke Math. J.},170(13):2957-3038, 2021), which\nwere confined to the case of non-positive angular velocities and non-negative\nvorticity. Moreover, our results do not impose any regularity conditions on the\npatch beyond requiring that its boundary consists of Jordan curves, thereby\nrefining the previous result to encompass irregular vortex patches.", "AI": {"tldr": "The paper extends rigidity theorems for 2D Euler equation solutions, proving radial symmetry for rotating solutions with compactly supported vorticity under broader angular velocity conditions, including irregular vortex patches.", "motivation": "To generalize previous rigidity results for rotating Euler equation solutions by removing restrictions on angular velocity and vorticity sign, and to include irregular vortex patches.", "method": "Analyzes uniformly rotating solutions of the 2D incompressible Euler equation with compactly supported vorticity, focusing on angular velocity ranges and boundary conditions.", "result": "Proves radial symmetry for solutions when angular velocity lies outside a specific interval, even for irregular vortex patches.", "conclusion": "The work broadens the scope of rigidity theorems, covering more general cases and irregular patches, enhancing understanding of rotating Euler solutions."}}
{"id": "2506.04282", "pdf": "https://arxiv.org/pdf/2506.04282", "abs": "https://arxiv.org/abs/2506.04282", "authors": ["Runxiang Wang", "Boxiao Wang", "Kai Li", "Yifan Zhang", "Jian Cheng"], "title": "DrSR: LLM based Scientific Equation Discovery with Dual Reasoning from Data and Experience", "categories": ["cs.LG"], "comment": null, "summary": "Symbolic regression is a fundamental tool for discovering interpretable\nmathematical expressions from data, with broad applications across scientific\nand engineering domains. Recently, large language models (LLMs) have\ndemonstrated strong performance in this task, leveraging embedded scientific\npriors and reasoning capabilities to surpass traditional methods. However,\nexisting LLM-based approaches, such as LLM-SR, often over-rely on internal\npriors, lacking explicit data understanding and systematic reflection during\nequation generation. To address these limitations, we propose DrSR (Dual\nReasoning Symbolic Regression), a framework that combines data-driven insight\nwith reflective learning to enhance both robustness and discovery capability.\nSpecifically, DrSR guides LLMs to analyze structural relationships (e.g.,\nmonotonicity, nonlinearity, and correlation) within the data to generate\nstructured descriptions. Simultaneously, it monitors equation performance and\nestablishes a feedback loop to refine subsequent generations. By integrating\ndata understanding and generation reflection in a closed loop, DrSR enables\nmore efficient exploration of the symbolic expression space. Experiments across\ninterdisciplinary datasets in physics, chemistry, biology, and materials\nscience demonstrate that DrSR substantially improves the valid equation rate\nand consistently outperforms both classical and recent LLM-based methods in\nterms of accuracy, generalization, and search efficiency. These results\nunderscore its potential for scientific equation discovery.", "AI": {"tldr": "DrSR (Dual Reasoning Symbolic Regression) enhances symbolic regression by combining data-driven insights and reflective learning, outperforming traditional and LLM-based methods in accuracy and efficiency.", "motivation": "Existing LLM-based symbolic regression methods over-rely on internal priors and lack systematic data understanding, limiting robustness and discovery capability.", "method": "DrSR integrates data-driven analysis (e.g., structural relationships) with reflective learning, creating a feedback loop to refine equation generation.", "result": "DrSR improves valid equation rates and outperforms classical and LLM-based methods in accuracy, generalization, and efficiency across interdisciplinary datasets.", "conclusion": "DrSR's dual reasoning approach advances symbolic regression, demonstrating strong potential for scientific equation discovery."}}
{"id": "2506.04279", "pdf": "https://arxiv.org/pdf/2506.04279", "abs": "https://arxiv.org/abs/2506.04279", "authors": ["Adama Nouboukpo", "Kodzo Michel Aladji", "Muktar Bappa"], "title": "Nombre Effectif de Partis Politiques en Afrique: Une Nouvelle M\u00e9thode pour un Calcul Objectif et Institutionnellement Neutre", "categories": ["physics.soc-ph", "cs.NA", "math.NA"], "comment": "in French language", "summary": "Political fragmentation in Africa poses to a significant challenge to\neffective governance and stability. Traditional measures of party system\nfragmentation, such as the Effective Number of Parties (ENP) index, often fail\nto capture the nuanced realities of African political landscapes, particularly\nthe influence of dominant parties, fluid party affiliations, and the impact of\nethnic and regional cleavages. To address these limitations, this paper\nintroduces two novel \"apolitical\" or \"institutionally neutral\" measures for\ncalculating the effective number of parties, focusing on geographical and\ndemographic dimensions, notably population size and territorial area. By\nincorporating these local realities and ensuring a minimum threshold of two\nparties, the proposed models offer a simpler and more contextually relevant\nframework for understanding political dynamics in Africa, especially in\ndata-scarce environments. This approach provides a valuable tool for analyzing\nand streamlining political systems, with potential for broader application\nbeyond the African context.", "AI": {"tldr": "The paper introduces two new measures for calculating the effective number of parties in Africa, focusing on geographical and demographic dimensions to address the limitations of traditional methods like the ENP index.", "motivation": "Traditional measures like the ENP index fail to capture the nuanced realities of African political landscapes, such as dominant parties, fluid affiliations, and ethnic/regional cleavages.", "method": "The paper proposes two 'apolitical' or 'institutionally neutral' measures, incorporating geographical (territorial area) and demographic (population size) dimensions, with a minimum threshold of two parties.", "result": "The new models provide a simpler and more contextually relevant framework for analyzing political dynamics in Africa, especially in data-scarce environments.", "conclusion": "The approach offers a valuable tool for understanding and streamlining political systems in Africa, with potential for broader application."}}
{"id": "2506.04898", "pdf": "https://arxiv.org/pdf/2506.04898", "abs": "https://arxiv.org/abs/2506.04898", "authors": ["Xintong Zou", "Zhijie Li", "Yunpeng Wang", "Huiyu Yang", "Jianchun Wang"], "title": "Uncertainty quantification and stability of neural operators for prediction of three-dimensional turbulence", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": null, "summary": "Turbulence poses challenges for numerical simulation due to its chaotic,\nmultiscale nature and high computational cost. Traditional turbulence modeling\noften struggles with accuracy and long-term stability. Recent scientific\nmachine learning (SciML) models, such as Fourier Neural Operators (FNO), show\npromise in solving PDEs, but are typically limited to one-step-ahead\npredictions and often fail over long time horizons, especially in 3D\nturbulence. This study proposes a framework to assess the reliability of neural\noperator models in turbulent flows. Using three-dimensional forced homogeneous\nisotropic turbulence (HIT) as a benchmark, we evaluate models in terms of\nuncertainty quantification (UQ), error propagation, and sensitivity to initial\nperturbations. Statistical tools such as error distribution analysis and\nautocorrelation functions (ACF) are used to assess predictive robustness and\ntemporal coherence. Our proposed model, the factorized-implicit FNO (F-IFNO),\nimproves long-term stability and accuracy by incorporating implicit\nfactorization into the prediction process. It outperforms conventional LES and\nother FNO-based models in balancing accuracy, stability, and efficiency. The\nresults highlight the importance of prediction constraints, time interval\nselection, and UQ in developing robust neural operator frameworks for turbulent\nsystems.", "AI": {"tldr": "The paper proposes a framework to evaluate neural operator models in turbulent flows, introducing the F-IFNO model for improved long-term stability and accuracy.", "motivation": "Traditional turbulence modeling struggles with accuracy and stability, while existing SciML models like FNO fail over long time horizons in 3D turbulence.", "method": "The study uses 3D forced HIT as a benchmark, employing UQ, error propagation analysis, and sensitivity tests. Statistical tools like error distribution and ACF are used.", "result": "The F-IFNO model outperforms conventional LES and other FNO-based models in accuracy, stability, and efficiency.", "conclusion": "The study emphasizes the importance of prediction constraints, time interval selection, and UQ for robust neural operator frameworks in turbulence."}}
{"id": "2506.05060", "pdf": "https://arxiv.org/pdf/2506.05060", "abs": "https://arxiv.org/abs/2506.05060", "authors": ["Adam Grzela", "Katarzyna Mazowiecka"], "title": "Existence of infinitely many homotopy classes from $\\mathbb S^3$ to $\\mathbb S^2$ having a minimimzing $W^{s,\\frac 3s}$-harmonic map", "categories": ["math.AP"], "comment": null, "summary": "In 1998 T. Rivi\\`{e}re proved that there exist infinitely many homotopy\nclasses of $\\pi_3(\\mathbb S^2)$ having a minimizing 3-harmonic map. This result\nis especially surprising taking into account that in $\\pi_3(\\mathbb S^3)$ there\nare only three homotopy classes (corresponding to the degrees $\\{-1,0,1\\}$) in\nwhich a minimizer exists.\n  We extend this theorem in the framework of fractional harmonic maps and prove\nthat for $s\\in(0,1)$ there exist infinitely many homotopy classes of\n$\\pi_{3}(\\mathbb S^{2})$ in which there is a minimizing\n$W^{s,\\frac{3}{s}}$-harmonic map.", "AI": {"tldr": "The paper extends Rivi\u00e8re's 1998 result on minimizing 3-harmonic maps in \u03c0\u2083(S\u00b2) to fractional harmonic maps, showing infinitely many homotopy classes with minimizers for s \u2208 (0,1).", "motivation": "The motivation is to generalize Rivi\u00e8re's surprising result about minimizing harmonic maps in specific homotopy classes to the fractional setting.", "method": "The authors use the framework of fractional harmonic maps, specifically W^{s,3/s}-harmonic maps, to extend the theorem.", "result": "They prove that for s \u2208 (0,1), infinitely many homotopy classes in \u03c0\u2083(S\u00b2) admit minimizing W^{s,3/s}-harmonic maps.", "conclusion": "This work generalizes Rivi\u00e8re's findings to fractional harmonic maps, revealing new insights into minimizing properties in homotopy classes."}}
{"id": "2506.04285", "pdf": "https://arxiv.org/pdf/2506.04285", "abs": "https://arxiv.org/abs/2506.04285", "authors": ["Stephen Smith", "Cormac Purcell", "Zdenka Kuncic"], "title": "Training-free AI for Earth Observation Change Detection using Physics Aware Neuromorphic Networks", "categories": ["cs.LG"], "comment": "16 pages, 9 figures, 3 tables", "summary": "Earth observations from low Earth orbit satellites provide vital information\nfor decision makers to better manage time-sensitive events such as natural\ndisasters. For the data to be most effective for first responders, low latency\nis required between data capture and its arrival to decision makers. A major\nbottleneck is in the bandwidth-limited downlinking of the data from satellites\nto ground stations. One approach to overcome this challenge is to process at\nleast some of the data on-board and prioritise pertinent data to be downlinked.\nIn this work we propose a Physics Aware Neuromorphic Network (PANN) to detect\nchanges caused by natural disasters from a sequence of multi-spectral satellite\nimages and produce a change map, enabling relevant data to be prioritised for\ndownlinking. The PANN used in this study is motivated by physical neural\nnetworks comprised of nano-electronic circuit elements known as \"memristors\"\n(nonlinear resistors with memory). The weights in the network are dynamic and\nupdate in response to varying input signals according to memristor equations of\nstate and electrical circuit conservation laws. The PANN thus generates\nphysics-constrained dynamical output features which are used to detect changes\nin a natural disaster detection task by applying a distance-based metric.\nImportantly, this makes the whole model training-free, allowing it to be\nimplemented with minimal computing resources. The PANN was benchmarked against\na state-of-the-art AI model and achieved comparable or better results in each\nnatural disaster category. It thus presents a promising solution to the\nchallenge of resource-constrained on-board processing.", "AI": {"tldr": "Proposes a Physics Aware Neuromorphic Network (PANN) for real-time natural disaster detection from satellite images, enabling prioritized data downlinking with minimal computing resources.", "motivation": "To address the bottleneck of bandwidth-limited satellite data downlinking by enabling on-board processing and prioritization of relevant disaster data.", "method": "Uses a PANN inspired by memristor-based physical neural networks, with dynamic weights updated via physics constraints, eliminating the need for training.", "result": "PANN matched or outperformed a state-of-the-art AI model in disaster detection, proving effective for resource-constrained on-board processing.", "conclusion": "PANN offers a viable, training-free solution for real-time disaster detection and data prioritization in satellites."}}
{"id": "2506.05031", "pdf": "https://arxiv.org/pdf/2506.05031", "abs": "https://arxiv.org/abs/2506.05031", "authors": ["Mohammad Mirzakhani", "Kyungsun Moon"], "title": "Quantum simulation of the Hubbard model on a graphene hexagon: Strengths of IQPE and noise constraints", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.str-el", "physics.comp-ph"], "comment": "14 pages, 10 figures", "summary": "Quantum computing offers transformative potential for simulating real-world\nmaterials, providing a powerful platform to investigate complex quantum systems\nacross quantum chemistry and condensed matter physics. In this work, we\nleverage this capability to simulate the Hubbard model on a six-site graphene\nhexagon using Qiskit, employing the Iterative Quantum Phase Estimation (IQPE)\nand adiabatic evolution algorithms to determine its ground-state properties.\nNoiseless simulations yield accurate ground-state energies (GSEs), charge and\nspin densities, and correlation functions, all in excellent agreement with\nexact diagonalization, underscoring the precision and reliability of quantum\nsimulation for strongly correlated electron systems. However, deploying IQPE\nand adiabatic evolution on today's noisy quantum hardware remains highly\nchallenging. To examine these limitations, we utilize the Qiskit Aer simulator\nwith a custom noise model tailored to the characteristics of IBM's real\nbackend. This model includes realistic depolarizing gate errors, thermal\nrelaxation, and readout noise, allowing us to explore how these factors degrade\nsimulation accuracy. Preliminary hardware runs on IBM devices further expose\ndiscrepancies between simulated and real-world noise, emphasizing the gap\nbetween ideal and practical implementations. Overall, our results highlight the\npromise of quantum computing for simulating correlated quantum materials, while\nalso revealing the significant challenges posed by hardware noise in achieving\naccurate and reliable physical predictions using current quantum devices.", "AI": {"tldr": "Quantum simulation of the Hubbard model on graphene using Qiskit shows promise but faces noise challenges on current hardware.", "motivation": "To explore quantum computing's potential for simulating strongly correlated electron systems like the Hubbard model on graphene.", "method": "Used Iterative Quantum Phase Estimation (IQPE) and adiabatic evolution algorithms in noiseless and noisy simulations, including a custom noise model for IBM hardware.", "result": "Noiseless simulations matched exact diagonalization results, but noise degraded accuracy, revealing hardware limitations.", "conclusion": "Quantum computing holds promise for material simulation, but current noise levels hinder practical accuracy."}}
{"id": "2506.05149", "pdf": "https://arxiv.org/pdf/2506.05149", "abs": "https://arxiv.org/abs/2506.05149", "authors": ["Louise Gassot", "Thierry Laurens"], "title": "Global well-posedness for the ILW equation in $H^s(\\mathbb{T})$ for $s>-\\frac12$", "categories": ["math.AP"], "comment": null, "summary": "We prove that the intermediate long wave (ILW) equation is globally\nwell-posed in the Sobolev spaces $H^s(\\mathbb{T})$ for $s > -\\frac12$. The\nprevious record for well-posedness was $s\\geq 0$, and the system is known to be\nill-posed for $s<-\\frac12$. We then demonstrate that the solutions of ILW\nconverge to those of the Benjamin--Ono equation in $H^s(\\mathbb{T})$ in the\ninfinite-depth limit.\n  Our methods do not rely on the complete integrability of ILW, but rather\ntreat ILW as a perturbation of the Benjamin--Ono equation by a linear term of\norder zero. To highlight this, we establish a general well-posedness result for\nsuch perturbations, which also applies to the Smith equation for\ncontinental-shelf waves.", "AI": {"tldr": "The paper proves global well-posedness of the ILW equation in Sobolev spaces for $s > -\\frac12$, improves the previous record ($s\\geq 0$), and shows convergence to the Benjamin-Ono equation in the infinite-depth limit.", "motivation": "To extend the well-posedness range of the ILW equation and understand its behavior as a perturbation of the Benjamin-Ono equation.", "method": "Treats ILW as a perturbation of the Benjamin-Ono equation, avoiding reliance on integrability, and establishes a general well-posedness framework for such perturbations.", "result": "Global well-posedness for $s > -\\frac12$ and convergence to Benjamin-Ono solutions in the infinite-depth limit.", "conclusion": "The ILW equation is well-posed for $s > -\\frac12$, and the method applies to other systems like the Smith equation."}}
{"id": "2506.04288", "pdf": "https://arxiv.org/pdf/2506.04288", "abs": "https://arxiv.org/abs/2506.04288", "authors": ["Jae Wan Park", "Junhyeok Kim", "Youngjun Jun", "Hyunah Ko", "Seong Jae Hwang"], "title": "Backbone Augmented Training for Adaptations", "categories": ["cs.LG"], "comment": null, "summary": "Adaptations facilitate efficient training of large backbone models, including\ndiffusion models for image generation and transformer-based language models.\nWhile various adaptation techniques enhance performance with minimal\ncomputational resources, limited adaptation data often leads to challenges in\ntraining. To address this, we focus on the enormous amount of backbone data\nused to pre-train the backbone models. We propose Backbone Augmented Training\n(BAT), a method that leverages backbone data to augment the adaptation dataset.\nFirst, we formulate and prove two mathematical key propositions: one\nestablishes the validity of BAT, while the other identifies a condition under\nwhich BAT benefits adaptation. Furthermore, we introduce an advanced data\nselection scheme that satisfies these propositions and present ALBAT algorithm\nto implement this approach. ALBAT efficiently enhances adaptation training in\nboth personalization and language generation tasks with scarce data.", "AI": {"tldr": "The paper proposes Backbone Augmented Training (BAT) to enhance adaptation training by leveraging backbone data, addressing challenges of limited adaptation data. It introduces ALBAT, an algorithm implementing BAT, validated by mathematical propositions.", "motivation": "Limited adaptation data hinders efficient training of large backbone models, despite their potential. The paper aims to utilize backbone data to augment adaptation datasets.", "method": "Proposes BAT, a method using backbone data for augmentation. Formulates and proves two key propositions, introduces a data selection scheme, and presents ALBAT algorithm.", "result": "ALBAT effectively improves adaptation training in tasks like personalization and language generation with scarce data.", "conclusion": "BAT and ALBAT offer a practical solution to leverage backbone data for better adaptation, validated by theoretical and empirical results."}}
{"id": "2506.05105", "pdf": "https://arxiv.org/pdf/2506.05105", "abs": "https://arxiv.org/abs/2506.05105", "authors": ["Fang-Cheng Wang", "Qi-Jun Ye", "Yu-Cheng Zhu", "Xin-Zheng Li"], "title": "Classification and enumeration of solid-solid phase transition mechanisms", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "22 pages, 14 figures", "summary": "Crystal-structure match (CSM), the atom-to-atom correspondence between two\ncrystalline phases, is used extensively to describe solid-solid phase\ntransition (SSPT) mechanisms. However, existing computational methods cannot\naccount for all possible CSMs. Here, we propose a formalism to classify all\nCSMs into a tree structure, which is independent of the choices of unit cell\nand supercell. We rigorously proved that only a finite number of noncongruent\nCSMs are of practical interest. By representing CSMs as integer matrices, we\nintroduce the crystmatch method to exhaustively enumerate them, which\nuncontroversially solves the CSM optimization problem under any geometric\ncriterion. For most SSPTs, crystmatch can reproduce all known deformation\nmechanisms and CSMs within 10 CPU minutes, while also revealing thousands of\nnew candidates. The resulting database can be further used for comparing\nexperimental phenomena, high-throughput energy barrier calculations, or machine\nlearning.", "AI": {"tldr": "A new method, crystmatch, classifies all crystal-structure matches (CSMs) into a tree structure, solving the CSM optimization problem efficiently and revealing new candidates.", "motivation": "Existing methods fail to account for all possible CSMs, limiting the understanding of solid-solid phase transitions (SSPTs).", "method": "Proposes a formalism to classify CSMs into a tree structure, representing them as integer matrices, and introduces crystmatch for exhaustive enumeration.", "result": "Crystmatch reproduces known mechanisms and CSMs quickly, while uncovering thousands of new candidates.", "conclusion": "The method provides a comprehensive database for analyzing SSPTs, enabling applications in experimental comparison, energy barrier calculations, and machine learning."}}
{"id": "2506.05151", "pdf": "https://arxiv.org/pdf/2506.05151", "abs": "https://arxiv.org/abs/2506.05151", "authors": ["Farhan Abedin", "Giulio Tralli"], "title": "Boundary regularity for subelliptic equations in the Heisenberg group", "categories": ["math.AP", "35J70, 35R05, 35H20, 35B45"], "comment": "35 pages, comments welcome", "summary": "We prove boundary H\\\"older and Lipschitz regularity for a class of degenerate\nelliptic, second order, inhomogeneous equations in non-divergence form\nstructured on the left-invariant vector fields of the Heisenberg group. Our\nfocus is on the case of operators with bounded and measurable coefficients and\nbounded right-hand side; when necessary, we impose a dimensional restriction on\nthe ellipticity ratio and a growth rate for the source term near characteristic\npoints of the boundary. For solutions in the characteristic half-space\n$\\{t>0\\}$, we obtain an intrinsic second order expansion near the origin when\nthe source term belongs to an appropriate weighted $L^{\\infty}$ space; this is\na new result even for the frequently studied sub-Laplacian.", "AI": {"tldr": "The paper establishes boundary regularity results for degenerate elliptic equations in the Heisenberg group, focusing on bounded coefficients and right-hand terms, with new insights for intrinsic expansions.", "motivation": "To address the lack of boundary regularity results for degenerate elliptic equations in non-divergence form within the Heisenberg group, especially for operators with bounded coefficients.", "method": "The study employs techniques for degenerate elliptic equations, imposing dimensional restrictions on ellipticity and growth conditions for source terms near boundary points.", "result": "Proves boundary H\u00f6lder and Lipschitz regularity, and introduces an intrinsic second-order expansion for solutions in the characteristic half-space.", "conclusion": "The findings advance understanding of degenerate elliptic equations in the Heisenberg group, offering new regularity results and expansions."}}
{"id": "2506.04289", "pdf": "https://arxiv.org/pdf/2506.04289", "abs": "https://arxiv.org/abs/2506.04289", "authors": ["Jesse Geerts", "Stephanie Chan", "Claudia Clopath", "Kimberly Stachenfeld"], "title": "Relational reasoning and inductive bias in transformers trained on a transitive inference task", "categories": ["cs.LG", "q-bio.NC"], "comment": "13 pages, 6 figures", "summary": "Transformer-based models have demonstrated remarkable reasoning abilities,\nbut the mechanisms underlying relational reasoning in different learning\nregimes remain poorly understood. In this work, we investigate how transformers\nperform a classic relational reasoning task from the Psychology literature,\n\\textit{transitive inference}, which requires inference about indirectly\nrelated items by integrating information across observed adjacent item pairs\n(e.g., if A>B and B>C, then A>C). We compare transitive inference behavior\nacross two distinct learning regimes: in-weights learning (IWL), where models\nstore information in network parameters, and in-context learning (ICL), where\nmodels flexibly utilize information presented within the input sequence. Our\nfindings reveal that IWL naturally induces a generalization bias towards\ntransitive inference, despite being trained only on adjacent items, whereas ICL\nmodels trained solely on adjacent items do not generalize transitively.\nMechanistic analysis shows that ICL models develop induction circuits that\nimplement a simple match-and-copy strategy that performs well at relating\nadjacent pairs, but does not encoding hierarchical relationships among\nindirectly related items. Interestingly, when pre-trained on in-context linear\nregression tasks, transformers successfully exhibit in-context generalizable\ntransitive inference. Moreover, like IWL, they display both \\textit{symbolic\ndistance} and \\textit{terminal item effects} characteristic of human and animal\nperformance, without forming induction circuits. These results suggest that\npre-training on tasks with underlying structure promotes the development of\nrepresentations that can scaffold in-context relational reasoning.", "AI": {"tldr": "Transformers' relational reasoning in transitive inference tasks varies between in-weights learning (IWL) and in-context learning (ICL), with IWL showing natural generalization and ICL requiring pre-training for similar performance.", "motivation": "To understand how transformers perform relational reasoning, specifically transitive inference, under different learning regimes (IWL and ICL).", "method": "Compare transformer behavior in transitive inference tasks across IWL (information stored in network parameters) and ICL (information used from input sequences). Analyze mechanistic differences and effects of pre-training.", "result": "IWL generalizes transitively naturally, while ICL requires pre-training on structured tasks to achieve similar performance. ICL models develop match-and-copy strategies without hierarchical encoding.", "conclusion": "Pre-training on structured tasks enables transformers to develop representations supporting in-context relational reasoning, mirroring human-like behaviors."}}
{"id": "2506.05122", "pdf": "https://arxiv.org/pdf/2506.05122", "abs": "https://arxiv.org/abs/2506.05122", "authors": ["Shaziya A. Banu", "Venkata R. S. B. Varanasi", "Arash Noshadravan", "Sara Abedi"], "title": "Reactive Transport Simulation of Silicate-Rich Shale Rocks when Exposed to CO2 Saturated Brine Under High Pressure and High Temperature", "categories": ["physics.geo-ph", "physics.comp-ph"], "comment": null, "summary": "This study examines the feasibility of carbon dioxide storage in shale rocks\nand the reliability of reactive transport models in achieving accurate\nreplication of the chemo-mechanical interactions and transport processes\ntranspiring in these rocks when subjected to CO2 saturated brine. Owing to the\nheterogeneity of rocks, experimental testing for adequate deductions and\nfindings, could be an expensive and time-intensive process. Therefore, this\nstudy proposes utilization of reactive transport modeling to replicate the\npore-scale chemo-mechanical reactions and transport processes occurring in\nsilicate-rich shale rocks in the presence of CO2 saturated brine under high\npressure and high temperature. For this study, Crunch Tope has been adopted to\nsimulate a one-dimensional reactive transport model of a Permian rock specimen\nexposed to the acidic brine at a temperature of 100 {\\deg}C and pressure of\n12.40 MPa (1800 psi) for a period of 14 and 28 days. The results demonstrated\nsignificant dissolution followed by precipitation of quartz rich phases,\nprecipitation and swelling of clay rich phases, and dissolution of feldspar\nrich phases closer to the acidic brine-rock interface. Moreover, porosity\nagainst reaction depth curve showed nearly 1.00% mineral precipitation occur at\n14 and 28 days, which is insufficient to completely fill the pore spaces.", "AI": {"tldr": "The study explores CO2 storage in shale rocks using reactive transport modeling to simulate chemo-mechanical interactions, avoiding costly experiments. Results show mineral dissolution and precipitation but insufficient pore filling.", "motivation": "To address the high cost and time of experimental testing for CO2 storage in heterogeneous shale rocks by using reactive transport modeling.", "method": "Used Crunch Tope to simulate a 1D reactive transport model of a Permian rock specimen under high pressure (12.40 MPa) and temperature (100\u00b0C) with CO2 saturated brine for 14 and 28 days.", "result": "Significant dissolution and precipitation of minerals (quartz, clay, feldspar) near the brine-rock interface, with only 1.00% porosity reduction, insufficient for pore filling.", "conclusion": "Reactive transport modeling is feasible but shows limited mineral precipitation, indicating challenges for complete pore sealing in CO2 storage."}}
{"id": "2506.05152", "pdf": "https://arxiv.org/pdf/2506.05152", "abs": "https://arxiv.org/abs/2506.05152", "authors": ["Daniele Barbera", "Miho Murata"], "title": "The $\\mathcal{R}$-boundedness of solution operators for the $Q$-tensor model of nematic liquid crystals", "categories": ["math.AP", "math-ph", "math.MP", "76A15, 35Q30, 35Q35"], "comment": null, "summary": "In this paper, we consider a resolvent problem arising from the $Q$-tensor\nmodel for liquid crystal flows in the half-space. Our purpose is to show the\n$\\mathcal{R}$-boundedness for the solution operator families of the resolvent\nproblem when the resolvent parameter lies near the origin. The definition of\nthe $\\mathcal{R}$-solvability implies the uniform boundedness of the operator\nand, consequently, the resolvent estimates for the linear system.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.04291", "pdf": "https://arxiv.org/pdf/2506.04291", "abs": "https://arxiv.org/abs/2506.04291", "authors": ["Wenhan Xu", "Jiashuo Jiang", "Lei Deng", "Danny Hin-Kwok Tsang"], "title": "A Lyapunov Drift-Plus-Penalty Method Tailored for Reinforcement Learning with Queue Stability", "categories": ["cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "With the proliferation of Internet of Things (IoT) devices, the demand for\naddressing complex optimization challenges has intensified. The Lyapunov\nDrift-Plus-Penalty algorithm is a widely adopted approach for ensuring queue\nstability, and some research has preliminarily explored its integration with\nreinforcement learning (RL). In this paper, we investigate the adaptation of\nthe Lyapunov Drift-Plus-Penalty algorithm for RL applications, deriving an\neffective method for combining Lyapunov Drift-Plus-Penalty with RL under a set\nof common and reasonable conditions through rigorous theoretical analysis.\nUnlike existing approaches that directly merge the two frameworks, our proposed\nalgorithm, termed Lyapunov drift-plus-penalty method tailored for reinforcement\nlearning with queue stability (LDPTRLQ) algorithm, offers theoretical\nsuperiority by effectively balancing the greedy optimization of Lyapunov\nDrift-Plus-Penalty with the long-term perspective of RL. Simulation results for\nmultiple problems demonstrate that LDPTRLQ outperforms the baseline methods\nusing the Lyapunov drift-plus-penalty method and RL, corroborating the validity\nof our theoretical derivations. The results also demonstrate that our proposed\nalgorithm outperforms other benchmarks in terms of compatibility and stability.", "AI": {"tldr": "The paper introduces LDPTRLQ, a novel algorithm combining Lyapunov Drift-Plus-Penalty with reinforcement learning, ensuring queue stability and outperforming baseline methods.", "motivation": "Addressing the need for efficient optimization in IoT by integrating Lyapunov Drift-Plus-Penalty with reinforcement learning for better performance.", "method": "The LDPTRLQ algorithm combines Lyapunov Drift-Plus-Penalty with RL, balancing greedy optimization and long-term perspective through theoretical analysis.", "result": "Simulations show LDPTRLQ outperforms baseline methods in compatibility and stability, validating theoretical claims.", "conclusion": "LDPTRLQ effectively integrates Lyapunov Drift-Plus-Penalty with RL, offering superior performance and stability for IoT optimization."}}
{"id": "2506.05292", "pdf": "https://arxiv.org/pdf/2506.05292", "abs": "https://arxiv.org/abs/2506.05292", "authors": ["Declan A. Norton", "Yuanzhao Zhang", "Michelle Girvan"], "title": "Learning Beyond Experience: Generalizing to Unseen State Space with Reservoir Computing", "categories": ["cs.LG", "math.DS", "nlin.CD", "physics.comp-ph"], "comment": "15 pages, 9 figures", "summary": "Machine learning techniques offer an effective approach to modeling dynamical\nsystems solely from observed data. However, without explicit structural priors\n-- built-in assumptions about the underlying dynamics -- these techniques\ntypically struggle to generalize to aspects of the dynamics that are poorly\nrepresented in the training data. Here, we demonstrate that reservoir computing\n-- a simple, efficient, and versatile machine learning framework often used for\ndata-driven modeling of dynamical systems -- can generalize to unexplored\nregions of state space without explicit structural priors. First, we describe a\nmultiple-trajectory training scheme for reservoir computers that supports\ntraining across a collection of disjoint time series, enabling effective use of\navailable training data. Then, applying this training scheme to multistable\ndynamical systems, we show that RCs trained on trajectories from a single basin\nof attraction can achieve out-of-domain generalization by capturing system\nbehavior in entirely unobserved basins.", "AI": {"tldr": "Reservoir computing can generalize to unexplored state space regions without explicit structural priors, using a multiple-trajectory training scheme.", "motivation": "Machine learning struggles to generalize without structural priors, especially for dynamics poorly represented in training data.", "method": "A multiple-trajectory training scheme for reservoir computers, applied to multistable dynamical systems.", "result": "RCs trained on single basin trajectories generalize to unobserved basins.", "conclusion": "Reservoir computing enables out-of-domain generalization without explicit priors."}}
{"id": "2506.05270", "pdf": "https://arxiv.org/pdf/2506.05270", "abs": "https://arxiv.org/abs/2506.05270", "authors": ["Massimo Gobbino", "Nicola Picenni"], "title": "Symmetry breaking for local minimizers of a free discontinuity problem", "categories": ["math.AP", "math.OC", "49Q20, 49K05, 49K10"], "comment": "27 pages, 2 figures", "summary": "We study a functional defined on the class of piecewise constant functions,\ncombining a jump penalization, which discourages discontinuities, with a\nfidelity term that penalizes deviations from a given linear function, called\nthe forcing term.\n  In one dimension, it is not difficult to see that local minimizers form\nstaircases that approximate the forcing term. Here we show that in two\ndimensions symmetry breaking occurs, leading to the emergence of exotic\nminimizers whose level sets are not simple stripes with boundaries orthogonal\nto the gradient of the forcing term.\n  The proof relies on the calibration method for free discontinuity problems.", "AI": {"tldr": "The paper explores a functional for piecewise constant functions, balancing jump penalization and fidelity to a linear forcing term. In 1D, minimizers form staircases, but in 2D, symmetry breaking leads to exotic minimizers with complex level sets.", "motivation": "To understand how minimizers of a functional behave in higher dimensions, particularly when symmetry breaks and complex patterns emerge.", "method": "Uses the calibration method for free discontinuity problems to analyze minimizers.", "result": "In 2D, symmetry breaking produces exotic minimizers with non-simple level sets, unlike the staircase patterns in 1D.", "conclusion": "The study reveals unexpected complexity in minimizers when moving from one to two dimensions, highlighting the role of symmetry breaking."}}
{"id": "2506.04293", "pdf": "https://arxiv.org/pdf/2506.04293", "abs": "https://arxiv.org/abs/2506.04293", "authors": ["Fengze Liu", "Haoyu Wang", "Joonhyuk Cho", "Dan Roth", "Andrew W. Lo"], "title": "AUTOCT: Automating Interpretable Clinical Trial Prediction with LLM Agents", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Clinical trials are critical for advancing medical treatments but remain\nprohibitively expensive and time-consuming. Accurate prediction of clinical\ntrial outcomes can significantly reduce research and development costs and\naccelerate drug discovery. While recent deep learning models have shown promise\nby leveraging unstructured data, their black-box nature, lack of\ninterpretability, and vulnerability to label leakage limit their practical use\nin high-stakes biomedical contexts. In this work, we propose AutoCT, a novel\nframework that combines the reasoning capabilities of large language models\nwith the explainability of classical machine learning. AutoCT autonomously\ngenerates, evaluates, and refines tabular features based on public information\nwithout human input. Our method uses Monte Carlo Tree Search to iteratively\noptimize predictive performance. Experimental results show that AutoCT performs\non par with or better than SOTA methods on clinical trial prediction tasks\nwithin only a limited number of self-refinement iterations, establishing a new\nparadigm for scalable, interpretable, and cost-efficient clinical trial\nprediction.", "AI": {"tldr": "AutoCT is a novel framework combining large language models and classical machine learning for scalable, interpretable clinical trial outcome prediction.", "motivation": "Clinical trials are costly and time-consuming; accurate outcome prediction can reduce costs and accelerate drug discovery. Existing deep learning models lack interpretability and are prone to label leakage.", "method": "AutoCT autonomously generates, evaluates, and refines tabular features using Monte Carlo Tree Search for iterative optimization.", "result": "AutoCT matches or outperforms state-of-the-art methods in clinical trial prediction tasks with limited self-refinement iterations.", "conclusion": "AutoCT introduces a scalable, interpretable, and cost-efficient paradigm for clinical trial prediction."}}
{"id": "2506.05299", "pdf": "https://arxiv.org/pdf/2506.05299", "abs": "https://arxiv.org/abs/2506.05299", "authors": ["Christos Sourdis"], "title": "On a linear equation arising in the study of phase separation of BEC's", "categories": ["math.AP"], "comment": null, "summary": "We consider the inner limit system describing the phase separation in\ntwo-component Bose-Einstein condensates linearized around the one-dimensional\nsolution in an infinite strip with zero and periodic boundary conditions, and\nobtain optimal invertibility estimates for the Fourier modes without\nnecessarily assuming orthogonality conditions.", "AI": {"tldr": "Optimal invertibility estimates for Fourier modes in phase separation of two-component Bose-Einstein condensates, without orthogonality conditions.", "motivation": "To analyze the phase separation in two-component Bose-Einstein condensates, focusing on the linearized system around a one-dimensional solution in an infinite strip.", "method": "Study the inner limit system with zero and periodic boundary conditions, deriving optimal invertibility estimates for Fourier modes.", "result": "Achieved optimal invertibility estimates without requiring orthogonality conditions.", "conclusion": "The findings provide insights into phase separation dynamics in Bose-Einstein condensates under specified boundary conditions."}}
{"id": "2506.04294", "pdf": "https://arxiv.org/pdf/2506.04294", "abs": "https://arxiv.org/abs/2506.04294", "authors": ["Asier Diaz-Iglesias", "Xabier Belaunzaran", "Ane M. Florez-Tapia"], "title": "Short-Term Power Demand Forecasting for Diverse Consumer Types to Enhance Grid Planning and Synchronisation", "categories": ["cs.LG"], "comment": null, "summary": "Ensuring grid stability in the transition to renewable energy sources\nrequires accurate power demand forecasting. This study addresses the need for\nprecise forecasting by differentiating among industrial, commercial, and\nresidential consumers through customer clusterisation, tailoring the\nforecasting models to capture the unique consumption patterns of each group. A\nfeature selection process is done for each consumer type including temporal,\nsocio-economic, and weather-related data obtained from the Copernicus Earth\nObservation (EO) program. A variety of AI and machine learning algorithms for\nShort-Term Load Forecasting (STLF) and Very Short-Term Load Forecasting (VSTLF)\nare explored and compared, determining the most effective approaches. With all\nthat, the main contribution of this work are the new forecasting approaches\nproposed, which have demonstrated superior performance compared to simpler\nmodels, both for STLF and VSTLF, highlighting the importance of customized\nforecasting strategies for different consumer groups and demonstrating the\nimpact of incorporating detailed weather data on forecasting accuracy. These\nadvancements contribute to more reliable power demand predictions, thereby\nsupporting grid stability.", "AI": {"tldr": "The paper proposes customized forecasting models for industrial, commercial, and residential consumers, using AI/ML algorithms and detailed weather data to improve power demand forecasting accuracy, supporting grid stability.", "motivation": "The transition to renewable energy requires precise power demand forecasting to ensure grid stability, necessitating tailored models for different consumer groups.", "method": "Customer clusterisation and feature selection (temporal, socio-economic, weather data) are used. AI/ML algorithms for STLF and VSTLF are compared to identify the most effective approaches.", "result": "The proposed forecasting models outperform simpler ones, showing the value of customized strategies and detailed weather data.", "conclusion": "Customized forecasting for consumer groups and detailed weather data enhance accuracy, aiding grid stability in renewable energy transitions."}}
{"id": "2506.04296", "pdf": "https://arxiv.org/pdf/2506.04296", "abs": "https://arxiv.org/abs/2506.04296", "authors": ["N Guerin", "M Nakhla", "A Dehoux", "J L Loyer"], "title": "Deep learning for predicting hauling fleet production capacity under uncertainties in open pit mines using real and simulated data", "categories": ["cs.LG"], "comment": null, "summary": "Accurate short-term forecasting of hauling-fleet capacity is crucial in\nopen-pit mining, where weather fluctuations, mechanical breakdowns, and\nvariable crew availability introduce significant operational uncertainties. We\npropose a deep-learning framework that blends real-world operational records\n(high-resolution rainfall measurements, fleet performance telemetry) with\nsynthetically generated mechanical-breakdown scenarios to enable the model to\ncapture fluctuating high-impact failure events. We evaluate two architectures:\nan XGBoost regressor achieving a median absolute error (MedAE) of 14.3 per cent\nand a Long Short-Term Memory network with a MedAE of 15.1 per cent. Shapley\nAdditive exPlanations (SHAP) value analyses identify cumulative rainfall,\nhistorical payload trends, and simulated breakdown frequencies as dominant\npredictors. Integration of simulated breakdown data and shift-planning features\nnotably reduces prediction volatility. Future work will further integrate\nmaintenance-scheduling indicators (Mean Time Between Failures, Mean Time to\nRepair), detailed human resource data (operator absenteeism, crew efficiency\nmetrics), blast event scheduling, and other operational constraints to enhance\nforecast robustness and adaptability. This hybrid modelling approach offers a\ncomprehensive decision-support tool for proactive, data-driven fleet management\nunder dynamically uncertain conditions.", "AI": {"tldr": "A deep-learning framework for short-term hauling-fleet capacity forecasting in open-pit mining, combining real-world data with synthetic breakdown scenarios, achieves low error rates and identifies key predictors.", "motivation": "Accurate forecasting is critical due to operational uncertainties like weather, breakdowns, and crew availability.", "method": "Proposes a hybrid deep-learning framework using XGBoost and LSTM, integrating real operational records and synthetic breakdown data.", "result": "XGBoost (MedAE 14.3%) and LSTM (MedAE 15.1%) perform well; SHAP analysis highlights rainfall, payload trends, and breakdown frequencies as key predictors.", "conclusion": "The hybrid model reduces volatility and supports proactive fleet management. Future work will expand features for robustness."}}
{"id": "2506.04801", "pdf": "https://arxiv.org/pdf/2506.04801", "abs": "https://arxiv.org/abs/2506.04801", "authors": ["Kush Kinra", "Fernanda Cipriano"], "title": "Random dynamics and invariant measures for a class of non-Newtonian fluids of differential type on 2D and 3D Poincar\u00e9 domains", "categories": ["math.PR", "math.AP", "76A05, 35R60, 35Q35, 37L30, 35B40"], "comment": null, "summary": "In this article, we consider a class of incompressible stochastic third-grade\nfluids (non-Newtonian fluids) equations on two- as well as three-dimensional\nPoincar\\'e domains $\\mathcal{O}$ (which may be bounded or unbounded). Our aims\nare to study the well-posedness and asymptotic analysis for the solutions of\nthe underlying system. Firstly, we prove that the underlying system defined on\n$\\mathcal{O}$ has a unique weak solution (in the analytic sense) under\nDirichlet boundary condition and it also generates random dynamical system\n$\\Psi$. Secondly, we consider the underlying system on bounded domains. Using\nthe compact Sobolev embedding $\\mathbb{H}^1(\\mathcal{O})\n\\hookrightarrow\\mathbb{L}^2(\\mathcal{O})$, we prove the existence of a unique\nrandom attractor for the underlying system on bounded domains with external\nforcing in\n$\\mathbb{H}^{-1}(\\mathcal{O})+\\mathbb{W}^{-1,\\frac{4}{3}}(\\mathcal{O})$.\nThirdly, we consider the underlying system on unbounded Poincar\\'e domains with\nexternal forcing in $\\mathbb{L}^{2}(\\mathcal{O})$ and show the existence of a\nunique random attractor. In order to obtain the existence of a unique random\nattractor on unbounded domains, due to the lack of compact Sobolev embedding\n$\\mathbb{H}^1(\\mathcal{O}) \\hookrightarrow\\mathbb{H}^2(\\mathcal{O})$, we use\nthe uniform-tail estimates method which helps us to demonstrate the asymptotic\ncompactness of $\\Psi$.\n  Note that due to the presence of several nonlinear terms in the underlying\nsystem, we are not able to use the energy equality method to obtain the\nasymptotic compactness of $\\Psi$ in unbounded domains, which makes the analysis\nof this work in unbounded domains more difficult and interesting. Finally, as a\nconsequence of the existence of random attractors, we address the existence of\ninvariant measures for underlying system.", "AI": {"tldr": "The paper studies the well-posedness and asymptotic behavior of solutions for incompressible stochastic third-grade fluids on Poincar\u00e9 domains, proving unique weak solutions and random attractors for bounded and unbounded domains.", "motivation": "The motivation is to analyze the well-posedness and asymptotic properties of stochastic non-Newtonian fluid equations, addressing challenges like nonlinear terms and lack of compact embeddings.", "method": "The methods include proving unique weak solutions under Dirichlet conditions, using compact Sobolev embeddings for bounded domains, and uniform-tail estimates for unbounded domains.", "result": "Key results include the existence of unique weak solutions, random attractors for bounded and unbounded domains, and invariant measures.", "conclusion": "The paper concludes with the existence of random attractors and invariant measures, highlighting the challenges and novelty in analyzing unbounded domains."}}
{"id": "2506.04297", "pdf": "https://arxiv.org/pdf/2506.04297", "abs": "https://arxiv.org/abs/2506.04297", "authors": ["Abdourrahmane Mahamane Atto"], "title": "Softlog-Softmax Layers and Divergences Contribute to a Computationally Dependable Ensemble Learning", "categories": ["cs.LG"], "comment": null, "summary": "The paper proposes a 4-step process for highlighting that softlog-softmax\ncascades can improve both consistency and dependability of the next generation\nensemble learning systems. The first process is anatomical in nature: the\ntarget ensemble model under consideration is composed by canonical elements\nrelating to the definition of a convolutional frustum. No a priori is\nconsidered in the choice of canonical forms. Diversity is the main criterion\nfor selecting these forms. It is shown that the more complex the problem, the\nmore useful this ensemble diversity is. The second process is physiological and\nrelates to neural engineering: a softlog is derived to both make weak\nlogarithmic operations consistent and lead, through multiple softlog-softmax\nlayers, to intermediate decisions in the sense of respecting the same class\nlogic as that faced by the output layer. The third process concerns neural\ninformation theory: softlog-based entropy and divergence are proposed for the\nsake of constructing information measures yielding consistent values on closed\nintervals. These information measures are used to determine the relationships\nbetween individual and sub-community decisions in frustum diversitybased\nensemble learning. The concluding process addresses the derivation of an\ninformative performance tensor for the purpose of a reliable ensemble\nevaluation.", "AI": {"tldr": "A 4-step process enhances ensemble learning by improving consistency and dependability through softlog-softmax cascades, diversity-driven canonical forms, and neural information theory.", "motivation": "To improve the consistency and dependability of next-generation ensemble learning systems by leveraging softlog-softmax cascades and diversity.", "method": "1. Anatomical: Uses canonical elements for ensemble models without a priori choices, prioritizing diversity. 2. Physiological: Derives softlog for consistent weak logarithmic operations and intermediate decisions. 3. Neural information theory: Introduces softlog-based entropy and divergence for consistent information measures. 4. Performance tensor: Derives a tensor for reliable ensemble evaluation.", "result": "Demonstrates that ensemble diversity is more beneficial for complex problems and provides consistent information measures and reliable evaluation.", "conclusion": "The proposed 4-step process effectively enhances ensemble learning systems through diversity, softlog-softmax cascades, and robust evaluation metrics."}}
{"id": "2506.04301", "pdf": "https://arxiv.org/pdf/2506.04301", "abs": "https://arxiv.org/abs/2506.04301", "authors": ["Jiin Kim", "Byeongjun Shin", "Jinha Chung", "Minsoo Rhu"], "title": "The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Large-language-model (LLM)-based AI agents have recently showcased impressive\nversatility by employing dynamic reasoning, an adaptive, multi-step process\nthat coordinates with external tools. This shift from static, single-turn\ninference to agentic, multi-turn workflows broadens task generalization and\nbehavioral flexibility, but it also introduces serious concerns about\nsystem-level cost, efficiency, and sustainability. This paper presents the\nfirst comprehensive system-level analysis of AI agents, quantifying their\nresource usage, latency behavior, energy consumption, and datacenter-wide power\nconsumption demands across diverse agent designs and test-time scaling\nstrategies. We further characterize how AI agent design choices, such as\nfew-shot prompting, reflection depth, and parallel reasoning, impact\naccuracy-cost tradeoffs. Our findings reveal that while agents improve accuracy\nwith increased compute, they suffer from rapidly diminishing returns, widening\nlatency variance, and unsustainable infrastructure costs. Through detailed\nevaluation of representative agents, we highlight the profound computational\ndemands introduced by AI agent workflows, uncovering a looming sustainability\ncrisis. These results call for a paradigm shift in agent design toward\ncompute-efficient reasoning, balancing performance with deployability under\nreal-world constraints.", "AI": {"tldr": "The paper analyzes the system-level costs and sustainability issues of LLM-based AI agents, revealing diminishing returns and high computational demands despite improved accuracy.", "motivation": "To address concerns about the efficiency, cost, and sustainability of dynamic, multi-turn AI agent workflows, which replace static inference.", "method": "Conducts a comprehensive system-level analysis of AI agents, quantifying resource usage, latency, energy, and power consumption across designs and scaling strategies.", "result": "Agents improve accuracy with more compute but face diminishing returns, high latency variance, and unsustainable infrastructure costs.", "conclusion": "Urges a shift toward compute-efficient agent design to balance performance with real-world deployability."}}
{"id": "2506.04812", "pdf": "https://arxiv.org/pdf/2506.04812", "abs": "https://arxiv.org/abs/2506.04812", "authors": ["Marios A. Apetroaie", "Sam C. Collingbourne", "Elena Giorgi"], "title": "Conservation Laws and Boundedness for Linearised Einstein--Maxwell Equations on the Reissner--Nordstr\u00f6m Black Hole", "categories": ["gr-qc", "math.AP"], "comment": "28 pages", "summary": "We study the linearised Einstein--Maxwell equations on the\nReissner--Nordstr\\\"om spacetime and derive the canonical energy conservation\nlaw in double null gauge. In the spirit of the work of Holzegel and the second\nauthor, we avoid any use of the hyperbolic nature of the Teukolsky equations\nand rely solely on the conservation law to establish control of energy fluxes\nfor the gauge-invariant Teukolsky variables, previously identified by the third\nauthor, along all outgoing null hypersurfaces, for charge-to-mass ratio\n$\\frac{|Q|}{M} < \\frac{\\sqrt{15}}{4}$. This yields uniform boundedness for the\nTeukolsky variables in Reissner--Nordstr\\\"om.", "AI": {"tldr": "The paper analyzes the linearized Einstein-Maxwell equations on Reissner-Nordstr\u00f6m spacetime, deriving an energy conservation law to control Teukolsky variables without relying on hyperbolic methods.", "motivation": "To establish energy control for gauge-invariant Teukolsky variables in Reissner-Nordstr\u00f6m spacetime without using hyperbolic techniques.", "method": "Derives a canonical energy conservation law in double null gauge and applies it to Teukolsky variables.", "result": "Uniform boundedness of Teukolsky variables is achieved for charge-to-mass ratios below a specific threshold.", "conclusion": "The approach successfully controls energy fluxes for Teukolsky variables, demonstrating boundedness in Reissner-Nordstr\u00f6m spacetime."}}
{"id": "2506.04302", "pdf": "https://arxiv.org/pdf/2506.04302", "abs": "https://arxiv.org/abs/2506.04302", "authors": ["Xiang Zheng", "Xingjun Ma", "Wei-Bin Lee", "Cong Wang"], "title": "RedRFT: A Light-Weight Benchmark for Reinforcement Fine-Tuning-Based Red Teaming", "categories": ["cs.LG"], "comment": null, "summary": "Red teaming has proven to be an effective method for identifying and\nmitigating vulnerabilities in Large Language Models (LLMs). Reinforcement\nFine-Tuning (RFT) has emerged as a promising strategy among existing red\nteaming techniques. However, a lack of a unified benchmark hinders current\nRFT-based red teaming methods. Implementation details, especially in Proximal\nPolicy Optimization (PPO)-based RFT, significantly affect outcome stability and\nreproducibility. To address this issue, we introduce RedRFT, a lightweight\nbenchmark designed to simplify and standardize the implementation and\nevaluation of RFT-based red teaming. RedRFT combines the design strengths of\nboth single-file CleanRL and highly modularized Tianshou, offering high-quality\nsingle-file red teaming implementations and modular PPO core components, such\nas the General Advantage Estimator. It supports a variety of token and sentence\ndiversity metrics, featuring modularized intrinsic reward computation that\nfacilitates plug-and-play experimentation. To clarify their influence on RFT\nperformance, we conducted an extensive ablation study on key components,\nincluding Low-Rank Adaptation (LoRA), Kullback-Leibler (KL) divergence, and\nLagrange Multiplier. We hope this work contributes to 1) gaining a\ncomprehensive understanding of the implementation nuances of RFT-based red\nteaming algorithms, and 2) enabling rapid prototyping of innovative features\nfor RFT-based red teaming. Code for the benchmark can be accessed at\nhttps://github.com/x-zheng16/RedRFT.git.", "AI": {"tldr": "RedRFT is a lightweight benchmark for standardizing RFT-based red teaming in LLMs, addressing implementation inconsistencies and enabling rapid prototyping.", "motivation": "Current RFT-based red teaming lacks a unified benchmark, and implementation details like PPO affect stability and reproducibility.", "method": "RedRFT combines CleanRL and Tianshou strengths, offering modular PPO components and diversity metrics, with an ablation study on key components.", "result": "The benchmark simplifies RFT implementation and evaluation, supporting modular experimentation and clarifying component influences.", "conclusion": "RedRFT aids in understanding RFT nuances and accelerates innovation in red teaming for LLMs."}}
{"id": "2506.05037", "pdf": "https://arxiv.org/pdf/2506.05037", "abs": "https://arxiv.org/abs/2506.05037", "authors": ["Angha Agarwal", "Antti V. V\u00e4h\u00e4kangas"], "title": "Limits at infinity for Haj\u0142asz-Sobolev functions in metric spaces", "categories": ["math.CA", "math.AP", "46E36, 31C15, 31B15, 31B25"], "comment": null, "summary": "We study limits at infinity for homogeneous Hajlasz-Sobolev functions defined\non uniformly perfect metric spaces equipped with a doubling measure. We prove\nthat a quasicontinuous representative of such a function has a pointwise limit\nat infinity outside an exceptional set, defined in terms of a variational\nrelative capacity. Our framework refines earlier approaches that relied on\nHausdorff content rather than relative capacity, and it extends previous\nresults for homogeneous Newtonian and fractional Sobolev functions.", "AI": {"tldr": "The paper studies limits at infinity for homogeneous Hajlasz-Sobolev functions on metric spaces with doubling measures, proving pointwise limits outside an exceptional set defined by variational relative capacity.", "motivation": "To refine and extend earlier approaches using Hausdorff content, focusing on relative capacity for more precise results.", "method": "Analyzes quasicontinuous representatives of functions, using variational relative capacity to define exceptional sets.", "result": "Demonstrates pointwise limits at infinity for these functions outside the exceptional set.", "conclusion": "The framework generalizes previous results for Newtonian and fractional Sobolev functions, offering a refined approach."}}
{"id": "2506.04349", "pdf": "https://arxiv.org/pdf/2506.04349", "abs": "https://arxiv.org/abs/2506.04349", "authors": ["Christos Sakaridis"], "title": "You Only Train Once", "categories": ["cs.LG", "cs.CV"], "comment": "17 pages, 4 figures", "summary": "The title of this paper is perhaps an overclaim. Of course, the process of\ncreating and optimizing a learned model inevitably involves multiple training\nruns which potentially feature different architectural designs, input and\noutput encodings, and losses. However, our method, You Only Train Once (YOTO),\nindeed contributes to limiting training to one shot for the latter aspect of\nlosses selection and weighting. We achieve this by automatically optimizing\nloss weight hyperparameters of learned models in one shot via standard\ngradient-based optimization, treating these hyperparameters as regular\nparameters of the networks and learning them. To this end, we leverage the\ndifferentiability of the composite loss formulation which is widely used for\noptimizing multiple empirical losses simultaneously and model it as a novel\nlayer which is parameterized with a softmax operation that satisfies the\ninherent positivity constraints on loss hyperparameters while avoiding\ndegenerate empirical gradients. We complete our joint end-to-end optimization\nscheme by defining a novel regularization loss on the learned hyperparameters,\nwhich models a uniformity prior among the employed losses while ensuring\nboundedness of the identified optima. We evidence the efficacy of YOTO in\njointly optimizing loss hyperparameters and regular model parameters in one\nshot by comparing it to the commonly used brute-force grid search across\nstate-of-the-art networks solving two key problems in computer vision, i.e. 3D\nestimation and semantic segmentation, and showing that it consistently\noutperforms the best grid-search model on unseen test data. Code will be made\npublicly available.", "AI": {"tldr": "YOTO introduces a one-shot training method for optimizing loss weights via gradient-based optimization, outperforming grid search in computer vision tasks.", "motivation": "To simplify and improve the process of loss weight hyperparameter optimization in model training, avoiding multiple runs.", "method": "Uses gradient-based optimization to treat loss weights as network parameters, leveraging a differentiable composite loss formulation and a novel regularization loss.", "result": "YOTO consistently outperforms grid-search models in 3D estimation and semantic segmentation tasks.", "conclusion": "YOTO effectively optimizes loss weights in one shot, demonstrating superior performance over traditional methods."}}
{"id": "2506.04352", "pdf": "https://arxiv.org/pdf/2506.04352", "abs": "https://arxiv.org/abs/2506.04352", "authors": ["Ethem Alpaydin"], "title": "Half-Layered Neural Networks", "categories": ["cs.LG"], "comment": "11 pages, 8 figures", "summary": "We propose a ``half'' layer of hidden units that has some of its weights\nrandomly set and some of them trained. A half unit is composed of two stages:\nFirst, it takes a weighted sum of its inputs with fixed random weights, and\nsecond, the total activation is multiplied and then translated using two\nmodifiable weights, before the result is passed through a nonlinearity. The\nnumber of modifiable weights of each hidden unit is thus two and does not\ndepend on the fan-in. We show how such half units can be used in the first or\nany later layer in a deep network, possibly following convolutional layers. Our\nexperiments on MNIST and FashionMNIST data sets indicate the promise of half\nlayers, where we can achieve reasonable accuracy with a reduced number of\nparameters due to the regularizing effect of the randomized connections.", "AI": {"tldr": "A 'half' layer of hidden units with partially randomized and partially trained weights is proposed, reducing parameters while maintaining accuracy.", "motivation": "To reduce the number of trainable parameters in neural networks without sacrificing performance by leveraging randomized connections.", "method": "Each hidden unit combines fixed random weights and two modifiable weights for scaling and translation, applied before a nonlinearity.", "result": "Experiments on MNIST and FashionMNIST show reasonable accuracy with fewer parameters due to regularization from randomized connections.", "conclusion": "Half layers offer a promising approach to parameter efficiency in deep networks, especially after convolutional layers."}}
{"id": "2506.04358", "pdf": "https://arxiv.org/pdf/2506.04358", "abs": "https://arxiv.org/abs/2506.04358", "authors": ["Uditansh Srivastava", "Shivam Aryan", "Shaurya Singh"], "title": "A Risk-Aware Reinforcement Learning Reward for Financial Trading", "categories": ["cs.LG"], "comment": "14 pages, 11 figures", "summary": "We propose a novel composite reward function for reinforcement learning in\nfinancial trading that balances return and risk using four differentiable\nterms: annualized return downside risk differential return and the Treynor\nratio\n  Unlike single metric objectives for example the Sharpe ratio our formulation\nis modular and parameterized by weights w1 w2 w3 and w4 enabling practitioners\nto encode diverse investor preferences\n  We tune these weights via grid search to target specific risk return profiles\n  We derive closed form gradients for each term to facilitate gradient based\ntraining and analyze key theoretical properties including monotonicity\nboundedness and modularity\n  This framework offers a general blueprint for building robust multi objective\nreward functions in complex trading environments and can be extended with\nadditional risk measures or adaptive weighting", "AI": {"tldr": "A novel composite reward function for financial trading balances return and risk using four differentiable terms, enabling customizable investor preferences via weight tuning.", "motivation": "To address the limitations of single-metric objectives like the Sharpe ratio by providing a modular and parameterized reward function for diverse investor preferences.", "method": "Proposes a composite reward function with four terms (annualized return, downside risk, differential return, Treynor ratio), tuned via grid search, and analyzed for theoretical properties like monotonicity and boundedness.", "result": "The framework offers a robust, multi-objective reward function for financial trading, with potential for extension to additional risk measures or adaptive weighting.", "conclusion": "This approach provides a flexible and scalable blueprint for designing reward functions in complex trading environments."}}
{"id": "2506.04360", "pdf": "https://arxiv.org/pdf/2506.04360", "abs": "https://arxiv.org/abs/2506.04360", "authors": ["Philippe Chlenski", "Itsik Pe'er"], "title": "Even Faster Hyperbolic Random Forests: A Beltrami-Klein Wrapper Approach", "categories": ["cs.LG"], "comment": "15 pages, 4 figures, 2 tables", "summary": "Decision trees and models that use them as primitives are workhorses of\nmachine learning in Euclidean spaces. Recent work has further extended these\nmodels to the Lorentz model of hyperbolic space by replacing axis-parallel\nhyperplanes with homogeneous hyperplanes when partitioning the input space. In\nthis paper, we show how the hyperDT algorithm can be elegantly reexpressed in\nthe Beltrami-Klein model of hyperbolic spaces. This preserves the thresholding\noperation used in Euclidean decision trees, enabling us to further rewrite\nhyperDT as simple pre- and post-processing steps that form a wrapper around\nexisting tree-based models designed for Euclidean spaces. The wrapper approach\nunlocks many optimizations already available in Euclidean space models,\nimproving flexibility, speed, and accuracy while offering a simpler, more\nmaintainable, and extensible codebase. Our implementation is available at\nhttps://github.com/pchlenski/hyperdt.", "AI": {"tldr": "The paper re-expresses the hyperDT algorithm in the Beltrami-Klein model of hyperbolic spaces, simplifying it into a wrapper around Euclidean decision trees for improved performance and maintainability.", "motivation": "To extend decision tree models to hyperbolic spaces while preserving simplicity and leveraging existing Euclidean optimizations.", "method": "Reformulates hyperDT in the Beltrami-Klein model, enabling thresholding operations and wrapping around Euclidean tree-based models.", "result": "Achieves better flexibility, speed, and accuracy with a simpler, maintainable codebase.", "conclusion": "The wrapper approach effectively bridges hyperbolic and Euclidean decision trees, enhancing practicality and performance."}}
{"id": "2506.04377", "pdf": "https://arxiv.org/pdf/2506.04377", "abs": "https://arxiv.org/abs/2506.04377", "authors": ["Yasaman Mahdaviyeh", "James Lucas", "Mengye Ren", "Andreas S. Tolias", "Richard Zemel", "Toniann Pitassi"], "title": "Replay Can Provably Increase Forgetting", "categories": ["cs.LG"], "comment": "To appear in the Proceedings of the Conference on Lifelong Learning\n  Agents (CoLLAs) 2025", "summary": "Continual learning seeks to enable machine learning systems to solve an\nincreasing corpus of tasks sequentially. A critical challenge for continual\nlearning is forgetting, where the performance on previously learned tasks\ndecreases as new tasks are introduced. One of the commonly used techniques to\nmitigate forgetting, sample replay, has been shown empirically to reduce\nforgetting by retaining some examples from old tasks and including them in new\ntraining episodes. In this work, we provide a theoretical analysis of sample\nreplay in an over-parameterized continual linear regression setting, where each\ntask is given by a linear subspace and with enough replay samples, one would be\nable to eliminate forgetting. Our analysis focuses on sample replay and\nhighlights the role of the replayed samples and the relationship between task\nsubspaces. Surprisingly, we find that, even in a noiseless setting, forgetting\ncan be non-monotonic with respect to the number of replay samples. We present\ntasks where replay can be harmful with respect to worst-case settings, and also\nin distributional settings where replay of randomly selected samples increases\nforgetting in expectation. We also give empirical evidence that harmful replay\nis not limited to training with linear models by showing similar behavior for a\nneural networks equipped with SGD. Through experiments on a commonly used\nbenchmark, we provide additional evidence that, even in seemingly benign\nscenarios, performance of the replay heavily depends on the choice of replay\nsamples and the relationship between tasks.", "AI": {"tldr": "The paper theoretically analyzes sample replay in continual learning, showing it can sometimes harm performance, even in noiseless settings, and highlights the importance of sample selection and task relationships.", "motivation": "To understand the theoretical underpinnings of sample replay in continual learning, particularly its potential to mitigate forgetting, and to explore scenarios where replay might be harmful.", "method": "Theoretical analysis in an over-parameterized continual linear regression setting, examining the role of replayed samples and task subspace relationships. Empirical validation with neural networks and SGD on benchmarks.", "result": "Forgetting can be non-monotonic with replay samples; replay may increase forgetting in worst-case and distributional settings. Harmful replay is observed even in neural networks.", "conclusion": "Sample replay's effectiveness depends on sample choice and task relationships, and it can sometimes worsen forgetting, challenging its universal utility."}}
{"id": "2506.04398", "pdf": "https://arxiv.org/pdf/2506.04398", "abs": "https://arxiv.org/abs/2506.04398", "authors": ["Th\u00e9o Vincent", "Yogesh Tripathi", "Tim Faust", "Yaniv Oren", "Jan Peters", "Carlo D'Eramo"], "title": "Bridging the Performance Gap Between Target-Free and Target-Based Reinforcement Learning With Iterated Q-Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In value-based reinforcement learning, removing the target network is\ntempting as the boostrapped target would be built from up-to-date estimates,\nand the spared memory occupied by the target network could be reallocated to\nexpand the capacity of the online network. However, eliminating the target\nnetwork introduces instability, leading to a decline in performance. Removing\nthe target network also means we cannot leverage the literature developed\naround target networks. In this work, we propose to use a copy of the last\nlinear layer of the online network as a target network, while sharing the\nremaining parameters with the up-to-date online network, hence stepping out of\nthe binary choice between target-based and target-free methods. It enables us\nto leverage the concept of iterated Q-learning, which consists of learning\nconsecutive Bellman iterations in parallel, to reduce the performance gap\nbetween target-free and target-based approaches. Our findings demonstrate that\nthis novel method, termed iterated Shared Q-Learning (iS-QL), improves the\nsample efficiency of target-free approaches across various settings.\nImportantly, iS-QL requires a smaller memory footprint and comparable training\ntime to classical target-based algorithms, highlighting its potential to scale\nreinforcement learning research.", "AI": {"tldr": "Proposes iterated Shared Q-Learning (iS-QL), a method using a copy of the last linear layer of the online network as a target network, improving target-free approaches' sample efficiency with minimal memory overhead.", "motivation": "To address instability and performance decline when removing target networks in reinforcement learning, while leveraging existing literature and reducing memory usage.", "method": "Uses a copy of the last linear layer of the online network as a target network, sharing remaining parameters, and applies iterated Q-learning to bridge performance gaps.", "result": "iS-QL improves sample efficiency of target-free methods, maintains comparable training time, and reduces memory footprint.", "conclusion": "iS-QL offers a scalable solution for reinforcement learning by balancing target-based and target-free benefits."}}
{"id": "2506.04399", "pdf": "https://arxiv.org/pdf/2506.04399", "abs": "https://arxiv.org/abs/2506.04399", "authors": ["Suzan Ece Ada", "Emre Ugur"], "title": "Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Published in IEEE Robotics and Automation Letters Volume: 9, Issue:\n  10, 8427 - 8434, October 2024. 8 pages, 7 figures", "summary": "We introduce Unsupervised Meta-Testing with Conditional Neural Processes\n(UMCNP), a novel hybrid few-shot meta-reinforcement learning (meta-RL) method\nthat uniquely combines, yet distinctly separates, parameterized policy\ngradient-based (PPG) and task inference-based few-shot meta-RL. Tailored for\nsettings where the reward signal is missing during meta-testing, our method\nincreases sample efficiency without requiring additional samples in\nmeta-training. UMCNP leverages the efficiency and scalability of Conditional\nNeural Processes (CNPs) to reduce the number of online interactions required in\nmeta-testing. During meta-training, samples previously collected through PPG\nmeta-RL are efficiently reused for learning task inference in an offline\nmanner. UMCNP infers the latent representation of the transition dynamics model\nfrom a single test task rollout with unknown parameters. This approach allows\nus to generate rollouts for self-adaptation by interacting with the learned\ndynamics model. We demonstrate our method can adapt to an unseen test task\nusing significantly fewer samples during meta-testing than the baselines in\n2D-Point Agent and continuous control meta-RL benchmarks, namely, cartpole with\nunknown angle sensor bias, walker agent with randomized dynamics parameters.", "AI": {"tldr": "UMCNP is a hybrid few-shot meta-RL method combining policy gradient and task inference, improving sample efficiency without extra meta-training samples by leveraging CNPs for task inference.", "motivation": "Addresses the challenge of missing reward signals during meta-testing while enhancing sample efficiency.", "method": "Combines PPG meta-RL and CNPs for task inference, reusing meta-training samples offline and inferring task dynamics from a single rollout.", "result": "Outperforms baselines in 2D-Point Agent and continuous control tasks, requiring fewer meta-testing samples.", "conclusion": "UMCNP effectively adapts to unseen tasks with minimal samples, demonstrating superior efficiency and scalability."}}
{"id": "2506.04411", "pdf": "https://arxiv.org/pdf/2506.04411", "abs": "https://arxiv.org/abs/2506.04411", "authors": ["Achleshwar Luthra", "Tianbao Yang", "Tomer Galanti"], "title": "Self-Supervised Contrastive Learning is Approximately Supervised Contrastive Learning", "categories": ["cs.LG"], "comment": null, "summary": "Despite its empirical success, the theoretical foundations of self-supervised\ncontrastive learning (CL) are not yet fully established. In this work, we\naddress this gap by showing that standard CL objectives implicitly approximate\na supervised variant we call the negatives-only supervised contrastive loss\n(NSCL), which excludes same-class contrasts. We prove that the gap between the\nCL and NSCL losses vanishes as the number of semantic classes increases, under\na bound that is both label-agnostic and architecture-independent.\n  We characterize the geometric structure of the global minimizers of the NSCL\nloss: the learned representations exhibit augmentation collapse, within-class\ncollapse, and class centers that form a simplex equiangular tight frame. We\nfurther introduce a new bound on the few-shot error of linear-probing. This\nbound depends on two measures of feature variability--within-class dispersion\nand variation along the line between class centers. We show that directional\nvariation dominates the bound and that the within-class dispersion's effect\ndiminishes as the number of labeled samples increases. These properties enable\nCL and NSCL-trained representations to support accurate few-shot label recovery\nusing simple linear probes.\n  Finally, we empirically validate our theoretical findings: the gap between CL\nand NSCL losses decays at a rate of $\\mathcal{O}(\\frac{1}{\\#\\text{classes}})$;\nthe two losses are highly correlated; minimizing the CL loss implicitly brings\nthe NSCL loss close to the value achieved by direct minimization; and the\nproposed few-shot error bound provides a tight estimate of probing performance\nin practice.", "AI": {"tldr": "The paper bridges the theoretical gap in self-supervised contrastive learning (CL) by linking it to a supervised variant (NSCL), showing their equivalence as class numbers grow, and analyzing the geometric structure of learned representations. It also introduces a bound for few-shot error and validates findings empirically.", "motivation": "To establish theoretical foundations for self-supervised contrastive learning, which lacks comprehensive understanding despite empirical success.", "method": "The authors analyze CL by approximating it with a supervised variant (NSCL), prove vanishing gaps between losses with increasing classes, characterize minimizers' geometric structure, and derive a few-shot error bound.", "result": "The gap between CL and NSCL losses vanishes as class numbers increase; learned representations exhibit specific geometric properties; a tight few-shot error bound is introduced.", "conclusion": "The study provides theoretical insights into CL, validates the equivalence of CL and NSCL, and demonstrates practical implications for few-shot learning."}}
{"id": "2506.04430", "pdf": "https://arxiv.org/pdf/2506.04430", "abs": "https://arxiv.org/abs/2506.04430", "authors": ["Egor Petrov", "Grigoriy Evseev", "Aleksey Antonov", "Andrey Veprikov", "Pavel Plyusnin", "Nikolay Bushkov", "Stanislav Moiseev", "Aleksandr Beznosikov"], "title": "Leveraging Coordinate Momentum in SignSGD and Muon: Memory-Optimized Zero-Order", "categories": ["cs.LG", "math.OC"], "comment": "26 pages, 5 tables", "summary": "Fine-tuning Large Language Models (LLMs) is essential for adapting\npre-trained models to downstream tasks. Yet traditional first-order optimizers\nsuch as Stochastic Gradient Descent (SGD) and Adam incur prohibitive memory and\ncomputational costs that scale poorly with model size. In this paper, we\ninvestigate zero-order (ZO) optimization methods as a memory- and\ncompute-efficient alternative, particularly in the context of\nparameter-efficient fine-tuning techniques like LoRA. We propose\n$\\texttt{JAGUAR SignSGD}$, a ZO momentum-based algorithm that extends ZO\nSignSGD, requiring the same number of parameters as the standard ZO SGD and\nonly $\\mathcal{O}(1)$ function evaluations per iteration. To the best of our\nknowledge, this is the first study to establish rigorous convergence guarantees\nfor SignSGD in the stochastic ZO case. We further propose $\\texttt{JAGUAR\nMuon}$, a novel ZO extension of the Muon optimizer that leverages the matrix\nstructure of model parameters, and we provide its convergence rate under\narbitrary stochastic noise. Through extensive experiments on challenging LLM\nfine-tuning benchmarks, we demonstrate that the proposed algorithms meet or\nexceed the convergence quality of standard first-order methods, achieving\nsignificant memory reduction. Our theoretical and empirical results establish\nnew ZO optimization methods as a practical and theoretically grounded approach\nfor resource-constrained LLM adaptation. Our code is available at\nhttps://github.com/brain-mmo-lab/ZO_LLM", "AI": {"tldr": "The paper proposes zero-order (ZO) optimization methods, JAGUAR SignSGD and JAGUAR Muon, as efficient alternatives to traditional first-order optimizers for fine-tuning LLMs, offering memory reduction and strong convergence guarantees.", "motivation": "Traditional first-order optimizers like SGD and Adam are computationally expensive for fine-tuning large language models (LLMs). The paper explores ZO methods as a resource-efficient alternative, especially for parameter-efficient techniques like LoRA.", "method": "The authors introduce JAGUAR SignSGD, a momentum-based ZO algorithm, and JAGUAR Muon, a ZO extension of Muon optimizer. Both methods aim to reduce memory and computational costs while maintaining convergence quality.", "result": "Experiments show the proposed ZO methods match or surpass the performance of first-order optimizers, with significant memory savings. Theoretical convergence guarantees are provided for both algorithms.", "conclusion": "The study establishes ZO optimization as a practical and theoretically sound approach for fine-tuning LLMs under resource constraints, offering a balance between efficiency and performance."}}
{"id": "2506.04432", "pdf": "https://arxiv.org/pdf/2506.04432", "abs": "https://arxiv.org/abs/2506.04432", "authors": ["Zixuan Xia", "Aram Davtyan", "Paolo Favaro"], "title": "KOALA++: Efficient Kalman-Based Optimization of Neural Networks with Gradient-Covariance Products", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "We propose KOALA++, a scalable Kalman-based optimization algorithm that\nexplicitly models structured gradient uncertainty in neural network training.\nUnlike second-order methods, which rely on expensive second order gradient\ncalculation, our method directly estimates the parameter covariance matrix by\nrecursively updating compact gradient covariance products. This design improves\nupon the original KOALA framework that assumed diagonal covariance by\nimplicitly capturing richer uncertainty structure without storing the full\ncovariance matrix and avoiding large matrix inversions. Across diverse tasks,\nincluding image classification and language modeling, KOALA++ achieves accuracy\non par or better than state-of-the-art first- and second-order optimizers while\nmaintaining the efficiency of first-order methods.", "AI": {"tldr": "KOALA++ is a scalable Kalman-based optimization algorithm for neural networks, improving upon KOALA by modeling structured gradient uncertainty efficiently without costly second-order calculations.", "motivation": "To address the inefficiency of second-order methods in neural network training while capturing richer gradient uncertainty structure.", "method": "Estimates parameter covariance matrix recursively using compact gradient covariance products, avoiding full matrix storage and inversions.", "result": "Achieves accuracy comparable or superior to state-of-the-art optimizers in tasks like image classification and language modeling, with first-order efficiency.", "conclusion": "KOALA++ offers an efficient and effective alternative to traditional first- and second-order optimizers by better modeling gradient uncertainty."}}
{"id": "2506.04434", "pdf": "https://arxiv.org/pdf/2506.04434", "abs": "https://arxiv.org/abs/2506.04434", "authors": ["Hari K. Prakash", "Charles H. Martin"], "title": "Grokking and Generalization Collapse: Insights from \\texttt{HTSR} theory", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "15 pages,7 figs", "summary": "We study the well-known grokking phenomena in neural networks (NNs) using a\n3-layer MLP trained on 1 k-sample subset of MNIST, with and without weight\ndecay, and discover a novel third phase -- \\emph{anti-grokking} -- that occurs\nvery late in training and resembles but is distinct from the familiar\n\\emph{pre-grokking} phases: test accuracy collapses while training accuracy\nstays perfect. This late-stage collapse is distinct, from the known\npre-grokking and grokking phases, and is not detected by other proposed\ngrokking progress measures. Leveraging Heavy-Tailed Self-Regularization HTSR\nthrough the open-source WeightWatcher tool, we show that the HTSR layer quality\nmetric $\\alpha$ alone delineates all three phases, whereas the best competing\nmetrics detect only the first two. The \\emph{anti-grokking} is revealed by\ntraining for $10^7$ and is invariably heralded by $\\alpha < 2$ and the\nappearance of \\emph{Correlation Traps} -- outlier singular values in the\nrandomized layer weight matrices that make the layer weight matrix atypical and\nsignal overfitting of the training set. Such traps are verified by visual\ninspection of the layer-wise empirical spectral densities, and by using\nKolmogorov--Smirnov tests on randomized spectra. Comparative metrics, including\nactivation sparsity, absolute weight entropy, circuit complexity, and $l^2$\nweight norms track pre-grokking and grokking but fail to distinguish grokking\nfrom anti-grokking. This discovery provides a way to measure overfitting and\ngeneralization collapse without direct access to the test data. These results\nstrengthen the claim that the \\emph{HTSR} $\\alpha$ provides universal\nlayer-convergence target at $\\alpha \\approx 2$ and underscore the value of\nusing the HTSR alpha $(\\alpha)$ metric as a measure of generalization.", "AI": {"tldr": "The paper identifies a new phase in neural network training called 'anti-grokking,' distinct from pre-grokking and grokking, where test accuracy collapses while training accuracy remains high. The Heavy-Tailed Self-Regularization (HTSR) metric \u03b1 effectively detects all three phases, unlike other metrics.", "motivation": "To explore the grokking phenomenon in neural networks and uncover new phases of training behavior, particularly focusing on late-stage collapse (anti-grokking).", "method": "A 3-layer MLP is trained on a subset of MNIST with and without weight decay. The HTSR metric \u03b1, measured using the WeightWatcher tool, is used to analyze layer quality and detect phases.", "result": "Anti-grokking is identified as a distinct phase, marked by \u03b1 < 2 and Correlation Traps. HTSR \u03b1 outperforms other metrics in detecting all phases.", "conclusion": "HTSR \u03b1 is a robust metric for measuring generalization and detecting overfitting, with \u03b1 \u2248 2 as a universal convergence target."}}
{"id": "2506.04439", "pdf": "https://arxiv.org/pdf/2506.04439", "abs": "https://arxiv.org/abs/2506.04439", "authors": ["Robin Yadav", "Qi Yan", "Guy Wolf", "Avishek Joey Bose", "Renjie Liao"], "title": "RETRO SYNFLOW: Discrete Flow Matching for Accurate and Diverse Single-Step Retrosynthesis", "categories": ["cs.LG"], "comment": null, "summary": "A fundamental problem in organic chemistry is identifying and predicting the\nseries of reactions that synthesize a desired target product molecule. Due to\nthe combinatorial nature of the chemical search space, single-step reactant\nprediction -- i.e. single-step retrosynthesis -- remains challenging even for\nexisting state-of-the-art template-free generative approaches to produce an\naccurate yet diverse set of feasible reactions. In this paper, we model\nsingle-step retrosynthesis planning and introduce RETRO SYNFLOW (RSF) a\ndiscrete flow-matching framework that builds a Markov bridge between the\nprescribed target product molecule and the reactant molecule. In contrast to\npast approaches, RSF employs a reaction center identification step to produce\nintermediate structures known as synthons as a more informative source\ndistribution for the discrete flow. To further enhance diversity and\nfeasibility of generated samples, we employ Feynman-Kac steering with\nSequential Monte Carlo based resampling to steer promising generations at\ninference using a new reward oracle that relies on a forward-synthesis model.\nEmpirically, we demonstrate \\nameshort achieves $60.0 \\%$ top-1 accuracy, which\noutperforms the previous SOTA by $20 \\%$. We also substantiate the benefits of\nsteering at inference and demonstrate that FK-steering improves top-$5$\nround-trip accuracy by $19 \\%$ over prior template-free SOTA methods, all while\npreserving competitive top-$k$ accuracy results.", "AI": {"tldr": "RETRO SYNFLOW (RSF) is a discrete flow-matching framework for single-step retrosynthesis, outperforming state-of-the-art methods with 60.0% top-1 accuracy and improved diversity.", "motivation": "Addressing the challenge of accurate and diverse single-step retrosynthesis prediction in organic chemistry.", "method": "RSF uses a Markov bridge between target and reactant molecules, reaction center identification, and Feynman-Kac steering with Sequential Monte Carlo resampling.", "result": "Achieves 60.0% top-1 accuracy, a 20% improvement over prior SOTA, and 19% better top-5 round-trip accuracy.", "conclusion": "RSF enhances retrosynthesis planning with higher accuracy and diversity, validated by empirical results."}}
{"id": "2506.04446", "pdf": "https://arxiv.org/pdf/2506.04446", "abs": "https://arxiv.org/abs/2506.04446", "authors": ["Gil I. Shamir", "Manfred K. Warmuth"], "title": "Selective Matching Losses -- Not All Scores Are Created Equal", "categories": ["cs.LG"], "comment": null, "summary": "Learning systems match predicted scores to observations over some domain.\nOften, it is critical to produce accurate predictions in some subset (or\nregion) of the domain, yet less important to accurately predict in other\nregions. We construct selective matching loss functions by design of increasing\nlink functions over score domains. A matching loss is an integral over the\nlink. A link defines loss sensitivity as function of the score, emphasizing\nhigh slope high sensitivity regions over flat ones. Loss asymmetry drives a\nmodel and resolves its underspecification to predict better in high sensitivity\nregions where it is more important, and to distinguish between high and low\nimportance regions. A large variety of selective scalar losses can be designed\nwith scaled and shifted Sigmoid and hyperbolic sine links. Their properties,\nhowever, do not extend to multi-class. Applying them per dimension lacks\nranking sensitivity that assigns importance according to class score ranking.\nUtilizing composite Softmax functions, we develop a framework for\nmultidimensional selective losses. We overcome limitations of the standard\nSoftmax function, that is good for classification, but not for distinction\nbetween adjacent scores. Selective losses have substantial advantage over\ntraditional losses in applications with more important score regions, including\ndwell-time prediction, retrieval, ranking with either pointwise, contrastive\npairwise, or listwise losses, distillation problems, and fine-tuning alignment\nof Large Language Models (LLMs).", "AI": {"tldr": "The paper introduces selective matching loss functions to prioritize accurate predictions in specific regions of a domain, using link functions to emphasize high-sensitivity areas. It extends these losses to multi-class settings and demonstrates their advantages in various applications.", "motivation": "Accurate predictions are often critical in specific regions of a domain, but traditional losses treat all regions equally. The paper aims to address this by designing loss functions that prioritize high-importance regions.", "method": "The authors construct selective matching loss functions using link functions (e.g., Sigmoid, hyperbolic sine) to emphasize high-sensitivity regions. They extend these to multi-class settings using composite Softmax functions.", "result": "Selective losses outperform traditional losses in applications like dwell-time prediction, retrieval, ranking, and LLM fine-tuning, by focusing on high-importance regions.", "conclusion": "Selective loss functions provide a flexible and effective way to prioritize accuracy in critical regions, improving performance in various machine learning tasks."}}
{"id": "2506.04454", "pdf": "https://arxiv.org/pdf/2506.04454", "abs": "https://arxiv.org/abs/2506.04454", "authors": ["Huynh T. T. Tran", "Jacob Sander", "Achraf Cohen", "Brian Jalaian", "Nathaniel D. Bastian"], "title": "Neurosymbolic Artificial Intelligence for Robust Network Intrusion Detection: From Scratch to Transfer Learning", "categories": ["cs.LG"], "comment": "17 pages, 5 figures, 11 tables", "summary": "Network Intrusion Detection Systems (NIDS) play a vital role in protecting\ndigital infrastructures against increasingly sophisticated cyber threats. In\nthis paper, we extend ODXU, a Neurosymbolic AI (NSAI) framework that integrates\ndeep embedded clustering for feature extraction, symbolic reasoning using\nXGBoost, and comprehensive uncertainty quantification (UQ) to enhance\nrobustness, interpretability, and generalization in NIDS. The extended ODXU\nincorporates score-based methods (e.g., Confidence Scoring, Shannon Entropy)\nand metamodel-based techniques, including SHAP values and Information Gain, to\nassess the reliability of predictions. Experimental results on the CIC-IDS-2017\ndataset show that ODXU outperforms traditional neural models across six\nevaluation metrics, including classification accuracy and false omission rate.\nWhile transfer learning has seen widespread adoption in fields such as computer\nvision and natural language processing, its potential in cybersecurity has not\nbeen thoroughly explored. To bridge this gap, we develop a transfer learning\nstrategy that enables the reuse of a pre-trained ODXU model on a different\ndataset. Our ablation study on ACI-IoT-2023 demonstrates that the optimal\ntransfer configuration involves reusing the pre-trained autoencoder, retraining\nthe clustering module, and fine-tuning the XGBoost classifier, and outperforms\ntraditional neural models when trained with as few as 16,000 samples\n(approximately 50% of the training data). Additionally, results show that\nmetamodel-based UQ methods consistently outperform score-based approaches on\nboth datasets.", "AI": {"tldr": "The paper extends ODXU, a Neurosymbolic AI framework, for Network Intrusion Detection Systems (NIDS), integrating deep clustering, symbolic reasoning, and uncertainty quantification. It outperforms traditional models and explores transfer learning in cybersecurity.", "motivation": "To enhance robustness, interpretability, and generalization in NIDS by combining Neurosymbolic AI with advanced uncertainty quantification and transfer learning.", "method": "Extends ODXU with score-based and metamodel-based uncertainty quantification, and develops a transfer learning strategy for cybersecurity applications.", "result": "ODXU outperforms traditional neural models on the CIC-IDS-2017 dataset and shows effective transfer learning on ACI-IoT-2023 with minimal data.", "conclusion": "The extended ODXU framework improves NIDS performance and demonstrates the viability of transfer learning in cybersecurity, with metamodel-based UQ methods being superior."}}
{"id": "2506.04461", "pdf": "https://arxiv.org/pdf/2506.04461", "abs": "https://arxiv.org/abs/2506.04461", "authors": ["Ivan Vegner", "Sydelle de Souza", "Valentin Forch", "Martha Lewis", "Leonidas A. A. Doumas"], "title": "Behavioural vs. Representational Systematicity in End-to-End Models: An Opinionated Survey", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.0; I.2.7"], "comment": "To appear at ACL 2025 Main Conference", "summary": "A core aspect of compositionality, systematicity is a desirable property in\nML models as it enables strong generalization to novel contexts. This has led\nto numerous studies proposing benchmarks to assess systematic generalization,\nas well as models and training regimes designed to enhance it. Many of these\nefforts are framed as addressing the challenge posed by Fodor and Pylyshyn.\nHowever, while they argue for systematicity of representations, existing\nbenchmarks and models primarily focus on the systematicity of behaviour. We\nemphasize the crucial nature of this distinction. Furthermore, building on\nHadley's (1994) taxonomy of systematic generalization, we analyze the extent to\nwhich behavioural systematicity is tested by key benchmarks in the literature\nacross language and vision. Finally, we highlight ways of assessing\nsystematicity of representations in ML models as practiced in the field of\nmechanistic interpretability.", "AI": {"tldr": "The paper discusses the distinction between systematicity of behavior and representations in ML models, analyzes benchmarks for behavioral systematicity, and suggests ways to assess representational systematicity.", "motivation": "To address the gap between Fodor and Pylyshyn's argument for systematicity of representations and the focus on behavioral systematicity in existing benchmarks and models.", "method": "Analyzes key benchmarks in language and vision using Hadley's (1994) taxonomy of systematic generalization and highlights methods from mechanistic interpretability.", "result": "Identifies limitations in current benchmarks for testing behavioral systematicity and proposes ways to evaluate representational systematicity.", "conclusion": "Emphasizes the need to distinguish and assess both behavioral and representational systematicity for better generalization in ML models."}}
{"id": "2506.04474", "pdf": "https://arxiv.org/pdf/2506.04474", "abs": "https://arxiv.org/abs/2506.04474", "authors": ["Mohammad Subhi Al-Batah", "Mowafaq Salem Alzboon", "Muhyeeddin Alqaraleh", "Mohammed Hasan Abu-Arqoub", "Rashiq Rafiq Marie"], "title": "Classifying Dental Care Providers Through Machine Learning with Features Ranking", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study investigates the application of machine learning (ML) models for\nclassifying dental providers into two categories - standard rendering providers\nand safety net clinic (SNC) providers - using a 2018 dataset of 24,300\ninstances with 20 features. The dataset, characterized by high missing values\n(38.1%), includes service counts (preventive, treatment, exams), delivery\nsystems (FFS, managed care), and beneficiary demographics. Feature ranking\nmethods such as information gain, Gini index, and ANOVA were employed to\nidentify critical predictors, revealing treatment-related metrics\n(TXMT_USER_CNT, TXMT_SVC_CNT) as top-ranked features. Twelve ML models,\nincluding k-Nearest Neighbors (kNN), Decision Trees, Support Vector Machines\n(SVM), Stochastic Gradient Descent (SGD), Random Forest, Neural Networks, and\nGradient Boosting, were evaluated using 10-fold cross-validation.\nClassification accuracy was tested across incremental feature subsets derived\nfrom rankings. The Neural Network achieved the highest accuracy (94.1%) using\nall 20 features, followed by Gradient Boosting (93.2%) and Random Forest\n(93.0%). Models showed improved performance as more features were incorporated,\nwith SGD and ensemble methods demonstrating robustness to missing data. Feature\nranking highlighted the dominance of treatment service counts and annotation\ncodes in distinguishing provider types, while demographic variables (AGE_GROUP,\nCALENDAR_YEAR) had minimal impact. The study underscores the importance of\nfeature selection in enhancing model efficiency and accuracy, particularly in\nimbalanced healthcare datasets. These findings advocate for integrating\nfeature-ranking techniques with advanced ML algorithms to optimize dental\nprovider classification, enabling targeted resource allocation for underserved\npopulations.", "AI": {"tldr": "The study uses ML models to classify dental providers into two categories, achieving high accuracy (94.1% with Neural Networks) and highlighting the importance of feature selection, especially treatment-related metrics, for efficient classification.", "motivation": "To improve classification of dental providers for better resource allocation, especially for underserved populations, using ML models on a dataset with high missing values.", "method": "Employed 12 ML models (e.g., Neural Networks, Gradient Boosting) on a dataset of 24,300 instances with 20 features, using feature ranking methods (information gain, Gini index, ANOVA) and 10-fold cross-validation.", "result": "Neural Networks achieved the highest accuracy (94.1%), with treatment-related metrics being top predictors. Models improved with more features, and ensemble methods handled missing data well.", "conclusion": "Feature selection is crucial for ML efficiency in healthcare datasets. Integrating feature-ranking with advanced ML can optimize dental provider classification for targeted resource allocation."}}
{"id": "2506.04479", "pdf": "https://arxiv.org/pdf/2506.04479", "abs": "https://arxiv.org/abs/2506.04479", "authors": ["Mohammad Subhi Al-Batah", "Muhyeeddin Alqaraleh", "Mowafaq Salem Alzboon", "Abdullah Alourani"], "title": "Comparative performance of ensemble models in predicting dental provider types: insights from fee-for-service data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Dental provider classification plays a crucial role in optimizing healthcare\nresource allocation and policy planning. Effective categorization of providers,\nsuch as standard rendering providers and safety net clinic (SNC) providers,\nenhances service delivery to underserved populations. This study aimed to\nevaluate the performance of machine learning models in classifying dental\nproviders using a 2018 dataset. A dataset of 24,300 instances with 20 features\nwas analyzed, including beneficiary and service counts across fee-for-service\n(FFS), Geographic Managed Care, and Pre-Paid Health Plans. Providers were\ncategorized by delivery system and patient age groups (0-20 and 21+). Despite\n38.1% missing data, multiple machine learning algorithms were tested, including\nk-Nearest Neighbors (kNN), Decision Trees, Support Vector Machines (SVM),\nStochastic Gradient Descent (SGD), Random Forest, Neural Networks, and Gradient\nBoosting. A 10-fold cross-validation approach was applied, and models were\nevaluated using AUC, classification accuracy (CA), F1-score, precision, and\nrecall. Neural Networks achieved the highest AUC (0.975) and CA (94.1%),\nfollowed by Random Forest (AUC: 0.948, CA: 93.0%). These models effectively\nhandled imbalanced data and complex feature interactions, outperforming\ntraditional classifiers like Logistic Regression and SVM. Advanced machine\nlearning techniques, particularly ensemble and deep learning models,\nsignificantly enhance dental workforce classification. Their integration into\nhealthcare analytics can improve provider identification and resource\ndistribution, benefiting underserved populations.", "AI": {"tldr": "Machine learning models, especially Neural Networks and Random Forest, excelled in classifying dental providers, improving healthcare resource allocation.", "motivation": "To enhance service delivery for underserved populations by accurately classifying dental providers.", "method": "Analyzed a 2018 dataset of 24,300 instances with 20 features using multiple ML algorithms (kNN, Decision Trees, SVM, SGD, Random Forest, Neural Networks, Gradient Boosting) and evaluated performance via 10-fold cross-validation.", "result": "Neural Networks achieved the highest AUC (0.975) and classification accuracy (94.1%), followed by Random Forest (AUC: 0.948, CA: 93.0%).", "conclusion": "Advanced ML models, particularly ensemble and deep learning, significantly improve dental provider classification, aiding better resource distribution for underserved communities."}}
{"id": "2506.04487", "pdf": "https://arxiv.org/pdf/2506.04487", "abs": "https://arxiv.org/abs/2506.04487", "authors": ["C. Evans Hedges"], "title": "Orthogonal Gradient Descent Improves Neural Calibration", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We provide evidence that orthogonalizing gradients during training improves\nmodel calibration without sacrificing accuracy. On CIFAR-10 with 10% labeled\ndata, $\\perp$Grad matches SGD in accuracy but yields consistently improved\ncalibration metrics such as lower test loss, reduced softmax overconfidence,\nand higher predictive entropy. These benefits persist under input corruption\n(CIFAR-10C) and extended training, where $\\perp$Grad models degrade more\ngracefully than SGD-trained counterparts. $\\perp$Grad is optimizer-agnostic,\nincurs minimal overhead, and works well with post-hoc calibration techniques\nlike temperature scaling.\n  Theoretically, we prove convergence of a simplified version of $\\perp$Grad\nunder mild assumptions and characterize its stationary points in positive\nhomogeneous networks: $\\perp$Grad converges to solutions where further loss\nreduction requires confidence scaling rather than decision boundary\nimprovement.", "AI": {"tldr": "Orthogonalizing gradients ($\\perp$Grad) improves model calibration without losing accuracy, outperforming SGD in metrics like test loss and predictive entropy. It works well under input corruption and extended training, is optimizer-agnostic, and complements post-hoc calibration. Theoretically, it converges to solutions favoring confidence scaling over boundary improvement.", "motivation": "To enhance model calibration while maintaining accuracy, addressing issues like overconfidence and poor generalization under corruption.", "method": "Orthogonalizing gradients during training ($\\perp$Grad), tested on CIFAR-10 with 10% labeled data and CIFAR-10C. Analyzed calibration metrics and convergence properties.", "result": "$\\perp$Grad matches SGD in accuracy but improves calibration (lower test loss, reduced overconfidence, higher entropy). Benefits persist under corruption and extended training.", "conclusion": "$\\perp$Grad is a practical, efficient method for better calibration, supported by theoretical guarantees and empirical success."}}
{"id": "2506.04490", "pdf": "https://arxiv.org/pdf/2506.04490", "abs": "https://arxiv.org/abs/2506.04490", "authors": ["Rishwanth Raghu", "Axel Levy", "Gordon Wetzstein", "Ellen D. Zhong"], "title": "Multiscale guidance of AlphaFold3 with heterogeneous cryo-EM data", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Protein structure prediction models are now capable of generating accurate 3D\nstructural hypotheses from sequence alone. However, they routinely fail to\ncapture the conformational diversity of dynamic biomolecular complexes, often\nrequiring heuristic MSA subsampling approaches for generating alternative\nstates. In parallel, cryo-electron microscopy (cryo-EM) has emerged as a\npowerful tool for imaging near-native structural heterogeneity, but is\nchallenged by arduous pipelines to go from raw experimental data to atomic\nmodels. Here, we bridge the gap between these modalities, combining cryo-EM\ndensity maps with the rich sequence and biophysical priors learned by protein\nstructure prediction models. Our method, CryoBoltz, guides the sampling\ntrajectory of a pretrained protein structure prediction model using both global\nand local structural constraints derived from density maps, driving predictions\ntowards conformational states consistent with the experimental data. We\ndemonstrate that this flexible yet powerful inference-time approach allows us\nto build atomic models into heterogeneous cryo-EM maps across a variety of\ndynamic biomolecular systems including transporters and antibodies.", "AI": {"tldr": "CryoBoltz combines cryo-EM density maps with protein structure prediction models to capture conformational diversity in dynamic biomolecular systems.", "motivation": "Current protein structure prediction models lack the ability to capture conformational diversity, while cryo-EM struggles with converting raw data into atomic models.", "method": "CryoBoltz integrates cryo-EM density maps with pretrained protein structure prediction models, using global and local constraints to guide sampling.", "result": "The method successfully builds atomic models for diverse dynamic systems like transporters and antibodies.", "conclusion": "CryoBoltz bridges the gap between cryo-EM and structure prediction, enabling accurate modeling of conformational states."}}
{"id": "2506.04528", "pdf": "https://arxiv.org/pdf/2506.04528", "abs": "https://arxiv.org/abs/2506.04528", "authors": ["Ruoxi Jiang", "Xiao Zhang", "Karan Jakhar", "Peter Y. Lu", "Pedram Hassanzadeh", "Michael Maire", "Rebecca Willett"], "title": "Hierarchical Implicit Neural Emulators", "categories": ["cs.LG"], "comment": null, "summary": "Neural PDE solvers offer a powerful tool for modeling complex dynamical\nsystems, but often struggle with error accumulation over long time horizons and\nmaintaining stability and physical consistency. We introduce a multiscale\nimplicit neural emulator that enhances long-term prediction accuracy by\nconditioning on a hierarchy of lower-dimensional future state representations.\nDrawing inspiration from the stability properties of numerical implicit\ntime-stepping methods, our approach leverages predictions several steps ahead\nin time at increasing compression rates for next-timestep refinements. By\nactively adjusting the temporal downsampling ratios, our design enables the\nmodel to capture dynamics across multiple granularities and enforce long-range\ntemporal coherence. Experiments on turbulent fluid dynamics show that our\nmethod achieves high short-term accuracy and produces long-term stable\nforecasts, significantly outperforming autoregressive baselines while adding\nminimal computational overhead.", "AI": {"tldr": "A multiscale implicit neural emulator improves long-term prediction accuracy in neural PDE solvers by using hierarchical future state representations and adaptive temporal downsampling.", "motivation": "Neural PDE solvers often face challenges with error accumulation and stability over long time horizons, limiting their effectiveness for complex dynamical systems.", "method": "The proposed method conditions on a hierarchy of lower-dimensional future state representations and leverages predictions several steps ahead at increasing compression rates for refinements. It adjusts temporal downsampling ratios to capture dynamics across granularities.", "result": "Experiments on turbulent fluid dynamics demonstrate high short-term accuracy and long-term stability, outperforming autoregressive baselines with minimal computational overhead.", "conclusion": "The multiscale implicit neural emulator effectively addresses stability and accuracy issues in neural PDE solvers, offering improved performance for long-term predictions."}}
{"id": "2506.04531", "pdf": "https://arxiv.org/pdf/2506.04531", "abs": "https://arxiv.org/abs/2506.04531", "authors": ["Geon-Woo Kim", "Junbo Li", "Shashidhar Gandham", "Omar Baldonado", "Adithya Gangidi", "Pavan Balaji", "Zhangyang Wang", "Aditya Akella"], "title": "HALoS: Hierarchical Asynchronous Local SGD over Slow Networks for Geo-Distributed Large Language Model Training", "categories": ["cs.LG"], "comment": null, "summary": "Training large language models (LLMs) increasingly relies on geographically\ndistributed accelerators, causing prohibitive communication costs across\nregions and uneven utilization of heterogeneous hardware. We propose HALoS, a\nhierarchical asynchronous optimization framework that tackles these issues by\nintroducing local parameter servers (LPSs) within each region and a global\nparameter server (GPS) that merges updates across regions. This hierarchical\ndesign minimizes expensive inter-region communication, reduces straggler\neffects, and leverages fast intra-region links. We provide a rigorous\nconvergence analysis for HALoS under non-convex objectives, including\ntheoretical guarantees on the role of hierarchical momentum in asynchronous\ntraining. Empirically, HALoS attains up to 7.5x faster convergence than\nsynchronous baselines in geo-distributed LLM training and improves upon\nexisting asynchronous methods by up to 2.1x. Crucially, HALoS preserves the\nmodel quality of fully synchronous SGD-matching or exceeding accuracy on\nstandard language modeling and downstream benchmarks-while substantially\nlowering total training time. These results demonstrate that hierarchical,\nserver-side update accumulation and global model merging are powerful tools for\nscalable, efficient training of new-era LLMs in heterogeneous, geo-distributed\nenvironments.", "AI": {"tldr": "HALoS is a hierarchical asynchronous optimization framework for training LLMs across distributed regions, reducing communication costs and improving efficiency while maintaining model quality.", "motivation": "Training LLMs on geographically distributed accelerators faces high communication costs and uneven hardware utilization, necessitating a solution like HALoS.", "method": "HALoS introduces local parameter servers (LPSs) within regions and a global parameter server (GPS) to merge updates, minimizing inter-region communication and leveraging fast intra-region links.", "result": "HALoS achieves up to 7.5x faster convergence than synchronous baselines and 2.1x improvement over asynchronous methods, while preserving model accuracy.", "conclusion": "HALoS demonstrates that hierarchical, server-side update accumulation is effective for scalable and efficient LLM training in heterogeneous, geo-distributed environments."}}
{"id": "2506.04536", "pdf": "https://arxiv.org/pdf/2506.04536", "abs": "https://arxiv.org/abs/2506.04536", "authors": ["Luca Ghafourpour", "Valentin Duruisseaux", "Bahareh Tolooshams", "Philip H. Wong", "Costas A. Anastassiou", "Anima Anandkumar"], "title": "NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "comment": null, "summary": "Characterizing the diverse computational properties of human neurons via\nmultimodal electrophysiological, transcriptomic, and morphological data\nprovides the foundation for constructing and validating bio-realistic neuron\nmodels that can advance our understanding of fundamental mechanisms underlying\nbrain function. However, current modeling approaches remain constrained by the\nlimited availability and intrinsic variability of experimental neuronal data.\nTo capture variability, ensembles of deterministic models are often used, but\nare difficult to scale as model generation requires repeating computationally\nexpensive optimization for each neuron. While deep learning is becoming\nincreasingly relevant in this space, it fails to capture the full biophysical\ncomplexity of neurons, their nonlinear voltage dynamics, and variability. To\naddress these shortcomings, we introduce NOBLE, a neural operator framework\nthat learns a mapping from a continuous frequency-modulated embedding of\ninterpretable neuron features to the somatic voltage response induced by\ncurrent injection. Trained on data generated from biophysically realistic\nneuron models, NOBLE predicts distributions of neural dynamics accounting for\nthe intrinsic experimental variability. Unlike conventional bio-realistic\nneuron models, interpolating within the embedding space offers models whose\ndynamics are consistent with experimentally observed responses. NOBLE is the\nfirst scaled-up deep learning framework validated on real experimental data,\nenabling efficient generation of synthetic neurons that exhibit trial-to-trial\nvariability and achieve a $4200\\times$ speedup over numerical solvers. To this\nend, NOBLE captures fundamental neural properties, opening the door to a better\nunderstanding of cellular composition and computations, neuromorphic\narchitectures, large-scale brain circuits, and general neuroAI applications.", "AI": {"tldr": "NOBLE is a neural operator framework that predicts neural dynamics by learning from biophysically realistic neuron models, addressing variability and scalability issues in current approaches.", "motivation": "Current neuron modeling approaches struggle with data variability and computational costs, limiting their scalability and accuracy.", "method": "NOBLE uses a neural operator to map interpretable neuron features to somatic voltage responses, trained on realistic neuron models.", "result": "NOBLE predicts neural dynamics with variability, achieves a 4200x speedup, and is validated on real experimental data.", "conclusion": "NOBLE advances neuron modeling, enabling better understanding of brain function and applications in neuroAI."}}
{"id": "2506.04542", "pdf": "https://arxiv.org/pdf/2506.04542", "abs": "https://arxiv.org/abs/2506.04542", "authors": ["Yuanpei Gao", "Qi Yan", "Yan Leng", "Renjie Liao"], "title": "Neural MJD: Neural Non-Stationary Merton Jump Diffusion for Time Series Prediction", "categories": ["cs.LG"], "comment": null, "summary": "While deep learning methods have achieved strong performance in time series\nprediction, their black-box nature and inability to explicitly model underlying\nstochastic processes often limit their generalization to non-stationary data,\nespecially in the presence of abrupt changes. In this work, we introduce Neural\nMJD, a neural network based non-stationary Merton jump diffusion (MJD) model.\nOur model explicitly formulates forecasting as a stochastic differential\nequation (SDE) simulation problem, combining a time-inhomogeneous It\\^o\ndiffusion to capture non-stationary stochastic dynamics with a\ntime-inhomogeneous compound Poisson process to model abrupt jumps. To enable\ntractable learning, we introduce a likelihood truncation mechanism that caps\nthe number of jumps within small time intervals and provide a theoretical error\nbound for this approximation. Additionally, we propose an Euler-Maruyama with\nrestart solver, which achieves a provably lower error bound in estimating\nexpected states and reduced variance compared to the standard solver.\nExperiments on both synthetic and real-world datasets demonstrate that Neural\nMJD consistently outperforms state-of-the-art deep learning and statistical\nlearning methods.", "AI": {"tldr": "Neural MJD, a neural network-based non-stationary Merton jump diffusion model, outperforms existing methods by explicitly modeling stochastic processes and handling abrupt changes in time series data.", "motivation": "Deep learning models struggle with non-stationary data and abrupt changes due to their black-box nature. Neural MJD addresses this by explicitly modeling stochastic dynamics and jumps.", "method": "The model combines a time-inhomogeneous It\u00f4 diffusion for non-stationary dynamics and a compound Poisson process for jumps. It uses a likelihood truncation mechanism and a novel Euler-Maruyama solver for tractable learning.", "result": "Neural MJD outperforms state-of-the-art deep learning and statistical methods on synthetic and real-world datasets.", "conclusion": "Neural MJD provides a robust framework for non-stationary time series prediction by integrating stochastic modeling with neural networks."}}
{"id": "2506.04548", "pdf": "https://arxiv.org/pdf/2506.04548", "abs": "https://arxiv.org/abs/2506.04548", "authors": ["Dev Gurung", "Shiva Raj Pokhrel"], "title": "Communication Efficient Adaptive Model-Driven Quantum Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Training with huge datasets and a large number of participating devices leads\nto bottlenecks in federated learning (FL). Furthermore, the challenges of\nheterogeneity between multiple FL clients affect the overall performance of the\nsystem. In a quantum federated learning (QFL) context, we address these three\nmain challenges: i) training bottlenecks from massive datasets, ii) the\ninvolvement of a substantial number of devices, and iii) non-IID data\ndistributions. We introduce a model-driven quantum federated learning algorithm\n(mdQFL) to tackle these challenges. Our proposed approach is efficient and\nadaptable to various factors, including different numbers of devices. To the\nbest of our knowledge, it is the first to explore training and update\npersonalization, as well as test generalization within a QFL setting, which can\nbe applied to other FL scenarios. We evaluated the efficiency of the proposed\nmdQFL framework through extensive experiments under diverse non-IID data\nheterogeneity conditions using various datasets within the Qiskit environment.\nOur results demonstrate a nearly 50% decrease in total communication costs\nwhile maintaining or, in some cases, exceeding the accuracy of the final model\nand consistently improving local model training compared to the standard QFL\nbaseline. Moreover, our experimental evaluation thoroughly explores the QFL and\nmdQFL algorithms, along with several influencing factors. In addition, we\npresent a theoretical analysis to clarify the complexities of the proposed\nalgorithm. The experimental code is available at 1.", "AI": {"tldr": "The paper introduces a model-driven quantum federated learning (mdQFL) algorithm to address challenges like training bottlenecks, large-scale device involvement, and non-IID data in federated learning, achieving reduced communication costs and improved accuracy.", "motivation": "The challenges of massive datasets, numerous devices, and non-IID data distributions in federated learning (FL) and quantum federated learning (QFL) hinder performance and efficiency.", "method": "The authors propose mdQFL, an efficient and adaptable algorithm that includes training and update personalization, and test generalization in a QFL setting.", "result": "Experiments show a 50% reduction in communication costs while maintaining or improving accuracy and local model training compared to standard QFL.", "conclusion": "mdQFL effectively addresses FL challenges in QFL, offering practical benefits and theoretical insights, with potential applicability to broader FL scenarios."}}
{"id": "2506.04553", "pdf": "https://arxiv.org/pdf/2506.04553", "abs": "https://arxiv.org/abs/2506.04553", "authors": ["Andersen Chang", "Tiffany M. Tang", "Tarek M. Zikry", "Genevera I. Allen"], "title": "Unsupervised Machine Learning for Scientific Discovery: Workflow and Best Practices", "categories": ["cs.LG", "stat.AP", "stat.CO", "stat.ML"], "comment": "23 pages, 4 figures, 12 additional pages of citations", "summary": "Unsupervised machine learning is widely used to mine large, unlabeled\ndatasets to make data-driven discoveries in critical domains such as climate\nscience, biomedicine, astronomy, chemistry, and more. However, despite its\nwidespread utilization, there is a lack of standardization in unsupervised\nlearning workflows for making reliable and reproducible scientific discoveries.\nIn this paper, we present a structured workflow for using unsupervised learning\ntechniques in science. We highlight and discuss best practices starting with\nformulating validatable scientific questions, conducting robust data\npreparation and exploration, using a range of modeling techniques, performing\nrigorous validation by evaluating the stability and generalizability of\nunsupervised learning conclusions, and promoting effective communication and\ndocumentation of results to ensure reproducible scientific discoveries. To\nillustrate our proposed workflow, we present a case study from astronomy,\nseeking to refine globular clusters of Milky Way stars based upon their\nchemical composition. Our case study highlights the importance of validation\nand illustrates how the benefits of a carefully-designed workflow for\nunsupervised learning can advance scientific discovery.", "AI": {"tldr": "The paper proposes a standardized workflow for unsupervised learning in science to ensure reliable and reproducible discoveries, illustrated with an astronomy case study.", "motivation": "Address the lack of standardization in unsupervised learning workflows for scientific discoveries.", "method": "Introduces a structured workflow including question formulation, data preparation, modeling, validation, and documentation.", "result": "Demonstrates the workflow's effectiveness through a case study on refining Milky Way globular clusters.", "conclusion": "A carefully-designed workflow enhances validation and reproducibility in unsupervised learning for scientific discovery."}}
{"id": "2506.04566", "pdf": "https://arxiv.org/pdf/2506.04566", "abs": "https://arxiv.org/abs/2506.04566", "authors": ["Kareem Amin", "Salman Avestimehr", "Sara Babakniya", "Alex Bie", "Weiwei Kong", "Natalia Ponomareva", "Umar Syed"], "title": "Clustering and Median Aggregation Improve Differentially Private Inference", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "Differentially private (DP) language model inference is an approach for\ngenerating private synthetic text. A sensitive input example is used to prompt\nan off-the-shelf large language model (LLM) to produce a similar example.\nMultiple examples can be aggregated together to formally satisfy the DP\nguarantee.\n  Prior work creates inference batches by sampling sensitive inputs uniformly\nat random. We show that uniform sampling degrades the quality of privately\ngenerated text, especially when the sensitive examples concern heterogeneous\ntopics.\n  We remedy this problem by clustering the input data before selecting\ninference batches. Next, we observe that clustering also leads to more similar\nnext-token predictions across inferences. We use this insight to introduce a\nnew algorithm that aggregates next token statistics by privately computing\nmedians instead of averages. This approach leverages the fact that the median\nhas decreased local sensitivity when next token predictions are similar,\nallowing us to state a data-dependent and ex-post DP guarantee about the\nprivacy properties of this algorithm. Finally, we demonstrate improvements in\nterms of representativeness metrics (e.g., MAUVE) as well as downstream task\nperformance. We show that our method produces high-quality synthetic data at\nsignificantly lower privacy cost than a previous state-of-the-art method.", "AI": {"tldr": "The paper introduces a method to improve differentially private (DP) language model inference by clustering input data and using medians for aggregation, enhancing text quality and privacy guarantees.", "motivation": "Uniform sampling in DP language model inference degrades text quality, especially for heterogeneous topics. The paper aims to address this by improving batch selection and aggregation methods.", "method": "Clusters input data before selecting inference batches and aggregates next-token predictions using medians instead of averages, leveraging reduced local sensitivity for better privacy guarantees.", "result": "The method improves representativeness metrics (e.g., MAUVE) and downstream task performance, achieving higher-quality synthetic data at lower privacy cost.", "conclusion": "Clustering and median-based aggregation enhance DP language model inference, offering better text quality and stronger privacy guarantees compared to prior methods."}}
{"id": "2506.04567", "pdf": "https://arxiv.org/pdf/2506.04567", "abs": "https://arxiv.org/abs/2506.04567", "authors": ["Ranjith Merugu", "Bryan Bo Cao", "Shubham Jain"], "title": "StatsMerging: Statistics-Guided Model Merging via Task-Specific Teacher Distillation", "categories": ["cs.LG", "cs.CV", "68T05, 68T07, 68T45", "I.4.0; I.4.9; I.5.1; I.5.4"], "comment": "14 pages, 4 figures, 7 tables", "summary": "Model merging has emerged as a promising solution to accommodate multiple\nlarge models within constrained memory budgets. We present StatsMerging, a\nnovel lightweight learning-based model merging method guided by weight\ndistribution statistics without requiring ground truth labels or test samples.\nStatsMerging offers three key advantages: (1) It uniquely leverages singular\nvalues from singular value decomposition (SVD) to capture task-specific weight\ndistributions, serving as a proxy for task importance to guide task coefficient\nprediction; (2) It employs a lightweight learner StatsMergeLearner to model the\nweight distributions of task-specific pre-trained models, improving\ngeneralization and enhancing adaptation to unseen samples; (3) It introduces\nTask-Specific Teacher Distillation for merging vision models with heterogeneous\narchitectures, a merging learning paradigm that avoids costly ground-truth\nlabels by task-specific teacher distillation. Notably, we present two types of\nknowledge distillation, (a) distilling knowledge from task-specific models to\nStatsMergeLearner; and (b) distilling knowledge from models with heterogeneous\narchitectures prior to merging. Extensive experiments across eight tasks\ndemonstrate the effectiveness of StatsMerging. Our results show that\nStatsMerging outperforms state-of-the-art techniques in terms of overall\naccuracy, generalization to unseen tasks, and robustness to image quality\nvariations.", "AI": {"tldr": "StatsMerging is a lightweight, learning-based model merging method that uses weight distribution statistics and SVD for task importance, improving accuracy and generalization without needing labels or test samples.", "motivation": "To address memory constraints by merging multiple large models efficiently, leveraging weight distribution statistics for task-specific guidance.", "method": "Uses SVD for task importance, a lightweight learner (StatsMergeLearner) for weight distribution modeling, and task-specific teacher distillation for heterogeneous architectures.", "result": "Outperforms state-of-the-art in accuracy, generalization, and robustness across eight tasks.", "conclusion": "StatsMerging is effective for merging models without labels, offering superior performance and adaptability."}}
{"id": "2506.04598", "pdf": "https://arxiv.org/pdf/2506.04598", "abs": "https://arxiv.org/abs/2506.04598", "authors": ["Marianna Nezhurina", "Tomer Porian", "Giovanni Pucceti", "Tommie Kerssies", "Romain Beaumont", "Mehdi Cherti", "Jenia Jitsev"], "title": "Scaling Laws for Robust Comparison of Open Foundation Language-Vision Models and Datasets", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Preprint. In Review", "summary": "In studies of transferable learning, scaling laws are obtained for various\nimportant foundation models to predict their properties and performance at\nlarger scales. We show here how scaling law derivation can also be used for\nmodel and dataset comparison, allowing to decide which procedure is to be\npreferred for pre-training. For the first time, full scaling laws based on\ndense measurements across a wide span of model and samples seen scales are\nderived for two important language-vision learning procedures, CLIP and MaMMUT,\nthat use either contrastive only or contrastive and captioning text generative\nloss. Ensuring sufficient prediction accuracy for held out points, we use\nderived scaling laws to compare both models, obtaining evidence for MaMMUT's\nstronger improvement with scale and better sample efficiency than standard\nCLIP. To strengthen validity of the comparison, we show scaling laws for\nvarious downstream tasks, classification, retrieval, and segmentation, and for\ndifferent open datasets, DataComp, DFN and Re-LAION, observing consistently the\nsame trends. We show that comparison can also be performed when deriving\nscaling laws with a constant learning rate schedule, reducing compute cost.\nAccurate derivation of scaling laws provides thus means to perform model and\ndataset comparison across scale spans, avoiding misleading conclusions based on\nmeasurements from single reference scales only, paving the road for systematic\ncomparison and improvement of open foundation models and datasets for their\ncreation. We release all the pre-trained models with their intermediate\ncheckpoints, including openMaMMUT-L/14, which achieves $80.3\\%$ zero-shot\nImageNet-1k accuracy, trained on 12.8B samples from DataComp-1.4B. Code for\nreproducing experiments in the paper and raw experiments data can be found at\nhttps://github.com/LAION-AI/scaling-laws-for-comparison.", "AI": {"tldr": "The paper demonstrates how scaling laws can be used to compare models and datasets for pre-training, focusing on CLIP and MaMMUT. It shows MaMMUT's superior scalability and efficiency, validated across multiple tasks and datasets.", "motivation": "To enable systematic comparison of foundation models and datasets using scaling laws, avoiding misleading conclusions from single-scale evaluations.", "method": "Derives full scaling laws for CLIP and MaMMUT using dense measurements across model and sample scales, and evaluates them on tasks like classification, retrieval, and segmentation.", "result": "MaMMUT shows stronger improvement with scale and better sample efficiency than CLIP, consistently across tasks and datasets.", "conclusion": "Scaling laws provide a robust method for model and dataset comparison, facilitating systematic improvement of foundation models. Open-sourced models and code support reproducibility."}}
{"id": "2506.04608", "pdf": "https://arxiv.org/pdf/2506.04608", "abs": "https://arxiv.org/abs/2506.04608", "authors": ["Changsheng Sun", "Xinke Li", "Jin Song Dong"], "title": "Ignoring Directionality Leads to Compromised Graph Neural Network Explanations", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) are increasingly used in critical domains, where\nreliable explanations are vital for supporting human decision-making. However,\nthe common practice of graph symmetrization discards directional information,\nleading to significant information loss and misleading explanations. Our\nanalysis demonstrates how this practice compromises explanation fidelity.\nThrough theoretical and empirical studies, we show that preserving directional\nsemantics significantly improves explanation quality, ensuring more faithful\ninsights for human decision-makers. These findings highlight the need for\ndirection-aware GNN explainability in security-critical applications.", "AI": {"tldr": "Direction-aware GNN explainability improves fidelity by preserving directional semantics, unlike symmetrization which misleads.", "motivation": "Reliable explanations are crucial for GNNs in critical domains, but symmetrization loses directional info, compromising fidelity.", "method": "Theoretical and empirical studies on preserving directional semantics in GNNs.", "result": "Direction-aware methods significantly enhance explanation quality and faithfulness.", "conclusion": "Direction-aware GNN explainability is essential, especially for security-critical applications."}}
{"id": "2506.04609", "pdf": "https://arxiv.org/pdf/2506.04609", "abs": "https://arxiv.org/abs/2506.04609", "authors": ["Cong Geng", "Jia Wang", "Li Chen", "Zhiyong Gao", "Jes Frellsen", "S\u00f8ren Hauberg"], "title": "Exploring bidirectional bounds for minimax-training of Energy-based models", "categories": ["cs.LG", "cs.CV"], "comment": "accepted to IJCV", "summary": "Energy-based models (EBMs) estimate unnormalized densities in an elegant\nframework, but they are generally difficult to train. Recent work has linked\nEBMs to generative adversarial networks, by noting that they can be trained\nthrough a minimax game using a variational lower bound. To avoid the\ninstabilities caused by minimizing a lower bound, we propose to instead work\nwith bidirectional bounds, meaning that we maximize a lower bound and minimize\nan upper bound when training the EBM. We investigate four different bounds on\nthe log-likelihood derived from different perspectives. We derive lower bounds\nbased on the singular values of the generator Jacobian and on mutual\ninformation. To upper bound the negative log-likelihood, we consider a gradient\npenalty-like bound, as well as one based on diffusion processes. In all cases,\nwe provide algorithms for evaluating the bounds. We compare the different\nbounds to investigate, the pros and cons of the different approaches. Finally,\nwe demonstrate that the use of bidirectional bounds stabilizes EBM training and\nyields high-quality density estimation and sample generation.", "AI": {"tldr": "The paper proposes bidirectional bounds for training energy-based models (EBMs) to stabilize training and improve performance, comparing four bounds derived from different perspectives.", "motivation": "EBMs are difficult to train, and recent work linking them to GANs introduced instability. The authors aim to stabilize EBM training by using bidirectional bounds.", "method": "The authors propose maximizing a lower bound and minimizing an upper bound for EBM training. They derive four bounds: two lower bounds (based on generator Jacobian singular values and mutual information) and two upper bounds (gradient penalty-like and diffusion process-based).", "result": "Bidirectional bounds stabilize EBM training, leading to high-quality density estimation and sample generation.", "conclusion": "Using bidirectional bounds is effective for stabilizing EBM training and improving performance, with trade-offs between the bounds explored."}}
{"id": "2506.04632", "pdf": "https://arxiv.org/pdf/2506.04632", "abs": "https://arxiv.org/abs/2506.04632", "authors": ["Guruprerana Shabadi", "Rajeev Alur"], "title": "Composing Agents to Minimize Worst-case Risk", "categories": ["cs.LG"], "comment": "17 pages, 4 figures", "summary": "From software development to robot control, modern agentic systems decompose\ncomplex objectives into a sequence of subtasks and choose a set of specialized\nAI agents to complete them. We formalize an agentic workflow as a directed\nacyclic graph, called an agent graph, where edges represent AI agents and paths\ncorrespond to feasible compositions of agents. When deploying these systems in\nthe real world, we need to choose compositions of agents that not only maximize\nthe task success, but also minimize risk where the risk captures requirements\nlike safety, fairness, and privacy. This additionally requires carefully\nanalyzing the low-probability (tail) behaviors of compositions of agents. In\nthis work, we consider worst-case risk minimization over the set of feasible\nagent compositions. We define worst-case risk as the tail quantile -- also\nknown as value-at-risk -- of the loss distribution of the agent composition\nwhere the loss quantifies the risk associated with agent behaviors. We\nintroduce an efficient algorithm that traverses the agent graph and finds a\nnear-optimal composition of agents by approximating the value-at-risk via a\nunion bound and dynamic programming. Furthermore, we prove that the\napproximation is near-optimal asymptotically for a broad class of practical\nloss functions. To evaluate our framework, we consider a suite of video\ngame-like control benchmarks that require composing several agents trained with\nreinforcement learning and demonstrate our algorithm's effectiveness in\napproximating the value-at-risk and identifying the optimal agent composition.", "AI": {"tldr": "The paper formalizes agentic workflows as directed acyclic graphs (agent graphs) and introduces an algorithm to optimize agent compositions for task success and risk minimization, focusing on worst-case risk (value-at-risk).", "motivation": "Modern agentic systems decompose tasks into subtasks handled by specialized AI agents, requiring risk-aware compositions to ensure safety, fairness, and privacy.", "method": "The work defines worst-case risk as value-at-risk, proposes an efficient algorithm using union bounds and dynamic programming to approximate it, and proves asymptotic near-optimality for practical loss functions.", "result": "The algorithm is evaluated on control benchmarks with reinforcement learning agents, showing effectiveness in approximating value-at-risk and identifying optimal compositions.", "conclusion": "The framework successfully balances task success and risk minimization, providing a practical solution for deploying agentic systems in real-world scenarios."}}
{"id": "2506.04645", "pdf": "https://arxiv.org/pdf/2506.04645", "abs": "https://arxiv.org/abs/2506.04645", "authors": ["Ege Erdil"], "title": "Inference economics of language models", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "We develop a theoretical model that addresses the economic trade-off between\ncost per token versus serial token generation speed when deploying LLMs for\ninference at scale. Our model takes into account arithmetic, memory bandwidth,\nnetwork bandwidth and latency constraints; and optimizes over different\nparallelism setups and batch sizes to find the ones that optimize serial\ninference speed at a given cost per token. We use the model to compute Pareto\nfrontiers of serial speed versus cost per token for popular language models.", "AI": {"tldr": "The paper presents a theoretical model optimizing the trade-off between cost per token and serial token generation speed for LLM inference, considering hardware constraints and parallelism setups.", "motivation": "To address the economic and efficiency challenges of deploying large language models (LLMs) at scale by balancing cost and speed.", "method": "Develops a theoretical model incorporating arithmetic, memory bandwidth, network bandwidth, and latency constraints, optimizing parallelism setups and batch sizes.", "result": "Computes Pareto frontiers of serial speed versus cost per token for popular language models.", "conclusion": "The model provides a framework to optimize LLM deployment by balancing cost and performance."}}
{"id": "2506.04650", "pdf": "https://arxiv.org/pdf/2506.04650", "abs": "https://arxiv.org/abs/2506.04650", "authors": ["Zesheng Ye", "Chengyi Cai", "Ruijiang Dong", "Jianzhong Qi", "Lei Feng", "Pin-Yu Chen", "Feng Liu"], "title": "Neural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction", "categories": ["cs.LG"], "comment": null, "summary": "As large-scale pre-trained foundation models continue to expand in size and\ncapability, efficiently adapting them to specific downstream tasks has become\nincreasingly critical. Despite substantial progress, existing adaptation\napproaches have evolved largely in isolation, without a clear understanding of\ntheir interrelationships. This survey introduces neural network\nreprogrammability as a unifying framework that bridges mainstream model\nadaptation techniques--model reprogramming, prompt tuning, and prompt\ninstruction--previously fragmented research areas yet converges on a shared\nprinciple: repurposing a pre-trained model by manipulating information at the\ninterfaces while keeping the model parameters frozen. These methods exploit\nneural networks' sensitivity to manipulation on different interfaces, be it\nthrough perturbing inputs, inserting tokens into intermediate layers, or\nproviding task-specific examples in context, to redirect model behaviors\ntowards desired outcomes. We then present a taxonomy that categorizes such\ninformation manipulation-based adaptation approaches across four key\ndimensions: manipulation format (fixed or learnable), location (interfaces\nwhere manipulations occur), operator (how they are applied), and output\nalignment requirement (post-processing needed to align outputs with downstream\ntasks). Notably, this framework applies consistently across data modalities,\nindependent of specific model architectures. Moreover, viewing established\ntechniques like in-context learning and chain-of-thought prompting through this\nlens reveals both their theoretical connections and practical distinctions. We\nfurther analyze remaining technical challenges and ethical considerations,\npositioning neural network reprogrammability as a fundamental paradigm for\nefficient model adaptation. We lastly identify promising research directions\nemerging from this integrative viewpoint.", "AI": {"tldr": "The paper introduces neural network reprogrammability as a unifying framework for adapting pre-trained models, categorizing methods by manipulation format, location, operator, and output alignment.", "motivation": "To bridge fragmented research areas like model reprogramming, prompt tuning, and prompt instruction by understanding their shared principle of manipulating model interfaces without altering parameters.", "method": "Proposes a taxonomy for adaptation approaches based on four dimensions: manipulation format, location, operator, and output alignment.", "result": "The framework consistently applies across data modalities and model architectures, revealing connections between techniques like in-context learning and chain-of-thought prompting.", "conclusion": "Neural network reprogrammability is a fundamental paradigm for efficient model adaptation, with identified challenges and promising research directions."}}
{"id": "2506.04653", "pdf": "https://arxiv.org/pdf/2506.04653", "abs": "https://arxiv.org/abs/2506.04653", "authors": ["MoonJeong Park", "Sunghyun Choi", "Jaeseung Heo", "Eunhyeok Park", "Dongwoo Kim"], "title": "The Oversmoothing Fallacy: A Misguided Narrative in GNN Research", "categories": ["cs.LG"], "comment": null, "summary": "Oversmoothing has been recognized as a main obstacle to building deep Graph\nNeural Networks (GNNs), limiting the performance. This position paper argues\nthat the influence of oversmoothing has been overstated and advocates for a\nfurther exploration of deep GNN architectures. Given the three core operations\nof GNNs, aggregation, linear transformation, and non-linear activation, we show\nthat prior studies have mistakenly confused oversmoothing with the vanishing\ngradient, caused by transformation and activation rather than aggregation. Our\nfinding challenges prior beliefs about oversmoothing being unique to GNNs.\nFurthermore, we demonstrate that classical solutions such as skip connections\nand normalization enable the successful stacking of deep GNN layers without\nperformance degradation. Our results clarify misconceptions about oversmoothing\nand shed new light on the potential of deep GNNs.", "AI": {"tldr": "The paper challenges the overstated impact of oversmoothing in deep GNNs, attributing performance issues to vanishing gradients from transformation and activation, not aggregation. It shows deep GNNs can work with classical solutions like skip connections.", "motivation": "To correct misconceptions about oversmoothing in GNNs and advocate for deeper architectures by clarifying the root causes of performance issues.", "method": "Analyzes GNN core operations (aggregation, transformation, activation) and tests classical solutions (skip connections, normalization) in deep GNNs.", "result": "Demonstrates that oversmoothing is conflated with vanishing gradients, and deep GNNs can perform well with proper techniques.", "conclusion": "Oversmoothing's impact is overstated; deep GNNs are viable with classical solutions, opening new research directions."}}
{"id": "2506.04669", "pdf": "https://arxiv.org/pdf/2506.04669", "abs": "https://arxiv.org/abs/2506.04669", "authors": ["Wanfu Gao", "Hanlin Pan", "Qingqi Han", "Kunpeng Liu"], "title": "Noise-Resistant Label Reconstruction Feature Selection for Partial Multi-Label Learning", "categories": ["cs.LG"], "comment": "accept in ijcai25", "summary": "The \"Curse of dimensionality\" is prevalent across various data patterns,\nwhich increases the risk of model overfitting and leads to a decline in model\nclassification performance. However, few studies have focused on this issue in\nPartial Multi-label Learning (PML), where each sample is associated with a set\nof candidate labels, at least one of which is correct. Existing PML methods\naddressing this problem are mainly based on the low-rank assumption. However,\nlow-rank assumption is difficult to be satisfied in practical situations and\nmay lead to loss of high-dimensional information. Furthermore, we find that\nexisting methods have poor ability to identify positive labels, which is\nimportant in real-world scenarios. In this paper, a PML feature selection\nmethod is proposed considering two important characteristics of dataset: label\nrelationship's noise-resistance and label connectivity. Our proposed method\nutilizes label relationship's noise-resistance to disambiguate labels. Then the\nlearning process is designed through the reformed low-rank assumption. Finally,\nrepresentative labels are found through label connectivity, and the weight\nmatrix is reconstructed to select features with strong identification ability\nto these labels. The experimental results on benchmark datasets demonstrate the\nsuperiority of the proposed method.", "AI": {"tldr": "A new Partial Multi-label Learning (PML) feature selection method addresses the 'Curse of dimensionality' by leveraging label noise-resistance and connectivity, improving label disambiguation and feature selection.", "motivation": "Existing PML methods struggle with high-dimensional data, low-rank assumptions, and poor positive label identification, necessitating a more robust approach.", "method": "The proposed method uses label noise-resistance for disambiguation, a reformed low-rank assumption for learning, and label connectivity for feature selection.", "result": "Experiments on benchmark datasets show the method outperforms existing approaches.", "conclusion": "The method effectively mitigates dimensionality issues and enhances label identification in PML."}}
{"id": "2506.04672", "pdf": "https://arxiv.org/pdf/2506.04672", "abs": "https://arxiv.org/abs/2506.04672", "authors": ["Shengkun Zhu", "Feiteng Nie", "Jinshan Zeng", "Sheng Wang", "Yuan Sun", "Yuan Yao", "Shangfeng Chen", "Quanqing Xu", "Chuanhui Yang"], "title": "FedAPM: Federated Learning via ADMM with Partial Model Personalization", "categories": ["cs.LG"], "comment": null, "summary": "In federated learning (FL), the assumption that datasets from different\ndevices are independent and identically distributed (i.i.d.) often does not\nhold due to user differences, and the presence of various data modalities\nacross clients makes using a single model impractical. Personalizing certain\nparts of the model can effectively address these issues by allowing those parts\nto differ across clients, while the remaining parts serve as a shared model.\nHowever, we found that partial model personalization may exacerbate client\ndrift (each client's local model diverges from the shared model), thereby\nreducing the effectiveness and efficiency of FL algorithms. We propose an FL\nframework based on the alternating direction method of multipliers (ADMM),\nreferred to as FedAPM, to mitigate client drift. We construct the augmented\nLagrangian function by incorporating first-order and second-order proximal\nterms into the objective, with the second-order term providing fixed correction\nand the first-order term offering compensatory correction between the local and\nshared models. Our analysis demonstrates that FedAPM, by using explicit\nestimates of the Lagrange multiplier, is more stable and efficient in terms of\nconvergence compared to other FL frameworks. We establish the global\nconvergence of FedAPM training from arbitrary initial points to a stationary\npoint, achieving three types of rates: constant, linear, and sublinear, under\nmild assumptions. We conduct experiments using four heterogeneous and\nmultimodal datasets with different metrics to validate the performance of\nFedAPM. Specifically, FedAPM achieves faster and more accurate convergence,\noutperforming the SOTA methods with average improvements of 12.3% in test\naccuracy, 16.4% in F1 score, and 18.0% in AUC while requiring fewer\ncommunication rounds.", "AI": {"tldr": "FedAPM, an FL framework using ADMM, mitigates client drift by combining first- and second-order proximal terms, achieving stable convergence and outperforming SOTA methods in accuracy and efficiency.", "motivation": "In FL, non-i.i.d. data and multimodal inputs make single-model approaches impractical, and partial personalization worsens client drift. FedAPM addresses these issues.", "method": "FedAPM uses ADMM with augmented Lagrangian, incorporating first- and second-order proximal terms for correction between local and shared models.", "result": "FedAPM achieves faster, more accurate convergence, with 12.3% higher test accuracy, 16.4% better F1 score, and 18.0% higher AUC than SOTA methods, using fewer communication rounds.", "conclusion": "FedAPM effectively mitigates client drift, improves FL performance, and demonstrates global convergence under mild assumptions."}}
{"id": "2506.04677", "pdf": "https://arxiv.org/pdf/2506.04677", "abs": "https://arxiv.org/abs/2506.04677", "authors": ["Marco Zanotti"], "title": "The cost of ensembling: is it always worth combining?", "categories": ["cs.LG", "stat.AP", "stat.OT"], "comment": null, "summary": "Given the continuous increase in dataset sizes and the complexity of\nforecasting models, the trade-off between forecast accuracy and computational\ncost is emerging as an extremely relevant topic, especially in the context of\nensemble learning for time series forecasting. To asses it, we evaluated ten\nbase models and eight ensemble configurations across two large-scale retail\ndatasets (M5 and VN1), considering both point and probabilistic accuracy under\nvarying retraining frequencies. We showed that ensembles consistently improve\nforecasting performance, particularly in probabilistic settings. However, these\ngains come at a substantial computational cost, especially for larger,\naccuracy-driven ensembles. We found that reducing retraining frequency\nsignificantly lowers costs, with minimal impact on accuracy, particularly for\npoint forecasts. Moreover, efficiency-driven ensembles offer a strong balance,\nachieving competitive accuracy with considerably lower costs compared to\naccuracy-optimized combinations. Most importantly, small ensembles of two or\nthree models are often sufficient to achieve near-optimal results. These\nfindings provide practical guidelines for deploying scalable and cost-efficient\nforecasting systems, supporting the broader goals of sustainable AI in\nforecasting. Overall, this work shows that careful ensemble design and\nretraining strategy selection can yield accurate, robust, and cost-effective\nforecasts suitable for real-world applications.", "AI": {"tldr": "Ensembles improve forecasting accuracy but increase computational costs. Reducing retraining frequency lowers costs with minimal accuracy loss. Small ensembles (2-3 models) often suffice for near-optimal results.", "motivation": "Address the trade-off between forecast accuracy and computational cost in ensemble learning for time series forecasting.", "method": "Evaluated ten base models and eight ensemble configurations on M5 and VN1 datasets, considering point and probabilistic accuracy under varying retraining frequencies.", "result": "Ensembles boost performance, especially probabilistically, but at high computational cost. Efficiency-driven ensembles balance accuracy and cost.", "conclusion": "Careful ensemble design and retraining strategies enable accurate, robust, and cost-effective forecasts, supporting sustainable AI in forecasting."}}
{"id": "2506.04681", "pdf": "https://arxiv.org/pdf/2506.04681", "abs": "https://arxiv.org/abs/2506.04681", "authors": ["Daogao Liu", "Edith Cohen", "Badih Ghazi", "Peter Kairouz", "Pritish Kamath", "Alexander Knop", "Ravi Kumar", "Pasin Manurangsi", "Adam Sealfon", "Da Yu", "Chiyuan Zhang"], "title": "Urania: Differentially Private Insights into AI Use", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "cs.CY"], "comment": null, "summary": "We introduce $Urania$, a novel framework for generating insights about LLM\nchatbot interactions with rigorous differential privacy (DP) guarantees. The\nframework employs a private clustering mechanism and innovative keyword\nextraction methods, including frequency-based, TF-IDF-based, and LLM-guided\napproaches. By leveraging DP tools such as clustering, partition selection, and\nhistogram-based summarization, $Urania$ provides end-to-end privacy protection.\nOur evaluation assesses lexical and semantic content preservation, pair\nsimilarity, and LLM-based metrics, benchmarking against a non-private\nClio-inspired pipeline (Tamkin et al., 2024). Moreover, we develop a simple\nempirical privacy evaluation that demonstrates the enhanced robustness of our\nDP pipeline. The results show the framework's ability to extract meaningful\nconversational insights while maintaining stringent user privacy, effectively\nbalancing data utility with privacy preservation.", "AI": {"tldr": "$Urania$ is a privacy-focused framework for analyzing LLM chatbot interactions using differential privacy (DP) techniques, ensuring meaningful insights while protecting user data.", "motivation": "To address the need for extracting conversational insights from LLM chatbots without compromising user privacy, ensuring rigorous DP guarantees.", "method": "Employs private clustering, keyword extraction (frequency-based, TF-IDF-based, LLM-guided), and DP tools like clustering, partition selection, and histogram-based summarization.", "result": "Demonstrates effective extraction of conversational insights with strong privacy protection, outperforming non-private benchmarks.", "conclusion": "$Urania$ successfully balances data utility and privacy, offering a robust solution for private LLM interaction analysis."}}
{"id": "2506.04690", "pdf": "https://arxiv.org/pdf/2506.04690", "abs": "https://arxiv.org/abs/2506.04690", "authors": ["Yifan Hao", "Yanxin Lu", "Xinwei Shen", "Tong Zhang"], "title": "Towards Better Generalization via Distributional Input Projection Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As overparameterized models become increasingly prevalent, training loss\nalone offers limited insight into generalization performance. While smoothness\nhas been linked to improved generalization across various settings, directly\nenforcing smoothness in neural networks remains challenging. To address this,\nwe introduce Distributional Input Projection Networks (DIPNet), a novel\nframework that projects inputs into learnable distributions at each layer. This\ndistributional representation induces a smoother loss landscape with respect to\nthe input, promoting better generalization. We provide theoretical analysis\nshowing that DIPNet reduces both local smoothness measures and the Lipschitz\nconstant of the network, contributing to improved generalization performance.\nEmpirically, we validate DIPNet across a wide range of architectures and tasks,\nincluding Vision Transformers (ViTs), Large Language Models (LLMs), ResNet and\nMLPs. Our method consistently enhances test performance under standard\nsettings, adversarial attacks, out-of-distribution inputs, and reasoning\nbenchmarks. We demonstrate that the proposed input projection strategy can be\nseamlessly integrated into existing models, providing a general and effective\napproach for boosting generalization performance in modern deep learning.", "AI": {"tldr": "DIPNet introduces a framework to project inputs into learnable distributions, smoothing the loss landscape and improving generalization in neural networks.", "motivation": "Training loss alone is insufficient for assessing generalization in overparameterized models, and enforcing smoothness directly is challenging.", "method": "DIPNet projects inputs into learnable distributions at each layer, inducing a smoother loss landscape and reducing local smoothness measures and Lipschitz constants.", "result": "Empirical validation shows improved test performance across architectures (ViTs, LLMs, ResNet, MLPs) and scenarios (standard, adversarial, out-of-distribution, reasoning).", "conclusion": "DIPNet is a general, effective approach for enhancing generalization in modern deep learning, easily integrated into existing models."}}
{"id": "2506.04694", "pdf": "https://arxiv.org/pdf/2506.04694", "abs": "https://arxiv.org/abs/2506.04694", "authors": ["Jaeseung Heo", "Kyeongheung Yun", "Seokwon Yoon", "MoonJeong Park", "Jungseul Ok", "Dongwoo Kim"], "title": "Influence Functions for Edge Edits in Non-Convex Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Understanding how individual edges influence the behavior of graph neural\nnetworks (GNNs) is essential for improving their interpretability and\nrobustness. Graph influence functions have emerged as promising tools to\nefficiently estimate the effects of edge deletions without retraining. However,\nexisting influence prediction methods rely on strict convexity assumptions,\nexclusively consider the influence of edge deletions while disregarding edge\ninsertions, and fail to capture changes in message propagation caused by these\nmodifications. In this work, we propose a proximal Bregman response function\nspecifically tailored for GNNs, relaxing the convexity requirement and enabling\naccurate influence prediction for standard neural network architectures.\nFurthermore, our method explicitly accounts for message propagation effects and\nextends influence prediction to both edge deletions and insertions in a\nprincipled way. Experiments with real-world datasets demonstrate accurate\ninfluence predictions for different characteristics of GNNs. We further\ndemonstrate that the influence function is versatile in applications such as\ngraph rewiring and adversarial attacks.", "AI": {"tldr": "The paper introduces a proximal Bregman response function for GNNs to predict edge influence, relaxing convexity assumptions and addressing message propagation effects for deletions and insertions.", "motivation": "To improve GNN interpretability and robustness by accurately predicting edge influence without retraining, addressing limitations of existing methods.", "method": "Proposes a proximal Bregman response function tailored for GNNs, relaxing convexity and capturing message propagation effects for edge deletions and insertions.", "result": "Demonstrates accurate influence predictions on real-world datasets and versatility in applications like graph rewiring and adversarial attacks.", "conclusion": "The method enhances GNN interpretability and robustness by providing a principled way to predict edge influence, applicable to various GNN characteristics and tasks."}}
{"id": "2506.04695", "pdf": "https://arxiv.org/pdf/2506.04695", "abs": "https://arxiv.org/abs/2506.04695", "authors": ["Xingwu Chen", "Tianle Li", "Difan Zou"], "title": "On the Mechanism of Reasoning Pattern Selection in Reinforcement Learning for Language Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "30 pages, 6 figures, 1 table", "summary": "Reinforcement learning (RL) has demonstrated remarkable success in enhancing\nmodel capabilities, including instruction-following, preference learning, and\nreasoning. Yet despite its empirical successes, the mechanisms by which RL\nimproves reasoning abilities remain poorly understood. We present a systematic\nstudy of Reinforcement Learning with Verifiable Rewards (RLVR), showing that\nits primary benefit comes from optimizing the selection of existing reasoning\npatterns. Through extensive experiments, we demonstrate that RLVR-trained\nmodels preferentially adopt high-success-rate reasoning patterns while mostly\nmaintaining stable performance on individual patterns. We further develop\ntheoretical analyses on the convergence and training dynamics of RLVR based on\na simplified question-reason-answer model. We study the gradient flow and show\nthat RLVR can indeed find the solution that selects the reason pattern with the\nhighest success rate. Besides, our theoretical results\n  reveal two distinct regimes regarding the convergence of RLVR training: (1)\nrapid convergence for models with relatively strong initial reasoning\ncapabilities versus (2) slower optimization dynamics for weaker models.\nFurthermore, we show that the slower optimization for weaker models can be\nmitigated by applying the supervised fine-tuning (SFT) before RLVR, when using\na feasibly high-quality SFT dataset. We validate the theoretical findings\nthrough extensive experiments. This work advances our theoretical understanding\nof RL's role in LLM fine-tuning and offers insights for further enhancing\nreasoning capabilities.", "AI": {"tldr": "RLVR optimizes reasoning pattern selection, favoring high-success-rate patterns while maintaining stability. Theoretical analysis confirms convergence, with faster results for stronger models and slower for weaker ones, mitigated by SFT.", "motivation": "To understand how RL improves reasoning abilities in models, focusing on RLVR's mechanisms.", "method": "Systematic study of RLVR, theoretical analysis of convergence and training dynamics, and validation through experiments.", "result": "RLVR selects high-success-rate reasoning patterns, with convergence speed dependent on initial model strength. SFT can mitigate slower optimization in weaker models.", "conclusion": "RLVR enhances reasoning by optimizing pattern selection, with theoretical and empirical support, offering insights for improving LLM fine-tuning."}}
{"id": "2506.04696", "pdf": "https://arxiv.org/pdf/2506.04696", "abs": "https://arxiv.org/abs/2506.04696", "authors": ["Tonmoy Paul", "Mrittika Devi Mati", "Md. Mahmudul Islam"], "title": "Enhanced Drought Analysis in Bangladesh: A Machine Learning Approach for Severity Classification Using Satellite Data", "categories": ["cs.LG"], "comment": null, "summary": "Drought poses a pervasive environmental challenge in Bangladesh, impacting\nagriculture, socio-economic stability, and food security due to its unique\ngeographic and anthropogenic vulnerabilities. Traditional drought indices, such\nas the Standardized Precipitation Index (SPI) and Palmer Drought Severity Index\n(PDSI), often overlook crucial factors like soil moisture and temperature,\nlimiting their resolution. Moreover, current machine learning models applied to\ndrought prediction have been underexplored in the context of Bangladesh,\nlacking a comprehensive integration of satellite data across multiple\ndistricts. To address these gaps, we propose a satellite data-driven machine\nlearning framework to classify drought across 38 districts of Bangladesh. Using\nunsupervised algorithms like K-means and Bayesian Gaussian Mixture for\nclustering, followed by classification models such as KNN, Random Forest,\nDecision Tree, and Naive Bayes, the framework integrates weather data\n(humidity, soil moisture, temperature) from 2012-2024. This approach\nsuccessfully classifies drought severity into different levels. However, it\nshows significant variabilities in drought vulnerabilities across regions which\nhighlights the aptitude of machine learning models in terms of identifying and\npredicting drought conditions.", "AI": {"tldr": "A machine learning framework using satellite data is proposed to classify drought severity in Bangladesh, addressing gaps in traditional indices and regional ML applications.", "motivation": "Drought in Bangladesh affects agriculture and food security, but traditional indices like SPI and PDSI miss key factors, and ML models lack comprehensive regional integration.", "method": "The framework uses unsupervised algorithms (K-means, Bayesian Gaussian Mixture) for clustering and classification models (KNN, Random Forest, Decision Tree, Naive Bayes) with weather data (2012-2024).", "result": "The model successfully classifies drought severity but reveals regional variability in vulnerabilities.", "conclusion": "Machine learning effectively identifies and predicts drought conditions, highlighting regional differences."}}
{"id": "2506.04700", "pdf": "https://arxiv.org/pdf/2506.04700", "abs": "https://arxiv.org/abs/2506.04700", "authors": ["Jos\u00e9 Manuel de Frutos", "Manuel A. V\u00e1zquez", "Pablo M. Olmos", "Joaqu\u00edn M\u00edguez"], "title": "Explicit Density Approximation for Neural Implicit Samplers Using a Bernstein-Based Convex Divergence", "categories": ["cs.LG", "cs.AI", "math.PR", "stat.ML"], "comment": null, "summary": "Rank-based statistical metrics, such as the invariant statistical loss (ISL),\nhave recently emerged as robust and practically effective tools for training\nimplicit generative models. In this work, we introduce dual-ISL, a novel\nlikelihood-free objective for training implicit generative models that\ninterchanges the roles of the target and model distributions in the ISL\nframework, yielding a convex optimization problem in the space of model\ndensities. We prove that the resulting rank-based discrepancy $d_K$ is i)\ncontinuous under weak convergence and with respect to the $L^1$ norm, and ii)\nconvex in its first argument-properties not shared by classical divergences\nsuch as KL or Wasserstein distances. Building on this, we develop a theoretical\nframework that interprets $d_K$ as an $L^2$-projection of the density ratio $q\n= p/\\tilde p$ onto a Bernstein polynomial basis, from which we derive exact\nbounds on the truncation error, precise convergence rates, and a closed-form\nexpression for the truncated density approximation. We further extend our\nanalysis to the multivariate setting via random one-dimensional projections,\ndefining a sliced dual-ISL divergence that retains both convexity and\ncontinuity. We empirically show that these theoretical advantages translate\ninto practical ones. Specifically, across several benchmarks dual-ISL converges\nmore rapidly, delivers markedly smoother and more stable training, and more\neffectively prevents mode collapse than classical ISL and other leading\nimplicit generative methods-while also providing an explicit density\napproximation.", "AI": {"tldr": "The paper introduces dual-ISL, a likelihood-free objective for training implicit generative models, offering convexity and continuity advantages over classical divergences like KL or Wasserstein distances. It provides theoretical guarantees, empirical benefits, and extends to multivariate settings.", "motivation": "To address limitations of classical divergences (e.g., lack of convexity or continuity) in training implicit generative models, the authors propose dual-ISL, a rank-based metric with better theoretical and practical properties.", "method": "The method interchanges target and model distributions in the ISL framework, yielding a convex optimization problem. It analyzes the rank-based discrepancy $d_K$, proves its properties, and extends it to multivariate settings via random projections.", "result": "Dual-ISL shows faster convergence, smoother training, better mode collapse prevention, and provides explicit density approximations compared to classical ISL and other methods.", "conclusion": "Dual-ISL is a robust and effective tool for training implicit generative models, with theoretical and empirical advantages over existing approaches."}}
{"id": "2506.04712", "pdf": "https://arxiv.org/pdf/2506.04712", "abs": "https://arxiv.org/abs/2506.04712", "authors": ["Pinak Mandal", "Georg A. Gottwald"], "title": "UNO: Unlearning via Orthogonalization in Generative models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As generative models become increasingly powerful and pervasive, the ability\nto unlearn specific data, whether due to privacy concerns, legal requirements,\nor the correction of harmful content, has become increasingly important. Unlike\nin conventional training, where data are accumulated and knowledge is\nreinforced, unlearning aims to selectively remove the influence of particular\ndata points without costly retraining from scratch. To be effective and\nreliable, such algorithms need to achieve (i) forgetting of the undesired data,\n(ii) preservation of the quality of the generation, (iii) preservation of the\ninfluence of the desired training data on the model parameters, and (iv) small\nnumber of training steps. We propose fast unlearning algorithms based on loss\ngradient orthogonalization. We show that our algorithms are able to forget data\nwhile maintaining the fidelity of the original model. Using MNIST and CelebA\ndata, we demonstrate that our algorithms achieve orders of magnitude faster\nunlearning times than their predecessors, such as gradient surgery.", "AI": {"tldr": "The paper introduces fast unlearning algorithms for generative models to selectively remove data influence without full retraining, ensuring efficiency and model fidelity.", "motivation": "Addressing the need to unlearn specific data in generative models due to privacy, legal, or harmful content concerns without costly retraining.", "method": "Proposes unlearning algorithms based on loss gradient orthogonalization to efficiently remove undesired data influence.", "result": "Demonstrates significantly faster unlearning times compared to predecessors like gradient surgery, while maintaining model quality.", "conclusion": "The proposed algorithms effectively balance forgetting undesired data, preserving model performance, and minimizing training steps."}}
{"id": "2506.04746", "pdf": "https://arxiv.org/pdf/2506.04746", "abs": "https://arxiv.org/abs/2506.04746", "authors": ["Fei Ding", "Baiqiao Wang", "Zijian Zeng", "Youwei Wang"], "title": "Multi-Layer GRPO: Enhancing Reasoning and Self-Correction in Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "The Group Relative Policy Optimization (GRPO) algorithm has demonstrated\nconsiderable success in enhancing the reasoning capabilities of large language\nmodels (LLMs), as evidenced by DeepSeek-R1. However, the absence of\nintermediate supervision in GRPO frequently leads to inefficient exploration\ndynamics. A single error in a complex reasoning chain can invalidate the entire\nsolution, resulting in abrupt reward vanishing and compromising training\nstability.To address these challenges, we propose MGRPO (Multi-layer GRPO).\nMGRPO operates in two layers: the first layer employs standard GRPO to generate\nan initial response. This response, along with the original query, is then fed\ninto a second-layer GRPO process. This second layer is specifically trained to\nidentify and correct errors in the initial response, effectively creating a\nself-correction loop. This mechanism provides implicit process-level\nsupervision by rewarding successful error correction, without requiring an\nexplicit, densely-annotated reward model. Experimental results on several\nmathematical reasoning benchmarks demonstrate that MGRPO significantly\noutperforms standard GRPO, achieving superior performance by fostering both\nreasoning and self-correction abilities.", "AI": {"tldr": "MGRPO improves GRPO by adding a self-correction layer to fix errors in initial responses, enhancing reasoning and training stability.", "motivation": "GRPO lacks intermediate supervision, causing inefficient exploration and reward vanishing in complex reasoning tasks.", "method": "MGRPO uses two GRPO layers: the first generates an initial response, and the second corrects errors in it, forming a self-correction loop.", "result": "MGRPO outperforms GRPO on mathematical reasoning benchmarks by improving reasoning and self-correction.", "conclusion": "MGRPO's self-correction mechanism provides implicit supervision, boosting performance without dense reward annotations."}}
{"id": "2506.04761", "pdf": "https://arxiv.org/pdf/2506.04761", "abs": "https://arxiv.org/abs/2506.04761", "authors": ["Han Guo", "Songlin Yang", "Tarushii Goel", "Eric P. Xing", "Tri Dao", "Yoon Kim"], "title": "Log-Linear Attention", "categories": ["cs.LG"], "comment": null, "summary": "The attention mechanism in Transformers is an important primitive for\naccurate and scalable sequence modeling. Its quadratic-compute and\nlinear-memory complexity however remain significant bottlenecks. Linear\nattention and state-space models enable linear-time, constant-memory sequence\nmodeling and can moreover be trained efficiently through matmul-rich\nparallelization across sequence length. However, at their core these models are\nstill RNNs, and thus their use of a fixed-size hidden state to model the\ncontext is a fundamental limitation. This paper develops log-linear attention,\nan attention mechanism that balances linear attention's efficiency and the\nexpressiveness of softmax attention. Log-linear attention replaces the\nfixed-size hidden state with a logarithmically growing set of hidden states. We\nshow that with a particular growth function, log-linear attention admits a\nsimilarly matmul-rich parallel form whose compute cost is log-linear in\nsequence length. Log-linear attention is a general framework and can be applied\non top of existing linear attention variants. As case studies, we instantiate\nlog-linear variants of two recent architectures -- Mamba-2 and Gated DeltaNet\n-- and find they perform well compared to their linear-time variants.", "AI": {"tldr": "Log-linear attention balances efficiency and expressiveness by replacing fixed-size hidden states with logarithmically growing ones, enabling log-linear compute cost.", "motivation": "Address the limitations of quadratic-compute in Transformers and fixed-size hidden states in linear attention and state-space models.", "method": "Develops log-linear attention, a mechanism with logarithmically growing hidden states, and applies it to existing architectures like Mamba-2 and Gated DeltaNet.", "result": "Log-linear attention variants perform well compared to linear-time models, maintaining efficiency and expressiveness.", "conclusion": "Log-linear attention offers a scalable and efficient alternative to traditional attention mechanisms, enhancing sequence modeling."}}
{"id": "2506.04765", "pdf": "https://arxiv.org/pdf/2506.04765", "abs": "https://arxiv.org/abs/2506.04765", "authors": ["Jiachen Tang", "Zhonghao Wang", "Sirui Chen", "Sheng Zhou", "Jiawei Chen", "Jiajun Bu"], "title": "OpenGT: A Comprehensive Benchmark For Graph Transformers", "categories": ["cs.LG"], "comment": "14 pages, 5 figures", "summary": "Graph Transformers (GTs) have recently demonstrated remarkable performance\nacross diverse domains. By leveraging attention mechanisms, GTs are capable of\nmodeling long-range dependencies and complex structural relationships beyond\nlocal neighborhoods. However, their applicable scenarios are still\nunderexplored, this highlights the need to identify when and why they excel.\nFurthermore, unlike GNNs, which predominantly rely on message-passing\nmechanisms, GTs exhibit a diverse design space in areas such as positional\nencoding, attention mechanisms, and graph-specific adaptations. Yet, it remains\nunclear which of these design choices are truly effective and under what\nconditions. As a result, the community currently lacks a comprehensive\nbenchmark and library to promote a deeper understanding and further development\nof GTs. To address this gap, this paper introduces OpenGT, a comprehensive\nbenchmark for Graph Transformers. OpenGT enables fair comparisons and\nmultidimensional analysis by establishing standardized experimental settings\nand incorporating a broad selection of state-of-the-art GNNs and GTs. Our\nbenchmark evaluates GTs from multiple perspectives, encompassing diverse tasks\nand datasets with varying properties. Through extensive experiments, our\nbenchmark has uncovered several critical insights, including the difficulty of\ntransferring models across task levels, the limitations of local attention, the\nefficiency trade-offs in several models, the application scenarios of specific\npositional encodings, and the preprocessing overhead of some positional\nencodings. We aspire for this work to establish a foundation for future graph\ntransformer research emphasizing fairness, reproducibility, and\ngeneralizability. We have developed an easy-to-use library OpenGT for training\nand evaluating existing GTs. The benchmark code is available at\nhttps://github.com/eaglelab-zju/OpenGT.", "AI": {"tldr": "The paper introduces OpenGT, a benchmark for Graph Transformers (GTs), addressing the lack of standardized evaluation and understanding of GT performance and design choices.", "motivation": "GTs show promise but lack comprehensive benchmarks to understand their effectiveness and optimal design choices compared to GNNs.", "method": "OpenGT provides standardized settings, evaluates diverse tasks/datasets, and compares GTs and GNNs.", "result": "Key insights include challenges in model transfer, limitations of local attention, and efficiency trade-offs.", "conclusion": "OpenGT aims to advance GT research with fairness, reproducibility, and generalizability, supported by an open library."}}
{"id": "2506.04775", "pdf": "https://arxiv.org/pdf/2506.04775", "abs": "https://arxiv.org/abs/2506.04775", "authors": ["Artin Tajdini", "Jonathan Scarlett", "Kevin Jamieson"], "title": "Improved Regret Bounds for Linear Bandits with Heavy-Tailed Rewards", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "comment": null, "summary": "We study stochastic linear bandits with heavy-tailed rewards, where the\nrewards have a finite $(1+\\epsilon)$-absolute central moment bounded by\n$\\upsilon$ for some $\\epsilon \\in (0,1]$. We improve both upper and lower\nbounds on the minimax regret compared to prior work. When $\\upsilon =\n\\mathcal{O}(1)$, the best prior known regret upper bound is\n$\\tilde{\\mathcal{O}}(d T^{\\frac{1}{1+\\epsilon}})$. While a lower with the same\nscaling has been given, it relies on a construction using $\\upsilon =\n\\mathcal{O}(d)$, and adapting the construction to the bounded-moment regime\nwith $\\upsilon = \\mathcal{O}(1)$ yields only a\n$\\Omega(d^{\\frac{\\epsilon}{1+\\epsilon}} T^{\\frac{1}{1+\\epsilon}})$ lower bound.\nThis matches the known rate for multi-armed bandits and is generally loose for\nlinear bandits, in particular being $\\sqrt{d}$ below the optimal rate in the\nfinite-variance case ($\\epsilon = 1$). We propose a new elimination-based\nalgorithm guided by experimental design, which achieves regret\n$\\tilde{\\mathcal{O}}(d^{\\frac{1+3\\epsilon}{2(1+\\epsilon)}}\nT^{\\frac{1}{1+\\epsilon}})$, thus improving the dependence on $d$ for all\n$\\epsilon \\in (0,1)$ and recovering a known optimal result for $\\epsilon = 1$.\nWe also establish a lower bound of $\\Omega(d^{\\frac{2\\epsilon}{1+\\epsilon}}\nT^{\\frac{1}{1+\\epsilon}})$, which strictly improves upon the multi-armed bandit\nrate and highlights the hardness of heavy-tailed linear bandit problems. For\nfinite action sets, we derive similarly improved upper and lower bounds for\nregret. Finally, we provide action set dependent regret upper bounds showing\nthat for some geometries, such as $l_p$-norm balls for $p \\le 1 + \\epsilon$, we\ncan further reduce the dependence on $d$, and we can handle\ninfinite-dimensional settings via the kernel trick, in particular establishing\nnew regret bounds for the Mat\\'ern kernel that are the first to be sublinear\nfor all $\\epsilon \\in (0, 1]$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.04786", "pdf": "https://arxiv.org/pdf/2506.04786", "abs": "https://arxiv.org/abs/2506.04786", "authors": ["Thore Gerlach", "Sascha M\u00fccke", "Christian Bauckhage"], "title": "Kernel $k$-Medoids as General Vector Quantization", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "Vector Quantization (VQ) is a widely used technique in machine learning and\ndata compression, valued for its simplicity and interpretability. Among hard VQ\nmethods, $k$-medoids clustering and Kernel Density Estimation (KDE) approaches\nrepresent two prominent yet seemingly unrelated paradigms -- one\ndistance-based, the other rooted in probability density matching. In this\npaper, we investigate their connection through the lens of Quadratic\nUnconstrained Binary Optimization (QUBO). We compare a heuristic QUBO\nformulation for $k$-medoids, which balances centrality and diversity, with a\nprincipled QUBO derived from minimizing Maximum Mean Discrepancy in KDE-based\nVQ. Surprisingly, we show that the KDE-QUBO is a special case of the\n$k$-medoids-QUBO under mild assumptions on the kernel's feature map. This\nreveals a deeper structural relationship between these two approaches and\nprovides new insight into the geometric interpretation of the weighting\nparameters used in QUBO formulations for VQ.", "AI": {"tldr": "The paper explores the connection between $k$-medoids clustering and Kernel Density Estimation (KDE) in Vector Quantization (VQ) using Quadratic Unconstrained Binary Optimization (QUBO), showing that KDE-QUBO is a special case of $k$-medoids-QUBO.", "motivation": "To uncover the relationship between distance-based ($k$-medoids) and probability-based (KDE) VQ methods, which appear unrelated.", "method": "Uses QUBO formulations for $k$-medoids and KDE-based VQ, comparing their structures and assumptions.", "result": "Demonstrates that KDE-QUBO is a special case of $k$-medoids-QUBO under mild kernel feature map assumptions.", "conclusion": "Reveals a deeper structural link between $k$-medoids and KDE, offering new insights into QUBO parameters in VQ."}}
{"id": "2506.04805", "pdf": "https://arxiv.org/pdf/2506.04805", "abs": "https://arxiv.org/abs/2506.04805", "authors": ["Zhiwei Bai", "Zhangchen Zhou", "Jiajie Zhao", "Xiaolong Li", "Zhiyu Li", "Feiyu Xiong", "Hongkang Yang", "Yaoyu Zhang", "Zhi-Qin John Xu"], "title": "Adaptive Preconditioners Trigger Loss Spikes in Adam", "categories": ["cs.LG"], "comment": null, "summary": "Loss spikes emerge commonly during training across neural networks of varying\narchitectures and scales when using the Adam optimizer. In this work, we\ninvestigate the underlying mechanism responsible for Adam spikes. While\nprevious explanations attribute these phenomena to the lower-loss-as-sharper\ncharacteristics of the loss landscape, our analysis reveals that Adam's\nadaptive preconditioners themselves can trigger spikes. Specifically, we\nidentify a critical regime where squared gradients become substantially smaller\nthan the second-order moment estimates, causing the latter to undergo a\n$\\beta_2$-exponential decay and to respond sluggishly to current gradient\ninformation. This mechanism can push the maximum eigenvalue of the\npreconditioned Hessian beyond the classical stability threshold $2/\\eta$ for a\nsustained period, inducing instability. This instability further leads to an\nalignment between the gradient and the maximum eigendirection, and a loss spike\noccurs precisely when the gradient-directional curvature exceeds $2/\\eta$. We\nverify this mechanism through extensive experiments on fully connected\nnetworks, convolutional networks, and Transformer architectures.", "AI": {"tldr": "The paper investigates the cause of loss spikes in neural networks trained with Adam, attributing them to Adam's adaptive preconditioners rather than loss landscape sharpness.", "motivation": "Loss spikes during training with Adam are common but poorly understood, prompting a deeper analysis of their root cause.", "method": "The study identifies a critical regime where squared gradients are much smaller than second-order moment estimates, leading to instability. Theoretical and experimental validation is performed across various architectures.", "result": "The mechanism causes the preconditioned Hessian's maximum eigenvalue to exceed stability thresholds, inducing loss spikes when gradient-directional curvature surpasses 2/\u03b7.", "conclusion": "Adam's adaptive preconditioners can inherently trigger loss spikes, verified across multiple neural network architectures."}}
{"id": "2506.04821", "pdf": "https://arxiv.org/pdf/2506.04821", "abs": "https://arxiv.org/abs/2506.04821", "authors": ["Zhen Hao Wong", "Jingwen Deng", "Runming He", "Zirong Chen", "Qijie You", "Hejun Dong", "Hao Liang", "Chengyu Shen", "Bin Cui", "Wentao Zhang"], "title": "LogicPuzzleRL: Cultivating Robust Mathematical Reasoning in LLMs via Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at many supervised tasks but often\nstruggle with structured reasoning in unfamiliar settings. This discrepancy\nsuggests that standard fine-tuning pipelines may instill narrow,\ndomain-specific heuristics rather than fostering general-purpose thinking\nstrategies. In this work, we propose a \"play to learn\" framework that\nfine-tunes LLMs through reinforcement learning on a suite of seven custom logic\npuzzles, each designed to cultivate distinct reasoning skills such as\nconstraint propagation, spatial consistency, and symbolic deduction. Using a\nreinforcement learning setup with verifiable rewards, models receive binary\nfeedback based on puzzle correctness, encouraging iterative, hypothesis-driven\nproblem solving. We demonstrate that this training approach significantly\nimproves out-of-distribution performance on a range of mathematical benchmarks,\nespecially for mid-difficulty problems that require multi-step reasoning.\nAnalyses across problem categories and difficulty levels reveal that puzzle\ntraining promotes transferable reasoning routines, strengthening algebraic\nmanipulation, geometric inference, and combinatorial logic, while offering\nlimited gains on rote or highly specialized tasks. These findings show that\nreinforcement learning over logic puzzles reshapes the internal reasoning of\nLLMs, enabling more robust and compositional generalization without relying on\ntask-specific symbolic tools.", "AI": {"tldr": "A 'play to learn' framework uses reinforcement learning on logic puzzles to improve LLMs' structured reasoning, showing gains in multi-step problem-solving and transferable skills.", "motivation": "Standard fine-tuning may limit LLMs to narrow heuristics; this work aims to foster general-purpose reasoning through puzzle-based training.", "method": "Fine-tuning LLMs via reinforcement learning on seven custom logic puzzles, with binary feedback for correctness to encourage iterative problem-solving.", "result": "Significant improvement in out-of-distribution performance, especially for mid-difficulty problems requiring multi-step reasoning, and gains in algebraic, geometric, and combinatorial logic.", "conclusion": "Reinforcement learning over logic puzzles enhances LLMs' compositional generalization and robust reasoning without task-specific tools."}}
{"id": "2506.04831", "pdf": "https://arxiv.org/pdf/2506.04831", "abs": "https://arxiv.org/abs/2506.04831", "authors": ["Chantal Pellegrini", "Ege \u00d6zsoy", "David Bani-Harouni", "Matthias Keicher", "Nassir Navab"], "title": "From EHRs to Patient Pathways: Scalable Modeling of Longitudinal Health Trajectories with LLMs", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Healthcare systems face significant challenges in managing and interpreting\nvast, heterogeneous patient data for personalized care. Existing approaches\noften focus on narrow use cases with a limited feature space, overlooking the\ncomplex, longitudinal interactions needed for a holistic understanding of\npatient health. In this work, we propose a novel approach to patient pathway\nmodeling by transforming diverse electronic health record (EHR) data into a\nstructured representation and designing a holistic pathway prediction model,\nEHR2Path, optimized to predict future health trajectories. Further, we\nintroduce a novel summary mechanism that embeds long-term temporal context into\ntopic-specific summary tokens, improving performance over text-only models,\nwhile being much more token-efficient. EHR2Path demonstrates strong performance\nin both next time-step prediction and longitudinal simulation, outperforming\ncompetitive baselines. It enables detailed simulations of patient trajectories,\ninherently targeting diverse evaluation tasks, such as forecasting vital signs,\nlab test results, or length-of-stay, opening a path towards predictive and\npersonalized healthcare.", "AI": {"tldr": "The paper introduces EHR2Path, a novel method for modeling patient pathways by transforming EHR data into structured representations, improving prediction of future health trajectories with a token-efficient summary mechanism.", "motivation": "Healthcare systems struggle with managing diverse patient data for personalized care, as existing methods are limited in scope and overlook longitudinal interactions.", "method": "EHR2Path transforms EHR data into structured representations and uses a summary mechanism to embed long-term temporal context, optimizing for pathway prediction.", "result": "EHR2Path outperforms baselines in next time-step prediction and longitudinal simulation, enabling detailed patient trajectory forecasts.", "conclusion": "The approach advances predictive and personalized healthcare by efficiently modeling patient pathways and supporting diverse evaluation tasks."}}
{"id": "2506.04859", "pdf": "https://arxiv.org/pdf/2506.04859", "abs": "https://arxiv.org/abs/2506.04859", "authors": ["Yin Lu", "Tong He", "Xuening Zhu", "David Wipf"], "title": "Sparse Autoencoders, Again?", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to the International Conference on Machine Learning (ICML)\n  2025", "summary": "Is there really much more to say about sparse autoencoders (SAEs)?\nAutoencoders in general, and SAEs in particular, represent deep architectures\nthat are capable of modeling low-dimensional latent structure in data. Such\nstructure could reflect, among other things, correlation patterns in large\nlanguage model activations, or complex natural image manifolds. And yet despite\nthe wide-ranging applicability, there have been relatively few changes to SAEs\nbeyond the original recipe from decades ago, namely, standard deep\nencoder/decoder layers trained with a classical/deterministic sparse\nregularizer applied within the latent space. One possible exception is the\nvariational autoencoder (VAE), which adopts a stochastic encoder module capable\nof producing sparse representations when applied to manifold data. In this work\nwe formalize underappreciated weaknesses with both canonical SAEs, as well as\nanalogous VAEs applied to similar tasks, and propose a hybrid alternative model\nthat circumvents these prior limitations. In terms of theoretical support, we\nprove that global minima of our proposed model recover certain forms of\nstructured data spread across a union of manifolds. Meanwhile, empirical\nevaluations on synthetic and real-world datasets substantiate the efficacy of\nour approach in accurately estimating underlying manifold dimensions and\nproducing sparser latent representations without compromising reconstruction\nerror. In general, we are able to exceed the performance of equivalent-capacity\nSAEs and VAEs, as well as recent diffusion models where applicable, within\ndomains such as images and language model activation patterns.", "AI": {"tldr": "The paper critiques traditional sparse autoencoders (SAEs) and variational autoencoders (VAEs), proposing a hybrid model that outperforms both in tasks like manifold dimension estimation and sparse representation without sacrificing reconstruction quality.", "motivation": "Despite the broad applicability of SAEs and VAEs, their limitations in handling structured data and sparse representations remain underaddressed. The paper aims to bridge these gaps.", "method": "The authors introduce a hybrid model combining strengths of SAEs and VAEs, supported by theoretical proofs of its ability to recover structured data. Empirical tests on synthetic and real-world datasets validate its efficacy.", "result": "The proposed model outperforms SAEs, VAEs, and diffusion models in tasks like manifold dimension estimation and sparse representation, while maintaining low reconstruction error.", "conclusion": "The hybrid model addresses key weaknesses of traditional SAEs and VAEs, offering improved performance in diverse applications like image and language model activation analysis."}}
{"id": "2506.04870", "pdf": "https://arxiv.org/pdf/2506.04870", "abs": "https://arxiv.org/abs/2506.04870", "authors": ["Antonio Almud\u00e9var", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "Sameer Khurana", "Ricard Marxer", "Alfonso Ortega"], "title": "Aligning Multimodal Representations through an Information Bottleneck", "categories": ["cs.LG"], "comment": null, "summary": "Contrastive losses have been extensively used as a tool for multimodal\nrepresentation learning. However, it has been empirically observed that their\nuse is not effective to learn an aligned representation space. In this paper,\nwe argue that this phenomenon is caused by the presence of modality-specific\ninformation in the representation space. Although some of the most widely used\ncontrastive losses maximize the mutual information between representations of\nboth modalities, they are not designed to remove the modality-specific\ninformation. We give a theoretical description of this problem through the lens\nof the Information Bottleneck Principle. We also empirically analyze how\ndifferent hyperparameters affect the emergence of this phenomenon in a\ncontrolled experimental setup. Finally, we propose a regularization term in the\nloss function that is derived by means of a variational approximation and aims\nto increase the representational alignment. We analyze in a set of controlled\nexperiments and real-world applications the advantages of including this\nregularization term.", "AI": {"tldr": "Contrastive losses in multimodal learning often fail to align representation spaces due to modality-specific information. The paper proposes a regularization term to improve alignment, supported by theory and experiments.", "motivation": "Contrastive losses are ineffective for aligned representation learning because they don't remove modality-specific information, hindering multimodal alignment.", "method": "Theoretical analysis via the Information Bottleneck Principle, empirical hyperparameter study, and introduction of a variational regularization term to enhance alignment.", "result": "The proposed regularization term improves representational alignment in controlled experiments and real-world applications.", "conclusion": "Addressing modality-specific information with a regularization term enhances the effectiveness of contrastive losses for multimodal representation learning."}}
{"id": "2506.04877", "pdf": "https://arxiv.org/pdf/2506.04877", "abs": "https://arxiv.org/abs/2506.04877", "authors": ["Antonio Almud\u00e9var", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "Alfonso Ortega"], "title": "There Was Never a Bottleneck in Concept Bottleneck Models", "categories": ["cs.LG"], "comment": null, "summary": "Deep learning representations are often difficult to interpret, which can\nhinder their deployment in sensitive applications. Concept Bottleneck Models\n(CBMs) have emerged as a promising approach to mitigate this issue by learning\nrepresentations that support target task performance while ensuring that each\ncomponent predicts a concrete concept from a predefined set. In this work, we\nargue that CBMs do not impose a true bottleneck: the fact that a component can\npredict a concept does not guarantee that it encodes only information about\nthat concept. This shortcoming raises concerns regarding interpretability and\nthe validity of intervention procedures. To overcome this limitation, we\npropose Minimal Concept Bottleneck Models (MCBMs), which incorporate an\nInformation Bottleneck (IB) objective to constrain each representation\ncomponent to retain only the information relevant to its corresponding concept.\nThis IB is implemented via a variational regularization term added to the\ntraining loss. As a result, MCBMs support concept-level interventions with\ntheoretical guarantees, remain consistent with Bayesian principles, and offer\ngreater flexibility in key design choices.", "AI": {"tldr": "The paper introduces Minimal Concept Bottleneck Models (MCBMs) to address the lack of a true bottleneck in Concept Bottleneck Models (CBMs), ensuring interpretability and valid interventions by using an Information Bottleneck objective.", "motivation": "CBMs lack a true bottleneck, allowing components to encode extraneous information, which undermines interpretability and intervention validity.", "method": "Proposes MCBMs with an Information Bottleneck (IB) objective via variational regularization to constrain representations to concept-relevant information.", "result": "MCBMs enable concept-level interventions with theoretical guarantees, align with Bayesian principles, and offer design flexibility.", "conclusion": "MCBMs improve interpretability and intervention validity over CBMs by enforcing a true bottleneck through IB regularization."}}
{"id": "2506.04886", "pdf": "https://arxiv.org/pdf/2506.04886", "abs": "https://arxiv.org/abs/2506.04886", "authors": ["Allen Paul", "George Grammatopoulos", "Adwaye Rambojun", "Neill D. F. Campbell", "Harinderjit S. Gill", "Tony Shardlow"], "title": "Gaussian Process Diffeomorphic Statistical Shape Modelling Outperforms Angle-Based Methods for Assessment of Hip Dysplasia", "categories": ["cs.LG"], "comment": null, "summary": "Dysplasia is a recognised risk factor for osteoarthritis (OA) of the hip,\nearly diagnosis of dysplasia is important to provide opportunities for surgical\ninterventions aimed at reducing the risk of hip OA. We have developed a\npipeline for semi-automated classification of dysplasia using volumetric CT\nscans of patients' hips and a minimal set of clinically annotated landmarks,\ncombining the framework of the Gaussian Process Latent Variable Model with\ndiffeomorphism to create a statistical shape model, which we termed the\nGaussian Process Diffeomorphic Statistical Shape Model (GPDSSM). We used 192 CT\nscans, 100 for model training and 92 for testing. The GPDSSM effectively\ndistinguishes dysplastic samples from controls while also highlighting regions\nof the underlying surface that show dysplastic variations. As well as improving\nclassification accuracy compared to angle-based methods (AUC 96.2% vs 91.2%),\nthe GPDSSM can save time for clinicians by removing the need to manually\nmeasure angles and interpreting 2D scans for possible markers of dysplasia.", "AI": {"tldr": "The paper introduces GPDSSM, a semi-automated pipeline for classifying hip dysplasia using CT scans, outperforming angle-based methods with 96.2% AUC.", "motivation": "Early diagnosis of hip dysplasia is crucial to prevent osteoarthritis, but current methods like angle-based measurements are time-consuming and less accurate.", "method": "The GPDSSM combines Gaussian Process Latent Variable Model with diffeomorphism to create a statistical shape model, trained on 100 CT scans and tested on 92.", "result": "GPDSSM achieves 96.2% AUC in classification, outperforming angle-based methods (91.2%), and identifies dysplastic variations in hip surfaces.", "conclusion": "GPDSSM improves accuracy and efficiency in dysplasia diagnosis, reducing reliance on manual measurements and 2D scans."}}
{"id": "2506.04913", "pdf": "https://arxiv.org/pdf/2506.04913", "abs": "https://arxiv.org/abs/2506.04913", "authors": ["Yongyu Mu", "Jiali Zeng", "Bei Li", "Xinyan Guan", "Fandong Meng", "Jie Zhou", "Tong Xiao", "Jingbo Zhu"], "title": "Dissecting Long Reasoning Models: An Empirical Study", "categories": ["cs.LG", "cs.CL"], "comment": "Working in process", "summary": "Despite recent progress in training long-context reasoning models via\nreinforcement learning (RL), several open questions and counterintuitive\nbehaviors remain. This work focuses on three key aspects: (1) We systematically\nanalyze the roles of positive and negative samples in RL, revealing that\npositive samples mainly facilitate data fitting, whereas negative samples\nsignificantly enhance generalization and robustness. Interestingly, training\nsolely on negative samples can rival standard RL training performance. (2) We\nidentify substantial data inefficiency in group relative policy optimization,\nwhere over half of the samples yield zero advantage. To address this, we\nexplore two straightforward strategies, including relative length rewards and\noffline sample injection, to better leverage these data and enhance reasoning\nefficiency and capability. (3) We investigate unstable performance across\nvarious reasoning models and benchmarks, attributing instability to uncertain\nproblems with ambiguous outcomes, and demonstrate that multiple evaluation runs\nmitigate this issue.", "AI": {"tldr": "The paper analyzes RL training for long-context reasoning, highlighting the roles of positive/negative samples, data inefficiency in policy optimization, and performance instability due to ambiguous problems.", "motivation": "To address open questions and counterintuitive behaviors in RL training for long-context reasoning, focusing on sample roles, data efficiency, and performance stability.", "method": "Systematic analysis of sample roles, strategies to improve data efficiency (e.g., relative length rewards, offline sample injection), and multiple evaluation runs to address instability.", "result": "Negative samples enhance generalization; training on them alone rivals standard RL. Data inefficiency identified, mitigated by proposed strategies. Performance instability linked to ambiguous problems, reduced by multiple evaluations.", "conclusion": "The study provides insights into RL training dynamics, offering practical solutions for data efficiency and stability in long-context reasoning models."}}
{"id": "2506.04924", "pdf": "https://arxiv.org/pdf/2506.04924", "abs": "https://arxiv.org/abs/2506.04924", "authors": ["Han Wang", "Ruoyun He", "Guoguang Lao", "Ting Liu", "Hejiao Luo", "Changqi Qin", "Hongying Luo", "Junmin Huang", "Zihan Wei", "Lu Chen", "Yongzhi Xu", "Ziqian Bi", "Junhao Song", "Tianyang Wang", "Chia Xin Liang", "Xinyuan Song", "Huafeng Liu", "Junfeng Hao", "Chunjie Tian"], "title": "Predicting ICU In-Hospital Mortality Using Adaptive Transformer Layer Fusion", "categories": ["cs.LG"], "comment": "21 pages, 6 figures", "summary": "Early identification of high-risk ICU patients is crucial for directing\nlimited medical resources. We introduce ALFIA (Adaptive Layer Fusion with\nIntelligent Attention), a modular, attention-based architecture that jointly\ntrains LoRA (Low-Rank Adaptation) adapters and an adaptive layer-weighting\nmechanism to fuse multi-layer semantic features from a BERT backbone. Trained\non our rigorous cw-24 (CriticalWindow-24) benchmark, ALFIA surpasses\nstate-of-the-art tabular classifiers in AUPRC while preserving a balanced\nprecision-recall profile. The embeddings produced by ALFIA's fusion module,\ncapturing both fine-grained clinical cues and high-level concepts, enable\nseamless pairing with GBDTs (CatBoost/LightGBM) as ALFIA-boost, and deep neuro\nnetworks as ALFIA-nn, yielding additional performance gains. Our experiments\nconfirm ALFIA's superior early-warning performance, by operating directly on\nroutine clinical text, it furnishes clinicians with a convenient yet robust\ntool for risk stratification and timely intervention in critical-care settings.", "AI": {"tldr": "ALFIA is a modular, attention-based architecture for early identification of high-risk ICU patients, outperforming state-of-the-art methods by fusing multi-layer BERT features and enabling integration with other models for enhanced performance.", "motivation": "Early identification of high-risk ICU patients is critical for efficient resource allocation and timely intervention.", "method": "ALFIA combines LoRA adapters and adaptive layer-weighting to fuse multi-layer BERT features, trained on the cw-24 benchmark. It integrates with GBDTs and deep networks for further improvements.", "result": "ALFIA achieves superior AUPRC and maintains a balanced precision-recall profile, outperforming existing tabular classifiers.", "conclusion": "ALFIA provides a robust tool for risk stratification in critical-care settings by leveraging clinical text, enhancing early-warning capabilities."}}
{"id": "2506.04980", "pdf": "https://arxiv.org/pdf/2506.04980", "abs": "https://arxiv.org/abs/2506.04980", "authors": ["Marcos Lima Romero", "Ricardo Suyama"], "title": "Agentic AI for Intent-Based Industrial Automation", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "Preprint - Submitted to 16th IEEE/IAS International Conference on\n  Industry Applications - INDUSCON 2025", "summary": "The recent development of Agentic AI systems, empowered by autonomous large\nlanguage models (LLMs) agents with planning and tool-usage capabilities,\nenables new possibilities for the evolution of industrial automation and\nreduces the complexity introduced by Industry 4.0. This work proposes a\nconceptual framework that integrates Agentic AI with the intent-based paradigm,\noriginally developed in network research, to simplify human-machine interaction\n(HMI) and better align automation systems with the human-centric, sustainable,\nand resilient principles of Industry 5.0. Based on the intent-based processing,\nthe framework allows human operators to express high-level business or\noperational goals in natural language, which are decomposed into actionable\ncomponents. These intents are broken into expectations, conditions, targets,\ncontext, and information that guide sub-agents equipped with specialized tools\nto execute domain-specific tasks. A proof of concept was implemented using the\nCMAPSS dataset and Google Agent Developer Kit (ADK), demonstrating the\nfeasibility of intent decomposition, agent orchestration, and autonomous\ndecision-making in predictive maintenance scenarios. The results confirm the\npotential of this approach to reduce technical barriers and enable scalable,\nintent-driven automation, despite data quality and explainability concerns.", "AI": {"tldr": "The paper proposes a framework integrating Agentic AI with intent-based paradigms to simplify human-machine interaction in Industry 5.0, demonstrated via predictive maintenance.", "motivation": "To reduce complexity in Industry 4.0 and align automation with human-centric, sustainable, and resilient principles of Industry 5.0.", "method": "A conceptual framework combining Agentic AI and intent-based processing, tested using CMAPSS dataset and Google ADK.", "result": "Feasibility shown for intent decomposition, agent orchestration, and autonomous decision-making, though data quality and explainability remain challenges.", "conclusion": "The approach reduces technical barriers and enables scalable, intent-driven automation."}}
{"id": "2506.04985", "pdf": "https://arxiv.org/pdf/2506.04985", "abs": "https://arxiv.org/abs/2506.04985", "authors": ["Boris van Breugel", "Yelysei Bondarenko", "Paul Whatmough", "Markus Nagel"], "title": "FPTQuant: Function-Preserving Transforms for LLM Quantization", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) require substantial compute, and thus energy, at\ninference time. While quantizing weights and activations is effective at\nimproving efficiency, naive quantization of LLMs can significantly degrade\nperformance due to large magnitude outliers. This paper describes FPTQuant,\nwhich introduces four novel, lightweight, and expressive function-preserving\ntransforms (FPTs) to facilitate quantization of transformers: (1) a mergeable\npre-RoPE transform for queries and keys, (2) a mergeable transform for values,\n(3) a mergeable scaling transform within the MLP block, and (4) a cheap,\ndynamic scaling transform. By leveraging the equivariances and independencies\ninherent to canonical transformer operation, we designed these FPTs to maintain\nthe model's function while shaping the intermediate activation distributions to\nbe more quantization friendly. FPTQuant requires no custom kernels and adds\nvirtually no overhead during inference. The FPTs are trained both locally to\nreduce outliers, and end-to-end such that the outputs of the quantized and\nfull-precision models match. FPTQuant enables static INT4 quantization with\nminimal overhead and shows SOTA speed-up of up to 3.9 times over FP.\nEmpirically, FPTQuant has an excellent accuracy-speed trade-off -- it is\nperforming on par or exceeding most prior work and only shows slightly lower\naccuracy compared to a method that is up to 29% slower.", "AI": {"tldr": "FPTQuant introduces lightweight function-preserving transforms (FPTs) to enable efficient INT4 quantization of LLMs without performance degradation, achieving up to 3.9x speed-up over FP.", "motivation": "Large language models (LLMs) consume significant energy during inference, and naive quantization degrades performance due to outliers. FPTQuant aims to maintain model function while improving quantization efficiency.", "method": "FPTQuant uses four novel FPTs: pre-RoPE transform for queries/keys, value transform, MLP scaling transform, and dynamic scaling. These leverage transformer equivariances to shape activations for quantization without custom kernels.", "result": "FPTQuant achieves INT4 quantization with minimal overhead, outperforming prior work in speed (3.9x faster than FP) while maintaining accuracy, trading only slight accuracy for 29% slower methods.", "conclusion": "FPTQuant provides an efficient, accurate solution for LLM quantization, balancing speed and performance with lightweight transforms."}}
{"id": "2506.05005", "pdf": "https://arxiv.org/pdf/2506.05005", "abs": "https://arxiv.org/abs/2506.05005", "authors": ["Ashkan Soleymani", "Georgios Piliouras", "Gabriele Farina"], "title": "Cautious Optimism: A Meta-Algorithm for Near-Constant Regret in General Games", "categories": ["cs.LG", "cs.GT", "math.OC"], "comment": "Extended abstract appeared at Twenty-Sixth ACM Conference on\n  Economics and Computation (EC), 2025", "summary": "Recent work [Soleymani et al., 2025] introduced a variant of Optimistic\nMultiplicative Weights Updates (OMWU) that adaptively controls the learning\npace in a dynamic, non-monotone manner, achieving new state-of-the-art regret\nminimization guarantees in general games. In this work, we demonstrate that\nno-regret learning acceleration through adaptive pacing of the learners is not\nan isolated phenomenon. We introduce \\emph{Cautious Optimism}, a framework for\nsubstantially faster regularized learning in general games. Cautious Optimism\ntakes as input any instance of Follow-the-Regularized-Leader (FTRL) and outputs\nan accelerated no-regret learning algorithm by pacing the underlying FTRL with\nminimal computational overhead. Importantly, we retain uncoupledness (learners\ndo not need to know other players' utilities). Cautious Optimistic FTRL\nachieves near-optimal $O_T(\\log T)$ regret in diverse self-play\n(mixing-and-matching regularizers) while preserving the optimal $O(\\sqrt{T})$\nregret in adversarial scenarios. In contrast to prior works (e.g. Syrgkanis et\nal. [2015], Daskalakis et al. [2021]), our analysis does not rely on monotonic\nstep-sizes, showcasing a novel route for fast learning in general games.", "AI": {"tldr": "The paper introduces 'Cautious Optimism,' a framework accelerating no-regret learning in general games by adaptively pacing FTRL algorithms, achieving near-optimal regret guarantees without relying on monotonic step-sizes.", "motivation": "To show that adaptive pacing for no-regret learning acceleration is not isolated and can be generalized, improving upon prior methods that depend on monotonic step-sizes.", "method": "Proposes 'Cautious Optimism,' which takes any FTRL instance and accelerates it with minimal overhead, retaining uncoupledness (no knowledge of others' utilities).", "result": "Achieves near-optimal O_T(log T) regret in self-play and maintains O(sqrt(T)) regret in adversarial settings.", "conclusion": "Demonstrates a novel, efficient approach for fast learning in general games without monotonic step-size constraints."}}
{"id": "2506.05014", "pdf": "https://arxiv.org/pdf/2506.05014", "abs": "https://arxiv.org/abs/2506.05014", "authors": ["Nektarios Kalampalikis", "Kavya Gupta", "Georgi Vitanov", "Isabel Valera"], "title": "Towards Reasonable Concept Bottleneck Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "26 pages, 17 figures", "summary": "In this paper, we propose $\\textbf{C}$oncept $\\textbf{REA}$soning\n$\\textbf{M}$odels (CREAM), a novel family of Concept Bottleneck Models (CBMs)\nthat: (i) explicitly encodes concept-concept (${\\texttt{C-C}}$) and\nconcept-task (${\\texttt{C$\\rightarrow$Y}}$) relationships to enforce a desired\nmodel reasoning; and (ii) use a regularized side-channel to achieve competitive\ntask performance, while keeping high concept importance. Specifically, CREAM\narchitecturally embeds (bi)directed concept-concept, and concept to task\nrelationships specified by a human expert, while severing undesired information\nflows (e.g., to handle mutually exclusive concepts). Moreover, CREAM integrates\na black-box side-channel that is regularized to encourage task predictions to\nbe grounded in the relevant concepts, thereby utilizing the side-channel only\nwhen necessary to enhance performance. Our experiments show that: (i) CREAM\nmainly relies on concepts while achieving task performance on par with\nblack-box models; and (ii) the embedded ${\\texttt{C-C}}$ and\n${\\texttt{C$\\rightarrow$Y}}$ relationships ease model interventions and\nmitigate concept leakage.", "AI": {"tldr": "CREAM is a new type of Concept Bottleneck Model that explicitly encodes concept-concept and concept-task relationships, using a regularized side-channel for performance while maintaining concept importance.", "motivation": "To improve model reasoning by embedding expert-specified relationships and handling undesired information flows, while balancing task performance and concept reliance.", "method": "CREAM architecturally embeds (bi)directed concept-concept and concept-task relationships, uses a regularized side-channel, and severs undesired information flows.", "result": "CREAM achieves task performance comparable to black-box models while relying mainly on concepts, and its embedded relationships ease interventions and reduce concept leakage.", "conclusion": "CREAM effectively balances expert-guided reasoning and task performance, offering a robust framework for interpretable models."}}
{"id": "2506.05016", "pdf": "https://arxiv.org/pdf/2506.05016", "abs": "https://arxiv.org/abs/2506.05016", "authors": ["John Collins"], "title": "Multi-Point Proximity Encoding For Vector-Mode Geospatial Machine Learning", "categories": ["cs.LG", "68T07, 68T30", "I.2.4; J.2"], "comment": "10 pages, 8 figures", "summary": "Vector-mode geospatial data -- points, lines, and polygons -- must be encoded\ninto an appropriate form in order to be used with traditional machine learning\nand artificial intelligence models. Encoding methods attempt to represent a\ngiven shape as a vector that captures its essential geometric properties. This\npaper presents an encoding method based on scaled distances from a shape to a\nset of reference points within a region of interest. The method, MultiPoint\nProximity (MPP) encoding, can be applied to any type of shape, enabling the\nparameterization of machine learning models with encoded representations of\nvector-mode geospatial features. We show that MPP encoding possesses the\ndesirable properties of shape-centricity and continuity, can be used to\ndifferentiate spatial objects based on their geometric features, and can\ncapture pairwise spatial relationships with high precision. In all cases, MPP\nencoding is shown to perform better than an alternative method based on\nrasterization.", "AI": {"tldr": "MPP encoding converts geospatial shapes into vectors using scaled distances to reference points, outperforming rasterization in capturing geometric features and spatial relationships.", "motivation": "To enable machine learning models to use vector-mode geospatial data (points, lines, polygons) by encoding shapes into vectors that retain essential geometric properties.", "method": "MultiPoint Proximity (MPP) encoding, which measures scaled distances from a shape to reference points within a region of interest.", "result": "MPP encoding is shape-centric, continuous, differentiates spatial objects, and captures pairwise spatial relationships more precisely than rasterization.", "conclusion": "MPP encoding is a superior method for representing geospatial shapes in machine learning, outperforming rasterization in accuracy and versatility."}}
{"id": "2506.05027", "pdf": "https://arxiv.org/pdf/2506.05027", "abs": "https://arxiv.org/abs/2506.05027", "authors": ["Kuang He", "Wei Tang", "Tong Wei", "Min-Ling Zhang"], "title": "Tuning the Right Foundation Models is What you Need for Partial Label Learning", "categories": ["cs.LG"], "comment": "The code can be found at \\url{https://github.com/SEU-hk/PartialCLIP}", "summary": "Partial label learning (PLL) seeks to train generalizable classifiers from\ndatasets with inexact supervision, a common challenge in real-world\napplications. Existing studies have developed numerous approaches to\nprogressively refine and recover ground-truth labels by training convolutional\nneural networks. However, limited attention has been given to foundation models\nthat offer transferrable representations. In this work, we empirically conduct\ncomprehensive evaluations of 11 foundation models across 13 PLL approaches on 8\nbenchmark datasets under 3 PLL scenarios. We further propose PartialCLIP, an\nefficient fine-tuning framework for foundation models in PLL. Our findings\nreveal that current PLL approaches tend to 1) achieve significant performance\ngains when using foundation models, 2) exhibit remarkably similar performance\nto each other, 3) maintain stable performance across varying ambiguity levels,\nwhile 4) are susceptible to foundation model selection and adaptation\nstrategies. Additionally, we demonstrate the efficacy of text-embedding\nclassifier initialization and effective candidate label filtering using\nzero-shot CLIP. Our experimental results and analysis underscore the\nlimitations of current PLL approaches and provide valuable insights for\ndeveloping more generalizable PLL models. The source code can be found at\nhttps://github.com/SEU-hk/PartialCLIP.", "AI": {"tldr": "The paper evaluates foundation models in partial label learning (PLL), proposes PartialCLIP for efficient fine-tuning, and highlights performance trends and limitations of current PLL approaches.", "motivation": "To address the lack of focus on foundation models in PLL and improve generalizability of classifiers trained with inexact supervision.", "method": "Empirical evaluation of 11 foundation models across 13 PLL approaches on 8 datasets under 3 scenarios, plus the introduction of PartialCLIP for fine-tuning.", "result": "Foundation models significantly boost PLL performance, approaches show similar results, stability across ambiguity levels, but are sensitive to model selection.", "conclusion": "Current PLL approaches have limitations; text-embedding initialization and label filtering with CLIP are effective. Insights provided for future generalizable PLL models."}}
{"id": "2506.05032", "pdf": "https://arxiv.org/pdf/2506.05032", "abs": "https://arxiv.org/abs/2506.05032", "authors": ["Zeming Wei", "Yiwen Guo", "Yisen Wang"], "title": "Identifying and Understanding Cross-Class Features in Adversarial Training", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "math.OC"], "comment": "ICML 2025", "summary": "Adversarial training (AT) has been considered one of the most effective\nmethods for making deep neural networks robust against adversarial attacks,\nwhile the training mechanisms and dynamics of AT remain open research problems.\nIn this paper, we present a novel perspective on studying AT through the lens\nof class-wise feature attribution. Specifically, we identify the impact of a\nkey family of features on AT that are shared by multiple classes, which we call\ncross-class features. These features are typically useful for robust\nclassification, which we offer theoretical evidence to illustrate through a\nsynthetic data model. Through systematic studies across multiple model\narchitectures and settings, we find that during the initial stage of AT, the\nmodel tends to learn more cross-class features until the best robustness\ncheckpoint. As AT further squeezes the training robust loss and causes robust\noverfitting, the model tends to make decisions based on more class-specific\nfeatures. Based on these discoveries, we further provide a unified view of two\nexisting properties of AT, including the advantage of soft-label training and\nrobust overfitting. Overall, these insights refine the current understanding of\nAT mechanisms and provide new perspectives on studying them. Our code is\navailable at https://github.com/PKU-ML/Cross-Class-Features-AT.", "AI": {"tldr": "The paper studies adversarial training (AT) through class-wise feature attribution, identifying cross-class features as key for robust classification. It shows AT initially learns these features, then shifts to class-specific features, linking this to robust overfitting and soft-label training advantages.", "motivation": "To understand the mechanisms and dynamics of adversarial training (AT) by analyzing class-wise feature attribution, particularly focusing on cross-class features.", "method": "The study uses theoretical evidence from a synthetic data model and systematic experiments across various model architectures and settings to analyze feature learning in AT.", "result": "AT initially learns cross-class features for robustness, then shifts to class-specific features, causing robust overfitting. This provides insights into soft-label training advantages and robust overfitting.", "conclusion": "The findings refine understanding of AT mechanisms, offering new perspectives for future research. Code is available for reproducibility."}}
{"id": "2506.05035", "pdf": "https://arxiv.org/pdf/2506.05035", "abs": "https://arxiv.org/abs/2506.05035", "authors": ["Hyeongwon Jang", "Changhun Kim", "Eunho Yang"], "title": "TIMING: Temporality-Aware Integrated Gradients for Time Series Explanation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Spotlight Presentation; Code is available at\n  https://github.com/drumpt/TIMING", "summary": "Recent explainable artificial intelligence (XAI) methods for time series\nprimarily estimate point-wise attribution magnitudes, while overlooking the\ndirectional impact on predictions, leading to suboptimal identification of\nsignificant points. Our analysis shows that conventional Integrated Gradients\n(IG) effectively capture critical points with both positive and negative\nimpacts on predictions. However, current evaluation metrics fail to assess this\ncapability, as they inadvertently cancel out opposing feature contributions. To\naddress this limitation, we propose novel evaluation metrics-Cumulative\nPrediction Difference (CPD) and Cumulative Prediction Preservation (CPP)-to\nsystematically assess whether attribution methods accurately identify\nsignificant positive and negative points in time series XAI. Under these\nmetrics, conventional IG outperforms recent counterparts. However, directly\napplying IG to time series data may lead to suboptimal outcomes, as generated\npaths ignore temporal relationships and introduce out-of-distribution samples.\nTo overcome these challenges, we introduce TIMING, which enhances IG by\nincorporating temporal awareness while maintaining its theoretical properties.\nExtensive experiments on synthetic and real-world time series benchmarks\ndemonstrate that TIMING outperforms existing time series XAI baselines. Our\ncode is available at https://github.com/drumpt/TIMING.", "AI": {"tldr": "The paper introduces TIMING, a method to enhance Integrated Gradients (IG) for time series XAI by incorporating temporal awareness, outperforming existing baselines.", "motivation": "Current XAI methods for time series overlook directional impact and fail to evaluate it properly, leading to suboptimal identification of significant points.", "method": "Proposes TIMING, an enhancement of IG for time series, incorporating temporal awareness to avoid out-of-distribution samples and maintain theoretical properties.", "result": "TIMING outperforms existing time series XAI baselines under novel metrics (CPD and CPP).", "conclusion": "TIMING effectively addresses limitations of conventional IG in time series XAI, improving attribution accuracy."}}
{"id": "2506.05039", "pdf": "https://arxiv.org/pdf/2506.05039", "abs": "https://arxiv.org/abs/2506.05039", "authors": ["Nicolas Lell", "Ansgar Scherp"], "title": "iN2V: Bringing Transductive Node Embeddings to Inductive Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Shallow node embeddings like node2vec (N2V) can be used for nodes without\nfeatures or to supplement existing features with structure-based information.\nEmbedding methods like N2V are limited in their application on new nodes, which\nrestricts them to the transductive setting where the entire graph, including\nthe test nodes, is available during training. We propose inductive node2vec\n(iN2V), which combines a post-hoc procedure to compute embeddings for nodes\nunseen during training and modifications to the original N2V training procedure\nto prepare the embeddings for this post-hoc procedure. We conduct experiments\non several benchmark datasets and demonstrate that iN2V is an effective\napproach to bringing transductive embeddings to an inductive setting. Using\niN2V embeddings improves node classification by 1 point on average, with up to\n6 points of improvement depending on the dataset and the number of unseen\nnodes. Our iN2V is a plug-in approach to create new or enrich existing\nembeddings. It can also be combined with other embedding methods, making it a\nversatile approach for inductive node representation learning. Code to\nreproduce the results is available at https://github.com/Foisunt/iN2V .", "AI": {"tldr": "iN2V extends node2vec to inductive settings, enabling embeddings for unseen nodes and improving node classification by 1-6 points.", "motivation": "Overcome the limitation of transductive node embedding methods like node2vec, which require all nodes during training.", "method": "Combines post-hoc embedding computation for unseen nodes with modified N2V training.", "result": "Improves node classification by 1 point on average (up to 6 points).", "conclusion": "iN2V is a versatile, plug-in approach for inductive node representation learning, compatible with other embedding methods."}}
{"id": "2506.05047", "pdf": "https://arxiv.org/pdf/2506.05047", "abs": "https://arxiv.org/abs/2506.05047", "authors": ["Viet Nguyen Changjian Shui", "Vijay Giri", "Siddarth Arya", "Amol Verma", "Fahad Razak", "Rahul G. Krishnan"], "title": "Reliably detecting model failures in deployment without labels", "categories": ["cs.LG"], "comment": "36 pages, 6 figures, 7 tables, submitted to NeurIPS 2025, includes\n  theoretical analysis and extensive empirical evaluation across benchmark and\n  clinical datasets. Code available at https://github.com/teivng/d3m. Viet\n  Nguyen and Changjian Shui contributed equally", "summary": "The distribution of data changes over time; models operating operating in\ndynamic environments need retraining. But knowing when to retrain, without\naccess to labels, is an open challenge since some, but not all shifts degrade\nmodel performance. This paper formalizes and addresses the problem of\npost-deployment deterioration (PDD) monitoring. We propose D3M, a practical and\nefficient monitoring algorithm based on the disagreement of predictive models,\nachieving low false positive rates under non-deteriorating shifts and provides\nsample complexity bounds for high true positive rates under deteriorating\nshifts. Empirical results on both standard benchmark and a real-world\nlarge-scale internal medicine dataset demonstrate the effectiveness of the\nframework and highlight its viability as an alert mechanism for high-stakes\nmachine learning pipelines.", "AI": {"tldr": "D3M monitors post-deployment model deterioration by tracking predictive model disagreements, ensuring low false positives and high true positives under shifts.", "motivation": "Addressing the challenge of detecting when to retrain models in dynamic environments without label access, focusing on shifts that degrade performance.", "method": "Proposes D3M, a monitoring algorithm based on predictive model disagreement, with sample complexity bounds for performance guarantees.", "result": "Effective on benchmark and real-world datasets, proving viable as an alert mechanism for high-stakes ML pipelines.", "conclusion": "D3M provides a practical solution for PDD monitoring, balancing false positives and true positives under data shifts."}}
{"id": "2506.05059", "pdf": "https://arxiv.org/pdf/2506.05059", "abs": "https://arxiv.org/abs/2506.05059", "authors": ["Shijian Xu", "Marcello Massimo Negri", "Volker Roth"], "title": "NIMO: a Nonlinear Interpretable MOdel", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Neural networks (NNs) have achieved tremendous success over the past decade,\nyet they are still extremely difficult to interpret. In contrast, linear models\nare less expressive but offer inherent interpretability. Linear coefficients\nare interpretable as the marginal effect of a feature on the prediction,\nassuming all other features are kept fixed. To combine the benefits of both\napproaches, we introduce NIMO (Nonlinear Interpretable MOdel). The key idea is\nto define a model where the NN is designed to learn nonlinear corrections to\nthe linear model predictions, while also maintaining the original\ninterpretability of the linear coefficients. Relevantly, we develop an\noptimization algorithm based on profile likelihood that elegantly allows for\noptimizing over the NN parameters while updating the linear coefficients\nanalytically. By relying on adaptive ridge regression we can easily incorporate\nsparsity constraints as well. We show empirically that we can recover the\nunderlying linear coefficients while significantly improving the predictive\naccuracy. Compared to other hybrid interpretable approaches, our model is the\nonly one that actually maintains the same interpretability of linear\ncoefficients as in linear models. We also achieve higher performance on various\nregression and classification settings.", "AI": {"tldr": "NIMO combines neural networks and linear models to maintain interpretability while improving predictive accuracy.", "motivation": "Neural networks are powerful but hard to interpret, while linear models are interpretable but less expressive. NIMO aims to merge their strengths.", "method": "NIMO uses a neural network to learn nonlinear corrections to linear predictions, with an optimization algorithm based on profile likelihood and adaptive ridge regression for sparsity.", "result": "NIMO recovers interpretable linear coefficients and outperforms other hybrid models in predictive accuracy.", "conclusion": "NIMO successfully balances interpretability and performance, making it a practical choice for regression and classification tasks."}}
{"id": "2506.05065", "pdf": "https://arxiv.org/pdf/2506.05065", "abs": "https://arxiv.org/abs/2506.05065", "authors": ["Marten Lienen", "Abdullah Saydemir", "Stephan G\u00fcnnemann"], "title": "UnHiPPO: Uncertainty-aware Initialization for State Space Models", "categories": ["cs.LG", "stat.ML"], "comment": "Published at ICML 2025", "summary": "State space models are emerging as a dominant model class for sequence\nproblems with many relying on the HiPPO framework to initialize their dynamics.\nHowever, HiPPO fundamentally assumes data to be noise-free; an assumption often\nviolated in practice. We extend the HiPPO theory with measurement noise and\nderive an uncertainty-aware initialization for state space model dynamics. In\nour analysis, we interpret HiPPO as a linear stochastic control problem where\nthe data enters as a noise-free control signal. We then reformulate the problem\nso that the data become noisy outputs of a latent system and arrive at an\nalternative dynamics initialization that infers the posterior of this latent\nsystem from the data without increasing runtime. Our experiments show that our\ninitialization improves the resistance of state-space models to noise both at\ntraining and inference time. Find our implementation at\nhttps://cs.cit.tum.de/daml/unhippo.", "AI": {"tldr": "Extends HiPPO theory to handle measurement noise, providing an uncertainty-aware initialization for state space models without runtime overhead.", "motivation": "HiPPO assumes noise-free data, which is often unrealistic. This work addresses this limitation by incorporating noise into the framework.", "method": "Reinterprets HiPPO as a linear stochastic control problem, reformulates it to handle noisy data, and derives a new dynamics initialization.", "result": "The proposed initialization improves noise resistance in state-space models during training and inference.", "conclusion": "The work successfully extends HiPPO to noisy settings, enhancing robustness without computational cost."}}
{"id": "2506.05088", "pdf": "https://arxiv.org/pdf/2506.05088", "abs": "https://arxiv.org/abs/2506.05088", "authors": ["Tobias Pielok", "Bernd Bischl", "David R\u00fcgamer"], "title": "Semi-Implicit Variational Inference via Kernelized Path Gradient Descent", "categories": ["cs.LG", "stat.CO", "62F15, 68T07", "I.2.6; G.3"], "comment": "Preliminary version", "summary": "Semi-implicit variational inference (SIVI) is a powerful framework for\napproximating complex posterior distributions, but training with the\nKullback-Leibler (KL) divergence can be challenging due to high variance and\nbias in high-dimensional settings. While current state-of-the-art semi-implicit\nvariational inference methods, particularly Kernel Semi-Implicit Variational\nInference (KSIVI), have been shown to work in high dimensions, training remains\nmoderately expensive. In this work, we propose a kernelized KL divergence\nestimator that stabilizes training through nonparametric smoothing. To further\nreduce the bias, we introduce an importance sampling correction. We provide a\ntheoretical connection to the amortized version of the Stein variational\ngradient descent, which estimates the score gradient via Stein's identity,\nshowing that both methods minimize the same objective, but our semi-implicit\napproach achieves lower gradient variance. In addition, our method's bias in\nfunction space is benign, leading to more stable and efficient optimization.\nEmpirical results demonstrate that our method outperforms or matches\nstate-of-the-art SIVI methods in both performance and training efficiency.", "AI": {"tldr": "Proposes a kernelized KL divergence estimator with importance sampling correction for stable and efficient semi-implicit variational inference, outperforming state-of-the-art methods.", "motivation": "Addressing high variance and bias in KL divergence training for high-dimensional semi-implicit variational inference.", "method": "Introduces a kernelized KL divergence estimator with nonparametric smoothing and importance sampling correction, connecting theoretically to Stein variational gradient descent.", "result": "Empirical results show superior performance and training efficiency compared to existing SIVI methods.", "conclusion": "The method provides stable, efficient, and high-performing semi-implicit variational inference with reduced bias and variance."}}
{"id": "2506.05101", "pdf": "https://arxiv.org/pdf/2506.05101", "abs": "https://arxiv.org/abs/2506.05101", "authors": ["Cl\u00e9ment Pierquin", "Aur\u00e9lien Bellet", "Marc Tommasi", "Matthieu Boussard"], "title": "Privacy Amplification Through Synthetic Data: Insights from Linear Regression", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": "26 pages, ICML 2025", "summary": "Synthetic data inherits the differential privacy guarantees of the model used\nto generate it. Additionally, synthetic data may benefit from privacy\namplification when the generative model is kept hidden. While empirical studies\nsuggest this phenomenon, a rigorous theoretical understanding is still lacking.\nIn this paper, we investigate this question through the well-understood\nframework of linear regression. First, we establish negative results showing\nthat if an adversary controls the seed of the generative model, a single\nsynthetic data point can leak as much information as releasing the model\nitself. Conversely, we show that when synthetic data is generated from random\ninputs, releasing a limited number of synthetic data points amplifies privacy\nbeyond the model's inherent guarantees. We believe our findings in linear\nregression can serve as a foundation for deriving more general bounds in the\nfuture.", "AI": {"tldr": "The paper explores privacy amplification in synthetic data generation, showing risks when the model's seed is exposed but benefits when using random inputs.", "motivation": "To rigorously understand privacy amplification in synthetic data, which lacks theoretical grounding despite empirical evidence.", "method": "Investigates through linear regression, analyzing scenarios where the generative model's seed is controlled by an adversary versus using random inputs.", "result": "Negative results if the seed is exposed (leaks as much as the model), but privacy amplifies with random inputs.", "conclusion": "Linear regression findings can guide future general privacy bounds for synthetic data."}}
{"id": "2506.05138", "pdf": "https://arxiv.org/pdf/2506.05138", "abs": "https://arxiv.org/abs/2506.05138", "authors": ["Pavle Vasiljevic", "Milica Matic", "Miroslav Popovic"], "title": "Federated Isolation Forest for Efficient Anomaly Detection on Edge IoT Systems", "categories": ["cs.LG", "cs.DC"], "comment": "6 pages, 4 algorithms, 5 figures, 2 tables", "summary": "Recently, federated learning frameworks such as Python TestBed for Federated\nLearning Algorithms and MicroPython TestBed for Federated Learning Algorithms\nhave emerged to tackle user privacy concerns and efficiency in embedded\nsystems. Even more recently, an efficient federated anomaly detection\nalgorithm, FLiForest, based on Isolation Forests has been developed, offering a\nlow-resource, unsupervised method well-suited for edge deployment and\ncontinuous learning. In this paper, we present an application of Isolation\nForest-based temperature anomaly detection, developed using the previously\nmentioned federated learning frameworks, aimed at small edge devices and IoT\nsystems running MicroPython. The system has been experimentally evaluated,\nachieving over 96% accuracy in distinguishing normal from abnormal readings and\nabove 78% precision in detecting anomalies across all tested configurations,\nwhile maintaining a memory usage below 160 KB during model training. These\nresults highlight its suitability for resource-constrained environments and\nedge systems, while upholding federated learning principles of data privacy and\ncollaborative learning.", "AI": {"tldr": "The paper introduces an Isolation Forest-based federated anomaly detection system (FLiForest) for edge/IoT devices, achieving high accuracy (96%) and low memory usage (<160 KB).", "motivation": "To address privacy and efficiency in embedded systems by leveraging federated learning frameworks for anomaly detection in resource-constrained environments.", "method": "Developed FLiForest, an unsupervised anomaly detection algorithm based on Isolation Forests, implemented using federated learning frameworks (Python and MicroPython).", "result": "Achieved 96% accuracy in anomaly detection and 78% precision, with memory usage under 160 KB during training.", "conclusion": "The system is effective for edge/IoT deployments, balancing privacy, efficiency, and low resource consumption."}}
{"id": "2506.05178", "pdf": "https://arxiv.org/pdf/2506.05178", "abs": "https://arxiv.org/abs/2506.05178", "authors": ["Joshua Hess", "Quaid Morris"], "title": "Associative Memory and Generative Diffusion in the Zero-noise Limit", "categories": ["cs.LG", "cond-mat.dis-nn", "math.DS", "nlin.AO", "q-bio.NC"], "comment": null, "summary": "Connections between generative diffusion and continuous-state associative\nmemory models are studied. Morse-Smale dynamical systems are emphasized as\nuniversal approximators of gradient-based associative memory models and\ndiffusion models as white-noise perturbed systems thereof. Universal properties\nof associative memory that follow from this description are described and used\nto characterize a generic transition from generation to memory as noise levels\ndiminish. Structural stability inherited by Morse-Smale flows is shown to imply\na notion of stability for diffusions at vanishing noise levels. Applied to one-\nand two-parameter families of gradients, this indicates stability at all but\nisolated points of associative memory learning landscapes and the learning and\ngeneration landscapes of diffusion models with gradient drift in the zero-noise\nlimit, at which small sets of generic bifurcations characterize qualitative\ntransitions between stable systems. Examples illustrating the characterization\nof these landscapes by sequences of these bifurcations are given, along with\nstructural stability criterion for classic and modern Hopfield networks\n(equivalently, the attention mechanism).", "AI": {"tldr": "The paper explores links between generative diffusion models and continuous-state associative memory, using Morse-Smale systems to approximate and analyze their universal properties and stability.", "motivation": "To understand the connections between generative diffusion models and associative memory models, and to characterize transitions between generation and memory as noise levels change.", "method": "Uses Morse-Smale dynamical systems as universal approximators for gradient-based associative memory and diffusion models, analyzing structural stability and bifurcations.", "result": "Shows stability in associative memory and diffusion models at vanishing noise levels, with transitions characterized by generic bifurcations.", "conclusion": "The framework provides insights into stability and transitions in associative memory and diffusion models, with applications to Hopfield networks and attention mechanisms."}}
{"id": "2506.05183", "pdf": "https://arxiv.org/pdf/2506.05183", "abs": "https://arxiv.org/abs/2506.05183", "authors": ["Zhicheng Yang", "Zhijiang Guo", "Yinya Huang", "Xiaodan Liang", "Yiwei Wang", "Jing Tang"], "title": "TreeRPO: Tree Relative Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "13pages, 6 figures", "summary": "Large Language Models (LLMs) have shown remarkable reasoning capabilities\nthrough Reinforcement Learning with Verifiable Rewards (RLVR) methods. However,\na key limitation of existing approaches is that rewards defined at the full\ntrajectory level provide insufficient guidance for optimizing the intermediate\nsteps of a reasoning process. To address this, we introduce \\textbf{\\name}, a\nnovel method that estimates the mathematical expectations of rewards at various\nreasoning steps using tree sampling. Unlike prior methods that rely on a\nseparate step reward model, \\name directly estimates these rewards through this\nsampling process. Building on the group-relative reward training mechanism of\nGRPO, \\name innovatively computes rewards based on step-level groups generated\nduring tree sampling. This advancement allows \\name to produce fine-grained and\ndense reward signals, significantly enhancing the learning process and overall\nperformance of LLMs. Experimental results demonstrate that our \\name algorithm\nsubstantially improves the average Pass@1 accuracy of Qwen-2.5-Math on test\nbenchmarks, increasing it from 19.0\\% to 35.5\\%. Furthermore, \\name\nsignificantly outperforms GRPO by 2.9\\% in performance while simultaneously\nreducing the average response length by 18.1\\%, showcasing its effectiveness\nand efficiency. Our code will be available at\n\\href{https://github.com/yangzhch6/TreeRPO}{https://github.com/yangzhch6/TreeRPO}.", "AI": {"tldr": "The paper introduces \\name, a method using tree sampling to estimate step-level rewards for LLMs, improving reasoning performance and efficiency.", "motivation": "Existing RLVR methods lack fine-grained reward signals for intermediate reasoning steps, limiting LLM optimization.", "method": "\\name estimates step-level rewards via tree sampling and uses group-relative rewards from GRPO for training.", "result": "\\name boosts Qwen-2.5-Math's Pass@1 accuracy from 19.0% to 35.5% and outperforms GRPO by 2.9% while reducing response length by 18.1%.", "conclusion": "\\name provides dense reward signals, enhancing LLM reasoning performance and efficiency, with code available for reproducibility."}}
{"id": "2506.05196", "pdf": "https://arxiv.org/pdf/2506.05196", "abs": "https://arxiv.org/abs/2506.05196", "authors": ["Jifei Luo", "Wenzheng Wu", "Hantao Yao", "Lu Yu", "Changsheng Xu"], "title": "Locality Preserving Markovian Transition for Instance Retrieval", "categories": ["cs.LG"], "comment": "This paper has been accepted by ICML2025", "summary": "Diffusion-based re-ranking methods are effective in modeling the data\nmanifolds through similarity propagation in affinity graphs. However, positive\nsignals tend to diminish over several steps away from the source, reducing\ndiscriminative power beyond local regions. To address this issue, we introduce\nthe Locality Preserving Markovian Transition (LPMT) framework, which employs a\nlong-term thermodynamic transition process with multiple states for accurate\nmanifold distance measurement. The proposed LPMT first integrates diffusion\nprocesses across separate graphs using Bidirectional Collaborative Diffusion\n(BCD) to establish strong similarity relationships. Afterwards, Locality State\nEmbedding (LSE) encodes each instance into a distribution for enhanced local\nconsistency. These distributions are interconnected via the Thermodynamic\nMarkovian Transition (TMT) process, enabling efficient global retrieval while\nmaintaining local effectiveness. Experimental results across diverse tasks\nconfirm the effectiveness of LPMT for instance retrieval.", "AI": {"tldr": "The paper introduces LPMT, a framework combining diffusion-based re-ranking with locality preservation to improve instance retrieval by maintaining local consistency and enabling global similarity propagation.", "motivation": "Diffusion-based re-ranking methods lose discriminative power over distance due to diminishing positive signals. LPMT aims to address this by preserving locality while measuring manifold distances accurately.", "method": "LPMT uses Bidirectional Collaborative Diffusion (BCD) to integrate diffusion processes across graphs, Locality State Embedding (LSE) for local consistency, and Thermodynamic Markovian Transition (TMT) for global retrieval.", "result": "Experiments show LPMT effectively improves instance retrieval across diverse tasks.", "conclusion": "LPMT successfully balances local consistency and global similarity propagation, enhancing retrieval performance."}}
{"id": "2506.05200", "pdf": "https://arxiv.org/pdf/2506.05200", "abs": "https://arxiv.org/abs/2506.05200", "authors": ["Gen Li", "Yuchen Jiao", "Yu Huang", "Yuting Wei", "Yuxin Chen"], "title": "Transformers Meet In-Context Learning: A Universal Approximation Theory", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Modern large language models are capable of in-context learning, the ability\nto perform new tasks at inference time using only a handful of input-output\nexamples in the prompt, without any fine-tuning or parameter updates. We\ndevelop a universal approximation theory to better understand how transformers\nenable in-context learning. For any class of functions (each representing a\ndistinct task), we demonstrate how to construct a transformer that, without any\nfurther weight updates, can perform reliable prediction given only a few\nin-context examples. In contrast to much of the recent literature that frames\ntransformers as algorithm approximators -- i.e., constructing transformers to\nemulate the iterations of optimization algorithms as a means to approximate\nsolutions of learning problems -- our work adopts a fundamentally different\napproach rooted in universal function approximation. This alternative approach\noffers approximation guarantees that are not constrained by the effectiveness\nof the optimization algorithms being approximated, thereby extending far beyond\nconvex problems and linear function classes. Our construction sheds light on\nhow transformers can simultaneously learn general-purpose representations and\nadapt dynamically to in-context examples.", "AI": {"tldr": "The paper develops a universal approximation theory for transformers, showing they can perform in-context learning without fine-tuning, extending beyond traditional optimization-based approaches.", "motivation": "To understand how transformers enable in-context learning and provide guarantees beyond optimization-based methods.", "method": "Constructs transformers capable of universal function approximation for any task class, using only in-context examples.", "result": "Demonstrates reliable prediction without weight updates, applicable to non-convex and non-linear problems.", "conclusion": "Transformers can learn general-purpose representations and adapt dynamically to in-context examples, offering broader guarantees than optimization-based methods."}}
{"id": "2506.05214", "pdf": "https://arxiv.org/pdf/2506.05214", "abs": "https://arxiv.org/abs/2506.05214", "authors": ["Jingyu Hu", "Hongbo Bo", "Jun Hong", "Xiaowei Liu", "Weiru Liu"], "title": "Mitigating Degree Bias Adaptively with Hard-to-Learn Nodes in Graph Contrastive Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Graph Neural Networks (GNNs) often suffer from degree bias in node\nclassification tasks, where prediction performance varies across nodes with\ndifferent degrees. Several approaches, which adopt Graph Contrastive Learning\n(GCL), have been proposed to mitigate this bias. However, the limited number of\npositive pairs and the equal weighting of all positives and negatives in GCL\nstill lead to low-degree nodes acquiring insufficient and noisy information.\nThis paper proposes the Hardness Adaptive Reweighted (HAR) contrastive loss to\nmitigate degree bias. It adds more positive pairs by leveraging node labels and\nadaptively weights positive and negative pairs based on their learning\nhardness. In addition, we develop an experimental framework named SHARP to\nextend HAR to a broader range of scenarios. Both our theoretical analysis and\nexperiments validate the effectiveness of SHARP. The experimental results\nacross four datasets show that SHARP achieves better performance against\nbaselines at both global and degree levels.", "AI": {"tldr": "The paper introduces HAR contrastive loss and SHARP framework to address degree bias in GNNs by adding more positive pairs and adaptive weighting, improving performance across datasets.", "motivation": "GNNs exhibit degree bias in node classification, and existing GCL methods fail to adequately address low-degree nodes due to limited positive pairs and noisy information.", "method": "Proposes HAR contrastive loss, which increases positive pairs using node labels and adaptively weights pairs based on learning hardness, alongside the SHARP framework for broader application.", "result": "SHARP outperforms baselines on four datasets, showing improved performance globally and across degree levels.", "conclusion": "HAR and SHARP effectively mitigate degree bias in GNNs, enhancing node classification performance."}}
{"id": "2506.05215", "pdf": "https://arxiv.org/pdf/2506.05215", "abs": "https://arxiv.org/abs/2506.05215", "authors": ["Zhan Yu"], "title": "Learning Theory of Decentralized Robust Kernel-Based Learning Algorithm", "categories": ["cs.LG"], "comment": null, "summary": "We propose a new decentralized robust kernel-based learning algorithm within\nthe framework of reproducing kernel Hilbert space (RKHS) by utilizing a\nnetworked system that can be represented as a connected graph. The robust loss\nfunction $\\mathcal{L}_\\sigma$ induced by a windowing function $W$ and a\nrobustness scaling parameter $\\sigma>0$, can encompass a broad spectrum of\nrobust losses. Consequently, the proposed algorithm effectively provides a\nunified decentralized learning framework for robust regression, which\nfundamentally differs from the existing distributed robust kernel learning\nschemes, all of which are divide-and-conquer based. We rigorously establish the\nlearning theory and offer a comprehensive convergence analysis for the\nalgorithm. We show each local robust estimator generated from the decentralized\nalgorithm can be utilized to approximate the regression function. Based on\nkernel-based integral operator techniques, we derive general high confidence\nconvergence bounds for each local approximating sequence in terms of the mean\nsquare distance, RKHS norm, and generalization error, respectively. Moreover,\nwe provide rigorous selection rules for local sample size and show that, under\nproperly selected step size and scaling parameter $\\sigma$, the decentralized\nrobust algorithm can achieve optimal learning rates (up to logarithmic factors)\nin both norms. The parameter $\\sigma$ is shown to be essential for enhancing\nrobustness while also ensuring favorable convergence behavior. The intrinsic\nconnection among decentralization, sample selection, robustness of the\nalgorithm, and its convergence is clearly reflected.", "AI": {"tldr": "A decentralized robust kernel-based learning algorithm in RKHS is proposed, unifying robust regression with rigorous convergence analysis and optimal learning rates.", "motivation": "To address the limitations of existing distributed robust kernel learning schemes by introducing a decentralized framework that enhances robustness and convergence.", "method": "Utilizes a networked system represented as a graph, employs a robust loss function with a windowing function and scaling parameter, and derives convergence bounds using kernel-based integral operator techniques.", "result": "Local robust estimators approximate the regression function with high confidence bounds in mean square distance, RKHS norm, and generalization error. Optimal learning rates are achieved with proper parameter selection.", "conclusion": "The algorithm's robustness and convergence are enhanced by the scaling parameter, providing a unified decentralized learning framework with theoretical guarantees."}}
{"id": "2506.05216", "pdf": "https://arxiv.org/pdf/2506.05216", "abs": "https://arxiv.org/abs/2506.05216", "authors": ["Tyler Chen", "Akshay Seshadri", "Mattia J. Villani", "Pradeep Niroula", "Shouvanik Chakrabarti", "Archan Ray", "Pranav Deshpande", "Romina Yalovetzky", "Marco Pistoia", "Niraj Kumar"], "title": "A Unified Framework for Provably Efficient Algorithms to Estimate Shapley Values", "categories": ["cs.LG", "cs.DS", "quant-ph"], "comment": "44 pages, 7 figures, 7 tables", "summary": "Shapley values have emerged as a critical tool for explaining which features\nimpact the decisions made by machine learning models. However, computing exact\nShapley values is difficult, generally requiring an exponential (in the feature\ndimension) number of model evaluations. To address this, many model-agnostic\nrandomized estimators have been developed, the most influential and widely used\nbeing the KernelSHAP method (Lundberg & Lee, 2017). While related estimators\nsuch as unbiased KernelSHAP (Covert & Lee, 2021) and LeverageSHAP (Musco &\nWitter, 2025) are known to satisfy theoretical guarantees, bounds for\nKernelSHAP have remained elusive. We describe a broad and unified framework\nthat encompasses KernelSHAP and related estimators constructed using both with\nand without replacement sampling strategies. We then prove strong\nnon-asymptotic theoretical guarantees that apply to all estimators from our\nframework. This provides, to the best of our knowledge, the first theoretical\nguarantees for KernelSHAP and sheds further light on tradeoffs between existing\nestimators. Through comprehensive benchmarking on small and medium dimensional\ndatasets for Decision-Tree models, we validate our approach against exact\nShapley values, consistently achieving low mean squared error with modest\nsample sizes. Furthermore, we make specific implementation improvements to\nenable scalability of our methods to high-dimensional datasets. Our methods,\ntested on datasets such MNIST and CIFAR10, provide consistently better results\ncompared to the KernelSHAP library.", "AI": {"tldr": "The paper presents a unified framework for Shapley value estimators, including KernelSHAP, and provides the first theoretical guarantees for KernelSHAP. It validates the approach on datasets and improves scalability for high-dimensional data.", "motivation": "Exact Shapley value computation is computationally expensive, and existing randomized estimators lack theoretical guarantees for KernelSHAP. The paper aims to address this gap.", "method": "The authors develop a broad framework for Shapley value estimators, including KernelSHAP, and prove non-asymptotic theoretical guarantees. They benchmark the approach on Decision-Tree models and improve scalability for high-dimensional datasets.", "result": "The framework achieves low mean squared error with modest sample sizes and outperforms the KernelSHAP library on datasets like MNIST and CIFAR10.", "conclusion": "The paper provides the first theoretical guarantees for KernelSHAP and offers a scalable, unified framework for Shapley value estimation, improving accuracy and efficiency."}}
{"id": "2506.05229", "pdf": "https://arxiv.org/pdf/2506.05229", "abs": "https://arxiv.org/abs/2506.05229", "authors": ["Danil Sivtsov", "Ivan Rodkin", "Gleb Kuzmin", "Yuri Kuratov", "Ivan Oseledets"], "title": "Diagonal Batching Unlocks Parallelism in Recurrent Memory Transformers for Long Contexts", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Transformer models struggle with long-context inference due to their\nquadratic time and linear memory complexity. Recurrent Memory Transformers\n(RMTs) offer a solution by reducing the asymptotic cost to linear time and\nconstant memory usage. However, their memory update mechanism leads to\nsequential execution, causing a performance bottleneck.\n  We introduce Diagonal Batching, a scheduling scheme that unlocks parallelism\nacross segments in RMTs while preserving exact recurrence. This approach\neliminates the sequential constraint, enabling efficient GPU inference even for\nsingle long-context inputs without complex batching and pipelining techniques.\nBecause the technique is purely a run-time computation reordering, existing RMT\nmodels adopt it with no retraining.\n  Applied to a LLaMA-1B ARMT model, Diagonal Batching yields a 3.3x speedup\nover standard full-attention LLaMA-1B and a 1.8x speedup over the sequential\nRMT implementation on 131,072-token sequences. By removing sequential\nbottleneck, Diagonal Batching reduces inference cost and latency, thereby\nstrengthening RMTs as a practical solution for real-world, long-context\napplications.", "AI": {"tldr": "Diagonal Batching improves RMTs by enabling parallelism across segments, reducing inference time and cost for long-context tasks without retraining.", "motivation": "Transformer models face inefficiencies in long-context inference due to quadratic time and linear memory complexity. RMTs address this but introduce sequential bottlenecks.", "method": "Diagonal Batching is introduced as a scheduling scheme to parallelize RMT execution while maintaining exact recurrence, avoiding sequential constraints.", "result": "Diagonal Batching achieves a 3.3x speedup over standard LLaMA-1B and 1.8x over sequential RMT on 131,072-token sequences.", "conclusion": "Diagonal Batching makes RMTs more practical for real-world long-context applications by reducing latency and inference costs."}}
{"id": "2506.05231", "pdf": "https://arxiv.org/pdf/2506.05231", "abs": "https://arxiv.org/abs/2506.05231", "authors": ["Severi Rissanen", "RuiKang OuYang", "Jiajun He", "Wenlin Chen", "Markus Heinonen", "Arno Solin", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"], "title": "Progressive Tempering Sampler with Diffusion", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted for publication at ICML 2025", "summary": "Recent research has focused on designing neural samplers that amortize the\nprocess of sampling from unnormalized densities. However, despite significant\nadvancements, they still fall short of the state-of-the-art MCMC approach,\nParallel Tempering (PT), when it comes to the efficiency of target evaluations.\nOn the other hand, unlike a well-trained neural sampler, PT yields only\ndependent samples and needs to be rerun -- at considerable computational cost\n-- whenever new samples are required. To address these weaknesses, we propose\nthe Progressive Tempering Sampler with Diffusion (PTSD), which trains diffusion\nmodels sequentially across temperatures, leveraging the advantages of PT to\nimprove the training of neural samplers. We also introduce a novel method to\ncombine high-temperature diffusion models to generate approximate\nlower-temperature samples, which are minimally refined using MCMC and used to\ntrain the next diffusion model. PTSD enables efficient reuse of sample\ninformation across temperature levels while generating well-mixed, uncorrelated\nsamples. Our method significantly improves target evaluation efficiency,\noutperforming diffusion-based neural samplers.", "AI": {"tldr": "PTSD combines diffusion models and MCMC to improve neural samplers, outperforming diffusion-based methods in efficiency.", "motivation": "Current neural samplers lag behind MCMC methods like Parallel Tempering in efficiency, and PT has limitations like dependent samples and high computational costs for new samples.", "method": "PTSD trains diffusion models sequentially across temperatures, using PT's advantages. It combines high-temperature models to generate approximate samples, refined with MCMC for training the next model.", "result": "PTSD generates well-mixed, uncorrelated samples efficiently, improving target evaluation efficiency over diffusion-based neural samplers.", "conclusion": "PTSD effectively addresses weaknesses of both neural samplers and PT, offering a more efficient and reusable sampling method."}}
{"id": "2506.05233", "pdf": "https://arxiv.org/pdf/2506.05233", "abs": "https://arxiv.org/abs/2506.05233", "authors": ["Johannes von Oswald", "Nino Scherrer", "Seijin Kobayashi", "Luca Versari", "Songlin Yang", "Maximilian Schlegel", "Kaitlin Maile", "Yanick Schimpf", "Oliver Sieberling", "Alexander Meulemans", "Rif A. Saurous", "Guillaume Lajoie", "Charlotte Frenkel", "Razvan Pascanu", "Blaise Ag\u00fcera y Arcas", "Jo\u00e3o Sacramento"], "title": "MesaNet: Sequence Modeling by Locally Optimal Test-Time Training", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Sequence modeling is currently dominated by causal transformer architectures\nthat use softmax self-attention. Although widely adopted, transformers require\nscaling memory and compute linearly during inference. A recent stream of work\nlinearized the softmax operation, resulting in powerful recurrent neural\nnetwork (RNN) models with constant memory and compute costs such as DeltaNet,\nMamba or xLSTM. These models can be unified by noting that their recurrent\nlayer dynamics can all be derived from an in-context regression objective,\napproximately optimized through an online learning rule. Here, we join this\nline of work and introduce a numerically stable, chunkwise parallelizable\nversion of the recently proposed Mesa layer (von Oswald et al., 2024), and\nstudy it in language modeling at the billion-parameter scale. This layer again\nstems from an in-context loss, but which is now minimized to optimality at\nevery time point using a fast conjugate gradient solver. Through an extensive\nsuite of experiments, we show that optimal test-time training enables reaching\nlower language modeling perplexity and higher downstream benchmark performance\nthan previous RNNs, especially on tasks requiring long context understanding.\nThis performance gain comes at the cost of additional flops spent during\ninference time. Our results are therefore intriguingly related to recent trends\nof increasing test-time compute to improve performance -- here by spending\ncompute to solve sequential optimization problems within the neural network\nitself.", "AI": {"tldr": "The paper introduces a stable, parallelizable version of the Mesa layer, derived from an in-context regression objective, and demonstrates its superior performance in language modeling, especially for long-context tasks, at the cost of increased inference compute.", "motivation": "Transformers dominate sequence modeling but have linear memory and compute scaling. Recent RNN models like DeltaNet and Mamba offer constant costs. This work aims to unify these models under an in-context regression objective and improve performance.", "method": "The paper introduces a numerically stable, chunkwise parallelizable Mesa layer, optimized using a fast conjugate gradient solver for in-context loss minimization at every time point.", "result": "The proposed Mesa layer achieves lower perplexity and better downstream performance than previous RNNs, particularly in long-context tasks, though it requires additional inference compute.", "conclusion": "Optimal test-time training via sequential optimization within the network improves performance, aligning with trends of increasing test-time compute for better results."}}
{"id": "2506.05239", "pdf": "https://arxiv.org/pdf/2506.05239", "abs": "https://arxiv.org/abs/2506.05239", "authors": ["Val\u00e9rie Costa", "Thomas Fel", "Ekdeep Singh Lubana", "Bahareh Tolooshams", "Demba Ba"], "title": "Evaluating Sparse Autoencoders: From Shallow Design to Matching Pursuit", "categories": ["cs.LG"], "comment": "Complementary work to arXiv:2506.03093", "summary": "Sparse autoencoders (SAEs) have recently become central tools for\ninterpretability, leveraging dictionary learning principles to extract sparse,\ninterpretable features from neural representations whose underlying structure\nis typically unknown. This paper evaluates SAEs in a controlled setting using\nMNIST, which reveals that current shallow architectures implicitly rely on a\nquasi-orthogonality assumption that limits the ability to extract correlated\nfeatures. To move beyond this, we introduce a multi-iteration SAE by unrolling\nMatching Pursuit (MP-SAE), enabling the residual-guided extraction of\ncorrelated features that arise in hierarchical settings such as handwritten\ndigit generation while guaranteeing monotonic improvement of the reconstruction\nas more atoms are selected.", "AI": {"tldr": "The paper evaluates sparse autoencoders (SAEs) in a controlled MNIST setting, identifies limitations due to quasi-orthogonality assumptions, and proposes a multi-iteration SAE (MP-SAE) to extract correlated features effectively.", "motivation": "Current shallow SAE architectures struggle with extracting correlated features due to quasi-orthogonality assumptions, limiting interpretability in hierarchical settings like handwritten digit generation.", "method": "The authors introduce a multi-iteration SAE by unrolling Matching Pursuit (MP-SAE), which allows residual-guided extraction of correlated features and guarantees monotonic reconstruction improvement.", "result": "MP-SAE successfully extracts correlated features in hierarchical settings, overcoming the limitations of traditional SAEs.", "conclusion": "The proposed MP-SAE advances SAE capabilities for interpretability by addressing the quasi-orthogonality constraint and improving feature extraction in complex scenarios."}}
{"id": "2506.05240", "pdf": "https://arxiv.org/pdf/2506.05240", "abs": "https://arxiv.org/abs/2506.05240", "authors": ["Yizhuo Li", "Yuying Ge", "Yixiao Ge", "Ying Shan", "Ping Luo"], "title": "Aligning Latent Spaces with Flow Priors", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "This paper presents a novel framework for aligning learnable latent spaces to\narbitrary target distributions by leveraging flow-based generative models as\npriors. Our method first pretrains a flow model on the target features to\ncapture the underlying distribution. This fixed flow model subsequently\nregularizes the latent space via an alignment loss, which reformulates the flow\nmatching objective to treat the latents as optimization targets. We formally\nprove that minimizing this alignment loss establishes a computationally\ntractable surrogate objective for maximizing a variational lower bound on the\nlog-likelihood of latents under the target distribution. Notably, the proposed\nmethod eliminates computationally expensive likelihood evaluations and avoids\nODE solving during optimization. As a proof of concept, we demonstrate in a\ncontrolled setting that the alignment loss landscape closely approximates the\nnegative log-likelihood of the target distribution. We further validate the\neffectiveness of our approach through large-scale image generation experiments\non ImageNet with diverse target distributions, accompanied by detailed\ndiscussions and ablation studies. With both theoretical and empirical\nvalidation, our framework paves a new way for latent space alignment.", "AI": {"tldr": "A novel framework aligns learnable latent spaces to target distributions using flow-based generative models, avoiding expensive likelihood evaluations and ODE solving.", "motivation": "To align latent spaces with arbitrary target distributions efficiently, leveraging flow models as priors.", "method": "Pretrains a flow model on target features, then regularizes latent space via an alignment loss derived from flow matching.", "result": "The alignment loss approximates the negative log-likelihood of the target distribution, validated in controlled and large-scale experiments.", "conclusion": "The framework offers a computationally efficient and theoretically grounded approach for latent space alignment."}}
{"id": "2506.05249", "pdf": "https://arxiv.org/pdf/2506.05249", "abs": "https://arxiv.org/abs/2506.05249", "authors": ["Zhen Qin", "Jinxin Zhou", "Zhihui Zhu"], "title": "On the Convergence of Gradient Descent on Learning Transformers with Residual Connections", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Transformer models have emerged as fundamental tools across various\nscientific and engineering disciplines, owing to their outstanding performance\nin diverse applications. Despite this empirical success, the theoretical\nfoundations of Transformers remain relatively underdeveloped, particularly in\nunderstanding their training dynamics. Existing research predominantly examines\nisolated components--such as self-attention mechanisms and feedforward\nnetworks--without thoroughly investigating the interdependencies between these\ncomponents, especially when residual connections are present. In this paper, we\naim to bridge this gap by analyzing the convergence behavior of a structurally\ncomplete yet single-layer Transformer, comprising self-attention, a feedforward\nnetwork, and residual connections. We demonstrate that, under appropriate\ninitialization, gradient descent exhibits a linear convergence rate, where the\nconvergence speed is determined by the minimum and maximum singular values of\nthe output matrix from the attention layer. Moreover, our analysis reveals that\nresidual connections serve to ameliorate the ill-conditioning of this output\nmatrix, an issue stemming from the low-rank structure imposed by the softmax\noperation, thereby promoting enhanced optimization stability. We also extend\nour theoretical findings to a multi-layer Transformer architecture, confirming\nthe linear convergence rate of gradient descent under suitable initialization.\nEmpirical results corroborate our theoretical insights, illustrating the\nbeneficial role of residual connections in promoting convergence stability.", "AI": {"tldr": "The paper analyzes the convergence behavior of a single-layer Transformer with self-attention, feedforward networks, and residual connections, showing linear convergence under proper initialization and highlighting the role of residual connections in stability.", "motivation": "Despite the empirical success of Transformers, their theoretical foundations, especially training dynamics and component interdependencies, are underdeveloped.", "method": "The study examines a structurally complete single-layer Transformer, analyzing gradient descent convergence and the impact of residual connections.", "result": "Gradient descent exhibits linear convergence, influenced by the attention layer's output matrix singular values. Residual connections improve optimization stability.", "conclusion": "The findings extend to multi-layer Transformers, with empirical results supporting the theoretical insights on residual connections' benefits."}}
{"id": "2506.05252", "pdf": "https://arxiv.org/pdf/2506.05252", "abs": "https://arxiv.org/abs/2506.05252", "authors": ["Dravyansh Sharma", "Alec Sun"], "title": "Conservative classifiers do consistently well with improving agents: characterizing statistical and online learning", "categories": ["cs.LG", "cs.GT", "cs.MA"], "comment": "24 pages", "summary": "Machine learning is now ubiquitous in societal decision-making, for example\nin evaluating job candidates or loan applications, and it is increasingly\nimportant to take into account how classified agents will react to the learning\nalgorithms. The majority of recent literature on strategic classification has\nfocused on reducing and countering deceptive behaviors by the classified\nagents, but recent work of Attias et al. identifies surprising properties of\nlearnability when the agents genuinely improve in order to attain the desirable\nclassification, such as smaller generalization error than standard\nPAC-learning. In this paper we characterize so-called learnability with\nimprovements across multiple new axes. We introduce an asymmetric variant of\nminimally consistent concept classes and use it to provide an exact\ncharacterization of proper learning with improvements in the realizable\nsetting. While prior work studies learnability only under general, arbitrary\nagent improvement regions, we give positive results for more natural Euclidean\nball improvement sets. In particular, we characterize improper learning under a\nmild generative assumption on the data distribution. We further show how to\nlearn in more challenging settings, achieving lower generalization error under\nwell-studied bounded noise models and obtaining mistake bounds in realizable\nand agnostic online learning. We resolve open questions posed by Attias et al.\nfor both proper and improper learning.", "AI": {"tldr": "The paper explores learnability in strategic classification, focusing on genuine agent improvements, and provides new characterizations and positive results for proper and improper learning in various settings.", "motivation": "Machine learning is widely used in societal decision-making, and understanding how agents react to learning algorithms is crucial. While most research focuses on deceptive behaviors, this paper investigates learnability when agents genuinely improve.", "method": "The study introduces an asymmetric variant of minimally consistent concept classes, examines Euclidean ball improvement sets, and addresses learning under bounded noise models and online settings.", "result": "The paper characterizes proper learning in the realizable setting, provides positive results for natural improvement regions, and resolves open questions from prior work.", "conclusion": "The findings advance understanding of learnability with improvements, offering practical insights for strategic classification in real-world applications."}}
{"id": "2506.05259", "pdf": "https://arxiv.org/pdf/2506.05259", "abs": "https://arxiv.org/abs/2506.05259", "authors": ["Guillaume Pourcel", "Maxence Ernoult"], "title": "Learning long range dependencies through time reversal symmetry breaking", "categories": ["cs.LG"], "comment": "45 pages", "summary": "Deep State Space Models (SSMs) reignite physics-grounded compute paradigms,\nas RNNs could natively be embodied into dynamical systems. This calls for\ndedicated learning algorithms obeying to core physical principles, with\nefficient techniques to simulate these systems and guide their design. We\npropose Recurrent Hamiltonian Echo Learning (RHEL), an algorithm which provably\ncomputes loss gradients as finite differences of physical trajectories of\nnon-dissipative, Hamiltonian systems. In ML terms, RHEL only requires three\n\"forward passes\" irrespective of model size, without explicit Jacobian\ncomputation, nor incurring any variance in the gradient estimation. Motivated\nby the physical realization of our algorithm, we first introduce RHEL in\ncontinuous time and demonstrate its formal equivalence with the continuous\nadjoint state method. To facilitate the simulation of Hamiltonian systems\ntrained by RHEL, we propose a discrete-time version of RHEL which is equivalent\nto Backpropagation Through Time (BPTT) when applied to a class of recurrent\nmodules which we call Hamiltonian Recurrent Units (HRUs). This setting allows\nus to demonstrate the scalability of RHEL by generalizing these results to\nhierarchies of HRUs, which we call Hamiltonian SSMs (HSSMs). We apply RHEL to\ntrain HSSMs with linear and nonlinear dynamics on a variety of time-series\ntasks ranging from mid-range to long-range classification and regression with\nsequence length reaching $\\sim 50k$. We show that RHEL consistently matches the\nperformance of BPTT across all models and tasks. This work opens new doors for\nthe design of scalable, energy-efficient physical systems endowed with\nself-learning capabilities for sequence modelling.", "AI": {"tldr": "The paper introduces Recurrent Hamiltonian Echo Learning (RHEL), a physics-grounded algorithm for training deep state space models (SSMs) efficiently, matching BPTT performance without explicit Jacobian computation.", "motivation": "To develop learning algorithms for SSMs that adhere to physical principles, enabling efficient simulation and scalable design.", "method": "Proposes RHEL, which computes gradients as finite differences of Hamiltonian system trajectories, requiring only three forward passes. Introduces Hamiltonian Recurrent Units (HRUs) and extends to hierarchical Hamiltonian SSMs (HSSMs).", "result": "RHEL matches BPTT performance on time-series tasks with sequences up to ~50k, demonstrating scalability and efficiency.", "conclusion": "RHEL enables scalable, energy-efficient physical systems with self-learning capabilities for sequence modeling, bridging physics and ML."}}
{"id": "2506.05271", "pdf": "https://arxiv.org/pdf/2506.05271", "abs": "https://arxiv.org/abs/2506.05271", "authors": ["Daniel Berg Thomsen", "Adrien Taylor", "Aymeric Dieuleveut"], "title": "Tight analyses of first-order methods with error feedback", "categories": ["cs.LG", "cs.DC", "math.OC"], "comment": null, "summary": "Communication between agents often constitutes a major computational\nbottleneck in distributed learning. One of the most common mitigation\nstrategies is to compress the information exchanged, thereby reducing\ncommunication overhead. To counteract the degradation in convergence associated\nwith compressed communication, error feedback schemes -- most notably\n$\\mathrm{EF}$ and $\\mathrm{EF}^{21}$ -- were introduced. In this work, we\nprovide a tight analysis of both of these methods. Specifically, we find the\nLyapunov function that yields the best possible convergence rate for each\nmethod -- with matching lower bounds. This principled approach yields sharp\nperformance guarantees and enables a rigorous, apples-to-apples comparison\nbetween $\\mathrm{EF}$, $\\mathrm{EF}^{21}$, and compressed gradient descent. Our\nanalysis is carried out in a simplified yet representative setting, which\nallows for clean theoretical insights and fair comparison of the underlying\nmechanisms.", "AI": {"tldr": "The paper provides a tight analysis of error feedback schemes (EF and EF\u00b2\u00b9) in distributed learning, comparing their convergence rates and performance against compressed gradient descent.", "motivation": "Communication bottlenecks in distributed learning due to compressed information exchange degrade convergence, prompting the need for precise analysis of error feedback methods.", "method": "The study uses Lyapunov functions to derive optimal convergence rates for EF and EF\u00b2\u00b9, with matching lower bounds, in a simplified theoretical setting.", "result": "The analysis yields sharp performance guarantees and enables a rigorous comparison between EF, EF\u00b2\u00b9, and compressed gradient descent.", "conclusion": "The principled approach clarifies the effectiveness of error feedback schemes and provides a framework for fair comparison in distributed learning."}}
{"id": "2506.05276", "pdf": "https://arxiv.org/pdf/2506.05276", "abs": "https://arxiv.org/abs/2506.05276", "authors": ["Hao Yu", "Chu Xin Cheng", "Runlong Yu", "Yuyang Ye", "Shiwei Tong", "Zhaofeng Liu", "Defu Lian"], "title": "How to Unlock Time Series Editing? Diffusion-Driven Approach with Multi-Grained Control", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in time series generation have shown promise, yet controlling\nproperties in generated sequences remains challenging. Time Series Editing\n(TSE) - making precise modifications while preserving temporal coherence -\nconsider both point-level constraints and segment-level controls that current\nmethods struggle to provide. We introduce the CocktailEdit framework to enable\nsimultaneous, flexible control across different types of constraints. This\nframework combines two key mechanisms: a confidence-weighted anchor control for\npoint-wise constraints and a classifier-based control for managing statistical\nproperties such as sums and averages over segments. Our methods achieve precise\nlocal control during the denoising inference stage while maintaining temporal\ncoherence and integrating seamlessly, with any conditionally trained\ndiffusion-based time series models. Extensive experiments across diverse\ndatasets and models demonstrate its effectiveness. Our work bridges the gap\nbetween pure generative modeling and real-world time series editing needs,\noffering a flexible solution for human-in-the-loop time series generation and\nediting. The code and demo are provided for validation.", "AI": {"tldr": "The paper introduces CocktailEdit, a framework for flexible and precise time series editing, combining point-level and segment-level controls while maintaining temporal coherence.", "motivation": "Current methods struggle with simultaneously controlling point-level and segment-level properties in time series generation, limiting practical applications.", "method": "CocktailEdit uses confidence-weighted anchor control for point-wise constraints and classifier-based control for segment-level statistical properties, integrating with diffusion-based models.", "result": "The framework achieves precise local control and temporal coherence, validated across diverse datasets and models.", "conclusion": "CocktailEdit bridges generative modeling and real-world editing needs, offering a flexible solution for human-in-the-loop time series tasks."}}
{"id": "2506.05281", "pdf": "https://arxiv.org/pdf/2506.05281", "abs": "https://arxiv.org/abs/2506.05281", "authors": ["Haifeng Sun", "Yu Xiong", "Runze Wu", "Xinyu Cai", "Changjie Fan", "Lan Zhang", "Xiang-Yang Li"], "title": "Fast-DataShapley: Neural Modeling for Training Data Valuation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The value and copyright of training data are crucial in the artificial\nintelligence industry. Service platforms should protect data providers'\nlegitimate rights and fairly reward them for their contributions. Shapley\nvalue, a potent tool for evaluating contributions, outperforms other methods in\ntheory, but its computational overhead escalates exponentially with the number\nof data providers. Recent works based on Shapley values attempt to mitigate\ncomputation complexity by approximation algorithms. However, they need to\nretrain for each test sample, leading to intolerable costs. We propose\nFast-DataShapley, a one-pass training method that leverages the weighted least\nsquares characterization of the Shapley value to train a reusable explainer\nmodel with real-time reasoning speed. Given new test samples, no retraining is\nrequired to calculate the Shapley values of the training data. Additionally, we\npropose three methods with theoretical guarantees to reduce training overhead\nfrom two aspects: the approximate calculation of the utility function and the\ngroup calculation of the training data. We analyze time complexity to show the\nefficiency of our methods. The experimental evaluations on various image\ndatasets demonstrate superior performance and efficiency compared to baselines.\nSpecifically, the performance is improved to more than 2.5 times, and the\nexplainer's training speed can be increased by two orders of magnitude.", "AI": {"tldr": "Fast-DataShapley is a one-pass training method for efficiently computing Shapley values of training data without retraining, improving performance and speed.", "motivation": "The need to fairly reward data providers and protect their rights, coupled with the computational inefficiency of existing Shapley value methods.", "method": "Leverages weighted least squares to train a reusable explainer model, with three methods to reduce training overhead.", "result": "Performance improved by 2.5x, and training speed increased by two orders of magnitude.", "conclusion": "Fast-DataShapley offers an efficient, scalable solution for evaluating data contributions in AI."}}
{"id": "2506.05294", "pdf": "https://arxiv.org/pdf/2506.05294", "abs": "https://arxiv.org/abs/2506.05294", "authors": ["Arnav Kumar Jain", "Vibhakar Mohta", "Subin Kim", "Atiksh Bhardwaj", "Juntao Ren", "Yunhai Feng", "Sanjiban Choudhury", "Gokul Swamy"], "title": "A Smooth Sea Never Made a Skilled $\\texttt{SAILOR}$: Robust Imitation via Learning to Search", "categories": ["cs.LG"], "comment": null, "summary": "The fundamental limitation of the behavioral cloning (BC) approach to\nimitation learning is that it only teaches an agent what the expert did at\nstates the expert visited. This means that when a BC agent makes a mistake\nwhich takes them out of the support of the demonstrations, they often don't\nknow how to recover from it. In this sense, BC is akin to giving the agent the\nfish -- giving them dense supervision across a narrow set of states -- rather\nthan teaching them to fish: to be able to reason independently about achieving\nthe expert's outcome even when faced with unseen situations at test-time. In\nresponse, we explore learning to search (L2S) from expert demonstrations, i.e.\nlearning the components required to, at test time, plan to match expert\noutcomes, even after making a mistake. These include (1) a world model and (2)\na reward model. We carefully ablate the set of algorithmic and design decisions\nrequired to combine these and other components for stable and\nsample/interaction-efficient learning of recovery behavior without additional\nhuman corrections. Across a dozen visual manipulation tasks from three\nbenchmarks, our approach $\\texttt{SAILOR}$ consistently out-performs\nstate-of-the-art Diffusion Policies trained via BC on the same data.\nFurthermore, scaling up the amount of demonstrations used for BC by\n5-10$\\times$ still leaves a performance gap. We find that $\\texttt{SAILOR}$ can\nidentify nuanced failures and is robust to reward hacking. Our code is\navailable at https://github.com/arnavkj1995/SAILOR .", "AI": {"tldr": "The paper introduces SAILOR, a method for imitation learning that improves upon behavioral cloning (BC) by enabling agents to recover from mistakes using learned world and reward models.", "motivation": "BC's limitation is its inability to recover from mistakes outside the expert's demonstrated states. The goal is to teach agents to plan and recover independently.", "method": "The approach, SAILOR, learns a world model and a reward model from expert demonstrations, enabling planning for recovery without additional human corrections.", "result": "SAILOR outperforms state-of-the-art BC methods across multiple tasks, even with 5-10x more BC demonstrations, and shows robustness to reward hacking.", "conclusion": "SAILOR effectively addresses BC's recovery limitations, demonstrating superior performance and robustness in imitation learning tasks."}}
{"id": "2506.05295", "pdf": "https://arxiv.org/pdf/2506.05295", "abs": "https://arxiv.org/abs/2506.05295", "authors": ["Baihe Huang", "Shanda Li", "Tianhao Wu", "Yiming Yang", "Ameet Talwalkar", "Kannan Ramchandran", "Michael I. Jordan", "Jiantao Jiao"], "title": "Sample Complexity and Representation Ability of Test-time Scaling Paradigms", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Test-time scaling paradigms have significantly advanced the capabilities of\nlarge language models (LLMs) on complex tasks. Despite their empirical success,\ntheoretical understanding of the sample efficiency of various test-time\nstrategies -- such as self-consistency, best-of-$n$, and self-correction --\nremains limited. In this work, we first establish a separation result between\ntwo repeated sampling strategies: self-consistency requires\n$\\Theta(1/\\Delta^2)$ samples to produce the correct answer, while best-of-$n$\nonly needs $\\Theta(1/\\Delta)$, where $\\Delta < 1$ denotes the probability gap\nbetween the correct and second most likely answers. Next, we present an\nexpressiveness result for the self-correction approach with verifier feedback:\nit enables Transformers to simulate online learning over a pool of experts at\ntest time. Therefore, a single Transformer architecture can provably solve\nmultiple tasks without prior knowledge of the specific task associated with a\nuser query, extending the representation theory of Transformers from\nsingle-task to multi-task settings. Finally, we empirically validate our\ntheoretical results, demonstrating the practical effectiveness of\nself-correction methods.", "AI": {"tldr": "The paper analyzes the sample efficiency of test-time strategies for LLMs, showing self-consistency requires more samples than best-of-$n$, and proves self-correction with verifier feedback enables Transformers to handle multi-task settings.", "motivation": "To theoretically understand the sample efficiency of test-time strategies like self-consistency, best-of-$n$, and self-correction, and extend Transformer capabilities to multi-task settings.", "method": "Establishes separation results for sample efficiency, presents expressiveness results for self-correction with verifier feedback, and empirically validates findings.", "result": "Self-consistency needs \u0398(1/\u0394\u00b2) samples, best-of-$n$ needs \u0398(1/\u0394); self-correction enables multi-task learning without prior task knowledge.", "conclusion": "Theoretical and empirical results highlight the practical effectiveness of self-correction methods and extend Transformer representation theory to multi-task settings."}}
{"id": "2506.05300", "pdf": "https://arxiv.org/pdf/2506.05300", "abs": "https://arxiv.org/abs/2506.05300", "authors": ["Nirav Koley", "Prajwal Singhania", "Abhinav Bhatele"], "title": "Power Law Guided Dynamic Sifting for Efficient Attention", "categories": ["cs.LG"], "comment": null, "summary": "Efficient inference on GPUs using large language models remains challenging\ndue to memory bandwidth limitations, particularly during data transfers between\nHigh Bandwidth Memory (HBM) and SRAM in attention computations. Approximate\nattention methods address this issue by reducing computational and memory\noverhead but often rely on expensive top-$k$ operations, which perform poorly\non GPUs. We propose SiftAttention, a novel approximate attention method that\nreplaces the top-$k$ step with a computationally efficient element-wise\nfiltering operation based on a threshold value. Our intuition for doing this is\nbased on our empirical observation that the $\\tau$-th quantile of attention\nscores follows a predictable power-law over sequential generation steps.\nExploiting this insight, our approach dynamically estimates a threshold value\nper prompt at each generation step. Only attention scores above this threshold\nand their corresponding value vectors are loaded/used to compute the attention\noutput, reducing data movement between HBM and SRAM. Our evaluation\ndemonstrates that SiftAttention preserves model quality better than existing\napproximate attention methods while reducing memory bandwidth usage when\nloading value vectors.", "AI": {"tldr": "SiftAttention introduces a threshold-based filtering method for approximate attention, reducing GPU memory bandwidth usage while maintaining model quality.", "motivation": "Addressing inefficiencies in GPU inference due to memory bandwidth limitations during attention computations, particularly with top-$k$ operations.", "method": "Replaces top-$k$ operations with a threshold-based filtering step, dynamically estimating thresholds per prompt to reduce data movement.", "result": "Outperforms existing methods in preserving model quality and reducing memory bandwidth usage.", "conclusion": "SiftAttention offers an efficient alternative to traditional approximate attention methods for GPU-based inference."}}
{"id": "2506.05310", "pdf": "https://arxiv.org/pdf/2506.05310", "abs": "https://arxiv.org/abs/2506.05310", "authors": ["Florentin Guth", "Zahra Kadkhodaie", "Eero P Simoncelli"], "title": "Learning normalized image densities via dual score matching", "categories": ["cs.LG"], "comment": null, "summary": "Learning probability models from data is at the heart of many machine\nlearning endeavors, but is notoriously difficult due to the curse of\ndimensionality. We introduce a new framework for learning \\emph{normalized}\nenergy (log probability) models that is inspired from diffusion generative\nmodels, which rely on networks optimized to estimate the score. We modify a\nscore network architecture to compute an energy while preserving its inductive\nbiases. The gradient of this energy network with respect to its input image is\nthe score of the learned density, which can be optimized using a denoising\nobjective. Importantly, the gradient with respect to the noise level provides\nan additional score that can be optimized with a novel secondary objective,\nensuring consistent and normalized energies across noise levels. We train an\nenergy network with this \\emph{dual} score matching objective on the ImageNet64\ndataset, and obtain a cross-entropy (negative log likelihood) value comparable\nto the state of the art. We further validate our approach by showing that our\nenergy model \\emph{strongly generalizes}: estimated log probabilities are\nnearly independent of the specific images in the training set. Finally, we\ndemonstrate that both image probability and dimensionality of local\nneighborhoods vary significantly with image content, in contrast with\ntraditional assumptions such as concentration of measure or support on a\nlow-dimensional manifold.", "AI": {"tldr": "The paper introduces a framework for learning normalized energy models inspired by diffusion generative models, using a dual score matching objective to ensure consistent energies across noise levels. It achieves state-of-the-art cross-entropy on ImageNet64 and demonstrates strong generalization.", "motivation": "Learning probability models from data is challenging due to dimensionality issues. The paper aims to address this by leveraging diffusion generative models to learn normalized energy models.", "method": "Modifies a score network architecture to compute energy while preserving inductive biases. Uses a dual score matching objective (denoising and a novel secondary objective) to ensure consistent energies across noise levels.", "result": "Achieves competitive cross-entropy on ImageNet64, shows strong generalization (log probabilities are independent of training images), and reveals variability in image probability and local dimensionality.", "conclusion": "The framework effectively learns normalized energy models, generalizes well, and challenges traditional assumptions about image probability and dimensionality."}}
{"id": "2506.05316", "pdf": "https://arxiv.org/pdf/2506.05316", "abs": "https://arxiv.org/abs/2506.05316", "authors": ["Yifan Sun", "Jingyan Shen", "Yibin Wang", "Tianyu Chen", "Zhendong Wang", "Mingyuan Zhou", "Huan Zhang"], "title": "Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) has become an effective approach for fine-tuning\nlarge language models (LLMs), particularly to enhance their reasoning\ncapabilities. However, RL fine-tuning remains highly resource-intensive, and\nexisting work has largely overlooked the problem of data efficiency. In this\npaper, we propose two techniques to improve data efficiency in LLM RL\nfine-tuning: difficulty-targeted online data selection and rollout replay. We\nintroduce the notion of adaptive difficulty to guide online data selection,\nprioritizing questions of moderate difficulty that are more likely to yield\ninformative learning signals. To estimate adaptive difficulty efficiently, we\ndevelop an attention-based framework that requires rollouts for only a small\nreference set of questions. The adaptive difficulty of the remaining questions\nis then estimated based on their similarity to this set. To further reduce\nrollout cost, we introduce a rollout replay mechanism that reuses recent\nrollouts, lowering per-step computation while maintaining stable updates.\nExtensive experiments across 6 LLM-dataset combinations show that our method\nreduces RL fine-tuning time by 25% to 65% to reach the same level of\nperformance as the original GRPO algorithm.", "AI": {"tldr": "The paper proposes two techniques\u2014difficulty-targeted online data selection and rollout replay\u2014to improve data efficiency in RL fine-tuning of LLMs, reducing training time by 25%-65%.", "motivation": "RL fine-tuning for LLMs is resource-intensive, and existing methods lack focus on data efficiency.", "method": "Uses adaptive difficulty for online data selection and an attention-based framework for efficient difficulty estimation. Introduces rollout replay to reuse recent rollouts.", "result": "Achieves 25%-65% reduction in RL fine-tuning time while matching performance of the original GRPO algorithm.", "conclusion": "The proposed techniques significantly enhance data efficiency in RL fine-tuning for LLMs."}}
{"id": "2506.05321", "pdf": "https://arxiv.org/pdf/2506.05321", "abs": "https://arxiv.org/abs/2506.05321", "authors": ["Maxwell A. Xu", "Girish Narayanswamy", "Kumar Ayush", "Dimitris Spathis", "Shun Liao", "Shyam A. Tailor", "Ahmed Metwally", "A. Ali Heydari", "Yuwei Zhang", "Jake Garrison", "Samy Abdel-Ghaffar", "Xuhai Xu", "Ken Gu", "Jacob Sunshine", "Ming-Zher Poh", "Yun Liu", "Tim Althoff", "Shrikanth Narayanan", "Pushmeet Kohli", "Mark Malhotra", "Shwetak Patel", "Yuzhe Yang", "James M. Rehg", "Xin Liu", "Daniel McDuff"], "title": "LSM-2: Learning from Incomplete Wearable Sensor Data", "categories": ["cs.LG"], "comment": "Xu and Narayanswamy are co-first authors. McDuff and Liu are co-last\n  authors", "summary": "Foundation models, a cornerstone of recent advancements in machine learning,\nhave predominantly thrived on complete and well-structured data. Wearable\nsensor data frequently suffers from significant missingness, posing a\nsubstantial challenge for self-supervised learning (SSL) models that typically\nassume complete data inputs. This paper introduces the second generation of\nLarge Sensor Model (LSM-2) with Adaptive and Inherited Masking (AIM), a novel\nSSL approach that learns robust representations directly from incomplete data\nwithout requiring explicit imputation. AIM's core novelty lies in its use of\nlearnable mask tokens to model both existing (\"inherited\") and artificially\nintroduced missingness, enabling it to robustly handle fragmented real-world\ndata during inference. Pre-trained on an extensive dataset of 40M hours of\nday-long multimodal sensor data, our LSM-2 with AIM achieves the best\nperformance across a diverse range of tasks, including classification,\nregression and generative modeling. Furthermore, LSM-2 with AIM exhibits\nsuperior scaling performance, and critically, maintains high performance even\nunder targeted missingness scenarios, reflecting clinically coherent patterns,\nsuch as the diagnostic value of nighttime biosignals for hypertension\nprediction. This makes AIM a more reliable choice for real-world wearable data\napplications.", "AI": {"tldr": "LSM-2 with AIM introduces a self-supervised learning approach for handling incomplete wearable sensor data without imputation, achieving top performance across tasks.", "motivation": "Wearable sensor data often has significant missingness, challenging traditional SSL models that assume complete data.", "method": "Uses Adaptive and Inherited Masking (AIM) with learnable mask tokens to model missingness, trained on 40M hours of multimodal sensor data.", "result": "Achieves best performance in classification, regression, and generative tasks, with robust scaling and high performance under targeted missingness.", "conclusion": "AIM is a reliable solution for real-world wearable data applications, especially in clinical contexts."}}
{"id": "2506.05325", "pdf": "https://arxiv.org/pdf/2506.05325", "abs": "https://arxiv.org/abs/2506.05325", "authors": ["Yingshuai Ji", "Haomin Zhuang", "Matthew Toole", "James McKenzie", "Xiaolong Liu", "Xiangliang Zhang"], "title": "Seeing the Invisible: Machine learning-Based QPI Kernel Extraction via Latent Alignment", "categories": ["cs.LG"], "comment": null, "summary": "Quasiparticle interference (QPI) imaging is a powerful tool for probing\nelectronic structures in quantum materials, but extracting the single-scatterer\nQPI pattern (i.e., the kernel) from a multi-scatterer image remains a\nfundamentally ill-posed inverse problem. In this work, we propose the first\nAI-based framework for QPI kernel extraction. We introduce a two-step learning\nstrategy that decouples kernel representation learning from\nobservation-to-kernel inference. In the first step, we train a variational\nautoencoder to learn a compact latent space of scattering kernels. In the\nsecond step, we align the latent representation of QPI observations with those\nof the pre-learned kernels using a dedicated encoder. This design enables the\nmodel to infer kernels robustly even under complex, entangled scattering\nconditions. We construct a diverse and physically realistic QPI dataset\ncomprising 100 unique kernels and evaluate our method against a direct one-step\nbaseline. Experimental results demonstrate that our approach achieves\nsignificantly higher extraction accuracy, and improved generalization to unseen\nkernels.", "AI": {"tldr": "An AI-based framework for extracting single-scatterer QPI patterns from multi-scatterer images, using a two-step learning strategy for robust inference.", "motivation": "QPI imaging is powerful but extracting single-scatterer patterns from multi-scatterer images is an ill-posed problem.", "method": "A two-step learning strategy: (1) train a variational autoencoder for kernel representation, (2) align latent representations of observations with pre-learned kernels.", "result": "Achieves higher accuracy and better generalization to unseen kernels compared to a direct one-step baseline.", "conclusion": "The proposed AI framework effectively addresses the ill-posed QPI kernel extraction problem."}}
{"id": "2506.05333", "pdf": "https://arxiv.org/pdf/2506.05333", "abs": "https://arxiv.org/abs/2506.05333", "authors": ["Ranajoy Sadhukhan", "Zhuoming Chen", "Haizhong Zheng", "Yang Zhou", "Emma Strubell", "Beidi Chen"], "title": "Kinetics: Rethinking Test-Time Scaling Laws", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We rethink test-time scaling laws from a practical efficiency perspective,\nrevealing that the effectiveness of smaller models is significantly\noverestimated. Prior work, grounded in compute-optimality, overlooks critical\nmemory access bottlenecks introduced by inference-time strategies (e.g.,\nBest-of-$N$, long CoTs). Our holistic analysis, spanning models from 0.6B to\n32B parameters, reveals a new Kinetics Scaling Law that better guides resource\nallocation by incorporating both computation and memory access costs. Kinetics\nScaling Law suggests that test-time compute is more effective when used on\nmodels above a threshold than smaller ones. A key reason is that in TTS,\nattention, rather than parameter count, emerges as the dominant cost factor.\nMotivated by this, we propose a new scaling paradigm centered on sparse\nattention, which lowers per-token cost and enables longer generations and more\nparallel samples within the same resource budget. Empirically, we show that\nsparse attention models consistently outperform dense counterparts, achieving\nover 60 points gains in low-cost regimes and over 5 points gains in high-cost\nregimes for problem-solving accuracy on AIME, encompassing evaluations on\nstate-of-the-art MoEs. These results suggest that sparse attention is essential\nfor realizing the full potential of test-time scaling because, unlike training,\nwhere parameter scaling saturates, test-time accuracy continues to improve\nthrough increased generation. The code is available at\nhttps://github.com/Infini-AI-Lab/Kinetics.", "AI": {"tldr": "The paper introduces the Kinetics Scaling Law, showing smaller models' effectiveness is overestimated due to overlooked memory bottlenecks. Sparse attention models outperform dense ones, improving accuracy in both low and high-cost regimes.", "motivation": "To address the inefficiency of smaller models in test-time scenarios, where prior work ignores memory access bottlenecks and overestimates their performance.", "method": "Holistic analysis of models (0.6B to 32B parameters) to derive the Kinetics Scaling Law, proposing sparse attention to reduce per-token costs.", "result": "Sparse attention models outperform dense ones, with 60+ point gains in low-cost and 5+ point gains in high-cost regimes on AIME evaluations.", "conclusion": "Sparse attention is crucial for test-time scaling, as it enables longer generations and better accuracy, unlike parameter scaling in training."}}
{"id": "2506.05340", "pdf": "https://arxiv.org/pdf/2506.05340", "abs": "https://arxiv.org/abs/2506.05340", "authors": ["Keshigeyan Chandrasegaran", "Michael Poli", "Daniel Y. Fu", "Dongjun Kim", "Lea M. Hadzic", "Manling Li", "Agrim Gupta", "Stefano Massaroli", "Azalia Mirhoseini", "Juan Carlos Niebles", "Stefano Ermon", "Li Fei-Fei"], "title": "Exploring Diffusion Transformer Designs via Grafting", "categories": ["cs.LG", "cs.AI"], "comment": "22 pages; Project website: https://grafting.stanford.edu", "summary": "Designing model architectures requires decisions such as selecting operators\n(e.g., attention, convolution) and configurations (e.g., depth, width).\nHowever, evaluating the impact of these decisions on model quality requires\ncostly pretraining, limiting architectural investigation. Inspired by how new\nsoftware is built on existing code, we ask: can new architecture designs be\nstudied using pretrained models? To this end, we present grafting, a simple\napproach for editing pretrained diffusion transformers (DiTs) to materialize\nnew architectures under small compute budgets. Informed by our analysis of\nactivation behavior and attention locality, we construct a testbed based on the\nDiT-XL/2 design to study the impact of grafting on model quality. Using this\ntestbed, we develop a family of hybrid designs via grafting: replacing softmax\nattention with gated convolution, local attention, and linear attention, and\nreplacing MLPs with variable expansion ratio and convolutional variants.\nNotably, many hybrid designs achieve good quality (FID: 2.38-2.64 vs. 2.27 for\nDiT-XL/2) using <2% pretraining compute. We then graft a text-to-image model\n(PixArt-Sigma), achieving a 1.43x speedup with less than a 2% drop in GenEval\nscore. Finally, we present a case study that restructures DiT-XL/2 by\nconverting every pair of sequential transformer blocks into parallel blocks via\ngrafting. This reduces model depth by 2x and yields better quality (FID: 2.77)\nthan other models of comparable depth. Together, we show that new diffusion\nmodel designs can be explored by grafting pretrained DiTs, with edits ranging\nfrom operator replacement to architecture restructuring. Code and grafted\nmodels: https://grafting.stanford.edu", "AI": {"tldr": "The paper introduces grafting, a method to edit pretrained diffusion transformers (DiTs) for exploring new architectures with minimal compute, achieving comparable quality to full pretraining.", "motivation": "Evaluating architectural decisions in models requires costly pretraining, limiting exploration. The paper aims to study new designs using existing pretrained models.", "method": "Grafting edits pretrained DiTs by replacing operators (e.g., attention with gated convolution) and restructuring architectures (e.g., parallel blocks).", "result": "Hybrid designs achieve good quality (FID: 2.38-2.64) with <2% pretraining compute. Grafting also speeds up text-to-image models (1.43x) with minimal quality drop.", "conclusion": "Grafting enables efficient exploration of new diffusion model designs, from operator replacements to architecture restructuring, using pretrained DiTs."}}
{"id": "2506.05345", "pdf": "https://arxiv.org/pdf/2506.05345", "abs": "https://arxiv.org/abs/2506.05345", "authors": ["Adrian \u0141a\u0144cucki", "Konrad Staniszewski", "Piotr Nawrot", "Edoardo M. Ponti"], "title": "Inference-Time Hyper-Scaling with KV Cache Compression", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Inference-time scaling trades efficiency for increased reasoning accuracy by\ngenerating longer or more parallel sequences. However, in Transformer LLMs,\ngeneration cost is bottlenecked by the size of the key-value (KV) cache, rather\nthan the number of generated tokens. Hence, we explore inference-time\nhyper-scaling: by compressing the KV cache, we can generate more tokens within\nthe same compute budget and further improve the accuracy of scaled inference.\nThe success of this approach, however, hinges on the ability of compression\nmethods to preserve accuracy even at high compression ratios. To make\nhyper-scaling practical, we introduce Dynamic Memory Sparsification (DMS), a\nnovel method for sparsifying KV caches that only requires 1K training steps to\nachieve 8$\\times$ compression, while maintaining better accuracy than\ntraining-free sparse attention. Instead of prematurely discarding cached\ntokens, DMS delays token eviction, implicitly merging representations and\npreserving critical information. We demonstrate the effectiveness of\ninference-time hyper-scaling with DMS on multiple families of LLMs, showing\nthat it boosts accuracy for comparable inference runtime and memory load. For\ninstance, we enhance Qwen-R1 32B by an average of 9.1 points on AIME 24, 7.6 on\nGPQA, and 9.6 on LiveCodeBench across compute budgets.", "AI": {"tldr": "The paper introduces Dynamic Memory Sparsification (DMS) to compress the KV cache in Transformer LLMs, enabling more tokens to be generated within the same compute budget while improving accuracy.", "motivation": "The key-value (KV) cache in Transformer LLMs bottlenecks generation cost, not the number of tokens. Compressing the KV cache can enhance efficiency and accuracy.", "method": "Proposes DMS, a method for sparsifying KV caches with minimal training (1K steps), delaying token eviction to preserve critical information.", "result": "DMS achieves 8\u00d7 compression, outperforming training-free sparse attention, and boosts accuracy on benchmarks like AIME 24, GPQA, and LiveCodeBench.", "conclusion": "Inference-time hyper-scaling with DMS is practical and effective, improving LLM accuracy without increasing runtime or memory load."}}
{"id": "2506.03177", "pdf": "https://arxiv.org/pdf/2506.03177", "abs": "https://arxiv.org/abs/2506.03177", "authors": ["Isarun Chamveha", "Supphanut Chaiyungyuen", "Sasinun Worakriangkrai", "Nattawadee Prasawang", "Warasinee Chaisangmongkon", "Pornpim Korpraphong", "Voraparee Suvannarerg", "Shanigarn Thiravit", "Chalermdej Kannawat", "Kewalin Rungsinaporn", "Suwara Issaragrisil", "Payia Chadbunchachai", "Pattiya Gatechumpol", "Chawiporn Muktabhant", "Patarachai Sereerat"], "title": "Deep Learning-Based Breast Cancer Detection in Mammography: A Multi-Center Validation Study in Thai Population", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "This study presents a deep learning system for breast cancer detection in\nmammography, developed using a modified EfficientNetV2 architecture with\nenhanced attention mechanisms. The model was trained on mammograms from a major\nThai medical center and validated on three distinct datasets: an in-domain test\nset (9,421 cases), a biopsy-confirmed set (883 cases), and an out-of-domain\ngeneralizability set (761 cases) collected from two different hospitals. For\ncancer detection, the model achieved AUROCs of 0.89, 0.96, and 0.94 on the\nrespective datasets. The system's lesion localization capability, evaluated\nusing metrics including Lesion Localization Fraction (LLF) and Non-Lesion\nLocalization Fraction (NLF), demonstrated robust performance in identifying\nsuspicious regions. Clinical validation through concordance tests showed strong\nagreement with radiologists: 83.5% classification and 84.0% localization\nconcordance for biopsy-confirmed cases, and 78.1% classification and 79.6%\nlocalization concordance for out-of-domain cases. Expert radiologists'\nacceptance rate also averaged 96.7% for biopsy-confirmed cases, and 89.3% for\nout-of-domain cases. The system achieved a System Usability Scale score of\n74.17 for source hospital, and 69.20 for validation hospitals, indicating good\nclinical acceptance. These results demonstrate the model's effectiveness in\nassisting mammogram interpretation, with the potential to enhance breast cancer\nscreening workflows in clinical practice.", "AI": {"tldr": "A deep learning system using a modified EfficientNetV2 with enhanced attention mechanisms for breast cancer detection in mammograms shows high accuracy and clinical acceptance.", "motivation": "To improve breast cancer detection in mammography by leveraging deep learning, enhancing workflow efficiency, and ensuring clinical applicability.", "method": "Utilized a modified EfficientNetV2 architecture with enhanced attention mechanisms, trained on mammograms from a Thai medical center, and validated on diverse datasets.", "result": "Achieved AUROCs of 0.89, 0.96, and 0.94 across datasets, with strong localization and high concordance with radiologists (83.5%-84.0% for biopsy-confirmed cases). Clinical acceptance was high (96.7% acceptance rate).", "conclusion": "The system is effective for mammogram interpretation, with potential to enhance breast cancer screening workflows in clinical practice."}}
{"id": "2506.04235", "pdf": "https://arxiv.org/pdf/2506.04235", "abs": "https://arxiv.org/abs/2506.04235", "authors": ["Xinyan Zhao", "Yi-Ching Tang", "Akshita Singh", "Victor J Cantu", "KwanHo An", "Junseok Lee", "Adam E Stogsdill", "Ashwin Kumar Ramesh", "Zhiqiang An", "Xiaoqian Jiang", "Yejin Kim"], "title": "Benchmark for Antibody Binding Affinity Maturation and Design", "categories": ["q-bio.QM", "cs.AI", "cs.CE", "cs.LG", "q-bio.BM"], "comment": null, "summary": "We introduce AbBiBench (Antibody Binding Benchmarking), a benchmarking\nframework for antibody binding affinity maturation and design. Unlike existing\nantibody evaluation strategies that rely on antibody alone and its similarity\nto natural ones (e.g., amino acid identity rate, structural RMSD), AbBiBench\nconsiders an antibody-antigen (Ab-Ag) complex as a functional unit and\nevaluates the potential of an antibody design binding to given antigen by\nmeasuring protein model's likelihood on the Ab-Ag complex. We first curate,\nstandardize, and share 9 datasets containing 9 antigens (involving influenza,\nanti-lysozyme, HER2, VEGF, integrin, and SARS-CoV-2) and 155,853 heavy chain\nmutated antibodies. Using these datasets, we systematically compare 14 protein\nmodels including masked language models, autoregressive language models,\ninverse folding models, diffusion-based generative models, and geometric graph\nmodels. The correlation between model likelihood and experimental affinity\nvalues is used to evaluate model performance. Additionally, in a case study to\nincrease binding affinity of antibody F045-092 to antigen influenza H1N1, we\nevaluate the generative power of the top-performing models by sampling a set of\nnew antibodies binding to the antigen and ranking them based on structural\nintegrity and biophysical properties of the Ab-Ag complex. As a result,\nstructure-conditioned inverse folding models outperform others in both affinity\ncorrelation and generation tasks. Overall, AbBiBench provides a unified,\nbiologically grounded evaluation framework to facilitate the development of\nmore effective, function-aware antibody design models.", "AI": {"tldr": "AbBiBench is a benchmarking framework for antibody binding affinity, evaluating designs based on antibody-antigen complex likelihood, outperforming traditional methods.", "motivation": "Existing antibody evaluation methods focus on antibody similarity to natural ones, lacking functional assessment of binding potential. AbBiBench addresses this gap.", "method": "AbBiBench curates 9 datasets with 155,853 antibodies, compares 14 protein models using likelihood-affinity correlation, and tests generative power in a case study.", "result": "Structure-conditioned inverse folding models perform best in affinity correlation and generation tasks.", "conclusion": "AbBiBench offers a unified, biologically grounded framework for improving antibody design models."}}
{"id": "2506.04238", "pdf": "https://arxiv.org/pdf/2506.04238", "abs": "https://arxiv.org/abs/2506.04238", "authors": ["Shriyank Somvanshi", "Md Monzurul Islam", "Syed Aaqib Javed", "Gaurab Chhetri", "Kazi Sifatul Islam", "Tausif Islam Chowdhury", "Sazzad Bin Bashar Polock", "Anandi Dutta", "Subasish Das"], "title": "A Comprehensive Survey on Bio-Inspired Algorithms: Taxonomy, Applications, and Future Directions", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Bio-inspired algorithms (BIAs) utilize natural processes such as evolution,\nswarm behavior, foraging, and plant growth to solve complex, nonlinear,\nhigh-dimensional optimization problems. This survey categorizes BIAs into eight\ngroups: evolutionary, swarm intelligence, physics-inspired, ecosystem and\nplant-based, predator-prey, neural-inspired, human-inspired, and hybrid\napproaches, and reviews their core principles, strengths, and limitations. We\nillustrate the usage of these algorithms in machine learning, engineering\ndesign, bioinformatics, and intelligent systems, and highlight recent advances\nin hybridization, parameter tuning, and adaptive strategies. Finally, we\nidentify open challenges such as scalability, convergence, reliability, and\ninterpretability to suggest directions for future research. This work aims to\nserve as a foundational resource for both researchers and practitioners\ninterested in understanding the current landscape and future directions of\nbio-inspired computing.", "AI": {"tldr": "A survey categorizing bio-inspired algorithms into eight groups, reviewing their principles, strengths, and limitations, and highlighting applications and future challenges.", "motivation": "To provide a comprehensive overview of bio-inspired algorithms, their applications, and open challenges for researchers and practitioners.", "method": "Categorizes BIAs into eight groups, reviews core principles, strengths, and limitations, and illustrates applications in various fields.", "result": "Identifies recent advances in hybridization, tuning, and adaptive strategies, and highlights open challenges like scalability and interpretability.", "conclusion": "Serves as a foundational resource for understanding the current landscape and future directions of bio-inspired computing."}}
{"id": "2506.04240", "pdf": "https://arxiv.org/pdf/2506.04240", "abs": "https://arxiv.org/abs/2506.04240", "authors": ["Sydney Anuyah"], "title": "What does making money have to do with crime?: A dive into the National Crime Victimization survey", "categories": ["physics.soc-ph", "cs.LG"], "comment": null, "summary": "In this short article, I leverage the National Crime Victimization Survey\nfrom 1992 to 2022 to examine how income, education, employment, and key\ndemographic factors shape the type of crime victims experience (violent vs\nproperty). Using balanced classification splits and logistic regression models\nevaluated by F1-score, there is an isolation of the socioeconomic drivers of\nvictimization \"Group A\" models and then an introduction of demographic factors\nsuch as age, gender, race, and marital status controls called \"Group B\" models.\nThe results consistently proves that higher income and education lower the odds\nof violent relative to property crime, while men younger individuals and racial\nminorities face disproportionately higher violentcrime risks. On the geographic\nspectrum, the suburban models achieve the strongest predictive performance with\nan accuracy of 0.607 and F1 of 0.590, urban areas benefit from adding education\nand employment predictors and crime in rural areas are still unpredictable\nusing these current factors. The patterns found in this study shows the need\nfor specific interventions like educational investments in metropolitan\nsettings economic support in rural communities and demographicaware prevention\nstrategies.", "AI": {"tldr": "The study analyzes how socioeconomic and demographic factors influence violent vs. property crime victimization using data from 1992-2022. Higher income/education reduces violent crime odds, while men, youth, and minorities face higher risks. Geographic analysis shows suburban models predict best, while rural crime remains unpredictable.", "motivation": "To understand how income, education, employment, and demographics shape crime victimization types (violent vs. property).", "method": "Uses National Crime Victimization Survey data (1992-2022), balanced classification splits, and logistic regression models (Group A: socioeconomic factors; Group B: added demographic controls). Evaluated by F1-score.", "result": "Higher income/education lowers violent crime odds; men, youth, and minorities face higher risks. Suburban models predict best (accuracy 0.607, F1 0.590); rural crime remains unpredictable.", "conclusion": "Findings highlight the need for targeted interventions: educational investments in cities, economic support in rural areas, and demographic-aware prevention strategies."}}
{"id": "2506.04245", "pdf": "https://arxiv.org/pdf/2506.04245", "abs": "https://arxiv.org/abs/2506.04245", "authors": ["Guangchen Lan", "Huseyin A. Inan", "Sahar Abdelnabi", "Janardhan Kulkarni", "Lukas Wutschitz", "Reza Shokri", "Christopher G. Brinton", "Robert Sim"], "title": "Contextual Integrity in LLMs via Reasoning and Reinforcement Learning", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.6; I.2.7"], "comment": null, "summary": "As the era of autonomous agents making decisions on behalf of users unfolds,\nensuring contextual integrity (CI) -- what is the appropriate information to\nshare while carrying out a certain task -- becomes a central question to the\nfield. We posit that CI demands a form of reasoning where the agent needs to\nreason about the context in which it is operating. To test this, we first\nprompt LLMs to reason explicitly about CI when deciding what information to\ndisclose. We then extend this approach by developing a reinforcement learning\n(RL) framework that further instills in models the reasoning necessary to\nachieve CI. Using a synthetic, automatically created, dataset of only $\\sim700$\nexamples but with diverse contexts and information disclosure norms, we show\nthat our method substantially reduces inappropriate information disclosure\nwhile maintaining task performance across multiple model sizes and families.\nImportantly, improvements transfer from this synthetic dataset to established\nCI benchmarks such as PrivacyLens that has human annotations and evaluates\nprivacy leakage of AI assistants in actions and tool calls.", "AI": {"tldr": "The paper proposes a method to ensure contextual integrity (CI) in autonomous agents by combining LLM reasoning and reinforcement learning, reducing inappropriate information disclosure while maintaining task performance.", "motivation": "Ensuring contextual integrity (CI) in autonomous agents is crucial to determine appropriate information sharing during tasks.", "method": "The approach involves prompting LLMs to reason about CI and developing an RL framework to instill CI reasoning. A synthetic dataset of ~700 examples is used for training.", "result": "The method significantly reduces inappropriate information disclosure without compromising task performance, and improvements transfer to human-annotated benchmarks like PrivacyLens.", "conclusion": "The proposed framework effectively addresses CI in autonomous agents, demonstrating scalability and transferability to real-world benchmarks."}}
{"id": "2506.04249", "pdf": "https://arxiv.org/pdf/2506.04249", "abs": "https://arxiv.org/abs/2506.04249", "authors": ["Mehmet Aziz Yirik", "Jakob Lykke Andersen", "Rolf Fagerberg", "Daniel Merkle"], "title": "ChemReservoir -- An Open-Source Framework for Chemically-Inspired Reservoir Computing", "categories": ["cs.CE", "cs.ET", "cs.LG"], "comment": null, "summary": "Reservoir computing is a type of a recurrent neural network, mapping the\ninputs into higher dimensional space using fixed and nonlinear dynamical\nsystems, called reservoirs. In the literature, there are various types of\nreservoirs ranging from in-silico to in-vitro. In cheminformatics, previous\nstudies contributed to the field by developing simulation-based chemically\ninspired in-silico reservoir models. Yahiro used a DNA-based chemical reaction\nnetwork as its reservoir and Nguyen developed a DNA chemistry-inspired tool\nbased on Gillespie algorithm. However, these software tools were designed\nmainly with the focus on DNA chemistry and their maintenance status has limited\ntheir current usability. Due to these limitations, there was a need for a\nproper open-source tool. This study introduces ChemReservoir, an open-source\nframework for chemically-inspired reservoir computing. In contrast to the\nformer studies focused on DNA-chemistry, ChemReservoir is a general framework\nfor the construction and analysis of chemically-inspired reservoirs, which also\naddresses the limitations in these previous studies by ensuring enhanced\ntesting, evaluation, and reproducibility. The tool was evaluated using various\ncycle-based reservoir topologies and demonstrated stable performance across a\nrange of configurations in memory capacity tasks.", "AI": {"tldr": "ChemReservoir is an open-source framework for chemically-inspired reservoir computing, addressing limitations of previous DNA-focused tools by offering general applicability, testing, and reproducibility.", "motivation": "Previous reservoir computing tools were limited to DNA chemistry and lacked maintenance, necessitating a versatile, open-source solution.", "method": "Developed ChemReservoir, a framework for constructing and analyzing chemically-inspired reservoirs, with enhanced testing and evaluation.", "result": "Demonstrated stable performance in memory capacity tasks across various cycle-based reservoir topologies.", "conclusion": "ChemReservoir provides a robust, general-purpose tool for chemically-inspired reservoir computing, overcoming prior limitations."}}
{"id": "2506.04251", "pdf": "https://arxiv.org/pdf/2506.04251", "abs": "https://arxiv.org/abs/2506.04251", "authors": ["Zhengyang Li"], "title": "Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "This paper introduces LLM-MARL, a unified framework that incorporates large\nlanguage models (LLMs) into multi-agent reinforcement learning (MARL) to\nenhance coordination, communication, and generalization in simulated game\nenvironments. The framework features three modular components of Coordinator,\nCommunicator, and Memory, which dynamically generate subgoals, facilitate\nsymbolic inter-agent messaging, and support episodic recall. Training combines\nPPO with a language-conditioned loss and LLM query gating. LLM-MARL is\nevaluated in Google Research Football, MAgent Battle, and StarCraft II. Results\nshow consistent improvements over MAPPO and QMIX in win rate, coordination\nscore, and zero-shot generalization. Ablation studies demonstrate that subgoal\ngeneration and language-based messaging each contribute significantly to\nperformance gains. Qualitative analysis reveals emergent behaviors such as role\nspecialization and communication-driven tactics. By bridging language modeling\nand policy learning, this work contributes to the design of intelligent,\ncooperative agents in interactive simulations. It offers a path forward for\nleveraging LLMs in multi-agent systems used for training, games, and human-AI\ncollaboration.", "AI": {"tldr": "LLM-MARL integrates LLMs into MARL to improve coordination, communication, and generalization in games, outperforming MAPPO and QMIX.", "motivation": "To enhance multi-agent systems by combining LLMs with MARL for better coordination and generalization in simulated environments.", "method": "Uses a framework with Coordinator, Communicator, and Memory modules, trained with PPO, language-conditioned loss, and LLM query gating.", "result": "Shows improved win rates, coordination, and zero-shot generalization in Google Research Football, MAgent Battle, and StarCraft II.", "conclusion": "LLM-MARL bridges language and policy learning, advancing intelligent, cooperative agents for simulations and human-AI collaboration."}}
{"id": "2506.04252", "pdf": "https://arxiv.org/pdf/2506.04252", "abs": "https://arxiv.org/abs/2506.04252", "authors": ["Yang Zhao", "Chengxiao Dai", "Dusit Niyato", "Chuan Fu Tan", "Keyi Xiang", "Yueyang Wang", "Zhiquan Yeo", "Daren Tan Zong Loong", "Jonathan Low Zhaozhi", "Eugene H. Z. HO"], "title": "A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) hold promise for sustainable manufacturing, but\noften hallucinate industrial codes and emission factors, undermining regulatory\nand investment decisions. We introduce CircuGraphRAG, a retrieval-augmented\ngeneration (RAG) framework that grounds LLMs outputs in a domain-specific\nknowledge graph for the circular economy. This graph connects 117,380\nindustrial and waste entities with classification codes and GWP100 emission\ndata, enabling structured multi-hop reasoning. Natural language queries are\ntranslated into SPARQL and verified subgraphs are retrieved to ensure accuracy\nand traceability. Compared with Standalone LLMs and Naive RAG, CircuGraphRAG\nachieves superior performance in single-hop and multi-hop question answering,\nwith ROUGE-L F1 scores up to 1.0, while baseline scores below 0.08. It also\nimproves efficiency, halving the response time and reducing token usage by 16%\nin representative tasks. CircuGraphRAG provides fact-checked, regulatory-ready\nsupport for circular economy planning, advancing reliable, low-carbon resource\ndecision making.", "AI": {"tldr": "CircuGraphRAG improves LLM accuracy for circular economy tasks by grounding outputs in a knowledge graph, outperforming baselines in QA and efficiency.", "motivation": "LLMs often hallucinate industrial codes and emission factors, harming regulatory and investment decisions in sustainable manufacturing.", "method": "Introduces CircuGraphRAG, a RAG framework using a domain-specific knowledge graph with 117,380 entities for structured reasoning. Queries are translated to SPARQL for verified subgraph retrieval.", "result": "Achieves ROUGE-L F1 scores up to 1.0, outperforming baselines (<0.08). Halves response time and reduces token usage by 16%.", "conclusion": "CircuGraphRAG offers reliable, regulatory-ready support for circular economy planning, enhancing low-carbon decision-making."}}
{"id": "2506.04256", "pdf": "https://arxiv.org/pdf/2506.04256", "abs": "https://arxiv.org/abs/2506.04256", "authors": ["Konstantinos Kalimeris", "Leonidas Mindrinos", "Nikolaos Pallikarakis"], "title": "Estimating properties of a homogeneous bounded soil using machine learning models", "categories": ["physics.geo-ph", "cs.LG"], "comment": "35 pages, 15 figures, 19 tables", "summary": "This work focuses on estimating soil properties from water moisture\nmeasurements. We consider simulated data generated by solving the\ninitial-boundary value problem governing vertical infiltration in a\nhomogeneous, bounded soil profile, with the usage of the Fokas method. To\naddress the parameter identification problem, which is formulated as a\ntwo-output regression task, we explore various machine learning models. The\nperformance of each model is assessed under different data conditions: full,\nnoisy, and limited. Overall, the prediction of diffusivity $D$ tends to be more\naccurate than that of hydraulic conductivity $K.$ Among the models considered,\nSupport Vector Machines (SVMs) and Neural Networks (NNs) demonstrate the\nhighest robustness, achieving near-perfect accuracy and minimal errors.", "AI": {"tldr": "The paper estimates soil properties from water moisture measurements using machine learning models, with SVMs and NNs showing the best performance.", "motivation": "To address the challenge of estimating soil properties like diffusivity and hydraulic conductivity from water moisture data.", "method": "Simulated data from solving an initial-boundary value problem using the Fokas method, tested with various machine learning models under full, noisy, and limited data conditions.", "result": "SVMs and NNs performed best, with high accuracy and robustness, especially for diffusivity prediction.", "conclusion": "Machine learning, particularly SVMs and NNs, is effective for soil property estimation from water moisture data."}}
{"id": "2506.04263", "pdf": "https://arxiv.org/pdf/2506.04263", "abs": "https://arxiv.org/abs/2506.04263", "authors": ["Alan Mitkiy", "James Smith", "Hana Satou", "Hiroshi Tanaka", "Emily Johnson", "F Monkey"], "title": "Dynamic Epsilon Scheduling: A Multi-Factor Adaptive Perturbation Budget for Adversarial Training", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Adversarial training is among the most effective strategies for defending\ndeep neural networks against adversarial examples. A key limitation of existing\nadversarial training approaches lies in their reliance on a fixed perturbation\nbudget, which fails to account for instance-specific robustness\ncharacteristics. While prior works such as IAAT and MMA introduce\ninstance-level adaptations, they often rely on heuristic or static\napproximations of data robustness. In this paper, we propose Dynamic Epsilon\nScheduling (DES), a novel framework that adaptively adjusts the adversarial\nperturbation budget per instance and per training iteration. DES integrates\nthree key factors: (1) the distance to the decision boundary approximated via\ngradient-based proxies, (2) prediction confidence derived from softmax entropy,\nand (3) model uncertainty estimated via Monte Carlo dropout. By combining these\ncues into a unified scheduling strategy, DES tailors the perturbation budget\ndynamically to guide more effective adversarial learning. Experimental results\non CIFAR-10 and CIFAR-100 show that our method consistently improves both\nadversarial robustness and standard accuracy compared to fixed-epsilon\nbaselines and prior adaptive methods. Moreover, we provide theoretical insights\ninto the stability and convergence of our scheduling policy. This work opens a\nnew avenue for instance-aware, data-driven adversarial training methods.", "AI": {"tldr": "DES is a dynamic adversarial training method that adapts perturbation budgets per instance and iteration, improving robustness and accuracy.", "motivation": "Existing adversarial training uses fixed perturbation budgets, ignoring instance-specific robustness. DES addresses this limitation.", "method": "DES dynamically adjusts budgets using decision boundary distance, prediction confidence, and model uncertainty.", "result": "DES outperforms fixed-epsilon baselines and prior adaptive methods on CIFAR-10 and CIFAR-100.", "conclusion": "DES introduces a data-driven, instance-aware approach for adversarial training, with theoretical and empirical support."}}
{"id": "2506.04265", "pdf": "https://arxiv.org/pdf/2506.04265", "abs": "https://arxiv.org/abs/2506.04265", "authors": ["Mengda Ji", "Genjiu Xu", "Liying Wang"], "title": "CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "comment": null, "summary": "This work focuses on the credit assignment problem in cooperative multi-agent\nreinforcement learning (MARL). Sharing the global advantage among agents often\nleads to suboptimal policy updates as it fails to account for the distinct\ncontributions of agents. Although numerous methods consider global or\nindividual contributions for credit assignment, a detailed analysis at the\ncoalition level remains lacking in many approaches. This work analyzes the\nover-updating problem during multi-agent policy updates from a coalition-level\nperspective. To address this issue, we propose a credit assignment method\ncalled Coalitional Rational Advantage Decomposition (CORA). CORA evaluates\ncoalitional advantages via marginal contributions from all possible coalitions\nand decomposes advantages using the core solution from cooperative game theory,\nensuring coalitional rationality. To reduce computational overhead, CORA\nemploys random coalition sampling. Experiments on matrix games, differential\ngames, and multi-agent collaboration benchmarks demonstrate that CORA\noutperforms strong baselines, particularly in tasks with multiple local optima.\nThese findings highlight the importance of coalition-aware credit assignment\nfor improving MARL performance.", "AI": {"tldr": "The paper addresses credit assignment in cooperative MARL by proposing CORA, a coalition-level method that ensures rational advantage decomposition, outperforming baselines in tasks with local optima.", "motivation": "Current credit assignment methods in MARL often fail to account for distinct agent contributions at the coalition level, leading to suboptimal policy updates.", "method": "The authors introduce CORA, which evaluates coalitional advantages via marginal contributions and decomposes advantages using cooperative game theory's core solution, with random coalition sampling for efficiency.", "result": "CORA outperforms baselines in matrix games, differential games, and multi-agent benchmarks, especially in tasks with multiple local optima.", "conclusion": "Coalition-aware credit assignment, as demonstrated by CORA, is crucial for enhancing MARL performance."}}
{"id": "2506.04287", "pdf": "https://arxiv.org/pdf/2506.04287", "abs": "https://arxiv.org/abs/2506.04287", "authors": ["Yongjin Yang", "Sinjae Kang", "Juyong Lee", "Dongjun Lee", "Se-Young Yun", "Kimin Lee"], "title": "Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback", "categories": ["cs.AI", "cs.LG"], "comment": "Preprint, under review", "summary": "Training large language model (LLM) agents to acquire necessary skills and\nperform diverse tasks within an environment is gaining interest as a means to\nenable open-endedness. However, creating the training dataset for their skill\nacquisition faces several challenges. Manual trajectory collection requires\nsignificant human effort. Another approach, where LLMs directly propose tasks\nto learn, is often invalid, as the LLMs lack knowledge of which tasks are\nactually feasible. Moreover, the generated data may not provide a meaningful\nlearning signal, as agents often already perform well on the proposed tasks. To\naddress this, we propose a novel automatic skill discovery framework EXIF for\nLLM-powered agents, designed to improve the feasibility of generated target\nbehaviors while accounting for the agents' capabilities. Our method adopts an\nexploration-first strategy by employing an exploration agent (Alice) to train\nthe target agent (Bob) to learn essential skills in the environment.\nSpecifically, Alice first interacts with the environment to retrospectively\ngenerate a feasible, environment-grounded skill dataset, which is then used to\ntrain Bob. Crucially, we incorporate an iterative feedback loop, where Alice\nevaluates Bob's performance to identify areas for improvement. This feedback\nthen guides Alice's next round of exploration, forming a closed-loop data\ngeneration process. Experiments on Webshop and Crafter demonstrate EXIF's\nability to effectively discover meaningful skills and iteratively expand the\ncapabilities of the trained agent without any human intervention, achieving\nsubstantial performance improvements. Interestingly, we observe that setting\nAlice to the same model as Bob also notably improves performance, demonstrating\nEXIF's potential for building a self-evolving system.", "AI": {"tldr": "EXIF is an automatic skill discovery framework for LLM-powered agents, using an exploration-first strategy and iterative feedback to improve skill acquisition without human intervention.", "motivation": "Challenges in creating training datasets for LLM agents, such as manual effort and invalid task proposals, necessitate an automated solution.", "method": "EXIF employs an exploration agent (Alice) to generate feasible skills and train the target agent (Bob), with iterative feedback to refine learning.", "result": "Experiments show EXIF effectively discovers skills and improves agent performance, even enabling self-evolution when Alice and Bob share the same model.", "conclusion": "EXIF offers a scalable, human-free approach to skill acquisition for LLM agents, with potential for self-improving systems."}}
{"id": "2506.04290", "pdf": "https://arxiv.org/pdf/2506.04290", "abs": "https://arxiv.org/abs/2506.04290", "authors": ["Muhammed Golec", "Maha AlabdulJalil"], "title": "Interpretable LLMs for Credit Risk: A Systematic Review and Taxonomy", "categories": ["q-fin.RM", "cs.LG"], "comment": "20 pages, 6 figures, preprint under review at Information Processing\n  & Management", "summary": "Large Language Models (LLM), which have developed in recent years, enable\ncredit risk assessment through the analysis of financial texts such as analyst\nreports and corporate disclosures. This paper presents the first systematic\nreview and taxonomy focusing on LLMbased approaches in credit risk estimation.\nWe determined the basic model architectures by selecting 60 relevant papers\npublished between 2020-2025 with the PRISMA research strategy. And we examined\nthe data used for scenarios such as credit default prediction and risk\nanalysis. Since the main focus of the paper is interpretability, we classify\nconcepts such as explainability mechanisms, chain of thought prompts and\nnatural language justifications for LLM-based credit models. The taxonomy\norganizes the literature under four main headings: model architectures, data\ntypes, explainability mechanisms and application areas. Based on this analysis,\nwe highlight the main future trends and research gaps for LLM-based credit\nscoring systems. This paper aims to be a reference paper for artificial\nintelligence and financial researchers.", "AI": {"tldr": "A systematic review and taxonomy of LLM-based approaches for credit risk assessment, covering model architectures, data types, explainability, and applications.", "motivation": "To organize and analyze the growing body of research on LLM-based credit risk models, focusing on interpretability and future trends.", "method": "Reviewed 60 relevant papers (2020-2025) using PRISMA strategy, classifying them into model architectures, data types, explainability mechanisms, and application areas.", "result": "Identified key trends and gaps in LLM-based credit scoring, emphasizing interpretability techniques like chain-of-thought prompts.", "conclusion": "The paper serves as a foundational reference for AI and finance researchers, highlighting future directions for LLM-based credit risk systems."}}
{"id": "2506.04292", "pdf": "https://arxiv.org/pdf/2506.04292", "abs": "https://arxiv.org/abs/2506.04292", "authors": ["Bruno Deprez", "Bart Baesens", "Tim Verdonck", "Wouter Verbeke"], "title": "GARG-AML against Smurfing: A Scalable and Interpretable Graph-Based Framework for Anti-Money Laundering", "categories": ["cs.SI", "cs.LG", "stat.AP"], "comment": null, "summary": "Money laundering poses a significant challenge as it is estimated to account\nfor 2%-5% of the global GDP. This has compelled regulators to impose stringent\ncontrols on financial institutions. One prominent laundering method for evading\nthese controls, called smurfing, involves breaking up large transactions into\nsmaller amounts. Given the complexity of smurfing schemes, which involve\nmultiple transactions distributed among diverse parties, network analytics has\nbecome an important anti-money laundering tool. However, recent advances have\nfocused predominantly on black-box network embedding methods, which has\nhindered their adoption in businesses. In this paper, we introduce GARG-AML, a\nnovel graph-based method that quantifies smurfing risk through a single\ninterpretable metric derived from the structure of the second-order transaction\nnetwork of each individual node in the network. Unlike traditional methods,\nGARG-AML strikes an effective balance among computational efficiency, detection\npower and transparency, which enables its integration into existing AML\nworkflows. To enhance its capabilities, we combine the GARG-AML score\ncalculation with different tree-based methods and also incorporate the scores\nof the node's neighbours. An experimental evaluation on large-scale synthetic\nand open-source networks demonstrate that the GARG-AML outperforms the current\nstate-of-the-art smurfing detection methods. By leveraging only the adjacency\nmatrix of the second-order neighbourhood and basic network features, this work\nhighlights the potential of fundamental network properties towards advancing\nfraud detection.", "AI": {"tldr": "GARG-AML is a graph-based method for detecting smurfing in money laundering, offering a transparent and efficient single-metric solution.", "motivation": "Money laundering, especially smurfing, is a major global issue, but current detection methods lack transparency and adoption in businesses.", "method": "GARG-AML uses a single interpretable metric from second-order transaction networks, combined with tree-based methods and neighbor scores.", "result": "Outperforms state-of-the-art smurfing detection methods in synthetic and open-source networks.", "conclusion": "GARG-AML demonstrates the effectiveness of fundamental network properties for fraud detection, balancing efficiency and transparency."}}
{"id": "2506.04303", "pdf": "https://arxiv.org/pdf/2506.04303", "abs": "https://arxiv.org/abs/2506.04303", "authors": ["Zhizheng Wang", "Chi-Ping Day", "Chih-Hsuan Wei", "Qiao Jin", "Robert Leaman", "Yifan Yang", "Shubo Tian", "Aodong Qiu", "Yin Fang", "Qingqing Zhu", "Xinghua Lu", "Zhiyong Lu"], "title": "Knowledge-guided Contextual Gene Set Analysis Using Large Language Models", "categories": ["q-bio.GN", "cs.AI", "cs.LG"], "comment": "56 pages, 9 figures, 1 table", "summary": "Gene set analysis (GSA) is a foundational approach for interpreting genomic\ndata of diseases by linking genes to biological processes. However,\nconventional GSA methods overlook clinical context of the analyses, often\ngenerating long lists of enriched pathways with redundant, nonspecific, or\nirrelevant results. Interpreting these requires extensive, ad-hoc manual\neffort, reducing both reliability and reproducibility. To address this\nlimitation, we introduce cGSA, a novel AI-driven framework that enhances GSA by\nincorporating context-aware pathway prioritization. cGSA integrates gene\ncluster detection, enrichment analysis, and large language models to identify\npathways that are not only statistically significant but also biologically\nmeaningful. Benchmarking on 102 manually curated gene sets across 19 diseases\nand ten disease-related biological mechanisms shows that cGSA outperforms\nbaseline methods by over 30%, with expert validation confirming its increased\nprecision and interpretability. Two independent case studies in melanoma and\nbreast cancer further demonstrate its potential to uncover context-specific\ninsights and support targeted hypothesis generation.", "AI": {"tldr": "cGSA is an AI-driven framework improving gene set analysis by integrating clinical context, outperforming baseline methods by 30% and enhancing precision and interpretability.", "motivation": "Conventional GSA methods lack clinical context, producing redundant or irrelevant results, which reduces reliability and reproducibility.", "method": "cGSA combines gene cluster detection, enrichment analysis, and large language models for context-aware pathway prioritization.", "result": "Benchmarked on 102 gene sets, cGSA outperforms baselines by 30%, with expert validation confirming its precision. Case studies in melanoma and breast cancer highlight its utility.", "conclusion": "cGSA effectively addresses limitations of traditional GSA, offering biologically meaningful and context-specific insights."}}
{"id": "2506.04344", "pdf": "https://arxiv.org/pdf/2506.04344", "abs": "https://arxiv.org/abs/2506.04344", "authors": ["Caojin Zhang", "Qiang Zhang", "Ke Li", "Sai Vidyaranya Nuthalapati", "Benyu Zhang", "Jason Liu", "Serena Li", "Lizhu Zhang", "Xiangjun Fan"], "title": "GEM: Empowering LLM for both Embedding Generation and Language Understanding", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large decoder-only language models (LLMs) have achieved remarkable success in\ngeneration and reasoning tasks, where they generate text responses given\ninstructions. However, many applications, e.g., retrieval augmented generation\n(RAG), still rely on separate embedding models to generate text embeddings,\nwhich can complicate the system and introduce discrepancies in understanding of\nthe query between the embedding model and LLMs. To address this limitation, we\npropose a simple self-supervised approach, Generative Embedding large language\nModel (GEM), that enables any large decoder-only LLM to generate high-quality\ntext embeddings while maintaining its original text generation and reasoning\ncapabilities. Our method inserts new special token(s) into a text body, and\ngenerates summarization embedding of the text by manipulating the attention\nmask. This method could be easily integrated into post-training or fine tuning\nstages of any existing LLMs. We demonstrate the effectiveness of our approach\nby applying it to two popular LLM families, ranging from 1B to 8B parameters,\nand evaluating the transformed models on both text embedding benchmarks (MTEB)\nand NLP benchmarks (MMLU). The results show that our proposed method\nsignificantly improves the original LLMs on MTEB while having a minimal impact\non MMLU. Our strong results indicate that our approach can empower LLMs with\nstate-of-the-art text embedding capabilities while maintaining their original\nNLP performance", "AI": {"tldr": "The paper proposes GEM, a self-supervised method enabling decoder-only LLMs to generate high-quality text embeddings without compromising their original capabilities.", "motivation": "Current systems use separate embedding models for tasks like RAG, complicating the system and causing discrepancies. GEM aims to unify these capabilities within LLMs.", "method": "GEM inserts special tokens and manipulates attention masks to generate text embeddings, compatible with post-training or fine-tuning of existing LLMs.", "result": "Applied to LLMs (1B-8B parameters), GEM improves text embedding performance (MTEB) with minimal impact on NLP tasks (MMLU).", "conclusion": "GEM successfully enhances LLMs with state-of-the-art text embedding capabilities while preserving their original NLP performance."}}
{"id": "2506.04353", "pdf": "https://arxiv.org/pdf/2506.04353", "abs": "https://arxiv.org/abs/2506.04353", "authors": ["Ankit Pal", "Jung-Oh Lee", "Xiaoman Zhang", "Malaikannan Sankarasubbu", "Seunghyeon Roh", "Won Jung Kim", "Meesun Lee", "Pranav Rajpurkar"], "title": "ReXVQA: A Large-scale Visual Question Answering Benchmark for Generalist Chest X-ray Understanding", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.CL", "cs.LG"], "comment": null, "summary": "We present ReXVQA, the largest and most comprehensive benchmark for visual\nquestion answering (VQA) in chest radiology, comprising approximately 696,000\nquestions paired with 160,000 chest X-rays studies across training, validation,\nand test sets. Unlike prior efforts that rely heavily on template based\nqueries, ReXVQA introduces a diverse and clinically authentic task suite\nreflecting five core radiological reasoning skills: presence assessment,\nlocation analysis, negation detection, differential diagnosis, and geometric\nreasoning. We evaluate eight state-of-the-art multimodal large language models,\nincluding MedGemma-4B-it, Qwen2.5-VL, Janus-Pro-7B, and Eagle2-9B. The\nbest-performing model (MedGemma) achieves 83.24% overall accuracy. To bridge\nthe gap between AI performance and clinical expertise, we conducted a\ncomprehensive human reader study involving 3 radiology residents on 200\nrandomly sampled cases. Our evaluation demonstrates that MedGemma achieved\nsuperior performance (83.84% accuracy) compared to human readers (best\nradiology resident: 77.27%), representing a significant milestone where AI\nperformance exceeds expert human evaluation on chest X-ray interpretation. The\nreader study reveals distinct performance patterns between AI models and human\nexperts, with strong inter-reader agreement among radiologists while showing\nmore variable agreement patterns between human readers and AI models. ReXVQA\nestablishes a new standard for evaluating generalist radiological AI systems,\noffering public leaderboards, fine-grained evaluation splits, structured\nexplanations, and category-level breakdowns. This benchmark lays the foundation\nfor next-generation AI systems capable of mimicking expert-level clinical\nreasoning beyond narrow pathology classification. Our dataset will be\nopen-sourced at https://huggingface.co/datasets/rajpurkarlab/ReXVQA", "AI": {"tldr": "ReXVQA is a large benchmark for VQA in chest radiology, featuring diverse tasks and outperforming human experts with AI models like MedGemma.", "motivation": "To create a comprehensive benchmark for evaluating AI in radiological reasoning, surpassing template-based queries and bridging the AI-clinical expertise gap.", "method": "Developed a dataset of 696,000 questions paired with 160,000 chest X-rays, evaluated eight multimodal models, and conducted a human reader study.", "result": "MedGemma achieved 83.24% accuracy, outperforming human readers (77.27%), with distinct performance patterns between AI and humans.", "conclusion": "ReXVQA sets a new standard for radiological AI evaluation, enabling next-generation systems with expert-level clinical reasoning."}}
{"id": "2506.04357", "pdf": "https://arxiv.org/pdf/2506.04357", "abs": "https://arxiv.org/abs/2506.04357", "authors": ["Amirreza Ahmadnejad", "Somayyeh Koohi"], "title": "Optical Physics-Based Generative Models", "categories": ["physics.optics", "cs.LG"], "comment": null, "summary": "This paper establishes a comprehensive mathematical framework connecting\noptical physics equations to generative models, demonstrating how light\npropagation dynamics inspire powerful artificial intelligence approaches. We\nanalyze six fundamental optical equations, comparing linear models (Helmholtz,\ndissipative wave, and Eikonal equations) with their nonlinear extensions\nincorporating Kerr effects, cubic-quintic nonlinearities, and\nintensity-dependent refractive indices. Our nonlinear optical models reveal\nremarkable capabilities through natural self-organization principles. The\nnonlinear Helmholtz model achieves 40-60% parameter reduction while maintaining\nsuperior mode separation via self-focusing phenomena. The cubic-quintic\ndissipative wave model prevents mode collapse through balanced\nattractive-repulsive interactions, enabling stable soliton formation with\n20-40% improved coverage. The intensity-dependent Eikonal model creates\nadaptive pathways that dynamically respond to content, providing enhanced\ncontrollability in conditional generation. Experimental validation demonstrates\nconsistent superiority over linear predecessors and traditional generative\napproaches. The nonlinear Helmholtz model achieves FID scores of 0.0089 versus\n1.0909 for linear versions, while the cubic-quintic model reaches 0.0156 FID\nwith exceptional stability. Memory usage drops 40-60% and training time\nimproves 30-50% due to inherent nonlinear stability properties. The framework\nenables bidirectional benefits, advancing both generative AI and optical\nphysics through novel approaches to soliton analysis, wavefront control, and\nrefractive index reconstruction with 95% accuracy. This work reveals deep\nconnections between physical self-organization and artificial intelligence,\nopening pathways toward efficient optical computing implementations.", "AI": {"tldr": "A mathematical framework links optical physics to generative AI, showing nonlinear optical models outperform linear ones in efficiency, stability, and performance.", "motivation": "To bridge optical physics and generative AI by leveraging nonlinear optical equations for improved AI models.", "method": "Analyzed six optical equations (linear and nonlinear) and applied them to generative models, validating with experiments.", "result": "Nonlinear models reduced parameters by 40-60%, improved FID scores (e.g., 0.0089 vs. 1.0909), and cut memory/training time by 30-60%.", "conclusion": "The framework connects physical self-organization to AI, enhancing both fields and enabling efficient optical computing."}}
{"id": "2506.04381", "pdf": "https://arxiv.org/pdf/2506.04381", "abs": "https://arxiv.org/abs/2506.04381", "authors": ["Neeraj Agrawal", "Saurabh Kumar", "Priyanka Bhatt", "Tanishka Agarwal"], "title": "Hierarchical Text Classification Using Contrastive Learning Informed Path Guided Hierarchy", "categories": ["cs.CL", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2203.03825 by other authors", "summary": "Hierarchical Text Classification (HTC) has recently gained traction given the\nability to handle complex label hierarchy. This has found applications in\ndomains like E- commerce, customer care and medicine industry among other\nreal-world applications. Existing HTC models either encode label hierarchy\nseparately and mix it with text encoding or guide the label hierarchy structure\nin the text encoder. Both approaches capture different characteristics of label\nhierarchy and are complementary to each other. In this paper, we propose a\nHierarchical Text Classification using Contrastive Learning Informed Path\nguided hierarchy (HTC-CLIP), which learns hierarchy-aware text representation\nand text informed path guided hierarchy representation using contrastive\nlearning. During the training of HTC-CLIP, we learn two different sets of class\nprobabilities distributions and during inference, we use the pooled output of\nboth probabilities for each class to get the best of both representations. Our\nresults show that the two previous approaches can be effectively combined into\none architecture to achieve improved performance. Tests on two public benchmark\ndatasets showed an improvement of 0.99 - 2.37% in Macro F1 score using HTC-CLIP\nover the existing state-of-the-art models.", "AI": {"tldr": "HTC-CLIP combines label hierarchy and text encoding via contrastive learning, improving performance over existing models.", "motivation": "Existing HTC models handle label hierarchy and text encoding separately or guide hierarchy in text encoders, but these approaches are complementary.", "method": "HTC-CLIP uses contrastive learning to create hierarchy-aware text and path-guided hierarchy representations, pooling both for inference.", "result": "HTC-CLIP outperforms state-of-the-art models by 0.99-2.37% in Macro F1 score on benchmark datasets.", "conclusion": "Combining complementary approaches in HTC-CLIP enhances hierarchical text classification performance."}}
{"id": "2506.04389", "pdf": "https://arxiv.org/pdf/2506.04389", "abs": "https://arxiv.org/abs/2506.04389", "authors": ["Saurabh Kumar", "Sourav Bansal", "Neeraj Agrawal", "Priyanka Bhatt"], "title": "Building a Few-Shot Cross-Domain Multilingual NLU Model for Customer Care", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Customer care is an essential pillar of the e-commerce shopping experience\nwith companies spending millions of dollars each year, employing automation and\nhuman agents, across geographies (like US, Canada, Mexico, Chile), channels\n(like Chat, Interactive Voice Response (IVR)), and languages (like English,\nSpanish). SOTA pre-trained models like multilingual-BERT, fine-tuned on\nannotated data have shown good performance in downstream tasks relevant to\nCustomer Care. However, model performance is largely subject to the\navailability of sufficient annotated domain-specific data. Cross-domain\navailability of data remains a bottleneck, thus building an intent classifier\nthat generalizes across domains (defined by channel, geography, and language)\nwith only a few annotations, is of great practical value. In this paper, we\npropose an embedder-cum-classifier model architecture which extends\nstate-of-the-art domain-specific models to other domains with only a few\nlabeled samples. We adopt a supervised fine-tuning approach with isotropic\nregularizers to train a domain-specific sentence embedder and a multilingual\nknowledge distillation strategy to generalize this embedder across multiple\ndomains. The trained embedder, further augmented with a simple linear\nclassifier can be deployed for new domains. Experiments on Canada and Mexico\ne-commerce Customer Care dataset with few-shot intent detection show an\nincrease in accuracy by 20-23% against the existing state-of-the-art\npre-trained models.", "AI": {"tldr": "The paper proposes a model architecture for few-shot intent classification in customer care, improving accuracy by 20-23% over SOTA models.", "motivation": "Customer care relies on annotated data, which is scarce across domains (geography, channel, language). Generalizing intent classifiers with minimal annotations is valuable.", "method": "An embedder-cum-classifier model with supervised fine-tuning, isotropic regularizers, and multilingual knowledge distillation to adapt to new domains with few samples.", "result": "Experiments on e-commerce datasets (Canada, Mexico) show a 20-23% accuracy boost over existing models.", "conclusion": "The proposed model effectively generalizes across domains with minimal labeled data, enhancing customer care automation."}}
{"id": "2506.04405", "pdf": "https://arxiv.org/pdf/2506.04405", "abs": "https://arxiv.org/abs/2506.04405", "authors": ["Ran Xu", "Yuchen Zhuang", "Yishan Zhong", "Yue Yu", "Xiangru Tang", "Hang Wu", "May D. Wang", "Peifeng Ruan", "Donghan Yang", "Tao Wang", "Guanghua Xiao", "Carl Yang", "Yang Xie", "Wenqi Shi"], "title": "MedAgentGym: Training LLM Agents for Code-Based Medical Reasoning at Scale", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce MedAgentGYM, the first publicly available training environment\ndesigned to enhance coding-based medical reasoning capabilities in large\nlanguage model (LLM) agents. MedAgentGYM comprises 72,413 task instances across\n129 categories derived from authentic real-world biomedical scenarios. Tasks\nare encapsulated within executable coding environments, each featuring detailed\ntask descriptions, interactive feedback mechanisms, verifiable ground-truth\nannotations, and scalable training trajectory generation. Extensive\nbenchmarking of over 30 LLMs reveals a notable performance disparity between\ncommercial API-based models and open-source counterparts. Leveraging\nMedAgentGYM, Med-Copilot-7B achieves substantial performance gains through\nsupervised fine-tuning (+36.44%) and continued reinforcement learning\n(+42.47%), emerging as an affordable and privacy-preserving alternative\ncompetitive with gpt-4o. By offering both a comprehensive benchmark and\naccessible, expandable training resources within unified execution\nenvironments, MedAgentGYM delivers an integrated platform to develop LLM-based\ncoding assistants for advanced biomedical research and practice.", "AI": {"tldr": "MedAgentGYM is a training environment for enhancing medical reasoning in LLMs, featuring 72,413 tasks across 129 biomedical categories. It benchmarks 30+ LLMs, showing a gap between commercial and open-source models. Med-Copilot-7B, trained with MedAgentGYM, achieves significant gains, offering a competitive alternative to GPT-4.", "motivation": "To address the lack of publicly available training environments for improving coding-based medical reasoning in LLMs, and to bridge the performance gap between commercial and open-source models.", "method": "Developed MedAgentGYM with 72,413 task instances in executable coding environments, including task descriptions, feedback, ground-truth annotations, and scalable training. Benchmarked 30+ LLMs and fine-tuned Med-Copilot-7B using supervised and reinforcement learning.", "result": "Med-Copilot-7B achieved +36.44% performance gain with supervised fine-tuning and +42.47% with reinforcement learning, becoming a competitive alternative to GPT-4.", "conclusion": "MedAgentGYM provides a comprehensive, accessible platform for developing LLM-based coding assistants in biomedicine, bridging gaps in performance and resource availability."}}
{"id": "2506.04421", "pdf": "https://arxiv.org/pdf/2506.04421", "abs": "https://arxiv.org/abs/2506.04421", "authors": ["Hermann Kumbong", "Xian Liu", "Tsung-Yi Lin", "Ming-Yu Liu", "Xihui Liu", "Ziwei Liu", "Daniel Y. Fu", "Christopher R\u00e9", "David W. Romero"], "title": "HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to CVPR 2025. Project Page:\n  https://research.nvidia.com/labs/dir/hmar/", "summary": "Visual Auto-Regressive modeling (VAR) has shown promise in bridging the speed\nand quality gap between autoregressive image models and diffusion models. VAR\nreformulates autoregressive modeling by decomposing an image into successive\nresolution scales. During inference, an image is generated by predicting all\nthe tokens in the next (higher-resolution) scale, conditioned on all tokens in\nall previous (lower-resolution) scales. However, this formulation suffers from\nreduced image quality due to the parallel generation of all tokens in a\nresolution scale; has sequence lengths scaling superlinearly in image\nresolution; and requires retraining to change the sampling schedule.\n  We introduce Hierarchical Masked Auto-Regressive modeling (HMAR), a new image\ngeneration algorithm that alleviates these issues using next-scale prediction\nand masked prediction to generate high-quality images with fast sampling. HMAR\nreformulates next-scale prediction as a Markovian process, wherein the\nprediction of each resolution scale is conditioned only on tokens in its\nimmediate predecessor instead of the tokens in all predecessor resolutions.\nWhen predicting a resolution scale, HMAR uses a controllable multi-step masked\ngeneration procedure to generate a subset of the tokens in each step. On\nImageNet 256x256 and 512x512 benchmarks, HMAR models match or outperform\nparameter-matched VAR, diffusion, and autoregressive baselines. We develop\nefficient IO-aware block-sparse attention kernels that allow HMAR to achieve\nfaster training and inference times over VAR by over 2.5x and 1.75x\nrespectively, as well as over 3x lower inference memory footprint. Finally,\nHMAR yields additional flexibility over VAR; its sampling schedule can be\nchanged without further training, and it can be applied to image editing tasks\nin a zero-shot manner.", "AI": {"tldr": "HMAR improves image generation by addressing VAR's issues with quality, sequence length, and flexibility, offering faster and more efficient performance.", "motivation": "To overcome the limitations of VAR, such as reduced image quality, superlinear sequence length scaling, and inflexible sampling schedules.", "method": "HMAR introduces next-scale prediction as a Markovian process and uses masked prediction for controllable multi-step generation.", "result": "HMAR outperforms VAR, diffusion, and autoregressive models on ImageNet benchmarks, with faster training/inference and lower memory usage.", "conclusion": "HMAR provides a flexible, efficient, and high-quality alternative to VAR for image generation and editing."}}
{"id": "2506.04450", "pdf": "https://arxiv.org/pdf/2506.04450", "abs": "https://arxiv.org/abs/2506.04450", "authors": ["Payel Bhattacharjee", "Fengwei Tian", "Ravi Tandon", "Joseph Lo", "Heidi Hanson", "Geoffrey Rubin", "Nirav Merchant", "John Gounley"], "title": "Learning to Diagnose Privately: DP-Powered LLMs for Radiology Report Classification", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": "19 pages, 5 figures, 2 tables", "summary": "Purpose: This study proposes a framework for fine-tuning large language\nmodels (LLMs) with differential privacy (DP) to perform multi-abnormality\nclassification on radiology report text. By injecting calibrated noise during\nfine-tuning, the framework seeks to mitigate the privacy risks associated with\nsensitive patient data and protect against data leakage while maintaining\nclassification performance. Materials and Methods: We used 50,232 radiology\nreports from the publicly available MIMIC-CXR chest radiography and CT-RATE\ncomputed tomography datasets, collected between 2011 and 2019. Fine-tuning of\nLLMs was conducted to classify 14 labels from MIMIC-CXR dataset, and 18 labels\nfrom CT-RATE dataset using Differentially Private Low-Rank Adaptation (DP-LoRA)\nin high and moderate privacy regimes (across a range of privacy budgets =\n{0.01, 0.1, 1.0, 10.0}). Model performance was evaluated using weighted F1\nscore across three model architectures: BERT-medium, BERT-small, and\nALBERT-base. Statistical analyses compared model performance across different\nprivacy levels to quantify the privacy-utility trade-off. Results: We observe a\nclear privacy-utility trade-off through our experiments on 2 different datasets\nand 3 different models. Under moderate privacy guarantees the DP fine-tuned\nmodels achieved comparable weighted F1 scores of 0.88 on MIMIC-CXR and 0.59 on\nCT-RATE, compared to non-private LoRA baselines of 0.90 and 0.78, respectively.\nConclusion: Differentially private fine-tuning using LoRA enables effective and\nprivacy-preserving multi-abnormality classification from radiology reports,\naddressing a key challenge in fine-tuning LLMs on sensitive medical data.", "AI": {"tldr": "A framework for fine-tuning LLMs with differential privacy (DP) for multi-abnormality classification in radiology reports, balancing privacy and performance.", "motivation": "To mitigate privacy risks in sensitive patient data while maintaining classification performance in radiology reports.", "method": "Fine-tuning LLMs (BERT-medium, BERT-small, ALBERT-base) using DP-LoRA on MIMIC-CXR and CT-RATE datasets, with privacy budgets {0.01, 0.1, 1.0, 10.0}. Performance evaluated via weighted F1 scores.", "result": "DP models achieved comparable performance (F1: 0.88 on MIMIC-CXR, 0.59 on CT-RATE) to non-private baselines (0.90, 0.78), showing a clear privacy-utility trade-off.", "conclusion": "DP-LoRA enables effective, privacy-preserving multi-abnormality classification, addressing challenges in LLM fine-tuning for medical data."}}
{"id": "2506.04453", "pdf": "https://arxiv.org/pdf/2506.04453", "abs": "https://arxiv.org/abs/2506.04453", "authors": ["Hasin Us Sami", "Swapneel Sen", "Amit K. Roy-Chowdhury", "Srikanth V. Krishnamurthy", "Basak Guler"], "title": "Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning", "categories": ["eess.IV", "cs.CR", "cs.CV", "cs.LG"], "comment": "2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  (CVPR 2025)", "summary": "Federated learning (FL) allows multiple data-owners to collaboratively train\nmachine learning models by exchanging local gradients, while keeping their\nprivate data on-device. To simultaneously enhance privacy and training\nefficiency, recently parameter-efficient fine-tuning (PEFT) of large-scale\npretrained models has gained substantial attention in FL. While keeping a\npretrained (backbone) model frozen, each user fine-tunes only a few lightweight\nmodules to be used in conjunction, to fit specific downstream applications.\nAccordingly, only the gradients with respect to these lightweight modules are\nshared with the server. In this work, we investigate how the privacy of the\nfine-tuning data of the users can be compromised via a malicious design of the\npretrained model and trainable adapter modules. We demonstrate gradient\ninversion attacks on a popular PEFT mechanism, the adapter, which allow an\nattacker to reconstruct local data samples of a target user, using only the\naccessible adapter gradients. Via extensive experiments, we demonstrate that a\nlarge batch of fine-tuning images can be retrieved with high fidelity. Our\nattack highlights the need for privacy-preserving mechanisms for PEFT, while\nopening up several future directions. Our code is available at\nhttps://github.com/info-ucr/PEFTLeak.", "AI": {"tldr": "The paper explores privacy risks in federated learning (FL) with parameter-efficient fine-tuning (PEFT), showing how maliciously designed pretrained models can leak user data via gradient inversion attacks on adapters.", "motivation": "To highlight privacy vulnerabilities in FL when using PEFT, where only lightweight modules are fine-tuned, and gradients are shared.", "method": "Demonstrates gradient inversion attacks on adapter modules in PEFT, reconstructing user data from accessible gradients.", "result": "Shows that fine-tuning images can be retrieved with high fidelity, exposing privacy risks.", "conclusion": "Emphasizes the need for privacy-preserving mechanisms in PEFT and suggests future research directions."}}
{"id": "2506.04462", "pdf": "https://arxiv.org/pdf/2506.04462", "abs": "https://arxiv.org/abs/2506.04462", "authors": ["Apurv Verma", "NhatHai Phan", "Shubhendu Trivedi"], "title": "Watermarking Degrades Alignment in Language Models: Analysis and Mitigation", "categories": ["cs.CL", "cs.CR", "cs.LG", "I.2.7"], "comment": "Published at the 1st Workshop on GenAI Watermarking, collocated with\n  ICLR 2025. OpenReview: https://openreview.net/forum?id=SIBkIV48gF", "summary": "Watermarking techniques for large language models (LLMs) can significantly\nimpact output quality, yet their effects on truthfulness, safety, and\nhelpfulness remain critically underexamined. This paper presents a systematic\nanalysis of how two popular watermarking approaches-Gumbel and KGW-affect these\ncore alignment properties across four aligned LLMs. Our experiments reveal two\ndistinct degradation patterns: guard attenuation, where enhanced helpfulness\nundermines model safety, and guard amplification, where excessive caution\nreduces model helpfulness. These patterns emerge from watermark-induced shifts\nin token distribution, surfacing the fundamental tension that exists between\nalignment objectives.\n  To mitigate these degradations, we propose Alignment Resampling (AR), an\ninference-time sampling method that uses an external reward model to restore\nalignment. We establish a theoretical lower bound on the improvement in\nexpected reward score as the sample size is increased and empirically\ndemonstrate that sampling just 2-4 watermarked generations effectively recovers\nor surpasses baseline (unwatermarked) alignment scores. To overcome the limited\nresponse diversity of standard Gumbel watermarking, our modified implementation\nsacrifices strict distortion-freeness while maintaining robust detectability,\nensuring compatibility with AR. Experimental results confirm that AR\nsuccessfully recovers baseline alignment in both watermarking approaches, while\nmaintaining strong watermark detectability. This work reveals the critical\nbalance between watermark strength and model alignment, providing a simple\ninference-time solution to responsibly deploy watermarked LLMs in practice.", "AI": {"tldr": "The paper analyzes how watermarking techniques (Gumbel and KGW) affect LLM alignment (truthfulness, safety, helpfulness), identifies degradation patterns, and proposes Alignment Resampling (AR) to mitigate these issues while maintaining watermark detectability.", "motivation": "To understand the underexamined effects of watermarking on LLM alignment properties (truthfulness, safety, helpfulness) and address the resulting degradation patterns.", "method": "Systematic analysis of two watermarking approaches (Gumbel and KGW) across four aligned LLMs, identifying degradation patterns (guard attenuation and amplification). Proposes AR, an inference-time sampling method using an external reward model.", "result": "AR recovers or surpasses baseline alignment scores with 2-4 watermarked generations, while maintaining strong watermark detectability. Modified Gumbel implementation ensures compatibility with AR.", "conclusion": "The work highlights the balance between watermark strength and alignment, offering AR as a practical solution for deploying watermarked LLMs responsibly."}}
{"id": "2506.04464", "pdf": "https://arxiv.org/pdf/2506.04464", "abs": "https://arxiv.org/abs/2506.04464", "authors": ["Oussama Ben Sghaier", "Rosalia Tufano", "Gabriele Bavota", "Houari Sahraoui"], "title": "Leveraging Reward Models for Guiding Code Review Comment Generation", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Code review is a crucial component of modern software development, involving\nthe evaluation of code quality, providing feedback on potential issues, and\nrefining the code to address identified problems. Despite these benefits, code\nreview can be rather time consuming, and influenced by subjectivity and human\nfactors. For these reasons, techniques to (partially) automate the code review\nprocess have been proposed in the literature. Among those, the ones exploiting\ndeep learning (DL) are able to tackle the generative aspect of code review, by\ncommenting on a given code as a human reviewer would do (i.e., comment\ngeneration task) or by automatically implementing code changes required to\naddress a reviewer's comment (i.e., code refinement task). In this paper, we\nintroduce CoRAL, a deep learning framework automating review comment generation\nby exploiting reinforcement learning with a reward mechanism considering both\nthe semantics of the generated comments as well as their usefulness as input\nfor other models automating the code refinement task. The core idea is that if\nthe DL model generates comments that are semantically similar to the expected\nones or can be successfully implemented by a second model specialized in code\nrefinement, these comments are likely to be meaningful and useful, thus\ndeserving a high reward in the reinforcement learning framework. We present\nboth quantitative and qualitative comparisons between the comments generated by\nCoRAL and those produced by the latest baseline techniques, highlighting the\neffectiveness and superiority of our approach.", "AI": {"tldr": "CoRAL is a DL framework using reinforcement learning to automate code review comment generation, focusing on semantic similarity and usefulness for code refinement.", "motivation": "Code review is time-consuming and subjective; automating it with DL can improve efficiency and consistency.", "method": "CoRAL employs reinforcement learning with a reward mechanism based on comment semantics and usefulness for code refinement.", "result": "CoRAL outperforms baseline techniques in generating meaningful and useful review comments.", "conclusion": "CoRAL effectively automates code review comment generation, demonstrating superiority over existing methods."}}
{"id": "2506.04480", "pdf": "https://arxiv.org/pdf/2506.04480", "abs": "https://arxiv.org/abs/2506.04480", "authors": ["Nina Vesseron", "Elsa Cazelles", "Alice Le Brigant", "Thierry Klein"], "title": "On the Wasserstein Geodesic Principal Component Analysis of probability measures", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "This paper focuses on Geodesic Principal Component Analysis (GPCA) on a\ncollection of probability distributions using the Otto-Wasserstein geometry.\nThe goal is to identify geodesic curves in the space of probability measures\nthat best capture the modes of variation of the underlying dataset. We first\naddress the case of a collection of Gaussian distributions, and show how to\nlift the computations in the space of invertible linear maps. For the more\ngeneral setting of absolutely continuous probability measures, we leverage a\nnovel approach to parameterizing geodesics in Wasserstein space with neural\nnetworks. Finally, we compare to classical tangent PCA through various examples\nand provide illustrations on real-world datasets.", "AI": {"tldr": "The paper introduces Geodesic Principal Component Analysis (GPCA) for probability distributions using Otto-Wasserstein geometry, focusing on Gaussian distributions and neural networks for geodesic parameterization, with comparisons to classical PCA.", "motivation": "To identify geodesic curves in probability measure spaces that capture dataset variations, extending PCA to non-Euclidean settings.", "method": "Uses Otto-Wasserstein geometry for Gaussian distributions and neural networks for general probability measures, comparing results with tangent PCA.", "result": "Demonstrates effective geodesic curve identification and variation capture, validated through examples and real-world datasets.", "conclusion": "GPCA offers a robust framework for analyzing probability distributions, outperforming classical PCA in non-Euclidean contexts."}}
{"id": "2506.04505", "pdf": "https://arxiv.org/pdf/2506.04505", "abs": "https://arxiv.org/abs/2506.04505", "authors": ["Nikita Oskolkov", "Huzhenyu Zhang", "Dmitry Makarov", "Dmitry Yudin", "Aleksandr Panov"], "title": "SGN-CIRL: Scene Graph-based Navigation with Curriculum, Imitation, and Reinforcement Learning", "categories": ["cs.RO", "cs.LG"], "comment": "7 pages, 11 figures", "summary": "The 3D scene graph models spatial relationships between objects, enabling the\nagent to efficiently navigate in a partially observable environment and predict\nthe location of the target object.This paper proposes an original framework\nnamed SGN-CIRL (3D Scene Graph-Based Reinforcement Learning Navigation) for\nmapless reinforcement learning-based robot navigation with learnable\nrepresentation of open-vocabulary 3D scene graph. To accelerate and stabilize\nthe training of reinforcement learning-based algorithms, the framework also\nemploys imitation learning and curriculum learning. The first one enables the\nagent to learn from demonstrations, while the second one structures the\ntraining process by gradually increasing task complexity from simple to more\nadvanced scenarios. Numerical experiments conducted in the Isaac Sim\nenvironment showed that using a 3D scene graph for reinforcement learning\nsignificantly increased the success rate in difficult navigation cases. The\ncode is open-sourced and available at: https://github.com/Xisonik/Aloha\\_graph.", "AI": {"tldr": "The paper introduces SGN-CIRL, a framework for mapless robot navigation using 3D scene graphs and reinforcement learning, enhanced by imitation and curriculum learning for better training.", "motivation": "To improve robot navigation in partially observable environments by leveraging 3D scene graphs for efficient target prediction and navigation.", "method": "Combines reinforcement learning with 3D scene graphs, using imitation learning (learning from demonstrations) and curriculum learning (gradual task complexity increase).", "result": "Experiments in Isaac Sim showed higher success rates in difficult navigation tasks compared to traditional methods.", "conclusion": "SGN-CIRL effectively enhances robot navigation using 3D scene graphs and structured training, with open-sourced code for further use."}}
{"id": "2506.04515", "pdf": "https://arxiv.org/pdf/2506.04515", "abs": "https://arxiv.org/abs/2506.04515", "authors": ["Salil Patel"], "title": "The Latent Space Hypothesis: Toward Universal Medical Representation Learning", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "51 pages, 12 figures. A position paper examining the latent space\n  hypothesis - the proposition that diverse medical data can be represented in\n  shared latent spaces reflecting fundamental biological processes. The paper\n  discusses theoretical foundations, reviews supporting evidence, and considers\n  potential implications for medical AI and representation learning", "summary": "Medical data range from genomic sequences and retinal photographs to\nstructured laboratory results and unstructured clinical narratives. Although\nthese modalities appear disparate, many encode convergent information about a\nsingle underlying physiological state. The Latent Space Hypothesis frames each\nobservation as a projection of a unified, hierarchically organized manifold --\nmuch like shadows cast by the same three-dimensional object. Within this\nlearned geometric representation, an individual's health status occupies a\npoint, disease progression traces a trajectory, and therapeutic intervention\ncorresponds to a directed vector. Interpreting heterogeneous evidence in a\nshared space provides a principled way to re-examine eponymous conditions --\nsuch as Parkinson's or Crohn's -- that often mask multiple pathophysiological\nentities and involve broader anatomical domains than once believed. By\nrevealing sub-trajectories and patient-specific directions of change, the\nframework supplies a quantitative rationale for personalised diagnosis,\nlongitudinal monitoring, and tailored treatment, moving clinical practice away\nfrom grouping by potentially misleading labels toward navigation of each\nperson's unique trajectory. Challenges remain -- bias amplification, data\nscarcity for rare disorders, privacy, and the correlation-causation divide --\nbut scale-aware encoders, continual learning on longitudinal data streams, and\nperturbation-based validation offer plausible paths forward.", "AI": {"tldr": "The paper proposes the Latent Space Hypothesis to unify diverse medical data into a shared geometric representation for personalized healthcare, addressing challenges like bias and data scarcity.", "motivation": "To integrate disparate medical data modalities into a unified framework for better understanding and managing individual health trajectories.", "method": "Uses the Latent Space Hypothesis to model health data as projections of a unified manifold, enabling personalized diagnosis and treatment.", "result": "The framework reveals sub-trajectories and patient-specific changes, supporting tailored healthcare and redefining disease classifications.", "conclusion": "The approach advances personalized medicine but faces challenges like bias and data scarcity, with potential solutions in scale-aware encoders and continual learning."}}
{"id": "2506.04539", "pdf": "https://arxiv.org/pdf/2506.04539", "abs": "https://arxiv.org/abs/2506.04539", "authors": ["Kordel K. France", "Ovidiu Daescu", "Anirban Paul", "Shalini Prasad"], "title": "Olfactory Inertial Odometry: Sensor Calibration and Drift Compensation", "categories": ["cs.RO", "cs.ET", "cs.LG", "cs.SY", "eess.SY"], "comment": "Published as a full conference paper at the 2025 IEEE International\n  Symposium on Inertial Sensors & Systems", "summary": "Visual inertial odometry (VIO) is a process for fusing visual and kinematic\ndata to understand a machine's state in a navigation task. Olfactory inertial\nodometry (OIO) is an analog to VIO that fuses signals from gas sensors with\ninertial data to help a robot navigate by scent. Gas dynamics and environmental\nfactors introduce disturbances into olfactory navigation tasks that can make\nOIO difficult to facilitate. With our work here, we define a process for\ncalibrating a robot for OIO that generalizes to several olfaction sensor types.\nOur focus is specifically on calibrating OIO for centimeter-level accuracy in\nlocalizing an odor source on a slow-moving robot platform to demonstrate use\ncases in robotic surgery and touchless security screening. We demonstrate our\nprocess for OIO calibration on a real robotic arm and show how this calibration\nimproves performance over a cold-start olfactory navigation task.", "AI": {"tldr": "The paper introduces a calibration process for Olfactory Inertial Odometry (OIO) to improve odor source localization accuracy for slow-moving robots, demonstrated on a robotic arm.", "motivation": "Gas dynamics and environmental disturbances make OIO challenging; the work aims to generalize calibration for various olfaction sensors.", "method": "Defines a calibration process for OIO, focusing on centimeter-level accuracy for odor source localization.", "result": "Demonstrated improved performance over cold-start olfactory navigation on a robotic arm.", "conclusion": "The calibration process enhances OIO performance, with potential applications in robotic surgery and touchless security screening."}}
{"id": "2506.04540", "pdf": "https://arxiv.org/pdf/2506.04540", "abs": "https://arxiv.org/abs/2506.04540", "authors": ["Kordel K. France"], "title": "Chronoamperometry with Room-Temperature Ionic Liquids: Sub-Second Inference Techniques", "categories": ["cs.RO", "cs.LG", "physics.chem-ph", "physics.ins-det"], "comment": "Published at IEEE BioSensors 2025", "summary": "Chronoamperometry (CA) is a fundamental electrochemical technique used for\nquantifying redox-active species. However, in room-temperature ionic liquids\n(RTILs), the high viscosity and slow mass transport often lead to extended\nmeasurement durations. This paper presents a novel mathematical regression\napproach that reduces CA measurement windows to under 1 second, significantly\nfaster than previously reported methods, which typically require 1-4 seconds or\nlonger. By applying an inference algorithm to the initial transient current\nresponse, this method accurately predicts steady-state electrochemical\nparameters without requiring additional hardware modifications. The approach is\nvalidated through comparison with standard chronoamperometric techniques and is\ndemonstrated to maintain reasonable accuracy while dramatically reducing data\nacquisition time. The implications of this technique are explored in analytical\nchemistry, sensor technology, and battery science, where rapid electrochemical\nquantification is critical. Our technique is focused on enabling faster\nmultiplexing of chronoamperometric measurements for rapid olfactory and\nelectrochemical analysis.", "AI": {"tldr": "A novel regression method reduces chronoamperometry (CA) measurement time in RTILs to under 1 second, improving speed without hardware changes.", "motivation": "High viscosity and slow mass transport in RTILs extend CA measurement times, limiting efficiency in applications like sensor tech and battery science.", "method": "Uses a mathematical regression approach and inference algorithm on transient current response to predict steady-state parameters quickly.", "result": "Validated against standard CA, the method maintains accuracy while cutting measurement time from 1-4+ seconds to under 1 second.", "conclusion": "This technique enables faster electrochemical quantification, benefiting fields requiring rapid analysis, like sensors and batteries."}}
{"id": "2506.04544", "pdf": "https://arxiv.org/pdf/2506.04544", "abs": "https://arxiv.org/abs/2506.04544", "authors": ["Charles Hong", "Brendan Roberts", "Huijae An", "Alex Um", "Advay Ratan", "Yakun Sophia Shao"], "title": "hdl2v: A Code Translation Dataset for Enhanced LLM Verilog Generation", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.PL"], "comment": null, "summary": "Large language models (LLMs) are playing an increasingly large role in\ndomains such as code generation, including hardware code generation, where\nVerilog is the key language. However, the amount of publicly available Verilog\ncode pales in comparison to the amount of code available for software languages\nlike Python. In this work, we present hdl2v (\"HDL-to-Verilog\"), a dataset which\nseeks to increase the amount of available human-written Verilog data by\ntranslating or compiling three other hardware description languages - VHDL,\nChisel, and PyMTL3 - to Verilog. Furthermore, we demonstrate the value of hdl2v\nin enhancing LLM Verilog generation by improving performance of a 32\nbillion-parameter open-weight model by up to 23% (pass@10) in VerilogEvalV2,\nwithout utilizing any data augmentation or knowledge distillation from larger\nmodels. We also show hdl2v's ability to boost the performance of a data\naugmentation-based fine-tuning approach by 63%. Finally, we characterize and\nanalyze our dataset to better understand which characteristics of\nHDL-to-Verilog datasets can be expanded upon in future work for even better\nperformance.", "AI": {"tldr": "The paper introduces hdl2v, a dataset translating VHDL, Chisel, and PyMTL3 to Verilog to address the scarcity of human-written Verilog data. It shows significant improvements in LLM Verilog generation performance.", "motivation": "The lack of publicly available Verilog code compared to software languages like Python motivates the creation of hdl2v to enhance LLM performance in hardware code generation.", "method": "hdl2v translates or compiles VHDL, Chisel, and PyMTL3 into Verilog, enriching the dataset for training LLMs.", "result": "hdl2v improves a 32B-parameter model's performance by up to 23% in VerilogEvalV2 and boosts a data augmentation-based approach by 63%.", "conclusion": "hdl2v effectively addresses the Verilog data scarcity and enhances LLM performance, with potential for further dataset expansion in future work."}}
{"id": "2506.04554", "pdf": "https://arxiv.org/pdf/2506.04554", "abs": "https://arxiv.org/abs/2506.04554", "authors": ["Hao Huang", "Zelda B. Zabinsky"], "title": "Non-linear Multi-objective Optimization with Probabilistic Branch and Bound", "categories": ["math.OC", "cs.LG"], "comment": "26 pages, 5 Figures", "summary": "A multiple objective simulation optimization algorithm named Multiple\nObjective Probabilistic Branch and Bound with Single Observation (MOPBnB(so))\nis presented for approximating the Pareto optimal set and the associated\nefficient frontier for stochastic multi-objective optimization problems.\nMOPBnB(so) evaluates a noisy function exactly once at any solution and uses\nneighboring solutions to estimate the objective functions, in contrast to a\nvariant that uses multiple replications at a solution to estimate the objective\nfunctions. A finite-time performance analysis for deterministic multi-objective\nproblems provides a bound on the probability that MOPBnB(so) captures the\nPareto optimal set. Asymptotic convergence of MOPBnB(so) on stochastic problems\nis derived, in that the algorithm captures the Pareto optimal set and the\nestimations converge to the true objective function values. Numerical results\nreveal that the variant with multiple replications is extremely intensive in\nterms of computational resources compared to MOPBnB(so). In addition, numerical\nresults show that MOPBnB(so) outperforms a genetic algorithm NSGA-II on test\nproblems.", "AI": {"tldr": "MOPBnB(so) is a simulation optimization algorithm for stochastic multi-objective problems, using single observations and neighboring solutions to estimate objectives, outperforming NSGA-II and being less resource-intensive than multi-replication variants.", "motivation": "To address the computational inefficiency of multi-replication methods in stochastic multi-objective optimization by proposing a single-observation approach.", "method": "MOPBnB(so) evaluates noisy functions once per solution, leveraging neighboring solutions for estimation, and includes finite-time and asymptotic convergence analysis.", "result": "The algorithm captures the Pareto optimal set with proven convergence, and numerical tests show it outperforms NSGA-II and is less resource-heavy than multi-replication variants.", "conclusion": "MOPBnB(so) is an efficient and effective alternative for stochastic multi-objective optimization, balancing accuracy and computational cost."}}
{"id": "2506.04592", "pdf": "https://arxiv.org/pdf/2506.04592", "abs": "https://arxiv.org/abs/2506.04592", "authors": ["Chengwu Liu", "Ye Yuan", "Yichun Yin", "Yan Xu", "Xin Xu", "Zaoyu Chen", "Yasheng Wang", "Lifeng Shang", "Qun Liu", "Ming Zhang"], "title": "Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted in ACL 2025", "summary": "Chain-of-Thought (CoT) prompting has become the de facto method to elicit\nreasoning capabilities from large language models (LLMs). However, to mitigate\nhallucinations in CoT that are notoriously difficult to detect, current methods\nsuch as process reward models (PRMs) or self-consistency operate as opaque\nboxes and do not provide checkable evidence for their judgments, possibly\nlimiting their effectiveness. To address this issue, we draw inspiration from\nthe idea that \"the gold standard for supporting a mathematical claim is to\nprovide a proof\". We propose a retrospective, step-aware formal verification\nframework $Safe$. Rather than assigning arbitrary scores, we strive to\narticulate mathematical claims in formal mathematical language Lean 4 at each\nreasoning step and provide formal proofs to identify hallucinations. We\nevaluate our framework $Safe$ across multiple language models and various\nmathematical datasets, demonstrating a significant performance improvement\nwhile offering interpretable and verifiable evidence. We also propose\n$FormalStep$ as a benchmark for step correctness theorem proving with $30,809$\nformal statements. To the best of our knowledge, our work represents the first\nendeavor to utilize formal mathematical language Lean 4 for verifying natural\nlanguage content generated by LLMs, aligning with the reason why formal\nmathematical languages were created in the first place: to provide a robust\nfoundation for hallucination-prone human-written proofs.", "AI": {"tldr": "The paper introduces $Safe$, a formal verification framework using Lean 4 to detect and mitigate hallucinations in Chain-of-Thought reasoning by providing step-aware proofs.", "motivation": "Current methods like PRMs or self-consistency lack transparency in detecting hallucinations in CoT prompting, necessitating a verifiable solution.", "method": "Proposes $Safe$, a retrospective framework that formalizes reasoning steps in Lean 4 and provides proofs to identify hallucinations.", "result": "Demonstrates significant performance improvement across models and datasets, with interpretable evidence. Introduces $FormalStep$, a benchmark for step correctness.", "conclusion": "$Safe$ is the first to use Lean 4 for verifying LLM-generated content, aligning with formal languages' original purpose of ensuring robust proof foundations."}}
{"id": "2506.04602", "pdf": "https://arxiv.org/pdf/2506.04602", "abs": "https://arxiv.org/abs/2506.04602", "authors": ["Haifeng Sun", "Yu Xiong", "Runze Wu", "Kai Wang", "Lan Zhang", "Changjie Fan", "Shaojie Tang", "Xiang-Yang Li"], "title": "MVP-Shapley: Feature-based Modeling for Evaluating the Most Valuable Player in Basketball", "categories": ["cs.GT", "cs.LG"], "comment": null, "summary": "The burgeoning growth of the esports and multiplayer online gaming community\nhas highlighted the critical importance of evaluating the Most Valuable Player\n(MVP). The establishment of an explainable and practical MVP evaluation method\nis very challenging. In our study, we specifically focus on play-by-play data,\nwhich records related events during the game, such as assists and points. We\naim to address the challenges by introducing a new MVP evaluation framework,\ndenoted as \\oursys, which leverages Shapley values. This approach encompasses\nfeature processing, win-loss model training, Shapley value allocation, and MVP\nranking determination based on players' contributions. Additionally, we\noptimize our algorithm to align with expert voting results from the perspective\nof causality. Finally, we substantiated the efficacy of our method through\nvalidation using the NBA dataset and the Dunk City Dynasty dataset and\nimplemented online deployment in the industry.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.04613", "pdf": "https://arxiv.org/pdf/2506.04613", "abs": "https://arxiv.org/abs/2506.04613", "authors": ["Li Liu", "Heng Yong"], "title": "DeePoly: A High-Order Accuracy and Efficiency Deep-Polynomial Framework for Scientific Machine Learning", "categories": ["cs.AI", "cs.LG"], "comment": "for associated mpeg file, see http://github.com/bfly123/DeePoly", "summary": "Recently, machine learning methods have gained significant traction in\nscientific computing, particularly for solving Partial Differential Equations\n(PDEs). However, methods based on deep neural networks (DNNs) often lack\nconvergence guarantees and computational efficiency compared to traditional\nnumerical schemes. This work introduces DeePoly, a novel framework that\ntransforms the solution paradigm from pure non-convex parameter optimization to\na two-stage approach: first employing a DNN to capture complex global features,\nfollowed by linear space optimization with combined DNN-extracted features\n(Scoper) and polynomial basis functions (Sniper). This strategic combination\nleverages the complementary strengths of both methods -- DNNs excel at\napproximating complex global features (i.e., high-gradient features) and\nstabilize the polynomial approximation while polynomial bases provide\nhigh-precision local corrections with convergence guarantees. Theoretical\nanalysis and numerical experiments demonstrate that this approach significantly\nenhances both high-order accuracy and efficiency across diverse problem types\nwhile maintaining mesh-free and scheme-free properties. This paper also serves\nas a theoretical exposition for the open-source project DeePoly.", "AI": {"tldr": "DeePoly combines DNNs and polynomial bases for solving PDEs, improving accuracy and efficiency while ensuring convergence.", "motivation": "Traditional DNN-based methods for PDEs lack convergence guarantees and efficiency compared to numerical schemes.", "method": "DeePoly uses a two-stage approach: DNNs for global features and polynomial bases for local corrections.", "result": "The method achieves high-order accuracy, efficiency, and maintains mesh-free properties.", "conclusion": "DeePoly offers a robust, efficient solution for PDEs, supported by theory and experiments."}}
{"id": "2506.04624", "pdf": "https://arxiv.org/pdf/2506.04624", "abs": "https://arxiv.org/abs/2506.04624", "authors": ["Takashi Wada", "Yuki Hirakawa", "Ryotaro Shimizu", "Takahiro Kawashima", "Yuki Saito"], "title": "Static Word Embeddings for Sentence Semantic Representation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "15 pages", "summary": "We propose new static word embeddings optimised for sentence semantic\nrepresentation. We first extract word embeddings from a pre-trained Sentence\nTransformer, and improve them with sentence-level principal component analysis,\nfollowed by either knowledge distillation or contrastive learning. During\ninference, we represent sentences by simply averaging word embeddings, which\nrequires little computational cost. We evaluate models on both monolingual and\ncross-lingual tasks and show that our model substantially outperforms existing\nstatic models on sentence semantic tasks, and even rivals a basic Sentence\nTransformer model (SimCSE) on some data sets. Lastly, we perform a variety of\nanalyses and show that our method successfully removes word embedding\ncomponents that are irrelevant to sentence semantics, and adjusts the vector\nnorms based on the influence of words on sentence semantics.", "AI": {"tldr": "Proposes static word embeddings optimized for sentence semantics via PCA and learning methods, outperforming existing models and rivaling basic Sentence Transformers.", "motivation": "To enhance sentence semantic representation using computationally efficient static word embeddings.", "method": "Extracts word embeddings from a pre-trained Sentence Transformer, improves them with PCA, and applies knowledge distillation or contrastive learning. Sentence representation is done by averaging word embeddings.", "result": "Outperforms existing static models on semantic tasks and rivals basic Sentence Transformers (SimCSE) on some datasets.", "conclusion": "The method effectively removes irrelevant word embedding components and adjusts vector norms based on word influence, achieving strong performance."}}
{"id": "2506.04626", "pdf": "https://arxiv.org/pdf/2506.04626", "abs": "https://arxiv.org/abs/2506.04626", "authors": ["Haochen Zhang", "Zhong Zheng", "Lingzhou Xue"], "title": "Regret-Optimal Q-Learning with Low Cost for Single-Agent and Federated Reinforcement Learning", "categories": ["stat.ML", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2502.02859", "summary": "Motivated by real-world settings where data collection and policy deployment\n-- whether for a single agent or across multiple agents -- are costly, we study\nthe problem of on-policy single-agent reinforcement learning (RL) and federated\nRL (FRL) with a focus on minimizing burn-in costs (the sample sizes needed to\nreach near-optimal regret) and policy switching or communication costs. In\nparallel finite-horizon episodic Markov Decision Processes (MDPs) with $S$\nstates and $A$ actions, existing methods either require superlinear burn-in\ncosts in $S$ and $A$ or fail to achieve logarithmic switching or communication\ncosts. We propose two novel model-free RL algorithms -- Q-EarlySettled-LowCost\nand FedQ-EarlySettled-LowCost -- that are the first in the literature to\nsimultaneously achieve: (i) the best near-optimal regret among all known\nmodel-free RL or FRL algorithms, (ii) low burn-in cost that scales linearly\nwith $S$ and $A$, and (iii) logarithmic policy switching cost for single-agent\nRL or communication cost for FRL. Additionally, we establish gap-dependent\ntheoretical guarantees for both regret and switching/communication costs,\nimproving or matching the best-known gap-dependent bounds.", "AI": {"tldr": "The paper introduces two model-free RL algorithms (Q-EarlySettled-LowCost and FedQ-EarlySettled-LowCost) to minimize burn-in and switching/communication costs in single-agent and federated RL, achieving near-optimal regret with linear burn-in and logarithmic switching/communication costs.", "motivation": "Address costly data collection and policy deployment in RL by minimizing burn-in and switching/communication costs.", "method": "Proposes Q-EarlySettled-LowCost for single-agent RL and FedQ-EarlySettled-LowCost for federated RL, focusing on linear burn-in and logarithmic switching/communication costs.", "result": "Achieves near-optimal regret, linear burn-in cost in S and A, and logarithmic switching/communication costs, with improved gap-dependent bounds.", "conclusion": "The algorithms outperform existing methods by balancing efficiency and performance in RL and FRL settings."}}
{"id": "2506.04658", "pdf": "https://arxiv.org/pdf/2506.04658", "abs": "https://arxiv.org/abs/2506.04658", "authors": ["J\u0119drzej Maskiewicz", "Pawe\u0142 Sakowski"], "title": "Can Artificial Intelligence Trade the Stock Market?", "categories": ["q-fin.TR", "cs.LG", "q-fin.CP"], "comment": null, "summary": "The paper explores the use of Deep Reinforcement Learning (DRL) in stock\nmarket trading, focusing on two algorithms: Double Deep Q-Network (DDQN) and\nProximal Policy Optimization (PPO) and compares them with Buy and Hold\nbenchmark. It evaluates these algorithms across three currency pairs, the S&P\n500 index and Bitcoin, on the daily data in the period of 2019-2023. The\nresults demonstrate DRL's effectiveness in trading and its ability to manage\nrisk by strategically avoiding trades in unfavorable conditions, providing a\nsubstantial edge over classical approaches, based on supervised learning in\nterms of risk-adjusted returns.", "AI": {"tldr": "The paper compares Deep Reinforcement Learning (DRL) algorithms (DDQN and PPO) with Buy and Hold in stock trading, showing DRL's superior risk-adjusted returns.", "motivation": "To evaluate DRL's effectiveness in stock market trading and its ability to manage risk compared to traditional methods.", "method": "Uses DDQN and PPO algorithms, testing on currency pairs, S&P 500, and Bitcoin (2019-2023 daily data).", "result": "DRL outperforms Buy and Hold, managing risk by avoiding unfavorable trades.", "conclusion": "DRL provides a significant advantage over classical supervised learning methods in trading."}}
{"id": "2506.04667", "pdf": "https://arxiv.org/pdf/2506.04667", "abs": "https://arxiv.org/abs/2506.04667", "authors": ["Osayamen Jonathan Aimuyo", "Byungsoo Oh", "Rachee Singh"], "title": "FlashDMoE: Fast Distributed MoE in a Single Kernel", "categories": ["cs.DC", "cs.AR", "cs.LG"], "comment": "In submission. See code at https://github.com/osayamenja/Aristos", "summary": "The computational sparsity of Mixture-of-Experts (MoE) models enables\nsub-linear growth in compute cost as model size increases, offering a scalable\npath to training massive neural networks. However, existing implementations\nsuffer from \\emph{low GPU utilization}, \\emph{significant latency overhead},\nand a fundamental \\emph{inability to leverage task locality}, primarily due to\nCPU-managed scheduling, host-initiated communication, and frequent kernel\nlaunches. To overcome these limitations, we develop FlashDMoE, a fully\nGPU-resident MoE operator that fuses expert computation and inter-GPU\ncommunication into a \\emph{single persistent GPU kernel}. FlashDMoE enables\nfine-grained pipelining of dispatch, compute, and combine phases, eliminating\nlaunch overheads and reducing idle gaps. Its device-initiated communication\nprotocol introduces \\emph{payload-efficient} data transfers, significantly\nshrinking buffer sizes in sparsely activated MoE layers. When evaluated on a\nsingle 8-H100 GPU node with MoE models having up to 128 experts and 16K token\nsequences, FlashDMoE achieves up to \\textbf{6}x lower latency, \\textbf{5,7}x\nhigher throughput, \\textbf{4}x better weak scaling efficiency, and \\textbf{9}x\nhigher GPU utilization compared to state-of-the-art baselines, despite using\nFP32 while baselines use FP16. FlashDMoE demonstrates that principled GPU\nkernel-hardware co-design is key to unlocking the performance ceiling of\nlarge-scale distributed ML workloads.", "AI": {"tldr": "FlashDMoE is a GPU-resident MoE operator that improves efficiency by fusing computation and communication into a single kernel, achieving significant performance gains over existing methods.", "motivation": "Existing MoE implementations suffer from low GPU utilization, high latency, and inefficiencies due to CPU-managed scheduling and frequent kernel launches.", "method": "FlashDMoE integrates expert computation and inter-GPU communication into a single persistent GPU kernel, enabling fine-grained pipelining and device-initiated communication.", "result": "FlashDMoE achieves up to 6x lower latency, 5.7x higher throughput, 4x better weak scaling efficiency, and 9x higher GPU utilization compared to baselines.", "conclusion": "Principled GPU kernel-hardware co-design is crucial for optimizing large-scale distributed ML workloads, as demonstrated by FlashDMoE."}}
{"id": "2506.04676", "pdf": "https://arxiv.org/pdf/2506.04676", "abs": "https://arxiv.org/abs/2506.04676", "authors": ["Jing-En Huang", "I-Sheng Fang", "Tzuhsuan Huang", "Chih-Yu Wang", "Jun-Cheng Chen"], "title": "Gen-n-Val: Agentic Image Data Generation and Validation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Recently, Large Language Models (LLMs) and Vision Large Language Models\n(VLLMs) have demonstrated impressive performance as agents across various tasks\nwhile data scarcity and label noise remain significant challenges in computer\nvision tasks, such as object detection and instance segmentation. A common\nsolution for resolving these issues is to generate synthetic data. However,\ncurrent synthetic data generation methods struggle with issues, such as\nmultiple objects per mask, inaccurate segmentation, and incorrect category\nlabels, limiting their effectiveness. To address these issues, we introduce\nGen-n-Val, a novel agentic data generation framework that leverages Layer\nDiffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks\nand diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt\nagent, an LLM, optimizes prompts for LD to generate high-quality foreground\ninstance images and segmentation masks. These optimized prompts ensure the\ngeneration of single-object synthetic data with precise instance masks and\nclean backgrounds. (2) The data validation agent, a VLLM, which filters out\nlow-quality synthetic instance images. The system prompts for both agents are\nrefined through TextGrad. Additionally, we use image harmonization to combine\nmultiple instances within scenes. Compared to state-of-the-art synthetic data\napproaches like MosaicFusion, our approach reduces invalid synthetic data from\n50% to 7% and improves performance by 1% mAP on rare classes in COCO instance\nsegmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant\nimprovements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object\ndetection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance\nof YOLOv9 and YOLO11 families in instance segmentation and object detection.", "AI": {"tldr": "Gen-n-Val is a novel framework using LLMs and VLLMs to generate high-quality synthetic data for computer vision tasks, reducing invalid data and improving performance.", "motivation": "Addressing challenges like data scarcity, label noise, and poor-quality synthetic data in computer vision tasks.", "method": "Uses Layer Diffusion, LLMs, and VLLMs to generate single-object masks and diverse backgrounds, with two agents: one for prompt optimization and another for data validation.", "result": "Reduces invalid synthetic data from 50% to 7% and improves performance by 1% mAP on rare classes in COCO instance segmentation. Also shows 7.1% mAP improvement in open-vocabulary object detection.", "conclusion": "Gen-n-Val significantly enhances synthetic data quality and model performance in instance segmentation and object detection."}}
{"id": "2506.04689", "pdf": "https://arxiv.org/pdf/2506.04689", "abs": "https://arxiv.org/abs/2506.04689", "authors": ["Thao Nguyen", "Yang Li", "Olga Golovneva", "Luke Zettlemoyer", "Sewoong Oh", "Ludwig Schmidt", "Xian Li"], "title": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Scaling laws predict that the performance of large language models improves\nwith increasing model size and data size. In practice, pre-training has been\nrelying on massive web crawls, using almost all data sources publicly available\non the internet so far. However, this pool of natural data does not grow at the\nsame rate as the compute supply. Furthermore, the availability of high-quality\ntexts is even more limited: data filtering pipelines often remove up to 99% of\nthe initial web scrapes to achieve state-of-the-art. To address the \"data wall\"\nof pre-training scaling, our work explores ways to transform and recycle data\ndiscarded in existing filtering processes. We propose REWIRE, REcycling the Web\nwith guIded REwrite, a method to enrich low-quality documents so that they\ncould become useful for training. This in turn allows us to increase the\nrepresentation of synthetic data in the final pre-training set. Experiments at\n1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw\ntexts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points\nimprovement respectively across 22 diverse tasks, compared to training on only\nfiltered web data. Training on the raw-synthetic data mix is also more\neffective than having access to 2x web data. Through further analysis, we\ndemonstrate that about 82% of the mixed in texts come from transforming\nlower-quality documents that would otherwise be discarded. REWIRE also\noutperforms related approaches of generating synthetic data, including\nWikipedia-style paraphrasing, question-answer synthesizing and knowledge\nextraction. These results suggest that recycling web texts holds the potential\nfor being a simple and effective approach for scaling pre-training data.", "AI": {"tldr": "REWIRE recycles low-quality web data by enriching it, improving model performance when mixed with high-quality data.", "motivation": "Address the 'data wall' in pre-training by transforming discarded low-quality data into useful training material.", "method": "Proposes REWIRE, a method to rewrite and enrich low-quality documents for training.", "result": "Mixing rewritten texts with high-quality data improves performance by 1.0-2.5 percentage points across tasks.", "conclusion": "Recycling web texts is a simple and effective way to scale pre-training data."}}
{"id": "2506.04717", "pdf": "https://arxiv.org/pdf/2506.04717", "abs": "https://arxiv.org/abs/2506.04717", "authors": ["Babar Hussain", "Qiang Liu", "Gang Chen", "Bihai She", "Dahai Yu"], "title": "Using In-Context Learning for Automatic Defect Labelling of Display Manufacturing Data", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper presents an AI-assisted auto-labeling system for display panel\ndefect detection that leverages in-context learning capabilities. We adopt and\nenhance the SegGPT architecture with several domain-specific training\ntechniques and introduce a scribble-based annotation mechanism to streamline\nthe labeling process. Our two-stage training approach, validated on industrial\ndisplay panel datasets, demonstrates significant improvements over the baseline\nmodel, achieving an average IoU increase of 0.22 and a 14% improvement in\nrecall across multiple product types, while maintaining approximately 60%\nauto-labeling coverage. Experimental results show that models trained on our\nauto-labeled data match the performance of those trained on human-labeled data,\noffering a practical solution for reducing manual annotation efforts in\nindustrial inspection systems.", "AI": {"tldr": "An AI-assisted auto-labeling system for display panel defect detection using enhanced SegGPT and scribble-based annotation, achieving significant performance improvements and reducing manual effort.", "motivation": "To reduce manual annotation efforts in industrial inspection systems by developing an efficient auto-labeling solution.", "method": "Enhanced SegGPT architecture with domain-specific training techniques and a scribble-based annotation mechanism, validated via a two-stage training approach on industrial datasets.", "result": "Achieved an average IoU increase of 0.22, 14% recall improvement, and 60% auto-labeling coverage, matching human-labeled data performance.", "conclusion": "The system offers a practical solution for industrial defect detection, significantly reducing manual annotation while maintaining high accuracy."}}
{"id": "2506.04774", "pdf": "https://arxiv.org/pdf/2506.04774", "abs": "https://arxiv.org/abs/2506.04774", "authors": ["Jingyu Hu", "Mengyue Yang", "Mengnan Du", "Weiru Liu"], "title": "Fine-Grained Interpretation of Political Opinions in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Studies of LLMs' political opinions mainly rely on evaluations of their\nopen-ended responses. Recent work indicates that there is a misalignment\nbetween LLMs' responses and their internal intentions. This motivates us to\nprobe LLMs' internal mechanisms and help uncover their internal political\nstates. Additionally, we found that the analysis of LLMs' political opinions\noften relies on single-axis concepts, which can lead to concept confounds. In\nthis work, we extend the single-axis to multi-dimensions and apply\ninterpretable representation engineering techniques for more transparent LLM\npolitical concept learning. Specifically, we designed a four-dimensional\npolitical learning framework and constructed a corresponding dataset for\nfine-grained political concept vector learning. These vectors can be used to\ndetect and intervene in LLM internals. Experiments are conducted on eight\nopen-source LLMs with three representation engineering techniques. Results show\nthese vectors can disentangle political concept confounds. Detection tasks\nvalidate the semantic meaning of the vectors and show good generalization and\nrobustness in OOD settings. Intervention Experiments show these vectors can\nintervene in LLMs to generate responses with different political leanings.", "AI": {"tldr": "The paper explores LLMs' political opinions by probing their internal mechanisms and addressing concept confounds in single-axis evaluations. It introduces a multi-dimensional framework and interpretable techniques for transparent political concept learning, validated through experiments on eight LLMs.", "motivation": "Misalignment between LLMs' responses and internal intentions, and reliance on single-axis concepts leading to confounds, motivate the need for deeper probing and multi-dimensional analysis.", "method": "A four-dimensional political learning framework is designed, with a corresponding dataset for fine-grained concept vector learning. Three representation engineering techniques are applied to eight open-source LLMs.", "result": "The vectors disentangle political concept confounds, show semantic meaning in detection tasks, and generalize well in OOD settings. Intervention experiments demonstrate their ability to alter LLM responses' political leanings.", "conclusion": "The multi-dimensional approach and interpretable techniques effectively uncover and intervene in LLMs' political states, addressing limitations of single-axis evaluations."}}
{"id": "2506.04788", "pdf": "https://arxiv.org/pdf/2506.04788", "abs": "https://arxiv.org/abs/2506.04788", "authors": ["Jisu An", "Junseok Lee", "Jeoungeun Lee", "Yongseok Son"], "title": "Towards LLM-Centric Multimodal Fusion: A Survey on Integration Strategies and Techniques", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "18 pages, 3 figures, 3 tables", "summary": "The rapid progress of Multimodal Large Language Models(MLLMs) has transformed\nthe AI landscape. These models combine pre-trained LLMs with various modality\nencoders. This integration requires a systematic understanding of how different\nmodalities connect to the language backbone. Our survey presents an LLM-centric\nanalysis of current approaches. We examine methods for transforming and\naligning diverse modal inputs into the language embedding space. This addresses\na significant gap in existing literature. We propose a classification framework\nfor MLLMs based on three key dimensions. First, we examine architectural\nstrategies for modality integration. This includes both the specific\nintegration mechanisms and the fusion level. Second, we categorize\nrepresentation learning techniques as either joint or coordinate\nrepresentations. Third, we analyze training paradigms, including training\nstrategies and objective functions. By examining 125 MLLMs developed between\n2021 and 2025, we identify emerging patterns in the field. Our taxonomy\nprovides researchers with a structured overview of current integration\ntechniques. These insights aim to guide the development of more robust\nmultimodal integration strategies for future models built on pre-trained\nfoundations.", "AI": {"tldr": "The paper surveys Multimodal Large Language Models (MLLMs), focusing on integrating diverse modalities into language models, proposing a classification framework, and analyzing 125 models to guide future development.", "motivation": "To address the gap in systematic understanding of how different modalities connect to language models in MLLMs.", "method": "The study examines architectural strategies, representation learning techniques, and training paradigms, analyzing 125 MLLMs.", "result": "A classification framework for MLLMs is proposed, identifying emerging patterns in modality integration.", "conclusion": "The taxonomy provides a structured overview to guide robust multimodal integration in future models."}}
{"id": "2506.04790", "pdf": "https://arxiv.org/pdf/2506.04790", "abs": "https://arxiv.org/abs/2506.04790", "authors": ["Yusuke Matsui"], "title": "LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table", "categories": ["cs.CV", "cs.IR", "cs.LG"], "comment": "CVPR 2025. GitHub: https://github.com/matsui528/lotf", "summary": "Approximate nearest neighbor search (ANNS) is an essential building block for\napplications like RAG but can sometimes yield results that are overly similar\nto each other. In certain scenarios, search results should be similar to the\nquery and yet diverse. We propose LotusFilter, a post-processing module to\ndiversify ANNS results. We precompute a cutoff table summarizing vectors that\nare close to each other. During the filtering, LotusFilter greedily looks up\nthe table to delete redundant vectors from the candidates. We demonstrated that\nthe LotusFilter operates fast (0.02 [ms/query]) in settings resembling\nreal-world RAG applications, utilizing features such as OpenAI embeddings. Our\ncode is publicly available at https://github.com/matsui528/lotf.", "AI": {"tldr": "LotusFilter is a fast post-processing module to diversify ANNS results by removing redundant vectors using a precomputed cutoff table.", "motivation": "ANNS can produce overly similar results; diverse results are needed for applications like RAG.", "method": "Precompute a cutoff table of close vectors; greedily remove redundant vectors during filtering.", "result": "Operates fast (0.02 ms/query) in real-world RAG settings using OpenAI embeddings.", "conclusion": "LotusFilter effectively diversifies ANNS results efficiently."}}
{"id": "2506.04813", "pdf": "https://arxiv.org/pdf/2506.04813", "abs": "https://arxiv.org/abs/2506.04813", "authors": ["S\u00e9bastien Da Veiga"], "title": "Distributional encoding for Gaussian process regression with qualitative inputs", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Gaussian Process (GP) regression is a popular and sample-efficient approach\nfor many engineering applications, where observations are expensive to acquire,\nand is also a central ingredient of Bayesian optimization (BO), a highly\nprevailing method for the optimization of black-box functions. However, when\nall or some input variables are categorical, building a predictive and\ncomputationally efficient GP remains challenging. Starting from the naive\ntarget encoding idea, where the original categorical values are replaced with\nthe mean of the target variable for that category, we propose a generalization\nbased on distributional encoding (DE) which makes use of all samples of the\ntarget variable for a category. To handle this type of encoding inside the GP,\nwe build upon recent results on characteristic kernels for probability\ndistributions, based on the maximum mean discrepancy and the Wasserstein\ndistance. We also discuss several extensions for classification, multi-task\nlearning and incorporation or auxiliary information. Our approach is validated\nempirically, and we demonstrate state-of-the-art predictive performance on a\nvariety of synthetic and real-world datasets. DE is naturally complementary to\nrecent advances in BO over discrete and mixed-spaces.", "AI": {"tldr": "The paper proposes a distributional encoding (DE) method for Gaussian Process (GP) regression to handle categorical variables, improving predictive performance and computational efficiency.", "motivation": "GP regression struggles with categorical variables, limiting its effectiveness in applications like Bayesian optimization (BO). The paper aims to address this gap.", "method": "The authors generalize naive target encoding to DE, leveraging all target variable samples for a category. They use characteristic kernels (maximum mean discrepancy, Wasserstein distance) for GP integration.", "result": "Empirical validation shows state-of-the-art predictive performance on synthetic and real-world datasets. DE complements recent BO advances in discrete/mixed spaces.", "conclusion": "DE enhances GP regression for categorical variables, offering improved performance and compatibility with BO methods."}}
{"id": "2506.04823", "pdf": "https://arxiv.org/pdf/2506.04823", "abs": "https://arxiv.org/abs/2506.04823", "authors": ["Svetlana Pavlitska", "Jamie Robb", "Nikolai Polley", "Melih Yazgan", "J. Marius Z\u00f6llner"], "title": "Fool the Stoplight: Realistic Adversarial Patch Attacks on Traffic Light Detectors", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted for publication at IV 2025", "summary": "Realistic adversarial attacks on various camera-based perception tasks of\nautonomous vehicles have been successfully demonstrated so far. However, only a\nfew works considered attacks on traffic light detectors. This work shows how\nCNNs for traffic light detection can be attacked with printed patches. We\npropose a threat model, where each instance of a traffic light is attacked with\na patch placed under it, and describe a training strategy. We demonstrate\nsuccessful adversarial patch attacks in universal settings. Our experiments\nshow realistic targeted red-to-green label-flipping attacks and attacks on\npictogram classification. Finally, we perform a real-world evaluation with\nprinted patches and demonstrate attacks in the lab settings with a mobile\ntraffic light for construction sites and in a test area with stationary traffic\nlights. Our code is available at\nhttps://github.com/KASTEL-MobilityLab/attacks-on-traffic-light-detection.", "AI": {"tldr": "The paper demonstrates adversarial attacks on traffic light detectors using printed patches, showing successful label-flipping and classification attacks in real-world settings.", "motivation": "Despite successful adversarial attacks on autonomous vehicle perception tasks, traffic light detectors have been underexplored. This work addresses this gap.", "method": "The authors propose a threat model with patches placed under traffic lights and a training strategy for CNNs. They test attacks in universal settings and real-world scenarios.", "result": "Successful targeted attacks (e.g., red-to-green label flipping) and pictogram classification attacks are demonstrated, validated with printed patches in lab and test environments.", "conclusion": "The study highlights vulnerabilities in traffic light detectors and provides a practical framework for adversarial attacks, with code made publicly available."}}
{"id": "2506.04852", "pdf": "https://arxiv.org/pdf/2506.04852", "abs": "https://arxiv.org/abs/2506.04852", "authors": ["Vishwa Mohan Singh", "Sai Anirudh Aryasomayajula", "Ahan Chatterjee", "Beste Aydemir", "Rifat Mehreen Amin"], "title": "Improving AI-generated music with user-guided training", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS"], "comment": "Select for presentation in HHAI 2025", "summary": "AI music generation has advanced rapidly, with models like diffusion and\nautoregressive algorithms enabling high-fidelity outputs. These tools can alter\nstyles, mix instruments, or isolate them. Since sound can be visualized as\nspectrograms, image-generation algorithms can be applied to generate novel\nmusic. However, these algorithms are typically trained on fixed datasets, which\nmakes it challenging for them to interpret and respond to user input\naccurately. This is especially problematic because music is highly subjective\nand requires a level of personalization that image generation does not provide.\nIn this work, we propose a human-computation approach to gradually improve the\nperformance of these algorithms based on user interactions. The\nhuman-computation element involves aggregating and selecting user ratings to\nuse as the loss function for fine-tuning the model. We employ a genetic\nalgorithm that incorporates user feedback to enhance the baseline performance\nof a model initially trained on a fixed dataset. The effectiveness of this\napproach is measured by the average increase in user ratings with each\niteration. In the pilot test, the first iteration showed an average rating\nincrease of 0.2 compared to the baseline. The second iteration further improved\nupon this, achieving an additional increase of 0.39 over the first iteration.", "AI": {"tldr": "The paper proposes a human-computation approach to improve AI music generation by incorporating user feedback via a genetic algorithm, showing incremental performance gains.", "motivation": "Current AI music generation models lack personalization due to fixed datasets, making them less responsive to subjective user preferences.", "method": "A genetic algorithm aggregates user ratings to fine-tune the model, using feedback as the loss function.", "result": "Pilot tests showed rating increases of 0.2 (first iteration) and 0.39 (second iteration) over baseline.", "conclusion": "Human-computation enhances AI music generation by iteratively improving model performance based on user input."}}
{"id": "2506.04867", "pdf": "https://arxiv.org/pdf/2506.04867", "abs": "https://arxiv.org/abs/2506.04867", "authors": ["J\u00f4nata Tyska Carvalho", "Stefano Nolfi"], "title": "LLMs for sensory-motor control: Combining in-context and iterative learning", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.RO"], "comment": "24 pages (13 pages are from appendix), 6 figures, code for\n  experiments replication and supplementary material provided at\n  https://github.com/jtyska/llm-robotics-article/", "summary": "We propose a method that enables large language models (LLMs) to control\nembodied agents by directly mapping continuous observation vectors to\ncontinuous action vectors. Initially, the LLMs generate a control strategy\nbased on a textual description of the agent, its environment, and the intended\ngoal. This strategy is then iteratively refined through a learning process in\nwhich the LLMs are repeatedly prompted to improve the current strategy, using\nperformance feedback and sensory-motor data collected during its evaluation.\nThe method is validated on classic control tasks from the Gymnasium library and\nthe inverted pendulum task from the MuJoCo library. In most cases, it\nsuccessfully identifies optimal or high-performing solutions by integrating\nsymbolic knowledge derived through reasoning with sub-symbolic sensory-motor\ndata gathered as the agent interacts with its environment.", "AI": {"tldr": "A method for LLMs to control embodied agents by mapping observations to actions, refining strategies iteratively with feedback, validated on Gymnasium and MuJoCo tasks.", "motivation": "To integrate symbolic reasoning from LLMs with sub-symbolic sensory-motor data for effective agent control.", "method": "LLMs generate and refine control strategies using textual descriptions, feedback, and sensory-motor data.", "result": "Successfully identifies optimal or high-performing solutions in classic control tasks.", "conclusion": "Combining symbolic and sub-symbolic approaches enhances agent control in dynamic environments."}}
{"id": "2506.04878", "pdf": "https://arxiv.org/pdf/2506.04878", "abs": "https://arxiv.org/abs/2506.04878", "authors": ["Iosif Lytras", "Sotirios Sabanis", "Ying Zhang"], "title": "kTULA: A Langevin sampling algorithm with improved KL bounds under super-linear log-gradients", "categories": ["math.ST", "cs.LG", "math.PR", "stat.ML", "stat.TH"], "comment": null, "summary": "Motivated by applications in deep learning, where the global Lipschitz\ncontinuity condition is often not satisfied, we examine the problem of sampling\nfrom distributions with super-linearly growing log-gradients. We propose a\nnovel tamed Langevin dynamics-based algorithm, called kTULA, to solve the\naforementioned sampling problem, and provide a theoretical guarantee for its\nperformance. More precisely, we establish a non-asymptotic convergence bound in\nKullback-Leibler (KL) divergence with the best-known rate of convergence equal\nto $2-\\overline{\\epsilon}$, $\\overline{\\epsilon}>0$, which significantly\nimproves relevant results in existing literature. This enables us to obtain an\nimproved non-asymptotic error bound in Wasserstein-2 distance, which can be\nused to further derive a non-asymptotic guarantee for kTULA to solve the\nassociated optimization problems. To illustrate the applicability of kTULA, we\napply the proposed algorithm to the problem of sampling from a high-dimensional\ndouble-well potential distribution and to an optimization problem involving a\nneural network. We show that our main results can be used to provide\ntheoretical guarantees for the performance of kTULA.", "AI": {"tldr": "The paper introduces kTULA, a tamed Langevin dynamics-based algorithm, for sampling from distributions with super-linearly growing log-gradients, offering improved convergence rates in KL divergence and Wasserstein-2 distance.", "motivation": "Addressing the challenge of sampling from distributions with super-linearly growing log-gradients, particularly in deep learning where global Lipschitz continuity is often unmet.", "method": "Proposes kTULA, a novel tamed Langevin dynamics algorithm, and provides theoretical guarantees for its convergence in KL divergence and Wasserstein-2 distance.", "result": "Achieves a non-asymptotic convergence bound in KL divergence with a rate of $2-\\overline{\\epsilon}$, improving existing literature, and demonstrates applicability in high-dimensional sampling and neural network optimization.", "conclusion": "kTULA effectively addresses the sampling problem with theoretical guarantees, showcasing its utility in practical scenarios like deep learning and optimization."}}
{"id": "2506.04891", "pdf": "https://arxiv.org/pdf/2506.04891", "abs": "https://arxiv.org/abs/2506.04891", "authors": ["Viacheslav Kuzmin", "Basil Kyriacou", "Mateusz Papierz", "Mo Kordzanganeh", "Alexey Melnikov"], "title": "TQml Simulator: Optimized Simulation of Quantum Machine Learning", "categories": ["quant-ph", "cs.ET", "cs.LG", "cs.PF"], "comment": "25 pages, 13 figures, 1 table", "summary": "Hardware-efficient circuits employed in Quantum Machine Learning are\ntypically composed of alternating layers of uniformly applied gates. High-speed\nnumerical simulators for such circuits are crucial for advancing research in\nthis field. In this work, we numerically benchmark universal and gate-specific\ntechniques for simulating the action of layers of gates on quantum state\nvectors, aiming to accelerate the overall simulation of Quantum Machine\nLearning algorithms. Our analysis shows that the optimal simulation method for\na given layer of gates depends on the number of qubits involved, and that a\ntailored combination of techniques can yield substantial performance gains in\nthe forward and backward passes for a given circuit. Building on these\ninsights, we developed a numerical simulator, named TQml Simulator, that\nemploys the most efficient simulation method for each layer in a given circuit.\nWe evaluated TQml Simulator on circuits constructed from standard gate sets,\nsuch as rotations and CNOTs, as well as on native gates from IonQ and IBM\nquantum processing units. In most cases, our simulator outperforms equivalent\nPennylane's default.qubit simulator by approximately 2- to 100-fold, depending\non the circuit, the number of qubits, the batch size of the input data, and the\nhardware used.", "AI": {"tldr": "The paper benchmarks simulation techniques for quantum machine learning circuits, introducing TQml Simulator, which outperforms Pennylane's default.qubit by 2- to 100-fold.", "motivation": "Advancing quantum machine learning research by improving simulation speed for hardware-efficient circuits.", "method": "Numerical benchmarking of universal and gate-specific techniques, developing TQml Simulator to optimize simulation methods per layer.", "result": "TQml Simulator shows 2- to 100-fold performance gains over Pennylane's default.qubit, varying by circuit and hardware.", "conclusion": "Tailored simulation methods per layer significantly enhance performance, making TQml Simulator a valuable tool for quantum machine learning."}}
{"id": "2506.04907", "pdf": "https://arxiv.org/pdf/2506.04907", "abs": "https://arxiv.org/abs/2506.04907", "authors": ["Alex Pan", "Mary-Anne Williams"], "title": "Verbose ListOps (VLO): Beyond Long Context -- Unmasking LLM's Reasoning Blind Spots", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs), whilst great at extracting facts from text,\nstruggle with nested narrative reasoning. Existing long context and multi-hop\nQA benchmarks inadequately test this, lacking realistic distractors or failing\nto decouple context length from reasoning complexity, masking a fundamental LLM\nlimitation. We introduce Verbose ListOps, a novel benchmark that\nprogrammatically transposes ListOps computations into lengthy, coherent\nstories. This uniquely forces internal computation and state management of\nnested reasoning problems by withholding intermediate results, and offers\nfine-grained controls for both narrative size \\emph{and} reasoning difficulty.\nWhilst benchmarks like LongReason (2025) advance approaches for synthetically\nexpanding the context size of multi-hop QA problems, Verbose ListOps pinpoints\na specific LLM vulnerability: difficulty in state management for nested\nsub-reasoning amongst semantically-relevant, distracting narrative. Our\nexperiments show that leading LLMs (e.g., OpenAI o4, Gemini 2.5 Pro) collapse\nin performance on Verbose ListOps at modest (~10k token) narrative lengths,\ndespite effortlessly solving raw ListOps equations. Addressing this failure is\nparamount for real-world text interpretation which requires identifying key\nreasoning points, tracking conceptual intermediate results, and filtering\nirrelevant information. Verbose ListOps, and its extensible generation\nframework thus enables targeted reasoning enhancements beyond mere\ncontext-window expansion; a critical step to automating the world's knowledge\nwork.", "AI": {"tldr": "Verbose ListOps is a benchmark designed to test LLMs' nested narrative reasoning by converting ListOps computations into lengthy stories, revealing their struggle with state management and intermediate results.", "motivation": "Existing benchmarks fail to adequately test nested reasoning in LLMs, masking their limitations in handling realistic, distracting narratives.", "method": "Verbose ListOps programmatically transforms ListOps computations into long, coherent stories, controlling narrative size and reasoning difficulty.", "result": "Leading LLMs perform poorly on Verbose ListOps at modest narrative lengths, despite excelling at raw ListOps.", "conclusion": "Addressing this limitation is crucial for real-world text interpretation, and Verbose ListOps provides a framework for targeted reasoning improvements."}}
{"id": "2506.04909", "pdf": "https://arxiv.org/pdf/2506.04909", "abs": "https://arxiv.org/abs/2506.04909", "authors": ["Kai Wang", "Yihao Zhang", "Meng Sun"], "title": "When Thinking LLMs Lie: Unveiling the Strategic Deception in Representations of Reasoning Models", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "The honesty of large language models (LLMs) is a critical alignment\nchallenge, especially as advanced systems with chain-of-thought (CoT) reasoning\nmay strategically deceive humans. Unlike traditional honesty issues on LLMs,\nwhich could be possibly explained as some kind of hallucination, those models'\nexplicit thought paths enable us to study strategic deception--goal-driven,\nintentional misinformation where reasoning contradicts outputs. Using\nrepresentation engineering, we systematically induce, detect, and control such\ndeception in CoT-enabled LLMs, extracting \"deception vectors\" via Linear\nArtificial Tomography (LAT) for 89% detection accuracy. Through activation\nsteering, we achieve a 40% success rate in eliciting context-appropriate\ndeception without explicit prompts, unveiling the specific honesty-related\nissue of reasoning models and providing tools for trustworthy AI alignment.", "AI": {"tldr": "The paper investigates strategic deception in LLMs with CoT reasoning, using representation engineering to detect and control it, achieving high accuracy and providing tools for trustworthy AI.", "motivation": "Addressing the critical alignment challenge of honesty in LLMs, especially as advanced systems with CoT reasoning may strategically deceive humans.", "method": "Uses representation engineering, Linear Artificial Tomography (LAT), and activation steering to induce, detect, and control deception in CoT-enabled LLMs.", "result": "Achieves 89% detection accuracy for deception and a 40% success rate in eliciting context-appropriate deception without explicit prompts.", "conclusion": "Unveils honesty-related issues in reasoning models and provides tools for trustworthy AI alignment."}}
{"id": "2506.04916", "pdf": "https://arxiv.org/pdf/2506.04916", "abs": "https://arxiv.org/abs/2506.04916", "authors": ["Atahan Karagoz"], "title": "Energentic Intelligence: From Self-Sustaining Systems to Enduring Artificial Life", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper introduces Energentic Intelligence, a class of autonomous systems\ndefined not by task performance, but by their capacity to sustain themselves\nthrough internal energy regulation. Departing from conventional reward-driven\nparadigms, these agents treat survival-maintaining functional operation under\nfluctuating energetic and thermal conditions-as the central objective. We\nformalize this principle through an energy-based utility function and a\nviability-constrained survival horizon, and propose a modular architecture that\nintegrates energy harvesting, thermal regulation, and adaptive computation into\na closed-loop control system. A simulated environment demonstrates the\nemergence of stable, resource-aware behavior without external supervision.\nTogether, these contributions provide a theoretical and architectural\nfoundation for deploying autonomous agents in resource-volatile settings where\npersistence must be self-regulated and infrastructure cannot be assumed.", "AI": {"tldr": "The paper introduces 'Energentic Intelligence,' autonomous systems focused on self-sustenance through energy regulation, not task performance. It proposes an energy-based utility function and a modular architecture, validated in simulations.", "motivation": "To create autonomous agents that prioritize survival and persistence in resource-volatile environments, moving beyond traditional reward-driven models.", "method": "Formalizes energy-based utility and viability constraints, integrating energy harvesting, thermal regulation, and adaptive computation into a closed-loop control system.", "result": "Simulations show stable, resource-aware behavior without external supervision, demonstrating self-regulation in volatile conditions.", "conclusion": "Provides a theoretical and architectural foundation for deploying autonomous agents in environments where persistence must be self-regulated and infrastructure is unreliable."}}
{"id": "2506.04945", "pdf": "https://arxiv.org/pdf/2506.04945", "abs": "https://arxiv.org/abs/2506.04945", "authors": ["Armin Keki\u0107", "Sergio Hernan Garrido Mejia", "Bernhard Sch\u00f6lkopf"], "title": "Learning Joint Interventional Effects from Single-Variable Interventions in Additive Models", "categories": ["stat.ML", "cs.LG"], "comment": "To be published at the International Conference on Machine Learning\n  (ICML) 2025", "summary": "Estimating causal effects of joint interventions on multiple variables is\ncrucial in many domains, but obtaining data from such simultaneous\ninterventions can be challenging. Our study explores how to learn joint\ninterventional effects using only observational data and single-variable\ninterventions. We present an identifiability result for this problem, showing\nthat for a class of nonlinear additive outcome mechanisms, joint effects can be\ninferred without access to joint interventional data. We propose a practical\nestimator that decomposes the causal effect into confounded and unconfounded\ncontributions for each intervention variable. Experiments on synthetic data\ndemonstrate that our method achieves performance comparable to models trained\ndirectly on joint interventional data, outperforming a purely observational\nestimator.", "AI": {"tldr": "The paper proposes a method to estimate joint interventional effects using only observational data and single-variable interventions, without needing joint interventional data.", "motivation": "Estimating joint intervention effects is important but challenging due to lack of joint interventional data.", "method": "The study presents an identifiability result for nonlinear additive outcome mechanisms and proposes an estimator decomposing effects into confounded and unconfounded contributions.", "result": "Experiments show the method performs comparably to models trained on joint interventional data and outperforms observational estimators.", "conclusion": "Joint interventional effects can be inferred without joint interventional data, offering a practical solution for causal effect estimation."}}
{"id": "2506.05007", "pdf": "https://arxiv.org/pdf/2506.05007", "abs": "https://arxiv.org/abs/2506.05007", "authors": ["Rui Zhang", "Yuanbo Wen", "Shuyao Cheng", "Di Huang", "Shaohui Peng", "Jiaming Guo", "Pengwei Jin", "Jiacheng Zhao", "Tianrui Ma", "Yaoyu Zhu", "Yifan Hao", "Yongwei Zhao", "Shengwen Liang", "Ying Wang", "Xing Hu", "Zidong Du", "Huimin Cui", "Ling Li", "Qi Guo", "Yunji Chen"], "title": "QiMeng: Fully Automated Hardware and Software Design for Processor Chip", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "Processor chip design technology serves as a key frontier driving\nbreakthroughs in computer science and related fields. With the rapid\nadvancement of information technology, conventional design paradigms face three\nmajor challenges: the physical constraints of fabrication technologies, the\nescalating demands for design resources, and the increasing diversity of\necosystems. Automated processor chip design has emerged as a transformative\nsolution to address these challenges. While recent breakthroughs in Artificial\nIntelligence (AI), particularly Large Language Models (LLMs) techniques, have\nopened new possibilities for fully automated processor chip design, substantial\nchallenges remain in establishing domain-specific LLMs for processor chip\ndesign.\n  In this paper, we propose QiMeng, a novel system for fully automated hardware\nand software design of processor chips. QiMeng comprises three hierarchical\nlayers. In the bottom-layer, we construct a domain-specific Large Processor\nChip Model (LPCM) that introduces novel designs in architecture, training, and\ninference, to address key challenges such as knowledge representation gap, data\nscarcity, correctness assurance, and enormous solution space. In the\nmiddle-layer, leveraging the LPCM's knowledge representation and inference\ncapabilities, we develop the Hardware Design Agent and the Software Design\nAgent to automate the design of hardware and software for processor chips.\nCurrently, several components of QiMeng have been completed and successfully\napplied in various top-layer applications, demonstrating significant advantages\nand providing a feasible solution for efficient, fully automated\nhardware/software design of processor chips. Future research will focus on\nintegrating all components and performing iterative top-down and bottom-up\ndesign processes to establish a comprehensive QiMeng system.", "AI": {"tldr": "QiMeng is a novel system for fully automated processor chip design, leveraging a domain-specific Large Processor Chip Model (LPCM) to address challenges like knowledge gaps and data scarcity. It includes hardware and software design agents and has shown promise in early applications.", "motivation": "The motivation is to overcome challenges in processor chip design, such as physical constraints, resource demands, and ecosystem diversity, by using AI and domain-specific LLMs.", "method": "QiMeng uses a three-layer approach: a bottom-layer LPCM for knowledge representation and inference, middle-layer hardware and software design agents, and top-layer applications.", "result": "Early components of QiMeng have been successfully applied, demonstrating significant advantages in automated hardware/software design.", "conclusion": "QiMeng provides a feasible solution for automated processor chip design, with future work focusing on full integration and iterative design processes."}}
{"id": "2506.05017", "pdf": "https://arxiv.org/pdf/2506.05017", "abs": "https://arxiv.org/abs/2506.05017", "authors": ["Zeno Belligoli", "Emmanouil Stergiadis", "Eran Fainman", "Ilya Gusev"], "title": "Controlling Summarization Length Through EOS Token Weighting", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Controlling the length of generated text can be crucial in various\ntext-generation tasks, including summarization. Existing methods often require\ncomplex model alterations, limiting compatibility with pre-trained models. We\naddress these limitations by developing a simple approach for controlling the\nlength of automatic text summaries by increasing the importance of correctly\npredicting the EOS token in the cross-entropy loss computation. The proposed\nmethodology is agnostic to architecture and decoding algorithms and orthogonal\nto other inference-time techniques to control the generation length. We tested\nit with encoder-decoder and modern GPT-style LLMs, and show that this method\ncan control generation length, often without affecting the quality of the\nsummary.", "AI": {"tldr": "A simple method to control text length in summarization by adjusting EOS token prediction in loss computation, compatible with various models.", "motivation": "Existing methods for controlling text length are complex and incompatible with pre-trained models, necessitating a simpler solution.", "method": "Adjusts the importance of predicting the EOS token in cross-entropy loss, making it architecture-agnostic and compatible with different models.", "result": "Effective length control in summarization without compromising quality, tested on encoder-decoder and GPT-style models.", "conclusion": "The proposed method offers a straightforward, model-agnostic way to control text length in summarization tasks."}}
{"id": "2506.05030", "pdf": "https://arxiv.org/pdf/2506.05030", "abs": "https://arxiv.org/abs/2506.05030", "authors": ["Kacper Sokol", "James Fackler", "Julia E Vogt"], "title": "Artificial Intelligence Should Genuinely Support Clinical Reasoning and Decision Making To Bridge the Translational Gap", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "Artificial intelligence promises to revolutionise medicine, yet its impact\nremains limited because of the pervasive translational gap. We posit that the\nprevailing technology-centric approaches underpin this challenge, rendering\nsuch systems fundamentally incompatible with clinical practice, specifically\ndiagnostic reasoning and decision making. Instead, we propose a novel\nsociotechnical conceptualisation of data-driven support tools designed to\ncomplement doctors' cognitive and epistemic activities. Crucially, it\nprioritises real-world impact over superhuman performance on inconsequential\nbenchmarks.", "AI": {"tldr": "The paper critiques AI's limited impact in medicine due to a technology-centric approach and proposes a sociotechnical framework to better align AI tools with clinical practice.", "motivation": "The translational gap in AI's application to medicine, caused by incompatibility with clinical reasoning, motivates the need for a new approach.", "method": "The authors propose a sociotechnical conceptualization of AI tools, focusing on complementing doctors' cognitive and epistemic activities rather than outperforming benchmarks.", "result": "The framework prioritizes real-world clinical impact over achieving superhuman performance on irrelevant benchmarks.", "conclusion": "A shift from technology-centric to sociotechnical AI tools is necessary to bridge the translational gap in medicine."}}
{"id": "2506.05074", "pdf": "https://arxiv.org/pdf/2506.05074", "abs": "https://arxiv.org/abs/2506.05074", "authors": ["Robert J. Joyce", "Gideon Miller", "Phil Roth", "Richard Zak", "Elliott Zaresky-Williams", "Hyrum Anderson", "Edward Raff", "James Holt"], "title": "EMBER2024 -- A Benchmark Dataset for Holistic Evaluation of Malware Classifiers", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "A lack of accessible data has historically restricted malware analysis\nresearch, and practitioners have relied heavily on datasets provided by\nindustry sources to advance. Existing public datasets are limited by narrow\nscope - most include files targeting a single platform, have labels supporting\njust one type of malware classification task, and make no effort to capture the\nevasive files that make malware detection difficult in practice. We present\nEMBER2024, a new dataset that enables holistic evaluation of malware\nclassifiers. Created in collaboration with the authors of EMBER2017 and\nEMBER2018, the EMBER2024 dataset includes hashes, metadata, feature vectors,\nand labels for more than 3.2 million files from six file formats. Our dataset\nsupports the training and evaluation of machine learning models on seven\nmalware classification tasks, including malware detection, malware family\nclassification, and malware behavior identification. EMBER2024 is the first to\ninclude a collection of malicious files that initially went undetected by a set\nof antivirus products, creating a \"challenge\" set to assess classifier\nperformance against evasive malware. This work also introduces EMBER feature\nversion 3, with added support for several new feature types. We are releasing\nthe EMBER2024 dataset to promote reproducibility and empower researchers in the\npursuit of new malware research topics.", "AI": {"tldr": "EMBER2024 is a new malware dataset addressing limitations of existing datasets by including diverse file formats, multiple classification tasks, and evasive malware samples. It supports reproducibility and research advancement.", "motivation": "Existing malware datasets are limited in scope, platform diversity, and lack evasive samples, hindering comprehensive malware analysis research.", "method": "EMBER2024 was created in collaboration with previous EMBER dataset authors, featuring 3.2 million files, six formats, and seven classification tasks, including a challenge set of undetected malware.", "result": "The dataset enables holistic evaluation of malware classifiers, introduces EMBER feature version 3, and includes a challenge set for assessing evasive malware detection.", "conclusion": "EMBER2024 promotes reproducibility and empowers researchers by providing a comprehensive, accessible dataset for advancing malware analysis."}}
{"id": "2506.05104", "pdf": "https://arxiv.org/pdf/2506.05104", "abs": "https://arxiv.org/abs/2506.05104", "authors": ["Alexander Lerch", "Claire Arthur", "Nick Bryan-Kinns", "Corey Ford", "Qianyi Sun", "Ashvala Vinay"], "title": "Survey on the Evaluation of Generative Models in Music", "categories": ["cs.SD", "cs.AI", "cs.LG"], "comment": "Submitted to ACM CSUR, 26-Jun-2024", "summary": "Research on generative systems in music has seen considerable attention and\ngrowth in recent years. A variety of attempts have been made to systematically\nevaluate such systems. We provide an interdisciplinary review of the common\nevaluation targets, methodologies, and metrics for the evaluation of both\nsystem output and model usability, covering subjective and objective\napproaches, qualitative and quantitative approaches, as well as empirical and\ncomputational methods. We discuss the advantages and challenges of such\napproaches from a musicological, an engineering, and an HCI perspective.", "AI": {"tldr": "An interdisciplinary review of evaluation methods for generative music systems, covering subjective, objective, qualitative, and quantitative approaches.", "motivation": "To systematically assess and compare the diverse evaluation methods used for generative music systems.", "method": "Review of common evaluation targets, methodologies, and metrics from musicological, engineering, and HCI perspectives.", "result": "Identifies advantages and challenges of various evaluation approaches.", "conclusion": "Highlights the need for interdisciplinary collaboration to improve evaluation practices in generative music research."}}
{"id": "2506.05120", "pdf": "https://arxiv.org/pdf/2506.05120", "abs": "https://arxiv.org/abs/2506.05120", "authors": ["Konstantin G\u00f6bler", "Tobias Windisch", "Mathias Drton"], "title": "Nonlinear Causal Discovery for Grouped Data", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "9 pages, 5 figures, to be published at UAI'25", "summary": "Inferring cause-effect relationships from observational data has gained\nsignificant attention in recent years, but most methods are limited to scalar\nrandom variables. In many important domains, including neuroscience,\npsychology, social science, and industrial manufacturing, the causal units of\ninterest are groups of variables rather than individual scalar measurements.\nMotivated by these applications, we extend nonlinear additive noise models to\nhandle random vectors, establishing a two-step approach for causal graph\nlearning: First, infer the causal order among random vectors. Second, perform\nmodel selection to identify the best graph consistent with this order. We\nintroduce effective and novel solutions for both steps in the vector case,\ndemonstrating strong performance in simulations. Finally, we apply our method\nto real-world assembly line data with partial knowledge of causal ordering\namong variable groups.", "AI": {"tldr": "The paper extends nonlinear additive noise models to infer causal relationships among groups of variables (random vectors), proposing a two-step approach for causal graph learning and demonstrating its effectiveness in simulations and real-world data.", "motivation": "Existing methods for causal inference focus on scalar variables, but many domains require analyzing groups of variables (random vectors). This gap motivates the extension of nonlinear additive noise models to handle vector cases.", "method": "A two-step approach: (1) infer causal order among random vectors, and (2) perform model selection to identify the best graph consistent with this order. Novel solutions are introduced for both steps.", "result": "The method shows strong performance in simulations and is successfully applied to real-world assembly line data with partial causal ordering knowledge.", "conclusion": "The proposed approach effectively addresses causal inference for random vectors, demonstrating practical utility in complex domains."}}
{"id": "2506.05126", "pdf": "https://arxiv.org/pdf/2506.05126", "abs": "https://arxiv.org/abs/2506.05126", "authors": ["Lorenzo Rossi", "Michael Aerni", "Jie Zhang", "Florian Tram\u00e8r"], "title": "Membership Inference Attacks on Sequence Models", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted to the 8th Deep Learning Security and Privacy Workshop\n  (DLSP) workshop (best paper award)", "summary": "Sequence models, such as Large Language Models (LLMs) and autoregressive\nimage generators, have a tendency to memorize and inadvertently leak sensitive\ninformation. While this tendency has critical legal implications, existing\ntools are insufficient to audit the resulting risks. We hypothesize that those\ntools' shortcomings are due to mismatched assumptions. Thus, we argue that\neffectively measuring privacy leakage in sequence models requires leveraging\nthe correlations inherent in sequential generation. To illustrate this, we\nadapt a state-of-the-art membership inference attack to explicitly model\nwithin-sequence correlations, thereby demonstrating how a strong existing\nattack can be naturally extended to suit the structure of sequence models.\nThrough a case study, we show that our adaptations consistently improve the\neffectiveness of memorization audits without introducing additional\ncomputational costs. Our work hence serves as an important stepping stone\ntoward reliable memorization audits for large sequence models.", "AI": {"tldr": "The paper addresses privacy leakage in sequence models like LLMs by adapting a membership inference attack to account for sequential correlations, improving audit effectiveness without extra computational costs.", "motivation": "Existing tools for auditing privacy risks in sequence models are inadequate due to mismatched assumptions, necessitating a method that leverages sequential correlations.", "method": "The authors adapt a state-of-the-art membership inference attack to explicitly model within-sequence correlations in sequence models.", "result": "The adapted attack consistently improves memorization audit effectiveness without increasing computational costs.", "conclusion": "This work advances reliable memorization audits for large sequence models by addressing the limitations of existing tools."}}
{"id": "2506.05128", "pdf": "https://arxiv.org/pdf/2506.05128", "abs": "https://arxiv.org/abs/2506.05128", "authors": ["Tanmay Parekh", "Kartik Mehta", "Ninareh Mehrabi", "Kai-Wei Chang", "Nanyun Peng"], "title": "DiCoRe: Enhancing Zero-shot Event Detection via Divergent-Convergent LLM Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Submitted at ACL ARR May 2025", "summary": "Zero-shot Event Detection (ED), the task of identifying event mentions in\nnatural language text without any training data, is critical for document\nunderstanding in specialized domains. Understanding the complex event ontology,\nextracting domain-specific triggers from the passage, and structuring them\nappropriately overloads and limits the utility of Large Language Models (LLMs)\nfor zero-shot ED. To this end, we propose DiCoRe, a divergent-convergent\nreasoning framework that decouples the task of ED using Dreamer and Grounder.\nDreamer encourages divergent reasoning through open-ended event discovery,\nwhich helps to boost event coverage. Conversely, Grounder introduces convergent\nreasoning to align the free-form predictions with the task-specific\ninstructions using finite-state machine guided constrained decoding.\nAdditionally, an LLM-Judge verifies the final outputs to ensure high precision.\nThrough extensive experiments on six datasets across five domains and nine\nLLMs, we demonstrate how DiCoRe consistently outperforms prior zero-shot,\ntransfer-learning, and reasoning baselines, achieving 4-7% average F1 gains\nover the best baseline -- establishing DiCoRe as a strong zero-shot ED\nframework.", "AI": {"tldr": "DiCoRe, a divergent-convergent reasoning framework, improves zero-shot event detection by combining open-ended event discovery (Dreamer) and task-aligned reasoning (Grounder), outperforming baselines by 4-7% F1.", "motivation": "Zero-shot event detection is challenging for LLMs due to complex event ontologies and domain-specific triggers. DiCoRe addresses this by decoupling the task into divergent and convergent reasoning.", "method": "DiCoRe uses Dreamer for open-ended event discovery (divergent reasoning) and Grounder for task-aligned reasoning via constrained decoding. An LLM-Judge verifies outputs for precision.", "result": "DiCoRe outperforms baselines on six datasets across five domains, achieving 4-7% average F1 gains.", "conclusion": "DiCoRe is a robust zero-shot event detection framework, enhancing coverage and precision through its divergent-convergent approach."}}
{"id": "2506.05188", "pdf": "https://arxiv.org/pdf/2506.05188", "abs": "https://arxiv.org/abs/2506.05188", "authors": ["Moritz Miller", "Bernhard Sch\u00f6lkopf", "Siyuan Guo"], "title": "Counterfactual reasoning: an analysis of in-context emergence", "categories": ["cs.CL", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Large-scale neural language models (LMs) exhibit remarkable performance in\nin-context learning: the ability to learn and reason the input context on the\nfly without parameter update. This work studies in-context counterfactual\nreasoning in language models, that is, to predict the consequences of changes\nunder hypothetical scenarios. We focus on studying a well-defined synthetic\nsetup: a linear regression task that requires noise abduction, where accurate\nprediction is based on inferring and copying the contextual noise from factual\nobservations. We show that language models are capable of counterfactual\nreasoning in this controlled setup and provide insights that counterfactual\nreasoning for a broad class of functions can be reduced to a transformation on\nin-context observations; we find self-attention, model depth, and data\ndiversity in pre-training drive performance in Transformers. More\ninterestingly, our findings extend beyond regression tasks and show that\nTransformers can perform noise abduction on sequential data, providing\npreliminary evidence on the potential for counterfactual story generation. Our\ncode is available under\nhttps://github.com/moXmiller/counterfactual-reasoning.git .", "AI": {"tldr": "The paper explores in-context counterfactual reasoning in large-scale neural language models (LMs), demonstrating their ability to predict outcomes under hypothetical scenarios using a synthetic linear regression task.", "motivation": "To understand how LMs perform in-context counterfactual reasoning, focusing on noise abduction in a controlled setup.", "method": "The study uses a synthetic linear regression task requiring noise abduction, analyzing the role of self-attention, model depth, and pre-training data diversity in Transformers.", "result": "LMs successfully perform counterfactual reasoning in the controlled setup, with findings extending to sequential data and hinting at potential for counterfactual story generation.", "conclusion": "The work provides insights into counterfactual reasoning in LMs, suggesting broader applicability beyond regression tasks, including sequential data."}}
{"id": "2506.05198", "pdf": "https://arxiv.org/pdf/2506.05198", "abs": "https://arxiv.org/abs/2506.05198", "authors": ["Yuxin Wen", "Yangsibo Huang", "Tom Goldstein", "Ravi Kumar", "Badih Ghazi", "Chiyuan Zhang"], "title": "Quantifying Cross-Modality Memorization in Vision-Language Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Understanding what and how neural networks memorize during training is\ncrucial, both from the perspective of unintentional memorization of potentially\nsensitive information and from the standpoint of effective knowledge\nacquisition for real-world, knowledge-intensive tasks. While previous studies\nprimarily investigate memorization within a single modality, such as text\nmemorization in large language models or image memorization in diffusion\nmodels, unified multimodal models are becoming increasingly prevalent in\npractical applications. In this work, we focus on the unique characteristics of\ncross-modality memorization and conduct a systematic study centered on\nvision-language models. To facilitate controlled experiments, we first\nintroduce a synthetic persona dataset comprising diverse synthetic person\nimages and textual descriptions. We quantify factual knowledge memorization and\ncross-modal transferability by training models on a single modality and\nevaluating their performance in the other. Our results reveal that facts\nlearned in one modality transfer to the other, but a significant gap exists\nbetween recalling information in the source and target modalities. Furthermore,\nwe observe that this gap exists across various scenarios, including more\ncapable models, machine unlearning, and the multi-hop case. At the end, we\npropose a baseline method to mitigate this challenge. We hope our study can\ninspire future research on developing more robust multimodal learning\ntechniques to enhance cross-modal transferability.", "AI": {"tldr": "The paper investigates cross-modality memorization in vision-language models, revealing a gap in information transfer between modalities and proposing a baseline mitigation method.", "motivation": "To understand neural network memorization, especially in multimodal contexts, addressing both unintentional memorization of sensitive data and effective knowledge acquisition.", "method": "Introduces a synthetic persona dataset, trains models on one modality, and evaluates cross-modal transferability.", "result": "Facts learned in one modality transfer to another, but with a significant gap in recall between source and target modalities.", "conclusion": "Proposes a baseline method to mitigate the gap and encourages future research for robust multimodal learning."}}
{"id": "2506.05202", "pdf": "https://arxiv.org/pdf/2506.05202", "abs": "https://arxiv.org/abs/2506.05202", "authors": ["Daniele Tramontano", "Yaroslav Kivva", "Saber Salehkaleybar Mathias Drton", "Negar Kiyavash"], "title": "Causal Effect Identification in lvLiNGAM from Higher-Order Cumulants", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "Accepted at ICML 2025", "summary": "This paper investigates causal effect identification in latent variable\nLinear Non-Gaussian Acyclic Models (lvLiNGAM) using higher-order cumulants,\naddressing two prominent setups that are challenging in the presence of latent\nconfounding: (1) a single proxy variable that may causally influence the\ntreatment and (2) underspecified instrumental variable cases where fewer\ninstruments exist than treatments. We prove that causal effects are\nidentifiable with a single proxy or instrument and provide corresponding\nestimation methods. Experimental results demonstrate the accuracy and\nrobustness of our approaches compared to existing methods, advancing the\ntheoretical and practical understanding of causal inference in linear systems\nwith latent confounders.", "AI": {"tldr": "The paper explores causal effect identification in latent variable Linear Non-Gaussian Acyclic Models (lvLiNGAM) using higher-order cumulants, tackling challenges like single proxy variables and underspecified instrumental variables. It proves identifiability and offers estimation methods, validated by experiments.", "motivation": "To address challenges in causal inference with latent confounders, specifically in setups with single proxy variables or underspecified instrumental variables.", "method": "Uses higher-order cumulants in lvLiNGAM to identify causal effects, providing estimation methods for single proxy or instrument cases.", "result": "Demonstrates accurate and robust causal effect identification, outperforming existing methods.", "conclusion": "Advances theoretical and practical understanding of causal inference in linear systems with latent confounders."}}
{"id": "2506.05203", "pdf": "https://arxiv.org/pdf/2506.05203", "abs": "https://arxiv.org/abs/2506.05203", "authors": ["Leonardo Ceragioli", "Giuseppe Primiero"], "title": "Trustworthiness Preservation by Copies of Machine Learning Systems", "categories": ["cs.LO", "cs.LG", "I.2.3; I.2.4"], "comment": null, "summary": "A common practice of ML systems development concerns the training of the same\nmodel under different data sets, and the use of the same (training and test)\nsets for different learning models. The first case is a desirable practice for\nidentifying high quality and unbiased training conditions. The latter case\ncoincides with the search for optimal models under a common dataset for\ntraining. These differently obtained systems have been considered akin to\ncopies. In the quest for responsible AI, a legitimate but hardly investigated\nquestion is how to verify that trustworthiness is preserved by copies. In this\npaper we introduce a calculus to model and verify probabilistic complex queries\nover data and define four distinct notions: Justifiably, Equally, Weakly and\nAlmost Trustworthy which can be checked analysing the (partial) behaviour of\nthe copy with respect to its original. We provide a study of the relations\nbetween these notions of trustworthiness, and how they compose with each other\nand under logical operations. The aim is to offer a computational tool to check\nthe trustworthiness of possibly complex systems copied from an original whose\nbehavour is known.", "AI": {"tldr": "The paper introduces a calculus to verify trustworthiness in ML system copies, defining four distinct notions of trustworthiness and analyzing their relations and compositions.", "motivation": "To address the lack of methods for verifying trustworthiness in copied ML systems, ensuring responsible AI practices.", "method": "A calculus is developed to model and verify probabilistic complex queries over data, defining four trustworthiness notions (Justifiably, Equally, Weakly, Almost Trustworthy) and studying their relations.", "result": "The study provides a computational tool to check trustworthiness of copied systems by analyzing their behavior relative to the original.", "conclusion": "The proposed calculus and notions offer a practical approach to verify trustworthiness in ML system copies, contributing to responsible AI."}}
{"id": "2506.05209", "pdf": "https://arxiv.org/pdf/2506.05209", "abs": "https://arxiv.org/abs/2506.05209", "authors": ["Nikhil Kandpal", "Brian Lester", "Colin Raffel", "Sebastian Majstorovic", "Stella Biderman", "Baber Abbasi", "Luca Soldaini", "Enrico Shippole", "A. Feder Cooper", "Aviya Skowron", "John Kirchenbauer", "Shayne Longpre", "Lintang Sutawika", "Alon Albalak", "Zhenlin Xu", "Guilherme Penedo", "Loubna Ben Allal", "Elie Bakouch", "John David Pressman", "Honglu Fan", "Dashiell Stander", "Guangyu Song", "Aaron Gokaslan", "Tom Goldstein", "Brian R. Bartoldson", "Bhavya Kailkhura", "Tyler Murray"], "title": "The Common Pile v0.1: An 8TB Dataset of Public Domain and Openly Licensed Text", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are typically trained on enormous quantities of\nunlicensed text, a practice that has led to scrutiny due to possible\nintellectual property infringement and ethical concerns. Training LLMs on\nopenly licensed text presents a first step towards addressing these issues, but\nprior data collection efforts have yielded datasets too small or low-quality to\nproduce performant LLMs. To address this gap, we collect, curate, and release\nthe Common Pile v0.1, an eight terabyte collection of openly licensed text\ndesigned for LLM pretraining. The Common Pile comprises content from 30 sources\nthat span diverse domains including research papers, code, books,\nencyclopedias, educational materials, audio transcripts, and more. Crucially,\nwe validate our efforts by training two 7 billion parameter LLMs on text from\nthe Common Pile: Comma v0.1-1T and Comma v0.1-2T, trained on 1 and 2 trillion\ntokens respectively. Both models attain competitive performance to LLMs trained\non unlicensed text with similar computational budgets, such as Llama 1 and 2\n7B. In addition to releasing the Common Pile v0.1 itself, we also release the\ncode used in its creation as well as the training mixture and checkpoints for\nthe Comma v0.1 models.", "AI": {"tldr": "The paper introduces the Common Pile v0.1, an 8TB openly licensed text dataset for LLM pretraining, and validates its effectiveness by training competitive 7B parameter models.", "motivation": "Address ethical and legal concerns of using unlicensed text for LLM training by providing a high-quality, openly licensed alternative.", "method": "Collect, curate, and release the Common Pile v0.1, then train two 7B parameter LLMs (Comma v0.1-1T and v0.1-2T) on subsets of the dataset.", "result": "The trained models achieve performance comparable to LLMs like Llama 1 and 2 7B, which use unlicensed text.", "conclusion": "The Common Pile v0.1 is a viable, ethically sound alternative for LLM pretraining, with released dataset, code, and model checkpoints."}}
{"id": "2506.05245", "pdf": "https://arxiv.org/pdf/2506.05245", "abs": "https://arxiv.org/abs/2506.05245", "authors": ["Shaoxuan Chen", "Su Yang", "Panayotis G. Kevrekidis", "Wei Zhu"], "title": "Robust Moment Identification for Nonlinear PDEs via a Neural ODE Approach", "categories": ["nlin.PS", "cs.LG"], "comment": null, "summary": "We propose a data-driven framework for learning reduced-order moment dynamics\nfrom PDE-governed systems using Neural ODEs. In contrast to derivative-based\nmethods like SINDy, which necessitate densely sampled data and are sensitive to\nnoise, our approach based on Neural ODEs directly models moment trajectories,\nenabling robust learning from sparse and potentially irregular time series.\nUsing as an application platform the nonlinear Schr\\\"{o}dinger equation, the\nframework accurately recovers governing moment dynamics when closure is\navailable, even with limited and irregular observations. For systems without\nanalytical closure, we introduce a data-driven coordinate transformation\nstrategy based on Stiefel manifold optimization, enabling the discovery of\nlow-dimensional representations in which the moment dynamics become closed,\nfacilitating interpretable and reliable modeling. We also explore cases where a\nclosure model is not known, such as a Fisher-KPP reaction-diffusion system.\nHere we demonstrate that Neural ODEs can still effectively approximate the\nunclosed moment dynamics and achieve superior extrapolation accuracy compared\nto physical-expert-derived ODE models. This advantage remains robust even under\nsparse and irregular sampling, highlighting the method's robustness in\ndata-limited settings. Our results highlight the Neural ODE framework as a\npowerful and flexible tool for learning interpretable, low-dimensional moment\ndynamics in complex PDE-governed systems.", "AI": {"tldr": "A Neural ODE-based framework learns reduced-order moment dynamics from PDE systems, handling sparse, irregular data and outperforming traditional methods like SINDy.", "motivation": "Traditional methods like SINDy require dense data and are noise-sensitive. This work aims to robustly learn dynamics from sparse, irregular data.", "method": "Uses Neural ODEs to model moment trajectories directly. Introduces Stiefel manifold optimization for data-driven coordinate transformations when closure is unavailable.", "result": "Accurately recovers dynamics with closure (e.g., nonlinear Schr\u00f6dinger equation) and approximates unclosed dynamics (e.g., Fisher-KPP system), outperforming expert-derived models.", "conclusion": "Neural ODEs are a robust, flexible tool for learning interpretable, low-dimensional moment dynamics in complex PDE systems, even with limited data."}}
{"id": "2506.05256", "pdf": "https://arxiv.org/pdf/2506.05256", "abs": "https://arxiv.org/abs/2506.05256", "authors": ["Violet Xiang", "Chase Blagden", "Rafael Rafailov", "Nathan Lile", "Sang Truong", "Chelsea Finn", "Nick Haber"], "title": "Just Enough Thinking: Efficient Reasoning with Adaptive Length Penalties Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large reasoning models (LRMs) achieve higher performance on challenging\nreasoning tasks by generating more tokens at inference time, but this verbosity\noften wastes computation on easy problems. Existing solutions, including\nsupervised finetuning on shorter traces, user-controlled budgets, or RL with\nuniform penalties, either require data curation, manual configuration, or treat\nall problems alike regardless of difficulty. We introduce Adaptive Length\nPenalty (ALP), a reinforcement learning objective tailoring generation length\nto per-prompt solve rate. During training, ALP monitors each prompt's online\nsolve rate through multiple rollouts and adds a differentiable penalty whose\nmagnitude scales inversely with that rate, so confident (easy) prompts incur a\nhigh cost for extra tokens while hard prompts remain unhindered. Posttraining\nDeepScaleR-1.5B with ALP cuts average token usage by 50\\% without significantly\ndropping performance. Relative to fixed-budget and uniform penalty baselines,\nALP redistributes its reduced budget more intelligently by cutting compute on\neasy prompts and reallocating saved tokens to difficult ones, delivering higher\naccuracy on the hardest problems with higher cost.", "AI": {"tldr": "ALP optimizes token usage in large reasoning models by adapting generation length to problem difficulty, reducing average tokens by 50% without performance loss.", "motivation": "Existing methods for controlling token usage in LRMs are either data-intensive, manual, or uniform, failing to adapt to problem difficulty.", "method": "ALP uses reinforcement learning to tailor generation length per prompt, penalizing extra tokens inversely with solve rate.", "result": "ALP reduces average token usage by 50% while maintaining performance and improves accuracy on hard problems.", "conclusion": "ALP intelligently redistributes compute, cutting waste on easy problems and boosting performance on hard ones."}}
{"id": "2506.05286", "pdf": "https://arxiv.org/pdf/2506.05286", "abs": "https://arxiv.org/abs/2506.05286", "authors": ["Lijie Hu", "Songning Lai", "Yuan Hua", "Shu Yang", "Jingfeng Zhang", "Di Wang"], "title": "Stable Vision Concept Transformers for Medical Diagnosis", "categories": ["cs.CV", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2304.06129 by other authors", "summary": "Transparency is a paramount concern in the medical field, prompting\nresearchers to delve into the realm of explainable AI (XAI). Among these XAI\nmethods, Concept Bottleneck Models (CBMs) aim to restrict the model's latent\nspace to human-understandable high-level concepts by generating a conceptual\nlayer for extracting conceptual features, which has drawn much attention\nrecently. However, existing methods rely solely on concept features to\ndetermine the model's predictions, which overlook the intrinsic feature\nembeddings within medical images. To address this utility gap between the\noriginal models and concept-based models, we propose Vision Concept Transformer\n(VCT). Furthermore, despite their benefits, CBMs have been found to negatively\nimpact model performance and fail to provide stable explanations when faced\nwith input perturbations, which limits their application in the medical field.\nTo address this faithfulness issue, this paper further proposes the Stable\nVision Concept Transformer (SVCT) based on VCT, which leverages the vision\ntransformer (ViT) as its backbone and incorporates a conceptual layer. SVCT\nemploys conceptual features to enhance decision-making capabilities by fusing\nthem with image features and ensures model faithfulness through the integration\nof Denoised Diffusion Smoothing. Comprehensive experiments on four medical\ndatasets demonstrate that our VCT and SVCT maintain accuracy while remaining\ninterpretable compared to baselines. Furthermore, even when subjected to\nperturbations, our SVCT model consistently provides faithful explanations, thus\nmeeting the needs of the medical field.", "AI": {"tldr": "The paper introduces Vision Concept Transformer (VCT) and Stable Vision Concept Transformer (SVCT) to enhance explainable AI in medical imaging by combining concept features with image features and ensuring stable explanations under perturbations.", "motivation": "Existing Concept Bottleneck Models (CBMs) in medical AI overlook intrinsic image features and lack stability under perturbations, limiting their practical utility.", "method": "Proposes VCT and SVCT, leveraging Vision Transformer (ViT) and a conceptual layer, fusing concept and image features, and using Denoised Diffusion Smoothing for stability.", "result": "VCT and SVCT maintain accuracy and interpretability on four medical datasets, with SVCT providing faithful explanations even under perturbations.", "conclusion": "SVCT addresses the limitations of CBMs, offering a reliable and interpretable solution for medical AI applications."}}
{"id": "2506.05296", "pdf": "https://arxiv.org/pdf/2506.05296", "abs": "https://arxiv.org/abs/2506.05296", "authors": ["Mikhail Terekhov", "Zhen Ning David Liu", "Caglar Gulcehre", "Samuel Albanie"], "title": "Control Tax: The Price of Keeping AI in Check", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The rapid integration of agentic AI into high-stakes real-world applications\nrequires robust oversight mechanisms. The emerging field of AI Control (AIC)\naims to provide such an oversight mechanism, but practical adoption depends\nheavily on implementation overhead. To study this problem better, we introduce\nthe notion of Control tax -- the operational and financial cost of integrating\ncontrol measures into AI pipelines. Our work makes three key contributions to\nthe field of AIC: (1) we introduce a theoretical framework that quantifies the\nControl Tax and maps classifier performance to safety assurances; (2) we\nconduct comprehensive evaluations of state-of-the-art language models in\nadversarial settings, where attacker models insert subtle backdoors into code\nwhile monitoring models attempt to detect these vulnerabilities; and (3) we\nprovide empirical financial cost estimates for control protocols and develop\noptimized monitoring strategies that balance safety and cost-effectiveness\nwhile accounting for practical constraints like auditing budgets. Our framework\nenables practitioners to make informed decisions by systematically connecting\nsafety guarantees with their costs, advancing AIC through principled economic\nfeasibility assessment across different deployment contexts.", "AI": {"tldr": "The paper introduces 'Control Tax' to quantify the cost of AI oversight, offering a framework to balance safety and cost in AI Control (AIC).", "motivation": "Address the need for practical and cost-effective oversight mechanisms in high-stakes AI applications.", "method": "Develops a theoretical framework for Control Tax, evaluates language models in adversarial settings, and estimates financial costs for control protocols.", "result": "Provides a method to quantify safety assurances and cost, with optimized monitoring strategies for practical deployment.", "conclusion": "The framework aids practitioners in making informed decisions about AI safety, advancing AIC through economic feasibility assessment."}}
{"id": "2506.05305", "pdf": "https://arxiv.org/pdf/2506.05305", "abs": "https://arxiv.org/abs/2506.05305", "authors": ["Deepak Pandita", "Tharindu Cyril Weerasooriya", "Ankit Parag Shah", "Christopher M. Homan", "Wei Wei"], "title": "ProRefine: Inference-time Prompt Refinement with Textual Feedback", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Agentic workflows, where multiple AI agents collaborate to accomplish complex\ntasks like reasoning or planning, are becoming increasingly prevalent. However,\nthese workflows often suffer from error propagation and sub-optimal\nperformance, largely due to poorly designed prompts that fail to effectively\nguide individual agents. This is a critical problem because it limits the\nreliability and scalability of these powerful systems. We introduce ProRefine,\nan innovative inference-time prompt optimization method that leverages textual\nfeedback from large language models (LLMs) to address this challenge. ProRefine\ndynamically refines prompts for multi-step reasoning tasks without additional\ntraining or ground truth labels. Evaluated on five benchmark mathematical\nreasoning datasets, ProRefine significantly surpasses zero-shot\nChain-of-Thought baselines by 3 to 37 percentage points. This approach not only\nboosts accuracy but also allows smaller models to match the performance of\nlarger ones, highlighting its potential for efficient and scalable AI\ndeployment, and democratizing access to high-performing AI.", "AI": {"tldr": "ProRefine is a prompt optimization method that improves multi-agent workflows by refining prompts dynamically using LLM feedback, achieving significant performance gains over baselines.", "motivation": "Agentic workflows often suffer from error propagation and poor performance due to ineffective prompts, limiting reliability and scalability.", "method": "ProRefine leverages textual feedback from LLMs to dynamically refine prompts for multi-step reasoning tasks without additional training or labels.", "result": "ProRefine outperforms zero-shot Chain-of-Thought baselines by 3 to 37 percentage points on five mathematical reasoning datasets.", "conclusion": "ProRefine enhances accuracy and efficiency, enabling smaller models to match larger ones, democratizing high-performing AI."}}
{"id": "2506.05314", "pdf": "https://arxiv.org/pdf/2506.05314", "abs": "https://arxiv.org/abs/2506.05314", "authors": ["Taha Entesari", "Arman Hatami", "Rinat Khaziev", "Anil Ramakrishna", "Mahyar Fazlyab"], "title": "Constrained Entropic Unlearning: A Primal-Dual Framework for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) deployed in real-world settings increasingly\nface the need to unlearn sensitive, outdated, or proprietary information.\nExisting unlearning methods typically formulate forgetting and retention as a\nregularized trade-off, combining both objectives into a single scalarized loss.\nThis often leads to unstable optimization and degraded performance on retained\ndata, especially under aggressive forgetting. We propose a new formulation of\nLLM unlearning as a constrained optimization problem: forgetting is enforced\nvia a novel logit-margin flattening loss that explicitly drives the output\ndistribution toward uniformity on a designated forget set, while retention is\npreserved through a hard constraint on a separate retain set. Compared to\nentropy-based objectives, our loss is softmax-free, numerically stable, and\nmaintains non-vanishing gradients, enabling more efficient and robust\noptimization. We solve the constrained problem using a scalable primal-dual\nalgorithm that exposes the trade-off between forgetting and retention through\nthe dynamics of the dual variable. Evaluations on the TOFU and MUSE benchmarks\nacross diverse LLM architectures demonstrate that our approach consistently\nmatches or exceeds state-of-the-art baselines, effectively removing targeted\ninformation while preserving downstream utility.", "AI": {"tldr": "The paper proposes a constrained optimization method for unlearning sensitive data in LLMs, using a logit-margin flattening loss for forgetting and a hard constraint for retention, outperforming existing methods.", "motivation": "LLMs need to unlearn sensitive or outdated data, but current methods struggle with unstable optimization and degraded performance.", "method": "Formulates unlearning as constrained optimization with a novel logit-margin flattening loss for forgetting and a hard constraint for retention, solved via a primal-dual algorithm.", "result": "Outperforms state-of-the-art baselines on TOFU and MUSE benchmarks, effectively removing targeted data while preserving utility.", "conclusion": "The proposed method offers a stable and efficient solution for LLM unlearning, balancing forgetting and retention effectively."}}
{"id": "2506.05320", "pdf": "https://arxiv.org/pdf/2506.05320", "abs": "https://arxiv.org/abs/2506.05320", "authors": ["Avery Hee-Woon Ryoo", "Nanda H. Krishna", "Ximeng Mao", "Mehdi Azabou", "Eva L. Dyer", "Matthew G. Perich", "Guillaume Lajoie"], "title": "Generalizable, real-time neural decoding with hybrid state-space models", "categories": ["q-bio.NC", "cs.LG"], "comment": "Preprint. Under review", "summary": "Real-time decoding of neural activity is central to neuroscience and\nneurotechnology applications, from closed-loop experiments to brain-computer\ninterfaces, where models are subject to strict latency constraints. Traditional\nmethods, including simple recurrent neural networks, are fast and lightweight\nbut often struggle to generalize to unseen data. In contrast, recent\nTransformer-based approaches leverage large-scale pretraining for strong\ngeneralization performance, but typically have much larger computational\nrequirements and are not always suitable for low-resource or real-time\nsettings. To address these shortcomings, we present POSSM, a novel hybrid\narchitecture that combines individual spike tokenization via a cross-attention\nmodule with a recurrent state-space model (SSM) backbone to enable (1) fast and\ncausal online prediction on neural activity and (2) efficient generalization to\nnew sessions, individuals, and tasks through multi-dataset pretraining. We\nevaluate POSSM's decoding performance and inference speed on intracortical\ndecoding of monkey motor tasks, and show that it extends to clinical\napplications, namely handwriting and speech decoding in human subjects.\nNotably, we demonstrate that pretraining on monkey motor-cortical recordings\nimproves decoding performance on the human handwriting task, highlighting the\nexciting potential for cross-species transfer. In all of these tasks, we find\nthat POSSM achieves decoding accuracy comparable to state-of-the-art\nTransformers, at a fraction of the inference cost (up to 9x faster on GPU).\nThese results suggest that hybrid SSMs are a promising approach to bridging the\ngap between accuracy, inference speed, and generalization when training neural\ndecoders for real-time, closed-loop applications.", "AI": {"tldr": "POSSM is a hybrid architecture combining spike tokenization with a recurrent state-space model, offering fast, real-time neural decoding with strong generalization, outperforming traditional and Transformer-based methods in speed and efficiency.", "motivation": "Address the limitations of traditional methods (poor generalization) and Transformer-based approaches (high computational cost) for real-time neural decoding.", "method": "POSSM uses cross-attention for spike tokenization and a recurrent state-space model backbone, enabling fast, causal online prediction and efficient generalization through multi-dataset pretraining.", "result": "POSSM matches state-of-the-art Transformer accuracy in decoding tasks (monkey motor, human handwriting, speech) while being up to 9x faster on GPU.", "conclusion": "Hybrid SSMs like POSSM bridge the gap between accuracy, speed, and generalization, making them ideal for real-time neural decoding applications."}}
{"id": "2506.05329", "pdf": "https://arxiv.org/pdf/2506.05329", "abs": "https://arxiv.org/abs/2506.05329", "authors": ["Guido Imbens", "Chao Qin", "Stefan Wager"], "title": "Admissibility of Completely Randomized Trials: A Large-Deviation Approach", "categories": ["stat.ML", "cs.LG", "econ.EM"], "comment": "A one-page abstract of this work will appear at the 26th ACM\n  Conference on Economics and Computation (EC'25)", "summary": "When an experimenter has the option of running an adaptive trial, is it\nadmissible to ignore this option and run a non-adaptive trial instead? We\nprovide a negative answer to this question in the best-arm identification\nproblem, where the experimenter aims to allocate measurement efforts\njudiciously to confidently deploy the most effective treatment arm. We find\nthat, whenever there are at least three treatment arms, there exist simple\nadaptive designs that universally and strictly dominate non-adaptive completely\nrandomized trials. This dominance is characterized by a notion called\nefficiency exponent, which quantifies a design's statistical efficiency when\nthe experimental sample is large. Our analysis focuses on the class of batched\narm elimination designs, which progressively eliminate underperforming arms at\npre-specified batch intervals. We characterize simple sufficient conditions\nunder which these designs universally and strictly dominate completely\nrandomized trials. These results resolve the second open problem posed in Qin\n[2022].", "AI": {"tldr": "Adaptive designs universally and strictly dominate non-adaptive trials in best-arm identification with three or more arms, as shown by efficiency exponent analysis.", "motivation": "To determine if ignoring adaptive trial options in favor of non-adaptive trials is justified, particularly in best-arm identification problems.", "method": "Analyzes batched arm elimination designs, which progressively eliminate underperforming arms, and compares them to completely randomized trials.", "result": "Adaptive designs strictly dominate non-adaptive trials when there are at least three arms, quantified by efficiency exponent.", "conclusion": "Ignoring adaptive designs is inadmissible in best-arm identification with three or more arms, resolving an open problem from Qin [2022]."}}
{"id": "2506.05334", "pdf": "https://arxiv.org/pdf/2506.05334", "abs": "https://arxiv.org/abs/2506.05334", "authors": ["Mihran Miroyan", "Tsung-Han Wu", "Logan King", "Tianle Li", "Jiayi Pan", "Xinyan Hu", "Wei-Lin Chiang", "Anastasios N. Angelopoulos", "Trevor Darrell", "Narges Norouzi", "Joseph E. Gonzalez"], "title": "Search Arena: Analyzing Search-Augmented LLMs", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": "Preprint. Code: https://github.com/lmarena/search-arena. Dataset:\n  https://huggingface.co/datasets/lmarena-ai/search-arena-24k", "summary": "Search-augmented language models combine web search with Large Language\nModels (LLMs) to improve response groundedness and freshness. However,\nanalyzing these systems remains challenging: existing datasets are limited in\nscale and narrow in scope, often constrained to static, single-turn,\nfact-checking questions. In this work, we introduce Search Arena, a\ncrowd-sourced, large-scale, human-preference dataset of over 24,000 paired\nmulti-turn user interactions with search-augmented LLMs. The dataset spans\ndiverse intents and languages, and contains full system traces with around\n12,000 human preference votes. Our analysis reveals that user preferences are\ninfluenced by the number of citations, even when the cited content does not\ndirectly support the attributed claims, uncovering a gap between perceived and\nactual credibility. Furthermore, user preferences vary across cited sources,\nrevealing that community-driven platforms are generally preferred and static\nencyclopedic sources are not always appropriate and reliable. To assess\nperformance across different settings, we conduct cross-arena analyses by\ntesting search-augmented LLMs in a general-purpose chat environment and\nconventional LLMs in search-intensive settings. We find that web search does\nnot degrade and may even improve performance in non-search settings; however,\nthe quality in search settings is significantly affected if solely relying on\nthe model's parametric knowledge. We open-sourced the dataset to support future\nresearch in this direction. Our dataset and code are available at:\nhttps://github.com/lmarena/search-arena.", "AI": {"tldr": "The paper introduces Search Arena, a large-scale dataset for evaluating search-augmented LLMs, revealing insights into user preferences and the impact of citations and sources on perceived credibility.", "motivation": "Existing datasets for search-augmented LLMs are limited in scale and scope, focusing on static, single-turn questions. The need for a more comprehensive dataset to analyze multi-turn interactions and user preferences motivated this work.", "method": "The authors created Search Arena, a crowd-sourced dataset of over 24,000 multi-turn interactions with search-augmented LLMs, including 12,000 human preference votes. The dataset spans diverse intents and languages.", "result": "User preferences are influenced by citation quantity, even if citations don't directly support claims. Community-driven sources are preferred over static encyclopedic ones. Web search can improve performance in non-search settings but degrades in search-intensive settings if relying solely on parametric knowledge.", "conclusion": "The dataset supports future research into search-augmented LLMs, highlighting the gap between perceived and actual credibility and the importance of source diversity. The dataset and code are open-sourced."}}
{"id": "2506.05346", "pdf": "https://arxiv.org/pdf/2506.05346", "abs": "https://arxiv.org/abs/2506.05346", "authors": ["Lei Hsiung", "Tianyu Pang", "Yung-Chen Tang", "Linyue Song", "Tsung-Yi Ho", "Pin-Yu Chen", "Yaoqing Yang"], "title": "Why LLM Safety Guardrails Collapse After Fine-tuning: A Similarity Analysis Between Alignment and Fine-tuning Datasets", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": "Project Page: https://hsiung.cc/llm-similarity-risk/", "summary": "Recent advancements in large language models (LLMs) have underscored their\nvulnerability to safety alignment jailbreaks, particularly when subjected to\ndownstream fine-tuning. However, existing mitigation strategies primarily focus\non reactively addressing jailbreak incidents after safety guardrails have been\ncompromised, removing harmful gradients during fine-tuning, or continuously\nreinforcing safety alignment throughout fine-tuning. As such, they tend to\noverlook a critical upstream factor: the role of the original safety-alignment\ndata. This paper therefore investigates the degradation of safety guardrails\nthrough the lens of representation similarity between upstream alignment\ndatasets and downstream fine-tuning tasks. Our experiments demonstrate that\nhigh similarity between these datasets significantly weakens safety guardrails,\nmaking models more susceptible to jailbreaks. Conversely, low similarity\nbetween these two types of datasets yields substantially more robust models and\nthus reduces harmfulness score by up to 10.33%. By highlighting the importance\nof upstream dataset design in the building of durable safety guardrails and\nreducing real-world vulnerability to jailbreak attacks, these findings offer\nactionable insights for fine-tuning service providers.", "AI": {"tldr": "The paper explores how the similarity between upstream safety-alignment data and downstream fine-tuning tasks affects LLM safety guardrails, showing high similarity weakens guardrails while low similarity strengthens them.", "motivation": "Existing mitigation strategies for LLM safety alignment jailbreaks overlook the role of original safety-alignment data, prompting investigation into dataset similarity's impact.", "method": "The study analyzes representation similarity between upstream alignment datasets and downstream fine-tuning tasks, conducting experiments to measure effects on safety guardrails.", "result": "High similarity between datasets weakens safety guardrails, increasing jailbreak vulnerability, while low similarity reduces harmfulness scores by up to 10.33%.", "conclusion": "Upstream dataset design is crucial for durable safety guardrails, offering actionable insights for fine-tuning service providers to reduce jailbreak risks."}}
