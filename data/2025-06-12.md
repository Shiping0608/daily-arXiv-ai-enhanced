<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 14]
- [math.AP](#math.AP) [Total: 9]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 2]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [math.SP](#math.SP) [Total: 1]
- [math.OC](#math.OC) [Total: 5]
- [math.PR](#math.PR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 5]
- [cs.LG](#cs.LG) [Total: 2]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [math-ph](#math-ph) [Total: 1]
- [math.DG](#math.DG) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [An Introduction to Solving the Least-Squares Problem in Variational Data Assimilation](https://arxiv.org/abs/2506.09211)
*I. Daužickaitė,M. A. Freitag,S. Gürol,A. S. Lawless,A. Ramage,J. A. Scott,J. M. Tabeart*

Main category: math.NA

TL;DR: The paper reviews variational data assimilation from a numerical linear algebra perspective, focusing on challenges in large-scale geophysical systems and the need for high-quality preconditioners.


<details>
  <summary>Details</summary>
Motivation: To address the computational demands and limitations in solving large-scale nonlinear least-squares problems in Earth system state estimation, particularly for weather and ocean forecasting.

Method: The approach involves solving sparse linear subproblems using sophisticated numerical linear algebra methods, emphasizing the role of Krylov subspace solvers and preconditioners.

Result: Highlights the critical need for efficient preconditioners due to computational constraints limiting solver iterations.

Conclusion: The paper underscores the importance of advanced numerical linear algebra techniques in variational data assimilation for practical geophysical applications.

Abstract: Variational data assimilation is a technique for combining measured data with
dynamical models. It is a key component of Earth system state estimation and is
commonly used in weather and ocean forecasting. The approach involves a
large-scale generalized nonlinear least-squares problem. Solving the resulting
sequence of sparse linear subproblems requires the use of sophisticated
numerical linear algebra methods. In practical applications, the computational
demands severely limit the number of iterations of a Krylov subspace solver
that can be performed and so high-quality preconditioners are vital. In this
paper, we introduce variational data assimilation from a numerical linear
algebra perspective and review current solution techniques, with a focus on the
challenges that arise in large-scale geophysical systems.

</details>


### [2] [Improved error bounds for Koopman operator and reconstructed trajectories approximations with kernel-based methods](https://arxiv.org/abs/2506.09266)
*Diego Olguín,Axel Osses,Héctor Ramírez*

Main category: math.NA

TL;DR: Proposes a new $O(N^{-1/2})$ error bound for Koopman operator approximation using Kernel Extended Dynamic Mode Decomposition, introduces a lifting back operator, and validates with numerical results.


<details>
  <summary>Details</summary>
Motivation: To improve error bounds for Koopman operator approximation and provide a practical method for trajectory generation in higher dimensions.

Method: Uses Kernel Extended Dynamic Mode Decomposition and introduces a lifting back operator for trajectory generation.

Result: Achieves an $O(N^{-1/2})$ error bound and demonstrates successful approximation with exponential decay in numerical examples.

Conclusion: The proposed method effectively bounds approximation errors and performs well in practical applications.

Abstract: In this article, we propose a new error bound for Koopman operator
approximation using Kernel Extended Dynamic Mode Decomposition. The new
estimate is $O(N^{-1/2})$, with a constant related to the probability of
success of the bound, given by Hoeffding's inequality, similar to other
methodologies, such as Philipp et al. Furthermore, we propose a \textit{lifting
back} operator to obtain trajectories generated by embedding the initial state
and iterating a linear system in a higher dimension. This naturally yields an
$O(N^{-1/2})$ error bound for mean trajectories. Finally, we show numerical
results including an example of nonlinear system, exhibiting successful
approximation with exponential decay faster than $-1/2$, as suggested by the
theoretical results.

</details>


### [3] [A discontinuous Galerkin plane wave neural network method for Helmholtz equation and Maxwell's equations](https://arxiv.org/abs/2506.09309)
*Long Yuan,Menghui Wu,Qiya Hu*

Main category: math.NA

TL;DR: The paper introduces a discontinuous Galerkin plane wave neural network (DGPWNN) method for solving Helmholtz and Maxwell's equations, combining neural networks with adaptive refinement techniques.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of solving Helmholtz and Maxwell's equations by leveraging neural networks and adaptive refinement for improved accuracy and efficiency.

Method: The method involves defining an elliptic-type variational problem, using adaptive construction of DG subspaces with neural network basis functions, and recursively generating basis functions via quasi-maximization problems.

Result: Convergence is proven without bounded neural network parameters, and numerical experiments validate the method's effectiveness.

Conclusion: The DGPWNN method is effective for solving Helmholtz and Maxwell's equations, with theoretical and numerical support.

Abstract: In this paper we propose a discontinuous Galerkin plane wave neural network
(DGPWNN) method for approximately solving Helmholtz equation and Maxwell's
equations. In this method, we define an elliptic-type variational problem as in
the plane wave least square method with $h-$refinement and introduce the
adaptive construction of recursively augmented discontinuous Galerkin subspaces
whose basis functions are realizations of element-wise neural network functions
with $hp-$refinement, where the activation function is chosen as a
complex-valued exponential function like the plane wave function.
  A sequence of basis functions approaching the unit residuals are recursively
generated by iteratively solving quasi-maximization problems associated with
the underlying residual functionals and the intersection of the closed unit
ball and discontinuous plane wave neural network spaces. The convergence
results of the DGPWNN method are established without the assumption on the
boundedness of the neural network parameters. Numerical experiments confirm the
effectiveness of the proposed method.

</details>


### [4] [Overcoming logarithmic singularities in the Cahn-Hilliard equation with Flory-Huggins potential: An unconditionally convergent ADMM approach](https://arxiv.org/abs/2506.09361)
*Ruo Li,Shengtong Liang,Zhonghua Qiao*

Main category: math.NA

TL;DR: A novel ADMM-based solver is introduced for the Cahn-Hilliard equation with Flory-Huggins potential, efficiently handling singularities and ensuring unconditional convergence without restrictive conditions.


<details>
  <summary>Details</summary>
Motivation: Existing solvers for the Cahn-Hilliard equation face challenges due to singular logarithmic terms and restrictive convergence conditions, limiting their practicality.

Method: The proposed method uses a tailored ADMM variant with a variable splitting strategy to decouple and handle singular nonlinearities effectively.

Result: The solver achieves unconditional convergence, eliminating the need for time step constraints or strict separation conditions, and demonstrates superior efficiency in numerical experiments.

Conclusion: The ADMM-based solver is robust and efficient, validating its design and theoretical framework for handling singular systems in phase separation models.

Abstract: The Cahn-Hilliard equation with Flory-Huggins potential serves as a
fundamental phase field model for describing phase separation phenomena. Due to
the presence of logarithmic singularities at $u=\pm 1$, the solution $u$ is
constrained within the interval $(-1,1)$. While convex splitting schemes are
commonly employed to preserve this bound and guarantee unconditional unique
solvability, their practical implementation requires solving nonlinear systems
containing singular logarithmic terms at each time step. This introduces
significant challenges in both ensuring convergence of iterative solvers and
maintaining the solution bounds throughout the iterations. Existing solvers
often rely on restrictive conditions -- such as the strict separation property
or small time step sizes -- to ensure convergence, which can limit their
applicability. In this work, we introduce a novel iterative solver that is
specifically designed for singular nonlinear systems, with the use of a variant
of the alternating direction method of multipliers (ADMM). By developing a
tailored variable splitting strategy within the ADMM framework, our method
efficiently decouples the challenging logarithmic nonlinearity, enabling
effective handling of singularities. Crucially, we rigorously prove the
unconditional convergence of our ADMM-based solver, which removes the need for
time step constraints or strict separation conditions. This allows us to fully
leverage the unconditional solvability offered by convex splitting schemes.
Comprehensive numerical experiments demonstrate the superior efficiency and
robustness of our ADMM variant, strongly validating both our algorithmic design
and theoretical results.

</details>


### [5] [Subspace-constrained randomized coordinate descent for linear systems with good low-rank matrix approximations](https://arxiv.org/abs/2506.09394)
*Jackie Lok,Elizaveta Rebrova*

Main category: math.NA

TL;DR: The paper introduces SC-RCD, a subspace-constrained variant of RCD, to improve convergence rates for linear systems with large spectral outliers, validated by experiments and theoretical analysis.


<details>
  <summary>Details</summary>
Motivation: RCD's performance degrades with large spectral outliers, limiting its effectiveness for certain optimization problems.

Method: SC-RCD restricts RCD dynamics to an affine subspace using a column Nyström approximation, computed via RPCholesky.

Result: SC-RCD converges unaffected by spectral outliers, proving efficient for dense linear systems with decaying spectra.

Conclusion: SC-RCD offers a memory-efficient solver for specific problems, with a broader framework for subspace-constrained iterative methods.

Abstract: The randomized coordinate descent (RCD) method is a classical algorithm with
simple, lightweight iterations that is widely used for various optimization
problems, including the solution of positive semidefinite linear systems. As a
linear solver, RCD is particularly effective when the matrix is
well-conditioned; however, its convergence rate deteriorates rapidly in the
presence of large spectral outliers. In this paper, we introduce the
subspace-constrained randomized coordinate descent (SC-RCD) method, in which
the dynamics of RCD are restricted to an affine subspace corresponding to a
column Nystr\"{o}m approximation, efficiently computed using the recently
analyzed RPCholesky algorithm. We prove that SC-RCD converges at a rate that is
unaffected by large spectral outliers, making it an effective and
memory-efficient solver for large-scale, dense linear systems with rapidly
decaying spectra, such as those encountered in kernel ridge regression.
Experimental validation and comparisons with related solvers based on
coordinate descent and the conjugate gradient method demonstrate the efficiency
of SC-RCD. Our theoretical results are derived by developing a more general
subspace-constrained framework for the sketch-and-project method. This
framework generalizes popular algorithms such as randomized Kaczmarz and
coordinate descent, and provides a flexible, implicit preconditioning strategy
for a variety of iterative solvers, which may be of independent interest.

</details>


### [6] [FNPF-SEM: A parallel spectral element model in Firedrake for fully nonlinear water wave simulations](https://arxiv.org/abs/2506.09435)
*Jens Visbech,Anders Melander,Allan Peter Engsig-Karup*

Main category: math.NA

TL;DR: FNPF-SEM is a parallel spectral element solver for simulating water waves and their interactions with structures, offering high accuracy, efficiency, and scalability.


<details>
  <summary>Details</summary>
Motivation: To develop a general-purpose wave model for offshore engineering, addressing the need for accurate simulation of linear and nonlinear wave phenomena.

Method: Built within Firedrake, FNPF-SEM uses high-order spectral finite elements and MPI-based parallelism for efficient large-scale simulations.

Result: Validated against analytical and experimental data, the model demonstrates high accuracy in simulating wave propagation and wave-structure interactions.

Conclusion: FNPF-SEM provides a scalable, high-accuracy framework for simulating complex wave phenomena and interactions with offshore structures.

Abstract: We present a new parallel spectral element solver, FNPF-SEM, for simulating
linear and fully nonlinear potential flow-based water waves and their
interaction with offshore structures. The tool is designed as a general-purpose
wave model for offshore engineering applications. Built within the open-source
framework Firedrake, the new FNPF-SEM model is designed as a computational tool
capable of capturing both linear and nonlinear wave phenomena with high
accuracy and efficiency, with support for high-order (spectral) finite
elements. Additionally, Firedrake provides native support for MPI-based
parallelism, allowing for efficient multi-CPU distributed computations needed
for large-scale simulations. We demonstrate the capabilities of the high-order
spectral element model through h- and p-convergence studies, and weak and
strong scaling tests. Validation is performed against analytical solutions and
experimental data for several benchmark cases, including nonlinear high-order
harmonic generation and linear and nonlinear wave interactions with a cylinder
and a breakwater. The new FNPF-SEM model offers a numerical framework for
simulating wave propagation and wave-structure interactions, with the following
key features: i) the ability to represent complex geometries through flexible,
unstructured finite element meshes; ii) reduced numerical diffusion and
dispersion by using high-order polynomial expansions; and iii) scalability to
full- and large-scale simulations over long time periods through a parallel
implementation.

</details>


### [7] [Segregated Runge-Kutta schemes for the time integration of the incompressible Navier-Stokes equations in presence of pressure stabilization](https://arxiv.org/abs/2506.09519)
*Pavel Bakhvalov*

Main category: math.NA

TL;DR: Segregated Runge-Kutta (SRK) schemes are generalized for pressure-stabilized spatial discretizations, outperforming third-order multistep methods in accuracy without increasing computational costs.


<details>
  <summary>Details</summary>
Motivation: To extend SRK schemes, originally for inf-sup stable finite-element methods, to pressure-stabilized spatial discretizations.

Method: Generalizes SRK schemes for spatial discretizations with pressure stabilization, tested with finite-difference and finite-element methods.

Result: One SRK scheme outperforms third-order multistep projection-based methods in accuracy while maintaining computational efficiency.

Conclusion: SRK schemes are effective for pressure-stabilized discretizations, offering accuracy advantages over existing methods.

Abstract: Segregated Runge-Kutta (SRK) schemes are time integration methods for the
incompressible Navier-Stokes equations. In this approach, convection and
diffusion can be independently treated either explicitly or implicitly, which
in particular allows to construct implicit-explicit (IMEX) methods. Original
SRK schemes (Colomes, Badia, IJNME, 2015) are designed for finite-element
methods that satisfy the inf-sup condition. In this paper, the idea of SRK
schemes is generalized to spatial discretizations with pressure stabilization.
In the numerical experiments, SRK schemes are demonstrated with both
finite-difference and finite element spatial discretizations. Numerical results
show that one of the SRK schemes outperforms the third-order multistep
projection-based method in terms of accuracy while preserving the computational
costs.

</details>


### [8] [Extensive Database of Spatial Ballistic Captures with Application to Lunar Trailblazer](https://arxiv.org/abs/2506.09584)
*Lorenzo Anoè,Roberto Armellin,Gregory Lantoine,Claudio Bombardelli*

Main category: math.NA

TL;DR: The paper extends the Energy Transition Domain framework to 3D for Ballistic Capture, applies it to Lunar Trailblazer, and selects high-fidelity backup trajectories.


<details>
  <summary>Details</summary>
Motivation: To enable practical application of Ballistic Capture for missions like Lunar Trailblazer by transitioning from planar to spatial analysis and ephemeris models.

Method: Extends the Energy Transition Domain to 3D, builds a spatial Ballistic Capture database, filters trajectories for Lunar Trailblazer, and transitions to an ephemeris model.

Result: A subset of trajectories is analyzed, and high-fidelity options are identified as backups for Lunar Trailblazer.

Conclusion: The spatial framework and ephemeris transition enhance mission flexibility and reliability for low-energy lunar missions.

Abstract: For low-energy missions to the Moon and beyond, Ballistic Capture has proven
to be a valuable technique for enabling orbital insertion while alleviating
propulsion system requirements. This approach offers two key advantages. First,
it extends the insertion window, allowing multiple maneuver opportunities to
mitigate potential failures at the nominal insertion point. Second, it enables
the required insertion maneuver to be distributed across multiple revolutions,
reducing propulsion system constraints in terms of single-burn thrust. Prior
research introduced the concept of Energy Transition Domain to support the
creation of a comprehensive database of Ballistic Captures in the planar
Circular Restricted Three-Body Problem. However, to apply these trajectories to
a real mission scenario, a three-dimensional, spatial analysis and transition
to an ephemeris model are necessary. This paper first extends the Energy
Transition Domain framework to the spatial case, constructing an extensive
database of spatial Ballistic Captures. Then, using Lunar Trailblazer as a case
study, a subset of the trajectories is filtered using a mission-specific
distance metric, and transitioned into an ephemeris model. Finally, interesting
features of this subset are analyzed, and sample high-fidelity trajectories are
selected as potential backup options for Lunar Trailblazer.

</details>


### [9] [Geometric flow regularization in latent spaces for smooth dynamics with the efficient variations of curvature](https://arxiv.org/abs/2506.09679)
*Andrew Gracyk*

Main category: math.NA

TL;DR: The paper introduces geometric flow regularization techniques to improve adversarial learning in encoder-decoder methods, focusing on maintaining geometric invariants and enhancing learning fidelity.


<details>
  <summary>Details</summary>
Motivation: To temper adversarial learning effects in smooth data dynamics by leveraging geometric flows, ensuring key geometric properties are preserved while improving computational efficiency.

Method: Uses adaptations of curvature and Ricci flow, introduces new geometric flows (parametric and non-parametric), and employs physics-informed learning. Key techniques include Gaussian curvature-based loss, a new parametric flow, and strategies involving time differentiation of functionals.

Result: The methods maintain integral latent structure and enhance learning fidelity, particularly in zero-shot and adversarial scenarios.

Conclusion: Geometric flow regularization effectively controls structure in latent spaces, improving learning outcomes while preserving essential geometric invariants.

Abstract: We design strategies in nonlinear geometric analysis to temper the effects of
adversarial learning for sufficiently smooth data of numerical method-type
dynamics in encoder-decoder methods, variational and deterministic, through the
use of geometric flow regularization. We augment latent spaces with geometric
flows to control structure. Our techniques rely on adaptations of curvature and
Ricci flow. We invent new geometric flows or discover them neurally and
non-parametrically. All of our flows are solved using physics-informed
learning. Traditional geometric meaning is traded for computing ability, but we
maintain key geometric invariants, the primary of which are maintained,
intrinsically-low structure, canonicity or a lack of irregularity,
nontriviality due to sufficient lower bounds on curvature, and distortion of
volume element, that develop quality in the inference stage. Our primary
contributions are fourfold. We develop a loss based on Gaussian curvature using
closed path circulation integration for surfaces, bypassing automatic
differentiation of the Christoffel symbols through use of Stokes' theorem. We
invent a new parametric flow derived from a linear version of the Gauss
equation and a Riemannian decomposition for a custom tensor defined with a
normal Hessian and Weyl tensor proxies. We develop two strategies based on time
differentiation of functionals, one with a special case of scalar curvature for
conformally-changed metrics, and another with harmonic maps, their energy, and
induced metrics. Our methods, while diminished analytically, maintain overall
integral latent structure. We showcase that curvature flows and the formulation
of geometric structure in intermediary encoded settings enhance learning and
overall zero-shot and adversarial fidelity.

</details>


### [10] [Matrix best approximation in the spectral norm](https://arxiv.org/abs/2506.09687)
*Vance Faber,Jörg Liesen,Petr Tichý*

Main category: math.NA

TL;DR: The paper presents a matrix formulation for spectral approximations, links it to semidefinite programming, provides MATLAB code for numerical solutions, and derives geometric characterizations and conditions for equality in min-max and max-min problems.


<details>
  <summary>Details</summary>
Motivation: To generalize Singer's best approximation theorem for spectral approximations and explore its connections to semidefinite programming and geometric properties.

Method: Develops a matrix formulation, links it to semidefinite programming, uses MATLAB for numerical solutions, and derives geometric characterizations and conditions for min-max and max-min equality.

Result: Provides geometric insights into spectral approximations, conditions for equality in min-max problems, and generalizes results from GMRES method analysis.

Conclusion: The spectral approximation problem's min-max and max-min values are equal under certain conditions, and doubling the problem ensures equality, extending GMRES method insights.

Abstract: We derive, similar to Lau and Riha, a matrix formulation of a general best
approximation theorem of Singer for the special case of spectral approximations
of a given matrix from a given subspace. Using our matrix formulation we
describe the relation of the spectral approximation problem to semidefinite
programming, and we present a simple MATLAB code to solve the problem
numerically. We then obtain geometric characterizations of spectral
approximations that are based on the $k$-dimensional field of $k$ matrices,
which we illustrate with several numerical examples. The general spectral
approximation problem is a min-max problem, whose value is bounded from below
by the corresponding max-min problem. Using our geometric characterizations of
spectral approximations, we derive several necessary and sufficient as well as
sufficient conditions for equality of the max-min and min-max values. Finally,
we prove that the max-min and min-max values are always equal when we
``double'' the problem. Several results in this paper generalize results that
have been obtained in the convergence analysis of the GMRES method for solving
linear algebraic systems.

</details>


### [11] [Generative Models for Parameter Space Reduction applied to Reduced Order Modelling](https://arxiv.org/abs/2506.09721)
*Guglielmo Padula,Gianluigi Rozza*

Main category: math.NA

TL;DR: The paper proposes using Generative Models to reduce geometric parameters in PDE solutions, enhancing the accuracy of DROMs and PPINNs.


<details>
  <summary>Details</summary>
Motivation: High computational complexity in solving PDEs for parameterised domains motivates learning direct mappings, but existing methods (DROMs, PPINNs) degrade with more parameters.

Method: Generative Models generate new geometries to reduce parameter dimensionality, improving DROMs and PPINNs. PPINNs use a new methodology for better convergence.

Result: DROMs show improved accuracy with reduced parameters. PPINNs benefit from enhanced convergence. Tested on a Poisson equation over deformed Stanford Bunny domains.

Conclusion: Generative Models effectively reduce parameter dimensions, boosting the performance of DROMs and PPINNs in solving PDEs for complex geometries.

Abstract: Solving and optimising Partial Differential Equations (PDEs) in geometrically
parameterised domains often requires iterative methods, leading to high
computational and time complexities. One potential solution is to learn a
direct mapping from the parameters to the PDE solution. Two prominent methods
for this are Data-driven Non-Intrusive Reduced Order Models (DROMs) and
Parametrised Physics Informed Neural Networks (PPINNs). However, their accuracy
tends to degrade as the number of geometric parameters increases. To address
this, we propose adopting Generative Models to create new geometries,
effectively reducing the number of parameters, and improving the performance of
DROMs and PPINNs. The first section briefly reviews the general theory of
Generative Models and provides some examples, whereas the second focusses on
their application to geometries with fixed or variable points, emphasising
their integration with DROMs and PPINNs. DROMs trained on geometries generated
by these models demonstrate enhanced accuracy due to reduced parameter
dimensionality. For PPINNs, we introduce a methodology that leverages
Generative Models to reduce the parameter dimensions and improve convergence.
This approach is tested on a Poisson equation defined over deformed Stanford
Bunny domains.

</details>


### [12] [Machine Learning-based quadratic closures for non-intrusive Reduced Order Models](https://arxiv.org/abs/2506.09830)
*Gabriele Codega,Anna Ivagnes,Nicola Demo,Gianluigi Rozza*

Main category: math.NA

TL;DR: A data-driven method improves non-intrusive Reduced Order Models (ROMs) by reintroducing neglected modes via a quadratic correction term, using a Multi-Input Operators Network (MIONet) for better generalization.


<details>
  <summary>Details</summary>
Motivation: Enhancing ROM accuracy in under-resolved regimes where standard POD modes fail to capture system dynamics.

Method: Proposes a quadratic correction term for neglected modes, parametrized by MIONet instead of least-squares optimization, ensuring continuous and parameter-dependent operators.

Result: Tests on fluid dynamics benchmarks show improved accuracy over standard POD-based ROMs.

Conclusion: The MIONet-based correction term effectively enhances ROM accuracy, offering better generalization and discretization-agnostic performance.

Abstract: In the present work, we introduce a data-driven approach to enhance the
accuracy of non-intrusive Reduced Order Models (ROMs). In particular, we focus
on ROMs built using Proper Orthogonal Decomposition (POD) in an under-resolved
and marginally-resolved regime, i.e. when the number of modes employed is not
enough to capture the system dynamics. We propose a method to re-introduce the
contribution of neglected modes through a quadratic correction term, given by
the action of a quadratic operator on the POD coefficients. Differently from
the state-of-the-art methodologies, where the operator is learned via
least-squares optimisation, we propose to parametrise the operator by a
Multi-Input Operators Network (MIONet). This way, we are able to build models
with higher generalisation capabilities, where the operator itself is
continuous in space -- thus agnostic of the domain discretisation -- and
parameter-dependent. We test our model on two standard benchmarks in fluid
dynamics and show that the correction term improves the accuracy of standard
POD-based ROMs.

</details>


### [13] [A Note on the Reliability of Goal-Oriented Error Estimates for Galerkin Finite Element Methods with Nonlinear Functionals](https://arxiv.org/abs/2506.09913)
*Brian N. Granzow,Stephen D. Bond,D. Thomas Seidl,Bernhard Endtmayer*

Main category: math.NA

TL;DR: The paper examines the reliability of error estimates in nonlinear functionals for Galerkin finite element methods, showing cases where these estimates fail despite exact adjoint solutions.


<details>
  <summary>Details</summary>
Motivation: To investigate the reliability of error estimates in nonlinear functionals within variational problems, highlighting scenarios where traditional estimates are unreliable.

Method: Analyzes error estimates of the form $\eta = L(z) - B(u_h, z)$ for nonlinear functionals $J(u)$, using abstract variational problems and Galerkin finite element approximations.

Result: Demonstrates that certain nonlinear functionals and bilinear forms lead to unreliable error estimates, even with exact adjoint solutions.

Conclusion: Traditional error estimates may not always be reliable for nonlinear functionals, necessitating further scrutiny in specific cases.

Abstract: We consider estimating the discretization error in a nonlinear functional
$J(u)$ in the setting of an abstract variational problem: find $u \in
\mathcal{V}$ such that $B(u,\varphi) = L(\varphi) \; \forall \varphi \in
\mathcal{V}$, as approximated by a Galerkin finite element method. Here,
$\mathcal{V}$ is a Hilbert space, $B(\cdot,\cdot)$ is a bilinear form, and
$L(\cdot)$ is a linear functional. We consider well-known error estimates
$\eta$ of the form $J(u) - J(u_h) \approx \eta = L(z) - B(u_h, z)$, where $u_h$
denotes a finite element approximation to $u$, and $z$ denotes the solution to
an auxiliary adjoint variational problem. We show that there exist nonlinear
functionals for which error estimates of this form are not reliable, even in
the presence of an exact adjoint solution solution $z$. An estimate $\eta$ is
said to be reliable if there exists a constant $C \in \mathbb{R}_{>0}$
independent of $u_h$ such that $|J(u) - J(u_h)| \leq C|\eta|$. We present
several example pairs of bilinear forms and nonlinear functionals where
reliability of $\eta$ is not achieved.

</details>


### [14] [Efficient multigrid solvers for mixed-degree local discontinuous Galerkin multiphase Stokes problems](https://arxiv.org/abs/2506.09933)
*Robert I. Saye*

Main category: math.NA

TL;DR: Efficient multigrid solvers for multiphase Stokes problems using mixed-degree local discontinuous Galerkin methods, with a custom smoother balancing velocity and pressure variables.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of solving multiphase Stokes problems efficiently, especially with varying polynomial degrees and boundary conditions.

Method: Developed a multigrid V-cycle with a smoother approximating element-wise block Gauss-Seidel, optimized via two-grid local Fourier analysis.

Result: Reliable convergence rates for piecewise constant pressure fields, and rapid convergence (5-10 orders of magnitude in 5 iterations) for higher-degree cases.

Conclusion: The solver is highly effective for multiphase Stokes problems, matching classical Poisson-style multigrid performance in most cases.

Abstract: We design and investigate efficient multigrid solvers for multiphase Stokes
problems discretised via mixed-degree local discontinuous Galerkin methods.
Using the template of a standard multigrid V-cycle, we develop a smoother
analogous to element-wise block Gauss-Seidel, except the diagonal block
inverses are replaced with an approximation that balances the smoothing of the
velocity and pressure variables, factoring in the unequal scaling of the
various Stokes system operators, and optimised via two-grid local Fourier
analysis. We evaluate the performance of the multigrid solver across an
extensive range of two- and three-dimensional test problems, including
steady-state and unsteady, standard-form and stress-form, single-phase and
high-contrast multiphase Stokes problems, with multiple kinds of boundary
conditions and various choices of polynomial degree. In the lowest-degree case,
i.e., that of piecewise constant pressure fields, we observe reliable multigrid
convergence rates, though not especially fast. However, in every other case, we
see rapid convergence rates matching those of classical Poisson-style geometric
multigrid methods; e.g., 5 iterations reduce the Stokes system residual by 5 to
10 orders of magnitude.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [15] [Displacement of three-phase flow for Heavy Oil: Riemann Solutions](https://arxiv.org/abs/2506.09077)
*Luis Fernando Lozano,Furtado Frederico,De Souza Aparecido,Marchesin Dan*

Main category: math.AP

TL;DR: The paper presents a Riemann solution for three-phase flow in porous media, focusing on cases where oil viscosity is higher than water and gas. It classifies solutions for specific initial and injection data, extending previous limited analytical solutions.


<details>
  <summary>Details</summary>
Motivation: The study aims to address gaps in understanding three-phase flow dynamics, particularly for scenarios with high oil viscosity, by providing a broader classification of Riemann solutions.

Method: The wave curve method is used to determine Riemann solutions for specified initial and injection data, excluding small regions near certain boundaries.

Result: The classification is valid for viscosity regimes where the umbilic point is near the vertex O, and numerical experiments confirm the solution's stability and validity.

Conclusion: The findings offer a comprehensive framework for analyzing three-phase flow in porous media under varied conditions, though uniqueness of the solution remains unproven.

Abstract: This work presents the Riemann solution for three-phase flow in porous media
under the condition that oil viscosity exceeds that of water and gas. We
classify all Riemann solution problems for scenarios where the left states $L$
lie along the edge $G$-$W$, and the right states $R$ span nearly the entire
saturation triangle, excluding small regions near the boundaries $G$-$O$ and
$W$-$O$. We use the wave curve method to determine the Riemann solution for
initial and injection data within the above-mentioned class. This study extends
previous analytical solutions, which were limited to right states near the
corner $O$ or within the quadrilateral $O$-$E$-$\mathcal{U}$-$D$. Notably, this
classification remains valid for all viscosity variations satisfying the
inequalities \eqref{eq:classical}, corresponding to viscosity regimes where the
umbilic point is close to the vertex $O$. We verify the $L^1_{loc}$-stability
of the Riemann solution with respect to variations in the data. While we do not
establish the uniqueness of the Riemann solution, extensive numerical
experiments confirm its validity. Our findings provide a comprehensive
framework for understanding three-phase flow dynamics in porous media under a
wide range of conditions.

</details>


### [16] [Slowly oscillating periodic solutions in a nonlinear Volterra equation with non-symmetric feedback](https://arxiv.org/abs/2506.09564)
*Quentin Griette,Franco Herrera*

Main category: math.AP

TL;DR: The paper studies a nonlinear Volterra equation from population dynamics, focusing on slowly oscillating periodic solutions when the trivial state is unstable. It overcomes symmetry-related challenges and proves existence via a homeomorphism and fixed-point property, also exploring a singular limit and numerical simulations.


<details>
  <summary>Details</summary>
Motivation: The motivation is to analyze the existence of slowly oscillating periodic solutions in a nonlinear Volterra equation with non-symmetric feedback, a problem arising in population dynamics where traditional symmetry-based methods fail.

Method: The method involves proving forward invariance of a set of initial data to ensure slow oscillations, constructing a homeomorphism to a convex Banach space subset for fixed-point analysis, and examining a singular parameter limit.

Result: The results include the existence of periodic solutions and their convergence to a discrete difference equation solution in a singular limit, supported by numerical simulations.

Conclusion: The paper concludes by confirming the existence of slowly oscillating periodic solutions and their behavior in a singular limit, validated numerically.

Abstract: In this work we study a nonlinear Volterra equation with non-symmetric
feedback that arises as a particular case of the Gurtin-MacCamy model in
population dynamics. We are particularly interested in the existence of slowly
oscillating periodic solutions when the trivial stationary state is unstable.
Here the absence of symmetry of the nonlinearity prevents the use of many
traditional strategies to obtain a priori estimates on the solution. Without a
precise knowledge of the period of the solution, we manage to prove the forward
invariance of a carefully constructed set of initial data whose properties
imply the slowly oscillating character of all continuations. We prove the
existence of periodic solutions by constructing a homeomorphism between our set
and a convex subset of a different Banach space, thereby showing that it
possesses the fixed-point property. Finally, in a singular limit of a
parameter, we show that this periodic solution converges to the solution of a
wellknown discrete difference equation. We conclude the paper with some
numerical simulations to illustrate the existence of the periodic orbit as well
as the singular limit behavior.

</details>


### [17] [Existence of variational solutions to doubly nonlinear systems in general noncylindrical domains](https://arxiv.org/abs/2506.09617)
*Leah Schätzler,Christoph Scheven,Jarkko Siltakoski,Calvin Stanko*

Main category: math.AP

TL;DR: The paper studies the Cauchy-Dirichlet problem for doubly nonlinear systems, proving existence of variational solutions and analyzing their time regularity under certain conditions.


<details>
  <summary>Details</summary>
Motivation: To address the existence and regularity of solutions for doubly nonlinear systems in noncylindrical domains, which are less explored in literature.

Method: The authors assume integrability, convexity, and growth conditions on the function $f$, and use variational techniques to construct solutions.

Result: Existence of variational solutions is proven, and under additional conditions, the solutions exhibit distributional time derivatives and time continuity.

Conclusion: The results extend understanding of doubly nonlinear systems, particularly in noncylindrical domains, with implications for regularity and solution behavior.

Abstract: We consider the Cauchy-Dirichlet problem to doubly nonlinear systems of the
form \begin{align*}
  \partial_t \big( |u|^{q-1}u \big) - \operatorname{div} \big( D_\xi f(x,u,Du)
\big) = - D_u f(x,u,Du) \end{align*} with $q \in (0, \infty)$ in a bounded
noncylindrical domain $E \subset \mathbb{R}^{n+1}$. Further, we suppose that $x
\mapsto f(x,u,\xi)$ is integrable, that $(u,\xi) \mapsto f(x,u,\xi)$ is convex,
and that $f$ satisfies a $p$-growth and -coercivity condition for some $p>\max
\big\{ 1,\frac{n(q+1)}{n+q+1} \big\}$. Merely assuming that
$\mathcal{L}^{n+1}(\partial E) = 0$, we prove the existence of variational
solutions $u \in L^\infty\big( 0,T;L^{q+1}(E,\mathbb{R}^N)\big)$. If $E$ does
not shrink too fast, we show that for the solution $u$ constructed in the first
step, $\vert u \vert^{q-1}u$ admits a distributional time derivative. Moreover,
under suitable conditions on $E$ and the stricter lower bound $p \geq
\frac{(n+1)(q+1)}{n+q+1}$, $u$ is continuous with respect to time.

</details>


### [18] [Decay and Strichartz estimates for critical electromagnetic wave equations on conic manifolds](https://arxiv.org/abs/2506.09635)
*Qiuye Jia,Junyong Zhang*

Main category: math.AP

TL;DR: The paper establishes decay and Strichartz estimates for the wave equation with large scaling-critical electromagnetic potentials on a conical singular space, extending prior work on smaller or faster-decaying potentials.


<details>
  <summary>Details</summary>
Motivation: To address the gap in understanding wave equations with large critical electromagnetic potentials on conical singular spaces, improving upon previous studies limited to small or faster-decaying potentials.

Method: The authors prove localized pointwise estimates for the half-wave propagator by constructing a localized spectral measure, separating contributions from conjugate point pairs.

Result: The results extend and improve prior work, handling large critical potentials, including Coulomb-type decay, on conical singular spaces.

Conclusion: The study advances the understanding of wave equations in singular geometries with critical potentials, offering new tools for localized spectral analysis.

Abstract: We establish the decay and Strichartz estimates for the wave equation with
large scaling-critical electromagnetic potentials on a conical singular space
$(X,g)$ with dimension $n\geq3$, where the metric $g=dr^2+r^2 h$ and
$X=C(Y)=(0,\infty)\times Y$ is a product cone over the closed Riemannian
manifold $(Y,h)$ with metric $h$. The decay assumption on the magnetic
potentials is scaling critical and includes the decay of Coulomb type. The main
technical innovation lies in proving localized pointwise estimates for the
half-wave propagator by constructing a localized spectral measure, which
effectively separates contributions from conjugate point pairs on $\CS$. In
particular, when $Y=\mathbb{S}^{n-1}$, our results, which address the case of
large critical electromagnetic potentials, extend and improve upon those in
[21], which considered sufficiently decaying, and small potentials and that of
[24], which considered potentials decaying faster than scaling critical ones.

</details>


### [19] [The twisted constant in Calabi-Yau type equation](https://arxiv.org/abs/2506.09639)
*Genglong Lin*

Main category: math.AP

TL;DR: The paper provides a necessary and sufficient condition for solving fully nonlinear elliptic equations on compact almost Hermitian manifolds, extending prior work. It applies this to determine twisted constants in Calabi-Yau type equations, addressing a question from Chu-Tosatti-Weinkove.


<details>
  <summary>Details</summary>
Motivation: To extend existing results on fully nonlinear elliptic equations and address unresolved questions in the field, particularly those related to Calabi-Yau type equations.

Method: Establishing a necessary and sufficient condition for solving a general class of fully nonlinear elliptic equations on compact almost Hermitian manifolds, building on recent work.

Result: The condition is applied to determine twisted constants in various Calabi-Yau type equations, including classical, Hessian, and form types with gradient terms.

Conclusion: The work successfully extends prior results and resolves a specific question raised in earlier research, contributing to the understanding of nonlinear elliptic equations in geometric contexts.

Abstract: In this paper we establish a necessary and sufficient condition for solving a
general class of fully nonlinear elliptic equations on compact almost Hermitian
manifolds, extending a recent work of Guo-Song. As applications, we determine
the twisted constants in Calabi-Yau type equations, including the classical
one, Hessian type one and form type one with gradient terms introduced by
Popovici and Tosatti-Weinkove. In particular, it addresses a question raised in
a work of Chu-Tosatti-Weinkove \cite[Introduction, Remark 5]{CTW19}.

</details>


### [20] [Formation of stationary interfaces in the fast reaction limit](https://arxiv.org/abs/2506.09716)
*Yuki Tsukamoto*

Main category: math.AP

TL;DR: The paper analyzes a two-component reaction-diffusion system with a singularly large reaction term, showing convergence to the heat equation in nonreactive regions and zero elsewhere, using barrier functions and comparison arguments.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of solutions in a reaction-diffusion system where one reaction term becomes singularly large, particularly under segregated initial conditions.

Method: The analysis employs explicitly constructed barrier functions and a comparison argument tailored for systems with asymmetric reaction terms to control behavior near the interface.

Result: The solution converges to the heat equation in nonreactive regions and remains zero elsewhere, with a stationary phase interface determined by the initial reactive component's support.

Conclusion: The study provides insights into the limiting behavior of such systems, highlighting the role of initial conditions and reaction asymmetry in shaping the solution's long-term dynamics.

Abstract: We study a two-component reaction-diffusion system in which one of the
reaction terms becomes singularly large. Assuming that the initial data are
nonnegative and mutually segregated, we prove that the solution converges to
that of the heat equation in the nonreactive region, while it remains zero
elsewhere. The analysis is based on explicitly constructed barrier functions
and a comparison argument adapted to systems with asymmetric reaction terms,
which together provide control near the interface. As a result, the limiting
behavior exhibits a stationary phase interface determined by the initial
support of the reactive component.

</details>


### [21] [On a nonlinear Schrödinger-Bopp-Podolsky system in the zero mass case: functional framework and existence](https://arxiv.org/abs/2506.09752)
*Erasmo Caponio,Pietro d'Avenia,Alessio Pomponio,Gaetano Siciliano,Lianfeng Yang*

Main category: math.AP

TL;DR: The paper studies a zero mass Schrödinger-Bopp-Podolsky system in ℝ³, introducing a Sobolev space with a nonlocal norm to prove the existence of a weak solution.


<details>
  <summary>Details</summary>
Motivation: The work is inspired by Ruiz (2010) and aims to address the system's solvability by leveraging a specialized Sobolev space and perturbation methods.

Method: The authors introduce a Sobolev space ℰ with a nonlocal norm, analyze its properties, and use a perturbation argument to derive solutions.

Result: Key results include fundamental properties of ℰ, embeddings into Lebesgue spaces, a lower bound for Bopp-Podolsky energy, and existence of a weak solution.

Conclusion: The paper successfully proves the existence of a weak solution to the system using the introduced Sobolev space and perturbation techniques.

Abstract: In this paper, we consider in $\mathbb{R}^3$ the following zero mass
Schr\"odinger-Bopp-Podolsky system \[ \begin{cases} -\Delta u +q^2\phi
u=|u|^{p-2}u\\ -\Delta \phi+a^2\Delta^2\phi=4\pi u^2 \end{cases} \] where
$a>0$, $q\ne 0$ and $p\in (3,6)$. Inspired by [Ruiz, Arch. Ration. Mech. Anal.
198 (2010)], we introduce a Sobolev space $\mathcal{E}$ endowed with a norm
containing a nonlocal term. Firstly, we provide some fundamental properties for
the space $\mathcal{E}$ including embeddings into Lebesgue spaces. Moreover a
general lower bound for the Bopp-Podolsky energy is obtained. Based on these
facts, by applying a perturbation argument, we finally prove the existence of a
weak solution to the above system.

</details>


### [22] [Large Time Behavior of the Klein-Gordon-Schrödigner system](https://arxiv.org/abs/2506.09863)
*Chanjin You*

Main category: math.AP

TL;DR: Global existence and scattering for small, localized solutions of the Klein-Gordon-Schrödinger system in 3D, analyzed using space-time resonance method.


<details>
  <summary>Details</summary>
Motivation: Study plasma oscillations from the Hartree equation near a translation-invariant equilibrium with Coulomb potential.

Method: Space-time resonance method applied to coupled semilinear Schrödinger and Klein-Gordon equations with quadratic nonlinearities.

Result: Established global existence and scattering for small, localized solutions despite challenges like a 2D resonant set and lack of null form structure.

Conclusion: The system's solutions exhibit global existence and scattering under small, localized conditions, overcoming inherent analytical difficulties.

Abstract: We establish the global existence and scattering for small and localized
solutions of the Klein-Gordon-Schr\"{o}dinger system in three dimensions. The
system consists of coupled semilinear Schr\"{o}dinger and Klein-Gordon
equations with quadratic nonlinearities. This model is motivated by the study
of plasma oscillations arising from the Hartree equation near a
translation-invariant equilibrium with the Coulomb potential. Our proof relies
on the space-time resonance method. The main difficulty comes from the two
dimensional space-time resonant set and the absence of null form structure.

</details>


### [23] [An optimal class of domains permitting inner boundaries in a divergence theorem for rough integrands](https://arxiv.org/abs/2506.09978)
*Thomas Ruf*

Main category: math.AP

TL;DR: The paper investigates the divergence theorem for rough vector fields on open domains, providing equivalent conditions for its validity and generalizing surface measures.


<details>
  <summary>Details</summary>
Motivation: To extend the divergence theorem to rough vector fields and domains with non-smooth boundaries, addressing discontinuities and optimal regularity.

Method: Analyzes the class of bounded vector fields with finite Radon measure divergence, proving equivalent conditions for the divergence theorem's validity.

Result: Equivalent conditions (a-d) are established, linking continuity of the divergence integral, boundary properties, and smooth approximations.

Conclusion: The work generalizes the divergence theorem for rough fields, offering a continuous surface functional and handling inner boundary discontinuities.

Abstract: The divergence theorem on an open domain $U \subset \mathbb{R}^m$ of finite
measure is investigated for the rough class $\mathcal{DM}_\infty(U)$ of bounded
vector fields $u \, \colon \, U \to \mathbb{R}^m$ with a finite Radon measure
divergence. Let $\mathcal{DB}(U)$ denote the closure of
$\mathcal{DM}_\infty(U)$ in the Lebesgue space $L_\infty(U)$. Equivalent
conditions are proved for the domain $U$ to admit the divergence theorem
\begin{equation} \exists ! \ell \in \mathcal{DB}'(U) \, \colon \, \int_U \,
\mathrm{d} \, \mathrm{div} u = \ell(u) \quad \forall u \in
\mathcal{DM}_\infty(U), \end{equation} where the functional $\ell$ generalizes
classical surface measure by being an equivalence class of finitely additive
measures concentrated on the domain boundary. Namely, the following are
equivalent to this divergence theorem: (a) the divergence integral $$
\mathcal{DM}_\infty(U) \to \mathbb{R} \, \colon \, u \mapsto \int_U \,
\mathrm{d} \, \mathrm{div} u $$ is continuous in the uniform topology, (b) the
non-exterior boundary $\partial U \setminus \mathrm{ext}_* U$ has finite
1-codimensional Hausdorff measure, where $\partial U$ is the topological
boundary, and $\mathrm{ext}_* U$ is the measure theoretic exterior, (c) the set
indicator function $\chi_U$ is a (sequential) limit from below of smooth
functions with gradient uniformly bounded in $L_1$, (d) the set $U$ is a
(sequential) limit from inside of smooth sets with uniformly bounded perimeter.
This provides an optimal regularity class of domains on which the divergence
theorem for $\mathcal{DM}_\infty$-fields holds with a surface functional that
is continuous in the uniform topology. Unlike the classical formulation, the
new formulation can take discontinuities of the integrand along 1-codimensional
inner boundaries into account.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [24] [Implicit unified gas kinetic particle method for steady-state solution of multiscale phonon transport](https://arxiv.org/abs/2506.09465)
*Hongyu Liu,Xiaojian Yang,Chuang Zhang,Xing Ji,Kun Xu*

Main category: physics.comp-ph

TL;DR: The paper introduces the IUGKP method for efficient steady-state solutions of multi-scale phonon transport, leveraging the BGK equation and particle sampling for high performance across Knudsen numbers.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of efficiently solving multi-scale phonon transport problems, particularly in varying Knudsen number regimes, where traditional methods struggle with performance and accuracy.

Method: The IUGKP method uses the BGK equation's integral solution for steady-state, sampling particles based on equilibrium states and mean free paths. It employs inexact Newton iteration for small Knudsen numbers and the null-collision concept for spatial-temporal consistency.

Result: Numerical tests show the method achieves speedups of one to two orders of magnitude, excelling in multi-scale phonon transport simulations.

Conclusion: The IUGKP method is a highly efficient and accurate tool for multi-scale non-equilibrium heat transfer, outperforming traditional methods in performance and applicability.

Abstract: This paper presents a highly efficient implicit unified gas-kinetic particle
(IUGKP) method for obtaining steady-state solutions of multi-scale phonon
transport. The method adapts and reinterprets the integral solution of the BGK
equation for time-independent solutions. The distribution function at a given
point is determined solely by the surrounding equilibrium states, where the
corresponding macroscopic quantities are computed through a weighted sum of
equilibrium distribution functions from neighboring spatial positions. From a
particle perspective, changes in macroscopic quantities within a cell result
from particle transport across cell interfaces. These particles are sampled
according to the equilibrium state of their original cells, accounting for
their mean free path as the traveling distance. The IUGKP method evolves the
solution according to the physical relaxation time scale, achieving high
efficiency in large Knudsen number regimes. To accelerate convergence for small
Knudsen numbers, an inexact Newton iteration method is implemented,
incorporating macroscopic equations for convergence acceleration in the
near-diffusive limit. The method also addresses spatial-temporal inconsistency
caused by relaxation time variations in physical space through the
null-collision concept. Numerical tests demonstrate the method's excellent
performance in accelerating multi-scale phonon transport solutions, achieving
speedups of one to two orders of magnitude. The IUGKP method proves to be an
efficient and accurate computational tool for simulating multiscale
non-equilibrium heat transfer, offering significant advantages over traditional
methods in both numerical performance and physical applicability.

</details>


### [25] [Data-Driven Performance Measures using Global Properties of Attractors for Black-Box Surrogate Models of Chaotic Systems](https://arxiv.org/abs/2506.09546)
*Luci Fumagalli,Kathy Lüdge,Jana de Wiljes,Heikki Haario,Lina Jaurigue*

Main category: physics.comp-ph

TL;DR: The paper introduces four data-driven measures to evaluate surrogate models of chaotic systems, using global attractor properties for robustness and eliminating manual fitting. It applies these measures for hypothesis testing, ranking, and hyperparameter optimization, demonstrating their utility in reservoir computing.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of evaluating surrogate models for chaotic dynamical systems without relying on manual fitting procedures, ensuring robustness against initial conditions.

Method: Proposes four measures based on empirical approximations of the correlation integral and probability density function, leveraging global attractor properties. Uses a hypothesis testing framework for systematic evaluation and ranking.

Result: The measures effectively reject poor surrogate models and serve as a ranking metric for hyperparameter optimization, improving solution quality in reservoir computing.

Conclusion: The introduced measures provide a robust, automated tool for evaluating and optimizing surrogate models in chaotic systems, with practical applications in fields like reservoir computing.

Abstract: In climate systems, physiological models, optics, and many more, surrogate
models are developed to reconstruct chaotic dynamical systems. We introduce
four data-driven measures using global attractor properties to evaluate the
quality of the reconstruction of a given surrogate time series. The measures
are robust against the initial position of the chaotic system as they are based
on empirical approximations of the correlation integral and the probability
density function, both of which are global properties of the attractor. In
contrast to previous methods, we do not need a manual fitting procedure, making
the measures straightforward to evaluate. Using a hypothesis testing framework,
we can systematically find and reject surrogate models whose reconstructions
significantly differ from the true system. Further, we show that the measures
can be used as a statistical ranking metric, which in practice allows for
hyperparameter optimization. Applying our measures to reservoir computing with
a low number of nodes, we demonstrate how the measures can be used to reject
poor reconstructions and use them as a tool to find an optimal spectral radius
for which considerably fewer solutions are rejected and the overall quality of
the solution improves.

</details>


### [26] [Optimization of Sound Energy Reduction in the Polycarbonate Plate Reinforced with Carbon Nanotubes](https://arxiv.org/abs/2506.09619)
*Parinus Vedadi,Edris Faizabadi*

Main category: physics.comp-ph

TL;DR: Study shows carbon nanotubes in polycarbonate plates improve sound insulation at low frequencies by increasing reflection and reducing wave pressure.


<details>
  <summary>Details</summary>
Motivation: To develop a new method for reinforcing sound insulation materials, focusing on carbon nanotubes' impact on polycarbonate plates.

Method: Numerical methods (FEM and FDTDM) were used to analyze the effect of carbon nanotubes on polycarbonate plates.

Result: Carbon nanotubes increased acoustic wave reflection and reduced wave pressure at frequencies below 1000 Hz, enhancing sound insulation.

Conclusion: Reinforced polycarbonate plates with carbon nanotubes are effective for low-frequency sound absorption and reflection, suitable for sound barriers.

Abstract: In order to develop a new method for sound insulation materials
reinforcement, in this study, the effect of carbon nanotubes on polycarbonate
plates as a sample of materials used in acoustic insulators, have been
investigated via numerical methods including finite element method (FEM) and
finite difference time domain method (FDTDM). It was observed that the addition
of carbon nanotubes to the polycarbonate material at frequencies below 1000 Hz
increased the reflection of the acoustic wave from the surface of the
polycarbonate plate and also decreased the amplitude of the acoustic wave
pressure within the material. Therefore, it can be concluded that the
reinforcement of polycarbonate plates by carbon nanotubes can reduce the
intensity and help absorption of acoustic energy in the plate, and as a result,
reduce the transmitted acoustic energy through the plate at low frequencies.
Thereupon, these reinforced polycarbonate plates can be used in situations
where a sound-absorbing material is needed next to the reflector material in
the sound barriers.

</details>


### [27] [Choosing a Suitable Acquisition Function for Batch Bayesian Optimization: Comparison of Serial and Monte Carlo Approaches](https://arxiv.org/abs/2506.09894)
*Imon Mia,Mark Lee,Weijie Xu,William Vandenberghe,Julia W. P. Hsu*

Main category: physics.comp-ph

TL;DR: The paper compares serial and Monte Carlo batch acquisition functions in Bayesian optimization for expensive experiments, finding qUCB optimal for noiseless and noisy conditions in ≤6 dimensions.


<details>
  <summary>Details</summary>
Motivation: To guide the choice of batch acquisition functions in Bayesian optimization when little is known about the 'black-box' function landscape.

Method: Comparison of UCB/LP, qlogEI, and qUCB on Ackley and Hartmann functions, and empirical validation on perovskite solar cell data.

Result: UCB/LP and qUCB excel in noiseless conditions; qUCB performs best in noisy scenarios. qUCB is recommended for ≤6 dimensions.

Conclusion: qUCB is the default choice for optimizing 'black-box' functions in ≤6 dimensions due to robustness and efficiency.

Abstract: Batch Bayesian optimization is widely used for optimizing expensive
experimental processes when several samples can be tested together to save time
or cost. A central decision in designing a Bayesian optimization campaign to
guide experiments is the choice of a batch acquisition function when little or
nothing is known about the landscape of the "black box" function to be
optimized. To inform this decision, we first compare the performance of serial
and Monte Carlo batch acquisition functions on two mathematical functions that
serve as proxies for typical materials synthesis and processing experiments.
The two functions, both in six dimensions, are the Ackley function, which
epitomizes a "needle-in-haystack" search, and the Hartmann function, which
exemplifies a "false optimum" problem. Our study evaluates the serial upper
confidence bound with local penalization (UCB/LP) batch acquisition policy
against Monte Carlo-based parallel approaches: q-log expected improvement
(qlogEI) and q-upper confidence bound (qUCB), where q is the batch size. Tests
on Ackley and Hartmann show that UCB/LP and qUCB perform well in noiseless
conditions, both outperforming qlogEI. For the Hartmann function with noise,
all Monte Carlo functions achieve faster convergence with less sensitivity to
initial conditions compared to UCB/LP. We then confirm the findings on an
empirical regression model built from experimental data in maximizing power
conversion efficiency of flexible perovskite solar cells. Our results suggest
that when empirically optimizing a "black-box" function in less than or equal
to six dimensions with no prior knowledge of the landscape or noise
characteristics, qUCB is best suited as the default to maximize confidence in
the modeled optimum while minimizing the number of expensive samples needed.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [28] [Excitation of whistler and slow-X waves by runaway electrons in a collisional plasma](https://arxiv.org/abs/2506.09233)
*Qile Zhang,Yanzeng Zhang,Xian-Zhu Tang*

Main category: physics.plasm-ph

TL;DR: The paper investigates the excitation of slow-X and whistler modes in runaway electron-driven plasma instabilities, finding slow-X modes dominate in growth rates and excitation timing.


<details>
  <summary>Details</summary>
Motivation: To understand the competition between collisional damping and collisionless drive in plasma wave instabilities, particularly focusing on slow-X and whistler modes in runaway electron scenarios.

Method: Uses relativistic Fokker-Planck-Boltzmann solver to compute runaway avalanche distributions, followed by linear dispersion analysis to identify unstable modes under varying plasma conditions.

Result: Slow-X modes are excited earlier and exhibit higher growth rates than whistler modes, even when both are unstable.

Conclusion: Slow-X modes should be prioritized in future research and experiments, despite historical focus on whistler modes.

Abstract: Runaway electrons are known to provide robust ideal or collisionless
  kinetic drive for plasma wave instabilities in both the whistler and
  slow-X branches, via the anomalous Doppler-shifted cyclotron
  resonances. In a cold and dense post-thermal-quench plasma,
  collisional damping of the plasma waves can be competitive with the
  collisionless drive. Previous studies have found that for its higher
  wavelength and frequency, slow-X waves suffer stronger collisional
  damping than the whistlers, while the ideal growth rate of slow-X
  modes is higher. Here we study runaway avalanche distributions that maintain
the same eigen distribution and increase only in magnitude over time. The
distributions are computed from the
  relativistic Fokker-Planck-Boltzmann solver, upon which a linear
  dispersion analysis is performed to search for the most unstable or
  least damped slow-X and whistler modes. Taking into account the
  effect of plasma density, plasma temperature, and effective charge
  number, we find that the slow-X modes tend to be excited before the
  whistlers in a runaway current ramp-up. Furthermore, even when the
  runaway current density is sufficiently high that both branches are
  excited, the most unstable slow-X mode has much higher growth rate
  than the most unstable whistler mode. The qualitative and
  quantitative trends uncovered in current study indicate that even
  though past experiments and modeling efforts have concentrated on whistler
modes, there's a compelling case that slow-X modes should also be a key area of
focus.

</details>


### [29] [Impact of model uncertainty on SPARC operating scenario predictions with empirical modeling](https://arxiv.org/abs/2506.09879)
*A. Saltzman,P. Rodriguez-Fernandez,T. Body,A. Ho,N. T. Howard*

Main category: physics.plasm-ph

TL;DR: The paper introduces statistical POPCONs using Monte Carlo analysis to address uncertainties in tokamak design, optimizing SPARC's operating points for robust performance.


<details>
  <summary>Details</summary>
Motivation: Traditional POPCON analyses neglect uncertainties in scaling laws, plasma profiles, and impurity concentrations, which can significantly impact performance predictions.

Method: Statistical POPCONs with Monte Carlo analysis, a gradient-based functional form for profiles, and multi-fidelity Bayesian optimization to efficiently identify optimal operating points.

Result: Accounting for uncertainties reveals an optimal operating point differing from deterministic predictions, balancing H-mode access, confinement, impurity dilution, and auxiliary power.

Conclusion: The proposed method improves robustness in tokamak design by systematically addressing uncertainties, leading to more reliable performance predictions.

Abstract: Understanding and accounting for uncertainty helps to ensure next-step
tokamaks such as SPARC will robustly achieve their goals. While traditional
Plasma OPerating CONtour (POPCON) analyses guide design, they often overlook
the significant impact of uncertainties in scaling laws, plasma profiles, and
impurity concentrations on performance predictions. This work confronts these
challenges by introducing statistical POPCONs, which leverage Monte Carlo
analysis to quantify the sensitivity of SPARC's operating points [1] to these
crucial variables. For profiles, a physically motivated gradient-based
functional form is introduced. We further develop a multi-fidelity Bayesian
optimization workflow that effectively identifies operating points maximizing
the probability of meeting performance goals, which gives a significant
speed-up over brute force methods. Our findings reveal that accounting for
these uncertainties leads to an optimal operating point different from
deterministic predictions, which balances H-mode access, confinement, impurity
dilution, and auxiliary power.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [30] [Scale-invariant dynamics in a purely deterministic Game of Life model](https://arxiv.org/abs/2411.07189)
*Hakan Akgun,Xianquan Yan,Tamer Taskiran,Muhamet Ibrahimi,Ching Hua Lee,Seymur Jahangirov*

Main category: cond-mat.stat-mech

TL;DR: The paper demonstrates scale-invariant critical dynamics in deterministic systems using an extended Game of Life model, identifying distinct phases and critical points with unconventional exponents.


<details>
  <summary>Details</summary>
Motivation: To explore whether scale-invariant dynamics can emerge from purely deterministic interactions, challenging the need for randomness or tunable stochasticity.

Method: The study uses an extended deterministic version of Conway's Game of Life (logistic GOL) with a Cantor set state space, analyzing equal-state clusters for critical behavior.

Result: Three asymptotic phases separated by two critical points were found, with power-law distributions of cluster sizes and unconventional critical exponents.

Conclusion: The work provides evidence of emergent scale invariance in deterministic systems, advancing the study of criticality beyond stochastic paradigms.

Abstract: Scale invariance is a key feature that characterizes criticality in complex
dynamical systems, which often organize into structures exhibiting no typical
size and/or lifespan. While random external inputs or tunable stochastic
interactions are typically required for showcasing such criticality, the
question of whether scale-invariant dynamics can emerge from purely
deterministic interactions remains unclear. In this work, we discover highly
affirmative signatures of critical dynamics in equal-state clusters that emerge
in the \textit{logistic} Game of life (GOL): an extension of Conway's GOL into
a Cantor set state space that is nevertheless deterministic. We uncover at
least three types of asymptotic behavior, i.e. phases, that are separated by
two fundamentally distinct critical points. The first critical point --
associated with a peculiar form of self-organized criticality -- defines the
non-analytic boundary between a sparse-static and a sparse-dynamic asymptotic
phase. Meanwhile, the second point marks an enigmatic deterministic percolation
transition between the sparse-dynamic and a third, dense-dynamic phase.
Moreover, we identify distinct power-law distributions of cluster sizes with
unconventional critical exponents that challenge the current paradigms for
critical behavior. Overall, our work concretely paves the way for studying
emergent scale invariance in purely deterministic systems.

</details>


<div id='math.SP'></div>

# math.SP [[Back]](#toc)

### [31] [Maximizing higher eigenvalues in dimensions three and above](https://arxiv.org/abs/2506.09328)
*Denis Vinokurov*

Main category: math.SP

TL;DR: The paper studies maximizing the $k$-th eigenvalue functional on Riemannian manifolds, showing smooth harmonic maps work for dimensions 3-6, while singularities appear for $m \geq 7$, with $m-7$ as the optimal bound for singular set dimension.


<details>
  <summary>Details</summary>
Motivation: To extend eigenvalue maximization results to higher dimensions and understand the role of harmonic maps and their singularities.

Method: Generalizes prior work on the first eigenvalue, using harmonic maps into spheres and analyzing singular sets for higher dimensions.

Result: For $3 \leq m \leq 6$, smooth harmonic maps maximize; for $m \geq 7$, singular harmonic maps do, with singular set dimension up to $m-7$.

Conclusion: The study provides a complete picture of eigenvalue maximization via harmonic maps, including singularities for higher dimensions.

Abstract: We study the problem of maximizing the $k$-th eigenvalue functional over the
class of absolutely continuous measures on a closed Riemannian manifold of
dimension $m\geq 3$.
  For dimensions $3 \leq m \leq 6$, we generalize the work of Karpukhin and
Stern on the first eigenvalue, showing that the maximizing measures are
realized by smooth harmonic maps into finite-dimensional spheres.
  For $m \geq 7$, the maximizing measures are again induced by harmonic maps,
which may now exhibit singularities. We prove that $m-7$ is the optimal upper
bound for the Hausdorff dimension of the singular set. More precisely, for any
$m \geq 7$, there exist maximizing harmonic maps on the $m$-dimensional sphere
whose singular sets have any prescribed integer dimension up to $m - 7$.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [32] [$C^{1,α}$-regularity for Schrödinger potentials of Shannon-entropy regularized Optimal Transport](https://arxiv.org/abs/2506.09302)
*Sumiya Baasandorj,Simone Di Marino,Augusto Gerolin*

Main category: math.OC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We provide the stability of $C^{1,\alpha}$ regularity of Schr\"odinger
potentials of Boltzmann-Shannon entropy regularized Optimal Transport under the
classical assumption of marginals supported on bounded convex sets and whose
densities are bounded above and below.

</details>


### [33] [Balanced quasistatic evolutions of critical points in metric spaces](https://arxiv.org/abs/2506.09812)
*Stefano Almi,Massimo Fornasier,Jona Klemenc,Alessandro Scagliotti*

Main category: math.OC

TL;DR: The paper introduces a novel approach to modeling quasistatic evolutions of critical points for time-dependent energies, decoupling time scales of energy evolution and equilibria transitions.


<details>
  <summary>Details</summary>
Motivation: Traditional methods rely on vanishing viscosity and inertia limits, which are limited to Euclidean spaces and non-degenerate critical points. This work seeks a more general and computationally feasible alternative.

Method: The approach alternates between evolving the energy while freezing the system state and updating the state while freezing the energy, using gradient flow or approximations like minimizing movement.

Result: The method is simpler, more general, and computationally implementable, avoiding the need for non-degenerate critical points and extending to locally compact metric spaces.

Conclusion: This approach aligns with physical principles, offers computational advantages, and broadens applicability beyond previous formulations.

Abstract: Quasistatic evolutions of critical points of time-dependent energies exhibit
piecewise smooth behavior, making them useful for modeling continuum mechanics
phenomena like elastic-plasticity and fracture. Traditionally, such evolutions
have been derived as vanishing viscosity and inertia limits, leading to
balanced viscosity solutions. However, for nonconvex energies, these
constructions have been realized in Euclidean spaces and assume non-degenerate
critical points. In this paper, we take a different approach by decoupling the
time scales of the energy evolution and of the transition to equilibria.
Namely, starting from an equilibrium configuration, we let the energy evolve,
while keeping frozen the system state; then, we update the state by freezing
the energy, while letting the system transit via gradient flow or an
approximation of it (e.g., minimizing movement or backward differentiation
schemes). This approach has several advantages. It aligns with the physical
principle that systems transit through energy-minimizing steady states. It is
also fully constructive and computationally implementable, with physical and
computational costs governed by appropriate action functionals. Additionally,
our analysis is simpler and more general than previous formulations in the
literature, as it does not require non-degenerate critical points. Finally,
this approach extends to evolutions in locally compact metric path spaces, and
our axiomatic presentation allows for various realizations.

</details>


### [34] [A thorough study of Riemannian Newton's Method](https://arxiv.org/abs/2506.09297)
*Caio O. da Silva,Yuri A. Aoto,Felipe F. G. S. Costa,Márcio F. da Silva*

Main category: math.OC

TL;DR: The paper compares Riemannian Newton's Method (RNM) with its Euclidean counterpart for optimization on Grassmannian and Stiefel manifolds, focusing on the Hartree-Fock problem. RNM shows superior convergence, fewer iterations, and robustness. A modified RNM ignoring small Hessian eigenvalues is also stable and effective.


<details>
  <summary>Details</summary>
Motivation: The study aims to evaluate the performance of RNM for optimization on manifolds, particularly for the Hartree-Fock energy minimization, and address numerical issues in quotient manifolds.

Method: The paper applies RNM and Euclidean Newton's Method to the Hartree-Fock problem, testing on 125 molecules. It also introduces a modified RNM ignoring small Hessian eigenvalues.

Result: RNM outperforms the Euclidean method with higher convergence rates, fewer iterations, and better robustness. The modified RNM is stable and performs comparably to RNM on quotient manifolds.

Conclusion: RNM is more effective for manifold optimization, and the modified RNM offers a stable alternative for quotient manifolds.

Abstract: This work presents a thorough numerical study of Riemannian Newton's Method
(RNM) for optimization problems, with a focus on the Grassmannian and on the
Stiefel manifold. We compare the Riemannian formulation of Newton's Method with
its classical Euclidean counterpart based on Lagrange multipliers by applying
both approaches to the important and challenging Hartree--Fock energy
minimization problem from Quantum Chemistry. Experiments on a dataset of 125
molecules show that the Riemannian approaches achieve higher convergence rates,
require fewer iterations, and exhibit greater robustness to the choice of
initial guess. In this work we also analyze the numerical issues that arise
from using Newton's Method on the total manifold when the cost function is
defined on the quotient manifold. We investigate the performance of a modified
RNM in which we ignore the small eigenvalues of the Hessian and the results
indicate that this modified method is stable and performs on par with the RNM
on the quotient manifold.

</details>


### [35] [Non-Euclidean dual gradient ascent for entropically regularized linear and semidefinite programming](https://arxiv.org/abs/2506.09711)
*Yuhang Cai,Michael Lindsey*

Main category: math.OC

TL;DR: An optimization framework for semidefinite programs (SDPs) achieves dimension-independent convergence using entropy regularization and dual gradient ascent.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of dimension-dependent convergence in SDPs, the framework aims to provide efficient, scalable solutions.

Method: The approach regularizes the primal problem with von Neumann entropy, solves it via dual gradient ascent with a problem-adapted norm, and uses stochastic gradients for scalability.

Result: The method achieves dimension-independent convergence, constructs primal-feasible solutions in special cases, and derives explicit convergence rates.

Conclusion: The framework is validated on practical problems like Max-Cut and optimal transport, demonstrating its effectiveness and generality.

Abstract: We present an optimization framework that exhibits dimension-independent
convergence on a broad class of semidefinite programs (SDPs). Our approach
first regularizes the primal problem with the von Neumann entropy, then solve
the regularized problem using dual gradient ascent with respect to a
problem-adapted norm. In particular, we show that the dual gradient norm
converges to zero at a rate independent of the ambient dimension and, via
rounding arguments, construct primal-feasible solutions in certain special
cases. We also derive explicit convergence rates for the objective. In order to
achieve optimal computational scaling, we must accommodate the use of
stochastic gradients constructed via randomized trace estimators. Throughout we
illustrate the generality of our framework via three important special cases --
the Goemans-Williamson SDP relaxation of the Max-Cut problem, the optimal
transport linear program, and several SDP relaxations of the permutation
synchronization problem. Numerical experiments confirm that our methods achieve
dimension-independent convergence in practice.

</details>


### [36] [The Intrinsic Riemannian Proximal Gradient Method for Nonconvex Optimization](https://arxiv.org/abs/2506.09775)
*Ronny Bergmann,Hajg Jasa,Paula John,Max Pfeffer*

Main category: math.OC

TL;DR: The paper introduces an intrinsic proximal gradient method on Riemannian manifolds for non-geodesically convex functions, avoiding embedding and demonstrating convergence and performance for nonconvex problems.


<details>
  <summary>Details</summary>
Motivation: To address optimization on Riemannian manifolds for nonconvex functions without relying on embedding, which is a limitation of existing methods.

Method: An intrinsic proximal gradient method using proximal maps defined on the manifold, derived from forward-backward-splitting.

Result: The method shows convergence and performs well numerically, especially for nonconvex or nonembedded problems.

Conclusion: The proposed method effectively handles nonconvex optimization on Riemannian manifolds without embedding, outperforming other methods for such cases.

Abstract: We consider the proximal gradient method on Riemannian manifolds for
functions that are possibly not geodesically convex. Starting from the
forward-backward-splitting, we define an intrinsic variant of the proximal
gradient method that uses proximal maps defined on the manifold and therefore
does not require or work in the embedding. We investigate its convergence
properties and illustrate its numerical performance, particularly for nonconvex
or nonembedded problems that are hence out of reach for other methods.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [37] [SDEs with critical general distributional drifts: sharp solvability and blow ups](https://arxiv.org/abs/2506.09244)
*D. Kinzebulatov,R. Vafadar*

Main category: math.PR

TL;DR: The paper establishes weak well-posedness for SDEs with discontinuous diffusion coefficients and general distributional drifts, applying results to particle systems and improving bounds in the many-particle Hardy inequality.


<details>
  <summary>Details</summary>
Motivation: To address SDEs with discontinuous diffusion and distributional drifts, which are common in systems like turbulent flows and Keller-Segel particle models, and to extend the understanding of their well-posedness.

Method: The authors assume minimal conditions on drifts, leveraging the well-posedness of the Kolmogorov backward equation in a Hilbert triple and results from Mazya and Verbitsky to represent drifts as form-bounded and divergence-free components.

Result: Weak well-posedness is proven for the SDEs, and applications to particle systems with strong interactions are covered, including nearly the entire range of attraction strengths in dimensions ≥3. An improved upper bound for the many-particle Hardy inequality is also derived.

Conclusion: The results extend the understanding of SDEs with discontinuous and distributional drifts, with practical implications for particle systems and inequalities, demonstrating near-optimal bounds in certain cases.

Abstract: We establish weak well-posedness for SDEs having discontinuous diffusion
coefficients and general distributional drifts that may introduce blow up
effects. Our drifts satisfy minimal assumptions, i.e.\,we assume only that the
Cauchy problem for the Kolmogorov backward equation is well-posed in the
standard Hilbert triple $W^{1,2} \hookrightarrow L^2 \hookrightarrow W^{-1,2}$.
By a result of Mazya and Verbitsky, these assumptions are precisely those
drifts that can be represented as the sum of a form-bounded component
(encompassing, for example, Morrey or Chang-Wilson-Wolff drifts) and a
divergence-free distributional component in the ${\rm BMO}^{-1}$ space of Koch
and Tataru.
  We apply our results to finite particle systems with strong attracting
interactions immersed in a turbulent flow. This includes particle systems of
Keller-Segel type. Crucially, in dimensions $d \geq 3$, we cover almost the
entire admissible range of attraction strengths, reaching nearly to the blow-up
threshold.
  As a further application of our results for SDEs and of the theory of Bessel
processes, we obtain an improved upper bound on the constant in the
many-particle Hardy inequality. Consequently, the lower bound previously
derived by Hoffmann-Ostenhof, Hoffmann-Ostenhof, Laptev, and Tidblom is shown
to be close to optimal.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [38] [TTrace: Lightweight Error Checking and Diagnosis for Distributed Training](https://arxiv.org/abs/2506.09280)
*Haitian Jiang,Shaowei Zhu,Zhen Zhang,Zhenyu Song,Xinwei Fu,Zhen Jia,Yida Wang,Jinyang Li*

Main category: cs.DC

TL;DR: TTrace is a system designed to detect and localize silent bugs in distributed training by comparing intermediate tensors against a trusted reference, using novel mathematical analysis for accurate thresholding.


<details>
  <summary>Details</summary>
Motivation: Distributed training for large models like LLMs is prone to silent bugs, which are hard to detect using traditional metrics. Existing methods are inefficient, especially in low-precision training.

Method: TTrace collects and compares intermediate tensors from distributed training with a single-device reference. It uses mathematical analysis to set thresholds for distinguishing bugs from floating-point errors.

Result: TTrace detected 11 existing and 3 new bugs in Megatron-LM with minimal code changes and worked effectively in low-precision training (BF16, FP8).

Conclusion: TTrace is an effective solution for detecting silent bugs in distributed training, offering practical benefits with low overhead.

Abstract: Distributed training is essential for scaling the training of large neural
network models, such as large language models (LLMs), across thousands of GPUs.
However, the complexity of distributed training programs makes them
particularly prone to silent bugs, which do not produce explicit error signal
but lead to incorrect training outcome. Effectively detecting and localizing
such silent bugs in distributed training is challenging. Common debugging
practice using metrics like training loss or gradient norm curves can be
inefficient and ineffective. Additionally, obtaining intermediate tensor values
and determining whether they are correct during silent bug localization is
difficult, particularly in the context of low-precision training.
  To address those challenges, we design and implement TTrace, the first system
capable of detecting and localizing silent bugs in distributed training. TTrace
collects intermediate tensors from distributing training in a fine-grained
manner and compares them against those from a trusted single-device reference
implementation. To properly compare the floating-point values in the tensors,
we propose novel mathematical analysis that provides a guideline for setting
thresholds, enabling TTrace to distinguish bug-induced errors from
floating-point round-off errors. Experimental results demonstrate that TTrace
effectively detects 11 existing bugs and 3 new bugs in the widely used
Megatron-LM framework, while requiring fewer than 10 lines of code change.
TTrace is effective in various training recipes, including low-precision
recipes involving BF16 and FP8.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [39] [Quantum block Krylov subspace projector algorithm for computing low-lying eigenenergies](https://arxiv.org/abs/2506.09971)
*Maria Gabriela Jordão Oliveira,Nina Glaser*

Main category: quant-ph

TL;DR: The paper introduces QBKSP, a quantum algorithm for efficiently computing low-lying eigenvalues, including degenerate states, using compact quantum circuits. Simulations show improved convergence with multiple reference states.


<details>
  <summary>Details</summary>
Motivation: Eigenvalue computation is computationally expensive but vital for natural sciences. QBKSP addresses this by leveraging quantum computing for efficiency and accuracy.

Method: QBKSP, a quantum variant of Lanczos, uses three compact quantum circuits for expectation values. Simulations test reference states, fidelity, and time evolution impact.

Result: Multiple reference states enhance convergence, especially in precision-limited settings. QBKSP also computes degenerate eigenstates and their multiplicity.

Conclusion: QBKSP is a promising quantum algorithm for eigenvalue problems, offering improved accuracy and efficiency, particularly for degenerate states.

Abstract: Determining eigenvalues is a computationally expensive task that is crucial
for countless applications in natural sciences. Toward this end, we introduce
the quantum block Krylov subspace projector (QBKSP) algorithm, a multireference
quantum variant of the Lanczos algorithm designed to accurately compute
low-lying eigenvalues, including degenerate states. We present three different
compact quantum circuits to evaluate the required expectation values, each
suited to different problem settings. To investigate the impact of the number
and fidelity of the initial reference states, as well as time evolution
duration, we perform error-free and limited-precision numerical simulations and
quantum circuit simulations. The results demonstrate that using multiple
initial reference states improves the convergence of the algorithm, especially
in realistic precision-limited simulations and in cases where a single
reference fails to simultaneously retrieve all desired eigenvalues.
Furthermore, the QBKSP algorithm enables the computation of degenerate
eigenstates and respective multiplicity by imposing appropriate convergence
criteria.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [40] [Accelerating Resonant Spectroscopy Simulations Using Multi-Shifted Bi-Conjugate Gradient](https://arxiv.org/abs/2506.09551)
*Prakash Sharma,Luogen Xu,Fei Xue,Yao Wang*

Main category: cond-mat.str-el

TL;DR: A new algorithm reduces computational complexity for simulating resonant spectroscopies in quantum materials, achieving constant complexity and maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: Theoretical understanding of resonant spectroscopies is limited by numerical challenges in solving Kramers-Heisenberg-type response functions for large systems.

Method: A multi-shifted biconjugate gradient algorithm is introduced, leveraging shared Krylov subspaces across spectra to reduce computational complexity.

Result: The algorithm significantly speeds up spectral simulations with constant complexity, independent of incident energies, while ensuring accuracy.

Conclusion: This scalable framework enables efficient simulation of advanced spectroscopies in quantum materials.

Abstract: Resonant spectroscopies, which involve intermediate states with finite
lifetimes, provide essential insights into collective excitations in quantum
materials that are otherwise inaccessible. However, theoretical understanding
in this area is often limited by the numerical challenges of solving
Kramers-Heisenberg-type response functions for large-scale systems. To address
this, we introduce a multi-shifted biconjugate gradient algorithm that exploits
the shared structure of Krylov subspaces across spectra with varying incident
energies, effectively reducing the computational complexity to that of linear
spectroscopies. Both mathematical proofs and numerical benchmarks confirm that
this algorithm substantially accelerates spectral simulations, achieving
constant complexity independent of the number of incident energies, while
ensuring accuracy and stability. This development provides a scalable,
versatile framework for simulating advanced spectroscopies in quantum
materials.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [41] [Surrogate models to optimize plasma assisted atomic layer deposition in high aspect ratio features](https://arxiv.org/abs/2506.09313)
*Angel Yanguas-Gil,Jeffrey W. Elam*

Main category: cond-mat.mtrl-sci

TL;DR: Machine learning surrogate models predict PEALD saturation times and surface recombination dominance with high accuracy, reducing experimental needs.


<details>
  <summary>Details</summary>
Motivation: Surface recombination in plasma-based processes like PEALD can lead to impractical exposure times for conformality in nanostructures.

Method: Artificial neural networks trained on synthetic PEALD simulation data predict saturation times and surface recombination dominance.

Result: Two undersaturated experiments predict saturation times within 10% error; surrogate model achieves 99% accuracy for recombination dominance.

Conclusion: Machine learning accelerates PEALD optimization, applicable to atomic layer etching and complex structures.

Abstract: In this work we explore surrogate models to optimize plasma enhanced atomic
layer deposition (PEALD) in high aspect ratio features. In plasma-based
processes such as PEALD and atomic layer etching, surface recombination can
dominate the reactivity of plasma species with the surface, which can lead to
unfeasibly long exposure times to achieve full conformality inside
nanostructures like high aspect ratio vias. Using a synthetic dataset based on
simulations of PEALD, we train artificial neural networks to predict saturation
times based on cross section thickness data obtained for partially coated
conditions. The results obtained show that just two experiments in
undersaturated conditions contain enough information to predict saturation
times within 10% of the ground truth. A surrogate model trained to determine
whether surface recombination dominates the plasma-surface interactions in a
PEALD process achieves 99% accuracy. This demonstrates that machine learning
can provide a new pathway to accelerate the optimization of PEALD processes in
areas such as microelectronics. Our approach can be easily extended to atomic
layer etching and more complex structures.

</details>


### [42] [Aluminum oxide coatings on Co-rich cathodes and interactions with organic electrolyte](https://arxiv.org/abs/2506.09252)
*M. D. Hashan C. Peiris,Michael Woodcox,Diana Liepinya,Robert Shephard,Hao Liu,Manuel Smeu*

Main category: cond-mat.mtrl-sci

TL;DR: Alumina coatings on LiCoO2 cathodes improve LIB durability by reducing electrolyte degradation and stabilizing the cathode-electrolyte interface, as shown through AIMD simulations.


<details>
  <summary>Details</summary>
Motivation: To address degradation issues like capacity fading and unstable interfaces in LIB cathodes, alumina coatings are explored for their protective benefits.

Method: Ab initio molecular dynamics (AIMD) simulations analyze LiCoO2 cathodes with/without alumina coatings, focusing on electrolyte interactions, decomposition, and mechanical robustness.

Result: Alumina coatings reduce electrolyte degradation, stabilize the cathode structure, and enhance mechanical strength, especially under high-charge states.

Conclusion: Optimizing alumina coating thickness and orientation can lead to more durable LIBs with higher energy densities and longer cycle life.

Abstract: Lithium-ion batteries (LIBs) have become essential in modern energy storage;
however, their performance is often limited by the stability and efficiency of
their components, particularly the cathode and electrolyte. Transition metal
layered oxide cathodes, a popular choice for lithium-ion batteries (LIBs),
suffer from several degradation mechanisms, including capacity fading,
reactions with the electrolyte, unstable cathode-electrolyte interfaces, and
lattice breakdown during cycling. In recent years, oxide coating, such as
alumina, has emerged as a promising strategy to enhance the durability of
cathodes by forming a protective layer that mitigates detrimental reactions and
improves the stability of the cathode electrolyte interphase (CEI). This study
employs ab initio molecular dynamics (AIMD) simulations to investigate the
chemical and mechanical behavior of LiCoO2 cathodes with and without aluminum
oxide coatings in contact with an organic electrolyte. We examine the
interactions between electrolyte molecules with both bare and coated cathode
surfaces, focusing on the decomposition of ethylene carbonate (EC) and dimethyl
carbonate (DMC), the formation of oxygen species, and solvation dynamics, and
evaluate the mechanical robustness of the cathode-coating interface using
calculations of axial strain and cleavage energy. Our findings reveal that
alumina coatings effectively reduce electrolyte degradation and stabilize the
cathode structure, particularly under high-charge states. The coating's
thickness and structural orientation are crucial in enhancing mechanical
strength and minimizing detrimental reactions at the cathode-electrolyte
interface. These insights contribute to the development of more durable LIBs by
optimizing the interface chemistry and mechanical properties, providing a
pathway toward higher energy densities and longer cycle life.

</details>


### [43] [Engineering topological phase transitions via sliding ferroelectricity in MBi2Te4 (M = Ge, Sn, Pb) bilayers](https://arxiv.org/abs/2506.09317)
*Xinlong Dong,Dan Qiao,Zeyu Li,Zhenhua Qiao,Xiaohong Xu*

Main category: cond-mat.mtrl-sci

TL;DR: The paper explores ferroelectricity and topological states in bilayer MBi2Te4 (M = Ge, Sn, Pb), showing reversible topological phase transitions via interlayer sliding and room-temperature quantum spin Hall effect.


<details>
  <summary>Details</summary>
Motivation: To advance quantum phenomena and device innovation by combining switchable ferroelectricity and tunable topological states.

Method: First-principles calculations to study sliding ferroelectricity-mediated topological transitions in MBi2Te4 bilayers.

Result: Demonstrated reversible band inversion, substantial ferroelectric polarization (0.571-0.623 pC/m), and room-temperature quantum spin Hall effect.

Conclusion: MBi2Te4 bilayers enable co-engineering of ferroelectric switching and topological conduction, offering a material paradigm for reconfigurable quantum devices.

Abstract: Materials combining electrically switchable ferroelectricity and tunable
topological states hold significant promise for advancing both foundamental
quantum phenomena and innovative device architectures. Here, we employ
first-principles calculations to systematically investigate the sliding
ferroelectricity-mediated topological transitions in bilayer MBi2Te4 (M = Ge,
Sn, Pb). By strategically engineering interlayer sliding configurations with
oppositely polarized states, we demonstrate reversible band inversion
accompanied by topological phase transitions. The calculated spin-orbit-coupled
bandgaps reach 31 meV (GeBi2Te4), 36 meV (SnBi2Te4), and 35 meV (PbBi2Te4),
thereby enabling room-temperature observation of the quantum spin Hall effect.
Crucially, these systems exhibit substantial out-of-plane ferroelectric
polarization magnitudes of 0.571-0.623 pC/m, with PbBi2Te4 showing the maximum
polarization (0.623 pC/m). The topological nontriviality is unambiguously
confirmed by two independent signatures: (i) the computed z2 topological
invariant, and (ii) the emergence of gapless helical edge states spanning the
bulk insulating gap. This synergy arises from the unique sliding-induced charge
redistribution mechanism, which simultaneously modulates Berry curvature and
breaks in-plane inversion symmetry without disrupting out-of-plane polarization
stability. The co-engineering of non-volatile ferroelectric switching and
topologically protected conduction channels in MBi2Te4 bilayers establishes a
material paradigm for designing reconfigurable quantum devices, where
electronic topology can be electrically controlled via polarization reversal.
Our results provide critical insights into manipulating correlated quantum
states in van der Waals ferroelectrics for multifunctional nanoelectronics.

</details>


### [44] [Molecular Dynamics Simulations of SrTiO$_3$ with Oxygen Vacancies using Neural Network Potentials](https://arxiv.org/abs/2506.09372)
*Kazutaka Nishiguchi,Ryota Yamamoto,Meguru Yamazaki,Naoki Matsumura,Yuta Yoshimoto,Seiichiro L. Ten-no,Yasufumi Sakai*

Main category: cond-mat.mtrl-sci

TL;DR: The paper demonstrates the use of neural network potentials (NNP) for accurate and efficient molecular dynamics (MD) simulations of point defects in SrTiO$_3$, showing good agreement with DFT results.


<details>
  <summary>Details</summary>
Motivation: Traditional ab initio MD simulations are computationally expensive, while classical MD lacks accuracy. The study aims to bridge this gap using NNP models.

Method: NNP-MD simulations are performed on pristine SrTiO$_3$ and SrTiO$_3$ with oxygen vacancies (V$_{\text{O}}$), comparing results with DFT calculations.

Result: NNP models accurately predict total and formation energies, even for larger supercells, matching extrapolated DFT values.

Conclusion: The study provides insights for developing accurate NNP models for point-defect systems like SrTiO$_3$:V$_{\text{O}}$.

Abstract: A precise analysis of point defects in solids requires accurate molecular
dynamics (MD) simulations of large-scale systems. However, ab initio MD
simulations based on density functional theory (DFT) incur high computational
cost, while classical MD simulations lack accuracy. We perform MD simulations
using a neural network potential (NNP) model (NNP-MD) to predict the physical
quantities of both pristine SrTiO$_3$ and SrTiO$_3$ in the presence of oxygen
vacancies (V$_{\text{O}}$). To verify the accuracy of the NNP models trained on
different data sets, their NNP-MD predictions are compared with the results
obtained from DFT calculations. The predictions of the total energy show good
agreement with the DFT results for all these NNP models, and the NNP models can
also predict the formation energy once SrTiO$_3$:V$_{\text{O}}$ data are
included in the training data sets. Even for larger supercell sizes that are
difficult to calculate using first-principles calculations, the formation
energies evaluated from the NNP-MD simulations well reproduce the extrapolated
DFT values. This study offer important knowledge for constructing accurate NNP
models to describe point-defect systems including SrTiO$_3$:V$_{\text{O}}$.

</details>


### [45] [Ferroelectric control of bipolar magnetic semiconductor with room Curie temperature](https://arxiv.org/abs/2506.09412)
*Jia-Wen Li,Gang Su,Bo Gu*

Main category: cond-mat.mtrl-sci

TL;DR: Proposal of 2D magnetic semiconductors with room-temperature tunability, featuring Cr2NiSe4 as a ferromagnetic bipolar magnetic semiconductor (BMS) with a 352 K Curie temperature and nonvolatile spin polarization control via ferroelectric substrates.


<details>
  <summary>Details</summary>
Motivation: Advancing low-power, high-performance information technologies by developing room-temperature tunable magnetic semiconductors.

Method: Density functional theory calculations, phonon spectra, molecular dynamics simulations, and formation energy calculations to propose and confirm stability of 2D magnetic semiconductors.

Result: Identification of Cr2NiSe4 as a BMS with 0.40 eV band gap and 352 K Curie temperature, demonstrating nonvolatile spin polarization control via ferroelectric Al2Se3 substrate.

Conclusion: The work presents a feasible strategy for nonvolatile electrical control of 2D BMS, enabling potential applications in multiferroic memory devices.

Abstract: The development of room-temperature tunable magnetic semiconductors is
crucial for the advancement of low-power, high-performance information
technologies. Using density functional theory calculations, we propose a series
of two-dimensional magnetic semiconductors with critical temperature above room
temperature, including three ferromagnetic and two antiferromagnetic
semiconductors.Their stability is confirmed through phonon spectra, molecular
dynamics simulations, and formation energy calculations. In particular, we
demonstrate a ferromagnetic bipolar magnetic semiconductor (BMS), Cr2NiSe4,
formed via Ni intercalation into bilayer CrSe2, which exhibits a 0.40 eV band
gap and a Curie temperature of 352 K. Nonvolatile carrier spin polarization
control in Cr2NiSe4 is achieved by switching the ferroelectric polarization of
an Al2Se3 substrate. Switching the ferroelectric state of monolayer Al2Se3
induces a BMS-to-half-metal transition. Reversing the polarization of bilayer
Al2Se3 yields a half-metallic Cr2NiSe4 with fully opposite carrier spin
polarization. Furthermore, we propose a multiferroic nonvolatile memory design:
write operations are controlled by the ferroelectric polarization state of
bilayer Al2Se3, while read operations rely on detecting the distinct carrier
spin polarizations of Cr2NiSe4. Our work reports a two dimensional BMS with
Curie temperature above room temperature and presents a feasible strategy for
its nonvolatile electrical control.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [46] [Efficient Prediction of SO(3)-Equivariant Hamiltonian Matrices via SO(2) Local Frames](https://arxiv.org/abs/2506.09398)
*Haiyang Yu,Yuchao Lin,Xuan Zhang,Xiaofeng Qian,Shuiwang Ji*

Main category: cs.LG

TL;DR: QHNetV2, a novel network, predicts Hamiltonian matrices efficiently using SO(2)-equivariant operations, avoiding costly SO(3) tensor products, and shows strong performance on molecular datasets.


<details>
  <summary>Details</summary>
Motivation: Accelerating electronic structure calculations in physics, chemistry, and materials science by leveraging the relationship between Hamiltonian matrices and SO(2) local frames.

Method: Proposes QHNetV2 with SO(2)-equivariant operations for feature updates and message passing within SO(2) local frames, eliminating SO(3) tensor products. Uses continuous SO(2) tensor products for node feature fusion.

Result: Superior performance on QH9 and MD17 datasets, demonstrating strong generalization across molecular structures and trajectories.

Conclusion: SO(2) operations on local frames provide scalable, symmetry-aware learning for electronic structures, with code to be released in the AIRS library.

Abstract: We consider the task of predicting Hamiltonian matrices to accelerate
electronic structure calculations, which plays an important role in physics,
chemistry, and materials science. Motivated by the inherent relationship
between the off-diagonal blocks of the Hamiltonian matrix and the SO(2) local
frame, we propose a novel and efficient network, called QHNetV2, that achieves
global SO(3) equivariance without the costly SO(3) Clebsch-Gordan tensor
products. This is achieved by introducing a set of new efficient and powerful
SO(2)-equivariant operations and performing all off-diagonal feature updates
and message passing within SO(2) local frames, thereby eliminating the need of
SO(3) tensor products. Moreover, a continuous SO(2) tensor product is performed
within the SO(2) local frame at each node to fuse node features, mimicking the
symmetric contraction operation. Extensive experiments on the large QH9 and
MD17 datasets demonstrate that our model achieves superior performance across a
wide range of molecular structures and trajectories, highlighting its strong
generalization capability. The proposed SO(2) operations on SO(2) local frames
offer a promising direction for scalable and symmetry-aware learning of
electronic structures. Our code will be released as part of the AIRS library
https://github.com/divelab/AIRS.

</details>


### [47] [mLaSDI: Multi-stage latent space dynamics identification](https://arxiv.org/abs/2506.09207)
*William Anderson,Kevin Chung,Youngsoo Choi*

Main category: cs.LG

TL;DR: The paper introduces mLaSDI, a multi-stage version of LaSDI, to improve accuracy and efficiency in reduced-order modeling for PDEs by sequentially training autoencoders to correct errors from previous stages.


<details>
  <summary>Details</summary>
Motivation: Accurate numerical solutions for PDEs are computationally expensive. While LaSDI offers a data-driven ROM framework, it struggles with reconstruction accuracy and latent space dynamics in complex scenarios.

Method: mLaSDI trains multiple autoencoders sequentially, each correcting errors from prior stages, to enhance reconstruction and prediction accuracy while reducing training time.

Result: mLaSDI achieves lower prediction and reconstruction errors with smaller autoencoders and faster training compared to LaSDI.

Conclusion: mLaSDI improves upon LaSDI by addressing its limitations, offering a more efficient and accurate ROM framework for PDEs.

Abstract: Determining accurate numerical solutions of partial differential equations
(PDEs) is an important task in many scientific disciplines. However, solvers
can be computationally expensive, leading to the development of reduced-order
models (ROMs). Recently, Latent Space Dynamics Identification (LaSDI) was
proposed as a data-driven, non-intrusive ROM framework. LaSDI compresses the
training data using an autoencoder and learns a system of user-chosen ordinary
differential equations (ODEs), which govern the latent space dynamics. This
allows for rapid predictions by interpolating and evolving the low-dimensional
ODEs in the latent space. While LaSDI has produced effective ROMs for numerous
problems, the autoencoder can have difficulty accurately reconstructing
training data while also satisfying the imposed dynamics in the latent space,
particularly in complex or high-frequency regimes. To address this, we propose
multi-stage Latent Space Dynamics Identification (mLaSDI). With mLaSDI, several
autoencoders are trained sequentially in stages, where each autoencoder learns
to correct the error of the previous stages. We find that applying mLaSDI with
small autoencoders results in lower prediction and reconstruction errors, while
also reducing training time compared to LaSDI.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [48] [Enhancing semi-resolved CFD-DEM for dilute to dense particle-fluid systems: A point cloud based, two-step mapping strategy via coarse graining](https://arxiv.org/abs/2506.09517)
*Yuxiang Liu,Lu Jing,Xudong Fu,Huabin Shi*

Main category: physics.flu-dyn

TL;DR: The paper introduces a two-step mapping CFD-DEM method using point-based coarse graining to improve stability and accuracy in simulating particle-fluid systems, validated across various scenarios.


<details>
  <summary>Details</summary>
Motivation: Current CFD-DEM methods suffer from grid resolution dependence, instability, and failure to capture pore fluid pressure in dense systems.

Method: A two-step mapping approach with multi-layer Fibonacci point cloud for coarse graining, independent of fluid grids, ensures accurate coupling.

Result: Validated in multiple configurations, the method accurately simulates fluid-particle interactions across diverse grid-to-particle ratios and solid concentrations.

Conclusion: The proposed CFD-DEM offers a robust solution for industrial and geophysical applications, overcoming limitations of traditional methods.

Abstract: Computational fluid dynamics and discrete element method (CFD-DEM) coupling
is an efficient and powerful tool to simulate particle-fluid systems. However,
current volume-averaged CFD-DEM relying on direct grid-based mapping between
the fluid and particle phases can exhibit a strong dependence on the fluid grid
resolution, becoming unstable as particles move across fluid grids, and can
fail to capture pore fluid pressure effects in very dense granular systems.
Here we propose a two-step mapping CFD-DEM which uses a point-based coarse
graining technique for intermediate smoothing to overcome these limitations.
The discrete particles are first converted into smooth, coarse-grained
continuum fields via a multi-layer Fibonacci point cloud, independent of the
fluid grids. Then, accurate coupling is achieved between the coarse-grained,
point cloud fields and the fluid grid-based variables. The algorithm is
validated in various configurations, including weight allocation of a static
particle on one-dimensional grids and a falling particle on two-dimensional
grids, sedimentation of a sphere in a viscous fluid, size-bidisperse fluidized
beds, Ergun's pressure drop test, and immersed granular column collapse. The
proposed CFD-DEM represents a novel strategy to accurately simulate
fluid-particle interactions for a wide range of grid-to-particle size ratios
and solid concentrations, which is of potential use in many industrial and
geophysical applications.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [49] [Photo-induced directional transport in extended SSH chains](https://arxiv.org/abs/2506.09783)
*Usham Harish Kumar Singha,Kallol Mondal,Sudin Ganguly,Santanu K. Maiti*

Main category: cond-mat.mes-hall

TL;DR: The paper explores how polarized light can control rectification in an extended SSH chain, achieving over 90% efficiency and directional control via light polarization.


<details>
  <summary>Details</summary>
Motivation: To demonstrate the potential of light as an external control for electronic behavior, specifically in rectification, using an extended SSH chain.

Method: Uses the Floquet-Bloch ansatz with minimal coupling for light effects and nonequilibrium Green's function formalism for charge transport.

Result: Achieves over 90% rectification efficiency with precise control of direction via light polarization.

Conclusion: Highlights the promise of optically controlled rectifiers in electronic applications.

Abstract: We investigate the current-voltage characteristics of an extended
Su-Schrieffer-Heeger (SSH) chain under irradiation by arbitrarily polarized
light, demonstrating its potential as a light-controlled rectifier. Irradiation
of light induces anisotropy in the system, enabling directional current flow
and active control of rectification behavior. Our analysis demonstrates that,
under optimized light parameters, the rectification efficiency can exceed 90\%.
Moreover, the direction of rectification-whether positive or negative-can be
precisely controlled by varying the polarization of the light, highlighting the
potential for external optical control of electronic behavior. The effect of
light irradiation is incorporated using the Floquet-Bloch ansatz combined with
the minimal coupling scheme, while charge transport is computed through the
nonequilibrium Green's function formalism within the Landauer-B\"{u}ttiker
framework.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [50] [Metriplectic relaxation to equilibria](https://arxiv.org/abs/2506.09787)
*C. Bressan,M. Kraus,O. Maj,P. J. Morrison*

Main category: math-ph

TL;DR: The paper discusses metriplectic systems, combining Hamiltonian and entropy-gradient flows, and provides conditions for convergence to entropy extrema. It also constructs a class of such systems inspired by the Landau operator and applies them to equilibrium problems in fluid dynamics and plasma physics.


<details>
  <summary>Details</summary>
Motivation: To understand the long-time behavior of metriplectic systems and ensure convergence to entropy extrema on constant-Hamiltonian surfaces.

Method: Proposes sufficient conditions for convergence and constructs a metriplectic system inspired by the Landau operator for Coulomb collisions.

Result: Demonstrates the applicability of the constructed metriplectic systems to equilibrium problems in fluid dynamics and plasma physics.

Conclusion: The study provides a framework for analyzing metriplectic systems and their convergence, with practical applications in physics.

Abstract: Metriplectic dynamical systems consist of a special combination of a
Hamiltonian and a (generalized) entropy-gradient flow, such that the
Hamiltonian is conserved and entropy is dissipated/produced (depending on a
sign convention). It is natural to expect that, in the long-time limit, the
orbit of a metriplectic system should converge to an extremum of entropy
restricted to a constant-Hamiltonian surface. In this paper, we discuss
sufficient conditions for this to occur, and construct a class of metriplectic
systems that satisfy one such condition. The proposed metriplectic structure is
inspired by the Landau operator for Coulomb collisions in plasmas, which is
included as special case. We apply these results to the construction of
relaxation methods for the solution of equilibrium problems in fluid dynamics
and plasma physics.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [51] [The capillary Gauss curvature flow](https://arxiv.org/abs/2506.09840)
*Xinqun Mei,Guofang Wang,Liangjun Weng*

Main category: math.DG

TL;DR: The paper introduces a capillary Gauss curvature flow for hypersurfaces, showing it shrinks to a point in finite time and its normalized flow converges to a soliton, analogous to prior works.


<details>
  <summary>Details</summary>
Motivation: To extend Firey's problem and Guan-Ni's results to capillary hypersurfaces with Robin boundary conditions.

Method: Introduces a capillary Gauss curvature flow and analyzes its behavior, including finite-time shrinking and convergence to a soliton.

Result: The flow shrinks to a point in finite time, and its normalized version converges to a soliton.

Conclusion: The work generalizes existing results to capillary settings, but soliton classification remains an open problem.

Abstract: In this article, we first introduce a Gauss curvature type flow for capillary
hypersurfaces, which we call capillary Gauss curvature flow. We then show that
the flow will shrink to a point in finite time. This is a capillary counterpart
(or Robin boundary counterpart) of Firey's problem studied in [Mathematika 21
(1974), pp. 1-11] and Tso [Comm. Pure Appl. Math. 38 (1985), no. 6, 867-882].
Finally, we prove that its normalized flow converges to a soliton. This is a
capillary counterpart of the result of Guan and Ni in [J. Eur. Math. Soc. 19
(2017), no. 12, 3735-3761]. The classification of solitons remains an open
conjecture.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [52] [Speed-dependent Threshold for Electron Injection into Diffusive Shock Acceleration](https://arxiv.org/abs/2506.09134)
*Siddhartha Gupta,Damiano Caprioli,Anatoly Spitkovsky*

Main category: astro-ph.HE

TL;DR: The paper identifies the conditions for electron injection into diffusive shock acceleration (DSA) and develops a minimal model to explain nonthermal electron spectra.


<details>
  <summary>Details</summary>
Motivation: The injection threshold for electron DSA in collisionless shocks has been a longstanding unsolved problem.

Method: First-principles kinetic simulations and analysis of electron trajectories and momentum gain during shock-recrossing cycles.

Result: Electrons start DSA when their speed is sufficient to overrun the shock, and a speed-dependent injection model reproduces observed nonthermal spectra.

Conclusion: The findings establish a new criterion for electron DSA, impacting nonthermal emission in shock-powered systems.

Abstract: Finding the injection threshold for diffusive shock acceleration (DSA) of
electrons in collisionless shocks has been a longstanding unsolved problem.
Using first-principles kinetic simulations, we identify the conditions for
electron injection into DSA and quantify the evolution of the nonthermal tail
in self-generated electromagnetic turbulence. By analyzing electron
trajectories and their momentum gain during shock-recrossing cycles, we
demonstrate that electrons start participating in DSA when their speed is large
enough to overrun the shock. We develop a minimal model showing that
speed-dependent injection reproduces nonthermal electron spectra observed in
kinetic simulations. Our findings establish a new criterion for electron DSA,
which has broad implications for the nonthermal emission of shock-powered
space/astrophysical systems.

</details>
