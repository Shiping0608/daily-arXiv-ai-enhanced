{"id": "2506.10118", "pdf": "https://arxiv.org/pdf/2506.10118", "abs": "https://arxiv.org/abs/2506.10118", "authors": ["Sean Reiter", "Steffen W. R. Werner"], "title": "Data-driven balanced truncation for second-order systems with generalized proportional damping", "categories": ["math.NA", "cs.NA", "cs.SY", "eess.SY", "math.DS", "math.OC", "37N35, 65F55, 93A15, 93B15, 93C57"], "comment": "31 pages, 5 figures, 5 tables", "summary": "Structured reduced-order modeling is a central component in the\ncomputer-aided design of control systems in which cheap-to-evaluate\nlow-dimensional models with physically meaningful internal structures are\ncomputed. In this work, we develop a new approach for the structured\ndata-driven surrogate modeling of linear dynamical systems described by\nsecond-order time derivatives via balanced truncation model-order reduction.\nThe proposed method is a data-driven reformulation of position-velocity\nbalanced truncation for second-order systems and generalizes the\nquadrature-based balanced truncation for unstructured first-order systems to\nthe second-order case. The computed surrogates encode a generalized\nproportional damping structure, and the damping coefficients are inferred\nsolely from data by minimizing a least-squares error over the coefficients.\nSeveral numerical examples demonstrate the effectiveness of the proposed\nmethod.", "AI": {"tldr": "A data-driven method for structured reduced-order modeling of second-order linear dynamical systems, generalizing balanced truncation techniques.", "motivation": "To enable efficient, low-dimensional models with meaningful structures for control system design.", "method": "Reformulates position-velocity balanced truncation for second-order systems, inferring damping coefficients via least-squares minimization.", "result": "Effective surrogate models with generalized proportional damping, validated through numerical examples.", "conclusion": "The method successfully extends balanced truncation to second-order systems, offering practical utility in control system design."}}
{"id": "2506.10243", "pdf": "https://arxiv.org/pdf/2506.10243", "abs": "https://arxiv.org/abs/2506.10243", "authors": ["Rongxin Lu", "Jiwei Jia", "Young Ju Lee", "Zheng Lu", "Chensong Zhang"], "title": "R-PINN: Recovery-type a-posteriori estimator enhanced adaptive PINN", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In recent years, with the advancements in machine learning and neural\nnetworks, algorithms using physics-informed neural networks (PINNs) to solve\nPDEs have gained widespread applications. While these algorithms are\nwell-suited for a wide range of equations, they often exhibit suboptimal\nperformance when applied to equations with large local gradients, resulting in\nsubstantial localized errors. To address this issue, this paper proposes an\nadaptive PINN algorithm designed to improve accuracy in such cases. The core\nidea of the algorithm is to adaptively adjust the distribution of collocation\npoints based on the recovery-type a-posterior error of the current numerical\nsolution, enabling a better approximation of the true solution. This approach\nis inspired by the adaptive finite element method. By combining the\nrecovery-type a-posteriori estimator, a gradient-recovery estimator commonly\nused in the adaptive finite element method (FEM) with PINNs, we introduce the\nRecovery-type a-posteriori estimator enhanced adaptive PINN (R-PINN) and\ncompare its performance with a typical adaptive PINN algorithm, FI-PINN. Our\nresults demonstrate that R-PINN achieves faster convergence with fewer adaptive\npoints and significantly outperforms in the cases with multiple regions of\nlarge errors than FI-PINN. Notably, our method is a hybrid numerical approach\nfor solving partial differential equations, integrating adaptive FEM with\nPINNs.", "AI": {"tldr": "The paper introduces R-PINN, an adaptive PINN algorithm, to improve accuracy for PDEs with large local gradients by dynamically adjusting collocation points using a recovery-type error estimator.", "motivation": "Existing PINNs perform poorly for PDEs with large local gradients, leading to localized errors. The goal is to enhance accuracy in such cases.", "method": "The proposed R-PINN adapts collocation points using a recovery-type a-posteriori error estimator, inspired by adaptive FEM. It combines this with PINNs for better performance.", "result": "R-PINN converges faster with fewer adaptive points and outperforms FI-PINN, especially in cases with multiple error-prone regions.", "conclusion": "R-PINN successfully integrates adaptive FEM with PINNs, offering a hybrid numerical approach for solving PDEs with improved accuracy."}}
{"id": "2506.10261", "pdf": "https://arxiv.org/pdf/2506.10261", "abs": "https://arxiv.org/abs/2506.10261", "authors": ["Liqi Guo", "Ruike Xiang", "Deren Han", "Jiaxin Xie"], "title": "Enhanced randomized Douglas-Rachford method: Improved probabilities and adaptive momentum", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Randomized iterative methods have gained recent interest in machine learning\nand signal processing for solving large-scale linear systems. One such example\nis the randomized Douglas-Rachford (RDR) method, which updates the iterate by\nreflecting it through two randomly selected hyperplanes and taking a convex\ncombination with the current point. In this work, we enhance RDR by introducing\nimproved sampling strategies and an adaptive heavy-ball momentum scheme.\nSpecifically, we incorporate without-replacement and volume sampling into RDR,\nand establish stronger convergence guarantees compared to conventional i.i.d.\nsampling. Furthermore, we develop an adaptive momentum mechanism that\ndynamically adjusts step sizes and momentum parameters based on previous\niterates, and prove that the resulting method achieves linear convergence in\nexpectation with improved convergence bounds. Numerical experiments demonstrate\nthat the enhanced RDR method consistently outperforms the original version,\nproviding substantial practical benefits across a range of problem settings.", "AI": {"tldr": "The paper enhances the randomized Douglas-Rachford (RDR) method with improved sampling strategies and adaptive heavy-ball momentum, achieving better convergence guarantees and practical performance.", "motivation": "To improve the efficiency and convergence of randomized iterative methods for solving large-scale linear systems, particularly the RDR method.", "method": "Incorporates without-replacement and volume sampling into RDR, and introduces an adaptive heavy-ball momentum scheme with dynamic parameter adjustment.", "result": "The enhanced RDR method achieves linear convergence in expectation with improved bounds and outperforms the original in numerical experiments.", "conclusion": "The proposed enhancements to RDR provide stronger theoretical guarantees and practical benefits, making it more effective for large-scale problems."}}
{"id": "2506.10263", "pdf": "https://arxiv.org/pdf/2506.10263", "abs": "https://arxiv.org/abs/2506.10263", "authors": ["Charles L. Epstein", "Tristan Goodwill", "Jeremy Hoskins", "Solomon Quinn", "Manas Rachh"], "title": "Complex scaling for open waveguides", "categories": ["math.NA", "cs.NA", "65N80, 35Q60, 35C15, 35P25, 45B05, 31A10, 30B40, 65R20"], "comment": null, "summary": "In this work we analyze the complex scaling method applied to the problem of\ntime-harmonic scalar wave propagation in junctions between `leaky,' or open\ndielectric waveguides. In [arXiv:2302.04353, arXiv:2310.05816,\narXiv:2401.04674, arXiv:2411.11204], it was shown that under suitable\nassumptions the problem can be reduced to a system of Fredholm second-kind\nintegral equations on an infinite interface, transverse to the waveguides.\nHere, we show that the kernels appearing in the integral equation admit a\nrapidly decaying analytic continuation on certain natural totally real\nsubmanifolds of $\\mathbb{C}^2.$ We then show that for suitable,\nphysically-meaningful, boundary data the resulting solutions to the integral\nequations themselves admit analytic continuation and satisfy related asymptotic\nestimates. By deforming the integral equation to a suitable contour, the decay\nin the kernels, density, and data enable straightforward discretization and\ntruncation, with an error that decays exponentially in the truncation length.\nWe illustrate our results with several representative numerical examples.", "AI": {"tldr": "The paper analyzes the complex scaling method for wave propagation in leaky dielectric waveguide junctions, showing rapid kernel decay and enabling efficient numerical solutions.", "motivation": "To address the challenges of wave propagation in open dielectric waveguides by leveraging analytic continuations and integral equations.", "method": "Reduces the problem to Fredholm integral equations, analyzes kernel decay, and deforms contours for numerical discretization.", "result": "Demonstrates exponential error decay in truncation and validates with numerical examples.", "conclusion": "The method provides an efficient and accurate approach for solving wave propagation in such junctions."}}
{"id": "2506.10099", "pdf": "https://arxiv.org/pdf/2506.10099", "abs": "https://arxiv.org/abs/2506.10099", "authors": ["Mate Vass", "Xiaokun Wang", "Ihor Korolov", "Julian Schulze", "Thomas Mussenbrock"], "title": "Synergistic control of radical generation in a radio frequency atmospheric pressure plasma jet via voltage waveform tailoring and structured electrodes", "categories": ["physics.plasm-ph", "physics.app-ph"], "comment": null, "summary": "The synergy between voltage waveform tailoring and structured electrodes is\ninvestigated in a radio-frequency (RF) atmospheric-pressure microplasma jet\noperated in helium with a 0.1% oxygen admixture. The device incorporates\nrectangular trenches in both electrodes and is driven by \"Peaks\" and \"Valleys\"\nwaveforms synthesized from four harmonics (base frequency $f_{\\rm b} =\n13.56$~MHz, $V_{\\rm pp} = 500$~V, $P=$1.2~W). Two-dimensional plasma fluid\nsimulations, together with spatially and temporally resolved optical\ndiagnostics (Phase-Resolved Optical Emission Spectroscopy and Tunable Diode\nLaser Absorption Spectroscopy), are used to demonstrate that the combination of\nasymmetric voltage waveforms with electrode structuring leads to strong spatial\nlocalization of electron power absorption and radical generation. This synergy\nresults in a single pronounced maximum inside a trench at either the powered or\ngrounded electrode, depending on the applied waveform, unlike a symmetric\nexcitation, which produces a spatially symmetric enhancement at both\nelectrodes. The effect is attributed to the interplay between waveform-induced\nsheath dynamics and geometric focusing provided by the trenches, enabling\nelectrically reversible and selective enhancement of electron power absorption\nat a chosen location.", "AI": {"tldr": "The study explores how combining tailored voltage waveforms with structured electrodes in an RF microplasma jet enhances localized electron power absorption and radical generation.", "motivation": "To investigate the synergy between voltage waveform tailoring and electrode structuring for spatial control of plasma properties.", "method": "Used 2D plasma fluid simulations and optical diagnostics (PROES and TDLAS) with asymmetric waveforms and rectangular trenches in electrodes.", "result": "Asymmetric waveforms and electrode structuring localized electron power absorption and radical generation at a single trench, unlike symmetric excitation.", "conclusion": "The interplay of waveform-induced sheath dynamics and geometric focusing enables selective enhancement of plasma properties at desired locations."}}
{"id": "2506.10149", "pdf": "https://arxiv.org/pdf/2506.10149", "abs": "https://arxiv.org/abs/2506.10149", "authors": ["Chesson Sipling", "Yuan-Hang Zhang", "Massimiliano Di Ventra"], "title": "Phase-Space Engineering and Dynamical Long-Range Order in Memcomputing", "categories": ["physics.comp-ph", "nlin.AO"], "comment": "13 pages, 4 figures", "summary": "Digital Memcomputing machines (DMMs) are dynamical systems with memory (time\nnon-locality) that have been designed to solve combinatorial optimization\nproblems. Their corresponding ordinary differential equations depend on a few\nhyper-parameters that define both the system's relevant time scales and its\nphase-space geometry. Using numerical simulations on a prototypical DMM, we\nanalyze the role of these physical parameters in engineering the phase space to\neither help or hinder the solution search by DMMs. We find that the DMM\nexplores its phase space efficiently for a wide range of parameters, aided by\nthe long-range correlations in their fast degrees of freedom that emerge\ndynamically due to coupling with the (slow) memory degrees of freedom. In this\nregime, the time it takes for the system to find a solution scales well as the\nnumber of variables increases. When these hyper-parameters are chosen poorly,\nthe system navigates its phase space far less efficiently. However, we find\nthat, in many cases, dynamical long-range order (DLRO) persists even when the\nphase-space exploration process is inefficient. DLRO only disappears if the\nmemories are made to evolve as quickly as the fast degrees of freedom. This\nstudy points to the important role of memory and hyper-parameters in\nengineering the DMMs' phase space for optimal computational efficiency.", "AI": {"tldr": "The paper explores how hyper-parameters in Digital Memcomputing Machines (DMMs) affect phase-space efficiency for solving optimization problems, highlighting the role of memory and long-range correlations.", "motivation": "To understand how hyper-parameters influence the efficiency of DMMs in solving combinatorial optimization problems by engineering their phase-space dynamics.", "method": "Numerical simulations on a prototypical DMM to analyze the impact of hyper-parameters on phase-space exploration and solution search.", "result": "DMMs explore phase space efficiently with well-chosen hyper-parameters, aided by long-range correlations. Poor hyper-parameters reduce efficiency, but dynamical long-range order often persists.", "conclusion": "Memory and hyper-parameters are crucial for optimizing DMMs' computational efficiency, with long-range correlations playing a key role."}}
{"id": "2506.10087", "pdf": "https://arxiv.org/pdf/2506.10087", "abs": "https://arxiv.org/abs/2506.10087", "authors": ["Fabio Bagagiolo", "Stefan Moreti"], "title": "Wave-front tracking for a quasi-linear scalar conservation law with hysteresis II: the case of Preisach", "categories": ["math.AP", "35L65, 47J40"], "comment": null, "summary": "We consider the Cauchy problem for the quasi-linear scalar conservation law\n\\[u_t+\\mathcal{F}(u)_t+u_x=0,\\] where $\\mathcal{F}$ is a specific hysteresis\noperator. Hysteresis models a rate-independent memory relationship between the\ninput $u$ and its output, giving a non-local feature to the equation. In a\nprevious work the authors studied the case when $\\mathcal{F}$ is the Play\noperator. In the present article, we extend the analysis to the case of\nPreisach operator, which is probably the most versatile mathematical model to\nthe describe hysteresis in the applications, especially for the presence of\nsome kind of internal variables. This fact has required a new analysis of the\nequation. Starting from the Riemann problem, we address the so-called\nwave-front tracking method for a solution to the Cauchy problem with bounded\nvariation initial data. An entropy-like condition is also exploited for\nuniqueness.", "AI": {"tldr": "The paper extends the analysis of a quasi-linear scalar conservation law with hysteresis from the Play operator to the more versatile Preisach operator, addressing the Cauchy problem using wave-front tracking and an entropy condition for uniqueness.", "motivation": "The motivation is to generalize previous work on hysteresis in conservation laws by using the Preisach operator, which better models real-world applications due to its ability to handle internal variables.", "method": "The method involves analyzing the Riemann problem and employing the wave-front tracking technique for bounded variation initial data, supplemented by an entropy-like condition to ensure solution uniqueness.", "result": "The study successfully extends the analysis to the Preisach operator, providing a framework for solving the Cauchy problem with hysteresis effects.", "conclusion": "The conclusion highlights the versatility of the Preisach operator in modeling hysteresis and validates the proposed method for solving the Cauchy problem with non-local features."}}
{"id": "2506.10428", "pdf": "https://arxiv.org/pdf/2506.10428", "abs": "https://arxiv.org/abs/2506.10428", "authors": ["Sudeep Kundu", "Shishu pal Singh"], "title": "Penalty-Based Feedback Control and Finite Element Analysis for the Stabilization of Nonlinear Reaction-Diffusion Equations", "categories": ["math.NA", "cs.NA", "math.OC", "93D15, 35K57, 65M60, 93B52, 65M15"], "comment": null, "summary": "In this work, first we employ the penalization technique to analyze the\nDirichlet boundary feedback control problem pertaining to reaction-diffusion\nequation. We establish the stabilization result of the equivalent Robin problem\nin the \\(H^{2}\\)-norm with respect to the penalty parameter. Furthermore, we\nprove that the solution of the penalized control problem converges to the\ncorresponding solution of the Dirichlet boundary feedback control problem as\nthe penalty parameter \\(\\epsilon\\) approaches zero. A \\(C^{0}\\)-conforming\nfinite element method is applied to this problem for the spatial variable while\nkeeping the time variable continuous. We discuss the stabilization of the\nsemi-discrete scheme for the penalized control problem and present an error\nanalysis of its solution. Finally, we validate our theoretical findings through\nnumerical experiments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.10410", "pdf": "https://arxiv.org/pdf/2506.10410", "abs": "https://arxiv.org/abs/2506.10410", "authors": ["Panagiotis Tolias", "Jan Vorberger", "Tobias Dornheim"], "title": "Exact series expansion for even frequency moments of the dynamic structure factor", "categories": ["physics.plasm-ph", "physics.chem-ph"], "comment": null, "summary": "An exact series representation of the even frequency moments of the dynamic\nstructure factor is derived. Truncations are proposed that allow to evaluate\nthe explicitly unknown second, fourth and fifth frequency moments for the\nfinite temperature uniform electron gas. Their applicability range in terms of\ndegeneracy parameter and wavenumber is determined by exploiting the\nnon-interacting limit and by comparing with the quasi-exact results of path\nintegral Monte Carlo simulations.", "AI": {"tldr": "Derived an exact series for even frequency moments of the dynamic structure factor, with truncations for unknown moments in the finite-temperature electron gas, validated against Monte Carlo simulations.", "motivation": "To address the lack of explicit knowledge of higher frequency moments (second, fourth, fifth) in the finite-temperature uniform electron gas.", "method": "Proposed truncations of the exact series representation, validated using the non-interacting limit and path integral Monte Carlo simulations.", "result": "Determined the applicability range of the truncations in terms of degeneracy parameter and wavenumber.", "conclusion": "The derived truncations provide a practical way to evaluate unknown frequency moments, validated by comparison with quasi-exact simulations."}}
{"id": "2506.10691", "pdf": "https://arxiv.org/pdf/2506.10691", "abs": "https://arxiv.org/abs/2506.10691", "authors": ["Dilara Abdel", "Jacob Relle", "Thomas Kirchartz", "Patrick Jaap", "J\u00fcrgen Fuhrmann", "Sven Burger", "Christiane Becker", "Klaus J\u00e4ger", "Patricio Farrell"], "title": "Unravelling the mystery of enhanced open-circuit voltages in nanotextured perovskite solar cells", "categories": ["physics.comp-ph", "physics.app-ph"], "comment": null, "summary": "Perovskite solar cells have reached power conversion efficiencies that rival\nthose of established silicon photovoltaic technologies. Nanotextures in\nperovskite solar cells optimise light trapping and scattering, thereby\nimproving optical absorption. In addition, nanotextures have been\nexperimentally shown to enhance electronic performance, in particular, by\nincreasing the open-circuit voltage $V_{\\text{OC}}$ -- a phenomenon that, until\nnow, has remained not fully understood. This study investigates the underlying\nreasons by combining multi-dimensional optical and charge-transport simulations\nfor a single-junction perovskite solar cell. Our results reveal that the\nincreased open-circuit voltage is not driven by optical effects but by the\ntextured geometry itself. For voltages near $V_{\\text{OC}}$, texturing one of\nthe absorber/transport layer interfaces increases the imbalance between\nelectron and hole densities in the absorber, thereby reducing\nShockley-Read-Hall (SRH) recombination, which is the dominant loss mechanism in\nthis study. While idealised solar cells benefit unconditionally from increasing\ntexture height, in realistic cells there is an optimal texture height which\nmaximizes the power conversion efficiency. These findings provide new insights\ninto the opto-electronic advantages of texturing and offer guidance for the\ndesign of next-generation textured perovskite-based solar cells, light emitting\ndiodes, and photodetectors.", "AI": {"tldr": "Nanotextures in perovskite solar cells boost efficiency by reducing recombination, not just light trapping. Optimal texture height exists for realistic cells.", "motivation": "To understand why nanotextures improve open-circuit voltage in perovskite solar cells, beyond optical effects.", "method": "Combined multi-dimensional optical and charge-transport simulations for a single-junction perovskite solar cell.", "result": "Texturing reduces Shockley-Read-Hall recombination, increasing voltage. Optimal texture height maximizes efficiency in realistic cells.", "conclusion": "Texturing offers opto-electronic benefits, guiding design for future perovskite devices."}}
{"id": "2506.10176", "pdf": "https://arxiv.org/pdf/2506.10176", "abs": "https://arxiv.org/abs/2506.10176", "authors": ["Rafael Ceja Ayala", "Isaac Harris", "Tonatiuh S\u00e1nchez-Vizuet"], "title": "Well--posedness for the biharmonic scattering problem for a penetrable obstacle", "categories": ["math.AP", "47A40, 74J05, 74H25, 35J35"], "comment": null, "summary": "We address the direct scattering problem for a penetrable obstacle in an\ninfinite elastic two--dimensional Kirchhoff--Love plate. Under the assumption\nthat the plate's thickness is small relative to the wavelength of the incident\nwave, the propagation of perturbations on the plate is governed by the\ntwo-dimensional biharmonic wave equation, which we study in the frequency\ndomain. With the help of an operator factorization, the scattering problem is\nanalyzed from the perspective of a coupled boundary value problem involving the\nHelmholtz and modified Helmholtz equations. Well--posedness and reciprocity\nrelations for the problem are established. Numerical examples for some special\ncases are provided to validate the theoretical findings.", "AI": {"tldr": "The paper analyzes the scattering problem for a penetrable obstacle in a 2D Kirchhoff-Love plate, using the biharmonic wave equation in the frequency domain. It employs operator factorization to study the problem as a coupled boundary value problem involving Helmholtz and modified Helmholtz equations, proving well-posedness and reciprocity. Numerical examples validate the theory.", "motivation": "To solve the direct scattering problem for a penetrable obstacle in an elastic plate, focusing on scenarios where the plate's thickness is small compared to the incident wavelength.", "method": "Uses the biharmonic wave equation in the frequency domain and operator factorization to analyze the problem as a coupled boundary value problem involving Helmholtz and modified Helmholtz equations.", "result": "Establishes well-posedness and reciprocity relations for the problem. Numerical examples support the theoretical findings.", "conclusion": "The theoretical framework is validated, providing a foundation for solving similar scattering problems in elastic plates."}}
{"id": "2506.10447", "pdf": "https://arxiv.org/pdf/2506.10447", "abs": "https://arxiv.org/abs/2506.10447", "authors": ["Igor Tominec", "Lukas Lundgren", "Andr\u00e9 L\u00f6fgren", "Josefin Ahlkrona"], "title": "Stability analysis of the free-surface Stokes problem and an unconditionally stable explicit scheme", "categories": ["math.NA", "cs.NA", "math.AP", "65J15, 65M12, 65M60"], "comment": null, "summary": "Accurate simulations of ice sheet dynamics, mantle convection, lava flow, and\nother highly viscous free-surface flows involve solving the coupled\nStokes/free-surface equations. In this paper, we theoretically analyze the\nstability and conservation properties of the weak form of this system for\nNewtonian fluids and non-Newtonian fluids, at both the continuous and discrete\nlevels. We perform the fully discrete stability analysis for finite element\nmethods used in space with explicit and implicit Euler time-stepping methods\nused in time. Motivated by the theory, we propose a stabilization term designed\nfor the explicit Euler discretization, which ensures unconditional time\nstability and permits conservation of the domain volume. Numerical experiments\nvalidate and support our theoretical findings.", "AI": {"tldr": "The paper analyzes stability and conservation properties of the Stokes/free-surface system for viscous flows, proposing a stabilization term for explicit Euler discretization to ensure stability and volume conservation.", "motivation": "To address the challenges in simulating highly viscous free-surface flows like ice sheets and lava flows by analyzing the coupled Stokes/free-surface equations.", "method": "Theoretical analysis of the weak form system for Newtonian and non-Newtonian fluids, with fully discrete stability analysis for finite element methods and Euler time-stepping. A stabilization term is proposed for explicit Euler.", "result": "Numerical experiments validate the proposed stabilization term, ensuring unconditional time stability and domain volume conservation.", "conclusion": "The study provides a theoretical and practical framework for stable and conservative simulations of viscous free-surface flows."}}
{"id": "2506.10411", "pdf": "https://arxiv.org/pdf/2506.10411", "abs": "https://arxiv.org/abs/2506.10411", "authors": ["S. Ratynskaia", "M. Hoelzl", "E. Nardon", "P. Aleynikov", "F. J. Artola", "V. Bandaru", "M. Beidler", "B. Breizman", "D. del-Castillo-Negrete", "M. De Angeli", "V. Dimitriou", "R. Ding", "J. Eriksson", "O. Ficker", "R. S. Granetz", "E. Hollmann", "M. Hoppe", "M. Houry", "I. Jepu", "H. R. Koslowski", "C. Liu", "J. R. Martin-Solis", "G. Pautasso", "Y. Peneliau", "R. A. Pitts", "G. I. Pokol", "C. Reux", "U. Sheikh", "S. A. Silburn", "T. Tang", "R. A. Tinguely", "P. Tolias", "E. Tomesova", "R. Villari"], "title": "Runaway electron-induced plasma facing component damage in tokamaks", "categories": ["physics.plasm-ph", "physics.app-ph"], "comment": "Submitted for publication in the journal Plasma Physics and\n  Controlled Fusion", "summary": "This Roadmap article addresses the critical and multifaceted challenge of\nplasma-facing component (PFC) damage caused by runaway electrons (REs) in\ntokamaks, a phenomenon that poses a significant threat to the viability and\nlongevity of future fusion reactors such as ITER and DEMO. The dramatically\nincreased RE production expected in future high-current tokamaks makes it\ndifficult to avoid or mitigate REs when a plasma discharge terminates\nabnormally. Preventing damage from the intense localised heat loads REs can\ncause requires a holistic approach that considers plasma, REs and PFC damage.\nDespite decades of progress in understanding the physics of REs and the\nthermomechanical response of PFCs, their complex interplay remains poorly\nunderstood. This document aims to initiate a coordinated, interdisciplinary\napproach to bridge this gap by reviewing experimental evidence, advancing\ndiagnostic capabilities, and improving modelling tools across different scales,\ndimensionalities and fidelities. Key topics include RE beam formation and\ntransport, damage mechanisms in brittle and metallic PFCs, and observations in\nmajor facilities such as JET, DIII-D, WEST and EAST. The Roadmap emphasises the\nurgency of predictive, high-fidelity modelling validated against well-diagnosed\ncontrolled experiments, particularly in the light of recent changes in ITER's\nwall material strategy and the growing importance of private sector\ninitiatives. Each section of the article is written to provide a concise\noverview of one area of this multidisciplinary subject, with an assessment of\nthe status, a look at current and future challenges, and a brief summary. The\nultimate goal of this initiative is to guide future mitigation strategies and\ndesign resilient components that can withstand the loads imposed by REs, thus\nensuring the safe and sustainable operation of the next generation of fusion\npower plants.", "AI": {"tldr": "The paper addresses the challenge of plasma-facing component (PFC) damage from runaway electrons (REs) in tokamaks, proposing a multidisciplinary approach to bridge gaps in understanding and mitigation.", "motivation": "RE-induced PFC damage threatens future fusion reactors like ITER and DEMO, necessitating urgent research to prevent localized heat load damage.", "method": "The paper reviews experimental evidence, advances diagnostics, and improves modeling across scales, focusing on RE beam formation, transport, and PFC damage mechanisms.", "result": "It highlights the need for predictive modeling validated by experiments, especially given ITER's wall material changes and private sector involvement.", "conclusion": "The goal is to guide mitigation strategies and design resilient PFCs for safe, sustainable fusion power plant operation."}}
{"id": "2506.10956", "pdf": "https://arxiv.org/pdf/2506.10956", "abs": "https://arxiv.org/abs/2506.10956", "authors": ["John L. A. Gardner", "Daniel F. Thomas du Toit", "Chiheb Ben Mahmoud", "Zo\u00e9 Faure Beaulieu", "Veronika Juraskova", "Laura-Bianca Pa\u015fca", "Louise A. M. Rosset", "Fernanda Duarte", "Fausto Martelli", "Chris J. Pickard", "Volker L. Deringer"], "title": "Distillation of atomistic foundation models across architectures and chemical domains", "categories": ["physics.comp-ph"], "comment": null, "summary": "Machine-learned interatomic potentials have transformed computational\nresearch in the physical sciences. Recent atomistic `foundation' models have\nchanged the field yet again: trained on many different chemical elements and\ndomains, these potentials are widely applicable, but comparably slow and\nresource-intensive to run. Here we show how distillation via synthetic data can\nbe used to cheaply transfer knowledge from atomistic foundation models to a\nrange of different architectures, unlocking much smaller, more efficient\npotentials. We demonstrate speed-ups of $> 10\\times$ by distilling from one\ngraph-network architecture into another, and $> 100\\times$ by leveraging the\natomic cluster expansion framework. We showcase applicability across chemical\nand materials domains: from liquid water to hydrogen under extreme conditions;\nfrom porous silica and a hybrid halide perovskite solar-cell material to\nmodelling organic reactions. Our work shows how distillation can support the\nroutine and computationally efficient use of current and future atomistic\nfoundation models in real-world scientific research.", "AI": {"tldr": "Distillation via synthetic data transfers knowledge from atomistic foundation models to smaller, efficient potentials, achieving significant speed-ups and broad applicability.", "motivation": "To address the inefficiency and resource-intensity of atomistic foundation models while retaining their broad applicability.", "method": "Distillation via synthetic data to transfer knowledge to smaller architectures, tested across various chemical and materials domains.", "result": "Achieved speed-ups of >10\u00d7 and >100\u00d7, demonstrated across diverse applications like liquid water, hydrogen, silica, perovskites, and organic reactions.", "conclusion": "Distillation enables efficient use of atomistic foundation models in real-world research, making them more practical and scalable."}}
{"id": "2506.10255", "pdf": "https://arxiv.org/pdf/2506.10255", "abs": "https://arxiv.org/abs/2506.10255", "authors": ["Haokun Chen", "Yong Wang"], "title": "Optimal decay of global strong solutions to nematic liquid crystal flows in the half-space", "categories": ["math.AP"], "comment": "37 pages", "summary": "We study asymptotic behaviors of the higher-order spatial derivatives and the\nfirst-order time derivatives for the strong solution to nematic liquid crystal\nflows in the half-space $\\mathbb{R}_+^3$. Furthermore, when the initial data\nlie in an appropriately weighted Sobolev space, we obtain the decay rates that\nare faster than the heat kernel. The main tools employed in this paper are the\n$L^p-L^q$ estimates of the Stokes semigroup, the a priori estimates of the\nsteady Stokes system in $\\mathbb{R}_+^3$, and the representation formula of the\nLeray projection operator.", "AI": {"tldr": "The paper analyzes the decay rates of higher-order spatial and first-order time derivatives for nematic liquid crystal flows in a half-space, showing faster decay than the heat kernel under specific initial conditions.", "motivation": "To understand the asymptotic behavior of derivatives in nematic liquid crystal flows and improve decay rate estimates beyond the heat kernel.", "method": "Uses $L^p-L^q$ estimates of the Stokes semigroup, a priori estimates of the steady Stokes system, and the Leray projection operator's representation formula.", "result": "Faster decay rates are achieved for the derivatives when initial data lie in a weighted Sobolev space.", "conclusion": "The study provides improved decay estimates for nematic liquid crystal flows, leveraging advanced analytical tools."}}
{"id": "2506.10499", "pdf": "https://arxiv.org/pdf/2506.10499", "abs": "https://arxiv.org/abs/2506.10499", "authors": ["Alexander Freiszlinger", "Dirk Pauly", "Dirk Praetorius"], "title": "Convergence of adaptive boundary element methods driven by functional a posteriori error estimates", "categories": ["math.NA", "cs.NA", "65N38, 65N15, 65N50, 65N12"], "comment": null, "summary": "The recent work [Kurz et al., Numer. Math., 147 (2021)] proposed functional a\nposteriori error estimates for boundary element methods (BEMs) together with a\nrelated adaptive mesh-refinement strategy. Unlike most a posteriori BEM error\nestimators, the proposed functional error estimators cover Galerkin as well as\ncollocation BEM and, more importantly, do not control the error in the integral\ndensity on the boundary, but the error of the potential approximation in the\ndomain, which is of greater relevance in practice. The estimates rely on the\nnumerical solution of auxiliary problems on auxiliary strip domains along the\nboundary, where the strips are affected by the adaptive mesh-refinement and\nhence vary. For Galerkin BEM, we prove that the proposed adaptive\nmesh-refinement algorithm yields convergence of the potential error to zero.\nDue to the structural difference to residual-based estimators, the proof\nrequires new ideas.", "AI": {"tldr": "Functional a posteriori error estimates for BEMs are proposed, covering Galerkin and collocation methods, focusing on potential approximation errors in the domain rather than boundary density errors. An adaptive mesh-refinement strategy is introduced, with convergence proven for Galerkin BEM.", "motivation": "To address the practical relevance of potential approximation errors in the domain, rather than boundary density errors, and to provide a unified approach for Galerkin and collocation BEMs.", "method": "Functional error estimates derived from auxiliary problems on adaptive strip domains along the boundary, with a mesh-refinement strategy.", "result": "Convergence of potential error to zero is proven for Galerkin BEM, requiring novel proof techniques due to structural differences from residual-based estimators.", "conclusion": "The proposed functional error estimators and adaptive strategy effectively address practical needs and unify error control for different BEM approaches."}}
{"id": "2506.10493", "pdf": "https://arxiv.org/pdf/2506.10493", "abs": "https://arxiv.org/abs/2506.10493", "authors": ["Chao Wang", "Lei Chang", "Ling-Feng Lu", "Shunjiro Shinohara", "Zhi-De Zeng", "Ilya Zadiriev", "Elena Kralkina", "Zhi Li", "Shi-Jie Zhang", "Zi-Chen Kan", "Ye Tao", "Ding-Zhou Li"], "title": "Spatial and temporal evolutions of blue-core helicon discharge driven by planar antenna with concentric rings", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The spatial and temporal evolutions of blue-core helicon discharge driven by\na planar antenna with four concentric rings are explored on the Linear\nExperimental Advanced Device (LEAD). The discharge experiences distinct density\njumps from E mode to H mode, W mode, and blue-core mode, when RF input power\nincreases. This is similar to previous observations using other typical helicon\nantennas; however, this special antenna could drive modes of even higher levels\nfor which the blue-core plasma column is actually hollow in radius, i.e.\npeaking off-axis, which was not presented before. The column shows\ncounterclockwise rotation for blue-core mode and clockwise rotation for\nnon-blue-core mode. The reason could be attributed to the radial electric field\ndifferenceses for both modes which reverses the rotation direction via ExB\ndrive. Moreover, the centrifugal instability of blue-core helicon plasma is\ncomputed using a two-fluid flowing plasma model. It shows that the instability\nis strong for small axial wave number but becomes weak for large axial wave\nnumber. Perturbed density peaks at radius of 0.045 m, while the equilibrium\ndensity gradient peaks at radius of 0.055 m. The coincidence of their radial\nlocations suggests that it is a resistive drift mode driven by density\ngradient. The blue-core mode weakens once the magnetic field or flow rate\nexceeds the threshold value. Increasing power further leads to a smoother\nplasma density gradient. The electron temperature profiles decrease with\nincreased power, and the radial gradient of the electron temperature inside the\ncore is smaller as the magnetic field changes. To our best knowledge, it is the\nfirst detailed characterization of blue-core helicon plasma driven by planar\nantenna, especially in terms of azimuthal rotation and centrifugal instability.", "AI": {"tldr": "The paper explores blue-core helicon discharge driven by a planar antenna, revealing unique density jumps, rotation direction reversals, and centrifugal instability, with detailed characterization of plasma behavior.", "motivation": "To investigate the spatial and temporal evolutions of blue-core helicon discharge using a novel planar antenna, uncovering unique phenomena like hollow blue-core plasma and rotation direction reversals.", "method": "Experiments conducted on the Linear Experimental Advanced Device (LEAD) with a planar antenna, analyzing density jumps, rotation, and instability using a two-fluid flowing plasma model.", "result": "The discharge shows distinct density jumps, hollow blue-core plasma, and rotation direction reversals. Centrifugal instability is strong for small axial wave numbers and weak for large ones. The blue-core mode weakens with increased magnetic field or flow rate.", "conclusion": "This study provides the first detailed characterization of blue-core helicon plasma driven by a planar antenna, highlighting unique features like hollow plasma and rotation reversals, advancing understanding of helicon discharge dynamics."}}
{"id": "2506.10211", "pdf": "https://arxiv.org/pdf/2506.10211", "abs": "https://arxiv.org/abs/2506.10211", "authors": ["Shriya Gumber", "Lorena Alzate-Vargas", "Benjamin T. Nebgen", "Arjen van Veelen", "Smit Kadvani", "Tammie Gibson", "Richard Messerly"], "title": "Going beyond density functional theory accuracy: Leveraging experimental data to refine pre-trained machine learning interatomic potentials", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Machine learning interatomic potentials (MLIPs) are inherently limited by the\naccuracy of the training data, usually consisting of energies and forces\nobtained from quantum mechanical calculations, such as density functional\ntheory (DFT). Since DFT itself is based on several approximations, MLIPs may\ninherit systematic errors that lead to discrepancies with experimental data. In\nthis paper, we use a trajectory re-weighting technique to refine DFT\npre-trained MLIPs to match the target experimental Extended X-ray Absorption\nFine Structure (EXAFS) spectra. EXAFS spectra are sensitive to the local\nstructural environment around an absorbing atom. Thus, refining an MLIP to\nimprove agreement with experimental EXAFS spectra also improves the MLIP\nprediction of other structural properties that are not directly involved in the\nrefinement process. We combine this re-weighting technique with transfer\nlearning and a minimal number of training epochs to avoid overfitting to the\nlimited experimental data. The refinement approach demonstrates significant\nimprovement for two MLIPs reported in previous work, one for an established\nnuclear fuel: uranium dioxide (UO$_2$) and second one for a nuclear fuel\ncandidate: uranium mononitride (UN). We validate the effectiveness of our\napproach by comparing the results obtained from the original (unrefined)\nDFT-based MLIP and the EXAFS-refined MLIP across various properties, such as\nlattice parameters, bulk modulus, heat capacity, point defect energies, elastic\nconstants, phonon dispersion spectra, and diffusion coefficients. An accurate\nMLIP for nuclear fuels is extremely beneficial as it enables reliable atomistic\nsimulation, which greatly reduces the need for large number of expensive and\ninherently dangerous experimental nuclear integral tests, traditionally\nrequired for the qualification of efficient and resilient fuel candidates.", "AI": {"tldr": "The paper introduces a trajectory re-weighting technique to refine DFT-trained MLIPs using experimental EXAFS spectra, improving accuracy for nuclear fuels like UO2 and UN.", "motivation": "MLIPs inherit systematic errors from DFT, limiting their accuracy. Refining them with experimental EXAFS data can enhance predictions for structural properties.", "method": "A trajectory re-weighting technique combined with transfer learning and minimal training epochs is used to refine MLIPs, avoiding overfitting.", "result": "The refined MLIPs show significant improvement in predicting lattice parameters, bulk modulus, and other properties compared to unrefined DFT-based MLIPs.", "conclusion": "The approach provides accurate MLIPs for nuclear fuels, reducing reliance on costly and hazardous experimental tests."}}
{"id": "2506.10273", "pdf": "https://arxiv.org/pdf/2506.10273", "abs": "https://arxiv.org/abs/2506.10273", "authors": ["V\u00edctor A Vicente-Ben\u00edtez"], "title": "Generalized Poisson kernel and solution of the Dirichlet problem for the radial Schr\u00f6dinger equation", "categories": ["math.AP", "35A24, 35C05, 35C10, 35C15, 35J10"], "comment": "28 pages", "summary": "We present an explicit construction of the solution to the Dirichlet boundary\nvalue problem for the radial Schr\\\"odinger equation in the unit ball, with a\ncomplex-valued potential $V$ satisfying the condition\n$\\int_0^1r|V(r)|dr<\\infty$. The solution is based on the construction of an\nexplicit orthogonal set of solutions for the radial equation. In the case of a\nDirichlet problem with boundary data in $W^{\\frac{1}{2},2}(\\mathbb{S}^{d-1})$,\nthe solution is expressed as a series expansion in terms of the so-called\nformal spherical polynomials. We establish conditions for the solvability and\nuniqueness of the Dirichlet problem. Based on this series representation, we\nintroduce the concept of generalized Poisson kernel, develop its main\nproperties, and investigate the conditions under which the Dirichlet problem,\nwith a boundary condition being a complex Radon measure on $\\mathbb{S}^{d-1}$,\nadmits a solution in the sense of a distributional boundary values.", "AI": {"tldr": "The paper provides an explicit solution to the Dirichlet boundary value problem for the radial Schr\u00f6dinger equation in a unit ball with a complex potential, using orthogonal solutions and formal spherical polynomials. It also introduces a generalized Poisson kernel and explores solvability and uniqueness conditions.", "motivation": "To address the Dirichlet boundary value problem for the radial Schr\u00f6dinger equation with a complex potential, ensuring solvability and uniqueness while extending the solution framework to distributional boundary values.", "method": "Constructs an explicit orthogonal set of solutions for the radial equation, uses series expansion with formal spherical polynomials, and introduces a generalized Poisson kernel.", "result": "Establishes conditions for solvability and uniqueness of the Dirichlet problem and extends the solution to cases with boundary conditions as complex Radon measures.", "conclusion": "The paper successfully solves the Dirichlet problem for the radial Schr\u00f6dinger equation, introduces a generalized Poisson kernel, and provides conditions for solvability and uniqueness, even for distributional boundary values."}}
{"id": "2506.10509", "pdf": "https://arxiv.org/pdf/2506.10509", "abs": "https://arxiv.org/abs/2506.10509", "authors": ["Elisabetta Carlini", "Valentina Coscetti"], "title": "A semi-Lagrangian scheme for First-Order Mean Field Games based on monotone operators", "categories": ["math.NA", "cs.NA", "91A16, 49N80, 35Q89, 65M12, 65M25"], "comment": null, "summary": "We construct a semi-Lagrangian scheme for first-order, time-dependent, and\nnon-local Mean Field Games. The convergence of the scheme to a weak solution of\nthe system is analyzed by exploiting a key monotonicity property. To solve the\nresulting discrete problem, we implement a Learning Value Algorithm, prove its\nconvergence, and propose an acceleration strategy based on a Policy iteration\nmethod. Finally, we present numerical experiments that validate the\neffectiveness of the proposed schemes and show that the accelerated version\nsignificantly improves performance.", "AI": {"tldr": "A semi-Lagrangian scheme for non-local Mean Field Games is developed, with convergence proven and a Learning Value Algorithm implemented. An acceleration strategy improves performance.", "motivation": "To address the challenges of solving first-order, time-dependent, non-local Mean Field Games efficiently.", "method": "A semi-Lagrangian scheme is constructed, analyzed for convergence, and solved using a Learning Value Algorithm with an acceleration strategy based on Policy iteration.", "result": "The scheme converges to a weak solution, and the accelerated version significantly enhances performance, validated by numerical experiments.", "conclusion": "The proposed methods are effective for solving non-local Mean Field Games, with the accelerated version offering notable performance gains."}}
{"id": "2506.10906", "pdf": "https://arxiv.org/pdf/2506.10906", "abs": "https://arxiv.org/abs/2506.10906", "authors": ["George J. Wilkie"], "title": "Analytic model for neutral penetration and plasma fueling", "categories": ["physics.plasm-ph", "physics.atom-ph"], "comment": "13 pages, 6 figures", "summary": "Neutral atoms recycled from wall interaction interact with confined plasma,\nthereby refueling it, most strongly in the region closest to the wall. This\noccurs near the X-point in diverted configurations, or else near the wall\nitself in limited configurations. A progression of analytic models are\ndeveloped for neutral density in the vicinity of a planar or linear source in\nan ionizing domain. First-principles neutral transport simulations with DEGAS2\nare used throughout to test the validity and limits of the model when using\nequivalent sources. The model is further generalized for strong plasma\ngradients or the inclusion of charge exchange. An important part of the problem\nof neutral fueling from recycling is thereby isolated and solved with a\nclosed-form analytic model. A key finding is that charge exchange with the\nconfined plasma can be significantly simplified with a reasonable sacrifice of\naccuracy by treating it as a loss. The several assumptions inherent to the\nmodel (and the simulations to which it is compared) can be adapted according to\nthe particular behavior of neutrals in the divertor and the manner in which\nthey cross the separatrix.", "AI": {"tldr": "The paper develops analytic models for neutral density near plasma walls, validated by simulations, and simplifies charge exchange effects.", "motivation": "To understand and model neutral atom recycling from walls and its impact on plasma fueling, particularly near divertor regions.", "method": "Develops analytic models for neutral density near planar or linear sources, validated with DEGAS2 simulations, and generalizes for plasma gradients or charge exchange.", "result": "The model isolates and solves neutral fueling, showing charge exchange can be simplified as a loss with minor accuracy trade-offs.", "conclusion": "The analytic model effectively addresses neutral fueling from recycling, adaptable to various neutral behaviors in divertor configurations."}}
{"id": "2506.10298", "pdf": "https://arxiv.org/pdf/2506.10298", "abs": "https://arxiv.org/abs/2506.10298", "authors": ["Anubhab Haldar", "Ali K. Hamze", "Nikhil Sivadas", "Yongwoo Shin"], "title": "GEARS H: Accurate machine-learned Hamiltonians for next-generation device-scale modeling", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "13 pages, 3 figures, later version will add supplement", "summary": "We introduce GEARS H, a state-of-the-art machine-learning Hamiltonian\nframework for large-scale electronic structure simulations. Using GEARS H, we\npresent a statistical analysis of the hole concentration induced in defective\n$\\mathrm{WSe}_2$ interfaced with Ni-doped amorphous $\\mathrm{HfO}_2$ as a\nfunction of the Ni doping rate, system density, and Se vacancy rate in 72\nsystems ranging from 3326 to 4160 atoms-a quantity and scale of interface\nelectronic structure calculation beyond the reach of conventional density\nfunctional theory codes and other machine-learning-based methods. We further\ndemonstrate the versatility of our architecture by training models for a\nmolecular system, 2D materials with and without defects, solid solution\ncrystals, and bulk amorphous systems with covalent and ionic bonds. The mean\nabsolute error of the inferred Hamiltonian matrix elements from the validation\nset is below 2.4 meV for all of these models. GEARS H outperforms other\nproposed machine-learning Hamiltonian frameworks, and our results indicate that\nmachine-learning Hamiltonian methods, starting with GEARS H, are now\nproduction-ready techniques for DFT-accuracy device-scale simulation.", "AI": {"tldr": "GEARS H is a machine-learning Hamiltonian framework for large-scale electronic structure simulations, outperforming existing methods with high accuracy.", "motivation": "To enable DFT-accuracy simulations for large-scale systems, which are beyond conventional methods.", "method": "Uses GEARS H to analyze hole concentration in defective WSe2 interfaced with Ni-doped HfO2, and trains models for various systems.", "result": "Achieves mean absolute error below 2.4 meV, outperforming other frameworks.", "conclusion": "GEARS H is production-ready for DFT-accuracy device-scale simulations."}}
{"id": "2506.10278", "pdf": "https://arxiv.org/pdf/2506.10278", "abs": "https://arxiv.org/abs/2506.10278", "authors": ["S. N. Antontsev", "H. B. de Oliveira", "I. V. Kuznetsov", "D. A. Prokudin", "Kh. Khompysh"], "title": "Mixtures of nonhomogeneous viscoelastic incompressible fluids governed by the Kelvin-Voigt equations", "categories": ["math.AP", "35Q35, 76D03, 76T30"], "comment": null, "summary": "An initial-and boundary-value problem for the Kelvin-Voigt system, modeling a\nmixture of n incompressible and viscoelastic fluids, with non-constant density,\nis investigated in this work. The existence of global-in-time weak solutions is\nestablished: velocity, density and pressure. Under additional regularity\nassumptions, we also prove the uniqueness of the solution.", "AI": {"tldr": "The paper studies the Kelvin-Voigt system for a mixture of incompressible, viscoelastic fluids with non-constant density, proving global weak solutions and uniqueness under certain conditions.", "motivation": "To address the mathematical challenges of modeling mixtures of fluids with varying densities and viscoelastic properties.", "method": "Investigates an initial-and boundary-value problem for the Kelvin-Voigt system, focusing on weak solutions for velocity, density, and pressure.", "result": "Existence of global-in-time weak solutions is proven; uniqueness is established under additional regularity assumptions.", "conclusion": "The work provides a rigorous framework for analyzing complex fluid mixtures, with potential applications in rheology and material science."}}
{"id": "2506.10533", "pdf": "https://arxiv.org/pdf/2506.10533", "abs": "https://arxiv.org/abs/2506.10533", "authors": ["Santiago Badia", "Carsten Carstensen", "Alberto F. Martin", "Ricardo Ruiz-Baier", "Segundo Villa-Fuentes"], "title": "Non-augmented velocity-vorticity-pressure formulation for the Navier--Stokes--Brinkman--Forchheimer problem", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "The flow of incompressible fluid in highly permeable porous media in\nvorticity - velocity - Bernoulli pressure form leads to a double saddle-point\nproblem in the Navier--Stokes--Brinkman--Forchheimer equations. The paper\nestablishes, for small sources, the existence of solutions on the continuous\nand discrete level of lowest-order piecewise divergence-free Crouzeix--Raviart\nfinite elements. The vorticity employs a vector version of the pressure space\nwith normal and tangential velocity jump penalisation terms. A simple\nRaviart--Thomas interpolant leads to pressure-robust a priori error estimates.\nAn explicit residual-based a posteriori error estimate allows for efficient and\nreliable a posteriori error control. The efficiency for the Forchheimer\nnonlinearity requires a novel discrete inequality of independent interest. The\nimplementation is based upon a light-weight forest-of-trees data structure\nhandled by a highly parallel set of adaptive {mesh refining} algorithms.\nNumerical simulations reveal robustness of the a posteriori error estimates and\nimproved convergence rates by adaptive mesh-refining.", "AI": {"tldr": "The paper addresses the flow of incompressible fluid in porous media, solving a double saddle-point problem using Crouzeix--Raviart finite elements. It provides existence proofs, error estimates, and efficient adaptive algorithms, demonstrating robustness in simulations.", "motivation": "To solve the Navier--Stokes--Brinkman--Forchheimer equations for fluid flow in porous media, addressing challenges like nonlinearity and error control.", "method": "Uses lowest-order piecewise divergence-free Crouzeix--Raviart finite elements, penalisation terms for vorticity, and Raviart--Thomas interpolant for pressure-robust error estimates. Includes adaptive mesh-refining algorithms.", "result": "Existence of solutions proven for small sources. Pressure-robust a priori and residual-based a posteriori error estimates derived. Simulations show robustness and improved convergence.", "conclusion": "The method effectively handles the nonlinearity and provides reliable error control, with adaptive mesh refinement enhancing performance."}}
{"id": "2506.10648", "pdf": "https://arxiv.org/pdf/2506.10648", "abs": "https://arxiv.org/abs/2506.10648", "authors": ["Weiyu Shen", "Rodolfo Ostilla-M\u00f3nico", "Xiaojue Zhu"], "title": "Vortex-magnetic competition and regime transitions in antiparallel flux tubes", "categories": ["physics.flu-dyn", "astro-ph.SR", "physics.plasm-ph"], "comment": null, "summary": "Vortex-magnetic interactions shape magnetohydrodynamic (MHD) turbulence,\ninfluencing energy transfer in astrophysical, geophysical, and industrial\nsystems. On the Sun, granular-scale vortex flows couple strongly with magnetic\nfields, channelling energy into the corona. At high Reynolds numbers, vorticity\nand magnetic fields are nearly frozen into the charged fluid, and MHD flows\nemerge from the interplay between vortex dynamics and Lorentz forces. To probe\nthis competition in a controlled setting, we revisit the canonical problem of\ntwo antiparallel flux tubes. By varying the magnetic flux threading each\ntube--and thus sweeping the interaction parameter $N_i$, which gauges\nLorentz-to-inertial force balance--we uncover three distinct regimes:\nvortex-dominated joint reconnection, instability-triggered cascade, and\nLorentz-induced vortex disruption. At low $N_i$, classical vortex dynamics\ndominate, driving joint vortex-magnetic reconnection and amplifying magnetic\nenergy via a dynamo effect. At moderate $N_i$, the system oscillates between\nvorticity-driven attraction and magnetic damping, triggering instabilities and\nnonlinear interactions that spawn secondary filaments and drive an energy\ncascade. At high $N_i$, Lorentz forces suppress vortex interactions, aligning\nthe tubes axially while disrupting vortex cores and rapidly converting magnetic\nto kinetic energy. These findings reveal how the inertial-Lorentz balance\ngoverns energy transfer and coherent structure formation in MHD turbulence,\noffering insight into vortex-magnetic coevolution in astrophysical plasmas.", "AI": {"tldr": "The paper explores how vortex-magnetic interactions in MHD turbulence influence energy transfer, identifying three regimes based on the Lorentz-to-inertial force balance.", "motivation": "Understanding the interplay between vortex dynamics and magnetic fields in MHD turbulence, relevant to astrophysical and industrial systems.", "method": "Revisiting the problem of two antiparallel flux tubes by varying the magnetic flux to study the interaction parameter $N_i$.", "result": "Three distinct regimes emerge: vortex-dominated reconnection, instability-triggered cascade, and Lorentz-induced vortex disruption, each affecting energy transfer differently.", "conclusion": "The inertial-Lorentz balance governs energy transfer and structure formation in MHD turbulence, providing insights for astrophysical plasmas."}}
{"id": "2506.10308", "pdf": "https://arxiv.org/pdf/2506.10308", "abs": "https://arxiv.org/abs/2506.10308", "authors": ["Zhen Huang", "Gunhee Park", "Garnet Kin-Lic Chan", "Lin Lin"], "title": "Coupled Lindblad pseudomode theory for simulating open quantum systems", "categories": ["quant-ph", "cond-mat.str-el", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Coupled Lindblad pseudomode theory is a promising approach for simulating\nnon-Markovian quantum dynamics on both classical and quantum platforms, with\ndynamics that can be realized as a quantum channel. We provide theoretical\nevidence that the number of coupled pseudomodes only needs to scale as\n$\\mathrm{polylog}(T/\\varepsilon)$ in the simulation time $T$ and precision\n$\\varepsilon$. Inspired by the realization problem in control theory, we also\ndevelop a robust numerical algorithm for constructing the coupled modes that\navoids the non-convex optimization required by existing approaches. We\ndemonstrate the effectiveness of our method by computing population dynamics\nand absorption spectra for the spin-boson model. This work provides a\nsignificant theoretical and computational improvement to the coupled Lindblad\nframework, which impacts a broad range of applications from classical\nsimulations of quantum impurity problems to quantum simulations on near-term\nquantum platforms.", "AI": {"tldr": "Coupled Lindblad pseudomode theory efficiently simulates non-Markovian quantum dynamics with polylog scaling in time and precision, avoiding non-convex optimization.", "motivation": "To improve the simulation of non-Markovian quantum dynamics for classical and quantum platforms by addressing scalability and optimization challenges.", "method": "Theoretical analysis of pseudomode scaling and a robust numerical algorithm for constructing coupled modes, avoiding non-convex optimization.", "result": "Demonstrated effectiveness via population dynamics and absorption spectra for the spin-boson model.", "conclusion": "Significant theoretical and computational improvements to the coupled Lindblad framework, benefiting quantum simulations and impurity problems."}}
{"id": "2506.10318", "pdf": "https://arxiv.org/pdf/2506.10318", "abs": "https://arxiv.org/abs/2506.10318", "authors": ["Yuxuan Chen", "Shengquan Xiang", "Zhifei Zhang", "Jia-Cheng Zhao"], "title": "Exponential mixing for the randomly forced NLS equation", "categories": ["math.AP", "math.DS", "math.OC", "math.PR"], "comment": null, "summary": "This paper investigates exponential mixing of the invariant measure for\nrandomly forced nonlinear Schr\\\"{o}dinger equation, with damping and random\nnoise localized in space. Our study emphasizes the crucial role of exponential\nasymptotic compactness and control properties in establishing the ergodic\nproperties of random dynamical systems. This work extends the series [15, 45]\non the statistical behavior of randomly forced dispersive equations.", "AI": {"tldr": "The paper studies exponential mixing in the invariant measure for a randomly forced nonlinear Schr\u00f6dinger equation with damping and localized noise, highlighting the importance of exponential asymptotic compactness and control properties.", "motivation": "To understand the ergodic properties of random dynamical systems in the context of dispersive equations, building on prior work [15, 45].", "method": "Focuses on exponential asymptotic compactness and control properties to analyze the system.", "result": "Establishes exponential mixing of the invariant measure for the given equation.", "conclusion": "Extends previous research on the statistical behavior of randomly forced dispersive equations, emphasizing key analytical tools."}}
{"id": "2506.10636", "pdf": "https://arxiv.org/pdf/2506.10636", "abs": "https://arxiv.org/abs/2506.10636", "authors": ["Wei Chen", "Giacomo Dimarco", "Lorenzo Pareschi"], "title": "Structure and asymptotic preserving deep neural surrogates for uncertainty quantification in multiscale kinetic equations", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "The high dimensionality of kinetic equations with stochastic parameters poses\nmajor computational challenges for uncertainty quantification (UQ). Traditional\nMonte Carlo (MC) sampling methods, while widely used, suffer from slow\nconvergence and high variance, which become increasingly severe as the\ndimensionality of the parameter space grows. To accelerate MC sampling, we\nadopt a multiscale control variates strategy that leverages low-fidelity\nsolutions from simplified kinetic models to reduce variance. To further improve\nsampling efficiency and preserve the underlying physics, we introduce surrogate\nmodels based on structure and asymptotic preserving neural networks (SAPNNs).\nThese deep neural networks are specifically designed to satisfy key physical\nproperties, including positivity, conservation laws, entropy dissipation, and\nasymptotic limits. By training the SAPNNs on low-fidelity models and enriching\nthem with selected high-fidelity samples from the full Boltzmann equation, our\nmethod achieves significant variance reduction while maintaining physical\nconsistency and asymptotic accuracy. The proposed methodology enables efficient\nlarge-scale prediction in kinetic UQ and is validated across both homogeneous\nand nonhomogeneous multiscale regimes. Numerical results demonstrate improved\naccuracy and computational efficiency compared to standard MC techniques.", "AI": {"tldr": "The paper introduces a multiscale control variates strategy and surrogate models (SAPNNs) to improve Monte Carlo sampling efficiency for high-dimensional kinetic equations with stochastic parameters, achieving better accuracy and computational performance.", "motivation": "High dimensionality in kinetic equations with stochastic parameters makes traditional Monte Carlo methods inefficient due to slow convergence and high variance.", "method": "A multiscale control variates strategy and surrogate models (SAPNNs) are used, leveraging low-fidelity solutions and enforcing physical properties like positivity and conservation laws.", "result": "The method significantly reduces variance while maintaining physical consistency and asymptotic accuracy, outperforming standard Monte Carlo techniques.", "conclusion": "The proposed approach enables efficient large-scale prediction in kinetic uncertainty quantification, validated in various regimes."}}
{"id": "2506.10379", "pdf": "https://arxiv.org/pdf/2506.10379", "abs": "https://arxiv.org/abs/2506.10379", "authors": ["Jie Liu", "Xin Wang"], "title": "Hamiltonian Learning via Inverse Physics-Informed Neural Networks", "categories": ["quant-ph", "cond-mat.dis-nn", "physics.comp-ph"], "comment": "13 pages, 10 figures", "summary": "Hamiltonian learning (HL), enabling precise estimation of system parameters\nand underlying dynamics, plays a critical role in characterizing quantum\nsystems. However, conventional HL methods face challenges in noise robustness\nand resource efficiency, especially under limited measurements. In this work,\nwe present \\textit{Inverse Physics-Informed Neural Networks for Hamiltonian\nLearning (iPINN-HL)}, an approach that embeds the Schr\\\"{o}dinger equation\ndirectly into the machine learning procedure. This formulation allows the model\nto integrate both observational data and known physical laws to infer\nHamiltonian parameters with greater accuracy and resource efficiency. We\nbenchmark iPINN-HL against a deep-neural-network-based quantum state tomography\nmethod (denoted as DNN-HL) and demonstrate its effectiveness across several\ndifferent scenarios, including one-dimensional spin chains, cross-resonance\ngate calibration, crosstalk identification, and real-time compensation to\nparameter drift. Our results show that iPINN-HL can approach the Heisenberg\nlimit in certain settings and exhibits robustness to noises, while\noutperforming DNN-HL in accuracy and resource efficiency. Therefore, iPINN-HL\nis a powerful and flexible framework for quantum system characterization for\npractical tasks.", "AI": {"tldr": "iPINN-HL integrates physical laws into machine learning for Hamiltonian learning, outperforming DNN-HL in accuracy and efficiency.", "motivation": "Conventional Hamiltonian learning methods struggle with noise and resource efficiency under limited measurements.", "method": "iPINN-HL embeds the Schr\u00f6dinger equation into ML, combining observational data and physics for parameter inference.", "result": "iPINN-HL approaches the Heisenberg limit, shows noise robustness, and outperforms DNN-HL in accuracy and efficiency.", "conclusion": "iPINN-HL is a powerful, flexible framework for quantum system characterization."}}
{"id": "2506.10578", "pdf": "https://arxiv.org/pdf/2506.10578", "abs": "https://arxiv.org/abs/2506.10578", "authors": ["Shikun Cui", "Lili Wang", "Wendong Wang", "Juncheng Wei"], "title": "On the sharp critical mass threshold for the 3D Patlak-Keller-Segel-Navier-Stokes system via Couette flow", "categories": ["math.AP"], "comment": null, "summary": "As is well-known, the solution of the Patlak-Keller-Segel system in 3D may\nblow up in finite time regardless of any initial cell mass. In this paper, we\nare interested in the suppression of blow-up and the critical mass threshold\nfor the 3D Patlak-Keller-Segel-Navier-Stokes system via the Couette flow $(Ay,\n0, 0)$. It is proved that if the Couette flow is sufficiently strong ($A$ is\nlarge enough), then the solutions for the system are global in time in the\nperiodic domain $(x,y,z)\\in\\mathbb{T}^{3}$ as long as the initial cell mass is\nless than $16\\pi^{2}$. This result seems to be sharp, since the zero-mode\nfunction (the mean value in $x-$direction) of the three dimensional density is\na complication of the two-dimensional Keller-Segel equations, whose critical\nmass in 2D is $8\\pi$. One new observation is the dissipative decay of\n$(\\widetilde{u}_{2,0},\\widetilde{u}_{3,0})$ (see Lemma 4.3 for more details),\nthen we combine the quasi-linear method proposed by Wei-Zhang (Comm. Pure Appl.\nMath., 2021) with the zero-mode estimate of the density by the logarithmic\nHardy-Littlewood-Sobolev inequality as Bedrossian-He (SIAM J. Math. Anal.,\n2017) or He (Nonlinearity, 2025) to obtain the bounded-ness of the density and\nthe velocity.", "AI": {"tldr": "The paper investigates the suppression of blow-up in the 3D Patlak-Keller-Segel-Navier-Stokes system using Couette flow, proving global solutions for initial cell mass below 16\u03c0\u00b2 when the flow is strong enough.", "motivation": "To understand how Couette flow can prevent blow-up in the 3D Patlak-Keller-Segel system and identify the critical mass threshold.", "method": "Combines quasi-linear methods with zero-mode estimates and logarithmic Hardy-Littlewood-Sobolev inequality to analyze the system's behavior.", "result": "Global solutions exist for initial cell mass < 16\u03c0\u00b2 under strong Couette flow, with the threshold appearing sharp due to 2D analogies.", "conclusion": "The study provides a sharp critical mass threshold and demonstrates the stabilizing effect of Couette flow on the system."}}
{"id": "2506.10661", "pdf": "https://arxiv.org/pdf/2506.10661", "abs": "https://arxiv.org/abs/2506.10661", "authors": ["Oliver Townsend", "Sergey Dolgov", "Silvia Gazzola", "Misha Kilmer"], "title": "Alternating steepest descent methods for tensor completion with applications to spectromicroscopy", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper we develop two new Tensor Alternating Steepest Descent\nalgorithms for tensor completion in the low-rank $\\star_{M}$-product format,\nwhereby we aim to reconstruct an entire low-rank tensor from a small number of\nmeasurements thereof. Both algorithms are rooted in the Alternating Steepest\nDescent (ASD) method for matrix completion, first proposed in [J. Tanner and K.\nWei, Appl. Comput. Harmon. Anal., 40 (2016), pp. 417-429]. In deriving the new\nmethods we target the X-ray spectromicroscopy undersampling problem, whereby\ndata are collected by scanning a specimen on a rectangular viewpoint with X-ray\nbeams of different energies. The recorded absorptions coefficients of the mixed\nspecimen materials are naturally stored in a third-order tensor, with spatial\nhorizontal and vertical axes, and an energy axis. To speed the X-ray\nspectromicroscopy measurement process up, only a fraction of tubes from (a\nreshaped version of) this tensor are fully scanned, leading to a tensor\ncompletion problem. In this framework we can apply any transform (such as the\nFourier transform) to the tensor tube by tube, providing a natural way to work\nwith the $\\star_{M}$-tensor algebra, and propose: (1) a tensor completion\nalgorithm that is essentially ASD reformulated in the $\\star_{M}$-induced\nmetric space and (2) a tensor completion algorithm that solves a set of\n(readily parallelizable) independent matrix completion problems for the frontal\nslices of the transformed tensor. The two new methods are tested on real X-ray\nspectromicroscopy data, demonstrating that they achieve the same reconstruction\nerror with fewer samples from the tensor compared to the matrix completion\nalgorithms applied to a flattened tensor.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.10418", "pdf": "https://arxiv.org/pdf/2506.10418", "abs": "https://arxiv.org/abs/2506.10418", "authors": ["Gibaek Kim", "Jungho Kim"], "title": "Efficient nanophotonic devices optimization using deep neural network trained with physics-based transfer learning (PBTL) methodology", "categories": ["physics.optics", "physics.comp-ph"], "comment": null, "summary": "We propose a neural network(NN)-based surrogate modeling framework for\nphotonic device optimization, especially in domains with imbalanced feature\nimportance and high data generation costs. Our framework, which comprises\nphysics-based transfer learning (PBTL)-enhanced surrogate modeling and\nscalarized multi-objective genetic algorithms (GAs), offers a generalizable\nsolution for photonic design automation with minimal data resources.To validate\nthe framework, we optimize mid-infrared quantum cascade laser (QCL) structures\nconsisting of two regions, active and injection, which have different levels of\nfeature importance. The optimization targets include five key QCL performance\nmetrics such as modal gain, emission wavelength, linewidth, and effective\ninjection, extraction energies. To address the challenge of multiple local\noptima in the output latent space, we integrate a deep neural network total\npredictor (DNN-TP) with a GA, enabling scalable and nature-inspired\noptimization. By replacing computationally expensive numerical simulations with\nthe DNN-TP surrogate model, the optimization achieves a speed-up of over 80,000\ntimes, allowing large-scale exploration of the QCL design space.To improve\nmodel generalization with limited data, we introduce PBTL, which transfers\nknowledge from a DNN core predictor (DNN-CP) trained on active-region\nstructures. This approach yields a 0.69 percentage increase in prediction\naccuracy, equivalent to a 50 percentage reduction in training data\nrequirements, and leads to generate more feasible device structure with 60\npercentage improvement in evaluation metric during optimization.", "AI": {"tldr": "A neural network-based surrogate modeling framework for photonic device optimization, combining physics-based transfer learning and genetic algorithms, achieves significant speed-up and accuracy improvements.", "motivation": "To address challenges in photonic device optimization, such as imbalanced feature importance and high data generation costs, by leveraging surrogate modeling and transfer learning.", "method": "The framework uses a physics-based transfer learning-enhanced surrogate model and scalarized multi-objective genetic algorithms, validated on mid-infrared quantum cascade laser structures.", "result": "Achieves an 80,000x speed-up in optimization and a 0.69% increase in prediction accuracy, reducing training data needs by 50% and improving feasible device structures by 60%.", "conclusion": "The proposed framework offers a scalable, efficient solution for photonic design automation with minimal data resources."}}
{"id": "2506.10595", "pdf": "https://arxiv.org/pdf/2506.10595", "abs": "https://arxiv.org/abs/2506.10595", "authors": ["Lucia Arens", "Marius Gritl"], "title": "On local well-posedness for the nonlinear Schr\u00f6dinger equation with general power nonlinearity", "categories": ["math.AP"], "comment": null, "summary": "The nonlinear Schr\\\"odinger equation plays a fundamental role in mathematical\nphysics, particularly in the study of quantum mechanics and Bose-Einstein\ncondensation. This paper explores two distinct approaches to establishing the\nlocal well-posedness of solutions: the semigroup theory ansatz and the\nStrichartz estimates ansatz. Semigroup theory provides a general and elegant\nframework rooted in functional analysis, allowing for the interpretation of the\ntime evolution of solutions as operator semigroups. Strichartz estimates,\ndeveloped specifically for dispersive equations, offer an alternative technique\nbased on refined space-time estimates and fixed-point arguments. We\nsystematically analyze and compare both approaches and apply them to nonlinear\nSchr\\\"odinger equations where the nonlinearity is given by $F(u)=\\lambda|u|^p\nu$ for some $\\lambda \\in \\mathbb{R}$. So our results extend beyond the\nphysically relevant case $p=2$.", "AI": {"tldr": "The paper compares semigroup theory and Strichartz estimates for local well-posedness of solutions to the nonlinear Schr\u00f6dinger equation, extending results beyond the case p=2.", "motivation": "To explore and compare two mathematical approaches for solving the nonlinear Schr\u00f6dinger equation, which is key in quantum mechanics and Bose-Einstein condensation.", "method": "Uses semigroup theory (functional analysis) and Strichartz estimates (dispersive equations) to analyze local well-posedness.", "result": "Demonstrates the applicability of both methods to the equation with nonlinearity F(u)=\u03bb|u|^p u, extending beyond p=2.", "conclusion": "Both approaches are effective, with semigroup theory offering generality and Strichartz estimates providing refined techniques."}}
{"id": "2506.10723", "pdf": "https://arxiv.org/pdf/2506.10723", "abs": "https://arxiv.org/abs/2506.10723", "authors": ["Danilo Costarelli", "Donato Lavella"], "title": "Semi-discrete moduli of smoothness and their applications in one- and two- sided error estimates", "categories": ["math.NA", "cs.NA", "math.FA"], "comment": null, "summary": "In this paper, we introduce a new semi-discrete modulus of smoothness, which\ngeneralizes the definition given by Kolomoitsev and Lomako (KL) in 2023 (in the\npaper published in the J. Approx. Theory), and we establish very general one-\nand two- sided error estimates under non-restrictive assumptions. The proposed\nresults have been proved exploiting the regularization and approximation\nproperties of certain Steklov integrals introduced by Sendov and Popov in 1983,\nand differ from the ones given by Kolomoitsev and Lomako. In addition, the\nproof of the original KL approximation theorems were strictly related to the\napplication of certain classical results of the trigonometric best\napproximation, and thus, they are applicable only for operators of the\ntrigonometric type. By the definition of semi-discrete moduli of smoothness\nhere proposed, we are able to deduce applications also for operators that are\nnot necessarily of the trigonometric type, and can also be used to derive\nsharper estimates than those that can be achieved by the classical averaged\nmoduli of smoothness ($\\tau$-moduli). Furthermore, a Rathore-type theorem is\nestablished, and a new notion of K-functional is also introduced showing its\nequivalence with the semi-discrete modulus of smoothness and its realization.\nOne-sided estimates of approximation can be established for classical operators\non bounded domains, such as the Bernstein polynomials. In the case of\napproximation operators on the whole real line, one-sided estimates can be\nachieved, e.g., for the Shannon sampling (cardinal) series, as well as for the\nso-called generalized sampling operators. At the end of the paper, the case of\nalgebraic Lagrange approximation has been considered, showing the main open\nproblems in order to derive two-sided error estimates in this noteworthy case.", "AI": {"tldr": "The paper introduces a new semi-discrete modulus of smoothness, generalizing prior work, and provides broad error estimates using Steklov integrals. It extends applicability beyond trigonometric operators and offers sharper estimates than classical methods.", "motivation": "To generalize and improve upon the semi-discrete modulus of smoothness introduced by Kolomoitsev and Lomako, enabling broader applications and sharper error estimates.", "method": "Uses regularization and approximation properties of Steklov integrals, introduces a new K-functional, and establishes equivalence with the semi-discrete modulus.", "result": "Proves one- and two-sided error estimates for various operators, including non-trigonometric ones, and introduces a Rathore-type theorem.", "conclusion": "The new modulus and methods provide versatile tools for approximation theory, with open problems noted for algebraic Lagrange approximation."}}
{"id": "2506.10701", "pdf": "https://arxiv.org/pdf/2506.10701", "abs": "https://arxiv.org/abs/2506.10701", "authors": ["Simon Elias Schrader", "H\u00e5kon Emil Kristiansen", "Thomas Bondo Pedersen", "Simen Kvaal"], "title": "Time-dependent Gaussian basis sets for many-body systems using Rothe's method: A mean-field study", "categories": ["physics.chem-ph", "physics.comp-ph"], "comment": "18 pages, 9 figures", "summary": "A challenge in modeling time-dependent strong-field processes such as\nhigh-harmonic generation for many-body systems, is how to effectively represent\nthe electronic continuum. We apply Rothe's method to the time-dependent\nHartree-Fock (TDHF) and density functional theory (TDDFT) equations of motion\nfor the orbitals, which reformulates them as an optimization problem. We show\nthat thawed, complex-valued Gaussian basis sets can be propagated efficiently\nfor these orbital-based approaches, removing the need for grids. In particular,\nwe illustrate that qualitatively correct results can often be obtained by using\njust a few fully flexible Gaussians that describe the unbound dynamics for both\nTDHF and TDDFT. Grid calculations can be reproduced quantitatively using\n$30$--$100$ Gaussians for intensities up to $4\\times10^{14}$ W/cm$^2$ for the\none-dimensional molecular systems considered in this work.", "AI": {"tldr": "The paper proposes using Rothe's method with Gaussian basis sets to model time-dependent strong-field processes like high-harmonic generation, avoiding grids and achieving accurate results with fewer Gaussians.", "motivation": "The challenge lies in representing the electronic continuum for many-body systems in time-dependent processes.", "method": "Rothe's method is applied to TDHF and TDDFT equations, reformulating them as an optimization problem, and using thawed, complex-valued Gaussian basis sets.", "result": "Qualitatively correct results are achieved with few Gaussians, and grid calculations are quantitatively reproduced with 30\u2013100 Gaussians for intensities up to 4\u00d710\u00b9\u2074 W/cm\u00b2.", "conclusion": "The method efficiently models unbound dynamics for TDHF and TDDFT, reducing reliance on grids."}}
{"id": "2506.10608", "pdf": "https://arxiv.org/pdf/2506.10608", "abs": "https://arxiv.org/abs/2506.10608", "authors": ["Vedansh Arya", "Vesa Julin"], "title": "Harnack inequality for degenerate fully nonlinear parabolic equations", "categories": ["math.AP", "35K55, 35K65, 35B65"], "comment": null, "summary": "We consider degenerate fully nonlinear parabolic equations, which generalize\nthe p-parabolic equation with $p>2$ to nondivergence form operators. We prove\nan intrinsic Harnack inequality for nonnegative solutions and a weak Harnack\ninequality for nonnegative supersolutions. These results can be seen as the\nnondivergence form counterparts of the results by DiBenedetto, Gianazza and\nVespri (Acta Math. 2008) and Kuusi (Ann. Sc. Norm. Super. Pisa 2008).", "AI": {"tldr": "The paper proves intrinsic and weak Harnack inequalities for nonnegative solutions and supersolutions of degenerate fully nonlinear parabolic equations, extending results from divergence form to nondivergence form.", "motivation": "To generalize the p-parabolic equation (p>2) to nondivergence form operators and establish Harnack inequalities, bridging a gap in existing literature.", "method": "The authors analyze degenerate fully nonlinear parabolic equations, focusing on nonnegative solutions and supersolutions.", "result": "Proven intrinsic Harnack inequality for solutions and weak Harnack inequality for supersolutions, analogous to prior divergence form results.", "conclusion": "The findings extend known results to nondivergence form, providing a foundation for further study in nonlinear parabolic equations."}}
{"id": "2506.10763", "pdf": "https://arxiv.org/pdf/2506.10763", "abs": "https://arxiv.org/abs/2506.10763", "authors": ["Mejdi Aza\u00efez", "Tom\u00e1s Chac\u00f3n Rebollo", "Carlos N\u00fa\u00f1ez Fern\u00e1ndez", "Samuele Rubino"], "title": "Reduced-Order Time Splitting for Navier-Stokes with Open Boundaries", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this work, we propose a Proper Orthogonal Decomposition-Reduced Order\nModel (POD-ROM) applied to time-splitting schemes for solving the Navier-Stokes\nequations with open boundary conditions. In this method, we combine three\nstrategies to reduce the computing time to solve NSE: time splitting, reduction\nof the computational domain through non-standard treatment of open boundary\nconditions and reduced order modelling. To make the work self-contained, we\nfirst present the formulation of the time-splitting scheme applied to the\nNavier-Stokes equations with open boundary conditions, employing a first-order\nEuler time discretization and deriving the non-standard boundary condition for\npressure. Then, we construct a Galerkin projection-based ROM using POD with two\ndifferent treatments of the pressure boundary condition on the outlet. We\npropose a comparative performance analysis between the standard\nprojection-based POD-ROM (fully intrusive) and a hybrid POD-ROM that combines a\nprojection-based approach (intrusive) with a data-driven technique\n(non-intrusive) using Radial Basis Functions (RBF). We illustrate this\ncomparison through two different numerical tests: the flow in a bifurcated tube\nand the benchmark numerical test of the flow past cylinder, numerically\ninvestigating the efficiency and accuracy of both ROMs.", "AI": {"tldr": "The paper proposes a POD-ROM combined with time-splitting schemes for solving Navier-Stokes equations with open boundary conditions, comparing intrusive and hybrid ROM approaches.", "motivation": "To reduce computational time for solving Navier-Stokes equations by combining time splitting, domain reduction, and reduced order modeling.", "method": "Combines time-splitting, non-standard boundary treatment, and POD-ROM with Galerkin projection, comparing intrusive and hybrid (RBF-based) approaches.", "result": "Numerical tests (bifurcated tube and flow past cylinder) show efficiency and accuracy of both ROMs.", "conclusion": "The hybrid POD-ROM offers a promising balance between accuracy and computational efficiency."}}
{"id": "2506.10794", "pdf": "https://arxiv.org/pdf/2506.10794", "abs": "https://arxiv.org/abs/2506.10794", "authors": ["Clint van Hoesel", "Reinder Coehoorn", "Peter A. Bobbert"], "title": "Dipole-quadrupole coupling in triplet exciton-polaron quenching in a phosphorescent OLED emission layer", "categories": ["physics.atm-clus", "physics.chem-ph", "physics.comp-ph"], "comment": "15 pages, 8 figures", "summary": "Improving the efficiency and stability of organic light-emitting diodes\n(OLEDs) will further expand their present success in display applications.\nTriplet exciton-polaron quenching (TPQ) is an important cause of limited\nefficiency and stability in modern phosphorescent OLEDs, where triplet excitons\nare the emitting species. Lack of understanding of the TPQ mechanism in these\nOLEDs impedes the development of more efficient and stable OLEDs. We\ninvestigate the TPQ mechanism for triplet excitons on a phosphorescent guest\ninteracting with hole polarons on a host. Our quantum-chemical calculations\nshow that at distances relevant for TPQ the F\\\"orster approximation for the TPQ\nrate fails and that dipole-quadrupole coupling is dominant. This resolves a\ndiscrepancy between estimates of the TPQ rate obtained from an OLED device\nstudy and from the overlap between the emission spectrum of the emitter and\nabsorption spectrum of the charged host. Equivalently to the F\\\"orster radius\nfor dipole-dipole TPQ, the dipole-quadrupole TPQ rate can be quantified by a\ndipole-quadrupole radius obtained from the overlap between the emission\nspectrum of the emitter and the quadrupolar absorption spectrum of the charged\nhost. The findings of this work are expected to have a broad relevance and to\nbe useful in developing phosphorescent emitter-host combinations with reduced\nTPQ.", "AI": {"tldr": "The paper investigates the triplet exciton-polaron quenching (TPQ) mechanism in phosphorescent OLEDs, revealing dipole-quadrupole coupling as dominant, resolving prior discrepancies and aiding future OLED development.", "motivation": "Understanding TPQ is crucial for improving OLED efficiency and stability, but the mechanism was unclear, hindering progress.", "method": "Quantum-chemical calculations were used to analyze TPQ rates, comparing F\u00f6rster approximation with dipole-quadrupole coupling.", "result": "Dipole-quadrupole coupling dominates TPQ, resolving discrepancies in rate estimates and enabling quantification via a dipole-quadrupole radius.", "conclusion": "The findings provide a foundation for developing phosphorescent emitter-host combinations with reduced TPQ, enhancing OLED performance."}}
{"id": "2506.10611", "pdf": "https://arxiv.org/pdf/2506.10611", "abs": "https://arxiv.org/abs/2506.10611", "authors": ["Mokhtar Kirane", "Ahmad Z. Fino", "Berikbol T. Torebek", "Zineb Sabbagh"], "title": "Cazenave-Dickstein-Weissler-type extension of Fujita's problem on Heisenberg groups", "categories": ["math.AP"], "comment": "21 pages", "summary": "This paper examines the critical exponents for the existence of global\nsolutions to the equation \\begin{equation*} \\begin{array}{ll} \\displaystyle\nu_t-\\Delta_{\\mathbb{H}}u=\\int_0^t(t-s)^{-\\gamma}|u(s)|^{p-1}u(s)\\,ds,&\\qquad\n0\\leq\\gamma<1,\\,\\,\\, {\\eta\\in \\mathbb{H}^n,\\,\\,\\,t>0,}\n\\end{array}\\end{equation*} on the Heisenberg groups $\\mathbb{H}^n.$ There\nexists a critical exponent $$p_c=\n\\max\\Big\\{\\frac{1}{\\gamma},p_\\gamma\\Big\\}\\in(0,+\\infty],\\quad\\hbox{with}\\quad\np_\\gamma=1+\\frac{2(2-\\gamma)}{Q-2+2\\gamma},\\,\\,Q=2n+2$$ such that for all\n$1<p\\leq p_c,$ no global solution exists regardless of the non-negative initial\ndata, while for $p>p_c$, a global positive solution exists if the initial data\nis sufficiently small. The results obtained are a natural extension of the\nresults of Cazenave et al. [Nonlinear Analysis 68 (2008), 862-874], where\nsimilar studies were carried out in $\\mathbb{R}^n$. Also given are several\ntheorems concerning the lifespan estimates of local solutions for different\ncases of initial data. The proofs of the main results are based on test\nfunction methods and Banach fixed point principle.", "AI": {"tldr": "The paper determines critical exponents for global solutions of a PDE on Heisenberg groups, extending prior work in Euclidean space.", "motivation": "To extend understanding of critical exponents for global solutions from Euclidean space to Heisenberg groups.", "method": "Uses test function methods and Banach fixed point principle to analyze the PDE.", "result": "For p \u2264 p_c, no global solutions exist; for p > p_c, small initial data yields global solutions.", "conclusion": "The study generalizes prior results and provides lifespan estimates for local solutions."}}
{"id": "2506.10820", "pdf": "https://arxiv.org/pdf/2506.10820", "abs": "https://arxiv.org/abs/2506.10820", "authors": ["Subhash Paudel", "Nail K. Yamaleev"], "title": "A Combined Parallel-in-time Direct Inverse (ParaDIn)-Parareal Method for Nonlinear Differential Equations", "categories": ["math.NA", "cs.NA", "65M06, 65F05, 65Y05"], "comment": "24 pages. arXiv admin note: text overlap with arXiv:2406.00878", "summary": "As has been shown in our previous work, the parallel-in-time direct inverse\n(ParaDIn) method introduced by Yamaleev and Paudel in (arXiv: 2406.00878v1,\n2024) imposes some constraint on the maximum number of time levels, $N_t$, that\ncan be integrated in parallel. To circumvent this problem and further increase\nthe speedup, we combine the ParaDIn method with the Parareal algorithm to\nefficiently parallelize the first-order time derivative term in nonlinear\npartial differential equations discretized by the method of lines. The main\nidea of the proposed approach is to use a block-Jacobi preconditioner, so that\neach block is solved by using the ParaDIn method. To accelerate the convergence\nof Jacobi iterations, we use the Parareal method which can be interpreted as a\ntwo-level multigrid method in time. In contrast to the conventional Parareal\nalgorithm whose coarse grid correction step is performed sequentially, both the\ncoarse- and fine-grid propagators in the proposed approach are implemented in\nparallel by using the ParaDIn method, thus significantly increasing the\nparallel performance of the combined algorithm. Numerical results show that the\nnew combined ParaDIn-Parareal method provides the speedup of up to 124 on 480\ncomputing cores as compared with the sequential first-order implicit backward\ndifference (BDF1) scheme for the 2-D nonlinear heat and Burgers equations with\nboth smooth and discontinuous solutions.", "AI": {"tldr": "The paper combines the ParaDIn method with the Parareal algorithm to enhance parallelization of nonlinear PDEs, achieving a speedup of 124 on 480 cores.", "motivation": "The ParaDIn method has constraints on parallel time levels. The goal is to overcome this and improve speedup by integrating it with the Parareal algorithm.", "method": "A block-Jacobi preconditioner is used, with each block solved via ParaDIn. The Parareal method accelerates Jacobi iterations, acting as a two-level multigrid in time. Both coarse- and fine-grid propagators are parallelized using ParaDIn.", "result": "The combined ParaDIn-Parareal method achieves a speedup of 124 on 480 cores for 2-D nonlinear heat and Burgers equations, outperforming the sequential BDF1 scheme.", "conclusion": "The hybrid approach significantly boosts parallel performance for solving nonlinear PDEs, demonstrating practical efficiency for both smooth and discontinuous solutions."}}
{"id": "2506.10812", "pdf": "https://arxiv.org/pdf/2506.10812", "abs": "https://arxiv.org/abs/2506.10812", "authors": ["S. Rendon Restrepo", "T. Rometsch", "U. Ziegler", "O. Gressel"], "title": "Self-gravity in thin protoplanetary discs: 1. The smoothing-length approximation versus the exact self-gravity kernel", "categories": ["astro-ph.EP", "astro-ph.IM", "physics.comp-ph"], "comment": null, "summary": "Planet-forming discs often contain structures like spiral arms, typically\nlinked to the disc's gravitational forces. In 2D models, an ad hoc softening\nprescription is commonly used for self-gravity, but this overlooks the vertical\nstructure's impact, suppresses the Newtonian nature of gravity at short\ndistances and doesn't respect Newton's third law.\n  To address these issues, associated with a Plummer potential approximation,\nwe developed an exact self-gravity kernel for thin, hydrostatically supported\ndiscs, including a dust fluid component. Our analytical framework provides a\nprecise 2D self-gravity prescription validated by benchmarks and 2D/3D\nnumerical tests.\n  The derived kernel, based on modified Bessel functions, maintains Newtonian\ngravitation features, such as point-wise symmetry, a smooth transition from\nlight to massive discs and a singularity at zero distance, among others. In\ncontrast to other prescriptions found in the literature, it proves capable of\nleading to an additional, and previously unnoticed, source of gravitational\nrunaway discernible only at infinitesimal distances.\n  We finally note that our new prescription remains compatible with methods\nbased on the fast Fourier transform, affording superior computational\nefficiency. Our exact kernel formulation overcomes substantial limitations\ninherent in the smoothing-length approach. It permits a novel, fully consistent\ntreatment of self-gravity in Gaussian-stratified thin discs. The approach, that\nmakes the usage of the Plummer potential obsolete, will prove useful to\nstudying all common planet formation scenarios, which are often backed by\n2D-flat numerical simulations. Accordingly, in an accompanying paper, we will\ninvestigate how the occurence of the gravitational instability is affected.", "AI": {"tldr": "The paper introduces an exact self-gravity kernel for thin, hydrostatically supported discs, addressing flaws in the ad hoc softening prescription used in 2D models. The kernel maintains Newtonian gravitation features and offers computational efficiency.", "motivation": "Current 2D models use an ad hoc softening prescription for self-gravity, which neglects vertical structure, suppresses Newtonian gravity at short distances, and violates Newton's third law.", "method": "Developed an exact self-gravity kernel for thin discs, validated through benchmarks and 2D/3D numerical tests, using modified Bessel functions.", "result": "The kernel preserves Newtonian features, reveals a new gravitational runaway source, and is computationally efficient via fast Fourier transform.", "conclusion": "The new kernel overcomes limitations of the smoothing-length approach, enabling consistent self-gravity treatment in thin discs and advancing planet formation studies."}}
{"id": "2506.10761", "pdf": "https://arxiv.org/pdf/2506.10761", "abs": "https://arxiv.org/abs/2506.10761", "authors": ["Dominik Schlagenhauf"], "title": "Stability of the Morse Index for the $p$-harmonic Approximation of Harmonic Maps into Homogeneous Spaces", "categories": ["math.AP", "35J92, 58E05, 35J50, 35J47, 58E12, 58E20, 53A10, 53C43"], "comment": "arXiv admin note: text overlap with arXiv:2502.09600", "summary": "In the joint work of the author with Da Lio and Rivi\\`ere (Morse Index\nStability for Sequences of Sacks-Uhlenbeck Maps into a Sphere) we studied the\nstability of the Morse index for Sacks-Uhlenbeck sequences into spheres as\n$p\\searrow2$. These are critical points of the energy $E_p(u) := \\int_\\Sigma\n\\left( 1+|\\nabla u|^2\\right)^{p/2} \\ dvol_\\Sigma,$ where $u:\\Sigma \\rightarrow\nS^n$ is a map from a closed Riemannian surface $\\Sigma$ into a sphere $ S^n$.\nIn this paper we extend the results found in our previous work to the case of\nSacks-Uhlenbeck sequences into homogeneous spaces, by incorporating the\nstrategy introduced by Bayer and Roberts (Energy identity and no neck property\nfor $\\epsilon$-harmonic and $\\alpha$-harmonic maps into homogeneous target\nmanifolds). In the spirit of the work of Da Lio, Gianocca and Rivi\\`ere (Morse\nIndex Stability for Critical Points to Conformally invariant Lagrangians), we\nshow in this setting the upper semicontinuity of the Morse index plus nullity\nand an improved pointwise estimate of the gradient in the neck regions around\nblow up points.", "AI": {"tldr": "The paper extends Morse index stability results for Sacks-Uhlenbeck sequences from spheres to homogeneous spaces, using methods from prior works to show upper semicontinuity of the Morse index plus nullity and improved gradient estimates in neck regions.", "motivation": "To generalize previous findings on Morse index stability for Sacks-Uhlenbeck sequences into spheres to the broader context of homogeneous spaces, leveraging insights from related research.", "method": "Extends prior results by incorporating strategies from Bayer and Roberts for homogeneous target manifolds, focusing on upper semicontinuity of the Morse index plus nullity and gradient estimates in neck regions.", "result": "Demonstrates upper semicontinuity of the Morse index plus nullity and provides refined pointwise gradient estimates in neck regions around blow-up points.", "conclusion": "The study successfully generalizes Morse index stability to homogeneous spaces, enhancing understanding of critical points in conformally invariant Lagrangians."}}
{"id": "2506.10894", "pdf": "https://arxiv.org/pdf/2506.10894", "abs": "https://arxiv.org/abs/2506.10894", "authors": ["Pedro B. Bazon", "Cristian G. Gebhardt", "Gustavo C. Buscaglia", "Roberto F. Ausas"], "title": "Numerical approximation of a PDE-constrained Optimization problem that appears in Data-Driven Computational Mechanics", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We investigate an optimization problem that arises when working within the\nparadigm of Data-Driven Computational Mechanics. In the context of the\ndiffusion-reaction problem, such an optimization problem seeks for the\ncontinuous primal fields (gradient and flux) that are closest to some\npredefined discrete fields taken from a material data set. The optimization is\nperformed over primal fields that satisfy the physical conservation law and the\ngeometrical compatibility. We consider a reaction term in the conservation law,\nwhich has the effect of coupling all the optimality conditions. We first\nestablish the well-posedness in the continuous setting. Then, we propose stable\nfinite element discretizations that consistently approximate the continuous\nformulation, preserving its saddle-point structure and allowing for equal-order\ninterpolation of all fields. Finally, we demonstrate the effectiveness of the\nproposed methods through a set of numerical examples.", "AI": {"tldr": "The paper addresses an optimization problem in Data-Driven Computational Mechanics, focusing on primal fields in diffusion-reaction problems, ensuring physical and geometric constraints. It proves well-posedness, proposes stable finite element methods, and validates with numerical examples.", "motivation": "The study aims to solve optimization problems for primal fields in diffusion-reaction scenarios, ensuring adherence to physical laws and compatibility, which is crucial for accurate material modeling.", "method": "The approach involves continuous primal field optimization, ensuring conservation and compatibility, with stable finite element discretizations preserving the saddle-point structure and allowing equal-order interpolation.", "result": "The paper establishes well-posedness in the continuous setting and demonstrates effective numerical results through stable finite element approximations.", "conclusion": "The proposed methods effectively solve the optimization problem, maintaining physical and geometric constraints, and are validated by numerical examples."}}
{"id": "2506.10944", "pdf": "https://arxiv.org/pdf/2506.10944", "abs": "https://arxiv.org/abs/2506.10944", "authors": ["Jingxuan Ding", "Laura Zichi", "Matteo Carli", "Menghang Wang", "Albert Musaelian", "Yu Xie", "Boris Kozinsky"], "title": "Coupled reaction and diffusion governing interface evolution in solid-state batteries", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Understanding and controlling the atomistic-level reactions governing the\nformation of the solid-electrolyte interphase (SEI) is crucial for the\nviability of next-generation solid state batteries. However, challenges persist\ndue to difficulties in experimentally characterizing buried interfaces and\nlimits in simulation speed and accuracy. We conduct large-scale explicit\nreactive simulations with quantum accuracy for a symmetric battery cell,\n{\\symcell}, enabled by active learning and deep equivariant neural network\ninteratomic potentials. To automatically characterize the coupled reactions and\ninterdiffusion at the interface, we formulate and use unsupervised\nclassification techniques based on clustering in the space of local atomic\nenvironments. Our analysis reveals the formation of a previously unreported\ncrystalline disordered phase, Li$_2$S$_{0.72}$P$_{0.14}$Cl$_{0.14}$, in the\nSEI, that evaded previous predictions based purely on thermodynamics,\nunderscoring the importance of explicit modeling of full reaction and transport\nkinetics. Our simulations agree with and explain experimental observations of\nthe SEI formations and elucidate the Li creep mechanisms, critical to dendrite\ninitiation, characterized by significant Li motion along the interface. Our\napproach is to crease a digital twin from first principles, without adjustable\nparameters fitted to experiment. As such, it offers capabilities to gain\ninsights into atomistic dynamics governing complex heterogeneous processes in\nsolid-state synthesis and electrochemistry.", "AI": {"tldr": "The paper presents a method for simulating and analyzing the formation of the solid-electrolyte interphase (SEI) in solid-state batteries using quantum-accurate reactive simulations and unsupervised classification techniques. It reveals a new crystalline disordered phase in the SEI and explains experimental observations.", "motivation": "Understanding and controlling atomistic-level reactions in SEI formation is critical for next-generation solid-state batteries, but experimental and simulation challenges persist.", "method": "Large-scale explicit reactive simulations with quantum accuracy, enabled by active learning and deep equivariant neural network interatomic potentials, combined with unsupervised classification techniques.", "result": "Discovery of a previously unreported crystalline disordered phase (Li$_2$S$_{0.72}$P$_{0.14}$Cl$_{0.14}$) in the SEI and explanation of Li creep mechanisms critical to dendrite initiation.", "conclusion": "The approach provides a parameter-free digital twin for studying atomistic dynamics in solid-state synthesis and electrochemistry, offering insights into complex heterogeneous processes."}}
{"id": "2506.10839", "pdf": "https://arxiv.org/pdf/2506.10839", "abs": "https://arxiv.org/abs/2506.10839", "authors": ["Filip Ficek", "Maciej Maliborski"], "title": "New class of time-periodic solutions to the 1D cubic wave equation", "categories": ["math.AP", "math-ph", "math.MP", "35B10, 68V05, 35B32, 35L71"], "comment": "18 pages, 2 figures. Includes Mathematica code and data files", "summary": "In recent papers (arXiv:2407.16507, arXiv:2408.05158) we presented results\nsuggesting the existence of a new class of time-periodic solutions to the\ndefocusing cubic wave equation on a one-dimensional interval with Dirichlet\nboundary conditions. Here we confirm these findings by rigorously constructing\nsolutions from this class. The proof uses rational arithmetic computations to\nverify essential operator bounds.", "AI": {"tldr": "The paper confirms the existence of a new class of time-periodic solutions for the defocusing cubic wave equation on a 1D interval with Dirichlet boundary conditions, using rigorous construction and rational arithmetic computations.", "motivation": "To validate earlier findings suggesting new time-periodic solutions for the defocusing cubic wave equation.", "method": "Rigorous construction of solutions using rational arithmetic computations to verify operator bounds.", "result": "Existence of the new class of time-periodic solutions is confirmed.", "conclusion": "The study successfully confirms the existence of these solutions, supporting prior theoretical suggestions."}}
{"id": "2506.10935", "pdf": "https://arxiv.org/pdf/2506.10935", "abs": "https://arxiv.org/abs/2506.10935", "authors": ["Ekaterina Grishina", "Matvey Smirnov", "Maxim Rakhuba"], "title": "Accelerating Newton-Schulz Iteration for Orthogonalization via Chebyshev-type Polynomials", "categories": ["math.NA", "cs.NA", "65F25, 65F60, 53Z50, 68W25"], "comment": null, "summary": "The problem of computing optimal orthogonal approximation to a given matrix\nhas attracted growing interest in machine learning. Notable applications\ninclude the recent Muon optimizer or Riemannian optimization on the Stiefel\nmanifold. Among existing approaches, the Newton-Schulz iteration has emerged as\na particularly effective solution, as it relies solely on matrix\nmultiplications and thus achieves high computational efficiency on GPU\nhardware. Despite its efficiency, the method has inherent limitations - its\ncoefficients are fixed and thus not optimized for a given matrix. In this paper\nwe address this issue by proposing a Chebyshev-optimized version of\nNewton-Schulz (CANS). Based on the Chebyshev's alternance theorem, we\ntheoretically derive optimal coefficients for the 3-rd order Newton-Schulz\niteration and apply a Remez algorithm to compute optimal higher-degree\npolynomials. We leverage these polynomials to construct controlled approximate\northogonalization schemes, which is of interest in deep learning applications.\nPractically, we demonstrate the method's effectiveness in two key applications:\northogonalization in the Muon optimizer, and providing an efficient retraction\nalternative for Riemannian optimization on the Stiefel manifold.", "AI": {"tldr": "The paper introduces CANS, a Chebyshev-optimized version of the Newton-Schulz iteration, to improve orthogonal matrix approximation by deriving optimal coefficients and applying higher-degree polynomials.", "motivation": "Existing Newton-Schulz iteration lacks optimized coefficients for specific matrices, limiting its efficiency.", "method": "The authors use Chebyshev's alternance theorem to derive optimal coefficients for 3rd-order iterations and apply the Remez algorithm for higher-degree polynomials.", "result": "CANS enhances orthogonalization in applications like the Muon optimizer and Riemannian optimization on the Stiefel manifold.", "conclusion": "CANS offers a more efficient and controlled approach to orthogonal approximation, benefiting deep learning and optimization tasks."}}
{"id": "2506.10870", "pdf": "https://arxiv.org/pdf/2506.10870", "abs": "https://arxiv.org/abs/2506.10870", "authors": ["Yuxin Li", "Meijie Yang", "Xiaojun Chang"], "title": "Normalized solutions for a Sobolev critical quasilinear Schr\u00f6dinger equation", "categories": ["math.AP"], "comment": "57pages", "summary": "In this paper, we study the existence of normalized solutions for the\nfollowing quasilinear Schr\\\"odinger equation with critical exponent:\n  \\begin{equation*}\n  -\\Delta u-u\\Delta (u^2)+\\lambda\nu=\\tau|u|^{q-2}u+|u|^{2\\cdot2^*-2}u,~~~~x\\in\\R^N,\n  \\end{equation*}\n  under the mass constraint $\\int_{\\R^N}|u|^2dx=c$ for some prescribed $c>0$.\nHere $\\tau\\in \\mathbb{R}$ is a parameter, $\\lambda\\in\\R$ appears as a Lagrange\nmultiplier, $N\\ge3$, $2^*:=\\frac{2N}{N-2}$ and $2<q<2\\cdot2^*$. By deriving\nprecise energy level estimates and establishing new convergence theorems, we\napply the perturbation method to establish several existence results for\n$\\tau>0$ in the Sobolev critical regime:\n  [label=(\\alph*)]\n  \\item For the case of $2<q<2+\\frac{4}{N}$, we obtain the existence of two\nsolutions, one of which is a local minimizer, and the other is a mountain pass\ntype solution, under explicit conditions on $c>0$;\n  \\item For the case of $2+\\frac{4}{N}\\leq q<4+\\frac{4}{N}$, we obtain the\nexistence of normalized solutions of mountain pass type under different\nconditions on $c>0$;\n  \\item For the case of $4+\\frac{4}{N}\\leq q<2\\cdot2^*$, we obtain the\nexistence of a ground state normalized solution under different conditions on\n$c>0$. Moreover, when $\\tau\\le 0$, we derive the non-existence result for\n$2<q<2\\cdot2^*$ and all $c>0$. Our research provides a comprehensive analysis\nacross the entire range $q\\in(2, 2 \\cdot 2^*)$ and for all $N\\ge3$. The methods\nwe have developed are flexible and can be extended to a broader class of\nnonlinearities.", "AI": {"tldr": "The paper studies normalized solutions for a quasilinear Schr\u00f6dinger equation with critical exponent, providing existence results for different parameter ranges and deriving non-existence conditions.", "motivation": "To address the existence of normalized solutions under mass constraints for a critical quasilinear Schr\u00f6dinger equation, filling gaps in the analysis for the entire range of parameters.", "method": "Uses energy level estimates, convergence theorems, and perturbation methods to derive existence results for various cases of the parameter q.", "result": "Existence of solutions (local minimizer, mountain pass type, ground state) is proven for specific ranges of q and c, with non-existence shown for \u03c4 \u2264 0.", "conclusion": "The study offers a complete analysis for q \u2208 (2, 2\u00b72^*) and N \u2265 3, with adaptable methods for broader nonlinearities."}}
{"id": "2506.10224", "pdf": "https://arxiv.org/pdf/2506.10224", "abs": "https://arxiv.org/abs/2506.10224", "authors": ["Alejandro N Diaz", "Shane A McQuarrie", "John T Tencer", "Patrick J Blonigan"], "title": "Interpretable and flexible non-intrusive reduced-order models using reproducing kernel Hilbert spaces", "categories": ["cs.CE", "cs.NA", "math.NA", "65D05, 46E22, 62J05", "G.1.0"], "comment": null, "summary": "This paper develops an interpretable, non-intrusive reduced-order modeling\ntechnique using regularized kernel interpolation. Existing non-intrusive\napproaches approximate the dynamics of a reduced-order model (ROM) by solving a\ndata-driven least-squares regression problem for low-dimensional matrix\noperators. Our approach instead leverages regularized kernel interpolation,\nwhich yields an optimal approximation of the ROM dynamics from a user-defined\nreproducing kernel Hilbert space. We show that our kernel-based approach can\nproduce interpretable ROMs whose structure mirrors full-order model structure\nby embedding judiciously chosen feature maps into the kernel. The approach is\nflexible and allows a combination of informed structure through feature maps\nand closure terms via more general nonlinear terms in the kernel. We also\nderive a computable a posteriori error bound that combines standard error\nestimates for intrusive projection-based ROMs and kernel interpolants. The\napproach is demonstrated in several numerical experiments that include\ncomparisons to operator inference using both proper orthogonal decomposition\nand quadratic manifold dimension reduction.", "AI": {"tldr": "The paper introduces a non-intrusive reduced-order modeling technique using regularized kernel interpolation, offering interpretability and flexibility by combining feature maps and nonlinear terms.", "motivation": "Existing non-intrusive methods lack interpretability and flexibility. This work aims to address these gaps by leveraging kernel interpolation for better ROM dynamics approximation.", "method": "The technique uses regularized kernel interpolation to approximate ROM dynamics, incorporating feature maps for structure and nonlinear terms for closure. It also provides an a posteriori error bound.", "result": "The approach produces interpretable ROMs that mirror full-order model structure and outperforms operator inference methods in numerical experiments.", "conclusion": "The kernel-based method is effective, flexible, and interpretable, with demonstrated superiority over existing techniques in numerical tests."}}
{"id": "2506.10321", "pdf": "https://arxiv.org/pdf/2506.10321", "abs": "https://arxiv.org/abs/2506.10321", "authors": ["Jorge Zuniga"], "title": "Fast Ramanujan--type Series for Logarithms. Part II", "categories": ["math.NT", "cs.NA", "math.NA", "65B10 33C20 33C90 90C11 65C05 91G60"], "comment": "17 pages, 1 table. TeX file must be downloaded, PARI GP program is\n  embedded as a large comment there", "summary": "This work extends the results of the preprint Ramanujan type Series for\nLogarithms, Part I, arXiv:2506.08245, which introduced single hypergeometric\ntype identities for the efficient computing of $\\log(p)$, where\n$p\\in\\mathbb{Z}_{>1}$. We present novel formulas for arctangents and methods\nfor a very fast multiseries evaluation of logarithms. Building upon a\n$\\mathcal{O}((p-1)^{6})$ Ramanujan type series asymptotic approximation for\n$\\log(p)$ as $p\\rightarrow1$, formulas for computing $n$ simultaneous\nlogarithms are developed. These formulas are derived by solving an integer\nprogramming problem to identify optimal variable values within a finite lattice\n$\\mathbb{Z}^{n}$. This approach yields linear combinations of series that\nprovide: (i) highly efficient formulas for single logarithms of natural numbers\nand (ii) the fastest known hypergeometric formulas for multivalued logarithms\nof $n$ selected integers in $\\mathbb{Z}_{>1}$. An application of these results\nwas to extend the number of decimal places known for log(10) up to\n2.0$\\cdot$10$^{12}$ digits (June 06 2025).", "AI": {"tldr": "The paper extends methods for computing logarithms and arctangents, introducing efficient hypergeometric formulas and solving integer programming problems to optimize series evaluations.", "motivation": "To improve the computational efficiency of logarithms and arctangents, particularly for multiple values simultaneously.", "method": "Uses Ramanujan-type series and integer programming to derive optimal formulas for evaluating logarithms and arctangents.", "result": "Developed highly efficient formulas for single and multivalued logarithms, achieving record precision for log(10).", "conclusion": "The approach significantly advances the speed and precision of logarithmic computations, with practical applications in high-precision calculations."}}
{"id": "2506.10466", "pdf": "https://arxiv.org/pdf/2506.10466", "abs": "https://arxiv.org/abs/2506.10466", "authors": ["Larissa Fardigola", "Kateryna Khalina"], "title": "Approximate Controllability Problems for the Heat Equation in a Half-Plane Controlled by the Dirichlet Boundary Condition with a Bounded Control", "categories": ["math.OC", "math.AP"], "comment": "arXiv admin note: text overlap with arXiv:2409.10169", "summary": "In the paper, the problems of approximate controllability are studied for the\ncontrol system $w_t=\\Delta w$, $w(0,x_2,t)=u(x_2,t)$, $x_1\\in\\mathbb\nR_+=(0,+\\infty)$, $x_2\\in\\mathbb R$, $t\\in(0,T)$, where $u$ is a control\nbelonging to a special subset of $L^\\infty(\\mathbb R\\times (0,T))\\cap\nL^2(\\mathbb R\\times (0,T))$. It is proved that each initial state belonging to\n$L^2(\\mathbb R_+\\times\\mathbb R)$ is approximately controllable to an arbitrary\nend state belonging to $L^2(\\mathbb R_+\\times\\mathbb R)$ by applying these\ncontrols. A numerical algorithm of solving the approximate controllability\nproblem for this system is given. The results are illustrated by an example.", "AI": {"tldr": "The paper studies approximate controllability for a heat equation system, proving controllability between initial and end states in $L^2$ space, and provides a numerical algorithm with an example.", "motivation": "To address the controllability of a heat equation system with boundary controls, ensuring practical applicability through theoretical proofs and numerical methods.", "method": "Theoretical analysis of the control system and development of a numerical algorithm to solve the approximate controllability problem.", "result": "Initial states in $L^2$ space are approximately controllable to arbitrary end states in the same space using specific controls.", "conclusion": "The study successfully demonstrates controllability and provides a practical numerical solution, validated by an example."}}
{"id": "2506.10506", "pdf": "https://arxiv.org/pdf/2506.10506", "abs": "https://arxiv.org/abs/2506.10506", "authors": ["Manfred Opper", "Sebastian Reich"], "title": "On a mean-field Pontryagin minimum principle for stochastic optimal control", "categories": ["math.OC", "cs.NA", "math.NA", "35F21, 49M99, 93E20, 70H30, 70H45"], "comment": null, "summary": "This papers outlines a novel extension of the classical Pontryagin minimum\n(maximum) principle to stochastic optimal control problems. Contrary to the\nwell-known stochastic Pontryagin minimum principle involving forward-backward\nstochastic differential equations, the proposed formulation is deterministic\nand of mean-field type. The Hamiltonian structure of the proposed Pontryagin\nminimum principle is achieved via the introduction of an appropriate gauge\nvariable. The gauge freedom can be used to decouple the forward and reverse\ntime equations; hence simplifying the solution of the underlying boundary value\nproblem. We also consider infinite horizon discounted cost optimal control\nproblems. In this case, the mean-field formulation allows converting the\ncomputation of the desired optimal control law into solving a pair of forward\nmean-field ordinary differential equations. The proposed mean-field formulation\nof the Pontryagin minimum principle is tested numerically for a controlled\ninverted pendulum and a controlled Lorenz-63 system.", "AI": {"tldr": "A deterministic, mean-field extension of the Pontryagin minimum principle for stochastic optimal control, simplifying boundary value problems via gauge variables and tested on inverted pendulum and Lorenz-63 systems.", "motivation": "To address stochastic optimal control problems with a deterministic, mean-field approach, avoiding the complexity of forward-backward stochastic differential equations.", "method": "Introduces a gauge variable to achieve Hamiltonian structure, decoupling forward and reverse time equations, and applies mean-field ordinary differential equations for infinite horizon problems.", "result": "The method simplifies boundary value problems and is validated numerically on controlled inverted pendulum and Lorenz-63 systems.", "conclusion": "The proposed mean-field Pontryagin minimum principle offers a computationally efficient alternative for stochastic optimal control problems."}}
{"id": "2506.10623", "pdf": "https://arxiv.org/pdf/2506.10623", "abs": "https://arxiv.org/abs/2506.10623", "authors": ["Julien Berestycki", "David Geldbach", "Michel Pain"], "title": "Polynomial slowdown in space-inhomogeneous branching Brownian motion", "categories": ["math.PR", "math.AP", "60J80, 60J65, 35R99"], "comment": "53 pages, 4 figures", "summary": "We consider a branching Brownian motion in $\\mathbb{R}^2$ in which particles\nindependently diffuse as standard Brownian motions and branch at an\ninhomogeneous rate $b(\\theta)$ which depends only on the angle $\\theta$ of the\nparticle. We assume that $b$ is maximal when $\\theta=0$, which is the preferred\ndirection for breeding. Furthermore we assume that $b(\\theta ) = 1 - \\beta\n\\abs{\\theta }^\\alpha + O(\\theta ^2)$, as $\\theta \\to 0$, for $\\alpha \\in\n(2/3,2)$ and $\\beta>0.$ We show that if $M_t$ is the maximum distance to the\norigin at time $t$, then $(M_t-m(t))_{t\\ge 1}$ is tight where $$m(t) = \\sqrt{2}\nt - \\frac{\\vartheta_1}{\\sqrt{2}} t^{(2-\\alpha)/(2+\\alpha)} -\n\\left(\\frac{3}{2\\sqrt{2}} - \\frac{\\alpha}{2\\sqrt{2}(2+\\alpha)}\\right) \\log t.\n$$ and $\\vartheta_1$ is explicit in terms of the first eigenvalue of a certain\noperator.", "AI": {"tldr": "The paper studies a 2D branching Brownian motion with angle-dependent branching rates, showing tightness of the maximum distance from the origin after adjusting for a deterministic growth function.", "motivation": "To understand how inhomogeneous branching rates, particularly favoring a specific direction, affect the spatial spread of particles in branching Brownian motion.", "method": "Analyzes a branching Brownian motion model in \u211d\u00b2 with angle-dependent branching rate b(\u03b8), focusing on asymptotic behavior of the maximum distance M_t. Derives a deterministic correction term m(t) for M_t.", "result": "Proves tightness of (M_t - m(t)) for large t, where m(t) includes explicit terms involving the branching rate's parameters and an eigenvalue.", "conclusion": "The study provides precise growth rates for the maximum distance in inhomogeneous branching Brownian motion, linking it to the branching rate's properties."}}
{"id": "2506.10711", "pdf": "https://arxiv.org/pdf/2506.10711", "abs": "https://arxiv.org/abs/2506.10711", "authors": ["Li Luo", "Shangsong Liang"], "title": "PDESpectralRefiner: Achieving More Accurate Long Rollouts with Spectral Adjustment", "categories": ["cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "Generating accurate and stable long rollouts is a notorious challenge for\ntime-dependent PDEs (Partial Differential Equations). Recently, motivated by\nthe importance of high-frequency accuracy, a refiner model called PDERefiner\nutilizes diffusion models to refine outputs for every time step, since the\ndenoising process could increase the correctness of modeling high frequency\npart. For 1-D Kuramoto-Sivashinsky equation, refiner models can degrade the\namplitude of high frequency part better than not doing refinement process.\nHowever, for some other cases, the spectrum might be more complicated. For\nexample, for a harder PDE like Navior-Stokes equation, diffusion models could\nover-degrade the higher frequency part. This motivates us to release the\nconstraint that each frequency weighs the same. We enhance our refiner model\nwith doing adjustments on spectral space, which recovers Blurring diffusion\nmodels. We developed a new v-prediction technique for Blurring diffusion\nmodels, recovering the MSE training objective on the first refinement step. We\nshow that in this case, for different model backbones, such as U-Net and neural\noperators, the outputs of PDE-SpectralRefiner are more accurate for both\none-step MSE loss and rollout loss.", "AI": {"tldr": "PDERefiner uses diffusion models to refine PDE solutions, improving high-frequency accuracy. Enhanced with spectral adjustments, it outperforms in accuracy for complex PDEs like Navier-Stokes.", "motivation": "High-frequency accuracy in PDE solutions is challenging. Diffusion models help refine outputs but may over-degrade frequencies in complex cases.", "method": "Enhanced PDERefiner with spectral adjustments, introducing v-prediction for Blurring diffusion models to balance frequency weights.", "result": "Improved accuracy for one-step MSE and rollout loss across model backbones (U-Net, neural operators).", "conclusion": "Spectral adjustments in PDERefiner enhance accuracy for complex PDEs, addressing over-degradation issues."}}
{"id": "2506.10652", "pdf": "https://arxiv.org/pdf/2506.10652", "abs": "https://arxiv.org/abs/2506.10652", "authors": ["Volker Branding", "Anna Siffert"], "title": "On the stability of the generalized equator map", "categories": ["math.DG", "math.AP"], "comment": null, "summary": "The energy, the $p$-energy ($p\\in\\mathbb{R}$ with $p\\geq 2$) and the\nextrinsic $k$-energy ($k\\in\\mathbb{N}$) for maps between Riemannian manifolds\nare central objects in the geometric calculus of variations. The equator map\nfrom the unit ball to the Euclidean sphere provides an explicit critical point\nof all aforementioned energy functionals. During the last four decades many\nresearchers studied the stability of this particular map when considered as a\ncritical point of one of these energy functionals, see e.g. \\cite{MR4436204},\n\\cite{MR705882}.\n  Recently, Nakauchi \\cite{MR4593065} introduced a generalized radial\nprojection map and proved that this map is both a critical point of the energy\nand a critical point of the $p$-energy. This generalized radial projection map\ngives rise to a generalized equator map which is also both a critical point of\nthe energy and a critical point of the $p$-energy.\n  In this manuscript we first of all show that the generalized equator map is\nalso a critical point of the extrinsic $k$-energy. Then, the main focus is a\ndetailed stability analysis of this map, considered as a critical point of both\nthe extrinsic $k$-energy and the $p$-energy. We thus establish a number of\ninteresting generalizations of the classical (in)stability results of J\\\"ager\nand Kaul \\cite{MR705882}.", "AI": {"tldr": "The paper studies the generalized equator map as a critical point of energy, p-energy, and extrinsic k-energy, focusing on its stability analysis and generalizing classical results.", "motivation": "To extend the understanding of critical points of energy functionals in geometric calculus of variations, particularly the stability of the generalized equator map.", "method": "Analyzes the generalized equator map as a critical point of extrinsic k-energy and p-energy, conducting a detailed stability analysis.", "result": "The generalized equator map is confirmed as a critical point of extrinsic k-energy, and its stability properties are generalized from classical results.", "conclusion": "The study broadens the scope of stability analysis for critical points of energy functionals, linking new findings to established theories."}}
{"id": "2506.10875", "pdf": "https://arxiv.org/pdf/2506.10875", "abs": "https://arxiv.org/abs/2506.10875", "authors": ["Guanjin Wang", "Xiangxue Zhao", "Shapour Azarm", "Balakumar Balachandran"], "title": "Data-Driven Prediction of Dynamic Interactions Between Robot Appendage and Granular Material", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "An alternative data-driven modeling approach has been proposed and employed\nto gain fundamental insights into robot motion interaction with granular\nterrain at certain length scales. The approach is based on an integration of\ndimension reduction (Sequentially Truncated Higher-Order Singular Value\nDecomposition), surrogate modeling (Gaussian Process), and data assimilation\ntechniques (Reduced Order Particle Filter). This approach can be used online\nand is based on offline data, obtained from the offline collection of\nhigh-fidelity simulation data and a set of sparse experimental data. The\nresults have shown that orders of magnitude reduction in computational time can\nbe obtained from the proposed data-driven modeling approach compared with\nphysics-based high-fidelity simulations. With only simulation data as input,\nthe data-driven prediction technique can generate predictions that have\ncomparable accuracy as simulations. With both simulation data and sparse\nphysical experimental measurement as input, the data-driven approach with its\nembedded data assimilation techniques has the potential in outperforming only\nhigh-fidelity simulations for the long-horizon predictions. In addition, it is\ndemonstrated that the data-driven modeling approach can also reproduce the\nscaling relationship recovered by physics-based simulations for maximum\nresistive forces, which may indicate its general predictability beyond a\ncase-by-case basis. The results are expected to help robot navigation and\nexploration in unknown and complex terrains during both online and offline\nphases.", "AI": {"tldr": "A data-driven approach combining dimension reduction, surrogate modeling, and data assimilation significantly reduces computational time while maintaining accuracy in predicting robot-granular terrain interactions.", "motivation": "To improve robot navigation in complex terrains by developing a faster, accurate alternative to physics-based simulations.", "method": "Integrates Sequentially Truncated Higher-Order Singular Value Decomposition, Gaussian Process surrogate modeling, and Reduced Order Particle Filter for data assimilation.", "result": "Achieves orders of magnitude faster predictions with comparable accuracy to simulations; outperforms simulations when combined with sparse experimental data.", "conclusion": "The approach enhances robot navigation in unknown terrains, offering scalable predictability and computational efficiency."}}
{"id": "2506.10880", "pdf": "https://arxiv.org/pdf/2506.10880", "abs": "https://arxiv.org/abs/2506.10880", "authors": ["V. Giunzioni", "A. Merlini", "F. P. Andriulli"], "title": "Spectral Analysis of Discretized Boundary Integral Operators in 3D: a High-Frequency Perspective", "categories": ["cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "When modeling propagation and scattering phenomena using integral equations\ndiscretized by the boundary element method, it is common practice to\napproximate the boundary of the scatterer with a mesh comprising elements of\nsize approximately equal to a fraction of the wavelength $\\lambda$ of the\nincident wave, e.g., $\\lambda/10$. In this work, by analyzing the spectra of\nthe operator matrices, we show a discrepancy with respect to the continuous\noperators which grows with the simulation frequency, challenging the common\nbelief that the aforementioned widely used discretization approach is\nsufficient to maintain the accuracy of the solution constant when increasing\nthe frequency.", "AI": {"tldr": "The paper challenges the common practice of using mesh elements sized at \u03bb/10 for boundary element method discretization, showing that accuracy degrades with increasing frequency.", "motivation": "To investigate the accuracy of the widely used discretization approach (\u03bb/10 mesh size) in boundary element methods for wave propagation and scattering.", "method": "Analyzing the spectra of operator matrices to compare discretized and continuous operators.", "result": "Discrepancy between discretized and continuous operators grows with frequency, indicating accuracy loss.", "conclusion": "The \u03bb/10 discretization is insufficient for maintaining accuracy at higher frequencies, contradicting common belief."}}
{"id": "2506.10924", "pdf": "https://arxiv.org/pdf/2506.10924", "abs": "https://arxiv.org/abs/2506.10924", "authors": ["Quang Huy Nguyen", "Phuong Cuc Hoang", "Van Chien Le", "Thi Thanh Mai Ta"], "title": "A space-time interface-fitted method for moving-subdomain distributed control problems with energy regularization", "categories": ["math.OC", "cs.NA", "math.NA", "35K20, 49N10, 65M15, 65M60"], "comment": null, "summary": "This paper investigates a space-time interface-fitted approximation of a\nmoving-interface optimal control problem with energy regularization. We\nreformulate the optimality conditions into a variational problem involving both\nthe state and adjoint. This problem is shown to be equivalent to our optimal\ncontrol problem. Based on fully unstructured, space-time interface-fitted\nmeshes, we propose and analyze a Petrov-Galerkin approximation of the problem.\nAn optimal error estimate with respect to a discrete norm is established under\na specific regularity assumption on the state and adjoint. Several numerical\nresults are presented to corroborate our theoretical results.", "AI": {"tldr": "The paper proposes a space-time interface-fitted approximation for a moving-interface optimal control problem with energy regularization, analyzing its Petrov-Galerkin approximation and proving optimal error estimates.", "motivation": "To address the challenges of moving-interface optimal control problems by reformulating optimality conditions into a variational problem involving state and adjoint variables.", "method": "The study uses fully unstructured, space-time interface-fitted meshes and a Petrov-Galerkin approximation, analyzing its properties and deriving error estimates.", "result": "An optimal error estimate is established under specific regularity assumptions, supported by numerical results.", "conclusion": "The proposed method effectively approximates the problem, with theoretical findings validated by numerical experiments."}}
{"id": "2506.10973", "pdf": "https://arxiv.org/pdf/2506.10973", "abs": "https://arxiv.org/abs/2506.10973", "authors": ["Julius Berner", "Miguel Liu-Schiaffini", "Jean Kossaifi", "Valentin Duruisseaux", "Boris Bonev", "Kamyar Azizzadenesheli", "Anima Anandkumar"], "title": "Principled Approaches for Extending Neural Architectures to Function Spaces for Operator Learning", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.FA", "math.NA"], "comment": null, "summary": "A wide range of scientific problems, such as those described by\ncontinuous-time dynamical systems and partial differential equations (PDEs),\nare naturally formulated on function spaces. While function spaces are\ntypically infinite-dimensional, deep learning has predominantly advanced\nthrough applications in computer vision and natural language processing that\nfocus on mappings between finite-dimensional spaces. Such fundamental\ndisparities in the nature of the data have limited neural networks from\nachieving a comparable level of success in scientific applications as seen in\nother fields. Neural operators are a principled way to generalize neural\nnetworks to mappings between function spaces, offering a pathway to replicate\ndeep learning's transformative impact on scientific problems. For instance,\nneural operators can learn solution operators for entire classes of PDEs, e.g.,\nphysical systems with different boundary conditions, coefficient functions, and\ngeometries. A key factor in deep learning's success has been the careful\nengineering of neural architectures through extensive empirical testing.\nTranslating these neural architectures into neural operators allows operator\nlearning to enjoy these same empirical optimizations. However, prior neural\noperator architectures have often been introduced as standalone models, not\ndirectly derived as extensions of existing neural network architectures. In\nthis paper, we identify and distill the key principles for constructing\npractical implementations of mappings between infinite-dimensional function\nspaces. Using these principles, we propose a recipe for converting several\npopular neural architectures into neural operators with minimal modifications.\nThis paper aims to guide practitioners through this process and details the\nsteps to make neural operators work in practice. Our code can be found at\nhttps://github.com/neuraloperator/NNs-to-NOs", "AI": {"tldr": "The paper introduces neural operators as a way to generalize neural networks for mappings between infinite-dimensional function spaces, enabling deep learning's success in scientific problems like PDEs. It provides a practical guide for converting existing neural architectures into neural operators.", "motivation": "Deep learning excels in finite-dimensional spaces (e.g., computer vision), but struggles with infinite-dimensional function spaces common in scientific problems (e.g., PDEs). Neural operators bridge this gap by extending neural networks to function spaces.", "method": "The paper identifies key principles for implementing mappings between function spaces and proposes a method to convert popular neural architectures into neural operators with minimal changes.", "result": "The approach enables neural operators to learn solution operators for PDEs across varying conditions, leveraging existing neural architectures' empirical optimizations.", "conclusion": "The paper provides a practical framework for adapting neural networks to function spaces, aiming to replicate deep learning's impact in scientific applications."}}
