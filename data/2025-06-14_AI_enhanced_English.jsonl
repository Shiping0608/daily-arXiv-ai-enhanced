{"id": "2506.10118", "pdf": "https://arxiv.org/pdf/2506.10118", "abs": "https://arxiv.org/abs/2506.10118", "authors": ["Sean Reiter", "Steffen W. R. Werner"], "title": "Data-driven balanced truncation for second-order systems with generalized proportional damping", "categories": ["math.NA", "cs.NA", "cs.SY", "eess.SY", "math.DS", "math.OC", "37N35, 65F55, 93A15, 93B15, 93C57"], "comment": "31 pages, 5 figures, 5 tables", "summary": "Structured reduced-order modeling is a central component in the\ncomputer-aided design of control systems in which cheap-to-evaluate\nlow-dimensional models with physically meaningful internal structures are\ncomputed. In this work, we develop a new approach for the structured\ndata-driven surrogate modeling of linear dynamical systems described by\nsecond-order time derivatives via balanced truncation model-order reduction.\nThe proposed method is a data-driven reformulation of position-velocity\nbalanced truncation for second-order systems and generalizes the\nquadrature-based balanced truncation for unstructured first-order systems to\nthe second-order case. The computed surrogates encode a generalized\nproportional damping structure, and the damping coefficients are inferred\nsolely from data by minimizing a least-squares error over the coefficients.\nSeveral numerical examples demonstrate the effectiveness of the proposed\nmethod.", "AI": {"tldr": "A data-driven method for structured reduced-order modeling of second-order linear dynamical systems, generalizing balanced truncation techniques.", "motivation": "To create efficient, low-dimensional models with meaningful structures for control system design, leveraging data-driven approaches.", "method": "Reformulates position-velocity balanced truncation for second-order systems, generalizing quadrature-based balanced truncation. Infers damping coefficients via least-squares minimization.", "result": "Effective surrogate models with generalized proportional damping structure, validated through numerical examples.", "conclusion": "The method successfully extends balanced truncation to second-order systems, offering a practical data-driven solution for structured modeling."}}
{"id": "2506.10243", "pdf": "https://arxiv.org/pdf/2506.10243", "abs": "https://arxiv.org/abs/2506.10243", "authors": ["Rongxin Lu", "Jiwei Jia", "Young Ju Lee", "Zheng Lu", "Chensong Zhang"], "title": "R-PINN: Recovery-type a-posteriori estimator enhanced adaptive PINN", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In recent years, with the advancements in machine learning and neural\nnetworks, algorithms using physics-informed neural networks (PINNs) to solve\nPDEs have gained widespread applications. While these algorithms are\nwell-suited for a wide range of equations, they often exhibit suboptimal\nperformance when applied to equations with large local gradients, resulting in\nsubstantial localized errors. To address this issue, this paper proposes an\nadaptive PINN algorithm designed to improve accuracy in such cases. The core\nidea of the algorithm is to adaptively adjust the distribution of collocation\npoints based on the recovery-type a-posterior error of the current numerical\nsolution, enabling a better approximation of the true solution. This approach\nis inspired by the adaptive finite element method. By combining the\nrecovery-type a-posteriori estimator, a gradient-recovery estimator commonly\nused in the adaptive finite element method (FEM) with PINNs, we introduce the\nRecovery-type a-posteriori estimator enhanced adaptive PINN (R-PINN) and\ncompare its performance with a typical adaptive PINN algorithm, FI-PINN. Our\nresults demonstrate that R-PINN achieves faster convergence with fewer adaptive\npoints and significantly outperforms in the cases with multiple regions of\nlarge errors than FI-PINN. Notably, our method is a hybrid numerical approach\nfor solving partial differential equations, integrating adaptive FEM with\nPINNs.", "AI": {"tldr": "The paper proposes R-PINN, an adaptive PINN algorithm, to improve accuracy for PDEs with large local gradients by adjusting collocation points based on error estimates, outperforming FI-PINN.", "motivation": "Standard PINNs perform poorly for PDEs with large local gradients, leading to localized errors.", "method": "Introduces R-PINN, combining recovery-type a-posteriori error estimators from adaptive FEM with PINNs to adaptively adjust collocation points.", "result": "R-PINN converges faster with fewer points and outperforms FI-PINN in cases with multiple error regions.", "conclusion": "R-PINN is a hybrid approach integrating adaptive FEM with PINNs, offering superior performance for challenging PDEs."}}
{"id": "2506.10261", "pdf": "https://arxiv.org/pdf/2506.10261", "abs": "https://arxiv.org/abs/2506.10261", "authors": ["Liqi Guo", "Ruike Xiang", "Deren Han", "Jiaxin Xie"], "title": "Enhanced randomized Douglas-Rachford method: Improved probabilities and adaptive momentum", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Randomized iterative methods have gained recent interest in machine learning\nand signal processing for solving large-scale linear systems. One such example\nis the randomized Douglas-Rachford (RDR) method, which updates the iterate by\nreflecting it through two randomly selected hyperplanes and taking a convex\ncombination with the current point. In this work, we enhance RDR by introducing\nimproved sampling strategies and an adaptive heavy-ball momentum scheme.\nSpecifically, we incorporate without-replacement and volume sampling into RDR,\nand establish stronger convergence guarantees compared to conventional i.i.d.\nsampling. Furthermore, we develop an adaptive momentum mechanism that\ndynamically adjusts step sizes and momentum parameters based on previous\niterates, and prove that the resulting method achieves linear convergence in\nexpectation with improved convergence bounds. Numerical experiments demonstrate\nthat the enhanced RDR method consistently outperforms the original version,\nproviding substantial practical benefits across a range of problem settings.", "AI": {"tldr": "The paper enhances the randomized Douglas-Rachford (RDR) method with improved sampling strategies and adaptive momentum, achieving stronger convergence guarantees and practical performance gains.", "motivation": "To improve the efficiency and convergence of randomized iterative methods for solving large-scale linear systems, particularly the RDR method.", "method": "Incorporates without-replacement and volume sampling into RDR, and introduces an adaptive heavy-ball momentum scheme with dynamic parameter adjustment.", "result": "The enhanced RDR method achieves linear convergence in expectation with improved bounds and outperforms the original in numerical experiments.", "conclusion": "The proposed enhancements to RDR offer significant theoretical and practical improvements for solving linear systems."}}
{"id": "2506.10263", "pdf": "https://arxiv.org/pdf/2506.10263", "abs": "https://arxiv.org/abs/2506.10263", "authors": ["Charles L. Epstein", "Tristan Goodwill", "Jeremy Hoskins", "Solomon Quinn", "Manas Rachh"], "title": "Complex scaling for open waveguides", "categories": ["math.NA", "cs.NA", "65N80, 35Q60, 35C15, 35P25, 45B05, 31A10, 30B40, 65R20"], "comment": null, "summary": "In this work we analyze the complex scaling method applied to the problem of\ntime-harmonic scalar wave propagation in junctions between `leaky,' or open\ndielectric waveguides. In [arXiv:2302.04353, arXiv:2310.05816,\narXiv:2401.04674, arXiv:2411.11204], it was shown that under suitable\nassumptions the problem can be reduced to a system of Fredholm second-kind\nintegral equations on an infinite interface, transverse to the waveguides.\nHere, we show that the kernels appearing in the integral equation admit a\nrapidly decaying analytic continuation on certain natural totally real\nsubmanifolds of $\\mathbb{C}^2.$ We then show that for suitable,\nphysically-meaningful, boundary data the resulting solutions to the integral\nequations themselves admit analytic continuation and satisfy related asymptotic\nestimates. By deforming the integral equation to a suitable contour, the decay\nin the kernels, density, and data enable straightforward discretization and\ntruncation, with an error that decays exponentially in the truncation length.\nWe illustrate our results with several representative numerical examples.", "AI": {"tldr": "The paper analyzes the complex scaling method for time-harmonic scalar wave propagation in leaky dielectric waveguide junctions, showing kernels decay rapidly and solutions admit analytic continuation, enabling efficient numerical discretization.", "motivation": "To address the problem of wave propagation in open dielectric waveguides by reducing it to a system of Fredholm integral equations and analyzing their properties for practical numerical solutions.", "method": "The study involves analytic continuation of kernels and solutions, deformation of integral equations to suitable contours, and numerical discretization with exponential error decay.", "result": "Kernels and solutions exhibit rapid decay and analytic continuation, allowing efficient numerical treatment with exponentially decaying truncation error.", "conclusion": "The method provides a robust framework for solving wave propagation problems in leaky waveguides, validated by numerical examples."}}
{"id": "2506.10149", "pdf": "https://arxiv.org/pdf/2506.10149", "abs": "https://arxiv.org/abs/2506.10149", "authors": ["Chesson Sipling", "Yuan-Hang Zhang", "Massimiliano Di Ventra"], "title": "Phase-Space Engineering and Dynamical Long-Range Order in Memcomputing", "categories": ["physics.comp-ph", "nlin.AO"], "comment": "13 pages, 4 figures", "summary": "Digital Memcomputing machines (DMMs) are dynamical systems with memory (time\nnon-locality) that have been designed to solve combinatorial optimization\nproblems. Their corresponding ordinary differential equations depend on a few\nhyper-parameters that define both the system's relevant time scales and its\nphase-space geometry. Using numerical simulations on a prototypical DMM, we\nanalyze the role of these physical parameters in engineering the phase space to\neither help or hinder the solution search by DMMs. We find that the DMM\nexplores its phase space efficiently for a wide range of parameters, aided by\nthe long-range correlations in their fast degrees of freedom that emerge\ndynamically due to coupling with the (slow) memory degrees of freedom. In this\nregime, the time it takes for the system to find a solution scales well as the\nnumber of variables increases. When these hyper-parameters are chosen poorly,\nthe system navigates its phase space far less efficiently. However, we find\nthat, in many cases, dynamical long-range order (DLRO) persists even when the\nphase-space exploration process is inefficient. DLRO only disappears if the\nmemories are made to evolve as quickly as the fast degrees of freedom. This\nstudy points to the important role of memory and hyper-parameters in\nengineering the DMMs' phase space for optimal computational efficiency.", "AI": {"tldr": "The paper analyzes how hyper-parameters in Digital Memcomputing Machines (DMMs) affect phase-space exploration and solution efficiency, highlighting the role of memory and dynamical long-range order.", "motivation": "To understand how hyper-parameters in DMMs influence their computational efficiency and phase-space dynamics for solving combinatorial optimization problems.", "method": "Numerical simulations on a prototypical DMM to study the impact of hyper-parameters on phase-space geometry and solution search efficiency.", "result": "DMMs explore phase space efficiently with well-chosen hyper-parameters, aided by dynamical long-range correlations. Poor hyper-parameters reduce efficiency, but dynamical long-range order often persists.", "conclusion": "Memory and hyper-parameters are crucial for optimizing DMMs' computational efficiency, with dynamical long-range order playing a key role."}}
{"id": "2506.10099", "pdf": "https://arxiv.org/pdf/2506.10099", "abs": "https://arxiv.org/abs/2506.10099", "authors": ["Mate Vass", "Xiaokun Wang", "Ihor Korolov", "Julian Schulze", "Thomas Mussenbrock"], "title": "Synergistic control of radical generation in a radio frequency atmospheric pressure plasma jet via voltage waveform tailoring and structured electrodes", "categories": ["physics.plasm-ph", "physics.app-ph"], "comment": null, "summary": "The synergy between voltage waveform tailoring and structured electrodes is\ninvestigated in a radio-frequency (RF) atmospheric-pressure microplasma jet\noperated in helium with a 0.1% oxygen admixture. The device incorporates\nrectangular trenches in both electrodes and is driven by \"Peaks\" and \"Valleys\"\nwaveforms synthesized from four harmonics (base frequency $f_{\\rm b} =\n13.56$~MHz, $V_{\\rm pp} = 500$~V, $P=$1.2~W). Two-dimensional plasma fluid\nsimulations, together with spatially and temporally resolved optical\ndiagnostics (Phase-Resolved Optical Emission Spectroscopy and Tunable Diode\nLaser Absorption Spectroscopy), are used to demonstrate that the combination of\nasymmetric voltage waveforms with electrode structuring leads to strong spatial\nlocalization of electron power absorption and radical generation. This synergy\nresults in a single pronounced maximum inside a trench at either the powered or\ngrounded electrode, depending on the applied waveform, unlike a symmetric\nexcitation, which produces a spatially symmetric enhancement at both\nelectrodes. The effect is attributed to the interplay between waveform-induced\nsheath dynamics and geometric focusing provided by the trenches, enabling\nelectrically reversible and selective enhancement of electron power absorption\nat a chosen location.", "AI": {"tldr": "The study explores how combining tailored voltage waveforms with structured electrodes in an RF microplasma jet enhances localized electron power absorption and radical generation.", "motivation": "To investigate the synergy between voltage waveform tailoring and electrode structuring for precise control of plasma properties.", "method": "Uses 2D plasma fluid simulations and optical diagnostics (PROES, TDLAS) with asymmetric waveforms and structured electrodes.", "result": "Asymmetric waveforms and electrode structuring localize electron power absorption and radical generation, unlike symmetric excitation.", "conclusion": "The synergy enables selective, reversible enhancement of electron power absorption at desired locations."}}
{"id": "2506.10087", "pdf": "https://arxiv.org/pdf/2506.10087", "abs": "https://arxiv.org/abs/2506.10087", "authors": ["Fabio Bagagiolo", "Stefan Moreti"], "title": "Wave-front tracking for a quasi-linear scalar conservation law with hysteresis II: the case of Preisach", "categories": ["math.AP", "35L65, 47J40"], "comment": null, "summary": "We consider the Cauchy problem for the quasi-linear scalar conservation law\n\\[u_t+\\mathcal{F}(u)_t+u_x=0,\\] where $\\mathcal{F}$ is a specific hysteresis\noperator. Hysteresis models a rate-independent memory relationship between the\ninput $u$ and its output, giving a non-local feature to the equation. In a\nprevious work the authors studied the case when $\\mathcal{F}$ is the Play\noperator. In the present article, we extend the analysis to the case of\nPreisach operator, which is probably the most versatile mathematical model to\nthe describe hysteresis in the applications, especially for the presence of\nsome kind of internal variables. This fact has required a new analysis of the\nequation. Starting from the Riemann problem, we address the so-called\nwave-front tracking method for a solution to the Cauchy problem with bounded\nvariation initial data. An entropy-like condition is also exploited for\nuniqueness.", "AI": {"tldr": "The paper extends the analysis of a quasi-linear scalar conservation law with hysteresis from the Play operator to the more versatile Preisach operator, focusing on the Cauchy problem and employing wave-front tracking for solutions.", "motivation": "The study aims to generalize previous work on hysteresis in conservation laws by using the Preisach operator, which better models real-world applications due to its internal variables.", "method": "The authors analyze the Riemann problem and apply the wave-front tracking method to solve the Cauchy problem for bounded variation initial data, supplemented by an entropy-like condition for uniqueness.", "result": "The paper provides a framework for solving the Cauchy problem with the Preisach hysteresis operator, ensuring uniqueness through an entropy condition.", "conclusion": "The extension to the Preisach operator enhances the applicability of hysteresis models in conservation laws, with rigorous analysis and solution methods."}}
{"id": "2506.10428", "pdf": "https://arxiv.org/pdf/2506.10428", "abs": "https://arxiv.org/abs/2506.10428", "authors": ["Sudeep Kundu", "Shishu pal Singh"], "title": "Penalty-Based Feedback Control and Finite Element Analysis for the Stabilization of Nonlinear Reaction-Diffusion Equations", "categories": ["math.NA", "cs.NA", "math.OC", "93D15, 35K57, 65M60, 93B52, 65M15"], "comment": null, "summary": "In this work, first we employ the penalization technique to analyze the\nDirichlet boundary feedback control problem pertaining to reaction-diffusion\nequation. We establish the stabilization result of the equivalent Robin problem\nin the \\(H^{2}\\)-norm with respect to the penalty parameter. Furthermore, we\nprove that the solution of the penalized control problem converges to the\ncorresponding solution of the Dirichlet boundary feedback control problem as\nthe penalty parameter \\(\\epsilon\\) approaches zero. A \\(C^{0}\\)-conforming\nfinite element method is applied to this problem for the spatial variable while\nkeeping the time variable continuous. We discuss the stabilization of the\nsemi-discrete scheme for the penalized control problem and present an error\nanalysis of its solution. Finally, we validate our theoretical findings through\nnumerical experiments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.10691", "pdf": "https://arxiv.org/pdf/2506.10691", "abs": "https://arxiv.org/abs/2506.10691", "authors": ["Dilara Abdel", "Jacob Relle", "Thomas Kirchartz", "Patrick Jaap", "J\u00fcrgen Fuhrmann", "Sven Burger", "Christiane Becker", "Klaus J\u00e4ger", "Patricio Farrell"], "title": "Unravelling the mystery of enhanced open-circuit voltages in nanotextured perovskite solar cells", "categories": ["physics.comp-ph", "physics.app-ph"], "comment": null, "summary": "Perovskite solar cells have reached power conversion efficiencies that rival\nthose of established silicon photovoltaic technologies. Nanotextures in\nperovskite solar cells optimise light trapping and scattering, thereby\nimproving optical absorption. In addition, nanotextures have been\nexperimentally shown to enhance electronic performance, in particular, by\nincreasing the open-circuit voltage $V_{\\text{OC}}$ -- a phenomenon that, until\nnow, has remained not fully understood. This study investigates the underlying\nreasons by combining multi-dimensional optical and charge-transport simulations\nfor a single-junction perovskite solar cell. Our results reveal that the\nincreased open-circuit voltage is not driven by optical effects but by the\ntextured geometry itself. For voltages near $V_{\\text{OC}}$, texturing one of\nthe absorber/transport layer interfaces increases the imbalance between\nelectron and hole densities in the absorber, thereby reducing\nShockley-Read-Hall (SRH) recombination, which is the dominant loss mechanism in\nthis study. While idealised solar cells benefit unconditionally from increasing\ntexture height, in realistic cells there is an optimal texture height which\nmaximizes the power conversion efficiency. These findings provide new insights\ninto the opto-electronic advantages of texturing and offer guidance for the\ndesign of next-generation textured perovskite-based solar cells, light emitting\ndiodes, and photodetectors.", "AI": {"tldr": "Nanotextures in perovskite solar cells improve efficiency by reducing recombination losses, not just optical effects, with an optimal texture height for real-world applications.", "motivation": "To understand why nanotextures enhance open-circuit voltage (V_OC) in perovskite solar cells, a phenomenon not fully explained before.", "method": "Combined multi-dimensional optical and charge-transport simulations for a single-junction perovskite solar cell.", "result": "Texturing reduces Shockley-Read-Hall recombination, increasing V_OC, with an optimal texture height for efficiency.", "conclusion": "Texturing offers opto-electronic benefits, guiding design for future perovskite-based devices."}}
{"id": "2506.10410", "pdf": "https://arxiv.org/pdf/2506.10410", "abs": "https://arxiv.org/abs/2506.10410", "authors": ["Panagiotis Tolias", "Jan Vorberger", "Tobias Dornheim"], "title": "Exact series expansion for even frequency moments of the dynamic structure factor", "categories": ["physics.plasm-ph", "physics.chem-ph"], "comment": null, "summary": "An exact series representation of the even frequency moments of the dynamic\nstructure factor is derived. Truncations are proposed that allow to evaluate\nthe explicitly unknown second, fourth and fifth frequency moments for the\nfinite temperature uniform electron gas. Their applicability range in terms of\ndegeneracy parameter and wavenumber is determined by exploiting the\nnon-interacting limit and by comparing with the quasi-exact results of path\nintegral Monte Carlo simulations.", "AI": {"tldr": "The paper derives an exact series for even frequency moments of the dynamic structure factor, proposes truncations for unknown moments, and validates their range using non-interacting limits and Monte Carlo simulations.", "motivation": "To address the challenge of evaluating unknown frequency moments (second, fourth, fifth) for the finite-temperature uniform electron gas.", "method": "Derives an exact series representation and proposes truncations; validates using non-interacting limits and path integral Monte Carlo simulations.", "result": "Identifies the applicability range of the proposed truncations in terms of degeneracy parameter and wavenumber.", "conclusion": "The derived truncations are validated and provide a practical approach for evaluating unknown frequency moments."}}
{"id": "2506.10176", "pdf": "https://arxiv.org/pdf/2506.10176", "abs": "https://arxiv.org/abs/2506.10176", "authors": ["Rafael Ceja Ayala", "Isaac Harris", "Tonatiuh S\u00e1nchez-Vizuet"], "title": "Well--posedness for the biharmonic scattering problem for a penetrable obstacle", "categories": ["math.AP", "47A40, 74J05, 74H25, 35J35"], "comment": null, "summary": "We address the direct scattering problem for a penetrable obstacle in an\ninfinite elastic two--dimensional Kirchhoff--Love plate. Under the assumption\nthat the plate's thickness is small relative to the wavelength of the incident\nwave, the propagation of perturbations on the plate is governed by the\ntwo-dimensional biharmonic wave equation, which we study in the frequency\ndomain. With the help of an operator factorization, the scattering problem is\nanalyzed from the perspective of a coupled boundary value problem involving the\nHelmholtz and modified Helmholtz equations. Well--posedness and reciprocity\nrelations for the problem are established. Numerical examples for some special\ncases are provided to validate the theoretical findings.", "AI": {"tldr": "The paper analyzes the scattering problem for a penetrable obstacle in a 2D elastic plate using the biharmonic wave equation, coupling Helmholtz and modified Helmholtz equations, and validates results numerically.", "motivation": "To understand wave propagation in thin elastic plates and solve the scattering problem for penetrable obstacles.", "method": "Uses the biharmonic wave equation in the frequency domain, coupled with Helmholtz and modified Helmholtz equations, and employs operator factorization for analysis.", "result": "Establishes well-posedness and reciprocity relations, supported by numerical examples.", "conclusion": "The theoretical framework is validated, providing insights into wave scattering in elastic plates."}}
{"id": "2506.10447", "pdf": "https://arxiv.org/pdf/2506.10447", "abs": "https://arxiv.org/abs/2506.10447", "authors": ["Igor Tominec", "Lukas Lundgren", "Andr\u00e9 L\u00f6fgren", "Josefin Ahlkrona"], "title": "Stability analysis of the free-surface Stokes problem and an unconditionally stable explicit scheme", "categories": ["math.NA", "cs.NA", "math.AP", "65J15, 65M12, 65M60"], "comment": null, "summary": "Accurate simulations of ice sheet dynamics, mantle convection, lava flow, and\nother highly viscous free-surface flows involve solving the coupled\nStokes/free-surface equations. In this paper, we theoretically analyze the\nstability and conservation properties of the weak form of this system for\nNewtonian fluids and non-Newtonian fluids, at both the continuous and discrete\nlevels. We perform the fully discrete stability analysis for finite element\nmethods used in space with explicit and implicit Euler time-stepping methods\nused in time. Motivated by the theory, we propose a stabilization term designed\nfor the explicit Euler discretization, which ensures unconditional time\nstability and permits conservation of the domain volume. Numerical experiments\nvalidate and support our theoretical findings.", "AI": {"tldr": "The paper analyzes stability and conservation properties of the Stokes/free-surface system for viscous flows, proposing a stabilization term for explicit Euler discretization to ensure stability and volume conservation.", "motivation": "To address the need for accurate simulations of highly viscous free-surface flows like ice sheet dynamics and mantle convection by analyzing the stability and conservation properties of the coupled Stokes/free-surface system.", "method": "Theoretical analysis of the weak form of the system for Newtonian and non-Newtonian fluids at continuous and discrete levels, with fully discrete stability analysis for finite element methods and explicit/implicit Euler time-stepping. A stabilization term for explicit Euler is proposed.", "result": "The proposed stabilization term ensures unconditional time stability and domain volume conservation, validated by numerical experiments.", "conclusion": "The study provides theoretical and numerical validation for the stabilization term, enhancing the stability and conservation properties of simulations for highly viscous free-surface flows."}}
{"id": "2506.10956", "pdf": "https://arxiv.org/pdf/2506.10956", "abs": "https://arxiv.org/abs/2506.10956", "authors": ["John L. A. Gardner", "Daniel F. Thomas du Toit", "Chiheb Ben Mahmoud", "Zo\u00e9 Faure Beaulieu", "Veronika Juraskova", "Laura-Bianca Pa\u015fca", "Louise A. M. Rosset", "Fernanda Duarte", "Fausto Martelli", "Chris J. Pickard", "Volker L. Deringer"], "title": "Distillation of atomistic foundation models across architectures and chemical domains", "categories": ["physics.comp-ph"], "comment": null, "summary": "Machine-learned interatomic potentials have transformed computational\nresearch in the physical sciences. Recent atomistic `foundation' models have\nchanged the field yet again: trained on many different chemical elements and\ndomains, these potentials are widely applicable, but comparably slow and\nresource-intensive to run. Here we show how distillation via synthetic data can\nbe used to cheaply transfer knowledge from atomistic foundation models to a\nrange of different architectures, unlocking much smaller, more efficient\npotentials. We demonstrate speed-ups of $> 10\\times$ by distilling from one\ngraph-network architecture into another, and $> 100\\times$ by leveraging the\natomic cluster expansion framework. We showcase applicability across chemical\nand materials domains: from liquid water to hydrogen under extreme conditions;\nfrom porous silica and a hybrid halide perovskite solar-cell material to\nmodelling organic reactions. Our work shows how distillation can support the\nroutine and computationally efficient use of current and future atomistic\nfoundation models in real-world scientific research.", "AI": {"tldr": "The paper demonstrates how distillation via synthetic data can efficiently transfer knowledge from large atomistic foundation models to smaller, faster potentials, achieving significant speed-ups and broad applicability.", "motivation": "To address the inefficiency and resource-intensive nature of current atomistic foundation models, enabling their practical use in scientific research.", "method": "Distillation via synthetic data to transfer knowledge from large foundation models to smaller architectures, tested across various chemical and materials domains.", "result": "Achieved speed-ups of >10\u00d7 and >100\u00d7 for different architectures, with successful applications in diverse domains like liquid water, hydrogen under extreme conditions, and organic reactions.", "conclusion": "Distillation enables computationally efficient use of atomistic foundation models, making them viable for real-world scientific applications."}}
{"id": "2506.10411", "pdf": "https://arxiv.org/pdf/2506.10411", "abs": "https://arxiv.org/abs/2506.10411", "authors": ["S. Ratynskaia", "M. Hoelzl", "E. Nardon", "P. Aleynikov", "F. J. Artola", "V. Bandaru", "M. Beidler", "B. Breizman", "D. del-Castillo-Negrete", "M. De Angeli", "V. Dimitriou", "R. Ding", "J. Eriksson", "O. Ficker", "R. S. Granetz", "E. Hollmann", "M. Hoppe", "M. Houry", "I. Jepu", "H. R. Koslowski", "C. Liu", "J. R. Martin-Solis", "G. Pautasso", "Y. Peneliau", "R. A. Pitts", "G. I. Pokol", "C. Reux", "U. Sheikh", "S. A. Silburn", "T. Tang", "R. A. Tinguely", "P. Tolias", "E. Tomesova", "R. Villari"], "title": "Runaway electron-induced plasma facing component damage in tokamaks", "categories": ["physics.plasm-ph", "physics.app-ph"], "comment": "Submitted for publication in the journal Plasma Physics and\n  Controlled Fusion", "summary": "This Roadmap article addresses the critical and multifaceted challenge of\nplasma-facing component (PFC) damage caused by runaway electrons (REs) in\ntokamaks, a phenomenon that poses a significant threat to the viability and\nlongevity of future fusion reactors such as ITER and DEMO. The dramatically\nincreased RE production expected in future high-current tokamaks makes it\ndifficult to avoid or mitigate REs when a plasma discharge terminates\nabnormally. Preventing damage from the intense localised heat loads REs can\ncause requires a holistic approach that considers plasma, REs and PFC damage.\nDespite decades of progress in understanding the physics of REs and the\nthermomechanical response of PFCs, their complex interplay remains poorly\nunderstood. This document aims to initiate a coordinated, interdisciplinary\napproach to bridge this gap by reviewing experimental evidence, advancing\ndiagnostic capabilities, and improving modelling tools across different scales,\ndimensionalities and fidelities. Key topics include RE beam formation and\ntransport, damage mechanisms in brittle and metallic PFCs, and observations in\nmajor facilities such as JET, DIII-D, WEST and EAST. The Roadmap emphasises the\nurgency of predictive, high-fidelity modelling validated against well-diagnosed\ncontrolled experiments, particularly in the light of recent changes in ITER's\nwall material strategy and the growing importance of private sector\ninitiatives. Each section of the article is written to provide a concise\noverview of one area of this multidisciplinary subject, with an assessment of\nthe status, a look at current and future challenges, and a brief summary. The\nultimate goal of this initiative is to guide future mitigation strategies and\ndesign resilient components that can withstand the loads imposed by REs, thus\nensuring the safe and sustainable operation of the next generation of fusion\npower plants.", "AI": {"tldr": "The paper addresses the challenge of plasma-facing component (PFC) damage from runaway electrons (REs) in tokamaks, proposing a coordinated, interdisciplinary approach to bridge gaps in understanding and mitigation.", "motivation": "The threat of RE-induced PFC damage to future fusion reactors like ITER and DEMO necessitates a holistic understanding and mitigation strategy.", "method": "The approach involves reviewing experimental evidence, advancing diagnostics, and improving multi-scale, multi-fidelity modelling.", "result": "Key findings include insights into RE beam formation, PFC damage mechanisms, and observations from major facilities.", "conclusion": "The paper aims to guide future mitigation strategies and resilient PFC designs for safe, sustainable fusion power plants."}}
{"id": "2506.10255", "pdf": "https://arxiv.org/pdf/2506.10255", "abs": "https://arxiv.org/abs/2506.10255", "authors": ["Haokun Chen", "Yong Wang"], "title": "Optimal decay of global strong solutions to nematic liquid crystal flows in the half-space", "categories": ["math.AP"], "comment": "37 pages", "summary": "We study asymptotic behaviors of the higher-order spatial derivatives and the\nfirst-order time derivatives for the strong solution to nematic liquid crystal\nflows in the half-space $\\mathbb{R}_+^3$. Furthermore, when the initial data\nlie in an appropriately weighted Sobolev space, we obtain the decay rates that\nare faster than the heat kernel. The main tools employed in this paper are the\n$L^p-L^q$ estimates of the Stokes semigroup, the a priori estimates of the\nsteady Stokes system in $\\mathbb{R}_+^3$, and the representation formula of the\nLeray projection operator.", "AI": {"tldr": "The paper analyzes the decay rates of higher-order spatial and first-order time derivatives for nematic liquid crystal flows in a half-space, showing faster decay than the heat kernel under certain initial conditions.", "motivation": "To understand the asymptotic behavior of derivatives in nematic liquid crystal flows and establish decay rates under weighted Sobolev space conditions.", "method": "Uses $L^p-L^q$ estimates of the Stokes semigroup, a priori estimates of the steady Stokes system, and the Leray projection operator's representation formula.", "result": "Demonstrates faster decay rates than the heat kernel for the derivatives when initial data lie in a weighted Sobolev space.", "conclusion": "The study provides insights into the decay behavior of derivatives in nematic liquid crystal flows, leveraging advanced analytical tools."}}
{"id": "2506.10499", "pdf": "https://arxiv.org/pdf/2506.10499", "abs": "https://arxiv.org/abs/2506.10499", "authors": ["Alexander Freiszlinger", "Dirk Pauly", "Dirk Praetorius"], "title": "Convergence of adaptive boundary element methods driven by functional a posteriori error estimates", "categories": ["math.NA", "cs.NA", "65N38, 65N15, 65N50, 65N12"], "comment": null, "summary": "The recent work [Kurz et al., Numer. Math., 147 (2021)] proposed functional a\nposteriori error estimates for boundary element methods (BEMs) together with a\nrelated adaptive mesh-refinement strategy. Unlike most a posteriori BEM error\nestimators, the proposed functional error estimators cover Galerkin as well as\ncollocation BEM and, more importantly, do not control the error in the integral\ndensity on the boundary, but the error of the potential approximation in the\ndomain, which is of greater relevance in practice. The estimates rely on the\nnumerical solution of auxiliary problems on auxiliary strip domains along the\nboundary, where the strips are affected by the adaptive mesh-refinement and\nhence vary. For Galerkin BEM, we prove that the proposed adaptive\nmesh-refinement algorithm yields convergence of the potential error to zero.\nDue to the structural difference to residual-based estimators, the proof\nrequires new ideas.", "AI": {"tldr": "Functional a posteriori error estimates for BEMs are proposed, covering Galerkin and collocation methods, focusing on potential approximation errors in the domain rather than boundary density errors. Adaptive mesh-refinement on auxiliary strip domains ensures convergence of potential error to zero for Galerkin BEM.", "motivation": "To address the practical relevance of potential approximation errors in the domain, rather than boundary density errors, and to provide a unified approach for Galerkin and collocation BEM.", "method": "Functional error estimates are derived by solving auxiliary problems on adaptive strip domains along the boundary. Adaptive mesh-refinement is applied to these strips.", "result": "The proposed adaptive mesh-refinement algorithm ensures convergence of the potential error to zero for Galerkin BEM.", "conclusion": "The functional error estimators and adaptive strategy offer a practical and unified approach for BEM error control, with proven convergence for Galerkin methods."}}
{"id": "2506.10211", "pdf": "https://arxiv.org/pdf/2506.10211", "abs": "https://arxiv.org/abs/2506.10211", "authors": ["Shriya Gumber", "Lorena Alzate-Vargas", "Benjamin T. Nebgen", "Arjen van Veelen", "Smit Kadvani", "Tammie Gibson", "Richard Messerly"], "title": "Going beyond density functional theory accuracy: Leveraging experimental data to refine pre-trained machine learning interatomic potentials", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Machine learning interatomic potentials (MLIPs) are inherently limited by the\naccuracy of the training data, usually consisting of energies and forces\nobtained from quantum mechanical calculations, such as density functional\ntheory (DFT). Since DFT itself is based on several approximations, MLIPs may\ninherit systematic errors that lead to discrepancies with experimental data. In\nthis paper, we use a trajectory re-weighting technique to refine DFT\npre-trained MLIPs to match the target experimental Extended X-ray Absorption\nFine Structure (EXAFS) spectra. EXAFS spectra are sensitive to the local\nstructural environment around an absorbing atom. Thus, refining an MLIP to\nimprove agreement with experimental EXAFS spectra also improves the MLIP\nprediction of other structural properties that are not directly involved in the\nrefinement process. We combine this re-weighting technique with transfer\nlearning and a minimal number of training epochs to avoid overfitting to the\nlimited experimental data. The refinement approach demonstrates significant\nimprovement for two MLIPs reported in previous work, one for an established\nnuclear fuel: uranium dioxide (UO$_2$) and second one for a nuclear fuel\ncandidate: uranium mononitride (UN). We validate the effectiveness of our\napproach by comparing the results obtained from the original (unrefined)\nDFT-based MLIP and the EXAFS-refined MLIP across various properties, such as\nlattice parameters, bulk modulus, heat capacity, point defect energies, elastic\nconstants, phonon dispersion spectra, and diffusion coefficients. An accurate\nMLIP for nuclear fuels is extremely beneficial as it enables reliable atomistic\nsimulation, which greatly reduces the need for large number of expensive and\ninherently dangerous experimental nuclear integral tests, traditionally\nrequired for the qualification of efficient and resilient fuel candidates.", "AI": {"tldr": "The paper introduces a trajectory re-weighting technique to refine DFT-trained MLIPs using experimental EXAFS spectra, improving accuracy for nuclear fuels like UO2 and UN.", "motivation": "MLIPs inherit errors from DFT approximations, leading to discrepancies with experimental data. Refining MLIPs to match EXAFS spectra can enhance their predictive accuracy for structural properties.", "method": "A trajectory re-weighting technique combined with transfer learning and minimal training epochs refines DFT-trained MLIPs to align with experimental EXAFS spectra.", "result": "The refined MLIPs show significant improvement in predicting various properties (lattice parameters, bulk modulus, etc.) for UO2 and UN compared to unrefined versions.", "conclusion": "The approach enhances MLIP accuracy for nuclear fuels, reducing reliance on costly and hazardous experimental tests."}}
{"id": "2506.10493", "pdf": "https://arxiv.org/pdf/2506.10493", "abs": "https://arxiv.org/abs/2506.10493", "authors": ["Chao Wang", "Lei Chang", "Ling-Feng Lu", "Shunjiro Shinohara", "Zhi-De Zeng", "Ilya Zadiriev", "Elena Kralkina", "Zhi Li", "Shi-Jie Zhang", "Zi-Chen Kan", "Ye Tao", "Ding-Zhou Li"], "title": "Spatial and temporal evolutions of blue-core helicon discharge driven by planar antenna with concentric rings", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The spatial and temporal evolutions of blue-core helicon discharge driven by\na planar antenna with four concentric rings are explored on the Linear\nExperimental Advanced Device (LEAD). The discharge experiences distinct density\njumps from E mode to H mode, W mode, and blue-core mode, when RF input power\nincreases. This is similar to previous observations using other typical helicon\nantennas; however, this special antenna could drive modes of even higher levels\nfor which the blue-core plasma column is actually hollow in radius, i.e.\npeaking off-axis, which was not presented before. The column shows\ncounterclockwise rotation for blue-core mode and clockwise rotation for\nnon-blue-core mode. The reason could be attributed to the radial electric field\ndifferenceses for both modes which reverses the rotation direction via ExB\ndrive. Moreover, the centrifugal instability of blue-core helicon plasma is\ncomputed using a two-fluid flowing plasma model. It shows that the instability\nis strong for small axial wave number but becomes weak for large axial wave\nnumber. Perturbed density peaks at radius of 0.045 m, while the equilibrium\ndensity gradient peaks at radius of 0.055 m. The coincidence of their radial\nlocations suggests that it is a resistive drift mode driven by density\ngradient. The blue-core mode weakens once the magnetic field or flow rate\nexceeds the threshold value. Increasing power further leads to a smoother\nplasma density gradient. The electron temperature profiles decrease with\nincreased power, and the radial gradient of the electron temperature inside the\ncore is smaller as the magnetic field changes. To our best knowledge, it is the\nfirst detailed characterization of blue-core helicon plasma driven by planar\nantenna, especially in terms of azimuthal rotation and centrifugal instability.", "AI": {"tldr": "The paper explores blue-core helicon discharge evolution driven by a planar antenna, revealing unique hollow plasma column behavior, rotation direction changes, and centrifugal instability dynamics.", "motivation": "To characterize the spatial and temporal evolution of blue-core helicon discharge using a novel planar antenna, focusing on mode transitions, rotation, and instability.", "method": "Experiments conducted on the LEAD device with a four-ring planar antenna, analyzing discharge modes, rotation, and instability using a two-fluid plasma model.", "result": "Observed hollow blue-core plasma, rotation direction reversal, and centrifugal instability peaking off-axis. Instability weakens with high axial wave numbers and exceeds thresholds for magnetic field/flow rate.", "conclusion": "First detailed study of blue-core helicon plasma with a planar antenna, highlighting unique rotation and instability behaviors, advancing understanding of helicon discharge dynamics."}}
{"id": "2506.10273", "pdf": "https://arxiv.org/pdf/2506.10273", "abs": "https://arxiv.org/abs/2506.10273", "authors": ["V\u00edctor A Vicente-Ben\u00edtez"], "title": "Generalized Poisson kernel and solution of the Dirichlet problem for the radial Schr\u00f6dinger equation", "categories": ["math.AP", "35A24, 35C05, 35C10, 35C15, 35J10"], "comment": "28 pages", "summary": "We present an explicit construction of the solution to the Dirichlet boundary\nvalue problem for the radial Schr\\\"odinger equation in the unit ball, with a\ncomplex-valued potential $V$ satisfying the condition\n$\\int_0^1r|V(r)|dr<\\infty$. The solution is based on the construction of an\nexplicit orthogonal set of solutions for the radial equation. In the case of a\nDirichlet problem with boundary data in $W^{\\frac{1}{2},2}(\\mathbb{S}^{d-1})$,\nthe solution is expressed as a series expansion in terms of the so-called\nformal spherical polynomials. We establish conditions for the solvability and\nuniqueness of the Dirichlet problem. Based on this series representation, we\nintroduce the concept of generalized Poisson kernel, develop its main\nproperties, and investigate the conditions under which the Dirichlet problem,\nwith a boundary condition being a complex Radon measure on $\\mathbb{S}^{d-1}$,\nadmits a solution in the sense of a distributional boundary values.", "AI": {"tldr": "The paper provides an explicit solution to the Dirichlet boundary value problem for the radial Schr\u00f6dinger equation in a unit ball with a complex-valued potential, using orthogonal solutions and formal spherical polynomials. It also introduces a generalized Poisson kernel and explores solvability and uniqueness conditions.", "motivation": "The motivation is to address the Dirichlet problem for the radial Schr\u00f6dinger equation with a complex potential, extending classical results to more general boundary conditions and potentials.", "method": "The method involves constructing an explicit orthogonal set of solutions for the radial equation and expressing the solution as a series expansion using formal spherical polynomials. A generalized Poisson kernel is introduced and analyzed.", "result": "The paper establishes conditions for solvability and uniqueness of the Dirichlet problem and demonstrates how the solution can be represented distributionally for boundary conditions given by complex Radon measures.", "conclusion": "The work generalizes classical results by providing explicit solutions and tools (like the generalized Poisson kernel) for the Dirichlet problem under broader conditions, including complex potentials and distributional boundary values."}}
{"id": "2506.10509", "pdf": "https://arxiv.org/pdf/2506.10509", "abs": "https://arxiv.org/abs/2506.10509", "authors": ["Elisabetta Carlini", "Valentina Coscetti"], "title": "A semi-Lagrangian scheme for First-Order Mean Field Games based on monotone operators", "categories": ["math.NA", "cs.NA", "91A16, 49N80, 35Q89, 65M12, 65M25"], "comment": null, "summary": "We construct a semi-Lagrangian scheme for first-order, time-dependent, and\nnon-local Mean Field Games. The convergence of the scheme to a weak solution of\nthe system is analyzed by exploiting a key monotonicity property. To solve the\nresulting discrete problem, we implement a Learning Value Algorithm, prove its\nconvergence, and propose an acceleration strategy based on a Policy iteration\nmethod. Finally, we present numerical experiments that validate the\neffectiveness of the proposed schemes and show that the accelerated version\nsignificantly improves performance.", "AI": {"tldr": "A semi-Lagrangian scheme for non-local Mean Field Games is developed, with convergence proven and a Learning Value Algorithm implemented. An acceleration strategy improves performance.", "motivation": "To address the challenges of solving first-order, time-dependent, non-local Mean Field Games efficiently.", "method": "A semi-Lagrangian scheme is constructed, and a Learning Value Algorithm is implemented with a Policy iteration-based acceleration strategy.", "result": "The scheme converges to a weak solution, and the accelerated version significantly enhances performance.", "conclusion": "The proposed schemes are effective, with the accelerated version offering notable performance improvements."}}
{"id": "2506.10298", "pdf": "https://arxiv.org/pdf/2506.10298", "abs": "https://arxiv.org/abs/2506.10298", "authors": ["Anubhab Haldar", "Ali K. Hamze", "Nikhil Sivadas", "Yongwoo Shin"], "title": "GEARS H: Accurate machine-learned Hamiltonians for next-generation device-scale modeling", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "13 pages, 3 figures, later version will add supplement", "summary": "We introduce GEARS H, a state-of-the-art machine-learning Hamiltonian\nframework for large-scale electronic structure simulations. Using GEARS H, we\npresent a statistical analysis of the hole concentration induced in defective\n$\\mathrm{WSe}_2$ interfaced with Ni-doped amorphous $\\mathrm{HfO}_2$ as a\nfunction of the Ni doping rate, system density, and Se vacancy rate in 72\nsystems ranging from 3326 to 4160 atoms-a quantity and scale of interface\nelectronic structure calculation beyond the reach of conventional density\nfunctional theory codes and other machine-learning-based methods. We further\ndemonstrate the versatility of our architecture by training models for a\nmolecular system, 2D materials with and without defects, solid solution\ncrystals, and bulk amorphous systems with covalent and ionic bonds. The mean\nabsolute error of the inferred Hamiltonian matrix elements from the validation\nset is below 2.4 meV for all of these models. GEARS H outperforms other\nproposed machine-learning Hamiltonian frameworks, and our results indicate that\nmachine-learning Hamiltonian methods, starting with GEARS H, are now\nproduction-ready techniques for DFT-accuracy device-scale simulation.", "AI": {"tldr": "GEARS H is a machine-learning Hamiltonian framework for large-scale electronic structure simulations, outperforming existing methods with high accuracy.", "motivation": "To enable DFT-accuracy simulations at device-scale, which conventional methods cannot handle due to computational limits.", "method": "Uses GEARS H for statistical analysis of hole concentration in defective WSe2 interfaced with Ni-doped HfO2, and trains models for diverse systems.", "result": "Achieves mean absolute error below 2.4 meV for Hamiltonian matrix elements, surpassing other frameworks.", "conclusion": "GEARS H is production-ready for DFT-accuracy device-scale simulations, marking a milestone for machine-learning Hamiltonian methods."}}
{"id": "2506.10906", "pdf": "https://arxiv.org/pdf/2506.10906", "abs": "https://arxiv.org/abs/2506.10906", "authors": ["George J. Wilkie"], "title": "Analytic model for neutral penetration and plasma fueling", "categories": ["physics.plasm-ph", "physics.atom-ph"], "comment": "13 pages, 6 figures", "summary": "Neutral atoms recycled from wall interaction interact with confined plasma,\nthereby refueling it, most strongly in the region closest to the wall. This\noccurs near the X-point in diverted configurations, or else near the wall\nitself in limited configurations. A progression of analytic models are\ndeveloped for neutral density in the vicinity of a planar or linear source in\nan ionizing domain. First-principles neutral transport simulations with DEGAS2\nare used throughout to test the validity and limits of the model when using\nequivalent sources. The model is further generalized for strong plasma\ngradients or the inclusion of charge exchange. An important part of the problem\nof neutral fueling from recycling is thereby isolated and solved with a\nclosed-form analytic model. A key finding is that charge exchange with the\nconfined plasma can be significantly simplified with a reasonable sacrifice of\naccuracy by treating it as a loss. The several assumptions inherent to the\nmodel (and the simulations to which it is compared) can be adapted according to\nthe particular behavior of neutrals in the divertor and the manner in which\nthey cross the separatrix.", "AI": {"tldr": "The paper develops analytic models for neutral density near plasma walls, validated with simulations, and simplifies charge exchange effects.", "motivation": "To understand and model how recycled neutral atoms from wall interactions refuel confined plasma, especially near walls or X-points.", "method": "Progression of analytic models for neutral density near planar/linear sources, validated with DEGAS2 simulations, and generalized for plasma gradients or charge exchange.", "result": "Charge exchange can be simplified as a loss with reasonable accuracy, and the model isolates and solves neutral fueling from recycling.", "conclusion": "The model provides a closed-form solution for neutral fueling, adaptable to various neutral behaviors in divertors and separatrix crossings."}}
{"id": "2506.10278", "pdf": "https://arxiv.org/pdf/2506.10278", "abs": "https://arxiv.org/abs/2506.10278", "authors": ["S. N. Antontsev", "H. B. de Oliveira", "I. V. Kuznetsov", "D. A. Prokudin", "Kh. Khompysh"], "title": "Mixtures of nonhomogeneous viscoelastic incompressible fluids governed by the Kelvin-Voigt equations", "categories": ["math.AP", "35Q35, 76D03, 76T30"], "comment": null, "summary": "An initial-and boundary-value problem for the Kelvin-Voigt system, modeling a\nmixture of n incompressible and viscoelastic fluids, with non-constant density,\nis investigated in this work. The existence of global-in-time weak solutions is\nestablished: velocity, density and pressure. Under additional regularity\nassumptions, we also prove the uniqueness of the solution.", "AI": {"tldr": "The paper studies a Kelvin-Voigt system for a mixture of incompressible, viscoelastic fluids with non-constant density, proving global weak solutions and uniqueness under extra regularity.", "motivation": "To address the mathematical modeling of mixtures of incompressible and viscoelastic fluids with variable density, focusing on solution existence and uniqueness.", "method": "Investigates an initial-and boundary-value problem for the Kelvin-Voigt system, analyzing weak solutions for velocity, density, and pressure.", "result": "Establishes global-in-time weak solutions and proves uniqueness under additional regularity conditions.", "conclusion": "The work successfully demonstrates the existence and uniqueness of solutions for the described fluid mixture system."}}
{"id": "2506.10533", "pdf": "https://arxiv.org/pdf/2506.10533", "abs": "https://arxiv.org/abs/2506.10533", "authors": ["Santiago Badia", "Carsten Carstensen", "Alberto F. Martin", "Ricardo Ruiz-Baier", "Segundo Villa-Fuentes"], "title": "Non-augmented velocity-vorticity-pressure formulation for the Navier--Stokes--Brinkman--Forchheimer problem", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "The flow of incompressible fluid in highly permeable porous media in\nvorticity - velocity - Bernoulli pressure form leads to a double saddle-point\nproblem in the Navier--Stokes--Brinkman--Forchheimer equations. The paper\nestablishes, for small sources, the existence of solutions on the continuous\nand discrete level of lowest-order piecewise divergence-free Crouzeix--Raviart\nfinite elements. The vorticity employs a vector version of the pressure space\nwith normal and tangential velocity jump penalisation terms. A simple\nRaviart--Thomas interpolant leads to pressure-robust a priori error estimates.\nAn explicit residual-based a posteriori error estimate allows for efficient and\nreliable a posteriori error control. The efficiency for the Forchheimer\nnonlinearity requires a novel discrete inequality of independent interest. The\nimplementation is based upon a light-weight forest-of-trees data structure\nhandled by a highly parallel set of adaptive {mesh refining} algorithms.\nNumerical simulations reveal robustness of the a posteriori error estimates and\nimproved convergence rates by adaptive mesh-refining.", "AI": {"tldr": "The paper addresses the flow of incompressible fluid in porous media, solving a double saddle-point problem using Crouzeix--Raviart finite elements. It provides existence proofs, error estimates, and adaptive algorithms for efficient simulations.", "motivation": "To tackle the complex Navier--Stokes--Brinkman--Forchheimer equations in porous media, ensuring accurate and efficient solutions for small sources.", "method": "Uses lowest-order piecewise divergence-free Crouzeix--Raviart finite elements, penalisation terms for velocity jumps, and Raviart--Thomas interpolants for pressure-robust error estimates.", "result": "Establishes existence of solutions, provides a priori and a posteriori error estimates, and demonstrates improved convergence with adaptive mesh-refining.", "conclusion": "The approach is robust, efficient, and scalable, validated by numerical simulations."}}
{"id": "2506.10308", "pdf": "https://arxiv.org/pdf/2506.10308", "abs": "https://arxiv.org/abs/2506.10308", "authors": ["Zhen Huang", "Gunhee Park", "Garnet Kin-Lic Chan", "Lin Lin"], "title": "Coupled Lindblad pseudomode theory for simulating open quantum systems", "categories": ["quant-ph", "cond-mat.str-el", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Coupled Lindblad pseudomode theory is a promising approach for simulating\nnon-Markovian quantum dynamics on both classical and quantum platforms, with\ndynamics that can be realized as a quantum channel. We provide theoretical\nevidence that the number of coupled pseudomodes only needs to scale as\n$\\mathrm{polylog}(T/\\varepsilon)$ in the simulation time $T$ and precision\n$\\varepsilon$. Inspired by the realization problem in control theory, we also\ndevelop a robust numerical algorithm for constructing the coupled modes that\navoids the non-convex optimization required by existing approaches. We\ndemonstrate the effectiveness of our method by computing population dynamics\nand absorption spectra for the spin-boson model. This work provides a\nsignificant theoretical and computational improvement to the coupled Lindblad\nframework, which impacts a broad range of applications from classical\nsimulations of quantum impurity problems to quantum simulations on near-term\nquantum platforms.", "AI": {"tldr": "Coupled Lindblad pseudomode theory efficiently simulates non-Markovian quantum dynamics with polylog scaling in time and precision, avoiding non-convex optimization.", "motivation": "To improve the simulation of non-Markovian quantum dynamics for classical and quantum platforms by simplifying the scaling and optimization challenges.", "method": "Develops a robust numerical algorithm for constructing coupled pseudomodes, avoiding non-convex optimization, and tests it on the spin-boson model.", "result": "Demonstrates effective computation of population dynamics and absorption spectra, showing polylog scaling in simulation time and precision.", "conclusion": "The work enhances the coupled Lindblad framework, benefiting applications from quantum impurity problems to near-term quantum simulations."}}
{"id": "2506.10648", "pdf": "https://arxiv.org/pdf/2506.10648", "abs": "https://arxiv.org/abs/2506.10648", "authors": ["Weiyu Shen", "Rodolfo Ostilla-M\u00f3nico", "Xiaojue Zhu"], "title": "Vortex-magnetic competition and regime transitions in antiparallel flux tubes", "categories": ["physics.flu-dyn", "astro-ph.SR", "physics.plasm-ph"], "comment": null, "summary": "Vortex-magnetic interactions shape magnetohydrodynamic (MHD) turbulence,\ninfluencing energy transfer in astrophysical, geophysical, and industrial\nsystems. On the Sun, granular-scale vortex flows couple strongly with magnetic\nfields, channelling energy into the corona. At high Reynolds numbers, vorticity\nand magnetic fields are nearly frozen into the charged fluid, and MHD flows\nemerge from the interplay between vortex dynamics and Lorentz forces. To probe\nthis competition in a controlled setting, we revisit the canonical problem of\ntwo antiparallel flux tubes. By varying the magnetic flux threading each\ntube--and thus sweeping the interaction parameter $N_i$, which gauges\nLorentz-to-inertial force balance--we uncover three distinct regimes:\nvortex-dominated joint reconnection, instability-triggered cascade, and\nLorentz-induced vortex disruption. At low $N_i$, classical vortex dynamics\ndominate, driving joint vortex-magnetic reconnection and amplifying magnetic\nenergy via a dynamo effect. At moderate $N_i$, the system oscillates between\nvorticity-driven attraction and magnetic damping, triggering instabilities and\nnonlinear interactions that spawn secondary filaments and drive an energy\ncascade. At high $N_i$, Lorentz forces suppress vortex interactions, aligning\nthe tubes axially while disrupting vortex cores and rapidly converting magnetic\nto kinetic energy. These findings reveal how the inertial-Lorentz balance\ngoverns energy transfer and coherent structure formation in MHD turbulence,\noffering insight into vortex-magnetic coevolution in astrophysical plasmas.", "AI": {"tldr": "The paper explores how vortex-magnetic interactions in MHD turbulence affect energy transfer across different regimes, revealing three distinct behaviors based on the Lorentz-to-inertial force balance.", "motivation": "Understanding the interplay between vortex dynamics and magnetic fields in MHD turbulence is crucial for astrophysical, geophysical, and industrial systems, particularly for energy transfer processes.", "method": "The study revisits the problem of two antiparallel flux tubes, varying the magnetic flux to analyze the interaction parameter (Ni), which measures Lorentz-to-inertial force balance.", "result": "Three regimes emerge: vortex-dominated reconnection (low Ni), instability-triggered cascade (moderate Ni), and Lorentz-induced vortex disruption (high Ni). Each regime exhibits unique energy transfer mechanisms.", "conclusion": "The inertial-Lorentz balance dictates energy transfer and structure formation in MHD turbulence, providing insights into vortex-magnetic coevolution in astrophysical plasmas."}}
{"id": "2506.10318", "pdf": "https://arxiv.org/pdf/2506.10318", "abs": "https://arxiv.org/abs/2506.10318", "authors": ["Yuxuan Chen", "Shengquan Xiang", "Zhifei Zhang", "Jia-Cheng Zhao"], "title": "Exponential mixing for the randomly forced NLS equation", "categories": ["math.AP", "math.DS", "math.OC", "math.PR"], "comment": null, "summary": "This paper investigates exponential mixing of the invariant measure for\nrandomly forced nonlinear Schr\\\"{o}dinger equation, with damping and random\nnoise localized in space. Our study emphasizes the crucial role of exponential\nasymptotic compactness and control properties in establishing the ergodic\nproperties of random dynamical systems. This work extends the series [15, 45]\non the statistical behavior of randomly forced dispersive equations.", "AI": {"tldr": "The paper explores exponential mixing in the invariant measure for a randomly forced nonlinear Schr\u00f6dinger equation with damping and localized noise, highlighting the importance of exponential asymptotic compactness and control properties.", "motivation": "To understand the ergodic properties of random dynamical systems, extending prior work on the statistical behavior of randomly forced dispersive equations.", "method": "Focuses on exponential asymptotic compactness and control properties to analyze the system.", "result": "Demonstrates exponential mixing of the invariant measure for the studied equation.", "conclusion": "The findings extend knowledge on the statistical behavior of randomly forced dispersive equations, emphasizing key properties for ergodicity."}}
{"id": "2506.10636", "pdf": "https://arxiv.org/pdf/2506.10636", "abs": "https://arxiv.org/abs/2506.10636", "authors": ["Wei Chen", "Giacomo Dimarco", "Lorenzo Pareschi"], "title": "Structure and asymptotic preserving deep neural surrogates for uncertainty quantification in multiscale kinetic equations", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "The high dimensionality of kinetic equations with stochastic parameters poses\nmajor computational challenges for uncertainty quantification (UQ). Traditional\nMonte Carlo (MC) sampling methods, while widely used, suffer from slow\nconvergence and high variance, which become increasingly severe as the\ndimensionality of the parameter space grows. To accelerate MC sampling, we\nadopt a multiscale control variates strategy that leverages low-fidelity\nsolutions from simplified kinetic models to reduce variance. To further improve\nsampling efficiency and preserve the underlying physics, we introduce surrogate\nmodels based on structure and asymptotic preserving neural networks (SAPNNs).\nThese deep neural networks are specifically designed to satisfy key physical\nproperties, including positivity, conservation laws, entropy dissipation, and\nasymptotic limits. By training the SAPNNs on low-fidelity models and enriching\nthem with selected high-fidelity samples from the full Boltzmann equation, our\nmethod achieves significant variance reduction while maintaining physical\nconsistency and asymptotic accuracy. The proposed methodology enables efficient\nlarge-scale prediction in kinetic UQ and is validated across both homogeneous\nand nonhomogeneous multiscale regimes. Numerical results demonstrate improved\naccuracy and computational efficiency compared to standard MC techniques.", "AI": {"tldr": "The paper introduces a multiscale control variates strategy and surrogate models (SAPNNs) to improve Monte Carlo sampling efficiency for high-dimensional kinetic equations with stochastic parameters, achieving better accuracy and computational efficiency.", "motivation": "Traditional Monte Carlo methods for uncertainty quantification in kinetic equations suffer from slow convergence and high variance, especially in high-dimensional parameter spaces.", "method": "The approach combines multiscale control variates with low-fidelity solutions and introduces SAPNNs, designed to preserve physical properties, trained on low-fidelity models and enriched with high-fidelity samples.", "result": "The method significantly reduces variance while maintaining physical consistency and asymptotic accuracy, outperforming standard Monte Carlo techniques.", "conclusion": "The proposed methodology enables efficient large-scale prediction in kinetic uncertainty quantification, validated across various regimes."}}
{"id": "2506.10379", "pdf": "https://arxiv.org/pdf/2506.10379", "abs": "https://arxiv.org/abs/2506.10379", "authors": ["Jie Liu", "Xin Wang"], "title": "Hamiltonian Learning via Inverse Physics-Informed Neural Networks", "categories": ["quant-ph", "cond-mat.dis-nn", "physics.comp-ph"], "comment": "13 pages, 10 figures", "summary": "Hamiltonian learning (HL), enabling precise estimation of system parameters\nand underlying dynamics, plays a critical role in characterizing quantum\nsystems. However, conventional HL methods face challenges in noise robustness\nand resource efficiency, especially under limited measurements. In this work,\nwe present \\textit{Inverse Physics-Informed Neural Networks for Hamiltonian\nLearning (iPINN-HL)}, an approach that embeds the Schr\\\"{o}dinger equation\ndirectly into the machine learning procedure. This formulation allows the model\nto integrate both observational data and known physical laws to infer\nHamiltonian parameters with greater accuracy and resource efficiency. We\nbenchmark iPINN-HL against a deep-neural-network-based quantum state tomography\nmethod (denoted as DNN-HL) and demonstrate its effectiveness across several\ndifferent scenarios, including one-dimensional spin chains, cross-resonance\ngate calibration, crosstalk identification, and real-time compensation to\nparameter drift. Our results show that iPINN-HL can approach the Heisenberg\nlimit in certain settings and exhibits robustness to noises, while\noutperforming DNN-HL in accuracy and resource efficiency. Therefore, iPINN-HL\nis a powerful and flexible framework for quantum system characterization for\npractical tasks.", "AI": {"tldr": "iPINN-HL integrates physics into ML for Hamiltonian learning, outperforming DNN-HL in accuracy and efficiency.", "motivation": "Conventional HL methods struggle with noise and resource efficiency under limited measurements.", "method": "iPINN-HL embeds the Schr\u00f6dinger equation into ML, combining data and physics for parameter inference.", "result": "iPINN-HL approaches the Heisenberg limit, shows noise robustness, and beats DNN-HL in accuracy and efficiency.", "conclusion": "iPINN-HL is a robust, flexible framework for quantum system characterization."}}
{"id": "2506.10578", "pdf": "https://arxiv.org/pdf/2506.10578", "abs": "https://arxiv.org/abs/2506.10578", "authors": ["Shikun Cui", "Lili Wang", "Wendong Wang", "Juncheng Wei"], "title": "On the sharp critical mass threshold for the 3D Patlak-Keller-Segel-Navier-Stokes system via Couette flow", "categories": ["math.AP"], "comment": null, "summary": "As is well-known, the solution of the Patlak-Keller-Segel system in 3D may\nblow up in finite time regardless of any initial cell mass. In this paper, we\nare interested in the suppression of blow-up and the critical mass threshold\nfor the 3D Patlak-Keller-Segel-Navier-Stokes system via the Couette flow $(Ay,\n0, 0)$. It is proved that if the Couette flow is sufficiently strong ($A$ is\nlarge enough), then the solutions for the system are global in time in the\nperiodic domain $(x,y,z)\\in\\mathbb{T}^{3}$ as long as the initial cell mass is\nless than $16\\pi^{2}$. This result seems to be sharp, since the zero-mode\nfunction (the mean value in $x-$direction) of the three dimensional density is\na complication of the two-dimensional Keller-Segel equations, whose critical\nmass in 2D is $8\\pi$. One new observation is the dissipative decay of\n$(\\widetilde{u}_{2,0},\\widetilde{u}_{3,0})$ (see Lemma 4.3 for more details),\nthen we combine the quasi-linear method proposed by Wei-Zhang (Comm. Pure Appl.\nMath., 2021) with the zero-mode estimate of the density by the logarithmic\nHardy-Littlewood-Sobolev inequality as Bedrossian-He (SIAM J. Math. Anal.,\n2017) or He (Nonlinearity, 2025) to obtain the bounded-ness of the density and\nthe velocity.", "AI": {"tldr": "The paper investigates the suppression of blow-up in the 3D Patlak-Keller-Segel-Navier-Stokes system using Couette flow, proving global solutions exist for initial cell mass below 16\u03c0\u00b2 if the flow is strong enough.", "motivation": "To understand how Couette flow can prevent blow-up in the 3D Patlak-Keller-Segel-Navier-Stokes system and identify the critical mass threshold.", "method": "Combines quasi-linear methods with zero-mode density estimates using logarithmic Hardy-Littlewood-Sobolev inequality, leveraging dissipative decay properties.", "result": "Solutions are global for initial mass < 16\u03c0\u00b2 under strong Couette flow, aligning with the 2D critical mass of 8\u03c0.", "conclusion": "The study provides a sharp threshold for global existence, linking 3D behavior to 2D dynamics and highlighting the role of Couette flow in stabilization."}}
{"id": "2506.10661", "pdf": "https://arxiv.org/pdf/2506.10661", "abs": "https://arxiv.org/abs/2506.10661", "authors": ["Oliver Townsend", "Sergey Dolgov", "Silvia Gazzola", "Misha Kilmer"], "title": "Alternating steepest descent methods for tensor completion with applications to spectromicroscopy", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper we develop two new Tensor Alternating Steepest Descent\nalgorithms for tensor completion in the low-rank $\\star_{M}$-product format,\nwhereby we aim to reconstruct an entire low-rank tensor from a small number of\nmeasurements thereof. Both algorithms are rooted in the Alternating Steepest\nDescent (ASD) method for matrix completion, first proposed in [J. Tanner and K.\nWei, Appl. Comput. Harmon. Anal., 40 (2016), pp. 417-429]. In deriving the new\nmethods we target the X-ray spectromicroscopy undersampling problem, whereby\ndata are collected by scanning a specimen on a rectangular viewpoint with X-ray\nbeams of different energies. The recorded absorptions coefficients of the mixed\nspecimen materials are naturally stored in a third-order tensor, with spatial\nhorizontal and vertical axes, and an energy axis. To speed the X-ray\nspectromicroscopy measurement process up, only a fraction of tubes from (a\nreshaped version of) this tensor are fully scanned, leading to a tensor\ncompletion problem. In this framework we can apply any transform (such as the\nFourier transform) to the tensor tube by tube, providing a natural way to work\nwith the $\\star_{M}$-tensor algebra, and propose: (1) a tensor completion\nalgorithm that is essentially ASD reformulated in the $\\star_{M}$-induced\nmetric space and (2) a tensor completion algorithm that solves a set of\n(readily parallelizable) independent matrix completion problems for the frontal\nslices of the transformed tensor. The two new methods are tested on real X-ray\nspectromicroscopy data, demonstrating that they achieve the same reconstruction\nerror with fewer samples from the tensor compared to the matrix completion\nalgorithms applied to a flattened tensor.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.10418", "pdf": "https://arxiv.org/pdf/2506.10418", "abs": "https://arxiv.org/abs/2506.10418", "authors": ["Gibaek Kim", "Jungho Kim"], "title": "Efficient nanophotonic devices optimization using deep neural network trained with physics-based transfer learning (PBTL) methodology", "categories": ["physics.optics", "physics.comp-ph"], "comment": null, "summary": "We propose a neural network(NN)-based surrogate modeling framework for\nphotonic device optimization, especially in domains with imbalanced feature\nimportance and high data generation costs. Our framework, which comprises\nphysics-based transfer learning (PBTL)-enhanced surrogate modeling and\nscalarized multi-objective genetic algorithms (GAs), offers a generalizable\nsolution for photonic design automation with minimal data resources.To validate\nthe framework, we optimize mid-infrared quantum cascade laser (QCL) structures\nconsisting of two regions, active and injection, which have different levels of\nfeature importance. The optimization targets include five key QCL performance\nmetrics such as modal gain, emission wavelength, linewidth, and effective\ninjection, extraction energies. To address the challenge of multiple local\noptima in the output latent space, we integrate a deep neural network total\npredictor (DNN-TP) with a GA, enabling scalable and nature-inspired\noptimization. By replacing computationally expensive numerical simulations with\nthe DNN-TP surrogate model, the optimization achieves a speed-up of over 80,000\ntimes, allowing large-scale exploration of the QCL design space.To improve\nmodel generalization with limited data, we introduce PBTL, which transfers\nknowledge from a DNN core predictor (DNN-CP) trained on active-region\nstructures. This approach yields a 0.69 percentage increase in prediction\naccuracy, equivalent to a 50 percentage reduction in training data\nrequirements, and leads to generate more feasible device structure with 60\npercentage improvement in evaluation metric during optimization.", "AI": {"tldr": "A NN-based surrogate modeling framework is proposed for photonic device optimization, combining PBTL-enhanced surrogate modeling and multi-objective GAs, achieving significant speed-up and improved accuracy with limited data.", "motivation": "To address challenges in photonic device optimization, such as imbalanced feature importance and high data generation costs, by providing a generalizable solution with minimal data resources.", "method": "The framework integrates physics-based transfer learning (PBTL) for enhanced surrogate modeling and scalarized multi-objective genetic algorithms (GAs) for optimization. A DNN-TP surrogate model replaces expensive simulations, and PBTL transfers knowledge from a DNN-CP trained on active-region structures.", "result": "Achieves an 80,000x speed-up in optimization, a 0.69% increase in prediction accuracy, and a 60% improvement in evaluation metrics for feasible device structures.", "conclusion": "The proposed framework efficiently optimizes photonic devices with limited data, demonstrating significant improvements in speed, accuracy, and feasibility."}}
{"id": "2506.10595", "pdf": "https://arxiv.org/pdf/2506.10595", "abs": "https://arxiv.org/abs/2506.10595", "authors": ["Lucia Arens", "Marius Gritl"], "title": "On local well-posedness for the nonlinear Schr\u00f6dinger equation with general power nonlinearity", "categories": ["math.AP"], "comment": null, "summary": "The nonlinear Schr\\\"odinger equation plays a fundamental role in mathematical\nphysics, particularly in the study of quantum mechanics and Bose-Einstein\ncondensation. This paper explores two distinct approaches to establishing the\nlocal well-posedness of solutions: the semigroup theory ansatz and the\nStrichartz estimates ansatz. Semigroup theory provides a general and elegant\nframework rooted in functional analysis, allowing for the interpretation of the\ntime evolution of solutions as operator semigroups. Strichartz estimates,\ndeveloped specifically for dispersive equations, offer an alternative technique\nbased on refined space-time estimates and fixed-point arguments. We\nsystematically analyze and compare both approaches and apply them to nonlinear\nSchr\\\"odinger equations where the nonlinearity is given by $F(u)=\\lambda|u|^p\nu$ for some $\\lambda \\in \\mathbb{R}$. So our results extend beyond the\nphysically relevant case $p=2$.", "AI": {"tldr": "The paper compares semigroup theory and Strichartz estimates for local well-posedness of nonlinear Schr\u00f6dinger equations, extending results beyond the case p=2.", "motivation": "To explore and compare two mathematical approaches for solving nonlinear Schr\u00f6dinger equations, which are key in quantum mechanics and Bose-Einstein condensation.", "method": "Uses semigroup theory (functional analysis) and Strichartz estimates (dispersive equations) to analyze local well-posedness.", "result": "Demonstrates applicability of both methods for nonlinearities beyond p=2.", "conclusion": "Both approaches are effective, with semigroup theory offering generality and Strichartz estimates providing refined estimates."}}
{"id": "2506.10723", "pdf": "https://arxiv.org/pdf/2506.10723", "abs": "https://arxiv.org/abs/2506.10723", "authors": ["Danilo Costarelli", "Donato Lavella"], "title": "Semi-discrete moduli of smoothness and their applications in one- and two- sided error estimates", "categories": ["math.NA", "cs.NA", "math.FA"], "comment": null, "summary": "In this paper, we introduce a new semi-discrete modulus of smoothness, which\ngeneralizes the definition given by Kolomoitsev and Lomako (KL) in 2023 (in the\npaper published in the J. Approx. Theory), and we establish very general one-\nand two- sided error estimates under non-restrictive assumptions. The proposed\nresults have been proved exploiting the regularization and approximation\nproperties of certain Steklov integrals introduced by Sendov and Popov in 1983,\nand differ from the ones given by Kolomoitsev and Lomako. In addition, the\nproof of the original KL approximation theorems were strictly related to the\napplication of certain classical results of the trigonometric best\napproximation, and thus, they are applicable only for operators of the\ntrigonometric type. By the definition of semi-discrete moduli of smoothness\nhere proposed, we are able to deduce applications also for operators that are\nnot necessarily of the trigonometric type, and can also be used to derive\nsharper estimates than those that can be achieved by the classical averaged\nmoduli of smoothness ($\\tau$-moduli). Furthermore, a Rathore-type theorem is\nestablished, and a new notion of K-functional is also introduced showing its\nequivalence with the semi-discrete modulus of smoothness and its realization.\nOne-sided estimates of approximation can be established for classical operators\non bounded domains, such as the Bernstein polynomials. In the case of\napproximation operators on the whole real line, one-sided estimates can be\nachieved, e.g., for the Shannon sampling (cardinal) series, as well as for the\nso-called generalized sampling operators. At the end of the paper, the case of\nalgebraic Lagrange approximation has been considered, showing the main open\nproblems in order to derive two-sided error estimates in this noteworthy case.", "AI": {"tldr": "The paper introduces a new semi-discrete modulus of smoothness, generalizing prior work, and provides broad error estimates for non-trigonometric operators, including sharper results than classical methods.", "motivation": "To extend and generalize the definition of semi-discrete moduli of smoothness beyond trigonometric operators, enabling broader applications and sharper estimates.", "method": "Uses regularization and approximation properties of Steklov integrals, avoiding reliance on trigonometric best approximation results. Introduces a new K-functional and proves its equivalence to the semi-discrete modulus.", "result": "Establishes one- and two-sided error estimates for various operators (e.g., Bernstein polynomials, Shannon sampling series) and introduces a Rathore-type theorem.", "conclusion": "The new modulus of smoothness and K-functional offer versatile tools for approximation theory, with potential for further research in algebraic Lagrange approximation."}}
{"id": "2506.10701", "pdf": "https://arxiv.org/pdf/2506.10701", "abs": "https://arxiv.org/abs/2506.10701", "authors": ["Simon Elias Schrader", "H\u00e5kon Emil Kristiansen", "Thomas Bondo Pedersen", "Simen Kvaal"], "title": "Time-dependent Gaussian basis sets for many-body systems using Rothe's method: A mean-field study", "categories": ["physics.chem-ph", "physics.comp-ph"], "comment": "18 pages, 9 figures", "summary": "A challenge in modeling time-dependent strong-field processes such as\nhigh-harmonic generation for many-body systems, is how to effectively represent\nthe electronic continuum. We apply Rothe's method to the time-dependent\nHartree-Fock (TDHF) and density functional theory (TDDFT) equations of motion\nfor the orbitals, which reformulates them as an optimization problem. We show\nthat thawed, complex-valued Gaussian basis sets can be propagated efficiently\nfor these orbital-based approaches, removing the need for grids. In particular,\nwe illustrate that qualitatively correct results can often be obtained by using\njust a few fully flexible Gaussians that describe the unbound dynamics for both\nTDHF and TDDFT. Grid calculations can be reproduced quantitatively using\n$30$--$100$ Gaussians for intensities up to $4\\times10^{14}$ W/cm$^2$ for the\none-dimensional molecular systems considered in this work.", "AI": {"tldr": "The paper proposes using Rothe's method with Gaussian basis sets for efficient modeling of time-dependent strong-field processes in many-body systems, eliminating the need for grids.", "motivation": "Addressing the challenge of representing the electronic continuum in time-dependent strong-field processes like high-harmonic generation for many-body systems.", "method": "Applies Rothe's method to TDHF and TDDFT equations, reformulating them as an optimization problem, and uses thawed, complex-valued Gaussian basis sets for orbital propagation.", "result": "Demonstrates that few flexible Gaussians yield qualitatively correct results, and grid calculations can be quantitatively reproduced with 30\u2013100 Gaussians for intensities up to 4\u00d710\u00b9\u2074 W/cm\u00b2 in 1D systems.", "conclusion": "The method offers an efficient, grid-free approach for modeling strong-field processes in many-body systems."}}
{"id": "2506.10608", "pdf": "https://arxiv.org/pdf/2506.10608", "abs": "https://arxiv.org/abs/2506.10608", "authors": ["Vedansh Arya", "Vesa Julin"], "title": "Harnack inequality for degenerate fully nonlinear parabolic equations", "categories": ["math.AP", "35K55, 35K65, 35B65"], "comment": null, "summary": "We consider degenerate fully nonlinear parabolic equations, which generalize\nthe p-parabolic equation with $p>2$ to nondivergence form operators. We prove\nan intrinsic Harnack inequality for nonnegative solutions and a weak Harnack\ninequality for nonnegative supersolutions. These results can be seen as the\nnondivergence form counterparts of the results by DiBenedetto, Gianazza and\nVespri (Acta Math. 2008) and Kuusi (Ann. Sc. Norm. Super. Pisa 2008).", "AI": {"tldr": "The paper proves intrinsic and weak Harnack inequalities for nonnegative solutions and supersolutions of degenerate fully nonlinear parabolic equations, extending results from divergence form to nondivergence form.", "motivation": "To generalize the p-parabolic equation (p>2) to nondivergence form operators and establish Harnack inequalities, bridging a gap in existing literature.", "method": "The authors analyze degenerate fully nonlinear parabolic equations, adapting techniques from divergence form to nondivergence form.", "result": "Intrinsic Harnack inequality for nonnegative solutions and weak Harnack inequality for nonnegative supersolutions are proven.", "conclusion": "The results extend prior work on divergence form equations to nondivergence form, providing new tools for analyzing such equations."}}
{"id": "2506.10763", "pdf": "https://arxiv.org/pdf/2506.10763", "abs": "https://arxiv.org/abs/2506.10763", "authors": ["Mejdi Aza\u00efez", "Tom\u00e1s Chac\u00f3n Rebollo", "Carlos N\u00fa\u00f1ez Fern\u00e1ndez", "Samuele Rubino"], "title": "Reduced-Order Time Splitting for Navier-Stokes with Open Boundaries", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this work, we propose a Proper Orthogonal Decomposition-Reduced Order\nModel (POD-ROM) applied to time-splitting schemes for solving the Navier-Stokes\nequations with open boundary conditions. In this method, we combine three\nstrategies to reduce the computing time to solve NSE: time splitting, reduction\nof the computational domain through non-standard treatment of open boundary\nconditions and reduced order modelling. To make the work self-contained, we\nfirst present the formulation of the time-splitting scheme applied to the\nNavier-Stokes equations with open boundary conditions, employing a first-order\nEuler time discretization and deriving the non-standard boundary condition for\npressure. Then, we construct a Galerkin projection-based ROM using POD with two\ndifferent treatments of the pressure boundary condition on the outlet. We\npropose a comparative performance analysis between the standard\nprojection-based POD-ROM (fully intrusive) and a hybrid POD-ROM that combines a\nprojection-based approach (intrusive) with a data-driven technique\n(non-intrusive) using Radial Basis Functions (RBF). We illustrate this\ncomparison through two different numerical tests: the flow in a bifurcated tube\nand the benchmark numerical test of the flow past cylinder, numerically\ninvestigating the efficiency and accuracy of both ROMs.", "AI": {"tldr": "The paper proposes a POD-ROM for solving Navier-Stokes equations with open boundary conditions, combining time-splitting, domain reduction, and reduced order modeling. It compares intrusive and hybrid ROMs using numerical tests.", "motivation": "To reduce computational time for solving Navier-Stokes equations by integrating time-splitting, domain reduction, and reduced order modeling.", "method": "Combines time-splitting, non-standard boundary conditions, and POD-ROM with Galerkin projection. Compares intrusive and hybrid (intrusive + data-driven) ROMs.", "result": "Numerical tests (bifurcated tube flow and cylinder flow) demonstrate efficiency and accuracy of the proposed ROMs.", "conclusion": "The hybrid POD-ROM shows promise in balancing accuracy and computational efficiency for Navier-Stokes simulations."}}
{"id": "2506.10794", "pdf": "https://arxiv.org/pdf/2506.10794", "abs": "https://arxiv.org/abs/2506.10794", "authors": ["Clint van Hoesel", "Reinder Coehoorn", "Peter A. Bobbert"], "title": "Dipole-quadrupole coupling in triplet exciton-polaron quenching in a phosphorescent OLED emission layer", "categories": ["physics.atm-clus", "physics.chem-ph", "physics.comp-ph"], "comment": "15 pages, 8 figures", "summary": "Improving the efficiency and stability of organic light-emitting diodes\n(OLEDs) will further expand their present success in display applications.\nTriplet exciton-polaron quenching (TPQ) is an important cause of limited\nefficiency and stability in modern phosphorescent OLEDs, where triplet excitons\nare the emitting species. Lack of understanding of the TPQ mechanism in these\nOLEDs impedes the development of more efficient and stable OLEDs. We\ninvestigate the TPQ mechanism for triplet excitons on a phosphorescent guest\ninteracting with hole polarons on a host. Our quantum-chemical calculations\nshow that at distances relevant for TPQ the F\\\"orster approximation for the TPQ\nrate fails and that dipole-quadrupole coupling is dominant. This resolves a\ndiscrepancy between estimates of the TPQ rate obtained from an OLED device\nstudy and from the overlap between the emission spectrum of the emitter and\nabsorption spectrum of the charged host. Equivalently to the F\\\"orster radius\nfor dipole-dipole TPQ, the dipole-quadrupole TPQ rate can be quantified by a\ndipole-quadrupole radius obtained from the overlap between the emission\nspectrum of the emitter and the quadrupolar absorption spectrum of the charged\nhost. The findings of this work are expected to have a broad relevance and to\nbe useful in developing phosphorescent emitter-host combinations with reduced\nTPQ.", "AI": {"tldr": "The paper investigates the triplet exciton-polaron quenching (TPQ) mechanism in phosphorescent OLEDs, revealing that dipole-quadrupole coupling dominates over F\u00f6rster approximation, providing a new metric for TPQ rate.", "motivation": "Understanding TPQ is crucial for improving OLED efficiency and stability, but current lack of knowledge hinders progress.", "method": "Quantum-chemical calculations were used to study TPQ for triplet excitons on a phosphorescent guest interacting with hole polarons on a host.", "result": "The study found that dipole-quadrupole coupling dominates TPQ at relevant distances, resolving discrepancies in TPQ rate estimates.", "conclusion": "The findings offer a new approach to quantify TPQ and can guide the development of more efficient and stable phosphorescent OLEDs."}}
{"id": "2506.10611", "pdf": "https://arxiv.org/pdf/2506.10611", "abs": "https://arxiv.org/abs/2506.10611", "authors": ["Mokhtar Kirane", "Ahmad Z. Fino", "Berikbol T. Torebek", "Zineb Sabbagh"], "title": "Cazenave-Dickstein-Weissler-type extension of Fujita's problem on Heisenberg groups", "categories": ["math.AP"], "comment": "21 pages", "summary": "This paper examines the critical exponents for the existence of global\nsolutions to the equation \\begin{equation*} \\begin{array}{ll} \\displaystyle\nu_t-\\Delta_{\\mathbb{H}}u=\\int_0^t(t-s)^{-\\gamma}|u(s)|^{p-1}u(s)\\,ds,&\\qquad\n0\\leq\\gamma<1,\\,\\,\\, {\\eta\\in \\mathbb{H}^n,\\,\\,\\,t>0,}\n\\end{array}\\end{equation*} on the Heisenberg groups $\\mathbb{H}^n.$ There\nexists a critical exponent $$p_c=\n\\max\\Big\\{\\frac{1}{\\gamma},p_\\gamma\\Big\\}\\in(0,+\\infty],\\quad\\hbox{with}\\quad\np_\\gamma=1+\\frac{2(2-\\gamma)}{Q-2+2\\gamma},\\,\\,Q=2n+2$$ such that for all\n$1<p\\leq p_c,$ no global solution exists regardless of the non-negative initial\ndata, while for $p>p_c$, a global positive solution exists if the initial data\nis sufficiently small. The results obtained are a natural extension of the\nresults of Cazenave et al. [Nonlinear Analysis 68 (2008), 862-874], where\nsimilar studies were carried out in $\\mathbb{R}^n$. Also given are several\ntheorems concerning the lifespan estimates of local solutions for different\ncases of initial data. The proofs of the main results are based on test\nfunction methods and Banach fixed point principle.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.10820", "pdf": "https://arxiv.org/pdf/2506.10820", "abs": "https://arxiv.org/abs/2506.10820", "authors": ["Subhash Paudel", "Nail K. Yamaleev"], "title": "A Combined Parallel-in-time Direct Inverse (ParaDIn)-Parareal Method for Nonlinear Differential Equations", "categories": ["math.NA", "cs.NA", "65M06, 65F05, 65Y05"], "comment": "24 pages. arXiv admin note: text overlap with arXiv:2406.00878", "summary": "As has been shown in our previous work, the parallel-in-time direct inverse\n(ParaDIn) method introduced by Yamaleev and Paudel in (arXiv: 2406.00878v1,\n2024) imposes some constraint on the maximum number of time levels, $N_t$, that\ncan be integrated in parallel. To circumvent this problem and further increase\nthe speedup, we combine the ParaDIn method with the Parareal algorithm to\nefficiently parallelize the first-order time derivative term in nonlinear\npartial differential equations discretized by the method of lines. The main\nidea of the proposed approach is to use a block-Jacobi preconditioner, so that\neach block is solved by using the ParaDIn method. To accelerate the convergence\nof Jacobi iterations, we use the Parareal method which can be interpreted as a\ntwo-level multigrid method in time. In contrast to the conventional Parareal\nalgorithm whose coarse grid correction step is performed sequentially, both the\ncoarse- and fine-grid propagators in the proposed approach are implemented in\nparallel by using the ParaDIn method, thus significantly increasing the\nparallel performance of the combined algorithm. Numerical results show that the\nnew combined ParaDIn-Parareal method provides the speedup of up to 124 on 480\ncomputing cores as compared with the sequential first-order implicit backward\ndifference (BDF1) scheme for the 2-D nonlinear heat and Burgers equations with\nboth smooth and discontinuous solutions.", "AI": {"tldr": "The paper combines the ParaDIn method with the Parareal algorithm to parallelize time derivatives in nonlinear PDEs, achieving a speedup of 124 on 480 cores.", "motivation": "The ParaDIn method has constraints on parallel time levels, limiting speedup. Combining it with Parareal aims to overcome this.", "method": "Uses a block-Jacobi preconditioner with ParaDIn for each block, accelerated by Parareal (a two-level multigrid in time). Both coarse- and fine-grid propagators are parallelized.", "result": "Achieves a speedup of 124 on 480 cores compared to sequential BDF1 for 2-D nonlinear heat and Burgers equations.", "conclusion": "The combined ParaDIn-Parareal method significantly improves parallel performance for solving nonlinear PDEs."}}
{"id": "2506.10812", "pdf": "https://arxiv.org/pdf/2506.10812", "abs": "https://arxiv.org/abs/2506.10812", "authors": ["S. Rendon Restrepo", "T. Rometsch", "U. Ziegler", "O. Gressel"], "title": "Self-gravity in thin protoplanetary discs: 1. The smoothing-length approximation versus the exact self-gravity kernel", "categories": ["astro-ph.EP", "astro-ph.IM", "physics.comp-ph"], "comment": null, "summary": "Planet-forming discs often contain structures like spiral arms, typically\nlinked to the disc's gravitational forces. In 2D models, an ad hoc softening\nprescription is commonly used for self-gravity, but this overlooks the vertical\nstructure's impact, suppresses the Newtonian nature of gravity at short\ndistances and doesn't respect Newton's third law.\n  To address these issues, associated with a Plummer potential approximation,\nwe developed an exact self-gravity kernel for thin, hydrostatically supported\ndiscs, including a dust fluid component. Our analytical framework provides a\nprecise 2D self-gravity prescription validated by benchmarks and 2D/3D\nnumerical tests.\n  The derived kernel, based on modified Bessel functions, maintains Newtonian\ngravitation features, such as point-wise symmetry, a smooth transition from\nlight to massive discs and a singularity at zero distance, among others. In\ncontrast to other prescriptions found in the literature, it proves capable of\nleading to an additional, and previously unnoticed, source of gravitational\nrunaway discernible only at infinitesimal distances.\n  We finally note that our new prescription remains compatible with methods\nbased on the fast Fourier transform, affording superior computational\nefficiency. Our exact kernel formulation overcomes substantial limitations\ninherent in the smoothing-length approach. It permits a novel, fully consistent\ntreatment of self-gravity in Gaussian-stratified thin discs. The approach, that\nmakes the usage of the Plummer potential obsolete, will prove useful to\nstudying all common planet formation scenarios, which are often backed by\n2D-flat numerical simulations. Accordingly, in an accompanying paper, we will\ninvestigate how the occurence of the gravitational instability is affected.", "AI": {"tldr": "The paper introduces an exact self-gravity kernel for thin discs, addressing flaws in traditional softening prescriptions and enabling more accurate 2D simulations of planet-forming discs.", "motivation": "Traditional 2D models use ad hoc softening for self-gravity, which neglects vertical structure, distorts Newtonian gravity, and violates Newton's third law. This work aims to provide a precise alternative.", "method": "Developed an analytical self-gravity kernel for thin, hydrostatically supported discs, validated through benchmarks and 2D/3D tests. The kernel uses modified Bessel functions to maintain Newtonian features.", "result": "The new kernel preserves Newtonian gravitation properties, identifies a new gravitational runaway source, and remains computationally efficient with FFT-based methods.", "conclusion": "The exact kernel overcomes smoothing-length limitations and enables consistent self-gravity treatment in thin discs, useful for planet formation studies. Future work will explore its impact on gravitational instability."}}
{"id": "2506.10761", "pdf": "https://arxiv.org/pdf/2506.10761", "abs": "https://arxiv.org/abs/2506.10761", "authors": ["Dominik Schlagenhauf"], "title": "Stability of the Morse Index for the $p$-harmonic Approximation of Harmonic Maps into Homogeneous Spaces", "categories": ["math.AP", "35J92, 58E05, 35J50, 35J47, 58E12, 58E20, 53A10, 53C43"], "comment": "arXiv admin note: text overlap with arXiv:2502.09600", "summary": "In the joint work of the author with Da Lio and Rivi\\`ere (Morse Index\nStability for Sequences of Sacks-Uhlenbeck Maps into a Sphere) we studied the\nstability of the Morse index for Sacks-Uhlenbeck sequences into spheres as\n$p\\searrow2$. These are critical points of the energy $E_p(u) := \\int_\\Sigma\n\\left( 1+|\\nabla u|^2\\right)^{p/2} \\ dvol_\\Sigma,$ where $u:\\Sigma \\rightarrow\nS^n$ is a map from a closed Riemannian surface $\\Sigma$ into a sphere $ S^n$.\nIn this paper we extend the results found in our previous work to the case of\nSacks-Uhlenbeck sequences into homogeneous spaces, by incorporating the\nstrategy introduced by Bayer and Roberts (Energy identity and no neck property\nfor $\\epsilon$-harmonic and $\\alpha$-harmonic maps into homogeneous target\nmanifolds). In the spirit of the work of Da Lio, Gianocca and Rivi\\`ere (Morse\nIndex Stability for Critical Points to Conformally invariant Lagrangians), we\nshow in this setting the upper semicontinuity of the Morse index plus nullity\nand an improved pointwise estimate of the gradient in the neck regions around\nblow up points.", "AI": {"tldr": "The paper extends previous results on Morse index stability for Sacks-Uhlenbeck sequences into spheres to homogeneous spaces, using methods from Bayer and Roberts, and shows upper semicontinuity of Morse index plus nullity and improved gradient estimates in neck regions.", "motivation": "To generalize Morse index stability results from spheres to homogeneous spaces and improve understanding of gradient behavior near blow-up points.", "method": "Extends prior work by incorporating Bayer and Roberts' strategy for homogeneous spaces, focusing on Sacks-Uhlenbeck sequences and analyzing Morse index and nullity.", "result": "Upper semicontinuity of Morse index plus nullity is proven, along with improved gradient estimates in neck regions around blow-up points.", "conclusion": "The study successfully generalizes Morse index stability to homogeneous spaces and provides refined gradient estimates, advancing the understanding of critical points in this context."}}
{"id": "2506.10894", "pdf": "https://arxiv.org/pdf/2506.10894", "abs": "https://arxiv.org/abs/2506.10894", "authors": ["Pedro B. Bazon", "Cristian G. Gebhardt", "Gustavo C. Buscaglia", "Roberto F. Ausas"], "title": "Numerical approximation of a PDE-constrained Optimization problem that appears in Data-Driven Computational Mechanics", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We investigate an optimization problem that arises when working within the\nparadigm of Data-Driven Computational Mechanics. In the context of the\ndiffusion-reaction problem, such an optimization problem seeks for the\ncontinuous primal fields (gradient and flux) that are closest to some\npredefined discrete fields taken from a material data set. The optimization is\nperformed over primal fields that satisfy the physical conservation law and the\ngeometrical compatibility. We consider a reaction term in the conservation law,\nwhich has the effect of coupling all the optimality conditions. We first\nestablish the well-posedness in the continuous setting. Then, we propose stable\nfinite element discretizations that consistently approximate the continuous\nformulation, preserving its saddle-point structure and allowing for equal-order\ninterpolation of all fields. Finally, we demonstrate the effectiveness of the\nproposed methods through a set of numerical examples.", "AI": {"tldr": "The paper addresses an optimization problem in Data-Driven Computational Mechanics, focusing on continuous primal fields for diffusion-reaction problems, ensuring physical and geometrical constraints. It proves well-posedness, proposes stable finite element methods, and validates with numerical examples.", "motivation": "To solve optimization problems in Data-Driven Computational Mechanics by finding continuous primal fields close to predefined discrete data, while adhering to physical and geometrical constraints.", "method": "Establishes well-posedness in continuous setting, proposes stable finite element discretizations preserving saddle-point structure, and uses equal-order interpolation for all fields.", "result": "Demonstrates effectiveness through numerical examples, showing the proposed methods work well in practice.", "conclusion": "The study successfully addresses the optimization problem, providing a robust framework for Data-Driven Computational Mechanics with validated numerical results."}}
{"id": "2506.10944", "pdf": "https://arxiv.org/pdf/2506.10944", "abs": "https://arxiv.org/abs/2506.10944", "authors": ["Jingxuan Ding", "Laura Zichi", "Matteo Carli", "Menghang Wang", "Albert Musaelian", "Yu Xie", "Boris Kozinsky"], "title": "Coupled reaction and diffusion governing interface evolution in solid-state batteries", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Understanding and controlling the atomistic-level reactions governing the\nformation of the solid-electrolyte interphase (SEI) is crucial for the\nviability of next-generation solid state batteries. However, challenges persist\ndue to difficulties in experimentally characterizing buried interfaces and\nlimits in simulation speed and accuracy. We conduct large-scale explicit\nreactive simulations with quantum accuracy for a symmetric battery cell,\n{\\symcell}, enabled by active learning and deep equivariant neural network\ninteratomic potentials. To automatically characterize the coupled reactions and\ninterdiffusion at the interface, we formulate and use unsupervised\nclassification techniques based on clustering in the space of local atomic\nenvironments. Our analysis reveals the formation of a previously unreported\ncrystalline disordered phase, Li$_2$S$_{0.72}$P$_{0.14}$Cl$_{0.14}$, in the\nSEI, that evaded previous predictions based purely on thermodynamics,\nunderscoring the importance of explicit modeling of full reaction and transport\nkinetics. Our simulations agree with and explain experimental observations of\nthe SEI formations and elucidate the Li creep mechanisms, critical to dendrite\ninitiation, characterized by significant Li motion along the interface. Our\napproach is to crease a digital twin from first principles, without adjustable\nparameters fitted to experiment. As such, it offers capabilities to gain\ninsights into atomistic dynamics governing complex heterogeneous processes in\nsolid-state synthesis and electrochemistry.", "AI": {"tldr": "The paper uses large-scale reactive simulations with quantum accuracy to study SEI formation in solid-state batteries, revealing a new crystalline disordered phase and Li creep mechanisms.", "motivation": "Understanding atomistic-level reactions in SEI formation is critical for next-generation solid-state batteries, but experimental and simulation challenges persist.", "method": "Large-scale explicit reactive simulations with quantum accuracy, enabled by active learning and deep equivariant neural network interatomic potentials, plus unsupervised classification techniques.", "result": "Discovery of a new crystalline disordered phase (Li$_2$S$_{0.72}$P$_{0.14}$Cl$_{0.14}$) in SEI and insights into Li creep mechanisms.", "conclusion": "The approach provides a parameter-free digital twin for studying complex heterogeneous processes in solid-state synthesis and electrochemistry."}}
{"id": "2506.10839", "pdf": "https://arxiv.org/pdf/2506.10839", "abs": "https://arxiv.org/abs/2506.10839", "authors": ["Filip Ficek", "Maciej Maliborski"], "title": "New class of time-periodic solutions to the 1D cubic wave equation", "categories": ["math.AP", "math-ph", "math.MP", "35B10, 68V05, 35B32, 35L71"], "comment": "18 pages, 2 figures. Includes Mathematica code and data files", "summary": "In recent papers (arXiv:2407.16507, arXiv:2408.05158) we presented results\nsuggesting the existence of a new class of time-periodic solutions to the\ndefocusing cubic wave equation on a one-dimensional interval with Dirichlet\nboundary conditions. Here we confirm these findings by rigorously constructing\nsolutions from this class. The proof uses rational arithmetic computations to\nverify essential operator bounds.", "AI": {"tldr": "The paper confirms the existence of a new class of time-periodic solutions for the defocusing cubic wave equation using rigorous construction and rational arithmetic computations.", "motivation": "To validate earlier findings suggesting new time-periodic solutions for the defocusing cubic wave equation under Dirichlet boundary conditions.", "method": "Rigorous construction of solutions using rational arithmetic computations to verify operator bounds.", "result": "Successful confirmation and construction of the proposed time-periodic solutions.", "conclusion": "The study rigorously establishes the existence of the new class of solutions, supporting prior theoretical suggestions."}}
{"id": "2506.10935", "pdf": "https://arxiv.org/pdf/2506.10935", "abs": "https://arxiv.org/abs/2506.10935", "authors": ["Ekaterina Grishina", "Matvey Smirnov", "Maxim Rakhuba"], "title": "Accelerating Newton-Schulz Iteration for Orthogonalization via Chebyshev-type Polynomials", "categories": ["math.NA", "cs.NA", "65F25, 65F60, 53Z50, 68W25"], "comment": null, "summary": "The problem of computing optimal orthogonal approximation to a given matrix\nhas attracted growing interest in machine learning. Notable applications\ninclude the recent Muon optimizer or Riemannian optimization on the Stiefel\nmanifold. Among existing approaches, the Newton-Schulz iteration has emerged as\na particularly effective solution, as it relies solely on matrix\nmultiplications and thus achieves high computational efficiency on GPU\nhardware. Despite its efficiency, the method has inherent limitations - its\ncoefficients are fixed and thus not optimized for a given matrix. In this paper\nwe address this issue by proposing a Chebyshev-optimized version of\nNewton-Schulz (CANS). Based on the Chebyshev's alternance theorem, we\ntheoretically derive optimal coefficients for the 3-rd order Newton-Schulz\niteration and apply a Remez algorithm to compute optimal higher-degree\npolynomials. We leverage these polynomials to construct controlled approximate\northogonalization schemes, which is of interest in deep learning applications.\nPractically, we demonstrate the method's effectiveness in two key applications:\northogonalization in the Muon optimizer, and providing an efficient retraction\nalternative for Riemannian optimization on the Stiefel manifold.", "AI": {"tldr": "The paper introduces Chebyshev-optimized Newton-Schulz (CANS), a method to improve orthogonal matrix approximation by optimizing coefficients using Chebyshev's theorem and Remez algorithm.", "motivation": "Existing Newton-Schulz iteration is efficient but uses fixed coefficients, limiting its adaptability. The paper aims to optimize these coefficients for better performance.", "method": "The authors derive optimal coefficients for the 3rd-order Newton-Schulz iteration using Chebyshev's alternance theorem and extend it to higher-degree polynomials via the Remez algorithm.", "result": "CANS improves orthogonalization in applications like the Muon optimizer and Riemannian optimization on the Stiefel manifold.", "conclusion": "The proposed CANS method offers a more efficient and adaptable solution for orthogonal matrix approximation, with practical benefits in machine learning."}}
{"id": "2506.10870", "pdf": "https://arxiv.org/pdf/2506.10870", "abs": "https://arxiv.org/abs/2506.10870", "authors": ["Yuxin Li", "Meijie Yang", "Xiaojun Chang"], "title": "Normalized solutions for a Sobolev critical quasilinear Schr\u00f6dinger equation", "categories": ["math.AP"], "comment": "57pages", "summary": "In this paper, we study the existence of normalized solutions for the\nfollowing quasilinear Schr\\\"odinger equation with critical exponent:\n  \\begin{equation*}\n  -\\Delta u-u\\Delta (u^2)+\\lambda\nu=\\tau|u|^{q-2}u+|u|^{2\\cdot2^*-2}u,~~~~x\\in\\R^N,\n  \\end{equation*}\n  under the mass constraint $\\int_{\\R^N}|u|^2dx=c$ for some prescribed $c>0$.\nHere $\\tau\\in \\mathbb{R}$ is a parameter, $\\lambda\\in\\R$ appears as a Lagrange\nmultiplier, $N\\ge3$, $2^*:=\\frac{2N}{N-2}$ and $2<q<2\\cdot2^*$. By deriving\nprecise energy level estimates and establishing new convergence theorems, we\napply the perturbation method to establish several existence results for\n$\\tau>0$ in the Sobolev critical regime:\n  [label=(\\alph*)]\n  \\item For the case of $2<q<2+\\frac{4}{N}$, we obtain the existence of two\nsolutions, one of which is a local minimizer, and the other is a mountain pass\ntype solution, under explicit conditions on $c>0$;\n  \\item For the case of $2+\\frac{4}{N}\\leq q<4+\\frac{4}{N}$, we obtain the\nexistence of normalized solutions of mountain pass type under different\nconditions on $c>0$;\n  \\item For the case of $4+\\frac{4}{N}\\leq q<2\\cdot2^*$, we obtain the\nexistence of a ground state normalized solution under different conditions on\n$c>0$. Moreover, when $\\tau\\le 0$, we derive the non-existence result for\n$2<q<2\\cdot2^*$ and all $c>0$. Our research provides a comprehensive analysis\nacross the entire range $q\\in(2, 2 \\cdot 2^*)$ and for all $N\\ge3$. The methods\nwe have developed are flexible and can be extended to a broader class of\nnonlinearities.", "AI": {"tldr": "The paper studies normalized solutions for a quasilinear Schr\u00f6dinger equation with critical exponent under a mass constraint, providing existence results for various parameter ranges and deriving non-existence conditions.", "motivation": "To address the existence of normalized solutions for quasilinear Schr\u00f6dinger equations with critical exponents, a problem with significant implications in mathematical physics.", "method": "The authors use precise energy level estimates, new convergence theorems, and the perturbation method to analyze the equation under different parameter conditions.", "result": "Existence of solutions is proven for specific ranges of parameters, including local minimizers and mountain pass solutions, with non-existence results for certain cases.", "conclusion": "The study offers a comprehensive analysis of normalized solutions across a broad parameter range, with methods adaptable to other nonlinearities."}}
{"id": "2506.10224", "pdf": "https://arxiv.org/pdf/2506.10224", "abs": "https://arxiv.org/abs/2506.10224", "authors": ["Alejandro N Diaz", "Shane A McQuarrie", "John T Tencer", "Patrick J Blonigan"], "title": "Interpretable and flexible non-intrusive reduced-order models using reproducing kernel Hilbert spaces", "categories": ["cs.CE", "cs.NA", "math.NA", "65D05, 46E22, 62J05", "G.1.0"], "comment": null, "summary": "This paper develops an interpretable, non-intrusive reduced-order modeling\ntechnique using regularized kernel interpolation. Existing non-intrusive\napproaches approximate the dynamics of a reduced-order model (ROM) by solving a\ndata-driven least-squares regression problem for low-dimensional matrix\noperators. Our approach instead leverages regularized kernel interpolation,\nwhich yields an optimal approximation of the ROM dynamics from a user-defined\nreproducing kernel Hilbert space. We show that our kernel-based approach can\nproduce interpretable ROMs whose structure mirrors full-order model structure\nby embedding judiciously chosen feature maps into the kernel. The approach is\nflexible and allows a combination of informed structure through feature maps\nand closure terms via more general nonlinear terms in the kernel. We also\nderive a computable a posteriori error bound that combines standard error\nestimates for intrusive projection-based ROMs and kernel interpolants. The\napproach is demonstrated in several numerical experiments that include\ncomparisons to operator inference using both proper orthogonal decomposition\nand quadratic manifold dimension reduction.", "AI": {"tldr": "The paper introduces a non-intrusive reduced-order modeling technique using regularized kernel interpolation, offering interpretability and flexibility by combining feature maps and kernel terms. It includes error bounds and demonstrates effectiveness in numerical experiments.", "motivation": "Existing non-intrusive methods lack interpretability and flexibility. The goal is to develop a technique that mirrors full-order model structure while allowing user-defined feature maps and kernel terms.", "method": "The approach uses regularized kernel interpolation to approximate ROM dynamics, embedding feature maps for interpretability and combining them with nonlinear kernel terms. It also derives a posteriori error bounds.", "result": "The method produces interpretable ROMs that reflect full-order model structure and performs well in numerical experiments, including comparisons with other techniques.", "conclusion": "The kernel-based approach is effective, flexible, and interpretable, offering a promising alternative to existing non-intrusive ROM methods."}}
{"id": "2506.10321", "pdf": "https://arxiv.org/pdf/2506.10321", "abs": "https://arxiv.org/abs/2506.10321", "authors": ["Jorge Zuniga"], "title": "Fast Ramanujan--type Series for Logarithms. Part II", "categories": ["math.NT", "cs.NA", "math.NA", "65B10 33C20 33C90 90C11 65C05 91G60"], "comment": "17 pages, 1 table. TeX file must be downloaded, PARI GP program is\n  embedded as a large comment there", "summary": "This work extends the results of the preprint Ramanujan type Series for\nLogarithms, Part I, arXiv:2506.08245, which introduced single hypergeometric\ntype identities for the efficient computing of $\\log(p)$, where\n$p\\in\\mathbb{Z}_{>1}$. We present novel formulas for arctangents and methods\nfor a very fast multiseries evaluation of logarithms. Building upon a\n$\\mathcal{O}((p-1)^{6})$ Ramanujan type series asymptotic approximation for\n$\\log(p)$ as $p\\rightarrow1$, formulas for computing $n$ simultaneous\nlogarithms are developed. These formulas are derived by solving an integer\nprogramming problem to identify optimal variable values within a finite lattice\n$\\mathbb{Z}^{n}$. This approach yields linear combinations of series that\nprovide: (i) highly efficient formulas for single logarithms of natural numbers\nand (ii) the fastest known hypergeometric formulas for multivalued logarithms\nof $n$ selected integers in $\\mathbb{Z}_{>1}$. An application of these results\nwas to extend the number of decimal places known for log(10) up to\n2.0$\\cdot$10$^{12}$ digits (June 06 2025).", "AI": {"tldr": "The paper extends prior work on Ramanujan-type series for logarithms, introducing new formulas for arctangents and fast multiseries evaluations. It develops methods for computing multiple logarithms simultaneously via integer programming, achieving highly efficient results and setting a record for log(10) precision.", "motivation": "To improve the efficiency and precision of computing logarithms, especially for multiple values simultaneously, by leveraging hypergeometric identities and integer programming.", "method": "Derives formulas by solving an integer programming problem within a finite lattice, optimizing variable values to create linear combinations of series for fast evaluations.", "result": "Achieves highly efficient formulas for single logarithms and the fastest known hypergeometric formulas for multivalued logarithms, extending log(10) precision to 2.0\u00b710\u00b9\u00b2 digits.", "conclusion": "The work significantly advances the computational efficiency and precision of logarithm evaluations, with practical applications in high-precision calculations."}}
{"id": "2506.10466", "pdf": "https://arxiv.org/pdf/2506.10466", "abs": "https://arxiv.org/abs/2506.10466", "authors": ["Larissa Fardigola", "Kateryna Khalina"], "title": "Approximate Controllability Problems for the Heat Equation in a Half-Plane Controlled by the Dirichlet Boundary Condition with a Bounded Control", "categories": ["math.OC", "math.AP"], "comment": "arXiv admin note: text overlap with arXiv:2409.10169", "summary": "In the paper, the problems of approximate controllability are studied for the\ncontrol system $w_t=\\Delta w$, $w(0,x_2,t)=u(x_2,t)$, $x_1\\in\\mathbb\nR_+=(0,+\\infty)$, $x_2\\in\\mathbb R$, $t\\in(0,T)$, where $u$ is a control\nbelonging to a special subset of $L^\\infty(\\mathbb R\\times (0,T))\\cap\nL^2(\\mathbb R\\times (0,T))$. It is proved that each initial state belonging to\n$L^2(\\mathbb R_+\\times\\mathbb R)$ is approximately controllable to an arbitrary\nend state belonging to $L^2(\\mathbb R_+\\times\\mathbb R)$ by applying these\ncontrols. A numerical algorithm of solving the approximate controllability\nproblem for this system is given. The results are illustrated by an example.", "AI": {"tldr": "The paper studies approximate controllability for a heat equation system, proving initial states can be controlled to arbitrary end states using specific controls, with a numerical algorithm provided.", "motivation": "To address the controllability of a heat equation system with boundary controls, ensuring practical applicability through theoretical proofs and numerical methods.", "method": "Theoretical analysis of the control system and development of a numerical algorithm for solving the approximate controllability problem.", "result": "Initial states in $L^2$ can be approximately controlled to arbitrary end states in $L^2$ using the specified controls.", "conclusion": "The study successfully demonstrates controllability and provides a practical numerical solution, validated by an example."}}
{"id": "2506.10506", "pdf": "https://arxiv.org/pdf/2506.10506", "abs": "https://arxiv.org/abs/2506.10506", "authors": ["Manfred Opper", "Sebastian Reich"], "title": "On a mean-field Pontryagin minimum principle for stochastic optimal control", "categories": ["math.OC", "cs.NA", "math.NA", "35F21, 49M99, 93E20, 70H30, 70H45"], "comment": null, "summary": "This papers outlines a novel extension of the classical Pontryagin minimum\n(maximum) principle to stochastic optimal control problems. Contrary to the\nwell-known stochastic Pontryagin minimum principle involving forward-backward\nstochastic differential equations, the proposed formulation is deterministic\nand of mean-field type. The Hamiltonian structure of the proposed Pontryagin\nminimum principle is achieved via the introduction of an appropriate gauge\nvariable. The gauge freedom can be used to decouple the forward and reverse\ntime equations; hence simplifying the solution of the underlying boundary value\nproblem. We also consider infinite horizon discounted cost optimal control\nproblems. In this case, the mean-field formulation allows converting the\ncomputation of the desired optimal control law into solving a pair of forward\nmean-field ordinary differential equations. The proposed mean-field formulation\nof the Pontryagin minimum principle is tested numerically for a controlled\ninverted pendulum and a controlled Lorenz-63 system.", "AI": {"tldr": "A deterministic, mean-field extension of the Pontryagin minimum principle for stochastic optimal control, simplifying solution via gauge variables and tested on inverted pendulum and Lorenz-63 systems.", "motivation": "To address stochastic optimal control problems with a deterministic, mean-field approach, avoiding the complexity of forward-backward stochastic differential equations.", "method": "Introduces a gauge variable to achieve Hamiltonian structure, decoupling forward and reverse time equations, and applies mean-field ordinary differential equations for infinite horizon problems.", "result": "Simplifies the boundary value problem and converts optimal control law computation into solving forward mean-field ODEs, validated numerically.", "conclusion": "The proposed mean-field Pontryagin principle offers a practical and efficient alternative for stochastic optimal control, demonstrated through numerical examples."}}
{"id": "2506.10623", "pdf": "https://arxiv.org/pdf/2506.10623", "abs": "https://arxiv.org/abs/2506.10623", "authors": ["Julien Berestycki", "David Geldbach", "Michel Pain"], "title": "Polynomial slowdown in space-inhomogeneous branching Brownian motion", "categories": ["math.PR", "math.AP", "60J80, 60J65, 35R99"], "comment": "53 pages, 4 figures", "summary": "We consider a branching Brownian motion in $\\mathbb{R}^2$ in which particles\nindependently diffuse as standard Brownian motions and branch at an\ninhomogeneous rate $b(\\theta)$ which depends only on the angle $\\theta$ of the\nparticle. We assume that $b$ is maximal when $\\theta=0$, which is the preferred\ndirection for breeding. Furthermore we assume that $b(\\theta ) = 1 - \\beta\n\\abs{\\theta }^\\alpha + O(\\theta ^2)$, as $\\theta \\to 0$, for $\\alpha \\in\n(2/3,2)$ and $\\beta>0.$ We show that if $M_t$ is the maximum distance to the\norigin at time $t$, then $(M_t-m(t))_{t\\ge 1}$ is tight where $$m(t) = \\sqrt{2}\nt - \\frac{\\vartheta_1}{\\sqrt{2}} t^{(2-\\alpha)/(2+\\alpha)} -\n\\left(\\frac{3}{2\\sqrt{2}} - \\frac{\\alpha}{2\\sqrt{2}(2+\\alpha)}\\right) \\log t.\n$$ and $\\vartheta_1$ is explicit in terms of the first eigenvalue of a certain\noperator.", "AI": {"tldr": "The paper studies a 2D branching Brownian motion with angle-dependent branching rates, showing tightness of the maximum distance from the origin after subtracting a time-dependent function.", "motivation": "To understand how inhomogeneous branching rates, particularly favoring a specific direction, affect the spatial spread of particles in branching Brownian motion.", "method": "Analyzes a branching Brownian motion in \u211d\u00b2 with branching rate b(\u03b8) depending on angle \u03b8, focusing on the maximum distance M_t from the origin and deriving a tightness result for M_t - m(t).", "result": "Proves tightness of (M_t - m(t))_{t\u22651}, where m(t) is a deterministic function involving time t and parameters \u03b1, \u03b2, and an eigenvalue \u03d1\u2081.", "conclusion": "The study provides insights into the spatial distribution of particles in branching Brownian motion with directional bias in branching rates."}}
{"id": "2506.10711", "pdf": "https://arxiv.org/pdf/2506.10711", "abs": "https://arxiv.org/abs/2506.10711", "authors": ["Li Luo", "Shangsong Liang"], "title": "PDESpectralRefiner: Achieving More Accurate Long Rollouts with Spectral Adjustment", "categories": ["cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "Generating accurate and stable long rollouts is a notorious challenge for\ntime-dependent PDEs (Partial Differential Equations). Recently, motivated by\nthe importance of high-frequency accuracy, a refiner model called PDERefiner\nutilizes diffusion models to refine outputs for every time step, since the\ndenoising process could increase the correctness of modeling high frequency\npart. For 1-D Kuramoto-Sivashinsky equation, refiner models can degrade the\namplitude of high frequency part better than not doing refinement process.\nHowever, for some other cases, the spectrum might be more complicated. For\nexample, for a harder PDE like Navior-Stokes equation, diffusion models could\nover-degrade the higher frequency part. This motivates us to release the\nconstraint that each frequency weighs the same. We enhance our refiner model\nwith doing adjustments on spectral space, which recovers Blurring diffusion\nmodels. We developed a new v-prediction technique for Blurring diffusion\nmodels, recovering the MSE training objective on the first refinement step. We\nshow that in this case, for different model backbones, such as U-Net and neural\noperators, the outputs of PDE-SpectralRefiner are more accurate for both\none-step MSE loss and rollout loss.", "AI": {"tldr": "PDERefiner uses diffusion models to refine PDE solutions, improving high-frequency accuracy. For complex PDEs like Navier-Stokes, spectral adjustments enhance performance.", "motivation": "High-frequency accuracy in PDE solutions is challenging. Diffusion models help refine outputs but may over-degrade frequencies in complex cases.", "method": "Enhanced refiner model with spectral adjustments (Blurring diffusion models) and v-prediction technique for better accuracy.", "result": "Improved accuracy for one-step MSE loss and rollout loss across model backbones like U-Net and neural operators.", "conclusion": "Spectral adjustments in refiner models address over-degradation, enhancing accuracy for complex PDEs."}}
{"id": "2506.10652", "pdf": "https://arxiv.org/pdf/2506.10652", "abs": "https://arxiv.org/abs/2506.10652", "authors": ["Volker Branding", "Anna Siffert"], "title": "On the stability of the generalized equator map", "categories": ["math.DG", "math.AP"], "comment": null, "summary": "The energy, the $p$-energy ($p\\in\\mathbb{R}$ with $p\\geq 2$) and the\nextrinsic $k$-energy ($k\\in\\mathbb{N}$) for maps between Riemannian manifolds\nare central objects in the geometric calculus of variations. The equator map\nfrom the unit ball to the Euclidean sphere provides an explicit critical point\nof all aforementioned energy functionals. During the last four decades many\nresearchers studied the stability of this particular map when considered as a\ncritical point of one of these energy functionals, see e.g. \\cite{MR4436204},\n\\cite{MR705882}.\n  Recently, Nakauchi \\cite{MR4593065} introduced a generalized radial\nprojection map and proved that this map is both a critical point of the energy\nand a critical point of the $p$-energy. This generalized radial projection map\ngives rise to a generalized equator map which is also both a critical point of\nthe energy and a critical point of the $p$-energy.\n  In this manuscript we first of all show that the generalized equator map is\nalso a critical point of the extrinsic $k$-energy. Then, the main focus is a\ndetailed stability analysis of this map, considered as a critical point of both\nthe extrinsic $k$-energy and the $p$-energy. We thus establish a number of\ninteresting generalizations of the classical (in)stability results of J\\\"ager\nand Kaul \\cite{MR705882}.", "AI": {"tldr": "The paper studies the generalized equator map as a critical point of energy, $p$-energy, and extrinsic $k$-energy, focusing on its stability analysis.", "motivation": "To extend classical stability results for the equator map by analyzing a generalized version under multiple energy functionals.", "method": "The authors first prove the generalized equator map is a critical point of extrinsic $k$-energy, then conduct a detailed stability analysis for both extrinsic $k$-energy and $p$-energy.", "result": "The study generalizes classical (in)stability results, providing new insights into the stability of the generalized equator map.", "conclusion": "The work extends prior findings and offers a comprehensive stability analysis of the generalized equator map under various energy functionals."}}
{"id": "2506.10875", "pdf": "https://arxiv.org/pdf/2506.10875", "abs": "https://arxiv.org/abs/2506.10875", "authors": ["Guanjin Wang", "Xiangxue Zhao", "Shapour Azarm", "Balakumar Balachandran"], "title": "Data-Driven Prediction of Dynamic Interactions Between Robot Appendage and Granular Material", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "An alternative data-driven modeling approach has been proposed and employed\nto gain fundamental insights into robot motion interaction with granular\nterrain at certain length scales. The approach is based on an integration of\ndimension reduction (Sequentially Truncated Higher-Order Singular Value\nDecomposition), surrogate modeling (Gaussian Process), and data assimilation\ntechniques (Reduced Order Particle Filter). This approach can be used online\nand is based on offline data, obtained from the offline collection of\nhigh-fidelity simulation data and a set of sparse experimental data. The\nresults have shown that orders of magnitude reduction in computational time can\nbe obtained from the proposed data-driven modeling approach compared with\nphysics-based high-fidelity simulations. With only simulation data as input,\nthe data-driven prediction technique can generate predictions that have\ncomparable accuracy as simulations. With both simulation data and sparse\nphysical experimental measurement as input, the data-driven approach with its\nembedded data assimilation techniques has the potential in outperforming only\nhigh-fidelity simulations for the long-horizon predictions. In addition, it is\ndemonstrated that the data-driven modeling approach can also reproduce the\nscaling relationship recovered by physics-based simulations for maximum\nresistive forces, which may indicate its general predictability beyond a\ncase-by-case basis. The results are expected to help robot navigation and\nexploration in unknown and complex terrains during both online and offline\nphases.", "AI": {"tldr": "A data-driven approach combining dimension reduction, surrogate modeling, and data assimilation significantly reduces computational time while maintaining accuracy in predicting robot-granular terrain interactions.", "motivation": "To improve robot navigation in complex terrains by developing a computationally efficient and accurate modeling approach.", "method": "Integration of dimension reduction (ST-HOSVD), surrogate modeling (Gaussian Process), and data assimilation (Reduced Order Particle Filter) using offline simulation and sparse experimental data.", "result": "Orders of magnitude reduction in computational time; comparable accuracy to simulations; potential outperformance in long-horizon predictions with experimental data.", "conclusion": "The approach enhances robot navigation in unknown terrains, offering efficiency and accuracy beyond traditional simulations."}}
{"id": "2506.10880", "pdf": "https://arxiv.org/pdf/2506.10880", "abs": "https://arxiv.org/abs/2506.10880", "authors": ["V. Giunzioni", "A. Merlini", "F. P. Andriulli"], "title": "Spectral Analysis of Discretized Boundary Integral Operators in 3D: a High-Frequency Perspective", "categories": ["cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "When modeling propagation and scattering phenomena using integral equations\ndiscretized by the boundary element method, it is common practice to\napproximate the boundary of the scatterer with a mesh comprising elements of\nsize approximately equal to a fraction of the wavelength $\\lambda$ of the\nincident wave, e.g., $\\lambda/10$. In this work, by analyzing the spectra of\nthe operator matrices, we show a discrepancy with respect to the continuous\noperators which grows with the simulation frequency, challenging the common\nbelief that the aforementioned widely used discretization approach is\nsufficient to maintain the accuracy of the solution constant when increasing\nthe frequency.", "AI": {"tldr": "The paper challenges the common practice of using mesh sizes of \u03bb/10 for boundary element method discretization, showing that accuracy degrades with increasing frequency.", "motivation": "To investigate the accuracy of the widely used discretization approach (mesh size \u2248 \u03bb/10) in boundary element methods for wave propagation and scattering.", "method": "Analyzed the spectra of operator matrices to compare discretized and continuous operators.", "result": "Found a growing discrepancy with increasing frequency, indicating that the \u03bb/10 rule may not maintain accuracy at higher frequencies.", "conclusion": "The common discretization approach may not suffice for high-frequency simulations, suggesting a need for reevaluation."}}
{"id": "2506.10924", "pdf": "https://arxiv.org/pdf/2506.10924", "abs": "https://arxiv.org/abs/2506.10924", "authors": ["Quang Huy Nguyen", "Phuong Cuc Hoang", "Van Chien Le", "Thi Thanh Mai Ta"], "title": "A space-time interface-fitted method for moving-subdomain distributed control problems with energy regularization", "categories": ["math.OC", "cs.NA", "math.NA", "35K20, 49N10, 65M15, 65M60"], "comment": null, "summary": "This paper investigates a space-time interface-fitted approximation of a\nmoving-interface optimal control problem with energy regularization. We\nreformulate the optimality conditions into a variational problem involving both\nthe state and adjoint. This problem is shown to be equivalent to our optimal\ncontrol problem. Based on fully unstructured, space-time interface-fitted\nmeshes, we propose and analyze a Petrov-Galerkin approximation of the problem.\nAn optimal error estimate with respect to a discrete norm is established under\na specific regularity assumption on the state and adjoint. Several numerical\nresults are presented to corroborate our theoretical results.", "AI": {"tldr": "The paper proposes a space-time interface-fitted method for solving a moving-interface optimal control problem with energy regularization, proving its equivalence to the original problem and providing optimal error estimates.", "motivation": "To address the challenges of moving-interface optimal control problems by developing a robust numerical approximation method.", "method": "A Petrov-Galerkin approximation on fully unstructured, space-time interface-fitted meshes, reformulating optimality conditions into a variational problem.", "result": "Optimal error estimates are derived under specific regularity assumptions, supported by numerical experiments.", "conclusion": "The proposed method effectively solves the problem, with theoretical and numerical validation."}}
{"id": "2506.10973", "pdf": "https://arxiv.org/pdf/2506.10973", "abs": "https://arxiv.org/abs/2506.10973", "authors": ["Julius Berner", "Miguel Liu-Schiaffini", "Jean Kossaifi", "Valentin Duruisseaux", "Boris Bonev", "Kamyar Azizzadenesheli", "Anima Anandkumar"], "title": "Principled Approaches for Extending Neural Architectures to Function Spaces for Operator Learning", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.FA", "math.NA"], "comment": null, "summary": "A wide range of scientific problems, such as those described by\ncontinuous-time dynamical systems and partial differential equations (PDEs),\nare naturally formulated on function spaces. While function spaces are\ntypically infinite-dimensional, deep learning has predominantly advanced\nthrough applications in computer vision and natural language processing that\nfocus on mappings between finite-dimensional spaces. Such fundamental\ndisparities in the nature of the data have limited neural networks from\nachieving a comparable level of success in scientific applications as seen in\nother fields. Neural operators are a principled way to generalize neural\nnetworks to mappings between function spaces, offering a pathway to replicate\ndeep learning's transformative impact on scientific problems. For instance,\nneural operators can learn solution operators for entire classes of PDEs, e.g.,\nphysical systems with different boundary conditions, coefficient functions, and\ngeometries. A key factor in deep learning's success has been the careful\nengineering of neural architectures through extensive empirical testing.\nTranslating these neural architectures into neural operators allows operator\nlearning to enjoy these same empirical optimizations. However, prior neural\noperator architectures have often been introduced as standalone models, not\ndirectly derived as extensions of existing neural network architectures. In\nthis paper, we identify and distill the key principles for constructing\npractical implementations of mappings between infinite-dimensional function\nspaces. Using these principles, we propose a recipe for converting several\npopular neural architectures into neural operators with minimal modifications.\nThis paper aims to guide practitioners through this process and details the\nsteps to make neural operators work in practice. Our code can be found at\nhttps://github.com/neuraloperator/NNs-to-NOs", "AI": {"tldr": "The paper introduces neural operators as a way to generalize neural networks for mappings between infinite-dimensional function spaces, enabling deep learning's success in scientific problems like PDEs. It provides a practical guide for converting existing neural architectures into neural operators.", "motivation": "The disparity between finite-dimensional deep learning applications and infinite-dimensional scientific problems limits neural networks' success in fields like PDEs. Neural operators bridge this gap.", "method": "The paper distills key principles for constructing mappings between function spaces and proposes a recipe to convert popular neural architectures into neural operators with minimal changes.", "result": "The approach enables neural operators to learn solution operators for PDEs, adapting to varying conditions like boundary constraints and geometries.", "conclusion": "The paper provides a practical framework for implementing neural operators, extending deep learning's impact to scientific applications."}}
