<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 19]
- [math.AP](#math.AP) [Total: 25]
- [physics.comp-ph](#physics.comp-ph) [Total: 6]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 6]
- [cs.CL](#cs.CL) [Total: 1]
- [math.FA](#math.FA) [Total: 3]
- [math.PR](#math.PR) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [astro-ph.EP](#astro-ph.EP) [Total: 1]
- [math.DG](#math.DG) [Total: 2]
- [nlin.PS](#nlin.PS) [Total: 2]
- [physics.chem-ph](#physics.chem-ph) [Total: 2]
- [math-ph](#math-ph) [Total: 1]
- [cond-mat.soft](#cond-mat.soft) [Total: 2]
- [math.MP](#math.MP) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 5]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Convergence Analysis of a Dual-Wind Discontinuous Galerkin Method for an Elliptic Optimal Control Problem with Control Constraints](https://arxiv.org/abs/2506.12330)
*Satyajith Bommana Boyana,Thomas Lewis,Sijing Liu,Yi Zhang*

Main category: math.NA

TL;DR: A symmetric dual-wind discontinuous Galerkin method is proposed for solving elliptic optimal control problems with constraints, showing robust results in numerical experiments.


<details>
  <summary>Details</summary>
Motivation: To address elliptic optimal control problems with control constraints using a symmetric DWDG approach for accurate discretization and error estimation.

Method: The symmetric DWDG method discretizes the elliptic PDE constraint, with derived error estimates for state, adjoint state, and control in energy and L2 norms.

Result: Error estimates are provided, and numerical experiments confirm the scheme's robustness and effectiveness.

Conclusion: The symmetric DWDG method is effective for solving constrained elliptic optimal control problems, supported by theoretical and numerical validation.

Abstract: This paper investigates a symmetric dual-wind discontinuous Galerkin (DWDG)
method for solving an elliptic optimal control problem with control
constraints. The governing constraint is an elliptic partial differential
equation (PDE), which is discretized using the symmetric DWDG approach. We
derive error estimates in the energy norm for both the state and the adjoint
state, as well as in the $L^2$ norm of the control variable. Numerical
experiments are provided to demonstrate the robustness and effectiveness of the
developed scheme.

</details>


### [2] [$Î¾$-Based adaptive phase field model for quasi-static anti-plane fracture](https://arxiv.org/abs/2506.12360)
*Maria P. Fernando,S. M. Mallikarjunaiah*

Main category: math.NA

TL;DR: The paper introduces a spatially adaptive three-field variable phase-field model for anti-plane crack propagation, featuring dynamic regularization length optimization and local mesh refinement for improved efficiency and accuracy.


<details>
  <summary>Details</summary>
Motivation: To enhance computational efficiency and accuracy in modeling quasi-static anti-plane crack propagation by integrating adaptive techniques and optimizing regularization length.

Method: Develops a three-field variable phase-field model with dynamic regularization length and local adaptive mesh refinement, discretized via finite-element method and incorporating penalty parameters.

Result: The adaptive model outperforms standard phase-field methods, providing accurate fracture representation and reduced computational costs, with a larger regularization length parameter.

Conclusion: The proposed spatially adaptive approach significantly improves fracture modeling efficiency and accuracy, surpassing traditional methods.

Abstract: The $\xi$-based spatially adaptive three-field variable phase-field model for
quasi-static anti-plane crack propagation is introduced. A dynamically
optimized regularization length is integrated to improve computational
efficiency and accuracy in numerical approximations. A local adaptive mesh
refinement strategy is developed, which maintains an optimal balance between
mesh resolution and the accurate depiction of fractures using the \textsf{AT1}
diffuse interface model. The total energy functional is comprised of three
components: strain energy, surface energy, and a third term reliant on the
damage zone's regularization length. The governing partial differential
equations for mechanics and phase-field variables, derived from Euler-Lagrange,
are discretized via the finite-element method. Two parameters functioning as
penalty variables are incorporated; both are asymptotically estimated from the
gradient of the phase-field variable. By these estimated parameters, mesh
adaptivity is enhanced, ensuring the convergence of the numerical solution.
Standard phase-field methods are shown by numerical results to be surpassed by
the adaptive model; an accurate representation of fractures is provided, and
computational costs are significantly lowered. By employing the proposed
spatially adaptive approach, a vastly larger regularization length parameter is
achieved compared to other methods throughout the entire computation.

</details>


### [3] [A new Lagrange multiplier approach for constructing structure preserving schemes, III. Bound preserving and energy dissipating](https://arxiv.org/abs/2506.12402)
*Qing Cheng,Tingfeng Wang,Xiaofei Zhao*

Main category: math.NA

TL;DR: A framework for preserving maximum bound principle (MBP) and energy dissipation in gradient flows, using predictor-corrector steps based on Lagrange multipliers.


<details>
  <summary>Details</summary>
Motivation: To develop efficient and accurate numerical schemes for gradient flows that maintain MBP and energy dissipation, building on prior work.

Method: Uses a predictor-corrector approach with Karush-Kuhn-Tucker conditions, starting with conventional schemes (e.g., Runge-Kutta exponential time differencing) as predictors.

Result: Rigorous proof of MBP and energy dissipation preservation, with solvability of the scheme. Numerical experiments validate effectiveness.

Conclusion: The proposed framework successfully preserves key properties and offers an efficient numerical solution for gradient flows.

Abstract: In the third part of this series, we continue to explore the idea of the
Lagrange multiplier introduced in the first part [2020, Comput. Methods Appl.
Mech. Engr., 391, 114585] and refined in the second part [2022, SIAM J. Numer.
Anal., 60, 970-998] to further develop efficient and accurate numerical schemes
that preserve the maximum bound principle (MBP) and energy dissipation for
solving gradient flows. The proposed framework allows us to begin with any
conventional scheme as a predictor step which is followed by two consecutive
correction steps written in the form of the Karush-Kuhn-Tucker conditions for
structure preserving. The preservation of both energy dissipation and MBP and
the solvability of the general resulting scheme are rigorously established. In
such a framework, we implement an explicit and efficient scheme by employing
the Runge-Kutta exponential time differencing scheme as the predictor step, and
give its convergence analysis. Extensive numerical experiments are provided to
validate the effectiveness of our approach.

</details>


### [4] [Superconvergent quadriatic finite element on uniform tetrahedral meshes](https://arxiv.org/abs/2506.12407)
*Yunqing Huang,Shangyou Zhang*

Main category: math.NA

TL;DR: The paper demonstrates that $P_2$ interpolation of a $P_3$ function acts as a local $H^1$-projection on uniform tetrahedral meshes, ensuring $H^1$ and $L^2$ convergence. It also lifts $P_2$ solutions to quasi-optimal $P_3$ solutions using a 20-point Lagrange interpolation.


<details>
  <summary>Details</summary>
Motivation: To establish the convergence properties of $P_2$ Lagrange finite elements on uniform tetrahedral meshes and enhance solutions by lifting them to higher-order $P_3$ approximations.

Method: Direct computation to show $H^1$-orthogonality and use of 20-point Lagrange $P_3$ interpolation for lifting $P_2$ solutions.

Result: Confirmed $H^1$ and $L^2$ convergence of $P_2$ elements and successful lifting to quasi-optimal $P_3$ solutions.

Conclusion: The theoretical findings are supported by numerical results, validating the approach.

Abstract: By a direct computation, we show that the $P_2$ interpolation of a $P_3$
function is also a local $H^1$-projection on uniform tetrahedral meshes, i.e.,
the difference is $H^1$-orthogonal to the $P_2$ Lagrange basis function on the
support patch of tetrahedra of the basis function. Consequently, we show the
$H^1$ and $L^2$ rconvergence of the $P_2$ Lagrange finite element on uniform
tetrahedral meshes. Using the standard 20-points Lagrange $P_3$ interpolation,
where the 20 nodes are exactly some $P_2$ global basis nodes, we lift the
superconvergent $P_2$ finite element solution to a quasi-optimal $P_3$ solution
on each cube. Numerical results confirm the theory.

</details>


### [5] [An optimal two-side Robin-Robin domain decomposition method for H(div)-elliptic problem](https://arxiv.org/abs/2506.12485)
*Na Xuyang*

Main category: math.NA

TL;DR: A new two-side Robin-Robin domain decomposition method for H(div)-elliptic problems is developed, with convergence rate dependent on subdomain and mesh size ratios. The method includes an algebraic system solved by MINRES, yielding stable iteration numbers.


<details>
  <summary>Details</summary>
Motivation: To address H(div)-elliptic problems efficiently using a domain decomposition approach with stable convergence properties.

Method: Develops a two-side Robin-Robin domain decomposition method, derives an algebraic system from iterative Robin boundary conditions, and solves it using MINRES.

Result: Convergence rate depends on H/h (subdomain to mesh size ratio), and MINRES yields asymptotically stable iteration numbers.

Conclusion: The proposed method is effective for H(div)-elliptic problems, with stable convergence and practical numerical performance.

Abstract: In this paper, we develop a new two-side Robin-Robin domain decomposition
method for H(div)-elliptic problem. Numerical results show that the convergence
rate of the new algorithm only depends on $H/h$, where $H$ is diameter of
subdomains and $h$ is the mesh size. Besides, an algebraic system of Robin
boundary conditions is derived from the iterative method. We solve it by MINRES
and get asymptotically stable iteration numbers as well.

</details>


### [6] [The convergence proof of the sixth-order compact 9-point FDM for the 2D transport problem](https://arxiv.org/abs/2506.12549)
*Qiwei Feng*

Main category: math.NA

TL;DR: The paper presents a sixth-order compact 9-point FDM for 2D transport problems, proving its convergence in the $l_{\infty}$ norm for any mesh size $h$.


<details>
  <summary>Details</summary>
Motivation: The challenge of proving convergence in the $l_{\infty}$ norm for high-order FDM/FEM in 2D motivates the development of a rigorous and implementable method.

Method: A sixth-order compact 9-point FDM with an explicit stencil is derived for a 2D transport problem with constant coefficients and Dirichlet boundary conditions. The method forms an M-matrix and uses a comparison function for proof.

Result: The method achieves sixth-order convergence in the $l_{\infty}$ norm, validated by numerical results.

Conclusion: The proposed FDM is theoretically sound, easy to implement, and reproduces numerical results effectively.

Abstract: It is widely acknowledged that the convergence proof of the error in the
$l_{\infty}$ norm of the high-order finite difference method (FDM) and finite
element method (FEM) in 2D is challenging. In this paper, we derive the
sixth-order compact 9-point FDM with the explicit stencil for the 2D transport
problem with the constant coefficient and the Dirichlet boundary condition in a
unit square. The proposed sixth-order FDM forms an M-matrix for the any mesh
size $h$ employing the uniform Cartesian mesh. The explicit formula of our FDM
also enables us to construct the comparison function with the explicit
expression to rigorously prove the sixth-order convergence rate of the maximum
pointwise error by the discrete maximum principle. Most importantly, we
demonstrate that the sixth-order convergence proof is valid for any mesh size
$h$. The numerical results are consistent with sixth-order accuracy in the
$l_{\infty}$ norm. Our theoretical convergence proof is clear and the proposed
sixth-order FDM is straightforward to be implemented, facilitating the
reproduction of our numerical results.

</details>


### [7] [Computing the Bogoliubov-de Gennes excitations of two-component Bose-Einstein condensates](https://arxiv.org/abs/2506.12688)
*Manting Xie,Yong Zhang*

Main category: math.NA

TL;DR: An efficient, spectrally accurate numerical method for solving the Bogoliubov-de Gennes equation in two-component Bose-Einstein condensates, using Fourier spectral methods and a modified Gram-Schmidt algorithm.


<details>
  <summary>Details</summary>
Motivation: To compute elementary/collective excitations in two-component BECs accurately and efficiently by addressing the non-Hermitian eigenvalue problem of the BdG equation.

Method: Combines Fourier spectral spatial discretization with a stable modified Gram-Schmidt bi-orthogonal algorithm for a matrix-free, structure-preserving iterative solution.

Result: The method is memory-friendly, spectrally accurate, and highly efficient, with near-optimal computational complexity.

Conclusion: Demonstrates superiority in accuracy and efficiency, applicable to excitation spectrum and Bogoliubov amplitudes in 1D, 2D, and 3D problems.

Abstract: In this paper, we present an efficient and spectrally accurate numerical
method to compute elementary/collective excitations in two-component
Bose-Einstein condensates (BEC), around their mean-field ground state, by
solving the associated Bogoliubov-de Gennes (BdG) equation. The BdG equation is
essentially an eigenvalue problem for a non-Hermitian differential operator
with an eigenfunction normalization constraint. Firstly, we investigate its
analytical properties, including the exact eigenpairs, generalized nullspace
structure and bi-orthogonality of eigenspaces. Subsequently, by combining the
Fourier spectral method for spatial discretization and a stable modified
Gram-Schmidt bi-orthogonal algorithm, we propose a structure-preserving
iterative method for the resulting large-scale dense non-Hermitian discrete
eigenvalue problem. Our method is matrix-free, and the matrix-vector
multiplication (or the operator-function evaluation) is implemented with a
near-optimal complexity ${\mathcal O}(N_{\rm t}\log(N_{\rm t}))$, where $N_{\rm
t}$ is the total number of grid points, thanks to the utilization of the
discrete Fast Fourier Transform (FFT). Therefore, it is memory-friendly,
spectrally accurate, and highly efficient. Finally, we carry out a
comprehensive numerical investigation to showcase its superiority in terms of
accuracy and efficiency, alongside some applications to compute the excitation
spectrum and Bogoliubov amplitudes in one, two, and three-dimensional problems.

</details>


### [8] [Permutation-Avoiding FFT-Based Convolution](https://arxiv.org/abs/2506.12718)
*Nicolas Venkovic,Hartwig Anzt*

Main category: math.NA

TL;DR: The paper proposes a method to avoid index-reversal permutations in FFT-based convolutions by deferring to a single offline permutation of the filter, improving arithmetic intensity.


<details>
  <summary>Details</summary>
Motivation: Index-reversal permutations in FFT degrade arithmetic intensity, especially for repeated convolutions with fixed filters.

Method: A multi-dimensional, permutation-avoiding convolution procedure within a general radix Cooley-Tukey framework.

Result: Benchmarks show improved performance compared to state-of-the-art FFT-based convolution implementations.

Conclusion: FFT libraries should support permutation-avoiding convolution kernels for better efficiency.

Abstract: Fast Fourier Transform (FFT) libraries are widely used for evaluating
discrete convolutions. Most FFT implementations follow some variant of the
Cooley-Tukey framework, in which the transform is decomposed into butterfly
operations and index-reversal permutations. While butterfly operations dominate
the floating-point operation count, the memory access patterns induced by
index-reversal permutations significantly degrade the FFT's arithmetic
intensity. In practice, discrete convolutions are often applied repeatedly with
a fixed filter. In such cases, we show that the index-reversal permutations
involved in both the forward and backward transforms of standard FFT-based
convolution implementations can be avoided by deferring to a single offline
permutation of the filter. We propose a multi-dimensional, permutation-avoiding
convolution procedure within a general radix Cooley-Tukey framework. We perform
numerical experiments to benchmark our algorithms against state-of-the-art
FFT-based convolution implementations. Our results suggest that developers of
FFT libraries should consider supporting permutation-avoiding convolution
kernels.

</details>


### [9] [A Geometric Multigrid Preconditioner for Discontinuous Galerkin Shifted Boundary Method](https://arxiv.org/abs/2506.12899)
*Michal Wichrowski*

Main category: math.NA

TL;DR: A geometric multigrid preconditioner for the Shifted Boundary Method (SBM) is introduced to solve PDEs on complex geometries, addressing inefficiencies in standard multigrid methods.


<details>
  <summary>Details</summary>
Motivation: SBM simplifies mesh generation but leads to non-symmetric, ill-conditioned systems, making efficient solving challenging. Standard multigrid methods fail due to localized perturbations from shifted boundaries.

Method: A Discontinuous Galerkin (DG) formulation for SBM is proposed, enabling a cell-wise multiplicative smoother within an $hp$-multigrid framework to handle boundary complexities.

Result: Numerical tests for the Poisson equation show good performance for linear and quadratic elements (2D/3D), but challenges arise with cubic elements in 3D due to smoother inefficiency.

Conclusion: The DG-based multigrid preconditioner effectively addresses SBM's challenges for lower-order elements, but further refinement is needed for higher-order cases.

Abstract: This paper introduces a geometric multigrid preconditioner for the Shifted
Boundary Method (SBM) designed to solve PDEs on complex geometries. While SBM
simplifies mesh generation by using a non-conforming background grid, it often
results in non-symmetric and potentially ill-conditioned linear systems that
are challenging to solve efficiently. Standard multigrid methods with pointwise
smoothers prove ineffective for such systems due to the localized perturbations
introduced by the shifted boundary conditions. To address this challenge, we
introduce a Discontinuous Galerkin (DG) formulation for SBM that enables the
design of a cell-wise multiplicative smoother within an $hp$-multigrid
framework. The element-local nature of DG methods naturally facilitates
cell-wise correction, which can effectively handle the local complexities
arising from the boundary treatment. Numerical results for the Poisson equation
demonstrate favorable performance with mesh refinement for linear ($p=1$) and
quadratic ($p=2$) elements in both 2D and 3D, with iteration counts showing
mild growth. However, challenges emerge for cubic ($p=3$) elements,
particularly in 3D, where the current smoother shows reduced effectiveness.

</details>


### [10] [Pointwise-in-time error bounds for semilinear and quasilinear fractional subdiffusion equations on graded meshes](https://arxiv.org/abs/2506.12954)
*Natalia Kopteva,Sean Kelly*

Main category: math.NA

TL;DR: The paper analyzes time-fractional parabolic equations with Caputo derivatives, focusing on singular initial behavior. It combines the L1 scheme with general discretizations for semilinear terms, deriving sharp error bounds on graded meshes. Both time and space discretizations are studied, supported by numerical experiments.


<details>
  <summary>Details</summary>
Motivation: To address the singular behavior of solutions in time-fractional parabolic equations at initial times and develop accurate numerical methods for such problems.

Method: Uses the L1 scheme in time with general discretizations for semilinear terms, analyzed on graded temporal meshes. Includes semi-discretizations and full discretizations with finite differences/elements.

Result: Obtains sharp pointwise-in-time error bounds for arbitrary grading degrees, validated by numerical experiments.

Conclusion: The proposed methods effectively handle singular initial behavior and provide accurate numerical solutions for time-fractional parabolic equations.

Abstract: Time-fractional semilinear and quasilinear parabolic equations with a Caputo
time derivative of order $\alpha\in(0,1)$ are considered, solutions of which
exhibit a singular behaviour at an initial time of type $t^\sigma$ for any
fixed $\sigma \in (0,1) \cup (1,2)$. The L1 scheme in time is combined with a
general class of discretizations for the semilinear term. For such
discretizations, we obtain sharp pointwise-in-time error bounds on graded
temporal meshes with arbitrary degree of grading. Both semi-discretizations in
time and full discretizations using finite differences and finite elements in
space are addressed. The theoretcal findings are illustrated by numerical
experiments.

</details>


### [11] [Recovery of initial displacement and velocity in anisotropic elastic systems by the time dimensional reduction method](https://arxiv.org/abs/2506.13000)
*Trong D. Dang,Chanh V. Le,Khoa D. Luu,Loc H Nguyen*

Main category: math.NA

TL;DR: A time-dimensional reduction method for inverse source problems in linear elasticity uses a Legendre polynomial-exponential basis to simplify the problem into spatial systems, solved via quasi-reversibility, proving stable and accurate reconstructions.


<details>
  <summary>Details</summary>
Motivation: To reconstruct initial displacement and velocity fields from partial boundary measurements of elastic wave propagation, addressing challenges in space-time inverse problems.

Method: Employ a spectral representation in time using Legendre polynomials weighted by exponential functions, reducing the problem to spatial systems solved with quasi-reversibility.

Result: Theoretical convergence guarantees stability and consistency; numerical experiments show accurate reconstruction of initial data geometry and amplitude, even with noise.

Conclusion: The framework is robust and computationally efficient for inverse elastic source problems.

Abstract: We introduce a time-dimensional reduction method for the inverse source
problem in linear elasticity, where the goal is to reconstruct the initial
displacement and velocity fields from partial boundary measurements of elastic
wave propagation. The key idea is to employ a novel spectral representation in
time, using an orthonormal basis composed of Legendre polynomials weighted by
exponential functions. This Legendre polynomial-exponential basis enables a
stable and accurate decomposition in the time variable, effectively reducing
the original space-time inverse problem to a sequence of coupled spatial
elasticity systems that no longer depend on time. These resulting systems are
solved using the quasi-reversibility method. On the theoretical side, we
establish a convergence theorem ensuring the stability and consistency of the
regularized solution obtained by the quasi-reversibility method as the noise
level tends to zero. On the computational side, two-dimensional numerical
experiments confirm the theory and demonstrate the method's ability to
accurately reconstruct both the geometry and amplitude of the initial data,
even in the presence of substantial measurement noise. The results highlight
the effectiveness of the proposed framework as a robust and computationally
efficient strategy for inverse elastic source problems.

</details>


### [12] [Mixed Finite element method for stress gradient elasticity](https://arxiv.org/abs/2506.13041)
*Ting Lin,Shudan Tian*

Main category: math.NA

TL;DR: The paper introduces stable finite element pairs for linear stress gradient elasticity, addressing size effects and providing robust error estimates.


<details>
  <summary>Details</summary>
Motivation: To overcome classical elasticity's limitations in capturing size effects by developing stable finite element pairs.

Method: Analyzes mesh conditions for parameter-robust error estimates, proposing unconditionally stable higher vertex continuity elements and conditionally stable CG-DG pairs.

Result: Achieves optimal convergence rates in numerical experiments, validating theoretical stability and error estimates.

Conclusion: The proposed finite element pairs effectively address size effects and demonstrate stability and convergence in practical applications.

Abstract: This paper develops stable finite element pairs for the linear stress
gradient elasticity model, overcoming classical elasticity's limitations in
capturing size effects. We analyze mesh conditions to establish
parameter-robust error estimates for the proposed pairs, achieving
unconditional stability for finite elements with higher vertex continuity and
conditional stability for Continuous Galerkin-Discontinuous Galerkin (CG-DG)
pairs when no interior vertex has edges lying on three or fewer lines.
Numerical experiments validate the theoretical results, demonstrating optimal
convergence rates.

</details>


### [13] [A second-order accurate, positive-preserving and mass conservative linear scheme for the Possion-Nernst-Planck equations](https://arxiv.org/abs/2506.13054)
*Jiayin Li,Jingwei Li*

Main category: math.NA

TL;DR: Proposes first- and second-order exponential time differencing schemes for PNP equations, ensuring mass conservation, positivity, and energy stability.


<details>
  <summary>Details</summary>
Motivation: Second-order linear positivity preserving schemes for PNP equations are challenging, motivating the development of new methods.

Method: Uses exponential time differencing with finite difference spatial discretization, Slotboom transformation, and linear stabilization.

Result: Schemes preserve mass and positivity without time step constraints; second-order scheme dissipates modified energy.

Conclusion: Numerical results validate the schemes' performance and theoretical stability.

Abstract: The first-order linear positivity preserving schemes in time are available
for the time dependent Poisson-Nernst-Planck (PNP) equations, second-order
linear ones are still challenging. This paper proposes the first- and
second-order exponential time differencing schemes with the finite difference
spatial discretization for PNP equations, based on the $Slotboom$
transformation of the Nernst-Planck equations and linear stabilization
technique. The proposed schemes are linear and preserve the mass conservation
and positivity preservation of ion concentration at full discrete level without
any constraints on the time step size. The corresponding energy stability
analysis is also presented, demonstrating that the second-order scheme can
dissipate the modified energy. Extensive numerical results are carried out to
support the theoretical findings and showcase the performance of the proposed
schemes.

</details>


### [14] [A High-Order Quadrature Method for Implicitly Defined Hypersurfaces and Regions](https://arxiv.org/abs/2506.13078)
*Zibo Zhao*

Main category: math.NA

TL;DR: A high-order accurate quadrature algorithm for integrals over curved surfaces using tetrahedral division and Gaussian quadrature.


<details>
  <summary>Details</summary>
Motivation: To efficiently evaluate integrals over implicitly defined curved surfaces with high accuracy.

Method: Divides the domain into tetrahedrons, uses change of variables, and applies one-dimensional root finding with Gaussian quadrature.

Result: The scheme ensures positive weights and maintains high-order accuracy, confirmed by numerical tests.

Conclusion: The algorithm is effective for high-order accurate integration over implicitly defined surfaces.

Abstract: This paper presents a high-order accurate numerical quadrature algorithm for
evaluating integrals over curved surfaces and regions defined implicitly via a
level set of a given function restricted to a hyperrectangle. The domain is
divided into small tetrahedrons, and by employing the change of variables
formula, the approach yields an algorithm requiring only one-dimensional root
finding and standard Gaussian quadrature. The resulting quadrature scheme
guarantees strictly positive weights and inherits the high-order accuracy of
Gaussian quadrature. Numerical convergence tests confirm the method's
high-order accuracy.

</details>


### [15] [Optimal ${L^2}$ error estimates for 2D/3D incompressible Cahn--Hilliard--magnetohydrodynamic equations](https://arxiv.org/abs/2506.13080)
*Haiyan Su,Jilu Wang,Zeyu Xia,Ke Zhang*

Main category: math.NA

TL;DR: The paper presents an optimal error analysis for a fully discrete finite element scheme for the CH-MHD system, improving upon previous suboptimal estimates and ensuring stability and conservation.


<details>
  <summary>Details</summary>
Motivation: Previous works provided suboptimal error estimates for the CH-MHD system due to strong coupling and nonlinearity. This paper aims to achieve optimal error estimates and preserve stability.

Method: The method uses Taylor--Hood/MINI, Lagrange, and NÃ©dÃ©lec elements, along with Ritz, Stokes, and Maxwell quasi-projections to eliminate low-order pollution.

Result: Optimal error estimates in various norms, unconditional energy stability, and mass conservation are achieved. Numerical examples validate the analysis.

Conclusion: The proposed scheme successfully improves error estimates and maintains stability, demonstrating its effectiveness through theoretical and numerical validation.

Abstract: This paper focuses on an optimal error analysis of a fully discrete finite
element scheme for the Cahn--Hilliard--magnetohydrodynamic (CH-MHD) system. The
method use the standard inf-sup stable Taylor--Hood/MINI elements to solve the
Navier--Stokes equations, Lagrange elements to solve the phase field, and
particularly, the N\'ed\'elec elements for solving the magnetic induction
field. Suffering from the strong coupling and high nonlinearity, the previous
works just provide suboptimal error estimates for phase field and velocity
field in $L^{2}/\L^2$-norm under the same order elements, and the suboptimal
error estimates for magnetic induction field in $\H(\rm curl)$-norm. To this
end, we utilize the Ritz, Stokes, and Maxwell quasi-projections to eliminate
the low-order pollution of the phase field and magnetic induction field. In
addition to the optimal $\L^2$-norm error estimates, we present the optimal
convergence rates for magnetic induction field in $\H(\rm curl)$-norm and for
velocity field in $\H^1$-norm. Moreover, the unconditional energy stability and
mass conservation of the proposed scheme are preserved. Numerical examples are
illustrated to validate the theoretical analysis and show the performance of
the proposed scheme.

</details>


### [16] [Faithful-Newton Framework: Bridging Inner and Outer Solvers for Enhanced Optimization](https://arxiv.org/abs/2506.13154)
*Alexander Lim,Fred Roosta*

Main category: math.NA

TL;DR: Faithful-Newton methods integrate subproblem solutions with outer iterations, matching gradient descent's complexity while retaining simplicity.


<details>
  <summary>Details</summary>
Motivation: Address the gap in global convergence complexity of Newton-type methods compared to first-order methods like gradient descent.

Method: Introduce Faithful-Newton variants with tightly integrated subproblem solutions, assessed by their effectiveness in reducing optimality.

Result: Matches gradient descent's worst-case complexity in strongly convex settings and achieves competitive iteration complexity for general convex problems.

Conclusion: Faithful-Newton methods offer a simple yet effective Newton-type approach with favorable global convergence properties.

Abstract: While Newton-type methods are known for their fast local convergence and
strong empirical performance, achieving theoretically favorable global
convergence compared to first-order methods remains a key challenge. For
instance, surprisingly, for simple strongly convex problems, no straightforward
variant of Newton's method matches the global complexity of gradient descent.
Although sophisticated variants can improve iteration complexity over gradient
descent for various problems, they often involve highly nontrivial subproblems
that incur significantly higher per-iteration costs, resulting in a much worse
overall operation complexity. These limitations arise from treating the
subproblem as an afterthought, either by handling it as a black box, thus
permitting complex, highly nontrivial, and nearly unimplementable formulations,
or by evaluating subproblem solutions in isolation, without considering their
effectiveness in advancing the optimization of the main objective. By
tightening the integration between the inner iterations of the subproblem
solver and the outer iterations of the optimization algorithm, we introduce
simple Newton-type variants, called Faithful-Newton methods, which, in a sense,
remain faithful to the overall simplicity of classical Newton's method by
retaining simple linear system subproblems. The key conceptual difference,
however, is that the quality of the subproblem solution is directly assessed
based on its effectiveness in reducing optimality, which in turn enables
desirable convergence complexities across a variety of settings. Under standard
assumptions, we show that our variants match the worst-case complexity of
gradient descent in strongly convex settings, both in iteration and operation
complexity, and achieve competitive iteration complexity for general convex
problems.

</details>


### [17] [Conditional a priori error estimates of finite volume and Runge-Kutta discontinuous Galerkin methods with abstract limiting for hyperbolic systems of conservation laws in 1D](https://arxiv.org/abs/2506.13221)
*Fabio Leotta*

Main category: math.NA

TL;DR: The paper derives conditional error estimates for finite volume and Runge-Kutta discontinuous Galerkin methods for hyperbolic systems in 1D, ensuring convergence under specific conditions.


<details>
  <summary>Details</summary>
Motivation: To provide rigorous error bounds for numerical methods solving hyperbolic conservation laws, ensuring accuracy and stability.

Method: Uses weak consistency and entropy stability analysis, with assumptions on solution regularity and numerical oscillation strength.

Result: Achieves $L^\infty L^1$ convergence with rate $h^{1/3}$ under a time step restriction and specific solution conditions.

Conclusion: The framework ensures reliable error estimates for numerical methods under practical conditions, advancing theoretical understanding.

Abstract: We derive conditional a priori error estimates of a wide class of finite
volume and Runge-Kutta discontinuous Galerkin methods with abstract limiting
for hyperbolic systems of conservation laws in 1D via the verification of weak
consistency and entropy stability, as recently proposed by Bressan et
al.~\cite{BressanChiriShen21}. Convergence in $L^\infty L^1$ with rate
$h^{1/3}$ is obtained under a time step restriction $\tau\leq ch$, provided the
following conditions hold: the exact solution is piecewise Lipschitz
continuous, its (finitely many and isolated) shock curves can be traced with
precision $h^{2/3}$ and, outside of these shock tracing tubular neighborhoods
the numerical solution -- assumed to be uniformly small in BV -- has
oscillation strength $h$ across each mesh cell and cell boundary.

</details>


### [18] [A High-Order, Pressure-Robust, and Decoupled Finite Difference Method for the Stokes Problem](https://arxiv.org/abs/2506.13645)
*Qiwei Feng,Bin Han,Michael Neilan*

Main category: math.NA

TL;DR: The paper presents a novel finite difference method for the Stokes problem, decoupling velocity and pressure via a biharmonic equation, achieving sixth-order accuracy for smooth solutions and robustness to pressure and viscosity.


<details>
  <summary>Details</summary>
Motivation: To address the Stokes problem with Dirichlet boundary conditions, avoiding the limitations of simply connected domains and ensuring pressure- and viscosity-robust solutions.

Method: Derives a biharmonic equation for velocity, constructs a sixth-order finite difference scheme, and modifies it for less regular velocity fields. Pressure is approximated locally without solving additional systems.

Result: Sixth-order convergence for smooth solutions and expected lower-order for non-smooth ones, with velocity errors independent of pressure and viscosity.

Conclusion: The method effectively solves the Stokes problem in various domains, maintaining high accuracy and robustness.

Abstract: In this paper, we consider the Stokes problem with Dirichlet boundary
conditions and the constant kinematic viscosity $\nu$ in an axis-aligned domain
$\Omega$. We decouple the velocity $\bm u$ and pressure $p$ by deriving a novel
biharmonic equation in $\Omega$ and third-order boundary conditions on
$\partial\Omega$. In contrast to the fourth-order streamfunction approach, our
formulation does not require $\Omega$ to be simply connected. For smooth
velocity fields $\bm u$ in two dimensions, we explicitly construct a finite
difference method (FDM) with sixth-order consistency to approximate $\bm u$ at
all relevant grid points: interior points, boundary side points, and boundary
corner points. The resulting scheme yields two linear systems
$A_1u^{(1)}_h=b_1$ and $A_2u^{(2)}_h=b_2$, where $A_1,A_2$ are constant
matrices, and $b_1,b_2$ are independent of the pressure $p$ and the kinematic
viscosity $\nu$. Thus, the proposed method is pressure- and viscosity-robust.
To accommodate velocity fields with less regularity, we modify the FDM by
removing singular terms in the right-hand side vectors. Once the discrete
velocity is computed, we apply a sixth-order finite difference operator to
approximate the pressure gradient locally, without solving any additional
linear systems. In our numerical experiments, we test both smooth and
non-smooth solutions $(\bm u,p)$ in a square domain, a triply connected domain,
and an $L$-shaped domain in two dimensions. The results confirm sixth-order
convergence of the velocity and pressure gradient in the $\ell_\infty$-norm for
smooth solutions. For non-smooth velocity fields, our method achieves the
expected lower-order convergence. Moreover, the observed velocity error $\|{\bm
u}_h-\bm u\|_{\infty}$ is independent of the pressure $p$ and viscosity $\nu$.

</details>


### [19] [A hybrid isogeometric and finite element method: NURBS-enhanced finite element method for hexahedral meshes](https://arxiv.org/abs/2506.13694)
*Duygu Sap*

Main category: math.NA

TL;DR: A NURBS-enhanced finite element method is proposed, combining NURBS-based boundary representations with standard finite elements for accurate simulations on complex geometries.


<details>
  <summary>Details</summary>
Motivation: To integrate the geometric precision of NURBS with the efficiency of finite element analysis for improved accuracy in simulations.

Method: Decompose a 3D domain into boundary (NURBS-enhanced elements) and interior (Lagrange elements), introducing novel quadrature and interpolation rules.

Result: Stability and approximation properties are derived, and h-refinement techniques are described for refinement.

Conclusion: The method enables more accurate and efficient simulations by combining NURBS precision with finite element efficiency.

Abstract: In this paper, we present a NURBS-enhanced finite element method that
integrates NURBS-based boundary representations of geometric domains into
standard finite element frameworks applied to hexahedral meshes. We decompose
an open, bounded, convex three-dimensional domain with a NURBS boundary into
two parts, define the NURBS-enhanced finite elements over the boundary layer,
and use piecewise-linear Lagrange finite elements in the interior region. We
introduce a novel quadrature rule and a novel interpolation operator for the
NURBS-enhanced elements. We derive the stability and approximation properties
of the interpolation operators that we use. We describe how the h-refinement in
finite element analysis and the knot insertion in isogeometric analysis can be
utilized in the refinement of the NURBS-enhanced elements. To illustrate an
application of our methodology, we utilize a generic weak formulation of a
second-order elliptic PDE and derive a priori error estimates in the $H^{1}$
norm. The proposed methodology combines the efficiency of finite element
analysis with the geometric precision of NURBS, and may enable more accurate
and efficient simulations over complex geometries.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [20] [The boundedness of rough generalized commutators with Lipschitz functions on homogeneous variable exponent Herz type spaces](https://arxiv.org/abs/2506.12164)
*Ferit Gurbuz*

Main category: math.AP

TL;DR: The paper explores the transition from classical function spaces to variable exponent function spaces to address nonlinear problems, focusing on the boundedness of rough generalized commutators with Lipschitz functions in variable exponent Herz and Herz-Morrey spaces.


<details>
  <summary>Details</summary>
Motivation: Classical function spaces are ineffective for nonlinear problems under nonstandard growth conditions, prompting the shift to variable exponent function spaces, which lack translation invariance but are crucial in harmonic analysis and applied mathematics.

Method: The study leverages properties of Lipschitz functions and variable exponents to analyze the boundedness of rough generalized commutators in homogeneous variable exponent Herz and Herz-Morrey spaces.

Result: The research establishes the boundedness of the specified commutators, demonstrating the utility of variable exponent spaces in addressing complex nonlinear problems.

Conclusion: Variable exponent function spaces offer a robust framework for tackling nonlinear problems, as evidenced by the successful application to commutator boundedness, highlighting their broader mathematical and practical relevance.

Abstract: With the development of science, many nonlinear problems have emerged. At
this time, the classical function space has certain restrictions. For example,
it has lost its effectiveness for nonlinear problems under nonstandard growth
conditions. In the process of studying such nonlinear problems, scholars are
paying more and more attention to the transition from classical function space
to variable exponent function space. Also, there is a big difference between
variable exponent space and classical function space, mainly because variable
exponent function space has lost translation invariance. This difference leads
to many properties that hold in classical space no longer hold in variable
exponent space. It is important to emphasize that variable exponent function
spaces are a fundamental building block in harmonic analysis. In recent years,
there has been a growing interest in the study of function spaces equipped with
variable exponents, leading to the development of a new framework known as
variable exponent analysis. These spaces provide a powerful tool for analyzing
functions with variable growth or decay rates and have found applications in
various areas of mathematics, including partial differential equations,
harmonic analysis and image processing. One can better understand the
heterogeneity and complexity inherent in many real world phenomena by taking
into consideration the theory of variable exponent function spaces. Thus, by
using certain properties of Lipschitz functions and variable exponents, in this
article, we establish the boundedness of a class of rough generalized
commutators with Lipschitz functions on homogeneous variable exponent Herz and
Herz-Morrey spaces.

</details>


### [21] [Global Hypoellipticity for Systems in Time-Periodic Gelfand-Shilov Spaces](https://arxiv.org/abs/2506.12178)
*Fernando de Ãvila Silva,Marco Cappiello,Alexandre Kirilov*

Main category: math.AP

TL;DR: The paper studies global hypoellipticity for overdetermined systems with time-space dependent coefficients in Gelfand-Shilov spaces, providing necessary and sufficient conditions based on Diophantine estimates and coefficient behavior.


<details>
  <summary>Details</summary>
Motivation: To understand and characterize the global hypoellipticity of overdetermined systems with time-space varying coefficients in periodic Gelfand-Shilov spaces.

Method: Reduction to a normal form and construction of singular solutions to analyze hypoellipticity conditions.

Result: Necessary and sufficient conditions for global hypoellipticity are derived, involving Diophantine estimates and sign-changing behavior of coefficients.

Conclusion: The study fully characterizes when the system is not globally hypoelliptic, linking it to specific coefficient properties and estimates.

Abstract: We investigate the global hypoellipticity of a class of overdetermined
systems with coefficients depending both on time and space variables in the
setting of time-periodic Gelfand-Shilov spaces. Our main result provides
necessary and sufficient conditions for the global hypoellipticity of this
class of systems, stated in terms of Diophantine-type estimates and
sign-changing behavior of the imaginary parts of the coefficients. Through a
reduction to a normal form and detailed construction of singular solutions, we
fully characterize when the system fails to be globally hypoelliptic.

</details>


### [22] [The Gierer-Meinhardt system in the entire space with non-local proliferation rates](https://arxiv.org/abs/2506.12426)
*Marius Ghergu,Nikos I. Kavallaris,Yasuhito Miyamoto*

Main category: math.AP

TL;DR: The paper introduces a stationary Gierer-Meinhardt system with non-local proliferation rates, analyzing its solutions in biological and ecological contexts.


<details>
  <summary>Details</summary>
Motivation: To model interactions in biological morphogenesis and ecological systems using non-local terms, focusing on activator-inhibitor dynamics and species interactions.

Method: The study employs a novel system of equations with convolution terms, assuming specific conditions on parameters and kernel functions, to analyze classical positive solutions.

Result: Existence and non-existence of classical positive solutions are established under integrability conditions on the kernel, emphasizing the role of non-local proliferation rates.

Conclusion: The non-local terms significantly influence the model, with results providing insights into the behavior of the system in various contexts.

Abstract: In this work, we present a novel stationary Gierer-Meinhardt system
incorporating non-local proliferation rates, defined as follows: $$
\begin{cases} \displaystyle -\Delta u+\lambda u=\frac{J*u^p}{v^q}+\rho(x)
&\quad\mbox{ in }\mathbb{R}^N\, , N\geq 1,\\[0.1in] \displaystyle -\Delta v+\mu
v=\frac{J*u^m}{v^s} &\quad\mbox{ in }\mathbb{R}^N.\\[0.1in] \end{cases} $$ This
system emerges in various contexts, such as biological morphogenesis, where two
interacting chemicals, identified as an activator and an inhibitor, are
described, and in ecological systems modelling the interaction between two
species, classified as specialists and generalists. The non-local interspecies
interactions are represented by the terms $J*u^p, J*u^m$ where the $*$-symbol
denotes the convolution operation in $\mathbb{R}^N$ with a kernel $J\in
C^1(\mathbb{R}^N\setminus\{0\})$.
  In the system, we assume that $0<\rho\in C^{0, \gamma}(\mathbb{R}^N)$ with
$\gamma\in (0,1)$, while the parameters satisfy $\lambda, \mu, q,m,s>0$ and
$p>1$. Under various integrability conditions on the kernel $J$, we establish
the existence and non-existence of classical positive solutions in the function
space $C^{2, \delta}_{loc}(\mathbb{R}^N).$ These results further highlight the
influence of the non-local terms, particularly the proliferation rates, in the
proposed model.

</details>


### [23] [Estimates for viscosity solutions of fully nonlinear equations near smooth boundaries](https://arxiv.org/abs/2506.12477)
*Niklas L. P. LundstrÃ¶m,Marcus Olofsson,Jesper Singh*

Main category: math.AP

TL;DR: The paper simplifies proving decay estimates for viscosity solutions of fully nonlinear PDEs by reducing them to one-dimensional ODE inequalities, allowing vanishing ellipticity and unbounded lower-order terms. It also derives boundary Harnack inequalities and HÃ¶lder continuity for solutions near $C^{1,1}$-boundaries, with applications to various PDEs and PhragmÃ©n-LindelÃ¶f-type results.


<details>
  <summary>Details</summary>
Motivation: To simplify the proof of decay estimates for viscosity solutions of fully nonlinear PDEs and extend results to broader classes of equations and boundary conditions.

Method: Reduction to one-dimensional ODE inequalities, allowing vanishing ellipticity and general lower-order terms. Derives boundary Harnack inequalities and combines with $C^{1,\alpha}$-estimates.

Result: Boundary Harnack inequalities for nonlinear PDEs near $C^{1,1}$-boundaries, HÃ¶lder continuity of solution quotients, and PhragmÃ©n-LindelÃ¶f-type corollaries.

Conclusion: The approach provides a versatile framework for analyzing fully nonlinear PDEs, with applications to diverse equations and boundary conditions.

Abstract: We reduce the problem of proving decay estimates for viscosity solutions of
fully nonlinear PDEs to proving analogous estimates for solutions of
one-dimensional ordinary differential inequalities. Our machinery allow the
ellipticity to vanish near the boundary and permits general, possibly
unbounded, lower-order terms. A key consequence is the derivation of boundary
Harnack inequalities for a broad class of fully nonlinear, nonhomogeneous
equations near $C^{1,1}$-boundaries.
  In combination with $C^{1,\alpha}$-estimates, we also obtain that quotients
of positive vanishing solutions are H\"older continuous near
$C^{1,1}$-boundaries.This result applies to a wide family of fully nonlinear
uniformly elliptic PDEs; and for $p(x)$-harmonic functions and planar
$\infty$-harmonic functions near locally flat boundaries. We end by deriving
some Phragm\'en-Lindel\"of-type corollaries in unbounded domains.

</details>


### [24] [Anisotropic CalderÃ³n problem of a nearly Laplace-Beltrami operator of order $2+$](https://arxiv.org/abs/2506.12535)
*Susovan Pramanik*

Main category: math.AP

TL;DR: The paper studies the anisotropic CalderÃ³n problem for the Logarithmic Laplacian on closed Riemannian manifolds, showing that the Cauchy data set can recover the manifold's geometry up to a standard gauge.


<details>
  <summary>Details</summary>
Motivation: To explore the inverse problem of determining the geometry of a Riemannian manifold using the Cauchy data set of the Logarithmic Laplacian, a near-Laplace operator.

Method: Analyzes the anisotropic CalderÃ³n problem for the Logarithmic Laplacian on closed Riemannian manifolds.

Result: Demonstrates that the Cauchy data set can recover the manifold's geometry up to a standard gauge.

Conclusion: The findings provide insights into the inverse problem for the Logarithmic Laplacian, extending understanding of geometric recovery from Cauchy data.

Abstract: This paper investigates the anisotropic Calder\'{o}n problem for Logarithemic
Laplacian, on closed Riemannian manifolds, which could be considered as near
Laplace operator. We demonstrate that the Cauchy data set recovers the geometry
of a closed Riemannian manifold up to standard gauge.

</details>


### [25] [An Iterative PDE Based Illumination Restoration Scheme for Image Enhancement](https://arxiv.org/abs/2506.12560)
*Dragos-Patru Covei*

Main category: math.AP

TL;DR: A novel iterative method for restoring uneven illumination in grayscale images using a nonlinear elliptic equation and logarithmic potential updates.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenge of uneven illumination in grayscale images to improve image quality and analysis.

Method: Solves a nonlinear elliptic equation for an auxiliary field, updates illumination via a time-marching step using the logarithmic potential of the field.

Result: Demonstrates improved performance (PSNR and SSIM gains) over classical methods on standard test images.

Conclusion: The method is effective for grayscale illumination restoration, with future work planned for color coupling and GPU acceleration.

Abstract: We present a novel iterative scheme for restoring uneven illumination in
grayscale images. Our approach solves, at each global iteration, a nonlinear
elliptic equation for an auxiliary field $u$ and then updates the illumination
via an explicit time-marching step driven by the logarithmic potential of $u$.
We establish existence and uniqueness of the discrete subproblems, analyze
convergence of the fixed point iteration, and demonstrate performance on
standard test images, reporting PSNR and SSIM gains over classical methods.
Future work will address color coupling and GPU acceleration.

</details>


### [26] [Quantitative quasi-invariance of Gaussian measures below the energy level for the 1D generalized nonlinear SchrÃ¶dinger equation and application to global well-posedness](https://arxiv.org/abs/2506.12582)
*Alexis Knezevitch*

Main category: math.AP

TL;DR: The paper explores global solutions for the SchrÃ¶dinger equation with odd-power nonlinearity for random initial data in low regularity regimes using Gaussian measures and energy renormalization.


<details>
  <summary>Details</summary>
Motivation: To address the lack of energy conservation in low regularity regimes (Ï < 1) for the SchrÃ¶dinger equation, the study focuses on random initial data to ensure almost sure global solutions.

Method: Combines deterministic local Cauchy theory with quasi-invariance of Gaussian measures and Lq-bounds on Radon-Nikodym derivatives, using BouÃ©-Dupuis formula and PoincarÃ©-Dulac reduction.

Result: Almost sure global solutions are generated for Gaussian initial data in specified regularity ranges, leveraging renormalized energy and probabilistic tools.

Conclusion: The approach extends Bourgain's invariant measure argument, providing a framework for global well-posedness in low regularity settings.

Abstract: We consider the Schr\"odinger equation on the one dimensional torus with a
general odd-power nonlinearity $p \geq 5$, which is known to be globally
well-posed in the Sobolev space $H^\sigma(\mathbb{T})$, for every $\sigma \geq
1$, thanks to the conservation and finiteness of the energy. For regularities
$\sigma < 1$, where this energy is infinite, we explore a globalization
argument adapted to random initial data distributed according to the Gaussian
measures $\mu_s$, with covariance operator $(1-\Delta)^s$, for $s$ in a range
$(s_p,\frac{3}{2}]$. We combine a deterministic local Cauchy theory with the
quasi-invariance of Gaussian measures $\mu_s$, with additional $L^q$-bounds on
the Radon-Nikodym derivatives, to prove that the Gaussian initial data generate
almost surely global solutions. These $L^q$-bounds are obtained with respect to
Gaussian measures accompanied by a cutoff on a renormalization of the energy;
the main tools to prove them are the Bou\'e-Dupuis variational formula and a
Poincar\'e-Dulac normal form reduction. This approach is similar in spirit to
Bourgain's invariant argument and to a recent work by Forlano-Tolomeo.

</details>


### [27] [On nth Level Fractional Derivatives: An Equivalent Representation and Applications to Inverse Problem](https://arxiv.org/abs/2506.12614)
*Asim Ilyas,Salman A. Malik,Kamran Suhaib*

Main category: math.AP

TL;DR: The paper presents an equivalent representation of 2nd level fractional derivative using Riemann-Liouville fractional derivative, generalizes it to nth level, and applies it to solve an inverse problem in a diffusion equation.


<details>
  <summary>Details</summary>
Motivation: To advance the theory of nth level fractional derivatives and provide practical applications, such as solving inverse problems in diffusion equations.

Method: Derives an equivalent representation of 2nd level fractional derivative using Riemann-Liouville fractional derivative and generalizes it to nth level.

Result: Successfully generalizes the representation to nth level and applies it to solve an inverse problem in a diffusion equation.

Conclusion: The work extends fractional derivative theory and demonstrates its utility in solving practical problems.

Abstract: This work contributes to the theory of nth level fractional derivative, where
$n$ is a positive integer. An equivalent representation of 2nd level fractional
derivative in terms of Riemann-Liouville fractional derivative is presented. We
generalized our result and provide representation of nth level fractional
derivative. As an application, we solve an inverse problem defined for a
diffusion equation involving 2nd level fractional derivative.

</details>


### [28] [Inverse source problem for a hyperbolic equation by Carleman estimates](https://arxiv.org/abs/2506.12703)
*Suliang Si*

Main category: math.AP

TL;DR: A simplified proof for conditional stability in inverse source problems for hyperbolic equations, avoiding time-extension requirements.


<details>
  <summary>Details</summary>
Motivation: To simplify existing proofs for conditional stability in inverse source problems by eliminating the need for time-extension of solutions.

Method: Modified argument for proving conditional stability, applicable to various evolution equations without time-extension.

Result: Demonstrates a more straightforward proof method, widely applicable to hyperbolic and other evolution equations.

Conclusion: The approach simplifies existing proofs and broadens applicability to diverse evolution equations.

Abstract: In this article, we provide a modified argument for proving the conditional
stability of inverse source problem for a hyperbolic equation. Our method does
not require any extension of solution with respect to time and therefore
simplifies the existing proofs, which is widely applicable to various evolution
equations.

</details>


### [29] [A degree-counting formula for a Keller-Segel equation on a surface with boundary](https://arxiv.org/abs/2506.12783)
*Mohameden Ahmedou,Zhengni Hu,Heming Wang*

Main category: math.AP

TL;DR: The paper analyzes the Keller-Segel equation on a compact Riemann surface, focusing on blow-up analysis, Morse index computation, and a degree counting formula.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of bubbling solutions and derive sharper estimates around concentration points, as well as compute the Morse index and Leray-Schauder degree.

Method: Refined blow-up analysis, Morse index computation, and techniques from Bahri's critical points at infinity.

Result: Sharper a priori estimates, Morse index of solutions, and a counting formula for the Leray-Schauder degree in the non-resonant case.

Conclusion: The approach extends previous work on mean field equations and provides new insights into the Keller-Segel equation on Riemann surfaces.

Abstract: In this paper, we consider the following Keller-Segel equation on a compact
Riemann surface $(\Sigma, g)$ with smooth boundary $\partial\Sigma$: \[
  -\Delta_g u = \rho\Big(\frac{V e^u}{\int_{\Sigma} V e^u \mathrm{d} v_g} -
\frac{1}{|\Sigma|_g}\Big) \text{ in } {\Sigma}, \quad \text{ with }
  \partial_{\nu_g} u = 0 \text{ on } \partial \Sigma, \]
  where $V$ is a smooth positive function on $\Sigma$ and $\rho > 0$ is a
parameter.
  We perform a refined blow-up analysis of bubbling solutions and establish
sharper a priori estimates around their concentration points. We then compute
the Morse index of these solutions and use it to derive a counting formula for
the Leray-Schauder degree in the non-resonant case (i.e., $\rho \notin 4 \pi
\mathbb{N}$). Our approach follows the strategy proposed by C.-S. Lin and C.-C.
Chen [15,16] for mean field equation on closed surfaces and employs techniques
from Bahri's critical points at infinity [8].

</details>


### [30] [Sharp inequalities and asymptotics for polyharmonic eigenvalues](https://arxiv.org/abs/2506.12791)
*Davide Buoso,Pedro Freitas*

Main category: math.AP

TL;DR: The paper analyzes eigenvalues of scalar Dirichlet polyharmonic problems in domains, proving inequalities and growth estimates, with specific results for the ball and asymptotic expansions for large orders.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of eigenvalues in polyharmonic problems, particularly their growth and relationships between operator orders.

Method: Proves inequalities and estimates for eigenvalues on general domains, derives eigenfunctions and eigenvalue equations for the ball, and computes asymptotic expansions for large orders.

Result: Obtains bounds for eigenvalues, their growth rates, and precise asymptotic terms for the first normalized eigenvalue as the order grows.

Conclusion: The study provides insights into eigenvalue behavior in polyharmonic problems, with applications to general domains and specific cases like the ball.

Abstract: We study eigenvalues of general scalar Dirichlet polyharmonic problems in
domains in $\mathbb R^{d}$. We first prove a number of inequalities satisfied
by the eigenvalues on general domains, depending on the relations between the
orders of the operators involved. We then obtain several estimates for these
eigenvalues, yielding their growth as a function of these orders. For the
problem in the ball we derive the general form of eigenfunctions together with
the equations satisfied by the corresponding eigenvalues, and obtain several
bounds for the first eigenvalue. In the case of the polyharmonic operator of
order $2m$ we derive precise bounds yielding the first two terms in the
asymptotic expansion for the first normalised eigenvalue as $m$ grows to
infinity. These results allow us to obtain the order of growth for the $k^{\rm
th}$ polyharmonic eigenvalue on general domains.

</details>


### [31] [Morse index, topological degree and local uniqueness of multi-spikes solutions to the Lane-Emden problem in dimension two](https://arxiv.org/abs/2506.12905)
*Isabella Ianni,Peng Luo,Shusen Yan*

Main category: math.AP

TL;DR: The paper extends classical theorems on Morse index for multi-spike solutions of the Lane-Emden problem to 2D domains, derives total topological degree, and proves local uniqueness.


<details>
  <summary>Details</summary>
Motivation: To generalize existing results on Morse index for multi-spike solutions from higher dimensions (Nâ¥3) to planar domains (N=2) and explore their concentration behavior.

Method: Analyzes multi-spike positive solutions in bounded smooth planar domains, computes their Morse index, investigates concentration behavior, and derives total topological degree.

Result: Extends theorems to N=2, provides Morse index and topological degree, and establishes a new local uniqueness result.

Conclusion: The study successfully generalizes prior work to 2D, offering insights into solution behavior and uniqueness in planar domains.

Abstract: We consider multi-spike positive solutions to the Lane-Emden problem in any
bounded smooth planar domain and compute their Morse index, extending to the
dimension $N=2$ classical theorems due to Bahri-Li-Rey (1995) and Rey (1999)
when $N\geq 4$ and $N=3$, respectively. Furthermore, by deeply investigating
their concentration behavior, we also derive the total topological degree. The
Morse index and the degree counting formula yield a new local uniqueness
result.

</details>


### [32] [Sign-changing solutions for critical Hamiltonian systems in $\mathbb{R}^N$](https://arxiv.org/abs/2506.13077)
*Yuxia Guo,Seunghyeok Kim,Angela Pistoia,Shusen Yan*

Main category: math.AP

TL;DR: Infinitely many non-radial sign-changing solutions for a Hamiltonian-type elliptic system on the critical hyperbola are constructed using novel strategies.


<details>
  <summary>Details</summary>
Motivation: The study aims to address the lack of solutions for critical problems without Kelvin invariance, expanding the understanding of such systems.

Method: New ideas and robust strategies are introduced to tackle the Hamiltonian-type elliptic system with exponents on the critical hyperbola.

Result: Infinitely many geometrically distinct non-radial sign-changing solutions are successfully constructed.

Conclusion: The introduced methods are not only effective for this problem but also hold potential for other critical problems lacking Kelvin invariance.

Abstract: We build infinitely many geometrically distinct non-radial sign-changing
solutions for the Hamiltonian-type elliptic systems $$ -\Delta u =|v|^{p-1}v\
\hbox{in}\ \mathbb{R}^N,\ -\Delta v =|u|^{q-1}u\ \hbox{in}\ \mathbb{R}^N,$$
where the exponents $(p,q)$ satisfy $p,q>1$ and belong to the critical
hyperbola $$\frac1{p+1}+\frac1{q+1} =\frac {N-2}N.$$ To establish this result,
we introduce several new ideas and strategies that are both robust and
potentially applicable to other critical problems lacking the Kelvin
invariance.

</details>


### [33] [Non-convergence and convergence of bounded solutions to semilinear wave equation with dissipative boundary condition](https://arxiv.org/abs/2506.13165)
*Zhe Jiao,Xiao Li*

Main category: math.AP

TL;DR: The paper studies the long-term behavior of semilinear wave equations with dissipative boundary conditions, analyzing equilibria, non-stabilizing solutions, and convergence under specific conditions.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of semilinear wave equations under dissipative boundary conditions, particularly focusing on equilibria and solution behavior.

Method: Analyze equilibria, study non-stabilizing solutions for certain nonlinear sources, and examine convergence under Åojasiewicz-type conditions.

Result: Infinitely many equilibria exist; some solutions approach a continuum of functions without stabilizing; convergence to equilibria occurs under Åojasiewicz conditions.

Conclusion: The dynamics of semilinear wave equations are complex, with infinite equilibria and varied solution behaviors, but convergence is possible under specific conditions.

Abstract: This paper is concerned with the long-time dynamics of semilinear wave
equation subject to dissipative boundary condition. To do so, we first analyze
the set of equilibria, and show it could contain infinitely many elements.
Second, we show that, for some nonlinear interior sources, the wave equations
have solutions that do not stabilize to any single function, while they
approach a continuum of such functions. Finally, if the interior source is a
{\L}ojasiewicz-type function, the solution of the wave equation converges to an
equilibrium at a rate that depends on the {\L}ojasiewicz exponent, although the
set of equilibria is infinite.

</details>


### [34] [Melting and freezing rates of the radial interior Stefan problem in two dimension](https://arxiv.org/abs/2506.13175)
*Jeongheon Park*

Main category: math.AP

TL;DR: The paper studies the interior Stefan problem in 2D radial symmetry, analyzing melting/freezing of a water ball in ice. It constructs global solutions with exponential convergence of the free boundary to a limiting radius, linked to Dirichlet eigenvalues.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of phase transitions (melting/freezing) in a bounded geometry, contrasting prior work on exterior problems.

Method: Constructs discrete global solutions for melting/freezing scenarios, analyzing free boundary evolution using spectral theory.

Result: Exponential convergence of the free boundary to a limiting radius, with stability under perturbations of co-dimension k-1.

Conclusion: The bounded geometry leads to non-degenerate spectrum and distinct long-term behavior, differing from exterior problems.

Abstract: We consider the interior Stefan problem under radial symmetry in two
dimension. A water ball surrounded by ice undergoes melting or freezing. We
construct a discrete family of global-in-time solutions, both melting and
freezing scenarios. The evolution of the free boundary, represented by the
radius of the water ball, $\lambda(t)$ exhibits exponential convergence to a
limiting radius value $\lambda_\infty > 0$, characterized by the asymptotic
expression \[ \lambda(t) = \lambda_\infty + (1 - \lambda_\infty)\,
e^{-\frac{\lambda_k}{\lambda_\infty^2} t + o_{t \to \infty}(1)}, \] where
$\lambda_k$ stands for the $k$-th Dirichlet eigenvalue of the Laplacian on the
unit disk for any $k\in \mathbb{N}$. Our approach draws inspiration from the
research conducted by Had\v{z}i\'c and Rapha\"el [24] concerning the exterior
radial Stefan problem, which involves an ice ball is surrounded by water. In
contrast, the bounded geometry in our setting leads to scenario results in a
non-degenerate spectrum, leading to distinctly different long-term behavior.
These solutions for each $k$ remain stable under perturbations of co-dimension
$k - 1$.

</details>


### [35] [On measure-valued solutions for a structured population model with transfers](https://arxiv.org/abs/2506.13225)
*Pierre Magal,GaÃ«l Raoul*

Main category: math.AP

TL;DR: The paper studies a transfer operator for interacting cells with non-negative traits, analyzing singular distributions, regularity of fixed distributions, and proving existence/uniqueness of solutions for a dynamic transfer model.


<details>
  <summary>Details</summary>
Motivation: To understand how trait transfers between cells lead to singular distributions and to analyze the behavior of such systems mathematically.

Method: Extends the transfer operator to non-negative measures with finite second moment, examines fixed distributions, and formulates a dynamic transfer model.

Result: Proves the existence and uniqueness of mild measure-valued solutions for the Cauchy problem in the dynamic transfer model.

Conclusion: The work provides a rigorous framework for analyzing trait transfer systems, including singular distributions and dynamic behavior.

Abstract: We consider a transfer operator where two interacting cells carrying
non-negative traits transfer a random fraction of their trait to each other.
These transfers can lead to population having singular distributions in trait.
We extend the definition of the transfer operator to non-negative measures with
a finite second moment, and we discuss the regularity of the fixed
distributions of that transfer operator. Finally, we consider a dynamic
transfer model where an initial population distribution is affected by a
transfer operator: we prove the existence and uniqueness of mild measure-valued
solutions for that Cauchy problem.

</details>


### [36] [Optimal rate of convergence in the vanishing viscosity for uniformly convex Hamilton-Jacobi equations](https://arxiv.org/abs/2506.13255)
*Louis-Pierre Chaintron,Samuel Daudin*

Main category: math.AP

TL;DR: The paper improves the convergence rate for first-order Hamilton-Jacobi equations with uniformly convex Hamiltonian from O(âÎµ) to O(ÎµlogÎµ), proving it optimal.


<details>
  <summary>Details</summary>
Motivation: To address the optimal rate of convergence in the vanishing viscosity regime for Hamilton-Jacobi equations, challenging the previously believed optimal rate of O(âÎµ).

Method: Combines sup-convolution regularization, entropy estimates for the adjoint linearized equation flow, and an integrated Laplacian estimate. Also leverages semiconcavity for less regular data in the quadratic case.

Result: Achieves a proven optimal convergence rate of O(ÎµlogÎµ), with an example showing this rate cannot be improved.

Conclusion: The study refines the understanding of convergence rates in Hamilton-Jacobi equations, demonstrating the optimality of O(ÎµlogÎµ) and advancing techniques for handling less regular data.

Abstract: The purpose of this note is to provide an optimal rate of convergence in the
vanishing viscosity regime for first-order Hamilton-Jacobi equations with
uniformly convex Hamiltonian. We prove that for a globally Lipschitz-continuous
and semiconcave terminal condition the rate is of order
O($\epsilon$log$\epsilon$), and we provide an example to show that this rate
cannot be sharpened. This improves on the previously known rate of convergence
O($\sqrt$$\epsilon$), which was widely believed to be optimal. Our proof
combines techniques involving regularisation by sup-convolution with entropy
estimates for the flow of a suitable version of the adjoint linearized
equation. The key technical point is an integrated estimate of the Laplacian of
the solution against this flow. Moreover, we exploit the semiconcavity
generated by the equation to handle less regular data in the quadratic case.

</details>


### [37] [Stochastic parabolic equations in Musielak-Orlicz spaces with discontinuous in time N-function](https://arxiv.org/abs/2506.13305)
*Piotr Gwiazda,Jakub WoÅºnicki,Aneta WrÃ³blewska-KamiÅska,Aleksandra Zimmermann*

Main category: math.AP

TL;DR: Existence of weak solutions for a stochastic parabolic PDE with multiplicative noise and a monotone operator, without time regularity, is proven. ItÃ´'s formula in Orlicz spaces is also derived.


<details>
  <summary>Details</summary>
Motivation: To address stochastic PDEs with general N-function controlled operators, extending existing results for specific cases like p(t,x)-Laplacian.

Method: Use of monotone operator theory and Orlicz spaces, with proof of ItÃ´'s formula for weak solutions.

Result: Existence of weak solutions is established, and ItÃ´'s formula in Orlicz spaces is proven as an auxiliary result.

Conclusion: The framework generalizes prior work and applies to problems like p(t,x)-Laplacian and double phase cases.

Abstract: We consider a stochastic parabolic partial differential equation with
Dirichlet boundary conditions, multiplicative stochastic noise, and a monotone
parabolic operator A. The growth and coercivity of A is controlled by a general
N-function M, which depends on time, and spatial variable, but we do not assume
any regularity with respect to the former. We show the existence of weak
solutions to such system. As auxiliary result, we also provide the proof for
the It\^{o}'s formula in Orlicz spaces. This general result applies to the ones
studied in the literature, such as p(t, x)-Laplacian and double phase problems.

</details>


### [38] [Large solutions to semilinear equations for subordinate Laplacians in $C^{1,1}$ bounded open sets](https://arxiv.org/abs/2506.13462)
*Indranil Chowdhury,Zoran VondraÄek,Vanja Wagner*

Main category: math.AP

TL;DR: Existence of large solutions for semilinear problems with nonlocal operators, generalizing the fractional Laplacian, under a nonlocal Keller-Osserman condition.


<details>
  <summary>Details</summary>
Motivation: To extend the understanding of semilinear problems in bounded domains to nonlocal operators, generalizing the fractional Laplacian.

Method: Study existence using a nonlocal version of the Keller-Osserman condition, involving the subordinator and source term.

Result: Demonstrates the existence of large solutions under the specified nonlocal condition.

Conclusion: The work provides a framework for analyzing semilinear problems with nonlocal operators, broadening the scope beyond classical fractional Laplacian cases.

Abstract: We study the existence of a large solution to a semilinear problem in a
bounded open $C^{1,1}$ set for a class of nonlocal operators obtained by an
appropriate subordination of the Laplacian. These operators are classical
generalisations of the fractional Laplacian. The existence result is shown
under a nonlocal version of the Keller-Osserman condition, stated in terms of
the subordinator and the source term $f$.

</details>


### [39] [A short proof of the Alt-Caffarelli-Friedman monotonicity formula](https://arxiv.org/abs/2506.13473)
*Emanuele Salato*

Main category: math.AP

TL;DR: A short proof of the Alt-Caffarelli-Friedman monotonicity formula is presented, leveraging a convexity property to prove the Friedland-Hayman inequality.


<details>
  <summary>Details</summary>
Motivation: The Alt-Caffarelli-Friedman formula is fundamental in free boundary problems, and a concise proof is sought to enhance understanding.

Method: The proof uses a convexity property to establish the Friedland-Hayman inequality, a key step.

Result: The paper provides a succinct proof of the Alt-Caffarelli-Friedman formula.

Conclusion: The proof simplifies understanding of this foundational result in free boundary problems.

Abstract: The Alt-Caffarelli-Friedman monotonicity formula is a cornerstone in the
theory of free boundary problems. In this note we provide a short proof of this
result. To prove the main stepping stone, namely the Friedland-Hayman
inequality, we exploit a useful convexity property.

</details>


### [40] [Global hypoellipticity on time-periodic Gelfand-Shilov spaces via non-discrete Fourier analysis](https://arxiv.org/abs/2506.13475)
*AndrÃ© Pedroso Kowacs,Pedro Meyer Tokoro*

Main category: math.AP

TL;DR: Characterization of time-periodic Gelfand-Shilov spaces via Fourier transforms and applications to global regularity for differential operators.


<details>
  <summary>Details</summary>
Motivation: To analyze and characterize time-periodic Gelfand-Shilov spaces using Fourier transforms, extending previous work by de Ãvila Silva and Cappiello.

Method: Study the asymptotic behavior of Euclidean and periodic partial Fourier transforms of elements in these spaces.

Result: Necessary and sufficient conditions for global regularity are established for constant-coefficient differential operators and first-order tube-type operators.

Conclusion: The framework provides a robust tool for understanding global regularity in the context of time-periodic Gelfand-Shilov spaces.

Abstract: In this paper, we provide a characterization of the time-periodic
Gelfand-Shilov spaces, as introduced by F. de \'Avila Silva and M. Cappiello
[J. Funct. Anal., 282(9):29, 2022], through the asymptotic behaviour of both
the Euclidean and periodic partial Fourier transforms of their elements. As an
application, we establish necessary and sufficient conditions for global
regularity -- within this framework -- for a broad class of
constant-coefficient differential operators, as well as for first-order
tube-type operators.

</details>


### [41] [Formal derivation of an isentropic two-phase flow model from the multi-species Boltzmann equation](https://arxiv.org/abs/2506.13480)
*Gabriella Puppo,Thomas Rey,Tommaso Tenna*

Main category: math.AP

TL;DR: Derivation of an isentropic two-phase flow model from the multi-species Boltzmann equation, focusing on the zero Knudsen number limit and resonant intra-species collisions.


<details>
  <summary>Details</summary>
Motivation: To formally derive a two-phase flow model from kinetic theory, addressing the need for explicit coefficients and volume fraction evolution in macroscopic multiphase models.

Method: Asymptotic analysis of the Boltzmann equation for a gas mixture in the zero Knudsen number limit, emphasizing resonant intra-species collisions.

Result: A multi-velocity and multi-pressure hydrodynamic model with explicitly computed coefficients for the two-phase macroscopic model, including volume fraction evolution.

Conclusion: The derived model provides a rigorous kinetic foundation for macroscopic two-phase flow descriptions, enhancing understanding of multiphase dynamics.

Abstract: Starting from the multi-species Boltzmann equation for a gas mixture, we
propose the formal derivation of the isentropic two-phase flow model introduced
in [Romenski, E., and Toro, E. F., Comput. Fluid Dyn. J., 13 (2004)]. We
examine the asymptotic limit as the Knudsen numbers approach zero, in a regime
characterized by resonant intra-species collisions, where interactions between
particles of the same species dominate. This specific regime leads to a
multi-velocity and multi-pressure hydrodynamic model, enabling the explicit
computation of the coefficients for the two-phase macroscopic model. Our
derivation also accounts for the inclusion of the evolution of the volume
fraction, which is a key variable in many macroscopic multiphase models

</details>


### [42] [Kinetic formulation of compartmental epidemic models](https://arxiv.org/abs/2506.13551)
*Carolina Strecht-Fernandes,Fabio A. C. C. Chalub*

Main category: math.AP

TL;DR: A kinetic model coupling individual movement and pathogen dynamics generalizes compartmental models in epidemiology, with proven solution existence and uniqueness, and potential applications.


<details>
  <summary>Details</summary>
Motivation: To generalize compartmental models in epidemiology by integrating individual movement and pathogen dynamics.

Method: Develop a kinetic model coupling population movement and pathogen dynamics, proving solution existence and uniqueness in specific cases.

Result: The model generalizes compartmental models and has valid solutions in certain spaces.

Conclusion: The approach shows promise for applications in epidemiology, supported by theoretical and example-based validation.

Abstract: We introduce a kinetic model that couples the movement of a population of
individuals with the dynamics of a pathogen in the same population. The model
is formally shown to generalize the well-known compartmental models in
mathematical epidemiology. We prove the existence and uniqueness of solutions
in appropriate spaces for particular instances of the model. We finish with
some examples, and discuss possible applications of this modeling approach.

</details>


### [43] [On uniqueness of coefficient identification in the Bloch-Torrey equation for magnetic resonance imaging](https://arxiv.org/abs/2506.13708)
*Barbara Kaltenbacher*

Main category: math.AP

TL;DR: Uniqueness results for identifying multiple coefficients in the Bloch-Torrey equation for MRI, using two approaches: k-space sampling and diffusion-based methods.


<details>
  <summary>Details</summary>
Motivation: To reconstruct spatially varying spin density and relaxation times in MRI, addressing the coefficient identification problem in the Bloch-Torrey equation.

Method: Two approaches: (a) k-space sampling with explicit formulas and perturbation estimates, (b) leveraging infinite speed of propagation due to diffusion.

Result: Proves well-posedness and Lipschitz continuous differentiability of the coefficient-to-state map.

Conclusion: Findings aid in convergence analysis of reconstruction schemes and optimization of MRI experimental design.

Abstract: In this paper we provide some uniqueness results for the (multi-)coefficient
identification problem of reconstructing the spatially varying spin density as
well as the spin-lattice and spin-spin relaxation times and the local field
inhomogeneity in the Bloch-Torrey equation, as relevant in magnetic resonance
imaging MRI. To this end, we follow two approaches: (a) Relying on sampling of
the k-space and (approximately) explicit reconstruction formulas in the
simplified (Bloch) ODE setting, along with perturbation estimates; (b) Relying
on infinite speed of propagation due to diffusion. The results on
well-posendess and Lipschitz continuous differentiability of the
coefficient-to-state map derived for this purpose, are expected to be useful
also in the convergence analysis of reconstruction schemes as well in
mathematical optimization of the experimental design in MRI.

</details>


### [44] [The evolution equation and the eigenvalue problem for the Laplacian in a regular tree](https://arxiv.org/abs/2506.13728)
*Leandro M. Del Pezzo,Nicolas Frevenza,Julio D. Rossi*

Main category: math.AP

TL;DR: Study of the Laplacian operator's evolution problem on a regular tree, proving solution existence, uniqueness, and exponential decay governed by the first eigenvalue.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of solutions to the Laplacian operator with Dirichlet boundary conditions in a regular tree.

Method: Prove existence and uniqueness of solutions for compatible initial conditions, then analyze asymptotic behavior and decay rates.

Result: Solutions decay exponentially fast, with the decay rate determined by the first eigenvalue.

Conclusion: The study provides insights into the dynamics of the Laplacian operator in tree structures, highlighting exponential decay properties.

Abstract: In this paper our main goal is to study the evolution problem associated with
the Laplacian operator with Dirichlet boundary conditions in a regular tree.
First, we prove existence and uniqueness of solutions when the initial
condition is compatible with the boundary condition. Next, we deal with the
asymptotic behavior of the solutions and we prove that they decay to zero
exponentially fast. This decay rate is governed by the associated first
eigenvalue that we also study here.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [45] [The Software Landscape for the Density Matrix Renormalization Group](https://arxiv.org/abs/2506.12629)
*Per Sehlstedt,Jan Brandejs,Paolo Bientinesi,Lars Karlsson*

Main category: physics.comp-ph

TL;DR: A survey compares 35 DMRG software packages, highlighting feature overlap and advocating for modularization and standardization to reduce duplication and improve interoperability.


<details>
  <summary>Details</summary>
Motivation: To map the expanding DMRG software landscape, compare features, and promote modularization and standardization for efficiency and collaboration.

Method: Comprehensive comparison of 35 DMRG packages, focusing on parallelism strategies, symmetry-adapted formulations, and shared functionalities.

Result: Significant feature overlap found, suggesting opportunities for modularizing common operations like tensor operations and eigensolvers.

Conclusion: Greater modularity and standardization would reduce duplication, enhance interoperability, and enable tackling more complex problems.

Abstract: The density matrix renormalization group (DMRG) algorithm is a cornerstone
computational method for studying quantum many-body systems, renowned for its
accuracy and adaptability. Despite DMRG's broad applicability across fields
such as materials science, quantum chemistry, and quantum computing, numerous
independent implementations have been developed. This survey maps the rapidly
expanding DMRG software landscape, providing a comprehensive comparison of
features among 35 existing packages. We found significant overlap in features
among the packages when comparing key aspects, such as parallelism strategies
for high-performance computing and symmetry-adapted formulations that enhance
efficiency. This overlap suggests opportunities for modularization of common
operations, including tensor operations, symmetry representations, and
eigensolvers, as the packages are mostly independent and share few third-party
library dependencies where functionality is factored out. More widespread
modularization and standardization would result in reduced duplication of
efforts and improved interoperability. We believe that the proliferation of
packages and the current lack of standard interfaces and modularity are more
social than technical. We aim to raise awareness of existing packages, guide
researchers in finding a suitable package for their needs, and help developers
identify opportunities for collaboration, modularity standardization, and
optimization. Ultimately, this work emphasizes the value of greater cohesion
and modularity, which would benefit DMRG software, allowing these powerful
algorithms to tackle more complex and ambitious problems.

</details>


### [46] [Adaptive criterion and modification of wave-particle decomposition in UGKWP method for high-speed flow simulation](https://arxiv.org/abs/2506.12722)
*Junzhe Cao,Yufeng Wei,Wenpei Long,Chengwen Zhong,Kun Xu*

Main category: physics.comp-ph

TL;DR: The paper introduces an adaptive UGKWP method to improve wave-particle decomposition in high-speed flow simulations, enhancing efficiency and accuracy in multiscale physics.


<details>
  <summary>Details</summary>
Motivation: To achieve a more efficient and suitable wave-particle decomposition in high-speed flow simulations and improve performance in regions with drastic scale variations.

Method: The study modifies the UGKWP method by introducing scale-adaptive criteria (space and gradient) and adjusting the flux evolution to better align with particles.

Result: Test cases, including hypersonic flows around various geometries, validate the adaptive UGKWP method's improved performance.

Conclusion: The adaptive UGKWP method effectively addresses multiscale challenges in high-speed flow simulations, offering enhanced efficiency and accuracy.

Abstract: Benefitting from the direct modeling of physical laws in a discretized space
and the automatic decomposition of hydrodynamic waves and particles, the
unified gas-kinetic wave-particle (UGKWP) method offers notable advantages in
various multiscale physics, such as hypersonic flow, plasma transport and
radiation transport. Aiming at achieving a more suitable and efficient
wave-particle decomposition in high-speed flow simulation and enhancing the
performance in the drastic scale variation region, in this work, the scale
adaptive criterion is studied and the flux evolution of UGKWP method is
modified. Specifically, besides the perspective of time which is naturally
considered in the time-dependent distribution function of UGKWP method, two
more criteria from views of space and gradient are utilized to identify the
local scale, and to reduce the computational consumption of particles on
describing the near-equilibrium microscopic gas distribution function.
Moreover, corresponding to the coefficients in the time integration flux of
unified gas-kinetic scheme (UGKS), the evolution of hydrodynamic wave is
modified to be more consistent with particles, which is essential when the
scale changes intensely in different cells. A variety of test cases are
conducted to validate the performance of the adaptive UGKWP method, including
hypersonic flows around a cylinder at multiple inflow Knudsen numbers,
hypersonic flow over a slender cavity, side-jet impingement on hypersonic flow
and three-dimensional hypersonic flows over a $70^{\circ}$ blunted cone with a
cylindrical sting.

</details>


### [47] [Analytical coarse grained potential parameterization by Reinforcement Learning for anisotropic cellulose](https://arxiv.org/abs/2506.12893)
*Xu Don*

Main category: physics.comp-ph

TL;DR: A Reinforcement Learning (RL)-based coarse-grained model for cellulose nanocrystals (CNC) is developed to study mesoscale mechanical behavior, overcoming limitations of experiments and atomistic simulations.


<details>
  <summary>Details</summary>
Motivation: Understanding CNC's anisotropic structure and mechanical properties at the mesoscale is crucial for improving manufacturing, but traditional methods like experiments and atomistic simulations are inadequate.

Method: RL and Boltzmann inversion are used to create a coarse-grained (CG) model of CNC, incorporating anisotropy and polymer stiffness. The model is trained without limiting target properties.

Result: The RL-based CG model accurately predicts mechanical properties under various conditions without additional training, demonstrating RL's potential for parameterizing physically explainable potentials.

Conclusion: RL can effectively parameterize CG potentials for CNC, providing insights into particle interactions and offering a powerful tool for mesoscale studies.

Abstract: Cellulose nanocrystals(CNC) is a nano form of cellulose with great mechanical
performance and other merit attributes. Revealed by preceding researches of
experiments and molecular simulations, CNC has an anisotropic structure, in
which hydrogen bonds play a pivotal role. Understanding structure and
mechanical behavior of CNC in a mesoscopic scale is critical to improve
manufacturing process and property of final products, in which experiment
observation and atomistic simulation are not appropriate. Reinforcement
Learning (RL) has been an important power source for many industrial and
academic achievements in lots of fields. Nevertheless, the potential of RL has
not been fully utilized in molecular dynamics (MD) simulations. In this work,
we introduce an analytical coarse grained (CG) potential directly parameterized
by RL. We utilize RL and Boltzmann inversion to develop a novel CG model of
cellulose with consideration of anisotropy and other properties like polymer
stiffness. Resultant CG model is not limited to target properties for training,
and it could present mechanical properties under other circumstances without
additional training. With a little help of prior physical knowledge, the
results show that RL could help us parameterize potentials and help us better
understand the interactions among particles. Our model illustrates the
capability of RL to construct a CG potential which are physically explainable
and powerful.

</details>


### [48] [Latent Representation Learning of Multi-scale Thermophysics: Application to Dynamics in Shocked Porous Energetic Material](https://arxiv.org/abs/2506.12996)
*Shahab Azarfar,Joseph B. Choi,Phong CH. Nguyen,Yen T. Nguyen,Pradeep Seshadri,H. S. Udaykumar,Stephen Baek*

Main category: physics.comp-ph

TL;DR: The paper proposes a meta-learning approach using tokenization to accelerate meso-scale learning in multi-scale modeling, outperforming traditional methods with limited data.


<details>
  <summary>Details</summary>
Motivation: Addressing the computational cost of meso-scale simulations for training deep learning-based surrogate models in multi-scale frameworks.

Method: Tokenization of meso-scale physics into reduced representations, leveraging micro-scale simulations and probabilistic latent dynamics for meso-scale learning.

Result: The model outperforms a physics-aware recurrent convolutional neural network (PARC) when trained on scarce meso-scale data.

Conclusion: The approach accelerates closure model development by combining inexpensive micro-scale simulations with fast training on small meso-scale datasets, applicable to various multi-scale problems.

Abstract: Coupling of physics across length and time scales plays an important role in
the response of microstructured materials to external loads. In a multi-scale
framework, unresolved (subgrid) meso-scale dynamics is upscaled to the
homogenized (macro-scale) representation of the heterogeneous material through
closure models. Deep learning models trained using meso-scale simulation data
are now a popular route to assimilate such closure laws. However, meso-scale
simulations are computationally taxing, posing practical challenges in training
deep learning-based surrogate models from scratch. In this work, we investigate
an alternative meta-learning approach motivated by the idea of tokenization in
natural language processing. We show that one can learn a reduced
representation of the micro-scale physics to accelerate the meso-scale learning
process by tokenizing the meso-scale evolution of the physical fields involved
in an archetypal, albeit complex, reactive dynamics problem, \textit{viz.},
shock-induced energy localization in a porous energetic material. A
probabilistic latent representation of \textit{micro}-scale dynamics is learned
as building blocks for \textit{meso}-scale dynamics. The \textit{meso-}scale
latent dynamics model learns the correlation between neighboring building
blocks by training over a small dataset of meso-scale simulations. We compare
the performance of our model with a physics-aware recurrent convolutional
neural network (PARC) trained only on the full meso-scale dataset. We
demonstrate that our model can outperform PARC with scarce meso-scale data. The
proposed approach accelerates the development of closure models by leveraging
inexpensive micro-scale simulations and fast training over a small meso-scale
dataset, and can be applied to a range of multi-scale modeling problems.

</details>


### [49] [Reactions of abiogenic hydrocarbons in Earth's upper mantle](https://arxiv.org/abs/2506.13350)
*Nore Stolte,Tao Li,Ding Pan*

Main category: physics.comp-ph

TL;DR: The paper explores abiotic hydrocarbon formation in Earth's interior via FTT-like processes, revealing a new pathway for deep carbon cycling.


<details>
  <summary>Details</summary>
Motivation: To challenge the traditional biogenic origin of hydrocarbons and investigate abiotic synthesis under deep Earth conditions.

Method: Extensive ab initio molecular dynamics (AIMD) simulations (> 2.4 ns) at 10-13 GPa and 1000-1400 K, studying FTT synthesis in dry and aqueous environments.

Result: Large hydrocarbon-related species form without catalysts; supercritical water limits product size but doesn't prevent synthesis.

Conclusion: The findings reveal an abiogenic hydrocarbon synthesis route in mantle geofluids, impacting the deep carbon cycle and potential energy sources.

Abstract: The formation of hydrocarbon fuels in Earth's interior has traditionally been
considered to have biogenic origins; however, growing evidence suggests that
some light hydrocarbons may instead originate abiotically. It is widely
expected that the Fisher-Tropsch-type (FTT) process, which typically refers to
the conversion of inorganic carbon to organic matter in the geologic
convention, may also happen in Earth's interior, but the aqueous conditions and
absence of industrial catalysts in deep environments suggest that the FTT
process can be very different from that in the chemical industry. Here, we
performed extensive ab initio molecular dynamics (AIMD) simulations (> 2.4 ns)
to investigate the FTT synthesis in dry mixture and in aqueous solutions at
10-13 GPa and 1000-1400 K. We found that large hydrocarbon-related species
containing C, O, and H are abiotically synthesized via the polymerization of CO
without any catalyst. Supercritical water, commonly found in deep Earth, does
not prevent organic molecule formation but restricts product size and carbon
reduction. Our studies reveal a previously unrecognized abiogenic route for
hydrocarbon synthesis in mantle geofluids. These carbon-containing fluids could
potentially migrate from depth to shallower crustal reservoirs, thereby
contributing to the deep carbon cycle, influencing surface carbon budgets, and
possibly serving as a new energy source.

</details>


### [50] [Quantized local reduced-order modeling in time (ql-ROM)](https://arxiv.org/abs/2506.13738)
*Antonio Colanera,Luca Magri*

Main category: physics.comp-ph

TL;DR: The paper introduces a quantized local reduced-order model (ql-ROM) for spatiotemporally chaotic systems, improving stability and accuracy over global ROMs.


<details>
  <summary>Details</summary>
Motivation: Global ROMs struggle with the intricate geometry and heterogeneous density of chaotic systems' manifolds.

Method: Partition the manifold into clusters, build local ROMs for each, and patch them seamlessly.

Result: ql-ROM outperforms global ROMs in stability, short-term prediction, and long-term statistics.

Conclusion: The ql-ROM framework retains interpretability while addressing limitations of intrusive projection-based ROMs.

Abstract: Spatiotemporally chaotic systems, such as the solutions of some nonlinear
partial differential equations, are dynamical systems that evolve toward a
lower dimensional manifold. This manifold has an intricate geometry with
heterogeneous density, which makes the design of a single (global) nonlinear
reduced-order model (ROM) challenging. In this paper, we turn this around.
Instead of modeling the manifold with one single model, we partition the
manifold into clusters within which the dynamics are locally modeled. This
results in a quantized local reduced-order model (ql-ROM), which consists of
(i) quantizing the manifold via unsupervised clustering; (ii) constructing
intrusive ROMs for each cluster; and (iii) seamlessly patch the local models
with a change of basis and assignment functions. We test the method on two
nonlinear partial differential equations, i.e., the Kuramoto-Sivashinsky and 2D
Navier-Stokes equations (Kolmogorov flow), across bursting, chaotic,
quasiperiodic, and turbulent regimes. The local models are built via Galerkin
projection onto the local principal directions, which are centered on the
cluster centroids. The dynamics are modeled by switching a local ROM based on
the cluster proximity. The proposed ql-ROM framework has three advantages over
global ROMs (g-ROMs): (i) numerical stability, (ii) improved short-term
prediction accuracy in time, and (iii) accurate prediction of long-term
statistics, such as energy spectra and probability distributions. The
computational overhead is minimal with respect to g-ROMs. The proposed
framework retains the interpretability and simplicity of intrusive
projection-based ROMs, whilst overcoming their limitations in modeling complex,
high-dimensional, nonlinear dynamics.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [51] [Validation of Hermes-3 turbulence simulations against the TCV-X21 diverted L-mode reference case](https://arxiv.org/abs/2506.12180)
*B D Dudson,M Kryjak,H Muhammed,J Omotani*

Main category: physics.plasm-ph

TL;DR: Simulations of electrostatic flux-driven turbulence in TCV L-mode conditions match experimental data well but differ in density profiles and target temperatures, likely due to missing neutral gas effects.


<details>
  <summary>Details</summary>
Motivation: To validate the Hermes-3 code by comparing simulations of TCV L-mode plasmas with experimental data under varying toroidal field configurations.

Method: Electrostatic flux-driven turbulence simulations using the Hermes-3 code, inputting magnetic equilibrium, power, and particle flux, and comparing results to the TCV-X21 dataset.

Result: Simulations reproduce key experimental features like strike point shifts but differ in density profiles and target temperatures, attributed to the absence of neutral gas.

Conclusion: Neutral gas plays a crucial role in edge plasma profiles, even in low recycling regimes, as its absence in simulations leads to discrepancies with experimental data.

Abstract: Electrostatic flux-driven turbulence simulations with the Hermes-3 code are
performed in TCV L-mode conditions in forward and reversed toroidal field
configurations, and compared to the TCV-X21 reference dataset [D.S. Oliveira
and T. Body et al. 2022] qualitatively and with a quantitative methodology.
Using only the magnetic equilibrium, total power across the separatrix (120kW)
and total particle flux to the targets (3e21/s) as inputs, the simulations
produce time-averaged plasma profiles in good agreement with experiment. Shifts
in the target peak location when the toroidal field direction is reversed are
reproduced in simulation, including the experimentally observed splitting of
the outer strike point into two density peaks.
  Differences between simulation and experiment include density profiles inside
the separatrix and at the inner target in forward (favorable Grad-B) field
configuration. These differences in target temperature in forward field
configuration lead to differences in the balance of current to the inner and
outer divertor in the private flux region. The cause of these differences is
most likely the lack of neutral gas in these simulations, indicating that even
in low recycling regimes neutral gas plays an important role in determining
edge plasma profiles. These conclusions are consistent with findings in [D.S.
Oliveira and T. Body et al. 2022].

</details>


### [52] [Global linear drift-wave eigenmode structures on flux surfaces in stellarators: ion temperature gradient mode](https://arxiv.org/abs/2506.12948)
*Hongxuan Zhu,H. Chen,Z. Lin,A. Bhattacharjee*

Main category: physics.plasm-ph

TL;DR: The paper investigates linear electrostatic ion-temperature-gradient modes in stellarators, revealing nonuniform eigenmode structures localized at the ion diamagnetic drift downstream, explained by complex wavenumber spectra.


<details>
  <summary>Details</summary>
Motivation: Understanding turbulence in stellarators is limited due to nonaxisymmetry, and the coupling of field lines within flux surfaces remains understudied.

Method: Numerical simulations using the global gyrokinetic particle-in-cell code GTC, supported by a model from Zocco et al., and validation with local gyrokinetic codes stella and GX.

Result: Eigenmode structures are nonuniform and localized, explained by the imaginary part of the binormal wavenumber. Localized surface-global eigenmodes can be constructed from local codes.

Conclusion: Complex-wavenumber spectra are essential for understanding linear drift-wave eigenmode structures in stellarators.

Abstract: Turbulent transport greatly impacts the performance of stellarator magnetic
confinement devices. While significant progress has been made on the numerical
front, theoretical understanding of turbulence in stellarators is still
lacking. In particular, due to nonaxisymmetry, different field lines couple
within flux surfaces, the effects from which have yet to be adequately studied.
In this work, we numerically simulate the linear electrostatic
ion-temperature-gradient modes in stellarators using the global gyrokinetic
particle-in-cell code GTC. We find that the linear eigenmode structures are
nonuniform on flux surfaces and are localized at the downstream direction of
the ion diamagnetic drift. Based on a simple model from Zocco etal [Phys.
Plasmas 23, 082516 (2016); 27, 022507 (2020)], we show that the localization
can be explained from the nonzero imaginary part of the binormal wavenumber. We
further demonstrate that a localized surface-global eigenmode can be
constructed from local gyrokinetic codes stella and GX, if we first solve the
local dispersion relation with real wavenumbers at each field line, and then do
an analytic continuation to the complex-wavenumber plane. These results suggest
that the complex-wavenumber spectra from surface-global effects are required to
understand linear drift-wave eigenmode structures in stellarators.

</details>


### [53] [Simulation of Shattered Pellet Injections with Plasmoid Drifts in ASDEX Upgrade and ITER](https://arxiv.org/abs/2506.12957)
*O. Vallhagen,L. Antonsson,P. Halldestam,G. Papp,P. Heinrich,A. Patel,M. Hoppe,L. Votta,the ASDEX Upgrade Team,the EUROfusion Tokamak Exploitation Team*

Main category: physics.plasm-ph

TL;DR: A semi-analytical model for ablation cloud drifts in DREAM reproduces SPI experiments in ASDEX Upgrade and assesses drift impacts on ITER disruption mitigation.


<details>
  <summary>Details</summary>
Motivation: To accurately evaluate pellet injection efficiency in fusion devices by accounting for material drift toward the low-field side.

Method: Implemented a semi-analytical drift model in DREAM, validated with ASDEX Upgrade SPI experiments, and applied to ITER scenarios.

Result: Drifts reduce deuterium SPI assimilation by ~10x in ITER; RE currents are similar but drift effects are larger in fast thermal quenches.

Conclusion: Drift impacts must be considered in ITER disruption mitigation design, especially for fast thermal quenches and RE losses.

Abstract: Pellet injection is an important means to fuel and control discharges and
mitigate disruptions in reactor-scale fusion devices. To accurately assess the
efficiency of these applications, it is necessary to account for the drift of
the ablated material toward the low-field side. In this study, we have
implemented a semi-analytical model for ablation cloud drifts in the numerical
disruption modelling tool DREAM. We show that this model is capable of
reproducing the density evolution in shattered pellet injection (SPI)
experiments in ASDEX Upgrade, for model parameters within the expected range.
The model is then used to investigate the prospects for disruption mitigation
by staggered SPIs in 15 MA DT H-mode ITER scenarios. We find that the drifts
may decrease the assimilation of pure deuterium SPIs by about an order of
magnitude, which may be important to consider when designing the disruption
mitigation scheme in ITER. The ITER scenarios studied here generally result in
similar multi-MA runaway electron (RE) currents, regardless of the drift
assumptions, but the effect of the drift is larger in situations with a fast
and early thermal quench. The RE current may also be more strongly affected by
the drift losses when accounting for RE losses caused by the vertical plasma
motion.

</details>


### [54] [Reconstruction-free magnetic control of DIII-D plasma with deep reinforcement learning](https://arxiv.org/abs/2506.13267)
*G. F. Subbotin,D. I. Sorokin,M. R. Nurgaliev,A. A. Granovskiy,I. P. Kharitonov,E. V. Adishchev,E. N. Khairutdinov,R. Clark,H. Shen,W. Choi,J. Barr,D. M. Orlov*

Main category: physics.plasm-ph

TL;DR: Deep reinforcement learning (RL) is applied for magnetic plasma control in tokamaks, improving robustness and flexibility without equilibrium reconstruction.


<details>
  <summary>Details</summary>
Motivation: Traditional plasma control methods are limited by equilibrium reconstruction and linearized models, hindering adaptability and real-time performance.

Method: Uses the Soft Actor-Critic algorithm trained with NSFsim, a 2D Grad-Shafranov equilibration solver, for nonlinear control.

Result: RL-based controllers achieved robust magnetic control in experiments, maintaining performance during transients and requiring no additional tuning.

Conclusion: This approach advances AI-driven plasma control, enhancing feasibility for next-generation fusion reactors.

Abstract: Precise control of plasma shape and position is essential for stable tokamak
operation and achieving commercial fusion energy. Traditional control methods
rely on equilibrium reconstruction and linearized models, limiting adaptability
and real-time performance. Here,the first application of deep reinforcement
learning (RL) for magnetic plasma control on the mid-size DIII-D tokamak is
presented, demonstrating a nonlinear approach that improves robustness and
flexibility across plasma scenarios. Using the Soft Actor-Critic algorithm,
this method eliminates the need for equilibrium reconstruction, enabling
high-speed control execution and scalability on larger fusion devices. NSFsim,
a 2D Grad-Shafranov equilibration solver with a circuit equation and a 1D
transport solver, is used to train the agent. Its capability of reproducing the
kinetic parameter evolution alongside magnetic equilibria evolution appears to
be an essential factor significantly affecting control quality. RL-based
controllers demonstrated robust magnetic control in experimental application at
DIII-D, preserving control performance in transient events during plasma
discharges, and reaching target parameters from the first discharge without
additional tuning or modifications. The approach itself has significant
generalization potential across devices and targets. This work represents a
step toward AI-driven, real-time plasma control, advancing the feasibility of
next-generation fusion reactors.

</details>


### [55] [The bump-on-tail instability excited by energetic electrons in helicon plasma](https://arxiv.org/abs/2506.13321)
*Shi-Jie Zhang,Dong Jing,Lei Chang,Kai-Jun Fu,Chao Wang,Zi-Chen Kan,Ye Tao,Jing-Jing Ma,Ji-Kai Sun,Ding-Zhou Li,Ilya Zadiriev,Elena Kralkina,Shin-Jae You*

Main category: physics.plasm-ph

TL;DR: First study of bump-on-tail (BOT) instability in helicon plasma using the Berk-Breizman model, revealing explosive oscillations and energy exchange dynamics under various conditions.


<details>
  <summary>Details</summary>
Motivation: To understand and control BOT instability in helicon plasma for applications like space propulsion and plasma-material interactions.

Method: Used the Berk-Breizman model to analyze BOT instability under typical helicon discharge conditions, with parameter studies on collisionality and energetic drive.

Result: Explosive oscillations in disturbed distribution function, no frequency shift, and stronger energy exchange in high-power devices. BOT instability affects bulk plasma density and flux, with larger effects in rotating plasma.

Conclusion: Findings provide a comprehensive understanding of BOT instability in helicon plasma, aiding its control for efficient and safe applications.

Abstract: This work explores for the first time bump-on-tail (BOT) instability excited
by energetic electrons in helicon plasma. The Berk-Breizman model that
developed for the wave-particle interaction and resulted instability in
magnetic fusion is used. Details of the BOT instability are computed referring
to typical helicon discharge conditions. Parameter studies are also conducted
to reveal the effects of collisionality and energetic drive, to account for
high-pressure and high-power senarios respectively. It is found that under the
HXHM (high magnetic field helicon experiment) experimental parameters, the
disturbed distribution function oscillates explosively at the initial stage of
BOT instability excitation, and the wave frequency shift does not appear, i.e.,
the steady-state solution always exists under this mode. In the process of
restoring stability, the exchange of energetic particles and wave energy is
concurrent with the change of wave amplitude. As the Krook operator increases
(i.e., from 0.1 to 1), the saturation level of the electric field and the
instability enhance. Additionally, there have a bigger disturbance for the
initial EEDF (electron energy distribution function) in high-power helicon
devices, so that the energy exchange between waves and energetic particles is
stronger as well. Moreover, BOT instability effects the density and flux of
bulk plasma, and the flux increases with the Krook operator. The effect of BOT
instability is one order of magnitude larger on rotating plasma than that on
stationary plasma.These findings present a full picture of BOT instability in
helicon plasma and are valuable to controlling it for efficient and safe
applications, e.g., high-power space plasma propulsion and plasma material
interactions using helicon source.

</details>


### [56] [Analytical models for the enhancement of fusion reactivity by turbulence](https://arxiv.org/abs/2506.13711)
*Henry Fetsch,Nathaniel J. Fisch*

Main category: physics.plasm-ph

TL;DR: Turbulence in fusion plasma enhances reactivity, potentially saving energy in ICF experiments.


<details>
  <summary>Details</summary>
Motivation: To understand and quantify how fine-scale turbulence affects fusion reactivity, aiming to improve ICF design.

Method: Analyzing general subsonic turbulent flows to quantify the enhancement of fusion reactivity.

Result: Turbulence enhances fusion reactivity, offering potential energy savings in ICF experiments.

Conclusion: Leveraging turbulence in ICF design could lead to significant energy efficiency improvements.

Abstract: The reactivity of fusion plasma depends not only on its local density and
temperature but also, through a recently identified kinetic effect, on the
relative velocities of nearby fluid elements. Turbulence on fine spatial scales
therefore enhances fusion reactivity. The enhancement is quantified here for
general subsonic turbulent flows. Leveraging this effect in the design of
inertial confinement fusion (ICF) experiments could enable substantial energy
savings.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [57] [TensorSLM: Energy-efficient Embedding Compression of Sub-billion Parameter Language Models on Low-end Devices](https://arxiv.org/abs/2506.13514)
*Mingxue Xu,Yao Lei Xu,Danilo P. Mandic*

Main category: cs.CL

TL;DR: The paper proposes a training-free token embedding compression method using Tensor-Train Decomposition (TTD) for Small Language Models (SLMs) to improve adaptivity and energy efficiency on low-end devices.


<details>
  <summary>Details</summary>
Motivation: SLMs for edge applications need adaptivity and energy efficiency, unlike datacenter-deployed LLMs, which are not constrained by device battery life.

Method: The method converts pre-trained token embeddings into lower-dimensional Matrix Product States (MPS) using TTD, evaluated on compression ratio, task performance, latency, and energy consumption.

Result: The approach achieves comparable task performance with 2x embedding layer compression and reduces energy consumption per query by half.

Conclusion: The proposed TTD-based compression effectively balances performance and efficiency for SLMs on low-end devices.

Abstract: Small Language Models (SLMs, or on-device LMs) have significantly fewer
parameters than Large Language Models (LLMs). They are typically deployed on
low-end devices, like mobile phones and single-board computers. Unlike LLMs,
which rely on increasing model size for better generalisation, SLMs designed
for edge applications are expected to have adaptivity to the deployment
environments and energy efficiency given the device battery life constraints,
which are not addressed in datacenter-deployed LLMs. This paper addresses these
two requirements by proposing a training-free token embedding compression
approach using Tensor-Train Decomposition (TTD). Each pre-trained token
embedding vector is converted into a lower-dimensional Matrix Product State
(MPS). We comprehensively evaluate the extracted low-rank structures across
compression ratio, language task performance, latency, and energy consumption
on a typical low-end device, i.e. Raspberry Pi. Taking the sub-billion
parameter versions of GPT-2/Cerebres-GPT and OPT models as examples, our
approach achieves a comparable language task performance to the original model
with around $2.0\times$ embedding layer compression, while the energy
consumption of a single query drops by half.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [58] [Weighted symbol spaces, magnetic translations, and pseudodifferential operators](https://arxiv.org/abs/2506.12191)
*Michael Hitrik,Reid Johnson*

Main category: math.FA

TL;DR: The paper analyzes pseudodifferential operators linked to microlocally defined normed symbol spaces with limited regularity, introduced by J. SjÃ¶strand. It proves their boundedness on modulation spaces under certain conditions and establishes continuity properties of the Weyl composition product.


<details>
  <summary>Details</summary>
Motivation: To understand and extend the boundedness and continuity properties of pseudodifferential operators in microlocally defined symbol spaces with limited regularity.

Method: The study uses microlocally defined normed symbol spaces and investigates boundedness on modulation spaces, along with analyzing the Weyl composition product.

Result: Boundedness of the operators on modulation spaces is proven under suitable conditions, and continuity of the Weyl composition product is established.

Conclusion: The findings contribute to the theory of pseudodifferential operators by clarifying their behavior in microlocally defined symbol spaces and their composition properties.

Abstract: We study pseudodifferential operators associated to microlocally defined
normed symbol spaces of limited regularity, introduced by J. Sj\"ostrand.
Boundedness of such operators on modulation spaces is obtained under suitable
conditions, and continuity properties of the Weyl composition product are
established.

</details>


### [59] [Regularized Moment Measures](https://arxiv.org/abs/2506.13218)
*Alex Delalande,Sara Farinelli*

Main category: math.FA

TL;DR: The paper explores a modified minimization problem in optimal transport, adding a strongly convex regularization to study solutions of a modified moment measure equation and their stability.


<details>
  <summary>Details</summary>
Motivation: To extend Santambrogio's work on moment measures via entropy and optimal transport by introducing a regularization term for better stability analysis.

Method: Introduces a strongly convex regularization term (dependent on Î±) to the original minimization problem, linking its solutions to a modified moment measure equation.

Result: Demonstrates that the modified problem's solutions relate to the new equation and analyzes their stability due to the regularization.

Conclusion: The regularization term enhances stability, providing a robust framework for studying moment measure equations.

Abstract: In the work "Dealing with moment measures via entropy and optimal transport",
Santambrogio provided an optimal transport approach to study existence of
solutions for the moment measure equation, that is: given $\mu$, find $u$ such
that $ (\nabla u)_{\sharp}e^{-u}=\mu$. In particular he proves that $u$
satisfies the previous equation if and only if $e^{-u}$ is the minimizer of an
entropy and a transport cost. Here we study a modified minimization problem, in
which we add a strongly convex regularization depending on a positive $\alpha$
and we link its solutions to a modified moment measure equation $(\nabla
u)_{\sharp}e^{-u-\frac{\alpha}{2} \|x\|^2}= \mu$. Exploiting the regularization
term, we study the stability of the minimizers.

</details>


### [60] [Failure of the Flat Chain Conjecture and non-regularity of the prescribed Jacobian equation](https://arxiv.org/abs/2506.13718)
*Jakub TakÃ¡Ä*

Main category: math.FA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We show that the Flat Chain Conjecture in Lang's formulation (that is,
without requiring finite mass of the underlying currents) fails for metric
$k$-currents in $\mathbb{R}^d$ whenever $d\geq 2$ and $k\in\{1, \dots, d\}$. In
all other cases, it holds. We first connect the conjecture to a regularity
statement concerning the prescribed Jacobian equation near $L^\infty$. We then
show that the equation does not have the required regularity. For a Lipschitz
vector field $\pi$, its derivative $\mathrm{D}\pi$ exists a.e. and is
identified with a matrix. Our non-regularity results for the prescribed
Jacobian equation quantify how "small" the set
  \begin{equation*}
  \operatorname{conv}(\{\operatorname{det}\mathrm{D} \pi:
\operatorname{Lip}(\pi)\leq L\})\subset L^\infty
  \end{equation*}
  is for every $L>0$. The symbol "$\operatorname{conv}$" stands for the convex
hull. The "smallness" is quantified in topological terms and is used to show
that the Flat Chain Conjecture fails.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [61] [Non-exchangeable mean-field theory for adaptive weights: propagation of chaos and graphon sampling lemma](https://arxiv.org/abs/2506.13587)
*Datong Zhou*

Main category: math.PR

TL;DR: A mean-field theory for non-exchangeable particle systems with co-evolving states and interaction weights is developed, using a novel metric space for convergence analysis.


<details>
  <summary>Details</summary>
Motivation: Classical approaches fail for systems with dynamic interaction weights, necessitating a new framework to describe their continuum limits.

Method: Introduces a label space with filtration and a unified metric combining Wasserstein distance and cut norm to analyze convergence.

Result: Generalizes propagation of chaos and establishes convergence of finite systems to continuum limits using dense graph theory.

Conclusion: The framework successfully addresses the inadequacy of static probability spaces for dynamic systems, leveraging advanced mathematical tools.

Abstract: We develop a mean-field theory for large, non-exchangeable particle (agent)
systems where the states and interaction weights co-evolve in a coupled system
of SDEs. A first main result is a generalization of the propagation of chaos.
The weight adaptation in the SDEs makes the classical approach of using a
static probability space as the continuum limit for the agent labels
inadequate. We address this by introducing a label space endowed with a
filtration that captures the stochasticity. While this yields a well-posed
McKean-Vlasov SDE, its limit is not easily described by a Vlasov-type PDE. This
difficulty, in turn, motivates the introduction of a unified metric that
naturally combines the Wasserstein distance for states and the cut norm for
weights. In this metric space, we establish the convergence of finite systems
to their continuum limit. This result, analogous to the classical convergence
of empirical measures, is a subtle consequence of a deep result from dense
graph theory, namely the Sampling Lemma.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [62] [An advanced heat transfer model for Eulerian-Lagrangian simulations of industrial gas-solid flow systems](https://arxiv.org/abs/2506.13176)
*Toshiki Imatani,Mikio Sakai*

Main category: physics.flu-dyn

TL;DR: A novel Eulerian-based heat transfer model for DEM-CFD simulations addresses limitations of existing DEM heat transfer models, improving accuracy and compatibility with scaling laws.


<details>
  <summary>Details</summary>
Motivation: Existing DEM heat transfer models have limitations due to the soft spring model and poor compatibility with scaling laws, necessitating a more accurate and efficient solution.

Method: Develops an Eulerian framework for heat transfer within DEM simulations, simplifying heat conduction calculations by using void fraction instead of complex contact modeling.

Result: Validation tests show the model accurately captures temperature distribution independent of particle contact state and works well with coarse-grained DEM, reducing computational costs.

Conclusion: The proposed model is reliable and universal, offering a promising standard for industrial DEM-CFD simulations.

Abstract: The discrete element method (DEM) coupled with computational fluid dynamics
(CFD), has been developed to simulate complex solid-fluid flow systems. Today,
DEM is regarded as an established approach, with extensive applications in
industrial systems. Heat transfer modeling might be essential to the DEM as the
industrial applications. However, existing DEM heat transfer models have
fundamental limitations. These issues arise from the soft spring model inherent
in DEM, where heat conduction is mathematically influenced by the spring
constant. Consequently, complex modeling, considering contact state such as
contact area and duration, is typically required to estimate heat conduction
accurately. Moreover, the current heat transfer models exhibit poor
compatibility with scaling laws, such as the coarse-grained DEM, leading to
amplified temperature errors relative to motion errors. To address these
challenges, we develop a novel heat transfer model based on an Eulerian
framework within DEM simulations. In our approach, the Eulerian description is
applied to the heat transfer calculation, while particle motion remains treated
by the DEM. Notably, the heat conduction in the solid phase is captured through
a simple setup by specifying the void fraction, rather than relying on complex
contact modeling. The adequacy of the proposed model is demonstrated through
validation tests in gas-solid flow systems, showing that the temperature
distribution is independent of the particle contact state. Furthermore, the
model exhibits strong compatibility with coarse-grained DEM, maintaining
accuracy even at reduced computational costs. These results establish the new
model's reliability and universality, positioning it as a promising standard
for DEM-CFD simulations in industrial applications.

</details>


### [63] [Dual guidance: ROM-informed field reconstruction with generative models](https://arxiv.org/abs/2506.13369)
*Sajad Salavatidezfouli,Henrik Karstoft,Alexandros Iosifidis,Mahdi Abkar*

Main category: physics.flu-dyn

TL;DR: A dual-guided framework combines optimized sensor placement and a physics-informed generative model for accurate flow field reconstruction from sparse data.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of reconstructing unsteady incompressible flow fields under sparse sensing conditions, where traditional methods fail.

Method: Uses mutual information theory for sensor placement and a denoising diffusion probabilistic model guided by physical constraints.

Result: Achieves L2 errors as low as 0.05 with optimized sensors, outperforming structured layouts in sparse sensing.

Conclusion: The approach effectively bridges sensor optimization and generative modeling for accurate, physics-consistent reconstructions in data-limited scenarios.

Abstract: We present a dual-guided framework for reconstructing unsteady incompressible
flow fields using sparse observations. The approach combines optimized sensor
placement with a physics-informed guided generative model. Sensor locations are
selected using mutual information theory applied to a reduced-order model of
the flow, enabling efficient identification of high-information observation
points with minimal computational cost. These sensors, once selected, provide
targeted observations that guide a denoising diffusion probabilistic model
conditioned by physical constraints. Extensive experiments on 2D laminar
cylinder wake flows demonstrate that under sparse sensing conditions, the
structured sensor layouts fail to capture key flow dynamics, yielding high
reconstruction errors. In contrast, our optimized sensor placement strategy
achieves accurate reconstructions with L2 errors as low as 0.05, even with a
limited number of sensors, confirming the effectiveness of the proposed
approach in data-limited regimes. When the number of sensors is higher than a
threshold, however, both methods perform comparably. Our dual-guided approach
bridges reduced order model-based sensor position optimization with modern
generative modeling, providing accurate, physics-consistent reconstruction from
sparse data for scientific machine-learning problems.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [64] [Electronic Correlations Control Interlayer Coupling and Magnetic Transition in MnBi$_2$Te$_4$/MnBr$_3$ Heterostructure](https://arxiv.org/abs/2506.13448)
*Yuanhao Zhu,Xixi Yuan,Ying Zhao,Jin Zhang,Zijing Ding,Huixia Fu*

Main category: cond-mat.mtrl-sci

TL;DR: A van der Waals heterostructure of monolayer MnBi$_2$Te$_4$ (ML-MBT) and MnBr$_3$ enhances the Curie temperature of ML-MBT by 4-5 times, improving spintronic device performance.


<details>
  <summary>Details</summary>
Motivation: The low NÃ©el temperature of bulk MnBi$_2$Te$_4$ limits its practical use. The study aims to enhance its magnetic properties by interfacing it with MnBr$_3$.

Method: Density functional theory calculations and Monte Carlo simulations were used to analyze the heterostructure.

Result: The heterostructure significantly boosts the Curie temperature of ML-MBT, with electronic correlations and structural distortions playing key roles in magnetic coupling.

Conclusion: The MBT/MnBr$_3$ heterostructure provides a new way to control magnetic order and improve spintronic device performance.

Abstract: Bulk MnBi$_2$Te$_4$ (MBT) is an intrinsic antiferromagnetic topological
insulator. However, its low N\'eel temperature of $\sim 25\,\mathrm{K}$
severely restricts its practical applications. Here, we propose a van der Waals
heterostructure composed of monolayer MBT (ML-MBT) and monolayer MnBr$_3$, an
intrinsic Chern insulator possessing a high Curie temperature ($T_\mathrm{C}
\sim 200\,\mathrm{K}$). By employing density functional theory calculations and
Monte Carlo simulations, we demonstrate that interfacing ML-MBT with MnBr$_3$
significantly enhances the $T_\mathrm{C}$ of ML-MBT by a factor of four to
five. Electronic correlations characterized by the Hubbard parameter $U_2$ for
Mn-$d$ orbitals in MnBr$_3$ play a crucial role in governing magnetic coupling
within the system. At a moderate correlation strength of $U_2 =
3.0\,\mathrm{eV}$, slight structural distortions in MnBr$_3$ break intralayer
symmetry, enabling robust interlayer ferromagnetic coupling and yielding a
single, unified magnetic transition. Increasing $U_2$ reduces these structural
distortions, weakens interlayer coupling, and induces two distinct magnetic
transitions, indicating interlayer magnetic decoupling. Thus, the MBT/MnBr$_3$
heterostructure offers a novel approach for controlling magnetic order and
enhancing the performance of spintronic devices.

</details>


<div id='astro-ph.EP'></div>

# astro-ph.EP [[Back]](#toc)

### [65] [Numerical approach to second-order canonical perturbation theory in the planetary 3-body problem. Application to exoplanets](https://arxiv.org/abs/2506.13745)
*Aya Alnajjarine,Federico Mogavero,Jacques Laskar*

Main category: astro-ph.EP

TL;DR: A numerical approach to second-order perturbation theory is developed to address limitations of traditional secular theories in modeling eccentric, inclined, or tightly-packed planetary systems.


<details>
  <summary>Details</summary>
Motivation: Traditional secular theories struggle with highly eccentric, inclined, or tightly-packed planetary systems due to convergence issues in orbital element expansions.

Method: The paper introduces a numerical method using Lie transform formalism to derive a second-order secular Hamiltonian, avoiding orbital element expansions. Fast Fourier transform is used for accurate long-term simulations.

Result: The method is validated against known systems (e.g., Sun-Jupiter-Saturn) and exoplanetary systems (e.g., WASP-148), showing broad applicability.

Conclusion: The proposed approach overcomes traditional limitations, offering robust convergence and wider applicability for diverse planetary architectures.

Abstract: Extrasolar planetary systems commonly exhibit planets on eccentric orbits,
with many systems located near or within mean-motion resonances, showcasing a
wide diversity of orbital architectures. Such complex systems challenge
traditional secular theories, which are limited to first-order approximations
in planetary masses or rely on expansions in orbital elements--eccentricities,
inclinations, and semi-major axis ratios--that are subject to convergence
issues, especially in highly eccentric, inclined, or tightly-packed systems. To
overcome these limitations, we develop a numerical approach to second-order
perturbation theory based on the Lie transform formalism. Our method avoids the
need for expansions in orbital elements, ensuring broader applicability and
more robust convergence. We first outline the Hamiltonian framework for the
3-body planetary problem, and apply a canonical transformation to eliminate
fast angle dependencies, deriving the secular Hamiltonian up to second order in
the mass ratio. We then use the fast Fourier transform algorithm to numerically
simulate, in an accurate way, the long-term evolution of planetary systems near
or away from mean-motion resonances. Finally, we validate our methods against
well-known planetary configurations, such as the Sun-Jupiter-Saturn system, as
well as to exoplanetary systems like WASP-148, TIC 279401253 and GJ 876,
demonstrating the applicability of our models across a wide range of planetary
configurations.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [66] [Generic regularity for minimizing hypersurfaces in dimension 11](https://arxiv.org/abs/2506.12852)
*Otis Chodosh,Christos Mantoulidis,Felix Schulze,Zhihan Wang*

Main category: math.DG

TL;DR: Area-minimizing hypersurfaces are generically smooth in 11D, while in higher dimensions (â¥12D), their singular sets are limited to lower dimensions after small perturbations.


<details>
  <summary>Details</summary>
Motivation: To understand the smoothness and singularities of area-minimizing hypersurfaces in higher dimensions, addressing the Plateau problem and integral homology.

Method: Mathematical proof for generic smoothness in 11D and analysis of singular set dimensions in higher dimensions (â¥12D) under small perturbations.

Result: In 11D, hypersurfaces are generically smooth; in â¥12D, singular sets are â¤(n-10-Îµâ)-dimensional after perturbations.

Conclusion: The study provides insights into the regularity of area-minimizing hypersurfaces, with smoothness in 11D and controlled singularities in higher dimensions.

Abstract: We prove that area-minimizing hypersurfaces are generically smooth in ambient
dimension $11$ in the context of the Plateau problem and of area minimization
in integral homology. For higher ambient dimensions, $n+1 \geq 12$, we prove in
the same two contexts that area-minimizing hypersurfaces have at most an
$n-10-\epsilon_n$ dimensional singular set after an arbitrarily
$C^\infty$-small perturbation of the Plateau boundary or the ambient Riemannian
metric, respectively.

</details>


### [67] [An Isomorphism Theorem for Some Linear Elliptic Differential Operators on Quasi-Asymptotically Conical Manifolds](https://arxiv.org/abs/2506.13069)
*Mohamed Nouidha*

Main category: math.DG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study a linear elliptic differential operator of the form
$\mathcal{P}=\Delta + V - \lambda$ on a quasi-asymptotically conical
(\textbf{QAC}) manifold $(M, g)$, where $g$ is a polyhomogeneous metric and $V$
is a $b$-vector field that is unbounded with respect to the metric $g$.

</details>


<div id='nlin.PS'></div>

# nlin.PS [[Back]](#toc)

### [68] [Chimera states on m-directed hypergraphs](https://arxiv.org/abs/2506.12511)
*Rommel Tchinda Djeudjo,Timoteo Carletti,Hiroya Nakao,Riccardo Muolo*

Main category: nlin.PS

TL;DR: The paper explores chimera states in non-reciprocal higher-order structures (m-directed hypergraphs), showing that higher-order interactions enable their emergence despite non-reciprocal coupling, unlike non-reciprocal pairwise interactions.


<details>
  <summary>Details</summary>
Motivation: Chimera states are typically studied in reciprocal pairwise couplings, but real-world systems often involve non-reciprocal, many-body interactions. This work investigates their emergence in such contexts.

Method: The study uses m-directed hypergraphs to model non-reciprocal higher-order interactions and analyzes chimera states through simulations and phase reduction theory.

Result: Chimera states emerge due to higher-order topology and directionality, contrasting with their elusiveness in non-reciprocal pairwise interactions.

Conclusion: Higher-order interactions facilitate chimera states in non-reciprocal systems, highlighting their role in synchronization phenomena.

Abstract: Chimera states are synchronization patterns in which coherent and incoherent
regions coexist in systems of identical oscillators. This elusive phenomenon
has attracted a lot of interest and has been widely studied, revealing several
types of chimeras. Most cases involve reciprocal pairwise couplings, where each
oscillator exerts and receives the same interaction, modeled via networks.
However, real-world systems often have non-reciprocal, non-pairwise (many-body)
interactions. From previous studies, it is known that chimera states are more
elusive in the presence of non-reciprocal pairwise interactions, while easier
to be found when the latter are reciprocal and higher-order (many-body). In
this work, we investigate the emergence of chimera states on non-reciprocal
higher-order structures, called m-directed hypergraphs, and we show that, not
only the higher-order topology allows the emergence of chimera states despite
the non-reciprocal coupling, but also that chimera states can emerge because of
the directionality. Finally, we compare the latter results with the one
resulting from non-reciprocal pairwise interactions: their elusiveness confirms
that the observed phenomenon is thus due to the presence of higher-order
interactions. The nature of phase chimeras has been further validated through
phase reduction theory.

</details>


### [69] [Fronts and patterns with a dynamic parameter ramp](https://arxiv.org/abs/2506.12142)
*Montie Avery,Odalys Garcia-Lopez,Ryan Goh,Benjamin Hosek,Ethan Shade*

Main category: nlin.PS

TL;DR: The paper analyzes the impact of slowly-varying time-dependent parameters on invasion fronts, focusing on linearized analysis, comparison principles, and modulation techniques to predict front behavior and spatial decay.


<details>
  <summary>Details</summary>
Motivation: To understand how dynamic parameters affect invasion fronts, particularly in systems where stability transitions occur, and to extend these insights to pattern-forming models.

Method: Uses linearized analysis for front position and decay, comparison principles for rigorous spreading results, and Burger's modulation for wavenumber prediction. Also employs space-time memory curves for delayed invasion analysis.

Result: Derives predictions for front behavior, spatial decay, and wavenumber selection, with numerical results showing delayed transitions in pushed and pulled fronts.

Conclusion: The study provides a framework for analyzing invasion fronts with dynamic parameters, applicable to various pattern-forming systems, and highlights the role of delayed effects in such processes.

Abstract: We examine the effect of a slowly-varying time-dependent parameter on
invasion fronts for which an unstable homogeneous equilibrium is invaded by
either another homogeneous state or a spatially periodic state. We first
explain and motivate our approach by studying asymptotically constant invasion
fronts in a scalar FKPP equation with time-dependent parameter which controls
the stability of the trivial state. Following recent works in the area, we use
a linearized analysis to derive formal predictions for front position and
leading-edge spatial decay. We then use a comparison principle approach to
establish a rigorous spreading result in the case of an unbounded temporal
parameter. We then consider patterned-invasion in the complex Ginzburg-Landau
equation with dynamic bifurcation parameter, a prototype for slow passage
through a spatio-temporal Hopf instability. Linearized analysis once again
gives front position and decay asymptotics, but also the selected spatial
wavenumber at the leading edge. We then use a Burger's modulation analysis to
predict the slowly-varying wavenumber in the wake of the front. Finally, in
both equations, we used the recently developed concept of a space-time memory
curve to characterize delayed invasion in the case where the parameter is
initially stable before a subsequent slow passage through instability and
invasion. We also provide preliminary results studying invasion in other
prototypical pattern formation models modified with a dynamic parameter, as
well as numerical results for delayed transition between pushed and pulled
fronts in Nagumo's equation with dynamic parameter.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [70] [Efficient vectorized evaluation of Gaussian AO integrals on modern central processing units](https://arxiv.org/abs/2506.12501)
*Andrey Asadchev,Edward F. Valeev*

Main category: physics.chem-ph

TL;DR: Implementation of McMurchie-Davidson scheme for Gaussian AO integrals optimized for modern CPUs with SIMD, achieving up to 50% peak FP64 performance and 30x speedup over Libint.


<details>
  <summary>Details</summary>
Motivation: To efficiently evaluate 1- and 2-particle Gaussian AO integrals on modern CPUs with SIMD instruction sets, optimizing for floating point throughput.

Method: Uses variable-sized batches of shellsets, optimized for SIMD (AVX2, AVX512, NEON) via standard C++ (std::simd), without explicit code generation.

Result: Achieves up to 50% of theoretical hardware peak FP64 performance and 30x speedup over Libint for various integrals.

Conclusion: The implementation, part of LibintX, demonstrates significant performance gains while maintaining portability and simplicity.

Abstract: We report an implementation of the McMurchie-Davidson evaluation scheme for
1- and 2-particle Gaussian AO integrals designed for efficient execution on
modern central processing units (CPUs) with Single Instruction Multiple Data
(SIMD) instruction sets. Like in our recent MD implementation for graphical
processing units (GPUs) [J. Chem. Phys. 160, 244109 (2024)], variable-sized
batches of shellsets of integrals are evaluated at a time. By optimizing for
the floating point instruction throughput rather than minimizing the number of
operations, this approach achieves up to 50% of the theoretical hardware peak
FP64 performance for many common SIMD-equipped platforms (AVX2, AVX512, NEON),
which translates to speedups of up to 30 over the state-of-the-art
one-shellset-at-a-time implementation of Obara-Saika-type schemes in Libint for
a variety of primitive and contracted integrals. As with our previous work, we
rely on the standard C++ programming language -- such as the std::simd standard
library feature to be included in the 2026 ISO C++ standard -- without any
explicit code generation to keep the code base small and portable. The
implementation is part of the open source LibintX library freely available at
https://github.com/ValeevGroup/libintx.

</details>


### [71] [Leveraging active learning-enhanced machine-learned interatomic potential for efficient infrared spectra prediction](https://arxiv.org/abs/2506.13486)
*Nitik Bhatia,Patrick Rinke,Ondrej Krejci*

Main category: physics.chem-ph

TL;DR: PALIRS, an active learning-based framework, efficiently predicts IR spectra of small organic molecules, reducing computational costs while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: Traditional IR spectrum simulations are computationally expensive, limiting system size and complexity. PALIRS aims to overcome this barrier.

Method: PALIRS uses active learning to train a machine-learned interatomic potential, enabling machine learning-assisted molecular dynamics for IR spectra prediction.

Result: PALIRS accurately reproduces ab-initio molecular dynamics results at lower computational cost and aligns well with experimental data.

Conclusion: PALIRS enables high-throughput IR spectra prediction, aiding exploration of complex catalytic systems and novel reaction pathways.

Abstract: Infrared (IR) spectroscopy is a pivotal analytical tool as it provides
real-time molecular insight into material structures and enables the
observation of reaction intermediates in situ. However, interpreting IR spectra
often requires high-fidelity simulations, such as density functional theory
based ab-initio molecular dynamics, which are computationally expensive and
therefore limited in the tractable system size and complexity. In this work, we
present a novel active learning-based framework, implemented in the open-source
software package PALIRS, for efficiently predicting the IR spectra of small
catalytically relevant organic molecules. PALIRS leverages active learning to
train a machine-learned interatomic potential, which is then used for machine
learning-assisted molecular dynamics simulations to calculate IR spectra.
PALIRS reproduces IR spectra computed with ab-initio molecular dynamics
accurately at a fraction of the computational cost. PALIRS further agrees well
with available experimental data not only for IR peak positions but also for
their amplitudes. This advancement with PALIRS enables high-throughput
prediction of IR spectra, facilitating the exploration of larger and more
intricate catalytic systems and aiding the identification of novel reaction
pathways.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [72] [Lower Bounds on Quantum Tunneling for Excited States](https://arxiv.org/abs/2506.12650)
*Charles L. Fefferman,Jacob Shapiro,Michael I. Weinstein*

Main category: math-ph

TL;DR: Extension of quantum tunneling results for reflection-symmetric single-well potentials in all spatial dimensions.


<details>
  <summary>Details</summary>
Motivation: To generalize existing quantum tunneling findings to reflection-symmetric potentials, filling a gap in prior research.

Method: Revisits quantum tunneling in the continuum without a magnetic field, focusing on reflection-symmetric single-well potentials.

Result: Extended previous results to include reflection-symmetry in all spatial dimensions.

Conclusion: The study successfully broadens the scope of quantum tunneling analysis to encompass symmetric potentials.

Abstract: We revisit the problem of quantum tunneling for a particle moving in the
continuum, and in the absence of a magnetic field. In all spatial dimensions,
we extend previous results to the case where the single-well potential
satisfies reflection-symmetry.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [73] [Nanodroplets Condensation on Solid Surfaces](https://arxiv.org/abs/2506.12565)
*Matteo Teodori,Dario Abbondanza,Mirko Gallo,Carlo Massimo Casciola*

Main category: cond-mat.soft

TL;DR: A mesoscale model simulates droplet condensation on hydrophobic/hydrophilic surfaces, revealing wettability's role in condensation regimes and limitations of classical nucleation theory.


<details>
  <summary>Details</summary>
Motivation: To understand the condensation process on surfaces with varying wettability and address gaps in classical nucleation theory.

Method: A stochastic mesoscale model combining fluctuating hydrodynamics and diffuse interface thermodynamics for direct simulation of vapour-liquid transition.

Result: Simulations clarify wettability's impact on filmwise vs. dropwise condensation and highlight shortcomings of classical nucleation theory.

Conclusion: The model successfully bridges nucleation to droplet hydrodynamics, offering insights into condensation behavior on different surfaces.

Abstract: This paper deals with the condensation of liquid droplets on hydrophobic and
hydrophilic surfaces. A stochastic mesoscale model based on the theory of
fluctuating hydrodynamics and the thermodynamics of a diffuse interface
approach shows how direct simulation of the vapour-liquid transition from the
nucleation process to droplet hydrodynamics can be achieved. Such simulations
explain the role of wettability in filmwise and dropwise condensation regimes
and the main limitations of classical nucleation theory.

</details>


### [74] [Non-reciprocal interactions reshape cells in a model for symbiosis](https://arxiv.org/abs/2506.13299)
*Maitane MuÃ±oz-Basagoiti,Michael Wassermair,Miguel Amaral,Buzz Baum,AnÄela Å ariÄ*

Main category: cond-mat.soft

TL;DR: A coarse-grained model studies non-reciprocal cell interactions, revealing emergent morphologies like branched protrusions and blebs, influenced by partner count and activity.


<details>
  <summary>Details</summary>
Motivation: To understand how cell shape and interactions with neighboring partners influence each other during symbiotic association.

Method: A coarse-grained model of non-reciprocal interactions between single-cell organisms is introduced.

Result: Cell membranes remodel into diverse morphologies (e.g., branched protrusions, blebs) based on partner count, asymmetry, and activity. A feedback between membrane deformation and driving force is identified.

Conclusion: Non-reciprocal interactions enable unique morphologies not possible in reciprocal systems, highlighting the role of dynamic feedback in shaping cell membranes.

Abstract: The shape of a cell influences and it is influenced by interactions with its
neighbouring partners. Here, we introduce a coarse-grained model of
non-reciprocal interactions between single-cell organisms to study emergent
morphologies during symbiotic association. We show that the cell membrane can
be remodelled into branched protrusions, invaginations, transient blebs and
other dynamical phases that depend on the number of interacting partners, the
asymmetry, and the magnitude of partnership activity. Our model finds a
dynamical feedback between the local deformation of the membrane and its
driving force, leading to morphologies not accessible to reciprocal systems.

</details>


<div id='math.MP'></div>

# math.MP [[Back]](#toc)

### [75] [The Kuramoto model on the Sierpinski Gasket](https://arxiv.org/abs/2506.12940)
*Georgi S. Medvedev,Matthew S. Mizuhara*

Main category: math.MP

TL;DR: The paper analyzes the Kuramoto model on Sierpinski gasket graphs, linking stable equilibria to harmonic maps and revealing connections between self-similarity and dynamics.


<details>
  <summary>Details</summary>
Motivation: To understand how the Kuramoto model's stable equilibria behave on fractal-like graphs, specifically the Sierpinski gasket, and their connection to harmonic maps.

Method: Study the KM on graphs approximating the Sierpinski gasket, analyzing stable equilibria as graph size grows, under Dirichlet and free boundary conditions.

Result: Unique stable equilibria exist in each homotopy class of functions from the SG to the circle, generalizing twisted states on ring networks.

Conclusion: The work establishes a link between self-similar fractal structures and network dynamics, with implications for broader fractal networks.

Abstract: We study the Kuramoto model (KM) of coupled phase oscillators on graphs
approximating the Sierpinski gasket (SG). As the size of the graph tends to
infinity, the limit points of the sequence of stable equilibria in the KM
correspond to the minima of the Dirichlet energy, i.e., to harmonic maps from
the SG to the circle. We provide a complete description of the stable
equilibria of the continuum limit of the KM on graphs approximating the SG,
under both Dirichlet and free boundary conditions. We show that there is a
unique stable equilibrium in each homotopy class of continuous functions from
the SG to the circle. These equilibria serve as generalizations of the
classical twisted states on ring networks. Furthermore, we extend the analysis
to the KM on post-critically finite fractals. The results of this work reveal
the link between self-similar organization and network dynamics.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [76] [Fully Quantum Lattice Gas Automata Building Blocks for Computational Basis State Encodings](https://arxiv.org/abs/2506.12662)
*CÄlin A. Georgescu,Merel A. Schalkers,Matthias MÃ¶ller*

Main category: quant-ph

TL;DR: The paper introduces novel building blocks for Quantum Lattice Gas Automata (QLGA) algorithms, addressing initialization, boundary conditions, collision operators, and measurement, with detailed complexity analyses and open-source implementations.


<details>
  <summary>Details</summary>
Motivation: QLGA has potential for efficient CFD modeling on quantum computers, but existing methods lack flexibility and comprehensive analysis. This work aims to fill these gaps.

Method: The authors propose new QLGA building blocks, including computational basis state encodings, initial condition instantiations, boundary condition implementations, a novel collision operator, and quantum circuits for measurement.

Result: Detailed complexity analyses and open-source implementations are provided, demonstrating practical and efficient QLGA algorithms.

Conclusion: The work advances QLGA by offering flexible, efficient, and well-analyzed building blocks for quantum CFD simulations.

Abstract: Lattice Gas Automata (LGA) is a classical method for simulating physical
phenomena, including Computational Fluid Dynamics (CFD). Quantum LGA (QLGA) is
the family of methods that implement LGA schemes on quantum computers. In
recent years, QLGA has garnered attention from researchers thanks to its
potential of efficiently modeling CFD processes by either reducing memory
requirements or providing simultaneous representations of exponentially many
LGA states. In this work, we introduce novel building blocks for QLGA
algorithms that rely on computational basis state encodings. We address every
step of the algorithm, from initial conditions to measurement, and provide
detailed complexity analyses that account for all discretization choices of the
system under simulation. We introduce multiple ways of instantiating initial
conditions, efficient boundary condition implementations for novel geometrical
patterns, a novel collision operator that models less restricted interactions
than previous implementations, and quantum circuits that extract quantities of
interest out of the quantum state. For each building block, we provide
intuitive examples and open-source implementations of the underlying quantum
circuits.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [77] [PDEfuncta: Spectrally-Aware Neural Representation for PDE Solution Modeling](https://arxiv.org/abs/2506.12790)
*Minju Jo,Woojin Cho,Uvini Balasuriya Mudiyanselage,Seungjun Lee,Noseong Park,Kookjin Lee*

Main category: cs.LG

TL;DR: The paper introduces Global Fourier Modulation (GFM) and PDEfuncta to address challenges in representing high-frequency features in scientific machine learning using implicit neural representations (INRs).


<details>
  <summary>Details</summary>
Motivation: Current INRs struggle with high-frequency features and multi-instance scalability, limiting their effectiveness in scientific applications.

Method: Proposes GFM, a Fourier-based reparameterization technique, and PDEfuncta, a meta-learning framework, to enhance INR performance for multi-modal solution fields.

Result: Empirical studies show improved representational quality and generalization for forward and inverse inference tasks without retraining.

Conclusion: GFM and PDEfuncta offer a scalable and accurate solution for modeling complex scientific data with high-frequency features.

Abstract: Scientific machine learning often involves representing complex solution
fields that exhibit high-frequency features such as sharp transitions,
fine-scale oscillations, and localized structures. While implicit neural
representations (INRs) have shown promise for continuous function modeling,
capturing such high-frequency behavior remains a challenge-especially when
modeling multiple solution fields with a shared network. Prior work addressing
spectral bias in INRs has primarily focused on single-instance settings,
limiting scalability and generalization. In this work, we propose Global
Fourier Modulation (GFM), a novel modulation technique that injects
high-frequency information at each layer of the INR through Fourier-based
reparameterization. This enables compact and accurate representation of
multiple solution fields using low-dimensional latent vectors. Building upon
GFM, we introduce PDEfuncta, a meta-learning framework designed to learn
multi-modal solution fields and support generalization to new tasks. Through
empirical studies on diverse scientific problems, we demonstrate that our
method not only improves representational quality but also shows potential for
forward and inverse inference tasks without the need for retraining.

</details>


### [78] [Mitigating loss of variance in ensemble data assimilation: machine learning-based and distance-free localizations for better covariance estimation](https://arxiv.org/abs/2506.13362)
*Vinicius L. S. Silva,Gabriel S. Seabra,Alexandre A. Emerick*

Main category: cs.LG

TL;DR: Two machine learning-based methods for tabular data and distance-free localization improve covariance estimations in ensemble data assimilation, reducing variance loss and enhancing results.


<details>
  <summary>Details</summary>
Motivation: To mitigate variance loss due to sampling errors in ensemble data assimilation and improve covariance accuracy.

Method: Two distance-free localization techniques using machine learning, integrated into the ES-MDA framework, with analysis of ML models for computational cost and accuracy.

Result: Improved covariance accuracy, reduced variance loss, and better data assimilation results. Certain ML models proved more suitable.

Conclusion: The proposed methods effectively mitigate variance loss, are easy to implement, and require no additional simulations or tuning.

Abstract: We propose two new methods based/inspired by machine learning for tabular
data and distance-free localization to enhance the covariance estimations in an
ensemble data assimilation. The main goal is to enhance the data assimilation
results by mitigating loss of variance due to sampling errors. We also analyze
the suitability of several machine learning models and the balance between
accuracy and computational cost of the covariance estimations. We introduce two
distance-free localization techniques leveraging machine learning methods
specifically tailored for tabular data. The methods are integrated into the
Ensemble Smoother with Multiple Data Assimilation (ES-MDA) framework. The
results show that the proposed localizations improve covariance accuracy and
enhance data assimilation and uncertainty quantification results. We observe
reduced variance loss for the input variables using the proposed methods.
Furthermore, we compare several machine learning models, assessing their
suitability for the problem in terms of computational cost, and quality of the
covariance estimation and data match. The influence of ensemble size is also
investigated, providing insights into balancing accuracy and computational
efficiency. Our findings demonstrate that certain machine learning models are
more suitable for this problem. This study introduces two novel methods that
mitigate variance loss for model parameters in ensemble-based data
assimilation, offering practical solutions that are easy to implement and do
not require any additional numerical simulation or hyperparameter tuning.

</details>


### [79] [Fast Convergence for High-Order ODE Solvers in Diffusion Probabilistic Models](https://arxiv.org/abs/2506.13061)
*Daniel Zhengyu Huang,Jiaoyang Huang,Zhengjiang Lin*

Main category: cs.LG

TL;DR: The paper analyzes convergence properties of deterministic sampling methods derived from probability flow ODEs, focusing on high-order Runge-Kutta schemes, and provides theoretical bounds on sampling accuracy.


<details>
  <summary>Details</summary>
Motivation: To understand the interaction between score function regularity, approximation error, and numerical integration error in diffusion probabilistic models, ensuring accurate sampling.

Method: Develops p-th order Runge-Kutta schemes under bounded first and second derivatives of the approximate score function, analyzing convergence and total variation distance.

Result: The total variation distance between target and generated distributions is bounded, with numerical verification confirming bounded derivatives in practice.

Conclusion: Theoretical guarantees for sampling accuracy hold for general forward processes, validated by empirical results on benchmark datasets.

Abstract: Diffusion probabilistic models generate samples by learning to reverse a
noise-injection process that transforms data into noise. Reformulating this
reverse process as a deterministic probability flow ordinary differential
equation (ODE) enables efficient sampling using high-order solvers, often
requiring only $\mathcal{O}(10)$ steps. Since the score function is typically
approximated by a neural network, analyzing the interaction between its
regularity, approximation error, and numerical integration error is key to
understanding the overall sampling accuracy. In this work, we continue our
analysis of the convergence properties of the deterministic sampling methods
derived from probability flow ODEs [25], focusing on $p$-th order (exponential)
Runge-Kutta schemes for any integer $p \geq 1$. Under the assumption that the
first and second derivatives of the approximate score function are bounded, we
develop $p$-th order (exponential) Runge-Kutta schemes and demonstrate that the
total variation distance between the target distribution and the generated data
distribution can be bounded above by \begin{align*}
  O\bigl(d^{\frac{7}{4}}\varepsilon_{\text{score}}^{\frac{1}{2}}
+d(dH_{\max})^p\bigr), \end{align*} where $\varepsilon^2_{\text{score}}$
denotes the $L^2$ error in the score function approximation, $d$ is the data
dimension and $H_{\max}$ represents the maximum step size used in the solver.
We numerically verify the regularity assumption on benchmark datasets,
confirming that the first and second derivatives of the approximate score
function remain bounded in practice. Our theoretical guarantees hold for
general forward processes with arbitrary variance schedules.

</details>


### [80] [Stability Analysis of Physics-Informed Neural Networks via Variational Coercivity, Perturbation Bounds, and Concentration Estimates](https://arxiv.org/abs/2506.13554)
*Ronald Katende*

Main category: cs.LG

TL;DR: A stability framework for PINNs is developed using variational analysis, operator coercivity, and perturbation theory, providing deterministic and probabilistic bounds for perturbations and generalization errors.


<details>
  <summary>Details</summary>
Motivation: To rigorously analyze and quantify the stability of PINNs in solving PDEs, addressing how perturbations and sampling variability affect performance.

Method: Derives stability bounds via variational analysis, operator coercivity, and McDiarmid's inequality, and validates with numerical experiments.

Result: Deterministic and probabilistic stability bounds are established, with numerical validation of perturbation sensitivity and generalization.

Conclusion: The framework clarifies the impact of operator structure, sampling, and regularity on PINN training, offering practical insights for robust PDE solutions.

Abstract: We develop a rigorous stability framework for Physics-Informed Neural
Networks (PINNs) grounded in variational analysis, operator coercivity, and
explicit perturbation theory. PINNs approximate solutions to partial
differential equations (PDEs) by minimizing residual-based losses over sampled
collocation points. We derive deterministic stability bounds that quantify how
bounded perturbations in the network output propagate through both residual and
supervised loss components. Probabilistic stability is established via
McDiarmid's inequality, yielding non-asymptotic concentration bounds that link
sampling variability to empirical loss fluctuations under minimal assumptions.
Generalization from Sobolev-norm training loss to uniform approximation is
analyzed using coercivity and Sobolev embeddings, leading to pointwise error
control. The theoretical results apply to both scalar and vector-valued PDEs
and cover composite loss formulations. Numerical experiments validate the
perturbation sensitivity, sample complexity estimates, and Sobolev-to-uniform
generalization bounds. This work provides a mathematically grounded and
practically applicable stability framework for PINNs, clarifying the role of
operator structure, sampling design, and functional regularity in robust
training.

</details>


### [81] [Global Convergence of Adjoint-Optimized Neural PDEs](https://arxiv.org/abs/2506.13633)
*Konstantin Riedl,Justin Sirignano,Konstantinos Spiliopoulos*

Main category: cs.LG

TL;DR: The paper studies the convergence of adjoint gradient descent for training neural-network PDE models, proving global convergence to target data despite non-local kernel and non-convex challenges.


<details>
  <summary>Details</summary>
Motivation: To address the growing interest in neural-network PDE models in scientific machine learning and their calibration via gradient descent, focusing on convergence in the infinite-width and infinite-time limit.

Method: Analyzes adjoint gradient descent for nonlinear parabolic PDEs with embedded neural networks, proving convergence to a global minimizer despite non-local kernel and non-convexity.

Result: Demonstrates global convergence of the neural-network PDE solution to target data, validated numerically.

Conclusion: The study provides theoretical and empirical support for the effectiveness of neural-network PDE models in scientific applications, even with inherent mathematical challenges.

Abstract: Many engineering and scientific fields have recently become interested in
modeling terms in partial differential equations (PDEs) with neural networks.
The resulting neural-network PDE model, being a function of the neural network
parameters, can be calibrated to available data by optimizing over the PDE
using gradient descent, where the gradient is evaluated in a computationally
efficient manner by solving an adjoint PDE. These neural-network PDE models
have emerged as an important research area in scientific machine learning. In
this paper, we study the convergence of the adjoint gradient descent
optimization method for training neural-network PDE models in the limit where
both the number of hidden units and the training time tend to infinity.
Specifically, for a general class of nonlinear parabolic PDEs with a neural
network embedded in the source term, we prove convergence of the trained
neural-network PDE solution to the target data (i.e., a global minimizer). The
global convergence proof poses a unique mathematical challenge that is not
encountered in finite-dimensional neural network convergence analyses due to
(1) the neural network training dynamics involving a non-local neural network
kernel operator in the infinite-width hidden layer limit where the kernel lacks
a spectral gap for its eigenvalues and (2) the nonlinearity of the limit PDE
system, which leads to a non-convex optimization problem, even in the
infinite-width hidden layer limit (unlike in typical neual network training
cases where the optimization problem becomes convex in the large neuron limit).
The theoretical results are illustrated and empirically validated by numerical
studies.

</details>
