<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 18]
- [math.AP](#math.AP) [Total: 9]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 6]
- [gr-qc](#gr-qc) [Total: 1]
- [math-ph](#math-ph) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Inverse initial data reconstruction for Maxwell's equations via time-dimensional reduction method](https://arxiv.org/abs/2506.20777)
*Thuy T. Le,Cong B. Van,Trong D. Dang,Loc H. Nguyen*

Main category: math.NA

TL;DR: The paper addresses an inverse problem for the time-dependent Maxwell system, aiming to recover the initial electric field using boundary measurements. A time-dimension reduction method and quasi-reversibility approach are employed, proving convergence and demonstrating robustness in numerical experiments.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by practical constraints in recovering the initial electric field without needing initial magnetic field or charge density data, addressing a gap in inverse electromagnetic problems.

Method: The method involves projecting the electric field onto a Legendre polynomial-exponential basis in time, reducing the problem to spatial systems. The quasi-reversibility method is used for reconstruction within a minimum-norm framework.

Result: Numerical experiments show accurate reconstruction of the initial electric field, even with 10% noise, validating the method's robustness.

Conclusion: The proposed approach effectively solves the inverse problem, proving convergence and demonstrating practical applicability in realistic scenarios.

Abstract: We study an inverse problem for the time-dependent Maxwell system in an
inhomogeneous and anisotropic medium. The objective is to recover the initial
electric field $\mathbf{E}_0$ in a bounded domain $\Omega \subset
\mathbb{R}^3$, using boundary measurements of the electric field and its normal
derivative over a finite time interval. Informed by practical constraints, we
adopt an under-determined formulation of Maxwell's equations that avoids the
need for initial magnetic field data and charge density information. To address
this inverse problem, we develop a time-dimension reduction approach by
projecting the electric field onto a finite-dimensional Legendre
polynomial-exponential basis in time. This reformulates the original space-time
problem into a sequence of spatial systems for the projection coefficients. The
reconstruction is carried out using the quasi-reversibility method within a
minimum-norm framework, which accommodates the inherent non-uniqueness of the
under-determined setting. We prove a convergence theorem that ensures the
quasi-reversibility solution approximates the true solution as the noise and
regularization parameters vanish. Numerical experiments in a fully
three-dimensional setting validate the method's performance. The reconstructed
initial electric field remains accurate even with $10\%$ noise in the data,
demonstrating the robustness and applicability of the proposed approach to
realistic inverse electromagnetic problems.

</details>


### [2] [Boundary integral equation analysis for spheroidal suspensions](https://arxiv.org/abs/2506.20809)
*Leo Crowder,Tianyue Li,Eduardo Corona,Shravan Veerapaneni*

Main category: math.NA

TL;DR: A fast, spectrally accurate method for evaluating boundary integral operators (BIOs) on spheroid suspensions, combining analytical spheroidal harmonic expansions with quadrature and fast multipole acceleration.


<details>
  <summary>Details</summary>
Motivation: To efficiently and accurately evaluate BIOs for dense, polydisperse spheroid suspensions, applicable to problems like particulate flows.

Method: Derives layer potential formulas in spheroidal harmonics, uses analytical expressions for near-field interactions, and accelerates far-field interactions with quadrature and the fast multipole method.

Result: Validated accuracy and efficiency for dense suspensions, handling hundreds of particles on a single processor for both Laplace and Stokes problems.

Conclusion: The method provides a robust framework for BIO evaluation in spheroid suspensions, with potential applications in particulate flow simulations.

Abstract: In this work, we provide a fast, spectrally accurate method for the
evaluation of boundary integral operators (BIOs) on a suspension of prolate and
oblate spheroids. We first derive formulas for the standard layer potential
operators for the Laplace equation applied to an expansion of the integral
densities in the appropriate spheroidal harmonic basis. These then lead to
analytical expressions in solid harmonics that allow spectrally accurate
evaluation of near-field particle interactions. Finally, a standard quadrature
scheme is used to evaluate smooth, far-field interactions; these are then
accelerated using the fast multipole method.
  Through a number of numerical test cases, we verify the accuracy and
efficiency of our BIO evaluation framework for dense, polydisperse suspensions
of spheroids. Through the use of standard formulas linking Stokes and Laplace
potentials, we show our scheme can be readily applied to problems involving
particulate suspension flows. For both Laplace and Stokes, our method allows us
to evaluate BIOs for suspensions up to hundreds of particles on a single
processor.

</details>


### [3] [Multicontinuum Homogenization for Poroelasticity Model](https://arxiv.org/abs/2506.20890)
*Dmitry Ammosov,Mohammed Al-Kobaisi,Yalchin Efendiev*

Main category: math.NA

TL;DR: The paper derives multicontinuum poroelasticity models using homogenization to address high-contrast properties in porous media, improving accuracy over standard methods.


<details>
  <summary>Details</summary>
Motivation: Standard homogenization fails for high-contrast poroelastic media due to missing macroscopic parameters, necessitating multicontinuum approaches.

Method: Uses multicontinuum homogenization, formulates coupled cell problems, and derives generalized models with smooth macroscopic variables.

Result: Numerical experiments show high accuracy of the multicontinuum models for heterogeneous media.

Conclusion: The multicontinuum approach effectively addresses computational challenges in high-contrast poroelasticity.

Abstract: In this paper, we derive multicontinuum poroelasticity models using the
multicontinuum homogenization method. Poroelasticity models are widely used in
many areas of science and engineering to describe coupled flow and mechanics
processes in porous media. However, in many applications, the properties of
poroelastic media possess high contrast, presenting serious computational
challenges. It is well known that standard homogenization approaches often fail
to give an accurate solution due to the lack of macroscopic parameters.
Multicontinuum approaches allow us to consider such cases by defining several
average states known as continua. In the field of poroelasticity,
multiple-network models arising from the multiple porous media theory are
representatives of these approaches. In this work, we extend previous findings
by deriving the generalized multicontinuum poroelasticity model. We apply the
recently developed multicontinuum homogenization method and provide a rigorous
derivation of multicontinuum equations. For this purpose, we formulate coupled
constraint cell problems in oversampled regions to consider different
homogenized effects. Then, we obtain a multicontinuum expansion of the
fine-scale fields and derive the multicontinuum model supposing the smoothness
of macroscopic variables. We present the most general version of equations and
the simplified ones based on our numerical experiments. Numerical results are
presented for different heterogeneous media cases and demonstrate the high
accuracy of our proposed multicontinuum models.

</details>


### [4] [Two-dimensional greedy randomized Kaczmarz methods for solving large-scale linear systems](https://arxiv.org/abs/2506.20940)
*Tao Li,Meng-Long Xiao,Xin-Fang Zhang*

Main category: math.NA

TL;DR: The paper introduces novel two-dimensional randomized Kaczmarz methods with improved sampling strategies for solving large-scale linear systems, demonstrating superior computational efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the inefficiency of existing methods for large-scale linear systems, the authors propose improved randomized Kaczmarz methods with better sampling strategies.

Method: The paper introduces a two-dimensional greedy randomized Kaczmarz method and a semi-randomized version with simple random sampling, leveraging cross-product-like constants and Chebyshev's law.

Result: The proposed methods converge to the least-norm solution for consistent linear systems and outperform existing methods in computational time.

Conclusion: The new methods are efficient for big data problems, offering faster convergence and practical advantages over traditional approaches.

Abstract: In this paper, we consider a novel two-dimensional randomized Kaczmarz method
and its improved version with simple random sampling, which chooses two active
rows with probability proportional to the square of their cross-product-like
constant, for solving large-scale linear systems. From the greedy selection
strategy with grasping two larger entries of the residual vector at each
iteration, we then devise a two-dimensional greedy randomized Kaczmarz method.
To improve the above methods further, motivated by the semi-randomized Kaczmarz
method and Chebyshev's law of large numbers, we propose a two-dimensional
semi-randomized Kaczmarz method and its modified version with simple random
sampling, which is particularly advantageous for big data problems.
Theoretically, we prove that the proposed methods converge to the unique
least-norm solution of the consistent linear systems. Numerical results on some
practical applications illustrate the superiority of the proposed methods
compared with some existing ones in terms of computing time.

</details>


### [5] [An energy-stable parametric finite element method for the Willmore flow in three dimensions](https://arxiv.org/abs/2506.21025)
*Weizhu Bao,Yifei Li,Dongmin Wang*

Main category: math.NA

TL;DR: Novel energy-stable parametric finite element methods (ES-PFEM) for Willmore flow and curvature-dependent geometric gradient flows in 3D, ensuring energy stability via new geometric identities and implicit schemes.


<details>
  <summary>Details</summary>
Motivation: To address energy stability and mesh quality in curvature-dependent geometric gradient flows, particularly for Willmore flow and Gauss curvature flow.

Method: Uses two geometric identities for a new variational formulation, develops an implicit fully discrete scheme via parametric finite element method, and applies tangential velocity control for mesh quality.

Result: The method maintains energy dissipation and good mesh quality, validated by numerical experiments.

Conclusion: ES-PFEM provides a robust framework for curvature-dependent flows, with applications in Willmore flow and Gauss curvature flow, and improves mesh quality in PFEM.

Abstract: This work develops novel energy-stable parametric finite element methods
(ES-PFEM) for the Willmore flow and curvature-dependent geometric gradient
flows of surfaces in three dimensions. The key to achieving the energy
stability lies in the use of two novel geometric identities: (i) a reformulated
variational form of the normal velocity field, and (ii) incorporation of the
temporal evolution of the mean curvature into the governing equations. These
identities enable the derivation of a new variational formulation. By using the
parametric finite element method, an implicit fully discrete scheme is
subsequently developed, which maintains the energy dissipative property at the
fully discrete level. Based on the ES-PFEM, comprehensive insights into the
design of ES-PFEM for general curvature-dependent geometric gradient flows and
a new understanding of mesh quality improvement in PFEM are provided. In
particular, we develop the first PFEM for the Gauss curvature flow of surfaces.
Furthermore, a tangential velocity control methodology is applied to improve
the mesh quality and enhance the robustness of the proposed numerical method.
Extensive numerical experiments confirm that the proposed method preserves
energy dissipation properties and maintain good mesh quality in the surface
evolution under the Willmore flow.

</details>


### [6] [Entropy-stable in- and outflow boundary conditions for the compressible Navier-Stokes equations](https://arxiv.org/abs/2506.21065)
*Magnus Svärd,Anita Gjesteland*

Main category: math.NA

TL;DR: Proposed inflow/outflow boundary conditions for compressible Navier-Stokes equations, ensuring entropy, mass, and energy estimates, with a focus on entropy-stable finite-volume schemes.


<details>
  <summary>Details</summary>
Motivation: To develop robust boundary conditions for compressible Navier-Stokes equations that maintain key physical properties like entropy, mass, and energy.

Method: Proposed boundary conditions are theoretically analyzed and approximated using an entropy-stable finite-volume scheme, with numerical validation.

Result: The method provides a priori estimates for entropy, mass, and energy, and numerical computations confirm its robustness.

Conclusion: The proposed boundary conditions are effective and compatible with entropy-stable schemes, validated through numerical experiments.

Abstract: We propose inflow and outflow boundary conditions for the compressible
Navier-Stokes equations and prove that they allow a priori estimates of the
entropy, mass and total energy. Furthermore, we demonstrate how to approximate
these boundary conditions in conjunction with an entropy-stable finite-volume
scheme. The method is also applicable to other types of entropy-stable schemes.
Finally, we carry out some numerical computations with the finite-volume scheme
and demonstrate their robustness.

</details>


### [7] [Inverse source problem with a posteriori interior measurements for space-time fractional diffusion equations](https://arxiv.org/abs/2506.21070)
*Kai Yu,Zhiyuan Li,Yikan Liu*

Main category: math.NA

TL;DR: The paper addresses an inverse source problem for space-time fractional diffusion equations using interior measurements, proving uniqueness and proposing a numerical reconstruction method.


<details>
  <summary>Details</summary>
Motivation: To solve the inverse source problem for fractional diffusion equations, leveraging the memory effect of fractional derivatives and unique continuation properties.

Method: Reformulates the problem as an optimization task with Tikhonov regularization and uses the Levenberg-Marquardt method for noisy data.

Result: Numerical examples demonstrate the algorithm's efficiency and accuracy in identifying unknown sources.

Conclusion: The proposed method effectively solves the inverse problem, validated by numerical results.

Abstract: This paper investigates an inverse source problem for space-time fractional
diffusion equations from a posteriori interior measurements. The uniqueness
result is established by the memory effect of fractional derivatives and the
unique continuation property. For the numerical reconstruction, the inverse
problem is reformulated as an optimization problem with the Tikhonov
regularization. We use the Levenberg-Marquardt method to identity the unknown
source from noisy measurements. Finally, we give some numerical examples to
illustrate the efficiency and accuracy of the proposed algorithm.

</details>


### [8] [Robust space-time multiscale upscaling via multicontinuum homogenization for evolving perforated media](https://arxiv.org/abs/2506.21104)
*Wei Xie,Viet Ha Hoang,Yin Yang,Yunqing Huang*

Main category: math.NA

TL;DR: A multiscale modeling framework is developed for time-evolving perforated domains using multicontinuum homogenization to derive effective macroscopic equations.


<details>
  <summary>Details</summary>
Motivation: Address computational challenges in capturing macroscopic behavior of dynamic fine-scale geometries in engineering and geoscientific applications.

Method: Uses multicontinuum homogenization, distinguishing continua by physical characteristics and coupling them via space-time local cell problems on representative volume elements.

Result: The upscaled system provides computable macroscopic coefficients, validated by numerical experiments for accuracy and efficiency.

Conclusion: The framework is robust, generalizable, and suitable for large-scale simulations of complex time-dependent problems.

Abstract: Time-evolving perforated domains arise in many engineering and geoscientific
applications, including reactive transport, particle deposition, and structural
degradation in porous media. Accurately capturing the macroscopic behavior of
such systems poses significant computational challenges due to the dynamic
fine-scale geometries. In this paper, we develop a robust and generalizable
multiscale modeling framework based on multicontinuum homogenization to derive
effective macroscopic equations in shrinking domains. The method distinguishes
multiple continua according to the physical characteristics (e.g., channel
widths), and couples them via space-time local cell problems formulated on
representative volume elements. These local problems incorporate temporal
derivatives and domain evolution, ensuring consistency with underlying
fine-scale dynamics. The resulting upscaled system yields computable
macroscopic coefficients and is suitable for large-scale simulations. Several
numerical experiments are presented to validate the accuracy, efficiency, and
potential applicability of the method to complex time-dependent engineering
problems.

</details>


### [9] [Robust and efficient pre-processing techniques for particle-based methods including dynamic boundary generation](https://arxiv.org/abs/2506.21206)
*Niklas S. Neher,Erik Faulhaber,Sven Berger,Christian Weißenfels,Gregor J. Gassner,Michael Schlottke-Lakemper*

Main category: math.NA

TL;DR: A preprocessing technique for generating high-quality particle distributions in 2D/3D geometries, optimized for SPH and other particle-based methods, ensuring stability and accuracy.


<details>
  <summary>Details</summary>
Motivation: Challenges in obtaining stable and accurate particle distributions for complex geometries in particle-based simulations.

Method: Generates resolution-adaptive point clouds, uses signed distance fields, hierarchical winding numbers for segmentation, and SPH-inspired relaxation for particle positioning.

Result: Robust, memory-efficient, and converges to exact geometry with higher resolution.

Conclusion: The method is meshless, easy to integrate, and effective for particle-based simulations.

Abstract: Obtaining high-quality particle distributions for stable and accurate
particle-based simulations poses significant challenges, especially for complex
geometries. We introduce a preprocessing technique for 2D and 3D geometries,
optimized for smoothed particle hydrodynamics (SPH) and other particle-based
methods. Our pipeline begins with the generation of a resolution-adaptive point
cloud near the geometry's surface employing a face-based neighborhood search.
This point cloud forms the basis for a signed distance field, enabling
efficient, localized computations near surface regions. To create an initial
particle configuration, we apply a hierarchical winding number method for fast
and accurate inside-outside segmentation. Particle positions are then relaxed
using an SPH-inspired scheme, which also serves to pack boundary particles.
This ensures full kernel support and promotes isotropic distributions while
preserving the geometry interface. By leveraging the meshless nature of
particle-based methods, our approach does not require connectivity information
and is thus straightforward to integrate into existing particle-based
frameworks. It is robust to imperfect input geometries and memory-efficient
without compromising performance. Moreover, our experiments demonstrate that
with increasingly higher resolution, the resulting particle distribution
converges to the exact geometry.

</details>


### [10] [On the coordinate system-dependence of the accuracy of symplectic numerical methods](https://arxiv.org/abs/2506.21241)
*Donát M. Takács,Tamás Fülöp*

Main category: math.NA

TL;DR: The paper explores how coordinate transformations impact the accuracy of symplectic numerical methods in Hamiltonian systems, providing theoretical insights and practical examples.


<details>
  <summary>Details</summary>
Motivation: Little attention has been given to how coordinate choices affect the accuracy of symplectic methods, despite their computational significance.

Method: The study derives conditions for non-invariance of modified Hamiltonians and non-preservation of first integrals, and explores order-compensating transformations.

Result: Theoretical derivations and numerical examples demonstrate the influence of coordinate transformations on simulation accuracy.

Conclusion: The paper fills a gap by systematically analyzing coordinate effects on symplectic methods, offering practical insights for improved simulations.

Abstract: Symplectic numerical methods have become a widely-used choice for the
accurate simulation of Hamiltonian systems in various fields, including
celestial mechanics, molecular dynamics and robotics. Even though their
characteristics are well-understood mathematically, relatively little attention
has been paid in general to the practical aspect of how the choice of
coordinates affects the accuracy of the numerical results, even though the
consequences can be computationally significant. The present article aims to
fill this gap by giving a systematic overview of how coordinate transformations
can influence the results of simulations performed using symplectic methods. We
give a derivation for the non-invariance of the modified Hamiltonian of
symplectic methods under coordinate transformations, as well as a sufficient
condition for the non-preservation of a first integral corresponding to a
cyclic coordinate for the symplectic Euler method. We also consider the
possibility of finding order-compensating coordinate transformations that
improve the order of accuracy of a numerical method. Various numerical examples
are presented throughout.

</details>


### [11] [Runge--Kutta generalized Convolution Quadrature for sectorial problems](https://arxiv.org/abs/2506.21242)
*Jing Guo,Maria Lopez-Fernandez*

Main category: math.NA

TL;DR: The paper explores the generalized convolution quadrature (gCQ) method for solving sectorial problems, achieving high-order convergence and efficiency comparable to uniform-step CQ, with improved handling of singular data.


<details>
  <summary>Details</summary>
Motivation: To address the suboptimal stability and convergence of Runge--Kutta based gCQ in sectorial problems, aiming to match the performance of uniform-step CQ under similar conditions.

Method: Uses Runge--Kutta based gCQ for variable steps, proving convergence and stability for sectorial problems, and optimizes time meshes for singular data.

Result: Achieves same convergence order as uniform-step CQ, with efficient implementation and improved handling of singularities.

Conclusion: The gCQ method is effective for sectorial problems, offering high-order convergence and computational efficiency, with numerical experiments validating the approach.

Abstract: We study the application of the generalized convolution quadrature (gCQ)
based on Runge--Kutta methods to approximate the solution of an important class
of sectorial problems. The gCQ generalizes Lubich's original convolution
quadrature (CQ) to variable steps. High-order versions of the gCQ have been
developed in the last decade, relying on certain Runge--Kutta methods. The
Runge--Kutta based gCQ has been studied so far in a rather general setting,
which includes applications to boundary integral formulations of wave problems.
The available stability and convergence results for these new methods are
suboptimal compared to those known for the uniform-step CQ, both in terms of
convergence order and regularity requirements of the data. Here we focus on a
special class of sectorial problems and prove that in these important
applications it is possible to achieve the same order of convergence as for the
original CQ, under the same regularity hypotheses on the data, and for very
general time meshes. In the particular case of data with some known algebraic
type of singularity, we also show how to choose an optimally graded time mesh
to achieve convergence with maximal order, overcoming the well-known order
reduction of the original CQ in these situations. An important advantage of the
gCQ method is that it allows for a fast and memory-efficient implementation. We
describe how the fast and oblivious Runge--Kutta based gCQ can be implemented
and illustrate our theoretical results with several numerical experiments. The
codes implementing the examples in this article are available in [13].

</details>


### [12] [On Uniform Weighted Deep Polynomial approximation](https://arxiv.org/abs/2506.21306)
*Kingsley Yeon,Steven B. Damelin*

Main category: math.NA

TL;DR: The paper introduces weighted deep polynomial approximants for functions with asymmetric behavior, showing superior performance over traditional methods.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of polynomial and rational approximations for non-smooth or singular functions, especially those with asymmetric growth.

Method: Proposes a class of weighted deep polynomial approximants, combining learnable deep polynomials with one-sided weights to capture local non-smoothness and global growth.

Result: Numerical results demonstrate outperformance over Taylor, Chebyshev, and standard deep polynomial approximants.

Conclusion: The framework offers a practical solution for approximating asymmetric functions, supported by a stable optimization strategy.

Abstract: It is a classical result in rational approximation theory that certain
non-smooth or singular functions, such as $|x|$ and $x^{1/p}$, can be
efficiently approximated using rational functions with root-exponential
convergence in terms of degrees of freedom \cite{Sta, GN}. In contrast,
polynomial approximations admit only algebraic convergence by Jackson's theorem
\cite{Lub2}. Recent work shows that composite polynomial architectures can
recover exponential approximation rates even without smoothness \cite{KY}. In
this work, we introduce and analyze a class of weighted deep polynomial
approximants tailored for functions with asymmetric behavior-growing unbounded
on one side and decaying on the other. By multiplying a learnable deep
polynomial with a one-sided weight, we capture both local non-smoothness and
global growth. We show numerically that this framework outperforms Taylor,
Chebyshev, and standard deep polynomial approximants, even when all use the
same number of parameters. To optimize these approximants in practice, we
propose a stable graph-based parameterization strategy building on \cite{Jar}.

</details>


### [13] [A Sampling-Based Adaptive Rank Approach to the Wigner-Poisson System](https://arxiv.org/abs/2506.21314)
*Andrew Christlieb,Sining Gong,Jing-Mei Qiu,Nanyi Zheng*

Main category: math.NA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We develop a mass-conserving, adaptive-rank solver for the 1D1V
Wigner-Poisson system. Our work is motivated by applications to the study of
the stopping power of $\alpha$ particles at the National Ignition Facility
(NIF). In this regime, electrons are in a warm dense state, requiring more than
a standard kinetic model. They are hot enough to neglect Pauli exclusion, yet
quantum enough to require accounting for uncertainty. The Wigner-Poisson system
captures these effects but presents challenges due to its nonlocal nature.
Based on a second-order Strang splitting method, we first design a full-rank
solver with a structure-preserving Fourier update that ensures the intermediate
solutions remain real-valued (up to machine precision), improving upon previous
methods. Simulations demonstrate that the solutions exhibit a low rank
structure for moderate to high dimensionless Planck constants ($H \ge 0.1$).
This observed low rank structure motivates the development of an adaptive-rank
solver, built on a Semi-Lagrangian adaptive-rank (SLAR) scheme for advection
and an adaptive-rank, structure-preserving Fourier update for the Wigner
integral terms, with a rigorous proof of structure-preserving property
provided. Our solver achieves $O(N)$ complexity in both storage and computation
time, while preserving mass and maintaining momentum accuracy up to the
truncation error. The adaptive rank simulations are visually indistinguishable
from the full-rank simulations in capturing solution structures. These results
highlight the potential of adaptive rank methods for high-dimensional
Wigner-Poisson simulations, paving the way toward fully kinetic studies of
stopping power in warm dense plasmas.

</details>


### [14] [A discontinuous in time Streamline Diffusion Virtual Element Method for Darcy-transport problem](https://arxiv.org/abs/2506.21326)
*R A Caraballo Diaz,F Dassi*

Main category: math.NA

TL;DR: Numerical study of reactive transport using advection-diffusion-reaction systems with Darcy's law, employing Streamline Diffusion and Virtual Element Method for accurate results.


<details>
  <summary>Details</summary>
Motivation: To model and analyze transport phenomena involving chemically reactive species in flow fields governed by Darcy's law.

Method: Uses Streamline Diffusion method, Virtual Element Method for velocity and concentrations, and Discontinuous Galerkin for time. Error estimates derived via Gauss-Radau interpolation and numerical integration.

Result: Achieves arbitrary-order accuracy in space and time, supported by numerical experiments.

Conclusion: The method is effective for modeling reactive transport with high accuracy, validated by theoretical and experimental results.

Abstract: We present a first numerical study of transport phenomena involving
chemically reactive species, modeled by advection-diffusion-reaction systems
with flow fields governed by Darcy's law. Among the various discretisation
approaches, we consider the Streamline Diffusion method. Both the velocity
field and the species concentrations are computed using the Virtual Element
Method using a Discontinuous Galerkin scheme for time. An abstract error
estimate has been derived using a special technique that utilizes Gauss-Radau
interpolation in conjunction with numerical integration. These theoretical
findings are supported by numerical experiments with arbitrary-order accuracy
in both space and time.

</details>


### [15] [Efficient parameter-robust preconditioners for linear poroelasticity and elasticity in the primal formulation](https://arxiv.org/abs/2506.21361)
*Weizhang Huang,Zhuoran Wang*

Main category: math.NA

TL;DR: The paper develops nonsingular preconditioners for large-scale saddle-point systems in poroelasticity, ensuring robust performance across parameter variations without exact Schur complement computations.


<details>
  <summary>Details</summary>
Motivation: Poroelasticity problems require efficient preconditioners for large-scale systems, especially in locking cases where traditional methods fail.

Method: Nonsingular preconditioners are designed, with eigenvalue clusters around 1 and outliers. Block triangular Schur complement preconditioners are analyzed, and a locking-free weak Galerkin finite element method is used.

Result: The preconditioners show robustness to mesh size, time step, and locking parameters, with numerical results confirming effectiveness in 2D and 3D.

Conclusion: The proposed preconditioners are effective and parameter-robust, offering a practical solution for poroelasticity problems.

Abstract: Poroelasticity problems play an important role in various engineering,
geophysical, and biological applications. Their full discretization results in
a large-scale saddle-point system at each time step that is becoming singular
for locking cases and needs effective preconditioners for its fast iterative
solution. Instead of constructing spectrally equivalent ones, we develop
nonsingular preconditioners so that the eigenvalues of the preconditioned
system consist of a cluster around $1$ and an outlier in the order of
$1/\lambda$, where $\lambda$ is a Lam\'{e} constant that is large for locking
cases. It is known that the convergence factor of GMRES is bounded by the
radius of the cluster for this type of systems. Both two- and three-field block
triangular Schur complement preconditioners are studied. Upper bounds of the
radius of the eigenvalue cluster for those systems are obtained and shown to be
related to the inf-sup condition but independent of mesh size, time step, and
locking parameters, which reflects the robustness of the preconditioners with
respect to parameter variations. Moreover, the developed preconditioners do not
need to compute the Schur complement and neither require exact inversion of
diagonal blocks except the leading one. A locking-free weak Galerkin finite
element method and the implicit Euler scheme are used for the discretization of
the governing equation. Both two- and three-dimensional numerical results are
presented to confirm the effectiveness and parameter-robustness of the
developed preconditioners.

</details>


### [16] [Optimal solutions employing an algebraic Variational Multiscale approach Part II: Application to Navier-Stokes](https://arxiv.org/abs/2506.21395)
*Suyash Shrestha,Marc Gerritsma,Gonzalo Rubio,Steven Hulshoff,Esteban Ferrer*

Main category: math.NA

TL;DR: A nonlinear extension of the VMS method for high-order discretization of the 2D incompressible Navier-Stokes equations, preserving accuracy and conservation properties.


<details>
  <summary>Details</summary>
Motivation: To generalize the VMS framework for nonlinear problems while maintaining scale separation and high-order accuracy.

Method: Uses an optimal projector and approximates fine-scale contributions via the symmetric operator's Fine-Scale Greens' function.

Result: Numerical solutions closely match optimal projections of highly resolved solutions, with confirmed robustness and accuracy.

Conclusion: The method is effective for nonlinear multiscale problems, offering consistency and high-order accuracy.

Abstract: This work presents a nonlinear extension of the high-order discretisation
framework based on the Variational Multiscale (VMS) method previously
introduced for steady linear problems. Building on the concept of an optimal
projector defined via the symmetric part of the governing operator, we
generalise the formulation to treat the 2D incompressible Navier-Stokes
equations. The arroach maintains a clear separation between the resolved and
unresolved scales, with the fine-scale contributions approximated through the
approximate Fine-Scale Greens' function of the associated symmetric operator.
This enables a consistent variational treatment of the nonlinearity while
preserving high-order accuracy. We show that the method yields numerical
solutions that closely approximate the optimal projection of the
continuous/highly resolved solution and inherits desirable conservation
properties. Numerical results confirm the framework's robustness, accuracy, and
its potential for application to a broad class of nonlinear multiscale
problems.

</details>


### [17] [An adaptive dynamical low-rank optimizer for solving kinetic parameter identification inverse problems](https://arxiv.org/abs/2506.21405)
*Lena Baumann,Lukas Einkemmer,Christian Klingenberg,Jonas Kusch*

Main category: math.NA

TL;DR: A dynamical low-rank scheme is proposed for efficiently reconstructing the scattering parameter in the radiative transfer equation, reducing computational and memory costs.


<details>
  <summary>Details</summary>
Motivation: High computational and memory costs in solving parameter identification inverse problems for kinetic equations motivate the need for efficient methods.

Method: The method involves PDE-constrained optimization, adjoint equations derivation, B-spline approximation for the scattering coefficient, and dynamical low-rank approximation (DLRA) with rank-adaptive techniques.

Result: The scheme significantly reduces memory and computational costs while maintaining accuracy, as validated by numerical results.

Conclusion: The proposed DLRA scheme is efficient and accurate for solving inverse problems in radiative transfer equations compared to full solvers.

Abstract: The numerical solution of parameter identification inverse problems for
kinetic equations can exhibit high computational and memory costs. In this
paper, we propose a dynamical low-rank scheme for the reconstruction of the
scattering parameter in the radiative transfer equation from a number of
macroscopic time-independent measurements. We first work through the PDE
constrained optimization procedure in a continuous setting and derive the
adjoint equations using a Lagrangian reformulation. For the scattering
coefficient, a periodic B-spline approximation is introduced and a gradient
descent step for updating its coefficients is formulated. After the
discretization, a dynamical low-rank approximation (DLRA) is applied. We make
use of the rank-adaptive basis update & Galerkin integrator and a line search
approach for the adaptive refinement of the gradient descent step size and the
DLRA tolerance. We show that the proposed scheme significantly reduces both
memory and computational cost. Numerical results computed with different
initial conditions validate the accuracy and efficiency of the proposed DLRA
scheme compared to solutions computed with a full solver.

</details>


### [18] [An Iterative Methodology for Unitary Quantum Channel Search](https://arxiv.org/abs/2506.21455)
*Matthew M. Lin,Hao-Wei Huang,Bing-Ze Lu*

Main category: math.NA

TL;DR: Proposes an iterative algorithm using polar decomposition to approximate a quantum channel from input-output state pairs, reducing search space and identifying local minima.


<details>
  <summary>Details</summary>
Motivation: To efficiently approximate quantum channels with limited data by leveraging specific structures in input-output pairs.

Method: Uses polar decomposition in an iterative algorithm to approximate unitary matrices, proving equivalence classes and optimal solutions.

Result: Demonstrates reduced search space and identifies critical points (local minima) in the objective function.

Conclusion: The algorithm effectively approximates quantum channels and optimizes the search for unitary matrices.

Abstract: In this paper, we propose an iterative algorithm using polar decomposition to
approximate a channel characterized by a single unitary matrix based on
input-output quantum state pairs. In limited data, we state and prove that the
optimal solution obtained from our method using one pair with a specific
structure will generate an equivalent class, significantly reducing the
dimension of the searching space. Furthermore, we prove that the unitary
matrices describing the same channel differ by a complex number with modulus 1.
We rigorously prove our proposed algorithm can ultimately identify a critical
point, which is also a local minimum of the established objective function.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [19] [The $\mathcal{M}$-Operator and Uniqueness of Nonlinear Kinetic Equations](https://arxiv.org/abs/2506.20775)
*Ricardo Alonso,Maria Pia Gualdani,Weiran Sun*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce an $\mathcal{M}$-operator approach to establish the uniqueness
of continuous or bounded solutions for a broad class of Landau-type nonlinear
kinetic equations. The specific $\mathcal{M}$-operator, originally developed in
[3], acts as a negative fractional derivative in both spatial and velocity
variables and interacts in a controllable manner with the kinetic transport
operator. The novelty of this method is that it bypasses the need for bounds on
the derivatives of the solution - an assumption typically required in
uniqueness arguments for non-cutoff equations. As a result, the method enables
working with solutions with low regularity.

</details>


### [20] [Normalized solutions for the NLS equation with mixed fractional Laplacians and combined nonlinearities](https://arxiv.org/abs/2506.20943)
*Shubin Yu,Chen Yang,Chun-Lei Tang*

Main category: math.AP

TL;DR: The paper studies normalized solutions to a nonlinear Schrödinger equation with mixed fractional Laplacians and combined nonlinearities, proving existence of multiple solutions under specific conditions.


<details>
  <summary>Details</summary>
Motivation: To extend previous results on nonlinear Schrödinger equations by considering mixed fractional Laplacians and combined nonlinearities, addressing gaps in the literature.

Method: Analyzes the problem using fractional Sobolev spaces, focusing on subcritical and critical exponents. Proves existence via ground state and mountain pass solutions.

Result: Demonstrates existence of at least two solutions (ground state and mountain pass type) for certain parameter ranges, and ground states for critical exponents.

Conclusion: The results generalize prior work, providing new insights into solutions for nonlinear Schrödinger equations with mixed fractional Laplacians.

Abstract: We look for normalized solutions to the nonlinear Schr\"{o}dinger equation
with mixed fractional Laplacians and combined nonlinearities $$
\left\{\begin{array}{ll} (-\Delta)^{s_{1}} u+(-\Delta)^{s_{2}} u=\lambda u+\mu
|u|^{q-2}u+|u|^{p-2}u \ \text{in}\;{\mathbb{R}^{N}}, \\[0.1cm]
\int_{\mathbb{R}^{N}}|u|^2\mathrm dx=a^2, \end{array} \right. $$ where $N\geq
2,\;0<s_2<s_1<1, \mu>0$ and $\lambda\in\mathbb R$ appears as an unknown
Lagrange multiplier. We mainly focus on some special cases, including
fractional Sobolev subcritical or critical exponent. More precisely, for
$2<q<2+\frac{4s_2}{N}<2+\frac{4s_1}{N}<p<2_{s_1}^{\ast}:=\frac{2N}{N-2s_1}$, we
prove that the above problem has at least two solutions: a ground state with
negative energy and a solution of mountain pass type with positive energy. For
$2<q<2+\frac{4s_2}{N}$ and $p=2_{s_1}^{\ast}$, we also obtain the existence of
ground states. Our results extend some previous ones of Chergui et al. (Calc.
Var. Partial Differ. Equ., 2023) and Luo et al. (Adv. Nonlinear Stud., 2022).

</details>


### [21] [Asymptotic Analysis of Boundary Layer Solutions to Poisson-Boltzmann Type Equations in General Bounded Smooth Domains](https://arxiv.org/abs/2506.20953)
*Jhih-Hong Lyu,Tai-Chia Lin*

Main category: math.AP

TL;DR: The paper rigorously analyzes boundary layer solutions for Poisson-Boltzmann (PB) type equations in bounded domains, deriving asymptotic expansions and decay estimates across three regions based on distance from the boundary.


<details>
  <summary>Details</summary>
Motivation: To address the analytical challenges of PB type equations, especially the nonlocal nonlinearity in charge-conserving PB (CCPB) equations, and understand how domain geometry influences electrostatic interactions.

Method: Uses principal coordinate system, exponential-type estimates, and moving plane arguments to partition the domain into three regions and derive asymptotic expansions and decay estimates.

Result: Second-order asymptotic formulas in Region I, exponential decay estimates in Regions II and III, and asymptotic expansions for key physical quantities like electric potential and charge density.

Conclusion: The study provides a comprehensive framework for understanding boundary layer solutions in PB type equations, highlighting the role of domain geometry in electrostatic interactions.

Abstract: We study the boundary layer solution to singular perturbation problems
involving Poisson-Boltzmann (PB) type equations with a small parameter
$\epsilon$ in general bounded smooth domains (including multiply connected
domains) under the Robin boundary condition. The PB type equations include the
classical PB, modified PB and charge-conserving PB (CCPB) equations, which are
mathematical models for the electric potential and ion distributions. The CCPB
equations present particular analytical challenges due to their nonlocal
nonlinearity introduced through integral terms enforcing charge conservation.
Using the principal coordinate system, exponential-type estimates and the
moving plane agruments, we rigorously prove asymptotic expansions of boundary
layer solutions throughout the whole domain. The solution domain is partitioned
into three characteristic regions based on the distance from the boundary:
Region I, where the distance from the boundary is at most $T\sqrt\epsilon$,
Region II, where the distance ranges between $T\sqrt\epsilon$ and
$\epsilon^\beta$, and Region III, where the distance is at least
$\epsilon^\beta$, for given parameters $T>0$ and $0<\beta<1/2$. In Region I, we
derive second-order asymptotic formulas explicitly incorporating the effects of
boundary mean curvature, while exponential decay estimates are established for
Regions II and III. Furthermore, we obtain asymptotic expansions for key
physical quantities, including the electric potential, electric field, total
ionic charge density and total ionic charge, revealing how domain geometry
regulates electrostatic interactions.

</details>


### [22] [Phase Transition in Non-isentropic Compressible Immiscible Two-Phase Flow with van der Waals Equation of State](https://arxiv.org/abs/2506.20955)
*Yazhou Chen,Yi Peng,Xiaoding Shi,Xiaoping Wang*

Main category: math.AP

TL;DR: The paper proves global well-posedness for the compressible non-isentropic Navier-Stokes/Allen-Cahn system with van der Waals equation of state and degenerate thermal conductivity, showing bounded solutions without small initial data restrictions.


<details>
  <summary>Details</summary>
Motivation: To model immiscible two-phase flow with diffusive interfaces and understand gas-liquid phase transitions driven by non-monotonic pressure-density relationships.

Method: Develops a refined $L^2$-energy framework to analyze the one-dimensional Cauchy problem for non-vacuum and finite-temperature initial data.

Result: Existence and uniqueness of global strong solutions are proven, with all physical quantities remaining bounded despite density fluctuations and phase transitions.

Conclusion: The study confirms the system's stability and boundedness under realistic conditions, advancing understanding of phase transitions in two-phase flows.

Abstract: This study establishes the global well-posedness of the compressible
non-isentropic Navier-Stokes/Allen-Cahn system governed by the van der Waals
equation of state $p(\rho,\theta)=- a\rho^2+\frac{R\theta\rho}{1-b\rho}$ and
degenerate thermal conductivity $\kappa(\theta)=\tilde{\kappa}\theta^\beta$,
where $p$, $\rho$ and $\theta$ are the pressure, the density and the
temperature of the flow respectively, and $a,b,R,\tilde\kappa$ are positive
constants related to the physical properties of the flow.
Navier-Stokes/Allen-Cahn system models immiscible two-phase flow with diffusive
interfaces, where the non-monotonic pressure-density relationship in the van
der Waals equation drives gas-liquid phase transitions. By developing a refined
$L^2$-energy framework, we prove the existence and uniqueness of global strong
solutions to the one-dimensional Cauchy problem for non-vacuum and
finite-temperature initial data, without imposing smallness restrictions on the
initial conditions. The findings demonstrate that despite non-monotonic
pressure inducing substantial density fluctuations and triggering phase
transitions, all physical quantities remain bounded over finite time intervals.

</details>


### [23] [Shape sensitivity analysis of the heat equation and the Dirichlet-to-Neumann map](https://arxiv.org/abs/2506.21196)
*Matteo Dalla Riva,Paolo Luzzini,Paolo Musolino*

Main category: math.AP

TL;DR: The paper analyzes the smoothness of solutions and their normal derivatives for a heat equation in a domain with a variable inner boundary, motivated by an inverse problem.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by an application to an inverse problem, where understanding the relationship between the shape parameter and the solution's behavior is crucial.

Method: The authors analyze the Dirichlet problem for the heat equation in a domain with a fixed outer boundary and a variable inner boundary defined by a diffeomorphism. They study the smoothness of the solution and its normal derivative with respect to the shape parameter.

Result: The paper proves that both the solution and its normal derivative are smooth with respect to the shape parameter. Additionally, the differential of the normal derivative on the exterior boundary is computed.

Conclusion: The results provide insights into the smooth dependence of solutions on geometric parameters, which is valuable for applications like inverse problems.

Abstract: We study a Dirichlet problem for the heat equation in a domain containing an
interior hole. The domain has a fixed outer boundary and a variable inner
boundary determined by a diffeomorphism $\phi$. We analyze the maps that assign
to the infinite-dimensional shape parameter $\phi$ the corresponding solution
and its normal derivative, and we prove that both are smooth. Motivated by an
application to an inverse problem, we then compute the differential with
respect to $\phi$ of the normal derivative of the solution on the exterior
boundary.

</details>


### [24] [Solving Mean-Field Games with Monotonicity Methods in Banach Spaces?](https://arxiv.org/abs/2506.21212)
*Rita Ferreira,Diogo Gomes,Melih Ucer*

Main category: math.AP

TL;DR: A unified framework for proving solutions to stationary first-order mean-field games (MFGs) using monotone operators in Banach spaces, yielding strong solutions with low-order regularization.


<details>
  <summary>Details</summary>
Motivation: Overcome limitations of prior Hilbert-space approaches that relied on high-order regularization and produced weak solutions.

Method: Use low-order regularization (p-Laplacian term) and infimal convolution for Hamiltonians to restore coercivity and derive solutions.

Result: Existence of strong solutions for models with power-growth and singular congestion, and weak solutions for minimal-growth Hamiltonians.

Conclusion: The Banach-space framework unifies and extends earlier results, offering a direct theoretical path and suitability for modern numerical algorithms.

Abstract: This paper develops a unified framework for proving the existence of
solutions to stationary first-order mean-field games (MFGs) based on the theory
of monotone operators in Banach spaces. We cast the coupled MFG system as a
variational inequality, overcoming the limitations of prior Hilbert-space
approaches that relied on high-order regularization and typically yielded only
weak solutions in the monotone operator sense. In contrast, with our low-order
regularization, we obtain strong solutions.
  Our approach addresses the non-coercivity of the underlying MFG operator
through two key regularization strategies. First, by adding a low-order
$p$-Laplacian term, we restore coercivity, derive uniform a priori estimates,
and pass to the limit via Minty's method. This establishes, for the first time
via monotonicity methods, the existence of strong solutions for models with
both standard power-growth and singular congestion, with the latter requiring a
careful restriction of the operator's domain. Second, for Hamiltonians with
only minimal growth hypotheses, we regularize the Hamiltonian itself via
infimal convolution to prove the existence of weak solutions.
  Our Banach-space framework unifies and extends earlier existence results. By
avoiding high-order smoothing, it not only provides a more direct theoretical
path but is also ideally suited for modern numerical algorithms.

</details>


### [25] [Determination of the potential by a fixed angle scattering data](https://arxiv.org/abs/2506.21251)
*Suliang Si*

Main category: math.AP

TL;DR: A compactly supported potential is uniquely determined by far field data at a fixed angle using a new Carleman estimate.


<details>
  <summary>Details</summary>
Motivation: To address the inverse problem of determining a potential from far field measurements.

Method: Uses a new Carleman estimate and techniques from Bukhgeim and Klibanov.

Result: The potential is uniquely identifiable from far field data at a fixed angle.

Conclusion: The method provides a unique solution for the inverse problem using far field patterns.

Abstract: In this paper, we show that a compactly supported potential is uniquely
determined by the far field pattern at a fixed angle. Our method is based on a
new Carleman estimate and the ideas introduced by Bukhgeim and Klibanov on the
use of Carleman estimates for inverse problems.

</details>


### [26] [Asymptotic stability of solutions to semilinear evolution equations in Banach spaces](https://arxiv.org/abs/2506.21437)
*Francesco Cellarosi,Anirban Dutta,Giusy Mazzone*

Main category: math.AP

TL;DR: The paper presents a linearization principle for nonlinear stability in semilinear parabolic evolution equations, proving global solutions near equilibria converge exponentially to steady states. Applied to fluid-filled heavy solids, weak solutions converge exponentially to equilibrium.


<details>
  <summary>Details</summary>
Motivation: To establish conditions under which solutions to semilinear parabolic equations converge to equilibria, extending stability analysis to broader settings.

Method: Assumes equilibria form a finite-dimensional manifold with normal stability/hyperbolicity. Uses analytic semigroup theory for linearized operators.

Result: Global solutions near equilibria converge exponentially to steady states. Applied to fluid-solid systems, weak solutions converge to equilibrium.

Conclusion: The abstract framework ensures exponential convergence to equilibria, validated in fluid-solid dynamics.

Abstract: We prove a new linearization principle for the nonlinear stability of
solutions to semilinear evolution equations of parabolic type. We assume that
the set of equilibria forms a finite dimensional manifold of normally stable
and normally hyperbolic equilibria. In addition, we assume that the linearized
operator is the generator of an analytic semigroup (not necessarily stable). We
show that if a mild solution to our evolution equation exists globally in time
and remains ``close'' to the manifold of equilibria at all times, then the
solution must eventually converge to an equilibrium point at an exponential
rate.
  We apply our abstract results to the equations governing the motion of a
fluid-filled heavy solid. Under general assumptions on the physical
configuration and initial conditions, we show that weak solutions to the
governing equations eventually converge to a steady state with an exponential
rate. In particular, the fluid velocity relative to the solid converges to zero
as $t\to\infty$ in $H^{2\alpha}_p(\Omega)$ for each $p\in [1,\infty)$ and
$\alpha\in [0,1)$ as well as in $H^{2}_2(\Omega)$.

</details>


### [27] [A priori estimates of stable solutions of the general Hardy-Henon equation in the ball](https://arxiv.org/abs/2506.21515)
*J. Silverio Martinez-Baena,Salvador Villegas*

Main category: math.AP

TL;DR: Study of semi-stable radial solutions for a PDE with nonlinearity, focusing on boundedness and pointwise estimates in specific dimensions.


<details>
  <summary>Details</summary>
Motivation: To analyze the behavior of semi-stable radial solutions in a PDE with a general nonlinearity, particularly in varying dimensions.

Method: Examines solutions in the unit ball, using functional analysis and PDE techniques to derive boundedness and pointwise estimates.

Result: Proves boundedness for dimensions 2≤N<10+4α and sharp pointwise estimates for N≥10+4α. Also identifies unbounded solutions.

Conclusion: The study provides insights into the behavior of semi-stable solutions, with explicit bounds and unbounded examples for certain dimensions.

Abstract: This paper is devoted to the study of semi-stable radial solutions $u\in
H^1(B_1)$ of $-\Delta u=\vert x\vert^\alpha f(u) \mbox{ in }
B_1\setminus\lbrace0\rbrace$, where $f\in C^1(\mathbb{R})$ is a general
nonlinearity, $\alpha>-2$ and $B_1$ is the unit ball of $\mathbb{R}^N$, $N>1$.
We establish the boudness of such solutions for dimensions $2\leq N<10+4\alpha$
and sharp pointwise estimates in the case $N\geq10+4\alpha$. In addition, we
provide, for this range of dimensions, a large family of semi-stable radially
decreasing unbounded $H^1(B_1)$ solutions.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [28] [On the rank-reduced relativistic coupled cluster method](https://arxiv.org/abs/2506.21133)
*Alexander V. Oleynichenko,Artem S. Rumiantsev,Andrei Zaitsevskii,Ephraim Eliav*

Main category: physics.comp-ph

TL;DR: The study explores Tucker decomposition in relativistic CCSD for efficient correlation energy estimates, achieving 1 kJ/mol accuracy with high compression rates.


<details>
  <summary>Details</summary>
Motivation: To improve computational efficiency and accuracy in relativistic CCSD for systems with heavy atoms.

Method: Tucker decomposition of amplitude tensors in RCCSD, tested on (AuCl)$_n$, Au$_n$, and YbCl$_2$ models.

Result: Achieved 1 kJ/mol accuracy with high compression; only ~3% of doubles amplitudes were significant in YbCl$_7$.

Conclusion: Rank reduction in relativistic CCSD is feasible, promising for large systems with heavy atoms, with preference for Goldstone diagrams.

Abstract: An efficiency of the Tucker decomposition of amplitude tensors within the
single-reference relativistic coupled cluster method with single and double
excitations (RCCSD) was studied in a series of benchmark calculations for
(AuCl)$_n$ chains, Au$_n$ clusters, and the cluster model of solid YbCl$_2$.
The 1 kJ/mol level of accuracy for correlation energy estimates of
moderate-size systems and typical reaction energies can be achieved with
relatively high compression rates of amplitude tensors via rejecting singular
values smaller than $\sim 10^{-4}$. For the most extensive system studied
(YbCl$_7$ cluster used for modeling of ytterbium center in ytterbium dichloride
crystal), only $\sim 3$% of compressed doubles amplitudes were shown to be
significant. Thus, the rank reduction for the relativistic CCSD theory
improving its computational scaling is feasible. The advantage (if not
necessity) of using the Goldstone diagrammatic technique rather than the
"antisymmetrized" Brandow one is underlined. The proposed approach is promising
for high-precision modeling of relatively large systems with heavy atoms.

</details>


### [29] [Anharmonic phonons via quantum thermal bath simulations](https://arxiv.org/abs/2506.21139)
*Taylor Baird,Rodolphe Vuilleumier,Sara Bonella*

Main category: physics.comp-ph

TL;DR: A novel method combines quantum correlators and quantum thermal bath (QTB) to efficiently compute phonon dispersion relations, addressing anharmonic and nuclear quantum effects (NQEs) with reduced computational cost.


<details>
  <summary>Details</summary>
Motivation: Accurate simulation of phonon characteristics in materials with light ions or extreme conditions (low temps/high pressures) is computationally expensive due to anharmonic and NQEs.

Method: Uses quantum correlators for anharmonic phonon frequencies and QTB for NQEs, tested on 1D systems and solid neon.

Result: Demonstrates efficient and accurate phonon dispersion calculations, highlighting the method's potential.

Conclusion: The approach effectively balances computational cost and accuracy, though further exploration of its limitations is needed.

Abstract: Lattice vibrations within crystalline solids, or phonons, provide information
on a variety of important material characteristics, from thermal qualities to
optical properties and phase transition behaviour. When the material contains
light ions, or is subjected to sufficiently low temperatures and/or high
pressures, anharmonic and nuclear quantum effects (NQEs) may significantly
alter its phonon characteristics. Unfortunately, accurate inclusion of these
two effects within numerical simulations typically incurs a substantial
computational cost. In this work, we present a novel approach which promises to
mitigate this problem. The scheme leverages the recently introduced quantum
correlators approach for the extraction of anharmonic phonon frequencies from
molecular dynamics data. To account for NQEs without excessive increase of the
computational cost, we include nuclear quantum effects via the quantum thermal
bath (QTB) method. This is the first full exploration of the use of QTB for the
calculation of phonon dispersion relations. We demonstrate the noteworthy
efficiency and accuracy of the scheme, and analyze its upsides and drawbacks by
first considering 1-dimensional systems, and then the physically interesting
case of solid neon.

</details>


### [30] [Benchmarking and Parallelization of Electrostatic Particle-In-Cell for low-temperature Plasma Simulation by particle-thread Binding](https://arxiv.org/abs/2506.21524)
*Libn Varghese,Bhaskar Chaudhury,Miral Shah,Mainak Bandyopadhyay*

Main category: physics.comp-ph

TL;DR: A novel particle-thread binding strategy improves Charge Deposition (CD) scalability in PIC simulations by reducing private grid requirements, enhancing performance without major code changes.


<details>
  <summary>Details</summary>
Motivation: High computational costs and scalability issues in 2D/3D PIC simulations, especially with CD as a bottleneck, drive the need for efficient parallelization.

Method: Proposes a particle-thread binding strategy requiring only four private grids per node (distributed) or system (shared), ensuring grid accessibility and avoiding particle access conflicts.

Result: Demonstrates scalability on shared and distributed memory systems (1000 cores) with minimal hardware dependency.

Conclusion: The method effectively addresses CD scalability while maintaining conventional PIC structures and requiring minimal code modifications.

Abstract: The Particle-In-Cell (PIC) method for plasma simulation tracks particle phase
space information using particle and grid data structures. High computational
costs in 2D and 3D device-scale PIC simulations necessitate parallelization,
with the Charge Deposition (CD) subroutine often becoming a bottleneck due to
frequent particle-grid interactions. Conventional methods mitigate dependencies
by generating private grids for each core, but this approach faces scalability
issues. We propose a novel approach based on a particle-thread binding strategy
that requires only four private grids per node in distributed memory systems or
four private grids in shared memory systems, enhancing CD scalability and
performance while maintaining conventional data structures and requiring
minimal changes to existing PIC codes. This method ensures complete
accessibility of grid data structure for concurrent threads and avoids
simultaneous access to particles within the same cell using additional
functions and flags. Performance evaluations using a PIC benchmark for
low-temperature partially magnetized E x B discharge simulation on a shared
memory as well as a distributed memory system (1000 cores) demonstrate the
method's scalability, and additionally, we show the method has little hardware
dependency.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [31] [Control of pedestal-top electron density using RMP and gas puff at KSTAR](https://arxiv.org/abs/2506.20700)
*Minseok Kim,S. K. Kim,A. Rothstein,P. Steiner,K. Erickson,Y. H. Lee,H. Han,Sang-hee Hahn,J. W. Juhn,B. Kim,R. Shousha,C. S. Byun,J. Butt,ChangMin Shin,J. Hwang,Minsoo Cha,Hiro Farre,S. M. Yang,Q. Hu,D. Eldon,N. C. Logan,A. Jalalvand,E. Kolemen*

Main category: physics.plasm-ph

TL;DR: The paper presents a real-time controller for pedestal-top electron density in KSTAR experiments, using resonant magnetic perturbation and gas puff, achieving high accuracy with median errors of 1.5%.


<details>
  <summary>Details</summary>
Motivation: To dynamically control electron density in fusion experiments for scenario exploration and stability.

Method: Uses a multi-layer perceptron for fast density reconstruction and a proportional-integration controller with gains from system identification.

Result: Controller achieves median error of 1.5% and can lower density via pump-out under RMP, outperforming single-actuator methods.

Conclusion: The controller enables dynamic density target setting and stable discharge maintenance, enhancing experimental flexibility.

Abstract: We report the experimental results of controlling the pedestal-top electron
density by applying resonant magnetic perturbation with the in-vessel control
coils and the main gas puff in the 2024-2025 KSTAR experimental campaign. The
density is reconstructed using a parametrized psi_N grid and the five channels
of the line-averaged density measured by a two-colored interferometer. The
reconstruction procedure is accelerated by deploying a multi-layer perceptron
to run in about 120 microseconds and is fast enough for real-time control. A
proportional-integration controller is adopted, with the controller gains being
estimated from the system identification processes. The experimental results
show that the developed controller can follow a dynamic target while
exclusively using both actuators. The absolute percentage errors between the
electron density at psi_N=0.89 and the target are approximately 1.5% median and
a 2.5% average value. The developed controller can even lower the density by
using the pump-out mechanism under RMP, and it can follow a more dynamic target
than a single actuator controller. The developed controller will enable
experimental scenario exploration within a shot by dynamically setting the
density target or maintaining a constant electron density within a discharge.

</details>


### [32] [Global properties and stability of transonic plasma acceleration in the magnetic nozzle](https://arxiv.org/abs/2506.20880)
*N. Sheth,A. Smolyakov,J. Deguire,S. Pande,P. N. Yushmanov*

Main category: physics.plasm-ph

TL;DR: The paper demonstrates that transonic plasma acceleration in a magnetic nozzle follows a unique global solution defined by the magnetic field, validated by MHD simulations.


<details>
  <summary>Details</summary>
Motivation: To validate the analytical solution for transonic plasma acceleration in a magnetic nozzle and explore its applicability under varying conditions.

Method: Comparison of the analytical solution with axisymmetric 2D MHD simulations, testing different nozzle lengths, boundary values, and initial magnetic fields.

Result: The analytical solution matches simulations near the axis and adjusts for arbitrary magnetic surfaces. Shock-like transitions ensure the flow adopts the unique transonic profile.

Conclusion: The study confirms the robustness of the analytical solution and its adaptability to modified magnetic fields, supporting its broader applicability.

Abstract: It is shown that transonic plasma acceleration in the converging-diverging
magnetic field (magnetic nozzle) follows the unique global solution which is
fully defined by the magnetic field. Such solution, which was analytically
obtained earlier in the paraxial approximation, is compared here with results
of the axisymmetric two-dimensional (rz) magnetohydrodynamics(MHD) simulations.
It is shown that analytical solution describes well the region near the axis
but also can be applied to arbitrary magnetic surfaces. The simulations with
different length of the nozzle and different boundary values for plasma
velocity show that the plasma flow switches to the unique transonic
acceleration profile via the shock-like transition in the velocity and pressure
profiles. The simulations with arbitrary (not vacuum) initial magnetic field
demonstrate the global adjustment of the magnetic field such that the transonic
acceleration velocity profile follows the analytic predictions with the
modified magnetic field.

</details>


### [33] [Nonlinear edge localized mode with impurity seeding in CFETR hybrid scenario](https://arxiv.org/abs/2506.20892)
*Shiyong Zeng,Ping Zhu*

Main category: physics.plasm-ph

TL;DR: The paper investigates ELM mitigation via impurity seeding, revealing its impact on pedestal pressure and ELM crash dynamics through MHD simulations.


<details>
  <summary>Details</summary>
Motivation: Understanding the physics behind ELM mitigation by impurity seeding to improve fusion plasma operation.

Method: Nonlinear MHD simulations to study ELM crash triggers and impurity seeding effects.

Result: Impurity seeding modifies pedestal pressure, triggering high-n ballooning instabilities, with impurity density and seeding location as key control parameters.

Conclusion: Impurity seeding's role in ELM dynamics is clarified, aiding future fusion plasma control strategies.

Abstract: A critical challenge for operating fusion burning plasma in high confinement
mode lies in mitigating damage caused by edge localized modes (ELMs). While
impurity seeding has been experimentally validated as a reliable and effective
ELM mitigation technique, its underlying physics remains insufficiently
understood and requires further clarification. Through nonlinear
magnetohydrodynamic (MHD) simulations, this work reproduces key features of
natural ELM crash and reveals its trigger mechanism. Impurity seeding
significantly affects nonlinear ELM dynamics by inducing local and global
modifications to the pedestal pressure profile, driving high-n ballooning mode
instabilities that govern ELM crash. Two critical control parameters --
impurity density level and poloidal seeding location -- are systematically
investigated, which play key roles in the ELM crash onset timing and the
resulting energy loss magnitude.

</details>


### [34] [Observation of Enhanced Core Impurity Transport in a Turbulence-Reduced Stellarator Plasma](https://arxiv.org/abs/2506.21141)
*Daniel Medina-Roque,Isabel García-Cortés,Naoki Tamura,Kieran J. McCarthy,Federico Nespoli,Kenji Tanaka,Mamoru Shoji,Suguru Masuzaki,Hisamichi Funaba,Chihiro Suzuki,Albert Mollen,Robert Lunsford,Katsumi Ida,Mikiro Yoshinuma,Motoshi Goto,Yasuko Kawamoto,Tomoko Kawate,Tokihiko Tokuzawa,Ichihiro Yamada*

Main category: physics.plasm-ph

TL;DR: Continuous lithium granule injection in high-density stellarator plasmas improves energy confinement by reducing turbulence but increases mid- and high-Z impurity transport. Simulations show neoclassical transport dominates for main plasma components, while classical transport is key for high-Z impurities.


<details>
  <summary>Details</summary>
Motivation: To investigate the impact of continuous lithium granule injection on plasma confinement and impurity transport in high-density stellarator plasmas.

Method: Experimental observation combined with simulations using the drift-kinetic transport code SFINCS.

Result: Improved energy confinement due to reduced turbulence, but increased transport of mid- and high-Z impurities. Classical transport dominates for high-Z impurities.

Conclusion: Classical transport plays a crucial role in enhancing high-Z impurity transport in high-density stellarator plasmas with lithium granule injection.

Abstract: An enhancement of core impurity transport is observed for the first time in a
high-density stellarator plasma with continuous lithium (Li) granule injection.
When Li-granules are dropped continuously into the plasma, energy confinement
is improved due to reduced turbulence. In parallel, the transport of mid- and
high-Z impurities is increased. Simulations with the drift-kinetic transport
code SFINCS for such plasmas show that the role of neoclassical transport
prevails for the main plasma components (electrons, ions, and Zavg = 3.5). In
contrast, the classical contribution is dominant in transporting high-Z
impurities. This study demonstrates experimentally, for the first time also,
that classical transport plays an essential role in enhancing the transport of
such impurities in high-density stellarator plasmas, a situation that is
achieved by continuous injection of Li-granules, which is effective for
real-time wall conditioning and plasma performance improvement

</details>


### [35] [Relativistic Oscillating Window Driven by an Intense Laguerre Gaussian Laser Pulse](https://arxiv.org/abs/2506.21407)
*Yao Meng,Runze Li,Longqing Yi*

Main category: physics.plasm-ph

TL;DR: Study of high-order harmonic generation via diffraction of an intense Laguerre-Gaussian laser beam through a small aperture, revealing complex spin-orbital angular momentum interplay and distinct selection rules.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of light in nonlinear optics and enable high-intensity UV/X-ray pulses with controllable orbital angular momentum (OAM) for scientific applications.

Method: Analyzed 2D peripheral electron dynamics on the rim of a small aperture, derived a theory, and validated it with simulations.

Result: For linearly polarized drivers, harmonic beams exhibit multiple Laguerre-Gaussian modes with topological charges equal to the harmonic order, breaking simple OAM conservation.

Conclusion: The study advances nonlinear optics by providing insights into OAM manipulation and enabling versatile tools for scientific research.

Abstract: High-order harmonic generation by the diffraction of an intense
Laguerre-Gaussian (LG) laser beam through a small aperture is studied. It is
found that the 2D peripheral electron dynamics on the rim can facilitate
complex interplay between the spin and orbital angular momentum interaction,
which leads to distinct selection rules for LG pulses with different
polarization states. In particular, when the driver is linearly polarized, the
harmonic beams no longer follow a simple orbital angular momentum conservation
rule. Instead, multiple LG modes with different topological charges are
produced in each harmonic beam, and the number of modes equals to the harmonic
order. A theory is derived and validated by simulations, which can predict the
harmonic topological charges as well as their relative intensities for LG
drivers with different polarization states. Our work provides fundamental
insight into the behavior of light in nonlinear optics, and paves the way
towards high-intensity UV or X-ray pulses carrying controllable OAM, that can
serve as versatile tools at frontiers of various scientific fields.

</details>


### [36] [Excitation of Giant Surface Waves During Laser Wake Field Acceleration](https://arxiv.org/abs/2506.21503)
*Travis Garrett,Christopher Pieronek,E. Rockafellow,Oliver Sale,Sahir Virani,J. E. Shrock,B. Miao,A. Sloss,Jennifer Elle,H. M. Milchberg*

Main category: physics.plasm-ph

TL;DR: Detection of intense surface waves during plasma waveguided laser wakefield acceleration, revealing strong RF radiation and multi-MeV electron ejection.


<details>
  <summary>Details</summary>
Motivation: To understand the excitation of high-intensity surface waves and their impact on wakefield acceleration and RF radiation.

Method: Combined laboratory measurements, particle-in-cell simulations, and analytic approximations to analyze the phenomenon.

Result: A 20 J laser pulse excites a 1 Joule, 400 GW broadband THz surface wave with a peak electric field of 35 GV/m.

Conclusion: The study highlights the generation of intense surface waves and their implications for laser wakefield acceleration and RF radiation.

Abstract: We have detected the presence of very high intensity surface waves that are
excited during plasma waveguided laser wakefield acceleration. Wakefield
acceleration can be enchanced by the introduction of an ``all optical" plasma
waveguide that confines and guides a laser pulse at the optimal intensity over
long distances, producing quasimonoenergetic multi-GeV electron bunches.
However strong pulses of radio frequency radiation (RF) are also produced, and
particle in cell simulations show why: a continuous stream of multi-MeV
electrons are also ejected radially from the plasma due to nonlinear wave
breaking, and these excite and copropagate coherently with a giant cylindrical
Sommerfeld surface wave. Laboratory measurements, simulations, and analytic
approximations all converge on a 20 J laser pulse exciting a 1 Joule, 400 GW
broadband THz surface wave, with a peak electric field strength of 35 GV/m.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [37] [Linear stability of Kerr black holes in the full subextremal range](https://arxiv.org/abs/2506.21183)
*Dietrich Häfner,Peter Hintz,András Vasy*

Main category: gr-qc

TL;DR: The paper proves the linear stability of the Kerr family in the full subextremal range unconditionally, building on prior work and incorporating additional results.


<details>
  <summary>Details</summary>
Motivation: To extend the understanding of the stability of the Kerr family beyond the slowly rotating case, addressing the full subextremal range.

Method: The proof leverages prior analytic methods, mode stability results by Andersson, Whiting, and the first author, and zero energy behavior computations by the second author.

Result: Unconditional linear stability of the Kerr family in the full subextremal range is established.

Conclusion: The work successfully extends stability results for the Kerr family, combining existing techniques with new insights.

Abstract: We prove, unconditionally, the linear stability of the Kerr family in the
full subextremal range. On an analytic level, our proof is the same as that of
our earlier paper in the slowly rotating case. The additional ingredients we
use are, firstly, the mode stability result proved by Andersson, Whiting, and
the first author and, secondly, computations related to the zero energy
behavior of the linearized gauge-fixed Einstein equation in work by the second
author.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [38] [Hamiltonian formulation of the quasineutral Vlasov-Poisson system](https://arxiv.org/abs/2506.21415)
*J. W. Burby*

Main category: math-ph

TL;DR: The paper derives a Hamiltonian formulation for a quasineutral limit of the Vlasov-Poisson system using slow manifold reduction and Poisson-Dirac submanifolds, modeling plasma dynamics without fast Langmuir oscillations.


<details>
  <summary>Details</summary>
Motivation: To provide a Hamiltonian structure for the quasineutral limit of the Vlasov-Poisson system, capturing plasma dynamics while eliminating fast oscillations.

Method: Uses slow manifold reduction and Poisson-Dirac submanifold theory to derive the Hamiltonian formulation.

Result: The quasineutral model preserves incompressible bulk plasma flow and synthesizes known Poisson brackets for incompressible fluids and kinetic equations.

Conclusion: The Hamiltonian structure successfully models quasineutral plasma dynamics, combining fluid and kinetic theory elements.

Abstract: Slow manifold reduction and the theory of Poisson-Dirac submanifolds are used
to deduce a Hamiltonian formulation for a quasineutral limit of the planar,
collisionless, magnetized Vlasov-Poisson system. Motion on the slow manifold
models plasma dynamics free of fast Langmuir oscillations. Preservation of
quasineutrality requires the bulk plasma flow is incompressible. The electric
field is determined by counterbalancing plasma stresses that would otherwise
produce compression. The Hamiltonian structure for the quasineutral model
synthesizes well-known Poisson brackets for incompressible fluids and
collisionless kinetic equations.

</details>


### [39] [Asymmetry of curl eigenfields solving Woltjer's variational problem](https://arxiv.org/abs/2506.21243)
*Daniel Peralta-Salas,David Perrella,David Pfefferlé*

Main category: math-ph

TL;DR: The paper disproves the common belief that eigenfields of the lowest curl eigenvalue must be symmetric in rotationally symmetric domains, showing some cases where they are not.


<details>
  <summary>Details</summary>
Motivation: To challenge the assumption that symmetry in domains guarantees symmetry in eigenfields of the first Ampèrian curl eigenvalue.

Method: Constructing families of rotationally symmetric toroidal domains in ℝ³ and analyzing their eigenfields.

Result: Found cases where eigenfields are symmetric and others where they are not, disproving the folk wisdom.

Conclusion: Minimizers of Woltjer's variational principle need not inherit the domain's rotational symmetry.

Abstract: We construct families of rotationally symmetric toroidal domains in $\mathbb
R^3$ for which the eigenfields associated to the first (positive) Amp\`erian
curl eigenvalue are symmetric, and others for which no first eigenfield is
symmetric. This implies, in particular, that minimizers of the celebrated
Woltjer's variational principle do not need to inherit the rotational symmetry
of the domain. This disproves the folk wisdom that the eigenfields
corresponding to the lowest curl eigenvalue must be symmetric if the domain is.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [40] [Anisotropy-Induced Magnetic Field Generation in Bidimensional Materials](https://arxiv.org/abs/2506.21464)
*Diogo Simões,Hugo Terças,Jorge Ferreira*

Main category: cond-mat.mtrl-sci

TL;DR: Study of electromagnetic instability in 2D materials due to Fermi surface anisotropy, analyzing growth rates and magnetic field generation.


<details>
  <summary>Details</summary>
Motivation: To understand how anisotropy in Fermi surfaces leads to electromagnetic instabilities in 2D materials.

Method: Used a kinetic model considering temperature, chemical potential, anisotropy ratio, and band structures (linear/quadratic). Derived growth rates in the linear regime and simulated non-linear behavior.

Result: Found wavenumber-dependent growth rates and confinement of unstable modes. Demonstrated structured magnetic field generation and saturation behavior.

Conclusion: Anisotropy in 2D materials induces electromagnetic instabilities, with distinct growth and saturation dynamics.

Abstract: We investigate an electromagnetic instability in two-dimensional materials
arising from an anisotropy of the Fermi surface, utilizing a kinetic model
accounting for the effects of the values of temperature, chemical potential and
anisotropy ratio, as well as considering both linear and quadratic low-energy
band structures. The wavenumber-dependent growth-rate of these modes is derived
in the linear regime, and their confinement, contrasting with stable
electromagnetic waves in these systems, is described. The generation of
structured out-of-plane magnetic fields, as well as their behaviour in
saturation, is shown using fully kinetic and non-linear simulations.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [41] [A generalised framework for phase field-based modelling of coupled problems: application to thermo-mechanical fracture, hydraulic fracture, hydrogen embrittlement and corrosion](https://arxiv.org/abs/2506.20763)
*Y. Navidtehrani,C. Betegón,E. Martínez-Pañeda*

Main category: cs.CE

TL;DR: A novel phase field and multi-physics approach for coupled structural integrity problems, demonstrated via Abaqus subroutines, shows strong agreement with experiments and existing solutions.


<details>
  <summary>Details</summary>
Motivation: To address coupled structural integrity problems with a versatile, generalised framework suitable for commercial finite element packages.

Method: Combines phase field and multi-physics modelling, leveraging the heat transfer equation, implemented via UMAT and UMATHT subroutines in Abaqus.

Result: Demonstrates excellent agreement with experimental data and existing solutions across four engineering problems.

Conclusion: The framework is effective and adaptable, with freely available subroutines for broader use.

Abstract: We present a novel, generalised formulation to treat coupled structural
integrity problems by combining phase field and multi-physics modelling. The
approach exploits the versatility of the heat transfer equation and is
therefore well suited to be adopted in commercial finite element packages,
requiring only integration point-level implementation. This aspect is
demonstrated here by implementing coupled, multi-variable phenomena through
simple \texttt{UMAT} and \texttt{UMATHT} subroutines in the finite element
package \texttt{Abaqus}. The generalised theoretical and computational
framework presented is particularised to four problems of engineering and
scientific relevance: thermo-mechanical fracture, hydraulic fracture,
hydrogen-assisted cracking and metallic corrosion. 2D and 3D problems are
considered. The results reveal a very good agreement with experimental data,
and existing numerical and analytical solutions.The user subroutines developed
are made freely available at https://mechmat.web.ox.ac.uk/codes.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [42] [Surrogate normal-forms for the numerical bifurcation and stability analysis of navier-stokes flows via machine learning](https://arxiv.org/abs/2506.21275)
*Alessandro Della Pia,Dimitrios G. Patsatzis,Gianluigi Rozza,Lucia Russo,Constantinos Siettos*

Main category: physics.flu-dyn

TL;DR: The paper presents a framework for constructing minimal-dimensional surrogate models from high-fidelity Navier-Stokes simulations using manifold learning and Gaussian Process Regression, enabling efficient bifurcation and stability analysis.


<details>
  <summary>Details</summary>
Motivation: To address the computational cost of analyzing high-dimensional spatio-temporal dynamics in Navier-Stokes simulations, the authors propose a reduced-order modeling approach inspired by Equation-Free multiscale modeling.

Method: The framework involves four steps: manifold learning to identify latent dimensions, constructing low-dimensional ROMs using GPR, applying bifurcation tools in latent space, and reconstructing results in the original space.

Result: The method successfully identifies latent dimensionality and constructs GPR-based surrogate models, enabling analysis of bifurcations (e.g., Andronov-Hopf and pitchfork) and stability in canonical flows like wake flow and sudden-expansion channel flow.

Conclusion: The framework efficiently enables bifurcation and stability analysis of high-dimensional systems by leveraging reduced-order modeling and machine learning techniques.

Abstract: Inspired by the Equation-Free multiscale modeling approach, we demonstrate
how the embed-learn-lift framework enables the construction of surrogate
normal-forms, namely minimal-dimensional reduced-order models (ROMs), from
high-fidelity Navier-Stokes simulations. These surrogate models are then used
for efficient and accurate bifurcation and stability analysis. The framework
proceeds in four steps. First, manifold learning reveals the intrinsic latent
dimension of the high-dimensional spatio-temporal Navier-Stokes dynamics across
parameter space. Second, we construct low-dimensional "normal-form" like ROMs
on this latent space using Gaussian Process Regression (GPR), capturing the
emergent dynamics. Third, using these models, we apply numerical bifurcation
tools to compute bifurcation diagrams and perform stability analysis in the
latent space. This includes tracing branches of limit cycles arising from
Andronov-Hopf bifurcations - tasks intractable in full space due to
computational cost. Finally, solving the pre-image problem allows
reconstruction of the bifurcation structure in the original high-dimensional
space. We demonstrate the methodology on two canonical flows: wake flow past an
infinite circular cylinder and planar sudden-expansion channel flow. These
exhibit Andronov-Hopf and pitchfork bifurcations, respectively, as Reynolds
number increases. Our method identifies the latent dimensionality and
constructs GPR-based surrogate normal-forms that enable the tracing and
stability analysis of bifurcating solutions, including limit cycles, their
period, and stability via Floquet multipliers.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [43] [Quantum Adaptive Search: A Hybrid Quantum-Classical Algorithm for Global Optimization of Multivariate Functions](https://arxiv.org/abs/2506.21124)
*G. Intoccia,U. Chirico,V. Schiano Di Cola,G. Pepe,S. Cuomo*

Main category: quant-ph

TL;DR: QAGS is a hybrid quantum-classical algorithm for global optimization, using quantum probability distributions to narrow search space and classical methods for refinement, outperforming classical methods in accuracy and complexity.


<details>
  <summary>Details</summary>
Motivation: To improve global optimization of multivariate functions by leveraging quantum computing for efficient search space reduction and classical methods for precise refinement.

Method: Combines quantum state encoding of solution quality with adaptive search space narrowing and classical local optimization.

Result: QAGS contracts search space toward global optima with controlled complexity, achieving higher accuracy and better time/space efficiency than classical methods.

Conclusion: QAGS is a promising hybrid approach for global optimization, offering superior performance and efficiency compared to classical techniques.

Abstract: This work presents Quantum Adaptive Search (QAGS), a hybrid quantum-classical
algorithm for the global optimization of multivariate functions. The method
employs an adaptive mechanism that dynamically narrows the search space based
on a quantum-estimated probability distribution of the objective function. A
quantum state encodes information about solution quality through an appropriate
complex amplitude mapping, enabling the identification of the most promising
regions, and thus progressively tightening the search bounds; then a classical
optimizer performs local refinement of the solution. The analysis demonstrates
that QAGS ensures a contraction of the search space toward global optima, with
controlled computational complexity. The numerical results on the benchmark
functions show that, compared to the classical methods, QAGS achieves higher
accuracy while offering advantages in both time and space complexity.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [44] [Stochastic and Non-local Closure Modeling for Nonlinear Dynamical Systems via Latent Score-based Generative Models](https://arxiv.org/abs/2506.20771)
*Xinghao Dong,Huchen Yang,Jin-Long Wu*

Main category: cs.LG

TL;DR: A latent score-based generative AI framework is proposed for learning stochastic, non-local closure models in nonlinear dynamical systems, addressing computational cost and scale separation challenges.


<details>
  <summary>Details</summary>
Motivation: To model complex multiscale dynamical systems without clear scale separation, where resolving all scales is computationally expensive, e.g., in turbulent flows.

Method: Joint training of convolutional autoencoders with conditional diffusion models in latent spaces to reduce dimensionality while preserving physical characteristics.

Result: The framework discovers a latent space ensuring small reconstruction errors and good diffusion model performance, achieving computational acceleration with comparable accuracy to standard diffusion models.

Conclusion: The proposed stochastic modeling framework via latent conditional diffusion models offers a computationally efficient solution for closure modeling in multiscale systems.

Abstract: We propose a latent score-based generative AI framework for learning
stochastic, non-local closure models and constitutive laws in nonlinear
dynamical systems of computational mechanics. This work addresses a key
challenge of modeling complex multiscale dynamical systems without a clear
scale separation, for which numerically resolving all scales is prohibitively
expensive, e.g., for engineering turbulent flows. While classical closure
modeling methods leverage domain knowledge to approximate subgrid-scale
phenomena, their deterministic and local assumptions can be too restrictive in
regimes lacking a clear scale separation. Recent developments of
diffusion-based stochastic models have shown promise in the context of closure
modeling, but their prohibitive computational inference cost limits practical
applications for many real-world applications. This work addresses this
limitation by jointly training convolutional autoencoders with conditional
diffusion models in the latent spaces, significantly reducing the
dimensionality of the sampling process while preserving essential physical
characteristics. Numerical results demonstrate that the joint training approach
helps discover a proper latent space that not only guarantees small
reconstruction errors but also ensures good performance of the diffusion model
in the latent space. When integrated into numerical simulations, the proposed
stochastic modeling framework via latent conditional diffusion models achieves
significant computational acceleration while maintaining comparable predictive
accuracy to standard diffusion models in physical spaces.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [45] [Correlated reaction coordinate motion produces non-additive rate enhancement for electron and energy transfer in multi-acceptor structures](https://arxiv.org/abs/2506.21504)
*Hanggai Nuomin,Feng-Feng Song,Peng Zhang,David N. Beratan*

Main category: physics.chem-ph

TL;DR: Multi-acceptor systems show quantum interference effects, leading to higher-than-expected electron transfer rates due to acceptor-acceptor interactions.


<details>
  <summary>Details</summary>
Motivation: To understand why multi-acceptor systems exhibit 4- to 5-fold increases in electron transfer rates, contrary to the expected factor of two.

Method: Analysis of coupling interactions in multi-acceptor systems, focusing on reaction free energy shifts, donor-acceptor coupling changes, and reaction-coordinate motion alterations.

Result: Acceptor-acceptor interactions explain the observed rate enhancements, revealing three key mechanisms: free energy shifts, coupling changes, and altered reaction-coordinate motion.

Conclusion: The findings provide insights into tailoring electron and energy transfer kinetics in molecular systems.

Abstract: Molecular structures with multiple donor, bridge, or acceptor units can
display quantum interference effects that influence electron and energy
transfer (ET and EnT) rates. Recent experiments found a 4- to 5-fold increase
in ET rates for donor-acceptor structures with two acceptors compared to one.
This result is surprising: simple classical or quantum analysis suggests a
factor of two rate enhancement. We analyze the coupling interactions in
multiple acceptor systems and find that rate enhancements beyond additive
effects arise from acceptor-acceptor interactions that: 1) shift the reaction
free energy, 2) change the donor-acceptor couplings, and 3) alter the
reaction-coordinate motion. Consideration of these effects explains the
observed rates in multi-acceptor systems and suggests strategies to tailor
energy and electron transfer kinetics.

</details>
