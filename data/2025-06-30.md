<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 9]
- [math.AP](#math.AP) [Total: 20]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [math.PR](#math.PR) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [math.OC](#math.OC) [Total: 3]
- [q-bio.PE](#q-bio.PE) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 3]
- [gr-qc](#gr-qc) [Total: 1]
- [nlin.PS](#nlin.PS) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Inverse scattering without phase: Carleman convexification and phase retrieval via the Wentzel--Kramers--Brillouin approximation](https://arxiv.org/abs/2506.21699)
*Thuy T. Le,Phuong M. Nguyen,Loc H. Nguyen*

Main category: math.NA

TL;DR: A robust numerical framework for reconstructing dielectric constants from phaseless backscattering data using phase retrieval, dimension reduction, and convexification.


<details>
  <summary>Details</summary>
Motivation: Addressing the ill-posedness and nonlinearity of phaseless inverse scattering problems in 3D Helmholtz equations.

Method: Combines WKB-based phase retrieval, Fourier dimension reduction, and Carleman convexification for stable solutions.

Result: Accurate recovery of scatterer geometry and contrast, even with high noise levels.

Conclusion: The proposed method is effective and robust for phaseless inverse scattering problems.

Abstract: This paper addresses the challenging and interesting inverse problem of
reconstructing the spatially varying dielectric constant of a medium from
phaseless backscattering measurements generated by single-point illumination.
The underlying mathematical model is governed by the three-dimensional
Helmholtz equation, and the available data consist solely of the magnitude of
the scattered wave field. To address the nonlinearity and severe ill-posedness
of this phaseless inverse scattering problem, we introduce a robust, globally
convergent numerical framework combining several key regularization strategies.
Our method first employs a phase retrieval step based on the
Wentzel--Kramers--Brillouin (WKB) ansatz, where the lost phase information is
reconstructed by solving a nonlinear optimization problem. Subsequently, we
implement a Fourier-based dimension reduction technique, transforming the
original problem into a more stable system of elliptic equations with Cauchy
boundary conditions. To solve this resulting system reliably, we apply the
Carleman convexification approach, constructing a strictly convex weighted cost
functional whose global minimizer provides an accurate approximation of the
true solution. Numerical simulations using synthetic data with high noise
levels demonstrate the effectiveness and robustness of the proposed method,
confirming its capability to accurately recover both the geometric location and
contrast of hidden scatterers.

</details>


### [2] [Genuinely multi-dimensional stationarity preserving global flux Finite Volume formulation for nonlinear hyperbolic PDEs](https://arxiv.org/abs/2506.21700)
*Wasilij Barsukow,Mirco Ciallella,Mario Ricchiuto,Davide Torlo*

Main category: math.NA

TL;DR: The paper introduces a general approach for stationarity preserving Finite Volume methods, improving performance over existing methods even on non-stationary solutions.


<details>
  <summary>Details</summary>
Motivation: Classical Finite Volume methods ignore multi-dimensional balance in stationary states, diffusing them away. This work aims to preserve such states.

Method: A multi-dimensional extension of the global flux approach is used to create stabilization terms that vanish at stationary states.

Result: The new methods outperform existing ones, including higher-order methods, even for non-stationary solutions.

Conclusion: The proposed approach effectively preserves multi-dimensional stationary states and enhances accuracy in Finite Volume methods.

Abstract: Classical Finite Volume methods for multi-dimensional problems include
stabilization (e.g. via a Riemann solver), that is derived by considering
several one-dimensional problems in different directions. Such methods
therefore ignore a possibly existing balance of contributions coming from
different directions, such as the one characterizing multi-dimensional
stationary states. Instead being preserved, they are usually diffused away by
such methods. Stationarity preserving methods use a better suited stabilization
term that vanishes at the stationary state, allowing the method to preserve it.
This work presents a general approach to stationarity preserving Finite Volume
methods for nonlinear conservation/balance laws. It is based on a
multi-dimensional extension of the global flux approach. The new methods are
shown to significantly outperform existing ones even if the latter are of
higher order of accuracy and even on non-stationary solutions.

</details>


### [3] [Optimizing Mixed Quantum Channels via Projected Gradient Dynamics](https://arxiv.org/abs/2506.21830)
*Matthew M. Lin,Bing-Ze Lu*

Main category: math.NA

TL;DR: The paper proposes a method to identify quantum channels using projected gradient dynamics, constrained to the Stiefel manifold and probabilistic simplex, with guaranteed convergence via Zariski topology.


<details>
  <summary>Details</summary>
Motivation: Designing mixed quantum channels is complex, requiring full characterization of input-output pairs. The work aims to simplify this by focusing on single input-output pairs.

Method: Uses projected gradient dynamics on the Stiefel manifold and probabilistic simplex to identify quantum channels. Numerical models validate the approach for multiple scenarios.

Result: The method efficiently identifies quantum channels, demonstrating flexibility and convergence in various scenarios.

Conclusion: The proposed approach is effective for characterizing quantum channels, offering a practical solution to a complex problem.

Abstract: Designing a mixed quantum channel is challenging due to the complexity of the
transformations and the probabilistic mixtures of more straightforward channels
involved. Fully characterizing a quantum channel generally requires preparing a
complete set of input states, such as a basis for the state space, and
measuring the corresponding output states. In this work, we begin by
investigating a single input-output pair using projected gradient dynamics.
This approach applies optimization flows constrained to the Stiefel manifold
and the probabilistic simplex to identify the original quantum channel. The
convergence of the flow is guaranteed by its relationship to the Zariski
topology. We present numerical investigations of models adapted to various
scenarios, including those with multiple input-output pairs, highlighting the
flexibility and efficiency of our proposed method.

</details>


### [4] [Semi Analytical Solution of a Nonlinear Oblique Boundary Value Problem](https://arxiv.org/abs/2506.21888)
*Mriganka Shekhar Chaki,Maria C. Jorge*

Main category: math.NA

TL;DR: A semi-analytical method using perturbation and the icosahedron method is developed to solve Laplace's equation with nonlinear oblique boundary conditions on a sphere's exterior, showing high precision and convergence.


<details>
  <summary>Details</summary>
Motivation: Existing functional analysis struggles with existence and uniqueness for nonlinear oblique boundary conditions, necessitating a new numerical approach.

Method: Perturbation around the monopole converts the problem into Neumann problems, solved using Green's function and adaptive quadrature with an icosahedron mesh.

Result: The method is precise, converges rapidly, and avoids inaccuracies, validated against exact solutions.

Conclusion: The icosahedron method effectively handles singularities and provides accurate approximations for nonlinear boundary conditions.

Abstract: A new numerical method is developed to approximate the solution of Laplace's
equation in the exterior of the sphere with a strongly nonlinear boundary value
of oblique type. A functional analysis attempt to solve this type of boundary
condition is not straight forward since results about existence and uniqueness
of solution are still limited. Hence, a semi analytical method is described
here to approach a solution. A perturbation solution around the monopole
converts the nonlinear oblique problem into a series of known Neumann problems
in the exterior of the sphere. The corresponding Green's function
representation for the exterior Neumann problem gives an exact analytic
solution for each perturbation step as an integral on the surface of the
sphere. Nevertheless, the boundary conditions become very complicated and
require to be approximated numerically. The perturbation solutions given by
integrals of the Green's function on the sphere are computed at each
perturbation step using different subdivisions of the surface integrals with
the help of adaptive quadrature method. We call icosahedron method to the
integration on the sphere with an icosahedron mesh using Gauss 5-point or
adaptive quadrature, according to the integration parameter. This method was
very effective to deal with the singularity of the Green's function
successfully avoiding inaccuracies on the numerical approximation and is an
important contribution of this work. The numerical perturbation scheme is
performed for two given exact solutions. The icosahedron method is found to be
very precise. The approximations show the desired properties: they get closer
to the exact solutions as the perturbation parameter gets smaller, show rapid
convergence in the exterior of the unit sphere and converge to zero as the
radius grows.

</details>


### [5] [StructMG: A Fast and Scalable Structured Algebraic Multigrid](https://arxiv.org/abs/2506.21932)
*Yi Zong,Peinan Yu,Haopeng Huang,Zhengding Hu,Xinliang Wang,Qin Wang,Chensong Zhang,Xiaowen Xu,Jian Sun,Yongxiao Zhou,Wei Xue*

Main category: math.NA

TL;DR: StructMG is a fast, scalable algebraic multigrid method for structured grids, outperforming existing methods in speed and efficiency.


<details>
  <summary>Details</summary>
Motivation: Current multigrid libraries lack satisfactory performance for structured grid problems in terms of speed and scalability.

Method: StructMG uses three principles from the 'multigrid seesaw' for efficient structured multigrid, employs stencil-based triple-matrix product for Galerkin coarsening, and a unified parallel framework for smoothers.

Result: StructMG achieves significant speedups (up to 15.5x) over existing methods like SMG, PFMG, SysPFMG, and BoomerAMG, with improved scaling efficiencies.

Conclusion: StructMG is highly effective for large-scale linear systems, offering low cost per iteration and good convergence, validated by real-world applications.

Abstract: Parallel multigrid is widely used as preconditioners in solving large-scale
sparse linear systems. However, the current multigrid library still needs more
satisfactory performance for structured grid problems regarding speed and
scalability. Based on the classical 'multigrid seesaw', we derive three
necessary principles for an efficient structured multigrid, which instructs our
design and implementation of StructMG, a fast and scalable algebraic multigrid
that constructs hierarchical grids automatically. As a preconditioner, StructMG
can achieve both low cost per iteration and good convergence when solving
large-scale linear systems with iterative methods in parallel. A stencil-based
triple-matrix product via symbolic derivation and code generation is proposed
for multi-dimensional Galerkin coarsening to reduce grid complexity, operator
complexity, and implementation effort. A unified parallel framework of sparse
triangular solver is presented to achieve fast convergence and high parallel
efficiency for smoothers, including dependence-preserving Gauss-Seidel and
incomplete LU methods. Idealized and real-world problems from radiation
hydrodynamics, petroleum reservoir simulation, numerical weather prediction,
and solid mechanics, are evaluated on ARM and X86 platforms to show StructMG's
effectiveness. In comparison to \textit{hypre}'s structured and general
multigrid preconditioners, StructMG achieves the fastest time-to-solutions in
all cases with average speedups of 15.5x, 5.5x, 6.7x, 7.3x over SMG, PFMG,
SysPFMG, and BoomerAMG, respectively. StructMG also significantly improves
strong and weak scaling efficiencies.

</details>


### [6] [Computing rough solutions of the KdV equation below ${\bf L^2}$](https://arxiv.org/abs/2506.21969)
*Jiachuan Cao,Buyang Li,Yifei Wu,Fangyan Yao*

Main category: math.NA

TL;DR: A novel framework for solving the KdV equation in negative Sobolev spaces, overcoming limitations of classical methods with a new numerical scheme and analytical approach.


<details>
  <summary>Details</summary>
Motivation: Classical numerical methods fail in negative Sobolev spaces due to high regularity requirements and poor control of nonlinear interactions.

Method: Combines continuous reformulation, Bourgain-space estimates, and rescaling to bridge numerical analysis and theoretical well-posedness.

Result: Proves nearly optimal-order convergence in $H^{-1/2}$ norm for initial data in $H^s$ ($-1/2 < s \leq 0$), unachievable by existing methods.

Conclusion: First numerical method capable of solving KdV in negative Sobolev spaces, advancing both numerical and theoretical understanding.

Abstract: We establish a novel numerical and analytical framework for solving the
Korteweg--de Vries (KdV) equation in the negative Sobolev spaces, where
classical numerical methods fail due to their reliance on high regularity and
inability to control nonlinear interactions at low regularities. Numerical
analysis is established by combining a continuous reformulation of the
numerical scheme, the Bourgain-space estimates for the continuous
reformulation, and a rescaling strategy that reduces the reformulated problem
to a small initial value problem, which allow us to bridge a critical gap
between numerical analysis and theoretical well-posedness by designing the
first numerical method capable of solving the KdV equation in the negative
Sobolev spaces. The numerical scheme is proved to have nearly optimal-order
convergence with respect to the spatial degrees of freedom in the
$H^{-\frac{1}{2}}$ norm for initial data in $H^s$, with $-\frac{1}{2} < s \leq
0$, a result unattainable by existing numerical methods.

</details>


### [7] [Do locking-free finite element schemes lock for holey Reissner-Mindlin plates with mixed boundary conditions?](https://arxiv.org/abs/2506.21999)
*Mark Ainsworth,Charles Parker*

Main category: math.NA

TL;DR: Analysis of finite element discretizations for Reissner-Mindlin plates on non-simply connected domains, ensuring locking-free, optimal convergence rates.


<details>
  <summary>Details</summary>
Motivation: To address challenges in finite element methods for plates with holes or mixed boundary conditions, ensuring robustness and accuracy.

Method: Guided by the de Rham complex, conditions for locking-free schemes are developed, extending to clamped and simply supported plates.

Result: Existing popular schemes often meet the new conditions, proving their locking-free performance.

Conclusion: The study validates many current methods while highlighting new conditions for robustness in complex domains.

Abstract: We revisit finite element discretizations of the Reissner-Mindlin plate in
the case of non-simply connected (holey) domains with mixed boundary
conditions. Guided by the de Rham complex, we develop conditions under which
schemes deliver locking-free, optimal rates of convergence. We naturally
recover the typical assumptions arising for clamped, simply supported plates.
More importantly, we also see new conditions arise naturally from the presence
of holes in the domain or in the case of mixed boundary conditions. We show
that, fortunately, many of the existing popularly used schemes do, in fact,
satisfy all of the conditions, and thus are locking-free.

</details>


### [8] [Scalable inference of large-scale random kronecker graphs via tensor decomposition and Einstein summation](https://arxiv.org/abs/2506.22292)
*Sanaa Khobizy*

Main category: math.NA

TL;DR: Extends random Kronecker graphs to multi-dimensional networks using tensor decomposition, introducing a denoise-and-solve framework for efficient analysis.


<details>
  <summary>Details</summary>
Motivation: To provide a detailed understanding of complex network structures by decomposing adjacency tensors into signal and noise components.

Method: Decomposes adjacency tensors into low-rank signal and noise tensors, using tensor decomposition and random tensor theory for a denoise-and-solve framework.

Result: Reduces computational complexity and improves performance in network inference tasks.

Conclusion: Offers a scalable and efficient solution for analyzing large-scale, multi-dimensional networks.

Abstract: In this paper, we extend the analysis of random Kronecker graphs to
multi-dimensional networks represented as tensors, enabling a more detailed and
nuanced understanding of complex network structures. We decompose the adjacency
tensor of such networks into two components: a low-rank signal tensor that
captures the essential network structure and a zero-mean noise tensor that
accounts for random variations. Building on recent advancements in tensor
decomposition and random tensor theory, we introduce a generalized
denoise-and-solve framework that leverages the Einstein summation convention
for efficient tensor operations. This approach significantly reduces
computational complexity while demonstrating strong performance in network
inference tasks, providing a scalable and efficient solution for analyzing
large-scale, multi-dimensional networks.

</details>


### [9] [An Alternative Finite Difference WENO-like Scheme with Physical Constraint Preservation for Divergence-Preserving Hyperbolic Systems](https://arxiv.org/abs/2506.22312)
*Dinshaw S. Balsara,Deepak Bhoriya,Chi-Wang Shu*

Main category: math.NA

TL;DR: AFD-WENO schemes are extended to handle divergence-preserving hyperbolic PDEs, improving efficiency for systems like CED, MHD, and RMHD.


<details>
  <summary>Details</summary>
Motivation: Existing methods for involution-constrained systems (e.g., CED, MHD, RMHD) were limited to higher-order finite volume discretizations, lacking efficiency.

Method: Extends AFD-WENO schemes to divergence-preserving hyperbolic PDEs while retaining Yee-style collocation for vector fields.

Result: Substantially more efficient treatment of divergence-preserving systems compared to previous methods.

Conclusion: AFD-WENO methods now efficiently handle involution-constrained hyperbolic PDEs, broadening their applicability.

Abstract: Alternative finite difference Weighted Essentially Non-Oscillatory (AFD-WENO)
schemes allow us to very efficiently update hyperbolic systems even in complex
geometries. Recent innovations in AFD-WENO methods allow us to treat hyperbolic
system with non-conservative products almost as efficiently as conservation
laws. However, some PDE systems,like computational electrodynamics (CED) and
magnetohydrodynamics (MHD) and relativistic magnetohydrodynamics (RMHD), have
involution constraints that require divergence-free or divergence-preserving
evolution of vector fields. In such situations, a Yee-style collocation of
variables proves indispensable; and that collocation is retained in this work.
In previous works, only higher order finite volume discretization of such
involution constrained systems was possible. In this work, we show that
substantially more efficient AFD-WENO methods have been extended to encompass
divergence-preserving hyperbolic PDEs.
  Our method retains the Yee-style collocation of normal components of...

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [10] [Remarks on the fine structure of the free boundary (the no-sign obstacle problem)](https://arxiv.org/abs/2506.21942)
*Seongmin Jeon,Henrik Shahgholian*

Main category: math.AP

TL;DR: The paper explores results inspired by Figalli and Serra's work on the obstacle problem, addressing the no-sign obstacle problem but leaving some key questions unresolved.


<details>
  <summary>Details</summary>
Motivation: To extend and apply the techniques from Figalli and Serra's work to the no-sign obstacle problem.

Method: Uses the fine structure approach from prior work, adapting it to the no-sign obstacle problem.

Result: Partial effectiveness in addressing the no-sign obstacle problem, but some central questions remain open.

Conclusion: The approach is promising but incomplete, requiring new techniques for unresolved questions.

Abstract: We present a number of results inspired by the approach developed in a recent
work by A. Figalli and J. Serra on the fine structure of the obstacle problem,
which turns out to be partially effective in addressing the no-sign obstacle
problem. However, we also highlight one or two central questions that remain
open and appear to require different techniques not presently available to us.

</details>


### [11] [Planar pulsating traveling wave solutions of non-cooperative Fisher--KPP systems in space-time periodic media](https://arxiv.org/abs/2506.22003)
*Léo Girardin,Grégoire Nadin*

Main category: math.AP

TL;DR: The paper analyzes non-cooperative Fisher-KPP systems with periodic coefficients, focusing on entire solutions for population invasion at constant speed. It establishes critical speeds for wave existence and behavior.


<details>
  <summary>Details</summary>
Motivation: Motivated by models of structured populations in periodic environments, the study aims to understand invasion dynamics and long-time behaviors in such systems.

Method: Combines methods for scalar equations with comparison principles and techniques for homogeneous systems to analyze critical speeds and wave existence.

Result: Proves existence of critical speeds for wave solutions: no waves below this speed, and for rational directions or homogeneous coefficients, waves exist at or above the critical speed.

Conclusion: The findings provide insights into invasion dynamics in periodic environments, with implications for understanding long-term behaviors in structured population models.

Abstract: Non-cooperative Fisher-KPP systems with space-time periodic coefficients are
motivated for instance by models for structured populations evolving in
periodic environments. This paper is concerned with entire solutions describing
the invasion of open space by a persistent population at constant speed. These
solutions are important in the understanding of long-time behaviors for the
Cauchy problem. Adapting methods developed for scalar equations satisfying the
comparison principle as well as methods developed for systems with homogeneous
coefficients, we prove, in each spatial direction, the existence of a critical
speed such that: there exists no almost planar generalized transition waves
with a smaller speed; if the direction is rational, each rational speed not
smaller than the critical speed is the speed of a weak planar pulsating
traveling wave; if the coefficients are homogeneous in space, each speed not
smaller than the critical speed is the speed of a strong planar pulsating
traveling wave.

</details>


### [12] [A note on Sobolev-Lorentz Capacity and Hausdorff measure](https://arxiv.org/abs/2506.22042)
*Daniel Campbell*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper we give an elementary proof that sets of zero
$p,1$-Sobolev-Lorentz capacity $\mathcal{H}^{n-p}$-null sets independently of
non-linear potential theory. We further show that there exists a set of
Sobolev-Lorentz-$(p,1)$ capacity equal zero with Hausdorff dimension equal
$n-p$.

</details>


### [13] [Dynamics and pattern formation in a diffusive Beddington-DeAngelis predator-prey model with fear effect](https://arxiv.org/abs/2506.22070)
*Aung Zaw Myint,Aye Chan May,Mya Hnin Lwin,Toe Toe Shwe,Adisak Seesanea*

Main category: math.AP

TL;DR: Study of a predator-prey system with fear effect and Beddington-DeAngelis response, focusing on dynamical properties and Turing patterns.


<details>
  <summary>Details</summary>
Motivation: To understand how fear effects and functional responses influence predator-prey dynamics and spatial patterns.

Method: Analysis of time-dependent solutions and stationary patterns (Turing patterns) under Neumann boundary conditions.

Result: Dynamical properties and Turing patterns are identified, showing the impact of fear and functional response.

Conclusion: The study reveals how fear and functional response shape predator-prey dynamics and spatial patterns.

Abstract: In this paper, dynamical properties and positive steady states of a diffusive
predator-prey system with fear effect and Beddington-DeAngelis functional
response subject to Neumann boundary conditions are investigated. Dynamical
properties of time-dependent solutions and the stationary patterns induced by
diffusion (Turing patterns) are presented.

</details>


### [14] [A gradient flow that is none: Heat flow with Wentzell boundary condition](https://arxiv.org/abs/2506.22093)
*Marie Bormann,Léonard Monsaingeon,D. R. Michiel Renger,Max von Renesse*

Main category: math.AP

TL;DR: The paper analyzes heat flow with Wentzell boundary conditions, showing it as gradient descent for entropy in an extended Otto manifold. However, weak boundary diffusion prevents recovering Fokker-Planck dynamics via entropy-driven JKO-Wasserstein schemes under certain metric regularity.


<details>
  <summary>Details</summary>
Motivation: To understand the representation of heat flow with Wentzell boundary conditions and its limitations in entropy-driven dynamics.

Method: Uses gradient descent dynamics for entropy in an extended Otto manifold and examines Fokker-Planck dynamics under weak boundary diffusion.

Result: Weak boundary diffusion prevents Fokker-Planck dynamics recovery via JKO-Wasserstein schemes under certain metric regularity.

Conclusion: The discrepancy highlights limitations in entropy-driven schemes for certain boundary conditions, illustrated through large-deviation heuristics.

Abstract: We establish a representation of the heat flow with Wentzell boundary
conditions on smooth domains as gradient descent dynamics for the entropy in a
suitably extended Otto manifold of probability measures with additional
boundary parts. Yet it is shown that for weak boundary diffusion, the
associated Fokker-Planck dynamics cannot be recovered from any entropy-driven
metric JKO-Wasserstein scheme, at least if the underlying point metric
satisfies certain natural regularity assumptions. This discrepancy is
illustrated in competing large-deviation heuristics in the Sanov and Schilder
regimes.

</details>


### [15] [Weak comparison principle for widely degenerate elliptic equations](https://arxiv.org/abs/2506.22128)
*Antonio Giuseppe Grimaldi,Stefania Russo*

Main category: math.AP

TL;DR: The paper proves a comparison principle for local weak solutions to a class of widely degenerate elliptic equations and establishes second-order regularity results, leading to a weighted Sobolev inequality.


<details>
  <summary>Details</summary>
Motivation: The study aims to address the behavior of solutions to degenerate elliptic equations, which are important in various mathematical and physical contexts.

Method: The authors analyze the equation using techniques for degenerate elliptic equations, focusing on comparison principles and second-order regularity.

Result: Key results include a comparison principle for weak solutions and second-order regularity, culminating in a weighted Sobolev inequality.

Conclusion: The findings contribute to the understanding of degenerate elliptic equations and provide tools for further analysis in related problems.

Abstract: We prove a comparison principle for local weak solutions to a class of widely
degenerate elliptic equations of the form \begin{equation}
  -\text{div} \left( \left(|Du|-1 \right)^{p-1}_+\frac{Du}{|Du|} \right) =
f(x,u) \qquad \text{ in } \Omega,\notag
  \end{equation}
  where $p \ge 2$ and $\Omega$ is an open subset of $\mathbb{R}^{n}$, $n\geq2$.
  Moreover, we establish some second order regularity results of the solutions,
that yields a weighted Sobolev inequality with widely degenerate weights.

</details>


### [16] [Multiple sign-changing and semi-nodal normalized solutions for a Gross-Pitaevskii type system on bounded domain: the $L^2$-supercritical case](https://arxiv.org/abs/2506.22152)
*Tianhao Liu,Linjie Song,Qiaoran Wu,Wenming Zou*

Main category: math.AP

TL;DR: Existence of multiple sign-changing and semi-nodal normalized solutions for an m-coupled elliptic system of Gross-Pitaevskii type, using vector linking methods.


<details>
  <summary>Details</summary>
Motivation: To explore the existence and multiplicity of solutions in coupled Schrödinger systems across all regimes of interaction coefficients, addressing gaps in the literature.

Method: Employing a novel vector linking technique, including partial vector linking for semi-nodal solutions, and analyzing the system's behavior as parameters approach zero.

Result: First demonstration of sign-changing and semi-nodal normalized solutions in all interaction regimes, with additional bifurcation insights.

Conclusion: The study successfully applies linking methods to coupled systems, providing new solutions and bifurcation results, particularly for Sobolev-critical cases.

Abstract: In this paper we investigate the existence of multiple sign-changing and
semi-nodal normalized solutions for an $m$-coupled elliptic system of the
Gross-Pitaevskii type:
  \begin{equation}
  \left\{
  \begin{aligned}
  &-\Delta u_j + \lambda_j u_j = \sum_{k=1 }^m\beta_{kj} u_k^2 u_j, \quad u_j
\in H_0^1(\Omega),
  &\int_\Omega u_j^2dx = c_j, \quad j = 1,2,\cdots,m.
  \end{aligned}
  \right.
  \end{equation}
  Here, $\Omega \subset \mathbb{R}^N$ ($N = 3,4$) is a bounded domain. The
constants $\beta_{kj} \neq 0$ and $c_j > 0$ are prescribed constants, while
$\lambda_1, \cdots, \lambda_m$ are unknown and appear as Lagrange multipliers.
This is the first result in the literature on the existence and multiplicity of
sign-changing and semi-nodal normalized solutions of couple Schr\"odinger
system in all regimes of $\beta_{kj}$. The main tool which we use is a new
skill of vector linking and this article attempts for the first time to use
linking method to search for solutions of a coupled system. Particularly, to
obtain semi-nodal normalized solutions, we introduce partial vector linking
which is new up to our knowledge. Moreover, by investigating the limit process
as $\vec{c}=(c_1,\ldots,c_m) \to \vec{0}$ we obtain some bifurcation results.
Note that when $N=4$, the system is of Sobolev critical.

</details>


### [17] [Weak solutions to incompressible heat-conducting motions with large flux](https://arxiv.org/abs/2506.22155)
*Joanna Rencławowicz,Wojciech M. Zajączkowski*

Main category: math.AP

TL;DR: Analysis of viscous incompressible heat-conducting fluid in a finite cylinder with large inflow/outflow, proving energy estimates and existence of weak solutions.


<details>
  <summary>Details</summary>
Motivation: To study the behavior of viscous incompressible heat-conducting fluids under large inflow and outflow conditions, addressing challenges in energy estimates and solution existence.

Method: Uses Navier-Stokes equations coupled with the heat equation, weighted spaces for nonlinear term estimation, and Galerkin approximation for weak solution existence.

Result: Proves energy estimates without restrictions on external force, initial data, inflow, or outflow, and demonstrates existence of weak solutions.

Conclusion: The paper successfully addresses the problem by providing unrestricted energy estimates and proving the existence of weak solutions for the given fluid dynamics scenario.

Abstract: We analyze the problem for viscous incompressible heat-conduc\-ting fluid in
a finite cylinder with large inflow and outflow, modelled with Navier-Stokes
equations coupled with the heat equation. We prove energy estimate without
restrictions on the magnitudes of the external force, initial data, inflow and
outflow. In order to estimate nonlinear terms we use weighted spaces. Next,
using Galerkin approximation, we show existence of weak solutions.

</details>


### [18] [Existence and decay for a Grushin problem in $\mathbb{R}^N$ with singular, convective, critical reaction](https://arxiv.org/abs/2506.22177)
*Laura Baldelli,Paolo Malanchini,Simone Secchi*

Main category: math.AP

TL;DR: Existence of solutions for a problem involving the Grushin operator with critical and singular convective terms, using variational methods and fixed point theory.


<details>
  <summary>Details</summary>
Motivation: To address the problem in Euclidean space with the Grushin operator, criticality, and singular convective reactions, which is novel when multiple features are combined.

Method: Combines variational methods, truncation, concentration-compactness, set-valued analysis, and fixed point theory.

Result: Existence of solutions proven; decay at infinity shown without the convective term.

Conclusion: The result is new, especially when multiple features (singularity, convectivity, criticality) are considered.

Abstract: We establish an existence result for a problem set in the whole Euclidean
space involving the Grushin operator and featuring a critical term perturbed by
a singular, convective reaction. Our approach combines variational methods,
truncation techniques, and concentration-compactness arguments, together with
set-valued analysis and fixed point theory. Additionally, we prove the decay at
infinity of solutions in the absence of the convective term. The result is new
even in the case where more than one feature between singularity, convectivity
and criticality is taken into account.

</details>


### [19] [On hot-spots free subregions of convex domains](https://arxiv.org/abs/2506.22184)
*Jonathan Rohleder*

Main category: math.AP

TL;DR: The paper investigates the second eigenfunction of the Neumann Laplacian on convex planar domains, showing that critical points (like interior hot spots) cannot be near the domain's center.


<details>
  <summary>Details</summary>
Motivation: Inspired by the hot spots conjecture and Steinerberger's result, the study aims to understand the location of critical points in such eigenfunctions.

Method: The analysis focuses on convex, planar domains and explicitly describes regions where critical points are excluded.

Result: Critical points of the second eigenfunction, including interior hot spots, are proven to avoid the central region of the domain.

Conclusion: The findings provide explicit constraints on the location of critical points, contributing to the understanding of eigenfunctions in convex planar domains.

Abstract: The second eigenfunction of the Neumann Laplacian on convex, planar domains
is considered. Inspired by the famous hot spots conjecture and a related result
of Steinerberger, we show that potential critical points of this eigenfunction
(and, in particular, interior "hot spots") cannot be located "near the center"
of the domain. The region in which critical points are excluded is described
explicitly.

</details>


### [20] [Boundary Estimates for the Monge-Ampère Equation in the Polygons with Guillemin Boundary Conditions](https://arxiv.org/abs/2506.22187)
*Masoud Bayrami-Aminlouee,Reza Seyyedali,Mohammad Talebi*

Main category: math.AP

TL;DR: Extends Schauder-type boundary regularity for a 2D singular Monge-Ampère equation with less regular right-hand side (Hölder continuous).


<details>
  <summary>Details</summary>
Motivation: To generalize previous work by Rubin and Huang to cases with less regular right-hand side functions.

Method: Uses advanced techniques from Donaldson's work on the Abreu equation.

Result: Establishes boundary regularity for the equation under Guillemin boundary conditions.

Conclusion: Advances understanding of singular Monge-Ampère equations with irregular data.

Abstract: We establish a Schauder-type boundary regularity result for a two-dimensional
singular Monge-Amp\'ere equation on convex polytopes with Guillemin boundary
conditions. This extends the previous work of Rubin and Huang to the case where
the right-hand side is less regular; specifically, H\"older continuous
functions. Our method relies heavily on the sophisticated techniques developed
by Donaldson in his series of papers on the Abreu equation.

</details>


### [21] [Density estimates for a (non)local variational model with degenerate double-well potential](https://arxiv.org/abs/2506.22193)
*Serena Dipierro,Alberto Farina,Giovanni Giacomin,Enrico Valdinoci*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper we provide density estimates for a class of functions which
includes all the minimizers of the energy
  $\mathcal{E}_s^p(u,\Omega):=(1-s)\left(\frac{1}{2}\int_{\Omega}\int_{\Omega}\frac{|u(x)-u(y)|^p}{|x-y|^{n+sp}}\,dx\,dy
+\int_{\Omega}\int_{\mathbb{R}^n \setminus
\Omega}\frac{|u(x)-u(y)|^p}{|x-y|^{n+sp}}\,dx\,dy\right)+\int_{\Omega}W(u(x))\,dx,$
  where $p\in (1,+\infty)$, $s \in \left(0,1\right)$ and $W$ is a double-well
potential with polynomial growth $m\in \left[p,+\infty\right)$ from the minima.
The nonlocal estimates obtained are uniform as $s\to1$.
  Moreover, making use of a $\Gamma$-convergence result for $\mathcal{E}_s^p$
as $s\to 1$, we obtain density estimates for the minimizers of the limit energy
functional, which takes the form
  $\mathcal{E}_1^p(u,\Omega):=\frac{K_{n,p}}{2p}\int_{\Omega} \left|\nabla
u(x)\right|^p+\int_{\Omega} W(u(x))\,dx,$
  for a suitable $K_{n,p}\in (0,+\infty)$.

</details>


### [22] [Existence and uniqueness results of unsteady reactive flows in porous media](https://arxiv.org/abs/2506.22225)
*Pankaj Roy,Satyajit Pramanik*

Main category: math.AP

TL;DR: The paper analyzes miscible reactive flows in porous media, focusing on existence and uniqueness of solutions for nonlinear PDEs describing fluid flow and solute transport.


<details>
  <summary>Details</summary>
Motivation: Understanding miscible reactive flows is crucial for engineering and industrial applications like oil recovery and carbon sequestration.

Method: Uses the semi-discrete Galerkin method to analyze the unsteady Darcy-Brinkman equation coupled with an advection-diffusion-reaction equation.

Result: Establishes convergence of approximate solutions to the proposed problem and discusses applications in miscible fingering instabilities.

Conclusion: The study provides theoretical foundations for modeling reactive flows in porous media, with practical implications for oil recovery and carbon sequestration.

Abstract: Miscible reactive flows in porous media play crucial roles in many
engineering and industrial applications. In this work, we establish several
results regarding the existence and uniqueness of solutions for a system of
time-dependent, nonlinear partial differential equations that describe the flow
and transport of miscible reactive fluids with variable viscosity in
heterogeneous porous media with variable permeability. Fluid flow is modelled
via the unsteady Darcy-Brinkman equation with Korteweg stresses coupled with an
advection-diffusion-reacton equation for the transport of a solute responsible
for the viscosity variation and the Korteweg stresses. Our analysis is based on
the semi-discrete Galerkin method, which allows us to pass the limit and
establish that the approximate solution converges to the solution of the
proposed problem. We also discuss particular cases that are widely used in the
studies of miscible fingering instabilities in the porous media with
application in oil recovery and/or geological carbon sequestration.

</details>


### [23] [Asymptotic analysis and design of shell-based thermal lattice metamaterials](https://arxiv.org/abs/2506.22319)
*Di Zhang,Ligang Liu*

Main category: math.AP

TL;DR: The paper introduces a framework for analyzing thermal conductivity in shell lattice metamaterials, introducing the asymptotic directional conductivity (ADC) metric. It provides theoretical and numerical support for optimizing thermal conductivity.


<details>
  <summary>Details</summary>
Motivation: To extend prior work on mechanical stiffness to heat transfer in shell lattice metamaterials and provide a theoretical foundation for optimizing thermal conductivity.

Method: Develops the ADC metric, establishes a convergence theorem, and provides a discrete algorithm for computing and optimizing ADC over periodic surfaces.

Result: Theoretical justification for optimal thermal conductivity of triply periodic minimal surfaces and a third-order approximation for low volume fractions. Numerical results validate the framework.

Conclusion: The ADC framework and optimization algorithm effectively analyze and optimize thermal conductivity in shell lattice metamaterials, supported by theoretical and numerical evidence.

Abstract: We present a rigorous asymptotic analysis framework for investigating the
thermal conductivity of shell lattice metamaterials, extending prior work from
mechanical stiffness to heat transfer. Central to our analysis is a new metric,
the asymptotic directional conductivity (ADC), which captures the leading-order
influence of the middle surface geometry on the effective thermal conductivity
in the vanishing-thickness limit. A convergence theorem is established for
evaluating ADC, along with a sharp upper bound and the necessary and sufficient
condition for achieving this bound. These results provide the first theoretical
justification for the optimal thermal conductivity of triply periodic minimal
surfaces. Furthermore, we show that ADC yields a third-order approximation to
the effective conductivity of shell lattices at low volume fractions. To
support practical design applications, we develop a discrete algorithm for
computing and optimizing ADC over arbitrary periodic surfaces. Numerical
results confirm the theoretical predictions and demonstrate the robustness and
effectiveness of the proposed optimization algorithm.

</details>


### [24] [Relaxation enhancement by controlling incompressible fluid flows](https://arxiv.org/abs/2506.22233)
*Kai Koike,Vahagn Nersesyan,Manuel Rissel,Marius Tucsnak*

Main category: math.AP

TL;DR: A PDE-controllability approach enhances diffusive mixing for passive scalar fields by deriving relaxation-enhancing vector fields from controlled incompressible Euler equations.


<details>
  <summary>Details</summary>
Motivation: Existing methods prescribe relaxation-enhancing fields upfront, limiting flexibility. This work aims to derive such fields dynamically from control systems.

Method: Time-dependent relaxation-enhancing vector fields are obtained as state trajectories of controlled incompressible Euler equations, using finite-dimensional or spatially localized controls.

Result: A new approximate controllability theorem for incompressible Euler equations on 𝕋² enables tracking the full state, leading to enhanced relaxation for passive scalar fields.

Conclusion: The approach successfully enhances diffusive mixing by dynamically deriving relaxation-enhancing fields from controlled Euler systems, supported by controllability theorems.

Abstract: We propose a PDE-controllability based approach to the enhancement of
diffusive mixing for passive scalar fields. Unlike in the existing literature,
our relaxation enhancing fields are not prescribed $\textit{ab initio}$ at
every time and at every point of the spatial domain. Instead, we prove that
time-dependent relaxation enhancing vector fields can be obtained as
$\textit{state trajectories of control systems described by the incompressible
Euler equations}$ either driven by finite-dimensional controls or by controls
localized in space. The main ingredient of our proof is a new approximate
controllability theorem for the incompressible Euler equations on
$\mathbb{T}^2$, ensuring the approximate tracking of the full state all over
the considered time interval. Combining this with a continuous dependence
result yields enhanced relaxation for the passive scalar field. Another
essential tool in our analysis is the exact controllability of the
incompressible Euler system driven by spatially localized forces.

</details>


### [25] [Global regularity and incompressible limit of 2D compressible Navier-Stokes equations with large bulk viscosity](https://arxiv.org/abs/2506.22235)
*Shengquan Liu,Jianwen Zhang*

Main category: math.AP

TL;DR: The paper analyzes global regularity of large solutions with vacuum in 2D compressible Navier-Stokes equations, fixes a flaw in prior work, and derives an incompressible limit with explicit convergence rate.


<details>
  <summary>Details</summary>
Motivation: To address a flaw in existing literature regarding global estimates of solutions and extend results to include vacuum cases.

Method: Uses non-trivial mathematical analysis to amend proofs and employs t-weighted estimates for solutions with vacuum.

Result: Achieves global regularity for large solutions with vacuum and provides an explicit convergence rate for the incompressible limit.

Conclusion: The work corrects prior errors and extends understanding of compressible Navier-Stokes equations, including vacuum scenarios.

Abstract: In this paper, we study the global regularity of large solutions with vacuum
to the two-dimensional compressible Navier-Stokes equations on
$\mathbb{T}^{2}=\mathbb{R}^{2}/\mathbb{Z}^{2}$, when the volume (bulk)
viscosity coefficient $\nu$ is sufficiently large. It firstly fixes a flaw in
[10, Proposition 3.3], which concerns the $\nu$-independent global $t$-weighted
estimates of the solutions. Amending the proof requires non-trivially
mathematical analysis. As a by-product, the incompressible limit with an
explicit rate of convergence is shown, when the volume viscosity tends to
infinity. In contrast to [9,Theorem 1.3] and [7,Corollary 1.1] where vacuum was
excluded, the convergence rate of the incompressible limit is obtained for the
global solutions with vacuum, based on some $t$-growth and singular
$t$-weighted estimates.

</details>


### [26] [Two types of compressible isotropic neo-Hookean material models](https://arxiv.org/abs/2506.22244)
*Sergey N. Korobeynikov,Alexey Yu. Larichkin,Patrizio Neff*

Main category: math.AP

TL;DR: The paper compares two compressible generalizations of the neo-Hookean material model: vol-iso (volumetric-isochoric decomposition) and mixed models. Mixed models offer simpler expressions and broader volumetric function applicability, while both perform similarly for q≥2.


<details>
  <summary>Details</summary>
Motivation: To systematically evaluate and compare the performance of two compressible neo-Hookean material models (vol-iso and mixed) for theoretical and practical applications.

Method: Theoretical analysis and simulations of homogeneous deformations using volumetric functions from the Hartmann-Neff family, focusing on parameter q≥2.

Result: Both models perform similarly for q≥2, but mixed models allow more volumetric functions and simpler stress/tangent stiffness expressions.

Conclusion: Mixed models are preferable for their flexibility and simplicity, though vol-iso models remain viable for specific cases.

Abstract: In this book, we present a systematic study of the performance of two known
types of compressible generalization of the incompressible neo-Hookean material
model. The first type of generalization is based on the development of
\emph{vol-iso} neo-Hookean models and involves the additive decomposition of
the elastic energy into volumetric and isochoric parts. The second simpler type
of generalization is based on the development of \emph{mixed} neo-Hookean
models that do not use this decomposition. Theoretical studies of model
performance and simulations of some homogeneous deformations have shown that
when using volumetric functions $(J^q+J^{-q}-2)/(2q^2)$ ($J$ is the volume
ratio, and $q\in \mathbb{R}$ is a parameter, $q\geq 0$) from the Hartmann--Neff
family [Hartmann and Neff, Int. J. Solids Structures, 40: 2767--2791 (2003)]
with parameter $q\geq 2$ (the preferred value is $q=5$), mixed and vol-iso
models show similar performance in applications and have physically reasonable
responses in extreme states, which is convenient for theoretical studies.
However, contrary to vol-iso models, mixed models allow the use of a wider set
of volumetric functions with physically reasonable responses in extreme states.
A further feature of mixed models is simpler expressions for stresses and
tangent stiffness tensors.

</details>


### [27] [A free boundary approach to non-scattering obstacles with vanishing contrast](https://arxiv.org/abs/2506.22328)
*Mikko Salo,Henrik Shahgholian*

Main category: math.AP

TL;DR: The paper develops free boundary methods for obstacle problems in inverse scattering theory, focusing on cases where solutions and right-hand sides vary in sign, with harmonic polynomial conditions to avoid corners.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by questions in inverse scattering theory, aiming to address obstacle problems with varying sign solutions and right-hand sides.

Method: The authors use free boundary methods, requiring the right-hand side to relate to a harmonic polynomial to prevent corners.

Result: New free boundary results are proven, showing that piecewise $C^1$ or convex penetrable obstacles in 2D and edge points in higher dimensions always scatter incoming waves nontrivially.

Conclusion: The findings provide insights into scattering behavior for obstacles with varying sign conditions, advancing free boundary theory in inverse scattering.

Abstract: Motivated by questions in inverse scattering theory, we develop free boundary
methods in obstacle problems where both the solution and the right hand side of
the equation may have varying sign. The key condition that prevents the
appearance of corners is that the right hand side should be related to a
harmonic polynomial. In this setting we prove new free boundary results not
found in existing literature. Notably, our results imply that piecewise $C^1$
or convex penetrable obstacles in two dimensions and edge points in higher
dimensions always cause nontrivial scattering of any incoming wave.

</details>


### [28] [Local Wellposedness and Global Weak Solutions of the Pauli-Darwin/Poisswell Equations](https://arxiv.org/abs/2506.22333)
*Pierre Germain,Norbert J. Mauser,Jakob Möller*

Main category: math.AP

TL;DR: Local strong and global weak solutions are constructed for Pauli-Darwin and Pauli-Poisswell equations, marking the first rigorous results for these models.


<details>
  <summary>Details</summary>
Motivation: To provide the first rigorous analysis of Pauli-Darwin and Pauli-Poisswell equations, which couple a 2-spinor with an electromagnetic field.

Method: Energy estimates for strong solutions and compactness with regularization for weak solutions.

Result: Existence of local strong solutions in $H^s(\mathbb{R}^3)$, $s>3/2$, and global weak solutions with finite energy.

Conclusion: The study establishes foundational results for these coupled models, opening avenues for further analysis.

Abstract: We construct local (in time) strong solutions in $H^s(\mathbb{R}^3)$, $s>3/2$
and global weak solutions with finite energy for the Pauli-Darwin equation and
the Pauli-Poisswell equation. These are the first rigorous results on these two
models, which couple a 2-spinor with an electromagnetic field. The proofs rely
on energy estimates for the strong solutions and compactness with an
appropriate regularization for the weak solutions.

</details>


### [29] [Energy local minimizers for the nonlinear Schrödinger equation on product spaces](https://arxiv.org/abs/2506.22371)
*Dario Pierotti,Gianmaria Verzini,Junwei Yu*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We investigate the existence of local minimizers with prescribed $L^2$-norm
for the energy functional associated to the mass-supercritical nonlinear
Schr\"{o}dinger equation on the product space $\mathbb{R}^N \times M^k$, where
$(M^k,g)$ is a compact Riemannian manifold, thus complementing the study of the
mass-subcritical case performed by Terracini, Tzvetkov and Visciglia in
[\emph{Anal. PDE} 2014, arXiv:1205.0342].
  First we prove that, for small $L^2$-mass, the problem admits local
minimizers. Next, we show that when the $L^2$-norm is sufficiently small, the
local minimizers are constants along $M^k$, and they coincide with those of the
corresponding problem on $\mathbb{R}^N$. Finally, under certain conditions, we
show that the local minimizers obtained above are nontrivial along $M^k$. The
latter situation occurs, for instance, for every $M^k$ of dimension $k\ge 2$,
with the choice of an appropriate metric $\hat g$, and in
$\mathbb{R}\times\mathbb{S}^k$, $k\ge 3$, where $\mathbb{S}^k$ is endowed with
the standard round metric.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [30] [Unbiased higher-order frictional contact using midplane and patch based segment-to-segment penalty method](https://arxiv.org/abs/2506.21767)
*Indrajeet Sahu,Nik Petrinic*

Main category: physics.comp-ph

TL;DR: A single-pass, unbiased frictional contact algorithm for higher-order elements improves accuracy in curved geometries by using midplane-based constraints and penalizing interpenetration and sliding.


<details>
  <summary>Details</summary>
Motivation: Higher-order elements better represent curved geometries than first-order elements, but existing contact algorithms may not fully exploit their potential. This work aims to enhance accuracy and versatility for frictional contact problems.

Method: The algorithm subdivides higher-order segments into sub-segments, applying compressive and frictional constraints. Normal traction penalizes interpenetration, and frictional traction depends on sliding between sub-segments. The midplane is corrected for local curvature.

Result: Tests show higher-order elements outperform first-order ones in accuracy for curved geometries. The algorithm works well in static and dynamic conditions, including Hertzian contact, elastic collision, and frictional sliding.

Conclusion: The algorithm excels in accuracy and versatility for frictional contact problems, especially for curved geometries and large deformations, benefiting from higher-order discretisation.

Abstract: A highly accurate, single-pass, unbiased frictional contact algorithm for
higher-order elements based on the concept of midplane is presented.
Higher-order elements offer a lucrative choice for contact problems as they can
better represent the curvature of original geometries compared to the
first-order elements. Compressive and frictional contact constraints are
applied over the contact pairs of sub-segments obtained by the subdivision of
higher-order segments. The normal traction depends upon the penalisation of
true interpenetration, and frictional traction depends upon relative sliding
between sub-segments over their shared patches. The midplane constructed by
linearised subfacets can be corrected to account for local curvature of
interacting physical surfaces. Demonstrated through multiple tests, the use of
higher-order elements surpasses the accuracy of first-order elements for curved
geometries. Its versatility extends from static to dynamic conditions for flat
and curved interfaces including frictional contact. The presented examples
include contact patch test, Hertzian contact, elastic collision, rotation of
concentric surfaces, frictional sliding, self-contact and inelastic collision
problems. Here, contact patch test matches the accuracy of finite elements and
Hertzian contact shows smoother solution compared to first-order meshes. The
elastic collision problem highlights the utility of the algorithm in accurate
prediction of configuration changes in multibody systems. The frictional
sliding demonstrates the ability to represent the expected nonlinear
distribution of nodal forces for the higher-order elements. The large
deformation problems, e.g. self-contact and inelastic collision, specifically
benefit from the accuracy in surface representation using higher-order
discretisation and continuous contact constraint imposition on such surfaces
during deformation.

</details>


### [31] [Large-Scale Simulations of Turbulent Flows using Lattice Boltzmann Methods on Heterogeneous High Performance Computers](https://arxiv.org/abs/2506.21804)
*Adrian Kummerländer,Fedor Bukreev,Yuji Shimojima,Shota Ito,Mathias J. Krause*

Main category: physics.comp-ph

TL;DR: A novel LBM scheme for wall-modeled LES in complex geometries is presented, optimized for GPU-accelerated supercomputers and implemented in OpenLB, showing scalability up to 128 nodes.


<details>
  <summary>Details</summary>
Motivation: To leverage GPU-accelerated supercomputers for large-scale turbulent flow simulations using LBM due to its parallel execution compatibility.

Method: Developed a novel LBM scheme for wall-modeled LES in complex geometries, implemented efficiently in OpenLB.

Result: Demonstrated scalability on HoreKa partitions, handling up to 18 billion cells with 128 nodes.

Conclusion: The LBM scheme is effective for large-scale turbulent flow simulations on modern GPU-accelerated supercomputers.

Abstract: Current GPU-accelerated supercomputers promise to enable large-scale
simulations of turbulent flows. Lattice Boltzmann Methods (LBM) are
particularly well-suited to fulfilling this promise due to their intrinsic
compatibility with highly parallel execution on both SIMD CPUs and GPUs. A
novel LBM scheme for wall-modeled LES in complex geometries is described with a
special focus on the efficient implementation in the open source LBM framework
OpenLB. Detailed scalability results are provided for all HoreKa partitions,
utilizing up to 128 nodes and covering problem sizes up to 18 billion cells.

</details>


### [32] [Physics-informed neural network framework for solving forward and inverse flexoelectric problems](https://arxiv.org/abs/2506.21810)
*Hyeonbin Moon,Donggeun Park,Jinwook Yeo,Seunghwa Ryu*

Main category: physics.comp-ph

TL;DR: A physics-informed neural network (PINN) framework is proposed to solve flexoelectricity problems, addressing computational challenges of fourth-order PDEs. It handles forward and inverse problems, showing agreement with traditional methods.


<details>
  <summary>Details</summary>
Motivation: Flexoelectricity's computational challenges due to high-order PDEs motivate a need for efficient, scalable solutions.

Method: The PINN framework uses an energy-based formulation, deep energy method (DEM), and variational loss for inverse problems, with finite element quadrature and hard constraints.

Result: The framework matches mixed-FEM solutions for flexoelectric effects and accurately identifies material parameters from sparse data.

Conclusion: The study presents a unified, scalable PINN approach for high-order electromechanical problems, offering an alternative to traditional methods.

Abstract: Flexoelectricity, the coupling between strain gradients and electric
polarization, poses significant computational challenges due to its governing
fourth-order partial differential equations that require C1-continuous
solutions. To address these issues, we propose a physics-informed neural
network (PINN) framework grounded in an energy-based formulation that treats
both forward and inverse problems within a unified architecture. The forward
problem is recast as a saddle-point optimization of the total potential energy,
solved via the deep energy method (DEM), which circumvents the direct
computation of high-order derivatives. For the inverse problem of identifying
unknown flexoelectric coefficients from sparse measurements, we introduce an
additional variational loss that enforces stationarity with respect to the
electric potential, ensuring robust and stable parameter inference. The
framework integrates finite element-based numerical quadrature for stable
energy evaluation and employs hard constraints to rigorously enforce boundary
conditions. Numerical results for both direct and converse flexoelectric
effects show excellent agreement with mixed-FEM solutions, and the inverse
model accurately recovers material parameters from limited data. This study
establishes a unified, mesh-compatible, and scalable PINN approach for
high-order electromechanical problems, offering a promising alternative to
traditional simulation techniques.

</details>


### [33] [Fine-Tuning Universal Machine-Learned Interatomic Potentials: A Tutorial on Methods and Applications](https://arxiv.org/abs/2506.21935)
*Xiaoqing Liu,Kehan Zeng,Zedong Luo,Yangshuai Wang,Teng Zhao,Zhenli Xu*

Main category: physics.comp-ph

TL;DR: A tutorial on fine-tuning universal machine-learned interatomic potentials (U-MLIPs) for computational materials modeling, using MACE-MP-0 as an example.


<details>
  <summary>Details</summary>
Motivation: Addresses the lack of systematic guidance on fine-tuning U-MLIPs despite their broad applicability and growing use.

Method: Provides a step-by-step guide covering dataset preparation, hyperparameter selection, training, and validation, with code examples.

Result: Demonstrates effectiveness through case studies on force prediction in solid-state electrolytes, stacking faults in metals, and solid-liquid interfaces.

Conclusion: Aims to help researchers efficiently incorporate fine-tuned U-MLIPs into their workflows, especially newcomers to the field.

Abstract: Universal machine-learned interatomic potentials (U-MLIPs) have demonstrated
broad applicability across diverse atomistic systems but often require
fine-tuning to achieve task-specific accuracy. While the number of available
U-MLIPs and their fine-tuning applications is rapidly expanding, there remains
a lack of systematic guidance on how to effectively fine-tune these models.
This tutorial provides a comprehensive, step-by-step guide to fine-tuning
U-MLIPs for computational materials modeling. Using the recently released
MACE-MP-0 as a representative example, we cover key aspects of the fine-tuning
process, including dataset preparation, hyperparameter selection, model
training, and validation. The effectiveness of fine-tuning is demonstrated
through case studies involving force prediction in solid-state electrolytes,
stacking fault defects in metals, and solid--liquid interfacial interactions in
low-dimensional systems. To support practical applications, we include code
examples that enable researchers, particularly those new to the field, to
efficiently incorporate fine-tuned U-MLIPs into their workflows.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [34] [Sharp mean-field estimates for the repulsive log gas in any dimension](https://arxiv.org/abs/2506.22083)
*Matias G. Delgadino,Rishabh S. Gvalani*

Main category: math.PR

TL;DR: Sharp estimates for the mean-field limit of weakly interacting diffusions with repulsive logarithmic interaction, showing uniform boundedness of the partition function and a logarithmic improvement in closeness estimates.


<details>
  <summary>Details</summary>
Motivation: To improve current estimates for the mean-field limit of weakly interacting diffusions with repulsive logarithmic interaction in arbitrary dimensions.

Method: Uses the modulated free energy method and borrows ideas from Nelson's construction of the φ⁴₂ Euclidean quantum field theory.

Result: Uniform boundedness of the partition function and a logarithmic improvement in closeness estimates.

Conclusion: The results provide a significant improvement over existing literature, leveraging techniques from quantum field theory.

Abstract: We prove sharp estimates for the mean-field limit of weakly interacting
diffusions with repulsive logarithmic interaction in arbitrary dimension. More
precisely, we show that the associated partition function is uniformly bounded
in the number of particles $N$ for an arbitrary bounded base measure. Combined
with the modulated free energy method, this amounts to a logarithmic
improvement in $N$ of the current best available closeness estimates in the
literature. Our arguments are inspired by and borrow ideas from Nelson's
classical construction of the $\varphi^4_2$ Euclidean quantum field theory.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [35] [Linearization Scheme of Shallow Water Equations for Quantum Algorithms](https://arxiv.org/abs/2506.22345)
*Till Appel,Zofia Binczyk,Francesco Conoscenti,Petr Ivashkov,Seyed Ali Hosseini,Ricardo Garcia,Carmen Recio*

Main category: quant-ph

TL;DR: Quantum algorithms are explored for solving the shallow water equations, showing potential for exponential speedup over classical methods.


<details>
  <summary>Details</summary>
Motivation: Address the computational demands of solving fluid dynamics problems using quantum computing.

Method: Extends a linearization scheme for Navier-Stokes to map nonlinear shallow water equations to a linear system solvable by quantum algorithms.

Result: Validated against analytical solutions, demonstrating potential for quantum speedup.

Conclusion: Highlights the promise of quantum algorithms in fluid dynamics and outlines future considerations.

Abstract: Computational fluid dynamics lies at the heart of many issues in science and
engineering, but solving the associated partial differential equations remains
computationally demanding. With the rise of quantum computing, new approaches
have emerged to address these challenges. In this work, we investigate the
potential of quantum algorithms for solving the shallow water equations, which
are, for example, used to model tsunami dynamics. By extending a linearization
scheme previously developed in [Phys. Rev. Research 7, 013036 (2025)] for the
Navier-Stokes equations, we create a mapping from the nonlinear shallow water
equation to a linear system of equations, which, in principle, can be solved
exponentially faster on a quantum device than on a classical computer. To
validate our approach, we compare its results to an analytical solution and
benchmark its dependence on key parameters. Additionally, we implement a
quantum linear system solver based on quantum singular value transformation and
study its performance in connection to our mapping. Our results demonstrate the
potential of applying quantum algorithms to fluid dynamics problems and
highlight necessary considerations for future developments.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [36] [Predicting Thermodynamics of Liquid Water from Time Series Analysis](https://arxiv.org/abs/2506.21821)
*Małgorzata J. Zimoń,Fausto Martelli*

Main category: physics.chem-ph

TL;DR: The paper proposes a time series analysis approach to interpret thermodynamic behavior, using molecular dynamics simulations of water to link microscopic HBN dynamics to macroscopic properties, aided by AI for predictive insights.


<details>
  <summary>Details</summary>
Motivation: To explore an alternative to traditional statistical mechanics for understanding thermodynamics, focusing on water's complex behavior.

Method: Classical molecular dynamics simulations of liquid water, analyzing HBN topology dynamics with AI to predict thermodynamic properties.

Result: Microscopic HBN dynamics encode macroscopic thermodynamic behavior, enabling predictions beyond sampled regions.

Conclusion: The work introduces a new paradigm for understanding material properties, extending beyond classical statistical mechanics.

Abstract: Thermodynamics, introduced over two centuries ago, remains foundational to
our understanding of physical, chemical, biological, and engineering systems.
Its principles are traditionally grounded in the statistical mechanics
framework, which explains macroscopic behavior from microscopic states. In this
work, we propose an alternative approach that interprets thermodynamic behavior
through the lenses of time series analysis, an approach commonly used in other
fields, including finance, climate, and signal processing. We perform classical
molecular dynamics simulations of liquid water, the most complex, anomalous,
and important substance known, over a wide range of its phase diagram. By
examining the temporal evolution of the hydrogen bond network (HBN) topology,
we demonstrate that the dynamics of microscopic topological motifs populating
the HBN encode the system's macroscopic thermodynamic behavior. Furthermore,
our approach enables the prediction of thermodynamic properties in regions
beyond those directly sampled in our simulations. We achieve this result by
leveraging artificial intelligence to uncover patterns in temporally resolved
data that are often lost through conventional averaging. This work offers new
insights into the fundamental behavior of water and network-forming materials
more broadly, establishing a new paradigm for understanding material properties
beyond the classical confines of statistical mechanics.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [37] [Modeling the g-factors, hyperfine interaction and optical properties of semiconductor QDs: the atomistic and eight-band $k \cdot p$ approaches](https://arxiv.org/abs/2506.22380)
*Krzysztof Gawarecki,Alina Garbiec,Jakub Stanecki,Michał Zieliński*

Main category: cond-mat.mes-hall

TL;DR: Comparative study of atomistic tight-binding and continuum eight-band k·p methods for modeling QDs, highlighting corrections to improve agreement and validation criteria.


<details>
  <summary>Details</summary>
Motivation: To compare and improve the accuracy of theoretical approaches for modeling spin and optical properties of quantum dots (QDs).

Method: Comparative study of atomistic sp³d⁵s* tight-binding and continuum eight-band k·p methods, with corrections to the latter for better alignment with atomistic results.

Result: Qualitative consistency but quantitative discrepancies between methods; corrections improved agreement for electron g-factors and single-particle energies.

Conclusion: Criteria established for selecting the appropriate modeling framework based on desired accuracy and computational efficiency in QD studies.

Abstract: We present a detailed comparative study of two important theoretical
approaches: atomistic sp$^3$d$^5$s$^*$ tight-binding and continuum eight-band
$k \cdot p$ methods, for modeling the spin and optical properties of quantum
dots (QDs). Our investigation spans key physical observables, including
single-particle energy levels, g-factors, exciton radiative lifetimes, and
hyperfine-induced Overhauser field fluctuations. We perform our calculations
for self-assembled InGaAs/GaAs QD systems as representative case studies. While
both methods yield qualitatively consistent trends, quantitative discrepancies
arise due to different treatment of atomistic details, strain effects, and
confinement. We introduce targeted corrections to the eight-band $k \cdot p$
framework, including a modified deformation potential scheme and adjusted
remote-band contributions, to improve agreement with atomistic results,
especially for electron g-factors and single-particle energies. Furthermore, we
validate the eight-band implementation of hyperfine interactions by
benchmarking it against the tight-binding model, showing reasonable convergence
for both electrons and holes. Our results establish criteria for selecting the
appropriate modeling framework based on the desired physical accuracy and
computational efficiency in spin-optical studies of semiconductor QDs.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [38] [Phase field approximation for Plateau's problem: a curve geodesic distance penalty approach](https://arxiv.org/abs/2506.22273)
*Matthieu Bonnivard,Elie Bretin,Antoine Lemenant,Eve Machefert*

Main category: math.OC

TL;DR: The paper introduces a phase field model combining Ambrosio-Torterelli energy and geodesic distance to approximate Plateau's problem, validated through Gamma-convergence and numerical optimization.


<details>
  <summary>Details</summary>
Motivation: To generalize the approach for solving Steiner's problem and approximate solutions to Plateau's problem.

Method: Combines Ambrosio-Torterelli energy with a geodesic distance term, analyzed via Gamma-convergence and numerical optimization.

Result: Good approximations of Plateau's problem solutions are achieved.

Conclusion: The proposed model effectively approximates Plateau's problem, supported by theoretical and numerical results.

Abstract: This work focuses on a phase field approximation of Plateau's problem.
Inspired by Reifenberg's point of view, we introduce a model that combines the
Ambrosio-Torterelli energy with a geodesic distance term, which can be
considered as a generalization of the approach developed by Bonnivard, Lemenant
and Santambrogio to approximate solutions to Steiner's problem. First, we
present a Gamma-convergence analysis of this model in the simple case of a
single curve located on the edge of a cylinder. In a numerical section, we
detail the numerical optimisation schemes used to minimize this energy for
numerous examples, for which good approximations of solutions to Plateau's
problem are found.

</details>


### [39] [Augmented Lagrangian methods for infeasible convex optimization problems and diverging proximal-point algorithms](https://arxiv.org/abs/2506.22428)
*Roland Andrews,Justin Carpentier,Adrien Taylor*

Main category: math.OC

TL;DR: The paper analyzes the convergence of augmented Lagrangian methods (ALMs) for convex optimization, even when problems are infeasible, showing iterates converge to solutions of the 'closest feasible problem' under mild assumptions.


<details>
  <summary>Details</summary>
Motivation: To understand and strengthen convergence guarantees for ALMs in convex optimization, especially in infeasible cases, by leveraging their relationship with the proximal-point algorithm.

Method: The study uses the proximal-point algorithm applied to the dual problem, with new technical results on its behavior for functions without minimizers.

Result: Under mild assumptions, ALM iterates converge to solutions of the closest feasible problem, with precise convergence rates provided.

Conclusion: The work advances convergence theory for ALMs in infeasible convex optimization, offering practical insights for constrained problem-solving.

Abstract: This work investigates the convergence behavior of augmented Lagrangian
methods (ALMs) when applied to convex optimization problems that may be
infeasible. ALMs are a popular class of algorithms for solving constrained
optimization problems. We establish progressively stronger convergence results,
ranging from basic sequence convergence to precise convergence rates, under a
hierarchy of assumptions. In particular, we demonstrate that, under mild
assumptions, the sequences of iterates generated by ALMs converge to solutions
of the ``closest feasible problem''.
  This study leverages the classical relationship between ALMs and the
proximal-point algorithm applied to the dual problem. A key technical
contribution is a set of concise results on the behavior of the proximal-point
algorithm when applied to functions that may not have minimizers. These results
pertain to its convergence in terms of its subgradients and of the values of
the convex conjugate.

</details>


### [40] [Memory-Type Null Controllability of Heat Equations with Delay Effects](https://arxiv.org/abs/2506.22221)
*Dev Prakash Jha,Raju K. George*

Main category: math.OC

TL;DR: Study of null controllability for evolution equations with memory and delay effects, requiring vanishing state, memory, and delay at terminal time. Uses duality arguments, rank conditions, and Carleman estimates to derive controllability conditions, validated numerically.


<details>
  <summary>Details</summary>
Motivation: Address the challenge of controllability in systems with memory integrals and delayed states, requiring stronger conditions than classical controllability.

Method: Uses duality arguments, rank-type conditions for finite-dimensional systems, and extends to parabolic PDEs with Carleman estimates and time-dependent control strategies.

Result: Establishes sufficient conditions for controllability, validated by numerical simulations showing the importance of moving control regions.

Conclusion: The proposed approach successfully addresses null controllability in systems with memory and delay, with theoretical and numerical validation.

Abstract: This article is devoted to the study of null controllability for evolution
equations that incorporate both memory and delay effects. The problem is
particularly challenging due to the presence of memory integrals and delayed
states, which necessitate strengthening the classical controllability
requirement to ensure complete rest at the final time. To address this, we
adopt the notion of Delay and memory-type null controllability, which demands
the vanishing of the state, the accumulated memory term, and the influence of
delay at the terminal time. Utilizing duality arguments, we reduce the
controllability analysis to proving suitable observability inequalities for the
corresponding adjoint system. We begin with finite-dimensional systems and
establish rank-type conditions characterizing controllability. These insights
are then extended to parabolic partial differential equations with delay and
memory terms. By leveraging Carleman estimates and time-dependent control
strategies, we derive sufficient conditions under which controllability can be
achieved. Numerical simulations validate the theoretical results and illustrate
the critical role of moving control regions in neutralizing the effects of
memory and delay.

</details>


<div id='q-bio.PE'></div>

# q-bio.PE [[Back]](#toc)

### [41] [Vegetation Patterning Can Both Impede and Trigger Critical Transitions from Savanna to Grassland](https://arxiv.org/abs/2506.22178)
*Jelle van der Voort,Mara Baudena,Ehud Meron,Max Rietkerk,Arjen Doelman*

Main category: q-bio.PE

TL;DR: The paper explores tree-grass coexistence in savannas, introducing a spatial model that reveals bistability and pattern formation under stress, including novel mechanisms like 'Turing-evades-tipping' and 'Turing-triggers-tipping' as early warnings for ecosystem transitions.


<details>
  <summary>Details</summary>
Motivation: Understanding how tree-grass interactions under environmental stress shape savanna dynamics, given their ecological and human importance.

Method: A minimalistic spatially extended model incorporating tree facilitation of grasses and competition for water, varying with tree life stage.

Result: The model predicts coexistence, bistability, and vegetation patterns under harsh conditions, with spatial dynamics preventing collapse or triggering tipping events.

Conclusion: Spatial patterns can act as early warnings for ecosystem transitions, highlighting the need for further research on their role in preventing or driving collapse.

Abstract: Tree-grass coexistence is a defining feature of savanna ecosystems, which
play an important role in supporting biodiversity and human populations
worldwide. While recent advances have clarified many of the underlying
processes, how these mechanisms interact to shape ecosystem dynamics under
environmental stress is not yet understood. Here, we present and analyze a
minimalistic spatially extended model of tree-grass dynamics in dry savannas.
We incorporate tree facilitation of grasses through shading and grass competing
with trees for water, both varying with tree life stage. Our model shows that
these mechanisms lead to grass-tree coexistence and bistability between savanna
and grassland states. Moreover, the model predicts vegetation patterns
consisting of trees and grasses, particularly under harsh environmental
conditions, which can persist in situations where a non-spatial version of the
model predicts ecosystem collapse from savanna to grassland instead (a
phenomenon called ''Turing-evades-tipping''). Additionally, we identify a novel
''Turing-triggers-tipping'' mechanism, where unstable pattern formation drives
tipping events that are overlooked when spatial dynamics are not included.
These transient patterns act as early warning signals for ecosystem
transitions, offering a critical window for intervention. Further theoretical
and empirical research is needed to determine when spatial patterns prevent
tipping or drive collapse.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [42] [A GENERIC-guided active learning SPH method for viscoelastic fluids using Gaussian process regression](https://arxiv.org/abs/2506.21877)
*Xuekai Dong,David Nieto Simavilla,Jie Ouyang,Xiaodong Wang,Marco Ellero*

Main category: physics.flu-dyn

TL;DR: A GENERIC-guided active learning SPH method (G²ALSPH) is proposed to learn viscoelastic constitutive relations, ensuring generalization and accuracy with active data acquisition and Gaussian process regression.


<details>
  <summary>Details</summary>
Motivation: Challenges in learning viscoelastic constitutive relations due to polymer history dependence and generalization issues in machine learning models.

Method: Uses GENERIC framework to simplify constitutive relations, employs active learning with GPR, and integrates SPH for numerical simulations.

Result: Validated with Poiseuille flows and cylinder array flows, showing effectiveness and accuracy compared to the Oldroyd-B model.

Conclusion: G²ALSPH is promising for data-driven viscoelastic fluid simulations, balancing accuracy and computational efficiency.

Abstract: When applying machine learning methods to learn viscoelastic constitutive
relations, the polymer history dependence in viscoelastic fluids and the
generalization ability of machine learning models are challenging. In this
paper, guided by the general equation for nonequilibrium
reversible-irreversible coupling (GENERIC) framework, a novel GENERIC-guided
active learning smoothed particle hydrodynamics (${\rm{G^2ALSPH}}$) method is
proposed to obtain effective constitutive relations for reliable simulations of
viscoelastic flows. By utilizing the GENERIC framework, the target viscoelastic
constitutive relation is reduced to a simple functional relation between the
eigenvalues of the conformation tensor and the eigenvalues of its
thermodynamically conjugated tensorial variable, which incorporates the
flow-history-dependent memory effect. Based on data and Gaussian process
regression (GPR), a new active learning strategy is developed to obtain the
simplified constitutive relation, in which the generalization ability is
ensured by actively acquiring more data points when needed. Moreover, a novel
relative uncertainty is devised to establish an accuracy evaluation tool for
the GPR prediction results, which reduces the number of required training data
points while maintaining accuracy. Furthermore, the SPH method combined with
the latest techniques serves as an effective macroscopic numerical method.
Eventually, the Poiseuille flows and the flows around a periodic array of
cylinders at different Weissenberg numbers are simulated to validate the
effectiveness and accuracy of the ${\rm{G^2ALSPH}}$ method. The Oldroyd-B model
is used as the ground truth constitutive relation to provide data for GPR,
bringing analytical solutions for comparison. The excellent performance
demonstrates that the ${\rm{G^2ALSPH}}$ method has promising applications in
data-driven simulations of viscoelastic fluids.

</details>


### [43] [A Multi-Species Enskog-Vlasov Solver to Determine Evaporation Coefficients of Fluids in High Pressure Environments](https://arxiv.org/abs/2506.22162)
*Raphael Tietz,Rolf Stierle,Kim Sophie Ellenberger,Stefanos Fasoulas,Marcel Pfeiffer*

Main category: physics.flu-dyn

TL;DR: A novel multi-species Enskog-Vlasov solver is introduced for high-pressure fluid evaporation, improving fuel mixing in engines. It uses species-specific collision handling and a new pair correlation function for accuracy. Validations show close matches with MD data and outperform traditional methods.


<details>
  <summary>Details</summary>
Motivation: The study aims to accurately model evaporation coefficients for fluids under high-pressure conditions, crucial for efficient fuel mixing in combustion engines, addressing gaps in multi-species interaction modeling.

Method: The solver employs a multi-species approach with separate collision handling and a BMCSL-based pair correlation function. Validation includes numerical simulations and comparisons with MD data and state-of-the-art models.

Result: The solver accurately predicts collision frequencies, liquid-vapor equilibria, and evaporation coefficients. It outperforms single-species methods, confirmed by comparisons with SAFT-VRQ Mie and density functional theory.

Conclusion: The solver advances multi-species evaporation modeling under high pressure, providing essential data for combustion and multi-phase fluid dynamics, though Onsager relations compliance needs further exploration.

Abstract: This paper introduces a novel multi-species Enskog-Vlasov solver. It is used
to determine evaporation coefficients of fluids under high-pressure conditions,
a critical factor for efficient fuel mixing in internal combustion engines. The
solver handles collisions for different fluid species separately, thereby
accurately capturing species-specific interactions essential for realistic
evaporation modeling. A new pair correlation function based on the BMCSL
equation of state is employed to enhance modeling accuracy, though compliance
with Onsager relations remains to be explored.
  Validation through various numerical simulations demonstrates the solver's
capability. Results from binary fluid relaxation simulations closely match
molecular dynamics (MD) data, highlighting accurate collision frequency
modeling. Comparative studies against state-of-the-art models verify the
solver's precision in predicting liquid-vapor equilibria and evaporation
coefficients across diverse pressure scenarios.
  Detailed simulations of argon-neon mixtures with realistic particle diameters
and masses underscore the significant improvements achieved by employing this
multi-species approach over traditional single-species methods. Comparisons
with the SAFT-VRQ Mie and classical density functional theory confirm the
solver's reliability in predicting liquid and vapor compositions and detailed
density profiles at interfaces over a wide range of pressures and temperatures.
  Further analyses illustrate complex dependencies of evaporation and
condensation coefficients on temperature and pressure, consistent with existing
research findings. Overall, this work advances computational modeling of
multi-species evaporation processes in high-pressure environments at different
temperatures, providing essential data for improved combustion modeling and
broader applications in multi-phase fluid dynamics.

</details>


### [44] [Physics-Informed Neural Networks: Bridging the Divide Between Conservative and Non-Conservative Equations](https://arxiv.org/abs/2506.22413)
*Arun Govind Neelan,Ferdin Sagai Don Bosco,Naveen Sagar Jarugumalli,Suresh Balaji Vedarethinam*

Main category: physics.flu-dyn

TL;DR: The paper examines how Physics-Informed Neural Networks (PINNs) perform with conservative vs. non-conservative PDE formulations, focusing on shocks and discontinuities in fluid dynamics.


<details>
  <summary>Details</summary>
Motivation: Traditional numerical methods require conservative PDE forms for accuracy, but many real-world PDEs are non-conservative, limiting solver applicability.

Method: The study tests PINNs on benchmark problems (Burgers equation, steady/unsteady Euler equations) to compare their sensitivity to PDE formulations.

Result: The investigation provides insights into PINNs' effectiveness in handling shocks and discontinuities with different PDE forms.

Conclusion: The work highlights PINNs' potential and limitations in solving non-conservative PDEs, offering a foundation for future improvements.

Abstract: In the realm of computational fluid dynamics, traditional numerical methods,
which heavily rely on discretization, typically necessitate the formulation of
partial differential equations (PDEs) in conservative form to accurately
capture shocks and other discontinuities in compressible flows. Conversely,
utilizing non-conservative forms often introduces significant errors near these
discontinuities or results in smeared shocks. This dependency poses a
considerable limitation, particularly as many PDEs encountered in complex
physical phenomena, such as multi-phase flows, are inherently non-conservative.
This inherent non-conservativity restricts the direct applicability of standard
numerical solvers designed for conservative forms. This work aims to thoroughly
investigate the sensitivity of Physics-Informed Neural Networks (PINNs) to the
choice of PDE formulation (conservative vs. non-conservative) when solving
problems involving shocks and discontinuities. We have conducted this
investigation across a range of benchmark problems, specifically the Burgers
equation and both steady and unsteady Euler equations, to provide a
comprehensive understanding of PINNs capabilities in this critical area.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [45] [High-frequency backreaction for the Einstein equations under $\mathbb U(1)$ symmetry: from Einstein-dust to Einstein-Vlasov](https://arxiv.org/abs/2506.21779)
*Cécile Huneau,Jonathan Luk*

Main category: gr-qc

TL;DR: The paper extends prior work by approximating localized solutions of the Einstein-massless Vlasov system with high-frequency vacuum spacetimes, generalizing from finite-sum delta measures to infinite families of dusts.


<details>
  <summary>Details</summary>
Motivation: To generalize previous approximations of Einstein-massless Vlasov solutions, which were limited to finite-sum delta measures, by allowing infinite families of dusts.

Method: Approximate solutions to the Einstein-massless Vlasov system via the Einstein-null dust system, then further approximate these by vacuum solutions, scaling the number of dust families to infinity.

Result: Localized solutions to the Einstein-massless Vlasov system can be approximated by high-frequency vacuum spacetimes, extending prior results.

Conclusion: The work successfully generalizes earlier constructions, demonstrating the feasibility of approximating Vlasov solutions with vacuum spacetimes for infinite dust families.

Abstract: Given suitable small, localized, $\mathbb U(1)$-symmetric solutions to the
Einstein-massless Vlasov system in an elliptic gauge, we prove that they can be
approximated by high-frequency vacuum spacetimes. This extends previous
constructions where the limiting spacetime solves the Einstein-(multiple) null
dust system (i.e., where the limiting massless Vlasov field can be written as a
finite sum of delta measures). The proof proceeds by first approximating
solutions to the Einstein-massless Vlasov system by solutions to the
Einstein-(multiple) null dust system, then approximating solutions to the
Einstein-null dust system by vacuum solutions. In the process, we take the
number of families of dusts to infinity.

</details>


<div id='nlin.PS'></div>

# nlin.PS [[Back]](#toc)

### [46] [Pattern formation in a Swift-Hohenberg equation with spatially periodic coefficients](https://arxiv.org/abs/2506.22211)
*Jolien Kamphuis,Martina Chirilus-Bruckner*

Main category: nlin.PS

TL;DR: The paper analyzes the Swift-Hohenberg equation with large periodic coefficients, identifying a Turing bifurcation leading to Bloch wave patterns modulated by Ginzburg-Landau solutions, distinguishing resonant and non-resonant regimes.


<details>
  <summary>Details</summary>
Motivation: To extend prior work on asymptotically small coefficients by studying pattern formation under O(1) forcing, revealing richer bifurcating solutions in Bloch space.

Method: The analysis is conducted directly in Bloch space, leveraging the interplay between forcing and intrinsic wavenumbers to distinguish resonant and non-resonant regimes.

Result: A Turing bifurcation generates Bloch wave patterns modulated by Ginzburg-Landau solutions, with the spectrum and patterns shaped by the wavenumber interplay.

Conclusion: The framework is applicable to complex systems like spatially heterogeneous reaction-diffusion equations, such as dryland vegetation models.

Abstract: We study the Swift-Hohenberg equation - a paradigm model for pattern
formation - with "large" spatially periodic coefficients and find a Turing
bifurcation that generates patterns whose leading order form is a Bloch wave
modulated by solutions of a Ginzburg-Landau type equation. Since the interplay
between forcing wavenumber and intrinsic wavenumber crucially shapes the
spectrum and emerging patterns, we distinguish between resonant and
non-resonant regimes. Extending earlier work that assumed asymptotically small
coefficients, we tackle the more involved onset analysis produced by O(1)
forcing and work directly in Bloch space, where the richer structure of the
bifurcating solutions becomes apparent. This abstract framework is readily
transferable to more complex systems, such as reaction-diffusion equations
arising as dryland vegetation models, where topography induces spatial
heterogeneity.

</details>
