{"id": "2506.22576", "pdf": "https://arxiv.org/pdf/2506.22576", "abs": "https://arxiv.org/abs/2506.22576", "authors": ["Hunter L Croix", "Alan E. Lindsay"], "title": "The lightning method for the heat equation", "categories": ["math.NA", "cs.NA", "math.CV"], "comment": null, "summary": "This paper introduces a new method for solving the planar heat equation based\non the Lightning Method. The lightning method is a recent development in the\nnumerical solution of linear PDEs which expresses solutions using sums of\npolynomials and rational functions, or more generally as sums of fundamental\nsolutions. The method is particularly well suited to handle domains with sharp\ncorners where solution singularities are present. Boundary conditions are\nformed on a set of collocation points which is then solved as an overdetermined\nlinear system. The approach of the present work is to utilize the Laplace\ntransform to obtain a modified Helmholtz equation which is solved by an\napplication of the lightning method. The numerical inversion of the Laplace\ntransform is then performed by means of Talbot integration. Our validation of\nthe method against existing results and multiple challenging test problems\nshows the method attains spectral accuracy with root-exponential convergence\nwhile being robust across a wide range of time intervals and adaptable to a\nvariety of geometric scenarios.", "AI": {"tldr": "A new method using the Lightning Method and Laplace transform solves the planar heat equation with spectral accuracy and root-exponential convergence.", "motivation": "To address challenges in solving the planar heat equation, especially in domains with sharp corners and singularities.", "method": "Combines the Lightning Method (using sums of polynomials/rational functions) with Laplace transform to solve a modified Helmholtz equation, followed by Talbot integration for numerical inversion.", "result": "Achieves spectral accuracy and root-exponential convergence, validated against existing results and test problems.", "conclusion": "The method is robust, adaptable to various geometries, and effective across different time intervals."}}
{"id": "2506.22615", "pdf": "https://arxiv.org/pdf/2506.22615", "abs": "https://arxiv.org/abs/2506.22615", "authors": ["James H. Adler", "Xiaozhe Hu", "Wenxiao Pan", "Zhongqin Xue"], "title": "Error Estimates for the Arnoldi Approximation of a Matrix Square Root", "categories": ["math.NA", "cs.NA", "65F60 65Z05 70-10"], "comment": null, "summary": "The Arnoldi process provides an efficient framework for approximating\nfunctions of a matrix applied to a vector, i.e., of the form $f(M)\\mathbf{b}$,\nby repeated matrix-vector multiplications. In this paper, we derive an\n\\textit{a priori} error estimate for approximating the action of a matrix\nsquare root using the Arnoldi process, where the integral representation of the\nerror is reformulated in terms of the error for solving the linear system\n$M\\mathbf{x}=\\mathbf{b}$. The results extend the error analysis of the Lanczos\nmethod for Hermitian matrices in [Chen et al., SIAM J. Matrix Anal. Appl.,\n2022] to non-Hermitian cases. Furthermore, to make the method applicable to\nlarge-scale problems, we assume that the matrices are preprocessed utilizing\ndata-sparse approximations preserving positive definiteness, and then establish\na refined error bound in this setting. The numerical results on matrices with\ndifferent structures demonstrate that our theoretical analysis yields a\nreliable upper bound. Finally, simulations on large-scale matrices arising in\nparticulate suspensions validate the effectiveness and practicality of the\napproach.", "AI": {"tldr": "The paper extends error analysis for approximating matrix square roots using the Arnoldi process to non-Hermitian matrices, refines bounds for large-scale problems, and validates results numerically.", "motivation": "To generalize error estimates for matrix square root approximations beyond Hermitian matrices and adapt the method for large-scale applications.", "method": "Derives an a priori error estimate using the Arnoldi process, reformulates error in terms of linear system solutions, and refines bounds for data-sparse approximations.", "result": "Theoretical analysis provides reliable error bounds, validated by numerical experiments on diverse matrices and large-scale simulations.", "conclusion": "The approach is effective for non-Hermitian matrices and scalable for large problems, as demonstrated by simulations."}}
{"id": "2506.22657", "pdf": "https://arxiv.org/pdf/2506.22657", "abs": "https://arxiv.org/abs/2506.22657", "authors": ["Andreas R\u00f6\u00dfler"], "title": "A Class of Stochastic Runge-Kutta Methods for Stochastic Differential Equations Converging with Order 1 in $L^p$-Norm", "categories": ["math.NA", "cs.NA", "math.PR", "65C30, 60H10, 65L06"], "comment": null, "summary": "For the approximation of solutions for It\\^o and Stratonovich stochastic\ndifferential equations (SDEs)a new class of efficient stochastic Runge-Kutta\n(SRK) methods is developed. As the main novelty only two stages are necessary\nfor the proposed SRK methods of order 1 that can be applied to SDEs with\nnon-commutative or with commutative noise. In addition, a variant of the SRK\nmethod for SDEs with additive noise is presented. All proposed SRK methods\ncover also the case of drift-implicit schemes and general order conditions for\nthe coefficients are calculated explicitly. The new class of SRK methods is\nhighly efficient in the sense that it features computational cost depending\nonly linearly on the dimension of the SDE and on the dimension of the driving\nWiener process. For all proposed SRK methods strong convergence with order 1 in\n$L^p$-norm for any $p \\geq 2$ is proved. Moreover, sufficient conditions for\napproximated iterated stochastic integrals are established such that\nconvergence with order 1 in $L^p$-norm is preserved if they are applied for the\nSRK method. The presented theoretical results are confirmed by numerical\nexperiments.", "AI": {"tldr": "A new class of efficient stochastic Runge-Kutta (SRK) methods is developed for solving It\u00f4 and Stratonovich SDEs, requiring only two stages for order 1, applicable to non-commutative or commutative noise.", "motivation": "To develop highly efficient SRK methods for SDEs with minimal computational cost and broad applicability.", "method": "Proposes two-stage SRK methods for order 1, including variants for additive noise and drift-implicit schemes, with explicit order conditions.", "result": "The methods are computationally efficient (linear cost in SDE and Wiener process dimensions) and achieve strong convergence of order 1 in L^p-norm (p \u2265 2).", "conclusion": "Theoretical results are validated numerically, confirming the efficiency and convergence properties of the new SRK methods."}}
{"id": "2506.22664", "pdf": "https://arxiv.org/pdf/2506.22664", "abs": "https://arxiv.org/abs/2506.22664", "authors": ["Haishen Dai", "Huan Lei"], "title": "Hybrid Explicit-Implicit Predictor-Corrector Exponential Time-Differencing Multistep Pad\u00e9 Schemes for Semilinear Parabolic Equations with Time-Delay", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we propose and analyze ETD-Multistep-Pad\\'{e}\n(ETD-MS-Pad\\'{e}) and ETD Implicit Multistep-Pad\\'{e} (ETD-IMS-Pad\\'{e}) for\nsemilinear parabolic delay differential equations with smooth solutions. In our\nprevious work [15], we proposed ETD-RK-Pad\\'{e} scheme to compute high-order\nnumerical solutions for nonlinear parabolic reaction-diffusion equation with\nconstant time delay. However, the based ETD-RK numerical scheme in [15] is very\ncomplex and the corresponding calculation program is also very complicated. We\npropose in this paper ETD-MS-Pad\\'{e} and ETD-IMS-Pad\\'{e} schemes for the\nsolution of semilinear parabolic equations with delay. We synergize the\nETD-MS-Pad\\'{e} with ETD-IMS-Pad\\'{e} to construct efficient\npredictor-corrector scheme. This new predictor-corrector scheme will become an\nimportant tool for solving the numerical solutions of parabolic differential\nequations. Remarkably, we also conducted experiments in Table$10$ to compare\nthe numerical results of the predictor-corrector scheme with the EERK scheme\nproposed in paper [42]. The predictor-corrector scheme demonstrated better\nconvergence.\n  The main idea is to employ an ETD-based Adams multistep extrapolation for the\ntime integration of the corresponding equation. To overcome the well-known\nnumerical instability associated with computing the exponential operator, we\nutilize the Pad\\'{e} approach to approximate this exponential operator. This\nmethodology leads to the development of the ETD-MS-Pad\\'{e} and\nETD-IMS-Pad\\'{e} schemes, applicable even for arbitrary time orders. We\nvalidate the ETD-MS1,2,3,4-Pad\\'{e} schemes and ETD-IMS2,3,4 schemes through\nnumerical experiments.", "AI": {"tldr": "Proposes ETD-MS-Pad\u00e9 and ETD-IMS-Pad\u00e9 schemes for semilinear parabolic delay differential equations, improving upon the complexity of previous ETD-RK-Pad\u00e9 methods. A predictor-corrector scheme is introduced, showing better convergence than existing methods.", "motivation": "To simplify and improve the numerical solution of semilinear parabolic delay differential equations, addressing the complexity and instability of previous methods.", "method": "Combines ETD-based Adams multistep extrapolation with Pad\u00e9 approximation for exponential operators, forming ETD-MS-Pad\u00e9 and ETD-IMS-Pad\u00e9 schemes, and validates them through numerical experiments.", "result": "The predictor-corrector scheme outperforms the EERK scheme in convergence, and the new methods are validated for arbitrary time orders.", "conclusion": "The proposed schemes are efficient tools for solving parabolic differential equations, offering improved stability and convergence."}}
{"id": "2506.22577", "pdf": "https://arxiv.org/pdf/2506.22577", "abs": "https://arxiv.org/abs/2506.22577", "authors": ["Haidar Al-Naseri", "Gert Brodin"], "title": "Probing the transition from classical to quantum radiation reaction in relativistic plasma", "categories": ["physics.plasm-ph", "hep-ph", "hep-th"], "comment": null, "summary": "We study the transition from classical radiation reaction, described by the\nLandau-Lifshitz model, to the quantum mechanical regime. The plasma is subject\nto a circularly polarized field where the self-consistent plasma current is the\nsource of the electromagnetic field through Ampere's law. The radiation\nreaction implies wave energy loss, frequency up-conversion, and a modified\ndistribution function. Increasing the value of the quantum $\\chi$-parameter,\nthe quantum results gradually differ from the classical ones. Moreover, the\ndeviation between models also depends on the plasma parameters, including\ndensity and temperature. We discuss the implications of our findings.", "AI": {"tldr": "The paper examines the shift from classical to quantum radiation reaction in a plasma under a circularly polarized field, highlighting differences due to the quantum \u03c7-parameter and plasma conditions.", "motivation": "To understand how quantum effects alter classical radiation reaction (Landau-Lifshitz model) in plasmas and how plasma parameters influence this transition.", "method": "The study uses a self-consistent plasma current model under a circularly polarized field, analyzing wave energy loss, frequency up-conversion, and distribution function changes.", "result": "Quantum effects diverge from classical predictions as the \u03c7-parameter increases, with deviations also tied to plasma density and temperature.", "conclusion": "The findings reveal the nuanced impact of quantum mechanics on radiation reaction, dependent on both \u03c7-parameter and plasma properties, with broader implications for plasma physics."}}
{"id": "2506.22453", "pdf": "https://arxiv.org/pdf/2506.22453", "abs": "https://arxiv.org/abs/2506.22453", "authors": ["Ehsan Roohi", "Ahmad Shoja-sani"], "title": "Data-Driven Surrogate Modeling of DSMC Solutions Using Deep Neural Networks", "categories": ["physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "This study presents a deep neural network (DNN) framework that accelerates\nDirect Simulation Monte Carlo (DSMC) computations for rarefied-gas flows, while\nmaintaining high physical fidelity. First, a fully connected deep neural\nnetwork is trained on high-quality DSMC data for seven temperatures (200-650 K)\nto reproduce the Maxwell-Boltzmann speed distribution of argon. Injecting the\nphysical boundary point into the training set enforces the correct low-speed\nlimit. It reduces the mean-squared error to below 10^-5, thereby decreasing\ninference time from tens of minutes per DSMC run to milliseconds. For\none-dimensional shock waves, a multi-output network equipped with learnable\nFourier features learns the complete profiles of density, velocity, and\ntemperature. Trained only on Mach numbers 1.4-1.9, it predicts a Mach 2 and 2.5\ncase with near-perfect agreement to DSMC, demonstrating robust out-of-training\ngeneralization. In a lid-driven cavity, the large parametric spread in Knudsen\nnumber is handled by a \"family-of-experts\" strategy: separate specialist models\nare trained at discrete Knudsen (Kn) values, and log-space interpolation fuses\ntheir outputs. This hybrid surrogate recovers the full 2-D velocity and\ntemperature fields at unseen Kn with less than 2% spatial error. Key\ninnovations include (i) explicit injection of physical constraints during data\npreprocessing, (ii) learnable Fourier feature mapping to capture steep shock\ngradients, and (iii) a modular expert-interpolation scheme to cover wide\nKnudsen ranges. Together, they establish a general recipe for trustworthy,\nrapid surrogate models that can be extended to non-equilibrium phenomena, gas\nmixtures, and design optimization workflows", "AI": {"tldr": "A DNN framework accelerates DSMC computations for rarefied-gas flows, maintaining high fidelity. Innovations include physical constraint injection, Fourier features for shocks, and expert-interpolation for Knudsen ranges.", "motivation": "To reduce the computational time of DSMC for rarefied-gas flows while preserving physical accuracy.", "method": "Uses a fully connected DNN trained on DSMC data, learnable Fourier features for shock waves, and a 'family-of-experts' strategy for varying Knudsen numbers.", "result": "Achieves near-perfect agreement with DSMC for shock waves and less than 2% error for lid-driven cavity flows, reducing inference time to milliseconds.", "conclusion": "The framework provides a general approach for rapid, accurate surrogate models applicable to non-equilibrium phenomena and design optimization."}}
{"id": "2506.22585", "pdf": "https://arxiv.org/pdf/2506.22585", "abs": "https://arxiv.org/abs/2506.22585", "authors": ["Gleiciane S. Arag\u00e3o", "Flank D. M. Bezerra", "Lucas G. Mendon\u00e7a"], "title": "Pullback dynamics for a semilinear heat equation with homogeneous Neumann boundary conditions on time-varying domains", "categories": ["math.AP", "35K90, 35B41, 37L05, 37L30, 35B20"], "comment": "28 pages, 1 figure", "summary": "We are interested in studying a non-autonomous semilinear heat equation with\nhomogeneous Neumann boundary conditions on time-varying domains. Using a\ndifferential geometry approach with coordinate transformations technique, we\nwill show that the non-autonomous problem on a time-varying domain is\nequivalent, in some sense, to a non-autonomous problem on a fixed domain.\nFurthermore, we intend to show the local existence and uniqueness of solutions\nto this problem, as well as, to extend these solutions globally. Finally, we\nwill show the existence of pullback attractors. To the best of our knowledge,\nresults on attractors are new even for non-autonomous semilinear heat equations\nwith homogeneous Neumann boundary conditions on time-varying domains subject to\nconditions with more restrictive assumptions", "AI": {"tldr": "The paper studies a non-autonomous semilinear heat equation on time-varying domains, using differential geometry to transform it into an equivalent problem on a fixed domain. It proves local and global solution existence, uniqueness, and introduces new results on pullback attractors.", "motivation": "To address the lack of results on attractors for non-autonomous semilinear heat equations on time-varying domains with homogeneous Neumann boundary conditions.", "method": "Differential geometry and coordinate transformations to equate the problem on time-varying domains to fixed domains, followed by analysis of solution existence, uniqueness, and attractors.", "result": "Local and global existence and uniqueness of solutions, plus new findings on pullback attractors for such equations.", "conclusion": "The study successfully extends understanding of non-autonomous semilinear heat equations on time-varying domains, particularly in terms of attractors."}}
{"id": "2506.22689", "pdf": "https://arxiv.org/pdf/2506.22689", "abs": "https://arxiv.org/abs/2506.22689", "authors": ["Yao Xiao", "Anne Gelb", "Aditya Viswanathan"], "title": "A new sparsity promoting residual transform operator for Lasso regression", "categories": ["math.NA", "cs.NA", "65F22, 62F15, 65K10, 68U10, 62J07"], "comment": null, "summary": "Lasso regression is a widely employed approach within the $\\ell_1$\nregularization framework used to promote sparsity and recover piecewise smooth\nsignals $f:[a,b) \\rightarrow \\mathbb{R}$ when the given observations are\nobtained from noisy, blurred, and/or incomplete data environments. In choosing\nthe regularizing sparsity-promoting operator, it is assumed that the particular\ntype of variability of the underlying signal, for example, piecewise constant\nor piecewise linear behavior across the entire domain, is both known and fixed.\nSuch an assumption is problematic in more general cases, e.g.~when a signal\nexhibits piecewise oscillatory behavior with varying wavelengths and\nmagnitudes. To address the limitations of assuming a fixed (and typically low\norder) variability when choosing a sparsity-promoting operator, this\ninvestigation proposes a novel residual transform operator that can be used\nwithin the Lasso regression formulation. In a nutshell, the idea is that for a\ngeneral piecewise smooth signal $f$, it is possible to design two operators\n$\\mathcal L_1$ and $\\mathcal L_2$ such that $\\mathcal L_1{\\boldsymbol f}\n\\approx \\mathcal L_2{\\boldsymbol f}$, where ${\\boldsymbol f} \\in \\mathbb{R}^n$\nis a discretized approximation of $f$, but $\\mathcal L_1 \\not\\approx \\mathcal\nL_2$. The corresponding residual transform operator, $\\mathcal L = \\mathcal\nL_1- \\mathcal L_2$, yields a result that (1) effectively reduces the\nvariability dependent error that occurs when applying either $\\mathcal L_1$ or\n$\\mathcal L_2$ to ${\\boldsymbol f}$, a property that holds even when $\\mathcal\nL_1{\\boldsymbol f} \\approx \\mathcal L_2{\\boldsymbol f}$ is not a good\napproximation to the true sparse domain vector of ${\\boldsymbol f}$, and (2)\ndoes not require $\\mathcal L_1$ or $\\mathcal L_2$ to have prior information\nregarding the variability of the underlying signal.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.23006", "pdf": "https://arxiv.org/pdf/2506.23006", "abs": "https://arxiv.org/abs/2506.23006", "authors": ["Daniels Krimans", "Hanno K\u00e4hlert"], "title": "Variational hydrodynamics of the classical Yukawa one-component plasma", "categories": ["physics.plasm-ph", "physics.flu-dyn"], "comment": "17 pages, 4 figures", "summary": "We consider a recently developed variational approach to the hydrodynamics of\nstrongly coupled plasmas [D. Krimans and S. Putterman, Phys. Fluids 36, 037131\n(2024)] and extend it to the Yukawa one-component plasma. This approach\ngeneralizes the ordinary hydrodynamic equations to finite length scales by\nexplicitly including terms that depend on the pair distribution function. After\ndiscussing the form of the Lagrangian, we derive equations of motion and\nexplicit formulas for the momentum and energy conservation laws. After\ndemonstrating consistency with thermodynamics, we consider the simpler linear\nregime and the dispersion laws. By comparing the longitudinal speed of sound to\nexisting numerical data, we find excellent agreement in the weak to moderate\nscreening regimes, while discrepancies arise at strong screening. The\nfinite-wavelength behavior of the longitudinal dispersion relation also shows\nexcellent agreement with simulations across a wide range of coupling and\nscreening parameters, even when the wavelength is comparable to the average\ninterparticle spacing. In addition to the linear regime, our variational\napproach has potential for application to nonlinear problems and other physical\nsystems.", "AI": {"tldr": "The paper extends a variational hydrodynamic approach to the Yukawa one-component plasma, deriving motion equations and conservation laws, and validating results with simulations.", "motivation": "To generalize hydrodynamic equations for strongly coupled plasmas to finite length scales, incorporating pair distribution effects.", "method": "A variational approach is used to derive equations of motion, momentum, and energy conservation laws, validated against thermodynamics and simulations.", "result": "Excellent agreement with numerical data for sound speed and dispersion relations in weak to moderate screening, with discrepancies at strong screening.", "conclusion": "The approach is effective for linear regimes and holds promise for nonlinear problems and other systems."}}
{"id": "2506.22559", "pdf": "https://arxiv.org/pdf/2506.22559", "abs": "https://arxiv.org/abs/2506.22559", "authors": ["Javier Ruiz-Pineda", "Jaime Romero-Barrientos", "Francisco Molina", "Marcelo Zambra", "Franco L\u00f3pez-Usquiano"], "title": "Extending OpenMC Validation to Spent Fuel Canisters: A Criticality Benchmark Against MCNP", "categories": ["physics.comp-ph", "physics.app-ph"], "comment": "10 pages, 5 figures, preprint submitted to Nuclear Engineering and\n  Technology", "summary": "OpenMC is an open-source Monte Carlo code with increasing relevance in\ncriticality safety and reactor physics applications. While its validation has\ncovered a broad range of systems, its performance in spent nuclear fuel storage\nscenarios remains limited in the literature. This work benchmarks OpenMC\nagainst MCNP for eleven configurations based on the KBS-3 disposal concept,\ninvolving variations in geometry, fuel composition (fresh vs spent), and\nenvironmental conditions (e.g., air, argon, flooding scenarios). Effective\nmultiplication factors (k-eff) and leakage fractions were evaluated for both\ncodes. Results show strong agreement, with code-to-code k-eff differences below\n0.8% in dry storage conditions, and consistent trends across all cases.\nNotably, OpenMC successfully captures inter-canister neutron interaction\neffects under periodic boundary conditions, demonstrating its applicability to\ndry storage configurations. This benchmark supports the extension of the\nvalidation domain of OpenMC toward SNF transport and disposal applications.", "AI": {"tldr": "OpenMC, an open-source Monte Carlo code, is benchmarked against MCNP for spent nuclear fuel storage scenarios, showing strong agreement in results.", "motivation": "To validate OpenMC's performance in spent nuclear fuel storage applications, an area with limited literature coverage.", "method": "Benchmarked OpenMC against MCNP for eleven KBS-3 disposal concept configurations, varying geometry, fuel composition, and environmental conditions. Evaluated k-eff and leakage fractions.", "result": "Strong agreement between OpenMC and MCNP, with k-eff differences below 0.8% in dry storage. OpenMC captures inter-canister neutron interactions effectively.", "conclusion": "The benchmark validates OpenMC's applicability to spent nuclear fuel storage, supporting its use in transport and disposal applications."}}
{"id": "2506.22731", "pdf": "https://arxiv.org/pdf/2506.22731", "abs": "https://arxiv.org/abs/2506.22731", "authors": ["Yoshikazu Giga", "Sho Katayama"], "title": "Remarks on graph-like forward self-similar solutions to the surface diffusion flow equations", "categories": ["math.AP"], "comment": null, "summary": "We clarify existence and non-existence of graph-like forward self-similar\nsolutions to the planar surface diffusion equations.", "AI": {"tldr": "The paper examines the existence and non-existence of graph-like forward self-similar solutions in planar surface diffusion equations.", "motivation": "To understand the behavior and properties of graph-like solutions in surface diffusion equations, which is crucial for modeling physical processes.", "method": "The study likely involves mathematical analysis and proofs to determine conditions for existence and non-existence of such solutions.", "result": "The paper clarifies under what conditions graph-like forward self-similar solutions exist or do not exist.", "conclusion": "The findings provide insights into the nature of solutions in planar surface diffusion equations, contributing to theoretical understanding."}}
{"id": "2506.22713", "pdf": "https://arxiv.org/pdf/2506.22713", "abs": "https://arxiv.org/abs/2506.22713", "authors": ["Weiwei Xu", "Weijie Shen", "Chang Liu", "Zhigang Jia"], "title": "A Novel Adaptive Low-Rank Matrix Approximation Method for Image Compression and Reconstruction", "categories": ["math.NA", "cs.NA"], "comment": "31 pages, 16 figures", "summary": "Low-rank matrix approximation plays an important role in various applications\nsuch as image processing, signal processing and data analysis. The existing\nmethods require a guess of the ranks of matrices that represent images or\ninvolve additional costs to determine the ranks. A novel efficient orthogonal\ndecomposition with automatic basis extraction (EOD-ABE) is proposed to compute\nthe optimal low-rank matrix approximation with adaptive identification of the\noptimal rank. By introducing a randomized basis extraction mechanism, EOD-ABE\neliminates the need for additional rank determination steps and can compute a\nrank-revealing approximation to a low-rank matrix. With a computational\ncomplexity of $O(mnr)$, where $m$ and $n$ are the dimensions of the matrix and\n$r$ is its rank, EOD-ABE achieves significant speedups compared to the\nstate-of-the-art methods. Experimental results demonstrate the superior speed,\naccuracy and robustness of EOD-ABE and indicate that EOD-ABE is a powerful tool\nfor fast image compression and reconstruction and hyperspectral image\ndimensionality reduction in large-scale applications.", "AI": {"tldr": "EOD-ABE is a novel method for low-rank matrix approximation that automatically identifies the optimal rank, eliminating the need for manual rank estimation. It offers speed, accuracy, and robustness, making it useful for image compression and dimensionality reduction.", "motivation": "Existing methods for low-rank matrix approximation require manual rank estimation or additional steps, which can be inefficient. EOD-ABE aims to automate this process for better efficiency and accuracy.", "method": "EOD-ABE uses a randomized basis extraction mechanism to compute rank-revealing approximations without additional rank determination steps. It has a computational complexity of O(mnr).", "result": "EOD-ABE outperforms state-of-the-art methods in speed, accuracy, and robustness, as demonstrated in experiments.", "conclusion": "EOD-ABE is an efficient and powerful tool for low-rank matrix approximation, particularly in large-scale applications like image compression and hyperspectral image processing."}}
{"id": "2506.23530", "pdf": "https://arxiv.org/pdf/2506.23530", "abs": "https://arxiv.org/abs/2506.23530", "authors": ["Yeongsun Lee", "Jace Waybright", "Jong-Kyu Park"], "title": "Investigation of resonant layer response in electron viscosity regime", "categories": ["physics.plasm-ph"], "comment": null, "summary": "We present a supplementary study of previous work in Waybright and Park\n[Phys. Plasmas 31, 022502 (2024)] which demonstrates a substantial effect of\nelectron viscosity on the resonant layer response to non-axisymmetric magnetic\nperturbations. A main refinement is to include a curl element of electron\nviscosity in the generalized Ohm's law. The refinement reveals a resonant layer\nresponse in the Electron Viscosity (EV) regime corresponding to slowly rotating\nand highly viscous plasmas.", "AI": {"tldr": "Study refines previous work by including electron viscosity in Ohm's law, revealing resonant layer response in viscous plasmas.", "motivation": "To explore the impact of electron viscosity on resonant layer response to magnetic perturbations.", "method": "Included a curl element of electron viscosity in the generalized Ohm's law.", "result": "Revealed a resonant layer response in the Electron Viscosity (EV) regime for slow, viscous plasmas.", "conclusion": "Electron viscosity significantly affects resonant layer dynamics in plasmas."}}
{"id": "2506.22614", "pdf": "https://arxiv.org/pdf/2506.22614", "abs": "https://arxiv.org/abs/2506.22614", "authors": ["Miguel Ayala", "Rustum Choksi", "Benedikt Wirth"], "title": "On the Structure of Carbon Nanotubes: Results from Computer-Assisted Proofs", "categories": ["physics.comp-ph", "math-ph", "math.MP"], "comment": null, "summary": "We present a toolbox based on computer-assisted proofs to rigorously study\nthe structure of capped carbon nanotubes. We model nanotubes as minimizers of\nan interatomic potential. Numerical simulations and validated computations\nproduce rigorous mathematical results about atomic distances and structural\nvariations. In particular, we rigorously measure the diameter, bond lengths,\nand bond angles of nanotubes and thereby precisely quantify oscillations near\nthe caps, differences between interaction potentials, and effects of nanotube\nsize or chirality. As an example, we observe that the caps induce diameter\noscillations along the tube (rather than a monotonous diameter equilibration)\nwith increasing spatial extent for less smooth interaction potentials.", "AI": {"tldr": "A toolbox using computer-assisted proofs rigorously analyzes capped carbon nanotubes, measuring atomic distances and structural variations.", "motivation": "To study the structure of capped carbon nanotubes with mathematical precision, quantifying oscillations and effects of interaction potentials.", "method": "Model nanotubes as minimizers of an interatomic potential, using numerical simulations and validated computations.", "result": "Rigorous measurements of diameter, bond lengths, and angles reveal oscillations near caps, differences in potentials, and effects of size/chirality.", "conclusion": "Caps induce diameter oscillations, with spatial extent increasing for less smooth potentials, challenging monotonic equilibration assumptions."}}
{"id": "2506.22759", "pdf": "https://arxiv.org/pdf/2506.22759", "abs": "https://arxiv.org/abs/2506.22759", "authors": ["Xing Wang", "Xiangjin Xu", "Cheng Zhang"], "title": "$L^p$-Logvinenko-Sereda sets and $L^p$-Carleson measures on compact manifolds", "categories": ["math.AP", "math.CA", "math.SP", "35P99, 58C35, 58C40"], "comment": "26 pages", "summary": "Marzo and Ortega-Cerd\\`a gave geometric characterizations for\n$L^p$-Logvinenko-Sereda sets on the standard sphere for all $1\\le p<\\infty$.\nLater, Ortega-Cerd\\`a and Pridhnani further investigated\n$L^2$-Logvinenko-Sereda sets and $L^2$-Carleson measures on compact manifolds\nwithout boundary. In this paper, we characterize $L^p$-Logvinenko-Sereda sets\nand $L^p$-Carleson measures on compact manifolds with or without boundary for\nall $1<p<\\infty$. Furthermore, we investigate $L^p$-Logvinenko-Sereda sets and\n$L^p$-Carleson measures for eigenfunctions on compact manifolds without\nboundary, and we completely characterize them on the standard sphere $S^m$ for\n$p > \\frac{2m}{m-1}$. For the range $p < \\frac{2m}{m-1}$, we conjecture that\n$L^p$-Logvinenko-Sereda sets for eigenfunctions on the standard sphere $S^m$\nare characterized by the tubular geometric control condition and we provide\nsome evidence. These results provide new progress on an open problem raised by\nOrtega-Cerd\\`a and Pridhnani.", "AI": {"tldr": "The paper extends geometric characterizations of $L^p$-Logvinenko-Sereda sets and $L^p$-Carleson measures to compact manifolds with or without boundary for $1<p<\\infty$, and investigates these for eigenfunctions, providing partial solutions and conjectures for the standard sphere.", "motivation": "To generalize and extend previous work on $L^p$-Logvinenko-Sereda sets and $L^p$-Carleson measures to broader settings, including manifolds with boundary, and to address an open problem raised by Ortega-Cerd\u00e0 and Pridhnani.", "method": "The authors characterize $L^p$-Logvinenko-Sereda sets and $L^p$-Carleson measures on compact manifolds, with or without boundary, and investigate these for eigenfunctions, particularly on the standard sphere.", "result": "Complete characterization for $p > \\frac{2m}{m-1}$ on the standard sphere, and partial results with conjectures for $p < \\frac{2m}{m-1}$.", "conclusion": "The work advances understanding of $L^p$-Logvinenko-Sereda sets and Carleson measures, offering new insights and partial solutions to an open problem."}}
{"id": "2506.22782", "pdf": "https://arxiv.org/pdf/2506.22782", "abs": "https://arxiv.org/abs/2506.22782", "authors": ["Yingwen Guo", "Yinnian He", "Wenlin Qiu", "Xiangcheng Zheng"], "title": "Long-time error estimate and decay of finite element method to a generalized viscoelastic flow", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This work analyzes the finite element approximation to a viscoelastic flow\nmodel, which generalizes the Navier-Stokes equation and Oldroyd's model by\nintroducing the tempered power-law memory kernel. We prove regularity and\nlong-time exponential decay of the solutions, as well as a long-time\nconvolution-type Gr\\\"onwall inequality to support numerical analysis. A\nVolterra-Stokes projection is developed and analyzed to facilitate the\nparabolic-type duality argument, leading to the long-time error estimates and\nexponential decay of velocity and pressure. A benchmark problem of planar\nfour-to-one contraction flow is simulated to substantiate the generality of the\nproposed model in comparison with the Navier-Stokes equation and Oldroyd's\nmodel.", "AI": {"tldr": "The paper analyzes a viscoelastic flow model using finite element approximation, proving solution regularity, long-time decay, and numerical error estimates. A benchmark simulation validates the model.", "motivation": "To generalize the Navier-Stokes equation and Oldroyd's model by introducing a tempered power-law memory kernel for viscoelastic flows.", "method": "Develops a Volterra-Stokes projection for parabolic-type duality, proves regularity, and uses finite element approximation. Simulates a benchmark problem for validation.", "result": "Proves solution regularity, long-time exponential decay, and provides error estimates. Benchmark shows model generality.", "conclusion": "The proposed model effectively generalizes existing models, with proven theoretical properties and practical validation."}}
{"id": "2506.23548", "pdf": "https://arxiv.org/pdf/2506.23548", "abs": "https://arxiv.org/abs/2506.23548", "authors": ["K. Ogura", "M. S. Pirozhkova", "A. Sagisaka", "T. Zh. Esirkepov", "A. Ya. Faenov", "T. A. Pikuz", "H. Kotaki", "Y. Hayashi", "Y. Fukuda", "J. K. Koga", "S. V. Bulanov", "H. Daido", "N. Hasegawa", "M. Ishino", "M. Nishikino", "M. Koike", "T. Kawachi", "H. Kiriyama", "M. Kando", "D. Neely", "A. S. Pirozhkov"], "title": "Alloharmonics in Burst Intensification by Singularity Emitting Radiation", "categories": ["physics.plasm-ph"], "comment": "7 pages, 5 figures", "summary": "Burst Intensification by Singularity Emitting Radiation (BISER) in underdense\nrelativistic laser plasma is a bright source of coherent extreme ultraviolet\n(XUV) and x-ray radiation. In contrast to all harmonic generation mechanisms,\nhigh-resolution experimental BISER spectra in the XUV region contain spectral\nfringes with separation much finer (down to 0.12 eV) than the initial driving\nlaser frequency (~1.5 eV). We show that these fringe separations result from\ntwo main factors: laser frequency downshift (redshift) due to the\nquasi-adiabatic energy loss to the plasma waves, and spectral interference of\ndifferent harmonic orders from different emission moments, i.e. alloharmonics\n[Pirozhkova et al., arXiv:2306.01018]", "AI": {"tldr": "BISER in underdense relativistic laser plasma produces coherent XUV and x-ray radiation with fine spectral fringes, explained by laser redshift and alloharmonic interference.", "motivation": "To understand the fine spectral fringes in BISER spectra, which differ from traditional harmonic generation mechanisms.", "method": "Analyzed high-resolution experimental BISER spectra in the XUV region, focusing on fringe separation and its causes.", "result": "Fringe separations are due to laser frequency redshift and spectral interference of alloharmonics from different emission moments.", "conclusion": "BISER's spectral fringes are uniquely explained by redshift and alloharmonic interference, distinguishing it from other harmonic generation methods."}}
{"id": "2506.22662", "pdf": "https://arxiv.org/pdf/2506.22662", "abs": "https://arxiv.org/abs/2506.22662", "authors": ["Lushun Fan", "Yuqin Xia", "Jun Li", "Karl Jenkins"], "title": "AirCANS: CFD 2D Mesh Optimisation-based Airfoil Classification and Assessment using Neural Networks", "categories": ["physics.comp-ph"], "comment": null, "summary": "This study explores the possibilities of automating the loading,\nclassification and assessment of Computational Fluid Dynamics (CFD) mesh data\nby Convolutional Neural Networks (CNNs). The research aim is finding a feasible\nway to quickly make classification and assessment on airfoil mesh data. For\nthis purpose, this study designed a new framework named CFD-based airfoil\nClassification and Assessment Network (AirCANS) for CFD mesh data which\nincluding the data loader and improved the CNN structure to achieve our target.\nIn our research, we found that CNNs are fully adaptable as well as\nunderstandable to CFD airfoil mesh data structures, which suggests that our\nhypothesis is successful and that neural networks can be used to have a greater\npositive impact on the CFD industry, such as it can be used to refine the mesh\nand accelerate the solution. This could allow CFD to spend much less time.", "AI": {"tldr": "The study proposes AirCANS, a CNN-based framework for automating the classification and assessment of CFD airfoil mesh data, showing CNNs are effective for this task and can benefit the CFD industry.", "motivation": "To automate and speed up the classification and assessment of CFD mesh data, particularly for airfoils, using neural networks.", "method": "Developed AirCANS, a framework with a data loader and improved CNN structure tailored for CFD mesh data.", "result": "CNNs are adaptable and effective for CFD airfoil mesh data, validating the hypothesis and suggesting potential industry benefits like faster solutions and refined meshes.", "conclusion": "Neural networks like AirCANS can significantly improve efficiency in the CFD industry by automating mesh data tasks."}}
{"id": "2506.22869", "pdf": "https://arxiv.org/pdf/2506.22869", "abs": "https://arxiv.org/abs/2506.22869", "authors": ["Davide Tramontana"], "title": "Subelliptic Random Walks on Riemannian Manifolds and Their Convergence to Equilibrium", "categories": ["math.AP", "math.PR", "58J65, 58J51, 60G50, 60J10"], "comment": null, "summary": "The aim of this work is to study the convergence to equilibrium of an\n$(h,\\rho)$-subelliptic random walk on a closed, connected Riemannian manifold\n$(M,g)$ associated with a subelliptic second-order differential operator $A$ on\n$M$. In such a random walk, $h$ roughly represents the step size and $\\rho$ the\nspeed at which it is carried out. To construct the random walk and prove the\nconvergence result, we employ a technique due to Fefferman and Phong, which\nreduces the problem to the study of a constant-coefficient operator $\\tilde{A}$\nthat is locally equivalent to our second-order subelliptic operator $A$, in the\nsense that the diffusion generated by $\\tilde{A}$ induces a local diffusion for\n$A$. By using the compactness of $M$ this local diffusion can be lifted to a\nglobal diffusion, and the convergence result is then obtained via the spectral\ntheory of the associated Markov operator.", "AI": {"tldr": "Study of convergence to equilibrium for an $(h,\rho)$-subelliptic random walk on a Riemannian manifold using Fefferman-Phong technique and spectral theory.", "motivation": "To understand the equilibrium behavior of subelliptic random walks on closed, connected Riemannian manifolds.", "method": "Uses Fefferman-Phong technique to reduce the problem to a constant-coefficient operator, then leverages compactness and spectral theory.", "result": "Convergence to equilibrium is proven for the constructed random walk.", "conclusion": "The method successfully demonstrates convergence, linking local and global diffusion properties."}}
{"id": "2506.22831", "pdf": "https://arxiv.org/pdf/2506.22831", "abs": "https://arxiv.org/abs/2506.22831", "authors": ["Raphael M\u00fcnster", "Otto Mierka", "Dmitri Kuzmin", "Stefan Turek"], "title": "A Chimera domain decomposition method with weak Dirichlet-Robin coupling for finite element simulation of particulate flows", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We introduce a new multimesh finite element method for direct numerical\nsimulation of incompressible particulate flows. The proposed approach falls\ninto the category of overlapping domain decomposition / Chimera / overset grid\nmeshes. In addition to calculating the velocity and pressure of the fictitious\nfluid on a fixed background mesh, we solve the incompressible Navier-Stokes\nequations on body-fitted submeshes that are attached to moving particles. The\nsubmesh velocity and pressure are used to calculate the hydrodynamic forces and\ntorques acting on the particles. The coupling with the background velocity and\npressure is enforced via (i) Robin-type boundary conditions for an\nArbitrary-Lagrangian-Eulerian (ALE) formulation of the submesh problems and\n(ii) a Dirichlet-type distributed interior penalty term in the weak form of the\nbackground mesh problem. The implementation of the weak Dirichlet-Robin\ncoupling is discussed in the context of discrete projection methods and finite\nelement discretizations. Detailed numerical studies are performed for standard\ntest problems involving fixed and moving immersed objects. A comparison of\nChimera results with those produced by fictitious boundary methods illustrates\nsignificant gains in the accuracy of drag and lift approximations.", "AI": {"tldr": "A multimesh finite element method for incompressible particulate flows is introduced, combining background and body-fitted submeshes for accurate force and torque calculations.", "motivation": "To improve accuracy in simulating particulate flows by leveraging overlapping domain decomposition and coupling techniques.", "method": "Uses overlapping meshes (background and body-fitted submeshes) with Robin and Dirichlet-type coupling for solving Navier-Stokes equations.", "result": "Demonstrates significant accuracy gains in drag and lift approximations compared to fictitious boundary methods.", "conclusion": "The proposed method enhances simulation accuracy for particulate flows, validated through numerical studies."}}
{"id": "2506.23593", "pdf": "https://arxiv.org/pdf/2506.23593", "abs": "https://arxiv.org/abs/2506.23593", "authors": ["Daniele Villa", "Nicolas Dubuit", "Olivier Agullo", "Xavier Garbet"], "title": "The interaction of turbulence, magnetic islands and zonal fields in fluid plasma models with cubic non-linearities", "categories": ["physics.plasm-ph"], "comment": null, "summary": "It is shown that magnetic islands generated by pressure-gradient-driven\nturbulence are common across a wide range of conditions. The interaction among\nturbulence, magnetic island and other large scale structures (the zonal flow\nand the zonal current), largely determines the dynamics of the system.\nTurbulence takes a background role, providing energy to the large-scale\nstructures, without influencing their evolution directly. The growth of the\nzonal current is linearly related to that of the magnetic island, while the\nzonal flow has a strongly sheared region where the island has its maximum\nradial extension. The zonal current is found to slow down the formation of\nlarge-scale magnetic islands, while the zonal flow is needed to have the system\nmove its energy to larger and larger scales. The driving instability in the\nsystem is the fluid Kinetic Ballooning Mode (KBM) instability at high beta,\nwhile the tearing mode is kept stable. The formation of magnetic-island-like\nstructures at the spatial scale of the fluid KBM instability is observed quite\nearly in the non-linear phase for most cases studied, and a slow coalescence\nprocess evolves the magnetic structures towards larger and larger scales. Cases\nthat did not show this coalescence process, nor the formation of the small\nscale island-like structures, were seen to have narrower mode structures for\ncomparable instability growth rates, which was achieved by varying the magnetic\nshear. The islands often end up exceeding the radial box size late in the\nnon-linear phase, showing unbounded growth. The impact on the pressure profile\nof turbulence driven magnetic islands is not trivial, showing flattening of the\npressure profile only far from the resonance, where the zonal flow is weaker,\nand the appearance of said flattening is slow, after the island has reached a\nsufficiently large size, when compared with collisional time scales.", "AI": {"tldr": "Magnetic islands from pressure-gradient-driven turbulence are common, interacting with zonal flows and currents, influencing system dynamics. Turbulence energizes large-scale structures indirectly. Zonal current slows island formation, while zonal flow aids energy transfer to larger scales. KBM instability drives the system, with islands forming early and coalescing over time.", "motivation": "To understand the role of turbulence-driven magnetic islands and their interaction with zonal flows and currents in plasma dynamics.", "method": "Analyzed interactions among turbulence, magnetic islands, zonal flow, and zonal current, focusing on KBM instability and tearing mode stability.", "result": "Magnetic islands form early, coalesce to larger scales, and show unbounded growth. Zonal current slows island formation, while zonal flow aids energy transfer. Pressure profile flattening occurs far from resonance.", "conclusion": "Turbulence-driven magnetic islands and their interactions with zonal structures are key to plasma dynamics, with implications for energy transfer and pressure profile evolution."}}
{"id": "2506.23020", "pdf": "https://arxiv.org/pdf/2506.23020", "abs": "https://arxiv.org/abs/2506.23020", "authors": ["Siyang Ling"], "title": "Generating Moving Field Initial Conditions with Spatially Varying Boost", "categories": ["physics.comp-ph", "astro-ph.CO", "gr-qc", "math-ph", "math.MP"], "comment": "5 pages, 4 figures. Supplementary materials: 4 pages. See\n  https://github.com/hypermania/Cosmic-Fields-Lite for associated code", "summary": "We introduce a novel class of algorithms, the ``spatially varying boost'',\nfor generating dynamical field initial conditions with prescribed bulk\nvelocities. Given (non-moving) initial field data, the algorithm generates new\ninitial data with the given velocity profile by performing local Lorentz\nboosts. This algorithm is generic, with no restriction on the type of the\nfield, the equation of motion, and can endow fields with ultra-relativistic\nvelocities. This algorithm enables new simulations in different branches of\nphysics, including cosmology and condensed matter physics. For demonstration,\nwe used this algorithm to (1) boost two Sine-Gordon solitons to\nultra-relativistic speeds for subsequent collision, (2) generate a relativistic\ntransverse Proca field with random velocities, and (3) set up a spin-$1$\nSchr\\\"{o}dinger-Poisson field with velocity and density perturbations\nconsistent with dark matter in matter dominated universe.", "AI": {"tldr": "A novel algorithm, 'spatially varying boost,' generates dynamical field initial conditions with prescribed bulk velocities by applying local Lorentz boosts to non-moving initial data.", "motivation": "To enable simulations of fields with ultra-relativistic velocities across various physics domains like cosmology and condensed matter.", "method": "The algorithm performs local Lorentz boosts on initial field data to achieve desired velocity profiles, applicable to any field type or equation of motion.", "result": "Demonstrated effectiveness in boosting Sine-Gordon solitons, generating relativistic Proca fields, and setting up Schr\u00f6dinger-Poisson fields for dark matter simulations.", "conclusion": "The algorithm is versatile and opens new possibilities for simulations in physics, particularly for ultra-relativistic scenarios."}}
{"id": "2506.22874", "pdf": "https://arxiv.org/pdf/2506.22874", "abs": "https://arxiv.org/abs/2506.22874", "authors": ["Giusy Mazzone"], "title": "Local well-posedness of the equations governing the motion of a fluid-filled elastic solid", "categories": ["math.AP", "35Q35, 76D05, 74B05, 74B10, 35K61, 35L20"], "comment": "50 pages, 1 figure", "summary": "We consider the fluid-structure interaction problem of a viscous\nincompressible fluid contained in an elastic solid whose motion is not\nprescribed. The equations governing the motion of the solid are given by the\nNavier equations of linear elasticity, whereas the fluid motion is described by\nthe Navier-Stokes equations. We prove that the governing equations admit a\nunique strong solution corresponding to non-zero initial data for the solid\ninitial displacement and velocity, and for a fluid initial velocity in\n$H^{5/2}$.", "AI": {"tldr": "The paper proves the existence of a unique strong solution for a fluid-structure interaction problem involving a viscous incompressible fluid and an elastic solid.", "motivation": "To address the challenge of modeling and solving the interaction between a fluid and an elastic solid, where the solid's motion is not predefined.", "method": "The Navier equations of linear elasticity describe the solid's motion, while the Navier-Stokes equations describe the fluid's motion. The study focuses on non-zero initial conditions for the solid and fluid.", "result": "A unique strong solution is proven for the governing equations under specified initial conditions, including fluid velocity in $H^{5/2}$.", "conclusion": "The paper successfully establishes the existence and uniqueness of solutions for the given fluid-structure interaction problem."}}
{"id": "2506.22912", "pdf": "https://arxiv.org/pdf/2506.22912", "abs": "https://arxiv.org/abs/2506.22912", "authors": ["Ziheng Chen", "Bj\u00f6rn Engquist"], "title": "A Dilation-based Seamless Multiscale Method For Elliptic Problems", "categories": ["math.NA", "cs.NA", "74Q05, 35B27, 65N30, 65N06, 74Q15"], "comment": null, "summary": "Many numerical methods for multiscale differential equations require a scale\nseparation between the larger and the smaller scales to achieve accuracy and\ncomputational efficiency. In the area of multiscale dynamical systems,\nso-called, seamless methods have been introduced to reduce the requirement of\nscale separation. We will translate these methods to numerical homogenization\nproblems and extend the technique to multiple dimensions. The initial step is\nto prove that a one-dimensional \\sepia{second-order} elliptic operator with\noscillatory coefficients can be rewritten as a multiscale dynamical system.\nInspired by this, multiscale elliptic operators in higher dimensions are\napproximated by a novel approach based on local dilation, which provides a\nmiddle ground for balancing intractability and accuracy without the need for\nfull resolution. The dilation operator can be further generalized to preserve\nimportant structures by properly decomposing the coefficient field. Error\nestimates are developed and promising numerical results of different examples\nare included.", "AI": {"tldr": "The paper introduces seamless methods for multiscale problems, extending them to numerical homogenization in multiple dimensions. It proves a 1D elliptic operator can be rewritten as a multiscale dynamical system and proposes a novel local dilation approach for higher dimensions, balancing accuracy and computational efficiency.", "motivation": "To reduce the reliance on scale separation in multiscale problems, enabling more efficient and accurate numerical methods for homogenization.", "method": "Translates seamless methods from multiscale dynamical systems to numerical homogenization, proves a 1D elliptic operator can be rewritten as a multiscale system, and introduces a local dilation approach for higher dimensions.", "result": "Develops error estimates and demonstrates promising numerical results for various examples.", "conclusion": "The proposed methods provide a practical balance between accuracy and computational efficiency for multiscale problems without requiring full resolution."}}
{"id": "2506.23668", "pdf": "https://arxiv.org/pdf/2506.23668", "abs": "https://arxiv.org/abs/2506.23668", "authors": ["Chiara Badiali", "Rafael Almeida", "Bernardo Malaca", "Ricardo Fonseca", "Thales Silva", "Jorge Vieira"], "title": "Plasma Accelerator For Decaying Particle", "categories": ["physics.plasm-ph", "physics.acc-ph"], "comment": "6 pages, 4 figures", "summary": "We introduce a plasma wakefield acceleration scheme capable of boosting\ninitially subrelativistic particles to relativistic velocities within\nmillimeter-scale distances. A subluminal light pulse drives a wake whose\nvelocity is continuously matched to the beam speed through a tailored plasma\ndensity, thereby extending the dephasing length. We develop a theoretical model\nthat is generalizable across particle mass, initial velocity, and the\nparticular accelerating bucket being used, and we verify its accuracy with\nparticle-in-cell simulations using laser drivers with energies in the Joule\nrange.", "AI": {"tldr": "A plasma wakefield acceleration scheme boosts subrelativistic particles to relativistic speeds over millimeter distances using a tailored plasma density and subluminal light pulse.", "motivation": "To extend the dephasing length and efficiently accelerate particles from subrelativistic to relativistic velocities.", "method": "A theoretical model generalizable across particle mass, initial velocity, and accelerating bucket, validated with particle-in-cell simulations using Joule-range laser drivers.", "result": "Successful acceleration of particles to relativistic velocities within millimeter-scale distances, verified by simulations.", "conclusion": "The scheme effectively extends dephasing length and accelerates particles efficiently, with potential for broader applications."}}
{"id": "2506.23357", "pdf": "https://arxiv.org/pdf/2506.23357", "abs": "https://arxiv.org/abs/2506.23357", "authors": ["Dimitrios C. Rodopoulos", "Panos Pantidis", "Nikolaos Karathanasopoulos"], "title": "Variational PINNs with tree-based integration and boundary element data in the modeling of multi-phase architected materials", "categories": ["physics.comp-ph"], "comment": null, "summary": "The current contribution develops a Variational Physics-Informed Neural\nNetwork (VPINN)-based framework for the analysis and design of multiphase\narchitected solids. The elaborated VPINN methodology is based on the\nPetrov-Galerkin approach, with a deep neural network acting as trial function\nand local polynomials as test functions. For the analysis, a Galerkin Boundary\nElement Method (GBEM) scheme is developed to generate the mechanical field\ndata, employing solely domain boundary information. The VPINN methodology is\ncomplemented by an adaptive, tree-based integration scheme for the evaluation\nof the weak-form integrals. Different double-phase material architectures are\nconsidered, with the VPINNs demonstrating their ability to capture the\ndeformation fields with considerable accuracy. Moreover, the performance\nenhancement by the incorporation of additional semi-analytical information at\nauxiliary internal points is analyzed. Tree-based integration schemes are shown\nto be capable of robustly capturing inner material discontinuities upon\nsubstantial computational cost reductions. The results suggest that the\nproposed VPINN formulation offers comparative advantages in the modeling of\nmultiphase architected materials compared to classical PINN formulations. The\nanalysis paves the way for the development of variational physics-informed\ncomputational models for the mechanical analysis of complex architected\nmultiphase materials and structures.", "AI": {"tldr": "A VPINN framework for multiphase architected solids is developed, using a Petrov-Galerkin approach with neural networks and local polynomials. It includes adaptive tree-based integration and demonstrates accurate deformation field capture.", "motivation": "To improve modeling of multiphase architected materials by combining neural networks with physics-informed methods for better accuracy and efficiency.", "method": "VPINN methodology with Petrov-Galerkin approach, neural networks as trial functions, local polynomials as test functions, and adaptive tree-based integration. GBEM generates mechanical field data.", "result": "VPINNs accurately capture deformation fields and handle material discontinuities with reduced computational cost, outperforming classical PINNs.", "conclusion": "The VPINN framework is advantageous for modeling multiphase architected materials, enabling future development of physics-informed computational models for complex structures."}}
{"id": "2506.22913", "pdf": "https://arxiv.org/pdf/2506.22913", "abs": "https://arxiv.org/abs/2506.22913", "authors": ["Guillaume Valette"], "title": "$W^{1,p}$ priori estimates for solutions of linear elliptic PDEs on subanalytic domains", "categories": ["math.AP", "35B45, 35A21, 32B20, 14P10"], "comment": null, "summary": "We prove a priori estimates for solutions of order $2$ linear elliptic PDEs\nin divergence form on subanalytic domains. More precisely, we study the\nsolutions of a strongly elliptic equation $Lu=f$, with $f\\in\nL^2(\\mathcal{\\Omega})$ and $Lu=div (A(x) \\nabla u)$, and, given a bounded\nsubanalytic domain $\\mathcal{\\Omega}$, possibly admitting non metrically\nconical singularities within its boundary, we provide explicit conditions on\nthe tangent cone of the singularities of the boundary which ensure that\n$||u||_{ W^{1,p}(\\mathcal{\\Omega})}\\le C||f||_{L^2(\\mathcal{\\Omega})}$, for\nsome $p>2$. The number $p$ depends on the geometry of the singularities of\n$\\delta \\mathcal{\\Omega}$, but not on $u$.", "AI": {"tldr": "The paper establishes a priori estimates for solutions of second-order linear elliptic PDEs on subanalytic domains with singular boundaries, ensuring $W^{1,p}$ bounds for $p>2$.", "motivation": "To understand how the geometry of singularities in the boundary of subanalytic domains affects the regularity of solutions to elliptic PDEs.", "method": "Analyzes solutions of the equation $Lu=f$ on bounded subanalytic domains, focusing on conditions related to the tangent cones of boundary singularities.", "result": "Proves $||u||_{W^{1,p}} \\le C||f||_{L^2}$ for some $p>2$, where $p$ depends on the boundary's singularity geometry.", "conclusion": "The geometry of boundary singularities determines the regularity of solutions, independent of the solution itself."}}
{"id": "2506.22918", "pdf": "https://arxiv.org/pdf/2506.22918", "abs": "https://arxiv.org/abs/2506.22918", "authors": ["Mark Fornace", "Michael Lindsey"], "title": "An approximation theory for Markov chain compression", "categories": ["math.NA", "cs.NA", "math.PR"], "comment": null, "summary": "We develop a framework for the compression of reversible Markov chains with\nrigorous error control. Given a subset of selected states, we construct reduced\ndynamics that can be lifted to an approximation of the full dynamics, and we\nprove simple spectral and nuclear norm bounds on the recovery error in terms of\na suitably interpreted Nystr\\\"{o}m approximation error. We introduce two\ncompression schemes: a projective compression based on committor functions and\na structure-preserving compression defined in terms of an induced Markov chain\nover the selected states. The Nystr\\\"{o}m error appearing in our bounds can be\ncontrolled using recent results on column subset selection by nuclear\nmaximization. Numerical experiments validate our theory and demonstrate the\nscalability of our approach.", "AI": {"tldr": "A framework for compressing reversible Markov chains with error control, using two compression schemes and validated by numerical experiments.", "motivation": "To provide a method for compressing reversible Markov chains while rigorously controlling approximation errors.", "method": "Two compression schemes: projective (using committor functions) and structure-preserving (induced Markov chain). Error bounds are derived using Nystr\u00f6m approximation.", "result": "Theoretical bounds on recovery error are proven, and numerical experiments confirm scalability.", "conclusion": "The framework effectively compresses Markov chains with controlled error, validated by scalable numerical results."}}
{"id": "2506.23718", "pdf": "https://arxiv.org/pdf/2506.23718", "abs": "https://arxiv.org/abs/2506.23718", "authors": ["E. Gerstmayr", "B. Kettle", "M. J. V. Streeter", "L. Tudor", "O. J. Finlay", "L. E. Bradley", "R. Fitzgarrald", "T. Foster", "P. Gellersen", "A. E. Gunn", "O. Lawrence", "P. P. Rajeev", "B. K. Russell", "D. R. Symes", "C. D. Murphy", "A. G. R. Thomas", "C. P. Ridgers", "G. Sarri", "S. P. D. Mangles"], "title": "High brightness multi-MeV photon source driven by a petawatt-scale laser wakefield accelerator", "categories": ["physics.plasm-ph", "physics.acc-ph"], "comment": "8 pages, 5 figures", "summary": "We present an experimental demonstration of a bright multi-MeV gamma source\ndriven by a petawatt laser. The source generates on average\n$(1.2\\pm0.6)\\times10^9$ photons above 1 MeV per pulse, exceeding those of\nprevious all-optical sources by a hundred times, and reached a peak spectral\nbrightness of $(3.9 \\pm 1.5)\\times 10^{22}$ photons/mm$^2$/mrad$^2$/s/0.1%BW at\n$\\epsilon_\\gamma\\approx11$ MeV. The source was produced by inverse Compton\nscattering of a laser wakefield accelerated GeV electron beam and its\nback-reflected driving laser pulse, and is well described by a simple model of\nthe laser and electron properties at the collision point. Our results highlight\nthe promise of this source for fundamental physics studies, as well as for\napplications of nuclear resonance fluorescence and nuclear transmutation.", "AI": {"tldr": "A petawatt laser-driven gamma source produces 1.2\u00d710^9 photons above 1 MeV per pulse, surpassing previous sources by 100x, with peak brightness of 3.9\u00d710^22 photons/mm\u00b2/mrad\u00b2/s/0.1%BW at 11 MeV.", "motivation": "To demonstrate a high-brightness, multi-MeV gamma source for fundamental physics and applications like nuclear resonance fluorescence and transmutation.", "method": "Inverse Compton scattering of a GeV electron beam (laser wakefield accelerated) and its back-reflected driving laser pulse.", "result": "Achieved unprecedented photon yield and brightness, validated by a simple model of laser and electron properties.", "conclusion": "The source shows great potential for fundamental physics and practical applications in nuclear studies."}}
{"id": "2506.23615", "pdf": "https://arxiv.org/pdf/2506.23615", "abs": "https://arxiv.org/abs/2506.23615", "authors": ["Heisam Moustafa", "Alexander Kovacs", "Johann Fischbacher", "Markus Gusenbauer", "Qais Ali", "Leoni Breth", "Thomas Schrefl", "Harald Oezelt"], "title": "Graph Neural Networks to Predict Coercivity of Hard Magnetic Microstructures", "categories": ["physics.comp-ph"], "comment": "24 pages, 15 figures", "summary": "Graph neural networks (GNN) are a promising tool to predict magnetic\nproperties of large multi-grain structures, which can speed up the search for\nrare-earth free permanent magnets. In this paper, we use our magnetic\nsimulation data to train a GNN to predict coercivity of hard magnetic\nmicrostructures. We evaluate the performance of the trained GNN and quantify\nits uncertainty. Subsequently, we reuse the GNN architecture for predicting the\nmaximum energy product. Out-of-distribution predictions of coercivity are also\nperformed, following feature engineering based on the observed dependence of\ncoercivity on system size.", "AI": {"tldr": "A GNN is trained to predict coercivity in magnetic microstructures, evaluated for performance and uncertainty, and repurposed for predicting maximum energy product, with out-of-distribution predictions also explored.", "motivation": "To speed up the search for rare-earth free permanent magnets by predicting magnetic properties of large multi-grain structures using GNNs.", "method": "Train a GNN on magnetic simulation data to predict coercivity, evaluate its performance and uncertainty, reuse the architecture for maximum energy product prediction, and perform out-of-distribution predictions.", "result": "The GNN successfully predicts coercivity and is adapted for other magnetic properties, with feature engineering aiding out-of-distribution predictions.", "conclusion": "GNNs are effective for predicting magnetic properties, offering potential for accelerating material discovery."}}
{"id": "2506.22947", "pdf": "https://arxiv.org/pdf/2506.22947", "abs": "https://arxiv.org/abs/2506.22947", "authors": ["Lauren Conger", "Franca Hoffmann", "Eric Mazumdar", "Lillian J. Ratliff"], "title": "Monotone Multispecies Flows", "categories": ["math.AP", "35G50, 91A06, 35B40"], "comment": null, "summary": "We present a novel notion of $\\lambda$-monotonicity for an $n$-species system\nof partial differential equations governed by mass-preserving flow dynamics,\nextending monotonicity in Banach spaces to the Wasserstein-2 metric space. We\nshow that monotonicity implies the existence of and convergence to a unique\nsteady state, convergence of the velocity fields and second moments, and\ncontraction in the Wasserstein-2 metric, at rates dependent on $\\lambda$. In\nthe special setting of Wasserstein-2 gradient descent of different energies for\neach species, we prove convergence to the unique Nash equilibrium of the\nassociated energies and delineate the relationship between monotonicity and\ndisplacement convexity. This extends known zero-sum results in\ninfinite-dimensional game theory to the general-sum setting. We provide a\nnumber of examples of monotone coupled gradient flow systems, including\ncross-diffusion, gradient flows with potentials, nonlocal interaction, linear\nand nonlinear diffusion, and min-max systems, and draw connections to a class\nof mean-field games. Numerically, we demonstrate convergence of a four-player\neconomic model for service providers and strategic users competing in a market,\nand a degenerately monotone game.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.23084", "pdf": "https://arxiv.org/pdf/2506.23084", "abs": "https://arxiv.org/abs/2506.23084", "authors": ["Hongxia Guo", "Tianjiao Wang", "Xiang Xu", "Yue Zhao"], "title": "PML method for the time-domain stochastic acoustic wave equation and an inverse source problem", "categories": ["math.NA", "cs.NA", "35B35, 35R60, 78A46"], "comment": null, "summary": "In this paper, we develop and analyze a time-domain perfectly matched layer\n(PML) method for the stochastic acoustic wave equation driven by spatially\nwhite additive Gaussian noise. We begin by establishing the well-posedness and\nstability of the direct problem through a rigorous analysis of the associated\ntime-harmonic stochastic Helmholtz equation and the application of an abstract\nLaplace transform inversion theorem. To address the low regularity of the\nrandom source, we employ scattering theory to investigate the meromorphic\ncontinuation of the Helmholtz resolvent defined on rough fields. Based on a\npiecewise constant approximation of the white noise, we construct an\napproximate wave solution and formulate a time-domain PML method. The\nconvergence of the PML method is established, with explicit dependence on the\nPML layer's thickness and medium properties, as well as the piecewise constant\napproximation of the white noise. In addition, we propose a frequency-domain\napproach for solving the inverse random source problem using time-domain\nboundary measurements. A logarithmic stability estimate is derived,\nhighlighting the ill-posedness of the inverse problem and offering guidance for\nthe design of effective numerical schemes.", "AI": {"tldr": "The paper develops a time-domain PML method for the stochastic acoustic wave equation with white Gaussian noise, analyzes its well-posedness, and proposes an inverse random source problem solution with stability estimates.", "motivation": "To address the challenges of low regularity in random sources and ensure stability in solving the stochastic acoustic wave equation.", "method": "Uses scattering theory for meromorphic continuation, constructs an approximate wave solution, and formulates a time-domain PML method. Also proposes a frequency-domain approach for inverse problems.", "result": "Convergence of the PML method is proven, with explicit dependencies on parameters. A logarithmic stability estimate for the inverse problem is derived.", "conclusion": "The PML method is effective for stochastic acoustic waves, and the stability estimate guides numerical scheme design for inverse problems."}}
{"id": "2506.23984", "pdf": "https://arxiv.org/pdf/2506.23984", "abs": "https://arxiv.org/abs/2506.23984", "authors": ["S. Chakraborty", "P. A. Inchin", "S. Debchoudhury", "C. Heale", "B. Bergsson", "M. Zettergren", "J. M. Ruohoniemi"], "title": "The impacts of tropospheric gravity wave-generated MSTIDs on skywaves at middle latitude North American sector observed and modeled using SuperDARN HF radars", "categories": ["physics.space-ph", "physics.plasm-ph"], "comment": null, "summary": "Trans-ionospheric high frequency (HF: 3-30 MHz) response to gravity waves\n(GWs) is studied in the middle-latitude ionosphere in relation to thunderstorm\nactivity. SuperDARN HF radar observations are compared against the model\nsimulations to quantify the impact of GW-generated MSTID (medium-scale\ntraveling ionospheric disturbances) activity on the skywaves traveling through\nionospheric F-region heights. The tropospheric thunderstorm-driven convective\nsource is modeled using MAGIC. The outputs are coupled with GEMINI to model\nionospheric plasma response, which is then used to model SuperDARN HF radar\nobservations using the PHaRLAP raytracing tool. Semi-concentric GWs were\nobserved at different atmospheric heights, creating MSTIDs at F-region heights.\nPHaRLAP raytracing through the modeled ionosphere shows great qualitative\nagreement with SuperDARN daytime ground scatter observations. Modeled rays show\npossibilities of long ducting Pedersen rays, suggesting MSTID can create a\nplasma waveguide to duct rays at the F-region height.", "AI": {"tldr": "The paper studies HF radar response to gravity waves in the mid-latitude ionosphere, linking thunderstorm activity to MSTIDs and their impact on skywaves.", "motivation": "To understand the impact of thunderstorm-driven gravity waves on ionospheric disturbances and HF radar observations.", "method": "Combined SuperDARN HF radar observations with model simulations (MAGIC, GEMINI, PHaRLAP) to analyze GW-generated MSTIDs.", "result": "Observed semi-concentric GWs created MSTIDs at F-region heights, with model simulations matching SuperDARN observations. MSTIDs may form plasma waveguides.", "conclusion": "Thunderstorm-driven GWs significantly affect ionospheric HF radar observations, with MSTIDs potentially enabling long ducting of rays."}}
{"id": "2506.23620", "pdf": "https://arxiv.org/pdf/2506.23620", "abs": "https://arxiv.org/abs/2506.23620", "authors": ["Aleksandar Borkovi\u0107", "Michael H. Gfrerer", "Roger A. Sauer", "Benjamin Marussig"], "title": "Efficient snap-to-contact computations for van der Waals interacting fibers", "categories": ["physics.comp-ph"], "comment": null, "summary": "We consider van der Waals interactions between in-plane fibers, where the\ncomputational model employs the Lennard-Jones potential and the coarse-grained\napproach. The involved 6D integral over two interacting fibers is split into a\n4D analytical pre-integration over cross sections and the remaining 2D\nnumerical integration along the fibers' axes. Two section-section interaction\nlaws are implemented, refined, and compared. Fibers are modeled using the\nBernoulli-Euler beam theory and spatially discretized with isogeometric finite\nelements. We derive and solve the weak form of both quasi-static and dynamic\nboundary value problems. Four numerical examples involving highly nonlinear and\ndynamic snap-to-contact phenomena are scrutinized. We observe that the\ncoarse-graining and pre-integration of interaction potentials enable the\nefficient modeling of complex phenomena at small length scales.", "AI": {"tldr": "The paper explores van der Waals interactions between in-plane fibers using Lennard-Jones potential and coarse-grained modeling, with efficient computational methods for complex phenomena.", "motivation": "To model and analyze van der Waals interactions between fibers efficiently, addressing computational challenges in small-scale phenomena.", "method": "Uses Lennard-Jones potential and coarse-grained approach, splitting integrals into analytical and numerical parts, and employs Bernoulli-Euler beam theory with isogeometric finite elements.", "result": "Demonstrates efficient modeling of nonlinear and dynamic snap-to-contact phenomena through refined computational techniques.", "conclusion": "Coarse-graining and pre-integration of interaction potentials enable efficient simulation of complex small-scale fiber interactions."}}
{"id": "2506.23076", "pdf": "https://arxiv.org/pdf/2506.23076", "abs": "https://arxiv.org/abs/2506.23076", "authors": ["Lu Chen", "Rou Jiang", "Guozhen Lu", "Maochun Zhu"], "title": "Existence and Nonexistence of Extremals for Trudinger-Moser inequalities with $L^p$ type perturbation on any bounded planar domains", "categories": ["math.AP", "35B44, 35B40, 35J61, 35B33"], "comment": "52Pages", "summary": "In this study, we investigate the perturbed Trudinger-Moser inequalities as\nfollows:\\[ S_\\Omega(\\lambda,p)=\\sup_{u\\in H_{0}^{1}(\\Omega),\\Vert\\nabla u\\Vert\n_{L^{2}\\left( \\Omega\\right) }\\leq 1}\\int_{\\Omega}\\left( e^{4\\pi\nu^{2}}-\\lambda|u|^{p}\\right) dx, \\] where $1\\leq p<\\infty$ and $\\Omega$ is a\nbounded domain in $\\mathbb{R}^2$. Our results demonstrate that there exists a\nthreshold $\\lambda^{\\ast}(p)>0$ such that $S_\\Omega(\\lambda,p)$ is attainable\nif $\\lambda<\\lambda^{\\ast}(p)$, but unattainable if $\\lambda>\\lambda^{\\ast}(p)$\nwhen $p\\in[1,2]$. For $p>2$, however, we show that $S_\\Omega(\\lambda,p)$ is\nalways attainable for any $\\lambda\\in \\mathbb{R}$. These results are achieved\nthrough a refined blow-up analysis, which allow us to establish a sharp\nDirichlet energy expansion formula for sequences of solutions to the\ncorresponding Euler-Lagrange equations. The asymmetric nature of our problem\nposes significant challenges to our analysis. To address these, we will\nestablish an appropriate comparison principle between radial and non-radial\nsolutions of the associated Euler-Lagrange equations. Our study establishes a\ncomplete characterization of how $L^p$-type perturbations influence the\nexistence of extremals for critical Trudinger-Moser inequalities on any bounded\nplanar domains, this extends the classical Brezis-Nirenberg problem framework\nto the two-dimensional settings.", "AI": {"tldr": "The paper investigates perturbed Trudinger-Moser inequalities, identifying a threshold \u03bb*(p) for attainability of S_\u03a9(\u03bb,p) and showing full attainability for p>2.", "motivation": "To understand how L^p-type perturbations affect extremals for critical Trudinger-Moser inequalities in 2D bounded domains, extending the Brezis-Nirenberg problem.", "method": "Refined blow-up analysis and establishing a sharp Dirichlet energy expansion formula, along with a comparison principle for radial vs. non-radial solutions.", "result": "For p\u2208[1,2], S_\u03a9(\u03bb,p) is attainable if \u03bb<\u03bb*(p) but not if \u03bb>\u03bb*(p). For p>2, it's always attainable.", "conclusion": "The study provides a complete characterization of extremals for perturbed Trudinger-Moser inequalities in 2D, addressing asymmetric challenges."}}
{"id": "2506.23093", "pdf": "https://arxiv.org/pdf/2506.23093", "abs": "https://arxiv.org/abs/2506.23093", "authors": ["Wei Xie", "Shubin Fu", "Yin Yang", "Yunqing Huang"], "title": "A residual driven multiscale method for Darcy's flow in perforated domains", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we present a residual-driven multiscale method for simulating\nDarcy flow in perforated domains, where complex geometries and highly\nheterogeneous permeability make direct simulations computationally expensive.\nTo address this, we introduce a velocity elimination technique that\nreformulates the mixed velocity-pressure system into a pressure-only\nformulation, significantly reducing complexity by focusing on the dominant\npressure variable. Our method is developed within the Generalized Multiscale\nFinite Element Method (GMsFEM) framework. For each coarse block, we construct\noffline basis functions from local spectral problems that capture key geometric\nand physical features. Online basis functions are then adaptively enriched\nusing residuals, allowing the method to incorporate global effects such as\nsource terms and boundary conditions, thereby improving accuracy. We provide\ndetailed error analysis demonstrating how the offline and online spaces\ncontribute to the accuracy and efficiency of the solution. Numerical\nexperiments confirm the method's effectiveness, showing substantial reductions\nin computational cost while maintaining high accuracy, particularly through\nadaptive online enrichment. These results highlight the method's potential for\nefficient and accurate simulation of Darcy flow in complex, heterogeneous\nperforated domains.", "AI": {"tldr": "A residual-driven multiscale method for Darcy flow in perforated domains reduces computational cost by focusing on pressure and using adaptive enrichment.", "motivation": "Direct simulations of Darcy flow in complex, heterogeneous perforated domains are computationally expensive.", "method": "Velocity elimination simplifies the system to pressure-only. Offline and online basis functions are constructed within GMsFEM, with adaptive online enrichment using residuals.", "result": "Numerical experiments show reduced computational cost and high accuracy, especially with adaptive online enrichment.", "conclusion": "The method efficiently and accurately simulates Darcy flow in complex perforated domains."}}
{"id": "2506.23914", "pdf": "https://arxiv.org/pdf/2506.23914", "abs": "https://arxiv.org/abs/2506.23914", "authors": ["Evan Bell", "Daniel A. Serino", "Ben S. Southworth", "Trevor Wilcox", "Marc L. Klasky"], "title": "Learning robust parameter inference and density reconstruction in flyer plate impact experiments", "categories": ["physics.comp-ph", "cs.LG"], "comment": "24 pages, 21 figures", "summary": "Estimating physical parameters or material properties from experimental\nobservations is a common objective in many areas of physics and material\nscience. In many experiments, especially in shock physics, radiography is the\nprimary means of observing the system of interest. However, radiography does\nnot provide direct access to key state variables, such as density, which\nprevents the application of traditional parameter estimation approaches. Here\nwe focus on flyer plate impact experiments on porous materials, and resolving\nthe underlying parameterized equation of state (EoS) and crush porosity model\nparameters given radiographic observation(s). We use machine learning as a tool\nto demonstrate with high confidence that using only high impact velocity data\ndoes not provide sufficient information to accurately infer both EoS and crush\nmodel parameters, even with fully resolved density fields or a dynamic sequence\nof images. We thus propose an observable data set consisting of low and high\nimpact velocity experiments/simulations that capture different regimes of\ncompaction and shock propagation, and proceed to introduce a generative machine\nlearning approach which produces a posterior distribution of physical\nparameters directly from radiographs. We demonstrate the effectiveness of the\napproach in estimating parameters from simulated flyer plate impact\nexperiments, and show that the obtained estimates of EoS and crush model\nparameters can then be used in hydrodynamic simulations to obtain accurate and\nphysically admissible density reconstructions. Finally, we examine the\nrobustness of the approach to model mismatches, and find that the learned\napproach can provide useful parameter estimates in the presence of\nout-of-distribution radiographic noise and previously unseen physics, thereby\npromoting a potential breakthrough in estimating material properties from\nexperimental radiographic images.", "AI": {"tldr": "The paper addresses the challenge of estimating material properties from radiographic observations in shock physics, proposing a machine learning approach to infer equation of state and crush model parameters from a combination of low and high impact velocity experiments.", "motivation": "Traditional parameter estimation methods fail in shock physics experiments because radiography doesn't directly measure key variables like density. The study aims to overcome this limitation.", "method": "A generative machine learning approach is introduced to produce posterior distributions of physical parameters from radiographs, using data from both low and high impact velocity experiments.", "result": "The method accurately estimates parameters for simulations and enables physically admissible density reconstructions. It also shows robustness to noise and unseen physics.", "conclusion": "The approach offers a breakthrough in estimating material properties from radiographic images, even with model mismatches."}}
{"id": "2506.23087", "pdf": "https://arxiv.org/pdf/2506.23087", "abs": "https://arxiv.org/abs/2506.23087", "authors": ["Alexander Shlapunov", "Alexander Polkovnikov", "Kseniya Gagelgans"], "title": "The Grothendieck duality and sparse minimizing in spaces of Sobolev solutions to elliptic systems", "categories": ["math.AP", "math.FA", "49J45, 49J35, 46A20, 35C15, 35Jxx"], "comment": null, "summary": "We present an instructive example of using Banach spaces of solutions to\n(linear, generally, non-scalar) elliptic operator $A$ to investigate\nvariational inverse problems related to neural networks and/or to\nregularization of solutions to boundary value problems. More precisely,\ninspired by kernel's method for optimization problems in locally convex spaces,\nwe prove the existence of the so-called sparse minimizers for the related\nvariational problem and produce a representer theorem where a suitable\nfundamental solution of the operator $A$ is used as a reproducing kernel. The\nGrothendieck type duality for the Sobolev spaces of solutions to elliptic\noperator $A$ plays an essential role in the considerations. The case where the\nnumber of data passes to infinity is also discussed. Some typical situations\nrelated to the standard elliptic operators, the corresponding function spaces\nand fundamental solutions are considered.", "AI": {"tldr": "The paper explores using Banach spaces and elliptic operators to solve variational inverse problems in neural networks and boundary value problems, proving sparse minimizers and a representer theorem with a fundamental solution as a kernel.", "motivation": "To address variational inverse problems in neural networks and regularization of boundary value problems using Banach spaces and elliptic operators.", "method": "Utilizes Banach spaces of solutions to elliptic operator $A$, kernel methods, and Grothendieck-type duality in Sobolev spaces to prove sparse minimizers and a representer theorem.", "result": "Existence of sparse minimizers and a representer theorem using a fundamental solution of $A$ as a reproducing kernel.", "conclusion": "The approach effectively addresses variational problems, with potential applications in infinite data scenarios and standard elliptic operators."}}
{"id": "2506.23249", "pdf": "https://arxiv.org/pdf/2506.23249", "abs": "https://arxiv.org/abs/2506.23249", "authors": ["Maria P. Fernando", "S. M. Mallikarjunaiah"], "title": "An \\textsf{AT1} phase-field framework for quasi-static anti-plane shear fracture: Unifying $\u03be$-based adaptivity and nonlinear strain energy density function", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This work introduces a novel \\textsf{AT1} phase-field framework for\nsimulating quasi-static anti-plane shear fracture in geometrically linear\nelastic bodies. A key feature of this framework is the unification of\n$\\xi$-based local mesh adaptivity -- where $\\xi$ represents the characteristic\nlength of the damage zone -- and an algebraically nonlinear strain energy\ndensity function. A modified Francfort-Marigo energy functional, together with\nits Ambrosio-Tortorelli-type regularization, is hereby proposed to address\nchallenges within the framework of nonlinearly constituted materials. We\ndynamically optimize $\\xi$ throughout the simulation, significantly enhancing\nthe computational efficiency and accuracy of numerically approximating the\nlocal minimizers of the Ambrosio-Tortorelli (\\textsf{AT1})-type phase-field\nmodel. The proposed regularization for the total energy functional comprises\nthree distinct components: a nonlinear strain energy, an evolving surface\nenergy, and a linear-type regularization term dependent on the length scale of\nthe damage zone. Variational principles applied to this novel energy functional\nyield a coupled system of governing second-order quasilinear partial\ndifferential equations for the mechanics and phase-field variables. These\nequations are subsequently discretized using the conforming bilinear finite\nelement method. The formulation is underpinned by four crucial parameters: two\nare integral to the nonlinear strain energy function, while the other two serve\nas penalty parameters. These penalty parameters are asymptotically calibrated\nand rigorously utilized in the numerical simulations. Our results demonstrate\nthat this spatially adaptive approach leads to enhanced mesh adaptivity,\nensuring the robust convergence of the numerical solution.", "AI": {"tldr": "A novel AT1 phase-field framework for simulating quasi-static anti-plane shear fracture is introduced, combining local mesh adaptivity and nonlinear strain energy for improved computational efficiency and accuracy.", "motivation": "To address challenges in simulating fracture in nonlinearly constituted materials by unifying mesh adaptivity and nonlinear strain energy.", "method": "Proposes a modified Francfort-Marigo energy functional with AT1 regularization, dynamically optimizing the damage zone length scale. Uses variational principles and conforming bilinear finite element method for discretization.", "result": "Enhanced mesh adaptivity and robust convergence of numerical solutions, validated through simulations with calibrated penalty parameters.", "conclusion": "The framework effectively improves computational efficiency and accuracy in fracture simulations for nonlinearly elastic materials."}}
{"id": "2506.23917", "pdf": "https://arxiv.org/pdf/2506.23917", "abs": "https://arxiv.org/abs/2506.23917", "authors": ["Hao Jin", "Sha Liu", "Sirui Yang", "Junzhe Cao", "Congshan Zhuo", "Chengwen Zhong"], "title": "A hybrid numerical algorithm based on the stochastic particle Shakhov and DSMC method", "categories": ["physics.comp-ph"], "comment": null, "summary": "The Direct Simulation Monte Carlo (DSMC) method is widely employed for\nsimulating rarefied nonequilibrium gas flows. With advances in aerospace\nengineering and micro/nano-scale technologies, gas flows exhibit the\ncoexistence of rarefied and continuum/near-continuum regimes, which calls for\nlarger time steps and coarser spatial grids for efficient numerical simulation.\nHowever, the mesh sizes and time steps in DSMC are constrained by the\nsingle-scale nature of the Boltzmann equation and the explicit treatment of\ncollision term following operator splitting. To overcome the resulting\ncomputational inefficiency, the Time-Relaxed Monte Carlo (TRMC) method\nintroduces a suitable time discretization of the Boltzmann equation, allowing\nfor significantly larger time steps. Besides, domain decomposition methods\nleverage the complementary strengths of continuum and particle-based\napproaches, facilitating the efficient simulation of multi-scale gas flows.\nHowever, in TRMC method, the physically accurate high-order terms are truncated\nand approximated through convergence to a local Maxwellian distribution.\nMeanwhile, the continuum breakdown criteria employed in hybrid methods are\neither empirical or semi-empirical. Recently, a timescale-based decomposition\nof the Boltzmann equation has been proposed to enable a more rational coupling\nbetween DSMC and Navier-Stokes. Inspired by this strategy, a novel hybrid\nparticle method is proposed to couple the stochastic particle Shakhov with\nDSMC, in which the collision operator is decomposed into two sub-steps based on\nlocal observation timescale and the relaxation time. The validity and accuracy\nof the proposed method are demonstrated through a series of benchmark cases,\nincluding 1-D sod shock tube, 2-D hypersonic flow around cylinder and jet\nexpansion into the vacuum, 3-D hypersonic flows around sphere and X-38 like\nvehicle in near-continuum flow regimes.", "AI": {"tldr": "The paper proposes a hybrid particle method combining stochastic particle Shakhov with DSMC, addressing computational inefficiency in multi-scale gas flow simulations by decomposing the collision operator based on timescales.", "motivation": "The need for efficient simulation of multi-scale gas flows, where rarefied and continuum regimes coexist, due to limitations in DSMC's time steps and mesh sizes.", "method": "Introduces a hybrid method coupling stochastic particle Shakhov with DSMC, decomposing the collision operator into sub-steps based on local timescales and relaxation time.", "result": "Demonstrated validity and accuracy through benchmark cases like 1-D shock tube, 2-D hypersonic flow, and 3-D hypersonic flows.", "conclusion": "The proposed method offers a rational and efficient approach for simulating multi-scale gas flows, overcoming DSMC's limitations."}}
{"id": "2506.23119", "pdf": "https://arxiv.org/pdf/2506.23119", "abs": "https://arxiv.org/abs/2506.23119", "authors": ["Sisi Huang", "Xiaohua Yao"], "title": "Decay estimates for discrete bi-Laplace operators with potentials on the lattice $\\mathbb{Z}$", "categories": ["math.AP"], "comment": "This is an expanded version of our previous work [arXiv:2504.03290]\n  and a new paper with 65 pages, inlcuding the all cases of resonance/\n  eigenvalue", "summary": "It is known that the discrete Laplace operator $\\Delta$ on the lattice\n$\\mathbb{Z}$ satisfies the following sharp time decay estimate:\n$$\\big\\|e^{it\\Delta}\\big\\|_{\\ell^1\\rightarrow\\ell^{\\infty}}\\lesssim|t|^{-\\frac{1}{3}},\\quad\nt\\neq0,$$ which is slower than the usual $ O(|t|^{-\\frac{1}{2}})$ decay in the\ncontinuous case on $\\mathbb{R}$. However, this paper shows that the discrete\nbi-Laplacian $\\Delta^2$ on $\\mathbb{Z}$ actually exhibits the same sharp decay\nestimate $|t|^{-\\frac{1}{4}}$ as its continuous counterpart.\n  In view of the free decay estimate, we further investigate the discrete\nbi-Schr\\\"{o}dinger operators of the form $H=\\Delta^2+V$ on the lattice space\n$\\ell^2(\\mathbb{Z})$, where $V$ is a class of real-valued decaying potentials\non $\\mathbb{Z}$. First, we establish the limiting absorption principle for $H$,\nand then derive the full asymptotic expansions of the resolvent of $H$ near the\nthresholds $0$ and $16$, including resonance cases. In particular, we provide a\ncomplete characterizations of the different resonance types in\n$\\ell^2$-weighted spaces.\n  Based on these results above, we establish the following sharp\n$\\ell^1-\\ell^{\\infty}$ decay estimates for all different resonances types of\n$H$ under suitable decay conditions on $V$:\n$$\\big\\|e^{-itH}P_{ac}(H)\\big\\|_{\\ell^1\\rightarrow\\ell^{\\infty}}\\lesssim|t|^{-\\frac{1}{4}},\\quad\nt\\neq0,$$ where $P_{ac}(H)$ denotes the spectral projection onto the absolutely\ncontinuous spectrum space of $H$. Additionally, the decay estimates for the\nevolution flow of discrete beam equation are also derived: $$\\|{\\cos}(t\\sqrt\nH)P_{ac}(H)\\|_{\\ell^1\\rightarrow\\ell^{\\infty}}+\\Big\\|\\frac{{\\sin}(t\\sqrt\nH)}{t\\sqrt\nH}P_{ac}(H)\\Big\\|_{\\ell^1\\rightarrow\\ell^{\\infty}}\\lesssim|t|^{-\\frac{1}{3}},\\quad\nt\\neq0.$$", "AI": {"tldr": "The paper shows the discrete bi-Laplacian on \u2124 matches the continuous decay rate of |t|^(-1/4). It also analyzes discrete bi-Schr\u00f6dinger operators, establishes limiting absorption principles, and derives sharp decay estimates for different resonance types.", "motivation": "To understand the decay properties of discrete bi-Laplacian and bi-Schr\u00f6dinger operators, comparing them to their continuous counterparts and exploring resonance effects.", "method": "The study involves establishing limiting absorption principles, deriving resolvent expansions near thresholds, and characterizing resonance types in weighted \u2113\u00b2 spaces.", "result": "Sharp decay estimates are proven for discrete bi-Laplacian and bi-Schr\u00f6dinger operators, matching continuous decay rates. The discrete beam equation also exhibits specific decay behavior.", "conclusion": "The discrete bi-Laplacian and bi-Schr\u00f6dinger operators exhibit decay rates analogous to their continuous versions, with detailed resonance characterizations and decay estimates provided."}}
{"id": "2506.23344", "pdf": "https://arxiv.org/pdf/2506.23344", "abs": "https://arxiv.org/abs/2506.23344", "authors": ["Difeng Cai", "Paulina Sep\u00falveda"], "title": "Data-Driven Self-Supervised Learning for the Discovery of Solution Singularity for Partial Differential Equations", "categories": ["math.NA", "cs.LG", "cs.NA", "stat.ML"], "comment": null, "summary": "The appearance of singularities in the function of interest constitutes a\nfundamental challenge in scientific computing. It can significantly undermine\nthe effectiveness of numerical schemes for function approximation, numerical\nintegration, and the solution of partial differential equations (PDEs), etc.\nThe problem becomes more sophisticated if the location of the singularity is\nunknown, which is often encountered in solving PDEs. Detecting the singularity\nis therefore critical for developing efficient adaptive methods to reduce\ncomputational costs in various applications. In this paper, we consider\nsingularity detection in a purely data-driven setting. Namely, the input only\ncontains given data, such as the vertex set from a mesh. To overcome the\nlimitation of the raw unlabeled data, we propose a self-supervised learning\n(SSL) framework for estimating the location of the singularity. A key component\nis a filtering procedure as the pretext task in SSL, where two filtering\nmethods are presented, based on $k$ nearest neighbors and kernel density\nestimation, respectively. We provide numerical examples to illustrate the\npotential pathological or inaccurate results due to the use of raw data without\nfiltering. Various experiments are presented to demonstrate the ability of the\nproposed approach to deal with input perturbation, label corruption, and\ndifferent kinds of singularities such interior circle, boundary layer,\nconcentric semicircles, etc.", "AI": {"tldr": "The paper addresses singularity detection in scientific computing using a self-supervised learning framework to improve accuracy and reduce computational costs.", "motivation": "Singularities in functions hinder numerical methods, especially when their locations are unknown. Detecting them is crucial for adaptive methods in PDEs and other applications.", "method": "Proposes a self-supervised learning (SSL) framework with filtering methods (k-nearest neighbors and kernel density estimation) to estimate singularity locations from raw data.", "result": "Numerical examples show the framework's effectiveness in handling input perturbations, label corruption, and various singularity types.", "conclusion": "The SSL-based approach successfully detects singularities, offering a robust solution for data-driven singularity detection."}}
{"id": "2506.24099", "pdf": "https://arxiv.org/pdf/2506.24099", "abs": "https://arxiv.org/abs/2506.24099", "authors": ["Roshan Philip Saji", "Panos Pantidis", "Mostafa E. Mobasher"], "title": "Modified non-local damage model: resolving spurious damage evolution", "categories": ["physics.comp-ph"], "comment": null, "summary": "Accurate prediction of damage and fracture evolution is critical for the\nsafety design and preventive maintenance of engineering structures, however\nexisting computational methods face significant limitations. On one hand,\ndiscrete damage and phase-field models are often computationally prohibitive\nfor real world applications and they are less generalizable across different\nmaterial classes. On the other hand, conventional gradient damage models which\nare based on phenomenological laws, though more computationally efficient, they\nsuffer from unrealistic widening of the damage-band as damage progresses. This\npaper presents a modified non-local gradient damage model (MNLD) that overcomes\nthese shortcomings by introducing modifications to the stress degradation\nfunction and forcing term in the Helmholtz free energy expression. These two\nmodifications ensure that as damage approaches its maximum value, both the\nthermodynamic damage driving force for damage vanishes and the evolution of the\nforcing term decays. Consequently, the damage band retains a non-growing\nconstant width throughout its evolution. The proposed approach builds on\ninsights gained from two intermediate models, which addressed the necessary\nconditions separately before integrating them into a unified formulation.\nNumerical validation is performed on several 1D and 2D benchmark problems,\ndemonstrating that the proposed model can reliably produce fixed-width damage\nbands. The proposed approach can be implemented within existing gradient\ndamage-based finite element frameworks with minimal implementation changes. The\nresults highlight the potential of this approach to resolve the decades-long\nchallenge of spurious widening in gradient damage models, offering an effective\nand practical solution for engineering applications.", "AI": {"tldr": "The paper introduces a modified non-local gradient damage model (MNLD) to address computational and generalizability limitations in existing damage prediction methods, ensuring fixed-width damage bands.", "motivation": "Existing methods for predicting damage and fracture evolution are either computationally prohibitive or suffer from unrealistic damage-band widening, limiting their practical application.", "method": "The MNLD model modifies the stress degradation function and forcing term in the Helmholtz free energy expression to ensure vanishing thermodynamic driving force and decay of the forcing term as damage progresses.", "result": "Numerical validation shows the model reliably produces fixed-width damage bands, resolving the spurious widening issue in gradient damage models.", "conclusion": "The MNLD model offers an effective, practical solution for engineering applications, overcoming long-standing challenges in gradient damage models."}}
{"id": "2506.23159", "pdf": "https://arxiv.org/pdf/2506.23159", "abs": "https://arxiv.org/abs/2506.23159", "authors": ["Renjun Duan", "Zongguang Li", "Dongcheng Yang", "Tong Yang"], "title": "Ionic KdV structure in weakly collisional plasmas", "categories": ["math.AP"], "comment": "79 pages. All comments are welcome", "summary": "We consider the one-dimensional ions dynamics in weakly collisional plasmas\ngoverned by the Vlasov-Poisson-Landau system under the Boltzmann relation with\nthe small collision frequency $\\nu>0$. It is observed in physical experiments\nthat the interplay of nonlinearities and dispersion may lead to the formation\nof ion acoustic solitons that are described by the Korteweg-de Vries equation.\nIn this paper, to capture the ionic KdV structure in the weak-collision regime,\nwe study the combined cold-ions limit and longwave limit of the rescaled VPL\nsystem depending on a small scaling parameter $\\epsilon>0$. The main goal is to\njustify the uniform convergence of the VPL solutions to the KdV solutions over\nany finite time interval as $\\epsilon\\to 0$ under restriction that\n$\\epsilon^{3/2}\\lesssim \\nu \\lesssim \\epsilon^{1/2}$. The proof is based on the\nenergy method near local Maxwellians for making use of the Euler-Poisson\ndynamics under the longwave scaling. The KdV profiles, in particular including\nboth velocity field and electric potential, may have large amplitude, which\ninduces the cubic velocity growth. To overcome the $\\epsilon$-singularity in\nsuch multi-parameter limit problem, we design delicate velocity weighted energy\nfunctional and dissipation rate functional in the framework of macro-micro\ndecomposition that is further incorporated with the Caflisch's decomposition.\nAs an application of our approach, the global-in-time existence of solutions\nnear global Maxwellians when the KdV profile is degenerate to a constant\nequilibrium is also established under the same scaling with\n$\\epsilon^{3}\\lesssim \\nu \\lesssim \\epsilon^{5/2}$. For the proof, the velocity\nweight is modified to depend on the solution itself, providing an extra quartic\ndissipation so as to obtain the global dynamics for most singular Coulomb\npotentials.", "AI": {"tldr": "The paper justifies the uniform convergence of Vlasov-Poisson-Landau (VPL) solutions to Korteweg-de Vries (KdV) solutions in weakly collisional plasmas under specific scaling conditions, using energy methods and velocity-weighted functionals.", "motivation": "To capture ion acoustic solitons in plasmas and understand their dynamics under weak-collision and longwave limits.", "method": "Combines cold-ions and longwave limits of the VPL system, using energy methods near local Maxwellians and velocity-weighted functionals to handle multi-parameter limits.", "result": "Uniform convergence of VPL solutions to KdV solutions is proven, and global-in-time existence of solutions near equilibrium is established.", "conclusion": "The approach successfully handles the multi-parameter limit problem and provides insights into soliton dynamics in plasmas."}}
{"id": "2506.23381", "pdf": "https://arxiv.org/pdf/2506.23381", "abs": "https://arxiv.org/abs/2506.23381", "authors": ["T. Chaumont-Frelet"], "title": "A new family of a posteriori error estimates for non-conforming finite element methods leading to stabilization-free error bounds", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We propose new a posteriori error estimators for non-conforming finite\nelement discretizations of second-order elliptic PDE problems. These estimators\nare based on novel reformulations of the standard Prager-Synge identity, and\nenable to prove efficiency estimates without extra stabilization terms in the\nerror measure for a large class of discretization schemes. We propose a\nresidual-based estimator for which the efficiency constant scales optimally in\npolynomial degree, as well as two equilibrated estimators that are\npolynomial-degree-robust. One of the two estimators further leads to guaranteed\nerror bounds.", "AI": {"tldr": "New a posteriori error estimators for non-conforming finite element methods for elliptic PDEs, offering efficiency without extra stabilization and polynomial-degree-robustness.", "motivation": "Improve error estimation for non-conforming finite element discretizations of elliptic PDEs by avoiding extra stabilization terms and ensuring robustness across polynomial degrees.", "method": "Novel reformulations of the Prager-Synge identity to derive residual-based and equilibrated estimators, with one providing guaranteed error bounds.", "result": "Efficiency estimates without stabilization, optimal scaling in polynomial degree, and polynomial-degree-robustness for equilibrated estimators.", "conclusion": "The proposed estimators enhance accuracy and robustness in error estimation for non-conforming finite element methods."}}
{"id": "2506.22533", "pdf": "https://arxiv.org/pdf/2506.22533", "abs": "https://arxiv.org/abs/2506.22533", "authors": ["Carlos A. Martins Junior", "Daniela A. Damasceno", "Keat Yung Hue", "Caetano R. Miranda", "Erich A. M\u00fcller", "Rodrigo A. Vargas-Hern\u00e1ndez"], "title": "Scalable Bayesian Optimization for High-Dimensional Coarse-Grained Model Parameterization", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "22 pages, 8 figures, (SI 9 pages, 2 figures, 8 tables)", "summary": "Coarse-grained (CG) force field models are extensively utilised in material\nsimulations due to their scalability. Traditionally, these models are\nparameterized using hybrid strategies that integrate top-down and bottom-up\napproaches; however, this combination restricts the capacity to jointly\noptimize all parameters. While Bayesian Optimization (BO) has been explored as\nan alternative search strategy for identifying optimal parameters, its\napplication has traditionally been limited to low-dimensional problems. This\nhas contributed to the perception that BO is unsuitable for more realistic CG\nmodels, which often involve a large number of parameters. In this study, we\nchallenge this assumption by successfully extending BO to optimize a\nhigh-dimensional CG model. Specifically, we show that a 41-parameter CG model\nof Pebax-1657, a copolymer composed of alternating polyamide and polyether\nsegments, can be effectively parameterized using BO, resulting in a model that\naccurately reproduces key physical properties of its atomistic counterpart. Our\noptimization framework simultaneously targets density, radius of gyration, and\nglass transition temperature. It achieves convergence in fewer than 600\niterations, resulting in a CG model that shows consistent improvements across\nall three properties.", "AI": {"tldr": "Bayesian Optimization (BO) is successfully applied to optimize a high-dimensional coarse-grained (CG) model of Pebax-1657, achieving accurate reproduction of atomistic properties in fewer than 600 iterations.", "motivation": "Traditional hybrid parameterization strategies for CG models limit joint optimization of all parameters, and BO is often considered unsuitable for high-dimensional problems. This study challenges that assumption.", "method": "BO is extended to optimize a 41-parameter CG model of Pebax-1657, targeting density, radius of gyration, and glass transition temperature.", "result": "The optimized CG model accurately reproduces key physical properties of its atomistic counterpart, converging in fewer than 600 iterations with consistent improvements.", "conclusion": "BO is viable for high-dimensional CG model optimization, offering an efficient alternative to traditional methods."}}
{"id": "2506.23166", "pdf": "https://arxiv.org/pdf/2506.23166", "abs": "https://arxiv.org/abs/2506.23166", "authors": ["Francisco Agostinho", "Sim\u00e3o Correia", "Hugo Tavares"], "title": "Stability transitions of NLS action ground-states on metric graphs", "categories": ["math.AP", "math-ph", "math.CA", "math.MP", "34C37, 35B35, 35Q55, 35R02, {37K45}, 70K05"], "comment": "39 pages, 3 figures. Keywords: action ground-states, metric graphs,\n  nonlinear Schr\\\"odinger equation, orbital stability, stability transitions", "summary": "We study the orbital stability of action ground-states of the nonlinear\nSchr\\\"odinger equation over two particular cases of metric graphs, the\n$\\mathcal{T}$ and the tadpole graphs. We show the existence of stability\ntransitions near the $L^2$-critical exponent, a new dynamical feature of the\nnonlinear Schr\\\"odinger equation. More precisely, as the frequency $\\lambda$\nincreases, the action ground-state transitions from stable to unstable and then\nback to stable (or vice-versa).\n  This result is complemented with the stability analysis of ground-states in\nthe asymptotic cases of low/high frequency and weak/strong nonlinear\ninteraction. Finally, we present a numerical simulation of the stability of\naction ground-states depending on the nonlinearity and the frequency parameter,\nwhich validates the aforementioned theoretical results.", "AI": {"tldr": "The paper investigates orbital stability of action ground-states in the nonlinear Schr\u00f6dinger equation on specific metric graphs, revealing stability transitions near the $L^2$-critical exponent.", "motivation": "To understand the dynamical behavior and stability transitions of ground-states in nonlinear Schr\u00f6dinger equations on metric graphs.", "method": "Theoretical analysis of stability transitions near the $L^2$-critical exponent, complemented by asymptotic case studies and numerical simulations.", "result": "Ground-states transition from stable to unstable and back to stable (or vice-versa) as frequency increases, with numerical validation.", "conclusion": "The study reveals new dynamical features of the nonlinear Schr\u00f6dinger equation, supported by theoretical and numerical evidence."}}
{"id": "2506.23449", "pdf": "https://arxiv.org/pdf/2506.23449", "abs": "https://arxiv.org/abs/2506.23449", "authors": ["Wenjie Huang", "Hao Wang", "Shiquan Zhang", "Qinyi Zhang"], "title": "Fourth-order compact difference schemes for the one-dimensional Euler-Bernoulli beam equation with damping term", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper proposes and analyzes a finite difference method based on compact\nschemes for the Euler-Bernoulli beam equation with damping terms. The method\nachieves fourth-order accuracy in space and second-order accuracy in time,\nwhile requiring only three spatial grid points within a single compact stencil.\nSpatial discretization is carried out using a compact finite difference scheme,\nwith a variable substitution technique employed to reduce the order of the\nequation and effectively handle the damping terms. For the temporal\ndiscretization, the Crank-Nicolson scheme is applied. The consistency,\nstability, and convergence of the proposed method are rigorously proved.\nNumerical experiments are presented to verify the theoretical results and\ndemonstrate the accuracy and efficiency of the method.", "AI": {"tldr": "A compact finite difference method for the Euler-Bernoulli beam equation with damping terms achieves high accuracy (4th-order in space, 2nd-order in time) using minimal grid points and rigorous theoretical validation.", "motivation": "To develop an efficient and accurate numerical method for solving the Euler-Bernoulli beam equation with damping, addressing challenges in spatial and temporal discretization.", "method": "Uses compact finite difference schemes for spatial discretization, reduces equation order via variable substitution, and applies the Crank-Nicolson scheme for temporal discretization.", "result": "The method is proven consistent, stable, and convergent, with numerical experiments confirming its accuracy and efficiency.", "conclusion": "The proposed method is effective for solving the Euler-Bernoulli beam equation with damping, offering high accuracy and computational efficiency."}}
{"id": "2506.22574", "pdf": "https://arxiv.org/pdf/2506.22574", "abs": "https://arxiv.org/abs/2506.22574", "authors": ["Madhumita Rano", "Henrik R. Larsson"], "title": "Computing excited eigenstates using inexact Lanczos methods and tree tensor network states", "categories": ["physics.chem-ph", "cond-mat.str-el", "physics.comp-ph"], "comment": null, "summary": "Excited eigenstates are crucial to understand the dynamics of quantum\nmany-body systems. Tensor network states are one of the workhorses to compute\nground states of many-body systems, yet the accurate computation of excited\neigenstates is still challenging. Here, we develop a combination of the inexact\nLanczos method, which aims at efficiently computing excited states, to tree\ntensor network states (TTNSs). We demonstrate our approach by computing excited\nvibrational states for three challenging problems: (1) 84 states in different\nenergy intervals of acetonitrile (12-dimensional), (2) Fermi resonance states\nof the fluxional Zundel ion (15-dimensional), and (3) selected excited states\nof the fluxional and very correlated Eigen ion (33-dimensional). The proposed\nTTNS inexact Lanczos method is directly applicable to other quantum many-body\nsystems.", "AI": {"tldr": "The paper introduces an inexact Lanczos method combined with tree tensor network states (TTNS) to compute excited eigenstates in quantum many-body systems, demonstrating its effectiveness on three complex problems.", "motivation": "Excited eigenstates are essential for understanding quantum many-body dynamics, but their computation remains challenging despite tensor network states being effective for ground states.", "method": "The authors develop an inexact Lanczos method tailored for TTNS to efficiently compute excited states.", "result": "The method successfully computes excited vibrational states for three challenging systems: acetonitrile, the Zundel ion, and the Eigen ion, showcasing its accuracy and applicability.", "conclusion": "The proposed TTNS inexact Lanczos method is versatile and directly applicable to other quantum many-body systems."}}
{"id": "2506.23188", "pdf": "https://arxiv.org/pdf/2506.23188", "abs": "https://arxiv.org/abs/2506.23188", "authors": ["Anders Bj\u00f6rn", "Jana Bj\u00f6rn", "Minhyun Kim"], "title": "Semiregular and strongly irregular boundary points for nonlocal Dirichlet problems", "categories": ["math.AP", "Primary: 35R11. Secondary: 31C15, 31C45, 35J66"], "comment": null, "summary": "In this paper we study nonlocal nonlinear equations of fractional\n$(s,p)$-Laplacian type on $\\mathbf{R}^n$. We show that the irregular boundary\npoints for the Dirichlet problem can be divided into two disjoint classes:\nsemiregular and strongly irregular boundary points, with very different\nbehaviour. Two fundamental tools needed to show this are the Kellogg property\n(from our previous paper) and a new removability result for solutions in the\n$V^{s,p}$ Sobolev type space, which we deduce more generally also for\nsupersolutions of equations with a right-hand side. Semiregular and strongly\nirregular points are also characterized in various ways. Finally, it is\nexplained how semiregularity depends on $s$ and $p$.", "AI": {"tldr": "The paper studies nonlocal nonlinear equations of fractional $(s,p)$-Laplacian type on $\\mathbf{R}^n$, classifying irregular boundary points into semiregular and strongly irregular points, and characterizing their behavior.", "motivation": "To understand the behavior of irregular boundary points in the Dirichlet problem for fractional $(s,p)$-Laplacian equations, distinguishing between semiregular and strongly irregular points.", "method": "Uses the Kellogg property and a new removability result for solutions in the $V^{s,p}$ Sobolev space, extending to supersolutions with a right-hand side.", "result": "Boundary points are classified into semiregular and strongly irregular, with distinct behaviors. Characterizations for both types are provided, and the dependence of semiregularity on $s$ and $p$ is explained.", "conclusion": "The study provides a clear classification and characterization of irregular boundary points, enhancing understanding of their behavior in fractional $(s,p)$-Laplacian equations."}}
{"id": "2506.23483", "pdf": "https://arxiv.org/pdf/2506.23483", "abs": "https://arxiv.org/abs/2506.23483", "authors": ["Harshit Bajpai", "Gaurav Mittal", "Ankik Kumar Giri"], "title": "On the convergence of iterative regularization method assisted by the graph Laplacian with early stopping", "categories": ["math.NA", "cs.NA", "math.FA", "math.OC"], "comment": null, "summary": "We present a data-assisted iterative regularization method for solving\nill-posed inverse problems in Hilbert space settings. The proposed approach,\ntermed \\texttt{IRMGL+\\(\\Psi\\)}, integrates classical iterative techniques with\na data-driven regularization term realized through an iteratively updated graph\nLaplacian. Our method commences by computing a preliminary solution using any\nsuitable reconstruction method, which then serves as the basis for constructing\nthe initial graph Laplacian. The solution is subsequently refined through an\niterative process, where the graph Laplacian is simultaneously recalibrated at\neach step to effectively capture the evolving structure of the solution. A key\ninnovation of this work lies in the formulation of this iterative scheme and\nthe rigorous justification of the classical discrepancy principle as a reliable\nearly stopping criterion specifically tailored to the proposed method. Under\nstandard assumptions, we establish stability and convergence results for the\nscheme when the discrepancy principle is applied. Furthermore, we demonstrate\nthe robustness and effectiveness of our method through numerical experiments\nutilizing four distinct initial reconstructors $\\Psi$: the adjoint operator\n(Adj), filtered back projection (FBP), total variation (TV) denoising, and\nstandard Tikhonov regularization (Tik). It is observed that \\texttt{IRMGL+Adj}\ndemonstrates a distinct advantage over the other initializers, producing a\nrobust and stable approximate solution directly from a basic initial\nreconstruction.", "AI": {"tldr": "A data-assisted iterative regularization method (IRMGL+\u03a8) combines classical techniques with a data-driven term via an iteratively updated graph Laplacian, showing robustness and stability, especially with the adjoint operator as the initial reconstructor.", "motivation": "Addressing ill-posed inverse problems in Hilbert spaces by integrating data-driven regularization with classical iterative methods to improve solution accuracy and stability.", "method": "The method starts with a preliminary solution, constructs an initial graph Laplacian, and iteratively refines both the solution and Laplacian. The discrepancy principle is justified as a stopping criterion.", "result": "Stability and convergence are proven under standard assumptions. Numerical experiments show IRMGL+Adj outperforms other initial reconstructors (FBP, TV, Tik).", "conclusion": "IRMGL+\u03a8, particularly with the adjoint operator, offers a robust and stable solution for ill-posed inverse problems, validated by theoretical and experimental results."}}
{"id": "2506.22627", "pdf": "https://arxiv.org/pdf/2506.22627", "abs": "https://arxiv.org/abs/2506.22627", "authors": ["Weiyi Xia", "Maxim Moraru", "Ying Wai Li", "Timothy Liao", "James R. Chelikowsky", "Cai-Zhuang Wang"], "title": "Accelerated discovery and design of Fe-Co-Zr magnets with tunable magnetic anisotropy through machine learning and parallel computing", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Rare earth (RE)-free permanent magnets, as alternative substitutes for\nRE-containing magnets for sustainable energy technologies and modern\nelectronics, have attracted considerable interest. We performed a comprehensive\nsearch for new hard magnetic materials in the ternary Fe-Co-Zr space by\nleveraging a scalable, machine learning-assisted materials discovery framework\nrunning on GPU-enabled exascale computing resources. This framework integrates\ncrystal graph convolutional neural network (CGCNN) machine learning (ML) method\nwith first-principles calculations to efficiently navigate the vast\ncomposition-structure space. The efficiency and accuracy of the ML approach\nenable us to reveal 9 new thermodynamically stable ternary Fe-Co-Zr compounds\nand 81 promising low-energy metastable phases with their formation energies\nwithin 0.1 eV/atom above the convex hull. The predicted compounds span a wide\nrange of crystal symmetries and magnetic behaviors, providing a rich platform\nfor tuning functional properties. Based on the analysis of site-specific\nmagnetic properties, we show that the Fe6Co17Zr6 compound obtained from our ML\ndiscovery can be further optimized by chemical doping. Chemical substitutions\nlead to a ternary Fe5Co18Zr6 phase with a strong anisotropy of K1 = 1.1 MJ/m3,\nand a stable quaternary magnetic Fe5Co16Zr6Mn4 compound.", "AI": {"tldr": "A machine learning-assisted framework identified new rare earth-free hard magnetic materials in the Fe-Co-Zr system, revealing stable and metastable phases with potential for optimization.", "motivation": "To find sustainable alternatives to rare earth-containing magnets for energy and electronics.", "method": "Combined crystal graph convolutional neural network (CGCNN) with first-principles calculations to explore Fe-Co-Zr compositions.", "result": "Discovered 9 stable and 81 metastable phases, with Fe6Co17Zr6 optimized into Fe5Co18Zr6 (strong anisotropy) and Fe5Co16Zr6Mn4.", "conclusion": "The approach efficiently identifies promising rare earth-free magnetic materials, enabling further optimization."}}
{"id": "2506.23216", "pdf": "https://arxiv.org/pdf/2506.23216", "abs": "https://arxiv.org/abs/2506.23216", "authors": ["Yao Zhang", "Xiaofeng Jin", "Lingwei Ma", "Zhenqiu Zhang"], "title": "Global Calder\u00f3n-Zygmund estimates for asymptotically convex fully nonlinear Grad-Mercier type equations", "categories": ["math.AP", "35B45, 35R05, 35B65"], "comment": "20 pages", "summary": "In this paper, we consider the following Dirichlet problem for the fully\nnonlinear elliptic equation of Grad-Mercier type under asymptotic convexity\nconditions \\begin{equation*}\n  \\left\\{\n  \\begin{array}{ll}\n  F(D^2u(x),Du(x),u(x),x)=g(|\\{y\\in \\Omega:u(y)\\ge u(x)\\}|)+f(x) & \\text{in }\n\\Omega,\n  u=\\psi &\\text{on } \\partial \\Omega.\n  \\end{array}\n  \\right. \\end{equation*} In order to overcome the non-convexity of the\noperator $F$ and the nonlocality of the nonhomogeneous term $g$, we apply the\ncompactness methods and frozen technique to prove the existence of the\n$W^{2,p}$-viscosity solutions and the global $W^{2,p}$ estimate. As an\napplication, we derive a Cordes-Nirenberg type continuous estimate up to\nboundary. Furthermore, we establish a global BMO estimate for the second\nderivatives of solutions by using an asymptotic approach, thereby refining the\nborderline case of Calder\\'{o}n-Zygmund estimates.", "AI": {"tldr": "The paper addresses a Dirichlet problem for a fully nonlinear elliptic equation under asymptotic convexity conditions, proving existence and estimates for solutions using compactness and frozen techniques.", "motivation": "The study aims to tackle the challenges posed by non-convexity in the operator and nonlocality in the nonhomogeneous term, seeking to establish rigorous mathematical solutions and estimates.", "method": "The authors employ compactness methods and frozen techniques to prove the existence of $W^{2,p}$-viscosity solutions and derive global $W^{2,p}$ estimates.", "result": "Key results include a Cordes-Nirenberg type continuous estimate up to the boundary and a global BMO estimate for second derivatives, refining Calder\u00f3n-Zygmund estimates.", "conclusion": "The paper successfully overcomes the non-convexity and nonlocality issues, providing robust solutions and refined estimates for the problem."}}
{"id": "2506.23702", "pdf": "https://arxiv.org/pdf/2506.23702", "abs": "https://arxiv.org/abs/2506.23702", "authors": ["Hongling Hu", "Shangyou Zhang"], "title": "Rectangular $C^1$-$Q_k$ Bell finite elements in two and three dimensions", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Both the function and its normal derivative on the element boundary are $Q_k$\npolynomials\n  for the Bogner-Fox-Schmit $C^1$-$Q_k$ finite element functions.\nMathematically, to keep the optimal order of approximation, their spaces are\nrequired to\n  include $P_k$ and $P_{k-1}$ polynomials respectively. We construct a Bell\ntype $C^1$-$Q_k$ finite element on rectangular meshes in 2D and 3D,\n  which has its normal derivative as a $Q_{k-1}$ polynomial on each face, for\n$k\\ge 4$. We show, with a big reduction of the space, the $C^1$-$Q_k$ Bell\n  finite element retains the optimal order of convergence. Numerical\nexperiments are performed, comparing the new elements with the original\nelements.", "AI": {"tldr": "The paper constructs a Bell-type $C^1$-$Q_k$ finite element on rectangular meshes in 2D and 3D, ensuring optimal convergence despite reduced space.", "motivation": "To maintain optimal approximation order while reducing the space for $C^1$-$Q_k$ finite elements, addressing the need for efficient numerical methods.", "method": "Constructs a Bell-type $C^1$-$Q_k$ element with normal derivatives as $Q_{k-1}$ polynomials for $k\\ge 4$, and compares it with original elements.", "result": "The new Bell-type element retains optimal convergence order despite space reduction, validated by numerical experiments.", "conclusion": "The proposed $C^1$-$Q_k$ Bell finite element is efficient and maintains optimal performance, offering a practical alternative to original elements."}}
{"id": "2506.22695", "pdf": "https://arxiv.org/pdf/2506.22695", "abs": "https://arxiv.org/abs/2506.22695", "authors": ["D. Jasuja", "P. J. Atzberger"], "title": "Protein Drift-Diffusion in Membranes with Non-equilibrium Fluctuations arising from Gradients in Concentration or Temperature", "categories": ["cond-mat.soft", "nlin.AO", "physics.bio-ph", "physics.comp-ph", "q-bio.SC"], "comment": null, "summary": "We investigate proteins within heterogeneous cell membranes where\nnon-equilibrium phenomena arises from spatial variations in concentration and\ntemperature. We develop simulation methods building on non-equilibrium\nstatistical mechanics to obtain stochastic hybrid continuum-discrete\ndescriptions which track individual protein dynamics, spatially varying\nconcentration fluctuations, and thermal exchanges. We investigate biological\nmechanisms for protein positioning and patterning within membranes and factors\nin thermal gradient sensing. We also study the kinetics of Brownian motion of\nparticles with temperature variations within energy landscapes arising from\nheterogeneous microstructures within membranes. The introduced approaches\nprovide self-consistent models for studying biophysical mechanisms involving\nthe drift-diffusion dynamics of individual proteins and energy exchanges and\nfluctuations between the thermal and mechanical parts of the system. The\nmethods also can be used for studying related non-equilibrium effects in other\nbiological systems and soft materials.", "AI": {"tldr": "The paper explores protein dynamics in heterogeneous cell membranes using hybrid simulation methods to study non-equilibrium effects like concentration gradients and thermal sensing.", "motivation": "To understand protein positioning, patterning, and thermal gradient sensing in cell membranes under non-equilibrium conditions.", "method": "Develops stochastic hybrid continuum-discrete simulation methods based on non-equilibrium statistical mechanics to track protein dynamics, concentration fluctuations, and thermal exchanges.", "result": "Provides self-consistent models for studying drift-diffusion dynamics of proteins and energy exchanges in membranes.", "conclusion": "The methods are applicable to other biological systems and soft materials for studying non-equilibrium phenomena."}}
{"id": "2506.23279", "pdf": "https://arxiv.org/pdf/2506.23279", "abs": "https://arxiv.org/abs/2506.23279", "authors": ["Yuncheng You"], "title": "Approximate Synchronization of Memristive Hopfield Neural Networks", "categories": ["math.AP", "34D06, 34D45, 37N25, 68T07, 92B20"], "comment": null, "summary": "Asymptotic synchronization is one of the essential differences between\nartificial neural networks and biologically inspired neural networks due to\nmismatches from dynamical update of weight parameters and heterogeneous\nactivations. In this paper a new concept of approximate synchronization is\nproposed and investigated for Hopfield neural networks coupled with nonlinear\nmemristors. It is proved that global solution dynamics are robustly dissipative\nand a sharp ultimate bound is acquired. Through \\emph{a priori} uniform\nestimates on the interneuron differencing equations, it is rigorously shown\nthat approximate synchronization to any prescribed small gap at an exponential\nconvergence rate of the memristive Hopfield neural networks occurs if an\nexplicitly computable threshold condition is satisfied by the interneuron\ncoupling strength coefficient. The main result is further extended to\nmemristive Hopfield neural networks with Hebbian learning rules for a broad\nrange of applications in unsupervised train learning.", "AI": {"tldr": "The paper introduces approximate synchronization in memristive Hopfield neural networks, proving robust dissipative dynamics and exponential convergence under a threshold condition.", "motivation": "To address the challenge of asymptotic synchronization differences between artificial and biologically inspired neural networks due to dynamical weight updates and heterogeneous activations.", "method": "Proposes and analyzes approximate synchronization in Hopfield neural networks with nonlinear memristors, using uniform estimates on interneuron differencing equations.", "result": "Demonstrates robust dissipative dynamics, a sharp ultimate bound, and exponential convergence to approximate synchronization under a computable threshold condition.", "conclusion": "The findings extend to memristive Hopfield networks with Hebbian learning, broadening applications in unsupervised train learning."}}
{"id": "2506.23741", "pdf": "https://arxiv.org/pdf/2506.23741", "abs": "https://arxiv.org/abs/2506.23741", "authors": ["Tomas Teijeiro", "Pouria Behnoudfar", "Jamie M. Taylor", "David Pardo", "Victor M. Calo"], "title": "Efficient Numerical Integration for Finite Element Trunk Spaces in 2D and 3D using Machine Learning: A new Optimisation Paradigm to Construct Application-Specific Quadrature Rules", "categories": ["math.NA", "cs.NA", "65D32"], "comment": "15 pages, 5 figures, 2 tables", "summary": "Finite element methods usually construct basis functions and quadrature rules\nfor multidimensional domains via tensor products of one-dimensional\ncounterparts. While straightforward, this approach results in integration\nspaces larger than necessary, especially as the polynomial degree $p$ or the\nspatial dimension increases, leading to considerable computational overhead.\nThis work starts from the hypothesis that reducing the dimensionality of the\npolynomial space can lead to quadrature rules with fewer points and lower\ncomputational cost, while preserving the exactness of numerical integration. We\nuse trunk spaces that exclude high-degree monomials that do not improve the\napproximation quality of the discrete space. These reduced spaces retain\nsufficient expressive power and allow us to construct smaller (more economical)\nintegration domains. Given a maximum degree $p$, we define trial and test\nspaces $U$ and $V$ as 2D or 3D trunk spaces and form the integration space\n$\\mathcal{S} = U \\otimes V$. We then construct exact quadrature rules by\nsolving a non-convex optimisation problem over the number of points $q$, their\ncoordinates, and weights. We use a shallow neural network with linear\nactivations to parametrise the rule, and a random restart strategy to mitigate\nconvergence to poor local minima. When necessary, we dynamically increase $q$\nto achieve exact integration. Our construction reaches machine-precision\naccuracy (errors below 1e-22) using significantly fewer points than standard\ntensor-product Gaussian quadrature: up to 30\\% reduction in 2D for $p \\leq 10$,\nand 50\\% in 3D for $p \\leq 6$. These results show that combining the\nmathematical understanding of polynomial structure with numerical optimisation\ncan lead to a practical and extensible methodology for improving the\nadaptiveness, efficiency, and scalability of quadrature rules for high-order\nfinite element simulations.", "AI": {"tldr": "The paper proposes using reduced polynomial spaces (trunk spaces) to create more efficient quadrature rules for finite element methods, reducing computational overhead while maintaining exact integration.", "motivation": "Standard tensor-product quadrature rules in finite element methods lead to unnecessarily large integration spaces, especially for high polynomial degrees or dimensions, causing computational inefficiency.", "method": "The authors define trial and test spaces as 2D or 3D trunk spaces, form an integration space, and solve a non-convex optimization problem to construct exact quadrature rules with fewer points. A shallow neural network and random restarts are used to optimize point coordinates and weights.", "result": "The method achieves machine-precision accuracy with up to 30% fewer points in 2D and 50% fewer in 3D compared to standard tensor-product quadrature.", "conclusion": "Combining polynomial structure understanding with numerical optimization yields practical, efficient, and scalable quadrature rules for high-order finite element simulations."}}
{"id": "2506.23089", "pdf": "https://arxiv.org/pdf/2506.23089", "abs": "https://arxiv.org/abs/2506.23089", "authors": ["Weiqiang Chen", "Kai Gong"], "title": "Insights into Ionic Diffusion in C-S-H Gel Pore from MD Simulations: Spatial Distributions, Energy Barriers, and Structural Descriptor", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "50 pages, 11 figures", "summary": "Understanding transport behavior in nanoconfined environments is critical to\nmany natural and engineering systems, including cementitious materials, yet its\nmolecular-level mechanisms remain poorly understood. Here, molecular dynamics\n(MD) simulations were used to investigate Na+, Cl-, and water diffusion inside\na 4 nm calcium-silicate-hydrate (C-S-H) pore channel over temperatures ranging\nfrom 300 K to 360 K. Spatially resolved analysis revealed strong suppression of\ndiffusivity near the solid-liquid interface and gradual recovery toward the\npore center. Arrhenius analysis further quantified the spatial variation of\nactivation energy barriers and intrinsic mobilities across the pore channel,\nshowing distinct confinement effects. The spatially resolved structural\nanalysis uncovers a mechanistic transition from structure-controlled to\nhydrodynamics-controlled transport regimes with increasing distance from the\npore surface. A structural descriptor, total coordination strength (TCS), was\nintroduced, providing a predictive link between local liquid structure and\nmolecular mobility within approximately 1 nm of the interface. Beyond 1 nm,\nsuppressed diffusivities were well captured by an exponential decay model based\non the Darcy-Brinkman framework. To the best of our knowledge, this is the\nfirst MD study to comprehensively resolve the spatial heterogeneity of\ntransport, thermal kinetics, and structure within cementitious nanopores. These\nfindings deepen the fundamental understanding of nanoscale transport phenomena\nand suggest that tailoring the nanochannel structure and interfacial chemistry\nof cementitious gels, such as surface coordination environments, pore size\ndistributions, and adsorption sites, may offer a promising strategy to suppress\nionic ingress and enhance the durability of cement-based materials.", "AI": {"tldr": "The paper investigates molecular transport in nanoconfined C-S-H pores using MD simulations, revealing spatial variations in diffusivity and activation energy, and introduces a structural descriptor (TCS) to predict mobility near interfaces.", "motivation": "Understanding transport in nanoconfined environments is crucial for natural and engineering systems, like cementitious materials, but molecular-level mechanisms are unclear.", "method": "MD simulations analyzed Na+, Cl-, and water diffusion in a 4 nm C-S-H pore channel across 300 K to 360 K, using spatially resolved and Arrhenius analyses.", "result": "Diffusivity is suppressed near interfaces, recovering toward the pore center. A mechanistic transition from structure-controlled to hydrodynamics-controlled transport was observed, with TCS predicting mobility near interfaces.", "conclusion": "Tailoring nanochannel structure and interfacial chemistry in cementitious gels could enhance durability by suppressing ionic ingress."}}
{"id": "2506.23327", "pdf": "https://arxiv.org/pdf/2506.23327", "abs": "https://arxiv.org/abs/2506.23327", "authors": ["Lauren M. M. Bonaldo", "Talita Mello", "Wladimir Neves"], "title": "An analysis of the 2-D isentropic Euler Equations for a generalized polytropic gas law", "categories": ["math.AP"], "comment": "30 pages", "summary": "In this paper we developed an analysis of the compressible, isentropic Euler\nequations in two spatial dimensions for a generalized polytropic gas law. The\nmain focus is rotational flows in the subsonic regimes, described through the\nframework of the Euler equations expressed in self-similar variables and\npseudo-velocities. A Bernoulli type equation is derived, serving as a\ncornerstone for establishing a self-similar system tailored to rotational\nflows. In the final section, the study extends to an analysis of a perturbed\nmodel, introducing the concept of quasi-potential flows, offering insights into\ntheir behavior and implications.", "AI": {"tldr": "Analysis of compressible, isentropic Euler equations in 2D for a generalized polytropic gas law, focusing on subsonic rotational flows using self-similar variables and pseudo-velocities. A Bernoulli-type equation is derived, and quasi-potential flows are explored.", "motivation": "To understand rotational flows in subsonic regimes for generalized polytropic gases using the Euler equations.", "method": "Uses self-similar variables and pseudo-velocities to derive a Bernoulli-type equation and analyze rotational flows. Extends to perturbed models for quasi-potential flows.", "result": "Established a self-similar system for rotational flows and insights into quasi-potential flows.", "conclusion": "The study provides a framework for analyzing rotational flows and extends understanding to quasi-potential flows in perturbed models."}}
{"id": "2506.23748", "pdf": "https://arxiv.org/pdf/2506.23748", "abs": "https://arxiv.org/abs/2506.23748", "authors": ["Nam Anh Nguyen", "Arnold Reusken"], "title": "Error analysis for a Finite Element Discretization of a radially symmetric harmonic map heat flow problem", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We consider the harmonic map heat flow problem for a radially symmetric case.\nFor discretization of this problem we apply a $H^1$-conforming finite element\nmethod in space combined with a semi-implicit Euler time stepping. The\nsemi-implicit Euler method results in a linear problem in each time step. We\nrestrict to the regime of smooth solutions of the continuous problem and\npresent an error analysis of this discretization method. This results in\noptimal order discretization error bounds. Key ingredients of the analysis are\na discrete energy estimate, that mimics the energy dissipation of the\ncontinuous solution, and a convexity property that is essential for discrete\nstability and for control of the linearization error. We also present numerical\nresults that validate the theoretical ones.", "AI": {"tldr": "The paper analyzes the harmonic map heat flow problem using a radially symmetric approach, employing an $H^1$-conforming finite element method and semi-implicit Euler time stepping. It provides optimal error bounds and validates results numerically.", "motivation": "To address the harmonic map heat flow problem in a radially symmetric case, ensuring accurate discretization and stability.", "method": "Uses $H^1$-conforming finite elements in space and semi-implicit Euler time stepping, resulting in linear problems per time step.", "result": "Achieves optimal order discretization error bounds, supported by discrete energy estimates and convexity properties.", "conclusion": "The method is validated numerically, demonstrating its effectiveness for smooth solutions of the continuous problem."}}
{"id": "2506.23765", "pdf": "https://arxiv.org/pdf/2506.23765", "abs": "https://arxiv.org/abs/2506.23765", "authors": ["Silvie Ill\u00e9sov\u00e1", "Tomasz Rybotycki", "Martin Beseda"], "title": "QMetric: Benchmarking Quantum Neural Networks Across Circuits, Features, and Training Dimensions", "categories": ["quant-ph", "physics.comp-ph"], "comment": null, "summary": "As hybrid quantum-classical models gain traction in machine learning, there\nis a growing need for tools that assess their effectiveness beyond raw\naccuracy. We present QMetric, a Python package offering a suite of\ninterpretable metrics to evaluate quantum circuit expressibility, feature\nrepresentations, and training dynamics. QMetric quantifies key aspects such as\ncircuit fidelity, entanglement entropy, barren plateau risk, and training\nstability. The package integrates with Qiskit and PyTorch, and is demonstrated\nvia a case study on binary MNIST classification comparing classical and\nquantum-enhanced models. Code, plots, and a reproducible environment are\navailable on GitLab.", "AI": {"tldr": "QMetric is a Python package for evaluating hybrid quantum-classical models with interpretable metrics like circuit fidelity and training stability.", "motivation": "The need for tools to assess hybrid quantum-classical models beyond raw accuracy.", "method": "QMetric provides metrics for circuit expressibility, feature representations, and training dynamics, integrating with Qiskit and PyTorch.", "result": "Demonstrated via a case study on binary MNIST classification comparing classical and quantum-enhanced models.", "conclusion": "QMetric offers a comprehensive toolkit for evaluating quantum models, with code and resources available on GitLab."}}
{"id": "2506.23365", "pdf": "https://arxiv.org/pdf/2506.23365", "abs": "https://arxiv.org/abs/2506.23365", "authors": ["Francesco Fanelli"], "title": "Yudovich theory under geometric regularity for density-dependent incompressible fluids", "categories": ["math.AP"], "comment": "Submitted", "summary": "This paper focuses on the study of the density-dependent incompressible Euler\nequations in space dimension $d=2$, for low regularity (\\textsl{i.e.}\nnon-Lipschitz) initial data satisfying assumptions in spirit of the celebrated\nYudovich theory for the classical homogeneous Euler equations.\n  We show that, under an \\textsl{a priori} control of a non-linear geometric\nquantity, namely the directional derivative $\\partial_Xu$ of the fluid velocity\n$u$ along the vector field $X:=\\nabla^\\perp\\rho$, where $\\rho$ is the fluid\ndensity, low regularity solutions \\textsl{\\`a la Yudovich} can be constructed\nalso in the non-homogeneous setting. More precisely, we prove the following\nfacts:\n  (i) \\emph{stability}: given a sequence of smooth approximate solutions\nenjoying a uniform control on the above mentioned geometric quantity, then (up\nto an extraction) that sequence converges to a Yudovich-type solution of the\ndensity-dependent incompressible Euler system; \\\\ (ii) \\emph{uniqueness}: there\nexists at most one Yudovich-type solution of the density-dependent\nincompressible Euler equations such that $\\partial_Xu$ remains finite; besides,\nthis statement improves previous uniqueness results for regular solutions,\ninasmuch as it requires less smoothness on the initial data.", "AI": {"tldr": "The paper extends Yudovich theory to density-dependent incompressible Euler equations in 2D, proving stability and uniqueness for low-regularity solutions under a geometric control condition.", "motivation": "To generalize Yudovich's results for homogeneous Euler equations to the non-homogeneous case, focusing on low-regularity initial data.", "method": "Uses a priori control of the directional derivative of velocity along a specific vector field to construct and analyze solutions.", "result": "Proves stability (convergence of approximate solutions) and uniqueness (under finiteness of the directional derivative) for Yudovich-type solutions.", "conclusion": "The study successfully extends Yudovich theory to density-dependent Euler equations, improving uniqueness conditions for less smooth initial data."}}
{"id": "2506.23892", "pdf": "https://arxiv.org/pdf/2506.23892", "abs": "https://arxiv.org/abs/2506.23892", "authors": ["Josie K\u00f6nig", "Elizabeth Qian", "Melina A. Freitag"], "title": "Dimension and model reduction approaches for linear Bayesian inverse problems with rank-deficient prior covariances", "categories": ["math.NA", "cs.NA", "cs.SY", "eess.SY"], "comment": null, "summary": "Bayesian inverse problems use observed data to update a prior probability\ndistribution for an unknown state or parameter of a scientific system to a\nposterior distribution conditioned on the data. In many applications, the\nunknown parameter is high-dimensional, making computation of the posterior\nexpensive due to the need to sample in a high-dimensional space and the need to\nevaluate an expensive high-dimensional forward model relating the unknown\nparameter to the data. However, inverse problems often exhibit low-dimensional\nstructure due to the fact that the available data are only informative in a\nlow-dimensional subspace of the parameter space. Dimension reduction approaches\nexploit this structure by restricting inference to the low-dimensional subspace\ninformed by the data, which can be sampled more efficiently. Further\ncomputational cost reductions can be achieved by replacing expensive\nhigh-dimensional forward models with cheaper lower-dimensional reduced models.\nIn this work, we propose new dimension and model reduction approaches for\nlinear Bayesian inverse problems with rank-deficient prior covariances, which\narise in many practical inference settings. The dimension reduction approach is\napplicable to general linear Bayesian inverse problems whereas the model\nreduction approaches are specific to the problem of inferring the initial\ncondition of a linear dynamical system. We provide theoretical approximation\nguarantees as well as numerical experiments demonstrating the accuracy and\nefficiency of the proposed approaches.", "AI": {"tldr": "The paper proposes dimension and model reduction methods for linear Bayesian inverse problems with rank-deficient prior covariances, improving computational efficiency while maintaining accuracy.", "motivation": "High-dimensional Bayesian inverse problems are computationally expensive due to sampling and forward model evaluations. Low-dimensional structure in data can be exploited for efficiency.", "method": "Dimension reduction restricts inference to low-dimensional subspaces informed by data. Model reduction replaces expensive high-dimensional forward models with cheaper reduced models.", "result": "Theoretical guarantees and numerical experiments show the proposed methods are accurate and efficient.", "conclusion": "The approaches effectively reduce computational costs in linear Bayesian inverse problems, particularly for inferring initial conditions in linear dynamical systems."}}
{"id": "2506.23775", "pdf": "https://arxiv.org/pdf/2506.23775", "abs": "https://arxiv.org/abs/2506.23775", "authors": ["Fabian Putterer", "Max M. Zumpe", "Isabel Nha Minh Le", "Qunsheng Huang", "Christian B. Mendl"], "title": "High-Performance Contraction of Quantum Circuits for Riemannian Optimization", "categories": ["quant-ph", "physics.comp-ph"], "comment": "15 pages, 18 figures", "summary": "This work focuses on optimizing the gates of a quantum circuit with a given\ntopology to approximate the unitary time evolution governed by a Hamiltonian.\nRecognizing that unitary matrices form a mathematical manifold, we employ\nRiemannian optimization methods -- specifically the Riemannian trust-region\nalgorithm -- which involves second derivative calculations with respect to the\ngates. Our key technical contribution is a matrix-free algorithmic framework\nthat avoids the explicit construction and storage of large unitary matrices\nacting on the whole Hilbert space. Instead, we evaluate all quantities as sums\nover state vectors, assuming that these vectors can be stored in memory. We\ndevelop HPC-optimized kernels for applying gates to state vectors and for the\ngradient and Hessian computation. Further improvements are achieved by\nexploiting sparsity structures due to Hamiltonian conservation laws, such as\nparity conservation, and lattice translation invariance. We benchmark our\nimplementation on the Fermi-Hubbard model with up to 16 sites, demonstrating a\nnearly linear parallelization speed-up with up to 112 CPU threads. Finally, we\ncompare our implementation with an alternative matrix product operator-based\napproach.", "AI": {"tldr": "The paper presents a method for optimizing quantum circuit gates using Riemannian optimization, avoiding large matrix storage by leveraging state vectors and HPC kernels.", "motivation": "To efficiently approximate unitary time evolution in quantum circuits without the computational burden of large matrix storage.", "method": "Uses Riemannian trust-region optimization, matrix-free algorithmic framework, and HPC-optimized kernels for gate operations and gradient/Hessian computations.", "result": "Demonstrated nearly linear parallelization speed-up on the Fermi-Hubbard model with 16 sites and compared favorably with a matrix product operator-based approach.", "conclusion": "The method is efficient and scalable, offering a practical solution for optimizing quantum circuits while conserving computational resources."}}
{"id": "2506.23378", "pdf": "https://arxiv.org/pdf/2506.23378", "abs": "https://arxiv.org/abs/2506.23378", "authors": ["Srinivasan Aiyappan", "Aditi Chattaraj", "Irina Pettersson"], "title": "Homogenization of an indefinite spectral problem arising in population genetics", "categories": ["math.AP", "math.SP", "35B27, 35B40, 35P15, 74K10, 35J25"], "comment": null, "summary": "We study an indefinite spectral problem for a second-order self-adjoint\nelliptic operator in an asymptotically thin cylinder. The operator coefficients\nand the spectral density function are assumed to be locally periodic in the\naxial direction of the cylinder. The key assumption is that the spectral\ndensity function changes sign, which leads to infinitely many both positive and\nnegative eigenvalues. The asymptotic behavior of the spectrum, as the thickness\nof the rod tends to zero, depends essentially on the sign of the average of the\ndensity function. We study the positive part of the spectrum in a specific case\nwhen the local average is negative. We derive a one-dimensional effective\nspectral problem that is a harmonic oscillator on the real line, and prove the\nconvergence of spectrum. A key auxiliary result is the existence of a positive\nprincipal eigenvalue of an indefinite spectral problem with the Neumann\nboundary condition on a periodicity cell. This study is motivated by\napplications in population genetics where spectral problems with sign-changing\nweight naturally appear.", "AI": {"tldr": "The paper analyzes the spectrum of a second-order self-adjoint elliptic operator in a thin cylinder with locally periodic coefficients and a sign-changing spectral density function. The asymptotic behavior of the spectrum is studied, focusing on the positive part when the average density is negative. A one-dimensional effective problem is derived, resembling a harmonic oscillator, and spectral convergence is proven.", "motivation": "The study is motivated by applications in population genetics, where spectral problems with sign-changing weight arise naturally.", "method": "The authors investigate the asymptotic behavior of the spectrum as the cylinder's thickness approaches zero, deriving a one-dimensional effective spectral problem (a harmonic oscillator) and proving spectral convergence. A key auxiliary result involves the existence of a positive principal eigenvalue for an indefinite spectral problem with Neumann boundary conditions.", "result": "The spectrum exhibits infinitely many positive and negative eigenvalues due to the sign-changing density function. The asymptotic behavior depends on the average density's sign, with the positive part of the spectrum converging to a one-dimensional harmonic oscillator when the average is negative.", "conclusion": "The paper provides insights into the spectral behavior of operators in thin cylinders with sign-changing weights, linking it to a simplified one-dimensional problem. The findings have implications for population genetics and similar fields."}}
{"id": "2506.23933", "pdf": "https://arxiv.org/pdf/2506.23933", "abs": "https://arxiv.org/abs/2506.23933", "authors": ["Aaron Brunk", "Maria Lukacova-Medvidova", "Dennis Schumann"], "title": "Structure-preserving approximation of the non-isothermal Cahn-Hilliard system", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We propose and analyze a structure-preserving approximation of the\nnon-isothermal Cahn-Hilliard equation using conforming finite elements for the\nspatial discretization and a problem-specific mixed explicit-implicit approach\nfor the temporal discretization. To ensure the preservation of structural\nproperties, i.e. conservation of mass and internal energy as well as entropy\nproduction, we introduce a suitable variational formulation for the continuous\nproblem, based on the entropy equation. Analytical findings are supported by\nnumerical tests, including convergence analysis.", "AI": {"tldr": "A structure-preserving approximation of the non-isothermal Cahn-Hilliard equation is proposed, using conforming finite elements and a mixed explicit-implicit temporal approach, ensuring mass and energy conservation and entropy production.", "motivation": "To develop a numerical method that preserves structural properties (mass, energy conservation, entropy production) in the non-isothermal Cahn-Hilliard equation.", "method": "Uses conforming finite elements for spatial discretization and a mixed explicit-implicit approach for temporal discretization, with a variational formulation based on the entropy equation.", "result": "Analytical findings confirm the method's structure-preserving properties, supported by numerical tests and convergence analysis.", "conclusion": "The proposed method effectively preserves structural properties and demonstrates robustness through numerical validation."}}
{"id": "2506.23837", "pdf": "https://arxiv.org/pdf/2506.23837", "abs": "https://arxiv.org/abs/2506.23837", "authors": ["Pratik Mullick", "Parongama Sen"], "title": "Sociophysics models inspired by the Ising model", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "physics.comp-ph"], "comment": "19 pages, 6 figures", "summary": "The Ising model, originally developed for understanding magnetic phase\ntransitions, has become a cornerstone in the study of collective phenomena\nacross diverse disciplines. In this review, we explore how Ising and Ising-like\nmodels have been successfully adapted to sociophysical systems, where\nbinary-state agents mimic human decisions or opinions. By focusing on key areas\nsuch as opinion dynamics, financial markets, social segregation, game theory,\nlanguage evolution, and epidemic spreading, we demonstrate how the models\ndescribing these phenomena, inspired by the Ising model, capture essential\nfeatures of collective behavior, including phase transitions, consensus\nformation, criticality, and metastability. In particular, we emphasize the role\nof the dynamical rules of evolution in the different models that often converge\nback to Ising-like universality. We end by outlining the future directions in\nsociphysics research, highlighting the continued relevance of the Ising model\nin the analysis of complex social systems.", "AI": {"tldr": "The paper reviews the adaptation of the Ising model to sociophysical systems, showing its effectiveness in modeling collective behaviors like opinion dynamics and epidemic spreading.", "motivation": "To demonstrate the versatility of the Ising model in capturing collective phenomena in sociophysical systems.", "method": "Review and analysis of Ising-like models applied to areas such as opinion dynamics, financial markets, and social segregation.", "result": "The Ising model effectively captures key features of collective behavior, including phase transitions and consensus formation.", "conclusion": "The Ising model remains highly relevant for analyzing complex social systems, with potential for future research in sociphysics."}}
{"id": "2506.23559", "pdf": "https://arxiv.org/pdf/2506.23559", "abs": "https://arxiv.org/abs/2506.23559", "authors": ["Leonard Busch", "Matti Lassas", "Lauri Oksanen", "Mikko Salo"], "title": "On Exponential Instability of an Inverse Problem for the Wave Equation", "categories": ["math.AP"], "comment": "13 pages, 1 figure", "summary": "For a time-independent potential $q\\in L^\\infty$, consider the\nsource-to-solution operator that maps a source $f$ to the solution $u=u(t,x)$\nof $(\\Box+q)u=f$ in Euclidean space with an obstacle, where we impose on $u$\nvanishing Cauchy data at $t=0$ and vanishing Dirichlet data at the boundary of\nthe obstacle. We study the inverse problem of recovering the potential $q$ from\nthis source-to-solution map restricted to some measurement domain. By giving an\nexample where measurements take place in some subset and the support of $q$\nlies in the `shadow region' of the obstacle, we show that recovery of $q$ is\nexponentially unstable.", "AI": {"tldr": "The paper examines the instability of recovering a potential $q$ from a source-to-solution map in a Euclidean space with an obstacle, showing exponential instability in certain cases.", "motivation": "To understand the feasibility and stability of reconstructing the potential $q$ from limited measurements in the presence of an obstacle.", "method": "Analyzes the source-to-solution operator for the wave equation with an obstacle, focusing on cases where measurements are restricted and $q$ lies in a 'shadow region.'", "result": "Demonstrates that recovering $q$ is exponentially unstable when measurements are confined and $q$ is in the shadow region.", "conclusion": "The study highlights the challenges in inverse problems involving obstacles, showing that stability deteriorates exponentially in certain scenarios."}}
{"id": "2506.23947", "pdf": "https://arxiv.org/pdf/2506.23947", "abs": "https://arxiv.org/abs/2506.23947", "authors": ["Yingsong Jiang", "Ruishu Liu", "Minhong Xu"], "title": "Explicit modified Euler approximations of the A\u00eft-Sahalia type model with Poisson jumps", "categories": ["math.NA", "cs.NA", "60H35, 60H15, 65C30"], "comment": null, "summary": "This paper focuses on mean-square approximations of a generalized\nA\\\"it-Sahalia interest rate model with Poisson jumps. The main challenge in the\nconstruction and analysis of time-discrete numerical schemes is caused by a\ndrift that blows up at the origin, highly nonlinear drift and diffusion\ncoefficients and positivity-preserving requirement. Due to the presence of the\nPoisson jumps, additional difficulties arise in recovering the exact order\n$1/2$ of convergence for the time-stepping schemes. By incorporating\nimplicitness in the term $\\alpha_{-1}x^{-1} $ and introducing the modifications\nfunctions $f_h$ and $g_h$ in the recursion, a novel explicit Euler-type scheme\nis proposed, which is easy to implement and preserves the positivity of the\noriginal model unconditionally, i.e., for any time step-size $h>0$. A\nmean-square convergence rate of order $1/2$ is established for the proposed\nscheme in both the non-critical and general critical cases. Finally, numerical\nexperiments are provided to confirm the theoretical findings.", "AI": {"tldr": "The paper proposes a novel explicit Euler-type scheme for the A\u00eft-Sahalia interest rate model with Poisson jumps, addressing challenges like drift blow-up and positivity preservation. It achieves a mean-square convergence rate of 1/2.", "motivation": "The study aims to overcome difficulties in numerical schemes for the A\u00eft-Sahalia model, including nonlinear drift/diffusion, positivity preservation, and Poisson jumps.", "method": "The authors introduce implicitness in the drift term and modification functions in the recursion to create an explicit Euler-type scheme.", "result": "The proposed scheme preserves positivity unconditionally and achieves a mean-square convergence rate of 1/2, confirmed by numerical experiments.", "conclusion": "The new scheme is effective for the A\u00eft-Sahalia model, handling its complexities while maintaining simplicity and theoretical guarantees."}}
{"id": "2506.23993", "pdf": "https://arxiv.org/pdf/2506.23993", "abs": "https://arxiv.org/abs/2506.23993", "authors": ["Himanshu Joshi", "Shradhanjali Dewan", "Lalrin Kima", "Aldrin Lalremtluanga", "Homnath Luitel", "K. C. Bhamu", "D. P. Rai"], "title": "Half-metallicity and anomalous Slater-Pauling behaviour in half-Heusler CrMnSb", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "12 pages, 6 figures, 1 table", "summary": "This study provides a first-principles insight into half-Heusler CrMnSb to\nunderstand its deviation from the conventional Slater-Pauling semiconducting\nbehavior. CrMnSb, having a valence electron count of 18, has been proposed to\nexhibit compensated ferrimagnetic character instead of the expected nonmagnetic\nsemiconducting ground state. As half-Heusler systems with a valence electron\ncount of 18 are not known to exhibit magnetic ordering, we have investigated\nthe electronic and magnetic properties of CrMnSb using a combination of density\nfunctional theory and Green's function-based multiple-scattering theory. We\nshow that, despite satisfying the 18 valence electron Slater-Pauling rule,\nCrMnSb does not exhibit ground-state nonmagnetic semiconducting behavior.\nInstead, it reveals a half-metallic, fully compensated ferrimagnetic ground\nstate. This anomaly originates from the presence of localized sublattice\nmoments, resulting from antiparallel alignment between Cr and Mn sublattices,\nwhich enforces half-metallic ferrimagnetism despite its ideal 18 valence\nelectron count.", "AI": {"tldr": "CrMnSb, a half-Heusler with 18 valence electrons, defies the Slater-Pauling rule by exhibiting a half-metallic ferrimagnetic state instead of the expected nonmagnetic semiconductor behavior.", "motivation": "To understand why CrMnSb deviates from the conventional Slater-Pauling semiconducting behavior despite having 18 valence electrons.", "method": "Combination of density functional theory and Green's function-based multiple-scattering theory.", "result": "CrMnSb shows a half-metallic, fully compensated ferrimagnetic ground state due to antiparallel alignment of Cr and Mn sublattices.", "conclusion": "The anomaly arises from localized sublattice moments, enforcing ferrimagnetism despite the 18 valence electron count."}}
{"id": "2506.23572", "pdf": "https://arxiv.org/pdf/2506.23572", "abs": "https://arxiv.org/abs/2506.23572", "authors": ["Artem Shafeev", "Yuri Trakhinin"], "title": "Three-dimensional structural stability of shock waves in elastodynamics", "categories": ["math.AP", "35Q35, 35L67, 35L04, 35L05, 76L05"], "comment": "22 pages", "summary": "We study the three-dimensional structural stability of shock waves for the\nequations of elastodynamics governing isentropic flows of compressible inviscid\nelastic materials. By nonlinear structural stability of a shock wave we mean\nthe local-in-time existence and uniqueness of the discontinuous shock front\nsolution to the hyperbolic system of elastodynamics. By using equivalent\nformulations of the uniform and weak Kreiss-Lopatinski conditions for 1-shocks,\nwe show that planar shock waves in three-dimensional elastodynamics are always\nat least weakly stable, and we find a condition necessary and sufficient for\ntheir uniform stability. Since the system of elastodynamics satisfies the\nAgranovich-Majda-Osher block structure condition, uniform stability implies\nstructural stability of corresponding nonplanar shock waves. We also show that,\nas in isentropic gas dynamics, all compressive shock waves are uniformly stable\nfor convex equations of state. This paper is a natural continuation of the\nprevious two-dimensional analysis in [Morando A., Trakhinin Y., Trebeschi P.,\nMath. Ann. 378 (2020), 1471-1504; Trakhinin Y., J. Hyperbolic Differ. Equ. 19\n(2022), 157-173]. As in the two-dimensional case, we make the conclusion that\nthe elastic force plays stabilizing role for uniform stability.", "AI": {"tldr": "The paper analyzes the structural stability of shock waves in 3D elastodynamics, showing planar shocks are weakly stable and identifying conditions for uniform stability. Compressive shocks are uniformly stable for convex equations of state.", "motivation": "To extend previous 2D analysis to 3D and understand the stability of shock waves in elastodynamics, focusing on the role of elastic forces.", "method": "Uses equivalent formulations of Kreiss-Lopatinski conditions for 1-shocks and leverages the Agranovich-Majda-Osher block structure condition.", "result": "Planar shock waves are weakly stable; uniform stability depends on specific conditions. Compressive shocks are uniformly stable for convex equations of state.", "conclusion": "Elastic forces stabilize shock waves, confirming findings from 2D studies."}}
{"id": "2506.23969", "pdf": "https://arxiv.org/pdf/2506.23969", "abs": "https://arxiv.org/abs/2506.23969", "authors": ["Martin Hutzenthaler", "Tuan Anh Nguyen"], "title": "Full history recursive multilevel Picard approximations suffer from the curse of dimensionality for the Hamilton-Jacobi-Bellman equation of a stochastic control problem", "categories": ["math.NA", "cs.NA"], "comment": "21 pages", "summary": "Full history recursive multilevel Picard (MLP) approximations have been\nproved to overcome the curse of dimensionality in the numerical approximation\nof semilinear heat equations with nonlinearities which are globally Lipschitz\ncontinuous with respect to the maximum-norm. Nonlinearities in\nHamilton-Jacobi-Bellman equations in stochastic control theory, however, are\noften (locally) Lipschitz continuous with respect to the standard Euclidean\nnorm. In this paper we prove the surprising fact that MLP approximations for\none such example equation suffer from the curse of dimensionality.", "AI": {"tldr": "MLP approximations overcome dimensionality curse for semilinear heat equations but fail for a specific Hamilton-Jacobi-Bellman equation due to its norm properties.", "motivation": "To investigate the applicability of MLP approximations for equations with nonlinearities in stochastic control theory, which differ in norm properties.", "method": "Analyze MLP approximations for a Hamilton-Jacobi-Bellman equation with locally Lipschitz nonlinearities under the Euclidean norm.", "result": "MLP approximations suffer from the curse of dimensionality for the studied equation.", "conclusion": "The norm properties of nonlinearities critically impact the effectiveness of MLP approximations, limiting their applicability in certain cases."}}
{"id": "2506.23608", "pdf": "https://arxiv.org/pdf/2506.23608", "abs": "https://arxiv.org/abs/2506.23608", "authors": ["Alessio Figalli", "Andr\u00e9 Guerra", "Sunghan Kim", "Henrik Shahgholian"], "title": "Constraint Maps: Insights and Related Themes", "categories": ["math.AP"], "comment": "To Sandro Salsa, on his 75th birthday, in recognition of his profound\n  contributions to the theory and development of free boundary problems", "summary": "This paper explores recent progress related to constraint maps. Building on\nthe exposition in [14], our goal is to provide a clear and accessible account\nof some of the more intricate arguments behind the main results in this work.\nAlong the way, we include several new results of independent value. In\nparticular, we give optimal geometric conditions on the target manifold that\nguarantee a unique continuation result for the projected image map. We also\nprove that the gradient of a minimizing harmonic map (or, more generally, of a\nminimizing constraint map) is an $A_\\infty$-weight, and therefore satisfies a\nstrong form of the unique continuation principle. In addition, we outline\npossible directions for future research and highlight several open problems\nthat may interest researchers working on free boundary problems and harmonic\nmaps.", "AI": {"tldr": "The paper clarifies complex arguments about constraint maps, introduces new results like optimal geometric conditions for unique continuation, and proves gradient properties of minimizing maps.", "motivation": "To provide a clear and accessible explanation of intricate arguments in constraint maps and contribute new findings.", "method": "Builds on prior work, introduces optimal geometric conditions, and analyzes gradients of minimizing harmonic maps.", "result": "Proves gradient of minimizing maps is an $A_\\infty$-weight and ensures unique continuation. Also provides new geometric conditions.", "conclusion": "Offers insights into constraint maps, presents new results, and suggests future research directions in harmonic maps and free boundary problems."}}
{"id": "2506.24054", "pdf": "https://arxiv.org/pdf/2506.24054", "abs": "https://arxiv.org/abs/2506.24054", "authors": ["Jakob Eggl", "Elias Mindlberger", "Mario Ullrich"], "title": "Sparse grids vs. random points for high-dimensional polynomial approximation", "categories": ["math.NA", "cs.NA", "65D05 (Primary)"], "comment": "31 pages, 12 figures", "summary": "We study polynomial approximation on a $d$-cube, where $d$ is large, and\ncompare interpolation on sparse grids, aka Smolyak's algorithm (SA), with a\nsimple least squares method based on randomly generated points (LS) using\nstandard benchmark functions. Our main motivation is the influential paper\n[Barthelmann, Novak, Ritter: High dimensional polynomial interpolation on\nsparse grids, Adv. Comput. Math. 12, 2000]. We repeat and extend their\ntheoretical analysis and numerical experiments for SA and compare to LS in\ndimensions up to 100. Our extensive experiments demonstrate that LS, even with\nonly slight oversampling, consistently matches the accuracy of SA in low\ndimensions. In high dimensions, however, LS shows clear superiority.", "AI": {"tldr": "Comparison of sparse grid interpolation (Smolyak's algorithm) and least squares with random points for polynomial approximation in high dimensions. LS matches SA in low dimensions and outperforms in high dimensions.", "motivation": "Extending the analysis from Barthelmann et al. (2000) on high-dimensional polynomial interpolation, comparing SA and LS methods.", "method": "Theoretical analysis and numerical experiments comparing SA and LS on benchmark functions in dimensions up to 100.", "result": "LS matches SA accuracy in low dimensions with slight oversampling and outperforms SA in high dimensions.", "conclusion": "LS is superior to SA for high-dimensional polynomial approximation, especially with oversampling."}}
{"id": "2506.23660", "pdf": "https://arxiv.org/pdf/2506.23660", "abs": "https://arxiv.org/abs/2506.23660", "authors": ["Bogdan Maxim"], "title": "A doubly nonlinear elliptic problem with variable exponents, homogeneous Neumann conditions and generalized logistic source", "categories": ["math.AP", "35A01, 35A02, 35B09, 35D30, 35J20, 35J62, 35J92, 98A08"], "comment": "51 pages. arXiv admin note: substantial text overlap with\n  arXiv:2502.20756", "summary": "The aim of this work is to prove existence and uniqueness results for a\ndoubly nonlinear elliptic problem that is essential for solving the associated\nparabolic problem using Rothe's method (discretizing time). We work under very\nweak assumptions, dropping the commonly used condition that the source term is\nlocally Lipschitz, which appears frequently in the literature. Instead, we rely\non the continuity of the Nemytskii operator between two Lebesgue spaces with\nvariable exponents. All results presented here are proved in full detail, which\nmakes the article lengthy.", "AI": {"tldr": "Existence and uniqueness results for a doubly nonlinear elliptic problem, relaxing the locally Lipschitz condition on the source term, using variable exponent Lebesgue spaces.", "motivation": "To solve the associated parabolic problem via Rothe's method under weaker assumptions than commonly used.", "method": "Relies on the continuity of the Nemytskii operator between variable exponent Lebesgue spaces, dropping the locally Lipschitz condition.", "result": "Proves existence and uniqueness for the doubly nonlinear elliptic problem.", "conclusion": "The results are rigorously proved, though the paper is lengthy due to detailed proofs."}}
{"id": "2506.22553", "pdf": "https://arxiv.org/pdf/2506.22553", "abs": "https://arxiv.org/abs/2506.22553", "authors": ["Heinz H. Bauschke", "Tran Thanh Tung"], "title": "On a result by Meshulam", "categories": ["math.OC", "cs.NA", "math.FA", "math.NA", "47H09, 65K05, 90C25 (Primary) 52A37, 52B55 (Secondary)"], "comment": null, "summary": "In 1996, Meshulam proved that every sequence generated by applying\nprojections onto affine subspaces, drawn from a finite collection in Euclidean\nspace, must be bounded.\n  In this paper, we extend his result not only from affine subspaces to convex\npolyhedral subsets, but also from Euclidean to general Hilbert space. Various\nexamples are provided to illustrate the sharpness of the results.", "AI": {"tldr": "The paper extends Meshulam's 1996 result on bounded sequences from affine subspaces in Euclidean space to convex polyhedral subsets in general Hilbert space.", "motivation": "To generalize Meshulam's bounded sequence theorem to broader settings, including convex polyhedral subsets and Hilbert spaces.", "method": "Extends the original proof framework to handle convex polyhedral subsets and general Hilbert spaces, supported by illustrative examples.", "result": "The sequences remain bounded under projections onto convex polyhedral subsets in Hilbert spaces, with examples demonstrating the sharpness of the results.", "conclusion": "The paper successfully generalizes Meshulam's theorem, confirming boundedness in more complex and abstract settings."}}
{"id": "2506.23763", "pdf": "https://arxiv.org/pdf/2506.23763", "abs": "https://arxiv.org/abs/2506.23763", "authors": ["Abdelkrim Atailia", "Frekh Taallah"], "title": "On Existence and Uniqueness of the Solution of a Two-Surfaces Contact Problem Using a Fixed Point Approach", "categories": ["math.AP", "74M15, 47H10, 35J88"], "comment": "7 pages, 3 figures", "summary": "In this work, we give the proof of the existence and uniqueness of the\nsolution to the weak form of a two-surfaces contact problem using fixed point\napproach. We begin by modeling the evolution of a two deformable surfaces\ncontact problem with a general viscoplastic law, the contact is considered\nfrictionless and governed by the Signorini-type condition with an initial gap.\nThen, we derive the variational formulation of the classical problem. Finally,\nwe conclude our work by establishing an existence and uniqueness theorem for\nthe weak form.", "AI": {"tldr": "Proof of existence and uniqueness for a two-surfaces contact problem's weak solution using fixed point approach.", "motivation": "To address the need for rigorous mathematical treatment of contact problems involving deformable surfaces with viscoplastic behavior.", "method": "Modeled the contact problem with a general viscoplastic law, derived its variational formulation, and applied fixed point theory.", "result": "Established an existence and uniqueness theorem for the weak form of the problem.", "conclusion": "The work provides a theoretical foundation for solving such contact problems, confirming solution validity."}}
{"id": "2506.22564", "pdf": "https://arxiv.org/pdf/2506.22564", "abs": "https://arxiv.org/abs/2506.22564", "authors": ["Bobby Shi", "Julia Lindberg", "Joe Kileel"], "title": "Efficient Tensor Decomposition via Moment Matrix Extension", "categories": ["math.AG", "cs.NA", "cs.SC", "math.NA"], "comment": null, "summary": "Motivated by a flurry of recent work on efficient tensor decomposition\nalgorithms, we show that the celebrated moment matrix extension algorithm of\nBrachat, Comon, Mourrain, and Tsigaridas for symmetric tensor canonical\npolyadic (CP) decomposition can be made efficient under the right conditions.\nWe first show that the crucial property determining the complexity of the\nalgorithm is the regularity of a target decomposition. This allows us to reduce\nthe complexity of the vanilla algorithm, while also unifying results from\nprevious works. We then show that for tensors in $S^d\\mathbb{C}^{n+1}$ with $d$\neven, low enough regularity can reduce finding a symmetric tensor decomposition\nto solving a system of linear equations. For order-$4$ tensors we prove that\ngeneric tensors of rank up to $r=2n+1$ can be decomposed efficiently via moment\nmatrix extension, exceeding the rank threshold allowed by simultaneous\ndiagonalization. We then formulate a conjecture that states for generic\norder-$4$ tensors of rank $r=O(n^2)$ the induced linear system is sufficient\nfor efficient tensor decomposition, matching the asymptotics of existing\nalgorithms and in fact improving the leading coefficient. Towards this\nconjecture we give computer assisted proofs that the statement holds for $n=2,\n\\dots, 17$. Next we demonstrate that classes of nonidentifiable tensors can be\ndecomposed efficiently via the moment matrix extension algorithm, bypassing the\nusual need for uniqueness of decomposition. Of particular interest is the class\nof monomials, for which the extension algorithm is not only efficient but also\nimproves on existing theory by explicitly parameterizing the space of\ndecompositions. Code for implementations of the efficient algorithm for generic\ntensors and monomials are provided, along with several numerical examples.", "AI": {"tldr": "The paper improves the efficiency of the moment matrix extension algorithm for symmetric tensor CP decomposition by focusing on regularity, reducing complexity, and enabling efficient decomposition for certain tensor classes.", "motivation": "Recent work on efficient tensor decomposition algorithms inspired the study to enhance the moment matrix extension algorithm's efficiency under specific conditions.", "method": "The paper analyzes the regularity of target decompositions to reduce algorithm complexity and shows that for certain tensors, decomposition can be reduced to solving linear systems. It also provides computer-assisted proofs for conjectures.", "result": "For order-4 tensors, generic tensors of rank up to r=2n+1 can be decomposed efficiently, exceeding previous rank thresholds. Nonidentifiable tensors, like monomials, can also be decomposed efficiently.", "conclusion": "The study advances tensor decomposition efficiency, particularly for symmetric tensors, and provides practical implementations and examples."}}
{"id": "2506.23807", "pdf": "https://arxiv.org/pdf/2506.23807", "abs": "https://arxiv.org/abs/2506.23807", "authors": ["Lingping Kang", "Yanfang Peng", "Chengfeng Xiong"], "title": "Nonlinearity exponential stability for Lions-Feireisl's weak solutions to the three-dimensional Barotropic Compressible Navier-Stokes Equations with large Potential Force", "categories": ["math.AP"], "comment": null, "summary": "We consider the large-time behavior for the barotropic compressible\nNavier-Stokes equations with large external force in 3D bounded domain. By\nconstructing a suitable Lyapunov functional and using the extra integrability\nof the density, we state the exponentially decay-in-time to the equilibrium\nstate for Lions-Feireisl's finite-energy weak solutions. In addition, some\ncareful discussion on Taylor expansion also plays a crucial role in our\nanalysis. The main difficulty lies in the fact that the equilibrium state of\ndensity is not a constant anymore induced by the large external force. It\nshould be noted that our result can be regarded as an extension of \\cite{PSW}\nto large potential forces case.", "AI": {"tldr": "The paper analyzes the large-time behavior of barotropic compressible Navier-Stokes equations with large external forces in 3D bounded domains, showing exponential decay to equilibrium for weak solutions.", "motivation": "To extend previous results (like \\cite{PSW}) to cases with large external forces, where the equilibrium density is non-constant.", "method": "Constructs a Lyapunov functional and uses density integrability, with careful Taylor expansion analysis.", "result": "Exponential decay to equilibrium is proven for finite-energy weak solutions.", "conclusion": "The work extends existing results to large potential forces, addressing the challenge of non-constant equilibrium density."}}
{"id": "2506.22634", "pdf": "https://arxiv.org/pdf/2506.22634", "abs": "https://arxiv.org/abs/2506.22634", "authors": ["Bugra Kilictas", "Faruk Alpay"], "title": "A Rigorous Error Bound for the TG Kernel in Prime Counting", "categories": ["math.NT", "cs.DS", "cs.NA", "math.NA", "11N05, 11Y35, 11M26, 65B10", "F.2.1; I.1.2"], "comment": "19 pages, 0 figure", "summary": "We establish rigorous error bounds for prime counting using a truncated\nGaussian (TG) kernel in the explicit formula framework. Our main theorem proves\nthat the approximation error remains globally below 1/2 for all sufficiently\nlarge arguments, guaranteeing exact computation of {\\pi}(x) through simple\nrounding, without relying on unproven hypotheses.\n  The TG kernel construction employs Gaussian-like test functions with compact\nsupport, engineered with vanishing moments to eliminate main terms. For x with\n10^8 decimal digits, we demonstrate that only ~1200 nontrivial zeta zeros\nsuffice to achieve the error bound, enabling computation in seconds on modern\nhardware - a dramatic improvement over classical methods.\n  Key contributions include: (1) Explicit tail truncation bounds using Taylor\nremainder analysis, showing exponential decay; (2) Zero-sum truncation error\nbounds via unconditional density estimates; (3) Rigorous treatment of trivial\nzero contributions. All constants are made explicit, ensuring full\nverifiability.\n  The method bridges analytic number theory and practical computation, with\npotential applications to record-breaking prime counting computations. We\ndiscuss algorithmic implications including FFT-based arithmetic for ~330\nmillion bit numbers. The framework's flexibility suggests connections to deeper\nstructures in prime distribution, particularly regarding optimized kernel\ndesigns and the interplay between smoothing parameters {\\alpha} and truncation\nheights.\n  This work exemplifies how classical analytic techniques, when carefully\nimplemented with modern computational perspectives, yield practical algorithms\nfor problems previously considered purely theoretical. The rigorous error\nanalysis ensures reliability even at astronomical scales, opening new avenues\nfor computational number theory research.", "AI": {"tldr": "The paper establishes rigorous error bounds for prime counting using a truncated Gaussian kernel, ensuring exact computation of \u03c0(x) without unproven hypotheses. It demonstrates efficiency for large-scale computations and connects analytic number theory with practical algorithms.", "motivation": "The motivation is to bridge analytic number theory and practical computation by providing a reliable method for exact prime counting at large scales, avoiding reliance on unproven hypotheses.", "method": "The method involves using a truncated Gaussian kernel with compact support and vanishing moments, combined with explicit error bounds for tail truncation, zero-sum truncation, and trivial zero contributions.", "result": "For x with 10^8 decimal digits, the method achieves the error bound with ~1200 nontrivial zeta zeros, enabling fast computation. All constants are explicit for verifiability.", "conclusion": "The work demonstrates how classical analytic techniques, when combined with modern computation, yield practical algorithms for theoretical problems, opening new research avenues in computational number theory."}}
{"id": "2506.23868", "pdf": "https://arxiv.org/pdf/2506.23868", "abs": "https://arxiv.org/abs/2506.23868", "authors": ["Benjamin Harrop-Griffiths", "Rowan Killip", "Monica Visan"], "title": "A priori bounds and equicontinuity of orbits for the intermediate long wave equation", "categories": ["math.AP"], "comment": "17 pages", "summary": "We prove uniform-in-time a priori $H^s$ bounds for solutions to the\nintermediate long wave equation posed both on the line and on the circle,\ncovering the range $-\\frac12<s\\leq0$. Additionally, we prove that the set of\norbits emanating from a bounded and equicontinuous set in $H^s$ is also bounded\nand equicontinuous in $H^s$. Our proof is based on the identification of a\nsuitable Lax pair formulation for the intermediate long wave equation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.22701", "pdf": "https://arxiv.org/pdf/2506.22701", "abs": "https://arxiv.org/abs/2506.22701", "authors": ["Shi Jie Yu"], "title": "Lower bounds for trace estimation via Block Krylov and other methods", "categories": ["math.ST", "cs.DS", "cs.LG", "cs.NA", "math.NA", "stat.TH"], "comment": null, "summary": "This paper studies theoretical lower bounds for estimating the trace of a\nmatrix function, $\\text{tr}(f(A))$, focusing on methods that use Hutchinson's\nmethod along with Block Krylov techniques. These methods work by approximating\nmatrix-vector products like $f(A)V$ using a Block Krylov subspace. This is\nclosely related to approximating functions with polynomials. We derive\ntheoretical upper bounds on how many Krylov steps are needed for functions such\nas $A^{-1/2}$ and $A^{-1}$ by analyzing the upper bounds from the polynomial\napproximation of their scalar equivalent. In addition, we also develop lower\nlimits on the number of queries needed for trace estimation, specifically for\n$\\text{tr}(W^{-p})$ where $W$ is a Wishart matrix. Our study clarifies the\nconnection between the number of steps in Block Krylov methods and the degree\nof the polynomial used for approximation. This links the total cost of trace\nestimation to basic limits in polynomial approximation and how much information\nis needed for the computation.", "AI": {"tldr": "The paper explores theoretical bounds for estimating the trace of matrix functions using Hutchinson's method and Block Krylov techniques, linking Krylov steps to polynomial approximation degrees.", "motivation": "To understand the theoretical limits and efficiency of trace estimation methods for matrix functions, particularly focusing on polynomial approximation and Krylov subspace techniques.", "method": "Uses Hutchinson's method combined with Block Krylov techniques to approximate matrix-vector products and analyzes polynomial approximations for functions like $A^{-1/2}$ and $A^{-1}$.", "result": "Derives upper bounds on Krylov steps for specific functions and lower limits on queries for trace estimation, especially for Wishart matrices.", "conclusion": "The study connects Krylov method steps to polynomial approximation degrees, highlighting the relationship between computational cost and fundamental limits in approximation."}}
{"id": "2506.23910", "pdf": "https://arxiv.org/pdf/2506.23910", "abs": "https://arxiv.org/abs/2506.23910", "authors": ["Stefan Schiffer", "Espen Xylander"], "title": "A variational view on constitutive laws in parabolic problems", "categories": ["math.AP", "35Q30, 49J45, 76D05"], "comment": "51 pages", "summary": "We consider a variational approach to solve parabolic problems by minimising\na functional over time and space. To achieve existence results we investigate\nthe notion of $\\mathscr{A}$-quasiconvexity for non-homogeneous operators in\nanisotropic spaces. The abstract theory is then applied to formulate a\nvariational solution concept for the non-Newtonian Navier--Stokes equations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.22826", "pdf": "https://arxiv.org/pdf/2506.22826", "abs": "https://arxiv.org/abs/2506.22826", "authors": ["Robert Beinert", "Jonas Bresch"], "title": "Denoising Multi-Color QR Codes and Stiefel-Valued Data by Relaxed Regularizations", "categories": ["math.OC", "cs.CV", "cs.NA", "math.NA", "94A08, 94A12, 65J22, 90C22, 90C25"], "comment": "9 pages, 2 figures, 3 algorithms", "summary": "The handling of manifold-valued data, for instance, plays a central role in\ncolor restoration tasks relying on circle- or sphere-valued color models, in\nthe study of rotational or directional information related to the special\northogonal group, and in Gaussian image processing, where the pixel statistics\nare interpreted as values on the hyperbolic sheet. Especially, to denoise these\nkind of data, there have been proposed several generalizations of total\nvariation (TV) and Tikhonov-type denoising models incorporating the underlying\nmanifolds. Recently, a novel, numerically efficient denoising approach has been\nintroduced, where the data are embedded in an Euclidean ambient space, the\nnon-convex manifolds are encoded by a series of positive semi-definite,\nfixed-rank matrices, and the rank constraint is relaxed to obtain a\nconvexification that can be solved using standard algorithms from convex\nanalysis. The aim of the present paper is to extent this approach to new kinds\nof data like multi-binary and Stiefel-valued data. Multi-binary data can, for\ninstance, be used to model multi-color QR codes whereas Stiefel-valued data\noccur in image and video-based recognition. For both new data types, we propose\nTV- and Tikhonov-based denoising modelstogether with easy-to-solve\nconvexification. All derived methods are evaluated on proof-of-concept,\nsynthetic experiments.", "AI": {"tldr": "The paper extends a convexification-based denoising approach to multi-binary and Stiefel-valued data, proposing TV- and Tikhonov-based models with synthetic experiments.", "motivation": "To address denoising challenges in manifold-valued data, particularly for multi-binary (e.g., multi-color QR codes) and Stiefel-valued data (e.g., image/video recognition).", "method": "Embed data in Euclidean space, encode manifolds via fixed-rank matrices, relax rank constraints for convexification, and apply TV/Tikhonov models.", "result": "Proposed models are evaluated on synthetic experiments, demonstrating feasibility.", "conclusion": "The approach successfully extends to new data types, offering efficient denoising solutions for manifold-valued data."}}
{"id": "2506.23948", "pdf": "https://arxiv.org/pdf/2506.23948", "abs": "https://arxiv.org/abs/2506.23948", "authors": ["Shiwei Sun", "Gen Nakamura", "Haibing Wang"], "title": "On the convergence of the no-response test for the heat equation", "categories": ["math.AP", "35R30, 31A10"], "comment": null, "summary": "Domain sampling methods called the range test (RT) and no-response test\n(NRT), and their duality are known for several inverse scattering problems and\nan inverse boundary value problem for the Laplace operator (see Section 1 for\nmore details). In our previous work [21], we established the duality between\nthe NRT and RT, and demonstrated the convergence of the RT for the heat\nequation. We also provided numerical studies for both methods. However, we did\nnot address the convergence for the NRT. As a continuation of this work, we\nprove the convergence of the NRT without using the duality. Specifically,\nassuming there exists a cavity $D$ inside a heat conductor $\\Omega$, we define\nan indicator function $I_{NRT}(G)$ for a prescribed test domain $G$, where\n$\\overline G\\subset\\Omega$ (i.e., $G\\Subset\\Omega$). By using the analytical\nextension property of solutions to the heat equation with respect to the\nspatial variables, we prove the convergence result given as $I_{NRT}(G)<\\infty$\nif and only if $\\overline{D}\\subset \\overline{G}$, provided that the solution\nto the heat equation cannot be analytically extended across the boundary of the\ncavity. Thus, we complete the theoretical study of both methods. Here the\nanalytic extension of solutions does not require the property that the\nsolutions are real analytic with respect to the space variables. However, for\nthe proof of the mentioned convergence result, we fully use this property.", "AI": {"tldr": "The paper proves the convergence of the No-Response Test (NRT) for the heat equation, independent of its duality with the Range Test (RT), completing the theoretical study of both methods.", "motivation": "Previous work established the duality between NRT and RT and proved RT's convergence but left NRT's convergence unaddressed. This paper fills that gap.", "method": "The authors define an indicator function for a test domain and use the analytical extension property of heat equation solutions to prove convergence.", "result": "The NRT converges if and only if the cavity is within the test domain, provided solutions cannot be analytically extended beyond the cavity's boundary.", "conclusion": "The study completes the theoretical foundation for both NRT and RT, emphasizing the role of analytical extension properties in proving convergence."}}
{"id": "2506.22851", "pdf": "https://arxiv.org/pdf/2506.22851", "abs": "https://arxiv.org/abs/2506.22851", "authors": ["Arnulf Jentzen", "Konrad Kleinberg", "Thomas Kruse"], "title": "Deep neural networks can provably solve Bellman equations for Markov decision processes without the curse of dimensionality", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "math.PR", "stat.ML", "90C40, 90C39, 60J05, 93E20, 65C05, 68T07"], "comment": null, "summary": "Discrete time stochastic optimal control problems and Markov decision\nprocesses (MDPs) are fundamental models for sequential decision-making under\nuncertainty and as such provide the mathematical framework underlying\nreinforcement learning theory. A central tool for solving MDPs is the Bellman\nequation and its solution, the so-called $Q$-function. In this article, we\nconstruct deep neural network (DNN) approximations for $Q$-functions associated\nto MDPs with infinite time horizon and finite control set $A$. More\nspecifically, we show that if the the payoff function and the random transition\ndynamics of the MDP can be suitably approximated by DNNs with leaky rectified\nlinear unit (ReLU) activation, then the solutions $Q_d\\colon \\mathbb R^d\\to\n\\mathbb R^{|A|}$, $d\\in \\mathbb{N}$, of the associated Bellman equations can\nalso be approximated in the $L^2$-sense by DNNs with leaky ReLU activation\nwhose numbers of parameters grow at most polynomially in both the dimension\n$d\\in \\mathbb{N}$ of the state space and the reciprocal $1/\\varepsilon$ of the\nprescribed error $\\varepsilon\\in (0,1)$. Our proof relies on the recently\nintroduced full-history recursive multilevel fixed-point (MLFP) approximation\nscheme.", "AI": {"tldr": "The paper constructs deep neural network (DNN) approximations for Q-functions in Markov decision processes (MDPs) with infinite time horizon and finite control sets, showing polynomial growth in parameters for state space dimension and error tolerance.", "motivation": "To address the challenge of approximating Q-functions in MDPs, which are central to reinforcement learning, using DNNs with leaky ReLU activation.", "method": "The authors use DNNs with leaky ReLU activation to approximate payoff functions and transition dynamics, leveraging the full-history recursive multilevel fixed-point (MLFP) scheme for proof.", "result": "The Q-functions can be approximated in the L\u00b2-sense by DNNs with polynomial parameter growth in state space dimension and error tolerance.", "conclusion": "DNNs with leaky ReLU activation are effective for approximating Q-functions in MDPs, with scalable parameter requirements."}}
{"id": "2506.23961", "pdf": "https://arxiv.org/pdf/2506.23961", "abs": "https://arxiv.org/abs/2506.23961", "authors": ["Fernando Ballesta-Yag\u00fce", "Mar\u00eda J. Carro"], "title": "Boundary Value Problems in graph Lipschitz domains in the plane with $A_{\\infty}$-measures on the boundary", "categories": ["math.AP", "math.CA", "Primary: 35J25, secondary: 35J05, 46E30, 42B37"], "comment": "31 pages, 2 figures", "summary": "We prove several results for the Dirichlet, Neumann and Regularity problems\nfor the Laplace equation in graph Lipschitz domains in the plane, considering\n$A_{\\infty}$-measures on the boundary. More specifically, we study the\n$L^{p,1}$-solvability for the Dirichlet problem, complementing results of Kenig\n(1980) and Carro and Ortiz-Caraballo (2018). Then, we study $L^p$-solvability\nof the Neumann problem, obtaining a range of solvability which is empty in some\ncases, a clear difference with the arc-length case. When it is not empty, it is\nan interval, and we consider solvability at its endpoints, establishing\nconditions for Lorentz space solvability when $p>1$ and atomic Hardy space\nsolvability when $p=1$. Solving the Lorentz endpoint leads us to a two-weight\nSawyer-type inequality, for which we give a sufficient condition. Finally, we\nshow how to adapt to the Regularity problem the results for the Neumann\nproblem.", "AI": {"tldr": "The paper analyzes solvability of Dirichlet, Neumann, and Regularity problems for the Laplace equation in graph Lipschitz domains, focusing on $A_{\\infty}$-measures and extending prior work.", "motivation": "To extend and complement existing results on solvability of boundary value problems for the Laplace equation in specific domains, addressing gaps in the literature.", "method": "Study $L^{p,1}$-solvability for Dirichlet, $L^p$-solvability for Neumann, and adapt results for Regularity problems, using $A_{\\infty}$-measures and exploring endpoint cases.", "result": "Established solvability ranges, conditions for Lorentz space and atomic Hardy space solvability, and a Sawyer-type inequality for the Neumann problem.", "conclusion": "The work generalizes and refines solvability conditions for boundary value problems, highlighting differences from the arc-length case and providing new insights."}}
{"id": "2506.22935", "pdf": "https://arxiv.org/pdf/2506.22935", "abs": "https://arxiv.org/abs/2506.22935", "authors": ["Marc Bara Iniesta"], "title": "Differentiable Radar Ambiguity Functions: Mathematical Formulation and Computational Implementation", "categories": ["eess.SP", "cs.LG", "cs.NA", "math.NA", "94A12, 65T50, 68T05", "F.2.1; I.2.6; G.1.0"], "comment": "16 pages, 4 figures, source code available at\n  https://github.com/marcbara/graf-psl-lpi (DOI: 10.5281/zenodo.15763301)", "summary": "The ambiguity function is fundamental to radar waveform design,\ncharacterizing range and Doppler resolution capabilities. However, its\ntraditional formulation involves non-differentiable operations, preventing\nintegration with gradient-based optimization methods and modern machine\nlearning frameworks. This paper presents the first complete mathematical\nframework and computational implementation for differentiable radar ambiguity\nfunctions. Our approach addresses the fundamental technical challenges that\nhave prevented the radar community from leveraging automatic differentiation:\nproper handling of complex-valued gradients using Wirtinger calculus, efficient\ncomputation through parallelized FFT operations, numerical stability throughout\ncascaded operations, and composability with arbitrary differentiable\noperations. We term this approach GRAF (Gradient-based Radar Ambiguity\nFunctions), which reformulates the ambiguity function computation to maintain\nmathematical equivalence while enabling gradient flow through the entire\npipeline. The resulting implementation provides a general-purpose\ndifferentiable ambiguity function compatible with modern automatic\ndifferentiation frameworks, enabling new research directions including neural\nnetwork-based waveform generation with ambiguity constraints, end-to-end\noptimization of radar systems, and integration of classical radar theory with\nmodern deep learning. We provide complete implementation details and\ndemonstrate computational efficiency suitable for practical applications. This\nwork establishes the mathematical and computational foundation for applying\nmodern machine learning techniques to radar waveform design, bridging classical\nradar signal processing with automatic differentiation frameworks.", "AI": {"tldr": "The paper introduces GRAF, a differentiable radar ambiguity function framework, enabling gradient-based optimization and integration with modern machine learning for radar waveform design.", "motivation": "Traditional radar ambiguity functions are non-differentiable, limiting their use with gradient-based methods and modern ML frameworks.", "method": "GRAF reformulates the ambiguity function using Wirtinger calculus, parallelized FFTs, and numerical stability measures to ensure differentiability.", "result": "GRAF enables gradient flow, compatibility with automatic differentiation, and supports applications like neural waveform generation and radar system optimization.", "conclusion": "GRAF bridges classical radar theory with modern ML, providing a foundation for advanced radar waveform design."}}
{"id": "2506.24049", "pdf": "https://arxiv.org/pdf/2506.24049", "abs": "https://arxiv.org/abs/2506.24049", "authors": ["K\u00e9vin Le Balc'h", "Jingrui Niu", "Chenmin Sun"], "title": "Geometric condition for the observability of electromagnetic Schr\u00f6dinger operators on $\\mathbb{T}^2$", "categories": ["math.AP"], "comment": "40 pages, 5 figures", "summary": "In this article we revisit the observability of the Schr\\\"odinger equation on\nthe two-dimensional torus. In contrast to the Schr\\\"odinger operator with a\npurely electric potential, for which any non-empty open set guarantees\nobservability, the presence of a magnetic potential introduces an additional\nobstruction. We establish a sufficient and almost necessary geometric condition\nfor the observability of electromagnetic Schr\\\"odinger operators. This\ncondition incorporates the magnetic potential, which can also be characterized\nby a geometric control condition for the corresponding magnetic field.", "AI": {"tldr": "The paper revisits the observability of the Schr\u00f6dinger equation on a 2D torus, highlighting the impact of a magnetic potential compared to purely electric potentials.", "motivation": "To understand how magnetic potentials introduce obstructions to observability, unlike purely electric potentials where any non-empty open set suffices.", "method": "Establishes a geometric condition incorporating the magnetic potential, linking it to a geometric control condition for the magnetic field.", "result": "A sufficient and almost necessary geometric condition for observability of electromagnetic Schr\u00f6dinger operators is derived.", "conclusion": "The presence of a magnetic potential requires additional geometric conditions for observability, unlike purely electric potentials."}}
{"id": "2506.23024", "pdf": "https://arxiv.org/pdf/2506.23024", "abs": "https://arxiv.org/abs/2506.23024", "authors": ["Jerry Liu", "Yasa Baig", "Denise Hui Jean Lee", "Rajat Vadiraj Dwaraknath", "Atri Rudra", "Chris R\u00e9"], "title": "BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": "Workshop for the Theory of AI for Scientific Computing @ COLT 2025\n  (Best Paper). 39 pages, 24 figures", "summary": "Physics-informed neural networks (PINNs) offer a flexible way to solve\npartial differential equations (PDEs) with machine learning, yet they still\nfall well short of the machine-precision accuracy many scientific tasks demand.\nIn this work, we investigate whether the precision ceiling comes from the\nill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP)\narchitecture. We introduce the Barycentric Weight Layer (BWLer), which models\nthe PDE solution through barycentric polynomial interpolation. A BWLer can be\nadded on top of an existing MLP (a BWLer-hat) or replace it completely\n(explicit BWLer), cleanly separating how we represent the solution from how we\ntake derivatives for the PDE loss. Using BWLer, we identify fundamental\nprecision limitations within the MLP: on a simple 1-D interpolation task, even\nMLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above\nfloat64 machine precision -- before any PDE terms are added. In PDE learning,\nadding a BWLer lifts this ceiling and exposes a tradeoff between achievable\naccuracy and the conditioning of the PDE loss. For linear PDEs we fully\ncharacterize this tradeoff with an explicit error decomposition and navigate it\nduring training with spectral derivatives and preconditioning. Across five\nbenchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for\nconvection, 10x for reaction, and 1800x for wave equations while remaining\ncompatible with first-order optimizers. Replacing the MLP entirely lets an\nexplicit BWLer reach near-machine-precision on convection, reaction, and wave\nproblems (up to 10 billion times better than prior results) and match the\nperformance of standard PINNs on stiff Burgers' and irregular-geometry Poisson\nproblems. Together, these findings point to a practical path for combining the\nflexibility of PINNs with the precision of classical spectral solvers.", "AI": {"tldr": "The paper investigates precision limitations in Physics-informed neural networks (PINNs) and introduces the Barycentric Weight Layer (BWLer) to address these issues, achieving significant accuracy improvements in solving PDEs.", "motivation": "PINNs struggle with machine-precision accuracy for PDEs, prompting an investigation into whether the issue stems from PDE ill-conditioning or MLP architecture limitations.", "method": "The BWLer, a barycentric polynomial interpolation layer, is introduced to either augment or replace MLPs, separating solution representation from PDE loss derivatives. Spectral derivatives and preconditioning are used to manage the tradeoff between accuracy and PDE loss conditioning.", "result": "BWLer improves RMSE by up to 30x for convection, 10x for reaction, and 1800x for wave equations. Explicit BWLer achieves near-machine-precision on some problems, outperforming standard PINNs.", "conclusion": "BWLer combines PINN flexibility with classical solver precision, offering a practical solution for high-accuracy PDE solving."}}
{"id": "2506.24058", "pdf": "https://arxiv.org/pdf/2506.24058", "abs": "https://arxiv.org/abs/2506.24058", "authors": ["Halit Sevki Aslan", "Michael Reissig"], "title": "Evolution models with time-dependent coefficients in friction and viscoelastic damping terms", "categories": ["math.AP", "35L05, 35L15, 35B40"], "comment": "110 pages, 4 figures", "summary": "We study the following Cauchy problem for the linear wave equation with both\ntime-dependent friction and time-dependent viscoelastic damping:\n\\begin{equation} \\label{EqAbstract}\\tag{$\\ast$} \\begin{cases} u_{tt}- \\Delta u\n+ b(t)u_t - g(t)\\Delta u_t=0, &(t,x) \\in (0,\\infty) \\times \\mathbb{R}^n, \\\\\nu(0,x)= u_0(x),\\quad u_t(0,x)= u_1(x), &x \\in \\mathbb{R}^n. \\end{cases}\n\\end{equation} Our goal is to derive decay estimates for higher order energy\nnorms of solutions to this problem. We focus on the interplay between the\ntime-dependent coefficients in both damping terms and their influence on the\nqualitative behavior of solutions. The analysis is based on a classification of\nthe damping mechanisms, frictional damping $b(t)u_t$ and viscoelastic damping\n$-g(t)\\Delta u_t$ as well, and employs the WKB-method in the extended phase\nspace.", "AI": {"tldr": "The paper analyzes decay estimates for solutions to a linear wave equation with time-dependent friction and viscoelastic damping, focusing on the interplay between damping terms.", "motivation": "To understand how time-dependent coefficients in damping terms influence the qualitative behavior of solutions.", "method": "Uses the WKB-method in extended phase space to classify damping mechanisms (frictional and viscoelastic).", "result": "Derives decay estimates for higher order energy norms of solutions.", "conclusion": "The interplay between damping terms significantly affects solution behavior, with decay estimates providing insights into their qualitative impact."}}
{"id": "2506.23062", "pdf": "https://arxiv.org/pdf/2506.23062", "abs": "https://arxiv.org/abs/2506.23062", "authors": ["Jason M. Altschuler", "Sinho Chewi", "Matthew S. Zhang"], "title": "Shifted Composition IV: Underdamped Langevin and Numerical Discretizations with Partial Acceleration", "categories": ["math.PR", "cs.DS", "cs.NA", "math.AP", "math.NA", "math.ST", "stat.TH"], "comment": null, "summary": "Quantifying the convergence rate of the underdamped Langevin dynamics (ULD)\nis a classical topic, in large part due to the possibility for\ndiffusive-to-ballistic speedups -- as was recently established for the\ncontinuous-time dynamics via space-time Poincare inequalities. A central\nchallenge for analyzing ULD is that its degeneracy necessitates the development\nof new analysis approaches, e.g., the theory of hypocoercivity. In this paper,\nwe give a new coupling-based framework for analyzing ULD and its numerical\ndiscretizations. First, in the continuous-time setting, we use this framework\nto establish new parabolic Harnack inequalities for ULD. These are the first\nHarnack inequalities that decay to zero in contractive settings, thereby\nreflecting the convergence properties of ULD in addition to just its regularity\nproperties.\n  Second, we build upon these Harnack inequalities to develop a local error\nframework for analyzing discretizations of ULD in KL divergence. This extends\nour framework in part III from uniformly elliptic diffusions to degenerate\ndiffusions, and shares its virtues: the framework is user-friendly, applies to\nsophisticated discretization schemes, and does not require contractivity.\nApplying this framework to the randomized midpoint discretization of ULD\nestablishes (i) the first ballistic acceleration result for log-concave\nsampling (i.e., sublinear dependence on the condition number), and (ii) the\nfirst $d^{1/3}$ iteration complexity guarantee for sampling to constant total\nvariation error in dimension $d$.", "AI": {"tldr": "The paper introduces a coupling-based framework for analyzing underdamped Langevin dynamics (ULD) and its discretizations, establishing new Harnack inequalities and a local error framework for KL divergence analysis.", "motivation": "The degeneracy of ULD requires new analysis approaches, and the paper aims to provide a user-friendly framework for analyzing ULD and its numerical discretizations.", "method": "A coupling-based framework is developed to analyze ULD, including parabolic Harnack inequalities and a local error framework for KL divergence analysis.", "result": "The framework enables ballistic acceleration for log-concave sampling and a $d^{1/3}$ iteration complexity guarantee for sampling in dimension $d$.", "conclusion": "The new framework advances the analysis of ULD and its discretizations, offering practical tools for degenerate diffusions."}}
{"id": "2506.24067", "pdf": "https://arxiv.org/pdf/2506.24067", "abs": "https://arxiv.org/abs/2506.24067", "authors": ["Hiroyuki Chihara", "Shubham R. Jathar", "Jesse Railo"], "title": "The matrix weighted real-analytic double fibration transforms", "categories": ["math.AP", "math.DG", "Primary 44A12, Secondary 53C65, 58J40, 45Q05"], "comment": "22 pages; comments and suggestions are welcome", "summary": "We show that the real-analytic matrix-weighted double fibration transform\ndetermines the analytic wavefront set of a vector-valued function. We apply\nthis result to show that the matrix weighted ray transform is injective on a\ntwo-dimensional, non-trapping, real-analytic Riemannian manifold with strictly\nconvex boundary. Additionally, we show that a real-analytic Higgs field can be\nuniquely determined from the nonabelian ray transform on real-analytic\nRiemannian manifolds of any dimension with a strictly convex boundary point.", "AI": {"tldr": "The paper demonstrates that the real-analytic matrix-weighted double fibration transform identifies the analytic wavefront set of vector-valued functions. It also proves injectivity of the matrix-weighted ray transform on 2D non-trapping real-analytic Riemannian manifolds with strictly convex boundaries and uniquely determines real-analytic Higgs fields from nonabelian ray transforms.", "motivation": "The study aims to extend understanding of transforms and their injectivity properties in real-analytic settings, particularly for vector-valued functions and Higgs fields on Riemannian manifolds.", "method": "The authors use the real-analytic matrix-weighted double fibration transform and apply it to analyze the analytic wavefront set. They then apply this to prove injectivity results for the matrix-weighted ray transform and nonabelian ray transform.", "result": "Key results include the injectivity of the matrix-weighted ray transform on 2D non-trapping real-analytic Riemannian manifolds and the unique determination of real-analytic Higgs fields from nonabelian ray transforms.", "conclusion": "The findings advance the theoretical framework for transforms in real-analytic contexts, with implications for geometric analysis and inverse problems."}}
{"id": "2506.23550", "pdf": "https://arxiv.org/pdf/2506.23550", "abs": "https://arxiv.org/abs/2506.23550", "authors": ["Ryui Kaneko", "Shimpei Goto"], "title": "Seeding neural network quantum states with tensor network states", "categories": ["cond-mat.str-el", "cs.LG", "cs.NA", "math.NA", "quant-ph"], "comment": "13 pages, 13 figures", "summary": "We find an efficient approach to approximately convert matrix product states\n(MPSs) into restricted Boltzmann machine wave functions consisting of a\nmultinomial hidden unit through a canonical polyadic (CP) decomposition of the\nMPSs. This method allows us to generate well-behaved initial neural network\nquantum states for quantum many-body ground-state calculations in polynomial\ntime of the number of variational parameters and systematically shorten the\ndistance between the initial states and the ground states with increasing the\nrank of the CP decomposition. We demonstrate the efficiency of our method by\ntaking the transverse-field Ising model as an example and discuss possible\napplications of our method to more general quantum many-body systems in which\nthe ground-state wave functions possess complex nodal structures.", "AI": {"tldr": "Efficient conversion of MPSs to restricted Boltzmann machine wave functions via CP decomposition, enabling polynomial-time ground-state calculations.", "motivation": "To simplify and accelerate quantum many-body ground-state calculations by bridging MPSs and neural network quantum states.", "method": "Uses CP decomposition of MPSs to generate initial neural network quantum states, tested on the transverse-field Ising model.", "result": "Demonstrates efficient ground-state approximation with systematic improvement via higher CP decomposition ranks.", "conclusion": "The method is effective for systems with complex nodal structures and offers scalable initial states for quantum calculations."}}
{"id": "2506.22887", "pdf": "https://arxiv.org/pdf/2506.22887", "abs": "https://arxiv.org/abs/2506.22887", "authors": ["George J. Bautista", "Roberto de A. Capistrano-Filho", "Juan L\u00edmaco"], "title": "On the controllability of laminated beams with Venttsel-type boundary conditions", "categories": ["math.OC", "math.AP"], "comment": "19 pp. Comments are welcome", "summary": "This paper examines the boundary controllability of a Timoshenko laminated\nbeam system subject to Venttsel-type boundary conditions. The study focuses on\na novel configuration in which three controls are applied solely at the\nboundary of the beam. Controllability is established by deriving an appropriate\nobservability inequality for the corresponding adjoint system, which is then\nemployed within the framework of the duality method in the setup of the\nclassical Hilbert uniqueness method (HUM) to achieve the control problem. The\nmain contribution lies in the analysis of a system comprising three beams\ngoverned by dynamic Venttsel-type boundary conditions, as introduced by\nVenttsel in [Theory Probab. Appl., 4 (1959)].", "AI": {"tldr": "The paper analyzes boundary controllability of a Timoshenko laminated beam with Venttsel-type boundary conditions using three boundary controls.", "motivation": "To study controllability in a novel beam configuration with dynamic Venttsel-type boundary conditions.", "method": "Derives an observability inequality for the adjoint system and uses the duality method (HUM) to solve the control problem.", "result": "Controllability is established for the system with three boundary controls.", "conclusion": "The work contributes to understanding controllability in systems with Venttsel-type boundary conditions."}}
{"id": "2506.24042", "pdf": "https://arxiv.org/pdf/2506.24042", "abs": "https://arxiv.org/abs/2506.24042", "authors": ["Gen Li", "Yuchen Zhou", "Yuting Wei", "Yuxin Chen"], "title": "Faster Diffusion Models via Higher-Order Approximation", "categories": ["cs.LG", "cs.NA", "math.NA", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "In this paper, we explore provable acceleration of diffusion models without\nany additional retraining. Focusing on the task of approximating a target data\ndistribution in $\\mathbb{R}^d$ to within $\\varepsilon$ total-variation\ndistance, we propose a principled, training-free sampling algorithm that\nrequires only the order of\n  $$ d^{1+2/K} \\varepsilon^{-1/K} $$\n  score function evaluations (up to log factor) in the presence of accurate\nscores, where $K$ is an arbitrarily large fixed integer. This result applies to\na broad class of target data distributions, without the need for assumptions\nsuch as smoothness or log-concavity. Our theory is robust vis-a-vis inexact\nscore estimation, degrading gracefully as the score estimation error increases\n-- without demanding higher-order smoothness on the score estimates as assumed\nin previous work. The proposed algorithm draws insight from high-order ODE\nsolvers, leveraging high-order Lagrange interpolation and successive refinement\nto approximate the integral derived from the probability flow ODE.", "AI": {"tldr": "A training-free sampling algorithm for diffusion models achieves provable acceleration without retraining, requiring fewer score function evaluations for accurate distribution approximation.", "motivation": "To improve the efficiency of diffusion models by reducing the computational cost of sampling without additional training or restrictive assumptions on data distributions.", "method": "Proposes a principled, training-free algorithm inspired by high-order ODE solvers, using high-order Lagrange interpolation and successive refinement to approximate the probability flow ODE integral.", "result": "The algorithm requires only O(d^{1+2/K} \u03b5^{-1/K}) score function evaluations (up to log factor) for accurate approximation, robust to inexact score estimation.", "conclusion": "The method provides a scalable and efficient solution for diffusion models, applicable to a broad class of distributions without smoothness or log-concavity assumptions."}}
{"id": "2506.23177", "pdf": "https://arxiv.org/pdf/2506.23177", "abs": "https://arxiv.org/abs/2506.23177", "authors": ["Mao Fabrice Djete"], "title": "A notion of BSDE on the Wasserstein space and its applications to control problems and PDEs", "categories": ["math.PR", "math.AP", "math.OC"], "comment": null, "summary": "We introduce a class of backward stochastic differential equations (BSDEs) on\nthe Wasserstein space of probability measures. This formulation extends the\nclassical correspondence between BSDEs, stochastic control, and partial\ndifferential equations (PDEs) to the mean--field (McKean--Vlasov) setting,\nwhere the dynamics depend on the law of the state process. The standard BSDE\nframework becomes inadequate in this context, motivating a new definition in\nterms of measure--dependent solutions.\n  Under suitable assumptions, we demonstrate that this formulation is in\ncorrespondence with both mean--field control problems and partial differential\nequations defined on the Wasserstein space. A comparison principle is\nestablished to ensure uniqueness, and existence results are obtained for\ngenerators that are linear or quadratic in the $z$--variable. This framework\nprovides a probabilistic approach to control and analysis on the space of\nprobability measures.", "AI": {"tldr": "The paper introduces a new class of BSDEs on the Wasserstein space, extending classical BSDEs to the mean-field setting, linking them to control problems and PDEs on probability measures.", "motivation": "Classical BSDEs are inadequate for mean-field settings, motivating a new measure-dependent framework.", "method": "Defines BSDEs on Wasserstein space, establishes correspondence with mean-field control and PDEs, and proves uniqueness via a comparison principle.", "result": "Existence shown for linear/quadratic generators; uniqueness ensured.", "conclusion": "Provides a probabilistic approach for control and analysis on probability measure spaces."}}
{"id": "2506.23206", "pdf": "https://arxiv.org/pdf/2506.23206", "abs": "https://arxiv.org/abs/2506.23206", "authors": ["Riju Basak", "You-Wei Benson Chen", "Prasun Roychowdhury"], "title": "Uncentered Fractional Maximal functions and mean oscillation spaces associated with dyadic Hausdorff content", "categories": ["math.FA", "math.AP", "math.CA", "46E35, 42B35, 42B37, 32A37, 42B25"], "comment": "32 pages", "summary": "We study the action of uncentered fractional maximal functions on mean\noscillation spaces associated with the dyadic Hausdorff content\n$\\mathcal{H}_{\\infty}^{\\beta}$ with $0<\\beta\\leq n$. For $0 < \\alpha < n$, we\nrefine existing results concerning the action of the Euclidean uncentered\nfractional maximal function $\\mathcal{M}_{\\alpha}$ on the functions of bounded\nmean oscillations (BMO) and vanishing mean oscillations (VMO). In addition, for\n$0 < \\beta_1 \\leq \\beta_2 \\leq n$, we establish the boundedness of the\n$\\beta_2$-dimensional uncentered maximal function $\\mathcal{M}^{\\beta_2}$ on\nthe space $\\text{BMO}^{\\beta_1}(\\mathbb{R}^n)$, where\n$\\text{BMO}^{\\beta_1}(\\mathbb{R}^n)$ denotes the mean oscillation space adapted\nto the dyadic Hausdorff content $\\mathcal{H}_{\\infty}^{\\beta_1}$ on\n$\\mathbb{R}^n$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.23245", "pdf": "https://arxiv.org/pdf/2506.23245", "abs": "https://arxiv.org/abs/2506.23245", "authors": ["Caiyan Li", "Hengyu Zhou"], "title": "The Dirichlet problem for the minimal surface system on smooth domains", "categories": ["math.DG", "math.AP"], "comment": "27 pages, Comments are welcome", "summary": "In this paper, we propose a new assumption (1.2) that involves a small\noscillation and $C^2$ norms for maps from smooth bounded domains into Euclidean\nspaces. Furthermore, by assuming that the domain has non-negative Ricci\ncurvature, we establish the Dirichlet problem for the minimal surface system\nvia the mean curvature flow (MCF) with boundary. The long-time existence of\nsuch flow is derived using Bernstein-type theorems of higher codimensional\nself-shrinkers in the whole space and the half-space. Another novel aspect is\nthat our hypothesis imposes no restriction on the diameter of the domains,\nwhich implies an existence result for an exterior Dirichlet problem of the\nminimal surface system.", "AI": {"tldr": "Proposes a new assumption for maps involving small oscillation and $C^2$ norms, solves the Dirichlet problem for minimal surfaces via mean curvature flow under non-negative Ricci curvature, and extends results to exterior problems.", "motivation": "To address the Dirichlet problem for minimal surfaces in domains with non-negative Ricci curvature, removing diameter restrictions.", "method": "Uses mean curvature flow (MCF) with boundary, leveraging Bernstein-type theorems for self-shrinkers in full and half-spaces.", "result": "Establishes long-time existence of MCF and solves the Dirichlet problem, including exterior cases.", "conclusion": "The approach successfully extends minimal surface theory to broader geometric settings without diameter constraints."}}
{"id": "2506.23324", "pdf": "https://arxiv.org/pdf/2506.23324", "abs": "https://arxiv.org/abs/2506.23324", "authors": ["Amiran Gogatishvili", "Tugce \u00dcnver"], "title": "Weighted inequalities involving two Hardy operators", "categories": ["math.FA", "math.AP", "math.CA", "26D10 (Primary), 46E20 (Secondary)"], "comment": null, "summary": "We find necessary and sufficient conditions on weights $u_1, u_2, v_1, v_2$,\ni.e. measurable, positive, and finite, a.e. on $(a,b)$, for which there exists\na positive constant $C$ such that for given $0 < p_1,q_1,p_2,q_2 <\\infty$ the\ninequality \\begin{equation*} \\begin{split} \\bigg(\\int_a^b \\bigg(\\int_a^t\nf(s)^{p_2} v_2(s)^{p_2} ds\\bigg)^{\\frac{q_2}{p_2}} u_2(t)^{q_2} dt\n\\bigg)^{\\frac{1}{q_2}}& \\\\ & \\hspace{-3cm}\\le C \\bigg(\\int_a^b \\bigg(\\int_a^t\nf(s)^{p_1} v_1(s)^{p_1} ds\\bigg)^{\\frac{q_1}{p_1}} u_1(t)^{q_1} dt\n\\bigg)^{\\frac{1}{q_1}} \\end{split} \\end{equation*} holds for every\nnon-negative, measurable function $f$ on $(a,b)$, where $0 \\le a <b \\le\n\\infty$. The proof is based on a recently developed discretization method that\nenables us to overcome the restrictions of the earlier results.", "AI": {"tldr": "The paper establishes necessary and sufficient conditions on weights for a weighted integral inequality to hold, using a discretization method.", "motivation": "To generalize and improve earlier results on weighted integral inequalities by removing restrictions and providing precise conditions.", "method": "A recently developed discretization method is applied to analyze the inequality.", "result": "Necessary and sufficient conditions on the weights are derived for the inequality to hold.", "conclusion": "The method successfully overcomes limitations of previous approaches, providing a complete solution for the given inequality."}}
{"id": "2506.24116", "pdf": "https://arxiv.org/pdf/2506.24116", "abs": "https://arxiv.org/abs/2506.24116", "authors": ["Ioann Vasilyev"], "title": "On the zero sets of harmonic polynomials", "categories": ["math.CV", "math.AP", "math.CA"], "comment": "9 pages, 2 figures. Comments are welcome !", "summary": "In this paper we consider nonzero harmonic functions vanishing on certain\nsubvarieties. Among other things, we give a positive solution to the Problem\n151 from the Scottish Book posed by R. Wavre in 1936. In more detail, we\nconstruct a nonzero harmonic function in the whole space that vanishes on the\nedges of the unit cube. Moreover, using harmonic morphisms we construct certain\nnew nontrivial families of harmonic polynomials that vanish at the same set in\nthe unit ball in n-dimensional space for all n greater than or equal to 4. This\nextends results of Logunov and Malinnikova. We also present some (presumably)\nnew results on harmonic functions in the space whose nodal sets are unions of\n(affine) subspaces.", "AI": {"tldr": "The paper solves Problem 151 from the Scottish Book, constructs a nonzero harmonic function vanishing on cube edges, and extends prior results on harmonic polynomials.", "motivation": "To address longstanding problems in harmonic analysis, particularly R. Wavre's 1936 problem, and explore harmonic functions with specific vanishing properties.", "method": "Constructs harmonic functions and polynomials, using harmonic morphisms, to vanish on specific subvarieties like cube edges and subspaces.", "result": "A nonzero harmonic function vanishing on cube edges is constructed, and new families of harmonic polynomials are developed, extending previous work.", "conclusion": "The paper advances understanding of harmonic functions with prescribed vanishing sets, solving a classic problem and introducing new constructions."}}
