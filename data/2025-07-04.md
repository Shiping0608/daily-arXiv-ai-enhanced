<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 13]
- [math.AP](#math.AP) [Total: 19]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [astro-ph.CO](#astro-ph.CO) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cs.AI](#cs.AI) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [math-ph](#math-ph) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [cs.CE](#cs.CE) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [physics.space-ph](#physics.space-ph) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A Hybrid DEC-SIE Framework for Potential-Based Electromagnetic Analysis of Heterogeneous Media](https://arxiv.org/abs/2507.02099)
*Amgad Abdrabou,Luis J. Gomez,Weng Cho Chew*

Main category: math.NA

TL;DR: A hybrid method combining discrete exterior calculus (DEC) and surface integral equations (SIE) is proposed to efficiently solve electromagnetic field problems in complex multi-material environments.


<details>
  <summary>Details</summary>
Motivation: Addressing computational challenges in analyzing electromagnetic fields in complex, multi-material environments.

Method: Couples DEC with SIE using magnetic vector and electric scalar potentials under the Lorenz gauge, dividing the domain into inhomogeneous (DEC) and homogeneous (SIE) regions.

Result: A scalar reformulation of SIEs reduces operators from fourteen to two, improving compatibility and numerical performance.

Conclusion: The hybrid method provides a unified, efficient, and physically consistent framework for electromagnetic scattering and radiation problems.

Abstract: Analyzing electromagnetic fields in complex, multi-material environments
presents substantial computational challenges. To address these, we propose a
hybrid numerical method that couples discrete exterior calculus (DEC) with
surface integral equations (SIE) in the potential-based formulation of
Maxwell's equations. The method employs the magnetic vector and electric scalar
potentials ($\mathbf{A}$-$\Phi$) under the Lorenz gauge, offering natural
compatibility with multi-physics couplings and inherent immunity to
low-frequency breakdown. To effectively handle both bounded and unbounded
regions, we divide the computational domain: the inhomogeneous interior is
discretized using DEC, a coordinate-free framework that preserves topological
invariants and enables structure-preserving discretization on unstructured
meshes, while the homogeneous exterior is treated using SIEs, which inherently
satisfy the radiation condition and eliminate the need for artificial domain
truncation. A key contribution of this work is a scalar reformulation of the
SIEs, which reduces the number of surface integral operators from fourteen to
two by expressing the problem in terms of the Cartesian components of the
vector potential and their normal derivatives. This simplification motivates a
corresponding adaptation in the DEC domain: each vector potential component is
represented as a discrete 0-form, in contrast to the conventional 1-form
representation. This novel treatment improves compatibility at the interface
and significantly enhances numerical performance. The proposed hybrid method
thus offers a unified, efficient, and physically consistent framework for
solving electromagnetic scattering and radiation problems in complex geometries
and heterogeneous materials

</details>


### [2] [Symplectic Hamiltonian Hybridizable Discontinuous Galerkin Methods for Linearized Shallow Water Equations](https://arxiv.org/abs/2507.02340)
*C. Núñez,M. A. Sánchez*

Main category: math.NA

TL;DR: The paper presents a numerical method for approximating the linearized shallow water equations using HDG methods, preserving Hamiltonian structure and energy conservation.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical scheme that maintains the Hamiltonian structure of the shallow water equations, ensuring accurate and stable simulations.

Method: Proposes an auxiliary variable formulation, discretizes space with HDG methods, and uses symplectic integrators for time discretization.

Result: Achieves optimal convergence rates and conserves total energy in numerical experiments.

Conclusion: The HDG method with symplectic time integration effectively preserves the Hamiltonian structure and energy conservation in the shallow water equations.

Abstract: This paper focuses on the numerical approximation of the linearized shallow
water equations using hybridizable discontinuous Galerkin (HDG) methods,
leveraging the Hamiltonian structure of the evolution system. First, we propose
an equivalent formulation of the equations by introducing an auxiliary
variable. Then, we discretize the space variables using HDG methods, resulting
in a semi-discrete scheme that preserves a discrete version of the Hamiltonian
structure. The use of an alternative formulation with the auxiliary variable is
crucial for developing the HDG scheme that preserves this Hamiltonian
structure. The resulting system is subsequently discretized in time using
symplectic integrators, ensuring the energy conservation of the fully discrete
scheme. We present numerical experiments that demonstrate optimal convergence
rates for all variables and showcase the conservation of total energy, as well
as the evolution of other physical quantities.

</details>


### [3] [An efficient asymptotic preserving Monte Carlo method for frequency-dependent radiative transfer equations](https://arxiv.org/abs/2507.02392)
*Yiyang Hong,Yi Shi,Yi Cai,Tao Xiong*

Main category: math.NA

TL;DR: An efficient asymptotic-preserving Monte Carlo method for frequency-dependent radiative transfer equations is developed, combining particle-based and implicit methods for improved computational efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of frequency-dependent radiative transfer equations, particularly in achieving correct free streaming limits and handling nonlinear coupling across frequency groups.

Method: A hybrid approach using Monte Carlo for convective fluxes and implicit central difference for diffusive fluxes, with a Picard iteration for nonlinear coupling.

Result: The method achieves larger time steps independent of light speed and frequency, enhancing efficiency while preserving asymptotic properties.

Conclusion: The proposed method is efficient and asymptotic-preserving, validated by numerical experiments.

Abstract: In this paper, we develop an efficient asymptotic-preserving (AP) Monte Carlo
(MC) method for frequency-dependent radiative transfer equations (RTEs), which
is based on the AP-MC method proposed for the gray RTEs in
\cite{shi2023efficient}. We follow the characteristics-based approach by Zhang
et al. \cite{zhang2023asymptotic} to get a reformulated model, which couples a
low dimension convection-diffusion-type equation for macroscopic quantities
with a high dimension transport equation for the radiative intensity.
  To recover the correct free streaming limit due to frequency-dependency, we
propose a correction to the reformulated macroscopic equation.
  The macroscopic system is solved using a hybrid method:
  convective fluxes are handled by a particle-based MC method, while diffusive
fluxes are treated implicitly with central difference.
  To address the nonlinear coupling between radiative intensity and the Planck
function across multiple frequency groups, we adopt a Picard iteration with a
predictor-corrector procedure, which decouples a global nonlinear system into a
linear system restricted to spatial dimension (independent of frequency) with
scalar algebraic nonlinear equations.
  Once the macroscopic update is done, the transport equation, with a known
emission source provided by the macroscopic variables, is efficiently solved
using an implicit MC method. This approach enables larger time steps
independent of the speed of light and also the frequency across a wide range,
significantly enhancing computational efficiency, especially for
frequency-dependent RTEs.
  Formal AP analysis in the diffusive scaling is established. Numerical
experiments are performed to demonstrate the high efficiency and AP property of
the proposed method.

</details>


### [4] [Fast reconstruction approaches for photoacoustic tomography with smoothing Sobolev/Matérn priors](https://arxiv.org/abs/2507.02401)
*Jaakko Kultima,Ronny Ramlau,Teemu Sahlström,Tanja Tarvainen*

Main category: math.NA

TL;DR: The paper explores the connection between deterministic and stochastic approaches in photoacoustic tomography (PAT), linking Matérn covariance operators to Sobolev embeddings and proposing efficient wavelet-based implementations.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between deterministic (regularization) and stochastic (Bayesian) methods in PAT, and to improve computational efficiency.

Method: Establishes equivalence between Matérn covariance operators and Sobolev embeddings, and introduces a wavelet-based adjoint operator for efficient implementation.

Result: Efficient computational methods are validated with successful reconstructions in PAT.

Conclusion: The study provides a unified framework for deterministic and stochastic approaches in PAT, enhancing computational efficiency.

Abstract: In photoacoustic tomography (PAT), the computation of the initial pressure
distribution within an object from its time-dependent boundary measurements
over time is considered. This problem can be approached from two
well-established points of view: deterministically using regularisation
methods, or stochastically using the Bayesian framework. Both approaches
frequently require the solution of a variational problem. In the paper we
elaborate the connection between these approaches by establishing the
equivalence between a smoothing Mat{\'e}rn class of covariance operators and
Sobolev embedding operator $E_s: H^s \hookrightarrow L^2$. We further discuss
the use of a Wavelet-based implementation of the adjoint operator $E_s^*$ which
also allows for efficient evaluations for certain Mat{\'e}rn covariance
operators, leading to efficient implementations both in terms of computational
effort as well as memory requirements. The proposed methods are validated with
reconstructions for the photoacoustic problem.

</details>


### [5] [A second-order and unconditionally stable time filtered scheme for the Cahn-Hilliard-Navier-Stokes system](https://arxiv.org/abs/2507.02402)
*Xi Li,Haijun Gao,Chunmei Xie,Minfu Feng*

Main category: math.NA

TL;DR: A novel low-complexity, linear, second-order, and energy-stable time-stepping scheme for the CHNS system is proposed using a time filter technique.


<details>
  <summary>Details</summary>
Motivation: To improve the temporal accuracy of the CHNS model discretization while maintaining energy stability.

Method: Uses a first-order backward Euler method combined with a time filter to achieve second-order accuracy with minimal modifications.

Result: Unconditional energy stability and second-order temporal error estimations are proven, supported by numerical experiments.

Conclusion: The proposed scheme effectively enhances accuracy and stability for the CHNS system.

Abstract: In this work, we propose, analyze, and test a novel computational
low-complexity, linear, second-order, and unconditional energy-stable
semi-discrete time-stepping scheme for the Cahn-Hilliard-Navier-Stokes (CHNS)
system by employing the time filter technique. Firstly, the first-order
semi-implicit backward Euler (BE) method is utilized to discretize the CHNS
model; Secondly, the time filter, as a post-processing strategy, is
incorporated into the BE scheme, requiring only minimal modifications to the
existing BE framework to improve its temporal accuracy from first- to
second-order. The unconditional energy stability and second-order temporal
error estimations are obtained, and several numerical experiments are conducted
to verify the theoretical results.

</details>


### [6] [A modified Crank-Nicolson scheme for the Vlasov-Poisson system with a strong external magnetic field](https://arxiv.org/abs/2507.02459)
*Francis Filbet,L Miguel Rodrigues,Kim Han Trinh*

Main category: math.NA

TL;DR: A PIC method using Crank-Nicolson time discretization for the Vlasov-Poisson system with strong magnetic fields, focusing on poloidal particle motion, avoids stability constraints via guiding-center discretization.


<details>
  <summary>Details</summary>
Motivation: To address stability constraints from small Larmor radius and plasma frequency in PIC methods for strong magnetic fields.

Method: Uses Crank-Nicolson time discretization and guiding-center PIC schemes to handle magnetic field variations.

Result: Theoretical proofs and numerical experiments validate the method's consistency and effectiveness.

Conclusion: The proposed method successfully avoids stability constraints and accurately models particle motion in strong magnetic fields.

Abstract: We propose and study a Particle-In-Cell (PIC) method based on the
Crank-Nicolson time discretization for the Vlasov-Poisson system with a strong
and inhomogeneous external magnetic field with fixed direction, where we focus
on the motion of particles in the plane orthogonal to the magnetic field
(so-called poloidal directions). In this regime, the time step can be subject
to stability constraints related to the smallness of Larmor radius and plasma
frequency [21]. To avoid this limitation, our approach is based on numerical
schemes [9, 10, 12], providing a consistent PIC discretization of the
guiding-center system taking into account variations of the magnetic field. We
carry out some theoretical proofs and perform several numerical experiments to
validate the method and its underlying concepts.

</details>


### [7] [Goal-oriented optimal sensor placement for PDE-constrained inverse problems in crisis management](https://arxiv.org/abs/2507.02500)
*Marco Mattuschka,Noah An der Lan,Max von Danwitz,Daniel Wolff,Alexander Popp*

Main category: math.NA

TL;DR: A Bayesian framework for optimal sensor placement and steering in PDE-constrained inverse problems, applied to airborne contaminant tracking for real-time crisis management.


<details>
  <summary>Details</summary>
Motivation: To enhance computational efficiency and accuracy in sensor placement and steering for complex geometries in PDE-constrained inverse problems, particularly for airborne contaminant tracking.

Method: Utilizes a Bayesian approach with low-rank approximations and a C-optimal design criterion for strategic sensor placement and dynamic steering.

Result: Numerical experiments confirm the framework's effectiveness in source identification and monitoring, enabling real-time decision-making.

Conclusion: The framework shows promise for efficient, real-time crisis management by minimizing prediction uncertainty in complex scenarios.

Abstract: This paper presents a novel framework for goal-oriented optimal static sensor
placement and dynamic sensor steering in PDE-constrained inverse problems,
utilizing a Bayesian approach accelerated by low-rank approximations. The
framework is applied to airborne contaminant tracking, extending recent dynamic
sensor steering methods to complex geometries for computational efficiency. A
C-optimal design criterion is employed to strategically place sensors,
minimizing uncertainty in predictions. Numerical experiments validate the
approach's effectiveness for source identification and monitoring, highlighting
its potential for real-time decision-making in crisis management scenarios.

</details>


### [8] [On low-dimensional approximation of function spaces of interior regularity](https://arxiv.org/abs/2507.02655)
*S. Aziz,M. Bauer,M. Bebendorf,T. Rau*

Main category: math.NA

TL;DR: A new technique for constructing local approximation spaces for Lipschitz domains improves exponential convergence by leveraging boundary approximations instead of eigenvalue problems.


<details>
  <summary>Details</summary>
Motivation: To enhance the relationship between dimensionality and convergence order in elliptic boundary value problems by exploiting interior regularity properties.

Method: The technique constructs local ansatz spaces by extending approximations from the boundary, avoiding eigenvalue problems and simplifying variational problem-solving on structured domains.

Result: Improved exponential convergence influenced by spatial dimension and easier construction of local spaces.

Conclusion: The proposed method offers a more efficient approach for constructing local approximation spaces in generalized finite element methods.

Abstract: Many elliptic boundary value problems exhibit an interior regularity
property, which can be exploited to construct local approximation spaces that
converge exponentially within function spaces satisfying this property. These
spaces can be used to define local ansatz spaces within the framework of
generalised finite element methods, leading to a better relation between
dimensionality and convergence order. In this paper, we present a new technique
for the construction of such spaces for Lipschitz domains. Instead of the
commonly used approach based on eigenvalue problems it relies on extensions of
approximations performed on the boundary. Hence, it improves the influence of
the spatial dimension on the exponential convergence and allows to construct
the local spaces by solving the original kind of variational problems on easily
structured domains.

</details>


### [9] [High order uniform in time schemes for weakly nonlinear Schrödinger equation and wave turbulence](https://arxiv.org/abs/2507.02662)
*Quentin Chauleur,Antoine Mouzard*

Main category: math.NA

TL;DR: Two high-order multiscale schemes for weakly nonlinear Schrödinger equations are introduced, achieving precision under CFL conditions and uniform accuracy over long times.


<details>
  <summary>Details</summary>
Motivation: To develop efficient numerical schemes for weakly nonlinear Schrödinger equations with high precision and long-term accuracy.

Method: Discretization of Picard iterates, exploiting scattering properties with low-frequency projected linear flow.

Result: High precision under CFL conditions and uniform accuracy over long times, validated by numerical simulations.

Conclusion: The schemes are effective for weakly nonlinear Schrödinger equations and applicable to wave turbulence dynamics.

Abstract: We introduce two multiscale numerical schemes for the time integration of
weakly nonlinear Schr\"odinger equations, built upon the discretization of
Picard iterates of the solution. These high-order schemes are designed to
achieve high precision with respect to the small nonlinearity parameter under
particular CFL condition. By exploiting the scattering properties of these
schemes thanks to a low-frequency projected linear flow, we also establish its
uniform accuracy over long time horizons. Numerical simulations are provided to
illustrate the theoretical results, and these schemes are further applied to
investigate dynamics in the framework of wave turbulence.

</details>


### [10] [Moments, Time-Inversion and Source Identification for the Heat Equation](https://arxiv.org/abs/2507.02677)
*Kang Liu,Enrique Zuazua*

Main category: math.NA

TL;DR: A novel moment-based approach is proposed for the ill-posed inverse problem of initial source identification in the heat equation, reducing exponential error growth to polynomial growth and promoting sparsity.


<details>
  <summary>Details</summary>
Motivation: The heat equation's initial source identification is highly unstable, and classical Tikhonov regularization is insufficient. A more stable and accurate method is needed.

Method: Transform the problem into an inverse moment formulation, evolve terminal time moments backward via ODEs, and solve a convex optimization problem to reconstruct the source with sparsity-promoting total variation minimization.

Result: The method reduces error growth from exponential to polynomial, provides explicit error estimates, and demonstrates improved stability in numerical experiments.

Conclusion: The moment-based approach offers a stable and efficient solution for the heat equation's inverse problem, with significant improvements over existing methods.

Abstract: We address the initial source identification problem for the heat equation, a
notably ill-posed inverse problem characterized by exponential instability.
Departing from classical Tikhonov regularization, we propose a novel approach
based on moment analysis of the heat flow, transforming the problem into a more
stable inverse moment formulation. By evolving the measured terminal time
moments backward through their governing ODE system, we recover the moments of
the initial distribution. We then reconstruct the source by solving a convex
optimization problem that minimizes the total variation of a measure subject to
these moment constraints. This formulation naturally promotes sparsity,
yielding atomic solutions that are sums of Dirac measures. Compared to existing
methods, our moment-based approach reduces exponential error growth to
polynomial growth with respect to the terminal time. We provide explicit error
estimates on the recovered initial distributions in terms of moment order,
terminal time, and measurement errors. In addition, we develop efficient
numerical discretization schemes and demonstrate significant stability
improvements of our approach through comprehensive numerical experiments.

</details>


### [11] [A $\mathcal{CR}$-rotated $Q_1$ nonconforming finite element method for Stokes interface problems on local anisotropic fitted mixed meshes](https://arxiv.org/abs/2507.02741)
*Geng Chenchen,Hua Wang,Fengren Zou*

Main category: math.NA

TL;DR: A new nonconforming finite element method for Stokes interface problems is proposed, using anisotropic mixed meshes and proving stability and optimal convergence without stabilization or penalty terms.


<details>
  <summary>Details</summary>
Motivation: To address Stokes interface problems efficiently by developing a method that avoids the need for stabilization or penalty terms while maintaining stability and optimal convergence.

Method: The method uses local anisotropic mixed meshes, fitting the interface via intersection points. It employs the standard CR element for triangles and a new rotated Q1-type element for quadrilaterals, proving unisolvency and stability.

Result: The CR-rotated Q1 element pair with P0 pressure spaces satisfies the inf-sup condition without stabilization, and consistency error achieves optimal convergence without penalty terms.

Conclusion: Numerical examples confirm the theoretical findings, demonstrating the method's effectiveness for Stokes interface problems.

Abstract: We propose a new nonconforming finite element method for solving Stokes
interface problems. The method is constructed on local anisotropic mixed
meshes, which are generated by fitting the interface through simple connection
of intersection points on an interface-unfitted background mesh, as introduced
in \cite{Hu2021optimal}. For triangular elements, we employ the standard
$\mathcal{CR}$ element; for quadrilateral elements, a new rotated $Q_1$-type
element is used. We prove that this rotated $Q_1$ element remains unisolvent
and stable even on degenerate quadrilateral elements. Based on these
properties, we further show that the space pair of $\mathcal{CR}$-rotated $Q_1$
elements (for velocity) and piecewise $P_0$ spaces (for pressure) satisfies the
inf-sup condition without requiring any stabilization terms. As established in
our previous work \cite{Wang2025nonconforming}, the consistency error achieves
the optimal convergence order without the need for penalty terms to control it.
Finally, several numerical examples are provided to verify our theoretical
results.

</details>


### [12] [Uniform semiclassical observable error bound of Trotterization without the Egorov theorem: a simple algebraic proof](https://arxiv.org/abs/2507.02783)
*Di Fang,Conrad Qu*

Main category: math.NA

TL;DR: The paper presents a new algebraic proof for uniform-in-$h$ error bounds in Trotterization schemes for semiclassical Schrödinger equation simulations, avoiding heavy semiclassical machinery.


<details>
  <summary>Details</summary>
Motivation: Efficient simulation of the semiclassical Schrödinger equation is challenging due to error control requirements. Prior work showed certain observables allow time-step independence of $h$, but proofs were limited to low-order schemes and relied on semiclassical tools.

Method: The authors characterize the class of observables with uniform-in-$h$ error bounds and provide a simple algebraic proof for arbitrarily high-order Trotterization schemes, leveraging operator algebra in continuous and discrete settings.

Result: The proof achieves uniform-in-$h$ error bounds without Egorov-type theorems or semiclassical machinery, a first for high-order Trotterization in this regime.

Conclusion: This work simplifies the analysis of Trotterization errors in semiclassical simulations by relying solely on algebraic structure, broadening applicability and avoiding complex semiclassical tools.

Abstract: Efficient simulation of the semiclassical Schr\"odinger equation has garnered
significant attention in the numerical analysis community. While controlling
the error in the unitary evolution or the wavefunction typically requires the
time step size to shrink as the semiclassical parameter $h$ decreases, it has
been observed -- and proved for first- and second-order Trotterization schemes
-- that the error in certain classes of observables admits a time step size
independent of $h$. In this work, we explicitly characterize this class of
observables and present a new, simple algebraic proof of uniform-in-$h$ error
bounds for arbitrarily high-order Trotterization schemes. Our proof relies
solely on the algebraic structure of the underlying operators in both the
continuous and discrete settings. Unlike previous analyses, it avoids
Egorov-type theorems and bypasses heavy semiclassical machinery. To our
knowledge, this is the first proof of uniform-in-$h$ observable error bounds
for Trotterization in the semiclassical regime that relies only on algebraic
structure, without invoking the semiclassical limit.

</details>


### [13] [Block triangular preconditioning for inverse source problems in time-space fractional diffusion equations](https://arxiv.org/abs/2507.02809)
*Monoswini Majumdar,Stefano Serra-Capizzano,Rosita L. Sormani*

Main category: math.NA

TL;DR: Block triangular preconditioners improve convergence and stability in solving inverse source problems for time-space fractional diffusion equations.


<details>
  <summary>Details</summary>
Motivation: Address the ill-posedness and computational challenges in solving inverse source problems for multi-dimensional TSFDEs.

Method: Quasi-boundary value regularization, finite difference discretization, and a block triangular preconditioning strategy.

Result: Preconditioner enhances GMRES solver performance, improving convergence, robustness, and accuracy.

Conclusion: The preconditioner is effective for large-scale inverse problems in fractional modeling.

Abstract: The current work investigates the effectiveness of block triangular
preconditioners in accelerating and stabilizing the numerical solution of
inverse source problems governed by time-space fractional diffusion equations
(TSFDEs). We focus on the recovery of an unknown spatial source function in a
multi-dimensional TSFDE, incorporating Caputo time-fractional derivatives and
the fractional Laplacian. The inherent ill-posedness is addressed via a
quasi-boundary value regularization, followed by a finite difference
discretization that leads to large, structured linear systems. We develop and
analyze a block triangular preconditioning strategy that mimics the coefficient
matrix, while simplifying its structure for computational efficiency. Numerical
experiments using the GMRES solver demonstrate that the proposed preconditioner
significantly improve convergence rates, robustness, and accuracy, making it
well-suited for large-scale, real-world inverse problems involving fractional
modeling.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [14] [Composite media, almost touching disks and the maximum principle](https://arxiv.org/abs/2507.02077)
*YanYan Li,Ben Weinkove*

Main category: math.AP

TL;DR: A new proof of a gradient bound for two nearly touching disks with finite conductivities using the maximum principle.


<details>
  <summary>Details</summary>
Motivation: To address the problem of gradient bounds in divergence form elliptic equations with discontinuous coefficients, specifically for two nearly touching disks.

Method: Utilizes the maximum principle to derive the gradient bound.

Result: A new proof of the Li-Vogelius gradient bound is provided.

Conclusion: The maximum principle is effective for proving gradient bounds in such settings.

Abstract: We consider the setting of two disks in a domain in $\mathbb{R}^2$ which are
almost touching and have finite and positive conductivities, giving rise to a
divergence form elliptic equation with discontinuous coefficients. We use the
maximum principle to give a new proof of a gradient bound of Li-Vogelius.

</details>


### [15] [Tools for stability analysis of fractional reaction diffusion systems](https://arxiv.org/abs/2507.02094)
*Sofwah Ahmad,Szymon Cygan,Grzegorz Karch*

Main category: math.AP

TL;DR: The paper proves the linearization principle for abstract fractional reaction-diffusion equations with time-fractional derivatives and applies it to derive results like fractional Turing instability.


<details>
  <summary>Details</summary>
Motivation: To extend the linearization principle, a foundational concept in stability analysis, to fractional reaction-diffusion equations, bridging a gap in nonlinear problem analysis.

Method: The authors use abstract fractional reaction-diffusion equations with time-fractional derivatives (order α ∈ (0,1)) and prove the linearization principle for them.

Result: The principle is validated for fractional equations, enabling stability analysis and yielding insights like fractional Turing instability.

Conclusion: The work successfully generalizes the linearization principle to fractional settings, providing tools for stability analysis in fractional reaction-diffusion problems.

Abstract: The linearization principle states that the stability (or instability) of
solutions to a suitable linearization of a nonlinear problem implies the
stability (or instability) of solutions to the original nonlinear problem. In
this work, we prove this principle for solutions of abstract fractional
reaction-diffusion equations with a fractional derivative in time of order
$\alpha\in (0,1)$. Then, we apply these results to particular fractional
reaction-diffusion equations, obtaining, for example, the counterpart of the
classical Turing instability in the case of fractional equations.

</details>


### [16] [Global existence of the solution of the modified Camassa-Holm equation with step-like boundary conditions](https://arxiv.org/abs/2507.02100)
*I. Karpenko,D. Shepelsky,G. Teschl*

Main category: math.AP

TL;DR: Global existence of solutions for the modified Camassa-Holm equation with step-like initial data is established.


<details>
  <summary>Details</summary>
Motivation: To address the Cauchy problem for the modified Camassa-Holm equation with step-like initial conditions and prove the global existence of its solution.

Method: Analysis of the modified Camassa-Holm equation with step-like initial data, focusing on the behavior as x approaches ±∞.

Result: Demonstrates the global existence of the solution under the given conditions.

Conclusion: The study successfully establishes the global existence of solutions for the modified Camassa-Holm equation with step-like initial data.

Abstract: We consider the Cauchy problem for
  the modified Camassa-Holm equation
  \[
  u_t+\left((u^2-u_x^2)m\right)_x=0,\quad
  m\coloneqq u-u_{xx},
  \quad t>0,\ \ -\infty<x<+\infty
  \]
  subject to the step-like initial data: $u(x,0)\to A_1$ as $x\to-\infty$ and
$u(x,0)\to A_2$ as $x\to+\infty$, where $0<A_1<A_2$.
  The goal is to
  establish the global existence of the solution of this problem.

</details>


### [17] [Traveling Wave Solutions to a Large Class of Brenner-Navier-Stokes-Fourier Systems](https://arxiv.org/abs/2507.02224)
*Saehoon Eo,Namhyun Eun*

Main category: math.AP

TL;DR: The paper analyzes the one-dimensional BNSF system with temperature-dependent transport coefficients, proving existence and uniqueness of small-amplitude viscous shocks using geometric singular perturbation theory and the implicit function theorem.


<details>
  <summary>Details</summary>
Motivation: To address deficiencies in the classical Navier-Stokes-Fourier system by incorporating volume velocity and temperature-dependent coefficients for physical realism.

Method: Uses geometric singular perturbation theory and the implicit function theorem to analyze the BNSF system in Lagrangian mass coordinates.

Result: Existence and uniqueness of monotone traveling wave solutions (viscous shocks) for small shock amplitudes with positive C² dissipation coefficients.

Conclusion: The study provides robust quantitative estimates for traveling wave solutions, supporting prior work on large solutions to the BNSF system.

Abstract: The Brenner-Navier-Stokes-Fourier (BNSF) system, introduced by Howard
Brenner, was developed to address some deficiencies in the classical
Navier-Stokes-Fourier system, based on the concept of volume velocity. We
consider the one-dimensional BNSF system in Lagrangian mass coordinates,
incorporating temperature-dependent transport coefficients, which yields a more
physically realistic framework. We establish the existence and uniqueness of
monotone traveling wave solutions (or viscous shocks) to the BNSF system with
any positive $C^2$ dissipation coefficients, provided that the shock amplitude
is sufficiently small. We utilize geometric singular perturbation theory as in
the constant coefficient case [13]; however, due to the arbitrary
nonlinearities of the coefficients, we employ the implicit function theorem,
which grants robustness to our approach. This work is motivated by [12], which
proves a contraction property of any large solutions to the BNSF system around
the traveling wave solutions. Thus, we also derive some quantitative estimates
on the traveling wave solutions that play a fundamental role in [12].

</details>


### [18] [Analysis and Numerical Approximation to Interactive Dynamics of Navier Stokes-Plate Interaction PDE System](https://arxiv.org/abs/2507.02230)
*Pelin G. Geredeli,Quyuan Lin,Dylan Mcknight,Mohammad Mahabubur Rahman*

Main category: math.AP

TL;DR: The paper analyzes a fluid-structure interaction (FSI) system involving a Navier-Stokes fluid and an elastic membrane, proving well-posedness of weak solutions and providing a numerical FEM approximation with error bounds.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by applications in aeroelasticity, biomedical fields (e.g., ocular pressure control), and sloshing phenomena.

Method: Theoretical analysis uses a nonlinear variational formulation and inf-sup conditions for existence-uniqueness. Numerically, a FEM scheme with Picard iterations is employed.

Result: Existence-uniqueness of solutions is proven for small data. FEM results validate theory with error bounds in Sobolev norms.

Conclusion: The theoretical and numerical results align, confirming the validity of the approach for the FSI system.

Abstract: We consider a Navier-Stokes fluid-plate interaction (FSI) system which
describes the evolutions of the fluid contained within a 3D cavity, as it
interacts with a deformable elastic membrane on the ``free" upper boundary of
the cavity. These models arise in various aeroelastic and biomedical
applications as well as in the control of ocular pressure, and sloshing
phenomena. We analyze the well-posedness of weak solutions to the stationary
($\lambda$-parametrized) coupled PDE system by way of invoking the nonlinear
generalization of the abstract variational formulations which was introduced in
\cite{girault2012finite}, wherein an inf-sup approach is followed to show
existence-uniqueness of solutions under a small data assumption.
  In addition, we provide a numerical approximation scheme of the infinite
dimensional coupled system via a finite element method approximation (FEM). The
numerical results use a standard conforming scheme and handle the introduced
nonlinearities via Picard iterations. Numerical results are obtained for an
appropriate test problem satisfying the necessary boundary conditions and
coupling. Moreover, error bounds between the FEM and theoretical solution in
terms of the characteristic mesh size are supplied in appropriate Sobolev norms
which agree with the established literature. These FEM approximations of the
coupled system with their associated error bounds validate the theoretical
findings.

</details>


### [19] [Ill-posedness of the Euler equations and inviscid limit of the Navie-Stokes equations in Besov spaces](https://arxiv.org/abs/2507.02247)
*Jinlu Li,Xing Wu,Yanghai Yu*

Main category: math.AP

TL;DR: The paper investigates the ill-posedness of the incompressible Euler and Navier-Stokes equations on a d-dimensional torus, presenting new initial data and proofs for discontinuity and non-Holder continuity in Besov spaces.


<details>
  <summary>Details</summary>
Motivation: To address the lack of well-posedness for the Euler equations by constructing new initial data and providing proofs for discontinuity in various senses.

Method: Constructs new initial data and analyzes the solution map's behavior in Besov spaces, focusing on discontinuity and non-Holder continuity.

Result: Demonstrates the solution map's discontinuity at t=0 in B^s_{p,∞} and its non-continuity in L^∞_T(B^s_{p,∞}), as well as non-Holder continuity in B^s_{p,r}.

Conclusion: The Euler equations exhibit ill-posedness in multiple senses, extending prior results and highlighting challenges in their analysis.

Abstract: In this paper, we consider the Cauchy problem to the incompressible Euler and
Navie-Stokes equations on the d-dimensional torus.Our aim of this paper is two
fold. Firstly, we construct a new initial data and present a simple proof of
the ill-posedness of the Euler equations in different senses: (1) the solution
map of the Euler equations starting from $u_0$ is discontinuous at $t = 0$ in
$B^s_{p,\infty}$ with $s>0$ and $1\leq p \leq \infty$, which covers the result
obtained by Cheskidov and Shvydkoy in ;(2) the solution map of the Euler
equations is not continuous as a map from $B^s_{p,\infty}$ to
$L^\infty_T(B^s_{p,\infty})$;(3) the solution map of the Euler equations cannot
be Holder continuous in time variable in Besov spaces $B^s_{p,r}$.

</details>


### [20] [Trapping by repulsion: the NLS with a delta-prime](https://arxiv.org/abs/2507.02330)
*Riccardo Adami,Filippo Boni,Matteo Gallone*

Main category: math.AP

TL;DR: The paper proves the existence and provides explicit expressions for stationary states in a 1D Schrödinger equation with a repulsive delta-prime potential and focusing nonlinearity. Ground states exist for subcritical nonlinearity, explained by an emergent energy space dimension.


<details>
  <summary>Details</summary>
Motivation: To understand ground states in repulsive potentials, counterintuitive due to nonlinearity and delta-prime interactions.

Method: Minimizing the action functional on the Nehari manifold in subcritical, critical, and supercritical regimes.

Result: Ground states exist for all interaction strengths and masses in subcritical cases, with explicit forms derived.

Conclusion: Repulsive potentials can support ground states due to emergent dimensions in energy space, a novel phenomenon.

Abstract: We establish the existence and provide explicit expressions for the
stationary states of the one-dimensional Schr\"odinger equation with a
repulsive delta-prime potential and a focusing nonlinearity of power type.
Furthermore, we prove that, if the nonlinearity is subcritical, then ground
states exist for any strength of the delta-prime interaction and for every
positive value of the mass.
  This result supplies an example of ground states arising from a repulsive
potential, a counterintuitive phenomenon explained by the emergence of an
additional dimension in the energy space, induced by the delta-prime
interaction. This new dimension contains states of lower energy and is thus
responsible for the existence of nonlinear ground states that do not originate
from linear eigenfunctions.
  The explicit form of the ground states is derived by addressing the ancillary
problem of minimizing the action functional on the Nehari manifold. We solve
such problem in the subcritical, critical, and supercritical regimes.

</details>


### [21] [Self-similar vorticity around the boundary and non-uniqueness of solutions to the two-dimensional Navier-Stokes equations in the half space](https://arxiv.org/abs/2507.02338)
*Motofumi Aoki,Yasunori Maekawa*

Main category: math.AP

TL;DR: Non-uniqueness of mild solutions to 2D forced Navier-Stokes equations in half-space under no-slip boundary conditions, leveraging self-similar vorticity instability at high Reynolds numbers.


<details>
  <summary>Details</summary>
Motivation: To extend the understanding of non-unique solutions in fluid dynamics, particularly near boundaries, contrasting prior results where vorticity was away from boundaries.

Method: Construction of non-unique solutions based on instability of self-similar vorticity near the boundary at high Reynolds numbers, incorporating boundary layer effects.

Result: Demonstrated non-uniqueness of solutions, highlighting the role of boundary proximity in vorticity instability.

Conclusion: Boundary proximity significantly impacts solution uniqueness in the Navier-Stokes equations, differing from cases where vorticity is distant from boundaries.

Abstract: In this paper we show the non-uniqueness of mild solutions to the
two-dimensional forced Navier-Stokes equations in the half space under the
noslip boundary condition, following the program established by Albritton,
Bru{\'e}, and Colombo in 2022. Our construction of non-unique solutions is
based on the instability of self-similar vorticity at high Reynolds numbers
which concentrates around the boundary at the initial time. In our
construction, therefore, a kind of boundary layer has to be taken into account
in the analysis, contrasting to the known results where the unstable
self-similar vorticity is located away from the boundary with $O(1)$ distance
around the initial time.

</details>


### [22] [A field-road system with a rectifiable set](https://arxiv.org/abs/2507.02451)
*Matthieu Bonnivard,Romain Ducasse,Antoine Lemenant,Alessandro Zilio*

Main category: math.AP

TL;DR: The paper defines a 2D field-road system with a 1D-rectifiable road, introducing a framework for coupled parabolic problems with transmission conditions.


<details>
  <summary>Details</summary>
Motivation: To model and analyze systems where a lower-dimensional structure (road) interacts with a surrounding field, requiring a mathematical framework for such coupled problems.

Method: Introduces a general setting for defining parabolic problems on a rectifiable set (road) coupled with classical parabolic problems outside it, incorporating transmission conditions.

Result: A mathematical framework is established for analyzing coupled parabolic problems involving lower-dimensional structures.

Conclusion: The paper provides a foundational approach for modeling and solving coupled field-road systems with transmission conditions.

Abstract: The aim of this paper is to define a field-road system in 2D where the road
is a merely 1D-rectifiable set. For this purpose we introduce a general setting
in order to define a parabolic problem onto a rectifiable set, which is coupled
with another more classical parabolic problem outside this set, with
transmission conditions.

</details>


### [23] [Global Existence and Incompressible Limit for Compressible Navier-Stokes Equations in Bounded Domains with Large Bulk Viscosity Coefficient and Large Initial Data](https://arxiv.org/abs/2507.02462)
*Qinghao Lei,Chengfeng Xiong*

Main category: math.AP

TL;DR: Global existence and exponential decay of solutions for compressible Navier-Stokes equations with Navier-slip boundary conditions, with large bulk viscosity and no initial data restrictions. Solutions converge to incompressible case as viscosity tends to infinity.


<details>
  <summary>Details</summary>
Motivation: To study the behavior of compressible Navier-Stokes equations in bounded domains with vanishing initial density and Navier-slip boundary conditions, focusing on global solutions and their decay.

Method: Utilizes logarithmic interpolation inequality and compensated compactness lemma to analyze solutions under large bulk viscosity.

Result: Global existence and exponential decay of weak, strong, and classical solutions proven; convergence to incompressible Navier-Stokes as viscosity increases.

Conclusion: Large bulk viscosity ensures global solutions and decay, with convergence to incompressible dynamics, highlighting the role of viscosity in fluid behavior.

Abstract: We investigate the barotropic compressible Navier-Stokes equations with the
Navier-slip boundary conditions in a general two-dimensional bounded simply
connected domain. For initial density that is allowed to vanish, we establish
the global existence and exponential decay of weak, strong, and classical
solutions when the bulk viscosity coefficient is suitably large, without any
restrictions on the size of the initial data. Furthermore, we prove that when
the bulk viscosity coefficient tends to infinity, the solutions of the
compressible Navier-Stokes equations converge to those of the inhomogeneous
incompressible Navier-Stokes equations. The key idea is to utilize the
logarithmic interpolation inequality on general bounded domains and apply the
compensated compactness lemma.

</details>


### [24] [Renormalized variational principles and Hardy-type inequalities](https://arxiv.org/abs/2507.02486)
*Satyanad Kichenassamy*

Main category: math.AP

TL;DR: The paper extends Hardy's and Trudinger's inequalities, proving integrability results for functions in $H^1_0(\Omega)$ and linking them to the Liouville equation's maximal solution.


<details>
  <summary>Details</summary>
Motivation: To generalize Hardy's inequality and connect it with Trudinger's inequality, while providing new insights into the Liouville equation's solutions.

Method: Proves integrability of $[\exp(u^2)-1]/\delta^2$ for $u\in H^1_0(\Omega)$, extends to higher dimensions, and characterizes the Liouville equation's maximal solution via renormalized functionals.

Result: Establishes integrability conditions, connects Hardy's and Trudinger's inequalities, and provides a variational characterization of the Liouville equation's maximal solution.

Conclusion: The results unify and extend classical inequalities, offering new tools for analyzing the Liouville equation and its solutions.

Abstract: Let $\Omega\subset{\mathbb R}^2$ be a bounded domain on which Hardy's
inequality holds. We prove that $[\exp(u^2)-1]/\delta^2\in L^1(\Omega)$ if
$u\in H^1_0(\Omega)$, where $\delta$ denotes the distance to $\partial\Omega$.
The corresponding higher-dimensional result is also given. These results
contain both Hardy's and Trudinger's inequalities, and yield a new variational
characterization of the maximal solution of the Liouville equation on smooth
domains, in terms of a renormalized functional. A global $H^1$ bound on the
difference between the maximal solution and the first term of its asymptotic
expansion follows.

</details>


### [25] [Long-time Existence and Incompressible Limit of Weak and Classical Solutions to the Cauchy Problem for Compressible Navier-Stokes Equations with Large Bulk Viscosity Coefficient and Large Initial Data](https://arxiv.org/abs/2507.02497)
*Qinghao Lei,Chengfeng Xiong*

Main category: math.AP

TL;DR: The paper studies the Cauchy problem for barotropic compressible Navier-Stokes equations in 2D, proving long-time existence of solutions without extra initial velocity divergence restrictions. It also shows convergence to incompressible Navier-Stokes solutions as bulk viscosity tends to infinity.


<details>
  <summary>Details</summary>
Motivation: To address the Cauchy problem for compressible Navier-Stokes equations with vacuum or nonvacuum far fields, overcoming the challenge posed by the failure of Poincaré's inequality.

Method: Uses a time-dependent Poincaré-type inequality and assumes a sufficiently large bulk viscosity coefficient. Initial density conditions are weighted for integrability.

Result: Establishes long-time existence of weak, strong, and classical solutions. Shows convergence to incompressible solutions as bulk viscosity increases, even without divergence-free initial velocity.

Conclusion: The approach resolves the Poincaré inequality issue and broadens the applicability of solutions, linking compressible and incompressible Navier-Stokes dynamics.

Abstract: This paper investigates the Cauchy problem for the barotropic compressible
Navier-Stokes equations in $\mathbb{R}^2$ with the constant state as far field,
which could be vacuum or nonvacuum. Under the assumption of a sufficiently
large bulk viscosity coefficient, we establish the long-time existence of weak,
strong, and classical solutions, without imposing any extra restrictions on the
initial velocity divergence. Moreover, we demonstrate that the solutions of the
compressible Navier-Stokes equations converge to solutions of the inhomogeneous
incompressible Navier-Stokes equations, as the bulk viscosity coefficient tends
to infinity. The incompressible limit of the weak solutions holds even without
requiring the initial velocity to be divergence-free. The key obstacle in the
Cauchy problem is the failure of the Poincar\'e's inequality. This could be
resolved by introducing a time-dependent Poincar\'e's type inequality, but it
needs imposing weighted-integrability conditions on the initial density.

</details>


### [26] [Sharp second order inequalities with distance function to the boundary and applications to a p-Biharmonic singular problem](https://arxiv.org/abs/2507.02551)
*Cristian Cazacu,Teodor Rugină*

Main category: math.AP

TL;DR: Generalizations of Hardy-Rellich inequalities in L^p settings for domains with boundary-distance singularities, with sharp results in bounded domains and new bounds for sharp constants. Applications include variational methods for singular problems.


<details>
  <summary>Details</summary>
Motivation: Extend Hardy-Rellich inequalities to L^p settings and explore their sharpness and dependence on domain geometry, with practical applications in solving singular problems.

Method: Prove inequalities using boundary-distance singularities, provide minimizing sequences for bounded domains, and apply variational methods and Pohozaev identity.

Result: Sharp inequalities in bounded domains, new bounds for sharp constants, and insights into solution existence for singular problems.

Conclusion: The work extends Hardy-Rellich inequalities, provides sharp results, and applies them to variational problems, advancing understanding of singular domains.

Abstract: In this paper, we prove generalizations to the L^p setting of the
Hardy-Rellich inequalities on domains of R^N with singularity given by the
distance function to the boundary. The inequalities we obtain are either sharp
in bounded domains, where we provide concrete minimizing sequences, or give a
new bound for the sharp constant, while also depending on the geometric
properties of the domain and its boundary. We also give applications to the
existence and non-existence of solutions for a singular problem using
variational methods and a Pohozaev identity.

</details>


### [27] [Homogenisation and spectral convergence of high-contrast convolution type operators](https://arxiv.org/abs/2507.02638)
*Mikhail Cherdantsev,Andrey Piatnitski,Igor Velcic*

Main category: math.AP

TL;DR: The paper studies homogenization of high-contrast symmetric convolution-type operators in periodic microstructures, using two-scale convergence for spectral analysis.


<details>
  <summary>Details</summary>
Motivation: To analyze homogenization and spectral behavior of nonlocal convolution-type operators in periodic microstructures.

Method: Adapts two-scale convergence for nonlocal operators, examining whole space and bounded domains with Dirichlet conditions.

Result: The limit operator's spectrum is a subset of the original's, but they may not coincide.

Conclusion: The method provides insights into spectral behavior during homogenization, showing non-trivial spectral limits.

Abstract: The paper deals with homogenisation problems for high-contrast symmetric
convolution-type operators with integrable kernels in media with a periodic
microstructure. We adapt the two-scale convergence method to nonlocal
convolution-type operators and obtain the homogenisation result both for
problems stated in the whole space and in bounded domains with the homogeneous
Dirichlet boundary condition.
  Our main focus is on spectral analysis. We describe the spectrum of the limit
two-scale operator and characterize the limit behaviour of the spectrum of the
original problem as the microstructure period tends to zero. It is shown that
the spectrum of the limit operator is a subset the limit of the spectrum of the
original operator, and that they need not coincide.

</details>


### [28] [On the two-dimensional Navier-Stokes equations with horizontal viscosity](https://arxiv.org/abs/2507.02775)
*Chongsheng Cao,Yanqiu Guo*

Main category: math.AP

TL;DR: Study of 2D channel flow with horizontal viscosity, focusing on well-posedness, long-term behavior, and stability under low differentiability assumptions.


<details>
  <summary>Details</summary>
Motivation: To analyze the behavior of 2D channel flows with minimal initial smoothness requirements, addressing gaps in understanding such systems.

Method: Assumes horizontal viscosity, periodic horizontal boundaries, and hard walls. Analyzes solutions with initial velocities in $L^2(\Omega)$ and partial derivative in $L^2(\Omega)$.

Result: Investigates global well-posedness, large-time behavior, and stability under reduced initial differentiability.

Conclusion: The paper provides insights into the dynamics of 2D channel flows with minimal smoothness assumptions, contributing to theoretical fluid mechanics.

Abstract: This paper is concerned with a 2D channel flow that is periodic horizontally
but bounded above and below by hard walls. We assume the presence of horizontal
viscosity only. We study the well-posedness, large-time behavior, and stability
of solutions. For global well-posedness, we aim to assume less
differentiability on initial velocity $(u_0, v_0)$: in particular, we assume
$u_0,v_0\in L^2(\Omega)$ and $\partial_y u_0 \in L^2(\Omega)$.

</details>


### [29] [Vanishing Vertical Viscosity in Two-Dimensional Anisotropic Navier-Stokes Equations with No-Slip Boundary Conditions: An $L^p$ result](https://arxiv.org/abs/2507.02794)
*Chongsheng Cao,Yanqiu Guo*

Main category: math.AP

TL;DR: Study of inviscid limit for 2D Navier-Stokes with anisotropic viscosity, showing strong convergence in L^p norm as vertical viscosity vanishes.


<details>
  <summary>Details</summary>
Motivation: To address the inviscid limit problem for anisotropic viscous fluids with mismatched boundary conditions (no-slip vs. slip).

Method: Analyze the 2D Navier-Stokes equations with anisotropic viscosity, assuming H^2 initial velocity and impenetrable walls.

Result: Strong convergence in L^p norm (2 ≤ p < ∞) to the limiting problem as vertical viscosity approaches zero.

Conclusion: The work resolves the boundary condition mismatch challenge, proving convergence despite differing conditions.

Abstract: This paper studies the inviscid limit problem for the two-dimensional
Navier-Stokes equations with anisotropic viscosity. The fluid is assumed to be
bounded above and below by impenetrable walls, with a no-slip boundary
condition imposed on the bottom wall. For $H^2$ initial velocity, we establish
strong convergence in the $L^p$ norm to the limiting problem as the vertical
viscosity approaches zero, for any $2\leq p <\infty$. The main challenge lies
in the mismatch of boundary conditions - specifically, the no-slip condition in
the original problem versus the slip condition in the limiting problem.

</details>


### [30] [On the Boundary Harnack Principle for operators with different lower order terms](https://arxiv.org/abs/2507.02836)
*Daniela De Silva,Ovidiu Savin*

Main category: math.AP

TL;DR: Classical Boundary Harnack principle for solutions of two linear elliptic equations with identical principal parts in Lipschitz domains.


<details>
  <summary>Details</summary>
Motivation: To extend the Boundary Harnack principle to cases involving two distinct linear elliptic equations sharing the same principal part, ensuring broader applicability in analysis.

Method: Analysis of solutions to two linear uniformly elliptic equations with identical principal parts within Lipschitz domains.

Result: Established the Boundary Harnack principle for such cases, confirming its validity under the specified conditions.

Conclusion: The principle holds for solutions of two different elliptic equations with the same principal part in Lipschitz domains, generalizing its scope.

Abstract: We provide the classical Boundary Harnack principle in Lipschitz domains for
solutions to two different linear uniformly elliptic equations with the same
principal part.

</details>


### [31] [Free boundary regularity for a tumor growth model with obstacle](https://arxiv.org/abs/2507.02837)
*Giulia Bevilacqua,Matteo Carducci*

Main category: math.AP

TL;DR: The paper develops a theory for existence and regularity of solutions to a geometric free boundary problem in tumor growth models, using viscosity solutions and proving boundary regularity.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by tumor growth models where the tumor invades a region but is obstructed by another region, requiring analysis of free boundary behavior.

Method: Existence of viscosity solutions is shown via Perron's method. Interior and boundary regularity are analyzed using an improvement of flatness argument and studying a thin obstacle problem with oblique conditions.

Result: The free boundary meets the obstacle as a C^{1,α} graph, and C^{1,α} estimates are established for the thin obstacle problem.

Conclusion: The paper provides a rigorous framework for analyzing tumor growth models with obstacles, demonstrating regularity and existence of solutions.

Abstract: We develop an existence and regularity theory for solutions to a geometric
free boundary problem motivated by models of tumor growth. In this setting, the
tumor invades an accessible region $D$, its motion is directed along a constant
vector $V$, and it cannot penetrate another region $K$ acting as an obstacle to
the spread of the tumor. Due to the non variational structure of the problem,
we show existence of viscosity solutions via Perron's method. Subsequently, we
prove interior regularity for the free boundary near regular points by means of
an improvement of flatness argument. We further analyze the boundary regularity
and we prove that the free boundary meets the obstacle as a $C^{1,\alpha}$
graph. A key step in the analysis of the boundary regularity involves the study
of a thin obstacle problem with oblique boundary conditions, for which we
establish $C^{1,\alpha}$ estimates.

</details>


### [32] [Diffeomorphic approximation of piecewise affine homeomorphisms](https://arxiv.org/abs/2507.02854)
*Daniel Campbell,Luigi D'Onofrio,Tomáš Vítek*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Given any $f$ a locally finitely piecewise affine homeomorphism of $\Omega
\subset \mathbb{R}^d$ onto $\Delta \subset \mathbb{R}^d$ (for $d=3, 4$) such
that $f\in W^{1,p}(\Omega, \mathbb{R}^d)$ and $f^{-1}\in W^{1,q}(\Delta,
\mathbb{R}^d)$, $1\leq p ,q < \infty$ and any $\epsilon >0$ we construct a
diffeomorphism $\tilde{f}$ such that
  $$\|f-\tilde{f}\|_{W^{1,p}(\Omega,\mathbb{R}^d)} +
\|f^{-1}-\tilde{f}^{-1}\|_{W^{1,q}(\Delta,\mathbb{R}^d)} < \epsilon.$$

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [33] [A Multi-Level Monte Carlo Tree Search Method for Configuration Generation in Crystalline Systems](https://arxiv.org/abs/2507.02509)
*Xiaoxu Li,Ge Xu,Huajie Chen,Xingyu Gao,Haifeng Song*

Main category: physics.comp-ph

TL;DR: A multi-level Monte Carlo tree search algorithm is developed to efficiently identify optimal atomic configurations in crystalline materials with substitutional defects.


<details>
  <summary>Details</summary>
Motivation: Predicting and designing atomic structures in crystalline materials with substitutional defects is challenging due to combinatorial growth and rugged landscapes.

Method: A multi-level Monte Carlo tree search algorithm with hierarchical decomposition of the crystalline structure is used to explore and optimize configurations.

Result: Numerical experiments demonstrate the method's efficiency in identifying optimal configurations in typical crystalline systems.

Conclusion: The proposed algorithm effectively addresses the challenges of exploring and optimizing atomic configurations in substitutional defect systems.

Abstract: In this paper, we study the construction of structural models for the
description of substitutional defects in crystalline materials. Predicting and
designing the atomic structures in such systems is highly challenging due to
the combinatorial growth of atomic arrangements and the ruggedness of the
associated landscape. We develop a multi-level Monte Carlo tree search
algorithm to generate the "optimal" configuration within a supercell. Our
method explores the configuration space with an expanding search tree through
random sampling, which further incorporates a hierarchical decomposition of the
crystalline structure to accelerate exploration and reduce redundancy. We
perform numerical experiments on some typical crystalline systems to
demonstrate the efficiency of our method in identifying optimal configurations.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [34] [Impact of super-Gaussian electron distributions on plasma K-shell emission](https://arxiv.org/abs/2507.02341)
*H. P. Le,E. V. Marley,H. A. Scott*

Main category: physics.plasm-ph

TL;DR: The paper explores how super-Gaussian electron distributions in laser-produced plasmas affect ionization balance and K-shell emission, showing significant spectral changes useful for inferring non-equilibrium distributions.


<details>
  <summary>Details</summary>
Motivation: To understand how super-Gaussian electron distributions alter fundamental plasma properties, particularly ionization balance and K-shell emission.

Method: Uses approximate formulas and detailed collisional-radiative simulations to analyze effects on ionization and K-shell spectra.

Result: Super-Gaussian distributions minimally impact plasma ionization but significantly modify K-shell spectra.

Conclusion: K-shell spectroscopy can infer non-equilibrium electron distributions like super-Gaussians.

Abstract: Electron distributions in laser-produced plasmas will be driven toward a
super-Gaussian distribution due to inverse bremsstrahlung absorption [Langdon,
Phys. Rev. Lett. 44, 575 (1980)]. Both theoretical and experimental evidence
suggest that fundamental plasma properties are altered by the super-Gaussian
distribution. This paper examines how the super-Gaussian distribution affects
the ionization balance and K-shell emission of atomic plasmas, utilizing
approximate formulas and detailed collisional-radiative simulations. While the
impact on plasma ionization is small, K-shell spectra can be significantly
modified. Based on these findings, we demonstrate that K-shell spectroscopy can
be used to infer super-Gaussian or other similar non-equilibrium electron
distributions.

</details>


### [35] [Electron heating in bulk overdense plasma aided by time dependent external magnetic field](https://arxiv.org/abs/2507.02543)
*Rohit Juneja,Trishul Dhalia,Amita Das*

Main category: physics.plasm-ph

TL;DR: The study explores localized electron heating in overdense plasma using a time-dependent magnetic field, achieving Electron Cyclotron Resonance (ECR) with laser energy transfer to electrons via PIC simulations.


<details>
  <summary>Details</summary>
Motivation: To investigate electron heating in overdense plasma and leverage magnetic fields to enable laser propagation and energy transfer.

Method: Uses a decaying external magnetic field to achieve ECR with laser frequency, studied via Particle-In-Cell (PIC) simulations on OSIRIS4.0.

Result: Demonstrates electron energy gain for various magnetic field profiles, laser intensities, and polarizations, with potential near-future experimental feasibility.

Conclusion: The method shows promise for localized electron heating, with practical applications possible as magnetic field technology advances.

Abstract: This study investigates the localized electron heating in a bulk overdense
plasma. The method relies on using a time dependent magnetic field. An
initially high external magnetic field imposed on the overdense plasma target
enables the propagation of a laser pulse inside it through the pass bands that
occur in the magnetized dispersion relation. The choice of decaying external
magnetic field is then tailored appropriately to achieve Electron Cyclotron
Resonance (ECR) with the frequency of the laser electromagnetic field. At the
resonance location, the field energy of the laser gets transferred to the
electrons. These studies have been carried out with the help of the
Particle-In-Cell (PIC) simulation technique on the OSIRIS4.0 platform. A
detailed study has been carried out to illustrate the energy gain by electrons
for a variety of temporal profiles of the magnetic field, laser intensities,
and polarizations. The experiments in this regime may be within reach in the
near future. For instance, the choice of long-wavelength CO$_2$ laser requires
a magnetic field of about 10s of kilo Tesla to comfortably elicit a magnetized
response from electrons. Recent technological advancements have shown the
generation of about 1.4 kilo Tesla of magnetic field.

</details>


### [36] [Boosting the NOx production in microwave air plasma: A synergy of chemistry and vibrational kinetics](https://arxiv.org/abs/2507.02795)
*Qinghao Shen,Aleksandr Pikalev,Jonas Gans,Lex Kuijpers,Ashley Hughes,Vasco Guerra,M. C. M van de Sanden*

Main category: physics.plasm-ph

TL;DR: A quasi-1.5D model studies NOx production in microwave plasma reactors, revealing non-thermal processes boost NOx in the discharge zone but fade in the afterglow. Turbulence aids NO diffusion and cooling, suggesting efficiency improvements via turbulence optimization.


<details>
  <summary>Details</summary>
Motivation: To understand NOx production mechanisms and energy costs in microwave plasma reactors, focusing on vibrational, chemical, and electron kinetics.

Method: Uses a quasi-1.5D multi-temperature model to simulate discharge and afterglow regions, comparing results with experimental data.

Result: Non-thermal processes enhance NOx in the discharge but diminish in the afterglow. Turbulence improves NO diffusion and cooling, aligning with experimental data.

Conclusion: Optimizing turbulence and maintaining non-thermal conditions can enhance NOx synthesis efficiency, advancing plasma-based chemical processes.

Abstract: This study employs a quasi-1.5D multi-temperature model to investigate the
mechanisms governing NOx production and energy costs in microwave plasma
reactors operating at 80 mbar, focusing on the interplay of vibrational,
chemical and electron kinetics, thermodynamics, and transport processes across
the discharge and afterglow. In the plasma discharge zone, non-thermal
processes enhance NOx production as electrons transfer energy effectively to
the vibrational mode of N2. However, the non-thermal enhancement is found to
diminish rapidly within the central-afterglow region. The simulation results
show good agreement with experimental data for both the temperature profile and
energy cost. Turbulent effects facilitate radial NO diffusion into cooler
regions while simultaneously enhancing cooling of the axial region. These
findings highlight the potential to improve NOx synthesis efficiency by
optimizing turbulence and maintaining non-thermal conditions, offering new
opportunities for the advancement of plasma-based chemical processes.

</details>


<div id='astro-ph.CO'></div>

# astro-ph.CO [[Back]](#toc)

### [37] [A general polynomial emulator for cosmology via moment projection](https://arxiv.org/abs/2507.02179)
*Zheng Zhang*

Main category: astro-ph.CO

TL;DR: MomentEmu is a polynomial emulator for fast, interpretable mappings between theoretical parameters and observational features, outperforming neural networks in training cost, speed, and transparency.


<details>
  <summary>Details</summary>
Motivation: To provide a lightweight, interpretable alternative to neural-network-based emulators for cosmological analysis, enabling efficient forward modeling, parameter inference, and uncertainty propagation.

Method: Constructs moment matrices to project simulation data onto polynomial bases, yielding symbolic expressions for the target mapping.

Result: Achieves sub-percent accuracy in emulating cosmological mappings (e.g., CMB power spectrum and acoustic peak features) with negligible training cost and millisecond-level evaluation.

Conclusion: MomentEmu is a highly efficient and transparent tool for moderate-dimensional, smooth mappings, suitable for cosmological applications.

Abstract: We present MomentEmu, a general-purpose polynomial emulator for fast and
interpretable mappings between theoretical parameters and observational
features. The method constructs moment matrices to project simulation data onto
polynomial bases, yielding symbolic expressions that approximate the target
mapping. Compared to neural-network-based emulators, MomentEmu offers
negligible training cost, millisecond-level evaluation, and transparent
functional forms. As a demonstration, we develop two emulators:
PolyCAMB-$D_\ell$, which maps six cosmological parameters to the CMB
temperature power spectrum, and PolyCAMB-peak, which enables bidirectional
mapping between parameters and acoustic peak features. PolyCAMB-$D_\ell$
achieves an accuracy of $0.03\%$over $\ell \leq 2510$, while PolyCAMB-peak also
reaches sub-percent accuracy and produces symbolic forms consistent with known
analytical approximations. The method is well suited for forward modelling,
parameter inference, and uncertainty propagation, particularly when the
parameter space is moderate in dimensionality and the mapping is smooth.
MomentEmu offers a lightweight and portable alternative to regression-based or
black-box emulators in cosmological analysis.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [38] [Hybrid least squares for learning functions from highly noisy data](https://arxiv.org/abs/2507.02215)
*Ben Adcock,Bernhard Hientzsch,Akil Narayan,Yiming Xu*

Main category: stat.ML

TL;DR: A hybrid method combining Christoffel sampling and optimal experimental design is proposed for efficient conditional expectation estimation with noisy data, outperforming existing methods in high-noise scenarios.


<details>
  <summary>Details</summary>
Motivation: The need for efficient estimation of conditional expectations in the presence of heavily polluted data, where existing methods underperform with large noise.

Method: A hybrid approach integrating Christoffel sampling and optimal experimental design, extended to convex-constrained settings and adaptive random subspaces for random field expectations.

Result: Improved computational efficiency and sample complexity, with theoretical guarantees and numerical validation on synthetic and computational finance data.

Conclusion: The proposed method addresses limitations of existing approaches in high-noise regimes, offering robust performance and adaptability.

Abstract: Motivated by the need for efficient estimation of conditional expectations,
we consider a least-squares function approximation problem with heavily
polluted data. Existing methods that are powerful in the small noise regime are
suboptimal when large noise is present. We propose a hybrid approach that
combines Christoffel sampling with certain types of optimal experimental design
to address this issue. We show that the proposed algorithm enjoys appropriate
optimality properties for both sample point generation and noise mollification,
leading to improved computational efficiency and sample complexity compared to
existing methods. We also extend the algorithm to convex-constrained settings
with similar theoretical guarantees. When the target function is defined as the
expectation of a random field, we extend our approach to leverage adaptive
random subspaces and establish results on the approximation capacity of the
adaptive procedure. Our theoretical findings are supported by numerical studies
on both synthetic data and on a more challenging stochastic simulation problem
in computational finance.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [39] [On the Design of Corrugated Boards: A New FEM Modeling and Experimental Validation](https://arxiv.org/abs/2507.02189)
*Ricardo Fitas,Heinz Joachim Schaffrath,Samuel Schabel*

Main category: physics.app-ph

TL;DR: A simplified FEM modeling approach for corrugated boards uses homogenization and correction factors to reduce computational time while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: To optimize corrugated packaging design by simplifying FEM models for faster, accurate simulations.

Method: Homogenization transforms flute geometries into equivalent elastic models, with correction factors (Weibull distributions) for contact and buckling mechanisms.

Result: Validated statistical parameters (β₁=0.14, β₂=1.31) enable efficient representation of corrugated boards.

Conclusion: The approach is computationally efficient and accurate, aiding in packaging design optimization.

Abstract: This study presents a simplified FEM modeling approach suitable for large
structures made of corrugated boards, such as customized packages, based on a
homogenization method, which is combined with correction factors for internal
mechanisms. The homogenization process reduces computational time by
transforming flute geometries into equivalent elastic models. In large
deformations and in the presence of contact for a given geometry, the effective
elastic modulus in the thickness direction, as well as the effective thickness
of the structure, are corrected by two statistical Weibull distributions
representing the contact and buckling mechanisms in a corrugated board. The
Weibull parameters are obtained via experimental analysis, and such a process
is then validated. The results demonstrate that the statistical parameters
($\beta_1 = 0.14$, $\beta_2 = 1.31$) can be used for the simplistic
representation of corrugated boards, being computationally efficient. This
research contributes to the optimization of corrugated packaging design,
specifically by simplifying FEM models for faster yet equally accurate
simulations.

</details>


### [40] [Modeling the Effective Elastic Modulus and Thickness of Corrugated Boards Using Gaussian Process Regression and Expected Hypervolume Improvement](https://arxiv.org/abs/2507.02208)
*Ricardo Fitas*

Main category: physics.app-ph

TL;DR: The paper models the hypersurface of effective elastic modulus and thickness in corrugated boards using LHS and GP with EHVI, achieving accurate predictions for engineering applications.


<details>
  <summary>Details</summary>
Motivation: Accurate modeling of effective elastic modulus and thickness is crucial for optimizing mechanical properties in corrugated materials.

Method: Uses Latin Hypercube Sampling (LHS) for initial sampling and Gaussian Process Regression (GP) enhanced by EHVI for modeling.

Result: Achieved MSE of 5.24 kPa² for elastic modulus and 1 mm² for thickness, showing improved accuracy.

Conclusion: GP with EHVI is effective for structural optimization in corrugated materials.

Abstract: This work aims to model the hypersurface of the effective elastic modulus, \(
E_{z, \text{eff}} \), and thickness, \( th_{\text{eff}} \), in corrugated
boards. A Latin Hypercube Sampling (LHS) is followed by Gaussian Process
Regression (GP), enhanced by EHVI as a multi-objective acquisition function.
Accurate modeling of \( E_{z, \text{eff}} \) and \( th_{\text{eff}} \) is
critical for optimizing the mechanical properties of corrugated materials in
engineering applications. LHS provides an efficient and straightforward
approach for an initial sampling of the input space; GP is expected to be able
to adapt to the complexity of the response surfaces by incorporating both
prediction and uncertainty. Therefore, the next points being generated and
evaluated are based on the complexity of the hypersurfaces, and some points,
especially those with higher variance, are more exploited and carry more
importance. The performance of GP with EHVI is measured by Mean Squared Error
(MSE). Prediction of GP resulted in \( \text{MSE}(E_{z, \text{eff}}) = 5.24 \,
\text{kPa}^2 \) and \( \text{MSE}(th_{\text{eff}}) = 1 \, \text{mm}^2 \). GP
possesses then improved accuracy and adaptability for future applications in
structural optimization.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [41] [Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning](https://arxiv.org/abs/2507.02211)
*Gustavo C. Mangold,Heitor C. M. Fernandes,Mendeli H. Vainstein*

Main category: cs.AI

TL;DR: The paper explores how dilution and mobility affect cooperation in spatial prisoner's dilemma games using multi-agent Q-learning, showing equivalence between fixed and learned rules and symbiotic effects.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of dilution and mobility on cooperation in spatial prisoner's dilemma games using reinforcement learning, extending prior non-reinforcement learning studies.

Method: Uses an independent multi-agent Q-learning algorithm to model the game, defining various actions to connect with classical results.

Result: Observes qualitative equivalence between fixed and learned update rules and identifies symbiotic mutualistic effects between populations.

Conclusion: The approach demonstrates versatility in modeling game-theoretical scenarios and highlights the benchmarking potential of reinforcement learning in such contexts.

Abstract: Recent studies in the spatial prisoner's dilemma games with reinforcement
learning have shown that static agents can learn to cooperate through a diverse
sort of mechanisms, including noise injection, different types of learning
algorithms and neighbours' payoff knowledge.In this work, using an independent
multi-agent Q-learning algorithm, we study the effects of dilution and mobility
in the spatial version of the prisoner's dilemma. Within this setting,
different possible actions for the algorithm are defined, connecting with
previous results on the classical, non-reinforcement learning spatial
prisoner's dilemma, showcasing the versatility of the algorithm in modeling
different game-theoretical scenarios and the benchmarking potential of this
approach.As a result, a range of effects is observed, including evidence that
games with fixed update rules can be qualitatively equivalent to those with
learned ones, as well as the emergence of a symbiotic mutualistic effect
between populations that forms when multiple actions are defined.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [42] [MeV cosmic-ray electrons modify the TeV pair-beam plasma instability](https://arxiv.org/abs/2507.02423)
*Mahmoud Alawashra,Yuanyuan Yang,Christopher M. Hirata,Heyang Long,Martin Pohl*

Main category: astro-ph.HE

TL;DR: The paper explores how linear Landau damping (LLD) affects the energy-loss efficiency of plasma instabilities in relativistic pair beams from blazars, finding it suppresses oblique modes but enhances quasi-parallel ones, significantly boosting energy loss.


<details>
  <summary>Details</summary>
Motivation: To explain the absence of GeV-scale electromagnetic cascades in hard-spectrum TeV-emitting blazars, focusing on the role of LLD in suppressing or enhancing plasma instabilities.

Method: The study investigates the impact of LLD on plasma instabilities in pair beams associated with blazar 1ES 0229+200, analyzing the suppression of oblique electrostatic modes and growth of quasi-parallel ones.

Result: LLD suppresses oblique electrostatic modes but allows quasi-parallel modes to grow, increasing the energy-loss efficiency of the instability by over an order of magnitude.

Conclusion: LLD plays a critical role in enhancing the energy-loss efficiency of plasma instabilities, providing a plausible explanation for the missing GeV cascade in blazar spectra.

Abstract: Relativistic pair beams created in the intergalactic medium (IGM) by TeV
gamma rays from blazars are expected to produce a detectable GeV-scale
electromagnetic cascade, but the cascade component is absent in the spectra of
many hard-spectrum TeV-emitting blazars. One common explanation is that weak
intergalactic magnetic fields deflect the electron-positron pairs away from our
line of sight. An alternative possibility is that electrostatic beam-plasma
instabilities drain the energy of these pairs before a cascade can develop.
Recent studies have shown that beam scattering by oblique electrostatic modes
leads to minimal energy loss. But these modes might be suppressed by linear
Landau damping (LLD) due to MeV-scale cosmic-ray electrons in the IGM. In this
work, we explore the impact of LLD on the energy-loss efficiency of plasma
instabilities in pair beams associated with 1ES 0229+200. We find that LLD
effectively suppresses oblique electrostatic modes, while quasi-parallel ones
grow to larger amplitudes. In this way, LLD enhances the energy-loss efficiency
of the instability by more than an order of magnitude.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [43] [Cauchy problem for the localized wave propagation in continuous model of the one-dimensional diatomic crystal](https://arxiv.org/abs/2507.02729)
*Sergey Sergeev*

Main category: math-ph

TL;DR: The paper studies wave propagation in a 1D diatomic lattice, modeling it as a Cauchy problem with localized initial data. It analyzes asymptotic solutions for two scenarios of perturbation size relative to the lattice step, using Airy functions.


<details>
  <summary>Details</summary>
Motivation: To understand localized wave propagation in diatomic lattices, focusing on the impact of perturbation size relative to the lattice step.

Method: Formulates the problem as a Cauchy problem with two small parameters (lattice step and perturbation size), derives asymptotic solutions via Airy functions for two cases.

Result: Analytical formulae for asymptotic solutions are provided, showing the solution's dependence on the ratio of perturbation size to lattice step.

Conclusion: The form of the solution is highly sensitive to the ratio of perturbation size to lattice step, with distinct behaviors in large and comparable cases.

Abstract: We study the continuous model of the localized wave propagation corresponding
to the one-dimensional diatomic crystal lattice. From the mathematical point of
view the problem can be described in terms of the Cauchy problem with localized
initial data for a system of two pseudo-differential equations. We assume two
small parameters in this formulation -- the lattice step and the size if the
initial perturbation. We construct the asymptotic solution of the continuous
Cauchy problem with respect to the size of perturbation.
  The ratio of the small parameters drastically affects the form of the
solution. We consider two situations -- when the size of the perturbation is
sufficiently large and when it is comparable with the lattice step. In each
situations we provide analytical formulae for the asymptotic solution via Airy
function.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [44] [Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework](https://arxiv.org/abs/2507.02106)
*Semih Kacmaz,E. A. Huerta,Roland Haas*

Main category: physics.flu-dyn

TL;DR: A hybrid ML framework combining PINOs and diffusion models accurately simulates 2D MHD turbulence across a wide range of Reynolds numbers, outperforming deterministic methods.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of simulating fully developed MHD turbulence, especially at high Reynolds numbers, where deterministic methods fail.

Method: Uses Physics-Informed Neural Operators (PINOs) for low-frequency dynamics and a conditional diffusion model for high-frequency corrections, trained on high-fidelity simulations.

Result: Achieves state-of-the-art accuracy, capturing non-Gaussian statistics and high-wavenumber evolution even at extreme turbulence levels (Re=10000).

Conclusion: The framework successfully models MHD turbulence across a broad Re range, enabling previously unattainable predictions.

Abstract: We present a hybrid machine learning framework that combines Physics-Informed
Neural Operators (PINOs) with score-based generative diffusion models to
simulate the full spatio-temporal evolution of two-dimensional, incompressible,
resistive magnetohydrodynamic (MHD) turbulence across a broad range of Reynolds
numbers ($\mathrm{Re}$). The framework leverages the equation-constrained
generalization capabilities of PINOs to predict coherent, low-frequency
dynamics, while a conditional diffusion model stochastically corrects
high-frequency residuals, enabling accurate modeling of fully developed
turbulence. Trained on a comprehensive ensemble of high-fidelity simulations
with $\mathrm{Re} \in \{100, 250, 500, 750, 1000, 3000, 10000\}$, the approach
achieves state-of-the-art accuracy in regimes previously inaccessible to
deterministic surrogates. At $\mathrm{Re}=1000$ and $3000$, the model
faithfully reconstructs the full spectral energy distributions of both velocity
and magnetic fields late into the simulation, capturing non-Gaussian
statistics, intermittent structures, and cross-field correlations with high
fidelity. At extreme turbulence levels ($\mathrm{Re}=10000$), it remains the
first surrogate capable of recovering the high-wavenumber evolution of the
magnetic field, preserving large-scale morphology and enabling statistically
meaningful predictions.

</details>


### [45] [Predicting Flow-Induced Vibration in Isolated and Tandem Cylinders Using Hypergraph Neural Networks](https://arxiv.org/abs/2507.02242)
*Shayan Heydari,Rui Gao,Rajeev K Jaiman*

Main category: physics.flu-dyn

TL;DR: A hypergraph neural network framework predicts flow-induced vibrations in cylinders, preserving finite-element discretization structure and accurately modeling fluid-structure interactions.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of predicting nonlinear flow-induced vibrations in freely oscillating cylinders, especially under complex wake-body interactions.

Method: Uses a modular architecture: a POD-based sub-network for mesh deformation and a hypergraph message-passing network for flow prediction, trained on high-fidelity ALE simulations.

Result: Accurately captures oscillation amplitudes, resolves wake-body interactions, and reproduces force statistics and flow dynamics.

Conclusion: The framework is a robust surrogate model for digital twin applications, demonstrating high fidelity in complex scenarios.

Abstract: We present a finite element-inspired hypergraph neural network framework for
predicting flow-induced vibrations in freely oscillating cylinders. The
surrogate architecture transforms unstructured computational meshes into
node-element hypergraphs that encode higher-order spatial relationships through
element-based connectivity, preserving the geometric and topological structure
of the underlying finite-element discretization. The temporal evolution of the
fluid-structure interaction is modeled via a modular partitioned architecture:
a complex-valued, proper orthogonal decomposition-based sub-network predicts
mesh deformation using a low-rank representation of Arbitrary
Lagrangian-Eulerian (ALE) grid displacements, while a hypergraph-based
message-passing network predicts the unsteady flow field using geometry-aware
node, element, and hybrid edge features. High-fidelity ALE-based simulations
provide training and evaluation data across a range of Reynolds numbers and
reduced velocities for isolated and tandem cylinder configurations. The
framework demonstrates stable roll-outs and accurately captures the nonlinear
variation of oscillation amplitudes with respect to reduced velocity, a key
challenge in surrogate modeling of flow-induced vibrations. In the tandem
configuration, the model successfully resolves complex wake-body interactions
and multi-scale coupling effects, enabling accurate prediction of pressure and
velocity fields under strong wake interference conditions. Our results show
high fidelity in reproducing force statistics, dominant frequencies, and
flow-field dynamics, supporting the framework's potential as a robust surrogate
model for digital twin applications.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [46] [Time Resolution Independent Operator Learning](https://arxiv.org/abs/2507.02524)
*Diab W. Abueidda,Mbebo Nonna,Panos Pantidis,Mostafa E. Mobasher*

Main category: cs.CE

TL;DR: NCDE-DeepONet, a continuous-time operator network, overcomes limitations of existing methods for learning PDE solution operators by using Neural Controlled Differential Equations (NCDEs) to handle sparse, irregular data and enable resolution-independent predictions.


<details>
  <summary>Details</summary>
Motivation: Existing methods like Recurrent DeepONet and neural-ODE surrogates have limitations in handling sparse, irregular data and continuous-time inputs. NCDE-DeepONet aims to address these challenges.

Method: NCDE-DeepONet embeds an NCDE in the branch to encode load history as a controlled ODE and augments the trunk with space-time coordinates, enabling resolution-independent predictions.

Result: The framework achieves robust and accurate predictions on transient PDE problems, offering almost instant solution prediction without retraining.

Conclusion: Controlled dynamics provide a principled and efficient foundation for high-fidelity operator learning in transient mechanics.

Abstract: Accurately learning solution operators for time-dependent partial
differential equations (PDEs) from sparse and irregular data remains a
challenging task. Recurrent DeepONet extensions inherit the discrete-time
limitations of sequence-to-sequence (seq2seq) RNN architectures, while
neural-ODE surrogates cannot incorporate new inputs after initialization. We
introduce NCDE-DeepONet, a continuous-time operator network that embeds a
Neural Controlled Differential Equation (NCDE) in the branch and augments the
trunk with explicit space-time coordinates. The NCDE encodes an entire load
history as the solution of a controlled ODE driven by a spline-interpolated
input path, making the representation input-resolution-independent: it encodes
different input signal discretizations of the observed samples. The trunk then
probes this latent path at arbitrary spatial locations and times, rendering the
overall map output-resolution independent: predictions can be queried on meshes
and time steps unseen during training without retraining or interpolation.
Benchmarks on transient Poisson, elastodynamic, and thermoelastic problems
confirm the robustness and accuracy of the framework, achieving almost instant
solution prediction. These findings suggest that controlled dynamics provide a
principled and efficient foundation for high-fidelity operator learning in
transient mechanics.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [47] [Spin Caloritronics in irradiated chiral ferromagnetic systems](https://arxiv.org/abs/2507.02765)
*Sudin Ganguly,Moumita Dey,Santanu K. Maiti*

Main category: cond-mat.mes-hall

TL;DR: The paper investigates the thermoelectric response of a ferromagnetic helical system under light irradiation, revealing enhanced spin thermoelectric performance compared to charge thermopower.


<details>
  <summary>Details</summary>
Motivation: To explore how light irradiation affects the thermoelectric properties of ferromagnetic helical systems, focusing on spin-dependent transport.

Method: Uses a tight-binding framework, Floquet-Bloch formalism, non-equilibrium Green's function technique for spin transport, and a mass-spring model for phonon thermal conductance.

Result: Light induces spin-split transmission, reduces thermal conductance, and improves spin thermopower and figure of merit (FOM). Spin FOM outperforms charge FOM, with long-range hopping further enhancing performance.

Conclusion: The study highlights the potential of light-irradiated ferromagnetic helical systems for efficient spin-dependent energy conversion, with long-range hopping as a key factor.

Abstract: We study the charge and spin-dependent thermoelectric response of a
ferromagnetic helical system irradiated by arbitrarily polarized light, using a
tight-binding framework and the Floquet-Bloch formalism. Transport properties
for individual spin channels are determined by employing the non-equilibrium
Green's function technique, while phonon thermal conductance is evaluated using
a mass-spring model with different lead materials. The findings reveal that
that light irradiation induces spin-split transmission features, suppresses
thermal conductance, and yields favorable spin thermopower and figure of merit
(FOM). The spin FOM consistently outperforms its charge counterpart under
various light conditions. Moreover, long-range hopping is shown to enhance the
spin thermoelectric performance, suggesting a promising strategy for efficient
energy conversion in related ferromagnetic systems.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [48] [Is the hyperscaling relation violated below the upper critical dimension in some particular cases?](https://arxiv.org/abs/2507.02159)
*Hung T. Diep,Van-Thanh Ngo*

Main category: cond-mat.stat-mech

TL;DR: The paper analyzes critical exponents in thin films via Monte Carlo simulations, revealing deviations from 2D values and violations of hyperscaling, suggesting an 'effective' dimension. It also explores cross-over transitions and new universality classes.


<details>
  <summary>Details</summary>
Motivation: To investigate critical exponents in thin films and understand deviations from known 2D and 3D values, as well as violations of hyperscaling relations.

Method: High-performance multi-histogram Monte Carlo simulations with free and periodic boundary conditions, studying the Ising model with nearest-neighbor interactions.

Result: Critical exponents for films deviate systematically from 2D values, suggesting an 'effective' dimension. Hyperscaling violations occur, and new universality classes are identified for coupled symmetries.

Conclusion: The findings challenge traditional hyperscaling relations and introduce new insights into critical behavior in thin films and coupled systems.

Abstract: In this review, we show our results with new interpretation on the critical
exponents of thin films obtained by high-performance multi-histogram Monte
Carlo simulations. The film thickness $N_z$ consists of a few layers up to a
dozen of layers in the $z$ direction. The free boundary condition is applied in
this direction while in the $xy$ plane periodic boundary conditions are used.
Large $xy$ plane sizes are used for finite-size scaling. The Ising model is
studied with nearest-neighbor (NN) interaction. When $N_z=1$, namely the
two-dimensional (2D) system, we find the critical exponents given by the
renormalization group. While, for $N_z>1$, the critical exponents calculated
with the high-precision multi-histogram technique show that they deviate
slightly but systematically from the 2D values. If we use these values of
critical exponents in the hyperscaling relation with $d=2$, then the
hyperscaling relation is violated. However, if we use the hyperscaling relation
and the critical exponents obtained for $N_z>1$ to calculate the dimension of
the system, we find the system dimension slightly larger than 2. This can be
viewed as an "effective" dimension. More discussion is given in the paper. We
also show the cross-over between the first- and second-order transition while
varying the film thickness in an antiferromagnetic FCC Ising frustrated thin
film. In addition, we will show evidence that when a 2D system has two order
parameters of different symmetries with a single transition, the critical
exponents are new, suggesting a universality class of coupled two-symmetry
breakings. In this case, the 2D hyperscaling does not hold. Another case is the
3D Ising model coupled to the lattice vibration: the critical exponents deviate
from the 3D Ising ones, the results suggest the violation of the hyperscaling.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [49] [Optimal boron-doped graphene substrate for glucose Raman signal enhancement](https://arxiv.org/abs/2507.02642)
*Jan Komeda,Antonio Cammarata,Tomas Polcar*

Main category: cond-mat.mtrl-sci

TL;DR: B-doped graphene enhances Raman signals, with higher doping concentrations and molecule orientation playing key roles in effectiveness for glucose detection.


<details>
  <summary>Details</summary>
Motivation: To explore how boron doping concentration and geometric distribution in graphene affect its performance as a SERS substrate for glucose detection.

Method: Quantum mechanical simulations analyzing interatomic force constants and phonon eigenvectors.

Result: Higher boron doping concentrations enhance glucose's Raman signal, and molecule orientation is crucial for Raman response.

Conclusion: High-concentration B-graphene is a promising SERS substrate for glucose detection, and phonon-based analysis aids in identifying effective substrate materials.

Abstract: Surface Enhanced Raman Spectroscopy (SERS) is a highly sensitive and
selective technique that greatly enhances the signal of an analyte, compared
with its signal from classical Raman Spectroscopy, due to its interaction with
a substrates surface. It has been shown that low concentration boron-doped
graphene (B-graphene) enhances the Raman signal of simple organic molecules
like pyridine. Recent studies also suggest that B-graphene can remain
thermodynamically stable when doped with significantly higher concentrations of
boron than previously observed. In this framework, we use quantum mechanical
simulations to investigate the influence of dopant concentration and geometric
distribution on the effectiveness of B-doped graphene as a SERS substrate, with
glucose as analyte. By combining analysis of interatomic force constants and of
phonon eigenvectors composition, we conclude that higher doping concentrations
provide a larger enhancement to glucose's Raman signal, while the molecule
orientation relative to the surface plays a fundamental role in the Raman
response. We suggest that high concentration B-graphene presents itself as a
potential substrate for SERS based detection of glucose, while the used
phonon-based analysis can be promptly applied for the search of promising
candidates as substrate materials for enhanced Raman response.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [50] [Langmuir Wave Excitation in Solar-wind Magnetic Holes](https://arxiv.org/abs/2507.02042)
*Jingting Liu,Daniel Verscharen,Jesse Coburn,Georgios Nicolaou,Xiangyu Wu,Wence Jiang,Oreste Pezzi,Francesco Pucci,Matteo Zuin,Christopher J. Owen,Hamish Reid*

Main category: physics.space-ph

TL;DR: The paper explains how Langmuir waves are excited in magnetic holes in the solar wind using a model based on magnetic-moment conservation and its violation, validated by Solar Orbiter data.


<details>
  <summary>Details</summary>
Motivation: To understand the strong correlation between magnetic holes and Langmuir waves observed in the solar wind.

Method: Developed a model using magnetic-moment conservation and its violation, analyzing data from the Solar Orbiter spacecraft.

Result: The model successfully explains the excitation of Langmuir waves in magnetic holes, matching observational data.

Conclusion: The proposed mechanism is viable for producing Langmuir waves in solar wind magnetic holes.

Abstract: Magnetic holes are structures commonly observed in various space plasma
environments throughout the solar system, including the solar wind. These
structures are characterized by a localized decrease in magnetic field
strength, coincident with an increase in plasma density. Previous observational
studies in the solar wind link the presence of Langmuir waves to magnetic
holes, suggesting a strong correlation between these phenomena. We develop a
model based on magnetic-moment conservation and its violation to explain the
excitation of Langmuir waves in magnetic holes. Our model illustrates that
magnetic holes induce changes in the electron velocity distribution function
that emit electrostatic Langmuir waves due to the bump-on-tail instability.
Using data from the Solar Orbiter spacecraft, we provide a comprehensive
analysis of this process and test our predictions with observations. The
consistency between the model and observations indicates that our proposed
process is a viable mechanism for producing Langmuir waves in magnetic holes in
the solar wind.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [51] [Public perspectives on the design of fusion energy facilities](https://arxiv.org/abs/2507.02207)
*Nathan Kawamoto,Daniel Hoover,Jonathan Xie,Jacob Walters,Katie Snyder,Aditi Verma*

Main category: physics.soc-ph

TL;DR: The paper explores participatory design for fusion energy facilities, involving community and engineering students to identify key values and criteria for social acceptance.


<details>
  <summary>Details</summary>
Motivation: Understanding public perspectives is crucial for social license, especially as fusion facilities may be sited near communities due to distinct regulations.

Method: A participatory design workshop with 22 community participants and 34 engineering students, analyzing textual and visual data.

Result: Key values: integrity and respect; top criteria: economic benefits and environmental safety. Design themes included community legacy, worker care, transparency, and safety.

Conclusion: Participatory design early in tech development can address public hopes/concerns, foster understanding, and support social license for fusion energy.

Abstract: As fusion energy technologies approach demonstration and commercial
deployment, understanding public perspectives on future fusion facilities will
be critical for achieving social license, especially because fusion energy
facilities, unlike large fission reactors, may be sited in closer proximity to
people and communities, due to distinct regulatory frameworks. In a departure
from the 'decide-announce-defend' approach typically used to site energy
infrastructure, we develop a participatory design methodology for
collaboratively designing fusion energy facilities with prospective host
communities. We present here our findings from a participatory design workshop
that brought together 22 community participants and 34 engineering students.
Our analysis of the textual and visual data from this workshop shows a range of
design values and decision-making criteria with 'integrity' and 'respect'
ranking highest among values and 'economic benefits' and 'environmental
protection/safety' ranking highest among decision-making criteria. Salient
design themes that emerge across facility concepts include connecting the
history and legacy of the community to the design of the facility, care for
workers, transparency and access to the facility, and health and safety of the
host community. Participants reported predominantly positive sentiments,
expressing joy and surprise as the workshop progressed from learning about
fusion to designing the hypothetical facility. Our findings suggest that
carrying out participatory design in the early stages of technology development
can invite and make concrete public hopes and concerns, improve understanding
of, and curiosity about, an emerging technology, build toward social license,
and inform context-specific development of fusion energy facilities.

</details>
