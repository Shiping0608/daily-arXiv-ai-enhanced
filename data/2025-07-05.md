<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 13]
- [math.AP](#math.AP) [Total: 19]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [math-ph](#math-ph) [Total: 1]
- [astro-ph.CO](#astro-ph.CO) [Total: 1]
- [physics.space-ph](#physics.space-ph) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A Hybrid DEC-SIE Framework for Potential-Based Electromagnetic Analysis of Heterogeneous Media](https://arxiv.org/abs/2507.02099)
*Amgad Abdrabou,Luis J. Gomez,Weng Cho Chew*

Main category: math.NA

TL;DR: A hybrid method combining DEC and SIE is proposed for efficient electromagnetic field analysis in complex environments, improving compatibility and performance.


<details>
  <summary>Details</summary>
Motivation: Addressing computational challenges in analyzing electromagnetic fields in multi-material environments.

Method: Couples DEC with SIE, using magnetic vector and electric scalar potentials under the Lorenz gauge, and divides the domain for bounded/unbounded regions.

Result: Scalar reformulation of SIEs reduces operators, enhancing compatibility and numerical performance.

Conclusion: The hybrid method provides a unified, efficient framework for electromagnetic problems in complex geometries.

Abstract: Analyzing electromagnetic fields in complex, multi-material environments
presents substantial computational challenges. To address these, we propose a
hybrid numerical method that couples discrete exterior calculus (DEC) with
surface integral equations (SIE) in the potential-based formulation of
Maxwell's equations. The method employs the magnetic vector and electric scalar
potentials ($\mathbf{A}$-$\Phi$) under the Lorenz gauge, offering natural
compatibility with multi-physics couplings and inherent immunity to
low-frequency breakdown. To effectively handle both bounded and unbounded
regions, we divide the computational domain: the inhomogeneous interior is
discretized using DEC, a coordinate-free framework that preserves topological
invariants and enables structure-preserving discretization on unstructured
meshes, while the homogeneous exterior is treated using SIEs, which inherently
satisfy the radiation condition and eliminate the need for artificial domain
truncation. A key contribution of this work is a scalar reformulation of the
SIEs, which reduces the number of surface integral operators from fourteen to
two by expressing the problem in terms of the Cartesian components of the
vector potential and their normal derivatives. This simplification motivates a
corresponding adaptation in the DEC domain: each vector potential component is
represented as a discrete 0-form, in contrast to the conventional 1-form
representation. This novel treatment improves compatibility at the interface
and significantly enhances numerical performance. The proposed hybrid method
thus offers a unified, efficient, and physically consistent framework for
solving electromagnetic scattering and radiation problems in complex geometries
and heterogeneous materials

</details>


### [2] [Symplectic Hamiltonian Hybridizable Discontinuous Galerkin Methods for Linearized Shallow Water Equations](https://arxiv.org/abs/2507.02340)
*C. Núñez,M. A. Sánchez*

Main category: math.NA

TL;DR: The paper presents a numerical method for approximating linearized shallow water equations using HDG methods, preserving Hamiltonian structure and energy conservation.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical scheme that maintains the Hamiltonian structure of the linearized shallow water equations, ensuring energy conservation.

Method: Proposes an auxiliary variable formulation, discretizes space with HDG methods, and uses symplectic integrators for time discretization.

Result: Achieves optimal convergence rates and demonstrates energy conservation in numerical experiments.

Conclusion: The HDG-based method effectively preserves Hamiltonian structure and energy, validated by numerical results.

Abstract: This paper focuses on the numerical approximation of the linearized shallow
water equations using hybridizable discontinuous Galerkin (HDG) methods,
leveraging the Hamiltonian structure of the evolution system. First, we propose
an equivalent formulation of the equations by introducing an auxiliary
variable. Then, we discretize the space variables using HDG methods, resulting
in a semi-discrete scheme that preserves a discrete version of the Hamiltonian
structure. The use of an alternative formulation with the auxiliary variable is
crucial for developing the HDG scheme that preserves this Hamiltonian
structure. The resulting system is subsequently discretized in time using
symplectic integrators, ensuring the energy conservation of the fully discrete
scheme. We present numerical experiments that demonstrate optimal convergence
rates for all variables and showcase the conservation of total energy, as well
as the evolution of other physical quantities.

</details>


### [3] [An efficient asymptotic preserving Monte Carlo method for frequency-dependent radiative transfer equations](https://arxiv.org/abs/2507.02392)
*Yiyang Hong,Yi Shi,Yi Cai,Tao Xiong*

Main category: math.NA

TL;DR: An efficient asymptotic-preserving Monte Carlo method for frequency-dependent radiative transfer equations is developed, combining particle-based and implicit methods for improved computational efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of solving frequency-dependent radiative transfer equations efficiently, especially in recovering correct free streaming limits and handling nonlinear coupling.

Method: A hybrid approach: particle-based MC for convective fluxes, implicit central difference for diffusive fluxes, and Picard iteration for nonlinear coupling.

Result: The method achieves high efficiency and maintains asymptotic-preserving properties, enabling larger time steps independent of light speed and frequency.

Conclusion: The proposed method effectively solves frequency-dependent RTEs with enhanced computational efficiency and accuracy, validated by numerical experiments.

Abstract: In this paper, we develop an efficient asymptotic-preserving (AP) Monte Carlo
(MC) method for frequency-dependent radiative transfer equations (RTEs), which
is based on the AP-MC method proposed for the gray RTEs in
\cite{shi2023efficient}. We follow the characteristics-based approach by Zhang
et al. \cite{zhang2023asymptotic} to get a reformulated model, which couples a
low dimension convection-diffusion-type equation for macroscopic quantities
with a high dimension transport equation for the radiative intensity.
  To recover the correct free streaming limit due to frequency-dependency, we
propose a correction to the reformulated macroscopic equation.
  The macroscopic system is solved using a hybrid method:
  convective fluxes are handled by a particle-based MC method, while diffusive
fluxes are treated implicitly with central difference.
  To address the nonlinear coupling between radiative intensity and the Planck
function across multiple frequency groups, we adopt a Picard iteration with a
predictor-corrector procedure, which decouples a global nonlinear system into a
linear system restricted to spatial dimension (independent of frequency) with
scalar algebraic nonlinear equations.
  Once the macroscopic update is done, the transport equation, with a known
emission source provided by the macroscopic variables, is efficiently solved
using an implicit MC method. This approach enables larger time steps
independent of the speed of light and also the frequency across a wide range,
significantly enhancing computational efficiency, especially for
frequency-dependent RTEs.
  Formal AP analysis in the diffusive scaling is established. Numerical
experiments are performed to demonstrate the high efficiency and AP property of
the proposed method.

</details>


### [4] [Fast reconstruction approaches for photoacoustic tomography with smoothing Sobolev/Matérn priors](https://arxiv.org/abs/2507.02401)
*Jaakko Kultima,Ronny Ramlau,Teemu Sahlström,Tanja Tarvainen*

Main category: math.NA

TL;DR: The paper connects deterministic and stochastic approaches in photoacoustic tomography (PAT) by linking Matérn covariance operators to Sobolev embeddings, proposing efficient wavelet-based implementations for adjoint operators, and validating the method with reconstructions.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between deterministic (regularization) and stochastic (Bayesian) approaches in PAT by establishing a theoretical and computational equivalence.

Method: Establishes equivalence between Matérn covariance operators and Sobolev embeddings, and introduces a wavelet-based implementation for efficient adjoint operator evaluations.

Result: Efficient computational and memory-saving implementations are achieved, validated through PAT reconstructions.

Conclusion: The proposed methods successfully unify deterministic and stochastic approaches, offering practical efficiency for PAT reconstructions.

Abstract: In photoacoustic tomography (PAT), the computation of the initial pressure
distribution within an object from its time-dependent boundary measurements
over time is considered. This problem can be approached from two
well-established points of view: deterministically using regularisation
methods, or stochastically using the Bayesian framework. Both approaches
frequently require the solution of a variational problem. In the paper we
elaborate the connection between these approaches by establishing the
equivalence between a smoothing Mat{\'e}rn class of covariance operators and
Sobolev embedding operator $E_s: H^s \hookrightarrow L^2$. We further discuss
the use of a Wavelet-based implementation of the adjoint operator $E_s^*$ which
also allows for efficient evaluations for certain Mat{\'e}rn covariance
operators, leading to efficient implementations both in terms of computational
effort as well as memory requirements. The proposed methods are validated with
reconstructions for the photoacoustic problem.

</details>


### [5] [A second-order and unconditionally stable time filtered scheme for the Cahn-Hilliard-Navier-Stokes system](https://arxiv.org/abs/2507.02402)
*Xi Li,Haijun Gao,Chunmei Xie,Minfu Feng*

Main category: math.NA

TL;DR: A novel low-complexity, second-order, energy-stable time-stepping scheme for the CHNS system is proposed using a time filter technique.


<details>
  <summary>Details</summary>
Motivation: To improve the temporal accuracy of the CHNS system discretization while maintaining energy stability.

Method: Uses a first-order backward Euler method with a time filter post-processing to achieve second-order accuracy.

Result: Unconditional energy stability and second-order temporal error estimations are proven, supported by numerical experiments.

Conclusion: The proposed scheme is effective, stable, and improves accuracy with minimal modifications to existing methods.

Abstract: In this work, we propose, analyze, and test a novel computational
low-complexity, linear, second-order, and unconditional energy-stable
semi-discrete time-stepping scheme for the Cahn-Hilliard-Navier-Stokes (CHNS)
system by employing the time filter technique. Firstly, the first-order
semi-implicit backward Euler (BE) method is utilized to discretize the CHNS
model; Secondly, the time filter, as a post-processing strategy, is
incorporated into the BE scheme, requiring only minimal modifications to the
existing BE framework to improve its temporal accuracy from first- to
second-order. The unconditional energy stability and second-order temporal
error estimations are obtained, and several numerical experiments are conducted
to verify the theoretical results.

</details>


### [6] [A modified Crank-Nicolson scheme for the Vlasov-Poisson system with a strong external magnetic field](https://arxiv.org/abs/2507.02459)
*Francis Filbet,L Miguel Rodrigues,Kim Han Trinh*

Main category: math.NA

TL;DR: A PIC method using Crank-Nicolson time discretization for the Vlasov-Poisson system with strong magnetic fields, focusing on poloidal motion, avoids stability constraints by leveraging guiding-center schemes.


<details>
  <summary>Details</summary>
Motivation: Address stability constraints in simulating particle motion under strong, inhomogeneous magnetic fields.

Method: Particle-In-Cell (PIC) method with Crank-Nicolson time discretization, incorporating guiding-center schemes for magnetic field variations.

Result: Theoretical proofs and numerical experiments validate the method's consistency and effectiveness.

Conclusion: The proposed method successfully avoids stability constraints and accurately models particle motion in strong magnetic fields.

Abstract: We propose and study a Particle-In-Cell (PIC) method based on the
Crank-Nicolson time discretization for the Vlasov-Poisson system with a strong
and inhomogeneous external magnetic field with fixed direction, where we focus
on the motion of particles in the plane orthogonal to the magnetic field
(so-called poloidal directions). In this regime, the time step can be subject
to stability constraints related to the smallness of Larmor radius and plasma
frequency [21]. To avoid this limitation, our approach is based on numerical
schemes [9, 10, 12], providing a consistent PIC discretization of the
guiding-center system taking into account variations of the magnetic field. We
carry out some theoretical proofs and perform several numerical experiments to
validate the method and its underlying concepts.

</details>


### [7] [Goal-oriented optimal sensor placement for PDE-constrained inverse problems in crisis management](https://arxiv.org/abs/2507.02500)
*Marco Mattuschka,Noah An der Lan,Max von Danwitz,Daniel Wolff,Alexander Popp*

Main category: math.NA

TL;DR: A Bayesian framework for optimal sensor placement and steering in PDE-constrained inverse problems, applied to airborne contaminant tracking for real-time crisis management.


<details>
  <summary>Details</summary>
Motivation: To enhance computational efficiency and accuracy in sensor placement and steering for complex geometries in PDE-constrained inverse problems, particularly for airborne contaminant tracking.

Method: Uses a Bayesian approach with low-rank approximations and a C-optimal design criterion for strategic sensor placement to minimize prediction uncertainty.

Result: Numerical experiments confirm the framework's effectiveness in source identification and monitoring, demonstrating computational efficiency.

Conclusion: The framework shows promise for real-time decision-making in crisis management, extending dynamic sensor steering to complex geometries.

Abstract: This paper presents a novel framework for goal-oriented optimal static sensor
placement and dynamic sensor steering in PDE-constrained inverse problems,
utilizing a Bayesian approach accelerated by low-rank approximations. The
framework is applied to airborne contaminant tracking, extending recent dynamic
sensor steering methods to complex geometries for computational efficiency. A
C-optimal design criterion is employed to strategically place sensors,
minimizing uncertainty in predictions. Numerical experiments validate the
approach's effectiveness for source identification and monitoring, highlighting
its potential for real-time decision-making in crisis management scenarios.

</details>


### [8] [On low-dimensional approximation of function spaces of interior regularity](https://arxiv.org/abs/2507.02655)
*S. Aziz,M. Bauer,M. Bebendorf,T. Rau*

Main category: math.NA

TL;DR: A new technique for constructing local approximation spaces for Lipschitz domains improves exponential convergence by extending boundary approximations, avoiding eigenvalue problems.


<details>
  <summary>Details</summary>
Motivation: To enhance the relation between dimensionality and convergence order in elliptic boundary value problems by leveraging interior regularity.

Method: Relies on extending boundary approximations instead of eigenvalue problems, solving variational problems on simpler domains.

Result: Improved exponential convergence influenced by spatial dimension, with easier construction of local spaces.

Conclusion: The technique offers a more efficient and practical approach for constructing local approximation spaces in generalized finite element methods.

Abstract: Many elliptic boundary value problems exhibit an interior regularity
property, which can be exploited to construct local approximation spaces that
converge exponentially within function spaces satisfying this property. These
spaces can be used to define local ansatz spaces within the framework of
generalised finite element methods, leading to a better relation between
dimensionality and convergence order. In this paper, we present a new technique
for the construction of such spaces for Lipschitz domains. Instead of the
commonly used approach based on eigenvalue problems it relies on extensions of
approximations performed on the boundary. Hence, it improves the influence of
the spatial dimension on the exponential convergence and allows to construct
the local spaces by solving the original kind of variational problems on easily
structured domains.

</details>


### [9] [High order uniform in time schemes for weakly nonlinear Schrödinger equation and wave turbulence](https://arxiv.org/abs/2507.02662)
*Quentin Chauleur,Antoine Mouzard*

Main category: math.NA

TL;DR: Two high-order multiscale schemes for weakly nonlinear Schrödinger equations are introduced, achieving precision under CFL conditions and uniform accuracy over long times.


<details>
  <summary>Details</summary>
Motivation: To develop efficient numerical methods for weakly nonlinear Schrödinger equations, addressing precision and long-term accuracy.

Method: Discretization of Picard iterates, exploiting scattering properties with low-frequency projected linear flow.

Result: High precision under CFL conditions and uniform accuracy over long times, validated by simulations.

Conclusion: The schemes are effective for weakly nonlinear Schrödinger equations and applicable to wave turbulence dynamics.

Abstract: We introduce two multiscale numerical schemes for the time integration of
weakly nonlinear Schr\"odinger equations, built upon the discretization of
Picard iterates of the solution. These high-order schemes are designed to
achieve high precision with respect to the small nonlinearity parameter under
particular CFL condition. By exploiting the scattering properties of these
schemes thanks to a low-frequency projected linear flow, we also establish its
uniform accuracy over long time horizons. Numerical simulations are provided to
illustrate the theoretical results, and these schemes are further applied to
investigate dynamics in the framework of wave turbulence.

</details>


### [10] [Moments, Time-Inversion and Source Identification for the Heat Equation](https://arxiv.org/abs/2507.02677)
*Kang Liu,Enrique Zuazua*

Main category: math.NA

TL;DR: A novel moment-based approach for solving the ill-posed inverse problem of initial source identification in the heat equation, reducing exponential error growth to polynomial growth.


<details>
  <summary>Details</summary>
Motivation: The heat equation's initial source identification is highly unstable, and classical methods like Tikhonov regularization are insufficient. A more stable and accurate solution is needed.

Method: Transform the problem into an inverse moment formulation, evolve terminal time moments backward via ODEs, and reconstruct the source using convex optimization with total variation minimization.

Result: The method reduces error growth from exponential to polynomial, provides explicit error estimates, and yields sparse, atomic solutions. Numerical experiments confirm improved stability.

Conclusion: The moment-based approach offers a stable and efficient solution for the heat equation's inverse problem, with significant improvements over existing methods.

Abstract: We address the initial source identification problem for the heat equation, a
notably ill-posed inverse problem characterized by exponential instability.
Departing from classical Tikhonov regularization, we propose a novel approach
based on moment analysis of the heat flow, transforming the problem into a more
stable inverse moment formulation. By evolving the measured terminal time
moments backward through their governing ODE system, we recover the moments of
the initial distribution. We then reconstruct the source by solving a convex
optimization problem that minimizes the total variation of a measure subject to
these moment constraints. This formulation naturally promotes sparsity,
yielding atomic solutions that are sums of Dirac measures. Compared to existing
methods, our moment-based approach reduces exponential error growth to
polynomial growth with respect to the terminal time. We provide explicit error
estimates on the recovered initial distributions in terms of moment order,
terminal time, and measurement errors. In addition, we develop efficient
numerical discretization schemes and demonstrate significant stability
improvements of our approach through comprehensive numerical experiments.

</details>


### [11] [A $\mathcal{CR}$-rotated $Q_1$ nonconforming finite element method for Stokes interface problems on local anisotropic fitted mixed meshes](https://arxiv.org/abs/2507.02741)
*Geng Chenchen,Hua Wang,Fengren Zou*

Main category: math.NA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a new nonconforming finite element method for solving Stokes
interface problems. The method is constructed on local anisotropic mixed
meshes, which are generated by fitting the interface through simple connection
of intersection points on an interface-unfitted background mesh, as introduced
in \cite{Hu2021optimal}. For triangular elements, we employ the standard
$\mathcal{CR}$ element; for quadrilateral elements, a new rotated $Q_1$-type
element is used. We prove that this rotated $Q_1$ element remains unisolvent
and stable even on degenerate quadrilateral elements. Based on these
properties, we further show that the space pair of $\mathcal{CR}$-rotated $Q_1$
elements (for velocity) and piecewise $P_0$ spaces (for pressure) satisfies the
inf-sup condition without requiring any stabilization terms. As established in
our previous work \cite{Wang2025nonconforming}, the consistency error achieves
the optimal convergence order without the need for penalty terms to control it.
Finally, several numerical examples are provided to verify our theoretical
results.

</details>


### [12] [Uniform semiclassical observable error bound of Trotterization without the Egorov theorem: a simple algebraic proof](https://arxiv.org/abs/2507.02783)
*Di Fang,Conrad Qu*

Main category: math.NA

TL;DR: The paper presents a new algebraic proof for uniform-in-$h$ error bounds in high-order Trotterization schemes for semiclassical Schrödinger equation simulations, avoiding heavy semiclassical machinery.


<details>
  <summary>Details</summary>
Motivation: Efficient simulation of the semiclassical Schrödinger equation is challenging, especially in controlling errors for observables without shrinking time steps as $h$ decreases.

Method: The authors characterize observables with uniform-in-$h$ error bounds and provide a simple algebraic proof for high-order Trotterization, relying on operator algebra.

Result: They achieve uniform-in-$h$ error bounds for observables, bypassing traditional semiclassical tools like Egorov-type theorems.

Conclusion: This work offers a novel, algebraically grounded proof for Trotterization error bounds in the semiclassical regime, simplifying previous approaches.

Abstract: Efficient simulation of the semiclassical Schr\"odinger equation has garnered
significant attention in the numerical analysis community. While controlling
the error in the unitary evolution or the wavefunction typically requires the
time step size to shrink as the semiclassical parameter $h$ decreases, it has
been observed -- and proved for first- and second-order Trotterization schemes
-- that the error in certain classes of observables admits a time step size
independent of $h$. In this work, we explicitly characterize this class of
observables and present a new, simple algebraic proof of uniform-in-$h$ error
bounds for arbitrarily high-order Trotterization schemes. Our proof relies
solely on the algebraic structure of the underlying operators in both the
continuous and discrete settings. Unlike previous analyses, it avoids
Egorov-type theorems and bypasses heavy semiclassical machinery. To our
knowledge, this is the first proof of uniform-in-$h$ observable error bounds
for Trotterization in the semiclassical regime that relies only on algebraic
structure, without invoking the semiclassical limit.

</details>


### [13] [Block triangular preconditioning for inverse source problems in time-space fractional diffusion equations](https://arxiv.org/abs/2507.02809)
*Monoswini Majumdar,Stefano Serra-Capizzano,Rosita L. Sormani*

Main category: math.NA

TL;DR: Block triangular preconditioners improve convergence and stability in solving inverse source problems for time-space fractional diffusion equations.


<details>
  <summary>Details</summary>
Motivation: To address the ill-posedness and computational challenges in recovering unknown spatial sources in multi-dimensional fractional diffusion equations.

Method: Quasi-boundary value regularization, finite difference discretization, and block triangular preconditioning for structured linear systems.

Result: The preconditioner enhances GMRES solver performance, improving convergence, robustness, and accuracy.

Conclusion: The proposed method is effective for large-scale inverse problems in fractional modeling.

Abstract: The current work investigates the effectiveness of block triangular
preconditioners in accelerating and stabilizing the numerical solution of
inverse source problems governed by time-space fractional diffusion equations
(TSFDEs). We focus on the recovery of an unknown spatial source function in a
multi-dimensional TSFDE, incorporating Caputo time-fractional derivatives and
the fractional Laplacian. The inherent ill-posedness is addressed via a
quasi-boundary value regularization, followed by a finite difference
discretization that leads to large, structured linear systems. We develop and
analyze a block triangular preconditioning strategy that mimics the coefficient
matrix, while simplifying its structure for computational efficiency. Numerical
experiments using the GMRES solver demonstrate that the proposed preconditioner
significantly improve convergence rates, robustness, and accuracy, making it
well-suited for large-scale, real-world inverse problems involving fractional
modeling.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [14] [Composite media, almost touching disks and the maximum principle](https://arxiv.org/abs/2507.02077)
*YanYan Li,Ben Weinkove*

Main category: math.AP

TL;DR: A new proof of a gradient bound for two almost-touching disks with finite conductivities in ℝ², using the maximum principle.


<details>
  <summary>Details</summary>
Motivation: To address the problem of gradient bounds in divergence form elliptic equations with discontinuous coefficients, specifically for two nearly touching disks.

Method: Utilizes the maximum principle to derive the gradient bound.

Result: Provides a new proof for the gradient bound established by Li-Vogelius.

Conclusion: The maximum principle offers an effective approach for proving gradient bounds in such settings.

Abstract: We consider the setting of two disks in a domain in $\mathbb{R}^2$ which are
almost touching and have finite and positive conductivities, giving rise to a
divergence form elliptic equation with discontinuous coefficients. We use the
maximum principle to give a new proof of a gradient bound of Li-Vogelius.

</details>


### [15] [Tools for stability analysis of fractional reaction diffusion systems](https://arxiv.org/abs/2507.02094)
*Sofwah Ahmad,Szymon Cygan,Grzegorz Karch*

Main category: math.AP

TL;DR: The paper proves the linearization principle for fractional reaction-diffusion equations with time-fractional derivatives and applies it to derive results like the fractional Turing instability.


<details>
  <summary>Details</summary>
Motivation: To extend the linearization principle to fractional reaction-diffusion equations, bridging classical and fractional stability analysis.

Method: Abstract analysis of fractional reaction-diffusion equations with time-fractional derivatives, followed by application to specific cases.

Result: Proof of the linearization principle for fractional equations and derivation of fractional Turing instability.

Conclusion: The work successfully generalizes classical stability results to fractional settings, providing new insights into fractional reaction-diffusion dynamics.

Abstract: The linearization principle states that the stability (or instability) of
solutions to a suitable linearization of a nonlinear problem implies the
stability (or instability) of solutions to the original nonlinear problem. In
this work, we prove this principle for solutions of abstract fractional
reaction-diffusion equations with a fractional derivative in time of order
$\alpha\in (0,1)$. Then, we apply these results to particular fractional
reaction-diffusion equations, obtaining, for example, the counterpart of the
classical Turing instability in the case of fractional equations.

</details>


### [16] [Global existence of the solution of the modified Camassa-Holm equation with step-like boundary conditions](https://arxiv.org/abs/2507.02100)
*I. Karpenko,D. Shepelsky,G. Teschl*

Main category: math.AP

TL;DR: The paper studies the global existence of solutions for the modified Camassa-Holm equation with step-like initial data.


<details>
  <summary>Details</summary>
Motivation: To address the Cauchy problem for the modified Camassa-Holm equation and ensure global solution existence under specific initial conditions.

Method: Analyzes the equation with step-like initial data (u(x,0) approaching A1 as x→−∞ and A2 as x→+∞, where 0<A1<A2).

Result: Aims to establish the global existence of the solution for the given problem.

Conclusion: The work contributes to understanding the behavior of solutions for the modified Camassa-Holm equation under step-like initial conditions.

Abstract: We consider the Cauchy problem for
  the modified Camassa-Holm equation
  \[
  u_t+\left((u^2-u_x^2)m\right)_x=0,\quad
  m\coloneqq u-u_{xx},
  \quad t>0,\ \ -\infty<x<+\infty
  \]
  subject to the step-like initial data: $u(x,0)\to A_1$ as $x\to-\infty$ and
$u(x,0)\to A_2$ as $x\to+\infty$, where $0<A_1<A_2$.
  The goal is to
  establish the global existence of the solution of this problem.

</details>


### [17] [Traveling Wave Solutions to a Large Class of Brenner-Navier-Stokes-Fourier Systems](https://arxiv.org/abs/2507.02224)
*Saehoon Eo,Namhyun Eun*

Main category: math.AP

TL;DR: The paper analyzes the one-dimensional BNSF system with temperature-dependent transport coefficients, proving existence and uniqueness of monotone traveling wave solutions for small shock amplitudes using geometric singular perturbation theory and the implicit function theorem.


<details>
  <summary>Details</summary>
Motivation: Address deficiencies in the classical Navier-Stokes-Fourier system by introducing the BNSF system, focusing on physically realistic temperature-dependent transport coefficients.

Method: Utilize geometric singular perturbation theory and the implicit function theorem to analyze the BNSF system in Lagrangian mass coordinates.

Result: Existence and uniqueness of monotone traveling wave solutions (viscous shocks) for sufficiently small shock amplitudes.

Conclusion: The work provides robust quantitative estimates for traveling wave solutions, supporting broader analysis of the BNSF system.

Abstract: The Brenner-Navier-Stokes-Fourier (BNSF) system, introduced by Howard
Brenner, was developed to address some deficiencies in the classical
Navier-Stokes-Fourier system, based on the concept of volume velocity. We
consider the one-dimensional BNSF system in Lagrangian mass coordinates,
incorporating temperature-dependent transport coefficients, which yields a more
physically realistic framework. We establish the existence and uniqueness of
monotone traveling wave solutions (or viscous shocks) to the BNSF system with
any positive $C^2$ dissipation coefficients, provided that the shock amplitude
is sufficiently small. We utilize geometric singular perturbation theory as in
the constant coefficient case [13]; however, due to the arbitrary
nonlinearities of the coefficients, we employ the implicit function theorem,
which grants robustness to our approach. This work is motivated by [12], which
proves a contraction property of any large solutions to the BNSF system around
the traveling wave solutions. Thus, we also derive some quantitative estimates
on the traveling wave solutions that play a fundamental role in [12].

</details>


### [18] [Analysis and Numerical Approximation to Interactive Dynamics of Navier Stokes-Plate Interaction PDE System](https://arxiv.org/abs/2507.02230)
*Pelin G. Geredeli,Quyuan Lin,Dylan Mcknight,Mohammad Mahabubur Rahman*

Main category: math.AP

TL;DR: The paper analyzes a fluid-plate interaction system, proving well-posedness of weak solutions and providing a FEM-based numerical approximation with error bounds.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by applications in aeroelasticity, biomedical fields, and control of ocular pressure, addressing the need for theoretical and numerical solutions.

Method: Theoretical analysis uses a variational formulation and inf-sup approach for existence-uniqueness. Numerically, a FEM scheme with Picard iterations is employed.

Result: Existence-uniqueness of solutions is proven under small data. FEM results validate theory with error bounds in Sobolev norms.

Conclusion: The work successfully combines theoretical and numerical approaches, validating the model's feasibility and accuracy.

Abstract: We consider a Navier-Stokes fluid-plate interaction (FSI) system which
describes the evolutions of the fluid contained within a 3D cavity, as it
interacts with a deformable elastic membrane on the ``free" upper boundary of
the cavity. These models arise in various aeroelastic and biomedical
applications as well as in the control of ocular pressure, and sloshing
phenomena. We analyze the well-posedness of weak solutions to the stationary
($\lambda$-parametrized) coupled PDE system by way of invoking the nonlinear
generalization of the abstract variational formulations which was introduced in
\cite{girault2012finite}, wherein an inf-sup approach is followed to show
existence-uniqueness of solutions under a small data assumption.
  In addition, we provide a numerical approximation scheme of the infinite
dimensional coupled system via a finite element method approximation (FEM). The
numerical results use a standard conforming scheme and handle the introduced
nonlinearities via Picard iterations. Numerical results are obtained for an
appropriate test problem satisfying the necessary boundary conditions and
coupling. Moreover, error bounds between the FEM and theoretical solution in
terms of the characteristic mesh size are supplied in appropriate Sobolev norms
which agree with the established literature. These FEM approximations of the
coupled system with their associated error bounds validate the theoretical
findings.

</details>


### [19] [Ill-posedness of the Euler equations and inviscid limit of the Navie-Stokes equations in Besov spaces](https://arxiv.org/abs/2507.02247)
*Jinlu Li,Xing Wu,Yanghai Yu*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we consider the Cauchy problem to the incompressible Euler and
Navie-Stokes equations on the d-dimensional torus.Our aim of this paper is two
fold. Firstly, we construct a new initial data and present a simple proof of
the ill-posedness of the Euler equations in different senses: (1) the solution
map of the Euler equations starting from $u_0$ is discontinuous at $t = 0$ in
$B^s_{p,\infty}$ with $s>0$ and $1\leq p \leq \infty$, which covers the result
obtained by Cheskidov and Shvydkoy in ;(2) the solution map of the Euler
equations is not continuous as a map from $B^s_{p,\infty}$ to
$L^\infty_T(B^s_{p,\infty})$;(3) the solution map of the Euler equations cannot
be Holder continuous in time variable in Besov spaces $B^s_{p,r}$.

</details>


### [20] [Trapping by repulsion: the NLS with a delta-prime](https://arxiv.org/abs/2507.02330)
*Riccardo Adami,Filippo Boni,Matteo Gallone*

Main category: math.AP

TL;DR: The paper proves the existence and provides explicit forms of stationary states for a 1D Schrödinger equation with a repulsive delta-prime potential and focusing nonlinearity. Ground states exist for subcritical nonlinearity, any interaction strength, and positive mass, explained by an emergent energy space dimension.


<details>
  <summary>Details</summary>
Motivation: To explore counterintuitive ground states in repulsive potentials and understand their origin via an additional energy dimension induced by delta-prime interaction.

Method: Derives explicit ground states by minimizing the action functional on the Nehari manifold, addressing subcritical, critical, and supercritical regimes.

Result: Ground states exist for subcritical nonlinearity, any delta-prime strength, and positive mass, with explicit forms provided.

Conclusion: The delta-prime interaction induces a new energy dimension enabling ground states in repulsive potentials, a phenomenon not originating from linear eigenfunctions.

Abstract: We establish the existence and provide explicit expressions for the
stationary states of the one-dimensional Schr\"odinger equation with a
repulsive delta-prime potential and a focusing nonlinearity of power type.
Furthermore, we prove that, if the nonlinearity is subcritical, then ground
states exist for any strength of the delta-prime interaction and for every
positive value of the mass.
  This result supplies an example of ground states arising from a repulsive
potential, a counterintuitive phenomenon explained by the emergence of an
additional dimension in the energy space, induced by the delta-prime
interaction. This new dimension contains states of lower energy and is thus
responsible for the existence of nonlinear ground states that do not originate
from linear eigenfunctions.
  The explicit form of the ground states is derived by addressing the ancillary
problem of minimizing the action functional on the Nehari manifold. We solve
such problem in the subcritical, critical, and supercritical regimes.

</details>


### [21] [Self-similar vorticity around the boundary and non-uniqueness of solutions to the two-dimensional Navier-Stokes equations in the half space](https://arxiv.org/abs/2507.02338)
*Motofumi Aoki,Yasunori Maekawa*

Main category: math.AP

TL;DR: The paper demonstrates non-unique mild solutions for 2D forced Navier-Stokes equations in half-space under no-slip boundary conditions, leveraging instability of self-similar vorticity near the boundary.


<details>
  <summary>Details</summary>
Motivation: To extend the work of Albritton, Brué, and Colombo (2022) by addressing non-uniqueness in solutions, particularly focusing on boundary-layer effects.

Method: Constructs non-unique solutions by analyzing instability of self-similar vorticity near the boundary at high Reynolds numbers.

Result: Shows non-uniqueness of solutions, contrasting prior results where vorticity was away from the boundary.

Conclusion: Highlights the role of boundary-layer dynamics in solution non-uniqueness, expanding understanding of Navier-Stokes behavior in constrained geometries.

Abstract: In this paper we show the non-uniqueness of mild solutions to the
two-dimensional forced Navier-Stokes equations in the half space under the
noslip boundary condition, following the program established by Albritton,
Bru{\'e}, and Colombo in 2022. Our construction of non-unique solutions is
based on the instability of self-similar vorticity at high Reynolds numbers
which concentrates around the boundary at the initial time. In our
construction, therefore, a kind of boundary layer has to be taken into account
in the analysis, contrasting to the known results where the unstable
self-similar vorticity is located away from the boundary with $O(1)$ distance
around the initial time.

</details>


### [22] [A field-road system with a rectifiable set](https://arxiv.org/abs/2507.02451)
*Matthieu Bonnivard,Romain Ducasse,Antoine Lemenant,Alessandro Zilio*

Main category: math.AP

TL;DR: The paper defines a 2D field-road system with a 1D-rectifiable road, introducing a framework for coupled parabolic problems on and off the road with transmission conditions.


<details>
  <summary>Details</summary>
Motivation: To model and analyze systems where a 1D road interacts with a surrounding 2D field, requiring coupled parabolic problems.

Method: Introduces a general setting for defining parabolic problems on a rectifiable set (road) coupled with classical parabolic problems outside it, including transmission conditions.

Result: A framework for analyzing such coupled systems is established.

Conclusion: The proposed setting provides a foundation for studying field-road systems with rectifiable roads and transmission conditions.

Abstract: The aim of this paper is to define a field-road system in 2D where the road
is a merely 1D-rectifiable set. For this purpose we introduce a general setting
in order to define a parabolic problem onto a rectifiable set, which is coupled
with another more classical parabolic problem outside this set, with
transmission conditions.

</details>


### [23] [Global Existence and Incompressible Limit for Compressible Navier-Stokes Equations in Bounded Domains with Large Bulk Viscosity Coefficient and Large Initial Data](https://arxiv.org/abs/2507.02462)
*Qinghao Lei,Chengfeng Xiong*

Main category: math.AP

TL;DR: Global existence and exponential decay of solutions for compressible Navier-Stokes equations with large bulk viscosity, converging to incompressible solutions as viscosity tends to infinity.


<details>
  <summary>Details</summary>
Motivation: To study the behavior of compressible Navier-Stokes equations with Navier-slip boundary conditions, especially for vanishing initial density, and understand the transition to incompressible solutions.

Method: Uses logarithmic interpolation inequality and compensated compactness lemma to analyze solutions in a 2D bounded domain.

Result: Proves global existence and exponential decay of weak, strong, and classical solutions without initial data size restrictions. Shows convergence to incompressible solutions as bulk viscosity increases.

Conclusion: Large bulk viscosity ensures stability and convergence to incompressible Navier-Stokes solutions, highlighting the role of viscosity in fluid dynamics.

Abstract: We investigate the barotropic compressible Navier-Stokes equations with the
Navier-slip boundary conditions in a general two-dimensional bounded simply
connected domain. For initial density that is allowed to vanish, we establish
the global existence and exponential decay of weak, strong, and classical
solutions when the bulk viscosity coefficient is suitably large, without any
restrictions on the size of the initial data. Furthermore, we prove that when
the bulk viscosity coefficient tends to infinity, the solutions of the
compressible Navier-Stokes equations converge to those of the inhomogeneous
incompressible Navier-Stokes equations. The key idea is to utilize the
logarithmic interpolation inequality on general bounded domains and apply the
compensated compactness lemma.

</details>


### [24] [Renormalized variational principles and Hardy-type inequalities](https://arxiv.org/abs/2507.02486)
*Satyanad Kichenassamy*

Main category: math.AP

TL;DR: The paper extends Hardy's and Trudinger's inequalities, proving integrability conditions for functions in Sobolev spaces and providing a variational characterization of the maximal solution of the Liouville equation.


<details>
  <summary>Details</summary>
Motivation: To generalize Hardy's inequality and connect it with Trudinger's inequality, while exploring applications to the Liouville equation.

Method: The authors use Sobolev space theory and variational methods to analyze integrability and derive bounds for solutions.

Result: They show integrability of a specific functional and provide a global $H^1$ bound for the maximal solution of the Liouville equation.

Conclusion: The results unify Hardy's and Trudinger's inequalities and offer new insights into the Liouville equation's solutions.

Abstract: Let $\Omega\subset{\mathbb R}^2$ be a bounded domain on which Hardy's
inequality holds. We prove that $[\exp(u^2)-1]/\delta^2\in L^1(\Omega)$ if
$u\in H^1_0(\Omega)$, where $\delta$ denotes the distance to $\partial\Omega$.
The corresponding higher-dimensional result is also given. These results
contain both Hardy's and Trudinger's inequalities, and yield a new variational
characterization of the maximal solution of the Liouville equation on smooth
domains, in terms of a renormalized functional. A global $H^1$ bound on the
difference between the maximal solution and the first term of its asymptotic
expansion follows.

</details>


### [25] [Long-time Existence and Incompressible Limit of Weak and Classical Solutions to the Cauchy Problem for Compressible Navier-Stokes Equations with Large Bulk Viscosity Coefficient and Large Initial Data](https://arxiv.org/abs/2507.02497)
*Qinghao Lei,Chengfeng Xiong*

Main category: math.AP

TL;DR: The paper studies the Cauchy problem for barotropic compressible Navier-Stokes equations in 2D, establishing long-time existence of solutions and their convergence to incompressible limits as bulk viscosity grows.


<details>
  <summary>Details</summary>
Motivation: To address the Cauchy problem for compressible Navier-Stokes equations with vacuum or nonvacuum far fields, overcoming challenges like the failure of Poincaré's inequality.

Method: Uses a sufficiently large bulk viscosity coefficient and introduces a time-dependent Poincaré-type inequality with weighted initial density conditions.

Result: Proves long-time existence of weak, strong, and classical solutions without initial velocity divergence restrictions and shows convergence to incompressible limits.

Conclusion: The approach resolves key obstacles and generalizes results, even for non-divergence-free initial velocities.

Abstract: This paper investigates the Cauchy problem for the barotropic compressible
Navier-Stokes equations in $\mathbb{R}^2$ with the constant state as far field,
which could be vacuum or nonvacuum. Under the assumption of a sufficiently
large bulk viscosity coefficient, we establish the long-time existence of weak,
strong, and classical solutions, without imposing any extra restrictions on the
initial velocity divergence. Moreover, we demonstrate that the solutions of the
compressible Navier-Stokes equations converge to solutions of the inhomogeneous
incompressible Navier-Stokes equations, as the bulk viscosity coefficient tends
to infinity. The incompressible limit of the weak solutions holds even without
requiring the initial velocity to be divergence-free. The key obstacle in the
Cauchy problem is the failure of the Poincar\'e's inequality. This could be
resolved by introducing a time-dependent Poincar\'e's type inequality, but it
needs imposing weighted-integrability conditions on the initial density.

</details>


### [26] [Sharp second order inequalities with distance function to the boundary and applications to a p-Biharmonic singular problem](https://arxiv.org/abs/2507.02551)
*Cristian Cazacu,Teodor Rugină*

Main category: math.AP

TL;DR: Generalizations of Hardy-Rellich inequalities in L^p for domains with boundary singularities, providing sharp bounds and applications to variational problems.


<details>
  <summary>Details</summary>
Motivation: Extend Hardy-Rellich inequalities to L^p settings and explore their implications for singular problems.

Method: Prove inequalities using distance-to-boundary singularity, analyze sharp constants, and apply variational methods with Pohozaev identity.

Result: Sharp inequalities in bounded domains, new bounds for sharp constants, and applications to solution existence/non-existence.

Conclusion: Generalized inequalities are effective, with geometric dependence and practical applications in variational problems.

Abstract: In this paper, we prove generalizations to the L^p setting of the
Hardy-Rellich inequalities on domains of R^N with singularity given by the
distance function to the boundary. The inequalities we obtain are either sharp
in bounded domains, where we provide concrete minimizing sequences, or give a
new bound for the sharp constant, while also depending on the geometric
properties of the domain and its boundary. We also give applications to the
existence and non-existence of solutions for a singular problem using
variational methods and a Pohozaev identity.

</details>


### [27] [Homogenisation and spectral convergence of high-contrast convolution type operators](https://arxiv.org/abs/2507.02638)
*Mikhail Cherdantsev,Andrey Piatnitski,Igor Velcic*

Main category: math.AP

TL;DR: The paper studies homogenization of high-contrast convolution-type operators in periodic microstructures, using two-scale convergence for spectral analysis.


<details>
  <summary>Details</summary>
Motivation: To analyze homogenization and spectral behavior of nonlocal operators in periodic microstructures.

Method: Adapts two-scale convergence for convolution-type operators, analyzing problems in whole space and bounded domains with Dirichlet conditions.

Result: The limit operator's spectrum is a subset of the original's spectrum but may not coincide.

Conclusion: The homogenization method effectively captures spectral behavior, though the limit and original spectra may differ.

Abstract: The paper deals with homogenisation problems for high-contrast symmetric
convolution-type operators with integrable kernels in media with a periodic
microstructure. We adapt the two-scale convergence method to nonlocal
convolution-type operators and obtain the homogenisation result both for
problems stated in the whole space and in bounded domains with the homogeneous
Dirichlet boundary condition.
  Our main focus is on spectral analysis. We describe the spectrum of the limit
two-scale operator and characterize the limit behaviour of the spectrum of the
original problem as the microstructure period tends to zero. It is shown that
the spectrum of the limit operator is a subset the limit of the spectrum of the
original operator, and that they need not coincide.

</details>


### [28] [On the two-dimensional Navier-Stokes equations with horizontal viscosity](https://arxiv.org/abs/2507.02775)
*Chongsheng Cao,Yanqiu Guo*

Main category: math.AP

TL;DR: Analysis of a 2D channel flow with horizontal viscosity, focusing on well-posedness, long-term behavior, and stability under minimal initial differentiability.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of a 2D channel flow with horizontal viscosity and reduced initial smoothness assumptions.

Method: Study well-posedness, large-time behavior, and stability of solutions, assuming initial velocity components in $L^2(\Omega)$ and partial derivative in $L^2(\Omega)$.

Result: Demonstrates global well-posedness and analyzes stability under minimal initial differentiability conditions.

Conclusion: The paper provides insights into the behavior of 2D channel flows with horizontal viscosity, even with less smooth initial data.

Abstract: This paper is concerned with a 2D channel flow that is periodic horizontally
but bounded above and below by hard walls. We assume the presence of horizontal
viscosity only. We study the well-posedness, large-time behavior, and stability
of solutions. For global well-posedness, we aim to assume less
differentiability on initial velocity $(u_0, v_0)$: in particular, we assume
$u_0,v_0\in L^2(\Omega)$ and $\partial_y u_0 \in L^2(\Omega)$.

</details>


### [29] [Vanishing Vertical Viscosity in Two-Dimensional Anisotropic Navier-Stokes Equations with No-Slip Boundary Conditions: An $L^p$ result](https://arxiv.org/abs/2507.02794)
*Chongsheng Cao,Yanqiu Guo*

Main category: math.AP

TL;DR: Study of inviscid limit for 2D Navier-Stokes with anisotropic viscosity, focusing on convergence to the limiting problem as vertical viscosity vanishes.


<details>
  <summary>Details</summary>
Motivation: To address the inviscid limit problem in 2D Navier-Stokes equations with anisotropic viscosity, particularly the boundary condition mismatch (no-slip vs. slip).

Method: Analyze the problem with $H^2$ initial velocity, proving strong $L^p$ norm convergence for $2\leq p <\infty$ as vertical viscosity approaches zero.

Result: Strong convergence in $L^p$ norm to the limiting problem is established for vanishing vertical viscosity.

Conclusion: The paper successfully resolves the boundary condition mismatch issue, proving convergence under the given conditions.

Abstract: This paper studies the inviscid limit problem for the two-dimensional
Navier-Stokes equations with anisotropic viscosity. The fluid is assumed to be
bounded above and below by impenetrable walls, with a no-slip boundary
condition imposed on the bottom wall. For $H^2$ initial velocity, we establish
strong convergence in the $L^p$ norm to the limiting problem as the vertical
viscosity approaches zero, for any $2\leq p <\infty$. The main challenge lies
in the mismatch of boundary conditions - specifically, the no-slip condition in
the original problem versus the slip condition in the limiting problem.

</details>


### [30] [On the Boundary Harnack Principle for operators with different lower order terms](https://arxiv.org/abs/2507.02836)
*Daniela De Silva,Ovidiu Savin*

Main category: math.AP

TL;DR: Classical Boundary Harnack principle for solutions to two linear uniformly elliptic equations with identical principal parts in Lipschitz domains.


<details>
  <summary>Details</summary>
Motivation: To extend the Boundary Harnack principle to cases involving two distinct linear uniformly elliptic equations sharing the same principal part.

Method: Analysis of solutions in Lipschitz domains, focusing on the common principal part of the equations.

Result: Demonstrates the applicability of the Boundary Harnack principle under the specified conditions.

Conclusion: The principle holds for solutions to such equations, generalizing its scope.

Abstract: We provide the classical Boundary Harnack principle in Lipschitz domains for
solutions to two different linear uniformly elliptic equations with the same
principal part.

</details>


### [31] [Free boundary regularity for a tumor growth model with obstacle](https://arxiv.org/abs/2507.02837)
*Giulia Bevilacqua,Matteo Carducci*

Main category: math.AP

TL;DR: Existence and regularity theory for solutions to a geometric free boundary problem in tumor growth models, involving obstacles and viscosity solutions.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by tumor growth models where the tumor invades a region but is obstructed by another region, requiring analysis of free boundary behavior.

Method: Existence of viscosity solutions is shown via Perron's method. Interior regularity is proven using an improvement of flatness argument. Boundary regularity is analyzed, showing the free boundary meets the obstacle as a C¹,α graph.

Result: Existence and interior regularity of solutions are established. The free boundary meets the obstacle smoothly (C¹,α).

Conclusion: The paper provides a comprehensive theory for existence and regularity in a geometric free boundary problem, with applications to tumor growth modeling.

Abstract: We develop an existence and regularity theory for solutions to a geometric
free boundary problem motivated by models of tumor growth. In this setting, the
tumor invades an accessible region $D$, its motion is directed along a constant
vector $V$, and it cannot penetrate another region $K$ acting as an obstacle to
the spread of the tumor. Due to the non variational structure of the problem,
we show existence of viscosity solutions via Perron's method. Subsequently, we
prove interior regularity for the free boundary near regular points by means of
an improvement of flatness argument. We further analyze the boundary regularity
and we prove that the free boundary meets the obstacle as a $C^{1,\alpha}$
graph. A key step in the analysis of the boundary regularity involves the study
of a thin obstacle problem with oblique boundary conditions, for which we
establish $C^{1,\alpha}$ estimates.

</details>


### [32] [Diffeomorphic approximation of piecewise affine homeomorphisms](https://arxiv.org/abs/2507.02854)
*Daniel Campbell,Luigi D'Onofrio,Tomáš Vítek*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Given any $f$ a locally finitely piecewise affine homeomorphism of $\Omega
\subset \mathbb{R}^d$ onto $\Delta \subset \mathbb{R}^d$ (for $d=3, 4$) such
that $f\in W^{1,p}(\Omega, \mathbb{R}^d)$ and $f^{-1}\in W^{1,q}(\Delta,
\mathbb{R}^d)$, $1\leq p ,q < \infty$ and any $\epsilon >0$ we construct a
diffeomorphism $\tilde{f}$ such that
  $$\|f-\tilde{f}\|_{W^{1,p}(\Omega,\mathbb{R}^d)} +
\|f^{-1}-\tilde{f}^{-1}\|_{W^{1,q}(\Delta,\mathbb{R}^d)} < \epsilon.$$

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [33] [A Multi-Level Monte Carlo Tree Search Method for Configuration Generation in Crystalline Systems](https://arxiv.org/abs/2507.02509)
*Xiaoxu Li,Ge Xu,Huajie Chen,Xingyu Gao,Haifeng Song*

Main category: physics.comp-ph

TL;DR: A multi-level Monte Carlo tree search algorithm is developed to efficiently identify optimal atomic configurations in crystalline materials with substitutional defects.


<details>
  <summary>Details</summary>
Motivation: Predicting and designing atomic structures in crystalline materials with substitutional defects is challenging due to combinatorial growth and rugged energy landscapes.

Method: A multi-level Monte Carlo tree search algorithm is used, incorporating hierarchical decomposition of the crystalline structure for accelerated exploration and reduced redundancy.

Result: Numerical experiments demonstrate the method's efficiency in identifying optimal configurations in typical crystalline systems.

Conclusion: The proposed algorithm effectively addresses the challenges of exploring configuration spaces in crystalline materials with substitutional defects.

Abstract: In this paper, we study the construction of structural models for the
description of substitutional defects in crystalline materials. Predicting and
designing the atomic structures in such systems is highly challenging due to
the combinatorial growth of atomic arrangements and the ruggedness of the
associated landscape. We develop a multi-level Monte Carlo tree search
algorithm to generate the "optimal" configuration within a supercell. Our
method explores the configuration space with an expanding search tree through
random sampling, which further incorporates a hierarchical decomposition of the
crystalline structure to accelerate exploration and reduce redundancy. We
perform numerical experiments on some typical crystalline systems to
demonstrate the efficiency of our method in identifying optimal configurations.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [34] [Impact of super-Gaussian electron distributions on plasma K-shell emission](https://arxiv.org/abs/2507.02341)
*H. P. Le,E. V. Marley,H. A. Scott*

Main category: physics.plasm-ph

TL;DR: Super-Gaussian electron distributions in laser-produced plasmas alter K-shell emission, enabling their detection via spectroscopy.


<details>
  <summary>Details</summary>
Motivation: To understand how super-Gaussian electron distributions affect plasma ionization and K-shell emission.

Method: Combines approximate formulas and collisional-radiative simulations.

Result: Small impact on ionization but significant changes in K-shell spectra.

Conclusion: K-shell spectroscopy can identify super-Gaussian or non-equilibrium electron distributions.

Abstract: Electron distributions in laser-produced plasmas will be driven toward a
super-Gaussian distribution due to inverse bremsstrahlung absorption [Langdon,
Phys. Rev. Lett. 44, 575 (1980)]. Both theoretical and experimental evidence
suggest that fundamental plasma properties are altered by the super-Gaussian
distribution. This paper examines how the super-Gaussian distribution affects
the ionization balance and K-shell emission of atomic plasmas, utilizing
approximate formulas and detailed collisional-radiative simulations. While the
impact on plasma ionization is small, K-shell spectra can be significantly
modified. Based on these findings, we demonstrate that K-shell spectroscopy can
be used to infer super-Gaussian or other similar non-equilibrium electron
distributions.

</details>


### [35] [Electron heating in bulk overdense plasma aided by time dependent external magnetic field](https://arxiv.org/abs/2507.02543)
*Rohit Juneja,Trishul Dhalia,Amita Das*

Main category: physics.plasm-ph

TL;DR: The study explores localized electron heating in overdense plasma using a time-dependent magnetic field, achieving Electron Cyclotron Resonance (ECR) with laser energy transfer to electrons via PIC simulations.


<details>
  <summary>Details</summary>
Motivation: To investigate efficient energy transfer from lasers to electrons in overdense plasma using tailored magnetic fields.

Method: Uses a decaying external magnetic field to enable laser propagation and achieve ECR, simulated via Particle-In-Cell (PIC) on OSIRIS4.0.

Result: Demonstrates electron energy gain for varying magnetic field profiles, laser intensities, and polarizations.

Conclusion: The method shows promise for future experiments, with current technology nearing required magnetic field strengths.

Abstract: This study investigates the localized electron heating in a bulk overdense
plasma. The method relies on using a time dependent magnetic field. An
initially high external magnetic field imposed on the overdense plasma target
enables the propagation of a laser pulse inside it through the pass bands that
occur in the magnetized dispersion relation. The choice of decaying external
magnetic field is then tailored appropriately to achieve Electron Cyclotron
Resonance (ECR) with the frequency of the laser electromagnetic field. At the
resonance location, the field energy of the laser gets transferred to the
electrons. These studies have been carried out with the help of the
Particle-In-Cell (PIC) simulation technique on the OSIRIS4.0 platform. A
detailed study has been carried out to illustrate the energy gain by electrons
for a variety of temporal profiles of the magnetic field, laser intensities,
and polarizations. The experiments in this regime may be within reach in the
near future. For instance, the choice of long-wavelength CO$_2$ laser requires
a magnetic field of about 10s of kilo Tesla to comfortably elicit a magnetized
response from electrons. Recent technological advancements have shown the
generation of about 1.4 kilo Tesla of magnetic field.

</details>


### [36] [Boosting the NOx production in microwave air plasma: A synergy of chemistry and vibrational kinetics](https://arxiv.org/abs/2507.02795)
*Qinghao Shen,Aleksandr Pikalev,Jonas Gans,Lex Kuijpers,Ashley Hughes,Vasco Guerra,M. C. M van de Sanden*

Main category: physics.plasm-ph

TL;DR: A quasi-1.5D model studies NOx production in microwave plasma reactors, revealing non-thermal enhancement in discharge zones and turbulence's role in efficiency.


<details>
  <summary>Details</summary>
Motivation: To understand NOx production mechanisms and energy costs in microwave plasma reactors, focusing on non-thermal processes and turbulence effects.

Method: Quasi-1.5D multi-temperature model analyzing vibrational, chemical, electron kinetics, thermodynamics, and transport in discharge and afterglow regions.

Result: Non-thermal processes boost NOx in discharge zones but fade in afterglow. Turbulence aids radial NO diffusion and axial cooling, aligning with experimental data.

Conclusion: Optimizing turbulence and non-thermal conditions can enhance NOx synthesis efficiency, advancing plasma-based chemical processes.

Abstract: This study employs a quasi-1.5D multi-temperature model to investigate the
mechanisms governing NOx production and energy costs in microwave plasma
reactors operating at 80 mbar, focusing on the interplay of vibrational,
chemical and electron kinetics, thermodynamics, and transport processes across
the discharge and afterglow. In the plasma discharge zone, non-thermal
processes enhance NOx production as electrons transfer energy effectively to
the vibrational mode of N2. However, the non-thermal enhancement is found to
diminish rapidly within the central-afterglow region. The simulation results
show good agreement with experimental data for both the temperature profile and
energy cost. Turbulent effects facilitate radial NO diffusion into cooler
regions while simultaneously enhancing cooling of the axial region. These
findings highlight the potential to improve NOx synthesis efficiency by
optimizing turbulence and maintaining non-thermal conditions, offering new
opportunities for the advancement of plasma-based chemical processes.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [37] [On the Design of Corrugated Boards: A New FEM Modeling and Experimental Validation](https://arxiv.org/abs/2507.02189)
*Ricardo Fitas,Heinz Joachim Schaffrath,Samuel Schabel*

Main category: physics.app-ph

TL;DR: A simplified FEM modeling approach for corrugated boards uses homogenization and Weibull correction factors to reduce computational time while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: To optimize corrugated packaging design by simplifying FEM models for faster simulations without sacrificing accuracy.

Method: Combines homogenization (transforming flute geometries into equivalent elastic models) with Weibull correction factors for contact and buckling mechanisms, validated experimentally.

Result: Demonstrates computational efficiency with statistical parameters (β₁=0.14, β₂=1.31) for accurate representation of corrugated boards.

Conclusion: The approach simplifies FEM models for corrugated boards, aiding in faster and accurate packaging design optimization.

Abstract: This study presents a simplified FEM modeling approach suitable for large
structures made of corrugated boards, such as customized packages, based on a
homogenization method, which is combined with correction factors for internal
mechanisms. The homogenization process reduces computational time by
transforming flute geometries into equivalent elastic models. In large
deformations and in the presence of contact for a given geometry, the effective
elastic modulus in the thickness direction, as well as the effective thickness
of the structure, are corrected by two statistical Weibull distributions
representing the contact and buckling mechanisms in a corrugated board. The
Weibull parameters are obtained via experimental analysis, and such a process
is then validated. The results demonstrate that the statistical parameters
($\beta_1 = 0.14$, $\beta_2 = 1.31$) can be used for the simplistic
representation of corrugated boards, being computationally efficient. This
research contributes to the optimization of corrugated packaging design,
specifically by simplifying FEM models for faster yet equally accurate
simulations.

</details>


### [38] [Modeling the Effective Elastic Modulus and Thickness of Corrugated Boards Using Gaussian Process Regression and Expected Hypervolume Improvement](https://arxiv.org/abs/2507.02208)
*Ricardo Fitas*

Main category: physics.app-ph

TL;DR: The paper models the effective elastic modulus and thickness of corrugated boards using LHS and GP with EHVI, achieving accurate predictions for engineering optimization.


<details>
  <summary>Details</summary>
Motivation: Accurate modeling of effective elastic modulus and thickness is crucial for optimizing mechanical properties in corrugated materials.

Method: Uses Latin Hypercube Sampling (LHS) for initial sampling and Gaussian Process Regression (GP) enhanced by EHVI for multi-objective acquisition.

Result: Achieved MSE of 5.24 kPa² for elastic modulus and 1 mm² for thickness, demonstrating GP's accuracy.

Conclusion: GP with EHVI improves adaptability and accuracy for structural optimization in engineering applications.

Abstract: This work aims to model the hypersurface of the effective elastic modulus, \(
E_{z, \text{eff}} \), and thickness, \( th_{\text{eff}} \), in corrugated
boards. A Latin Hypercube Sampling (LHS) is followed by Gaussian Process
Regression (GP), enhanced by EHVI as a multi-objective acquisition function.
Accurate modeling of \( E_{z, \text{eff}} \) and \( th_{\text{eff}} \) is
critical for optimizing the mechanical properties of corrugated materials in
engineering applications. LHS provides an efficient and straightforward
approach for an initial sampling of the input space; GP is expected to be able
to adapt to the complexity of the response surfaces by incorporating both
prediction and uncertainty. Therefore, the next points being generated and
evaluated are based on the complexity of the hypersurfaces, and some points,
especially those with higher variance, are more exploited and carry more
importance. The performance of GP with EHVI is measured by Mean Squared Error
(MSE). Prediction of GP resulted in \( \text{MSE}(E_{z, \text{eff}}) = 5.24 \,
\text{kPa}^2 \) and \( \text{MSE}(th_{\text{eff}}) = 1 \, \text{mm}^2 \). GP
possesses then improved accuracy and adaptability for future applications in
structural optimization.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [39] [Spin Caloritronics in irradiated chiral ferromagnetic systems](https://arxiv.org/abs/2507.02765)
*Sudin Ganguly,Moumita Dey,Santanu K. Maiti*

Main category: cond-mat.mes-hall

TL;DR: The paper explores the thermoelectric response of a ferromagnetic helical system under light irradiation, revealing enhanced spin thermoelectric performance compared to charge thermoelectricity.


<details>
  <summary>Details</summary>
Motivation: To understand how light irradiation affects the charge and spin-dependent thermoelectric properties of ferromagnetic helical systems, aiming for efficient energy conversion.

Method: Uses a tight-binding framework, Floquet-Bloch formalism, non-equilibrium Green's function technique for transport, and a mass-spring model for phonon thermal conductance.

Result: Light induces spin-split transmission, suppresses thermal conductance, and improves spin thermopower and figure of merit (FOM). Spin FOM outperforms charge FOM, with long-range hopping further enhancing performance.

Conclusion: The study highlights the potential of light-irradiated ferromagnetic helical systems for efficient spin thermoelectric energy conversion, with long-range hopping as a key enhancer.

Abstract: We study the charge and spin-dependent thermoelectric response of a
ferromagnetic helical system irradiated by arbitrarily polarized light, using a
tight-binding framework and the Floquet-Bloch formalism. Transport properties
for individual spin channels are determined by employing the non-equilibrium
Green's function technique, while phonon thermal conductance is evaluated using
a mass-spring model with different lead materials. The findings reveal that
that light irradiation induces spin-split transmission features, suppresses
thermal conductance, and yields favorable spin thermopower and figure of merit
(FOM). The spin FOM consistently outperforms its charge counterpart under
various light conditions. Moreover, long-range hopping is shown to enhance the
spin thermoelectric performance, suggesting a promising strategy for efficient
energy conversion in related ferromagnetic systems.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [40] [Optimal boron-doped graphene substrate for glucose Raman signal enhancement](https://arxiv.org/abs/2507.02642)
*Jan Komeda,Antonio Cammarata,Tomas Polcar*

Main category: cond-mat.mtrl-sci

TL;DR: Higher boron doping in graphene enhances glucose's Raman signal, with molecule orientation critical for SERS effectiveness.


<details>
  <summary>Details</summary>
Motivation: To explore how boron doping concentration and geometric distribution in graphene affect its performance as a SERS substrate for glucose detection.

Method: Quantum mechanical simulations analyzing interatomic force constants and phonon eigenvectors.

Result: Higher boron doping concentrations significantly enhance glucose's Raman signal, and molecule orientation is crucial.

Conclusion: High-concentration boron-doped graphene is promising for SERS-based glucose detection, and phonon analysis can aid substrate material discovery.

Abstract: Surface Enhanced Raman Spectroscopy (SERS) is a highly sensitive and
selective technique that greatly enhances the signal of an analyte, compared
with its signal from classical Raman Spectroscopy, due to its interaction with
a substrates surface. It has been shown that low concentration boron-doped
graphene (B-graphene) enhances the Raman signal of simple organic molecules
like pyridine. Recent studies also suggest that B-graphene can remain
thermodynamically stable when doped with significantly higher concentrations of
boron than previously observed. In this framework, we use quantum mechanical
simulations to investigate the influence of dopant concentration and geometric
distribution on the effectiveness of B-doped graphene as a SERS substrate, with
glucose as analyte. By combining analysis of interatomic force constants and of
phonon eigenvectors composition, we conclude that higher doping concentrations
provide a larger enhancement to glucose's Raman signal, while the molecule
orientation relative to the surface plays a fundamental role in the Raman
response. We suggest that high concentration B-graphene presents itself as a
potential substrate for SERS based detection of glucose, while the used
phonon-based analysis can be promptly applied for the search of promising
candidates as substrate materials for enhanced Raman response.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [41] [Cauchy problem for the localized wave propagation in continuous model of the one-dimensional diatomic crystal](https://arxiv.org/abs/2507.02729)
*Sergey Sergeev*

Main category: math-ph

TL;DR: The paper studies wave propagation in a 1D diatomic lattice using a continuous model, analyzing asymptotic solutions for localized perturbations under two parameter regimes.


<details>
  <summary>Details</summary>
Motivation: To understand wave propagation in diatomic lattices by addressing the Cauchy problem with localized initial data and small parameters.

Method: Constructs asymptotic solutions for the continuous Cauchy problem using pseudo-differential equations, focusing on two parameter regimes (large perturbation vs. perturbation comparable to lattice step).

Result: Analytical formulae for asymptotic solutions are derived using Airy functions, showing the solution's dependence on parameter ratios.

Conclusion: The study reveals how parameter ratios influence wave solutions, providing explicit analytical results for different regimes.

Abstract: We study the continuous model of the localized wave propagation corresponding
to the one-dimensional diatomic crystal lattice. From the mathematical point of
view the problem can be described in terms of the Cauchy problem with localized
initial data for a system of two pseudo-differential equations. We assume two
small parameters in this formulation -- the lattice step and the size if the
initial perturbation. We construct the asymptotic solution of the continuous
Cauchy problem with respect to the size of perturbation.
  The ratio of the small parameters drastically affects the form of the
solution. We consider two situations -- when the size of the perturbation is
sufficiently large and when it is comparable with the lattice step. In each
situations we provide analytical formulae for the asymptotic solution via Airy
function.

</details>


<div id='astro-ph.CO'></div>

# astro-ph.CO [[Back]](#toc)

### [42] [A general polynomial emulator for cosmology via moment projection](https://arxiv.org/abs/2507.02179)
*Zheng Zhang*

Main category: astro-ph.CO

TL;DR: MomentEmu is a polynomial emulator for fast, interpretable mappings between theoretical parameters and observational features, outperforming neural-network-based emulators in training cost, speed, and transparency.


<details>
  <summary>Details</summary>
Motivation: To provide a lightweight, interpretable alternative to black-box emulators for cosmological analysis, enabling efficient forward modeling, parameter inference, and uncertainty propagation.

Method: Constructs moment matrices to project simulation data onto polynomial bases, yielding symbolic expressions for the target mapping.

Result: Achieves sub-percent accuracy in emulating cosmological mappings, with negligible training cost and millisecond-level evaluation.

Conclusion: MomentEmu is a portable, efficient, and transparent tool for moderate-dimensional, smooth mappings in cosmological analysis.

Abstract: We present MomentEmu, a general-purpose polynomial emulator for fast and
interpretable mappings between theoretical parameters and observational
features. The method constructs moment matrices to project simulation data onto
polynomial bases, yielding symbolic expressions that approximate the target
mapping. Compared to neural-network-based emulators, MomentEmu offers
negligible training cost, millisecond-level evaluation, and transparent
functional forms. As a demonstration, we develop two emulators:
PolyCAMB-$D_\ell$, which maps six cosmological parameters to the CMB
temperature power spectrum, and PolyCAMB-peak, which enables bidirectional
mapping between parameters and acoustic peak features. PolyCAMB-$D_\ell$
achieves an accuracy of $0.03\%$over $\ell \leq 2510$, while PolyCAMB-peak also
reaches sub-percent accuracy and produces symbolic forms consistent with known
analytical approximations. The method is well suited for forward modelling,
parameter inference, and uncertainty propagation, particularly when the
parameter space is moderate in dimensionality and the mapping is smooth.
MomentEmu offers a lightweight and portable alternative to regression-based or
black-box emulators in cosmological analysis.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [43] [Langmuir Wave Excitation in Solar-wind Magnetic Holes](https://arxiv.org/abs/2507.02042)
*Jingting Liu,Daniel Verscharen,Jesse Coburn,Georgios Nicolaou,Xiangyu Wu,Wence Jiang,Oreste Pezzi,Francesco Pucci,Matteo Zuin,Christopher J. Owen,Hamish Reid*

Main category: physics.space-ph

TL;DR: The paper explains how magnetic holes in the solar wind excite Langmuir waves via a bump-on-tail instability, supported by Solar Orbiter data.


<details>
  <summary>Details</summary>
Motivation: To understand the correlation between magnetic holes and Langmuir waves in the solar wind.

Method: Developed a model based on magnetic-moment conservation and its violation, tested with Solar Orbiter observations.

Result: The model aligns with observations, confirming the mechanism for Langmuir wave excitation.

Conclusion: The proposed process is a viable explanation for Langmuir waves in magnetic holes.

Abstract: Magnetic holes are structures commonly observed in various space plasma
environments throughout the solar system, including the solar wind. These
structures are characterized by a localized decrease in magnetic field
strength, coincident with an increase in plasma density. Previous observational
studies in the solar wind link the presence of Langmuir waves to magnetic
holes, suggesting a strong correlation between these phenomena. We develop a
model based on magnetic-moment conservation and its violation to explain the
excitation of Langmuir waves in magnetic holes. Our model illustrates that
magnetic holes induce changes in the electron velocity distribution function
that emit electrostatic Langmuir waves due to the bump-on-tail instability.
Using data from the Solar Orbiter spacecraft, we provide a comprehensive
analysis of this process and test our predictions with observations. The
consistency between the model and observations indicates that our proposed
process is a viable mechanism for producing Langmuir waves in magnetic holes in
the solar wind.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [44] [Public perspectives on the design of fusion energy facilities](https://arxiv.org/abs/2507.02207)
*Nathan Kawamoto,Daniel Hoover,Jonathan Xie,Jacob Walters,Katie Snyder,Aditi Verma*

Main category: physics.soc-ph

TL;DR: Participatory design workshops for fusion energy facilities engage communities early, revealing key values like integrity and respect, and criteria like economic benefits and safety, fostering social license.


<details>
  <summary>Details</summary>
Motivation: To understand public perspectives on fusion energy facilities and achieve social license by involving communities in the design process.

Method: Conducted a participatory design workshop with 22 community participants and 34 engineering students, analyzing textual and visual data.

Result: Top values: integrity and respect; top criteria: economic benefits and environmental safety. Design themes included community legacy, worker care, transparency, and safety. Positive sentiments like joy and surprise were reported.

Conclusion: Early participatory design can address public hopes/concerns, improve understanding of fusion energy, and inform context-specific facility development.

Abstract: As fusion energy technologies approach demonstration and commercial
deployment, understanding public perspectives on future fusion facilities will
be critical for achieving social license, especially because fusion energy
facilities, unlike large fission reactors, may be sited in closer proximity to
people and communities, due to distinct regulatory frameworks. In a departure
from the 'decide-announce-defend' approach typically used to site energy
infrastructure, we develop a participatory design methodology for
collaboratively designing fusion energy facilities with prospective host
communities. We present here our findings from a participatory design workshop
that brought together 22 community participants and 34 engineering students.
Our analysis of the textual and visual data from this workshop shows a range of
design values and decision-making criteria with 'integrity' and 'respect'
ranking highest among values and 'economic benefits' and 'environmental
protection/safety' ranking highest among decision-making criteria. Salient
design themes that emerge across facility concepts include connecting the
history and legacy of the community to the design of the facility, care for
workers, transparency and access to the facility, and health and safety of the
host community. Participants reported predominantly positive sentiments,
expressing joy and surprise as the workshop progressed from learning about
fusion to designing the hypothetical facility. Our findings suggest that
carrying out participatory design in the early stages of technology development
can invite and make concrete public hopes and concerns, improve understanding
of, and curiosity about, an emerging technology, build toward social license,
and inform context-specific development of fusion energy facilities.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [45] [MeV cosmic-ray electrons modify the TeV pair-beam plasma instability](https://arxiv.org/abs/2507.02423)
*Mahmoud Alawashra,Yuanyuan Yang,Christopher M. Hirata,Heyang Long,Martin Pohl*

Main category: astro-ph.HE

TL;DR: The paper investigates how linear Landau damping (LLD) affects the energy-loss efficiency of plasma instabilities in relativistic pair beams from blazars, finding it suppresses oblique modes but enhances quasi-parallel ones, significantly boosting energy loss.


<details>
  <summary>Details</summary>
Motivation: The absence of GeV-scale electromagnetic cascades in blazar spectra suggests energy loss mechanisms like plasma instabilities or magnetic deflection; this study explores LLD's role.

Method: The impact of LLD on plasma instabilities in pair beams from blazar 1ES 0229+200 is analyzed, focusing on oblique and quasi-parallel electrostatic modes.

Result: LLD suppresses oblique electrostatic modes but allows quasi-parallel modes to grow, increasing energy-loss efficiency by over an order of magnitude.

Conclusion: LLD plays a critical role in enhancing the energy-loss efficiency of plasma instabilities in relativistic pair beams, explaining the missing GeV cascade in blazar spectra.

Abstract: Relativistic pair beams created in the intergalactic medium (IGM) by TeV
gamma rays from blazars are expected to produce a detectable GeV-scale
electromagnetic cascade, but the cascade component is absent in the spectra of
many hard-spectrum TeV-emitting blazars. One common explanation is that weak
intergalactic magnetic fields deflect the electron-positron pairs away from our
line of sight. An alternative possibility is that electrostatic beam-plasma
instabilities drain the energy of these pairs before a cascade can develop.
Recent studies have shown that beam scattering by oblique electrostatic modes
leads to minimal energy loss. But these modes might be suppressed by linear
Landau damping (LLD) due to MeV-scale cosmic-ray electrons in the IGM. In this
work, we explore the impact of LLD on the energy-loss efficiency of plasma
instabilities in pair beams associated with 1ES 0229+200. We find that LLD
effectively suppresses oblique electrostatic modes, while quasi-parallel ones
grow to larger amplitudes. In this way, LLD enhances the energy-loss efficiency
of the instability by more than an order of magnitude.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [46] [Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework](https://arxiv.org/abs/2507.02106)
*Semih Kacmaz,E. A. Huerta,Roland Haas*

Main category: physics.flu-dyn

TL;DR: A hybrid framework combining Physics-Informed Neural Operators (PINOs) and diffusion models accurately simulates 2D MHD turbulence across various Reynolds numbers, outperforming deterministic methods.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of simulating fully developed turbulence across a wide range of Reynolds numbers, where deterministic surrogates fall short.

Method: Uses PINOs for low-frequency dynamics and a conditional diffusion model for high-frequency residuals, trained on high-fidelity simulations.

Result: Achieves state-of-the-art accuracy, capturing spectral energy distributions, non-Gaussian statistics, and cross-field correlations, even at extreme turbulence levels (Re=10000).

Conclusion: The hybrid framework enables accurate and statistically meaningful predictions of MHD turbulence, surpassing previous deterministic approaches.

Abstract: We present a hybrid machine learning framework that combines Physics-Informed
Neural Operators (PINOs) with score-based generative diffusion models to
simulate the full spatio-temporal evolution of two-dimensional, incompressible,
resistive magnetohydrodynamic (MHD) turbulence across a broad range of Reynolds
numbers ($\mathrm{Re}$). The framework leverages the equation-constrained
generalization capabilities of PINOs to predict coherent, low-frequency
dynamics, while a conditional diffusion model stochastically corrects
high-frequency residuals, enabling accurate modeling of fully developed
turbulence. Trained on a comprehensive ensemble of high-fidelity simulations
with $\mathrm{Re} \in \{100, 250, 500, 750, 1000, 3000, 10000\}$, the approach
achieves state-of-the-art accuracy in regimes previously inaccessible to
deterministic surrogates. At $\mathrm{Re}=1000$ and $3000$, the model
faithfully reconstructs the full spectral energy distributions of both velocity
and magnetic fields late into the simulation, capturing non-Gaussian
statistics, intermittent structures, and cross-field correlations with high
fidelity. At extreme turbulence levels ($\mathrm{Re}=10000$), it remains the
first surrogate capable of recovering the high-wavenumber evolution of the
magnetic field, preserving large-scale morphology and enabling statistically
meaningful predictions.

</details>


### [47] [Predicting Flow-Induced Vibration in Isolated and Tandem Cylinders Using Hypergraph Neural Networks](https://arxiv.org/abs/2507.02242)
*Shayan Heydari,Rui Gao,Rajeev K Jaiman*

Main category: physics.flu-dyn

TL;DR: A hypergraph neural network framework predicts flow-induced vibrations in cylinders, using finite element-inspired methods and modular architecture for high-fidelity results.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of predicting nonlinear flow-induced vibrations in freely oscillating cylinders, especially under complex wake-body interactions.

Method: Transforms unstructured meshes into hypergraphs, uses POD-based sub-network for mesh deformation, and hypergraph message-passing for flow field prediction.

Result: Accurately captures oscillation amplitudes, resolves wake-body interactions, and reproduces force statistics and flow dynamics.

Conclusion: The framework is a robust surrogate model for digital twin applications, handling complex fluid-structure interactions effectively.

Abstract: We present a finite element-inspired hypergraph neural network framework for
predicting flow-induced vibrations in freely oscillating cylinders. The
surrogate architecture transforms unstructured computational meshes into
node-element hypergraphs that encode higher-order spatial relationships through
element-based connectivity, preserving the geometric and topological structure
of the underlying finite-element discretization. The temporal evolution of the
fluid-structure interaction is modeled via a modular partitioned architecture:
a complex-valued, proper orthogonal decomposition-based sub-network predicts
mesh deformation using a low-rank representation of Arbitrary
Lagrangian-Eulerian (ALE) grid displacements, while a hypergraph-based
message-passing network predicts the unsteady flow field using geometry-aware
node, element, and hybrid edge features. High-fidelity ALE-based simulations
provide training and evaluation data across a range of Reynolds numbers and
reduced velocities for isolated and tandem cylinder configurations. The
framework demonstrates stable roll-outs and accurately captures the nonlinear
variation of oscillation amplitudes with respect to reduced velocity, a key
challenge in surrogate modeling of flow-induced vibrations. In the tandem
configuration, the model successfully resolves complex wake-body interactions
and multi-scale coupling effects, enabling accurate prediction of pressure and
velocity fields under strong wake interference conditions. Our results show
high fidelity in reproducing force statistics, dominant frequencies, and
flow-field dynamics, supporting the framework's potential as a robust surrogate
model for digital twin applications.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [48] [Is the hyperscaling relation violated below the upper critical dimension in some particular cases?](https://arxiv.org/abs/2507.02159)
*Hung T. Diep,Van-Thanh Ngo*

Main category: cond-mat.stat-mech

TL;DR: The paper investigates critical exponents in thin films using high-performance Monte Carlo simulations, revealing deviations from 2D values and violations of hyperscaling, suggesting an 'effective' dimension. It also explores transitions in frustrated films and new universality classes.


<details>
  <summary>Details</summary>
Motivation: To understand how critical exponents and hyperscaling relations behave in thin films, especially when transitioning between 2D and quasi-2D systems, and to explore novel universality classes.

Method: High-performance multi-histogram Monte Carlo simulations with free boundary conditions in the z-direction and periodic boundary conditions in the xy-plane. The Ising model with nearest-neighbor interactions is studied.

Result: Critical exponents for N_z>1 deviate systematically from 2D values, violating hyperscaling unless an 'effective' dimension (>2) is considered. New universality classes emerge for coupled order parameters, and hyperscaling violations are observed in 3D Ising models with lattice vibrations.

Conclusion: The study highlights the complexity of critical phenomena in thin films, revealing deviations from classical expectations and proposing new universality classes, with implications for understanding dimensional crossovers and hyperscaling violations.

Abstract: In this review, we show our results with new interpretation on the critical
exponents of thin films obtained by high-performance multi-histogram Monte
Carlo simulations. The film thickness $N_z$ consists of a few layers up to a
dozen of layers in the $z$ direction. The free boundary condition is applied in
this direction while in the $xy$ plane periodic boundary conditions are used.
Large $xy$ plane sizes are used for finite-size scaling. The Ising model is
studied with nearest-neighbor (NN) interaction. When $N_z=1$, namely the
two-dimensional (2D) system, we find the critical exponents given by the
renormalization group. While, for $N_z>1$, the critical exponents calculated
with the high-precision multi-histogram technique show that they deviate
slightly but systematically from the 2D values. If we use these values of
critical exponents in the hyperscaling relation with $d=2$, then the
hyperscaling relation is violated. However, if we use the hyperscaling relation
and the critical exponents obtained for $N_z>1$ to calculate the dimension of
the system, we find the system dimension slightly larger than 2. This can be
viewed as an "effective" dimension. More discussion is given in the paper. We
also show the cross-over between the first- and second-order transition while
varying the film thickness in an antiferromagnetic FCC Ising frustrated thin
film. In addition, we will show evidence that when a 2D system has two order
parameters of different symmetries with a single transition, the critical
exponents are new, suggesting a universality class of coupled two-symmetry
breakings. In this case, the 2D hyperscaling does not hold. Another case is the
3D Ising model coupled to the lattice vibration: the critical exponents deviate
from the 3D Ising ones, the results suggest the violation of the hyperscaling.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [49] [Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning](https://arxiv.org/abs/2507.02211)
*Gustavo C. Mangold,Heitor C. M. Fernandes,Mendeli H. Vainstein*

Main category: cs.AI

TL;DR: The paper explores how dilution and mobility affect cooperation in spatial prisoner's dilemma games using multi-agent Q-learning, showing equivalence between fixed and learned update rules and symbiotic effects.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of dilution and mobility on cooperation in spatial prisoner's dilemma games using reinforcement learning.

Method: Uses an independent multi-agent Q-learning algorithm to model different actions and scenarios in the game.

Result: Observes equivalence between fixed and learned update rules and identifies symbiotic mutualistic effects between populations.

Conclusion: The approach demonstrates versatility in modeling game-theoretical scenarios and highlights the benchmarking potential of reinforcement learning in such contexts.

Abstract: Recent studies in the spatial prisoner's dilemma games with reinforcement
learning have shown that static agents can learn to cooperate through a diverse
sort of mechanisms, including noise injection, different types of learning
algorithms and neighbours' payoff knowledge.In this work, using an independent
multi-agent Q-learning algorithm, we study the effects of dilution and mobility
in the spatial version of the prisoner's dilemma. Within this setting,
different possible actions for the algorithm are defined, connecting with
previous results on the classical, non-reinforcement learning spatial
prisoner's dilemma, showcasing the versatility of the algorithm in modeling
different game-theoretical scenarios and the benchmarking potential of this
approach.As a result, a range of effects is observed, including evidence that
games with fixed update rules can be qualitatively equivalent to those with
learned ones, as well as the emergence of a symbiotic mutualistic effect
between populations that forms when multiple actions are defined.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [50] [Hybrid least squares for learning functions from highly noisy data](https://arxiv.org/abs/2507.02215)
*Ben Adcock,Bernhard Hientzsch,Akil Narayan,Yiming Xu*

Main category: stat.ML

TL;DR: A hybrid method combining Christoffel sampling and optimal experimental design improves efficiency in estimating conditional expectations with noisy data.


<details>
  <summary>Details</summary>
Motivation: Efficient estimation of conditional expectations in the presence of heavily polluted data, where existing methods underperform with large noise.

Method: Proposes a hybrid approach integrating Christoffel sampling and optimal experimental design, extended to convex-constrained settings and adaptive random subspaces.

Result: The algorithm shows optimality in sample point generation and noise reduction, improving computational efficiency and sample complexity. Theoretical guarantees are supported by numerical studies.

Conclusion: The proposed method outperforms existing techniques in noisy environments and adapts well to complex settings, validated by synthetic and real-world data.

Abstract: Motivated by the need for efficient estimation of conditional expectations,
we consider a least-squares function approximation problem with heavily
polluted data. Existing methods that are powerful in the small noise regime are
suboptimal when large noise is present. We propose a hybrid approach that
combines Christoffel sampling with certain types of optimal experimental design
to address this issue. We show that the proposed algorithm enjoys appropriate
optimality properties for both sample point generation and noise mollification,
leading to improved computational efficiency and sample complexity compared to
existing methods. We also extend the algorithm to convex-constrained settings
with similar theoretical guarantees. When the target function is defined as the
expectation of a random field, we extend our approach to leverage adaptive
random subspaces and establish results on the approximation capacity of the
adaptive procedure. Our theoretical findings are supported by numerical studies
on both synthetic data and on a more challenging stochastic simulation problem
in computational finance.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [51] [Time Resolution Independent Operator Learning](https://arxiv.org/abs/2507.02524)
*Diab W. Abueidda,Mbebo Nonna,Panos Pantidis,Mostafa E. Mobasher*

Main category: cs.CE

TL;DR: NCDE-DeepONet introduces a continuous-time operator network for learning PDE solution operators from sparse data, overcoming limitations of RNNs and neural-ODEs.


<details>
  <summary>Details</summary>
Motivation: Existing methods like RNNs and neural-ODEs struggle with sparse, irregular data and lack flexibility for new inputs post-initialization.

Method: NCDE-DeepONet uses Neural Controlled Differential Equations (NCDEs) in the branch and augments the trunk with space-time coordinates, enabling resolution-independent predictions.

Result: The framework achieves robust and accurate predictions on transient problems, offering nearly instant solutions.

Conclusion: Controlled dynamics provide a principled and efficient foundation for high-fidelity operator learning in transient mechanics.

Abstract: Accurately learning solution operators for time-dependent partial
differential equations (PDEs) from sparse and irregular data remains a
challenging task. Recurrent DeepONet extensions inherit the discrete-time
limitations of sequence-to-sequence (seq2seq) RNN architectures, while
neural-ODE surrogates cannot incorporate new inputs after initialization. We
introduce NCDE-DeepONet, a continuous-time operator network that embeds a
Neural Controlled Differential Equation (NCDE) in the branch and augments the
trunk with explicit space-time coordinates. The NCDE encodes an entire load
history as the solution of a controlled ODE driven by a spline-interpolated
input path, making the representation input-resolution-independent: it encodes
different input signal discretizations of the observed samples. The trunk then
probes this latent path at arbitrary spatial locations and times, rendering the
overall map output-resolution independent: predictions can be queried on meshes
and time steps unseen during training without retraining or interpolation.
Benchmarks on transient Poisson, elastodynamic, and thermoelastic problems
confirm the robustness and accuracy of the framework, achieving almost instant
solution prediction. These findings suggest that controlled dynamics provide a
principled and efficient foundation for high-fidelity operator learning in
transient mechanics.

</details>
