<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 13]
- [math.AP](#math.AP) [Total: 19]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [stat.ML](#stat.ML) [Total: 1]
- [physics.space-ph](#physics.space-ph) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [math-ph](#math-ph) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [astro-ph.CO](#astro-ph.CO) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A Hybrid DEC-SIE Framework for Potential-Based Electromagnetic Analysis of Heterogeneous Media](https://arxiv.org/abs/2507.02099)
*Amgad Abdrabou,Luis J. Gomez,Weng Cho Chew*

Main category: math.NA

TL;DR: A hybrid method combining discrete exterior calculus (DEC) and surface integral equations (SIE) is proposed for efficient electromagnetic field analysis in complex multi-material environments.


<details>
  <summary>Details</summary>
Motivation: Address computational challenges in analyzing electromagnetic fields in complex, multi-material settings.

Method: Couples DEC with SIE using magnetic vector and electric scalar potentials under the Lorenz gauge, dividing the domain into inhomogeneous (DEC) and homogeneous (SIE) regions.

Result: Simplifies SIE operators from fourteen to two, improves interface compatibility, and enhances numerical performance.

Conclusion: The hybrid method provides a unified, efficient, and physically consistent framework for electromagnetic problems in complex geometries.

Abstract: Analyzing electromagnetic fields in complex, multi-material environments
presents substantial computational challenges. To address these, we propose a
hybrid numerical method that couples discrete exterior calculus (DEC) with
surface integral equations (SIE) in the potential-based formulation of
Maxwell's equations. The method employs the magnetic vector and electric scalar
potentials ($\mathbf{A}$-$\Phi$) under the Lorenz gauge, offering natural
compatibility with multi-physics couplings and inherent immunity to
low-frequency breakdown. To effectively handle both bounded and unbounded
regions, we divide the computational domain: the inhomogeneous interior is
discretized using DEC, a coordinate-free framework that preserves topological
invariants and enables structure-preserving discretization on unstructured
meshes, while the homogeneous exterior is treated using SIEs, which inherently
satisfy the radiation condition and eliminate the need for artificial domain
truncation. A key contribution of this work is a scalar reformulation of the
SIEs, which reduces the number of surface integral operators from fourteen to
two by expressing the problem in terms of the Cartesian components of the
vector potential and their normal derivatives. This simplification motivates a
corresponding adaptation in the DEC domain: each vector potential component is
represented as a discrete 0-form, in contrast to the conventional 1-form
representation. This novel treatment improves compatibility at the interface
and significantly enhances numerical performance. The proposed hybrid method
thus offers a unified, efficient, and physically consistent framework for
solving electromagnetic scattering and radiation problems in complex geometries
and heterogeneous materials

</details>


### [2] [Symplectic Hamiltonian Hybridizable Discontinuous Galerkin Methods for Linearized Shallow Water Equations](https://arxiv.org/abs/2507.02340)
*C. Núñez,M. A. Sánchez*

Main category: math.NA

TL;DR: The paper presents a hybridizable discontinuous Galerkin (HDG) method for numerically approximating the linearized shallow water equations, preserving Hamiltonian structure and energy conservation.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical method that preserves the Hamiltonian structure of the linearized shallow water equations, ensuring energy conservation and accurate physical evolution.

Method: Introduces an auxiliary variable for equivalent formulation, discretizes space with HDG methods, and uses symplectic integrators for time discretization.

Result: Achieves optimal convergence rates and conserves total energy, demonstrating accurate evolution of physical quantities.

Conclusion: The HDG method with auxiliary variables and symplectic integrators effectively preserves Hamiltonian structure and energy in the linearized shallow water equations.

Abstract: This paper focuses on the numerical approximation of the linearized shallow
water equations using hybridizable discontinuous Galerkin (HDG) methods,
leveraging the Hamiltonian structure of the evolution system. First, we propose
an equivalent formulation of the equations by introducing an auxiliary
variable. Then, we discretize the space variables using HDG methods, resulting
in a semi-discrete scheme that preserves a discrete version of the Hamiltonian
structure. The use of an alternative formulation with the auxiliary variable is
crucial for developing the HDG scheme that preserves this Hamiltonian
structure. The resulting system is subsequently discretized in time using
symplectic integrators, ensuring the energy conservation of the fully discrete
scheme. We present numerical experiments that demonstrate optimal convergence
rates for all variables and showcase the conservation of total energy, as well
as the evolution of other physical quantities.

</details>


### [3] [An efficient asymptotic preserving Monte Carlo method for frequency-dependent radiative transfer equations](https://arxiv.org/abs/2507.02392)
*Yiyang Hong,Yi Shi,Yi Cai,Tao Xiong*

Main category: math.NA

TL;DR: An efficient asymptotic-preserving Monte Carlo method is developed for frequency-dependent radiative transfer equations, combining particle-based and implicit methods for computational efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of frequency-dependent radiative transfer equations, including nonlinear coupling and computational inefficiency, by extending the AP-MC method to handle frequency-dependency.

Method: A hybrid approach: particle-based MC for convective fluxes and implicit central difference for diffusive fluxes, with a Picard iteration for nonlinear coupling.

Result: The method achieves high efficiency and maintains asymptotic-preserving properties across a wide frequency range.

Conclusion: The proposed method effectively solves frequency-dependent RTEs with improved computational efficiency and accuracy.

Abstract: In this paper, we develop an efficient asymptotic-preserving (AP) Monte Carlo
(MC) method for frequency-dependent radiative transfer equations (RTEs), which
is based on the AP-MC method proposed for the gray RTEs in
\cite{shi2023efficient}. We follow the characteristics-based approach by Zhang
et al. \cite{zhang2023asymptotic} to get a reformulated model, which couples a
low dimension convection-diffusion-type equation for macroscopic quantities
with a high dimension transport equation for the radiative intensity.
  To recover the correct free streaming limit due to frequency-dependency, we
propose a correction to the reformulated macroscopic equation.
  The macroscopic system is solved using a hybrid method:
  convective fluxes are handled by a particle-based MC method, while diffusive
fluxes are treated implicitly with central difference.
  To address the nonlinear coupling between radiative intensity and the Planck
function across multiple frequency groups, we adopt a Picard iteration with a
predictor-corrector procedure, which decouples a global nonlinear system into a
linear system restricted to spatial dimension (independent of frequency) with
scalar algebraic nonlinear equations.
  Once the macroscopic update is done, the transport equation, with a known
emission source provided by the macroscopic variables, is efficiently solved
using an implicit MC method. This approach enables larger time steps
independent of the speed of light and also the frequency across a wide range,
significantly enhancing computational efficiency, especially for
frequency-dependent RTEs.
  Formal AP analysis in the diffusive scaling is established. Numerical
experiments are performed to demonstrate the high efficiency and AP property of
the proposed method.

</details>


### [4] [Fast reconstruction approaches for photoacoustic tomography with smoothing Sobolev/Matérn priors](https://arxiv.org/abs/2507.02401)
*Jaakko Kultima,Ronny Ramlau,Teemu Sahlström,Tanja Tarvainen*

Main category: math.NA

TL;DR: The paper explores the equivalence between deterministic and stochastic approaches in PAT, linking Matérn covariance operators to Sobolev embeddings, and proposes efficient wavelet-based implementations.


<details>
  <summary>Details</summary>
Motivation: To bridge deterministic (regularization) and stochastic (Bayesian) methods in PAT for solving the inverse problem of reconstructing initial pressure distributions.

Method: Establishes equivalence between Matérn covariance operators and Sobolev embeddings, and introduces a wavelet-based adjoint operator for efficient computation.

Result: Efficient implementations are achieved, validated through reconstructions in PAT.

Conclusion: The work successfully connects deterministic and stochastic frameworks, offering computationally efficient solutions for PAT.

Abstract: In photoacoustic tomography (PAT), the computation of the initial pressure
distribution within an object from its time-dependent boundary measurements
over time is considered. This problem can be approached from two
well-established points of view: deterministically using regularisation
methods, or stochastically using the Bayesian framework. Both approaches
frequently require the solution of a variational problem. In the paper we
elaborate the connection between these approaches by establishing the
equivalence between a smoothing Mat{\'e}rn class of covariance operators and
Sobolev embedding operator $E_s: H^s \hookrightarrow L^2$. We further discuss
the use of a Wavelet-based implementation of the adjoint operator $E_s^*$ which
also allows for efficient evaluations for certain Mat{\'e}rn covariance
operators, leading to efficient implementations both in terms of computational
effort as well as memory requirements. The proposed methods are validated with
reconstructions for the photoacoustic problem.

</details>


### [5] [A second-order and unconditionally stable time filtered scheme for the Cahn-Hilliard-Navier-Stokes system](https://arxiv.org/abs/2507.02402)
*Xi Li,Haijun Gao,Chunmei Xie,Minfu Feng*

Main category: math.NA

TL;DR: A novel low-complexity, second-order, energy-stable time-stepping scheme for the CHNS system is proposed using a time filter technique.


<details>
  <summary>Details</summary>
Motivation: To improve the temporal accuracy of the CHNS system discretization while maintaining energy stability and low computational complexity.

Method: Uses a first-order backward Euler method combined with a time filter to achieve second-order accuracy with minimal modifications.

Result: Unconditional energy stability and second-order temporal error estimations are proven, supported by numerical experiments.

Conclusion: The proposed scheme effectively enhances accuracy and stability for the CHNS system.

Abstract: In this work, we propose, analyze, and test a novel computational
low-complexity, linear, second-order, and unconditional energy-stable
semi-discrete time-stepping scheme for the Cahn-Hilliard-Navier-Stokes (CHNS)
system by employing the time filter technique. Firstly, the first-order
semi-implicit backward Euler (BE) method is utilized to discretize the CHNS
model; Secondly, the time filter, as a post-processing strategy, is
incorporated into the BE scheme, requiring only minimal modifications to the
existing BE framework to improve its temporal accuracy from first- to
second-order. The unconditional energy stability and second-order temporal
error estimations are obtained, and several numerical experiments are conducted
to verify the theoretical results.

</details>


### [6] [A modified Crank-Nicolson scheme for the Vlasov-Poisson system with a strong external magnetic field](https://arxiv.org/abs/2507.02459)
*Francis Filbet,L Miguel Rodrigues,Kim Han Trinh*

Main category: math.NA

TL;DR: A PIC method using Crank-Nicolson time discretization for the Vlasov-Poisson system with strong magnetic fields, focusing on poloidal motion, avoids stability constraints via guiding-center discretization.


<details>
  <summary>Details</summary>
Motivation: Address stability constraints in simulating particle motion under strong, inhomogeneous magnetic fields by developing a robust numerical method.

Method: Particle-In-Cell (PIC) method with Crank-Nicolson time discretization, adapted for guiding-center dynamics in poloidal directions.

Result: Theoretical proofs and numerical experiments validate the method's consistency and effectiveness.

Conclusion: The proposed method successfully overcomes stability constraints and accurately models particle motion in strong magnetic fields.

Abstract: We propose and study a Particle-In-Cell (PIC) method based on the
Crank-Nicolson time discretization for the Vlasov-Poisson system with a strong
and inhomogeneous external magnetic field with fixed direction, where we focus
on the motion of particles in the plane orthogonal to the magnetic field
(so-called poloidal directions). In this regime, the time step can be subject
to stability constraints related to the smallness of Larmor radius and plasma
frequency [21]. To avoid this limitation, our approach is based on numerical
schemes [9, 10, 12], providing a consistent PIC discretization of the
guiding-center system taking into account variations of the magnetic field. We
carry out some theoretical proofs and perform several numerical experiments to
validate the method and its underlying concepts.

</details>


### [7] [Goal-oriented optimal sensor placement for PDE-constrained inverse problems in crisis management](https://arxiv.org/abs/2507.02500)
*Marco Mattuschka,Noah An der Lan,Max von Danwitz,Daniel Wolff,Alexander Popp*

Main category: math.NA

TL;DR: A Bayesian framework for optimal sensor placement and steering in PDE-constrained inverse problems, validated for airborne contaminant tracking.


<details>
  <summary>Details</summary>
Motivation: To enhance real-time decision-making in crisis management by optimizing sensor placement and steering for accurate source identification and monitoring.

Method: Uses a Bayesian approach with low-rank approximations and a C-optimal design criterion for sensor placement and steering.

Result: Numerical experiments confirm the framework's effectiveness in reducing prediction uncertainty and improving computational efficiency.

Conclusion: The framework shows promise for real-time applications in complex geometries, advancing dynamic sensor steering methods.

Abstract: This paper presents a novel framework for goal-oriented optimal static sensor
placement and dynamic sensor steering in PDE-constrained inverse problems,
utilizing a Bayesian approach accelerated by low-rank approximations. The
framework is applied to airborne contaminant tracking, extending recent dynamic
sensor steering methods to complex geometries for computational efficiency. A
C-optimal design criterion is employed to strategically place sensors,
minimizing uncertainty in predictions. Numerical experiments validate the
approach's effectiveness for source identification and monitoring, highlighting
its potential for real-time decision-making in crisis management scenarios.

</details>


### [8] [On low-dimensional approximation of function spaces of interior regularity](https://arxiv.org/abs/2507.02655)
*S. Aziz,M. Bauer,M. Bebendorf,T. Rau*

Main category: math.NA

TL;DR: A new technique for constructing local approximation spaces for Lipschitz domains improves exponential convergence by using boundary approximations instead of eigenvalue problems.


<details>
  <summary>Details</summary>
Motivation: To enhance the relationship between dimensionality and convergence order in generalised finite element methods by exploiting interior regularity properties.

Method: Relies on extending approximations from the boundary, avoiding eigenvalue problems, and solving variational problems on simpler domains.

Result: Improved exponential convergence influenced by spatial dimension and easier construction of local spaces.

Conclusion: The new method offers a more efficient and practical approach for constructing local approximation spaces in elliptic boundary value problems.

Abstract: Many elliptic boundary value problems exhibit an interior regularity
property, which can be exploited to construct local approximation spaces that
converge exponentially within function spaces satisfying this property. These
spaces can be used to define local ansatz spaces within the framework of
generalised finite element methods, leading to a better relation between
dimensionality and convergence order. In this paper, we present a new technique
for the construction of such spaces for Lipschitz domains. Instead of the
commonly used approach based on eigenvalue problems it relies on extensions of
approximations performed on the boundary. Hence, it improves the influence of
the spatial dimension on the exponential convergence and allows to construct
the local spaces by solving the original kind of variational problems on easily
structured domains.

</details>


### [9] [High order uniform in time schemes for weakly nonlinear Schrödinger equation and wave turbulence](https://arxiv.org/abs/2507.02662)
*Quentin Chauleur,Antoine Mouzard*

Main category: math.NA

TL;DR: Two high-order multiscale schemes for weakly nonlinear Schrödinger equations are introduced, achieving precision under CFL conditions and uniform accuracy over long times.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of high-precision time integration for weakly nonlinear Schrödinger equations, especially under small nonlinearity parameters.

Method: Discretization of Picard iterates of the solution, leveraging scattering properties and low-frequency projected linear flow.

Result: High precision and uniform accuracy over long time horizons, validated by numerical simulations and applied to wave turbulence dynamics.

Conclusion: The schemes effectively integrate weakly nonlinear Schrödinger equations with high precision and long-term accuracy, demonstrating practical utility in wave turbulence studies.

Abstract: We introduce two multiscale numerical schemes for the time integration of
weakly nonlinear Schr\"odinger equations, built upon the discretization of
Picard iterates of the solution. These high-order schemes are designed to
achieve high precision with respect to the small nonlinearity parameter under
particular CFL condition. By exploiting the scattering properties of these
schemes thanks to a low-frequency projected linear flow, we also establish its
uniform accuracy over long time horizons. Numerical simulations are provided to
illustrate the theoretical results, and these schemes are further applied to
investigate dynamics in the framework of wave turbulence.

</details>


### [10] [Moments, Time-Inversion and Source Identification for the Heat Equation](https://arxiv.org/abs/2507.02677)
*Kang Liu,Enrique Zuazua*

Main category: math.NA

TL;DR: A novel moment-based approach for solving the ill-posed inverse problem of initial source identification in the heat equation, reducing exponential error growth to polynomial growth.


<details>
  <summary>Details</summary>
Motivation: The heat equation's initial source identification is highly unstable, requiring a more stable method than classical Tikhonov regularization.

Method: Transform the problem into an inverse moment formulation, recover moments via backward ODE evolution, and solve a convex optimization problem for source reconstruction.

Result: The method reduces error growth to polynomial rates, provides explicit error estimates, and demonstrates stability improvements in numerical experiments.

Conclusion: The moment-based approach offers a stable and efficient solution for the heat equation's inverse problem, with practical numerical advantages.

Abstract: We address the initial source identification problem for the heat equation, a
notably ill-posed inverse problem characterized by exponential instability.
Departing from classical Tikhonov regularization, we propose a novel approach
based on moment analysis of the heat flow, transforming the problem into a more
stable inverse moment formulation. By evolving the measured terminal time
moments backward through their governing ODE system, we recover the moments of
the initial distribution. We then reconstruct the source by solving a convex
optimization problem that minimizes the total variation of a measure subject to
these moment constraints. This formulation naturally promotes sparsity,
yielding atomic solutions that are sums of Dirac measures. Compared to existing
methods, our moment-based approach reduces exponential error growth to
polynomial growth with respect to the terminal time. We provide explicit error
estimates on the recovered initial distributions in terms of moment order,
terminal time, and measurement errors. In addition, we develop efficient
numerical discretization schemes and demonstrate significant stability
improvements of our approach through comprehensive numerical experiments.

</details>


### [11] [A $\mathcal{CR}$-rotated $Q_1$ nonconforming finite element method for Stokes interface problems on local anisotropic fitted mixed meshes](https://arxiv.org/abs/2507.02741)
*Geng Chenchen,Hua Wang,Fengren Zou*

Main category: math.NA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a new nonconforming finite element method for solving Stokes
interface problems. The method is constructed on local anisotropic mixed
meshes, which are generated by fitting the interface through simple connection
of intersection points on an interface-unfitted background mesh, as introduced
in \cite{Hu2021optimal}. For triangular elements, we employ the standard
$\mathcal{CR}$ element; for quadrilateral elements, a new rotated $Q_1$-type
element is used. We prove that this rotated $Q_1$ element remains unisolvent
and stable even on degenerate quadrilateral elements. Based on these
properties, we further show that the space pair of $\mathcal{CR}$-rotated $Q_1$
elements (for velocity) and piecewise $P_0$ spaces (for pressure) satisfies the
inf-sup condition without requiring any stabilization terms. As established in
our previous work \cite{Wang2025nonconforming}, the consistency error achieves
the optimal convergence order without the need for penalty terms to control it.
Finally, several numerical examples are provided to verify our theoretical
results.

</details>


### [12] [Uniform semiclassical observable error bound of Trotterization without the Egorov theorem: a simple algebraic proof](https://arxiv.org/abs/2507.02783)
*Di Fang,Conrad Qu*

Main category: math.NA

TL;DR: The paper presents a simple algebraic proof for uniform-in-$h$ error bounds in high-order Trotterization schemes for semiclassical Schrödinger equation observables, avoiding heavy semiclassical machinery.


<details>
  <summary>Details</summary>
Motivation: The motivation is to characterize observables with time-step-independent errors in semiclassical simulations and provide a simpler proof for uniform-in-$h$ error bounds.

Method: The method involves a new algebraic proof leveraging the structure of operators in continuous and discrete settings, avoiding Egorov-type theorems and semiclassical tools.

Result: The result is a uniform-in-$h$ error bound for high-order Trotterization schemes, applicable to a specific class of observables.

Conclusion: The conclusion highlights the simplicity and generality of the algebraic approach, marking the first proof of its kind without relying on semiclassical limits.

Abstract: Efficient simulation of the semiclassical Schr\"odinger equation has garnered
significant attention in the numerical analysis community. While controlling
the error in the unitary evolution or the wavefunction typically requires the
time step size to shrink as the semiclassical parameter $h$ decreases, it has
been observed -- and proved for first- and second-order Trotterization schemes
-- that the error in certain classes of observables admits a time step size
independent of $h$. In this work, we explicitly characterize this class of
observables and present a new, simple algebraic proof of uniform-in-$h$ error
bounds for arbitrarily high-order Trotterization schemes. Our proof relies
solely on the algebraic structure of the underlying operators in both the
continuous and discrete settings. Unlike previous analyses, it avoids
Egorov-type theorems and bypasses heavy semiclassical machinery. To our
knowledge, this is the first proof of uniform-in-$h$ observable error bounds
for Trotterization in the semiclassical regime that relies only on algebraic
structure, without invoking the semiclassical limit.

</details>


### [13] [Block triangular preconditioning for inverse source problems in time-space fractional diffusion equations](https://arxiv.org/abs/2507.02809)
*Monoswini Majumdar,Stefano Serra-Capizzano,Rosita L. Sormani*

Main category: math.NA

TL;DR: Block triangular preconditioners improve convergence and stability in solving inverse source problems for time-space fractional diffusion equations.


<details>
  <summary>Details</summary>
Motivation: Address the ill-posedness and computational challenges in solving inverse source problems for multi-dimensional fractional diffusion equations.

Method: Quasi-boundary value regularization, finite difference discretization, and block triangular preconditioning for structured linear systems.

Result: Preconditioner enhances GMRES solver performance, improving convergence rates, robustness, and accuracy.

Conclusion: The preconditioner is effective for large-scale inverse problems in fractional modeling.

Abstract: The current work investigates the effectiveness of block triangular
preconditioners in accelerating and stabilizing the numerical solution of
inverse source problems governed by time-space fractional diffusion equations
(TSFDEs). We focus on the recovery of an unknown spatial source function in a
multi-dimensional TSFDE, incorporating Caputo time-fractional derivatives and
the fractional Laplacian. The inherent ill-posedness is addressed via a
quasi-boundary value regularization, followed by a finite difference
discretization that leads to large, structured linear systems. We develop and
analyze a block triangular preconditioning strategy that mimics the coefficient
matrix, while simplifying its structure for computational efficiency. Numerical
experiments using the GMRES solver demonstrate that the proposed preconditioner
significantly improve convergence rates, robustness, and accuracy, making it
well-suited for large-scale, real-world inverse problems involving fractional
modeling.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [14] [Composite media, almost touching disks and the maximum principle](https://arxiv.org/abs/2507.02077)
*YanYan Li,Ben Weinkove*

Main category: math.AP

TL;DR: A gradient bound for two almost touching disks with finite conductivities is proven using the maximum principle.


<details>
  <summary>Details</summary>
Motivation: To analyze the behavior of elliptic equations with discontinuous coefficients in a domain with two nearly touching disks.

Method: Employ the maximum principle to derive a gradient bound, building on the work of Li-Vogelius.

Result: A new proof of the gradient bound for the given setting is provided.

Conclusion: The maximum principle offers a viable approach to proving gradient bounds in such configurations.

Abstract: We consider the setting of two disks in a domain in $\mathbb{R}^2$ which are
almost touching and have finite and positive conductivities, giving rise to a
divergence form elliptic equation with discontinuous coefficients. We use the
maximum principle to give a new proof of a gradient bound of Li-Vogelius.

</details>


### [15] [Tools for stability analysis of fractional reaction diffusion systems](https://arxiv.org/abs/2507.02094)
*Sofwah Ahmad,Szymon Cygan,Grzegorz Karch*

Main category: math.AP

TL;DR: The paper proves the linearization principle for abstract fractional reaction-diffusion equations with time-fractional derivatives and applies it to derive results like fractional Turing instability.


<details>
  <summary>Details</summary>
Motivation: To extend the linearization principle to fractional reaction-diffusion equations, bridging classical stability theory with fractional calculus.

Method: Proving the principle for abstract fractional equations and applying it to specific cases, including fractional Turing instability.

Result: The linearization principle holds for fractional reaction-diffusion equations, enabling stability analysis akin to classical cases.

Conclusion: The work successfully generalizes classical stability results to fractional frameworks, with implications for fractional dynamical systems.

Abstract: The linearization principle states that the stability (or instability) of
solutions to a suitable linearization of a nonlinear problem implies the
stability (or instability) of solutions to the original nonlinear problem. In
this work, we prove this principle for solutions of abstract fractional
reaction-diffusion equations with a fractional derivative in time of order
$\alpha\in (0,1)$. Then, we apply these results to particular fractional
reaction-diffusion equations, obtaining, for example, the counterpart of the
classical Turing instability in the case of fractional equations.

</details>


### [16] [Global existence of the solution of the modified Camassa-Holm equation with step-like boundary conditions](https://arxiv.org/abs/2507.02100)
*I. Karpenko,D. Shepelsky,G. Teschl*

Main category: math.AP

TL;DR: The paper studies the global existence of solutions for the modified Camassa-Holm equation with step-like initial data.


<details>
  <summary>Details</summary>
Motivation: To address the Cauchy problem for the modified Camassa-Holm equation and ensure global solution existence under step-like initial conditions.

Method: Analyzes the equation with step-like initial data where the solution approaches different constants at infinities.

Result: Establishes the global existence of the solution for the given problem.

Conclusion: The modified Camassa-Holm equation with step-like initial data admits a global solution.

Abstract: We consider the Cauchy problem for
  the modified Camassa-Holm equation
  \[
  u_t+\left((u^2-u_x^2)m\right)_x=0,\quad
  m\coloneqq u-u_{xx},
  \quad t>0,\ \ -\infty<x<+\infty
  \]
  subject to the step-like initial data: $u(x,0)\to A_1$ as $x\to-\infty$ and
$u(x,0)\to A_2$ as $x\to+\infty$, where $0<A_1<A_2$.
  The goal is to
  establish the global existence of the solution of this problem.

</details>


### [17] [Traveling Wave Solutions to a Large Class of Brenner-Navier-Stokes-Fourier Systems](https://arxiv.org/abs/2507.02224)
*Saehoon Eo,Namhyun Eun*

Main category: math.AP

TL;DR: The paper analyzes the one-dimensional Brenner-Navier-Stokes-Fourier (BNSF) system with temperature-dependent transport coefficients, proving existence and uniqueness of small-amplitude viscous shocks using geometric singular perturbation theory and the implicit function theorem.


<details>
  <summary>Details</summary>
Motivation: Address deficiencies in the classical Navier-Stokes-Fourier system by introducing the BNSF framework, motivated by prior work on contraction properties of solutions around traveling waves.

Method: Utilizes geometric singular perturbation theory and the implicit function theorem to handle nonlinearities in temperature-dependent coefficients, ensuring robustness.

Result: Existence and uniqueness of monotone traveling wave solutions (viscous shocks) for the BNSF system with small shock amplitudes and positive C² dissipation coefficients.

Conclusion: The study provides quantitative estimates for traveling wave solutions, supporting prior work on solution contraction properties, and advances the physical realism of the BNSF system.

Abstract: The Brenner-Navier-Stokes-Fourier (BNSF) system, introduced by Howard
Brenner, was developed to address some deficiencies in the classical
Navier-Stokes-Fourier system, based on the concept of volume velocity. We
consider the one-dimensional BNSF system in Lagrangian mass coordinates,
incorporating temperature-dependent transport coefficients, which yields a more
physically realistic framework. We establish the existence and uniqueness of
monotone traveling wave solutions (or viscous shocks) to the BNSF system with
any positive $C^2$ dissipation coefficients, provided that the shock amplitude
is sufficiently small. We utilize geometric singular perturbation theory as in
the constant coefficient case [13]; however, due to the arbitrary
nonlinearities of the coefficients, we employ the implicit function theorem,
which grants robustness to our approach. This work is motivated by [12], which
proves a contraction property of any large solutions to the BNSF system around
the traveling wave solutions. Thus, we also derive some quantitative estimates
on the traveling wave solutions that play a fundamental role in [12].

</details>


### [18] [Analysis and Numerical Approximation to Interactive Dynamics of Navier Stokes-Plate Interaction PDE System](https://arxiv.org/abs/2507.02230)
*Pelin G. Geredeli,Quyuan Lin,Dylan Mcknight,Mohammad Mahabubur Rahman*

Main category: math.AP

TL;DR: The paper analyzes a fluid-plate interaction system, proving well-posedness of weak solutions and providing a FEM-based numerical approximation with error bounds.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by applications in aeroelasticity, biomedical fields, and control of phenomena like sloshing and ocular pressure.

Method: Theoretical analysis uses a variational approach for existence-uniqueness of solutions. Numerically, a FEM scheme with Picard iterations is employed.

Result: Existence-uniqueness of solutions is proven under small data assumptions. Numerical results validate the theory with error bounds in Sobolev norms.

Conclusion: The FEM approximations and theoretical results align, confirming the validity of the approach for the coupled system.

Abstract: We consider a Navier-Stokes fluid-plate interaction (FSI) system which
describes the evolutions of the fluid contained within a 3D cavity, as it
interacts with a deformable elastic membrane on the ``free" upper boundary of
the cavity. These models arise in various aeroelastic and biomedical
applications as well as in the control of ocular pressure, and sloshing
phenomena. We analyze the well-posedness of weak solutions to the stationary
($\lambda$-parametrized) coupled PDE system by way of invoking the nonlinear
generalization of the abstract variational formulations which was introduced in
\cite{girault2012finite}, wherein an inf-sup approach is followed to show
existence-uniqueness of solutions under a small data assumption.
  In addition, we provide a numerical approximation scheme of the infinite
dimensional coupled system via a finite element method approximation (FEM). The
numerical results use a standard conforming scheme and handle the introduced
nonlinearities via Picard iterations. Numerical results are obtained for an
appropriate test problem satisfying the necessary boundary conditions and
coupling. Moreover, error bounds between the FEM and theoretical solution in
terms of the characteristic mesh size are supplied in appropriate Sobolev norms
which agree with the established literature. These FEM approximations of the
coupled system with their associated error bounds validate the theoretical
findings.

</details>


### [19] [Ill-posedness of the Euler equations and inviscid limit of the Navie-Stokes equations in Besov spaces](https://arxiv.org/abs/2507.02247)
*Jinlu Li,Xing Wu,Yanghai Yu*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we consider the Cauchy problem to the incompressible Euler and
Navie-Stokes equations on the d-dimensional torus.Our aim of this paper is two
fold. Firstly, we construct a new initial data and present a simple proof of
the ill-posedness of the Euler equations in different senses: (1) the solution
map of the Euler equations starting from $u_0$ is discontinuous at $t = 0$ in
$B^s_{p,\infty}$ with $s>0$ and $1\leq p \leq \infty$, which covers the result
obtained by Cheskidov and Shvydkoy in ;(2) the solution map of the Euler
equations is not continuous as a map from $B^s_{p,\infty}$ to
$L^\infty_T(B^s_{p,\infty})$;(3) the solution map of the Euler equations cannot
be Holder continuous in time variable in Besov spaces $B^s_{p,r}$.

</details>


### [20] [Trapping by repulsion: the NLS with a delta-prime](https://arxiv.org/abs/2507.02330)
*Riccardo Adami,Filippo Boni,Matteo Gallone*

Main category: math.AP

TL;DR: Existence and explicit forms of stationary states for a 1D Schrödinger equation with a repulsive delta-prime potential and focusing nonlinearity are established. Ground states exist for subcritical nonlinearity, explained by an emergent energy space dimension.


<details>
  <summary>Details</summary>
Motivation: To explore ground states in repulsive potentials, a counterintuitive phenomenon, and understand their origin via the delta-prime interaction.

Method: Minimizing the action functional on the Nehari manifold in subcritical, critical, and supercritical regimes.

Result: Ground states exist for any delta-prime strength and positive mass in subcritical cases, with explicit forms derived.

Conclusion: The delta-prime interaction induces a new energy dimension, enabling ground states in repulsive potentials, solved via action minimization.

Abstract: We establish the existence and provide explicit expressions for the
stationary states of the one-dimensional Schr\"odinger equation with a
repulsive delta-prime potential and a focusing nonlinearity of power type.
Furthermore, we prove that, if the nonlinearity is subcritical, then ground
states exist for any strength of the delta-prime interaction and for every
positive value of the mass.
  This result supplies an example of ground states arising from a repulsive
potential, a counterintuitive phenomenon explained by the emergence of an
additional dimension in the energy space, induced by the delta-prime
interaction. This new dimension contains states of lower energy and is thus
responsible for the existence of nonlinear ground states that do not originate
from linear eigenfunctions.
  The explicit form of the ground states is derived by addressing the ancillary
problem of minimizing the action functional on the Nehari manifold. We solve
such problem in the subcritical, critical, and supercritical regimes.

</details>


### [21] [Self-similar vorticity around the boundary and non-uniqueness of solutions to the two-dimensional Navier-Stokes equations in the half space](https://arxiv.org/abs/2507.02338)
*Motofumi Aoki,Yasunori Maekawa*

Main category: math.AP

TL;DR: The paper demonstrates non-uniqueness of mild solutions to 2D forced Navier-Stokes equations in half-space with no-slip boundary, leveraging self-similar vorticity instability at high Reynolds numbers near the boundary.


<details>
  <summary>Details</summary>
Motivation: To extend the understanding of non-uniqueness in fluid dynamics by focusing on boundary effects, contrasting prior work where vorticity was distant from boundaries.

Method: Constructs non-unique solutions by analyzing instability of self-similar vorticity near the boundary at high Reynolds numbers, incorporating boundary layer effects.

Result: Shows non-uniqueness of mild solutions, highlighting the role of boundary proximity in vorticity instability.

Conclusion: Boundary proximity significantly impacts solution uniqueness in Navier-Stokes equations, differing from cases where vorticity is away from boundaries.

Abstract: In this paper we show the non-uniqueness of mild solutions to the
two-dimensional forced Navier-Stokes equations in the half space under the
noslip boundary condition, following the program established by Albritton,
Bru{\'e}, and Colombo in 2022. Our construction of non-unique solutions is
based on the instability of self-similar vorticity at high Reynolds numbers
which concentrates around the boundary at the initial time. In our
construction, therefore, a kind of boundary layer has to be taken into account
in the analysis, contrasting to the known results where the unstable
self-similar vorticity is located away from the boundary with $O(1)$ distance
around the initial time.

</details>


### [22] [A field-road system with a rectifiable set](https://arxiv.org/abs/2507.02451)
*Matthieu Bonnivard,Romain Ducasse,Antoine Lemenant,Alessandro Zilio*

Main category: math.AP

TL;DR: The paper defines a 2D field-road system with a 1D-rectifiable road, introducing a framework for coupled parabolic problems on and off the road.


<details>
  <summary>Details</summary>
Motivation: To model and analyze systems where a road (1D-rectifiable set) interacts with its surrounding field (2D space) through coupled parabolic problems.

Method: Introduces a general setting for defining parabolic problems on a rectifiable set, coupled with classical parabolic problems outside the set, including transmission conditions.

Result: A theoretical framework for analyzing field-road systems with coupled parabolic equations is established.

Conclusion: The paper provides a foundation for studying interactions between 1D-rectifiable roads and 2D fields using coupled parabolic problems.

Abstract: The aim of this paper is to define a field-road system in 2D where the road
is a merely 1D-rectifiable set. For this purpose we introduce a general setting
in order to define a parabolic problem onto a rectifiable set, which is coupled
with another more classical parabolic problem outside this set, with
transmission conditions.

</details>


### [23] [Global Existence and Incompressible Limit for Compressible Navier-Stokes Equations in Bounded Domains with Large Bulk Viscosity Coefficient and Large Initial Data](https://arxiv.org/abs/2507.02462)
*Qinghao Lei,Chengfeng Xiong*

Main category: math.AP

TL;DR: Global existence and exponential decay of solutions for compressible Navier-Stokes equations with large bulk viscosity, converging to incompressible solutions as viscosity tends to infinity.


<details>
  <summary>Details</summary>
Motivation: To study the behavior of compressible Navier-Stokes equations with vanishing initial density and Navier-slip boundary conditions in 2D domains.

Method: Use logarithmic interpolation inequality and compensated compactness lemma to analyze solutions.

Result: Global existence and exponential decay of weak, strong, and classical solutions without initial data size restrictions.

Conclusion: Solutions converge to inhomogeneous incompressible Navier-Stokes solutions as bulk viscosity increases.

Abstract: We investigate the barotropic compressible Navier-Stokes equations with the
Navier-slip boundary conditions in a general two-dimensional bounded simply
connected domain. For initial density that is allowed to vanish, we establish
the global existence and exponential decay of weak, strong, and classical
solutions when the bulk viscosity coefficient is suitably large, without any
restrictions on the size of the initial data. Furthermore, we prove that when
the bulk viscosity coefficient tends to infinity, the solutions of the
compressible Navier-Stokes equations converge to those of the inhomogeneous
incompressible Navier-Stokes equations. The key idea is to utilize the
logarithmic interpolation inequality on general bounded domains and apply the
compensated compactness lemma.

</details>


### [24] [Renormalized variational principles and Hardy-type inequalities](https://arxiv.org/abs/2507.02486)
*Satyanad Kichenassamy*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Let $\Omega\subset{\mathbb R}^2$ be a bounded domain on which Hardy's
inequality holds. We prove that $[\exp(u^2)-1]/\delta^2\in L^1(\Omega)$ if
$u\in H^1_0(\Omega)$, where $\delta$ denotes the distance to $\partial\Omega$.
The corresponding higher-dimensional result is also given. These results
contain both Hardy's and Trudinger's inequalities, and yield a new variational
characterization of the maximal solution of the Liouville equation on smooth
domains, in terms of a renormalized functional. A global $H^1$ bound on the
difference between the maximal solution and the first term of its asymptotic
expansion follows.

</details>


### [25] [Long-time Existence and Incompressible Limit of Weak and Classical Solutions to the Cauchy Problem for Compressible Navier-Stokes Equations with Large Bulk Viscosity Coefficient and Large Initial Data](https://arxiv.org/abs/2507.02497)
*Qinghao Lei,Chengfeng Xiong*

Main category: math.AP

TL;DR: The paper studies the Cauchy problem for barotropic compressible Navier-Stokes equations in 2D, proving long-time existence of solutions (weak, strong, classical) with large bulk viscosity. It also shows convergence to incompressible Navier-Stokes solutions as viscosity tends to infinity, even without divergence-free initial velocity.


<details>
  <summary>Details</summary>
Motivation: To address the Cauchy problem for compressible Navier-Stokes equations with vacuum or nonvacuum far fields, overcoming the challenge posed by the failure of Poincaré's inequality.

Method: Assumes a sufficiently large bulk viscosity coefficient and uses a time-dependent Poincaré-type inequality with weighted-integrability conditions on initial density.

Result: Establishes long-time existence of solutions and their convergence to incompressible Navier-Stokes solutions as bulk viscosity tends to infinity.

Conclusion: The approach resolves the Poincaré inequality issue and extends results to cases without divergence-free initial velocity, providing a broader framework for analysis.

Abstract: This paper investigates the Cauchy problem for the barotropic compressible
Navier-Stokes equations in $\mathbb{R}^2$ with the constant state as far field,
which could be vacuum or nonvacuum. Under the assumption of a sufficiently
large bulk viscosity coefficient, we establish the long-time existence of weak,
strong, and classical solutions, without imposing any extra restrictions on the
initial velocity divergence. Moreover, we demonstrate that the solutions of the
compressible Navier-Stokes equations converge to solutions of the inhomogeneous
incompressible Navier-Stokes equations, as the bulk viscosity coefficient tends
to infinity. The incompressible limit of the weak solutions holds even without
requiring the initial velocity to be divergence-free. The key obstacle in the
Cauchy problem is the failure of the Poincar\'e's inequality. This could be
resolved by introducing a time-dependent Poincar\'e's type inequality, but it
needs imposing weighted-integrability conditions on the initial density.

</details>


### [26] [Sharp second order inequalities with distance function to the boundary and applications to a p-Biharmonic singular problem](https://arxiv.org/abs/2507.02551)
*Cristian Cazacu,Teodor Rugină*

Main category: math.AP

TL;DR: Generalizations of Hardy-Rellich inequalities in L^p for domains with boundary distance singularities, with sharp results in bounded domains and new bounds for sharp constants. Applications include variational methods for singular problems.


<details>
  <summary>Details</summary>
Motivation: Extend Hardy-Rellich inequalities to L^p settings and explore their sharpness and dependence on domain geometry, with applications to singular problems.

Method: Prove inequalities using distance-to-boundary singularity, provide minimizing sequences, and apply variational methods and Pohozaev identity.

Result: Sharp inequalities in bounded domains, new bounds for sharp constants, and insights into existence/non-existence of solutions for singular problems.

Conclusion: The work extends Hardy-Rellich inequalities, provides sharp results, and applies them to variational problems, enhancing understanding of singularities and domain geometry.

Abstract: In this paper, we prove generalizations to the L^p setting of the
Hardy-Rellich inequalities on domains of R^N with singularity given by the
distance function to the boundary. The inequalities we obtain are either sharp
in bounded domains, where we provide concrete minimizing sequences, or give a
new bound for the sharp constant, while also depending on the geometric
properties of the domain and its boundary. We also give applications to the
existence and non-existence of solutions for a singular problem using
variational methods and a Pohozaev identity.

</details>


### [27] [Homogenisation and spectral convergence of high-contrast convolution type operators](https://arxiv.org/abs/2507.02638)
*Mikhail Cherdantsev,Andrey Piatnitski,Igor Velcic*

Main category: math.AP

TL;DR: The paper studies homogenization of high-contrast symmetric convolution-type operators in periodic microstructures, using two-scale convergence for spectral analysis.


<details>
  <summary>Details</summary>
Motivation: To analyze homogenization and spectral behavior of nonlocal convolution-type operators in periodic media.

Method: Adapts two-scale convergence method for nonlocal operators, examining problems in whole space and bounded domains with Dirichlet conditions.

Result: Shows the limit operator's spectrum is a subset of the original operator's spectrum, not necessarily equal.

Conclusion: The homogenization approach reveals spectral properties of high-contrast operators, with implications for nonlocal problems.

Abstract: The paper deals with homogenisation problems for high-contrast symmetric
convolution-type operators with integrable kernels in media with a periodic
microstructure. We adapt the two-scale convergence method to nonlocal
convolution-type operators and obtain the homogenisation result both for
problems stated in the whole space and in bounded domains with the homogeneous
Dirichlet boundary condition.
  Our main focus is on spectral analysis. We describe the spectrum of the limit
two-scale operator and characterize the limit behaviour of the spectrum of the
original problem as the microstructure period tends to zero. It is shown that
the spectrum of the limit operator is a subset the limit of the spectrum of the
original operator, and that they need not coincide.

</details>


### [28] [On the two-dimensional Navier-Stokes equations with horizontal viscosity](https://arxiv.org/abs/2507.02775)
*Chongsheng Cao,Yanqiu Guo*

Main category: math.AP

TL;DR: Study of 2D channel flow with horizontal viscosity, focusing on well-posedness, long-term behavior, and stability under minimal initial differentiability.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of 2D channel flows with horizontal viscosity and reduced initial smoothness assumptions.

Method: Analyze solutions assuming initial velocity components and partial derivatives lie in L² space.

Result: Establishes global well-posedness and stability under minimal initial conditions.

Conclusion: The study confirms well-posedness and stability for 2D channel flows with horizontal viscosity under less stringent initial conditions.

Abstract: This paper is concerned with a 2D channel flow that is periodic horizontally
but bounded above and below by hard walls. We assume the presence of horizontal
viscosity only. We study the well-posedness, large-time behavior, and stability
of solutions. For global well-posedness, we aim to assume less
differentiability on initial velocity $(u_0, v_0)$: in particular, we assume
$u_0,v_0\in L^2(\Omega)$ and $\partial_y u_0 \in L^2(\Omega)$.

</details>


### [29] [Vanishing Vertical Viscosity in Two-Dimensional Anisotropic Navier-Stokes Equations with No-Slip Boundary Conditions: An $L^p$ result](https://arxiv.org/abs/2507.02794)
*Chongsheng Cao,Yanqiu Guo*

Main category: math.AP

TL;DR: The paper examines the inviscid limit for 2D Navier-Stokes equations with anisotropic viscosity, proving strong convergence in $L^p$ norm as vertical viscosity vanishes.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of boundary condition mismatch (no-slip vs. slip) in the inviscid limit problem.

Method: Analyzes the 2D Navier-Stokes equations with anisotropic viscosity and $H^2$ initial velocity, focusing on convergence as vertical viscosity approaches zero.

Result: Establishes strong $L^p$ norm convergence for $2 \leq p < \infty$ to the limiting problem.

Conclusion: The study successfully resolves the boundary condition mismatch issue, proving convergence under the given conditions.

Abstract: This paper studies the inviscid limit problem for the two-dimensional
Navier-Stokes equations with anisotropic viscosity. The fluid is assumed to be
bounded above and below by impenetrable walls, with a no-slip boundary
condition imposed on the bottom wall. For $H^2$ initial velocity, we establish
strong convergence in the $L^p$ norm to the limiting problem as the vertical
viscosity approaches zero, for any $2\leq p <\infty$. The main challenge lies
in the mismatch of boundary conditions - specifically, the no-slip condition in
the original problem versus the slip condition in the limiting problem.

</details>


### [30] [On the Boundary Harnack Principle for operators with different lower order terms](https://arxiv.org/abs/2507.02836)
*Daniela De Silva,Ovidiu Savin*

Main category: math.AP

TL;DR: Classical Boundary Harnack principle extended to Lipschitz domains for solutions of two linear elliptic equations with identical principal parts.


<details>
  <summary>Details</summary>
Motivation: To generalize the Boundary Harnack principle to cases involving two distinct linear elliptic equations sharing the same principal part, ensuring broader applicability.

Method: Analyze solutions in Lipschitz domains for two linear uniformly elliptic equations with matching principal terms.

Result: Established the Boundary Harnack principle for such pairs of equations, demonstrating its validity under the given conditions.

Conclusion: The principle holds for solutions of two different linear elliptic equations with identical principal parts in Lipschitz domains, expanding its theoretical scope.

Abstract: We provide the classical Boundary Harnack principle in Lipschitz domains for
solutions to two different linear uniformly elliptic equations with the same
principal part.

</details>


### [31] [Free boundary regularity for a tumor growth model with obstacle](https://arxiv.org/abs/2507.02837)
*Giulia Bevilacqua,Matteo Carducci*

Main category: math.AP

TL;DR: Existence and regularity theory for solutions to a tumor growth model's free boundary problem, addressing obstacle penetration and non-variational structure.


<details>
  <summary>Details</summary>
Motivation: Model tumor growth where the tumor invades region D, moves along vector V, and avoids obstacle K, requiring analysis of free boundary behavior.

Method: Uses Perron's method for existence of viscosity solutions, improvement of flatness for interior regularity, and studies a thin obstacle problem for boundary regularity.

Result: Existence of solutions proven; interior and boundary regularity established, with free boundary meeting obstacle as a C^{1,α} graph.

Conclusion: The theory provides rigorous analysis of tumor growth dynamics with obstacles, offering insights into free boundary regularity.

Abstract: We develop an existence and regularity theory for solutions to a geometric
free boundary problem motivated by models of tumor growth. In this setting, the
tumor invades an accessible region $D$, its motion is directed along a constant
vector $V$, and it cannot penetrate another region $K$ acting as an obstacle to
the spread of the tumor. Due to the non variational structure of the problem,
we show existence of viscosity solutions via Perron's method. Subsequently, we
prove interior regularity for the free boundary near regular points by means of
an improvement of flatness argument. We further analyze the boundary regularity
and we prove that the free boundary meets the obstacle as a $C^{1,\alpha}$
graph. A key step in the analysis of the boundary regularity involves the study
of a thin obstacle problem with oblique boundary conditions, for which we
establish $C^{1,\alpha}$ estimates.

</details>


### [32] [Diffeomorphic approximation of piecewise affine homeomorphisms](https://arxiv.org/abs/2507.02854)
*Daniel Campbell,Luigi D'Onofrio,Tomáš Vítek*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Given any $f$ a locally finitely piecewise affine homeomorphism of $\Omega
\subset \mathbb{R}^d$ onto $\Delta \subset \mathbb{R}^d$ (for $d=3, 4$) such
that $f\in W^{1,p}(\Omega, \mathbb{R}^d)$ and $f^{-1}\in W^{1,q}(\Delta,
\mathbb{R}^d)$, $1\leq p ,q < \infty$ and any $\epsilon >0$ we construct a
diffeomorphism $\tilde{f}$ such that
  $$\|f-\tilde{f}\|_{W^{1,p}(\Omega,\mathbb{R}^d)} +
\|f^{-1}-\tilde{f}^{-1}\|_{W^{1,q}(\Delta,\mathbb{R}^d)} < \epsilon.$$

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [33] [A Multi-Level Monte Carlo Tree Search Method for Configuration Generation in Crystalline Systems](https://arxiv.org/abs/2507.02509)
*Xiaoxu Li,Ge Xu,Huajie Chen,Xingyu Gao,Haifeng Song*

Main category: physics.comp-ph

TL;DR: A multi-level Monte Carlo tree search algorithm is developed to efficiently identify optimal atomic configurations in crystalline materials with substitutional defects.


<details>
  <summary>Details</summary>
Motivation: Predicting and designing atomic structures in crystalline materials is challenging due to combinatorial growth and rugged landscapes.

Method: A hierarchical decomposition of the crystalline structure is combined with random sampling in a Monte Carlo tree search to explore configurations.

Result: Numerical experiments show the method efficiently identifies optimal configurations in typical crystalline systems.

Conclusion: The proposed algorithm effectively addresses the challenges of exploring and optimizing atomic configurations in defective crystalline materials.

Abstract: In this paper, we study the construction of structural models for the
description of substitutional defects in crystalline materials. Predicting and
designing the atomic structures in such systems is highly challenging due to
the combinatorial growth of atomic arrangements and the ruggedness of the
associated landscape. We develop a multi-level Monte Carlo tree search
algorithm to generate the "optimal" configuration within a supercell. Our
method explores the configuration space with an expanding search tree through
random sampling, which further incorporates a hierarchical decomposition of the
crystalline structure to accelerate exploration and reduce redundancy. We
perform numerical experiments on some typical crystalline systems to
demonstrate the efficiency of our method in identifying optimal configurations.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [34] [Impact of super-Gaussian electron distributions on plasma K-shell emission](https://arxiv.org/abs/2507.02341)
*H. P. Le,E. V. Marley,H. A. Scott*

Main category: physics.plasm-ph

TL;DR: The paper explores how super-Gaussian electron distributions in laser-produced plasmas affect ionization balance and K-shell emission, showing significant spectral modifications useful for inferring non-equilibrium distributions.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of super-Gaussian electron distributions on fundamental plasma properties, particularly ionization balance and K-shell emission.

Method: Uses approximate formulas and detailed collisional-radiative simulations to analyze effects on ionization and K-shell spectra.

Result: Super-Gaussian distributions minimally affect plasma ionization but significantly modify K-shell spectra.

Conclusion: K-shell spectroscopy can infer non-equilibrium electron distributions like super-Gaussian.

Abstract: Electron distributions in laser-produced plasmas will be driven toward a
super-Gaussian distribution due to inverse bremsstrahlung absorption [Langdon,
Phys. Rev. Lett. 44, 575 (1980)]. Both theoretical and experimental evidence
suggest that fundamental plasma properties are altered by the super-Gaussian
distribution. This paper examines how the super-Gaussian distribution affects
the ionization balance and K-shell emission of atomic plasmas, utilizing
approximate formulas and detailed collisional-radiative simulations. While the
impact on plasma ionization is small, K-shell spectra can be significantly
modified. Based on these findings, we demonstrate that K-shell spectroscopy can
be used to infer super-Gaussian or other similar non-equilibrium electron
distributions.

</details>


### [35] [Electron heating in bulk overdense plasma aided by time dependent external magnetic field](https://arxiv.org/abs/2507.02543)
*Rohit Juneja,Trishul Dhalia,Amita Das*

Main category: physics.plasm-ph

TL;DR: The study explores localized electron heating in overdense plasma using a time-dependent magnetic field, achieving Electron Cyclotron Resonance (ECR) with laser energy transfer to electrons via PIC simulations.


<details>
  <summary>Details</summary>
Motivation: To investigate efficient electron heating in overdense plasma by leveraging magnetized dispersion and ECR, addressing challenges in laser-plasma interactions.

Method: Uses a decaying external magnetic field to enable laser propagation and achieve ECR, simulated via Particle-In-Cell (PIC) techniques on OSIRIS4.0.

Result: Demonstrates electron energy gain under varied magnetic field profiles, laser intensities, and polarizations, with potential experimental feasibility using CO$_2$ lasers and high magnetic fields.

Conclusion: The method shows promise for future experiments, supported by advancements in generating high magnetic fields (~1.4 kilo Tesla).

Abstract: This study investigates the localized electron heating in a bulk overdense
plasma. The method relies on using a time dependent magnetic field. An
initially high external magnetic field imposed on the overdense plasma target
enables the propagation of a laser pulse inside it through the pass bands that
occur in the magnetized dispersion relation. The choice of decaying external
magnetic field is then tailored appropriately to achieve Electron Cyclotron
Resonance (ECR) with the frequency of the laser electromagnetic field. At the
resonance location, the field energy of the laser gets transferred to the
electrons. These studies have been carried out with the help of the
Particle-In-Cell (PIC) simulation technique on the OSIRIS4.0 platform. A
detailed study has been carried out to illustrate the energy gain by electrons
for a variety of temporal profiles of the magnetic field, laser intensities,
and polarizations. The experiments in this regime may be within reach in the
near future. For instance, the choice of long-wavelength CO$_2$ laser requires
a magnetic field of about 10s of kilo Tesla to comfortably elicit a magnetized
response from electrons. Recent technological advancements have shown the
generation of about 1.4 kilo Tesla of magnetic field.

</details>


### [36] [Boosting the NOx production in microwave air plasma: A synergy of chemistry and vibrational kinetics](https://arxiv.org/abs/2507.02795)
*Qinghao Shen,Aleksandr Pikalev,Jonas Gans,Lex Kuijpers,Ashley Hughes,Vasco Guerra,M. C. M van de Sanden*

Main category: physics.plasm-ph

TL;DR: The study uses a quasi-1.5D model to analyze NOx production in microwave plasma reactors, revealing non-thermal processes enhance NOx in the discharge zone but diminish in the afterglow. Turbulence aids NO diffusion and cooling, suggesting efficiency improvements via turbulence optimization.


<details>
  <summary>Details</summary>
Motivation: To understand the mechanisms of NOx production and energy costs in microwave plasma reactors, focusing on vibrational, chemical, and electron kinetics.

Method: A quasi-1.5D multi-temperature model is employed to simulate the discharge and afterglow regions, analyzing vibrational, chemical, and electron kinetics alongside thermodynamics and transport processes.

Result: Non-thermal processes boost NOx production in the discharge zone but fade in the afterglow. Turbulence enhances NO diffusion and cooling, with simulations matching experimental data.

Conclusion: Optimizing turbulence and maintaining non-thermal conditions can improve NOx synthesis efficiency, advancing plasma-based chemical processes.

Abstract: This study employs a quasi-1.5D multi-temperature model to investigate the
mechanisms governing NOx production and energy costs in microwave plasma
reactors operating at 80 mbar, focusing on the interplay of vibrational,
chemical and electron kinetics, thermodynamics, and transport processes across
the discharge and afterglow. In the plasma discharge zone, non-thermal
processes enhance NOx production as electrons transfer energy effectively to
the vibrational mode of N2. However, the non-thermal enhancement is found to
diminish rapidly within the central-afterglow region. The simulation results
show good agreement with experimental data for both the temperature profile and
energy cost. Turbulent effects facilitate radial NO diffusion into cooler
regions while simultaneously enhancing cooling of the axial region. These
findings highlight the potential to improve NOx synthesis efficiency by
optimizing turbulence and maintaining non-thermal conditions, offering new
opportunities for the advancement of plasma-based chemical processes.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [37] [Hybrid least squares for learning functions from highly noisy data](https://arxiv.org/abs/2507.02215)
*Ben Adcock,Bernhard Hientzsch,Akil Narayan,Yiming Xu*

Main category: stat.ML

TL;DR: A hybrid method combining Christoffel sampling and optimal experimental design is proposed for efficient conditional expectation estimation with noisy data, outperforming existing methods in high-noise scenarios.


<details>
  <summary>Details</summary>
Motivation: The need for efficient estimation of conditional expectations in the presence of heavily polluted data, where existing methods underperform.

Method: A hybrid approach integrating Christoffel sampling and optimal experimental design, extended to convex-constrained settings and adaptive random subspaces.

Result: Improved computational efficiency, sample complexity, and theoretical guarantees, validated by synthetic and real-world data.

Conclusion: The proposed method effectively addresses high-noise challenges and extends to broader settings with robust performance.

Abstract: Motivated by the need for efficient estimation of conditional expectations,
we consider a least-squares function approximation problem with heavily
polluted data. Existing methods that are powerful in the small noise regime are
suboptimal when large noise is present. We propose a hybrid approach that
combines Christoffel sampling with certain types of optimal experimental design
to address this issue. We show that the proposed algorithm enjoys appropriate
optimality properties for both sample point generation and noise mollification,
leading to improved computational efficiency and sample complexity compared to
existing methods. We also extend the algorithm to convex-constrained settings
with similar theoretical guarantees. When the target function is defined as the
expectation of a random field, we extend our approach to leverage adaptive
random subspaces and establish results on the approximation capacity of the
adaptive procedure. Our theoretical findings are supported by numerical studies
on both synthetic data and on a more challenging stochastic simulation problem
in computational finance.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [38] [Langmuir Wave Excitation in Solar-wind Magnetic Holes](https://arxiv.org/abs/2507.02042)
*Jingting Liu,Daniel Verscharen,Jesse Coburn,Georgios Nicolaou,Xiangyu Wu,Wence Jiang,Oreste Pezzi,Francesco Pucci,Matteo Zuin,Christopher J. Owen,Hamish Reid*

Main category: physics.space-ph

TL;DR: The paper explains how magnetic holes in the solar wind excite Langmuir waves via a bump-on-tail instability, supported by Solar Orbiter data.


<details>
  <summary>Details</summary>
Motivation: To understand the correlation between magnetic holes and Langmuir waves in the solar wind.

Method: Developed a model based on magnetic-moment conservation and its violation, tested with Solar Orbiter observations.

Result: The model aligns with observations, confirming the mechanism for Langmuir wave excitation.

Conclusion: The proposed process is a viable explanation for Langmuir waves in solar wind magnetic holes.

Abstract: Magnetic holes are structures commonly observed in various space plasma
environments throughout the solar system, including the solar wind. These
structures are characterized by a localized decrease in magnetic field
strength, coincident with an increase in plasma density. Previous observational
studies in the solar wind link the presence of Langmuir waves to magnetic
holes, suggesting a strong correlation between these phenomena. We develop a
model based on magnetic-moment conservation and its violation to explain the
excitation of Langmuir waves in magnetic holes. Our model illustrates that
magnetic holes induce changes in the electron velocity distribution function
that emit electrostatic Langmuir waves due to the bump-on-tail instability.
Using data from the Solar Orbiter spacecraft, we provide a comprehensive
analysis of this process and test our predictions with observations. The
consistency between the model and observations indicates that our proposed
process is a viable mechanism for producing Langmuir waves in magnetic holes in
the solar wind.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [39] [Is the hyperscaling relation violated below the upper critical dimension in some particular cases?](https://arxiv.org/abs/2507.02159)
*Hung T. Diep,Van-Thanh Ngo*

Main category: cond-mat.stat-mech

TL;DR: The paper analyzes critical exponents in thin films using Monte Carlo simulations, revealing deviations from 2D values and violations of hyperscaling, suggesting an 'effective' dimension. It also explores cross-over transitions and new universality classes in 2D systems with multiple order parameters.


<details>
  <summary>Details</summary>
Motivation: To investigate critical exponents in thin films and understand deviations from theoretical predictions, particularly in relation to hyperscaling and dimensionality.

Method: High-performance multi-histogram Monte Carlo simulations with free boundary conditions in the z-direction and periodic boundary conditions in the xy-plane, applied to the Ising model with nearest-neighbor interactions.

Result: Critical exponents for thin films deviate systematically from 2D values, violating hyperscaling unless an 'effective' dimension is considered. New universality classes emerge in 2D systems with multiple order parameters.

Conclusion: The study highlights the complexity of critical phenomena in thin films, showing deviations from classical theories and suggesting new universality classes and effective dimensions.

Abstract: In this review, we show our results with new interpretation on the critical
exponents of thin films obtained by high-performance multi-histogram Monte
Carlo simulations. The film thickness $N_z$ consists of a few layers up to a
dozen of layers in the $z$ direction. The free boundary condition is applied in
this direction while in the $xy$ plane periodic boundary conditions are used.
Large $xy$ plane sizes are used for finite-size scaling. The Ising model is
studied with nearest-neighbor (NN) interaction. When $N_z=1$, namely the
two-dimensional (2D) system, we find the critical exponents given by the
renormalization group. While, for $N_z>1$, the critical exponents calculated
with the high-precision multi-histogram technique show that they deviate
slightly but systematically from the 2D values. If we use these values of
critical exponents in the hyperscaling relation with $d=2$, then the
hyperscaling relation is violated. However, if we use the hyperscaling relation
and the critical exponents obtained for $N_z>1$ to calculate the dimension of
the system, we find the system dimension slightly larger than 2. This can be
viewed as an "effective" dimension. More discussion is given in the paper. We
also show the cross-over between the first- and second-order transition while
varying the film thickness in an antiferromagnetic FCC Ising frustrated thin
film. In addition, we will show evidence that when a 2D system has two order
parameters of different symmetries with a single transition, the critical
exponents are new, suggesting a universality class of coupled two-symmetry
breakings. In this case, the 2D hyperscaling does not hold. Another case is the
3D Ising model coupled to the lattice vibration: the critical exponents deviate
from the 3D Ising ones, the results suggest the violation of the hyperscaling.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [40] [Cauchy problem for the localized wave propagation in continuous model of the one-dimensional diatomic crystal](https://arxiv.org/abs/2507.02729)
*Sergey Sergeev*

Main category: math-ph

TL;DR: The paper analyzes wave propagation in a 1D diatomic lattice using a continuous model, focusing on asymptotic solutions for localized perturbations under two parameter regimes.


<details>
  <summary>Details</summary>
Motivation: To understand wave behavior in diatomic lattices with localized perturbations, exploring the impact of small parameters (lattice step and perturbation size).

Method: Formulates the problem as a Cauchy problem with pseudo-differential equations, constructs asymptotic solutions using Airy functions for two parameter regimes.

Result: Derives analytical solutions for large perturbations and perturbations comparable to the lattice step, showing their dependence on parameter ratios.

Conclusion: The study provides explicit asymptotic solutions for wave propagation in diatomic lattices, highlighting the role of parameter ratios in solution forms.

Abstract: We study the continuous model of the localized wave propagation corresponding
to the one-dimensional diatomic crystal lattice. From the mathematical point of
view the problem can be described in terms of the Cauchy problem with localized
initial data for a system of two pseudo-differential equations. We assume two
small parameters in this formulation -- the lattice step and the size if the
initial perturbation. We construct the asymptotic solution of the continuous
Cauchy problem with respect to the size of perturbation.
  The ratio of the small parameters drastically affects the form of the
solution. We consider two situations -- when the size of the perturbation is
sufficiently large and when it is comparable with the lattice step. In each
situations we provide analytical formulae for the asymptotic solution via Airy
function.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [41] [Time Resolution Independent Operator Learning](https://arxiv.org/abs/2507.02524)
*Diab W. Abueidda,Mbebo Nonna,Panos Pantidis,Mostafa E. Mobasher*

Main category: cs.CE

TL;DR: NCDE-DeepONet is a continuous-time operator network for learning PDE solution operators from sparse data, using Neural Controlled Differential Equations (NCDEs) for input-resolution-independent encoding and output-resolution-independent predictions.


<details>
  <summary>Details</summary>
Motivation: Existing methods like Recurrent DeepONet and neural-ODE surrogates have limitations in handling sparse, irregular data and continuous-time inputs. NCDE-DeepONet aims to overcome these challenges.

Method: The framework embeds an NCDE in the branch to encode input histories as controlled ODE solutions and augments the trunk with space-time coordinates for flexible predictions.

Result: Benchmarks on transient problems (Poisson, elastodynamic, thermoelastic) show robust and accurate predictions, enabling instant solution queries on unseen meshes and time steps.

Conclusion: Controlled dynamics in NCDE-DeepONet offer a principled and efficient approach for high-fidelity operator learning in transient mechanics.

Abstract: Accurately learning solution operators for time-dependent partial
differential equations (PDEs) from sparse and irregular data remains a
challenging task. Recurrent DeepONet extensions inherit the discrete-time
limitations of sequence-to-sequence (seq2seq) RNN architectures, while
neural-ODE surrogates cannot incorporate new inputs after initialization. We
introduce NCDE-DeepONet, a continuous-time operator network that embeds a
Neural Controlled Differential Equation (NCDE) in the branch and augments the
trunk with explicit space-time coordinates. The NCDE encodes an entire load
history as the solution of a controlled ODE driven by a spline-interpolated
input path, making the representation input-resolution-independent: it encodes
different input signal discretizations of the observed samples. The trunk then
probes this latent path at arbitrary spatial locations and times, rendering the
overall map output-resolution independent: predictions can be queried on meshes
and time steps unseen during training without retraining or interpolation.
Benchmarks on transient Poisson, elastodynamic, and thermoelastic problems
confirm the robustness and accuracy of the framework, achieving almost instant
solution prediction. These findings suggest that controlled dynamics provide a
principled and efficient foundation for high-fidelity operator learning in
transient mechanics.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [42] [Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning](https://arxiv.org/abs/2507.02211)
*Gustavo C. Mangold,Heitor C. M. Fernandes,Mendeli H. Vainstein*

Main category: cs.AI

TL;DR: The paper explores how dilution and mobility affect cooperation in spatial prisoner's dilemma games using multi-agent Q-learning, showing equivalence between fixed and learned update rules and symbiotic effects.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of dilution and mobility on cooperation in spatial prisoner's dilemma games using reinforcement learning.

Method: Uses an independent multi-agent Q-learning algorithm to model different game-theoretical scenarios.

Result: Observes equivalence between fixed and learned update rules and emergence of symbiotic mutualistic effects.

Conclusion: Demonstrates the versatility of Q-learning in modeling diverse game-theoretical scenarios and its benchmarking potential.

Abstract: Recent studies in the spatial prisoner's dilemma games with reinforcement
learning have shown that static agents can learn to cooperate through a diverse
sort of mechanisms, including noise injection, different types of learning
algorithms and neighbours' payoff knowledge.In this work, using an independent
multi-agent Q-learning algorithm, we study the effects of dilution and mobility
in the spatial version of the prisoner's dilemma. Within this setting,
different possible actions for the algorithm are defined, connecting with
previous results on the classical, non-reinforcement learning spatial
prisoner's dilemma, showcasing the versatility of the algorithm in modeling
different game-theoretical scenarios and the benchmarking potential of this
approach.As a result, a range of effects is observed, including evidence that
games with fixed update rules can be qualitatively equivalent to those with
learned ones, as well as the emergence of a symbiotic mutualistic effect
between populations that forms when multiple actions are defined.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [43] [On the Design of Corrugated Boards: A New FEM Modeling and Experimental Validation](https://arxiv.org/abs/2507.02189)
*Ricardo Fitas,Heinz Joachim Schaffrath,Samuel Schabel*

Main category: physics.app-ph

TL;DR: A simplified FEM modeling approach for corrugated boards uses homogenization and correction factors to reduce computational time while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: To optimize corrugated packaging design by simplifying FEM models for faster simulations without sacrificing accuracy.

Method: Homogenization transforms flute geometries into equivalent elastic models, with correction factors (Weibull distributions) for contact and buckling mechanisms.

Result: The method is validated with statistical parameters (β₁=0.14, β₂=1.31) for efficient representation of corrugated boards.

Conclusion: This approach enables computationally efficient and accurate FEM simulations for corrugated packaging design.

Abstract: This study presents a simplified FEM modeling approach suitable for large
structures made of corrugated boards, such as customized packages, based on a
homogenization method, which is combined with correction factors for internal
mechanisms. The homogenization process reduces computational time by
transforming flute geometries into equivalent elastic models. In large
deformations and in the presence of contact for a given geometry, the effective
elastic modulus in the thickness direction, as well as the effective thickness
of the structure, are corrected by two statistical Weibull distributions
representing the contact and buckling mechanisms in a corrugated board. The
Weibull parameters are obtained via experimental analysis, and such a process
is then validated. The results demonstrate that the statistical parameters
($\beta_1 = 0.14$, $\beta_2 = 1.31$) can be used for the simplistic
representation of corrugated boards, being computationally efficient. This
research contributes to the optimization of corrugated packaging design,
specifically by simplifying FEM models for faster yet equally accurate
simulations.

</details>


### [44] [Modeling the Effective Elastic Modulus and Thickness of Corrugated Boards Using Gaussian Process Regression and Expected Hypervolume Improvement](https://arxiv.org/abs/2507.02208)
*Ricardo Fitas*

Main category: physics.app-ph

TL;DR: The paper models the hypersurface of effective elastic modulus and thickness in corrugated boards using LHS and GP with EHVI, achieving accurate predictions.


<details>
  <summary>Details</summary>
Motivation: Accurate modeling of effective elastic modulus and thickness is crucial for optimizing mechanical properties in corrugated materials for engineering applications.

Method: Latin Hypercube Sampling (LHS) for initial sampling, followed by Gaussian Process Regression (GP) enhanced by EHVI as a multi-objective acquisition function.

Result: Prediction errors: MSE for elastic modulus = 5.24 kPa², MSE for thickness = 1 mm². GP showed improved accuracy and adaptability.

Conclusion: GP with EHVI is effective for modeling and optimizing corrugated board properties, with potential for future structural optimization applications.

Abstract: This work aims to model the hypersurface of the effective elastic modulus, \(
E_{z, \text{eff}} \), and thickness, \( th_{\text{eff}} \), in corrugated
boards. A Latin Hypercube Sampling (LHS) is followed by Gaussian Process
Regression (GP), enhanced by EHVI as a multi-objective acquisition function.
Accurate modeling of \( E_{z, \text{eff}} \) and \( th_{\text{eff}} \) is
critical for optimizing the mechanical properties of corrugated materials in
engineering applications. LHS provides an efficient and straightforward
approach for an initial sampling of the input space; GP is expected to be able
to adapt to the complexity of the response surfaces by incorporating both
prediction and uncertainty. Therefore, the next points being generated and
evaluated are based on the complexity of the hypersurfaces, and some points,
especially those with higher variance, are more exploited and carry more
importance. The performance of GP with EHVI is measured by Mean Squared Error
(MSE). Prediction of GP resulted in \( \text{MSE}(E_{z, \text{eff}}) = 5.24 \,
\text{kPa}^2 \) and \( \text{MSE}(th_{\text{eff}}) = 1 \, \text{mm}^2 \). GP
possesses then improved accuracy and adaptability for future applications in
structural optimization.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [45] [Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework](https://arxiv.org/abs/2507.02106)
*Semih Kacmaz,E. A. Huerta,Roland Haas*

Main category: physics.flu-dyn

TL;DR: A hybrid framework combining Physics-Informed Neural Operators (PINOs) and diffusion models accurately simulates 2D MHD turbulence across Reynolds numbers, outperforming deterministic methods.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of simulating fully developed turbulence in MHD systems, especially at high Reynolds numbers, where deterministic surrogates fail.

Method: Uses PINOs for low-frequency dynamics and a conditional diffusion model for high-frequency residuals, trained on high-fidelity simulations.

Result: Achieves state-of-the-art accuracy, capturing spectral energy distributions, non-Gaussian statistics, and cross-field correlations, even at Re=10000.

Conclusion: The hybrid framework enables accurate turbulence modeling in previously inaccessible regimes, with high fidelity to real-world physics.

Abstract: We present a hybrid machine learning framework that combines Physics-Informed
Neural Operators (PINOs) with score-based generative diffusion models to
simulate the full spatio-temporal evolution of two-dimensional, incompressible,
resistive magnetohydrodynamic (MHD) turbulence across a broad range of Reynolds
numbers ($\mathrm{Re}$). The framework leverages the equation-constrained
generalization capabilities of PINOs to predict coherent, low-frequency
dynamics, while a conditional diffusion model stochastically corrects
high-frequency residuals, enabling accurate modeling of fully developed
turbulence. Trained on a comprehensive ensemble of high-fidelity simulations
with $\mathrm{Re} \in \{100, 250, 500, 750, 1000, 3000, 10000\}$, the approach
achieves state-of-the-art accuracy in regimes previously inaccessible to
deterministic surrogates. At $\mathrm{Re}=1000$ and $3000$, the model
faithfully reconstructs the full spectral energy distributions of both velocity
and magnetic fields late into the simulation, capturing non-Gaussian
statistics, intermittent structures, and cross-field correlations with high
fidelity. At extreme turbulence levels ($\mathrm{Re}=10000$), it remains the
first surrogate capable of recovering the high-wavenumber evolution of the
magnetic field, preserving large-scale morphology and enabling statistically
meaningful predictions.

</details>


### [46] [Predicting Flow-Induced Vibration in Isolated and Tandem Cylinders Using Hypergraph Neural Networks](https://arxiv.org/abs/2507.02242)
*Shayan Heydari,Rui Gao,Rajeev K Jaiman*

Main category: physics.flu-dyn

TL;DR: A hypergraph neural network framework predicts flow-induced vibrations in cylinders using finite element-inspired methods, achieving high accuracy in simulating complex fluid-structure interactions.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of accurately predicting flow-induced vibrations in freely oscillating cylinders, which is critical for applications like digital twins.

Method: The framework uses hypergraphs to encode spatial relationships and a modular architecture with POD-based sub-networks for mesh deformation and hypergraph message-passing for flow prediction.

Result: The model accurately captures nonlinear oscillation amplitudes and resolves complex wake-body interactions, showing high fidelity in force statistics and flow dynamics.

Conclusion: The framework is a robust surrogate model for digital twin applications, effectively handling complex fluid-structure interactions.

Abstract: We present a finite element-inspired hypergraph neural network framework for
predicting flow-induced vibrations in freely oscillating cylinders. The
surrogate architecture transforms unstructured computational meshes into
node-element hypergraphs that encode higher-order spatial relationships through
element-based connectivity, preserving the geometric and topological structure
of the underlying finite-element discretization. The temporal evolution of the
fluid-structure interaction is modeled via a modular partitioned architecture:
a complex-valued, proper orthogonal decomposition-based sub-network predicts
mesh deformation using a low-rank representation of Arbitrary
Lagrangian-Eulerian (ALE) grid displacements, while a hypergraph-based
message-passing network predicts the unsteady flow field using geometry-aware
node, element, and hybrid edge features. High-fidelity ALE-based simulations
provide training and evaluation data across a range of Reynolds numbers and
reduced velocities for isolated and tandem cylinder configurations. The
framework demonstrates stable roll-outs and accurately captures the nonlinear
variation of oscillation amplitudes with respect to reduced velocity, a key
challenge in surrogate modeling of flow-induced vibrations. In the tandem
configuration, the model successfully resolves complex wake-body interactions
and multi-scale coupling effects, enabling accurate prediction of pressure and
velocity fields under strong wake interference conditions. Our results show
high fidelity in reproducing force statistics, dominant frequencies, and
flow-field dynamics, supporting the framework's potential as a robust surrogate
model for digital twin applications.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [47] [Public perspectives on the design of fusion energy facilities](https://arxiv.org/abs/2507.02207)
*Nathan Kawamoto,Daniel Hoover,Jonathan Xie,Jacob Walters,Katie Snyder,Aditi Verma*

Main category: physics.soc-ph

TL;DR: The paper explores participatory design for fusion energy facilities, involving community and engineering students to identify key values and criteria, aiming to foster social license and address public concerns early in development.


<details>
  <summary>Details</summary>
Motivation: Understanding public perspectives on fusion energy facilities is crucial for social license, especially as these facilities may be sited closer to communities due to distinct regulatory frameworks.

Method: A participatory design workshop with 22 community participants and 34 engineering students, analyzing textual and visual data to identify design values and decision-making criteria.

Result: Key values included 'integrity' and 'respect'; top decision-making criteria were 'economic benefits' and 'environmental protection/safety'. Design themes linked community history, worker care, transparency, and safety. Participants expressed positive sentiments.

Conclusion: Participatory design early in technology development can concretize public hopes/concerns, enhance understanding, build social license, and guide context-specific fusion facility development.

Abstract: As fusion energy technologies approach demonstration and commercial
deployment, understanding public perspectives on future fusion facilities will
be critical for achieving social license, especially because fusion energy
facilities, unlike large fission reactors, may be sited in closer proximity to
people and communities, due to distinct regulatory frameworks. In a departure
from the 'decide-announce-defend' approach typically used to site energy
infrastructure, we develop a participatory design methodology for
collaboratively designing fusion energy facilities with prospective host
communities. We present here our findings from a participatory design workshop
that brought together 22 community participants and 34 engineering students.
Our analysis of the textual and visual data from this workshop shows a range of
design values and decision-making criteria with 'integrity' and 'respect'
ranking highest among values and 'economic benefits' and 'environmental
protection/safety' ranking highest among decision-making criteria. Salient
design themes that emerge across facility concepts include connecting the
history and legacy of the community to the design of the facility, care for
workers, transparency and access to the facility, and health and safety of the
host community. Participants reported predominantly positive sentiments,
expressing joy and surprise as the workshop progressed from learning about
fusion to designing the hypothetical facility. Our findings suggest that
carrying out participatory design in the early stages of technology development
can invite and make concrete public hopes and concerns, improve understanding
of, and curiosity about, an emerging technology, build toward social license,
and inform context-specific development of fusion energy facilities.

</details>


<div id='astro-ph.CO'></div>

# astro-ph.CO [[Back]](#toc)

### [48] [A general polynomial emulator for cosmology via moment projection](https://arxiv.org/abs/2507.02179)
*Zheng Zhang*

Main category: astro-ph.CO

TL;DR: MomentEmu is a polynomial emulator for fast, interpretable mappings between theoretical parameters and observational features, outperforming neural networks in speed and transparency.


<details>
  <summary>Details</summary>
Motivation: To provide a lightweight, interpretable alternative to neural-network-based emulators for cosmological analysis, enabling fast and transparent mappings.

Method: Constructs moment matrices to project simulation data onto polynomial bases, yielding symbolic expressions for approximation.

Result: Achieves sub-percent accuracy in emulating CMB power spectra and acoustic peak features, with negligible training cost and millisecond-level evaluation.

Conclusion: MomentEmu is a portable, efficient tool for forward modelling, parameter inference, and uncertainty propagation in moderate-dimensional, smooth mapping scenarios.

Abstract: We present MomentEmu, a general-purpose polynomial emulator for fast and
interpretable mappings between theoretical parameters and observational
features. The method constructs moment matrices to project simulation data onto
polynomial bases, yielding symbolic expressions that approximate the target
mapping. Compared to neural-network-based emulators, MomentEmu offers
negligible training cost, millisecond-level evaluation, and transparent
functional forms. As a demonstration, we develop two emulators:
PolyCAMB-$D_\ell$, which maps six cosmological parameters to the CMB
temperature power spectrum, and PolyCAMB-peak, which enables bidirectional
mapping between parameters and acoustic peak features. PolyCAMB-$D_\ell$
achieves an accuracy of $0.03\%$over $\ell \leq 2510$, while PolyCAMB-peak also
reaches sub-percent accuracy and produces symbolic forms consistent with known
analytical approximations. The method is well suited for forward modelling,
parameter inference, and uncertainty propagation, particularly when the
parameter space is moderate in dimensionality and the mapping is smooth.
MomentEmu offers a lightweight and portable alternative to regression-based or
black-box emulators in cosmological analysis.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [49] [Spin Caloritronics in irradiated chiral ferromagnetic systems](https://arxiv.org/abs/2507.02765)
*Sudin Ganguly,Moumita Dey,Santanu K. Maiti*

Main category: cond-mat.mes-hall

TL;DR: The paper investigates the thermoelectric response of a ferromagnetic helical system under light irradiation, revealing enhanced spin thermoelectric performance and suppressed thermal conductance.


<details>
  <summary>Details</summary>
Motivation: To explore the spin-dependent thermoelectric properties of ferromagnetic systems under light irradiation, aiming for efficient energy conversion.

Method: Uses tight-binding framework, Floquet-Bloch formalism, non-equilibrium Green's function technique, and a mass-spring model for phonon thermal conductance.

Result: Light induces spin-split transmission, suppresses thermal conductance, and improves spin thermopower and FOM, outperforming charge FOM. Long-range hopping further enhances spin thermoelectric performance.

Conclusion: The study highlights the potential of light-irradiated ferromagnetic helical systems for efficient spin thermoelectric energy conversion, with long-range hopping as a key enhancer.

Abstract: We study the charge and spin-dependent thermoelectric response of a
ferromagnetic helical system irradiated by arbitrarily polarized light, using a
tight-binding framework and the Floquet-Bloch formalism. Transport properties
for individual spin channels are determined by employing the non-equilibrium
Green's function technique, while phonon thermal conductance is evaluated using
a mass-spring model with different lead materials. The findings reveal that
that light irradiation induces spin-split transmission features, suppresses
thermal conductance, and yields favorable spin thermopower and figure of merit
(FOM). The spin FOM consistently outperforms its charge counterpart under
various light conditions. Moreover, long-range hopping is shown to enhance the
spin thermoelectric performance, suggesting a promising strategy for efficient
energy conversion in related ferromagnetic systems.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [50] [MeV cosmic-ray electrons modify the TeV pair-beam plasma instability](https://arxiv.org/abs/2507.02423)
*Mahmoud Alawashra,Yuanyuan Yang,Christopher M. Hirata,Heyang Long,Martin Pohl*

Main category: astro-ph.HE

TL;DR: The paper investigates how linear Landau damping (LLD) affects the energy-loss efficiency of plasma instabilities in relativistic pair beams from blazars, finding it suppresses oblique modes but enhances quasi-parallel ones, significantly increasing energy loss.


<details>
  <summary>Details</summary>
Motivation: To explain the absence of GeV-scale electromagnetic cascades in blazar spectra, the study explores whether LLD impacts the energy-loss efficiency of plasma instabilities in pair beams.

Method: The impact of LLD on plasma instabilities is analyzed for pair beams associated with blazar 1ES 0229+200, focusing on suppression of oblique electrostatic modes and growth of quasi-parallel ones.

Result: LLD suppresses oblique electrostatic modes but enhances quasi-parallel ones, increasing the energy-loss efficiency of the instability by over an order of magnitude.

Conclusion: LLD plays a critical role in enhancing the energy-loss efficiency of plasma instabilities, providing a plausible explanation for the missing GeV cascade in blazar spectra.

Abstract: Relativistic pair beams created in the intergalactic medium (IGM) by TeV
gamma rays from blazars are expected to produce a detectable GeV-scale
electromagnetic cascade, but the cascade component is absent in the spectra of
many hard-spectrum TeV-emitting blazars. One common explanation is that weak
intergalactic magnetic fields deflect the electron-positron pairs away from our
line of sight. An alternative possibility is that electrostatic beam-plasma
instabilities drain the energy of these pairs before a cascade can develop.
Recent studies have shown that beam scattering by oblique electrostatic modes
leads to minimal energy loss. But these modes might be suppressed by linear
Landau damping (LLD) due to MeV-scale cosmic-ray electrons in the IGM. In this
work, we explore the impact of LLD on the energy-loss efficiency of plasma
instabilities in pair beams associated with 1ES 0229+200. We find that LLD
effectively suppresses oblique electrostatic modes, while quasi-parallel ones
grow to larger amplitudes. In this way, LLD enhances the energy-loss efficiency
of the instability by more than an order of magnitude.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [51] [Optimal boron-doped graphene substrate for glucose Raman signal enhancement](https://arxiv.org/abs/2507.02642)
*Jan Komeda,Antonio Cammarata,Tomas Polcar*

Main category: cond-mat.mtrl-sci

TL;DR: B-doped graphene enhances Raman signals, with higher doping concentrations and molecule orientation improving glucose detection in SERS.


<details>
  <summary>Details</summary>
Motivation: To explore how boron doping concentration and geometric distribution in graphene affect its effectiveness as a SERS substrate for glucose detection.

Method: Quantum mechanical simulations analyzing interatomic force constants and phonon eigenvectors.

Result: Higher boron doping concentrations enhance glucose's Raman signal, and molecule orientation is crucial for Raman response.

Conclusion: High-concentration B-graphene is a promising SERS substrate for glucose detection, and phonon-based analysis aids in identifying effective substrate materials.

Abstract: Surface Enhanced Raman Spectroscopy (SERS) is a highly sensitive and
selective technique that greatly enhances the signal of an analyte, compared
with its signal from classical Raman Spectroscopy, due to its interaction with
a substrates surface. It has been shown that low concentration boron-doped
graphene (B-graphene) enhances the Raman signal of simple organic molecules
like pyridine. Recent studies also suggest that B-graphene can remain
thermodynamically stable when doped with significantly higher concentrations of
boron than previously observed. In this framework, we use quantum mechanical
simulations to investigate the influence of dopant concentration and geometric
distribution on the effectiveness of B-doped graphene as a SERS substrate, with
glucose as analyte. By combining analysis of interatomic force constants and of
phonon eigenvectors composition, we conclude that higher doping concentrations
provide a larger enhancement to glucose's Raman signal, while the molecule
orientation relative to the surface plays a fundamental role in the Raman
response. We suggest that high concentration B-graphene presents itself as a
potential substrate for SERS based detection of glucose, while the used
phonon-based analysis can be promptly applied for the search of promising
candidates as substrate materials for enhanced Raman response.

</details>
