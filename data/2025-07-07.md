<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 13]
- [math.AP](#math.AP) [Total: 19]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [math-ph](#math-ph) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [astro-ph.CO](#astro-ph.CO) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [physics.space-ph](#physics.space-ph) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A Hybrid DEC-SIE Framework for Potential-Based Electromagnetic Analysis of Heterogeneous Media](https://arxiv.org/abs/2507.02099)
*Amgad Abdrabou,Luis J. Gomez,Weng Cho Chew*

Main category: math.NA

TL;DR: A hybrid method combining DEC and SIE is proposed for efficient electromagnetic field analysis in complex environments, improving compatibility and performance.


<details>
  <summary>Details</summary>
Motivation: Addressing computational challenges in analyzing electromagnetic fields in multi-material environments.

Method: Couples discrete exterior calculus (DEC) with surface integral equations (SIE) using magnetic vector and electric scalar potentials under the Lorenz gauge.

Result: Reduces surface integral operators from fourteen to two, enhancing numerical performance and compatibility.

Conclusion: The hybrid method provides a unified, efficient framework for solving electromagnetic problems in complex geometries.

Abstract: Analyzing electromagnetic fields in complex, multi-material environments
presents substantial computational challenges. To address these, we propose a
hybrid numerical method that couples discrete exterior calculus (DEC) with
surface integral equations (SIE) in the potential-based formulation of
Maxwell's equations. The method employs the magnetic vector and electric scalar
potentials ($\mathbf{A}$-$\Phi$) under the Lorenz gauge, offering natural
compatibility with multi-physics couplings and inherent immunity to
low-frequency breakdown. To effectively handle both bounded and unbounded
regions, we divide the computational domain: the inhomogeneous interior is
discretized using DEC, a coordinate-free framework that preserves topological
invariants and enables structure-preserving discretization on unstructured
meshes, while the homogeneous exterior is treated using SIEs, which inherently
satisfy the radiation condition and eliminate the need for artificial domain
truncation. A key contribution of this work is a scalar reformulation of the
SIEs, which reduces the number of surface integral operators from fourteen to
two by expressing the problem in terms of the Cartesian components of the
vector potential and their normal derivatives. This simplification motivates a
corresponding adaptation in the DEC domain: each vector potential component is
represented as a discrete 0-form, in contrast to the conventional 1-form
representation. This novel treatment improves compatibility at the interface
and significantly enhances numerical performance. The proposed hybrid method
thus offers a unified, efficient, and physically consistent framework for
solving electromagnetic scattering and radiation problems in complex geometries
and heterogeneous materials

</details>


### [2] [Symplectic Hamiltonian Hybridizable Discontinuous Galerkin Methods for Linearized Shallow Water Equations](https://arxiv.org/abs/2507.02340)
*C. Núñez,M. A. Sánchez*

Main category: math.NA

TL;DR: The paper presents an HDG method for approximating the linearized shallow water equations while preserving Hamiltonian structure, using auxiliary variables and symplectic integrators for energy conservation.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical method that preserves the Hamiltonian structure of the linearized shallow water equations, ensuring energy conservation and accurate physical evolution.

Method: Proposes an equivalent formulation with an auxiliary variable, discretizes space using HDG methods, and time using symplectic integrators.

Result: Achieves optimal convergence rates and conserves total energy, demonstrating accurate physical evolution.

Conclusion: The HDG method with auxiliary variables and symplectic integrators effectively preserves Hamiltonian structure and energy conservation in numerical approximations.

Abstract: This paper focuses on the numerical approximation of the linearized shallow
water equations using hybridizable discontinuous Galerkin (HDG) methods,
leveraging the Hamiltonian structure of the evolution system. First, we propose
an equivalent formulation of the equations by introducing an auxiliary
variable. Then, we discretize the space variables using HDG methods, resulting
in a semi-discrete scheme that preserves a discrete version of the Hamiltonian
structure. The use of an alternative formulation with the auxiliary variable is
crucial for developing the HDG scheme that preserves this Hamiltonian
structure. The resulting system is subsequently discretized in time using
symplectic integrators, ensuring the energy conservation of the fully discrete
scheme. We present numerical experiments that demonstrate optimal convergence
rates for all variables and showcase the conservation of total energy, as well
as the evolution of other physical quantities.

</details>


### [3] [An efficient asymptotic preserving Monte Carlo method for frequency-dependent radiative transfer equations](https://arxiv.org/abs/2507.02392)
*Yiyang Hong,Yi Shi,Yi Cai,Tao Xiong*

Main category: math.NA

TL;DR: An efficient asymptotic-preserving Monte Carlo method for frequency-dependent radiative transfer equations is developed, combining macroscopic and transport equations with corrections for accuracy.


<details>
  <summary>Details</summary>
Motivation: To address the computational challenges of frequency-dependent radiative transfer equations, ensuring accuracy and efficiency across a wide range of frequencies and time steps.

Method: A hybrid approach solves the macroscopic system with particle-based Monte Carlo for convective fluxes and implicit central difference for diffusive fluxes, using Picard iteration for nonlinear coupling.

Result: The method achieves high efficiency and maintains asymptotic-preserving properties, enabling larger time steps independent of frequency and speed of light.

Conclusion: The proposed method effectively handles frequency-dependent radiative transfer, demonstrating computational efficiency and accuracy in numerical experiments.

Abstract: In this paper, we develop an efficient asymptotic-preserving (AP) Monte Carlo
(MC) method for frequency-dependent radiative transfer equations (RTEs), which
is based on the AP-MC method proposed for the gray RTEs in
\cite{shi2023efficient}. We follow the characteristics-based approach by Zhang
et al. \cite{zhang2023asymptotic} to get a reformulated model, which couples a
low dimension convection-diffusion-type equation for macroscopic quantities
with a high dimension transport equation for the radiative intensity.
  To recover the correct free streaming limit due to frequency-dependency, we
propose a correction to the reformulated macroscopic equation.
  The macroscopic system is solved using a hybrid method:
  convective fluxes are handled by a particle-based MC method, while diffusive
fluxes are treated implicitly with central difference.
  To address the nonlinear coupling between radiative intensity and the Planck
function across multiple frequency groups, we adopt a Picard iteration with a
predictor-corrector procedure, which decouples a global nonlinear system into a
linear system restricted to spatial dimension (independent of frequency) with
scalar algebraic nonlinear equations.
  Once the macroscopic update is done, the transport equation, with a known
emission source provided by the macroscopic variables, is efficiently solved
using an implicit MC method. This approach enables larger time steps
independent of the speed of light and also the frequency across a wide range,
significantly enhancing computational efficiency, especially for
frequency-dependent RTEs.
  Formal AP analysis in the diffusive scaling is established. Numerical
experiments are performed to demonstrate the high efficiency and AP property of
the proposed method.

</details>


### [4] [Fast reconstruction approaches for photoacoustic tomography with smoothing Sobolev/Matérn priors](https://arxiv.org/abs/2507.02401)
*Jaakko Kultima,Ronny Ramlau,Teemu Sahlström,Tanja Tarvainen*

Main category: math.NA

TL;DR: The paper explores the connection between deterministic and stochastic approaches in photoacoustic tomography (PAT), linking Matérn covariance operators to Sobolev embeddings and proposing efficient wavelet-based implementations.


<details>
  <summary>Details</summary>
Motivation: To bridge deterministic (regularization) and stochastic (Bayesian) methods in PAT by establishing equivalence between Matérn covariance operators and Sobolev embeddings, enabling efficient computational solutions.

Method: Establishes equivalence between Matérn covariance operators and Sobolev embeddings, and introduces a wavelet-based implementation of the adjoint operator for efficient evaluations.

Result: Validated with reconstructions for PAT, showing computational and memory efficiency.

Conclusion: The proposed methods successfully connect deterministic and stochastic approaches, offering efficient solutions for PAT reconstruction.

Abstract: In photoacoustic tomography (PAT), the computation of the initial pressure
distribution within an object from its time-dependent boundary measurements
over time is considered. This problem can be approached from two
well-established points of view: deterministically using regularisation
methods, or stochastically using the Bayesian framework. Both approaches
frequently require the solution of a variational problem. In the paper we
elaborate the connection between these approaches by establishing the
equivalence between a smoothing Mat{\'e}rn class of covariance operators and
Sobolev embedding operator $E_s: H^s \hookrightarrow L^2$. We further discuss
the use of a Wavelet-based implementation of the adjoint operator $E_s^*$ which
also allows for efficient evaluations for certain Mat{\'e}rn covariance
operators, leading to efficient implementations both in terms of computational
effort as well as memory requirements. The proposed methods are validated with
reconstructions for the photoacoustic problem.

</details>


### [5] [A second-order and unconditionally stable time filtered scheme for the Cahn-Hilliard-Navier-Stokes system](https://arxiv.org/abs/2507.02402)
*Xi Li,Haijun Gao,Chunmei Xie,Minfu Feng*

Main category: math.NA

TL;DR: A low-complexity, energy-stable second-order time-stepping scheme for the CHNS system is proposed using a time filter technique.


<details>
  <summary>Details</summary>
Motivation: To improve the temporal accuracy of the CHNS system discretization while maintaining energy stability.

Method: Uses a first-order backward Euler method with a time filter to achieve second-order accuracy.

Result: Unconditional energy stability and second-order temporal error estimations are proven, supported by numerical experiments.

Conclusion: The proposed scheme effectively enhances accuracy and stability for the CHNS system.

Abstract: In this work, we propose, analyze, and test a novel computational
low-complexity, linear, second-order, and unconditional energy-stable
semi-discrete time-stepping scheme for the Cahn-Hilliard-Navier-Stokes (CHNS)
system by employing the time filter technique. Firstly, the first-order
semi-implicit backward Euler (BE) method is utilized to discretize the CHNS
model; Secondly, the time filter, as a post-processing strategy, is
incorporated into the BE scheme, requiring only minimal modifications to the
existing BE framework to improve its temporal accuracy from first- to
second-order. The unconditional energy stability and second-order temporal
error estimations are obtained, and several numerical experiments are conducted
to verify the theoretical results.

</details>


### [6] [A modified Crank-Nicolson scheme for the Vlasov-Poisson system with a strong external magnetic field](https://arxiv.org/abs/2507.02459)
*Francis Filbet,L Miguel Rodrigues,Kim Han Trinh*

Main category: math.NA

TL;DR: A Particle-In-Cell (PIC) method using Crank-Nicolson time discretization is proposed for the Vlasov-Poisson system with a strong magnetic field, focusing on poloidal motion. The method avoids stability constraints by leveraging guiding-center system discretization.


<details>
  <summary>Details</summary>
Motivation: To address stability constraints in simulating particle motion under strong, inhomogeneous magnetic fields, particularly in poloidal directions.

Method: Uses Crank-Nicolson time discretization and a consistent PIC discretization of the guiding-center system, accounting for magnetic field variations.

Result: Theoretical proofs and numerical experiments validate the method's effectiveness.

Conclusion: The proposed method successfully avoids stability constraints and accurately models particle motion in strong magnetic fields.

Abstract: We propose and study a Particle-In-Cell (PIC) method based on the
Crank-Nicolson time discretization for the Vlasov-Poisson system with a strong
and inhomogeneous external magnetic field with fixed direction, where we focus
on the motion of particles in the plane orthogonal to the magnetic field
(so-called poloidal directions). In this regime, the time step can be subject
to stability constraints related to the smallness of Larmor radius and plasma
frequency [21]. To avoid this limitation, our approach is based on numerical
schemes [9, 10, 12], providing a consistent PIC discretization of the
guiding-center system taking into account variations of the magnetic field. We
carry out some theoretical proofs and perform several numerical experiments to
validate the method and its underlying concepts.

</details>


### [7] [Goal-oriented optimal sensor placement for PDE-constrained inverse problems in crisis management](https://arxiv.org/abs/2507.02500)
*Marco Mattuschka,Noah An der Lan,Max von Danwitz,Daniel Wolff,Alexander Popp*

Main category: math.NA

TL;DR: A Bayesian framework for optimal sensor placement and steering in PDE-constrained inverse problems, applied to contaminant tracking, with efficient low-rank approximations and C-optimal design.


<details>
  <summary>Details</summary>
Motivation: Address the need for efficient sensor placement and steering in complex geometries for real-time crisis management, like airborne contaminant tracking.

Method: Uses a Bayesian approach with low-rank approximations for computational efficiency and C-optimal design for sensor placement to minimize prediction uncertainty.

Result: Numerical experiments confirm the framework's effectiveness in source identification and monitoring, enabling real-time decision-making.

Conclusion: The framework is promising for real-time applications in crisis management, offering computational efficiency and reduced uncertainty.

Abstract: This paper presents a novel framework for goal-oriented optimal static sensor
placement and dynamic sensor steering in PDE-constrained inverse problems,
utilizing a Bayesian approach accelerated by low-rank approximations. The
framework is applied to airborne contaminant tracking, extending recent dynamic
sensor steering methods to complex geometries for computational efficiency. A
C-optimal design criterion is employed to strategically place sensors,
minimizing uncertainty in predictions. Numerical experiments validate the
approach's effectiveness for source identification and monitoring, highlighting
its potential for real-time decision-making in crisis management scenarios.

</details>


### [8] [On low-dimensional approximation of function spaces of interior regularity](https://arxiv.org/abs/2507.02655)
*S. Aziz,M. Bauer,M. Bebendorf,T. Rau*

Main category: math.NA

TL;DR: A new technique for constructing local approximation spaces for Lipschitz domains improves exponential convergence by leveraging boundary approximations instead of eigenvalue problems.


<details>
  <summary>Details</summary>
Motivation: To enhance the efficiency of generalized finite element methods by improving the relationship between dimensionality and convergence order.

Method: The technique extends boundary approximations to construct local spaces, avoiding eigenvalue problems and simplifying variational problem solving on structured domains.

Result: The method improves the influence of spatial dimension on exponential convergence and simplifies the construction of local spaces.

Conclusion: The proposed technique offers a more efficient and practical approach for constructing local approximation spaces in Lipschitz domains.

Abstract: Many elliptic boundary value problems exhibit an interior regularity
property, which can be exploited to construct local approximation spaces that
converge exponentially within function spaces satisfying this property. These
spaces can be used to define local ansatz spaces within the framework of
generalised finite element methods, leading to a better relation between
dimensionality and convergence order. In this paper, we present a new technique
for the construction of such spaces for Lipschitz domains. Instead of the
commonly used approach based on eigenvalue problems it relies on extensions of
approximations performed on the boundary. Hence, it improves the influence of
the spatial dimension on the exponential convergence and allows to construct
the local spaces by solving the original kind of variational problems on easily
structured domains.

</details>


### [9] [High order uniform in time schemes for weakly nonlinear Schrödinger equation and wave turbulence](https://arxiv.org/abs/2507.02662)
*Quentin Chauleur,Antoine Mouzard*

Main category: math.NA

TL;DR: Two high-order multiscale schemes for weakly nonlinear Schrödinger equations are introduced, achieving precision under CFL conditions and uniform accuracy over long times.


<details>
  <summary>Details</summary>
Motivation: To address the need for precise and efficient numerical methods for weakly nonlinear Schrödinger equations, especially for long-term simulations.

Method: Discretization of Picard iterates of the solution, leveraging low-frequency projected linear flow for scattering properties.

Result: High precision under CFL conditions and uniform accuracy over long times, validated by numerical simulations.

Conclusion: The schemes are effective for weakly nonlinear Schrödinger equations and applicable to wave turbulence dynamics.

Abstract: We introduce two multiscale numerical schemes for the time integration of
weakly nonlinear Schr\"odinger equations, built upon the discretization of
Picard iterates of the solution. These high-order schemes are designed to
achieve high precision with respect to the small nonlinearity parameter under
particular CFL condition. By exploiting the scattering properties of these
schemes thanks to a low-frequency projected linear flow, we also establish its
uniform accuracy over long time horizons. Numerical simulations are provided to
illustrate the theoretical results, and these schemes are further applied to
investigate dynamics in the framework of wave turbulence.

</details>


### [10] [Moments, Time-Inversion and Source Identification for the Heat Equation](https://arxiv.org/abs/2507.02677)
*Kang Liu,Enrique Zuazua*

Main category: math.NA

TL;DR: A novel moment-based approach for solving the ill-posed inverse problem of initial source identification in the heat equation, reducing exponential error growth to polynomial growth and promoting sparsity.


<details>
  <summary>Details</summary>
Motivation: The heat equation's initial source identification is highly unstable (exponentially ill-posed). Classical methods like Tikhonov regularization are insufficient, necessitating a more stable and accurate solution.

Method: Transform the problem into an inverse moment formulation by analyzing heat flow moments. Recover initial moments via backward ODE evolution and reconstruct the source using convex optimization (total variation minimization) with moment constraints.

Result: The method reduces error growth from exponential to polynomial, provides explicit error estimates, and yields sparse (atomic) solutions. Numerical experiments confirm improved stability.

Conclusion: The moment-based approach offers a stable, accurate, and computationally efficient solution for the heat equation's inverse problem, outperforming traditional methods.

Abstract: We address the initial source identification problem for the heat equation, a
notably ill-posed inverse problem characterized by exponential instability.
Departing from classical Tikhonov regularization, we propose a novel approach
based on moment analysis of the heat flow, transforming the problem into a more
stable inverse moment formulation. By evolving the measured terminal time
moments backward through their governing ODE system, we recover the moments of
the initial distribution. We then reconstruct the source by solving a convex
optimization problem that minimizes the total variation of a measure subject to
these moment constraints. This formulation naturally promotes sparsity,
yielding atomic solutions that are sums of Dirac measures. Compared to existing
methods, our moment-based approach reduces exponential error growth to
polynomial growth with respect to the terminal time. We provide explicit error
estimates on the recovered initial distributions in terms of moment order,
terminal time, and measurement errors. In addition, we develop efficient
numerical discretization schemes and demonstrate significant stability
improvements of our approach through comprehensive numerical experiments.

</details>


### [11] [A $\mathcal{CR}$-rotated $Q_1$ nonconforming finite element method for Stokes interface problems on local anisotropic fitted mixed meshes](https://arxiv.org/abs/2507.02741)
*Geng Chenchen,Hua Wang,Fengren Zou*

Main category: math.NA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a new nonconforming finite element method for solving Stokes
interface problems. The method is constructed on local anisotropic mixed
meshes, which are generated by fitting the interface through simple connection
of intersection points on an interface-unfitted background mesh, as introduced
in \cite{Hu2021optimal}. For triangular elements, we employ the standard
$\mathcal{CR}$ element; for quadrilateral elements, a new rotated $Q_1$-type
element is used. We prove that this rotated $Q_1$ element remains unisolvent
and stable even on degenerate quadrilateral elements. Based on these
properties, we further show that the space pair of $\mathcal{CR}$-rotated $Q_1$
elements (for velocity) and piecewise $P_0$ spaces (for pressure) satisfies the
inf-sup condition without requiring any stabilization terms. As established in
our previous work \cite{Wang2025nonconforming}, the consistency error achieves
the optimal convergence order without the need for penalty terms to control it.
Finally, several numerical examples are provided to verify our theoretical
results.

</details>


### [12] [Uniform semiclassical observable error bound of Trotterization without the Egorov theorem: a simple algebraic proof](https://arxiv.org/abs/2507.02783)
*Di Fang,Conrad Qu*

Main category: math.NA

TL;DR: The paper presents a simple algebraic proof for uniform-in-$h$ error bounds in high-order Trotterization schemes for semiclassical Schrödinger equation simulations, avoiding heavy semiclassical machinery.


<details>
  <summary>Details</summary>
Motivation: Efficient simulation of the semiclassical Schrödinger equation is challenging due to error control requirements. Prior work showed certain observables allow time-step independence of $h$, but proofs relied on semiclassical limits. This work aims to simplify the proof using algebraic structure.

Method: The authors characterize the class of observables with uniform-in-$h$ error bounds and provide a new algebraic proof for high-order Trotterization schemes, avoiding Egorov-type theorems and semiclassical tools.

Result: A uniform-in-$h$ error bound is proven for Trotterization schemes of arbitrary order, relying solely on algebraic operator structure.

Conclusion: This work simplifies the proof of uniform-in-$h$ error bounds for Trotterization, making it more accessible and generalizable without invoking semiclassical limits.

Abstract: Efficient simulation of the semiclassical Schr\"odinger equation has garnered
significant attention in the numerical analysis community. While controlling
the error in the unitary evolution or the wavefunction typically requires the
time step size to shrink as the semiclassical parameter $h$ decreases, it has
been observed -- and proved for first- and second-order Trotterization schemes
-- that the error in certain classes of observables admits a time step size
independent of $h$. In this work, we explicitly characterize this class of
observables and present a new, simple algebraic proof of uniform-in-$h$ error
bounds for arbitrarily high-order Trotterization schemes. Our proof relies
solely on the algebraic structure of the underlying operators in both the
continuous and discrete settings. Unlike previous analyses, it avoids
Egorov-type theorems and bypasses heavy semiclassical machinery. To our
knowledge, this is the first proof of uniform-in-$h$ observable error bounds
for Trotterization in the semiclassical regime that relies only on algebraic
structure, without invoking the semiclassical limit.

</details>


### [13] [Block triangular preconditioning for inverse source problems in time-space fractional diffusion equations](https://arxiv.org/abs/2507.02809)
*Monoswini Majumdar,Stefano Serra-Capizzano,Rosita L. Sormani*

Main category: math.NA

TL;DR: The paper explores block triangular preconditioners for solving inverse source problems in time-space fractional diffusion equations, showing improved convergence and accuracy.


<details>
  <summary>Details</summary>
Motivation: To address the ill-posedness and computational challenges of inverse source problems in fractional diffusion equations.

Method: Uses quasi-boundary value regularization, finite difference discretization, and a block triangular preconditioning strategy for solving large linear systems.

Result: Numerical experiments with GMRES show the preconditioner enhances convergence, robustness, and accuracy.

Conclusion: The proposed preconditioner is effective for large-scale inverse problems in fractional modeling.

Abstract: The current work investigates the effectiveness of block triangular
preconditioners in accelerating and stabilizing the numerical solution of
inverse source problems governed by time-space fractional diffusion equations
(TSFDEs). We focus on the recovery of an unknown spatial source function in a
multi-dimensional TSFDE, incorporating Caputo time-fractional derivatives and
the fractional Laplacian. The inherent ill-posedness is addressed via a
quasi-boundary value regularization, followed by a finite difference
discretization that leads to large, structured linear systems. We develop and
analyze a block triangular preconditioning strategy that mimics the coefficient
matrix, while simplifying its structure for computational efficiency. Numerical
experiments using the GMRES solver demonstrate that the proposed preconditioner
significantly improve convergence rates, robustness, and accuracy, making it
well-suited for large-scale, real-world inverse problems involving fractional
modeling.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [14] [Composite media, almost touching disks and the maximum principle](https://arxiv.org/abs/2507.02077)
*YanYan Li,Ben Weinkove*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We consider the setting of two disks in a domain in $\mathbb{R}^2$ which are
almost touching and have finite and positive conductivities, giving rise to a
divergence form elliptic equation with discontinuous coefficients. We use the
maximum principle to give a new proof of a gradient bound of Li-Vogelius.

</details>


### [15] [Tools for stability analysis of fractional reaction diffusion systems](https://arxiv.org/abs/2507.02094)
*Sofwah Ahmad,Szymon Cygan,Grzegorz Karch*

Main category: math.AP

TL;DR: The paper proves the linearization principle for abstract fractional reaction-diffusion equations with time-fractional derivatives and applies it to derive results like fractional Turing instability.


<details>
  <summary>Details</summary>
Motivation: To extend the linearization principle to fractional reaction-diffusion equations, bridging classical stability theory with fractional calculus.

Method: Proving the principle for abstract fractional equations and applying it to specific cases, including fractional Turing instability.

Result: The linearization principle holds for fractional reaction-diffusion equations, enabling stability analysis akin to classical cases.

Conclusion: The work successfully generalizes classical stability results to fractional frameworks, with implications for fractional dynamical systems.

Abstract: The linearization principle states that the stability (or instability) of
solutions to a suitable linearization of a nonlinear problem implies the
stability (or instability) of solutions to the original nonlinear problem. In
this work, we prove this principle for solutions of abstract fractional
reaction-diffusion equations with a fractional derivative in time of order
$\alpha\in (0,1)$. Then, we apply these results to particular fractional
reaction-diffusion equations, obtaining, for example, the counterpart of the
classical Turing instability in the case of fractional equations.

</details>


### [16] [Global existence of the solution of the modified Camassa-Holm equation with step-like boundary conditions](https://arxiv.org/abs/2507.02100)
*I. Karpenko,D. Shepelsky,G. Teschl*

Main category: math.AP

TL;DR: The paper studies the global existence of solutions for the modified Camassa-Holm equation with step-like initial data.


<details>
  <summary>Details</summary>
Motivation: To address the Cauchy problem for the modified Camassa-Holm equation and prove the global existence of its solution under specific initial conditions.

Method: Analyzes the equation with step-like initial data (u(x,0) → A₁ as x → -∞ and u(x,0) → A₂ as x → +∞, where 0 < A₁ < A₂).

Result: Establishes the global existence of the solution for the given problem.

Conclusion: The modified Camassa-Holm equation with step-like initial data admits a globally existing solution.

Abstract: We consider the Cauchy problem for
  the modified Camassa-Holm equation
  \[
  u_t+\left((u^2-u_x^2)m\right)_x=0,\quad
  m\coloneqq u-u_{xx},
  \quad t>0,\ \ -\infty<x<+\infty
  \]
  subject to the step-like initial data: $u(x,0)\to A_1$ as $x\to-\infty$ and
$u(x,0)\to A_2$ as $x\to+\infty$, where $0<A_1<A_2$.
  The goal is to
  establish the global existence of the solution of this problem.

</details>


### [17] [Traveling Wave Solutions to a Large Class of Brenner-Navier-Stokes-Fourier Systems](https://arxiv.org/abs/2507.02224)
*Saehoon Eo,Namhyun Eun*

Main category: math.AP

TL;DR: The paper analyzes the one-dimensional Brenner-Navier-Stokes-Fourier (BNSF) system with temperature-dependent transport coefficients, proving existence and uniqueness of small-amplitude viscous shocks using geometric singular perturbation theory and the implicit function theorem.


<details>
  <summary>Details</summary>
Motivation: Address deficiencies in the classical Navier-Stokes-Fourier system and extend results from prior work [12] on contraction properties of solutions around traveling waves.

Method: Employ geometric singular perturbation theory and the implicit function theorem to handle nonlinearities in temperature-dependent coefficients.

Result: Existence and uniqueness of monotone traveling wave solutions for small shock amplitudes, with quantitative estimates supporting prior work [12].

Conclusion: The BNSF system with temperature-dependent coefficients is rigorously analyzed, providing foundational results for further studies on solution behavior.

Abstract: The Brenner-Navier-Stokes-Fourier (BNSF) system, introduced by Howard
Brenner, was developed to address some deficiencies in the classical
Navier-Stokes-Fourier system, based on the concept of volume velocity. We
consider the one-dimensional BNSF system in Lagrangian mass coordinates,
incorporating temperature-dependent transport coefficients, which yields a more
physically realistic framework. We establish the existence and uniqueness of
monotone traveling wave solutions (or viscous shocks) to the BNSF system with
any positive $C^2$ dissipation coefficients, provided that the shock amplitude
is sufficiently small. We utilize geometric singular perturbation theory as in
the constant coefficient case [13]; however, due to the arbitrary
nonlinearities of the coefficients, we employ the implicit function theorem,
which grants robustness to our approach. This work is motivated by [12], which
proves a contraction property of any large solutions to the BNSF system around
the traveling wave solutions. Thus, we also derive some quantitative estimates
on the traveling wave solutions that play a fundamental role in [12].

</details>


### [18] [Analysis and Numerical Approximation to Interactive Dynamics of Navier Stokes-Plate Interaction PDE System](https://arxiv.org/abs/2507.02230)
*Pelin G. Geredeli,Quyuan Lin,Dylan Mcknight,Mohammad Mahabubur Rahman*

Main category: math.AP

TL;DR: The paper analyzes a fluid-plate interaction system, proving well-posedness of weak solutions and providing a FEM-based numerical scheme with error bounds.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by applications in aeroelasticity, biomedical fields, and control of phenomena like ocular pressure and sloshing.

Method: Theoretical analysis uses a variational approach for existence-uniqueness of solutions. Numerically, a FEM scheme with Picard iterations is employed.

Result: Existence-uniqueness of solutions is proven under small data. FEM results validate theory with error bounds in Sobolev norms.

Conclusion: The theoretical and numerical results align, confirming the validity of the approach for the coupled system.

Abstract: We consider a Navier-Stokes fluid-plate interaction (FSI) system which
describes the evolutions of the fluid contained within a 3D cavity, as it
interacts with a deformable elastic membrane on the ``free" upper boundary of
the cavity. These models arise in various aeroelastic and biomedical
applications as well as in the control of ocular pressure, and sloshing
phenomena. We analyze the well-posedness of weak solutions to the stationary
($\lambda$-parametrized) coupled PDE system by way of invoking the nonlinear
generalization of the abstract variational formulations which was introduced in
\cite{girault2012finite}, wherein an inf-sup approach is followed to show
existence-uniqueness of solutions under a small data assumption.
  In addition, we provide a numerical approximation scheme of the infinite
dimensional coupled system via a finite element method approximation (FEM). The
numerical results use a standard conforming scheme and handle the introduced
nonlinearities via Picard iterations. Numerical results are obtained for an
appropriate test problem satisfying the necessary boundary conditions and
coupling. Moreover, error bounds between the FEM and theoretical solution in
terms of the characteristic mesh size are supplied in appropriate Sobolev norms
which agree with the established literature. These FEM approximations of the
coupled system with their associated error bounds validate the theoretical
findings.

</details>


### [19] [Ill-posedness of the Euler equations and inviscid limit of the Navie-Stokes equations in Besov spaces](https://arxiv.org/abs/2507.02247)
*Jinlu Li,Xing Wu,Yanghai Yu*

Main category: math.AP

TL;DR: The paper analyzes the ill-posedness of the incompressible Euler and Navier-Stokes equations on a d-dimensional torus, presenting new initial data and proofs for discontinuity in various Besov spaces.


<details>
  <summary>Details</summary>
Motivation: To investigate and rigorously prove the ill-posedness of the Euler equations in different functional settings, extending prior results.

Method: Constructs new initial data and provides proofs for discontinuity of the solution map in Besov spaces, covering multiple cases.

Result: Demonstrates discontinuity in the solution map at t=0 and in time-dependent Besov spaces, as well as non-Holder continuity.

Conclusion: The Euler equations exhibit ill-posedness in various senses, highlighting challenges in their analysis and solution behavior.

Abstract: In this paper, we consider the Cauchy problem to the incompressible Euler and
Navie-Stokes equations on the d-dimensional torus.Our aim of this paper is two
fold. Firstly, we construct a new initial data and present a simple proof of
the ill-posedness of the Euler equations in different senses: (1) the solution
map of the Euler equations starting from $u_0$ is discontinuous at $t = 0$ in
$B^s_{p,\infty}$ with $s>0$ and $1\leq p \leq \infty$, which covers the result
obtained by Cheskidov and Shvydkoy in ;(2) the solution map of the Euler
equations is not continuous as a map from $B^s_{p,\infty}$ to
$L^\infty_T(B^s_{p,\infty})$;(3) the solution map of the Euler equations cannot
be Holder continuous in time variable in Besov spaces $B^s_{p,r}$.

</details>


### [20] [Trapping by repulsion: the NLS with a delta-prime](https://arxiv.org/abs/2507.02330)
*Riccardo Adami,Filippo Boni,Matteo Gallone*

Main category: math.AP

TL;DR: The paper proves the existence of ground states for the 1D Schrödinger equation with a repulsive delta-prime potential and focusing nonlinearity, even in subcritical cases, due to an emergent energy dimension.


<details>
  <summary>Details</summary>
Motivation: To explore counterintuitive ground states arising from repulsive potentials, explained by an additional energy dimension induced by the delta-prime interaction.

Method: Explicit expressions for stationary states are derived, and the action functional is minimized on the Nehari manifold across subcritical, critical, and supercritical regimes.

Result: Ground states exist for any delta-prime strength and positive mass in subcritical nonlinearity, with explicit forms provided.

Conclusion: The study reveals a novel mechanism for ground state formation in repulsive potentials, expanding understanding of nonlinear Schrödinger systems.

Abstract: We establish the existence and provide explicit expressions for the
stationary states of the one-dimensional Schr\"odinger equation with a
repulsive delta-prime potential and a focusing nonlinearity of power type.
Furthermore, we prove that, if the nonlinearity is subcritical, then ground
states exist for any strength of the delta-prime interaction and for every
positive value of the mass.
  This result supplies an example of ground states arising from a repulsive
potential, a counterintuitive phenomenon explained by the emergence of an
additional dimension in the energy space, induced by the delta-prime
interaction. This new dimension contains states of lower energy and is thus
responsible for the existence of nonlinear ground states that do not originate
from linear eigenfunctions.
  The explicit form of the ground states is derived by addressing the ancillary
problem of minimizing the action functional on the Nehari manifold. We solve
such problem in the subcritical, critical, and supercritical regimes.

</details>


### [21] [Self-similar vorticity around the boundary and non-uniqueness of solutions to the two-dimensional Navier-Stokes equations in the half space](https://arxiv.org/abs/2507.02338)
*Motofumi Aoki,Yasunori Maekawa*

Main category: math.AP

TL;DR: Non-uniqueness of mild solutions to 2D forced Navier-Stokes equations in half space under no-slip boundary conditions, driven by instability of self-similar vorticity near the boundary.


<details>
  <summary>Details</summary>
Motivation: To extend the work of Albritton, Brué, and Colombo (2022) by exploring non-uniqueness in solutions due to boundary-layer effects.

Method: Construction of non-unique solutions based on instability of self-similar vorticity near the boundary at high Reynolds numbers.

Result: Demonstrated non-uniqueness of solutions, contrasting prior results where vorticity was away from the boundary.

Conclusion: Boundary-layer effects are crucial for understanding non-uniqueness in solutions to the Navier-Stokes equations.

Abstract: In this paper we show the non-uniqueness of mild solutions to the
two-dimensional forced Navier-Stokes equations in the half space under the
noslip boundary condition, following the program established by Albritton,
Bru{\'e}, and Colombo in 2022. Our construction of non-unique solutions is
based on the instability of self-similar vorticity at high Reynolds numbers
which concentrates around the boundary at the initial time. In our
construction, therefore, a kind of boundary layer has to be taken into account
in the analysis, contrasting to the known results where the unstable
self-similar vorticity is located away from the boundary with $O(1)$ distance
around the initial time.

</details>


### [22] [A field-road system with a rectifiable set](https://arxiv.org/abs/2507.02451)
*Matthieu Bonnivard,Romain Ducasse,Antoine Lemenant,Alessandro Zilio*

Main category: math.AP

TL;DR: The paper defines a 2D field-road system with a 1D-rectifiable road, coupling parabolic problems on and off the road with transmission conditions.


<details>
  <summary>Details</summary>
Motivation: To model and analyze systems where a lower-dimensional structure (road) interacts with a surrounding field, requiring a mathematical framework for such coupling.

Method: Introduces a general setting to define a parabolic problem on a rectifiable set (road) coupled with a classical parabolic problem outside it, using transmission conditions.

Result: A framework for analyzing coupled parabolic problems involving lower-dimensional structures is established.

Conclusion: The proposed setting provides a mathematical foundation for studying field-road systems with transmission conditions.

Abstract: The aim of this paper is to define a field-road system in 2D where the road
is a merely 1D-rectifiable set. For this purpose we introduce a general setting
in order to define a parabolic problem onto a rectifiable set, which is coupled
with another more classical parabolic problem outside this set, with
transmission conditions.

</details>


### [23] [Global Existence and Incompressible Limit for Compressible Navier-Stokes Equations in Bounded Domains with Large Bulk Viscosity Coefficient and Large Initial Data](https://arxiv.org/abs/2507.02462)
*Qinghao Lei,Chengfeng Xiong*

Main category: math.AP

TL;DR: Global existence and exponential decay of solutions for compressible Navier-Stokes equations with large bulk viscosity, converging to incompressible solutions as viscosity tends to infinity.


<details>
  <summary>Details</summary>
Motivation: To study the behavior of compressible Navier-Stokes equations with vanishing initial density and Navier-slip boundary conditions in 2D domains.

Method: Utilizes logarithmic interpolation inequality and compensated compactness lemma for analysis.

Result: Established global existence and decay of solutions without initial data size restrictions, with convergence to incompressible solutions.

Conclusion: Large bulk viscosity ensures stability and convergence, providing insights into compressible-incompressible transitions.

Abstract: We investigate the barotropic compressible Navier-Stokes equations with the
Navier-slip boundary conditions in a general two-dimensional bounded simply
connected domain. For initial density that is allowed to vanish, we establish
the global existence and exponential decay of weak, strong, and classical
solutions when the bulk viscosity coefficient is suitably large, without any
restrictions on the size of the initial data. Furthermore, we prove that when
the bulk viscosity coefficient tends to infinity, the solutions of the
compressible Navier-Stokes equations converge to those of the inhomogeneous
incompressible Navier-Stokes equations. The key idea is to utilize the
logarithmic interpolation inequality on general bounded domains and apply the
compensated compactness lemma.

</details>


### [24] [Renormalized variational principles and Hardy-type inequalities](https://arxiv.org/abs/2507.02486)
*Satyanad Kichenassamy*

Main category: math.AP

TL;DR: The paper extends Hardy's and Trudinger's inequalities, proving integrability results for functions in $H^1_0(\Omega)$ and providing a variational characterization of the maximal solution of the Liouville equation.


<details>
  <summary>Details</summary>
Motivation: To generalize Hardy's inequality and connect it with Trudinger's inequality, while deriving new results for the Liouville equation.

Method: The authors use functional analysis and variational methods to prove integrability conditions and characterize solutions of the Liouville equation.

Result: They show $[\exp(u^2)-1]/\delta^2\in L^1(\Omega)$ for $u\in H^1_0(\Omega)$ and provide a variational characterization of the maximal solution of the Liouville equation.

Conclusion: The results unify Hardy's and Trudinger's inequalities and offer new insights into the Liouville equation, including a global $H^1$ bound.

Abstract: Let $\Omega\subset{\mathbb R}^2$ be a bounded domain on which Hardy's
inequality holds. We prove that $[\exp(u^2)-1]/\delta^2\in L^1(\Omega)$ if
$u\in H^1_0(\Omega)$, where $\delta$ denotes the distance to $\partial\Omega$.
The corresponding higher-dimensional result is also given. These results
contain both Hardy's and Trudinger's inequalities, and yield a new variational
characterization of the maximal solution of the Liouville equation on smooth
domains, in terms of a renormalized functional. A global $H^1$ bound on the
difference between the maximal solution and the first term of its asymptotic
expansion follows.

</details>


### [25] [Long-time Existence and Incompressible Limit of Weak and Classical Solutions to the Cauchy Problem for Compressible Navier-Stokes Equations with Large Bulk Viscosity Coefficient and Large Initial Data](https://arxiv.org/abs/2507.02497)
*Qinghao Lei,Chengfeng Xiong*

Main category: math.AP

TL;DR: The paper studies the Cauchy problem for barotropic compressible Navier-Stokes equations in 2D, proving long-time existence of solutions and their convergence to incompressible limits as bulk viscosity grows.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of the Cauchy problem for compressible Navier-Stokes equations, especially with vacuum or nonvacuum far fields, and overcome the failure of Poincaré's inequality.

Method: Assumes a large bulk viscosity coefficient, uses a time-dependent Poincaré-type inequality, and imposes weighted-integrability conditions on initial density.

Result: Establishes long-time existence of weak, strong, and classical solutions and shows convergence to incompressible Navier-Stokes solutions as bulk viscosity tends to infinity.

Conclusion: The approach resolves key obstacles, enabling solutions without divergence-free initial velocity and providing insights into the incompressible limit.

Abstract: This paper investigates the Cauchy problem for the barotropic compressible
Navier-Stokes equations in $\mathbb{R}^2$ with the constant state as far field,
which could be vacuum or nonvacuum. Under the assumption of a sufficiently
large bulk viscosity coefficient, we establish the long-time existence of weak,
strong, and classical solutions, without imposing any extra restrictions on the
initial velocity divergence. Moreover, we demonstrate that the solutions of the
compressible Navier-Stokes equations converge to solutions of the inhomogeneous
incompressible Navier-Stokes equations, as the bulk viscosity coefficient tends
to infinity. The incompressible limit of the weak solutions holds even without
requiring the initial velocity to be divergence-free. The key obstacle in the
Cauchy problem is the failure of the Poincar\'e's inequality. This could be
resolved by introducing a time-dependent Poincar\'e's type inequality, but it
needs imposing weighted-integrability conditions on the initial density.

</details>


### [26] [Sharp second order inequalities with distance function to the boundary and applications to a p-Biharmonic singular problem](https://arxiv.org/abs/2507.02551)
*Cristian Cazacu,Teodor Rugină*

Main category: math.AP

TL;DR: Generalizations of Hardy-Rellich inequalities in L^p settings for domains with boundary distance singularities, with sharp results in bounded domains and new bounds for sharp constants. Applications include variational methods for singular problems.


<details>
  <summary>Details</summary>
Motivation: To extend Hardy-Rellich inequalities to L^p settings and explore their sharpness and dependence on domain geometry, with practical applications in solving singular problems.

Method: Proving generalizations of Hardy-Rellich inequalities, providing minimizing sequences for bounded domains, and using variational methods and Pohozaev identity for applications.

Result: Sharp inequalities in bounded domains, new bounds for sharp constants, and insights into existence/non-existence of solutions for singular problems.

Conclusion: The work advances understanding of Hardy-Rellich inequalities in L^p settings, with practical implications for solving singular problems via variational methods.

Abstract: In this paper, we prove generalizations to the L^p setting of the
Hardy-Rellich inequalities on domains of R^N with singularity given by the
distance function to the boundary. The inequalities we obtain are either sharp
in bounded domains, where we provide concrete minimizing sequences, or give a
new bound for the sharp constant, while also depending on the geometric
properties of the domain and its boundary. We also give applications to the
existence and non-existence of solutions for a singular problem using
variational methods and a Pohozaev identity.

</details>


### [27] [Homogenisation and spectral convergence of high-contrast convolution type operators](https://arxiv.org/abs/2507.02638)
*Mikhail Cherdantsev,Andrey Piatnitski,Igor Velcic*

Main category: math.AP

TL;DR: The paper studies homogenization of high-contrast convolution-type operators in periodic microstructures, using two-scale convergence for spectral analysis.


<details>
  <summary>Details</summary>
Motivation: To analyze homogenization and spectral behavior of nonlocal operators in periodic media.

Method: Adapts two-scale convergence for convolution-type operators, examining whole space and bounded domains with Dirichlet conditions.

Result: The limit operator's spectrum is a subset of the original's, but they may not coincide.

Conclusion: Homogenization and spectral analysis reveal differences between the limit and original operators' spectra.

Abstract: The paper deals with homogenisation problems for high-contrast symmetric
convolution-type operators with integrable kernels in media with a periodic
microstructure. We adapt the two-scale convergence method to nonlocal
convolution-type operators and obtain the homogenisation result both for
problems stated in the whole space and in bounded domains with the homogeneous
Dirichlet boundary condition.
  Our main focus is on spectral analysis. We describe the spectrum of the limit
two-scale operator and characterize the limit behaviour of the spectrum of the
original problem as the microstructure period tends to zero. It is shown that
the spectrum of the limit operator is a subset the limit of the spectrum of the
original operator, and that they need not coincide.

</details>


### [28] [On the two-dimensional Navier-Stokes equations with horizontal viscosity](https://arxiv.org/abs/2507.02775)
*Chongsheng Cao,Yanqiu Guo*

Main category: math.AP

TL;DR: Analysis of a 2D channel flow with horizontal viscosity, focusing on well-posedness, long-term behavior, and stability under minimal initial differentiability.


<details>
  <summary>Details</summary>
Motivation: To study fluid dynamics in a 2D channel with horizontal viscosity, addressing theoretical gaps in well-posedness and stability under low-regularity initial conditions.

Method: Assumes periodic horizontal boundaries and hard walls, with horizontal viscosity. Analyzes solutions with initial velocity in $L^2(\Omega)$ and $\partial_y u_0 \in L^2(\Omega)$.

Result: Demonstrates global well-posedness and stability for solutions under the specified initial conditions.

Conclusion: The study provides theoretical foundations for understanding 2D channel flows with minimal initial regularity, contributing to fluid dynamics research.

Abstract: This paper is concerned with a 2D channel flow that is periodic horizontally
but bounded above and below by hard walls. We assume the presence of horizontal
viscosity only. We study the well-posedness, large-time behavior, and stability
of solutions. For global well-posedness, we aim to assume less
differentiability on initial velocity $(u_0, v_0)$: in particular, we assume
$u_0,v_0\in L^2(\Omega)$ and $\partial_y u_0 \in L^2(\Omega)$.

</details>


### [29] [Vanishing Vertical Viscosity in Two-Dimensional Anisotropic Navier-Stokes Equations with No-Slip Boundary Conditions: An $L^p$ result](https://arxiv.org/abs/2507.02794)
*Chongsheng Cao,Yanqiu Guo*

Main category: math.AP

TL;DR: The paper investigates the inviscid limit of 2D Navier-Stokes equations with anisotropic viscosity, proving strong $L^p$ convergence for $H^2$ initial velocity as vertical viscosity vanishes.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of boundary condition mismatch (no-slip vs. slip) in the inviscid limit problem.

Method: Analyzes the 2D Navier-Stokes equations with anisotropic viscosity, focusing on $H^2$ initial velocity and impenetrable walls.

Result: Strong $L^p$ convergence is established for $2 \leq p < \infty$ as vertical viscosity approaches zero.

Conclusion: The study successfully resolves the boundary condition mismatch issue, proving convergence to the limiting problem.

Abstract: This paper studies the inviscid limit problem for the two-dimensional
Navier-Stokes equations with anisotropic viscosity. The fluid is assumed to be
bounded above and below by impenetrable walls, with a no-slip boundary
condition imposed on the bottom wall. For $H^2$ initial velocity, we establish
strong convergence in the $L^p$ norm to the limiting problem as the vertical
viscosity approaches zero, for any $2\leq p <\infty$. The main challenge lies
in the mismatch of boundary conditions - specifically, the no-slip condition in
the original problem versus the slip condition in the limiting problem.

</details>


### [30] [On the Boundary Harnack Principle for operators with different lower order terms](https://arxiv.org/abs/2507.02836)
*Daniela De Silva,Ovidiu Savin*

Main category: math.AP

TL;DR: Classical Boundary Harnack principle extended to Lipschitz domains for solutions of two linear elliptic equations with identical principal parts.


<details>
  <summary>Details</summary>
Motivation: To generalize the Boundary Harnack principle for solutions of distinct but related elliptic equations in Lipschitz domains.

Method: Analyze solutions to two linear uniformly elliptic equations sharing the same principal part within Lipschitz domains.

Result: Established the Boundary Harnack principle for such solutions, ensuring comparability near the boundary.

Conclusion: The principle holds for solutions of related elliptic equations in Lipschitz domains, extending classical results.

Abstract: We provide the classical Boundary Harnack principle in Lipschitz domains for
solutions to two different linear uniformly elliptic equations with the same
principal part.

</details>


### [31] [Free boundary regularity for a tumor growth model with obstacle](https://arxiv.org/abs/2507.02837)
*Giulia Bevilacqua,Matteo Carducci*

Main category: math.AP

TL;DR: The paper develops a theory for existence and regularity of solutions to a geometric free boundary problem in tumor growth models, using viscosity solutions and proving boundary regularity.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by tumor growth models where the tumor spreads in a region but is obstructed by another region, requiring analysis of free boundary behavior.

Method: Existence of viscosity solutions is shown via Perron's method. Interior and boundary regularity are analyzed using improvement of flatness and studying a thin obstacle problem with oblique conditions.

Result: The free boundary meets the obstacle as a C^{1,α} graph, and C^{1,α} estimates are established for the thin obstacle problem.

Conclusion: The paper provides a robust framework for analyzing free boundary problems in tumor growth, with implications for understanding tumor spread and obstruction.

Abstract: We develop an existence and regularity theory for solutions to a geometric
free boundary problem motivated by models of tumor growth. In this setting, the
tumor invades an accessible region $D$, its motion is directed along a constant
vector $V$, and it cannot penetrate another region $K$ acting as an obstacle to
the spread of the tumor. Due to the non variational structure of the problem,
we show existence of viscosity solutions via Perron's method. Subsequently, we
prove interior regularity for the free boundary near regular points by means of
an improvement of flatness argument. We further analyze the boundary regularity
and we prove that the free boundary meets the obstacle as a $C^{1,\alpha}$
graph. A key step in the analysis of the boundary regularity involves the study
of a thin obstacle problem with oblique boundary conditions, for which we
establish $C^{1,\alpha}$ estimates.

</details>


### [32] [Diffeomorphic approximation of piecewise affine homeomorphisms](https://arxiv.org/abs/2507.02854)
*Daniel Campbell,Luigi D'Onofrio,Tomáš Vítek*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Given any $f$ a locally finitely piecewise affine homeomorphism of $\Omega
\subset \mathbb{R}^d$ onto $\Delta \subset \mathbb{R}^d$ (for $d=3, 4$) such
that $f\in W^{1,p}(\Omega, \mathbb{R}^d)$ and $f^{-1}\in W^{1,q}(\Delta,
\mathbb{R}^d)$, $1\leq p ,q < \infty$ and any $\epsilon >0$ we construct a
diffeomorphism $\tilde{f}$ such that
  $$\|f-\tilde{f}\|_{W^{1,p}(\Omega,\mathbb{R}^d)} +
\|f^{-1}-\tilde{f}^{-1}\|_{W^{1,q}(\Delta,\mathbb{R}^d)} < \epsilon.$$

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [33] [A Multi-Level Monte Carlo Tree Search Method for Configuration Generation in Crystalline Systems](https://arxiv.org/abs/2507.02509)
*Xiaoxu Li,Ge Xu,Huajie Chen,Xingyu Gao,Haifeng Song*

Main category: physics.comp-ph

TL;DR: A multi-level Monte Carlo tree search algorithm is developed to efficiently identify optimal atomic configurations in crystalline materials with substitutional defects.


<details>
  <summary>Details</summary>
Motivation: Predicting and designing atomic structures in crystalline materials with substitutional defects is challenging due to combinatorial growth and rugged landscapes.

Method: A multi-level Monte Carlo tree search algorithm with hierarchical decomposition of the crystalline structure is used to explore configuration space.

Result: Numerical experiments demonstrate the method's efficiency in finding optimal configurations.

Conclusion: The proposed algorithm effectively addresses the challenges of combinatorial growth and rugged landscapes in crystalline material design.

Abstract: In this paper, we study the construction of structural models for the
description of substitutional defects in crystalline materials. Predicting and
designing the atomic structures in such systems is highly challenging due to
the combinatorial growth of atomic arrangements and the ruggedness of the
associated landscape. We develop a multi-level Monte Carlo tree search
algorithm to generate the "optimal" configuration within a supercell. Our
method explores the configuration space with an expanding search tree through
random sampling, which further incorporates a hierarchical decomposition of the
crystalline structure to accelerate exploration and reduce redundancy. We
perform numerical experiments on some typical crystalline systems to
demonstrate the efficiency of our method in identifying optimal configurations.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [34] [Impact of super-Gaussian electron distributions on plasma K-shell emission](https://arxiv.org/abs/2507.02341)
*H. P. Le,E. V. Marley,H. A. Scott*

Main category: physics.plasm-ph

TL;DR: Super-Gaussian electron distributions in plasmas alter K-shell emission, enabling spectroscopy to infer non-equilibrium distributions.


<details>
  <summary>Details</summary>
Motivation: To understand how super-Gaussian electron distributions impact ionization balance and K-shell emission in plasmas.

Method: Combines approximate formulas and collisional-radiative simulations.

Result: Small effect on ionization balance but significant modification of K-shell spectra.

Conclusion: K-shell spectroscopy can infer super-Gaussian or similar non-equilibrium electron distributions.

Abstract: Electron distributions in laser-produced plasmas will be driven toward a
super-Gaussian distribution due to inverse bremsstrahlung absorption [Langdon,
Phys. Rev. Lett. 44, 575 (1980)]. Both theoretical and experimental evidence
suggest that fundamental plasma properties are altered by the super-Gaussian
distribution. This paper examines how the super-Gaussian distribution affects
the ionization balance and K-shell emission of atomic plasmas, utilizing
approximate formulas and detailed collisional-radiative simulations. While the
impact on plasma ionization is small, K-shell spectra can be significantly
modified. Based on these findings, we demonstrate that K-shell spectroscopy can
be used to infer super-Gaussian or other similar non-equilibrium electron
distributions.

</details>


### [35] [Electron heating in bulk overdense plasma aided by time dependent external magnetic field](https://arxiv.org/abs/2507.02543)
*Rohit Juneja,Trishul Dhalia,Amita Das*

Main category: physics.plasm-ph

TL;DR: The study explores localized electron heating in overdense plasma using a time-dependent magnetic field and laser interaction, achieving Electron Cyclotron Resonance (ECR) for energy transfer to electrons.


<details>
  <summary>Details</summary>
Motivation: To investigate efficient electron heating in overdense plasma by leveraging magnetic fields and laser interactions, a challenge in plasma physics.

Method: Uses a decaying external magnetic field to enable laser propagation and achieve ECR with laser frequency, simulated via Particle-In-Cell (PIC) on OSIRIS4.0.

Result: Demonstrates electron energy gain varies with magnetic field profiles, laser intensities, and polarizations, with potential experimental feasibility.

Conclusion: The method shows promise for future experiments, though current magnetic field technology (1.4 kT) needs scaling up for practical applications like CO$_2$ lasers.

Abstract: This study investigates the localized electron heating in a bulk overdense
plasma. The method relies on using a time dependent magnetic field. An
initially high external magnetic field imposed on the overdense plasma target
enables the propagation of a laser pulse inside it through the pass bands that
occur in the magnetized dispersion relation. The choice of decaying external
magnetic field is then tailored appropriately to achieve Electron Cyclotron
Resonance (ECR) with the frequency of the laser electromagnetic field. At the
resonance location, the field energy of the laser gets transferred to the
electrons. These studies have been carried out with the help of the
Particle-In-Cell (PIC) simulation technique on the OSIRIS4.0 platform. A
detailed study has been carried out to illustrate the energy gain by electrons
for a variety of temporal profiles of the magnetic field, laser intensities,
and polarizations. The experiments in this regime may be within reach in the
near future. For instance, the choice of long-wavelength CO$_2$ laser requires
a magnetic field of about 10s of kilo Tesla to comfortably elicit a magnetized
response from electrons. Recent technological advancements have shown the
generation of about 1.4 kilo Tesla of magnetic field.

</details>


### [36] [Boosting the NOx production in microwave air plasma: A synergy of chemistry and vibrational kinetics](https://arxiv.org/abs/2507.02795)
*Qinghao Shen,Aleksandr Pikalev,Jonas Gans,Lex Kuijpers,Ashley Hughes,Vasco Guerra,M. C. M van de Sanden*

Main category: physics.plasm-ph

TL;DR: A quasi-1.5D model analyzes NOx production in microwave plasma reactors, revealing non-thermal processes enhance NOx in the discharge zone but diminish in the afterglow. Turbulence aids NO diffusion and cooling, suggesting efficiency improvements via turbulence optimization.


<details>
  <summary>Details</summary>
Motivation: To understand the mechanisms of NOx production and energy costs in microwave plasma reactors, focusing on vibrational, chemical, and electron kinetics, thermodynamics, and transport processes.

Method: A quasi-1.5D multi-temperature model is used to simulate the discharge and afterglow regions, comparing results with experimental data.

Result: Non-thermal processes boost NOx production in the discharge zone but fade in the afterglow. Turbulence enhances NO diffusion and cooling, aligning with experimental data.

Conclusion: Optimizing turbulence and maintaining non-thermal conditions can improve NOx synthesis efficiency, advancing plasma-based chemical processes.

Abstract: This study employs a quasi-1.5D multi-temperature model to investigate the
mechanisms governing NOx production and energy costs in microwave plasma
reactors operating at 80 mbar, focusing on the interplay of vibrational,
chemical and electron kinetics, thermodynamics, and transport processes across
the discharge and afterglow. In the plasma discharge zone, non-thermal
processes enhance NOx production as electrons transfer energy effectively to
the vibrational mode of N2. However, the non-thermal enhancement is found to
diminish rapidly within the central-afterglow region. The simulation results
show good agreement with experimental data for both the temperature profile and
energy cost. Turbulent effects facilitate radial NO diffusion into cooler
regions while simultaneously enhancing cooling of the axial region. These
findings highlight the potential to improve NOx synthesis efficiency by
optimizing turbulence and maintaining non-thermal conditions, offering new
opportunities for the advancement of plasma-based chemical processes.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [37] [Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework](https://arxiv.org/abs/2507.02106)
*Semih Kacmaz,E. A. Huerta,Roland Haas*

Main category: physics.flu-dyn

TL;DR: A hybrid framework combining Physics-Informed Neural Operators (PINOs) and diffusion models accurately simulates 2D MHD turbulence across a wide Reynolds number range, outperforming deterministic methods.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of simulating fully developed turbulence across varying Reynolds numbers, where deterministic surrogates fail, especially at high turbulence levels.

Method: Uses PINOs for low-frequency dynamics and a conditional diffusion model for high-frequency corrections, trained on high-fidelity simulations.

Result: Achieves state-of-the-art accuracy, capturing spectral energy distributions, non-Gaussian statistics, and cross-field correlations, even at extreme turbulence (Re=10000).

Conclusion: The hybrid framework enables accurate, high-fidelity simulations of MHD turbulence, surpassing previous deterministic approaches.

Abstract: We present a hybrid machine learning framework that combines Physics-Informed
Neural Operators (PINOs) with score-based generative diffusion models to
simulate the full spatio-temporal evolution of two-dimensional, incompressible,
resistive magnetohydrodynamic (MHD) turbulence across a broad range of Reynolds
numbers ($\mathrm{Re}$). The framework leverages the equation-constrained
generalization capabilities of PINOs to predict coherent, low-frequency
dynamics, while a conditional diffusion model stochastically corrects
high-frequency residuals, enabling accurate modeling of fully developed
turbulence. Trained on a comprehensive ensemble of high-fidelity simulations
with $\mathrm{Re} \in \{100, 250, 500, 750, 1000, 3000, 10000\}$, the approach
achieves state-of-the-art accuracy in regimes previously inaccessible to
deterministic surrogates. At $\mathrm{Re}=1000$ and $3000$, the model
faithfully reconstructs the full spectral energy distributions of both velocity
and magnetic fields late into the simulation, capturing non-Gaussian
statistics, intermittent structures, and cross-field correlations with high
fidelity. At extreme turbulence levels ($\mathrm{Re}=10000$), it remains the
first surrogate capable of recovering the high-wavenumber evolution of the
magnetic field, preserving large-scale morphology and enabling statistically
meaningful predictions.

</details>


### [38] [Predicting Flow-Induced Vibration in Isolated and Tandem Cylinders Using Hypergraph Neural Networks](https://arxiv.org/abs/2507.02242)
*Shayan Heydari,Rui Gao,Rajeev K Jaiman*

Main category: physics.flu-dyn

TL;DR: A hypergraph neural network framework predicts flow-induced vibrations in cylinders, using finite-element-inspired methods to model fluid-structure interactions with high accuracy.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of accurately predicting flow-induced vibrations in freely oscillating cylinders, which is critical for applications like digital twins.

Method: The framework transforms unstructured meshes into hypergraphs, uses a modular architecture for temporal evolution, and trains on high-fidelity ALE simulations.

Result: The model accurately predicts oscillation amplitudes, resolves wake-body interactions, and reproduces force statistics and flow-field dynamics.

Conclusion: The framework is a robust surrogate model for digital twin applications, demonstrating high fidelity in complex scenarios.

Abstract: We present a finite element-inspired hypergraph neural network framework for
predicting flow-induced vibrations in freely oscillating cylinders. The
surrogate architecture transforms unstructured computational meshes into
node-element hypergraphs that encode higher-order spatial relationships through
element-based connectivity, preserving the geometric and topological structure
of the underlying finite-element discretization. The temporal evolution of the
fluid-structure interaction is modeled via a modular partitioned architecture:
a complex-valued, proper orthogonal decomposition-based sub-network predicts
mesh deformation using a low-rank representation of Arbitrary
Lagrangian-Eulerian (ALE) grid displacements, while a hypergraph-based
message-passing network predicts the unsteady flow field using geometry-aware
node, element, and hybrid edge features. High-fidelity ALE-based simulations
provide training and evaluation data across a range of Reynolds numbers and
reduced velocities for isolated and tandem cylinder configurations. The
framework demonstrates stable roll-outs and accurately captures the nonlinear
variation of oscillation amplitudes with respect to reduced velocity, a key
challenge in surrogate modeling of flow-induced vibrations. In the tandem
configuration, the model successfully resolves complex wake-body interactions
and multi-scale coupling effects, enabling accurate prediction of pressure and
velocity fields under strong wake interference conditions. Our results show
high fidelity in reproducing force statistics, dominant frequencies, and
flow-field dynamics, supporting the framework's potential as a robust surrogate
model for digital twin applications.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [39] [Cauchy problem for the localized wave propagation in continuous model of the one-dimensional diatomic crystal](https://arxiv.org/abs/2507.02729)
*Sergey Sergeev*

Main category: math-ph

TL;DR: Asymptotic solution for wave propagation in a diatomic lattice, analyzed for two parameter regimes using Airy functions.


<details>
  <summary>Details</summary>
Motivation: To understand localized wave propagation in a 1D diatomic lattice under varying perturbation sizes.

Method: Construct asymptotic solutions for a continuous Cauchy problem with two small parameters (lattice step and perturbation size), using Airy functions.

Result: Solutions vary based on the ratio of parameters; analytical formulae provided for large and comparable perturbation sizes.

Conclusion: The study provides insights into wave behavior in diatomic lattices, with solutions dependent on perturbation size relative to the lattice step.

Abstract: We study the continuous model of the localized wave propagation corresponding
to the one-dimensional diatomic crystal lattice. From the mathematical point of
view the problem can be described in terms of the Cauchy problem with localized
initial data for a system of two pseudo-differential equations. We assume two
small parameters in this formulation -- the lattice step and the size if the
initial perturbation. We construct the asymptotic solution of the continuous
Cauchy problem with respect to the size of perturbation.
  The ratio of the small parameters drastically affects the form of the
solution. We consider two situations -- when the size of the perturbation is
sufficiently large and when it is comparable with the lattice step. In each
situations we provide analytical formulae for the asymptotic solution via Airy
function.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [40] [Is the hyperscaling relation violated below the upper critical dimension in some particular cases?](https://arxiv.org/abs/2507.02159)
*Hung T. Diep,Van-Thanh Ngo*

Main category: cond-mat.stat-mech

TL;DR: The paper analyzes critical exponents in thin films using Monte Carlo simulations, revealing deviations from 2D values and violations of hyperscaling, suggesting an 'effective' dimension. It also explores cross-over transitions and new universality classes in 2D systems with multiple order parameters.


<details>
  <summary>Details</summary>
Motivation: To investigate critical exponents in thin films and understand deviations from standard 2D and 3D Ising model predictions, as well as explore new universality classes in systems with coupled order parameters.

Method: High-performance multi-histogram Monte Carlo simulations with free boundary conditions in the z-direction and periodic boundary conditions in the xy-plane. The Ising model with nearest-neighbor interactions is studied for varying film thicknesses.

Result: Critical exponents for N_z>1 deviate slightly but systematically from 2D values, violating hyperscaling. An 'effective' dimension larger than 2 is observed. Cross-over transitions and new critical exponents for coupled order parameters are also identified.

Conclusion: The findings suggest deviations from standard hyperscaling relations and introduce new universality classes for systems with coupled symmetries, highlighting the complexity of critical behavior in thin films.

Abstract: In this review, we show our results with new interpretation on the critical
exponents of thin films obtained by high-performance multi-histogram Monte
Carlo simulations. The film thickness $N_z$ consists of a few layers up to a
dozen of layers in the $z$ direction. The free boundary condition is applied in
this direction while in the $xy$ plane periodic boundary conditions are used.
Large $xy$ plane sizes are used for finite-size scaling. The Ising model is
studied with nearest-neighbor (NN) interaction. When $N_z=1$, namely the
two-dimensional (2D) system, we find the critical exponents given by the
renormalization group. While, for $N_z>1$, the critical exponents calculated
with the high-precision multi-histogram technique show that they deviate
slightly but systematically from the 2D values. If we use these values of
critical exponents in the hyperscaling relation with $d=2$, then the
hyperscaling relation is violated. However, if we use the hyperscaling relation
and the critical exponents obtained for $N_z>1$ to calculate the dimension of
the system, we find the system dimension slightly larger than 2. This can be
viewed as an "effective" dimension. More discussion is given in the paper. We
also show the cross-over between the first- and second-order transition while
varying the film thickness in an antiferromagnetic FCC Ising frustrated thin
film. In addition, we will show evidence that when a 2D system has two order
parameters of different symmetries with a single transition, the critical
exponents are new, suggesting a universality class of coupled two-symmetry
breakings. In this case, the 2D hyperscaling does not hold. Another case is the
3D Ising model coupled to the lattice vibration: the critical exponents deviate
from the 3D Ising ones, the results suggest the violation of the hyperscaling.

</details>


<div id='astro-ph.CO'></div>

# astro-ph.CO [[Back]](#toc)

### [41] [A general polynomial emulator for cosmology via moment projection](https://arxiv.org/abs/2507.02179)
*Zheng Zhang*

Main category: astro-ph.CO

TL;DR: MomentEmu is a polynomial emulator for fast, interpretable mappings between theoretical parameters and observational features, offering negligible training cost and millisecond evaluation.


<details>
  <summary>Details</summary>
Motivation: To provide a lightweight, transparent alternative to neural-network-based emulators for cosmological analysis.

Method: Constructs moment matrices to project simulation data onto polynomial bases, yielding symbolic expressions.

Result: Achieves sub-percent accuracy in emulating CMB power spectra and acoustic peak features, with symbolic forms consistent with known approximations.

Conclusion: MomentEmu is suitable for forward modeling, parameter inference, and uncertainty propagation in moderate-dimensional, smooth-mapping scenarios.

Abstract: We present MomentEmu, a general-purpose polynomial emulator for fast and
interpretable mappings between theoretical parameters and observational
features. The method constructs moment matrices to project simulation data onto
polynomial bases, yielding symbolic expressions that approximate the target
mapping. Compared to neural-network-based emulators, MomentEmu offers
negligible training cost, millisecond-level evaluation, and transparent
functional forms. As a demonstration, we develop two emulators:
PolyCAMB-$D_\ell$, which maps six cosmological parameters to the CMB
temperature power spectrum, and PolyCAMB-peak, which enables bidirectional
mapping between parameters and acoustic peak features. PolyCAMB-$D_\ell$
achieves an accuracy of $0.03\%$over $\ell \leq 2510$, while PolyCAMB-peak also
reaches sub-percent accuracy and produces symbolic forms consistent with known
analytical approximations. The method is well suited for forward modelling,
parameter inference, and uncertainty propagation, particularly when the
parameter space is moderate in dimensionality and the mapping is smooth.
MomentEmu offers a lightweight and portable alternative to regression-based or
black-box emulators in cosmological analysis.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [42] [Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning](https://arxiv.org/abs/2507.02211)
*Gustavo C. Mangold,Heitor C. M. Fernandes,Mendeli H. Vainstein*

Main category: cs.AI

TL;DR: The paper explores how dilution and mobility affect cooperation in spatial prisoner's dilemma games using multi-agent Q-learning, showing equivalence between fixed and learned rules and symbiotic effects.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of dilution and mobility on cooperation in spatial prisoner's dilemma games using reinforcement learning.

Method: Uses an independent multi-agent Q-learning algorithm to model the game, varying actions to connect with classical results.

Result: Observes equivalence between fixed and learned rules and identifies symbiotic mutualistic effects in populations.

Conclusion: Demonstrates the algorithm's versatility in modeling game-theoretical scenarios and its benchmarking potential.

Abstract: Recent studies in the spatial prisoner's dilemma games with reinforcement
learning have shown that static agents can learn to cooperate through a diverse
sort of mechanisms, including noise injection, different types of learning
algorithms and neighbours' payoff knowledge.In this work, using an independent
multi-agent Q-learning algorithm, we study the effects of dilution and mobility
in the spatial version of the prisoner's dilemma. Within this setting,
different possible actions for the algorithm are defined, connecting with
previous results on the classical, non-reinforcement learning spatial
prisoner's dilemma, showcasing the versatility of the algorithm in modeling
different game-theoretical scenarios and the benchmarking potential of this
approach.As a result, a range of effects is observed, including evidence that
games with fixed update rules can be qualitatively equivalent to those with
learned ones, as well as the emergence of a symbiotic mutualistic effect
between populations that forms when multiple actions are defined.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [43] [Spin Caloritronics in irradiated chiral ferromagnetic systems](https://arxiv.org/abs/2507.02765)
*Sudin Ganguly,Moumita Dey,Santanu K. Maiti*

Main category: cond-mat.mes-hall

TL;DR: Study of thermoelectric response in a ferromagnetic helical system under light irradiation, revealing enhanced spin thermoelectric performance.


<details>
  <summary>Details</summary>
Motivation: To explore the charge and spin-dependent thermoelectric properties of ferromagnetic helical systems under light irradiation for potential energy conversion applications.

Method: Uses tight-binding framework, Floquet-Bloch formalism, non-equilibrium Green's function technique for transport, and mass-spring model for phonon thermal conductance.

Result: Light induces spin-split transmission, suppresses thermal conductance, and improves spin thermopower and FOM, outperforming charge FOM. Long-range hopping further enhances performance.

Conclusion: Light irradiation and long-range hopping significantly improve spin thermoelectric efficiency, offering a promising approach for energy conversion in ferromagnetic systems.

Abstract: We study the charge and spin-dependent thermoelectric response of a
ferromagnetic helical system irradiated by arbitrarily polarized light, using a
tight-binding framework and the Floquet-Bloch formalism. Transport properties
for individual spin channels are determined by employing the non-equilibrium
Green's function technique, while phonon thermal conductance is evaluated using
a mass-spring model with different lead materials. The findings reveal that
that light irradiation induces spin-split transmission features, suppresses
thermal conductance, and yields favorable spin thermopower and figure of merit
(FOM). The spin FOM consistently outperforms its charge counterpart under
various light conditions. Moreover, long-range hopping is shown to enhance the
spin thermoelectric performance, suggesting a promising strategy for efficient
energy conversion in related ferromagnetic systems.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [44] [Time Resolution Independent Operator Learning](https://arxiv.org/abs/2507.02524)
*Diab W. Abueidda,Mbebo Nonna,Panos Pantidis,Mostafa E. Mobasher*

Main category: cs.CE

TL;DR: NCDE-DeepONet is a continuous-time operator network for learning solution operators of time-dependent PDEs, overcoming limitations of RNNs and neural-ODEs by using Neural Controlled Differential Equations (NCDEs) for input-resolution-independent encoding and output-resolution-independent predictions.


<details>
  <summary>Details</summary>
Motivation: Existing methods like RNNs and neural-ODEs have limitations in handling sparse, irregular data and incorporating new inputs after initialization, necessitating a more robust approach for learning solution operators of time-dependent PDEs.

Method: NCDE-DeepONet embeds a Neural Controlled Differential Equation (NCDE) in the branch to encode load histories as solutions of controlled ODEs, while the trunk uses explicit space-time coordinates for predictions at arbitrary locations and times.

Result: The framework achieves robust and accurate predictions on transient Poisson, elastodynamic, and thermoelastic problems, enabling almost instant solution prediction without retraining or interpolation.

Conclusion: Controlled dynamics provide a principled and efficient foundation for high-fidelity operator learning in transient mechanics.

Abstract: Accurately learning solution operators for time-dependent partial
differential equations (PDEs) from sparse and irregular data remains a
challenging task. Recurrent DeepONet extensions inherit the discrete-time
limitations of sequence-to-sequence (seq2seq) RNN architectures, while
neural-ODE surrogates cannot incorporate new inputs after initialization. We
introduce NCDE-DeepONet, a continuous-time operator network that embeds a
Neural Controlled Differential Equation (NCDE) in the branch and augments the
trunk with explicit space-time coordinates. The NCDE encodes an entire load
history as the solution of a controlled ODE driven by a spline-interpolated
input path, making the representation input-resolution-independent: it encodes
different input signal discretizations of the observed samples. The trunk then
probes this latent path at arbitrary spatial locations and times, rendering the
overall map output-resolution independent: predictions can be queried on meshes
and time steps unseen during training without retraining or interpolation.
Benchmarks on transient Poisson, elastodynamic, and thermoelastic problems
confirm the robustness and accuracy of the framework, achieving almost instant
solution prediction. These findings suggest that controlled dynamics provide a
principled and efficient foundation for high-fidelity operator learning in
transient mechanics.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [45] [Hybrid least squares for learning functions from highly noisy data](https://arxiv.org/abs/2507.02215)
*Ben Adcock,Bernhard Hientzsch,Akil Narayan,Yiming Xu*

Main category: stat.ML

TL;DR: A hybrid method combining Christoffel sampling and optimal experimental design is proposed for efficient conditional expectation estimation with noisy data, outperforming existing methods in high-noise scenarios.


<details>
  <summary>Details</summary>
Motivation: The need for efficient estimation of conditional expectations in the presence of heavily polluted data drives the research. Existing methods are suboptimal for large noise.

Method: A hybrid approach integrating Christoffel sampling and optimal experimental design is introduced, with extensions to convex-constrained settings and adaptive random subspaces.

Result: The algorithm shows improved computational efficiency and sample complexity, with theoretical guarantees and numerical validation on synthetic and real-world data.

Conclusion: The proposed method effectively addresses high-noise challenges, offering theoretical and practical advantages over existing approaches.

Abstract: Motivated by the need for efficient estimation of conditional expectations,
we consider a least-squares function approximation problem with heavily
polluted data. Existing methods that are powerful in the small noise regime are
suboptimal when large noise is present. We propose a hybrid approach that
combines Christoffel sampling with certain types of optimal experimental design
to address this issue. We show that the proposed algorithm enjoys appropriate
optimality properties for both sample point generation and noise mollification,
leading to improved computational efficiency and sample complexity compared to
existing methods. We also extend the algorithm to convex-constrained settings
with similar theoretical guarantees. When the target function is defined as the
expectation of a random field, we extend our approach to leverage adaptive
random subspaces and establish results on the approximation capacity of the
adaptive procedure. Our theoretical findings are supported by numerical studies
on both synthetic data and on a more challenging stochastic simulation problem
in computational finance.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [46] [Langmuir Wave Excitation in Solar-wind Magnetic Holes](https://arxiv.org/abs/2507.02042)
*Jingting Liu,Daniel Verscharen,Jesse Coburn,Georgios Nicolaou,Xiangyu Wu,Wence Jiang,Oreste Pezzi,Francesco Pucci,Matteo Zuin,Christopher J. Owen,Hamish Reid*

Main category: physics.space-ph

TL;DR: A model explains Langmuir wave excitation in solar wind magnetic holes via electron velocity changes, validated by Solar Orbiter data.


<details>
  <summary>Details</summary>
Motivation: To understand the link between magnetic holes and Langmuir waves in the solar wind.

Method: Developed a model based on magnetic-moment conservation and its violation, tested with Solar Orbiter observations.

Result: Model predictions align with observations, confirming the mechanism for Langmuir wave production.

Conclusion: The proposed process is a viable explanation for Langmuir waves in magnetic holes.

Abstract: Magnetic holes are structures commonly observed in various space plasma
environments throughout the solar system, including the solar wind. These
structures are characterized by a localized decrease in magnetic field
strength, coincident with an increase in plasma density. Previous observational
studies in the solar wind link the presence of Langmuir waves to magnetic
holes, suggesting a strong correlation between these phenomena. We develop a
model based on magnetic-moment conservation and its violation to explain the
excitation of Langmuir waves in magnetic holes. Our model illustrates that
magnetic holes induce changes in the electron velocity distribution function
that emit electrostatic Langmuir waves due to the bump-on-tail instability.
Using data from the Solar Orbiter spacecraft, we provide a comprehensive
analysis of this process and test our predictions with observations. The
consistency between the model and observations indicates that our proposed
process is a viable mechanism for producing Langmuir waves in magnetic holes in
the solar wind.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [47] [MeV cosmic-ray electrons modify the TeV pair-beam plasma instability](https://arxiv.org/abs/2507.02423)
*Mahmoud Alawashra,Yuanyuan Yang,Christopher M. Hirata,Heyang Long,Martin Pohl*

Main category: astro-ph.HE

TL;DR: The paper explores how linear Landau damping (LLD) affects plasma instabilities in relativistic pair beams, finding it suppresses oblique modes but enhances energy-loss efficiency.


<details>
  <summary>Details</summary>
Motivation: To explain the absence of GeV-scale electromagnetic cascades in blazar spectra, focusing on the role of LLD in suppressing plasma instabilities.

Method: Study the impact of LLD on plasma instabilities in pair beams from blazar 1ES 0229+200, analyzing mode suppression and energy-loss efficiency.

Result: LLD suppresses oblique electrostatic modes but allows quasi-parallel modes to grow, increasing energy-loss efficiency by over an order of magnitude.

Conclusion: LLD significantly enhances the energy-loss efficiency of plasma instabilities, offering an explanation for missing GeV cascades in blazar spectra.

Abstract: Relativistic pair beams created in the intergalactic medium (IGM) by TeV
gamma rays from blazars are expected to produce a detectable GeV-scale
electromagnetic cascade, but the cascade component is absent in the spectra of
many hard-spectrum TeV-emitting blazars. One common explanation is that weak
intergalactic magnetic fields deflect the electron-positron pairs away from our
line of sight. An alternative possibility is that electrostatic beam-plasma
instabilities drain the energy of these pairs before a cascade can develop.
Recent studies have shown that beam scattering by oblique electrostatic modes
leads to minimal energy loss. But these modes might be suppressed by linear
Landau damping (LLD) due to MeV-scale cosmic-ray electrons in the IGM. In this
work, we explore the impact of LLD on the energy-loss efficiency of plasma
instabilities in pair beams associated with 1ES 0229+200. We find that LLD
effectively suppresses oblique electrostatic modes, while quasi-parallel ones
grow to larger amplitudes. In this way, LLD enhances the energy-loss efficiency
of the instability by more than an order of magnitude.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [48] [On the Design of Corrugated Boards: A New FEM Modeling and Experimental Validation](https://arxiv.org/abs/2507.02189)
*Ricardo Fitas,Heinz Joachim Schaffrath,Samuel Schabel*

Main category: physics.app-ph

TL;DR: A simplified FEM modeling approach for corrugated boards uses homogenization and correction factors to reduce computational time while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: To optimize corrugated packaging design by simplifying FEM models for faster, accurate simulations.

Method: Homogenization transforms flute geometries into equivalent elastic models, with correction factors (Weibull distributions) for contact and buckling mechanisms.

Result: Validated statistical parameters (β₁=0.14, β₂=1.31) enable computationally efficient simulations.

Conclusion: The approach simplifies FEM models for corrugated boards, aiding in faster and accurate packaging design optimization.

Abstract: This study presents a simplified FEM modeling approach suitable for large
structures made of corrugated boards, such as customized packages, based on a
homogenization method, which is combined with correction factors for internal
mechanisms. The homogenization process reduces computational time by
transforming flute geometries into equivalent elastic models. In large
deformations and in the presence of contact for a given geometry, the effective
elastic modulus in the thickness direction, as well as the effective thickness
of the structure, are corrected by two statistical Weibull distributions
representing the contact and buckling mechanisms in a corrugated board. The
Weibull parameters are obtained via experimental analysis, and such a process
is then validated. The results demonstrate that the statistical parameters
($\beta_1 = 0.14$, $\beta_2 = 1.31$) can be used for the simplistic
representation of corrugated boards, being computationally efficient. This
research contributes to the optimization of corrugated packaging design,
specifically by simplifying FEM models for faster yet equally accurate
simulations.

</details>


### [49] [Modeling the Effective Elastic Modulus and Thickness of Corrugated Boards Using Gaussian Process Regression and Expected Hypervolume Improvement](https://arxiv.org/abs/2507.02208)
*Ricardo Fitas*

Main category: physics.app-ph

TL;DR: The paper models the hypersurface of effective elastic modulus and thickness in corrugated boards using LHS and GP with EHVI, achieving accurate predictions for engineering applications.


<details>
  <summary>Details</summary>
Motivation: Accurate modeling of effective elastic modulus and thickness is crucial for optimizing corrugated materials' mechanical properties in engineering.

Method: Combines Latin Hypercube Sampling (LHS) for initial input sampling with Gaussian Process Regression (GP) enhanced by EHVI for multi-objective optimization.

Result: Achieved MSE of 5.24 kPa² for elastic modulus and 1 mm² for thickness, demonstrating GP's accuracy and adaptability.

Conclusion: GP with EHVI is effective for structural optimization in corrugated materials, offering improved accuracy and adaptability.

Abstract: This work aims to model the hypersurface of the effective elastic modulus, \(
E_{z, \text{eff}} \), and thickness, \( th_{\text{eff}} \), in corrugated
boards. A Latin Hypercube Sampling (LHS) is followed by Gaussian Process
Regression (GP), enhanced by EHVI as a multi-objective acquisition function.
Accurate modeling of \( E_{z, \text{eff}} \) and \( th_{\text{eff}} \) is
critical for optimizing the mechanical properties of corrugated materials in
engineering applications. LHS provides an efficient and straightforward
approach for an initial sampling of the input space; GP is expected to be able
to adapt to the complexity of the response surfaces by incorporating both
prediction and uncertainty. Therefore, the next points being generated and
evaluated are based on the complexity of the hypersurfaces, and some points,
especially those with higher variance, are more exploited and carry more
importance. The performance of GP with EHVI is measured by Mean Squared Error
(MSE). Prediction of GP resulted in \( \text{MSE}(E_{z, \text{eff}}) = 5.24 \,
\text{kPa}^2 \) and \( \text{MSE}(th_{\text{eff}}) = 1 \, \text{mm}^2 \). GP
possesses then improved accuracy and adaptability for future applications in
structural optimization.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [50] [Optimal boron-doped graphene substrate for glucose Raman signal enhancement](https://arxiv.org/abs/2507.02642)
*Jan Komeda,Antonio Cammarata,Tomas Polcar*

Main category: cond-mat.mtrl-sci

TL;DR: Higher boron doping in graphene enhances glucose's Raman signal, with molecule orientation critical for SERS effectiveness.


<details>
  <summary>Details</summary>
Motivation: To explore how boron doping concentration and geometric distribution in graphene affect its performance as a SERS substrate for glucose detection.

Method: Quantum mechanical simulations analyzing interatomic force constants and phonon eigenvectors.

Result: Higher boron doping concentrations improve Raman signal enhancement; molecule orientation is key.

Conclusion: High-concentration B-graphene is promising for SERS glucose detection, and phonon-based analysis aids substrate material discovery.

Abstract: Surface Enhanced Raman Spectroscopy (SERS) is a highly sensitive and
selective technique that greatly enhances the signal of an analyte, compared
with its signal from classical Raman Spectroscopy, due to its interaction with
a substrates surface. It has been shown that low concentration boron-doped
graphene (B-graphene) enhances the Raman signal of simple organic molecules
like pyridine. Recent studies also suggest that B-graphene can remain
thermodynamically stable when doped with significantly higher concentrations of
boron than previously observed. In this framework, we use quantum mechanical
simulations to investigate the influence of dopant concentration and geometric
distribution on the effectiveness of B-doped graphene as a SERS substrate, with
glucose as analyte. By combining analysis of interatomic force constants and of
phonon eigenvectors composition, we conclude that higher doping concentrations
provide a larger enhancement to glucose's Raman signal, while the molecule
orientation relative to the surface plays a fundamental role in the Raman
response. We suggest that high concentration B-graphene presents itself as a
potential substrate for SERS based detection of glucose, while the used
phonon-based analysis can be promptly applied for the search of promising
candidates as substrate materials for enhanced Raman response.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [51] [Public perspectives on the design of fusion energy facilities](https://arxiv.org/abs/2507.02207)
*Nathan Kawamoto,Daniel Hoover,Jonathan Xie,Jacob Walters,Katie Snyder,Aditi Verma*

Main category: physics.soc-ph

TL;DR: A participatory design approach for fusion energy facilities engages communities early, revealing key values like integrity and respect, and criteria like economic benefits and safety.


<details>
  <summary>Details</summary>
Motivation: To achieve social license for fusion energy by involving communities in design, avoiding traditional 'decide-announce-defend' methods.

Method: Conducted a participatory design workshop with community members and engineering students, analyzing textual and visual data.

Result: Identified top values (integrity, respect) and criteria (economic benefits, safety), with positive participant sentiments and design themes like community legacy and transparency.

Conclusion: Early participatory design fosters public engagement, clarifies hopes/concerns, and aids context-specific fusion facility development.

Abstract: As fusion energy technologies approach demonstration and commercial
deployment, understanding public perspectives on future fusion facilities will
be critical for achieving social license, especially because fusion energy
facilities, unlike large fission reactors, may be sited in closer proximity to
people and communities, due to distinct regulatory frameworks. In a departure
from the 'decide-announce-defend' approach typically used to site energy
infrastructure, we develop a participatory design methodology for
collaboratively designing fusion energy facilities with prospective host
communities. We present here our findings from a participatory design workshop
that brought together 22 community participants and 34 engineering students.
Our analysis of the textual and visual data from this workshop shows a range of
design values and decision-making criteria with 'integrity' and 'respect'
ranking highest among values and 'economic benefits' and 'environmental
protection/safety' ranking highest among decision-making criteria. Salient
design themes that emerge across facility concepts include connecting the
history and legacy of the community to the design of the facility, care for
workers, transparency and access to the facility, and health and safety of the
host community. Participants reported predominantly positive sentiments,
expressing joy and surprise as the workshop progressed from learning about
fusion to designing the hypothetical facility. Our findings suggest that
carrying out participatory design in the early stages of technology development
can invite and make concrete public hopes and concerns, improve understanding
of, and curiosity about, an emerging technology, build toward social license,
and inform context-specific development of fusion energy facilities.

</details>
