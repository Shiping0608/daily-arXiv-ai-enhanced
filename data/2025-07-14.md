<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 5]
- [math.AP](#math.AP) [Total: 10]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [math.SP](#math.SP) [Total: 1]
- [math.FA](#math.FA) [Total: 1]
- [math.CA](#math.CA) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [physics.acc-ph](#physics.acc-ph) [Total: 1]
- [stat.AP](#stat.AP) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [gr-qc](#gr-qc) [Total: 2]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [math.DG](#math.DG) [Total: 1]
- [quant-ph](#quant-ph) [Total: 2]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A Stokes-Brinkman-type formulation for the eigenvalue problem in porous media](https://arxiv.org/abs/2507.08226)
*Felipe Lepe,Gonzalo Rivera,Jesus Vellojin*

Main category: math.NA

TL;DR: A finite element method for approximating natural frequencies in Stokes-Brinkman flow systems in 2D/3D, with convergence and error estimates validated numerically.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of modeling fluid flow in porous media using Stokes-Brinkman equations, ensuring accurate eigenvalue and eigenfunction approximations.

Method: Uses inf-sup stable finite elements, leverages Stokes regularity, and applies compact operators theory for convergence and error analysis.

Result: Proven convergence and a priori/a posteriori error estimates for eigenvalues and eigenfunctions, supported by numerical tests.

Conclusion: The method effectively approximates natural frequencies in porous media flows, validated by theoretical and numerical results.

Abstract: In this paper we introduce and analyze, for two and three dimensions, a
finite element method to approximate the natural frequencies of a flow system
governed by the Stokes-Brinkman equations. Here, the fluid presents the
capability of being within a porous media. Taking advantage of the Stokes
regularity results for the solution, and considering inf-sup stable families of
finite elements, we prove convergence together with a priori and a posteriori
error estimates for the eigenvalues and eigenfunctions with the aid of the
compact operators theory. We report a series of numerical tests in order to
confirm the developed theory.

</details>


### [2] [Computational algorithm for downward continuation of gravity anomalies](https://arxiv.org/abs/2507.08506)
*D. K. Ivanov,L. N. Temirbekova,P. N. Vabishchevich*

Main category: math.NA

TL;DR: The paper presents a method for downward continuation of potential fields using a simple layer representation and NNLS to enforce non-negativity, demonstrating effectiveness on models.


<details>
  <summary>Details</summary>
Motivation: Downward continuation is crucial in gravity exploration to identify anomaly sources, but it's inherently unstable. The work aims to stabilize this process.

Method: The method represents the continued field as a simple layer potential or its derivative, enforcing density sign constancy and using NNLS for non-negativity.

Result: The algorithm preserves anomaly signs and stabilizes the continuation process, as shown in model examples.

Conclusion: The proposed method effectively stabilizes downward continuation while preserving anomaly characteristics.

Abstract: The downward continuation of potential fields from the Earth's surface into
the subsurface is a critical task in gravity exploration, as it helps to
identify the sources of gravity anomalies. This problem is often addressed by
solving a first-kind integral equation using regularization techniques to
stabilize an inherently unstable process. A similar approach is used in our
work, where the continued field is represented as the potential of a simple
layer or its vertical derivative. The constancy of the density sign of this
equivalent simple layer preserves the sign of anomalies, provided that the
layer's surface encloses all anomalous sources. This constraint is a key
feature of our algorithm for the downward continuation of potential fields. To
enforce, for instance, non-negativity in the simple layer density, we employ
the NNLS (Non-Negative Least Squares) method. The efficiency of the proposed
method is demonstrated on model examples.

</details>


### [3] [Minimum-norm interpolation for unknown surface reconstruction](https://arxiv.org/abs/2507.08632)
*Alex Shiu Lun Chu,Leevan Ling,Ka Chun Cheung*

Main category: math.NA

TL;DR: The paper presents a kernel-based interpolation method using radial basis functions (RBF) for estimating geometric properties of point clouds, enhancing the trial space with 1D kernel basis functions for better surface reconstruction.


<details>
  <summary>Details</summary>
Motivation: To improve the estimation of geometric properties from raw point cloud data by leveraging implicit surface representations and overcoming limitations of traditional RBF methods.

Method: Reformulates the interpolation problem into a constrained optimization model, minimizing a user-defined norm while satisfying interpolation conditions, and introduces 1D kernel basis functions inspired by Kolmogorov-Arnold Networks (KANs).

Result: The proposed method significantly improves surface reconstruction, especially in estimating surface normals, outperforming traditional RBF approaches.

Conclusion: The framework enhances point cloud data processing and holds potential for advancing computational geometry, as demonstrated by practical examples.

Abstract: We study algorithms to estimate geometric properties of raw point cloud data
through implicit surface representations. Given that any level-set function
with a constant level set corresponding to the surface can be used for such
estimations, numerical methods need not specify a unique target function for
the domain-type interpolation problems. In this paper, we focus on kernel-based
interpolation by radial basis functions (RBF) and reformulate the uniquely
solvable interpolation problem into a constrained optimization model. This
model minimizes some user-defined norm while enforcing all interpolation
conditions. To enable nontrivial feasible solutions, we propose to enhance the
trial space with 1D kernel basis functions inspired by Kolmogorov-Arnold
Networks (KANs). Numerical experiments demonstrate that our proposed mixed
dimensional trial space significantly improves surface reconstruction from raw
point clouds. This is particularly evident in the precise estimation of surface
normals, outperforming traditional RBF trial spaces including the one for
Hermite interpolation. This framework not only enhances processing of raw point
cloud data but also shows potential for further contributions to computational
geometry. We demonstrate this with a point cloud processing example.

</details>


### [4] [Long-time relative error analysis for linear ODEs with perturbed initial value](https://arxiv.org/abs/2507.08752)
*Stefano Maset*

Main category: math.NA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We investigate the propagation of initial value perturbations along the
solution of a linear ODE \( y'(t) = Ay(t) \). This propagation is analized
using the relative error rather than the absolute error. Our focus is on the
long-term behavior of this relative error, which differs significantly from
that of the absolute error. Understanding this long-term behavior provides
insights into the growth of the relative error over all times, not just at
large times. Therefore, it represents a crucial and fundamental aspect of the
conditioning of linear ODEs, with applications in, for example, non-normal
dynamics. The author hopes that this paper will stimulate attention to the role
of relative error in dynamic contexts.

</details>


### [5] [Asymptotic condition numbers for linear ODEs](https://arxiv.org/abs/2507.08762)
*Stefano Maset*

Main category: math.NA

TL;DR: The paper studies the long-time conditioning of the matrix exponential's action on a vector in linear ODEs, focusing on relative errors and introducing three condition numbers for perturbation analysis.


<details>
  <summary>Details</summary>
Motivation: To understand how perturbations in initial values propagate in linear ODEs over time, using relative error measures instead of absolute ones.

Method: Introduces three condition numbers for perturbation analysis: specific initial value and direction, worst-case direction for a given initial value, and worst-case for both initial value and direction.

Result: Analyzes the long-time behavior of these condition numbers to understand perturbation propagation.

Conclusion: The study provides insights into the stability and sensitivity of solutions to linear ODEs under perturbations, emphasizing relative error measures.

Abstract: We are interested in the (relative) conditioning of the linear problem
$y_0\mapsto \mathrm{e}^{tA}y_0$, i.e. the conditioning of the action of the
matrix exponential $\mathrm{e}^{tA}$ on a vector with respect to perturbations
of this vector. The present paper is a qualitative study of the long-time
behavior of this conditioning. In other words, we are interested to study the
propagation to the solution $y(t)$ of perturbations of the initial value for a
linear ODE $y^\prime(t)=Ay(t)$, by measuring these perturbations with relative
errors instead of absolute errors. We introduce three condition numbers: the
first considers a specific initial value and a specific direction of
perturbation; the second considers a specific initial value and the worst case
by varying the direction of perturbation; and the third considers the worst
case by varying both the initial value and the direction of perturbation. The
long-time behaviors of these three condition numbers are studied.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [6] [Nonresonance for problems involving $(p,q)$-Laplacian equations with nonlinear perturbations](https://arxiv.org/abs/2507.08229)
*Emer Lopera,Nsoki Mavinga,Diana Sanchez*

Main category: math.AP

TL;DR: The paper studies solvability of $(p,q)$-Laplacian problems with nonlinear terms and non-homogeneous Neumann conditions, analyzing the spectrum and proving existence of weak solutions using variational methods.


<details>
  <summary>Details</summary>
Motivation: To understand the solvability of complex $(p,q)$-Laplacian problems with nonlinear reactions and non-homogeneous boundary conditions, which are relevant in PDE theory.

Method: Variational methods and critical point theory are used to analyze the spectrum and prove existence of weak solutions under specific asymptotic conditions.

Result: Existence of weak solutions is proven when nonlinearities stay below the first eigenvalue of the $q$-Laplacian or the first Steklov-Neumann eigenvalue-line.

Conclusion: The study provides theoretical insights and existence results for $(p,q)$-Laplacian problems, contributing to PDE analysis.

Abstract: We study the solvability of $(p,q)$-Laplacian problems with nonlinear
reaction terms and non-homogeneous Neumann boundary conditions. First, we
provide a complete description of the spectrum of the eigenvalue problem
involving the $(p,q)$-Laplacian with weights and a spectral parameter present
in both the differential equation and on the boundary. Then, using variational
methods and critical point theory, we prove the existence of weak solutions for
the nonlinear problem when the nonlinearities involved remain asymptotically,
in some sense, below the first eigenvalue of the $q$-Laplacian problem with
weights and a spectral parameter present in both the differential equation and
on the boundary. We also establish an existence result for the nonlinear
problem when the nonlinearities involved remain asymptotically below the first
Steklov-Neumann eigenvalue-line, which is a line connecting the first Steklov
and first Neumann eigenvalues for $q$-Laplacian problems with weights and a
spectral parameter present either in the differential equation or on the
boundary.

</details>


### [7] [Global in-time rough large data solution to complex-valued semilinear damped evolution equations](https://arxiv.org/abs/2507.08272)
*Wenhui Chen,Michael Reissig*

Main category: math.AP

TL;DR: The paper studies a semilinear Cauchy problem for damped evolution equations, proving global existence for rough initial data without smallness conditions.


<details>
  <summary>Details</summary>
Motivation: To address the global existence of solutions for complex-valued damped evolution equations with rough initial data in a specific functional space.

Method: Analyzes the problem using Fourier transforms and functional norms, focusing on initial data in the rough space $E^{\alpha}_s$.

Result: Demonstrates global existence without requiring smallness of initial data, under specific conditions on parameters and data support.

Conclusion: The findings provide a robust existence result for the given damped evolution equations with rough initial data.

Abstract: We study the semilinear Cauchy problem for complex-valued damped evolution
equations \begin{align*}
  \partial_t^2u+(-\Delta)^{\sigma}u+(-\Delta)^{\delta}\partial_tu=u^p,\ \
u(0,x)=u_0(x),\ \partial_tu(0,x)=u_1(x), \end{align*} with
$\delta\in[0,\sigma]$, $\sigma\in\mathbb{R}_+$ and
$p\in\mathbb{N}_+\backslash\{1\}$, where the initial data belong to the rough
space $E^{\alpha}_s$ endowed with the norm \begin{align*}
  \|f\|_{E^{\alpha}_s}=\big\|\langle\xi\rangle^s\,2^{\alpha|\xi|}\widehat{f}(\xi)\big\|_{L^2}\
\ \mbox{with}\ \ \alpha<0, \ s\in\mathbb{R}. \end{align*} Concerning
$(u_0,u_1)\in E^{\alpha}_{s+\bar{\kappa}}\times E^{\alpha}_s$ when
$s\geqslant\frac{n}{2}-\frac{2\kappa+\bar{\kappa}-2\delta}{p-1}-\bar{\kappa}$
with $\kappa=\min\{2\delta,\sigma\}$ and $\bar{\kappa}=\max\{2\delta,\sigma\}$
whose Fourier transforms are supported in a suitable subset of first octant, we
prove a global in-time existence result without requiring the smallness of
rough initial data.

</details>


### [8] [Global in-time existence of solutions for the complex-valued Jordan-Moore-Gibson-Thompson equations of Westervelt-type under different conditions on initial data](https://arxiv.org/abs/2507.08273)
*Wenhui Chen*

Main category: math.AP

TL;DR: The paper studies global in-time solutions for the complex-valued JMGT equations, proving existence results under two scenarios: with Fourier support restrictions and without them, using Sobolev spaces.


<details>
  <summary>Details</summary>
Motivation: To address the global existence of solutions for the JMGT equations without requiring small initial data, exploring both restricted and unrestricted Fourier support cases.

Method: Analyzes the JMGT equations with fractional Laplacian, using Fourier support restrictions and Sobolev spaces for initial data.

Result: Demonstrates global existence without small initial data under Fourier restrictions and proves existence for strongly coupled systems without restrictions.

Conclusion: The study provides two global existence results for JMGT equations, expanding understanding under different initial data conditions.

Abstract: We are interested in the global in-time existence of solutions for the
complex-valued Jordan-Moore-Gibson-Thompson (JMGT) equations of
Westervelt-type, namely, \begin{align*}
\tau\partial_t^3\psi+\partial_t^2\psi+\mathcal{A}\psi+(\delta+\tau)\mathcal{A}\partial_t\psi=(1+\tfrac{B}{2A})\partial_t[(\partial_t\psi)^2]
\end{align*} in the whole space $\mathbb{R}^n$, with
$\tau,\delta,\frac{B}{A}\in\mathbb{R}_+$ and the fractional Laplacian
$\mathcal{A}:=(-\Delta)^{\sigma}$ equipping $\sigma\in\mathbb{R}_+$. Our aims
are twofold. For one thing, by considering the rough initial data with their
Fourier support restrictions in a suitable subset of first octant, we
demonstrate a global in-time existence result without requiring the smallness
of initial data. For another, by removing these Fourier support restrictions,
we prove another global in-time existence result for the equivalent strongly
coupled JMGT systems, where the real and imaginary parts of initial data,
respectively, belong to regular Sobolev spaces with different additional
Lebesgue integrabilities.

</details>


### [9] [Global small data weak solutions of 2-D semilinear wave equations with scale-invariant damping, III](https://arxiv.org/abs/2507.08274)
*Qianqian Li,Huicheng Yin*

Main category: math.AP

TL;DR: The paper addresses the global existence of small solutions for a 2-D semilinear wave equation with scale-invariant damping, resolving conjectured thresholds for different ranges of the damping parameter μ.


<details>
  <summary>Details</summary>
Motivation: To solve the open question of global small data weak solutions for the given wave equation, particularly for μ ≥ 2 and μ = 1, which were previously unresolved.

Method: Uses the vector field method and detailed analysis of Bessel functions to prove global existence for p > 2 when μ ≥ 2.

Result: Global small solutions exist for p > 2 when μ ≥ 2, and forthcoming work confirms p > 1 + √2 for μ = 1, fully resolving the conjecture.

Conclusion: The paper successfully closes the gap in the conjecture, providing complete solutions for all ranges of μ.

Abstract: For the $2$-D semilinear wave equation with scale-invariant damping $\square
u+\frac{\mu}{t}\partial_tu=|u|^p$, where $t\geq 1$, $\mu>0$ and $p>1$, it is
conjectured that the global small data weak solution $u$ exists when
$p>p_{s}(2+\mu) =\frac{\mu+3+\sqrt{\mu^2+14\mu+17}}{2(\mu+1)}$ for $0<\mu\le 2$
and $p>p_f(2)=2$ for $\mu\geq 2$. In our previous papers, the global small
solution $u$ has been obtained for $p>p_{s}(2+\mu)$ and $0<\mu<2$ but
$\mu\not=1$. In the present paper, by the vector field method together with the
delicate analysis on the Bessel functions, we will show the global existence of
small solution $u$ for $p>2$ and $\mu\ge 2$. In forthcoming paper, for $\mu=1$
and $p>p_{s}(2+\mu)=p_{s}(3)=1+\sqrt 2$, the global solution $u$ is also
obtained. Therefore, this open question has been solved completely.

</details>


### [10] [Equivalent Characterizations and Applications of Fractional Sobolev Spaces with Partially Vanishing Traces on $(ε,δ,D)$-Domains Supporting $D$-Adapted Fractional Hardy Inequalities](https://arxiv.org/abs/2507.08295)
*Jun Cao,Dachun Yang,Qishun Zhang*

Main category: math.AP

TL;DR: The paper establishes equivalences between fractional Sobolev spaces on a domain under certain conditions, introduces weighted fractional Sobolev spaces, and applies these to characterize properties of an elliptic operator.


<details>
  <summary>Details</summary>
Motivation: To unify and generalize the understanding of fractional Sobolev spaces and their equivalences, and to apply these insights to elliptic operators with mixed boundary conditions.

Method: The authors define fractional Sobolev spaces via restriction, intrinsic norms, and completion, then prove their equivalence under a fractional Hardy inequality. They introduce weighted spaces and link them to interpolation theory.

Result: Equivalences of fractional Sobolev spaces are proven under a Hardy inequality, and new weighted spaces are shown to match interpolation spaces. Applications include characterizing elliptic operator domains and parabolic maximal regularity.

Conclusion: The work provides a framework for understanding fractional Sobolev spaces and their applications, particularly in the context of elliptic operators and boundary conditions.

Abstract: Let $\Omega\subset\mathbb{R}^n$ be an $(\epsilon,\delta,D)$-domain, with
$\epsilon\in(0,1]$, $\delta\in(0,\infty]$, and $D\subset \partial \Omega$ being
a closed part of $\partial \Omega$, which is a general open connected set when
$D=\partial \Omega$ and an $(\epsilon,\delta)$-domain when $D=\emptyset$. Let
$s\in(0,1)$ and $p\in[1,\infty)$. If ${W}^{s,p}(\Omega)$, ${\mathcal
W}^{s,p}(\Omega)$, and $\mathring{W}_D^{s,p}(\Omega)$ are the fractional
Sobolev spaces on $\Omega$ that are defined respectively via the restriction of
$W^{s,p}(\mathbb{R}^n)$ to $\Omega$, the intrinsic Gagliardo norm, and the
completion of all $C^\infty(\Omega)$ functions with compact support away from
$D$, in this article we prove their equivalences [that is,
${W}^{s,p}(\Omega)={\mathcal{W}}^{s,p}(\Omega) =\mathring{W}_D^{s,p}(\Omega)$]
if $\Omega$ supports a $D$-adapted fractional Hardy inequality and, moreover,
when $sp\ne 1$ such a fractional Hardy inequality is shown to be necessary to
guarantee these equivalences under some mild geometric conditions on $\Omega$.
We also introduce new weighted fractional Sobolev spaces
$\mathcal{W}^{s,p}_{d_D^s}(\Omega)$. Using the aforementioned equivalences, we
show that this new space $\mathcal{W}^{s,p}_{d_D^s}(\Omega)$ is exactly the
real interpolation space $(L^p(\Omega), \mathring{W}_D^{1,p}(\Omega))_{s,p}$
when $p\in (1,\infty)$. Applying this to the elliptic operator $\mathcal{L}_D$
in $\Omega$ with mixed boundary condition, we characterize both the domain of
its fractional power and the parabolic maximal regularity of its Cauchy initial
problem by means of $\mathcal{W}^{s,p}_{d_D^s}(\Omega)$.

</details>


### [11] [Global existence and boundedness in an attraction-repulsion chemotaxis system with nonlocal logistic source and sublinear productions](https://arxiv.org/abs/2507.08305)
*Gnanasekaran Shanmugasundaram,Nithyadevi Nagarajan*

Main category: math.AP

TL;DR: The paper studies a chemotaxis system with attraction-repulsion and nonlocal logistic source, proving global bounded solutions under specific conditions.


<details>
  <summary>Details</summary>
Motivation: To analyze the behavior of a chemotaxis system with nonlocal logistic terms and sublinear productions, ensuring global boundedness of solutions.

Method: Mathematical analysis of the PDE system, focusing on parameter conditions for global boundedness. Numerical examples are also provided.

Result: Existence of unique globally bounded classical solutions under certain parameter constraints.

Conclusion: The system admits globally bounded solutions, validated by analytical and numerical results.

Abstract: This paper deals with the following attraction-repulsion chemotaxis system
with nonlocal logistic source and sublinear productions \[ \left\{
\begin{array}{rrll} &&u_t = d_1 \Delta u-\chi \nabla\cdot(u^k \nabla v)+\xi
\nabla\cdot(u^k \nabla w)+ \mu u^m \left(1-\int_\Omega u(x,t){\rm
d}x\right),\qquad &x\in\Omega,\, t>0,\\ &&v_t = d_2 \Delta v-\alpha v+f(u),
&x\in\Omega,\, t>0,\\ &&w_t = d_3 \Delta w-\beta w+f(u), &x\in\Omega,\, t>0,\\
&&\frac{\partial u}{\partial\nu} = \frac{\partial v}{\partial\nu} =
\frac{\partial w}{\partial\nu} = 0, &x\in\partial\Omega,\, t>0,\\ &&u(x,0) =
u_0, \quad v(x,0)=v_0, \quad w(x,0)=w_0,&x\in\Omega, \end{array} \right. \] in
an open, bounded domain $\Omega \subset \mathbb{R}^n$, $n\geq 2$ with smooth
boundary $\partial\Omega$. Assume the parameters $d_1$, $d_2$, $d_3$, $\chi$,
$\xi$, $\alpha$, $\beta$ and $\mu$ are positive constants, initial data $(u_0,
v_0, w_0)$ are nonnegative and the function $f(u)\leq K u^l\in C^1([0,
\infty))$ for some $K, l>0$. Under appropriate conditions on the parameter $k$,
$l$ and $m$ we show that the above problem admits a unique globally bounded
classical solution. Further, to illustrate the analytical results, some of
numerical examples are provided.

</details>


### [12] [An improved version of a spectral inequality by Payne](https://arxiv.org/abs/2507.08631)
*Paolo Acampora,Emanuele Cristoforoni,Carlo Nitsch,Cristina Trombetti*

Main category: math.AP

TL;DR: The paper improves Payne's inequality, refining the spectral bound between the first eigenvalues of the Dirichlet Laplacian and the buckling problem.


<details>
  <summary>Details</summary>
Motivation: To establish a quantitative version of Payne's inequality, which was not sharp.

Method: The authors refine Payne's original estimate to improve the spectral bound.

Result: A sharper version of Payne's inequality is achieved, enabling further quantitative enhancements in spectral theory.

Conclusion: The refined inequality opens avenues for deeper investigation into classical spectral inequalities.

Abstract: A celebrated inequality by Payne relates the first eigenvalue of the
Dirichlet Laplacian to the first eigenvalue of the buckling problem. Motivated
by the goal of establishing a quantitative version of this inequality, we sho
that Payne's original estimate - which is not sharp - can in fact be improved.
Our result provides a refined spectral bound and opens the way to further
investigations into quantitative enhancements of classical inequalities in
spectral theory.

</details>


### [13] [The fuzzy Landau equation: global well-posedness and Fisher information](https://arxiv.org/abs/2507.08689)
*Maria Pia Gualdani,Nestor Guillen,Nataša Pavlović,Maja Tasković,Nicola Zamponi*

Main category: math.AP

TL;DR: Global existence and uniqueness of smooth solutions for a fuzzy inhomogeneous Landau equation with moderately soft potentials, showing enhanced regularity and structural properties.


<details>
  <summary>Details</summary>
Motivation: To explore the effects of spatial delocalization in the collision operator of the Landau equation, aiming to enhance regularity and prevent singularities.

Method: Study a fuzzy variant of the inhomogeneous Landau equation, analyzing the impact of spatial delocalization on regularity and structural properties.

Result: Global-in-time existence and uniqueness of smooth solutions for moderately soft potentials, with monotonic decay or uniform boundedness of Fisher information forms.

Conclusion: Spatial delocalization in the collision operator improves regularity and reveals structural insights, ensuring long-term smooth solutions.

Abstract: We study a fuzzy variant of the inhomogeneous Landau equation and establish
global-in-time existence and uniqueness of smooth solutions for moderately soft
potentials. The spatial delocalization introduced in the collision operator not
only enhances regularity and prevents singularity formation, but also reveals
additional structural properties of the model. In particular, we show that
several forms of the Fisher information decay monotonically or remain uniformly
bounded in time.

</details>


### [14] [A note on impossible scenario of Type II blowups of suitable weak solutions to the Navier-Stokes equations](https://arxiv.org/abs/2507.08733)
*Gregory Seregin*

Main category: math.AP

TL;DR: The paper uses Euler scaling to exclude Type II blowups in Navier-Stokes solutions, generalizing the Ladyzhenskaya-Prodi-Serrin condition.


<details>
  <summary>Details</summary>
Motivation: To address potential Type II blowups in Navier-Stokes solutions by leveraging Euler scaling and extending known conditions.

Method: Applies Euler scaling and introduces a generalized version of the Ladyzhenskaya-Prodi-Serrin condition.

Result: Excludes certain Type II blowup scenarios in Navier-Stokes solutions.

Conclusion: The approach successfully narrows down blowup possibilities, contributing to understanding Navier-Stokes behavior.

Abstract: In the note, the Euler scaling is used to exclude a certain scenario of
potential Type II blowups of solutions to the Navier-Stokes equations. An
additional assumption looks like a generalisation of the
Ladyzhenskaya-Prodi-Serrin condition.

</details>


### [15] [Varifold solutions to Volume-Preserving Mean Curvature Flow: existence and weak-strong uniqueness](https://arxiv.org/abs/2507.08783)
*Andrea Poiatti*

Main category: math.AP

TL;DR: A novel weak solution concept for two-phase volume-preserving mean curvature flow is introduced, ensuring global existence and weak-strong uniqueness. It extends prior work and links to nonlocal Allen-Cahn equations, with proofs for calibration and uniqueness.


<details>
  <summary>Details</summary>
Motivation: To address the lack of a weak solution framework for volume-preserving mean curvature flow that guarantees both global existence and weak-strong uniqueness.

Method: Evolving varifolds coupled with phase volumes via a transport equation, and introducing volume-preserving gradient-flow calibrations.

Result: Sharp interface limits of modified nonlocal Allen-Cahn equations align with the new varifold solutions. Regular strong solutions are calibrated, and classical solutions are unique in this class.

Conclusion: The proposed weak solution concept is robust, linking to existing theories and ensuring uniqueness and calibration for classical solutions.

Abstract: In this contribution we introduce a novel weak solution concept for two-phase
volume-preserving mean curvature flow, having both properties of unconditional
global-in-time existence and weak-strong uniqueness. These solutions extend the
ones proposed by Hensel-Laux [J. Differential Geom. 130, 209-268 (2025)] for
the standard mean curvature flow, and consist in evolving varifolds coupled
with the phase volumes by a transport equation. First, we show that, in the
same setting as in Takasao [Arch. Ration. Mech. Anal. 247, 52 (2023)], any
sharp interface limit of solutions to a slightly modified nonlocal Allen-Cahn
equation is a varifold solution according to our new definition. Secondly, we
crucially introduce a new notion of volume-preserving gradient-flow
calibrations, allowing the extended velocity vector field to point in the
normal direction on the interface. We show that any sufficiently regular strong
solution is calibrated in this sense. Finally, we prove that any classical
solution to volume-preserving mean curvature flow, which is then automatically
a calibrated flow, is unique in the class of our new varifold solutions.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [16] [Discontinuity-aware KAN-based physics-informed neural networks](https://arxiv.org/abs/2507.08338)
*Guoqiang Lei,D. Exposito,Xuerui Mao*

Main category: physics.comp-ph

TL;DR: DPINN improves PINNs for solving PDEs with sharp transitions by using adaptive Fourier-feature embedding, discontinuity-aware modeling, mesh transformation, and learnable viscosity.


<details>
  <summary>Details</summary>
Motivation: PINNs struggle with accuracy for PDEs involving sharp spatial or fast temporal changes due to spectral bias and instability.

Method: DPINN introduces adaptive Fourier-feature embedding, a discontinuity-aware network, mesh transformation, and learnable viscosity to address these issues.

Result: DPINN outperforms existing methods in accuracy for problems like the inviscid Burgers' equation and transonic/supersonic flows.

Conclusion: DPINN effectively enhances PINNs for handling discontinuities in PDEs, offering superior performance in challenging scenarios.

Abstract: Physics-informed neural networks (PINNs) have proved to be a promising method
for the rapid solving of partial differential equations (PDEs) in both forward
and inverse problems. However, due to the smoothness assumption of functions
approximated by general neural networks, PINNs are prone to spectral bias and
numerical instability and suffer from reduced accuracy when solving PDEs with
sharp spatial transitions or fast temporal evolution. To address this
limitation, a discontinuity-aware physics-informed neural network (DPINN)
method is proposed. It incorporates an adaptive Fourier-feature embedding layer
to mitigate spectral bias and capture sharp changes, a discontinuity-aware
Kolmogorov-Arnold network for the modeling of shockwave properties, mesh
transformation to accelerate loss function convergence for complex geometries,
and learnable local artificial viscosity to stabilize the algorithm near
discontinuities. In numerical experiments regarding the inviscid Burgers'
equation and transonic and supersonic airfoil flows, DPINN demonstrated
superior accuracy when calculating discontinuities compared to existing
methods.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [17] [Volume-Preserving Deformation of Honeycomb Wire Media Enables Broad Plasma Frequency Tunability](https://arxiv.org/abs/2507.08156)
*Denis Sakhno,Jim A. Enriquez,Pavel A. Belov*

Main category: physics.plasm-ph

TL;DR: Mechanical deformation of a honeycomb-structured wire medium achieves up to 78% tunability in plasma frequency, with experimental confirmation of 64%.


<details>
  <summary>Details</summary>
Motivation: To explore methods for tuning plasma frequency in wire media, which is crucial for applications like metamaterials and wave manipulation.

Method: Mechanically deform a lattice of parallel metallic wires arranged in a honeycomb structure.

Result: Numerical simulations predict 78% tunability; experiments confirm 64%.

Conclusion: Mechanical deformation is an effective method for tuning plasma frequency in wire media.

Abstract: We demonstrate tunability of the plasma frequency in a wire medium by
mechanically deforming a lattice of parallel metallic wires arranged at the
nodes of a honeycomb structure. Numerical simulations predict up to 78%
tunability and a proof-of-concept experiment confirms 64%.

</details>


### [18] [Vidyut3d: a GPU accelerated fluid solver for non-equilibrium plasmas on adaptive grids](https://arxiv.org/abs/2507.08200)
*Hariswaran Sitaraman,Nicholas Deak,Taaresh Taneja*

Main category: physics.plasm-ph

TL;DR: A non-equilibrium plasma fluid solver for CPU+GPU architectures is presented, verified, and tested for performance, showing significant speed-ups on GPUs.


<details>
  <summary>Details</summary>
Motivation: To develop a high-performance plasma fluid solver adaptable to modern CPU+GPU architectures for accurate and efficient simulations.

Method: The solver uses AMReX for adaptive Cartesian grids, solving coupled conservation equations with second-order accuracy (central diffusion) and fifth-order WENO advection. Verification includes manufactured solutions and comparisons with literature.

Result: Verified accuracy and demonstrated performance with 150-400X speed-up on GPUs for large-scale simulations (4M cells, 15 species).

Conclusion: The solver is efficient, portable, and scalable for plasma simulations on diverse architectures.

Abstract: We present the numerical methods, programming methodology, verification, and
performance assessment of a non-equilibrium plasma fluid solver that can
effectively utilize current and upcoming central processing and graphics
processing unit (CPU+GPU) architectures, in this work. Our plasma fluid model
solves the coupled conservation equations for species transport, electrostatic
Poisson and electron temperature on adaptive Cartesian grids. Our solver is
written using performance portable adaptive-grid/particle management library,
AMReX, and is portable over widely available vendor specific GPU architectures.
We present verification of our solver using method of manufactured solutions
that indicate formal second order accuracy with central diffusion and
fifth-order weighted-essentially-non-oscillatory (WENO) advection scheme. We
also verify our solver with published literature on capacitive discharges and
atmospheric pressure streamer propagation. We demonstrate the use of our solver
on two 3D simulation cases: an atmospheric streamer propagation in Ar-H2
mixtures and a low pressure twin electrode radio frequency reactor. Our
performance studies on three different CPU+GPU architectures indicate
approximately 150-400X speed-up using AMD and NVIDIA GPUs per time step
compared to a single CPU core for a 4 million cell simulation with 15 species.

</details>


### [19] [Edge Radial Electric Field in Positive and Negative Triangularity Plasmas in the TCV Tokamak](https://arxiv.org/abs/2507.08682)
*S. Rienäcker,P. Hennequin,L. Vermare,C. Honoré,R. Bouffet-Klein,S. Coda,B. Labit,B. Vincent,K. E. Thome,O. Krutkin,A. Balestri,Y. Nakeva,the TCV team*

Main category: physics.plasm-ph

TL;DR: Negative triangularity (NT) plasmas show stronger $E_r$ well and $E_r \times B$ shear compared to positive triangularity (PT) plasmas, linked to NT's performance gain in L-mode.


<details>
  <summary>Details</summary>
Motivation: To investigate the impact of triangularity on the $E_r$ well and $E_r \times B$ shear in plasmas, comparing NT and PT configurations.

Method: Doppler backscattering measurements of $v_\perp \approx E_r/B$ in Ohmic, NBI, and ECRH heated discharges.

Result: NT-shaped plasmas exhibit stronger $E_r$ well and $E_r \times B$ shear than PT plasmas.

Conclusion: The findings suggest a connection between the enhanced $E_r$ properties in NT plasmas and their improved performance in L-mode.

Abstract: We present the first edge $E_r$ measurements in negative triangularity (NT)
TCV plasmas. The Doppler backscattering measurements of $v_\perp \approx E_r/B$
reveal a significant impact of triangularity on the $E_r$ well: In Ohmic, NBI,
and ECRH heated discharges, the $E_r$ well and associated $E_r \times B$ shear
are stronger in NT-shaped plasmas compared to their positive triangularity (PT)
counterpart. This suggests a connection to the concomitant NT performance gain
relative to PT L-mode.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [20] [Entropy-conservative numerical fluxes for compressible Euler equations with thermally perfect gas models](https://arxiv.org/abs/2507.08115)
*Alessandro Aiello,Carlo De Michele,Gennaro Coppola*

Main category: physics.flu-dyn

TL;DR: A novel spatial discretization method for compressible Euler equations ensures entropy conservation for thermally perfect gases, improving accuracy and robustness.


<details>
  <summary>Details</summary>
Motivation: To extend entropy-conserving schemes to thermally perfect gases while preserving linear invariants and kinetic energy.

Method: Locally conservative formulation for spatial discretization, adaptable to multicomponent gases and asymptotically entropy-conservative cases.

Result: The method outperforms existing approaches in accuracy and robustness.

Conclusion: The proposed methodology is effective for realistic gas models and offers broader applicability.

Abstract: This study proposes a novel spatial discretization procedure for the
compressible Euler equations that guarantees entropy conservation at a discrete
level for thermally perfect gases. The procedure is based on a locally
conservative formulation, and extends the entropy-conserving schemes to the
more realistic case of thermally perfect gases, while still guaranteeing
preservation of both linear invariants and kinetic energy. The proposed
methodology, which can also be extended to multicomponent gases and to an
Asymptotically Entropy-Conservative formulation, shows advantages in terms of
accuracy and robustness when compared to existing similar approaches.

</details>


### [21] [Impacts of internal heating on temperature distribution in channels](https://arxiv.org/abs/2507.08515)
*Lubomír Bureš,Per Nilsson*

Main category: physics.flu-dyn

TL;DR: The paper investigates the effects of volumetric heat generation and heat removal in molten-salt reactors using DNS, LES, and SAS methods, comparing results and providing guidelines for modeling.


<details>
  <summary>Details</summary>
Motivation: To quantify the impact of internal heating and heat removal in molten-salt reactors, which is critical for reactor design and analysis.

Method: Uses Direct Numerical Simulation (DNS), Large Eddy Simulation (LES), and a semi-analytical solver (SAS) to study turbulent channel flow with internal heating, comparing results across Prandtl and Reynolds numbers.

Result: DNS and LES show excellent agreement, with SAS providing acceptable accuracy. Volumetric heating is secondary in turbulent regimes but significant at lower Reynolds or higher Prandtl numbers.

Conclusion: The study offers modeling guidelines for reactor analyses and identifies conditions where internal heating is critical, with future work focusing on variable properties and complex geometries.

Abstract: In molten-salt-fuelled reactor systems, the fluid may experience substantial
volumetric heat generation in addition to heat removal from surrounding
structures. To quantify these effects, we investigate developed channel flow
with internal heating using a systematic multi-scale approach comprising Direct
Numerical Simulation (DNS), Large Eddy Simulation (LES), and a semi-analytical
solver (SAS). First, DNS and LES are compared in a turbulent parallel-plate
configuration at different Prandtl and Reynolds numbers, demonstrating
excellent agreement in flow and thermal fields, with the SAS method showing
acceptable accuracy. Building on this benchmarking, the SAS tool is then
employed to explore a broad parameter space, offering insights into how
internal heat deposition modifies the temperature distribution across Reynolds
and Prandtl numbers. Comparisons are also drawn against the canonical
wall-heating scenario, revealing that volumetric heating often remains a
secondary effect in turbulent regimes but can become more pronounced at lower
Reynolds numbers, higher Prandtl numbers, or when nearly all heat is deposited
in the fluid. These findings establish guidelines for reduced-order modeling in
liquid-fuel reactor analyses and highlight conditions under which internal
heating warrants particular attention. The paper concludes by outlining ongoing
and future research directions, including refinements for variable fluid
properties and complex geometry extensions.

</details>


<div id='math.SP'></div>

# math.SP [[Back]](#toc)

### [22] [Approximation of magnetic Schrödinger operators with $δ$-interactions supported on networks](https://arxiv.org/abs/2507.08301)
*Markus Holzmann*

Main category: math.SP

TL;DR: The paper approximates a magnetic Schrödinger operator with a singular δ-potential using regular potentials in the norm resolvent sense, under minimal assumptions on the coefficients and geometry.


<details>
  <summary>Details</summary>
Motivation: To rigorously approximate singular δ-potentials in magnetic Schrödinger operators with regular potentials, ensuring mathematical tractability and applicability.

Method: Approximation in the norm resolvent sense for Σ as finite unions of C²-hypersurfaces, with minimal assumptions on A, Q, and α, allowing complex-valued functions.

Result: Successful approximation under broad conditions, including Σ as graphs or boundaries of piecewise C²-domains.

Conclusion: The method provides a robust framework for approximating singular potentials, with implications for spectral analysis.

Abstract: This paper deals with the approximation of a magnetic Schr\"odinger operator
with a singular $\delta$-potential that is formally given by $(i \nabla + A)^2
+ Q + \alpha \delta_\Sigma$ by Schr\"odinger operators with regular potentials
in the norm resolvent sense. This is done for $\Sigma$ being the finite union
of $C^2$-hypersurfaces, for coefficients $A$, $Q$, and $\alpha$ under minimal
assumptions such that the associated quadratic forms are closed and sectorial,
and $Q$ and $\alpha$ are allowed to be complex-valued functions. In particular,
$\Sigma$ can be a graph in $\mathbb{R}^2$ or the boundary of a piecewise
$C^2$-domain. Moreover, spectral implications of the mentioned convergence
result are discussed.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [23] [Energy inequalities for cutoff functions of $p$-energies on metric measures spaces](https://arxiv.org/abs/2507.08577)
*Meng Yang*

Main category: math.FA

TL;DR: The paper establishes conditions linking the Poincaré inequality and cutoff Sobolev inequality for p-energy on metric measure spaces, using methods from Trudinger-Wang and Holopainen. It advances the capacity conjecture and resolves a problem about p-energy measure on the Sierpiński carpet.


<details>
  <summary>Details</summary>
Motivation: To understand the interplay between Poincaré and cutoff Sobolev inequalities in metric measure spaces and address open problems in capacity theory and energy measures.

Method: Uses Trudinger-Wang's technique for Wolff potential estimates and Holopainen's method for elliptic Harnack inequality.

Result: Proves equivalent conditions for the inequalities, makes progress on the capacity conjecture, and shows the p-energy measure's singularity on the Sierpiński carpet.

Conclusion: The work provides insights into inequalities in metric spaces and resolves specific conjectures, contributing to analysis and geometric measure theory.

Abstract: For $p\in(1,+\infty)$, and for a $p$-energy on a metric measure space, we
establish equivalent conditions for the conjunction of the Poincar\'e
inequality and the cutoff Sobolev inequality. In particular, we employ a
technique of Trudinger and Wang [Amer. J. Math. 124 (2002), no. 2, 369--410] to
derive a Wolff potential estimate for superharmonic functions, and a method of
Holopainen [Contemp. Math. 338 (2003), 219--239] to prove the elliptic Harnack
inequality for harmonic functions. As applications, we make progress toward the
capacity conjecture of Grigor'yan, Hu, and Lau [Springer Proc. Math. Stat. 88
(2014), 147--207], and we prove that the $p$-energy measure is singular with
respect to the Hausdorff measure on the Sierpi\'nski carpet for all $p>1$,
resolving a problem posed by Murugan and Shimizu [Comm. Pure Appl. Math., to
appear].

</details>


<div id='math.CA'></div>

# math.CA [[Back]](#toc)

### [24] [Some More Sparse Bounds for Rough and Smooth Pseudodifferential Operators](https://arxiv.org/abs/2507.08409)
*Solange Mukeshimana,David Rule*

Main category: math.CA

TL;DR: The paper extends techniques for sparse bounds of pseudodifferential operators, avoiding geometric decay proofs and addressing sharp endpoint cases.


<details>
  <summary>Details</summary>
Motivation: To improve sparse bounds for pseudodifferential operators and explore sharp endpoint conditions.

Method: Uses $L^r$ to $L^s$ bounds and develops techniques to avoid geometric decay proofs.

Result: Pointwise sparse bounds for rough operators and verification of conditions at sharp endpoint $m$.

Conclusion: The method provides new insights and avoids complex proofs, with verified conditions for sparse bounds.

Abstract: D.~Beltran and L.~Cladek (arXiv:1711.02339) use $L^r$ to $L^s$ bounds to
prove sparse form bounds for pseudodifferential operators with H\"ormander
symbols in $S^m_{\rho,\delta}$ up to, but not including, the sharp end-point in
decay $m$. We further develop their technique, obtaining pointwise sparse
bounds for rough pseudodifferential operators that are merely bounded in their
spatial variables and an alternative proof of their results which avoids
proving geometrically decaying sparse bounds. We also provide sufficient
conditions for sparse form bounds to hold and verify those conditions in a
limited number of cases at the sharp endpoint value of $m$ for the composition
of a pseudodifferential operator with the sharp maximal function.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [25] [Plasma instability in the front of ejected energetic electrons and Type III solar radiobursts](https://arxiv.org/abs/2507.08437)
*Vladimir Krasnoselskikh,Immanuel Christopher Jebaraj,Tom Robert Franck Cooper,Andrii Voschepynets,Thierry Dudok de Wit,Marc Pulupa,Forrest Mozer,Oleksiy Agapitov,Michael Balikhin,Stuart D. Bale*

Main category: astro-ph.SR

TL;DR: The paper revises the traditional model of Type III radio bursts, proposing that electron beam truncation due to the 'time-of-flight' effect in inhomogeneous solar-wind plasma generates Langmuir waves via linear instability, matching observed burst profiles.


<details>
  <summary>Details</summary>
Motivation: To challenge the traditional belief that Type III radio bursts are generated solely by the two-stream instability and propose a revised mechanism involving electron beam truncation.

Method: Examines the 'time-of-flight' effect on electron beams in inhomogeneous solar-wind plasma, focusing on linear instability for Langmuir wave generation.

Result: The revised model's wave intensity growth and decay align with observed Type III radio burst profiles, supporting the new theory.

Conclusion: The study suggests that linear instability due to electron beam truncation better explains Type III radio bursts than the traditional two-stream instability model.

Abstract: Type III radio bursts are a signature of the flux of near-relativistic
electrons ejected during solar flares. These bursts are frequently observed by
spacecraft such as the Parker Solar Probe. It is traditionally believed that
these electron beams generate Langmuir waves through the two-stream
instability, which are then converted into electromagnetic waves. In this
study, we revise that model by examining how the electron distribution becomes
truncated due to the "time-of-flight" effect as the beam travels through a
randomly inhomogeneous, and gently varying solar-wind plasma. Rather than the
two-stream instability, this truncation destabilizes the distribution and leads
to the generation of Langmuir waves via a linear instability; we confine our
analysis to this linear regime and do not take into account the back reaction
of the generated Langmuir waves on the electron distribution, which is
nonlinear. The instability grows until slower electrons arrive and dampen the
waves. Our qualitative analysis shows that the resulting wave intensity growth
and decay closely match the intensity-time profile of observed Type III radio
bursts at the fundamental frequency, supporting this modified theory.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [26] [Quasi-Random Physics-informed Neural Networks](https://arxiv.org/abs/2507.08121)
*Tianchi Yu,Ivan Oseledets*

Main category: cs.LG

TL;DR: QRPINNs improve PINNs by using quasi-random sampling for better convergence and performance in solving PDEs, especially in high dimensions.


<details>
  <summary>Details</summary>
Motivation: The performance of physics-informed neural networks (PINNs) is sensitive to point sampling, and quasi Monte-Carlo methods show promise in high-dimensional problems.

Method: Proposes Quasi-Random Physics-Informed Neural Networks (QRPINNs), using low-discrepancy sequences for sampling instead of random points.

Result: QRPINNs outperform PINNs and adaptive sampling methods, with theoretical and empirical validation. Combining QRPINNs with adaptive sampling further enhances performance.

Conclusion: QRPINNs offer a superior alternative to PINNs for solving PDEs, particularly in high-dimensional settings, with potential for further improvement via adaptive sampling.

Abstract: Physics-informed neural networks have shown promise in solving partial
differential equations (PDEs) by integrating physical constraints into neural
network training, but their performance is sensitive to the sampling of points.
Based on the impressive performance of quasi Monte-Carlo methods in high
dimensional problems, this paper proposes Quasi-Random Physics-Informed Neural
Networks (QRPINNs), which use low-discrepancy sequences for sampling instead of
random points directly from the domain. Theoretically, QRPINNs have been proven
to have a better convergence rate than PINNs. Empirically, experiments
demonstrate that QRPINNs significantly outperform PINNs and some representative
adaptive sampling methods, especially in high-dimensional PDEs. Furthermore,
combining QRPINNs with adaptive sampling can further improve the performance.

</details>


<div id='physics.acc-ph'></div>

# physics.acc-ph [[Back]](#toc)

### [27] [Theoretical study of the ECRIPAC accelerator concept](https://arxiv.org/abs/2507.08374)
*Andrea Cernuschi,Thomas Thuillier,Laurent Garrigues*

Main category: physics.acc-ph

TL;DR: The paper introduces ECRIPAC, a plasma-based accelerator for adjustable ion beams, focusing on medical uses. It corrects prior literature, proposes a compact demonstrator, and details the physics and stability of the system.


<details>
  <summary>Details</summary>
Motivation: To advance plasma-based ion acceleration for medical applications by addressing gaps in literature and proposing a stable, compact design.

Method: Theoretical investigation and Monte Carlo simulations to study stability, with detailed mathematical derivations and extended parameter analysis.

Result: Validation of a compact demonstrator and identification of stable operating conditions for ion acceleration.

Conclusion: ECRIPAC is a viable concept for medical ion beam generation, with stability insights and a validated demonstrator design.

Abstract: The Electron Cyclotron Resonance Ion Plasma ACcelerator (ECRIPAC) is an
original concept for a plasma-based particle accelerator able to generate
pulsed ion beams with adjustable energy, targeting mostly medical applications.
In a complementary letter (Cernuschi et al., arXiv:2507.07827) we thoroughly
reviewed and corrected the current literature on the subject, including also an
original theoretical investigation on the influence of several physical
parameters on the accelerator stability. This study led to the proposal of a
compact demonstrator device, which has been validated through Monte Carlo
simulations. The present paper provides a detailed and more extended
explanation of the ECRIPAC working principle and physics, including
mathematical derivations for several physical formulas. Moreover, several other
parameters have been included in the accelerator stability study, providing an
overview of achievable external fields and plasma characteristics allowing a
stable ion acceleration.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [28] [Uncertainty quantification of a multi-component Hall thruster model at varying facility pressures](https://arxiv.org/abs/2507.08113)
*Thomas A. Marks,Joshua D. Eckels,Gabriel E. Mora,Alex A. Gorodetsky*

Main category: stat.AP

TL;DR: Bayesian inference calibrates a Hall thruster model, improving predictive accuracy and uncertainty quantification across varying pressures and facilities.


<details>
  <summary>Details</summary>
Motivation: To enhance predictive modeling of Hall thrusters by addressing uncertainty and calibration challenges across different vacuum test facilities.

Method: Uses Bayesian inference to calibrate a multi-component model (cathode, discharge, plume) for two thrusters (H9, SPT-100) at varying pressures.

Result: Model reduces predictive errors by >50%, achieves 10% accuracy on untrained data, and extrapolates on-orbit performance with 9% error.

Conclusion: The model shows promise for predictive Hall thruster modeling, with potential improvements for broader applicability.

Abstract: Bayesian inference is applied to calibrate and quantify prediction
uncertainty in a coupled multi-component Hall thruster model at varying
facility background pressures. The model, consisting of a cathode model,
discharge model, and plume model, is used to simulate two thrusters across a
range of background pressures in multiple vacuum test facilities. The model
outputs include thruster performance metrics, one-dimensional plasma
properties, and the angular distribution of the current density in the plume.
The simulated thrusters include a magnetically shielded thruster, the H9, and
an unshielded thruster, the SPT-100. After calibration, the model captures
several key performance trends with background pressure, including changes in
thrust and upstream shifts in the ion acceleration region. Furthermore, the
model exhibits predictive accuracy to within 10\% when evaluated on flow rates
and pressures not included in the training data, and the model can predict some
performance characteristics across test facilities to within the same range.
Evaluated on the same data as prior work [Eckels et al. 2024], the model
reduced predictive errors in thrust and discharge current by greater than 50%.
An extrapolation to on-orbit performance is performed with an error of 9\%,
capturing trends in discharge current but not thrust. Possible extensions and
improvements are discussed in the context of using data for predictive Hall
thruster modeling across vacuum facilities.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [29] [Extending Nonlocal Kinetic Energy Density Functionals to Isolated Systems via a Density-Functional-Dependent Kernel](https://arxiv.org/abs/2507.08442)
*Liang Sun,Mohan Chen*

Main category: cond-mat.mtrl-sci

TL;DR: The paper addresses instability in the Wang-Teter-like nonlocal KEDF for isolated systems by constructing a density-functional-dependent kernel, improving accuracy and preserving computational efficiency.


<details>
  <summary>Details</summary>
Motivation: The Wang-Teter-like KEDF shows instability in isolated systems, violating scaling laws and Pauli energy positivity, limiting its applicability.

Method: A density-functional-dependent kernel is rigorously constructed to resolve the instability while maintaining the framework's exactness.

Result: Benchmarking on 56 elements shows an order-of-magnitude accuracy improvement over WT KEDF, with retained efficiency and superior bulk metal performance.

Conclusion: The new KEDF resolves instability issues, enhances accuracy, and maintains computational efficiency, outperforming semilocal functionals in both isolated and bulk systems.

Abstract: The Wang-Teter-like nonlocal kinetic energy density functional (KEDF) in the
framework of orbital-free density functional theory, while successful in some
bulk systems, exhibits a critical Blanc-Cances instability [J. Chem. Phys. 122,
214106 (2005)] when applied to isolated systems, where the total energy becomes
unbounded from below. We trace this instability to the use of an ill-defined
average charge density, which causes the functional to simultaneously violate
the scaling law and the positivity of the Pauli energy. By rigorously
constructing a density-functional-dependent kernel, we resolve these
pathologies while preserving the formal exactness of the original framework. By
systematically benchmarking single-atom systems of 56 elements, we find the
resulting KEDF retains computational efficiency while achieving an
order-of-magnitude accuracy enhancement over the WT KEDF. In addition, the new
KEDF preserves WT's superior accuracy in bulk metals, outperforming the
semilocal functionals in both regimes.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [30] [Genericity of Polyak-Lojasiewicz Inequalities for Entropic Mean-Field Neural ODEs](https://arxiv.org/abs/2507.08486)
*Samuel Daudin,François Delarue*

Main category: math.OC

TL;DR: The paper analyzes idealized deep ResNets using an optimal control framework, focusing on stable optimizers and the Polyak--Lojasiewicz condition under entropic regularization.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of deep ResNets in the continuum limit and identify conditions for stable optimization.

Method: Model ResNets via an optimal control problem over continuity equations, with relaxed controls in probability measures and entropic regularization.

Result: For most initial data, a unique stable global minimizer exists, satisfying a local Polyak--Lojasiewicz inequality, ensuring exponential convergence near optimal parameters.

Conclusion: The Polyak--Lojasiewicz condition is generic in ResNets with continuum layers and entropic penalization, facilitating stable optimization.

Abstract: We address the behavior of idealized deep residual neural networks (ResNets),
modeled via an optimal control problem set over continuity (or adjoint
transport) equations. The continuity equations describe the statistical
evolution of the features in the asymptotic regime where the layers of the
network form a continuum. The velocity field is expressed through the network
activation function, which is itself viewed as a function of the statistical
distribution of the network parameters (weights and biases). From a
mathematical standpoint, the control is interpreted in a relaxed sense, taking
values in the space of probability measures over the set of parameters. We
investigate the optimal behavior of the network when the cost functional arises
from a regression problem and includes an additional entropic regularization
term on the distribution of the parameters. In this framework, we focus in
particular on the existence of stable optimizers --that is, optimizers at which
the Hessian of the cost is non-degenerate. We show that, for an open and dense
set of initial data, understood here as probability distributions over features
and associated labels, there exists a unique stable global minimizer of the
control problem. Moreover, we show that such minimizers satisfy a local
Polyak--Lojasiewicz inequality, which can lead to exponential convergence of
the corresponding gradient descent when the initialization lies sufficiently
close to the optimal parameters. This result thus demonstrates the genericity
(with respect to the distribution of features and labels) of the
Polyak--Lojasiewicz condition in ResNets with a continuum of layers and under
entropic penalization.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [31] [Critical Phenomena in Gravitational Collapse](https://arxiv.org/abs/2507.07636)
*Carsten Gundlach,David Hilditch,José M. Martín-García*

Main category: gr-qc

TL;DR: The paper discusses critical phenomena in general relativity, including universality, power-law scaling, and scale echoing, explained by attractor solutions. It highlights relevance to cosmic censorship, quantum gravity, and astrophysics, with updates on numerical simulations and mathematical results.


<details>
  <summary>Details</summary>
Motivation: To explore the structure and simplicity of the black hole threshold in general relativity, and its implications for cosmic censorship, quantum gravity, and astrophysics.

Method: Analysis of exact solutions acting as attractors within the black hole threshold, numerical simulations beyond spherical symmetry, and mathematical PDE blowup models.

Result: Critical phenomena provide a pathway from smooth initial data to extreme curvatures, with insights into singularity formation and naked singularities.

Conclusion: Critical phenomena are key to understanding general relativity dynamics, with recent advancements in simulations and mathematical models enhancing their study.

Abstract: As first discovered by Choptuik, the black hole threshold in the space of
initial data for general relativity shows both surprising structure and
surprising simplicity. Universality, power-law scaling of the black hole mass,
and scale echoing have given rise to the term ``critical phenomena''. They are
explained by the existence of exact solutions which are attractors within the
black hole threshold, that is, attractors of codimension one in phase space,
and which are typically self-similar. Critical phenomena give a natural route
from smooth initial data to arbitrarily large curvatures visible from infinity,
and are therefore likely to be relevant for cosmic censorship, quantum gravity,
astrophysics, and our general understanding of the dynamics of general
relativity. Major additions since the 2010 version of this review are numerical
simulations beyond spherical symmetry, in particular of vacuum critical
collapse, and new sections on mathematical results in PDE blowup (as a toy
model for singularity formation) and on naked singularity formation in GR.

</details>


### [32] [On Axially Symmetric Perturbations of Kerr Black Hole Spacetimes](https://arxiv.org/abs/2507.08326)
*Nishanth Gudapati*

Main category: gr-qc

TL;DR: A positive-definite and conserved Hamiltonian energy is constructed for axially symmetric linear perturbations of Kerr black hole exteriors, ensuring dynamical stability.


<details>
  <summary>Details</summary>
Motivation: The lack of a positive-definite and conserved energy in black hole stability problems is a significant challenge.

Method: Dimensional reduction to a 2+1 Einstein-wave map system and construction of a gauge-invariant energy functional.

Result: The constructed energy is conserved, implying dynamical linear stability of Kerr black hole exteriors.

Conclusion: The study provides a conserved energy functional, advancing the understanding of Kerr black hole stability.

Abstract: The lack of a positive-definite and conserved energy is a serious obstacle in
the black hole stability problem. In this work, we will show that there exists
a positive-definite and conserved Hamiltonian energy for axially symmetric
linear perturbations of the exterior of Kerr black hole spacetimes. In the
first part, based on the Hamiltonian dimensional reduction of 3+1 axially
symmetric, Ricci-flat Lorentzian spacetimes to a 2+1 Einstein-wave map system
with the negatively curved hyperbolic 2-plane target, we construct a
positive-definite, spacetime gauge-invariant energy functional for linear
axially symmetric perturbations in the exterior of Kerr black holes, in a
manner that is also gauge-independent on the target manifold. In the
construction of the positive-definite energy, various dynamical terms at the
boundary of the orbit space occur critically. In the second part, after setting
up the initial value problem in harmonic coordinates, we prove that the
positive energy for the axially symmetric linear perturbative theory of Kerr
black holes is strictly conserved in time, by establishing that all the
boundary terms dynamically vanish for all times. This result implies a form of
dynamical linear stability of the exterior of Kerr black hole spacetimes.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [33] [Nonconserved critical dynamics of the two-dimensional Ising model as a surface kinetic roughening process](https://arxiv.org/abs/2507.08447)
*Hector Vaquero del Pino,Rodolfo Cuerno*

Main category: cond-mat.stat-mech

TL;DR: The paper revisits 2D Ising model's critical dynamics, analyzing Glauber dynamics and TDGL equation. It explores scaling, exponents, and fluctuation statistics for ordered and disordered initial states, revealing distinct behaviors.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamic scaling and fluctuation statistics of the 2D Ising model under different initial conditions using modern tools from surface kinetic roughening.

Method: Numerical simulations of lattice (Glauber dynamics) and continuum (TDGL equation) formulations, analyzing scaling, exponents, and fluctuation statistics for ordered and disordered quenches.

Result: Ordered quenches follow FV scaling, while disordered quenches show anomalous roughening before equilibrium. Fluctuation statistics are time-independent when normalized. An integral GL model reveals FV or faceted roughening.

Conclusion: Initial conditions critically influence dynamic scaling and roughening behavior in the 2D Ising model, with nonlinear interactions stabilizing stochastic dynamics. The integral GL model further highlights emergent symmetries.

Abstract: We have revisited the non-conserved (or model A) critical dynamics of the
two-dimensional Ising model through numerical simulations of its lattice and
continuum formulations --Glauber dynamics and the timedependent Ginzburg-Landau
(TDGL) equation, respectively--, to analyze them with current tools from
surface kinetic roughening. Our study examines two critical quenches, one from
an ordered and a different one from a disordered initial state, for both of
which we assess the dynamic scaling ansatz, the critical exponent values, and
the fluctuation field statistics that occur. Notably, the dynamic scaling
ansatz followed by the system strongly depends on the initial condition: a
critical quench from the ordered phase follows Family-Vicsek (FV) scaling,
while a critical quench from the disordered phase shows an initial overgrowth
regime with intrinsic anomalous roughening, followed by relaxation to
equilibrium. This behavior is explained in terms of the dynamical instability
of the stochastic Ginzburg-Landau equation at the critical temperature, whereby
the linearly unstable term is eventually stabilized by nonlinear interactions.
For both quenches we have determined the occurrence of probability distribution
functions for the field fluctuations, which are time-independent along the
non-equilibrium dynamics when suitably normalized by the time-dependent
fluctuation amplitude. Additionally, we have developed a related interface
model for a field which scales as the space integral of the TDGL field
(integral GL model). Numerical simulations of this model reveal either FV or
faceted anomalous roughening, depending on the critical quenched performed, as
well as an emergent symmetry in the fluctuation statistics for a critical
quench from the ordered phase.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [34] [Universal energy limits of radiation belts in planetary and brown dwarf magnetospheric systems](https://arxiv.org/abs/2507.08146)
*Drew L. Turner,Savvas Raptis,Adnane Osmane,Arika Egan,George Clark,Tom Nordheim,Leonardo Regoli,Sasha Ukhorskiy*

Main category: astro-ph.HE

TL;DR: A model predicts the upper energy limit of radiation belts, depending on surface magnetic field strength, with a limit of 7 +/- 2 TeV, offering insights into cosmic rays and exoplanetary systems.


<details>
  <summary>Details</summary>
Motivation: Despite the ubiquity of radiation belts, no general theory predicts their uppermost energy limits.

Method: Developed a model based on fundamental loss processes to bound and explain maximum observed energies.

Result: The model yields a simple function for energy limits, predicting a 7 +/- 2 TeV asymptote, and identifies synchrotron-emitting exoplanets.

Conclusion: The model provides a universal energy limit for radiation belts, aiding in cosmic ray studies and exoplanet habitability assessments.

Abstract: Radiation belts are regions of magnetically trapped particle radiation found
around all of the sufficiently magnetized planets in the Solar System and
recently also observed around brown dwarfs, yet despite their ubiquity, there
is not yet a general theory or model to predict the uppermost energy limits
that any particular magnetospheric system's radiation belts can attain. By
considering only the most fundamental loss processes, a model and corresponding
theory are developed that successfully bound and explain the maximum observed
energies of all documented radiation belt systems. Interestingly, this approach
yields a relatively simple function for the uppermost energy limit that depends
on only the surface magnetic field strength of the system. The model predicts
an energy limit for all radiation belt systems that asymptotes at 7 +/- 2 TeV
(for protons and electrons), offering intriguing new insight on potential
sources of galactic cosmic rays. This model is also applied to an exoplanetary
system, demonstrating that the planet is likely a synchrotron emitter and
showcasing the model's use for identifying candidate targets for
synchrotron-emitting astrophysical systems and revealing details critical to
habitability at those remote worlds.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [35] [Rigidity of an overdetermined heat equation and minimal helicoids in space-forms](https://arxiv.org/abs/2507.08389)
*Andrea Bisterzo,Alessandro Savo*

Main category: math.DG

TL;DR: The paper studies domains in Riemannian manifolds where the boundary temperature remains constant over time in a heat diffusion problem, proving minimality of such boundaries and classifying them in 3D space-forms.


<details>
  <summary>Details</summary>
Motivation: To understand the geometry of domains with constant boundary temperature in heat diffusion, extending prior results from Euclidean space to other 3D space-forms.

Method: Analyzes the heat equation on Riemannian manifolds, proving minimality of boundaries with the 1/2-property and classifying such domains in 3D space-forms like S³ and H³.

Result: In S³, such domains are bounded by totally geodesic surfaces or the Clifford torus; in H³, by totally geodesic surfaces or minimal hyperbolic helicoids.

Conclusion: The work generalizes prior classifications and extends Nitsche's result on uniformly dense domains to 3D space-forms.

Abstract: Let $M$ be a Riemannian manifold and $\Omega$ a smooth domain of $M$. We
study the following heat diffusion problem: assume that the initial temperature
is equal to $1$, uniformly on $\Omega$, and is $0$ on its complement. Heat will
then flow away from $\Omega$ to its complement, and we are interested in the
temperature on the boundary of $\Omega$ at all positive times $t>0$. In
particular we ask: are there domains for which the temperature at the boundary
is a constant $c$, for all positive times $t$ and for all points of the
boundary? If they exist, what can we say about their geometry?
  This is a typical example of overdetermined heat equation. It is readily seen
that if $c$ exists it must be $\frac 12$, and domains with constant boundary
temperature will be said to have the $\frac 12$-property. Previous work by
\cite{MPS06} and \cite{CSU23} show that, on $\mathbb R^3$, the only such
domains (up to congruences) have boundary which is a plane or (a bit
surprisingly) the right helicoid.
  In this paper we first show that, in great generality, the boundary of a
$\frac 12$-domain must be minimal; we then extend (with a different proof) the
above classification from $\mathbb R^3$ to the other $3$-dimensional
space-forms. We prove that, in $\mathbb S^3$, $\frac 12$-domains are bounded by
a totally geodesic surface or the Clifford torus, and in the hyperbolic space
$\mathbb H^3$ are bounded by a totally geodesic surface or by an (embedded)
minimal hyperbolic helicoid. %(there is a one-parameter family of such
surfaces) As a by-product, we extend (with a different proof) a result by
Nitsche on uniformly dense domains from $\mathbb R^3$ to $3$-dimensional
space-forms.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [36] [Continuous-time parametrization of neural quantum states for quantum dynamics](https://arxiv.org/abs/2507.08418)
*Dingzu Wang,Wenxuan Zhang,Xiansong Xu,Dario Poletti*

Main category: quant-ph

TL;DR: The paper introduces smooth neural quantum states (s-NQS) for simulating quantum dynamics with differentiable, time-continuous parameterization, showing efficiency and accuracy in non-integrable spin chains.


<details>
  <summary>Details</summary>
Motivation: To improve the representation of quantum dynamics by ensuring time-continuous and differentiable neural network parameterization, addressing limitations of discrete optimization.

Method: Parameters are expressed as linear combinations of temporal basis functions with trainable coefficients, tested on a non-integrable spin chain using a restricted Boltzmann machine.

Result: Accurate time evolution achieved with fewer parameters, and the model generalizes to times outside the training set.

Conclusion: The s-NQS framework is efficient and effective for simulating quantum dynamics, offering advantages in parameterization and generalization.

Abstract: Neural quantum states are a promising framework for simulating many-body
quantum dynamics, as they can represent states with volume-law entanglement. As
time evolves, the neural network parameters are typically optimized at discrete
time steps to approximate the wave function at each point in time. Given the
differentiability of the wave function stemming from the Schr\"odinger
equation, here we impose a time-continuous and differentiable parameterization
of the neural network by expressing its parameters as linear combinations of
temporal basis functions with trainable, time-independent coefficients. We test
this ansatz, referred to as the smooth neural quantum state ($s$-NQS) with a
loss function defined over an extended time interval, under a sudden quench of
a non-integrable many-body quantum spin chain. We demonstrate accurate time
evolution using simply a restricted Boltzmann machine as the instantaneous
neural network architecture. Furthermore, we demonstrate that the
parameterization is efficient in the number of parameters and the smooth neural
quantum state allows us to initialize and evaluate the wave function at times
not included in the training set, both within and beyond the training interval.

</details>


### [37] [A novel quantum circuit for the quantum Fourier transform](https://arxiv.org/abs/2507.08699)
*Juan M. Romero,Emiliano Montoya-González,Guillermo Cruz,Roberto C. Romero*

Main category: quant-ph

TL;DR: The paper introduces a more efficient quantum circuit for the Quantum Fourier Transform (QFT) and an improved HHL algorithm.


<details>
  <summary>Details</summary>
Motivation: To enhance the efficiency of the QFT and its applications, such as the HHL algorithm, in quantum computing.

Method: Proposes an alternative method for factoring the QFT and designs a new quantum circuit for its implementation.

Result: The new QFT circuit is more efficient than the conventional one, and the adapted HHL algorithm shows improved performance.

Conclusion: The proposed methods offer significant efficiency gains for QFT and HHL, advancing quantum computing applications.

Abstract: The Quantum Fourier Transform (QFT) is a fundamental component of many
quantum computing algorithms. In this paper, we present an alternative method
for factoring this transformation. Inspired by this approach, we introduce a
new quantum circuit for implementing the QFT. We show that this circuit is more
efficient than the conventional design. Furthermore, using this circuit, we
develop an alternative version of the HHL algorithm, which also demonstrates
improved performance compared to the standard implementation.

</details>
