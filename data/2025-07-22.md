<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 29]
- [math.AP](#math.AP) [Total: 31]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 4]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [math-ph](#math-ph) [Total: 1]
- [cs.ET](#cs.ET) [Total: 1]
- [math.RA](#math.RA) [Total: 1]
- [math.CV](#math.CV) [Total: 2]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [math.DG](#math.DG) [Total: 3]
- [physics.optics](#physics.optics) [Total: 1]
- [physics.acc-ph](#physics.acc-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [math.PR](#math.PR) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [math.OC](#math.OC) [Total: 2]
- [hep-ph](#hep-ph) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [astro-ph.IM](#astro-ph.IM) [Total: 2]
- [cs.RO](#cs.RO) [Total: 1]
- [gr-qc](#gr-qc) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [An inverse moving point source problem in electromagnetics](https://arxiv.org/abs/2507.14440)
*Minghui Li,Guanghui Hu,Yue Zhao*

Main category: math.NA

TL;DR: The paper addresses an inverse problem to reconstruct a moving point source's orbit in electromagnetics using tangential magnetic field data from four non-coplanar points. A nonlinear ODE system is solved for distance functions, and Lipschitz stability is proven. Numerical results show linear error dependence on noise and wave speed's impact on accuracy.


<details>
  <summary>Details</summary>
Motivation: To solve the inverse problem of reconstructing a moving point source's orbit in electromagnetics using limited measurement data, which is crucial for applications like tracking or sensing.

Method: A nonlinear ODE system is solved to compute distance functions between observation points and the moving source, using tangential magnetic field data from four non-coplanar points.

Result: The method successfully reconstructs the orbit with Lipschitz stability. Numerical experiments confirm linear error dependence on noise and highlight wave speed's role in accuracy.

Conclusion: The proposed method is effective for reconstructing moving orbits with limited data, demonstrating stability and practical applicability in noisy environments.

Abstract: This paper is concerned with an inverse moving point source problem in
electromagnetics. The aim is to reconstruct the moving orbit from the
tangential components of magnetic fields taken at a finite number of
observation points. The distance function between each observation point and
the moving point source is computed by solving a nonlinear ordinary
differential equation with an initial value. This ODE system only involves the
measurement data from the tangential trace of the magnetic field at observation
points. As a consequence, the dynamical measurement data recorded at four
non-coplanar points are sufficient to reconstruct the orbit function. A
Lipschitz stability is established for the inverse problem, and numerical
experiments are reported to demonstrate the effectiveness of the proposed
method. Numerical examples have shown that the reconstructed error depends
linearly on the noise level and that the wave speed is a critical factor
affecting the relative error.

</details>


### [2] [Explicit Runge-Kutta Methods with MQ and IMQ-Radial Basis Functions](https://arxiv.org/abs/2507.14474)
*Shipra Mahata,Samala Rathan*

Main category: math.NA

TL;DR: The paper introduces Runge-Kutta methods enhanced with multiquadric and inverse multiquadric RBFs, improving time integration accuracy for ODEs without extra stages.


<details>
  <summary>Details</summary>
Motivation: To enhance the accuracy of time integration in ordinary differential equations using RBF-based corrections.

Method: Uses RBFs (MQ and IMQ) derived from Taylor series expansions, with optimal shape parameter selection, to improve Runge-Kutta methods.

Result: Achieves a one-order accuracy increase; validated by convergence, stability analyses, and MATLAB experiments.

Conclusion: The proposed method effectively improves accuracy in ODE time integration, supported by theory and experiments.

Abstract: This article presents a class of explicit Runge-Kutta methods with
multiquadric (MQ) and inverse multiquadric (IMQ) radial basis functions (RBFs)
to improve the accuracy of time integration for ordinary differential
equations. By introducing RBF-based corrections derived from Taylor series
expansions and optimally selecting the shape parameter, the method achieves a
one-order increase in accuracy without additional stages. Convergence and
stability analyses support the theoretical claims, and numerical experiments in
MATLAB confirm the predicted performance.

</details>


### [3] [Entropy Stable Nodal Discontinuous Galerkin Methods via Quadratic Knapsack Limiting](https://arxiv.org/abs/2507.14488)
*Brian Christner,Jesse Chan*

Main category: math.NA

TL;DR: The paper modifies a high-order entropy stable discontinuous Galerkin method by replacing a linear knapsack solver with a quadratic one, improving efficiency and time regularity.


<details>
  <summary>Details</summary>
Motivation: To enhance the efficiency and regularity of entropy-stable discontinuous Galerkin methods by optimizing limiting coefficients.

Method: Combines flux-corrected transport (FCT)-type limiting with a quadratic knapsack solver for optimal limiting coefficients.

Result: The quadratic knapsack approach is efficient, improves time regularity, and reduces adaptive timesteps in shock problems.

Conclusion: The modified method outperforms linear knapsack limiting in terms of efficiency and robustness for shock-type problems.

Abstract: Lin, Chan (High order entropy stable discontinuous Galerkin spectral element
methods through subcell limiting, 2024) enforces a cell entropy inequality for
nodal discontinuous Galerkin methods by combining flux corrected transport
(FCT)-type limiting and a knapsack solver, which determines optimal limiting
coefficients that result in a semi-discrete cell entropy inequality while
preserving nodal bounds. In this work, we provide a slight modification of this
approach, where we utilize a quadratic knapsack problem instead of a standard
linear knapsack problem. We prove that this quadratic knapsack problem can be
reduced to efficient scalar root-finding. Numerical results demonstrate that
the proposed quadratic knapsack limiting strategy is efficient and results in a
semi-discretization with improved regularity in time compared with linear
knapsack limiting, while resulting in fewer adaptive timesteps in shock-type
problems.

</details>


### [4] [Numerical Artifacts in Learning Dynamical Systems](https://arxiv.org/abs/2507.14491)
*Bing-Ze Lu,Richard Tsai*

Main category: math.NA

TL;DR: The paper highlights how numerical schemes in learning dynamical systems can lead to incorrect identification of system properties, such as mislabeling damped oscillatory systems as anti-damped.


<details>
  <summary>Details</summary>
Motivation: To investigate the impact of numerical integration schemes on the accuracy of learned dynamical systems, especially when fitting sampled data.

Method: Analyzes the learning process by comparing candidate dynamical systems integrated numerically against sampled data, revealing discrepancies.

Result: Demonstrates that numerical schemes can cause misidentification, e.g., damped systems appearing anti-damped with reversed oscillation.

Conclusion: Careful choice of numerical schemes is crucial to avoid misleading interpretations of dynamical systems from sampled data.

Abstract: In many applications, one needs to learn a dynamical system from its
solutions sampled at a finite number of time points. The learning problem is
often formulated
  as an optimization problem over a chosen function class. However, in the
optimization procedure, it is necessary to employ a numerical scheme to
integrate candidate dynamical systems and assess how their solutions fit the
data.
  This paper reveals potentially serious effects of a chosen numerical scheme
on the learning outcome. In particular, our analysis demonstrates that a damped
oscillatory system may be incorrectly identified as having "anti-damping" and
exhibiting a reversed oscillation direction, despite adequately fitting the
given data points.

</details>


### [5] [Mathematical modeling and simulation of two-phase magnetohydrodynamic flows at low magnetic Reynolds numbers](https://arxiv.org/abs/2507.14518)
*Jiancheng Wang,Maojun Li,Zeyu Xia,Liwei Xu*

Main category: math.NA

TL;DR: A novel phase-field model for simulating two-phase incompressible MHD problems, validated through theoretical and numerical analysis.


<details>
  <summary>Details</summary>
Motivation: To address the simulation of two-phase incompressible MHD problems, especially in low magnetic Reynolds number regimes, by developing a reliable phase-field approach.

Method: Formulates a sharp-interface system, then uses the phase-field approach and Onsager's variational principle to derive a thermodynamically consistent model. Couples the AGG model with quasi-static electromagnetic modeling.

Result: Theoretical analysis shows the sharp-interface system is recoverable as the interface thickness vanishes. Numerical experiments validate the framework's ability to capture complex MHD phenomena.

Conclusion: The phase-field approach is reliable for approximating two-phase MHD problems, as demonstrated by theoretical and numerical validation.

Abstract: We propose a novel mathematical framework for simulating the two-phase
incompressible magnetohydrodynamic (MHD) problems. Focusing on low magnetic
Reynolds number regimes, where induced magnetic fields are negligible compared
to applied fields, an intrinsic sharp-interface system is first formulated.
Subsequently, we utilize the phase-field approach to characterize the interface
and derive a thermodynamically consistent phase-field model through the
Onsager's variational principle. The resulting system couples the
Abels--Garcke--Gr\"un (AGG) model of two-phase flows with a quasi-static
formulation modeling the electromagnetic phenomena. Theoretically, the
sharp-interface limit is investigated via asymptotic arguments, deducing that
the sharp-interface system can be recovered in the limit of vanishing interface
thickness. Consequently, this justifies the reliability of the phase-field
approach as an approximated method. In addition, we present some
three-dimensional numerical experiments of magnetic damping effects on bubble
dynamics, where the observed results demonstrate the validity of the proposed
framework in capturing complex MHD phenomena.

</details>


### [6] [On the vector potential formulation with an energy-based hysteresis model and its numerical solution](https://arxiv.org/abs/2507.14521)
*Herbert Egger,Felix Engertsberger*

Main category: math.NA

TL;DR: The paper focuses on integrating an energy-based vector hysteresis model into magnetic field equations for accurate simulation of ferromagnetic devices, ensuring solution uniqueness and efficient numerical methods.


<details>
  <summary>Details</summary>
Motivation: Accurate simulation of electric devices with ferromagnetic materials requires proper handling of magnetic hysteresis, which this paper addresses by incorporating a specific hysteresis model.

Method: The paper uses a convex minimization problem to model magnetic fields, ensuring existence and uniqueness of solutions, and employs finite element discretization and iterative methods for numerical solutions.

Result: The approach is validated through numerical tests on a benchmark problem, demonstrating its efficiency and consistency with governing field equations.

Conclusion: The proposed method effectively integrates hysteresis modeling into magnetic field simulations, providing reliable and accurate results for ferromagnetic devices.

Abstract: The accurate modelling and simulation of electric devices involving
ferromagnetic materials requires the appropriate consideration of magnetic
hysteresis. We discuss the systematic incorporation of the energy-based vector
hysteresis model of Henrotte et al. into vector potential formulations for the
governing magnetic field equations. The field model describing a single step in
a load cycle is phrased as a convex minimization problem which allows us to
establish existence and uniqueness of solutions and to obtain accurate
approximations by finite element discretization. Consistency of the model with
the governing field equations is deduced from the first order optimality
conditions. In addition, two globally convergent iterative methods are
presented for the solution of the underlying minimization problems. The
efficiency of the approach is illustrated by numerical tests for a typical
benchmark problem.

</details>


### [7] [On the convergence analysis of MsFEM with oversampling: Interpolation error](https://arxiv.org/abs/2507.14548)
*Guanglian Li*

Main category: math.NA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we investigate the approximation properties of two types of
multiscale finite element methods with oversampling as proposed in [Hou \& Wu,
{\textit{J. Comput. Phys.}}, 1997] and [Efendiev, Hou \& Wu, \textit{SIAM J.
Numer. Anal.}, 2000] without scale separation. We develop a general
interpolation error analysis for elliptic problems with highly oscillatory
rough coefficients, under the assumption of the existence of a macroscopic
problem with suitable $L^2$-accuracy. The distinct features of the analysis, in
the setting of highly oscillatory periodic coefficients, include: (i) The
analysis is independent of the first-order corrector or the solutions to the
cell problems, and thus independent of their regularity properties; (ii) The
analysis only involves the homogenized solution and its minimal regularity. We
derive an interpolation error $\mathcal{O}\left(H+\frac{\epsilon}{H}\right)$
with $\epsilon$ and $H$ being the period size and the coarse mesh size,
respectively, when the oversampling domain includes one layer of elements from
the target coarse element.

</details>


### [8] [1/2 order convergence rate of Euler-type methods for time-changed stochastic differential equations with super-linearly growing drift and diffusion coefficients](https://arxiv.org/abs/2507.14562)
*Yuanling Niu,Shuai Wang,Ying Zhang*

Main category: math.NA

TL;DR: The paper analyzes two Euler-type methods for time-changed stochastic differential equations with super-linear coefficients, proving both achieve optimal strong convergence rates.


<details>
  <summary>Details</summary>
Motivation: To extend and adapt Euler methods for time-changed stochastic differential equations with super-linear growth in drift and diffusion coefficients.

Method: Adapts the backward Euler method and introduces the projected Euler method for the equations.

Result: Both methods achieve optimal strong convergence rate of order 1/2 in mean-square sense.

Conclusion: Numerical simulations validate the theoretical convergence rates of the proposed methods.

Abstract: This paper investigates the convergence rates of two Euler-type methods for a
class of time-changed stochastic differential equations with super-linearly
growing drift and diffusion coefficients. Building upon existing research, we
adapt the backward Euler method to time-changed stochastic differential
equations where both coefficients exhibit super-linear growth and introduce an
explicit counterpart, the projected Euler method. It is shown that both methods
achieve the optimal strong convergence rate of order 1/2 in the mean-square
sense for this class of equations. Numerical simulations confirm the
theoretical findings

</details>


### [9] [Spectral Analysis of Node- and Cell-Centered Higher-Order Compact Schemes for Fully Discrete One and Two-Dimensional Convection-Dispersion Equation](https://arxiv.org/abs/2507.14692)
*Lavanya V Salian,Vivek S Yadav,Rathan Samala,Rakesh Kumar*

Main category: math.NA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this study, we present a comprehensive global spectral analysis of the
convection dispersion equation, which is also referred to in specific contexts
as the Korteweg de Vries (KdV) equation, to investigate the behaviour of high
order numerical schemes across a wide range of nondimensional parameters. The
motivation for this analysis stems from the equation's importance in modeling
wave propagation and transport phenomena, where accurate resolution of
dispersive effects is critical, and traditional numerical schemes often suffer
from spurious artifacts. We analyze one sixth order and two eighth order
compact spatial discretization schemes, encompassing both node centered and
cell centered formulations, combined with a third order strong stability
preserving Runge Kutta (SSPRK3) time integrator. The analysis is performed in
terms of key nondimensional parameters such as the wavenumber, Courant
Friedrichs Lewy number $N_c$, and dispersion number $D_{\alpha}$ over the full
spectral plane for both one and two dimensional cases. Key numerical
indicators, including the amplification factor, normalized phase speed, and
normalized group velocity, are evaluated to characterize stability, dispersion
error, errors in energy transport, and directional anisotropy. Critical
dispersion thresholds and Courant numbers are identified, beyond which
numerical instability and nonphysical phenomena such as spurious q waves and
reversed phase or energy transport arise. Theoretical predictions are validated
through numerical experiments involving linear and nonlinear one and two
dimensional test problems, including cases with exact solutions and established
benchmark results. This comprehensive analysis uncovers subtle numerical errors
and offers practical guidance for selecting reliable discretization parameters,
ensuring accurate and stable simulations of convection dispersion systems.

</details>


### [10] [Thermodynamically Consistent Modeling and Stable ALE Approximations of Reactive Semi-Permeable Interfaces](https://arxiv.org/abs/2507.14774)
*Weidong Shi,Shixin Xu,Zhen Zhang,Quan Zhao*

Main category: math.NA

TL;DR: A thermodynamically consistent continuum framework is proposed to model reactive, semi-permeable interfaces, integrating fluid motion, interfacial dynamics, and solute exchange. A finite element scheme ensures efficient solving, validated by numerical experiments and biological examples.


<details>
  <summary>Details</summary>
Motivation: To address the complexity of modeling mechanochemical couplings in biological processes like drug delivery and signal transduction.

Method: Develops a continuum framework via energy variation, solved with a finite element scheme using ALE and BGN strategies for mesh regularity and conservation.

Result: Numerical experiments confirm convergence and conservation, with applications in cholesterol efflux and self-propelled droplet systems.

Conclusion: Provides a unified computational platform for studying coupled biochemical and mechanical interactions at interfaces, applicable to biological and industrial contexts.

Abstract: Reactive, semi-permeable interfaces play important roles in key biological
processes such as targeted drug delivery, lipid metabolism, and signal
transduction. These systems involve coupled surface reactions, transmembrane
transport, and interfacial deformation, often triggered by local biochemical
signals. The strong mechanochemical couplings complicate the modeling of such
interfacial dynamics. We propose a thermodynamically consistent continuum
framework that integrates bulk fluid motion, interfacial dynamics, surface
chemistry, and selective solute exchange, derived via an energy variation
approach to ensure mass conservation and energy dissipation. To efficiently
solve the resulting coupled system, we develop a finite element scheme within
an Arbitrary Lagrangian-Eulerian (ALE) framework, incorporating the
Barrett-Garcke-Nurnberg (BGN) strategy to maintain mesh regularity and preserve
conservation laws. Numerical experiments verify the convergence and
conservation properties of the scheme and demonstrate its ability in capturing
complex interfacial dynamics. Two biologically inspired examples showcase the
model's versatility: cholesterol efflux via the ABCG1 pathway, involving
multistage interfacial reactions and HDL uptake; and a self-propelled droplet
system with reaction-activated permeability, mimicking drug release in
pathological environments. This work provides a unified computational platform
for studying strongly coupled biochemical and mechanical interactions at
interfaces, offering new insights into reactive transport processes in both
biological and industrial contexts.

</details>


### [11] [An adaptive symplectic integrator for gravitational dynamics](https://arxiv.org/abs/2507.14881)
*Keqi Ye,Zizhe Cai,Mingji Wang,Kun Yang,Xiaodong Liu*

Main category: math.NA

TL;DR: SQQ-PTQ is an adaptive symplectic integrator improving precision, stability, and efficiency via Chebyshev interpolation, projection methods, and a quasi-Newton approach for Jacobian matrices.


<details>
  <summary>Details</summary>
Motivation: To enhance the fixed-step symplectic integrator SQQ by addressing the Runge phenomenon and reducing computational costs while maintaining symplectic properties.

Method: Uses Chebyshev interpolation for action approximation, a projection method for efficiency, and a quasi-Newton method for Jacobian matrices. Implements adaptive time steps via time transformation.

Result: Demonstrated effectiveness in numerical experiments, handling close-encounter problems and maintaining energy conservation in long-term integrations.

Conclusion: SQQ-PTQ is robust, efficient, and adaptable, confirming its advantages as a symplectic algorithm.

Abstract: This paper presents an adaptive symplectic integrator, SQQ-PTQ, developed on
the basis of the fixed-step symplectic integrator SQQ. To mitigate the Runge
phenomenon, SQQ-PTQ employs Chebyshev interpolation for approximating the
action, enhancing both the precision and stability of the interpolation. In
addition, to reduce the computational cost of evaluating interpolation
functions, SQQ-PTQ introduces a projection method that improves the efficiency
of these computations. A key feature of SQQ-PTQ is its use of the time
transformation to implement an adaptive time step. To address the challenge of
computing complicated Jacobian matrices attributed to the time transformation,
SQQ-PTQ adopts a quasi-Newton method based on Broyden's method. This strategy
accelerates the solution of nonlinear equations, thereby improving the overall
computational performance. The effectiveness and robustness of SQQ-PTQ are
demonstrated via three numerical experiments. In particular, SQQ-PTQ
demonstrates adaptability in handling close-encounter problems. Moreover,
during long-term integrations, SQQ-PTQ maintains the energy conservation,
further confirming its advantages as a symplectic algorithm.

</details>


### [12] [A second-order generalized BDF method for the two-dimensional (modified) Fisher-Kolmogorov-Petrovsky-Piskunov equation](https://arxiv.org/abs/2507.14939)
*Lei Ge,Yong-Liang Zhao*

Main category: math.NA

TL;DR: A second-order scheme using shifted BDF2 is proposed for the 2D Fisher-KPP equation, with stability proven for uniform steps. Both uniform and nonuniform schemes show robustness and accuracy.


<details>
  <summary>Details</summary>
Motivation: To improve numerical solutions for the Fisher-KPP equation, a widely used model in biology, chemistry, and physics.

Method: Employed a shifted BDF2 method for uniform and nonuniform time steps in 2D Fisher-KPP equation.

Result: Stability proven for uniform discretization; numerical tests confirm robustness and accuracy for both schemes.

Conclusion: The proposed schemes are effective for solving the Fisher-KPP equation, with potential applications in various fields.

Abstract: The Kolmogorov-Petrovsky-Piskunov (Fisher-KPP) equation is a classical
reaction-diffusion equation with broad applications such as biology, chemistry
and physics. In this paper, an alternative second-order scheme is proposed by
employing a shifted BDF2 method to approximate the two-dimensional (modified)
Fisher-KPP equation. We both consider an uniform and a nonuniform time steps of
such the scheme. The stability of the uniform discretization scheme is proved.
Numerical experiments demonstrate that our uniform and non-uniform schemes are
robust and accurate.

</details>


### [13] [Quadrature formulas from rational approximations](https://arxiv.org/abs/2507.14971)
*Andrew Horning,Lloyd N. Trefethen*

Main category: math.NA

TL;DR: Quadrature formulas can be derived from rational approximation of the Cauchy transform of a weight function, simplifying their derivation and providing mathematical insight.


<details>
  <summary>Details</summary>
Motivation: To simplify the derivation of quadrature formulas and deepen understanding of their mathematical foundations.

Method: Use rational approximation of the Cauchy transform of a weight function to derive quadrature formulas.

Result: Quadrature nodes correspond to near-optimal branch cuts of the Cauchy transform.

Conclusion: Rational approximation offers an efficient and insightful method for deriving quadrature formulas across applications.

Abstract: It is shown that quadrature formulas in many different applications can be
derived from rational approximation of the Cauchy transform of a weight
function. Since rational approximation is now a routine technology, this
provides an easy new method to derive all kinds of quadrature formulas as well
as fundamental insight into the mathematics of quadrature. Intervals or curves
of quadrature nodes correspond to near-optimal branch cuts of the Cauchy
transform.

</details>


### [14] [$\textit{A Priori}$ Error Analysis for the $p$-Stokes Equations with Slip Boundary Conditions: A Discrete Leray Projection Framework](https://arxiv.org/abs/2507.15016)
*Alex Kaltenbach,Jörn Wichmann*

Main category: math.NA

TL;DR: Error analysis for kinematic pressure in a finite-differences/-elements discretization of unsteady $p$-Stokes equations, with boundary conditions handled weakly or strongly.


<details>
  <summary>Details</summary>
Motivation: To analyze error decay rates for velocity and kinematic pressure in non-Newtonian fluid models, focusing on boundary conditions and projection stability.

Method: Uses a discrete Leray projection for Helmholtz-type decomposition and derives error rates, measuring pressure error in an ad hoc norm.

Result: Optimal error decay rates for velocity and kinematic pressure, robust under reduced regularity.

Conclusion: Boundary conditions and projection stability critically influence pressure approximation accuracy.

Abstract: We present an $\textit{a priori}$ error analysis for the kinematic pressure
in a fully-discrete finite-differences/-elements discretization of the unsteady
$p$-Stokes equations, modelling non-Newtonian fluids. This system is subject to
both impermeability and perfect Navier slip boundary conditions, which are
incorporated either weakly via Lagrange multipliers or strongly in the discrete
velocity space. A central aspect of the $\textit{a priori}$ error analysis is
the discrete Leray projection, constructed to quantitatively approximate its
continuous counterpart. The discrete Leray projection enables a Helmholtz-type
decomposition at the discrete level and plays a key role in deriving error
decay rates for the kinematic pressure. We derive (in some cases optimal) error
decay rates for both the velocity vector field and kinematic pressure, with the
error for the kinematic pressure measured in an $\textit{ad hoc}$ norm informed
by the projection framework. The $\textit{a priori}$ error analysis remains
robust even under reduced regularity of the velocity vector field and the
kinematic pressure, and illustrates how the interplay of boundary conditions
and projection stability governs the accuracy of pressure approximations.

</details>


### [15] [Analysis of fully discrete Crank-Nicolson finite element methods for a stochastic Keller-Segel chemotaxis system with gradient-type multiplicative noise](https://arxiv.org/abs/2507.15103)
*Liet Vo*

Main category: math.NA

TL;DR: The paper develops a numerical method for a stochastic Keller-Segel system, proving stability and strong convergence rates, with numerical validation.


<details>
  <summary>Details</summary>
Motivation: To model chemotactic behavior under random environmental fluctuations using a stochastic Keller-Segel system.

Method: A fully discrete scheme combining Crank-Nicolson time discretization with a splitting mixed finite element method in space.

Result: Proved stability and strong convergence rates of order O(k^(1/2) + k^(-1/2)h^2), with stochastic effects causing an inverse dependence on time step size.

Conclusion: The numerical scheme is effective and accurate, validated by experiments, with distinct convergence behavior due to stochastic forcing.

Abstract: We develop and analyze numerical methods for a stochastic Keller-Segel system
perturbed by Stratonovich noise, which models chemotactic behavior under
randomly fluctuating environmental conditions. The proposed fully discrete
scheme couples a Crank-Nicolson time discretization with a splitting mixed
finite element method in space. We rigorously prove the stability of the
numerical scheme and establish strong convergence rates of order $O(k^{1/2} +
k^{-1/2}h^2)$, where $k$ and $h$ denote the time and spatial step sizes,
respectively. Notably, the presence of stochastic forcing leads to an inverse
dependence on $k$ in the error estimates, distinguishing the convergence
behavior from that of the deterministic case. Numerical experiments are
presented to validate the theoretical results and demonstrate the effectiveness
and accuracy of the proposed methods.

</details>


### [16] [Extending Data to Improve Stability and Error Estimates Using Asymmetric Kansa-like Methods to Solve PDEs](https://arxiv.org/abs/2507.15137)
*Thomas Hangelbroek,Francis J. Narcowich,Joseph D. Ward*

Main category: math.NA

TL;DR: The paper presents a theoretical framework for solving elliptic PDEs on spheres and manifolds using a Kansa-like method, focusing on stability and error estimates.


<details>
  <summary>Details</summary>
Motivation: To address the numerical solution of elliptic PDEs on complex geometries like spheres and manifolds, improving accuracy and stability.

Method: Uses a Kansa-like method with a larger norming set Y for test points, forming a rectangular matrix. Stability is analyzed, and two approximation methods (discrete least squares and a thinning algorithm) are provided.

Result: High-accuracy error estimates for smooth solutions and comparable stability to the elliptic operator. The thinning algorithm reduces the test set size without requiring Y to be a norming set.

Conclusion: The framework successfully extends the Kansa method to manifolds, ensuring stability and high accuracy, with practical benefits from the thinning algorithm.

Abstract: In this paper, a theoretical framework is presented
  for the use of a Kansa-like method to numerically solve elliptic
  partial differential equations on spheres and other manifolds. The
  theory addresses both the stability of the method and provides error
  estimates for two different approximation methods. A Kansa-like
  matrix is obtained by replacing the test point set $X$, used in the
  traditional Kansa method, by a larger set $Y$, which is a norming
  set for the underlying trial space. This gives rise to a rectangular
  matrix. In addition, if a basis of Lagrange (or local Lagrange)
  functions is used for the trial space, then it is shown
  that the stability of the matrix is comparable to the stability of
  the elliptic operator acting on the trial space. Finally, two
  different types of error estimates are given. Discrete least squares
  estimates of very high accuracy are obtained for solutions that are
  sufficiently smooth. The second method, giving similar error
  estimates, uses a rank revealing factorization to create a
  ``thinning algorithm'' that reduces $\#Y$ to $\#X$. In practice,
  this algorithm doesn't need $Y$ to be a norming set.

</details>


### [17] [On Subsample Size of Quantile-Based Randomized Kaczmarz](https://arxiv.org/abs/2507.15185)
*Jian-Feng Cai,Junren Chen,Anna Ma,Tong Wu*

Main category: math.NA

TL;DR: The paper introduces a subsampling QRK method to solve sparsely corrupted linear systems efficiently, reducing the required subsample size from O(m) to O(log(T)/log(1/β)), while maintaining linear convergence.


<details>
  <summary>Details</summary>
Motivation: Existing QRK methods require computing quantiles from all m samples, negating computational advantages. This work aims to overcome this bottleneck by using smaller subsamples.

Method: Proposes a subsampling QRK that computes quantiles from D uniformly chosen samples per iteration, with D ≥ C log(T)/log(1/β).

Result: QRK with reduced subsample size linearly converges over T iterations with high probability, and the subsample size is shown to be tight.

Conclusion: The subsampling QRK method significantly reduces computational overhead while maintaining convergence guarantees, validated by numerical results.

Abstract: Quantile-based randomized Kaczmarz (QRK) was recently introduced to
efficiently solve sparsely corrupted linear systems $\mathbf{A}
\mathbf{x}^*+\mathbf{\epsilon} = \mathbf{b}$ [SIAM J. Matrix Anal. Appl.,
43(2), 605-637], where $\mathbf{A}\in \mathbb{R}^{m\times n}$ and
$\mathbf{\epsilon}$ is an arbitrary $(\beta m)$-sparse corruption. However, all
existing theoretical guarantees for QRK require quantiles to be computed using
all $m$ samples (or a subsample of the same order), thus negating the
computational advantage of Kaczmarz-type methods. This paper overcomes the
bottleneck. We analyze a subsampling QRK, which computes quantiles from $D$
uniformly chosen samples at each iteration. Under some standard scaling
assumptions on the coefficient matrix, we show that QRK with subsample size
$D\ge\frac{C\log (T)}{\log(1/\beta)}$ linearly converges over the first $T$
iterations with high probability, where $C$ is some absolute constant. This
subsample size is a substantial reduction from $O(m)$ in prior results. For
instance, it translates into $O(\log(n))$ even if an approximation error of
$\exp(-n^2)$ is desired. Intriguingly, our subsample size is also tight up to a
multiplicative constant: if $D\le \frac{c\log(T)}{\log(1/\beta)}$ for some
constant $c$, the error of the $T$-th iterate could be arbitrarily large with
high probability. Numerical results are provided to corroborate our theory.

</details>


### [18] [On the stability of the low-rank projector-splitting integrator for hyperbolic and parabolic equations](https://arxiv.org/abs/2507.15192)
*Shiheng Zhang,Jingwei Hu*

Main category: math.NA

TL;DR: The paper analyzes the stability of the projector-splitting integrator (PSI) for linear hyperbolic and parabolic equations, comparing discretize-then-project (DtP) and project-then-discretize (PtD) formulations.


<details>
  <summary>Details</summary>
Motivation: To understand the stability conditions of PSI when coupled with standard spatial discretizations for hyperbolic and parabolic equations.

Method: Von Neumann-type analysis is used to study stability under DtP and PtD formulations, with Lie-Trotter and Strang splitting for hyperbolic equations, and Crank-Nicolson or hybrid schemes for parabolic equations.

Result: For hyperbolic equations, DtP and PtD have the same stability conditions under Lie-Trotter splitting, while Strang splitting enlarges the stability region. For parabolic equations, unconditional stability is achievable with certain time-stepping schemes.

Conclusion: The analysis provides insights into PSI stability for simplified models, with implications for more complex systems like those in kinetic theory.

Abstract: We study the stability of a class of dynamical low-rank methods--the
projector-splitting integrator (PSI)--applied to linear hyperbolic and
parabolic equations. Using a von Neumann-type analysis, we investigate the
stability of such low-rank time integrator coupled with standard spatial
discretizations, including upwind and central finite difference schemes, under
two commonly used formulations: discretize-then-project (DtP) and
project-then-discretize (PtD). For hyperbolic equations, we show that the
stability conditions for DtP and PtD are the same under Lie-Trotter splitting,
and that the stability region can be significantly enlarged by using Strang
splitting. For parabolic equations, despite the presence of a negative S-step,
unconditional stability can still be achieved by employing Crank-Nicolson or a
hybrid forward-backward Euler scheme in time stepping. While our analysis
focuses on simplified model problems, it offers insight into the stability
behavior of PSI for more complex systems, such as those arising in kinetic
theory.

</details>


### [19] [Efficient evaluation of forward and inverse energy-based magnetic hysteresis operators](https://arxiv.org/abs/2507.15289)
*Herbert Egger,Felix Engertsberger,Andreas Schafelner*

Main category: math.NA

TL;DR: The paper proposes a regularization method to approximate non-smooth terms in an energy-based vector hysteresis model, enabling efficient implementation via Newton methods and deriving an inverse hysteresis operator.


<details>
  <summary>Details</summary>
Motivation: To address the computational challenge of solving non-smooth minimization problems in the energy-based vector hysteresis model for efficient implementation in magnetic field solvers.

Method: Approximates non-smooth terms via regularization, employs Newton methods for local material model evaluation, and derives a regularized inverse hysteresis operator.

Result: An efficient algorithm for solving Newton systems is proposed, allowing evaluation of the inverse hysteresis operator at the same cost as the forward model.

Conclusion: The regularization approach effectively controls approximation errors and enables efficient implementation, demonstrated through numerical benchmark tests.

Abstract: The energy-based vector hysteresis model of Francois-Lavet et al. establishes
an implicit relation between magnetic fields and fluxes via internal magnetic
polarizations which are determined by convex but non-smooth minimization
problems. The systematic solution of these problems for every material point is
a key ingredient for the efficient implementation of the model into standard
magnetic field solvers. We propose to approximate the non-smooth terms via
regularization which allows to employ standard Newton methods for the
evaluation of the local material models while being in control of the error in
this approximation. We further derive the inverse of the regularized hysteresis
operator which amounts to a regularized version of the inverse hysteresis
model. The magnetic polarizations in this model are again determined by local
minimization problems which here are coupled across the different pinning
forces. An efficient algorithm for solving the Newton systems is proposed which
allows evaluation of the inverse hysteresis operator at the same cost as the
forward model. Numerical tests on standard benchmark problems are presented for
illustration of our results.

</details>


### [20] [Convergence analysis of Anderson acceleration for nonlinear equations with Hölder continuous derivatives](https://arxiv.org/abs/2507.15322)
*Yonghui Ling,Zikang Xiong,Juan Liang*

Main category: math.NA

TL;DR: The paper analyzes the local convergence of Anderson acceleration for nonlinear systems, proving R-linear convergence under certain conditions and demonstrating its efficiency in practical applications.


<details>
  <summary>Details</summary>
Motivation: To understand and improve the convergence behavior of Anderson acceleration, a popular method for solving nonlinear systems, especially in challenging cases like nearly singular or large-scale problems.

Method: The study establishes local R-linear convergence results for Anderson acceleration with general depth $m$, assuming H"older continuous Jacobian and contractive fixed-point functions. It also refines results for depth $m = 1$.

Result: Anderson acceleration shows R-linear convergence under given assumptions and outperforms existing methods in reducing iterations and computation time, as demonstrated in solving a nonsymmetric Riccati equation.

Conclusion: Anderson acceleration is effective for nonlinear systems, offering significant computational advantages, particularly in difficult cases.

Abstract: This work investigates the local convergence behavior of Anderson
acceleration in solving nonlinear systems. We establish local R-linear
convergence results for Anderson acceleration with general depth $m$ under the
assumptions that the Jacobian of the nonlinear operator is H\"older continuous
and the corresponding fixed-point function is contractive. In the Lipschitz
continuous case, we obtain a sharper R-linear convergence factor. We also
derive a refined residual bound for the depth $m = 1$ under the same
assumptions used for the general depth results. Applications to a nonsymmetric
Riccati equation from transport theory demonstrate that Anderson acceleration
yields comparable results to several existing fixed-point methods for the
regular cases, and that it brings significant reductions in both the number of
iterations and computation time, even in challenging cases involving nearly
singular or large-scale problems.

</details>


### [21] [Exponential Runge-Kutta Galerkin finite element method for a reaction-diffusion system with nonsmooth initial data](https://arxiv.org/abs/2507.15345)
*Runjie Zhang,Jinwei Fang,Shuo Yang*

Main category: math.NA

TL;DR: Numerical analysis of the Field-Noyes reaction-diffusion model with nonsmooth initial data using Galerkin FEM and exponential Runge-Kutta, deriving sharp error estimates in L2 and H1 norms.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of nonsmooth initial data in the Field-Noyes model, where classical regularity assumptions fail, requiring specialized error analysis.

Method: Linear Galerkin finite element method for spatial discretization and second-order exponential Runge-Kutta for temporal integration, leveraging semigroup techniques and fractional Sobolev space theory.

Result: Sharp fully discrete error estimates in L2 and H1 norms, showing convergence order adapts to initial data smoothness.

Conclusion: The method outperforms traditional approaches by handling nonsmooth data effectively, supported by numerical examples.

Abstract: This study presents a numerical analysis of the Field-Noyes
reaction-diffusion model with nonsmooth initial data, employing a linear
Galerkin finite element method for spatial discretization and a second-order
exponential Runge-Kutta scheme for temporal integration. The initial data are
assumed to reside in the fractional Sobolev space H^gamma with 0 < gamma < 2,
where classical regularity conditions are violated, necessitating specialized
error analysis. By integrating semigroup techniques and fractional Sobolev
space theory, sharp fully discrete error estimates are derived in both L2 and
H1 norms. This demonstrates that the convergence order adapts to the smoothness
of initial data, a key advancement over traditional approaches that assume
higher regularity. Numerical examples are provided to support the theoretical
analysis.

</details>


### [22] [Superconvergence points of Hermite spectral interpolation](https://arxiv.org/abs/2507.15350)
*Haiyong Wang,Zhimin Zhang*

Main category: math.NA

TL;DR: The paper explores superconvergence properties of Hermite spectral interpolation and collocation methods for PDEs on unbounded domains, identifying points with faster convergence rates for derivatives and validating findings numerically.


<details>
  <summary>Details</summary>
Motivation: Hermite spectral methods are crucial for PDE simulations on unbounded domains, but understanding superconvergence properties can enhance their efficiency and accuracy.

Method: The study analyzes Hermite spectral interpolation and collocation methods, identifying superconvergence points for derivatives and function values.

Result: Superconvergence points for first- and second-order derivatives and function values are identified, with numerical examples confirming the analysis.

Conclusion: The findings improve the understanding and application of Hermite spectral methods, particularly for solving PDEs on unbounded domains.

Abstract: Hermite spectral method plays an important role in the numerical simulation
of various partial differential equations (PDEs) on unbounded domains. In this
work, we study the superconvergence properties of Hermite spectral
interpolation, i.e., interpolation at the zeros of Hermite polynomials in the
space spanned by Hermite functions. We identify the points at which the
convergence rates of the first- and second-order derivatives of the interpolant
converge faster. We further extend the analysis to the Hermite spectral
collocation method in solving differential equations and identify the
superconvergence points both for function and derivative values. Numerical
examples are provided to confirm the analysis of superconvergence points.

</details>


### [23] [PDEformer-2: A Versatile Foundation Model for Two-Dimensional Partial Differential Equations](https://arxiv.org/abs/2507.15409)
*Zhanhong Ye,Zining Liu,Bingyang Wu,Hongjie Jiang,Leheng Chen,Minyan Zhang,Xiang Huang,Qinghe Meng. Jingyuan Zou,Hongsheng Liu,Bin Dong*

Main category: math.NA

TL;DR: PDEformer-2 is a versatile foundation model for 2D PDEs, improving upon PDEformer-1 by handling diverse PDE forms, domains, and conditions via a computational graph input. It offers fast, accurate, and differentiable solutions, excelling in zero-shot predictions and adaptation to new PDEs with limited data.


<details>
  <summary>Details</summary>
Motivation: Traditional PDE solvers and specialized neural operators lack versatility and efficiency, prompting the need for a foundation model capable of handling diverse PDEs with high accuracy and speed.

Method: PDEformer-2 uses computational graph representation to encode PDEs, enabling mesh-free solutions at arbitrary coordinates. It is pretrained on a large, diverse dataset (40TB) to handle varied PDE forms, domains, and conditions.

Result: The model achieves accurate zero-shot predictions for familiar PDEs and outperforms specialized models in learning new PDEs with limited data. It also performs well in inverse problems, recovering PDE coefficients.

Conclusion: PDEformer-2 is a powerful, adaptable foundation model for 2D PDEs, offering fast, accurate, and differentiable solutions, with potential applications in diverse scientific and engineering problems.

Abstract: Partial differential equations (PDEs) play a central role in describing many
physical phenomena. Various scientific and engineering applications demand a
versatile and differentiable PDE solver that can quickly generate solutions
with adequate accuracy, and limitations of the traditional solvers and
specialized neural operators motivate the development of foundation models for
solving PDEs. This paper introduces PDEformer-2, a versatile foundation model
for two-dimensional PDEs. Based on our previous one-dimensional PDEformer-1
model, PDEformer-2 receives the PDE form as network input via computational
graph representation, which has the flexibility to encode most common PDEs. The
mesh-free predicted solutions can be directly queried at arbitrary
spatio-temporal coordinates. A large (40TB) diverse dataset is employed to
pretrain the current model, making it capable of simultaneously addressing PDEs
with different symbolic forms, domain shapes, boundary conditions, number of
variables, and time-dependency. Accurate zero-shot prediction is allowed for
PDEs that resemble the pretraining ones. When adapted to new unseen PDEs,
PDEformer-2 demonstrates faster learning than many specialized models, and has
smaller errors given limited (less than 100) samples. Additionally, PDEformer-2
can be employed in the inverse problems thanks to its fast and differentiable
nature and produces reasonable results in our experiments to recover
coefficient scalars and fields of a PDE.

</details>


### [24] [Neural Preconditioning via Krylov Subspace Geometry](https://arxiv.org/abs/2507.15452)
*Nunzio Dimola,Alessandro Coclite,Paolo Zunino*

Main category: math.NA

TL;DR: A geometry-aware training strategy for neural preconditioners improves convergence in mixed-dimensional PDE systems by combining static pre-training and dynamic fine-tuning with a novel loss functional.


<details>
  <summary>Details</summary>
Motivation: Mixed-dimensional PDE systems are ill-conditioned due to embedded lower-dimensional structures, requiring efficient preconditioners for Krylov subspace methods.

Method: A two-stage training framework: static pre-training (residual minimization) followed by dynamic fine-tuning using a novel loss functional based on principal angles between residuals and Krylov subspaces. Differentiable Flexible GMRES enables backpropagation.

Result: The neural preconditioner improves early-stage convergence, reduces iteration counts, and enhances robustness and generalization in 3D-1D mixed-dimensional problems.

Conclusion: The solver-aligned approach significantly boosts convergence rate and robustness, demonstrating the effectiveness of integrating solver dynamics into training.

Abstract: We propose a geometry-aware strategy for training neural preconditioners
tailored to parametrized linear systems arising from the discretization of
mixed-dimensional partial differential equations (PDEs). These systems are
typically ill-conditioned because of the presence of embedded lower-dimensional
structures and are solved using Krylov subspace methods. Our approach yields an
approximation of the inverse operator employing a learning algorithm consisting
of a two-stage training framework: an initial static pre-training phase, based
on residual minimization, followed by a dynamic fine-tuning phase that
incorporates solver convergence dynamics into training via a novel loss
functional. This dynamic loss is defined by the principal angles between the
residuals and the Krylov subspaces. It is evaluated using a differentiable
implementation of the Flexible GMRES algorithm, which enables backpropagation
through both the Arnoldi process and Givens rotations. The resulting neural
preconditioner is explicitly optimized to improve early-stage convergence and
reduce iteration counts in a family of 3D-1D mixed-dimensional problems with
geometric variability of the 1D domain. Numerical experiments show that our
solver-aligned approach significantly improves convergence rate, robustness,
and generalization.

</details>


### [25] [Solving nonconvex Hamilton--Jacobi--Isaacs equations with PINN-based policy iteration](https://arxiv.org/abs/2507.15455)
*Hee Jun Yang,Min Jung Kim,Yeoneung Kim*

Main category: math.NA

TL;DR: A mesh-free policy iteration framework combining dynamic programming and PINNs solves high-dimensional HJI equations, proving convergence and demonstrating accuracy in numerical experiments.


<details>
  <summary>Details</summary>
Motivation: Address the challenge of solving high-dimensional, nonconvex HJI equations in stochastic differential games and robust control.

Method: Alternates between solving linear PDEs under fixed policies and updating controls via minimax optimization using automatic differentiation.

Result: Converges to viscosity solutions, outperforms benchmarks in accuracy and scalability, especially in high-dimensional scenarios.

Conclusion: The framework is practical and theoretically grounded, with applications in robotics, finance, and multi-agent reinforcement learning.

Abstract: We propose a mesh-free policy iteration framework that combines classical
dynamic programming with physics-informed neural networks (PINNs) to solve
high-dimensional, nonconvex Hamilton--Jacobi--Isaacs (HJI) equations arising in
stochastic differential games and robust control. The method alternates between
solving linear second-order PDEs under fixed feedback policies and updating the
controls via pointwise minimax optimization using automatic differentiation.
Under standard Lipschitz and uniform ellipticity assumptions, we prove that the
value function iterates converge locally uniformly to the unique viscosity
solution of the HJI equation. The analysis establishes equi-Lipschitz
regularity of the iterates, enabling provable stability and convergence without
requiring convexity of the Hamiltonian. Numerical experiments demonstrate the
accuracy and scalability of the method. In a two-dimensional stochastic
path-planning game with a moving obstacle, our method matches finite-difference
benchmarks with relative $L^2$-errors below %10^{-2}%. In five- and
ten-dimensional publisher-subscriber differential games with anisotropic noise,
the proposed approach consistently outperforms direct PINN solvers, yielding
smoother value functions and lower residuals. Our results suggest that
integrating PINNs with policy iteration is a practical and theoretically
grounded method for solving high-dimensional, nonconvex HJI equations, with
potential applications in robotics, finance, and multi-agent reinforcement
learning.

</details>


### [26] [tiDAS: a time invariant approximation of the Delay and Sum algorithm for biomedical ultrasound PSF reconstructions](https://arxiv.org/abs/2507.15464)
*Chiara Razzetta,Sara Garbarino,Michele Piana,Marco Crocco,Federico Benvenuto*

Main category: math.NA

TL;DR: The paper introduces tiDAS, a time-invariant approximation of the Delay and Sum (DAS) algorithm, to accelerate ultrasound image reconstruction without losing quality.


<details>
  <summary>Details</summary>
Motivation: The computational cost of DAS limits real-time ultrasound imaging, prompting the need for a faster alternative.

Method: tiDAS uses a one-dimensional, row-wise convolutional formulation to reduce complexity while maintaining image quality.

Result: Synthetic experiments show tiDAS balances speed and accuracy, enhancing real-time imaging efficiency.

Conclusion: tiDAS is a promising solution for faster, efficient ultrasound image reconstruction.

Abstract: Ultrasound imaging is a real-time diagnostic modality that reconstructs
acoustic signals into visual representations of internal body structures. A key
component in this process is beamforming, with the Delay and Sum (DAS)
algorithm being a standard due to its balance between simplicity and
effectiveness. However, the computational cost of DAS can be a limiting factor,
especially in real-time scenarios where fast frame reconstruction is essential.
In this work, we introduce a time-invariant approximation of the DAS algorithm
(tiDAS), designed to accelerate the reconstruction process without compromising
image quality. By adopting a one-dimensional, row-wise convolutional
formulation, tiDAS significantly reduces computational complexity while
preserving the core properties of the original model. This approach not only
enables faster image reconstruction but also provides a structured foundation
for the application of deconvolution methods aimed at enhancing resolution.
Synthetic experiments demonstrate that tiDAS achieves a favorable trade-off
between speed and accuracy, making it a promising tool for improving the
efficiency of real-time ultrasound imaging.

</details>


### [27] [Mathematical modeling and sensitivity analysis of hypoxia-activated drugs](https://arxiv.org/abs/2507.15642)
*Alessandro Coclite,Riccardo Montanelli Eccher,Luca Possenti,Piermario Vitullo,Paolo Zunino*

Main category: math.NA

TL;DR: A multiscale model simulates hypoxia-activated prodrug behavior in tumors, integrating transport, metabolism, and cellular response for optimized therapy design.


<details>
  <summary>Details</summary>
Motivation: Targeting oxygen-deficient tumor regions resistant to conventional therapies requires understanding the complex interplay of oxygen, drug activation, and cell survival.

Method: Developed a multiscale, mixed-dimensional model coupling drug/oxygen transport, pharmacokinetics, and pharmacodynamics, with a reduced 0D model for computational efficiency.

Result: Global sensitivity analysis identified key parameters for drug activation and therapeutic outcomes, enabling efficient simulation.

Conclusion: The model supports optimized hypoxia-targeted therapy design by efficiently simulating tumor response to hypoxia-activated prodrugs.

Abstract: Hypoxia-activated prodrugs offer a promising strategy for targeting
oxygen-deficient regions in solid tumors, which are often resistant to
conventional therapies. However, modeling their behavior is challenging because
of the complex interplay between oxygen availability, drug activation, and cell
survival. In this work, we develop a multiscale and mixed-dimensional model
that couples spatially resolved drug and oxygen transport with pharmacokinetics
and pharmacodynamics to simulate the cellular response. The model integrates
blood flow, oxygen diffusion and consumption, drug delivery, and metabolism. To
reduce computational cost, we mitigate the global nonlinearity through a
one-way coupling of the multiscale and mixed/dimensional models with a reduced
0D model for the drug metabolism. The global sensitivity analysis is then used
to identify key parameters influencing drug activation and therapeutic outcome.
This approach enables efficient simulation and supports the design of optimized
hypoxia-targeted therapies.

</details>


### [28] [Data-driven optimal approximation on Hardy spaces in simply connected domains](https://arxiv.org/abs/2507.15837)
*Alessandro Borghi,Tobias Breiten*

Main category: math.NA

TL;DR: The paper explores optimal interpolation of analytic functions in complex domains, linking it to discrete-time dynamical systems and numerical methods, with a data-driven algorithm for approximants.


<details>
  <summary>Details</summary>
Motivation: To develop optimal interpolation methods for analytic functions in complex domains and connect them to dynamical systems and numerical integration techniques.

Method: A specific approximant structure is chosen, leading to first-order optimality conditions interpreted as optimal H₂ interpolation conditions. Connections to numerical methods like implicit Euler are made, and a data-driven algorithm is proposed.

Result: The method is validated through three numerical experiments, demonstrating its effectiveness in computing locally optimal approximants.

Conclusion: The approach successfully bridges interpolation theory with dynamical systems and numerical methods, offering practical computational tools.

Abstract: We consider optimal interpolation of functions analytic in simply connected
domains in the complex plane. By choosing a specific structure for the
approximant, we show that the resulting first order optimality conditions can
be interpreted as optimal $\mathcal{H}_2$ interpolation conditions for
discrete-time dynamical systems. Connections to the implicit Euler method, the
midpoint method, and backward differentiation methods are also established. A
data-driven algorithm is developed to compute a (locally) optimal approximant.
Our method is tested on three numerical experiments.

</details>


### [29] [Iterative thresholding low-rank time integration](https://arxiv.org/abs/2507.15848)
*Markus Bachmayr,Matthieu Dolbeault,Polina Sachsenmaier*

Main category: math.NA

TL;DR: Adaptive low-rank time integration methods with soft thresholding ensure accuracy while maintaining proportional ranks to best approximations, tested on Schrödinger and parabolic problems.


<details>
  <summary>Details</summary>
Motivation: To develop efficient time integration methods that adaptively adjust ranks for accuracy while staying proportional to optimal ranks.

Method: Iterative scheme with soft thresholding of iterates, applied to low-rank matrix approximations for time-dependent problems.

Result: Successful numerical tests for Schrödinger and parabolic problems, demonstrating adaptive rank adjustment.

Conclusion: The method effectively balances accuracy and computational efficiency for low-rank time integration.

Abstract: We develop time integration methods in low-rank representation that can
adaptively adjust approximation ranks to achieve a prescribed accuracy, while
ensuring that these ranks remain proportional to the corresponding best
approximation ranks. Our approach relies on an iterative scheme combined with
soft thresholding of the iterates. A model case of a time-dependent
Schr\"odinger equation with low-rank matrix approximation is analyzed in
detail, and the required modifications for second-order parabolic problems are
described. Numerical tests illustrate the results for both cases.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [30] [Very weak solutions of the heat equation with anisotropically singular time-dependent diffusivity](https://arxiv.org/abs/2507.14411)
*Zhirayr Avetisyan,Zahra Keyshams,Monire Mikaeili Nia,Michael Ruzhansky*

Main category: math.AP

TL;DR: Existence and uniqueness of solutions for the heat equation with singular, anisotropic, time-dependent diffusivity using very weak solutions.


<details>
  <summary>Details</summary>
Motivation: Weak or distributional solutions may not exist for the heat equation with singular, anisotropic, time-dependent diffusivity.

Method: Employ the framework of very weak solutions.

Result: Established existence and uniqueness of solutions.

Conclusion: Very weak solutions are effective for this problem.

Abstract: We investigate the heat equation with a time-dependent, anisotropic, and
potentially singular diffusivity tensor. Since weak (in the Sobolev sense) or
distributional solutions may not exist in this setting, we employ the framework
of very weak solutions to establish the existence and uniqueness of solutions
to the heat equation with singular, anisotropic, time-dependent diffusivity.

</details>


### [31] [On the direct and inverse electromagnetic scattering in a parallel-plate waveguide](https://arxiv.org/abs/2507.14480)
*Jiawei Liang,Maojun Li,Tao Yin*

Main category: math.AP

TL;DR: The paper analyzes the wellposedness of the direct problem and uniqueness of the inverse problem in electromagnetic scattering within a parallel-plate waveguide, using variational methods and the probe method.


<details>
  <summary>Details</summary>
Motivation: To rigorously study the theoretical foundations of electromagnetic scattering problems in waveguides, focusing on wellposedness and uniqueness.

Method: Reduces the direct problem to a bounded domain using an exact transparent boundary condition, employs variational approach for wellposedness, and uses the probe method for uniqueness in the inverse problem.

Result: Proves wellposedness in Sobolev spaces and establishes uniqueness for the inverse obstacle problem.

Conclusion: The theoretical framework provides a solid foundation for solving electromagnetic scattering problems in waveguides.

Abstract: This paper devotes to providing rigorous theoretical analysis of the
wellposedness of the direct problem and the uniqueness of the inverse problem
of electromagnetic scattering in a parallel-plate waveguide. The direct problem
is reduced to an equivalent boundary value problem on a bounded domain by
introducing an exact transparent boundary condition in terms of the
electric-to-magnetic Calder\'on operator which can be explicitly represented as
a series expansion. Then the wellopsedness of the reduced problem in
appropriate Sobolev spaces is proved via the variational approach provided by
some necessary properties of the Calder\'on operator and Helmholtz
decomposition. Relying on the Green's representation formula and a reciprocity
relation, the probe method, finally, is utilized to show the uniqueness of the
inverse obstacle problem.

</details>


### [32] [New non-invertible mappings and general solutions of linear wave equations with variable wave speeds](https://arxiv.org/abs/2507.14522)
*Rafael de la Rosa,George W. Bluman*

Main category: math.AP

TL;DR: The paper introduces symmetry-based methods to map linear wave equations with variable wave speeds to other wave equations, including those with constant speeds, and derives general solutions.


<details>
  <summary>Details</summary>
Motivation: To explore non-invertible mappings for wave equations with variable speeds, enabling solutions for such equations.

Method: Uses symmetry-based techniques to transform wave equations with variable speeds into equations with different or constant speeds.

Result: New non-invertible mappings are derived, and general solutions for wave equations with variable speeds are obtained.

Conclusion: The symmetry-based approach effectively solves linear wave equations with variable speeds by transforming them into simpler forms.

Abstract: We show how the symmetry-based method can be used to obtain new
non-invertible equivalence mappings of linear wave equations with variable wave
speeds $c(x,t)$ to linear wave equations with different variable wave speeds.
Moreover, we present new non-invertible mappings of linear wave equations with
variable wave speeds $c(x,t)$ to a linear wave equation with a constant wave
speed. Consequently, the general solutions of these linear wave equations with
variable wave speeds $c(x,t)$ are obtained.

</details>


### [33] [A concentration phenomenon for a semilinear Schrödinger equation with periodic self-focusing core](https://arxiv.org/abs/2507.14541)
*Mónica Clapp,Alberto Saldaña,Andrzej Szulkin*

Main category: math.AP

TL;DR: The paper studies a nonlinear Schrödinger equation with a sign-changing potential and proves the existence of least energy solutions, showing concentration behavior as the potential's scale approaches zero.


<details>
  <summary>Details</summary>
Motivation: To investigate the existence and behavior of solutions to a nonlinear Schrödinger equation with a rapidly oscillating potential, which alternates between positive and negative values.

Method: The authors analyze the equation using variational methods in the Sobolev space $H^1(\mathbb{R}^N)$, focusing on least energy solutions and their concentration properties.

Result: Existence of least energy solutions is proven for small scales of the potential, with solutions concentrating near lattice points as the scale decreases.

Conclusion: The study demonstrates the impact of oscillating potentials on solution behavior, particularly concentration near lattice points, providing insights into nonlinear PDEs with sign-changing potentials.

Abstract: We consider the equation $$-\Delta u+u=Q_\varepsilon(x)|u|^{p-2}u,\qquad u\in
H^1(\mathbb{R}^N),$$ where $Q_\varepsilon$ takes the value $1$ on each ball
$B_\varepsilon(y)$, $y\in\mathbb{Z}^N$, and the value $-1$ elsewhere. We
establish the existence of a least energy solution for each
$\varepsilon\in(0,\frac{1}{2})$ and show that their $H^1$ and $L^p$ norms
concentrate locally at points of $\mathbb{Z}^N$ as $\varepsilon\to 0$.

</details>


### [34] [Scattering for the nonlinear Schrödinger equation with concentrated nonlinearity](https://arxiv.org/abs/2507.14571)
*Benjamin Harrop-Griffiths,Rowan Killip,Monica Visan*

Main category: math.AP

TL;DR: Global well-posedness and scattering are proven for the cubic defocusing NLS with point-concentrated nonlinearity in 1D, extending to spatially concentrated nonlinearities.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of nonlinear Schrödinger equations with highly localized nonlinear effects, particularly in critical spaces.

Method: Analyze the cubic defocusing NLS with nonlinearity concentrated at a single point, using scaling-critical spaces and scattering theory.

Result: Global well-posedness in $L^2(\mathbb{R})$ and scattering for all solutions, with broader applicability to spatially concentrated nonlinearities.

Conclusion: The study confirms robust behavior of solutions under concentrated nonlinear effects, offering insights for similar systems.

Abstract: We consider the cubic defocusing nonlinear Schr\"odinger equation in one
dimension with the nonlinearity concentrated at a single point. We prove global
well-posedness in the scaling-critical space $L^2(\mathbb{R})$ and scattering
for all such solutions. Moreover, we demonstrate that the same phenomenology
holds whenever nonlinear effects are sufficiently concentrated in space.

</details>


### [35] [Relaxation limit of pressureless Euler-Poisson equations](https://arxiv.org/abs/2507.14576)
*GuiRong Tang*

Main category: math.AP

TL;DR: The paper studies the relaxation problem for pressureless Euler-Poisson equations with initial density as a finite Radon measure, showing convergence to drift-diffusion equations and proving uniqueness of entropy solutions.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of entropy solutions in pressureless Euler-Poisson systems and their convergence to drift-diffusion equations as relaxation time vanishes.

Method: Constructs explicit solution formulas for both systems and directly proves convergence, using Oleinik condition and weak continuity of kinetic energy measure for uniqueness.

Result: Entropy solutions converge to weak solutions of drift-diffusion equations without diffusion; uniqueness of entropy solutions is established.

Conclusion: The study provides a direct convergence result and uniqueness proof for entropy solutions in pressureless Euler-Poisson systems.

Abstract: We investigate the relaxation problem for the one-dimensional pressureless
Euler--Poisson equations with the initial density being a finite Radon measure.
The entropy solution of this linearly degenerate hyperbolic system converges to
the weak solution of part of drift--diffusion equations without diffusion term
when the momentum relaxation time tends to zero. Independent of compactness,
our strategy is to construct the formula of solutions to both systems and
directly obtain the convergent result. Furthermore, the uniqueness of entropy
solution to pressureless Euler--Poisson equations is also proved by Oleinik
condition and the initially weak continuity of kinetic energy measure.

</details>


### [36] [Structurally damped semilinear evolution equation for positive operators on Hilbert space](https://arxiv.org/abs/2507.14581)
*Aparajita Dasgupta,Lalit Mohan,Abhilash Tushir*

Main category: math.AP

TL;DR: The paper analyzes decay estimates for solutions of a semilinear damped evolution equation under various damping conditions, focusing on linear evolution with minimal regularity initial data. It also explores global existence for certain cases with polynomial nonlinearity.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of solutions to damped evolution equations under different damping conditions and initial data regularity, providing insights into decay rates and global existence.

Method: The study examines the Cauchy problem for a linear evolution equation with a self-adjoint, positive operator, analyzing decay estimates for solutions, their derivatives, and the impact of initial data regularity.

Result: Decay rates of solutions improve with initial data regularity, and global existence is demonstrated for certain cases with polynomial nonlinearity.

Conclusion: The findings provide decay estimates and conditions for global existence, with further exploration of local existence and blow-up results reserved for a follow-up study.

Abstract: In this study, we analyze a semilinear damped evolution equation under
different damping conditions, including the undamped $(\theta=0)$, effectively
damped $(0<2\theta<\sigma)$, critically damped $(2\theta=\sigma)$, and
non-effectively damped $(\sigma<2\theta\leq 2\sigma)$. The analysis is
conducted in two parts; the present article is devoted to examining decay
estimates of solutions to the linear evolution equation governed by a
self-adjoint, positive operator $\mathcal{L}$ with discrete spectrum subject to
initial Cauchy data of minimal regularity. Specifically, we consider the Cauchy
problem: \begin{equation*}
  \left\{\begin{array}{l}
  u_{tt}(t)+\mathcal{L}^{\theta}u_{t}(t)+\mathcal{L}^{\sigma}u(t) =0, \quad
t>0,
  u(0)=u_{0}\in\mathcal{H},\quad
  u_{t}(0)=u_{1}\in\mathcal{H},
  \end{array}\right. \end{equation*} in different damping conditions. %More
precisely, we study decay estimates for a solution, its time derivative, and
space derivative in both cases. Furthermore, we demonstrate that the decay
rates of the associated solutions improve with the regularity of the initial
Cauchy data. As an application of the decay estimates, we also demonstrate the
global existence (in time) of the solution in certain cases, taking into
account polynomial-type nonlinearity. In the 2nd article, we will address the
remaining instances where global existence cannot be assured and instead
present findings on local existence and possible blow-up results.

</details>


### [37] [Global Lipschitz regularity in anisotropic elliptic problems with natural gradient growth](https://arxiv.org/abs/2507.14606)
*Carlo Alberto Antonini,Andrea Cianchi*

Main category: math.AP

TL;DR: The paper establishes global Lipschitz regularity for solutions to anisotropic elliptic p-Laplace problems under minimal assumptions on the right-hand side and domain curvature.


<details>
  <summary>Details</summary>
Motivation: To address boundary-value problems for anisotropic elliptic operators, which arise in variational calculus, and to extend regularity results under weak assumptions.

Method: Analyzes homogeneous Dirichlet and Neumann problems for anisotropic p-Laplace operators, focusing on integral functionals of gradient norms.

Result: Proves global Lipschitz regularity of solutions in convex domains or those with minimal boundary curvature integrability.

Conclusion: The findings generalize regularity results for anisotropic p-Laplace problems under minimal conditions, applicable to a broader class of domains.

Abstract: We deal with homogeneous Dirichlet and Neumann boundary-value problems for
anisotropic elliptic operators of p-Laplace type. They emerge as Euler-Lagrange
equations of integral functionals of the Calculus of Variations built upon
possibly anisotropic norms of the gradient of trial functions. We establish
global Lipschitz regularity of solutions under the weakest possible assumption
on right-hand side of the equation, which may also include the gradient term
with natural growth exponent. The results hold in either convex domains, or
domains enjoying minimal integrability assumptions on the curvature of its
boundary.

</details>


### [38] [Self-Similar Solutions to a Nonlinear Forward-Backward Parabolic Equation](https://arxiv.org/abs/2507.14635)
*Tian Jing*

Main category: math.AP

TL;DR: Study of a mixed-type equation u u_x = u_{yy}, analyzing solutions that change type smoothly, simplified to a second-order ODE, yielding a self-similar solution with a sign change.


<details>
  <summary>Details</summary>
Motivation: The equation arises from boundary layers with separation, and understanding its behavior when solutions change type is key.

Method: Simplify the equation into a second-order ODE using similarity variables and analyze it as a first-order nonlinear ODE system.

Result: Existence of a self-similar solution with a sign change is proven.

Conclusion: The analysis provides insights into the equation's behavior when solutions transition smoothly between forward and backward parabolic types.

Abstract: In this paper, we study the mixed-type equation u u_x = u_{yy}, which behaves
as forward and backward parabolic equations depending on the sign of u. The
equation arises from the study of boundary layers with separation. We seek
solutions that change their type smoothly to better understand the equation. We
simplify the equation into a second-order ODE using similarity variables, and
prove an existence result by analyzing it as a first-order nonlinear ODE
system. This provides us a self-similar solution with a sign change.

</details>


### [39] [On a Generalized System with Applications to Ideal Magnetohydrodynamics](https://arxiv.org/abs/2507.14772)
*Alejandro Sarria*

Main category: math.AP

TL;DR: The paper investigates finite-time blowup in solutions to a generalized system of equations, with applications in MHD and fluid dynamics, using concavity arguments, energy estimates, and ODE comparisons.


<details>
  <summary>Details</summary>
Motivation: To understand blowup criteria in a parameter-dependent system relevant to MHD and fluid dynamics, focusing on smooth initial data.

Method: Tracking evolution of $u_x$ along Lagrangian trajectories, employing concavity arguments, energy estimates, and ODE comparison methods.

Result: Derived precise blowup criteria for specific parameter values; showed non-vanishing $b_0'(x_0)$ can suppress blowup.

Conclusion: The study provides insights into blowup behavior in MHD and fluid systems, highlighting parameter-dependent suppression effects.

Abstract: Finite-time blowup of solutions $(u(x,t),b(x,t))$ to a generalized system of
equations with applications to ideal Magnetohydrodynamics (MHD) and
one-dimensional fluid convection and stretching, among other areas, is
investigated. The system is parameter-dependent, our spatial domain is the unit
interval or the circle, and the initial data $(u_0(x),b_0(x))$ is assumed to be
smooth. Among other results, we derive precise blowup criteria for specific
values of the parameters by tracking the evolution of $u_x$ along Lagrangian
trajectories that originate at a point $x_0$ at which $b_0(x)$ and $b_0'(x)$
vanish. We employ concavity arguments, energy estimates, and ODE comparison
methods. We also show that for some values of the parameters, a non-vanishing
$b_0'(x_0)$ suppresses finite-time blowup.

</details>


### [40] [Pattern formations of coupled PDEs with transparent boundary conditions in product-type ends and applications](https://arxiv.org/abs/2507.14779)
*Huaian Diao,Hongyu Liu,Qingle Meng,Li Wang*

Main category: math.AP

TL;DR: The paper explores pattern formations in coupled elliptic PDE systems with transparent boundary conditions, linking diverse fields like inverse boundary problems and wave scattering. It identifies a novel local pattern formation and establishes a quantitative relationship between PDE terms and geometric parameters.


<details>
  <summary>Details</summary>
Motivation: To unify and analyze pattern formations in coupled elliptic PDE systems, connecting inverse boundary problems, spectral geometry, and wave scattering phenomena.

Method: Study of coupled elliptic PDE systems governed by transparent boundary conditions, focusing on local pattern formations and their quantitative relationships with geometric parameters.

Result: Discovery of a novel local pattern formation and a sharp quantitative link between PDE terms and geometric/regularity parameters in high-curvature domains.

Conclusion: The findings provide foundational insights with practical implications across inverse problems, spectral geometry, and wave scattering.

Abstract: This paper studies pattern formations in coupled elliptic PDE systems
governed by transparent boundary conditions. Such systems unify diverse areas,
including inverse boundary problems (via a single passive/active boundary
measurement), spectral geometry of transmission eigenfunctions, and geometric
characterization of invisibility phenomena and inverse shape problems in wave
scattering. We uncover and rigorously characterize a novel local pattern
formation, establishing a sharp quantitative relationship between the
difference in the PDEs' lower-order terms and the geometric/regularity
parameters within a generic domain's product-type ends-structures characterized
by high extrinsic curvature. This foundational result yields new findings with
novel physical insights and practical implications across these fields.

</details>


### [41] [Existence and asymptotical behavior of normalized solutions to focusing biharmonic HLS upper critical Hartree equation with a local perturbation](https://arxiv.org/abs/2507.14896)
*Jianlun Liu,Hong-Rui Sun,Ziheng Zhang*

Main category: math.AP

TL;DR: The paper extends previous results on the L²-subcritical perturbation to the case of a biharmonic HLS upper critical Hartree equation, proving the existence of normalized solutions and analyzing their asymptotic behavior.


<details>
  <summary>Details</summary>
Motivation: The study aims to address the existence of normalized solutions for a perturbed biharmonic HLS equation, extending prior work on L²-subcritical cases.

Method: The authors use a testing function to estimate the mountain pass level and verify the (PS) condition to prove solution existence for any μ>0.

Result: Existence of normalized solutions is shown for the extended case, and asymptotic behavior of energy is analyzed as μ and c approach zero.

Conclusion: The paper successfully generalizes earlier results and provides insights into the energy behavior of solutions under specific limits.

Abstract: This paper is concerned with the following focusing biharmonic HLS upper
critical Hartree equation with a local perturbation $$ \begin{cases}
  {\Delta}^2u-\lambda
u-\mu|u|^{p-2}u-(I_\alpha*|u|^{4^*_\alpha})|u|^{4^*_\alpha-2}u=0\ \ \mbox{in}\
\mathbb{R}^N, \\[0.1cm]
  \int_{\mathbb{R}^N} u^2 dx = c, \end{cases} $$ where $0<\alpha<N$, $N \geq
5$, $\mu,c>0$, $2+\frac{8}{N}=:\bar{p}\leq p<4^*:=\frac{2N}{N-4}$,
$4^*_\alpha:=\frac{N+\alpha}{N-4}$, $\lambda \in \mathbb{R}$ is a Lagrange
multiplier and $I_\alpha$ is the Riesz potential. Choosing an appropriate
testing function, one can derive some reasonable estimate on the mountain pass
level. Based on this point, we show the existence of normalized solutions by
verifying the \emph{(PS)} condition at the corresponding mountain pass level
for any $\mu>0$. The contribution of this paper is that the recent results
obtained for $L^2$-subcritical perturbation by Chen et al. (J. Geom. Anal. 33,
371 (2023)) is extended to the case $\bar{p}\leq p<4^*$. Moreover, we also
discuss asymptotic behavior of the energy to the mountain pass solution when
$\mu\to 0^+$ and $c\to 0^+$, respectively.

</details>


### [42] [Improved convergence of Landau-de Gennes minimizers in the vanishing elasticity limit](https://arxiv.org/abs/2507.14955)
*Haotong Fu,Huaijie Wang,Wei Wang*

Main category: math.AP

TL;DR: Study of vanishing elasticity limit in Landau-de Gennes model, proving optimal L^p convergence and sharp L^1 rate for bulk energy.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of minimizers in the Landau-de Gennes model as elasticity vanishes, focusing on convergence properties.

Method: Refined blow-up and covering analysis to examine minimizers.

Result: Optimal L^p convergence for minimizers and sharp L^1 convergence rate for bulk energy.

Conclusion: The analysis provides rigorous convergence results for the model, enhancing understanding of its limiting behavior.

Abstract: We investigate the vanishing elasticity limit for minimizers of the Landau-de
Gennes model with finite energy. By adopting a refined blow-up and covering
analysis, we establish the optimal $ L^p $ ($ 1<p<\infty $) convergence of
minimizers and achieve the sharp $ L^1 $ convergence rate of the bulk energy
term.

</details>


### [43] [On global regular axially-symmetric solution to the Navier-Stokes equations in a cylinder](https://arxiv.org/abs/2507.14964)
*Wiesław J. Grygierzec,Wojciech M. Zajączkowski*

Main category: math.AP

TL;DR: The paper proves the existence of global regular solutions for the axisymmetric Navier-Stokes equations in a finite cylinder under specific boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To establish global regularity for axially-symmetric solutions of the Navier-Stokes equations, a long-standing problem in fluid dynamics.

Method: Uses $H^3$ Sobolev estimates for the modified stream function and energy estimates for the gradient of swirl to derive reduction estimates.

Result: Derives a global estimate for regular solutions, leading to the existence of global regular axially-symmetric solutions.

Conclusion: The method successfully demonstrates the existence of global regular solutions under the given boundary conditions.

Abstract: We consider the axisymmetric Navier-Stokes equations in a finite cylinder
$\Omega\subset\mathbb{R}^3$. We assume that $v_r$, $v_\varphi$,
$\omega_\varphi$ vanish on the lateral part of boundary $\partial\Omega$ of the
cylinder, and that $v_z$, $\omega_\varphi$, $\partial_zv_\varphi$ vanish on the
top and bottom parts of the boundary $\partial\Omega$, where we used standard
cylindrical coordinates, and we denoted by $\omega={\rm curl}\, v$ the
vorticity field. We use $H^3$ Sobolev estimates for the modified stream
function (stream function divided by radius) and energy type estimates for
gradient of swirl to derive two order reduction estimates. These help one to
derive a global estimate for a regular solution. This estimate yields the
existence of global regular axially-symmetric solutions.

</details>


### [44] [Strichartz estimates involving orthonormal systems at the critical summability exponent](https://arxiv.org/abs/2507.14974)
*Guoxia Feng,Manli Song,Huoxiong Wu*

Main category: math.AP

TL;DR: The paper investigates orthonormal Strichartz estimates for the Schrödinger operator, proving new global strong-type estimates at the optimal exponent.


<details>
  <summary>Details</summary>
Motivation: To extend and improve existing work on orthonormal Strichartz estimates for the Schrödinger operator with initial data from homogeneous Sobolev spaces.

Method: Uses restricted weak-type orthonormal estimates, real interpolation, and leverages the condition q<p in the ODCA interior.

Result: Proves new global strong-type orthonormal Strichartz estimates at the optimal summability exponent α=q.

Conclusion: The findings significantly supplement prior work, providing stronger estimates under specific conditions.

Abstract: The primary objective of this paper is to investigate the orthonormal
Strichartz estimates at the critical summability exponent for the Schr\"odinger
operator $e^{it\Delta}$ with initial data from the homogeneous Sobolev space
$\dot{H}^s (\mathbb{R}^n)$. We prove new global strong-type orthonormal
Strichartz estimates in the interior of $ODCA$ at the optimal summability
exponent $\alpha=q$, thereby substantially supplymenting the work of
Bez-Hong-Lee-Nakamura-Sawano \cite{Bez-Hong-Lee-Nakamura-Sawano}. Our approach
is based on restricted weak-type orthonormal estimates, real interpolation
argument and the advantageous condition $q<p$ in the interior of $ODCA$.

</details>


### [45] [Propagation of Chaos for Singular Interactions via Regular Drivers](https://arxiv.org/abs/2507.14981)
*Qian Qi*

Main category: math.AP

TL;DR: A framework for proving propagation of chaos in particle systems with singular, density-dependent interactions using a regular driver function and dissipation conditions.


<details>
  <summary>Details</summary>
Motivation: Addressing the classical challenge in mean-field theory of analyzing singular interactions in particle systems.

Method: Defines dynamics implicitly via a regular driver to generate singular interactions, with analytical control through a priori bounds for non-linear Fokker-Planck equations.

Result: Propagation of chaos is proven under a dissipation condition, with uniform bounds in $L^\infty([0,T]; H^1(\R) \cap L^\infty(\R))$.

Conclusion: The work provides a new approach for singular systems and a constructive theory for challenging interactions.

Abstract: We introduce a framework to prove propagation of chaos for interacting
particle systems with singular, density-dependent interactions, a classical
challenge in mean-field theory. Our approach is to define the dynamics
implicitly via a regular driver function. This regular driver is engineered to
generate a singular effective interaction, yet its underlying regularity
provides the necessary analytical control. Our main result establishes
propagation of chaos under a key dissipation condition. The proof hinges on
deriving a priori bounds, uniform in a regularization parameter, for the
densities of the associated non-linear Fokker-Planck equations. Specifically,
we establish uniform bounds in $L^\infty([0,T]; H^1(\R) \cap L^\infty(\R))$.
These are established via an energy method for the excess mass to secure the
$L^\infty$ bound, and a novel energy estimate for the $H^1$ norm that
critically leverages the stability condition. These bounds provide the
compactness necessary to pass to the singular limit, showing convergence to a
McKean-Vlasov SDE with a singular, density-dependent diffusion coefficient.
This work opens a new path to analyzing singular systems and provides a
constructive theory for a class of interactions that present significant
challenges to classical techniques.

</details>


### [46] [Gradient continuity estimates for elliptic equations of singular $p$-Laplace type with measure data](https://arxiv.org/abs/2507.15029)
*Longjuan Xu,Yirui Zhao*

Main category: math.AP

TL;DR: The paper studies $p$-Laplace type elliptic equations with measure data, proving gradient pointwise estimates using Wolff and Riesz potentials under Dini continuity conditions. It generalizes prior results and establishes gradient continuity estimates.


<details>
  <summary>Details</summary>
Motivation: To extend and generalize existing results on gradient estimates for $p$-Laplace type equations with measure data, particularly under Dini continuity assumptions on coefficients.

Method: The authors assume Dini continuity of coefficients in the $L^2$-mean sense, prove a new comparison estimate, and derive interior and global gradient pointwise estimates using Wolff potential for $p\geq2$ and Riesz potential for $1<p<2$.

Result: Interior and global gradient pointwise estimates are derived, and the results are applied to singular quasilinear elliptic equations. Gradient continuity estimates are also established.

Conclusion: The work generalizes prior research and provides new insights into gradient behavior for $p$-Laplace type equations with measure data under Dini continuity conditions.

Abstract: In this paper, we are concerned with elliptic equations of $p$-Laplace type
with measure data, which is given by $-div\big(a(x)(|\nabla
u|^2+s^2)^{\frac{p-2}{2}}\nabla u\big)=\mu$ with $p>1$ and $s\geq0$. Under the
assumption that the modulus of continuity of the coefficient $a(x)$ in the
$L^2$-mean sense satisfies the Dini condition, we prove a new comparison
estimate and use it to derive interior and global gradient pointwise estimates
by Wolff potential for $p\geq 2$ and Riesz potential for $1<p<2$, respectively.
Our interior gradient pointwise estimates can be applied to a class of singular
quasilinear elliptic equations with measure data given by $-div(A(x,\nabla
u))=\mu$. We generalize the results in the papers of Duzaar and Mingione [Amer.
J. Math. 133, 1093-1149 (2011)], Dong and Zhu [J. Eur. Math. Soc. 26, 3939-3985
(2024)], and Nguyen and Phuc [Arch. Rational Mech. Anal. (2023) 247:49], etc.,
where the coefficient is assumed to be Dini continuous. Moreover, we establish
interior and global modulus of continuity estimates of the gradients of
solutions.

</details>


### [47] [Global Bifurcation of Spiral Wave Solutions to the Complex Ginzburg-Landau Equation](https://arxiv.org/abs/2507.15098)
*Carlos Garcia-Azpeitia,Ziad Ghanem,Wieslaw Krawcewicz*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We use the $\mathbb T^2$-equivariant degree to establish the existence of
unbounded branches of rotating spiral wave solutions with any number of arms
for the complex Ginzburg Landau equation GLe on the planar unit disc,
leveraging the spatial symmetries inherent to the problem and avoiding limiting
constraints encountered in previous studies (Dai 2021) that utilized the
classical Leray-Schauder degree. Our results provide rigorous mathematical
justification for the formation and persistence of these fundamental patterns,
which are ubiquitous in physical, chemical, and biological systems but have,
until now, eluded formal proof under general conditions.

</details>


### [48] [Global Spherically Symmetric Solutions and Relaxation Limit for the Relaxed Compressible Navier-Stokes Equations](https://arxiv.org/abs/2507.15179)
*Yuxi Hu,Mengran Yuan*

Main category: math.AP

TL;DR: The paper analyzes spherically symmetric solutions for hyperbolized compressible Navier-Stokes equations with Maxwell law in an exterior domain, proving global well-posedness and relaxation limit.


<details>
  <summary>Details</summary>
Motivation: To address the hyperbolized compressible Navier-Stokes equations with Maxwell law, focusing on spherically symmetric solutions in an exterior domain.

Method: Constructs an approximate system with non-characteristic boundary, uses weighted energy functionals for uniform estimates, and applies compactness arguments.

Result: Proves global well-posedness of the original system and justifies the global relaxation limit.

Conclusion: The study successfully establishes global solutions and validates the relaxation limit for the hyperbolized system.

Abstract: This paper studies an initial boundary value problem for the multidimensional
hyperbolized compressible Navier-Stokes equations, in which the classical
Newtonian law is replaced by the Maxwell law. We seek spherically symmetric
solutions to the studied system in an exterior domain of a ball in $\mathbb
R^3$, which are a system possessing a uniform characteristic boundary. First,
we construct an approximate system featuring a non-characteristic boundary and
establish its local well-posedness. Subsequently, by defining a suitable
weighted energy functional and carefully handling boundary terms, we derive
uniform a priori estimates, enabling the proof of uniform global existence.
Leveraging these uniform estimates alongside standard compactness arguments, we
establish the global well-posedness of the original system. Additionally, we
rigorously justify the global relaxation limit.

</details>


### [49] [Proofs of singularity-free solutions and scalarization in nonlinear Einstein-scalar-Gauss-Bonnet cosmology](https://arxiv.org/abs/2507.15304)
*Chihang He,Chao Liu,Jinhua Wang*

Main category: math.AP

TL;DR: Global existence and precise estimates of singularity-free cosmological solutions in ESGB gravity with quadratic coupling are established, confirming numerical results and proving nonlinear spontaneous scalarization.


<details>
  <summary>Details</summary>
Motivation: To rigorously analyze and prove the existence of singularity-free solutions in ESGB gravity and understand spontaneous scalarization triggered by a tachyonic instability.

Method: Derived decoupled differential inequalities for the Hubble parameter using a structural identity called the power identity.

Result: Confirmed global existence of solutions and provided precise estimates, aligning with numerical results. Proved nonlinear spontaneous scalarization mathematically.

Conclusion: The study successfully established rigorous mathematical proofs for singularity-free solutions and spontaneous scalarization in ESGB gravity.

Abstract: We establish the global existence and precise estimates of a class of
singularity-free cosmological solutions in nonlinear
Einstein-scalar-Gauss-Bonnet (ESGB) gravity with quadratic coupling, in close
agreement with previous numerical results. Our analysis also yields a rigorous
mathematical proof of nonlinear spontaneous scalarization, triggered by a
tachyonic instability induced by the Gauss-Bonnet term. The proof is based on a
set of decoupled differential inequalities for the Hubble parameter $H$,
derived from a key structural identity that we refer to as the power identity.

</details>


### [50] [On the reachable space for parabolic equations](https://arxiv.org/abs/2507.15407)
*Sylvain Ervedoza,Adrien Tendani-Soler*

Main category: math.AP

TL;DR: The paper describes the reachable space for the heat equation with lower-order terms in a Euclidean ball, covering linear and semilinear cases, and uses holomorphic function spaces for proofs.


<details>
  <summary>Details</summary>
Motivation: To characterize the reachable space for heat equations with lower-order terms, controlled from the boundary, in both linear and semilinear settings.

Method: Analyzes the heat equation in holomorphic function spaces over a specific domain, proving reachability for functions extendable as holomorphic in this domain.

Result: In the linear case, functions holomorphically extendable to a certain domain belong to the reachable space. For semilinear cases, this holds for small data.

Conclusion: The study provides a framework for understanding reachability in heat equations with lower-order terms using holomorphic function spaces.

Abstract: In this article, we provide a description of the reachable space for the heat
equation with various lower order terms, set in the euclidean ball of
$\mathbb{R}^d$ centered at $0$ and of radius one and controlled from the whole
external boundary. Namely, we consider the case of linear heat equations with
lower order terms of order $0$ and $1$, and the case of a semilinear heat
equations. In the linear case, we prove that any function which can be extended
as an holomorphic function in a set of the form $\Omega_\alpha = \{
z\in\mathbb{C}^d \big| |\Re(z)| + \alpha |\Im(z)| < 1\}$ for some $\alpha \in
(0,1)$ and which admits a continuous extension up to $\overline\Omega_\alpha$
belongs to the reachable space. In the semilinear case, we prove a similar
result for sufficiently small data. Our proofs are based on well-posedness
results for the heat equation in a suitable space of holomorphic functions over
$\Omega_\alpha$ for $\alpha > 1$.

</details>


### [51] [Discontinuous shear-thickening asymptotic for power-law systems related to compressible flows](https://arxiv.org/abs/2507.15410)
*Didier Bresch,Cosmin Burtea,Maja Szlenk*

Main category: math.AP

TL;DR: The paper extends previous studies on power-law models for fluids to compressible thick fluids, addressing large pressures and hyperbolic-parabolic coupling.


<details>
  <summary>Details</summary>
Motivation: Large pressures in squeezing flows necessitate compressibility consideration, extending prior incompressible and elliptic models.

Method: Analyzes one-dimensional non-stationary and semi-stationary multi-dimensional compressible power-law systems, including a singular shear-rate case.

Result: Two main results: convergence for one-dimensional and multi-dimensional compressible systems, plus an extension for singular shear-rate dependence.

Conclusion: The study successfully extends prior incompressible models to compressible fluids, addressing key mathematical and physical challenges.

Abstract: In this paper we study the convergence of a power-law model for dilatant
compressible fluids to a class of models exhibiting a maximum admissible shear
rate, called thick compressible fluids. These kinds of problems were studied
previously for elliptic equations, stating with the work of Bhattacharya, E.
DiBenedetto and J. Manfredi [Rend. Sem. Mat. Univ. Politec. Torino 1989], and
more recently for incompressible fluids by J.F. Rodrigues [J. Math. Sciences
2015]. Our result may be seen as an extension to the compressible setting of
these previous works. Physically, this is motivated by the fact that the
pressures generated during a squeezing flow are often large, potentially
requiring the consideration of compressibility, see M. Fang and R. Gilbert [Z.
Anal. Anwend 2004]. Mathematically, the main difficulty in the compressible
setting concerns the strong hyperbolicparabolic coupling between the density
and velocity field. We obtain two main results, the first concerning the
one-dimensional non-stationary compressible power-law system while the second
one concerns the semi-stationary multi-dimensional case. Finally, we present an
extension in onedimension for a viscous Cauchy stress with singular dependence
on the shear rate.

</details>


### [52] [Boundary vortices in the presence of a magnetic field](https://arxiv.org/abs/2507.15412)
*Khalida Awashra,Matthias Kurzke*

Main category: math.AP

TL;DR: The paper analyzes magnetization in a thin ferromagnetic film under an external field, focusing on boundary vortices and their energy interactions.


<details>
  <summary>Details</summary>
Motivation: To understand how boundary vortices dominate energy in thin films and their interaction under external fields.

Method: Uses Gamma-convergence to link micromagnetic energy to renormalized energy, with numerical simulations in disk and oval domains.

Result: Energy concentrates around boundary vortices, whose locations depend on the external field.

Conclusion: The study provides a rigorous link between micromagnetic and renormalized energy, validated by simulations.

Abstract: We study the behaviour of the magnetization vector field in a thin
ferromagnetic film in the presence of an external in-plane constant magnetic
field. We work on a specific thin-film regime where boundary vortices dominate
the energy and show the Gamma-convergence at the second order of the
micromagnetic energy to an energy term called the renormalized energy,
representing the interaction energy between boundary vortices. We present a new
approach to defining the renormalized energy and rigorously show the relation
between this definition and the classical one. We prove the concentration of
the energy around boundary vortices, where the location of these vortices
depends on the external field applied. We provide some numerical simulations of
the magnetization vector field and the renormalized energy versus the location
of the vortices in two different domains: the unit disk and an oval-shaped
domain.

</details>


### [53] [Superlinear fractional $Φ$-Laplacian type problems via the nonlinear Rayleigh quotient with two parameters](https://arxiv.org/abs/2507.15514)
*L. R. S. de Assis,M. L. M. Carvalho,Edcarlos D. Silva,A. Salort*

Main category: math.AP

TL;DR: The paper establishes the existence and multiplicity of weak solutions for nonlocal elliptic problems with a sign-indefinite nonlinearity, focusing on the fractional Φ-Laplacian operator. It determines sharp parameter values for applying the Nehari method and analyzes solution behavior asymptotically.


<details>
  <summary>Details</summary>
Motivation: The study aims to address nonlocal elliptic problems with sign-indefinite nonlinearities, a challenging area in PDEs, by leveraging the Nehari method and analyzing asymptotic solution behavior.

Method: The authors use the nonlinear Rayleigh quotient and analyze fibering maps of the energy functional to apply the Nehari method. They also study asymptotic behavior of solutions as parameters λ and μ vary.

Result: Existence and multiplicity of weak solutions are proven, with sharp parameter values identified for the Nehari method. Asymptotic behavior of solutions is characterized.

Conclusion: The work successfully applies the Nehari method to nonlocal elliptic problems, providing insights into solution multiplicity and behavior under varying parameters.

Abstract: In this work, we establish the existence and multiplicity of weak solutions
for nonlocal elliptic problems driven by the fractional $\Phi$-Laplacian
operator, in the presence of a sign-indefinite nonlinearity. More specifically,
we investigate the following nonlocal elliptic problem: \begin{equation*}
\left\{\begin{array}{rcl} (-\Delta_\Phi)^s u +V(x)u & = & \mu
a(x)|u|^{q-2}u-\lambda |u|^{p-2}u \mbox{ in }\, \mathbb{R}^N, \\ u\in
W^{s,\Phi}(\mathbb{R}^N),&& \end{array} \right. \end{equation*} where $s \in
(0,1), N \geq 2$ and $\mu, \lambda >0$. Here, the potentials $V, a :
\mathbb{R}^N \to \mathbb{R}$ satisfy some suitable hypotheses. Our main
objective is to determine sharp values for the parameters $\lambda > 0$ and
$\mu > 0$ where the Nehari method can be effectively applied. To achieve this,
we utilize the nonlinear Rayleigh quotient along with a detailed analysis of
the fibering maps associated with the energy functional. Additionally, we study
the asymptotic behavior of the weak solutions to the main problem as $\lambda
\to 0$ or $\mu \to +\infty$.

</details>


### [54] [Decay Properties of Invariant Measure and Application to Elliptic Homogenization of Non-divergence Form with an Interface](https://arxiv.org/abs/2507.15536)
*Pengxiu Yu,Yiping Zhang*

Main category: math.AP

TL;DR: The paper studies existence and decay of invariant measures in elliptic homogenization for non-divergence form PDEs with interface assumptions, offering an alternative proof to prior work and providing quantitative estimates.


<details>
  <summary>Details</summary>
Motivation: To explore invariant measures in elliptic homogenization, particularly for non-divergence form PDEs, and to extend or complement existing results.

Method: Self-contained PDE analysis with interface assumptions on coefficients, building on prior work by Hairer and Manson and leveraging analysis from another author.

Result: Existence and decay properties of invariant measures are established, with quantitative estimates derived for the homogenization problem.

Conclusion: The work provides insights into invariant measures in homogenization and offers quantitative results, contributing to the broader understanding of such problems.

Abstract: Using the self-contained PDE analysis, this paper investigates the existence
and the decay properties of the invariant measure in elliptic homogenization of
non-divergence form with an interface assumptions on the leading coefficient
$A$ and the drift $b$ for $b_1\equiv 0$, which partially provides an
alternative proof of the previous work by Hairer and Manson [Ann. Probab.
39(2011) 648-682]. Moreover, as a direct application after using the analysis
by the second author [Calc. Var. Partial Differ. Equ. 64(2025) No. 114], we
obtain the quantitative estimates for the homogenization problem.

</details>


### [55] [Stability of Gel'fand's inverse interior spectral problem for Schrödinger operators](https://arxiv.org/abs/2507.15560)
*Jinpeng Lu*

Main category: math.AP

TL;DR: The paper addresses Gel'fand's inverse interior spectral problem, proving that finite spectral data can approximate a Riemannian manifold and potential function with stability estimates.


<details>
  <summary>Details</summary>
Motivation: To solve the inverse problem of reconstructing a manifold and potential from partial spectral data, advancing understanding of Schrödinger operators.

Method: Uses eigenvalues and restricted eigenfunctions of the Schrödinger operator to approximate the manifold and potential, leveraging Gromov-Hausdorff topology.

Result: Finite spectral data yields a metric space close to the original manifold and a discrete function approximating the potential with uniform estimates.

Conclusion: The approach provides quantitative stability for the inverse interior spectral problem, applicable to general cases.

Abstract: We study Gel'fand's inverse interior spectral problem of determining a closed
Riemannian manifold $(M,g)$ and a potential function $q$ from the knowledge of
the eigenvalues $\lambda_j$ of the Schr\"odinger operator $-\Delta_g + q$ and
the restriction of the eigenfunctions $\phi_j|_U$ on a given open subset
$U\subset M$, where $\Delta_g$ is the Laplace-Beltrami operator on $(M,g)$. We
prove that an approximation of finitely many spectral data on $U$ determines a
finite metric space that is close to $(M,g)$ in the Gromov-Hausdorff topology,
and further determines a discrete function that approximates the potential $q$
with uniform estimates. This leads to a quantitative stability estimate for the
inverse interior spectral problem for Schr\"odinger operators in the general
case.

</details>


### [56] [Schauder estimates for parabolic $p$-Laplace systems](https://arxiv.org/abs/2507.15722)
*Verena Bögelein,Frank Duzaar,Ugo Gianazza,Naian Liao,Christoph Scheven*

Main category: math.AP

TL;DR: The paper establishes local Hölder regularity for the spatial gradient of solutions to a non-linear parabolic system and applies it to a doubly non-linear parabolic equation in the fast diffusion regime.


<details>
  <summary>Details</summary>
Motivation: To analyze the regularity of solutions to non-linear parabolic systems, particularly focusing on the spatial gradient's Hölder continuity, which is crucial for understanding solution behavior.

Method: The study considers bounded weak solutions to a non-linear parabolic system with specific conditions on the coefficient and parameters, using analytical techniques to derive regularity results.

Result: Local Hölder regularity of the spatial gradient is proven for the given system, and this result is extended to provide Hölder estimates for solutions in a doubly non-linear parabolic equation.

Conclusion: The findings contribute to the understanding of gradient regularity in non-linear parabolic systems, with applications to fast diffusion problems.

Abstract: We establish the local H\"older regularity of the spatial gradient of bounded
weak solutions $u\colon E_T\to\R^k$ to the non-linear system of parabolic type
\begin{equation*}
  \partial_tu-\Div\Big( a(x,t)\big(\mu^2+|Du|^2\big)^\frac{p-2}2Du\Big)=0
  \qquad\mbox{in $E_T$}, \end{equation*} where $p>1$, $\mu\in[0,1]$, and the
coefficient $a\in L^\infty(E_T)$ is bounded below by a positive constant and is
H\"older continuous in the space variable $x$. As an application, we prove
H\"older estimates for the gradient of weak solutions to a doubly non-linear
parabolic equation in the super-critical fast diffusion regime.

</details>


### [57] [Qualitative properties of solutions to parabolic anisotropic equations: Part II -- The anisotropic Trudinger's equation](https://arxiv.org/abs/2507.15730)
*Simone Ciani,Eurica Henriques,Mariia O. Savchenko,Igor I. Skrypnik*

Main category: math.AP

TL;DR: The paper studies weak solutions to anisotropic doubly nonlinear parabolic operators, proving a Harnack inequality and Hölder continuity for certain cases.


<details>
  <summary>Details</summary>
Motivation: To understand the regularity properties of weak solutions in anisotropic nonlinear parabolic equations, particularly the anisotropic Trudinger's equation.

Method: Analyzes local weak solutions, focusing on proving a parabolic Harnack inequality and Hölder continuity for specific diffusion exponents.

Result: Establishes a Harnack inequality without restrictions on exponent sparsity and proves Hölder continuity for a restricted range of exponents.

Conclusion: The findings advance the understanding of regularity in anisotropic nonlinear parabolic equations, with implications for broader applications.

Abstract: In this paper we study the local regularity properties of weak solutions to a
special class of anisotropic doubly nonlinear parabolic operators, whose
prototype is the anisotropic Trudinger's equation $$ u_t- \sum\limits_{i=1}^N
D_i\Big(u^{2-p_i}|D_i u|^{p_i-2} D_i u\Big)=0,\quad u\geqslant 0. $$ We prove a
parabolic Harnack inequality for nonnegative local weak solutions, without any
restrictions on the sparseness of the exponents $p_i$s. Moreover, for a
restricted range of diffusion exponents, we prove that solutions are H\"{o}lder
continuous.

</details>


### [58] [Superlinear gradient growth for 2D Euler equation without boundary](https://arxiv.org/abs/2507.15739)
*In-Jee Jeong,Yao Yao,Tao Zhou*

Main category: math.AP

TL;DR: The paper demonstrates superlinear growth of vorticity gradient in 2D Euler equations for open sets of smooth initial data in torus and plane, without symmetry assumptions.


<details>
  <summary>Details</summary>
Motivation: To explore vorticity gradient growth in 2D Euler equations, focusing on stable steady states with saddle points.

Method: Construct perturbations near stable steady states in torus and plane, using smooth initial data.

Result: Superlinear growth occurs for open sets of initial data in torus and compactly supported vorticity in plane.

Conclusion: First results showing superlinear growth for open sets of smooth data, advancing understanding of 2D Euler dynamics.

Abstract: We consider the vorticity gradient growth of solutions to the two-dimensional
Euler equations in domains without boundary, namely in the torus
$\mathbb{T}^{2}$ and the whole plane $\mathbb{R}^{2}$. In the torus, whenever
we have a steady state $\omega^*$ that is orbitally stable up to a translation
and has a saddle point, we construct ${\tilde{\omega}}_0 \in
C^\infty(\mathbb{T}^2)$ that is arbitrarily close to $\omega^*$ in $L^2$, such
that superlinear growth of the vorticity gradient occurs for an open set of
smooth initial data around ${\tilde{\omega}}_0$. This seems to be the first
superlinear growth result which holds for an open set of smooth initial data
(and does not require any symmetry assumptions on the initial vorticity).
Furthermore, we obtain the first superlinear growth result for smooth and
compactly supported vorticity in the plane, using perturbations of the
Lamb-Chaplygin dipole.

</details>


### [59] [Minimal horizontal triods: Analysis and computation](https://arxiv.org/abs/2507.15740)
*Robert Nürnberg,Paola Pozzi*

Main category: math.AP

TL;DR: The paper explores minimal-length network configurations (triods) in the Heisenberg group, proves their existence, characterizes them, and introduces a curve-shortening flow to find critical points. Numerical experiments offer insights into sub-Riemannian geometry.


<details>
  <summary>Details</summary>
Motivation: To understand and find minimal-length network configurations connecting three points in the Heisenberg group, a key problem in sub-Riemannian geometry.

Method: Proves existence of minimal horizontal triods, characterizes them, and formulates a horizontal curve-shortening flow. Uses a finite element scheme for numerical experiments.

Result: Existence of minimal triods is proven, and a curve-shortening flow is developed to find critical points. Numerical results reveal complex sub-Riemannian geometry.

Conclusion: The study advances understanding of minimal networks in the Heisenberg group, with numerical methods providing practical insights.

Abstract: In this article we investigate the question of finding a network
configuration of minimal length connecting three given points in the Heisenberg
group. After proving existence of (possibly degenerate) minimal horizontal
triods, we investigate their characterization. We then formulate a horizontal
curve shortening flow that deforms any given suitable initial triod into a
critical point for the length functional. Numerical experiments based on a
stable fully discrete finite element scheme provide useful insights into the
rich landscape of this sub-Riemannian geometry.

</details>


### [60] [Infinitely many non-radial solutions to a critical Choquard equation](https://arxiv.org/abs/2507.15747)
*Sabrina Caputo,Giusi Vaira*

Main category: math.AP

TL;DR: The paper studies critical Choquard equations with symmetric potentials, proving the existence of infinitely many non-radial solutions under specific conditions.


<details>
  <summary>Details</summary>
Motivation: To explore solutions for critical Choquard equations with symmetric potentials, particularly focusing on non-radial solutions.

Method: Finite dimensional reduction method applied to the equation with a bounded, nonnegative, symmetric potential.

Result: If the potential has a local maximum or minimum point, the problem admits infinitely many non-radial solutions with large energies.

Conclusion: The study confirms the existence of numerous non-radial solutions for the given equation under certain potential conditions.

Abstract: In this paper we study a class of critical Choquard equations with a
symmetric potential, i.e. we consider the equation $$-\Delta u +V(|x|) u
=\left(|x|^{-\mu}*
|u|^{2^\star_\mu}\right)|u|^{2^\star_\mu-2}u,\quad\mbox{in}\quad\mathbb R^N$$
where $V(|x|)$ is a bounded, nonnegative and symmetric potential in $\mathbb
R^N$ with $N\geq 5$, $0<\mu\leq 4$, $*$ stands for the standard convolution and
$2^\star_\mu:=\frac{2N-\mu}{N-2}$ is the upper critical exponent in the sense
of the Hardy - Littlewood - Sobolev inequality. By applying a finite
dimensional reduction method we prove that if $r^2V(r)$ has a local maximum
point or local minimum point $r_0>0$ with $V(r_0)>0$ then the problem has
infinitely many non-radial solutions with arbitrary large energies.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [61] [A Machine Learning Framework for Scattering Kernel Derivation Using Molecular Dynamics Data in Very Low Earth Orbit](https://arxiv.org/abs/2507.14143)
*Miklas Schütte,Stephen Hocker,Hansjörg Lipp,Johannes Roth,Stefanos Fasoulas,Marcel Pfeiffer*

Main category: physics.comp-ph

TL;DR: The paper proposes a high-precision gas-surface interaction (GSI) model using molecular dynamics (MD) and a conditional Variational Autoencoder (cVAE) to enhance Direct Simulation Monte Carlo (DSMC) accuracy for satellite aerodynamics.


<details>
  <summary>Details</summary>
Motivation: Current GSI models like the Maxwell model oversimplify interactions with constant accommodation coefficients, limiting accuracy in satellite aerodynamic modeling and atmospheric breathing propulsion design.

Method: MD simulations analyze velocity vector impacts on an amorphous Al₂O₃ surface. Scattering kernels from MD train a cVAE to predict kernels for any velocity vector, integrated into DSMC.

Result: The cVAE predicts shifts from diffuse to quasi-specular reflection with polar angle changes, showing significant differences in aerodynamic coefficients and molecular fluxes compared to the Maxwell model.

Conclusion: The cVAE-based GSI model improves DSMC accuracy, aiding satellite aerodynamics optimization, mission planning, and cost reduction.

Abstract: The free molecular flow regime in VLEO makes gas-surface interactions (GSIs)
crucial for satellite aerodynamic modeling. The Direct Simulation Monte Carlo
(DSMC) method is required to estimate aerodynamic forces due to the breakdown
of the continuum assumption. In DSMC, the Maxwell model is the most widely used
approach for GSI. It simplifies the process by treating it as a superposition
of diffuse and specular reflections while assuming a constant accommodation
coefficient. In reality, this coefficient is influenced by multiple factors,
such as the angle and magnitude of the incident velocity. A high-precision GSI
model could significantly improve satellite aerodynamics optimization and the
design of efficient intakes for atmospheric breathing propulsion systems. This
advancement would greatly refine mission planning and fuel requirement
calculations, ultimately extending operational lifetimes and lowering costs. To
gain a deep understanding of the GSI at the microscopic level, molecular
dynamics (MD) simulations provide valuable insights into the physical processes
involved. However, due to computational limitations, simulating an entire
satellite is impractical. Instead, we use MD to analyze the impact of selected
velocity vectors on a amorphous $\text{Al}_2\text{O}_3$ surface. The obtained
scattering kernels for the respective velocity vectors are then used to train a
conditional Variational Autoencoder (cVAE). This model is able to generate
scattering kernels for any incident velocity vector and can be integrated into
DSMC simulations, significantly enhancing their accuracy. Applications of this
model on a flat plate have shown that the cVAE is able to predict the shift
from diffuse to quasi-specular reflection with increasing polar angle.
Additionally, the aerodynamic coefficients and molecular fluxes are
considerably different from those obtained with the Maxwell model.

</details>


### [62] [MENO: Hybrid Matrix Exponential-based Neural Operator for Stiff ODEs. Application to Thermochemical Kinetics](https://arxiv.org/abs/2507.14341)
*Ivan Zanardi,Simone Venturi,Marco Panesi*

Main category: physics.comp-ph

TL;DR: MENO is a hybrid surrogate model for solving stiff ODEs with sparse nonlinearity, combining neural operators for nonlinear parts and a neural matrix exponential for linear parts, ensuring physical consistency and efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the inefficiency and lack of physical consistency in black-box or PI models for stiff ODE systems with sparse nonlinearity.

Method: Decomposes the system into nonlinear (neural operators) and linear (neural matrix exponential) parts, embedding governing equations for physical consistency.

Result: Achieves <2% error in 0D settings, good accuracy in extrapolatory regimes, and significant speedups (up to 4800x on GPU).

Conclusion: MENO offers scalable, efficient, and reliable real-time simulation for stiff reactive systems.

Abstract: We introduce MENO (''Matrix Exponential-based Neural Operator''), a hybrid
surrogate modeling framework for efficiently solving stiff systems of ordinary
differential equations (ODEs) that exhibit a sparse nonlinear structure. In
such systems, only a few variables contribute nonlinearly to the dynamics,
while the majority influence the equations linearly. MENO exploits this
property by decomposing the system into two components: the low-dimensional
nonlinear part is modeled using conventional neural operators, while the linear
time-varying subsystem is integrated using a novel neural matrix exponential
formulation. This approach combines the exact solution of linear time-invariant
systems with learnable, time-dependent graph-based corrections applied to the
linear operators. Unlike black-box or soft-constrained physics-informed (PI)
models, MENO embeds the governing equations directly into its architecture,
ensuring physical consistency (e.g., steady states), improved robustness, and
more efficient training. We validate MENO on three complex thermochemical
systems: the POLLU atmospheric chemistry model, an oxygen mixture in
thermochemical nonequilibrium, and a collisional-radiative argon plasma in one-
and two-dimensional shock-tube simulations. MENO achieves relative errors below
2% in trained zero-dimensional settings and maintains good accuracy in
extrapolatory multidimensional regimes. It also delivers substantial
computational speedups, achieving up to 4 800$\times$ on GPU and 185$\times$ on
CPU compared to standard implicit ODE solvers. Although intrusive by design,
MENO's physics-based architecture enables superior generalization and
reliability, offering a scalable path for real-time simulation of stiff
reactive systems.

</details>


### [63] [Towards Quantum Accelerated Large-scale Topology Optimization](https://arxiv.org/abs/2507.14478)
*Zisheng Ye,Wenxiao Pan*

Main category: physics.comp-ph

TL;DR: A new method using modified Dantzig-Wolfe (MDW) decomposition efficiently solves large-scale 3D topology optimization (TO) problems, reducing computation time significantly and enabling quantum computing acceleration.


<details>
  <summary>Details</summary>
Motivation: Address the computational challenges of large-scale, multi-material TO problems beyond prior studies, leveraging quantum computing for potential speedups.

Method: Modified Dantzig-Wolfe (MDW) decomposition splits MILP into local and global sub-problems, with local BIP problems convertible to QUBO for quantum acceleration.

Result: Classical implementation matches state-of-the-art TO quality while drastically reducing runtime, even in extreme cases (e.g., 50M variables). Quantum-ready QUBO formulation scales linearly.

Conclusion: The method, combined with quantum computing, offers scalable solutions for real-world TO challenges, with growing advantages for larger and multi-material designs.

Abstract: We present a new method that efficiently solves TO problems and provides a
practical pathway to leverage quantum computing to exploit potential quantum
advantages. This work targets on large-scale, multi-material TO challenges for
three-dimensional (3D) continuum structures, beyond what have been addressed in
prior studies. Central to this new method is the modified Dantzig-Wolfe (MDW)
decomposition, which effectively mitigates the escalating computational cost
associated with using classical Mixed-Integer Linear Programming (MILP) solvers
to solve the master problems involved in TO, by decomposing the MILP into local
and global sub-problems. Evaluated on 3D bridge designs, our classical
implementation achieves comparable solution quality to state-of-the-art TO
methods while reducing computation time by orders of magnitude. It also
maintains low runtimes even in extreme cases where classical MILP solvers fail
to converge, such as designs involving over 50 million variables. The
computationally intensive local sub-problems, which are essentially Binary
Integer Programming (BIP) problems, can potentially be accelerated by quantum
computing via their equivalent Quadratic Unconstrained Binary Optimization
(QUBO) formulations. Enabled by the MDW decomposition, the resulting QUBO
formulation requires only sparse qubit connectivity and incurs a QUBO
construction cost that scales linearly with problem size, potentially
accelerating BIP sub-problem solutions by an additional order of magnitude. All
observed and estimated speedups become increasingly significant with larger
problem sizes and when moving from single-material to multi-material designs.
This suggests that this new method, along with quantum computing, will play an
increasingly valuable role in addressing the scale and complexity of real-world
TO applications.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [64] [Electromagnetic Flow Control in Hypersonic Rarefied Environment](https://arxiv.org/abs/2507.14628)
*Zhigang Pu,Kun Xu*

Main category: physics.plasm-ph

TL;DR: The UGKWP method is extended to unstructured meshes for multiscale plasma simulations, showing good agreement with reference and experimental data, highlighting the importance of rarefied effects in electromagnetic flow control.


<details>
  <summary>Details</summary>
Motivation: To address the need for multiscale modeling in partially ionized plasmas, especially for electromagnetic flows across varying regimes.

Method: Extends the UGKWP method to unstructured meshes, treating neutrals, ions, and electrons distinctly, with electrons modeled beyond fluid approximation.

Result: Validated against reference solutions and experimental data, showing good agreement and revealing significant rarefied effects in flow control.

Conclusion: Multiscale modeling is essential for accurate plasma flow applications, as demonstrated by the UGKWP method's success.

Abstract: The Unified Gas-Kinetic Wave-Particle (UGKWP) method, developed for
multiscale simulation of partially ionized plasmas, has been extended to
unstructured meshes, enabling the modeling of electromagnetic flows around a
hemisphere across near-continuum to rarefied regimes. To the best of our
knowledge, this work represents the first application of a multiscale plasma
solver to this problem. In our approach, neutrals, ions, and electrons are
treated as distinct species, with electrons modeled beyond the conventional
fluid approximation. The numerical implementation is validated through
comparison with reference solutions for neutral hypersonic flow around a
sphere, as well as benchmarking against experimental data for a Mach 4.75
pre-ionized argon flow. In both cases, the UGKWP results show good agreement
with the reference and experimental data. The findings reveal that rarefied
effects play a significant role in the prediction of electromagnetic flow
control, underscoring the necessity of multiscale modeling in plasma flow
applications.

</details>


### [65] [Effects of turbulence spreading and symmetry breaking on edge shear flow during sawtooth cycles in J-TEXT tokamak](https://arxiv.org/abs/2507.15201)
*Xiaoguan Ding,Kaijun Zhao,Yaoyu Xie,Zhipeng Chen,Zhongyong Chen,Zhoujun Yang,Li Gao,Yonghua Ding,Siyu Wen,Yingxin Hu*

Main category: physics.plasm-ph

TL;DR: Sawtooth oscillations trigger heat and turbulence pulses, enhancing edge shear flow and transitioning plasma to high confinement mode. Turbulence spreading and symmetry breaking drive Reynolds stress, boosting shear flows post-sawtooth crashes.


<details>
  <summary>Details</summary>
Motivation: To understand how sawtooth oscillations influence edge plasma turbulence and shear flow, and how turbulence spreading and symmetry breaking contribute to confinement transitions.

Method: Measurements of edge plasma turbulence and shear flow using a fast reciprocating electrostatic probe array in the J-TEXT tokamak, analyzing heat and turbulence pulses post-sawtooth crashes.

Result: Post-sawtooth crashes, turbulence pulses precede heat pulses, enhancing edge turbulence and shear flow. Turbulence spreading and symmetry breaking increase Reynolds stress, driving faster shear flows than temperature changes.

Conclusion: Turbulence spreading and symmetry breaking are key mechanisms for enhancing Reynolds stress and shear flows, facilitating transitions to high confinement mode after sawtooth crashes.

Abstract: Sawtooth oscillations can trigger off heat and turbulence pulses that
propagate into the edge plasma, and thus enhancing the edge shear flow and
inducing a transition from low confinement mode to high confinement mode. The
influences of turbulence spreading and symmetry breaking on edge shear flow
with sawtooth crashes are observed in the J-TEXT tokamak. The edge plasma
turbulence and shear flow are measured using a fast reciprocating electrostatic
probe array. After sawtooth crashes, the heat and turbulence pulses in the core
propagate to the edge, with the turbulence pulse being faster than the heat
pulse. After sawtooth crashes, the edge electron temperature increases and the
edge turbulence is enhanced, with turbulence preceding temperature. The
enhanced edge turbulence is mainly composed of two parts: the turbulence driven
by local gradient and the turbulence spreading from core to edge. The
development of the estimated turbulence spreading rate is prior to that of the
turbulence driving rate. The increase in the turbulence intensity can cause the
turbulent Reynold stress and its gradient to increase, thereby enhancing shear
flows and radial electric fields. Turbulence spreading leads the edge Reynolds
stresses to develop and the shear flow to be faster than edge electron
temperature. The Reynolds stress arises from the symmetry breaking of the
turbulence wave number spectrum. After sawtooth collapses, the joint
probability density function of radial wave number and poloidal wave number of
turbulence intensity exhibits strong asymmetry. These results show that the
turbulence spreading and symmetry breaking can enhance turbulent Reynolds
stress, thereby driving shear flows, after sawtooth has crashed.

</details>


### [66] [Investigations of the kinetic ion-acoustic soliton by the Bernstein-Greene-Kruskal integral method](https://arxiv.org/abs/2507.15207)
*Ran Guo*

Main category: physics.plasm-ph

TL;DR: The paper investigates solitary waves using the Bernstein-Greene-Kruskal method, analyzing trapped electron distributions for single and counter-propagating ion streams. It distinguishes between electron holes and humps, identifies soliton boundaries, and validates stability via Vlasov simulations.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of solitary waves and trapped electron distributions in plasma, particularly how ion responses and electron distributions influence phase-space structures.

Method: Uses the Bernstein-Greene-Kruskal integral method with ion response, analyzing single-stream (waterbag) and counter-propagating (Maxwellian) ion cases. Derives trapped electron distributions and conducts Vlasov simulations.

Result: Trapped electron distributions vary (hole or hump) based on passing electrons, potential, and ion response. Boundaries between solitons and holes are identified. Potential amplitude, width, and mass ratio affect separatrices. Simulations confirm soliton stability.

Conclusion: The study provides insights into solitary wave dynamics, distinguishing electron holes from humps and validating the stability of ion-acoustic solitons.

Abstract: The solitary waves are investigated through the Bernstein-Greene-Kruskal
integral method with the ion response. We consider two specific cases of ions,
i.e., the single stream with the waterbag distribution and the two
counter-propagating streams with the Maxwellian distribution. The trapped
electron distributions are derived for both two cases. The results show that
the trapped electron distribution can be either a hole or a hump in the phase
space, depending on the competition between the contributions from the passing
electron distribution, the potential profile, and the ion response. We obtain
the boundary between the ion-acoustic soliton and the electron hole in the
parameter space. The effects of the potential amplitude, width, and the
ion-to-electron mass ratio on the separatrices are discussed. The Vlasov
simulations are conducted to verify the stability of the ion-acoustic soliton
constructed by the integral method.

</details>


### [67] [Effect of radial pressure corrugations and profile shearing on turbulence in Fusion plasmas](https://arxiv.org/abs/2507.15513)
*Ajay C. J,M. J. Pueschel,Justin Ball,David Hatch,Tobias Goerler,Stephan Brunner*

Main category: physics.plasm-ph

TL;DR: Microturbulence causes fine-scale radial corrugations in plasma density and temperature gradients, regulating turbulent transport. ETG modes split into three eigenvalues with varying stability, but nonlinear simulations show reduced fluxes due to profile shearing.


<details>
  <summary>Details</summary>
Motivation: To understand how microturbulence-induced corrugations affect turbulent transport in fusion plasmas, particularly in the pedestal region.

Method: Derived a linear dispersion relation for ETG modes in a shearless slab case and conducted nonlinear gyrokinetic simulations with corrugated backgrounds.

Result: ETG modes split into three eigenvalues, but nonlinear simulations show reduced transport due to profile shearing from corrugations.

Conclusion: Fine-scale corrugations can regulate turbulence by profile shearing, a mechanism potentially applicable beyond fusion plasmas.

Abstract: Microturbulence can produce stationary fine-scale radial corrugations on the
plasma density and temperature gradients in magnetic confinement fusion
devices. We show that these structures play a significant role in regulating
turbulent transport. We focus on the pedestal, studying
electron-temperature-gradient (ETG) mode destabilisation and saturation in the
presence of radial corrugations on the electron temperature gradient that could
result from microtearing turbulence. A linear dispersion relation is derived
for a shearless slab case, which indicates that in the presence of a sinusoidal
background corrugation, each ETG mode splits into three distinct eigenvalues,
with one being the original, one being more unstable and one being less
unstable. However, despite the presence of more unstable linear modes,
nonlinear gyrokinetic simulations of ETG with corrugated background electron
temperature show a reduction of fluxes. Our investigation reveals a radial
variation of the phase velocity of the modes that is proportional to the
diamagnetic drift velocity and the local pressure gradient. The associated
profile shearing breaks the turbulent eddies apart, reducing the transport
level. This profile shearing resulting from fine-scale pressure corrugations
could be a ubiquitous turbulence saturation mechanism not just in Fusion
plasmas, but in Astrophysics and other areas.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [68] [A universal augmentation framework for long-range electrostatics in machine learning interatomic potentials](https://arxiv.org/abs/2507.14302)
*Dongjin Kim,Xiaoyu Wang,Peichen Zhong,Daniel S. King,Theo Jaffrelot Inizan,Bingqing Cheng*

Main category: physics.chem-ph

TL;DR: The paper introduces the Latent Ewald Summation (LES) method, a standalone library for MLIPs that incorporates long-range electrostatics, improving accuracy and compatibility with existing methods.


<details>
  <summary>Details</summary>
Motivation: Current MLIPs lack explicit long-range electrostatic treatment, limiting their accuracy and applicability. LES addresses this gap.

Method: LES infers electrostatic interactions, polarization, and BECs from energy and force data, integrating with short-range MLIPs like MACE, NequIP, CACE, and CHGNet.

Result: LES-enhanced models show improved accuracy in systems like bulk water and polar dipeptides. MACELES-OFF, trained on SPICE, outperforms its short-range counterpart.

Conclusion: LES enables efficient long-range electrostatics without direct training on electrical properties, advancing the development of electrostatic foundation MLIPs.

Abstract: Most current machine learning interatomic potentials (MLIPs) rely on
short-range approximations, without explicit treatment of long-range
electrostatics. To address this, we recently developed the Latent Ewald
Summation (LES) method, which infers electrostatic interactions, polarization,
and Born effective charges (BECs), just by learning from energy and force
training data. Here, we present LES as a standalone library, compatible with
any short-range MLIP, and demonstrate its integration with methods such as
MACE, NequIP, CACE, and CHGNet. We benchmark LES-enhanced models on distinct
systems, including bulk water, polar dipeptides, and gold dimer adsorption on
defective substrates, and show that LES not only captures correct
electrostatics but also improves accuracy. Additionally, we scale LES to large
and chemically diverse data by training MACELES-OFF on the SPICE set containing
molecules and clusters, making a universal MLIP with electrostatics for organic
systems including biomolecules. MACELES-OFF is more accurate than its
short-range counterpart (MACE-OFF) trained on the same dataset, predicts
dipoles and BECs reliably, and has better descriptions of bulk liquids. By
enabling efficient long-range electrostatics without directly training on
electrical properties, LES paves the way for electrostatic foundation MLIPs.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [69] [Causal Fermion Systems: An Introduction to Fundamental Structures, Methods and Applications](https://arxiv.org/abs/2411.06450)
*Felix Finster,Sebastian Kindermann,Jan-Hendrik Treude*

Main category: math-ph

TL;DR: The textbook introduces causal fermion systems, a unified theory for quantum mechanics, general relativity, and quantum field theory, with a focus on non-smooth and quantum geometries.


<details>
  <summary>Details</summary>
Motivation: To provide a unified framework for fundamental physics and explore non-smooth geometries using causal fermion systems.

Method: Uses the causal action principle as a variational method to describe dynamics, with detailed mathematical and physical preliminaries.

Result: The theory unifies quantum mechanics, general relativity, and quantum field theory, offering a new perspective on quantum geometries.

Conclusion: The textbook serves as a comprehensive resource for students and researchers, bridging mathematics and physics in the study of causal fermion systems.

Abstract: This textbook introduces the basic concepts of the theory of causal fermion
systems, a recent approach to the description of fundamental physics. The
theory yields quantum mechanics, general relativity and quantum field theory as
limiting cases and is therefore a candidate for a unified physical theory. From
the mathematical perspective, causal fermion systems provide a general
framework for describing and analyzing non-smooth geometries and "quantum
geometries." The dynamics is described by a novel variational principle, the
causal action principle.
  The book includes a detailed summary of the mathematical and physical
preliminaries. It explains the physical concepts behind the causal fermion
system approach from the basics. Moreover, all the mathematical objects and
structures are introduced step by step. The mathematical methods used for the
analysis of causal fermion systems and the causal action principle are
introduced in depth. Many examples and applications are worked out.
  The textbook is addressed to master and graduate students in mathematics or
physics. Furthermore, it serves as a reference work for researchers working in
the field.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [70] [Advancing Lunar Communication through Inter-domain Space Networks and Dynamic Orchestration](https://arxiv.org/abs/2507.15483)
*Selen Gecgel Cetin,Baris Donmez,Gunes Karabulut Kurt*

Main category: cs.ET

TL;DR: Proposes inter-domain space network cooperation using near space networks for resilient lunar communication, addressing challenges of direct-to-Earth links.


<details>
  <summary>Details</summary>
Motivation: Address the limitations of conventional lunar communication, which relies on oversubscribed deep space networks and faces visibility and environmental challenges.

Method: Introduces near space networks, a unified link analysis framework, outage risk assessment, and an inter-domain space digital twin for dynamic decision-making.

Result: A resilient, multi-layered communication backbone for lunar exploration, ensuring high reliability and optimized power consumption.

Conclusion: Highlights the need for advanced lunar communication infrastructure to support sustained human and economic presence on the Moon.

Abstract: The reawakened era of lunar exploration is defined by a strategic shift from
temporary visits to a sustained international and commercial presence,
resulting in an unprecedented demand for a robust and continuously available
communication infrastructure. The conventional direct-to-Earth communication
architecture relies on limited and oversubscribed deep space networks, which
are further challenged by the radiative environment and insufficient visibility
in certain areas of the cislunar domain. We address these issues by proposing a
foundational move toward inter-domain space network cooperation by introducing
architectures based on near space networks. They can directly service lunar
surface users or, via cislunar relays, by forming a resilient and multi-layered
communication backbone. First, we establish a unified link analysis framework
incorporating frequently disregarded environmental factors, such as the Moon's
variable illumination, to provide a high-fidelity performance evaluation.
Second, we assess architectures' reliability based on the outage risk,
essential for quantifying the operational robustness of communication links.
Finally, to manage the inherent dynamism of architectures, we propose an
inter-domain space digital twin$-$a dynamic decision-making engine that
performs real-time analysis to autonomously select the best communication path,
ensuring high and stable reliability while simultaneously optimizing power
consumption. Overall, our paper provides a holistic architectural and
conceptual management framework, emphasizing the necessity of lunar
communications to support a permanent human and economic foothold on the Moon.

</details>


<div id='math.RA'></div>

# math.RA [[Back]](#toc)

### [71] [Generic cuspidal points and their localization](https://arxiv.org/abs/2507.15762)
*Luca Dieci,Alessandro Pugliese*

Main category: math.RA

TL;DR: The paper studies generic coalescing of eigenvalues in 2-parameter complex matrix functions, focusing on cuspidal points and their relation to exceptional points. It analyzes phase accumulation in eigenvectors and eigenvalue periodicity to localize cuspidal points.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of eigenvalues and eigenvectors near cuspidal points in 2-parameter matrix functions and their connection to exceptional points.

Method: Examines loops in parameter space enclosing cuspidal points, analyzing phase accumulation of eigenvectors and eigenvalue periodicity.

Result: Rigorously proves conditions for phase accumulation and demonstrates how eigenvalue periodicity and phase accumulation can localize cuspidal points.

Conclusion: The study provides insights into eigenvalue coalescence and offers tools to identify cuspidal points through eigenvector and eigenvalue analysis.

Abstract: In this work we consider generic coalescing of eigenvalues of smooth complex
valued matrix functions depending on 2 parameters. We call generic cuspidal
points the parameter values where eigenvalues coalesce and we discuss the
relation between cuspidal points and the closely related exceptional points
studied in the literature. By considering loops in parameter space enclosing
the cuspidal points, we rigorously prove when there is a phase accumulation for
the eigenvectors and further detail how, by looking at the periodicity of the
eigenvalues along the loop, and/or by looking at the aforementioned phase
accumulation, one may be able to localize generic cuspidal points.

</details>


<div id='math.CV'></div>

# math.CV [[Back]](#toc)

### [72] [Bicomplex Schwarz and Dirichlet Boundary Value Problems](https://arxiv.org/abs/2507.15653)
*William L. Blair*

Main category: math.CV

TL;DR: The paper solves boundary value problems (Schwarz and Dirichlet types) for bicomplex-valued functions on the complex unit disk.


<details>
  <summary>Details</summary>
Motivation: To extend classical boundary value problems to bicomplex-valued functions, exploring their properties and solutions.

Method: Defines and solves Schwarz and Dirichlet boundary value problems for bicomplex functions on the unit disk.

Result: Solutions to the boundary value problems for bicomplex-valued functions are derived.

Conclusion: The study successfully extends classical boundary value problems to bicomplex functions, providing theoretical solutions.

Abstract: We define and solve boundary value problems of Schwarz and Dirichlet type on
the complex unit disk for bicomplex-valued functions.

</details>


### [73] [Bicomplex Hardy Classes of Solutions to Beltrami Equations and the Schwarz Boundary Value Problem](https://arxiv.org/abs/2507.15657)
*William L. Blair*

Main category: math.CV

TL;DR: The paper extends Hardy classes to bicomplex-valued functions, solving bicomplex Beltrami equations and showing boundary behavior akin to classic holomorphic Hardy spaces. It also solves Schwarz and Dirichlet problems.


<details>
  <summary>Details</summary>
Motivation: To generalize known results for complex-valued functions to bicomplex-valued functions and explore their boundary behavior and solvability of related equations.

Method: Defines bicomplex Hardy classes, uses representations via complex-valued counterparts, and analyzes boundary behavior and solvability of Schwarz and Dirichlet problems.

Result: Bicomplex-valued functions retain boundary behavior of classic Hardy spaces, and solutions to Schwarz and Dirichlet problems are provided.

Conclusion: The work successfully generalizes complex results to bicomplex settings, offering new insights and solution formulas for boundary value problems.

Abstract: We define Hardy classes of bicomplex-valued functions on the complex unit
disk which solve bicomplex versions of the Beltrami and related equations.
Using representations in terms of their complex-valued counterparts, we show
these bicomplex-valued functions recover the boundary behavior associated with
the classic holomorphic Hardy spaces. This work generalizes known results for
complex-valued functions and continues recent work in the setting of bicomplex
analogues of Hardy spaces of both holomorphic and generalized analytic
functions. Also, we show Schwarz and Dirichlet boundary value problems
associated with the bicomplex Beltrami equation are solvable and provide
solution formulas.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [74] [Nonmonotonic consensus transitions in bounded-confidence dynamics on unbiased networks](https://arxiv.org/abs/2507.14276)
*Paolo Molignini*

Main category: physics.soc-ph

TL;DR: The paper explores the Hegselmann-Krause opinion dynamics model on sparse networks, revealing how connectivity and confidence levels shape collective behavior, including nonmonotonic transitions and consensus suppression.


<details>
  <summary>Details</summary>
Motivation: To understand how network structure and confidence bounds influence opinion dynamics and consensus formation in sparse, unbiased networks.

Method: Systematic exploration of the parameter space (confidence level and mean degree density) using Wilson's algorithm to generate networks, constructing phase diagrams for steady states.

Result: Nonmonotonic transitions where higher connectivity can suppress consensus, structural isolation prevents unanimity at low connectivity, and convergence times show distinct slowdowns. Critical confidence stabilizes near 0.2 for large systems.

Conclusion: Network topology and opinion dynamics are deeply intertwined, with increased connectivity sometimes hindering consensus, offering new insights into collective behavior.

Abstract: We study the Hegselmann-Krause model of opinion dynamics on sparse, unbiased
networks generated via Wilson's algorithm, unveiling how network connectivity
and confidence bounds jointly determine collective behavior. By systematically
exploring the parameter space spanned by the confidence level $\epsilon$ and
the mean degree density $\mu$, we construct comprehensive phase diagrams that
classify the emergent steady states into different degrees of fragmentation and
consensus. We uncover a nonmonotonic re-entrant transition where increased
connectivity can paradoxically suppress consensus, and show that full unanimity
is unattainable at low connectivity due to structural isolation. Convergence
times exhibit two distinct slowdowns: a finite-size, connectivity-dependent
resonance near $\epsilon \sim 1/N$, and a critical peak associated with the
established fragmentation-to-consensus transition. While the critical
confidence threshold $\epsilon_c$ stabilizes near 0.2 for large system sizes,
finite-size effects and sparse connectivity significantly alter the dynamics
and phase boundaries in smaller populations. Our results offer new insights
into the interplay between network topology and opinion dynamics, and highlight
conditions under which increased connectivity may hinder, rather than promote,
consensus.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [75] [Gravitational instantons and harmonic maps](https://arxiv.org/abs/2507.15284)
*Mingyang Li,Song Sun*

Main category: math.DG

TL;DR: The paper explores the relationship between toric Ricci-flat metrics in 4D and axisymmetric harmonic maps, leading to new Ricci-flat 4-manifolds and PDE classification results.


<details>
  <summary>Details</summary>
Motivation: To understand the interaction between toric Ricci-flat metrics and harmonic maps, and to construct new Ricci-flat manifolds with specific properties.

Method: Non-perturbative approach to avoid conical singularities from harmonic maps; uses Gibbons-Hawking and LeBrun-Tod ansatzes for PDE classification.

Result: Constructed non-spin, simply-connected Ricci-flat 4-manifolds with arbitrary second Betti number; classified axisymmetric harmonic maps of degree ≤1.

Conclusion: The work provides new insights into Ricci-flat metrics and harmonic maps, with applications to gravitational instantons and black hole uniqueness.

Abstract: We study the interaction between toric Ricci-flat metrics in dimension 4 and
axisymmetric harmonic maps from the 3-dimensional Euclidean space into the
hyperbolic plane. Applications include
  (1). The construction of complete Ricci-flat 4-manifolds that are non-spin,
simply-connected, and with arbitrary second Betti number. Our method is
non-perturbative and is based on ruling out conical singularities arising from
axisymmetric harmonic maps. These metrics also give systematic counterexamples
to various versions of the Riemannian black hole uniqueness conjecture.
  (2). A PDE classification result for axisymmetric harmonic maps of degree at
most 1, via the Gibbons-Hawking ansatz and the LeBrun-Tod ansatz, in terms of
axisymmetric harmonic functions. This is motivated by the study of hyperkahler
and conformally Kahler gravitational instantons.

</details>


### [76] [Analysis on fibred cusp spaces](https://arxiv.org/abs/2507.15467)
*Daniel Grieser,Álvaro Sánchez-Hernández,Boris Vertman*

Main category: math.DG

TL;DR: Survey of analytic and geometric results on fibred cusp spaces, covering spectral geometry, analytic torsion, index theory, and boundary value problems.


<details>
  <summary>Details</summary>
Motivation: To compile and present key findings and methodologies in the study of fibred cusp spaces, focusing on their spectral and geometric properties.

Method: Microlocal analysis of the resolvent and heat kernel, along with exposition of foundational geometric and analytic concepts.

Result: Comprehensive insights into spectral geometry and related topics, with proofs of main theorems outlined.

Conclusion: The survey consolidates significant results and tools for understanding fibred cusp spaces, aiding further research in the field.

Abstract: We give a survey of a number of analytic and geometric results on `fibred
cusp spaces'. These results cover topics in spectral geometry, in particular
analytic torsion and index theory, and boundary value problems. The underlying
tools include a careful microlocal analysis of the resolvent and the heat
kernel. We include an exposition of the geometric and analytic foundations and
sketch the ideas of the proofs of the main theorems.

</details>


### [77] [A Nash-Kuiper theorem for isometric immersions in a high codimension](https://arxiv.org/abs/2507.15808)
*Zhiwen Zhao*

Main category: math.DG

TL;DR: The paper improves the Hölder regularity of isometric immersions of Riemannian manifolds in high codimensions, achieving better results for odd and even dimensions, and provides explicit C¹ estimates.


<details>
  <summary>Details</summary>
Motivation: To enhance the understanding and construction of isometric immersions by improving their regularity and providing quantitative estimates.

Method: The study focuses on refining the Hölder regularity of isometric immersions, distinguishing between odd and even dimensions, and deriving explicit C¹ estimates.

Result: Improved regularity: C¹,θ for θ∈(0,1/n) in odd dimensions and θ∈(0,1/(n+1)) in even dimensions. Explicit C¹ estimates show dependence on initial metric error.

Conclusion: The paper advances the theory of isometric immersions by achieving higher regularity and providing quantitative insights into the relationship between initial errors and the resulting maps.

Abstract: This paper is devoted to investigating the isometric immersion problem of
Riemannian manifolds in a high codimension. It has recently been demonstrated
that any short immersion from an $n$-dimensional smooth compact manifold into
$2n$-dimensional Euclidean space can be uniformly approximated by
$C^{1,\theta}$ isometric immersions with any $\theta\in(0,1/(n+2))$ in
dimensions $n\geq3$. In this paper, we improve the H\"{o}lder regularity of the
constructed isometric immersions in the local setting, achieving $C^{1,\theta}$
for all $\theta\in(0,1/n)$ in odd dimensions and all $\theta\in(0,1/(n+1))$ in
even dimensions. Moreover, we also establish explicit $C^{1}$ estimates for the
isometric immersions, which indicate that the larger the initial metric error
is, the greater the $C^{1}$ norms of the resulting isometric maps become,
meaning that their slope become steeper.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [78] [Hypergraph modelling of wave scattering to speed-up material design](https://arxiv.org/abs/2507.15329)
*Kunwoo Park,Ikbeom Lee,Seungmok Youn,Gitae Lee,Namkyoo Park,Sunkyu Yu*

Main category: physics.optics

TL;DR: The paper introduces a hypergraph framework for modeling complex multiparticle interactions, enabling efficient material design with reduced computational complexity.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of traditional pairwise interaction models in describing complex systems, particularly in material design and multiparticle interactions.

Method: Develops a hypergraph model for wave-matter interactions, using hyperedges to describe multiparticle scattering events, and combines it with an evolutionary algorithm for material design.

Result: Achieves O(N1/2) time complexity and maintains accuracy, outperforming traditional O(N) methods, and integrates with existing techniques for further speed-up.

Conclusion: The hypergraph framework offers scalable and efficient material design, with potential for broader applications in large-scale multiparticle systems.

Abstract: Hypergraphs offer a generalized framework for understanding complex systems,
covering group interactions of different orders beyond traditional pairwise
interactions. This modelling allows for the simplified description of
simultaneous interactions among multiple elements in coupled oscillators, graph
neural networks, and entangled qubits. Here, we employ this generalized
framework to describe wave-matter interactions for material design
acceleration. By devising the set operations for multiparticle systems, we
develop the hypergraph model, which compactly describes wave interferences
among multiparticles in scattering events by hyperedges of different orders.
This compactness enables an evolutionary algorithm with O(N1/2) time complexity
and approximated accuracy for designing stealthy hyperuniform materials, which
is superior to traditional methods of O(N) scaling. By hybridizing our
hypergraph evolutions to the conventional collective-coordinate method, we
preserve the original accuracy, while achieving substantial speed-up in
approaching near the optimum. Our result paves the way toward scalable material
design and compact interpretations of large-scale multiparticle systems.

</details>


<div id='physics.acc-ph'></div>

# physics.acc-ph [[Back]](#toc)

### [79] [Reduced Order Hysteretic Flux Model for Transport Current Homogenization in Composite Superconductors](https://arxiv.org/abs/2507.15402)
*Alexander Glock,Julien Dular,Arjan Verweij,Mariusz Wozniak*

Main category: physics.acc-ph

TL;DR: The paper introduces the Reduced Order Hysteretic Flux (ROHF) model for simulating superconductors, enabling efficient computation of macroscopic quantities without detailed field solutions.


<details>
  <summary>Details</summary>
Motivation: To simplify the modeling of large-scale superconducting magnets by avoiding fine discretization and reducing computational effort.

Method: The ROHF model is parametrized using reference simulations and can be implemented as rate-independent or rate-dependent. It includes workflow steps like parameter identification and coupling with other fields.

Result: The model successfully computes macroscopic quantities (e.g., voltage, power loss) and is verified using a twisted multifilamentary strand.

Conclusion: ROHF provides an efficient and scalable approach for homogenizing transport current effects in superconducting magnets.

Abstract: In this paper, we present the Reduced Order Hysteretic Flux (ROHF) model to
describe the relationship between time-varying transport current and internal
magnetic flux for composite superconductors. The ROHF model is parametrized
using reference simulations of the conductor response, after which it enables
the computation of macroscopic quantities such as voltage and power loss
without requiring detailed electromagnetic field solutions. It is therefore
suitable for the homogenization of transport current effects in large-scale
superconducting magnets, avoiding a fine discretization of the composite strand
small scale structures, allowing to drastically reduce the computational
effort. The approximation can be implemented either (i) as a rate-independent
model, neglecting eddy current effects in the normal conducting matrix, or (ii)
as a rate-dependent model, including those eddy current effects. In this paper,
the complete modeling workflow, including parameter identification, coupling
with the other fields (temperature and magnetic field), and post-processing of
the results, is described and verified using a twisted multifilamentary strand
as an example.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [80] [Understanding Two-Layer Neural Networks with Smooth Activation Functions](https://arxiv.org/abs/2507.14177)
*Changcun Huang*

Main category: cs.LG

TL;DR: The paper analyzes training solutions of two-layer neural networks with smooth activation functions, revealing insights into the solution space and enriching approximation theory.


<details>
  <summary>Details</summary>
Motivation: To understand the training solutions of two-layer neural networks with smooth activation functions and demystify the 'black box' of their solution space.

Method: Uses four principles: Taylor series expansions, strict partial order of knots, smooth-spline implementation, and smooth-continuity restriction.

Result: Proves universal approximation for arbitrary input dimensionality and provides experimental verification.

Conclusion: The study reveals the solution space's structure and contributes new proofs to approximation theory.

Abstract: This paper aims to understand the training solution, which is obtained by the
back-propagation algorithm, of two-layer neural networks whose hidden layer is
composed of the units with smooth activation functions, including the usual
sigmoid type most commonly used before the advent of ReLUs. The mechanism
contains four main principles: construction of Taylor series expansions, strict
partial order of knots, smooth-spline implementation and smooth-continuity
restriction. The universal approximation for arbitrary input dimensionality is
proved and experimental verification is given, through which the mystery of
``black box'' of the solution space is largely revealed. The new proofs
employed also enrich approximation theory.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [81] [Existence of solutions for multivalued mckean-vlasov sdes with non-lipschitz coefficients](https://arxiv.org/abs/2507.14546)
*Lingyan Cheng,Caihong Gu,Wei Lu,Fengwu Zhu*

Main category: math.PR

TL;DR: The paper establishes the existence and uniqueness of strong solutions for multivalued McKean-Vlasov SDEs with Levy noise and non-Lipschitz coefficients, extends to weak solutions under linear growth, and proves martingale solutions.


<details>
  <summary>Details</summary>
Motivation: To address the well-posedness and solution types for multivalued McKean-Vlasov SDEs with Levy noise, extending beyond Lipschitz conditions.

Method: Analyzes strong solutions under non-Lipschitz conditions, weak solutions under linear growth, and martingale solutions.

Result: Existence and uniqueness of strong solutions, existence of weak solutions, and proof of martingale solutions.

Conclusion: The paper successfully extends solution theories for MMVSDEs with Levy noise, covering strong, weak, and martingale cases.

Abstract: In this paper, we first establish the existence and uniqueness of strong
solutions for multivalued McKean-Vlasov stochastic differential equations
(MMVSDEs) driven by Levy noise with non-Lipschitz coefficients. It is important
to note that these findings are based upon the well-posedness of strong
solutions for MMVSDEs under Lipschitz conditions, which will be stated briefly.
Secondly, we study the existence of weak solutions under linear growth
condition. Finally, we prove the existence of martingale solutions.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [82] [A "Faux-Shock" Method for Hybrid Simulations of Astrophysical Shocks](https://arxiv.org/abs/2507.14282)
*Emily R. Simon,Damiano Caprioli,Colby C. Haggerty,Brian Reville*

Main category: astro-ph.HE

TL;DR: A novel hybrid particle-in-cell simulation setup reduces computational cost while isolating shock precursor physics using a "faux-shock" boundary condition.


<details>
  <summary>Details</summary>
Motivation: To study shock precursor physics over long periods with lower computational cost than traditional methods.

Method: Uses a "faux-shock" boundary condition to mimic downstream scattering, allowing high-resolution simulations at reduced cost.

Result: Reproduces fluid quantities and phase spaces of traditional shock simulations, including 3D cases, efficiently.

Conclusion: The method reliably captures essential physics, making it a practical tool for future cosmic ray instability studies.

Abstract: We demonstrate a novel setup for hybrid particle-in-cell simulations designed
to isolate the physics of the shock precursor over long time periods for
significantly lower computational cost than previous methods. This is achieved
using a "faux-shock" or shock-like boundary condition on one edge of our
simulation domain such that particles that interact with the boundary either
pass through it or are reflected off of it with a change in momentum that
mimics scattering in the downstream. We show that our faux-shock setup
reproduces the same fluid quantities and phase spaces as traditional shock
simulations, including those which could otherwise only be done in 3D, with
higher particle resolution and for reduced computational cost. While the method
involves an assumed boundary condition, it nonetheless captures the essential
physics of interest, establishing it as a reliable and efficient tool for
future self-consistent studies of instabilities driven by cosmic rays in a
shock upstream medium.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [83] [Sensor network localization has a benign landscape after low-dimensional relaxation](https://arxiv.org/abs/2507.15662)
*Christopher Criscitiello,Andrew D. McRae,Quentin Rebjock,Nicolas Boumal*

Main category: math.OC

TL;DR: The paper explores the sensor network localization problem, showing it's nonconvex and may have spurious local minima. However, relaxing the problem to higher dimensions ensures all second-order critical points are global minimizers.


<details>
  <summary>Details</summary>
Motivation: To understand the challenges in recovering point configurations from pairwise distances and propose solutions to avoid spurious local minima.

Method: Analyzes the problem's nonconvexity, introduces a relaxation by optimizing in higher dimensions, and proves global optimality under specific conditions.

Result: Shows that relaxing to dimensions k > ℓ ensures all second-order critical points are global minimizers, with proofs for two settings.

Conclusion: Higher-dimensional relaxation effectively avoids spurious local minima, providing a robust solution for sensor network localization.

Abstract: We consider the sensor network localization problem, also known as
multidimensional scaling or Euclidean distance matrix completion. Given a
ground truth configuration of $n$ points in $\mathbb{R}^\ell$, we observe a
subset of the pairwise distances and aim to recover the underlying
configuration (up to rigid transformations). We show with a simple
counterexample that the associated optimization problem is nonconvex and may
admit spurious local minimizers, even when all distances are known. Yet,
inspired by numerical experiments, we argue that all second-order critical
points become global minimizers when the problem is relaxed by optimizing over
configurations in dimension $k > \ell$. Specifically, we show this for two
settings, both when all pairwise distances are known: (1) for arbitrary ground
truth points, and $k= O(\sqrt{\ell n})$, and: (2) for isotropic random ground
truth points, and $k = O(\ell + \log n)$. To prove these results, we identify
and exploit key properties of the linear map which sends inner products to
squared distances.

</details>


### [84] [Identifying Solution Constraints for ODE Systems](https://arxiv.org/abs/2507.15805)
*Nicolae Tarfulea*

Main category: math.OC

TL;DR: A framework for discovering sparse relations between components of solutions to first-order ODE systems using sparse identification techniques.


<details>
  <summary>Details</summary>
Motivation: To uncover hidden mathematical relationships between components of solutions to initial-value problems in ODE systems.

Method: Uses sparse identification techniques on numerical solution data, assuming sparse connections between components.

Result: Demonstrated effectiveness through application examples.

Conclusion: The framework successfully identifies sparse relations in ODE solutions, validated by examples.

Abstract: This work develops a framework to discover relations between the components
of the solution to a given initial-value problem for a first-order system of
ordinary differential equations. This is done by using sparse identification
techniques on the data represented by the numerical solution of the
initial-value problem at hand. The only assumption is that there are only a few
terms that connects the components, so that the mathematical relations to be
discovered are sparse in the set of possible functions. We illustrate the
method through examples of applications.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [85] [Spectral Surgery in a Heat Bath: a finite-temperature guide to particle production for phenomenologists](https://arxiv.org/abs/2507.14277)
*Nirmalya Brahma,Saniya Heeba,Hugo Schérer,Katelin Schutz*

Main category: hep-ph

TL;DR: A simplified framework for calculating particle production rates at finite temperature and density (FTD) is introduced, avoiding full thermal field theory. It links the imaginary part of a particle's self-energy to thermally weighted tree-level vacuum rates, revealing overlooked interference terms that regulate divergences and significantly impact production rates.


<details>
  <summary>Details</summary>
Motivation: Understanding particle properties under FTD conditions is crucial for phenomena within and beyond the Standard Model, but full thermal field theory calculations are complex. A simpler method is needed.

Method: The framework relates the imaginary part of a particle's $n$-loop finite temperature self-energy to a sum of thermally weighted tree-level vacuum rates, introducing interference terms.

Result: Interference terms, previously overlooked, regulate divergences and alter particle production by an $O(1)$ amount. Their impact is comparable to thermal mass corrections.

Conclusion: The simplified framework highlights the importance of interference terms in particle production at FTD, offering a practical alternative to complex thermal field theory calculations.

Abstract: Quantifying the effects of finite temperature and density (FTD) on particle
properties is essential for understanding phenomena within and beyond the
Standard Model. In this work, we present a simplified framework for calculating
particle production rates at FTD without resorting to a full thermal field
theory calculation. We do so by relating the imaginary part of a particle's
$n$-loop finite temperature self energy, which defines its in-medium damping
rate, to a sum of thermally weighted tree-level vacuum rates. Such a mapping
results in novel "interference" contributions to particle production which have
no vacuum analog and which have been relatively overlooked in the phenomenology
literature. These interference terms are known to regulate collinear and
infrared divergences that arise when calculating interaction rates in a medium.
We demonstrate the impact of these corrections with two toy models and find
that properly accounting for these interference terms can alter particle
production by an $O(1)$ amount. We additionally compare the size of these
corrections to the thermal mass corrections often studied in the literature,
finding the sizes of these contributions to be of similar order.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [86] [Martini 3 application for the design of bistable nanomachines](https://arxiv.org/abs/2507.14319)
*Alexander D. Muratov,Vladik A. Avetisov*

Main category: cond-mat.mes-hall

TL;DR: The paper discusses transitioning from all-atom molecular dynamics to a coarse-grained Martini model to study long-time behavior of foldamers resembling bistable machines.


<details>
  <summary>Details</summary>
Motivation: Time limitations of all-atom molecular dynamics hinder full-scale investigation of long-time behavior of foldamers.

Method: Development of a coarse-grained model using the Martini method.

Result: Not explicitly stated in the abstract, but the focus is on model development.

Conclusion: A coarse-grained Martini model is proposed to overcome the limitations of all-atom molecular dynamics for studying foldamers.

Abstract: During our previous modeling using all-atom molecular dynamics, we have
identified several foldamers whose nanoscale behavior resembles that of classic
bistable machines, namely the Euler archs and Duffing oscillators. However,
time limitations of the all-atom molecular dynamics prevent us from performing
a full-scale investigation of long-time behavior and prompt us to develop a
coarse-grained model. In this work, we summarize our recent research on
developing such models using the most widely available method called Martini.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [87] [Impact of Geant4's Electromagnetic Physics Constructors on Accuracy and Performance of Simulations for Rare Event Searches](https://arxiv.org/abs/2507.14788)
*H. Kluck,R. Breier,A. Fuß,V. Mokina,V. Palušová,P. Povinec*

Main category: astro-ph.IM

TL;DR: The paper evaluates the impact of Geant4 physics constructors on energy deposition in low-background physics experiments, focusing on CaWO4 and Ge targets, and assesses their computational performance.


<details>
  <summary>Details</summary>
Motivation: To improve background predictions in searches for rare phenomena beyond the Standard Model, such as Dark Matter or neutrinoless double beta decay, by optimizing Geant4 simulations.

Method: Quantifies the impact of different Geant4 physics constructors on total energy deposition for common radioactive contaminants (α, β, γ) and target thicknesses (thin, bulky), while also evaluating computing performance.

Result: Provides insights into how physics constructors affect energy deposition and computational efficiency, aiding in their selection for experiments.

Conclusion: The study aids in selecting appropriate Geant4 physics constructors for accurate and efficient simulations in low-background physics experiments.

Abstract: A primary objective in contemporary low background physics is the search for
rare and novel phenomena beyond the Standard Model of particle physics, e.g.
the scattering off of a potential Dark Matter particle or the neutrinoless
double beta decay. The success of such searches depends on a reliable
background prediction via Monte Carlo simulations. A widely used toolkit to
construct these simulations is Geant4, which offers the user a wide choice of
how to model the physics of particle interactions. For example, for
electromagnetic interactions, Geant4 provides pre-defined sets of models:
physics constructors. As decay products of radioactive contaminants contribute
to the background mainly via electromagnetic interactions, the physics
constructor used in a Geant4 simulation may have an impact on the total energy
deposition inside the detector target. To facilitate the selection of physics
constructors for simulations of experiments that are using CaWO$_\mathrm{4}$
and Ge targets, we quantify their impact on the total energy deposition for
several test cases. These cases consist of radioactive contaminants commonly
encountered, covering energy depositions via $\alpha$, $\beta$, and $\gamma$
particles, as well as two examples for the target thickness: thin and bulky. We
also consider the computing performance of the studied physics constructors.

</details>


### [88] [Wide Area Linear Optical Polarimeter Control Software](https://arxiv.org/abs/2507.15010)
*John A. Kypriotakis,Bhushan Joshi,Dmitry Blinov,Sebastian Kiehlmann,Ramya M. Anche,Ioannis Liodakis,Myrto Falalaki,Tuhin Ghosh,Eirik Gjerløw,Siddharth Maharana,Nikolaos Mandarakas,Georgia V. Panopoulou,Katerina Papadaki,Vasiliki Pavlidou,Timothy J. Pearson,Vincent Pelgrims,Stephen B. Potter,Chaitanya V. Rajarshi,A. N. Ramaprakash,Anthony C. S. Readhead,Raphael Skalidis,Konstantinos Tassis*

Main category: astro-ph.IM

TL;DR: WALOPControl software manages WALOP polarimeters, integrating hardware control, user interface, and automated observations for the PASIPHAE project.


<details>
  <summary>Details</summary>
Motivation: To enable safe and efficient control of WALOP polarimeters for studying Milky Way's dust and magnetic fields via starlight polarization.

Method: Developed with NodeJS/ExpressJS backend, React.JS frontend, RESTful API, MongoDB, and CI/CD pipeline for reliability.

Result: A robust system for real-time instrument control, data logging, and automated observations.

Conclusion: WALOPControl is essential for PASIPHAE, ensuring precise polarimetry and operational stability.

Abstract: The WALOPControl software is designed to facilitate comprehensive control and
operation of the WALOP (Wide Area Linear Optical Polarimeter) polarimeters,
ensuring safe and concurrent management of various instrument components and
functionalities. This software encompasses several critical requirements,
including control of the filter wheel, calibration half-wave plate, calibration
polarizer, guider positioning, focusers, and 4 concurrent CCD cameras. It also
manages the host telescope and dome operations while logging operational
parameters, user commands, and environmental conditions for troubleshooting and
stability. It provides a user-friendly graphical user interface, secure access
control, a notification system for errors, and a modular configuration for
troubleshooting are integral to the software's architecture. It is accessible
over the internet with the backend developed using NodeJS and ExpressJS,
featuring a RESTful API that interacts with a MongoDB database, facilitating
real-time status updates and data logging. The frontend utilizes the React.JS
framework, with Redux for state management and Material UI for the graphical
components. The system also allows for automatic observations based on
user-defined schedules. A Continuous Integration and Continuous Deployment (CI
CD) pipeline ensures the software's reliability through automated testing and
streamlined deployment. The WALOPControl software is a key component of the
PASIPHAE (Polar-Areas Stellar Imaging in Polarimetry High Accuracy Experiment)
project, which aims to study the dust and magnetic field of the Milky Way by
observing the polarization of starlight.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [89] [A Recursive Lie-Group Formulation for the Second-Order Time Derivatives of the Inverse Dynamics of parallel Kinematic Manipulators](https://arxiv.org/abs/2507.14274)
*Andreas Mueller,Shivesh Kumar,Thomas Kordik*

Main category: cs.RO

TL;DR: The paper addresses the lack of efficient methods for trajectory control of parallel kinematics manipulators (PKM) with series elastic actuators (SEA), introducing a novel approach using Lie group formulation and recursive algorithms.


<details>
  <summary>Details</summary>
Motivation: Trajectory control for PKMs with SEAs is unexplored, requiring efficient computation of the second time derivative of inverse dynamics, which this paper aims to solve.

Method: The paper leverages the topology of PKMs, reusing recursive algorithms from serial robots, and employs a Lie group formulation for deriving all relations.

Result: Numerical results are demonstrated for a 6-DOF Gough-Stewart platform and a planar PKM using a flatness-based control scheme.

Conclusion: The proposed method successfully addresses the computational challenge for PKMs with SEAs, validated through numerical examples.

Abstract: Series elastic actuators (SEA) were introduced for serial robotic arms. Their
model-based trajectory tracking control requires the second time derivatives of
the inverse dynamics solution, for which algorithms were proposed. Trajectory
control of parallel kinematics manipulators (PKM) equipped with SEAs has not
yet been pursued. Key element for this is the computationally efficient
evaluation of the second time derivative of the inverse dynamics solution. This
has not been presented in the literature, and is addressed in the present paper
for the first time. The special topology of PKM is exploited reusing the
recursive algorithms for evaluating the inverse dynamics of serial robots. A
Lie group formulation is used and all relations are derived within this
framework. Numerical results are presented for a 6-DOF Gough-Stewart platform
(as part of an exoskeleton), and for a planar PKM when a flatness-based control
scheme is applied.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [90] [Well-posed geometric boundary data in General Relativity, III: conformal-volume boundary data](https://arxiv.org/abs/2507.15567)
*Zhongshan An,Michael T. Anderson*

Main category: gr-qc

TL;DR: Proves local-in-time well-posedness of the IBVP for vacuum Einstein equations with twisted Dirichlet boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To establish the solvability of the initial boundary value problem (IBVP) for vacuum Einstein equations under specific boundary conditions, advancing understanding in general relativity.

Method: Uses twisted Dirichlet boundary conditions, specifying the conformal class of the boundary metric and a scalar density involving volume forms.

Result: Demonstrates local-in-time well-posedness for the IBVP under the given conditions.

Conclusion: The work successfully extends the understanding of boundary conditions in general relativity, confirming solvability for the specified setup.

Abstract: In this third work in a series, we prove the local-in-time well-posedness of
the IBVP for the vacuum Einstein equations in general relativity with twisted
DIrichlet boundary conditions on a finite timelike boundary. The boundary
conditions consist of specification of the pointwise conformal class of the
boundary metric, together with a scalar density involving a combination of the
volume form of the bulk metric restricted to the boundary together with the
volume form of the boundary metric itself.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [91] [Designing Two-Dimensional Octuple-Atomic-Layer M$_2$A$_2$Z$_4$ as Promising Photocatalysts for Overall Water Splitting](https://arxiv.org/abs/2507.14654)
*Dingyanyan Zhou,Yujin Ji,Mir F. Mousavi,Youyong Li*

Main category: cond-mat.mtrl-sci

TL;DR: The paper systematically designs and screens 108 M2A2Z4 monolayers for photocatalytic water splitting, identifying Al2Si2N4 and Al2Ge2N4 as promising candidates with enhanced activity under N vacancies.


<details>
  <summary>Details</summary>
Motivation: To explore 2D materials for efficient photocatalytic water splitting due to their tunable properties and large surface areas.

Method: First-principles calculations to evaluate stability, band gaps, and band edge alignments of 108 M2A2Z4 monolayers.

Result: Eight candidates, including Al2Si2N4 and Al2Ge2N4, meet criteria for water splitting; N vacancies enhance their catalytic activity.

Conclusion: The study provides theoretical insights for designing stable and efficient 2D photocatalysts for water splitting.

Abstract: Two-dimensional (2D) materials have emerged as promising candidates as
photocatalytic materials due to their large surface areas and tunable
electronic properties. In this work, we systematically design and screen a
series of octuple-atomic-layer M$_2$A$_2$Z$_4$ monolayers (M = Al, Ga, In; A =
Si, Ge, Sn; Z = N, P, As) using first-principles calculations. 108 structures
are constructed by intercalation approach, followed by a comprehensive
evaluation of their thermodynamic and dynamic stability, band gaps, and band
edge alignments to assess their potential for photocatalytic overall water
splitting. Among them, eight candidates meet the criteria for overall water
splitting under acidic condition (pH = 0), and Al$_2$Si$_2$N$_4$ and
Al$_2$Ge$_2$N$_4$, further exhibit suitable band edge positions for
photocatalysis under both acidic and neutral environments (pH = 0 and 7).
Al$_2$Si$_2$N$_4$ and Al$_2$Ge$_2$N$_4$ also show pronounced visible-light
absorption and structural stability in aqueous conditions. Importantly, the
introduction of N vacancies on the surfaces of Al$_2$Si$_2$N$_4$ and
Al$_2$Ge$_2$N$_4$ significantly enhances their catalytic activity for both
hydrogen reduction and water oxidation reactions, further supporting their
potential as photocatalysts for overall water splitting. Our study provides
theoretical insights for the rational design of efficient and stable 2D
photocatalysts for overall water splitting.

</details>


### [92] [Temperature Dependent Mechanical and Structural Properties of Uniaxially Strained Planar Graphene](https://arxiv.org/abs/2507.14709)
*Sané Erasmus,Charalampos Skokos,George Kalosakas*

Main category: cond-mat.mtrl-sci

TL;DR: The paper examines how temperature affects the mechanical properties of graphene under uniaxial stress, revealing linear decreases in fracture stress, strain, and Young's modulus with temperature.


<details>
  <summary>Details</summary>
Motivation: To understand the temperature-dependent mechanical behavior of graphene under tensile stress, which is crucial for its applications in nanotechnology.

Method: Molecular dynamics simulations of a planar graphene sheet under uniaxial tensile stress in armchair and zigzag directions, analyzing stress-strain curves and elastic parameters.

Result: Fracture stress, strain, and Young's modulus decrease linearly with temperature. Analytical expressions accurately describe bond length and angle distributions.

Conclusion: Temperature significantly impacts graphene's mechanical properties, with linear dependencies observed, and analytical models match simulation results well.

Abstract: Using molecular dynamics simulations in a planar graphene sheet, we
investigate the temperature dependence of its mechanical behavior under
uniaxial tensile stress applied either along the armchair or the zigzag
direction. Stress-strain curves are calculated for different temperatures and
the corresponding dependence of various elastic parameters, like the Young
modulus, the third-order elastic modulus, the tensile strength and failure
strain, is presented. Fracture stress and strain, as well as the Young modulus,
decrease almost linearly with temperature. The distributions of bond lengths
and bond angles at different strains and temperatures are also discussed and
approximate analytical expressions are presented. The latter describe
accurately the numerically obtained distributions.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [93] [Ground and excited-state energies with analytic errors and short time evolution on a quantum computer](https://arxiv.org/abs/2507.15148)
*Timothy Stroschein,Davide Castaldo,Markus Reiher*

Main category: quant-ph

TL;DR: The paper introduces a novel eigenvalue problem based on autocorrelation functions to solve the Schrödinger equation, avoiding wave functions. It proposes a hybrid classical-quantum algorithm (QPD) for precise energy estimation in molecular systems.


<details>
  <summary>Details</summary>
Motivation: Accurate solutions to the Schrödinger equation are critical in computational physics, chemistry, and materials science, but traditional methods are challenging. The paper aims to bypass wave functions for more efficient solutions.

Method: The method involves an eigenvalue problem using autocorrelation functions, leveraging prolate spheroidal wave functions for error bounds. It combines this with a quantum subroutine to create the QPD algorithm for energy estimation.

Result: The QPD algorithm achieves chemical accuracy in estimating ground and excited state energies at the Heisenberg limit, even with imperfect state preparation.

Conclusion: The framework is general and robust, offering precise spectral estimation and potential applications in quantum computation for molecular systems.

Abstract: Accurately solving the Schr\"odinger equation remains a central challenge in
computational physics, chemistry, and materials science. Here, we propose an
alternative eigenvalue problem based on a system's autocorrelation function,
avoiding direct reference to a wave function. In particular, we develop a
rigorous approximation framework that enables precise frequency estimation from
a finite number of signal samples. Our analysis builds on new results involving
prolate spheroidal wave functions and yields error bounds that reveal a sharp
accuracy transition governed by the observation time and spectral density of
the signal. These results are very general and thus carry far. As one important
example application we consider the quantum computation for molecular systems.
By combining our spectral method with a quantum subroutine for signal
generation, we define quantum prolate diagonalization (QPD) - a hybrid
classical-quantum algorithm. QPD simultaneously estimates ground and excited
state energies within chemical accuracy at the Heisenberg limit. An analysis of
different input states demonstrates the robustness of the method, showing that
high precision can be retained even under imperfect state preparation.

</details>
