{"id": "2507.16938", "pdf": "https://arxiv.org/pdf/2507.16938", "abs": "https://arxiv.org/abs/2507.16938", "authors": ["Davod Khojasteh Salkuyeh"], "title": "A parameterized block-splitting preconditioner for indefinite least squares problem", "categories": ["math.NA", "cs.NA", "65F10"], "comment": "13 pages, 1 Figure", "summary": "We present a stationary iteration based upon a block splitting for a class of\nindefinite least squares problem. Convergence of the proposed method is\ninvestigated and optimal value of the involving parameter is used. The induced\npreconditioner is applied to accelerate the convergence of the GMRES method for\nsolving the problem. We also analysed the eigenpair distribution of the\npreconditioned matrix. Some numerical are presented to show the effectiveness\nof the preconditioner. Numerical comparison with other well-known methods are\nalso presented.", "AI": {"tldr": "A block splitting-based stationary iteration method is proposed for indefinite least squares problems, with optimal parameter selection and preconditioning for GMRES acceleration, demonstrating effectiveness through numerical experiments.", "motivation": "To develop an efficient iterative method for solving indefinite least squares problems, which are challenging due to their indefinite nature and require specialized approaches for effective solution.", "method": "A stationary iteration method based on block splitting with optimal parameter selection, combined with a preconditioner applied to accelerate GMRES convergence. The approach includes theoretical analysis of convergence properties and eigenpair distribution of the preconditioned matrix.", "result": "The proposed preconditioner effectively accelerates GMRES convergence for indefinite least squares problems. Numerical experiments demonstrate the method's effectiveness and show favorable comparisons with other well-known methods.", "conclusion": "The block splitting-based stationary iteration with optimal parameter selection provides an effective preconditioning strategy for indefinite least squares problems, successfully accelerating GMRES convergence and outperforming existing methods in numerical comparisons."}}
{"id": "2507.16964", "pdf": "https://arxiv.org/pdf/2507.16964", "abs": "https://arxiv.org/abs/2507.16964", "authors": ["Luke Benfield", "Andreas Dedner"], "title": "DDFEM: A Python Package for Diffuse Domain Methods", "categories": ["math.NA", "cs.NA", "65-04, 65M60, 65M50"], "comment": null, "summary": "Solving partial differential equations (PDEs) on complex domains can present\nsignificant computational challenges. The Diffuse Domain Method (DDM) is an\nalternative that reformulates the partial differential equations on a larger,\nsimpler domain. The original geometry is embedded into the problem by\nrepresenting it with a phase-field function. This paper introduces ddfem, an\nextensible Python package to provide a framework for transforming PDEs into a\nDiffuse Domain formulation. We aim to make the application of a variety of\ndifferent Diffuse Domain approaches more accessible and straightforward to use.\nThe ddfem package includes features to intuitively define complex domains by\ncombining signed distance functions and provides a number of DDM transformers\nfor general second evolution equations. In addition, we present a new approach\nfor combining multiple boundary conditions of different types on distinct\nboundary segments. This is achieved by applying a normalised weighting, derived\nfrom multiple phase fields, to combine the additional boundary terms in the\nDiffuse Domain formulations. The domain definition and Diffuse Domain\ntransformation provided by our package are designed to be compatible with a\nwide range of existing finite element solvers without requiring code\nalterations. Both the original (non-linear) PDEs provided by the user and the\nresulting transformed PDEs on the extended domain are defined using the Unified\nForm Language UFL which is a domain specific language used by a number of\nsoftware packages. Our experiments were carried out using the Dune-Fem\nframework.", "AI": {"tldr": "This paper introduces ddfem, a Python package that implements the Diffuse Domain Method (DDM) to solve PDEs on complex domains by reformulating them on simpler domains using phase-field functions, making DDM more accessible to researchers.", "motivation": "Solving PDEs on complex geometries presents significant computational challenges. Traditional methods struggle with complex domain handling, so there's a need for more accessible tools that can transform complex domain problems into simpler formulations while maintaining accuracy.", "method": "The paper develops ddfem, a Python package that uses the Diffuse Domain Method to embed complex geometries into simpler domains via phase-field functions. The package combines signed distance functions for domain definition, provides DDM transformers for second-order evolution equations, and introduces a normalized weighting approach for handling multiple boundary conditions using multiple phase fields.", "result": "The ddfem package successfully provides an extensible framework for DDM transformations, offers intuitive complex domain definition through signed distance functions, handles multiple boundary condition types on distinct segments, and maintains compatibility with existing finite element solvers through UFL integration. Experiments were validated using the Dune-Fem framework.", "conclusion": "The ddfem package makes Diffuse Domain Methods more accessible and practical for solving PDEs on complex domains. By providing a user-friendly Python interface and compatibility with existing finite element frameworks, it enables broader adoption of DDM approaches in computational science applications."}}
{"id": "2507.17051", "pdf": "https://arxiv.org/pdf/2507.17051", "abs": "https://arxiv.org/abs/2507.17051", "authors": ["Syver D\u00f8ving Agdestein", "Roel Verstappen", "Benjamin Sanderse"], "title": "Exact closure for discrete large-eddy simulation", "categories": ["math.NA", "cs.NA"], "comment": "26 pages, 12 figures", "summary": "In this article we propose new discretization-consistent expressions for the\nsub-filter stress (SFS) tensor in discrete LES, where the filter is induced by\nthe discretization. We introduce a new two-grid filter that allows us to\nexactly compute the SFS tensor when DNS data is available. This new filter\nsatisfies a \"filter-swap\" property, such that filtering and finite differencing\ncan be interchanged and the resulting commutator expressions are of structural\nform (they can be written as the discrete divergence of an SFS tensor). For 1D\nconservation laws such as Burgers' equation, the resulting\ndiscretization-consistent SFS expression is markedly different from the\ncommonly used (discretization-inconsistent) expression $\\overline{u u} -\n\\bar{u} \\bar{u}$. For the 3D incompressible Navier-Stokes equations, we propose\nthree new two-grid filters, based on either volume- or surface-averaging, each\ninducing new discretization-consistent commutator expressions. We show that\nvolume-averaging is required to obtain a commutator expression of structural\nform. However, the resulting SFS tensor is shown to be non-symmetric. Based on\nDNS results, we show that the non-symmetric part of the SFS tensor plays an\nimportant role in the discrete LES equation. When the non-symmetric part is\nincluded, our SFS expressions give zero a-posteriori error in LES, while\nexisting SFS expressions give errors that increase over time. We propose to use\na class of non-symmetric tensor-basis closure models to approximate the new\nexact SFS expressions.", "AI": {"tldr": "This paper proposes new discretization-consistent expressions for the sub-filter stress (SFS) tensor in discrete Large Eddy Simulation (LES) using a novel two-grid filter approach that can exactly compute SFS when DNS data is available, showing that including non-symmetric components significantly improves accuracy compared to traditional methods.", "motivation": "Traditional sub-filter stress expressions in discrete LES are discretization-inconsistent, leading to accumulated errors over time. The commonly used expression $\\overline{u u} - \\bar{u} \\bar{u}$ does not properly account for the discrete nature of numerical schemes, creating a need for discretization-consistent approaches that better represent the physics in computational fluid dynamics simulations.", "method": "The authors introduce a new two-grid filter with a \"filter-swap\" property that allows filtering and finite differencing to be interchanged. They develop three different two-grid filters based on volume- or surface-averaging for 3D incompressible Navier-Stokes equations. The method enables exact computation of SFS tensors when DNS data is available and produces commutator expressions in structural form (discrete divergence of SFS tensor).", "result": "The new discretization-consistent SFS expressions are markedly different from traditional approaches, particularly for 1D Burgers' equation. Volume-averaging produces non-symmetric SFS tensors, but DNS results show the non-symmetric part plays an important role. When including the non-symmetric component, the new SFS expressions achieve zero a-posteriori error in LES, while existing methods show increasing errors over time.", "conclusion": "The paper demonstrates that discretization-consistent SFS expressions with non-symmetric components significantly outperform traditional symmetric approaches in LES accuracy. The authors propose using non-symmetric tensor-basis closure models to approximate the new exact SFS expressions, providing a foundation for more accurate turbulence modeling in computational fluid dynamics."}}
{"id": "2507.17053", "pdf": "https://arxiv.org/pdf/2507.17053", "abs": "https://arxiv.org/abs/2507.17053", "authors": ["Micha\u0142 Wichrowski"], "title": "Matrix-Free Evaluation of High-Order Shifted Boundary Finite Element Operators", "categories": ["math.NA", "cs.NA", "65N30, 65Y20, 65Y05, 68W10"], "comment": null, "summary": "This paper presents a matrix-free approach for implementing the shifted\nboundary method (SBM) in finite element analysis. The SBM is a versatile\ntechnique for solving partial differential equations on complex geometries by\nshifting boundary conditions to nearby surrogate boundaries. We focus on the\nefficient evaluation of shifted boundary operators using precomputed data and\ntensor-product structures. The proposed method avoids the explicit assembly of\nglobal matrices, achieving a computational complexity of $O(p^{2d-1})$ per face\nfor the evaluation of shifted boundary contributions on elements of polynomial\ndegree $p$ in $d$ dimensions. Numerical experiments validate the accuracy and\nefficiency of the approach, demonstrating its scalability and applicability to\nhigh-order finite element methods for both continuous and discontinuous\nGalerkin formulations. We compare the performance of the proposed method with a\nmatrix-free CutFEM implementation.", "AI": {"tldr": "This paper presents a matrix-free implementation of the shifted boundary method (SBM) for finite element analysis, achieving O(p^{2d-1}) computational complexity per face and demonstrating superior performance compared to matrix-free CutFEM.", "motivation": "The motivation is to develop an efficient computational approach for solving partial differential equations on complex geometries using the shifted boundary method, while avoiding the computational overhead of explicit global matrix assembly in finite element analysis.", "method": "The method employs a matrix-free approach that uses precomputed data and tensor-product structures to efficiently evaluate shifted boundary operators, avoiding explicit assembly of global matrices while maintaining the versatility of SBM for handling complex geometries.", "result": "The proposed method achieves computational complexity of O(p^{2d-1}) per face for evaluating shifted boundary contributions on elements of polynomial degree p in d dimensions, and numerical experiments validate its accuracy, efficiency, and scalability for both continuous and discontinuous Galerkin formulations.", "conclusion": "The matrix-free shifted boundary method implementation successfully provides an efficient and scalable solution for high-order finite element methods on complex geometries, outperforming matrix-free CutFEM implementations while maintaining computational accuracy."}}
{"id": "2507.16895", "pdf": "https://arxiv.org/pdf/2507.16895", "abs": "https://arxiv.org/abs/2507.16895", "authors": ["Joaquim Duran"], "title": "The $\\overline\\partial$-Robin Laplacian", "categories": ["math.AP", "35P05, 47A10"], "comment": "50 pages, 3 figures", "summary": "We study the family of operators $\\{\\mathcal{R}_a\\}_{a\\in [0,+\\infty)}$\nassociated to the Robin-type problems in a bounded domain\n$\\Omega\\subset\\mathbb{R}^2$ $$\n  \\begin{cases}\n  -\\Delta u = f & \\text{in } \\Omega, \\\\\n  2 \\bar \\nu \\partial_{\\bar z} u + au = 0 & \\text{on } \\partial\\Omega,\n  \\end{cases} $$ and their dependency on the boundary parameter $a$ as it moves\nalong $[0,+\\infty)$. In this regard, we study the convergence of such operators\nin a resolvent sense. We also describe the eigenvalues of such operators and\nshow some of their properties, both for all fixed $a$ and as functions of the\nparameter $a$. As shall be seen in more detail in a forthcoming paper, the\neigenvalues of these operators characterize the positive eigenvalues of quantum\ndot Dirac operators.", "AI": {"tldr": "This paper studies Robin-type operators with parameter-dependent boundary conditions in 2D bounded domains, analyzing their resolvent convergence and eigenvalue properties as the boundary parameter varies from 0 to infinity, with applications to quantum dot Dirac operators.", "motivation": "The motivation is to understand how Robin-type operators behave as their boundary parameter changes continuously, particularly to characterize eigenvalues that appear in quantum dot Dirac operators through this family of operators.", "method": "The authors study the family of operators {R_a} associated with Robin boundary value problems featuring the boundary condition 2\u03bd\u0304\u2202_z\u0304u + au = 0, analyzing their resolvent convergence properties and eigenvalue behavior as the parameter a varies over [0,+\u221e).", "result": "The paper establishes convergence results for the operators in resolvent sense and describes properties of their eigenvalues both for fixed parameter values and as functions of the varying parameter a.", "conclusion": "The eigenvalue analysis of these Robin-type operators provides a characterization of positive eigenvalues in quantum dot Dirac operators, establishing a connection between classical boundary value problems and quantum mechanical systems."}}
{"id": "2507.16949", "pdf": "https://arxiv.org/pdf/2507.16949", "abs": "https://arxiv.org/abs/2507.16949", "authors": ["Mojtaba Shirozhan", "Fabien Qu\u00e9r\u00e9", "Subhendu Kahaly"], "title": "Single attosecond XUV pulse source via light-wave controlled relativistic laser-plasma interaction: Thomson Back Scattering Scheme", "categories": ["physics.plasm-ph", "physics.app-ph", "physics.comp-ph", "physics.optics"], "comment": "12 pages, 4 figures", "summary": "Reflecting light off a mirror moving near light speed, as first envisioned by\nEinstein, offers a powerful method for generating bright, ultrashort pulses in\nthe extreme ultraviolet range. Recent breakthroughs show that dense\nrelativistic electron mirrors can be created by striking a nanometre-scale foil\nwith a high-intensity, sharp-front laser pulse, forming a single relativistic\nelectron sheet (RES). This RES coherently reflects and upshifts a\ncounter-propagating laser beam from the infrared to the extreme ultraviolet\nwith efficiency exceeding incoherent scattering by over several orders of\nmagnitude. Here we demonstrate that optimizing the drive laser waveform can\nreliably produce a single RES, leading to generation of isolated\n\\emph{attosecond} pulses enhancing both intensity and temporal compression of\nthe back reflected light in a controlled manner. Simulations reveal that tuning\nparameters like timing delay enables control over the amplitude, duration, and\nbandwidth of the resulting attosecond Thomson backscattering (TBS) pulse.\nTogether, these advances meet key experimental challenges and pave the way for\ncompact, tunable sources of isolated attosecond pulses for probing ultrafast\nphenomena.", "AI": {"tldr": "Researchers demonstrate how to generate isolated attosecond pulses in the extreme ultraviolet range by optimizing laser waveforms to create relativistic electron sheets that coherently reflect and upshift light, offering a compact solution for ultrafast phenomena research.", "motivation": "To develop a powerful method for generating bright, ultrashort pulses in the extreme ultraviolet range using Einstein's concept of reflecting light off mirrors moving near light speed, addressing key experimental challenges in creating compact, tunable sources for probing ultrafast phenomena.", "method": "The method involves striking nanometre-scale foils with high-intensity, sharp-front laser pulses to create dense relativistic electron mirrors (single relativistic electron sheet - RES), then optimizing the drive laser waveform to reliably produce isolated attosecond pulses through Thomson backscattering, with parameter tuning for controlling pulse characteristics.", "result": "Successfully demonstrated reliable production of single RES leading to isolated attosecond pulse generation with enhanced intensity and temporal compression. Simulations showed that tuning parameters like timing delay enables control over amplitude, duration, and bandwidth of the resulting attosecond Thomson backscattering pulses, with efficiency exceeding incoherent scattering by several orders of magnitude.", "conclusion": "The optimization of drive laser waveforms enables reliable generation of isolated attosecond pulses through relativistic electron sheets, meeting key experimental challenges and paving the way for compact, tunable sources of isolated attosecond pulses for ultrafast phenomena research."}}
{"id": "2507.17535", "pdf": "https://arxiv.org/pdf/2507.17535", "abs": "https://arxiv.org/abs/2507.17535", "authors": ["Chuyu Zhou", "ianyu Li", "Chenxi Lan", "Rongyu Du", "Guoguo Xin", "Pengyu Nan", "Hangzhou Yang", "Guoqing Wang", "Xun Liu", "Wei Li"], "title": "Hybrid Boundary Physics-Informed Neural Networks for Solving Navier-Stokes Equations with Complex Boundary", "categories": ["physics.comp-ph"], "comment": null, "summary": "Physics-informed neural networks (PINN) have achieved notable success in\nsolving partial differential equations (PDE), yet solving the Navier-Stokes\nequations (NSE) with complex boundary conditions remains a challenging task. In\nthis paper, we introduce a novel Hybrid Boundary PINN (HB-PINN) method that\ncombines a pretrained network for efficient initialization with a\nboundary-constrained mechanism. The HB-PINN method features a primary network\nfocused on inner domain points and a distance metric network that enhances\npredictions at the boundaries, ensuring accurate solutions for both boundary\nand interior regions. Comprehensive experiments have been conducted on the NSE\nunder complex boundary conditions, including the 2D cylinder wake flow and the\n2D blocked cavity flow with a segmented inlet. The proposed method achieves\nstate-of-the-art (SOTA) performance on these benchmark scenarios, demonstrating\nsignificantly improved accuracy over existing PINN-based approaches.", "AI": {"tldr": "The paper introduces HB-PINN, a hybrid physics-informed neural network that combines pretrained networks with boundary-constrained mechanisms to solve Navier-Stokes equations with complex boundary conditions, achieving state-of-the-art performance on benchmark fluid dynamics problems.", "motivation": "Solving Navier-Stokes equations with complex boundary conditions using physics-informed neural networks (PINN) remains challenging, requiring better methods to handle both interior domain solutions and accurate boundary condition enforcement simultaneously.", "method": "HB-PINN combines a pretrained network for efficient initialization with a boundary-constrained mechanism, featuring a primary network for inner domain points and a distance metric network that enhances boundary predictions to ensure accurate solutions across both boundary and interior regions.", "result": "The method achieves state-of-the-art performance on benchmark scenarios including 2D cylinder wake flow and 2D blocked cavity flow with segmented inlet, demonstrating significantly improved accuracy over existing PINN-based approaches.", "conclusion": "HB-PINN successfully addresses the challenge of solving Navier-Stokes equations with complex boundary conditions by effectively combining pretrained networks with boundary-enhanced mechanisms, establishing a new state-of-the-art for PINN-based fluid dynamics simulations."}}
{"id": "2507.17062", "pdf": "https://arxiv.org/pdf/2507.17062", "abs": "https://arxiv.org/abs/2507.17062", "authors": ["Zheng Tan", "Tariq D. Aslam", "Andrea L. Bertozzi"], "title": "Explicit Monotone Stable Super-Time-Stepping Methods for Finite Time Singularities", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We explore a novel way to numerically resolve the scaling behavior of\nfinite-time singularities in solutions of nonlinear parabolic PDEs. The\nRunge--Kutta--Legendre (RKL) and Runge--Kutta--Gegenbauer (RKG)\nsuper-time-stepping methods were originally developed for nonlinear complex\nphysics problems with diffusion. These are multi-stage single step\nsecond-order, forward-in-time methods with no implicit solves. The advantage is\nthat the timestep size for stability scales with stage number $s$ as\n$\\mathcal{O}(s^2)$. Many interesting nonlinear PDEs have finite-time\nsingularities, and the presence of diffusion often limits one to using implicit\nor semi-implicit timestep methods for stability constraints. Finite-time\nsingularities are particularly challenging due to the large range of scales\nthat one desires to resolve, often with adaptive spatial grids and adaptive\ntimesteps. Here we show two examples of nonlinear PDEs for which the\nself-similar singularity structure has time and space scales that are\nresolvable using the RKL and RKG methods, without forcing even smaller\ntimesteps. Compared to commonly-used implicit numerical methods, we achieve\nsignificantly smaller run time while maintaining comparable accuracy. We also\nprove numerical monotonicity for both the RKL and RKG methods under their\nlinear stability conditions for the constant coefficient heat equation, in the\ncase of infinite domain and periodic boundary condition, leading to a\ntheoretical guarantee of the superiority of the RKL and RKG methods over\ntraditional super-time-stepping methods, such as the Runge-Kutta-Chebyshev\n(RKC) and the orthogonal Runge-Kutta-Chebyshev (ROCK) methods.", "AI": {"tldr": "This paper introduces RKL and RKG super-time-stepping methods for numerically resolving finite-time singularities in nonlinear parabolic PDEs, achieving faster computation than implicit methods while maintaining accuracy.", "motivation": "Finite-time singularities in nonlinear PDEs are challenging to resolve numerically due to large scale ranges and stability constraints that typically require implicit methods. There's a need for efficient explicit methods that can handle these singularities without compromising stability or accuracy.", "method": "The paper employs Runge-Kutta-Legendre (RKL) and Runge-Kutta-Gegenbauer (RKG) super-time-stepping methods - multi-stage single step second-order explicit methods where timestep size scales as O(s\u00b2) with stage number s. These methods avoid implicit solves while maintaining stability for diffusion problems.", "result": "The RKL and RKG methods successfully resolve self-similar singularity structures in two nonlinear PDE examples, achieving significantly reduced runtime compared to implicit methods while maintaining comparable accuracy. The methods prove superior to traditional super-time-stepping approaches like RKC and ROCK.", "conclusion": "RKL and RKG methods provide an effective alternative to implicit methods for solving nonlinear parabolic PDEs with finite-time singularities, offering computational efficiency gains without sacrificing numerical accuracy or stability. Theoretical monotonicity guarantees further establish their superiority over existing super-time-stepping methods."}}
{"id": "2507.17197", "pdf": "https://arxiv.org/pdf/2507.17197", "abs": "https://arxiv.org/abs/2507.17197", "authors": ["Hyunjin In", "Dong-ha Kim", "Junha Kim"], "title": "Asymptotic stability of the $2D$ temperature-dependent tropical climate model with the sharp decay rates", "categories": ["math.AP"], "comment": "35 pages", "summary": "We investigate the asymptotic stability of a tropical climate model posed on\n$\\bR^2$, with temperature-dependent diffusion in the barotropic mode $u$ and\nlinear damping in the first baroclinic mode $v$. We consider two distinct cases\nfor the barotropic component: one with linear damping and one without. For both\ncases, we prove the small data global existence of smooth solutions.\nFurthermore, we establish sharp temporal decay estimates for solutions in\narbitrary Sobolev norms $H^m (\\bR^2)$, $m \\ge 0$.", "AI": {"tldr": "This paper studies the asymptotic stability of a tropical climate model on R^2 with temperature-dependent diffusion and proves global existence of smooth solutions with sharp decay estimates in Sobolev norms.", "motivation": "To analyze the long-term behavior and stability properties of tropical climate systems, particularly investigating how temperature-dependent diffusion affects the dynamics of barotropic and baroclinic modes in atmospheric modeling.", "method": "Mathematical analysis using PDE theory to study two cases of the tropical climate model: (1) barotropic mode with linear damping and (2) barotropic mode without damping. The approach involves proving small data global existence and establishing temporal decay estimates in Sobolev spaces H^m(R^2).", "result": "Successfully proved small data global existence of smooth solutions for both cases of the model. Established sharp temporal decay estimates for solutions in arbitrary Sobolev norms H^m(R^2) for m \u2265 0, demonstrating the asymptotic stability of the tropical climate system.", "conclusion": "The tropical climate model with temperature-dependent diffusion exhibits asymptotic stability under both damping scenarios. The mathematical framework provides rigorous foundation for understanding the long-term behavior of tropical atmospheric dynamics with sharp decay characterization."}}
{"id": "2507.16960", "pdf": "https://arxiv.org/pdf/2507.16960", "abs": "https://arxiv.org/abs/2507.16960", "authors": ["Simin Shekarpaz", "Chuanfei Dong", "Ziyu Huang"], "title": "Surrogate Modeling of Landau Damping with Deep Operator Networks", "categories": ["physics.plasm-ph", "astro-ph.HE", "astro-ph.IM", "astro-ph.SR", "physics.comp-ph", "physics.space-ph"], "comment": "10 pages, 8 figures, 4 tables, accepted for publication in ApJ", "summary": "Kinetic simulations excel at capturing microscale plasma physics phenomena\nwith high accuracy, but their computational demands make them impractical for\nmodeling large-scale space and astrophysical systems. In this context, we build\na surrogate model, using Deep Operator Networks (DeepONets), based upon the\nVlasov-Poisson simulation data to model the dynamical evolution of plasmas,\nfocusing on the Landau damping process - a fundamental kinetic phenomenon in\nspace and astrophysical plasmas. The trained DeepONets are able to capture the\nevolution of electric field energy in both linear and nonlinear regimes under\nvarious conditions. Extensive validation highlights DeepONets' robust\nperformance in reproducing complex plasma behaviors with high accuracy, paving\nthe way for large-scale modeling of space and astrophysical plasmas.", "AI": {"tldr": "Researchers developed a Deep Operator Networks (DeepONets) surrogate model to efficiently simulate plasma dynamics, particularly Landau damping, achieving high accuracy while reducing computational demands for large-scale space and astrophysical plasma modeling.", "motivation": "Kinetic simulations provide high accuracy for microscale plasma physics but are computationally prohibitive for large-scale space and astrophysical systems, necessitating the development of efficient surrogate models that maintain accuracy while reducing computational costs.", "method": "Built a surrogate model using Deep Operator Networks (DeepONets) trained on Vlasov-Poisson simulation data to model plasma dynamical evolution, specifically focusing on the Landau damping process in both linear and nonlinear regimes.", "result": "The trained DeepONets successfully captured the evolution of electric field energy across various conditions in both linear and nonlinear regimes, demonstrating robust performance in reproducing complex plasma behaviors with high accuracy through extensive validation.", "conclusion": "DeepONets provide a promising pathway for large-scale modeling of space and astrophysical plasmas by maintaining high accuracy while significantly reducing computational demands compared to traditional kinetic simulations."}}
{"id": "2507.17672", "pdf": "https://arxiv.org/pdf/2507.17672", "abs": "https://arxiv.org/abs/2507.17672", "authors": ["Jakob Filser", "Edan Bainglass", "Karsten Reuter", "Oliviero Andreussi"], "title": "Coupling all-electron full-potential density functional theory with grid-based continuum embeddings", "categories": ["physics.comp-ph"], "comment": "43 pages, 7 figures, submitted to the Journal of Chemical Physics", "summary": "Recent advances in continuum embedding models have enabled the incorporation\nof solvent and electrolyte effects into density functional theory (DFT)\nsimulations of material surfaces, significantly benefiting electrochemistry,\ncatalysis, and other applications. To extend the simulation of diverse systems\nand properties, the implementation of continuum embedding models into the\nEnviron library adopts a modular programming paradigm, offering a flexible\ninterface for communication with various DFT programs. The speed and\nscalability of the current implementation rely on a smooth definition of the\nkey physical properties of the atomistic system, in particular of its\nelectronic density. This has hindered the coupling of Environ with all-electron\nsimulation packages, as the sharp electron density peaks near atomic nuclei are\ndifficult to represent on regular grids. In this work, we introduce a novel\nsmoothing scheme that transforms atom-centered electron densities into a\nregular grid representation while preserving the accuracy of electrostatic\ncalculations. This approach enables a minimal and generic interface,\nfacilitating seamless interoperability between Environ and all-electron DFT\nprograms. We demonstrate this development through the coupling of Environ with\nthe FHI-aims package and present benchmark simulations that validate the\nproposed method.", "AI": {"tldr": "This paper presents a novel smoothing scheme for continuum embedding models that enables coupling of the Environ library with all-electron DFT programs by transforming sharp electron density peaks into smooth grid representations while maintaining electrostatic accuracy.", "motivation": "Previous continuum embedding models in Environ library could not couple with all-electron simulation packages due to sharp electron density peaks near atomic nuclei that are difficult to represent on regular grids, limiting the simulation of diverse systems and properties in electrochemistry and catalysis applications.", "method": "Development of a novel smoothing scheme that transforms atom-centered electron densities into regular grid representations while preserving electrostatic calculation accuracy, creating a minimal and generic interface for seamless interoperability between Environ and all-electron DFT programs.", "result": "Successfully demonstrated coupling of Environ with the FHI-aims package and presented benchmark simulations that validate the proposed smoothing method, enabling extension of continuum embedding models to all-electron DFT simulations.", "conclusion": "The novel smoothing scheme successfully overcomes the technical barrier of sharp electron density peaks, enabling seamless integration of continuum embedding models with all-electron DFT programs and expanding the capability to simulate diverse electrochemical and catalytic systems."}}
{"id": "2507.17333", "pdf": "https://arxiv.org/pdf/2507.17333", "abs": "https://arxiv.org/abs/2507.17333", "authors": ["Daniele A. Di Pietro", "J\u00e9r\u00f4me Droniou", "Kaibo Hu", "Arax Leroy"], "title": "Design and analysis of twisted and BGG Stokes-de Rham polytopal complexes", "categories": ["math.NA", "cs.NA", "65N30, 65N12, 74K20"], "comment": null, "summary": "We design a discrete Bernstein--Gelfand--Gelfand (BGG) diagram on polygonal\nmeshes based on the DDR framework; the diagram is made of a discrete Stokes\npolygonal complex and a tensorised Discrete De Rham complex, and the BGG\nconstruction leads to a novel elasticity complex applicable on generic\npolygonal meshes. Complete homological and analytical properties of the\ndiscrete Stokes complex are established, including primal and adjoint\nconsistency estimates as well as Poincar\\'e inequalities. Homological\nproperties of the complexes built from the BGG diagram are also established.", "AI": {"tldr": "This paper develops a discrete Bernstein-Gelfand-Gelfand (BGG) diagram for polygonal meshes using the DDR framework, creating a novel elasticity complex with proven mathematical properties including consistency estimates and Poincar\u00e9 inequalities.", "motivation": "The paper is motivated by the need to develop robust computational frameworks for elasticity problems on generic polygonal meshes, extending the classical BGG construction from differential geometry to discrete settings while maintaining essential mathematical properties.", "method": "The authors use the Discrete De Rham (DDR) framework to construct a discrete BGG diagram consisting of a discrete Stokes polygonal complex and a tensorised Discrete De Rham complex, which together form the basis for building an elasticity complex on polygonal meshes.", "result": "The paper establishes complete homological and analytical properties of the discrete Stokes complex, including primal and adjoint consistency estimates and Poincar\u00e9 inequalities. Additionally, homological properties of the complexes derived from the BGG diagram are proven.", "conclusion": "The discrete BGG construction successfully provides a mathematically rigorous elasticity complex for polygonal meshes with established theoretical guarantees, offering a new computational tool for elasticity problems on general polygonal discretizations."}}
{"id": "2507.17213", "pdf": "https://arxiv.org/pdf/2507.17213", "abs": "https://arxiv.org/abs/2507.17213", "authors": ["Anamika Pandey", "T. Raja Sekhar"], "title": "Formation of vacuum state and delta-shock in the solution of two-dimensional Riemann problem for zero pressure gas dynamics", "categories": ["math.AP"], "comment": "23 pages, 22 figures", "summary": "In this article, we investigate the two-dimensional pressureless Euler\nequations with three constant Riemann initial data. Our primary focus is on the\nwave interactions involving contact discontinuities and delta shocks. A\ndistinguishing feature of the solution is the emergence of a delta shock wave\nwhich is characterized by a Dirac delta function appearing in both the density\nand internal energy variables. By exploiting generalized characteristic\nanalysis, nine topologically distinct solution patterns are derived. Some of\nthese configurations exhibit features similar to Mach-reflection and in certain\ncases, vacuum regions may also develop. To validate the theoretical results,\nnumerical simulations are carried out using a semidiscrete central upwind\nscheme. The comparison between analytical and numerical results demonstrates\nexcellent agreement, providing", "AI": {"tldr": "This paper studies two-dimensional pressureless Euler equations with three constant Riemann initial data, focusing on wave interactions and delta shock formation, deriving nine distinct solution patterns including Mach-reflection-like configurations.", "motivation": "To investigate complex wave interactions in two-dimensional pressureless Euler equations, particularly the behavior of contact discontinuities and delta shocks that emerge from three constant Riemann initial data configurations.", "method": "Generalized characteristic analysis is employed to derive solution patterns, complemented by numerical simulations using a semidiscrete central upwind scheme to validate theoretical results.", "result": "Nine topologically distinct solution patterns are identified, featuring delta shock waves characterized by Dirac delta functions in density and internal energy. Some configurations show Mach-reflection-like features and vacuum region development. Numerical simulations show excellent agreement with analytical results.", "conclusion": "The study successfully characterizes the complex wave interaction phenomena in two-dimensional pressureless Euler equations, providing a comprehensive classification of solution patterns and demonstrating the reliability of the theoretical framework through numerical validation."}}
{"id": "2507.17046", "pdf": "https://arxiv.org/pdf/2507.17046", "abs": "https://arxiv.org/abs/2507.17046", "authors": ["Caleb Redshaw", "Matthew R. Edwards"], "title": "Radiation reaction effects on particle dynamics in intense counterpropagating laser pulses", "categories": ["physics.plasm-ph"], "comment": "12 pages, 8 figures", "summary": "In high-intensity laser-plasma interactions, particles can lose a substantial\nfraction of their energy by emitting radiation. Using particle-in-cell\nsimulations, we study the impact of radiation reaction on the dynamics of an\nunderdense plasma target struck by counterpropagating circularly polarized\nlaser pulses. By varying the relative wavelengths and intensities of the\npulses, we find a range of parameters where radiation reaction can detrap\nelectrons from the interference beat wave. The resulting charge separation\nfield and the dominant direction of ion expulsion are thus reversed by\nradiative effects. Based on the electron dynamics during the interaction, we\nestimate the bounds on the parameter regime where the reversal occurs. The\nbounds take the form of three simple inequalities which depend only on the\nwavelength, normalized vector potential, and pulse duration ratios of the two\nlasers as well as the product of the pulse duration with a dimensionless\nradiation reaction parameter. Our estimates, which predict whether radiation\nreaction will change the final ion direction for a given set of laser\nparameters, broadly agree with the simulated results. Finally, we outline an\nexperimental procedure by which the reversal could be used to observe the\ntransition to radiation-dominated dynamics.", "AI": {"tldr": "This study uses particle-in-cell simulations to investigate how radiation reaction affects plasma dynamics when struck by counterpropagating circularly polarized laser pulses, finding that radiation reaction can reverse electron trapping and ion expulsion direction under specific parameter conditions.", "motivation": "Understanding the impact of radiation reaction on high-intensity laser-plasma interactions is crucial as particles can lose substantial energy through radiation emission, which affects the fundamental dynamics of the interaction and needs to be characterized for applications in laser-plasma physics.", "method": "The researchers used particle-in-cell simulations to study underdense plasma targets struck by counterpropagating circularly polarized laser pulses, systematically varying the relative wavelengths and intensities of the pulses to map out parameter regimes where radiation reaction effects become significant.", "result": "The study identified a parameter range where radiation reaction detraps electrons from interference beat waves, reversing charge separation fields and ion expulsion direction. They derived three simple inequalities that predict this reversal based on wavelength, normalized vector potential, pulse duration ratios, and radiation reaction parameters, with good agreement between theoretical estimates and simulation results.", "conclusion": "Radiation reaction can significantly alter plasma dynamics by reversing fundamental processes like electron trapping and ion acceleration direction. The derived parameter bounds provide a practical framework for predicting when these effects occur, and the researchers propose an experimental method to observe the transition to radiation-dominated dynamics."}}
{"id": "2507.17700", "pdf": "https://arxiv.org/pdf/2507.17700", "abs": "https://arxiv.org/abs/2507.17700", "authors": ["Sergio Contreras Arredondo", "Chenyu Tang", "Radu A. Talmazan", "Alberto Meg\u00edas", "Cheng Giuseppe Chen", "Christophe Chipot"], "title": "From Atoms to Dynamics: Learning the Committor Without Collective Variables", "categories": ["physics.comp-ph", "cond-mat.stat-mech", "physics.data-an"], "comment": "32 pages (including supplementary information with 13 pages), 15\n  figures (5 figures in the main text and 10 figures in the supplementary\n  information)", "summary": "This Brief Communication introduces a graph-neural-network architecture built\non geometric vector perceptrons to predict the committor function directly from\natomic coordinates, bypassing the need for hand-crafted collective variables\n(CVs). The method offers atom-level interpretability, pinpointing the key\natomic players in complex transitions without relying on prior assumptions.\nApplied across diverse molecular systems, the method accurately infers the\ncommittor function and highlights the importance of each heavy atom in the\ntransition mechanism. It also yields precise estimates of the rate constants\nfor the underlying processes. The proposed approach opens new avenues for\nunderstanding and modeling complex dynamics, by enabling CV-free learning and\nautomated identification of physically meaningful reaction coordinates of\ncomplex molecular processes.", "AI": {"tldr": "A graph neural network architecture using geometric vector perceptrons is developed to predict committor functions directly from atomic coordinates, eliminating the need for hand-crafted collective variables and providing atom-level interpretability for molecular transitions.", "motivation": "Traditional methods for studying molecular transitions require hand-crafted collective variables (CVs) and prior assumptions about reaction mechanisms, which limits their applicability and interpretability. There is a need for automated, assumption-free approaches that can identify physically meaningful reaction coordinates and provide atom-level insights into complex molecular processes.", "method": "The paper introduces a graph neural network architecture based on geometric vector perceptrons that takes atomic coordinates as direct input to predict committor functions. This approach bypasses the need for predefined collective variables and provides atom-level interpretability by identifying key atomic players in transitions.", "result": "The method successfully predicts committor functions across diverse molecular systems with high accuracy. It provides atom-level interpretability by highlighting the importance of each heavy atom in transition mechanisms and yields precise estimates of rate constants for the underlying processes.", "conclusion": "The proposed graph neural network approach enables CV-free learning and automated identification of physically meaningful reaction coordinates, opening new avenues for understanding and modeling complex molecular dynamics without requiring prior assumptions about transition mechanisms."}}
{"id": "2507.17378", "pdf": "https://arxiv.org/pdf/2507.17378", "abs": "https://arxiv.org/abs/2507.17378", "authors": ["Chengrun Jiang", "Guozhi Dong", "Hailong Guo", "Zuoqiang Shi"], "title": "An FDM-sFEM scheme on time-space manifolds and its superconvergence analysis", "categories": ["math.NA", "cs.NA", "65M15, 65M60"], "comment": null, "summary": "We study superconvergent discretization of the Laplace-Beltrami operator on\ntime-space product manifolds with Neumann temporal boundary values, which arise\nin the context of dynamic optimal transport on general surfaces. We propose a\ncoupled scheme that combines finite difference methods in time with surface\nfinite element methods in space. By establishing a new summation by parts\nformula and proving the supercloseness of the semi-discrete solution, we derive\nsuperconvergence results for the recovered gradient via post-processing\ntechniques. In addition, our geometric error analysis is implemented within a\nnovel framework based on the approximation of the Riemannian metric. Several\nnumerical examples are provided to validate and illustrate the theoretical\nresults.", "AI": {"tldr": "This paper develops a superconvergent numerical method for solving the Laplace-Beltrami operator on time-space product manifolds with Neumann boundary conditions, combining finite differences in time with surface finite elements in space, and achieves enhanced accuracy through post-processing techniques.", "motivation": "The research is motivated by the need to solve dynamic optimal transport problems on general surfaces, which requires efficient and accurate discretization of the Laplace-Beltrami operator on time-space product manifolds with Neumann temporal boundary conditions.", "method": "The authors propose a coupled numerical scheme that combines finite difference methods for temporal discretization with surface finite element methods for spatial discretization. They establish a new summation by parts formula and implement geometric error analysis within a framework based on Riemannian metric approximation.", "result": "The method achieves superconvergence for the recovered gradient through post-processing techniques. The authors prove supercloseness of the semi-discrete solution and derive theoretical superconvergence results, which are validated through numerical examples.", "conclusion": "The proposed coupled scheme successfully provides superconvergent discretization of the Laplace-Beltrami operator on time-space product manifolds, offering enhanced accuracy for dynamic optimal transport problems on surfaces through the combination of appropriate temporal and spatial discretization methods with post-processing techniques."}}
{"id": "2507.17282", "pdf": "https://arxiv.org/pdf/2507.17282", "abs": "https://arxiv.org/abs/2507.17282", "authors": ["Qi Lu", "Jean-Claude Saut", "Li Xu"], "title": "Long time existence for a Boussinesq-like system with strong topography variation", "categories": ["math.AP"], "comment": null, "summary": "We prove the long time existence of solutions of a Boussinesq system with\nstrong topography variations.", "AI": {"tldr": "This paper proves that solutions to a Boussinesq system with strong topography variations exist for long periods of time.", "motivation": "The motivation is to establish mathematical rigor for the long-term behavior of fluid flow systems described by Boussinesq equations when the underlying topography has significant variations, which is important for understanding real-world fluid dynamics in complex terrains.", "method": "The paper uses mathematical proof techniques to demonstrate the long time existence of solutions for the Boussinesq system under conditions of strong topographical variations.", "result": "The main result is a mathematical proof establishing that solutions to the Boussinesq system with strong topography variations exist over long time periods.", "conclusion": "The authors successfully prove long time existence for solutions of Boussinesq systems with strong topography variations, providing theoretical foundation for the stability and persistence of such fluid flow models."}}
{"id": "2507.17299", "pdf": "https://arxiv.org/pdf/2507.17299", "abs": "https://arxiv.org/abs/2507.17299", "authors": ["Soumitra Banerjee", "Harshita Raj", "Sk Injamul Hoque", "Komal Yadav", "Sharvil Patel", "Ankit Kumar", "Kaushlender Singh", "Ashok Kumawat", "Bharat Hegde", "Subhojit Bose", "Priyanka Verma", "Kumudini Tahiliani", "Asha Adhiya", "Manoj Kumar", "Rohit Kumar", "Malay Bikash Chowdhuri", "Nilam Ramaiya", "Ananya Kundu", "Suman Aich", "Suman Dolui", "K. A. Jadeja", "K. M. Patel", "Ankit Patel", "Rakesh L. Tanna", "Joydeep Ghosh"], "title": "Identification and Characterization of a New Disruption Regime in ADITYA-U Tokamak", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Disruptions continue to pose a significant challenge to the stable operation\nand future design of tokamak reactors. A comprehensive statistical\ninvestigation carried out on the ADITYA-U tokamak has led to the observation\nand characterization of a novel disruption regime. In contrast to the\nconventional Locked Mode Disruption (LMD), the newly identified disruption\nexhibits a distinctive two-phase evolution: an initial phase characterized by a\nsteady rise in mode frequency with a nonlinearly saturated amplitude, followed\nby a sudden frequency collapse accompanied by a pronounced increase in\namplitude. This behaviour signifies the onset of the precursor phase on a\nsignificantly shorter timescale. Clear empirical thresholds have been\nidentified to distinguish this disruption type from conventional LMD events,\nincluding edge safety factor, current decay coefficient, current quench (CQ)\ntime, and CQ rate. The newly identified disruption regime is predominantly\ngoverned by the (m/n = 2/1) drift-tearing mode (DTM), which, in contrast to\ntypical disruptions in the ADITYA-U tokamak that involve both m/n = 2/1 and 3/1\nmodes, consistently manifests as the sole dominant instability. Initiated by\ncore temperature hollowing, the growth of this mode is significantly enhanced\nby a synergistic interplay between a strongly localized pressure gradient and\nthe pronounced steepening of the current density profile in the vicinity of the\nmode rational surface.", "AI": {"tldr": "Researchers discovered a new type of tokamak disruption in ADITYA-U that differs from conventional locked mode disruptions, featuring a two-phase evolution with frequency rise followed by collapse, governed solely by the (2/1) drift-tearing mode and triggered by core temperature hollowing.", "motivation": "Disruptions pose significant challenges to tokamak reactor stability and future design, necessitating comprehensive understanding of different disruption mechanisms to improve plasma control and reactor safety.", "method": "Statistical investigation conducted on ADITYA-U tokamak to characterize disruption events, analyzing mode frequency evolution, amplitude behavior, and identifying empirical thresholds including edge safety factor, current decay coefficient, current quench time, and rate to distinguish disruption types.", "result": "Identified a novel disruption regime with distinctive two-phase evolution: initial steady frequency rise with nonlinearly saturated amplitude, followed by sudden frequency collapse with amplitude increase. This regime is dominated solely by (m/n = 2/1) drift-tearing mode, unlike typical ADITYA-U disruptions involving both 2/1 and 3/1 modes. Clear empirical thresholds were established to distinguish this from conventional locked mode disruptions.", "conclusion": "The newly identified disruption regime represents a distinct category governed by (2/1) drift-tearing mode, initiated by core temperature hollowing and enhanced by synergistic effects between localized pressure gradients and current density profile steepening near the mode rational surface, providing new insights for tokamak disruption prediction and mitigation strategies."}}
{"id": "2507.16879", "pdf": "https://arxiv.org/pdf/2507.16879", "abs": "https://arxiv.org/abs/2507.16879", "authors": ["Azhar Ikhtiarudin", "Gagus Ketut Sunnardianto", "Fadjar Fathurrahman", "Mohammad Kemal Agusta", "Hermawan Kresno Dipojono"], "title": "Shot-Efficient ADAPT-VQE via Reused Pauli Measurements and Variance-Based Shot Allocation", "categories": ["quant-ph", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "The Adaptive Variational Quantum Eigensolver (ADAPT-VQE) is a promising\napproach for quantum algorithms in the Noisy Intermediate-Scale Quantum (NISQ)\nera, offering advantages over traditional VQE methods by reducing circuit depth\nand mitigating challenges in classical optimization. However, a major challenge\nin ADAPT-VQE is the high quantum measurement (shot) overhead required for\ncircuit parameter optimization and operator selection. In this work, we propose\ntwo integrated strategies to reduce the shot requirements in ADAPT-VQE. First,\nwe reuse Pauli measurement outcomes obtained during VQE parameter optimization\nin the subsequent operator selection step of the next ADAPT-VQE iteration,\nwhich involves operator gradient measurements. Second, we apply variance-based\nshot allocation to both Hamiltonian and operator gradient measurements. Our\nnumerical results demonstrate that each method, individually and in\ncombination, significantly reduces the number of shots needed to achieve\nchemical accuracy while maintaining result fidelity across the studied\nmolecular systems.", "AI": {"tldr": "This paper proposes two strategies to reduce quantum measurement overhead in ADAPT-VQE: reusing measurement outcomes between optimization steps and applying variance-based shot allocation, achieving significant shot reduction while maintaining chemical accuracy.", "motivation": "ADAPT-VQE shows promise for NISQ quantum algorithms but suffers from high quantum measurement (shot) overhead required for both circuit parameter optimization and operator selection, creating a major computational bottleneck.", "method": "Two integrated strategies: (1) reusing Pauli measurement outcomes from VQE parameter optimization for operator gradient measurements in the next ADAPT-VQE iteration, and (2) applying variance-based shot allocation to both Hamiltonian and operator gradient measurements.", "result": "Numerical results show that both methods, individually and combined, significantly reduce the number of shots needed to achieve chemical accuracy while maintaining result fidelity across studied molecular systems.", "conclusion": "The proposed shot reduction strategies effectively address the measurement overhead challenge in ADAPT-VQE, making the algorithm more practical for NISQ devices by reducing quantum resource requirements without compromising accuracy."}}
{"id": "2507.17404", "pdf": "https://arxiv.org/pdf/2507.17404", "abs": "https://arxiv.org/abs/2507.17404", "authors": ["Carlos Beltr\u00e1n"], "title": "Univariate amenable functions", "categories": ["math.NA", "cs.NA", "65Y04"], "comment": null, "summary": "The concepts of amenable and compatible functions have been introduced in a\nrecent work, in order to state precise mathematical theorems that guarantee\nthat a backward stable algorithm is also forward stable, and that the\ncomposition of two stable algorithms results in an stable algorithm. In this\nwork, we elaborate in this theory for univariate real analytic functions,\nproviding simple tests for both concepts and producing tables for a number of\nelementary functions which are or fail to be amenable.", "AI": {"tldr": "This paper develops theory and practical tests for amenable and compatible functions in the context of univariate real analytic functions, building on previous work that established mathematical conditions for algorithm stability composition.", "motivation": "To provide practical tools and characterizations for determining when backward stable algorithms remain forward stable and when compositions of stable algorithms preserve stability, specifically focusing on univariate real analytic functions.", "method": "The authors elaborate on existing theory of amenable and compatible functions by developing simple tests for these concepts and systematically analyzing elementary functions to determine which satisfy the amenability condition.", "result": "The paper produces practical tests for identifying amenable and compatible functions and creates comprehensive tables categorizing various elementary functions based on whether they are amenable or not.", "conclusion": "The work successfully extends the theoretical framework of amenable and compatible functions to practical applications, providing concrete tools for analyzing the stability properties of algorithms involving univariate real analytic functions."}}
{"id": "2507.17310", "pdf": "https://arxiv.org/pdf/2507.17310", "abs": "https://arxiv.org/abs/2507.17310", "authors": ["Alexander Gladkov"], "title": "Blow-up problem for porous medium equation with absorption under nonlinear nonlocal boundary condition", "categories": ["math.AP", "35K20, 35K61, 35K65"], "comment": null, "summary": "In this paper we consider initial boundary value problem for porous medium\nequation with absorption under nonlinear nonlocal boundary condition and\nnonnegative initial datum. We prove local existence, comparison principle,\nglobal existence and blow-up of solutions.", "AI": {"tldr": "This paper analyzes the porous medium equation with absorption under nonlinear nonlocal boundary conditions, establishing existence, comparison principles, and blow-up behavior of solutions.", "motivation": "To understand the mathematical behavior of porous medium equations with absorption terms under complex nonlinear nonlocal boundary conditions, which are important in modeling fluid flow in porous media with boundary effects.", "method": "Mathematical analysis techniques including proving local existence theorems, establishing comparison principles for solution ordering, and analyzing conditions for global existence versus finite-time blow-up of solutions.", "result": "Successfully established local existence of solutions, proved comparison principle for solution behavior, determined conditions for global existence, and characterized blow-up phenomena for the porous medium equation with absorption under nonlinear nonlocal boundary conditions.", "conclusion": "The paper provides a complete theoretical framework for understanding solution behavior of porous medium equations with absorption under nonlinear nonlocal boundary conditions, covering existence, uniqueness, and long-time dynamics including blow-up scenarios."}}
{"id": "2507.17483", "pdf": "https://arxiv.org/pdf/2507.17483", "abs": "https://arxiv.org/abs/2507.17483", "authors": ["Stefano Romeo", "Angelo Biagioni", "Lucio Crincoli", "Alessio Del Dotto", "Massimo Ferrario", "Anna Giribono", "Gianmarco Parise", "Andrea Renato Rossi", "Gilles Jacopo Silvi", "Cristina Vaccarezza"], "title": "Evaluation of the Transfer Matrix of a Plasma Ramp with Squared Cosine Shape via an Approximate Solution of the Mathieu Differential Equation", "categories": ["physics.plasm-ph"], "comment": "16 pages, 10 figures", "summary": "The high longitudinal electric fields generated in plasma wakefields are very\nattractive for a new generation of high gradient plasma based accelerators. On\nthe other hand, the strong transverse fields increase the demand for a proper\nmatching device in order to avoid the spoiling of beam transverse quality. A\nsolution can be provided by the use of a plasma ramp, a region at the plasma\ninjection/extraction with smoothly increasing/decreasing plasma density. The\ntransport of a beam inside a plasma ramp, beside its parameters, depends on the\nprofile of the ramp itself. Establishing the transfer matrix for a plasma ramp\nrepresents a very useful tool in order to evaluate the beam evolution in the\nplasma. In this paper a study of a cosine squared ramp is presented. An\napproximate solution of the transverse equation of motion is evaluated and\nexploited to provide a simple transfer matrix for the plasma ramp. The transfer\nmatrix is then employed to demonstrate that this kind of ramp has the effect to\nminimize the emittance growth due to betatron dephasing. The behavior of a\nsquared cosine plasma ramp will be compared with an experimentally measured\nplasma ramp profile in order to validate the applicability of the transfer\nmatrix to real cases.", "AI": {"tldr": "This paper develops a transfer matrix approach for analyzing beam transport through cosine squared plasma ramps in plasma wakefield accelerators, showing that such ramps minimize emittance growth and can be applied to real experimental cases.", "motivation": "Plasma wakefield accelerators generate high longitudinal electric fields for acceleration but also strong transverse fields that can degrade beam quality. Plasma ramps with smoothly varying density at injection/extraction points are needed as matching devices to preserve beam transverse quality, requiring proper analytical tools to evaluate beam evolution.", "method": "The authors derive an approximate solution to the transverse equation of motion for a cosine squared plasma ramp profile and use this to construct a simple transfer matrix. They then apply this transfer matrix to analyze beam evolution and compare the cosine squared profile with experimentally measured plasma ramp profiles.", "result": "The transfer matrix successfully describes beam transport through cosine squared plasma ramps and demonstrates that this ramp profile minimizes emittance growth due to betatron dephasing. The approach shows good agreement when validated against experimentally measured plasma ramp profiles.", "conclusion": "Cosine squared plasma ramps provide an effective solution for beam matching in plasma wakefield accelerators by minimizing emittance growth, and the developed transfer matrix approach offers a practical tool for designing and analyzing such systems in real experimental conditions."}}
{"id": "2507.17423", "pdf": "https://arxiv.org/pdf/2507.17423", "abs": "https://arxiv.org/abs/2507.17423", "authors": ["Anna Ivagnes", "Toby van Gastelen", "Syver D\u00f8ving Agdestein", "Benjamin Sanderse", "Giovanni Stabile", "Gianluigi Rozza"], "title": "A new data-driven energy-stable Evolve-Filter-Relax model for turbulent flow simulation", "categories": ["math.NA", "cs.NA", "physics.flu-dyn"], "comment": null, "summary": "We present a novel approach to define the filter and relax steps in the\nevolve-filter-relax (EFR) framework for simulating turbulent flows. The EFR\nmain advantages are its ease of implementation and computational efficiency.\nHowever, as it only contains two parameters (one for the filter step and one\nfor the relax step) its flexibility is rather limited. In this work, we propose\na data-driven approach in which the optimal filter is found based on DNS data\nin the frequency domain. The optimization step is computationally efficient and\nonly involves one-dimensional least-squares problems for each wavenumber.\nAcross both decaying turbulence and Kolmogorov flow, our learned filter\ndecisively outperforms the standard differential filter and the Smagorinsky\nmodel, yielding significantly improved accuracy in energy spectra and in the\ntemporal evolution of both energy and enstrophy. In addition, the relax\nparameter is determined by requiring energy and/or enstrophy conservation,\nwhich enforces stability of the method and reduces the appearance of numerical\nwiggles, especially when the filter is built in scarce data regimes. Applying\nthe learned filter is also more computationally efficient compared to\ntraditional differential filters, as it circumvents solving a linear system.", "AI": {"tldr": "This paper proposes a data-driven approach to optimize the evolve-filter-relax (EFR) framework for turbulent flow simulation by learning optimal filters from DNS data in the frequency domain, achieving better accuracy and computational efficiency than traditional methods.", "motivation": "The traditional EFR framework for turbulent flow simulation has limited flexibility with only two parameters and uses suboptimal standard differential filters. There is a need for more accurate and computationally efficient filtering approaches that can better capture turbulent flow dynamics.", "method": "The authors develop a data-driven optimization approach that learns optimal filters from DNS data in the frequency domain using one-dimensional least-squares problems for each wavenumber. The relax parameter is determined by enforcing energy and/or enstrophy conservation to ensure method stability.", "result": "The learned filter significantly outperforms standard differential filters and the Smagorinsky model in both decaying turbulence and Kolmogorov flow simulations, showing improved accuracy in energy spectra and temporal evolution of energy and enstrophy. The method is also more computationally efficient as it avoids solving linear systems.", "conclusion": "The data-driven filter optimization approach successfully enhances the EFR framework's performance, providing better accuracy and computational efficiency for turbulent flow simulations while maintaining stability through energy/enstrophy conservation constraints."}}
{"id": "2507.17345", "pdf": "https://arxiv.org/pdf/2507.17345", "abs": "https://arxiv.org/abs/2507.17345", "authors": ["Lia Bronsard", "Dmitry Golovaty", "Xavier Lamy", "Peter Sternberg"], "title": "Compensation effects for anisotropic energies of two-dimensional unit vector fields", "categories": ["math.AP"], "comment": null, "summary": "We study the highly anisotropic energy of two-dimensional unit vector fields\ngiven by \\begin{align*} E_\\epsilon(u)= \\int_{\\Omega} (\\mathrm{div}\\,u)^2 +\n\\epsilon(\\mathrm{curl}\\,u)^2\\, dx\\,, \\quad u\\colon\\Omega\\subset\\mathbb\nR^2\\to\\mathbb S^1\\, \\end{align*}\n  in the limit $\\epsilon\\to 0$. This energy clearly loses control on the full\ngradient of $u$ as $\\epsilon\\to 0$, but, adapting tools from hyperbolic\nconservations laws, we show that it still controls derivatives of order 1/2. In\nparticular, any bounded energy sequence $E_\\epsilon(u_\\epsilon)\\leq C$ is\ncompact in $W^{s,3}_{\\mathrm{loc}}(\\Omega)$ for $s<1/2$. Moreover, this order\n1/2 of differentiability is optimal, in the sense that any map $u\\in\nW^{1/2,4}(\\Omega;\\mathbb S^1)$ is a limit of a bounded energy sequence. We also\nestablish compactness of boundary traces in $L^1(\\partial\\Omega)$, and\ncharacterize the $\\Gamma$-limit in the simpler case of maps of a single\nvariable and in the case of a thin-film model.", "AI": {"tldr": "This paper studies the anisotropic energy of 2D unit vector fields in the limit \u03b5\u21920, showing that despite losing gradient control, the energy still controls 1/2-order derivatives, with optimal compactness results in W^{s,3} spaces for s<1/2.", "motivation": "The motivation is to understand the behavior of highly anisotropic energy functionals for unit vector fields when one term (curl) becomes negligible compared to another (divergence), particularly investigating what regularity can still be controlled when full gradient control is lost.", "method": "The authors adapt tools from hyperbolic conservation laws to analyze the energy functional E_\u03b5(u) = \u222b(div u)\u00b2 + \u03b5(curl u)\u00b2 dx for unit vector fields u: \u03a9\u2282\u211d\u00b2\u2192S\u00b9 in the limit \u03b5\u21920, studying compactness properties and characterizing \u0393-limits.", "result": "The main results show that bounded energy sequences are compact in W^{s,3}_loc(\u03a9) for s<1/2, this 1/2 order of differentiability is optimal (any map in W^{1/2,4}(\u03a9;S\u00b9) is a limit of bounded energy sequences), boundary traces are compact in L\u00b9(\u2202\u03a9), and explicit \u0393-limit characterizations are provided for single variable maps and thin-film models.", "conclusion": "The paper establishes that even when anisotropic energies lose full gradient control, they can still provide meaningful regularity control at the optimal fractional order 1/2, with complete characterization of the limiting behavior through \u0393-convergence analysis."}}
{"id": "2507.17447", "pdf": "https://arxiv.org/pdf/2507.17447", "abs": "https://arxiv.org/abs/2507.17447", "authors": ["Debesh Bhattacharjee", "Saikat Majumder", "Prasad Subramanian"], "title": "Characterizing proton polytropic indices inside near-Earth magnetic clouds and ICME sheaths", "categories": ["astro-ph.SR", "physics.plasm-ph"], "comment": "Accepted by Journal of Astrophysics and Astronomy (JoAA)", "summary": "The thermodynamics of interplanetary coronal mass ejections (ICMEs) is often\ndescribed using a polytropic process. Estimating the polytopic index ($\\gamma$)\nallows us to quantify the expansion or compression of the ICME plasma arising\nfrom changes in the plasma temperature. In this study, we estimate $\\gamma$ for\nprotons inside the magnetic clouds (MCs), their associated sheaths, and ambient\nsolar wind for a large sample of well-observed events observed by the Wind\nspacecraft at 1 AU. We find that $\\gamma$ shows a high ($\\approx 1.6$) - low\n($\\approx 1.05$) - high ($\\approx 1.2$) behavior inside the ambient solar wind,\nsheath, and MCs, respectively. We also find that the proton polytropic index is\nindependent of small-scale density fluctuations. Furthermore, our results show\nthat the stored energy inside MC plasma is not expended in expanding its\ncross-section at 1 AU. The sub-adiabatic nature of MC plasma implies external\nheating - possibly due to thermal conduction from the corona. We find that the\nheating gradient per unit mass from the corona to the protons of MC at 1 AU is\n$\\approx 0.21$ erg cm$^{-1}$ g$^{-1}$ which is in agreement with the required\nproton heating budget.", "AI": {"tldr": "This study analyzes the polytropic index of protons in interplanetary coronal mass ejections (ICMEs) using Wind spacecraft data, finding distinct thermodynamic behaviors in different plasma regions and evidence for external heating from the corona.", "motivation": "To understand the thermodynamics of ICME plasma by quantifying the polytropic index (\u03b3) which describes expansion/compression processes, and to investigate the energy budget and heating mechanisms in magnetic clouds and their associated regions.", "method": "Statistical analysis of a large sample of well-observed ICME events from Wind spacecraft at 1 AU, calculating polytropic indices for protons in three distinct regions: ambient solar wind, sheath regions, and magnetic clouds (MCs).", "result": "Found characteristic polytropic index pattern: high (~1.6) in ambient solar wind, low (~1.05) in sheath, and intermediate (~1.2) in magnetic clouds. The polytropic index is independent of small-scale density fluctuations. Stored energy in MC plasma is not used for cross-sectional expansion at 1 AU. Calculated heating gradient of ~0.21 erg cm\u207b\u00b9 g\u207b\u00b9 from corona to MC protons.", "conclusion": "The sub-adiabatic nature of magnetic cloud plasma indicates external heating, likely from thermal conduction from the corona. The calculated heating gradient matches the required proton heating budget, supporting the hypothesis of coronal thermal conduction as a heating mechanism for ICME plasma."}}
{"id": "2507.17569", "pdf": "https://arxiv.org/pdf/2507.17569", "abs": "https://arxiv.org/abs/2507.17569", "authors": ["Alexandre Caboussat", "Anna Peruso", "Marco Picasso"], "title": "Error estimates and adaptivity for a least-squares method applied to the Monge-Amp\u00e8re equation", "categories": ["math.NA", "cs.NA", "65M60 (Primary) 65M50 (Secondary)", "G.1.8; G.1.6"], "comment": "29 pages, 46 figures. Submitted to IMA Journal of Numerical Analysis", "summary": "We introduce novel a posteriori error indicators for a nonlinear\nleast-squares solver for smooth solutions of the Monge--Amp\\`ere equation on\nconvex polygonal domains in $\\mathbb{R}^2$. At each iteration, our iterative\nscheme decouples the problem into (i) a pointwise nonlinear minimization\nproblem and (ii) a linear biharmonic variational problem. For the latter, we\nderive an equivalence to a biharmonic problem with Navier boundary conditions\nand solve it via mixed piecewise-linear finite elements. Reformulating this as\na coupled second-order system, we derive a priori and a posteriori\n$\\mathbb{P}^1$ finite element error estimators and we design a robust adaptive\nmesh refinement strategy. Numerical tests confirm that errors in different\nnorms scale appropriately. Finally, we demonstrate the effectiveness of our a\nposteriori indicators in guiding mesh refinement.", "AI": {"tldr": "This paper presents a novel adaptive finite element method for solving the nonlinear Monge-Amp\u00e8re equation using a posteriori error indicators and mesh refinement strategies.", "motivation": "The Monge-Amp\u00e8re equation is a challenging nonlinear PDE that requires efficient numerical methods. Current approaches lack robust adaptive strategies with reliable error control, making it difficult to achieve optimal computational efficiency while maintaining accuracy.", "method": "The authors develop an iterative scheme that decouples the problem into (i) a pointwise nonlinear minimization and (ii) a linear biharmonic variational problem with Navier boundary conditions. They use mixed piecewise-linear finite elements and reformulate it as a coupled second-order system to derive both a priori and a posteriori error estimators for adaptive mesh refinement.", "result": "Numerical tests demonstrate that errors in different norms scale appropriately with the theoretical predictions. The a posteriori error indicators effectively guide mesh refinement, leading to optimal convergence rates and computational efficiency.", "conclusion": "The proposed method successfully combines nonlinear least-squares solving with adaptive finite element techniques, providing a robust and efficient approach for solving Monge-Amp\u00e8re equations on convex polygonal domains with reliable error control."}}
{"id": "2507.17381", "pdf": "https://arxiv.org/pdf/2507.17381", "abs": "https://arxiv.org/abs/2507.17381", "authors": ["Charles Collot", "Christophe Prange", "Jin Tan"], "title": "Stable self-similar singularity formation for infinite energy solutions of the incompressible porous medium equations", "categories": ["math.AP", "76B03, 35Q35, 76S05"], "comment": "34 pages", "summary": "We consider a special class of infinite energy solutions to the inviscid\nincompressible porous medium equations (IPM), introduced in\nCastro-C\\'ordoba-Gancedo-Orive [9]. The (IPM) equations then reduce to a\none-dimensional nonlocal nonlinear equation, for which an explicit self-similar\nblow-up solution is found in [9]. We show the stability of this explicit\nblow-up solution by smooth enough perturbations, and identity a sharp\nregularity threshold below which it is unstable. The heart of our proof is a\nchange of variables that transforms the study of finite time blow-up solutions,\nto the study of global-in-time solutions to the Proudman-Johnson equation,\nwhich is a reduced equation that appears for special classes of solutions of\nthe two-dimensional Euler equations, and of the inviscid primitive equations\n(or hydrostatic Euler equations). Our main result is in fact the asymptotic\nstability with decay estimates for a family of steady states of this reduced\nequation. It thus also implies the corresponding stability of steady states for\nthe associated classes of solutions to the Euler equations and inviscid\nprimitive equations.", "AI": {"tldr": "This paper analyzes the stability of explicit blow-up solutions to inviscid incompressible porous medium equations by transforming the finite-time blow-up problem into a global-time stability problem for the Proudman-Johnson equation, establishing sharp regularity thresholds and asymptotic stability results.", "motivation": "The motivation is to understand the stability properties of special infinite energy solutions to the inviscid incompressible porous medium equations, particularly focusing on explicit self-similar blow-up solutions that were previously discovered, and to determine the conditions under which these solutions remain stable or become unstable.", "method": "The key method involves a change of variables that transforms the study of finite-time blow-up solutions into the analysis of global-in-time solutions to the Proudman-Johnson equation. This transformation allows the authors to leverage existing theory for studying stability of steady states in reduced equations that appear in special classes of Euler equations and inviscid primitive equations.", "result": "The main results include: (1) proof of stability of the explicit blow-up solution under smooth enough perturbations, (2) identification of a sharp regularity threshold below which the solution becomes unstable, and (3) asymptotic stability with decay estimates for a family of steady states of the Proudman-Johnson equation, which extends to corresponding stability results for Euler equations and inviscid primitive equations.", "conclusion": "The paper successfully establishes the stability theory for blow-up solutions in inviscid incompressible porous medium equations by connecting them to the well-studied Proudman-Johnson equation. The approach not only resolves the stability question for the specific blow-up solutions but also provides broader implications for understanding steady state stability in related fluid dynamics equations including Euler and inviscid primitive equations."}}
{"id": "2507.17032", "pdf": "https://arxiv.org/pdf/2507.17032", "abs": "https://arxiv.org/abs/2507.17032", "authors": ["Yuxuan Wang", "Guoqiang Lan", "Huicong Chen", "Jun Song"], "title": "Thermophysical and Mechanical Properties Prediction of Rear-earth High-entropy Pyrochlore Based on Deep-learning Potential", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "19 pages, 6 figures, 1 table", "summary": "High-entropy pyrochlore oxides possess ultra-low thermal conductivity and\nexcellent high-temperature phase stability, making them promising candidate for\nnext-generation thermal barrier coating (TBC) materials. However, reliable\npredictive models for such complex and disordered systems remain challenging.\nAb initio methods, although accurate in describing anharmonic phonon-phonon\ninteractions, struggle to capture the strong inherent phonon-disorder\nscattering in high-entropy systems. Moreover, the limited simulation cell size,\nhundreds of atoms, cannot fully represent the configurational complexity of\nhigh-entropy phases. On the other hand, classical molecular dynamics (MD)\nsimulations lack accurate and transferable interatomic potentials, particularly\nin multi-component systems like high-entropy ceramics. In this work, we\nemployed Deep Potential Molecular Dynamics (DPMD) to predict the thermophysical\nand mechanical properties of rare-earth high-entropy pyrochlore oxide system.\nThe deep-potential (DP) model is trained on a limited dataset from ab initio\nmolecular dynamics (AIMD) calculations, enabling large-scale molecular dynamics\nsimulations with on-the-fly potential evaluations. This model not only achieves\nhigh accuracy in reproducing ab initio results but also demonstrates strong\ngeneralizability, making it applicable to medium-entropy ceramics containing\nthe same constituent elements. Our study successfully develops a deep potential\nmodel for rare-earth pyrochlore systems and demonstrates that the\ndeep-learning-based potential method offers a powerful computational approach\nfor designing high-entropy TBC materials.", "AI": {"tldr": "Researchers developed a Deep Potential Molecular Dynamics (DPMD) model to predict properties of high-entropy pyrochlore oxides for thermal barrier coatings, overcoming limitations of traditional ab initio and classical MD methods by achieving both accuracy and scalability.", "motivation": "High-entropy pyrochlore oxides show promise as next-generation thermal barrier coating materials due to their ultra-low thermal conductivity and excellent high-temperature stability. However, existing computational methods face significant limitations: ab initio methods struggle with phonon-disorder scattering and are limited by small simulation cell sizes, while classical MD lacks accurate interatomic potentials for multi-component high-entropy systems.", "method": "The authors employed Deep Potential Molecular Dynamics (DPMD) approach, where a deep-potential (DP) model is trained on a limited dataset from ab initio molecular dynamics (AIMD) calculations. This enables large-scale molecular dynamics simulations with on-the-fly potential evaluations, combining the accuracy of ab initio methods with the scalability of classical MD.", "result": "The deep potential model successfully achieved high accuracy in reproducing ab initio results while demonstrating strong generalizability. The model proved applicable not only to high-entropy systems but also to medium-entropy ceramics containing the same constituent elements, enabling prediction of thermophysical and mechanical properties of rare-earth high-entropy pyrochlore oxide systems.", "conclusion": "The study successfully develops a deep potential model for rare-earth pyrochlore systems and demonstrates that deep-learning-based potential methods offer a powerful computational approach for designing high-entropy thermal barrier coating materials, bridging the gap between accuracy and computational efficiency in complex multi-component ceramic systems."}}
{"id": "2507.17673", "pdf": "https://arxiv.org/pdf/2507.17673", "abs": "https://arxiv.org/abs/2507.17673", "authors": ["Vasileios Kalantzis", "Mark S. Squillante", "Chai Wah Wu"], "title": "Stable Iterative Solvers for Ill-conditioned Linear Systems", "categories": ["math.NA", "cs.DS", "cs.NA", "65F22", "F.2.1"], "comment": "7 pages, 13 figures", "summary": "Iterative solvers for large-scale linear systems such as Krylov subspace\nmethods can diverge when the linear system is ill-conditioned, thus\nsignificantly reducing the applicability of these iterative methods in practice\nfor high-performance computing solutions of such large-scale linear systems. To\naddress this fundamental problem, we propose general algorithmic frameworks to\nmodify Krylov subspace iterative solution methods which ensure that the\nalgorithms are stable and do not diverge. We then apply our general frameworks\nto current implementations of the corresponding iterative methods in SciPy and\ndemonstrate the efficacy of our stable iterative approach with respect to\nnumerical experiments across a wide range of synthetic and real-world\nill-conditioned linear systems.", "AI": {"tldr": "This paper proposes general algorithmic frameworks to stabilize Krylov subspace iterative methods for solving ill-conditioned large-scale linear systems, preventing divergence and improving reliability in high-performance computing applications.", "motivation": "Krylov subspace methods for solving large-scale linear systems can diverge when dealing with ill-conditioned systems, which significantly limits their practical applicability in high-performance computing scenarios where such systems are common.", "method": "The authors develop general algorithmic frameworks that modify existing Krylov subspace iterative solution methods to ensure algorithmic stability and prevent divergence. These frameworks are then implemented and integrated with current SciPy implementations of iterative methods.", "result": "The proposed stable iterative approach demonstrates efficacy through numerical experiments conducted on a wide range of both synthetic and real-world ill-conditioned linear systems, showing improved performance compared to standard methods.", "conclusion": "The general frameworks successfully stabilize Krylov subspace methods, making them more reliable for solving ill-conditioned large-scale linear systems and expanding their practical applicability in high-performance computing applications."}}
{"id": "2507.17463", "pdf": "https://arxiv.org/pdf/2507.17463", "abs": "https://arxiv.org/abs/2507.17463", "authors": ["Fanfei Meng", "Yilin Song", "Ruixiao Zhang"], "title": "Asymptotic behavior of mass-critical Schr\u00f6dinger equation in $ \\mathbb{R}$", "categories": ["math.AP", "35Q55"], "comment": null, "summary": "In this paper, we study the long-time behavior for the mass-critical\nnonlinear Schr\\\"odinger equation on the line\n  \\[\n  i\\partial_t u + \\partial_x^2 u = |u|^4 u,\n  u(0, x) = u_0 \\in L_x^2(\\Bbb R).\n  \\] The global well-posedness and scattering for this equation was solved in\nDodson [Amer. J. Math. (2016)]. Inspired by the pioneering work of\nKillip-Visan-Zhang [Amer. J. Math. (2021)], we show that solution can be\napproximated by a finite-dimensional Hamiltonian system. This system is the\nnonlinear Schr\\\"odinger equation on the rescaled torus $\\Bbb R/(L_n\\Bbb Z)$\nwith Fourier truncated nonlinear term. To prove this, we introduce the Fourier\ntruncated mass-critical NLS on $\\mathbb{R}$. First, we establish the uniformly\nglobal space-time bound for this truncated model on $\\mathbb{R}$. Second, we\nshow that the truncated NLS on rescaled torus can be approximated by the\ntruncated equation on $\\Bbb R$. Then, using the Gromov theorem, we can show the\nnon-squeezing property for the truncated NLS on torus. The last step to show\nthe non-squeezing property for original NLS is to connect the solution with\ntruncated nonlinearity and a single equation in $\\mathbb{R}$, which can be done\nby performing the nonlinear profile decomposition.\n  Our second result is to study the homogenization of the mass-critical\ninhomogeneous NLS, where we add a $L^\\infty$ function $h(nx)$ in front of the\nnonlinear term. Based on the method of Ntekoume [Comm. PDE, (2020)], we give\nthe sufficient condition on $h$ such that the scattering holds for this\ninhomogeneous model and show that the solution to inhomogeneous converges to\nthe homogeneous model when $n\\to\\infty$. As a corollary, we can transfer the\nnon-squeezing property from homogeneous model to inhomogeneous.", "AI": {"tldr": "This paper studies the long-time behavior of the mass-critical nonlinear Schr\u00f6dinger equation, proving that solutions can be approximated by finite-dimensional Hamiltonian systems and establishing non-squeezing properties. Additionally, it analyzes homogenization of inhomogeneous NLS equations and shows convergence to homogeneous models.", "motivation": "The motivation is to understand the long-time behavior of the mass-critical nonlinear Schr\u00f6dinger equation on the real line, particularly building upon previous work on global well-posedness and scattering. The authors are inspired by Killip-Visan-Zhang's pioneering work to show finite-dimensional approximations and extend results to inhomogeneous cases.", "method": "The method involves: (1) introducing Fourier truncated mass-critical NLS on \u211d and establishing uniform global space-time bounds, (2) showing that truncated NLS on rescaled torus approximates the truncated equation on \u211d, (3) using Gromov's theorem to prove non-squeezing property for truncated NLS on torus, (4) connecting solutions via nonlinear profile decomposition, and (5) applying Ntekoume's method for homogenization analysis of inhomogeneous NLS.", "result": "The main results are: (1) solutions to the mass-critical NLS can be approximated by finite-dimensional Hamiltonian systems (NLS on rescaled torus with Fourier truncated nonlinear terms), (2) establishment of non-squeezing property for both truncated and original NLS, (3) sufficient conditions for scattering in inhomogeneous NLS models, and (4) convergence of inhomogeneous solutions to homogeneous models as n\u2192\u221e.", "conclusion": "The paper successfully demonstrates that mass-critical NLS solutions admit finite-dimensional approximations and satisfy non-squeezing properties. For inhomogeneous cases, the authors establish conditions ensuring scattering behavior and prove convergence to homogeneous models, allowing transfer of non-squeezing properties from homogeneous to inhomogeneous systems."}}
{"id": "2507.17247", "pdf": "https://arxiv.org/pdf/2507.17247", "abs": "https://arxiv.org/abs/2507.17247", "authors": ["Deping Guo", "Jiaqi Dai", "Renhong Wang", "Cong Wang", "Wei Ji"], "title": "Mechanically and electrically switchable triferroic altermagnet in a pentagonal FeO2 monolayer", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Two-dimensional multiferroics promise low-power, multifunctional devices, yet\nthe intrinsic coexistence and mutual control of three coupled ferroic orders in\na single layer remains elusive. Here, we identify pentagonal monolayer FeO$_2$\nas an intrinsic triferroic altermagnet where ferroelectric (FE), ferroelastic\n(FA), and altermagnetic (AM) orders coexist and are tightly coupled,\naccompanied by a competing antiferroelectric (AFE) phase using first-principles\ncalculations. The sole presence of glide mirror $M_x$ symmetry in a FeO$_2$\nsublayer, with the breaking of four-fold rotation $C_{4z}$ symmetry, induces\nin-plane vector ferroelectricity and twin-related ferroelastic strains. Both FE\nand AFE phases break combined parity - time symmetry and display sizable\naltermagnetic spin splitting with N\\'eel temperatures over 200~K.\nElectric-field-induced rotation of the FE polarization reverses the sign of the\nspin splitting, while in-plane uniaxial strain triggers ferroelastic switching\nthat simultaneously rotates the FE polarization vector by $90^\\circ$ and\nreverses the AM state. These electric-field- and strain-mediated pathways\ninterlink six distinct polarization states that can be selected purely by\nelectric fields and/or mechanical strain. This work extends intrinsic\ntriferroicity to pentagonal monolayers and outlines a symmetry-based route\ntoward mechanically and electrically configurable altermagnetic spintronics.", "AI": {"tldr": "Researchers discovered pentagonal monolayer FeO\u2082 as an intrinsic triferroic altermagnet with coexisting ferroelectric, ferroelastic, and altermagnetic orders that can be controlled by electric fields and mechanical strain, enabling configurable spintronic devices.", "motivation": "Two-dimensional multiferroics are promising for low-power, multifunctional devices, but achieving intrinsic coexistence and mutual control of three coupled ferroic orders in a single layer has remained challenging.", "method": "First-principles calculations were used to study pentagonal monolayer FeO\u2082, analyzing its crystal symmetry (glide mirror Mx symmetry with broken four-fold rotation C4z symmetry) and the coupling between ferroelectric, ferroelastic, and altermagnetic orders.", "result": "The study identified six distinct polarization states that can be controlled by electric fields and mechanical strain. Electric-field-induced rotation of ferroelectric polarization reverses spin splitting sign, while uniaxial strain triggers ferroelastic switching that rotates polarization by 90\u00b0 and reverses the altermagnetic state. N\u00e9el temperatures exceed 200K.", "conclusion": "This work extends intrinsic triferroicity to pentagonal monolayers and provides a symmetry-based route toward mechanically and electrically configurable altermagnetic spintronics, offering new possibilities for multifunctional device applications."}}
{"id": "2507.17685", "pdf": "https://arxiv.org/pdf/2507.17685", "abs": "https://arxiv.org/abs/2507.17685", "authors": ["Maneesh Kumar Singh", "Joshua Hope-Collins", "Colin J. Cotter", "Dan Crisan"], "title": "Data assimilation using a global Girsanov nudged particle filter", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We present a particle filtering algorithm for stochastic models on infinite\ndimensional state space, making use of Girsanov perturbations to nudge the\nensemble of particles into regions of higher likelihood. We argue that the\noptimal control problem needs to couple control variables for all of the\nparticles to maintain an ensemble with good effective sample size (ESS). We\nprovide an optimisation formulation that separates the problem into three\nstages, separating the nonlinearity in the ESS term in the functional with the\nnonlinearity due to the forward problem, and allowing independent parallel\ncomputation for each particle when calculations are performed over control\nvariable space. The particle filter is applied to the stochastic\nKuramoto-Sivashinsky equation, and compared with the temper-jitter particle\nfilter approach. We observe that whilst the nudging filter is over spread\ncompared to the temper-jitter filter, it responds to extreme events in the\nassimilated data more quickly and robustly.", "AI": {"tldr": "A particle filtering algorithm for infinite dimensional stochastic models using Girsanov perturbations to nudge particles toward high-likelihood regions, with optimized control coupling and three-stage computation framework.", "motivation": "Traditional particle filters struggle with stochastic models on infinite dimensional state spaces due to particle degeneracy and poor effective sample size, requiring better methods to guide particles toward regions of higher likelihood.", "method": "Developed a particle filtering algorithm using Girsanov perturbations with coupled control variables across all particles, implemented through a three-stage optimization formulation that separates nonlinearities in ESS terms from forward problem nonlinearities, enabling parallel computation.", "result": "Applied to stochastic Kuramoto-Sivashinsky equation, the nudging filter showed faster and more robust response to extreme events in assimilated data compared to temper-jitter particle filter, though with greater spread.", "conclusion": "The proposed nudging particle filter with coupled control variables effectively handles infinite dimensional stochastic models and provides superior responsiveness to extreme data events, despite being more spread than alternative approaches."}}
{"id": "2507.17465", "pdf": "https://arxiv.org/pdf/2507.17465", "abs": "https://arxiv.org/abs/2507.17465", "authors": ["Leandro G. Fernandes Jr.", "Edir J. F. Leite"], "title": "On a global estimate and a Stampacchia-type maximum principle for Lane-Emden systems", "categories": ["math.AP"], "comment": null, "summary": "We establish a global boundedness result for Lane-Emden systems involving\ngeneral second-order elliptic operators in divergence form and arbitrary\npositive exponents whose product equals one. Furthermore, we observe that, for\nthis class of systems -- and for certain operators in divergence form,\nincluding the case when both operators are the Laplacian -- it is not possible\nto recover the classical Stampacchia maximum principle as a particular case\ncorresponding to single equations.", "AI": {"tldr": "This paper proves global boundedness for Lane-Emden systems with general second-order elliptic operators in divergence form when exponents multiply to one, and shows that the classical Stampacchia maximum principle cannot be recovered as a special case for certain operators including the Laplacian.", "motivation": "To establish boundedness properties for Lane-Emden systems with general elliptic operators and understand the limitations of extending classical maximum principles from single equations to systems of equations.", "method": "Mathematical analysis using second-order elliptic operators in divergence form, focusing on systems where the product of positive exponents equals one, and examining the applicability of maximum principle techniques.", "result": "Achieved global boundedness for the specified class of Lane-Emden systems and demonstrated that the Stampacchia maximum principle cannot be recovered as a particular case for certain divergence form operators, including when both operators are Laplacians.", "conclusion": "The work successfully extends boundedness theory to Lane-Emden systems with general elliptic operators while revealing fundamental limitations in applying classical maximum principles to multi-equation systems, even in cases involving standard Laplacian operators."}}
{"id": "2507.17250", "pdf": "https://arxiv.org/pdf/2507.17250", "abs": "https://arxiv.org/abs/2507.17250", "authors": ["Dinesh Kumar Panda", "Colin Benjamin"], "title": "Quantum walks reveal topological flat bands, robust edge states and topological phase transitions in cyclic graphs", "categories": ["quant-ph", "cond-mat.dis-nn", "hep-ph", "math-ph", "math.MP", "physics.comp-ph"], "comment": "22 pages, 19 figures, 1 table", "summary": "Topological phases, edge states, and flat bands in synthetic quantum systems\nare a key resource for topological quantum computing and noise-resilient\ninformation processing. We introduce a scheme based on step-dependent quantum\nwalks on cyclic graphs, termed cyclic quantum walks (CQWs), to simulate exotic\ntopological phenomena using discrete Fourier transforms and an effective\nHamiltonian. Our approach enables the generation of both gapped and gapless\ntopological phases, including Dirac cone-like energy dispersions, topologically\nnontrivial flat bands, and protected edge states, all without resorting to\nsplit-step or split-coin protocols. Odd and even-site cyclic graphs exhibit\nmarkedly different spectral characteristics, with rotationally symmetric flat\nbands emerging exclusively $4n$-site graphs ($n\\in \\mathbf{N}$). We\nanalytically establish the conditions for the emergence of topological, gapped\nflat bands and show that gap closings in rotation space imply the formation of\nDirac cones in momentum space. Further, we engineer protected edge states at\nthe interface between distinct topological phases in both odd and even cycle\ngraphs. We numerically demonstrate that the edge states are robust against\nmoderate static and dynamic gate disorder and remain stable against\nphase-preserving perturbations. This scheme serves as a resource-efficient and\nversatile platform for engineering topological phases, transitions, edge\nstates, and flat bands in quantum systems, opening new avenues for\nfault-tolerant quantum technologies.", "AI": {"tldr": "This paper introduces cyclic quantum walks (CQWs) as a novel scheme to simulate topological phenomena in quantum systems, enabling the generation of various topological phases, flat bands, and protected edge states without complex protocols.", "motivation": "To develop a resource-efficient platform for simulating exotic topological phenomena in synthetic quantum systems, which are crucial for topological quantum computing and noise-resilient information processing, without requiring complex split-step or split-coin protocols.", "method": "The authors propose step-dependent quantum walks on cyclic graphs (CQWs) using discrete Fourier transforms and an effective Hamiltonian approach. They analyze odd and even-site cyclic graphs to study their spectral characteristics and topological properties.", "result": "The scheme successfully generates both gapped and gapless topological phases, including Dirac cone-like energy dispersions and topologically nontrivial flat bands. Rotationally symmetric flat bands emerge exclusively in 4n-site graphs. Protected edge states are engineered at interfaces between distinct topological phases, and these states remain robust against moderate static/dynamic gate disorder and phase-preserving perturbations.", "conclusion": "Cyclic quantum walks provide a versatile and resource-efficient platform for engineering topological phases, transitions, edge states, and flat bands in quantum systems, opening new possibilities for fault-tolerant quantum technologies and topological quantum computing applications."}}
{"id": "2507.17723", "pdf": "https://arxiv.org/pdf/2507.17723", "abs": "https://arxiv.org/abs/2507.17723", "authors": ["Abelardo Torres Alba", "Jorge Manuel Mercado Colmenero", "Juan de Dios Caballero Garcia", "Cristina Martin Donate"], "title": "Application of new conformal cooling layouts to the green injection molding of complex slender polymeric parts with high dimensional specifications", "categories": ["cs.CE"], "comment": null, "summary": "Eliminating warpage in injection molded polymeric parts is one of the most\nimportant problems in the injection molding industry today. This situation is\ncritical in geometries that are particularly susceptible to warping due to\ntheir geometric features, and this occurs with topologies of great length and\nslenderness with high changes in thickness. These features are, in these\nspecial geometries, impossible to manufacture with traditional technologies to\nmeet the dimensional and sustainable requirements of the industry. This paper\npresents an innovative green conformal cooling system that is specifically\ndesigned for parts with slender geometric shapes that are highly susceptible to\nwarping. Additionally, the work presented by the authors investigates the\nimportance of using highly conductive inserts made of steel alloys in\ncombination with the use of additively manufactured conformal channels for\nreducing influential parameters, such as warpage, cooling time, and residual\nstresses in the complex manufacturing of long and slender parts. The results of\nthis real industrial case study indicated that the use of conformal cooling\nlayouts decreased the cycle time by 175.1 s 66% below the current cooling time;\nthe temperature gradient by 78.5% specifically, 18.16 C; the residual stress by\n39.78 MPa or 81.88%; and the warpage by 6.9 mm or 90.5%. In this way, it was\npossible to achieve a final warping in the complex geometry studied of 0.72 mm,\nwhich was under the maximum value required at the industrial level of 1 mm. The\nresulting values obtained by the researchers present a turning point from which\nthe manufacturing and sustainability in the injection molding of said plastic\ngeometries is possible, and they take into account that the geometric\nmanufacturing features analyzed will present a great demand in the coming years\nin the auto parts manufacturing industry.", "AI": {"tldr": "This paper presents an innovative green conformal cooling system for injection molding that significantly reduces warpage in long, slender plastic parts by using additively manufactured cooling channels and highly conductive steel inserts, achieving 90.5% warpage reduction and meeting industrial requirements.", "motivation": "Eliminating warpage in injection molded polymeric parts is critical, especially for long and slender geometries with high thickness variations that are impossible to manufacture with traditional technologies while meeting dimensional and sustainability requirements of the industry.", "method": "The authors developed an innovative green conformal cooling system specifically designed for slender geometric shapes, combining highly conductive steel alloy inserts with additively manufactured conformal cooling channels to address warpage, cooling time, and residual stresses in complex manufacturing processes.", "result": "The conformal cooling system achieved remarkable improvements: 66% reduction in cycle time (175.1s decrease), 78.5% reduction in temperature gradient (18.16\u00b0C), 81.88% reduction in residual stress (39.78 MPa), and 90.5% reduction in warpage (6.9mm), resulting in final warping of 0.72mm which meets the industrial requirement of <1mm.", "conclusion": "The research demonstrates a turning point that makes manufacturing and sustainability possible for complex plastic geometries in injection molding, with particular relevance for the auto parts manufacturing industry where such geometric features will be in high demand in coming years."}}
{"id": "2507.17565", "pdf": "https://arxiv.org/pdf/2507.17565", "abs": "https://arxiv.org/abs/2507.17565", "authors": ["Xin Yang"], "title": "Global well-posedness of the Majda-Biello system in the resonant case on the real line", "categories": ["math.AP"], "comment": "34 pages", "summary": "We study the Cauchy problem for the following Majda-Biello system in the case\n$\\alpha=4$, which has the most significant resonance effect, on the real line.\n\\[ \\left\\{ \\begin{array}{l}\n  u_{t} + u_{xxx} = - v v_x,\n  v_{t} + \\alpha v_{xxx} = - (uv)_{x},\n  (u,v)|_{t=0} = (u_0,v_0) \\in H^{s}(\\mathbb{R}) \\times H^{s}(\\mathbb{R}),\n\\end{array} \\right. \\quad x \\in \\mathbb{R}, \\, t \\in \\mathbb{R}. \\] For Sobolev\nregularity $s\\in[\\frac34, 1)$, we establish the global well-posedness by\nrefining the I-method. Previously, the critical index for the local\nwell-posedness was known to be $\\frac34$, while the global well-posedness was\nonly obtained for $s\\geq 1$. Our global well-posedness result bridges the gap\nand matches the threshold in the local theory. The main novelty of our approach\nis to introduce a pair of distinct $I$-operators, tailored to the resonant\nstructure of the Majda-Biello system with $\\alpha=4$. This dual-operator\nframework allows for pointwise control of the multipliers in the modified\nenergies constructed via the multilinear correction technique. These modified\nenergies are almost conserved and provide effective control over the Sobolev\nnorm of the solution globally in time. This new approach has potential\napplications to other coupled dispersive systems exhibiting strong resonant\ninteractions.", "AI": {"tldr": "This paper establishes global well-posedness for the Majda-Biello system with \u03b1=4 in the critical Sobolev regularity range s\u2208[3/4, 1) by developing a refined I-method with dual operators, bridging the gap between local and global theory.", "motivation": "The Majda-Biello system with \u03b1=4 exhibits the most significant resonance effects, and while local well-posedness was known for s\u22653/4 and global well-posedness for s\u22651, there was a gap in the critical regularity range s\u2208[3/4, 1) that needed to be addressed to match the local theory threshold.", "method": "The authors refine the I-method by introducing a pair of distinct I-operators specifically tailored to the resonant structure of the Majda-Biello system with \u03b1=4. They use a dual-operator framework combined with multilinear correction techniques to construct modified energies that provide pointwise control of multipliers.", "result": "Global well-posedness is established for the Majda-Biello system with \u03b1=4 in the Sobolev regularity range s\u2208[3/4, 1), successfully bridging the gap between local and global theory. The modified energies constructed are almost conserved and provide effective control over the Sobolev norm globally in time.", "conclusion": "The dual I-operator approach successfully extends global well-posedness to the critical regularity range, matching the local theory threshold. This new framework has potential applications to other coupled dispersive systems with strong resonant interactions, representing a significant advancement in the analysis of such systems."}}
{"id": "2507.17295", "pdf": "https://arxiv.org/pdf/2507.17295", "abs": "https://arxiv.org/abs/2507.17295", "authors": ["Mengjie Yang", "Ching Hua Lee"], "title": "Beyond symmetry protection: Robust feedback-enforced edge states in non-Hermitian stacked quantum spin Hall systems", "categories": ["cond-mat.mes-hall", "cond-mat.other", "math-ph", "math.MP", "physics.comp-ph", "quant-ph"], "comment": "Any comments are welcome", "summary": "Conventional wisdom holds that strongly coupling two QSH layers yields a\ntrivial $\\mathbb{Z}_2$ phase and no protected topological edge states. We\ndemonstrate that, in a regime with intermediate inter-layer coupling (neither\nin the strong or weak coupling regimes) and competitive non-Hermitian directed\namplification, bulk modes are suppressed while arbitrary bulk excitations\ninevitably accumulate into robust helical edge transport modes - without\nrelying on any symmetry protection. Our feedback-enforced mechanism persists\nover broad parameter ranges and remains robust even on fractal or irregular\nboundaries. These findings challenge the traditional view of stacked QSH\ninsulators as inevitably trivial, and open up new avenues for designing helical\ntopological devices that exploit feedback-enforced non-Hermitian engineering,\ninstead of symmetry-enforced robustness.", "AI": {"tldr": "This paper demonstrates that coupling two quantum spin Hall (QSH) layers with intermediate strength and non-Hermitian directed amplification can create robust helical edge transport modes without symmetry protection, challenging the conventional view that strongly coupled QSH layers become trivial.", "motivation": "Conventional wisdom suggests that strongly coupling two QSH layers results in a trivial topological phase with no protected edge states. The authors aim to challenge this traditional view and explore alternative mechanisms for creating robust helical transport modes in stacked QSH systems.", "method": "The authors employ intermediate inter-layer coupling (between strong and weak coupling regimes) combined with competitive non-Hermitian directed amplification. This feedback-enforced mechanism suppresses bulk modes while accumulating bulk excitations into helical edge transport modes without relying on symmetry protection.", "result": "The mechanism successfully creates robust helical edge transport modes that persist over broad parameter ranges and remain stable even on fractal or irregular boundaries. Bulk excitations inevitably accumulate into these edge modes while bulk transport is suppressed.", "conclusion": "The findings challenge the traditional understanding of stacked QSH insulators as inevitably trivial and open new possibilities for designing helical topological devices using feedback-enforced non-Hermitian engineering rather than conventional symmetry-enforced robustness."}}
{"id": "2507.16915", "pdf": "https://arxiv.org/pdf/2507.16915", "abs": "https://arxiv.org/abs/2507.16915", "authors": ["April Herwig", "Matthew J. Colbrook", "Oliver Junge", "P\u00e9ter Koltai", "Julia Slipantschuk"], "title": "Avoiding spectral pollution for transfer operators using residuals", "categories": ["math.DS", "cs.LG", "cs.NA", "math.NA", "math.SP", "stat.ML"], "comment": null, "summary": "Koopman operator theory enables linear analysis of nonlinear dynamical\nsystems by lifting their evolution to infinite-dimensional function spaces.\nHowever, finite-dimensional approximations of Koopman and transfer\n(Frobenius--Perron) operators are prone to spectral pollution, introducing\nspurious eigenvalues that can compromise spectral computations. While recent\nadvances have yielded provably convergent methods for Koopman operators,\nanalogous tools for general transfer operators remain limited. In this paper,\nwe present algorithms for computing spectral properties of transfer operators\nwithout spectral pollution, including extensions to the Hardy-Hilbert space.\nCase studies--ranging from families of Blaschke maps with known spectrum to a\nmolecular dynamics model of protein folding--demonstrate the accuracy and\nflexibility of our approach. Notably, we demonstrate that spectral features can\narise even when the corresponding eigenfunctions lie outside the chosen space,\nhighlighting the functional-analytic subtleties in defining the \"true\" Koopman\nspectrum. Our methods offer robust tools for spectral estimation across a broad\nrange of applications.", "AI": {"tldr": "This paper presents new algorithms for computing spectral properties of transfer operators without spectral pollution, extending beyond Koopman operators to provide robust spectral estimation tools for nonlinear dynamical systems.", "motivation": "Finite-dimensional approximations of Koopman and transfer operators suffer from spectral pollution, which introduces spurious eigenvalues that compromise spectral computations. While provably convergent methods exist for Koopman operators, analogous tools for general transfer operators are limited.", "method": "The authors develop algorithms for computing spectral properties of transfer operators without spectral pollution, including extensions to the Hardy-Hilbert space. The approach addresses the functional-analytic subtleties in defining the \"true\" Koopman spectrum.", "result": "Case studies demonstrate the accuracy and flexibility of the approach, ranging from families of Blaschke maps with known spectrum to molecular dynamics models of protein folding. The methods successfully identify spectral features even when corresponding eigenfunctions lie outside the chosen space.", "conclusion": "The proposed methods offer robust tools for spectral estimation across a broad range of applications, providing pollution-free spectral analysis for transfer operators and advancing the computational capabilities for nonlinear dynamical systems analysis."}}
{"id": "2507.17644", "pdf": "https://arxiv.org/pdf/2507.17644", "abs": "https://arxiv.org/abs/2507.17644", "authors": ["Qing Guo", "Angela Pistoia", "Shixin Wen"], "title": "Segregated solutions for a class of systems with Lotka-Volterra interaction", "categories": ["math.AP"], "comment": null, "summary": "This paper deals with the existence of positive solutions to the system\n  $$ -\\Delta w_1 - \\varepsilon w_1 = \\mu_{1} w_1^{p} + \\beta w_1 w_2\\ \\text{in\n} \\Omega,\\\n  -\\Delta w_2 - \\varepsilon w_2 = \\mu_{2} w_2^{p} + \\beta w_1 w_2 \\ \\text{in }\n\\Omega,\\\n  w_1 = w_2 = 0 \\ \\text{on } \\partial \\Omega,\n  $$\n  where $\\Omega \\subseteq \\mathbb{R}^{N}$, $N \\ge 4$, $ p ={N+2\\over N-2}$ and\n$ \\varepsilon $ is positive and sufficiently small. The interaction coefficient\n$ \\beta = \\beta(\\varepsilon) \\to 0 $ as $ \\varepsilon \\to 0 $.\n  We construct a family of segregated solutions to this system, where each\ncomponent blows-up at a different critical point of the Robin function as\n$\\varepsilon \\to 0. The system lacks a variational formulation due to its\nspecific coupling form,\n  which leads to essentially different behaviors in the subcritical, critical,\nand supercritical regimes and requires an\n  appropriate functional settings to carry out the construction.", "AI": {"tldr": "This paper constructs segregated solutions for a coupled elliptic system with critical nonlinearity where components blow up at different critical points of the Robin function as a parameter approaches zero, despite the system lacking a variational structure.", "motivation": "The system studied lacks a variational formulation due to its specific coupling form, which creates essentially different behaviors in subcritical, critical, and supercritical regimes. This non-variational nature makes it challenging to analyze and requires new approaches beyond standard variational methods.", "method": "The authors develop appropriate functional settings to construct solutions despite the lack of variational structure. They work with a coupled elliptic system where the interaction coefficient \u03b2(\u03b5) \u2192 0 as \u03b5 \u2192 0, and use techniques that can handle the critical Sobolev exponent p = (N+2)/(N-2) in dimensions N \u2265 4.", "result": "The paper successfully constructs a family of segregated solutions where each component of the solution blows up at a different critical point of the Robin function as the parameter \u03b5 approaches zero. These solutions demonstrate the existence of positive solutions to the non-variational system.", "conclusion": "The authors prove the existence of segregated positive solutions for a coupled elliptic system with critical nonlinearity that lacks variational structure. The construction works for the critical Sobolev exponent and shows that each solution component concentrates at distinct critical points of the Robin function in the limit."}}
{"id": "2507.17414", "pdf": "https://arxiv.org/pdf/2507.17414", "abs": "https://arxiv.org/abs/2507.17414", "authors": ["Pawel Wojda"], "title": "The $n$-body problem -- an alternative scheme for determining solutions for planetary systems", "categories": ["astro-ph.EP", "physics.comp-ph"], "comment": "18 pages, 6 figures", "summary": "This study presents a general alternative scheme of the procedure and\nnecessary conditions for solving the $n$-body problem. The presented solution\nis not a solution of the classical problem, where the initial conditions of\npositions and initial velocities/momenta of the bodies are known. Starting from\nthe standard initial condition the procedure treats contributions to momentum\nfrom particular pair-wise interactions as independent variables from which the\ntotal momentum and velocity of a given mass is then reproduced. Initial values\nof those contributions are arbitrary as long as the resulting velocities match\nthe initial condition. The obtained solutions take into account the\ngravitational interactions between each pair of bodies, as a result of which\nthey are characterized by higher stability than the solutions of the classical\nproblem. The presented procedure was used to calculate the positions and mutual\nvelocities of three bodies: the Sun, the Earth and the Moon. It has also been\ntested for our entire planetary system (8 planets) with the Sun and the Moon.\nFor these types of systems, the method allows obtaining solutions that are\nstable. The procedure was also tested on the example of the Pythagorean system\nof bodies.", "AI": {"tldr": "This paper presents an alternative approach to solving the n-body problem by treating pair-wise momentum contributions as independent variables rather than using classical initial conditions, resulting in more stable gravitational system solutions.", "motivation": "The classical n-body problem with known initial positions and velocities often produces unstable solutions. The authors aim to develop a more stable alternative approach that better accounts for gravitational interactions between all pairs of bodies in the system.", "method": "The method treats momentum contributions from each pair-wise gravitational interaction as independent variables, with arbitrary initial values as long as they reproduce the correct total velocities. The total momentum and velocity of each mass is then reconstructed from these individual pair-wise contributions, incorporating all gravitational interactions between body pairs.", "result": "The method was successfully tested on multiple systems: Sun-Earth-Moon three-body system, the complete solar system (8 planets + Sun + Moon), and the Pythagorean system. All tests demonstrated improved stability compared to classical n-body problem solutions, with the method able to produce stable solutions for these gravitational systems.", "conclusion": "The alternative scheme provides a viable approach to solving n-body problems with enhanced stability by decomposing momentum into pair-wise interaction contributions. This method offers advantages over classical approaches for calculating long-term dynamics of gravitational systems like planetary systems."}}
{"id": "2507.16995", "pdf": "https://arxiv.org/pdf/2507.16995", "abs": "https://arxiv.org/abs/2507.16995", "authors": ["Di Fang", "David Lloyd George", "Yu Tong"], "title": "Qubit-Efficient Quantum Algorithm for Linear Differential Equations", "categories": ["quant-ph", "cs.NA", "math.NA"], "comment": null, "summary": "As quantum hardware rapidly advances toward the early fault-tolerant era, a\nkey challenge is to develop quantum algorithms that are not only theoretically\nsound but also hardware-friendly on near-term devices. In this work, we propose\na quantum algorithm for solving linear ordinary differential equations (ODEs)\nwith a provable runtime guarantee. Our algorithm uses only a single ancilla\nqubit, and is locality preserving, i.e., when the coefficient matrix of the ODE\nis $k$-local, the algorithm only needs to implement the time evolution of\n$(k+1)$-local Hamiltonians. We also discuss the connection between our proposed\nalgorithm and Lindbladian simulation as well as its application to the\ninteracting Hatano-Nelson model, a widely studied non-Hermitian model with rich\nphenomenology.", "AI": {"tldr": "A quantum algorithm for solving linear ODEs that uses only one ancilla qubit and preserves locality, making it suitable for near-term quantum devices with provable runtime guarantees.", "motivation": "As quantum hardware advances toward fault-tolerant computing, there's a critical need to develop quantum algorithms that are both theoretically rigorous and practical for near-term quantum devices with limited resources and connectivity constraints.", "method": "The authors propose a quantum algorithm that solves linear ordinary differential equations using only a single ancilla qubit while maintaining locality preservation - when the ODE coefficient matrix is k-local, the algorithm only requires implementing (k+1)-local Hamiltonian time evolution.", "result": "The algorithm achieves provable runtime guarantees while being hardware-friendly for near-term devices. The authors establish connections to Lindbladian simulation and demonstrate applicability to the interacting Hatano-Nelson model, a well-studied non-Hermitian system.", "conclusion": "The proposed quantum algorithm successfully bridges theoretical quantum computing with practical hardware constraints, offering an efficient solution for linear ODE problems that can be implemented on current and near-future quantum devices while maintaining locality and using minimal ancilla resources."}}
{"id": "2507.17675", "pdf": "https://arxiv.org/pdf/2507.17675", "abs": "https://arxiv.org/abs/2507.17675", "authors": ["P. Cannarsa", "G. Floridia", "M. Yamamoto"], "title": "Carleman estimate with piecewise weight and applications to inverse problems for first-order transport equations", "categories": ["math.AP", "35R30"], "comment": null, "summary": "We consider a first-order transport equation $\\ppp_tu(x,t) + (H(x)\\cdot\\nabla\nu(x,t)) + p(x)u(x,t) = F(x,t)$ for $x \\in \\OOO \\subset \\R^d$, where $\\OOO$ is a\nbounded domain and $0<t<T$. We prove a Carleman estimate for more generous\ncondition on the principal coefficients $H(x)$ than in the existing works. The\nkey is the construction of a piecewise smooth weight function in $x$ according\nto a suitable decomposition of $\\OOO$. Our assumptions on $H$ generalize the\nconditions in the existing articles, and require that a directed graph created\nby the corresponding stream field has no closed loops. Then, we apply our\nCarleman estimate to two inverse problems of determinination of an initial\nvalue and one of a spatial factor of a source term, so that we establish\nLipschitz stability estimates for the inverse problems.", "AI": {"tldr": "This paper proves improved Carleman estimates for first-order transport equations with more general coefficient conditions and applies them to establish Lipschitz stability for inverse problems involving initial value and source term determination.", "motivation": "Existing Carleman estimates for first-order transport equations require restrictive conditions on the principal coefficients H(x). The authors aim to generalize these conditions and develop more flexible estimates that can handle broader classes of transport problems while maintaining their applicability to inverse problems.", "method": "The key methodological innovation is constructing a piecewise smooth weight function in x based on a suitable decomposition of the domain \u03a9. The approach requires that the directed graph created by the corresponding stream field has no closed loops, which generalizes previous restrictive conditions on H(x).", "result": "The authors successfully prove Carleman estimates under more generous conditions on the principal coefficients H(x) than previously available. They then apply these estimates to two specific inverse problems: determining an initial value and determining a spatial factor of a source term, establishing Lipschitz stability estimates for both cases.", "conclusion": "The paper extends the theoretical framework for Carleman estimates in transport equations by relaxing coefficient restrictions through innovative weight function construction. The practical impact is demonstrated through applications to inverse problems, where Lipschitz stability is established under the new generalized conditions."}}
{"id": "2507.17421", "pdf": "https://arxiv.org/pdf/2507.17421", "abs": "https://arxiv.org/abs/2507.17421", "authors": ["Hrvoje Vrcan", "Johan H. Mentink"], "title": "Instability of explicit time integration for strongly quenched dynamics with neural quantum states", "categories": ["quant-ph", "cond-mat.dis-nn", "physics.comp-ph"], "comment": "17 pages, 4 figures, 1 table, related repository:\n  https://github.com/HVrcan/lattice_nqs", "summary": "Neural quantum states have recently demonstrated significant potential for\nsimulating quantum dynamics beyond the capabilities of existing variational\nans\\\"atze. However, studying strongly driven quantum dynamics with neural\nnetworks has proven challenging so far. Here, we focus on assessing several\nsources of numerical instabilities that can appear in the simulation of quantum\ndynamics based on the time-dependent variational principle (TDVP) with the\ncomputationally efficient explicit time integration scheme. Using the\nrestricted Boltzmann machine architecture, we compare solutions obtained by\nTDVP with analytical solutions and implicit methods as a function of the quench\nstrength. Interestingly, we uncover a quenching strength that leads to a\nnumerical breakdown in the absence of Monte Carlo noise, despite the fact that\nphysical observables don't exhibit irregularities. This breakdown phenomenon\nappears consistently across several different TDVP formulations, even those\nthat eliminate small eigenvalues of the Fisher matrix or use geometric\nproperties to recast the equation of motion. We conclude that alternative\nmethods need to be developed to leverage the computational efficiency of\nexplicit time integration of the TDVP equations for simulating strongly\nnonequilibrium quantum dynamics with neural-network quantum states.", "AI": {"tldr": "This paper investigates numerical instabilities in neural quantum state simulations of strongly driven quantum dynamics using time-dependent variational principle (TDVP) with explicit time integration, revealing a critical quenching strength that causes numerical breakdown even when physical observables remain regular.", "motivation": "Neural quantum states show promise for simulating quantum dynamics beyond traditional variational methods, but studying strongly driven quantum dynamics with neural networks remains challenging due to numerical instabilities that need to be understood and addressed.", "method": "The authors use restricted Boltzmann machine architecture to implement TDVP with explicit time integration schemes, comparing solutions with analytical results and implicit methods across different quench strengths. They test multiple TDVP formulations including those that eliminate small Fisher matrix eigenvalues and use geometric properties.", "result": "A specific quenching strength was identified that consistently causes numerical breakdown across different TDVP formulations, even when physical observables show no irregularities. This breakdown occurs even in the absence of Monte Carlo noise and persists across various mathematical reformulations of the equations of motion.", "conclusion": "The study concludes that current explicit time integration schemes for TDVP equations are insufficient for simulating strongly nonequilibrium quantum dynamics with neural-network quantum states, and alternative computational methods must be developed to maintain efficiency while ensuring numerical stability."}}
{"id": "2507.17036", "pdf": "https://arxiv.org/pdf/2507.17036", "abs": "https://arxiv.org/abs/2507.17036", "authors": ["Edem Boahen", "Simone Brugiapaglia", "Hung-Hsu Chou", "Mark Iwen", "Felix Krahmer"], "title": "Fast One-Pass Sparse Approximation of the Top Eigenvectors of Huge Low-Rank Matrices? Yes, $MAM^*$!", "categories": ["cs.IT", "cs.DS", "cs.NA", "math.IT", "math.NA"], "comment": null, "summary": "Motivated by applications such as sparse PCA, in this paper we present\nprovably-accurate one-pass algorithms for the sparse approximation of the top\neigenvectors of extremely massive matrices based on a single compact linear\nsketch. The resulting compressive-sensing-based approaches can approximate the\nleading eigenvectors of huge approximately low-rank matrices that are too large\nto store in memory based on a single pass over its entries while utilizing a\ntotal memory footprint on the order of the much smaller desired sparse\neigenvector approximations. Finally, the compressive sensing recovery algorithm\nitself (which takes the gathered compressive matrix measurements as input, and\nthen outputs sparse approximations of its top eigenvectors) can also be\nformulated to run in a time which principally depends on the size of the sought\nsparse approximations, making its runtime sublinear in the size of the large\nmatrix whose eigenvectors one aims to approximate. Preliminary experiments on\nhuge matrices having $\\sim 10^{16}$ entries illustrate the developed theory and\ndemonstrate the practical potential of the proposed approach.", "AI": {"tldr": "This paper presents one-pass algorithms for sparse approximation of top eigenvectors of massive matrices using compressive sensing, requiring only memory proportional to the sparse output size rather than the full matrix size.", "motivation": "The need to compute sparse principal component analysis (sparse PCA) and eigenvector approximations for extremely massive matrices that are too large to store in memory, requiring memory-efficient single-pass algorithms.", "method": "Compressive-sensing-based one-pass algorithms that use a single compact linear sketch to approximate leading eigenvectors of huge approximately low-rank matrices, with recovery algorithms that run in time sublinear to the original matrix size.", "result": "The algorithms can approximate top eigenvectors using memory footprint proportional to the desired sparse approximations rather than the full matrix, with runtime principally dependent on the sparse approximation size. Experiments on matrices with ~10^16 entries demonstrate practical feasibility.", "conclusion": "The proposed compressive sensing approach enables provably-accurate sparse eigenvector approximation for massive matrices in a single pass with dramatically reduced memory requirements and sublinear runtime complexity."}}
{"id": "2507.16457", "pdf": "https://arxiv.org/pdf/2507.16457", "abs": "https://arxiv.org/abs/2507.16457", "authors": ["Hemanta Mandal"], "title": "Exactness, Cohomology, and Uniqueness in First-Order Differential Equations", "categories": ["math.DS", "math.AP", "math.AT", "math.DG", "Primary 34A05, 58A12, Secondary 34A25, 55N30"], "comment": null, "summary": "This paper investigates the relationship between the solvability of\nfirst-order differential equations and the topology of the underlying domain\nthrough the lens of de\\,Rham cohomology. We analyze the conditions under which\na closed 1-form associated with a first-order ODE admits a global potential,\nthereby reducing the problem to the exactness of differential forms. While it\nis well known that exactness is guaranteed on simply connected domains, we show\nthat triviality of the first de\\,Rham cohomology group is the more fundamental\nrequirement for global integrability and uniqueness of solutions. In\nparticular, we demonstrate that certain non-simply connected manifolds, such as\nthe real projective plane $\\mathbb{RP}^2$, still support global solutions due\nto the vanishing of $H^1_{\\text{dR}}$. By explicitly constructing examples on\n$\\mathbb{RP}^2$ and comparing them with domains like $\\mathbb{R}^2 \\setminus\n\\{0\\}$, we illustrate how topological obstructions manifest analytically as\nnon-uniqueness or multi-valued behavior. We further discuss the correspondence\nbetween integrating factors and the trivialization of cohomology classes,\ndrawing connections to classical symmetry methods and potential theory. This\nsynthesis of geometric, topological, and analytic perspectives provides a\nunifying framework for understanding the global behavior of first-order ODEs\nbeyond local existence theorems.", "AI": {"tldr": "This paper explores how the topology of domains affects the solvability of first-order differential equations using de Rham cohomology, showing that vanishing first cohomology groups (not just simple connectivity) is the key requirement for global solutions.", "motivation": "While local existence theorems for first-order ODEs are well-established, understanding their global behavior requires examining the relationship between differential equation solvability and the topological properties of the underlying domain, particularly moving beyond the traditional requirement of simple connectivity.", "method": "The authors use de Rham cohomology theory to analyze closed 1-forms associated with first-order ODEs, focusing on conditions for global potential existence. They construct explicit examples on non-simply connected manifolds like the real projective plane \u211dP\u00b2 and compare with domains like \u211d\u00b2\\{0} to demonstrate topological effects.", "result": "The study demonstrates that triviality of the first de Rham cohomology group H\u00b9_dR is the fundamental requirement for global integrability, not simple connectivity. Non-simply connected manifolds like \u211dP\u00b2 can still support global solutions due to vanishing H\u00b9_dR, while topological obstructions manifest as non-uniqueness or multi-valued behavior in other cases.", "conclusion": "The paper provides a unifying geometric-topological-analytic framework for understanding global behavior of first-order ODEs, establishing the correspondence between integrating factors and cohomology class trivialization, and connecting classical symmetry methods with modern topological tools beyond local existence theorems."}}
{"id": "2507.17069", "pdf": "https://arxiv.org/pdf/2507.17069", "abs": "https://arxiv.org/abs/2507.17069", "authors": ["Xuemei Chen", "Owen Deen"], "title": "The Generalized Matrix Separation Problem: Algorithms", "categories": ["math.OC", "cs.NA", "math.NA"], "comment": "24 pages", "summary": "When given a generalized matrix separation problem, which aims to recover a\nlow rank matrix $L_0$ and a sparse matrix $S_0$ from $M_0=L_0+HS_0$, the work\n\\cite{CW25} proposes a novel convex optimization problem whose objective\nfunction is the sum of the $\\ell_1$-norm and nuclear norm. In this paper we\ndetail the iterative algorithms and its associated computations for solving\nthis convex optimization problem. We present various efficient implementation\nstrategies, with attention to practical cases where $H$ is circulant,\nseparable, or block structured. Notably, we propose a preconditioning technique\nthat drastically improved the performance of our algorithms in terms of\nefficiency, accuracy, and robustness. While this paper serves as an\nillustrative algorithm implementation manual, we also provide theoretical\nguarantee for our preconditioning strategy. Numerical results illustrate the\neffectiveness of the proposed approach.", "AI": {"tldr": "This paper presents efficient iterative algorithms and implementation strategies for solving a convex optimization problem that recovers low-rank and sparse matrices from their corrupted observations, with a focus on practical matrix structures and a novel preconditioning technique.", "motivation": "The motivation is to develop practical and efficient algorithms for the generalized matrix separation problem, which aims to recover a low-rank matrix L\u2080 and a sparse matrix S\u2080 from their corrupted observation M\u2080=L\u2080+HS\u2080, building upon the convex optimization framework proposed in prior work.", "method": "The authors develop iterative algorithms for solving the convex optimization problem with \u2113\u2081-norm and nuclear norm regularization. They focus on efficient implementation strategies for practical cases where H has special structures (circulant, separable, or block structured) and propose a novel preconditioning technique to improve algorithm performance.", "result": "The proposed algorithms with preconditioning demonstrate significant improvements in efficiency, accuracy, and robustness compared to standard approaches. Numerical experiments validate the effectiveness of the implementation strategies, particularly for matrices with special structures, and show the practical benefits of the preconditioning technique.", "conclusion": "The paper successfully provides a comprehensive algorithmic framework for the generalized matrix separation problem, with practical implementation strategies and theoretical guarantees for the preconditioning approach. The work serves as both an implementation manual and a contribution to improving the computational efficiency of matrix separation algorithms."}}
{"id": "2507.17014", "pdf": "https://arxiv.org/pdf/2507.17014", "abs": "https://arxiv.org/abs/2507.17014", "authors": ["Joe Jackson", "Alp\u00e1r R. M\u00e9sz\u00e1ros"], "title": "Quantitative convergence for displacement monotone Mean Field Games of control", "categories": ["math.PR", "math.AP", "math.OC", "91A16, 49N80, 60H30"], "comment": null, "summary": "In this paper we establish quantitative convergence results for both open and\nclosed-loop Nash equilibria of N-player stochastic differential games in the\nsetting of Mean Field Games of Controls (MFGC), a class of models where\ninteractions among agents occur through both states and controls. Our analysis\ncovers a general class of non-separable Hamiltonians satisfying a displacement\nmonotonicity condition, along with mild regularity and growth conditions at\ninfinity. A major novelty of our work is the rigorous treatment of a nontrivial\nfixed-point problem on a space of measures, which arises naturally in the MFGC\nformulation. Unlike prior works that either restrict to separable Hamiltonians\n- rendering the fixed-point map trivial - or assume convergence or regularity\nproperties of the fixed point map, we develop a detailed structural analysis of\nthis equation and its N-player analogue. This leads to new regularity results\nfor the fixed-point maps and, in turn, to quantitative convergence of open-loop\nequilibria. We further derive sharp a priori estimates for the N-player Nash\nsystem, enabling us to control the discrepancy between open and closed-loop\nstrategies, and thus to conclude the convergence of closed-loop equilibria. Our\nframework also accommodates common noise in a natural way.", "AI": {"tldr": "This paper proves quantitative convergence results for N-player stochastic differential games to Mean Field Games of Controls (MFGC), where agents interact through both states and controls, by solving a nontrivial fixed-point problem on measure spaces and establishing regularity for both open-loop and closed-loop Nash equilibria.", "motivation": "Existing works on Mean Field Games of Controls either restrict to separable Hamiltonians (making the fixed-point problem trivial) or assume convergence properties without proof. There was a need to rigorously analyze the nontrivial fixed-point problem that arises naturally in MFGC formulations with non-separable Hamiltonians, and to establish quantitative convergence rates for both open-loop and closed-loop equilibria.", "method": "The authors develop a detailed structural analysis of the fixed-point equation on measure spaces and its N-player analogue. They work with general non-separable Hamiltonians satisfying displacement monotonicity conditions along with mild regularity and growth conditions. The approach involves establishing new regularity results for fixed-point maps, deriving sharp a priori estimates for the N-player Nash system, and controlling the discrepancy between open and closed-loop strategies.", "result": "The paper establishes quantitative convergence results for both open-loop and closed-loop Nash equilibria in N-player stochastic differential games to their mean field limits. New regularity results are obtained for the fixed-point maps, and sharp a priori estimates are derived for the N-player Nash system. The framework successfully accommodates common noise and handles the challenging case of non-separable Hamiltonians.", "conclusion": "The authors successfully provide a rigorous mathematical foundation for Mean Field Games of Controls with non-separable Hamiltonians by solving the nontrivial fixed-point problem and establishing quantitative convergence rates. This advances the theoretical understanding of mean field games where agents interact through both states and controls, extending beyond previous limitations of separable Hamiltonians."}}
{"id": "2507.17096", "pdf": "https://arxiv.org/pdf/2507.17096", "abs": "https://arxiv.org/abs/2507.17096", "authors": ["Olivia Dry", "Timothy L. Molloy", "Wanxin Jin", "Iman Shames"], "title": "ZORMS-LfD: Learning from Demonstrations with Zeroth-Order Random Matrix Search", "categories": ["cs.LG", "cs.NA", "cs.SY", "eess.SY", "math.NA", "math.OC"], "comment": null, "summary": "We propose Zeroth-Order Random Matrix Search for Learning from Demonstrations\n(ZORMS-LfD). ZORMS-LfD enables the costs, constraints, and dynamics of\nconstrained optimal control problems, in both continuous and discrete time, to\nbe learned from expert demonstrations without requiring smoothness of the\nlearning-loss landscape. In contrast, existing state-of-the-art first-order\nmethods require the existence and computation of gradients of the costs,\nconstraints, dynamics, and learning loss with respect to states, controls\nand/or parameters. Most existing methods are also tailored to discrete time,\nwith constrained problems in continuous time receiving only cursory attention.\nWe demonstrate that ZORMS-LfD matches or surpasses the performance of\nstate-of-the-art methods in terms of both learning loss and compute time across\na variety of benchmark problems. On unconstrained continuous-time benchmark\nproblems, ZORMS-LfD achieves similar loss performance to state-of-the-art\nfirst-order methods with an over $80$\\% reduction in compute time. On\nconstrained continuous-time benchmark problems where there is no specialized\nstate-of-the-art method, ZORMS-LfD is shown to outperform the commonly used\ngradient-free Nelder-Mead optimization method.", "AI": {"tldr": "The paper proposes ZORMS-LfD, a zeroth-order optimization method for learning optimal control problems from expert demonstrations that doesn't require gradient computation and works for both continuous and discrete time systems with constraints.", "motivation": "Existing first-order methods for learning from demonstrations require gradient computation of costs, constraints, dynamics, and learning loss, which demands smoothness assumptions. Most methods are also limited to discrete-time problems, with constrained continuous-time problems receiving insufficient attention.", "method": "ZORMS-LfD uses zeroth-order random matrix search optimization that can learn costs, constraints, and dynamics of constrained optimal control problems from expert demonstrations without requiring smoothness of the learning-loss landscape or gradient computation.", "result": "ZORMS-LfD matches or exceeds state-of-the-art methods in learning loss and compute time across various benchmarks. For unconstrained continuous-time problems, it achieves similar performance with over 80% reduction in compute time. For constrained continuous-time problems, it outperforms gradient-free Nelder-Mead optimization.", "conclusion": "ZORMS-LfD provides an effective gradient-free alternative for learning from demonstrations in optimal control, particularly excelling in continuous-time constrained problems where specialized methods are lacking, while offering significant computational efficiency improvements."}}
{"id": "2507.17018", "pdf": "https://arxiv.org/pdf/2507.17018", "abs": "https://arxiv.org/abs/2507.17018", "authors": ["Vasanth Pidaparthy", "Yanir A. Rubinstein"], "title": "Convexity and the degenerate special Lagrangian equation", "categories": ["math.DG", "math.AP", "math.SG", "35J70, 53D12 (Primary) 35J66, 35D40, 35B50 (Secondary)"], "comment": "19 pages", "summary": "In 2015 Rubinstein--Solomon introduced the degenerate special Lagrangian\nequation (DSL) that governs geodesics in the space of positive Lagrangians,\nshowed that subsolutions in the top branch of DSL are convex in space, and\nraised the question of whether they should be convex in space-time and whether\nsubsolutions in the second branch possess any convexity properties. In 2019,\nDarvas--Rubinstein gave a partial answer to the first problem by showing\nsubsolutions in the top branch must be bi-convex. We settle both questions. The\nkey new ingredient is a space-time coordinate transformation that preserves the\nspace-time Lagrangian angle and allows for a partial $C^2$ estimate. This also\nshows that the top two branches of the DSL subequation have a $\\star$-product\nstructure in the sense of Ross--Witt-Nystr\\\"om.", "AI": {"tldr": "This paper resolves open questions about convexity properties of subsolutions to the degenerate special Lagrangian equation (DSL) by introducing a novel space-time coordinate transformation that preserves the space-time Lagrangian angle.", "motivation": "The paper addresses two unresolved questions from previous work: (1) whether subsolutions in the top branch of DSL are convex in space-time, and (2) whether subsolutions in the second branch possess any convexity properties. These questions were raised by Rubinstein-Solomon (2015) and partially addressed by Darvas-Rubinstein (2019).", "method": "The key methodological innovation is a space-time coordinate transformation that preserves the space-time Lagrangian angle. This transformation enables the derivation of a partial C\u00b2 estimate, which is crucial for analyzing the convexity properties of DSL subsolutions.", "result": "The paper successfully settles both open questions about convexity properties of DSL subsolutions. Additionally, it demonstrates that the top two branches of the DSL subequation have a \u22c6-product structure in the sense of Ross-Witt-Nystr\u00f6m.", "conclusion": "Through the novel coordinate transformation technique, the authors provide complete answers to the outstanding convexity questions for DSL subsolutions and reveal new structural properties of the equation that connect it to the \u22c6-product framework."}}
{"id": "2507.17184", "pdf": "https://arxiv.org/pdf/2507.17184", "abs": "https://arxiv.org/abs/2507.17184", "authors": ["Hui Zhao"], "title": "A Scientist Question: Research on the Impact of Super Structured Quadrilateral Meshes on Convergence and Accuracy of Finite Element Analysis", "categories": ["cs.GR", "cs.NA", "math.NA"], "comment": "in Chinese and English", "summary": "In the current practices of both industry and academia, the convergence and\naccuracy of finite element calculations are closely related to the methods and\nquality of mesh generation. For years, the research on high-quality mesh\ngeneration in the domestic academic field has mainly referred to the local\nquality of quadrilaterals and hexahedrons approximating that of squares and\ncubes. The main contribution of this paper is to propose a brand-new research\ndirection and content: it is necessary to explore and study the influence of\nthe overall global arrangement structure and pattern of super structured\nquadrilateral meshes on the convergence and calculation accuracy of finite\nelement calculations. Through the research in this new field, it can help solve\nthe non-rigorous state of serious reliance on \"experience\" in the mesh\ngeneration stage during simulation in the current industry and academia, and\nmake clear judgments on which global arrangements of mesh generation can ensure\nthe convergence of finite element calculations. In order to generate and design\nsuper-structured quadrilateral meshes with controllable overall arrangement\nstructures, a large number of modern two-dimensional and three-dimensional\ngeometric topology theories are required, such as moduli space, Teichm\\\"uller\nspace, harmonic foliations, dynamical systems, surface mappings, meromorphic\nquadratic differentials, surface mappings, etc.", "AI": {"tldr": "This paper proposes studying how global arrangement patterns of super structured quadrilateral meshes affect finite element calculation convergence and accuracy, moving beyond traditional local mesh quality metrics to address the current reliance on experience-based mesh generation.", "motivation": "Current mesh generation practices in industry and academia rely heavily on experience rather than rigorous scientific principles, focusing only on local quality metrics (quadrilaterals/hexahedrons approximating squares/cubes) while ignoring the impact of global mesh arrangement patterns on finite element calculation convergence and accuracy.", "method": "The paper proposes using modern two-dimensional and three-dimensional geometric topology theories including moduli space, Teichm\u00fcller space, harmonic foliations, dynamical systems, surface mappings, and meromorphic quadratic differentials to generate and design super-structured quadrilateral meshes with controllable overall arrangement structures.", "result": "The paper establishes a new research direction that explores the relationship between global mesh arrangement structures and finite element calculation performance, providing a theoretical framework to move away from experience-based mesh generation toward scientifically rigorous approaches.", "conclusion": "This work opens a new research field that can help solve the non-rigorous reliance on experience in mesh generation by enabling clear judgments about which global mesh arrangements ensure finite element calculation convergence, potentially revolutionizing mesh generation practices in computational simulations."}}
{"id": "2507.17166", "pdf": "https://arxiv.org/pdf/2507.17166", "abs": "https://arxiv.org/abs/2507.17166", "authors": ["Kyeong-Hun Kim", "Junhee Ryu"], "title": "The Dirichlet problem for stochastic partial differential equations with nonlocal operators in $C^{1,\u03c3}$ open sets", "categories": ["math.PR", "math.AP", "60H15, 35R60, 35B65, 45K05"], "comment": "48 pages", "summary": "This paper provides a comprehensive Sobolev regularity theory for the\nDirichlet problem of stochastic partial differential equations in\n$C^{1,\\sigma}$ open sets. We consider substantially large classes of nonlocal\noperators and generalized Gaussian noise. Our main results include the\nexistence and uniqueness of strong solutions in weighted Sobolev spaces, along\nwith maximal $L_p$-regularity estimates for the solutions.", "AI": {"tldr": "This paper develops a comprehensive Sobolev regularity theory for stochastic partial differential equations (SPDEs) with Dirichlet boundary conditions in smooth domains, establishing existence, uniqueness, and regularity estimates for solutions.", "motivation": "The motivation is to establish a rigorous mathematical framework for analyzing the regularity properties of solutions to stochastic partial differential equations with Dirichlet boundary conditions, particularly for nonlocal operators and generalized Gaussian noise, which are important in many applications but lack comprehensive theoretical foundations.", "method": "The authors employ Sobolev space theory and weighted function spaces to analyze SPDEs in C^{1,\u03c3} open sets. They work with substantially large classes of nonlocal operators and generalized Gaussian noise to develop their regularity framework.", "result": "The main results include: (1) existence and uniqueness of strong solutions in weighted Sobolev spaces, and (2) maximal L_p-regularity estimates for the solutions of the Dirichlet problem for stochastic partial differential equations.", "conclusion": "The paper successfully establishes a comprehensive Sobolev regularity theory for SPDEs with Dirichlet boundary conditions, providing both existence/uniqueness results and sharp regularity estimates that advance the theoretical understanding of stochastic partial differential equations in smooth domains."}}
{"id": "2507.17173", "pdf": "https://arxiv.org/pdf/2507.17173", "abs": "https://arxiv.org/abs/2507.17173", "authors": ["Mustafa Avci"], "title": "Existence results for the Cox-Ingersoll-Ross model with variable exponent diffusion", "categories": ["math.PR", "math.AP", "60G07, 60H15, 60H20, 60H30"], "comment": null, "summary": "We propose a new stochastic model where the diffusion coefficient involves a\nstate-dependent variable exponent function $p(\\cdot)$. This new theoretically\nflexible framework generalizes the classical Cox-Ingersoll-Ross model. The\nexistence, uniqueness, higher moment and martingale properties of solutions are\nanalyzed. The validity and efficiency of the model is illustrated with\nnumerical experiments.", "AI": {"tldr": "The paper proposes a generalized Cox-Ingersoll-Ross model with state-dependent variable exponent function in the diffusion coefficient, analyzing its mathematical properties and demonstrating its validity through numerical experiments.", "motivation": "To develop a more theoretically flexible framework that generalizes the classical Cox-Ingersoll-Ross model by incorporating a state-dependent variable exponent function p(\u00b7) in the diffusion coefficient, addressing limitations of existing models.", "method": "Development of a new stochastic model with variable exponent diffusion coefficient, followed by mathematical analysis of existence, uniqueness, higher moment properties, and martingale properties of solutions, complemented by numerical experiments.", "result": "The theoretical analysis establishes existence and uniqueness of solutions, characterizes higher moment and martingale properties. Numerical experiments validate the model's effectiveness and demonstrate its computational efficiency.", "conclusion": "The proposed stochastic model with state-dependent variable exponent successfully generalizes the Cox-Ingersoll-Ross model, providing a more flexible theoretical framework with proven mathematical properties and demonstrated practical validity through numerical validation."}}
{"id": "2507.17331", "pdf": "https://arxiv.org/pdf/2507.17331", "abs": "https://arxiv.org/abs/2507.17331", "authors": ["Carlo Orrieri", "Luca Scarpa", "Ulisse Stefanelli"], "title": "Weak stability by noise for approximations of doubly nonlinear evolution equations", "categories": ["math.PR", "math.AP", "35K55, 35R60, 60H15"], "comment": null, "summary": "Doubly nonlinear stochastic evolution equations are considered. Upon assuming\nthe additive noise to be rough enough, we prove the existence of\nprobabilistically weak solutions of Friedrichs type and study their uniqueness\nin law. This entails stability for approximations of stochastic doubly\nnonlinear equations in a weak probabilistic sense. Such effect is a genuinely\nstochastic, as doubly nonlinear equations are not even expected to exhibit\nuniqueness in the deterministic case.", "AI": {"tldr": "This paper proves existence and uniqueness in law of probabilistically weak solutions for doubly nonlinear stochastic evolution equations with rough additive noise, showing that stochastic noise can restore uniqueness that is typically lost in deterministic doubly nonlinear equations.", "motivation": "Doubly nonlinear equations typically lack uniqueness in the deterministic case, making their analysis challenging. The authors investigate whether adding stochastic noise can restore well-posedness properties that are absent in the deterministic setting.", "method": "The authors assume additive noise that is \"rough enough\" and construct probabilistically weak solutions of Friedrichs type for doubly nonlinear stochastic evolution equations. They then analyze the uniqueness in law of these solutions.", "result": "The paper establishes existence of probabilistically weak solutions of Friedrichs type and proves their uniqueness in law. Additionally, they demonstrate stability for approximations of stochastic doubly nonlinear equations in a weak probabilistic sense.", "conclusion": "The stochastic noise has a regularizing effect that is genuinely stochastic in nature - it restores uniqueness properties in doubly nonlinear equations that do not possess uniqueness in the deterministic case. This represents a fundamental difference between stochastic and deterministic doubly nonlinear evolution equations."}}
