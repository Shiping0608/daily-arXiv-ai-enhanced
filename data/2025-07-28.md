<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 11]
- [math.AP](#math.AP) [Total: 24]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 6]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [math.DS](#math.DS) [Total: 1]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A conservative invariant-domain preserving projection technique for hyperbolic systems under adaptive mesh refinement](https://arxiv.org/abs/2507.18717)
*Jake Harmon,Martin Kronbichler,Matthias Maier,Eric Tovar*

Main category: math.NA

TL;DR: A conservative invariant-domain preserving (IDP) projection technique for hierarchical discretizations is proposed, ensuring physical property preservation in hyperbolic systems.


<details>
  <summary>Details</summary>
Motivation: To develop a method that rigorously preserves physical invariants in adaptive numerical simulations of hyperbolic systems, avoiding ad hoc corrections.

Method: A projection technique coupled with refinement indicators, implemented in a high-performance finite element code.

Result: Demonstrated enhanced accuracy and efficiency in benchmark problems while preserving physical invariants.

Conclusion: The proposed scheme provides a provably IDP adaptive method for hyperbolic systems, validated through challenging benchmarks.

Abstract: We propose a rigorous, conservative invariant-domain preserving (IDP)
projection technique for hierarchical discretizations that enforces membership
in physics-implied convex sets when mapping between solution spaces. When
coupled with suitable refinement indicators, the proposed scheme enables a
provably IDP adaptive numerical method for hyperbolic systems where
preservation of physical properties is essential. In addition to proofs of
these characteristics, we supply a detailed construction of the method in the
context of a high-performance finite element code. To illustrate our proposed
scheme, we study a suite of computationally challenging benchmark problems,
demonstrating enhanced accuracy and efficiency properties while entirely
avoiding \emph{ad hoc} corrections to preserve physical invariants.

</details>


### [2] [Symmetry-reduced model reduction of shift-equivariant systems via operator inference](https://arxiv.org/abs/2507.18780)
*Yu Shuai,Clarence W. Rowley*

Main category: math.NA

TL;DR: A method for data-driven reduced-order modeling of shift-equivariant PDEs, focusing on traveling solutions by representing them in a moving frame and estimating travel speed.


<details>
  <summary>Details</summary>
Motivation: To improve reduced-order models for shift-equivariant systems by capturing traveling solutions more accurately and stably.

Method: Extends operator inference with additional terms to estimate traveling speed and represent solutions in a moving frame.

Result: Demonstrates robust capture of traveling solutions and improved stability over standard operator inference, validated with the Kuramoto-Sivashinsky equation.

Conclusion: The proposed method effectively models traveling solutions in shift-equivariant systems with enhanced stability.

Abstract: We consider data-driven reduced-order models of partial differential
equations with shift equivariance. Shift-equivariant systems typically admit
traveling solutions, and the main idea of our approach is to represent the
solution in a traveling reference frame, in which it can be described by a
relatively small number of basis functions. Existing methods for operator
inference allow one to approximate a reduced-order model directly from data,
without knowledge of the full-order dynamics. Our method adds additional terms
to ensure that the reduced-order model not only approximates the spatially
frozen profile of the solution, but also estimates the traveling speed as a
function of that profile. We validate our approach using the
Kuramoto-Sivashinsky equation, a one-dimensional partial differential equation
that exhibits traveling solutions and spatiotemporal chaos. Results indicate
that our method robustly captures traveling solutions, and exhibits improved
numerical stability over the standard operator inference approach.

</details>


### [3] [Fourth-Order Compact FDMs for Steady and Time-Dependent Nonlinear Convection-Diffusion Equations](https://arxiv.org/abs/2507.18799)
*Qiwei Feng,Catalin Trenchea*

Main category: math.NA

TL;DR: The paper presents high-order compact finite difference methods (FDMs) for solving steady and time-dependent nonlinear convection-diffusion equations, ensuring accuracy and reduced pollution effects.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of solving nonlinear convection-diffusion equations with high accuracy and efficiency, especially for variable and time-dependent coefficients.

Method: Uses iterative methods to linearize the nonlinear equations, derives compact 9-point FDMs for steady and time-dependent cases, and employs Crank-Nicolson, BDF3, and BDF4 schemes for temporal discretization.

Result: Demonstrates high accuracy and convergence rates in numerical examples, outperforming the discontinuous Galerkin method in some cases.

Conclusion: The proposed methods are effective, extendable to 3D and more general equations, and offer superior performance in terms of error reduction.

Abstract: In this paper, we discuss the steady and time-dependent nonlinear
convection-diffusion (advection-diffusion) equations with the Dirichlet
boundary condition. For the steady nonlinear equation, we use an iteration
method to reformulate the nonlinear equation into its linear counterpart, and
derive a fourth-order compact 9-point finite difference method (FDM) to solve
the reformulated equation on a uniform Cartesian grid. To increase the
accuracy, we modify the FDM to reduce the pollution effect. The linear system
of the FDM generates an M-matrix, provided the mesh size $h$ is sufficiently
small. For the time dependent nonlinear equation, we discrete the temporal
domain using the Crank-Nicolson (CN), BDF3, BDF4 time stepping methods, and
apply a similar iterative method to rewrite the nonlinear equation as the same
linear convection-diffusion equation. Then we propose the second-order to
fourth-order compact 9-point FDMs with the reduced pollution effects on a
uniform Cartesian grid. We prove that all FDMs satisfy the discrete maximum
principle for sufficiently small $h$. Several examples with the variable and
time-dependent diffusion coefficients and challenging nonlinear terms (not
limited to the Burgers equation) are provided to verify the accuracy and the
desired convergence rates in the $l_2$ and $l_{\infty}$ norms in space and
time. We also compare our second-order CN method with the third-order BDF3
method and the discontinuous Galerkin (DG) method, and the numerical results
demonstrate that our FDM with the coarse time step generates the small error.
Especially, if the same BDF3 scheme is applied, our error is 1.6\% of that
obtained from the DG method. The proposed methods can be easily extended to a
3D spatial domain and more general nonlinear convection-diffusion-reaction
equations.

</details>


### [4] [Neural Correction Operator: A Reliable and Fast Approach for Electrical Impedance Tomography](https://arxiv.org/abs/2507.18875)
*Amit Bhat,Ke Chen,Chunmei Wang*

Main category: math.NA

TL;DR: The paper proposes a neural correction operator framework for Electrical Impedance Tomography (EIT), combining L-BFGS optimization with deep learning to improve reconstruction quality and robustness.


<details>
  <summary>Details</summary>
Motivation: EIT's severe ill-posedness makes direct neural operator learning unreliable, necessitating a hybrid approach.

Method: A two-step framework: L-BFGS for initial reconstruction and deep learning (CNNs or diffusion models) for correction.

Result: Superior reconstruction quality, noise robustness, and computational speedup compared to iterative and direct neural methods.

Conclusion: The framework offers a general solution for ill-posed inverse problems, balancing accuracy and efficiency.

Abstract: Electrical Impedance Tomography (EIT) is a non-invasive medical imaging
method that reconstructs electrical conductivity mediums from boundary
voltage-current measurements, but its severe ill-posedness renders direct
operator learning with neural networks unreliable. We propose the neural
correction operator framework, which learns the inverse map as a composition of
two operators: a reconstruction operator using L-BFGS optimization with limited
iterations to obtain an initial estimate from measurement data and a correction
operator implemented with deep learning models to reconstruct the true media
from this initial guess. We explore convolutional neural network architectures
and conditional diffusion models as alternative choices for the correction
operator. We evaluate the neural correction operator by comparing with L-BFGS
methods as well as neural operators and conditional diffusion models that
directly learn the inverse map over several benchmark datasets. Our numerical
experiments demonstrate that our approach achieves significantly better
reconstruction quality compared to both iterative methods and direct neural
operator learning methods with the same architecture. The proposed framework
also exhibits robustness to measurement noise while achieving substantial
computational speedup compared to conventional methods. The neural correction
operator provides a general paradigm for approaching neural operator learning
in severely ill-posed inverse problems.

</details>


### [5] [A Simple and Robust Weak Galerkin Method for the Brinkman Equations on Non-Convex Polytopal Meshes](https://arxiv.org/abs/2507.18896)
*Chunmei Wang,Shangyou Zhang*

Main category: math.NA

TL;DR: A Stabilizer-Free weak Galerkin (WG) finite element method is introduced for solving Brinkman equations without traditional stabilization, handling both Stokes- and Darcy-dominated flows in heterogeneous porous media.


<details>
  <summary>Details</summary>
Motivation: The Brinkman model combines Stokes and Darcy equations, but standard finite element spaces are incompatible for both regimes. The study aims to develop a unified numerical scheme for stability and accuracy across both flows.

Method: The WG method uses bubble functions for stability and convergence, supports convex and non-convex polytopal elements, and avoids conventional stabilization techniques.

Result: Optimal-order error estimates are derived, and numerical experiments confirm the method's robustness, reliability, flexibility, and accuracy.

Conclusion: The proposed WG method effectively resolves Stokes- and Darcy-dominated flows in a unified framework, validated by theoretical and numerical results.

Abstract: This paper presents a novel Stabilizer-Free weak Galerkin (WG) finite element
method for solving the Brinkman equations without the need for conventional
stabilization techniques. The Brinkman model, which mathematically blends
features of both the Stokes and Darcy equations, describes fluid flow in
multi-physics environments, particularly in heterogeneous porous media
characterized by spatially varying permeability. In such settings, flow
behavior may be governed predominantly by Darcy dynamics in certain regions and
by Stokes dynamics in others. A central difficulty in this context arises from
the incompatibility of standard finite element spaces: elements stable for the
Stokes equations typically perform poorly for Darcy flows, and vice versa. The
primary challenge addressed in this study is the development of a unified
numerical scheme that maintains stability and accuracy across both flow
regimes. To this end, the proposed WG method demonstrates a robust capacity to
resolve both Stokes- and Darcy-dominated flows through a unified framework. The
method supports general finite element partitions consisting of convex and
non-convex polytopal elements, and employs bubble functions as a critical
analytical component to achieve stability and convergence. Optimal-order error
estimates are rigorously derived for the WG finite element solutions.
Additionally, a series of numerical experiments is conducted to validate the
theoretical findings, illustrating the method's robustness, reliability,
flexibility, and accuracy in solving the Brinkman equations.

</details>


### [6] [Fourier Spectral Methods for Block Copolymer Systems on Sphere](https://arxiv.org/abs/2507.18968)
*Wangbo Luo,Yanxiang Zhao*

Main category: math.NA

TL;DR: Spectral methods for OK and NO models on a sphere reveal coarsening dynamics and equilibrium patterns, resembling biomembrane experiments, with insights into repulsive strength and bubble assemblies.


<details>
  <summary>Details</summary>
Motivation: To study coarsening dynamics and equilibrium pattern formations of OK and NO models on a spherical domain, and validate their real-world applicability.

Method: Used Double Fourier Sphere (DFS) for spatial discretization and BDF2 for time evolution, creating an energy-stable scheme.

Result: Observed self-assembled patterns (single/double/mixed-bubble) resembling biomembranes, and confirmed the two-thirds law in OK model.

Conclusion: The OK model effectively captures real-world patterns, with system parameters quantitatively influencing self-assembly.

Abstract: We introduce spectral methods for the Ohta-Kawasaki (OK) and Nakazawa-Ohta
(NO) models on a spherical domain, examining their coarsening dynamics and
equilibrium pattern formations. We employed the Double Fourier Sphere (DFS)
method for spatial discretization and the second-order Backward Differentiation
Formula (BDF2) scheme for time evolution, resulting in an efficient
energy-stable scheme to simulate the OK and NO models on the unit sphere. Our
numerical experiments reveal various self-assembled patterns, such as
single-bubble assemblies in binary systems and double-bubble and mixed-bubble
assemblies in ternary systems. These patterns closely resemble experimental
biomembrane patterns, demonstrating the effectiveness of the OK model in
real-world applications. Additionally, our study explores the relationship
between repulsive strength and the number of bubbles in assemblies, confirming
the two-thirds law in the OK model. This provides quantitative evidence of how
self-assembled patterns depend on system parameters in copolymer systems.

</details>


### [7] [Weighted least squares subdivision schemes for noisy data on triangular meshes](https://arxiv.org/abs/2507.18976)
*Costanza Conti,Sergio López-Ureña,Dionisio F. Yáñez*

Main category: math.NA

TL;DR: A new family of linear subdivision schemes for refining noisy triangular mesh data is introduced, using weighted least squares polynomial fitting. The schemes are geometry-dependent, versatile for various grids, and demonstrate denoising, approximation, and convergence properties.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of refining noisy data on triangular meshes with a method that combines subdivision flexibility and denoising capabilities.

Method: Uses weighted least squares approximating first-degree polynomials for subdivision rules, applicable to diverse triangular grids, including those with extraordinary vertices.

Result: Proves properties like reproduction, approximation order, denoising, and convergence (for specific grids). Numerical experiments show performance comparable to advanced linear regression methods.

Conclusion: The subdivision schemes are effective for multiresolution contexts and handling noisy geometric data, offering a balance of flexibility and performance.

Abstract: This paper presents and analyses a new family of linear subdivision schemes
to refine noisy data given on triangular meshes. The subdivision rules consist
of locally fitting and evaluating a weighted least squares approximating
first-degree polynomial. This type of rules, applicable to any type of
triangular grid, including finite grids or grids containing extraordinary
vertices, are geometry-dependent which may result in non-uniform schemes. For
these new subdivision schemes, we are able to prove reproduction, approximation
order, denoising capabilities and, for some special type of grids, convergence
as well. Several numerical experiments demonstrate that their performance is
similar to advanced local linear regression methods but their subdivision
nature makes them suitable for use within a multiresolution context as well as
to deal with noisy geometric data as shown with an example.

</details>


### [8] [Barenblatt solutions for the time-fractional porous medium equation: approach via integral equations](https://arxiv.org/abs/2507.19217)
*Josefa Caballero,Hanna Okrasińska-Płociniczak,Łukasz Płociniczak,Kishin Sadarangani*

Main category: math.NA

TL;DR: The paper studies Barenblatt solutions for the time-fractional porous medium equation, proving their existence and properties, and introduces numerical schemes for practical computation.


<details>
  <summary>Details</summary>
Motivation: To rigorously analyze and compute Barenblatt solutions for the time-fractional porous medium equation, bridging theory and practice.

Method: Uses an integral equation approach to prove solution existence and properties, and designs numerical schemes for computation.

Result: Establishes existence, estimates, mass conservation, regularity, and monotonicity of solutions, with validated numerical methods.

Conclusion: The work advances theoretical understanding and practical computation of Barenblatt solutions, supported by examples and numerical validation.

Abstract: This paper explores Barenblatt solutions of the time-fractional porous medium
equation, characterized by a Caputo-type time derivative. Employing an integral
equation approach, we rigorously prove the existence of these solutions and
establish several fundamental properties, including upper and lower estimates,
mass conservation, regularity, and monotonicity. To bridge theory and practice,
we introduce a family of convergent numerical schemes specifically designed to
compute the Barenblatt solutions, ensuring reliable and efficient
approximations. The theoretical framework is enriched with various examples
that illustrate the concepts and validate the effectiveness of the proposed
numerical methods, enhancing the understanding and applicability of our
results.

</details>


### [9] [Plug and Play Splitting Techniques for Poisson Image Restoration](https://arxiv.org/abs/2507.19378)
*Alessandro Benfenati*

Main category: math.NA

TL;DR: Extends PIDSplit+ to PnP for Poisson image restoration, avoiding iterative solvers and ensuring convergence with a non-expansive denoiser.


<details>
  <summary>Details</summary>
Motivation: Existing PnP methods for Gaussian data can't handle Poisson cases due to non-Lipschitz gradients and lack of closed-form solutions.

Method: Extends PIDSplit+ using ADMM to provide closed-form deblurring without iterative solvers, employing a firmly non-expansive denoiser.

Result: PnPSplit+ performs well in Poisson image restoration, even under high noise and severe blurring.

Conclusion: PnPSplit+ effectively addresses Poisson image restoration challenges, outperforming existing methods.

Abstract: Plug and Play (PnP) methods achieve remarkable results in the framework of
image restoration problems for Gaussian data. Nonetheless, the theory available
for the Gaussian case cannot be extended to the Poisson case, due to the
non-Lipschitz gradient of the fidelity function, the Kullback-Leibler
functional, or the absence of closed-form solution for the proximal operator of
such term, leading to employ iterative solvers for the inner subproblem. In
this work we extend the idea of PIDSplit+ algorithm, exploiting the Alternating
Direction Method of Multipliers, to PnP scheme: this allows to provide a closed
form solution for the deblurring step, with no need for iterative solvers. The
convergence of the method is assured by employing a firmly non expansive
denoiser. The proposed method, namely PnPSplit+, is tested on different Poisson
image restoration problems, showing remarkable performance even in presence of
high noise level and severe blurring conditions.

</details>


### [10] [A non-iterative domain decomposition time integrator for linear wave equations](https://arxiv.org/abs/2507.19379)
*Tim Buchholz,Marlis Hochbruck*

Main category: math.NA

TL;DR: A non-iterative domain decomposition integrator for the linear acoustic wave equation is proposed, combining implicit Crank-Nicolson steps with local predictions for parallelization and large time steps.


<details>
  <summary>Details</summary>
Motivation: To enable parallelization in space while advancing sequentially in time for the wave equation, avoiding iterations per time step.

Method: Combines implicit Crank-Nicolson steps on subdomains with local predictions at interfaces, using linear finite elements with mass lumping.

Result: Achieves second-order accuracy in time and global convergence of O(h + τ²) under a CFL-type condition.

Conclusion: Numerical experiments confirm the method's accuracy and efficiency, allowing larger time steps than explicit schemes.

Abstract: We propose and analyze a non-iterative domain decomposition integrator for
the linear acoustic wave equation. The core idea is to combine an implicit
Crank-Nicolson step on spatial subdomains with a local prediction step at the
subdomain interfaces. This enables parallelization across space while advancing
sequentially in time, without requiring iterations at each time step. The
method is similar to the methods from Blum, Lisky and Rannacher (1992) or
Dawson and Dupont (1992), which have been designed for parabolic problems. Our
approach adapts them to the case of the wave equation in a fully discrete
setting, using linear finite elements with mass lumping. Compared to explicit
schemes, our method permits significantly larger time steps and retains high
accuracy. We prove that the resulting method achieves second-order accuracy in
time and global convergence of order $\mathcal{O}(h + \tau^2)$ under a CFL-type
condition, which depends on the overlap width between subdomains. We conclude
with numerical experiments which confirm the theoretical

</details>


### [11] [Convergence of Discrete Exterior Calculus for the Hodge-Dirac Operator](https://arxiv.org/abs/2507.19405)
*Radovan Dabetić,Ralf Hiptmair*

Main category: math.NA

TL;DR: A concise proof of convergence for the Hodge-Dirac operator discretization in DEC, leveraging techniques from prior work.


<details>
  <summary>Details</summary>
Motivation: To provide a simplified and rigorous proof of convergence for the Hodge-Dirac operator in DEC, building on existing methods.

Method: Uses techniques from generalized Whitney forms and DEC, as established in prior research.

Result: A short and clear proof of convergence for the discretization of the Hodge-Dirac operator.

Conclusion: The proof successfully demonstrates convergence, reinforcing the validity of DEC for such problems.

Abstract: A short proof of convergence for the discretization of the Hodge-Dirac
operator in the framework of discrete exterior calculus (DEC) is provided using
the techniques established in [Johnny Guzm\'an and Pratyush Potu, A Framework
for Analysis of DEC Approximations to Hodge-Laplacian Problems using
Generalized Whitney Forms, arXiv:2505.08934, 2025]

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [12] [Existence of an Infinite Number of Solutions to a Singular Superlinear p-Laplacian Equation on Exterior Domains](https://arxiv.org/abs/2507.18662)
*Md Suzan Ahamed,Joseph Iaia*

Main category: math.AP

TL;DR: The paper proves the existence of infinitely many radial solutions for a p-Laplacian equation on the exterior of a ball, with specific growth and singularity conditions on the nonlinear term and a power-law decay for the coefficient.


<details>
  <summary>Details</summary>
Motivation: To address the existence of solutions for a p-Laplacian equation with singular and superlinear nonlinearities in an unbounded domain, extending previous results.

Method: Analyzes radial solutions using variational methods and asymptotic assumptions on the nonlinear term and coefficient.

Result: Demonstrates the existence of infinitely many radial solutions vanishing at infinity under the given conditions.

Conclusion: The study confirms the existence of solutions for the p-Laplacian equation with singular and superlinear behavior, contributing to the understanding of such problems in unbounded domains.

Abstract: In this paper, we prove the existence of an infinite number of radial
solutions of the $p$-$Laplacian$ equation $\Delta_p u + K(|x|) f(u) =0$ on the
exterior of the ball of radius $R>0$ in ${\mathbb R}^{N}$ such that $u(|x|)\to
0$ as $|x|\to \infty$ where $f$ grows superlinearly at infinity and is singular
at $0$ with $f(u) \sim -\frac{1}{|u|^{m-1}u}$ and $0<m<1$ for small $u$. We
also assume $K(|x|) \sim |x|^{-\alpha}$ for large $|x|$ where $N +
\frac{m(N-p)}{p-1}< \alpha<2(N-1).$

</details>


### [13] [A connection between quantum dot Dirac operators and $\overline\partial$-Robin Laplacians in the context of shape optimization problems](https://arxiv.org/abs/2507.18698)
*Joaquim Duran,Albert Mas,Tomás Sanz-Perela*

Main category: math.AP

TL;DR: The paper explores Faber-Krahn-type inequalities for quantum dot Dirac operators with nonnegative mass on 2D domains, linking them to similar inequalities for ∂¯-Robin Laplacians, and extends results to negative mass cases.


<details>
  <summary>Details</summary>
Motivation: To establish connections between inequalities for quantum dot Dirac operators and ∂¯-Robin Laplacians, and to extend these findings to domains with specific boundary conditions and negative mass.

Method: The work demonstrates equivalence between inequalities for Dirac operators and ∂¯-Robin Laplacians, then proves them for simply connected domains with quantum dot boundary conditions close to zigzag.

Result: Proves Faber-Krahn-type inequalities for the specified operators and boundary conditions, and extends the analysis to negative mass scenarios.

Conclusion: The study successfully connects and generalizes Faber-Krahn-type inequalities for quantum dot Dirac operators, providing insights for both nonnegative and negative mass cases.

Abstract: This work addresses Faber-Krahn-type inequalities for quantum dot Dirac
operators with nonnegative mass on bounded domains in $\mathbb{R}^2$. We show
that this family of inequalities is equivalent to a family of Faber-Krahn-type
inequalities for $\overline\partial$-Robin Laplacians. Thanks to this, we prove
them in the case of simply connected domains for quantum dot boundary
conditions asymptotically close to zigzag boundary conditions. Finally, we also
study the case of negative mass.

</details>


### [14] [Variational principles on the space of Lorenz curves: Gradient structures and isometries inspired by Wasserstein geometry](https://arxiv.org/abs/2507.18766)
*David W. Cohen*

Main category: math.AP

TL;DR: Novel Riemannian gradient structures on Lorenz curves are derived, linking Wasserstein geometry and Fokker-Planck equations, with isometry results between probability measures and Lorenz curves.


<details>
  <summary>Details</summary>
Motivation: To explore infinite-dimensional variational principles inherited from Fokker-Planck equations using Wasserstein geometry.

Method: Derive Riemannian gradient structures on Lorenz curves and prove isometry results between probability measures and Lorenz curves.

Result: Meaningful metrics on Lorenz curves are suggested, and elegant variational principles are applied to nonlinear integro-differential equations.

Conclusion: The work connects Wasserstein geometry with Lorenz curves, offering new insights into variational principles and evolution equations.

Abstract: We motivate and derive novel Riemannian gradient structures on the space of
Lorenz curves, which preserve infinite-dimensional variational principles
inherited from Fokker-Planck equations via the lens of Wasserstein geometry and
its variants. We also prove isometry results between corresponding formal
manifolds of probability measures and Lorenz curves, which suggest meaningful
metrics on the space of Lorenz curves when an underlying kinetic premise is
present. In so doing, elegant variational principles are imbued upon highly
nonlinear and nonlocal integro-differential evolution equations resulting from
a recently derived variable transformation of McKean-Vlasov Fokker-Planck
equations.

</details>


### [15] [Relaxation of variational problems in the space of functions with bounded $\mathcal{B}$-variation: interaction with measures and lack of concentration phenomena](https://arxiv.org/abs/2507.18781)
*Lorenza D'Elia,Elvira Zappale*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We prove an integral representation result for variational functionals in the
space $BV^{\mathcal{B}}$ of functions with bounded $\mathcal{B}$-variation
where $\mathcal{B}$ denotes a $k$-th order, $\mathbb{C}$-elliptic, linear
homogeneous differential operator. This result has been used as a key tool to
get an explicit representation of relaxed energies with linear growth which
lead to limiting generic measures. According to the space dimension and the
order of the operator, concentration phenomena appear and an explicit
interaction is featured. These results are complemented also with Sobolev-type
counterparts. As a further application, a lower semicontinuity result in the
space of fields with $p(\cdot)$-bounded $\mathcal{B}$-variation has also been
obtained.

</details>


### [16] [Gaussian estimates for fundamental solutions of higher-order parabolic equations with time-independent coefficients](https://arxiv.org/abs/2507.18898)
*Guoming Zhang*

Main category: math.AP

TL;DR: The paper extends De Giorgi-Moser-Nash estimates to higher-order parabolic equations with complex, measurable, bounded, and time-independent coefficients, also providing Gaussian bounds and Hölder regularity for their fundamental solutions.


<details>
  <summary>Details</summary>
Motivation: To generalize existing estimates and regularity results for higher-order parabolic equations with complex coefficients, addressing gaps in the literature.

Method: Analyzes higher-order parabolic equations in divergence form with specific coefficient properties, using techniques inspired by De Giorgi-Moser-Nash.

Result: Derives De Giorgi-Moser-Nash estimates, Gaussian upper bounds, and Hölder regularity for the fundamental solutions.

Conclusion: The study successfully extends classical results to a broader class of parabolic equations, providing new insights into their regularity and behavior.

Abstract: We study the De Giorgi-Moser-Nash estimates of higher-order parabolic
equations in divergence form with complex-valued, measurable, bounded,
uniformly elliptic (in the sense of G$\mathring{a}$rding inequality) and
time-independent coefficients. We also obtain Gaussian upper bounds and
H\"{o}lder regularity estimates for the fundamental solutions of this class of
parabolic equations.

</details>


### [17] [Bayesian Inverse Problems on Metric Graphs](https://arxiv.org/abs/2507.18951)
*David Bolin,Wenwen Li,Daniel Sanz-Alonso*

Main category: math.AP

TL;DR: The paper analyzes Bayesian inverse problems on metric graphs, focusing on recovering diffusion coefficients from noisy data, ensuring stability and using Gaussian priors for accurate results.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of recovering diffusion coefficients in metric graphs from noisy measurements, ensuring well-posedness and stability.

Method: Uses stability analysis of forward models and Gaussian Whittle-Matérn priors for the inverse problem, supported by numerical solutions.

Result: Demonstrates accurate reconstruction and effective uncertainty quantification in numerical experiments.

Conclusion: The approach is robust for solving Bayesian inverse problems on metric graphs, combining theoretical stability with practical numerical efficacy.

Abstract: This paper studies the formulation, well-posedness, and numerical solution of
Bayesian inverse problems on metric graphs, in which the edges represent
one-dimensional wires connecting vertices. We focus on the inverse problem of
recovering the diffusion coefficient of a (fractional) elliptic equation on a
metric graph from noisy measurements of the solution. Well-posedness hinges on
both stability of the forward model and an appropriate choice of prior. We
establish the stability of elliptic and fractional elliptic forward models
using recent regularity theory for differential equations on metric graphs. For
the prior, we leverage modern Gaussian Whittle--Mat\'ern process models on
metric graphs with sufficiently smooth sample paths. Numerical results
demonstrate accurate reconstruction and effective uncertainty quantification.

</details>


### [18] [On the convergence of PINNs for inverse source problem in the complex Ginzburg-Landau equation](https://arxiv.org/abs/2507.18978)
*Xing Cheng,Zhiyuan Li,Mengmeng Zhang,Xuezhao Zhang*

Main category: math.AP

TL;DR: The paper solves the inverse problem of recovering the source profile in the Ginzburg-Landau equation using regional data. It provides two measurement types for unique solvability, establishes stability, and proposes PINN-based algorithms with numerical validation.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of determining the source term in the Ginzburg-Landau equation from limited observation data, ensuring unique solvability and stability.

Method: Uses eigenfunction expansion for conditional stability and analytic continuation for uniqueness and stability from local data. Proposes PINN-based algorithms for numerical solutions.

Result: Demonstrates unique solvability with two measurement types and provides stability estimates. Numerical experiments validate the proposed algorithms.

Conclusion: The paper successfully solves the inverse problem with theoretical guarantees and practical algorithms, supported by numerical results.

Abstract: This paper addresses the problem of recovering the spatial profile of the
source in the complex Ginzburg-Landau equation from regional observation data
at fixed times. We establish two types of sufficient measurements for the
unique solvability of the inverse problem. The first is to determine the source
term by using whole data at one fixed instant. Conditional stability is
established by using the eigenfunction expansion argument. Next, using the
analytic continuation method, both uniqueness and a stability estimate for
recovering the unknown source can be established from local data at two
instants. Finally, algorithms based on the physics-informed neural networks
(PINNs) are proposed, and several numerical experiments are presented to show
the accuracy and efficiency of the algorithm.

</details>


### [19] [A priori Hölder estimates for equations degenerating on nodal sets](https://arxiv.org/abs/2507.18991)
*Susanna Terracini,Giorgio Tortone,Stefano Vita*

Main category: math.AP

TL;DR: The paper proves a priori Hölder bounds for solutions to degenerate equations with variable coefficients, focusing on uniform estimates and boundary Harnack principles.


<details>
  <summary>Details</summary>
Motivation: The study aims to address the behavior of solutions to degenerate equations, particularly when the nodal set of solutions is non-trivial, and to establish uniform estimates for such solutions.

Method: The analysis involves studying weighted Sobolev spaces, examining integrability of weights, capacitary properties of nodal sets, and deriving uniform Sobolev inequalities to ensure local boundedness of solutions.

Result: The results include uniform Hölder bounds for solutions and a boundary Harnack principle for the quotient of two solutions vanishing on a common set.

Conclusion: The work provides a rigorous framework for understanding solutions to degenerate equations, with implications for boundary behavior and uniform estimates.

Abstract: We prove a priori H\"older bounds for continuous solutions to degenerate
equations with variable coefficients of type $$ \mathrm{div}\left(u^2 A\nabla
w\right)=0\quad\mathrm{in \ }\Omega\subset\mathbb R^n,\qquad \mbox{with}\qquad
\mathrm{div}\left(A\nabla u\right)=0, $$ where $A$ is a Lipschitz continuous,
uniformly elliptic matrix (possibly $u$ has non-trivial singular nodal set).
Such estimates are uniform with respect to $u$ in a class of normalized
solutions that have a bounded Almgren frequency. As a consequence, a boundary
Harnack principle holds for the quotient of two solutions vanishing on a common
set.
  This analysis relies on a detailed study of the associated weighted Sobolev
spaces, including integrability of the weight, capacitary properties of the
nodal set, and uniform Sobolev inequalities yielding local boundedness of
solutions.

</details>


### [20] [Counterexample to the second eigenfunction having one zero for a non-local Schrodinger operator](https://arxiv.org/abs/2507.19016)
*Ben Andrews,Sophie Chen*

Main category: math.AP

TL;DR: The paper shows that the second eigenfunction of a perturbed fractional Laplace operator can have two sign changes, challenging the classical expectation of one zero.


<details>
  <summary>Details</summary>
Motivation: To explore the qualitative behavior of eigenfunctions for perturbed nonlocal Schrödinger operators, which lacks rigorous insights.

Method: Uses Kato-Rellich perturbation theory and energy-minimization for infinite and finite potential wells, focusing on the Cauchy process (s=1/2).

Result: Demonstrates that the second eigenfunction can exhibit two sign changes, suggesting similar behavior for other rational s in (0,1).

Conclusion: Provides novel insights into eigenfunction behavior for perturbed nonlocal operators, with implications for broader cases.

Abstract: We demonstrate that the second eigenfunction of a perturbed fractional
Laplace operator on a bounded interval can exhibit two sign changes, in stark
contrast with the classical expectation that it should have exactly one zero.
Our construction employs the Kato-Rellich regular perturbation theory to
analyse an infinite potential well eigenvalue problem, and then uses an
energy-minimisation argument to extend this counterexample to finite potential
wells. Although our detailed analysis focuses on the case where s takes value
1/2 (the Cauchy process), our approach strongly suggests that similar phenomena
occur for other rational values of s in (0, 1). At the time of writing, this
result provides one of the first rigorous insights into the qualitative
behaviour of eigenfunctions for perturbed nonlocal Schrodinger operators.

</details>


### [21] [Modulus of continuity for solutions of non-local heat equations](https://arxiv.org/abs/2507.19023)
*Ben Andrews,Sophie Chen*

Main category: math.AP

TL;DR: The paper extends the modulus of continuity method to non-local heat equations, showing initial conditions' preservation and uncovering a counterexample for a non-local Payne-Weinberger inequality.


<details>
  <summary>Details</summary>
Motivation: To generalize the modulus of continuity method for parabolic equations to non-local heat equations and explore its implications.

Method: Extends the modulus of continuity technique to non-local heat equations on R^n and in one dimension with non-local Neumann boundary conditions.

Result: Initial modulus of continuity is preserved over time for solutions of non-local heat equations. A counterexample suggests limitations in generalizing the Payne-Weinberger inequality.

Conclusion: The method successfully applies to non-local heat equations, but generalizations of inequalities like Payne-Weinberger may require additional domain considerations.

Abstract: We extend the method of modulus of continuity for solutions of parabolic
equations--as used, for instance, to prove the Fundamental Gap Conjecture--to
solutions of non-local heat equations on R^n and in dimension one with a
non-local Neumann boundary condition. Specifically, we show that if a solution
of a non-local heat equation has an initial modulus of continuity satisfying
simple criteria, then this modulus of continuity is preserved at all subsequent
times. In the process of trying to generalise our result in one dimension, we
found a counterexample suggesting that a non-local analogue of the
Payne-Weinberger inequality would depend on more than the diameter of a bounded
(convex) domain.

</details>


### [22] [Stability of laminar monotone shear flows in a channel for high Reynolds number](https://arxiv.org/abs/2507.19106)
*Yaniv Almog,Bernard Helffer*

Main category: math.AP

TL;DR: The paper studies the stability of a laminar flow in a 2D channel at high Reynolds numbers, generalizing prior results by allowing long wave perturbations.


<details>
  <summary>Details</summary>
Motivation: To extend understanding of flow stability under less restrictive conditions, particularly when the second derivative of the flow profile vanishes.

Method: Analyzes the operator $\mathcal{K}_{\nu}$ for strict positivity, ensuring stability for large Reynolds numbers.

Result: If $\mathcal{K}_{\nu}$ is strictly positive under given conditions, the flow remains stable at high Reynolds numbers.

Conclusion: The work broadens stability criteria by accommodating more general flow profiles and longer perturbations.

Abstract: We consider the stability of a laminar flow $U\in C^4([-1,1])$ in the
two-dimensional channel $\mathbb{R} \times[-1,1]$ in the large Reynolds number
limit. Assuming that $U$ is strictly monotone but allowing $U^{\prime\prime}$
to vanish, we obtain that if the operator
  $$
  {\mathcal K}_{\nu}=-\frac{d^2}{dx^2}+\frac{U^{\prime\prime}}{U-\nu} \,, $$ is
strictly positive for all $\nu\in\mathbb{R}$ for which
$U^{\prime\prime}(U^{-1}(\nu))=0$,then $U$ is stable for sufficiently large
Reynolds number. This contribution generalizes previous results mostly by
allowing long wave perturbations (but much shorter than the Reynolds number).

</details>


### [23] [Scattering theory of the nonlinear wave equations on lattices](https://arxiv.org/abs/2507.19160)
*Jiajun Wang*

Main category: math.AP

TL;DR: Summary of uniform decay estimates for discrete wave equations and scattering theory for discrete nonlinear wave equations using oscillatory integrals and Strichartz estimates.


<details>
  <summary>Details</summary>
Motivation: To extend scattering theory to discrete nonlinear wave equations by leveraging existing frameworks and estimates.

Method: Combines oscillatory integral theory and abstract scattering framework, with additional use of Strichartz estimates.

Result: Established scattering theory for DNLW, including wave operators and asymptotic completeness.

Conclusion: Demonstrated applicability of scattering theory to discrete nonlinear wave equations through multiple approaches.

Abstract: In this paper, I will summarize the uniform decay estimates of the discrete
wave equations (DW) established by the oscillatory integral theory in [Sch98,
BCH23, BCH24], and combine the abstract framework of the scattering theory of
the dispersive equations established in [Str81] to finally establish the
scattering theory of the discrete nonlinear wave equations (DNLW), including
the existence of the wave operators and the asymptotic completeness. In
addition, I will establish the scattering theory again by the Strichartz
estimate.

</details>


### [24] [Reconstruction in the Calderón problem on a fixed partition from finite and partial boundary data](https://arxiv.org/abs/2507.19410)
*Henrik Garde*

Main category: math.AP

TL;DR: Modifies a reconstruction method for piecewise constant conductivities in the Calderón problem, removing the need for layering assumptions and local Neumann-to-Dirichlet maps when the partitioning is known.


<details>
  <summary>Details</summary>
Motivation: To simplify the reconstruction process by eliminating unnecessary assumptions and requirements when the partitioning of piecewise constant conductivities is known.

Method: Adjusts the author's prior reconstruction method to work with known partitioning, requiring only finite partial boundary measurements and no conductivity bounds.

Result: The modified method successfully reconstructs general piecewise constant conductivities without layering assumptions or conductivity bounds.

Conclusion: The method is more flexible and efficient for cases where the partitioning is known, reducing computational and theoretical overhead.

Abstract: This short note modifies a reconstruction method by the author (Comm. PDE,
45(9):1118--1133, 2020), for reconstructing piecewise constant conductivities
in the Calder\'on problem (electrical impedance tomography). In the former
paper, a layering assumption and the local Neumann-to-Dirichlet map was needed
since the piecewise constant partitioning also was assumed unknown. Here I show
how to modify the method in case the partitioning is known, for general
piecewise constant conductivities and only a finite number of partial boundary
measurements. Moreover, no lower/upper bounds on the unknown conductivity are
needed.

</details>


### [25] [On polarization interface conditions for time-harmonic Maxwell's equations](https://arxiv.org/abs/2507.19192)
*Bérangère Delourme,Ben Schweizer,David Wiedemann*

Main category: math.AP

TL;DR: Analysis of time-harmonic Maxwell's equations with a polarization interface condition, derived from thin wire homogenization, including existence results and a Fredholm-alternative.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of Maxwell's equations under polarization interface conditions, which arise from homogenizing thin wire inclusions.

Method: Analyze the limit equations derived from the interface conditions, focusing on existence and uniqueness of solutions.

Result: Established an existence result and a Fredholm-alternative for the limit equations.

Conclusion: The study provides theoretical insights into the solutions of Maxwell's equations under specific interface conditions, relevant for thin wire homogenization.

Abstract: We consider the time-harmonic Maxwell's equations with a polarization
interface condition. The interface condition demands that one component of the
electric field vanishes at the interface and that the corresponding component
of the magnetic field has no jump across the interface. These conditions have
been derived in the literature as a homogenization limit for thin wire
inclusion. We analyze the limit equations and provide an existence result and a
Fredholm-alternative.

</details>


### [26] [Infinite Dimensional Mean-Field Belavkin Equation: Well-posedness and Derivation](https://arxiv.org/abs/2507.19231)
*Anne de Bouard,Gaoyue Guo,Théo Hérouard*

Main category: math.AP

TL;DR: Derived mean-field limit for a stochastic Schrödinger equation in quantum control, extending prior results to unbounded operators and infinite dimensions, with rigorous convergence proofs.


<details>
  <summary>Details</summary>
Motivation: To address the gap in mean-field approximations for quantum systems with unbounded operators and infinite dimensions, enabling better simulation and control of large quantum systems.

Method: Used fixed-point methods for global well-posedness, avoiding measure-change techniques, and derived mean-field approximations under minimal assumptions.

Result: Achieved higher regularity solutions and proved rigorous convergence to the mean-field limit in infinite-dimensional settings.

Conclusion: First derivation of mean-field limits for wave functions in L²(R^d), advancing quantum system simulation and control.

Abstract: We analyze the mean-field limit of a stochastic Schr{\"o}dinger equation
arising in quantum optimal control and mean-field games, where N interacting
particles undergo continuous indirect measurement. For the open quantum system
described by Belavkin's filtering equation, we derive a mean-field
approximation under minimal assumptions, extending prior results limited to
bounded operators and finitedimensional settings. By establishing global
well-posedness via fixed-point methods-avoiding measure-change techniques-we
obtain higher regularity solutions. Furthermore, we prove rigorous convergence
to the mean-field limit in an infinitedimensional framework. Our work provides
the first derivation of such limits for wave functions in $L^2 (R^d)$, with
implications for simulating and controlling large quantum systems.

</details>


### [27] [A Wave-type Model for Age- and Space-structured Epidemics](https://arxiv.org/abs/2507.19252)
*Nicolas Schlosser*

Main category: math.AP

TL;DR: A novel epidemic modeling approach combines age-structured models with damped wave equations, transforming parabolic reaction-diffusion into a hyperbolic system. Solutions converge to standard models as the wave parameter diminishes, supported by numerical examples.


<details>
  <summary>Details</summary>
Motivation: To enhance epidemic modeling by integrating age-structured dynamics with wave-like behavior, improving accuracy and realism.

Method: Combines age-structured models with damped wave equations, transforming parabolic reaction-diffusion into hyperbolic systems. Uses characteristics to establish weak solutions.

Result: Solutions converge to standard age-dependent reaction-diffusion models as the wave parameter approaches zero. Numerical examples validate the model.

Conclusion: The new model effectively bridges wave-like and standard epidemic dynamics, offering a more versatile framework for modeling.

Abstract: We introduce a novel approach of epidemic modeling by combining
age-structured models with damped wave equations. This transforms the
parabolic-type reaction-diffusion model into a hyperbolic system that shares
many properties with a wave or telegrapher's equation. After we establish the
existence of a weak solution of the resulting partial differential equation by
means of characteristics, we show that the solutions to the new model converge
to a solution of the standard age-dependent reaction-diffusion equation when we
let the wave parameter become arbitrarily small. We conclude with a numerical
example to illustrate the behavior of the new model and to further support our
findings.

</details>


### [28] [Vanishing viscosity non-unique solutions to the forced 2D Euler Equations](https://arxiv.org/abs/2507.19257)
*Dallas Albritton,Maria Colombo,Giulia Mescolini*

Main category: math.AP

TL;DR: The paper explores whether the inviscid limit of 2D Navier-Stokes equations can resolve non-uniqueness in 2D Euler solutions, identifying a uniqueness threshold for perturbations.


<details>
  <summary>Details</summary>
Motivation: To determine if the inviscid limit acts as a selection principle for non-unique solutions in forced 2D Euler equations, focusing on perturbations near Vishik's non-uniqueness scenario.

Method: Incorporate viscosity and analyze small perturbations of initial data, identifying a threshold where solutions transition from unique (radial) to non-unique (non-radial).

Result: A uniqueness threshold ε ∼ ν^κ_c is found, below which solutions are unique and radial, and at which non-unique, non-radial solutions emerge.

Conclusion: The inviscid limit can act as a selection principle, but only below a critical perturbation size, beyond which non-uniqueness persists.

Abstract: The forced 2D Euler equations exhibit non-unique solutions with vorticity in
$L^p$, $p > 1$, whereas the corresponding Navier-Stokes solutions are unique.
We investigate whether the inviscid limit $\nu \to 0^+$ from the forced 2D
Navier-Stokes to Euler equations is a selection principle capable of
"resolving" the non-uniqueness. We focus on solutions in a neighborhood of the
non-uniqueness scenario discovered by Vishik; specifically, we incorporate
viscosity $\nu$ and consider $O(\varepsilon)$ size perturbations of the initial
datum. We discover a uniqueness threshold $\varepsilon \sim \nu^{\kappa_{\rm
c}}$, below which the vanishing viscosity solution is unique and radial, and at
which there are viscous solutions converging to non-unique, non-radial
solutions.

</details>


### [29] [Free boundary problem of low Mach number magnetohydrodynamic flows](https://arxiv.org/abs/2507.19268)
*Ruixi Zhang*

Main category: math.AP

TL;DR: Analysis of a free boundary problem in low Mach number magnetohydrodynamic flow, deriving a priori estimates and a blow-up criterion.


<details>
  <summary>Details</summary>
Motivation: To study the behavior of low Mach number magnetohydrodynamic flows in higher spatial dimensions and establish analytical tools for understanding their dynamics.

Method: Adopts a geometrical approach inspired by Christodoulou and Lindblad for a priori estimates and uses the Beale-Kato-Majda method for the blow-up criterion.

Result: Obtained Sobolev norm estimates for the second fundamental form and flow quantities, along with a derived blow-up criterion.

Conclusion: The paper provides analytical insights into the dynamics of low Mach number magnetohydrodynamic flows, with potential applications in fluid dynamics and plasma physics.

Abstract: In this paper we consider a free boundary problem of low Mach number
magnetohydrodynamic flow in spatial dimension n $\geq$ 2. A priori estimates of
the second fundamental form and various flow quantities in Sobolev norms are
obtained by adopting the geometrical point of view introduced by Christodoulou
and Lindblad [3]. Moreover, a blow up criterion is derived by using the method
of Beale, Kato and Majda [2].

</details>


### [30] [Fully nonlinear parabolic fixed transmission problems](https://arxiv.org/abs/2507.19277)
*David Jesus,María Soria-Carro*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We consider transmission problems for parabolic equations governed by
distinct fully nonlinear operators on each side of a time-dependent interface.
We prove that if the interface is $C^{1,\alpha}$, in the parabolic sense, then
viscosity solutions are piecewise $C^{1,\alpha}$ up to the interface. As
byproducts, we obtain a new ABP-Krylov-Tso estimate, and establish existence,
uniqueness, a comparison principle, and regularity results for the flat
interface problem.

</details>


### [31] [Concentration comparison for nonlinear diffusion on model manifolds and Pólya-Szegő inequality](https://arxiv.org/abs/2507.19279)
*Matteo Muratori,Bruno Volzone*

Main category: math.AP

TL;DR: The paper examines the mass concentration comparison for nonlinear diffusion equations on spherically symmetric Riemannian manifolds, linking it to the Pólya-Szegő inequality and scalar curvature.


<details>
  <summary>Details</summary>
Motivation: To understand when the mass concentration comparison holds for diffusion equations on model manifolds, given its validity in Euclidean space due to the Pólya-Szegő inequality.

Method: Analyzes conditions involving scalar curvature and proves the equivalence of the concentration comparison and the Pólya-Szegő inequality for filtration equations.

Result: Shows the concentration comparison holds if and only if the Pólya-Szegő inequality is valid, extending to hyperbolic space and the sphere via centered isoperimetric inequalities.

Conclusion: The validity of the concentration comparison is tied to the Pólya-Szegő inequality, with implications for important manifolds like hyperbolic space and the sphere.

Abstract: We investigate the validity of the mass concentration comparison for a class
of nonlinear diffusion equations posed on Riemannian manifolds $ \mathbb{M}^n $
that are spherically symmetric, that is, model manifolds. The concentration
comparison states that the solution of a certain diffusion equation that takes
the radially decreasing (Schwarz) rearrangement $ u_0^\star $ as its initial
datum is more concentrated than the original solution starting from $u_0$. This
is known to hold in $\mathbb{R}^n$ as a consequence of the celebrated
P\'olya-Szeg\H{o} inequality, which asserts that the $ L^2 $ norm of the
gradient of a function $f$ (belonging to an appropriate Sobolev space) is
always larger than the $ L^2 $ norm of the gradient of its radially decreasing
rearrangement $f^\star$. However, if $ \mathbb{M}^n $ is a general model
manifold, it is not for granted that the P\'olya-Szeg\H{o} inequality holds; in
fact, we will provide a simple condition involving the scalar curvature of
$\mathbb{M}^n $ under which such an inequality actually fails. The main result
we prove states that, given any continuous, nondecreasing, and nontrivial
function $ \phi: [0,+\infty) \to [0,+\infty) $, the filtration equation $
\partial_t u = \Delta \phi(u) $ satisfies the concentration comparison in $
\mathbb{M}^n \times (0,+\infty) $ if and only if $ \mathbb{M}^n $ supports the
P\'olya-Szeg\H{o} inequality. In particular, the validity of such a comparison
for the heat equation is sufficient to guarantee that the same holds for all
filtration equations. Moreover, we prove that if $ \mathbb{M}^n $ supports a
centered isoperimetric inequality then the P\'olya-Szeg\H{o} inequality, and
thus the concentration comparison, holds. This allows us to include important
examples such as the hyperbolic space and the sphere.

</details>


### [32] [On the asymptotic properties of solutions to a nonlinear transmission problem for a Bresse beam with thermal damping](https://arxiv.org/abs/2507.19297)
*Tamara Fastovska,Dirk Langemann*

Main category: math.AP

TL;DR: The paper analyzes a nonlinear transmission problem for an arch beam with thermal damping in one part, proving well-posedness and global attractor existence under specific conditions. It also studies singular limits and includes numerical simulations.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of an arch beam with mixed material properties and thermal damping, focusing on well-posedness and dynamic stability.

Method: Theoretical analysis of the system in the energy space, with conditions on damping coefficients, and numerical simulations for singular limits.

Result: Proves well-posedness and existence of a compact global attractor. Studies singular limits as curvature vanishes or shear moduli diverge.

Conclusion: The system is well-posed with a global attractor under certain conditions, and singular limits are numerically validated.

Abstract: A nonlinear transmission problem for an arch beam, which consists of two
parts with different material properties is considered. One of the parts is
subjected to thermal damping while another one is undamped. The thermal damping
affects only the shear angle and the longitudinal equation within the damped
part, which can have any positive length. We prove the well-posedness of the
system in the energy space and establish the existence of a compact global
attractor under certain conditions imposed solely on the coefficients of the
damped part. Additionally, we study singular limits of the system as the
curvature of the beam tends to zero or in case both the curvature vanishes and
the shear moduli tend to infinity. Numerical simulations are also carried out
to model these limiting behaviors.

</details>


### [33] [Miminization of the first eigenvalue of the Dirichlet Laplacian with a small volume obstacle](https://arxiv.org/abs/2507.19339)
*Benedetta Noris,Giovanni Siclari,Gianmaria Verzini*

Main category: math.AP

TL;DR: The paper analyzes the optimal placement of obstacles to minimize the first Dirichlet eigenvalue in a domain, showing that in the small volume limit, obstacles concentrate at boundary points with minimal gradient of the first eigenfunction.


<details>
  <summary>Details</summary>
Motivation: To understand how to optimally remove obstacles from a domain to minimize the first Dirichlet eigenvalue, a problem relevant in spectral optimization and shape design.

Method: The study uses sharp eigenvalue estimates and a notion of relative capacity to analyze the behavior of optimal obstacles, eigenvalues, and eigenfunctions as the obstacle volume approaches zero.

Result: Optimal obstacles accumulate at boundary points where the gradient of the first eigenfunction is minimal, with detailed convergence results for eigenvalues, eigenfunctions, and free boundaries.

Conclusion: The findings provide a precise description of optimal obstacle placement and eigenvalue behavior in the small volume regime, advancing spectral optimization theory.

Abstract: We consider the well-known shape optimization problem with spectral cost:
minimizing the first eigenvalue of the Dirichlet Laplacian among all subdomains
$\Omega$ having prescribed volume and contained in a fixed box $D$;
equivalently, we look for the best way to remove a compact set (obstacle)
$K\subset\overline{D}$ of Lebesgue measure $|K|=\varepsilon$,
$0<\varepsilon<|D|$, in order to minimize the first Dirichlet eigenvalue of the
set $\Omega = D \setminus K$.
  In the small volume regime $\varepsilon\to0$, we prove that the optimal
obstacles accumulate, in a suitable sense, to points of $\partial D$ where
$|\nabla \phi_0|$ is minimal, where $\phi_0$ denotes the first eigenfunction of
the Dirichlet Laplacian on $D$. Moreover, we provide a fairly detailed
description of the convergence of the optimal eigenvalues, eigenfunctions and
free boundaries. Our results are based on sharp estimates of the optimal
eigenvalues, in terms of a suitable notion of relative capacity.

</details>


### [34] [Self-Similar Solutions to the Hele-Shaw Problem with Surface Tension](https://arxiv.org/abs/2507.19443)
*Siddhant Agrawal,Neel Patel*

Main category: math.AP

TL;DR: Existence of self-similar solutions for the Hele-Shaw problem with surface tension, starting from a corner at t=0 and smoothing for t>0.


<details>
  <summary>Details</summary>
Motivation: To explore the behavior of the Hele-Shaw problem with surface tension, particularly focusing on initial corner conditions and their evolution.

Method: Analysis of self-similar solutions, starting with a corner of angle θ near π at t=0 and examining smoothness for t>0.

Result: Proves the existence of a family of self-similar solutions that transition from a corner to smoothness over time.

Conclusion: The study demonstrates the existence and evolution of self-similar solutions in the Hele-Shaw problem, highlighting the role of surface tension.

Abstract: We consider the Hele-Shaw problem with surface tension in an infinite domain.
We prove the existence of a family of self-similar solutions. At $t=0$, these
solutions have a corner of angle $\theta$ with $ 0 < |\theta - \pi| \ll 1$, and
for $t>0$, the solutions are smooth.

</details>


### [35] [Schrödinger-Bopp-Podolsky system with sublinear and critical nonlinearities: solutions at negative energy levels and asymptotic behaviour](https://arxiv.org/abs/2507.19444)
*Heydy M. Santos Damian,Gaetano Siciliano*

Main category: math.AP

TL;DR: The paper studies a Schrödinger-Bopp-Podolsky system with critical and sublinear terms, proving existence of infinitely many solutions (including ground states) for small λ, analyzing solution structure, and examining behavior as parameters a, λ approach zero.


<details>
  <summary>Details</summary>
Motivation: To explore solutions of a complex Schrödinger-Bopp-Podolsky system with critical and sublinear terms, addressing gaps in understanding solution multiplicity and behavior under parameter variations.

Method: Mathematical analysis of the system, including variational methods to prove existence of solutions and asymptotic analysis to study parameter-dependent behavior.

Result: Existence of infinitely many solutions (including ground states) for small λ; ground states converge to Schrödinger-Poisson solutions as a→0.

Conclusion: The system exhibits rich solution structures, with ground states transitioning to Schrödinger-Poisson solutions as a parameter vanishes, providing insights into critical nonlinear systems.

Abstract: We consider the following Schr\"odinger-Bopp-Podolsky system with critical
and sublinear terms \begin{equation*} \begin{cases}
  - \Delta u+ u+Q(x)\phi u= \vert u\vert^4 u+ \lambda K(x)\vert u
\vert^{p-1}u&\mbox{ in }\ \mathbb{R}^3 \smallskip
  - \Delta \phi+ a^{2}\Delta^{2} \phi = 4\pi Q(x) u^{2}& \mbox{ in }\
\mathbb{R}^3. \end{cases} \end{equation*} Here $u,\phi:\mathbb
{R}^{3}\rightarrow \mathbb{R}$ are the unknowns, $Q$ and $K$ are given
functions satisfying mild assumptions, $a\geq0, \lambda>0$ are parameters and
$p\in (0,1)$.
  We first show existence of infinitely many solutions at negative energy
level, including the ground state, when the parameter $\lambda$ is small. Then
  we give general results concerning the structure of the set of solutions.
  We show also the behaviour of the solutions as the parameters $a,\lambda$
tend to zero. In particular the ground states solutions tends to a ground state
solution of the Schr\"odinger-Poisson system as $a$ tends to zero.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [36] [Tensor Networks for Liquids in Heterogeneous Systems](https://arxiv.org/abs/2507.19352)
*Zachary A. Johnson,Luciano G. Silvestri,Pierson Guthrey,Michael S. Murillo*

Main category: physics.comp-ph

TL;DR: Tensor network methods solve high-dimensional equations for equilibrium density and density-density correlations in confined heterogeneous liquids, showing compression efficiency in certain representations.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenge of describing many-body correlations in strongly coupled liquids and plasmas in heterogeneous environments due to high-dimensional equations.

Method: Using tensor network decompositions (quantized tensor trains and standard tensor-train formats) to solve for equilibrium density and density-density correlation functions.

Result: Demonstrated high compression efficiency for lengthscale and spatial-coordinate dependencies, but not for distinct particle coordinates.

Conclusion: Tensor network methods are effective for certain representations in solving high-dimensional problems in heterogeneous environments.

Abstract: Many-body correlations in strongly coupled liquids and plasmas are critical
for many applications in nanofluids, biology, and fusion-related plasma
physics, but their description in fully heterogeneous environments remains
challenging due to the high-dimensional equations involved. Recently, tensor
network decompositions have emerged as powerful tools for tackling such
equations by reducing memory usage and computational complexity. In this paper,
we solve for equilibrium density and density-density correlation functions of
liquids in confined heterogeneous environments using tensor network methods. We
demonstrate that these functions admit high compression when their lengthscale
dependence is encoded via quantized tensor trains or when their
spatial-coordinate dependence is represented in standard tensor-train format,
but not with respect to their dependence on distinct particle coordinates.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [37] [An ignition criterion for inertial fusion boosted by microturbulence](https://arxiv.org/abs/2507.18917)
*Henry Fetsch,Nathaniel J. Fisch*

Main category: physics.plasm-ph

TL;DR: Turbulence in plasmas lowers ignition temperature by enhancing fusion reactivity, with optimal turbulence scale in the micron range.


<details>
  <summary>Details</summary>
Motivation: To explore how turbulence can reduce the energy required for ignition in inertially confined plasmas.

Method: Derived a modified Lawson-like ignition criterion for plasmas with turbulent kinetic energy, focusing on small-scale turbulence in the hot spot.

Result: Turbulence reduces ignition energy if confined to the hot spot; optimal turbulence scale is typically microns.

Conclusion: Turbulence can significantly lower ignition requirements, offering a pathway to more efficient fusion.

Abstract: Turbulence enhances fusion reactivity, enabling ignition at lower
temperature. A modified Lawson-like ignition criterion is derived for
inertially confined plasmas harboring turbulent kinetic energy. Remarkably, if
small-scale turbulence is driven in the hot spot while avoiding mixing at the
boundary, less energy is required to ignite a target. The optimal length scale
for hot-spot turbulence is quantified, typically lying in the micron range.

</details>


### [38] [Dynamically phase-separated states in driven binary dusty plasma](https://arxiv.org/abs/2507.19248)
*Farida Batool,Sandeep Kumar,Sanat Kumar Tiwari*

Main category: physics.plasm-ph

TL;DR: The paper studies dynamical structure formation in binary dusty plasma mixtures, revealing phase segregation into bands and lanes under external forcing, with scaling behaviors differing from equilibrium systems.


<details>
  <summary>Details</summary>
Motivation: To understand phase segregation in binary dusty plasma mixtures under external forcing and bridge the gap between dusty plasmas and colloidal systems.

Method: Two-dimensional driven-dissipative molecular dynamics simulations with Debye-Hückel potential interactions, analyzing phase-space diagrams and diagnostics like order parameters and diffusion coefficients.

Result: Phase segregation into bands and lanes occurs beyond a critical forcing threshold, with lane formation under high forcing. Time evolution of widths follows a 1/3 exponent, differing from equilibrium scaling.

Conclusion: The findings provide insights into non-equilibrium phase segregation and support controlled experiments in dusty plasmas, contrasting with equilibrium behaviors.

Abstract: We comprehensively study external forcing-driven dynamical structure
formation in a binary dusty plasma mixture. Using two-dimensional
driven-dissipative molecular dynamics simulations, we demonstrate phase
segregation into bands and lanes beyond a critical forcing threshold. The
particles interact via the Debye-H\"uckel potential, with interaction strength
serving as a control parameter for determining the critical forcing. During
early evolution, the results exhibit features of two-stream instability. A
steady-state phase-space diagram indicates that bands and lanes emerge beyond a
critical forcing and coupling strength. Lanes predominantly form under high
external forcing. Multiple independent diagnostics, including the order
parameter, drift velocity, diffusion coefficients, domain size, and the
final-to-initial coupling strength ratio, provide insight into phase
segregation and help determine the critical forcing amplitude. Furthermore, we
show that the time evolution of band and lane widths follows an exponent of 1/3
for both critical and off-critical mixtures. These findings contrast with the
previously reported scaling of 1/2 for equilibrium phase separation in critical
mixtures. These results help bridge the gap between dusty plasmas and colloidal
systems and facilitate controlled dusty plasma experiments in this direction.

</details>


### [39] [Enhanced performance in quasi-isodynamic max-$J$ stellarators with a turbulent particle pinch](https://arxiv.org/abs/2507.19319)
*G. G. Plunk,A. G. Goodman,P. Xanthopoulos,P. Costello,H. M. Smith,K. Aleynikova,C. D. Beidler,M. Drevlak,P. Helander*

Main category: physics.plasm-ph

TL;DR: SQuID-τ is a self-fueling stellarator that enables inward particle transport via turbulence, improving confinement and relaxing reactor design constraints.


<details>
  <summary>Details</summary>
Motivation: Traditional stellarators face outward turbulent particle transport, hindering density gradients needed for confinement.

Method: Introduces SQuID-τ, a quasi-isodynamic stellarator, using high-fidelity gyrokinetic simulations to predict profiles.

Result: Demonstrates sustained density peaking and enhanced performance, reducing reactor size and magnetic field requirements.

Conclusion: SQuID-τ offers a promising solution for stellarator reactor designs by addressing turbulent transport limitations.

Abstract: Recent stellarator reactor designs demonstrate mostly outward turbulent
particle transport, which, without advanced fueling technology, inhibits the
formation of density gradients needed for confinement. We introduce
``SQuID-$\tau$'', a self-fueling quasi-isodynamic stellarator capable of
sustaining density peaking through inward particle transport caused by
turbulence. Temperature and density profile predictions based on high-fidelity
gyrokinetic simulations demonstrate enhanced performance, significantly
relaxing constraints on the size and magnetic field strength for reactor
designs.

</details>


### [40] [Multiscale Modeling of Positive Corona Discharges](https://arxiv.org/abs/2507.19337)
*Giuseppe Caliò,Fabio Ragazzi,Arturo Popoli,Andrea Cristofolini,Lorenzo Valdettaro,Carlo De Falco,Paolo Barbante*

Main category: physics.plasm-ph

TL;DR: The paper proposes a macro-scale model for corona discharges, simplifying the ionization process with boundary conditions to reduce computational effort, validated by experimental data.


<details>
  <summary>Details</summary>
Motivation: To address the computational complexity of modeling corona discharges, especially in multi-dimensional simulations, by simplifying the ionization region.

Method: Develops a macro-scale model using boundary conditions derived from a detailed full-scale 1D model of the discharge, including the ionization region.

Result: The macro-scale model's results align with experimental data and simplified analytical models for positive corona discharges.

Conclusion: The proposed methodology effectively reduces computational effort while maintaining accuracy, applicable to various geometries with the same emitter.

Abstract: In the field of corona discharges, the complex chemical mechanisms inside the
ionization region have prompted the development of simplified models to
replicate the macroscopic effects of ion generation, thereby reducing the
computational effort, especially in two and three dimensional simulations. We
propose a methodology that allows to replace the ionization process with
appropriate boundary conditions used by a corona model solving the drift
region. We refer to this model as macro-scale, since it does not solve the
ionization region. Our approach begins with one dimensional computations in
cylindrical coordinates of the whole discharge, where we include a fairly
detailed model of the plasma region near the emitter. We refer to this model as
full-scale, since all the spatial scales, including the ionization region, are
properly taken into account. From these results it is possible to establish
boundary conditions for macroscopic simulations. The idea is that, given an
emitter radius, the boundary conditions can be used for a variety of geometries
that leverage on that emitter as active electrode. Our results agree with
available experimental data for positive corona discharges in different
configurations and with simplified analytical models from literature.

</details>


### [41] [Perturbative model for the saturation of energetic-particle-driven modes limited by self-generated zonal modes](https://arxiv.org/abs/2507.19393)
*Tommaso Barberis,Vinícius N. Duarte,Eamon J. Hartigan-O'Connor,Nikolai N. Gorelenkov*

Main category: physics.plasm-ph

TL;DR: A simplified model enforces energy conservation to study zonal modes and wave-particle nonlinearities, showing how zonal perturbations affect mode saturation and microturbulence.


<details>
  <summary>Details</summary>
Motivation: To understand the role of zonal modes and nonlinearities in mode saturation and their impact on microturbulent particle scattering.

Method: Analytical and numerical investigation of mode amplitude evolution and saturation, assuming zonal perturbations grow at twice the pump wave rate.

Result: The model captures key simulation features, like reduced saturation amplitude and wave-wave nonlinear effects, and can be integrated into reduced-model codes.

Conclusion: The model improves predictive capability for strongly driven instabilities by accounting for zonal mode effects and energy conservation.

Abstract: We present a simplified approach enforcing energy conservation to incorporate
the effects of zonal modes alongside wave-particle nonlinearities in the
determination of the saturation amplitude. The model assumes that the zonal
perturbations grow at a rate twice that of the original (pump) wave, consistent
with a beat-driven (or force-driven) generation mechanism. The evolution and
saturation of the mode amplitude are investigated both analytically and
numerically within our reduced model assumptions, in both the collisionless and
scattering-dominated regimes. These studies underscore the crucial role of
sources and sinks in accurately capturing the impact and the role of
beat-driven zonal perturbations on mode evolution. In the realistic case of
saturation set by sources and sinks, we discuss the role of a finite amplitude
zonal mode in reducing microturbulent particle scattering, thus limiting the
energy source for the resonant mode. We then discuss comparisons between the
model predictions and simulation results. The model reproduces key features
observed in gyrokinetic simulations as the reduction in saturated mode
amplitude and the onset of wave-wave nonlinear effects as functions of mode
growth rate and amplitude. Thanks to its simplicity, it can be readily
implemented into codes based on reduced models, thereby improving their
predictive capability for strongly driven instabilities.

</details>


### [42] [Unveiling the Velocity-Space Signature of Ion Cyclotron Damping Using Liouville Mapping](https://arxiv.org/abs/2507.19436)
*Rui Huang,Gregory G. Howes*

Main category: physics.plasm-ph

TL;DR: The study investigates ion cyclotron damping using Liouville mapping and field-particle correlation, revealing distinct velocity-space signatures and validating the method with Landau damping.


<details>
  <summary>Details</summary>
Motivation: To understand and quantify the velocity-space signatures of ion cyclotron damping in weakly collisional plasmas.

Method: Combines Liouville mapping for efficient prediction of velocity distribution perturbations and field-particle correlation to identify energy transfer signatures.

Result: Reveals quadrupolar patterns in perpendicular velocity space and localized energization at resonant velocity, with minimal dependence on ion plasma beta.

Conclusion: Provides a systematic approach to identify ion cyclotron damping in simulations or spacecraft data, showing consistent signatures across varying plasma conditions.

Abstract: Ion cyclotron damping is a key mechanism for the dissipation of
electromagnetic wave energy in weakly collisional plasmas. This study presents
a combined approach using Liouville mapping and the field-particle correlation
technique to investigate qualitatively and quantitatively the velocity-space
signature of ion cyclotron damping. Liouville mapping offers a computationally
efficient way to predict perturbations to the particle velocity distribution
function using single-particle trajectories in prescribed electromagnetic
fields. One may apply the field-particle correlation technique to these
perturbed velocity distributions to reveal the unique velocity-space signatures
of the secular energy transfer rate associated with specific wave-particle
interactions. We validate this method by reproducing known Landau damping
signatures for kinetic Alfv\'en waves, and then we apply this method to ion
cyclotron waves where ion cyclotron damping dominates. The resulting
velocity-space signature reveals distinct energization features of ion
cyclotron damping : (i) a quadrupolar pattern in the perpendicular $(v_x, v_y)$
plane; and (ii) a localized energization near the $n = 1$ resonant velocity in
gyrotropic $(v_\parallel, v_\perp)$ velocity-space. The quantitative patterns
remain unchanged as the ion plasma beta $\beta_i$ is varied, ultimately showing
minimal $v_\perp$ dependence on $\beta_i$ of the velocity-space signature at
the $n = 1$ resonant velocity. This work provides a systematic study of how the
ion cyclotron damping signature varies with $\beta_i$, offering a practical
foundation to identify ion cyclotron damping using kinetic simulation data or
spacecraft data.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [43] [Accuracy and Limitations of Machine-Learned Interatomic Potentials for Magnetic Systems: A Case Study on Fe-Cr-C](https://arxiv.org/abs/2507.18935)
*E. O. Khazieva,N. M. Chtchelkatchev,R. E. Ryltsev*

Main category: cond-mat.mtrl-sci

TL;DR: The paper explores machine-learned interatomic potentials (MLIPs) for magnetic materials, focusing on the Fe-Cr-C system. It compares non-magnetic (DP-NM) and spin-polarized (DP-M) potentials, finding DP-NM better for dynamic properties and DP-M for static properties. A transfer-learning protocol reduces computational costs for developing magnetic MLIPs.


<details>
  <summary>Details</summary>
Motivation: Extending MLIPs to magnetic materials is challenging due to spin fluctuations. The study aims to address this for the Fe-Cr-C system, a technologically important material.

Method: Two deep machine learning potentials (DP-NM and DP-M) are constructed using DeePMD, trained on non-magnetic and spin-polarized DFT data, respectively. A transfer-learning protocol is introduced to reduce computational costs.

Result: DP-NM accurately predicts dynamic properties (viscosity, melting temperatures), while DP-M excels in static properties (density, lattice parameters). Transfer-learning reduces computational costs significantly.

Conclusion: Proper treatment of spin fluctuations in DFT and force fields is crucial for general-purpose MLIPs. The transfer-learning protocol offers a cost-effective solution for developing magnetic MLIPs.

Abstract: Machine-learned interatomic potentials (MLIPs) have become the gold standard
for atomistic simulations, yet their extension to magnetic materials remains
challenging because spin fluctuations must be captured either explicitly or
implicitly. We address this problem for the technologically vital Fe-Cr-C
system by constructing two deep machine learning potentials in DeePMD
realization: one trained on non-magnetic DFT data (DP-NM) and one on
spin-polarised DFT data (DP-M). Extensive validation against experiments
reveals a striking dichotomy. The dynamic, collective properties, viscosity and
melting temperatures are reproduced accurately by DP-NM but are incorrectly
estimated by DP-M. Static, local properties, density, and lattice parameters
are captured excellently by DP-M, especially in Fe-rich alloys, whereas DP-NM
fails. This behaviour is explained by general properties of paramagnetic state:
at high temperature, local magnetic moments self-average in space and time, so
their explicit treatment is unnecessary for transport properties but essential
for equilibrium volumes. Exploiting this insight, we show that a
transfer-learning protocol, pre-training on non-magnetic DFT and fine-tuning on
a small set of spin-polarised data, reduces the computational cost to develop
magnetic MLIPs by more than an order of magnitude. Developing general-purpose
potentials that capture static and dynamic behaviors throughout the whole
composition space requires proper accounting for temperature-induced spin
fluctuations in DFT calculations and correctly incorporating spin degrees of
freedom into classical force fields.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [44] [Early State Exclusion in 7-Qubit Spin Chains](https://arxiv.org/abs/2507.18767)
*Mia Gabriella Escobar,Valentin Garcia,Anastasiia Minenkova*

Main category: quant-ph

TL;DR: Existence of infinite families of Jacobi matrices for odd N≥7 is proven, addressing a previously open problem.


<details>
  <summary>Details</summary>
Motivation: To resolve the open problem of whether infinite families of Jacobi matrices exist for odd N≥7 in quantum spin chains.

Method: Analyze a chain of qubits with nearest-neighbor interactions and environmental effects, focusing on 7×7 Jacobi matrices.

Result: Infinite families of 7×7 Jacobi matrices with and without early state exclusion (ESE) are presented.

Conclusion: The study successfully extends the existence of such matrices to odd N≥7, filling a gap in prior knowledge.

Abstract: The existence of infinite families of $N \times N$ Jacobi matrices
representing the Hamiltonians of quantum spin chains with and without early
state exclusion (ESE) has been shown to exist for any even $N \geq 4$. However,
their existence for odd $N \geq 7$ has remained an open problem. In Section 3,
we consider a chain of qubits experiencing nearest-neighbor interactions with
environmental effects and present infinite families of $7 \times 7$ Jacobi
matrices with and without ESE.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [45] [Neural network ensemble for computing cross sections for rotational transitions in H$_{2}$O + H$_{2}$O collisions](https://arxiv.org/abs/2507.18974)
*Bikramaditya Mandal,Dmitri Babikov,Phillip C. Stancil,Robert C. Forrey,Roman V. Krems,Naduvalath Balakrishnan*

Main category: physics.chem-ph

TL;DR: A machine learning tool using neural networks predicts cross sections for rotational transitions in water molecule collisions, achieving high accuracy with minimal training data.


<details>
  <summary>Details</summary>
Motivation: Quantum mechanical methods are computationally intractable for modeling rotational transitions in water-rich environments, necessitating an efficient alternative.

Method: An ensemble of neural networks is trained on mixed quantum-classical theory (MQCT) data to predict cross sections for rotational transitions, using only 10% of computed data.

Result: The neural networks predict cross sections with an average relative root mean square error of 0.409 and thermally averaged cross sections with ~13.5% deviation from MQCT calculations.

Conclusion: The ML methodology is robust and scalable, applicable to other complex molecular systems.

Abstract: Water (H$_2$O) is one of the most abundant molecules in the universe and is
found in a wide variety of astrophysical environments. Rotational transitions
in H$_2$O + H$_2$O collisions are important in modeling environments rich in
water molecules but they are computationally intractable using quantum
mechanical methods. Here, we present a machine learning (ML) tool using an
ensemble of neural networks (NNs) to predict cross sections to construct a
database of rate coefficients for rotationally inelastic transitions in
collisions of complex molecules such as water. The proposed methodology
utilizes data computed with a mixed quantum-classical theory (MQCT). We
illustrate that efficient ML models using NN can be built to accurately
interpolate in the space of 12 quantum numbers for rotational transitions in
two asymmetric top molecules, spanning both initial and final states. We
examine various architectures of data corresponding to each collision energy,
symmetry of water molecule, and excitation/de-excitation rotational
transitions, and optimize the training/validation data sets. Using only about
10\% of the computed data for training, the NNs predict cross sections of
state-to-state rotational transitions of H$_{2}$O + H$_{2}$O collision with
average relative root mean square error of 0.409. Thermally averaged cross
sections, computed using the predicted state-to-state cross sections
($\sim$90\%) and the data used for training and validation ($\sim$10\%) were
compared against those obtained entirely from MQCT calculations. The agreement
is found to be excellent with an average percent deviation of about
$\sim$13.5\%. The methodology is robust, and thus, applicable to other complex
molecular systems.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [46] [Entanglement across scales: Quantics tensor trains as a natural framework for renormalization](https://arxiv.org/abs/2507.19069)
*Stefan Rohshap,Jheng-Wei Li,Alena Lorenz,Serap Hasil,Karsten Held,Anna Kauch,Markus Wallerberger*

Main category: cond-mat.str-el

TL;DR: The paper explores length/energy scale entanglement using the quantics tensor train (QTT) technique, linking it to renormalization group methods and demonstrating its utility in semi-analytical treatments.


<details>
  <summary>Details</summary>
Motivation: To address the understudied area of length/energy scale entanglement and leverage QTT for computational efficiency in renormalization group methods.

Method: Analytically expresses a cyclic reduction-based real-space renormalization scheme in QTT language, matching QTT bond dimension to rescaled couplings in coarse-graining steps.

Result: The QTT bond dimension matches the number of rescaled couplings in the renormalization procedure, as shown for the one-dimensional tight-binding model.

Conclusion: QTTs are powerful for both numerical and semi-analytical treatments, bridging entanglement measures and computational efficiency.

Abstract: Understanding entanglement remains one of the most intriguing problems in
physics. While particle and site entanglement have been studied extensively,
the investigation of length or energy scale entanglement, quantifying the
information exchange between different length scales, has received far less
attention. Here, we identify the quantics tensor train (QTT) technique, a
matrix product state-inspired approach for overcoming computational bottlenecks
in resource-intensive numerical calculations, as a renormalization group method
by analytically expressing an exact cyclic reduction-based real-space
renormalization scheme in QTT language, which serves as a natural formalism for
the method. In doing so, we precisely match the QTT bond dimension, a measure
of length scale entanglement, to the number of rescaled couplings generated in
each coarse-graining renormalization step. While QTTs have so far been applied
almost exclusively to numerical problems in physics, our analytical
calculations demonstrate that they are also powerful tools for mitigating
computational costs in semi-analytical treatments. We present our results for
the one-dimensional tight-binding model with n-th-nearest-neighbor hopping,
where the 2n rescaled couplings generated in the renormalization procedure
precisely match the QTT bond dimension of the one-particle Green's function.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [47] [Adaptive Neural Quantum States: A Recurrent Neural Network Perspective](https://arxiv.org/abs/2507.18700)
*Jake McNaughton,Mohamed Hibat-Allah*

Main category: cond-mat.dis-nn

TL;DR: An adaptive scheme optimizes neural-network quantum states (NQS) using recurrent neural networks (RNNs), reducing computational costs and improving variational calculations for ground states.


<details>
  <summary>Details</summary>
Motivation: To enhance the efficiency and quality of variational calculations in quantum many-body physics using NQS, while minimizing computational resources.

Method: An adaptive technique trains small RNNs and reuses them to initialize larger RNNs, reducing computational costs and training fluctuations.

Result: The method improves the quality of variational calculations and reduces computational expenses, demonstrated in one- and two-dimensional models.

Conclusion: This approach optimizes GPU resources for large-scale NQS simulations, making it a promising tool for quantum many-body physics.

Abstract: Neural-network quantum states (NQS) are powerful neural-network ans\"atzes
that have emerged as promising tools for studying quantum many-body physics
through the lens of the variational principle. These architectures are known to
be systematically improvable by increasing the number of parameters. Here we
demonstrate an Adaptive scheme to optimize NQSs, through the example of
recurrent neural networks (RNN), using a fraction of the computation cost while
reducing training fluctuations and improving the quality of variational
calculations targeting ground states of prototypical models in one- and
two-spatial dimensions. This Adaptive technique reduces the computational cost
through training small RNNs and reusing them to initialize larger RNNs. This
work opens up the possibility for optimizing graphical processing unit (GPU)
resources deployed in large-scale NQS simulations.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [48] [Central limit theorems for the eigenvalues of graph Laplacians on data clouds](https://arxiv.org/abs/2507.18803)
*Chenghui Li,Nicolás García Trillos,Housen Li,Leo Suchan*

Main category: stat.ML

TL;DR: The paper studies the asymptotic fluctuations of eigenvalues of a graph Laplacian operator derived from samples on a low-dimensional manifold, proving Gaussian behavior and linking the variance to a gradient flow and Cramer-Rao lower bound.


<details>
  <summary>Details</summary>
Motivation: To understand the statistical behavior of eigenvalues of graph Laplacians in manifold learning, providing insights into their efficiency and interpretability.

Method: Analyzes the graph Laplacian operator for ε-proximity graphs, derives asymptotic Gaussian fluctuations of eigenvalues, and interprets variance via Fisher-Rao geometry and Cramer-Rao bounds.

Result: Proves that normalized eigenvalue fluctuations are asymptotically Gaussian with explicit variance, linked to gradient flow and statistical efficiency.

Conclusion: The eigenvalues of graph Laplacians exhibit efficient statistical behavior, validated theoretically and numerically, with broader implications for manifold learning.

Abstract: Given i.i.d.\ samples $X_n =\{ x_1, \dots, x_n \}$ from a distribution
supported on a low dimensional manifold ${M}$ embedded in Eucliden space, we
consider the graph Laplacian operator $\Delta_n$ associated to an
$\varepsilon$-proximity graph over $X_n$ and study the asymptotic fluctuations
of its eigenvalues around their means. In particular, letting
$\hat{\lambda}_l^\varepsilon$ denote the $l$-th eigenvalue of $\Delta_n$, and
under suitable assumptions on the data generating model and on the rate of
decay of $\varepsilon$, we prove that $\sqrt{n } (\hat{\lambda}_{l}^\varepsilon
- \mathbb{E}[\hat{\lambda}_{l}^\varepsilon] )$ is asymptotically Gaussian with
a variance that we can explicitly characterize. A formal argument allows us to
interpret this asymptotic variance as the dissipation of a gradient flow of a
suitable energy with respect to the Fisher-Rao geometry. This geometric
interpretation allows us to give, in turn, a statistical interpretation of the
asymptotic variance in terms of a Cramer-Rao lower bound for the estimation of
the eigenvalues of certain weighted Laplace-Beltrami operator. The latter
interpretation suggests a form of asymptotic statistical efficiency for the
eigenvalues of the graph Laplacian. We also present CLTs for multiple
eigenvalues and through several numerical experiments explore the validity of
our results when some of the assumptions that we make in our theoretical
analysis are relaxed.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [49] [On the regularity of solutions to the Hamilton-Jacobi equations for the N-body problem](https://arxiv.org/abs/2507.19170)
*Diego Berti,Davide Polimeni,Susanna Terracini*

Main category: math.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We prove that certain suitably renormalized value functions associated with
the $d$-dimensional ($d\geq2$) $N$-body problem corresponding to different
limiting shapes of expanding solutions, under the assumption that the center of
mass is at the origin, are viscosity solutions of the associated
Hamilton-Jacobi equation. We analyze their singularities, defined as the
initial configurations for which the minimizer of the associated variational
problem is not unique. Moreover, we estimate the size of the closure of the
singular set by proving its $\mathcal{H}^{d(N-1)-1}$-rectifiability, and we
provide an upper bound on the Hausdorff dimension of the set of regular
conjugate points.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [50] [Query Efficient Structured Matrix Learning](https://arxiv.org/abs/2507.19290)
*Noah Amsel,Pratyush Avi,Tyler Chen,Feyza Duman Keles,Chinmay Hegde,Cameron Musco,Christopher Musco,David Persson*

Main category: cs.DS

TL;DR: The paper studies learning structured matrix approximations using matrix-vector queries, achieving near-quadratic improvement in query complexity over prior bounds.


<details>
  <summary>Details</summary>
Motivation: Understanding the query complexity of learning matrix approximations from general families is crucial for applications in scientific computing and machine learning.

Method: The authors analyze the problem in a general setting, focusing on finite and infinite matrix families, and derive tight bounds for matvec queries.

Result: They show a nearly quadratic improvement in query complexity, reducing it to ~O(√log|F|) for finite families and ~O(√q) for linear families of dimension q.

Conclusion: The results provide significant improvements over prior bounds, demonstrating the efficiency of matvec queries for learning structured matrix approximations.

Abstract: We study the problem of learning a structured approximation (low-rank,
sparse, banded, etc.) to an unknown matrix $A$ given access to matrix-vector
product (matvec) queries of the form $x \rightarrow Ax$ and $x \rightarrow
A^Tx$. This problem is of central importance to algorithms across scientific
computing and machine learning, with applications to fast multiplication and
inversion for structured matrices, building preconditioners for first-order
optimization, and as a model for differential operator learning. Prior work
focuses on obtaining query complexity upper and lower bounds for learning
specific structured matrix families that commonly arise in applications.
  We initiate the study of the problem in greater generality, aiming to
understand the query complexity of learning approximations from general matrix
families. Our main result focuses on finding a near-optimal approximation to
$A$ from any finite-sized family of matrices, $\mathcal{F}$. Standard results
from matrix sketching show that $O(\log|\mathcal{F}|)$ matvec queries suffice
in this setting. This bound can also be achieved, and is optimal, for
vector-matrix-vector queries of the form $x,y\rightarrow x^TAy$, which have
been widely studied in work on rank-$1$ matrix sensing.
  Surprisingly, we show that, in the matvec model, it is possible to obtain a
nearly quadratic improvement in complexity, to
$\tilde{O}(\sqrt{\log|\mathcal{F}|})$. Further, we prove that this bound is
tight up to log-log factors.Via covering number arguments, our result extends
to well-studied infinite families. As an example, we establish that a
near-optimal approximation from any \emph{linear matrix family} of dimension
$q$ can be learned with $\tilde{O}(\sqrt{q})$ matvec queries, improving on an
$O(q)$ bound achievable via sketching techniques and vector-matrix-vector
queries.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [51] [Scale-Consistent Learning for Partial Differential Equations](https://arxiv.org/abs/2507.18813)
*Zongyi Li,Samuel Lanthaler,Catherine Deng,Michael Chen,Yixuan Wang,Kamyar Azizzadenesheli,Anima Anandkumar*

Main category: cs.LG

TL;DR: The paper proposes a scale-informed neural operator with a scale-consistency loss to generalize ML models for solving PDEs across varying scales and Reynolds numbers, reducing errors by 34%.


<details>
  <summary>Details</summary>
Motivation: Overcome the limitation of ML models for PDEs that cannot generalize outside training data, such as fixed Reynolds numbers or domains.

Method: Introduces a data augmentation scheme using scale-consistency properties of PDEs and a scale-informed neural operator with a scale-consistency loss.

Result: The model generalizes to Reynolds numbers from 250 to 10000 (trained on 1000) and reduces error by 34% on tested PDEs.

Conclusion: Scale-consistency loss and scale-informed neural operators effectively generalize ML models for PDEs across scales, improving accuracy.

Abstract: Machine learning (ML) models have emerged as a promising approach for solving
partial differential equations (PDEs) in science and engineering. Previous ML
models typically cannot generalize outside the training data; for example, a
trained ML model for the Navier-Stokes equations only works for a fixed
Reynolds number ($Re$) on a pre-defined domain. To overcome these limitations,
we propose a data augmentation scheme based on scale-consistency properties of
PDEs and design a scale-informed neural operator that can model a wide range of
scales. Our formulation leverages the facts: (i) PDEs can be rescaled, or more
concretely, a given domain can be re-scaled to unit size, and the parameters
and the boundary conditions of the PDE can be appropriately adjusted to
represent the original solution, and (ii) the solution operators on a given
domain are consistent on the sub-domains. We leverage these facts to create a
scale-consistency loss that encourages matching the solutions evaluated on a
given domain and the solution obtained on its sub-domain from the rescaled PDE.
Since neural operators can fit to multiple scales and resolutions, they are the
natural choice for incorporating scale-consistency loss during training of
neural PDE solvers. We experiment with scale-consistency loss and the
scale-informed neural operator model on the Burgers' equation, Darcy Flow,
Helmholtz equation, and Navier-Stokes equations. With scale-consistency, the
model trained on $Re$ of 1000 can generalize to $Re$ ranging from 250 to 10000,
and reduces the error by 34% on average of all datasets compared to baselines.

</details>


### [52] [A diffusion-based generative model for financial time series via geometric Brownian motion](https://arxiv.org/abs/2507.19003)
*Gihun Kim,Sun-Yong Choi,Yeoneung Kim*

Main category: cs.LG

TL;DR: A diffusion-based generative framework for financial time series integrates geometric Brownian motion (GBM) into the forward noising process, reflecting heteroskedasticity and balancing drift-diffusion terms. A Transformer-based architecture trains the reverse-time process, outperforming conventional models in reproducing stylized facts like heavy-tailed returns and volatility clustering.


<details>
  <summary>Details</summary>
Motivation: Standard score-based models treat financial time series as generic sequences, ignoring heteroskedasticity. This work aims to incorporate GBM and realistic noise injection to better model financial data.

Method: The framework injects noise proportionally to asset prices, balancing drift and diffusion terms. It uses a Transformer-based architecture for denoising score matching, adapted from the CSDI framework.

Result: The model accurately reproduces stylized facts (heavy-tailed returns, volatility clustering, leverage effect) more realistically than conventional diffusion models.

Conclusion: The proposed framework effectively integrates GBM into diffusion models, improving the realism of generated financial time series.

Abstract: We propose a novel diffusion-based generative framework for financial time
series that incorporates geometric Brownian motion (GBM), the foundation of the
Black--Scholes theory, into the forward noising process. Unlike standard
score-based models that treat price trajectories as generic numerical
sequences, our method injects noise proportionally to asset prices at each time
step, reflecting the heteroskedasticity observed in financial time series. By
accurately balancing the drift and diffusion terms, we show that the resulting
log-price process reduces to a variance-exploding stochastic differential
equation, aligning with the formulation in score-based generative models. The
reverse-time generative process is trained via denoising score matching using a
Transformer-based architecture adapted from the Conditional Score-based
Diffusion Imputation (CSDI) framework. Empirical evaluations on historical
stock data demonstrate that our model reproduces key stylized facts
heavy-tailed return distributions, volatility clustering, and the leverage
effect more realistically than conventional diffusion models.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [53] [Cosmic-ray transport in inhomogeneous media](https://arxiv.org/abs/2507.19044)
*Robert J. Ewart,Patrick Reichherzer,Shuzhe Ren,Stephen Majeski,Francesco Mori,Michael L. Nastac,Archie F. A. Bott,Matthew W. Kunz,Alexander A. Schekochihin*

Main category: astro-ph.HE

TL;DR: The paper develops a theory for cosmic-ray transport in multi-phase diffusive media, showing long-time diffusive behavior dominated by low-diffusion regions, with transient sub-diffusion on intermediate time scales.


<details>
  <summary>Details</summary>
Motivation: To understand cosmic-ray transport in media with spatially fluctuating diffusion coefficients, addressing the impact of multi-scale variations.

Method: Developed a theoretical framework for cosmic-ray transport, analyzing the effects of spatial fluctuations in diffusion coefficients, including a simplified two-phase medium case.

Result: Long-time transport is diffusive with an average diffusion coefficient equal to the harmonic mean of local coefficients, while intermediate times show sub-diffusion. The energy dependence of transport is altered only with moderate perpendicular diffusion.

Conclusion: Multi-phase media significantly influence cosmic-ray confinement times, but energy dependence is only affected under specific conditions of perpendicular diffusion.

Abstract: A theory of cosmic-ray transport in multi-phase diffusive media is developed,
with the specific application to cases in which the cosmic-ray diffusion
coefficient has large spatial fluctuations that may be inherently multi-scale.
We demonstrate that the resulting transport of cosmic rays is diffusive in the
long-time limit, with an average diffusion coefficient equal to the harmonic
mean of the spatially varying diffusion coefficient. Thus, cosmic-ray transport
is dominated by areas of low diffusion even if these areas occupy a relatively
small, but not infinitesimal, fraction of the volume. On intermediate time
scales, the cosmic rays experience transient effective sub-diffusion, as a
result of low-diffusion regions interrupting long flights through
high-diffusion regions. In the simplified case of a two-phase medium, we show
that the extent and extremity of the sub-diffusivity of cosmic-ray transport is
controlled by the spectral exponent of the distribution of patch sizes of each
of the phases. We finally show that, despite strongly influencing the
confinement times, the multi-phase medium is only capable of altering the
energy dependence of cosmic-ray transport when there is a moderate (but not
excessive) level of perpendicular diffusion across magnetic-field lines.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [54] [Interpretable inverse design of optical multilayer thin films based on extended neural adjoint and regression activation mapping](https://arxiv.org/abs/2507.18644)
*Sungjun Kim,Jungho Kim*

Main category: physics.optics

TL;DR: The paper introduces an extended neural adjoint (ENA) framework for inverse design of optical multilayer thin films, improving accuracy, efficiency, diversity, scalability, flexibility, and interpretability.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of existing methods in inverse design of optical multilayer thin films, the authors aim to enhance scalability, interpretability, and flexibility while maintaining accuracy and diversity.

Method: The ENA framework includes a novel forward neural network architecture, a material loss function, and regression activation mapping (F-RAM) for interpretability. Ablation studies and comparisons with Res-GLOnet validate the approach.

Result: ENA outperforms Res-GLOnet in accuracy and diversity. The material loss improves results, and F-RAM confirms consistent feature importance across diverse OMT structures.

Conclusion: The ENA framework is effective for inverse design of OMTs, offering improved performance, interpretability, and flexibility.

Abstract: We propose an extended neural adjoint (ENA) framework, which meets six key
criteria for artificial intelligence-assisted inverse design of optical
multilayer thin films (OMTs): accuracy, efficiency, diversity, scalability,
flexibility, and interpretability. To enhance the scalability of the existing
neural adjoint method, we present a novel forward neural network architecture
for OMTs and introduce a material loss function into the existing neural
adjoint loss function, facilitating the exploration of material configurations
of OMTs. Furthermore, we present the detailed formulation of the regression
activation mapping for the presented forward neural network architecture
(F-RAM), a feature visualization method aimed at improving interpretability. We
validated the efficacy of the material loss by conducting an ablation study,
where each component of the loss function is systematically removed and
evaluated. The results indicated that the inclusion of the material loss
significantly improves accuracy and diversity. To substantiate the performance
of the ENA-based inverse design, we compared it against the residual
network-based global optimization network (Res-GLOnet). The ENA yielded the OMT
solutions of an inverse design with higher accuracy and better diversity
compared to the Res-GLOnet. To demonstrate the interpretability, we applied
F-RAM to diverse OMT structures with similar optical properties, obtained by
the proposed ENA method. We showed that distributions of feature importance for
various OMT structures exhibiting analogous optical properties are consistent,
despite variations in material configurations, layer number, and thicknesses.
Furthermore, we demonstrate the flexibility of the ENA method by restricting
the initial layer of OMTs to SiO2 and 100 nm.

</details>
