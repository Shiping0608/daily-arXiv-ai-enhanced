{"id": "2507.21269", "pdf": "https://arxiv.org/pdf/2507.21269", "abs": "https://arxiv.org/abs/2507.21269", "authors": ["Patrick Chatain", "Michael Rizvi-Martel", "Guillaume Rabusseau", "Adam Oberman"], "title": "Numerical PDE solvers outperform neural PDE solvers", "categories": ["math.NA", "cs.LG", "cs.NA", "35R30 (Primary) 65M06 65M32 65C20 68T07 (Secondary)"], "comment": "17 pages, 7 figures", "summary": "We present DeepFDM, a differentiable finite-difference framework for learning\nspatially varying coefficients in time-dependent partial differential equations\n(PDEs). By embedding a classical forward-Euler discretization into a\nconvolutional architecture, DeepFDM enforces stability and first-order\nconvergence via CFL-compliant coefficient parameterizations. Model weights\ncorrespond directly to PDE coefficients, yielding an interpretable\ninverse-problem formulation. We evaluate DeepFDM on a benchmark suite of scalar\nPDEs: advection, diffusion, advection-diffusion, reaction-diffusion and\ninhomogeneous Burgers' equations-in one, two and three spatial dimensions. In\nboth in-distribution and out-of-distribution tests (quantified by the Hellinger\ndistance between coefficient priors), DeepFDM attains normalized mean-squared\nerrors one to two orders of magnitude smaller than Fourier Neural Operators,\nU-Nets and ResNets; requires 10-20X fewer training epochs; and uses 5-50X fewer\nparameters. Moreover, recovered coefficient fields accurately match\nground-truth parameters. These results establish DeepFDM as a robust,\nefficient, and transparent baseline for data-driven solution and identification\nof parametric PDEs.", "AI": {"tldr": "DeepFDM is a differentiable finite-difference framework for learning spatially varying coefficients in PDEs, outperforming other methods in accuracy, efficiency, and interpretability.", "motivation": "To address the challenge of learning spatially varying coefficients in time-dependent PDEs with a robust, interpretable, and efficient method.", "method": "Embeds a forward-Euler discretization into a convolutional architecture, enforcing stability and convergence via CFL-compliant coefficient parameterizations.", "result": "Achieves lower errors, faster training, and fewer parameters than Fourier Neural Operators, U-Nets, and ResNets, with accurate coefficient recovery.", "conclusion": "DeepFDM is a strong baseline for data-driven PDE solution and identification, offering transparency and efficiency."}}
{"id": "2507.21351", "pdf": "https://arxiv.org/pdf/2507.21351", "abs": "https://arxiv.org/abs/2507.21351", "authors": ["Walter Boscheri", "Firas Dhaouadi"], "title": "Structure Preserving Finite Volume Schemes on Voronoi Grids: Curl Involution, Asymptotic Limit and Thermodynamics", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "35L40, 65M08"], "comment": null, "summary": "We propose a new curl-free and thermodynamically compatible finite volume\nscheme on Voronoi grids to solve compressible heat conducting flows written in\nfirst-order hyperbolic form. The approach is based on the definition of\ncompatible discrete curl-grad operators, exploiting the triangular nature of\nthe dual mesh. We design a cell solver reminiscent of the nodal solvers used in\nLagrangian schemes to discretize the evolution equation for the thermal impulse\nvector, and we demonstrate that the resulting numerical scheme ensures energy\nconservation, local non-negative entropy production, as well as asymptotic\nconsistency with the classical Fourier law in the stiff relaxation limit. A\nnovel technique is proposed to transfer residuals from the dual to the primal\nmesh as subfluxes, which eventually yields the construction of entropy\ncompatible semi-discrete methods. The scheme and its properties are validated\non a set of numerical test cases.", "AI": {"tldr": "A new curl-free, thermodynamically compatible finite volume scheme for compressible heat conducting flows on Voronoi grids is proposed, ensuring energy conservation and entropy production.", "motivation": "To address the need for accurate and compatible numerical methods for compressible heat conducting flows, particularly in hyperbolic form.", "method": "Uses compatible discrete curl-grad operators on Voronoi grids, a cell solver for thermal impulse, and transfers residuals as subfluxes for entropy-compatible semi-discrete methods.", "result": "The scheme conserves energy, ensures non-negative entropy production, and is asymptotically consistent with the Fourier law.", "conclusion": "The proposed scheme is validated numerically, demonstrating its effectiveness for compressible heat conducting flows."}}
{"id": "2507.21392", "pdf": "https://arxiv.org/pdf/2507.21392", "abs": "https://arxiv.org/abs/2507.21392", "authors": ["Nan Zheng", "Xu Guo", "Wenlong Pei", "Wenju Zhao"], "title": "Divergence-free Preserving Mix Finite Element Methods for Fourth-order Active Fluid Model", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper is concerned with mixed finite element method (FEM) for solving\nthe two-dimensional, nonlinear fourth-order active fluid equations. By\nintroducing an auxiliary variable $w=-\\Delta u$, the original fourth problem is\ntransformed into a system of second-order equations, which relaxes the\nregularity requirements of standard $H^2$-conforming finite spaces. To further\nenhance the robustness and efficiency of the algorithm, an additional auxiliary\nvariable $\\phi$, treated analogously to the pressure, is introduced, leading to\na divergence-free preserving mixed finite element scheme. A fully discrete\nscheme is then constructed by coupling the spatial mixed FEM with the\nvariable-step Dahlquist-Liniger-Nevanlinna (DLN) time integrator. The\nboundedness of the scheme and corresponding error estimates can be rigorously\nproven under appropriate assumptions due to unconditional non-linear stability\nand second-order accuracy of the DLN method. To enhance computational\nefficiency in practice, we develop an adaptive time-stepping strategy based on\na minimum-dissipation criterion. Several numerical experiments are displayed to\nfully validate the theoretical results and demonstrate the accuracy and\nefficiency of the scheme for complex active fluid simulations.", "AI": {"tldr": "The paper presents a mixed FEM for solving nonlinear fourth-order active fluid equations by introducing auxiliary variables and coupling with the DLN time integrator, ensuring robustness and efficiency.", "motivation": "To address the challenges of solving nonlinear fourth-order active fluid equations by relaxing regularity requirements and improving computational efficiency.", "method": "Introduces auxiliary variables to transform the problem into second-order equations, uses a divergence-free preserving mixed FEM, and couples it with the DLN time integrator for a fully discrete scheme.", "result": "The scheme is proven to be bounded and accurate, with numerical experiments validating its efficiency for complex simulations.", "conclusion": "The proposed method effectively solves the active fluid equations with enhanced robustness and computational efficiency."}}
{"id": "2507.21519", "pdf": "https://arxiv.org/pdf/2507.21519", "abs": "https://arxiv.org/abs/2507.21519", "authors": ["Xun Tang", "Rajat Dwaraknath", "Lexing Ying"], "title": "Variational inference and density estimation with non-negative tensor train", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This work proposes an efficient numerical approach for compressing a\nhigh-dimensional discrete distribution function into a non-negative tensor\ntrain (NTT) format. The two settings we consider are variational inference and\ndensity estimation, whereby one has access to either the unnormalized analytic\nformula of the distribution or the samples generated from the distribution. In\nparticular, the compression is done through a two-stage approach. In the first\nstage, we use existing subroutines to encode the distribution function in a\ntensor train format. In the second stage, we use an NTT ansatz to fit the\nobtained tensor train. For the NTT fitting procedure, we use a log barrier term\nto ensure the positivity of each tensor component, and then utilize a\nsecond-order alternating minimization scheme to accelerate convergence. In\npractice, we observe that the proposed NTT fitting procedure exhibits\ndrastically faster convergence than an alternative multiplicative update method\nthat has been previously proposed. Through challenging numerical experiments,\nwe show that our approach can accurately compress target distribution\nfunctions.", "AI": {"tldr": "Proposes a two-stage method to compress high-dimensional discrete distributions into non-negative tensor train (NTT) format, showing faster convergence than existing methods.", "motivation": "Efficiently compress high-dimensional discrete distributions for variational inference and density estimation tasks.", "method": "Two-stage approach: encode distribution into tensor train format, then fit using NTT with log barrier and second-order alternating minimization.", "result": "Faster convergence than multiplicative update methods; accurate compression in numerical experiments.", "conclusion": "The NTT fitting procedure is efficient and effective for compressing high-dimensional distributions."}}
{"id": "2507.21279", "pdf": "https://arxiv.org/pdf/2507.21279", "abs": "https://arxiv.org/abs/2507.21279", "authors": ["\u0160t\u011bp\u00e1n Marek", "Jan Wilhelm"], "title": "Linear and Nonlinear Optical Properties of Molecules from Real-Time Propagation Based on the Bethe-Salpeter Equation", "categories": ["physics.comp-ph", "physics.chem-ph"], "comment": null, "summary": "We present a real-time propagation method for computing linear and nonlinear\noptical properties of molecules based on the Bethe-Salpeter equation. The\nmethod follows the time evolution of the one-particle density matrix under an\nexternal electric field. We include electron-electron interaction effects\nthrough a self-energy based on the screened exchange approximation.\nQuasiparticle energies are taken from a prior $GW$ calculation to construct the\neffective single-particle Hamiltonian and we represent all operators and\nwavefunctions in an atom-centered Gaussian basis. We benchmark the accuracy of\nthe real-time propagation against the standard linear-response Bethe-Salpeter\nequation using a set of organic molecules. We find very good agreement when\ncomputing linear-response isotropic polarizability spectra from both\napproaches, with a mean absolute deviation of 30~meV in peak positions. Beyond\nlinear response, we simulate second harmonic generation and optical\nrectification in a non-centrosymmetric molecule. These phenomena are not\ncaptured by the commonly used linear-response Bethe-Salpeter equation. We\nforesee broad applicability of real-time propagation based on the\nBethe-Salpeter equation for the study of linear and nonlinear optical\nproperties of molecules as the method has a similar computational cost as\ntime-dependent density functional theory with hybrid functionals.", "AI": {"tldr": "A real-time propagation method for computing linear and nonlinear optical properties of molecules using the Bethe-Salpeter equation, benchmarked against standard linear-response methods with good agreement.", "motivation": "To develop a computationally efficient method for studying both linear and nonlinear optical properties of molecules, addressing limitations of the standard linear-response Bethe-Salpeter equation.", "method": "Time evolution of the one-particle density matrix under an external electric field, incorporating electron-electron interactions via a screened exchange approximation and quasiparticle energies from GW calculations.", "result": "Very good agreement with linear-response methods (30 meV deviation in peak positions) and successful simulation of nonlinear phenomena like second harmonic generation.", "conclusion": "The method is accurate and computationally feasible, offering broad applicability for studying optical properties of molecules."}}
{"id": "2507.21185", "pdf": "https://arxiv.org/pdf/2507.21185", "abs": "https://arxiv.org/abs/2507.21185", "authors": ["Abdelhamid Gouasmia", "Kaushik Bal"], "title": "Comparison principle for Singular Fractional $ g- $Laplacian Problems", "categories": ["math.AP", "35J75, 35R11, 35J62"], "comment": "26 pages", "summary": "In this paper, we establish a novel comparison principle of independent\ninterest and prove the uniqueness of weak solutions within the local\nOrlicz--Sobolev space framework, for the following class of fractional elliptic\nproblems:\n  \\begin{equation*}\n  (-\\Delta)^{s}_{g} u = f(x) u^{-\\alpha} + k(x) u^{\\beta}, \\quad u > 0 \\quad\n\\text{in } \\Omega; \\quad u = 0 \\quad \\text{in } \\mathbb{R}^{N} \\setminus\n\\Omega,\n  \\end{equation*}\n  where \\( \\Omega \\subset \\mathbb{R}^{N} \\) is a smooth bounded domain, \\(\n\\alpha > 0 \\), and \\( \\beta > 0 \\) satisfies a suitable upper bound. Here, \\(\n(-\\Delta)^{s}_{g} \\) denotes the fractional \\( g \\)-Laplacian, with \\( g \\)\nbeing the derivative of a Young function \\( G \\). The function \\( f \\) is\nassumed to be nontrivial, while \\( k \\) is a positive function, and both \\( f\n\\) and \\( k \\) are assumed to lie in suitable Orlicz spaces. Our analysis\nrelies on a refined variational approach that incorporates a \\( G \\)-fractional\nversion of the D\\'iaz--Saa inequality together with a \\( G \\)-fractional\nanalogue of Picone's identity. These tools, which are of independent interest,\nalso play a key role in the study of simplicity of eigenvalues, Sturmian-type\ncomparison results, Hardy-type inequalities, and related topics.", "AI": {"tldr": "The paper establishes a novel comparison principle and proves uniqueness of weak solutions for a class of fractional elliptic problems in local Orlicz-Sobolev spaces.", "motivation": "To address the uniqueness of weak solutions for fractional elliptic problems with nonlinear terms, leveraging the fractional g-Laplacian framework.", "method": "A refined variational approach incorporating a G-fractional version of the D\u00edaz--Saa inequality and a G-fractional analogue of Picone's identity.", "result": "Uniqueness of weak solutions is proven for the given fractional elliptic problem under suitable conditions.", "conclusion": "The tools developed are also applicable to other problems like eigenvalue simplicity and Hardy-type inequalities, demonstrating broader utility."}}
{"id": "2507.21525", "pdf": "https://arxiv.org/pdf/2507.21525", "abs": "https://arxiv.org/abs/2507.21525", "authors": ["Ilnaz I. Fairushin", "Anatolii V. Mokshin"], "title": "Weak decaying collective-excitation approximation for Yukawa one-component plasmas", "categories": ["physics.plasm-ph", "cond-mat.dis-nn", "cond-mat.soft", "cond-mat.stat-mech", "physics.comp-ph"], "comment": "9 pages, 4 figures, 1 table", "summary": "In this paper, the theoretical model of weak decaying collective excitations\ncharacteristic of many-particle systems with long-range interaction potentials\nis developed using the example of one-component strongly coupled Yukawa\nplasmas. The proposed model is based on the self-consistent relaxation theory\nof collective dynamics and covers spatial scales from extended hydrodynamics to\nscales related to the mean interparticle distance. The theoretical model\nreproduces the dynamic structure factor spectra and the corresponding\ndispersion characteristics in agreement with molecular dynamics simulation data\nwithout using any fitting parameters. In the limit of small wave numbers, the\ncorrespondence of the proposed theoretical model with the damped harmonic\noscillator model is established. The simple analytical expression for the sound\nattenuation coefficient of strongly coupled Yukawa plasmas is obtained.", "AI": {"tldr": "The paper develops a theoretical model for weak decaying collective excitations in strongly coupled Yukawa plasmas, aligning with molecular dynamics simulations without fitting parameters.", "motivation": "To model collective excitations in systems with long-range interactions, specifically Yukawa plasmas, bridging hydrodynamics and interparticle scales.", "method": "Uses self-consistent relaxation theory to derive dynamic structure factors and dispersion characteristics, comparing with molecular dynamics simulations.", "result": "The model matches simulation data and connects to the damped harmonic oscillator model at small wave numbers, providing a sound attenuation coefficient.", "conclusion": "The theoretical framework successfully describes collective excitations in Yukawa plasmas, validated by simulations."}}
{"id": "2507.21552", "pdf": "https://arxiv.org/pdf/2507.21552", "abs": "https://arxiv.org/abs/2507.21552", "authors": ["Robert Altmann", "Attila Karsai", "Philipp Schulze"], "title": "Structure-Preserving Discretization and Model Reduction for Energy-Based Models", "categories": ["math.NA", "cs.NA", "37J06, 65P10, 65M60"], "comment": "20 pages, 5 figures", "summary": "We investigate discretization strategies for a recently introduced class of\nenergy-based models. The model class encompasses classical port-Hamiltonian\nsystems, generalized gradient flows, and certain systems with algebraic\nconstraints. Our framework combines existing ideas from the literature and\nsystematically addresses temporal discretization, spatial discretization, and\nmodel order reduction, ensuring that all resulting schemes are\ndissipation-preserving in the sense of a discrete dissipation inequality. For\nthis, we use a Petrov-Galerkin ansatz together with appropriate projections.\nNumerical results for a nonlinear circuit model and the Cahn-Hilliard equation\nillustrate the effectiveness of the approach.", "AI": {"tldr": "The paper explores discretization strategies for energy-based models, ensuring dissipation-preserving schemes through a Petrov-Galerkin approach, validated with numerical examples.", "motivation": "To address temporal, spatial, and model order reduction discretization for energy-based models while preserving dissipation properties.", "method": "Uses a Petrov-Galerkin ansatz with appropriate projections for discretization.", "result": "Demonstrates effectiveness via numerical results for a nonlinear circuit model and the Cahn-Hilliard equation.", "conclusion": "The framework successfully combines existing ideas to ensure dissipation-preserving discretization across various systems."}}
{"id": "2507.21800", "pdf": "https://arxiv.org/pdf/2507.21800", "abs": "https://arxiv.org/abs/2507.21800", "authors": ["Andr\u00e9s Mart\u00ednez-Esteban", "Pablo Calvo-Barl\u00e9s", "Luis Mart\u00edn-Moreno", "Sergio G Rodrigo"], "title": "Physics-Informed Neural Networks with Dynamical Boundary Constraints", "categories": ["physics.comp-ph"], "comment": null, "summary": "Physics-informed neural networks (PINNs) are numerical solvers that embed all\nthe physical information of a system into the loss function of a neural\nnetwork. In this way the learned solution accounts for data (if available), the\ngoverning differential equations, or any other constraint known of the physical\nproblem. However, they face serious issues, notably their tendency to converge\non trivial or misleading solutions. The latter occurs when, although the loss\nfunction reaches low values the model makes incorrect predictions. These\ndifficulties become especially significant in differential equations involving\nmulti-scale behavior, such as rapidly varying terms and solutions exhibiting\nstrong oscillatory behavior. To address these challenges, we introduce the\nDynamical Boundary Constraint (DBC) algorithm, which imposes restrictions on\nthe loss function based on prior training of the PINN. To demonstrate its\napplicability, we tested this approach on examples of different areas of\nphysics.", "AI": {"tldr": "PINNs embed physical information into neural network loss functions but struggle with convergence on misleading solutions, especially in multi-scale problems. The DBC algorithm addresses this by imposing loss function restrictions based on prior PINN training.", "motivation": "PINNs often converge on trivial or incorrect solutions despite low loss values, particularly in multi-scale differential equations.", "method": "The Dynamical Boundary Constraint (DBC) algorithm restricts the loss function using prior PINN training.", "result": "The DBC algorithm was tested on various physics examples, showing improved handling of multi-scale behavior.", "conclusion": "DBC effectively mitigates PINN convergence issues in multi-scale problems, enhancing solution accuracy."}}
{"id": "2507.21201", "pdf": "https://arxiv.org/pdf/2507.21201", "abs": "https://arxiv.org/abs/2507.21201", "authors": ["J. Dongho", "Joel Fotso Tachago", "H. Nnang", "T. F. A. Tchinda"], "title": "Reiterated $\u03a3$-Convergence In Orlicz Setting and Applications", "categories": ["math.AP", "35B40, 35J60, 35J70, 46J10, 46J25, 46E30"], "comment": null, "summary": "The concept of reiterated $\\Sigma$-convergence (and more generally of\nmultiscale $\\Sigma$-convergence) is extended to framework of Orlicz-Sobolev\nspaces, in order to deals with homogenization of multiscales problems in\ngeneral deterministic setting and whose solutions leads in this type of spaces.\nThis concept relies on the notion of reiterated homogenization supralgebra that\nwe will assumed being ergodic. An application to the deterministic reiterated\nhomogenization of nonlinear degenerate elliptic operators with nonstandard\ngrowth is given and some concrete homogenization problems following varied\nstructure hypothesis are deduce from this latter.", "AI": {"tldr": "Extension of reiterated \u03a3-convergence to Orlicz-Sobolev spaces for homogenizing multiscale problems in deterministic settings.", "motivation": "To address homogenization of multiscale problems with solutions in Orlicz-Sobolev spaces, leveraging ergodic reiterated homogenization supralgebra.", "method": "Extends reiterated \u03a3-convergence to Orlicz-Sobolev spaces, applies to nonlinear degenerate elliptic operators with nonstandard growth.", "result": "Demonstrates applicability to deterministic reiterated homogenization and derives concrete problems under varied structural hypotheses.", "conclusion": "The framework successfully generalizes multiscale homogenization to Orlicz-Sobolev spaces, with practical applications in nonlinear problems."}}
{"id": "2507.21564", "pdf": "https://arxiv.org/pdf/2507.21564", "abs": "https://arxiv.org/abs/2507.21564", "authors": ["Jing Guo", "Yongyong Cai", "Dong Wang"], "title": "Efficient and stable diffusion generated methods for ground state computation in Bose--Einstein condensates", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper investigates numerical methods for approximating the ground state\nof Bose--Einstein condensates (BECs) by introducing two relaxed formulations of\nthe Gross--Pitaevskii energy functional. These formulations achieve first- and\nsecond-order accuracy with respect to the relaxation parameter \\( \\tau \\), and\nare shown to converge to the original energy functional as \\( \\tau \\to 0 \\). A\nkey feature of the relaxed functionals is their concavity, which ensures that\nlocal minima lie on the boundary of the concave hull. This property prevents\nenergy increases during constraint normalization and enables the development of\nenergy-dissipative algorithms. Numerical methods based on sequential linear\nprogramming are proposed, accompanied by rigorous analysis of their stability\nwith respect to the relaxed energy. To enhance computational efficiency, an\nadaptive strategy is introduced, dynamically refining solutions obtained with\nlarger relaxation parameters to achieve higher accuracy with smaller ones.\nNumerical experiments demonstrate the stability, convergence, and energy\ndissipation of the proposed methods, while showcasing the adaptive strategy's\neffectiveness in improving computational performance.", "AI": {"tldr": "The paper introduces relaxed formulations of the Gross-Pitaevskii energy functional for BECs, achieving first- and second-order accuracy. The methods ensure concavity, enabling energy-dissipative algorithms and adaptive strategies for efficiency.", "motivation": "To develop stable and efficient numerical methods for approximating the ground state of Bose-Einstein condensates (BECs) by relaxing the Gross-Pitaevskii energy functional.", "method": "Two relaxed formulations of the energy functional are introduced, with sequential linear programming-based numerical methods and adaptive refinement strategies.", "result": "The methods demonstrate stability, convergence, and energy dissipation, with the adaptive strategy improving computational performance.", "conclusion": "The proposed relaxed formulations and adaptive algorithms provide effective and efficient numerical solutions for BEC ground state approximation."}}
{"id": "2507.21856", "pdf": "https://arxiv.org/pdf/2507.21856", "abs": "https://arxiv.org/abs/2507.21856", "authors": ["Anatoli Fedynitch", "Hans Dembinski", "Anton Prosekin"], "title": "Chromo: A High-Performance Python Interface to Hadronic Event Generators for Collider and Cosmic-Ray Simulations", "categories": ["physics.comp-ph", "astro-ph.HE", "hep-ph"], "comment": "10 pages, 5 figures, 1 table. Code archived on Zenodo:\n  https://doi.org/10.5281/zenodo.16562752. Submitted to Computer Physics\n  Communications", "summary": "Simulations of hadronic and nuclear interactions are essential in both\ncollider and astroparticle physics. The Chromo package provides a unified\nPython interface to multiple widely used hadronic event generators, including\nEPOS, DPMJet, Sibyll, QGSJet, and Pythia. Built on top of their original\nFortran and C++ implementations, Chromo offers a zero-overhead abstraction\nlayer suitable for use in Python scripts, Jupyter notebooks, or from the\ncommand line, while preserving the performance of direct calls to the\ngenerators. It is easy to install via precompiled binary wheels distributed\nthrough PyPI, and it integrates well with the Scientific Python ecosystem.\nChromo supports event export in HepMC, ROOT, and SVG formats and provides a\nconsistent interface for inspecting, filtering, and modifying particle\ncollision events. This paper describes the architecture, typical use cases, and\nperformance characteristics of Chromo and its role in contemporary\nastroparticle simulations, such as in the MCEq cascade solver.", "AI": {"tldr": "Chromo is a Python package providing a unified interface to multiple hadronic event generators, offering high performance and integration with the Scientific Python ecosystem.", "motivation": "To simplify and unify the use of various hadronic event generators (like EPOS, DPMJet, etc.) in collider and astroparticle physics simulations.", "method": "Built as an abstraction layer on top of Fortran and C++ implementations, Chromo offers a Python interface with zero overhead, supporting event export in HepMC, ROOT, and SVG formats.", "result": "Chromo preserves the performance of direct generator calls while being easy to install and integrate with Python tools like Jupyter notebooks.", "conclusion": "Chromo is a versatile tool for hadronic and nuclear simulations, enhancing workflows in astroparticle physics, as demonstrated in the MCEq cascade solver."}}
{"id": "2507.21312", "pdf": "https://arxiv.org/pdf/2507.21312", "abs": "https://arxiv.org/abs/2507.21312", "authors": ["Sebastian Throm"], "title": "Mean field limit for interacting systems on co-evolving networks", "categories": ["math.AP", "math.DS"], "comment": null, "summary": "Interacting particle systems are in frequent use to model collective\nbehaviour in various situations and applications. For many systems, the\ninteraction between the agents is restricted to an underlying network structure\nand often, the latter also evolves in time with its dynamics coupled to the\nevolution of the particles. Due to their relevance for applications such\nsystems on adaptive or co-evolutionary networks have received increasing\ninterest in recent years. In particular, a fundamental question concerns the\nbehaviour of the system in the infinite particle limit. In this work we provide\na mean-field description for a general particle system which exhibits\nnon-locality in time (memory). The result applies particularly to a large class\nof systems on co-evolving networks including non-linear weight dynamics.", "AI": {"tldr": "A mean-field description is developed for particle systems with memory on co-evolving networks, addressing the infinite particle limit.", "motivation": "To model collective behavior in adaptive networks, where particle interactions and network dynamics are coupled, and to understand the system's behavior in the infinite particle limit.", "method": "A general mean-field approach is applied to particle systems with non-local time interactions (memory), including non-linear weight dynamics in co-evolving networks.", "result": "The work provides a mean-field framework suitable for a broad class of systems on co-evolving networks, accommodating memory effects.", "conclusion": "The proposed mean-field description advances the understanding of particle systems with memory on adaptive networks, particularly in the infinite particle limit."}}
{"id": "2507.21686", "pdf": "https://arxiv.org/pdf/2507.21686", "abs": "https://arxiv.org/abs/2507.21686", "authors": ["Rene Winchenbach", "Andreas Kolb"], "title": "Solving Boundary Handling Analytically in Two Dimensions for Smoothed Particle Hydrodynamics", "categories": ["math.NA", "cs.GR", "cs.NA", "G.1.0; I.6.0; I.3.5"], "comment": null, "summary": "We present a fully analytic approach for evaluating boundary integrals in two\ndimensions for Smoothed Particle Hydrodynamics (SPH). Conventional methods\noften rely on boundary particles or wall re-normalization approaches derived\nfrom applying the divergence theorem, whereas our method directly evaluates the\narea integrals for SPH kernels and gradients over triangular boundaries. This\ndirect integration strategy inherently accommodates higher-order boundary\nconditions, such as piecewise cubic fields defined via Finite Element stencils,\nenabling analytic and flexible coupling with mesh-based solvers. At the core of\nour approach is a general solution for compact polynomials of arbitrary degree\nover triangles by decomposing the boundary elements into elementary integrals\nthat can be solved with closed-form solutions. We provide a complete,\nclosed-form solution for these generalized integrals, derived by relating the\nangular components to Chebyshev polynomials and solving the resulting radial\nintegral via a numerically stable evaluation of the Gaussian hypergeometric\nfunction $_2F_1$. Our solution is robust and adaptable and works regardless of\ntriangle geometries and kernel functions. We validate the accuracy against\nhigh-precision numerical quadrature rules, as well as in problems with known\nexact solutions. We provide an open-source implementation of our general\nsolution using differentiable programming to facilitate the adoption of our\napproach to SPH and other contexts that require analytic integration over\npolygonal domains. Our analytic solution outperforms existing numerical\nquadrature rules for this problem by up to five orders of magnitude, for\nintegrals and their gradients, while providing a flexible framework to couple\narbitrary triangular meshes analytically to Lagrangian schemes, building a\nstrong foundation for addressing several grand challenges in SPH and beyond.", "AI": {"tldr": "A fully analytic method for evaluating boundary integrals in 2D SPH, replacing conventional boundary particles with direct integration over triangles, enabling higher-order boundary conditions and mesh-based solver coupling.", "motivation": "To overcome limitations of conventional SPH boundary methods (e.g., boundary particles or wall re-normalization) by providing a direct, analytic integration approach for flexible and accurate coupling with mesh-based solvers.", "method": "Direct evaluation of area integrals for SPH kernels and gradients over triangular boundaries, using closed-form solutions for compact polynomials decomposed into elementary integrals. Angular components relate to Chebyshev polynomials, and radial integrals are solved via Gaussian hypergeometric functions.", "result": "The method outperforms numerical quadrature by up to five orders of magnitude in accuracy for integrals and gradients, validated against high-precision quadrature and exact solutions.", "conclusion": "The analytic solution provides a robust, adaptable framework for SPH and other contexts requiring polygonal integration, addressing grand challenges in SPH with open-source implementation."}}
{"id": "2507.21961", "pdf": "https://arxiv.org/pdf/2507.21961", "abs": "https://arxiv.org/abs/2507.21961", "authors": ["Cheng Giuseppe Chen", "Chenyu Tang", "Alberto Meg\u00edas", "Radu A. Talmazan", "Sergio Contreras Arredondo", "Beno\u00eet Roux", "Christophe Chipot"], "title": "Following the Committor Flow: A Data-Driven Discovery of Transition Pathways", "categories": ["physics.comp-ph", "cond-mat.stat-mech", "physics.chem-ph"], "comment": "18 pages (including supplemental material with 10 pages), 9 figures\n  (4 figures in the main text and 5 figures in the supplemental material)", "summary": "The discovery of transition pathways to unravel distinct reaction mechanisms\nand, in general, rare events that occur in molecular systems is still a\nchallenge. Recent advances have focused on analyzing the transition path\nensemble using the committor probability, widely regarded as the most\ninformative one-dimensional reaction coordinate. Consistency between transition\npathways and the committor function is essential for accurate mechanistic\ninsight. In this work, we propose an iterative framework to infer the committor\nand, subsequently, to identify the most relevant transition pathways. Starting\nfrom an initial guess for the transition path, we generate biased sampling from\nwhich we train a neural network to approximate the committor probability. From\nthis learned committor, we extract dominant transition channels as discretized\nstrings lying on isocommittor surfaces. These pathways are then used to enhance\nsampling and iteratively refine both the committor and the transition paths\nuntil convergence. The resulting committor enables accurate estimation of the\nreaction rate constant. We demonstrate the effectiveness of our approach on\nbenchmark systems, including a two-dimensional model potential, peptide\nconformational transitions, and a Diels--Alder reaction.", "AI": {"tldr": "An iterative framework is proposed to infer the committor probability and identify key transition pathways in molecular systems, enhancing sampling and refining results until convergence.", "motivation": "The challenge of discovering transition pathways and rare events in molecular systems, with the committor probability being a critical but hard-to-compute reaction coordinate.", "method": "An iterative approach using biased sampling, neural networks to approximate the committor, and discretized strings on isocommittor surfaces to refine pathways.", "result": "The framework accurately estimates reaction rate constants and is validated on benchmark systems like peptide transitions and a Diels-Alder reaction.", "conclusion": "The method effectively refines committor and transition paths, providing accurate mechanistic insights and reaction rate estimates."}}
{"id": "2507.21470", "pdf": "https://arxiv.org/pdf/2507.21470", "abs": "https://arxiv.org/abs/2507.21470", "authors": ["Yu Mei", "Peng Yuan"], "title": "Stability of Large-Amplitude Viscous Shock Under Periodic Perturbation for 1-d Viscoelasticity with Non-Convex Constitutive Relations", "categories": ["math.AP", "35B40, 35L65, 35L67, 76A10"], "comment": "30 pages", "summary": "This paper investigates the large-time behavior of the viscous shock profile\nfor the one-dimensional system of viscoelasticity, subject to initial\nperturbations that approach space-periodic functions at far fields. We\nspecifically address the case with non-convex constitutive stress relations and\nnon-degenerate Lax's shock. Under the assumptions of suitably small initial\nperturbations satisfying a zero-mass type condition, we prove that the solution\nof the system converges to a viscous shock profile with a shift, which is\npartially determined by the space-periodic perturbation. Notably, our result\nimposes no amplitude restrictions on the viscous shock waves. This work extends\nthe result of Kawashima-Matsumura (\\textit{Commun. Pure Appl. Math.}\n\\textbf{47}, 1994) by simultaneously handling both large-amplitude shocks and\nspace-periodic perturbations, while also generalizing the result of Huang-Yuan\n(\\textit{Commun. Math. Phys.} \\textbf{387}, 2021) by allowing for a non-convex\nconstitutive relation. The key ingredient of proof is decomposing the\nlarge-amplitude shock wave into small-amplitude shocks and, for each,\nintroducing suitable transform and weight functions to counteract the adverse\neffects of non-convex constitutive relations encountered during weighted energy\nestimates on the system in effective velocity and deformation gradient\nvariables.", "AI": {"tldr": "The paper studies the long-term behavior of viscous shock profiles in a 1D viscoelastic system with non-convex stress relations and space-periodic perturbations, proving convergence to a shifted shock profile without amplitude restrictions.", "motivation": "To extend prior results by handling large-amplitude shocks and space-periodic perturbations simultaneously, while also allowing non-convex constitutive relations.", "method": "Decompose large-amplitude shocks into smaller ones, use transforms and weight functions to manage non-convexity in energy estimates.", "result": "The solution converges to a shifted viscous shock profile, partially determined by the perturbation, with no amplitude restrictions.", "conclusion": "The work generalizes previous findings by addressing non-convexity and large shocks, demonstrating robustness in handling complex perturbations."}}
{"id": "2507.21757", "pdf": "https://arxiv.org/pdf/2507.21757", "abs": "https://arxiv.org/abs/2507.21757", "authors": ["Channa Hatharasinghe", "Run Yan Teh", "Jesse van Rhijn", "Peter D. Drummond", "Margaret D. Reid"], "title": "Non-periodic Fourier propagation algorithms for partial differential equations", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "comment": null, "summary": "Spectral methods for solving partial differential equations (PDEs) and\nstochastic partial differential equations (SPDEs) often use Fourier or\npolynomial spectral expansions on either uniform and non-uniform grids.\nHowever, while very widely used, especially for slowly-varying solutions,\nnon-uniform spatial grids can give larger spatial discretization errors if the\nsolutions change rapidly in space. Here, we implement a Fourier method that\nemploys fast trigonometric expansions on a uniform grid with non-periodic\nboundaries using fast discrete sine transforms (DST) or/and discrete cosine\ntransforms (DCT) to solve parabolic PDEs. We implement this method in two ways:\neither using a Fourier spectral derivative or a Fourier interaction picture\napproach. These methods can treat vector fields with a combination of Dirichlet\nand/or Neumann boundary conditions in one or more space dimensions. We use them\nto solve a variety of PDEs with analytical solutions, including the Peregrine\nsolitary wave solution. For the 1D heat equation problem, our method with an\ninteraction picture is accurate up to the machine precision. A soluble example\nof an SPDE with non-periodic boundaries is also treated. We compare the results\nobtained from these algorithms with those from publicly available solvers that\nuse either polynomial spectral or finite element methods. For problems with\nsolutions that vary rapidly in space, our method outperforms the other methods\nby recording lower spatial discretization errors, as well being faster in many\ncases, due to the efficiency improvements given by fast transforms.", "AI": {"tldr": "A Fourier method using fast trigonometric expansions on uniform grids with non-periodic boundaries (DST/DCT) is implemented for solving parabolic PDEs, outperforming other methods in accuracy and speed for rapidly varying solutions.", "motivation": "Non-uniform grids can introduce larger spatial errors for rapidly varying solutions, prompting the need for a more efficient and accurate method.", "method": "The method employs fast discrete sine/cosine transforms (DST/DCT) on uniform grids, using either Fourier spectral derivatives or an interaction picture approach, adaptable to Dirichlet/Neumann boundary conditions.", "result": "For the 1D heat equation, the method achieves machine precision accuracy. It also outperforms polynomial spectral and finite element methods in accuracy and speed for rapidly varying solutions.", "conclusion": "The proposed Fourier method is highly accurate and efficient, especially for problems with rapidly varying spatial solutions, and is adaptable to various boundary conditions."}}
{"id": "2507.21126", "pdf": "https://arxiv.org/pdf/2507.21126", "abs": "https://arxiv.org/abs/2507.21126", "authors": ["Changdon Shin", "Sunghyun Yoon", "Yongchul G. Chung"], "title": "Evaluating Isoreticular Series of CALF-20 for Biogas Upgrading using a Pressure/Vacuum Swing Adsorption (PVSA) Process", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Cyclic swing adsorption processes, such as pressure vacuum swing adsorption\n(PVSA), have emerged as a promising technology for upgrading biogas by\nseparating carbon dioxide (CO2) from methane (CH4). The rational design of\nadsorbent materials with tailored properties is important for deployment of\nhigh-performance PVSA technology. Metal-organic frameworks (MOFs), particularly\nthe CALF-20 isoreticular series, have attracted interest due to their high CO2\nselectivity, thermal and water stability. In this study, we report a multiscale\nassessment of CALF-20 and its isoreticular five derivatives by integrating\nmolecular simulations and PVSA cycle optimization. Structural parameters such\nas pore volume, pore size, and isosteric adsorption enthalpy were first\ncalculated, followed by atomistic grand canonical Monte Carlo (GCMC)\nsimulations. Process-level performances of the six materials were evaluated and\noptimized using the Thompson Sampling Efficient Multi-objective Optimization\n(TSEMO) algorithm. From the process-level optimization, we found that\nFumCALF-20 is the only material that can reach CH4 purity > 0.90 while\nmaintaining high recovery. Other materials either lacked sufficient CO2\ncapacity or showed inefficient CH4 desorption at low pressures. This study\nunderscores the value of process-level optimization in MOF evaluation and\nscreening for energy-efficient biogas upgrading.", "AI": {"tldr": "The study evaluates CALF-20 and its derivatives for biogas upgrading using PVSA, identifying FumCALF-20 as the top performer for high CH4 purity and recovery.", "motivation": "To design high-performance adsorbent materials for efficient CO2/CH4 separation in biogas upgrading.", "method": "Combined molecular simulations (GCMC) and PVSA cycle optimization (TSEMO algorithm) to assess six CALF-20 derivatives.", "result": "FumCALF-20 achieved CH4 purity > 0.90 with high recovery, outperforming other materials.", "conclusion": "Process-level optimization is crucial for evaluating MOFs in energy-efficient biogas upgrading."}}
{"id": "2507.21604", "pdf": "https://arxiv.org/pdf/2507.21604", "abs": "https://arxiv.org/abs/2507.21604", "authors": ["Guanhua Liu"], "title": "The parabolic Harnack inequality on non-local Dirichlet spaces in the view of pure analysis", "categories": ["math.AP", "34K30 (primary), 31C25, 35K08, 47D07, 60J46 (secondary)"], "comment": null, "summary": "This paper provides the general theory on parabolic Harnack inequalities\n(PHI, for short) for regular Dirichlet forms without killing part. We prove PHI\nby pure analytic methods, using both Nash and Moser approaches, and yield some\nimportant properties contained in PHI. Combining our recent result on weak\nHarnack inequalities, we greatly enlarge the list of equivalent\ncharacterizations of PHI.", "AI": {"tldr": "The paper presents a general theory for parabolic Harnack inequalities (PHI) in regular Dirichlet forms, using Nash and Moser methods, and expands equivalent characterizations of PHI.", "motivation": "To establish a comprehensive theory for PHI in regular Dirichlet forms without killing, leveraging analytic methods.", "method": "Uses Nash and Moser approaches to prove PHI and derives key properties. Combines recent results on weak Harnack inequalities.", "result": "Enlarges the list of equivalent characterizations of PHI.", "conclusion": "The study advances the understanding of PHI and its properties in regular Dirichlet forms."}}
{"id": "2507.21913", "pdf": "https://arxiv.org/pdf/2507.21913", "abs": "https://arxiv.org/abs/2507.21913", "authors": ["Chunzhi Xiang", "Bo Wang", "Wenzhong Zhang", "Wei Cai"], "title": "Fast multipole method for the Laplace equation in half plane with Robin boundary condition", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "65D30, 65D32, 65R10, 41A60", "G.1.8; F.2.1; I.6.4"], "comment": null, "summary": "In this paper, we present a fast multipole method (FMM) for solving the\ntwo-dimensional Laplace equation in a half-plane with Robin boundary\nconditions. The method is based on a novel expansion theory for the reaction\ncomponent of the Green's function. By applying the Fourier transform, the\nreaction field component is obtained in a Sommerfeld-type integral form. We\nderive far-field approximations and corresponding shifting and translation\noperators from the Fourier integral representation. The FMM for the reaction\ncomponent is then developed by using the new far-field approximations\nincorporated into the classic FMM framework in which the tree structure is\nconstructed from the original and image charges. Combining this with the\nstandard FMM for the free-space components, we develop a fast algorithm to\ncompute the interaction of the half plane Laplace Green's function. We prove\nthat the method exhibits exponential convergence, similar to the free-space\nFMM. Finally, numerical examples are presented to validate the theoretical\nresults and demonstrate that the FMM achieves $O(N)$ computational complexity.", "AI": {"tldr": "A fast multipole method (FMM) for solving the 2D Laplace equation in a half-plane with Robin boundary conditions, using a novel expansion theory for the Green's function's reaction component.", "motivation": "To efficiently solve the Laplace equation in a half-plane with Robin boundary conditions, leveraging the FMM framework for computational speed.", "method": "Uses Fourier transform to express the reaction field as a Sommerfeld-type integral, derives far-field approximations, and integrates them into the classic FMM with a tree structure of original and image charges.", "result": "The method achieves exponential convergence and $O(N)$ computational complexity, validated by numerical examples.", "conclusion": "The developed FMM is efficient and accurate for solving the half-plane Laplace equation with Robin boundary conditions."}}
{"id": "2507.21725", "pdf": "https://arxiv.org/pdf/2507.21725", "abs": "https://arxiv.org/abs/2507.21725", "authors": ["Ansgar J\u00fcngel", "Tuan Tung Nguyen"], "title": "Existence analysis of a three-species memristor drift-diffusion system coupled to electric networks", "categories": ["math.AP", "34A09, 35K51, 35K55, 35Q81"], "comment": null, "summary": "The existence of global weak solutions to a partial-differential-algebraic\nsystem is proved. The system consists of the drift-diffusion equations for the\nelectron, hole, and oxide vacancy densities in a memristor device, the Poisson\nequation for the electric potential, and the differential-algebraic equations\nfor an electric network. The memristor device is modeled by a two-dimensional\nbounded domain, and mixed Dirichlet-Neumann boundary conditions for the\nelectron and hole densities as well as the potential are imposed. The coupling\nis realized via the total current through the memristor terminal and the\nnetwork node potentials at the terminals. The network equations are decomposed\nin a differential and an algebraic part. The existence proof is based on the\nLeray-Schauder fixed-point theorem, a priori estimates coming from the free\nenergy inequality, and a logarithmic-type Gagliardo-Nirenberg inequality. It is\nshown, under suitable assumptions, that the solutions are bounded and strictly\npositive.", "AI": {"tldr": "Existence of global weak solutions for a coupled PDE-algebraic system in memristor devices is proven using fixed-point theorems and energy estimates.", "motivation": "To model and analyze the complex interactions in memristor devices, coupling drift-diffusion equations with electric network dynamics.", "method": "Combines drift-diffusion equations, Poisson equation, and differential-algebraic network equations. Uses Leray-Schauder fixed-point theorem, energy inequalities, and Gagliardo-Nirenberg inequality.", "result": "Solutions are bounded and strictly positive under suitable assumptions.", "conclusion": "The proof establishes the existence of physically meaningful solutions for the coupled system."}}
{"id": "2507.21948", "pdf": "https://arxiv.org/pdf/2507.21948", "abs": "https://arxiv.org/abs/2507.21948", "authors": ["Yuchang Liu", "Wei Guo", "Yan Jiang", "Mengping Zhang"], "title": "Structure-preserving nodal DG method for Euler equations with gravity II: general equilibrium states", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We develop an entropy-stable nodal discontinuous Galerkin (DG) scheme for the\nEuler equations with gravity, which is also well-balanced with respect to\ngeneral equilibrium solutions, including both hydrostatic and moving\nequilibria. The core of our approach lies in a novel treatment of the\ngravitational source term, combining entropy-conservative numerical fluxes with\na linear entropy correction. In addition, the proposed formulation is carefully\ndesigned to ensure compatibility with a positivity-preserving limiter. We\nprovide a rigorous theoretical analysis to establish the accuracy and\nstructure-preserving properties of the proposed scheme. Extensive numerical\nexperiments confirm the robustness and efficiency of the scheme.", "AI": {"tldr": "An entropy-stable nodal DG scheme for Euler equations with gravity, ensuring well-balanced properties and compatibility with positivity-preserving limiters.", "motivation": "To address the need for accurate and robust numerical methods for Euler equations with gravity, including general equilibrium solutions.", "method": "Novel treatment of gravitational source term using entropy-conservative fluxes and linear entropy correction, designed for positivity preservation.", "result": "Theoretical analysis confirms accuracy and structure-preserving properties; numerical experiments demonstrate robustness and efficiency.", "conclusion": "The scheme is effective for Euler equations with gravity, balancing accuracy, stability, and computational efficiency."}}
{"id": "2507.21497", "pdf": "https://arxiv.org/pdf/2507.21497", "abs": "https://arxiv.org/abs/2507.21497", "authors": ["Angxiu Ni"], "title": "Backpropagation in unstable diffusions", "categories": ["math.PR", "math.DS", "physics.comp-ph"], "comment": null, "summary": "We derive the adjoint path-kernel method for the parameter-gradient of SDEs,\nwhere the observable is averaged at a particular time or over the stationary\nmeasure. Its cost is almost independent of the number of parameters; it extends\nthe conventional backpropagation method to cases with gradient explosion. It\nworks for non-hyperbolic systems with multiplicative noise controlled by\nparameters. We derive a Monte-Carlo-type algorithm and demonstrate it on the\n40-dimensional Lorenz 96 system.", "AI": {"tldr": "The paper introduces the adjoint path-kernel method for computing parameter-gradients in SDEs, applicable even with gradient explosion, and demonstrates it on the Lorenz 96 system.", "motivation": "To address the challenge of computing parameter-gradients in SDEs, especially in cases with gradient explosion or non-hyperbolic systems with multiplicative noise.", "method": "Derives the adjoint path-kernel method, extending conventional backpropagation, and develops a Monte-Carlo-type algorithm.", "result": "The method is shown to work effectively, demonstrated on the 40-dimensional Lorenz 96 system.", "conclusion": "The adjoint path-kernel method provides a scalable and robust solution for gradient computation in SDEs, even in challenging scenarios."}}
{"id": "2507.21779", "pdf": "https://arxiv.org/pdf/2507.21779", "abs": "https://arxiv.org/abs/2507.21779", "authors": ["Juan Carlos Fern\u00e1ndez", "Alberto Salda\u00f1a"], "title": "The conformal logarithmic Laplacian on the sphere: Yamabe-type problems and Sobolev spaces", "categories": ["math.AP", "math.DG", "35B33, 35R01, 35R11, 58J40, 58J70, 58J90"], "comment": "26 pages", "summary": "We study the conformal logarithmic Laplacian on the sphere, an explicit\nsingular integral operator that arises as the derivative (with respect to the\norder parameter) of the conformal fractional Laplacian at zero. Our analysis\nprovides a detailed investigation of its spectral properties, its conformal\ninvariance, and the associated \\(Q\\)-curvature problem. Furthermore, we\nestablish a precise connection between this operator on the sphere and the\nlogarithmic Laplacian in \\(\\mathbb{R}^N\\) via stereographic projection. This\ncorrespondence bridges classification results for two Yamabe-type problems\npreviously studied in the literature, extending one of them to the weak\nsetting. To this end, we introduce a Hilbert space that serves as the\nlogarithmic counterpart of the homogeneous fractional Sobolev space, offering a\nnatural functional framework for the variational study of logarithmic-type\nequations in unbounded domains.", "AI": {"tldr": "The paper analyzes the conformal logarithmic Laplacian on the sphere, its spectral properties, conformal invariance, and connection to the logarithmic Laplacian in Euclidean space via stereographic projection. It also links Yamabe-type problems and introduces a Hilbert space for variational study.", "motivation": "To understand the spectral and conformal properties of the logarithmic Laplacian on the sphere and its connection to Euclidean space, bridging gaps in Yamabe-type problems.", "method": "Detailed investigation of the operator's properties, conformal invariance, and stereographic projection to connect it with the Euclidean case. Introduction of a Hilbert space for variational analysis.", "result": "Established spectral properties, conformal invariance, and a precise connection between the sphere and Euclidean space. Extended classification results for Yamabe-type problems.", "conclusion": "The study provides a comprehensive framework for analyzing logarithmic-type operators and their applications, unifying results for the sphere and Euclidean space."}}
{"id": "2507.21574", "pdf": "https://arxiv.org/pdf/2507.21574", "abs": "https://arxiv.org/abs/2507.21574", "authors": ["Charles Dapogny", "Julien Prando", "Boris Thibert"], "title": "Distributionally Robust Shape and Topology Optimization", "categories": ["math.OC", "cs.NA", "math.NA"], "comment": null, "summary": "This article aims to introduce the paradigm of distributional robustness from\nthe field of convex optimization to tackle optimal design problems under\nuncertainty. We consider realistic situations where the physical model, and\nthereby the cost function of the design to be minimized depend on uncertain\nparameters. The probability distribution of the latter is itself known\nimperfectly, through a nominal law, reconstructed from a few observed samples.\nThe distributionally robust optimal design problem is an intricate bilevel\nprogram which consists in minimizing the worst value of a statistical quantity\nof the cost function (typically, its expectation) when the law of the uncertain\nparameters belongs to a certain ``ambiguity set''. We address three classes of\nsuch problems: firstly, this ambiguity set is made of the probability laws\nwhose Wasserstein distance to the nominal law is less than a given threshold;\nsecondly, the ambiguity set is based on the first- and second-order moments of\nthe actual and nominal probability laws. Eventually, a statistical quantity of\nthe cost other than its expectation is made robust with respect to the law of\nthe parameters, namely its conditional value at risk. Using techniques from\nconvex duality, we derive tractable, single-level reformulations of these\nproblems, framed over augmented sets of variables. Our methods are essentially\nagnostic of the optimal design framework; they are described in a unifying\nabstract framework, before being applied to multiple situations in\ndensity-based topology optimization and in geometric shape optimization.\nSeveral numerical examples are discussed in two and three space dimensions to\nappraise the features of the proposed techniques.", "AI": {"tldr": "The paper introduces distributional robustness from convex optimization to address optimal design under uncertainty, focusing on imperfectly known parameter distributions. It tackles three problem classes using Wasserstein distance, moment-based ambiguity, and conditional value at risk, deriving tractable reformulations via convex duality.", "motivation": "To handle optimal design problems where cost functions depend on uncertain parameters with imperfectly known distributions, ensuring robustness against distributional uncertainty.", "method": "Uses convex duality to reformulate bilevel programs into single-level problems, addressing ambiguity sets based on Wasserstein distance, moments, and conditional value at risk.", "result": "Tractable reformulations for robust optimal design problems, demonstrated through numerical examples in topology and shape optimization.", "conclusion": "The proposed methods effectively address distributional uncertainty in optimal design, with broad applicability beyond the discussed examples."}}
{"id": "2507.21797", "pdf": "https://arxiv.org/pdf/2507.21797", "abs": "https://arxiv.org/abs/2507.21797", "authors": ["M. Chirilus-Bruckner", "L. van Vianen", "F. Veerman"], "title": "Travelling front solutions in a spatially heterogeneous reaction-diffusion system", "categories": ["math.AP", "nlin.PS"], "comment": null, "summary": "We investigate a two-component reaction-diffusion system with a slow-fast\nstructure and spatially varying coefficients $ f_1 $ and $ f_2 $ appearing in\nthe slow equation. Under mild boundedness and regularity conditions on $ f_1 $\nand $ f_2 $ the system is shown to exhibit bi-stability in the form of two\nstable stationary heterogeneous background states. These background states can\nbe connected by stationary and travelling front solutions. Travelling fronts\nfeature an interface that moves with a non-uniform speed through the motionless\nspatially varying background states it connects. As a result, unlike classical\ntravelling waves, these fronts are not stationary in any co-moving frame. We\nconstruct both the background states and stationary fronts using an extension\nof Fenichel theory to the non-compact case. Additionally, we establish the\nexistence of travelling front solutions and derive a leading-order expression\nfor the dynamic position of the moving interface through a non-autonomous\nspatial dynamics approach. This expression takes the form of a\ndelay-differential equation, and its accuracy is validated through numerical\nsimulations. A key contribution of our work lies in the general treatment of $\nf_1 $ and $ f_2 $, which are neither (necessarily) asymptotically small nor\nrestricted to specific forms such as periodic or localised structures.\nFurthermore, our derivation of the front position formula circumvents the\ntraditional reliance on spectral analysis, enabling us to describe front\ndynamics beyond bifurcations from stationary fronts. This approach has the\npotential to be extended to other settings in which spectral properties at\nonset preclude conventional reduction techniques.", "AI": {"tldr": "The paper studies a slow-fast reaction-diffusion system with spatially varying coefficients, revealing bi-stability and the existence of stationary and travelling fronts with non-uniform speeds. It extends Fenichel theory and avoids spectral analysis for front dynamics.", "motivation": "To understand the dynamics of reaction-diffusion systems with spatially varying coefficients, particularly focusing on bi-stability and front solutions connecting stable states.", "method": "Extends Fenichel theory to non-compact cases, uses non-autonomous spatial dynamics for front solutions, and derives a delay-differential equation for interface motion.", "result": "Demonstrates bi-stability, constructs stationary and travelling fronts, and validates a leading-order expression for front dynamics numerically.", "conclusion": "The work generalizes treatment of spatially varying coefficients and offers a novel approach to front dynamics, applicable beyond traditional spectral analysis."}}
{"id": "2507.21791", "pdf": "https://arxiv.org/pdf/2507.21791", "abs": "https://arxiv.org/abs/2507.21791", "authors": ["Erin Carson", "Yuxin Ma"], "title": "The Performance of Low-Synchronization Variants of Reorthogonalized Block Classical Gram--Schmidt", "categories": ["cs.DC", "cs.NA", "math.NA", "65F10, 65F25, 65G50, 65Y20"], "comment": "7 pages, 2 figures", "summary": "Numerous applications, such as Krylov subspace solvers, make extensive use of\nthe block classical Gram-Schmidt (BCGS) algorithm and its reorthogonalized\nvariants for orthogonalizing a set of vectors. For large-scale problems in\ndistributed memory settings, the communication cost, particularly the global\nsynchronization cost, is a major performance bottleneck. In recent years, many\nlow-synchronization BCGS variants have been proposed in an effort to reduce the\nnumber of synchronization points. The work [E. Carson, Y. Ma, arXiv preprint\n2411.07077] recently proposed stable one-synchronization and\ntwo-synchronization variants of BCGS, i.e., BCGSI+P-1S and BCGSI+P-2S. In this\nwork, we evaluate the performance of BCGSI+P-1S and BCGSI+P-2S on a distributed\nmemory system compared to other well-known low-synchronization BCGS variants.\nIn comparison to the classical reorthogonalized BCGS algorithm (BCGSI+),\nnumerical experiments demonstrate that BCGSI+P-1S and BCGSI+P-2S can achieve up\nto 4 times and 2 times speedups, respectively, and perform similarly to other\n(less stable) one-synchronization and two-synchronization variants. BCGSI+P-1S\nand BCGSI+P-2S are therefore recommended as the best choice in practice for\ncomputing an economic QR factorization on distributed memory systems due to\ntheir superior stability when compared to other variants with the same\nsynchronization cost.", "AI": {"tldr": "The paper evaluates the performance of low-synchronization BCGS variants (BCGSI+P-1S and BCGSI+P-2S) on distributed memory systems, showing significant speedups and stability advantages.", "motivation": "Communication costs, especially global synchronization, are a bottleneck in distributed memory systems for orthogonalizing vectors. Reducing synchronization points while maintaining stability is crucial.", "method": "Performance comparison of BCGSI+P-1S and BCGSI+P-2S against other low-synchronization BCGS variants on distributed memory systems.", "result": "BCGSI+P-1S achieves up to 4x speedup, BCGSI+P-2S up to 2x, with similar performance to less stable variants. Both are stable and efficient.", "conclusion": "BCGSI+P-1S and BCGSI+P-2S are recommended for economic QR factorization due to their stability and performance advantages."}}
{"id": "2507.21695", "pdf": "https://arxiv.org/pdf/2507.21695", "abs": "https://arxiv.org/abs/2507.21695", "authors": ["Kristian G. Barman", "Sascha Caron", "Faegheh Hasibi", "Eugene Shalugin", "Yoris Marcet", "Johannes Otte", "Henk W. de Regt", "Merijn Moody"], "title": "Towards a Large Physics Benchmark", "categories": ["physics.data-an", "cs.AI", "hep-ph", "physics.comp-ph", "physics.hist-ph"], "comment": null, "summary": "We introduce a benchmark framework developed by and for the scientific\ncommunity to evaluate, monitor and steer large language model development in\nfundamental physics. Building on philosophical concepts of scientific\nunderstanding and creativity, we develop a scoring system in which each\nquestion is scored by an expert for its correctness, difficulty, and surprise.\nThe questions are of three forms: (i) multiple-choice questions for conceptual\nunderstanding, (ii) analytical problems requiring mathematical derivation, and\n(iii) openended tasks requiring complex problem solving. Our current dataset\ncontains diverse set of examples, including a machine learning challenge to\nclassify high-energy physics events, such as the four top quark signal. To\nensure continued relevance, we propose a living benchmark, where physicists\ncontribute questions, for instance alongside new publications. We invite\ncontributions via: http://www.physicsbenchmarks.org/. We hope that this\nbenchmark will enable a targeted AI development that can make a meaningful\ncontribution to fundamental physics research.", "AI": {"tldr": "A benchmark framework for evaluating large language models in physics, scoring questions for correctness, difficulty, and surprise, with contributions from the community.", "motivation": "To steer AI development in fundamental physics by providing a structured evaluation system based on scientific understanding and creativity.", "method": "Developed a scoring system with three question types: multiple-choice, analytical problems, and open-ended tasks, evaluated by experts. Includes a living benchmark for ongoing relevance.", "result": "A diverse dataset, including a machine learning challenge for high-energy physics events, with community-driven contributions.", "conclusion": "The benchmark aims to guide meaningful AI contributions to physics research, inviting ongoing participation."}}
{"id": "2507.21850", "pdf": "https://arxiv.org/pdf/2507.21850", "abs": "https://arxiv.org/abs/2507.21850", "authors": ["Cosmin Burtea", "David G\u00e9rard-Varet"], "title": "Weak solutions of a viscous model for fluid-bubbles interaction", "categories": ["math.AP", "35Q30, 76D05"], "comment": null, "summary": "We present a system of Navier-Stokes type that describes the dynamics of\nseveral spherical bubbles of gas in a liquid. It is derived from a more\ncomplete model, where the bubbles are seen as inclusions of gas of homogeneous\nbarotropic pressure with free surfaces. The usual condition of continuity of\nthe stress is relaxed in order to preserve the sphericity of the bubbles\nthrough time. We construct weak solutions \\`a la Leray for this relaxed system,\nup to collision between the bubbles. Although these solutions are reminiscent\nof weak solutions for fluid-solid interaction systems, accounting for the\ncompression/dilation of the bubbles creates new and significant mathematical\ndifficulties.", "AI": {"tldr": "A system of Navier-Stokes type for spherical gas bubbles in liquid is derived, relaxing stress continuity to maintain sphericity. Weak solutions are constructed until bubble collisions, addressing new mathematical challenges.", "motivation": "To model the dynamics of spherical gas bubbles in a liquid while preserving their shape over time, relaxing traditional stress continuity conditions.", "method": "Derived from a complete model treating bubbles as gas inclusions with homogeneous barotropic pressure and free surfaces. Weak solutions are constructed \u00e0 la Leray, accounting for bubble compression/dilation.", "result": "Weak solutions are successfully constructed up to the point of bubble collisions, despite new mathematical complexities introduced by bubble compression/dilation.", "conclusion": "The relaxed system provides a viable framework for modeling spherical bubble dynamics, though challenges remain in handling compression/dilation effects."}}
{"id": "2507.21716", "pdf": "https://arxiv.org/pdf/2507.21716", "abs": "https://arxiv.org/abs/2507.21716", "authors": ["Eneko Lazpita", "Jesus Garicano-Mena", "Soledad Le Clainche"], "title": "Efficient Reduced Order Modeling Based on HODMD to Predict Intraventricular Flow Dynamics", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": "28 pages, 11 figures", "summary": "Accurate and efficient modeling of cardiac blood flow is crucial for\nadvancing data-driven tools in cardiovascular research and clinical\napplications. Recently, the accuracy and availability of computational fluid\ndynamics (CFD) methodologies for simulating intraventricular flow have\nincreased. However, these methods remain complex and computationally costly.\nThis study presents a reduced order model (ROM) based on higher order dynamic\nmode decomposition (HODMD). The proposed approach enables accurate\nreconstruction and long term prediction of left ventricle flow fields. The\nmethod is tested on two idealized ventricular geometries exhibiting distinct\nflow regimes to assess its robustness under different hemodynamic conditions.\nBy leveraging a small number of training snapshots and focusing on the dominant\nperiodic components representing the physics of the system, the HODMD-based\nmodel accurately reconstructs the flow field over entire cardiac cycles and\nprovides reliable long-term predictions beyond the training window. The\nreconstruction and prediction errors remain below 5\\% for the first geometry\nand below 10\\% for the second, even when using as few as the first 3 cycles of\nsimulated data, representing the transitory regime. Additionally, the approach\nreduces computational costs with a speed-up factor of at least $10^{5}$\ncompared to full-order simulations, enabling fast surrogate modeling of complex\ncardiac flows. These results highlight the potential of spectrally-constrained\nHODMD as a robust and interpretable ROM for simulating intraventricular\nhemodynamics. This approach shows promise for integration in real-time analysis\nand patient specific models.", "AI": {"tldr": "A reduced order model (ROM) using higher order dynamic mode decomposition (HODMD) is proposed for accurate and efficient cardiac blood flow simulation, achieving low error rates and significant computational savings.", "motivation": "Accurate and efficient modeling of cardiac blood flow is essential for cardiovascular research and clinical applications, but current CFD methods are complex and costly.", "method": "The study introduces a HODMD-based ROM to reconstruct and predict left ventricle flow fields, tested on two idealized ventricular geometries with distinct flow regimes.", "result": "The model achieves reconstruction and prediction errors below 5-10%, with a computational speed-up of 10^5 compared to full-order simulations.", "conclusion": "The HODMD-based ROM is robust and interpretable, suitable for real-time analysis and patient-specific models in cardiac hemodynamics."}}
{"id": "2507.21870", "pdf": "https://arxiv.org/pdf/2507.21870", "abs": "https://arxiv.org/abs/2507.21870", "authors": ["Xing Liang", "Linfeng Xu", "Tao Zhou"], "title": "Spreading speeds in rapidly and slowly varying almost periodic media", "categories": ["math.AP"], "comment": "36 pages", "summary": "This paper is concerned with the asymptotic behavior of the spreading speeds\nof Fisher-KPP equations in rapidly and slowly varying almost periodic settings\nrespectively. Thanks to the variational formula for the spreading speeds\ninvolving generalized principal eigenvalue, we are able to concentrate on the\nhomogenization problem of certain Hamilton-Jacobi equations. We will present\nalso the limits and the convergence rate of the spreading speeds. At last, we\nwill consider the effect on the spreading speeds after adding a fixed reaction\nterm.", "AI": {"tldr": "The paper analyzes the spreading speeds of Fisher-KPP equations in varying almost periodic settings, focusing on homogenization of Hamilton-Jacobi equations, limits, convergence rates, and the impact of adding a reaction term.", "motivation": "To understand the asymptotic behavior of spreading speeds in Fisher-KPP equations under rapidly and slowly varying almost periodic conditions.", "method": "Uses a variational formula involving generalized principal eigenvalues to study homogenization of Hamilton-Jacobi equations.", "result": "Presents limits and convergence rates of spreading speeds and examines the effect of adding a fixed reaction term.", "conclusion": "The study provides insights into the behavior of spreading speeds in Fisher-KPP equations under varying conditions and the influence of additional reaction terms."}}
{"id": "2507.21748", "pdf": "https://arxiv.org/pdf/2507.21748", "abs": "https://arxiv.org/abs/2507.21748", "authors": ["Simon Daubner", "Alexander E. Cohen", "Benjamin D\u00f6rich", "Samuel J. Cooper"], "title": "evoxels: A differentiable physics framework for voxel-based microstructure simulations", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.CE", "physics.comp-ph"], "comment": "9 pages, 3 figures, structure following JOSS style", "summary": "Materials science inherently spans disciplines: experimentalists use advanced\nmicroscopy to uncover micro- and nanoscale structure, while theorists and\ncomputational scientists develop models that link processing, structure, and\nproperties. Bridging these domains is essential for inverse material design\nwhere you start from desired performance and work backwards to optimal\nmicrostructures and manufacturing routes. Integrating high-resolution imaging\nwith predictive simulations and data-driven optimization accelerates discovery\nand deepens understanding of process-structure-property relationships. The\ndifferentiable physics framework evoxels is based on a fully Pythonic, unified\nvoxel-based approach that integrates segmented 3D microscopy data, physical\nsimulations, inverse modeling, and machine learning.", "AI": {"tldr": "The paper introduces evoxels, a differentiable physics framework for integrating microscopy data, simulations, and machine learning to optimize material design.", "motivation": "Bridging experimental and computational domains is crucial for inverse material design, linking desired performance to optimal microstructures and manufacturing.", "method": "The evoxels framework uses a Pythonic, voxel-based approach to combine segmented 3D microscopy data, physical simulations, inverse modeling, and machine learning.", "result": "This integration accelerates material discovery and enhances understanding of process-structure-property relationships.", "conclusion": "Evoxels provides a unified solution for advancing inverse material design through interdisciplinary integration."}}
{"id": "2507.21962", "pdf": "https://arxiv.org/pdf/2507.21962", "abs": "https://arxiv.org/abs/2507.21962", "authors": ["Sidy M. Djitte"], "title": "Pohozaev-like identity for the regional fractional laplacian", "categories": ["math.AP"], "comment": null, "summary": "We establish a new integration by parts formula for the regional fractional\nlaplacian $(-\\Delta)^s_\\Omega$ in bounded open sets of class $C^2$. As a direct\napplication, we prove that weak solutions to the corresponding Dirichlet\nproblem satisfy a Pohozaev-like identity with an explicit remainder term. We\napply the later to eigenvalue problems in the unit ball and discuss its\npotential use in establishing boundary-type unique continuation properties.", "AI": {"tldr": "A new integration by parts formula for the regional fractional Laplacian is derived, leading to a Pohozaev-like identity for weak solutions and applications in eigenvalue problems and unique continuation properties.", "motivation": "To extend integration by parts techniques to the regional fractional Laplacian in bounded domains and explore its implications for PDEs.", "method": "Derive an integration by parts formula for the regional fractional Laplacian in C^2 bounded sets, then apply it to weak solutions of the Dirichlet problem.", "result": "A Pohozaev-like identity is proven for weak solutions, with applications in eigenvalue problems and boundary-type unique continuation.", "conclusion": "The new formula and identity provide tools for analyzing fractional Laplacian problems and potential extensions to unique continuation properties."}}
{"id": "2507.21760", "pdf": "https://arxiv.org/pdf/2507.21760", "abs": "https://arxiv.org/abs/2507.21760", "authors": ["Andrea Fantasia", "Daniele Lanzoni", "Niccol\u00f2 Di Eugenio", "Angelo Monteleone", "Roberto Bergamaschini", "Francesco Montalenti"], "title": "Unified machine-learning framework for property prediction and time-evolution simulation of strained alloy microstructure", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "cs.LG", "physics.comp-ph"], "comment": "19 pages, 9 figures", "summary": "We introduce a unified machine-learning framework designed to conveniently\ntackle the temporal evolution of alloy microstructures under the influence of\nan elastic field. This approach allows for the simultaneous extraction of\nelastic parameters from a short trajectory and for the prediction of further\nmicrostructure evolution under their influence. This is demonstrated by\nfocusing on spinodal decomposition in the presence of a lattice mismatch eta,\nand by carrying out an extensive comparison between the ground-truth evolution\nsupplied by phase field simulations and the predictions of suitable\nconvolutional recurrent neural network architectures. The two tasks may then be\nperformed subsequently into a cascade framework. Under a wide spectrum of\nmisfit conditions, the here-presented cascade model accurately predicts eta and\nthe full corresponding microstructure evolution, also when approaching critical\nconditions for spinodal decomposition. Scalability to larger computational\ndomain sizes and mild extrapolation errors in time (for time sequences five\ntimes longer than the sampled ones during training) are demonstrated. The\nproposed framework is general and can be applied beyond the specific,\nprototypical system considered here as an example. Intriguingly, experimental\nvideos could be used to infer unknown external parameters, prior to simulating\nfurther temporal evolution.", "AI": {"tldr": "A unified ML framework predicts alloy microstructure evolution under elastic fields, extracting parameters and forecasting future states accurately.", "motivation": "To address the challenge of predicting temporal microstructure evolution in alloys influenced by elastic fields, using a scalable and generalizable approach.", "method": "Combines convolutional recurrent neural networks with phase field simulations to extract elastic parameters and predict microstructure evolution.", "result": "Accurate predictions of misfit conditions and microstructure evolution, even near critical conditions, with scalability and minimal extrapolation errors.", "conclusion": "The framework is generalizable and applicable beyond the studied system, potentially using experimental data to infer unknown parameters."}}
{"id": "2507.21227", "pdf": "https://arxiv.org/pdf/2507.21227", "abs": "https://arxiv.org/abs/2507.21227", "authors": ["Sim\u00e3o Correia", "Jos\u00e9 Nat\u00e1rio", "Jorge Drumond Silva"], "title": "Elastic rigid rod in an expanding universe", "categories": ["gr-qc", "math-ph", "math.AP", "math.MP", "35L05, 74K05, 83C10, 83C55"], "comment": "20 pages, 4 figures", "summary": "We study the motion of a rigid elastic rod, initially set in its relaxed\nstate along a spacelike geodesic, in an expanding\nFriedmann-Lema\\^itre-Robertson-Walker universe. This leads to an initial\nboundary value problem (IBVP) for a nonlinear wave equation whose nonlinearity\ndepends on a parameter $\\kappa \\geq 0$, related to the ratio between the rod's\nlength and the cosmological scale. We show that if $\\kappa$ is small enough\nthen the solution to the IBVP is global in time and bounded, meaning that the\nrod's length oscillates around its initial value. For greater values of\n$\\kappa$, however, the solution to the IBVP blows up in finite coordinate time,\nindicating that the rod is infinitely stretched by the cosmological expansion.\nThis supports the widely held belief that sufficiently small bound systems do\nnot follow the Hubble flow, whereas larger systems may do so. Similar\nconclusions apply to the tethered galaxy version of this problem, where the rod\nis used to connect two point masses (which results in nonlinear boundary\nconditions for the IBVP).", "AI": {"tldr": "The paper examines the motion of a rigid elastic rod in an expanding universe, showing its behavior depends on a parameter \u03ba. Small \u03ba leads to bounded oscillations, while large \u03ba causes infinite stretching, aligning with the idea that small bound systems resist Hubble flow.", "motivation": "To understand how bound systems like rigid rods behave in an expanding universe and whether they follow the Hubble flow.", "method": "Analyzes an initial boundary value problem (IBVP) for a nonlinear wave equation with parameter \u03ba, representing the rod's length relative to the cosmological scale.", "result": "For small \u03ba, the rod's length oscillates around its initial value; for large \u03ba, it stretches infinitely, supporting the idea that small systems resist expansion.", "conclusion": "Small bound systems resist cosmological expansion, while larger ones may follow the Hubble flow, with implications for tethered galaxy scenarios."}}
{"id": "2507.21763", "pdf": "https://arxiv.org/pdf/2507.21763", "abs": "https://arxiv.org/abs/2507.21763", "authors": ["Daniele Lanzoni", "Olivier Pierre-Louis", "Roberto Bergamaschini", "Francesco Montalenti"], "title": "Learning Kinetic Monte Carlo stochastic dynamics with Deep Generative Adversarial Networks", "categories": ["cond-mat.stat-mech", "cond-mat.mtrl-sci", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": "15 pages, 8 figures, 2 appendices", "summary": "We show that Generative Adversarial Networks (GANs) may be fruitfully\nexploited to learn stochastic dynamics, surrogating traditional models while\ncapturing thermal fluctuations. Specifically, we showcase the application to a\ntwo-dimensional, many-particle system, focusing on surface-step fluctuations\nand on the related time-dependent roughness. After the construction of a\ndataset based on Kinetic Monte Carlo simulations, a conditional GAN is trained\nto propagate stochastically the state of the system in time, allowing the\ngeneration of new sequences with a reduced computational cost. Modifications\nwith respect to standard GANs, which facilitate convergence and increase\naccuracy, are discussed. The trained network is demonstrated to quantitatively\nreproduce equilibrium and kinetic properties, including scaling laws, with\ndeviations of a few percent from the exact value. Extrapolation limits and\nfuture perspectives are critically discussed.", "AI": {"tldr": "GANs are used to learn stochastic dynamics, replacing traditional models for simulating particle systems with thermal fluctuations, achieving accurate results with reduced computational cost.", "motivation": "To leverage GANs for learning stochastic dynamics in particle systems, capturing thermal fluctuations more efficiently than traditional methods like Kinetic Monte Carlo.", "method": "A conditional GAN is trained on a dataset from Kinetic Monte Carlo simulations to propagate system states stochastically, with modifications for better convergence and accuracy.", "result": "The GAN quantitatively reproduces equilibrium and kinetic properties, including scaling laws, with deviations of a few percent from exact values.", "conclusion": "GANs are effective for simulating stochastic dynamics, though extrapolation limits exist, suggesting future work to address these constraints."}}
{"id": "2507.21305", "pdf": "https://arxiv.org/pdf/2507.21305", "abs": "https://arxiv.org/abs/2507.21305", "authors": ["William Cooperman", "Gautam Iyer", "Keefer Rowan", "Seungjae Son"], "title": "Exponentially mixing flows with slow enhanced dissipation rates", "categories": ["math.PR", "math.AP", "math.DS", "60J25, 35Q49, 76R05"], "comment": null, "summary": "Consider a passive scalar which is advected by an incompressible flow $u$ and\nhas small molecular diffusivity $\\kappa$. Previous results show that if $u$ is\nexponentially mixing and $C^1$, then the dissipation time is $O(|\\log\n\\kappa|^2)$. We produce a family of incompressible flows which are $C^0$ and\nexponentially mixing, uniformly in $\\kappa$; however have a dissipation time of\norder $1/\\kappa$ (i.e. exhibits no enhanced dissipation). We also estimate the\ndissipation time of mixing flows, and obtain improved bounds in terms of the\nmixing rate with explicit constants, and allow for a time inhomogeneous mixing\nrate which is typical for random constructions of mixing flows.", "AI": {"tldr": "The paper explores the dissipation time of a passive scalar in incompressible flows, contrasting previous results with new findings for $C^0$ flows.", "motivation": "To understand how the regularity of the flow affects the dissipation time of a passive scalar, especially in cases where enhanced dissipation is absent.", "method": "The authors construct a family of incompressible $C^0$ flows that are exponentially mixing and analyze their dissipation time. They also estimate dissipation times for mixing flows with improved bounds.", "result": "For $C^0$ flows, the dissipation time scales as $1/\\kappa$, showing no enhanced dissipation, unlike $C^1$ flows. Improved bounds for mixing flows are derived.", "conclusion": "The regularity of the flow significantly impacts dissipation time, with $C^0$ flows lacking enhanced dissipation despite being mixing."}}
{"id": "2507.21789", "pdf": "https://arxiv.org/pdf/2507.21789", "abs": "https://arxiv.org/abs/2507.21789", "authors": ["Xinyuan Liang", "Renxi Liu", "Mohan Chen"], "title": "Investigating CO Adsorption on Cu(111) and Rh(111) Surfaces Using Machine Learning Exchange-Correlation Functionals", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "The \"CO adsorption puzzle\", a persistent failure of utilizing generalized\ngradient approximations (GGA) in density functional theory to replicate CO's\nexperimental preference for top-site adsorption on transition-metal surfaces,\nremains a critical barrier in surface chemistry. While hybrid functionals such\nas HSE06 partially resolve this discrepancy, their prohibitive computational\ncost limits broader applications. We tackle this issue by adopting the Deep\nKohn-Sham (DeePKS) method to train machine-learned exchange-correlation\nfunctionals. Principal component analysis reveals that the input descriptors\nfor electronic structures separate distinctly across different chemical\nenvironments, enabling the DeePKS models to generalize to multi-element\nsystems. We train system-specific DeePKS models for transition-metal surfaces\nCu(111) and Rh(111). These models successfully recover experimental site\npreferences, yielding adsorption energy differences of about 10 meV compared to\nHSE06. Furthermore, a single model for the two surfaces is trained, and the\nmodel achieves comparable accuracy in predicting not only adsorption energies\nand site preference but also potential energy surfaces and relaxed surface\nadsorption structures. The above work demonstrates a promising path towards\nuniversal models, enabling catalyst exploration with hybrid functional accuracy\nat substantially reduced cost.", "AI": {"tldr": "The paper addresses the CO adsorption puzzle in surface chemistry by using the Deep Kohn-Sham (DeePKS) method to train machine-learned exchange-correlation functionals, achieving experimental accuracy at lower computational cost.", "motivation": "The persistent failure of GGA in replicating CO's experimental adsorption preferences on transition-metal surfaces motivates the need for more accurate and computationally feasible solutions.", "method": "The DeePKS method is employed to train machine-learned functionals, with principal component analysis used to generalize models to multi-element systems. System-specific models for Cu(111) and Rh(111) are developed.", "result": "The trained models successfully replicate experimental site preferences, with adsorption energy differences of ~10 meV compared to HSE06. A single model for both surfaces also performs comparably well.", "conclusion": "The DeePKS approach offers a promising path to universal models for catalyst exploration, combining hybrid functional accuracy with reduced computational cost."}}
{"id": "2507.21646", "pdf": "https://arxiv.org/pdf/2507.21646", "abs": "https://arxiv.org/abs/2507.21646", "authors": ["Vincenzo Recupero", "Federico Stra"], "title": "Excess-continuous prox-regular sweeping processes", "categories": ["math.CA", "math.AP", "math.DS", "34G25, 34A60, 47J20, 74C05"], "comment": "23 pages, 1 figure", "summary": "In this paper we consider the Moreau's sweeping processes driven by a time\ndependent prox-regular set $C(t)$ which is continuous in time with respect to\nthe asymmetric distance $e$ called the excess, defined by $e(A,B) := \\sup_{x\n\\in A} d(x,B)$ for every pair of sets $A$, $B$ in a Hilbert space. As observed\nby J.J. Moreau in his pioneering works, the excess provides the natural\ntopological framework for sweeping process. Assuming a uniform interior cone\ncondition for $C(t)$, we prove that the associated sweeping process has a\nunique solution, thereby improving the existing result on continuous\nprox-regular sweeping processes in two directions: indeed, in the previous\nliterature $C(t)$ was supposed to be continuous in time with respect to the\nsymmetric Hausdorff distance instead of the excess and also its boundary\n$\\partial C(t)$ was required to be continuous in time, an assumption which we\ncompletely drop. Therefore our result allows to consider a much wider class of\ncontinuously moving constraints.", "AI": {"tldr": "The paper improves uniqueness results for Moreau's sweeping processes by using the asymmetric excess distance and dropping boundary continuity assumptions.", "motivation": "To generalize and improve existing results on sweeping processes by relaxing continuity requirements and using the excess distance.", "method": "Analyzes Moreau's sweeping processes with prox-regular sets continuous in time under the excess distance, assuming a uniform interior cone condition.", "result": "Proves unique solution existence for sweeping processes under weaker conditions than previous literature.", "conclusion": "The work extends applicability of sweeping processes by allowing more general moving constraints."}}
{"id": "2507.21841", "pdf": "https://arxiv.org/pdf/2507.21841", "abs": "https://arxiv.org/abs/2507.21841", "authors": ["Rahul Golder", "M. M. Faruque Hasan"], "title": "Discovering Interpretable Ordinary Differential Equations from Noisy Data", "categories": ["cs.LG", "physics.comp-ph"], "comment": "20 pages, 11 figures, 7 tables", "summary": "The data-driven discovery of interpretable models approximating the\nunderlying dynamics of a physical system has gained attraction in the past\ndecade. Current approaches employ pre-specified functional forms or basis\nfunctions and often result in models that lack physical meaning and\ninterpretability, let alone represent the true physics of the system. We\npropose an unsupervised parameter estimation methodology that first finds an\napproximate general solution, followed by a spline transformation to linearly\nestimate the coefficients of the governing ordinary differential equation\n(ODE). The approximate general solution is postulated using the same functional\nform as the analytical solution of a general homogeneous, linear,\nconstant-coefficient ODE. An added advantage is its ability to produce a\nhigh-fidelity, smooth functional form even in the presence of noisy data. The\nspline approximation obtains gradient information from the functional form\nwhich are linearly independent and creates the basis of the gradient matrix.\nThis gradient matrix is used in a linear system to find the coefficients of the\nODEs. From the case studies, we observed that our modeling approach discovers\nODEs with high accuracy and also promotes sparsity in the solution without\nusing any regularization techniques. The methodology is also robust to noisy\ndata and thus allows the integration of data-driven techniques into real\nexperimental setting for data-driven learning of physical phenomena.", "AI": {"tldr": "Proposes an unsupervised method for discovering interpretable ODE models from noisy data using spline transformations and linear estimation.", "motivation": "Current methods lack physical interpretability and accuracy in modeling system dynamics.", "method": "Uses an approximate general solution and spline transformation to linearly estimate ODE coefficients, leveraging gradient information.", "result": "Achieves high accuracy and sparsity in ODE discovery without regularization, robust to noise.", "conclusion": "Enables practical data-driven learning of physical phenomena with interpretable models."}}
{"id": "2507.21729", "pdf": "https://arxiv.org/pdf/2507.21729", "abs": "https://arxiv.org/abs/2507.21729", "authors": ["S\u0142awomir Dinew", "Marcin Sroka"], "title": "A priori estimates for the complex Monge-Amp\u00e8re equation after Krylov", "categories": ["math.CV", "math.AP"], "comment": null, "summary": "We establish an analytic proof for the Krylov $C^{1,1}$ estimates for\nsolutions of degenerate complex Monge-Amp\\`ere equation. We also provide an\nanalytic proof of the Bedford-Taylor interior $C^{1,1}$ estimate.", "AI": {"tldr": "Analytic proofs for Krylov $C^{1,1}$ estimates and Bedford-Taylor interior $C^{1,1}$ estimates in degenerate complex Monge-Amp\u00e8re equations.", "motivation": "To provide rigorous analytic proofs for key estimates in the study of degenerate complex Monge-Amp\u00e8re equations, addressing gaps in existing literature.", "method": "Uses analytic techniques to derive $C^{1,1}$ estimates for solutions of the degenerate complex Monge-Amp\u00e8re equation, focusing on Krylov and Bedford-Taylor cases.", "result": "Successful establishment of analytic proofs for the Krylov $C^{1,1}$ estimates and the Bedford-Taylor interior $C^{1,1}$ estimate.", "conclusion": "The proofs enhance understanding of regularity in degenerate complex Monge-Amp\u00e8re equations, contributing to broader mathematical analysis."}}
{"id": "2507.21890", "pdf": "https://arxiv.org/pdf/2507.21890", "abs": "https://arxiv.org/abs/2507.21890", "authors": ["Baoyang Zhang", "Zhen Lu", "Yaomin Zhao", "Yue Yang"], "title": "Data-driven quantum Koopman method for simulating nonlinear dynamics", "categories": ["quant-ph", "cs.AI", "cs.LG", "physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "Quantum computation offers potential exponential speedups for simulating\ncertain physical systems, but its application to nonlinear dynamics is\ninherently constrained by the requirement of unitary evolution. We propose the\nquantum Koopman method (QKM), a data-driven framework that bridges this gap\nthrough transforming nonlinear dynamics into linear unitary evolution in\nhigher-dimensional observable spaces. Leveraging the Koopman operator theory to\nachieve a global linearization, our approach maps system states into a\nhierarchy of Hilbert spaces using a deep autoencoder. Within the linearized\nembedding spaces, the state representation is decomposed into modulus and phase\ncomponents, and the evolution is governed by a set of unitary Koopman operators\nthat act exclusively on the phase. These operators are constructed from\ndiagonal Hamiltonians with coefficients learned from data, a structure designed\nfor efficient implementation on quantum hardware. This architecture enables\ndirect multi-step prediction, and the operator's computational complexity\nscales logarithmically with the observable space dimension. The QKM is\nvalidated across diverse nonlinear systems. Its predictions maintain relative\nerrors below 6% for reaction-diffusion systems and shear flows, and capture key\nstatistics in 2D turbulence. This work establishes a practical pathway for\nquantum-accelerated simulation of nonlinear phenomena, exploring a framework\nbuilt on the synergy between deep learning for global linearization and quantum\nalgorithms for unitary dynamics evolution.", "AI": {"tldr": "The paper introduces the Quantum Koopman Method (QKM), a data-driven framework for simulating nonlinear dynamics using quantum computation by transforming them into linear unitary evolution in higher-dimensional spaces.", "motivation": "Quantum computation's potential for simulating physical systems is limited by the requirement of unitary evolution, which inherently constrains its application to nonlinear dynamics. The QKM aims to bridge this gap.", "method": "The QKM leverages Koopman operator theory for global linearization, mapping system states into Hilbert spaces via a deep autoencoder. It decomposes states into modulus and phase components, with evolution governed by unitary Koopman operators acting on the phase, constructed from data-learned diagonal Hamiltonians.", "result": "Validated across diverse nonlinear systems, QKM maintains relative errors below 6% for reaction-diffusion systems and shear flows, and captures key statistics in 2D turbulence.", "conclusion": "The QKM provides a practical pathway for quantum-accelerated simulation of nonlinear phenomena, combining deep learning for linearization and quantum algorithms for unitary evolution."}}
