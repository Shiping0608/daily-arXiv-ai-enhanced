<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 13]
- [math.AP](#math.AP) [Total: 18]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [physics.optics](#physics.optics) [Total: 2]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [math.PR](#math.PR) [Total: 1]
- [cond-mat.supr-con](#cond-mat.supr-con) [Total: 1]
- [math.DG](#math.DG) [Total: 1]
- [math-ph](#math-ph) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Convergence analysis of a second-order SAV-ZEC scheme for the Cahn-Hilliard-Navier-Stokes system](https://arxiv.org/abs/2507.22949)
*Jingwei Sun,Zeyu Xia,Wei Zhang*

Main category: math.NA

TL;DR: A linear, fully decoupled numerical scheme for the CHNS system is proposed using SAV-ZEC reformulation, MAC finite difference, BDF2, and Adams-Bashforth, ensuring unconditional stability and optimal convergence rates.


<details>
  <summary>Details</summary>
Motivation: To develop a stable and efficient numerical method for the CHNS system by decoupling and simplifying the computational process.

Method: Combines SAV-ZEC reformulation, MAC finite difference, BDF2 temporal discretization, and Adams-Bashforth extrapolation, with a pressure correction approach for the Stokes equation.

Result: The scheme is unconditionally stable and achieves optimal convergence rates for phase and velocity variables in specified norms.

Conclusion: The proposed method effectively decouples and stabilizes the CHNS system, offering a practical and efficient numerical solution.

Abstract: Incorporating the scalar auxiliary variable (SAV) method and the zero energy
contribution (ZEC) technique, we analyze a linear and fully decoupled numerical
scheme for the Cahn-Hilliard-Naiver-Stokes (CHNS) system. More precisely, the
fully discrete scheme combines the marker-and-cell (MAC) finite difference
spatial approximation and BDF2 temporal discretization, as well as the
Adams-Bashforth extrapolation for the nonlinear terms, based on the SAV-ZEC
reformulation. A pressure correction approach is applied to decouple the Stokes
equation. Only constant-coefficient Poisson-like solvers are needed in the
implementation for the resulting numerical system. The numerical scheme is
unconditionally stable with respect to a rewritten total energy functional,
represented in terms of one auxiliary variable in the double-well potential,
another auxiliary variable to balance all the nonlinear and coupled terms, the
surface energy in the original phase variable, combined with the kinematic
energy part. Specifically, the error estimate for the phase variable in the
$\ell^{\infty}(0,T;H_h^1)\cap\ell^2(0,T;H_h^3)$ norm, the velocity variable in
the $\ell^{\infty}(0,T;\ell^2)\cap\ell^2(0,T;H_h^1)$ norm, is derived with
optimal convergence rates.

</details>


### [2] [Hybrid Shifted Gegenbauer Integral-Pseudospectral Method for Solving Time-Fractional Benjamin-Bona-Mahony-Burgers Equation](https://arxiv.org/abs/2507.23099)
*Kareem T. Elgindy*

Main category: math.NA

TL;DR: A high-order hybrid shifted Gegenbauer integral-pseudospectral (HSG-IPS) method is introduced for solving the time-fractional Benjamin-Bona-Mahony-Burgers (FBBMB) equation, achieving spectral accuracy and outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: To address numerical instability and inefficiency in solving the FBBMB equation by transforming it into a fractional partial-integro differential form with only first-order derivatives.

Method: Combines shifted Gegenbauer pseudospectral (SGPS) method, Gegenbauer-based fractional approximation (GBFA), and other advanced techniques to approximate the transformed equation with spectral accuracy.

Result: Demonstrates significantly lower average absolute errors (AAEs) and fast computational times (0.04-0.05 seconds), with robustness across fractional orders.

Conclusion: The HSG-IPS method provides a stable, efficient, and accurate framework for fractional calculus applications, particularly in wave propagation and nonlinearity modeling.

Abstract: This paper presents a high-order hybrid shifted Gegenbauer
integral-pseudospectral (HSG-IPS) method for solving the time-fractional
Benjamin-Bona-Mahony-Burgers (FBBMB) equation. A key innovation of our approach
is the transformation of the original equation into a fractional
partial-integro differential form that contains only a first-order derivative,
which can be accurately approximated using a first-order shifted Gegenbauer
differentiation matrix (SGDM), while all other terms in the transformed
equation are resolved using highly accurate quadrature rules. The method
combines several advanced numerical techniques including the shifted Gegenbauer
pseudospectral (SGPS) method, Gegenbauer-based fractional approximation (GBFA),
shifted Gegenbauer integration matrix (SGIM), shifted Gegenbauer integration
row vector (SGIRV), and SGDM to achieve spectral accuracy. Numerical
experiments demonstrate that the HSG-IPS method outperforms existing numerical
approaches, achieving significantly lower average absolute errors (AAEs) with
computational times as low as 0.04-0.05 seconds. The method's robustness is
validated across various fractional orders, showing excellent agreement with
analytical solutions. The transformation strategy effectively circumvents the
numerical instability associated with direct approximation of high-order
derivatives in the original equation, while the use of shifted Gegenbauer (SG)
polynomials and barycentric representations ensures numerical stability and
efficiency. This work provides a powerful computational framework for modeling
wave propagation, dispersion, and nonlinearity in fractional calculus
applications.

</details>


### [3] [$hp$-adaptive finite element simulation of a static anti-plane shear crack in a nonlinear strain-limiting elastic solid](https://arxiv.org/abs/2507.23195)
*S. M. Mallikarjunaiah,Pavithra Venkatachalapthy*

Main category: math.NA

TL;DR: An $hp$-adaptive finite element method is developed for analyzing static anti-plane shear cracks in nonlinear strain-limiting elastic bodies, ensuring well-posedness and accuracy through adaptive refinement and error estimation.


<details>
  <summary>Details</summary>
Motivation: The study aims to address the challenge of modeling cracks in nonlinear elastic materials with bounded, monotone, coercive, and Lipschitz continuous constitutive laws, ensuring mathematical robustness.

Method: The method involves an $hp$-adaptive finite element scheme with residual-based error indicators for mesh refinement ($h$-adaptivity) and local polynomial degree adjustment ($p$-adaptivity) based on solution regularity.

Result: Numerical experiments confirm the method's accuracy and convergence, with crack-tip field analysis for various parameters.

Conclusion: The framework provides a robust basis for extending to more complex problems like dynamic crack propagation in brittle materials.

Abstract: An $hp$-adaptive continuous Galerkin finite element method is developed to
analyze a static anti-plane shear crack embedded in a nonlinear,
strain-limiting elastic body. The geometrically linear material is described by
a constitutive law relating stress and strain that is algebraically nonlinear.
In this investigation, the constitutive relation utilized is \textit{uniformly
bounded}, \textit{monotone}, \textit{coercive}, and \textit{Lipschitz
continuous}, ensuring the well-posedness of the mathematical model. The
governing equation, derived from the balance of linear momentum coupled with
the nonlinear constitutive relationship, is formulated as a second-order
quasi-linear elliptic partial differential equation. For a body with an edge
crack, this governing equation is augmented with a classical traction-free
boundary condition on the crack faces. An $hp$-adaptive finite element scheme
is proposed for the numerical approximation of the resulting boundary value
problem. The adaptive strategy is driven by a dual-component error estimation
scheme: mesh refinement ($h$-adaptivity) is guided by a residual-based a
posteriori error indicator of the \textit{Kelly type}, while the local
polynomial degree ($p$-adaptivity) is adjusted based on an estimator of the
local solution regularity. The performance, accuracy, and convergence
characteristics of the proposed method are demonstrated through numerical
experiments. The structure of the regularized crack-tip fields is examined for
various modeling parameters. Furthermore, the presented framework establishes a
robust foundation for extension to more complex and computationally demanding
problems, including quasi-static and dynamic crack propagation in brittle
materials.

</details>


### [4] [Error analysis of the projected PO method with additive inflation for the partially observed Lorenz 96 model](https://arxiv.org/abs/2507.23199)
*Kota Takeda*

Main category: math.NA

TL;DR: The study establishes the error bound of the PO method, a variant of the EnKF, for the partially observed Lorenz 96 model, using additive inflation and covariance projection.


<details>
  <summary>Details</summary>
Motivation: To address the unestablished accuracy of the EnKF for the Lorenz 96 model, focusing on the PO method.

Method: Introduces additive inflation and projects background covariance to observation space to derive the PO method's error bound.

Result: Theoretical error bound is established and validated numerically, suggesting potential for further analysis.

Conclusion: The PO method's error bound is successfully derived and verified, paving the way for extended research.

Abstract: We consider the filtering problem with the partially observed Lorenz 96
model. Although the accuracy of the 3DVar filter applied to this problem has
been established, that of the EnKF has not yet been. This study aims to
establish the error bound of a variant of the EnKF, known as the PO method. By
introducing the additive inflation and a projection of the background
covariance to the observation space, we establish the error bound of the PO
method. A numerical example validates theoretical findings and shows the
potential to extend the analysis.

</details>


### [5] [Improved Analysis of Khatri-Rao Random Projections and Applications](https://arxiv.org/abs/2507.23207)
*Arvind K. Saibaba,Bhisham Dev Verma,Grey Ballard*

Main category: math.NA

TL;DR: The paper explores the use of Khatri-Rao random projections (KRPs) for efficient matrix and tensor decompositions, addressing the gap between theoretical guarantees and practical performance. It proposes new algorithms for low-rank approximations and provides theoretical and empirical validation.


<details>
  <summary>Details</summary>
Motivation: Standard Gaussian random matrices are costly for large-scale matrix and tensor decompositions, while KRPs offer a cheaper alternative but lack strong theoretical backing. The paper aims to bridge this gap.

Method: The authors propose new algorithms for low-rank approximations of block-structured matrices and tensor computations in the Tucker format using KRPs, with improved theoretical analysis.

Result: Numerical experiments on synthetic and real-world tensors demonstrate the computational efficiency and accuracy of the proposed methods.

Conclusion: KRPs are a viable and efficient alternative to Gaussian random matrices for matrix and tensor decompositions, with improved theoretical guarantees and practical performance.

Abstract: Randomization has emerged as a powerful set of tools for large-scale matrix
and tensor decompositions. Randomized algorithms involve computing sketches
with random matrices. A prevalent approach is to take the random matrix as a
standard Gaussian random matrix, for which the theory is well developed.
However, this approach has the drawback that the cost of generating and
multiplying by the random matrix can be prohibitively expensive. Khatri-Rao
random projections (KRPs), obtained by sketching with Khatri-Rao products of
random matrices, offer a viable alternative and are much cheaper to generate.
However, the theoretical guarantees of using KRPs are much more pessimistic
compared to their accuracy observed in practice. We attempt to close this gap
by obtaining improved analysis of the use of KRPs in matrix and tensor low-rank
decompositions. We propose and analyze a new algorithm for low-rank
approximations of block-structured matrices (e.g., block Hankel) using KRPs. We
also develop new algorithms to accelerate tensor computations in the Tucker
format using KRPs, and give theoretical guarantees of the resulting low-rank
approximations. Numerical experiments on synthetic and real-world tensors show
the computational benefits of the proposed methods.

</details>


### [6] [An optimal preconditioner for high-order scheme arising from multi-dimensional Riesz space fractional diffusion equations with variable coefficients](https://arxiv.org/abs/2507.23408)
*Yuan-Yuan Huang,Wei Qu,Sean Y. Hon,Siu-Long Lei*

Main category: math.NA

TL;DR: Proposes an efficient CN-4FCD scheme for multi-dimensional Riesz space fractional diffusion equations, ensuring stability, convergence, and high accuracy, with a sine transform-based preconditioner for computational efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of solving multi-dimensional Riesz space fractional diffusion equations with variable coefficients efficiently and accurately.

Method: Uses Crank-Nicolson (CN) for temporal discretization and fourth-order fractional centered difference (4FCD) for spatial discretization, with a sine transform-based preconditioner for efficiency.

Result: The CN-4FCD scheme is unconditionally stable and convergent, achieving second-order accuracy in time and fourth-order in space. The preconditioner ensures mesh-size-independent convergence.

Conclusion: The proposed method is validated numerically, showing superior performance over existing methods.

Abstract: In this paper, we propose an efficient method for solving multi-dimensional
Riesz space fractional diffusion equations with variable coefficients. The
Crank-Nicolson (CN) method is used for temporal discretization, while the
fourth-order fractional centered difference (4FCD) method is employed for
spatial discretization. Using a novel technique, we show that the CN-4FCD
scheme for the multi-dimensional case is unconditionally stable and convergent,
achieving second-order accuracy in time and fourth-order accuracy in space with
respect to the discrete L2-norm. Moreover, leveraging the symmetric multi-level
Toeplitz-like structure of the coefficient matrix in the discrete linear
systems, we enhance the computational efficiency of the proposed scheme with a
sine transform-based preconditioner, ensuring a mesh-size-independent
convergence rate for the conjugate gradient method. Finally, two numerical
examples validate the theoretical analysis and demonstrate the superior
performance of the proposed preconditioner compared to existing methods.

</details>


### [7] [The Effect of Prior Parameters on Standardized Kalman Filter-Based EEG Source Localization](https://arxiv.org/abs/2507.23450)
*Dilshanie Prasikala,Joonas Lahtinen,Alexandra Koulouri,Sampsa Pursiainen*

Main category: math.NA

TL;DR: The paper explores EEG source localization using the Standardized Kalman Filter (SKF) with Gaussian priors, optimizing parameters for detecting cortical and sub-cortical activity, and highlights improved accuracy with specific standardization and smoothing.


<details>
  <summary>Details</summary>
Motivation: EEG source localization is challenging due to its ill-posed nature. The study aims to enhance accuracy by refining Gaussian prior models within the SKF framework, addressing depth bias and improving detection of deep and superficial sources.

Method: The study uses synthetic data resembling somatosensory evoked potentials (SEP) to test Gaussian prior configurations in the SKF framework. It evaluates parameter settings and the impact of RTS smoothing on source separability.

Result: Raising the standardization exponent to 1.25 and applying smoothing significantly improves depth localization accuracy, especially at low noise levels.

Conclusion: The optimized SKF framework with Gaussian priors and smoothing enhances EEG source localization, particularly for deep and superficial activity detection.

Abstract: EEG Source localization is a critical tool in neuroscience, with applications
ranging from epilepsy diagnosis to cognitive research. It involves solving an
ill-posed inverse problem that lacks a unique solution unless constrained by
prior knowledge. The Bayesian framework enables the incorporation of such
knowledge, typically encoded through prior models. Various algorithms have been
proposed for source localization, and they differ significantly in how prior
knowledge is incorporated. Some approaches rely on anatomical or functional
constraints, while others use statistical distributions or sampling-based
techniques. In this landscape, the Standardized Kalman Filter (SKF) represents
a dynamic Bayesian approach that integrates temporal modeling with a Gaussian
prior structure. It addresses the depth bias, a common limitation in source
localization, through a post-hoc standardization step that equalizes
sensitivity across cortical depths and makes deep activity detection feasible.
  This study focuses on the development and optimization of Gaussian prior
models within the SKF framework for simultaneous cortical and sub-cortical
activity detection. Synthetic data similar to the P20 / N20 component of the
somatosensory evoked potentials (SEP) was used to identify effective prior
parameter configurations for reconstructing both deep and superficial sources
under different noise levels. We also investigated the role of RTS smoothing in
enhancing source separability. Our results indicate that raising the
standardization exponent to 1.25, along with smoothing, significantly improves
depth localization accuracy at low noise levels.

</details>


### [8] [Rational complex Bezier curves](https://arxiv.org/abs/2507.23485)
*A. Canton,L. Fernandez-Jambrina,M. J. Vazquez-Gallo*

Main category: math.NA

TL;DR: The paper introduces rational complex Bézier curves, extending CAD paradigms with complex control polygons and weights, enabling new projective transformations and degree reduction.


<details>
  <summary>Details</summary>
Motivation: To enhance curve design by extending Bézier curves to complex values, allowing more transformations and potential degree reduction.

Method: Extends Bézier curves to complex values, uses projective transformations (real and complex), and applies resultants to check curve properties.

Result: Enables new transformations (e.g., geometric inversion) and provides a formula to identify if a rational cubic curve is a conic.

Conclusion: The formalism broadens design possibilities and simplifies curve analysis, demonstrated with classical curve examples.

Abstract: In this paper we develop the formalism of rational complex Bezier curves.
This framework is a simple extension of the CAD paradigm, since it describes
arc of curves in terms of control polygons and weights, which are extended to
complex values. One of the major advantages of this extension is that we may
make use of two different groups of projective transformations. Besides the
group of projective transformations of the real plane, we have the group of
complex projective transformations. This allows us to apply useful
transformations like the geometric inversion to curves in design. In addition
to this, the use of the complex formulation allows to lower the degree of the
curves in some cases. This can be checked using the resultant of two
polynomials and provides a simple formula for determining whether a rational
cubic curve is a conic or not. Examples of application of the formalism to
classical curves are included.

</details>


### [9] [Quantum simulation of Helmholtz equations via Schr{ö}dingerization](https://arxiv.org/abs/2507.23547)
*Anjiao Gu,Shi Jin,Chuwen Ma*

Main category: math.NA

TL;DR: A quantum algorithm for solving the Helmholtz equation using the Schrödingerization framework, achieving efficient query complexity with preconditioning.


<details>
  <summary>Details</summary>
Motivation: The Helmholtz equation's challenges (indefiniteness, large systems) motivate a quantum solution leveraging damped dynamics and higher-dimensional reformulation.

Method: The Schrödingerization framework reformulates the problem into a Schrödinger-type system, using a warped phase transformation and asymptotic dispersion correction.

Result: The algorithm achieves query complexity of O(κ² polylog ε⁻¹), reduced to O(κ polylog ε⁻¹) for Helmholtz with preconditioning.

Conclusion: The method is broadly applicable to indefinite problems, offering a quantum-compatible solution with improved efficiency.

Abstract: The Helmholtz equation is a prototypical model for time-harmonic wave
propagation. Numerical solutions become increasingly challenging as the wave
number $k$ grows, due to the equation's elliptic yet noncoercive character and
the highly oscillatory nature of its solutions, with wavelengths scaling as
$1/k$. These features lead to strong indefiniteness and large system sizes.
  We present a quantum algorithm for solving such indefinite problems, built
upon the Schr\"odingerization framework. This approach reformulates linear
differential equations into Schr\"odinger-type systems by capturing the steady
state of damped dynamics. A warped phase transformation lifts the original
problem to a higher-dimensional formulation, making it compatible with quantum
computation. To suppress numerical pollution, the algorithm incorporates
asymptotic dispersion correction. It achieves a query complexity of
$\mathcal{O}(\kappa^2\text{polylog}\varepsilon^{-1})$, where $\kappa$ is the
condition number and $\varepsilon$ the desired accuracy. For the Helmholtz
equation, a simple preconditioner further reduces the complexity to
$\mathcal{O}(\kappa\text{polylog}\varepsilon^{-1})$. Our constructive extension
to the quantum setting is broadly applicable to all indefinite problems.

</details>


### [10] [Fitted norm preconditioners for the Hodge Laplacian in mixed form](https://arxiv.org/abs/2507.23586)
*Wietse M. Boon,Johannes Kraus,Tomáš Luber,Maria Lymbery*

Main category: math.NA

TL;DR: The paper analyzes the mixed formulation of the Hodge Laplace problem using perturbed saddle point problems, ensuring well-posedness and proposing a simplified, efficient preconditioner.


<details>
  <summary>Details</summary>
Motivation: To address the well-posedness and stability of the Hodge Laplace problem's mixed formulation, leveraging recent theoretical frameworks.

Method: Composing parameter-dependent norms for uniform continuity and stability, simplifying these norms, and deriving a norm-equivalent preconditioner.

Result: Demonstrated efficiency and uniformity of the preconditioner through numerical experiments with fast convergence and bounded iterations.

Conclusion: The approach guarantees well-posedness and provides an easily implementable, effective preconditioner for Hodge Laplace problems.

Abstract: We use the practical framework for abstract perturbed saddle point problems
recently introduced by Hong et al. to analyze the mixed formulation of the
Hodge Laplace problem. We compose two parameter-dependent norms in which the
uniform continuity and stability of the problem follow. This not only
guarantees the well-posedness of the corresponding variational formulation on
the continuous level, but also of related compatible discrete models.
  We further simplify the obtained norms and, in both cases, arrive at the same
norm-equivalent preconditioner that is easily implementable. The efficiency and
uniformity of the preconditioner are demonstrated numerically by the fast
convergence and uniformly bounded number of preconditioned MINRES iterations
required to solve various instances of Hodge Laplace problems in two and three
space dimensions.

</details>


### [11] [Efficient Numerical Strategies for Entropy-Regularized Semi-Discrete Optimal Transport](https://arxiv.org/abs/2507.23602)
*Moaad Khamlich,Francesco Romor,Gianluigi Rozza*

Main category: math.NA

TL;DR: The paper addresses computational challenges in semi-discrete optimal transport (SOT) with entropic regularization, proposing a framework combining distance-based truncation, R-trees, multilevel techniques, and adaptive regularization to enable large-scale applications.


<details>
  <summary>Details</summary>
Motivation: The computational bottleneck in evaluating the dual objective function for RSOT, especially with finite element discretization of complex geometries, limits practical applications.

Method: The framework accelerates evaluations via distance-based truncation and R-trees, integrates multilevel techniques for convergence, and uses adaptive regularization scheduling.

Result: The unified methods significantly reduce computational costs, making RSOT feasible for large-scale problems.

Conclusion: The proposed framework, with an open-source C++ implementation, enables practical use of RSOT in complex scenarios.

Abstract: Semi-discrete optimal transport (SOT), which maps a continuous probability
measure to a discrete one, is a fundamental problem with wide-ranging
applications. Entropic regularization is often employed to solve the SOT
problem, leading to a regularized (RSOT) formulation that can be solved
efficiently via its convex dual. However, a significant computational challenge
emerges when the continuous source measure is discretized via the finite
element (FE) method to handle complex geometries or densities, such as those
arising from solutions to Partial Differential Equations (PDEs). The evaluation
of the dual objective function requires dense interactions between the numerous
source quadrature points and all target points, creating a severe bottleneck
for large-scale problems. This paper presents a cohesive framework of numerical
strategies to overcome this challenge. We accelerate the dual objective and
gradient evaluations by combining distance-based truncation with fast spatial
queries using R-trees. For overall convergence, we integrate multilevel
techniques based on hierarchies of both the FE source mesh and the discrete
target measure, alongside a robust scheduling strategy for the regularization
parameter. When unified, these methods drastically reduce the computational
cost of RSOT, enabling its practical application to complex, large-scale
scenarios. We provide an open-source C++ implementation of this framework,
built upon the deal.II finite element library, available at
https://github.com/SemiDiscreteOT/SemiDiscreteOT.

</details>


### [12] [A Multi-Frequency Helmholtz Solver Based on the WaveHoltz Algorithm](https://arxiv.org/abs/2507.23613)
*Daniel Appelö,Francis Appiah,Jeffrey W. Banks,Cassandra Carrick,William D. Henshaw,Donald W. Schwendeman*

Main category: math.NA

TL;DR: The paper introduces the Multi-Frequency WaveHoltz (MFWH) algorithm, an extension of the WaveHoltz method, for simultaneously solving Helmholtz equations for multiple frequencies and forcing functions using a single wave equation and time filters.


<details>
  <summary>Details</summary>
Motivation: The need for efficient computation of multiple Helmholtz solutions for varying frequencies and forcing functions motivates the development of the MFWH algorithm.

Method: MFWH combines a single wave equation with multiple time filters, employs fixed-point iteration accelerated by Krylov methods (e.g., GMRES), and uses high-order spatial and second-order temporal discretizations.

Result: The algorithm achieves O(N) solution cost with fixed frequencies and increasing grid points, validated by numerical results using second- and fourth-order discretizations.

Conclusion: MFWH efficiently computes Helmholtz solutions, converges to discretized Helmholtz solutions, and is validated by numerical experiments.

Abstract: We develop and analyze a new approach for simultaneously computing multiple
solutions to the Helmholtz equation for different frequencies and different
forcing functions. The new Multi-Frequency WaveHoltz (MFWH) algorithm is an
extension of the original WaveHoltz method and both are based on time-filtering
solutions to an associated wave equation. With MFWH, the different Helmholtz
solutions are computed simultaneously by solving a single wave equation
combined with multiple time filters. The MFWH algorithm defines a fixed-point
iteration which can be accelerated with Krylov methods such as GMRES. The
solution of the wave equation can be efficiently solved with either explicit
time-stepping or implicit time-stepping using as few as five time-steps per
period. When combined with an $O(N)$ solver for the implicit equations, such a
multigrid, the scheme has an $O(N)$ solution cost when the frequencies are
fixed and the number of grid points $N$ increases. High-order accurate
approximations in space are used together with second-order accurate
approximations in time. We show how to remove time discretization errors so
that the MFWH solutions converge to the corresponding solutions to the
discretized Helmholtz problems. Numerical results are given using second-order
accurate and fourth-accurate discretizations to confirm the convergence theory.

</details>


### [13] [Regularization of Inverse Problems by Filtered Diagonal Frame Decomposition under general source](https://arxiv.org/abs/2507.23651)
*Dang Duc Trong,Nguyen Dang Minh,Luu Xuan Thang,Luu Dang Khoa*

Main category: math.NA

TL;DR: The paper explores regularization methods for ill-posed inverse problems in Hilbert spaces, introducing Diagonal Frame Decomposition (DFD) as an alternative to SVD, and analyzes convergence rates under generalized source conditions.


<details>
  <summary>Details</summary>
Motivation: Inverse problems with noisy data are ill-posed, requiring stabilization. SVD is computationally expensive for some operators, motivating the search for alternatives like DFD.

Method: The paper proposes DFD to generalize SVD-based techniques, introducing a regularized solution and analyzing convergence under a generalized source condition.

Result: Theoretical results include modulus of continuity bounds and convergence rates for DFD, applicable to polynomial and exponentially ill-posed problems.

Conclusion: DFD offers a viable alternative to SVD for regularization, with theoretical guarantees on convergence and optimality under generalized source conditions.

Abstract: Let $X$ and $Y$ be Hilbert spaces, and $\mathbf{K}: \text{dom} \mathbf{K}
\subset X \to Y$ a bounded linear operator. This paper addresses the inverse
problem $\mathbf{K}x = y$, where exact data $y$ is replaced by noisy data
$y^\delta$ satisfying $\|y^\delta - y\|_Y \leq \delta$. Due to the
ill-posedness of such problems, we employ regularization methods to stabilize
solutions. While singular value decomposition (SVD) provides a classical
approach, its computation can be costly and impractical for certain operators.
We explore alternatives via Diagonal Frame Decomposition (DFD), generalizing
SVD-based techniques, and introduce a regularized solution $x^\delta_\alpha =
\sum_{\lambda \in \Lambda} \kappa_\lambda g_\alpha(\kappa_\lambda^2) \langle
y^\delta, v_\lambda \rangle \overline{u}_\lambda$. Convergence rates and
optimality are analyzed under a generalized source condition
$\mathbf{M}_{\varphi, E} = \{ x \in \text{dom} \mathbf{K} : \sum_{\lambda \in
\Lambda} [\varphi(\kappa_\lambda^2)]^{-1} |\langle x, u_\lambda \rangle|^2 \leq
E^2 \}$. Key questions include constructing DFD systems, relating DFD and SVD
singular values, and extending source conditions. We present theoretical
results, including modulus of continuity bounds and convergence rates for a
priori and a posteriori parameter choices, with applications to polynomial and
exponentially ill-posed problems.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [14] [Mean-field approximation, Gibbs relaxation, and cross estimates](https://arxiv.org/abs/2507.23123)
*Armand Bernou,Mitia Duerinckx*

Main category: math.AP

TL;DR: The paper improves the mean-field approximation error for Brownian particles with weak interactions, showing a cross error of $O(N^{-1}e^{-ct})$ between chaos propagation and Gibbs relaxation.


<details>
  <summary>Details</summary>
Motivation: To advance understanding of chaos propagation and Gibbs relaxation in systems of Brownian particles with weak mean-field interactions.

Method: Analysis of the BBGKY hierarchy for correlation functions, applied to underdamped and overdamped Langevin dynamics with bounded interaction forces.

Result: Improved mean-field approximation error from $O(N^{-1})$ to $O(N^{-1}e^{-ct})$ for translation-invariant systems.

Conclusion: The work provides refined error bounds and extends results on Gibbs relaxation, with partial extensions beyond weak interactions.

Abstract: This work focuses on the propagation of chaos and the relaxation to Gibbs
equilibrium for a system of $N$ classical Brownian particles with weak
mean-field interactions. While it is known that propagation of chaos holds at
rate $O(N^{-1})$ uniformly in time, and Gibbs relaxation at rate $O(e^{-ct})$
uniformly in $N$, we go a step further by showing that the cross error between
chaos propagation and Gibbs relaxation is $O(N^{-1}e^{-ct})$. For
translation-invariant systems on the torus, this leads to an improved
mean-field approximation error at the level of the one-particle density: the
error decreases from $O(N^{-1})$ to $O(N^{-1}e^{-ct})$. Our approach relies on
a detailed analysis of the BBGKY hierarchy for correlation functions, and
applies to both underdamped and overdamped Langevin dynamics with merely
bounded interaction forces. We also derive new results on Gibbs relaxation and
present partial extensions beyond the weak interaction regime.

</details>


### [15] [A note on the first Steklov eigenvalue on planar domains](https://arxiv.org/abs/2507.23312)
*Azahara DelaTorre,Gabriele Mancini,Angela Pistoia,Luigi Provenzano*

Main category: math.AP

TL;DR: The paper examines the first positive Steklov eigenvalue on planar domains, providing an example with a closed nodal line and establishing a lower bound for symmetric domains, proving simplicity for ellipses.


<details>
  <summary>Details</summary>
Motivation: To address gaps in the understanding of the first positive Steklov eigenvalue, particularly regarding nodal lines and eigenvalue simplicity, as highlighted by Kuttler and Sigillito's work.

Method: The study involves constructing an example of a planar domain with a closed nodal line and deriving a lower bound for symmetric domains, with a focus on ellipses.

Result: A planar domain with a closed nodal line is demonstrated, and a lower bound for the first positive eigenvalue on symmetric domains is established, proving simplicity for ellipses.

Conclusion: The findings complement prior work by Kuttler and Sigillito, enhancing the understanding of Steklov eigenvalues on planar domains.

Abstract: We consider the first positive Steklov eigenvalue on planar domains. First,
we provide an example of a planar domain for which a first eigenfunction has a
closed nodal line. Second, we establish a lower bound for the first positive
eigenvalue on certain symmetric domains and show that this eigenvalue is simple
for all ellipses. These results complement two statements contained in a work
by Kuttler and Sigillito (Proc. Amer. Math. Soc. 20, 1969).

</details>


### [16] [On the existence of normalized solutions to a class of fractional Choquard equation with potentials](https://arxiv.org/abs/2507.23363)
*Yongpeng Chen,Zhipeng Yang,Jianjun Zhang*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper investigates the existence of normalized solutions to the
nonlinear fractional Choquard equation: $$ (-\Delta)^s u+V(x) u=\lambda
u+f(x)\left(I_\alpha *\left(f|u|^q\right)\right)|u|^{q-2} u+g(x)\left(I_\alpha
*\left(g|u|^p\right)\right)|u|^{p-2} u, \quad x \in \mathbb{R}^N $$ subject to
the mass constraint $$ \int_{\mathbb{R}^N}|u|^2 d x=a>0, $$ where $N>2 s, s
\in(0,1), \alpha \in(0, N)$, and $\frac{N+\alpha}{N} \leq q<p \leq
\frac{N+\alpha+2 s}{N}$. Here, the parameter $\lambda \in \mathbb{R}$ appears
as an unknown Lagrange multiplier associated with the normalization condition.
By employing variational methods under appropriate assumptions on the
potentials $V(x), f(x)$, and $g(x)$, we establish several existence results for
normalized solutions.

</details>


### [17] [Quantitative homogenisation for differential equations with highly anisotropic partially degenerating coefficients](https://arxiv.org/abs/2507.23380)
*Shane Cooper,Ilia Kamotski*

Main category: math.AP

TL;DR: The paper studies a non-uniformly elliptic operator modeling anisotropic fibers in an isotropic medium, focusing on resolvent behavior as the periodicity parameter ε→0. It extends prior work by providing asymptotic resolvent descriptions and operator-type error estimates, addressing new challenges like directional ellipticity loss and a weaker spectral gap assumption.


<details>
  <summary>Details</summary>
Motivation: The research aims to understand the asymptotic behavior of resolvents for highly anisotropic composite media, addressing gaps in prior work and tackling new complexities like directional ellipticity loss.

Method: The approach builds on a general scheme from prior research but incorporates additional analysis for directional ellipticity loss and a weaker spectral gap assumption, including interfacial boundary layer analysis near fibers.

Result: The study achieves order-ε operator-type error estimates for the resolvent, overcoming challenges posed by directional ellipticity loss and the weaker spectral gap condition.

Conclusion: The work advances the understanding of resolvent behavior in anisotropic composite media, providing precise error estimates and addressing novel analytical challenges.

Abstract: We consider a non-uniformly elliptic second-order differential operator with
periodic coefficients that models composite media consisting of highly
anisotropic cylindrical fibres periodically distributed in an isotropic
background. The degree of anisotropy is related to the period of the
coefficients via a `critical' high-contrast scaling. In particular, ellipticity
is lost in certain directions as the period, $\epsilon$, tends to zero. Our
primary interest is in the asymptotic behaviour of the resolvent of this
operator in the limit of small $\epsilon$.
  Two-scale resolvent convergence results were established for such operators
in Cherednichenko, Smyshlyaev and Zhikov (Proceedings of The Royal Society of
Edinburgh:Seciton A Mathematics. 136(1), 87--114(2006)). In this work, we
provide an asymptotic description of the resolvent and establish operator-type
error estimates. Our approach adopts the general scheme of Cooper, Kamotski and
Smyshlyaev (preprint available at arXiv:2307.13151). However, we face new
challenges such as a directional dependence on the loss of ellipticity in
addition to a key `spectral gap' assumption of the above article only holding
in a weaker sense. This results in an additional `interfacial' boundary layer
analysis in the vicinity of each fibre to arrive at order-$\epsilon$
operator-type error estimates.

</details>


### [18] [Global well-posedness and scattering for the 2D modified Zakharov-Kuznetsov equation](https://arxiv.org/abs/2507.23397)
*Simão Correia,Shinya Kinoshita*

Main category: math.AP

TL;DR: The paper analyzes the Cauchy problem for the modified Zakharov-Kuznetsov equation in 2D, proving local and global well-posedness in a new function space, with sharp results.


<details>
  <summary>Details</summary>
Motivation: To study the dispersive effects and establish well-posedness for the modified Zakharov-Kuznetsov equation in a two-parameter space.

Method: Introduces a new function space $H^{s,a}(\mathbb{R}^2)$ and proves local well-posedness for $s+a\ge 1/4$, $0<a<1/4$, and global well-posedness for small data when $s=0, a=1/4$.

Result: Local well-posedness is achieved for $s+a\ge 1/4$, $0<a<1/4$, and global well-posedness with scattering for small data when $s=0, a=1/4$. Results are sharp.

Conclusion: The introduced function space and conditions provide sharp well-posedness results for the modified Zakharov-Kuznetsov equation.

Abstract: We consider the Cauchy problem associated with the modified
Zakharov-Kuznetsov equation over $\mathbb{R}^2$. Taking into consideration the
associated dispersive effects, we introduce, for $s,a\ge 0$, a two-parameter
space $H^{s,a}(\mathbb{R}^2)$, which scales as the classic $H^s$ spaces. In
this new class, we prove local well-posedness for $s+a\ge 1/4$, $0<a<1/4$, and
global well-posedness and scattering for small data in the case $s=0, \ a=1/4$.
These results are shown to be sharp in the sense of $C^3$-flows.

</details>


### [19] [$p(x)$-Stability of the Dirichlet problem for Poisson's equation with variable exponents](https://arxiv.org/abs/2507.23417)
*Behzad Djafari Rouhani,Osvaldo Mendez*

Main category: math.AP

TL;DR: The paper demonstrates convergence of solutions to Dirichlet problems for variable exponent $p(x)$-Laplacian as the exponent sequence uniformly approaches $p(x)$.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of solutions to Dirichlet problems when the exponent in the $p(x)$-Laplacian varies uniformly.

Method: Analyzes sequences of solutions for increasing and decreasing exponent sequences converging to $p(x)$.

Result: Solutions converge to the solution of the Dirichlet problem for the limiting exponent $p(x)$.

Conclusion: Uniform convergence of exponents ensures convergence of solutions, validating stability under such variations.

Abstract: It is shown that if the sequence $(p_j(x))$ increases uniformly to $p(x)$ in
a bounded, smooth domain $\Omega$, then the sequence $(u_i)$ of solutions to
the Dirichlet problem for the $p_i(x)$-Laplacian with fixed boundary datum
$\varphi$ converges (in a sense to be made precise) to the solution $u_p$ of
the Dirichlet problem for the $p(x)$-Laplacian with boundary datum $\varphi$. A
similar result is proved for a decreasing sequence $p_j\searrow p$

</details>


### [20] [Heat content asymptotics for sets with positive reach](https://arxiv.org/abs/2507.23427)
*Paolo De Fazio,Michele Miranda Jr*

Main category: math.AP

TL;DR: The paper studies the heat content of sets with positive reach in Euclidean space, focusing on short-time asymptotics of the heat content for such sets.


<details>
  <summary>Details</summary>
Motivation: To extend the understanding of heat content beyond smooth boundaries to non-smooth and singular sets with positive reach, leveraging Federer's concept.

Method: Analyzes the short-time asymptotics of the heat content for bounded subsets with positive reach, using techniques distinct from prior work.

Result: Provides a slightly different result compared to previous studies, demonstrating the behavior of heat content for these sets.

Conclusion: The work contributes to the broader study of heat content in non-smooth geometries, offering new insights and techniques.

Abstract: In this paper we study the heat content for sets with positive reach. In
details, we investigate the asymptotic behavior of the heat content of bounded
subsets of the Euclidean space with positive reach. The concept of positive
reach was introduced by Federer in \cite{fed_1959} and widely developed in the
following years (see for instance the recent book by Rataj and Zh{\"a}le
\cite{rat_zah_2019}). It extends the class of sets with smooth boundaries to
include certain non-smooth and singular sets while still admitting a
well-defined normal geometry. For such sets $E\subseteq\Rn$, we analyze the
short-time asymptotics of the heat content $\|T_t\mathbbm{1}_E\|_2$, where
$T_t\mathbbm{1}_E$ is the soluzion of the heat equation in $\Rn$ with initial
condition $\mathbbm{1}_E$. The present paper is in the spirit of Angiuli,
Massari and Miranda Jr.\cite{ang_mas_mir_2013}, but the technique's used here
are completely different and also the final result is slightly different.

</details>


### [21] [Improvement of the Parabolic Regularization Method and Applications to Dispersive Models](https://arxiv.org/abs/2507.23530)
*Alysson Cunha*

Main category: math.AP

TL;DR: The paper proves global well-posedness of the Benjamin-Ono equation in $H^s(\mathbb{R})$ for $s > 1/2$ using a modified parabolic regularization method, extending results to the DGBO equation.


<details>
  <summary>Details</summary>
Motivation: To establish global well-posedness for the Benjamin-Ono equation without relying on Tao's global gauge transformation, and to extend this to the DGBO equation.

Method: A modified version of the standard parabolic regularization method is employed.

Result: Global well-posedness is proven for both the Benjamin-Ono and DGBO equations in $H^s(\mathbb{R})$ for $s > 1/2$.

Conclusion: The modified parabolic regularization method successfully avoids Tao's approach and extends results to the DGBO equation.

Abstract: We prove that the Benjamin Ono equation is globally well-posed in
$H^s(\mathbb{R})$ for $s > 1/2$. Our approach does not rely on the global gauge
transformation introduced by Tao (arXiv:math/0307289). Instead, we employ a
modified version of the standard parabolic regularization method. In
particular, this technique also enables us to establish global well-posedness,
in the same Sobolev space, for the dispersion-generalized Benjamin Ono (DGBO)
equation.

</details>


### [22] [Transverse asymptotic stability of line solitary waves for the Ionic Euler-Poisson system](https://arxiv.org/abs/2507.23572)
*Frédéric Rousset,Changzhen Sun*

Main category: math.AP

TL;DR: The paper proves the stability of small amplitude solitary waves in a 3D Euler-Poisson system under small perturbations, showing global smooth solutions and their asymptotic behavior.


<details>
  <summary>Details</summary>
Motivation: To understand the stability and dynamics of solitary waves in the Euler-Poisson system, which models ion dynamics.

Method: Analyzes linear and nonlinear asymptotic stability of small amplitude solitary waves under localized irrotational perturbations.

Result: Demonstrates the existence of global smooth solutions and describes their asymptotic behavior in the given regime.

Conclusion: Small amplitude solitary waves in the 3D Euler-Poisson system are stable under small perturbations, with well-defined asymptotic behavior.

Abstract: We prove the linear and nonlinear asymptotic stability of small amplitude
one-dimensional solitary waves submitted to small localized irrotational
perturbations in the three dimensional Euler-Poisson system describing the
dynamics of ions. In particular, in this regime, we obtain the existence of
global smooth solutions and describe their asymptotic behavior.

</details>


### [23] [On blow-up trees for the harmonic map heat flow from $B^2$ to $S^2$](https://arxiv.org/abs/2507.23583)
*Dylan Samuelian*

Main category: math.AP

TL;DR: The paper analyzes finite-time and $k$-equivariant solutions to the harmonic map heat flow from $B^2$ to $S^2$, proving single-bubble decomposition and infinite-time blow-up solutions for $k \geq 1$.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of solutions to the harmonic map heat flow under time-dependent boundary conditions, particularly focusing on bubble tree decomposition and blow-up phenomena.

Method: Utilizes the Maximum and Comparison Principle to analyze the solutions and their decomposition.

Result: Proves that the bubble tree decomposition contains only one bubble and demonstrates infinite-time blow-up solutions for any $k \geq 1$.

Conclusion: The study provides insights into the structure of solutions to the harmonic map heat flow, highlighting single-bubble decomposition and infinite-time blow-up behavior.

Abstract: We consider finite-time and $k$-equivariant solutions to the harmonic map
heat flow from $B^2$ to $S^2$ under general time-dependent boundary data and
prove that the bubble tree decomposition contains only one bubble. The method
relies on the Maximum and Comparison Principle. We also exhibit solutions
blowing up in infinite time for any $k \geq 1$.

</details>


### [24] [Elliptic unique continuation below the Lipschitz threshold](https://arxiv.org/abs/2507.23614)
*Cole Jeznach*

Main category: math.AP

TL;DR: The paper explores unique continuation principles for elliptic equations with less regular coefficients, showing log-Lipschitz conditions are sharp for general matrices and Holder continuity suffices for isotropic cases.


<details>
  <summary>Details</summary>
Motivation: To determine the minimal regularity conditions on coefficients ensuring unique continuation for solutions of elliptic equations, addressing gaps in prior work.

Method: Analyzes uniformly elliptic equations with coefficients of varying regularity, using Osgood conditions for general matrices and Holder continuity for isotropic cases.

Result: Log-Lipschitz is sharp for general matrices; Holder continuity (order α ∈ (2/3,1)) suffices for isotropic equations, disproving a 1974 conjecture.

Conclusion: The study clarifies minimal regularity requirements for unique continuation, resolving conjectures and contrasting anisotropic behavior.

Abstract: In this article, we investigate unique continuation principles for solutions
$u$ of uniformly elliptic equations of the form $-\mathrm{div}(A \nabla u) = 0$
when $A$ is less regular than Lipschitz. For general matrices $A$, we prove
that strong unique continuation holds provided that $A$ has modulus of
continuity $\omega$ satisfying the Osgood condition $\int_0^1 \omega(t)^{-1}dt
= \infty$, plus some other mild hypotheses. Along with the counterexamples of
Mandache, this shows that the sharp condition on $A$ that guarantees unique
continuation is essentially that $A$ is log-Lipschitz. In the class of
isotropic equations (i.e., $A(x) = a(x)I$ for some scalar function $a$) we show
that Holder continuity of $a$ of the order $\alpha \in (2/3,1)$ is sufficient
to guarantee strong unique continuation. This latter result contrasts
counterexamples known for anisotropic equations, and disproves a conjecture of
Miller from 1974.

</details>


### [25] [Normalized solutions for the NLS equation with potential in higher dimension: the purely Sobolev critical case](https://arxiv.org/abs/2507.23639)
*Juntao Sun,Shuai Yao,He Zhang*

Main category: math.AP

TL;DR: The paper addresses normalized solutions for the NLS equation with potential and Sobolev critical nonlinearity, solving an open problem and improving prior results.


<details>
  <summary>Details</summary>
Motivation: To solve an open problem in recent literature regarding normalized solutions for the NLS equation with potential and Sobolev critical nonlinearity.

Method: Establishes suitable assumptions on the potential and employs new techniques to find mountain-pass type solutions for N>=6 and local minimizers with negative energy for N>=3.

Result: A mountain-pass type solution for N>=6 and a local minimizer with negative energy for N>=3, improving previous findings.

Conclusion: The study successfully resolves the open problem and enhances understanding of normalized solutions for the NLS equation under the given conditions.

Abstract: We study normalized solutions for the nonlinear Schrodinger (NLS) equation
with potential and Sobolev critical nonlinearity. By establishing suitable
assumptions on the potential, together with new techniques, we find a
mountain-pass type solution for N>=6, which solves an open problem presented in
a recent paper [Verzini and Yu, arXiv:2505.05357v1]. Moreover, we also find a
local minimizer with negative energy for N>=3, which improves the results in
[Verzini and Yu, arXiv:2505.05357v1].

</details>


### [26] [Infinite BV, large $L^\infty$ solutions of conservation laws are Hölder-stable in $L^2$ in the class of front tracking limits](https://arxiv.org/abs/2507.23645)
*Geng Chen,Cooper Faile,Sam G. Krupa*

Main category: math.AP

TL;DR: The paper establishes a Hölder-type stability estimate in $L^2$ for hyperbolic systems of conservation laws, independent of the BV norm of the solution.


<details>
  <summary>Details</summary>
Motivation: To provide stability estimates for weak solutions without BV assumptions, applicable to physical systems like isentropic Euler.

Method: Uses the $L^2$ theory of shock stability with an artificial shift, extending to limits of front tracking solutions with BV bounds.

Result: Proves a universal stability estimate for general weak solutions, even with large $L^\infty$ and infinite BV data.

Conclusion: The framework enables uniqueness results for solutions with large initial data, demonstrated for isothermal Euler.

Abstract: We consider hyperbolic systems of conservation laws in one spatial dimension.
For any limit of front tracking solutions $v$, and for a general weak solution
$u\in L^\infty$ with no BV assumption, we prove the following H\"older-type
stability estimate in $L^2$:
  $$||u(\cdot,\tau)-v(\cdot,\tau)||_{L^2} \leq K \sqrt{||u( \cdot,0)-v(
\cdot,0)||_{L^2}}$$
  for all $\tau$ without smallness and for a universal constant $K$. Our result
holds for all limits of front tracking solutions $v$ with BV bound, either for
general systems with small-BV data, or for special systems (isothermal Euler,
Temple-class systems) with large-BV data. Our results apply to physical systems
such as isentropic Euler. The stability estimate is completely independent of
the BV norm of the potentially very wild solution $u$. We use the $L^2$ theory
of shock stability modulo an artificial shift of position (Vasseur [Handbook of
Differential Equations: Evolutionary Equations, 4:323 -- 376, 2008]) but our
stability results do not depend on an unknown shift. Moreover, we give the
first result within this framework which can show uniqueness of some solutions
with large $L^\infty$ and infinite BV initial data. We apply these techniques
to isothermal Euler.

</details>


### [27] [Analysis of a Cross-Nonlinear Porous-Medium System Modeling Pressure-Driven Cell Population Dynamics](https://arxiv.org/abs/2507.23680)
*Alexis Béjar-López,Rafael Granero-Belinchón,Carlos Pulido,Juan Soler*

Main category: math.AP

TL;DR: A cross-diffusion model explores how internal pressure affects growth and motility by coupling population density and occupied area, incorporating nonlinear interactions and novel terms.


<details>
  <summary>Details</summary>
Motivation: To understand the feedback between density fluctuations and tissue dynamics, extending Shraiman's area-growth paradigm.

Method: Blends nonlinear nonlocal interactions, porous-medium diffusion, and an antidiffusive pressure term, with density-dependent spreading and cross-diffusion.

Result: Proves local well-posedness, nonnegativity, and uniqueness under certain conditions; identifies finite-time blow-up and invariant spatial support.

Conclusion: Provides insights into pattern formation and mass transport in biological tissues.

Abstract: In this work, we introduce a cross-diffusion model that couples population
density and occupied area to investigate how internal pressure drives growth
and motility. By blending nonlinear nonlocal interactions with porous-medium
diffusion and an antidiffusive pressure term, the model captures the two-way
feedback between local density fluctuations and tissue expansion or
contraction. Building on Shraiman's area-growth paradigm, we enrich the
framework with density-dependent spreading at the population boundary and a
novel cross-diffusion term, yielding fully nonlinear transport in both
equations. We prove local well-posedness for nonnegative solutions in Sobolev
spaces and, under higher regularity, show both density and area remain
nonnegative. Uniqueness follows when the initial density's square root lies in
$H^2$, even if density vanishes on parts of the domain. We also exhibit initial
data that induce finite-time blow-up, highlighting potential singularity
formation. Finally, we establish that the density's spatial support remains
invariant and characterize the co-evolution of occupied area and population
density domains, offering new insights into pattern formation and mass
transport in biological tissues.

</details>


### [28] [Approximation of time-periodic flow past a translating body by flows in bounded domains](https://arxiv.org/abs/2507.23697)
*Thomas Eiter,Ana Leonor Silvestre*

Main category: math.AP

TL;DR: Existence and uniqueness of strong solutions for 3D Navier-Stokes flow past a translating body, with pointwise estimates. Truncated domain approximations with error bounds as truncation radius grows.


<details>
  <summary>Details</summary>
Motivation: To analyze time-periodic incompressible Navier-Stokes flow around a moving body, ensuring accurate solutions in exterior domains and their approximations in bounded domains.

Method: Uses fundamental solutions of time-periodic Oseen equations for pointwise estimates. Approximates exterior flow in truncated domains with artificial boundary conditions, proving existence and uniqueness of weak solutions.

Result: Strong solutions exist and are unique in exterior domains. Truncated domain solutions converge to exterior flow velocity as truncation radius increases.

Conclusion: The study provides rigorous solutions and approximations for time-periodic Navier-Stokes flows, with convergence guarantees for truncated domains.

Abstract: We consider a time-periodic incompressible three-dimensional Navier-Stokes
flow past a translating rigid body. In the first part of the paper, we
establish the existence and uniqueness of strong solutions in the exterior
domain $\Omega \subset {\mathbb R}^3$ that satisfy pointwise estimates for both
the velocity and pressure. The fundamental solution of the time-periodic Oseen
equations plays a central role in obtaining these estimates. The second part
focuses on approximating this exterior flow within truncated domains $\Omega
\cap B_R$, incorporating appropriate artificial boundary conditions on
$\partial B_R$. For these bounded domain problems, we prove the existence and
uniqueness of weak solutions. Finally, we estimate the error in the velocity
component as a function of the truncation radius $R$, showing that, as $R \to
\infty$, the velocities of the truncated problems converge, in an appropriate
norm, to the velocity of the exterior flow.

</details>


### [29] [Nonlinear Vibrational Mode of Molecule with Octahedral Configuration](https://arxiv.org/abs/2507.23720)
*Jingzhou Liu*

Main category: math.AP

TL;DR: Study of nonlinear dynamics in octahedral molecules (SF6) using equivariant gradient degree, revealing 16 distinct periodic solution branches with unique symmetries.


<details>
  <summary>Details</summary>
Motivation: To explore the nonlinear dynamics and vibrational modes of octahedral molecules like SF6, focusing on symmetry and periodic solutions.

Method: Applied the method of equivariant gradient degree under isotypic nonresonance assumptions to analyze periodic solutions.

Result: Identified 16 distinct types of symmetries with maximal orbit kinds, supported by numerical animations of vibrational modes.

Conclusion: The study successfully demonstrates the existence of diverse periodic solutions in SF6, highlighting the role of symmetry in nonlinear dynamics.

Abstract: In this work, we investigate the nonlinear dynamics of molecules with an
octahedral configuration, with particular focus on sulfur hexafluoride SF6.
Under the assumption of isotypic nonresonance, we apply the method of
equivariant gradient degree to prove the existence of branches of periodic
solutions emerging from the critical orbit of equilibrium, corresponding to at
least 16 distinct types of symmetries with maximal orbit kinds. Numerical
animations are presented to illustrate the detected vibrational modes.

</details>


### [30] [Renormalisation of singular SPDEs with Correlated Coefficients](https://arxiv.org/abs/2507.23737)
*Nicolas Clozeau,Harprit Singh*

Main category: math.AP

TL;DR: Local well-posedness of g-PAM and ϕ²ₖ₊₁ equations on a 2D torus with random correlated coefficients is proven, avoiding variance blow-up via random renormalization.


<details>
  <summary>Details</summary>
Motivation: Address challenges in renormalization for stochastic PDEs with correlated noise and coefficients, preventing variance blow-up.

Method: Use random renormalization functions, combining heat kernel asymptotics, Gaussian integration by parts, and Hairer-Quastel bounds.

Result: Convergence of renormalized models is achieved, ensuring local well-posedness.

Conclusion: Random renormalization effectively handles correlated settings, advancing stochastic PDE theory.

Abstract: We show local well-posedness of the g-PAM and the $\phi^{K+1}_2$-equation for
$K\geq 1$ on the two-dimensional torus when the coefficient field is random and
correlated to the driving noise. In the setting considered here, even when the
model in the sense of [Hai14] is stationary, naive use of renormalisation
constants in general leads to variance blow-up. Instead, we prove convergence
of renormalised models choosing random renormalisation functions analogous to
the deterministic variable coefficient setting. The main technical contribution
are stochastic estimates on the model in this correlated setting which are
obtained by a combination of heat kernel asymptotics, Gaussian integration by
parts formulae and Hairer--Quastel type bounds [HQ18].

</details>


### [31] [Hölder continuous dissipative solutions of ideal MHD with nonzero helicity](https://arxiv.org/abs/2507.23749)
*Alberto Enciso,Javier Peñafiel-Tomás,Daniel Peralta-Salas*

Main category: math.AP

TL;DR: Existence of weak solutions to 3D ideal MHD equations with non-conserved energy and cross helicity, but preserved magnetic helicity, using a novel convex integration scheme.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that weak solutions can exist without conserving total energy or cross helicity, while preserving magnetic helicity, challenging symmetry-based assumptions.

Method: A novel convex integration scheme ensuring magnetic helicity preservation at each step, applicable on torus and Euclidean space.

Result: Construction of $C^\alpha$ solutions ($\alpha=10^{-8}$) with non-conserved energy and cross helicity but nonzero conserved magnetic helicity.

Conclusion: First example of continuous weak solutions where one conservation law is preserved while another is not, without relying on symmetry.

Abstract: We prove the existence of weak solutions to the 3D ideal MHD equations, of
class $C^\alpha$ with $\alpha=10^{-8}$, for which the total energy and the
cross helicity (i.e., the so-called Els\"asser energies) are not conserved. The
solutions do not possess any symmetry properties and the magnetic helicity,
which is necessarily conserved for H\"older continuous solutions, is nonzero.
The construction, which works both on the torus $\mathbb{T}^3$ and on
$\mathbb{R}^3$ with compact spatial support, is based on a novel convex
integration scheme in which the magnetic helicity is preserved at each step.
This is the first construction of continuous weak solutions at a regularity
level where one conservation law (here, the magnetic helicity) is necessarily
preserved while another (here, the total energy or cross helicity) is not, and
where the preservation of the former is nontrivial in the sense that it does
not follow from symmetry considerations.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [32] [Real-space Hubbard-corrected density functional theory](https://arxiv.org/abs/2507.23612)
*Sayan Bhowmik,Andrew J. Medford,Phanish Suryanarayana*

Main category: physics.comp-ph

TL;DR: A framework for real-space Hubbard-corrected DFT is presented, offering accurate energy, forces, and stress tensor calculations. It outperforms planewave methods in efficiency and scalability, with applications in TiO2 polymorphs.


<details>
  <summary>Details</summary>
Motivation: To improve the accuracy and efficiency of Hubbard-corrected DFT calculations in real-space, addressing limitations of planewave methods.

Method: Develops expressions for energy, forces, and stress tensor in real-space finite-difference discretization, with a parallel implementation.

Result: The framework is highly efficient and scalable, outperforming planewave codes significantly, especially for larger systems or more processors.

Conclusion: The method successfully addresses exchange-correlation inconsistency and optimizes Hubbard parameters, demonstrated with TiO2 polymorphs.

Abstract: We present an accurate and efficient framework for real-space
Hubbard-corrected density functional theory. In particular, we obtain
expressions for the energy, atomic forces, and stress tensor suitable for
real-space finite-difference discretization, and develop a large-scale parallel
implementation. We verify the accuracy of the formalism through comparisons
with established planewave results. We demonstrate that the implementation is
highly efficient and scalable, outperforming established planewave codes by
more than an order of magnitude in minimum time to solution, with increasing
advantages as the system size and/or number of processors is increased. We
apply this framework to examine the impact of exchange-correlation
inconsistency in local atomic orbital generation and introduce a scheme for
optimizing the Hubbard parameter based on hybrid functionals, both while
studying TiO$_2$ polymorphs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [33] [AI paradigm for solving differential equations: first-principles data generation and scale-dilation operator AI solver](https://arxiv.org/abs/2507.23141)
*Xiangshu Gong,Zhiqiang Xie,Xiaowei Jin,Chen Wang,Yanling Qu,Wangmeng Zuo,Hui Li*

Main category: cs.LG

TL;DR: Proposes an AI paradigm for solving differential equations (DEs) with a novel data generation method and a scale-dilation operator (SDO) AI solver, addressing high-frequency component approximation challenges.


<details>
  <summary>Details</summary>
Motivation: Existing AI solvers struggle with high-frequency component approximation and data scarcity in solving DEs.

Method: Uses DE-ruled first-principles data generation and a reversible SDO AI solver with Fourier transforms and attention-based Transformer architecture.

Result: Achieves superior accuracy over state-of-the-art methods, with a smoother loss landscape and efficient training.

Conclusion: The AI paradigm makes DE solvers practical for broad applications in nature and engineering.

Abstract: Many problems are governed by differential equations (DEs). Artificial
intelligence (AI) is a new path for solving DEs. However, data is very scarce
and existing AI solvers struggle with approximation of high frequency
components (AHFC). We propose an AI paradigm for solving diverse DEs, including
DE-ruled first-principles data generation methodology and scale-dilation
operator (SDO) AI solver. Using either prior knowledge or random fields, we
generate solutions and then substitute them into the DEs to derive the sources
and initial/boundary conditions through balancing DEs, thus producing
arbitrarily vast amount of, first-principles-consistent training datasets at
extremely low computational cost. We introduce a reversible SDO that leverages
the Fourier transform of the multiscale solutions to fix AHFC, and design a
spatiotemporally coupled, attention-based Transformer AI solver of DEs with
SDO. An upper bound on the Hessian condition number of the loss function is
proven to be proportional to the squared 2-norm of the solution gradient,
revealing that SDO yields a smoother loss landscape, consequently fixing AHFC
with efficient training. Extensive tests on diverse DEs demonstrate that our AI
paradigm achieves consistently superior accuracy over state-of-the-art methods.
This work makes AI solver of DEs to be truly usable in broad nature and
engineering fields.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [34] [Physics-Informed PointNets for Modeling Electromagnetic Scattering from All-Dielectric Metasurfaces with Inclined Nanopillars](https://arxiv.org/abs/2507.23119)
*Leon Armbruster,Vlad Medvedev,Andreas Rosskopf*

Main category: physics.optics

TL;DR: A mesh-free Physics-Informed PointNet (PIPN) is introduced to model electromagnetic scattering in all-dielectric metasurfaces with irregular geometries, offering accurate and efficient computational modeling.


<details>
  <summary>Details</summary>
Motivation: Conventional solvers struggle with accurate and efficient modeling of metasurfaces, especially those with irregular geometries, necessitating a new approach.

Method: The PIPN method integrates the PointNet architecture into a Physics-Informed Machine Learning (PIML) framework to encode spatially varying material properties.

Result: PIPN demonstrates generalization capability across datasets with varying refractive indices and inclination angles, simulating manufacturing defects.

Conclusion: PIPN provides a promising mesh-free framework for modeling complex optical structures efficiently and accurately.

Abstract: Metasurfaces are innovative planar optical structures capable of manipulating
incident light properties. Accurate and computationally efficient modeling of
such metasurfaces, particularly those with irregular geometries, remains a
challenge for conventional solvers. In this work, we present a mesh-free
Physics-Informed PointNet (PIPN) to model electromagnetic scattering from
all-dielectric metasurfaces that feature spatially varying nanopillars. Our
approach uses the PointNet architecture to directly encode spatially varying
material properties into the Physics-Informed Machine Learning (PIML)
framework. We demonstrate the generalization capability of our PIPN through
evaluations on datasets; these datasets are generated with varying refractive
indices representing common dielectric materials. Furthermore, the inclination
angles are varied within each dataset, which represent expected manufacturing
defects. Overall, our method provides a promising, mesh-free framework for
accurate and efficient modeling of complex optical structures represented by
irregular geometries.

</details>


### [35] [Conical diffraction of the synchrotron beam to probe the efficiency and morphology of blazed gratings](https://arxiv.org/abs/2507.23513)
*K. V. Nikolaev,L. I. Goray,P. S. Savchenkov,A. V. Rogachev,A. A. Chouprik,T. N. Berezovskaya,D. V. Mokhov,S. A. Garakhin,N. I. Chkhalo,A. D. Buravleuv,S. N. Yakunin*

Main category: physics.optics

TL;DR: The study demonstrates synchrotron measurements as a nanometrology tool for analyzing blazed gratings, revealing sensitivity to groove profiles and surface roughness.


<details>
  <summary>Details</summary>
Motivation: To highlight synchrotron measurements as a valuable tool for nanometrology in modern optical elements.

Method: Combined grazing incidence geometry for simultaneous measurement of conical diffraction and diffuse scattering, supported by numerical simulations and additional microscopy data.

Result: Diffraction patterns are sensitive to groove profiles, while diffuse scattering reflects surface roughness morphology.

Conclusion: Synchrotron measurements are effective for nanometrology of blazed gratings, offering insights into structural and surface properties.

Abstract: This study explores the use of synchrotron measurements as a nanometrology
tool for blazed gratings. In grazing incidence geometry, one can measure both
the conical diffraction and the diffuse scattering on the grating
simultaneously in a single scattering pattern. The sensitivity of scattering
patterns to the structure of the blazed gratings is evaluated. The diffraction
component of the pattern is shown to be sensitive to the average groove profile
of the gratings. Meanwhile, the diffuse scattering depends on the roughness
morphology of the reflective surface of blazed gratings. These findings are
supported by numerical simulations. The simulations were performed using
several rigorous solvers for the Helmholtz equations, and with a perturbation
theory. The analysis relies on synchrotron data, as well as data from atomic
force microscopy and scanning electron microscopy. The aim of this article is
to draw the attention of the optical community to the synchrotron measurements
as a nanometrology tool for the modern optical elements.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [36] [Deriving effective electrode-ion interactions from free-energy profiles at electrochemical interfaces](https://arxiv.org/abs/2507.23031)
*Fabrice Roncoroni,Abrar Faiyad,Yichen Li,Tao Ye,Ashlie Martini,David Prendergast*

Main category: physics.chem-ph

TL;DR: The paper investigates ion adsorption at electrified interfaces using molecular dynamics and machine-learned potentials, highlighting the impact of force field parameters and validating results with experiments.


<details>
  <summary>Details</summary>
Motivation: Accurate modeling of electrochemical systems requires understanding ion adsorption at electrified metal-electrolyte interfaces.

Method: Enhanced sampling molecular dynamics with classical force fields and machine-learned interatomic potentials (MLIPs) were used to study free energy profiles of ions at the Au(111)-water interface.

Result: Classical metadynamics showed parameter dependence, while MLIPs validated trends: strong chloride adsorption, weak fluoride adsorption, and no sodium adsorption. Integration into continuum models revealed significant impacts on interfacial properties.

Conclusion: Force field parameterization and advanced potentials are crucial for predictive modeling of ion-specific effects, bridging molecular simulations and continuum electrochemical models.

Abstract: Understanding ion adsorption at electrified metal-electrolyte interfaces is
essential for accurate modeling of electrochemical systems. Here, we
systematically investigate the free energy profiles of Na$^+$, Cl$^-$, and
F$^-$ ions at the Au(111)-water interface using enhanced sampling molecular
dynamics with both classical force fields and machine-learned interatomic
potentials (MLIPs). Our classical metadynamics results reveal a strong
dependence of predicted ion adsorption on the Lennard-Jones parameters,
highlighting that --without due care-- standard mixing rules can lead to
qualitatively incorrect descriptions of ion-metal interactions. We present a
systematic methodology for tuning the cross-term LJ parameters to control
adsorption energetics in agreement with more accurate models. As a surrogate
for an ab initio model, we employed the recently released Universal Models for
Atoms (UMA) MLIP, which validates classical trends and displays strong specific
adsorption for chloride, weak adsorption for fluoride, and no specific
adsorption for sodium, in agreement with experimental and theoretical
expectations. By integrating molecular-level adsorption free energies into
continuum models of the electric double layer, we show that specific ion
adsorption substantially alters the interfacial ion population, the potential
of zero charge, and the differential capacitance of the system. Our results
underscore the critical importance of force field parameterization and advanced
interatomic potentials for the predictive modeling of ion-specific effects at
electrified interfaces and provide a robust framework for bridging molecular
simulations and continuum electrochemical models.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [37] [Extensional rheology of dilute suspensions of spheres in polymeric liquids](https://arxiv.org/abs/2507.23114)
*Arjun Sharma,Donald L. Koch*

Main category: physics.flu-dyn

TL;DR: The study explores how dilute sphere suspensions in viscoelastic liquids affect extensional rheology, revealing that polymer concentration and Deborah number influence viscosity changes through polymer stretching and collapse.


<details>
  <summary>Details</summary>
Motivation: To understand how local flow and polymer interactions in suspensions alter extensional viscosity, especially at varying polymer concentrations and Deborah numbers.

Method: Computational analysis of dilute sphere suspensions in viscoelastic liquids, focusing on polymer stretching and collapse under different conditions.

Result: At low De (<0.5), stretched polymers increase viscosity; at high De (>0.5), collapsed polymers reduce it. Higher polymer concentration initially aligns local flow but later introduces a new mechanism reducing viscosity.

Conclusion: Dilute sphere suspensions can effectively reduce viscosity in viscoelastic liquids at high De and polymer concentration due to negative interaction stress scaling.

Abstract: The extensional rheology of dilute suspensions of spheres in viscoelastic or
polymeric liquids is studied computationally. At low polymer concentration (c)
and Deborah number (De), a wake of highly stretched polymers forms downstream
of the particles due to larger local velocity gradients than the imposed flow,
indicated by a positive deviation in local De. This increases the suspension's
extensional viscosity with time and De for De less than 0.5. When De exceeds
0.5 (the coil-stretch transition), the fully stretched polymers from the far
field collapse in regions with lower local velocity gradients around the
particle's stagnation points, reducing suspension viscosity relative to the
polymer-only liquid. The interaction between local flow and polymers
intensifies with increasing c. Highly stretched polymers impede local flow,
reducing local De, while it increases in regions with collapsed polymers.
Initially, increasing c aligns local De and polymer stretch with far-field
values, diminishing particle-polymer interaction effects. However, beyond a
certain c, a new mechanism emerges. At low c, fluid three particle radii
upstream exhibits increased local De, stretching polymers beyond their
undisturbed state. As c increases, this deviation becomes negative, collapsing
polymers and resulting in increasingly negative stress from particle-polymer
interactions at large De and time. At high c, this negative interaction stress
scales as c squared, surpassing the linear increase in polymer stress, making
dilute sphere suspensions more effective at reducing the viscosity of
viscoelastic liquids at larger De and c.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [38] [Matching Large Deviation Bounds of the Zero-Range Process in the whole space](https://arxiv.org/abs/2507.23452)
*Benjamin Fehrman,Benjamin Gess,Daniel Heydecker*

Main category: math.PR

TL;DR: The paper resolves the large deviations problem for the hydrodynamic rescaling of the zero-range process in any dimension, extending prior work and removing restrictive assumptions.


<details>
  <summary>Details</summary>
Motivation: The study aims to address the unresolved problem of large deviations for the zero-range process's hydrodynamic rescaling, initially posed by KL99, and to generalize existing results to higher dimensions.

Method: The authors extend superexponential estimates to any dimension, prove concentration on paths with finite entropy dissipation, and generalize the theory of the parabolic-hyperbolic skeleton equation without global convexity/concavity assumptions.

Result: Matching upper and lower bounds for large deviations are obtained, resolving the problem and extending prior results.

Conclusion: The work successfully generalizes and resolves key issues in the large deviations theory for the zero-range process, removing previous limitations and assumptions.

Abstract: We consider the large deviations of the hydrodynamic rescaling of the
zero-range process on $\mathbb{Z}^d$ in any dimension $d\ge 1$. Under mild and
canonical hypotheses on the local jump rate, we obtain matching upper and lower
bounds, thus resolving the problem opened by \cite{KL99}. On the probabilistic
side, we extend the superexponential estimate to any dimension, and prove the
superexponential concentration on paths with finite entropy dissipation. In
addition, we extend the theory of the parabolic-hyperbolic skeleton equation to
the whole space, and remove global convexity/concavity assumptions on the
nonlinearity.

</details>


<div id='cond-mat.supr-con'></div>

# cond-mat.supr-con [[Back]](#toc)

### [39] [AC/DC spin current in ferromagnet/superconductor/normal metal trilayer systems](https://arxiv.org/abs/2507.23262)
*Koki Mizuno,Hirone Ishida,Manato Teranishi*

Main category: cond-mat.supr-con

TL;DR: Study investigates spin pumping in a trilayer system (FMI/SC/NM), deriving AC and DC spin currents under microwave irradiation. Classical and quantum treatments yield AC and DC currents, respectively. QTCI method reduces computational cost. Results show coherence peaks in temperature dependence and a transition in SC layer thickness dependence.


<details>
  <summary>Details</summary>
Motivation: To explore spin pumping in a trilayer system (FMI/SC/NM) and understand the induced spin currents under microwave irradiation, addressing computational challenges with QTCI.

Method: Derive AC and DC spin currents using classical and quantum treatments of spin motion. Apply QTCI to mitigate high computational costs. Analyze temperature, frequency, and SC thickness dependencies.

Result: AC and DC spin currents exhibit coherence peaks in temperature dependence. A transition structure appears in SC thickness dependence at a specific frequency.

Conclusion: The study provides insights into spin pumping in trilayer systems, revealing unique dependencies and demonstrating the utility of QTCI for computational efficiency.

Abstract: Spin pumping with superconductors has been extensively studied, particularly
in double-layer systems. In this study, we investigate spin pumping in a
trilayer system comprising a ferromagnetic insulator (FMI), a superconductor
(SC), and a normal metal (NM). We derive the AC and DC spin currents in the NM
layer induced by spin motion in the FMI under circularly polarized microwave
irradiation. If we treat the spin motion as classical, the AC spin current is
expressed. On the other hand, if we treat the spin motion as quantum
quasiparticles, the DC spin current is derived. After these derivations, while
the computational cost of evaluating the spin current is extremely high, we
mitigate this using the Quantics Tensor Cross Interpolation (QTCI) method. We
present numerical results showing the dependence of the spin current on
temperature, microwave frequency, and superconductor layer thickness. Notably,
the temperature dependence of AC and DC spin currents exhibits a coherence
peak. Furthermore, we have discovered a transition structure in the dependence
of the spin current on the thickness of the superconductor layer, where the
dependence changes after a particular frequency.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [40] [Existence of genus 2 minimal surfaces in 3-spheres. I](https://arxiv.org/abs/2507.23239)
*Adrian Chun-Pong Chu,Yangyang Li,Zhihan Wang*

Main category: math.DG

TL;DR: The paper proves the existence of embedded minimal surfaces of genus 2 in 3-spheres with positive Ricci curvature and generalizes this to relate minimal surfaces in 3-manifolds to topological properties.


<details>
  <summary>Details</summary>
Motivation: To explore the existence of minimal surfaces in 3-dimensional spaces with specific curvature conditions and generalize findings to broader topological contexts.

Method: Mathematical proof and theoretical analysis linking minimal surfaces to topological properties of 3-manifolds.

Result: Existence of genus 2 minimal surfaces in 3-spheres with positive Ricci curvature and a generalized theorem for 3-manifolds.

Conclusion: The study advances understanding of minimal surfaces in curved 3-dimensional spaces and their topological implications.

Abstract: We prove that every 3-sphere of positive Ricci curvature contains some
embedded minimal surface of genus 2.
  We also establish a theorem for more general 3-manifolds that relates the
existence of genus $g$ minimal surfaces to topological properties regarding the
set of all embedded singular surfaces of genus $\leq g$.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [41] [Derivations of two one-dimensional models for transversely curved shallow shells: one leads to relaxation](https://arxiv.org/abs/2507.23545)
*Paroni Roberto,Picchi Scardaoni Marco*

Main category: math-ph

TL;DR: The paper analyzes the Γ-limit of variational problems for shallow shells as their width approaches zero, identifying two distinct one-dimensional models based on the scaling of stretching energy.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of shallow shells under varying energy scaling regimes and boundary conditions as their width diminishes.

Method: The study uses von Kármán-type energy for shallow shells, focusing on the scaling of stretching energy (∼ε^(2β)) and derives one-dimensional models for β in (0, 2].

Result: For β ∈ (0, 2), the Γ-limit shows relaxation with vanishing membrane energy under compression. For β=2, a nonlinear energy model emerges, coupling four kinematical descriptors. Special cases include nonlinear Vlasov torsion and Euler-Bernoulli beam theories.

Conclusion: Boundary conditions are crucial for compactness, and the derived models provide insights into the behavior of shallow shells in different energy scaling regimes.

Abstract: We study the $\Gamma$-limit of sequences of variational problems for
straight, transversely curved shallow shells, as the width of the planform
$\varepsilon$ goes to zero.
  The energy is of von K\'arm\'an type for shallow shells under suitable
boundary conditions. What distinguishes the various regimes is the scaling of
the stretching energy $\sim \varepsilon^{2\beta}$, with $\beta$ a positive
number. We derive two one-dimensional models as $\beta$ ranges in $(0, 2]$.
Remarkably, boundary conditions are essential to get compactness.
  We show that for $\beta \in (0, 2)$ the $\Gamma$-limit leads to relaxation:
the limit membrane energy vanishes on compression. For $\beta=2$ there is no
relaxation, and the limit model is a nonlinear energy coupling four kinematical
descriptors in a nontrivial way.
  As special cases of the latter limit model, a nonlinear Vlasov torsion theory
and a nonlinear Euler-Bernoulli beam theory can be deduced.

</details>
