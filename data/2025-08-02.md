<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 13]
- [math.AP](#math.AP) [Total: 18]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [cond-mat.supr-con](#cond-mat.supr-con) [Total: 1]
- [math-ph](#math-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [physics.optics](#physics.optics) [Total: 2]
- [math.DG](#math.DG) [Total: 1]
- [math.PR](#math.PR) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Convergence analysis of a second-order SAV-ZEC scheme for the Cahn-Hilliard-Navier-Stokes system](https://arxiv.org/abs/2507.22949)
*Jingwei Sun,Zeyu Xia,Wei Zhang*

Main category: math.NA

TL;DR: A linear, fully decoupled numerical scheme for the CHNS system is proposed using SAV-ZEC reformulation, MAC finite difference, BDF2, and Adams-Bashforth, ensuring unconditional stability and optimal convergence rates.


<details>
  <summary>Details</summary>
Motivation: To develop a stable and efficient numerical method for the CHNS system by decoupling and simplifying the computational process.

Method: Combines SAV-ZEC reformulation, MAC finite difference, BDF2 temporal discretization, and Adams-Bashforth extrapolation, with a pressure correction approach for the Stokes equation.

Result: The scheme is unconditionally stable and achieves optimal convergence rates for phase and velocity variables in specified norms.

Conclusion: The proposed method effectively decouples and stabilizes the CHNS system, offering computational efficiency and accuracy.

Abstract: Incorporating the scalar auxiliary variable (SAV) method and the zero energy
contribution (ZEC) technique, we analyze a linear and fully decoupled numerical
scheme for the Cahn-Hilliard-Naiver-Stokes (CHNS) system. More precisely, the
fully discrete scheme combines the marker-and-cell (MAC) finite difference
spatial approximation and BDF2 temporal discretization, as well as the
Adams-Bashforth extrapolation for the nonlinear terms, based on the SAV-ZEC
reformulation. A pressure correction approach is applied to decouple the Stokes
equation. Only constant-coefficient Poisson-like solvers are needed in the
implementation for the resulting numerical system. The numerical scheme is
unconditionally stable with respect to a rewritten total energy functional,
represented in terms of one auxiliary variable in the double-well potential,
another auxiliary variable to balance all the nonlinear and coupled terms, the
surface energy in the original phase variable, combined with the kinematic
energy part. Specifically, the error estimate for the phase variable in the
$\ell^{\infty}(0,T;H_h^1)\cap\ell^2(0,T;H_h^3)$ norm, the velocity variable in
the $\ell^{\infty}(0,T;\ell^2)\cap\ell^2(0,T;H_h^1)$ norm, is derived with
optimal convergence rates.

</details>


### [2] [Hybrid Shifted Gegenbauer Integral-Pseudospectral Method for Solving Time-Fractional Benjamin-Bona-Mahony-Burgers Equation](https://arxiv.org/abs/2507.23099)
*Kareem T. Elgindy*

Main category: math.NA

TL;DR: A high-order hybrid method (HSG-IPS) is introduced for solving the FBBMB equation, combining advanced numerical techniques for spectral accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: To address numerical instability and inefficiency in solving the FBBMB equation by transforming it into a simpler form and leveraging high-accuracy quadrature rules.

Method: Transforms the FBBMB equation into a fractional partial-integro differential form, using shifted Gegenbauer polynomials and matrices for approximation and integration.

Result: Achieves lower errors (AAEs) and faster computational times (0.04-0.05s), with robustness across fractional orders.

Conclusion: The HSG-IPS method offers a stable, efficient framework for fractional calculus applications, outperforming existing approaches.

Abstract: This paper presents a high-order hybrid shifted Gegenbauer
integral-pseudospectral (HSG-IPS) method for solving the time-fractional
Benjamin-Bona-Mahony-Burgers (FBBMB) equation. A key innovation of our approach
is the transformation of the original equation into a fractional
partial-integro differential form that contains only a first-order derivative,
which can be accurately approximated using a first-order shifted Gegenbauer
differentiation matrix (SGDM), while all other terms in the transformed
equation are resolved using highly accurate quadrature rules. The method
combines several advanced numerical techniques including the shifted Gegenbauer
pseudospectral (SGPS) method, Gegenbauer-based fractional approximation (GBFA),
shifted Gegenbauer integration matrix (SGIM), shifted Gegenbauer integration
row vector (SGIRV), and SGDM to achieve spectral accuracy. Numerical
experiments demonstrate that the HSG-IPS method outperforms existing numerical
approaches, achieving significantly lower average absolute errors (AAEs) with
computational times as low as 0.04-0.05 seconds. The method's robustness is
validated across various fractional orders, showing excellent agreement with
analytical solutions. The transformation strategy effectively circumvents the
numerical instability associated with direct approximation of high-order
derivatives in the original equation, while the use of shifted Gegenbauer (SG)
polynomials and barycentric representations ensures numerical stability and
efficiency. This work provides a powerful computational framework for modeling
wave propagation, dispersion, and nonlinearity in fractional calculus
applications.

</details>


### [3] [$hp$-adaptive finite element simulation of a static anti-plane shear crack in a nonlinear strain-limiting elastic solid](https://arxiv.org/abs/2507.23195)
*S. M. Mallikarjunaiah,Pavithra Venkatachalapthy*

Main category: math.NA

TL;DR: An $hp$-adaptive finite element method is developed for analyzing static anti-plane shear cracks in nonlinear, strain-limiting elastic bodies, ensuring well-posedness and accuracy through adaptive refinement and error estimation.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of modeling cracks in nonlinear elastic materials with bounded, monotone, and coercive constitutive laws, ensuring accurate and efficient numerical solutions.

Method: An $hp$-adaptive continuous Galerkin finite element method with residual-based error indicators for mesh refinement ($h$-adaptivity) and local polynomial degree adjustment ($p$-adaptivity) based on solution regularity.

Result: The method demonstrates strong performance, accuracy, and convergence in numerical experiments, with crack-tip field analysis for various parameters.

Conclusion: The framework provides a robust foundation for extending to more complex problems like dynamic crack propagation in brittle materials.

Abstract: An $hp$-adaptive continuous Galerkin finite element method is developed to
analyze a static anti-plane shear crack embedded in a nonlinear,
strain-limiting elastic body. The geometrically linear material is described by
a constitutive law relating stress and strain that is algebraically nonlinear.
In this investigation, the constitutive relation utilized is \textit{uniformly
bounded}, \textit{monotone}, \textit{coercive}, and \textit{Lipschitz
continuous}, ensuring the well-posedness of the mathematical model. The
governing equation, derived from the balance of linear momentum coupled with
the nonlinear constitutive relationship, is formulated as a second-order
quasi-linear elliptic partial differential equation. For a body with an edge
crack, this governing equation is augmented with a classical traction-free
boundary condition on the crack faces. An $hp$-adaptive finite element scheme
is proposed for the numerical approximation of the resulting boundary value
problem. The adaptive strategy is driven by a dual-component error estimation
scheme: mesh refinement ($h$-adaptivity) is guided by a residual-based a
posteriori error indicator of the \textit{Kelly type}, while the local
polynomial degree ($p$-adaptivity) is adjusted based on an estimator of the
local solution regularity. The performance, accuracy, and convergence
characteristics of the proposed method are demonstrated through numerical
experiments. The structure of the regularized crack-tip fields is examined for
various modeling parameters. Furthermore, the presented framework establishes a
robust foundation for extension to more complex and computationally demanding
problems, including quasi-static and dynamic crack propagation in brittle
materials.

</details>


### [4] [Error analysis of the projected PO method with additive inflation for the partially observed Lorenz 96 model](https://arxiv.org/abs/2507.23199)
*Kota Takeda*

Main category: math.NA

TL;DR: The paper analyzes the error bound of the PO method, a variant of the EnKF, for the partially observed Lorenz 96 model, using additive inflation and covariance projection.


<details>
  <summary>Details</summary>
Motivation: To establish the error bound of the PO method for the EnKF in the partially observed Lorenz 96 model, which was previously unaddressed.

Method: The study introduces additive inflation and projects the background covariance to the observation space to derive the error bound.

Result: Theoretical error bounds are established and validated through a numerical example.

Conclusion: The findings validate the PO method's error bounds and suggest potential for extending the analysis.

Abstract: We consider the filtering problem with the partially observed Lorenz 96
model. Although the accuracy of the 3DVar filter applied to this problem has
been established, that of the EnKF has not yet been. This study aims to
establish the error bound of a variant of the EnKF, known as the PO method. By
introducing the additive inflation and a projection of the background
covariance to the observation space, we establish the error bound of the PO
method. A numerical example validates theoretical findings and shows the
potential to extend the analysis.

</details>


### [5] [Improved Analysis of Khatri-Rao Random Projections and Applications](https://arxiv.org/abs/2507.23207)
*Arvind K. Saibaba,Bhisham Dev Verma,Grey Ballard*

Main category: math.NA

TL;DR: The paper explores improved theoretical guarantees and practical algorithms for using Khatri-Rao random projections (KRPs) in matrix and tensor decompositions, showing computational benefits over standard Gaussian methods.


<details>
  <summary>Details</summary>
Motivation: Standard Gaussian random matrices are costly to generate and multiply, while KRPs are cheaper but have pessimistic theoretical guarantees. The paper aims to bridge this gap.

Method: Proposes new algorithms for low-rank approximations of block-structured matrices and tensor computations in the Tucker format using KRPs, with theoretical analysis.

Result: Improved theoretical guarantees for KRPs and numerical experiments demonstrate computational advantages over Gaussian methods.

Conclusion: KRPs offer a viable, efficient alternative to Gaussian random matrices for matrix and tensor decompositions, with validated practical benefits.

Abstract: Randomization has emerged as a powerful set of tools for large-scale matrix
and tensor decompositions. Randomized algorithms involve computing sketches
with random matrices. A prevalent approach is to take the random matrix as a
standard Gaussian random matrix, for which the theory is well developed.
However, this approach has the drawback that the cost of generating and
multiplying by the random matrix can be prohibitively expensive. Khatri-Rao
random projections (KRPs), obtained by sketching with Khatri-Rao products of
random matrices, offer a viable alternative and are much cheaper to generate.
However, the theoretical guarantees of using KRPs are much more pessimistic
compared to their accuracy observed in practice. We attempt to close this gap
by obtaining improved analysis of the use of KRPs in matrix and tensor low-rank
decompositions. We propose and analyze a new algorithm for low-rank
approximations of block-structured matrices (e.g., block Hankel) using KRPs. We
also develop new algorithms to accelerate tensor computations in the Tucker
format using KRPs, and give theoretical guarantees of the resulting low-rank
approximations. Numerical experiments on synthetic and real-world tensors show
the computational benefits of the proposed methods.

</details>


### [6] [An optimal preconditioner for high-order scheme arising from multi-dimensional Riesz space fractional diffusion equations with variable coefficients](https://arxiv.org/abs/2507.23408)
*Yuan-Yuan Huang,Wei Qu,Sean Y. Hon,Siu-Long Lei*

Main category: math.NA

TL;DR: Proposes an efficient CN-4FCD scheme for multi-dimensional Riesz space fractional diffusion equations, ensuring stability, convergence, and high accuracy. A sine transform-based preconditioner boosts computational efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of solving multi-dimensional Riesz space fractional diffusion equations with variable coefficients efficiently and accurately.

Method: Combines Crank-Nicolson (CN) for temporal discretization and fourth-order fractional centered difference (4FCD) for spatial discretization. Uses a sine transform-based preconditioner for efficiency.

Result: The CN-4FCD scheme is unconditionally stable and convergent, achieving second-order time and fourth-order space accuracy. The preconditioner ensures mesh-size-independent convergence.

Conclusion: The proposed method is validated numerically, showing superior performance over existing methods.

Abstract: In this paper, we propose an efficient method for solving multi-dimensional
Riesz space fractional diffusion equations with variable coefficients. The
Crank-Nicolson (CN) method is used for temporal discretization, while the
fourth-order fractional centered difference (4FCD) method is employed for
spatial discretization. Using a novel technique, we show that the CN-4FCD
scheme for the multi-dimensional case is unconditionally stable and convergent,
achieving second-order accuracy in time and fourth-order accuracy in space with
respect to the discrete L2-norm. Moreover, leveraging the symmetric multi-level
Toeplitz-like structure of the coefficient matrix in the discrete linear
systems, we enhance the computational efficiency of the proposed scheme with a
sine transform-based preconditioner, ensuring a mesh-size-independent
convergence rate for the conjugate gradient method. Finally, two numerical
examples validate the theoretical analysis and demonstrate the superior
performance of the proposed preconditioner compared to existing methods.

</details>


### [7] [The Effect of Prior Parameters on Standardized Kalman Filter-Based EEG Source Localization](https://arxiv.org/abs/2507.23450)
*Dilshanie Prasikala,Joonas Lahtinen,Alexandra Koulouri,Sampsa Pursiainen*

Main category: math.NA

TL;DR: The paper explores EEG source localization using the Standardized Kalman Filter (SKF), optimizing Gaussian prior models for detecting cortical and sub-cortical activity. It highlights improved depth localization with specific parameter adjustments and smoothing.


<details>
  <summary>Details</summary>
Motivation: EEG source localization is vital for neuroscience but faces challenges like depth bias and lack of unique solutions. The study aims to enhance accuracy by refining prior models within the SKF framework.

Method: The study uses synthetic data resembling somatosensory evoked potentials (SEP) to test Gaussian prior models in SKF. It evaluates parameter configurations and RTS smoothing for source reconstruction under varying noise levels.

Result: Raising the standardization exponent to 1.25 and applying smoothing notably improves depth localization accuracy, especially at low noise levels.

Conclusion: Optimized Gaussian prior models in SKF, combined with smoothing, enhance EEG source localization accuracy, addressing depth bias and improving detection of deep and superficial sources.

Abstract: EEG Source localization is a critical tool in neuroscience, with applications
ranging from epilepsy diagnosis to cognitive research. It involves solving an
ill-posed inverse problem that lacks a unique solution unless constrained by
prior knowledge. The Bayesian framework enables the incorporation of such
knowledge, typically encoded through prior models. Various algorithms have been
proposed for source localization, and they differ significantly in how prior
knowledge is incorporated. Some approaches rely on anatomical or functional
constraints, while others use statistical distributions or sampling-based
techniques. In this landscape, the Standardized Kalman Filter (SKF) represents
a dynamic Bayesian approach that integrates temporal modeling with a Gaussian
prior structure. It addresses the depth bias, a common limitation in source
localization, through a post-hoc standardization step that equalizes
sensitivity across cortical depths and makes deep activity detection feasible.
  This study focuses on the development and optimization of Gaussian prior
models within the SKF framework for simultaneous cortical and sub-cortical
activity detection. Synthetic data similar to the P20 / N20 component of the
somatosensory evoked potentials (SEP) was used to identify effective prior
parameter configurations for reconstructing both deep and superficial sources
under different noise levels. We also investigated the role of RTS smoothing in
enhancing source separability. Our results indicate that raising the
standardization exponent to 1.25, along with smoothing, significantly improves
depth localization accuracy at low noise levels.

</details>


### [8] [Rational complex Bezier curves](https://arxiv.org/abs/2507.23485)
*A. Canton,L. Fernandez-Jambrina,M. J. Vazquez-Gallo*

Main category: math.NA

TL;DR: The paper introduces rational complex Bézier curves, extending CAD paradigms with complex-valued control polygons and weights, enabling additional projective transformations and degree reduction.


<details>
  <summary>Details</summary>
Motivation: To extend the CAD framework by incorporating complex values in Bézier curves, allowing more flexible transformations and potential degree reduction.

Method: Develops rational complex Bézier curves using complex control polygons and weights, leveraging complex projective transformations and resultant-based degree checks.

Result: Demonstrates the ability to apply complex projective transformations (e.g., geometric inversion) and reduce curve degrees in some cases, with examples provided.

Conclusion: The formalism enhances curve design flexibility and efficiency, with practical applications in classical curve modeling.

Abstract: In this paper we develop the formalism of rational complex Bezier curves.
This framework is a simple extension of the CAD paradigm, since it describes
arc of curves in terms of control polygons and weights, which are extended to
complex values. One of the major advantages of this extension is that we may
make use of two different groups of projective transformations. Besides the
group of projective transformations of the real plane, we have the group of
complex projective transformations. This allows us to apply useful
transformations like the geometric inversion to curves in design. In addition
to this, the use of the complex formulation allows to lower the degree of the
curves in some cases. This can be checked using the resultant of two
polynomials and provides a simple formula for determining whether a rational
cubic curve is a conic or not. Examples of application of the formalism to
classical curves are included.

</details>


### [9] [Quantum simulation of Helmholtz equations via Schr{ö}dingerization](https://arxiv.org/abs/2507.23547)
*Anjiao Gu,Shi Jin,Chuwen Ma*

Main category: math.NA

TL;DR: A quantum algorithm for solving the Helmholtz equation using the Schrödingerization framework, achieving efficient query complexity with asymptotic dispersion correction and preconditioning.


<details>
  <summary>Details</summary>
Motivation: The Helmholtz equation's challenges (indefiniteness, large system sizes) for numerical solutions at high wave numbers motivate a quantum approach.

Method: Reformulates the problem into a Schrödinger-type system via warped phase transformation, incorporating dispersion correction and preconditioning.

Result: Achieves query complexity of O(κ² polylog ε⁻¹) for general indefinite problems, reduced to O(κ polylog ε⁻¹) for the Helmholtz equation.

Conclusion: The method is broadly applicable to indefinite problems, offering efficient quantum solutions.

Abstract: The Helmholtz equation is a prototypical model for time-harmonic wave
propagation. Numerical solutions become increasingly challenging as the wave
number $k$ grows, due to the equation's elliptic yet noncoercive character and
the highly oscillatory nature of its solutions, with wavelengths scaling as
$1/k$. These features lead to strong indefiniteness and large system sizes.
  We present a quantum algorithm for solving such indefinite problems, built
upon the Schr\"odingerization framework. This approach reformulates linear
differential equations into Schr\"odinger-type systems by capturing the steady
state of damped dynamics. A warped phase transformation lifts the original
problem to a higher-dimensional formulation, making it compatible with quantum
computation. To suppress numerical pollution, the algorithm incorporates
asymptotic dispersion correction. It achieves a query complexity of
$\mathcal{O}(\kappa^2\text{polylog}\varepsilon^{-1})$, where $\kappa$ is the
condition number and $\varepsilon$ the desired accuracy. For the Helmholtz
equation, a simple preconditioner further reduces the complexity to
$\mathcal{O}(\kappa\text{polylog}\varepsilon^{-1})$. Our constructive extension
to the quantum setting is broadly applicable to all indefinite problems.

</details>


### [10] [Fitted norm preconditioners for the Hodge Laplacian in mixed form](https://arxiv.org/abs/2507.23586)
*Wietse M. Boon,Johannes Kraus,Tomáš Luber,Maria Lymbery*

Main category: math.NA

TL;DR: The paper analyzes the mixed formulation of the Hodge Laplace problem using perturbed saddle point problems, ensuring well-posedness and proposing a simplified, efficient preconditioner.


<details>
  <summary>Details</summary>
Motivation: To address the well-posedness and computational efficiency of the Hodge Laplace problem through a mixed formulation and preconditioning.

Method: Uses parameter-dependent norms for uniform continuity and stability, simplifies these norms, and derives a norm-equivalent preconditioner.

Result: Demonstrates fast convergence and uniform performance of the preconditioner in solving Hodge Laplace problems in 2D and 3D.

Conclusion: The proposed framework ensures well-posedness and provides an efficient, implementable preconditioner for the Hodge Laplace problem.

Abstract: We use the practical framework for abstract perturbed saddle point problems
recently introduced by Hong et al. to analyze the mixed formulation of the
Hodge Laplace problem. We compose two parameter-dependent norms in which the
uniform continuity and stability of the problem follow. This not only
guarantees the well-posedness of the corresponding variational formulation on
the continuous level, but also of related compatible discrete models.
  We further simplify the obtained norms and, in both cases, arrive at the same
norm-equivalent preconditioner that is easily implementable. The efficiency and
uniformity of the preconditioner are demonstrated numerically by the fast
convergence and uniformly bounded number of preconditioned MINRES iterations
required to solve various instances of Hodge Laplace problems in two and three
space dimensions.

</details>


### [11] [Efficient Numerical Strategies for Entropy-Regularized Semi-Discrete Optimal Transport](https://arxiv.org/abs/2507.23602)
*Moaad Khamlich,Francesco Romor,Gianluigi Rozza*

Main category: math.NA

TL;DR: The paper presents a framework to accelerate semi-discrete optimal transport (SOT) with entropic regularization, addressing computational bottlenecks in large-scale problems involving finite element discretization.


<details>
  <summary>Details</summary>
Motivation: The computational challenge arises when evaluating the dual objective function in RSOT due to dense interactions between source quadrature points and target points, especially in complex geometries or densities from PDEs.

Method: The framework combines distance-based truncation, fast spatial queries (R-trees), multilevel techniques (hierarchies of FE mesh and target measure), and a robust regularization parameter scheduling strategy.

Result: The unified methods significantly reduce computational costs, enabling practical large-scale applications of RSOT.

Conclusion: The paper provides an open-source C++ implementation, making the framework accessible for complex, large-scale SOT problems.

Abstract: Semi-discrete optimal transport (SOT), which maps a continuous probability
measure to a discrete one, is a fundamental problem with wide-ranging
applications. Entropic regularization is often employed to solve the SOT
problem, leading to a regularized (RSOT) formulation that can be solved
efficiently via its convex dual. However, a significant computational challenge
emerges when the continuous source measure is discretized via the finite
element (FE) method to handle complex geometries or densities, such as those
arising from solutions to Partial Differential Equations (PDEs). The evaluation
of the dual objective function requires dense interactions between the numerous
source quadrature points and all target points, creating a severe bottleneck
for large-scale problems. This paper presents a cohesive framework of numerical
strategies to overcome this challenge. We accelerate the dual objective and
gradient evaluations by combining distance-based truncation with fast spatial
queries using R-trees. For overall convergence, we integrate multilevel
techniques based on hierarchies of both the FE source mesh and the discrete
target measure, alongside a robust scheduling strategy for the regularization
parameter. When unified, these methods drastically reduce the computational
cost of RSOT, enabling its practical application to complex, large-scale
scenarios. We provide an open-source C++ implementation of this framework,
built upon the deal.II finite element library, available at
https://github.com/SemiDiscreteOT/SemiDiscreteOT.

</details>


### [12] [A Multi-Frequency Helmholtz Solver Based on the WaveHoltz Algorithm](https://arxiv.org/abs/2507.23613)
*Daniel Appelö,Francis Appiah,Jeffrey W. Banks,Cassandra Carrick,William D. Henshaw,Donald W. Schwendeman*

Main category: math.NA

TL;DR: The paper introduces the Multi-Frequency WaveHoltz (MFWH) algorithm, an extension of the WaveHoltz method, for solving Helmholtz equations for multiple frequencies and forcing functions simultaneously using time-filtering and wave equation solutions.


<details>
  <summary>Details</summary>
Motivation: The need for efficient computation of multiple Helmholtz equation solutions for varying frequencies and forcing functions motivates the development of the MFWH algorithm.

Method: MFWH combines a single wave equation solution with multiple time filters, employs fixed-point iteration accelerated by Krylov methods (e.g., GMRES), and uses high-order spatial and second-order temporal discretizations.

Result: The algorithm achieves O(N) solution cost with fixed frequencies and increasing grid points, confirmed by numerical results using second- and fourth-order discretizations.

Conclusion: MFWH efficiently computes Helmholtz solutions, with convergence to discretized Helmholtz problems demonstrated theoretically and numerically.

Abstract: We develop and analyze a new approach for simultaneously computing multiple
solutions to the Helmholtz equation for different frequencies and different
forcing functions. The new Multi-Frequency WaveHoltz (MFWH) algorithm is an
extension of the original WaveHoltz method and both are based on time-filtering
solutions to an associated wave equation. With MFWH, the different Helmholtz
solutions are computed simultaneously by solving a single wave equation
combined with multiple time filters. The MFWH algorithm defines a fixed-point
iteration which can be accelerated with Krylov methods such as GMRES. The
solution of the wave equation can be efficiently solved with either explicit
time-stepping or implicit time-stepping using as few as five time-steps per
period. When combined with an $O(N)$ solver for the implicit equations, such a
multigrid, the scheme has an $O(N)$ solution cost when the frequencies are
fixed and the number of grid points $N$ increases. High-order accurate
approximations in space are used together with second-order accurate
approximations in time. We show how to remove time discretization errors so
that the MFWH solutions converge to the corresponding solutions to the
discretized Helmholtz problems. Numerical results are given using second-order
accurate and fourth-accurate discretizations to confirm the convergence theory.

</details>


### [13] [Regularization of Inverse Problems by Filtered Diagonal Frame Decomposition under general source](https://arxiv.org/abs/2507.23651)
*Dang Duc Trong,Nguyen Dang Minh,Luu Xuan Thang,Luu Dang Khoa*

Main category: math.NA

TL;DR: The paper explores regularization methods for solving ill-posed inverse problems in Hilbert spaces, proposing Diagonal Frame Decomposition (DFD) as an alternative to SVD, and analyzes convergence rates and optimality under generalized source conditions.


<details>
  <summary>Details</summary>
Motivation: To address the computational impracticality of SVD for certain operators and provide a generalized framework for solving ill-posed inverse problems with noisy data.

Method: Introduces DFD as a generalization of SVD, derives a regularized solution, and analyzes convergence rates under a generalized source condition.

Result: Theoretical results include modulus of continuity bounds and convergence rates for both a priori and a posteriori parameter choices, applicable to polynomial and exponentially ill-posed problems.

Conclusion: DFD offers a viable alternative to SVD for regularization, with theoretical guarantees on convergence and optimality under generalized conditions.

Abstract: Let $X$ and $Y$ be Hilbert spaces, and $\mathbf{K}: \text{dom} \mathbf{K}
\subset X \to Y$ a bounded linear operator. This paper addresses the inverse
problem $\mathbf{K}x = y$, where exact data $y$ is replaced by noisy data
$y^\delta$ satisfying $\|y^\delta - y\|_Y \leq \delta$. Due to the
ill-posedness of such problems, we employ regularization methods to stabilize
solutions. While singular value decomposition (SVD) provides a classical
approach, its computation can be costly and impractical for certain operators.
We explore alternatives via Diagonal Frame Decomposition (DFD), generalizing
SVD-based techniques, and introduce a regularized solution $x^\delta_\alpha =
\sum_{\lambda \in \Lambda} \kappa_\lambda g_\alpha(\kappa_\lambda^2) \langle
y^\delta, v_\lambda \rangle \overline{u}_\lambda$. Convergence rates and
optimality are analyzed under a generalized source condition
$\mathbf{M}_{\varphi, E} = \{ x \in \text{dom} \mathbf{K} : \sum_{\lambda \in
\Lambda} [\varphi(\kappa_\lambda^2)]^{-1} |\langle x, u_\lambda \rangle|^2 \leq
E^2 \}$. Key questions include constructing DFD systems, relating DFD and SVD
singular values, and extending source conditions. We present theoretical
results, including modulus of continuity bounds and convergence rates for a
priori and a posteriori parameter choices, with applications to polynomial and
exponentially ill-posed problems.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [14] [Mean-field approximation, Gibbs relaxation, and cross estimates](https://arxiv.org/abs/2507.23123)
*Armand Bernou,Mitia Duerinckx*

Main category: math.AP

TL;DR: The paper improves the mean-field approximation error for a system of Brownian particles with weak interactions, showing a combined error rate of $O(N^{-1}e^{-ct})$ for chaos propagation and Gibbs relaxation.


<details>
  <summary>Details</summary>
Motivation: To enhance understanding of the interplay between chaos propagation and Gibbs relaxation in systems of Brownian particles, particularly for weak mean-field interactions.

Method: Analysis of the BBGKY hierarchy for correlation functions, applied to underdamped and overdamped Langevin dynamics with bounded interaction forces.

Result: Demonstrated an improved mean-field approximation error, reducing from $O(N^{-1})$ to $O(N^{-1}e^{-ct})$, and derived new Gibbs relaxation results.

Conclusion: The study provides a refined error estimate for mean-field approximations and extends understanding of Gibbs relaxation in weakly interacting systems.

Abstract: This work focuses on the propagation of chaos and the relaxation to Gibbs
equilibrium for a system of $N$ classical Brownian particles with weak
mean-field interactions. While it is known that propagation of chaos holds at
rate $O(N^{-1})$ uniformly in time, and Gibbs relaxation at rate $O(e^{-ct})$
uniformly in $N$, we go a step further by showing that the cross error between
chaos propagation and Gibbs relaxation is $O(N^{-1}e^{-ct})$. For
translation-invariant systems on the torus, this leads to an improved
mean-field approximation error at the level of the one-particle density: the
error decreases from $O(N^{-1})$ to $O(N^{-1}e^{-ct})$. Our approach relies on
a detailed analysis of the BBGKY hierarchy for correlation functions, and
applies to both underdamped and overdamped Langevin dynamics with merely
bounded interaction forces. We also derive new results on Gibbs relaxation and
present partial extensions beyond the weak interaction regime.

</details>


### [15] [A note on the first Steklov eigenvalue on planar domains](https://arxiv.org/abs/2507.23312)
*Azahara DelaTorre,Gabriele Mancini,Angela Pistoia,Luigi Provenzano*

Main category: math.AP

TL;DR: The paper examines the first positive Steklov eigenvalue on planar domains, presenting an example with a closed nodal line and proving a lower bound for symmetric domains, including simplicity for ellipses.


<details>
  <summary>Details</summary>
Motivation: To address gaps in the understanding of the first positive Steklov eigenvalue, particularly regarding nodal lines and symmetric domains, as highlighted by Kuttler and Sigillito's work.

Method: The study provides a specific example of a planar domain with a closed nodal line and derives a lower bound for the eigenvalue on symmetric domains, with a focus on ellipses.

Result: Demonstrates a planar domain with a closed nodal line for the first eigenfunction and establishes a lower bound for the eigenvalue on symmetric domains, proving simplicity for ellipses.

Conclusion: The findings complement prior work by Kuttler and Sigillito, enhancing the understanding of Steklov eigenvalues on planar domains.

Abstract: We consider the first positive Steklov eigenvalue on planar domains. First,
we provide an example of a planar domain for which a first eigenfunction has a
closed nodal line. Second, we establish a lower bound for the first positive
eigenvalue on certain symmetric domains and show that this eigenvalue is simple
for all ellipses. These results complement two statements contained in a work
by Kuttler and Sigillito (Proc. Amer. Math. Soc. 20, 1969).

</details>


### [16] [On the existence of normalized solutions to a class of fractional Choquard equation with potentials](https://arxiv.org/abs/2507.23363)
*Yongpeng Chen,Zhipeng Yang,Jianjun Zhang*

Main category: math.AP

TL;DR: The paper explores normalized solutions for a nonlinear fractional Choquard equation with mass constraint, using variational methods to establish existence results.


<details>
  <summary>Details</summary>
Motivation: To address the existence of normalized solutions for a complex fractional Choquard equation under specific constraints, which is relevant in mathematical physics and analysis.

Method: Variational methods are applied under assumptions on potentials V(x), f(x), and g(x) to analyze the equation.

Result: Several existence results for normalized solutions are proven.

Conclusion: The study successfully demonstrates the existence of normalized solutions for the given fractional Choquard equation under the specified conditions.

Abstract: This paper investigates the existence of normalized solutions to the
nonlinear fractional Choquard equation: $$ (-\Delta)^s u+V(x) u=\lambda
u+f(x)\left(I_\alpha *\left(f|u|^q\right)\right)|u|^{q-2} u+g(x)\left(I_\alpha
*\left(g|u|^p\right)\right)|u|^{p-2} u, \quad x \in \mathbb{R}^N $$ subject to
the mass constraint $$ \int_{\mathbb{R}^N}|u|^2 d x=a>0, $$ where $N>2 s, s
\in(0,1), \alpha \in(0, N)$, and $\frac{N+\alpha}{N} \leq q<p \leq
\frac{N+\alpha+2 s}{N}$. Here, the parameter $\lambda \in \mathbb{R}$ appears
as an unknown Lagrange multiplier associated with the normalization condition.
By employing variational methods under appropriate assumptions on the
potentials $V(x), f(x)$, and $g(x)$, we establish several existence results for
normalized solutions.

</details>


### [17] [Quantitative homogenisation for differential equations with highly anisotropic partially degenerating coefficients](https://arxiv.org/abs/2507.23380)
*Shane Cooper,Ilia Kamotski*

Main category: math.AP

TL;DR: The paper analyzes the resolvent of a non-uniformly elliptic operator with periodic coefficients, focusing on high-contrast scaling and anisotropy. It extends prior work by providing asymptotic descriptions and operator-type error estimates, addressing new challenges like directional ellipticity loss and weaker spectral gap assumptions.


<details>
  <summary>Details</summary>
Motivation: The study aims to understand the asymptotic behavior of the resolvent of a highly anisotropic operator as the period tends to zero, addressing gaps in prior work and handling new complexities like directional ellipticity loss.

Method: The approach builds on a general scheme from prior research but incorporates additional boundary layer analysis near fibres to account for directional ellipticity loss and weaker spectral gap conditions, achieving order-ϵ error estimates.

Result: The paper provides an asymptotic description of the resolvent and establishes operator-type error estimates, including an interfacial boundary layer analysis to handle new challenges.

Conclusion: The work successfully extends prior results by addressing additional complexities, offering refined error estimates and insights into the resolvent's behavior in highly anisotropic media.

Abstract: We consider a non-uniformly elliptic second-order differential operator with
periodic coefficients that models composite media consisting of highly
anisotropic cylindrical fibres periodically distributed in an isotropic
background. The degree of anisotropy is related to the period of the
coefficients via a `critical' high-contrast scaling. In particular, ellipticity
is lost in certain directions as the period, $\epsilon$, tends to zero. Our
primary interest is in the asymptotic behaviour of the resolvent of this
operator in the limit of small $\epsilon$.
  Two-scale resolvent convergence results were established for such operators
in Cherednichenko, Smyshlyaev and Zhikov (Proceedings of The Royal Society of
Edinburgh:Seciton A Mathematics. 136(1), 87--114(2006)). In this work, we
provide an asymptotic description of the resolvent and establish operator-type
error estimates. Our approach adopts the general scheme of Cooper, Kamotski and
Smyshlyaev (preprint available at arXiv:2307.13151). However, we face new
challenges such as a directional dependence on the loss of ellipticity in
addition to a key `spectral gap' assumption of the above article only holding
in a weaker sense. This results in an additional `interfacial' boundary layer
analysis in the vicinity of each fibre to arrive at order-$\epsilon$
operator-type error estimates.

</details>


### [18] [Global well-posedness and scattering for the 2D modified Zakharov-Kuznetsov equation](https://arxiv.org/abs/2507.23397)
*Simão Correia,Shinya Kinoshita*

Main category: math.AP

TL;DR: The paper analyzes the modified Zakharov-Kuznetsov equation in 2D, proving local and global well-posedness and scattering for specific parameter ranges.


<details>
  <summary>Details</summary>
Motivation: To study the dispersive effects and well-posedness of the modified Zakharov-Kuznetsov equation in a two-parameter space.

Method: Introduces a new space $H^{s,a}(\mathbb{R}^2)$ and uses it to prove local and global well-posedness and scattering for small data.

Result: Local well-posedness for $s+a\ge 1/4$, $0<a<1/4$, and global well-posedness and scattering for small data when $s=0, a=1/4$. Results are sharp.

Conclusion: The introduced space and methods provide sharp results for the modified Zakharov-Kuznetsov equation, advancing understanding of its behavior.

Abstract: We consider the Cauchy problem associated with the modified
Zakharov-Kuznetsov equation over $\mathbb{R}^2$. Taking into consideration the
associated dispersive effects, we introduce, for $s,a\ge 0$, a two-parameter
space $H^{s,a}(\mathbb{R}^2)$, which scales as the classic $H^s$ spaces. In
this new class, we prove local well-posedness for $s+a\ge 1/4$, $0<a<1/4$, and
global well-posedness and scattering for small data in the case $s=0, \ a=1/4$.
These results are shown to be sharp in the sense of $C^3$-flows.

</details>


### [19] [$p(x)$-Stability of the Dirichlet problem for Poisson's equation with variable exponents](https://arxiv.org/abs/2507.23417)
*Behzad Djafari Rouhani,Osvaldo Mendez*

Main category: math.AP

TL;DR: The paper demonstrates convergence of solutions to Dirichlet problems for variable exponent p(x)-Laplacian as the exponent sequence uniformly approaches p(x).


<details>
  <summary>Details</summary>
Motivation: To understand how solutions to Dirichlet problems behave when the exponent in the p(x)-Laplacian varies uniformly.

Method: Analyze sequences of solutions for increasing and decreasing exponent sequences, comparing them to the limit solution.

Result: Solutions converge to the limit solution for both increasing and decreasing exponent sequences.

Conclusion: Uniform convergence of exponents ensures convergence of solutions in Dirichlet problems for p(x)-Laplacian.

Abstract: It is shown that if the sequence $(p_j(x))$ increases uniformly to $p(x)$ in
a bounded, smooth domain $\Omega$, then the sequence $(u_i)$ of solutions to
the Dirichlet problem for the $p_i(x)$-Laplacian with fixed boundary datum
$\varphi$ converges (in a sense to be made precise) to the solution $u_p$ of
the Dirichlet problem for the $p(x)$-Laplacian with boundary datum $\varphi$. A
similar result is proved for a decreasing sequence $p_j\searrow p$

</details>


### [20] [Heat content asymptotics for sets with positive reach](https://arxiv.org/abs/2507.23427)
*Paolo De Fazio,Michele Miranda Jr*

Main category: math.AP

TL;DR: Study of heat content asymptotics for sets with positive reach in Euclidean space.


<details>
  <summary>Details</summary>
Motivation: Extend understanding of heat content behavior to non-smooth sets with positive reach, building on Federer's concept.

Method: Analyze short-time asymptotics of heat content for bounded subsets with positive reach using new techniques.

Result: Derives slightly different results compared to prior work, showcasing unique methodology.

Conclusion: Advances the study of heat content for non-smooth sets, contributing to broader geometric analysis.

Abstract: In this paper we study the heat content for sets with positive reach. In
details, we investigate the asymptotic behavior of the heat content of bounded
subsets of the Euclidean space with positive reach. The concept of positive
reach was introduced by Federer in \cite{fed_1959} and widely developed in the
following years (see for instance the recent book by Rataj and Zh{\"a}le
\cite{rat_zah_2019}). It extends the class of sets with smooth boundaries to
include certain non-smooth and singular sets while still admitting a
well-defined normal geometry. For such sets $E\subseteq\Rn$, we analyze the
short-time asymptotics of the heat content $\|T_t\mathbbm{1}_E\|_2$, where
$T_t\mathbbm{1}_E$ is the soluzion of the heat equation in $\Rn$ with initial
condition $\mathbbm{1}_E$. The present paper is in the spirit of Angiuli,
Massari and Miranda Jr.\cite{ang_mas_mir_2013}, but the technique's used here
are completely different and also the final result is slightly different.

</details>


### [21] [Improvement of the Parabolic Regularization Method and Applications to Dispersive Models](https://arxiv.org/abs/2507.23530)
*Alysson Cunha*

Main category: math.AP

TL;DR: The paper proves global well-posedness of the Benjamin-Ono equation in $H^s(\mathbb{R})$ for $s > 1/2$ without using Tao's gauge transformation, instead employing a modified parabolic regularization method.


<details>
  <summary>Details</summary>
Motivation: To establish global well-posedness for the Benjamin-Ono equation in Sobolev spaces without relying on Tao's gauge transformation, and extend this to the dispersion-generalized Benjamin-Ono (DGBO) equation.

Method: A modified version of the standard parabolic regularization method is used, avoiding the global gauge transformation.

Result: Global well-posedness is proven for the Benjamin-Ono equation in $H^s(\mathbb{R})$ for $s > 1/2$, and extended to the DGBO equation.

Conclusion: The modified parabolic regularization method successfully establishes global well-posedness for both equations in the specified Sobolev space.

Abstract: We prove that the Benjamin Ono equation is globally well-posed in
$H^s(\mathbb{R})$ for $s > 1/2$. Our approach does not rely on the global gauge
transformation introduced by Tao (arXiv:math/0307289). Instead, we employ a
modified version of the standard parabolic regularization method. In
particular, this technique also enables us to establish global well-posedness,
in the same Sobolev space, for the dispersion-generalized Benjamin Ono (DGBO)
equation.

</details>


### [22] [Transverse asymptotic stability of line solitary waves for the Ionic Euler-Poisson system](https://arxiv.org/abs/2507.23572)
*Frédéric Rousset,Changzhen Sun*

Main category: math.AP

TL;DR: The paper proves stability of small solitary waves in a 3D Euler-Poisson system, showing global smooth solutions and their asymptotic behavior.


<details>
  <summary>Details</summary>
Motivation: To understand the stability and behavior of small solitary waves in ion dynamics described by the 3D Euler-Poisson system.

Method: Analyzing linear and nonlinear asymptotic stability of small amplitude one-dimensional solitary waves under localized irrotational perturbations.

Result: Demonstrates existence of global smooth solutions and describes their asymptotic behavior in the given regime.

Conclusion: Small amplitude solitary waves are stable under small perturbations, with global smooth solutions exhibiting predictable asymptotic behavior.

Abstract: We prove the linear and nonlinear asymptotic stability of small amplitude
one-dimensional solitary waves submitted to small localized irrotational
perturbations in the three dimensional Euler-Poisson system describing the
dynamics of ions. In particular, in this regime, we obtain the existence of
global smooth solutions and describe their asymptotic behavior.

</details>


### [23] [On blow-up trees for the harmonic map heat flow from $B^2$ to $S^2$](https://arxiv.org/abs/2507.23583)
*Dylan Samuelian*

Main category: math.AP

TL;DR: The paper analyzes finite-time and $k$-equivariant solutions to the harmonic map heat flow from $B^2$ to $S^2$, proving a single-bubble decomposition under time-dependent boundary data and showing infinite-time blow-up for $k \geq 1$.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of harmonic map heat flow solutions under time-dependent boundary conditions and their bubble tree decomposition.

Method: Uses the Maximum and Comparison Principle to analyze solutions and their decomposition.

Result: Proves the bubble tree decomposition has only one bubble and demonstrates infinite-time blow-up for solutions with $k \geq 1$.

Conclusion: The study provides insights into the structure of solutions and their blow-up behavior under specific conditions.

Abstract: We consider finite-time and $k$-equivariant solutions to the harmonic map
heat flow from $B^2$ to $S^2$ under general time-dependent boundary data and
prove that the bubble tree decomposition contains only one bubble. The method
relies on the Maximum and Comparison Principle. We also exhibit solutions
blowing up in infinite time for any $k \geq 1$.

</details>


### [24] [Elliptic unique continuation below the Lipschitz threshold](https://arxiv.org/abs/2507.23614)
*Cole Jeznach*

Main category: math.AP

TL;DR: The paper explores unique continuation principles for elliptic equations with less regular coefficients, showing log-Lipschitz conditions are sharp for general matrices and disproving a conjecture for isotropic cases.


<details>
  <summary>Details</summary>
Motivation: To determine the minimal regularity conditions on coefficients of elliptic equations ensuring unique continuation of solutions.

Method: Analyzes uniformly elliptic equations with non-Lipschitz coefficients, proving results under Osgood conditions and Holder continuity for isotropic cases.

Result: Log-Lipschitz conditions are sharp for general matrices; Holder continuity suffices for isotropic equations, disproving a 1974 conjecture.

Conclusion: The study clarifies the regularity needed for unique continuation, with implications for both general and isotropic elliptic equations.

Abstract: In this article, we investigate unique continuation principles for solutions
$u$ of uniformly elliptic equations of the form $-\mathrm{div}(A \nabla u) = 0$
when $A$ is less regular than Lipschitz. For general matrices $A$, we prove
that strong unique continuation holds provided that $A$ has modulus of
continuity $\omega$ satisfying the Osgood condition $\int_0^1 \omega(t)^{-1}dt
= \infty$, plus some other mild hypotheses. Along with the counterexamples of
Mandache, this shows that the sharp condition on $A$ that guarantees unique
continuation is essentially that $A$ is log-Lipschitz. In the class of
isotropic equations (i.e., $A(x) = a(x)I$ for some scalar function $a$) we show
that Holder continuity of $a$ of the order $\alpha \in (2/3,1)$ is sufficient
to guarantee strong unique continuation. This latter result contrasts
counterexamples known for anisotropic equations, and disproves a conjecture of
Miller from 1974.

</details>


### [25] [Normalized solutions for the NLS equation with potential in higher dimension: the purely Sobolev critical case](https://arxiv.org/abs/2507.23639)
*Juntao Sun,Shuai Yao,He Zhang*

Main category: math.AP

TL;DR: The paper addresses normalized solutions for the NLS equation with potential and Sobolev critical nonlinearity, solving an open problem and improving prior results.


<details>
  <summary>Details</summary>
Motivation: To solve an open problem in the study of NLS equations with potential and Sobolev critical nonlinearity, and to improve existing results.

Method: Establishes suitable assumptions on the potential and employs new techniques to find mountain-pass type solutions and local minimizers.

Result: A mountain-pass type solution for N>=6 and a local minimizer with negative energy for N>=3 are found.

Conclusion: The work resolves an open problem and enhances previous findings, contributing to the understanding of NLS equations with critical nonlinearity.

Abstract: We study normalized solutions for the nonlinear Schrodinger (NLS) equation
with potential and Sobolev critical nonlinearity. By establishing suitable
assumptions on the potential, together with new techniques, we find a
mountain-pass type solution for N>=6, which solves an open problem presented in
a recent paper [Verzini and Yu, arXiv:2505.05357v1]. Moreover, we also find a
local minimizer with negative energy for N>=3, which improves the results in
[Verzini and Yu, arXiv:2505.05357v1].

</details>


### [26] [Infinite BV, large $L^\infty$ solutions of conservation laws are Hölder-stable in $L^2$ in the class of front tracking limits](https://arxiv.org/abs/2507.23645)
*Geng Chen,Cooper Faile,Sam G. Krupa*

Main category: math.AP

TL;DR: The paper proves a Hölder-type stability estimate in $L^2$ for hyperbolic systems of conservation laws, independent of the BV norm of the solution, and applies it to physical systems like isentropic Euler.


<details>
  <summary>Details</summary>
Motivation: To establish stability estimates for weak solutions of hyperbolic conservation laws without relying on BV assumptions, addressing both small-BV and large-BV data cases.

Method: Uses the $L^2$ theory of shock stability with an artificial shift of position, extending results to limits of front tracking solutions with BV bounds.

Result: A universal stability estimate in $L^2$ is derived, applicable to systems like isothermal Euler, and uniqueness results for solutions with large $L^\infty$ and infinite BV data are shown.

Conclusion: The framework provides robust stability estimates and uniqueness results for hyperbolic systems, even for wild solutions without BV constraints.

Abstract: We consider hyperbolic systems of conservation laws in one spatial dimension.
For any limit of front tracking solutions $v$, and for a general weak solution
$u\in L^\infty$ with no BV assumption, we prove the following H\"older-type
stability estimate in $L^2$:
  $$||u(\cdot,\tau)-v(\cdot,\tau)||_{L^2} \leq K \sqrt{||u( \cdot,0)-v(
\cdot,0)||_{L^2}}$$
  for all $\tau$ without smallness and for a universal constant $K$. Our result
holds for all limits of front tracking solutions $v$ with BV bound, either for
general systems with small-BV data, or for special systems (isothermal Euler,
Temple-class systems) with large-BV data. Our results apply to physical systems
such as isentropic Euler. The stability estimate is completely independent of
the BV norm of the potentially very wild solution $u$. We use the $L^2$ theory
of shock stability modulo an artificial shift of position (Vasseur [Handbook of
Differential Equations: Evolutionary Equations, 4:323 -- 376, 2008]) but our
stability results do not depend on an unknown shift. Moreover, we give the
first result within this framework which can show uniqueness of some solutions
with large $L^\infty$ and infinite BV initial data. We apply these techniques
to isothermal Euler.

</details>


### [27] [Analysis of a Cross-Nonlinear Porous-Medium System Modeling Pressure-Driven Cell Population Dynamics](https://arxiv.org/abs/2507.23680)
*Alexis Béjar-López,Rafael Granero-Belinchón,Carlos Pulido,Juan Soler*

Main category: math.AP

TL;DR: A cross-diffusion model is introduced to study how internal pressure affects growth and motility in biological tissues, capturing nonlinear interactions and proving local well-posedness and nonnegativity of solutions.


<details>
  <summary>Details</summary>
Motivation: To understand the feedback between local density fluctuations and tissue expansion or contraction, driven by internal pressure, in biological systems.

Method: The model blends nonlinear nonlocal interactions, porous-medium diffusion, and an antidiffusive pressure term, incorporating density-dependent spreading and a novel cross-diffusion term.

Result: Local well-posedness is proven for nonnegative solutions, with uniqueness under specific conditions. Finite-time blow-up is shown, and the invariance of density's spatial support is established.

Conclusion: The model provides insights into pattern formation and mass transport in biological tissues, highlighting the interplay between density and area dynamics.

Abstract: In this work, we introduce a cross-diffusion model that couples population
density and occupied area to investigate how internal pressure drives growth
and motility. By blending nonlinear nonlocal interactions with porous-medium
diffusion and an antidiffusive pressure term, the model captures the two-way
feedback between local density fluctuations and tissue expansion or
contraction. Building on Shraiman's area-growth paradigm, we enrich the
framework with density-dependent spreading at the population boundary and a
novel cross-diffusion term, yielding fully nonlinear transport in both
equations. We prove local well-posedness for nonnegative solutions in Sobolev
spaces and, under higher regularity, show both density and area remain
nonnegative. Uniqueness follows when the initial density's square root lies in
$H^2$, even if density vanishes on parts of the domain. We also exhibit initial
data that induce finite-time blow-up, highlighting potential singularity
formation. Finally, we establish that the density's spatial support remains
invariant and characterize the co-evolution of occupied area and population
density domains, offering new insights into pattern formation and mass
transport in biological tissues.

</details>


### [28] [Approximation of time-periodic flow past a translating body by flows in bounded domains](https://arxiv.org/abs/2507.23697)
*Thomas Eiter,Ana Leonor Silvestre*

Main category: math.AP

TL;DR: Existence and uniqueness of strong solutions for time-periodic 3D Navier-Stokes flow past a rigid body, with pointwise estimates. Truncated domain approximations with error analysis for velocity convergence.


<details>
  <summary>Details</summary>
Motivation: To analyze time-periodic flows around moving bodies, ensuring accurate solutions in unbounded domains via truncated approximations.

Method: Use of time-periodic Oseen equations for estimates; truncated domains with artificial boundary conditions for approximations.

Result: Existence/uniqueness of strong (exterior) and weak (truncated) solutions; velocity convergence as truncation radius grows.

Conclusion: The approach effectively approximates exterior flows, with proven convergence of truncated solutions to the exterior flow.

Abstract: We consider a time-periodic incompressible three-dimensional Navier-Stokes
flow past a translating rigid body. In the first part of the paper, we
establish the existence and uniqueness of strong solutions in the exterior
domain $\Omega \subset {\mathbb R}^3$ that satisfy pointwise estimates for both
the velocity and pressure. The fundamental solution of the time-periodic Oseen
equations plays a central role in obtaining these estimates. The second part
focuses on approximating this exterior flow within truncated domains $\Omega
\cap B_R$, incorporating appropriate artificial boundary conditions on
$\partial B_R$. For these bounded domain problems, we prove the existence and
uniqueness of weak solutions. Finally, we estimate the error in the velocity
component as a function of the truncation radius $R$, showing that, as $R \to
\infty$, the velocities of the truncated problems converge, in an appropriate
norm, to the velocity of the exterior flow.

</details>


### [29] [Nonlinear Vibrational Mode of Molecule with Octahedral Configuration](https://arxiv.org/abs/2507.23720)
*Jingzhou Liu*

Main category: math.AP

TL;DR: The paper explores nonlinear dynamics in octahedral molecules like SF6, proving the existence of periodic solutions with diverse symmetries using equivariant gradient degree.


<details>
  <summary>Details</summary>
Motivation: To understand the vibrational behavior and symmetry properties of octahedral molecules, particularly SF6.

Method: Applies the method of equivariant gradient degree under isotypic nonresonance assumptions.

Result: Identifies at least 16 distinct symmetry types of periodic solutions emerging from equilibrium.

Conclusion: The findings highlight rich vibrational dynamics in octahedral molecules, supported by numerical illustrations.

Abstract: In this work, we investigate the nonlinear dynamics of molecules with an
octahedral configuration, with particular focus on sulfur hexafluoride SF6.
Under the assumption of isotypic nonresonance, we apply the method of
equivariant gradient degree to prove the existence of branches of periodic
solutions emerging from the critical orbit of equilibrium, corresponding to at
least 16 distinct types of symmetries with maximal orbit kinds. Numerical
animations are presented to illustrate the detected vibrational modes.

</details>


### [30] [Renormalisation of singular SPDEs with Correlated Coefficients](https://arxiv.org/abs/2507.23737)
*Nicolas Clozeau,Harprit Singh*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We show local well-posedness of the g-PAM and the $\phi^{K+1}_2$-equation for
$K\geq 1$ on the two-dimensional torus when the coefficient field is random and
correlated to the driving noise. In the setting considered here, even when the
model in the sense of [Hai14] is stationary, naive use of renormalisation
constants in general leads to variance blow-up. Instead, we prove convergence
of renormalised models choosing random renormalisation functions analogous to
the deterministic variable coefficient setting. The main technical contribution
are stochastic estimates on the model in this correlated setting which are
obtained by a combination of heat kernel asymptotics, Gaussian integration by
parts formulae and Hairer--Quastel type bounds [HQ18].

</details>


### [31] [Hölder continuous dissipative solutions of ideal MHD with nonzero helicity](https://arxiv.org/abs/2507.23749)
*Alberto Enciso,Javier Peñafiel-Tomás,Daniel Peralta-Salas*

Main category: math.AP

TL;DR: Existence of weak solutions to 3D ideal MHD equations with non-conserved energy and cross helicity, while preserving magnetic helicity.


<details>
  <summary>Details</summary>
Motivation: To demonstrate non-conservation of energy and cross helicity in weak solutions while maintaining magnetic helicity, challenging symmetry-based assumptions.

Method: Novel convex integration scheme preserving magnetic helicity at each step, applicable on torus and compact spatial support in ℝ³.

Result: Construction of C^α weak solutions (α=10⁻⁸) where magnetic helicity is conserved but energy and cross helicity are not.

Conclusion: First example of continuous weak solutions where one conservation law is preserved while others are not, without relying on symmetry.

Abstract: We prove the existence of weak solutions to the 3D ideal MHD equations, of
class $C^\alpha$ with $\alpha=10^{-8}$, for which the total energy and the
cross helicity (i.e., the so-called Els\"asser energies) are not conserved. The
solutions do not possess any symmetry properties and the magnetic helicity,
which is necessarily conserved for H\"older continuous solutions, is nonzero.
The construction, which works both on the torus $\mathbb{T}^3$ and on
$\mathbb{R}^3$ with compact spatial support, is based on a novel convex
integration scheme in which the magnetic helicity is preserved at each step.
This is the first construction of continuous weak solutions at a regularity
level where one conservation law (here, the magnetic helicity) is necessarily
preserved while another (here, the total energy or cross helicity) is not, and
where the preservation of the former is nontrivial in the sense that it does
not follow from symmetry considerations.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [32] [Real-space Hubbard-corrected density functional theory](https://arxiv.org/abs/2507.23612)
*Sayan Bhowmik,Andrew J. Medford,Phanish Suryanarayana*

Main category: physics.comp-ph

TL;DR: A framework for Hubbard-corrected DFT in real-space is presented, offering accurate energy, forces, and stress tensor calculations, with superior efficiency and scalability compared to planewave methods.


<details>
  <summary>Details</summary>
Motivation: To improve the accuracy and efficiency of Hubbard-corrected DFT calculations in real-space, addressing limitations of existing planewave methods.

Method: Develops expressions for energy, forces, and stress tensor for real-space finite-difference discretization, and implements a parallel framework. Validates accuracy against planewave results.

Result: The framework is highly efficient and scalable, outperforming planewave codes by over an order of magnitude, especially for larger systems or more processors.

Conclusion: The framework is successfully applied to study exchange-correlation inconsistency in TiO$_2$ polymorphs and introduces a Hubbard parameter optimization scheme using hybrid functionals.

Abstract: We present an accurate and efficient framework for real-space
Hubbard-corrected density functional theory. In particular, we obtain
expressions for the energy, atomic forces, and stress tensor suitable for
real-space finite-difference discretization, and develop a large-scale parallel
implementation. We verify the accuracy of the formalism through comparisons
with established planewave results. We demonstrate that the implementation is
highly efficient and scalable, outperforming established planewave codes by
more than an order of magnitude in minimum time to solution, with increasing
advantages as the system size and/or number of processors is increased. We
apply this framework to examine the impact of exchange-correlation
inconsistency in local atomic orbital generation and introduce a scheme for
optimizing the Hubbard parameter based on hybrid functionals, both while
studying TiO$_2$ polymorphs.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [33] [Extensional rheology of dilute suspensions of spheres in polymeric liquids](https://arxiv.org/abs/2507.23114)
*Arjun Sharma,Donald L. Koch*

Main category: physics.flu-dyn

TL;DR: The study examines how dilute suspensions of spheres in viscoelastic liquids affect extensional rheology, revealing that polymer concentration and Deborah number influence viscosity changes through local flow-polymer interactions.


<details>
  <summary>Details</summary>
Motivation: Understanding how particle-polymer interactions in suspensions alter the extensional rheology of viscoelastic liquids, particularly focusing on viscosity changes under varying conditions.

Method: Computational analysis of dilute suspensions of spheres in viscoelastic liquids, examining effects of polymer concentration (c) and Deborah number (De) on local flow and polymer stretch.

Result: At low De (<0.5), stretched polymers increase suspension viscosity; at higher De, collapsed polymers reduce it. Higher c initially aligns local and far-field conditions but eventually introduces negative stress scaling as c².

Conclusion: Dilute sphere suspensions can effectively reduce viscosity in viscoelastic liquids at high De and c, driven by negative particle-polymer interaction stress.

Abstract: The extensional rheology of dilute suspensions of spheres in viscoelastic or
polymeric liquids is studied computationally. At low polymer concentration (c)
and Deborah number (De), a wake of highly stretched polymers forms downstream
of the particles due to larger local velocity gradients than the imposed flow,
indicated by a positive deviation in local De. This increases the suspension's
extensional viscosity with time and De for De less than 0.5. When De exceeds
0.5 (the coil-stretch transition), the fully stretched polymers from the far
field collapse in regions with lower local velocity gradients around the
particle's stagnation points, reducing suspension viscosity relative to the
polymer-only liquid. The interaction between local flow and polymers
intensifies with increasing c. Highly stretched polymers impede local flow,
reducing local De, while it increases in regions with collapsed polymers.
Initially, increasing c aligns local De and polymer stretch with far-field
values, diminishing particle-polymer interaction effects. However, beyond a
certain c, a new mechanism emerges. At low c, fluid three particle radii
upstream exhibits increased local De, stretching polymers beyond their
undisturbed state. As c increases, this deviation becomes negative, collapsing
polymers and resulting in increasingly negative stress from particle-polymer
interactions at large De and time. At high c, this negative interaction stress
scales as c squared, surpassing the linear increase in polymer stress, making
dilute sphere suspensions more effective at reducing the viscosity of
viscoelastic liquids at larger De and c.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [34] [Deriving effective electrode-ion interactions from free-energy profiles at electrochemical interfaces](https://arxiv.org/abs/2507.23031)
*Fabrice Roncoroni,Abrar Faiyad,Yichen Li,Tao Ye,Ashlie Martini,David Prendergast*

Main category: physics.chem-ph

TL;DR: The paper investigates ion adsorption at electrified interfaces using molecular dynamics and machine-learned potentials, highlighting the impact of force field parameterization and validating findings with experiments.


<details>
  <summary>Details</summary>
Motivation: Understanding ion adsorption at electrified metal-electrolyte interfaces is crucial for accurate electrochemical modeling.

Method: Enhanced sampling molecular dynamics with classical force fields and machine-learned interatomic potentials (MLIPs) are used to study free energy profiles of ions.

Result: Classical metadynamics shows parameter sensitivity, while MLIPs validate trends: chloride adsorbs strongly, fluoride weakly, and sodium not at all. Adsorption alters interfacial properties like capacitance.

Conclusion: Force field parameterization and advanced potentials are critical for predictive modeling, bridging molecular simulations and continuum electrochemical models.

Abstract: Understanding ion adsorption at electrified metal-electrolyte interfaces is
essential for accurate modeling of electrochemical systems. Here, we
systematically investigate the free energy profiles of Na$^+$, Cl$^-$, and
F$^-$ ions at the Au(111)-water interface using enhanced sampling molecular
dynamics with both classical force fields and machine-learned interatomic
potentials (MLIPs). Our classical metadynamics results reveal a strong
dependence of predicted ion adsorption on the Lennard-Jones parameters,
highlighting that --without due care-- standard mixing rules can lead to
qualitatively incorrect descriptions of ion-metal interactions. We present a
systematic methodology for tuning the cross-term LJ parameters to control
adsorption energetics in agreement with more accurate models. As a surrogate
for an ab initio model, we employed the recently released Universal Models for
Atoms (UMA) MLIP, which validates classical trends and displays strong specific
adsorption for chloride, weak adsorption for fluoride, and no specific
adsorption for sodium, in agreement with experimental and theoretical
expectations. By integrating molecular-level adsorption free energies into
continuum models of the electric double layer, we show that specific ion
adsorption substantially alters the interfacial ion population, the potential
of zero charge, and the differential capacitance of the system. Our results
underscore the critical importance of force field parameterization and advanced
interatomic potentials for the predictive modeling of ion-specific effects at
electrified interfaces and provide a robust framework for bridging molecular
simulations and continuum electrochemical models.

</details>


<div id='cond-mat.supr-con'></div>

# cond-mat.supr-con [[Back]](#toc)

### [35] [AC/DC spin current in ferromagnet/superconductor/normal metal trilayer systems](https://arxiv.org/abs/2507.23262)
*Koki Mizuno,Hirone Ishida,Manato Teranishi*

Main category: cond-mat.supr-con

TL;DR: Study of spin pumping in a trilayer system (FMI/SC/NM) under microwave irradiation, deriving AC and DC spin currents with classical and quantum treatments, using QTCI to reduce computational cost, and analyzing dependencies on temperature, frequency, and SC thickness.


<details>
  <summary>Details</summary>
Motivation: To explore spin pumping in a more complex trilayer system (FMI/SC/NM) and understand the behavior of spin currents under microwave irradiation, addressing computational challenges with QTCI.

Method: Derived AC (classical spin motion) and DC (quantum quasiparticles) spin currents in the NM layer, mitigated computational cost using QTCI, and analyzed dependencies on temperature, frequency, and SC thickness.

Result: Observed coherence peaks in temperature dependence of spin currents and a transition structure in SC thickness dependence, changing after a specific frequency.

Conclusion: The study provides insights into spin current behavior in trilayer systems, highlighting the role of quantum effects and computational efficiency with QTCI.

Abstract: Spin pumping with superconductors has been extensively studied, particularly
in double-layer systems. In this study, we investigate spin pumping in a
trilayer system comprising a ferromagnetic insulator (FMI), a superconductor
(SC), and a normal metal (NM). We derive the AC and DC spin currents in the NM
layer induced by spin motion in the FMI under circularly polarized microwave
irradiation. If we treat the spin motion as classical, the AC spin current is
expressed. On the other hand, if we treat the spin motion as quantum
quasiparticles, the DC spin current is derived. After these derivations, while
the computational cost of evaluating the spin current is extremely high, we
mitigate this using the Quantics Tensor Cross Interpolation (QTCI) method. We
present numerical results showing the dependence of the spin current on
temperature, microwave frequency, and superconductor layer thickness. Notably,
the temperature dependence of AC and DC spin currents exhibits a coherence
peak. Furthermore, we have discovered a transition structure in the dependence
of the spin current on the thickness of the superconductor layer, where the
dependence changes after a particular frequency.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [36] [Derivations of two one-dimensional models for transversely curved shallow shells: one leads to relaxation](https://arxiv.org/abs/2507.23545)
*Paroni Roberto,Picchi Scardaoni Marco*

Main category: math-ph

TL;DR: The paper analyzes the Γ-limit of variational problems for shallow shells as the width ε approaches zero, identifying two distinct regimes based on the scaling of stretching energy. Boundary conditions are crucial for compactness.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of shallow shells under varying energy scaling regimes and derive one-dimensional models for different cases.

Method: Study the Γ-limit of von Kármán-type energy for shallow shells, focusing on the scaling of stretching energy (∼ε^(2β)) and boundary conditions.

Result: For β ∈ (0,2), the limit membrane energy vanishes under compression (relaxation). For β=2, a nonlinear energy model emerges, coupling four kinematical descriptors. Special cases include nonlinear Vlasov torsion and Euler-Bernoulli beam theories.

Conclusion: The study reveals distinct behaviors in shallow shells depending on energy scaling, with boundary conditions playing a key role. The derived models provide insights into nonlinear mechanics.

Abstract: We study the $\Gamma$-limit of sequences of variational problems for
straight, transversely curved shallow shells, as the width of the planform
$\varepsilon$ goes to zero.
  The energy is of von K\'arm\'an type for shallow shells under suitable
boundary conditions. What distinguishes the various regimes is the scaling of
the stretching energy $\sim \varepsilon^{2\beta}$, with $\beta$ a positive
number. We derive two one-dimensional models as $\beta$ ranges in $(0, 2]$.
Remarkably, boundary conditions are essential to get compactness.
  We show that for $\beta \in (0, 2)$ the $\Gamma$-limit leads to relaxation:
the limit membrane energy vanishes on compression. For $\beta=2$ there is no
relaxation, and the limit model is a nonlinear energy coupling four kinematical
descriptors in a nontrivial way.
  As special cases of the latter limit model, a nonlinear Vlasov torsion theory
and a nonlinear Euler-Bernoulli beam theory can be deduced.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [AI paradigm for solving differential equations: first-principles data generation and scale-dilation operator AI solver](https://arxiv.org/abs/2507.23141)
*Xiangshu Gong,Zhiqiang Xie,Xiaowei Jin,Chen Wang,Yanling Qu,Wangmeng Zuo,Hui Li*

Main category: cs.LG

TL;DR: An AI paradigm for solving differential equations (DEs) using first-principles data generation and a scale-dilation operator (SDO) AI solver, addressing high-frequency approximation challenges and achieving superior accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing AI solvers struggle with high-frequency component approximation and data scarcity in solving DEs, limiting their practical usability.

Method: Proposes a DE-ruled first-principles data generation method and an SDO AI solver, leveraging Fourier transforms and a Transformer-based architecture to address high-frequency issues.

Result: Demonstrates consistently superior accuracy over state-of-the-art methods across diverse DEs, with a smoother loss landscape due to SDO.

Conclusion: The AI paradigm makes DE solvers truly usable in broad fields by overcoming data scarcity and high-frequency approximation challenges.

Abstract: Many problems are governed by differential equations (DEs). Artificial
intelligence (AI) is a new path for solving DEs. However, data is very scarce
and existing AI solvers struggle with approximation of high frequency
components (AHFC). We propose an AI paradigm for solving diverse DEs, including
DE-ruled first-principles data generation methodology and scale-dilation
operator (SDO) AI solver. Using either prior knowledge or random fields, we
generate solutions and then substitute them into the DEs to derive the sources
and initial/boundary conditions through balancing DEs, thus producing
arbitrarily vast amount of, first-principles-consistent training datasets at
extremely low computational cost. We introduce a reversible SDO that leverages
the Fourier transform of the multiscale solutions to fix AHFC, and design a
spatiotemporally coupled, attention-based Transformer AI solver of DEs with
SDO. An upper bound on the Hessian condition number of the loss function is
proven to be proportional to the squared 2-norm of the solution gradient,
revealing that SDO yields a smoother loss landscape, consequently fixing AHFC
with efficient training. Extensive tests on diverse DEs demonstrate that our AI
paradigm achieves consistently superior accuracy over state-of-the-art methods.
This work makes AI solver of DEs to be truly usable in broad nature and
engineering fields.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [38] [Physics-Informed PointNets for Modeling Electromagnetic Scattering from All-Dielectric Metasurfaces with Inclined Nanopillars](https://arxiv.org/abs/2507.23119)
*Leon Armbruster,Vlad Medvedev,Andreas Rosskopf*

Main category: physics.optics

TL;DR: A mesh-free Physics-Informed PointNet (PIPN) is introduced for modeling electromagnetic scattering in all-dielectric metasurfaces with irregular geometries, offering accuracy and computational efficiency.


<details>
  <summary>Details</summary>
Motivation: Conventional solvers struggle with accurate and efficient modeling of metasurfaces, especially those with irregular geometries, necessitating a new approach.

Method: The PIPN method uses PointNet architecture within a Physics-Informed Machine Learning (PIML) framework to encode spatially varying material properties.

Result: The method demonstrates generalization capability across datasets with varying refractive indices and inclination angles, simulating manufacturing defects.

Conclusion: PIPN provides a promising mesh-free framework for modeling complex optical structures efficiently and accurately.

Abstract: Metasurfaces are innovative planar optical structures capable of manipulating
incident light properties. Accurate and computationally efficient modeling of
such metasurfaces, particularly those with irregular geometries, remains a
challenge for conventional solvers. In this work, we present a mesh-free
Physics-Informed PointNet (PIPN) to model electromagnetic scattering from
all-dielectric metasurfaces that feature spatially varying nanopillars. Our
approach uses the PointNet architecture to directly encode spatially varying
material properties into the Physics-Informed Machine Learning (PIML)
framework. We demonstrate the generalization capability of our PIPN through
evaluations on datasets; these datasets are generated with varying refractive
indices representing common dielectric materials. Furthermore, the inclination
angles are varied within each dataset, which represent expected manufacturing
defects. Overall, our method provides a promising, mesh-free framework for
accurate and efficient modeling of complex optical structures represented by
irregular geometries.

</details>


### [39] [Conical diffraction of the synchrotron beam to probe the efficiency and morphology of blazed gratings](https://arxiv.org/abs/2507.23513)
*K. V. Nikolaev,L. I. Goray,P. S. Savchenkov,A. V. Rogachev,A. A. Chouprik,T. N. Berezovskaya,D. V. Mokhov,S. A. Garakhin,N. I. Chkhalo,A. D. Buravleuv,S. N. Yakunin*

Main category: physics.optics

TL;DR: Synchrotron measurements are evaluated as a nanometrology tool for blazed gratings, analyzing diffraction and diffuse scattering to assess groove profiles and surface roughness.


<details>
  <summary>Details</summary>
Motivation: To highlight synchrotron measurements as a modern tool for nanometrology in optical elements, particularly blazed gratings.

Method: Combines synchrotron measurements with numerical simulations (Helmholtz equation solvers and perturbation theory) and data from atomic force microscopy and scanning electron microscopy.

Result: Diffraction patterns reveal average groove profiles, while diffuse scattering indicates surface roughness morphology.

Conclusion: Synchrotron measurements are a valuable tool for characterizing blazed gratings, offering insights into both groove profiles and surface roughness.

Abstract: This study explores the use of synchrotron measurements as a nanometrology
tool for blazed gratings. In grazing incidence geometry, one can measure both
the conical diffraction and the diffuse scattering on the grating
simultaneously in a single scattering pattern. The sensitivity of scattering
patterns to the structure of the blazed gratings is evaluated. The diffraction
component of the pattern is shown to be sensitive to the average groove profile
of the gratings. Meanwhile, the diffuse scattering depends on the roughness
morphology of the reflective surface of blazed gratings. These findings are
supported by numerical simulations. The simulations were performed using
several rigorous solvers for the Helmholtz equations, and with a perturbation
theory. The analysis relies on synchrotron data, as well as data from atomic
force microscopy and scanning electron microscopy. The aim of this article is
to draw the attention of the optical community to the synchrotron measurements
as a nanometrology tool for the modern optical elements.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [40] [Existence of genus 2 minimal surfaces in 3-spheres. I](https://arxiv.org/abs/2507.23239)
*Adrian Chun-Pong Chu,Yangyang Li,Zhihan Wang*

Main category: math.DG

TL;DR: The paper proves the existence of an embedded minimal surface of genus 2 in 3-spheres with positive Ricci curvature and generalizes this to relate minimal surfaces' existence to topological properties in 3-manifolds.


<details>
  <summary>Details</summary>
Motivation: The study aims to understand the relationship between geometric conditions (like Ricci curvature) and the existence of minimal surfaces, extending results to broader topological contexts.

Method: The proof involves geometric analysis and topological arguments, linking minimal surfaces' existence to the structure of embedded singular surfaces.

Result: The main result confirms the existence of genus 2 minimal surfaces in 3-spheres with positive Ricci curvature and provides a general theorem for 3-manifolds.

Conclusion: The findings contribute to the understanding of minimal surfaces in geometric and topological settings, with implications for further research in differential geometry.

Abstract: We prove that every 3-sphere of positive Ricci curvature contains some
embedded minimal surface of genus 2.
  We also establish a theorem for more general 3-manifolds that relates the
existence of genus $g$ minimal surfaces to topological properties regarding the
set of all embedded singular surfaces of genus $\leq g$.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [41] [Matching Large Deviation Bounds of the Zero-Range Process in the whole space](https://arxiv.org/abs/2507.23452)
*Benjamin Fehrman,Benjamin Gess,Daniel Heydecker*

Main category: math.PR

TL;DR: The paper resolves the large deviations problem for the hydrodynamic rescaling of the zero-range process in any dimension, extending prior results and removing restrictive assumptions.


<details>
  <summary>Details</summary>
Motivation: To address the unresolved problem of large deviations for the zero-range process's hydrodynamic rescaling, particularly in higher dimensions, and to generalize existing theoretical frameworks.

Method: Extends superexponential estimates to any dimension, proves concentration on paths with finite entropy dissipation, and generalizes the parabolic-hyperbolic skeleton equation theory without global convexity/concavity assumptions.

Result: Matching upper and lower bounds for large deviations are obtained, resolving the problem posed by prior work.

Conclusion: The study successfully generalizes and resolves key issues in the large deviations theory for the zero-range process, providing a more robust and widely applicable framework.

Abstract: We consider the large deviations of the hydrodynamic rescaling of the
zero-range process on $\mathbb{Z}^d$ in any dimension $d\ge 1$. Under mild and
canonical hypotheses on the local jump rate, we obtain matching upper and lower
bounds, thus resolving the problem opened by \cite{KL99}. On the probabilistic
side, we extend the superexponential estimate to any dimension, and prove the
superexponential concentration on paths with finite entropy dissipation. In
addition, we extend the theory of the parabolic-hyperbolic skeleton equation to
the whole space, and remove global convexity/concavity assumptions on the
nonlinearity.

</details>
