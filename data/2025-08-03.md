<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 13]
- [math.AP](#math.AP) [Total: 18]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [math-ph](#math-ph) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [math.DG](#math.DG) [Total: 1]
- [cond-mat.supr-con](#cond-mat.supr-con) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [math.PR](#math.PR) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [physics.optics](#physics.optics) [Total: 2]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Convergence analysis of a second-order SAV-ZEC scheme for the Cahn-Hilliard-Navier-Stokes system](https://arxiv.org/abs/2507.22949)
*Jingwei Sun,Zeyu Xia,Wei Zhang*

Main category: math.NA

TL;DR: A linear, decoupled numerical scheme for the CHNS system using SAV-ZEC, MAC finite difference, BDF2, and Adams-Bashforth, ensuring unconditional stability and optimal convergence rates.


<details>
  <summary>Details</summary>
Motivation: To develop a stable and efficient numerical method for the CHNS system by leveraging SAV-ZEC reformulation and decoupling techniques.

Method: Combines MAC finite difference, BDF2 temporal discretization, Adams-Bashforth for nonlinear terms, and pressure correction for the Stokes equation.

Result: Unconditionally stable scheme with optimal error estimates for phase and velocity variables in specified norms.

Conclusion: The proposed scheme is effective, stable, and achieves optimal convergence rates for the CHNS system.

Abstract: Incorporating the scalar auxiliary variable (SAV) method and the zero energy
contribution (ZEC) technique, we analyze a linear and fully decoupled numerical
scheme for the Cahn-Hilliard-Naiver-Stokes (CHNS) system. More precisely, the
fully discrete scheme combines the marker-and-cell (MAC) finite difference
spatial approximation and BDF2 temporal discretization, as well as the
Adams-Bashforth extrapolation for the nonlinear terms, based on the SAV-ZEC
reformulation. A pressure correction approach is applied to decouple the Stokes
equation. Only constant-coefficient Poisson-like solvers are needed in the
implementation for the resulting numerical system. The numerical scheme is
unconditionally stable with respect to a rewritten total energy functional,
represented in terms of one auxiliary variable in the double-well potential,
another auxiliary variable to balance all the nonlinear and coupled terms, the
surface energy in the original phase variable, combined with the kinematic
energy part. Specifically, the error estimate for the phase variable in the
$\ell^{\infty}(0,T;H_h^1)\cap\ell^2(0,T;H_h^3)$ norm, the velocity variable in
the $\ell^{\infty}(0,T;\ell^2)\cap\ell^2(0,T;H_h^1)$ norm, is derived with
optimal convergence rates.

</details>


### [2] [Hybrid Shifted Gegenbauer Integral-Pseudospectral Method for Solving Time-Fractional Benjamin-Bona-Mahony-Burgers Equation](https://arxiv.org/abs/2507.23099)
*Kareem T. Elgindy*

Main category: math.NA

TL;DR: The paper introduces a high-order hybrid shifted Gegenbauer integral-pseudospectral (HSG-IPS) method for solving the time-fractional Benjamin-Bona-Mahony-Burgers (FBBMB) equation, achieving spectral accuracy and outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: To address numerical instability and inefficiency in solving the FBBMB equation by transforming it into a fractional partial-integro differential form and leveraging advanced numerical techniques.

Method: The HSG-IPS method combines shifted Gegenbauer pseudospectral techniques, fractional approximations, and integration matrices to transform and solve the equation with spectral accuracy.

Result: Numerical experiments show significantly lower errors (AAEs) and fast computational times (0.04-0.05s), with robustness across fractional orders and agreement with analytical solutions.

Conclusion: The method provides a stable, efficient framework for modeling wave propagation and nonlinearity in fractional calculus, avoiding instability from high-order derivatives.

Abstract: This paper presents a high-order hybrid shifted Gegenbauer
integral-pseudospectral (HSG-IPS) method for solving the time-fractional
Benjamin-Bona-Mahony-Burgers (FBBMB) equation. A key innovation of our approach
is the transformation of the original equation into a fractional
partial-integro differential form that contains only a first-order derivative,
which can be accurately approximated using a first-order shifted Gegenbauer
differentiation matrix (SGDM), while all other terms in the transformed
equation are resolved using highly accurate quadrature rules. The method
combines several advanced numerical techniques including the shifted Gegenbauer
pseudospectral (SGPS) method, Gegenbauer-based fractional approximation (GBFA),
shifted Gegenbauer integration matrix (SGIM), shifted Gegenbauer integration
row vector (SGIRV), and SGDM to achieve spectral accuracy. Numerical
experiments demonstrate that the HSG-IPS method outperforms existing numerical
approaches, achieving significantly lower average absolute errors (AAEs) with
computational times as low as 0.04-0.05 seconds. The method's robustness is
validated across various fractional orders, showing excellent agreement with
analytical solutions. The transformation strategy effectively circumvents the
numerical instability associated with direct approximation of high-order
derivatives in the original equation, while the use of shifted Gegenbauer (SG)
polynomials and barycentric representations ensures numerical stability and
efficiency. This work provides a powerful computational framework for modeling
wave propagation, dispersion, and nonlinearity in fractional calculus
applications.

</details>


### [3] [$hp$-adaptive finite element simulation of a static anti-plane shear crack in a nonlinear strain-limiting elastic solid](https://arxiv.org/abs/2507.23195)
*S. M. Mallikarjunaiah,Pavithra Venkatachalapthy*

Main category: math.NA

TL;DR: An $hp$-adaptive finite element method is developed for analyzing static anti-plane shear cracks in nonlinear strain-limiting elastic bodies, ensuring well-posedness and accuracy through adaptive refinement and error estimation.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of modeling cracks in nonlinear elastic materials with bounded, monotone, coercive, and Lipschitz continuous constitutive laws, ensuring robust numerical solutions.

Method: An $hp$-adaptive continuous Galerkin finite element method, combining $h$-adaptivity (mesh refinement) and $p$-adaptivity (polynomial degree adjustment), guided by residual-based error indicators and local solution regularity estimators.

Result: The method demonstrates high accuracy and convergence in numerical experiments, effectively capturing crack-tip fields and providing a foundation for more complex problems like dynamic crack propagation.

Conclusion: The proposed $hp$-adaptive framework is effective for nonlinear crack analysis and scalable for advanced applications in fracture mechanics.

Abstract: An $hp$-adaptive continuous Galerkin finite element method is developed to
analyze a static anti-plane shear crack embedded in a nonlinear,
strain-limiting elastic body. The geometrically linear material is described by
a constitutive law relating stress and strain that is algebraically nonlinear.
In this investigation, the constitutive relation utilized is \textit{uniformly
bounded}, \textit{monotone}, \textit{coercive}, and \textit{Lipschitz
continuous}, ensuring the well-posedness of the mathematical model. The
governing equation, derived from the balance of linear momentum coupled with
the nonlinear constitutive relationship, is formulated as a second-order
quasi-linear elliptic partial differential equation. For a body with an edge
crack, this governing equation is augmented with a classical traction-free
boundary condition on the crack faces. An $hp$-adaptive finite element scheme
is proposed for the numerical approximation of the resulting boundary value
problem. The adaptive strategy is driven by a dual-component error estimation
scheme: mesh refinement ($h$-adaptivity) is guided by a residual-based a
posteriori error indicator of the \textit{Kelly type}, while the local
polynomial degree ($p$-adaptivity) is adjusted based on an estimator of the
local solution regularity. The performance, accuracy, and convergence
characteristics of the proposed method are demonstrated through numerical
experiments. The structure of the regularized crack-tip fields is examined for
various modeling parameters. Furthermore, the presented framework establishes a
robust foundation for extension to more complex and computationally demanding
problems, including quasi-static and dynamic crack propagation in brittle
materials.

</details>


### [4] [Error analysis of the projected PO method with additive inflation for the partially observed Lorenz 96 model](https://arxiv.org/abs/2507.23199)
*Kota Takeda*

Main category: math.NA

TL;DR: The paper establishes the error bound of the PO method, a variant of the EnKF, for the partially observed Lorenz 96 model, using additive inflation and covariance projection.


<details>
  <summary>Details</summary>
Motivation: The accuracy of the EnKF for the Lorenz 96 model is unverified, motivating the study of the PO method's error bounds.

Method: The PO method is analyzed with additive inflation and projection of background covariance to the observation space.

Result: Theoretical error bounds are derived and validated numerically, showing potential for further analysis.

Conclusion: The study successfully establishes the PO method's error bounds, supported by numerical validation.

Abstract: We consider the filtering problem with the partially observed Lorenz 96
model. Although the accuracy of the 3DVar filter applied to this problem has
been established, that of the EnKF has not yet been. This study aims to
establish the error bound of a variant of the EnKF, known as the PO method. By
introducing the additive inflation and a projection of the background
covariance to the observation space, we establish the error bound of the PO
method. A numerical example validates theoretical findings and shows the
potential to extend the analysis.

</details>


### [5] [Improved Analysis of Khatri-Rao Random Projections and Applications](https://arxiv.org/abs/2507.23207)
*Arvind K. Saibaba,Bhisham Dev Verma,Grey Ballard*

Main category: math.NA

TL;DR: The paper explores randomized algorithms for matrix and tensor decompositions, focusing on Khatri-Rao random projections (KRPs) as a cost-effective alternative to Gaussian random matrices. It provides improved theoretical guarantees for KRPs and introduces new algorithms for low-rank approximations of block-structured matrices and tensor computations.


<details>
  <summary>Details</summary>
Motivation: Standard Gaussian random matrices are expensive to generate and multiply, while KRPs are cheaper but lack strong theoretical guarantees. The paper aims to bridge this gap by improving the analysis and performance of KRPs.

Method: The authors propose new algorithms for low-rank approximations of block-structured matrices (e.g., block Hankel) and tensor computations in the Tucker format using KRPs. Theoretical guarantees are provided for these methods.

Result: Numerical experiments on synthetic and real-world tensors demonstrate the computational efficiency and effectiveness of the proposed methods.

Conclusion: The study successfully improves the theoretical understanding and practical application of KRPs, offering efficient alternatives for large-scale matrix and tensor decompositions.

Abstract: Randomization has emerged as a powerful set of tools for large-scale matrix
and tensor decompositions. Randomized algorithms involve computing sketches
with random matrices. A prevalent approach is to take the random matrix as a
standard Gaussian random matrix, for which the theory is well developed.
However, this approach has the drawback that the cost of generating and
multiplying by the random matrix can be prohibitively expensive. Khatri-Rao
random projections (KRPs), obtained by sketching with Khatri-Rao products of
random matrices, offer a viable alternative and are much cheaper to generate.
However, the theoretical guarantees of using KRPs are much more pessimistic
compared to their accuracy observed in practice. We attempt to close this gap
by obtaining improved analysis of the use of KRPs in matrix and tensor low-rank
decompositions. We propose and analyze a new algorithm for low-rank
approximations of block-structured matrices (e.g., block Hankel) using KRPs. We
also develop new algorithms to accelerate tensor computations in the Tucker
format using KRPs, and give theoretical guarantees of the resulting low-rank
approximations. Numerical experiments on synthetic and real-world tensors show
the computational benefits of the proposed methods.

</details>


### [6] [An optimal preconditioner for high-order scheme arising from multi-dimensional Riesz space fractional diffusion equations with variable coefficients](https://arxiv.org/abs/2507.23408)
*Yuan-Yuan Huang,Wei Qu,Sean Y. Hon,Siu-Long Lei*

Main category: math.NA

TL;DR: Proposes an efficient CN-4FCD scheme for multi-dimensional Riesz space fractional diffusion equations, ensuring stability, convergence, and high accuracy, with a sine transform-based preconditioner for computational efficiency.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenge of solving multi-dimensional Riesz space fractional diffusion equations with variable coefficients efficiently and accurately.

Method: Uses Crank-Nicolson (CN) for temporal discretization and fourth-order fractional centered difference (4FCD) for spatial discretization, with a sine transform-based preconditioner.

Result: The CN-4FCD scheme is unconditionally stable and convergent, achieving second-order accuracy in time and fourth-order in space, with enhanced computational efficiency.

Conclusion: Numerical examples validate the scheme's superiority and efficiency, demonstrating its practical applicability.

Abstract: In this paper, we propose an efficient method for solving multi-dimensional
Riesz space fractional diffusion equations with variable coefficients. The
Crank-Nicolson (CN) method is used for temporal discretization, while the
fourth-order fractional centered difference (4FCD) method is employed for
spatial discretization. Using a novel technique, we show that the CN-4FCD
scheme for the multi-dimensional case is unconditionally stable and convergent,
achieving second-order accuracy in time and fourth-order accuracy in space with
respect to the discrete L2-norm. Moreover, leveraging the symmetric multi-level
Toeplitz-like structure of the coefficient matrix in the discrete linear
systems, we enhance the computational efficiency of the proposed scheme with a
sine transform-based preconditioner, ensuring a mesh-size-independent
convergence rate for the conjugate gradient method. Finally, two numerical
examples validate the theoretical analysis and demonstrate the superior
performance of the proposed preconditioner compared to existing methods.

</details>


### [7] [The Effect of Prior Parameters on Standardized Kalman Filter-Based EEG Source Localization](https://arxiv.org/abs/2507.23450)
*Dilshanie Prasikala,Joonas Lahtinen,Alexandra Koulouri,Sampsa Pursiainen*

Main category: math.NA

TL;DR: The paper explores EEG source localization using the Standardized Kalman Filter (SKF), optimizing Gaussian prior models for detecting cortical and sub-cortical activity. It highlights improved depth localization accuracy with specific parameter adjustments and smoothing.


<details>
  <summary>Details</summary>
Motivation: EEG source localization is vital for neuroscience but faces challenges like depth bias and lack of unique solutions. The study aims to enhance SKF's performance for detecting deep and superficial sources.

Method: The study uses synthetic data resembling somatosensory evoked potentials (SEP) to test Gaussian prior models within the SKF framework. It evaluates parameter configurations and RTS smoothing for source separability.

Result: Raising the standardization exponent to 1.25 and applying smoothing significantly improves depth localization accuracy, especially at low noise levels.

Conclusion: The SKF framework, with optimized Gaussian priors and smoothing, effectively addresses depth bias and enhances source localization for both cortical and sub-cortical activity.

Abstract: EEG Source localization is a critical tool in neuroscience, with applications
ranging from epilepsy diagnosis to cognitive research. It involves solving an
ill-posed inverse problem that lacks a unique solution unless constrained by
prior knowledge. The Bayesian framework enables the incorporation of such
knowledge, typically encoded through prior models. Various algorithms have been
proposed for source localization, and they differ significantly in how prior
knowledge is incorporated. Some approaches rely on anatomical or functional
constraints, while others use statistical distributions or sampling-based
techniques. In this landscape, the Standardized Kalman Filter (SKF) represents
a dynamic Bayesian approach that integrates temporal modeling with a Gaussian
prior structure. It addresses the depth bias, a common limitation in source
localization, through a post-hoc standardization step that equalizes
sensitivity across cortical depths and makes deep activity detection feasible.
  This study focuses on the development and optimization of Gaussian prior
models within the SKF framework for simultaneous cortical and sub-cortical
activity detection. Synthetic data similar to the P20 / N20 component of the
somatosensory evoked potentials (SEP) was used to identify effective prior
parameter configurations for reconstructing both deep and superficial sources
under different noise levels. We also investigated the role of RTS smoothing in
enhancing source separability. Our results indicate that raising the
standardization exponent to 1.25, along with smoothing, significantly improves
depth localization accuracy at low noise levels.

</details>


### [8] [Rational complex Bezier curves](https://arxiv.org/abs/2507.23485)
*A. Canton,L. Fernandez-Jambrina,M. J. Vazquez-Gallo*

Main category: math.NA

TL;DR: The paper introduces rational complex Bézier curves, extending CAD paradigms with complex control polygons and weights, enabling new transformations and degree reduction.


<details>
  <summary>Details</summary>
Motivation: To extend traditional Bézier curves by incorporating complex values, allowing more flexible transformations and potential degree reduction in curve representation.

Method: Develops a formalism for rational complex Bézier curves, using complex projective transformations and polynomial resultants to analyze curve properties.

Result: Demonstrates that complex formulations enable useful transformations (e.g., geometric inversion) and can reduce curve degrees, with a formula to identify conics in rational cubic curves.

Conclusion: The framework enhances curve design with complex values, offering practical advantages like transformation flexibility and simplified curve analysis.

Abstract: In this paper we develop the formalism of rational complex Bezier curves.
This framework is a simple extension of the CAD paradigm, since it describes
arc of curves in terms of control polygons and weights, which are extended to
complex values. One of the major advantages of this extension is that we may
make use of two different groups of projective transformations. Besides the
group of projective transformations of the real plane, we have the group of
complex projective transformations. This allows us to apply useful
transformations like the geometric inversion to curves in design. In addition
to this, the use of the complex formulation allows to lower the degree of the
curves in some cases. This can be checked using the resultant of two
polynomials and provides a simple formula for determining whether a rational
cubic curve is a conic or not. Examples of application of the formalism to
classical curves are included.

</details>


### [9] [Quantum simulation of Helmholtz equations via Schr{ö}dingerization](https://arxiv.org/abs/2507.23547)
*Anjiao Gu,Shi Jin,Chuwen Ma*

Main category: math.NA

TL;DR: A quantum algorithm for solving the Helmholtz equation, leveraging the Schrödingerization framework, achieves efficient query complexity with asymptotic dispersion correction and preconditioning.


<details>
  <summary>Details</summary>
Motivation: The Helmholtz equation's challenges (indefiniteness, large system sizes) motivate a quantum solution for efficient computation.

Method: The Schrödingerization framework reformulates the problem into a quantum-compatible system, using a warped phase transformation and dispersion correction.

Result: Query complexity is reduced to O(κ polylog ε⁻¹) for the Helmholtz equation with preconditioning.

Conclusion: The method is broadly applicable to indefinite problems, offering a quantum advantage.

Abstract: The Helmholtz equation is a prototypical model for time-harmonic wave
propagation. Numerical solutions become increasingly challenging as the wave
number $k$ grows, due to the equation's elliptic yet noncoercive character and
the highly oscillatory nature of its solutions, with wavelengths scaling as
$1/k$. These features lead to strong indefiniteness and large system sizes.
  We present a quantum algorithm for solving such indefinite problems, built
upon the Schr\"odingerization framework. This approach reformulates linear
differential equations into Schr\"odinger-type systems by capturing the steady
state of damped dynamics. A warped phase transformation lifts the original
problem to a higher-dimensional formulation, making it compatible with quantum
computation. To suppress numerical pollution, the algorithm incorporates
asymptotic dispersion correction. It achieves a query complexity of
$\mathcal{O}(\kappa^2\text{polylog}\varepsilon^{-1})$, where $\kappa$ is the
condition number and $\varepsilon$ the desired accuracy. For the Helmholtz
equation, a simple preconditioner further reduces the complexity to
$\mathcal{O}(\kappa\text{polylog}\varepsilon^{-1})$. Our constructive extension
to the quantum setting is broadly applicable to all indefinite problems.

</details>


### [10] [Fitted norm preconditioners for the Hodge Laplacian in mixed form](https://arxiv.org/abs/2507.23586)
*Wietse M. Boon,Johannes Kraus,Tomáš Luber,Maria Lymbery*

Main category: math.NA

TL;DR: The paper analyzes the mixed formulation of the Hodge Laplace problem using perturbed saddle point theory, ensuring well-posedness and proposing a simplified, efficient preconditioner.


<details>
  <summary>Details</summary>
Motivation: To address the well-posedness and computational efficiency of the Hodge Laplace problem in mixed formulations.

Method: Uses parameter-dependent norms for uniform continuity and stability, simplifying these norms to derive a norm-equivalent preconditioner.

Result: Demonstrates fast convergence and uniform performance of the preconditioner in solving Hodge Laplace problems in 2D and 3D.

Conclusion: The proposed framework ensures well-posedness and provides an efficient, implementable preconditioner for the Hodge Laplace problem.

Abstract: We use the practical framework for abstract perturbed saddle point problems
recently introduced by Hong et al. to analyze the mixed formulation of the
Hodge Laplace problem. We compose two parameter-dependent norms in which the
uniform continuity and stability of the problem follow. This not only
guarantees the well-posedness of the corresponding variational formulation on
the continuous level, but also of related compatible discrete models.
  We further simplify the obtained norms and, in both cases, arrive at the same
norm-equivalent preconditioner that is easily implementable. The efficiency and
uniformity of the preconditioner are demonstrated numerically by the fast
convergence and uniformly bounded number of preconditioned MINRES iterations
required to solve various instances of Hodge Laplace problems in two and three
space dimensions.

</details>


### [11] [Efficient Numerical Strategies for Entropy-Regularized Semi-Discrete Optimal Transport](https://arxiv.org/abs/2507.23602)
*Moaad Khamlich,Francesco Romor,Gianluigi Rozza*

Main category: math.NA

TL;DR: The paper addresses computational challenges in semi-discrete optimal transport (SOT) with entropic regularization, proposing a framework combining truncation, spatial queries, multilevel techniques, and scheduling to enable large-scale applications.


<details>
  <summary>Details</summary>
Motivation: The computational bottleneck in evaluating the dual objective function for RSOT, especially with finite element discretization, limits practical applications.

Method: The framework combines distance-based truncation, R-tree spatial queries, multilevel techniques for FE mesh and target measure, and a scheduling strategy for regularization.

Result: The unified methods significantly reduce computational costs, making RSOT feasible for large-scale problems.

Conclusion: The proposed framework and open-source implementation enable practical use of RSOT in complex scenarios.

Abstract: Semi-discrete optimal transport (SOT), which maps a continuous probability
measure to a discrete one, is a fundamental problem with wide-ranging
applications. Entropic regularization is often employed to solve the SOT
problem, leading to a regularized (RSOT) formulation that can be solved
efficiently via its convex dual. However, a significant computational challenge
emerges when the continuous source measure is discretized via the finite
element (FE) method to handle complex geometries or densities, such as those
arising from solutions to Partial Differential Equations (PDEs). The evaluation
of the dual objective function requires dense interactions between the numerous
source quadrature points and all target points, creating a severe bottleneck
for large-scale problems. This paper presents a cohesive framework of numerical
strategies to overcome this challenge. We accelerate the dual objective and
gradient evaluations by combining distance-based truncation with fast spatial
queries using R-trees. For overall convergence, we integrate multilevel
techniques based on hierarchies of both the FE source mesh and the discrete
target measure, alongside a robust scheduling strategy for the regularization
parameter. When unified, these methods drastically reduce the computational
cost of RSOT, enabling its practical application to complex, large-scale
scenarios. We provide an open-source C++ implementation of this framework,
built upon the deal.II finite element library, available at
https://github.com/SemiDiscreteOT/SemiDiscreteOT.

</details>


### [12] [A Multi-Frequency Helmholtz Solver Based on the WaveHoltz Algorithm](https://arxiv.org/abs/2507.23613)
*Daniel Appelö,Francis Appiah,Jeffrey W. Banks,Cassandra Carrick,William D. Henshaw,Donald W. Schwendeman*

Main category: math.NA

TL;DR: The paper introduces the Multi-Frequency WaveHoltz (MFWH) algorithm, an extension of the WaveHoltz method, for simultaneously solving Helmholtz equations for multiple frequencies and forcing functions using time-filtered wave equation solutions.


<details>
  <summary>Details</summary>
Motivation: The need for efficient computation of multiple Helmholtz solutions for varying frequencies and forcing functions motivates the development of the MFWH algorithm.

Method: MFWH combines a single wave equation solution with multiple time filters, uses fixed-point iteration accelerated by Krylov methods, and employs efficient time-stepping (explicit or implicit) with high-order spatial accuracy.

Result: The algorithm achieves O(N) solution cost with fixed frequencies and increasing grid points, and numerical results confirm convergence to discretized Helmholtz solutions.

Conclusion: MFWH is an efficient and accurate method for solving Helmholtz problems, validated by theoretical and numerical results.

Abstract: We develop and analyze a new approach for simultaneously computing multiple
solutions to the Helmholtz equation for different frequencies and different
forcing functions. The new Multi-Frequency WaveHoltz (MFWH) algorithm is an
extension of the original WaveHoltz method and both are based on time-filtering
solutions to an associated wave equation. With MFWH, the different Helmholtz
solutions are computed simultaneously by solving a single wave equation
combined with multiple time filters. The MFWH algorithm defines a fixed-point
iteration which can be accelerated with Krylov methods such as GMRES. The
solution of the wave equation can be efficiently solved with either explicit
time-stepping or implicit time-stepping using as few as five time-steps per
period. When combined with an $O(N)$ solver for the implicit equations, such a
multigrid, the scheme has an $O(N)$ solution cost when the frequencies are
fixed and the number of grid points $N$ increases. High-order accurate
approximations in space are used together with second-order accurate
approximations in time. We show how to remove time discretization errors so
that the MFWH solutions converge to the corresponding solutions to the
discretized Helmholtz problems. Numerical results are given using second-order
accurate and fourth-accurate discretizations to confirm the convergence theory.

</details>


### [13] [Regularization of Inverse Problems by Filtered Diagonal Frame Decomposition under general source](https://arxiv.org/abs/2507.23651)
*Dang Duc Trong,Nguyen Dang Minh,Luu Xuan Thang,Luu Dang Khoa*

Main category: math.NA

TL;DR: The paper explores regularization methods for solving ill-posed inverse problems in Hilbert spaces, focusing on Diagonal Frame Decomposition (DFD) as an alternative to SVD. It introduces a regularized solution and analyzes convergence rates under generalized source conditions.


<details>
  <summary>Details</summary>
Motivation: To address the computational challenges of SVD in solving ill-posed inverse problems and provide a more practical alternative via DFD.

Method: The study employs DFD to generalize SVD-based techniques, introduces a regularized solution, and analyzes convergence rates under a generalized source condition.

Result: Theoretical results include modulus of continuity bounds and convergence rates for a priori and a posteriori parameter choices, applicable to polynomial and exponentially ill-posed problems.

Conclusion: DFD offers a viable alternative to SVD for regularization, with theoretical guarantees on convergence and optimality under generalized source conditions.

Abstract: Let $X$ and $Y$ be Hilbert spaces, and $\mathbf{K}: \text{dom} \mathbf{K}
\subset X \to Y$ a bounded linear operator. This paper addresses the inverse
problem $\mathbf{K}x = y$, where exact data $y$ is replaced by noisy data
$y^\delta$ satisfying $\|y^\delta - y\|_Y \leq \delta$. Due to the
ill-posedness of such problems, we employ regularization methods to stabilize
solutions. While singular value decomposition (SVD) provides a classical
approach, its computation can be costly and impractical for certain operators.
We explore alternatives via Diagonal Frame Decomposition (DFD), generalizing
SVD-based techniques, and introduce a regularized solution $x^\delta_\alpha =
\sum_{\lambda \in \Lambda} \kappa_\lambda g_\alpha(\kappa_\lambda^2) \langle
y^\delta, v_\lambda \rangle \overline{u}_\lambda$. Convergence rates and
optimality are analyzed under a generalized source condition
$\mathbf{M}_{\varphi, E} = \{ x \in \text{dom} \mathbf{K} : \sum_{\lambda \in
\Lambda} [\varphi(\kappa_\lambda^2)]^{-1} |\langle x, u_\lambda \rangle|^2 \leq
E^2 \}$. Key questions include constructing DFD systems, relating DFD and SVD
singular values, and extending source conditions. We present theoretical
results, including modulus of continuity bounds and convergence rates for a
priori and a posteriori parameter choices, with applications to polynomial and
exponentially ill-posed problems.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [14] [Mean-field approximation, Gibbs relaxation, and cross estimates](https://arxiv.org/abs/2507.23123)
*Armand Bernou,Mitia Duerinckx*

Main category: math.AP

TL;DR: The paper improves the mean-field approximation error for a system of Brownian particles by showing a cross error of $O(N^{-1}e^{-ct})$ between chaos propagation and Gibbs relaxation.


<details>
  <summary>Details</summary>
Motivation: To advance understanding of chaos propagation and Gibbs relaxation in systems of Brownian particles with weak mean-field interactions.

Method: Detailed analysis of the BBGKY hierarchy for correlation functions, applied to underdamped and overdamped Langevin dynamics with bounded interaction forces.

Result: Improved mean-field approximation error at the one-particle density level, reducing from $O(N^{-1})$ to $O(N^{-1}e^{-ct})$.

Conclusion: The approach provides new insights into Gibbs relaxation and extends partially beyond weak interactions, enhancing the understanding of such systems.

Abstract: This work focuses on the propagation of chaos and the relaxation to Gibbs
equilibrium for a system of $N$ classical Brownian particles with weak
mean-field interactions. While it is known that propagation of chaos holds at
rate $O(N^{-1})$ uniformly in time, and Gibbs relaxation at rate $O(e^{-ct})$
uniformly in $N$, we go a step further by showing that the cross error between
chaos propagation and Gibbs relaxation is $O(N^{-1}e^{-ct})$. For
translation-invariant systems on the torus, this leads to an improved
mean-field approximation error at the level of the one-particle density: the
error decreases from $O(N^{-1})$ to $O(N^{-1}e^{-ct})$. Our approach relies on
a detailed analysis of the BBGKY hierarchy for correlation functions, and
applies to both underdamped and overdamped Langevin dynamics with merely
bounded interaction forces. We also derive new results on Gibbs relaxation and
present partial extensions beyond the weak interaction regime.

</details>


### [15] [A note on the first Steklov eigenvalue on planar domains](https://arxiv.org/abs/2507.23312)
*Azahara DelaTorre,Gabriele Mancini,Angela Pistoia,Luigi Provenzano*

Main category: math.AP

TL;DR: The paper examines the first positive Steklov eigenvalue on planar domains, providing an example with a closed nodal line and establishing a lower bound for symmetric domains, proving simplicity for ellipses.


<details>
  <summary>Details</summary>
Motivation: To address gaps in the understanding of the first positive Steklov eigenvalue, particularly regarding nodal lines and eigenvalue simplicity, as highlighted by prior work by Kuttler and Sigillito.

Method: The study involves constructing an example of a planar domain with a closed nodal line and deriving a lower bound for the eigenvalue on symmetric domains, with a focus on ellipses.

Result: The paper demonstrates the existence of a planar domain with a closed nodal line and proves the simplicity of the first positive eigenvalue for all ellipses.

Conclusion: The findings complement and extend earlier results by Kuttler and Sigillito, enhancing the understanding of Steklov eigenvalues on planar domains.

Abstract: We consider the first positive Steklov eigenvalue on planar domains. First,
we provide an example of a planar domain for which a first eigenfunction has a
closed nodal line. Second, we establish a lower bound for the first positive
eigenvalue on certain symmetric domains and show that this eigenvalue is simple
for all ellipses. These results complement two statements contained in a work
by Kuttler and Sigillito (Proc. Amer. Math. Soc. 20, 1969).

</details>


### [16] [On the existence of normalized solutions to a class of fractional Choquard equation with potentials](https://arxiv.org/abs/2507.23363)
*Yongpeng Chen,Zhipeng Yang,Jianjun Zhang*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper investigates the existence of normalized solutions to the
nonlinear fractional Choquard equation: $$ (-\Delta)^s u+V(x) u=\lambda
u+f(x)\left(I_\alpha *\left(f|u|^q\right)\right)|u|^{q-2} u+g(x)\left(I_\alpha
*\left(g|u|^p\right)\right)|u|^{p-2} u, \quad x \in \mathbb{R}^N $$ subject to
the mass constraint $$ \int_{\mathbb{R}^N}|u|^2 d x=a>0, $$ where $N>2 s, s
\in(0,1), \alpha \in(0, N)$, and $\frac{N+\alpha}{N} \leq q<p \leq
\frac{N+\alpha+2 s}{N}$. Here, the parameter $\lambda \in \mathbb{R}$ appears
as an unknown Lagrange multiplier associated with the normalization condition.
By employing variational methods under appropriate assumptions on the
potentials $V(x), f(x)$, and $g(x)$, we establish several existence results for
normalized solutions.

</details>


### [17] [Quantitative homogenisation for differential equations with highly anisotropic partially degenerating coefficients](https://arxiv.org/abs/2507.23380)
*Shane Cooper,Ilia Kamotski*

Main category: math.AP

TL;DR: The paper studies a non-uniformly elliptic operator modeling anisotropic fibers in a composite medium, focusing on resolvent behavior as the periodicity parameter ε→0. It extends prior work by providing asymptotic resolvent descriptions and operator-type error estimates, addressing new challenges like directional ellipticity loss and weaker spectral gap assumptions.


<details>
  <summary>Details</summary>
Motivation: The work aims to understand the resolvent behavior of a high-contrast, anisotropic periodic operator as ε→0, building on prior results but tackling additional complexities like directional ellipticity loss and weaker spectral conditions.

Method: The approach follows a general scheme from prior research but incorporates new analyses, including interfacial boundary layer techniques near fibers, to derive order-ε error estimates.

Result: The paper achieves asymptotic descriptions of the resolvent and establishes operator-type error estimates of order ε, overcoming challenges like directional ellipticity loss.

Conclusion: The study advances understanding of resolvent behavior in high-contrast anisotropic media, providing refined error estimates and addressing new analytical challenges.

Abstract: We consider a non-uniformly elliptic second-order differential operator with
periodic coefficients that models composite media consisting of highly
anisotropic cylindrical fibres periodically distributed in an isotropic
background. The degree of anisotropy is related to the period of the
coefficients via a `critical' high-contrast scaling. In particular, ellipticity
is lost in certain directions as the period, $\epsilon$, tends to zero. Our
primary interest is in the asymptotic behaviour of the resolvent of this
operator in the limit of small $\epsilon$.
  Two-scale resolvent convergence results were established for such operators
in Cherednichenko, Smyshlyaev and Zhikov (Proceedings of The Royal Society of
Edinburgh:Seciton A Mathematics. 136(1), 87--114(2006)). In this work, we
provide an asymptotic description of the resolvent and establish operator-type
error estimates. Our approach adopts the general scheme of Cooper, Kamotski and
Smyshlyaev (preprint available at arXiv:2307.13151). However, we face new
challenges such as a directional dependence on the loss of ellipticity in
addition to a key `spectral gap' assumption of the above article only holding
in a weaker sense. This results in an additional `interfacial' boundary layer
analysis in the vicinity of each fibre to arrive at order-$\epsilon$
operator-type error estimates.

</details>


### [18] [Global well-posedness and scattering for the 2D modified Zakharov-Kuznetsov equation](https://arxiv.org/abs/2507.23397)
*Simão Correia,Shinya Kinoshita*

Main category: math.AP

TL;DR: The paper studies the Cauchy problem for the modified Zakharov-Kuznetsov equation in 2D, proving local and global well-posedness and scattering for small data in a new two-parameter space.


<details>
  <summary>Details</summary>
Motivation: To analyze the dispersive effects and establish well-posedness results for the modified Zakharov-Kuznetsov equation in a scaled space.

Method: Introduces a two-parameter space $H^{s,a}(\mathbb{R}^2)$ and proves results using dispersive techniques.

Result: Local well-posedness for $s+a\ge 1/4$, $0<a<1/4$, and global well-posedness and scattering for small data when $s=0, a=1/4$.

Conclusion: The results are sharp in the sense of $C^3$-flows, demonstrating optimality.

Abstract: We consider the Cauchy problem associated with the modified
Zakharov-Kuznetsov equation over $\mathbb{R}^2$. Taking into consideration the
associated dispersive effects, we introduce, for $s,a\ge 0$, a two-parameter
space $H^{s,a}(\mathbb{R}^2)$, which scales as the classic $H^s$ spaces. In
this new class, we prove local well-posedness for $s+a\ge 1/4$, $0<a<1/4$, and
global well-posedness and scattering for small data in the case $s=0, \ a=1/4$.
These results are shown to be sharp in the sense of $C^3$-flows.

</details>


### [19] [$p(x)$-Stability of the Dirichlet problem for Poisson's equation with variable exponents](https://arxiv.org/abs/2507.23417)
*Behzad Djafari Rouhani,Osvaldo Mendez*

Main category: math.AP

TL;DR: The paper shows convergence of solutions to Dirichlet problems for variable exponent p(x)-Laplacian as the exponent sequence uniformly converges.


<details>
  <summary>Details</summary>
Motivation: To understand how solutions to Dirichlet problems behave when the exponent in the p(x)-Laplacian varies uniformly.

Method: Analyze sequences of solutions for increasing and decreasing exponent sequences, comparing them to the limiting problem.

Result: Solutions converge to the limiting problem's solution when the exponent sequence uniformly converges.

Conclusion: Uniform convergence of exponents ensures convergence of solutions in Dirichlet problems for p(x)-Laplacian.

Abstract: It is shown that if the sequence $(p_j(x))$ increases uniformly to $p(x)$ in
a bounded, smooth domain $\Omega$, then the sequence $(u_i)$ of solutions to
the Dirichlet problem for the $p_i(x)$-Laplacian with fixed boundary datum
$\varphi$ converges (in a sense to be made precise) to the solution $u_p$ of
the Dirichlet problem for the $p(x)$-Laplacian with boundary datum $\varphi$. A
similar result is proved for a decreasing sequence $p_j\searrow p$

</details>


### [20] [Heat content asymptotics for sets with positive reach](https://arxiv.org/abs/2507.23427)
*Paolo De Fazio,Michele Miranda Jr*

Main category: math.AP

TL;DR: The paper studies the heat content of sets with positive reach in Euclidean space, analyzing its short-time asymptotic behavior.


<details>
  <summary>Details</summary>
Motivation: To extend the understanding of heat content beyond smooth boundaries to include non-smooth and singular sets with positive reach.

Method: Analyzes the short-time asymptotics of the heat content for bounded subsets with positive reach using techniques distinct from prior work.

Result: Provides a slightly different result compared to previous studies, leveraging new methods.

Conclusion: The study advances the geometric analysis of heat content for sets with positive reach, offering new insights.

Abstract: In this paper we study the heat content for sets with positive reach. In
details, we investigate the asymptotic behavior of the heat content of bounded
subsets of the Euclidean space with positive reach. The concept of positive
reach was introduced by Federer in \cite{fed_1959} and widely developed in the
following years (see for instance the recent book by Rataj and Zh{\"a}le
\cite{rat_zah_2019}). It extends the class of sets with smooth boundaries to
include certain non-smooth and singular sets while still admitting a
well-defined normal geometry. For such sets $E\subseteq\Rn$, we analyze the
short-time asymptotics of the heat content $\|T_t\mathbbm{1}_E\|_2$, where
$T_t\mathbbm{1}_E$ is the soluzion of the heat equation in $\Rn$ with initial
condition $\mathbbm{1}_E$. The present paper is in the spirit of Angiuli,
Massari and Miranda Jr.\cite{ang_mas_mir_2013}, but the technique's used here
are completely different and also the final result is slightly different.

</details>


### [21] [Improvement of the Parabolic Regularization Method and Applications to Dispersive Models](https://arxiv.org/abs/2507.23530)
*Alysson Cunha*

Main category: math.AP

TL;DR: Global well-posedness of the Benjamin-Ono and DGBO equations in $H^s(\mathbb{R})$ for $s > 1/2$ is proven using a modified parabolic regularization method, avoiding Tao's gauge transformation.


<details>
  <summary>Details</summary>
Motivation: To establish global well-posedness for the Benjamin-Ono and DGBO equations in Sobolev spaces without relying on Tao's gauge transformation.

Method: A modified version of the standard parabolic regularization method is employed.

Result: Global well-posedness is proven for both equations in $H^s(\mathbb{R})$ for $s > 1/2$.

Conclusion: The modified parabolic regularization method successfully avoids Tao's gauge transformation and extends results to the DGBO equation.

Abstract: We prove that the Benjamin Ono equation is globally well-posed in
$H^s(\mathbb{R})$ for $s > 1/2$. Our approach does not rely on the global gauge
transformation introduced by Tao (arXiv:math/0307289). Instead, we employ a
modified version of the standard parabolic regularization method. In
particular, this technique also enables us to establish global well-posedness,
in the same Sobolev space, for the dispersion-generalized Benjamin Ono (DGBO)
equation.

</details>


### [22] [Transverse asymptotic stability of line solitary waves for the Ionic Euler-Poisson system](https://arxiv.org/abs/2507.23572)
*Frédéric Rousset,Changzhen Sun*

Main category: math.AP

TL;DR: The paper proves stability of small solitary waves in a 3D Euler-Poisson system for ions, showing global smooth solutions and their asymptotic behavior.


<details>
  <summary>Details</summary>
Motivation: To understand the stability and behavior of small solitary waves in ion dynamics described by the 3D Euler-Poisson system.

Method: Analyzes linear and nonlinear asymptotic stability of one-dimensional solitary waves under small perturbations.

Result: Demonstrates existence of global smooth solutions and describes their asymptotic behavior.

Conclusion: Small amplitude solitary waves are stable under localized perturbations, with predictable long-term behavior.

Abstract: We prove the linear and nonlinear asymptotic stability of small amplitude
one-dimensional solitary waves submitted to small localized irrotational
perturbations in the three dimensional Euler-Poisson system describing the
dynamics of ions. In particular, in this regime, we obtain the existence of
global smooth solutions and describe their asymptotic behavior.

</details>


### [23] [On blow-up trees for the harmonic map heat flow from $B^2$ to $S^2$](https://arxiv.org/abs/2507.23583)
*Dylan Samuelian*

Main category: math.AP

TL;DR: The paper analyzes finite-time and $k$-equivariant solutions to the harmonic map heat flow, proving a single-bubble decomposition and infinite-time blow-up solutions.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of harmonic map heat flow solutions under time-dependent boundary conditions and equivariance constraints.

Method: Uses the Maximum and Comparison Principle to analyze bubble tree decomposition and blow-up behavior.

Result: Proves the bubble tree decomposition contains only one bubble and exhibits infinite-time blow-up solutions for any $k \geq 1$.

Conclusion: The study provides insights into the structure and dynamics of harmonic map heat flow solutions under specific conditions.

Abstract: We consider finite-time and $k$-equivariant solutions to the harmonic map
heat flow from $B^2$ to $S^2$ under general time-dependent boundary data and
prove that the bubble tree decomposition contains only one bubble. The method
relies on the Maximum and Comparison Principle. We also exhibit solutions
blowing up in infinite time for any $k \geq 1$.

</details>


### [24] [Elliptic unique continuation below the Lipschitz threshold](https://arxiv.org/abs/2507.23614)
*Cole Jeznach*

Main category: math.AP

TL;DR: The paper explores unique continuation principles for solutions of elliptic equations with less regular coefficients, showing log-Lipschitz conditions are sharp and disproving a 1974 conjecture for isotropic cases.


<details>
  <summary>Details</summary>
Motivation: To determine the minimal regularity conditions on coefficients of elliptic equations ensuring unique continuation of solutions, addressing gaps in existing theory.

Method: Analyzes solutions of uniformly elliptic equations with coefficients satisfying Osgood conditions, comparing isotropic and anisotropic cases.

Result: Proves log-Lipschitz is sharp for general matrices; shows Holder continuity suffices for isotropic cases, disproving Miller's conjecture.

Conclusion: The study clarifies minimal regularity for unique continuation, highlighting differences between isotropic and anisotropic equations.

Abstract: In this article, we investigate unique continuation principles for solutions
$u$ of uniformly elliptic equations of the form $-\mathrm{div}(A \nabla u) = 0$
when $A$ is less regular than Lipschitz. For general matrices $A$, we prove
that strong unique continuation holds provided that $A$ has modulus of
continuity $\omega$ satisfying the Osgood condition $\int_0^1 \omega(t)^{-1}dt
= \infty$, plus some other mild hypotheses. Along with the counterexamples of
Mandache, this shows that the sharp condition on $A$ that guarantees unique
continuation is essentially that $A$ is log-Lipschitz. In the class of
isotropic equations (i.e., $A(x) = a(x)I$ for some scalar function $a$) we show
that Holder continuity of $a$ of the order $\alpha \in (2/3,1)$ is sufficient
to guarantee strong unique continuation. This latter result contrasts
counterexamples known for anisotropic equations, and disproves a conjecture of
Miller from 1974.

</details>


### [25] [Normalized solutions for the NLS equation with potential in higher dimension: the purely Sobolev critical case](https://arxiv.org/abs/2507.23639)
*Juntao Sun,Shuai Yao,He Zhang*

Main category: math.AP

TL;DR: The paper addresses normalized solutions for the NLS equation with potential and Sobolev critical nonlinearity, solving an open problem and improving prior results.


<details>
  <summary>Details</summary>
Motivation: To solve an open problem regarding mountain-pass type solutions for N>=6 and extend results to local minimizers with negative energy for N>=3.

Method: Establishes assumptions on the potential and employs new techniques to derive solutions.

Result: Finds a mountain-pass solution for N>=6 and a local minimizer with negative energy for N>=3, improving previous work.

Conclusion: The study advances understanding of NLS equations by resolving open problems and enhancing existing results.

Abstract: We study normalized solutions for the nonlinear Schrodinger (NLS) equation
with potential and Sobolev critical nonlinearity. By establishing suitable
assumptions on the potential, together with new techniques, we find a
mountain-pass type solution for N>=6, which solves an open problem presented in
a recent paper [Verzini and Yu, arXiv:2505.05357v1]. Moreover, we also find a
local minimizer with negative energy for N>=3, which improves the results in
[Verzini and Yu, arXiv:2505.05357v1].

</details>


### [26] [Infinite BV, large $L^\infty$ solutions of conservation laws are Hölder-stable in $L^2$ in the class of front tracking limits](https://arxiv.org/abs/2507.23645)
*Geng Chen,Cooper Faile,Sam G. Krupa*

Main category: math.AP

TL;DR: The paper proves a Hölder-type stability estimate in L² for hyperbolic conservation laws, independent of BV norms, and applies it to physical systems like isentropic Euler.


<details>
  <summary>Details</summary>
Motivation: To establish stability estimates for weak solutions of hyperbolic conservation laws without relying on BV assumptions, addressing limitations in existing frameworks.

Method: Uses the L² theory of shock stability with an artificial shift of position, extending results to general systems and special cases like isothermal Euler.

Result: Proves a universal stability estimate in L² for all limits of front tracking solutions, even with large-BV data, and demonstrates uniqueness for some solutions with infinite BV.

Conclusion: The framework provides robust stability estimates and uniqueness results for hyperbolic systems, applicable to physical models like isentropic Euler.

Abstract: We consider hyperbolic systems of conservation laws in one spatial dimension.
For any limit of front tracking solutions $v$, and for a general weak solution
$u\in L^\infty$ with no BV assumption, we prove the following H\"older-type
stability estimate in $L^2$:
  $$||u(\cdot,\tau)-v(\cdot,\tau)||_{L^2} \leq K \sqrt{||u( \cdot,0)-v(
\cdot,0)||_{L^2}}$$
  for all $\tau$ without smallness and for a universal constant $K$. Our result
holds for all limits of front tracking solutions $v$ with BV bound, either for
general systems with small-BV data, or for special systems (isothermal Euler,
Temple-class systems) with large-BV data. Our results apply to physical systems
such as isentropic Euler. The stability estimate is completely independent of
the BV norm of the potentially very wild solution $u$. We use the $L^2$ theory
of shock stability modulo an artificial shift of position (Vasseur [Handbook of
Differential Equations: Evolutionary Equations, 4:323 -- 376, 2008]) but our
stability results do not depend on an unknown shift. Moreover, we give the
first result within this framework which can show uniqueness of some solutions
with large $L^\infty$ and infinite BV initial data. We apply these techniques
to isothermal Euler.

</details>


### [27] [Analysis of a Cross-Nonlinear Porous-Medium System Modeling Pressure-Driven Cell Population Dynamics](https://arxiv.org/abs/2507.23680)
*Alexis Béjar-López,Rafael Granero-Belinchón,Carlos Pulido,Juan Soler*

Main category: math.AP

TL;DR: A cross-diffusion model coupling population density and occupied area is introduced to study internal pressure-driven growth and motility, featuring nonlinear interactions and novel cross-diffusion terms.


<details>
  <summary>Details</summary>
Motivation: To understand the feedback between local density fluctuations and tissue expansion/contraction, and to explore pattern formation in biological tissues.

Method: Blends nonlinear nonlocal interactions, porous-medium diffusion, and an antidiffusive pressure term, with density-dependent spreading and a novel cross-diffusion term.

Result: Proves local well-posedness, nonnegativity of solutions, uniqueness under certain conditions, and identifies finite-time blow-up scenarios.

Conclusion: The model provides insights into pattern formation and mass transport in biological tissues, with implications for understanding tissue dynamics.

Abstract: In this work, we introduce a cross-diffusion model that couples population
density and occupied area to investigate how internal pressure drives growth
and motility. By blending nonlinear nonlocal interactions with porous-medium
diffusion and an antidiffusive pressure term, the model captures the two-way
feedback between local density fluctuations and tissue expansion or
contraction. Building on Shraiman's area-growth paradigm, we enrich the
framework with density-dependent spreading at the population boundary and a
novel cross-diffusion term, yielding fully nonlinear transport in both
equations. We prove local well-posedness for nonnegative solutions in Sobolev
spaces and, under higher regularity, show both density and area remain
nonnegative. Uniqueness follows when the initial density's square root lies in
$H^2$, even if density vanishes on parts of the domain. We also exhibit initial
data that induce finite-time blow-up, highlighting potential singularity
formation. Finally, we establish that the density's spatial support remains
invariant and characterize the co-evolution of occupied area and population
density domains, offering new insights into pattern formation and mass
transport in biological tissues.

</details>


### [28] [Approximation of time-periodic flow past a translating body by flows in bounded domains](https://arxiv.org/abs/2507.23697)
*Thomas Eiter,Ana Leonor Silvestre*

Main category: math.AP

TL;DR: Existence and uniqueness of strong solutions for time-periodic 3D Navier-Stokes flow past a rigid body, with pointwise estimates. Truncated domain approximations with error analysis as R→∞.


<details>
  <summary>Details</summary>
Motivation: To analyze time-periodic flows past rigid bodies, ensuring accurate modeling and numerical approximations.

Method: Uses time-periodic Oseen equations for estimates. Approximates exterior flow in truncated domains with artificial boundary conditions.

Result: Existence/uniqueness of strong (exterior) and weak (truncated) solutions. Velocity convergence proven as R→∞.

Conclusion: The approach provides rigorous foundations for modeling and approximating such flows, with convergence guarantees.

Abstract: We consider a time-periodic incompressible three-dimensional Navier-Stokes
flow past a translating rigid body. In the first part of the paper, we
establish the existence and uniqueness of strong solutions in the exterior
domain $\Omega \subset {\mathbb R}^3$ that satisfy pointwise estimates for both
the velocity and pressure. The fundamental solution of the time-periodic Oseen
equations plays a central role in obtaining these estimates. The second part
focuses on approximating this exterior flow within truncated domains $\Omega
\cap B_R$, incorporating appropriate artificial boundary conditions on
$\partial B_R$. For these bounded domain problems, we prove the existence and
uniqueness of weak solutions. Finally, we estimate the error in the velocity
component as a function of the truncation radius $R$, showing that, as $R \to
\infty$, the velocities of the truncated problems converge, in an appropriate
norm, to the velocity of the exterior flow.

</details>


### [29] [Nonlinear Vibrational Mode of Molecule with Octahedral Configuration](https://arxiv.org/abs/2507.23720)
*Jingzhou Liu*

Main category: math.AP

TL;DR: Study of SF6's nonlinear dynamics using equivariant gradient degree, revealing 16 periodic solution branches with distinct symmetries.


<details>
  <summary>Details</summary>
Motivation: To explore the nonlinear dynamics of octahedral molecules like SF6, focusing on periodic solutions under isotypic nonresonance.

Method: Applied equivariant gradient degree to analyze critical orbits and prove existence of periodic solutions.

Result: Identified 16 distinct symmetry types of periodic solutions emerging from equilibrium.

Conclusion: Demonstrated rich vibrational modes in SF6, supported by numerical animations.

Abstract: In this work, we investigate the nonlinear dynamics of molecules with an
octahedral configuration, with particular focus on sulfur hexafluoride SF6.
Under the assumption of isotypic nonresonance, we apply the method of
equivariant gradient degree to prove the existence of branches of periodic
solutions emerging from the critical orbit of equilibrium, corresponding to at
least 16 distinct types of symmetries with maximal orbit kinds. Numerical
animations are presented to illustrate the detected vibrational modes.

</details>


### [30] [Renormalisation of singular SPDEs with Correlated Coefficients](https://arxiv.org/abs/2507.23737)
*Nicolas Clozeau,Harprit Singh*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We show local well-posedness of the g-PAM and the $\phi^{K+1}_2$-equation for
$K\geq 1$ on the two-dimensional torus when the coefficient field is random and
correlated to the driving noise. In the setting considered here, even when the
model in the sense of [Hai14] is stationary, naive use of renormalisation
constants in general leads to variance blow-up. Instead, we prove convergence
of renormalised models choosing random renormalisation functions analogous to
the deterministic variable coefficient setting. The main technical contribution
are stochastic estimates on the model in this correlated setting which are
obtained by a combination of heat kernel asymptotics, Gaussian integration by
parts formulae and Hairer--Quastel type bounds [HQ18].

</details>


### [31] [Hölder continuous dissipative solutions of ideal MHD with nonzero helicity](https://arxiv.org/abs/2507.23749)
*Alberto Enciso,Javier Peñafiel-Tomás,Daniel Peralta-Salas*

Main category: math.AP

TL;DR: Existence of weak solutions to 3D ideal MHD equations with non-conserved energy and cross helicity, while preserving magnetic helicity.


<details>
  <summary>Details</summary>
Motivation: To demonstrate solutions where some conservation laws (energy, cross helicity) fail while others (magnetic helicity) hold, challenging symmetry-based assumptions.

Method: Novel convex integration scheme preserving magnetic helicity at each step, applicable on torus and Euclidean space.

Result: Constructed $C^{10^{-8}}$ solutions without symmetry, where magnetic helicity is conserved but energy and cross helicity are not.

Conclusion: First example of continuous weak solutions where nontrivial conservation (magnetic helicity) coexists with non-conservation (energy, cross helicity).

Abstract: We prove the existence of weak solutions to the 3D ideal MHD equations, of
class $C^\alpha$ with $\alpha=10^{-8}$, for which the total energy and the
cross helicity (i.e., the so-called Els\"asser energies) are not conserved. The
solutions do not possess any symmetry properties and the magnetic helicity,
which is necessarily conserved for H\"older continuous solutions, is nonzero.
The construction, which works both on the torus $\mathbb{T}^3$ and on
$\mathbb{R}^3$ with compact spatial support, is based on a novel convex
integration scheme in which the magnetic helicity is preserved at each step.
This is the first construction of continuous weak solutions at a regularity
level where one conservation law (here, the magnetic helicity) is necessarily
preserved while another (here, the total energy or cross helicity) is not, and
where the preservation of the former is nontrivial in the sense that it does
not follow from symmetry considerations.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [32] [Real-space Hubbard-corrected density functional theory](https://arxiv.org/abs/2507.23612)
*Sayan Bhowmik,Andrew J. Medford,Phanish Suryanarayana*

Main category: physics.comp-ph

TL;DR: A framework for Hubbard-corrected DFT in real-space, offering accurate energy, forces, and stress tensor calculations, with scalable parallel implementation outperforming planewave methods.


<details>
  <summary>Details</summary>
Motivation: To improve efficiency and scalability of Hubbard-corrected DFT calculations in real-space, addressing limitations of planewave methods.

Method: Developed expressions for energy, forces, and stress tensor for real-space finite-difference discretization, with large-scale parallel implementation.

Result: Outperforms planewave codes by over an order of magnitude in speed, with better scalability for larger systems or more processors.

Conclusion: The framework is accurate, efficient, and scalable, with applications in optimizing Hubbard parameters and studying exchange-correlation inconsistency in TiO2 polymorphs.

Abstract: We present an accurate and efficient framework for real-space
Hubbard-corrected density functional theory. In particular, we obtain
expressions for the energy, atomic forces, and stress tensor suitable for
real-space finite-difference discretization, and develop a large-scale parallel
implementation. We verify the accuracy of the formalism through comparisons
with established planewave results. We demonstrate that the implementation is
highly efficient and scalable, outperforming established planewave codes by
more than an order of magnitude in minimum time to solution, with increasing
advantages as the system size and/or number of processors is increased. We
apply this framework to examine the impact of exchange-correlation
inconsistency in local atomic orbital generation and introduce a scheme for
optimizing the Hubbard parameter based on hybrid functionals, both while
studying TiO$_2$ polymorphs.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [33] [Derivations of two one-dimensional models for transversely curved shallow shells: one leads to relaxation](https://arxiv.org/abs/2507.23545)
*Paroni Roberto,Picchi Scardaoni Marco*

Main category: math-ph

TL;DR: The paper analyzes the Γ-limit of variational problems for shallow shells, focusing on energy scaling and boundary conditions, leading to two distinct one-dimensional models.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of shallow shells under varying energy scalings and boundary conditions, and to derive simplified models for practical applications.

Method: The study uses von Kármán-type energy for shallow shells, scaling the stretching energy with ε^(2β), and analyzes the Γ-limit as ε→0 for β in (0, 2].

Result: For β ∈ (0, 2), the limit membrane energy vanishes under compression (relaxation). For β=2, a nonlinear energy model emerges, coupling four kinematical descriptors.

Conclusion: Boundary conditions are crucial for compactness, and the derived models (including nonlinear Vlasov torsion and Euler-Bernoulli beam theories) provide insights into shell behavior under different energy scalings.

Abstract: We study the $\Gamma$-limit of sequences of variational problems for
straight, transversely curved shallow shells, as the width of the planform
$\varepsilon$ goes to zero.
  The energy is of von K\'arm\'an type for shallow shells under suitable
boundary conditions. What distinguishes the various regimes is the scaling of
the stretching energy $\sim \varepsilon^{2\beta}$, with $\beta$ a positive
number. We derive two one-dimensional models as $\beta$ ranges in $(0, 2]$.
Remarkably, boundary conditions are essential to get compactness.
  We show that for $\beta \in (0, 2)$ the $\Gamma$-limit leads to relaxation:
the limit membrane energy vanishes on compression. For $\beta=2$ there is no
relaxation, and the limit model is a nonlinear energy coupling four kinematical
descriptors in a nontrivial way.
  As special cases of the latter limit model, a nonlinear Vlasov torsion theory
and a nonlinear Euler-Bernoulli beam theory can be deduced.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [34] [Deriving effective electrode-ion interactions from free-energy profiles at electrochemical interfaces](https://arxiv.org/abs/2507.23031)
*Fabrice Roncoroni,Abrar Faiyad,Yichen Li,Tao Ye,Ashlie Martini,David Prendergast*

Main category: physics.chem-ph

TL;DR: The paper investigates ion adsorption at electrified interfaces using molecular dynamics and machine-learned potentials, highlighting the impact of force field parameters and validating findings with experimental data.


<details>
  <summary>Details</summary>
Motivation: Accurate modeling of electrochemical systems requires understanding ion adsorption at electrified metal-electrolyte interfaces.

Method: Enhanced sampling molecular dynamics with classical force fields and machine-learned interatomic potentials (MLIPs) are used to study free energy profiles of ions at the Au(111)-water interface.

Result: Classical metadynamics shows parameter sensitivity, while MLIPs validate trends: chloride adsorbs strongly, fluoride weakly, and sodium not at all. Adsorption alters interfacial properties like potential of zero charge.

Conclusion: Force field parameterization and advanced potentials are crucial for predictive modeling of ion-specific effects, bridging molecular simulations and continuum models.

Abstract: Understanding ion adsorption at electrified metal-electrolyte interfaces is
essential for accurate modeling of electrochemical systems. Here, we
systematically investigate the free energy profiles of Na$^+$, Cl$^-$, and
F$^-$ ions at the Au(111)-water interface using enhanced sampling molecular
dynamics with both classical force fields and machine-learned interatomic
potentials (MLIPs). Our classical metadynamics results reveal a strong
dependence of predicted ion adsorption on the Lennard-Jones parameters,
highlighting that --without due care-- standard mixing rules can lead to
qualitatively incorrect descriptions of ion-metal interactions. We present a
systematic methodology for tuning the cross-term LJ parameters to control
adsorption energetics in agreement with more accurate models. As a surrogate
for an ab initio model, we employed the recently released Universal Models for
Atoms (UMA) MLIP, which validates classical trends and displays strong specific
adsorption for chloride, weak adsorption for fluoride, and no specific
adsorption for sodium, in agreement with experimental and theoretical
expectations. By integrating molecular-level adsorption free energies into
continuum models of the electric double layer, we show that specific ion
adsorption substantially alters the interfacial ion population, the potential
of zero charge, and the differential capacitance of the system. Our results
underscore the critical importance of force field parameterization and advanced
interatomic potentials for the predictive modeling of ion-specific effects at
electrified interfaces and provide a robust framework for bridging molecular
simulations and continuum electrochemical models.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [35] [Existence of genus 2 minimal surfaces in 3-spheres. I](https://arxiv.org/abs/2507.23239)
*Adrian Chun-Pong Chu,Yangyang Li,Zhihan Wang*

Main category: math.DG

TL;DR: The paper proves the existence of genus 2 minimal surfaces in 3-spheres with positive Ricci curvature and generalizes this to relate minimal surfaces of genus g to topological properties in 3-manifolds.


<details>
  <summary>Details</summary>
Motivation: To explore the existence of minimal surfaces in 3-spheres and 3-manifolds, linking geometric and topological properties.

Method: Mathematical proof and generalization of results for minimal surfaces in 3-spheres and 3-manifolds.

Result: Existence of genus 2 minimal surfaces in 3-spheres with positive Ricci curvature and a general theorem for 3-manifolds.

Conclusion: The findings connect geometric conditions (Ricci curvature) to topological properties of minimal surfaces in 3-manifolds.

Abstract: We prove that every 3-sphere of positive Ricci curvature contains some
embedded minimal surface of genus 2.
  We also establish a theorem for more general 3-manifolds that relates the
existence of genus $g$ minimal surfaces to topological properties regarding the
set of all embedded singular surfaces of genus $\leq g$.

</details>


<div id='cond-mat.supr-con'></div>

# cond-mat.supr-con [[Back]](#toc)

### [36] [AC/DC spin current in ferromagnet/superconductor/normal metal trilayer systems](https://arxiv.org/abs/2507.23262)
*Koki Mizuno,Hirone Ishida,Manato Teranishi*

Main category: cond-mat.supr-con

TL;DR: Study investigates spin pumping in a trilayer system (FMI/SC/NM), deriving AC and DC spin currents in the NM layer under microwave irradiation. Classical and quantum treatments yield AC and DC currents, respectively. The computationally intensive evaluation is mitigated using QTCI, revealing temperature, frequency, and thickness dependencies, including a coherence peak and a transition structure.


<details>
  <summary>Details</summary>
Motivation: To explore spin pumping in a trilayer system (FMI/SC/NM) and understand the induced spin currents under microwave irradiation, addressing computational challenges and uncovering dependencies on system parameters.

Method: Derivation of AC (classical spin motion) and DC (quantum quasiparticles) spin currents in the NM layer, with computational mitigation using QTCI. Numerical analysis of temperature, frequency, and SC layer thickness dependencies.

Result: AC and DC spin currents exhibit a coherence peak in temperature dependence. A transition structure is observed in the spin current's dependence on SC layer thickness, changing after a specific frequency.

Conclusion: The study successfully analyzes spin pumping in a trilayer system, revealing key dependencies and introducing QTCI to handle computational complexity, with implications for understanding spin dynamics in hybrid structures.

Abstract: Spin pumping with superconductors has been extensively studied, particularly
in double-layer systems. In this study, we investigate spin pumping in a
trilayer system comprising a ferromagnetic insulator (FMI), a superconductor
(SC), and a normal metal (NM). We derive the AC and DC spin currents in the NM
layer induced by spin motion in the FMI under circularly polarized microwave
irradiation. If we treat the spin motion as classical, the AC spin current is
expressed. On the other hand, if we treat the spin motion as quantum
quasiparticles, the DC spin current is derived. After these derivations, while
the computational cost of evaluating the spin current is extremely high, we
mitigate this using the Quantics Tensor Cross Interpolation (QTCI) method. We
present numerical results showing the dependence of the spin current on
temperature, microwave frequency, and superconductor layer thickness. Notably,
the temperature dependence of AC and DC spin currents exhibits a coherence
peak. Furthermore, we have discovered a transition structure in the dependence
of the spin current on the thickness of the superconductor layer, where the
dependence changes after a particular frequency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [AI paradigm for solving differential equations: first-principles data generation and scale-dilation operator AI solver](https://arxiv.org/abs/2507.23141)
*Xiangshu Gong,Zhiqiang Xie,Xiaowei Jin,Chen Wang,Yanling Qu,Wangmeng Zuo,Hui Li*

Main category: cs.LG

TL;DR: The paper proposes an AI paradigm for solving differential equations (DEs) with a focus on addressing high-frequency component approximation issues, using a novel scale-dilation operator (SDO) and Transformer-based solver.


<details>
  <summary>Details</summary>
Motivation: Existing AI solvers struggle with high-frequency component approximation and data scarcity. The work aims to provide a scalable, efficient, and accurate AI-driven solution for diverse DEs.

Method: The method involves first-principles data generation, reversible SDO for fixing high-frequency issues, and a Transformer-based AI solver. It leverages Fourier transforms and proves theoretical bounds on loss landscape smoothness.

Result: Extensive tests show superior accuracy over state-of-the-art methods, with efficient training and scalable data generation.

Conclusion: The proposed AI paradigm makes DE solvers practical for broad applications in nature and engineering.

Abstract: Many problems are governed by differential equations (DEs). Artificial
intelligence (AI) is a new path for solving DEs. However, data is very scarce
and existing AI solvers struggle with approximation of high frequency
components (AHFC). We propose an AI paradigm for solving diverse DEs, including
DE-ruled first-principles data generation methodology and scale-dilation
operator (SDO) AI solver. Using either prior knowledge or random fields, we
generate solutions and then substitute them into the DEs to derive the sources
and initial/boundary conditions through balancing DEs, thus producing
arbitrarily vast amount of, first-principles-consistent training datasets at
extremely low computational cost. We introduce a reversible SDO that leverages
the Fourier transform of the multiscale solutions to fix AHFC, and design a
spatiotemporally coupled, attention-based Transformer AI solver of DEs with
SDO. An upper bound on the Hessian condition number of the loss function is
proven to be proportional to the squared 2-norm of the solution gradient,
revealing that SDO yields a smoother loss landscape, consequently fixing AHFC
with efficient training. Extensive tests on diverse DEs demonstrate that our AI
paradigm achieves consistently superior accuracy over state-of-the-art methods.
This work makes AI solver of DEs to be truly usable in broad nature and
engineering fields.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [38] [Matching Large Deviation Bounds of the Zero-Range Process in the whole space](https://arxiv.org/abs/2507.23452)
*Benjamin Fehrman,Benjamin Gess,Daniel Heydecker*

Main category: math.PR

TL;DR: The paper resolves the large deviations problem for the hydrodynamic rescaling of the zero-range process in any dimension, extending superexponential estimates and removing convexity assumptions.


<details>
  <summary>Details</summary>
Motivation: To address the unresolved problem of large deviations in the hydrodynamic rescaling of the zero-range process, as posed by prior work (KL99).

Method: Extends superexponential estimates to any dimension, proves concentration on paths with finite entropy dissipation, and generalizes the parabolic-hyperbolic skeleton equation theory.

Result: Matching upper and lower bounds for large deviations are obtained, resolving the open problem.

Conclusion: The study successfully resolves the problem and extends theoretical tools, removing restrictive assumptions.

Abstract: We consider the large deviations of the hydrodynamic rescaling of the
zero-range process on $\mathbb{Z}^d$ in any dimension $d\ge 1$. Under mild and
canonical hypotheses on the local jump rate, we obtain matching upper and lower
bounds, thus resolving the problem opened by \cite{KL99}. On the probabilistic
side, we extend the superexponential estimate to any dimension, and prove the
superexponential concentration on paths with finite entropy dissipation. In
addition, we extend the theory of the parabolic-hyperbolic skeleton equation to
the whole space, and remove global convexity/concavity assumptions on the
nonlinearity.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [39] [Extensional rheology of dilute suspensions of spheres in polymeric liquids](https://arxiv.org/abs/2507.23114)
*Arjun Sharma,Donald L. Koch*

Main category: physics.flu-dyn

TL;DR: The study examines how dilute suspensions of spheres in viscoelastic liquids behave under extensional flow, revealing that polymer concentration and Deborah number significantly influence viscosity changes due to polymer stretching and collapse.


<details>
  <summary>Details</summary>
Motivation: Understanding the rheological behavior of suspensions in viscoelastic liquids is crucial for applications like industrial fluid dynamics and material processing.

Method: Computational analysis of extensional rheology, focusing on polymer concentration (c) and Deborah number (De) effects on local flow and polymer stretch.

Result: At low De (<0.5), stretched polymers increase viscosity; at high De (>0.5), collapsed polymers reduce viscosity. High c introduces a new mechanism where negative stress scales with c², reducing viscosity.

Conclusion: Dilute sphere suspensions can effectively reduce viscosity in viscoelastic liquids at high De and c, offering insights for designing fluid systems.

Abstract: The extensional rheology of dilute suspensions of spheres in viscoelastic or
polymeric liquids is studied computationally. At low polymer concentration (c)
and Deborah number (De), a wake of highly stretched polymers forms downstream
of the particles due to larger local velocity gradients than the imposed flow,
indicated by a positive deviation in local De. This increases the suspension's
extensional viscosity with time and De for De less than 0.5. When De exceeds
0.5 (the coil-stretch transition), the fully stretched polymers from the far
field collapse in regions with lower local velocity gradients around the
particle's stagnation points, reducing suspension viscosity relative to the
polymer-only liquid. The interaction between local flow and polymers
intensifies with increasing c. Highly stretched polymers impede local flow,
reducing local De, while it increases in regions with collapsed polymers.
Initially, increasing c aligns local De and polymer stretch with far-field
values, diminishing particle-polymer interaction effects. However, beyond a
certain c, a new mechanism emerges. At low c, fluid three particle radii
upstream exhibits increased local De, stretching polymers beyond their
undisturbed state. As c increases, this deviation becomes negative, collapsing
polymers and resulting in increasingly negative stress from particle-polymer
interactions at large De and time. At high c, this negative interaction stress
scales as c squared, surpassing the linear increase in polymer stress, making
dilute sphere suspensions more effective at reducing the viscosity of
viscoelastic liquids at larger De and c.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [40] [Physics-Informed PointNets for Modeling Electromagnetic Scattering from All-Dielectric Metasurfaces with Inclined Nanopillars](https://arxiv.org/abs/2507.23119)
*Leon Armbruster,Vlad Medvedev,Andreas Rosskopf*

Main category: physics.optics

TL;DR: A mesh-free Physics-Informed PointNet (PIPN) is introduced for modeling electromagnetic scattering in all-dielectric metasurfaces with irregular geometries, offering accurate and efficient computational modeling.


<details>
  <summary>Details</summary>
Motivation: Conventional solvers struggle with accurate and efficient modeling of metasurfaces, especially those with irregular geometries and spatially varying nanopillars.

Method: The PIPN integrates PointNet architecture into a Physics-Informed Machine Learning (PIML) framework to encode spatially varying material properties.

Result: PIPN demonstrates generalization across datasets with varying refractive indices and inclination angles, simulating manufacturing defects.

Conclusion: The PIPN framework is a promising solution for mesh-free, accurate modeling of complex optical structures with irregular geometries.

Abstract: Metasurfaces are innovative planar optical structures capable of manipulating
incident light properties. Accurate and computationally efficient modeling of
such metasurfaces, particularly those with irregular geometries, remains a
challenge for conventional solvers. In this work, we present a mesh-free
Physics-Informed PointNet (PIPN) to model electromagnetic scattering from
all-dielectric metasurfaces that feature spatially varying nanopillars. Our
approach uses the PointNet architecture to directly encode spatially varying
material properties into the Physics-Informed Machine Learning (PIML)
framework. We demonstrate the generalization capability of our PIPN through
evaluations on datasets; these datasets are generated with varying refractive
indices representing common dielectric materials. Furthermore, the inclination
angles are varied within each dataset, which represent expected manufacturing
defects. Overall, our method provides a promising, mesh-free framework for
accurate and efficient modeling of complex optical structures represented by
irregular geometries.

</details>


### [41] [Conical diffraction of the synchrotron beam to probe the efficiency and morphology of blazed gratings](https://arxiv.org/abs/2507.23513)
*K. V. Nikolaev,L. I. Goray,P. S. Savchenkov,A. V. Rogachev,A. A. Chouprik,T. N. Berezovskaya,D. V. Mokhov,S. A. Garakhin,N. I. Chkhalo,A. D. Buravleuv,S. N. Yakunin*

Main category: physics.optics

TL;DR: The study demonstrates synchrotron measurements as a nanometrology tool for blazed gratings, analyzing diffraction and diffuse scattering to evaluate groove profiles and surface roughness.


<details>
  <summary>Details</summary>
Motivation: To highlight synchrotron measurements as a valuable tool for nanometrology in modern optical elements.

Method: Uses grazing incidence geometry to measure conical diffraction and diffuse scattering, supported by numerical simulations (Helmholtz equations and perturbation theory) and data from AFM/SEM.

Result: Diffraction reveals average groove profiles, while diffuse scattering indicates surface roughness morphology.

Conclusion: Synchrotron measurements are effective for characterizing blazed gratings, urging the optical community to adopt this tool.

Abstract: This study explores the use of synchrotron measurements as a nanometrology
tool for blazed gratings. In grazing incidence geometry, one can measure both
the conical diffraction and the diffuse scattering on the grating
simultaneously in a single scattering pattern. The sensitivity of scattering
patterns to the structure of the blazed gratings is evaluated. The diffraction
component of the pattern is shown to be sensitive to the average groove profile
of the gratings. Meanwhile, the diffuse scattering depends on the roughness
morphology of the reflective surface of blazed gratings. These findings are
supported by numerical simulations. The simulations were performed using
several rigorous solvers for the Helmholtz equations, and with a perturbation
theory. The analysis relies on synchrotron data, as well as data from atomic
force microscopy and scanning electron microscopy. The aim of this article is
to draw the attention of the optical community to the synchrotron measurements
as a nanometrology tool for the modern optical elements.

</details>
