<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 23]
- [math.AP](#math.AP) [Total: 16]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 4]
- [math.ST](#math.ST) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.CE](#cs.CE) [Total: 2]
- [math.PR](#math.PR) [Total: 3]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Orbit recovery for spherical functions](https://arxiv.org/abs/2508.02674)
*Tamir Bendory,Dan Edidin,Josh Katz,Shay Kreymer*

Main category: math.NA

TL;DR: The paper shows that degree three invariants (bispectrum) can recover generic orbits of functions under SO(n) rotation, with explicit bounds on radial samples. For SO(3), three spherical shells suffice, verified experimentally on protein structures.


<details>
  <summary>Details</summary>
Motivation: Orbit recovery is crucial in structural biology (e.g., cryo-EM). The paper aims to simplify and generalize recovery using invariants.

Method: Uses degree three invariants (bispectrum) and finite-dimensional approximations of L²(ℝⁿ). Provides an explicit algorithm via linear systems.

Result: For SO(3), three radial samples suffice for generic orbit recovery. Algorithm tested successfully on protein structures.

Conclusion: The bispectrum-based method is effective for orbit recovery, with practical applications in structural biology.

Abstract: Orbit recovery is a central problem in both mathematics and applied sciences,
with important applications to structural biology. This paper focuses on
recovering generic orbits of functions on ${\mathbb R}^{n}$ and the sphere
$S^{n-1}$ under the rotation action of $SO(n)$. Specifically, we demonstrate
that invariants of degree three (called the bispectrum) suffice to recover
generic orbits of functions in finite-dimensional approximations of
$L^2({\mathbb R}^n)$ obtained by band-limiting the spherical component and
discretizing the radial direction. In particular, our main result explicitly
bounds the number of samples in the radial direction required for recovery from
the degree three invariants. From an application perspective, the most
important case is $SO(3)$, which arises in many scientific fields, and in
particular, plays a central role in leading structural biology applications
such as cryo-electron tomography and cryo-electron microscopy. Our result for
$SO(3)$ states that considering three spherical shells (i.e., samples in the
radial direction) is sufficient to recover generic orbits, which verifies an
implicit conjecture made in a paper of Bandeira et al. Our proof technique
provides an explicit, computationally efficient algorithm to recover the signal
by successively solving systems of linear equations. We implemented this
algorithm and demonstrated its effectiveness on two protein structures.

</details>


### [2] [Full Vectorial Maxwell Equations with Continuous Angular Indices](https://arxiv.org/abs/2508.02675)
*Mustafa Bakr*

Main category: math.NA

TL;DR: A mathematical framework for solving Maxwell's equations in cylindrical and spherical geometries with continuous angular indices, capturing singular behavior and finite-energy fields.


<details>
  <summary>Details</summary>
Motivation: To extend beyond discrete harmonic decomposition and address electromagnetic solutions with singular behavior in continuous spectral representations.

Method: Uses generalized spectral integrals, weighted Sobolev spaces, and biorthogonal function systems to study existence, uniqueness, and finite energy of solutions.

Result: Proves finite energy for specific conditions, constructs spectral kernels, and validates the framework numerically.

Conclusion: The framework successfully handles singular behavior and provides a robust spectral representation for Maxwell's equations in complex geometries.

Abstract: This article presents a mathematical framework for solving Maxwell's
equations in cylindrical and spherical geometries with continuous angular
indices. We extend beyond standard discrete harmonic decomposition to a
continuous spectral representation using generalized spectral integrals,
capturing electromagnetic solutions that exhibit singular behavoiur yet yield
finite-energy fields at the geometric center. For continuous angular indices
$\ell, m \in \mathbb{R}$, we study existence and uniqueness of solutions in
weighted Sobolev spaces $H^s_{\alpha(\ell,m)}(\Omega)$ following the framework
established in ~\cite{adams2003, reed1975}, prove finite energy for $\ell >
-\frac{1}{2}$, and construct explicit spectral kernels via biorthogonal
function systems. The framework encompasses both separable cylindrical modes
with continuous azimuthal index $\nu \in (0,1)$ and non-separable spherical
modes where field components couple through vectorial curl operations. We
present asymptotic analysis of singular field behavior, investigate convergence
rates for spectral approximations, and validate the theoretical framework
through Galerkin projection methods and numerical spectral integration.

</details>


### [3] [When surface evolution meets Fokker-Planck equation: a novel tangential velocity model for uniform parametrization](https://arxiv.org/abs/2508.02676)
*Jiangong Pan,Guozhi Dong,Hailong Guo,Zuoqiang Shi*

Main category: math.NA

TL;DR: A novel artificial tangential velocity method is proposed to address point clustering in geometric surface evolution, using a Fokker-Planck equation and Kullback-Leibler divergence for point distribution.


<details>
  <summary>Details</summary>
Motivation: Unexpected point clustering in surface evolution simulations causes numerical instability, necessitating a robust solution.

Method: Artificial tangential velocity derived from a surface density field, with a target distribution algorithm using Kullback-Leibler divergence, implemented in a meshless framework.

Result: The method demonstrates robustness, accuracy, and effectiveness in various surface evolution problems, including mean curvature flow.

Conclusion: The proposed approach successfully mitigates point clustering issues without requiring mesh generation, offering flexibility for unstructured data.

Abstract: A common issue in simulating geometric evolution of surfaces is unexpected
clustering of points that may cause numerical instability. We propose a novel
artificial tangential velocity method for this matter. The artificial
tangential velocity is generated from a surface density field governed by a
Fokker-Planck equation to guide the point distribution. A target distribution
matching algorithm is developed leveraging the surface Kullback-Leibler
divergence of density functions. The numerical method is formulated within a
fully meshless framework using the moving least squares approximation, thereby
eliminating the need for mesh generation and allowing flexible treatment of
unstructured point cloud data. Extensive numerical experiments are conducted to
demonstrate the robustness, accuracy, and effectiveness of the proposed
approach across a variety of surface evolution problems, including the mean
curvature flow.

</details>


### [4] [Automated $h$-adaptivity for finite element approximations of the Falkner-Skan equation](https://arxiv.org/abs/2508.02677)
*B. Veena S. N. Rao*

Main category: math.NA

TL;DR: The paper presents an $h$-adaptive finite element method for solving the Falkner-Skan equation, using a posteriori error estimation for mesh adaptivity, achieving accurate boundary layer resolution and precise skin friction coefficient computation.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of accurately resolving boundary layer behavior in Falkner-Skan flows, especially under varying pressure gradients, using an adaptive finite element method.

Method: An $h$-adaptive finite element method with a posteriori error estimation (Kelly error estimator) was employed to dynamically refine the mesh based on gradient jumps across elements.

Result: The method provided accurate and efficient solutions for Falkner-Skan flows, including precise computation of the skin friction coefficient under diverse conditions.

Conclusion: The adaptive finite element approach is robust and accurate for nonlinear boundary layer problems like the Falkner-Skan equation.

Abstract: This paper details the development and application of an $h$-adaptive finite
element method for the numerical solution of the \textit{Falkner-Skan
equation}. A posteriori error estimation governs the adaptivity of the mesh,
specifically the well-established \textit{Kelly error estimator}, which
utilizes the jump in the gradient across elements. The implementation of this
method allowed for accurate and efficient resolution of the boundary layer
behavior characteristic of Falkner-Skan flows. Numerical solutions were
obtained across various wedge flow parameters, encompassing favorable and
adverse pressure gradients. A key focus of this study was the precise
computation of the skin friction coefficient, a critical parameter in boundary
layer analysis, across this diverse range of flow conditions. The results are
presented and discussed, demonstrating the robustness and accuracy of the
adaptive finite element approach for this class of nonlinear boundary layer
problems.

</details>


### [5] [On sliced Cramér metrics](https://arxiv.org/abs/2508.02678)
*William Leeb*

Main category: math.NA

TL;DR: The paper demonstrates the robustness of sliced Cramér metrics to geometric deformations and noise, comparing them to Wasserstein distances, and introduces efficient Fourier-based discretizations.


<details>
  <summary>Details</summary>
Motivation: To analyze the robustness of sliced Cramér metrics under deformations and noise, and compare them with Wasserstein distances.

Method: The study bounds the sliced Cramér distance by deformation measures and mean mixed norms, extends to tomographic projections, and introduces Fourier-based discretizations.

Result: Sliced Cramér metrics are robust to deformations and noise, with efficient computational methods validated by experiments.

Conclusion: Sliced Cramér metrics offer robust and computationally efficient alternatives to Wasserstein distances for certain applications.

Abstract: We study the family of sliced Cram\'er metrics, showing that they are robust
to a broad class of geometric deformations. Our central results are that the
sliced Cram\'er distance between a function and its deformation may be bounded
by certain natural measures of the deformation's displacement, multiplied by
the function's mean mixed norm. These results extend to sliced Cram\'er
distances between tomographic projections. We also remark on the effect of
convolution on the sliced Cram\'er metrics. We compare these properties of
sliced Cram\'er metrics to similar properties satisfied by Wasserstein
distances. In addition, we study computationally efficient Fourier-based
discretizations of the Cram\'er and sliced Cram\'er distances in 1D and 2D, and
prove that they are robust to heteroscedastic noise. The results are
illustrated by numerical experiments.

</details>


### [6] [Accelerating Conjugate Gradient Solvers for Homogenization Problems with Unitary Neural Operators](https://arxiv.org/abs/2508.02681)
*Julius Herb,Felix Fritzen*

Main category: math.NA

TL;DR: UNO-CG is a hybrid solver combining machine-learned preconditioners with conjugate gradient methods to accelerate PDE solutions while ensuring convergence.


<details>
  <summary>Details</summary>
Motivation: The need for efficient solvers for parametric PDEs in material design, overcoming limitations of classical solvers (high cost) and data-driven methods (lack of accuracy guarantees).

Method: Introduces UNO-CG, using Unitary Neural Operators as preconditioners to accelerate conjugate gradient solvers, ensuring convergence by design.

Result: Substantial reduction in iterations, competitive with expert-crafted preconditioners, and robust across diverse boundary conditions.

Conclusion: UNO-CG offers a versatile, robust, and efficient hybrid approach for solving homogenization problems with heterogeneous microstructures.

Abstract: Rapid and reliable solvers for parametric partial differential equations
(PDEs) are needed in many scientific and engineering disciplines. For example,
there is a growing demand for composites and architected materials with
heterogeneous microstructures. Designing such materials and predicting their
behavior in practical applications requires solving homogenization problems for
a wide range of material parameters and microstructures. While classical
numerical solvers offer reliable and accurate solutions supported by a solid
theoretical foundation, their high computational costs and slow convergence
remain limiting factors. As a result, scientific machine learning is emerging
as a promising alternative. However, such approaches often lack guaranteed
accuracy and physical consistency. This raises the question of whether it is
possible to develop hybrid approaches that combine the advantages of both
data-driven methods and classical solvers. To address this, we introduce
UNO-CG, a hybrid solver that accelerates conjugate gradient (CG) solvers using
specially designed machine-learned preconditioners, while ensuring convergence
by construction. As a preconditioner, we propose Unitary Neural Operators as a
modification of Fourier Neural Operators. Our method can be interpreted as a
data-driven discovery of Green's functions, which are then used to accelerate
iterative solvers. We evaluate UNO-CG on various homogenization problems
involving heterogeneous microstructures and millions of degrees of freedom. Our
results demonstrate that UNO-CG enables a substantial reduction in the number
of iterations and is competitive with handcrafted preconditioners for
homogenization problems that involve expert knowledge. Moreover, UNO-CG
maintains strong performance across a variety of boundary conditions, where
many specialized solvers are not applicable, highlighting its versatility and
robustness.

</details>


### [7] [Transient thermal analysis of a bi-layered composites with the dual-reciprocity inclusion-based boundary element method](https://arxiv.org/abs/2508.02683)
*Chunlin Wu,Liangliang Zhang,Tengxiang Wang,Huiming Yin*

Main category: math.NA

TL;DR: Proposes a DR-iBEM for 3D bi-layered composites with ellipsoidal inhomogeneities under thermal loads, validated by FEM.


<details>
  <summary>Details</summary>
Motivation: To analyze transient/harmonic thermal behaviors in bi-layered composites with material mismatches.

Method: Uses dual-reciprocity method to transform heat equation into boundary integrals, avoiding interface continuity equations. Introduces eigen-fields for material mismatch.

Result: Validated by FEM, showing robustness and accuracy. Applied to functionally graded materials.

Conclusion: DR-iBEM is effective for thermal analysis in bi-layered composites and graded materials.

Abstract: This paper proposes a single-domain dual-reciprocity inclusion-based boundary
element method (DR-iBEM) for a three-dimensional fully bonded bi-layered
composite embedded with ellipsoidal inhomogeneities under transient/harmonic
thermal loads. The heat equation is interpreted as a static one containing
time- and frequency-dependent nonhomogeneous source terms, which is similar to
eigen-fields but is transformed into a boundary integral by the
dual-reciprocity method. Using the steady-state bimaterial Green's function,
boundary integral equations are proposed to take into account continuity
conditions of temperature and heat flux, which avoids setting up any continuity
equations at the bimaterial interface. Eigen-temperature-gradients and
eigen-heat-source are introduced to simulate the material mismatch in thermal
conductivity and heat capacity, respectively. The DR-iBEM algorithm is
particularly suitable for investigating the transient and harmonic thermal
behaviors of bi-layered composites and is verified by the finite element method
(FEM). Numerical comparison with the FEM demonstrates its robustness and
accuracy. The method has been applied to a functionally graded material as a
bimaterial with graded particle distributions, where particle size and
gradation effects are evaluated.

</details>


### [8] [Diffusive behavior of transport noise on $\mathbb{S}^2$](https://arxiv.org/abs/2508.02707)
*Sagy Ephrati,Erik Jansson,Andrea Papini*

Main category: math.NA

TL;DR: The paper studies noise-induced diffusion in spherical flows, showing that transport noise mimics Navier-Stokes-like dissipation while preserving enstrophy and coadjoint orbits.


<details>
  <summary>Details</summary>
Motivation: To extend prior work on torus flows to spherical dynamics and explore noise as a parametrization for unresolved processes in geophysical fluids.

Method: Theoretical and numerical analysis using the Zeitlin discretization for structure-preserving simulations.

Result: Appropriate transport noise induces energy dissipation without altering enstrophy or coadjoint orbits.

Conclusion: The findings support using transport noise models for parametrizing unresolved processes in geophysical fluid simulations.

Abstract: We investigate transport theoretically and numerically noise-induced
diffusion in flows on the sphere. Previous analysis on the torus demonstrated
that suitably chosen transport noise in the Euler equations leads to diffusive
behavior resembling the Navier--Stokes equations. Here, we analyze dynamics on
the sphere with noise-induced differential elliptic operator dissipation and
characterize their energy and enstrophy decay properties. Through
structure-preserving numerical simulations with the Zeitlin discretization, we
demonstrate that appropriately scaled transport noise induces energy
dissipation while preserving enstrophy and coadjoint orbits. The presented
analysis lays a groundwork for further theoretical investigation of transport
noise and supports the calibration of transport noise models as a
parametrization for unresolved processes in geophysical fluid simulations.

</details>


### [9] [Spline Shallow Water Moment Equations](https://arxiv.org/abs/2508.02714)
*Ullika Scholz,Julian Koellermeier*

Main category: math.NA

TL;DR: The paper introduces Spline Shallow Water Moment Equations (SSWME) for flexible velocity profile modeling in shallow flows, addressing limitations of existing models.


<details>
  <summary>Details</summary>
Motivation: Existing reduced models like the Shallow Water Equations (SWE) lack vertical velocity profile details, while the Shallow Water Moment Equations (SWME) use global polynomials, limiting flexibility.

Method: The SSWME uses piecewise spline ansatz functions for adaptable velocity profiles, systematically deriving and analyzing hierarchies of models, including a regularized hyperbolic version.

Result: Numerical simulations demonstrate the SSWME's high accuracy and robustness.

Conclusion: The SSWME offers a flexible and accurate alternative for modeling shallow flows with velocity profile variations.

Abstract: Reduced models for free-surface flows are required due to the high
dimensionality of the underlying incompressible Navier-Stokes equations, which
need to fully resolve the flow in vertical direction to compute the surface
height. On the other hand, standard reduced models, such as the classical
Shallow Water Equations (SWE), which assume a small depth-to-length ratio and
use depth-averaging, do not provide information about the vertical velocity
profile variations. As a compromise, a recently proposed moment approach for
shallow flow using Legendre polynomials as ansatz functions for vertical
velocity variations showed the derivation of so-called Shallow Water Moment
Equations (SWME) that combine low dimensionality with velocity profile
modeling. However, only global polynomials are considered so far.
  This paper introduces Spline Shallow Water Moment Equations (SSWME) where
piecewise defined spline ansatz functions allow for a flexible representation
of velocity profiles with lower regularity. The local support of the spline
basis functions opens up the possibility of adaptability and greater
flexibility regarding some typical profile shapes. We systematically derive and
analyze hierarchies of SSWME models with different number of basis functions
and different degrees, before deriving a regularized hyperbolic version by
performing a hyperbolic regularization with analytical proof of hyperbolicity
for a hierarchy of high-order SSWME models. Numerical simulations show high
accuracy and robustness of the new models.

</details>


### [10] [DD-DeepONet: Domain decomposition and DeepONet for solving partial differential equations in three application scenarios](https://arxiv.org/abs/2508.02717)
*Bo Yang,Xingquan Li,Jie Zhao,Ying Jiang*

Main category: math.NA

TL;DR: DD-DeepONet is a scalable framework for repetitive PDE solving, decomposing complex geometries into simpler structures. It reduces training difficulty, requires smaller datasets, and speeds up solutions.


<details>
  <summary>Details</summary>
Motivation: Addresses the need for rapid, repetitive PDE solving in engineering applications with varying geometries, boundary conditions, or parameters.

Method: Decomposes complex geometries into simple structures (rectangles/cuboids) and uses stretching transformations for shape-dependent problems.

Result: Successfully solves PDEs like Laplace, Poisson, N-S, and drift-diffusion equations, showing reduced training difficulty and faster solutions.

Conclusion: DD-DeepONet is efficient for repetitive PDE simulations, offering scalability and computational advantages.

Abstract: In certain practical engineering applications, there is an urgent need to
perform repetitive solving of partial differential equations (PDEs) in a short
period. This paper primarily considers three scenarios requiring extensive
repetitive simulations. These three scenarios are categorized based on whether
the geometry, boundary conditions(BCs), or parameters vary. We introduce the
DD-DeepONet, a framework with strong scalability, whose core concept involves
decomposing complex geometries into simple structures and vice versa. We
primarily study complex geometries composed of rectangles and cuboids, which
have numerous practical applications. Simultaneously, stretching
transformations are applied to simple geometries to solve shape-dependent
problems. This work solves several prototypical PDEs in three scenarios,
including Laplace, Poission, N-S, and drift-diffusion equations, demonstrating
DD-DeepONet's computational potential. Experimental results demonstrate that
DD-DeepONet reduces training difficulty, requires smaller datasets andVRAMper
network, and accelerates solution acquisition.

</details>


### [11] [Floquet stability of periodically stationary pulses in a short-pulse fiber laser](https://arxiv.org/abs/2508.02735)
*Vrushaly Shinglot,John Zweck*

Main category: math.NA

TL;DR: The paper introduces a lumped model for short-pulse fiber lasers, using the monodromy operator for stability analysis and a gradient-based optimization method for periodic pulse discovery. A novel Fourier split-step method is developed for linearized propagation modeling.


<details>
  <summary>Details</summary>
Motivation: Traditional averaged models fail for modern short-pulse fiber lasers due to large pulse parameter variations. Lumped models are needed for accurate quantitative modeling and design.

Method: The study uses the monodromy operator for linear stability analysis, a gradient-based optimization method for periodic pulses, and a novel Fourier split-step method for solving linearized propagation equations.

Result: The monodromy operator's spectrum includes essential spectrum and eigenvalues, with a multiplicity two eigenvalue at λ=1. Simulations validate the numerical methods and demonstrate stable periodic pulses.

Conclusion: The proposed methods accurately model and optimize short-pulse fiber lasers, providing insights into pulse stability and periodic solutions.

Abstract: The quantitative modeling and design of modern short-pulse fiber lasers
cannot be performed with averaged models because of large variations in the
pulse parameters within each round trip. Instead, lumped models obtained by
concatenating models for the various components of the laser are required.
Since the optical pulses in lumped models are periodic, their linear stability
is investigated using the monodromy operator, which is the linearization of the
roundtrip operator about the pulse. A gradient-based optimization method is
developed to discover periodic pulses. The computation of the gradient of the
objective function involves numerical computation of the action of both the
round trip operator and the adjoint of the monodromy operator. A novel Fourier
split-step method is introduced to compute solutions of the linearization of
the nonlinear, nonlocal, stiff equation that models optical propagation in the
fiber amplifier. This method is derived by linearizing the two solution
operators in a split-step method for the nonlinear equation. The spectrum of
the monodromy operator consists of the essential spectrum, for which there is
an analytical formula, and the eigenvalues. There is a multiplicity two
eigenvalue at $\lambda=1$, which is due to phase and translation invariance.
The remaining eigenvalues are determined from a matrix discretization of the
monodromy operator. Simulation results verify the accuracy of the numerical
methods, show examples of periodically stationary pulses, their spectra and
eigenfunctions, and discuss their stability.

</details>


### [12] [Mixed Finite Element Method for a Hemivariational Inequality of Stationary convective Brinkman-Forchheimer Extended Darcy equations](https://arxiv.org/abs/2508.02797)
*Wasim Akram,Manil T. Mohan*

Main category: math.NA

TL;DR: A mixed finite element method is developed for a hemivariational inequality in the CBFeD model, handling nonsmooth boundary conditions and achieving optimal convergence rates with low-order elements.


<details>
  <summary>Details</summary>
Motivation: To model viscous, incompressible fluid flow in porous media with nonsmooth boundary conditions, extending the Navier-Stokes equations.

Method: Mixed finite element method with pseudomonotonicity and coercivity analysis; uses P1b/P1 element pair.

Result: Existence, uniqueness, and optimal convergence rates proven; numerical experiments validate theory.

Conclusion: The method effectively solves the CBFeD model with nonsmooth conditions, supported by theory and experiments.

Abstract: This paper presents the formulation and analysis of a mixed finite element
method for a hemivariational inequality arising from the stationary convective
Brinkman-Forchheimer extended Darcy (CBFeD) equations. This model extends the
incompressible Navier-Stokes equations by incorporating both damping and
pumping effects. The hemivariational inequality describes the flow of a
viscous, incompressible fluid through a saturated porous medium, subject to a
nonsmooth, nonconvex friction-type slip boundary condition. The
incompressibility constraint is handled via a mixed variational formulation. We
establish the existence and uniqueness of solutions by utilizing the
pseudomonotonicity and coercivity properties of the underlying operators and
provide a detailed error analysis of the proposed numerical scheme. Under
suitable regularity assumptions, the method achieves optimal convergence rates
with low-order mixed finite element pairs. The scheme is implemented using the
$\text{P1b/P1}$ element pair, and numerical experiments are presented to
validate the theoretical results and confirm the expected convergence behavior.

</details>


### [13] [H(curl)-based approximation of the Stokes problem with weakly enforced no-slip boundary conditions](https://arxiv.org/abs/2508.02861)
*Wietse M. Boon,Wouter Tonnon,Enrico Zampa*

Main category: math.NA

TL;DR: The paper addresses the challenge of imposing no-slip boundary conditions in H(curl)-based Stokes flow formulations, proposing a Nitsche-based finite element method to avoid ill-posed discretizations.


<details>
  <summary>Details</summary>
Motivation: The motivation is to ensure proper boundary conditions in structure-preserving discretizations of Navier-Stokes and magnetohydrodynamics equations, avoiding ill-posed problems.

Method: The authors propose a Nitsche-based finite element method to enforce no-slip boundary conditions, analyzing stability and deriving a priori error estimates.

Result: Numerical experiments confirm the method's stability and show optimal convergence rates for the velocity field.

Conclusion: The Nitsche-based approach effectively resolves the ill-posed issue and ensures accurate results for incompressible Stokes flow.

Abstract: In this work, we show how to impose no-slip boundary conditions for an
H(curl)-based formulation for incompressible Stokes flow, which is used in
structure-preserving discretizations of Navier-Stokes and magnetohydrodynamics
equations. At first glance, it seems straightforward to apply no-slip boundary
conditions: the tangential part is an essential boundary condition on H(curl)
and the normal component can be naturally enforced through integration-by-parts
of the divergence term. However, we show that this can lead to an ill-posed
discretization and propose a Nitsche-based finite element method instead. We
analyze the discrete system, establishing stability and deriving a priori error
estimates. Numerical experiments validate our analysis and demonstrate optimal
convergence rates for the velocity field.

</details>


### [14] [Goal-Oriented Adaptive Finite Element Multilevel Quasi-{M}onte {C}arlo](https://arxiv.org/abs/2508.02925)
*Joakim Beck,Yang Liu,Erik von Schwerin,Raúl Tempone*

Main category: math.NA

TL;DR: A multilevel quasi-Monte Carlo framework is proposed for approximating PDE solutions with lognormal diffusivity, using adaptive meshes and variance reduction techniques to achieve higher efficiency.


<details>
  <summary>Details</summary>
Motivation: Efficient approximation of PDE-derived quantities with lognormal diffusivity is challenging in uncertainty quantification.

Method: Multilevel quasi-Monte Carlo with adaptive meshes, importance sampling, and a level-0 control variate.

Result: The adaptive QMC algorithm achieves desired accuracy at lower computational cost than standard multilevel Monte Carlo.

Conclusion: The proposed framework is effective for PDEs with lognormal diffusivity, especially with adaptive meshes and variance reduction.

Abstract: The efficient approximation of quantity of interest derived from PDEs with
lognormal diffusivity is a central challenge in uncertainty quantification. In
this study, we propose a multilevel quasi-Monte Carlo framework to approximate
deterministic, real-valued, bounded linear functionals that depend on the
solution of a linear elliptic PDE with a lognormal diffusivity coefficient
{parameterized by a 49-dimensional Gaussian random vector} and deterministic
geometric singularities in bounded domains of $\mathbb{R}^d$. We analyze the
parametric regularity and develop the multilevel implementation based on a
sequence of adaptive meshes, developed in "Goal-oriented adaptive finite
element multilevel Monte Carlo with convergence rates", \emph{CMAME}, 402
(2022), p. 115582. For further variance reduction, we incorporate importance
sampling and introduce a level-0 control variate within the multilevel
hierarchy. {Introducing such control variate can alter the optimal choice of
initial mesh, further highlighting the advantages of adaptive meshes.}
Numerical experiments demonstrate that our adaptive QMC algorithm achieves a
prescribed accuracy at substantially lower computational cost than the standard
multilevel Monte Carlo method.

</details>


### [15] [Sparse Identification of Nonlinear Dynamics for Stochastic Delay Differential Equations](https://arxiv.org/abs/2508.03040)
*Dimitri Breda,Dajana Conte,Raffaele D'Ambrosio,Ida Santaniello,Muhammad Tanveer*

Main category: math.NA

TL;DR: A framework for recovering drift and diffusion dynamics from sampled trajectories in stochastic delay differential equations using SINDy and high-order estimates.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of identifying drift and diffusion dynamics in stochastic delay differential equations from sampled data.

Method: Combines SINDy for sparse identification with high-order drift/covariance estimates and augmented libraries for delayed arguments. Three strategies are proposed for realistic data usage.

Result: Numerical investigation on various models provides insights into effective and outperforming schemes.

Conclusion: The framework successfully identifies dynamics, with comparative analysis guiding optimal strategy selection.

Abstract: A general framework for recovering drift and diffusion dynamics from sampled
trajectories is presented for the first time for stochastic delay differential
equations. The core relies on the well-established SINDy algorithm for the
sparse identification of nonlinear dynamics. The proposed methodology combines
recently proposed high-order estimates of drift and covariance for dealing with
stochastic problems with augmented libraries to handle delayed arguments. Three
different strategies are discussed in view of exploiting only realistically
available data. A thorough comparative numerical investigation is performed on
different models, which helps guiding the choice of effective and possibly
outperforming schemes.

</details>


### [16] [Low-rankness and Smoothness Meet Subspace: A Unified Tensor Regularization for Hyperspectral Image Super-resolution](https://arxiv.org/abs/2508.03049)
*Jun Zhang,Chao Yi,Mingxi Ma,Chao Wang*

Main category: math.NA

TL;DR: Proposes JLRST, a unified tensor regularizer for hyperspectral image super-resolution, combining low-rankness and local smoothness priors under a subspace framework for improved efficiency and accuracy.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenge of hyperspectral image super-resolution (HSI-SR) by overcoming limitations of existing regularization techniques due to high spectral dimensionality.

Method: Introduces JLRST, a tensor regularizer encoding low-rankness and local smoothness priors on subspace coefficients, using mode-3 logarithmic TNN for gradient tensors and solving via ADMM.

Result: Demonstrates superior performance over state-of-the-art methods in HSI-SR.

Conclusion: JLRST effectively integrates priors and improves computational efficiency and accuracy in HSI-SR.

Abstract: Hyperspectral image super-resolution (HSI-SR) has emerged as a challenging
yet critical problem in remote sensing. Existing approaches primarily focus on
regularization techniques that leverage low-rankness and local smoothness
priors. Recently, correlated total variation has been introduced for tensor
recovery, integrating these priors into a single regularization framework.
Direct application to HSI-SR, however, is hindered by the high spectral
dimensionality of hyperspectral data. In this paper, we propose a unified
tensor regularizer, called JLRST, which jointly encodes low-rankness and local
smoothness priors under a subspace framework. Specifically, we compute the
gradients of the clustered coefficient tensors along all three tensor modes to
fully exploit spectral correlations and nonlocal similarities in HSI. By
enforcing priors on subspace coefficients rather than the entire HR-HSI data,
the proposed method achieves improved computational efficiency and accuracy.
Furthermore, to mitigate the bias introduced by the tensor nuclear norm (TNN),
we introduce the mode-3 logarithmic TNN to process gradient tensors. An
alternating direction method of multipliers with proven convergence is
developed to solve the proposed model. Experimental results demonstrate that
our approach significantly outperforms state-of-the-art methods in HSI-SR.

</details>


### [17] [Reduced Order Data-driven Twin Models for Nonlinear PDEs by Randomized Koopman Orthogonal Decomposition and Explainable Deep Learning](https://arxiv.org/abs/2508.03325)
*D. A. Bistrian*

Main category: math.NA

TL;DR: A data-driven twin modeling framework using Koopman operator theory improves nonlinear dynamics capture with reduced complexity and no manual tuning.


<details>
  <summary>Details</summary>
Motivation: To advance classical modal decomposition by accurately modeling nonlinear dynamics without heuristic adjustments.

Method: Integrates a novel algorithm with Pareto front analysis for reduced-order models, uses NLARX deep learning for real-time calibration, and computes orthogonal Koopman modes via randomized projections.

Result: Demonstrated on shock wave phenomena with three experiments, showing high-fidelity, self-consistent models.

Conclusion: The framework enhances interpretability and accuracy in data-driven twin modeling, avoiding heuristic choices.

Abstract: This study introduces a data-driven twin modeling framework based on modern
Koopman operator theory, offering a significant advancement over classical
modal decomposition by accurately capturing nonlinear dynamics with reduced
complexity and no manual parameter adjustment. The method integrates a novel
algorithm with Pareto front analysis to construct a compact, high-fidelity
reduced-order model that balances accuracy and efficiency. An explainable NLARX
deep learning framework enables real-time, adaptive calibration and prediction,
while a key innovation-computing orthogonal Koopman modes via randomized
orthogonal projections-ensures optimal data representation. This approach for
data-driven twin modeling is fully self-consistent, avoiding heuristic choices
and enhancing interpretability through integrated explainable learning
techniques. The proposed method is demonstrated on shock wave phenomena using
three experiments of increasing complexity, accompanied by a qualitative
analysis of the resulting data-driven twin models.

</details>


### [18] [Estimation of Hemodynamic Parameters via Physics Informed Neural Networks including Hematocrit Dependent Rheology](https://arxiv.org/abs/2508.03326)
*Moises Sierpe,Ernesto Castillo,Hernan Mella,Felipe Galarce*

Main category: math.NA

TL;DR: PINNs effectively estimate velocity and pressure fields from 4D flow MRI data, outperforming vWERP in accuracy and resolution, especially when integrated into the vWERP framework.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of solving inverse problems in blood flow dynamics with limited observations using Physics-Informed Neural Networks (PINNs).

Method: Utilized PINNs with adaptive loss balancing, curriculum training, and a realistic measurement operator to analyze 3D blood flow in an aortic model under various hematocrit conditions.

Result: PINNs accurately estimated viscosity and pressure fields, with relative errors below 5%, and outperformed vWERP in accuracy and time resolution.

Conclusion: PINNs, especially when combined with vWERP, provide superior results for blood flow analysis, offering clinically viable accuracy and high-resolution estimations.

Abstract: Physics-Informed Neural Networks (PINNs) show significant potential for
solving inverse problems, especially when observations are limited and sparse,
provided that the relevant physical equations are known. We use PINNs to
estimate smooth velocity and pressure fields from synthetic 4D flow Magnetic
Resonance Imaging (MRI) data. We analyze five non-Newtonian dynamic 3D blood
flow cases within a realistic aortic model, covering a range of hematocrit
values from anemic to polycythemic conditions. To enhance state estimation
results, we consider various design and training techniques for PINNs,
including adaptive loss balancing, curriculum training, and a realistic
measurement operator. Regarding blood rheology, the PINN approach accurately
estimates viscosity globally and locally under peak systolic conditions. It
also provides a clear pattern recognition for diastolic stages. Regarding mass
conservation, PINN estimations effectively reproduce the bifurcation of flow
through the different branches of the aorta, demonstrate an excellent
representation of the non-slip conditions at the walls, and accurately estimate
pressure drops with relative errors below the 5% in the whole pressure field.
We test our pressure drop estimations against the state of the art Virtual Work
Energy Relative Pressure (vWERP) estimator, and we observe how our results
outperform vWERP in terms of both accuracy and time resolution. Additionally,
we find that the best results are achieved by computing the velocity field
using the PINN, which is then integrated into the vWERP framework, leading to
time super-sampled and high-order approximations, with a clinically admissible
accuracy.

</details>


### [19] [Two operator splitting methods for three-dimensional stochastic Maxwell equations with multiplicative noise](https://arxiv.org/abs/2508.03390)
*Liying Zhang,Xinyue Kang,Lihai Ji*

Main category: math.NA

TL;DR: Two energy-preserving splitting methods (Splitting Method I and II) for 3D stochastic Maxwell equations with multiplicative noise are developed, preserving discrete energy conservation and achieving first-order temporal convergence.


<details>
  <summary>Details</summary>
Motivation: To solve 3D stochastic Maxwell equations efficiently while preserving energy, addressing the challenge of multiplicative noise.

Method: Operator splitting decouples equations into 1D subsystems; combines spatial compact difference, midpoint rule for deterministic parts, and exact unitary solutions for stochastic parts.

Result: Both methods strictly preserve discrete energy conservation; numerical experiments confirm energy preservation and first-order temporal convergence.

Conclusion: The proposed methods are effective for energy-preserving solutions of stochastic Maxwell equations with multiplicative noise.

Abstract: In this paper, we develop two energy-preserving splitting methods for solving
three-dimensional stochastic Maxwell equations driven by multiplicative noise.
We use operator splitting methods to decouple stochastic Maxwell equations into
simple one-dimensional subsystems and construct two stochastic splitting
methods, Splitting Method I and Splitting Method II, through a combination of
spatial compact difference methods and the midpoint rule in time discretization
for the deterministic parts, and exact unitary analytical solutions for the
stochastic parts. Theoretical proofs show that both methods strictly preserve
the discrete energy conservation law. Finally, numerical experiments fully
verify the energy conservation of the methods and demonstrate that the temporal
convergence order of the two splitting methods is first-order.

</details>


### [20] [A matrix preconditioning framework for physics-informed neural networks based on adjoint method](https://arxiv.org/abs/2508.03421)
*Jiahao Song,Wenbo Cao,Weiwei Zhang*

Main category: math.NA

TL;DR: The paper proposes a matrix preconditioning method to improve the convergence of physics-informed neural networks (PINNs) for solving PDEs, addressing slow convergence and failure issues.


<details>
  <summary>Details</summary>
Motivation: PINNs struggle with slow convergence and failure in certain scenarios, particularly in multi-scale and high Reynolds number problems. The study aims to enhance PINN performance by improving the condition number of the Jacobian matrix.

Method: The method combines automatic differentiation with matrix coloring to compute the Jacobian matrix, constructs a preconditioner via incomplete LU factorization, and scales the PDE residual in the loss function. A framework based on the adjoint method is also designed to handle gradient computation.

Result: Numerical experiments show the method successfully solves multi-scale and high Reynolds number problems where standard PINNs fail.

Conclusion: The proposed preconditioning method effectively improves PINN convergence and performance in challenging scenarios.

Abstract: Physics-informed neural networks (PINNs) have recently emerged as a popular
approach for solving forward and inverse problems involving partial
differential equations (PDEs). Compared to fully connected neural networks,
PINNs based on convolutional neural networks offer advantages in the hard
enforcement of boundary conditions and in reducing the computational cost of
partial derivatives. However, the latter still struggles with slow convergence
and even failure in some scenarios. In this study, we propose a matrix
preconditioning method to improve the convergence of the latter. Specifically,
we combine automatic differentiation with matrix coloring to compute the
Jacobian matrix of the PDE system, which is used to construct the
preconditioner via incomplete LU factorization. We subsequently use the
preconditioner to scale the PDE residual in the loss function in order to
reduce the condition number of the Jacobian matrix, which is key to improving
the convergence of PINNs. To overcome the incompatibility between automatic
differentiation and triangular solves in the preconditioning, we also design a
framework based on the adjoint method to compute the gradients of the loss
function with respect to the network parameters. By numerical experiments, we
validate that the proposed method successfully and efficiently solves the
multi-scale problem and the high Reynolds number problem, in both of which
PINNs fail to obtain satisfactory results.

</details>


### [21] [Numerical study on a multi-dimensional pressureless Euler-type model with non-local interactions and chemotaxis for collective cell migration](https://arxiv.org/abs/2508.03439)
*Marta Menci,Roberto Natalini,Tommaso Tenna*

Main category: math.NA

TL;DR: Numerical study of a pressureless Euler-type model for collective cell migration, derived from microscopic dynamics, with non-local interactions and chemotaxis. Extended to multi-population interactions and validated via parameter estimation.


<details>
  <summary>Details</summary>
Motivation: To understand collective cell migration through macroscopic models derived from microscopic dynamics, incorporating mechanical and chemotactic interactions.

Method: Proposes a multi-dimensional pressureless Euler-type model with non-local interactions and chemotaxis, extended to multiple cell populations. Validated via parameter estimation.

Result: The macroscopic model aligns with microscopic dynamics, demonstrating validity in specific settings.

Conclusion: The model effectively captures collective cell migration dynamics, including multi-population interactions, and is validated through parameter analysis.

Abstract: In this paper we propose a numerical study of macroscopic models for
collective cell migration, focusing on a multi-dimensional pressureless
Euler-type model with non-local interactions coupled with chemotaxis,
rigorously derived from microscopic dynamics. Different mechanical interactions
are investigated, including attraction-repulsion effects. Moreover, the model
is extended to the case of different populations of interacting cells. The
validity of such macroscopic model and its agreement with the microscopic
dynamics is finally assessed through a parameter estimation analysis in a
specific setting.

</details>


### [22] [Error Estimates of Semi-Lagrangian Schemes for Diffusive Conservation Laws](https://arxiv.org/abs/2508.03455)
*Haruki Takemura*

Main category: math.NA

TL;DR: Error estimates for a fully semi-Lagrangian scheme with high-order interpolation operators for nonlinear diffusive conservation laws, showing convergence rates in $L^2$ and $H^s$ norms.


<details>
  <summary>Details</summary>
Motivation: To analyze and validate the error estimates of high-order interpolation methods (spline and Hermite) in solving nonlinear diffusive conservation laws, particularly the Burgers equation.

Method: A fully semi-Lagrangian scheme with high-order interpolation operators (spline and Hermite) is applied to solve initial value problems for one-dimensional nonlinear diffusive conservation laws. Theoretical convergence rates are derived.

Result: Convergence rates of $O(\Delta t + h^{2s} / \Delta t)$ in $L^2$-norm and $O(\Delta t + h^{s} / (\Delta t)^{1/2} + h^{2s} / \Delta t)$ in $H^s$-norm are established, validated by numerical results.

Conclusion: The theoretical error estimates align with numerical results, confirming the effectiveness of high-order interpolation operators in the semi-Lagrangian scheme for solving nonlinear diffusive conservation laws.

Abstract: We present error estimates of the fully semi-Lagrangian scheme with
high-order interpolation operators, solving the initial value problems for the
one-dimensional nonlinear diffusive conservation laws, including the Burgers
equations. We impose certain assumptions on the interpolation operator, which
are satisfied by both spline and Hermite interpolations. We establish the
convergence rates of $ O(\Delta t + h^{2 s} / \Delta t) $ in the $ L^2 $-norm
and $ O(\Delta t + h^{s} / (\Delta t)^{1/2} + h^{2s} / \Delta t) $ in the $ H^s
$-norm for the spatial mesh size $ h $ and the temporal step size $ \Delta t $,
where the spline or Hermite interpolation operator of degree $ (2s - 1) $ is
employed. The numerical results are in agreement with the theoretical analysis.

</details>


### [23] [Homogenization rates of beam lattices to micropolar continua](https://arxiv.org/abs/2508.03512)
*Eric T. Chung,Kuang Huang,Changqing Ye*

Main category: math.NA

TL;DR: The paper rigorously analyzes the homogenization of a beam lattice into a micropolar continuum, deriving quantitative error estimates and revealing deviations from classical theory due to rotational degrees of freedom.


<details>
  <summary>Details</summary>
Motivation: The engineering community lacks quantitative homogenization error estimates for beam lattices, which this paper addresses.

Method: The study uses Fourier transformations and Schur complement techniques to analyze homogenization, focusing on a triangular lattice with periodic boundary conditions.

Result: The homogenization process differs from classical theory beyond low-frequency modes, and optimal convergence rate estimates are derived and validated numerically.

Conclusion: The paper provides rigorous quantitative homogenization error estimates for beam lattices, highlighting the role of rotational degrees of freedom.

Abstract: As the size of a mechanical lattice with beam-modeled edges approaches zero,
it undergoes homogenization into a continuum model, which exhibits unusual
mechanical properties that deviate from classical Cauchy elasticity, named
micropolar elasticity. Typically, the homogenization process is qualitative in
the engineering community, lacking quantitative homogenization error estimates.
In this paper, we rigorously analyze the homogenization process of a beam
lattice to a continuum. Our approach is initiated from an engineered mechanical
problem defined on a triangular lattice with periodic boundary conditions. By
applying Fourier transformations, we reduce the problem to a series of
equations in the frequency domain. As the lattice size approaches zero, this
yields a homogenized model in the form of a partial differential equation with
periodic boundary conditions. This process can be easily justified if the
external conditions in the frequency domain are nonzero only at low-frequency
modes. However, through numerical experiments, we discover that beyond the
low-frequency regime, the homogenization of the beam lattice differs from
classical periodic homogenization theory due to the additional rotational
degrees of freedom in the beams. A crucial technique in our analysis is the
decoupling of displacement and rotation fields, achieved through a linear
algebraic manipulation known as the Schur complement. Through dedicated
analysis, we establish the coercivity of the Schur complements in both lattice
and continuum models, which enables us to derive convergence rate estimates for
homogenization errors. Numerical experiments validate the optimality of the
homogenization rate estimates.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [24] [Global Dynamics of the Non-Radial Energy-Critical Inhomogeneous Biharmonic NLS](https://arxiv.org/abs/2508.02796)
*Carlos M. Guzmán,Sahbi Keraani,Chengbin Xu*

Main category: math.AP

TL;DR: The paper studies the inhomogeneous nonlinear biharmonic Schrödinger equation in the energy-critical regime, focusing on non-radial settings. It proves global well-posedness and scattering under a subcritical assumption, overcoming challenges posed by spatial inhomogeneity and fourth-order dispersion.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend previous results (often relying on radial symmetry) to the non-radial setting, addressing analytical challenges introduced by spatial inhomogeneity and fourth-order dispersion.

Method: The authors develop a refined concentration-compactness and rigidity framework, inspired by the Kenig-Merle approach and recent work in second-order inhomogeneous settings.

Result: Global well-posedness and scattering are established under the subcritical assumption, without relying on symmetry or conserved quantities.

Conclusion: The work successfully tackles the non-radial, inhomogeneous case, providing a framework for future studies in similar contexts.

Abstract: We investigate the focusing inhomogeneous nonlinear biharmonic Schr\"odinger
equation \[ i\partial_t u + \Delta^2 u - |x|^{-b}|u|^p u = 0 \quad \text{on }
\mathbb{R} \times \mathbb{R}^N, \] in the energy-critical regime, $p = \frac{8
- 2b}{N - 4}$, and $5 \leq N < 12$. We focus on the challenging non-radial
setting and establish global well-posedness and scattering under the
subcritical assumption $ \sup_{t \in I} \|\Delta u(t)\|_{L^2} < \|\Delta
W\|_{L^2}, $ where $W$ denotes the ground state solution to the associated
elliptic equation.
  In contrast to previous results in the homogeneous case ($b = 0$), which
often rely on radial symmetry and conserved quantities, our analysis is carried
out without symmetry assumptions and under a non-conserved quantity, the
kinetic energy. The presence of spatial inhomogeneity combined with the
fourth-order dispersive operator introduces substantial analytical challenges.
To overcome these difficulties, we develop a refined concentration-compactness
and rigidity framework, based on the Kenig-Merle approach \cite{KM}, but more
directly inspired by recent work of Murphy and the first author \cite{CM} in
the second-order inhomogeneous setting.

</details>


### [25] [On the Rayleigh--B\' enard convection problem for rotating fluids](https://arxiv.org/abs/2508.02933)
*Francesco Fanelli,Eduard Feireisl*

Main category: math.AP

TL;DR: The Oberbeck-Boussinesq approximation cannot be derived as a singular limit of the Navier-Stokes-Fourier system in a rotating frame with buoyancy forces involving gravity and centrifugal effects.


<details>
  <summary>Details</summary>
Motivation: To clarify the limitations of the Oberbeck-Boussinesq approximation in rotating systems with combined gravitational and centrifugal buoyancy forces.

Method: Analyze the Navier-Stokes-Fourier system in a rotational coordinate system, focusing on the buoyancy force's dependence on temperature variation, gravity, and centrifugal forces.

Result: The standard Oberbeck-Boussinesq approximation fails to emerge as a singular limit under these conditions.

Conclusion: The study highlights the inapplicability of the Oberbeck-Boussinesq approximation in certain rotating fluid systems, suggesting the need for alternative models.

Abstract: In contrast with a large variety of conventional models of thermally driven
fluids, we show that the standard Oberbeck--Boussinesq approximation
\emph{cannot} be obtained as a singular limit of the Navier--Stokes--Fourier
system in the rotational coordinate system, with the buoyancy force
proportional to the sum of the gravitational and centrifugal forces multiplied
by the temperature variation.

</details>


### [26] [Homogenization of flow in inflatable periodic structures with nonlinear effects](https://arxiv.org/abs/2508.03225)
*Eduard Rohan,Vladimír Lukeš*

Main category: math.AP

TL;DR: A weakly nonlinear two-scale model for inflatable periodic poroelastic structures with Newtonian fluids, incorporating microstructural nonlinearities and homogenized coefficients for computational design.


<details>
  <summary>Details</summary>
Motivation: To develop a computational tool for designing porous metamaterials for fluid transport and shape morphing, addressing nonlinearities in macroscopic Biot-type models.

Method: Derives a homogenized model under small deformation assumptions, using sensitivity analysis for deformation-dependent coefficients and numerical simulations.

Result: Demonstrates inflation processes and induced bending in a bi-material cantilever, validating the model's effectiveness.

Conclusion: The model provides a practical tool for designing porous metamaterials with applications in fluid transport and shape morphing.

Abstract: The paper presents a new type of weakly nonlinear two-scale model of
inflatable periodic poroelastic structures saturated by Newtonian fluids. The
periodic microstructures incorporate fluid inclusions connected to the fluid
channels by admission and ejection valves respected by a 0D model. This induces
a nonlinearity in the macroscopic Biot-type model, whereby the Darcy flow model
governs the fluid transport due to the channels. Moreover, the fluid channels
consist of compartments separated by semipermeable membranes inducing the
pressure discontinuity. The homogenized model is derived under the small
deformation assumption, however the equilibrium is considered in the Eulerian
frame. Deformation-dependent homogenized coefficients of the incremental
poroelasticity constitutive law and the permeability are approximated using the
sensitivity analysis, to avoid coupled two-scale iterations. Numerical
simulations illustrate the inflation process in time. Example of a bi-material
cantilever demonstrates the inflation induced bending. The proposed two-scale
model is intended to provide a computational tool for designing of porous
metamaterials for fluid transport, or shape morphing with various potential
applications.

</details>


### [27] [A variational approach to the volume-preserving anisotropic mean curvature flow in 2D](https://arxiv.org/abs/2508.03134)
*Andrea Kubin,Domenico Angelo La Manna,Enrico Pasqualetto*

Main category: math.AP

TL;DR: A variational algorithm for volume-preserving anisotropic mean curvature flow in 2D is introduced, proving existence and convergence to global solutions.


<details>
  <summary>Details</summary>
Motivation: To model and analyze the volume-preserving anisotropic mean curvature flow in 2D, ensuring classical solutions and global convergence.

Method: A variational algorithm inspired by the minimizing movements scheme is developed.

Result: The algorithm proves existence of classical solutions and converges to the global solution of the equation.

Conclusion: The proposed algorithm effectively models the flow and guarantees convergence to global solutions.

Abstract: In this article, we introduce a variational algorithm, in the spirit of the
minimizing movements scheme, to model the volume-preserving anisotropic mean
curvature flow in 2D. We show that this algorithm can be used to prove the
existence of classical solutions. Moreover, we prove that this algorithm
converges to the global solution of the equation.

</details>


### [28] [Discrete Caffarelli-Kohn-Nirenberg inequalities and ground state solutions to nonlinear elliptic equations](https://arxiv.org/abs/2508.03195)
*Fengwen Han,Ruowei Li*

Main category: math.AP

TL;DR: The paper extends discrete Caffarelli-Kohn-Nirenberg inequalities on lattices, proving broader parameter ranges than classical versions, and shows existence of extremal functions for best constants. Applications include nonlinear elliptic equations.


<details>
  <summary>Details</summary>
Motivation: To generalize and extend discrete versions of Caffarelli-Kohn-Nirenberg inequalities on lattices, addressing broader parameter ranges and proving existence of extremal functions.

Method: Proves inequalities using discrete Schwarz rearrangement for special cases, establishing extremal functions for best constants in supercritical cases.

Result: Discrete inequalities hold for extended parameter ranges; extremal functions exist for best constants in supercritical cases.

Conclusion: The work generalizes discrete inequalities and provides solutions to nonlinear elliptic equations, demonstrating practical applications.

Abstract: In this paper, we prove the discrete Caffarelli-Kohn-Nirenberg inequalities
on the lattice $\mathbb{Z}^{N}$ ($N\geq 1$) in a broader range of parameters
than the classical continuous version [8]: \[ \parallel
u\parallel_{\ell_{b}^{q}}\leq C(a,b,c,p,q,r,\theta,N)\parallel
u\parallel_{D_{a}^{1,p}}^{\theta}\parallel
u\parallel_{\ell_{c}^{r}}^{1-\theta},\:\forall u\in
D_{a,0}^{1,p}(\mathbb{Z}^{N}) \cap \ell_c ^r(\mathbb{Z}^{N}), \] where
$p,q,r>1,0\leq\theta\leq1$,
$\frac{1}{p}+\frac{a}{N}>0,\frac{1}{r}+\frac{c}{N}>0,b\leq\theta
a+(1-\theta)c,$$\frac{1}{q^{\ast}}+\frac{b}{N}=
\theta(\frac{1}{p}+\frac{a-1}{N})+(1-\theta)(\frac{1}{r}+\frac{c}{N})$ and
$q\geq q^{\ast}$. For two special cases $\theta=1,a=0$ and $a=b=c=0$, by the
discrete Schwarz rearrangement established in [24], we prove the existence of
extremal functions for the best constants in the supercritical case
$q>q^{\ast}$. As an application, we get positive ground state solutions to the
nonlinear elliptic equations.

</details>


### [29] [Zero-relaxation and vanishing-damping limits of pressureless Euler system](https://arxiv.org/abs/2508.03198)
*Guirong Tang*

Main category: math.AP

TL;DR: The paper analyzes the one-dimensional pressureless Euler system with relaxation in Radon measure space, examining convergence of entropy solutions under varying relaxation times.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of entropy solutions in the pressureless Euler system under extreme relaxation times (zero and infinity).

Method: Study the system in Radon measure space, analyzing convergence of entropy solutions as relaxation time approaches zero and infinity.

Result: For zero relaxation time, density converges to initial value; for infinite time, solution converges to the undamped pressureless Euler system.

Conclusion: The study reveals distinct behaviors of the system under extreme relaxation conditions, providing insights into its dynamics.

Abstract: We are concerned with the one-dimensional pressureless Euler system with
relaxation in the Radon measure space. As the relaxation time tends to zero,
the entropy solution converges to a static solution with the density converging
to its initial value. As the relaxation time tends to infinity, which means the
damping vanishes, the entropy solution of damped pressureless Euler system
converges to that of pressureless Euler system.

</details>


### [30] [Modeling Carreau fluid flows through a very thin porous medium](https://arxiv.org/abs/2508.03214)
*María Anguiano,Matthieu Bonnivard,Francisco J. Suárez-Grau*

Main category: math.AP

TL;DR: The paper studies 3D steady-state non-Newtonian flows in a thin porous medium, analyzing asymptotic behavior as thickness approaches zero, deriving reduced limit systems for filtration velocity and Darcy's laws.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of non-Newtonian fluids in very thin porous media, which is crucial for applications like filtration and microfluidics.

Method: Asymptotic techniques, pressure decomposition, and the unfolding method are used to derive sharp a priori estimates and compactness results for rescaled velocity and pressure.

Result: Different linear and nonlinear reduced limit systems are derived, providing explicit expressions for filtration velocity and simplified Darcy's laws for limit pressure.

Conclusion: The study successfully models non-Newtonian flows in thin porous media, offering practical insights for engineering and industrial applications.

Abstract: This study investigates three-dimensional, steady-state, and non-Newtonian
flows within a very thin porous medium (VTPM). The medium is modeled as a
domain confined between two parallel plates and perforated by solid cylinders
that connect the plates and are distributed periodically in perpendicular
directions. We denote the order of magnitude of the thickness of the domain by
$\epsilon$ and define the period and order of magnitude of the cylinders'
diameter by $\epsilon$^l, where 0 < l < 1 is fixed. In other words, we consider
the regime $\epsilon$ $\ll$ $\epsilon$^l. We assume that the viscosity of the
non-Newtonian fluid follows Carreau's law and is scaled by a factor of
$\epsilon$^$\gamma$, where $\gamma$ is a real number. Using asymptotic
techniques with respect to the thickness of the domain, we perform a new,
complete study of the asymptotic behaviour of the fluid as $\epsilon$ tends to
zero. Our mathematical analysis is based on deriving sharp a priori estimates
through pressure decomposition, and on compactness results for the rescaled
velocity and pressure, obtained using the unfolding method. Depending on
$\gamma$ and the flow index r, we rigorously derive different linear and
nonlinear reduced limit systems. These systems allow us to obtain explicit
expressions for the filtration velocity and simpler Darcy's laws for limit
pressure.

</details>


### [31] [Approximate transonic shock solution for hypersonic flow past a large curved convex wedge](https://arxiv.org/abs/2508.03255)
*Dian Hu*

Main category: math.AP

TL;DR: The paper studies global transonic shocks in hypersonic potential flow over a curved convex wedge, reducing the problem to a linear equation via hodograph transformation and solving it using elliptic boundary value methods.


<details>
  <summary>Details</summary>
Motivation: To understand and model the behavior of hypersonic potential flow over curved surfaces, particularly the formation of transonic shocks.

Method: Uses hodograph transformation to simplify the quasilinear problem into a linear one, then solves a narrow-region elliptic boundary value problem for an approximate solution.

Result: Constructs an approximate boundary and solution, providing an error estimate for the free boundary using Schauder estimates.

Conclusion: The approach successfully approximates the free boundary problem for hypersonic flow, offering insights into transonic shock behavior.

Abstract: In this paper, we study the existence of a global transonic shock generated
by hypersonic potential flow over a large curved convex wedge. Modeling
2-dimensional steady potential flow leads to a free boundary value problem of
quasilinear equation. By applying the hodograph transformation, in which one of
the coordinate is the unknown function, this problem is reduced to a free
boundary value problem of linear equation. For hypersonic incoming flow with
adiabatic index $\gamma=2$, we construct an approximate boundary based on the
asymptotic state. Then, within the region defined by this approximate boundary,
we solve a narrow-region elliptic boundary value problem. This solution serves
as the approximate solution to the free boundary problem that we seek.
Utilizing uniform weighted Schauder estimates for the elliptic mixed boundary
value problem in the narrow region, we obtain an error estimate for the free
boundary.

</details>


### [32] [Global solvability for doubly degenerate nutrient taxis system with a wide range of bacterial responses in physical dimension](https://arxiv.org/abs/2508.03268)
*Bao-Ngoc Tran,Juan Yang*

Main category: math.AP

TL;DR: The paper explores global weak solvability of a nutrient taxis system for bacteria, focusing on parameter ranges 0≤α<2 in 3D, categorizing chemotaxis effects as weak, moderate, or strong.


<details>
  <summary>Details</summary>
Motivation: To understand bacteria's response to environmental conditions through a nutrient taxis system, addressing challenges like nonlinear diffusion and chemotactic effects.

Method: Analyzes the system under no-flux boundary conditions and smooth initial data, dividing the problem into three cases based on the bacterial response parameter α.

Result: Summarizes recent findings on global weak solvability for specific α values and dimensions, aiming to extend this to 0≤α<2 in 3D.

Conclusion: The work aims to provide a comprehensive understanding of global weak solvability for the nutrient taxis system in 3D, categorizing chemotaxis effects by α ranges.

Abstract: Motivated by the study of bacteria's response to environmental conditions, we
consider the doubly degenerate nutrient taxis system \begin{align*}
\begin{cases} u_t=\nabla\cdot(uv\nabla u)-\chi\nabla\cdot(u^{\alpha}v\nabla
v)+\ell uv,\\ v_t=\Delta v-uv, \end{cases} \end{align*} subjected to no-flux
boundary conditions and smooth initial data, where $\alpha\in\mathbb{R}$ is the
bacterial response parameter. Global solvability of weak solutions to this
taxis system is highly challenging due to not only the doubly nonlinear
diffusion and its degeneracy but also the strong chemotactic effect, where the
latter is strong at the large species density if $\alpha$ is close to $2$ or at
the small species density if $\alpha<0$. Recent findings on the global weak
solvability for the considered system are summarised as follows \begin{itemize}
\item In [M. Winkler, \textit{Trans. Amer. Math. Soc.}, 2021] for $\alpha=2$,
$N=1$; \item In [M. Winkler, \textit{J. Differ. Equ.}, 2024] for $1\le\alpha\le
2$, $N=2$ with initial data of small size if $\alpha=2$; \item In [Z. Zhang and
Y. Li, \textit{arXiv:2405.20637}, 2024] for $\alpha=2$, $N=2$; and \item In [G.
Li, \textit{J. Differ. Equ.}, 2022] for $\frac{7}{6}<\alpha<\frac{13}{9}$,
$N=3$. \end{itemize} Our work aims to provide a picture of global weak
solvability for $0\le\alpha<2$ in the physically dimensional setting $N=3$. As
suggested by the analysis, it is divided into three separable cases, including
(i) $0\le\alpha\le 1$: Weak chemotaxis effect; (ii) $1<\alpha\le 3/2$: Moderate
chemotaxis effect; and (iii) $3/2<\alpha<2$: Strong chemotaxis effect.

</details>


### [33] [Well-Posedness of One-Dimensional Nonlinear Diffusion Equations with a Fourth-Type Dynamic Boundary Condition](https://arxiv.org/abs/2508.03288)
*Ken Furukawa*

Main category: math.AP

TL;DR: The paper studies the local well-posedness of a diffusion equation with a unique boundary condition (FK-type) for modeling filtration in aquaria, using L^p-L^q maximal regularity.


<details>
  <summary>Details</summary>
Motivation: To analyze a non-classical boundary condition (FK-type) for diffusion equations, capturing boundary interactions in filtration processes.

Method: Uses L^p-L^q maximal regularity framework to establish well-posedness of the Cauchy problem.

Result: Demonstrates local well-posedness for the diffusion equation with FK-type boundary conditions.

Conclusion: The FK-type boundary condition is viable for modeling filtration, with well-posedness proven under the given framework.

Abstract: This paper addresses the local well-posedness of the Cauchy problem for a
one-dimensional diffusion equation equipped with a dynamic boundary condition
and an additional boundary condition that renders the one-dimensional Laplace
operator self-adjoint. The equation serves as a model for describing filtration
in aquaria, originally introduced by the author and Kitahata. The boundary
condition treated in this work differs from classical types such as Dirichlet,
Neumann, and Robin conditions; we refer to it as the fourth or FK-type boundary
condition. The boundary condition is designed to capture interactions between
the two boundaries in the context of filtration. The framework for establishing
well-posedness is based on L^p-L^q maximal regularity classes.

</details>


### [34] [The non-isothermal Maxwell-Stefan asymptotics of the multi-species Boltzmann equations](https://arxiv.org/abs/2508.03311)
*Xinqiu Chen,Ning Jiang,Yi-Long Luo*

Main category: math.AP

TL;DR: The paper rigorously justifies the convergence from multi-species Boltzmann equations to the non-isothermal Maxwell-Stefan system, generalizing prior work from the isothermal case.


<details>
  <summary>Details</summary>
Motivation: To extend the understanding of hydrodynamic limits in multi-species systems, particularly focusing on the non-isothermal Maxwell-Stefan system, which differs from classical cases due to cross-interactions.

Method: Establishes global-in-time well-posedness of the Maxwell-Stefan system, constructs a local Maxwellian vector, and proves a local coercivity property for the linearized operator.

Result: The global-in-time solution to the multi-species Boltzmann equations is derived uniformly in Knudsen number, validating the Maxwell-Stefan asymptotics.

Conclusion: The work generalizes previous results to the non-isothermal case, providing a rigorous foundation for the Maxwell-Stefan system's derivation from Boltzmann equations.

Abstract: We study the convergence from the multi-species Boltzmann equations to the
non-isothermal Maxwell-Stefan system. The global-in-time well-posedness of the
Maxwell-Stefan system is first established. The solution is utilized as the
fluid quantities to construct a local Maxwellian vector. The Maxwell-Stefan
system can be derived from the multi-species Boltzmann equations under
diffusive scaling by adding a relation on the total concentration. Different
with the classical hydrodynamic limits of the Boltzmann equations, the
Maxwellian based on the Maxwell-Stefan system is not a local equilibrium for
the mixtures due to cross-interactions. A local coercivity property for the
operator linearized around the local Maxwellian is established, based on the
explicit spectral gap of the operator linearized around the global equilibrium.
The global-in-time solution to the multi-species Boltzmann equations uniform in
Knudsen number $\varepsilon$ is established in this scaling, thus the first
non-isothermal Maxwell-Stefan asymptotics is rigorously justified. This
generalizes Bondesan and Briant's work \cite{briant2021stability} from
isothermal to non-isothermal case.

</details>


### [35] [Global smooth solutions of 2-D quadratically quasilinear wave equations with null conditions in exterior domains, II](https://arxiv.org/abs/2508.03348)
*Fei Hou,Huicheng Yin*

Main category: math.AP

TL;DR: The paper resolves the open problem of global existence of small solutions for 2-D quasilinear wave equations with null conditions in exterior domains, extending previous results for Cauchy problems.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the unresolved question of global solutions for 2-D initial boundary value problems in exterior domains, building on prior work for Cauchy problems.

Method: The method involves identifying divergence structures, introducing a good unknown to handle nonlinearity, and deriving precise decay estimates for solutions and derivatives.

Result: The result confirms the global existence of small solutions for general quasilinear wave equations with null conditions in exterior domains.

Conclusion: The conclusion is that the open problem is solved, demonstrating global existence under null conditions for exterior domains.

Abstract: In the paper [S. Alinhac, The null condition for quasilinear wave equations
in two space dimensions I, Invent. Math. 145 (2001), no. 3, 597-618], S.
Alinhac established the global existence of small data smooth solutions to the
Cauchy problem of 2-D quadratically quasilinear wave equations with null
conditions. However, for the corresponding 2-D initial boundary value problem
in exterior domains, it is still open whether the global solutions exist. When
the 2-D quadratic nonlinearity admits a special $Q_0$ type null form, the
global small solution is shown in our previous article [Hou Fei, Yin Huicheng,
Yuan Meng, Global smooth solutions of 2-D quadratically quasilinear wave
equations with null conditions in exterior domains, arXiv:2411.06984]. In the
present paper, we now solve this open problem through proving the global
existence of small solutions to 2-D general quasilinear wave equations with
null conditions in exterior domains. Our proof procedure is based on finding
appropriate divergence structures of quasilinear wave equations under null
conditions, introducing a good unknown to eliminate the resulting $Q_0$ type
nonlinearity and deriving some new precise pointwise spacetime decay estimates
of solutions and their derivatives.

</details>


### [36] [On the optimization of the Robin eigenvalues in some classes of polygons](https://arxiv.org/abs/2508.03502)
*Alessandro Carbotti,Simone Cito,Diego Pallara*

Main category: math.AP

TL;DR: The paper examines shape optimization for the first eigenvalues of the Laplacian with Robin boundary conditions, focusing on minimization for β>0 and maximization for β<0, within a class of generalized polygons under perimeter or volume constraints.


<details>
  <summary>Details</summary>
Motivation: To explore how the Robin parameter β influences shape optimization problems for eigenvalues, particularly in constrained geometric settings.

Method: Analyzes the eigenvalue problem for the Laplacian with Robin boundary conditions, formulating shape optimization (minimization for β>0, maximization for β<0) in a class of generalized polygons with constraints on perimeter or volume.

Result: Establishes results for shape optimization problems under specified constraints, highlighting the role of the Robin parameter β.

Conclusion: The study provides insights into eigenvalue optimization under Robin boundary conditions, demonstrating the impact of β and geometric constraints.

Abstract: Given the eigenvalue problem for the Laplacian with Robin boundary
conditions, (with $\beta\in\R\setminus\{0\}$ the Robin parameter), we consider
a shape minimization problem for a function of the first eigenvalues if
$\beta>0$ and a shape maximization problem if $\beta<0$. Both problems are
settled in a suitable class of generalized polygons with an upper bound on the
number of sides, under either perimeter or volume constraint.

</details>


### [37] [On Properties of Statistically Stationary Solutions to the One-Dimensional Schrödinger Map Equation](https://arxiv.org/abs/2508.03551)
*Emanuela Gussetti,Mouhamadou Sy*

Main category: math.AP

TL;DR: The paper explores qualitative properties of statistically stationary solutions to the Schrödinger map equation (SME) and Binormal Curvature Flow (BCF), focusing on the laws of observables and solution dimensions.


<details>
  <summary>Details</summary>
Motivation: To extend prior work by E. G. and M. Hofmanová, investigating deeper properties of stationary solutions to SME and BCF.

Method: Analyze the laws of observables like space average and energy, and measure the dimension of the solution's law.

Result: The laws of observables are absolutely continuous with Gaussian decay for energy. The solution's law has a dimension of at least two.

Conclusion: The findings apply similarly to BCF solutions, confirming robust qualitative properties across both equations.

Abstract: We investigate further qualitative properties of statistically stationary
solutions to the Schr\"odinger map equation (SME) and the Binormal Curvature
Flow (BCF), continuing the work initiated by E. G., M. Hofmanov\'a. Concerning
the statistically stationary solutions to the SME, we show that the laws of
some relevant observables (such as the space average and the energy) are
absolutely continuous with respect to the Lebesgue measure, with a Gaussian
decay property for the energy. We further prove that the law $\mu$ of the
statistically stationary solution has dimension of at least two: this means
that any compact set of Hausdorff dimension smaller than two has $\mu$-measure
zero. These properties, with appropriate modifications of the norms, pass
directly to the statistically stationary solutions to the BCF.

</details>


### [38] [Uniqueness problem for Prandtl spirals](https://arxiv.org/abs/2508.03554)
*Tomasz Cieślak,Piotr Kokocki,Przemysław Kosewski*

Main category: math.AP

TL;DR: The paper proves the uniqueness of a divergence-free velocity field with vorticity given by the Prandtl spiral under specific conditions and extends this to concentric logarithmic spirals. It also provides an alternative derivation for the velocity formula.


<details>
  <summary>Details</summary>
Motivation: To address the problem of uniqueness in divergence-free velocity fields with specific vorticity structures, particularly the Prandtl spiral and its extensions.

Method: Restricts admissible velocities to those meeting velocity matching and decay conditions, uses conformal mapping to transform the problem, and establishes uniqueness of a holomorphic function on a strip.

Result: The velocity field is uniquely determined under the given conditions, and the method extends to unions of concentric logarithmic spirals.

Conclusion: The approach not only resolves the uniqueness problem but also offers a novel derivation for the velocity formula, with the conformal mapping technique being of independent interest.

Abstract: In this paper, we study the problem of uniqueness of a divergence-free
velocity field with vorticity given by the Prandtl spiral. We show that if the
class of admissible velocities is restricted to those satisfying the velocity
matching condition and an appropriate decay condition at the origin of the
spiral, then the velocity field is uniquely determined. We subsequently extend
the result to the case of fields with vorticity composed of unions of
concentric logarithmic spirals. As a by-product, we derive an alternative way
of deriving formula for the velocity corresponding to the Prandtl spirals. The
proof relies on an approach that is of independent interest. We construct an
explicit conformal map from the exterior of a logarithmic spiral onto a strip.
This transformation reduces the problem to establishing the uniqueness of a
holomorphic function defined on the strip, under non-standard boundary and
decay conditions.

</details>


### [39] [Long time behavior of discrete velocity kinetic equations](https://arxiv.org/abs/2508.03646)
*Gayrat Toshpulatov*

Main category: math.AP

TL;DR: Exponential decay of solutions to global equilibrium in $L^2$ space for nonlinear discrete velocity kinetic equations in 1D and 3D with periodic boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To analyze long-time behavior and convergence rates for solutions of kinetic equations, extending to a broad class of interaction rates.

Method: Construction of Lyapunov functionals by modifying Boltzmann's entropy to prove exponential decay.

Result: Explicit and constructive estimates on convergence rates, applicable to models like Goldstein-Taylor and Carleman equations.

Conclusion: The approach provides a robust framework for studying decay in kinetic equations, with practical implications for specific models.

Abstract: We study long time behavior of some nonlinear discrete velocity kinetic
equations in the one and three dimensions with periodic boundary conditions. We
prove the exponential time decay of solutions towards the global equilibrium in
the $L^2$ space. Our result holds for a wide class of interaction rates
including the Goldstein-Taylor and Carleman equations, and the estimates on the
rate of convergence are explicit and constructive. The technique is based on
the construction of suitable Lyapunov functionals by modifying Boltzmann's
entropy.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [40] [Control of cross-beam energy transfer through laser-plasma parameter adjustment](https://arxiv.org/abs/2508.03152)
*Yilin Xu,Yao Zhao,Hongwei Yin,Zhuwen Lin,Yan Yin,Liang Hao,Yaozhi Yi,Hongyu Zhou,Jinlong Jiao,Anle Lei*

Main category: physics.plasm-ph

TL;DR: The paper investigates cross-beam energy transfer (CBET) between lasers, analyzing its linear and nonlinear evolution under various conditions, with findings on saturation levels, wave breaking, and the impact of laser intensity and frequency differences.


<details>
  <summary>Details</summary>
Motivation: To understand the linear and nonlinear evolution of CBET under different laser-plasma conditions and identify factors influencing energy transfer.

Method: Combines analytical theory and 2D simulations, focusing on stimulated Brillouin scattering dispersion and harmonic ion acoustic wave effects.

Result: CBET saturation levels vary with laser intensity; high intensities reduce saturation due to harmonic IAW, while smoothed lasers mitigate saturation. Maximum transfer occurs at slightly smaller frequency differences than linear matching.

Conclusion: CBET behavior is sensitive to laser intensity, frequency difference, and plasma conditions, with laser intensity playing a critical role in controlling energy transfer.

Abstract: Cross-beam energy transfer (CBET) between two lasers is investigated through
both analytical theory and two-dimensional simulations, with particular
attention to its linear and nonlinear evolution under various laser-plasma
conditions over timescales from several hundred picoseconds to one nanosecond.
Based on the dispersion relation of stimulated Brillouin scattering driven by
two laser beams, we obtain a laser frequency difference range within which CBET
occurs. In the nonlinear regime, high harmonic of ion acoustic wave (IAW) leads
to the reduction of saturation level at high laser intensities ($I\gtrsim
10^{15}\,\mathrm{W/cm^2}$). The wave breaking of harmonic IAW causes the second
growth and final saturation of CBET. At low intensities, the linear saturation
level slowly varies over time. Compared to Gaussian beams, smoothed lasers with
speckles can mitigate CBET saturation level by reducing the effective overlap
region. The maximum energy transfer is found at a frequency difference slightly
smaller than the linear matching condition due to the reduction of IAW
frequency induced by ion trapping. We find that the nonlinear behavior is
sensitive to laser intensity, frequency difference, electron density, and ion
temperature. The total energy transfer rate increases approximately linearly
with laser intensity, underscoring its critical role in CBET control.

</details>


### [41] [Characterization of a laser filament-induced plasma in air at 10 kHz using optical emission spectroscopy](https://arxiv.org/abs/2508.03309)
*Malte C. Schroeder,Robin Löscher,Nikita Bibinov,Ihor Korolov,Peter Awakowicz,Thomas Mussenbrock,Clara J. Saraceno*

Main category: physics.plasm-ph

TL;DR: Study uses optical emission spectroscopy to analyze plasma dynamics in high-repetition-rate laser filaments, focusing on gas/electron temperatures and species decay.


<details>
  <summary>Details</summary>
Motivation: Understand plasma parameters and kinetics in high-repetition-rate laser filaments due to potential accumulation effects.

Method: Optical emission spectroscopy to measure nanosecond dynamics of gas/electron temperatures, species decay, and electron density in a 10 kHz laser filament.

Result: Derived molecular excitation mechanisms for nitrogen photoemissions and provided a holistic diagnostic technique for plasma wake characterization.

Conclusion: The technique complements optical probe schemes, offering comprehensive insights into high-repetition-rate filament plasmas.

Abstract: The increasing availability of high-power Yb-based ultrafast laser-amplifier
systems has opened the possibility of air filamentation at high repetition
rates >1 kHz. In this new regime, accumulation effects cannot be ruled out,
therefore, characterizing the plasma parameters and afterglow plasma-chemical
kinetics becomes increasingly relevant. In this work, we use optical emission
spectroscopy to measure nanosecond dynamics of gas temperature and electron
temperature, species-specific decay times, and electron density of an
atmospheric air laser filament produced by high average power femtosecond laser
at a high repetition rate of 10 kHz. The molecular excitation mechanisms behind
the nitrogen photoemissions are derived from vibrational distributions and
temporal behavior of the studied emission bands. The presented diagnostic
technique offers a complementary but more holistic measurement approach to
optical probe schemes to characterize the laser-filament-induced plasma wake
for high repetition rate filaments.

</details>


### [42] [Stationary Power-Law Solutions of Kinetic-Alfvénic Turbulence](https://arxiv.org/abs/2508.03478)
*Kexun Shen,Zhiwen Cheng,Zhiyong Qiu*

Main category: physics.plasm-ph

TL;DR: The paper proposes a wave-kinetic framework for weak kinetic-Alfvénic turbulence, derives a wave kinetic equation for spectral cascading, and analyzes stationary spectra analytically and numerically.


<details>
  <summary>Details</summary>
Motivation: To understand and describe the spectral cascading of kinetic Alfvén waves in weak turbulence using a gyrokinetic framework.

Method: Derives a wave kinetic equation for resonant three-wave interactions and uses the Zakharov transformation to obtain stationary spectra analytically. Numerical solutions verify the results.

Result: Stationary spectra are obtained for long- and short-wavelength limits, and cascade directions are identified.

Conclusion: The findings are relevant to solar wind turbulence and helical kinetic-Alfvénic turbulence.

Abstract: The wave-kinetic description of weak kinetic-Alfv\'{e}nic turbulence based on
the gyrokinetic theoretical framework is proposed. The wave kinetic equation
describing kinetic Alfv\'{e}n wave spectral cascading via resonant three-wave
interactions is derived, and the stationary spectra are analytically obtained
using the Zakharov transformation in both the long-wavelength limit and the
short-wavelength limit, for both counter-propagating and co-propagating cases.
The cascade directions of stationary solutions are identified and their
existence is further verified by numerical solution of the wave kinetic
equation. A brief discussion on the relevance of such predictions to the solar
wind turbulence and helical kinetic-Alfv\'{e}nic turbulence is presented.

</details>


### [43] [A Simple Model of Current Ramp-Up and Ramp-Down in Tokamaks](https://arxiv.org/abs/2508.03561)
*R. Fitzpatrick*

Main category: physics.plasm-ph

TL;DR: The paper models toroidal current ramp-up/down in tokamaks, finding Faraday's law limits safe ramp rates. JET, SPARC, and ITER have minimum safe ramp times of 4.2, 2.0, and 14.7 seconds, respectively. Design ramp rates for SPARC and ITER are feasible, and runaway electron issues are unlikely.


<details>
  <summary>Details</summary>
Motivation: To determine safe ramp rates for toroidal current in tokamaks (JET, SPARC, ITER) and assess feasibility of design ramp rates.

Method: Develops a simple model based on Faraday's law of electric induction to estimate minimum safe ramp-up/down times.

Result: Minimum safe ramp times: JET (4.2s), SPARC (2.0s), ITER (14.7s). Design ramp rates are feasible, and runaway electron risks are low.

Conclusion: The model confirms feasibility of design ramp rates for SPARC and ITER, with no expected runaway electron issues, aligning with JET's operational success.

Abstract: A simple model of the ramp-up and ramp-down of the toroidal current in a
tokamak plasma is developed. Faraday's law of electric induction is found to
limit how rapidly the current can be safety ramped up or down. It is estimated
that the minimum safe ramp-up/down times for the JET, SPARC, and ITER tokamaks
are 4.2, 2.0, and 14.7 seconds, respectively. The JET ramp rate is in
accordance with operational experience. The SPARC and ITER minimum safe ramp
rates are less than the ramp rates in the respective designs. Hence, there is
no indication that the design ramp rates are infeasible, as was recently
suggested in arXiv:2507.05456 (2025). The typical ratios of the inductive
electric field to the Connor-Hastie field in SPARC and ITER are found to be
less than those in JET. Thus, the fact that the JET tokamak was able to operate
successfully without encountering runaway electron problems during current
ramps suggests that the future SPARC and ITER tokamaks should also be able to
avoid such problems.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [44] [Polynomial complexity sampling from multimodal distributions using Sequential Monte Carlo](https://arxiv.org/abs/2508.02763)
*Ruiyu Han,Gautam Iyer,Dejan Slepčev*

Main category: math.ST

TL;DR: A sequential Monte Carlo algorithm is analyzed for sampling from Gibbs measures with non-convex energy at low temperatures, using geometric annealing and Langevin diffusion for local mixing. The method achieves convergence with time complexity scaling as the fourth power of inverse temperature and square of inverse error.


<details>
  <summary>Details</summary>
Motivation: To efficiently sample from Gibbs measures with non-convex energy functions at low temperatures, where traditional methods face challenges due to slow global mixing.

Method: Uses a sequential Monte Carlo algorithm with geometric annealing and Langevin diffusion for local mixing within energy valleys, avoiding the need for global mixing.

Result: Convergence of Monte Carlo estimators is proven, with time complexity scaling as the fourth power of the inverse temperature and the square of the inverse allowed error.

Conclusion: The proposed algorithm is efficient for low-temperature sampling, with explicit estimates provided in a model scenario.

Abstract: We study a sequential Monte Carlo algorithm to sample from the Gibbs measure
with a non-convex energy function at a low temperature. We use the practical
and popular geometric annealing schedule, and use a Langevin diffusion at each
temperature level. The Langevin diffusion only needs to run for a time that is
long enough to ensure local mixing within energy valleys, which is much shorter
than the time required for global mixing. Our main result shows convergence of
Monte Carlo estimators with time complexity that, approximately, scales like
the forth power of the inverse temperature, and the square of the inverse
allowed error. We also study this algorithm in an illustrative model scenario
where more explicit estimates can be given.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [45] [A nonstandard finite difference scheme for an SEIQR epidemiological PDE mode](https://arxiv.org/abs/2508.02928)
*Achraf Zinihi,Matthias Ehrhardt,Moulay Rchid Sidi Ammi*

Main category: q-bio.QM

TL;DR: The paper presents a nonstandard finite difference (NSFD) method for a reaction-diffusion SEIQR epidemiological model, ensuring qualitative features like positivity and stability, unlike standard methods.


<details>
  <summary>Details</summary>
Motivation: To accurately model spatiotemporal disease dynamics while preserving essential biological properties often lost in standard discretizations.

Method: Develops an NSFD scheme for a semilinear PDE system, analyzing well-posedness, convergence, and truncation error.

Result: The NSFD scheme maintains model properties and performs well in numerical simulations.

Conclusion: The proposed NSFD approach effectively preserves biological consistency in epidemiological modeling.

Abstract: This paper introduces a nonstandard finite difference (NSFD) approach to a
reaction-diffusion SEIQR epidemiological model, which captures the
spatiotemporal dynamics of infectious disease transmission. Formulated as a
system of semilinear parabolic partial differential equations (PDEs), the model
extends classical compartmental models by incorporating spatial diffusion to
account for population movement and spatial heterogeneity. The proposed NSFD
discretization is designed to preserve the continuous model's essential
qualitative features, such as positivity, boundedness, and stability, which are
often compromised by standard finite difference methods. We rigorously analyze
the model's well-posedness, construct a structure-preserving NSFD scheme for
the PDE system, and study its convergence and local truncation error. Numerical
simulations validate the theoretical findings and demonstrate the scheme's
effectiveness in preserving biologically consistent dynamics.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [46] [Fermionic-Adapted Shadow Tomography for dynamical correlation functions](https://arxiv.org/abs/2508.03192)
*Taehee Ko,Mancheon Han,Sangkook Choi*

Main category: quant-ph

TL;DR: FAST protocols improve quantum efficiency for calculating dynamical correlation functions by reformulating them for shadow tomography, reducing measurement circuits significantly.


<details>
  <summary>Details</summary>
Motivation: Classical methods are intractable for calculating dynamical correlation functions in quantum many-body systems, necessitating efficient quantum algorithms.

Method: Introduces Fermionic-Adapted Shadow Tomography (FAST) protocols, reformulating functions for shadow tomography compatibility, using two-copy measurements.

Result: Enhances sample efficiency and reduces measurement circuits by one or two orders of magnitude relative to qubit count.

Conclusion: FAST protocols offer a scalable and efficient quantum solution for dynamical correlation functions.

Abstract: Dynamical correlation functions are essential for characterizing the response
of the quantum many-body systems to the external perturbation. As their
calculation is classically intractible in general, quantum algorithms are
promising in this aspect, but most rely on brute force measurement strategies
that evaluate one body observable pair per circuit. In this work, we introduce
Fermionic-Adapted Shadow Tomography (FAST) protocols, a new framework for the
efficient calculation of multiple dynamical correlation functions. The key idea
is to reformulate these functions into forms that are compatible with shadow
tomography techniques. The circuits in our protocols require at most two-copy
measurements with uncontrolled Hamiltonian simulation. We show that the
proposed protocols enhance sample efficiency and reduce the number of
measurement circuits by an order of one or two with respect to the number of
qubits across a range of scenarios.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [47] [Overcoming the Loss Conditioning Bottleneck in Optimization-Based PDE Solvers: A Novel Well-Conditioned Loss Function](https://arxiv.org/abs/2508.02692)
*Wenbo Cao,Weiwei Zhang*

Main category: cs.CE

TL;DR: The paper introduces a Stabilized Gradient Residual (SGR) loss to address the inefficiency of optimization-based PDE solvers caused by the MSE loss, demonstrating faster convergence in both ODIL and PINNs frameworks.


<details>
  <summary>Details</summary>
Motivation: Optimization-based PDE solvers like ODIL and PINNs are slow due to the MSE loss's poor conditioning, which squares the condition number and hampers optimization.

Method: Proposes the SGR loss, which modulates the condition number between the original system and its normal equations, and benchmarks it in ODIL and PINNs frameworks.

Result: SGR achieves orders-of-magnitude faster convergence than MSE in ODIL and consistently outperforms MSE in PINNs, bridging the gap with classical solvers.

Conclusion: The SGR loss improves efficiency in optimization-based PDE solvers by addressing loss conditioning, offering insights for future solver designs.

Abstract: Optimization-based PDE solvers that minimize scalar loss functions have
gained increasing attention in recent years. These methods either define the
loss directly over discrete variables, as in Optimizing a Discrete Loss (ODIL),
or indirectly through a neural network surrogate, as in Physics-Informed Neural
Networks (PINNs). However, despite their promise, such methods often converge
much more slowly than classical iterative solvers and are commonly regarded as
inefficient. This work provides a theoretical insight, attributing the
inefficiency to the use of the mean squared error (MSE) loss, which implicitly
forms the normal equations, squares the condition number, and severely impairs
optimization. To address this, we propose a novel Stabilized Gradient Residual
(SGR) loss. By tuning a weight parameter, it flexibly modulates the condition
number between the original system and its normal equations, while reducing to
the MSE loss in the limiting case. We systematically benchmark the convergence
behavior and optimization stability of the SGR loss within both the ODIL
framework and PINNs-employing either numerical or automatic differentiation-and
compare its performance against classical iterative solvers. Numerical
experiments on a range of benchmark problems demonstrate that, within the ODIL
framework, the proposed SGR loss achieves orders-of-magnitude faster
convergence than the MSE loss. Further validation within the PINNs framework
shows that, despite the high nonlinearity of neural networks, SGR consistently
outperforms the MSE loss. These theoretical and empirical findings help bridge
the performance gap between classical iterative solvers and optimization-based
solvers, highlighting the central role of loss conditioning, and provide key
insights for the design of more efficient PDE solvers.

</details>


### [48] [Numerical Errors in Quantitative System Analysis With Decision Diagrams](https://arxiv.org/abs/2508.02673)
*Sebastiaan Brand,Arend-Jan Quist,Richard M. K. van Dijk,Alfons Laarman*

Main category: cs.CE

TL;DR: The paper examines the numerical stability of MTBDD matrix-vector multiplication, proving it can be stable under certain conditions, though practical implementations often fail to meet these. A quantum circuit case study highlights varying error impacts.


<details>
  <summary>Details</summary>
Motivation: Floating-point rounding errors in DDs affect correctness and compression, especially in probabilistic and quantum systems, prompting a study of numerical stability in MTBDD operations.

Method: Investigates numerical stability of MTBDD matrix-vector multiplication, proving stability under specific conditions, and includes a quantum circuit simulation case study.

Result: MTBDD matrix-vector multiplication can be numerically stable under certain conditions, but practical implementations often lack these. Quantum circuit simulations show significant variability in error impact.

Conclusion: While MTBDD matrix-vector multiplication can achieve numerical stability, practical challenges remain. Case studies reveal context-dependent error variability, emphasizing the need for careful implementation.

Abstract: Decision diagrams (DDs) are a powerful data structure that is used to tackle
the state-space explosion problem, not only for discrete systems, but for
probabilistic and quantum systems as well. While many of the DDs used in the
probabilistic and quantum domains make use of floating-point numbers, this is
not without challenges. Floating-point computations are subject to small
rounding errors, which can affect both the correctness of the result and the
effectiveness of the DD's compression. In this paper, we investigate the
numerical stability, i.e. the robustness of an algorithm to small numerical
errors, of matrix-vector multiplication with multi-terminal binary decision
diagrams (MTBDDs). Matrix-vector multiplication is of particular interest
because it is the function that computes successor states for both
probabilistic and quantum systems. We prove that the MTBDD matrix-vector
multiplication algorithm can be made numerically stable under certain
conditions, although in many practical implementations of MTBDDs these
conditions are not met. Additionally, we provide a case study of the numerical
errors in the simulation of quantum circuits, which shows that the extent of
numerical errors in practice varies greatly between instances.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [49] [Fast Computation of Path Integrals of Killed Processes Using Confined Stochastic Bridges](https://arxiv.org/abs/2508.03671)
*Henrique B. N. Monteiro,Daniel M. Tartakovsky*

Main category: math.PR

TL;DR: A novel stochastic method for evaluating path integrals of killed processes without simulating full paths, reducing bias and computational cost.


<details>
  <summary>Details</summary>
Motivation: Addressing the bias and high computational expense in simulating killed stochastic processes for path integrals in physics, chemistry, and finance.

Method: Connects stochastic bridges and killed processes to sample exit times and locations, avoiding full path simulation. Explicitly derives densities for Brownian bridges in n-balls (n=1,2,3).

Result: Demonstrates negligible bias and lower computational cost compared to the standard Euler-Maruyama method.

Conclusion: The method offers an efficient and accurate alternative for evaluating path integrals of killed processes.

Abstract: Expectations of path integrals of killed stochastic processes play a central
role in several applications across physics, chemistry, and finance.
Simulation-based evaluation of these functionals is often biased and
numerically expensive due to the need to explicitly approximate stochastic
paths and the challenge of correctly modeling them in the neighborhood of the
killing boundary. We consider It\^{o} processes killed at the boundary of some
set in the $n$-dimensional space and introduce a novel stochastic method with
negligible bias and lower computational cost to evaluate path integrals without
simulated paths. Our approach draws a connection between stochastic bridges and
killed processes to sample only exit times and locations instead of the full
path. We apply it to a Wiener process killed in the $n$-ball and explicitly
derive the density of the Brownian bridge confined to the $n$-ball for $n = 1,
2, 3$. Finally, we present two numerical examples that demonstrate the
efficiency and negligible bias of the novel procedure compared to an evaluation
using the standard Euler-Maruyama method.

</details>


### [50] [Quenching time and probability estimates for a stochastic reaction-diffusion system with coupled inner singular absorption terms driven by mixed noises](https://arxiv.org/abs/2508.03354)
*Nikos I. Kavallaris,Christos V. Nikolopoulos,Subramani Sankar*

Main category: math.PR

TL;DR: The paper studies a stochastic parabolic system with Robin boundary conditions, analyzing quenching time bounds, global solution existence, and quenching probability using Malliavin calculus, supported by numerical validation.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of mixed noise (Brownian and fractional Brownian motion) on the quenching behavior of a stochastic parabolic system.

Method: Theoretical analysis with Malliavin calculus to derive quenching time bounds and probability, complemented by a tailored numerical scheme.

Result: Explicit bounds for quenching time, global existence of weak solutions, and quantifiable quenching probability bounds. Numerical results align with theory.

Conclusion: The study provides theoretical and numerical insights into how noise influences quenching in stochastic parabolic systems.

Abstract: This paper investigates a stochastic parabolic system under Robin boundary
conditions, for which the deterministic counterpart exhibits finite quenching.
The stochastic system incorporates mixed noise, combining standard
one-dimensional Brownian motion and fractional Brownian motion. Under
appropriate assumptions, we derive explicit lower and upper bounds for the
quenching time of the solution and establish the global existence of a weak
solution. Leveraging Malliavin calculus, we further obtain a quantifiable lower
and upper bound on the quenching probability. To complement the theoretical
analysis, we design a numerical scheme tailored to the system and present
results that validate the analytical predictions, offering insights into the
interplay between noise and quenching behaviour.

</details>


### [51] [Itô-Stratonovich Conversion in Infinite Dimensions for Unbounded, Time-Dependent, Nonlinear Operators](https://arxiv.org/abs/2508.03424)
*Daniel Goodair*

Main category: math.PR

TL;DR: The paper establishes a variational solution for a Stratonovich SPDE by linking it to an Itô equation with a corrector term, using martingale techniques.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of solving Stratonovich stochastic partial differential equations (SPDEs) with noise, especially when the noise operator is time-dependent, nonlinear, or unbounded.

Method: The authors transform the Stratonovich SPDE into an Itô equation with an Itô-Stratonovich corrector term, leveraging martingale techniques and Fréchet derivatives.

Result: They prove the equivalence of solutions between the Stratonovich SPDE and the Itô equation, even for complex noise operators.

Conclusion: The findings extend to fluid equations with nonlinear and time-dependent transport noise, demonstrating broad applicability.

Abstract: We prove that a solution, in a variational framework, to the Stratonovich
stochastic partial differential equation with noise $G\left(t, \Psi_t\right)
\circ dW_t$ is given by a solution to the It\^{o} equation with
It\^{o}-Stratonovich corrector $\frac{1}{2}\sum_{i=1}^\infty D_uG_i\left(t,
\Psi_t\right)\left[G_i(t,\Psi_t)\right]dt$. Here $G_i$ denotes the action of
$G$ on the $i^{th}$ component of the cylindrical noise, and $D_uG_i$ its
Fr\'{e}chet partial derivative in the Hilbert space for which the It\^{o} form
is satisfied. The noise operator $G$ may be time-dependent, nonlinear, and
unbounded in the sense of differential operators; in the latter case, one must
pass to a larger space in order to solve the Stratonovich equation. Our proof
relies on martingale techniques, and the results apply to fluid equations with
time-dependent and nonlinear transport noise.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [52] [Machine learning potential for predicting thermal conductivity of θ-phase and amorphous Tantalum Nitride](https://arxiv.org/abs/2508.03297)
*Zhicheng Zong,Yangjun Qin,Jiahong Zhan,Haisheng Fang,Nuo Yang*

Main category: cond-mat.mtrl-sci

TL;DR: The study develops deep potential models for TaN phases, compares thermal conductivities via simulations, and explains discrepancies between theory and experiments.


<details>
  <summary>Details</summary>
Motivation: Address discrepancies in thermal conductivity measurements and predictions for TaN, particularly the θ-phase, to enhance its electronic and thermal applications.

Method: Developed deep potential models for θ-phase and amorphous TaN, used molecular dynamics simulations to study thermal conductivities of bulk and nanofilms.

Result: Simulation results compared with existing data, revealing mechanisms behind discrepancies in thermal conductivity.

Conclusion: Provides insights into TaN's thermal transport, aiding its use in electronic and thermal management devices.

Abstract: Tantalum nitride (TaN) has attracted considerable attention due to its unique
electronic and thermal properties, high thermal conductivity, and applications
in electronic components. However, for the {\theta}-phase of TaN, significant
discrepancies exist between previous experimental measurements and theoretical
predictions. In this study, deep potential models for TaN in both the
{\theta}-phase and amorphous phase were developed and employed in molecular
dynamics simulations to investigate the thermal conductivities of bulk and
nanofilms. The simulation results were compared with reported experimental and
theoretical results, and the mechanism for differences were discussed. This
study provides insights into the thermal transport mechanisms of TaN, offering
guidance for its application in advanced electronic and thermal management
devices.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [53] [Neural Networks with Orthogonal Jacobian](https://arxiv.org/abs/2508.02882)
*Alex Massucco,Davide Murari,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: A unified framework for deep neural networks ensures Jacobian orthogonality, enabling stable training and competitive performance without traditional skip connections.


<details>
  <summary>Details</summary>
Motivation: Training very deep neural networks is challenging due to vanishing or exploding gradients. Existing solutions like orthogonal initialization and residual architectures help but are limited.

Method: Introduces a mathematical framework for nonlinear feedforward and residual networks with exactly orthogonal Jacobian matrices, ensuring dynamical isometry.

Result: Perfect Jacobian orthogonality stabilizes training and matches residual networks' performance. Extended models with partial isometries also maintain trainability.

Conclusion: The framework enables efficient training of deep networks without skip connections, offering new designs and maintaining stability.

Abstract: Very deep neural networks achieve state-of-the-art performance by extracting
rich, hierarchical features. Yet, training them via backpropagation is often
hindered by vanishing or exploding gradients. Existing remedies, such as
orthogonal or variance-preserving initialisation and residual architectures,
allow for a more stable gradient propagation and the training of deeper models.
In this work, we introduce a unified mathematical framework that describes a
broad class of nonlinear feedforward and residual networks, whose
input-to-output Jacobian matrices are exactly orthogonal almost everywhere.
Such a constraint forces the resulting networks to achieve perfect dynamical
isometry and train efficiently despite being very deep. Our formulation not
only recovers standard architectures as particular cases but also yields new
designs that match the trainability of residual networks without relying on
conventional skip connections. We provide experimental evidence that perfect
Jacobian orthogonality at initialisation is sufficient to stabilise training
and achieve competitive performance. We compare this strategy to networks
regularised to maintain the Jacobian orthogonality and obtain comparable
results. We further extend our analysis to a class of networks
well-approximated by those with orthogonal Jacobians and introduce networks
with Jacobians representing partial isometries. These generalized models are
then showed to maintain the favourable trainability properties.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [54] [Energy Cascade and Damping in Fast-Mode Compressible Turbulence](https://arxiv.org/abs/2508.03443)
*Chuanpeng Hou,Huirong Yan,Siqi Zhao,Parth Pavaskar*

Main category: astro-ph.SR

TL;DR: Hybrid and kinetic simulations show fast-mode compressible turbulence follows linear transit-time damping theory, sustaining energy cascading despite phase steepening, challenging classical wave theories.


<details>
  <summary>Details</summary>
Motivation: To resolve the validity of classical wave theories in nonlinear regimes and address the presumption that wave steepening disrupts compressible turbulence.

Method: Hybrid and fully kinetic particle-in-cell simulations of fast-mode compressible turbulence.

Result: Turbulence damping aligns with linear transit-time damping theory, and energy cascading persists despite phase steepening.

Conclusion: The findings challenge classical wave theories, showing turbulence cascade remains robust in nonlinear regimes, providing a clearer understanding of MHD turbulence.

Abstract: This letter presents hybrid and fully kinetic particle-in-cell simulations of
fast-mode compressible turbulence. Turbulence damping at magnetohydrodynamic
(MHD) scales closely follows linear transit-time damping theory. Despite strong
phase steepening, turbulence sustains robust cross-scale energy cascading.
These findings resolve the long-standing question about the validity of
classical wave theories in strongly nonlinear regimes and overturn the common
presumption that wave steepening disrupts compressible turbulence cascade,
thereby providing a more complete picture of MHD turbulence.

</details>
