<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 11]
- [math.AP](#math.AP) [Total: 16]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [cs.DS](#cs.DS) [Total: 1]
- [hep-ph](#hep-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [gr-qc](#gr-qc) [Total: 1]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Unconditional energy dissipation of Strang splitting for the matrix-valued Allen-Cahn equation](https://arxiv.org/abs/2508.03992)
*Chaoyu Quan,Tao Tang,Dong Wang*

Main category: math.NA

TL;DR: The paper refines the stability analysis of the Strang splitting method for the matrix-valued Allen-Cahn equation, proving unconditional energy dissipation and global stability.


<details>
  <summary>Details</summary>
Motivation: To eliminate restrictive time-step constraints and rigorously prove unconditional energy dissipation for the Strang splitting method.

Method: Refined stability analysis framework, focusing on precise estimation of the double-well potential term in the modified energy functional.

Result: Unconditional energy dissipation, global-in-time H1-stability, determinant boundedness, and second-order temporal convergence.

Conclusion: Numerical experiments validate the theoretical findings, confirming energy stability and determinant bound preservation.

Abstract: The energy dissipation property of the Strang splitting method was first
demonstrated for the matrix-valued Allen-Cahn (MAC) equation under restrictive
time-step constraints [J. Comput. Phys. 454, 110985, 2022]. In this work, we
eliminate this limitation through a refined stability analysis framework,
rigorously proving that the Strang splitting method preserves the energy
dissipation law unconditionally for arbitrary time steps. The refined proof
hinges on a precise estimation of the double-well potential term in the
modified energy functional. Leveraging this unconditional energy dissipation
property, we rigorously establish that the Strang splitting method achieves
global-in-time $H^1$-stability, preserves determinant boundedness, and
maintains second-order temporal convergence for the matrix-valued Allen-Cahn
equation. To validate these theoretical findings, we conduct numerical
experiments confirming the method's energy stability and determinant bound
preservation for the MAC equation.

</details>


### [2] [The Ubiquitous Sparse Matrix-Matrix Products](https://arxiv.org/abs/2508.04077)
*Aydın Buluç*

Main category: math.NA

TL;DR: The paper explores sparse matrix-matrix multiplication, a key operation in data science, and its applications across diverse fields like machine learning, biology, and graph algorithms.


<details>
  <summary>Details</summary>
Motivation: To address the computational needs of various data science applications by generalizing sparse matrix multiplication to arbitrary algebraic semirings or heterogeneous algebras.

Method: Provides a unifying framework for sparse matrix-matrix operations, accommodating user-defined functions and varying input domains.

Result: Demonstrates the versatility of sparse matrix multiplication in applications such as graph algorithms, neural networks, and biological data analysis.

Conclusion: The paper highlights the broad applicability and flexibility of sparse matrix operations in solving complex problems across multiple domains.

Abstract: Multiplication of a sparse matrix with another (dense or sparse) matrix is a
fundamental operation that captures the computational patterns of many data
science applications, including but not limited to graph algorithms, sparsely
connected neural networks, graph neural networks, clustering, and many-to-many
comparisons of biological sequencing data.
  In many application scenarios, the matrix multiplication takes places on an
arbitrary algebraic semiring where the scalar operations are overloaded with
user-defined functions with certain properties or a more general heterogenous
algebra where even the domains of the input matrices can be different. Here, we
provide a unifying treatment of the sparse matrix-matrix operation and its rich
application space including machine learning, computational biology and
chemistry, graph algorithms, and scientific computing.

</details>


### [3] [POD-based reduced order modeling of global-in-time iterative decoupled algorithms for Biot's consolidation model](https://arxiv.org/abs/2508.04082)
*Huipeng Gu,Francesco Ballarin,Mingchao Cai,Jingzhi Li*

Main category: math.NA

TL;DR: The paper introduces efficient numerical algorithms for a three-field Biot's consolidation model, featuring monolithic and global-in-time iterative decoupled methods with backward differentiation formulas. It also proposes a reduced order modeling approach to accelerate computations.


<details>
  <summary>Details</summary>
Motivation: To address the computational challenges in solving the three-field Biot's consolidation model efficiently.

Method: Innovative monolithic and global-in-time iterative decoupled algorithms with backward differentiation formulas, combined with a reduced order modeling approach using proper orthogonal decomposition.

Result: The proposed method is theoretically validated and demonstrated effective through numerical experiments.

Conclusion: The novel approach successfully improves computational efficiency for the three-field Biot's consolidation model.

Abstract: This paper focuses on the efficient numerical algorithms of a three-field
Biot's consolidation model. The approach begins with the introduction of
innovative monolithic and global-in-time iterative decoupled algorithms, which
incorporate the backward differentiation formulas for time discretization. In
each iteration, these algorithms involve solving a diffusion subproblem over
the entire temporal domain, followed by solving a generalized Stokes subproblem
over the same time interval. To accelerate the global-in-time iterative
process, we present a reduced order modeling approach based on proper
orthogonal decomposition, aimed at reducing the primary computational cost from
the generalized Stokes subproblem. The effectiveness of this novel method is
validated both theoretically and through numerical experiments.

</details>


### [4] [Convergence of hyperbolic approximations to higher-order PDEs for smooth solutions](https://arxiv.org/abs/2508.04112)
*Jan Giesselmann,Hendrik Ranocha*

Main category: math.NA

TL;DR: Proves convergence of hyperbolic approximations for higher-order PDEs, requiring only weak solutions, and supports findings with numerical results.


<details>
  <summary>Details</summary>
Motivation: To provide a rigorous foundation for hyperbolic approximations used in literature without thorough convergence analysis.

Method: Analyzes convergence for classes of PDEs (e.g., Benjamin-Bona-Mahony, Korteweg-de Vries) under smooth solution assumptions, using weak entropy solutions.

Result: Demonstrates convergence of hyperbolic approximations for specified PDEs, validated by numerical results.

Conclusion: Establishes a solid theoretical basis for hyperbolic approximations in higher-order PDEs, backed by numerical evidence.

Abstract: We prove the convergence of hyperbolic approximations for several classes of
higher-order PDEs, including the Benjamin-Bona-Mahony, Korteweg-de Vries,
Gardner, Kawahara, and Kuramoto-Sivashinsky equations, provided a smooth
solution of the limiting problem exists. We only require weak (entropy)
solutions of the hyperbolic approximations. Thereby, we provide a solid
foundation for these approximations, which have been used in the literature
without rigorous convergence analysis. We also present numerical results that
support our theoretical findings.

</details>


### [5] [Optimal Design of Broadband Absorbers with Multiple Plasmonic Nanoparticles via Reduced Basis Method](https://arxiv.org/abs/2508.04198)
*Yu Gao,Hai Zhang,Kai Zhang*

Main category: math.NA

TL;DR: A computational framework for designing broadband absorbing plasmonic nanoparticle arrays, addressing challenges like multi-particle interactions, broadband responses, and non-convex optimization via parameterized integral equations, shape-adaptive RBM, and physics-informed initialization.


<details>
  <summary>Details</summary>
Motivation: The design of broadband absorbing materials with plasmonic nanoparticle arrays faces challenges like complex interactions, broadband frequency requirements, and non-convex optimization landscapes.

Method: Uses parameterized integral equations, shape-adaptive reduced basis method (RBM), and physics-informed initialization to streamline design and optimization.

Result: Numerical experiments confirm accurate and efficient designs across various geometric configurations, with flexibility for other material systems.

Conclusion: The framework effectively addresses key challenges in plasmonic material design, offering computational efficiency and extensibility.

Abstract: In this paper, we propose a computational framework for the optimal design of
broadband absorbing materials composed of plasmonic nanoparticle arrays. This
design problem poses several key challenges: (1) the complex multi-particle
interactions and high-curvature geometries; (2) the requirement to achieve
broadband frequency responses, including resonant regimes; (3) the complexity
of shape derivative calculations; and (4) the non-convexity of the optimization
landscape. To systematically address these challenges, we employ three
sequential strategies. First, we introduce a parameterized integral equation
formulation that circumvents traditional shape derivative computations. Second,
we develop a shape-adaptive reduced basis method (RBM) that utilizes the
eigenfunctions of the Neumann-Poincar\'{e} operator for forward problems and
their adjoint counterparts for adjoint problems, thereby addressing
singularities and accelerating computations. Third, we propose a
physics-informed initialization strategy that estimates nanoparticle
configurations under weak coupling assumptions, thereby improving the
performance of gradient-based optimization algorithms. The method's
computational advantages are demonstrated through numerical experiments, which
show accurate and efficient designs across various geometric configurations.
Furthermore, the framework is flexible and extensible to other material systems
and boundary conditions.

</details>


### [6] [Monolithic Multi-level Overlapping Schwarz Solvers for Fluid Problems](https://arxiv.org/abs/2508.04356)
*Stephan Köhler,Oliver Rheinbah*

Main category: math.NA

TL;DR: The paper discusses additive overlapping Schwarz methods for solving partial differential equations, focusing on scalability through coarse levels and introducing monolithic preconditioners for saddle point problems. Parallel results are shown for fluid problems using the FROSch and FEATFLOW libraries.


<details>
  <summary>Details</summary>
Motivation: To achieve numerical and parallel scalability in solving partial differential equations, particularly for incompressible fluid problems, by leveraging coarse spaces and monolithic preconditioners.

Method: The study uses additive overlapping Schwarz methods with GDSW-inspired coarse spaces, implemented in the FROSch library, combined with the FEATFLOW library for efficient coupling. Parallel results are demonstrated on up to 32768 MPI ranks.

Result: Successful parallel results for incompressible fluid problems, including Poiseuille flow and complex geometries, using two- and three-level monolithic overlapping Schwarz preconditioners.

Conclusion: The combination of FROSch and FEATFLOW libraries provides scalable solutions for complex fluid dynamics problems, supported by the SCALEXA project.

Abstract: Additive overlapping Schwarz Methods are iterative methods of the domain
decomposition type for the solution of partial differential equations.
Numerical and parallel scalability of these methods can be achieved by adding
coarse levels. A successful coarse space, inspired by iterative substructuring,
is the generalized Dryja-Smith-Widlund (GDSW) space. In
https://doi.org/10.1137/18M1184047, based on the GDSW approach, two-level
monolithic overlapping Schwarz preconditioners for saddle point problems were
introduced. We present parallel results up to 32768 MPI ranks for the solution
of incompressible fluid problems for a Poiseuille flow example on the unit cube
and a complex extrusion die geometry using a two- and a three-level monolithic
overlapping Schwarz preconditioner. These results are achieved through the
combination of the additive overlapping Schwarz solvers implemented in the Fast
and Robust Overlapping Schwarz (FROSch) library
https://doi.org/10.1007/978-3-030-56750-7_19, which is part of the Trilinos
package ShyLU https://doi.org/10.1109/IPDPS.2012.64, and the FEATFLOW library
http://www.featflow.de using a scalable interface for the efficient coupling of
the two libraries. This work is part of the project StroemungsRaum - Novel
Exascale-Architectures with Heterogeneous Hardware Components for Computational
Fluid Dynamics Simulations, funded by the German Bundesministerium fur
Forschung, Technologie und Raumfahrt BMFTR (formerly BMBF) as part of the
program on New Methods and Technologies for Exascale Computing (SCALEXA).

</details>


### [7] [Derivation and Numerical Simulation of a Thermodynamically Consistent Magneto Two-Phase Flow Model for Magnetic Drug Targeting](https://arxiv.org/abs/2508.04360)
*Eberhard Bänsch,Jonas Knoch,Nicolas Neuss,Maria Neuss-Radu*

Main category: math.NA

TL;DR: A thermodynamically consistent model for SPIONs, carrier fluid, and magnetic field interactions in MDT is developed, extending previous models by including fluid and field responses to SPION dynamics. Numerical simulations validate the model.


<details>
  <summary>Details</summary>
Motivation: To improve Magnetic Drug Targeting (MDT) by modeling the complex interactions between SPIONs, carrier fluid, and magnetic field, addressing gaps in prior models.

Method: Derives a model combining convection-diffusion, modified Navier-Stokes, and quasi-stationary Maxwell systems. Uses a semi-implicit finite element scheme for numerical simulation.

Result: Simulations show the fully coupled model outperforms reduced versions, and sensitivity to parameters like magnet positioning is analyzed.

Conclusion: The model provides a comprehensive tool for MDT prediction and optimization, validated by numerical results.

Abstract: In this paper, we derive a novel and comprehensive thermodynamically
consistent model for the complex interactions between superparamagnetic iron
oxide nanoparticles (SPIONs), a carrier fluid, and a magnetic field, as they
occur in Magnetic Drug Targeting (MDT), the targeted delivery of magnetically
functionalized drug carriers by external magnetic fields. It consists of a
convection-diffusion equation for SPIONs, a modified Navier-Stokes system for
the averaged velocity of the carrier fluid-nanoparticle mixture and a
quasi-stationary Maxwell system for the magnetic variables. The derived model
extends previous models for MDT by taking into account the response of the
carrier fluid and of the magnetic field to the dynamics of the SPIONs, and thus
provides a comprehensive tool for the prediction and optimization of MDT
processes. After introducing a semi-implicit finite element scheme for the
numerical simulation of the model, simulation results for the fully coupled
model are performed and compared with results from a reduced version of the
model, where the response of the carrier flow and of the magnetic field to the
SPION dynamics is neglected. Furthermore, the sensitivity of MDT with respect
to experimental parameters, such as magnet positioning, is investigated.

</details>


### [8] [Explicit Construction of Approximate Kolmogorov-Arnold Superpositions with C2-Smoothness](https://arxiv.org/abs/2508.04392)
*Lunji Song,Juan Diego Toscano,Li-Lian Wang*

Main category: math.NA

TL;DR: The paper constructs an approximate version of Kolmogorov-Arnold superpositions using C2 inner and outer functions to approximate alpha-Holder continuous functions, avoiding pathological behaviors while retaining exact representation essence.


<details>
  <summary>Details</summary>
Motivation: To overcome the wild and pathological behaviors in traditional Kolmogorov-Arnold superpositions while maintaining their exact representation capability.

Method: Uses C2 inner functions (via translations/dilations of a piecewise C2 function) and outer functions (via piecewise C2 interpolation with new shape functions).

Result: The constructed variant approximates arbitrary alpha-Holder continuous functions well.

Conclusion: The novel variant retains the Kolmogorov strategy's essence while addressing its drawbacks, aligning with Sprecher's objectives.

Abstract: We explicitly construct an approximate version of the Kolmogorov-Arnold
superpositions, which is composed of C2 inner and outer functions, and can
approximate an arbitrary alpha-Holder continuous function well. The inner
functions are generated by applying suitable translations and dilations to a
piecewise C2, strictly increasing function, while the outer functions are
constructed row-wise through piecewise C2 interpolation using newly designed
shape functions. This novel variant of Kolmogorov-Arnold superpositions
overcomes the wild and pathological behaviors of the inherent single variable
functions, but retains the essence of Kolmogorov strategy of exact
representation, an objective that Sprecher, Neural Networks 144, 2021, has
actively pursued.

</details>


### [9] [A high-order deterministic dynamical low-rank method for proton transport in heterogeneous media](https://arxiv.org/abs/2508.04484)
*Pia Stammer,Niklas Wahl,Jonas Kusch,Danny Lathouwers*

Main category: math.NA

TL;DR: The paper proposes a dynamical low-rank approximation (DLRA) method to efficiently solve high-dimensional proton transport equations in therapy, reducing computational cost while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: Proton therapy requires solving complex transport equations for multiple beams, which is computationally expensive due to forward-peaked scattering. A faster, accurate method is needed.

Method: Uses DLRA to evolve solutions on low-rank matrices, combining a collided-uncollided split, ray-tracing for uncollided parts, and high-order discretizations for collided parts.

Result: The method matches full-rank results at lower computational cost, enables higher resolutions, and maintains accuracy compared to TOPAS MC in various materials.

Conclusion: DLRA effectively reduces computational demands for proton transport calculations, making high-resolution simulations feasible for multiple beams.

Abstract: Dose calculations in proton therapy require the fast and accurate solution of
a high-dimensional transport equation for a large number of (pencil) beams with
different energies and directions. Deterministically solving this transport
problem at a sufficient resolution can however be prohibitively expensive,
especially due to highly forward peaked scattering of the protons. We propose
using a model order reduction approach, the dynamical low-rank approximation
(DLRA), which evolves the solution on the manifold of low-rank matrices in
(pseudo-)time. For this, we compare a collided-uncollided split of the linear
Boltzmann equation and its Fokker-Planck approximation. We treat the uncollided
part using a ray-tracer and combine high-order phase space discretizations and
a mixture model for materials with DLRA for the collided equation. Our method
reproduces the results of a full-rank reference code at significantly lower
rank, and thus computational cost and memory, and further makes computations
feasible at much higher resolutions. At higher resolutions, we also achieve
good accuracy with respect to TOPAS MC in homogeneous as well as heterogeneous
materials. Finally, we demonstrate that several beam sources with different
angles can be computed with little cost increase compared to individual beams.

</details>


### [10] [Discretizing linearized Einstein-Bianchi system by symmetric and traceless tensors](https://arxiv.org/abs/2508.04560)
*Yuyang Guo,Jun Hu,Ting Lin*

Main category: math.NA

TL;DR: The paper introduces a new formulation for the Einstein-Bianchi system, treating it as the Hodge wave equation, and constructs a conforming finite element method to preserve constraints.


<details>
  <summary>Details</summary>
Motivation: Preserving algebraic constraints (symmetry and traceless-ness) in the Einstein-Bianchi system is challenging for numerical methods.

Method: The linearized system is treated as the Hodge wave equation, and a conforming finite element conformal Hessian complex is constructed on 3D tetrahedral grids.

Result: The method preserves symmetry and traceless-ness simultaneously, and its exactness is proven.

Conclusion: The proposed formulation and discretization successfully address the challenge of preserving constraints in the Einstein-Bianchi system.

Abstract: The Einstein-Bianchi system uses symmetric and traceless tensors to
reformulate Einstein's original field equations. However, preserving these
algebraic constraints simultaneously remains a challenge for numerical methods.
This paper proposes a new formulation that treats the linearized
Einstein-Bianchi system (near the trivial Minkowski metric) as the Hodge wave
equation associated with the conformal Hessian complex. To discretize this
equation, a conforming finite element conformal Hessian complex that preserves
symmetry and traceless-ness simultaneously is constructed on general
three-dimensional tetrahedral grids, and its exactness is proven.

</details>


### [11] [$h$-Trigonometric B-splines](https://arxiv.org/abs/2508.04582)
*Fatma Zürnacı-Yetiş,Ron Goldman,Plamen Simeonov*

Main category: math.NA

TL;DR: Discrete analogues of exponential, sine, and cosine functions are introduced, leading to discrete trigonometric B-splines with recurrence relations and derivative formulas. Results extend classical B-spline theory.


<details>
  <summary>Details</summary>
Motivation: To generalize classical B-spline results to discrete trigonometric analogues, bridging continuous and discrete mathematical frameworks.

Method: Define discrete trigonometric B-splines using non-polynomial divided differences, derive recurrence relations, derivative formulas, and Marsden identities.

Result: Two-term recurrence relation, derivative formula, and Marsden identities for discrete trigonometric B-splines are established.

Conclusion: Classical B-spline results naturally extend to both trigonometric and discrete trigonometric B-splines, unifying continuous and discrete cases.

Abstract: We introduce discrete analogues of the exponential, sine, and cosine
functions. Then using a discrete trigonometric version of a non-polynomial
divided difference, we define discrete analogues of the trigonometric
B-splines. We derive a two-term recurrence relation, a two-term formula for the
discrete derivative, and two variants of the Marsden identity for these
discrete trigonometric B-splines. Since the classical exponential, sine, and
cosine functions are limiting cases of their discrete analogues, we conclude
that many of the standard results for classical polynomial B-splines extend
naturally both to trigonometric B-splines and to discrete trigonometric
B-splines.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [12] [Steady periodic hydroelastic waves on the water surface of finite depth with constant vorticity](https://arxiv.org/abs/2508.03748)
*Yong Zhang*

Main category: math.AP

TL;DR: The study analyzes hydroelastic waves under nonlinear elastic membranes in finite-depth water, using conformal mapping and bifurcation theory to explore wave existence and behavior.


<details>
  <summary>Details</summary>
Motivation: To extend previous work by accommodating rotational flows and addressing the existence of periodic hydroelastic waves.

Method: Employs conformal mapping to transform the problem into a quasilinear pseudodifferential equation, analyzed via bifurcation theory.

Result: Demonstrates a sheet of solutions bifurcating from simple eigenvalues and identifies secondary bifurcation curves near critical vorticity values.

Conclusion: The study successfully models hydroelastic waves, revealing complex solution structures under varying parameters.

Abstract: This study analyzes steady periodic hydroelastic waves propagating on the
water surface of finite depth beneath nonlinear elastic membranes. Unlike
previous work \cite{BaldiT,BaldiT1,Toland,Toland1}, our formulation
accommodates rotational flows in finite-depth water. We employ a conformal
mapping technique to transform the free-boundary problem into a quasilinear
pseudodifferential equation, resulting in a periodic function of a single
variable. This reduction allows the existence question for such waves to be
addressed within the framework of bifurcation theory. With the wavelength
normalized to 2$\pi$, the problem features two free parameters: the wave speed
and the constant vorticity. Under the assumption of the local convexity of
undeformed membrane's stored energy, it is observed that the problem, when
linearized about uniform horizontal flow, has at most two independent solutions
for any values of the parameters. Fixing the vorticity and treating the wave
speed as the bifurcation parameter, the linearized problem possesses a single
solution. We demonstrate that the full nonlinear problem exhibits a sheet of
solutions comprising a family of curves bifurcating from simple eigenvalues.
Taking both the wave speed and vorticity as parameters, when the constant
vorticity approaches critical values, the linearized problem exhibits a
two-dimensional kernel. Near these critical points, a secondary bifurcation
curve emerges from the primary solution branch. This secondary branch consists
of ripple solutions on the surface.

</details>


### [13] [Coefficient Identification Problem with Integral Overdetermination Condition for Diffusion Equations](https://arxiv.org/abs/2508.03859)
*R. R. Ashurov,O. T. Mukhiddinova*

Main category: math.AP

TL;DR: The paper investigates recovering a time- and space-dependent coefficient in a diffusion equation using an additional integral measurement, proving existence and uniqueness of weak and strong solutions.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of recovering coefficients in diffusion equations with partial spatial dependence, extending previous work on full-space problems.

Method: Combines the Fourier method with a priori estimates to analyze the inverse problem.

Result: Establishes theorems for existence and uniqueness of local and global weak and strong solutions under smooth data conditions.

Conclusion: The approach successfully solves the inverse problem, extending results beyond full-space scenarios.

Abstract: In this paper, we investigate a nonlinear inverse problem aimed at recovering
a coefficient $a(t, x)$, dependent on both time and a subset of spatial
variables, in a diffusion equation \( u_t - \Delta_x u - u_{yy} +a(t, x) u =
f(t,x,y) \), using an additional measurement given as an integral over the
spatial domain. Here \(x \in G \subset \mathbb{R}^m\) and \(y \in (0, \pi)\).
We establish theorems on the existence and uniqueness of both local and global
weak solutions. Furthermore, we demonstrate that, under sufficient smoothness
of the problem data, there exists a uniquely determined strong solution (both
local and global) to the inverse problem. Our approach combines the Fourier
method with a priori estimates. Previous studies have addressed similar inverse
problems for parabolic equations defined over the entire space.

</details>


### [14] [Finite-time blowup for the infinite dimensional vorticity equation](https://arxiv.org/abs/2508.03877)
*Evan Miller*

Main category: math.AP

TL;DR: The paper explores the dynamics of the Euler equation in higher dimensions, revealing increased singularity and finite-time blowup, and proposes a model equation to study this behavior.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by the observation that barriers to finite-time blowup in three dimensions vanish in higher dimensions, prompting an investigation into the behavior of smooth solutions.

Method: A model equation is derived by taking the formal limit of the scalar vorticity evolution equation as dimensions approach infinity, exhibiting Burgers shock-type blowup.

Result: The model equation demonstrates finite-time blowup, suggesting a mechanism for similar behavior in the full Euler equation in high dimensions.

Conclusion: The findings imply that smooth solutions of the Euler equation in sufficiently high dimensions may exhibit finite-time blowup, with the model equation providing a framework for further study.

Abstract: In a previous work with Tai-Peng Tsai, the author studied the dynamics of
axisymmetric, swirl-free Euler equation in four and higher dimensions. One
conclusion of this analysis is that the dynamics become dramatically more
singular as the dimension increases. In particular, the barriers to finite-time
blowup for smooth solutions which exist in three dimensions do not exist in
higher dimensions $d\geq 4$. Motivated by this result, we will consider a model
equation that is obtained by taking the formal limit of the scalar vorticity
evolution equation as $d\to +\infty$. This model exhibits finite-time blowup of
a Burgers shock type. The blowup result for the infinite dimensional model
equation strongly suggests a mechanism for the finite-time blowup of smooth
solutions of the Euler equation in sufficiently high dimensions. It is also
possible to treat the full Euler equation as a perturbation of the infinite
dimensional model equation, although this perturbation is highly singular.

</details>


### [15] [The refined area formula for Sobolev mappings $W^{k,p}$](https://arxiv.org/abs/2508.03880)
*Paz Hashash*

Main category: math.AP

TL;DR: The paper proves an area formula for change-of-variable mappings in Sobolev spaces using Lipschitz approximations.


<details>
  <summary>Details</summary>
Motivation: To extend the area formula to Sobolev spaces, which is fundamental in analysis and geometry.

Method: Construct Lipschitz approximations of Sobolev functions that match the original functions except on a set of Riesz capacity zero.

Result: The area formula is established for mappings in the Sobolev space $W^{k,p}_{\text{loc}}$.

Conclusion: The method successfully generalizes the area formula to Sobolev spaces, leveraging Lipschitz approximations.

Abstract: We establish the area formula for change-of-variable mappings in the Sobolev
space $W^{k,p}_{\text{loc}}$. Our approach relies on constructing Lipschitz
approximations of Sobolev functions that agree with the original functions
outside a set of Riesz capacity zero.

</details>


### [16] [Optimal regularity for degenerate elliptic equations with Hamiltonian terms](https://arxiv.org/abs/2508.03924)
*Pêdra D. S. Andrade,Thialita M. Nascimento*

Main category: math.AP

TL;DR: The paper establishes optimal H"older estimates for solutions to degenerate elliptic equations with Hamiltonian terms, addressing challenges in gradient regimes.


<details>
  <summary>Details</summary>
Motivation: To extend regularity theory for degenerate elliptic equations by incorporating Hamiltonian terms, which introduce complexities in gradient behavior.

Method: Uses perturbative techniques to analyze the interplay between degeneracy rate and Hamiltonian growth.

Result: Derives quantitative H"older estimates for gradients, generalizing prior work by Araujo-Ricarte-Teixeira and Birindelli-Demengel.

Conclusion: The results broaden the applicability of regularity theory in degenerate elliptic equations with Hamiltonian terms.

Abstract: We establish optimal, quantitative H\"oder estimates for the gradient of
solutions to a class of degenerate elliptic equations with Hamiltonian terms.
The presence of such lower-order terms introduces additional challenges,
particularly in regimes where the gradient is either very small or very large.
Our approach adapts perturbative techniques to capture the interplay between
the degeneracy rate and the Hamiltonian's growth. Our results naturally extend
the regularity theory developed by Araujo-Ricarte-Teixeira (Calc. Var.
53:605-625, 2015) and Birindelli-Demengel (Nonlinear Differ. Equ. Appl. 23:41,
2016) to a more general setting.

</details>


### [17] [Micro-macro and macro-macro limits for controlled leader-follower systems](https://arxiv.org/abs/2508.04020)
*Giacomo Albi,Young-Pil Choi,Matteo Piu,Sihyun Song*

Main category: math.AP

TL;DR: The paper analyzes a leader-follower particle system under feedback control, deriving mean-field limits via micro-macro and macro-macro transitions, with stability and convergence proofs.


<details>
  <summary>Details</summary>
Motivation: To rigorously reduce controlled multi-agent systems hierarchically and validate the dynamics through numerical simulations.

Method: Uses modulated energy methods and Wasserstein distances for stability and convergence estimates in mean-field limits.

Result: Quantitative stability and convergence estimates are established, supported by numerical simulations.

Conclusion: The study provides a rigorous foundation for hierarchical reduction in controlled multi-agent systems, with numerical validation.

Abstract: We study a leader-follower system of interacting particles subject to
feedback control and derive its mean-field limits through a two-step passage:
first to a micro-macro system coupling leader particles with a follower fluid,
and then to a fully continuum macro-macro system. For each limiting procedure,
we establish quantitative stability and convergence estimates based on
modulated energy methods and Wasserstein distances. These results provide a
rigorous foundation for the hierarchical reduction of controlled multi-agent
systems. Numerical simulations are presented, including examples with
interaction potentials beyond the analytical class considered, to demonstrate
the dynamics and support the theoretical results.

</details>


### [18] [Nonlinear stability of two-dimensional periodic waves in parabolic systems with conservation laws](https://arxiv.org/abs/2508.04023)
*L. Miguel Rodrigues,Aric Wheeler*

Main category: math.AP

TL;DR: A stability theory for 2D periodic traveling waves in parabolic systems is developed, extending prior work to include conservation laws and nonlocalized perturbations.


<details>
  <summary>Details</summary>
Motivation: To generalize stability results for 1D waves to 2D patterns and systems with conservation laws, addressing spectral irregularities.

Method: Identify diffusive spectral stability and prove nonlinear stability for various perturbations, handling conic-like and Jordan-block singularities.

Result: Nonlinear stability is achieved under the identified spectral assumption, even for critically nonlocalized perturbations.

Conclusion: The work extends stability theory to broader contexts, overcoming spectral challenges in multidimensional and conservation law systems.

Abstract: We develop a stability theory for two-dimensional periodic traveling waves of
general parabolic systems, possibly including conservation laws. In particular,
we identify a diffusive spectral stability assumption and prove that it implies
nonlinear stability for variously-(non)localized perturbations, including
critically nonlocalized perturbations. Thus we extend the stability parts of
Johnson et al., Invent. Math. 2014, to two-dimensional patterns and of
Melinand-Rodrigues, preprint 2024, to systems with conservation laws. In doing
so we need to bypass two kinds of low spectral regularity, explicitly
conic-like singularities due to multidimensionality and Jordan-block like
singularities due to conservation laws.

</details>


### [19] [Smoothing effect for higher order dispersive equations and applications to nonlinear initial value problems](https://arxiv.org/abs/2508.04130)
*Alexandre Arias Junior,Alessia Ascanelli,Marco Cappiello*

Main category: math.AP

TL;DR: Study of smoothing effects in dispersive inhomogeneous evolution equations with variable coefficients, applied to nonlinear problems for existence and uniqueness of solutions.


<details>
  <summary>Details</summary>
Motivation: To understand the smoothing effect of spatial decay assumptions on the subleading coefficient of linear operators in p-evolution equations.

Method: Analyze the initial value problem for dispersive inhomogeneous evolution equations with variable coefficients, focusing on spatial decay assumptions. Apply results to nonlinear problems with derivative nonlinearities.

Result: Existence and uniqueness of solutions in a suitable Sobolev class for nonlinear equations, including KdV-type and Kawahara-type equations.

Conclusion: The study provides insights into smoothing effects and extends applicability to physically significant nonlinear equations.

Abstract: In this paper we deal with the initial value problem related to a family of
dispersive inhomogeneous evolution equations Pu=f with variable coefficients
belonging to the class of p-evolution equations, $p\geq 2$. We study the
smoothing effect produced by some spatial decay assumptions on the imaginary
part of the subleading coefficient of the linear operator P. Then we apply this
result to nonlinear problems with derivative nonlinearities obtaining existence
and uniqueness of the solution in a suitable Sobolev class. The nonlinear
equations considered include various equations of physical interest such as
KdV-type and Kawahara-type equations.

</details>


### [20] [Analysis on a generalized two-component Novikov system](https://arxiv.org/abs/2508.04290)
*Yonghui Zhou,Xiaowan Li,Shuguan Ji,Zhijun Qiao*

Main category: math.AP

TL;DR: Study of a generalized two-component Novikov system with weak dissipation, covering local well-posedness, wave breaking conditions, and persistence properties in weighted spaces.


<details>
  <summary>Details</summary>
Motivation: To analyze the behavior of solutions for a generalized two-component Novikov system under weak dissipation, addressing local existence, wave breaking, and solution persistence.

Method: Uses Kato's theorem for local well-posedness, derives conditions for wave breaking, and investigates persistence in weighted $L^{p}(\mathbb{R})$ spaces.

Result: Established local well-posedness, identified wave breaking conditions, and demonstrated persistence properties in weighted spaces.

Conclusion: The study provides insights into the dynamics of the generalized Novikov system, including solution behavior and persistence under weak dissipation.

Abstract: In this paper, we study the Cauchy problem for a generalized two-component
Novikov system with weak dissipation. We first establish the local
well-posedness of solutions by using the Kato's theorem. Then we give the
necessary and sufficient condition for the occurrence of wave breaking in a
finite time. Finally, we investigate the persistence properties of strong
solutions in the weighted $L^{p}(\mathbb{R})$ spaces for a large class of
moderate weights.

</details>


### [21] [The effect of stratification on the stability of a rest state in the 2D inviscid Boussinesq system](https://arxiv.org/abs/2508.04514)
*Catalina Jurja,Haram Ko*

Main category: math.AP

TL;DR: The paper studies the impact of stratification on the stability of a rest state in the 2D inviscid Boussinesq system, achieving stability for Sobolev-regular perturbations over a specific timescale.


<details>
  <summary>Details</summary>
Motivation: To understand how stratification influences stability in the 2D inviscid Boussinesq system and improve upon previous results by reducing regularity assumptions.

Method: Uses inhomogeneous Strichartz estimates to control nonlinear effects, leveraging dispersion induced by stratification.

Result: Stability is proven for Sobolev-regular perturbations on a timescale of O(ε^(-4/3)), with only L²-based regularity assumptions.

Conclusion: The approach successfully extends to the dispersive SQG equation, demonstrating broader applicability of the method.

Abstract: We investigate and quantify the effect of stratification on the stability
time of a stably stratified rest state for the 2D inviscid Boussinesq system on
$\mathbb{R}^2$. As an important consequence, we obtain stability of the steady
state starting from an $\varepsilon$-sized initial perturbation of Sobolev
regularity $H^{3^+}$ on a timescale $\mathcal{O}(\varepsilon^{-4/3})$.
  In our setting, stratification induces dispersion and at the core of our
approach are inhomogeneous Strichartz estimates used to control nonlinear
contributions. This allows to keep only $L^2-$based regularity assumptions on
the initial perturbation, whereas previous works impose additional
localizations to achieve this timescale.
  We prove the analogous result for the related dispersive SQG equation.

</details>


### [22] [Optical Tomography with Scattered Rays](https://arxiv.org/abs/2508.04543)
*Francis Chung,Faith Hensley*

Main category: math.AP

TL;DR: The paper presents an algebraic method to reconstruct the scattering coefficient in radiative transport equations (RTE) using single-scattered light, offering improved stability over traditional X-ray transform inversion.


<details>
  <summary>Details</summary>
Motivation: To address the instability of traditional methods for reconstructing scattering coefficients in RTE, the study explores using single-scattered light for more stable reconstructions.

Method: The method involves extracting information from the second term in the collision expansion (single-scattered light) and deriving an algebraic formula for the scattering coefficient. It is extended to multi-frequency scenarios where photons change frequency post-collision.

Result: The proposed method provides a stable algebraic reconstruction of the scattering coefficient, outperforming traditional X-ray transform inversion.

Conclusion: The study demonstrates a stable reconstruction technique for RTE scattering coefficients and suggests potential applications in 3D image reconstruction.

Abstract: We consider the inverse problem of reconstructing the scattering coefficient
of a simple radiative transport equation (RTE) used to model light propagation
inside a scattering medium. To do so, we extract information from the second
term in the collision expansion, that is, light that has been scattered by a
single collision, for solutions to the RTE. We show that with proper sources
and measurements, the scattering coefficient for the RTE can be obtained via an
algebraic formula, resulting in a reconstruction with improved stability
compared to the normal X-ray transform inversion method. We extend these
theorems to apply to a multi-frequency setting in which photons change
frequency after collisions. Then, we discuss potential applications of our
theory for 3D image reconstruction.

</details>


### [23] [Effective interface laws of Navier-slip-type involving the elastic displacement for Stokes flow through a thin porous elastic layer](https://arxiv.org/abs/2508.04607)
*Markus Gahn,Maria Neuss-Radu*

Main category: math.AP

TL;DR: The paper derives an effective model for fluid flow through a thin elastic porous membrane, coupling bulk fluid domains via interface laws, with results dependent on elastic stress tensor scaling.


<details>
  <summary>Details</summary>
Motivation: To rigorously model fluid-structure interaction in thin porous membranes separating fluid domains, addressing microscale complexities and deriving macroscopic interface laws.

Method: Uses two-scale convergence techniques for thin domains, coupled with instationary Stokes and linear elasticity equations, and employs cell problem techniques for macroscopic coefficients.

Result: Derives effective interface laws (Navier-slip-type) coupling bulk fluids, yielding either membrane or Kirchhoff-Love plate equations for displacement, with mass exchange between fluids.

Conclusion: The scaling of the elastic stress tensor critically determines the effective interface behavior, enabling systematic derivation of macroscopic models from microscopic interactions.

Abstract: This paper presents a rigorous derivation of an effective model for fluid
flow through a thin elastic porous membrane separating two fluid bulk domains.
The microscopic setting involves a periodically structured porous membrane
composed of a solid phase and fluid-filled pores, with thickness and
periodicity of order $\varepsilon$, small compared to the size of the bulk
regions. The microscopic model is governed by a coupled fluid-structure
interaction system: instationary Stokes equations for the fluid and linear
elasticity for the solid, with two distinct scalings of the elastic stress
tensor yielding different effective behaviors.
  Using two-scale convergence techniques adapted to thin domains and
oscillatory microstructures, the membrane is reduced to an effective interface
across which transmission conditions are derived. The resulting macroscopic
model couples the bulk fluid domains via effective interface laws of
Navier-slip-type including the dynamic displacement. The character of this
coupling depends critically on the choice of the scaling in the elastic stress
tensor, leading to either a membrane equation or a Kirchhoff-Love plate
equation for the effective displacement. The resulting interface conditions
naturally admit mass exchange between the adjacent fluid regions. In the
analytical framework, a new two-scale compactness theorem for the symmetric
gradient is established, underpinning the passage to the limit in the coupled
system. Moreover, cell problem techniques are employed systematically to
construct admissible test functions and to rigorously extract the effective
macroscopic coefficients.

</details>


### [24] [Analysis of the Darcy-Brinkman flow with viscous dissipation and non-homogeneous thermal boundary condition](https://arxiv.org/abs/2508.04615)
*Igor Pažanin,Francisco J. Suárez-Grau*

Main category: math.AP

TL;DR: The study analyzes Darcy-Brinkman flow in a thin porous domain, deriving a simplified model using asymptotic techniques to account for viscous dissipation and thermal boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To understand the effects of viscous dissipation and non-homogeneous thermal boundary conditions in thin porous domains, which is relevant for engineering applications.

Method: Asymptotic techniques are applied to derive a simplified coupled model, supported by sharp a priori estimates and compactness results of rescaled functions.

Result: A limit model is derived, incorporating viscous dissipation and thermal boundary effects, applicable to porous media engineering.

Conclusion: The derived model is rigorous and useful for practical engineering applications involving porous media.

Abstract: This study investigates the steady-state Darcy-Brinkman flow within a thin,
saturated porous domain, focusing on the effects of viscous dissipation and
non-homogeneous boundary condition for the temperature. Employing asymptotic
techniques with respect to the domain's thickness, we rigorously derive the
simplified coupled model describing the fluid flow. The mathematical analysis
is based on deriving the sharp a priori estimates and proving the compactness
results of the rescaled functions. The resulting limit model incorporates
contributions of viscous dissipation and thermal boundary conditions and thus
could prove useful in the engineering applications involving porous media.

</details>


### [25] [Mathematical modelling of a thin-film flow obeying Carreau's law without high-rate viscosity](https://arxiv.org/abs/2508.04617)
*María Anguiano,Francisco J. Suárez-Grau*

Main category: math.AP

TL;DR: Extended Reynolds law for quasi-Newtonian fluid flows in thin domains using asymptotic analysis.


<details>
  <summary>Details</summary>
Motivation: To understand how non-Newtonian effects and thin domain thickness influence flow behavior.

Method: Asymptotic analysis with respect to domain thickness ε.

Result: Framework derived for flow behavior in thin domains with Carreau law viscosity.

Conclusion: Provides insights into non-Newtonian flow dynamics in thin domains.

Abstract: In this paper, we derive an extension of the Reynolds law for quasi-Newtonian
fluid flows through a thin domain with thickness $0<\varepsilon\ll 1$ with
viscosity obeying the Carreau law without high-rate viscosity, by applying
asymptotic analysis with respect to $\varepsilon$. This provides a framework
for understanding how the non-Newtonian effects and the thickness of the domain
(which is significantly smaller than the other dimensions) influence its flow
behavior.

</details>


### [26] [Darcy's law for micropolar fluid flow in a periodic thin porous medium](https://arxiv.org/abs/2508.04629)
*María Anguiano,Francisco J. Suárez-Grau*

Main category: math.AP

TL;DR: Extension of Darcy law for micropolar fluid flow in thin porous media, considering microstructural properties, geometry, and domain thickness.


<details>
  <summary>Details</summary>
Motivation: To understand how microstructural properties, porous medium geometry, and thin domain thickness influence fluid flow beyond standard Darcy law.

Method: Extend Darcy law to incorporate micropolar fluid dynamics in thin porous media.

Result: Provides a framework for analyzing flow behavior influenced by microstructure and geometry.

Conclusion: The extended Darcy law offers deeper insights into micropolar fluid flow in thin porous media.

Abstract: In this paper, we extend the Darcy law for micropolar fluid flow in a thin
porous medium. This provides a framework for understanding how a fluid's
microstructural properties, the geometry of the porous medium and the thickness
of the domain (which is significantly smaller than the other dimensions)
influence its flow behavior, going beyond the simple pressure-driven flow
described by the standard Darcy law.

</details>


### [27] [Modeling non-Newtonian fluids in a thin domain perforated with cylinders of small diameter](https://arxiv.org/abs/2508.04688)
*María Anguiano,Francisco J. Suárez-Grau*

Main category: math.AP

TL;DR: The paper generalizes the study of non-Newtonian fluid flow in thin porous media with small cylinders, identifying three asymptotic models based on the parameter λ.


<details>
  <summary>Details</summary>
Motivation: To extend previous research on non-Newtonian fluids in thin porous media by considering varying heights and providing a comprehensive asymptotic analysis.

Method: Analyzes the 3D incompressible Stokes system with non-linear power law viscosity for shear-thinning fluids, focusing on the limit behavior as parameters ε, δ_ε, and h_ε approach zero.

Result: Identifies three asymptotic models: non-linear Darcy law (λ=0), non-linear Brinkman-type law (0<λ<∞), and non-linear Reynolds law (λ=∞).

Conclusion: The study offers a complete description of non-Newtonian fluid behavior in thin porous media, generalizing prior work and revealing distinct flow regimes based on λ.

Abstract: We consider the flow of a generalized Newtonian fluid through a thin porous
medium of height $h_\varepsilon$ perforated with $\varepsilon$-periodically
distributed solid cylinders of very small diameter
$\varepsilon\delta_\varepsilon$, where the small parameters $\varepsilon,
\delta_\varepsilon$ and $h_\varepsilon$ are devoted to tend to zero. We assume
that the fluid is described by the 3D incompressible Stokes system with a
non-linear power law viscosity of flow index $1<r<2$ (shear thinning). The
particular case $h_\varepsilon=\sigma_\varepsilon$, where
$\sigma_\varepsilon:=\varepsilon/\delta_\varepsilon^{{2-r\over r}}\to 0$, was
recently published in (Anguiano and Su\'arez-Grau, \emph{Mediterr. J. Math.}
(2021) 18:175). In this paper, we generalize previous study for any
$h_\varepsilon$ and we provide a more complete description on the asymptotic
behavior of non-Newtonian fluids in a thin porous medium composed by cylinders
of small diameter. We prove that depending on the value of
$\lambda:=\lim_{\varepsilon\to 0}\sigma_\varepsilon/h_\varepsilon\in
[0,+\infty]$, there exist three types of lower-dimensional asymptotic models: a
non-linear Darcy law in the case $\lambda=0$, a non-linear Brinkman-type law in
the case $\lambda\in (0,+\infty)$, and a non-linear Reynolds law in the case
$\lambda=+\infty$.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [28] [FFTArray: A Python Library for the Implementation of Discretized Multi-Dimensional Fourier Transforms](https://arxiv.org/abs/2508.03697)
*Stefan J. Seckmeyer,Christian Struckmann,Gabriel Müller,Jan-Niclas Kirsten-Siemß,Naceur Gaaloul*

Main category: physics.comp-ph

TL;DR: FFTArray is a Python library automating Fourier transform discretization, simplifying grid selection and corrections for spectral methods, with GPU support and seamless integration with array backends.


<details>
  <summary>Details</summary>
Motivation: Existing Fourier spectral methods are tightly integrated into software, sacrificing generality and adaptability to new coordinate systems or boundary conditions.

Method: FFTArray automates Fourier transform discretization, defines coordinate grids, and applies corrections efficiently without sacrificing performance.

Result: The library supports GPU acceleration, integrates with NumPy, JAX, and PyTorch, and simplifies translating equations into code.

Conclusion: FFTArray reduces barriers to developing high-performance, maintainable code for pseudo-spectral Fourier methods, focusing on scientific challenges.

Abstract: Partial differential equations describing the dynamics of physical systems
rarely have closed-form solutions. Fourier spectral methods, which use Fast
Fourier Transforms (FFTs) to approximate solutions, are a common approach to
solving these equations. However, implementing those requires careful attention
to grid selection and coordinate-dependent phase and scale factors when mapping
the Fourier integrals to discrete FFTs. Most existing software packages
integrate the Fourier transform discretization tightly into their full-stack
implementations. This integrated design sacrifices generality, making it
difficult to adapt to new coordinate systems, boundary conditions, or
problem-specific requirements. To address these challenges, we present
FFTArray, a Python library that automates the general discretization of Fourier
transforms. It allows to easily define valid coordinate grids and efficiently
applies the coordinate grid specific corrections with minimal impact on
computational performance. Built on the Python Array API Standard, FFTArray
supports GPU acceleration and integrates seamlessly with array backends like
NumPy, JAX and PyTorch. Its interface enables the direct translation of
textbook equations and complex research problems into code, while its modular
design scales naturally to multiple dimensions. FFTArray allows scientists to
focus on their core scientific challenges and thereby reduces the barrier to
developing high-performance, maintainable code for pseudo-spectral Fourier
methods. The code is openly available at https://github.com/QSTheory/fftarray
under Apache-2.0 license.

</details>


### [29] [Physics-Informed Neural Network for Elastic Wave-Mode Separation](https://arxiv.org/abs/2508.04600)
*E. A. B. Alves,P. D. S. de Lima,D. H. G. Duarte,M. S. Ferreira,J. M. de Araújo,C. G. Bezerra*

Main category: physics.comp-ph

TL;DR: A physics-informed neural network (PINN) is used to separate P and S modes in elastic media by solving a scalar Poisson equation, reducing computational costs and improving accuracy compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: Accurate mode decomposition in non-homogeneous elastic media is challenging but essential for interpreting physical properties. Machine learning, particularly PINN, offers a promising solution.

Method: The study employs a PINN to solve a scalar Poisson equation for mode separation, leveraging Helmholtz decomposition. This approach reduces computational costs and is tested on homogeneous and non-homogeneous models.

Result: The separated modes closely match conventional techniques, with reduced transverse wave leakage, demonstrating the method's effectiveness.

Conclusion: PINN-based mode separation is a viable, efficient alternative to traditional methods, offering scalability and accuracy in both homogeneous and non-homogeneous media.

Abstract: Mode conversion in non-homogeneous elastic media makes it challenging to
interpret physical properties accurately. Decomposing these modes correctly is
crucial across various scientific areas. Recent machine learning approaches
have been proposed to address this problem, utilizing the Helmholtz
decomposition technique. In this paper, we investigate the capabilities of a
physics-informed neural network (PINN) in separating P and S modes by solving a
scalar Poisson equation. This scalar formulation offers a dimensionally
scalable reduction in computational cost compared to the traditional vector
formulation. We verify the proposed method in both homogeneous and realistic
non-homogeneous elastic models as showcases. The obtained separated modes
closely match those from conventional numerical techniques, while exhibiting
reduced transverse wave leakage.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [30] [Stimulated Brillouin Amplification with Flying Focus](https://arxiv.org/abs/2508.04121)
*Zhaohui Wu,Xiaoming Zeng,Zhaoli Li,Xiaodong Wang,Xiao Wang,Jie Mu,Yanlei Zuo,Kainan Zhou,Hao Peng,C. Riconda,S. Weber*

Main category: physics.plasm-ph

TL;DR: The paper demonstrates SBS amplification using a flying focus in a plasma channel, achieving high efficiency at low intensities.


<details>
  <summary>Details</summary>
Motivation: Material damage thresholds limit CPA in high-power lasers; SBS offers a damage-free alternative but is hindered by instabilities.

Method: Experimental demonstration of SBS amplification with a flying focus in a 3-mm plasma channel, using chromatic aberration and interferometric ionization for precise velocity measurement.

Result: SBS amplification achieved at pump and seed intensities two orders of magnitude lower than conventional setups, with 14.5% conversion efficiency.

Conclusion: Flying focus extends interaction lengths and enables efficient plasma-based laser amplification at reduced intensities.

Abstract: Material damage thresholds pose a fundamental limit to chirped pulse
amplification (CPA) in high-power laser systems. Plasma-based amplification via
stimulated Brillouin scattering (SBS) offers a damage-free alternative, yet its
effectiveness has been hindered by instabilities that constrain interaction
length. In this study, we report the first experimental demonstration of SBS
amplification driven by a flying focus in a 3-mm plasma channel. The flying
focus is generated using chromatic aberration from spherical lenses, with its
velocity precisely measured by an interferometric ionization method achieving
6.6 fs timing resolution. At a focus velocity near -c, SBS amplification is
realized at pump and seed intensities more than two orders of magnitude lower
than in conventional setups, yielding a conversion efficiency of 14.5%. These
results validate flying focus as a powerful tool for extending interaction
lengths and enabling efficient plasma-based laser amplification at reduced
intensities.

</details>


### [31] [Stabilization and Re-excitation of Sawtooth Oscillations due to Energetic Particles in Tokamaks](https://arxiv.org/abs/2508.04210)
*H. X. Zhang,H. W. Zhang,Z. W. Ma,J. X. Huang,W. Zhang*

Main category: physics.plasm-ph

TL;DR: The study explores how energetic particles (EPs) interact with sawtooth oscillations in tokamak plasmas, revealing their impact on oscillation types and transitions, as well as coupling with other instabilities like TAEs and r-TM.


<details>
  <summary>Details</summary>
Motivation: Understanding the interaction between sawtooth oscillations and EPs is crucial for optimizing energy confinement and sawtooth control in fusion reactors like ITER.

Method: The study uses the CLT-K code for long-term nonlinear simulations, analyzing EP redistribution and their effects on sawtooth behavior and type transitions.

Result: Co-passing EPs extend sawtooth periods, while counter-passing EPs promote small sawteeth or steady-island states. EP redistribution also excites TAEs and r-TM.

Conclusion: Multi-mode simulations are essential for capturing EP-sawtooth interactions, offering insights for optimizing sawtooth control in future reactors.

Abstract: Sawtooth oscillations, driven by internal kink modes (IKMs), are fundamental
phenomena in tokamak plasmas. They can be classified into different types,
including normal sawteeth, small sawteeth, and in some cases, evolving into the
steady-island state, each having a different impact on energy confinement in
fusion reactors. This study investigates the interaction between sawtooth
oscillations and energetic particles (EPs) using the initial-value MHD-kinetic
hybrid code CLT-K, which can perform long-term self-consistent nonlinear
simulations. We analyze the redistribution of EPs caused by sawtooth crashes
and the effect of EPs on sawtooth behavior and type transitions. The results
show that co-passing EPs tend to re-excite sawtooth oscillations, extending
their period, while counter-passing EPs promote the system evolution toward
small sawteeth, potentially leading to the steady-island state. Additionally,
we provide a physical picture of how EPs influence sawtooth type through the
mechanism of magnetic flux pumping. We demonstrate that the radial residual
flow in the core plays a crucial role in determining the reconnection rate and
sawtooth type. Moreover, we observe new phenomena about couplings of various
instabilities, such as the excitation of global multi-mode toroidal Alfv\'en
eigenmodes (TAEs) due to EP redistribution following a sawtooth crash and the
excitation of the resonant tearing mode (r-TM) when injecting counter-passing
EPs. The study also explores the impact of EP energy and the safety factor
profile on the development of stochastic magnetic fields and EP transport.
These findings emphasize the necessity of multi-mode simulations in capturing
the complexity of EP-sawtooth interactions and provide insights for optimizing
sawtooth control in future reactors such as ITER.

</details>


### [32] [Controlling the electric force on a dust particle during the afterglow of a plasma at a higher gas pressure](https://arxiv.org/abs/2508.04621)
*Neeraj Chaubey,J. Goree*

Main category: physics.plasm-ph

TL;DR: The study confirms that dust particle charge and electric force can be controlled in plasma afterglow at higher gas pressure (90 mTorr), extending applicability to semiconductor manufacturing.


<details>
  <summary>Details</summary>
Motivation: To explore and confirm the feasibility of controlling dust particle charge and electric force in plasma afterglow at higher gas pressures, relevant for mitigating particle contamination in semiconductor manufacturing.

Method: Experiments in a capacitively coupled radio-frequency plasma (CCP) with timed DC electric field application during afterglow, analyzing particle velocity and comparing to motion equation predictions.

Result: Dust particles can be charged and controlled with electric forces comparable to gravity even at higher pressures, with potential for easier control of submicron particles.

Conclusion: The findings extend the parameter range for particle contamination control in semiconductor manufacturing, suggesting broader applicability and easier control for smaller particles.

Abstract: When dust particles are immersed in a plasma, and the power that sustains a
plasma is terminated, the charge of dust particles will change in the early
afterglow, as electrons and ions gradually diminish in number. The possibility
of controlling this charge, along with the electric force acting on the
particles in the late afterglow, has earlier been demonstrated at a low gas
pressure of 8 mTorr. Here, it is confirmed experimentally that controlling
particles is possible also at a higher gas pressure of 90 mTorr, in a
capacitively coupled radio-frequency plasma (CCP). A timed application of a DC
electric field during the afterglow is a key element of this control scheme.
Analyzing the experimental results, the electric force in the late afterglow
was determined by comparing measurements of particle velocity to a prediction
made by integrating the equation of motion, taking into account gas friction.
In addition to applying friction to dust particles, gas also slows the drifting
motion of electrons and ions, reducing their energy during the afterglow, but
nevertheless we find that dust particles become charged in the afterglow so
that one can apply an electric force to them that is comparable to the
gravitational force, even at a higher pressure than had previously been
demonstrated. This result extends the parameter range for which it is expected
that particle contamination in semiconductor manufacturing can be mitigated by
controlling charge and forces during the afterglow. Because of the way that
forces scale with particle size, it is expected that submicron particles can be
controlled even more easily than the larger spheres in the present experiment.

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [33] [MD-LLM-1: A Large Language Model for Molecular Dynamics](https://arxiv.org/abs/2508.03709)
*Mhd Hussein Murtada,Z. Faidon Brotzakis,Michele Vendruscolo*

Main category: q-bio.BM

TL;DR: A deep learning framework (MD-LLM) is introduced to predict protein dynamics and discover new conformational states, leveraging LLMs to address computational challenges in molecular dynamics.


<details>
  <summary>Details</summary>
Motivation: Molecular dynamics (MD) is computationally intensive for macromolecular systems; deep learning offers a potential solution.

Method: Developed MD-LLM-1 by fine-tuning Mistral 7B, applied to T4 lysozyme and Mad2 protein systems to predict conformational states.

Result: MD-LLM-1 successfully predicted new conformational states from training on one state, demonstrating its ability to explore protein landscapes.

Conclusion: MD-LLM-1 shows promise for learning protein dynamics principles, though it doesn't explicitly model thermodynamics or kinetics yet.

Abstract: Molecular dynamics (MD) is a powerful approach for modelling molecular
systems, but it remains computationally intensive on spatial and time scales of
many macromolecular systems of biological interest. To explore the
opportunities offered by deep learning to address this problem, we introduce a
Molecular Dynamics Large Language Model (MD-LLM) framework to illustrate how
LLMs can be leveraged to learn protein dynamics and discover states not seen in
training. By applying MD-LLM-1, the first implementation of this approach,
obtained by fine-tuning Mistral 7B, to the T4 lysozyme and Mad2 protein
systems, we show that training on one conformational state enables the
prediction of other conformational states. These results indicate that MD-LLM-1
can learn the principles for the exploration of the conformational landscapes
of proteins, although it is not yet modeling explicitly their thermodynamics
and kinetics.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [34] [Mathematical formulation of mode-to-mode energy transfers and energy fluxes in compressible turbulence](https://arxiv.org/abs/2508.04300)
*Dhananjay Singh,Harshit Tiwari,Lekha Sharma,Mahendra K. Verma*

Main category: physics.flu-dyn

TL;DR: A novel framework for analyzing energy transfer in compressible turbulence, decomposing transfers into rotational, compressive, and mixed components, with analogies to incompressible flows.


<details>
  <summary>Details</summary>
Motivation: Understanding compressible turbulence is crucial for atmospheric, astrophysical, and engineering applications, but it is more complex than incompressible turbulence.

Method: Developed a mathematical framework to compute mode-to-mode energy transfer rates and fluxes, capturing energy conservation in triads and decomposing transfers.

Result: The framework provides detailed insights into energy exchange among velocity and internal energy modes and shows universality by analogies with incompressible flows.

Conclusion: The proposed formalism offers a clear and universal approach to studying energy transfers in compressible turbulence.

Abstract: Understanding compressible turbulence is critical for modeling atmospheric,
astrophysical, and engineering flows. However, compressible turbulence poses a
more significant challenge than incompressible turbulence. We present a novel
mathematical framework to compute \textit{mode-to-mode energy transfer rates}
and energy fluxes for compressible flows. The formalism captures detailed
energy conservation within triads and allows decomposition of transfers into
rotational, compressive, and mixed components, providing a clear picture of
energy exchange among velocity and internal energy modes. We also establish
analogies with incompressible hydrodynamic and magnetohydrodynamic flows,
highlighting the framework's universality in studying energy transfers.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [35] [A 60-Addition, Rank-23 Scheme for Exact 3x3 Matrix Multiplication](https://arxiv.org/abs/2508.03857)
*Joshua Stapleton*

Main category: cs.DS

TL;DR: Reduced additive cost of 3x3 matrix multiplication from 61/62 to 60, setting a new state-of-the-art.


<details>
  <summary>Details</summary>
Motivation: Improve efficiency in non-commutative 3x3 matrix multiplication by reducing additive cost.

Method: Achieved reduction without changing the basis, building on prior work (Schwartz-Vaknin, 2023; Martensson-Wagner, 2025).

Result: New record of 60 additive cost, surpassing previous benchmarks.

Conclusion: Demonstrates advancement in matrix multiplication efficiency, offering potential computational benefits.

Abstract: We reduce the additive cost of general (non-commutative) 3x3 matrix
multiplication from the previous records of 61 (Schwartz-Vaknin, 2023) and 62
(Martensson-Wagner, 2025) to 60 without a change of basis. To our knowledge,
this represents a new state-of-the-art.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [36] [Theory uncertainties in predictions of strong-field QED](https://arxiv.org/abs/2508.03975)
*T. G. Blackburn*

Main category: hep-ph

TL;DR: A simulation framework is introduced to quantify theory uncertainties in strong-field QED experiments, revealing a few percent uncertainty due to the locally constant field approximation.


<details>
  <summary>Details</summary>
Motivation: Precision testing of strong-field QED requires reliable simulations with quantified uncertainties to identify discrepancies between experiment and theory.

Method: The paper presents a simulation framework that provides meaningful bounds on theory uncertainties, focusing on the locally constant field approximation.

Result: The framework reveals a few percent theory uncertainty in quantum radiation reaction signals for near-term experiments.

Conclusion: Quantifying theory uncertainties is crucial for reliable comparisons between experiment and theory in strong-field QED.

Abstract: Experiments using high-power lasers and relativistic electron beams will soon
be capable of precision testing of the theory of strong-field quantum
electrodynamics. The comparison between experiment and theory always occurs via
numerical simulations, but the lack of quantitative uncertainty bounds for the
latter means that the origin of any discrepancies cannot be identified
conclusively. Here I present a simulation framework that can place meaningful
bounds on the theory uncertainties inherent to its operation. This work shows
that the use of the locally constant field approximation leads to a theory
uncertainty of a few per cent in the signals of quantum radiation reaction
expected in near-term experiments.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [LRTuckerRep: Low-rank Tucker Representation Model for Multi-dimensional Data Completion](https://arxiv.org/abs/2508.03755)
*Wenwu Gong,Lili Yang*

Main category: cs.LG

TL;DR: A novel Low-Rank Tucker Representation (LRTuckerRep) model unifies global and local prior modeling for multi-dimensional data completion, outperforming existing methods in accuracy and robustness.


<details>
  <summary>Details</summary>
Motivation: Existing methods for multi-dimensional data completion have limitations: low-rank methods are computationally expensive and disrupt data structures, while smoothness-based approaches require manual tuning and generalize poorly.

Method: LRTuckerRep combines low-rank Tucker decomposition with self-adaptive weighted nuclear norm and parameter-free Laplacian-based regularization. Two iterative algorithms solve the nonconvex optimization problem with convergence guarantees.

Result: LRTuckerRep achieves superior completion accuracy and robustness under high missing rates in experiments on image inpainting and traffic data imputation.

Conclusion: LRTuckerRep effectively unifies global and local priors, offering a robust and accurate solution for multi-dimensional data completion.

Abstract: Multi-dimensional data completion is a critical problem in computational
sciences, particularly in domains such as computer vision, signal processing,
and scientific computing. Existing methods typically leverage either global
low-rank approximations or local smoothness regularization, but each suffers
from notable limitations: low-rank methods are computationally expensive and
may disrupt intrinsic data structures, while smoothness-based approaches often
require extensive manual parameter tuning and exhibit poor generalization. In
this paper, we propose a novel Low-Rank Tucker Representation (LRTuckerRep)
model that unifies global and local prior modeling within a Tucker
decomposition. Specifically, LRTuckerRep encodes low rankness through a
self-adaptive weighted nuclear norm on the factor matrices and a sparse Tucker
core, while capturing smoothness via a parameter-free Laplacian-based
regularization on the factor spaces. To efficiently solve the resulting
nonconvex optimization problem, we develop two iterative algorithms with
provable convergence guarantees. Extensive experiments on multi-dimensional
image inpainting and traffic data imputation demonstrate that LRTuckerRep
achieves superior completion accuracy and robustness under high missing rates
compared to baselines.

</details>


### [38] [Next Generation Equation-Free Multiscale Modelling of Crowd Dynamics via Machine Learning](https://arxiv.org/abs/2508.03926)
*Hector Vargas Alvarez,Dimitrios G. Patsatzis,Lucia Russo,Ioannis Kevrekidis,Constantinos Siettos*

Main category: cs.LG

TL;DR: The paper proposes a combined manifold and machine learning approach to model crowd dynamics by bridging microscopic and macroscopic scales, ensuring mass conservation and high accuracy.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of bridging microscopic and macroscopic modeling scales in crowd dynamics for systematic numerical analysis, optimization, and control.

Method: A four-stage approach: 1) derive macroscopic fields from microscopic data using KDE, 2) map to latent space via POD, 3) learn reduced-order surrogate models (LSTMs, MVARs), and 4) reconstruct dynamics in high-dimensional space.

Result: The method achieves high accuracy, robustness, and generalizability, enabling fast and accurate crowd dynamics modeling from agent-based simulations.

Conclusion: The framework effectively bridges scales, conserves mass, and provides a solution operator for macroscopic PDEs, validated by numerical results.

Abstract: Bridging the microscopic and the macroscopic modelling scales in crowd
dynamics constitutes an important, open challenge for systematic numerical
analysis, optimization, and control. We propose a combined manifold and machine
learning approach to learn the discrete evolution operator for the emergent
crowd dynamics in latent spaces from high-fidelity agent-based simulations. The
proposed framework builds upon our previous works on next-generation
Equation-free algorithms on learning surrogate models for high-dimensional and
multiscale systems. Our approach is a four-stage one, explicitly conserving the
mass of the reconstructed dynamics in the high-dimensional space. In the first
step, we derive continuous macroscopic fields (densities) from discrete
microscopic data (pedestrians' positions) using KDE. In the second step, based
on manifold learning, we construct a map from the macroscopic ambient space
into the latent space parametrized by a few coordinates based on POD of the
corresponding density distribution. The third step involves learning
reduced-order surrogate ROMs in the latent space using machine learning
techniques, particularly LSTMs networks and MVARs. Finally, we reconstruct the
crowd dynamics in the high-dimensional space in terms of macroscopic density
profiles. We demonstrate that the POD reconstruction of the density
distribution via SVD conserves the mass. With this "embed->learn in latent
space->lift back to the ambient space" pipeline, we create an effective
solution operator of the unavailable macroscopic PDE for the density evolution.
For our illustrations, we use the Social Force Model to generate data in a
corridor with an obstacle, imposing periodic boundary conditions. The numerical
results demonstrate high accuracy, robustness, and generalizability, thus
allowing for fast and accurate modelling/simulation of crowd dynamics from
agent-based simulations.

</details>


### [39] [Matrix-Free Two-to-Infinity and One-to-Two Norms Estimation](https://arxiv.org/abs/2508.04444)
*Askar Tsyganov,Evgeny Frolov,Sergey Samsonov,Maxim Rakhuba*

Main category: cs.LG

TL;DR: Proposes randomized algorithms for matrix norm estimation using matrix-vector multiplications, with applications in deep learning and recommender systems.


<details>
  <summary>Details</summary>
Motivation: To efficiently estimate matrix norms in a matrix-free setting, addressing needs in deep neural network training and adversarial attack mitigation.

Method: Modifies Hutchinson's diagonal estimator and Hutch++ for matrix norm estimation, providing oracle complexity bounds.

Result: Demonstrates practical utility in Jacobian-based regularization for deep learning and adversarial attack mitigation in recommender systems.

Conclusion: The proposed algorithms are effective for matrix norm estimation and have practical applications in machine learning and security.

Abstract: In this paper, we propose new randomized algorithms for estimating the
two-to-infinity and one-to-two norms in a matrix-free setting, using only
matrix-vector multiplications. Our methods are based on appropriate
modifications of Hutchinson's diagonal estimator and its Hutch++ version. We
provide oracle complexity bounds for both modifications. We further illustrate
the practical utility of our algorithms for Jacobian-based regularization in
deep neural network training on image classification tasks. We also demonstrate
that our methodology can be applied to mitigate the effect of adversarial
attacks in the domain of recommender systems.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [40] [Controlled regularity at future null infinity from past asymptotic initial data: the wave equation](https://arxiv.org/abs/2508.04690)
*Jordan Marajh,Grigalius Taujanskas,Juan A. Valiente Kroon*

Main category: gr-qc

TL;DR: The paper examines the link between initial data for the wave equation at past null infinity and solution regularity at future null infinity in Minkowski spacetime, using conformal methods and Grönwall estimates.


<details>
  <summary>Details</summary>
Motivation: To understand how the regularity of initial data at past null infinity affects the solution's behavior at future null infinity, particularly in non-compact support cases.

Method: Constructs estimates on a causal rectangle extending to the conformal boundary, using Friedrich's conformal representation and non-degenerate Grönwall estimates.

Result: Demonstrates controlled asymptotic expansion of solutions near null and spatial infinity, enabling peeling behavior for non-compact data.

Conclusion: The method provides quantitative control over solution regularity and bridges the description between conformal and physical coordinates.

Abstract: We study the relationship between asymptotic characteristic initial data for
the wave equation at past null infinity and the regularity of the solution at
future null infinity on the Minkowski spacetime. By constructing estimates on a
causal rectangle reaching the conformal boundary, we prove that the solution
admits an asymptotic expansion near null and spatial infinity whose regularity
is controlled quantitatively in terms of the regularity of the data at past
null infinity. In particular, our method gives rise to solutions to the wave
equation in a neighbourhood of spatial infinity satisfying the peeling
behaviour, for data on past null infinity with non-compact support. Our
approach makes use of Friedrich's conformal representation of spatial infinity
in which we prove delicate non-degenerate Gr\"onwall estimates. We describe the
relationship between the solution and the data both in terms of Friedrich's
conformal coordinates and the usual physical coordinates on Minkowski space.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [41] [Simulations of dielectric permittivity of water by Machine Learned Potentials with long-range Coulombic interactions](https://arxiv.org/abs/2508.04628)
*Kehan Cai,Chunyi Zhang,Xifan Wu*

Main category: cond-mat.soft

TL;DR: A machine learning framework is introduced to compute water's dielectric permittivity, incorporating various electric boundary conditions using deep potentials and neural networks.


<details>
  <summary>Details</summary>
Motivation: Understanding water's dielectric permittivity is crucial for its role in physical, biological, and chemical processes.

Method: Uses a long-range-inclusive deep potential trained on hybrid density functional theory data and an auxiliary neural network for Wannier function centers. Evaluates three boundary conditions (metallic, insulating, Kirkwood-Frohlich).

Result: Demonstrates a consistent method for computing Kirkwood correlation factor, correlation length, and permittivity under different boundary conditions.

Conclusion: Establishes a generalizable machine-learning framework for modeling dielectric properties of polar liquids in diverse electrostatic environments.

Abstract: The dielectric permittivity of liquid water is a fundamental property that
underlies its distinctive behaviors in numerious physical, biological, and
chemical processes. Within a machine learning framework, we present a unified
approach to compute the dielectric permittivity of water, systematically
incorporating various electric boundary conditions. Our method employs a
long-range-inclusive deep potential trained on data from hybrid density
functional theory calculations. Dielectric response is evaluated using an
auxiliary deep neural network that predicts the centers of maximally localized
Wannier functions. We investigate three types of electric boundary
conditions--metallic, insulating, and Kirkwood-Frohlich--to assess their
influence on correlated dipole fluctuations and dielectric relaxation dynamics.
In particular, we demonstrate a consistent methodology for computing the
Kirkwood correlation factor, correlation length, and dielectric permittivity
under each boundary condition, where long-range electrostatics play a critical
role. This work establishes a robust and generalizable machine-learning
framework for modeling the dielectric properties of polar liquids under diverse
electrostatic environments.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [42] [Calculating Vibronic Spectra with a linear algorithm based on Gaussian Boson Sampling](https://arxiv.org/abs/2508.03943)
*I. Konyshev,R. Pradip,O. Page,C. Ünlüer,R. T. Nasibullin,V. V. Rybkin,W. Pernice,S. Ferrari*

Main category: quant-ph

TL;DR: The paper presents a scalable algorithm using the linear coupling model within Gaussian boson sampling to simulate molecular vibronic spectra, achieving high fidelity and accuracy for small and larger molecules.


<details>
  <summary>Details</summary>
Motivation: Accurate simulation of molecular vibronic spectra is computationally challenging due to exponential scaling. The study aims to overcome this limitation.

Method: Implemented the algorithm for pentacene using numerical simulation and two optical setups (SNSPD and SPAD). Extended to larger systems (naphthalene, anthracene).

Result: High fidelity (F>0.999) achieved between simulated and analytical profiles. Simulated spectra matched experimental data in position and shape.

Conclusion: The algorithm is scalable, requiring minimal optical components regardless of system size, and accurately reproduces experimental spectra.

Abstract: Accurately simulating molecular vibronic spectra remains computationally
challenging due to the exponential scaling of required calculations. Here, we
show that employing the linear coupling model within the gaussian boson
sampling framework effectively addresses this limitation. We implement the
algorithm for simulating the pentacene molecule through three distinct
approaches, using numerical simulation on a classical computer and
experimentally using two optical setups equipped with different photon
detectors (SNSPD and SPAD). High fidelity $(F>0.999)$ was achieved between the
simulated Franck-Condon profiles and analytically calculated profiles obtained
by enumerating all possible transitions within the linear coupling model.
Furthermore, simulations were performed for larger molecular systems using 48
vibrational modes of naphthalene and 64 vibrational modes of anthracene.
Comparison with experimental data confirms that the simulated spectra
accurately reproduce both the positions and shapes of the measured spectral
bands. A notable advantage of our algorithm is its scalability, requiring only
a fixed minimal set of optical components irrespective of the size of the
studied system.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [43] [A machine learning approach for image classification in synthetic aperture RADAR](https://arxiv.org/abs/2508.04234)
*Romina Gaburro,Patrick Healy,Shraddha Naidu,Clifford Nolan*

Main category: cs.CV

TL;DR: The paper explores using CNNs for classifying objects in SAR data, achieving high accuracy (≥75%) for shape and ice type classification, and examines the impact of antenna height on classification success.


<details>
  <summary>Details</summary>
Motivation: The study aims to leverage CNNs for accurate object and environmental classification in SAR imagery, addressing challenges in synthetic and real-world data.

Method: The approach involves simulating SAR data, reconstructing images, and applying CNNs for classification, with experiments on both synthetic and real Sentinel-1 SAR data.

Result: High classification accuracy (≥75%) is achieved for object shapes and ice types, demonstrating CNN effectiveness in SAR tasks.

Conclusion: CNNs are effective for SAR-based classification, with antenna height impacting success, suggesting practical applications in remote sensing.

Abstract: We consider the problem in Synthetic Aperture RADAR (SAR) of identifying and
classifying objects located on the ground by means of Convolutional Neural
Networks (CNNs). Specifically, we adopt a single scattering approximation to
classify the shape of the object using both simulated SAR data and
reconstructed images from this data, and we compare the success of these
approaches. We then identify ice types in real SAR imagery from the satellite
Sentinel-1. In both experiments we achieve a promising high classification
accuracy ($\geq$75\%). Our results demonstrate the effectiveness of CNNs in
using SAR data for both geometric and environmental classification tasks. Our
investigation also explores the effect of SAR data acquisition at different
antenna heights on our ability to classify objects successfully.

</details>
