{"id": "2508.04926", "pdf": "https://arxiv.org/pdf/2508.04926", "abs": "https://arxiv.org/abs/2508.04926", "authors": ["Fran\u00e7ois Cl\u00e9ment", "Nathan Kirk", "Art B. Owen", "T. Konstantin Rusch"], "title": "On the optimization of discrepancy measures", "categories": ["math.NA", "cs.NA", "math.OC"], "comment": "22 pages, 3 Figures, 4 Tables", "summary": "Points in the unit cube with low discrepancy can be constructed using algebra\nor, more recently, by direct computational optimization of a criterion. The\nusual $L_\\infty$ star discrepancy is a poor criterion for this because it is\ncomputationally expensive and lacks differentiability. Its usual replacement,\nthe $L_2$ star discrepancy, is smooth but exhibits other pathologies shown by\nJ. Matou\\v{s}ek. In an attempt to address these problems, we introduce the\n\\textit{average squared discrepancy} which averages over $2^d$ versions of the\n$L_2$ star discrepancy anchored in the different vertices of $[0,1]^d$. Not\nonly can this criterion be computed in $O(dn^2)$ time, like the $L_2$ star\ndiscrepancy, but also we show that it is equivalent to a weighted symmetric\n$L_2$ criterion of Hickernell's by a constant factor. We compare this criterion\nwith a wide range of traditional discrepancy measures, and show that only the\naverage squared discrepancy avoids the problems raised by Matou\\v{s}ek.\nFurthermore, we present a comprehensive numerical study showing in particular\nthat optimizing for the average squared discrepancy leads to strong performance\nfor the $L_2$ star discrepancy, whereas the converse does not hold.", "AI": {"tldr": "The paper introduces the average squared discrepancy to address issues with traditional discrepancy measures like $L_\\infty$ and $L_2$ star discrepancy, showing computational efficiency and avoiding pathologies.", "motivation": "Traditional discrepancy measures like $L_\\infty$ and $L_2$ star discrepancy have computational and theoretical limitations, prompting the search for a better criterion.", "method": "The authors propose the average squared discrepancy, which averages over $2^d$ versions of the $L_2$ star discrepancy, and compare it with traditional measures.", "result": "The average squared discrepancy is computationally efficient, avoids pathologies, and performs well compared to other measures, especially for $L_2$ star discrepancy.", "conclusion": "The average squared discrepancy is a robust and efficient alternative to traditional discrepancy measures, addressing their shortcomings effectively."}}
{"id": "2508.05111", "pdf": "https://arxiv.org/pdf/2508.05111", "abs": "https://arxiv.org/abs/2508.05111", "authors": ["Marco Sutti", "Mei-Heng Yueh"], "title": "Toroidal area-preserving parameterizations of genus-one closed surfaces", "categories": ["math.NA", "cs.NA", "68U05, 65K10, 65D18, 65D19"], "comment": "28 pages, 10 figures", "summary": "We consider the problem of computing toroidal area-preserving\nparameterizations of genus-one closed surfaces. We propose four algorithms\nbased on Riemannian geometry: the projected gradient descent method, the\nprojected conjugate gradient method, the Riemannian gradient method, and the\nRiemannian conjugate gradient method. Our objective function is based on the\nstretch energy functional, and the minimization is constrained on a power\nmanifold of ring tori embedded in three-dimensional Euclidean space. Numerical\nexperiments on several mesh models demonstrate the effectiveness of the\nproposed framework. Finally, we show how to use the proposed algorithms in the\ncontext of surface registration and texture mapping applications.", "AI": {"tldr": "The paper presents four algorithms for computing toroidal area-preserving parameterizations of genus-one surfaces, using Riemannian geometry and stretch energy minimization.", "motivation": "The problem involves parameterizing genus-one closed surfaces while preserving area, which is useful for applications like surface registration and texture mapping.", "method": "Four algorithms are proposed: projected gradient descent, projected conjugate gradient, Riemannian gradient, and Riemannian conjugate gradient, all minimizing stretch energy on a power manifold of ring tori.", "result": "Numerical experiments confirm the effectiveness of the framework.", "conclusion": "The algorithms are successfully applied to surface registration and texture mapping, demonstrating practical utility."}}
{"id": "2508.05166", "pdf": "https://arxiv.org/pdf/2508.05166", "abs": "https://arxiv.org/abs/2508.05166", "authors": ["Junming Duan", "Wasilij Barsukow", "Christian Klingenberg"], "title": "An asymptotic-preserving active flux scheme for the hyperbolic heat equation in the diffusive scaling", "categories": ["math.NA", "cs.NA"], "comment": "26 pages, 9 figures", "summary": "The Active Flux (AF) method is a compact, high-order finite volume scheme\nthat enhances flexibility by introducing point values at cell interfaces as\nadditional degrees of freedom alongside cell averages. The method of lines is\nemployed here for temporal discretization. A common approach for updating point\nvalues relies on the Jacobian Splitting (JS) method, which incorporates\nupwinding. A key advantage of the AF method over standard finite volume schemes\nis its structure-preserving property, motivating the investigation of its\nasymptotic-preserving (AP) behavior in the diffusive scaling. We show that the\nJS-based AF method without any modification is AP for solving the hyperbolic\nheat equation, in the sense that the limit scheme is a discretization of the\nlimit heat equation. We use formal asymptotic analysis, discrete Fourier\nanalysis, and numerical experiments to illustrate our findings.", "AI": {"tldr": "The paper analyzes the Active Flux (AF) method, a high-order finite volume scheme, demonstrating its asymptotic-preserving (AP) behavior for the hyperbolic heat equation without modifications.", "motivation": "The study is motivated by the AF method's structure-preserving property, exploring its AP behavior in diffusive scaling.", "method": "The method employs Jacobian Splitting (JS) for updating point values and uses formal asymptotic analysis, discrete Fourier analysis, and numerical experiments.", "result": "The JS-based AF method is shown to be AP for the hyperbolic heat equation, with the limit scheme discretizing the heat equation.", "conclusion": "The AF method's AP behavior is validated, confirming its suitability for solving the hyperbolic heat equation."}}
{"id": "2508.05303", "pdf": "https://arxiv.org/pdf/2508.05303", "abs": "https://arxiv.org/abs/2508.05303", "authors": ["Emil L\u00f8vbak", "Sebastian Krumscheid"], "title": "An Investigation into the Distribution of Ratios of Particle Solver-based Likelihoods", "categories": ["math.NA", "cs.NA"], "comment": "16 pages, 4 figures", "summary": "We investigate the use of the Metropolis-Hastings algorithm to sample\nposterior distribution in a Bayesian inverse problem, where the likelihood\nfunction is random. Concretely, we consider the case where one has full field\nobservations of a PDE solution, in case a one-dimensional diffusion equation,\nsubject to a Gaussian observation error. Assuming one uses a particle-based\nMonte Carlo simulation when approximating the likelihood function, one gets an\napproximate likelihood with additive Gaussian noise in the log-likelihood. We\nstudy how these two Gaussian distributions affect the distribution of ratios of\napproximate likelihood evaluations, as required when evaluating acceptance\nprobabilities in the Metropolis-Hastings algorithm. We do so through both\ntheoretical analysis and numerical experiments.", "AI": {"tldr": "The paper explores the Metropolis-Hastings algorithm for sampling posterior distributions in Bayesian inverse problems with random likelihood functions, focusing on PDE solutions and Gaussian noise.", "motivation": "To understand the impact of Gaussian noise in likelihood approximations on the Metropolis-Hastings algorithm's performance.", "method": "Theoretical analysis and numerical experiments are used to study the effects of additive Gaussian noise in log-likelihood evaluations.", "result": "The study examines how Gaussian distributions influence likelihood ratio distributions, crucial for acceptance probabilities in Metropolis-Hastings.", "conclusion": "The findings provide insights into the behavior of the algorithm under noisy likelihood approximations, aiding practical implementations."}}
{"id": "2508.04785", "pdf": "https://arxiv.org/pdf/2508.04785", "abs": "https://arxiv.org/abs/2508.04785", "authors": ["Mar\u00eda Anguiano", "Francisco J. Su\u00e1rez-Grau"], "title": "Two-dimensional Carreau law for a quasi-newtonian fluid flow through a thin domain with a slightly rough boundary", "categories": ["math.AP", "35B27, 35Q35, 76A05, 76M50, 76A20"], "comment": "arXiv admin note: text overlap with arXiv:2312.01844,\n  arXiv:2508.04617", "summary": "This study investigates the asymptotic behavior of the steady-state\nquasi-Newtonian Stokesflow with viscosity given by the Carreau law within a\nthin domain, focusing on the effects of a slightly rough boundary of the\ndomain. Employing asymptotic techniques with respect to the domain's thickness,\nwe rigorously derive the effective nonlinear two-dimensional Reynolds model\ndescribing the fluid flow. The mathematical analysis is based on deriving the\nsharp a priori estimates and proving the compactness results of the rescaled\nfunctions together with monotonicity arguments. The resulting limit model\nincorporates contributions of the oscillating boundary and thus, it could prove\nuseful in the applications involving this lubrication regime.", "AI": {"tldr": "The paper studies the steady-state quasi-Newtonian Stokes flow in a thin domain with a rough boundary, deriving an effective 2D Reynolds model using asymptotic techniques.", "motivation": "To understand the impact of slightly rough boundaries on fluid flow in thin domains and derive a practical model for lubrication applications.", "method": "Asymptotic techniques, sharp a priori estimates, compactness results, and monotonicity arguments are used to derive the limit model.", "result": "An effective nonlinear two-dimensional Reynolds model is derived, incorporating the effects of the oscillating boundary.", "conclusion": "The derived model is useful for applications in lubrication regimes, capturing boundary roughness effects."}}
{"id": "2508.04765", "pdf": "https://arxiv.org/pdf/2508.04765", "abs": "https://arxiv.org/abs/2508.04765", "authors": ["Yanick Thurn", "Manuel Schrauth", "Johanna Erdmenger"], "title": "Hyperbolic tiling neighborhoods in O(1) time", "categories": ["physics.comp-ph", "cond-mat.other", "hep-lat"], "comment": "12 pages, 9 figures", "summary": "Tilings of the hyperbolic plane are of significant interest among many\nbranches of mathematics, physics and computer science. Yet, their construction\nremains a non-trivial task. Current approaches primarily use tree-based\nrecursive algorithms, which are fundamentally limited: they do not readily\nyield the neighborhood graph representing cell adjacencies, which is however\nrequired for many applications. We introduce a novel approach that allows to\nbuild hyperbolic tilings and their associated graph structure simultaneously,\nusing only combinatoric rules without requiring an explicit coordinate\nrepresentation. This allows to generate arbitrarily large, exact hyperbolic\ngraphs, with an algorithmic complexity that does not depend on the lattice\nsize. We provide an easy-to-use implementation which substantially outperforms\nexisting methods, hence rendering ultra large-scale numerical simulations on\nthese geometric structures accessible for the scientific community.", "AI": {"tldr": "A novel method for constructing hyperbolic tilings and their adjacency graphs simultaneously using combinatoric rules, outperforming existing recursive algorithms.", "motivation": "Current recursive methods for hyperbolic tilings lack efficient adjacency graph generation, limiting practical applications.", "method": "Uses combinatoric rules to build tilings and graphs without explicit coordinates, enabling scalable and exact constructions.", "result": "Generates arbitrarily large hyperbolic graphs with size-independent complexity, outperforming existing methods.", "conclusion": "The approach enables large-scale simulations and broadens accessibility for scientific applications."}}
{"id": "2508.04806", "pdf": "https://arxiv.org/pdf/2508.04806", "abs": "https://arxiv.org/abs/2508.04806", "authors": ["Bernard Parent", "Felipe Martin Rodriguez Fuentes", "Spencer LaFoley"], "title": "Electrodeless Magnetohydrodynamic Local Force Generator for Aerocapture", "categories": ["physics.plasm-ph"], "comment": "14 pages, 12 figures", "summary": "This paper presents a novel magnetohydrodynamics (MHD) system for planetary\nentry aerocapture. The system is advantaged over previous approaches by having\nthe following two characteristics: (i) it can be deployed locally to one or\nvarious flow regions, and (ii) it does not make use of electrodes. Previous MHD\nsystems for planetary entry were either electrodeless global systems or\ntwo-electrode local systems. The proposed novel MHD system employs two magnets\nto establish a current loop resulting in a Faraday electromotive force (EMF).\nThe first magnet is positioned to ensure the magnetic field faces outward from\nthe shell, while the second magnet is oriented to ensure the magnetic field\nfaces inward toward the shell. Preliminary findings demonstrate that when\nlocated on the surface of an Earth entry capsule at a flight Mach number of 35,\nthe novel electrodeless MHD system can generate forces several times greater\nthan a two-electrode system while utilizing the same magnetic field strength.\nThe study is conducted entirely through numerical simulation using CFDWARP, a\ncomputational fluid dynamics (CFD) code that employs advanced numerical methods\nallowing for the full coupling between aerodynamics, magnetohydrodynamics, and\nnon-neutral plasma sheaths. The physical model includes an 11-species\nfinite-rate chemical solver including real gas effects, the drift-diffusion\nmodel for all charged species, along with an electric field potential equation\nthat satisfies Gauss's law.", "AI": {"tldr": "A novel electrodeless MHD system for planetary entry aerocapture is proposed, outperforming previous methods by generating stronger forces without electrodes.", "motivation": "To improve planetary entry aerocapture by addressing limitations of existing MHD systems, which were either global and electrodeless or local with electrodes.", "method": "The system uses two magnets to create a Faraday EMF, avoiding electrodes. Simulations with CFDWARP, a CFD code, model aerodynamics, MHD, and plasma sheaths.", "result": "The electrodeless system generates forces several times greater than electrode-based systems at the same magnetic field strength.", "conclusion": "The novel MHD system offers a superior alternative for planetary entry aerocapture, combining local deployment and electrode-free operation."}}
{"id": "2508.05328", "pdf": "https://arxiv.org/pdf/2508.05328", "abs": "https://arxiv.org/abs/2508.05328", "authors": ["Yujun Zhu", "Yulan Ning", "Zhipeng Yang", "Xiaoming He", "Ju Ming"], "title": "A low-rank solver for the Stokes-Darcy model with random hydraulic conductivity and Beavers-Joseph condition", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper proposes, analyzes, and demonstrates an efficient low-rank solver\nfor the stochastic Stokes-Darcy interface model with a random hydraulic\nconductivity both in the porous media domain and on the interface. We consider\nthree interface conditions with randomness, including the Beavers-Joseph\ninterface condition with the random hydraulic conductivity, on the interface\nbetween the free flow and the porous media flow. Our solver employs a novel\ngeneralized low-rank approximation of the large-scale stiffness matrices, which\ncan significantly cut down the computational costs and memory requirements\nassociated with matrix inversion without losing accuracy. Therefore, by\nadopting a suitable data compression ratio, the low-rank solver can maintain a\nhigh numerical precision with relatively low computational and space\ncomplexities. We also propose a strategy to determine the best choice of data\ncompression ratios. Furthermore, we carry out the error analysis of the\ngeneralized low-rank matrix approximation algorithm and the low-rank solver.\nFinally, numerical experiments are conducted to validate the proposed\nalgorithms and the theoretical conclusions.", "AI": {"tldr": "The paper introduces an efficient low-rank solver for the stochastic Stokes-Darcy interface model with random hydraulic conductivity, reducing computational costs while maintaining accuracy.", "motivation": "To address high computational and memory demands in solving stochastic Stokes-Darcy interface problems with randomness in hydraulic conductivity.", "method": "Uses a generalized low-rank approximation for stiffness matrices, proposes a strategy for optimal data compression ratios, and conducts error analysis.", "result": "The solver reduces computational and memory costs without sacrificing accuracy, validated by numerical experiments.", "conclusion": "The low-rank solver is efficient and accurate, with theoretical and experimental validation."}}
{"id": "2508.04856", "pdf": "https://arxiv.org/pdf/2508.04856", "abs": "https://arxiv.org/abs/2508.04856", "authors": ["T. M. Nascimento", "X. H. Nguyen", "P. R. Stinga"], "title": "Regularity of solutions to degenerate and singular free boundary problems with volume constraint", "categories": ["math.AP", "math.CA"], "comment": "13 pages", "summary": "We prove existence and regularity of solutions to degenerate and singular\nelliptic free boundary problems, where the volume of the positivity set of the\nsolution is prescribed.", "AI": {"tldr": "Existence and regularity of solutions for degenerate/singular elliptic free boundary problems with prescribed positivity set volume.", "motivation": "To address challenges in degenerate and singular elliptic free boundary problems where the volume of the solution's positivity set is fixed.", "method": "Proving existence and regularity of solutions under the given constraints.", "result": "Demonstrated existence and regularity of solutions for the specified problems.", "conclusion": "The study successfully establishes solutions for these complex free boundary problems with volume constraints."}}
{"id": "2508.05308", "pdf": "https://arxiv.org/pdf/2508.05308", "abs": "https://arxiv.org/abs/2508.05308", "authors": ["B. D. Jenkins", "A. L. Nicusan", "A. Neveu", "G. Lumay", "F. Francqui", "J. P. K. Seville", "C. R. K. Windows-Yule"], "title": "Identifying Optimal Regression Models For DEM Simulation Datasets", "categories": ["physics.comp-ph"], "comment": null, "summary": "Developing fast regression models (surrogate/metamodels) from DEM data is key\nfor practical industrial application to allow real-time evaluations. However,\nbenchmarking different models is often overlooked in particle technology for\nregression tasks, as model selection is frequently not the primary research\nfocus. This can lead to the use of suboptimal models, resulting in subpar\npredictive accuracy, slow evaluations, or poor generalisation, hindering\neffective real-time decision-making and process optimisation. In this work, we\ndiscuss applying k-fold cross-validation to assess regression models for\ntabular DEM datasets and propose a simple framework for readers to follow to\nfind the optimal model for their data. An example demonstrates its application\nto a DEM dataset of packing fractions measured in a simple measuring beaker\nwith varying inter-particle properties, namely, average particle diameter,\ncoefficient of restitution, coefficient of sliding friction, coefficient of\nrolling resistance, and cohesive energy density. Out of 16 different models\ntested, a histogram-based gradient boosting model was found to be optimal,\nproviding a good fit with acceptable training and inference times.", "AI": {"tldr": "The paper proposes a framework using k-fold cross-validation to benchmark regression models for DEM data, identifying a histogram-based gradient boosting model as optimal among 16 tested.", "motivation": "Fast and accurate regression models are needed for real-time industrial applications, but model benchmarking is often overlooked, leading to suboptimal choices.", "method": "The study applies k-fold cross-validation to evaluate regression models on DEM datasets, focusing on packing fractions with varying particle properties.", "result": "A histogram-based gradient boosting model outperformed 15 others, offering good accuracy and efficiency.", "conclusion": "The proposed framework aids in selecting optimal regression models for DEM data, improving real-time decision-making and process optimization."}}
{"id": "2508.04881", "pdf": "https://arxiv.org/pdf/2508.04881", "abs": "https://arxiv.org/abs/2508.04881", "authors": ["Z. Tecchiolli", "A. J. Coelho", "J. Loizu", "B. De Lucca", "P. Ricci"], "title": "Magnetic shear effects on ballooning turbulence in the boundary of fusion devices", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The effect of magnetic shear on ballooning-driven plasma edge turbulence is\nstudied through nonlinear simulations complemented by linear numerical and\nanalytical investigations. Nonlinear, 3D, global, flux-driven simulations using\nthe GBS code show that the scale separation between radial, x, and poloidal, y,\nsize of turbulent eddies, kx << ky , considered by Ricci et al. (2008) and\nextensively used to predict pressure gradient lengths, SOL width, particle and\nheat fluxes, is observed with high magnetic shear. In contrast, for low\nmagnetic shear, kx ~ ky is observed, with fluctuation properties resembling\nthose shown by recent low-shear stellarator simulations reported in Coelho et\nal. (2024a). Global linear investigations of the ballooning mode qualitatively\ncaptures the transition in mode structure with varying magnetic shear, showing\nthat kx << ky is achieved with sufficiently strong poloidal mode coupling\nenhanced by increasing magnetic shear, resistivity, toroidal mode number, and\nequilibrium gradient scale length. This is confirmed by an analytical study\nconsidering a dominant poloidal mode and its sidebands, which highlights that\nthe poloidal mode structure is determined by curvature and k parallel effects", "AI": {"tldr": "The study examines how magnetic shear affects ballooning-driven plasma edge turbulence, showing that high shear leads to scale separation (kx << ky), while low shear results in kx ~ ky, aligning with stellarator simulations.", "motivation": "To understand the impact of magnetic shear on turbulence properties and validate previous predictions about pressure gradients and transport in plasma edges.", "method": "Nonlinear 3D simulations (GBS code), linear numerical investigations, and analytical studies of ballooning modes and poloidal mode coupling.", "result": "High magnetic shear causes kx << ky, while low shear leads to kx ~ ky. Linear and analytical studies confirm the transition in mode structure with shear variation.", "conclusion": "Magnetic shear significantly influences turbulence scale separation, with implications for predicting plasma edge behavior in fusion devices."}}
{"id": "2508.05372", "pdf": "https://arxiv.org/pdf/2508.05372", "abs": "https://arxiv.org/abs/2508.05372", "authors": ["Louis Petri", "Gunnar Birke", "Christian Engwer", "Hendrik Ranocha"], "title": "The domain-of-dependence stabilization for cut-cell meshes is fully discretely stable", "categories": ["math.NA", "cs.NA", "65M12, 65M20, 65M60"], "comment": "31 pages, 11 figures, 3 tables. For the associated reproducibility\n  repository, see https://github.com/louispetri/2025_dod_linear_stability", "summary": "We present a fully discrete stability analysis of the domain-of-dependence\nstabilization for hyperbolic problems. The method aims to address issues caused\nby small cut cells by redistributing mass around the neighborhood of a small\ncut cell at a semi-discrete level. Our analysis is conducted for the linear\nadvection model problem in one spatial dimension. We demonstrate that fully\ndiscrete stability can be achieved under a time step restriction that does not\ndepend on the arbitrarily small cells, using an operator norm estimate.\nAdditionally, this analysis offers a detailed understanding of the stability\nmechanism and highlights some challenges associated with higher-order\npolynomials. We also propose a way to mitigate these issues to derive a\nfeasible CFL-like condition. The analytical findings, as well as the proposed\nsolution are verified numerically in one- and two-dimensional simulations.", "AI": {"tldr": "The paper analyzes the stability of domain-of-dependence stabilization for hyperbolic problems, focusing on small cut cells. It achieves fully discrete stability with a time step restriction independent of cell size and addresses challenges with higher-order polynomials.", "motivation": "To address stability issues caused by small cut cells in hyperbolic problems, which can disrupt numerical simulations.", "method": "The study uses a linear advection model in one dimension, applying operator norm estimates to analyze stability and proposing a CFL-like condition for higher-order polynomials.", "result": "Fully discrete stability is achieved under a time step restriction independent of small cells. The analysis reveals stability mechanisms and challenges with higher-order polynomials.", "conclusion": "The proposed method and analysis are validated numerically in 1D and 2D simulations, offering a feasible solution for stability in hyperbolic problems with small cut cells."}}
{"id": "2508.04863", "pdf": "https://arxiv.org/pdf/2508.04863", "abs": "https://arxiv.org/abs/2508.04863", "authors": ["Patrick Ballard", "Flaviana Iurlano"], "title": "Transition from Continuous to Jumping Solutions in 2D Quasi-static Elastic Contact Problems with Coulomb Friction: the Mathematics Underlying the Onset of Brake Squeal", "categories": ["math.AP"], "comment": null, "summary": "We formulate the quasi-static elastic contact problem with Coulomb friction\nin a very general setting, with possible jumps in time for both the load and\nthe solution. Exploiting ideas originating in our recent paper [4], we exhibit\nan optimal condition on the magnitude of the friction coefficient under which\nwe prove the existence of an absolutely continuous solution for arbitrary\nabsolutely continuous loads in the case of the most general 2D problem. We\nprovide examples showing that, when the condition is violated, spontaneous\njumps in time of the solution may occur, even when the load varies absolutely\ncontinuously in time. We argue that these spontaneous jumps in time of the\nsolution in the quasi-static problem reveal a transition of the process from a\nquasi-static nature to a dynamic nature, interpreted as the mathematical\nsignature of the onset of friction-induced vibrations in the elastodynamic\ncontact problem with dry friction.", "AI": {"tldr": "The paper analyzes the quasi-static elastic contact problem with Coulomb friction, proving existence of solutions under optimal friction conditions and showing spontaneous jumps as evidence of dynamic transitions.", "motivation": "To understand the conditions for existence of solutions in quasi-static elastic contact problems with friction and explore the transition to dynamic behavior.", "method": "Formulates the problem in a general setting, uses optimal friction conditions, and provides examples of solution jumps.", "result": "Proves existence of absolutely continuous solutions under certain friction conditions; shows spontaneous jumps indicate dynamic transitions.", "conclusion": "Spontaneous jumps in solutions reveal a shift from quasi-static to dynamic behavior, indicating onset of friction-induced vibrations."}}
{"id": "2508.04861", "pdf": "https://arxiv.org/pdf/2508.04861", "abs": "https://arxiv.org/abs/2508.04861", "authors": ["Henrik Dick", "Thomas Dahm"], "title": "Optimization of Ab-Initio Based Tight-Binding Models", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "16 pages, 6 figures", "summary": "The electronic structure of solids can routinely be calculated by standard\nmethods like density functional theory. However, in complicated situations like\ninterfaces, grain boundaries or contact geometries one needs to resort to more\nsimplified models of the electronic structure. Tight-binding models are using a\nreduced set of orbitals and aim to approximate the electronic structure by\nshort range hopping processes. For example, maximally localized Wannier\nfunctions are often used for that purpose. However, their accuracy is limited\nby the need to disentangle the electronic bands. Here, we develop and\ninvestigate a different procedure to obtain tight-binding models inspired by\nmachine-learning techniques. The model parameters are optimized in such a way\nas to reproduce ab-initio band structure data as accurately as possible using\nan as small as possible number of model parameters. The procedure is shown to\nresult in models with smaller ranges and fewer orbitals than maximally\nlocalized Wannier functions but same or even better accuracy. We argue that\nsuch a procedure is more useful for automated construction of tight-binding\nmodels particularly for large-scale materials calculations.", "AI": {"tldr": "The paper introduces a machine-learning-inspired method to create tight-binding models for electronic structure calculations, achieving better accuracy with fewer parameters than traditional methods like Wannier functions.", "motivation": "Traditional methods like density functional theory and Wannier functions are limited in accuracy and complexity for interfaces, grain boundaries, or contact geometries. A simpler, more accurate approach is needed.", "method": "A machine-learning-inspired procedure optimizes tight-binding model parameters to closely match ab-initio band structure data while minimizing the number of parameters.", "result": "The new method produces models with smaller ranges and fewer orbitals than Wannier functions, yet maintains or improves accuracy.", "conclusion": "This approach is more efficient for automated, large-scale materials calculations, offering a practical alternative to traditional methods."}}
{"id": "2508.05127", "pdf": "https://arxiv.org/pdf/2508.05127", "abs": "https://arxiv.org/abs/2508.05127", "authors": ["Tomohiro Tanogami", "Makoto Sasaki", "Tatsuya Kobayashi"], "title": "Information Propagation in Predator-Prey Dynamics of Turbulent Plasma", "categories": ["physics.plasm-ph", "cond-mat.stat-mech", "physics.flu-dyn"], "comment": "6 pages, 2 figures (+ supplemental material 8 pages, 2 figures)", "summary": "Magnetically confined fusion plasmas exhibit predator-prey-like cyclic\noscillations through the self-regulating interaction between drift-wave\nturbulence and zonal flow. To elucidate the detailed mechanism and causality\nunderlying this phenomenon, we construct a simple stochastic predator-prey\nmodel that incorporates intrinsic fluctuations and analyze its statistical\nproperties from an information-theoretic perspective. We first show that the\nmodel exhibits persistent fluctuating cyclic oscillations called quasi-cycles\ndue to amplification of intrinsic noise. This result suggests the possibility\nthat the previously observed periodic oscillations in a toroidal plasma are not\nlimit cycles but quasi-cycles, and that such quasi-cycles may be widely\nobserved under various conditions. For this model, we further prove that\ninformation of zonal flow is propagated to turbulence. This\ninformation-theoretic analysis may provide a theoretical basis for regulating\nturbulence by controlling zonal flow.", "AI": {"tldr": "The paper explores cyclic oscillations in fusion plasmas using a stochastic predator-prey model, suggesting observed oscillations are quasi-cycles, not limit cycles, and demonstrates information flow from zonal flow to turbulence.", "motivation": "To understand the mechanism behind cyclic oscillations in magnetically confined fusion plasmas and the interaction between drift-wave turbulence and zonal flow.", "method": "Construct a stochastic predator-prey model incorporating intrinsic fluctuations and analyze its statistical properties using information theory.", "result": "The model shows quasi-cycles due to noise amplification, suggesting observed plasma oscillations are quasi-cycles. Information flows from zonal flow to turbulence.", "conclusion": "The study provides a theoretical basis for turbulence regulation by controlling zonal flow, with quasi-cycles potentially common under various conditions."}}
{"id": "2508.05376", "pdf": "https://arxiv.org/pdf/2508.05376", "abs": "https://arxiv.org/abs/2508.05376", "authors": ["Zhengjie Sun", "Leevan Ling"], "title": "Inverse inequalities for kernel-based approximation on bounded domains and Riemannian manifolds", "categories": ["math.NA", "cs.NA", "41A17, 65D05, 65D12"], "comment": null, "summary": "This paper establishes inverse inequalities for kernel-based approximation\nspaces defined on bounded Lipschitz domains in $\\mathbb{R}^d$ and compact\nRiemannian manifolds. While inverse inequalities are well-studied for\npolynomial spaces, their extension to kernel-based trial spaces poses\nsignificant challenges. For bounded Lipschitz domains, we extend prior\nBernstein inequalities, which only apply to a limited range of Sobolev orders,\nto all orders on the lower bound and $L_2$ on the upper, and derive Nikolskii\ninequalities that bound $L_\\infty$ norms by $L_2$ norms. Our theory achieves\nthe desired form but may require slightly more smoothness on the kernel than\nthe regular $>d/2$ assumption. For compact Riemannian manifolds, we focus on\nrestricted kernels, which are defined as the restriction of positive definite\nkernels from the ambient Euclidean space to the manifold, and prove their\ncounterparts.", "AI": {"tldr": "The paper extends inverse inequalities to kernel-based approximation spaces on bounded Lipschitz domains and compact Riemannian manifolds, addressing challenges not present in polynomial spaces.", "motivation": "To generalize inverse inequalities, traditionally studied for polynomial spaces, to kernel-based trial spaces, which are less explored.", "method": "Extends Bernstein inequalities for bounded Lipschitz domains to all Sobolev orders and derives Nikolskii inequalities. For Riemannian manifolds, focuses on restricted kernels from Euclidean space.", "result": "Achieves desired inverse inequalities but may require slightly more kernel smoothness. Proves analogous results for restricted kernels on manifolds.", "conclusion": "The work successfully extends inverse inequalities to kernel-based spaces, though with potential additional smoothness requirements, and provides foundational results for manifolds."}}
{"id": "2508.05220", "pdf": "https://arxiv.org/pdf/2508.05220", "abs": "https://arxiv.org/abs/2508.05220", "authors": ["Joly Romain"], "title": "Parabolic abstract evolution equations in cylindrical domains and uniformly local Sobolev spaces", "categories": ["math.AP", "35A01, 35A02, 35K57, 35K58, 35K90, 47B12, 47D62"], "comment": null, "summary": "In this article, we consider parabolic equations of the type $$\\partial_t\nu(x,t)=\\Delta u(x,t) - Bu(x,t) + F(u(x,t))$$ where $u$ is valued in a\ntransverse Hilbert space $Y$ and $B$ is a positive self-adjoint operator on\n$Y$, allowing a different diffusion mechanism in the transverse direction. We\naim at considering solutions with infinite energy and we study the Cauchy\nproblem in the uniformly local spaces associated with the norm\n$$\\|u\\|_{L^2_{\\text{ul}}(\\mathbb{R},Y)}= \\sup_{a\\in\\mathbb{R}^d}\n\\|u(x)\\|_{L^2(B(a,1),Y)}.$$ For the classical parabolic equation, i.e. if\n$Y=\\mathbb{R}$, it is known that the Cauchy problem is ill-posed in the weak\nversion of the uniformly local spaces but well-posed in a stronger version,\nwhere additional uniform continuity is required. In this paper, we show that\nthe linear operator $\\partial^2_{xx} - B$ is not necessarily a sectorial\noperator in any version of the uniformly local Lebesgue space, due to the\npossible non-density of its domain. Then, we use the theory of parabolic\nabstract evolution equations to set a well-posed Cauchy problem, even in the\nweak version of the uniformly local space. In particular, we believe that this\npaper offers a new perspective on the comparison between both versions of the\nuniformly local spaces and also provides a new natural example of differential\noperators with non-dense domain.", "AI": {"tldr": "The paper analyzes parabolic equations with transverse Hilbert space-valued solutions, focusing on the Cauchy problem in uniformly local spaces. It highlights issues with sectoriality and domain density, proposing a well-posed solution using abstract evolution equations.", "motivation": "To study solutions with infinite energy for parabolic equations in transverse Hilbert spaces and address the ill-posedness of the Cauchy problem in uniformly local spaces.", "method": "Uses the theory of parabolic abstract evolution equations to analyze the linear operator and establish well-posedness in weak uniformly local spaces.", "result": "Shows the linear operator may not be sectorial due to non-dense domains but successfully sets a well-posed Cauchy problem.", "conclusion": "Provides insights into uniformly local spaces and introduces a new example of differential operators with non-dense domains."}}
{"id": "2508.04930", "pdf": "https://arxiv.org/pdf/2508.04930", "abs": "https://arxiv.org/abs/2508.04930", "authors": ["Cal J. Rising", "Eric J. Ching", "Ryan F. Johnson"], "title": "Simulation of Non-Premixed, Supersonic Combustion using the Discontinuous Galerkin Method on Fully Unstructured Grids", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": null, "summary": "In this study, three-dimensional simulations of a reacting hydrogen jet in\nsupersonic crossflow using a structure-preserving discontinuous Galerkin (DG)\nformulation are examined. The hydrogen jet, with a momentum flux ratio of five,\nis injected into a high enthalpy crossflow. The sensitivities of the solution\nto the grid element size and polynomial order are investigated to determine an\naccurate and computationally efficient approach to simulating high-speed\nairbreathing propulsion vehicles. The results demonstrate that DG(p = 2)\nsolutions, which are nominally third-order accurate in smooth regions of the\nflow, show reasonable agreement with existing experimental results. The\nseparation shock formation behind the jet is found to be heavily grid dependent\nand necessary for accurate simulations of the reacting jet in supersonic\ncrossflow. It is determined that the highest resolution cell and polynomial\norder is required to capture the upstream separation shock and consequently the\nflame stabilization point. The mixing and combustion mode is also determined\nusing the flame index and demonstrates the flow is heavily skewed towards a\nnon-premixed diffusion mode which is consistent with previously run simulations\nof this case using traditional finite volume schemes and sub grid scale\nmodeling approaches. Beyond this analysis, the novelty of this work lies in\ndemonstrating a high-speed, multicomponent, chemically reacting flow on a fully\nunstructured tetrahedral mesh: a first-of-its-kind calculation. This highlights\nthe potential of these methods for simulating fluids in complex geometries with\ncomplex physics", "AI": {"tldr": "3D simulations of a hydrogen jet in supersonic crossflow using DG methods show grid and polynomial order sensitivity, with DG(p=2) matching experiments. High resolution is needed for accurate shock and flame stabilization. The work pioneers unstructured tetrahedral mesh use for such flows.", "motivation": "To develop an accurate and efficient approach for simulating high-speed airbreathing propulsion vehicles using DG methods.", "method": "Structure-preserving discontinuous Galerkin (DG) formulation for 3D simulations of a reacting hydrogen jet in supersonic crossflow, examining grid and polynomial order sensitivities.", "result": "DG(p=2) agrees with experiments; high resolution captures separation shock and flame stabilization. Mixing/combustion is non-premixed diffusion mode, consistent with prior simulations.", "conclusion": "The study demonstrates DG methods' potential for complex geometries and physics, pioneering unstructured tetrahedral mesh use for high-speed reacting flows."}}
{"id": "2508.05400", "pdf": "https://arxiv.org/pdf/2508.05400", "abs": "https://arxiv.org/abs/2508.05400", "authors": ["Jean-Guillaume de Damas", "Laura Grigori"], "title": "Randomized Krylov-Schur eigensolver with deflation", "categories": ["math.NA", "cs.NA", "65F15, 65F25, 65F50, 15B52"], "comment": null, "summary": "This work introduces a novel algorithm to solve large-scale eigenvalue\nproblems and seek a small set of eigenpairs. The method, called randomized\nKrylov-Schur (rKS), has a simple implementation and benefits from fast and\nefficient operations in low-dimensional spaces, such as\nsketch-orthogonalization processes and stable reordering of Schur\nfactorizations. It also includes a practical deflation technique for converged\neigenpairs, enabling the computation of the eigenspace associated with a given\npart of the spectrum. Numerical experiments are provided to demonstrate the\nscalability and accuracy of the method.", "AI": {"tldr": "A novel algorithm, randomized Krylov-Schur (rKS), is introduced for solving large-scale eigenvalue problems efficiently, focusing on computing a small set of eigenpairs with scalability and accuracy.", "motivation": "To address the challenge of solving large-scale eigenvalue problems efficiently, especially for extracting a small set of eigenpairs, with a simple and practical approach.", "method": "The rKS algorithm leverages low-dimensional operations like sketch-orthogonalization and stable Schur reordering, along with a deflation technique for converged eigenpairs.", "result": "Numerical experiments confirm the method's scalability and accuracy in computing eigenspaces for targeted spectral regions.", "conclusion": "The rKS algorithm is an effective and practical solution for large-scale eigenvalue problems, combining simplicity with robust performance."}}
{"id": "2508.05230", "pdf": "https://arxiv.org/pdf/2508.05230", "abs": "https://arxiv.org/abs/2508.05230", "authors": ["Wentao Cao", "Jonas Hirsch", "Dominik Inauen"], "title": "Isometric Immersions and Weak Solutions to the Darboux Equation", "categories": ["math.AP", "53A05, 35J96, 53C45, 35D30"], "comment": null, "summary": "We study the Darboux equation, a fundamental PDE arising in the theory of\nisometric immersions of two-dimensional Riemannian manifolds into\n$\\mathbb{R}^3$, in the low-regularity regime. We introduce a notion of weak\nsolution for $u\\in C^{1,\\theta}$ with $\\theta>1/2$, and show that the classical\ncorrespondence between solutions of the Darboux equation and isometric\nimmersions remains valid in this regime. The key ingredient is an extension of\nthe classical flatness criterion to H\\\"older continuous metrics, achieved via\nan analysis of a weak notion of Gaussian curvature.", "AI": {"tldr": "The paper extends the Darboux equation's weak solutions to low-regularity regimes (C^{1,\u03b8}, \u03b8>1/2) and validates their correspondence with isometric immersions.", "motivation": "To address the Darboux equation in low-regularity settings, bridging gaps in the theory of isometric immersions for Riemannian manifolds.", "method": "Introduces weak solutions for C^{1,\u03b8} with \u03b8>1/2 and extends the flatness criterion to H\u00f6lder continuous metrics via weak Gaussian curvature analysis.", "result": "The classical link between Darboux equation solutions and isometric immersions holds even in low-regularity regimes.", "conclusion": "The work successfully generalizes the Darboux equation's applicability, maintaining its foundational role in isometric immersion theory."}}
{"id": "2508.05043", "pdf": "https://arxiv.org/pdf/2508.05043", "abs": "https://arxiv.org/abs/2508.05043", "authors": ["Tarun Singh", "Sandipan Paul"], "title": "Constitutive modeling of viscoelastic solids at large strains based on the theory of evolving natural configurations", "categories": ["cond-mat.soft", "physics.comp-ph"], "comment": "This article is prepared for a proposed special issue in a journal\n  which is currently under editorial review", "summary": "The theory of evolving natural configurations is an effective technique to\nmodel dissipative processes. In this paper, we use this theory to revisit\nnonlinear constitutive models of viscoelastic solids. Particularly, a Maxwell\nand a Kelvin-Voigt model and their associated standard solids, viz., a Zener\nand a Poynting-Thompson solids respectively, have been modeled within a\nLagrangian framework. We show that while a strain-space formulation of the\nevolving natural configurations is useful in modeling Maxwell-type materials, a\nstress-space formulation that incorporates a rate of dissipation function in\nterms of the relevant configurational forces is required for modeling the\nKelvin-Voigt type materials. Furthermore, we also show that the basic Maxwell\nand Kelvin-Voigt models can be obtained as limiting cases from the derived\nstandard solid models. Integration algorithms for the proposed models have been\ndeveloped and numerical solutions for a relevant boundary value problem are\nobtained. The response of the developed models have been compared and\nbenchmarked with experimental data. Specifically, the response of the novel\nPoynting-Thompson model is studied in details. This model shows a very good\nmatch with the existing experimental data obtained from a uniaxial stretching\nof polymers over a large extent of strain. The relaxation behavior and rate\neffects for the developed models have been studied.", "AI": {"tldr": "The paper revisits nonlinear viscoelastic solid models using the theory of evolving natural configurations, comparing Maxwell and Kelvin-Voigt models and their standard solids, with numerical validation against experimental data.", "motivation": "To improve modeling of dissipative processes in viscoelastic solids by leveraging the theory of evolving natural configurations.", "method": "Develops Lagrangian-based models for Maxwell and Kelvin-Voigt materials, introduces strain-space and stress-space formulations, and derives standard solid models (Zener and Poynting-Thompson). Numerical algorithms are implemented and validated.", "result": "The Poynting-Thompson model aligns well with experimental data, especially in polymer stretching. Relaxation and rate effects are analyzed.", "conclusion": "The proposed models effectively capture viscoelastic behavior, with the Poynting-Thompson model showing strong experimental agreement."}}
{"id": "2508.05407", "pdf": "https://arxiv.org/pdf/2508.05407", "abs": "https://arxiv.org/abs/2508.05407", "authors": ["Moritz Feuerle", "Richard L\u00f6scher", "Olaf Steinbach", "Karsten Urban"], "title": "A unified framework for the analysis, numerical approximation and model reduction of linear operator equations, Part I: Well-posedness in space and time", "categories": ["math.NA", "cs.NA", "35R20, 35A15, 65N12"], "comment": "linear operator equations, well-posedness, space-time variational\n  methods", "summary": "We present a unified framework to construct well-posed formulations for large\nclasses of linear operator equations including elliptic, parabolic and\nhyperbolic partial differential equations. This general approach incorporates\nknown weak variational formulations as well as novel space-time variational\nforms of the hyperbolic wave equation. The main concept is completion and\nextension of operators starting from the strong form of the problem.\n  This paper lays the theoretical foundation for a unified approach towards\nnumerical approximation methods and also model reduction of parameterized\nlinear operator equations which will be the subject of the following parts.", "AI": {"tldr": "A unified framework for well-posed formulations of linear operator equations, including PDEs, using operator completion and extension.", "motivation": "To provide a general approach for constructing well-posed formulations for various linear operator equations, including elliptic, parabolic, and hyperbolic PDEs.", "method": "Completion and extension of operators from the strong form of the problem, incorporating weak variational and novel space-time variational forms.", "result": "Theoretical foundation for unified numerical approximation and model reduction of parameterized linear operator equations.", "conclusion": "The framework supports future work on numerical methods and model reduction for linear operator equations."}}
{"id": "2508.05252", "pdf": "https://arxiv.org/pdf/2508.05252", "abs": "https://arxiv.org/abs/2508.05252", "authors": ["Kiyoshi Suzuki"], "title": "A viscosity solution as a piecewise classical solution to a free boundary problem for the optimal switching problem with simultaneous multiple switches", "categories": ["math.AP", "math.OC"], "comment": null, "summary": "\\citeN{suzuki2020optimal} proves the uniqueness of the viscosity solution to\na variational inequality which is solved by the value function of the infinite\nhorizon optimal switching problem with simultaneous multiple switchings.\nAlthough it also identifies each connected region possibly including at most\none connected switching region, the exact switching regions of the solution are\nnot identified. The problem is finally converted into a system of free boundary\nproblems and generally solved by the numerical calculation. However, if the PDE\npart of the variational inequality has a classical solution, the viscosity\nsolution may be constructed as a series of piecewise classical solutions,\npossibly analytical.\n  Under a certain assumption we prove that the series of piecewise classical\nsolutions is indeed the viscosity solution on $\\real{}$, after we prove the\nsmooth pasting condition is its necessary condition, and establish the\nalgorithm to compute all the free boundaries. Applying the results to the\nconcrete problem studied in \\citeN{suzuki2020optimal} we find the explicit\nsolution and identify the continuation and switching regions in a computer with\nPython programs.", "AI": {"tldr": "The paper extends the work of Suzuki (2020) by proving the uniqueness of viscosity solutions for a variational inequality in optimal switching problems, and provides a method to compute free boundaries and identify switching regions analytically or numerically.", "motivation": "To address the gap in Suzuki (2020) regarding the exact identification of switching regions and to provide a method for constructing viscosity solutions as piecewise classical solutions.", "method": "Proves smooth pasting as a necessary condition, establishes an algorithm for free boundaries, and applies it to a concrete problem with Python.", "result": "Explicit solutions and identification of continuation and switching regions are achieved.", "conclusion": "The series of piecewise classical solutions is confirmed as the viscosity solution, and the method is validated through practical application."}}
{"id": "2508.05217", "pdf": "https://arxiv.org/pdf/2508.05217", "abs": "https://arxiv.org/abs/2508.05217", "authors": ["Minas Kouroublakis", "Nikolaos L. Tsitsas", "Yehuda Leviatan"], "title": "A Time-Domain Method of Auxiliary Sources for Efficient Analysis of Transient Electromagnetic Scattering by Moderately Conductive Cylinders", "categories": ["physics.class-ph", "physics.comp-ph"], "comment": null, "summary": "This paper presents a time-domain implementation of the Method of Auxiliary\nSources (MAS) combined with the Standard Impedance Boundary Condition (SIBC)\nfor electromagnetic scattering problems involving cylindrical scatterers with\nfinite but moderate conductivity. The proposed approach focuses on solving the\ntwo-dimensional problem using a first-order SIBC, which is valid when the\nconductivity is sufficiently higher than the maximum spectral frequency times\nthe dielectric permittivity of the scatterer. This regime includes moderately\nconductive materials--such as carbon-based composites, conductive polymers, and\ndoped dielectrics--that are increasingly used in real-world radio-frequency\napplications, including wearable electronics, electromagnetic interference\nshielding, and biomedical sensors. Under the above validity conditions, the\ninteraction between the incident wave and the scatterer is dominated by surface\neffects, allowing for an efficient and accurate modeling strategy without the\nneed to compute internal fields. The theoretical formulation of the time-domain\nMAS-SIBC method is developed, followed by extensive numerical testing on\nvarious geometries whose cross section is a closed curve. Such geometries\ninclude circular, elliptical, super-circular, rounded-triangular, and\ninverted-elliptical scatterers. A planar geometry is also tested. All results\nare validated against analytical solutions and commercial frequency-domain\nsolvers, demonstrating the accuracy and practical potential of the proposed\nmethod. The findings suggest that time-domain MAS-SIBC offers a promising and\ncomputationally efficient approach for modeling scattering from materials even\nwith moderate conductivity.", "AI": {"tldr": "The paper introduces a time-domain MAS-SIBC method for electromagnetic scattering in moderately conductive cylindrical scatterers, validated through numerical tests.", "motivation": "To address the need for efficient modeling of scattering in moderately conductive materials (e.g., carbon-based composites, conductive polymers) used in RF applications.", "method": "Combines Method of Auxiliary Sources (MAS) with Standard Impedance Boundary Condition (SIBC) in 2D, focusing on surface effects without internal field computation.", "result": "Validated against analytical solutions and commercial solvers, showing accuracy for various scatterer geometries.", "conclusion": "Time-domain MAS-SIBC is efficient and promising for modeling scattering in moderately conductive materials."}}
{"id": "2508.05445", "pdf": "https://arxiv.org/pdf/2508.05445", "abs": "https://arxiv.org/abs/2508.05445", "authors": ["Costas Smaragdakis"], "title": "Learning Geometric-Aware Quadrature Rules for Functional Minimization", "categories": ["math.NA", "cs.LG", "cs.NA", "65D32, 65N12, 68T07"], "comment": "15 pages, 4 figures", "summary": "Accurate numerical integration over non-uniform point clouds is a challenge\nfor modern mesh-free machine learning solvers for partial differential\nequations (PDEs) using variational principles. While standard Monte Carlo (MC)\nmethods are not capable of handling a non-uniform point cloud, modern neural\nnetwork architectures can deal with permutation-invariant inputs, creating\nquadrature rules for any point cloud. In this work, we introduce QuadrANN, a\nGraph Neural Network (GNN) architecture designed to learn optimal quadrature\nweights directly from the underlying geometry of point clouds. The design of\nthe model exploits a deep message-passing scheme where the initial layer\nencodes rich local geometric features from absolute and relative positions as\nwell as an explicit local density measure. In contrast, the following layers\nincorporate a global context vector. These architectural choices allow the\nQuadrANN to generate a data-driven quadrature rule that is\npermutation-invariant and adaptive to both local point density and the overall\ndomain shape. We test our methodology on a series of challenging test cases,\nincluding integration on convex and non-convex domains and estimating the\nsolution of the Heat and Fokker-Planck equations. Across all the tests,\nQuadrANN reduces the variance of the integral estimation compared to standard\nQuasi-Monte Carlo methods by warping the point clouds to be more dense in\ncritical areas where the integrands present certain singularities. This\nenhanced stability in critical areas of the domain at hand is critical for the\noptimization of energy functionals, leading to improved deep learning-based\nvariational solvers.", "AI": {"tldr": "QuadrANN, a GNN architecture, learns optimal quadrature weights for non-uniform point clouds, improving integration accuracy for PDE solvers.", "motivation": "Accurate numerical integration over non-uniform point clouds is challenging for mesh-free PDE solvers, requiring adaptive and permutation-invariant methods.", "method": "QuadrANN uses a deep message-passing GNN to encode local geometric features and global context, generating data-driven quadrature rules.", "result": "QuadrANN reduces variance in integral estimation compared to Quasi-Monte Carlo, especially in critical areas with singularities.", "conclusion": "QuadrANN enhances stability in integration, benefiting deep learning-based variational solvers for PDEs."}}
{"id": "2508.05324", "pdf": "https://arxiv.org/pdf/2508.05324", "abs": "https://arxiv.org/abs/2508.05324", "authors": ["Stefano Bianchini", "Martina Zizza"], "title": "Existence of spiral strategies for blocking fire spreading", "categories": ["math.AP"], "comment": null, "summary": "In this paper we address the problem for blocking fire by constructing a wall\n$\\zeta$ whose shape is spiral-like. This is supposed to be the best strategy\nwhen a single firefighter is constructing the wall with a finite construction\nspeed $\\sigma$: the barriers which satisfy this bound on the construction speed\nare called admissible.\n  We prove a sharp version of Bressan's Fire Conjecture in this case, i.e. when\nadmissible barriers are spiral-like curves: namely, there exists a spiral-like\nbarrier confining the fire in a bounded region of $\\mathbb R^2$ if and only if\nthe speed of construction of the barrier $\\sigma$ is strictly larger than a\ncritical speed $\\bar \\sigma = 2.614...$.\n  The existence of confining spiral barriers for $\\sigma > \\bar \\sigma$ is\nalready known [Bressan A. et al., 2008, Klein R. et al., 2019], while we\nconcentrate on the negative side, i.e. if $\\sigma \\leq \\bar \\sigma$ no\nadmissible spiral blocks the fire.\n  The proof of these results relies on: 1) the precise definition of spiral\nbarrier and its representation; 2) the analysis of saturated spiral barriers as\na Retarded Differential Equation (RDE) in the spirit of [Klein R. et al.,\n2019]; 3) the equivalent reformulation of the conjecture as a minimum problem\nfor a prescribed functional; 4) the construction of the optimal closing spiral;\n5) the analysis of a differentiable path of admissible spirals along which the\nfunctional is differentiable, and in particular increasing when moving from the\noptimal spiral to any other one (homotopy argument).\n  Due to the complexity of the solution, the evaluation of the quantities\nneeded to prove that the functional is increasing is performed numerically.", "AI": {"tldr": "The paper proves a sharp version of Bressan's Fire Conjecture for spiral-like barriers, showing confinement is possible only if construction speed exceeds a critical value.", "motivation": "To determine the minimal construction speed for a spiral-like barrier to block a fire, addressing Bressan's Fire Conjecture.", "method": "Uses spiral barrier definitions, Retarded Differential Equations, functional minimization, and numerical analysis.", "result": "Confinement is possible if construction speed \u03c3 > critical speed \u03c3\u0304 = 2.614; otherwise, it fails.", "conclusion": "The critical speed \u03c3\u0304 is the threshold for effective fire confinement using spiral barriers."}}
{"id": "2508.05247", "pdf": "https://arxiv.org/pdf/2508.05247", "abs": "https://arxiv.org/abs/2508.05247", "authors": ["Max Gro\u00dfmann", "Marc Thieme", "Malte Grunert", "Erich Runge"], "title": "Many-body perturbation theory vs. density functional theory: A systematic benchmark for band gaps of solids", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "We benchmark many-body perturbation theory against density functional theory\n(DFT) for the band gaps of solids. We systematically compare four $GW$ variants\n$-$ $G_{0}W_{0}$ using the Godby-Needs plasmon-pole approximation\n($G_{0}W_{0}$-PPA), full-frequency quasiparticle $G_{0}W_{0}$ (QP$G_{0}W_{0}$),\nfull-frequency quasiparticle self-consistent $GW$ (QS$GW$), and QS$GW$\naugmented with vertex corrections in $W$ (QS$G\\hat{W}$) $-$ against the\ncurrently best performing and popular density functionals mBJ and HSE06. Our\nresults show that $G_{0}W_{0}$-PPA calculations offer only a marginal accuracy\ngain over the best DFT methods, however at a higher cost. Replacing the PPA\nwith a full-frequency integration of the dielectric screening improves the\npredictions dramatically, almost matching the accuracy of the QS$G\\hat{W}$. The\nQS$GW$ removes starting-point bias, but systematically overestimates\nexperimental gaps by about $15\\%$. Adding vertex corrections to the screened\nCoulomb interaction, i.e., performing a QS$G\\hat{W}$ calculation, eliminates\nthe overestimation, producing band gaps that are so accurate that they even\nreliably flag questionable experimental measurements.", "AI": {"tldr": "The paper benchmarks many-body perturbation theory (GW methods) against DFT for band gaps of solids, showing QSG\u0174 as the most accurate method.", "motivation": "To compare the accuracy and cost of GW variants and DFT methods for predicting band gaps in solids.", "method": "Systematic comparison of four GW variants (G0W0-PPA, QPG0W0, QSGW, QSG\u0174) against DFT methods (mBJ, HSE06).", "result": "QSG\u0174 is highly accurate, correcting overestimations in QSGW and flagging questionable experimental data. G0W0-PPA offers marginal improvement over DFT at higher cost.", "conclusion": "Full-frequency GW methods, especially QSG\u0174, outperform DFT and simpler GW variants for band gap predictions."}}
{"id": "2508.05564", "pdf": "https://arxiv.org/pdf/2508.05564", "abs": "https://arxiv.org/abs/2508.05564", "authors": ["Dominic Breit", "Andreas Prohl", "J\u00f6rn Wichman"], "title": "Numerical analysis of the stochastic Navier-Stokes equations", "categories": ["math.NA", "cs.NA", "math.AP", "math.PR"], "comment": null, "summary": "The developments over the last five decades concerning numerical\ndiscretisations of the incompressible Navier--Stokes equations have lead to\nreliable tools for their approximation: those include stable methods to\nproperly address the incompressibility constraint, stable discretisations to\naccount for convection dominated problems, efficient time (splitting) methods,\nand methods to tackle their nonlinear character. While these tools may\nsuccessfully be applied to reliably simulate even more complex fluid flow PDE\nmodels, their understanding requires a fundamental revision in the case of\nstochastic fluid models, which are gaining increased importance nowadays.\n  This work motivates and surveys optimally convergent numerical methods for\nthe stochastic Stokes and Navier--Stokes equations that were obtained in the\nlast decades. Furtheremore, we computationally illustrate the failure of some\nof those methods from the deterministic setting, if they are straight-forwardly\napplied to the stochastic case. In fact, we explain why some of these\ndeterministic methods perform sub-optimally by highlighting crucial analytical\ndifferences between the deterministic and stochastic equations -- and how\nmodifications of the deterministic methods restore their optimal performance if\nthey properly address the probabilistic nature of the stochastic problem.\n  Next to the numerical analysis of schemes, we propose a general benchmark of\nprototypic fluid flow problems driven by different types of noise to also\ncompare new algorithms by simulations in terms of complexities, efficiencies,\nand possible limitations. The driving motivation is to reach a better\ncomparison of simulations for new schemes in terms of accuracy and\ncomplexities, and to also complement theoretical performance studies for\nrestricted settings of data by more realistic ones.", "AI": {"tldr": "The paper surveys optimally convergent numerical methods for stochastic Stokes and Navier--Stokes equations, highlighting differences from deterministic methods and proposing benchmarks for new algorithms.", "motivation": "To address the need for reliable numerical methods for stochastic fluid models, which differ fundamentally from deterministic ones, and to provide benchmarks for comparing new algorithms.", "method": "Surveys and analyzes numerical methods for stochastic fluid equations, compares deterministic and stochastic approaches, and proposes computational benchmarks.", "result": "Identifies sub-optimal performance of deterministic methods in stochastic settings and suggests modifications to restore optimality. Introduces benchmarks for evaluating new algorithms.", "conclusion": "The study emphasizes the importance of adapting deterministic methods for stochastic problems and provides tools for comparing and improving numerical schemes in realistic settings."}}
{"id": "2508.05401", "pdf": "https://arxiv.org/pdf/2508.05401", "abs": "https://arxiv.org/abs/2508.05401", "authors": ["Huaian Diao", "Xiaoxu Fei", "Hongyu Liu"], "title": "Geometrical characterizations of radiating and non-radiating elastic sources and mediums with applications", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we investigate two types of time-harmonic elastic wave\nscattering problems. The first one involves the scattered wave generated by an\nactive elastic source with compact support. The second one concerns elastic\nwave scattering caused by an inhomogeneous medium, also with compact support.\nWe derive several novel quantitative results concerning the geometrical\nproperties of the underlying scatterer, the associated source or incident wave\nfield, and the physical parameters. In particular, we show that a scatterer\nwith either a small support or high-curvature boundary points must radiate at\nany frequency. These qualitative characterizations allow us to establish\nseveral local and global uniqueness results for determining the support of the\nsource or medium scatterer from a single far-field measurement. Furthermore, we\nreveal new geometric properties of elastic transmission eigenfunctions. To\nderive a quantitative relationship between the intensity of a radiating or\nnon-radiating source and the diameter of its support, we utilize the Helmholtz\ndecomposition, the translation-invariant $L^2$-norm estimate for the Lam\\'e\noperator, and global energy estimates. Another pivotal technical approach\ncombines complex geometric optics (CGO) solutions with local regularity\nestimates, facilitating microlocal analysis near admissible $K$-curvature\nboundary points.", "AI": {"tldr": "The paper investigates two types of time-harmonic elastic wave scattering problems, deriving quantitative results about scatterer geometry and physical parameters. It shows that certain scatterers must radiate at any frequency and establishes uniqueness results for determining scatterer support from far-field measurements.", "motivation": "To understand the geometric and physical properties of scatterers in elastic wave problems and derive uniqueness results for their identification.", "method": "Uses Helmholtz decomposition, Lam\u00e9 operator estimates, global energy estimates, and combines complex geometric optics (CGO) solutions with local regularity estimates.", "result": "Demonstrates that scatterers with small support or high-curvature boundaries radiate at any frequency, and establishes local/global uniqueness results for scatterer identification.", "conclusion": "The study provides new insights into elastic wave scattering, enabling unique identification of scatterers and revealing geometric properties of transmission eigenfunctions."}}
{"id": "2508.05333", "pdf": "https://arxiv.org/pdf/2508.05333", "abs": "https://arxiv.org/abs/2508.05333", "authors": ["Felix Binkowski", "Aris Koulas-Simos", "Fridtjof Betz", "Matthias Plock", "Ivan Sekulic", "Phillip Manley", "Martin Hammerschmidt", "Philipp-Immanuel Schneider", "Lin Zschiedrich", "Battulga Munkhbat", "Stephan Reitzenstein", "Sven Burger"], "title": "High Purcell enhancement in all-TMDC nanobeam resonator designs with optically active monolayers for nanolasers", "categories": ["physics.optics", "cond-mat.mes-hall", "physics.comp-ph"], "comment": null, "summary": "We propose a nanobeam resonator incorporating an optically active monolayer,\ndesigned to achieve a high Purcell enhancement. The resonator is fully composed\nof transition metal dichalcogenide (TMDC) materials and intended to operate as\na high-beta-factor nanolaser. A theoretical framework that models and optimizes\nthe Purcell enhancement associated with the emission from atomically thin\nlayers is developed. This framework is based on a resonance expansion, enabling\nspectral resolution of physical quantities governed by high-Q resonances. The\nnumerical optimization of the resonator leads to the presence of a high-Q\nresonance supporting a strong electric field confinement in the monolayer to\nmaximize the modal gain.", "AI": {"tldr": "A nanobeam resonator with an optically active monolayer achieves high Purcell enhancement, optimized for high-beta-factor nanolaser operation using TMDC materials.", "motivation": "To enhance light-matter interaction in atomically thin layers for efficient nanolaser applications.", "method": "Developed a theoretical framework using resonance expansion to model and optimize Purcell enhancement, focusing on high-Q resonances for electric field confinement.", "result": "Numerical optimization revealed a high-Q resonance enabling strong electric field confinement in the monolayer, maximizing modal gain.", "conclusion": "The proposed resonator design and framework effectively enhance light emission in TMDC monolayers, suitable for high-performance nanolasers."}}
{"id": "2508.04853", "pdf": "https://arxiv.org/pdf/2508.04853", "abs": "https://arxiv.org/abs/2508.04853", "authors": ["Haoyu Zhang", "Shihao Zhang", "Ian Colbert", "Rayan Saab"], "title": "Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.NA", "math.IT", "math.NA", "68T07, 68W25, 62M45, 68Q25"], "comment": null, "summary": "Post-training quantization (PTQ) has become a crucial tool for reducing the\nmemory and compute costs of modern deep neural networks, including large\nlanguage models (LLMs). Among PTQ algorithms, the OPTQ framework-also known as\nGPTQ-has emerged as a leading method due to its computational efficiency and\nstrong empirical performance. Despite its widespread adoption, however, OPTQ\nlacks rigorous quantitative theoretical guarantees. This paper presents the\nfirst quantitative error bounds for both deterministic and stochastic variants\nof OPTQ, as well as for Qronos, a recent related state-of-the-art PTQ\nalgorithm. We analyze how OPTQ's iterative procedure induces quantization error\nand derive non-asymptotic 2-norm error bounds that depend explicitly on the\ncalibration data and a regularization parameter that OPTQ uses. Our analysis\nprovides theoretical justification for several practical design choices,\nincluding the widely used heuristic of ordering features by decreasing norm, as\nwell as guidance for selecting the regularization parameter. For the stochastic\nvariant, we establish stronger infinity-norm error bounds, which enable control\nover the required quantization alphabet and are particularly useful for\ndownstream layers and nonlinearities. Finally, we extend our analysis to\nQronos, providing new theoretical bounds, for both its deterministic and\nstochastic variants, that help explain its empirical advantages.", "AI": {"tldr": "The paper provides the first quantitative error bounds for OPTQ (GPTQ) and Qronos, analyzing their iterative quantization errors and offering theoretical justification for practical design choices.", "motivation": "Despite OPTQ's widespread use in PTQ for deep neural networks, it lacks rigorous theoretical guarantees. This paper aims to fill that gap.", "method": "The authors derive non-asymptotic 2-norm error bounds for deterministic and stochastic OPTQ variants, and extend the analysis to Qronos.", "result": "The analysis justifies practical heuristics (e.g., feature ordering by norm) and provides guidance for parameter selection. Stronger infinity-norm bounds are established for stochastic OPTQ.", "conclusion": "The paper enhances understanding of OPTQ and Qronos, offering theoretical insights that support their empirical success and practical use."}}
{"id": "2508.05478", "pdf": "https://arxiv.org/pdf/2508.05478", "abs": "https://arxiv.org/abs/2508.05478", "authors": ["Alina Chertock", "Roman Shvydkoy", "Trevor Teolis"], "title": "Modulation of the Monokinetic Limit for Models of Collective Dynamics", "categories": ["math.AP", "cs.NA", "math.NA", "37A60, 92D50"], "comment": null, "summary": "In this work, we perform modulation analysis of monokinetic limits from the\nkinetic Cucker- Smale model to the pressureless Euler alignment system. Two\nregimes are considered -- a strong Fokker- Planck force with vanishing noise\nand Knudsen number, and a pure noiseless Vlasov scheme. In the former case, we\ndemonstrate convergence of the modulated profile to the standard Gaussian\ndistribution, while in the latter case, the distribution converges to a profile\nsatisfying an explicit transport equation along limiting characteristics.", "AI": {"tldr": "The paper analyzes monokinetic limits in the kinetic Cucker-Smale model, comparing two regimes: strong Fokker-Planck force with vanishing noise and a noiseless Vlasov scheme. Results show convergence to Gaussian and transport equation profiles, respectively.", "motivation": "To understand the transition from kinetic models to macroscopic systems, specifically focusing on the Cucker-Smale model's monokinetic limits.", "method": "Modulation analysis is applied to two regimes: (1) strong Fokker-Planck force with vanishing noise and Knudsen number, and (2) a pure noiseless Vlasov scheme.", "result": "In the first regime, the modulated profile converges to a Gaussian distribution. In the second, it converges to a profile satisfying an explicit transport equation.", "conclusion": "The study successfully links kinetic models to macroscopic systems, providing insights into convergence behaviors under different conditions."}}
{"id": "2508.05345", "pdf": "https://arxiv.org/pdf/2508.05345", "abs": "https://arxiv.org/abs/2508.05345", "authors": ["Pravan Omprakash", "Gwan Yeong Jung", "Guodong Ren", "Rohan Mishra"], "title": "Hole-doping reduces the coercive field in ferroelectric hafnia", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Ferroelectric hafnia holds promise for next-generation memory and logic\napplications because of its CMOS compatibility. However, the high coercive\nfield required for polarization switching in hafnia remains a critical\nchallenge for efficient device operations. Using first-principles calculations\nand phenomenological modeling, we predict that hole doping can reduce the\ncoercive field from 8 MV/cm in undoped hafnia to 6 MV/cm in hafnia doped with\n0.2 holes per formula unit (f.u.). In the absence of doping, the reversal of\npolarization of the Pca21 phase is preferred through the non-polar, tetragonal\nP42/nmc phase. This switching pathway involves the coupling of three hard\ndistortion modes that render undoped hafnia as an improper ferroelectric. The\noverall energy barrier through this pathway remains unchanged (80 meV/f.u.)\nupon hole doping. However, the introduction of holes hardens the polar\ndistortion mode that connects the polar Pca21 phase to the non-polar,\northorhombic Pbcm phase, and reduces the energy barrier from 180 meV/f.u. in\nundoped hafnia to 80 meV/f.u. at 0.2 holes/f.u.. Overall, hole doping makes the\nlatter switching pathway through the Pbcm phase competitive, and renders hafnia\nas a proper ferroelectric with a lower coercive field.", "AI": {"tldr": "Hole doping in ferroelectric hafnia reduces the coercive field, making it more efficient for memory and logic applications.", "motivation": "The high coercive field in hafnia hinders efficient device operations, prompting exploration of doping to lower it.", "method": "First-principles calculations and phenomenological modeling were used to study the effects of hole doping on hafnia.", "result": "Hole doping reduces the coercive field from 8 MV/cm to 6 MV/cm and alters the polarization switching pathway.", "conclusion": "Hole doping transforms hafnia into a proper ferroelectric with a lower coercive field, enhancing its device potential."}}
{"id": "2508.04917", "pdf": "https://arxiv.org/pdf/2508.04917", "abs": "https://arxiv.org/abs/2508.04917", "authors": ["Atharva Gondhalekar", "Kjetil Haugen", "Thomas Gibson", "Wu-chun Feng"], "title": "Mapping Sparse Triangular Solves to GPUs via Fine-grained Domain Decomposition", "categories": ["cs.PF", "cs.NA", "math.NA", "G.1.3; D.1.3"], "comment": "14 pages, 14 figures", "summary": "Sparse linear systems are typically solved using preconditioned iterative\nmethods, but applying preconditioners via sparse triangular solves introduces\nbottlenecks due to irregular memory accesses and data dependencies. This work\nleverages fine-grained domain decomposition to adapt triangular solves to the\nGPU architecture. We develop a fine-grained domain decomposition strategy that\ngenerates non-overlapping subdomains, increasing parallelism in the application\nof preconditioner at the expense of a modest increase in the iteration count\nfor convergence. Each subdomain is assigned to a thread block and is sized such\nthat the subdomain vector fits in the GPU shared memory, eliminating the need\nfor inter-block synchronization and reducing irregular global memory accesses.\nCompared to other state-of-the-art implementations using the ROCm$^{\\text{TM}}$\nsoftware stack, we achieve a 10.7$\\times$ speedup for triangular solves and a\n3.2$\\times$ speedup for the ILU0-preconditioned biconjugate gradient stabilized\n(BiCGSTAB) solver on the AMD Instinct$^{\\text{TM}}$ MI210 GPU.", "AI": {"tldr": "The paper proposes a fine-grained domain decomposition method to optimize sparse triangular solves on GPUs, improving parallelism and reducing memory bottlenecks.", "motivation": "Sparse triangular solves in preconditioned iterative methods cause performance bottlenecks due to irregular memory access and dependencies on GPUs.", "method": "A fine-grained domain decomposition strategy creates non-overlapping subdomains, each handled by a thread block, fitting in GPU shared memory to reduce global memory access and synchronization.", "result": "Achieves a 10.7\u00d7 speedup for triangular solves and 3.2\u00d7 speedup for ILU0-preconditioned BiCGSTAB on AMD MI210 GPU.", "conclusion": "The method effectively adapts triangular solves to GPU architecture, balancing parallelism and convergence efficiency."}}
{"id": "2508.05481", "pdf": "https://arxiv.org/pdf/2508.05481", "abs": "https://arxiv.org/abs/2508.05481", "authors": ["Gilles A. Francfort", "Alessandro Giacomini", "Scott Weady"], "title": "Velocity optimization of self-equilibrated obstacles in a two-dimensional viscous flow", "categories": ["math.AP"], "comment": null, "summary": "An obstacle is immersed in an externally driven 2D Stokes or Navier-Stokes\nfluid. We study the self-equilibration conditions for that obstacle under\nsteady state assumptions on the flow. We then seek to optimize the\ntranslational and/or angular velocity of the obstacle by varying its shape. To\nallow general variations, we must consider a very large class of obstacles for\nwhich the notion of trace is meaningless. This forces us to revisit the notion\nof self-equilibration for both Stokes and Navier-Stokes in a measure theoretic\nenvironment.", "AI": {"tldr": "Study of self-equilibration and shape optimization for obstacles in 2D Stokes/Navier-Stokes fluids under steady-state conditions.", "motivation": "To understand and optimize obstacle behavior in fluid dynamics, addressing challenges in defining equilibration for a broad class of obstacles.", "method": "Revisits self-equilibration in measure-theoretic terms for Stokes and Navier-Stokes fluids, allowing general shape variations.", "result": "Framework for analyzing and optimizing obstacle velocities (translational/angular) by shape variation.", "conclusion": "Provides a theoretical foundation for optimizing obstacle dynamics in complex fluid environments."}}
{"id": "2508.05528", "pdf": "https://arxiv.org/pdf/2508.05528", "abs": "https://arxiv.org/abs/2508.05528", "authors": ["James F. Lutsko"], "title": "The use of open boundaries in stochastic hydrodynamic models of nucleation", "categories": ["cond-mat.stat-mech", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Stochastic hydrodynamics is a central tool in the study of first order phase\ntransitions at a fundamental level. Combined with sophisticated free energy\nmodels, e.g. as developed in classical Density Functional Theory, complex\nprocesses such as crystallization can be modeled and information such as free\nenergy barriers, nucleation pathways and the unstable eigenvector and\neigenvalues determined. The latter are particularly interesting as they play\nkey roles in defining the natural (unbiased) order parameter and the nucleation\nrate respectively. As is often the case, computational realities restrict the\nsize of system that can be modeled and this makes it difficult to achieve\nexperimental conditions for which the volume is effectively infinite. In this\npaper, the use of open boundary conditions is discussed. By using an open\nsystem, the calculations become much closer to experimental conditions however,\nthe introduction of open boundary conditions raises a number of questions\nconcerning the stochastic model such as whether the fluctuation-dissipation\nrelation is preserved and whether stationary points on the free energy surface\nremain stationary points of the dynamics.", "AI": {"tldr": "The paper explores stochastic hydrodynamics for modeling first-order phase transitions, focusing on open boundary conditions to better match experimental conditions, while addressing challenges like preserving fluctuation-dissipation relations and dynamic stability.", "motivation": "To bridge the gap between computational models and experimental conditions by using open boundary conditions in stochastic hydrodynamics, despite potential issues with the fluctuation-dissipation relation and dynamic stability.", "method": "Utilizes stochastic hydrodynamics combined with free energy models (e.g., Density Functional Theory) and introduces open boundary conditions to simulate infinite-volume systems.", "result": "Open boundary conditions bring computational models closer to experimental conditions but raise questions about the stochastic model's integrity, such as the preservation of fluctuation-dissipation relations and dynamic stability.", "conclusion": "Open boundary conditions are promising for aligning simulations with experiments but require careful consideration of their impact on stochastic models and dynamic properties."}}
{"id": "2508.05141", "pdf": "https://arxiv.org/pdf/2508.05141", "abs": "https://arxiv.org/abs/2508.05141", "authors": ["Yahong Yang", "Juncai He"], "title": "Deep Neural Networks with General Activations: Super-Convergence in Sobolev Norms", "categories": ["cs.LG", "cs.NA", "math.NA", "68T07, 41A30, 35Q68", "F.1.1; G.1.2; I.2.6"], "comment": "45 pages, 4 figures", "summary": "This paper establishes a comprehensive approximation result for deep\nfully-connected neural networks with commonly-used and general activation\nfunctions in Sobolev spaces $W^{n,\\infty}$, with errors measured in the\n$W^{m,p}$-norm for $m < n$ and $1\\le p \\le \\infty$. The derived rates surpass\nthose of classical numerical approximation techniques, such as finite element\nand spectral methods, exhibiting a phenomenon we refer to as\n\\emph{super-convergence}. Our analysis shows that deep networks with general\nactivations can approximate weak solutions of partial differential equations\n(PDEs) with superior accuracy compared to traditional numerical methods at the\napproximation level. Furthermore, this work closes a significant gap in the\nerror-estimation theory for neural-network-based approaches to PDEs, offering a\nunified theoretical foundation for their use in scientific computing.", "AI": {"tldr": "Deep neural networks with general activations achieve superior approximation rates in Sobolev spaces, outperforming classical methods like finite elements and spectral methods, termed as 'super-convergence.'", "motivation": "To bridge the gap in error-estimation theory for neural-network-based PDE solutions and provide a unified theoretical foundation for their use in scientific computing.", "method": "Analysis of deep fully-connected neural networks with general activation functions in Sobolev spaces, measuring errors in the $W^{m,p}$-norm for $m < n$.", "result": "Deep networks surpass classical numerical methods in approximating weak PDE solutions, demonstrating 'super-convergence.'", "conclusion": "This work establishes a comprehensive theoretical foundation for neural networks in PDE approximation, highlighting their superior accuracy over traditional methods."}}
{"id": "2508.05533", "pdf": "https://arxiv.org/pdf/2508.05533", "abs": "https://arxiv.org/abs/2508.05533", "authors": ["Han Cheng", "Shanlin Huang", "Avy Soffer", "Zhao Wu"], "title": "The $L^p$ boundedness of wave operators for the Laplace operator with finite rank perturbations", "categories": ["math.AP", "math.CA"], "comment": "33 pages", "summary": "This paper investigates the $L^p$ boundedness of wave operators for the\nLaplace operator with finite rank perturbations \\begin{equation*}\n  H=-\\Delta+\\sum\\limits_{i=1}^N\\langle\\cdot\\,, \\varphi_i\\rangle \\varphi_i\n\\qquad \\mbox{on}\\,\\,\\, \\R^d. \\end{equation*} For dimensions $d\\ge 3$, we prove\nthat the wave operators $W_\\pm(H,H_0)$ are bounded on $L^p$ for the full range\n$1\\le p\\le \\infty$. This extends the work of Nier and the third author\n\\cite{NS} by resolving the previously unexplored question of boundedness at the\nendpoint cases $p=1$ and $p=\\infty$. In lower dimensions $d = 1, 2$, we\nestablish the $L^p$-boundedness of the wave operators for the first time.\nFurthermore, we reveal an intriguing dichotomy in the endpoint case $p = 1$:\n\\begin{itemize}\n  \\item If $\\int_{\\mathbb{R}^d} \\varphi_i(x) \\, \\d x = 0$ holds for every $1\\le\ni\\le N$, then the wave operators are bounded on $L^p(\\mathbb{R}^d)$ for all $1\n\\leq p \\leq \\infty$.\n  \\item If there exists at least one $i$ ($1\\le i\\le N$) such that\n$\\int_{\\mathbb{R}^d}\\varphi_i(x)\\d x\\ne0$, then the wave operators remain\nbounded for $1 < p < \\infty$ and satisfy weak type $(1,1)$ estimates, but fail\nto be bounded on $L^1(\\mathbb{R}^d)$. \\end{itemize}", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.05538", "pdf": "https://arxiv.org/pdf/2508.05538", "abs": "https://arxiv.org/abs/2508.05538", "authors": ["Junpei Oba", "Hsin-Pin Lo", "Yasuhiro Yamada", "Takayuki Matsui", "Takuya Ikuta", "Yuya Yonezu", "Toshimori Honjo", "Seiji Kajita", "Hiroki Takesue"], "title": "Model-based framework for automated quantification of error sources in quantum state tomography", "categories": ["quant-ph", "physics.comp-ph", "physics.optics"], "comment": "18 pages, 12 figures, 3 tables", "summary": "High-quality quantum state generation is essential for advanced quantum\ninformation processing, including quantum communication, quantum sensing, and\nquantum computing. In practice, various error sources degrade the quality of\nquantum states, and quantum state tomography (QST) is a standard diagnostic\ntool. However, in QST, multiple error sources gather in a single density\nmatrix, making it difficult to identify individual error sources. To address\nthis problem, we propose an automated method for quantifying error sources by\ncombining simulation and parameter optimization to reproduce the experimental\ndensity matrix. We focus on the experimental generation of time-bin entangled\nphoton pairs, for which we model the relevant error sources and simulate the\ndensity matrix with adjustable model parameters, thereby optimizing the\nparameters and minimizing the trace distance to the experimental data.\nOptimization of the parameters reduced the trace distance from 0.177 to 0.024,\nindicating that our modeled error sources explain 86% of the errors. Reducing\nthe predicted error sources improves the state quality, consistent with our\npredictions and thus validating the proposed method. In addition, the modular\nstructure of this framework makes it applicable to other quantum platforms,\nsuch as superconducting qubits, atoms, and solid-state spins.", "AI": {"tldr": "Proposes an automated method to quantify error sources in quantum state generation by combining simulation and parameter optimization, improving state quality and validating the approach.", "motivation": "High-quality quantum states are crucial for quantum information processing, but error sources degrade quality. Current QST methods struggle to identify individual errors.", "method": "Combines simulation and parameter optimization to model error sources and reproduce experimental density matrices, focusing on time-bin entangled photon pairs.", "result": "Reduced trace distance from 0.177 to 0.024, explaining 86% of errors, and improved state quality validated the method.", "conclusion": "The framework is effective for identifying and mitigating errors in quantum state generation and is adaptable to other quantum platforms."}}
{"id": "2508.05551", "pdf": "https://arxiv.org/pdf/2508.05551", "abs": "https://arxiv.org/abs/2508.05551", "authors": ["Tristan C. Collins", "Benjy Firester"], "title": "On a general class of free boundary Monge-Amp\u00e8re equations", "categories": ["math.AP", "math.DG"], "comment": null, "summary": "We solve a general class of free boundary Monge-Amp\\`ere equations given by\n\\[\n  \\det D^2u = \\lambda \\dfrac{f(-u)}{g(u^\\star)h(\\nabla u)}\\chi_{\\{u<0\\}} \\;\n\\text{ in } \\mathbb{R}^n, \\quad \\nabla u (\\mathbb{R}^n) = P \\] where $P$ is a\nbounded convex set containing the origin, and $h>0$ on $P$. We consider\napplications to optimal transport with degenerate densities, Monge-Amp\\`ere\neigenvalue problems, and geometric problems including a hemispherical Minkowski\nproblem and free boundary K\\\"ahler-Ricci solitons on toric Fano manifolds.", "AI": {"tldr": "The paper addresses a general class of free boundary Monge-Amp\u00e8re equations, with applications in optimal transport, eigenvalue problems, and geometric problems.", "motivation": "To solve complex Monge-Amp\u00e8re equations with free boundaries, extending applications to diverse mathematical problems.", "method": "Analyzes the equation involving determinants and gradients, with constraints on the domain and function properties.", "result": "Provides solutions to the equations, applicable to optimal transport, eigenvalue problems, and geometric scenarios.", "conclusion": "The framework extends the understanding and solvability of Monge-Amp\u00e8re equations in various mathematical contexts."}}
{"id": "2508.05619", "pdf": "https://arxiv.org/pdf/2508.05619", "abs": "https://arxiv.org/abs/2508.05619", "authors": ["Bo Wen"], "title": "The Missing Reward: Active Inference in the Era of Experience", "categories": ["cs.AI", "nlin.AO", "physics.bio-ph", "physics.comp-ph", "physics.hist-ph"], "comment": null, "summary": "This paper argues that Active Inference (AIF) provides a crucial foundation\nfor developing autonomous AI agents capable of learning from experience without\ncontinuous human reward engineering. As AI systems begin to exhaust\nhigh-quality training data and rely on increasingly large human workforces for\nreward design, the current paradigm faces significant scalability challenges\nthat could impede progress toward genuinely autonomous intelligence. The\nproposal for an ``Era of Experience,'' where agents learn from self-generated\ndata, is a promising step forward. However, this vision still depends on\nextensive human engineering of reward functions, effectively shifting the\nbottleneck from data curation to reward curation. This highlights what we\nidentify as the \\textbf{grounded-agency gap}: the inability of contemporary AI\nsystems to autonomously formulate, adapt, and pursue objectives in response to\nchanging circumstances. We propose that AIF can bridge this gap by replacing\nexternal reward signals with an intrinsic drive to minimize free energy,\nallowing agents to naturally balance exploration and exploitation through a\nunified Bayesian objective. By integrating Large Language Models as generative\nworld models with AIF's principled decision-making framework, we can create\nagents that learn efficiently from experience while remaining aligned with\nhuman values. This synthesis offers a compelling path toward AI systems that\ncan develop autonomously while adhering to both computational and physical\nconstraints.", "AI": {"tldr": "Active Inference (AIF) offers a foundation for autonomous AI agents to learn from experience without human reward engineering, addressing scalability challenges in current paradigms.", "motivation": "Current AI systems face scalability issues due to reliance on human reward engineering and high-quality training data, hindering autonomous intelligence.", "method": "Proposes using AIF to replace external rewards with an intrinsic drive to minimize free energy, integrating Large Language Models as generative world models.", "result": "AIF enables agents to autonomously balance exploration and exploitation, learning efficiently while aligning with human values.", "conclusion": "AIF bridges the grounded-agency gap, offering a path to autonomous AI development within computational and physical constraints."}}
{"id": "2508.05573", "pdf": "https://arxiv.org/pdf/2508.05573", "abs": "https://arxiv.org/abs/2508.05573", "authors": ["Pierre Germain", "Simon L. Rydin Myerson", "Daniel Pezzi"], "title": "Bounds for spectral projectors on the three-dimensional torus", "categories": ["math.AP", "math.CA", "42A45, 42B15 (Primary), 11L07, 11H06, 11P21 (Secondary)"], "comment": "51 pages, 1 figure", "summary": "We study $L^2$ to $L^p$ operator norms of spectral projectors for the\nEuclidean Laplacian on the torus in the case where the spectral window is\nnarrow. With a window of constant size this is a classical result of Sogge; in\nthe small-window limit we are left with $L^p$ norms of eigenfunctions of the\nLaplacian, as considered for instance by Bourgain. For the three-dimensional\ntorus we prove new cases of a previous conjecture of the first two authors\nconcerning the size of these norms; we also refine certain prior results to\nremove $\\epsilon$-losses in all dimensions. We use methods from number theory:\nthe geometry of numbers, the circle method and exponential sum bounds due to\nGuo. We complement these techniques with height splitting and a bilinear\nargument to prove sharp results.\n  We exposit on the various techniques used and their limitations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
