{"id": "2508.04926", "pdf": "https://arxiv.org/pdf/2508.04926", "abs": "https://arxiv.org/abs/2508.04926", "authors": ["Fran\u00e7ois Cl\u00e9ment", "Nathan Kirk", "Art B. Owen", "T. Konstantin Rusch"], "title": "On the optimization of discrepancy measures", "categories": ["math.NA", "cs.NA", "math.OC"], "comment": "22 pages, 3 Figures, 4 Tables", "summary": "Points in the unit cube with low discrepancy can be constructed using algebra\nor, more recently, by direct computational optimization of a criterion. The\nusual $L_\\infty$ star discrepancy is a poor criterion for this because it is\ncomputationally expensive and lacks differentiability. Its usual replacement,\nthe $L_2$ star discrepancy, is smooth but exhibits other pathologies shown by\nJ. Matou\\v{s}ek. In an attempt to address these problems, we introduce the\n\\textit{average squared discrepancy} which averages over $2^d$ versions of the\n$L_2$ star discrepancy anchored in the different vertices of $[0,1]^d$. Not\nonly can this criterion be computed in $O(dn^2)$ time, like the $L_2$ star\ndiscrepancy, but also we show that it is equivalent to a weighted symmetric\n$L_2$ criterion of Hickernell's by a constant factor. We compare this criterion\nwith a wide range of traditional discrepancy measures, and show that only the\naverage squared discrepancy avoids the problems raised by Matou\\v{s}ek.\nFurthermore, we present a comprehensive numerical study showing in particular\nthat optimizing for the average squared discrepancy leads to strong performance\nfor the $L_2$ star discrepancy, whereas the converse does not hold.", "AI": {"tldr": "The paper introduces the 'average squared discrepancy' as a new criterion for constructing low-discrepancy point sets in the unit cube, addressing issues with traditional $L_\\infty$ and $L_2$ star discrepancies.", "motivation": "The $L_\\infty$ star discrepancy is computationally expensive and non-differentiable, while the $L_2$ star discrepancy has pathologies highlighted by J. Matou\u0161ek. The goal is to find a better criterion.", "method": "The authors propose the average squared discrepancy, which averages over $2^d$ versions of the $L_2$ star discrepancy anchored at the vertices of $[0,1]^d$. It is computationally efficient and equivalent to Hickernell's weighted symmetric $L_2$ criterion.", "result": "The average squared discrepancy avoids the problems of traditional measures and performs well in numerical studies, optimizing for it also improves $L_2$ star discrepancy performance.", "conclusion": "The average squared discrepancy is a robust and efficient alternative to traditional discrepancy measures, validated by theoretical and empirical results."}}
{"id": "2508.05111", "pdf": "https://arxiv.org/pdf/2508.05111", "abs": "https://arxiv.org/abs/2508.05111", "authors": ["Marco Sutti", "Mei-Heng Yueh"], "title": "Toroidal area-preserving parameterizations of genus-one closed surfaces", "categories": ["math.NA", "cs.NA", "68U05, 65K10, 65D18, 65D19"], "comment": "28 pages, 10 figures", "summary": "We consider the problem of computing toroidal area-preserving\nparameterizations of genus-one closed surfaces. We propose four algorithms\nbased on Riemannian geometry: the projected gradient descent method, the\nprojected conjugate gradient method, the Riemannian gradient method, and the\nRiemannian conjugate gradient method. Our objective function is based on the\nstretch energy functional, and the minimization is constrained on a power\nmanifold of ring tori embedded in three-dimensional Euclidean space. Numerical\nexperiments on several mesh models demonstrate the effectiveness of the\nproposed framework. Finally, we show how to use the proposed algorithms in the\ncontext of surface registration and texture mapping applications.", "AI": {"tldr": "The paper presents four algorithms for computing toroidal area-preserving parameterizations of genus-one surfaces, using Riemannian geometry and stretch energy minimization.", "motivation": "The need for efficient and accurate parameterization methods for genus-one closed surfaces in applications like surface registration and texture mapping.", "method": "Four algorithms: projected gradient descent, projected conjugate gradient, Riemannian gradient, and Riemannian conjugate gradient, minimizing stretch energy on a power manifold of ring tori.", "result": "Numerical experiments confirm the effectiveness of the proposed framework.", "conclusion": "The algorithms are successfully applied to surface registration and texture mapping, demonstrating practical utility."}}
{"id": "2508.05166", "pdf": "https://arxiv.org/pdf/2508.05166", "abs": "https://arxiv.org/abs/2508.05166", "authors": ["Junming Duan", "Wasilij Barsukow", "Christian Klingenberg"], "title": "An asymptotic-preserving active flux scheme for the hyperbolic heat equation in the diffusive scaling", "categories": ["math.NA", "cs.NA"], "comment": "26 pages, 9 figures", "summary": "The Active Flux (AF) method is a compact, high-order finite volume scheme\nthat enhances flexibility by introducing point values at cell interfaces as\nadditional degrees of freedom alongside cell averages. The method of lines is\nemployed here for temporal discretization. A common approach for updating point\nvalues relies on the Jacobian Splitting (JS) method, which incorporates\nupwinding. A key advantage of the AF method over standard finite volume schemes\nis its structure-preserving property, motivating the investigation of its\nasymptotic-preserving (AP) behavior in the diffusive scaling. We show that the\nJS-based AF method without any modification is AP for solving the hyperbolic\nheat equation, in the sense that the limit scheme is a discretization of the\nlimit heat equation. We use formal asymptotic analysis, discrete Fourier\nanalysis, and numerical experiments to illustrate our findings.", "AI": {"tldr": "The paper analyzes the Active Flux (AF) method, a high-order finite volume scheme, showing its asymptotic-preserving (AP) behavior for the hyperbolic heat equation without modifications.", "motivation": "The study is motivated by the AF method's structure-preserving property and its potential advantages over standard finite volume schemes.", "method": "The method employs Jacobian Splitting (JS) for updating point values and uses formal asymptotic analysis, discrete Fourier analysis, and numerical experiments.", "result": "The JS-based AF method is proven AP for the hyperbolic heat equation, with the limit scheme discretizing the heat equation.", "conclusion": "The AF method's AP behavior is validated, highlighting its suitability for problems in the diffusive scaling."}}
{"id": "2508.05303", "pdf": "https://arxiv.org/pdf/2508.05303", "abs": "https://arxiv.org/abs/2508.05303", "authors": ["Emil L\u00f8vbak", "Sebastian Krumscheid"], "title": "An Investigation into the Distribution of Ratios of Particle Solver-based Likelihoods", "categories": ["math.NA", "cs.NA"], "comment": "16 pages, 4 figures", "summary": "We investigate the use of the Metropolis-Hastings algorithm to sample\nposterior distribution in a Bayesian inverse problem, where the likelihood\nfunction is random. Concretely, we consider the case where one has full field\nobservations of a PDE solution, in case a one-dimensional diffusion equation,\nsubject to a Gaussian observation error. Assuming one uses a particle-based\nMonte Carlo simulation when approximating the likelihood function, one gets an\napproximate likelihood with additive Gaussian noise in the log-likelihood. We\nstudy how these two Gaussian distributions affect the distribution of ratios of\napproximate likelihood evaluations, as required when evaluating acceptance\nprobabilities in the Metropolis-Hastings algorithm. We do so through both\ntheoretical analysis and numerical experiments.", "AI": {"tldr": "The paper explores the Metropolis-Hastings algorithm for sampling posterior distributions in Bayesian inverse problems with random likelihood functions, focusing on PDE solutions with Gaussian observation errors.", "motivation": "To understand the impact of additive Gaussian noise in log-likelihood approximations on the Metropolis-Hastings algorithm's acceptance probabilities.", "method": "Theoretical analysis and numerical experiments are used to study the distribution of ratios of approximate likelihood evaluations.", "result": "The study examines how Gaussian distributions affect likelihood ratios, crucial for Metropolis-Hastings acceptance probabilities.", "conclusion": "The findings provide insights into the behavior of the Metropolis-Hastings algorithm in scenarios with random likelihood functions and Gaussian noise."}}
{"id": "2508.04806", "pdf": "https://arxiv.org/pdf/2508.04806", "abs": "https://arxiv.org/abs/2508.04806", "authors": ["Bernard Parent", "Felipe Martin Rodriguez Fuentes", "Spencer LaFoley"], "title": "Electrodeless Magnetohydrodynamic Local Force Generator for Aerocapture", "categories": ["physics.plasm-ph"], "comment": "14 pages, 12 figures", "summary": "This paper presents a novel magnetohydrodynamics (MHD) system for planetary\nentry aerocapture. The system is advantaged over previous approaches by having\nthe following two characteristics: (i) it can be deployed locally to one or\nvarious flow regions, and (ii) it does not make use of electrodes. Previous MHD\nsystems for planetary entry were either electrodeless global systems or\ntwo-electrode local systems. The proposed novel MHD system employs two magnets\nto establish a current loop resulting in a Faraday electromotive force (EMF).\nThe first magnet is positioned to ensure the magnetic field faces outward from\nthe shell, while the second magnet is oriented to ensure the magnetic field\nfaces inward toward the shell. Preliminary findings demonstrate that when\nlocated on the surface of an Earth entry capsule at a flight Mach number of 35,\nthe novel electrodeless MHD system can generate forces several times greater\nthan a two-electrode system while utilizing the same magnetic field strength.\nThe study is conducted entirely through numerical simulation using CFDWARP, a\ncomputational fluid dynamics (CFD) code that employs advanced numerical methods\nallowing for the full coupling between aerodynamics, magnetohydrodynamics, and\nnon-neutral plasma sheaths. The physical model includes an 11-species\nfinite-rate chemical solver including real gas effects, the drift-diffusion\nmodel for all charged species, along with an electric field potential equation\nthat satisfies Gauss's law.", "AI": {"tldr": "A novel electrodeless MHD system for planetary entry aerocapture is proposed, outperforming previous systems by generating greater forces without electrodes.", "motivation": "To improve planetary entry aerocapture by addressing limitations of previous MHD systems, which were either global and electrodeless or local with electrodes.", "method": "The system uses two magnets to create a Faraday EMF, avoiding electrodes. Simulations with CFDWARP, a CFD code, model aerodynamics, MHD, and plasma sheaths.", "result": "The electrodeless system generates forces several times greater than a two-electrode system at the same magnetic field strength.", "conclusion": "The novel MHD system is a promising alternative for planetary entry aerocapture, offering higher efficiency without electrodes."}}
{"id": "2508.04765", "pdf": "https://arxiv.org/pdf/2508.04765", "abs": "https://arxiv.org/abs/2508.04765", "authors": ["Yanick Thurn", "Manuel Schrauth", "Johanna Erdmenger"], "title": "Hyperbolic tiling neighborhoods in O(1) time", "categories": ["physics.comp-ph", "cond-mat.other", "hep-lat"], "comment": "12 pages, 9 figures", "summary": "Tilings of the hyperbolic plane are of significant interest among many\nbranches of mathematics, physics and computer science. Yet, their construction\nremains a non-trivial task. Current approaches primarily use tree-based\nrecursive algorithms, which are fundamentally limited: they do not readily\nyield the neighborhood graph representing cell adjacencies, which is however\nrequired for many applications. We introduce a novel approach that allows to\nbuild hyperbolic tilings and their associated graph structure simultaneously,\nusing only combinatoric rules without requiring an explicit coordinate\nrepresentation. This allows to generate arbitrarily large, exact hyperbolic\ngraphs, with an algorithmic complexity that does not depend on the lattice\nsize. We provide an easy-to-use implementation which substantially outperforms\nexisting methods, hence rendering ultra large-scale numerical simulations on\nthese geometric structures accessible for the scientific community.", "AI": {"tldr": "A novel method for constructing hyperbolic tilings and their adjacency graphs simultaneously using combinatoric rules, outperforming existing recursive algorithms.", "motivation": "Current tree-based recursive methods for hyperbolic tiling construction lack efficient adjacency graph generation, limiting their utility for applications requiring such structures.", "method": "Introduces a combinatoric rule-based approach to build tilings and adjacency graphs without explicit coordinates, enabling scalable and exact hyperbolic graph generation.", "result": "The method efficiently generates large, exact hyperbolic graphs with size-independent complexity, offering a user-friendly implementation for large-scale simulations.", "conclusion": "This approach advances hyperbolic tiling construction, making large-scale simulations feasible and accessible."}}
{"id": "2508.04785", "pdf": "https://arxiv.org/pdf/2508.04785", "abs": "https://arxiv.org/abs/2508.04785", "authors": ["Mar\u00eda Anguiano", "Francisco J. Su\u00e1rez-Grau"], "title": "Two-dimensional Carreau law for a quasi-newtonian fluid flow through a thin domain with a slightly rough boundary", "categories": ["math.AP", "35B27, 35Q35, 76A05, 76M50, 76A20"], "comment": "arXiv admin note: text overlap with arXiv:2312.01844,\n  arXiv:2508.04617", "summary": "This study investigates the asymptotic behavior of the steady-state\nquasi-Newtonian Stokesflow with viscosity given by the Carreau law within a\nthin domain, focusing on the effects of a slightly rough boundary of the\ndomain. Employing asymptotic techniques with respect to the domain's thickness,\nwe rigorously derive the effective nonlinear two-dimensional Reynolds model\ndescribing the fluid flow. The mathematical analysis is based on deriving the\nsharp a priori estimates and proving the compactness results of the rescaled\nfunctions together with monotonicity arguments. The resulting limit model\nincorporates contributions of the oscillating boundary and thus, it could prove\nuseful in the applications involving this lubrication regime.", "AI": {"tldr": "The paper studies the steady-state quasi-Newtonian Stokes flow in a thin domain with a rough boundary, deriving an effective 2D Reynolds model using asymptotic techniques.", "motivation": "To understand the impact of a slightly rough boundary on fluid flow in thin domains, particularly for lubrication applications.", "method": "Asymptotic techniques, sharp a priori estimates, compactness results, and monotonicity arguments.", "result": "Derived an effective nonlinear 2D Reynolds model incorporating boundary oscillations.", "conclusion": "The model is useful for applications in lubrication regimes involving rough boundaries."}}
{"id": "2508.05328", "pdf": "https://arxiv.org/pdf/2508.05328", "abs": "https://arxiv.org/abs/2508.05328", "authors": ["Yujun Zhu", "Yulan Ning", "Zhipeng Yang", "Xiaoming He", "Ju Ming"], "title": "A low-rank solver for the Stokes-Darcy model with random hydraulic conductivity and Beavers-Joseph condition", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper proposes, analyzes, and demonstrates an efficient low-rank solver\nfor the stochastic Stokes-Darcy interface model with a random hydraulic\nconductivity both in the porous media domain and on the interface. We consider\nthree interface conditions with randomness, including the Beavers-Joseph\ninterface condition with the random hydraulic conductivity, on the interface\nbetween the free flow and the porous media flow. Our solver employs a novel\ngeneralized low-rank approximation of the large-scale stiffness matrices, which\ncan significantly cut down the computational costs and memory requirements\nassociated with matrix inversion without losing accuracy. Therefore, by\nadopting a suitable data compression ratio, the low-rank solver can maintain a\nhigh numerical precision with relatively low computational and space\ncomplexities. We also propose a strategy to determine the best choice of data\ncompression ratios. Furthermore, we carry out the error analysis of the\ngeneralized low-rank matrix approximation algorithm and the low-rank solver.\nFinally, numerical experiments are conducted to validate the proposed\nalgorithms and the theoretical conclusions.", "AI": {"tldr": "An efficient low-rank solver for the stochastic Stokes-Darcy interface model with random hydraulic conductivity is proposed, reducing computational costs while maintaining accuracy.", "motivation": "To address high computational and memory costs in solving the stochastic Stokes-Darcy interface model with randomness in hydraulic conductivity.", "method": "Uses a generalized low-rank approximation for stiffness matrices, optimizing data compression ratios, and includes error analysis and numerical validation.", "result": "The solver reduces computational and memory requirements without losing accuracy, validated by numerical experiments.", "conclusion": "The proposed low-rank solver is efficient and accurate, with a strategy for optimal data compression ratios."}}
{"id": "2508.04881", "pdf": "https://arxiv.org/pdf/2508.04881", "abs": "https://arxiv.org/abs/2508.04881", "authors": ["Z. Tecchiolli", "A. J. Coelho", "J. Loizu", "B. De Lucca", "P. Ricci"], "title": "Magnetic shear effects on ballooning turbulence in the boundary of fusion devices", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The effect of magnetic shear on ballooning-driven plasma edge turbulence is\nstudied through nonlinear simulations complemented by linear numerical and\nanalytical investigations. Nonlinear, 3D, global, flux-driven simulations using\nthe GBS code show that the scale separation between radial, x, and poloidal, y,\nsize of turbulent eddies, kx << ky , considered by Ricci et al. (2008) and\nextensively used to predict pressure gradient lengths, SOL width, particle and\nheat fluxes, is observed with high magnetic shear. In contrast, for low\nmagnetic shear, kx ~ ky is observed, with fluctuation properties resembling\nthose shown by recent low-shear stellarator simulations reported in Coelho et\nal. (2024a). Global linear investigations of the ballooning mode qualitatively\ncaptures the transition in mode structure with varying magnetic shear, showing\nthat kx << ky is achieved with sufficiently strong poloidal mode coupling\nenhanced by increasing magnetic shear, resistivity, toroidal mode number, and\nequilibrium gradient scale length. This is confirmed by an analytical study\nconsidering a dominant poloidal mode and its sidebands, which highlights that\nthe poloidal mode structure is determined by curvature and k parallel effects", "AI": {"tldr": "The study examines how magnetic shear affects ballooning-driven plasma edge turbulence, showing differences in turbulent eddy scales between high and low shear conditions.", "motivation": "To understand the impact of magnetic shear on turbulence in plasma edges, which is crucial for predicting pressure gradients and transport properties.", "method": "Nonlinear 3D simulations using the GBS code, complemented by linear numerical and analytical investigations of ballooning modes.", "result": "High magnetic shear leads to kx << ky, while low shear results in kx ~ ky. Linear studies confirm the transition in mode structure with shear.", "conclusion": "Magnetic shear significantly influences turbulence scales, with implications for predicting plasma behavior in different shear conditions."}}
{"id": "2508.05308", "pdf": "https://arxiv.org/pdf/2508.05308", "abs": "https://arxiv.org/abs/2508.05308", "authors": ["B. D. Jenkins", "A. L. Nicusan", "A. Neveu", "G. Lumay", "F. Francqui", "J. P. K. Seville", "C. R. K. Windows-Yule"], "title": "Identifying Optimal Regression Models For DEM Simulation Datasets", "categories": ["physics.comp-ph"], "comment": null, "summary": "Developing fast regression models (surrogate/metamodels) from DEM data is key\nfor practical industrial application to allow real-time evaluations. However,\nbenchmarking different models is often overlooked in particle technology for\nregression tasks, as model selection is frequently not the primary research\nfocus. This can lead to the use of suboptimal models, resulting in subpar\npredictive accuracy, slow evaluations, or poor generalisation, hindering\neffective real-time decision-making and process optimisation. In this work, we\ndiscuss applying k-fold cross-validation to assess regression models for\ntabular DEM datasets and propose a simple framework for readers to follow to\nfind the optimal model for their data. An example demonstrates its application\nto a DEM dataset of packing fractions measured in a simple measuring beaker\nwith varying inter-particle properties, namely, average particle diameter,\ncoefficient of restitution, coefficient of sliding friction, coefficient of\nrolling resistance, and cohesive energy density. Out of 16 different models\ntested, a histogram-based gradient boosting model was found to be optimal,\nproviding a good fit with acceptable training and inference times.", "AI": {"tldr": "The paper proposes a framework using k-fold cross-validation to benchmark regression models for DEM data, identifying a histogram-based gradient boosting model as optimal.", "motivation": "Developing fast, accurate regression models for DEM data is crucial for real-time industrial applications, but model benchmarking is often overlooked, leading to suboptimal choices.", "method": "The study applies k-fold cross-validation to evaluate 16 regression models on a DEM dataset of packing fractions with varying inter-particle properties.", "result": "A histogram-based gradient boosting model was found to be the best-performing, balancing accuracy and computational efficiency.", "conclusion": "The proposed framework helps select optimal regression models for DEM data, improving predictive accuracy and real-time decision-making."}}
{"id": "2508.04856", "pdf": "https://arxiv.org/pdf/2508.04856", "abs": "https://arxiv.org/abs/2508.04856", "authors": ["T. M. Nascimento", "X. H. Nguyen", "P. R. Stinga"], "title": "Regularity of solutions to degenerate and singular free boundary problems with volume constraint", "categories": ["math.AP", "math.CA"], "comment": "13 pages", "summary": "We prove existence and regularity of solutions to degenerate and singular\nelliptic free boundary problems, where the volume of the positivity set of the\nsolution is prescribed.", "AI": {"tldr": "Existence and regularity of solutions for degenerate/singular elliptic free boundary problems with prescribed positivity set volume.", "motivation": "To address the challenge of solving degenerate and singular elliptic free boundary problems where the volume of the solution's positivity set is fixed.", "method": "Mathematical analysis and proof techniques to establish solution existence and regularity.", "result": "Demonstrated existence and regularity of solutions under the given constraints.", "conclusion": "The study successfully resolves the problem, providing a foundation for further research in this area."}}
{"id": "2508.05372", "pdf": "https://arxiv.org/pdf/2508.05372", "abs": "https://arxiv.org/abs/2508.05372", "authors": ["Louis Petri", "Gunnar Birke", "Christian Engwer", "Hendrik Ranocha"], "title": "The domain-of-dependence stabilization for cut-cell meshes is fully discretely stable", "categories": ["math.NA", "cs.NA", "65M12, 65M20, 65M60"], "comment": "31 pages, 11 figures, 3 tables. For the associated reproducibility\n  repository, see https://github.com/louispetri/2025_dod_linear_stability", "summary": "We present a fully discrete stability analysis of the domain-of-dependence\nstabilization for hyperbolic problems. The method aims to address issues caused\nby small cut cells by redistributing mass around the neighborhood of a small\ncut cell at a semi-discrete level. Our analysis is conducted for the linear\nadvection model problem in one spatial dimension. We demonstrate that fully\ndiscrete stability can be achieved under a time step restriction that does not\ndepend on the arbitrarily small cells, using an operator norm estimate.\nAdditionally, this analysis offers a detailed understanding of the stability\nmechanism and highlights some challenges associated with higher-order\npolynomials. We also propose a way to mitigate these issues to derive a\nfeasible CFL-like condition. The analytical findings, as well as the proposed\nsolution are verified numerically in one- and two-dimensional simulations.", "AI": {"tldr": "The paper analyzes the stability of domain-of-dependence stabilization for hyperbolic problems, focusing on small cut cells. It demonstrates fully discrete stability under a time step restriction independent of cell size, with numerical validation.", "motivation": "Address issues caused by small cut cells in hyperbolic problems, ensuring stability without dependence on cell size.", "method": "Analyzes the linear advection model in 1D using operator norm estimates, proposing a CFL-like condition for stability.", "result": "Achieves fully discrete stability under a cell-size-independent time step restriction, validated numerically in 1D and 2D.", "conclusion": "The method effectively stabilizes small cut cells, with insights into higher-order challenges and a proposed solution."}}
{"id": "2508.05127", "pdf": "https://arxiv.org/pdf/2508.05127", "abs": "https://arxiv.org/abs/2508.05127", "authors": ["Tomohiro Tanogami", "Makoto Sasaki", "Tatsuya Kobayashi"], "title": "Information Propagation in Predator-Prey Dynamics of Turbulent Plasma", "categories": ["physics.plasm-ph", "cond-mat.stat-mech", "physics.flu-dyn"], "comment": "6 pages, 2 figures (+ supplemental material 8 pages, 2 figures)", "summary": "Magnetically confined fusion plasmas exhibit predator-prey-like cyclic\noscillations through the self-regulating interaction between drift-wave\nturbulence and zonal flow. To elucidate the detailed mechanism and causality\nunderlying this phenomenon, we construct a simple stochastic predator-prey\nmodel that incorporates intrinsic fluctuations and analyze its statistical\nproperties from an information-theoretic perspective. We first show that the\nmodel exhibits persistent fluctuating cyclic oscillations called quasi-cycles\ndue to amplification of intrinsic noise. This result suggests the possibility\nthat the previously observed periodic oscillations in a toroidal plasma are not\nlimit cycles but quasi-cycles, and that such quasi-cycles may be widely\nobserved under various conditions. For this model, we further prove that\ninformation of zonal flow is propagated to turbulence. This\ninformation-theoretic analysis may provide a theoretical basis for regulating\nturbulence by controlling zonal flow.", "AI": {"tldr": "The paper explores cyclic oscillations in fusion plasmas using a stochastic predator-prey model, suggesting observed oscillations may be quasi-cycles and demonstrating information flow from zonal flow to turbulence.", "motivation": "To understand the mechanism behind cyclic oscillations in magnetically confined fusion plasmas and the interaction between drift-wave turbulence and zonal flow.", "method": "Constructed a stochastic predator-prey model incorporating intrinsic fluctuations and analyzed its statistical properties using information theory.", "result": "The model shows quasi-cycles due to noise amplification, suggesting observed plasma oscillations may not be limit cycles. Information flow from zonal flow to turbulence was proven.", "conclusion": "The analysis provides a theoretical basis for turbulence regulation by controlling zonal flow, with quasi-cycles potentially common under various conditions."}}
{"id": "2508.04861", "pdf": "https://arxiv.org/pdf/2508.04861", "abs": "https://arxiv.org/abs/2508.04861", "authors": ["Henrik Dick", "Thomas Dahm"], "title": "Optimization of Ab-Initio Based Tight-Binding Models", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "16 pages, 6 figures", "summary": "The electronic structure of solids can routinely be calculated by standard\nmethods like density functional theory. However, in complicated situations like\ninterfaces, grain boundaries or contact geometries one needs to resort to more\nsimplified models of the electronic structure. Tight-binding models are using a\nreduced set of orbitals and aim to approximate the electronic structure by\nshort range hopping processes. For example, maximally localized Wannier\nfunctions are often used for that purpose. However, their accuracy is limited\nby the need to disentangle the electronic bands. Here, we develop and\ninvestigate a different procedure to obtain tight-binding models inspired by\nmachine-learning techniques. The model parameters are optimized in such a way\nas to reproduce ab-initio band structure data as accurately as possible using\nan as small as possible number of model parameters. The procedure is shown to\nresult in models with smaller ranges and fewer orbitals than maximally\nlocalized Wannier functions but same or even better accuracy. We argue that\nsuch a procedure is more useful for automated construction of tight-binding\nmodels particularly for large-scale materials calculations.", "AI": {"tldr": "A machine-learning-inspired method is developed to create accurate tight-binding models with fewer parameters and orbitals than traditional Wannier functions.", "motivation": "Standard methods like density functional theory struggle with complex systems (e.g., interfaces, grain boundaries), requiring simplified models. Tight-binding models, though useful, face accuracy limitations with Wannier functions.", "method": "A new procedure optimizes tight-binding model parameters to closely match ab-initio band structure data, minimizing the number of parameters and orbitals.", "result": "The method produces models with smaller ranges and fewer orbitals than Wannier functions, achieving equal or better accuracy.", "conclusion": "This approach is more efficient for automated, large-scale tight-binding model construction in materials science."}}
{"id": "2508.04863", "pdf": "https://arxiv.org/pdf/2508.04863", "abs": "https://arxiv.org/abs/2508.04863", "authors": ["Patrick Ballard", "Flaviana Iurlano"], "title": "Transition from Continuous to Jumping Solutions in 2D Quasi-static Elastic Contact Problems with Coulomb Friction: the Mathematics Underlying the Onset of Brake Squeal", "categories": ["math.AP"], "comment": null, "summary": "We formulate the quasi-static elastic contact problem with Coulomb friction\nin a very general setting, with possible jumps in time for both the load and\nthe solution. Exploiting ideas originating in our recent paper [4], we exhibit\nan optimal condition on the magnitude of the friction coefficient under which\nwe prove the existence of an absolutely continuous solution for arbitrary\nabsolutely continuous loads in the case of the most general 2D problem. We\nprovide examples showing that, when the condition is violated, spontaneous\njumps in time of the solution may occur, even when the load varies absolutely\ncontinuously in time. We argue that these spontaneous jumps in time of the\nsolution in the quasi-static problem reveal a transition of the process from a\nquasi-static nature to a dynamic nature, interpreted as the mathematical\nsignature of the onset of friction-induced vibrations in the elastodynamic\ncontact problem with dry friction.", "AI": {"tldr": "The paper analyzes the quasi-static elastic contact problem with Coulomb friction, proving existence of solutions under optimal friction conditions and showing how violations lead to dynamic transitions.", "motivation": "To understand the conditions under which solutions to the quasi-static elastic contact problem with Coulomb friction remain absolutely continuous, and to explore the implications of violations.", "method": "Formulates the problem in a general setting, uses ideas from prior work to derive an optimal friction coefficient condition, and provides examples of violations.", "result": "Proves existence of absolutely continuous solutions under optimal conditions; violations cause spontaneous jumps, indicating a dynamic transition.", "conclusion": "Spontaneous jumps in the solution reveal a shift from quasi-static to dynamic behavior, marking the onset of friction-induced vibrations."}}
{"id": "2508.05376", "pdf": "https://arxiv.org/pdf/2508.05376", "abs": "https://arxiv.org/abs/2508.05376", "authors": ["Zhengjie Sun", "Leevan Ling"], "title": "Inverse inequalities for kernel-based approximation on bounded domains and Riemannian manifolds", "categories": ["math.NA", "cs.NA", "41A17, 65D05, 65D12"], "comment": null, "summary": "This paper establishes inverse inequalities for kernel-based approximation\nspaces defined on bounded Lipschitz domains in $\\mathbb{R}^d$ and compact\nRiemannian manifolds. While inverse inequalities are well-studied for\npolynomial spaces, their extension to kernel-based trial spaces poses\nsignificant challenges. For bounded Lipschitz domains, we extend prior\nBernstein inequalities, which only apply to a limited range of Sobolev orders,\nto all orders on the lower bound and $L_2$ on the upper, and derive Nikolskii\ninequalities that bound $L_\\infty$ norms by $L_2$ norms. Our theory achieves\nthe desired form but may require slightly more smoothness on the kernel than\nthe regular $>d/2$ assumption. For compact Riemannian manifolds, we focus on\nrestricted kernels, which are defined as the restriction of positive definite\nkernels from the ambient Euclidean space to the manifold, and prove their\ncounterparts.", "AI": {"tldr": "The paper extends inverse inequalities to kernel-based approximation spaces on bounded Lipschitz domains and compact Riemannian manifolds, overcoming challenges not present in polynomial spaces.", "motivation": "To generalize inverse inequalities, traditionally studied for polynomial spaces, to kernel-based trial spaces, addressing gaps in Sobolev orders and norms.", "method": "Extends Bernstein inequalities for bounded Lipschitz domains to all Sobolev orders and derives Nikolskii inequalities. For Riemannian manifolds, it focuses on restricted kernels from Euclidean spaces.", "result": "Achieves desired inverse inequalities, though requiring slightly more kernel smoothness than the standard assumption.", "conclusion": "The work successfully generalizes inverse inequalities to kernel-based spaces, with implications for approximation theory on complex domains."}}
{"id": "2508.04930", "pdf": "https://arxiv.org/pdf/2508.04930", "abs": "https://arxiv.org/abs/2508.04930", "authors": ["Cal J. Rising", "Eric J. Ching", "Ryan F. Johnson"], "title": "Simulation of Non-Premixed, Supersonic Combustion using the Discontinuous Galerkin Method on Fully Unstructured Grids", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": null, "summary": "In this study, three-dimensional simulations of a reacting hydrogen jet in\nsupersonic crossflow using a structure-preserving discontinuous Galerkin (DG)\nformulation are examined. The hydrogen jet, with a momentum flux ratio of five,\nis injected into a high enthalpy crossflow. The sensitivities of the solution\nto the grid element size and polynomial order are investigated to determine an\naccurate and computationally efficient approach to simulating high-speed\nairbreathing propulsion vehicles. The results demonstrate that DG(p = 2)\nsolutions, which are nominally third-order accurate in smooth regions of the\nflow, show reasonable agreement with existing experimental results. The\nseparation shock formation behind the jet is found to be heavily grid dependent\nand necessary for accurate simulations of the reacting jet in supersonic\ncrossflow. It is determined that the highest resolution cell and polynomial\norder is required to capture the upstream separation shock and consequently the\nflame stabilization point. The mixing and combustion mode is also determined\nusing the flame index and demonstrates the flow is heavily skewed towards a\nnon-premixed diffusion mode which is consistent with previously run simulations\nof this case using traditional finite volume schemes and sub grid scale\nmodeling approaches. Beyond this analysis, the novelty of this work lies in\ndemonstrating a high-speed, multicomponent, chemically reacting flow on a fully\nunstructured tetrahedral mesh: a first-of-its-kind calculation. This highlights\nthe potential of these methods for simulating fluids in complex geometries with\ncomplex physics", "AI": {"tldr": "3D simulations of a reacting hydrogen jet in supersonic crossflow using DG methods show grid and polynomial order sensitivity, with DG(p=2) agreeing with experiments. High resolution is needed for accurate shock and flame capture.", "motivation": "To determine an accurate and efficient approach for simulating high-speed airbreathing propulsion vehicles using DG methods.", "method": "Structure-preserving DG formulation for 3D simulations of a hydrogen jet in supersonic crossflow, examining grid and polynomial order sensitivity.", "result": "DG(p=2) agrees with experiments; high resolution captures separation shock and flame stabilization. Mixing and combustion are non-premixed diffusion mode.", "conclusion": "The study demonstrates the potential of DG methods for complex geometries and physics, marking a first-of-its-kind calculation on unstructured tetrahedral meshes."}}
{"id": "2508.05220", "pdf": "https://arxiv.org/pdf/2508.05220", "abs": "https://arxiv.org/abs/2508.05220", "authors": ["Joly Romain"], "title": "Parabolic abstract evolution equations in cylindrical domains and uniformly local Sobolev spaces", "categories": ["math.AP", "35A01, 35A02, 35K57, 35K58, 35K90, 47B12, 47D62"], "comment": null, "summary": "In this article, we consider parabolic equations of the type $$\\partial_t\nu(x,t)=\\Delta u(x,t) - Bu(x,t) + F(u(x,t))$$ where $u$ is valued in a\ntransverse Hilbert space $Y$ and $B$ is a positive self-adjoint operator on\n$Y$, allowing a different diffusion mechanism in the transverse direction. We\naim at considering solutions with infinite energy and we study the Cauchy\nproblem in the uniformly local spaces associated with the norm\n$$\\|u\\|_{L^2_{\\text{ul}}(\\mathbb{R},Y)}= \\sup_{a\\in\\mathbb{R}^d}\n\\|u(x)\\|_{L^2(B(a,1),Y)}.$$ For the classical parabolic equation, i.e. if\n$Y=\\mathbb{R}$, it is known that the Cauchy problem is ill-posed in the weak\nversion of the uniformly local spaces but well-posed in a stronger version,\nwhere additional uniform continuity is required. In this paper, we show that\nthe linear operator $\\partial^2_{xx} - B$ is not necessarily a sectorial\noperator in any version of the uniformly local Lebesgue space, due to the\npossible non-density of its domain. Then, we use the theory of parabolic\nabstract evolution equations to set a well-posed Cauchy problem, even in the\nweak version of the uniformly local space. In particular, we believe that this\npaper offers a new perspective on the comparison between both versions of the\nuniformly local spaces and also provides a new natural example of differential\noperators with non-dense domain.", "AI": {"tldr": "The paper analyzes parabolic equations in transverse Hilbert spaces, focusing on solutions with infinite energy and the Cauchy problem in uniformly local spaces. It addresses ill-posedness in weak versions and well-posedness in stronger versions, using abstract evolution equations.", "motivation": "To study parabolic equations in transverse Hilbert spaces with infinite energy solutions, comparing weak and strong versions of uniformly local spaces, and addressing the non-sectorial nature of certain operators.", "method": "Uses the theory of parabolic abstract evolution equations to analyze the Cauchy problem in uniformly local spaces, particularly focusing on the operator \u2202\u00b2\u2093\u2093 - B.", "result": "Shows the linear operator \u2202\u00b2\u2093\u2093 - B is not necessarily sectorial in uniformly local Lebesgue spaces due to non-density of its domain, but establishes well-posedness using abstract evolution theory.", "conclusion": "Provides new insights into uniformly local spaces and non-dense domain operators, offering a well-posed framework for the Cauchy problem even in weak versions."}}
{"id": "2508.05400", "pdf": "https://arxiv.org/pdf/2508.05400", "abs": "https://arxiv.org/abs/2508.05400", "authors": ["Jean-Guillaume de Damas", "Laura Grigori"], "title": "Randomized Krylov-Schur eigensolver with deflation", "categories": ["math.NA", "cs.NA", "65F15, 65F25, 65F50, 15B52"], "comment": null, "summary": "This work introduces a novel algorithm to solve large-scale eigenvalue\nproblems and seek a small set of eigenpairs. The method, called randomized\nKrylov-Schur (rKS), has a simple implementation and benefits from fast and\nefficient operations in low-dimensional spaces, such as\nsketch-orthogonalization processes and stable reordering of Schur\nfactorizations. It also includes a practical deflation technique for converged\neigenpairs, enabling the computation of the eigenspace associated with a given\npart of the spectrum. Numerical experiments are provided to demonstrate the\nscalability and accuracy of the method.", "AI": {"tldr": "A novel algorithm, randomized Krylov-Schur (rKS), is introduced for solving large-scale eigenvalue problems efficiently.", "motivation": "To address the challenge of computing a small set of eigenpairs in large-scale eigenvalue problems with simplicity and efficiency.", "method": "The rKS method leverages low-dimensional operations like sketch-orthogonalization and stable Schur reordering, along with a deflation technique for converged eigenpairs.", "result": "Numerical experiments confirm the method's scalability and accuracy.", "conclusion": "The rKS algorithm is a practical and efficient solution for targeted eigenvalue computations."}}
{"id": "2508.05043", "pdf": "https://arxiv.org/pdf/2508.05043", "abs": "https://arxiv.org/abs/2508.05043", "authors": ["Tarun Singh", "Sandipan Paul"], "title": "Constitutive modeling of viscoelastic solids at large strains based on the theory of evolving natural configurations", "categories": ["cond-mat.soft", "physics.comp-ph"], "comment": "This article is prepared for a proposed special issue in a journal\n  which is currently under editorial review", "summary": "The theory of evolving natural configurations is an effective technique to\nmodel dissipative processes. In this paper, we use this theory to revisit\nnonlinear constitutive models of viscoelastic solids. Particularly, a Maxwell\nand a Kelvin-Voigt model and their associated standard solids, viz., a Zener\nand a Poynting-Thompson solids respectively, have been modeled within a\nLagrangian framework. We show that while a strain-space formulation of the\nevolving natural configurations is useful in modeling Maxwell-type materials, a\nstress-space formulation that incorporates a rate of dissipation function in\nterms of the relevant configurational forces is required for modeling the\nKelvin-Voigt type materials. Furthermore, we also show that the basic Maxwell\nand Kelvin-Voigt models can be obtained as limiting cases from the derived\nstandard solid models. Integration algorithms for the proposed models have been\ndeveloped and numerical solutions for a relevant boundary value problem are\nobtained. The response of the developed models have been compared and\nbenchmarked with experimental data. Specifically, the response of the novel\nPoynting-Thompson model is studied in details. This model shows a very good\nmatch with the existing experimental data obtained from a uniaxial stretching\nof polymers over a large extent of strain. The relaxation behavior and rate\neffects for the developed models have been studied.", "AI": {"tldr": "The paper revisits nonlinear constitutive models of viscoelastic solids using the theory of evolving natural configurations, focusing on Maxwell and Kelvin-Voigt models and their standard solids (Zener and Poynting-Thompson). It highlights the need for strain-space and stress-space formulations for Maxwell and Kelvin-Voigt materials, respectively, and shows their limiting cases. Numerical solutions and experimental benchmarking are provided, with the Poynting-Thompson model showing strong agreement with polymer stretching data.", "motivation": "To improve the modeling of dissipative processes in viscoelastic solids by leveraging the theory of evolving natural configurations, addressing gaps in existing nonlinear constitutive models.", "method": "The study employs a Lagrangian framework to model Maxwell and Kelvin-Voigt materials and their standard solids (Zener and Poynting-Thompson). Strain-space and stress-space formulations are used, with numerical integration algorithms developed for solving boundary value problems.", "result": "The Poynting-Thompson model aligns well with experimental data for polymer stretching, demonstrating accurate relaxation behavior and rate effects. The Maxwell and Kelvin-Voigt models are derived as limiting cases of the standard solids.", "conclusion": "The theory of evolving natural configurations effectively models viscoelastic solids, with the Poynting-Thompson model standing out for its experimental validation. The work provides a robust framework for future studies on dissipative processes."}}
{"id": "2508.05230", "pdf": "https://arxiv.org/pdf/2508.05230", "abs": "https://arxiv.org/abs/2508.05230", "authors": ["Wentao Cao", "Jonas Hirsch", "Dominik Inauen"], "title": "Isometric Immersions and Weak Solutions to the Darboux Equation", "categories": ["math.AP", "53A05, 35J96, 53C45, 35D30"], "comment": null, "summary": "We study the Darboux equation, a fundamental PDE arising in the theory of\nisometric immersions of two-dimensional Riemannian manifolds into\n$\\mathbb{R}^3$, in the low-regularity regime. We introduce a notion of weak\nsolution for $u\\in C^{1,\\theta}$ with $\\theta>1/2$, and show that the classical\ncorrespondence between solutions of the Darboux equation and isometric\nimmersions remains valid in this regime. The key ingredient is an extension of\nthe classical flatness criterion to H\\\"older continuous metrics, achieved via\nan analysis of a weak notion of Gaussian curvature.", "AI": {"tldr": "The paper extends the Darboux equation's weak solution concept to low-regularity regimes (C\u00b9,\u03b8 with \u03b8>1/2) and maintains its classical link to isometric immersions.", "motivation": "To address the Darboux equation in low-regularity settings, crucial for understanding isometric immersions of 2D Riemannian manifolds into \u211d\u00b3.", "method": "Introduces weak solutions for C\u00b9,\u03b8 functions (\u03b8>1/2) and extends the flatness criterion to H\u00f6lder continuous metrics via weak Gaussian curvature analysis.", "result": "The classical correspondence between Darboux equation solutions and isometric immersions holds in the low-regularity regime.", "conclusion": "The study successfully generalizes the Darboux equation's applicability to weaker regularity conditions, preserving its geometric significance."}}
{"id": "2508.05407", "pdf": "https://arxiv.org/pdf/2508.05407", "abs": "https://arxiv.org/abs/2508.05407", "authors": ["Moritz Feuerle", "Richard L\u00f6scher", "Olaf Steinbach", "Karsten Urban"], "title": "A unified framework for the analysis, numerical approximation and model reduction of linear operator equations, Part I: Well-posedness in space and time", "categories": ["math.NA", "cs.NA", "35R20, 35A15, 65N12"], "comment": "linear operator equations, well-posedness, space-time variational\n  methods", "summary": "We present a unified framework to construct well-posed formulations for large\nclasses of linear operator equations including elliptic, parabolic and\nhyperbolic partial differential equations. This general approach incorporates\nknown weak variational formulations as well as novel space-time variational\nforms of the hyperbolic wave equation. The main concept is completion and\nextension of operators starting from the strong form of the problem.\n  This paper lays the theoretical foundation for a unified approach towards\nnumerical approximation methods and also model reduction of parameterized\nlinear operator equations which will be the subject of the following parts.", "AI": {"tldr": "A unified framework for well-posed formulations of linear operator equations, including PDEs, is introduced, extending from strong forms to novel space-time variational forms.", "motivation": "To provide a theoretical foundation for numerical approximation and model reduction of parameterized linear operator equations.", "method": "Completion and extension of operators from the strong form, incorporating weak and space-time variational formulations.", "result": "A general approach for constructing well-posed formulations for elliptic, parabolic, and hyperbolic PDEs.", "conclusion": "The framework supports future work on numerical methods and model reduction for linear operator equations."}}
{"id": "2508.05217", "pdf": "https://arxiv.org/pdf/2508.05217", "abs": "https://arxiv.org/abs/2508.05217", "authors": ["Minas Kouroublakis", "Nikolaos L. Tsitsas", "Yehuda Leviatan"], "title": "A Time-Domain Method of Auxiliary Sources for Efficient Analysis of Transient Electromagnetic Scattering by Moderately Conductive Cylinders", "categories": ["physics.class-ph", "physics.comp-ph"], "comment": null, "summary": "This paper presents a time-domain implementation of the Method of Auxiliary\nSources (MAS) combined with the Standard Impedance Boundary Condition (SIBC)\nfor electromagnetic scattering problems involving cylindrical scatterers with\nfinite but moderate conductivity. The proposed approach focuses on solving the\ntwo-dimensional problem using a first-order SIBC, which is valid when the\nconductivity is sufficiently higher than the maximum spectral frequency times\nthe dielectric permittivity of the scatterer. This regime includes moderately\nconductive materials--such as carbon-based composites, conductive polymers, and\ndoped dielectrics--that are increasingly used in real-world radio-frequency\napplications, including wearable electronics, electromagnetic interference\nshielding, and biomedical sensors. Under the above validity conditions, the\ninteraction between the incident wave and the scatterer is dominated by surface\neffects, allowing for an efficient and accurate modeling strategy without the\nneed to compute internal fields. The theoretical formulation of the time-domain\nMAS-SIBC method is developed, followed by extensive numerical testing on\nvarious geometries whose cross section is a closed curve. Such geometries\ninclude circular, elliptical, super-circular, rounded-triangular, and\ninverted-elliptical scatterers. A planar geometry is also tested. All results\nare validated against analytical solutions and commercial frequency-domain\nsolvers, demonstrating the accuracy and practical potential of the proposed\nmethod. The findings suggest that time-domain MAS-SIBC offers a promising and\ncomputationally efficient approach for modeling scattering from materials even\nwith moderate conductivity.", "AI": {"tldr": "A time-domain Method of Auxiliary Sources (MAS) combined with Standard Impedance Boundary Condition (SIBC) is proposed for electromagnetic scattering from moderately conductive cylindrical scatterers, validated for accuracy and efficiency.", "motivation": "To address the need for efficient modeling of scattering from moderately conductive materials (e.g., carbon-based composites, conductive polymers) used in RF applications like wearable electronics and biomedical sensors.", "method": "Uses a first-order SIBC in a 2D problem, focusing on surface effects without computing internal fields, and validates with numerical tests on various geometries.", "result": "Demonstrates accuracy and computational efficiency, validated against analytical solutions and commercial solvers.", "conclusion": "Time-domain MAS-SIBC is a promising, efficient method for modeling scattering from moderately conductive materials."}}
{"id": "2508.05252", "pdf": "https://arxiv.org/pdf/2508.05252", "abs": "https://arxiv.org/abs/2508.05252", "authors": ["Kiyoshi Suzuki"], "title": "A viscosity solution as a piecewise classical solution to a free boundary problem for the optimal switching problem with simultaneous multiple switches", "categories": ["math.AP", "math.OC"], "comment": null, "summary": "\\citeN{suzuki2020optimal} proves the uniqueness of the viscosity solution to\na variational inequality which is solved by the value function of the infinite\nhorizon optimal switching problem with simultaneous multiple switchings.\nAlthough it also identifies each connected region possibly including at most\none connected switching region, the exact switching regions of the solution are\nnot identified. The problem is finally converted into a system of free boundary\nproblems and generally solved by the numerical calculation. However, if the PDE\npart of the variational inequality has a classical solution, the viscosity\nsolution may be constructed as a series of piecewise classical solutions,\npossibly analytical.\n  Under a certain assumption we prove that the series of piecewise classical\nsolutions is indeed the viscosity solution on $\\real{}$, after we prove the\nsmooth pasting condition is its necessary condition, and establish the\nalgorithm to compute all the free boundaries. Applying the results to the\nconcrete problem studied in \\citeN{suzuki2020optimal} we find the explicit\nsolution and identify the continuation and switching regions in a computer with\nPython programs.", "AI": {"tldr": "The paper proves the uniqueness of the viscosity solution for an optimal switching problem, identifies regions, and provides a numerical and analytical solution method.", "motivation": "To address the lack of exact identification of switching regions in the infinite horizon optimal switching problem and provide a solution method.", "method": "Converts the problem into free boundary problems, uses numerical and analytical methods, and proves smooth pasting conditions.", "result": "Explicit solution and identification of continuation and switching regions using Python programs.", "conclusion": "The series of piecewise classical solutions under certain assumptions is the viscosity solution, with practical applications demonstrated."}}
{"id": "2508.05445", "pdf": "https://arxiv.org/pdf/2508.05445", "abs": "https://arxiv.org/abs/2508.05445", "authors": ["Costas Smaragdakis"], "title": "Learning Geometric-Aware Quadrature Rules for Functional Minimization", "categories": ["math.NA", "cs.LG", "cs.NA", "65D32, 65N12, 68T07"], "comment": "15 pages, 4 figures", "summary": "Accurate numerical integration over non-uniform point clouds is a challenge\nfor modern mesh-free machine learning solvers for partial differential\nequations (PDEs) using variational principles. While standard Monte Carlo (MC)\nmethods are not capable of handling a non-uniform point cloud, modern neural\nnetwork architectures can deal with permutation-invariant inputs, creating\nquadrature rules for any point cloud. In this work, we introduce QuadrANN, a\nGraph Neural Network (GNN) architecture designed to learn optimal quadrature\nweights directly from the underlying geometry of point clouds. The design of\nthe model exploits a deep message-passing scheme where the initial layer\nencodes rich local geometric features from absolute and relative positions as\nwell as an explicit local density measure. In contrast, the following layers\nincorporate a global context vector. These architectural choices allow the\nQuadrANN to generate a data-driven quadrature rule that is\npermutation-invariant and adaptive to both local point density and the overall\ndomain shape. We test our methodology on a series of challenging test cases,\nincluding integration on convex and non-convex domains and estimating the\nsolution of the Heat and Fokker-Planck equations. Across all the tests,\nQuadrANN reduces the variance of the integral estimation compared to standard\nQuasi-Monte Carlo methods by warping the point clouds to be more dense in\ncritical areas where the integrands present certain singularities. This\nenhanced stability in critical areas of the domain at hand is critical for the\noptimization of energy functionals, leading to improved deep learning-based\nvariational solvers.", "AI": {"tldr": "QuadrANN, a GNN architecture, learns optimal quadrature weights for non-uniform point clouds, improving integration accuracy for PDE solvers.", "motivation": "Addressing the challenge of accurate numerical integration over non-uniform point clouds for mesh-free PDE solvers.", "method": "Uses a deep message-passing GNN to encode local geometric features and global context, generating adaptive quadrature rules.", "result": "Reduces variance in integral estimation, outperforming Quasi-Monte Carlo methods, especially in critical areas.", "conclusion": "QuadrANN enhances stability and accuracy for deep learning-based variational solvers."}}
{"id": "2508.05247", "pdf": "https://arxiv.org/pdf/2508.05247", "abs": "https://arxiv.org/abs/2508.05247", "authors": ["Max Gro\u00dfmann", "Marc Thieme", "Malte Grunert", "Erich Runge"], "title": "Many-body perturbation theory vs. density functional theory: A systematic benchmark for band gaps of solids", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "We benchmark many-body perturbation theory against density functional theory\n(DFT) for the band gaps of solids. We systematically compare four $GW$ variants\n$-$ $G_{0}W_{0}$ using the Godby-Needs plasmon-pole approximation\n($G_{0}W_{0}$-PPA), full-frequency quasiparticle $G_{0}W_{0}$ (QP$G_{0}W_{0}$),\nfull-frequency quasiparticle self-consistent $GW$ (QS$GW$), and QS$GW$\naugmented with vertex corrections in $W$ (QS$G\\hat{W}$) $-$ against the\ncurrently best performing and popular density functionals mBJ and HSE06. Our\nresults show that $G_{0}W_{0}$-PPA calculations offer only a marginal accuracy\ngain over the best DFT methods, however at a higher cost. Replacing the PPA\nwith a full-frequency integration of the dielectric screening improves the\npredictions dramatically, almost matching the accuracy of the QS$G\\hat{W}$. The\nQS$GW$ removes starting-point bias, but systematically overestimates\nexperimental gaps by about $15\\%$. Adding vertex corrections to the screened\nCoulomb interaction, i.e., performing a QS$G\\hat{W}$ calculation, eliminates\nthe overestimation, producing band gaps that are so accurate that they even\nreliably flag questionable experimental measurements.", "AI": {"tldr": "The paper benchmarks GW methods against DFT for band gap predictions, showing full-frequency GW variants outperform DFT and PPA, with QSG\u0174 being the most accurate.", "motivation": "To evaluate the accuracy and efficiency of GW methods compared to DFT for predicting band gaps in solids.", "method": "Comparison of four GW variants (G0W0-PPA, QPG0W0, QSGW, QSG\u0174) against DFT methods (mBJ, HSE06) for band gap calculations.", "result": "Full-frequency GW methods (QPG0W0, QSGW, QSG\u0174) outperform DFT and PPA, with QSG\u0174 achieving the highest accuracy.", "conclusion": "QSG\u0174 is the most reliable method for band gap predictions, even identifying questionable experimental data."}}
{"id": "2508.05324", "pdf": "https://arxiv.org/pdf/2508.05324", "abs": "https://arxiv.org/abs/2508.05324", "authors": ["Stefano Bianchini", "Martina Zizza"], "title": "Existence of spiral strategies for blocking fire spreading", "categories": ["math.AP"], "comment": null, "summary": "In this paper we address the problem for blocking fire by constructing a wall\n$\\zeta$ whose shape is spiral-like. This is supposed to be the best strategy\nwhen a single firefighter is constructing the wall with a finite construction\nspeed $\\sigma$: the barriers which satisfy this bound on the construction speed\nare called admissible.\n  We prove a sharp version of Bressan's Fire Conjecture in this case, i.e. when\nadmissible barriers are spiral-like curves: namely, there exists a spiral-like\nbarrier confining the fire in a bounded region of $\\mathbb R^2$ if and only if\nthe speed of construction of the barrier $\\sigma$ is strictly larger than a\ncritical speed $\\bar \\sigma = 2.614...$.\n  The existence of confining spiral barriers for $\\sigma > \\bar \\sigma$ is\nalready known [Bressan A. et al., 2008, Klein R. et al., 2019], while we\nconcentrate on the negative side, i.e. if $\\sigma \\leq \\bar \\sigma$ no\nadmissible spiral blocks the fire.\n  The proof of these results relies on: 1) the precise definition of spiral\nbarrier and its representation; 2) the analysis of saturated spiral barriers as\na Retarded Differential Equation (RDE) in the spirit of [Klein R. et al.,\n2019]; 3) the equivalent reformulation of the conjecture as a minimum problem\nfor a prescribed functional; 4) the construction of the optimal closing spiral;\n5) the analysis of a differentiable path of admissible spirals along which the\nfunctional is differentiable, and in particular increasing when moving from the\noptimal spiral to any other one (homotopy argument).\n  Due to the complexity of the solution, the evaluation of the quantities\nneeded to prove that the functional is increasing is performed numerically.", "AI": {"tldr": "The paper proves a sharp version of Bressan's Fire Conjecture for spiral-like barriers, showing confinement of fire is possible only if construction speed exceeds a critical value.", "motivation": "To determine the conditions under which a single firefighter can construct a spiral-like barrier to block fire, given finite construction speed.", "method": "The proof involves defining spiral barriers, analyzing them as Retarded Differential Equations, reformulating the problem as a functional minimization, constructing optimal spirals, and using a homotopy argument. Numerical evaluation supports the analysis.", "result": "A spiral-like barrier confines fire if and only if the construction speed \u03c3 exceeds a critical value \u03c3\u0304 \u2248 2.614.", "conclusion": "The study confirms the critical speed threshold for spiral barriers, with numerical methods validating the theoretical framework."}}
{"id": "2508.05564", "pdf": "https://arxiv.org/pdf/2508.05564", "abs": "https://arxiv.org/abs/2508.05564", "authors": ["Dominic Breit", "Andreas Prohl", "J\u00f6rn Wichman"], "title": "Numerical analysis of the stochastic Navier-Stokes equations", "categories": ["math.NA", "cs.NA", "math.AP", "math.PR"], "comment": null, "summary": "The developments over the last five decades concerning numerical\ndiscretisations of the incompressible Navier--Stokes equations have lead to\nreliable tools for their approximation: those include stable methods to\nproperly address the incompressibility constraint, stable discretisations to\naccount for convection dominated problems, efficient time (splitting) methods,\nand methods to tackle their nonlinear character. While these tools may\nsuccessfully be applied to reliably simulate even more complex fluid flow PDE\nmodels, their understanding requires a fundamental revision in the case of\nstochastic fluid models, which are gaining increased importance nowadays.\n  This work motivates and surveys optimally convergent numerical methods for\nthe stochastic Stokes and Navier--Stokes equations that were obtained in the\nlast decades. Furtheremore, we computationally illustrate the failure of some\nof those methods from the deterministic setting, if they are straight-forwardly\napplied to the stochastic case. In fact, we explain why some of these\ndeterministic methods perform sub-optimally by highlighting crucial analytical\ndifferences between the deterministic and stochastic equations -- and how\nmodifications of the deterministic methods restore their optimal performance if\nthey properly address the probabilistic nature of the stochastic problem.\n  Next to the numerical analysis of schemes, we propose a general benchmark of\nprototypic fluid flow problems driven by different types of noise to also\ncompare new algorithms by simulations in terms of complexities, efficiencies,\nand possible limitations. The driving motivation is to reach a better\ncomparison of simulations for new schemes in terms of accuracy and\ncomplexities, and to also complement theoretical performance studies for\nrestricted settings of data by more realistic ones.", "AI": {"tldr": "The paper surveys and motivates optimally convergent numerical methods for stochastic Stokes and Navier-Stokes equations, highlighting differences from deterministic methods and proposing benchmarks for new algorithms.", "motivation": "To address the need for reliable numerical methods for stochastic fluid models, which differ fundamentally from deterministic ones, and to provide benchmarks for comparing new algorithms.", "method": "Survey of existing numerical methods for stochastic equations, computational illustration of deterministic methods' failures in stochastic settings, and proposal of benchmarks for algorithm comparison.", "result": "Deterministic methods perform sub-optimally in stochastic cases; modifications addressing probabilistic nature restore optimal performance. Benchmarks aid in comparing new algorithms.", "conclusion": "The paper emphasizes the need for tailored numerical methods for stochastic fluid models and provides tools for evaluating new algorithms through benchmarks."}}
{"id": "2508.05333", "pdf": "https://arxiv.org/pdf/2508.05333", "abs": "https://arxiv.org/abs/2508.05333", "authors": ["Felix Binkowski", "Aris Koulas-Simos", "Fridtjof Betz", "Matthias Plock", "Ivan Sekulic", "Phillip Manley", "Martin Hammerschmidt", "Philipp-Immanuel Schneider", "Lin Zschiedrich", "Battulga Munkhbat", "Stephan Reitzenstein", "Sven Burger"], "title": "High Purcell enhancement in all-TMDC nanobeam resonator designs with optically active monolayers for nanolasers", "categories": ["physics.optics", "cond-mat.mes-hall", "physics.comp-ph"], "comment": null, "summary": "We propose a nanobeam resonator incorporating an optically active monolayer,\ndesigned to achieve a high Purcell enhancement. The resonator is fully composed\nof transition metal dichalcogenide (TMDC) materials and intended to operate as\na high-beta-factor nanolaser. A theoretical framework that models and optimizes\nthe Purcell enhancement associated with the emission from atomically thin\nlayers is developed. This framework is based on a resonance expansion, enabling\nspectral resolution of physical quantities governed by high-Q resonances. The\nnumerical optimization of the resonator leads to the presence of a high-Q\nresonance supporting a strong electric field confinement in the monolayer to\nmaximize the modal gain.", "AI": {"tldr": "A nanobeam resonator with an optically active monolayer achieves high Purcell enhancement, optimized for high-beta-factor nanolaser operation using TMDC materials.", "motivation": "To enhance light-matter interaction in atomically thin layers for efficient nanolaser applications.", "method": "Developed a theoretical framework using resonance expansion to model and optimize Purcell enhancement, focusing on high-Q resonances and electric field confinement.", "result": "Numerical optimization revealed a high-Q resonance enabling strong electric field confinement in the monolayer, maximizing modal gain.", "conclusion": "The proposed resonator design and framework effectively enhance light emission in TMDC monolayers, promising for high-performance nanolasers."}}
{"id": "2508.05401", "pdf": "https://arxiv.org/pdf/2508.05401", "abs": "https://arxiv.org/abs/2508.05401", "authors": ["Huaian Diao", "Xiaoxu Fei", "Hongyu Liu"], "title": "Geometrical characterizations of radiating and non-radiating elastic sources and mediums with applications", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we investigate two types of time-harmonic elastic wave\nscattering problems. The first one involves the scattered wave generated by an\nactive elastic source with compact support. The second one concerns elastic\nwave scattering caused by an inhomogeneous medium, also with compact support.\nWe derive several novel quantitative results concerning the geometrical\nproperties of the underlying scatterer, the associated source or incident wave\nfield, and the physical parameters. In particular, we show that a scatterer\nwith either a small support or high-curvature boundary points must radiate at\nany frequency. These qualitative characterizations allow us to establish\nseveral local and global uniqueness results for determining the support of the\nsource or medium scatterer from a single far-field measurement. Furthermore, we\nreveal new geometric properties of elastic transmission eigenfunctions. To\nderive a quantitative relationship between the intensity of a radiating or\nnon-radiating source and the diameter of its support, we utilize the Helmholtz\ndecomposition, the translation-invariant $L^2$-norm estimate for the Lam\\'e\noperator, and global energy estimates. Another pivotal technical approach\ncombines complex geometric optics (CGO) solutions with local regularity\nestimates, facilitating microlocal analysis near admissible $K$-curvature\nboundary points.", "AI": {"tldr": "The paper investigates time-harmonic elastic wave scattering, deriving quantitative results about scatterer geometry, source properties, and physical parameters. It shows unique determination of scatterer support from far-field measurements and reveals geometric properties of elastic transmission eigenfunctions.", "motivation": "To understand and characterize the geometric and physical properties of scatterers in elastic wave problems, enabling unique identification from minimal data.", "method": "Uses Helmholtz decomposition, Lam\u00e9 operator estimates, global energy estimates, and combines complex geometric optics solutions with local regularity estimates.", "result": "Demonstrates that scatterers with small support or high-curvature boundaries radiate at any frequency, enabling unique determination from single far-field measurements.", "conclusion": "The study provides novel insights into scatterer properties and establishes practical uniqueness results for elastic wave scattering problems."}}
{"id": "2508.04853", "pdf": "https://arxiv.org/pdf/2508.04853", "abs": "https://arxiv.org/abs/2508.04853", "authors": ["Haoyu Zhang", "Shihao Zhang", "Ian Colbert", "Rayan Saab"], "title": "Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.NA", "math.IT", "math.NA", "68T07, 68W25, 62M45, 68Q25"], "comment": null, "summary": "Post-training quantization (PTQ) has become a crucial tool for reducing the\nmemory and compute costs of modern deep neural networks, including large\nlanguage models (LLMs). Among PTQ algorithms, the OPTQ framework-also known as\nGPTQ-has emerged as a leading method due to its computational efficiency and\nstrong empirical performance. Despite its widespread adoption, however, OPTQ\nlacks rigorous quantitative theoretical guarantees. This paper presents the\nfirst quantitative error bounds for both deterministic and stochastic variants\nof OPTQ, as well as for Qronos, a recent related state-of-the-art PTQ\nalgorithm. We analyze how OPTQ's iterative procedure induces quantization error\nand derive non-asymptotic 2-norm error bounds that depend explicitly on the\ncalibration data and a regularization parameter that OPTQ uses. Our analysis\nprovides theoretical justification for several practical design choices,\nincluding the widely used heuristic of ordering features by decreasing norm, as\nwell as guidance for selecting the regularization parameter. For the stochastic\nvariant, we establish stronger infinity-norm error bounds, which enable control\nover the required quantization alphabet and are particularly useful for\ndownstream layers and nonlinearities. Finally, we extend our analysis to\nQronos, providing new theoretical bounds, for both its deterministic and\nstochastic variants, that help explain its empirical advantages.", "AI": {"tldr": "The paper provides the first quantitative error bounds for OPTQ (GPTQ) and Qronos, explaining their performance and guiding practical design choices.", "motivation": "Despite OPTQ's widespread use, it lacks theoretical guarantees. This paper aims to fill that gap by analyzing its error bounds and extending the analysis to Qronos.", "method": "The authors derive non-asymptotic 2-norm and infinity-norm error bounds for deterministic and stochastic variants of OPTQ and Qronos, analyzing how quantization error is induced.", "result": "The analysis justifies practical design choices (e.g., feature ordering by norm) and provides guidance for parameter selection. Stronger infinity-norm bounds for stochastic variants improve control over quantization.", "conclusion": "The paper offers rigorous theoretical support for OPTQ and Qronos, enhancing understanding and practical application of these PTQ methods."}}
{"id": "2508.05345", "pdf": "https://arxiv.org/pdf/2508.05345", "abs": "https://arxiv.org/abs/2508.05345", "authors": ["Pravan Omprakash", "Gwan Yeong Jung", "Guodong Ren", "Rohan Mishra"], "title": "Hole-doping reduces the coercive field in ferroelectric hafnia", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Ferroelectric hafnia holds promise for next-generation memory and logic\napplications because of its CMOS compatibility. However, the high coercive\nfield required for polarization switching in hafnia remains a critical\nchallenge for efficient device operations. Using first-principles calculations\nand phenomenological modeling, we predict that hole doping can reduce the\ncoercive field from 8 MV/cm in undoped hafnia to 6 MV/cm in hafnia doped with\n0.2 holes per formula unit (f.u.). In the absence of doping, the reversal of\npolarization of the Pca21 phase is preferred through the non-polar, tetragonal\nP42/nmc phase. This switching pathway involves the coupling of three hard\ndistortion modes that render undoped hafnia as an improper ferroelectric. The\noverall energy barrier through this pathway remains unchanged (80 meV/f.u.)\nupon hole doping. However, the introduction of holes hardens the polar\ndistortion mode that connects the polar Pca21 phase to the non-polar,\northorhombic Pbcm phase, and reduces the energy barrier from 180 meV/f.u. in\nundoped hafnia to 80 meV/f.u. at 0.2 holes/f.u.. Overall, hole doping makes the\nlatter switching pathway through the Pbcm phase competitive, and renders hafnia\nas a proper ferroelectric with a lower coercive field.", "AI": {"tldr": "Hole doping reduces the coercive field in ferroelectric hafnia, making it more efficient for memory and logic applications.", "motivation": "The high coercive field in hafnia hinders efficient device operations, prompting exploration of doping to mitigate this issue.", "method": "First-principles calculations and phenomenological modeling were used to study the effects of hole doping on hafnia's ferroelectric properties.", "result": "Hole doping lowers the coercive field from 8 MV/cm to 6 MV/cm and alters the preferred polarization switching pathway, reducing energy barriers.", "conclusion": "Hole doping transforms hafnia into a proper ferroelectric with a lower coercive field, enhancing its potential for practical applications."}}
{"id": "2508.05478", "pdf": "https://arxiv.org/pdf/2508.05478", "abs": "https://arxiv.org/abs/2508.05478", "authors": ["Alina Chertock", "Roman Shvydkoy", "Trevor Teolis"], "title": "Modulation of the Monokinetic Limit for Models of Collective Dynamics", "categories": ["math.AP", "cs.NA", "math.NA", "37A60, 92D50"], "comment": null, "summary": "In this work, we perform modulation analysis of monokinetic limits from the\nkinetic Cucker- Smale model to the pressureless Euler alignment system. Two\nregimes are considered -- a strong Fokker- Planck force with vanishing noise\nand Knudsen number, and a pure noiseless Vlasov scheme. In the former case, we\ndemonstrate convergence of the modulated profile to the standard Gaussian\ndistribution, while in the latter case, the distribution converges to a profile\nsatisfying an explicit transport equation along limiting characteristics.", "AI": {"tldr": "Analysis of monokinetic limits from the kinetic Cucker-Smale model to the pressureless Euler alignment system, comparing two regimes: strong Fokker-Planck force and pure noiseless Vlasov scheme.", "motivation": "To understand the transition from kinetic models to macroscopic systems and analyze convergence properties under different regimes.", "method": "Modulation analysis is performed for two regimes: (1) strong Fokker-Planck force with vanishing noise and Knudsen number, (2) pure noiseless Vlasov scheme.", "result": "In the first regime, the modulated profile converges to a Gaussian distribution. In the second, it converges to a profile satisfying a transport equation along limiting characteristics.", "conclusion": "The study provides insights into the behavior of monokinetic limits under different conditions, linking kinetic and macroscopic descriptions."}}
{"id": "2508.04917", "pdf": "https://arxiv.org/pdf/2508.04917", "abs": "https://arxiv.org/abs/2508.04917", "authors": ["Atharva Gondhalekar", "Kjetil Haugen", "Thomas Gibson", "Wu-chun Feng"], "title": "Mapping Sparse Triangular Solves to GPUs via Fine-grained Domain Decomposition", "categories": ["cs.PF", "cs.NA", "math.NA", "G.1.3; D.1.3"], "comment": "14 pages, 14 figures", "summary": "Sparse linear systems are typically solved using preconditioned iterative\nmethods, but applying preconditioners via sparse triangular solves introduces\nbottlenecks due to irregular memory accesses and data dependencies. This work\nleverages fine-grained domain decomposition to adapt triangular solves to the\nGPU architecture. We develop a fine-grained domain decomposition strategy that\ngenerates non-overlapping subdomains, increasing parallelism in the application\nof preconditioner at the expense of a modest increase in the iteration count\nfor convergence. Each subdomain is assigned to a thread block and is sized such\nthat the subdomain vector fits in the GPU shared memory, eliminating the need\nfor inter-block synchronization and reducing irregular global memory accesses.\nCompared to other state-of-the-art implementations using the ROCm$^{\\text{TM}}$\nsoftware stack, we achieve a 10.7$\\times$ speedup for triangular solves and a\n3.2$\\times$ speedup for the ILU0-preconditioned biconjugate gradient stabilized\n(BiCGSTAB) solver on the AMD Instinct$^{\\text{TM}}$ MI210 GPU.", "AI": {"tldr": "The paper proposes a fine-grained domain decomposition method to optimize sparse triangular solves on GPUs, achieving significant speedups in preconditioned iterative solvers.", "motivation": "Sparse triangular solves in preconditioned iterative methods create bottlenecks due to irregular memory access and data dependencies, which this work addresses for GPU architectures.", "method": "A fine-grained domain decomposition strategy is developed, creating non-overlapping subdomains assigned to GPU thread blocks. This reduces global memory access and eliminates inter-block synchronization.", "result": "The method achieves a 10.7\u00d7 speedup for triangular solves and a 3.2\u00d7 speedup for the ILU0-preconditioned BiCGSTAB solver on an AMD MI210 GPU.", "conclusion": "The approach effectively adapts triangular solves to GPUs, balancing increased parallelism with a modest rise in iteration count for convergence."}}
{"id": "2508.05528", "pdf": "https://arxiv.org/pdf/2508.05528", "abs": "https://arxiv.org/abs/2508.05528", "authors": ["James F. Lutsko"], "title": "The use of open boundaries in stochastic hydrodynamic models of nucleation", "categories": ["cond-mat.stat-mech", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Stochastic hydrodynamics is a central tool in the study of first order phase\ntransitions at a fundamental level. Combined with sophisticated free energy\nmodels, e.g. as developed in classical Density Functional Theory, complex\nprocesses such as crystallization can be modeled and information such as free\nenergy barriers, nucleation pathways and the unstable eigenvector and\neigenvalues determined. The latter are particularly interesting as they play\nkey roles in defining the natural (unbiased) order parameter and the nucleation\nrate respectively. As is often the case, computational realities restrict the\nsize of system that can be modeled and this makes it difficult to achieve\nexperimental conditions for which the volume is effectively infinite. In this\npaper, the use of open boundary conditions is discussed. By using an open\nsystem, the calculations become much closer to experimental conditions however,\nthe introduction of open boundary conditions raises a number of questions\nconcerning the stochastic model such as whether the fluctuation-dissipation\nrelation is preserved and whether stationary points on the free energy surface\nremain stationary points of the dynamics.", "AI": {"tldr": "The paper explores stochastic hydrodynamics for modeling phase transitions, focusing on open boundary conditions to better match experimental conditions, while addressing challenges like preserving fluctuation-dissipation relations.", "motivation": "To bridge the gap between computational models and experimental conditions by using open boundary conditions in stochastic hydrodynamics.", "method": "Employing stochastic hydrodynamics with open boundary conditions and analyzing their impact on the model's properties.", "result": "Open boundary conditions bring calculations closer to experimental conditions but raise questions about model consistency.", "conclusion": "Open boundary conditions are promising but require further validation to ensure model integrity."}}
{"id": "2508.05481", "pdf": "https://arxiv.org/pdf/2508.05481", "abs": "https://arxiv.org/abs/2508.05481", "authors": ["Gilles A. Francfort", "Alessandro Giacomini", "Scott Weady"], "title": "Velocity optimization of self-equilibrated obstacles in a two-dimensional viscous flow", "categories": ["math.AP"], "comment": null, "summary": "An obstacle is immersed in an externally driven 2D Stokes or Navier-Stokes\nfluid. We study the self-equilibration conditions for that obstacle under\nsteady state assumptions on the flow. We then seek to optimize the\ntranslational and/or angular velocity of the obstacle by varying its shape. To\nallow general variations, we must consider a very large class of obstacles for\nwhich the notion of trace is meaningless. This forces us to revisit the notion\nof self-equilibration for both Stokes and Navier-Stokes in a measure theoretic\nenvironment.", "AI": {"tldr": "Study of self-equilibration and shape optimization for obstacles in 2D Stokes/Navier-Stokes fluids under steady-state conditions, using measure theory.", "motivation": "To understand and optimize obstacle motion (translational/angular velocity) in fluid dynamics by varying its shape, addressing challenges in general shape variations.", "method": "Revisits self-equilibration conditions in measure theory for Stokes and Navier-Stokes fluids, accommodating a large class of obstacles.", "result": "Develops a framework for optimizing obstacle velocity through shape variation in a measure-theoretic setting.", "conclusion": "Provides a theoretical foundation for shape optimization in fluid dynamics, extending applicability to a broader class of obstacles."}}
{"id": "2508.05141", "pdf": "https://arxiv.org/pdf/2508.05141", "abs": "https://arxiv.org/abs/2508.05141", "authors": ["Yahong Yang", "Juncai He"], "title": "Deep Neural Networks with General Activations: Super-Convergence in Sobolev Norms", "categories": ["cs.LG", "cs.NA", "math.NA", "68T07, 41A30, 35Q68", "F.1.1; G.1.2; I.2.6"], "comment": "45 pages, 4 figures", "summary": "This paper establishes a comprehensive approximation result for deep\nfully-connected neural networks with commonly-used and general activation\nfunctions in Sobolev spaces $W^{n,\\infty}$, with errors measured in the\n$W^{m,p}$-norm for $m < n$ and $1\\le p \\le \\infty$. The derived rates surpass\nthose of classical numerical approximation techniques, such as finite element\nand spectral methods, exhibiting a phenomenon we refer to as\n\\emph{super-convergence}. Our analysis shows that deep networks with general\nactivations can approximate weak solutions of partial differential equations\n(PDEs) with superior accuracy compared to traditional numerical methods at the\napproximation level. Furthermore, this work closes a significant gap in the\nerror-estimation theory for neural-network-based approaches to PDEs, offering a\nunified theoretical foundation for their use in scientific computing.", "AI": {"tldr": "Deep neural networks with general activations achieve super-convergence in approximating PDE solutions, outperforming classical methods like finite elements and spectral methods.", "motivation": "To bridge the gap in error-estimation theory for neural networks in PDEs and demonstrate their superior approximation capabilities.", "method": "Analysis of deep fully-connected neural networks in Sobolev spaces, measuring errors in the $W^{m,p}$-norm for $m < n$.", "result": "Deep networks surpass classical methods in accuracy, exhibiting super-convergence for PDE solutions.", "conclusion": "This work provides a unified theoretical foundation for neural networks in scientific computing, closing a gap in PDE approximation theory."}}
{"id": "2508.05538", "pdf": "https://arxiv.org/pdf/2508.05538", "abs": "https://arxiv.org/abs/2508.05538", "authors": ["Junpei Oba", "Hsin-Pin Lo", "Yasuhiro Yamada", "Takayuki Matsui", "Takuya Ikuta", "Yuya Yonezu", "Toshimori Honjo", "Seiji Kajita", "Hiroki Takesue"], "title": "Model-based framework for automated quantification of error sources in quantum state tomography", "categories": ["quant-ph", "physics.comp-ph", "physics.optics"], "comment": "18 pages, 12 figures, 3 tables", "summary": "High-quality quantum state generation is essential for advanced quantum\ninformation processing, including quantum communication, quantum sensing, and\nquantum computing. In practice, various error sources degrade the quality of\nquantum states, and quantum state tomography (QST) is a standard diagnostic\ntool. However, in QST, multiple error sources gather in a single density\nmatrix, making it difficult to identify individual error sources. To address\nthis problem, we propose an automated method for quantifying error sources by\ncombining simulation and parameter optimization to reproduce the experimental\ndensity matrix. We focus on the experimental generation of time-bin entangled\nphoton pairs, for which we model the relevant error sources and simulate the\ndensity matrix with adjustable model parameters, thereby optimizing the\nparameters and minimizing the trace distance to the experimental data.\nOptimization of the parameters reduced the trace distance from 0.177 to 0.024,\nindicating that our modeled error sources explain 86% of the errors. Reducing\nthe predicted error sources improves the state quality, consistent with our\npredictions and thus validating the proposed method. In addition, the modular\nstructure of this framework makes it applicable to other quantum platforms,\nsuch as superconducting qubits, atoms, and solid-state spins.", "AI": {"tldr": "Proposes an automated method to quantify error sources in quantum state generation by combining simulation and parameter optimization, validated with time-bin entangled photon pairs.", "motivation": "High-quality quantum states are crucial for quantum technologies, but error sources in QST obscure individual causes, necessitating a method to identify and quantify them.", "method": "Combines simulation and parameter optimization to model error sources and reproduce experimental density matrices, focusing on time-bin entangled photon pairs.", "result": "Reduced trace distance from 0.177 to 0.024, explaining 86% of errors, improving state quality and validating the method.", "conclusion": "The modular framework is effective for identifying error sources and applicable to various quantum platforms."}}
{"id": "2508.05533", "pdf": "https://arxiv.org/pdf/2508.05533", "abs": "https://arxiv.org/abs/2508.05533", "authors": ["Han Cheng", "Shanlin Huang", "Avy Soffer", "Zhao Wu"], "title": "The $L^p$ boundedness of wave operators for the Laplace operator with finite rank perturbations", "categories": ["math.AP", "math.CA"], "comment": "33 pages", "summary": "This paper investigates the $L^p$ boundedness of wave operators for the\nLaplace operator with finite rank perturbations \\begin{equation*}\n  H=-\\Delta+\\sum\\limits_{i=1}^N\\langle\\cdot\\,, \\varphi_i\\rangle \\varphi_i\n\\qquad \\mbox{on}\\,\\,\\, \\R^d. \\end{equation*} For dimensions $d\\ge 3$, we prove\nthat the wave operators $W_\\pm(H,H_0)$ are bounded on $L^p$ for the full range\n$1\\le p\\le \\infty$. This extends the work of Nier and the third author\n\\cite{NS} by resolving the previously unexplored question of boundedness at the\nendpoint cases $p=1$ and $p=\\infty$. In lower dimensions $d = 1, 2$, we\nestablish the $L^p$-boundedness of the wave operators for the first time.\nFurthermore, we reveal an intriguing dichotomy in the endpoint case $p = 1$:\n\\begin{itemize}\n  \\item If $\\int_{\\mathbb{R}^d} \\varphi_i(x) \\, \\d x = 0$ holds for every $1\\le\ni\\le N$, then the wave operators are bounded on $L^p(\\mathbb{R}^d)$ for all $1\n\\leq p \\leq \\infty$.\n  \\item If there exists at least one $i$ ($1\\le i\\le N$) such that\n$\\int_{\\mathbb{R}^d}\\varphi_i(x)\\d x\\ne0$, then the wave operators remain\nbounded for $1 < p < \\infty$ and satisfy weak type $(1,1)$ estimates, but fail\nto be bounded on $L^1(\\mathbb{R}^d)$. \\end{itemize}", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.05619", "pdf": "https://arxiv.org/pdf/2508.05619", "abs": "https://arxiv.org/abs/2508.05619", "authors": ["Bo Wen"], "title": "The Missing Reward: Active Inference in the Era of Experience", "categories": ["cs.AI", "nlin.AO", "physics.bio-ph", "physics.comp-ph", "physics.hist-ph"], "comment": null, "summary": "This paper argues that Active Inference (AIF) provides a crucial foundation\nfor developing autonomous AI agents capable of learning from experience without\ncontinuous human reward engineering. As AI systems begin to exhaust\nhigh-quality training data and rely on increasingly large human workforces for\nreward design, the current paradigm faces significant scalability challenges\nthat could impede progress toward genuinely autonomous intelligence. The\nproposal for an ``Era of Experience,'' where agents learn from self-generated\ndata, is a promising step forward. However, this vision still depends on\nextensive human engineering of reward functions, effectively shifting the\nbottleneck from data curation to reward curation. This highlights what we\nidentify as the \\textbf{grounded-agency gap}: the inability of contemporary AI\nsystems to autonomously formulate, adapt, and pursue objectives in response to\nchanging circumstances. We propose that AIF can bridge this gap by replacing\nexternal reward signals with an intrinsic drive to minimize free energy,\nallowing agents to naturally balance exploration and exploitation through a\nunified Bayesian objective. By integrating Large Language Models as generative\nworld models with AIF's principled decision-making framework, we can create\nagents that learn efficiently from experience while remaining aligned with\nhuman values. This synthesis offers a compelling path toward AI systems that\ncan develop autonomously while adhering to both computational and physical\nconstraints.", "AI": {"tldr": "Active Inference (AIF) offers a foundation for autonomous AI agents to learn without human reward engineering, addressing scalability challenges in current paradigms.", "motivation": "Current AI systems face scalability issues due to reliance on human reward engineering and high-quality training data, hindering autonomous intelligence.", "method": "Proposes AIF to replace external rewards with intrinsic free energy minimization, integrating Large Language Models for efficient learning.", "result": "AIF bridges the grounded-agency gap, enabling autonomous objective formulation and adaptation while aligning with human values.", "conclusion": "AIF combined with generative models presents a viable path for autonomous, scalable AI systems adhering to constraints."}}
{"id": "2508.05551", "pdf": "https://arxiv.org/pdf/2508.05551", "abs": "https://arxiv.org/abs/2508.05551", "authors": ["Tristan C. Collins", "Benjy Firester"], "title": "On a general class of free boundary Monge-Amp\u00e8re equations", "categories": ["math.AP", "math.DG"], "comment": null, "summary": "We solve a general class of free boundary Monge-Amp\\`ere equations given by\n\\[\n  \\det D^2u = \\lambda \\dfrac{f(-u)}{g(u^\\star)h(\\nabla u)}\\chi_{\\{u<0\\}} \\;\n\\text{ in } \\mathbb{R}^n, \\quad \\nabla u (\\mathbb{R}^n) = P \\] where $P$ is a\nbounded convex set containing the origin, and $h>0$ on $P$. We consider\napplications to optimal transport with degenerate densities, Monge-Amp\\`ere\neigenvalue problems, and geometric problems including a hemispherical Minkowski\nproblem and free boundary K\\\"ahler-Ricci solitons on toric Fano manifolds.", "AI": {"tldr": "The paper addresses a class of free boundary Monge-Amp\u00e8re equations with applications in optimal transport, eigenvalue problems, and geometric problems.", "motivation": "The study aims to generalize solutions to Monge-Amp\u00e8re equations and explore their applications in diverse mathematical contexts.", "method": "The authors solve the given Monge-Amp\u00e8re equation with specific boundary conditions and constraints, leveraging convex analysis and geometric methods.", "result": "Solutions are derived for the equation, with applications demonstrated in optimal transport, eigenvalue problems, and geometric settings like the hemispherical Minkowski problem.", "conclusion": "The work extends the understanding of Monge-Amp\u00e8re equations and their utility in solving complex mathematical and geometric problems."}}
{"id": "2508.05573", "pdf": "https://arxiv.org/pdf/2508.05573", "abs": "https://arxiv.org/abs/2508.05573", "authors": ["Pierre Germain", "Simon L. Rydin Myerson", "Daniel Pezzi"], "title": "Bounds for spectral projectors on the three-dimensional torus", "categories": ["math.AP", "math.CA", "42A45, 42B15 (Primary), 11L07, 11H06, 11P21 (Secondary)"], "comment": "51 pages, 1 figure", "summary": "We study $L^2$ to $L^p$ operator norms of spectral projectors for the\nEuclidean Laplacian on the torus in the case where the spectral window is\nnarrow. With a window of constant size this is a classical result of Sogge; in\nthe small-window limit we are left with $L^p$ norms of eigenfunctions of the\nLaplacian, as considered for instance by Bourgain. For the three-dimensional\ntorus we prove new cases of a previous conjecture of the first two authors\nconcerning the size of these norms; we also refine certain prior results to\nremove $\\epsilon$-losses in all dimensions. We use methods from number theory:\nthe geometry of numbers, the circle method and exponential sum bounds due to\nGuo. We complement these techniques with height splitting and a bilinear\nargument to prove sharp results.\n  We exposit on the various techniques used and their limitations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
