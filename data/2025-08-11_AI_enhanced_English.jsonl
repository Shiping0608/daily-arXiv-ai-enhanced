{"id": "2508.05793", "pdf": "https://arxiv.org/pdf/2508.05793", "abs": "https://arxiv.org/abs/2508.05793", "authors": ["Moshen Hu", "Lucas Onisk"], "title": "On the Choice of Subspace for the Quasi-minimal Residual Method for Linear Inverse Problems", "categories": ["math.NA", "cs.NA", "65F22, 65F10, 15A29"], "comment": "21 pages", "summary": "Inverse problems arise in various scientific and engineering applications,\nnecessitating robust numerical methods for their solution. In this work, we\nconsider the effectiveness of Krylov subspace iterative methods, including\nGMRES, QMR, and their range restricted variants for solving linear discrete\nill-posed problems. We analyze the impact of subspace selection on solution\nquality. Our findings indicate that range restricted QMR can outperform\nstandard QMR, and confirm the previously observed behavior that range\nrestricted GMRES can be superior to conventional GMRES in terms of\napproximation efficacy. Notably, range restricted QMR demonstrates a key\nadvantage over GMRES with respect to range restricted QMR's singular spectrum\nwhich can make the method less sensitive to errors that are naturally present\nmaking it particularly effective when the noise level in the problem is\nuncertain.", "AI": {"tldr": "The paper evaluates Krylov subspace methods (GMRES, QMR, and their range-restricted variants) for solving linear discrete ill-posed problems, finding range-restricted QMR superior in certain cases.", "motivation": "To assess the effectiveness of Krylov subspace methods, particularly range-restricted variants, in solving ill-posed linear problems and their sensitivity to noise.", "method": "Analysis of GMRES, QMR, and their range-restricted variants, focusing on subspace selection and its impact on solution quality.", "result": "Range-restricted QMR outperforms standard QMR, and range-restricted GMRES is superior to conventional GMRES. Range-restricted QMR is less sensitive to errors, especially with uncertain noise levels.", "conclusion": "Range-restricted Krylov subspace methods, particularly QMR, offer improved performance for ill-posed problems, especially under uncertain noise conditions."}}
{"id": "2508.05948", "pdf": "https://arxiv.org/pdf/2508.05948", "abs": "https://arxiv.org/abs/2508.05948", "authors": ["Shanheng Han", "Lei-Hong Zhang", "Ren-Cang Li"], "title": "A Minimal Perturbation Approach For The Rectangular Multiparameter Eigenvalue Problem", "categories": ["math.NA", "cs.NA", "65F15, 65F20, 15A18, 47A75, 65N35"], "comment": null, "summary": "The rectangular multiparameter eigenvalue problem (RMEP) involves rectangular\ncoefficient matrices (usually with more rows than columns) and may potentially\nhave no solution in its original form. A minimal perturbation framework is\nproposed to defines approximate solutions. Computationally, two particular\nscenarios are considered: computing one approximate eigen-tuple or a complete\nset of approximate eigen-tuples. For computing one approximate eigen-tuple, an\nalternating iterative scheme with proven convergence is devised, while for a\ncomplete set of approximate eigen-tuples, the framework leads to a standard MEP\n(RMEP with square coefficient matrices) for numerical solutions. The proposed\napproach is validated on RMEPs from discretizing the multiparameter\nSturm-Liouville equation and the Helmholtz equations by the least-squares\nspectral method.", "AI": {"tldr": "A minimal perturbation framework is proposed to solve the rectangular multiparameter eigenvalue problem (RMEP) by defining approximate solutions, with methods for computing single or complete sets of eigen-tuples.", "motivation": "The RMEP involves rectangular matrices and may lack solutions in its original form, necessitating a framework for approximate solutions.", "method": "An alternating iterative scheme for single eigen-tuples and transforming RMEP into a standard MEP for complete sets.", "result": "Validated on RMEPs from discretizing multiparameter Sturm-Liouville and Helmholtz equations using least-squares spectral method.", "conclusion": "The proposed framework effectively addresses RMEPs, providing practical solutions for both single and complete eigen-tuples."}}
{"id": "2508.05958", "pdf": "https://arxiv.org/pdf/2508.05958", "abs": "https://arxiv.org/abs/2508.05958", "authors": ["Yingzhou Li", "Jingyu Liu"], "title": "Hierarchical Tucker Low-Rank Matrices: Construction and Matrix-Vector Multiplication", "categories": ["math.NA", "cs.NA"], "comment": "25 pages, 10 figures", "summary": "In this paper, a hierarchical Tucker low-rank (HTLR) matrix is proposed to\napproximate non-oscillatory kernel functions in linear complexity. The HTLR\nmatrix is based on the hierarchical matrix, with the low-rank blocks replaced\nby Tucker low-rank blocks. Using high-dimensional interpolation as well as\ntensor contractions, algorithms for the construction and matrix-vector\nmultiplication of HTLR matrices are proposed admitting linear and quasi-linear\ncomplexities respectively. Numerical experiments demonstrate that the HTLR\nmatrix performs well in both memory and runtime. Furthermore, the HTLR matrix\ncan also be applied on quasi-uniform grids in addition to uniform grids,\nenhancing its versatility.", "AI": {"tldr": "Proposes a hierarchical Tucker low-rank (HTLR) matrix for efficient approximation of non-oscillatory kernel functions with linear complexity.", "motivation": "To improve efficiency in approximating non-oscillatory kernel functions by reducing memory and runtime costs.", "method": "Uses hierarchical matrix structure with Tucker low-rank blocks, employing high-dimensional interpolation and tensor contractions for construction and matrix-vector multiplication.", "result": "Numerical experiments show HTLR matrices perform well in memory and runtime, and work on both uniform and quasi-uniform grids.", "conclusion": "HTLR matrices offer efficient, versatile solutions for kernel function approximation with linear complexity."}}
{"id": "2508.06049", "pdf": "https://arxiv.org/pdf/2508.06049", "abs": "https://arxiv.org/abs/2508.06049", "authors": ["Benjamin Mann", "Ulrich R\u00fcde"], "title": "$k\\ell$-refinement: An adaptive mesh refinement scheme for hiearchical hybrid grids", "categories": ["math.NA", "cs.NA", "65N50, 65N55"], "comment": "Submitted to \"Applications of Mathematics\"", "summary": "This work introduces an adaptive mesh refinement technique for hierarchical\nhybrid grids with the goal to reach scalability and maintain excellent\nperformance on massively parallel computer systems. On the block structured\nhierarchical hybrid grids, this is accomplished by using classical,\nunstructured refinement only on the coarsest level of the hierarchy, while\nkeeping the number of structured refinement levels constant on the whole\ndomain. This leads to a compromise where the excellent performance\ncharacteristics of hierarchical hybrid grids can be maintained at the price\nthat the flexibility of generating locally refined meshes is constrained.\nFurthermore, mesh adaptivity often relies on a posteriori error estimators or\nerror indicators that tend to become computationally expensive. Again with the\ngoal of preserving scalability and performance, a method is proposed that\nleverages the grid hierarchy and the full multigrid scheme that generates a\nnatural sequence of approximations on the nested hierarchy of grids. This\npermits to compute a cheap error estimator that is well-suited for large-scale\nparallel computing. We present the theoretical foundations for both global and\nlocal error estimates and present a rigorous analysis of their effectivity. The\nproposed method, including error estimator and the adaptive coarse grid\nrefinement, is implemented in the finite element framework HyTeG. Extensive\nnumerical experiments are conducted to validate the effectiveness, as well as\nperformance and scalability.", "AI": {"tldr": "An adaptive mesh refinement technique for hierarchical hybrid grids is introduced, balancing scalability and performance on parallel systems by limiting unstructured refinement to the coarsest level and using a multigrid-based error estimator.", "motivation": "To achieve scalability and maintain high performance on massively parallel systems while addressing the computational cost of traditional mesh adaptivity methods.", "method": "Combines classical unstructured refinement on the coarsest level with structured refinement, leveraging grid hierarchy and multigrid schemes for efficient error estimation.", "result": "The method maintains performance and scalability, validated through numerical experiments in the HyTeG framework.", "conclusion": "The proposed technique effectively balances flexibility and performance, offering a scalable solution for large-scale parallel computing."}}
{"id": "2508.05642", "pdf": "https://arxiv.org/pdf/2508.05642", "abs": "https://arxiv.org/abs/2508.05642", "authors": ["Joonbeom Kim", "Eunji Jun"], "title": "A second-order particle Fokker-Planck-Master method for diatomic gas flows", "categories": ["physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "The direct simulation Monte Carlo (DSMC) method is widely used to describe\nrarefied gas flows. The DSMC method accounts for the transport and collisions\nof computational particles, resulting in higher computational costs in the\ncontinuum regime. The Fokker-Planck (FP) model approximates particle collisions\nas Brownian motion to reduce computational cost. Advanced FP models have been\ndeveloped to enhance physical fidelity, ensuring the correct Prandtl number and\nthe H-theorem. The FP model has further been extended to handle diatomic gases,\nsuch as the Fokker-Planck-Master (FPM) model. Alongside these developments in\nmodeling, computational efficiency has also been improved by achieving\nsecond-order spatial and temporal accuracy, as demonstrated in the unified\nstochastic particle FP (USP-FP) method. However, these accuracy improvements\nhave not yet been extended to diatomic gases, which are essential for\nengineering applications such as atmospheric reentry. This study proposes a\nunified stochastic particle Fokker-Planck-Master (USP-FPM) method for diatomic\ngases that achieves second-order accuracy in both time and space. Temporal\naccuracy is enhanced by reproducing second-order energy, viscous stress, and\nheat flux relaxations. Spatial accuracy is improved by employing a first-order\npolynomial reconstruction method. Three test cases are investigated:\nhomogeneous relaxation, Poiseuille flow, and hypersonic flow around a cylinder.\nThe results show that the USP-FPM method provides accurate solutions even with\ncoarser cell sizes and larger time steps compared to the DSMC and FPM methods.\nIn particular, for the hypersonic flow around a cylinder, the USP-FPM method\nachieves a speed-up factor of 28 compared to the DSMC method, while maintaining\naccuracy.", "AI": {"tldr": "The study introduces the USP-FPM method for diatomic gases, achieving second-order accuracy in time and space, outperforming DSMC and FPM in computational efficiency while maintaining accuracy.", "motivation": "Existing FP models lack second-order accuracy for diatomic gases, which are crucial for engineering applications like atmospheric reentry.", "method": "The USP-FPM method enhances temporal accuracy with second-order relaxations and spatial accuracy via polynomial reconstruction. Tested on homogeneous relaxation, Poiseuille flow, and hypersonic cylinder flow.", "result": "USP-FPM provides accurate solutions with coarser cells and larger time steps, achieving a 28x speed-up over DSMC for hypersonic flow.", "conclusion": "The USP-FPM method is a computationally efficient and accurate alternative for simulating diatomic gas flows, especially in high-speed applications."}}
{"id": "2508.05780", "pdf": "https://arxiv.org/pdf/2508.05780", "abs": "https://arxiv.org/abs/2508.05780", "authors": ["Paulo M. Carvalho-Neto", "Cicero L. Frota", "Juan C. Oyola Ballesteros", "Pedro G. P. Torelli"], "title": "Energy Estimates for Fractional Evolution Equations", "categories": ["math.AP", "26A33, 35R11, 35A15, 35K05"], "comment": null, "summary": "This work presents a more broadly applicable version of an energy inequality\nfor weak solutions of evolution equations involving fractional time\nderivatives. Unlike the classical identity that relates the time derivative of\nthe squared norm to the inner product of the derivative and the function\nitself, its fractional analogue typically requires a regularity condition that\nis difficult to verify in practice. We revisit this inequality in the setting\nof square integrable functions over an open domain and provide a new proof\nbased solely on the assumption that the solution is essentially bounded in\ntime. In our approach, the required regularity emerges naturally within the\nargument, rather than being imposed beforehand. This refinement expands the\nscope of applicability of the inequality and offers a rigorous foundation for\nusing the Faedo Galerkin method in problems governed by fractional evolution\nequations. As an application, we prove existence, uniqueness, and regularity of\nweak solutions to the fractional heat equation.", "AI": {"tldr": "A refined energy inequality for weak solutions of fractional evolution equations is presented, removing the need for difficult-to-verify regularity conditions and enabling broader applicability.", "motivation": "Address the impracticality of verifying regularity conditions in classical fractional energy inequalities.", "method": "Revisits the inequality for square integrable functions, using a new proof based on essential boundedness in time.", "result": "The refined inequality naturally incorporates regularity, expanding its applicability and supporting the Faedo Galerkin method.", "conclusion": "The work provides a rigorous foundation for fractional evolution problems, demonstrated by proving existence, uniqueness, and regularity for the fractional heat equation."}}
{"id": "2508.05727", "pdf": "https://arxiv.org/pdf/2508.05727", "abs": "https://arxiv.org/abs/2508.05727", "authors": ["Heinz Isliker", "Loukas Vlahos"], "title": "Transport of Particles in Strongly Turbulent 3D Magnetized Plasmas", "categories": ["physics.plasm-ph", "astro-ph.HE"], "comment": "accepted for publication in Physics of Plasmas, August 2025; a review\n  with 42 pages, 43 figures", "summary": "In this review, we examine particle transport in strongly turbulent\nthree-dimensional (3D) magnetized plasmas, characterized by intense\n(large-amplitude) magnetic field fluctuations. Such environments naturally give\nrise to a network of coherent structures (CoSs), including current sheets,\nfilaments, shocks, switchbacks, and significant magnetic perturbations, which\ncritically influence particle dynamics at the kinetic level. Within this\nturbulent regime, two fundamental particle energization mechanisms emerge,\nstochastic acceleration and systematic acceleration. Systematic acceleration\nwithin open turbulent volumes promotes the development of power-law tails in\nenergy distributions. Our analysis distinguishes the roles of two electric\nfields: the perpendicular (or convective) fields, which drive stochastic\nheating via interactions with randomly moving scatterers, and the parallel\nelectric fields, which enable systematic particle acceleration in regions of\nstrong currents. Combined with accurate estimates of particle escape times in\nfinite volumes, the interplay of these mechanisms leads to the formation of\nKappa distributions. The transport properties differ significantly between the\ntwo energization modes. Stochastic energization follows Gaussian statistics and\ncan be effectively described by the Fokker-Planck equation. In contrast,\nsystematic acceleration exhibits Levy flight statistics, necessitating a\nfractional transport equation for an accurate description. Furthermore, the\nfractal spatial distribution of CoSs introduces deviations from traditional\ntransport models, influencing e.g. particle escape times. Systematic\nacceleration is most efficient during the early, high-energy phases of\nturbulence, while stochastic heating becomes dominant during the later stages,\ncontributing to gradual particle energization.", "AI": {"tldr": "The paper reviews particle transport in turbulent 3D magnetized plasmas, highlighting two energization mechanisms: stochastic and systematic acceleration, leading to distinct transport properties and energy distributions.", "motivation": "To understand particle dynamics in turbulent plasmas with intense magnetic fluctuations and coherent structures, which influence energization and transport.", "method": "Analysis of particle energization mechanisms (stochastic and systematic acceleration) and their interplay, using theoretical models like Fokker-Planck and fractional transport equations.", "result": "Stochastic acceleration follows Gaussian statistics, while systematic acceleration exhibits Levy flight statistics. The interplay forms Kappa distributions, with systematic acceleration dominating early turbulence and stochastic heating later.", "conclusion": "The study provides insights into particle transport in turbulent plasmas, emphasizing the roles of coherent structures and distinct energization mechanisms, with implications for modeling and understanding plasma behavior."}}
{"id": "2508.06217", "pdf": "https://arxiv.org/pdf/2508.06217", "abs": "https://arxiv.org/abs/2508.06217", "authors": ["Bingru Huang", "Falai Chen"], "title": "A Preliminary Study on the Dimensional Stability Classification of Polynomial Spline Spaces over T-meshes", "categories": ["math.NA", "cs.NA", "65D07"], "comment": null, "summary": "This paper introduces the concept of dimensional stability for spline spaces\nover T-meshes, providing the first mathematical definition and a preliminary\nclassification framework. We define dimensional stability as an invariant\nwithin the structurally isomorphic class, contingent on the rank stability of\nthe conformality matrix. Absolute stability is proposed via structurally\nsimilar maps to address topological and order structures. Through the\n$k$-partition decomposition of T-connected components and analysis of the CNDC,\nwe establish a correspondence between conformality vector spaces and rank\nstability. For diagonalizable T-meshes, decomposition into independent\none-dimensional T $l$-edges facilitates basis function construction, while\narbitrary T-meshes are partitioned into one- and two-dimensional components.\nThese findings lay the groundwork for understanding dimensional stability and\ndeveloping spline space basis functions.", "AI": {"tldr": "The paper defines dimensional stability for spline spaces over T-meshes, introduces a classification framework, and establishes a link between conformality vector spaces and rank stability. It also provides methods for basis function construction.", "motivation": "To mathematically define and classify dimensional stability for spline spaces over T-meshes, addressing topological and order structures.", "method": "Uses $k$-partition decomposition of T-connected components, analysis of CNDC, and structurally similar maps to propose absolute stability. Diagonalizable T-meshes are decomposed into one-dimensional T $l$-edges for basis construction.", "result": "Establishes a correspondence between conformality vector spaces and rank stability, enabling basis function construction for spline spaces.", "conclusion": "The findings provide a foundation for understanding dimensional stability and developing spline space basis functions."}}
{"id": "2508.05908", "pdf": "https://arxiv.org/pdf/2508.05908", "abs": "https://arxiv.org/abs/2508.05908", "authors": ["Shreshth A. Malik", "Tiarnan A. S. Doherty", "Benjamin Colmey", "Stephen J. Roberts", "Yarin Gal", "Paul A. Midgley"], "title": "Hybrid Physics-Machine Learning Models for Quantitative Electron Diffraction Refinements", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "High-fidelity electron microscopy simulations required for quantitative\ncrystal structure refinements face a fundamental challenge: while physical\ninteractions are well-described theoretically, real-world experimental effects\nare challenging to model analytically. To address this gap, we present a novel\nhybrid physics-machine learning framework that integrates differentiable\nphysical simulations with neural networks. By leveraging automatic\ndifferentiation throughout the simulation pipeline, our method enables\ngradient-based joint optimization of physical parameters and neural network\ncomponents representing experimental variables, offering superior scalability\ncompared to traditional second-order methods. We demonstrate this framework\nthrough application to three-dimensional electron diffraction (3D-ED) structure\nrefinement, where our approach learns complex thickness distributions directly\nfrom diffraction data rather than relying on simplified geometric models. This\nmethod achieves state-of-the-art refinement performance across synthetic and\nexperimental datasets, recovering atomic positions, thermal displacements, and\nthickness profiles with high fidelity. The modular architecture proposed can\nnaturally be extended to accommodate additional physical phenomena and extended\nto other electron microscopy techniques. This establishes differentiable hybrid\nmodeling as a powerful new paradigm for quantitative electron microscopy, where\nexperimental complexities have historically limited analysis.", "AI": {"tldr": "A hybrid physics-machine learning framework combines differentiable simulations with neural networks for high-fidelity electron microscopy, improving refinement of crystal structures.", "motivation": "Traditional methods struggle to model real-world experimental effects in electron microscopy, limiting quantitative analysis.", "method": "Integrates differentiable physical simulations with neural networks, enabling joint optimization of parameters and experimental variables via automatic differentiation.", "result": "Achieves state-of-the-art refinement in 3D electron diffraction, accurately recovering atomic positions, thermal displacements, and thickness profiles.", "conclusion": "Differentiable hybrid modeling is a powerful paradigm for overcoming experimental complexities in quantitative electron microscopy."}}
{"id": "2508.05788", "pdf": "https://arxiv.org/pdf/2508.05788", "abs": "https://arxiv.org/abs/2508.05788", "authors": ["Paulo M. Carvalho-Neto", "Cesar E. T. Ledesma"], "title": "There and Back Again: Revisiting the Failure of Concatenation in Mittag-Leffler Functions", "categories": ["math.AP", "math.CA", "26A33, 34A08, 33E12, 47D03"], "comment": null, "summary": "The function $t \\mapsto E_{\\alpha}(\\lambda t^\\alpha)$ is widely regarded as\nthe fractional analogue of the exponential function, yet its algebraic\nproperties remain poorly understood. In particular, standard references lack a\nrigorous proof of the failure of the semigroup property. In this work, we fill\nthis gap by providing an analytical proof that the semigroup property holds if\nand only if either $\\alpha = 1$ or $\\lambda = 0$. Our result establishes a\nprecise criterion for when Mittag-Leffler dynamics are compatible with\nsemigroup evolution, thereby emphasizing the intrinsic nonlocality of\nfractional-order differential equations.", "AI": {"tldr": "The paper proves that the semigroup property for the Mittag-Leffler function holds only if \u03b1=1 or \u03bb=0, highlighting the nonlocality of fractional-order dynamics.", "motivation": "To address the lack of rigorous proof for the failure of the semigroup property in the Mittag-Leffler function, a key fractional analogue of the exponential function.", "method": "Analytical proof demonstrating the conditions under which the semigroup property holds.", "result": "The semigroup property is valid only when \u03b1=1 or \u03bb=0.", "conclusion": "The study clarifies the nonlocal nature of fractional-order differential equations by establishing precise criteria for semigroup compatibility."}}
{"id": "2508.05837", "pdf": "https://arxiv.org/pdf/2508.05837", "abs": "https://arxiv.org/abs/2508.05837", "authors": ["Brendan McCluskey", "Jesse Griff-McMahon", "Daniel Haberberger", "Vicente Valenzuela-Villaseca", "Huws Landsberger", "William Fox"], "title": "Reconstruction of 2D line-integrated electron density using angular filter refractometry and a fast marching Eikonal solver", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Refraction of an optical probe beam by a plasma can be measured with angular\nfilter refractometry (AFR), which produces an image containing intensity\ncontours that correspond to curves of constant refraction angle. Further\nanalysis is required to reconstruct the underlying line-integrated electron\ndensity. Most prior efforts to calculate density from AFR data have been\nlimited to 1D analysis or forward-fitting techniques. In this paper, we detail\nthe use of a fast marching Eikonal solver to directly invert AFR data and\nobtain the 2D line-integrated electron density. The analysis method is first\nverified with synthetic data and then applied to laser-driven experiments of\nsingle and double plume expansion collected at the OMEGA EP Laser Facility. The\ncalculated densities agree with 1D results and are shown to be consistent with\nthe original AFR measurements via forward modeling. We also discuss how\nadditional measurements could improve the precision of this technique.", "AI": {"tldr": "A fast marching Eikonal solver is used to invert AFR data for 2D line-integrated electron density reconstruction, validated with synthetic and experimental data.", "motivation": "Prior methods for analyzing AFR data were limited to 1D or forward-fitting techniques, lacking direct 2D inversion.", "method": "A fast marching Eikonal solver is applied to directly invert AFR data, verified with synthetic data and tested in laser-driven experiments.", "result": "The method successfully reconstructs 2D electron density, agreeing with 1D results and validating via forward modeling.", "conclusion": "The technique is effective but could benefit from additional measurements for improved precision."}}
{"id": "2508.06235", "pdf": "https://arxiv.org/pdf/2508.06235", "abs": "https://arxiv.org/abs/2508.06235", "authors": ["Dmitriy Leykekhman", "Boris Vexler", "Jakob Wagner"], "title": "Fully discrete error analysis of finite element discretizations of time-dependent Stokes equations in a stream-function formulation", "categories": ["math.NA", "cs.NA", "76M10, 35G16, 65M15, 65M60, 65N30"], "comment": null, "summary": "In this paper we establish best approximation type error estimates for the\nfully discrete Galerkin solutions of the time-dependent Stokes problem using\nthe stream-function formulation. For the time discretization we use the\ndiscontinuous Galerkin method of arbitrary degree, whereas we present the space\ndiscretization in a general framework. This makes our result applicable for a\nwide variety of space discretization methods, provided some Galerkin\northogonality conditions are satisfied. As an example, conformal $C^1$ and\n$C^0$ interior penalty methods are covered by our analysis. The results do not\nrequire any additional regularity assumptions beyond the natural regularity\ngiven by the domain and data and can be used for optimal control problems.", "AI": {"tldr": "Best approximation error estimates for fully discrete Galerkin solutions of the time-dependent Stokes problem using stream-function formulation, with arbitrary-degree discontinuous Galerkin time discretization and general space discretization.", "motivation": "To provide error estimates for Galerkin solutions of the Stokes problem without requiring additional regularity assumptions, applicable to various space discretization methods.", "method": "Uses discontinuous Galerkin method for time discretization and a general framework for space discretization, ensuring Galerkin orthogonality.", "result": "Error estimates are derived without extra regularity assumptions, applicable to conformal C1 and C0 interior penalty methods, and useful for optimal control problems.", "conclusion": "The framework is versatile, covering multiple discretization methods and requiring only natural regularity, making it broadly applicable."}}
{"id": "2508.06012", "pdf": "https://arxiv.org/pdf/2508.06012", "abs": "https://arxiv.org/abs/2508.06012", "authors": ["Tim A. Linke", "Dane M. Sterbentz", "Jean-Pierre R. Delplanque", "Sebastien Hamel", "Kevin A. Korner", "Philip C. Myint", "Lorin X. Benedict", "Jonathan L. Belof"], "title": "Advancing Material Modeling in Hydrocodes Beyond Equations of State", "categories": ["physics.comp-ph"], "comment": "26 pages, 16 figures", "summary": "We present a multiscale simulation framework that couples the Finite Element\nMethod with molecular dynamics. Bypassing traditional equations of state (EOS)\nby using in-line atomistic simulations, the method offers the advantage of\nincorporating detailed microscale physics not easily represented with\ncoarse-grained models. Coupling consistency with the continuum code is ensured\nthrough the use of lifting and restriction operators, in line with\nheterogeneous multiscale methods. The concurrent continuum-atomistic framework\nis validated through comparison with experimental results and conventional EOS\nmodels, and demonstrated in a shock-driven hydrodynamic flow simulation under\nextreme conditions. We further evaluate the framework's usability by comparing\nit to state-of-the-art EOS models of deuterium. A computational performance\nstudy reveals that the atomistic EOS evaluation is a feasible alternative to\nconventional approaches, and demonstrates a weak scaling of 99% efficiency.\nThese results highlight the framework's potential for large-scale multiscale\nmodeling across a broad range of materials and conditions.", "AI": {"tldr": "A multiscale simulation framework combines Finite Element Method and molecular dynamics, bypassing traditional EOS for detailed microscale physics. Validated with experiments and EOS models, it shows high efficiency and potential for large-scale modeling.", "motivation": "To incorporate detailed microscale physics not easily represented by coarse-grained models and bypass traditional EOS limitations.", "method": "Couples Finite Element Method with molecular dynamics using lifting and restriction operators for consistency. Validated with experiments and conventional EOS models.", "result": "Demonstrated in shock-driven hydrodynamic flow, outperforming state-of-the-art EOS models with 99% weak scaling efficiency.", "conclusion": "The framework is efficient and viable for large-scale multiscale modeling across diverse materials and conditions."}}
{"id": "2508.05817", "pdf": "https://arxiv.org/pdf/2508.05817", "abs": "https://arxiv.org/abs/2508.05817", "authors": ["Ely Sandine"], "title": "Hunter-type Implosion Profiles for Energy-supercritical Polytropic Equations of State", "categories": ["math.AP"], "comment": "79 pages", "summary": "We rigorously construct a family of smooth self-similar solutions to the\nisentropic gravitational Euler-Poisson system with a polytropic equation of\nstate for polytropic indices lying in the full energy-supercritical range,\n$1<\\gamma<\\frac{6}{5}$. The result is an extension of the author's previous\nconstruction of Hunter solutions in the isothermal case, $\\gamma=1$, and\ncomplements a construction of Larson-Penston-type solutions by\nGuo-Had\\v{z}i\\'c-Jang-Schrecker for the same system in the full\nmass-supercritical range, $1<\\gamma<\\frac{4}{3}$. As an ingredient in the\nproof, a general framework is introduced for proving local analyticity of\nsolutions to this system in the vicinity of singular points. This framework\ncould be used for other quasilinear self-similar blow-up constructions.", "AI": {"tldr": "The paper constructs smooth self-similar solutions for the isentropic gravitational Euler-Poisson system with a polytropic equation of state, focusing on the energy-supercritical range (1<\u03b3<6/5). It extends previous work and introduces a framework for proving local analyticity near singular points.", "motivation": "To extend prior constructions of self-similar solutions (Hunter and Larson-Penston-type) and address the energy-supercritical range, while providing a general framework for analyzing singular points in such systems.", "method": "The authors rigorously construct solutions for the Euler-Poisson system with a polytropic equation of state, using a framework to prove local analyticity near singular points.", "result": "A family of smooth self-similar solutions is constructed for the specified range of polytropic indices, complementing existing results.", "conclusion": "The work successfully extends prior constructions and provides a reusable framework for analyzing singularities in similar quasilinear systems."}}
{"id": "2508.05900", "pdf": "https://arxiv.org/pdf/2508.05900", "abs": "https://arxiv.org/abs/2508.05900", "authors": ["Bryce Boyer", "Timothy S. Fisher"], "title": "Energetics and limitations of passive electron transpiration cooling for hypersonic leading edges", "categories": ["physics.plasm-ph"], "comment": "35 page, 17 figures", "summary": "Electron transpiration cooling (ETC) offers a promising approach for thermal\nmanagement of hypersonic vehicles by leveraging thermionic emission from the\nleading edge. While emitted electrons cool the surface, subsequent collection\nof flowfield electrons induces heating, limiting ETC effectiveness unless\ncollection occurs in cooler aftbody regions. Most existing ETC studies neglect\nthis heating contribution, assuming ideal downstream collection. This work\nintegrates a one-dimensional collisionless plasma sheath model into a\ndiscretized leading-edge framework to predict surface potentials and\ncharged-particle fluxes. A parametric study examines how plasma and vehicle\nproperties affect ETC performance. Results reveal that passive ETC is\nsusceptible to thermionic space-charge overcompensation, which can reverse the\nintended cooling effect and cause surface heating at high plasma densities.\nFlowfield electron heating can be mitigated but not eliminated by using\ndielectric coatings or blunt geometries. The same mechanisms that protect blunt\nbodies from adverse electrical conduction and flowfield heating also preclude\nincorporation of ETC-based cooling in those vehicle geometries.", "AI": {"tldr": "ETC for hypersonic vehicles cools via thermionic emission but faces heating from collected flowfield electrons. A 1D plasma sheath model shows passive ETC can reverse cooling at high plasma densities, with mitigation strategies like dielectric coatings or blunt geometries having trade-offs.", "motivation": "To address the overlooked heating effect of flowfield electron collection in ETC studies and evaluate its impact on cooling performance.", "method": "Integration of a 1D collisionless plasma sheath model into a discretized leading-edge framework to analyze surface potentials and charged-particle fluxes, with a parametric study on plasma and vehicle properties.", "result": "Passive ETC can reverse cooling due to thermionic space-charge overcompensation at high plasma densities. Mitigation strategies like dielectric coatings or blunt geometries have limitations.", "conclusion": "ETC effectiveness is limited by flowfield electron heating, and mitigation strategies come with trade-offs, restricting its application in certain vehicle geometries."}}
{"id": "2508.06264", "pdf": "https://arxiv.org/pdf/2508.06264", "abs": "https://arxiv.org/abs/2508.06264", "authors": ["Randal E. Bryant"], "title": "Numerical Considerations in Weighted Model Counting", "categories": ["math.NA", "cs.AI", "cs.LO", "cs.NA"], "comment": null, "summary": "Weighted model counting computes the sum of the rational-valued weights\nassociated with the satisfying assignments for a Boolean formula, where the\nweight of an assignment is given by the product of the weights assigned to the\npositive and negated variables comprising the assignment. Weighted model\ncounting finds applications across a variety of domains including probabilistic\nreasoning and quantitative risk assessment.\n  Most weighted model counting programs operate by (explicitly or implicitly)\nconverting the input formula into a form that enables arithmetic evaluation,\nusing multiplication for conjunctions and addition for disjunctions. Performing\nthis evaluation using floating-point arithmetic can yield inaccurate results,\nand it cannot quantify the level of precision achieved. Computing with rational\narithmetic gives exact results, but it is costly in both time and space.\n  This paper describes how to combine multiple numeric representations to\nefficiently compute weighted model counts that are guaranteed to achieve a\nuser-specified precision. When all weights are nonnegative, we prove that the\nprecision loss of arithmetic evaluation using floating-point arithmetic can be\ntightly bounded. We show that supplementing a standard IEEE double-precision\nrepresentation with a separate 64-bit exponent, a format we call extended-range\ndouble (ERD), avoids the underflow and overflow issues commonly encountered in\nweighted model counting. For problems with mixed negative and positive weights,\nwe show that a combination of interval floating-point arithmetic and rational\narithmetic can achieve the twin goals of efficiency and guaranteed precision.\nFor our evaluations, we have devised especially challenging formulas and weight\nassignments, demonstrating the robustness of our approach.", "AI": {"tldr": "The paper proposes a method to compute weighted model counts efficiently with guaranteed precision by combining multiple numeric representations, addressing issues of floating-point inaccuracy and rational arithmetic inefficiency.", "motivation": "Weighted model counting is crucial in probabilistic reasoning and risk assessment, but existing methods using floating-point arithmetic are inaccurate, while rational arithmetic is computationally expensive.", "method": "The paper combines numeric representations: extended-range double (ERD) for nonnegative weights to avoid underflow/overflow, and interval floating-point with rational arithmetic for mixed weights, ensuring efficiency and precision.", "result": "The approach provides tight bounds on precision loss for nonnegative weights and handles mixed weights robustly, as demonstrated by challenging evaluations.", "conclusion": "The proposed method efficiently computes weighted model counts with guaranteed precision, overcoming limitations of traditional approaches."}}
{"id": "2508.06070", "pdf": "https://arxiv.org/pdf/2508.06070", "abs": "https://arxiv.org/abs/2508.06070", "authors": ["Hong-Kyun Noh", "Jeong-Hoon Park", "Minseok Choi", "Jae Hyuk Lim"], "title": "Real-time physics-informed reconstruction of transient fields using sensor guidance and higher-order time differentiation", "categories": ["physics.comp-ph"], "comment": "44 pages, 11 figures", "summary": "This study proposes FTI-PBSM (Fixed-Time-Increment Physics-informed neural\nnetwork-Based Surrogate Model), a novel physics-informed surrogate modeling\nframework designed for real-time reconstruction of transient responses in\ntime-dependent Partial Differential Equations (PDEs) using only sparse,\ntime-dependent sensor measurements. Unlike conventional Physics-Informed Neural\nNetwork (PINN)-based models that rely on Automatic Differentiation (AD) over\nboth spatial and temporal domains and require dedicated causal network\narchitectures to impose temporal causality, the proposed approach entirely\nremoves AD in the time direction. Instead, it leverages higher-order numerical\ndifferentiation methods, such as the Central Difference, Adams-Bashforth, and\nBackward Differentiation Formula, to explicitly impose temporal causality. This\nleads to a simplified model architecture with improved training stability,\ncomputational efficiency, and extrapolation capability. Furthermore, FTI-PBSM\nis trained on sparse sensor measurements from multiple PDE cases generated by\nvarying PDE coefficients, with the sensor data serving as model input. This\nenables the model to learn a parametric PDE family and generalize to unseen\nphysical cases, accurately reconstructing full-field transient solutions in\nreal time. The proposed model is validated on four representative PDE\nproblems-the convection equation, diffusion-reaction dynamics, Korteweg-de\nVries (KdV) equation, and Allen-Cahn equation-and demonstrates superior\nprediction accuracy and generalization performance compared to a causal PBSM,\nwhich is used as the baseline model, in both interpolation and extrapolation\ntasks. It also shows strong robustness to sensor noise and variations in\ntraining data size, while significantly reducing training time.", "AI": {"tldr": "FTI-PBSM is a physics-informed surrogate model for real-time PDE solutions, using higher-order numerical differentiation instead of AD for temporal causality, improving stability, efficiency, and generalization.", "motivation": "To address limitations of conventional PINN-based models, such as reliance on AD and complex architectures, by simplifying temporal causality imposition and enhancing performance.", "method": "Uses higher-order numerical differentiation (e.g., Central Difference) instead of AD for temporal causality, trained on sparse sensor data from varied PDE cases.", "result": "Outperforms baseline in accuracy, generalization, robustness to noise, and reduces training time across four PDE problems.", "conclusion": "FTI-PBSM offers a simpler, more efficient, and robust framework for real-time PDE solutions with sparse data."}}
{"id": "2508.05927", "pdf": "https://arxiv.org/pdf/2508.05927", "abs": "https://arxiv.org/abs/2508.05927", "authors": ["Josh Culver", "Aubrey Ayres", "Evan Halloran", "Ryan Lin", "Emily Peng", "Charis Tsikkou"], "title": "An Analysis of the Riemann Problem for a $2 \\times 2$ System of Keyfitz-Kranzer Type Conservation Laws Using Shadow Waves and Dafermos Regularization", "categories": ["math.AP", "34A05, 34C37, 34C45, 34E15, 35L45, 35L65, 35L67, 35L80, 35Q92,\n  65M06, 74L10, 76A30"], "comment": "37 pages", "summary": "We consider a system of two conservation laws and provide a detailed\ndescription of both classical and non-classical self-similar Riemann solutions.\nIn particular, we demonstrate the existence of overcompressive delta shocks as\nsingular limits of the Dafermos regularization of the system. The system is\nchosen for its minimal yet representative structure, which captures the\nessential features of transport dynamics under density constraints. Our\nanalysis is carried out using blow-up techniques within the framework of\nGeometric Singular Perturbation Theory (GSPT), allowing us to resolve the\ninternal structure of these singular solutions. Despite its simplicity, the\nsystem serves as a versatile prototype for crowding-limited transport across a\nrange of applications, including biological aggregation, ecological dispersal,\ngranular compaction, and traffic congestion. Our findings are supported by\nnumerical simulations using the Local Lax-Friedrichs scheme.", "AI": {"tldr": "The paper analyzes self-similar Riemann solutions in a system of two conservation laws, highlighting overcompressive delta shocks and their emergence from Dafermos regularization. It uses GSPT and numerical simulations to study these solutions.", "motivation": "To understand transport dynamics under density constraints, focusing on minimal yet representative systems that model crowding-limited transport in various applications.", "method": "Employed blow-up techniques within Geometric Singular Perturbation Theory (GSPT) and numerical simulations using the Local Lax-Friedrichs scheme.", "result": "Demonstrated the existence of overcompressive delta shocks as singular limits of Dafermos regularization, resolving their internal structure.", "conclusion": "The system serves as a versatile prototype for crowding-limited transport, applicable to fields like biology, ecology, granular physics, and traffic modeling."}}
{"id": "2508.06045", "pdf": "https://arxiv.org/pdf/2508.06045", "abs": "https://arxiv.org/abs/2508.06045", "authors": ["Prokopis Hadjisolomou", "Rashid Shaisultanon", "Tae Moon Jeong", "Christopher Paul Ridgers", "Sergei Vladimirovich Bulanov"], "title": "High-Energy Photon Generation from Self-Organized Plasma Cavities in Field-Enhanced Laser-Preplasma Interactions", "categories": ["physics.plasm-ph"], "comment": "6 pages, 4 figures", "summary": "The interaction of an ultraintense Nd:glass laser pulse with a near-critical\nplasma self-organizes into a highly efficient $\\gamma$-ray source.\nThree-dimensional particle-in-cell simulations demonstrate that relativistic\nself-focusing, aided by a self-generated electron cavity, enhances the laser\nintensity by more than an order of magnitude, driving the system into the\nradiation-reaction-dominated regime, i.e. one where the electrons lose a\nsubstantial amount of their energy as hard radiation. Peak photon emission\noccurs near $0.5$ times the relativistic critical density, with a\n$\\gamma$-photon yield exceeding $20\\%$ of the laser energy. Compared to Ti:Sa\nlasers of the same power, the longer duration of Nd:glass laser pulses leads to\nan order of magnitude increase in $\\gamma$-photon number in the extreme\nconversion efficiency regime, making them particularly well-suited for\nphotonuclear physics applications. These findings point to a robust and\nscalable mechanism for compact, ultra-bright $\\gamma$-ray generation in the\nmulti-petawatt regime.", "AI": {"tldr": "An ultraintense Nd:glass laser interacting with near-critical plasma forms a highly efficient \u03b3-ray source, with simulations showing enhanced laser intensity and extreme photon yield.", "motivation": "To explore efficient \u03b3-ray generation using ultraintense lasers for applications like photonuclear physics.", "method": "Three-dimensional particle-in-cell simulations to study laser-plasma interaction, focusing on relativistic self-focusing and electron cavity effects.", "result": "Peak \u03b3-photon yield exceeds 20% of laser energy, with Nd:glass lasers outperforming Ti:Sa lasers in photon number and efficiency.", "conclusion": "Nd:glass lasers offer a robust, scalable method for ultra-bright \u03b3-ray generation, ideal for high-power applications."}}
{"id": "2508.06273", "pdf": "https://arxiv.org/pdf/2508.06273", "abs": "https://arxiv.org/abs/2508.06273", "authors": ["Erik Chudzik", "Christiane Helzel", "Amelie Porfetye"], "title": "A Fully Discrete Truly Multidimensional Active Flux Method For The Two-Dimensional Euler Equations", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "The Active Flux method is a finite volume method for hyperbolic conservation\nlaws that uses both cell averages and point values as degrees of freedom.\nSeveral versions of such methods are currently under development. We focus on\nthird order accurate, fully discrete Active Flux methods with compact stencil\nin space and time. These methods require exact or approximate evolution\noperators for the update of the point value degrees of freedom which are\nprovided by the method of bicharacteristics. Here we propose new limiting\nstrategies that guarantee positivity of pressure and density and furthermore\ndiscuss the implementation of reflecting boundary conditions. Numerical results\nshow that the method leads to accurate approximates on coarse grids.", "AI": {"tldr": "The paper introduces new limiting strategies for third-order Active Flux methods to ensure positivity of pressure and density, along with reflecting boundary conditions, demonstrating accurate results on coarse grids.", "motivation": "To enhance the Active Flux method by addressing positivity preservation and boundary conditions for hyperbolic conservation laws.", "method": "Uses third-order accurate, fully discrete Active Flux methods with compact stencils, employing bicharacteristics for point value updates and new limiting strategies.", "result": "Numerical results confirm the method's accuracy on coarse grids while maintaining positivity.", "conclusion": "The proposed strategies improve the robustness and applicability of Active Flux methods for hyperbolic conservation laws."}}
{"id": "2508.05656", "pdf": "https://arxiv.org/pdf/2508.05656", "abs": "https://arxiv.org/abs/2508.05656", "authors": ["Jiajia Huang", "Ding Pan"], "title": "Comment on \"Mineral-water reactions in Earth's mantle: Predictions from Born theory and ab initio molecular dynamics\" by Fowler et al. 2024 (Geochim. Cosmochim. Acta 372, 111-123)", "categories": ["physics.geo-ph", "physics.comp-ph"], "comment": "Comment on 10.1016/j.gca.2024.03.012, 9 pages, 2 figures", "summary": "This comment addresses discrepancies in dielectric constant calculations of\nwater under extreme conditions (~10 GPa and 1000 K) between Fowler et al.'s\nrecent study [Geochim. Cosmochim. Acta 372, 111-123 (2024)] and the earlier\nwork by Pan et al. [Proc. Natl. Acad. Sci. 110, 6646-6650 (2013)]. Through\nreproduced ab initio molecular dynamics (AIMD) simulations using the CP2K code\nwith extended duration and identical system size, we rigorously validate that\nPan et al.'s original results (39.4) are well-converged, contrasting with\nFowler et al.'s reported value of 51. The observed discrepancy cannot be\nattributed to simulation duration limitations, but rather to methodological\ndifferences in dipole moment calculation. Our analysis highlights critical\nissues in the treatment of dipole moment fluctuations in periodic systems\nwithin the framework of modern theory of polarization. This clarification has\nsignificant implications for modeling mineral-water interactions in Earth's\nmantle using Born theory.", "AI": {"tldr": "The paper resolves discrepancies in dielectric constant calculations of water under extreme conditions, validating Pan et al.'s results over Fowler et al.'s due to methodological differences in dipole moment calculations.", "motivation": "Address inconsistencies between two studies (Fowler et al. and Pan et al.) on dielectric constant calculations of water under extreme conditions.", "method": "Reproduced AIMD simulations using CP2K code with extended duration and identical system size.", "result": "Validated Pan et al.'s dielectric constant (39.4) as accurate, contrasting Fowler et al.'s 51, attributing the discrepancy to dipole moment calculation methods.", "conclusion": "The findings clarify critical issues in dipole moment treatment for periodic systems, impacting mineral-water interaction modeling in Earth's mantle."}}
{"id": "2508.05930", "pdf": "https://arxiv.org/pdf/2508.05930", "abs": "https://arxiv.org/abs/2508.05930", "authors": ["Sigifredo Herr\u00f3n", "Emer Lopera", "Diana S\u00e1nchez"], "title": "Nonexistence of positive radial solutions for semipositone $\u03c6$-Laplacian problems with superlinear reaction term", "categories": ["math.AP", "35A01, 35A24, 35B09, 35B33, 35G31, 35J62"], "comment": null, "summary": "The aim of this paper is to prove the nonexistence of positive radial\nsolutions to the problem $-\\Delta_\\phi u=\\lambda f(u)$, $x\\in B_1(0)$, $u(x)=0$\non $|x|=1$, for $\\lambda>0$ sufficiently large. Here, $\\phi$ is a continuous\nfunction, $\\Delta_\\phi$ denotes the $\\phi$-Laplacian operator which is defined\nby $\\Delta_\\phi (u):=div (\\phi (|\\nabla u|) \\nabla u)$, and $B_1(0)$ is the\nunit ball in $\\mathbb{R}^N$, with $N>1$. Furthermore, $f$ is a continuous,\nnondecreasing function such that $f(0)<0$, and its behavior at infinity is\nintimately related to $\\phi$. Our findings are presented in a combined format,\nemploying both an indirect argument and an energy analysis.", "AI": {"tldr": "The paper proves the nonexistence of positive radial solutions for a specific PDE problem involving the \u03d5-Laplacian operator for large \u03bb.", "motivation": "To address the lack of positive radial solutions for the given PDE under certain conditions, particularly for large \u03bb.", "method": "Combines indirect argument and energy analysis to study the problem.", "result": "Demonstrates that no positive radial solutions exist for sufficiently large \u03bb.", "conclusion": "The findings confirm the nonexistence of solutions under the specified conditions, contributing to the understanding of such PDEs."}}
{"id": "2508.06116", "pdf": "https://arxiv.org/pdf/2508.06116", "abs": "https://arxiv.org/abs/2508.06116", "authors": ["G. Merlo", "A. Ba\u00f1\u00f3n Navarro", "T. G\u00f6rler", "F. Jenko", "F. Wilms"], "title": "Multiscale turbulence in stellarators", "categories": ["physics.plasm-ph"], "comment": null, "summary": "We present the first gyrokinetic simulations of multiscale turbulence in a\nstellarator, using the magnetic geometry of Wendelstein 7-X (W7-X) and\nexperimentally relevant parameters. A broad range of scenarios is explored,\nincluding regimes where electron-temperature-gradient (ETG) turbulence coexists\nwith varying levels of ion-temperature-gradient (ITG) turbulence, as well as\ncases involving microtearing modes (MTMs) relevant to high-$\\beta$ and\nreactor-like conditions. Notably, while ETG turbulence does not form radial\nstreamers as in tokamaks, it can still drive significant transport and interact\nwith ion-scale turbulence. In electrostatic ITG-dominated regimes,\nelectron-scale fluctuations erode zonal flows, enhancing ion-scale transport,\nwhile ion-scale turbulence suppresses ETG activity. In contrast, under\nelectromagnetic MTM conditions, the isotropic nature of ETG turbulence limits\nits suppressive effect, allowing MTMs to persist. These findings underscore the\ncritical role of cross-scale effects for accurate transport predictions in W7-X\nand future stellarators.", "AI": {"tldr": "First gyrokinetic simulations of multiscale turbulence in W7-X show cross-scale interactions between electron- and ion-scale turbulence, impacting transport predictions.", "motivation": "To understand multiscale turbulence in stellarators, particularly W7-X, and its impact on transport under various conditions.", "method": "Gyrokinetic simulations using W7-X magnetic geometry and experimentally relevant parameters, exploring ETG, ITG, and MTM regimes.", "result": "ETG turbulence drives transport without streamers; ITG regimes show zonal flow erosion, while MTM conditions allow persistence due to isotropic ETG turbulence.", "conclusion": "Cross-scale effects are crucial for accurate transport predictions in W7-X and future stellarators."}}
{"id": "2508.06302", "pdf": "https://arxiv.org/pdf/2508.06302", "abs": "https://arxiv.org/abs/2508.06302", "authors": ["Junqing Wu", "Ling Hong", "Mingwu Li", "Jun Jiang"], "title": "Parallelized computation of quasi-periodic solutions for finite element problems: A Fourier series expansion-based shooting method", "categories": ["math.NA", "cs.NA", "math.DS"], "comment": "49 pages, 23 figures", "summary": "High-dimensional nonlinear mechanical systems admit quasi-periodic solutions\nthat are essential for the understanding of the dynamical systems. These\nquasi-periodic solutions stay on some invariant tori governed by complex PDEs\nin hyper-time. Here, we propose a Fourier series expansion-based shooting\nmethod (FSE-Shooting) for the parallelized computation of quasi-periodic\nsolution with $d$ base frequencies ($d \\ge 2$). We represent the associated\n$d$-torus as a collection of trajectories initialized at a ($d-1$)-torus. We\ndrive a set of ODEs that hold for any of these trajectories. We also derive a\nset of boundary conditions that couple the initial and terminal states of these\ntrajectories and then formulate a set of nonlinear algebraic equations via the\ncoupling conditions. We use Fourier series expansion to parameterize the\n($d-1$)-torus and shooting method to iterate the Fourier coefficients\nassociated with initial torus such that the coupling conditions are satisfied.\nIn particular, the terminal points of these trajectories are parallelized\ncomputed via Newmark integration, where the time points and Fourier\ncoefficients are transformed to each other by alternating Frequency-Time\nmethod. A straightforward phase condition is devised to track the\nquasi-periodic solutions with priori unknown base frequencies. Additionally,\nthe by-product of the FSE-Shooting can be also directly used to compute the\nLyapunov exponents to assess the stabilities of quasi-periodic solutions. The\nresults of three finite element systems show the efficiency and versatility of\nFSE-Shooting in high-dimensional nonlinear dynamical systems, including a\nthree-dimensional shell structure with $1872$ DOFs.", "AI": {"tldr": "The paper introduces FSE-Shooting, a Fourier series expansion-based shooting method for computing quasi-periodic solutions in high-dimensional nonlinear mechanical systems. It efficiently handles systems with multiple base frequencies and demonstrates versatility in complex dynamical systems.", "motivation": "Quasi-periodic solutions are crucial for understanding nonlinear dynamical systems, but their computation is challenging, especially in high-dimensional cases. The paper aims to address this by proposing a parallelizable and efficient method.", "method": "The method involves representing quasi-periodic solutions as trajectories on invariant tori, using Fourier series expansion to parameterize initial conditions, and employing shooting methods to satisfy coupling conditions. Parallel computation and Newmark integration enhance efficiency.", "result": "The method successfully computes quasi-periodic solutions in high-dimensional systems, including a 3D shell structure with 1872 DOFs, demonstrating efficiency and versatility.", "conclusion": "FSE-Shooting is an effective tool for analyzing quasi-periodic solutions in complex nonlinear dynamical systems, offering computational efficiency and stability assessment capabilities."}}
{"id": "2508.05921", "pdf": "https://arxiv.org/pdf/2508.05921", "abs": "https://arxiv.org/abs/2508.05921", "authors": ["Siddharth Rout"], "title": "Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations", "categories": ["cs.LG", "math.FA", "math.RT", "physics.comp-ph"], "comment": null, "summary": "Accuracy in neural PDE solvers often breaks down not because of limited\nexpressivity, but due to poor optimisation caused by ill-conditioning,\nespecially in multi-fidelity and stiff problems. We study this issue in\nPhysics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural\nPDE solvers, and show that asymptotic components in governing equations can\nproduce highly ill-conditioned activation matrices, severely limiting\nconvergence. We introduce Shifted Gaussian Encoding, a simple yet effective\nactivation filtering step that increases matrix rank and expressivity while\npreserving convexity. Our method extends the solvable range of Peclet numbers\nin steady advection-diffusion equations by over two orders of magnitude,\nachieves up to six orders lower error on multi-frequency function learning, and\nfits high-fidelity image vectors more accurately and faster than deep networks\nwith over a million parameters. This work highlights that conditioning, not\ndepth, is often the bottleneck in scientific neural solvers and that simple\narchitectural changes can unlock substantial gains.", "AI": {"tldr": "The paper addresses poor optimization in neural PDE solvers due to ill-conditioning, proposing Shifted Gaussian Encoding to improve matrix rank and convergence, achieving significant accuracy gains.", "motivation": "Neural PDE solvers often fail due to ill-conditioning, not expressivity, especially in multi-fidelity and stiff problems.", "method": "Introduces Shifted Gaussian Encoding, an activation filtering step to enhance matrix rank and expressivity while maintaining convexity in PIELMs.", "result": "Extends solvable Peclet numbers by two orders, reduces error by six orders in multi-frequency learning, and outperforms deep networks in speed and accuracy.", "conclusion": "Conditioning, not depth, is the bottleneck in neural solvers; simple architectural changes can yield substantial improvements."}}
{"id": "2508.05955", "pdf": "https://arxiv.org/pdf/2508.05955", "abs": "https://arxiv.org/abs/2508.05955", "authors": ["Hiroshi Takeda"], "title": "$L^{2}$-estimates for the linear elastic waves", "categories": ["math.AP"], "comment": null, "summary": "This paper is concerned with the large time behavior of the solution to the\nCauchy problem for the elastic wave equations. In particular, optimal $L^{2}$\nestimates of the elastic waves are obtained in the sense that the upper and\nlower bounds of the $L^{2}$ norms of each component of the solution are proved\nfor large $t$, under the minimum assumptions necessary regarding regularity\nwith respect to initial data. The proof is based on the approximation of the\nsolution by a smooth auxiliary function with suitable parameters.", "AI": {"tldr": "The paper analyzes the long-term behavior of solutions to the Cauchy problem for elastic wave equations, providing optimal L\u00b2 estimates for large times.", "motivation": "To understand the large time behavior of elastic wave solutions and establish precise L\u00b2 norm bounds under minimal regularity assumptions.", "method": "Approximation of the solution using a smooth auxiliary function with carefully chosen parameters.", "result": "Optimal upper and lower bounds for the L\u00b2 norms of each solution component are derived for large times.", "conclusion": "The study successfully characterizes the long-time behavior of elastic wave solutions with minimal regularity requirements."}}
{"id": "2508.06462", "pdf": "https://arxiv.org/pdf/2508.06462", "abs": "https://arxiv.org/abs/2508.06462", "authors": ["G. D. Glenn", "F. Treffert", "H. Ahmed", "S. Astbury", "M. Borghesi", "N. Bourgeois", "C. B. Curry", "S. J. D. Dann", "S. DiIorio", "N. P. Dover", "T. Dzelzainis", "O. Ettlinger", "M. Gauthier", "L. Giuffrida", "R. J. Gray", "J. S. Green", "G. S. Hicks", "C. Hyland", "V. Istokskaia", "M. King", "B. Loughran", "D. Margarone", "O. McCusker", "P. McKenna", "Z. Najmudin", "C. Parisua\u00f1a", "P. Parsons", "C. Spindloe", "M. J. V. Streeter", "D. R. Symes", "A. G. R. Thomas", "N. Xu", "S. H. Glenzer", "C. A. J. Palmer"], "title": "Characterization and automated optimization of laser-driven proton beams from converging liquid sheet jet targets", "categories": ["physics.plasm-ph"], "comment": "39 pages, 8 figures", "summary": "Compact, stable, and versatile laser-driven ion sources hold great promise\nfor applications ranging from medicine to materials science and fundamental\nphysics. While single-shot sources have demonstrated favorable beam properties,\nincluding the peak fluxes necessary for several applications, high repetition\nrate operation will be necessary to generate and sustain the high average flux\nneeded for many of the most exciting applications of laser-driven ion sources.\nFurther, to navigate through the high-dimensional space of laser and target\nparameters towards experimental optima, it is essential to develop ion\nacceleration platforms compatible with machine learning learning techniques and\ncapable of autonomous real-time optimization. Here we present a multi-Hz ion\nacceleration platform employing a liquid sheet jet target. We characterize the\nlaser-plasma interaction and the laser-driven proton beam across a variety of\nkey parameters governing the interaction using an extensive suite of online\ndiagnostics. We also demonstrate real-time, closed-loop optimization of the ion\nbeam maximum energy by tuning the laser wavefront using a Bayesian optimization\nscheme. This approach increased the maximum proton energy by 11% compared to a\nmanually-optimized wavefront by enhancing the energy concentration within the\nlaser focal spot, demonstrating the potential for closed-loop optimization\nschemes to tune future ion accelerators for robust high repetition rate\noperation.", "AI": {"tldr": "A multi-Hz ion acceleration platform using a liquid sheet jet target is presented, demonstrating real-time optimization of proton beam energy via Bayesian methods, achieving an 11% increase in energy.", "motivation": "To develop high repetition rate laser-driven ion sources for applications in medicine, materials science, and physics, requiring robust and autonomous optimization.", "method": "Employed a liquid sheet jet target and used Bayesian optimization to tune the laser wavefront for real-time, closed-loop optimization of proton beam energy.", "result": "Achieved an 11% increase in maximum proton energy compared to manual optimization, enhancing energy concentration in the laser focal spot.", "conclusion": "Closed-loop optimization schemes show promise for tuning future ion accelerators for high repetition rate operation."}}
{"id": "2508.06303", "pdf": "https://arxiv.org/pdf/2508.06303", "abs": "https://arxiv.org/abs/2508.06303", "authors": ["Gerhard Kirsten", "Bilgesu Bilgin", "Janith Petangoda", "Phillip Stanley-Marbell"], "title": "A Tensor Train Approach for Deterministic Arithmetic Operations on Discrete Representations of Probability Distributions", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Computing with discrete representations of high-dimensional probability\ndistributions is fundamental to uncertainty quantification, Bayesian inference,\nand stochastic modeling. However, storing and manipulating such distributions\nsuffers from the curse of dimensionality, as memory and computational costs\ngrow exponentially with dimension. Monte Carlo methods require thousands to\nbillions of samples, incurring high computational costs and producing\ninconsistent results due to stochasticity. We present an efficient tensor train\nmethod for performing exact arithmetic operations on discretizations of\ncontinuous probability distributions while avoiding exponential growth. Our\napproach leverages low-rank tensor train decomposition to represent latent\nrandom variables compactly using Dirac deltas, enabling deterministic addition,\nsubtraction and multiplication operations directly in the compressed format. We\ndevelop an efficient implementation using sparse matrices and specialized data\nstructures that further enhances performance. Theoretical analysis demonstrates\npolynomial scaling of memory and computational complexity under rank\nassumptions, and shows how statistics of latent variables can be computed with\npolynomial complexity. Numerical experiments spanning randomized linear algebra\nto stochastic differential equations demonstrate orders-of-magnitude\nimprovements in memory usage and computational time compared to conventional\napproaches, enabling tractable deterministic computations on discretized random\nvariables in previously intractable dimensions.", "AI": {"tldr": "The paper introduces a tensor train method for efficient arithmetic operations on high-dimensional probability distributions, avoiding exponential growth in memory and computation.", "motivation": "High-dimensional probability distributions are crucial for uncertainty quantification and Bayesian inference, but current methods face scalability issues due to the curse of dimensionality and stochasticity in Monte Carlo approaches.", "method": "The proposed method uses tensor train decomposition to compactly represent distributions with Dirac deltas, enabling deterministic arithmetic operations in a compressed format. Efficient implementation leverages sparse matrices and specialized data structures.", "result": "Theoretical and numerical results show polynomial scaling in memory and computation, with significant improvements in performance compared to conventional methods.", "conclusion": "The tensor train approach enables tractable deterministic computations on high-dimensional distributions, overcoming previous scalability limitations."}}
{"id": "2508.06311", "pdf": "https://arxiv.org/pdf/2508.06311", "abs": "https://arxiv.org/abs/2508.06311", "authors": ["Lukas Volkmer", "Leonardo Medrano Sandonas", "Philip Grimm", "Julia Kristin Hufenbach", "Gianaurelio Cuniberti"], "title": "On-the-Fly Machine Learning of Interatomic Potentials for Elastic Property Modeling in Al-Mg-Zr Solid Solutions", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "17 pages, 6 figures, 1 table", "summary": "The development of resilient and lightweight Aluminum alloys is central to\nadvancing structural materials for energy-efficient engineering applications.\nTo address this challenge, in this study, we explore the elastic properties of\nAl-Mg-Zr solid solutions by integrating advanced machine learning (ML)\ntechniques with quantum-mechanical (QM) atomistic simulations. For this\npurpose, we develop accurate and transferable machine-learned interatomic\npotentials (MLIPs) using two complementary approaches: (i) an on-the-fly\nlearning scheme combined with Bayesian linear regression during ab initio\nmolecular dynamics simulations, and (ii) the equivariant neural network\narchitecture MACE. Both MLIPs facilitate the prediction of\ncomposition-dependent elastic properties while drastically reducing the\ncomputational cost compared to conventional QM methods. Comparison with\nultrasonic measurements shows that the deviation between simulation and\nexperiment remains within a few GPa across all Al-Mg-Zr systems investigated.\nThese potentials also enable the systematic exploration of the Al-Mg-Zr solid\nsolution phase space and provide insights into the elastic behavior as a\nfunction of alloying element concentration. Hence, our findings demonstrate the\nreliability and transferability of the parameterized on-the-fly MLIPs, making\nthem valuable for accelerating the design of Al alloys with tailored\nphysicomechanical properties in complex compositional spaces. While the present\nstudy focuses on homogeneous phases, it establishes a foundation for future\nmultiscale simulations that include microstructural features such as\nprecipitates and grain boundaries.", "AI": {"tldr": "The paper explores elastic properties of Al-Mg-Zr alloys using ML and QM simulations, developing accurate MLIPs to predict composition-dependent properties efficiently.", "motivation": "To advance lightweight, resilient Al alloys for energy-efficient engineering by understanding their elastic properties.", "method": "Combines ML techniques (on-the-fly learning with Bayesian regression and MACE neural networks) with QM simulations to develop MLIPs.", "result": "MLIPs predict elastic properties with minimal deviation from experiments, enabling systematic exploration of Al-Mg-Zr phase space.", "conclusion": "The MLIPs are reliable and transferable, useful for designing tailored Al alloys, and lay groundwork for future multiscale studies."}}
{"id": "2508.05985", "pdf": "https://arxiv.org/pdf/2508.05985", "abs": "https://arxiv.org/abs/2508.05985", "authors": ["Dingqun Deng", "Jong-in Kim", "Donghyun Lee"], "title": "Global solutions in $L^{p}_{v}L^{\\infty}_{x}$ for the Boltzmann equation in bounded domains", "categories": ["math.AP"], "comment": "97 pages", "summary": "The existence theory for solutions to the Boltzmann equation in bounded\ndomains has primarily been developed within uniformly bounded function classes,\nsuch as $L^{\\infty}_{x,v}$, as in [Duan-Huang-Wang-Yang,2017],\n[Duan-Wang,2019], [Guo,2010]. In this paper, we investigate solutions in\nrelaxed function spaces $L^{p}_{v}L^\\infty_{x}$ for the initial-boundary value\nproblem of the Boltzmann equation in bounded domains. We consider the case of\nhard potential under diffuse reflection boundary conditions and assume cutoff\nmodel. For large initial data in a weighted $L^{p}_{v}L^\\infty_{x}$ space with\nsmall relative entropy, we construct unique global-in-time mild solution that\nconverge exponentially to the global Maxwellian. A pointwise estimate for the\ngain term, bounded in terms of $L^p_v$ and $L^2_v$ norms, is essential to prove\nour main results. Relative to [Gualdani-Mischler-Mouhot,2017], our work\nprovides an alternative perspective on convergence to equilibrium in the\npresence of boundary conditions.", "AI": {"tldr": "The paper explores solutions to the Boltzmann equation in bounded domains using relaxed function spaces, focusing on hard potentials and diffuse reflection boundary conditions. It constructs unique global solutions for large initial data with small relative entropy, showing exponential convergence to equilibrium.", "motivation": "Prior work on the Boltzmann equation in bounded domains has been limited to uniformly bounded function classes. This paper aims to extend the theory to relaxed function spaces, addressing the initial-boundary value problem under specific conditions.", "method": "The study uses the $L^{p}_{v}L^\\infty_{x}$ space for the Boltzmann equation, considering hard potentials and diffuse reflection boundary conditions. A key tool is a pointwise estimate for the gain term, bounded by $L^p_v$ and $L^2_v$ norms.", "result": "Unique global-in-time mild solutions are constructed for large initial data with small relative entropy, demonstrating exponential convergence to the global Maxwellian.", "conclusion": "The work offers a new perspective on convergence to equilibrium in bounded domains, complementing existing literature and expanding the theoretical framework for the Boltzmann equation."}}
{"id": "2508.05943", "pdf": "https://arxiv.org/pdf/2508.05943", "abs": "https://arxiv.org/abs/2508.05943", "authors": ["Andrew Longman", "Danny Attiyah", "Elizabeth Grace", "Christopher Gardner", "Tayyab Suratwala", "Gary Tham", "Colin Harthcock", "Robert Fedosejevs", "Franklin Dollar"], "title": "Spatiotemporal shaping of broadband helical light pulses at relativistic intensities", "categories": ["physics.optics", "physics.plasm-ph"], "comment": null, "summary": "Spatiotemporal control of laser pulses at relativistic intensities is a\nlongstanding goal with broad implications in laser-plasma acceleration,\nhigh-brightness radiation sources, and extreme-field science. Laser pulses with\nhelical spatiotemporal intensity profiles, often referred to as light springs,\ncarry multiple spectral and orbital angular momentum (OAM) modes, producing a\nrotating intensity profile capable of coupling directly to helical plasma\nwaves. Until now, light springs have only been realized on low-power systems,\nlimited by optical damage thresholds and large-aperture beamline constraints.\nHere, we report the first experimental realization of light springs at\nrelativistic intensities, achieving peak intensities above $1.4\\times10^{18}$\nW/cm$^{2}$. Our approach spectrally splits a high-power laser pulse, imprints\ndistinct helical phases on each component, and coherently recombines them.\nHyperspectral imaging, off-axis holography, and spectral phase reconstruction\nconfirm excellent agreement with theory and reveal the potential to drive\nsuperluminal rotational velocities. Introducing spectral chirp demonstrates\nfurther control of the temporal evolution of the transverse mode structure.\nThis platform opens new regimes of ultra-intense laser-plasma interaction where\nlaser OAM can directly couple to plasma OAM.", "AI": {"tldr": "First experimental realization of relativistic-intensity light springs, achieving peak intensities above 1.4\u00d710\u00b9\u2078 W/cm\u00b2, enabling direct coupling of laser OAM to plasma OAM.", "motivation": "Spatiotemporal control of laser pulses at relativistic intensities has broad implications for laser-plasma acceleration, radiation sources, and extreme-field science. Light springs, with helical spatiotemporal profiles, could couple directly to helical plasma waves but were previously limited to low-power systems.", "method": "Spectrally split a high-power laser pulse, imprint distinct helical phases on each component, and coherently recombine them. Techniques like hyperspectral imaging and off-axis holography validated the results.", "result": "Achieved peak intensities above 1.4\u00d710\u00b9\u2078 W/cm\u00b2, confirmed excellent agreement with theory, and demonstrated superluminal rotational velocities. Spectral chirp allowed control of transverse mode structure evolution.", "conclusion": "This platform opens new regimes for ultra-intense laser-plasma interactions, enabling direct coupling of laser orbital angular momentum to plasma."}}
{"id": "2508.06306", "pdf": "https://arxiv.org/pdf/2508.06306", "abs": "https://arxiv.org/abs/2508.06306", "authors": ["Thomas M\u00e4rz", "Vladyslav Gapyak", "Andreas Weinmann"], "title": "Higher Order Regularization using Harmonic Eigenfunctions for Model-Based Reconstruction in Magnetic Particle Imaging", "categories": ["math.NA", "cs.NA", "65K10, 65R32, 65T40, 92C55"], "comment": null, "summary": "Magnetic Particle Imaging (MPI) is a recent imaging modality where\nsuperparamagnetic nanoparticles are employed as tracers. The reconstruction\ntask is to obtain the spatial particle distribution from a voltage signal\ninduced by the particles. Generally, in computational imaging variational\nreconstruction techniques are common and rely on a mathematical model to\ndescribe the underlying physics. For the MPI reconstruction task we propose a\nmodel-based variational reconstruction technique which incorporates a higher\norder regularizer, where the regularizer is diagonalized by harmonic\neigenfunctions. The proposed image reconstruction algorithm features two major\nstages: in the first stage, the core stage, the components of the MPI core\nresponse are reconstructed. This is the MPI-specific data approximation task\nwhich we formulate as a variational problem incorporating the higher order\nregularizer. The relationship between the particle distribution, the MPI core\nresponse and the measured data is given by a mathematical model which was\nintroduced in our earlier research. According to this model the MPI core\nresponse is tied to the particle distribution by convolution. Therefore the\noutcome of the core stage yields the data for the second stage, the\ndeconvolution stage, in which the final reconstructed image is produced by\nsolving an ill-posed deconvolution problem in a robust way relying on earlier\nresearch. Interestingly, the quality of the final image depends significantly\non the quality of the result of the core stage. A contribution is thus the\nenhancement of the core stage via higher order regularization. We provide a\ntheoretical foundation for our approach and demonstrate its benefit with\nnumerical examples.", "AI": {"tldr": "A model-based variational reconstruction technique for Magnetic Particle Imaging (MPI) is proposed, using a higher-order regularizer diagonalized by harmonic eigenfunctions, improving image quality through a two-stage process.", "motivation": "To enhance the reconstruction of spatial particle distribution in MPI by addressing the limitations of existing methods through a robust variational approach.", "method": "A two-stage algorithm: first, reconstructing the MPI core response with a higher-order regularizer; second, solving an ill-posed deconvolution problem to produce the final image.", "result": "The proposed method improves the quality of the final image by enhancing the core stage reconstruction, supported by theoretical foundation and numerical examples.", "conclusion": "Higher-order regularization in the core stage significantly improves MPI image reconstruction, demonstrating the method's effectiveness."}}
{"id": "2508.06119", "pdf": "https://arxiv.org/pdf/2508.06119", "abs": "https://arxiv.org/abs/2508.06119", "authors": ["Angelica Pia Di Feola", "Vittorio Pane"], "title": "Weighted estimates for the Stokes semigroup in the half-space", "categories": ["math.AP", "math-ph", "math.MP", "35Q30, 35B65, 76D05"], "comment": null, "summary": "We investigate the initial-boundary value problem for the Stokes system in\nthe half-space, within the framework of weighted Lebesgue spaces. Introducing a\nnew weight function defined via a product of powers of distances from fixed\npoints, we establish existence, uniqueness, and regularity results for strong\nsolutions to the Stokes problem in the half space. Our analysis generalizes\nprevious results for the Stokes system in radial-weighted spaces (Galdi and\nMaremonti, J. Math. Fluid Mech. 25:7,2023; Maremonti and Pane, J. Math. Fluid\nMech. 27:2,2025) and extends the theory to our setting. These results represent\na first step toward the analysis of the Navier-Stokes system in weighted\nspaces, with applications in both half-space and exterior domain\nconfigurations.", "AI": {"tldr": "The paper studies the Stokes system in the half-space using weighted Lebesgue spaces, proving existence, uniqueness, and regularity of solutions. It generalizes prior work and lays groundwork for Navier-Stokes analysis.", "motivation": "To extend the theory of the Stokes system to weighted Lebesgue spaces, generalizing previous results and paving the way for Navier-Stokes applications.", "method": "Introduces a new weight function based on distances from fixed points and analyzes the Stokes system in weighted Lebesgue spaces.", "result": "Establishes existence, uniqueness, and regularity of strong solutions in the half-space.", "conclusion": "The findings generalize earlier work and serve as a foundation for future Navier-Stokes research in weighted spaces."}}
{"id": "2508.06158", "pdf": "https://arxiv.org/pdf/2508.06158", "abs": "https://arxiv.org/abs/2508.06158", "authors": ["Kouichi Hirotani", "Hsien Shang", "Ruben Krasnopolsky", "Satoki Matsushita", "Britton Jeter", "Keiichi Asada"], "title": "Constraining Active Galactic Nucleus Jets with Spectrum and Core Shift: The Case of M87", "categories": ["astro-ph.HE", "physics.plasm-ph"], "comment": "26 pages, 21 figures. Astrophysical Journal in press", "summary": "We analytically model stationary and axisymmetric active galactic nucleus\njets, assuming energy conservation along each magnetic flux tube. Using\nvery-long-baseline interferometry (VLBI) observations and published general\nrelativistic magnetohydrodynamic simulations, we constrain the evolution of the\nbulk Lorentz factor, the magnetization parameter, and the magnetic field\nstrength along the jet. We then infer the electron density, emission\ncoefficient, and absorption coefficient at each point, and integrate the\nradiative transfer equation to compute the spectral energy distribution (SED)\nand the core shift of the synchrotron emission from the relativistic jet.\nApplying the method to the M87 jet, we find that the hot plasmas are injected\nat the altitude of seven Schwarzschild radii from the black hole (BH), that the\nM87 jet is likely composed of a pair plasma, and that the jet flowline geometry\nis quasi-parabolic as reported at much greater distances. Fitting the\nnonthermal fraction of the leptonic jet as a function of position, we also find\nthat most of the radio photons are emitted within 1000 Schwarzschild radii from\nthe BH. Although hadronic jets do not reproduce all the VLBI observations\nconsistently in our model, we also discuss that their heavy mass allows a\nstronger magnetic field within the observational constraints, leading to an\ninverted SED in sub-millimeter wavelengths by the thermal emission from the jet\nbase. It is therefore implied that contemporaneous observations of the M87 jet\nwith Atacama Large Millimeter/submillimeter Array (ALMA) and VLBI could\ndiscriminate the jet composition and its collimation within the central 100\nSchwarzschild radii.", "AI": {"tldr": "The paper models AGN jets analytically, using VLBI and simulations to infer jet properties, applies it to M87, and suggests ALMA and VLBI observations could determine jet composition and collimation.", "motivation": "To understand the properties and evolution of AGN jets, particularly the M87 jet, by combining analytical modeling with observational data.", "method": "Analytical modeling of jets with energy conservation, using VLBI observations and simulations to constrain parameters, and integrating radiative transfer for SED and core shift calculations.", "result": "Found plasma injection at 7 Schwarzschild radii, M87 jet likely pair plasma, quasi-parabolic geometry, and radio emission within 1000 Schwarzschild radii. Hadronic jets show potential for inverted SED.", "conclusion": "Combined ALMA and VLBI observations could discriminate jet composition and collimation near the black hole."}}
{"id": "2508.06378", "pdf": "https://arxiv.org/pdf/2508.06378", "abs": "https://arxiv.org/abs/2508.06378", "authors": ["Lei-Hong Zhang", "Ya-Nan Zhang", "Chenkun Zhang", "Shanheng Han"], "title": "Rational minimax approximation of matrix-valued functions", "categories": ["math.NA", "cs.NA", "41A50, 41A20, 65D15, 90C46"], "comment": "31 pages", "summary": "In this paper, we present a rigorous framework for rational minimax\napproximation of matrix-valued functions that generalizes classical scalar\napproximation theory. Given sampled data $\\{(x_\\ell, {F}(x_\\ell))\\}_{\\ell=1}^m$\nwhere ${F}:\\mathbb{C} \\to \\mathbb{C}^{s \\times t}$ is a matrix-valued function,\nwe study the problem of finding a matrix-valued rational approximant ${R}(x) =\n{P}(x)/q(x)$ (with ${P}:\\mathbb{C} \\to \\mathbb{C}^{s \\times t}$ a matrix-valued\npolynomial and $q(x)$ a nonzero scalar polynomial of prescribed degrees) that\nminimizes the worst-case Frobenius norm error over the given nodes: $$\n\\inf_{{R}(x) = {P}(x)/q(x)} \\max_{1 \\leq \\ell \\leq m} \\|{F}(x_\\ell) -\n{R}(x_\\ell)\\|_{\\rm F}. $$ By reformulating this min-max optimization problem\nthrough Lagrangian duality, we derive a maximization dual problem over the\nprobability simplex. We analyze weak and strong duality properties and\nestablish a sufficient condition ensuring that the solution of the dual problem\nyields the minimax approximant $R(x)$. For numerical implementation, we propose\nan efficient method (\\textsf{m-d-Lawson}) to solve the dual problem,\ngeneralizing Lawson's iteration to matrix-valued functions. Numerical\nexperiments are conducted and compared to state-of-the-art approaches,\ndemonstrating its efficiency as a novel computational framework for\nmatrix-valued rational approximation.", "AI": {"tldr": "A framework for matrix-valued rational minimax approximation, generalizing scalar theory, with a dual problem approach and efficient numerical method.", "motivation": "To extend classical scalar approximation theory to matrix-valued functions, addressing the challenge of minimizing worst-case Frobenius norm errors.", "method": "Reformulates the min-max problem via Lagrangian duality, derives a dual problem over the probability simplex, and proposes an efficient numerical method (m-d-Lawson).", "result": "The dual problem solution yields the minimax approximant under certain conditions, with numerical experiments showing efficiency.", "conclusion": "The framework provides a novel and effective computational approach for matrix-valued rational approximation."}}
{"id": "2508.06144", "pdf": "https://arxiv.org/pdf/2508.06144", "abs": "https://arxiv.org/abs/2508.06144", "authors": ["Lucie Baudouin", "Sylvain Ervedoza"], "title": "Event triggered control and exponential stability for infinite dimensional linear systems $\\star$", "categories": ["math.AP"], "comment": null, "summary": "This article aims at providing a unified analysis of the exponential\nstabilization of some abstract infinite dimensional systems undergoing an\nevent-triggering mechanism that samples the control input. The partial\ndifferential equation is supposed to be defined by a skew-adjoint operator and\ncontrolled and observed through bounded operators. The continuously controlled\nclosed loop system is assumed to be exponentially stable and the goal is to\nprove that a well-designed event-triggering mechanism to rule the time updates\nof the sampled control will allow to keep such a stability property. The key of\nthe proof relies on the existence of an adequate Lyapunov functional. Existence\nand regularity of the solution to the closed-loop event-triggered system are\nalso proven, along with the avoidance of Zeno behavior.", "AI": {"tldr": "The paper analyzes exponential stabilization of infinite-dimensional systems with event-triggered control, ensuring stability and avoiding Zeno behavior.", "motivation": "To unify the analysis of exponential stabilization for abstract infinite-dimensional systems using event-triggered control, maintaining stability properties.", "method": "Uses a Lyapunov functional to design an event-triggering mechanism for sampled control, ensuring stability and solution regularity.", "result": "Proves exponential stability, solution existence/regularity, and avoidance of Zeno behavior for the closed-loop system.", "conclusion": "A well-designed event-triggering mechanism preserves stability in infinite-dimensional systems, validated by Lyapunov analysis."}}
{"id": "2508.06408", "pdf": "https://arxiv.org/pdf/2508.06408", "abs": "https://arxiv.org/abs/2508.06408", "authors": ["Huan Zhang", "Hui Zhang", "Yan Wang", "Yingxiang Xu"], "title": "Heterogeneous optimized Schwarz Methods for heat conduction in composites with thermal contact resistance", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Heat transfer in composites is critical in engineering, where imperfect layer\ncontact causes thermal contact resistance (TCR), leading to interfacial\ntemperature discontinuity. We propose solving this numerically using the\noptimized Schwarz method (OSM), which decouples the heterogeneous problem into\nhomogeneous subproblems. This avoids ill-conditioned systems from monolithic\nsolving due to high contrast and interface jumps. Both energy estimate and\nFourier analysis are used to prove the convergence of this algorithm when the\nstandard Robin condition is applied to transmit information between subdomains.\nTo achieve fast convergence, instead of the standard Robin, the scaled Robin\ntransmission condition is proposed, and the involved free parameter is\nrigorously optimized. The results reveal several new findings due to the\npresence of TCR: first, the larger the TCR, the faster the OSM converges;\nsecond, mesh-independent convergence is achieved in the asymptotic sense, in\ncontrast to the mesh-dependent results without TCR; and last, the heterogeneity\ncontrast benefits the convergence, with a larger contrast leading to faster\nconvergence. Interestingly, different from the case without TCR, the thermal\nconductivity also benefits the convergence, similar to the effect of\nheterogeneity. Numerical experiments confirm the theoretical findings and\ndemonstrate the method's potential for nonlinear problems on irregular domains.", "AI": {"tldr": "The paper proposes using the optimized Schwarz method (OSM) to solve heat transfer in composites with thermal contact resistance (TCR). It introduces a scaled Robin transmission condition for faster convergence and analyzes its benefits, such as mesh independence and improved convergence with larger TCR and heterogeneity contrast.", "motivation": "Imperfect layer contact in composites causes TCR, leading to interfacial temperature discontinuity, which complicates heat transfer analysis. Traditional monolithic solving methods face ill-conditioned systems due to high contrast and interface jumps.", "method": "The OSM decouples the heterogeneous problem into homogeneous subproblems. A scaled Robin transmission condition replaces the standard Robin to optimize convergence, with rigorous parameter optimization. Energy estimate and Fourier analysis validate convergence.", "result": "Larger TCR and heterogeneity contrast accelerate OSM convergence. Mesh-independent convergence is achieved asymptotically, unlike mesh-dependent results without TCR. Thermal conductivity also aids convergence, similar to heterogeneity.", "conclusion": "The OSM with scaled Robin transmission effectively addresses TCR in composites, offering faster convergence and mesh independence. Numerical experiments validate its potential for nonlinear problems on irregular domains."}}
{"id": "2508.06164", "pdf": "https://arxiv.org/pdf/2508.06164", "abs": "https://arxiv.org/abs/2508.06164", "authors": ["Razvan Gabriel Iagar", "Philippe Lauren\u00e7ot"], "title": "Sharp non-existence threshold for a parabolic Hardy-H{\u00e9}non equation with quasilinear diffusion", "categories": ["math.AP"], "comment": null, "summary": "Optimal conditions for initial data leading to non-existence of non-negative\nsolutions to the Cauchy problem for the parabolic Hardy-H{\\'e}non equation $$\n\\partial\\_tu=\\Delta u^m+|x|^{\\sigma}u^p, \\quad\n(t,x)\\in(0,\\infty)\\times\\mathbb{R}^N, $$ with $m>0$, $\\sigma>0$ and\n$p>\\max\\{1,m\\}$, are identified. Assuming that the initial condition satisfies\n$$ u\\_0\\in L^{\\infty}(\\mathbb{R}^N), \\quad\n\\lim\\limits\\_{|x|\\to\\infty}|x|^{\\gamma}u\\_0(x)=L\\in(0,\\infty), \\quad u\\_0\\geq0,\n$$ it is shown that non-existence of solution occurs for $$\n\\gamma<\\frac{\\sigma+2}{p-m} - \\frac{2\\max{\\{p-p\\_G,0\\}}}{(p-1)(p-m)} $$ with $$\np\\_G:=1+\\frac{\\sigma(1-m)}{2}. $$ The above threshold for non-existence is\noptimal, in view of the existence of self-similar solutions for the limiting\nvalue of $\\gamma$.", "AI": {"tldr": "The paper identifies optimal conditions for initial data leading to non-existence of non-negative solutions to a parabolic Hardy-H\u00e9non equation. It shows a threshold for non-existence based on initial conditions and parameters.", "motivation": "To determine the precise conditions under which non-negative solutions to the Cauchy problem for the parabolic Hardy-H\u00e9non equation fail to exist, given specific initial data.", "method": "Analyzes the equation with parameters m, \u03c3, and p, and derives a threshold for \u03b3 in the initial condition that leads to non-existence of solutions.", "result": "Non-existence occurs for \u03b3 below a derived threshold, which is shown to be optimal by comparing with self-similar solutions.", "conclusion": "The threshold for \u03b3 is optimal, as confirmed by the existence of self-similar solutions at the limiting value."}}
{"id": "2508.06487", "pdf": "https://arxiv.org/pdf/2508.06487", "abs": "https://arxiv.org/abs/2508.06487", "authors": ["Akash Sharma"], "title": "Weak approximation of stochastic differential equations with sticky boundary conditions", "categories": ["math.NA", "cs.NA", "math.PR"], "comment": null, "summary": "Sticky diffusion models a Markovian particle experiencing reflection and\ntemporary adhesion phenomena at the boundary. Numerous numerical schemes exist\nfor approximating stopped or reflected stochastic differential equations\n(SDEs), but this is not the case for sticky SDEs. In this paper, we construct\nand analyze half-order and first-order numerical schemes for the weak\napproximation of stochastic differential equations with sticky boundary\nconditions. We present the algorithms in general setting such that they can be\nused to solve general linear parabolic partial differential equations with\nsecond-order sticky boundary condition via the probabilistic representations of\ntheir solutions. Since the sticky diffusion spends non-zero amount of time on\nboundary, it poses extra challenge in designing the schemes and obtaining their\norder of convergence. We support the theoretical results with numerical\nexperiments.", "AI": {"tldr": "The paper introduces numerical schemes for approximating sticky SDEs, addressing the lack of existing methods for such boundary conditions.", "motivation": "Existing numerical schemes focus on stopped or reflected SDEs, leaving a gap for sticky SDEs, which involve boundary adhesion.", "method": "Constructs half-order and first-order numerical schemes for weak approximation of sticky SDEs, applicable to linear parabolic PDEs with sticky boundary conditions.", "result": "Theoretical analysis and numerical experiments validate the schemes' convergence and effectiveness.", "conclusion": "The proposed schemes fill a gap in numerical methods for sticky SDEs and demonstrate practical utility for solving related PDEs."}}
{"id": "2508.06209", "pdf": "https://arxiv.org/pdf/2508.06209", "abs": "https://arxiv.org/abs/2508.06209", "authors": ["Rahmonov Askar Ahmadovich"], "title": "Inverse Source Problems for the Time-Fractional Evolution Equation", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we investigate the direct and linear inverse problems of\nidentifying time-dependent and time-independent source terms in a\ntime-fractional diffusion-wave equation, using measured data at an interior\npoint of the time interval. We first establish the existence, uniqueness, and\nregularity of the solution to the direct problem by employing the spectral\nmethod. Then, based on the properties of the direct problem, we study two\ninverse problems: one involving the recovery of a time-independent source term,\nand the other concerning the identification of a time-dependent coefficient\nfunction in the source term.", "AI": {"tldr": "The paper studies inverse problems for identifying source terms in a time-fractional diffusion-wave equation using interior point data.", "motivation": "To address the challenges of identifying time-dependent and time-independent source terms in fractional diffusion-wave equations, which are crucial for modeling real-world phenomena.", "method": "The spectral method is used to analyze the direct problem for existence, uniqueness, and regularity. Inverse problems are then tackled using properties derived from the direct problem.", "result": "The study establishes the feasibility of recovering both time-independent and time-dependent source terms from measured data.", "conclusion": "The proposed approach effectively solves the inverse problems, providing a foundation for further applications in modeling and analysis."}}
{"id": "2508.05764", "pdf": "https://arxiv.org/pdf/2508.05764", "abs": "https://arxiv.org/abs/2508.05764", "authors": ["Arvind K. Saibaba", "Ilse C. F. Ipsen"], "title": "Stochastic Trace Optimization of Parameter Dependent Matrices Based on Statistical Learning Theory", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "15A15, 65F99, 65C05, 68W20, 68Q32"], "comment": "3 figures", "summary": "We consider matrices $\\boldsymbol{A}(\\boldsymbol\\theta)\\in\\mathbb{R}^{m\\times\nm}$ that depend, possibly nonlinearly, on a parameter $\\boldsymbol\\theta$ from\na compact parameter space $\\Theta$. We present a Monte Carlo estimator for\nminimizing $\\text{trace}(\\boldsymbol{A}(\\boldsymbol\\theta))$ over all\n$\\boldsymbol\\theta\\in\\Theta$, and determine the sampling amount so that the\nbackward error of the estimator is bounded with high probability. We derive two\ntypes of bounds, based on epsilon nets and on generic chaining. Both types\npredict a small sampling amount for matrices\n$\\boldsymbol{A}(\\boldsymbol\\theta)$ with small offdiagonal mass, and parameter\nspaces $\\Theta$ of small ``size.'' Dependence on the matrix dimension~$m$ is\nonly weak or not explicit. The bounds based on epsilon nets are easier to\nevaluate and come with fully specified constants. In contrast, the bounds based\non chaining depend on the Talagrand functionals which are difficult to\nevaluate, except in very special cases. Comparisons between the two types of\nbounds are difficult, although the literature suggests that chaining bounds can\nbe superior.", "AI": {"tldr": "A Monte Carlo estimator is proposed for minimizing the trace of parameter-dependent matrices, with bounds on sampling amount for backward error control. Two bound types (epsilon nets and generic chaining) are derived, favoring small offdiagonal mass and compact parameter spaces.", "motivation": "To efficiently minimize the trace of matrices dependent on parameters, ensuring bounded backward error with high probability.", "method": "Monte Carlo estimator for trace minimization, with sampling bounds derived via epsilon nets and generic chaining.", "result": "Bounds predict small sampling for matrices with small offdiagonal mass and compact parameter spaces, with weak or implicit dependence on matrix dimension.", "conclusion": "Epsilon net bounds are easier to evaluate, while chaining bounds may be superior but are harder to compute. Comparisons between them remain challenging."}}
{"id": "2508.06241", "pdf": "https://arxiv.org/pdf/2508.06241", "abs": "https://arxiv.org/abs/2508.06241", "authors": ["Andrea Aspri", "Elena Beretta", "Elisa Francini", "Antonino Morassi", "Edi Rosset", "Eva Sincich", "Sergio Vessella"], "title": "Lipschitz Stability for Polyhedral Elastic Inclusions from Partial Data", "categories": ["math.AP"], "comment": null, "summary": "The paper deals with the inverse problem of determining a polyhedral\ninclusion compactly contained in an elastic body from boundary measurements of\ntraction and displacement taken on an open portion of the boundary. Both the\ninclusion and the body are made of homogeneous isotropic material. Under\nsuitable assumptions on the geometry of the unknown inclusion, we prove a\nconstructive Lipschitz stability estimate from the local Dirichlet-to-Neumann\nmap.", "AI": {"tldr": "The paper addresses the inverse problem of identifying a polyhedral inclusion in an elastic body using boundary measurements, proving a constructive Lipschitz stability estimate.", "motivation": "To solve the inverse problem of determining hidden inclusions in elastic materials, which is crucial for applications like non-destructive testing and medical imaging.", "method": "Uses boundary measurements of traction and displacement on part of the boundary, assuming homogeneous isotropic materials and specific geometric conditions.", "result": "Proves a constructive Lipschitz stability estimate from the local Dirichlet-to-Neumann map.", "conclusion": "The method provides a stable and constructive way to identify polyhedral inclusions in elastic bodies."}}
{"id": "2508.05778", "pdf": "https://arxiv.org/pdf/2508.05778", "abs": "https://arxiv.org/abs/2508.05778", "authors": ["Jaemin Oh", "Jinsil Lee", "Youngjoon Hong"], "title": "Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": "21 pages, 5 figures, 6 tables", "summary": "Nudging is an empirical data assimilation technique that incorporates an\nobservation-driven control term into the model dynamics. The trajectory of the\nnudged system approaches the true system trajectory over time, even when the\ninitial conditions differ. For linear state space models, such control terms\ncan be derived under mild assumptions. However, designing effective nudging\nterms becomes significantly more challenging in the nonlinear setting. In this\nwork, we propose neural network nudging, a data-driven method for learning\nnudging terms in nonlinear state space models. We establish a theoretical\nexistence result based on the Kazantzis--Kravaris--Luenberger observer theory.\nThe proposed approach is evaluated on three benchmark problems that exhibit\nchaotic behavior: the Lorenz 96 model, the Kuramoto--Sivashinsky equation, and\nthe Kolmogorov flow.", "AI": {"tldr": "Neural network nudging is proposed to learn nudging terms for nonlinear state space models, validated on chaotic systems.", "motivation": "Designing effective nudging terms for nonlinear systems is challenging, motivating a data-driven approach.", "method": "Proposes neural network nudging, leveraging Kazantzis-Kravaris-Luenberger observer theory for theoretical grounding.", "result": "Evaluated on chaotic systems (Lorenz 96, Kuramoto-Sivashinsky, Kolmogorov flow), showing effectiveness.", "conclusion": "Neural network nudging is a viable method for nonlinear state space models, supported by theory and experiments."}}
{"id": "2508.06333", "pdf": "https://arxiv.org/pdf/2508.06333", "abs": "https://arxiv.org/abs/2508.06333", "authors": ["In-Jee Jeong", "Luis Mart\u00ednez-Zoroa", "Wojciech S. O\u017ca\u0144ski"], "title": "Instantaneous continuous loss of Sobolev regularity for the 3D incompressible Euler equation", "categories": ["math.AP"], "comment": "33 pages, 1 figure", "summary": "We prove instantaneous and continuous-in-time loss of supercritical Sobolev\nregularity for the 3D incompressible Euler equations in $\\mathbb{R}^{3}$.\nNamely, for any $s\\in (0,3/2)$ and $\\varepsilon >0$, we construct a\ndivergence-free initial vorticity $\\omega_0$ defined in $\\mathbb{R}^{3}$\nsatisfying $\\| \\omega_0 \\|_{H^s}\\leq \\varepsilon$, as well as $T>0$, $c>0$ and\na corresponding local-in-time solution $\\omega$ such that, for each $t\\in\n[0,T]$, $\\omega (\\cdot ,t ) \\in {H^{\\frac{s-ct}{1+ct}}}$ and $ \\omega (\\cdot ,t\n) \\not \\in {H^\\beta }$ for any $\\beta > \\frac{s-ct}{1+ct} $. Moreover, $\\omega$\nis unique among all solutions with initial condition $\\omega_0$ which are\nlocally $C^2$ and belong to $C([0,T];L^p )$ for any $p>3 $.", "AI": {"tldr": "The paper demonstrates the instantaneous and continuous loss of supercritical Sobolev regularity for the 3D incompressible Euler equations in \u211d\u00b3, constructing specific initial conditions and solutions to show this behavior.", "motivation": "To understand the regularity loss in solutions of the 3D Euler equations, which is crucial for analyzing fluid dynamics and turbulence.", "method": "Construct divergence-free initial vorticity with specific Sobolev regularity and analyze the corresponding local-in-time solution's behavior.", "result": "For any given Sobolev exponent s \u2208 (0, 3/2), the solution loses regularity continuously in time, with explicit bounds on the regularity loss.", "conclusion": "The study confirms the loss of supercritical Sobolev regularity in the 3D Euler equations, providing insights into the behavior of fluid flows and potential turbulence mechanisms."}}
{"id": "2508.05831", "pdf": "https://arxiv.org/pdf/2508.05831", "abs": "https://arxiv.org/abs/2508.05831", "authors": ["Alexander DeLise", "Kyle Loh", "Krish Patel", "Meredith Teague", "Andrea Arnold", "Matthias Chung"], "title": "Optimal Linear Baseline Models for Scientific Machine Learning", "categories": ["cs.LG", "cs.NA", "math.NA", "15A29 Inverse problems in linear algebra 65F22, 68T07, 65F05, 62C12", "G.1.3; F.2.1; I.2.6"], "comment": "40 pages, 10 Figures, 9 Tables", "summary": "Across scientific domains, a fundamental challenge is to characterize and\ncompute the mappings from underlying physical processes to observed signals and\nmeasurements. While nonlinear neural networks have achieved considerable\nsuccess, they remain theoretically opaque, which hinders adoption in contexts\nwhere interpretability is paramount. In contrast, linear neural networks serve\nas a simple yet effective foundation for gaining insight into these complex\nrelationships. In this work, we develop a unified theoretical framework for\nanalyzing linear encoder-decoder architectures through the lens of Bayes risk\nminimization for solving data-driven scientific machine learning problems. We\nderive closed-form, rank-constrained linear and affine linear optimal mappings\nfor forward modeling and inverse recovery tasks. Our results generalize\nexisting formulations by accommodating rank-deficiencies in data, forward\noperators, and measurement processes. We validate our theoretical results by\nconducting numerical experiments on datasets from simple biomedical imaging,\nfinancial factor analysis, and simulations involving nonlinear fluid dynamics\nvia the shallow water equations. This work provides a robust baseline for\nunderstanding and benchmarking learned neural network models for scientific\nmachine learning problems.", "AI": {"tldr": "The paper presents a theoretical framework for analyzing linear encoder-decoder architectures in scientific machine learning, focusing on interpretability and Bayes risk minimization.", "motivation": "To address the opacity of nonlinear neural networks and provide interpretable solutions for scientific machine learning problems.", "method": "Develops a unified framework using Bayes risk minimization, deriving closed-form, rank-constrained linear and affine linear optimal mappings for forward and inverse tasks.", "result": "Generalizes existing formulations to handle rank deficiencies and validates findings with numerical experiments across biomedical imaging, finance, and fluid dynamics.", "conclusion": "Offers a robust baseline for benchmarking neural network models in scientific machine learning, emphasizing interpretability."}}
{"id": "2508.06359", "pdf": "https://arxiv.org/pdf/2508.06359", "abs": "https://arxiv.org/abs/2508.06359", "authors": ["Abdelkrim Moussaoui"], "title": "Sub-supersolutions method for singular quasilinear systems involving gradient terms", "categories": ["math.AP"], "comment": null, "summary": "Existence, regularity and location of solutions to quasilinear singular\nelliptic systems with general gradient dependence are established developing a\nmethod of sub-supersolution. The abstract theorems involving sub-supersolutions\nare applied to prove the existence of positive solutions for convective and\nabsorption singular systems.", "AI": {"tldr": "Existence, regularity, and location of solutions for quasilinear singular elliptic systems with gradient dependence are proven using sub-supersolution methods.", "motivation": "To address the challenges of solving quasilinear singular elliptic systems with general gradient dependence.", "method": "Develops and applies a sub-supersolution method to analyze the systems.", "result": "Existence of positive solutions for convective and absorption singular systems is demonstrated.", "conclusion": "The sub-supersolution method effectively solves the problem, providing theoretical and practical insights."}}
{"id": "2508.05920", "pdf": "https://arxiv.org/pdf/2508.05920", "abs": "https://arxiv.org/abs/2508.05920", "authors": ["Chris Cama\u00f1o", "Raphael A. Meyer", "Kevin Shu"], "title": "Debiasing Polynomial and Fourier Regression", "categories": ["cs.DS", "cs.NA", "math.NA", "65F99", "G.1.3"], "comment": null, "summary": "We study the problem of approximating an unknown function\n$f:\\mathbb{R}\\to\\mathbb{R}$ by a degree-$d$ polynomial using as few function\nevaluations as possible, where error is measured with respect to a probability\ndistribution $\\mu$. Existing randomized algorithms achieve near-optimal sample\ncomplexities to recover a $ (1+\\varepsilon) $-optimal polynomial but produce\nbiased estimates of the best polynomial approximation, which is undesirable.\n  We propose a simple debiasing method based on a connection between polynomial\nregression and random matrix theory. Our method involves evaluating\n$f(\\lambda_1),\\ldots,f(\\lambda_{d+1})$ where $\\lambda_1,\\ldots,\\lambda_{d+1}$\nare the eigenvalues of a suitably designed random complex matrix tailored to\nthe distribution $\\mu$. Our estimator is unbiased, has near-optimal sample\ncomplexity, and experimentally outperforms iid leverage score sampling.\n  Additionally, our techniques enable us to debias existing methods for\napproximating a periodic function with a truncated Fourier series with\nnear-optimal sample complexity.", "AI": {"tldr": "The paper introduces a debiasing method for approximating an unknown function using polynomial regression, leveraging random matrix theory to achieve unbiased, near-optimal results.", "motivation": "Existing randomized algorithms for polynomial approximation produce biased estimates, which is undesirable. The goal is to develop an unbiased method with near-optimal sample complexity.", "method": "The proposed method evaluates the function at eigenvalues of a specially designed random complex matrix, tailored to the distribution of interest, to debias polynomial regression.", "result": "The estimator is unbiased, achieves near-optimal sample complexity, and outperforms iid leverage score sampling in experiments. It also debiases Fourier series approximation methods.", "conclusion": "The debiasing method effectively addresses bias in polynomial and Fourier series approximations, offering practical improvements over existing techniques."}}
{"id": "2508.06375", "pdf": "https://arxiv.org/pdf/2508.06375", "abs": "https://arxiv.org/abs/2508.06375", "authors": ["David Arcoya", "Jos\u00e9 Carmona", "Tommaso Leonori", "Pedro J. Mart\u00ednez-Aparicio", "Luigi Orsina", "Francesco Petitta"], "title": "Existence and nonexistence of solutions for singular quadratic quasilinear equations", "categories": ["math.AP"], "comment": null, "summary": "We study both existence and nonexistence of nonnegative solutions for\nnonlinear elliptic problems with singular lower order terms that have natural\ngrowth with respect to the gradient, whose model is $$ \\begin{cases}\n  -\\Delta u + \\frac{|\\nabla u|^2}{u^{\\gamma}} = f & \\mbox{in } \\Omega,\\newline\n  \\hfill u=0 \\hfill & \\mbox{on } \\partial \\Omega, \\end{cases} $$ where $\\Omega$\nis an open bounded subset of $\\mathbb{R}^N $, $\\gamma> 0$ and $f$ is a function\nwhich is strictly positive on every compactly contained subset of $\\Omega$. As\na consequence of our main results, we prove that the condition $\\gamma<2$ is\nnecessary and sufficient for the existence of solutions in $H^{1}_{0}(\\Omega)$\nfor every sufficiently regular $f$ as above.", "AI": {"tldr": "The paper investigates the existence and nonexistence of nonnegative solutions for nonlinear elliptic problems with singular gradient terms, showing that \u03b3<2 is necessary and sufficient for solutions in H\u00b9\u2080(\u03a9).", "motivation": "To understand the conditions under which solutions exist for nonlinear elliptic problems with singular lower order terms and natural gradient growth.", "method": "Analyzes the model problem involving a PDE with singular gradient terms and Dirichlet boundary conditions, focusing on the parameter \u03b3.", "result": "Proves that \u03b3<2 is necessary and sufficient for the existence of solutions in H\u00b9\u2080(\u03a9) for sufficiently regular f.", "conclusion": "The condition \u03b3<2 is critical for the existence of solutions in the given context."}}
{"id": "2508.06002", "pdf": "https://arxiv.org/pdf/2508.06002", "abs": "https://arxiv.org/abs/2508.06002", "authors": ["Yifeng Meng", "Chungen Shen", "Linuo Xue", "Lei-Hong Zhang"], "title": "Kahan's Automatic Step-Size Control for Unconstrained Optimization", "categories": ["math.OC", "cs.NA", "math.NA", "65L20, 65B99, 90C25"], "comment": "27 pages", "summary": "The Barzilai and Borwein (BB) gradient method is one of the most widely-used\nline-search gradient methods. It computes the step-size for the current iterate\nby using the information carried in the previous iteration. Recently, William\nKahan [Kahan, Automatic Step-Size Control for Minimization Iterations,\nTechnical report, University of California, Berkeley CA, USA, 2019] proposed\nnew Gradient Descent (KGD) step-size strategies which iterate the step-size\nitself by effectively utilizing the information in the previous iteration. In\nthe quadratic model, such a new step-size is shown to be mathematically\nequivalent to the long BB step, but no rigorous mathematical proof of its\nefficiency and effectiveness for the general unconstrained minimization is\navailable. In this paper, by this equivalence with the long BB step, we first\nderive a short version of KGD step-size and show that, for the strongly convex\nquadratic model with a Hessian matrix $H$, both the long and short KGD\nstep-size (and hence BB step-sizes) gradient methods converge at least\nR-linearly with a rate $1-\\frac{1}{{\\rm cond}(H)}$. For the general\nunconstrained minimization, we further propose an adaptive framework to\neffectively use the KGD step-sizes; global convergence and local R-linear\nconvergence rate are proved. Numerical experiments are conducted on the CUTEst\ncollection as well as the practical logistic regression problems, and we\ncompare the performance of the proposed methods with various BB step-size\napproaches and other recently proposed adaptive gradient methods to demonstrate\nthe efficiency and robustness.", "AI": {"tldr": "The paper analyzes the Kahan Gradient Descent (KGD) step-size strategies, showing equivalence to the Barzilai-Borwein (BB) step, and proves convergence rates for quadratic and general unconstrained minimization.", "motivation": "To rigorously analyze the efficiency and effectiveness of KGD step-size strategies, which iterate step-sizes using previous iteration information, and extend their application to general unconstrained minimization.", "method": "Derives a short KGD step-size, proves R-linear convergence for quadratic models, and proposes an adaptive framework for general minimization with global and local convergence proofs.", "result": "For quadratic models, KGD step-sizes converge R-linearly. The adaptive framework ensures global convergence and local R-linear rates for general problems. Numerical experiments validate efficiency and robustness.", "conclusion": "KGD step-sizes are effective and efficient, with proven convergence properties, and outperform other adaptive gradient methods in numerical tests."}}
{"id": "2508.06376", "pdf": "https://arxiv.org/pdf/2508.06376", "abs": "https://arxiv.org/abs/2508.06376", "authors": ["Minjiang Feng", "Sirui Li", "Qi Zeng"], "title": "Global strong solutions to the frame hydrodynamics for biaxial nematic phases", "categories": ["math.AP"], "comment": "30 pages", "summary": "In this article, we consider the frame hydrodynamics of biaxial nematic\nphases, a coupled system between the evolution of the orthonormal frame and the\nNavier--Stokes equation, which is derived from a molecular-theory-based\ndynamical tensor model about two second-order tensors. In two and three\ndimensions, we establish global well-posedness of strong solutions to the\nCauchy problem of frame hydrodynamics for small initial data. The key\ningredient of the proof relies on estimates of nonlinear terms with rotational\nderivatives on $SO(3)$, together with the dissipative structure of the frame\nhydrodynamics.", "AI": {"tldr": "Global well-posedness of strong solutions for frame hydrodynamics of biaxial nematic phases is proven for small initial data in 2D and 3D.", "motivation": "To study the coupled system of orthonormal frame evolution and Navier-Stokes equations derived from a molecular-theory-based dynamical tensor model.", "method": "Analysis of nonlinear terms with rotational derivatives on SO(3) and leveraging the dissipative structure of the system.", "result": "Global well-posedness of strong solutions for small initial data in two and three dimensions.", "conclusion": "The dissipative structure and careful estimates of nonlinear terms ensure the global existence of solutions for small data."}}
{"id": "2508.06025", "pdf": "https://arxiv.org/pdf/2508.06025", "abs": "https://arxiv.org/abs/2508.06025", "authors": ["Faruk Alpay", "Taylan Alpay", "Hamdi Alakkad"], "title": "Transfinite Iteration of Operator Transforms and Spectral Projections in Hilbert and Banach Spaces", "categories": ["math.FA", "cs.NA", "math.NA", "math.SP", "47A10, 47A60, 47A35, 47B15, 47D06, 47A15", "G.1.0; G.1.3; G.1.10"], "comment": "14 pages, no figures. Includes appendices on dominated convergence in\n  the normal functional calculus and a two-point Schur/Nevanlinna-Pick lemma", "summary": "We study ordinal-indexed, multi-layer iterations of bounded operator\ntransforms and prove convergence to spectral/ergodic projections under\nfunctional-calculus hypotheses. For normal operators on Hilbert space and\npolynomial or holomorphic layers that are contractive on the spectrum and fix\nthe peripheral spectrum only at fixed points, the iterates converge in the\nstrong operator topology by a countable stage to the spectral projection onto\nthe joint peripheral fixed set. We describe spectral mapping at finite stages\nand identify the spectrum of the limit via the essential range. In reflexive\nBanach spaces, for Ritt or sectorial operators with a bounded H-infinity\nfunctional calculus, the composite layer is power-bounded and its mean-ergodic\nprojection yields an idempotent commuting with the original operator; under a\nperipheral-separation condition the powers converge strongly to this\nprojection. We provide explicit two-layer Schur filters, a concise\nSchur/Nevanlinna-Pick lemma, a Fejer-type monotonicity bound implying\nstabilization by the first countable limit (omega), examples that attain\nexactly the omega stage, and counterexamples outside the hypotheses.", "AI": {"tldr": "The paper studies multi-layer iterations of bounded operator transforms, proving convergence to spectral/ergodic projections under specific conditions. It covers normal operators on Hilbert space and reflexive Banach spaces, providing explicit examples and counterexamples.", "motivation": "To understand the convergence behavior of ordinal-indexed, multi-layer iterations of bounded operator transforms under functional-calculus hypotheses, and to identify spectral properties and ergodic projections.", "method": "The study involves analyzing normal operators on Hilbert space and Ritt or sectorial operators in reflexive Banach spaces. It uses functional-calculus hypotheses, spectral mapping, and ergodic theory to prove convergence.", "result": "For normal operators, iterates converge strongly to spectral projections. In Banach spaces, composite layers yield power-bounded projections. Explicit examples and counterexamples are provided.", "conclusion": "The paper establishes convergence results for operator iterations under specific conditions, with applications in spectral theory and ergodic projections, supported by examples and counterexamples."}}
{"id": "2508.06384", "pdf": "https://arxiv.org/pdf/2508.06384", "abs": "https://arxiv.org/abs/2508.06384", "authors": ["Francesco Petitta", "Augusto C. Ponce", "Alessio Porretta"], "title": "Diffuse measures and nonlinear parabolic equations", "categories": ["math.AP"], "comment": null, "summary": "Given a parabolic cylinder $Q =(0,T)\\times\\Omega$, where $\\Omega\\subset\n\\mathbb{R}^{N}$ is a bounded domain, we prove new properties of solutions of \\[\nu_t-\\Delta_p u = \\mu \\quad \\text{in $Q$} \\] with Dirichlet boundary conditions,\nwhere $\\mu$ is a finite Radon measure in $Q$. We first prove a priori estimates\non the $p$-parabolic capacity of level sets of $u$. We then show that diffuse\nmeasures (i.e.\\@ measures which do not charge sets of zero parabolic\n$p$-capacity) can be strongly approximated by the measures $\\mu_k =\n(T_k(u))_t-\\Delta_p(T_k(u))$, and we introduce a new notion of renormalized\nsolution based on this property. We finally apply our new approach to prove the\nexistence of solutions of $$ u_t-\\Delta_{p} u + h(u)=\\mu \\quad \\text{in $Q$,}\n$$ for any function $h$ such that $h(s)s\\geq 0$ and for any diffuse measure\n$\\mu$; when $h$ is nondecreasing we also prove uniqueness in the renormalized\nformulation. Extensions are given to the case of more general nonlinear\noperators in divergence form.", "AI": {"tldr": "The paper studies properties of solutions to a parabolic PDE with Dirichlet boundary conditions, focusing on a priori estimates, diffuse measures, and renormalized solutions. It also extends results to nonlinear operators.", "motivation": "To analyze solutions of parabolic PDEs involving p-Laplacian and diffuse measures, aiming to generalize existing results and introduce new solution concepts.", "method": "Proves a priori estimates for p-parabolic capacity, approximates diffuse measures, and introduces renormalized solutions. Applies these to solve PDEs with nonlinear terms.", "result": "Existence of solutions for PDEs with nonlinear terms and diffuse measures, with uniqueness under nondecreasing conditions. Extends to general nonlinear operators.", "conclusion": "The paper advances the understanding of parabolic PDEs with diffuse measures, introducing renormalized solutions and proving existence/uniqueness results."}}
{"id": "2508.06316", "pdf": "https://arxiv.org/pdf/2508.06316", "abs": "https://arxiv.org/abs/2508.06316", "authors": ["Theresa Pollinger", "Masado Ishii", "Jens Domke"], "title": "The Beauty of Anisotropic Mesh Refinement: Omnitrees for Efficient Dyadic Discretizations", "categories": ["cs.DS", "cs.CG", "cs.GR", "cs.IT", "cs.NA", "math.IT", "math.NA", "65D15, 65D18, 68P05, 68P30"], "comment": "contains pdf animations; we recommend Okular or Firefox for viewing", "summary": "Structured adaptive mesh refinement (AMR), commonly implemented via quadtrees\nand octrees, underpins a wide range of applications including databases,\ncomputer graphics, physics simulations, and machine learning. However, octrees\nenforce isotropic refinement in regions of interest, which can be especially\ninefficient for problems that are intrinsically anisotropic--much resolution is\nspent where little information is gained. This paper presents omnitrees as an\nanisotropic generalization of octrees and related data structures. Omnitrees\nallow to refine only the locally most important dimensions, providing tree\nstructures that are less deep than bintrees and less wide than octrees. As a\nresult, the convergence of the AMR schemes can be increased by up to a factor\nof the dimensionality d for very anisotropic problems, quickly offsetting their\nmodest increase in storage overhead. We validate this finding on the problem of\nbinary shape representation across 4,166 three-dimensional objects: Omnitrees\nincrease the mean convergence rate by 1.5x, require less storage to achieve\nequivalent error bounds, and maximize the information density of the stored\nfunction faster than octrees. These advantages are projected to be even\nstronger for higher-dimensional problems. We provide a first validation by\nintroducing a time-dependent rotation to create four-dimensional\nrepresentations, and discuss the properties of their 4-d octree and omnitree\napproximations. Overall, omnitree discretizations can make existing AMR\napproaches more efficient, and open up new possibilities for high-dimensional\napplications.", "AI": {"tldr": "Omnitrees generalize octrees for anisotropic problems, improving convergence and storage efficiency, validated on 3D and 4D tasks.", "motivation": "Octrees enforce isotropic refinement, which is inefficient for anisotropic problems. Omnitrees address this by allowing refinement only in important dimensions.", "method": "Introduces omnitrees as an anisotropic generalization of octrees, refining only locally important dimensions to optimize tree structure depth and width.", "result": "Omnitrees improve convergence rates by 1.5x, reduce storage for equivalent error bounds, and maximize information density faster than octrees, especially in higher dimensions.", "conclusion": "Omnitrees enhance AMR efficiency for anisotropic problems and enable new high-dimensional applications."}}
{"id": "2508.06390", "pdf": "https://arxiv.org/pdf/2508.06390", "abs": "https://arxiv.org/abs/2508.06390", "authors": ["Kenneth H. Karlsen", "Francesco Petitta", "Suleyman Ulusoy"], "title": "A duality approach to the fractional Laplacian with measure data", "categories": ["math.AP"], "comment": null, "summary": "We describe a duality method to prove both existence and uniqueness of\nsolutions to nonlocal problems like $$ (-\\Delta)^s v = \\mu \\quad \\text{in}\\\n\\mathbb{R}^N, $$ with vanishing conditions at infinity.\n  Here $\\mu$ is a bounded Radon measure whose support is compactly contained in\n$\\mathbb{R}^N$, $N\\geq2$, and $-(\\Delta)^s$ is the fractional Laplace operator\nof order $s\\in (1/2,1)$.", "AI": {"tldr": "A duality method is introduced to prove existence and uniqueness of solutions to nonlocal problems involving the fractional Laplacian with compactly supported measures.", "motivation": "To address the challenge of solving nonlocal problems with vanishing conditions at infinity, particularly for the fractional Laplacian.", "method": "A duality method is employed to analyze the problem.", "result": "Existence and uniqueness of solutions are proven for the given nonlocal problem.", "conclusion": "The duality method effectively resolves the nonlocal problem with compactly supported measures."}}
{"id": "2508.06486", "pdf": "https://arxiv.org/pdf/2508.06486", "abs": "https://arxiv.org/abs/2508.06486", "authors": ["Tyler Chen", "Ethan N. Epperly", "Raphael A. Meyer", "Christopher Musco", "Akash Rao"], "title": "Does block size matter in randomized block Krylov low-rank approximation?", "categories": ["cs.DS", "cs.NA", "math.NA", "65F55 65F15", "G.1.3; F.2.1"], "comment": null, "summary": "We study the problem of computing a rank-$k$ approximation of a matrix using\nrandomized block Krylov iteration. Prior work has shown that, for block size $b\n= 1$ or $b = k$, a $(1 + \\varepsilon)$-factor approximation to the best\nrank-$k$ approximation can be obtained after $\\tilde O(k/\\sqrt{\\varepsilon})$\nmatrix-vector products with the target matrix. On the other hand, when $b$ is\nbetween $1$ and $k$, the best known bound on the number of matrix-vector\nproducts scales with $b(k-b)$, which could be as large as $O(k^2)$.\nNevertheless, in practice, the performance of block Krylov methods is often\noptimized by choosing a block size $1 \\ll b \\ll k$. We resolve this\ntheory-practice gap by proving that randomized block Krylov iteration produces\na $(1 + \\varepsilon)$-factor approximate rank-$k$ approximation using $\\tilde\nO(k/\\sqrt{\\varepsilon})$ matrix-vector products for any block size $1\\le b\\le\nk$. Our analysis relies on new bounds for the minimum singular value of a\nrandom block Krylov matrix, which may be of independent interest. Similar\nbounds are central to recent breakthroughs on faster algorithms for sparse\nlinear systems [Peng & Vempala, SODA 2021; Nie, STOC 2022].", "AI": {"tldr": "The paper resolves the theory-practice gap in randomized block Krylov iteration for rank-$k$ matrix approximation, proving a $(1 + \\varepsilon)$-factor approximation is achievable with $\\tilde O(k/\\sqrt{\\varepsilon})$ matrix-vector products for any block size $1 \\le b \\le k$.", "motivation": "Prior work showed inefficiencies or gaps in performance for block sizes between $1$ and $k$, despite practical optimizations. This paper aims to bridge this gap.", "method": "The study uses randomized block Krylov iteration, analyzing the minimum singular value of random block Krylov matrices.", "result": "The paper proves that the method achieves a $(1 + \\varepsilon)$-factor approximation efficiently for any block size $1 \\le b \\le k$.", "conclusion": "The findings close the theory-practice gap and provide insights applicable to faster algorithms for sparse linear systems."}}
{"id": "2508.05714", "pdf": "https://arxiv.org/pdf/2508.05714", "abs": "https://arxiv.org/abs/2508.05714", "authors": ["Kousuke Kuto", "Juli\u00e1n L\u00f3pez-G\u00f3mez", "Eduardo Mu\u00f1oz-Hern\u00e1ndez"], "title": "High multiplicity and global structure of coexistence states in a predator-prey model with saturation", "categories": ["math.DS", "math.AP", "35J57, 92D40, 34C23, 70K05"], "comment": "30 pages, 5 figures", "summary": "This paper establishes that, under the appropriate range of values of the\nparameters involved in the formulation of the model, a diffusive predator-prey\nsystem with saturation can have an arbitrarily large number of coexistence\nstates for sufficiently large saturation rates. Moreover, it ascertains the\nglobal structure of the set of coexistence states in the limiting system as the\nsaturation rate blows-up.", "AI": {"tldr": "A diffusive predator-prey system with saturation can exhibit numerous coexistence states under certain parameter ranges, especially with high saturation rates.", "motivation": "To explore the conditions under which a predator-prey system with saturation can sustain multiple coexistence states.", "method": "Analysis of the model under varying parameter values, focusing on the saturation rate's impact.", "result": "The system can have arbitrarily many coexistence states for large saturation rates, with a detailed global structure in the limiting case.", "conclusion": "Saturation rates significantly influence the diversity of coexistence states in predator-prey systems."}}
{"id": "2508.05986", "pdf": "https://arxiv.org/pdf/2508.05986", "abs": "https://arxiv.org/abs/2508.05986", "authors": ["Robert Marangell", "Dmitry E. Pelinovsky"], "title": "Selection of the ground state on a compact metric graph", "categories": ["math.SP", "math.AP"], "comment": "37 pages, 7 figures", "summary": "We show that the ground state in the Fisher--KPP model on a compact metric\ngraph with Dirichlet conditions on boundary vertices is either trivial (zero)\nor nontrivial and strictly positive. For positive initial data, we prove that\nthe trivial ground state is globally asymptotically stable if the edges of the\nmetric graph are uniformly small and the nontrivial ground state is globally\nasymptotically stable if the edges are uniformly large. For the intermediate\ncase, we find a sharp criterion for the existence, uniqueness and global\nasymptotic stability of the trivial versus nontrivial ground state. Besides\nstandard methods based on the comparison theory, energy minimizers, and the\nlowest eigenvalue of the graph Laplacian, we develop a novel method based on\nthe period function for differential equations to characterize the nontrivial\nground state in the particular case of flower graphs.", "AI": {"tldr": "The paper analyzes the Fisher-KPP model on compact metric graphs, showing ground states are either trivial or nontrivial. Stability depends on edge sizes, with a sharp criterion for intermediate cases. A novel method using the period function is introduced for flower graphs.", "motivation": "To understand the ground states of the Fisher-KPP model on metric graphs and their stability under varying edge conditions.", "method": "Uses comparison theory, energy minimizers, graph Laplacian eigenvalues, and introduces a novel period function method for flower graphs.", "result": "Trivial ground state is stable for small edges, nontrivial for large edges, with a sharp criterion for intermediate cases.", "conclusion": "The study provides a comprehensive stability analysis of ground states in the Fisher-KPP model on metric graphs, with a new method for flower graphs."}}
{"id": "2508.06019", "pdf": "https://arxiv.org/pdf/2508.06019", "abs": "https://arxiv.org/abs/2508.06019", "authors": ["Adrian Chun-Pong Chu"], "title": "Minimal surfaces with arbitrary genus in 3-spheres of positive Ricci curvature", "categories": ["math.DG", "math.AP", "math.GT"], "comment": "60 pages", "summary": "We describe some topological structure in the set of all surfaces with\nfinitely many singularities in the 3-sphere.\n  As an application, we prove that every Riemannian 3-sphere of positive Ricci\ncurvature contains, for every g, a genus g embedded minimal surface with area\nat most twice the first Simon-Smith width of the ambient 3-sphere.", "AI": {"tldr": "The paper explores topological structures in surfaces with singularities in the 3-sphere and applies this to prove a result about minimal surfaces in Riemannian 3-spheres.", "motivation": "To understand the topological properties of surfaces with singularities in the 3-sphere and apply this knowledge to Riemannian geometry.", "method": "Analyzes the topological structure of surfaces with finitely many singularities in the 3-sphere and uses this to study minimal surfaces.", "result": "Proves that every Riemannian 3-sphere of positive Ricci curvature contains a genus g embedded minimal surface with area bounded by twice the first Simon-Smith width.", "conclusion": "The study provides insights into the interplay between topology and geometry, particularly in the context of minimal surfaces in positively curved spaces."}}
{"id": "2508.06029", "pdf": "https://arxiv.org/pdf/2508.06029", "abs": "https://arxiv.org/abs/2508.06029", "authors": ["Alex R. Taylor"], "title": "An index formula for families of end-periodic Dirac operators", "categories": ["math.DG", "math.AP", "math.GT", "58J20, 58J28, 58J35, 35K05, 19K56"], "comment": "58 pages", "summary": "We derive a transgression formula for the renormalized Chern character of the\nBismut superconnection in the context of end-periodic fiber bundles and\nfamilies of end-periodic Clifford modules. The transgression is expressed in\nterms of the Fourier-Laplace transform of the Bismut superconnection using the\nrenormalized supertrace of Mrowka-Ruberman-Saveliev. Consequently, we establish\nan index formula for families of Dirac operators on end-periodic manifolds. The\nindex formula involves a new ``end-periodic eta form'' which generalizes both\nthe Bismut-Cheeger eta form and the end-periodic eta invariant of\nMrowka-Ruberman-Saveliev.", "AI": {"tldr": "A transgression formula for the renormalized Chern character of the Bismut superconnection is derived, leading to an index formula for families of Dirac operators on end-periodic manifolds, involving a new 'end-periodic eta form'.", "motivation": "To generalize the Bismut-Cheeger eta form and the end-periodic eta invariant by deriving a transgression formula in the context of end-periodic fiber bundles and Clifford modules.", "method": "Uses the Fourier-Laplace transform of the Bismut superconnection and the renormalized supertrace of Mrowka-Ruberman-Saveliev.", "result": "An index formula for families of Dirac operators on end-periodic manifolds, incorporating a new end-periodic eta form.", "conclusion": "The work extends existing eta forms and invariants, providing a unified framework for index theory in end-periodic settings."}}
