<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 27]
- [math.AP](#math.AP) [Total: 36]
- [physics.comp-ph](#physics.comp-ph) [Total: 6]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 4]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [nlin.PS](#nlin.PS) [Total: 1]
- [math.PR](#math.PR) [Total: 2]
- [physics.acc-ph](#physics.acc-ph) [Total: 1]
- [math.FA](#math.FA) [Total: 2]
- [physics.bio-ph](#physics.bio-ph) [Total: 1]
- [cs.SD](#cs.SD) [Total: 2]
- [math.MG](#math.MG) [Total: 1]
- [gr-qc](#gr-qc) [Total: 2]
- [math.OC](#math.OC) [Total: 3]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 2]
- [math.DG](#math.DG) [Total: 1]
- [physics.atom-ph](#physics.atom-ph) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 2]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [cs.LG](#cs.LG) [Total: 4]
- [nlin.CD](#nlin.CD) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A note on generating Voronoi cells with a given size distribution](https://arxiv.org/abs/2508.06630)
*Georg Stadler,Gonzalo G. De Diego*

Main category: math.NA

TL;DR: A method for generating random points to achieve Voronoi cells with a desired size distribution, like a power law, is presented and tested in 2D.


<details>
  <summary>Details</summary>
Motivation: To create Voronoi tessellations with cells that follow a specific size distribution, such as a power law, which is useful in various applications.

Method: A simple method for drawing random points to control the size distribution of Voronoi cells, demonstrated and verified numerically in 2D.

Result: The method successfully generates Voronoi tessellations with cells approximating the desired size distribution.

Conclusion: The proposed method is effective for creating Voronoi tessellations with controlled cell sizes, as validated by numerical examples.

Abstract: This note describes a simple method to draw random points such that the cells
of the corresponding Voronoi tesselation (approximately) satisfy a desired size
distribution, for instance, follow a power law. The method is illustrated and
numerically verified in two dimensions, and we also provide a simple
implementation.

</details>


### [2] [Diffeomorphic Neural Operator Learning](https://arxiv.org/abs/2508.06690)
*Seth Taylor,Alex Bihlo,Jean-Christophe Nave*

Main category: math.NA

TL;DR: An operator learning method for evolution operators using diffeomorphisms, preserving symmetries and demonstrating benefits in turbulent fluid dynamics.


<details>
  <summary>Details</summary>
Motivation: To transform the semigroup structure of evolution operators into a group structure for improved time stepping and symmetry preservation.

Method: Composition of learned lift into diffeomorphism space and group action on field space, leveraging geometric structure.

Result: Demonstrates conservative properties, non-diffusivity, and captures statistical scaling relations in turbulent fluid dynamics.

Conclusion: Geometric operator learning with a priori structure enhances performance and preserves dynamics.

Abstract: We present an operator learning approach for a class of evolution operators
using a composition of a learned lift into the space of diffeomorphisms of the
domain and the group action on the field space. In turn, this transforms the
semigroup structure of the evolution operator into a corresponding group
structure allowing time stepping be performed through composition on the space
of diffeomorphisms rather than in the field space directly. This results in a
number of structure-preserving properties related to preserving a relabelling
symmetry of the dynamics as a hard constraint. We study the resolution
properties of our approach, along with its connection to the techniques of
diffeomorphic image registration. Numerical experiments on forecasting
turbulent fluid dynamics are provided, demonstrating its conservative
properties, non-diffusivity, and ability to capture anticipated statistical
scaling relations at sub-grid scales. Our method provides an example of
geometric operator learning and indicates a clear performance benefit from
leveraging a priori known infinite-dimensional geometric structure.

</details>


### [3] [Computable Poincaré--Friedrichs constants for the $L^{p}$ de~Rham complex over convex domains and domains with shellable triangulations](https://arxiv.org/abs/2508.06741)
*Théophile Chaumont-Frelet,Martin Werner Licht,Martin Vohralík*

Main category: math.NA

TL;DR: The paper constructs potentials for exterior derivative operators (gradient, curl, divergence) over domains with shellable triangulations, providing computable bounds for operator norms and applications in Poincaré--Friedrichs inequalities and vector Laplacian eigenvalues.


<details>
  <summary>Details</summary>
Motivation: To address the need for explicitly computable bounds for potentials of exterior derivative operators, applicable to domains with shellable triangulations, and to derive practical inequalities and eigenvalue bounds.

Method: The authors construct potentials for the exterior derivative (gradient, curl, divergence) over shellable triangulated domains, compute operator norms with geometry-dependent bounds, and apply these to Poincaré--Friedrichs inequalities and vector Laplacian eigenvalues.

Result: Explicitly computable bounds for operator norms are derived, enabling upper bounds for Poincaré--Friedrichs inequalities and lower bounds for vector Laplacian eigenvalues. Additional results include $L^{p}$ de Rham complex inequalities for convex domains.

Conclusion: The work provides practical tools for analyzing exterior derivative operators, with computable bounds and applications in inequalities and eigenvalue problems, demonstrated through computational examples.

Abstract: We construct potentials for the exterior derivative, in particular, for the
gradient, the curl, and the divergence operators, over domains with shellable
triangulations. Notably, the class of shellable triangulations includes local
patches (stars) in two or three dimensions. The operator norms of our
potentials satisfy explicitly computable bounds that depend only on the
geometry. We thus compute upper bounds for constants in Poincar\'e--Friedrichs
inequalities and lower bounds for the eigenvalues of vector Laplacians. As an
additional result with independent standing, we establish
Poincar\'e--Friedrichs inequalities with computable constants for the $L^{p}$
de~Rham complex over bounded convex domains, derived as explicit operator norms
of regularized Poincar\'e and Bogovski\u{\i} potential operators. We express
all our main results in the calculus of differential forms and treat the
gradient, curl, and divergence operators as instances of the exterior
derivative. Computational examples illustrate the theoretical findings.

</details>


### [4] [Modified Cubic B-spline Based Differential Quadrature Methods for Time-fractional Black-Scholes Equation](https://arxiv.org/abs/2508.06780)
*Nizamudheen V,Riyasudheen TK,Noufal Asharaf,Shefeeq T*

Main category: math.NA

TL;DR: The paper proposes an efficient numerical method using modified cubic B-splines and DQM to solve the time-fractional Black-Scholes equation, achieving high accuracy and convergence rates.


<details>
  <summary>Details</summary>
Motivation: The non-local nature of fractional derivatives in the TFBSE poses challenges for accurate solutions, necessitating a robust numerical approach.

Method: Combines time fractional discretization (L1 finite difference) and space discretization (modified cubic B-spline DQM) on uniform meshes, with theoretical stability analysis.

Result: The method shows fourth-order spatial convergence and $2-\alpha$ temporal convergence, with improved spatial convergence as $\alpha$ approaches 0.

Conclusion: The proposed method outperforms existing techniques in accuracy, validated by numerical comparisons.

Abstract: The time-fractional Black-Scholes equation (TFBSE) is intended to price the
options for which the underlying price fluctuates within a correlated fractal
transmission system. Although the TFBSE is an influential approach for grasping
the long-term memory traits of financial markets, the non-local nature of
fractional derivatives makes significant challenges in finding an accurate
solution. We perform an efficient use of the differential quadrature method
(DQM) based on modified cubic B-splines to solve the TFBSE governing European
options. This paper constructs an algorithm by the combination of time
fractional discretization using the finite difference method $L1$ and space
discretization using the modified cubic B-spline-based differential quadrature
method. Uniform meshes are considered for the discretization of both temporal
and spatial domains. Theoretical stability has been established by finding an
estimate for the maximum norm of the inverse operator regardless of the
involvement of mesh parameters. We trigger the Neumann series theorem to obtain
a uniform bound for the inverse operator under reasonable conditions on the
mesh parameters. The numerical illustrations show that this implicit numerical
method exhibits a fourth-order convergence in the space direction and the order
$2-\alpha$ in time. Moreover, we observe an enhancement in order of spatial
convergence whenever $\alpha$ tends to $0$. The results obtained are then
compared with existing popular techniques to demonstrate the accuracy of
modified cubic B-spline-based DQM.

</details>


### [5] [Onsager Principle-Based Domain Embedding for Thermodynamically Consistent Cahn-Hilliard Model in Arbitrary Domain](https://arxiv.org/abs/2508.06830)
*Wenkai Yu,Qi Wang,Zhen Zhang,Tiezheng Qian*

Main category: math.NA

TL;DR: The paper extends the Cahn-Hilliard model to a larger domain using the OPBDE method, ensuring thermodynamic consistency and recovering the original model through asymptotic analysis. A numerical scheme validates the approach.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of the original Cahn-Hilliard model in arbitrary domains by embedding it into a larger, regular domain while maintaining thermodynamic consistency.

Method: Uses the Onsager principle-based domain embedding (OPBDE) method, introduces a modified conservation law, and employs variational and asymptotic analysis.

Result: The extended OPBDE Cahn-Hilliard model accurately recovers the original model, and numerical results confirm its effectiveness and robustness.

Conclusion: The OPBDE method is a powerful tool for handling gradient flow problems in arbitrary domains, ensuring accuracy and thermodynamic consistency.

Abstract: The original Cahn-Hilliard model in an arbitrary domain with two prescribed
boundary conditions is extended to a Cahn-Hilliard-type model in a larger,
regular domain with homogeneous Neumann boundary conditions. The extension is
based on the Onsager principle-based domain embedding (OPBDE) method, which has
been developed as a systematic domain embedding framework to ensure
thermodynamic consistency. By introducing a modified conservation law, the flux
at the boundary of the original domain is incorporated into the conservation
law as a source term. Our variational approach demonstrates that, even without
a prior knowledge on the specific form of the rate of free energy pumped into
the system, the Onsager principle remains an effective instrument in deriving
the constitutive equation of the extended system. This approach clarifies the
intrinsic structure of the extended model in the perspectives of free energy
and its dissipation. Asymptotic analysis is carried out for the extended OPBDE
Cahn-Hilliard model, demonstrating that the original Cahn-Hilliard model,
including its boundary conditions, can be fully recovered. To validate our
approach, a structure-preserving numerical scheme is developed to discretize
the extended model. Numerical results show that the OPBDE Cahn-Hilliard model
is accurate, effective, and robust, highlighting the capability of the OPBDE
method in handling gradient flow problems in arbitrary domain geometries.

</details>


### [6] [Efficient iterative linearised solvers for numerical approximations of stochastic Stefan problems](https://arxiv.org/abs/2508.06867)
*Muhammad Awais Khan,Jérôme Droniou,Kim-Ngan Le,Iuliu Sorin Pop*

Main category: math.NA

TL;DR: The paper discusses iterative solvers for stochastic Stefan problems, comparing Newton and linearised methods, with insights on solver efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of solving nonlinear equations in stochastic Stefan problems efficiently.

Method: Explores Newton and linearised solvers, focusing on the latter's advantage of reusing coefficient matrices.

Result: Linearised solvers, though slower, offer efficiency by reusing factorised matrices, with adaptive tolerance aiding solver choice.

Conclusion: The study provides insights for selecting effective solvers in stochastic Stefan problems, balancing speed and efficiency.

Abstract: We present iterative solvers to approximate the solution of numerical schemes
for stochastic Stefan problems. After briefly talking about the convergence
results, we tackle the question of efficient strategies for solving the
nonlinear equation associated with this scheme. We explore several approaches,
from a standard Newton technique to linearised solvers. The latter offer the
advantage of using the same coefficient matrix of the linearised system in each
nonlinear iteration, for all time steps, and across all realisations of the
Brownian motions. As a consequence, the system can be factorised once and for
all. Although the linearised approach has a slower convergence rate, our
sensitivity analysis and the use of adaptive tolerance in both deterministic
and stochastic cases provide valuable insights for choosing the most effective
solver across various scenarii.

</details>


### [7] [Nonconforming approximation methods for function reconstruction on general polygonal meshes via orthogonal polynomials](https://arxiv.org/abs/2508.07036)
*Francesco Dell'Accio,Allal Guessab,Gradimir V. Milovanović,Federico Nudo*

Main category: math.NA

TL;DR: New nonconforming approximation methods for function reconstruction on polygonal meshes using weighted moments of orthogonal polynomials, with conditions for unisolvence and an enrichment strategy when needed.


<details>
  <summary>Details</summary>
Motivation: Address scenarios where only integral measurements over subdomains are available, not pointwise evaluations.

Method: Define methods using weighted moments of orthogonal polynomials; develop unisolvence theory and enrichment strategy.

Result: Unisolvence depends on the parity of the product of polynomial degree and polygon edges; numerical experiments confirm accuracy.

Conclusion: Proposed methods effectively reconstruct functions with integral-only data, validated by numerical results.

Abstract: In this work, we introduce new families of nonconforming approximation
methods for reconstructing functions on general polygonal meshes. These methods
are defined using degrees of freedom based on weighted moments of orthogonal
polynomials and can reproduce higher-degree polynomials. This setting naturally
arises in applications where pointwise evaluations are unavailable and only
integral measurements over subdomains are accessible. We develop a unisolvence
theory and derive necessary and sufficient conditions for the associated
approximation spaces to be unisolvent. Specifically, it is shown that
unisolvence depends on the parity of the product of the polynomial degree~$m$
and the number of polygon edges~$N$. When this condition is not satisfied, we
introduce an enrichment strategy involving an additional linear functional and
a suitably designed enrichment function to ensure unisolvence. Numerical
experiments confirm the accuracy of the proposed method.

</details>


### [8] [A novel interpolation-regression approach for function approximation on the disk and its application to cubature formulas](https://arxiv.org/abs/2508.07047)
*Francesco Dell'Accio,Francisco Marcellán,Federico Nudo*

Main category: math.NA

TL;DR: A polynomial approximation method using interpolation-regression for disk domains, avoiding Runge phenomenon, with focus on stable node selection and Zernike polynomials, applied to cubature formulas.


<details>
  <summary>Details</summary>
Motivation: To extend interpolation-regression techniques to disk domains, ensuring stability and accuracy, especially for Zernike polynomials.

Method: Polynomial approximation via interpolation-regression, with careful node selection for stability.

Result: Accurate reconstruction of functions on disks and derivation of precise cubature formulas.

Conclusion: The method effectively avoids Runge phenomenon and provides stable, accurate approximations for disk domains.

Abstract: The interpolation-regression approximation is a powerful tool in numerical
analysis for reconstructing functions defined on square or triangular domains
from their evaluations at a regular set of nodes. The importance of this
technique lies in its ability to avoid the Runge phenomenon. In this paper, we
present a polynomial approximation method based on an interpolation-regression
approach for reconstructing functions defined on disk domains from their
evaluations at a general set of sampling points. Special attention is devoted
to the selection of interpolation nodes to ensure numerical stability,
particularly in the context of Zernike polynomials. As an application, the
proposed method is used to derive accurate cubature formulas for numerical
integration over the disk.

</details>


### [9] [$C^{\infty}$ rational approximation and quasi-histopolation of functions with jumps through multinode Shepard functions](https://arxiv.org/abs/2508.07070)
*Francesco Dell'Accio,Francesco Larosa,Federico Nudo,Najoua Siar*

Main category: math.NA

TL;DR: The paper introduces a $C^{\infty}$ rational quasi-histopolation operator to approximate functions using integral data, avoiding the Runge and Gibbs phenomena by blending local histopolation polynomials with multinode Shepard functions.


<details>
  <summary>Details</summary>
Motivation: Classical histopolation suffers from the Runge and Gibbs phenomena when using equispaced nodes or approximating discontinuous functions. Quasi-histopolation offers flexibility to mitigate these issues.

Method: The authors propose a $C^{\infty}$ rational quasi-histopolation operator that blends local histopolation polynomials using multinode Shepard functions.

Result: Numerical experiments show the method's accuracy in approximating functions while avoiding oscillatory behavior.

Conclusion: The introduced operator effectively defeats the Runge and Gibbs phenomena, providing a robust alternative to classical histopolation.

Abstract: Histopolation, or interpolation on segments, is a mathematical technique used
to approximate a function $f$ over a given interval $I=[a,b]$ by exploiting
integral information over a set of subintervals of $I$. Unlike classical
polynomial interpolation, which is based on pointwise function evaluations,
histopolation reconstructs a function using integral data. However, similar to
classical polynomial interpolation, histopolation suffers from the well-known
Runge phenomenon when integral data are based on a grid with many equispaced
nodes, as well as the Gibbs phenomenon when approximating discontinuous
functions. In contrast, quasi-histopolation is designed to relax the strict
requirement of passing through all the given data points. This inherent
flexibility can reduce the likelihood of oscillatory behavior using, for
example, rational approximation operators. In this work, we introduce a
$C^{\infty}$ rational quasi-histopolation operator, for bounded (integrable)
functions, which reconstruct a function by defeating both the Runge and Gibbs
phenomena. A key element of our approach is to blend local histopolation
polynomials on a few nodes using multinode Shepard functions as blending
functions. Several numerical experiments demonstrate the accuracy of our
method.

</details>


### [10] [A brief introduction to matrix hydrodynamics](https://arxiv.org/abs/2508.07088)
*Klas Modin,Milo Viviani*

Main category: math.NA

TL;DR: Survey on matrix hydrodynamics, a field by V. Zeitlin, using quantization theory for 2-D incompressible fluids.


<details>
  <summary>Details</summary>
Motivation: To introduce and explain matrix hydrodynamics, a novel approach to spatially discretize 2-D incompressible fluids.

Method: Utilizes quantization theory for spatial discretization.

Result: Provides a foundational understanding of matrix hydrodynamics.

Conclusion: Matrix hydrodynamics offers a promising framework for studying 2-D fluid dynamics through quantization.

Abstract: This survey gives a basic demonstration of matrix hydrodynamics; the field
pioneered by V. Zeitlin, where 2-D incompressible fluids are spatially
discretized via quantization theory.

</details>


### [11] [Modelling Human Skin Morphology and Simulating Transdermal Transport of 50 Chemicals](https://arxiv.org/abs/2508.07123)
*Milana Tesfamarian,Arne Nägel,Michael Heisig,Gabriel Wittum*

Main category: math.NA

TL;DR: The paper develops computable skin meshes to simulate chemical permeation, identifying key factors like diffusion coefficients and molecular weights, aiding pharmaceutical formulation.


<details>
  <summary>Details</summary>
Motivation: Understanding chemical transport through skin is crucial due to widespread use of products containing diffusible chemicals.

Method: Created 2D and 3D skin meshes for young and old skin, simulated permeation of 50 chemicals using numerical methods.

Result: Diffusion coefficients, partition coefficients, and molecular weights significantly influenced chemical diffusion and absorption.

Conclusion: The findings offer insights into permeation pathways, supporting pharmaceutical formulation development and optimization.

Abstract: People use various products containing chemical substances that can diffuse
through the human skin barrier and reach deeper layers. Therefore, it is
essential to understand the transport mechanisms of these chemicals. We
developed computable skin meshes for different anatomical regions of young and
old skin in two and three dimensions. Numerical methods were applied to
simulate the permeation of 50 chemicals. Diffusion coefficients, partition
coefficients, and molecular weights were key factors that influenced diffusion
and absorption. These findings provide insights into permeation pathways that
can support the development and optimization of pharmaceutical formulations.

</details>


### [12] [Computational investigation of crack-tip fields in a compressed nonlinear strain-limiting material](https://arxiv.org/abs/2508.07175)
*Dambaru Bhatta,Saugata Ghosh,S. M. Mallikarjunaiah*

Main category: math.NA

TL;DR: A nonlinear finite element framework analyzes crack-tip phenomena in elastic materials under compression, mitigating strain singularities and providing a more accurate representation of crack-tip fields.


<details>
  <summary>Details</summary>
Motivation: To address non-physical strain singularities and improve the analysis of crack-tip behavior in elastic materials under compressive loading.

Method: A nonlinear constitutive model relates stress to strain, formulated as a quasilinear elliptic BVP. Solved using Picard-type linearization and continuous Galerkin finite element method.

Result: High compressive stress and strain energy density at crack tips, but strain growth is lower than stress. Findings align with linear elastic fracture mechanics but offer a more accurate nonlinear representation.

Conclusion: The framework provides a rigorous basis for studying crack propagation and damage in anisotropic, strain-limiting solids under compression.

Abstract: A finite element framework is presented for the analysis of crack-tip
phenomena in an elastic material containing a single edge crack under
compressive loading. The mechanical response of the material is modeled by a
nonlinear constitutive relationship that algebraically relates stress to
linearized strain. This approach serves to mitigate non-physical strain
singularities and ensures that the crack-tip strains don't grow, unlike
singular stresses. A significant advancement is thus achieved in the
formulation of boundary value problems (BVPs) for such complex scenarios. The
governing equilibrium equation, derived from the balance of linear momentum and
the nonlinear constitutive model, is formulated as a second-order,
vector-valued, quasilinear elliptic BVP. A classical traction-free boundary
condition is imposed on the crack face. The problem is solved using a robust
numerical scheme in which a Picard-type linearization is combined with a
continuous Galerkin finite element method for the discretization. Analyses are
performed for both an isotropic and a transversely isotropic elastic solid
containing a crack subjected to compressive loads. The primary crack-tip
variables**-stress, strain, and strain energy density-**are examined in detail.
It is demonstrated that while high concentrations of compressive stress and
strain energy density are observed at the crack tip, the growth of strain is
substantially lower than that of stress. These findings are shown to be
consistent with the predictions of linear elastic fracture mechanics, but a
more physically meaningful representation of the crack-tip field is provided by
the nonlinear approach. A rigorous basis is thus established for investigating
fundamental processes like crack propagation and damage in anisotropic,
strain-limiting solids under various loading conditions, including compression.

</details>


### [13] [Weighted and unweighted enrichment strategies for solving the Poisson problem with Dirichlet boundary conditions](https://arxiv.org/abs/2508.07238)
*Francesco Dell'Accio,Luca Desiderio,Allal Guessab,Federico Nudo*

Main category: math.NA

TL;DR: Proposed weighted and unweighted enrichment strategies to improve linear lagrangian finite element accuracy for Poisson problems with Dirichlet boundary conditions.


<details>
  <summary>Details</summary>
Motivation: Overcome limitations of linear lagrangian finite elements in capturing sharp gradients and boundary-layer phenomena.

Method: Introduced two novel three-parameter families of weighted enrichment functions and derived an explicit error bound in $L^2$-norm.

Result: Numerical experiments confirmed improved approximation accuracy.

Conclusion: The approach is effective and has potential for diverse applications.

Abstract: In this paper, we propose weighted and unweighted enrichment strategies to
enhance the accuracy of the linear lagrangian finite element for solving the
Poisson problem with Dirichlet boundary conditions. We first recall key
examples of admissible enrichment functions, specifically designed to overcome
the limitations of the linear lagrangian finite element in capturing solution
features such as sharp gradients and boundary-layer phenomena. We then
introduce two novel three-parameter families of weighted enrichment functions
and derive an explicit error bound in $L^2$-norm. Numerical experiments confirm
the effectiveness of the proposed approach in improving approximation accuracy,
demonstrating its potential for a wide range of applications.

</details>


### [14] [Robust, fast, and adaptive splitting schemes for nonlinear doubly-degenerate diffusion equations](https://arxiv.org/abs/2508.07420)
*Ayesha Javed,Koondanibha Mitra,Iuliu Sorin Pop*

Main category: math.NA

TL;DR: The paper analyzes iterative linearization strategies (Newton, L-scheme, modified L-scheme) for nonlinear, doubly-degenerate parabolic equations, proving convergence and proposing an adaptive M-scheme for stability and efficiency.


<details>
  <summary>Details</summary>
Motivation: Address the challenges of degeneracies in nonlinear parabolic equations by developing stable and efficient iterative schemes.

Method: Uses Euler implicit time-stepping, splitting strategy, and analyzes Newton, L-scheme, and modified L-scheme. Introduces an adaptive M-scheme with a posteriori estimators.

Result: Proves convergence for L-scheme and modified L-scheme in double-degenerate cases. Adaptive M-scheme outperforms others in stability and convergence.

Conclusion: The adaptive M-scheme is superior, offering stability and quadratic convergence, making it a robust choice for solving doubly-degenerate parabolic equations.

Abstract: We consider linear iterative schemes for the time-discrete equations stemming
from a class of nonlinear, doubly-degenerate parabolic equations. More
precisely, the diffusion is nonlinear and may vanish or become multivalued for
certain values of the unknown, so the parabolic equation becomes hyperbolic or
elliptic, respectively. After performing an Euler implicit time-stepping, a
splitting strategy is applied to the time-discrete equations. This leads to a
formulation that is more suitable for dealing with the degeneracies. Based on
this splitting, different iterative linearization strategies are considered,
namely the Newton scheme, the L-scheme, and the modified L-scheme. We prove the
convergence of the latter two schemes even for the double-degenerate case. In
the non-degenerate case, we prove that the scheme is contractive, and the
contraction rate is proportional to a non-negative exponent of the time-step
size. Moreover, an a posteriori estimator-based adaptive algorithm is developed
to select the optimal parameters for the M-scheme, which accelerates its
convergence. Numerical results are presented, showing that the M- and the
M-adaptive schemes are more stable than the Newton scheme, as they converge
irrespective of the mesh. Moreover, the adaptive M-scheme consistently
out-competes not only the M/L-schemes, but also the Newton scheme showing
quadratic convergence behavior.

</details>


### [15] [Physics-informed Multiresolution Wavelet Neural Network Method for Solving Partial Differential Equations](https://arxiv.org/abs/2508.07546)
*Feng Han,Jianguo Wang,Guoliang Peng,Xueting Shi*

Main category: math.NA

TL;DR: A physics-informed multiresolution wavelet neural network (PIMWNN) method is proposed for solving PDEs, achieving higher accuracy and speed than PINNs while being mesh-free and adaptable to various boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of Physics Informed Neural Networks (PINNs) in solving PDEs, particularly in terms of accuracy, speed, and handling boundary conditions.

Method: Uses multiresolution wavelet neural network (MWNN) to approximate unknown functions, substitutes MWNN into PDEs, and trains it with a least-squares algorithm.

Result: PIMWNN outperforms PINNs in accuracy and speed, handles boundary conditions easily, and efficiently solves time-dependent problems.

Conclusion: PIMWNN shows great potential for numerical PDE solving, addressing spectral bias and offering mesh-free flexibility.

Abstract: In this paper, a physics-informed multiresolution wavelet neural network
(PIMWNN) method is proposed for solving partial differential equations (PDEs).
This method uses the multiresolution wavelet neural network (MWNN) to
approximate unknown functions, then substituting the MWNN into PDEs and
training the MWNN by least-squares algorithm. We apply the proposed method to
various problems, including stationary/nonstationary advection, diffusion and
advection-diffusion problems, and linear/nonlinear time-dependent problems.
Numerical experiments show that the PIMWNN method can achieve higher accuracy
and faster speed than Physics Informed Neural Networks (PINNs). Moreover, the
PIMWNN method, being mesh-free, can handle different boundary conditions easily
and solve the time-dependent problems efficiently. The proposed method is
expected to solve the spectral bias problem in network training. These
characteristics show the great potential of the PIMWNN method used in the field
of numerical solving methods for PDEs.

</details>


### [16] [Efficient adaptive randomized algorithms for fixed-threshold low-rank matrix approximation](https://arxiv.org/abs/2508.07553)
*Qiaohua Liu,Yuejuan Yu*

Main category: math.NA

TL;DR: The paper introduces an adaptive randomized rank-revealing algorithm for low-rank matrix approximation, offering efficient and reliable performance in applications like image processing and background estimation.


<details>
  <summary>Details</summary>
Motivation: Low-rank matrix approximation is crucial in fields like information retrieval and image processing, but existing methods may lack efficiency or reliability for large matrices.

Method: The algorithm adaptively builds the basis matrix Q block by block using a recursive deflation procedure on A, with detailed analysis of randomized projection schemes.

Result: The method provides provable spectral and Frobenius error bounds for the approximate low-rank matrix and singular values, outperforming Lanczos-based and other rank-revealing algorithms.

Conclusion: The blocked randomized algorithm is pass-efficient, accelerates computations for large matrices, and proves more reliable and efficient in practical applications.

Abstract: The low-rank matrix approximation problems within a threshold are widely
applied in information retrieval, image processing, background estimation of
the video sequence problems and so on. This paper presents an adaptive
randomized rank-revealing algorithm of the data matrix $A$, in which the basis
matrix $Q$ of the approximate range space is adaptively built block by block,
through a recursive deflation procedure on $A$. Detailed analysis of randomized
projection schemes are provided to analyze the numerical rank reduce during the
deflation. The provable spectral and Frobenius error $(I-QQ^T)A$ of the
approximate low-rank matrix $\tilde A=QQ^TA$ are presented, as well as the
approximate singular values. This blocked deflation technique is pass-efficient
and can accelerate practical computations of large matrices. Applied to image
processing and background estimation problems, the blocked randomized algorithm
behaves more reliable and more efficient than the known Lanczos-based method
and a rank-revealing algorithm proposed by Lee, Li and Zeng (in SIAM J. Matrix
Anal. Appl. 31 (2009), pp. 503-525).

</details>


### [17] [Barron Space Representations for Elliptic PDEs with Homogeneous Boundary Conditions](https://arxiv.org/abs/2508.07559)
*Ziang Chen,Liqiang Huang*

Main category: math.NA

TL;DR: The paper shows that two-layer neural networks can efficiently approximate high-dimensional PDE solutions in Barron spaces, avoiding the curse of dimensionality.


<details>
  <summary>Details</summary>
Motivation: To explore the expressive power of shallow neural networks in solving high-dimensional PDEs under structural assumptions.

Method: Analyze approximation complexity of second-order elliptic PDEs in Barron spaces using two-layer neural networks.

Result: Efficient approximation of solutions is possible, circumventing the curse of dimensionality.

Conclusion: Shallow networks are powerful for high-dimensional PDE solutions under Barron space assumptions.

Abstract: We study the approximation complexity of high-dimensional second-order
elliptic PDEs with homogeneous boundary conditions on the unit hypercube,
within the framework of Barron spaces. Under the assumption that the
coefficients belong to suitably defined Barron spaces, we prove that the
solution can be efficiently approximated by two-layer neural networks,
circumventing the curse of dimensionality. Our results demonstrate the
expressive power of shallow networks in capturing high-dimensional PDE
solutions under appropriate structural assumptions.

</details>


### [18] [Addendum on data driven regularization by projection](https://arxiv.org/abs/2508.07709)
*Martin Hanke,Otmar Scherzer*

Main category: math.NA

TL;DR: The paper extends a data-driven regularization method to handle noisy and potentially linearly dependent input-output pairs for solving linear inverse problems.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of solving linear inverse problems when the forward operator is indirectly specified via noisy and possibly linearly dependent training data.

Method: Extends the projection-based regularization approach from prior work to accommodate noisy and linearly dependent data pairs.

Result: The method remains stable under the new conditions, demonstrating robustness to noise and linear dependencies in the training data.

Conclusion: The extended approach effectively handles noisy and linearly dependent data, maintaining stability in solving linear inverse problems.

Abstract: We study the stability of regularization by projection for solving linear
inverse problems if the forward operator is given indirectly but specified via
some input-output training pairs. We extend the approach in "Data driven
regularization by projection" (Aspri, Korolev, and Scherzer; Inverse Problems;
36 (2020), 125009) to data pairs, which are noisy and, possibly, linearly
dependent.

</details>


### [19] [A $C^{\infty}$ rational quasi-interpolation operator for functions with jumps without the Gibbs phenomenon](https://arxiv.org/abs/2508.07741)
*Francesco Dell'Accio,Francesco Larosa,Federico Nudo,Najoua Siar*

Main category: math.NA

TL;DR: A $C^{\infty}$ rational quasi-interpolation operator is introduced to approximate functions with jump discontinuities, avoiding issues like the Gibbs phenomenon in traditional methods.


<details>
  <summary>Details</summary>
Motivation: Quasi-interpolation is valuable for handling jump discontinuities in fields like signal processing and computational physics, where classical interpolation often fails.

Method: The paper proposes a $C^{\infty}$ rational quasi-interpolation operator to approximate functions without requiring exact data point matching.

Result: The method effectively approximates functions with jump discontinuities, minimizing problems like the Gibbs phenomenon.

Conclusion: The presented operator offers a flexible and efficient alternative to traditional interpolation for handling discontinuous functions.

Abstract: The study of quasi-interpolation has gained significant importance in
numerical analysis and approximation theory due to its versatile applications
in scientific and engineering fields. This technique provides a flexible and
efficient alternative to traditional interpolation methods by approximating
data points without requiring the approximated function to pass exactly through
them. This approach is particularly valuable for handling jump discontinuities,
where classical interpolation methods often fail due to the Gibbs phenomenon.
These discontinuities are common in practical scenarios such as signal
processing and computational physics. In this paper, we present a $C^{\infty}$
rational quasi-interpolation operator designed to effectively approximate
functions with jump discontinuities while minimizing the issues typically
associated with traditional interpolation methods.

</details>


### [20] [Multinode Shepard Functions and Tensor Product Polynomial Interpolation: Applications to Digital Elevation Models](https://arxiv.org/abs/2508.07764)
*Domingo Barrera,Francesco Dell'Accio,Filomena Di Tommaso,Salah Eddargani,María José Ibáñez,Francesco Larosa,Federico Nudo,Juan F. Reinoso*

Main category: math.NA

TL;DR: The paper explores the multinode Shepard interpolant on a rectangular grid for surface reconstruction from DEM data, analyzes its approximation order, and provides a detailed algorithm with numerical validation.


<details>
  <summary>Details</summary>
Motivation: To improve surface reconstruction from DEM data using the multinode Shepard interpolant and understand its approximation capabilities.

Method: Develops a detailed algorithm for the multinode Shepard interpolant on a regular grid and evaluates its performance numerically.

Result: Numerical tests confirm the algorithm's effectiveness in surface reconstruction.

Conclusion: The multinode Shepard interpolant is effective for DEM-based surface reconstruction, supported by theoretical and numerical results.

Abstract: The paper presents an in-depth exploration of the multinode Shepard
interpolant on a regular rectangular grid, demonstrating its efficacy in
reconstructing surfaces from DEM data. Additionally, we study the approximation
order associated to this interpolant and present a detailed algorithm for
reconstructing surfaces. Numerical tests showcase the effectiveness of the
proposed algorithm.

</details>


### [21] [Reconstructing the dielectric properties of melanoma in 3D using real-life melanoma model](https://arxiv.org/abs/2508.07780)
*Georg Kyhn,Eric Lindström,Larisa Beilina*

Main category: math.NA

TL;DR: The paper evaluates an adaptive domain decomposition method for reconstructing dielectric permittivity and conductivity in 3D melanoma models using backscattered electric field data.


<details>
  <summary>Details</summary>
Motivation: To improve reconstruction accuracy of dielectric properties in realistic 3D melanoma models at 6 GHz.

Method: Uses gradient-based reconstruction algorithms with optimization to find stationary points of the Lagrangian.

Result: Demonstrates qualitative and quantitative reconstruction of dielectric properties.

Conclusion: The method effectively reconstructs dielectric permittivity and conductivity in 3D melanoma models.

Abstract: The paper presents performance of the adaptive domain decomposition finite
element/finite difference method for reconstruction of the dielectric
permittivity and conductivity functions for 3D real-life melanoma model using
measurements of the backscattered electric field at the boundary of the
investigated domain. We present several gradient-based reconstruction
algorithms which use optimization approach to find stationary point of the
Lagrangian. Our computational tests show qualitative and quantitative
reconstruction of dielectric permittivity and conductivity functions using
realistic model of malign melanoma at 6 GHz in 3D.

</details>


### [22] [Finite element 3D models of melanoma growth and time-dependent backscattered data for dielectric properties of melanoma at 6 GHz](https://arxiv.org/abs/2508.07794)
*Eric Lindström,Larisa Beilina*

Main category: math.NA

TL;DR: Developed 3D finite element meshes for simulating malignant melanoma growth, incorporating skin dielectric properties, and used them to evaluate reconstruction algorithms.


<details>
  <summary>Details</summary>
Motivation: To simulate realistic malignant melanoma growth and assess reconstruction algorithms for dielectric property determination.

Method: Created 3D finite element meshes with accurate skin dielectric properties and performed numerical simulations to generate backscattered data.

Result: Demonstrated the utility of 3D meshes in evaluating reconstruction algorithms for dielectric property analysis.

Conclusion: The approach enables realistic simulation and assessment of malignant melanoma growth and dielectric property reconstruction.

Abstract: Finite element meshes for 3D models simulating realistic malignant melanoma
(MM) growth, incorporating accurate dielectric properties of the skin, have
been developed. Numerical simulations illustrate how 3D finite element meshes
can be utilized to generate backscattered data, enabling the evaluation of
reconstruction algorithms designed to determine the dielectric properties of
the proposed 3D model.

</details>


### [23] [Prediction error certification for PINNs: Theory, computation, and application to Stokes flow](https://arxiv.org/abs/2508.07994)
*Birgit Hillebrecht,Benjamin Unger*

Main category: math.NA

TL;DR: The paper extends a semigroup-based framework for error estimation in PINNs, making it applicable to a broader class of problems by modifying error bounds and approximating stability parameters.


<details>
  <summary>Details</summary>
Motivation: To address the limitation of existing PINN error estimators, which are restricted to academic examples, by enabling certification of predictions in more realistic scenarios.

Method: The authors modify the error bound and propose numerical strategies to approximate stability parameters, extending the semigroup-based framework.

Result: The extended framework successfully certifies PINN predictions, demonstrated by a numerical study of Stokes flow around a cylinder.

Conclusion: The work broadens the applicability of PINN error estimation, enhancing its utility for practical problems.

Abstract: Rigorous error estimation is a fundamental topic in numerical analysis. With
the increasing use of physics-informed neural networks (PINNs) for solving
partial differential equations, several approaches have been developed to
quantify the associated prediction error. In this work, we build upon a
semigroup-based framework previously introduced by the authors for estimating
the PINN error. While this estimator has so far been limited to academic
examples - due to the need to compute quantities related to input-to-state
stability - we extend its applicability to a significantly broader class of
problems. This is accomplished by modifying the error bound and proposing
numerical strategies to approximate the required stability parameters. The
extended framework enables the certification of PINN predictions in more
realistic scenarios, as demonstrated by a numerical study of Stokes flow around
a cylinder.

</details>


### [24] [Multinode Shepard collocation method for pricing of financial derivatives](https://arxiv.org/abs/2508.08023)
*Francesco Dell'Accio,Filomena Di Tommaso,Elisa Francomano,Clara Lorenzi*

Main category: math.NA

TL;DR: The paper proposes a multinode Shepard method combined with Backward Difference Formula for solving the 2D Black-Scholes equation, showing its accuracy and effectiveness through numerical experiments.


<details>
  <summary>Details</summary>
Motivation: To address the numerical solution of the two-dimensional Black-Scholes equation efficiently.

Method: Integrates spatial approximation using the multinode Shepard operator with temporal discretization via the Backward Difference Formula.

Result: Numerical experiments confirm the method's accuracy and effectiveness.

Conclusion: The proposed approach is a viable solution for the 2D Black-Scholes equation.

Abstract: This paper explores the use of the multinode Shepard method for the numerical
solution of the two-dimensional Black-Scholes equation. The proposed approach
integrates a spatial approximation via the multinode Shepard operator with a
temporal discretization based on the Backward Difference Formula. Numerical
experiments are presented to demonstrate the accuracy and effectiveness of the
method.

</details>


### [25] [The univariate multinode Shepard method for the Caputo fractional derivatives: from Approximation to the solution of Bagley-Torvik equation](https://arxiv.org/abs/2508.08067)
*Francesco Dell'Accio,Filomena Di Tommaso,Ilde Ferrara*

Main category: math.NA

TL;DR: The paper proposes a method to approximate fractional derivatives using the univariate multinode Shepard method with Gauss-Jacobi quadrature, applied to solve BVPs and IVPs like the Bagley-Torvik equations.


<details>
  <summary>Details</summary>
Motivation: To address the need for accurate numerical solutions for fractional derivatives in BVPs and IVPs, particularly for the Bagley-Torvik equations.

Method: Uses the univariate multinode Shepard method combined with the Gauss-Jacobi quadrature formula to approximate fractional derivatives.

Result: The method effectively approximates solutions for the Bagley-Torvik equations in both BVPs and IVPs.

Conclusion: The proposed method is validated as effective for solving fractional derivative problems, especially the Bagley-Torvik equations.

Abstract: In this paper, we approximate the fractional derivative of a given function
using the univariate multinode Shepard method through the Gauss-Jacobi
quadrature formula. Subsequently, the proposed method is applied to the
numerical solution of boundary value problems (BVPs) and initial value problems
(IVPs), specifically addressing the Bagley-Torvik equations. Experimental
results confirm the method's effectiveness, particularly in accurately
approximating the Bagley-Torvik equation for both BVPs and IVPs.

</details>


### [26] [A Note on Eigenvalues of Perturbed Hermitian Matrices](https://arxiv.org/abs/2508.08203)
*Chi-Kwong Li,Ren-Cang Li*

Main category: math.NA

TL;DR: The paper improves perturbation bounds for eigenvalues of Hermitian matrices under block perturbations, providing tighter estimates than existing results.


<details>
  <summary>Details</summary>
Motivation: Existing perturbation bounds either overestimate changes when the perturbation is small relative to spectral gaps or become unstable when gaps are tiny. The paper aims to derive a more accurate bound.

Method: The authors analyze Hermitian matrices with block perturbations, using spectral norms and gaps to derive new bounds for eigenvalue differences.

Result: A new bound is derived: $|\lambda_i - \wtd \lambda_i| \le \frac{2\|E\|^2}{\eta+\sqrt{\eta^2+4\|E\|^2}}$, improving existing results. Similar bounds are also obtained for singular values.

Conclusion: The proposed bounds are tighter and more stable, addressing limitations of previous methods and providing better estimates for eigenvalue and singular value perturbations.

Abstract: Let $$ A=\left(\begin{array}{cc} H_1 & E^*\\ E & H_2\end{array}\right) \quad
\hbox{ and } \quad \wtd A=\left(\begin{array}{cc} H_1 & O\\ O &
H_2\end{array}\right)$$ be two $N$-by-$N$ Hermitian matrices with eigenvalues
$\lambda_1 \ge \cdots \ge \lambda_{N}$ and $\wtd \lambda_1 \ge \cdots \ge \wtd
\lambda_N$, respectively. \iffalse There are two kinds of perturbation bounds
on $|\lambda_i - \wtd \lambda_i|$:
  $|\lambda_i- \wtd \lambda_i| \le \|E\|$, where $\|E\|$
  is the largest singular value of $\|E\|$, regardless of
  $H_i$'s spectral distributions, and
  $|\lambda_i - \wtd \lambda_i| \le \|E\|^2/\eta$, where $\eta$ is
  the minimum gap between $H_i$'s spectra. \end{enumerate} Bounds of the first
kind overestimate the changes when $\|E\|\ll\eta$ while those of the second
kind may blow up when $\eta$ is too tiny. \fi Denote by $\|E\|$ the spectral
norm of the matrix $E$, and $\eta$ the spectral gap between the spectra of
$H_1$ and $H_2$. It is shown that $$ |\lambda_i - \wtd \lambda_i| \le {2\|E\|^2
\over \eta+\sqrt{\eta^2+4\|E\|^2}} \, , $$ which improves all the existing
results. Similar bounds are obtained for singular values of matrices under
block perturbations.

</details>


### [27] [A probabilistic approach to spectral analysis of Cauchy-type inverse problems: Convergence and stability analysis](https://arxiv.org/abs/2508.08215)
*Iulian Cîmpean,Andreea Grecu,Liviu Marin*

Main category: math.NA

TL;DR: The paper analyzes the convergence and stability of probabilistic numerical methods for solving ill-posed Cauchy-type inverse problems involving elliptic PDEs.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of solving severely ill-posed inverse problems with incomplete boundary/internal conditions, the authors develop a probabilistic framework for thorough analysis.

Method: The study uses stochastic representations, Monte Carlo simulations, spectral theory, regularity theory, and concentration inequalities to analyze and bound errors.

Result: The paper proves convergence of approximations and provides explicit error bounds for the probabilistic methods.

Conclusion: The probabilistic framework offers a robust approach for analyzing and solving ill-posed inverse problems, with proven convergence and error bounds.

Abstract: A comprehensive convergence and stability analysis of some probabilistic
numerical methods designed to solve Cauchy-type inverse problems is performed
in this study. Such inverse problems aim at solving an elliptic partial
differential equation (PDE) or a system of elliptic PDEs in a bounded Euclidean
domain, subject to incomplete boundary and/or internal conditions, and are
usually severely ill-posed. In a very recent paper \cite{CiGrMaI}, a
probabilistic numerical framework has been developed by the authors, wherein
such inverse problems could be analysed thoroughly by simulating the spectrum
of some corresponding direct problem and its singular value decomposition based
on stochastic representations and Monte Carlo simulations. Herein a full
probabilistic error analysis of the aforementioned methods is provided, whereas
the convergence of the corresponding approximations is proved and explicit
error bounds are provided. This is achieved by employing tools from several
areas such as spectral theory, regularity theory for elliptic measures,
stochastic representations, and concentration inequalities.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [28] [Regularity for Mixed Local and Nonlocal Degenerate Elliptic Equations in the Heisenberg Group](https://arxiv.org/abs/2508.06919)
*Junli Zhang,Pengcheng Niu*

Main category: math.AP

TL;DR: The paper establishes regularity results for mixed local and nonlocal degenerate elliptic equations in the Heisenberg group, including boundedness, Hölder continuity, and Harnack inequalities.


<details>
  <summary>Details</summary>
Motivation: To extend the De Giorgi-Nash-Moser theory to mixed local and nonlocal degenerate elliptic equations in the Heisenberg group.

Method: Derives Caccioppoli type inequalities, logarithmic estimates, and uses Tail term and expansion of positivity techniques.

Result: Proves local boundedness, Hölder continuity, Harnack inequalities, and weak Harnack inequalities for solutions.

Conclusion: The results generalize classical regularity theory to mixed local and nonlocal settings in the Heisenberg group.

Abstract: In this paper, we investigate the regularity for mixed local and nonlocal
degenerate elliptic equations in the Heisenberg group. Inspired by the De
Giorgi-Nash-Moser theory, the local boundedness of weak subsolutions and the
H\"{o}lder continuity of weak solutions to mixed local and nonlocal degenerate
elliptic equations are established by deriving the Caccioppoli type inequality
for weak subsolutions and the logarithmic estimates for weak supersolutions.
Furthermore, the Harnack inequality for weak solutions and the weak Harnack
inequality for weak supersolutions are proved by using the estimates involving
a Tail term and expansion of positivity.

</details>


### [29] [Global well-posedness and asymptotic behavior of large strong solutions to the 3D full compressible Navier-Stokes equations with temperature-dependent coefficients](https://arxiv.org/abs/2508.06933)
*Yachun Li,Peng Lu,Zhaoyang Shang*

Main category: math.AP

TL;DR: The paper establishes global existence of large strong solutions for 3D Navier-Stokes equations with temperature-dependent coefficients and proves optimal decay rates for solutions.


<details>
  <summary>Details</summary>
Motivation: The global well-posedness of Navier-Stokes equations with temperature-dependent coefficients is a challenging problem, especially in multi-dimensional space.

Method: The study focuses on the 3D Navier-Stokes equations with temperature-dependent coefficients in the whole space, assuming initial density and temperature are linearly equivalent to large constant states.

Result: First result on global existence of large strong solutions and optimal decay rates for solutions when initial data belong to $L^p(\mathbb{R}^3)$ for $p\in[1,2]$.

Conclusion: The work provides a significant advancement in understanding the behavior of solutions to the Navier-Stokes equations with temperature-dependent coefficients.

Abstract: It is well known that the global well-posedness of the Navier-Stokes
equations with temperature-dependent coefficients is a challenging problem,
especially in multi-dimensional space. In this paper, we study the 3D
Navier-Stokes equations with temperature-dependent coefficients in the whole
space, and establish the first result on the global existence of large strong
solution when the initial density and the initial temperature are linearly
equivalent to some large constant states. Moreover, the optimal decay rates of
the solution to its associated equilibrium are established when the initial
data belong to $L^p(\mathbb{R}^3)$ for some $p\in[1,2]$.

</details>


### [30] [Fractional Borg-Levinson Problem with small non-negative potential of small growth](https://arxiv.org/abs/2508.06998)
*Saumyajit Das,Tuhin Ghosh*

Main category: math.AP

TL;DR: The paper proves the unique determination of potentials in the fractional Borg-Levinson problem using boundary spectral data, with restrictions on the fractional exponent and potential conditions.


<details>
  <summary>Details</summary>
Motivation: To address the inverse spectral problem of recovering potentials from boundary spectral data in the fractional Borg-Levinson context.

Method: Analyzes boundary spectral data under specific conditions: fractional exponent in (0.5, 1), small non-negative potentials with mild growth.

Result: Potentials can be uniquely determined from the data, with explicit smallness conditions depending on domain and dimension.

Conclusion: The study confirms unique recovery of potentials under the given constraints, advancing understanding of the fractional Borg-Levinson problem.

Abstract: In this article, we investigate the fractional Borg-Levinson problem, an
inverse spectral problem focused on recovering potentials from boundary
spectral data. We demonstrate that the potential can, in fact, be uniquely
determined by this data. However, for technical reasons, we restrict the
fractional exponent to the interval (0.5, 1). Additionally, we assume that at
least one of the potentials is small, non-negative, and exhibits mild growth.
The smallness condition is made explicit in our calculations and depends only
on the domain and the spatial dimension.

</details>


### [31] [On the 2D initial boundary value problem for the Navier-Stokes equations: square in time integrability of the maximum norm of the solutions with finite energy](https://arxiv.org/abs/2508.07025)
*Alfonsina Tartaglione*

Main category: math.AP

TL;DR: The paper proves an $L^1-L^\infty$ duality-based estimate for Navier-Stokes solutions in planar domains, extending prior work to unbounded domains.


<details>
  <summary>Details</summary>
Motivation: To generalize existing results for bounded domains to suitable planar domains, ensuring broader applicability.

Method: Uses an $L^1-L^\infty$ duality argument to derive the estimate for the Navier-Stokes IBVP.

Result: The solution $u$ satisfies $\left(\int_0^{+\infty}\|u(\tau)\|_\infty^2{\hbox{d}}\tau\right)^{1/2}\le c(1+\|u_0\|_2)\|u_0\|_2$.

Conclusion: The estimate holds in planar domains, extending the bounded domain result by Farwig and Giga.

Abstract: By means of an $L^1-L^\infty$ duality argument, it is proved that, in a
suitable planar domain $\Omega$, the solution $u$ to the IBVP associated to the
Navier-Stokes equations, with initial datum $u_0\in L^2(\Omega)$, satisfies the
following estimate $$ \left(\int_0^{+\infty}\|u(\tau)\|_\infty^2{\hbox
{d}}\tau\right)^{1/2}\le c(1+\|u_0\|_2)\|u_0\|_2, $$ proved by R. Farwig and Y.
Giga [Algebra i Analiz, 36, 289-307 (2024)] for bounded domains.

</details>


### [32] [On the geometric Brownian motion with state-dependent variable exponent diffusion term](https://arxiv.org/abs/2508.07130)
*Mustafa Avci*

Main category: math.AP

TL;DR: A stochastic model with state-dependent variable exponent $p(\cdot)$ is introduced, generalizing GBM and CEV models. Existence-uniqueness is proven, and pathwise error bounds between this model and GBM are derived and tested.


<details>
  <summary>Details</summary>
Motivation: To create a flexible framework for modeling systems where noise intensity adapts to the current state, extending beyond GBM and CEV models.

Method: Proposes a stochastic model with $p(\cdot)$, proves existence-uniqueness, and derives error bounds between this model and GBM, validated analytically and numerically.

Result: The model generalizes GBM and CEV, with proven existence-uniqueness and accurate error bounds.

Conclusion: The proposed model offers a versatile and theoretically sound approach for adaptive noise intensity systems.

Abstract: We propose a new stochastic model involving state-dependent variable exponent
$p(\cdot)$ which allows modeling of systems where noise intensity adapts to the
current state. This new flexible theoretical framework generalizes both the
geometric Brownian motion (GBM) and the Constant-Elasticity-of-Variance (CEV)
models. We prove an existence-uniqueness theorem. We obtain an upper-bound
approximation for the model-to-model pathwise error between our model and the
GBM model as well as test its accuracy through analytical and numerical error
estimates.

</details>


### [33] [Scattering for the Klein-Gordon-Zakharov system in two dimensions](https://arxiv.org/abs/2508.07154)
*Shijie Dong,Zihua Guo,Kuijie Li*

Main category: math.AP

TL;DR: The paper analyzes the Klein-Gordon-Zakharov system in 2D, proving global existence and sharp long-time behavior of solutions for small, smooth initial data, revealing a dichotomy in scattering behavior.


<details>
  <summary>Details</summary>
Motivation: The study aims to understand the long-time dynamics of the Klein-Gordon-Zakharov system in plasma physics, particularly in 2D where challenges like weak decay and lack of symmetry arise.

Method: A novel nonlinear transformation of the wave component is introduced, and the nonlinear coupling is reinterpreted as a perturbation of the Klein-Gordon mass term. The proof combines physical and frequency space methods.

Result: Global existence of solutions is established, with sharp decay and scattering properties. The Klein-Gordon component shows modified or linear scattering depending on initial data.

Conclusion: The work highlights delicate long-range interaction effects in 2D and provides a framework for analyzing similar systems with weak decay and symmetry issues.

Abstract: We study the Klein-Gordon-Zakharov system in two spatial dimensions, an
important model in plasma physics. For small, smooth, and spatially localized
initial data, we establish the global existence of solutions and characterize
their sharp long-time behavior, including sharp time decay and scattering
properties. A particularly interesting phenomenon is that the Klein-Gordon
component exhibits modified scattering for certain initial data, while for
others it undergoes linear scattering-a dichotomy highlighting delicate
long-range interaction effects.
  The major obstacles are lack of symmetry and weak decay of the solution in
two dimensions. To overcome these, we introduce a novel nonlinear
transformation of the wave component and reinterpret the nonlinear coupling as
a perturbation of the mass term in the Klein-Gordon equation. The proof employs
a combination of physical space and frequency space methods.

</details>


### [34] [Hypocoercivity for the Linear Semiconductor Boltzmann Equation with Boundaries and Uncertainties](https://arxiv.org/abs/2508.07181)
*Hongxu Chen,Liu Liu,Jiayu Wan*

Main category: math.AP

TL;DR: The paper establishes hypocoercivity for the semiconductor Boltzmann equation under an external electrical potential and Maxwell boundary conditions, using a modified entropy Lyapunov functional to show exponential decay to equilibrium. It also extends the method to handle model uncertainties.


<details>
  <summary>Details</summary>
Motivation: To analyze the behavior of the semiconductor Boltzmann equation under external influences and boundary conditions, and to extend the analysis to uncertain scenarios.

Method: Constructing a modified entropy Lyapunov functional, proving its equivalence to a weighted norm, and demonstrating its dissipation along solutions using a Gronwall-type inequality.

Result: Exponential decay to equilibrium is proven, and the method is generalized to handle uncertainties, analyzing solution regularity in random spaces.

Conclusion: The hypocoercivity method effectively analyzes the system's behavior and extends to uncertain models, providing insights into solution regularity.

Abstract: In this paper, we establish hypocoercivity for the semiconductor Boltzmann
equation with the presence of an external electrical potential under the
Maxwell boundary condition. We will construct a modified entropy Lyapunov
functional, which is proved to be equivalent to some weighted norm of the
corresponding function space. We then show that the entropy functional
dissipates along the solutions, and the exponential decay to the equilibrium
state of the system follows by a Gronwall type inequality. We also generalize
our arguments to situations where uncertainties in our model arise,and the
hypocoercivity method we have established is adopted to analyze the regularity
of the solutions along the random space.

</details>


### [35] [Stable Determination of Coefficients in Nonlinear Dynamical Schrödinger Equations by Carleman Estimates](https://arxiv.org/abs/2508.07231)
*Pranav Arrepu,Hanming Zhou*

Main category: math.AP

TL;DR: The paper addresses recovering stationary coefficients in nonlinear dynamical Schrödinger equations using boundary data and high-order linearization techniques.


<details>
  <summary>Details</summary>
Motivation: To solve the inverse problem of determining coefficients in nonlinear Schrödinger equations, leveraging boundary measurements for stability and uniqueness.

Method: Uses high-order linearization and Carleman estimates for the linear Schrödinger equation, with assumptions on boundary data and coefficient regularity.

Result: Establishes stable and unique determination of coefficients under specific boundary and regularity conditions.

Conclusion: The approach successfully recovers coefficients with boundary data, extending to arbitrary subsets under stronger assumptions.

Abstract: We consider the inverse problem of recovering stationary coefficients in a
class of dynamical Schr\"odinger equations with locally analytic nonlinear
terms. Upon treating the well-posedness for small initial data and trivial
boundary data, we proceed to establish stable and unique determination provided
knowledge of the coefficients near the boundary and the measured Neumann data
of the solution. We discuss both the case of measurement on a subset of the
boundary large enough to satisfy a certain geometrical condition and, under
stronger assumptions on the regularity and size of the coefficients, the case
of measurement on arbitrary subsets of the boundary. Our argument relies on
high-order linearization and Carleman estimates for the linear Schr\"odinger
equation.

</details>


### [36] [Nonlinear stability of 2-D Couette flow for the compressible Navier-Stokes equations at high Reynolds number](https://arxiv.org/abs/2508.07291)
*Minling Li,Chao Wang,Zhifei Zhang*

Main category: math.AP

TL;DR: The paper proves nonlinear stability of Couette flow in 2D compressible Navier-Stokes equations at high Reynolds numbers, with a sharp stability threshold for Sobolev perturbations.


<details>
  <summary>Details</summary>
Motivation: To understand the stability of Couette flow in compressible fluids at high Reynolds numbers, a key problem in fluid dynamics.

Method: Uses Fourier-multiplier method with three key steps: introducing 'good unknowns,' designing a Fourier multiplier, and distinct energy functionals for different modes.

Result: Global existence and proximity to Couette flow are shown for initial data within a specific small perturbation bound.

Conclusion: The stability threshold is sharp, and the method effectively handles the interplay of dissipation, damping, and lift-up effects.

Abstract: In this paper, we investigate the nonlinear stability of the Couette flow for
the two-dimensional compressible Navier--Stokes equations at high Reynolds
numbers ($Re$) regime. It was proved that if the initial data
$(\rho_{in},u_{in})$ satisfies $\|(\rho_{in},u_{in})-(1, y,
0)\|_{H^4(\mathbb{T}\times\mathbb{R})}\leq \epsilon Re^{-1}$ for some small
$\epsilon$ independent of $Re$, then the corresponding solution exists globally
and remains close to the Couette flow for all time. Formal asymptotics indicate
that this stability threshold is sharp within the class of Sobolev
perturbations. The proof relies on the Fourier-multiplier method and exploits
three essential ingredients: (i) the introduction of ``good unknowns" that
decouple the perturbation system; (ii) the construction of a carefully designed
Fourier multiplier that simultaneously captures the enhanced dissipation and
inviscid-damping effects while taming the lift-up mechanism; and (iii) the
design of distinct energy functionals for the incompressible and compressible
modes.

</details>


### [37] [Boundary estimates for singular elliptic problems involving a gradient term](https://arxiv.org/abs/2508.07360)
*Phuong Le*

Main category: math.AP

TL;DR: The paper analyzes weak solutions to a singular quasilinear elliptic problem, providing estimates for directional derivatives near boundaries and proving symmetry of solutions in symmetric domains.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of weak solutions to singular quasilinear elliptic problems, particularly near boundaries and in symmetric domains.

Method: Study the problem using analysis of directional derivatives and symmetry properties in bounded domains.

Result: Precise estimates for directional derivatives near boundaries and proof of symmetry for positive solutions in symmetric convex domains.

Conclusion: The results are novel, even for simpler cases like p=2 and θ=0, advancing understanding of such elliptic problems.

Abstract: We study the behavior of weak solutions to the singular quasilinear elliptic
problem $-\Delta_p u + \vartheta |\nabla u|^q = \frac{1}{u^\gamma} + f(u)$, in
a bounded domain with the Dirichlet boundary condition, where $p>1$,
$\gamma>0$, $0<q\le p$, $\vartheta\ge0$ and $f:[0,+\infty)\to\mathbb{R}$ is a
locally Lipschitz continuous function. We obtain a precise estimate for
directional derivatives of positive solutions in a neighborhood of the
boundary. We also deduce the symmetry of positive solutions to the problem in a
bounded symmetric convex domain. Our results are new even in the case $p=2$ and
$\vartheta=0$.

</details>


### [38] [Unconditional alignment of solutions to the Fokker-Planck-Navier-Stokes system with locally averaged Brinkman force](https://arxiv.org/abs/2508.07415)
*Roman Shvydkoy,Trevor Teolis*

Main category: math.AP

TL;DR: The paper studies a coupled FPNS system for particle-fluid dynamics, proving unconditional alignment and synchronization of velocities for weak solutions. It uses an entropy method and hypocoercivity to avoid density concentration and applies to nonlocal alignment protocols like Cucker-Smale.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of particles in a fluid and achieve unconditional alignment of particle and fluid velocities, overcoming density concentration issues.

Method: Uses a new entropy method and hypocoercivity framework for quantitative decay estimates and hypoelliptic regularization.

Result: Proves unconditional alignment and synchronization for weak solutions in any dimension, with global weak solutions in any dimension and strong solutions in 2D.

Conclusion: The approach successfully addresses alignment and synchronization in particle-fluid systems, applicable to various nonlocal protocols.

Abstract: We study a coupled Fokker-Planck--Navier-Stokes (FPNS) system modeling the
dynamics of interacting particles suspended in a viscous incompressible fluid,
where the coupling occurs through a locally averaged Brinkman drag force. Our
main result is the unconditional alignment and synchronization of particle and
fluid velocities for all weak solutions, in any dimension, on the periodic
domain. The proof leverages a new entropy method and a hypocoercivity
framework, which together yield quantitative decay estimates and prevent
density concentration, a key obstacle in previous analyses. Our approach
applies to a broad class of nonlocal alignment protocols, including the
Cucker-Smale model. We also prove develop well-posedness theory for global weak
solutions with hypoelliptic regularization in any dimension, and global strong
solutions in two dimensions.

</details>


### [39] [Electroconvection in a Magnetic Field](https://arxiv.org/abs/2508.07439)
*Elie Abdo,Peter Constantin,Mihaela Ignatova,Quyuan Lin*

Main category: math.AP

TL;DR: The paper studies electroconvection in a porous medium under a strong magnetic field, showing global smooth solutions for small data and linking them to surface quasigeostrophic equations in the infinite field limit.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of electroconvection in porous media under strong magnetic fields and its mathematical modeling.

Method: Uses an active scalar equation for charge density, analyzing global weak solutions and smoothness under strong fields.

Result: For strong enough fields, small $L^{\infty}$ solutions are globally smooth and converge to surface quasigeostrophic equations.

Conclusion: Strong magnetic fields ensure smooth solutions and connect the system to quasigeostrophic dynamics in the limit.

Abstract: Electroconvection in a porous medium under a strong transversal magnetic
field is described by an active scalar equation for the charge density. The
equation has global weak solutions with $L^{\infty}$ data. We show that for
strong enough magnetic fields, $L^{\infty}$-small solutions are smooth globally
in time and they obey surface quasigeostrophic equations in the limit of
infinite magnetic field strength.

</details>


### [40] [Data Assimilation in Large Eddy Simulation: Addressing Model-Observation Mismatch from Navier-Stokes Data](https://arxiv.org/abs/2508.07492)
*Adam Larios,Ali Pakzad,Nicholas White*

Main category: math.AP

TL;DR: The paper analyzes a continuous data assimilation (CDA) algorithm for a Smagorinsky/Ladyzhenskaya-type LES model, proving global well-posedness and exponential convergence to the true solution in 2D, with numerical validation in 2D and 3D.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between observational data from full Navier-Stokes equations (NSE) and LES modeling, ensuring accurate and efficient assimilation.

Method: The study uses a CDA algorithm applied to a Smagorinsky/Ladyzhenskaya-type LES model, with theoretical analysis in 2D and numerical simulations in 2D and 3D.

Result: Global well-posedness and exponential convergence to the true solution (up to an error of order $ar{
u}^{1/2}$) are proven in 2D, with numerical results supporting synchronization.

Conclusion: The CDA algorithm effectively synchronizes LES models with NSE data, validated by theory and simulations, offering practical utility in turbulence modeling.

Abstract: In atmospheric and turbulent flow modeling, Large Eddy Simulation (LES) is
often used to reduce computational cost, while observational data typically
originates from the underlying physical system. Motivated by this setting, we
study a continuous data assimilation (CDA) algorithm applied to a
Smagorinsky/Ladyzhenskaya-type LES model, in which the observational data is
generated from the full Navier--Stokes equations (NSE). In the two-dimensional
setting, we establish global well-posedness of the assimilated system and prove
exponential convergence to the true solution, up to an error of order
$\bar{\nu}^{1/2}$, where $\bar{\nu}$ is the turbulence viscosity parameter. In
addition to rigorous analysis in 2D, we provide numerical simulations in both
2D domains with physical boundary conditions and 3D periodic domains,
demonstrating effective synchronization in these cases, and corroborating our
theoretical predictions.

</details>


### [41] [Global weak solutions to a doubly degenerate nutrient taxis system on the whole real line](https://arxiv.org/abs/2508.07503)
*Federico Herrero-Hervás*

Main category: math.AP

TL;DR: Analysis of a 1D Cauchy problem for a doubly degenerate nutrient taxis model.


<details>
  <summary>Details</summary>
Motivation: To study the behavior and solutions of a nutrient taxis model with doubly degenerate terms.

Method: Formulates and solves the one-dimensional Cauchy problem using partial differential equations.

Result: Provides insights into the dynamics of the nutrient taxis model under degenerate conditions.

Conclusion: The model's behavior is analyzed, contributing to understanding degenerate PDEs in biological contexts.

Abstract: This work addresses the one-dimensional Cauchy problem for the doubly
degenerate nutrient taxis model \begin{equation*}
  \begin{cases}
  \displaystyle \frac{\partial u}{\partial t} = \frac{\partial}{\partial x}(u v
u_x) - \frac{\partial}{\partial x}(u^2 v v_x) + u v, & x\in \mathbb{R}, ~t>0,

</details>


### [42] [Motion of Elastic Thin Films by Evaporation-Condensation in the Dewetting Regime](https://arxiv.org/abs/2508.07562)
*M. S. Indulekha*

Main category: math.AP

TL;DR: The paper proves short-time existence of solutions for solid-state dewetting evolution equations, modeling thin film dewetting via evaporation-condensation as a 2D sharp interface variational problem.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of thin film dewetting under evaporation-condensation, particularly with moving contact lines and epitaxial strain.

Method: The evolution law is derived as the $L^2$ gradient flow of surface energies, incorporating epitaxial strain and moving contact lines.

Result: Short-time existence of solutions is demonstrated for the proposed model.

Conclusion: The work provides a theoretical foundation for studying thin film dewetting dynamics with moving contact lines and strain effects.

Abstract: In this work, we show the short-time existence of solutions of the evolution
equations that represent the solid state dewetting of thin films through
evaporation-condensation as a two dimensional sharp interface variational
model. The evolution law is established as the $L^2$ gradient flow of surface
energies in the presence of epitaxial strain. The main novelty is the presence
of moving contact lines when the film formation is governed by the
evaporation-condensation method.

</details>


### [43] [Stability and bifurcation of Navier-Stokes equations in an annular domain with mixed boundary conditions](https://arxiv.org/abs/2508.07694)
*Zhibo Hou,Liang Li,Quan Wang*

Main category: math.AP

TL;DR: Study of non-trivial steady-state solutions in 2D Navier-Stokes equations in an annular domain, analyzing stability, critical viscosity, and bifurcation phenomena.


<details>
  <summary>Details</summary>
Motivation: To understand the existence and stability of steady-state solutions in annular domains with mixed boundary conditions, revealing dynamical behaviors and bifurcations.

Method: Global-in-time strong solutions, energy estimates, critical viscosity computation, stability analysis, and bifurcation theory.

Result: Identified critical viscosity μ_c, stability regimes, and pitchfork bifurcation generating non-trivial steady states with counter-rotating vortices.

Conclusion: The trivial solution's stability depends on μ vs. μ_c, with bifurcation leading to non-trivial states, often supercritical but subcritical in some parameter subsets.

Abstract: We study the existence and stability of non-trivial steady-state solutions to
the two-dimensional incompressible Navier-Stokes equations in an annular domain
$\Omega = B(0,b) \setminus \overline{B(0,a)}$ with radii $b>a>0$.The outer
boundary $\partial B(0, b)$ is subject to the free condition, while the inner
boundary $\partial B(0, a)$ obeys a Navier-slip condition with effective slip
length $\alpha > 0$. Our main results are fourfold. First, we establish
global-in-time strong solutions and derive a sharp energy estimate that
underpins the subsequent nonlinear instability analysis. Second, for $\alpha >
0$, we compute an explicit critical viscosity $\mu_c:=\mu_c(\alpha, a,b,\mu)$
that separates qualitatively different dynamical behaviours. Third, we
precisely characterize the stability properties of the trivial solution in
three distinct regimes. The zero solution is globally asymptotically stable in
$H^2$ if $\mu > \mu_c$. If $\mu = \mu_c$, we prove an alternative theorem that
completely describes the local dynamics near the trivial state. If $\mu <
\mu_c$, the trivial solution is nonlinearly unstable in every $L^p (p \geq
1)$.Finally, we demonstrate that for $\mu < \mu_c$, the system undergoes a
pitchfork bifurcation that generates an infinite family of non-trivial steady
states. For generic choices of $(\alpha,b)$, this bifurcation is supercritical;
a measurable subset of parameter space yields subcritical transitions. Notably,
all bifurcating solutions share the same topological pattern-a single row of
counter-rotating vortices-despite their mathematical non-uniqueness.

</details>


### [44] [Quasilinear elliptic equations with singular quadratic growth terms](https://arxiv.org/abs/2508.07695)
*Lucio Boccardo,Tommaso Leonori,Luigi Orsina,Francesco Petitta*

Main category: math.AP

TL;DR: The paper studies existence and nonexistence of positive solutions for singular quasilinear problems, focusing on the impact of parameters γ and the size of function g.


<details>
  <summary>Details</summary>
Motivation: To understand the conditions under which singular quasilinear problems admit positive solutions, particularly how γ and g influence solvability.

Method: Analyzes a model problem involving a singular term and a gradient term, using mathematical techniques to derive existence and nonexistence results.

Result: Existence and nonexistence of solutions are proven, with outcomes depending on γ and the size of g.

Conclusion: The study provides clear criteria for solvability of such problems, highlighting the roles of γ and g.

Abstract: In this paper we deal with positive solutions for singular quasilinear
problems whose model is $$ \begin{cases} -\Delta u + \frac{|\nabla
u|^2}{(1-u)^\gamma}=g & \mbox{in $\Omega$,}\newline \hfill u=0 \hfill &
\mbox{on $\partial\Omega$,} \end{cases} $$ where $\Omega $ is a bounded open
set of $\mathbb{R}^N$, $g\geq 0 $ is a function in some Lebesgue space, and
$\gamma>0$. We prove both existence and nonexistence of solutions depending on
the value of $\gamma$ and on the size of $g$.

</details>


### [45] [Global-in-time convergence in infinity-ion-mass limit for bipolar Euler-Poisson equations](https://arxiv.org/abs/2508.07704)
*Zhongmin Qian,Liang Zhao,Shengguo Zhu*

Main category: math.AP

TL;DR: The paper rigorously proves the global-in-time convergence of solutions from multi-dimensional bipolar Euler-Poisson equations to unipolar ones via the infinity-ion mass limit, using uniform tame estimates and careful compactness methods.


<details>
  <summary>Details</summary>
Motivation: The study aims to understand the transition from bipolar to unipolar Euler-Poisson systems under specific conditions, addressing challenges in singular limits and large initial velocities.

Method: The approach involves designing approximate problems with truncated convection operators and compactly supported initial data, deriving uniform a-priori estimates, and using compactness to attain global solutions.

Result: Global-in-time uniform tame estimates for regular solutions are established, enabling error estimates between bipolar and unipolar systems.

Conclusion: The paper successfully demonstrates the convergence of solutions under the infinity-ion mass limit, providing a framework for analyzing similar singular limits in hyperbolic-elliptic coupled systems.

Abstract: In this paper, the Cauchy problem for the multi-dimensional (M-D) bipolar
Euler-Poisson equations with far field vacuum is considered. Based on physical
observations and some elaborate analysis of this system's intrinsic symmetric
hyperbolic-elliptic coupled structures, for a class of smooth initial data that
are of small scaled density but possibly large mean velocity, we give one
rigorous global-in-time convergence proof for regular solutions from M-D
bipolar Euler-Poisson equations to M-D unipolar Euler-Poisson equations through
the infinity-ion mass limit. Here the initial scaled density is required to
decay to zero in the far field, and the spectrum of the Jacobi matrix of the
initial mean velocity are all positive. In order to deal with such kind of
singular limits, the global-in-time uniform tame estimates of regular solutions
to M-D bipolar Euler-Poisson equations with respect to the ratio of electron
mass over ion mass are established, based on which the corresponding error
estimates in smooth function spaces between the two systems considered are also
given. To achieve these, our main strategy is to regard the original problem
for M-D bipolar Euler-Poisson equations as the limit of a series of carefully
designed approximate problems which have truncated convection operators and
compactly supported initial data. For such artificial problems, we can derive
careful a-priori estimates that are independent of the mass ratio, the size of
the initial data' supports and the truncation parameters. Then the global
uniform existence of regular solutions of the original problem are attained via
careful compactness.

</details>


### [46] [Nondegeneracy of positive solutions for critical Hartree equation on Heisenberg group and it's applications](https://arxiv.org/abs/2508.07719)
*Minbo Yang,Shuijin Zhang*

Main category: math.AP

TL;DR: The paper studies the uniqueness and nondegeneracy of positive bubble solutions for a generalized energy-critical Hartree equation on the Heisenberg group, using techniques like the Cayley transform and spherical harmonic decomposition. It also explores the asymptotic behavior of solutions for a related Brezis-Nirenberg type problem.


<details>
  <summary>Details</summary>
Motivation: To understand the properties of solutions to the generalized energy-critical Hartree equation on the Heisenberg group, particularly their uniqueness and nondegeneracy, and to extend these insights to a related Brezis-Nirenberg problem.

Method: The authors employ the Cayley transform, spherical harmonic decomposition, and the Funk-Hecke formula to analyze the nondegeneracy of positive bubble solutions.

Result: The nondegeneracy of positive bubble solutions for the Hartree equation is proven. Additionally, the asymptotic behavior of solutions for the Brezis-Nirenberg problem is investigated as a parameter approaches zero.

Conclusion: The study provides rigorous proofs for the nondegeneracy of solutions and offers insights into their behavior, contributing to the broader understanding of nonlinear equations on the Heisenberg group.

Abstract: We study the uniqueness and nondegeneracy of positive bubble solutions for
the generalized energy-critical Hartree equation on the Heisenberg group
$\mathbb{H}^{n}$, \begin{equation}\label{0.1}
  -\Delta_{\mathbb{H}}u=\left(\int_{\mathbb{H}^{n}}\frac{|u(\eta)|^{Q^{\ast}_{\mu}}}{|\eta^{-1}\xi|^{\mu}}\mathrm{d}\eta\right)|u|^{Q^{\ast}_{\mu}-2}u,~~~\xi,\eta\in\mathbb{H}^{n},
\end{equation} where $\Delta_{\mathbb{H}}$ represents the Kohn Laplacian,
$u(\eta)$ is a real-valued function, $Q=2n+2$ is the homogeneous dimension of
$\mathbb{H}^{n}$, $\mu\in (0,Q)$ is a real parameter and $Q^{\ast}_{\mu}$ is
the upper critical exponent following the Hardy-Littlewood-Sobolev inequality
on the Heisenberg group. By applying the Cayley transform, the spherical
harmonic decomposition and the Funk-Hecke formula of the spherical harmonic
function, we prove the nondegeneracy of positive bubble solutions for
(\ref{0.1}). As an applications, we investigate the asymptotic behavior of the
solutions for the Brezis-Nirenberg type problem as $\varepsilon\rightarrow 0$
\begin{equation}\label{0.2}
  \left\{
  \begin{aligned}
  &-\Delta_{\mathbb{H}}u=\varepsilon
u+\left(\int_{\Omega}\frac{|u(\eta)|^{Q^{\ast}_{\mu}}}{|\eta^{-1}\xi|^{\mu}}\mathrm{d}\eta
\right)|u|^{Q^{\ast}_{\mu}-2}u,~~&&\mathrm{in}~\Omega\subset \mathbb{H}^{n},
  &u=0,~~&&\mathrm{on}~\partial\Omega.
  \end{aligned}
  \right. \end{equation}

</details>


### [47] [Blow-up construction and instability for mass-critical half-wave equation with slightly superthreshold mass](https://arxiv.org/abs/2508.07787)
*Jeongheon Park,Soonsik Kwon,Taegyu Kim*

Main category: math.AP

TL;DR: The paper constructs finite-time blow-up solutions for the $L^2$-critical focusing half-wave equation with mass slightly above the threshold, inspired by mass-critical NLS results. It analyzes their asymptotic behavior and instability.


<details>
  <summary>Details</summary>
Motivation: To extend insights from mass-critical NLS to the nonlocal half-wave equation, which lacks pseudo-conformal symmetry, and to understand blow-up dynamics near the threshold mass.

Method: Constructs blow-up solutions with a profile driven by the rescaled ground state and a decoupled dispersive radiation component. Analyzes modulation dynamics and instability.

Result: Rigorous description of asymptotic behavior near blow-up time and demonstration of instability via non-blow-up solutions.

Conclusion: The work overcomes challenges of the nonlocal setting and extends mass-critical blow-up insights to the half-wave equation.

Abstract: We study the blow-up dynamics for the $L^2$-critical focusing half-wave
equation on the real line, a nonlocal dispersive PDE arising in various
physical models. As in other mass-critical models, the ground state solution
becomes a threshold between the global well-posedness and the existence of a
blow-up. The first blow-up construction is due to Krieger, Lenzmann and
Rapha\"el, in which they constructed the minimal mass blow-up solution at the
threshold mass. In this paper, we construct finite-time blow-up solutions with
mass slightly exceeding the threshold. This is inspired by similar results in
the mass-critical NLS by Bourgain and Wang, and their instability by Merle,
Rapha\"el and Szeftel. We exhibit a blow-up profile driven by the rescaled
ground state, with a decoupled dispersive radiation component. We rigorously
describe the asymptotic behavior of such solutions near the blow-up time,
including sharp modulation dynamics. Furthermore, we demonstrate the
instability of these solutions by constructing non-blow-up solutions that are
arbitrarily close to the blow-up solutions. The main contribution of this work
is to overcome the nonlocal setting of half-wave and to extend insights from
the mass-critical NLS to a setting lacking pseudo-conformal symmetry.

</details>


### [48] [A new critical exponent for semi-linear damped wave equations with the initial data from Sobolev spaces of negative order](https://arxiv.org/abs/2508.07802)
*Dinh Van Duong,Tuan Anh Dao*

Main category: math.AP

TL;DR: The paper studies critical exponents for semi-linear damped wave equations with power nonlinearity, focusing on Sobolev spaces of negative order. It identifies a new critical exponent and analyzes global existence and blow-up conditions.


<details>
  <summary>Details</summary>
Motivation: To determine the critical exponent for semi-linear damped wave equations with power nonlinearity and initial data in negative-order Sobolev spaces, addressing gaps in existing literature.

Method: Proving global existence of small data Sobolev solutions for exponents above the critical value and blow-up for exponents below it, with additional lifespan estimates for blow-up cases.

Result: A new critical exponent is derived, and it is shown to belong to the global existence range. Blow-up conditions and lifespan estimates are provided.

Conclusion: The study successfully identifies a critical exponent and clarifies conditions for global existence and blow-up, contributing to the understanding of semi-linear damped wave equations.

Abstract: In this paper, we would like to study critical exponent for semi-linear
damped wave equations with power nonlinearity and initial data belonging to
Sobolev spaces of negative order $\dot{H}_m^{-\gamma}$. Precisely, we obtain a
new critical exponent $p_c(m,\gamma) := 1 + \frac{2m}{n+m\gamma}$ for $m \in
(1, 2], \,\gamma \in \left[0, \frac{n(m-1)}{m} \right)$ by proving global (in
time) existence of small data Sobolev solutions when $p \geq p_c(m,\gamma)$ and
blow-up of weak solutions in finite time even for small data if $1 < p <
p_c(m,\gamma)$. Additionally, the new point of this paper is the critical value
$p= p_c(m,\gamma)$ belongs to the global existence range. Furthermore, we are
going to provide lifespan estimates for solutions when the blow-up phenomenon
occurs.

</details>


### [49] [Nadirashvili' Conjecture for Elliptic PDEs and its Applications](https://arxiv.org/abs/2508.07861)
*Jiahuan Li,Junyuan Wang,Zhichen Ying*

Main category: math.AP

TL;DR: The paper confirms Nadirashvili's conjecture about bounding the supremum of a harmonic function in a half-ball by derivatives at the center, using nodal set bounds and elliptic estimates. It extends the conjecture to general elliptic PDEs and provides applications.


<details>
  <summary>Details</summary>
Motivation: To address Nadirashvili's conjecture regarding harmonic functions with bounded nodal volume and explore its broader implications for elliptic PDEs.

Method: Utilizes lower bounds of nodal sets, propagation of smallness, and elliptic estimates to validate and extend the conjecture.

Result: The conjecture is proven true for harmonic functions and extended to general elliptic PDEs with smooth coefficients, with a weaker version for less regular coefficients.

Conclusion: The findings affirm the conjecture and demonstrate its applicability to a wider class of problems, supported by practical applications.

Abstract: In this article, we investigate the conjecture posed by Nadirashvili in
\cite{nadirashvilli1997geometry}. It states that if a harmonic function has
bounded nodal volume in the unit ball, then the supermum over the half-ball can
be bounded by a finite sum of derivatives at the center. The main tool in this
paper is the lower bound of nodal sets, which is first proved in
\cite{MR3739232}. Also we combine the propagation of smallness property and
elliptic estimates to give a positive answer to this conjecture. In fact, we
can extend this conjecture to general elliptic PDEs with smooth coefficients
and also obtain a weak verison for less regular coefficients. Finally, we give
several applications of this conjecture.

</details>


### [50] [A Becker-D{ö}ring model with injection and irreversible fragmentation](https://arxiv.org/abs/2508.07884)
*Simon Loin*

Main category: math.AP

TL;DR: A variant of the Becker-Döring equations is introduced, modeling cluster growth with irreversible fragmentation and monomer injection. Well-posedness is proven, and long-time behavior is analyzed, showing convergence to equilibrium under certain conditions. A numerical scheme is also presented.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by enzymatic reactions in biology, aiming to model cluster growth dynamics with irreversible fragmentation and monomer injection.

Method: The model extends the Becker-Döring equations to include irreversible fragmentation and monomer injection. Well-posedness is established, and long-time behavior is analyzed under varying conditions. A numerical scheme is developed.

Result: Under strong fragmentation, infinite steady-states may occur. For low monomer injection and moderate fragmentation, solutions converge exponentially fast to equilibrium.

Conclusion: The model provides insights into cluster growth dynamics, with analytical and numerical results supporting its validity and applicability.

Abstract: We introduce and analyse a variant of the Becker-D{\"o}ring equations that
models the growth of clusters through the gain or loss of monomers. Motivated
by enzymatic reactions in biology, this model incorporates irreversible
fragmentation and monomers injection. We establish the well-posedness of the
equations under suitable conditions on the kinetic rates. Then, as in the
Becker-D{\"o}ring equations, we distinguish two cases for the long time
behaviour of our solution, however the distinction is made from the constant
rate injection of monomers. While under strong fragmentation rate the system
may exhibit infinite steady-states, we prove for low injection rate and
moderate fragmentation the solution converges locally exponentially fast to the
equilibrium. Finally, we present a well-balanced and coarse-grained numerical
scheme.

</details>


### [51] [A Hamilton-Jacobi approach for the evolutionary dynamics of a model with gene transfer: characterizing monomorphic dynamics for non-concave fitness functions](https://arxiv.org/abs/2508.07886)
*Alejandro Gárriz,Sepideh Mirrahimi*

Main category: math.AP

TL;DR: The paper analyzes the asymptotic behavior of an integro-differential equation modeling population adaptation, focusing on mutation, selection, horizontal gene transfer, and competition. It characterizes dynamics in two regimes: adaptation to a balanced trait or evolutionary suicide.


<details>
  <summary>Details</summary>
Motivation: To understand the rich dynamics of population adaptation, particularly how traits evolve under mutation, selection, horizontal gene transfer, and competition.

Method: Uses an approach involving Hamilton-Jacobi equations with constraint, extending previous work to non-globally concave growth rates.

Result: Identifies two regimes: 1) adaptation to a balanced trait, 2) evolutionary suicide (maladaptation leading to extinction).

Conclusion: The study extends theoretical understanding of population dynamics, particularly for non-globally concave growth rates, providing insights into evolutionary outcomes.

Abstract: We study the asymptotic behavior of an integro-dierential equation describing
the evolutionary adaptation of a population structured by a phenotypic trait.
The model takes into account mutation, selection, horizontal gene transfer and
competition. Previous works, based on the numerical studies or theoretical
study of the corresponding stationary problem, have shown that the dynamics of
the solutions are rich and we may expect several qualitative outcomes. In this
article, we characterize the dynamics of the solution in two regimes: 1) a
situation where the solution concentrates around a dominant trait, evolving
gradually to a trait determined by a balance between selection and horizontal
gene transfer; 2) a situation where the solution concentrates around a dominant
trait which evolves gradually to a maladapted trait such that the population
becomes extinct (a situation known as the evolutionary suicide). Our analysis
is based on an approach involving Hamilton-Jacobi equations with constraint.
Previously, the solutions to such equations were characterized for globally
concave growth rates. Here, we extend this approach to situations where the
growth rate is not globally concave.

</details>


### [52] [Symmetry and monotonicity of singular solutions for the Hartree equation](https://arxiv.org/abs/2508.07893)
*Ying Cai,Guangze Gu,Aleks Jevnikar*

Main category: math.AP

TL;DR: The paper analyzes positive singular solutions of a nonlocal Hartree equation, proving symmetry and monotonicity using moving plane methods, and demonstrates existence of such solutions for a model problem.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of singular solutions in nonlocal Hartree equations and establish symmetry and monotonicity properties.

Method: Employing moving plane methods to analyze symmetry and monotonicity of solutions relative to the singular set.

Result: Proves that the solution is symmetric and monotone with respect to the singular set and shows existence of such solutions for a model problem.

Conclusion: The study successfully establishes symmetry and monotonicity properties of singular solutions and confirms their existence for a model case.

Abstract: In this paper we are concerned with positive singular solutions of the
following nonlocal Hartree equation $$-\Delta u\!=\Big(
\int_{\mathbb{R}^N\setminus \Gamma}\frac{F(u(y))}{|x-y|^\mu}dy \Big)f (u(x)),
\quad x\in \mathbb{R}^N\setminus\Gamma,$$ where $F$ is the primitive of $f$ and
$\Gamma$ is the singular set. Under suitable assumptions, we prove that $u$ is
symmetric and monotone with respect to the singular set by using moving plane
methods. Furthermore, we complement this study by showing the existence, for a
model problem, of a singular solution with the desired properties.

</details>


### [53] [Formation of singularities for the relativistic membrane equation with radial symmetry](https://arxiv.org/abs/2508.07895)
*Lv Cai,Jianli Liu*

Main category: math.AP

TL;DR: The paper rewrites the relativistic membrane equation as a first-order hyperbolic system and uses the characteristic decomposition method to prove a new blow-up theorem, showing singularity formation when the hypersurface turns from timelike to null.


<details>
  <summary>Details</summary>
Motivation: To generalize previous results (Kong, Sun, and Zhou, 2006) on singularity formation in the relativistic membrane equation to a broader context.

Method: Rewriting the equation as a first-order hyperbolic system and applying the characteristic decomposition method.

Result: A new blow-up theorem is established, demonstrating singularity formation when the hypersurface becomes null.

Conclusion: The work generalizes earlier findings and provides a deeper understanding of singularity formation in relativistic membranes.

Abstract: The relativistic membrane equation can be rewritten as a first order
hyperbolic system. Making use of the characteristic decomposition method, a new
blow-up theorem is established. As an application, it demonstrates the
formation of singularities for the relativistic membrane equation. Indeed, the
singularity occurs when the hypersurface turns from being timelike to being
null. This generalizes the result of Kong, Sun and Zhou's work for
one-dimensional case [J Math Phys 47(1): 013503, 2006].

</details>


### [54] [Propagation of weak log-concavity along generalised heat flows via Hamilton-Jacobi equations](https://arxiv.org/abs/2508.07931)
*Louis-Pierre Chaintron,Giovanni Conforti,Katharina Eichinger*

Main category: math.AP

TL;DR: The paper introduces a weaker notion of log-concavity that generalizes the preservation property of logconcavity by heat semigroups, extending it to non-log-concave settings and providing new functional inequalities and log-Hessian estimates.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the limitation of the Prékopa-Leindler inequality, which preserves logconcavity only for heat semigroups, by generalizing the concept for broader semigroups and non-convex potentials.

Method: The method involves stochastic control interpretation and second-order analysis of reflection coupling along HJB characteristics to propagate weak log-concavity and derive new functional inequalities.

Result: Key results include logsemiconcavity for Schrödinger operators' ground states, propagation of functional inequalities, and uniform two-sided log-Hessian estimates for parabolic equations with unbounded coefficients.

Conclusion: The paper concludes with novel insights into weak log-concavity propagation, conditioning, and marginalization, extending classical results to non-log-concave settings and providing new tools for parabolic regularization.

Abstract: A well-known consequence of the Pr{\'e}kopa-Leindler inequality is the
preservation of logconcavity by the heat semigroup. Unfortunately, this
property does not hold for more general semigroups. In this paper, we exhibit a
slightly weaker notion of log-concavity that can be propagated along
generalised heat semigroups. As a consequence, we obtain logsemiconcavity
properties for the ground state of Schr{\"o}dinger operators for non-convex
potentials, as well as propagation of functional inequalities along generalised
heat flows. We then investigate the preservation of weak log-concavity by
conditioning and marginalisation, following the seminal works of Brascamp and
Lieb. To our knowledge, our results are the first of this type in non
log-concave settings. We eventually study generation of log-concavity by
parabolic regularisation and prove novel two-sided log-Hessian estimates for
the fundamental solution of parabolic equations with unbounded coefficients,
which can be made uniform in time. These properties are obtained as a
consequence of new propagation of weak convexity results for quadratic
Hamilton-Jacobi-Bellman (HJB) equations. The proofs rely on a stochastic
control interpretation combined with a second order analysis of reflection
coupling along HJB characteristics.

</details>


### [55] [Well-posedness for a fourth-order nonisothermal tumor growth model of Caginalp type](https://arxiv.org/abs/2508.07979)
*Giulia Cavalleri,Pierluigi Colli,Elisabetta Rocca*

Main category: math.AP

TL;DR: A nonisothermal phase-field model for tumor growth under hyperthermia, coupling Cahn-Hilliard, heat balance, and nutrient equations, analyzed via approximation and regularization.


<details>
  <summary>Details</summary>
Motivation: To model tumor growth dynamics under hyperthermia, incorporating chemotaxis and active transport effects.

Method: Two-step approximation: regularization of potential and Faedo-Galerkin discretization. Strong solutions analyzed under stricter assumptions.

Result: Existence of strong solutions and uniqueness via continuous dependence.

Conclusion: The model effectively describes tumor growth under hyperthermia, with rigorous mathematical analysis supporting its validity.

Abstract: We introduce a nonisothermal phase-field system of Caginalp type that
describes tumor growth under hyperthermia. The model couples a possibly viscous
Cahn-Hilliard equation, governing the evolution of the healthy and tumor
phases, with an equation for the heat balance, and a reaction-diffusion
equation for the nutrient concentration. The resulting nonlinear system
incorporates chemotaxis and active transport effects, and is supplemented with
no-flux boundary conditions. The analysis is carried out through a two-step
approximation procedure, involving a regularization of the potential and a
Faedo-Galerkin discretization scheme. Under stronger regularity assumptions, we
further establish the existence of strong solutions and their uniqueness via a
continuous dependence result.

</details>


### [56] [Boundary Regularity for Fully Nonlinear Parabolic equations on $C^{1,\mathrm{Dini}}$ Domains](https://arxiv.org/abs/2508.08008)
*Jiqi Dong,Xuemei Li,Yuanyuan Lian*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We establish the boundary pointwise Lipschitz regularity on exterior
$C^{1,\mathrm{Dini}}$ domains and the Hopf lemma on interior
$C^{1,\mathrm{Dini}}$ domains for fully nonlinear parabolic equations by a
unified perturbation method. In fact, above two regularity hold for more
general solution sets, i.e., the Pucci's class $S^*(\lambda, \Lambda, f)$.
Furthermore, based on the boundary pointwise Lipschitz regularity, we obtain
the global ${W}^{2,\delta}$ regularity on exterior $C^{1,\mathrm{Dini}}$
domains for any $0<\delta<1$, which is new even for the harmonic functions.

</details>


### [57] [Asymptotic stability of composite waves of shock profile and rarefaction for the Navier-Stokes-Poisson system](https://arxiv.org/abs/2508.08059)
*Wanyong Shim*

Main category: math.AP

TL;DR: The paper analyzes the stability of composite waves (shock and rarefaction) in the isothermal Navier-Stokes-Poisson system for plasma ion dynamics, proving convergence to these waves under certain initial conditions.


<details>
  <summary>Details</summary>
Motivation: To understand the long-term behavior of composite waves in collision-dominated plasmas, extending prior work on single shock profiles.

Method: Uses the $a$-contraction with shifts method and a modulated relative functional to adapt techniques from Navier-Stokes equations.

Result: Shows convergence to composite waves (shock and rarefaction) under $H^2$-close initial data, with dynamical shifts.

Conclusion: The method successfully extends to composite waves, confirming stability and convergence in the NSP system.

Abstract: We study the stability of composite waves consisting of a shock profile and a
rarefaction wave for the one-dimensional isothermal Navier--Stokes--Poisson
(NSP) system, which describes the ion dynamics in a collision-dominated plasma.
More precisely, we prove that if the initial data are sufficiently close in the
$H^2$ norm to the Riemann data for which the associated quasi-neutral Euler
system admits a Riemann solution consisting of a shock and a rarefaction wave,
then the solution to the Cauchy problem for the NSP system converges, up to a
dynamical shift, to a superposition of the corresponding shock profile and the
rarefaction wave as time tends to infinity. The proof is based on the method of
$a$-contraction with shifts, which has recently been applied to establish the
asymptotic stability of composite waves for the Navier--Stokes equations. To
adapt this method to our problem, we employ a modulated relative functional
introduced in our previous work on the stability of single shock profiles for
the NSP system.

</details>


### [58] [Blow up for nonlinear wave-type equations with perturbed derivatives](https://arxiv.org/abs/2508.08089)
*F. A. Chiarello,G. Girardi,S. Lucente*

Main category: math.AP

TL;DR: Refinement of blow-up results for semilinear wave equations with perturbed derivatives, focusing on radial initial data and zero-order term conditions.


<details>
  <summary>Details</summary>
Motivation: To understand the interplay between derivative perturbations, initial data size, and nonlinearity exponent in semilinear wave equations.

Method: Analyze semilinear wave-type equations recast as wave equations with perturbed derivatives, focusing on radial initial data with suitable decay.

Result: Identified conditions on zero-order terms that govern the blow-up behavior, refining existing results.

Conclusion: The study provides refined blow-up criteria for semilinear wave equations, highlighting the role of zero-order terms and initial data.

Abstract: We investigate semilinear wave-type equations that can be recast as wave
equations with derivatives perturbed by zero-order terms. This framework covers
several well-studied cases, including the scale-invariant wave equation. In
this setting, we refine existing blow-up results for radial initial data with
suitable decay, and identify conditions on the zero-order terms that govern the
interplay between derivative perturbations, initial data size, and nonlinearity
exponent.

</details>


### [59] [Weak solutions and incompressible limit of a quasi-incompressible Navier--Stokes/Cahn--Hilliard model for viscous two-phase flows](https://arxiv.org/abs/2508.08090)
*Mingwen Fei,Xiang Fei,Daozhi Han,Yadong Liu*

Main category: math.AP

TL;DR: The paper studies a quasi-incompressible Navier-Stokes/Cahn-Hilliard system for two immiscible fluids with partial mixing and long-range interactions, focusing on unmatched densities and mass-averaged velocity. It proves global weak solutions in 3D and establishes convergence to model H as density difference vanishes.


<details>
  <summary>Details</summary>
Motivation: To address the motion of two immiscible viscous fluids with partial mixing and unmatched densities, where the velocity field is not divergence-free and pressure affects the chemical potential.

Method: Uses implicit time discretization and fixed-point arguments for approximate systems, along with the relative entropy method for incompressible limits.

Result: Existence of global weak solutions in 3D and convergence to model H as density difference approaches zero, leveraging non-standard pressure controls.

Conclusion: The study successfully analyzes the quasi-incompressible system, providing theoretical insights and convergence results for practical applications.

Abstract: We study a quasi-incompressible Navier--Stokes/Cahn--Hilliard coupled system
which describes the motion of two macroscopically immiscible incompressible
viscous fluids with partial mixing in a small interfacial region and long-range
interactions. The case of unmatched densities with mass-averaged velocity is
considered so that the velocity field is no longer divergence-free, and the
pressure enters the equation of the chemical potential. We first prove the
existence of global weak solutions to the model in a three-dimensional periodic
domain, for which the implicit time discretization together with a fixed-point
argument to the approximate system is employed. In particular, we obtain a new
regularity estimate of the order parameter by exploiting the partial damping
effect of the capillary force. Then utilizing the relative entropy method, we
establish the incompressible limit -- the quasi-incompressible two-phase model
converges to model H as the density difference tends to zero. Crucial to the
passage of the incompressible limit, due to the lack of regularity of the
pressure, are some non-standard uniform-in-density difference controls of the
pressure, which are derived from the structure of the momentum equations and
the improved regularity of the order parameter.

</details>


### [60] [Finite-time blow-up for the three dimensional axially symmetric Keller-Segel system](https://arxiv.org/abs/2508.08103)
*Federico Buseghin,Juan Dávila,Manuel del Pino,Monica Musso*

Main category: math.AP

TL;DR: Construction of axially symmetric finite-time blow-up solutions for the 3D Keller-Segel system, with mass concentration along multiple rings and refined blow-up rate expansion.


<details>
  <summary>Details</summary>
Motivation: To generalize and refine the understanding of Type II singularities in the 3D Keller-Segel system, building on recent work by Hou, Nguyen, and Song.

Method: Adaptation of gluing techniques to derive precise asymptotic expansions for the solutions.

Result: Solutions exhibit mass concentration along multiple rings, with a refined expansion for the blow-up rate.

Conclusion: The work advances the understanding of blow-up phenomena in the Keller-Segel system, providing new insights into Type II singularities.

Abstract: We construct axially symmetric finite-time blow-up solutions to the
three-dimensional Keller-Segel system. By adapting gluing techniques, we derive
a precise asymptotic expansion for Type II singularities that generalizes the
recent work of Hou, Nguyen, and Song. In our construction the mass concentrates
along multiple rings and we obtain a refined expansion for the blow-up rate.

</details>


### [61] [Time-delayed opinion dynamics with leader-follower interactions: consensus, stability, and mean-field limits](https://arxiv.org/abs/2508.08157)
*Young-Pil Choi,Chiara Cicolani,Cristina Pignotti*

Main category: math.AP

TL;DR: The paper analyzes a time-delayed Hegselmann-Krause opinion model with leaders and non-leaders, proving exponential consensus convergence and studying mean-field limits in two regimes.


<details>
  <summary>Details</summary>
Motivation: To understand opinion dynamics in systems with leaders and non-leaders, accounting for time delays in communication and decision-making.

Method: The study uses a time-delayed variant of the Hegselmann-Krause model, analyzing exponential convergence to consensus and mean-field limits in two population regimes.

Result: Exponential convergence to consensus is proven without small delay assumptions. Mean-field analysis shows existence, uniqueness, and exponential decay in macroscopic models.

Conclusion: The model provides insights into opinion formation with leaders and delays, with rigorous convergence and mean-field results.

Abstract: We study a time-delayed variant of the Hegselmann-Krause opinion formation
model featuring a small group of leaders and a large group of non-leaders. In
this model, leaders influence all agents but only interact among themselves. At
the same time, non-leaders update their opinions via interactions with their
peers and the leaders, with time delays accounting for communication and
decision-making lags. We prove the exponential convergence to consensus of the
particle system, without imposing smallness assumptions on the delay
parameters. Furthermore, we analyze the mean-field limit in two regimes: (i)
with a fixed number of leaders and an infinite number of non-leaders, and (ii)
with both populations tending to infinity, obtaining existence, uniqueness, and
exponential decay estimates for the corresponding macroscopic models.

</details>


### [62] [On the attainability of singular Wiener bound](https://arxiv.org/abs/2508.08208)
*Zhonggan Huang*

Main category: math.AP

TL;DR: The paper analyzes the attainability of the Wiener bound for conductive material mixtures, focusing on lower and upper bounds. It links geometric properties of the material's support to the effective tensor and introduces a transformation to connect conductance maximality with area criticality. Applications in modeling leaf venation are suggested.


<details>
  <summary>Details</summary>
Motivation: To understand how the geometric distribution of conductive materials affects the attainability of the Wiener bound, with potential applications in natural systems like leaf venation.

Method: For lower attainability, mixtures with high-conductance materials on sets of finite Hausdorff measures are studied. For upper attainability, a transformation from varifolds to matrix-valued measures is applied.

Result: Lower attainability is linked to the homotopy classes of closed paths, while upper attainability connects conductance maximality to area criticality, with a pointwise dimension bound derived.

Conclusion: The findings provide insights into the geometric constraints of conductive mixtures and suggest novel applications in modeling natural patterns like leaf venation.

Abstract: We characterize the lower and upper attainability of the Wiener bound (also
known as Voigt-Reuss bound) for singularly distributed conductive material
mixtures. For the lower attainability we consider mixtures in which
high-conductance materials support on sets having finite one-dimensional
Hausdorff measures. We show that, under a mild coercivity condition, the kernel
of the effective tensor of the mixture is equal to the orthogonal complement of
the homotopy classes of closed paths in the supporting set. This shows that a
periodic planar network has positive definite effective tensor, i.e., it is
resilient to fluctuations, if and only if the network is reticulate. We provide
a geometric characterization of the upper attainability by applying a
transformation from varifolds to matrix-valued measures. We show that this
transformation leads to an equivalence between two distinct notions from
material science and geometric measure theory respectively: conductance
maximality and area criticality. Based on this relation we show a pointwise
dimension bound for mixtures that attain the upper Wiener bound by applying a
fractional version of the monotonicity formula for stationary varifolds. This
dimension bound illustrates how the maximality condition constrains the local
anisotropy and the local distribution of conductance magnitudes. Both the lower
and upper attainability results have potential novel applications in modeling
leaf venation patterns.

</details>


### [63] [Structural properties of one-dimensional metric currents: SBV-representations, connectedness and the flat chain conjecture](https://arxiv.org/abs/2508.08212)
*Adolfo Arroyo-Rabasa,Guy Bouchitté*

Main category: math.AP

TL;DR: The paper resolves the one-dimensional flat chain conjecture, linking metric currents to geometric connectedness, and provides approximation and decomposition results for currents in Banach and metric spaces.


<details>
  <summary>Details</summary>
Motivation: To understand the relationship between one-dimensional metric currents and the geometry of metric spaces, resolving the flat chain conjecture and exploring approximation and decomposition properties.

Method: Proves equivalence of the flat chain conjecture to a geometric connectedness property, approximates currents by normal and polyhedral currents, and establishes a Smirnov-type decomposition for one-dimensional currents.

Result: Metric currents can be approximated by normal currents if a geometric condition holds; any 1-current in a Banach space can be completed into a cycle with controlled mass; and a Smirnov-type decomposition is proven for arbitrary metric spaces.

Conclusion: The study advances the understanding of metric currents, resolving key conjectures and providing practical tools for approximation and decomposition in various settings.

Abstract: A comprehensive study of one-dimensional metric currents and their
relationship to the geometry of metric spaces is presented. We resolve the
one-dimensional flat chain conjecture in this general setting, by proving that
its validity is equivalent to a simple geometric connectedness property. More
precisely, we prove that metric currents can be approximated in the mass norm
by normal currents if and only if every $1$-rectifiable set can be covered by
countably many Lipschitz curves up to an $\mathscr{H}^1$-negligible set.
Building on this, we demonstrate that any $1$-current in a Banach space can be
completed into a cycle by a rectifiable current, with the added mass controlled
by the Kantorovich--Rubinstein norm of its boundary. We further refine our
approximation result by showing that these currents can be approximated by
polyhedral currents modulo a cycle. Finally, in arbitrary complete metric
spaces, we establish a Smirnov-type decomposition for one-dimensional currents.
This decomposition expresses such currents as a superposition, without mass
cancellation, of currents associated with curves of bounded variation that have
a vanishing Cantor part.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [64] [TorchSim: An efficient atomistic simulation engine in PyTorch](https://arxiv.org/abs/2508.06628)
*Orion Cohen,Janosh Riebesell,Rhys Goodall,Adeesh Kolluru,Stefano Falletta,Joseph Krause,Jorge Colindres,Gerbrand Ceder,Abhijeet S. Gangan*

Main category: physics.comp-ph

TL;DR: TorchSim is an open-source atomistic simulation engine optimized for MLIPs, offering GPU-accelerated batched simulations and compatibility with various potentials and tools.


<details>
  <summary>Details</summary>
Motivation: To address the inefficiency of existing molecular dynamics packages by leveraging modern GPUs for batched simulations and supporting MLIPs.

Method: Rewrites core atomistic simulation primitives in PyTorch, enabling batched simulations and GPU acceleration. Supports diverse potentials and integrates with materials informatics tools.

Result: Achieves orders of magnitude acceleration for MLIPs and efficiently utilizes GPUs by simulating multiple systems concurrently.

Conclusion: TorchSim provides a powerful, flexible, and efficient solution for atomistic simulations in the MLIP era.

Abstract: We introduce TorchSim, an open-source atomistic simulation engine tailored
for the Machine Learned Interatomic Potential (MLIP) era. By rewriting core
atomistic simulation primitives in PyTorch, TorchSim can achieve orders of
magnitude acceleration for popular MLIPs. Unlike existing molecular dynamics
packages, which simulate one system at a time, TorchSim performs batched
simulations that efficiently utilize modern GPUs by evolving multiple systems
concurrently. TorchSim supports molecular dynamics integrators, structural
relaxation optimizers, both machine-learned and classical interatomic
potentials (such as Lennard-Jones, Morse, soft-sphere), batching with automatic
memory management, differentiable simulation, and integration with popular
materials informatics tools.

</details>


### [65] [How to simulate Lévy flights in a steep potential: An explicit splitting numerical scheme](https://arxiv.org/abs/2508.07339)
*Ilya Pavlyukevich,Olga Aryasova,Alexei Chechkin,Oleksii Kulyk*

Main category: physics.comp-ph

TL;DR: An explicit numerical scheme for simulating stochastic differential equations with superlinear drift and multiplicative heavy-tailed Lévy noise, ensuring no explosion and accurate moment capture.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of simulating solutions with confining superlinear drift and heavy-tailed Lévy noise, ensuring stability and accuracy.

Method: Proposes an explicit numerical scheme designed to prevent explosion and accurately capture finite moments, including sub-Gaussian tails in Gaussian cases.

Result: The scheme effectively approximates statistical moments and probabilistic characteristics of Lévy flights in steep potential landscapes.

Conclusion: The method is robust for simulating complex stochastic systems with heavy-tailed noise and superlinear drift.

Abstract: We propose an effective explicit numerical scheme for simulating solutions of
stochastic differential equations with confining superlinear drift terms,
driven by multiplicative heavy-tailed L\'evy noise. The scheme is designed to
prevent explosion and accurately capture all finite moments of the solutions.
  In the purely Gaussian case, it correctly reproduces moments of sub-Gaussian
tails of the solutions.
  This method is particularly well-suited for approximating statistical moments
and other probabilistic characteristics of L\'evy flights in steep potential
landscapes.

</details>


### [66] [A hybrid electromechanical phase-field and deep learning framework for predicting fracture in dielectric nanocomposites](https://arxiv.org/abs/2508.07469)
*Aamir Dean,Jaykumar Mavani,Betim Bahtiri,Behrouz Arash,Raimund Rolfes*

Main category: physics.comp-ph

TL;DR: A hybrid model combining electromechanical phase-field fracture and deep learning predicts crack propagation in dielectric nanocomposites, with electric potential fields proving more effective for CNN-based segmentation.


<details>
  <summary>Details</summary>
Motivation: Accurate prediction of crack propagation in dielectric materials is crucial for structural health monitoring and smart system design.

Method: A hybrid framework integrates phase-field fracture simulations with CNNs (ResNet-U-Net) trained on phase-field damage and electric potential data.

Result: Electric potential fields outperform phase-field data in segmentation accuracy, convergence speed, and generalization due to smoother gradients.

Conclusion: The framework reduces computational costs while maintaining accuracy, with potential for sensor-based applications.

Abstract: The accurate and efficient prediction of crack propagation in dielectric
materials is a critical challenge in structural health monitoring and the
design of smart systems. This work presents a hybrid modeling framework that
combines an electromechanical phase-field fracture model with deep
learning-based surrogate modeling to predict fracture evolution in dielectric
nanocomposite plates. The underlying finite element simulations capture the
coupling between mechanical deformation and electrical field perturbations
caused by cracks, using a variational phase-field formulation. High-fidelity
simulation outputs - namely, phase-field damage variables and electric
potential fields -- are used to train convolutional neural networks (CNNs) with
ResNet-U-Net architectures for pixel-wise segmentation of crack paths. The
study systematically compares the performance of CNNs trained on phase-field
versus electric potential data across multiple ResNet backbones. The results
reveal that electric potential fields, although they encode damage indirectly,
offer superior segmentation accuracy, faster convergence, and enhanced
generalization, owing to their smoother gradient distribution and global
spatial coverage. The proposed framework significantly reduces computational
costs while preserving high accuracy, offers potential when appropriately
adapted for sensor-based input data.

</details>


### [67] [Development of a Novel Riemann Solver for Solid Dynamics](https://arxiv.org/abs/2508.07954)
*Khoder Alhamwi Alshaar,J C Mandal*

Main category: physics.comp-ph

TL;DR: A new finite volume framework for solid dynamics using a momentum-deformation formulation and a Roe-type Riemann solver improves stability and accuracy in hyperbolic conservation law solutions.


<details>
  <summary>Details</summary>
Motivation: To enhance stability and accuracy in solid dynamics simulations, particularly for hyperbolic conservation laws, and to provide a foundation for future nonlinear and fluid-structure interaction cases.

Method: Develops a Roe-type Riemann solver within the C-TOUCH methodology, focusing on a momentum-deformation formulation for multidimensional problems.

Result: Validated against 2D and 3D linear elasticity benchmarks, showing robustness and accuracy compared to traditional displacement-based methods.

Conclusion: The framework is promising for large-scale dynamic simulations due to its stability, accuracy, and potential for future extensions.

Abstract: This work presents a new finite volume framework for solid dynamics based on
a momentum-deformation formulation. Building on the C-TOUCH methodology [1], a
novel Roe-type Riemann solver is developed to enhance the stability and
accuracy of hyperbolic conservation law solutions in solids. The approach
naturally handles multidimensional problems and provides a foundation for
future extensions to nonlinear and fluid-structure interaction cases.
Validation against standard two- and three-dimensional linear elasticity
benchmarks demonstrates the method's robustness and accuracy relative to
traditional displacement-based approaches, highlighting its promise for
large-scale dynamic simulations.

</details>


### [68] [Adaptive Online Emulation for Accelerating Complex Physical Simulations](https://arxiv.org/abs/2508.08012)
*Tara P. A. Tahseen,Nikolaos Nikolaou,Luís F. Simões,Kai Hou Yip,João M. Mendonça,Ingo P. Waldmann*

Main category: physics.comp-ph

TL;DR: AOE introduces adaptive neural surrogates for simulations, achieving 11.1x speedup with minimal offline training.


<details>
  <summary>Details</summary>
Motivation: Addresses trade-offs between model fidelity and computational feasibility in complex simulations.

Method: Uses OS-ELMs for dynamic emulator adaptation, avoiding matrix inversion instabilities with cumulative statistics.

Result: Achieves 91% time reduction (11.1x speedup) in a 1D atmospheric model while maintaining accuracy.

Conclusion: AOE enables high-fidelity simulations previously deemed intractable, with significant computational savings.

Abstract: Complex physical simulations often require trade-offs between model fidelity
and computational feasibility. We introduce Adaptive Online Emulation (AOE),
which dynamically learns neural network surrogates during simulation execution
to accelerate expensive components. Unlike existing methods requiring extensive
offline training, AOE uses Online Sequential Extreme Learning Machines
(OS-ELMs) to continuously adapt emulators along the actual simulation
trajectory. We employ a numerically stable variant of the OS-ELM using
cumulative sufficient statistics to avoid matrix inversion instabilities. AOE
integrates with time-stepping frameworks through a three-phase strategy
balancing data collection, updates, and surrogate usage, while requiring orders
of magnitude less training data than conventional surrogate approaches.
Demonstrated on a 1D atmospheric model of exoplanet GJ1214b, AOE achieves 11.1
times speedup (91% time reduction) across 200,000 timesteps while maintaining
accuracy, potentially making previously intractable high-fidelity time-stepping
simulations computationally feasible.

</details>


### [69] [Reproducing and Extending Brownian Motion in Optical Trap: A Computational Reimplementation of Volpe and Volpe (2013)](https://arxiv.org/abs/2508.08138)
*Eyad I. B Hamid*

Main category: physics.comp-ph

TL;DR: The paper re-simulates a 2013 study on Brownian particles in optical traps using Python, validating key physical regimes and extending the analysis with additional forces and transitions.


<details>
  <summary>Details</summary>
Motivation: To reproduce and validate the original study's findings while enhancing it with new simulations for pedagogical and research purposes.

Method: Reconstructed simulations from first principles using Python, implementing stochastic differential equations via finite difference schemes. Extended analysis includes force perturbations, rotational fields, Kramers transitions, and stochastic resonance.

Result: Successfully reproduced key physical regimes (ballistic to diffusive motion, optical confinement, velocity autocorrelations) and extended the model with additional dynamics.

Conclusion: The work reinforces the original study's value as a teaching and research tool, providing insights into stochastic dynamics and numerical modeling.

Abstract: We present a re-representation and independent simulation of the model
introduced by Giorgio Volpe and Giovanni Volpe in their 2013 study of a
Brownian particle in an optical trap (Volpe and Volpe, 2013). Rather than
duplicating their original plots, we reconstructed the simulations from first
principles using Python, implementing stochastic differential equations via
finite difference schemes. This work reproduces and validates the key physical
regimes described in the original article, including the transition from
ballistic to diffusive motion, optical confinement, and velocity
autocorrelations. To simulate rotational forces (Grier, 2003) and Kramers
transitions (Haenggi et al., 1990), we also extend the analysis to include
force perturbations, rotational fields, Kramers transitions, and stochastic
resonance. The simulations provide pedagogical insight into stochastic dynamics
and numerical modeling, reinforcing the original study's value as a teaching
and research tool in statistical and computational physics.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [70] [Polywell Revisited](https://arxiv.org/abs/2508.06761)
*Jaeyoung Park,Nicholas A. Krall,Giovanni Lapenta,Masayuki Ono*

Main category: physics.plasm-ph

TL;DR: The Polywell fusion concept combines magnetic and electrostatic confinement for compact fusion energy, but challenges in plasma confinement have hindered progress. This study updates the model to address these issues and suggests a path to net energy gain.


<details>
  <summary>Details</summary>
Motivation: To overcome historical limitations in the Polywell fusion concept and achieve net energy gain for practical fusion energy.

Method: Examines previous work, updates the Polywell physics model with experimental data and particle-in-cell simulations, and identifies solutions for confinement losses.

Result: The updated model provides a credible path to achieving net energy gain using deuterium-tritium fuels.

Conclusion: The study renews scientific support for the Polywell concept as a viable and scalable fusion energy solution.

Abstract: The Polywell fusion concept, originally proposed by Robert W. Bussard in
1985, has been investigated for over four decades as a potential solution for
achieving net fusion energy in a compact and economically viable reactor. It
combines two distinct approaches: high-beta magnetic cusp confinement of
electrons using polyhedral coil configurations and electrostatic ion
confinement via a potential well formed by injected electron beams. While the
hybrid nature of the Polywell system offers advantages in plasma stability and
engineering simplicity, previous efforts have been limited by persistent
challenges in achieving sufficient plasma confinement required to generate a
net energy gain. In this study, we examine previous work and identify
limitations of several Polywell embodiments that have historically impeded
progress. We present an updated Polywell physics model incorporating
experimental findings and recent first-principles particle-in-cell simulations.
This updated model outlines a credible path toward overcoming confinement
losses and achieving net energy gain using deuterium-tritium (D-T) fuels. Our
findings provide a renewed scientific basis for the continued development of
the Polywell fusion concept as a practical and scalable approach to fusion
energy.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [71] [Exploiting repeated matrix block structures for more efficient CFD on modern supercomputers](https://arxiv.org/abs/2508.06710)
*Josep Plana-Riu,F. Xavier Trias,Àdel Alsalti-Baldellou,Xavier Álvarez-Farré,Guillem Colomer,Assensi Oliva*

Main category: physics.flu-dyn

TL;DR: The paper introduces a method to improve CFD performance by transforming sparse matrix-vector operations into matrix-matrix operations and using inline mesh-refinement.


<details>
  <summary>Details</summary>
Motivation: Memory-bound sparse matrix-vector operations limit CFD performance on HPC systems.

Method: Transform SpMV to SpMM for higher arithmetic intensity and use inline mesh-refinement to reduce wall-clock time.

Result: Substantial speed-ups, up to 50% in mesh-refinement setups, validated through test cases.

Conclusion: The approach enhances CFD performance by leveraging SpMM and mesh-refinement, offering significant efficiency gains.

Abstract: Computational Fluid Dynamics (CFD) simulations are often constrained by the
memory-bound nature of sparse matrix-vector operations, which eventually limits
performance on modern high-performance computing (HPC) systems. This work
introduces a novel approach to increase arithmetic intensity in CFD by
leveraging repeated matrix block structures. The method transforms the
conventional sparse matrix-vector product (SpMV) into a sparse matrix-matrix
product (SpMM), enabling simultaneous processing of multiple right-hand sides.
This shifts the computation towards a more compute-bound regime by reusing
matrix coefficients. Additionally, an inline mesh-refinement strategy is
proposed: simulations initially run on a coarse mesh to establish a
statistically steady flow, then refine to the target mesh. This reduces the
wall-clock time to reach transition, leading to faster convergence with
equivalent computational cost. The methodology is evaluated using theoretical
performance bounds and validated through three test cases: a turbulent channel
flow, Rayleigh-B\'{e}nard convection, and an industrial airfoil simulation.
Results demonstrate substantial speed-ups - from modest improvements in basic
configurations to over 50% in the mesh-refinement setup - highlighting the
benefits of integrating SpMM across all CFD operators, including divergence,
gradient, and Laplacian.

</details>


### [72] [Gas dynamic equations from Boltzmann to Navier-Stokes scales](https://arxiv.org/abs/2508.07189)
*Zhaoli Guo,Kun Xu,Yajun Zhu*

Main category: physics.flu-dyn

TL;DR: A kinetic framework is proposed to model nonequilibrium gas flows by classifying molecules into collided, free-transport, and transitional types, enabling multiscale analysis and efficient simulations.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of modeling gas flows across multiple regimes where scale separation breaks down.

Method: Classifies molecules into three types based on collision behavior, derives sub-kinetic equations from the Boltzmann equation, and analyzes their asymptotic behaviors.

Result: The framework captures molecular transport dynamics and enables variable-scale modeling, offering potential for efficient numerical simulations.

Conclusion: The framework provides a multiscale approach to gas flow modeling and may contribute insights into Hillbert's sixth problem.

Abstract: Understanding the dynamics of nonequilibrium gas flows spanning multiple flow
regimes is challenging due to the breakdown of scale separation. In this work,
we propose a kinetic framework that captures the transport of molecules under
varying collision behaviors within a given observation timescale $h$. Within
this framework, gas molecules in the system are classified into three types
over the time interval $0\le t<h$, namely, collided molecules that have
experienced collisions with other molecules, free-transport molecules that
encounter no collisions during $[0,h]$, and transitional molecules which
encounter no collisions during $[0, t]$ but collide with other molecules during
$[t,h]$. Then three coupled sub-kinetic equations for different types of
molecules are developed rigorously through the formal solution of the Boltzmann
equation. The asymptotic behaviors of the three sub-kinetic equations are
analyzed, and it is shown that the system presents a framework for describing
the exchange among the molecules with different collision behaviors. Beyond
enabling variable-scale kinetic modeling, this framework can provide a basis
for developing efficient numerical methods for simulating multiscale gas flows.
Importantly, due to its intrinstic mutiscale nature, the proposed framework may
also offer new insights into Hillbert's sixth problem.

</details>


### [73] [An implicit gas-kinetic scheme for internal and external flows](https://arxiv.org/abs/2508.07644)
*Yue Zhang,Xing Ji,Kun Xu*

Main category: physics.flu-dyn

TL;DR: The paper advances the gas-kinetic scheme (GKS) for engineering applications by introducing a rotating coordinate frame, implicit time discretization, and turbulence modeling, demonstrating its accuracy and efficiency in simulations.


<details>
  <summary>Details</summary>
Motivation: GKS has strong theoretical foundations but lacks development for real-world engineering problems compared to traditional CFD methods. This study aims to bridge that gap.

Method: Extended GKS to rotating frames, implemented implicit time discretization with the generalized minimal residual method, and coupled the shear-stress transport turbulence model.

Result: Validated with numerical tests, achieving convergence in 500 steps for a 3-D wing-body flow with 5 million mesh elements.

Conclusion: The work showcases GKS's potential to compete with established CFD solvers in high-Reynolds-number turbulent flows.

Abstract: The gas-kinetic scheme(GKS) is a promising computational fluid dynamics (CFD)
method for solving the Navier-Stokes equations. It is based on the analytical
solution of the BGK equation, which enables accurate and robust simulations.
While GKS has demonstrated excellent properties (e.g., unified treatment of
inviscid and viscous fluxes, inherent adaptive dissipation control), its
application to classical engineering problems, such as aerodynamic flows and
fluid machinery, remains underdeveloped compared to conventional CFD methods.
This study bridges this gap by advancing GKS capabilities for real-world
engineering challenges. First, the GKS is extended to a rotating coordinate
frame, enabling efficient simulations of internal flows in turbomachinery.
Second, the computational inefficiency of explicit GKS is addressed through an
implicit time discretization using the generalized minimal residual method. The
Jacobian matrices for inviscid/viscous fluxes are approximated using the
first-order kinetic flux vector splitting scheme and the thin shear layer
approximation to enhance robustness and computational efficiency further.
Third, the shear-stress transport turbulence model is coupled to expand GKS's
applicability to industrial turbulent flows. Numerical tests, including
internal compressor rotor flow and external flow over a 3-D wingbody, validate
the proposed method's accuracy and efficiency. Via our implicit scheme, the
force coefficients of the 3-D wing-body flow with about five million mesh
elements can converge after 500 steps. This work represents a practical
advancement of GKS, demonstrating its potential to compete with established CFD
solvers in high-Reynolds-number external and internal turbulent flows.

</details>


### [74] [A Lagrangian method for solving the spherical shallow water equations using power diagrams](https://arxiv.org/abs/2508.08129)
*Philip Caplan,Otis Milliken,Toby Pouler,Zeyi Tong,Col McDermott,Sam Millay*

Main category: physics.flu-dyn

TL;DR: A new Lagrangian method using spherical power cells for atmospheric simulations is introduced, showing efficiency and stability without artificial viscosity.


<details>
  <summary>Details</summary>
Motivation: Evaluate if Lagrangian approaches can outperform Eulerian methods in global atmospheric simulations, addressing the smoother solutions issue in prior Lagrangian methods.

Method: Develop a Lagrangian method with spherical power cells, an efficient algorithm for computing these cells, and a semi-discrete optimal transport problem for mass conservation. Uses semi-implicit time stepping.

Result: Spherical Voronoi diagrams of 100 million sites computed in under 2 minutes. The method shows comparable momentum and energy conservation to existing Lagrangian approaches.

Conclusion: The new Lagrangian method is efficient and stable, offering a viable alternative to Eulerian simulations for atmospheric modeling.

Abstract: Numerical simulations of the air in the atmosphere and water in the oceans
are essential for numerical weather prediction. The state-of-the-art for
performing these fluid simulations relies on an Eulerian viewpoint, in which
the fluid domain is discretized into a mesh, and the governing equations
describe the fluid motion as it passes through each cell of the mesh. However,
it is unclear whether a Lagrangian viewpoint, in which the fluid is discretized
by a collection of particles, can outperform Eulerian simulations in global
atmospheric simulations. To date, Lagrangian approaches have shown promise, but
tend to produce smoother solutions. In this work, a new Lagrangian method is
developed to simulate the atmosphere in which particles are represented with
spherical power cells. We introduce an efficient algorithm for computing these
cells which are then used to discretize the spherical shallow water equations.
Mass conservation is enforced by solving a semi-discrete optimal transport
problem and a semi-implicit time stepping procedure is used to advance the
solution in time. We note that, in contrast to previous work, artificial
viscosity is not needed to stabilize the simulation. The performance of the
spherical Voronoi diagram calculation is first assessed, which shows that
spherical Voronoi diagrams of 100 million sites can be computed in under 2
minutes on a single machine. The new simulation method is then evaluated on
standard benchmark test cases, which shows that momentum and energy
conservation of this new method is comparable to the latest Lagrangian approach
for simulating the spherical shallow water equations.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [75] [Short-Range Order and Li$_x$TM$_{4-x}$ Probability Maps for Disordered Rocksalt Cathodes](https://arxiv.org/abs/2508.08112)
*Tzu-chen Liu,Steven B. Torrisi,Chris Wolverton*

Main category: cond-mat.mtrl-sci

TL;DR: The paper investigates how short-range order (SRO) affects Li$_4$ tetrahedron clusters in disordered rocksalt (DRX) cathode materials, proposing strategies to exceed the random limit of Li$_4$ probability.


<details>
  <summary>Details</summary>
Motivation: The study aims to address the lack of systematic investigation into Li$_4$ probability below the random limit in DRX materials and explore fundamental ordering behaviors on the FCC lattice.

Method: The research uses exhaustive Monte Carlo mapping to analyze pair SRO parameters and Li$_x$TM$_{4-x}$ probabilities in a simplified parameter space.

Result: Findings show Li$_4$ probability is controlled by nearest neighbor (NN) pair-wise SRO parameters, which do not simply mirror low-temperature long-range order. Strategies to surpass the random limit are proposed.

Conclusion: The study enhances understanding of FCC lattice ordering behaviors and offers practical strategies to improve Li$_4$ probability in DRX materials.

Abstract: Short-range order (SRO) in the cation-disordered state is a controlling
factor influencing the probability of finding Li$_{4}$ tetrahedron clusters in
disordered rocksalt (DRX) cathode materials. However, the prevalent Li$_4$
probability below the random limit across reported DRX compositions has not
been systematically investigated, active strategies to surpass the random limit
of Li$_4$ probability are lacking, and the fundamental ordering behavior on the
face-centered cubic (FCC) lattice remains insufficiently explored. This
research quantitatively examines pair SRO parameters and Li$_x$TM$_{4-x}$
probabilities via exhaustive Monte Carlo mapping across a simplified subset of
the parameter space. The results indicate that, in the disordered state, the
Li$_4$ probability is governed by the nearest neighbor (NN) pair-wise SRO
parameter, and that these quantities do not necessarily represent a simple
attenuation of their corresponding low-temperature long-range order,
particularly for the important cases of Layered and Spinel-like orderings.
Strategies are proposed to mitigate or even reverse the lithium and transition
metals mixing tendency of NN pair SRO to achieve Li$_4$ probabilities that
exceed the random limit. This study advances the fundamental thermodynamic
understanding of ordering behaviors, which can be generalized to any FCC
system.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [76] [Fast and efficient long-distance quantum state transfer in long-range spin-$\frac{1}{2}$ models](https://arxiv.org/abs/2508.08182)
*F. Faria,C. C. Nelmes,T. J. G. Apollaro,T. P. Spiller,I. D'Amico*

Main category: quant-ph

TL;DR: Quantum state transfer in spin-1/2 chains achieves >99% fidelity with minimal engineering, using on-site fields and modified couplings.


<details>
  <summary>Details</summary>
Motivation: Explore efficient quantum state transfer beyond nearest-neighbor coupling in long spin chains.

Method: Use on-site magnetic fields and symmetrically-modified couplings, optimized via a genetic algorithm, to exploit the Hamiltonian's dispersion relation.

Result: Achieves >99% average transfer fidelity with linear time scaling relative to chain length.

Conclusion: The method is robust for arbitrary next-nearest couplings and scalable to longer-range schemes.

Abstract: Quantum state transfer is investigated beyond the nearest-neighbour coupling
scheme in long spin-$\frac{1}{2}$ linear chains. Exploiting the properties of
the next-nearest neighbour Hamiltonian's dispersion relation, it is shown that
with minimal engineering, i.e., an on-site magnetic field on the two end sites
and only a few symmetrically-modified end inter-site couplings, an average
transfer fidelity above $99\%$ can be achieved. To leading order, the required
time scales linearly with the length of the chain. Such a fast, high-quality
quantum state transfer is based on the ballistic propagation of the wave packet
centred in the linear region of the dispersion relation by means of the on-site
magnetic field. At the same time, the wave packet width, modulated by the
inter-site couplings at the chain ends, whose values are found via a carefully
designed genetic algorithm, is constrained mostly in the linear region of the
dispersion relation. Our coupling scheme is shown to hold for arbitrary values
of the next-nearest inter-site coupling and can be straightforwardly applied to
longer range coupling schemes.

</details>


<div id='nlin.PS'></div>

# nlin.PS [[Back]](#toc)

### [77] [Efficient data-driven regression for reduced-order modeling of spatial pattern formation](https://arxiv.org/abs/2508.06833)
*Alessandro Alla,Rudy Geelen,Hannah Lu*

Main category: nlin.PS

TL;DR: An efficient data-driven regression method for reduced-order models (ROMs) of reaction-diffusion systems, using polynomial forms and POD, improves accuracy with low computational cost.


<details>
  <summary>Details</summary>
Motivation: To create non-intrusive ROMs for pattern-forming systems without needing underlying physical models or governing equations.

Method: Uses polynomial model forms and POD for subspace identification, learning ROMs via least-squares regression from simulation data.

Result: Higher-order surrogate models enhance prediction accuracy while remaining computationally efficient, demonstrated on Schnakenberg and Mimura-Tsujikawa models.

Conclusion: The method offers a flexible, non-intrusive framework for analyzing complex spatio-temporal pattern formation.

Abstract: We present an efficient data-driven regression approach for constructing
reduced-order models (ROMs) of reaction-diffusion systems exhibiting pattern
formation. The ROMs are learned non-intrusively from available training data of
physically accurate numerical simulations. The method can be applied to general
nonlinear systems through the use of polynomial model form, while not requiring
knowledge of the underlying physical model, governing equations, or numerical
solvers. The process of learning ROMs is posed as a low-cost least-squares
problem in a reduced-order subspace identified via Proper Orthogonal
Decomposition (POD). Numerical experiments on classical pattern-forming
systems--including the Schnakenberg and Mimura--Tsujikawa models--demonstrate
that higher-order surrogate models significantly improve prediction accuracy
while maintaining low computational cost. The proposed method provides a
flexible, non-intrusive model reduction framework, well suited for the analysis
of complex spatio-temporal pattern formation phenomena.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [78] [Ergodicity of infinite volume $Φ^4_3$ at high temperature](https://arxiv.org/abs/2508.07776)
*Paweł Duch,Martin Hairer,Jaeyun Yi,Wenhao Zhao*

Main category: math.PR

TL;DR: The paper proves global well-posedness of the infinite-volume Φ⁴₃ dynamic in a weighted Besov space and shows exponential convergence of solutions at high temperatures, establishing the uniqueness of the invariant measure and verifying Osterwalder-Schrader axioms.


<details>
  <summary>Details</summary>
Motivation: To rigorously analyze the infinite-volume Φ⁴₃ dynamic, ensuring well-posedness and characterizing its invariant measure, while verifying fundamental physical axioms.

Method: The study uses weighted Besov spaces for distributions and analyzes solutions driven by the same noise, focusing on high-temperature/small-coupling regimes.

Result: Global well-posedness is proven, solutions converge exponentially, and the invariant measure is unique and satisfies Osterwalder-Schrader axioms (translation, rotation, reflection invariance, and exponential correlation decay).

Conclusion: The infinite-volume Φ⁴₃ dynamic is well-posed, with a unique invariant measure at high temperatures, fulfilling key physical axioms.

Abstract: We consider the infinite volume $\Phi^4_3$ dynamic and show that it is
globally well-posed in a suitable weighted Besov space of distributions. At
high temperatures / small coupling, we furthermore show that the difference
between any two solutions driven by the same realisation of the noise converges
to zero exponentially fast. This allows us to characterise the infinite-volume
$\Phi^4_3$ measure at high temperature as the unique invariant measure of the
dynamic, and to prove that it satisfies all Osterwalder--Schrader axioms,
including invariance under translations, rotations, and reflections, as well as
exponential decay of correlations.

</details>


### [79] [Rearrangements and infimum convolutions](https://arxiv.org/abs/2508.07983)
*Devraj Duggal,James Melbourne,Cyril Roberto*

Main category: math.PR

TL;DR: A general comparison result for inf convolution operators under rearrangement is developed, leading to simplified proofs and new results for Laplace and polar transforms, as well as parabolic PDEs.


<details>
  <summary>Details</summary>
Motivation: To establish a unified framework for comparison results involving rearrangement and inf convolution operators, simplifying existing proofs and extending applications.

Method: Develops a general comparison result for inf convolution operators under rearrangement, then applies it to Laplace and polar transforms and parabolic PDEs.

Result: Derives comparison results for spherically symmetric rearrangement, simplifies proofs for the functional Blaschke Santalo inequality, and obtains a new comparison result for parabolic PDEs.

Conclusion: The framework provides a versatile tool for comparison problems, with applications in transforms and PDEs, while simplifying prior work.

Abstract: We develop a general comparison result for inf convolution operators related
to rearrangement. As a consequence we derive comparison results under
spherically symmetric rearrangement for Laplace and polar transforms. As a by
product we simplify existing proofs related to the functional Blaschke Santalo
inequality of Keith Ball and derive a comparison result for some parabolic PDE.

</details>


<div id='physics.acc-ph'></div>

# physics.acc-ph [[Back]](#toc)

### [80] [Beam-Beam Fields with Full Six-Dimensional Coupling: Theory and Computational Methods](https://arxiv.org/abs/2508.07418)
*Yi-Kai Kan,Derong Xu*

Main category: physics.acc-ph

TL;DR: A generalized framework for calculating beam-beam fields with six-dimensional coupling is presented, with computational techniques and a case study on the EIC electron storage ring.


<details>
  <summary>Details</summary>
Motivation: To address the underestimation of longitudinal fields in the standard slice model for beam-beam kick.

Method: Developed a theoretical framework and computational techniques for evaluating beam-beam fields with full six-dimensional coupling.

Result: The standard slice model underestimates the longitudinal field, and the proposed framework offers improved accuracy.

Conclusion: The framework can enhance simulation models and guide future design studies.

Abstract: This work presents a generalized theoretical framework for calculating
beam-beam fields induced by a Gaussian beam with full six-dimensional coupling.
We also develop computational techniques for evaluating these fields. A case
study based on the Electron-Ion Collider (EIC) electron storage ring
illustrates the practical application of the framework. Our results suggest
that the standard slice model for the beam-beam kick can significantly
underestimate the longitudinal field. The proposed theory may provide a
foundation for developing improved simulation models and guiding future design
studies.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [81] [Best $m$-term trigonometric approximation in weighted Wiener spaces and applications](https://arxiv.org/abs/2508.07336)
*Moritz Moeller,Serhii Stasyuk,Tino Ullrich*

Main category: math.FA

TL;DR: The paper extends recovery bounds for best $m$-term trigonometric approximation in multivariate weighted Wiener spaces, leveraging tools from compressed sensing and embedding classical smoothness spaces.


<details>
  <summary>Details</summary>
Motivation: To improve optimal sampling recovery error bounds in multivariate function spaces by extending existing results.

Method: Uses best $m$-term trigonometric widths, nonlinear recovery algorithms from compressed sensing, and embeddings of classical smoothness spaces into weighted Wiener spaces.

Result: Extended recovery bounds for multivariate weighted Wiener spaces and classical smoothness spaces.

Conclusion: The study advances the understanding of optimal sampling recovery in multivariate function spaces by integrating new and existing tools.

Abstract: In this paper we study best $m$-term trigonometric approximation of functions
belonging to multivariate weighted Wiener spaces. It has {recently been
observed} that best $m$-term trigonometric widths in the uniform and Wiener
norm together with nonlinear recovery algorithms stemming from compressed
sensing serve to control the optimal sampling recovery error in various
relevant spaces of multivariate functions. We use a collection of old and new
tools as well as novel findings to extend these recovery bounds. In addition,
by establishing embeddings of classical smoothness spaces into weighted Wiener
spaces we extend recovery bounds to classical multivariate smoothness spaces.

</details>


### [82] [Analysis of Solow-Swan model with nonlocal fractional derivative operator](https://arxiv.org/abs/2508.06883)
*MO Aibinu,KJ Duffy,S Moyo*

Main category: math.FA

TL;DR: The paper extends the Solow-Swan economic growth model by incorporating fractional calculus to account for memory effects, comparing it with the classical integer-order model.


<details>
  <summary>Details</summary>
Motivation: Traditional Solow-Swan models use integer-order derivatives, which may not fully capture real-world economic memory and hereditary properties.

Method: The study introduces fractional calculus into the Solow-Swan framework to model memory effects and compares capital dynamics between classical and fractional formulations.

Result: The fractional model better captures the influence of past states on capital change, unlike the standard model.

Conclusion: The fractional-order Solow-Swan model provides a more accurate representation of economic growth dynamics by accounting for memory effects.

Abstract: The Solow-Swan equation is a foundational model in the evolution of modern
economic growth theory. It offers key insights into the long-term behaviour of
capital accumulation and output. Since its inception, the model has served as a
cornerstone for understanding macroeconomic dynamics and has inspired a vast
body of subsequent research. However, traditional formulations of the
Solow-Swan model rely on integer-order derivatives, which may not fully capture
the memory and hereditary properties often observed in real-world economic
systems. In this paper, we extend the classical Solow-Swan framework by
incorporating memory effects through the use of fractional calculus. The
fractional model accounts for the influence of past states on the present rate
of capital change, a feature not accommodated in the standard model. We present
a comparative analysis of the capital dynamics under both the classical and
fractional-order formulations of the Solow-Swan equation.

</details>


<div id='physics.bio-ph'></div>

# physics.bio-ph [[Back]](#toc)

### [83] [An RBC-MsUQ Framework for Red Blood Cell Morpho-Mechanics](https://arxiv.org/abs/2508.06852)
*Shuo Wang,Lei Ma,Ling Guo,Xuejin Li,Tao Zhou*

Main category: physics.bio-ph

TL;DR: RBC-MsUQ is a multi-stage uncertainty quantification framework for red blood cells, integrating Bayesian inference and deep learning to reduce uncertainties and improve parameter identification.


<details>
  <summary>Details</summary>
Motivation: Current computational models for RBCs are limited by uncertainties from experimental discrepancies and parameter variability, hindering accurate characterization of morpho-mechanical properties.

Method: The framework uses hierarchical Bayesian inference, microscopic simulations, and deep neural networks for efficient approximation. It has a two-stage process: Stage I constrains geometric and shear modulus parameters, while Stage II identifies full parameters using membrane tests.

Result: Applied to healthy and malaria-infected RBCs, RBC-MsUQ reveals increased stiffness and viscosity in pathological cells, with robust posterior distributions.

Conclusion: RBC-MsUQ effectively mitigates uncertainties through cross-platform data fusion, offering a systematic approach for studying RBC properties and advancing biomedical engineering.

Abstract: Characterizing the morpho-mechanical properties of red blood cells (RBCs) is
crucial for understanding microvascular transport mechanisms and cellular
pathophysiological processes, yet current computational models are constrained
by multi-source uncertainties including cross-platform experimental
discrepancies and parameter identification stochasticity. We present RBC-MsUQ,
a novel multi-stage uncertainty quantification framework tailored for RBCs. It
integrates hierarchical Bayesian inference with diverse experimental datasets,
establishing prior distributions for RBC parameters via microscopic simulations
and literature-derived data. A dynamic annealing technique defines stress-free
baselines, while deep neural network surrogates, optimized through sensitivity
analysis, achieve sub-10$^{-2}$ prediction errors for efficient simulation
approximation. Its two-stage hierarchical inference architecture constrains
geometric and shear modulus parameters using stress-free state and stretching
data in Stage I and enables full-parameter identification via membrane
fluctuation and relaxation tests in Stage II. Applied to healthy and
malaria-infected RBCs, the RBC-MsUQ framework produces statistically robust
posterior distributions, revealing increased stiffness and viscosity in
pathological cells. Quantitative model-experiment validation demonstrates that
RBC-MsUQ effectively mitigates uncertainties through cross-platform data
fusion, overcoming the critical limitations of existing computational
approaches. The RBC-MsUQ framework thus provides a systematic paradigm for
studying RBC properties and advancing cellular mechanics and biomedical
engineering.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [84] [Inversion of Arctic dual-channel sound speed profile based on random airgun signal](https://arxiv.org/abs/2508.07152)
*Jinbao Weng,Yubo Qi,Yanming Yang,Hongtao Wen,Hongtao Zhou,Benqing Chen,Dewei Xu,Ruichao Xue,Caigao Zeng*

Main category: cs.SD

TL;DR: Proposes an inversion method for dual-channel sound speed profiles in the Arctic using refracted normal modes, with fewer parameters and faster speed than previous methods.


<details>
  <summary>Details</summary>
Motivation: Addresses the unique dual-channel sound speed profiles in the Canadian Basin and Chukchi Plateau, aiming for efficient and low-cost inversion.

Method: Uses refracted normal modes, dual-parameter representation, and dispersion structure extraction to invert dual-channel sound speed profiles, including horizontal variations.

Result: Verified effective in Arctic low-frequency long-range acoustic experiments; outperforms previous methods in speed and parameter efficiency.

Conclusion: The method is cost-effective, easy to deploy, and fast, solving inversion for horizontal variation of sound speed profiles.

Abstract: For the unique dual-channel sound speed profiles of the Canadian Basin and
the Chukchi Plateau in the Arctic, based on the propagation characteristics of
refracted normal modes under dual-channel sound speed profiles, an inversion
method using refracted normal modes for dual-channel sound speed profiles is
proposed. This method proposes a dual-parameter representation method for
dual-channel sound speed profiles, tailored to the characteristics of
dual-channel sound speed profiles. A dispersion structure extraction method is
proposed for the dispersion structure characteristics of refracted normal modes
under dual-channel sound speed profiles. Combining the parameter representation
method of sound speed profiles and the dispersion structure extraction method,
an inversion method for dual-channel sound speed profiles is proposed. For the
common horizontal variation of sound speed profiles in long-distance acoustic
propagation, a method for inverting horizontally varying dual-channel sound
speed profiles is proposed. Finally, this article verifies the effectiveness of
the dual-channel sound speed profile inversion method using the Arctic
low-frequency long-range acoustic propagation experiment. Compared with
previous sound speed profile inversion methods, the method proposed in this
article has the advantages of fewer inversion parameters and faster inversion
speed. It can be implemented using only a single hydrophone passively receiving
random air gun signals, and it also solves the inversion problem of horizontal
variation of sound speed profiles. It has significant advantages such as low
cost, easy deployment, and fast computation speed.

</details>


### [85] [Acoustic source depth estimation method based on a single hydrophone in Arctic underwater](https://arxiv.org/abs/2508.07157)
*Jinbao Weng,Yubo Qi,Yanming Yang,Hongtao Wen,Hongtao Zhou,Benqing Chen,Dewei Xu,Ruichao Xue,Caigao Zeng*

Main category: cs.SD

TL;DR: The paper explores depth estimation methods for surface sound sources using normal modes and ray theory, proposing a method based on modal frequency limits and verifying its applicability with experimental data.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of estimating sound source depth in surface layers and deep Arctic seas by leveraging normal mode and ray theory characteristics.

Method: Uses warping transformation to separate modes, matches amplitude and cutoff frequency of normal modes, and analyzes ray arrival structures for depth estimation.

Result: Proposes effective depth estimation methods validated by experimental data, highlighting their applicability and limitations.

Conclusion: The methods based on normal modes and ray theory are viable for sound source depth estimation, with experimental verification supporting their effectiveness.

Abstract: Based on the normal mode and ray theory, this article discusses the
characteristics of surface sound source and reception at the surface layer, and
explores depth estimation methods based on normal modes and rays, and proposes
a depth estimation method based on the upper limit of modal frequency. Data
verification is conducted to discuss the applicability and limitations of
different methods. For the surface refracted normal mode waveguide, modes can
be separated through warping transformation. Based on the characteristics of
normal mode amplitude variation with frequency and number, the sound source
depth can be estimated by matching amplitude information. Based on the spatial
variation characteristics of eigenfunctions with frequency, a sound source
depth estimation method matching the cutoff frequency of normal modes is
proposed. For the deep Arctic sea, the sound ray arrival structure at the
receiving end is obtained through the analysis of deep inversion sound ray
trajectories, and the sound source depth can be estimated by matching the time
difference of ray arrivals. Experimental data is used to verify the sound field
patterns and the effectiveness of the sound source depth estimation method.

</details>


<div id='math.MG'></div>

# math.MG [[Back]](#toc)

### [86] [Structure of Metric $1$-currents: approximation by normal currents and representation results](https://arxiv.org/abs/2508.08017)
*David Bate,Emanuele Caputo,Jakub Takáč,Phoebe Valentine,Pietro Wald*

Main category: math.MG

TL;DR: The paper proves the 1-dimensional flat chain conjecture in complete, quasiconvex metric spaces, showing metric 1-currents can be approximated by normal 1-currents. It introduces a Banach space isomorphism theorem and generalizes representation results for metric 1-currents.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend the understanding of metric 1-currents and their approximations in general metric spaces, dropping previous dimensionality constraints.

Method: The proof uses a new Banach space isomorphism theorem, connecting metric 1-currents to the Arens-Eells space, and a structure theorem for metric 1-currents in Banach spaces.

Result: The main result is the proof of the 1-dimensional flat chain conjecture and a representation theorem for metric 1-currents as integral superpositions of oriented 1-rectifiable sets.

Conclusion: The work generalizes previous results to Banach spaces and provides new tools for analyzing metric 1-currents, with implications for geometric measure theory.

Abstract: We prove the $1$-dimensional flat chain conjecture in any complete and
quasiconvex metric space, namely that metric $1$-currents can be approximated
in mass by normal $1$-currents. The proof relies on a new Banach space
isomorphism theorem, relating metric $1$-currents and their boundaries to the
Arens-Eells space. As a by-product, any metric $1$-current in a complete and
separable metric space can be represented as the integral superposition of
oriented $1$-rectifiable sets, thus dropping a finite dimensionality condition
from previous results of Schioppa [Schioppa Adv. Math. 2016, Schioppa J. Funct.
Anal. 2016]. The connection between the flat chain conjecture and the
representation result is provided by a structure theorem for metric
$1$-currents in Banach spaces, showing that any such current can be realised as
the restriction to a Borel set of a boundaryless normal $1$-current. This
generalizes, to any Banach space, the $1$-dimensional case of a recent result
of Alberti-Marchese in Euclidean spaces [Alberti-Marchese 2023]. The argument
of Alberti-Marchese requires the strict polyhedral approximation theorem of
Federer for normal $1$-currents, which we obtain in Banach spaces.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [87] [Conditional non-linear stability of Kerr-de Sitter spacetimes in the full subextremal range](https://arxiv.org/abs/2508.06620)
*Peter Hintz,Oliver Petersen,András Vasy*

Main category: gr-qc

TL;DR: The paper demonstrates the stability of Kerr-de Sitter black holes in the subextremal range, assuming mode stability, using constraint damping and verifying a subprincipal symbol condition.


<details>
  <summary>Details</summary>
Motivation: To extend the understanding of black hole stability beyond the slowly rotating case, addressing the full subextremal range.

Method: Similar to Hintz and Vasy's approach but includes constraint damping and verification of a subprincipal symbol condition at the trapped set.

Result: Stability of Kerr-de Sitter black holes is proven under the assumption of mode stability.

Conclusion: The work generalizes previous results, providing a framework for stability in the full subextremal range with key technical advancements.

Abstract: We show the stability of Kerr-de Sitter black holes, in the full subextremal
range, as solutions of the vacuum Einstein equation with a positive
cosmological constant under the assumption that mode stability holds for these
spacetimes. The method is similar to the (unconditional) proof in the slowly
rotating case by Hintz and Vasy. The key novelties are the implementation of
constraint damping in the full subextremal range as well as the verification of
a subprincipal symbol condition at the trapped set.

</details>


### [88] [Interior instability of naked singularities of a scalar field](https://arxiv.org/abs/2508.07655)
*Junbin Li*

Main category: gr-qc

TL;DR: The paper demonstrates instability of $k$-self-similar naked singularities in the Einstein-Scalar field system, showing they collapse into black holes under interior and exterior perturbations below a regularity threshold. It also introduces a new approach for analyzing interior instability.


<details>
  <summary>Details</summary>
Motivation: To understand the stability of naked singularities and provide insights into the weak cosmic censorship conjecture for the Einstein-Scalar field system.

Method: Analyzing perturbations (interior and exterior) below a regularity threshold and studying a family of incoming null cones to prove interior instability.

Result: Naked singularities are unstable under perturbations, collapsing into black holes, with a novel approach for interior instability.

Conclusion: The findings support the weak cosmic censorship conjecture and highlight the instability of naked singularities in this model.

Abstract: We show that the $k$-self-similar naked singularity solutions of the
spherically symmetric Einstein--Scalar field system are unstable to black hole
formation under perturbations that are totally supported in the interior
region, in all regularities strictly below the threshold. The instability below
the threshold is also established for exterior perturbations. We also show that
general naked singularity solutions are unstable under interior BV
perturbations, which provides a new insight into understanding the weak cosmic
censorship conjecture for this model. In contrast to all previous results on
the exterior instability of naked singularities (and even trapped surface
formation), where only a single incoming null cone is considered, the novel
approach to proving the interior instability is analyzing a family of incoming
null cones becoming more and more singular.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [89] [Randomized coordinate gradient descent almost surely escapes strict saddle points](https://arxiv.org/abs/2508.07535)
*Ziang Chen,Yingzhou Li,Zihao Li*

Main category: math.OC

TL;DR: Randomized coordinate gradient descent escapes strict saddle points in nonconvex optimization, proven using dynamical systems theory.


<details>
  <summary>Details</summary>
Motivation: To understand and ensure the escape from strict saddle points in nonconvex optimization using randomized coordinate gradient descent.

Method: Formulated as a nonlinear random dynamical system, analyzed using the center-stable manifold theorem.

Result: Iterates almost surely escape strict saddle points under standard assumptions.

Conclusion: The method reliably avoids strict saddle points, enhancing its applicability in nonconvex optimization.

Abstract: We analyze the behavior of randomized coordinate gradient descent for
nonconvex optimization, proving that under standard assumptions, the iterates
almost surely escape strict saddle points. By formulating the method as a
nonlinear random dynamical system and characterizing neighborhoods of critical
points, we establish this result through the center-stable manifold theorem.

</details>


### [90] [Anderson Accelerated Primal-Dual Hybrid Gradient for solving LP](https://arxiv.org/abs/2508.08062)
*Yingxin Zhou,Stefano Cipolla,Phan Tu Vuong*

Main category: math.OC

TL;DR: AA-PDHG and FAA-PDHG improve convergence speed for large-scale LP problems compared to standard PDHG.


<details>
  <summary>Details</summary>
Motivation: Overcome slow convergence of the standard PDHG method for solving LP problems.

Method: Introduce AA-PDHG with global convergence under safeguard, and FAA-PDHG with angle/length filtering to ensure boundedness.

Result: Significant speedups over vanilla PDHG for large-scale LP instances.

Conclusion: AA-PDHG and FAA-PDHG are effective enhancements to PDHG for LP problems.

Abstract: We present the Anderson Accelerated Primal-Dual Hybrid Gradient (AA-PDHG), a
fixed-point-based framework designed to overcome the slow convergence of the
standard PDHG method for the solution of linear programming (LP) problems. We
establish the global convergence of AA-PDHG under a safeguard condition. In
addition, we propose a filtered variant (FAA-PDHG) that applies angle and
length filtering to preserve the uniform boundedness of the coefficient matrix,
a property crucial for guaranteeing convergence. Numerical results show that
both AA-PDHG and FAA-PDHG deliver significant speedups over vanilla PDHG for
large-scale LP instances.

</details>


### [91] [Optimization of a Nonlinear Acoustics -- Structure Interaction Model](https://arxiv.org/abs/2508.07728)
*Barbara Kaltenbacher,Amjad Tuffaha*

Main category: math.OC

TL;DR: The paper addresses a control/shape optimization problem for a nonlinear acoustics-structure interaction model, using the Westervelt and Kirchoff equations, and proves the existence of solutions and characterizes optimal states via adjoint PDEs.


<details>
  <summary>Details</summary>
Motivation: To optimize the interaction between acoustic waves and elastic boundaries by controlling excitation, mechanical forces, and boundary shape, aiming to track desired states.

Method: Uses a quadratic objective functional with three control types: excitation (Neumann data), mechanical (forcing function), and shape (graph function). Derives adjoint PDEs from first-order optimality conditions.

Result: Existence of solutions to the minimization problem is proven, and optimal states are characterized through adjoint PDEs.

Conclusion: The study successfully formulates and solves the optimization problem, providing a framework for controlling acoustics-structure interactions.

Abstract: In this paper, we consider a control/shape optimization problem of a
nonlinear acoustics-structure interaction model of PDEs, whereby acoustic wave
propagation in a chamber is governed by the Westervelt equation, and the motion
of the elastic part of the boundary is governed by a 4th order Kirchoff
equation. We consider a quadratic objective functional capturing the tracking
of prescribed desired states, with three types of controls: 1) An excitation
control represented by prescribed Neumann data for the pressure on the
excitation part of the boundary 2) A mechanical control represented by a
forcing function in the Kirchoff equations and 3) Shape of the excitation part
of the boundary represented by a graph function. Our main result is the
existence of solutions to the minimization problem, and the characterization of
the optimal states through an adjoint system of PDEs derived from the
first-order optimality conditions.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [92] [Giant spin Hall effects and topological surface states in ternary-layered MAX carbides Mn+1AlCn (M= Nb, Ta, n=1, 2, 3)](https://arxiv.org/abs/2508.07061)
*Yanhui Chen,Hong-Yan Lu,Wenjin Yang,Meifeng Liu,Bin Cui,Desheng Liu,Bing Huang,Xi Zuo*

Main category: cond-mat.mes-hall

TL;DR: Study of MAX carbides reveals Dirac-band-crossing features, nontrivial Z2 topology, and giant spin Hall effect, with Ta3AlC2 showing superior charge-to-spin conversion.


<details>
  <summary>Details</summary>
Motivation: To explore electronic structures, band topology, and intrinsic spin Hall effect in layered MAX carbides, focusing on correlation effects.

Method: Systematic study of Mn+1AlCn (M= Nb, Ta, n=1, 2, 3) using electronic structure analysis, including spin-orbit coupling and Hubbard U correction.

Result: Dirac-band-crossing features near EF form nodal lines without SOC; inclusion of SOC gaps these, leading to nontrivial Z2 topology and large spin Hall conductivities (up to ~60% for Ta3AlC2).

Conclusion: Ta3AlC2 is a promising layered Z2 topological metal with high charge-to-spin conversion efficiency.

Abstract: In this work, we report a systematic study of the electronic structures, band
topology, and intrinsic spin Hall effect (SHE) of the layered MAX carbides
Mn+1AlCn (M= Nb, Ta, n=1, 2, 3) and explore the correlation effects on the SHE.
The results show that M3AlC2 and M4AlC3 (M= Nb, Ta) share similar
Dirac-band-crossing features near the Fermi level (EF) and form nodal lines in
the absence of spin-orbit coupling (SOC). When the SOC is included, the Dirac
band crossings are fully gapped, resulting in nontrivial Z2 topological
invariants (1;000) with a pair of surface states on the (001) plane.
Remarkably, the multiple gapped Dirac points contribute to locally strong spin
Berry curvatures, which lead to large spin Hall conductivities and a giant spin
Hall angle up to ~ 60% for Ta3AlC2. Moreover, we also elucidate the impact of
Hubbard U correction on SHC. Our findings indicate that Ta3AlC2 might represent
an intriguing layered Z2 topological metal with superior charge-to-spin
conversion efficiency.

</details>


### [93] [QVNTVS, Open-Source Quantum Well Simulator](https://arxiv.org/abs/2508.07792)
*Barbaros Şair*

Main category: cond-mat.mes-hall

TL;DR: QVNTVS is an open-source simulator for quantum wells, solving the Time-Independent Schrödinger Equation to model energy levels, wavefunctions, and optical properties, outperforming existing tools.


<details>
  <summary>Details</summary>
Motivation: Quantum wells are critical in optoelectronic devices, but existing simulators lack flexibility and open-source solutions for niche problems like electric fields and heterojunctions.

Method: QVNTVS uses the finite-difference method to solve the Time-Independent Schrödinger Equation for various potential profiles, enabling fast and accurate computations.

Result: The simulator's results match analytical calculations and experimental data, validating its accuracy.

Conclusion: QVNTVS provides a versatile, open-source tool for modeling quantum wells, addressing gaps in current simulation capabilities.

Abstract: Quantum Wells (QW) are of great importance in optoelectronic devices such as
LEDs and LASERs, being the emissive layers.Simulating the quantum particles in
different QW topologies like rectangular finite potential wells, multiple
potential wells, and triangular biased potential well heterojunctions enables
faster modeling, theoretical characterization, and more. QVNTVS performs energy
level and wavefunction calculations, recombination probability, transition
energy, and optical emission computations quickly and accurately. Contrasting
with the existing simulators, QVNTVS is an open-source project and can produce
solutions for niche problems like potential wells under an electric field,
heterojunctions, recombination, and transition matrices. QVNTVS simulates QWs
by solving the Time-Independent Schr\"odinger Equation for different potential
profiles in a discretized space using the finite-difference method and computes
the properties of the device using the extracted information from the solution.
The results align with the analytical calculations and the experimental data.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [94] [Linear and nonlinear stability for the Bach flow, I](https://arxiv.org/abs/2508.06633)
*Eric Bahuaud,Christine Guenther,James Isenberg,Rafe Mazzeo*

Main category: math.DG

TL;DR: The paper proves linear stability of a gauge-modified Bach flow on constant curvature manifolds and introduces a higher-order Koiso identity. It also shows nonlinear stability for hyperbolic and near-Poincaré-Einstein spaces, with Part II addressing compact or flat cases.


<details>
  <summary>Details</summary>
Motivation: To analyze the stability of gauge-modified Bach flows on manifolds of constant curvature, extending understanding of geometric flows.

Method: Intricate spectral calculations and introduction of a higher-order Koiso identity to derive stability bounds.

Result: Linear stability proven for constant curvature manifolds; nonlinear stability shown for hyperbolic and near-Poincaré-Einstein spaces.

Conclusion: The work advances stability analysis of Bach flows, with Part II planned for compact and flat cases.

Abstract: In this paper we prove the linear stability of a gauge-modified version of
the Bach flow on any complete manifold (M, h) of constant curvature. This
involves some intricate calculations to obtain spectral bounds, and in
particular introduces a higher order generalization of the well-known Koiso
identity. We also prove nonlinear stability for the Bach flow if (M, h) is
hyperbolic space, and more generally any Poincar\'e-Einstein space sufficiently
close to h. In the forthcoming Part II of this project, we study the nonlinear
stability question if M is either compact or else noncompact and flat, since
those cases require different considerations involving a center manifold.

</details>


<div id='physics.atom-ph'></div>

# physics.atom-ph [[Back]](#toc)

### [95] [Ionization rate vs. laser intensity determined from ion count vs. peak intensity due to neutral gas exposure to an 800 nm ultrashort pulsed laser](https://arxiv.org/abs/2508.07500)
*Edward L. Ruden*

Main category: physics.atom-ph

TL;DR: The paper recalibrates ionization rates for Ar, O₂, and N₂ using inverted TOF spectrometer data and MCP efficiency adjustments.


<details>
  <summary>Details</summary>
Motivation: To accurately determine ionization rates of gases under high laser intensities by addressing calibration issues in prior data.

Method: Numerically invert TOF spectrometer data, recalibrate MCP efficiency for Ar⁺, and use published MCP cathode data for other species.

Result: Recalibrated ionization rates for Ar, O₂, and N₂; O₂ results align with reevaluated multiphoton cross-section data.

Conclusion: The recalibration improves accuracy of ionization rate measurements, particularly for O₂ in the multiphoton regime.

Abstract: The optical cycle-averaged ionization rate of Ar, O$_{2}$, and N$_{2}$ vs.
local instantaneous laser intensity $I$ for linear polarized $800$ nm light is
determined up to approx. $300$ TW/cm$^{2}$ by numerically inverting published
time-of-flight ion spectrometer data. The published Ar$^{+}$ collection
efficiency of the microchannel plate (MCP) at the end of the spectrometer and
its $I_{0}$ scale are recalibrated by fitting it to its high $I_{0}$ solution.
The relative collection efficiencies of the other species are determined by
published MCP cathode data. Results for O$_2$ are consistent with a
reevaluation of published data used to determine its cross section $\sigma_8$
in the multiphoton (low $I$) regime.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [96] [Nonparametric Reaction Coordinate Optimization with Histories: A Framework for Rare Event Dynamics](https://arxiv.org/abs/2508.07326)
*Polina V. Banushkina,Sergei V. Krivov*

Main category: physics.chem-ph

TL;DR: A nonparametric framework optimizes reaction coordinates for rare events in complex systems, validated by protein folding and other applications.


<details>
  <summary>Details</summary>
Motivation: Understanding rare but critical events in complex systems requires accurate reaction coordinates, which current methods struggle with due to irregular or incomplete data.

Method: Introduces a nonparametric RC optimization framework incorporating trajectory histories for robust analysis.

Result: Demonstrates accurate committor estimates, high-resolution free energy profiles, and applicability to diverse systems like protein folding, phase space, ocean models, and clinical data.

Conclusion: The framework enables accurate rare event analysis without exhaustive sampling, offering a general and robust tool for complex systems.

Abstract: Rare but critical events in complex systems, such as protein folding,
chemical reactions, disease progression, and extreme weather or climate
phenomena, are governed by complex, high-dimensional, stochastic dynamics.
Identifying an optimal reaction coordinate (RC) that accurately captures the
progress of these dynamics is crucial for understanding and simulating such
processes. This work introduces a nonparametric RC optimization framework that
incorporates trajectory histories, enabling robust analysis even for irregular
or incomplete data. The power of the method is demonstrated through
increasingly challenging analyses of protein folding dynamics, where it
provides accurate committor estimates that pass a stringent validation test and
yield high-resolution free energy profiles. Its generality is further
illustrated through applications to dynamics in phase space, a conceptual ocean
circulation model, and a longitudinal clinical dataset. These results
demonstrate that rare event dynamics can be accurately characterized without
exhaustive sampling of the configuration space, establishing a general,
flexible, and robust framework for analyzing complex dynamical systems and
longitudinal datasets.

</details>


### [97] [MiqroForge: An Intelligent Workflow Platform for Quantum-Enhanced Computational Chemistry](https://arxiv.org/abs/2508.07583)
*Jianan Wang,Wenbo Guo,Xin Yue,Minjie Xu,Yueqiang Zheng,Jingxiang Dong,Jiarui Hu,Jian Xia,Chuixiong Wu*

Main category: physics.chem-ph

TL;DR: MiqroForge is an intelligent cross-scale platform integrating quantum computing to address multi-scale simulation challenges in computational sciences, leveraging AI and visual interfaces for efficiency and collaboration.


<details>
  <summary>Details</summary>
Motivation: Persistent demands for multi-scale simulations in computational chemistry, materials science, and biology are constrained by simplistic platform designs.

Method: MiqroForge combines AI-driven dynamic resource scheduling with an intuitive visual interface and shared node libraries and data repositories.

Result: The platform lowers entry barriers, optimizes computational efficiency, and fosters collaboration across classical and quantum computational domains.

Conclusion: MiqroForge bridges the gap between practitioners in classical and quantum computational fields, enhancing collaborative development.

Abstract: The connect-fill-run workflow paradigm, widely adopted in mature software
engineering, accelerates collaborative development. However, computational
chemistry, computational materials science, and computational biology face
persistent demands for multi-scale simulations constrained by simplistic
platform designs. We present MiqroForge, an intelligent cross-scale platform
integrating quantum computing capabilities. By combining AI-driven dynamic
resource scheduling with an intuitive visual interface, MiqroForge
significantly lowers entry barriers while optimizing computational efficiency.
The platform fosters a collaborative ecosystem through shared node libraries
and data repositories, thereby bridging practitioners across classical and
quantum computational domains.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [98] [Engineering snags for spatial curvature in weaves: Fabrication, mechanics, and inverse design](https://arxiv.org/abs/2508.06673)
*Guowei Wayne Tu,Evgueni T. Filipov*

Main category: cond-mat.soft

TL;DR: A novel method uses intentional 'snags' in plain weaves to create complex spatial curvature, enabling applications in smart textiles and soft robots.


<details>
  <summary>Details</summary>
Motivation: Traditional weaving struggles with irregular curved surfaces; this work aims to simplify the process using snags.

Method: Introducing snags in dense plain weaves, simulating deformation with a bar & hinge model, and using an evolutionary algorithm for inverse design.

Result: Local snags induce global curvature, scalable with ribbon properties, enabling approximation of arbitrary surfaces.

Conclusion: Snag engineering in plain weaves offers a versatile strategy for customizable wearable devices, soft robots, and architecture.

Abstract: Weaving as an old craft has extensive applications in modern science and
technology such as smart textiles and intelligent soft robots. However, weaving
irregular curved surfaces has been difficult, with prior alternatives requiring
curved ribbons and triaxial weaving patterns. In this work, we present a simple
strategy to achieve complex spatial curvature by purposely introducing 'snags',
a traditionally unwanted textile defect, into dense plain weaves consisting of
straight ribbons assembled in a straightforward biaxial network. We detail the
fabrication methodology where we pull out ribbons of initially smooth two- (2D)
and three-dimensional (3D) plain weaves to form local snags. We show that these
local defects cause global curvatures through the propagation of geometric
frustration. We then use a reduced-order bar & hinge model to simulate the
mechanics-guided deformation of snagged plain weaves, and we investigate how
the curvature scales with system parameters such as the thickness and Young's
modulus of the ribbons. Finally, we introduce an inverse design platform where
an evolutionary algorithm is used to inversely compute the optimal snag
patterns of smooth plain weaves to approximate arbitrary target surfaces
including 2D and 3D woven exoskeletons that fit human legs and elbows,
respectively. Engineering snags in plain weaves as a general strategy can pave
the way for future design of customizable wearable devices, adaptive soft
robots, reconfigurable architecture, and more.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [99] [Structure-Preserving Digital Twins via Conditional Neural Whitney Forms](https://arxiv.org/abs/2508.06981)
*Brooks Kinch,Benjamin Shaffer,Elizabeth Armstrong,Michael Meehan,John Hewson,Nathaniel Trask*

Main category: cs.LG

TL;DR: A framework for real-time digital twins using reduced finite element models with conditional attention mechanisms, ensuring numerical stability and exact conservation laws.


<details>
  <summary>Details</summary>
Motivation: To enable real-time digital twins with accurate predictions on complex geometries, even with sparse data, while preserving numerical well-posedness and conserved quantities.

Method: Uses conditional attention mechanisms within finite element exterior calculus (FEEC) to learn reduced bases and nonlinear conservation laws, supporting real-time calibration and closed-loop inference.

Result: Achieves accurate predictions on benchmarks (e.g., advection diffusion, shock hydrodynamics) with sparse data, real-time inference (~0.1s), and significant speedup (3.1x10^8).

Conclusion: The framework successfully integrates learned models with conventional finite element techniques, enabling efficient and accurate digital twins for complex problems.

Abstract: We present a framework for constructing real-time digital twins based on
structure-preserving reduced finite element models conditioned on a latent
variable Z. The approach uses conditional attention mechanisms to learn both a
reduced finite element basis and a nonlinear conservation law within the
framework of finite element exterior calculus (FEEC). This guarantees numerical
well-posedness and exact preservation of conserved quantities, regardless of
data sparsity or optimization error. The conditioning mechanism supports
real-time calibration to parametric variables, allowing the construction of
digital twins which support closed loop inference and calibration to sensor
data. The framework interfaces with conventional finite element machinery in a
non-invasive manner, allowing treatment of complex geometries and integration
of learned models with conventional finite element techniques.
  Benchmarks include advection diffusion, shock hydrodynamics, electrostatics,
and a complex battery thermal runaway problem. The method achieves accurate
predictions on complex geometries with sparse data (25 LES simulations),
including capturing the transition to turbulence and achieving real-time
inference ~0.1s with a speedup of 3.1x10^8 relative to LES. An open-source
implementation is available on GitHub.

</details>


### [100] [Discovery Learning accelerates battery design evaluation](https://arxiv.org/abs/2508.06985)
*Jiawei Zhang,Yifei Zhang,Baozhao Yi,Yao Ren,Qi Jiao,Hanyu Bai,Weiran Jiang,Ziyou Song*

Main category: cs.LG

TL;DR: Discovery Learning (DL) integrates active, physics-guided, and zero-shot learning to predict battery lifetimes efficiently, reducing prototyping needs and saving significant time and energy.


<details>
  <summary>Details</summary>
Motivation: Battery R&D is bottlenecked by high costs and time for prototyping and testing. Existing methods lack efficiency for rapid feedback in design.

Method: DL combines active learning, physics-guided learning, and zero-shot learning, leveraging historical data to predict lifetimes without additional labeling.

Result: DL achieves 7.2% test error in predicting cycle life, saving 98% time and 95% energy compared to industrial practices.

Conclusion: DL accelerates battery innovation by efficiently using historical data, advancing data-driven modeling for scientific discovery.

Abstract: Fast and reliable validation of novel designs in complex physical systems
such as batteries is critical to accelerating technological innovation.
However, battery research and development remain bottlenecked by the
prohibitively high time and energy costs required to evaluate numerous new
design candidates, particularly in battery prototyping and life testing.
Despite recent progress in data-driven battery lifetime prediction, existing
methods require labeled data of target designs to improve accuracy and cannot
make reliable predictions until after prototyping, thus falling far short of
the efficiency needed to enable rapid feedback for battery design. Here, we
introduce Discovery Learning (DL), a scientific machine-learning paradigm that
integrates active learning, physics-guided learning, and zero-shot learning
into a human-like reasoning loop, drawing inspiration from learning theories in
educational psychology. DL can learn from historical battery designs and
actively reduce the need for prototyping, thus enabling rapid lifetime
evaluation for unobserved material-design combinations without requiring
additional data labeling. To test DL, we present 123 industrial-grade
large-format lithium-ion pouch cells, spanning eight material-design
combinations and diverse cycling protocols. Trained solely on public datasets
of small-capacity cylindrical cells, DL achieves 7.2% test error in predicting
the average cycle life under unknown device variability. This results in
savings of 98% in time and 95% in energy compared to industrial practices. This
work highlights the potential of uncovering insights from historical designs to
inform and accelerate the development of next-generation battery technologies.
DL represents a key advance toward efficient data-driven modeling and helps
realize the promise of machine learning for accelerating scientific discovery
and engineering innovation.

</details>


### [101] [Fractal Language Modelling by Universal Sequence Maps (USM)](https://arxiv.org/abs/2508.06641)
*Jonas S Almeida,Daniel E Russ,Susana Vinga,Ines Duarte,Lee Mason,Praphulla Bhawsar,Aaron Ge,Arlindo Oliveira,Jeya Balaji Balasubramanian*

Main category: cs.LG

TL;DR: The paper explores Universal Sequence Maps (USM) for bijective fractal encoding of symbolic sequences, resolving seeding biases and revealing USM's efficiency as a numeric process.


<details>
  <summary>Details</summary>
Motivation: Interest in encoding symbolic sequences numerically for contextual retention, especially with Transformer-based models like ChatGPT.

Method: USM uses iterated forward and backward Chaos Game Representations (CGR) projected into the frequency domain (FCGR), enabling Chebyshev distance and k-mer frequency computation.

Result: Resolved seeding biases, reconciled numeric positioning with sequence identity, and uncovered USM's steady-state convergence. Demonstrated with genomic sequences.

Conclusion: USM is efficient and applicable to alphabets of any cardinality, with genomic sequences as a convenient example.

Abstract: Motivation: With the advent of Language Models using Transformers,
popularized by ChatGPT, there is a renewed interest in exploring encoding
procedures that numerically represent symbolic sequences at multiple scales and
embedding dimensions. The challenge that encoding addresses is the need for
mechanisms that uniquely retain contextual information about the succession of
individual symbols, which can then be modeled by nonlinear formulations such as
neural networks.
  Context: Universal Sequence Maps(USM) are iterated functions that bijectively
encode symbolic sequences onto embedded numerical spaces. USM is composed of
two Chaos Game Representations (CGR), iterated forwardly and backwardly, that
can be projected into the frequency domain (FCGR). The corresponding USM
coordinates can be used to compute a Chebyshev distance metric as well as k-mer
frequencies, without having to recompute the embedded numeric coordinates, and,
paradoxically, allowing for non-integers values of k.
  Results: This report advances the bijective fractal encoding by Universal
Sequence Maps (USM) by resolving seeding biases affecting the iterated process.
The resolution had two results, the first expected, the second an intriguing
outcome: 1) full reconciliation of numeric positioning with sequence identity;
and 2) uncovering the nature of USM as an efficient numeric process converging
towards a steady state sequence embedding solution. We illustrate these results
for genomic sequences because of the convenience of a planar representation
defined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless,
the application to alphabet of arbitrary cardinality was found to be
straightforward.

</details>


### [102] [SGD Convergence under Stepsize Shrinkage in Low-Precision Training](https://arxiv.org/abs/2508.07142)
*Vincent-Daniel Yun*

Main category: cs.LG

TL;DR: The paper analyzes the impact of low-precision training on SGD convergence, showing it slows training and increases error due to gradient shrinkage and quantization noise.


<details>
  <summary>Details</summary>
Motivation: To understand how gradient quantization affects SGD convergence, as low-precision training is crucial for reducing computational costs in large-scale deep learning.

Method: Models gradient quantization as shrinkage and additive noise, analyzing SGD convergence under smoothness and bounded-variance assumptions.

Result: Low-precision SGD converges but slower, with an increased asymptotic error floor due to quantization noise.

Conclusion: Gradient shrinkage and noise from low-precision training degrade SGD performance, though convergence is still achievable.

Abstract: Low-precision training has become essential for reducing the computational
and memory costs of large-scale deep learning. However, quantization of
gradients introduces both magnitude shrinkage and additive noise, which can
alter the convergence behavior of stochastic gradient descent (SGD). In this
work, we study the convergence of SGD under a gradient shrinkage model, where
each stochastic gradient is scaled by a factor $q_k \in (0,1]$ and perturbed by
zero-mean quantization noise. We show that this shrinkage is equivalent to
replacing the nominal stepsize $\mu_k$ with an effective stepsize $\mu_k q_k$,
which slows convergence when $q_{\min} < 1$. Under standard smoothness and
bounded-variance assumptions, we prove that low-precision SGD still converges,
but at a reduced rate determined by $q_{\min}$, and with an increased
asymptotic error floor due to quantization noise. We theoretically analyze how
reduced numerical precision slows down training by modeling it as gradient
shrinkage in the standard SGD convergence framework.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [103] [Enhancing cluster synchronization in phase-lagged multilayer networks](https://arxiv.org/abs/2508.06502)
*Abhijit Mondal,Pitambar Khanra,Subrata Ghosh,Prosenjit Kundu,Chittaranjan Hens,Pinaki Pal*

Main category: nlin.CD

TL;DR: The study explores how natural frequency distributions affect cluster synchronization in multilayer networks with phase-lag, finding that degree-correlated frequencies (deg-deg) enhance stability.


<details>
  <summary>Details</summary>
Motivation: Address challenges of cluster synchronization in phase-lag networks by investigating the role of frequency distributions.

Method: Use the Sakaguchi-Kuramoto model to analyze four frequency distributions (uni-uni, deg-uni, uni-deg, deg-deg) in two network architectures. Validate stability with transverse Lyapunov exponents (TLEs).

Result: Deg-deg distribution outperforms others, enabling robust synchronization even at high phase-lag. TLEs confirm broader synchronization regimes.

Conclusion: Degree-correlated frequencies counteract phase-lag effects, offering a design framework for resilient multilayer systems like power grids or biological networks.

Abstract: Cluster synchronization in multilayer networks of phase oscillators with
phase-lag poses significant challenges due to the destabilizing effects of
delayed interactions. Leveraging the Sakaguchi-Kuramoto model, this study
addresses these challenges by systematically exploring the role of natural
frequency distributions in sustaining cluster synchronization under high
phase-lag conditions. We focus on four distributions: uniform (uni-uni),
partially degree-correlated (deg-uni, uni-deg), and fully degree-correlated
(deg-deg), where oscillators' intrinsic frequencies align with their network
connectivity. Through numerical and analytical investigations, we demonstrate
that the deg-deg distribution, where both layers employ degree-matched
frequencies, remarkably enhances synchronization stability, outperforming other
configurations. We analyze two distinct network architectures: one composed
entirely of nontrivial clusters and another combining trivial and nontrivial
clusters. Results reveal that structural heterogeneity encoded in the deg-deg
coupling counteracts phase-lag-induced desynchronization, enabling robust
cluster synchronization even at large phase-lag values. Stability is rigorously
validated via transverse Lyapunov exponents (TLEs), which confirm that deg-deg
networks exhibit broader synchronization regimes compared to uniform or
partially correlated systems. These findings provide critical insights into the
interplay between topological heterogeneity and dynamical resilience, offering
a framework for designing robust multilayer systems from delay-tolerant power
grids to adaptive biological networks, where synchronization under phase-lag is
paramount.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [104] [A Registration-Based Star-Shape Segmentation Model and Fast Algorithms](https://arxiv.org/abs/2508.07721)
*Daoping Zhang,Xue-Cheng Tai,Lok Ming Lui*

Main category: cs.CV

TL;DR: Proposes a star-shape segmentation model using registration framework and level set representation, enabling full/partial segmentation with single/multiple centers and landmark constraints.


<details>
  <summary>Details</summary>
Motivation: Address challenges in accurate image segmentation due to occlusions, obscurities, or noise by leveraging star-shape priors.

Method: Combines level set representation with registration framework, imposes constraints on deformed level set function, and uses alternating direction method of multipliers.

Result: Demonstrates efficacy in achieving accurate star-shape segmentation on synthetic and real images.

Conclusion: The proposed model effectively handles star-shape segmentation with flexibility for full/partial shapes and landmark constraints.

Abstract: Image segmentation plays a crucial role in extracting objects of interest and
identifying their boundaries within an image. However, accurate segmentation
becomes challenging when dealing with occlusions, obscurities, or noise in
corrupted images. To tackle this challenge, prior information is often
utilized, with recent attention on star-shape priors. In this paper, we propose
a star-shape segmentation model based on the registration framework. By
combining the level set representation with the registration framework and
imposing constraints on the deformed level set function, our model enables both
full and partial star-shape segmentation, accommodating single or multiple
centers. Additionally, our approach allows for the enforcement of identified
boundaries to pass through specified landmark locations. We tackle the proposed
models using the alternating direction method of multipliers. Through numerical
experiments conducted on synthetic and real images, we demonstrate the efficacy
of our approach in achieving accurate star-shape segmentation.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [105] [Applying the Spectral Method for Modeling Linear Filters: Butterworth, Linkwitz-Riley, and Chebyshev filters](https://arxiv.org/abs/2508.07206)
*Konstantin A. Rybakov,Egor D. Shermatov*

Main category: eess.SP

TL;DR: A new technique for modeling linear filters using spectral forms and non-stationary transfer functions is proposed and tested on common filter types.


<details>
  <summary>Details</summary>
Motivation: To improve computer modeling of linear filters by leveraging spectral descriptions and orthogonal expansions for accurate continuous-time output signal representation.

Method: Input and output signals are represented as orthogonal expansions, and filters are described by two-dimensional non-stationary transfer functions.

Result: Successfully tested on Butterworth, Linkwitz-Riley, and Chebyshev filters of varying orders.

Conclusion: The technique effectively models output signals in continuous time, demonstrating its applicability to common filter types.

Abstract: This paper proposes a new technique for computer modeling linear filters
based on the spectral form of mathematical description of linear systems. It
assumes that input and output signals of the filter are represented as
orthogonal expansions, while filters themselves are described by
two-dimensional non-stationary transfer functions. This technique allows one to
model the output signal in continuous time, and it is successfully tested on
the Butterworth, Linkwitz-Riley, and Chebyshev filters with different orders.

</details>
