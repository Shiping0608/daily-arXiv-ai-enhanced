<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 9]
- [math.AP](#math.AP) [Total: 13]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 4]
- [math.DG](#math.DG) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [physics.med-ph](#physics.med-ph) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [math.PR](#math.PR) [Total: 1]
- [math.FA](#math.FA) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Efficient Computation of Dominant Eigenvalues Using Adaptive Block Lanczos with Chebyshev Filtering](https://arxiv.org/abs/2508.08495)
*M. El Guide,K. Jbilou,K. Lachhab*

Main category: math.NA

TL;DR: An efficient method for computing dominant eigenvalues of large nonsymmetric matrices using adaptive block Lanczos and Chebyshev filtering.


<details>
  <summary>Details</summary>
Motivation: To improve numerical stability and spectral separation in eigenvalue computations for large nonsymmetric matrices.

Method: Combines Adaptive Block Lanczos (ABLE) with SVD-based stabilization and Chebyshev polynomial filtering.

Result: Numerical experiments show the ABLE Chebyshev algorithm is effective for dense and sparse matrices.

Conclusion: The proposed method enhances stability and accuracy in eigenvalue computations.

Abstract: We present an efficient method for computing dominant eigenvalues of large,
nonsymmetric, diagonalizable matrices based on an adaptive block Lanczos
algorithm combined with Chebyshev polynomial filtering. The proposed approach
improves numerical stability through two key components: (i) the Adaptive Block
Lanczos (ABLE) method, which maintains biorthogonality using SVD based
stabilization, and (ii) Chebyshev filtering, which enhances spectral separation
via iterative polynomial filtering. Numerical experiments on dense and sparse
test problems confirm the effectiveness of the ABLE Chebyshev algorithm.

</details>


### [2] [Fast adaptive tubal rank-revealing algorithm for t-product based tensor approximation](https://arxiv.org/abs/2508.08557)
*Qiaohua Liu,Jiehui Gu*

Main category: math.NA

TL;DR: The paper introduces an adaptive randomized algorithm for tubal rank revelation in tensors, avoiding prior rank estimation and reducing computational cost of t-SVD.


<details>
  <summary>Details</summary>
Motivation: To address the computational burden of tensor singular value decomposition (t-SVD) in low tubal-rank approximations.

Method: An adaptive randomized algorithm selectively captures principal information from frontal slices in the Fourier domain using a threshold, without prior rank estimation.

Result: The method provides efficient low tubal-rank approximations with theoretical guarantees and performs well in image processing and background modeling.

Conclusion: The proposed algorithm is effective for tensor approximation, offering computational efficiency and practical utility in real-world tasks.

Abstract: Color images and video sequences can be modeled as three-way tensors, which
admit low tubal-rank approximations via convex surrogate minimization. This
optimization problem is efficiently addressed by tensor singular value
thresholding (t-SVT). To mitigate the computational burden of tensor singular
value decomposition (t-SVD) in each iteration, this paper introduces an
adaptive randomized algorithm for tubal rank revelation in data tensors
\(\mathcal{A}\). Our method selectively captures the principal information from
frontal slices in the Fourier domain using a predefined threshold, obviating
the need for priori tubal-rank and Fourier-domain singular values estimations
while providing an explicit tensor approximation. Leveraging optimality results
from matrix randomized SVD, we establish theoretical guarantees demonstrating
that the proposed algorithm computes low tubal-rank approximations within
constants dependent on data dimensions and the Fourier-domain singular value
gap. Empirical evaluations validate its efficacy in image processing and
background modeling tasks.

</details>


### [3] [Efficient Function Approximation Under Heteroskedastic Noise](https://arxiv.org/abs/2508.08683)
*Yuji Nakatsukasa,Yifu Zhang*

Main category: math.NA

TL;DR: HeteroChebtrunc, an algorithm for approximating functions with heteroskedastic noise, achieves tighter error bounds and runs efficiently in $O(N+\hat{N}\log \hat{N})$ operations.


<details>
  <summary>Details</summary>
Motivation: Existing methods lack efficient $O(N\log N)$ algorithms for function approximation under heteroskedastic noise.

Method: Adapts NoisyChebtrunc using high-dimensional probability techniques to handle heteroskedastic noise.

Result: Tighter infinity-norm error bound under heteroskedastic noise; also derives a non-asymptotic error bound for sample variance estimation.

Conclusion: HeteroChebtrunc improves uniform error and efficiency, with broader implications for variance estimation.

Abstract: Approximating a function $f(x)$ on $[-1,1]$ based on $N+1$ samples is a
classical problem in numerical analysis. If the samples come with
heteroskedastic noise depending on $x$ of variance $\sigma(x)^2$, an $O(N\log
N)$ algorithm for this problem has not yet been found in the current
literature. In this paper, we propose a method called HeteroChebtrunc, adapted
from an algorithm named NoisyChebtrunc. Using techniques in high-dimensional
probability, we show that with high probability, HeteroChebtrunc achieves a
tighter infinity-norm error bound than NoisyChebtrunc under heteroskedastic
noise. This algorithm runs in $O(N+\hat{N}\log \hat{N})$ operations, where
$\hat{N}\ll N$ is a chosen parameter. While investigating the properties of
HeteroChebtrunc, we also derive a high-probability non-asymptotic relative
error bound on the sample variance estimator for subgaussian variables, which
is potentially another result of broader interest. We provide numerical
experiments to demonstrate the improved uniform error of our algorithm.

</details>


### [4] [Solving Approximation Tasks with Greedy Deep Kernel Methods](https://arxiv.org/abs/2508.08759)
*Marian Klink,Tobias Ehring,Robin Herkert,Robin Lautenschlager,Dominik Göddeke,Bernard Haasdonk*

Main category: math.NA

TL;DR: The paper introduces deep kernel greedy models, combining multilayer kernel structures with greedy techniques for improved function approximation and surrogate modeling.


<details>
  <summary>Details</summary>
Motivation: To enhance the expressiveness and adaptability of kernel methods by leveraging deep, multilayer structures inspired by deep neural networks.

Method: Proposes deep kernels with alternating linear kernel layers and optimizable kernel activation function layers, pretrained using a tailored optimization objective.

Result: Deep kernels outperform standard kernels and neural networks in approximation accuracy, demonstrated through numerical investigations and applications.

Conclusion: Deep kernel greedy models offer superior approximation capabilities and adaptability, validated by practical applications in reactive flow and differential equations.

Abstract: Kernel methods are versatile tools for function approximation and surrogate
modeling. In particular, greedy techniques offer computational efficiency and
reliability through inherent sparsity and provable convergence. Inspired by the
success of deep neural networks and structured deep kernel networks, we
consider deep, multilayer kernels for greedy approximation. This multilayer
structure, consisting of linear kernel layers and optimizable kernel activation
function layers in an alternating fashion, increases the expressiveness of the
kernels and thus of the resulting approximants. Compared to standard kernels,
deep kernels are able to adapt kernel intrinsic shape parameters automatically,
incorporate transformations of the input space and induce a data-dependent
reproducing kernel Hilbert space. For this, deep kernels need to be pretrained
using a specifically tailored optimization objective. In this work, we not only
introduce deep kernel greedy models, but also present numerical investigations
and comparisons with neural networks, which clearly show the advantages in
terms of approximation accuracies. As applications we consider the
approximation of model problems, the prediction of breakthrough curves for
reactive flow through porous media and the approximation of solutions for
parametrized ordinary differential equation systems.

</details>


### [5] [A Parareal Algorithm with Spectral Coarse Solver](https://arxiv.org/abs/2508.08873)
*Martin J. Gander,Mario Ohlberger,Stephan Rave*

Main category: math.NA

TL;DR: A new Parareal algorithm uses localized reduced basis methods and randomized SVDs for parallel coarse solver construction, outperforming traditional methods and increasing parallelism.


<details>
  <summary>Details</summary>
Motivation: To improve the efficiency and parallelism of Parareal algorithms by leveraging spectral approximations of transfer operators.

Method: Uses localized reduced basis methods and randomized SVDs to construct coarse solvers from spectral approximations of transfer operators, computed in parallel.

Result: Demonstrates superior performance over traditional Parareal methods and enables increased parallelism by reducing global iterations.

Conclusion: The proposed method enhances Parareal algorithms by improving efficiency and scalability through parallel spectral approximations.

Abstract: We consider a new class of Parareal algorithms, which use ideas from
localized reduced basis methods to construct the coarse solver from spectral
approximations of the transfer operators mapping initial values for a given
time interval to the solution at the end of the interval. By leveraging
randomized singular value decompositions, these spectral approximations are
obtained embarrassingly parallel by computing local fine solutions for random
initial values. We show a priori and a posteriori error bounds in terms of the
computed singular values of the transfer operators. Our numerical experiments
demonstrate that our approach can significantly outperform Parareal with
single-step coarse solvers. At the same time, it permits to further increase
parallelism in Parareal by trading global iterations for a larger number of
independent local solves.

</details>


### [6] [Provably positivity-preserving, globally divergence-free central DG methods for ideal MHD system](https://arxiv.org/abs/2508.08913)
*Ruifang Yan,Huihui Cao,Kailiang Wu*

Main category: math.NA

TL;DR: The paper introduces PosDiv-CDG, a high-order numerical method preserving positivity and divergence-free conditions in multiple dimensions, resolving incompatibility in CDG frameworks.


<details>
  <summary>Details</summary>
Motivation: To address the structural incompatibility between positivity-preserving limiters and global divergence-free enforcement in CDG methods.

Method: Combines a novel positivity-limiting strategy, modified dissipation, and an auxiliary magnetic field evolution equation, using geometric quasi-linearization (GQL) for proofs.

Result: Proves positivity preservation under CFL conditions and demonstrates robustness in extreme conditions like high Mach number MHD jets.

Conclusion: PosDiv-CDG successfully preserves positivity and divergence-free properties while maintaining high-order accuracy and suppressing oscillations.

Abstract: This paper proposes a numerical method, termed PosDiv-CDG, that provably
preserves both positivity and the globally divergence-free (DF) condition at
arbitrarily high order in multiple dimensions. It resolves the fundamental
structural incompatibility between standard positivity-preserving limiters and
global DF enforcement in the central discontinuous Galerkin (CDG) framework.
The method integrates a novel positivity-limiting strategy, a modified
dissipation mechanism guided by convex decomposition, and an auxiliary
evolution equation for the magnetic field, which are designed based on rigorous
theoretical analysis. Notably, we provide a rigorous proof of positivity
preservation for the updated cell averages under an explicit CFL-type
condition. The proof leverages the geometric quasi-linearization (GQL)
technique, which reformulates the nonlinear positivity constraint into an
equivalent linear form. This enables the derivation of flux-based inequalities
and technical estimates under the global DF constraint. To suppress nonphysical
oscillations near shocks, we develop a compact, non-intrusive
convex-oscillation-suppressing (COS) procedure based on the entropy function.
The COS process acts only on non-magnetic variables, avoids costly
characteristic decomposition, and maintains both the globally DF property and
high-order accuracy. Several challenging experiments -- including low
plasma-beta MHD jets with Mach numbers up to 1,000,000 -- demonstrate the
proposed method robustness, high-order accuracy, non-oscillatory behavior, and
its ability to preserve both positivity and globally DF structures under
extreme conditions.

</details>


### [7] [An effective implementation of high-order compact gas-kinetic scheme on structured meshes for compressible flows](https://arxiv.org/abs/2508.08965)
*Yaqing Yang,Fengxiang Zhao,Kun Xu*

Main category: math.NA

TL;DR: A fifth-order compact gas-kinetic scheme is developed for high-resolution compressible flow simulations, using a novel reconstruction method for accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: To improve resolution and efficiency in simulating compressible flows on structured meshes, especially for non-orthogonal cases.

Method: Uses a fifth-order compact reconstruction with line-averaged derivatives, a unified polynomial form, and adaptive nonlinear switching for robustness. Implemented with multi-GPU parallelization.

Result: Validated through numerical tests, showing high accuracy, resolution, and robustness across subsonic to supersonic turbulence.

Conclusion: The scheme achieves superior performance in accuracy and efficiency, suitable for large-scale applications.

Abstract: A novel fifth-order compact gas-kinetic scheme is developed for
high-resolution simulation of compressible flows on structured meshes. Its
accuracy relies on a new multidimensional fifth-order compact reconstruction
that uses line-averaged derivatives to introduce additional degrees of freedom,
enabling a compact stencil with superior resolution. For non-orthogonal meshes,
reconstruction is performed on a standard reference cell in a transformed
computational space. This approach provides a unified polynomial form,
significantly reducing memory usage and computational cost while simplifying
implementation compared to direct multi-dimensional or dimension-by-dimension
methods. A nonlinear adaptive method ensures high accuracy and robustness by
smoothly transitioning from the high-order linear scheme in smooth regions to a
second-order scheme at discontinuities. The method is implemented with
multi-GPU parallelization using CUDA and MPI for large-scale applications.
Comprehensive numerical tests, from subsonic to supersonic turbulence, validate
the scheme's high accuracy, resolution and excellent robustness.

</details>


### [8] [Optimality of adaptive $H(\operatorname{div}\operatorname{div})$ mixed finite element methods for the Kirchhoff-Love plate bending problem](https://arxiv.org/abs/2508.09008)
*Jun Hu,Rui Ma,Min Zhang*

Main category: math.NA

TL;DR: The paper introduces a residual-based error analysis for a mixed finite element method for plate bending, ensuring optimal adaptive algorithm performance.


<details>
  <summary>Details</summary>
Motivation: To address the Kirchhoff-Love plate bending problem with mixed boundary conditions reliably and efficiently.

Method: Constructs boundary-condition-preserving complexes and extends the discrete symmetric $H(\operatorname{div}\operatorname{div})$ space for nestedness.

Result: Numerical examples confirm the error estimator's effectiveness and optimal convergence under adaptive refinements.

Conclusion: The proposed method is effective and achieves optimal convergence in adaptive settings.

Abstract: This paper presents a reliable and efficient residual-based a posteriori
error analysis for the symmetric $H(\operatorname{div}\operatorname{div})$
mixed finite element method for the Kirchhoff-Love plate bending problem with
mixed boundary conditions. The key ingredient lies in the construction of
boundary-condition-preserving complexes at both continuous and discrete levels.
Additionally, the discrete symmetric $H(\operatorname{div}\operatorname{div})$
space is extended to ensure nestedness, which leads to optimality for the
adaptive algorithm. Numerical examples confirm the effectiveness of the a
posteriori error estimator and demonstrate the optimal convergence rate under
adaptive refinements.

</details>


### [9] [Weighted Proper Orthogonal Decomposition for High-Dimensional Optimization](https://arxiv.org/abs/2508.09084)
*Sebastiaan P. C. van Schie,Boris Kramer,John T. Hwang*

Main category: math.NA

TL;DR: Weighted POD improves model reduction by dynamically updating snapshot weights, enhancing accuracy and efficiency without offline training.


<details>
  <summary>Details</summary>
Motivation: Standard POD lacks parametric adaptability, leading to inefficiencies and inaccuracies in model reduction.

Method: Assigns and updates weights to snapshot matrix columns, derives an error bound, and efficiently computes reduced basis.

Result: Weighted POD achieves significantly smaller errors than regular POD and Grassmann interpolation, with comparable computational costs.

Conclusion: Weighted POD offers a robust, adaptive, and efficient alternative for model reduction in parametric and optimization contexts.

Abstract: While proper orthogonal decomposition (POD) is widely used for model
reduction, its standard form does not take into account any parametric model
structure. Extensions to POD have been proposed to address this, but these
either require large amounts of solution data, lack online adaptivity, or have
limited approximation accuracy. We circumvent these limitations by instead
assigning weights to the snapshot matrix columns, and updating these whenever
the model is evaluated at a new point in the parameter space. We derive an a
posteriori error bound that depends on these snapshot weights, show how these
weights can be chosen to tighten the error bound, and present an algorithm to
compute the corresponding reduced basis efficiently. We show how this weighted
POD approach can be used to naturally generalize the calculation of reduced
basis derivatives to situations with multidimensional parameter spaces and
snapshots at multiple locations in the parameter space. Lastly, we cover how
these approaches can be implemented within an optimization algorithm, without
the need for an offline training phase. The proposed weighted POD methods with
and without reduced basis derivatives are applied to a gradient-based shell
thickness optimization problem with 105 design parameters and a time-dependent
partial differential equation. The numerical solutions obtained for this
problem attain errors that are several orders of magnitude smaller when using
weighted POD than those computed with regular POD and Grassmann manifold
interpolation, while having comparable wall times per query and requiring fewer
high-dimensional model snapshots to reach an optimal solution.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [10] [Eigenvalue falls in thin broken quantum strips](https://arxiv.org/abs/2508.08403)
*Lucas Chesnel,Sergei A. Nazarov*

Main category: math.AP

TL;DR: The paper studies the spectrum of the Dirichlet Laplacian in thin broken strips with angle α, focusing on eigenvalue behavior as ε→0 and its dependence on α.


<details>
  <summary>Details</summary>
Motivation: To understand how eigenvalues of the Laplace operator with mixed boundary conditions behave in thin trapezoids, especially their dependence on the angle α.

Method: Analyzes spectral problems using symmetries, derives asymptotic expansions for eigenvalues and eigenfunctions as ε→0, and investigates eigenvalue behavior at specific angles α⋆k.

Result: For small ε>0, eigenvalues dive below π²/ε² at certain angles α⋆k, with the phenomenon being milder at α⋆0=0.

Conclusion: The study characterizes the diving behavior of eigenvalues at specific angles, providing insights into spectral properties in thin trapezoids.

Abstract: We are interesting in the spectrum of the Dirichlet Laplacian in thin broken
strips with angle $\alpha$. Playing with symmetries, this leads us to
investigate spectral problems for the Laplace operator with mixed boundary
conditions in thin trapezoids characterized by a parameter $\varepsilon$ small.
We give an asymptotic expansion of the first eigenvalues and corresponding
eigenfunctions as $\varepsilon$ tends to zero. The new point in this work is to
study the dependence with respect to $\alpha$. We show that for a small fixed
$\varepsilon>0$, at certain particular angles $\alpha^\star_k$, $k=0,1,\dots$,
that we characterize, an eigenvalue dives, i.e. moves down rapidly, below the
normalized threshold $\pi^2/\varepsilon^2$ as $\alpha>0$ increases. We describe
the way the eigenvalue dives below $\pi^2/\varepsilon^2$ and prove that the
phenomenon is milder at $\alpha^\star_0=0$ than at $\alpha^\star_k$ for
$k\ge1$.

</details>


### [11] [Hydrodynamic limit from kinetic models with massless electrons to the ionic Euler--Poisson system](https://arxiv.org/abs/2508.08482)
*Young-Pil Choi,Dowan Koo,Sihyun Song*

Main category: math.AP

TL;DR: The paper derives the ionic Euler-Poisson system from kinetic models, overcoming mathematical challenges with physical insights and proving hydrodynamic limits and global existence of solutions.


<details>
  <summary>Details</summary>
Motivation: To understand ion dynamics by connecting kinetic descriptions (Vlasov-Poisson with Fokker-Planck or alignment terms) to fluid models, addressing challenges posed by the Poisson-Boltzmann equation.

Method: Uses the modulated energy method for quantitative error estimates in the hydrodynamic limit and proves global existence of weak entropy solutions for kinetic equations.

Result: Establishes the hydrodynamic limit from kinetic to fluid models and ensures global-in-time existence of solutions, maintaining consistency.

Conclusion: The study successfully bridges kinetic and fluid descriptions of ion dynamics, providing rigorous mathematical foundations and physical insights.

Abstract: We study the derivation of ion dynamics, namely, the ionic Euler--Poisson
system, from kinetic descriptions. The kinetic framework consists of the ionic
Vlasov--Poisson equation coupled with either a nonlinear Fokker--Planck
operator or a local alignment term. In both kinetic and fluid models, the
massless electrons are assumed to be in thermodynamic equilibrium, leading to
an electric potential governed by the Poisson--Boltzmann equation. The
exponential nonlinearity in this semilinear elliptic problem creates
significant mathematical difficulties, which we overcome by exploiting the
physical structure of the system, in particular, the role of the electron
velocity field hidden in the limiting equation. Our first main result
establishes the hydrodynamic limit from the kinetic model to the ionic
Euler--Poisson system, providing quantitative error estimates via the modulated
energy method. As a second contribution, we prove the global-in-time existence
of weak entropy solutions to the kinetic equations, ensuring consistency with
the hydrodynamic limit framework.

</details>


### [12] [Quantitative stability of critical points for the nonlocal-Sobolev inequality in Heisenberg group](https://arxiv.org/abs/2508.08614)
*Shuijin Zhang,Jijie Xu,Jialin Wang*

Main category: math.AP

TL;DR: The paper studies the stability of the nonlocal Sobolev inequality in the Heisenberg group, showing that the distance to optimizers can be bounded linearly by a functional derivative term.


<details>
  <summary>Details</summary>
Motivation: To understand the quantitative stability of the nonlocal Sobolev inequality and its optimizers in the Heisenberg group.

Method: Analyzes the Euler equation and functional derivative term to bound the distance to optimizers.

Result: For solutions close to the Euler equation, the distance to optimizers is linearly bounded by the functional derivative term.

Conclusion: The stability result holds for weakly interacting bubble solutions in dimension Q=4.

Abstract: We investigate the quantitative stability of the nonlocal Sobolev inequality
in Heisenberg group \begin{equation*}\label{non-Sobolev}
  C_{HL}(Q,\mu)
\left(\int_{\mathbb{H}^{n}}\int_{\mathbb{H}^{n}}\frac{|u(\xi)|^{Q^{\ast}_{\mu}}|u(\eta)|^{Q^{\ast}_{\mu}}}{|\eta^{-1}\xi|^{\mu}}\mathrm{d}\xi\mathrm{d}\eta\right)^{\frac{1}{Q^{\ast}_{\mu}}}\leq
\int_{\mathbb{H}^{n}}|\nabla_{H}u|^{2}d\xi,\qquad\forall u\in
S^{1,2}(\mathbb{H}^{n}), \end{equation*} where $Q=2n+2$ is the homogeneous
dimension of the Hiesenberg group $\mathbb{H}^{n}$, $\mu\in(0,Q)$ and
$Q^{\ast}_{\mu}=\frac{2Q-\mu}{Q-2}$ are two parameters corresponding to the
Hardy-Littlewood-Sobolev inequality and Folland-Stein inequality on Heisenberg
group, $C_{HL}(Q,\mu)$ is the sharp constant of the nonlocal-Sobolev
inequality. Specifically, when $u$ is close to solving the Euler equation
\begin{equation*}\label{non-critical-n}
  -\Delta_{H}
u=\left(\int_{\mathbb{H}^{n}}\frac{|u(\eta)|^{Q^{\ast}_{\mu}}}{|\eta^{-1}\xi|^{\mu}}\mathrm{d}\eta\right)|u|^{Q^{\ast}_{\mu}-2}u,\qquad\xi,\eta\in\mathbb{H}^{n},
\end{equation*} the natural distance between $u$ and the the set of optimizers
$U_{\lambda,\zeta}$, defined as
$\delta(u)=||\nabla_{H}u-\nabla_{H}U_{\lambda,\zeta}||_{L^{2}}$, can be
linearly bounded by the functional derivative term \begin{equation*}
  \Gamma(u)=\left\|\Delta_{H}u+\left(\int_{\mathbb{H}^{n}}\frac{|u(\eta)|^{Q^{\ast}_{\mu}}}{|\eta^{-1}\xi|^{\mu}}\mathrm{d}\eta\right)|u|^{Q^{\ast}_{\mu}-2}u\right\|_{(S^{1,2}(\mathbb{H}^{n}))^{-1}}.
  \end{equation*} And for the weakly interacting bubble solutions
$\mathop{\sum}\limits_{i=1}^{\nu}U_{\lambda_{i},\zeta_{i}}$, the aforementioned
quantitative stability result holds when the dimension $Q=4$.

</details>


### [13] [Nonlinear dynamics of reaction-diffusion wave trains under large and fully nonlocalized modulations](https://arxiv.org/abs/2508.08637)
*Joannis Alexopoulos,Björn de Rijk*

Main category: math.AP

TL;DR: The paper analyzes the stability of periodic wave trains in reaction-diffusion systems under large, nonlocalized modulations, proving convergence to modulated wave trains governed by a viscous Hamilton-Jacobi equation.


<details>
  <summary>Details</summary>
Motivation: To extend modulational stability theory to large, nonlocalized initial data without requiring phase shifts at infinity, addressing gaps in previous literature.

Method: Uses $L^\infty$-stability theory, interpolation inequalities for decay balance, and detailed linear dynamics analysis under nonlocalized data.

Result: Global stability is achieved for bounded modulational initial data, with solutions converging to modulated wave trains at an enhanced diffusive rate.

Conclusion: The framework removes localization requirements, enabling treatment of a broader range of initial data under minimal regularity assumptions.

Abstract: We study the dynamics of periodic wave trains in reaction-diffusion systems
on the real line under large, fully nonlocalized modulations. We prove that
solutions with nearby initial data converge, at an enhanced diffusive rate, to
a modulated wave train whose leading-order phase and wavenumber dynamics are
governed by an explicit solution to the viscous Hamilton-Jacobi equation. This
constitutes a global stability result: such initial data are generally not
close to the large-time modulated wave train. In contrast to previous
modulational stability results, our analysis does not require that the initial
data approach phase shifts of the wave train at spatial infinity. The central
methodological advance is a nontrivial extension of the recently developed
$L^\infty$-stability theory to accommodate large phase modulations. This
framework, based entirely on $L^\infty$-estimates, removes all localization
requirements as imposed in the previous literature, allowing us to treat the
full range of bounded modulational initial data under minimal regularity
assumptions. The main technical contributions include: the strategic use of
interpolation inequalities to balance smallness and temporal decay, and a
detailed analysis of the linear dynamics under fully nonlocalized modulational
data.

</details>


### [14] [Global solution and asymptotic behavior for the kinetic derivative NLS on $\mathbb R$](https://arxiv.org/abs/2508.08647)
*Nobu Kishimoto,Kiyeon Lee*

Main category: math.AP

TL;DR: The paper studies the global well-posedness and long-term behavior of solutions to the kinetic derivative nonlinear Schrödinger equation (KDNLS) on the real line, proving global existence for small initial data and analyzing asymptotic behavior.


<details>
  <summary>Details</summary>
Motivation: The KDNLS equation models plasma physics interactions with local and non-local nonlinearities, requiring rigorous analysis of its solutions' behavior.

Method: The authors use energy methods and a frequency-localized gauge transformation to handle non-local nonlinearities and analyze asymptotic behavior.

Result: Global existence for small initial data in $H^2 \cap H^{1,1}$ is proven, with optimal time decay and modified scattering phenomena described.

Conclusion: The solutions exhibit a precise asymptotic profile as $t \to \infty$, demonstrating the effectiveness of the methods used.

Abstract: In this paper we investigate the global well-posedness and long-term behavior
of solutions to the kinetic derivative nonlinear Schr\"odinger equation (KDNLS)
on the real line. The equation incorporates both local cubic nonlinearities
with derivative terms and a non-local term arising from the Hilbert transform,
modeling interactions in plasma physics. We establish global existence for
small initial data in the weighted Sobolev space $H^2 \cap H^{1,1}$ and optimal
time decay effect. Using energy methods and a frequency-localized gauge
transformation, we overcome the difficulties posed by the non-local
nonlinearities and provide a rigorous analysis of the asymptotic behavior. Our
results also describe modified scattering phenomena with a suitable phase
modification, showing that the solutions exhibit a precise asymptotic profile
as $t \to \infty$.

</details>


### [15] [Trudinger's Parabolic Equation](https://arxiv.org/abs/2508.08716)
*Peter Lindqvist,Mikko Parviainen,Saara Sarsa*

Main category: math.AP

TL;DR: The paper investigates the uniqueness of non-negative solutions for a specific PDE using the Galerkin Method.


<details>
  <summary>Details</summary>
Motivation: To understand the uniqueness of solutions for the given PDE, which is crucial for theoretical and applied mathematics.

Method: The Galerkin Method is employed to derive basic estimates.

Result: Basic estimates for the solutions are derived, contributing to the understanding of the PDE's behavior.

Conclusion: The study provides foundational insights into the uniqueness of solutions for the given equation.

Abstract: We study the uniqueness of non-negative solutions of the equation
\begin{align*}
  \partial_t\left(|u|^{p-2}u\right)\,=\, \operatorname{div}(|\nabla
u|^{p-2}\nabla u).
  \end{align*} Basic estimates are derived with the Galerkin Method.

</details>


### [16] [Finite-Time Splash in Free Boundary Problem of 3D Neo-Hookean Elastodynamics](https://arxiv.org/abs/2508.08751)
*Wei Zhang,Jie Fu,Chengchun Hao*

Main category: math.AP

TL;DR: The paper proves finite-time splash singularity formation in 3D viscous incompressible neo-Hookean elastodynamics with free boundaries, using a Lagrangian framework and specialized coordinate charts.


<details>
  <summary>Details</summary>
Motivation: To understand singularity formation in complex boundary conditions where viscous-elastic stresses balance pressure forces, distinct from Navier-Stokes or MHD systems.

Method: A Lagrangian framework with specialized coordinate charts, divergence-free initial conditions, and uniform a priori estimates to track interface evolution.

Result: Finite-time self-intersection (splash singularity) is proven, with smoothness preserved near the singular point until intersection.

Conclusion: The analysis confirms inevitable splash singularity formation within bounded time, with stability ensured by energy conservation and higher-order controls.

Abstract: This paper establishes finite-time splash singularity formation for 3D
viscous incompressible neo-Hookean elastodynamics with free boundaries. The
system features mixed stress-kinematic conditions where viscous-elastic
stresses balance pressure forces at the evolving interface -- a configuration
generating complex boundary integrals that distinguish it from Navier-Stokes or
MHD systems. To address this challenge, we employ a Lagrangian framework
inspired by Coutand and Shkoller (2019), developing specialized coordinate
charts and constructing a sequence of shrinking initial domains with
cylindrical necks connecting hemispherical regions to bases. Divergence-free
initial velocity and deformation tensor fields are designed to satisfy exact
mechanical compatibility. Uniform a priori estimates across the domain sequence
demonstrate that interface evolution preserves local smoothness while
developing finite-time self-intersection. Energy conservation provides
foundational stability, while higher-order energy functionals yield
scaling-invariant regularity control. The analysis proves inevitable splash
singularity formation within explicitly bounded time, maintaining spatial
smoothness near the singular point up to the intersection time.

</details>


### [17] [Improved existence time for Whitham and a Whitham-Boussinesq system](https://arxiv.org/abs/2508.08809)
*Didier Pilod,Sigmund Selberg,Nadia Skoglund Taki,Achenef Tesfahun*

Main category: math.AP

TL;DR: The paper extends the lifespan of solutions for Whitham and Whitham-Boussinesq models in shallow water regimes, achieving well-posedness beyond hyperbolic time using refined Strichartz estimates.


<details>
  <summary>Details</summary>
Motivation: To improve understanding of solution longevity in shallow water wave models, addressing gaps in existing results, especially for 2D cases.

Method: Combines energy methods with new refined Strichartz estimates incorporating the parameter μ.

Result: Establishes well-posedness on timescales of order μ^(1/4^-)ε^(-5/4^+) (1D) and μ^(1/4^-)ε^(-3/2^+) (2D), with a novel result for μ ∼ ε in 2D.

Conclusion: The techniques are robust and adaptable for similar equations, offering new insights into solution longevity in shallow water regimes.

Abstract: In this paper, we investigate the time of existence of the solutions to two
full dispersion models derived from the water waves equations in the shallow
water regime: the Whitham equation and a Whitham-Boussinesq system in dimension
one and two. The regime is characterized by the nonlinearity parameter
$\epsilon\in(0,1]$ and the shallow water parameter $\mu\in(0,1]$.
  We extend the lifespan of the solution beyond the hyperbolic time
$\epsilon^{-1}$. More precisely, we establish well-posedness on the timescale
of order $\mu^{\frac{1}{4}^-}\epsilon^{(-\frac{5}{4})^+}$ in the
one-dimensional case, and of order
$\mu^{\frac{1}{4}^-}\epsilon^{(-\frac{3}{2})^+}$ in dimension two. We emphasize
that for the two-dimensional case, we obtain a time of existence of order
$\epsilon^{-\frac54}$ in the long wave regime $\mu \sim \epsilon$. This kind of
result seems to be new, even for the Boussinesq systems.
  The proofs combine energy methods with Strichartz estimates. Here, a key
ingredient is to obtain new refined Strichartz estimates that include the small
parameter $\mu$. These techniques are robust and could be adapted to improve
the lifespan of solutions for other equations and systems of the same form.

</details>


### [18] [Generalized quasi-linear fractional Wentzell problems](https://arxiv.org/abs/2508.08813)
*Efren Mesino-Espinosa,Alejandro Vélez-Santiago*

Main category: math.AP

TL;DR: The paper studies a generalized quasi-linear elliptic boundary value problem involving the regional fractional $p$-Laplacian and fractional Wentzell boundary conditions, proving existence, uniqueness, and boundedness of weak solutions, along with $L^\infty$-estimates and a Weak Comparison Principle.


<details>
  <summary>Details</summary>
Motivation: To analyze a complex elliptic boundary value problem with fractional operators and generalized boundary conditions, aiming to establish solvability and solution properties.

Method: The authors investigate the problem using weak solution frameworks, derive a priori estimates, and employ comparison principles to analyze solution behavior.

Result: Existence and uniqueness of globally bounded weak solutions are proven, along with $L^\infty$-estimates for solution differences and a Weak Comparison Principle.

Conclusion: The paper successfully addresses the problem, providing theoretical foundations for solutions and their properties, including a nonlinear Fredholm Alternative.

Abstract: Given a bounded $(\epsilon,\delta)$-domain $\Omega\subseteq\mathbb{R\!}^N$
($N\geq2$) whose boundary $\Gamma:=\partial\Omega$ is a $d$-set for
$d\in(N-p,N)$, we investigate a generalized quasi-linear elliptic boundary
value problem governed by the regional fractional $p$-Laplacian
$(-\Delta)^s_{_{p,\Omega}}$ in $\Omega$, and generalized fractional Wentzell
boundary conditions of type $$C'_{p,s}\mathcal{N}^{p'(1-s)}u+\beta|u|^{q-2}
u+\Theta^{\eta}_qu\,=\,g\indent\indent\indent\textrm{on}\,\,\Gamma,$$ where
$\Theta^{\eta}_q$ stands as a nonlocal fractional-type $q$-operator on $\Gamma$
(also refered as a Besov $q$-map), $C'_{p,s}\mathcal{N}^{p'(1-s)}$ denotes the
fractional $p$-normal derivative operator in $\Gamma$, and $p,\,q$ are two
growth exponents acting on the interior and boundary, respectively (which are
in general unrelated between each other). We first show that this model
equation admits a unique weak solution, which is globally bounded in
$\overline{\Omega}$. Furthermore, given two distinct weak solution related to
this boundary value problem with different data values, we establish a priori
$L^{\infty}$-estimates for the difference of weak solutions with upper bound
depending in the differences of the respective interior and boundary data
functions. Additionally, a Weak Comparison Principle is derived, and we
conclude by establishing a sort of nonlinear Fredholm Alternative related to
this generalized elliptic fractional model equation.

</details>


### [19] [Derivation of the Reissner-Mindlin model from nonlinear elasticity](https://arxiv.org/abs/2508.08834)
*Tamara Fastovska,Janusz Ginster,Barbara Zwicknagl*

Main category: math.AP

TL;DR: The paper derives the Reissner-Mindlin plate model from 3D finite elasticity using Γ-convergence, emphasizing transverse shear effects and employing rigidity estimates.


<details>
  <summary>Details</summary>
Motivation: To rigorously connect the Reissner-Mindlin plate model with 3D elasticity, addressing transverse shear effects.

Method: Uses Γ-convergence, scaling strain components differently, and combines rigidity estimates with averaged deformations.

Result: Successfully derives the Reissner-Mindlin model from 3D elasticity, capturing shear effects.

Conclusion: The approach provides a rigorous foundation for the Reissner-Mindlin model, validated by technical tools.

Abstract: We discuss how the Reissner-Mindlin plate model can be derived from
three-dimensional finite elasticity in terms of $\Gamma$-convergence. The
presence of transverse shear effects in the Reissner-Mindlin model requires to
scale different components of the three-dimensional elastic strain differently.
A main technical tool is then the combination of rigidity estimates for the
deformation and suitably averaged versions.

</details>


### [20] [Monotonicity in half-spaces for singular quasilinear elliptic problems involving the gradient](https://arxiv.org/abs/2508.08859)
*Phuong Le*

Main category: math.AP

TL;DR: The paper analyzes positive solutions to a nonlinear PDE in the upper half-space, focusing on behavior near the boundary and proving monotonicity using the moving plane method.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of solutions and their derivatives near the boundary for a specific class of nonlinear PDEs, and to establish monotonicity results.

Method: The study uses boundary behavior analysis and the moving plane method to prove monotonicity of solutions in the $x_N$-direction.

Result: Monotonicity of solutions is proven for certain function spaces, with results being novel even for simpler cases like $\vartheta=0$ or $p=2$.

Conclusion: The paper provides new insights into the behavior and monotonicity of solutions for the given PDE, extending known results to more general cases.

Abstract: We study positive solutions to the problem $-\Delta_p u + \vartheta |\nabla
u|^q = \frac{1}{u^\gamma} + f(u)$ in $\mathbb{R}^N_+$ with the zero Dirichlet
boundary condition, where $p>1$, $\gamma>0$, $0<q\le p$, $\vartheta\ge0$ and
$f:[0,+\infty)\to\mathbb{R}$ is a locally Lipschitz continuous function. We
describe the behavior of solutions and their derivatives near the boundary.
Then we exploit that information and the moving plane method to prove the
monotonicity of solutions in the $x_N$-direction. This result holds for
$W^{1,p}_{\rm loc}(\mathbb{R}^2_+)\cap L^\infty_{\rm
loc}(\overline{\mathbb{R}^2_+})$ solutions in dimension two and for
$W^{1,p}_{\rm loc}(\mathbb{R}^N_+)$ solutions which are bounded in strips in
higher dimensions. Most of our results are new even in the case $\vartheta=0$
or $p=2$.

</details>


### [21] [A Bourgain-Brezis-Mironescu result for fractional thin films](https://arxiv.org/abs/2508.08874)
*Andrea Braides,Margherita Solci*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We consider the limit of squared $H^s$-Gagliardo seminorms on thin domains of
the form $\Omega_\varepsilon=\omega\times(0,\varepsilon)$ in $\mathbb R^d$.
When $\varepsilon$ is fixed, multiplying by $1-s$ such seminorms have been
proved to converge as $s\to 1^-$ to a dimensional constant $c_d$ times the
Dirichlet integral on $\Omega_\varepsilon$ by Bourgain, Brezis and Mironescu.
In its turn such Dirichlet integrals divided by $\varepsilon$ converge as
$\varepsilon\to 0$ to a dimensionally reduced Dirichlet integral on $\omega$.
We prove that if we let simultaneously $\varepsilon\to 0$ and $s\to 1$ then
these squared seminorms still converge to the same dimensionally reduced limit
when multiplied by $(1-s) \varepsilon^{2s-3}$, independently of the relative
converge speed of $s$ and $\varepsilon$. This coefficient combines the
geometrical scaling $\varepsilon^{-1}$ and the fact that relevant interactions
for the $H^s$-Gagliardo seminorms are those at scale $\varepsilon$. We also
study the usual membrane scaling, obtained by multiplying by
$(1-s)\varepsilon^{-1}$, which highlighs the {\em critical scaling}
$1-s\sim|\log\varepsilon|^{-1}$, and the limit when $\varepsilon\to 0$ at fixed
$s$.

</details>


### [22] [Weighted, Multiphase, Volume-Preserving Mean Curvature Flow as Limit of the MBO Scheme on Manifolds](https://arxiv.org/abs/2508.09064)
*Fabius Krämer*

Main category: math.AP

TL;DR: The paper studies a multiphase, volume-constrained version of the Merriman-Bence-Osher thresholding scheme on weighted manifolds, proving conditional convergence to weighted, volume-preserving mean curvature flow.


<details>
  <summary>Details</summary>
Motivation: To extend the efficient thresholding scheme to multiphase, weighted manifolds, relevant in data science, and establish convergence under natural assumptions.

Method: Uses energy dissipation inequality and gradient flow structure, developing heat kernel derivative estimates to pass to the limit.

Result: Convergence to multiphase, weighted, volume-preserving mean curvature flow, conditional on energy convergence.

Conclusion: Introduces a new De Giorgi solution concept for weakly describing the limiting flow, with implications for gradient flow structures.

Abstract: The famous thresholding scheme by Merriman, Bence, and Osher (Motion of
multiple junctions: A level set approach. Journal of Computational Physics
112.2 (1994): 334-363.) proved itself as a very efficient time discretization
of mean curvature flow. The present paper studies a multiphase, volume
constrained version on a weighted manifold that naturally arises in the context
of data science. The main result of this work proves convergence to multiphase,
weighted, volume-preserving mean curvature flow on a smooth, closed manifold.
The proof is only conditional in the sense that convergence of the
approximating energy to the weighted perimeter is assumed. These type of
assumptions are natural and common in the literature. The proof shows
convergence in the energy dissipation inequality, induced by the underlying
gradient flow structure, similar to the work of Laux and Otto (The thresholding
scheme for mean curvature flow and De Giorgi's ideas for minimizing movements.
The Role of Metrics in the Theory of Partial Differential Equations 85 (2020):
63-94.). This leads to a new De Giorgi solution concept that describes weakly
the limiting flow. Estimates regarding the derivatives of the heat kernel are
developed in order to pass to the limit in the variations of the energy and
metric.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [23] [Bridging Quantum Mechanics to Organic Liquid Properties via a Universal Force Field](https://arxiv.org/abs/2508.08575)
*Tianze Zheng,Xingyuan Xu,Zhi Wang,Xu Han,Zhenliang Mu,Ziqing Zhang,Sheng Gong,Kuang Yu,Wen Yan*

Main category: physics.comp-ph

TL;DR: ByteFF-Pol, a GNN-parameterized polarizable force field, predicts macroscopic properties from QM data, outperforming SOTA methods.


<details>
  <summary>Details</summary>
Motivation: Overcome the trade-off between computational cost and accuracy in predicting macroscopic properties from ab initio calculations.

Method: Uses graph neural networks (GNNs) trained on high-level QM data with physically-motivated force field forms.

Result: Exceptional performance in predicting thermodynamic and transport properties for small-molecule liquids and electrolytes.

Conclusion: ByteFF-Pol bridges QM calculations and macroscopic properties, enabling new applications in materials discovery.

Abstract: Molecular dynamics (MD) simulations are essential tools for unraveling
atomistic insights into the structure and dynamics of condensed-phase systems.
However, the universal and accurate prediction of macroscopic properties from
ab initio calculations remains a significant challenge, often hindered by the
trade-off between computational cost and simulation accuracy. Here, we present
ByteFF-Pol, a graph neural network (GNN)-parameterized polarizable force field,
trained exclusively on high-level quantum mechanics (QM) data. Leveraging
physically-motivated force field forms and training strategies, ByteFF-Pol
exhibits exceptional performance in predicting thermodynamic and transport
properties for a wide range of small-molecule liquids and electrolytes,
outperforming state-of-the-art (SOTA) classical and machine learning force
fields. The zero-shot prediction capability of ByteFF-Pol bridges the gap
between microscopic QM calculations and macroscopic liquid properties, enabling
the exploration of previously intractable chemical spaces. This advancement
holds transformative potential for applications such as electrolyte design and
custom-tailored solvent, representing a pivotal step toward data-driven
materials discovery.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [24] [A High-Order Low-Order extended moment method for the Vlasov-Darwin particle-in-cell system](https://arxiv.org/abs/2508.08530)
*Derek A. Kuldinow,William T. Taitano,Kentaro Hara*

Main category: physics.plasm-ph

TL;DR: The paper introduces a coupled high-order low-order (HOLO) method for the electromagnetic Vlasov-Darwin model, demonstrating its ability to exceed explicit timestep limits while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of explicit methods in simulating the Vlasov-Darwin model by developing a more efficient and accurate implicit approach.

Method: The HOLO method combines a high-order (HO) system for particle evolution with a low-order (LO) system for fluid moment and Darwin equations, acting as a convergence accelerator.

Result: The HOLO method allows larger timesteps than explicit limits and accurately recovers system evolution, with LO fluid moment equations significantly affecting nonlinear convergence.

Conclusion: The HOLO method is validated through benchmarks like Landau damping and Weibel instabilities, proving its effectiveness for the Vlasov-Darwin model.

Abstract: In this study, we develop an extended implicit moment method, namely, a
coupled high-order low-order (HOLO) method and apply it to the electromagnetic
Vlasov-Darwin model. The high-order (HO) system evolves particles in a manner
that conserves charge, energy, and canonical momentum, while the low-order (LO)
system solves the fluid moment and Darwin equations, acting as an algorithmic
convergence accelerator to the HO system. We demonstrate the HOLO method's
ability to take timesteps far larger than the explicit limit, and accurately
recover the system's evolution so long as its dynamical timescale is respected.
Also, we find that the choice of LO fluid moment equations has a strong impact
on the nonlinear convergence of the coupled particle-field system. The HOLO
algorithm is benchmarked against electrostatic Landau damping and the
electromagnetic electron and ion Weibel instabilities.

</details>


### [25] [Transition to Petschek Reconnection in Subrelativistic Pair Plasmas: Implications for Particle Acceleration](https://arxiv.org/abs/2508.08533)
*Adam Robbins,Anatoly Spitkovsky*

Main category: physics.plasm-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: While relativistic magnetic reconnection in pair plasmas has emerged in
recent years as a candidate for the origin of radiation from extreme
astrophysical environments, the corresponding subrelativistic pair plasma
regime has remained less explored, leaving open the question of how
relativistic physics affects reconnection. In this paper, we investigate the
differences between these regimes by contrasting 2D particle-in-cell
simulations of reconnection in pair plasmas with relativistic magnetization
($\sigma \gg 1$) and subrelativistic magnetization ($\sigma < 1$). By utilizing
unprecedentedly large domain sizes and outflow boundary conditions, we
demonstrate that lowering the magnetization results in a change in the
reconnection geometry from a plasmoid chain to a Petschek geometry, where
laminar exhausts bounded by slow-mode shocks emanate from a single diffusion
region. We attribute this change to the reduced plasmoid production rate in the
low-$\sigma$ case: when the secondary tearing rate is sufficiently low,
plasmoids are too few in number to prevent the system from relaxing into a
stable Petschek configuration. This geometric change also affects particle
energization: we show that while high-$\sigma$ plasmoid chains generate
power-law energy spectra, low-$\sigma$ Petschek exhausts merely heat incoming
plasma and yield negligible nonthermal acceleration. These results have
implications for predicting the global current sheet geometry and the resulting
energy spectrum in a variety of systems.

</details>


### [26] [Characteristics of monotonic sheaths near a wall with grazing magnetic incidence](https://arxiv.org/abs/2508.09067)
*Alessandro Geraldini,Robert J. Ewart,Stephan Brunner,Felix I. Parra*

Main category: physics.plasm-ph

TL;DR: The paper develops a scheme (GYRAZE) to solve for both the quasineutral magnetic presheath and non-neutral Debye sheath in a magnetized plasma, analyzing ion and electron distributions at the wall and the critical magnetic field angle.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of magnetized plasma near an absorbing wall, particularly the electrostatic potential and particle distributions, which is crucial for fusion device applications.

Method: A grazing-incidence gyrokinetic treatment is used, building on an iterative scheme to solve for steady-state electrostatic potential in the presheath and Debye sheath. The code GYRAZE is developed for this purpose.

Result: GYRAZE provides ion and electron distributions at the wall. The critical magnetic field angle for a monotonic potential profile increases with γ but remains smaller than angles at fusion divertor targets.

Conclusion: The developed scheme successfully models plasma-wall interactions, with implications for fusion device design, though the critical angle limitation must be considered.

Abstract: We consider a magnetised plasma in contact with an absorbing planar wall,
where the angle $\alpha$ between the magnetic field and the wall is small,
$\alpha \ll 1$ (in radians) and the system is symmetric tangential to the wall.
The finite ratio $\gamma$ of the characteristic electron gyroradius $\rho_{\rm
e}$ to the Debye length $\lambda_{\rm D}$, $\gamma = \rho_{\rm e} /
\lambda_{\rm D}$, is retained via a grazing-incidence ($\alpha \ll 1$)
gyrokinetic treatment [1,2]. Building on a previously developed iterative
scheme [2,3] to solve for the steady-state electrostatic potential in the
quasineutral magnetic presheath of width $\sim \rho_{\rm S}$, we developed a
scheme that simultaneously solves for both the presheath and the non-neutral
Debye sheath of width $\sim \lambda_{\rm D}$ in the limit $\lambda_{\rm D} /
\rho_{\rm S} \rightarrow 0$. The code, called GYRAZE, thus provides the
energy-angle distribution of ions at the wall and the velocity distributions of
electrons reflected by the wall for different values of wall potential. A
monotonic electrostatic potential profile, assumed in this work, can only exist
for magnetic field angles larger than a critical value [3]. While the critical
angle is shown here to significantly increase with $\gamma$, it is still
typically smaller than the magnetic field angle at divertor targets of a fusion
device.

</details>


### [27] [Direct Measurement of Electron Heating in Electron-Only Reconnection in a Laboratory Mini-Magnetosphere](https://arxiv.org/abs/2508.09086)
*Lucas Rovige,Filipe D. Cruz,Timothy Van Hoomisen,Robert S. Dorst,Carmen G. Constantin,Stephen Vincena,Luis O. Silva,Christoph Niemann,Derek B. Schaeffer*

Main category: physics.plasm-ph

TL;DR: Experimental observation of electron heating in electron-only magnetic reconnection in laser-driven mini-magnetospheres, showing a 40% conversion of Poynting flux into electron enthalpy flux.


<details>
  <summary>Details</summary>
Motivation: To study electron heating in electron-only magnetic reconnection, a phenomenon relevant to astrophysical and laboratory plasmas.

Method: Laser-driven mini-magnetospheres on the LAPD, with electron velocity distribution measured via non-collective Thomson scattering. Particle-in-cell simulations were also used.

Result: Significant electron heating observed, with temperature rising from 1.8 eV to 9.5 eV in the electron diffusion region.

Conclusion: The experiment demonstrates efficient electron heating in electron-only reconnection, supported by simulations.

Abstract: We report on the experimental observation of electron heating in
electron-only magnetic reconnection in laser-driven laboratory
mini-magnetospheres on the Large Plasma Device (LAPD) at the University of
California, Los Angeles. In this experiment, a fast-flowing plasma impacts a
pulsed magnetic dipole embedded within LAPD's magnetized ambient plasma,
creating an ion-scale magnetosphere and driving electron-only magnetic
reconnection between the background and dipole field lines. The electron
velocity distribution is measured across the reconnection region using
non-collective Thomson scattering, enabling determination of electron
temperature and density. Significant electron heating is observed in the
electron diffusion region, increasing from an initial temperature of 1.8 eV to
9.5 eV, corresponding to a 40\% conversion of Poynting flux into electron
enthalpy flux. Particle-in-cell simulations that provide insights into the
heating mechanisms are also presented.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [28] [Stability of spinorial Sobolev inequalities on $\mathbb{S}^n$](https://arxiv.org/abs/2508.09047)
*Guofang Wang,Mingwei Zhang*

Main category: math.DG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The spinorial Sobolev inequality on the unit sphere states \begin{equation*}
  \Big(\int|
D\psi|^{\frac{2n}{n+1}}\Big)^{\frac{n+1}{n}}-\frac{n}{2}\omega_{n}^{1/n}\int\langle
D\psi,\psi\rangle
  \geq 0, \end{equation*} with equality if and only if $\psi \in {\mathcal M}$,
the set of all $-\frac 12$-Killing spinors and their conformal transformations.
  Our main result in this paper is to refine this inequality by establishing a
stability inequality
  \begin{equation*} \Big(\int|
D\psi|^{\frac{2n}{n+1}}\Big)^{\frac{n+1}{n}}-\frac{n}{2}\omega_{n}^{1/n}\int\langle
D\psi,\psi\rangle
  \geq {\bf c}_S\inf_{\phi\in\mathcal{M}}\Big(\int|
D(\psi-\phi)|^{\frac{2n}{n+1}}\Big)^{\frac{n+1}{n}}.
  \end{equation*}
  As a by-product of our argument, we show that elements in set $\mathcal M$
are not optimizers of another spinorial Sobolev inequality
  \begin{equation*}
  \Big(\int| D\psi|^{\frac{2n}{n+1}}\Big)^{\frac{n+1}{n}} \geq C_S
\Big(\int|\psi|^{\frac{2n}{n-1}}\Big)^{\frac{n-1}{n}},
  \end{equation*}
  unlike expected by experts. They have in fact index $n+1$ and nullity
$2^{[\frac n2]+2}$.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [29] [UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss](https://arxiv.org/abs/2508.08615)
*Zhichao Wang,Xinhai Chen,Qinglin Wang,Xiang Gao,Qingyang Zhang,Menghan Jia,Xiang Zhang,Jie Liu*

Main category: cs.AI

TL;DR: UGM2N introduces an unsupervised, generalizable mesh movement network for PDEs, improving accuracy and efficiency without pre-adapted meshes.


<details>
  <summary>Details</summary>
Motivation: Traditional mesh movement methods are computationally complex and inflexible, while supervised learning lacks generalization.

Method: UGM2N uses localized geometric feature learning and a physics-constrained M-Uniform loss for mesh equidistribution.

Result: UGM2N outperforms existing methods, generalizing across PDEs and mesh geometries, scaling to multi-scale resolutions, and reducing errors.

Conclusion: UGM2N offers a robust, equation-agnostic solution for efficient mesh adaptation in PDE simulations.

Abstract: Partial differential equations (PDEs) form the mathematical foundation for
modeling physical systems in science and engineering, where numerical solutions
demand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address
this challenge by dynamically relocating mesh nodes to rapidly-varying regions,
enhancing both simulation accuracy and computational efficiency. However,
traditional approaches suffer from high computational complexity and geometric
inflexibility, limiting their applicability, and existing supervised
learning-based approaches face challenges in zero-shot generalization across
diverse PDEs and mesh topologies.In this paper, we present an Unsupervised and
Generalizable Mesh Movement Network (UGM2N). We first introduce unsupervised
mesh adaptation through localized geometric feature learning, eliminating the
dependency on pre-adapted meshes. We then develop a physics-constrained loss
function, M-Uniform loss, that enforces mesh equidistribution at the nodal
level.Experimental results demonstrate that the proposed network exhibits
equation-agnostic generalization and geometric independence in efficient mesh
adaptation. It demonstrates consistent superiority over existing methods,
including robust performance across diverse PDEs and mesh geometries,
scalability to multi-scale resolutions and guaranteed error reduction without
mesh tangling.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [30] [SonicRadiation: A Hybrid Numerical Solution for Sound Radiation without Ghost Cells](https://arxiv.org/abs/2508.08775)
*Xutong Jin,Guoping Wang,Sheng Li*

Main category: cs.SD

TL;DR: SonicRadiation is a hybrid method combining FDTD and TDBEM for accurate and efficient sound radiation simulation, overcoming limitations of ghost cells in complex boundaries.


<details>
  <summary>Details</summary>
Motivation: Existing ghost cell-based FDTD methods fail in complex boundary scenarios, necessitating a more robust solution for sound radiation simulation.

Method: A hybrid approach integrating FDTD and TDBEM with a boundary grid synchronization strategy to handle complex boundaries without ghost cells.

Result: The method outperforms previous approaches in accuracy and efficiency, especially in complex scenes.

Conclusion: SonicRadiation effectively addresses the challenges of sound radiation simulation in complex boundaries, offering superior performance.

Abstract: Interactive synthesis of physical sound effects is crucial in digital media
production. Sound radiation simulation, a key component of physically based
sound synthesis, has posed challenges in the context of complex object
boundaries. Previous methods, such as ghost cell-based finite-difference
time-domain (FDTD) wave solver, have struggled to address these challenges,
leading to large errors and failures in complex boundaries because of the
limitation of ghost cells. We present SonicRadiation, a hybrid numerical
solution capable of handling complex and dynamic object boundaries in sound
radiation simulation without relying on ghost cells. We derive a consistent
formulation to connect the physical quantities on grid cells in FDTD with the
boundary elements in the time-domain boundary element method (TDBEM). Hereby,
we propose a boundary grid synchronization strategy to seamlessly integrate
TDBEM with FDTD while maintaining high numerical accuracy. Our method holds
both advantages from the accuracy of TDBEM for the near-field and the
efficiency of FDTD for the far-field. Experimental results demonstrate the
superiority of our method in sound radiation simulation over previous
approaches in terms of accuracy and efficiency, particularly in complex scenes,
further validating its effectiveness.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [31] [Universal power-law distribution functions in an electromagnetic kinetic plasma: implications for the inverted temperature profile in the solar corona](https://arxiv.org/abs/2508.08361)
*Uddipan Banik,Amitava Bhattacharjee*

Main category: astro-ph.SR

TL;DR: A quasilinear theory explains how electromagnetic kinetic plasmas relax, forming a universal $v^{-5}$ tail in particle distributions, with implications for solar corona dynamics.


<details>
  <summary>Details</summary>
Motivation: To understand the relaxation of electromagnetic kinetic plasmas and its role in creating non-thermal particle distributions in astrophysical environments like the solar corona.

Method: Developed a self-consistent quasilinear theory to model the relaxation process and analyzed the resulting particle distribution functions.

Result: Found that mean distribution functions relax to a universal $v^{-5}$ tail, with large-scale EM fields accelerating fast particles, leading to suprathermal escape and temperature inversion in the solar corona.

Conclusion: The theory explains non-thermal particle acceleration in the solar corona, suggesting EM turbulence can invert temperature profiles and enable particle escape.

Abstract: We develop a self-consistent quasilinear theory for the relaxation of
electromagnetic kinetic plasmas, and demonstrate that the mean distribution
functions of both electrons and ions tend to relax to a universal $v^{-5}$
tail. Large-scale electromagnetic (EM) fields efficiently accelerate the
unscreened, fast particles but not the screened, slow ones. This non-thermal
tail may arise in the solar corona from EM turbulence despite collisions,
allowing suprathermal particles to escape the sun's gravity (velocity
filtration) and inverting the temperature $(T)$ profile with $T$ rising to
$10^6$ K.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [32] [Stochastic Reconstruction of the Speed of Sound in Breast Ultrasound Computed Tomography with Phase Encoding in the Frequency Domain](https://arxiv.org/abs/2508.08434)
*Luca A. Forte*

Main category: physics.med-ph

TL;DR: The paper introduces a stochastic inversion method in the frequency domain for USCT breast imaging, showing comparable image quality to deterministic methods while significantly reducing reconstruction time.


<details>
  <summary>Details</summary>
Motivation: To improve ultrasound computed tomography (USCT) for breast imaging by addressing the limitations of deterministic optimization methods, such as long reconstruction times.

Method: Proposes a stochastic inversion algorithm in the frequency domain (phase encoding) for speed of sound reconstruction, tested on synthetic 2D/3D data and experimental data, comparing it to deterministic inversion.

Result: Stochastic inversion achieves comparable image quality to deterministic methods while reducing reconstruction time by more than half.

Conclusion: Stochastic inversion in the frequency domain is a viable alternative to deterministic methods, offering efficiency without compromising quality.

Abstract: The framework of ultrasound computed tomography (USCT) has recently
re-emerged as a powerful, safe and operator-independent way to image the
breast. State of the art image reconstruction methods are performed with
iterative techniques based on deterministic optimization algorithms in the
frequency domain in the 300 kHz - 1 MHz bandwidth. Alternative algorithms with
deterministic and stochastic optimization have been considered in the
time-domain. In this paper, we present the equivalent stochastic inversion in
the frequency domain (phase encoding), with a focus on reconstructing the speed
of sound. We test the inversion algorithm on synthetic data in 2D and 3D, by
explicitly differentiating between inverse crime and non-inverse crime
scenarios, and compare against the deterministic inversion. We then show the
results of the stochastic inversion in the frequency domain on experimental
data. By leveraging on the concepts of multiple super-shots and stochastic
ensembles, we provide robust evidence that image quality of a stochastic
reconstruction of the speed of sound with phase encoding in the frequency
domain is comparable, and essentially equivalent, to the one of a deterministic
reconstruction, with the further benefit of drastically reducing reconstruction
times by more than half.

</details>


### [33] [Beam hardening correction of Bremsstrahlung X-ray computed tomography measurements and required measurement accuracies](https://arxiv.org/abs/2508.08515)
*Nikhil Deshmukh*

Main category: physics.med-ph

TL;DR: The paper explores beam hardening correction (BHC) in quantitative CT using Bremsstrahlung sources, analyzing how uncertainties in transmission and material thickness measurements affect spectrum estimation and CT reconstruction.


<details>
  <summary>Details</summary>
Motivation: Accurate spectrum estimation is crucial for beam hardening correction in CT, but uncertainties in measurements can propagate errors. This study aims to quantify these uncertainties.

Method: Adopts Lifton's BHC procedure, using simulations to analyze how uncertainties in transmission and material thickness measurements propagate to spectrum estimation and CT reconstruction.

Result: Demonstrates the impact of measurement uncertainties on spectrum estimation, BHC curve, and final CT reconstruction accuracy.

Conclusion: Highlights the need for precise measurements in BHC procedures to minimize errors in quantitative CT.

Abstract: Doing quantitative computed tomography (CT) using Bremsstrahlung sources
requires an estimate of the spectrum emitted by the X-ray source. One method of
beam hardening correction (BHC), as described by Lifton[1], first uses
transmission measurements of a known material and range of thicknesses to
estimate the spectrum and then uses the estimated spectrum to correct the beam
hardening error, not necessarily on the same material as used for estimating
the spectrum. We adopt Lifton's BHC procedure and through simulations show how
the uncertainties in the transmission measurements and the uncertainties in the
material thickness measurements propagate to uncertainties in the spectrum, the
beam hardening correction curve and thence to uncertainties in the beam
hardening corrected CT reconstruction.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [34] [Neural quantum states for emitter dynamics in waveguide QED](https://arxiv.org/abs/2508.08964)
*Tatiana Vovk,Anka Van de Walle,Hannes Pichler,Annabelle Bohrdt*

Main category: quant-ph

TL;DR: A novel numerical method (t-NQS) is introduced to study the dynamics of quantum emitters in waveguides, extending the t-NQS framework to open quantum systems.


<details>
  <summary>Details</summary>
Motivation: General analytical solutions for arbitrarily spaced quantum emitters in waveguides are unavailable due to lost permutation symmetry.

Method: Extends the time-dependent neural quantum state (t-NQS) framework to open quantum systems and benchmarks it against tensor-network calculations.

Result: The t-NQS approach is competitive with other numerical methods and shows promise for studying open quantum many-body systems out of equilibrium.

Conclusion: The t-NQS framework is a viable tool for exploring complex dynamics in waveguide QED systems.

Abstract: Quantum emitters coupled to one-dimensional waveguides constitute a
paradigmatic quantum-optical platform for exploring collective phenomena in
open quantum many-body systems. For appropriately spaced emitters, they realize
the Dicke model, whose characteristic permutation symmetry allows for efficient
exact solutions featuring superradiance. When the emitters are arbitrarily
spaced, however, this symmetry is lost and general analytical solutions are no
longer available. In this work, we introduce a novel numerical method to study
the dynamics of such systems by extending the time-dependent neural quantum
state (t-NQS) framework to open quantum systems. We benchmark our approach
across a range of waveguide QED settings and compare its performance with
tensor-network calculations. Our results demonstrate that the t-NQS approach is
competitive with other numerical methods and highlight the potential of t-NQSs
for studying open quantum many-body systems out of equilibrium.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [35] [Sharp phase transition in the grand canonical $Φ^3$ measure at critical chemical potential](https://arxiv.org/abs/2508.08427)
*Nikolay Barashkov,Kihoon Seong,Philippe Sosoe*

Main category: math.PR

TL;DR: The paper identifies a critical chemical potential for the grand canonical Φ³ measure in 2D Euclidean QFT, showing a sharp phase transition. At criticality, it analyzes Gaussian fluctuations and divergence in the partition function.


<details>
  <summary>Details</summary>
Motivation: To understand the phase transition and critical phenomena in the Φ³ measure, extending prior work limited to non-critical regimes.

Method: Combines correlation decay analysis of Gaussian fluctuations in the partition function with a coarse-graining argument to study divergence.

Result: Identifies a critical chemical potential and demonstrates a sharp phase transition at this threshold.

Conclusion: The study advances understanding of critical behavior in the Φ³ measure, linking Gaussian fluctuations to phase transition dynamics.

Abstract: We study the phase transition and critical phenomenon for the grand canonical
$\Phi^3$ measure in two-dimensional Euclidean quantum field theory. The study
of this measure was initiated by Jaffe, Bourgain, and
Carlen--Fr\"ohlich--Lebowitz, primarily in regimes far from criticality. We
identify a critical chemical potential and show that the measure exhibits a
sharp phase transition at this critical threshold. At the critical threshold,
the analysis is based on establishing the correlation decay of the Gaussian
fluctuations in the partition function, combined with a coarse-graining
argument to show divergence of the maximum of an approximating Gaussian
process.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [36] [Characterization of Vanishing Campanato Spaces via Ball Banach Function Spaces and Its Applications](https://arxiv.org/abs/2508.08536)
*Xing Fu,Yoshihiro Sawano,Jin Tao,Dachun Yang*

Main category: math.FA

TL;DR: New characterizations of vanishing Campanato spaces using oscillation in ball Banach function spaces, revealing self-improvement phenomena and applying higher-order differences with convolution smoothing.


<details>
  <summary>Details</summary>
Motivation: To provide fresh insights into vanishing Campanato spaces, especially the vanishing BMO space, and explore their applications in fractional integral commutators.

Method: Uses higher-order differences dominated by convolution smoothing within ball Banach function spaces.

Result: New characterizations of vanishing Campanato spaces and their natural appearance in fractional integral commutators' compactness.

Conclusion: The approach offers novel insights and tools for studying vanishing Campanato spaces and their applications.

Abstract: In this article, the authors provide some new characterizations of several
vanishing Campanato spaces using a type of oscillation defined within the
general framework of ball Banach function spaces. This approach yields fresh
insights even in the special case of the vanishing BMO space. The
characterization reveals a self-improvement phenomenon inherent in vanishing
Campanato spaces. A key innovation of this approach lies in using higher-order
differences to dominate oscillations. Instead of directly estimating these
differences, the authors achieve the domination by smoothing the function via
convolution. As additional outcomes, the authors also obtain new
characterizations of vanishing Campanato spaces in terms of higher-order
differences. Finally, the authors present several examples to show that these
vanishing Campanato spaces naturally arise in the study on the compactness of
fractional integral commutators in Morrey spaces.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [37] [Electronic transport and Fermi surface of Weyl semimetal WTe2: quantum oscillations and first-principles study](https://arxiv.org/abs/2508.08419)
*B. M. Fominykh,A. N. Perevalova,S. T. Baidak,A. V. Lukoyanov,S. V. Naumov,E. B. Marchenkova,V. V. Marchenkov*

Main category: cond-mat.mtrl-sci

TL;DR: Experimental and theoretical study of Weyl semimetal $WTe_2$ reveals its near-compensated state, quadratic magnetoresistivity, and violation of Kohler's rule, with detailed Fermi surface analysis.


<details>
  <summary>Details</summary>
Motivation: Investigate the unique electronic and transport properties of topological semimetals, particularly $WTe_2$, for potential applications in electronics.

Method: Combined DFT+U+SOC calculations and experimental analysis of electronic transport, magnetoresistivity, and Shubnikov-de Haas oscillations.

Result: $WTe_2$ shows near-compensated state, quadratic magnetoresistivity, and violation of Kohler's rule. Fermi surface analysis reveals three distinct pockets.

Conclusion: $WTe_2$ exhibits complex electronic behavior due to multiple scattering mechanisms and temperature-dependent carrier concentration, with implications for topological semimetal applications.

Abstract: Currently, topological semimetals are being actively investigated from both
theoretical and experimental perspectives due to their unique physical
properties, including topologically protected states, large magnetoresistivity,
and high carrier mobility, which make these materials promising for various
applications in electronics. In this work, we present experimental and
theoretical studies of the electronic structure and electronic transport in the
Weyl semimetal $WTe_2$. Band structure of $WTe_2$ was scrutinized with
DFT+U+SOC method showing the semimetallic nature and sensitivity of the
structure to the value of U and to changes in the Fermi energy. Our results
demonstrate that $WTe_2$ is in a near-compensated state and exhibits an almost
quadratic non-saturating magnetoresistivity. It is found that $WTe_2$ violates
the classical Kohler's rule, which is attributed to the coexistence of multiple
scattering mechanisms and a strong temperature dependence of the current
carrier concentration. Analysis of the Shubnikov-de Haas oscillations reveals
three distinct frequencies corresponding to two electron and one hole Fermi
surface pockets, which are well reproduced in Fermi surface calculations. Using
the Lifshitz-Kosevich formalism, we determined the electronic structure
parameters for each Fermi surface pocket. Additionally, we discuss the
relationship between the g-factor and the Berry phase extracted from quantum
oscillations.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [38] [Representative Volume Element: Existence and Extent in Cracked Heterogeneous Medium](https://arxiv.org/abs/2508.08320)
*Hari Sankar R,Harpreet Singha*

Main category: cs.CE

TL;DR: This paper addresses microscale failure in composites using multiscale modeling, proposing modified periodic boundary conditions (MPBCs) to reduce mesh and size sensitivities in RVE modeling, validated through extensive simulations.


<details>
  <summary>Details</summary>
Motivation: The increasing demand for composites in engineering drives the need to improve their failure analysis at microscale using advanced modeling techniques.

Method: Proposes MPBCs to equalize fracture energy and reduce size dependency in RVE modeling, tested on 1,200 RVE samples under transverse loading.

Result: MPBCs effectively attenuate RVE size effects, improving material response accuracy, especially in the inelastic regime. Damage initiation is influenced by fiber arrangement.

Conclusion: The study successfully enhances RVE modeling representativeness, offering insights into damage initiation factors in composites.

Abstract: Acknowledging the ever-increasing demand for composites in the engineering
industry, this paper focuses on the failure of composites at the microscale and
augmenting the use of multiscale modelling techniques to make them better for
various applications. This work aims to increase the representativeness of the
volume element by attenuating the mesh and size sensitivities in representative
volume element (RVE) modelling. A technique to alleviate mesh sensitivity in
RVE modelling is proposed, which equalises the fracture energy observed from
computational analysis with the real phenomenon, thereby keeping the response
independent of the bandwidth of strain localisation. Based on the hypothesis
that ensuring periodicity of strain, in addition to displacement periodicity
across the domain boundary and supplementing the capability of periodic
boundary conditions (PBCs) to attenuate the size dependency in RVE modelling, a
set of modified PBCs (MPBCs) are formulated. One thousand two hundred RVE
samples falling into combinations of five fibre volume fractions and four RVE
sizes are analysed under transverse loading, and the ability of MPBCs to
attenuate the effect of RVE size on the precision of material response,
particularly in the inelastic regime, is verified. This work also focuses on
various factors affecting damage initiation in 2D composite RVEs. The
arrangement of a pair of fibres with their members placed close to each other,
such that the angle between the direction of loading and an imaginary line
drawn between their centres is less, is observed to make the region between
them more favourable to damage.

</details>
