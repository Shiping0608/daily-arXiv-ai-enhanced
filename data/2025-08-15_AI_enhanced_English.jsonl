{"id": "2508.10126", "pdf": "https://arxiv.org/pdf/2508.10126", "abs": "https://arxiv.org/abs/2508.10126", "authors": ["Arvind K. Saibaba", "Misha E. Kilmer", "Khalil Hall-Hooper", "Fan Tian", "Alex Mize"], "title": "A tensor-based dynamic mode decomposition based on the $\\star_{\\boldsymbol{M}}$-product", "categories": ["math.NA", "cs.NA", "15A69, 65F99, 93B30"], "comment": null, "summary": "Dynamic mode decomposition (DMD) is a data-driven method for estimating the\ndynamics of a discrete dynamical system. This paper proposes a tensor-based\napproach to DMD for applications in which the states can be viewed as tensors.\nSpecifically, we use the $\\star_{\\boldsymbol{M}}$-product framework for tensor\ndecompositions which we demonstrate offers excellent compression compared to\nmatrix-based methods and can be implemented in a computationally efficient\nmanner. We show how the proposed approach is connected to the traditional DMD\nand physics-informed DMD frameworks. We give a computational framework for\ncomputing the tensor-based DMD and detail the computational costs. We also give\na randomized algorithm that enables efficient $\\star_{\\boldsymbol{M}}$-DMD\ncomputations in the streaming setting. The numerical results show that the\nproposed method achieves equal or better accuracy for the same storage compared\nto the standard DMD on these examples and is more efficient to compute.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.10158", "pdf": "https://arxiv.org/pdf/2508.10158", "abs": "https://arxiv.org/abs/2508.10158", "authors": ["Yunhui He", "Santolo Leveque"], "title": "A Generalized Alternating Anderson Acceleration Method", "categories": ["math.NA", "cs.NA", "65F10, 65H10, 65K10"], "comment": "24 pages, 9 figures", "summary": "In this work, we propose a generalized alternating Anderson acceleration\nmethod, a periodic scheme composed of $t$ fixed-point iteration steps,\ninterleaved with $s$ steps of Anderson acceleration with window size $m$, to\nsolve linear and nonlinear problems. This allows flexibility to use different\ncombinations of fixed-point iteration and Anderson iteration. We present a\nconvergence analysis of the proposed scheme for accelerating the Richardson\niteration in the linear case, with a focus on specific parameter choices of\ninterest. Specifically, we prove convergence of the proposed method under\ncontractive fixed-point iteration and provide a sufficient condition for\nconvergence when the Richardson iteration matrix is diagonalizable and\nnoncontractive. To demonstrate the broader applicability of our proposed\nmethod, we use it to accelerate Jacobi iteration, Picard iteration, gradient\ndescent, and the alternating direction method of multipliers in solving partial\ndifferential equations and nonlinear, nonsmooth optimization problems. The\nnumerical results illustrate that the proposed scheme is more efficient than\nthe existing windowed Anderson acceleration and alternating Anderson ($s=1$) in\nterms of iteration number and CPU time for careful choice of parameters $m, s,\nt$.", "AI": {"tldr": "A generalized alternating Anderson acceleration method is proposed, combining fixed-point and Anderson iterations for solving linear and nonlinear problems, with proven convergence and improved efficiency over existing methods.", "motivation": "To enhance flexibility and efficiency in solving linear and nonlinear problems by combining fixed-point and Anderson acceleration iterations.", "method": "A periodic scheme alternating between fixed-point iteration steps and Anderson acceleration steps, with convergence analysis for specific parameter choices.", "result": "Proven convergence under contractive conditions and demonstrated efficiency in accelerating various iterative methods like Jacobi and gradient descent.", "conclusion": "The proposed method outperforms existing techniques in iteration count and CPU time for well-chosen parameters."}}
{"id": "2508.10322", "pdf": "https://arxiv.org/pdf/2508.10322", "abs": "https://arxiv.org/abs/2508.10322", "authors": ["Qixuan Zhou", "Chuqi Chen", "Tao Luo", "Yang Xiang"], "title": "SSBE-PINN: A Sobolev Boundary Scheme Boosting Stability and Accuracy in Elliptic/Parabolic PDE Learning", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving partial differential equations (PDEs), yet they often fail to\nachieve accurate convergence in the H1 norm, especially in the presence of\nboundary approximation errors. In this work, we propose a novel method called\nSobolev-Stable Boundary Enforcement (SSBE), which redefines the boundary loss\nusing Sobolev norms to incorporate boundary regularity directly into the\ntraining process. We provide rigorous theoretical analysis demonstrating that\nSSBE ensures bounded H1 error via a stability guarantee and derive\ngeneralization bounds that characterize its robustness under finite-sample\nregimes. Extensive numerical experiments on linear and nonlinear PDEs,\nincluding Poisson, heat, and elliptic problems, show that SSBE consistently\noutperforms standard PINNs in terms of both relative L2 and H1 errors, even in\nhigh-dimensional settings. The proposed approach offers a principled and\npractical solution for improving gradient fidelity and overall solution\naccuracy in neural network based PDE solvers.", "AI": {"tldr": "The paper introduces Sobolev-Stable Boundary Enforcement (SSBE) to improve boundary loss in PINNs, ensuring better convergence in the H1 norm and robustness under finite-sample regimes.", "motivation": "Standard PINNs often fail to achieve accurate convergence in the H1 norm due to boundary approximation errors, necessitating a more stable method.", "method": "SSBE redefines boundary loss using Sobolev norms, incorporating boundary regularity directly into training, with theoretical guarantees for bounded H1 error.", "result": "SSBE outperforms standard PINNs in relative L2 and H1 errors across various PDEs, including high-dimensional settings.", "conclusion": "SSBE provides a principled and practical solution for enhancing gradient fidelity and solution accuracy in neural network-based PDE solvers."}}
{"id": "2508.10344", "pdf": "https://arxiv.org/pdf/2508.10344", "abs": "https://arxiv.org/abs/2508.10344", "authors": ["Thomas Hangelbroek", "Christian Rieger", "Grady B. Wright"], "title": "A Semi-Lagrangian scheme on embedded manifolds using generalized local polynomial reproductions", "categories": ["math.NA", "cs.NA", "65M12, 65M15, 65M25, 41A25, 41A63"], "comment": null, "summary": "We analyze rates of uniform convergence for a class of high-order\nsemi-Lagrangian schemes for first-order, time-dependent partial differential\nequations on embedded submanifolds of $\\mathbb{R}^d$ (including advection\nequations on surfaces) by extending the error analysis of Falcone and Ferretti.\nA central requirement in our analysis is a remapping operator that achieves\nboth high approximation orders and strong stability, a combination that is\nchallenging to obtain and of independent interest. For this task, we propose a\nnovel mesh-free remapping operator based on $\\ell_1$ minimizing generalized\npolynomial reproduction, which uses only point values and requires no\nadditional geometric information from the manifold (such as access to tangent\nspaces or curvature). Our framework also rigorously addresses the numerical\nsolution of ordinary differential equations on manifolds via projection\nmethods. We include numerical experiments that support the theoretical results\nand also suggest some new directions for future research.", "AI": {"tldr": "The paper analyzes uniform convergence rates for high-order semi-Lagrangian schemes on manifolds, introducing a novel mesh-free remapping operator for stability and accuracy.", "motivation": "To address the challenge of achieving high approximation orders and strong stability in solving PDEs on manifolds, particularly for advection equations on surfaces.", "method": "Extends Falcone and Ferretti's error analysis, proposes a mesh-free remapping operator using \u21131 minimizing generalized polynomial reproduction, and includes numerical experiments.", "result": "Theoretical results are supported by numerical experiments, demonstrating the effectiveness of the proposed remapping operator.", "conclusion": "The framework advances the numerical solution of PDEs and ODEs on manifolds, with potential for future research directions."}}
{"id": "2508.10121", "pdf": "https://arxiv.org/pdf/2508.10121", "abs": "https://arxiv.org/abs/2508.10121", "authors": ["Sergei Avdonin", "Julian Edward"], "title": "An inverse problem on a metric graph with cycle", "categories": ["math.AP", "math.OC", "math.SP", "35R30 (primary), 35L05, 93B05 (secondary)"], "comment": null, "summary": "Consider a quantum graph consisting of a ring with two attached edges, and\nassume Kirchhoff-Neumann conditions hold at the internal vertices. Associated\nto this graph is a Schr\\\"{o}dinger type operator $L=-\\Delta +q(x)$ with\nDirichlet boundary conditions at the two boundary nodes. Let $\\{ \\omega_n^2, \\\n\\varphi_n(x)\\}$ be the eigenvalues and associated normalized eigenfunctions.\nLet $v_1$ be a boundary vertex, and $v_2$ the adjacent internal vertex. Assume\nwe know the following data: $\\{ \\omega_n^2,\\partial_x\n\\varphi_n(v_1),\\partial_x\\varphi_n(v_2)\\}.$ Here $\\partial_x\\varphi_n(v_2)$\nrefers to an outward normal derivative at $v_2$ along one of the edges incident\nto the other internal vertex. From this data we determine the following unknown\nquantities: the lengths of edges and the potential functions on each edge.", "AI": {"tldr": "The paper analyzes a quantum graph with a ring and two edges, using given spectral data to determine edge lengths and potential functions.", "motivation": "To solve the inverse problem of determining unknown geometric and potential properties of a quantum graph from partial spectral data.", "method": "Uses eigenvalues and eigenfunction derivatives at specific vertices to reconstruct edge lengths and potential functions.", "result": "Demonstrates that the given spectral data is sufficient to uniquely determine the edge lengths and potential functions.", "conclusion": "The approach successfully solves the inverse problem for the described quantum graph configuration."}}
{"id": "2508.10277", "pdf": "https://arxiv.org/pdf/2508.10277", "abs": "https://arxiv.org/abs/2508.10277", "authors": ["Yi Huang", "Bowen Zheng", "Yunxi Dong", "Hong Tang", "Huan Zhao", "Rakibul Hasan Shawon", "Sensong An", "Hualiang Zhang"], "title": "MCP-Enabled LLM for Meta-optics Inverse Design: Leveraging Differentiable Solver without LLM Expertise", "categories": ["physics.comp-ph", "physics.optics"], "comment": null, "summary": "Automatic differentiation (AD) enables powerful metasurface inverse design\nbut requires extensive theoretical and programming expertise. We present a\nModel Context Protocol (MCP) assisted framework that allows researchers to\nconduct inverse design with differentiable solvers through large language\nmodels (LLMs). Since LLMs inherently lack knowledge of specialized solvers, our\nproposed solution provides dynamic access to verified code templates and\ncomprehensive documentation through dedicated servers. The LLM autonomously\naccesses these resources to generate complete inverse design codes without\nprescribed coordination rules. Evaluation on the Huygens meta-atom design task\nwith the differentiable TorchRDIT solver shows that while both natural language\nand structured prompting strategies achieve high success rates, structured\nprompting significantly outperforms in design quality, workflow efficiency,\ncomputational cost, and error reduction. The minimalist server design, using\nonly 5 APIs, demonstrates how MCP makes sophisticated computational tools\naccessible to researchers without programming expertise, offering a\ngeneralizable integration solution for other scientific tasks.", "AI": {"tldr": "A framework using Model Context Protocol (MCP) and LLMs simplifies inverse design for metasurfaces by providing verified code templates and documentation, outperforming natural language prompting in efficiency and quality.", "motivation": "To make automatic differentiation (AD) and inverse design accessible to researchers without extensive programming or theoretical expertise.", "method": "Proposes an MCP-assisted framework where LLMs dynamically access verified code templates and documentation to generate inverse design codes, evaluated using the TorchRDIT solver.", "result": "Structured prompting outperforms natural language in design quality, efficiency, computational cost, and error reduction.", "conclusion": "MCP enables accessible and efficient inverse design, generalizable to other scientific tasks with minimal server requirements."}}
{"id": "2508.10513", "pdf": "https://arxiv.org/pdf/2508.10513", "abs": "https://arxiv.org/abs/2508.10513", "authors": ["Andreas Mueller"], "title": "Product Of Exponentials (POE) Splines on Lie-Groups: Limitations, Extensions, and Application to SO(3) and SE(3)", "categories": ["math.NA", "cs.NA", "math.DG", "math.GR"], "comment": null, "summary": "Existing methods for constructing splines and Bezier curves on a Lie group G\ninvolve repeated products of exponentials deduced from local geodesics, w.r.t.\na Riemannian metric, or rely on general polynomials. Moreover, each of these\nlocal curves is supposed to start at the identity of $G$. Both assumptions may\nnot reflect the actual curve to be interpolated. This paper pursues a different\napproach to construct splines on $G$. Local curves are expressed as solutions\nof the Poisson equation on G. Therewith, the local interpolations satisfies the\nboundary conditions while respecting the geometry of $G$. A $k$th-order\napproximation of the solutions gives rise to a $k$th-order product of\nexponential (POE) spline. Algorithms for constructing 3rd- and 4th-order\nsplines are derived from closed form expressions for the approximate solutions.\nAdditionally, spline algorithms are introduced that allow prescribing a vector\nfield the curve must follow at the interpolation points. It is shown that the\nestablished algorithms, where $k$th-order POE-splines are constructed by\nconcatenating local curves starting at the identity, cannot exactly reconstruct\na $k$th-order motion. To tackle this issue, the formulations are extended by\nallowing for local curves between arbitrary points, rather than curves\nemanating from the identity. This gives rise to a global $k$th-order spline\nwith arbitrary initial conditions. Several examples are presented, in\nparticular the shape reconstruction of slender rods modeled as geometrically\nnon-linear Cosserat rods.", "AI": {"tldr": "The paper introduces a new method for constructing splines on Lie groups using solutions of the Poisson equation, addressing limitations of existing methods that rely on local geodesics or polynomials starting at the identity. It provides algorithms for 3rd- and 4th-order splines and extends formulations for arbitrary initial conditions.", "motivation": "Existing methods for spline construction on Lie groups rely on restrictive assumptions (e.g., starting at the identity) and may not accurately reflect the desired curve. This paper aims to overcome these limitations by leveraging the Poisson equation.", "method": "Local curves are derived as solutions of the Poisson equation on the Lie group, ensuring boundary conditions and geometric fidelity. Closed-form expressions enable 3rd- and 4th-order spline algorithms, with extensions for arbitrary initial conditions.", "result": "The proposed method produces higher-order splines that respect the group's geometry and boundary conditions. It outperforms existing methods in reconstructing motions, as demonstrated with examples like Cosserat rods.", "conclusion": "The Poisson equation-based approach offers a flexible and accurate framework for spline construction on Lie groups, overcoming limitations of traditional methods and enabling applications like shape reconstruction."}}
{"id": "2508.10254", "pdf": "https://arxiv.org/pdf/2508.10254", "abs": "https://arxiv.org/abs/2508.10254", "authors": ["David M. Ambrose", "Ryan Aschoff", "Elaine Cozzi", "James P. Kelliher"], "title": "Non-Decaying Solutions to the 2D Dissipative Quasi-Geostrophic Equations", "categories": ["math.AP"], "comment": null, "summary": "We consider the surface quasi-geostrophic equation in two spatial dimensions,\nwith subcritical diffusion (i.e. with fractional diffusion of order $2\\alpha$\nfor $\\alpha>\\frac{1}{2}$.) We establish existence of solutions without assuming\neither decay at spatial infinity or spatial periodicity. One obstacle is that\nfor $L^{\\infty}$ data, the constitutive law may not be applicable, as Riesz\ntransforms are unbounded. However, for $L^{\\infty}$ initial data for which the\nconstitutive law does converge, we demonstrate that there exists a unique\nsolution locally in time, and that the constitutive law continues to hold at\npositive times. In the case that $\\alpha\\in(\\frac{1}{2},1]$ and that the\ninitial data has some smoothness (specifically, if the data is in $C^{2}$), we\ndemonstrate a maximum principle and show that this unique solution is actually\nclassical and global in time. Then, a density argument allows us to show that\nmild solutions with only $L^{\\infty}$ data are also global in time, and also\npossess this maximum principle. Finally, we introduce a related problem in\nwhich we replace the usual constitutive law for the surface quasi-geostrophic\nequation with a generalization of Sertfati type, and prove the same results for\nthis relaxed model.", "AI": {"tldr": "The paper studies the 2D surface quasi-geostrophic equation with subcritical diffusion, proving existence, uniqueness, and global solutions under specific conditions, including a maximum principle and extension to $L^{\\infty}$ data.", "motivation": "To address the challenges of solving the surface quasi-geostrophic equation without decay or periodicity assumptions, especially for $L^{\\infty}$ data where Riesz transforms are unbounded.", "method": "Analyzes solutions under subcritical diffusion, uses smoothness assumptions for classical solutions, and employs a density argument for $L^{\\infty}$ data. Introduces a relaxed model with generalized constitutive law.", "result": "Existence of unique local solutions for $L^{\\infty}$ data, global classical solutions for smooth data, and extension to $L^{\\infty}$ data via density. Maximum principle holds.", "conclusion": "The paper successfully extends solutions to broader data classes and introduces a relaxed model with similar properties, advancing understanding of the quasi-geostrophic equation."}}
{"id": "2508.10454", "pdf": "https://arxiv.org/pdf/2508.10454", "abs": "https://arxiv.org/abs/2508.10454", "authors": ["Qi Zhou", "Teng Wu", "Jianghao Liu", "Qingyuan Sun", "Hehu Xie", "Zhenli Xu"], "title": "Sum-of-Gaussians tensor neural networks for high-dimensional Schr\u00f6dinger equation", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "35Q40, 65D40, 65N25, 68W25, 68W40"], "comment": "22 pages, 6 figures", "summary": "We propose an accurate, efficient, and low-memory sum-of-Gaussians tensor\nneural network (SOG-TNN) algorithm for solving the high-dimensional\nSchr\\\"odinger equation. The SOG-TNN utilizes a low-rank tensor product\nrepresentation of the solution to overcome the curse of dimensionality\nassociated with high-dimensional integration. To handle the Coulomb\ninteraction, we introduce an SOG decomposition to approximate the interaction\nkernel such that it is dimensionally separable, leading to a tensor\nrepresentation with rapid convergence. We further develop a range-splitting\nscheme that partitions the Gaussian terms into short-, long-, and mid-range\ncomponents. They are treated with the asymptotic expansion, the low-rank\nChebyshev expansion, and the model reduction with singular-value decomposition,\nrespectively, significantly reducing the number of two-dimensional integrals in\ncomputing electron-electron interactions. The SOG decomposition well resolves\nthe computational challenge due to the singularity of the Coulomb interaction,\nleading to an efficient algorithm for the high-dimensional problem under the\nTNN framework. Numerical results demonstrate the outstanding performance of the\nnew method, revealing that the SOG-TNN is a promising way for tackling large\nand complex quantum systems.", "AI": {"tldr": "The paper introduces SOG-TNN, a sum-of-Gaussians tensor neural network for solving high-dimensional Schr\u00f6dinger equations efficiently, overcoming dimensionality challenges with low-rank tensor representations and SOG decomposition.", "motivation": "High-dimensional Schr\u00f6dinger equations are computationally challenging due to the curse of dimensionality and singular Coulomb interactions. The goal is to develop an efficient, accurate, and low-memory method.", "method": "SOG-TNN uses low-rank tensor product representations and SOG decomposition for Coulomb interactions. A range-splitting scheme divides Gaussian terms into short-, long-, and mid-range components, each treated with specialized techniques (asymptotic expansion, Chebyshev expansion, SVD).", "result": "Numerical results show SOG-TNN performs outstandingly, efficiently handling high-dimensional problems and resolving Coulomb interaction challenges.", "conclusion": "SOG-TNN is a promising method for large, complex quantum systems, offering accuracy, efficiency, and reduced computational costs."}}
{"id": "2508.10547", "pdf": "https://arxiv.org/pdf/2508.10547", "abs": "https://arxiv.org/abs/2508.10547", "authors": ["Hameed Ullah Jan", "Marjan Uddin", "Irshad Ali Shah", "Salam Ullah Khan"], "title": "On The Eventual Periodicity of Fractional Order Dispersive Wave Equations Using RBFs and Transform", "categories": ["math.NA", "cs.NA", "34K28, 35G61, 35Q53, 34A08, 34K13"], "comment": "16 pages, 9 figures", "summary": "In this research work, let us focus on the construction of numerical scheme\nbased on radial basis functions finite difference (RBF-FD) method combined with\nthe Laplace transform for the solution of fractional order dispersive wave\nequations. The numerical scheme is then applied to examine the eventual\nperiodicity of the proposed model subject to the periodic boundary conditions.\nThe implementation of proposed technique for high order fractional and integer\ntype nonlinear partial differential equations (PDEs) is beneficial because this\nmethod is local in nature, therefore it yields and resulted in sparse\ndifferentiation matrices instead of full and dense matrices. Only small\ndimensions of linear systems of equations are to be solved for every center in\nthe domain and hence this procedure is more reliable and efficient to solve\nlarge scale physical and engineering problems in complex domain. Laplace\ntransform is utilized for obtaining the equivalent time-independent equation in\nLaplace space and also valuable to handle time-fractional derivatives in the\nCaputo sense. Application of Laplace transform avoids the time steeping\nprocedure which commonly encounters the time instability issues. The solution\nto the transformed model is then obtained by computing the inversion of Laplace\ntransform with an appropriate contour in a complex space, which is approximated\nby trapezoidal rule with high accuracy. Also since the Laplace transform\noperator is linear, it cannot be used to transform non-linear terms therefore\nlet us use a linearization approach and an appropriate iterative scheme. The\nproposed approach is tasted for some nonlinear fractional order KdV and Burgers\nequations. The capacity, high order accuracy and efficiency of our approach are\ndemonstrated using examples and results", "AI": {"tldr": "The paper presents a numerical scheme combining radial basis functions finite difference (RBF-FD) with Laplace transform to solve fractional order dispersive wave equations, focusing on efficiency and accuracy.", "motivation": "To address the challenges of solving high-order fractional and integer-type nonlinear PDEs efficiently, especially in complex domains, by leveraging local methods and avoiding time instability issues.", "method": "Uses RBF-FD for spatial discretization and Laplace transform to handle time-fractional derivatives, avoiding time-stepping. Linearization and iterative schemes address nonlinear terms.", "result": "Demonstrates high accuracy and efficiency in solving nonlinear fractional KdV and Burgers equations, with sparse matrices for computational reliability.", "conclusion": "The proposed method is reliable, efficient, and scalable for large-scale problems, offering a robust alternative to traditional approaches."}}
{"id": "2508.10314", "pdf": "https://arxiv.org/pdf/2508.10314", "abs": "https://arxiv.org/abs/2508.10314", "authors": ["Tatsuya Miura", "Kensuke Yoshizawa"], "title": "Stability of flat-core pinned p-elasticae", "categories": ["math.AP", "math.DG", "49Q10 and 53A04"], "comment": "12 pages, 3 figures", "summary": "We classify the stability of flat-core $p$-elasticae in $\\mathbf{R}^d$\nsubject to the pinned boundary condition. Together with previous work, this\ncompletes the classification of stable pinned $p$-elasticae in $\\mathbf{R}^d$\nfor all $p\\in(1,\\infty)$ and $d\\geq2$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.10515", "pdf": "https://arxiv.org/pdf/2508.10515", "abs": "https://arxiv.org/abs/2508.10515", "authors": ["Andrea Urgolo", "Monika Stipsitz", "Helios Sanchis-Alepuz"], "title": "Virtual Sensing for Solder Layer Degradation and Temperature Monitoring in IGBT Modules", "categories": ["physics.comp-ph", "cs.CE", "cs.LG", "cs.SY", "eess.SY"], "comment": "Andrea Urgolo and Monika Stipsitz contributed equally to this work", "summary": "Monitoring the degradation state of Insulated Gate Bipolar Transistor (IGBT)\nmodules is essential for ensuring the reliability and longevity of power\nelectronic systems, especially in safety-critical and high-performance\napplications. However, direct measurement of key degradation indicators - such\nas junction temperature, solder fatigue or delamination - remains challenging\ndue to the physical inaccessibility of internal components and the harsh\nenvironment. In this context, machine learning-based virtual sensing offers a\npromising alternative by bridging the gap from feasible sensor placement to the\nrelevant but inaccessible locations. This paper explores the feasibility of\nestimating the degradation state of solder layers, and the corresponding full\ntemperature maps based on a limited number of physical sensors. Based on\nsynthetic data of a specific degradation mode, we obtain a high accuracy in the\nestimation of the degraded solder area (1.17% mean absolute error), and are\nable to reproduce the surface temperature of the IGBT with a maximum relative\nerror of 4.56% (corresponding to an average relative error of 0.37%).", "AI": {"tldr": "The paper proposes a machine learning-based virtual sensing method to estimate IGBT module degradation and temperature maps using limited physical sensors, achieving high accuracy.", "motivation": "Direct measurement of IGBT degradation indicators is challenging due to physical inaccessibility and harsh environments, necessitating alternative methods.", "method": "Uses synthetic data and machine learning to estimate solder layer degradation and temperature maps from limited sensor inputs.", "result": "Achieves 1.17% mean absolute error in degraded solder area estimation and 4.56% maximum relative error in temperature reproduction.", "conclusion": "Machine learning-based virtual sensing is feasible for accurate IGBT degradation monitoring, offering a practical solution for inaccessible indicators."}}
{"id": "2508.10558", "pdf": "https://arxiv.org/pdf/2508.10558", "abs": "https://arxiv.org/abs/2508.10558", "authors": ["Marjan Uddin", "Hameed Ullah Jan", "Muhammad Usman"], "title": "RBF-FD Method for Some Dispersive Wave Equations and Their Eventual Periodicity", "categories": ["math.NA", "cs.NA", "33F05, 34K10, 34K13, 34K28, 35Q51, 35Q53"], "comment": "23 pages, 10 figures", "summary": "In this paper, we approximate the solution and also discuss the periodic\nbehavior termed as eventual periodicity of solutions of (IBVPs) for some\ndispersive wave equations on a bounded domain corresponding to periodic\nforcing. The constructed numerical scheme is based on radial kernels and local\nin nature like finite difference method. The temporal variable is executed\nthrough RK4 scheme. Due to the local nature and sparse differentiation matrices\nour numerical scheme efficiently recovers the solution. The results achieved\nare validated and examined with other methods accessible in the literature.", "AI": {"tldr": "The paper approximates solutions and analyzes eventual periodicity for dispersive wave equations with periodic forcing, using a local numerical scheme based on radial kernels and RK4 for time integration.", "motivation": "To study the periodic behavior (eventual periodicity) of solutions for dispersive wave equations under periodic forcing on bounded domains.", "method": "A numerical scheme using radial kernels (local like finite difference) and RK4 for temporal integration, leveraging sparse differentiation matrices.", "result": "The scheme efficiently recovers solutions, validated against existing methods in literature.", "conclusion": "The proposed method is effective for solving IBVPs of dispersive wave equations with periodic forcing."}}
{"id": "2508.10347", "pdf": "https://arxiv.org/pdf/2508.10347", "abs": "https://arxiv.org/abs/2508.10347", "authors": ["Josh Culver", "Aubrey Ayres", "Evan Halloran", "Ryan Lin", "Emily Peng", "Charis Tsikkou"], "title": "An Analysis of the Riemann Problem for a $2 \\times 2$ System of Keyfitz-Kranzer Type Balance Laws With a Time-Dependent Source Term", "categories": ["math.AP", "math-ph", "math.CA", "math.DS", "math.MP", "34A05, 34C37, 34C45, 34E15, 35L45, 35L65, 35L67, 35L80, 35Q92,\n  65M06, 74L10, 76A30"], "comment": "35 pages. arXiv admin note: text overlap with arXiv:2508.05927", "summary": "We consider a system consisting of one conservation law and one balance law\nwith a time-dependent source term, and provide a comprehensive analysis of\nRiemann solutions, including the non-classical overcompressive delta shocks.\nThe minimal yet representative structure of the system captures essential\nfeatures of transport under density constraints and, despite its simplicity,\nserves as a versatile prototype for crowd-limited transport processes across\ndiverse contexts, including biological aggregation, ecological dispersal,\ngranular compaction, and traffic congestion. In addition to non-self-similar\nsolutions mentioned above, the associated Riemann problem admits solution\nstructures that traverse vacuum states ($\\rho = 0$) and the critical density\nthreshold ($\\rho = \\bar{\\rho}$), where mobility vanishes and characteristic\nspeed degenerates. Moreover, the explicit time dependence in the source term\nleads to the breakdown of self-similarity, resulting in distinct Riemann\nsolutions over successive time intervals and highlighting the dynamic nature of\nthe solution landscape. The theoretical findings are numerically confirmed\nusing the Local Lax-Friedrichs scheme.", "AI": {"tldr": "The paper analyzes Riemann solutions for a system of conservation and balance laws with a time-dependent source term, focusing on non-classical delta shocks, vacuum states, and critical density thresholds.", "motivation": "To understand transport processes under density constraints, applicable to biological aggregation, traffic congestion, and more.", "method": "Comprehensive analysis of Riemann solutions, including non-self-similar structures, and numerical validation using the Local Lax-Friedrichs scheme.", "result": "Discovery of diverse solution structures, including delta shocks and dynamic solutions due to the time-dependent source term.", "conclusion": "The system serves as a versatile prototype for density-constrained transport, with theoretical insights confirmed numerically."}}
{"id": "2508.10555", "pdf": "https://arxiv.org/pdf/2508.10555", "abs": "https://arxiv.org/abs/2508.10555", "authors": ["Haoran Sun", "Daoqi Liu", "Hongyu Zhou", "Maokun Li", "Shenheng Xu", "Fan Yang"], "title": "Physics-Informed Deep Contrast Source Inversion: A Unified Framework for Inverse Scattering Problems", "categories": ["physics.comp-ph", "cs.CE", "cs.LG"], "comment": null, "summary": "Inverse scattering problems are critical in electromagnetic imaging and\nmedical diagnostics but are challenged by their nonlinearity and diverse\nmeasurement scenarios. This paper proposes a physics-informed deep contrast\nsource inversion framework (DeepCSI) for fast and accurate medium\nreconstruction across various measurement conditions. Inspired by contrast\nsource inversion (CSI) and neural operator methods, a residual multilayer\nperceptron (ResMLP) is employed to model current distributions in the region of\ninterest under different transmitter excitations, effectively linearizing the\nnonlinear inverse scattering problem and significantly reducing the\ncomputational cost of traditional full-waveform inversion. By modeling medium\nparameters as learnable tensors and utilizing a hybrid loss function that\nintegrates state equation loss, data equation loss, and total variation\nregularization, DeepCSI establishes a fully differentiable framework for joint\noptimization of network parameters and medium properties. Compared with\nconventional methods, DeepCSI offers advantages in terms of simplicity and\nuniversal modeling capabilities for diverse measurement scenarios, including\nphase-less and multi-frequency observation. Simulations and experiments\ndemonstrate that DeepCSI achieves high-precision, robust reconstruction under\nfull-data, phaseless data, and multifrequency conditions, outperforming\ntraditional CSI methods and providing an efficient and universal solution for\ncomplex inverse scattering problems.", "AI": {"tldr": "DeepCSI is a physics-informed deep learning framework for fast and accurate inverse scattering problem solving, outperforming traditional methods.", "motivation": "Addressing the challenges of nonlinearity and diverse measurement scenarios in inverse scattering problems for electromagnetic imaging and medical diagnostics.", "method": "Uses a residual multilayer perceptron (ResMLP) to model current distributions, linearizing the problem. Combines state equation loss, data equation loss, and total variation regularization in a hybrid loss function.", "result": "Achieves high-precision, robust reconstruction under various conditions (full-data, phaseless, multi-frequency), outperforming traditional CSI methods.", "conclusion": "DeepCSI provides an efficient, universal solution for complex inverse scattering problems, simplifying and improving accuracy."}}
{"id": "2508.10570", "pdf": "https://arxiv.org/pdf/2508.10570", "abs": "https://arxiv.org/abs/2508.10570", "authors": ["Ramsharan Rangarajan", "N. Sukumar"], "title": "CutVEM: Conforming virtual element method on embedded domains with shape-agnostic element agglomeration", "categories": ["math.NA", "cs.NA"], "comment": "35 pages, 20 figures", "summary": "The virtual element method (VEM) is a stabilized Galerkin method that is\nrobust and accurate on general polygonal meshes. This feature makes it an\nappealing candidate for simulations involving meshes with embedded interfaces\nand evolving geometries. However, the method can yield poorly conditioned\nstiffness matrices in such scenarios due to meshes having cut cells. We propose\na novel element agglomeration algorithm for the virtual element method to\naddress this issue. The agglomeration algorithm renders the VEM robust over\nplanar polygonal meshes, particularly on finite element meshes cut by immersed\ngeometries. The algorithm relies on the element stability ratio, which we\ndefine using the extreme eigenvalues of the element stiffness matrix. The\nresulting element agglomeration criterion is free from nebulous polygon quality\nmetrics and is defined independently of polygon shapes. The algorithm proceeds\niteratively and element-wise to maximize the minimum element stability ratio,\neven at the expense of degrading elements with better ratios. Crucially,\nelement agglomeration alters the number of elements, not the degree of freedom\ncount. The resulting method, which we label as CutVEM, retains node locations\nof cut elements unchanged, and yields discretizations that conform to embedded\ninterfaces. This, in turn, facilitates straightforward imposition of boundary\nconditions and interfacial constraints. Through detailed numerical experiments\nthat sample varied element-interface intersections, we demonstrate that CutVEM\nenjoys dramatically improved condition numbers of global stiffness matrices\nover the VEM. Furthermore, simulations of prototypical heat conduction problems\nwith Dirichlet and Neumann boundary conditions on domains with immersed\ngeometries show that element agglomeration does not noticeably degrade solution\naccuracy and that CutVEM retains the VEM's optimal convergence rate.", "AI": {"tldr": "The paper introduces CutVEM, a novel element agglomeration algorithm for the virtual element method (VEM), improving robustness on polygonal meshes with cut cells while maintaining accuracy and optimal convergence.", "motivation": "The VEM is robust on general polygonal meshes but suffers from poor conditioning in scenarios with cut cells due to embedded interfaces. This work aims to address this limitation.", "method": "The proposed CutVEM uses an element agglomeration algorithm based on the element stability ratio, iteratively optimizing mesh stability without altering degrees of freedom.", "result": "CutVEM significantly improves the condition numbers of stiffness matrices and retains the VEM's accuracy and convergence rates in numerical experiments.", "conclusion": "CutVEM effectively addresses the conditioning issues of VEM on cut-cell meshes, making it a robust choice for simulations involving evolving geometries and embedded interfaces."}}
{"id": "2508.10387", "pdf": "https://arxiv.org/pdf/2508.10387", "abs": "https://arxiv.org/abs/2508.10387", "authors": ["Giusi Vaira"], "title": "Blow-up phenomena for a boundary Yamabe problem with umbilic boundary", "categories": ["math.AP"], "comment": null, "summary": "We consider a linear perturbation of the classical geometric problem of\nprescribing the scalar and the boundary mean curvature problem in a Riemannian\nmanifold with umbilic boundary provided the Weyl tensor is non-zero everywhere.\nWe will deal with the case of negative scalar curvature showing the existence\nof a positive solutions when $n\\geq 8$.", "AI": {"tldr": "Existence of positive solutions for a linear perturbation of the scalar and boundary mean curvature problem in Riemannian manifolds with umbilic boundary, under non-zero Weyl tensor and negative scalar curvature for dimensions \u22658.", "motivation": "To address the classical geometric problem of prescribing scalar and boundary mean curvature in a Riemannian manifold, extending it with a linear perturbation under specific conditions.", "method": "Analyzes the problem in a Riemannian manifold with umbilic boundary, assuming non-zero Weyl tensor and negative scalar curvature, focusing on dimensions \u22658.", "result": "Demonstrates the existence of positive solutions for the perturbed problem in dimensions \u22658.", "conclusion": "The study confirms the feasibility of positive solutions under the given geometric constraints, particularly for higher dimensions."}}
{"id": "2508.10237", "pdf": "https://arxiv.org/pdf/2508.10237", "abs": "https://arxiv.org/abs/2508.10237", "authors": ["Ray Yang", "Junchi Chen", "Douglas Thibodeaux", "Robert B. Wexler"], "title": "FreeBird.jl: An Extensible Toolbox for Simulating Interfacial Phase Equilibria", "categories": ["cond-mat.stat-mech", "cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph"], "comment": "17 pages, 5 figures", "summary": "We present FreeBird.jl, an extensible Julia-based platform for computational\nstudies of phase equilibria at generic interfaces. The package supports a range\nof system configurations, from atomistic solid surfaces to coarse-grained\nlattice$-$gas models, with energies evaluated using classical interatomic\npotentials or lattice Hamiltonians. Both atomistic and lattice systems\naccommodate single- or multi-component mixtures with flexibly definable surface\nand lattice geometries. Implemented sampling algorithms include nested\nsampling, Wang$-$Landau sampling, Metropolis Monte Carlo, and, for tractable\nlattice systems, exact enumeration. Leveraging Julia's type hierarchies and\nmultiple dispatch, FreeBird.jl provides a modular interface that allows\nseamless integration of system definitions, energy evaluators, and sampling\nschemes. Designed for flexibility, extensibility, and performance, FreeBird.jl\noffers a versatile framework for exploring the thermodynamics of interfacial\nphenomena.", "AI": {"tldr": "FreeBird.jl is a Julia-based platform for studying phase equilibria at interfaces, supporting various system configurations and sampling algorithms.", "motivation": "To provide a flexible and extensible tool for computational studies of interfacial thermodynamics.", "method": "Uses Julia's type hierarchies and multiple dispatch for modular integration of system definitions, energy evaluators, and sampling schemes (e.g., nested sampling, Wang-Landau, Metropolis Monte Carlo).", "result": "A versatile framework capable of handling atomistic and lattice systems with customizable geometries and multi-component mixtures.", "conclusion": "FreeBird.jl offers a powerful and adaptable solution for exploring interfacial phenomena."}}
{"id": "2508.10578", "pdf": "https://arxiv.org/pdf/2508.10578", "abs": "https://arxiv.org/abs/2508.10578", "authors": ["Brandiece N. Berry", "Md Mahmudul Islam", "Muhammad Mohebujjaman", "Neethu Suma Raveendran"], "title": "Efficient and Optimally Accurate Numerical Algorithms for Stochastic Turbulent Flow Problems", "categories": ["math.NA", "cs.NA", "65M12, 65M22, 65M60, 76W05"], "comment": "26 pages, 8 figures", "summary": "In this paper, we first propose a filter-based continuous Ensemble Eddy\nViscosity (EEV) model for stochastic turbulent flow problems. We then propose a\ngeneric algorithm for a family of fully discrete, grad-div regularized,\nefficient ensemble parameterized schemes for this model. The linearized\nImplicit-Explicit (IMEX) EEV generic algorithm shares a common coefficient\nmatrix for each realization per time-step, but with different right-hand-side\nvectors, which reduces the computational cost and memory requirements to the\norder of solving deterministic flow problems. Two family members of the\nproposed time-stepping algorithm are analyzed and proven to be stable. It is\nfound that one is first-order and the other is second-order accurate in time\nfor any stable finite element pairs. Avoiding the discrete inverse inequality,\nthe optimal convergence of both schemes is proven rigorously for both 2D and 3D\nproblems. For appropriately large grad-div parameters, both schemes are\nunconditionally stable and allow weakly divergence-free elements. Several\nnumerical tests are given for high expected Reynolds number ($\\textbf{E}[Re]$)\nproblems. The convergence rates are verified using manufactured solutions with\n$\\textbf{E}[Re]=10^{3},10^{4},\\;\\text{and}\\; 10^{5}$. For various high\n$\\textbf{E}[Re]$, the schemes are implemented on benchmark problems which\nincludes: A 2D channel flow over a unit step problem, a non-intrusive\nStochastic Collocation Method (SCM) is used to examine the performance of the\nschemes on a 2D Regularized Lid Driven Cavity (RLDC) problem, and a 3D RLDC\nproblem, and found them perform well.", "AI": {"tldr": "Proposed a filter-based EEV model for stochastic turbulent flows and a generic IMEX algorithm for efficient ensemble schemes, proving stability and accuracy for high Reynolds numbers.", "motivation": "Address computational challenges in stochastic turbulent flow problems by reducing cost and memory requirements.", "method": "Developed a linearized IMEX EEV algorithm with shared coefficient matrices and analyzed two stable, accurate time-stepping schemes.", "result": "Proven stability and optimal convergence for 2D/3D problems; validated with high Reynolds number tests.", "conclusion": "The schemes perform well for high Reynolds numbers, offering computational efficiency and accuracy."}}
{"id": "2508.10448", "pdf": "https://arxiv.org/pdf/2508.10448", "abs": "https://arxiv.org/abs/2508.10448", "authors": ["Romain Petrides"], "title": "Regularity estimates on harmonic eigenmaps with arbitrary number of coordinates", "categories": ["math.AP", "math.DG"], "comment": null, "summary": "We revisit the well-established regularity estimates on harmonic maps on\nsurfaces to question their independence with respect to the dimension of the\ntarget manifold. We are mainly interested in harmonic maps into target\nellipsoids, that we call Laplace harmonic eigenmaps. These maps are related to\ncritical metrics in the context of eigenvalue optimization. The tools that we\ngather here are useful to handle convergence of almost critical metrics via\nPalais-Smale sequences of (almost harmonic) eigenmaps. They could also be a\npreliminary step for a general regularity theory for critical points of\ninfinite combinations of eigenvalues.", "AI": {"tldr": "The paper investigates the regularity of harmonic maps on surfaces, focusing on their dependence on the target manifold's dimension, particularly for ellipsoids.", "motivation": "To understand the independence of regularity estimates of harmonic maps with respect to the target manifold's dimension and their connection to eigenvalue optimization.", "method": "The study uses Laplace harmonic eigenmaps (harmonic maps into ellipsoids) and tools for handling convergence of almost critical metrics via Palais-Smale sequences.", "result": "The gathered tools aid in analyzing convergence of almost critical metrics and could support a broader regularity theory for critical points of eigenvalue combinations.", "conclusion": "The findings provide foundational insights for future research on regularity theory for critical points of infinite eigenvalue combinations."}}
{"id": "2508.10380", "pdf": "https://arxiv.org/pdf/2508.10380", "abs": "https://arxiv.org/abs/2508.10380", "authors": ["Qisheng Yu", "Boyu Liu", "Hongjun Xiang", "Shi Liu"], "title": "Type-I Multiferroic VHfO$_4$ with Strain-Switchable Magnetic Orders and Magnetoelectric Coupling", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Motivated by the complementary properties of vanadium-based ferromagnets and\nHfO$_2$-based ferroelectrics, we propose a novel multiferroic oxide, VHfO$_4$,\nthrough 50\\% Hf$^{4+}$ substitution with V$^{4+}$ in the ferroelectric $Pca2_1$\nphase of HfO$_2$. First-principles DFT calculations reveal that the\n$Pca2_1$-like VHfO$_4$ phase exhibits dynamic stability and concurrent ferroic\norders: robust ferroelectric polarization comparable to HfO$_2$ and V-driven\nmagnetism. Parallel tempering Monte Carlo simulations identify an\nantiferromagnetic ground state, while strain engineering enables tunable\nmagnetoelectric coupling. Biaxial in-plane strain induces four magnetic states:\nintralayer FM/interlayer AFM, intralayer AFM/interlayer FM, spiral-like\nnon-collinear order, and discrete alternating spin alignment. Critically,\n$c$-axis strain modulates magnetic energy landscapes, demonstrating\nelectromechanical control of magnetism. This work establishes VHfO$_4$ as a\nType-I multiferroic with coexisting atomic-scale ferroic origins and\nstrain-tunable cross-coupling, offering a platform for voltage-controlled\nspintronics devices.", "AI": {"tldr": "The paper proposes VHfO$_4$ as a novel multiferroic oxide, combining ferroelectricity and magnetism, with strain-tunable magnetoelectric coupling for spintronics applications.", "motivation": "The study is motivated by the complementary properties of vanadium-based ferromagnets and HfO$_2$-based ferroelectrics, aiming to create a material with concurrent ferroic orders.", "method": "First-principles DFT calculations and parallel tempering Monte Carlo simulations are used to analyze dynamic stability, ferroic orders, and strain effects.", "result": "VHfO$_4$ exhibits robust ferroelectric polarization and V-driven magnetism, with strain engineering enabling tunable magnetoelectric coupling and four distinct magnetic states.", "conclusion": "VHfO$_4$ is established as a Type-I multiferroic with atomic-scale ferroic origins and strain-tunable cross-coupling, promising for voltage-controlled spintronics devices."}}
{"id": "2508.10630", "pdf": "https://arxiv.org/pdf/2508.10630", "abs": "https://arxiv.org/abs/2508.10630", "authors": ["Kasper B\u00e5gmark", "Adam Andersson", "Stig Larsson"], "title": "Nonlinear filtering based on density approximation and deep BSDE prediction", "categories": ["math.NA", "cs.NA", "stat.CO", "stat.ML", "60G25, 60G35, 62F15, 62G07, 62M20, 65C30, 65M75, 68T07"], "comment": "19 pages, 6 figures", "summary": "A novel approximate Bayesian filter based on backward stochastic differential\nequations is introduced. It uses a nonlinear Feynman--Kac representation of the\nfiltering problem and the approximation of an unnormalized filtering density\nusing the well-known deep BSDE method and neural networks. The method is\ntrained offline, which means that it can be applied online with new\nobservations. A mixed a priori-a posteriori error bound is proved under an\nelliptic condition. The theoretical convergence rate is confirmed in two\nnumerical examples.", "AI": {"tldr": "A new Bayesian filter using backward stochastic differential equations and neural networks is introduced, with offline training for online application. Theoretical and numerical results confirm its effectiveness.", "motivation": "To develop an efficient Bayesian filter leveraging deep learning and stochastic methods for real-time applications.", "method": "Uses nonlinear Feynman-Kac representation and deep BSDE method with neural networks to approximate filtering density. Trained offline for online use.", "result": "Proves a mixed error bound under elliptic conditions and confirms theoretical convergence in numerical tests.", "conclusion": "The method is effective, with theoretical backing and practical validation."}}
{"id": "2508.10508", "pdf": "https://arxiv.org/pdf/2508.10508", "abs": "https://arxiv.org/abs/2508.10508", "authors": ["Ferdinand Eitler", "Peter Lewintan"], "title": "On $\\mathrm{BV}^{\\mathbb{A}}$-Minimisers in two Dimensions", "categories": ["math.AP", "35B65, 35J60, 49J45, 35A15"], "comment": null, "summary": "We investigate into the regularity of $\\mathrm{BV}^{\\mathbb{A}}$-minimisers\nfor $\\mathbb{C}$-elliptic differential operators $\\mathbb{A}$ in $2$\ndimensions. Our studies strongly rely on the special structure of such\ndifferential operators. The gradient integrability is established for the sharp\nellipticity range known from the (symmetric) gradient case.", "AI": {"tldr": "The paper examines the regularity of BV^\ud835\udd38-minimisers for \u2102-elliptic operators in 2D, leveraging their structure to establish gradient integrability.", "motivation": "To understand the regularity properties of minimisers for \u2102-elliptic differential operators in two dimensions.", "method": "Relies on the special structure of \u2102-elliptic operators and extends techniques from the symmetric gradient case.", "result": "Gradient integrability is proven for the sharp ellipticity range.", "conclusion": "The study confirms regularity for BV^\ud835\udd38-minimisers in the specified ellipticity range."}}
{"id": "2508.10418", "pdf": "https://arxiv.org/pdf/2508.10418", "abs": "https://arxiv.org/abs/2508.10418", "authors": ["Feng-Feng Song", "Naoki Kawashima"], "title": "Variational boundary based tensor network renormalization group", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "comment": "7 pages, 5 figures", "summary": "We propose a real-space renormalization group algorithm for accurately\ncoarse-graining two-dimensional tensor networks. The central innovation of our\nmethod lies in utilizing variational boundary tensors as a globally optimized\nenvironment for the entire system. Based on this optimized environment, we\nconstruct renormalization projectors that significantly enhance accuracy. By\nleveraging the canonical form of tensors, our algorithm maintains the same\ncomputational complexity as the original tensor renormalization group (TRG)\nmethod, yet achieves higher accuracy than existing approaches that do not\nincorporate entanglement filtering. Our work offers a practical pathway for\nextending TRG methods to higher dimensions while keeping computational costs\nmanageable.", "AI": {"tldr": "A real-space renormalization group algorithm for 2D tensor networks uses variational boundary tensors for global optimization, improving accuracy without increasing computational complexity.", "motivation": "To enhance the accuracy of tensor renormalization group (TRG) methods in higher dimensions while maintaining manageable computational costs.", "method": "Utilizes variational boundary tensors for global optimization and constructs renormalization projectors based on this environment, leveraging tensor canonical forms.", "result": "Achieves higher accuracy than existing TRG methods without entanglement filtering, with the same computational complexity.", "conclusion": "Provides a practical approach for extending TRG to higher dimensions efficiently."}}
{"id": "2508.10648", "pdf": "https://arxiv.org/pdf/2508.10648", "abs": "https://arxiv.org/abs/2508.10648", "authors": ["Hugo M. Verhelst", "Angelos Mantzaflaris", "Matthias M\u00f6ller"], "title": "Isogeometric multi-patch shell analysis using the Geometry + Simulation Modules", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Isogeometric Analysis (IGA) bridges Computer-Aided Design (CAD) and Finite\nElement Analysis (FEA) by employing splines as a common basis for geometry and\nanalysis. One of the advantages of IGA is in the realm of thin shell analysis:\ndue to the arbitrary continuity of the spline basis, Kirchhoff-Love shells can\nbe modeled without the need to introduce unknowns for the mid-plane rotations,\nleading to a reduction in the number of unknowns. In this paper, we provide the\nbackground of an implementation of Isogeometric Kirchhoff--Love shells within\nthe Geometry + Simulation Modules (G+Smo). This paper accompanies multiple\nprevious publications and elaborates on the design of the software used in\nthese papers, rather than the novelty of the methods presented therein. The\npresented implementation provides patch coupling via penalty methods and\nunstructured splines, goal-oriented error estimators, several algorithms for\nstructural analysis and advanced algorithms for the modeling of wrinkling in\nhyperelastic membranes. These methods are all contained in three new modules in\nG+Smo: a module for Kirchhoff-Love shells, a module for structural analysis,\nand a module for unstructured spline constructions. As motivated in this paper,\nthe modules are implemented to be compatible with future developments. For\nexample, by providing base implementations of material laws, by using black-box\nfunctions for the structural analysis module, or by providing a standardized\napproach for the implementation of unstructured spline constructions. Overall,\nthis paper demonstrates that the new modules contribute to a versatile\necosystem for the modeling of multi-patch shell problems through fast\noff-the-shelf solvers with a simple interface, designed to be extended in\nfuture research.", "AI": {"tldr": "The paper details the implementation of Isogeometric Kirchhoff-Love shells in G+Smo, focusing on software design and compatibility for future extensions.", "motivation": "To bridge CAD and FEA using splines, particularly for thin shell analysis, and to provide a versatile ecosystem for multi-patch shell problems.", "method": "Implementation includes patch coupling via penalty methods, unstructured splines, goal-oriented error estimators, and advanced algorithms for wrinkling in hyperelastic membranes.", "result": "Three new modules in G+Smo (Kirchhoff-Love shells, structural analysis, unstructured splines) enable fast, extendable solvers for shell modeling.", "conclusion": "The modules enhance G+Smo's versatility for shell problems and are designed for future research extensions."}}
{"id": "2508.10690", "pdf": "https://arxiv.org/pdf/2508.10690", "abs": "https://arxiv.org/abs/2508.10690", "authors": ["Filomena De Filippis", "Antonella Nastasi", "Cintia Pacchiano Camacho"], "title": "Vectorial Double Phase Obstacle Problems", "categories": ["math.AP"], "comment": null, "summary": "We investigate partial regularity for vector valued local minimizers of\ndouble phase functionals, under vectorial obstacle type constraints satisfying\nappropriate topological properties.", "AI": {"tldr": "Study of partial regularity for vector-valued minimizers of double phase functionals under vectorial obstacle constraints.", "motivation": "To understand the regularity properties of minimizers in constrained optimization problems involving double phase functionals.", "method": "Analysis of vector-valued local minimizers under topological constraints for double phase functionals.", "result": "Partial regularity results are derived for the minimizers under the given constraints.", "conclusion": "The study provides insights into the regularity of solutions in constrained double phase functional problems."}}
{"id": "2508.10422", "pdf": "https://arxiv.org/pdf/2508.10422", "abs": "https://arxiv.org/abs/2508.10422", "authors": ["Ludovico Foss\u00e0", "Pierre Ricco"], "title": "Compressible boundary layers over isotropic porous surfaces", "categories": ["physics.flu-dyn", "physics.app-ph", "physics.comp-ph", "76J20, 76N20, 76S05"], "comment": null, "summary": "A compressible laminar boundary layer developing over an isotropic porous\nsubstrate is investigated by asymptotic and numerical methods. The substrate is\nmodeled as an array of cubes. The momentum and enthalpy balance equations are\nderived by volume averaging. The self-similar solution proposed by Tsiberkin\n(2018) [Transp. Porous Media 121(1):109-120] for streamwise-growing\npermeability is extended to include compressibility, heat conduction and a\nnonlinear drag. The velocity profile shows an inflection point at the free\nfluid-porous interfacial layer, below which it decreases to zero. A marked\nreduction of the adiabatic recovery temperature of the fluid and the velocity\ngradient at the interface is observed for high porosity, large grains and\nrelatively high Mach numbers. The temperature imposed at the bottom of the\nporous substrate has a negligible influence on the shear stresses.", "AI": {"tldr": "The paper studies a compressible laminar boundary layer over an isotropic porous substrate using asymptotic and numerical methods, extending Tsiberkin's self-similar solution to include compressibility, heat conduction, and nonlinear drag.", "motivation": "To understand the behavior of compressible laminar boundary layers over porous substrates, including effects like heat conduction and nonlinear drag.", "method": "Asymptotic and numerical methods are used, with the porous substrate modeled as an array of cubes. Momentum and enthalpy balance equations are derived via volume averaging.", "result": "The velocity profile shows an inflection point at the interface, with reduced adiabatic recovery temperature and velocity gradient for high porosity, large grains, and high Mach numbers. Bottom temperature has negligible impact on shear stresses.", "conclusion": "The study extends existing solutions and highlights key influences of porosity, grain size, and Mach number on boundary layer behavior."}}
{"id": "2508.10674", "pdf": "https://arxiv.org/pdf/2508.10674", "abs": "https://arxiv.org/abs/2508.10674", "authors": ["Wei Chen", "Xinyuan Du", "Jun Hu"], "title": "The Hu-Zhang element for linear elasticity on curved domains", "categories": ["math.NA", "cs.NA", "65N12, 65N30, 74S05"], "comment": null, "summary": "This paper extends the Hu-Zhang element for linear elasticity problems to\ncurved domains, preserving strong symmetry and H(div)-conformity. The\nnon-polynomial structure of the curved Hu-Zhang element makes it difficult to\nanalyze the stability result, which is overcome by establishing a novel inf-sup\ncondition. Optimal convergence rates are achieved for all variables except the\nstress $L^2$-error. This suboptimality originates from the fact that the\ndivergence space of the curved Hu-Zhang element is not contained in the\ndiscrete displacement space, which is rectified by local $p$-enrichment in the\nHu-Zhang space on curved boundary elements. Some numerical experiments validate\nthe theoretical results.", "AI": {"tldr": "The paper extends the Hu-Zhang element to curved domains, ensuring symmetry and H(div)-conformity, and addresses stability and convergence issues with novel techniques.", "motivation": "To adapt the Hu-Zhang element for curved domains while maintaining key properties like symmetry and H(div)-conformity, which is challenging due to non-polynomial structures.", "method": "A novel inf-sup condition is introduced to analyze stability. Local p-enrichment is used to rectify suboptimal stress L^2-error convergence.", "result": "Optimal convergence rates are achieved for most variables, though stress L^2-error remains suboptimal without enrichment. Numerical experiments support the theory.", "conclusion": "The extended Hu-Zhang element effectively handles curved domains, with local enrichment resolving convergence issues, validated by numerical results."}}
{"id": "2508.10697", "pdf": "https://arxiv.org/pdf/2508.10697", "abs": "https://arxiv.org/abs/2508.10697", "authors": ["Shuchen Guo"], "title": "From Kac particles to the Landau equation with hard potentials: BBGKY hierarchy method", "categories": ["math.AP"], "comment": "30 pages", "summary": "We study the Kac particle model for the space-homogenous Landau equation with\nhard potentials. By showing a sharper Povzner-type inequality, we obtain the\nuniform-in-time and uniform-in-N propagation of exponential moment for the\nfirst marginal of the solution of the many-particle Liouville equation. This\nkey property enables us to show the uniqueness of weak solutions of the\ncorresponding infinite Landau hierarchy by coupling method. As a result, we\nprove the propagation of chaos for the Landau equation with hard potentials.", "AI": {"tldr": "The paper proves propagation of chaos for the Landau equation with hard potentials using a sharper Povzner-type inequality and coupling methods.", "motivation": "To study the Kac particle model for the space-homogenous Landau equation and ensure uniform propagation of exponential moments.", "method": "Uses a sharper Povzner-type inequality and coupling methods to analyze the many-particle Liouville equation.", "result": "Uniform-in-time propagation of exponential moments and uniqueness of weak solutions for the Landau hierarchy.", "conclusion": "Propagation of chaos is proven for the Landau equation with hard potentials."}}
{"id": "2508.10505", "pdf": "https://arxiv.org/pdf/2508.10505", "abs": "https://arxiv.org/abs/2508.10505", "authors": ["Hanwen Kang", "Tenglong Lu", "Zhanbin Qi", "Jiandong Guo", "Sheng Meng", "Miao Liu"], "title": "FastTrack: a fast method to evaluate mass transport in solid leveraging universal machine learning interatomic potential", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "We introduce a rapid, accurate framework for computing atomic migration\nbarriers in crystals by combining universal machine learning force fields\n(MLFFs) with 3D potential energy surface sampling and interpolation. Our method\nsuppresses periodic self interactions via supercell expansion, builds a\ncontinuous PES from MLFF energies on a spatial grid, and extracts minimum\nenergy pathways without predefined NEB images. Across twelve benchmark\nelectrode and electrolyte materials including LiCoO2, LiFePO4, and LGPS our\nMLFF-derived barriers lie within tens of meV of DFT and experiment, while\nachieving ~10^2 x speedups over DFT-NEB. We benchmark GPTFF, CHGNet, and MACE,\nshow that fine-tuning on PBE/PBE+U data further enhances accuracy, and provide\nan open-source package for high-throughput materials screening and interactive\nPES visualization.", "AI": {"tldr": "A fast, accurate framework for computing atomic migration barriers in crystals using machine learning force fields (MLFFs) and 3D potential energy surface sampling, achieving significant speedups over DFT-NEB.", "motivation": "To address the computational cost and accuracy challenges in calculating atomic migration barriers in materials, leveraging MLFFs for efficiency and precision.", "method": "Combines MLFFs with 3D potential energy surface sampling and interpolation, suppresses periodic self-interactions via supercell expansion, and extracts minimum energy pathways without predefined NEB images.", "result": "MLFF-derived barriers are within tens of meV of DFT and experimental values, with ~100x speedups over DFT-NEB. Benchmarked GPTFF, CHGNet, and MACE, showing improved accuracy with fine-tuning.", "conclusion": "The framework offers a rapid, accurate alternative for high-throughput materials screening, supported by an open-source package for PES visualization."}}
{"id": "2508.10125", "pdf": "https://arxiv.org/pdf/2508.10125", "abs": "https://arxiv.org/abs/2508.10125", "authors": ["Christian Engwer", "Carsten Gr\u00e4ser", "Steffen M\u00fcthing", "Simon Praetorius", "Oliver Sander"], "title": "Concepts for Composing Finite Element Function Space Bases", "categories": ["cs.MS", "cs.NA", "math.NA", "68U20, 65N30, 65N08", "G.4; G.1.8"], "comment": "arXiv admin note: substantial text overlap with arXiv:1806.09545", "summary": "Finite Element discretizations of coupled multi-physics partial differential\nequation models require the handling of composed function spaces. In this paper\nwe discuss software concepts and abstractions to handle the composition of\nfunction spaces, based on a representation of product spaces as trees of\nsimpler bases. From this description, many different numberings of degrees of\nfreedom by multi-indices can be derived in a natural way, allowing to adapt the\nfunction spaces to very different data layouts, so that it opens the\npossibility to directly use the finite element code with very different linear\nalgebra codes, different data structures, and different algebraic solvers.\n  A recurring example throughout the paper is the stationary Stokes equation\nwith Taylor--Hood elements as these are naturally formulated as product spaces\nand highlight why different storage patterns are desirable.\n  In the second half of the paper we discuss a particular realization of most\nof these concepts in the \\dunemodule{dune-functions} module, as part of the\nDUNE ecosystem.", "AI": {"tldr": "The paper discusses software concepts for handling composed function spaces in finite element discretizations, using tree-based representations to adapt to various data layouts and linear algebra codes.", "motivation": "To address the need for flexible handling of composed function spaces in multi-physics PDE models, enabling compatibility with diverse data structures and solvers.", "method": "Representation of product spaces as trees of simpler bases, allowing derivation of multi-indexed degrees of freedom for adaptable data layouts.", "result": "Demonstrates the approach with the stationary Stokes equation using Taylor-Hood elements and implements it in the DUNE module dune-functions.", "conclusion": "The proposed abstractions enable flexible and efficient handling of function spaces, facilitating integration with various linear algebra tools and solvers."}}
{"id": "2508.10722", "pdf": "https://arxiv.org/pdf/2508.10722", "abs": "https://arxiv.org/abs/2508.10722", "authors": ["Moritz Immanuel Gau", "Katharina Hopf"], "title": "Well-posedness and relaxation in a simplified model for viscoelastic phase separation via Hilbertian gradients flows", "categories": ["math.AP"], "comment": null, "summary": "This article is concerned with a gradient-flow approach to a Cahn-Hilliard\nmodel for viscoelastic phase separation introduced by Zhou et al. (Phys. Rev.\nE, 2006) in its variant with constant mobility. By means of time-incremental\nminimisation and generalised contractivity estimates, we establish the global\nwell-posedness of the Cauchy problem for moderately regular initial data. For\ngeneral finite-energy data we obtain the existence of gradient-flow solutions\nand a stability estimate of weak-strong type. We further study the asymptotic\nbehaviour for relaxation time and bulk modulus depending on a small parameter.\nDepending on the scaling, we recover the Cahn-Hilliard, the mass-conserving\nAllen-Cahn or the viscous Cahn-Hilliard equation. A challenge in the\nwell-posedness analysis is the failure of semiconvexity of the appropriate\ndriving functional, which is caused by a phase-dependence of the bulk modulus.", "AI": {"tldr": "The paper analyzes a gradient-flow approach to a Cahn-Hilliard model for viscoelastic phase separation, proving global well-posedness and stability, and studying asymptotic behavior under parameter scaling.", "motivation": "To address the well-posedness and stability of a Cahn-Hilliard model for viscoelastic phase separation, particularly overcoming challenges like non-semiconvexity due to phase-dependent bulk modulus.", "method": "Uses time-incremental minimization and generalized contractivity estimates to analyze the model.", "result": "Establishes global well-posedness for moderately regular data, existence of gradient-flow solutions for finite-energy data, and derives stability estimates. Also recovers classical equations under specific parameter scalings.", "conclusion": "The study successfully tackles the challenges of the model, providing insights into its behavior and connecting it to known equations under certain conditions."}}
{"id": "2508.10590", "pdf": "https://arxiv.org/pdf/2508.10590", "abs": "https://arxiv.org/abs/2508.10590", "authors": ["Viswak R Balaji", "Samuel Punch"], "title": "Simulating Mass-Dependent Decoherence in Quantum Computers: Baseline Signatures for Testing Gravity-Induced Collapse", "categories": ["quant-ph", "cs.ET", "physics.comp-ph"], "comment": null, "summary": "We present a quantum computing simulation study of mass-dependent decoherence\nmodels inspired by Penrose's gravity-induced collapse hypothesis. According to\nobjective reduction (OR) theory, quantum superpositions become unstable when\nthe gravitational self-energy difference between branches exceeds a certain\nthreshold, leading to a collapse time $\\tau \\approx \\hbar / E_G$. In this work,\nwe implement a mass-dependent dephasing noise channel, $p(m) = 1 - e^{-k\nm^{\\alpha}}$, within the Qiskit AerSimulator, where $m$ is a proxy for the\neffective mass of a superposition, mapped to circuit parameters such as the\nnumber of entangled qubits or branch size. We apply this model to three\ncanonical quantum computing experiments: GHZ state parity measurements,\nbranch-mass entanglement tests, and Grover's search to generate distinctive\ncollapse signatures that differ qualitatively from constant-rate dephasing. The\nresulting patterns serve as a baseline reference: if future hardware\nexperiments exhibit the same scaling trends under ideal isolation, this could\nindicate a contribution from mass-dependent collapse processes. Conversely,\ndeviation toward constant-noise behaviour would suggest the absence of such\ngravitationally induced effects. Our results provide a reproducible protocol\nand reference for using quantum computers as potential testbeds for probing\nfundamental questions in quantum mechanics.", "AI": {"tldr": "Simulation study of mass-dependent decoherence models inspired by Penrose's gravity-induced collapse hypothesis, using Qiskit AerSimulator to test collapse signatures in quantum computing experiments.", "motivation": "To explore whether quantum superpositions collapse due to gravitational effects, as suggested by Penrose's objective reduction theory, and to provide a protocol for testing this in quantum computers.", "method": "Implemented a mass-dependent dephasing noise channel in Qiskit AerSimulator, applied to GHZ state parity measurements, branch-mass entanglement tests, and Grover's search.", "result": "Generated distinctive collapse signatures differing from constant-rate dephasing, serving as a baseline for future hardware experiments.", "conclusion": "The study offers a reproducible protocol for probing fundamental quantum mechanics questions using quantum computers, with potential to confirm or refute gravity-induced collapse effects."}}
{"id": "2508.10202", "pdf": "https://arxiv.org/pdf/2508.10202", "abs": "https://arxiv.org/abs/2508.10202", "authors": ["Sreeram Venkat", "Kasia Swirydowicz", "Noah Wolfe", "Omar Ghattas"], "title": "Mixed-Precision Performance Portability of FFT-Based GPU-Accelerated Algorithms for Block-Triangular Toeplitz Matrices", "categories": ["cs.DC", "cs.NA", "cs.PF", "math.NA", "65Y20, 65Y05, 65Y10, 68Q25, 68W40, 65M32, 5B05", "F.2; G.4; C.4"], "comment": null, "summary": "The hardware diversity displayed in leadership-class computing facilities,\nalongside the immense performance boosts exhibited by today's GPUs when\ncomputing in lower precision, provide a strong incentive for scientific HPC\nworkflows to adopt mixed-precision algorithms and performance portability\nmodels. We present an on-the-fly framework using Hipify for performance\nportability and apply it to FFTMatvec-an HPC application that computes\nmatrix-vector products with block-triangular Toeplitz matrices. Our approach\nenables FFTMatvec, initially a CUDA-only application, to run seamlessly on AMD\nGPUs with excellent observed performance. Performance optimizations for AMD\nGPUs are integrated directly into the open-source rocBLAS library, keeping the\napplication code unchanged. We then present a dynamic mixed-precision framework\nfor FFTMatvec; a Pareto front analysis determines the optimal mixed-precision\nconfiguration for a desired error tolerance. Results are shown for AMD Instinct\nMI250X, MI300X, and the newly launched MI355X GPUs. The performance-portable,\nmixed-precision FFTMatvec is scaled to 2,048 GPUs on the OLCF Frontier\nsupercomputer.", "AI": {"tldr": "A framework using Hipify enables performance portability for FFTMatvec, allowing it to run on AMD GPUs. A dynamic mixed-precision approach optimizes performance for desired error tolerance, scaling to 2,048 GPUs on Frontier.", "motivation": "Hardware diversity and GPU performance gains in lower precision motivate adoption of mixed-precision algorithms and performance portability in HPC workflows.", "method": "Uses Hipify for porting CUDA-based FFTMatvec to AMD GPUs, integrates optimizations into rocBLAS, and employs a dynamic mixed-precision framework with Pareto front analysis.", "result": "Achieves seamless performance on AMD GPUs (MI250X, MI300X, MI355X) and scales to 2,048 GPUs on Frontier.", "conclusion": "The framework successfully combines performance portability and mixed-precision optimization for HPC applications."}}
{"id": "2508.10773", "pdf": "https://arxiv.org/pdf/2508.10773", "abs": "https://arxiv.org/abs/2508.10773", "authors": ["Yuxiang Qiao"], "title": "$\\mathrm{C}^2$ estimates for general $p$-Hessian equations on closed Riemannian manifolds", "categories": ["math.AP", "math.DG", "35B45, 58J05 (Primary) 35J60, 35R01 (Secondary)"], "comment": "Any comments welcome!", "summary": "We study the $\\mathrm{C}^2$ estimates for $p$-Hessian equations with general\nleft-hand and right-hand terms on closed Riemannian manifolds of dimension $n$.\nTo overcome the constraints of closed manifolds, we advance a new kind of\n\"subsolution\", called pseudo-solution, which generalizes\n\"$\\mathcal{C}$-subsolution\" to some extent and is well-defined for fully\ngeneral $p$-Hessian equations. Based on pseudo-solutions, we prove the\n$\\mathrm{C}^0$ estimates, first-order estimates for general $p$-Hessian\nequations, and the corresponding second-order estimates when $p\\in\\{2, n-1,\nn\\}$, under sharp conditions -- we don't impose curvature restrictions,\nconvexity conditions or \"MTW condition\" on our main results. Some other\nconclusions related to a priori estimates and different kinds of \"subsolutions\"\nare also given, including estimates for \"semi-convex\" solutions and when there\nexists a pseudo-solution.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.10666", "pdf": "https://arxiv.org/pdf/2508.10666", "abs": "https://arxiv.org/abs/2508.10666", "authors": ["Timothy Heightman", "Marcin P\u0142odzie\u0144"], "title": "Deep Learning in Classical and Quantum Physics", "categories": ["quant-ph", "cs.AI", "cs.NE", "physics.comp-ph"], "comment": null, "summary": "Scientific progress is tightly coupled to the emergence of new research\ntools. Today, machine learning (ML)-especially deep learning (DL)-has become a\ntransformative instrument for quantum science and technology. Owing to the\nintrinsic complexity of quantum systems, DL enables efficient exploration of\nlarge parameter spaces, extraction of patterns from experimental data, and\ndata-driven guidance for research directions. These capabilities already\nsupport tasks such as refining quantum control protocols and accelerating the\ndiscovery of materials with targeted quantum properties, making ML/DL literacy\nan essential skill for the next generation of quantum scientists. At the same\ntime, DL's power brings risks: models can overfit noisy data, obscure causal\nstructure, and yield results with limited physical interpretability.\nRecognizing these limitations and deploying mitigation strategies is crucial\nfor scientific rigor. These lecture notes provide a comprehensive,\ngraduate-level introduction to DL for quantum applications, combining\nconceptual exposition with hands-on examples. Organized as a progressive\nsequence, they aim to equip readers to decide when and how to apply DL\neffectively, to understand its practical constraints, and to adapt AI methods\nresponsibly to problems across quantum physics, chemistry, and engineering.", "AI": {"tldr": "The paper discusses the transformative role of deep learning (DL) in quantum science, highlighting its benefits and risks, and provides a graduate-level guide for its responsible application.", "motivation": "To address the growing importance of DL in quantum science and the need for literacy in this area, while also acknowledging its potential pitfalls.", "method": "The paper offers a structured, progressive sequence of lecture notes combining conceptual explanations with practical examples.", "result": "It equips readers with the knowledge to apply DL effectively in quantum physics, chemistry, and engineering, while understanding its limitations.", "conclusion": "DL is a powerful tool for quantum science, but its responsible use requires awareness of its constraints and risks."}}
{"id": "2508.10320", "pdf": "https://arxiv.org/pdf/2508.10320", "abs": "https://arxiv.org/abs/2508.10320", "authors": ["Aaditya Chandrasekhar", "Stefan Knapik", "Deepak Sharma", "John Reidy", "Ian McCue", "Jian Cao", "Wei Chen"], "title": "TOBACO: Topology Optimization via Band-limited Coordinate Networks for Compositionally Graded Alloys", "categories": ["cs.CE", "cs.NA", "math.NA"], "comment": "Submitted to Structural and Multidisciplinary Optimization", "summary": "Compositionally Graded Alloys (CGAs) offer unprecedented design flexibility\nby enabling spatial variations in composition; tailoring material properties to\nlocal loading conditions. This flexibility leads to components that are\nstronger, lighter, and more cost-effective than traditional monolithic\ncounterparts. The fabrication of CGAs have become increasingly feasible owing\nto recent advancements in additive manufacturing (AM), particularly in\nmulti-material printing and improved precision in material deposition. However,\nAM of CGAs requires imposition of manufacturing constraints; in particular\nlimits on the maximum spatial gradation of composition.\n  This paper introduces a topology optimization (TO) based framework for\ndesigning optimized CGA components with controlled compositional gradation. In\nparticular, we represent the constrained composition distribution using a\nband-limited coordinate neural network. By regulating the network's bandwidth,\nwe ensure implicit compliance with gradation limits, eliminating the need for\nexplicit constraints. The proposed approach also benefits from the inherent\nadvantages of TO using coordinate networks, including mesh independence,\nhigh-resolution design extraction, and end-to-end differentiability. The\neffectiveness of our framework is demonstrated through various elastic and\nthermo-elastic TO examples.", "AI": {"tldr": "A topology optimization framework using neural networks to design Compositionally Graded Alloys (CGAs) with controlled gradation, leveraging additive manufacturing advancements.", "motivation": "CGAs offer superior material properties and cost-effectiveness, but their fabrication via additive manufacturing requires managing compositional gradation limits.", "method": "A band-limited coordinate neural network represents composition distribution, ensuring implicit compliance with gradation constraints while benefiting from mesh independence and high-resolution design.", "result": "Demonstrated effectiveness in elastic and thermo-elastic topology optimization examples.", "conclusion": "The framework successfully designs optimized CGA components with controlled gradation, addressing manufacturing constraints."}}
{"id": "2508.10892", "pdf": "https://arxiv.org/pdf/2508.10892", "abs": "https://arxiv.org/abs/2508.10892", "authors": ["S. E. Boutiah", "D. Kinzebulatov"], "title": "Upper bound on heat kernels of finite particle systems of Keller-Segel type", "categories": ["math.AP", "math-ph", "math.MP", "math.PR"], "comment": null, "summary": "We obtain an upper bound on the heat kernel of the Keller-Segel finite\nparticle system that exhibits blow up effects. The proof exploits a connection\nbetween Keller-Segel finite particles and certain non-local operators. The\nlatter allows to address some aspects of the critical behaviour of the\nKeller-Segel system resulting from its two-dimensionality.", "AI": {"tldr": "Upper bound on the heat kernel for Keller-Segel finite particle system, showing blow-up effects.", "motivation": "Understand the critical behavior of the Keller-Segel system, particularly in two dimensions.", "method": "Connects Keller-Segel finite particles to non-local operators to analyze the system.", "result": "Derives an upper bound on the heat kernel, highlighting blow-up effects.", "conclusion": "The approach provides insights into the critical behavior of the Keller-Segel system in two dimensions."}}
{"id": "2508.10671", "pdf": "https://arxiv.org/pdf/2508.10671", "abs": "https://arxiv.org/abs/2508.10671", "authors": ["Fabio Tarocco", "Pi A. B. Haase", "Fabijan Pavo\u0161evi\u0107", "Vijay Krishna", "Leonardo Guidoni", "Stefan Knecht", "Martina Stella"], "title": "AEGISS -- Atomic orbital and Entropy-based Guided Inference for Space Selection -- A novel semi-automated active space selection workflow for quantum chemistry and quantum computing applications", "categories": ["physics.chem-ph", "cond-mat.str-el", "physics.comp-ph", "quant-ph"], "comment": null, "summary": "The selection of a balanced active space is a critical step in\nmulti-reference quantum chemistry calculations, particularly for systems with\nstrong electron correlation. Likewise, active space selection is a key to\nunlock the potential of contemporary quantum computing in quantum chemistry.\nAlbeit recent progress, there remains a lack of a unified, robust, and fully\nautomated framework for active space selection that performs reliably across a\nwide range of molecular systems.\n  In this work, we present a novel approach inspired by both the AVAS (Atomic\nValence Active Space) and AutoCAS methods. Our method unifies orbital entropy\nanalysis with atomic orbital projections to guide the construction of\nchemically and physically meaningful active spaces. This integrated scheme\nenables a more consistent and flexible selection of active orbitals while\nretaining automation and scalability. We validate our approach on a set of\nmolecular systems relevant to photodynamic therapy, in particular a set of\nRu(II)-complexes, selected to span increasing levels of electron correlation\nand structural complexity. These molecules serve as challenging test cases due\nto the presence of strong static correlation and the need for highly accurate\nelectronic structure descriptions. Our results demonstrate that the method can\nreliably identify compact, chemically intuitive active spaces that capture the\nessential physics, making it suitable for both classical and quantum\ncomputational frameworks.\n  Furthermore, we have developed this approach in a package that is intuitive\nto use for users and can be interfaced with both standard quantum chemistry and\nquantum computing applications, making it accessible to a broad research\ncommunity.", "AI": {"tldr": "A novel method for automated active space selection in quantum chemistry combines orbital entropy analysis and atomic orbital projections, validated on Ru(II)-complexes for photodynamic therapy.", "motivation": "Addressing the lack of a unified, robust, and automated framework for active space selection in systems with strong electron correlation, crucial for quantum computing applications.", "method": "Integrates AVAS and AutoCAS approaches, using orbital entropy and atomic orbital projections to guide active space construction.", "result": "Reliably identifies compact, chemically intuitive active spaces for challenging systems like Ru(II)-complexes, suitable for classical and quantum computing.", "conclusion": "The method offers a consistent, flexible, and automated solution for active space selection, accessible via a user-friendly package for broader research use."}}
{"id": "2508.10452", "pdf": "https://arxiv.org/pdf/2508.10452", "abs": "https://arxiv.org/abs/2508.10452", "authors": ["Zhiqiang Xu"], "title": "New Lower Bounds for the Minimum Singular Value in Matrix Selection", "categories": ["math.FA", "cs.NA", "math.NA"], "comment": "13 pages", "summary": "The objective of the matrix selection problem is to select a submatrix\n$A_{S}\\in \\mathbb{R}^{n\\times k}$ from $A\\in \\mathbb{R}^{n\\times m}$ such that\nits minimum singular value is maximized. In this paper, we employ the\ninterlacing polynomial method to investigate this problem. This approach allows\nus to identify a submatrix $A_{S_0}\\in \\mathbb{R}^{n\\times k}$ and establish a\nlower bound for its minimum singular value. Specifically, unlike common\ninterlacing polynomial approaches that estimate the smallest root of the\nexpected characteristic polynomial via barrier functions, we leverage the\ndirect relationship between roots and coefficients. This leads to a tighter\nlower bound when $k$ is close to $n$. For the case where\n$AA^{\\top}=\\mathbb{I}_n$ and $k=n$, our result improves the well-known result\nby Hong-Pan, which involves extracting a basis from a tight frame and\nestablishing a lower bound for the minimum singular value of the basis matrix.", "AI": {"tldr": "The paper uses interlacing polynomials to maximize the minimum singular value of a submatrix, improving bounds for specific cases.", "motivation": "To address the matrix selection problem by maximizing the minimum singular value of a submatrix, improving upon existing methods.", "method": "Employs the interlacing polynomial method, leveraging root-coefficient relationships for tighter bounds, especially when submatrix dimensions are close to the original.", "result": "Achieves a tighter lower bound for the minimum singular value, improving the Hong-Pan result for specific cases.", "conclusion": "The interlacing polynomial approach provides a more effective solution for maximizing the minimum singular value in matrix selection."}}
{"id": "2508.10306", "pdf": "https://arxiv.org/pdf/2508.10306", "abs": "https://arxiv.org/abs/2508.10306", "authors": ["Pawel Gajer", "Jacques Ravel"], "title": "Intrinsic and Normal Mean Ricci Curvatures: A Bochner--Weitzenboeck Identity for Simple d-Vectors", "categories": ["math.DG", "math.AP", "math.SP", "53C20 (Primary), 58J50, 53C65, 53C21, 35P15 53C20 (Primary), 58J50,\n  53C65, 53C21, 35P15 (Secondary) 53C20 (Primary), 58J50, 53C65, 53C21, 35P15\n  (Secondary)"], "comment": "12 pages, 1 figure", "summary": "We introduce two pointwise subspace averages of sectional curvature on a\nd-dimensional plane Pi in T_p M: (i) the intrinsic mean Ricci (the average of\nsectional curvatures of 2-planes contained in Pi); and (ii) the normal (mixed)\nmean Ricci (the average of sectional curvatures of 2-planes spanned by one\nvector in Pi and one in Pi^perp). Using Jacobi-field expansions, these means\noccur as the r^2/6 coefficients in the intrinsic (d-1)-sphere and normal\n(n-d-1)-sphere volume elements. A direct consequence is a Bochner--Weitzenboeck\nidentity for simple d-vectors V (built from an orthonormal frame X_1,...,X_d\nwith Pi = span{X_i}): the curvature term equals d(n-d) times the normal mean\nRicci of Pi. This yields two immediate applications: (a) a Bochner vanishing\ncriterion for harmonic simple d-vectors under a positive lower bound on the\nnormal mean Ricci; and (b) a Lichnerowicz-type lower bound for the first\neigenvalue of the Hodge Laplacian on simple d-eigenfields.", "AI": {"tldr": "The paper introduces two pointwise subspace averages of sectional curvature and derives a Bochner--Weitzenboeck identity, leading to applications in harmonic simple d-vectors and eigenvalue bounds.", "motivation": "To generalize curvature averages and derive new geometric identities with applications in differential geometry.", "method": "Uses Jacobi-field expansions to define intrinsic and normal mean Ricci curvatures and applies them to derive a Bochner--Weitzenboeck identity.", "result": "A curvature term equals d(n-d) times the normal mean Ricci, enabling vanishing criteria and eigenvalue bounds.", "conclusion": "The introduced curvature averages provide new tools for geometric analysis, with applications in harmonic forms and spectral geometry."}}
{"id": "2508.10718", "pdf": "https://arxiv.org/pdf/2508.10718", "abs": "https://arxiv.org/abs/2508.10718", "authors": ["Wei Shan Lee", "I Hang Kwok", "Kam Ian Leong", "Chi Kiu Althina Chau", "Kei Chon Sio"], "title": "Symmetry-Constrained Multi-Scale Physics-Informed Neural Networks for Graphene Electronic Band Structure Prediction", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": "36 pages and 14 figures", "summary": "Accurate prediction of electronic band structures in two-dimensional\nmaterials remains a fundamental challenge, with existing methods struggling to\nbalance computational efficiency and physical accuracy. We present the\nSymmetry-Constrained Multi-Scale Physics-Informed Neural Network (SCMS-PINN)\nv35, which directly learns graphene band structures while rigorously enforcing\ncrystallographic symmetries through a multi-head architecture. Our approach\nintroduces three specialized ResNet-6 pathways -- K-head for Dirac physics,\nM-head for saddle points, and General head for smooth interpolation --\noperating on 31 physics-informed features extracted from k-points. Progressive\nDirac constraint scheduling systematically increases the weight parameter from\n5.0 to 25.0, enabling hierarchical learning from global topology to local\ncritical physics. Training on 10,000 k-points over 300 epochs achieves 99.99\\%\nreduction in training loss (34.597 to 0.003) with validation loss of 0.0085.\nThe model predicts Dirac point gaps within 30.3 $\\mu$eV of theoretical zero and\nachieves average errors of 53.9 meV (valence) and 40.5 meV (conduction) across\nthe Brillouin zone. All twelve C$_{6v}$ operations are enforced through\nsystematic averaging, guaranteeing exact symmetry preservation. This framework\nestablishes a foundation for extending physics-informed learning to broader\ntwo-dimensional materials for accelerated discovery.", "AI": {"tldr": "SCMS-PINN v35 predicts graphene band structures with high accuracy by enforcing crystallographic symmetries and using multi-head ResNet-6 pathways.", "motivation": "Existing methods struggle to balance computational efficiency and physical accuracy in predicting electronic band structures of 2D materials.", "method": "Uses Symmetry-Constrained Multi-Scale Physics-Informed Neural Network (SCMS-PINN) with three ResNet-6 pathways (K-head, M-head, General head) and progressive Dirac constraint scheduling.", "result": "Achieves 99.99% training loss reduction, predicts Dirac point gaps within 30.3 \u00b5eV, and maintains symmetry preservation.", "conclusion": "The framework enables accurate and efficient prediction of band structures, paving the way for broader applications in 2D materials."}}
{"id": "2508.10694", "pdf": "https://arxiv.org/pdf/2508.10694", "abs": "https://arxiv.org/abs/2508.10694", "authors": ["Molly Brennan", "Edwina F. Yeo", "Philip Pearce", "Mohit P. Dalwadi"], "title": "Effective permeability conditions for diffusive transport through impermeable membranes with gaps", "categories": ["cond-mat.soft", "math.AP", "math.DS", "physics.bio-ph"], "comment": null, "summary": "Membranes regulate transport in a wide variety of industrial and biological\napplications. The microscale geometry of the membrane can significantly affect\noverall transport through the membrane, but the precise nature of this\nmultiscale coupling is not well characterised in general. Motivated by the\napplication of transport across a bacterial membrane, in this paper we use\nformal multiscale analysis to derive explicit effective coupling conditions for\nmacroscale transport across a two-dimensional impermeable membrane with\nperiodically spaced gaps, and validate these with numerical simulations. We\nderive analytic expressions for effective macroscale quantities associated with\nthe membrane, such as the permeability, in terms of the microscale geometry.\nOur results generalise the classic constitutive membrane coupling conditions to\na wider range of membrane geometries and time-varying scenarios. Specifically,\nwe demonstrate that if the exterior concentration varies in time, for membranes\nwith long channels, the transport gains a memory property where the coupling\nconditions depend on the system history. By applying our effective conditions\nin the context of small molecule transport through gaps in bacterial membranes\ncalled porins, we predict that bacterial membrane permeability is primarily\ndominated by the thickness of the membrane. Furthermore, we predict how\nalterations to membrane microstructure, for example via changes to porin\nexpression, might affect overall transport, including when external\nconcentrations vary in time. These results will apply to a broad range of\nphysical applications with similar membrane structures, from medical and\nindustrial filtration to carbon capture.", "AI": {"tldr": "The paper uses multiscale analysis to derive effective coupling conditions for transport across membranes with periodic gaps, validating results with simulations. It generalizes classic membrane conditions and predicts bacterial membrane permeability dominated by thickness.", "motivation": "To understand how microscale geometry affects macroscale transport across membranes, particularly in bacterial membranes with periodic gaps.", "method": "Formal multiscale analysis and numerical simulations to derive and validate effective macroscale coupling conditions.", "result": "Analytic expressions for membrane permeability in terms of microscale geometry, revealing a memory property for time-varying concentrations. Bacterial membrane permeability is primarily influenced by thickness.", "conclusion": "The derived conditions apply broadly, from bacterial membranes to industrial filtration, predicting how microstructure changes affect transport, especially under time-varying conditions."}}
{"id": "2508.10727", "pdf": "https://arxiv.org/pdf/2508.10727", "abs": "https://arxiv.org/abs/2508.10727", "authors": ["Segun Goh", "Dennis Haustein", "Gerhard Gompper"], "title": "Run-and-Tumble Escape in Pursuit-Evasion Dynamics of Intelligent Active Particles", "categories": ["physics.bio-ph", "cond-mat.stat-mech", "physics.comp-ph"], "comment": "6 figures", "summary": "The pursuit-evasion game is studied for two adversarial active agents,\nmodelled as a deterministic self-steering pursuer and a stochastic, cognitive\nevader. The pursuer chases the evader by reorienting its propulsion direction\nwith limited maneuverability, while the evader escapes by executing sharp,\nunpredictable turns, whose timing and direction the pursuer cannot anticipate.\nTo make the target responsive and agile when the threat level is high, the\ntumbling frequency is set to increase with decreasing distance from the\npursuer; furthermore, the range of preferred tumbling directions is varied.\nNumerical simulations of such a pursuit-target pair in two spatial dimensions\nreveal two important scenarios. For dominant pursuers, the evader is compelled\nto adopt a high-risk strategy that allows the pursuer to approach closely\nbefore the evader executes a potentially game-changing backward maneuver to\npull away from the pursuer. Otherwise, a strategy where the evader tumbles\nforward with continuous slight adjustments of the propulsion direction can\nsignificantly increase the capture time by preventing the pursuer from aligning\nwith the target propulsion direction, while maintaining the persistence of the\ntarget motion. Our results can guide the design of bioinspired robotic systems\nwith efficient evasion capabilities.", "AI": {"tldr": "The paper studies a pursuit-evasion game between a deterministic pursuer and a stochastic evader, analyzing strategies and outcomes in 2D simulations.", "motivation": "To understand and model adversarial interactions between agile agents, with applications in bioinspired robotics.", "method": "Numerical simulations of a pursuer-evader pair, with the evader's tumbling frequency and direction varying based on threat level.", "result": "Two key scenarios emerge: high-risk backward maneuvers for dominant pursuers and forward tumbling to prolong capture time.", "conclusion": "The findings can inform the design of robotic systems with effective evasion strategies."}}
{"id": "2508.10587", "pdf": "https://arxiv.org/pdf/2508.10587", "abs": "https://arxiv.org/abs/2508.10587", "authors": ["Xuanhao Mu", "G\u00f6khan Demirel", "Yuzhe Zhang", "Jianlei Liu", "Thorsten Schlachter", "Veit Hagenmeyer"], "title": "Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer", "categories": ["cs.LG", "cs.NA", "eess.SP", "math.NA"], "comment": null, "summary": "To bridge the temporal granularity gap in energy network design and operation\nbased on Energy System Models, resampling of time series is required. While\nconventional upsampling methods are computationally efficient, they often\nresult in significant information loss or increased noise. Advanced models such\nas time series generation models, Super-Resolution models and imputation models\nshow potential, but also face fundamental challenges. The goal of time series\ngenerative models is to learn the distribution of the original data to generate\nhigh-resolution series with similar statistical characteristics. This is not\nentirely consistent with the definition of upsampling. Time series\nSuper-Resolution models or imputation models can degrade the accuracy of\nupsampling because the input low-resolution time series are sparse and may have\ninsufficient context. Moreover, such models usually rely on supervised learning\nparadigms. This presents a fundamental application paradox: their training\nrequires the high-resolution time series that is intrinsically absent in\nupsampling application scenarios. To address the mentioned upsampling issue,\nthis paper introduces a new method utilizing Generative Adversarial\nTransformers (GATs), which can be trained without access to any ground-truth\nhigh-resolution data. Compared with conventional interpolation methods, the\nintroduced method can reduce the root mean square error (RMSE) of upsampling\ntasks by 9%, and the accuracy of a model predictive control (MPC) application\nscenario is improved by 13%.", "AI": {"tldr": "The paper introduces a Generative Adversarial Transformers (GATs) method for upsampling energy network time series, reducing RMSE by 9% and improving MPC accuracy by 13%, without needing high-resolution training data.", "motivation": "To address the limitations of conventional upsampling methods and advanced models (like time series generation, Super-Resolution, and imputation models) in energy network design, which suffer from information loss, noise, or reliance on unavailable high-resolution data.", "method": "Proposes a Generative Adversarial Transformers (GATs) approach that learns to generate high-resolution time series without requiring ground-truth high-resolution data.", "result": "The method reduces RMSE by 9% and improves MPC accuracy by 13% compared to conventional interpolation.", "conclusion": "GATs offer a promising solution for upsampling in energy networks, overcoming the limitations of existing methods by eliminating the need for high-resolution training data."}}
{"id": "2508.10721", "pdf": "https://arxiv.org/pdf/2508.10721", "abs": "https://arxiv.org/abs/2508.10721", "authors": ["Romain Petrides"], "title": "Isoperimetric inequalities involving Steklov eigenvalues on surfaces", "categories": ["math.DG", "math.AP", "math.SP"], "comment": null, "summary": "We give results on optimal constants of isoperimetric inequalities involving\nSteklov eigenvalues on surfaces with boundary. We both consider this question\non Riemannian surfaces with a same given topology or more specifically\nbelonging to the same conformal class. We provide new examples of topological\ndisks that realize optimal constants. We prove inequalities that relate\nconformal invariants associated to combinations of Steklov eigenvalues on a\ncompact Riemannian surface with boundary and the ones on the disk. In the\nappendix, we show rigidity of the first conformal Steklov eigenvalue on annuli\nand M\\\"obius bands.", "AI": {"tldr": "The paper explores optimal constants for isoperimetric inequalities involving Steklov eigenvalues on surfaces with boundary, focusing on Riemannian surfaces with shared topology or conformal class. It provides new examples of optimal topological disks and proves inequalities linking conformal invariants of Steklov eigenvalues on surfaces and disks. The appendix addresses rigidity of the first conformal Steklov eigenvalue on annuli and M\u00f6bius bands.", "motivation": "To understand and characterize optimal constants in isoperimetric inequalities related to Steklov eigenvalues, particularly for surfaces with boundary, and to explore their behavior under topological and conformal constraints.", "method": "The study involves analyzing Riemannian surfaces with given topology or conformal class, deriving inequalities, and providing explicit examples (topological disks) to illustrate optimal constants. The appendix uses rigidity analysis for specific surfaces (annuli and M\u00f6bius bands).", "result": "New examples of topological disks achieving optimal constants are presented. Inequalities connecting conformal invariants of Steklov eigenvalues on surfaces and disks are proven. Rigidity results for the first conformal Steklov eigenvalue on annuli and M\u00f6bius bands are established.", "conclusion": "The work advances understanding of isoperimetric inequalities and Steklov eigenvalues on surfaces with boundary, offering new insights into optimal constants and their dependence on topology and conformal structure."}}
{"id": "2508.10808", "pdf": "https://arxiv.org/pdf/2508.10808", "abs": "https://arxiv.org/abs/2508.10808", "authors": ["Akash Rodhiya", "Shashwat Bhattacharya", "Mahendra K Verma"], "title": "Relative accuracy of turbulence simulations using pseudo-spectral and finite difference solvers", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": "10 pages, 7 figures", "summary": "For a single timestep, a spectral solver is known to be more accurate than\nits finite-difference counterpart. However, as we show in this paper,\nturbulence simulations using the two methods have nearly the same accuracy. In\nthis paper, we simulate forced hydrodynamic turbulence on a uniform 256$^3$\ngrid for Reynolds numbers 965, 1231, 1515, and 1994. We show that the two\nmethods yield nearly the same evolution for the total energy and the flow\nprofiles. In addition, the steady-state energy spectrum, energy flux, and\nprobability distribution functions of the velocity and its derivatives are very\nsimilar. We argue that within a turbulence attractor, the numerical errors are\nlikely to get cancelled (rather than get added up), which leads to similar\nresults for the finite-difference and spectral methods. These findings are very\nvaluable, considering that a parallel finite-difference simulation is more\nversatile and efficient (for large grids) than its spectral counterpart.", "AI": {"tldr": "Spectral and finite-difference methods yield similar accuracy in turbulence simulations, despite spectral methods being more accurate for single timesteps.", "motivation": "To compare the accuracy of spectral and finite-difference methods in turbulence simulations, challenging the assumption that spectral methods are always superior.", "method": "Simulated forced hydrodynamic turbulence on a uniform 256\u00b3 grid for varying Reynolds numbers, comparing energy evolution, flow profiles, and statistical measures.", "result": "Both methods produced nearly identical results for energy, energy spectrum, flux, and velocity distributions, suggesting numerical errors cancel out in turbulence attractors.", "conclusion": "Finite-difference methods are equally effective for turbulence simulations and more efficient for large grids, making them a practical alternative to spectral methods."}}
{"id": "2508.10596", "pdf": "https://arxiv.org/pdf/2508.10596", "abs": "https://arxiv.org/abs/2508.10596", "authors": ["Andreas E. Kyprianou", "Aaron Pim", "Tristan Pryer"], "title": "A Unified Framework from Boltzmann Transport to Proton Treatment Planning", "categories": ["math.PR", "cs.NA", "math.NA", "math.OC", "physics.med-ph"], "comment": "23 pages, 3 figures", "summary": "This work develops a rigorous mathematical formulation of proton transport by\nintegrating both deterministic and stochastic perspectives. The deterministic\nframework is based on the Boltzmann-Fokker-Planck equation, formulated as an\noperator equation in a suitable functional setting. The stochastic approach\nmodels proton evolution via a track-length parameterised diffusion process,\nwhose infinitesimal generator provides an alternative description of transport.\n  A key result is the duality between the stochastic and deterministic\nformulations, established through the adjoint relationship between the\ntransport operator and the stochastic generator. We prove that the resolvent of\nthe stochastic process corresponds to the Green's function of the deterministic\nequation, providing a natural link between fluence-based and particle-based\ntransport descriptions. The theory is applied to dose computation, where we\nshow that the classical relation: dose = (fluence * mass stopping power) arises\nconsistently in both approaches.\n  Building on this foundation, we formulate a hybrid optimisation framework for\ntreatment planning, in which dose is computed using a stochastic model while\noptimisation proceeds via adjoint-based PDE methods. We prove existence and\ndifferentiability of the objective functional and derive the first-order\noptimality system. This framework bridges stochastic simulation with\ndeterministic control theory and provides a foundation for future work in\nconstrained, adaptive and uncertainty-aware optimisation in proton therapy.", "AI": {"tldr": "The paper integrates deterministic and stochastic models for proton transport, proving their duality and applying it to dose computation and treatment planning.", "motivation": "To rigorously unify deterministic and stochastic perspectives of proton transport for improved accuracy in proton therapy.", "method": "Combines Boltzmann-Fokker-Planck (deterministic) and diffusion process (stochastic) models, linking them via adjoint relationships and resolvents.", "result": "Demonstrates duality between models, derives dose computation consistency, and formulates a hybrid optimization framework for treatment planning.", "conclusion": "The framework bridges stochastic simulation with deterministic control, enabling advanced optimization in proton therapy."}}
{"id": "2508.10841", "pdf": "https://arxiv.org/pdf/2508.10841", "abs": "https://arxiv.org/abs/2508.10841", "authors": ["Viktor Zaverkin", "Matheus Ferraz", "Francesco Alesiani", "Mathias Niepert"], "title": "Performance of universal machine-learned potentials with explicit long-range interactions in biomolecular simulations", "categories": ["physics.chem-ph", "cond-mat.soft", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Universal machine-learned potentials promise transferable accuracy across\ncompositional and vibrational degrees of freedom, yet their application to\nbiomolecular simulations remains underexplored. This work systematically\nevaluates equivariant message-passing architectures trained on the SPICE-v2\ndataset with and without explicit long-range dispersion and electrostatics. We\nassess the impact of model size, training data composition, and electrostatic\ntreatment across in- and out-of-distribution benchmark datasets, as well as\nmolecular simulations of bulk liquid water, aqueous NaCl solutions, and\nbiomolecules, including alanine tripeptide, the mini-protein Trp-cage, and\nCrambin. While larger models improve accuracy on benchmark datasets, this trend\ndoes not consistently extend to properties obtained from simulations. Predicted\nproperties also depend on the composition of the training dataset. Long-range\nelectrostatics show no systematic impact across systems. However, for Trp-cage,\ntheir inclusion yields increased conformational variability. Our results\nsuggest that imbalanced datasets and immature evaluation practices currently\nchallenge the applicability of universal machine-learned potentials to\nbiomolecular simulations.", "AI": {"tldr": "The paper evaluates equivariant message-passing architectures for biomolecular simulations, finding that model size and training data composition affect accuracy, while long-range electrostatics show inconsistent impact.", "motivation": "To assess the applicability of universal machine-learned potentials in biomolecular simulations, addressing gaps in transferability and accuracy.", "method": "Systematic evaluation of equivariant message-passing architectures trained on SPICE-v2 dataset, with and without long-range dispersion/electrostatics, tested on various systems.", "result": "Larger models improve benchmark accuracy but not simulation properties; training data composition matters; long-range electrostatics inconsistently impact systems.", "conclusion": "Imbalanced datasets and immature evaluation practices hinder universal machine-learned potentials' applicability to biomolecular simulations."}}
