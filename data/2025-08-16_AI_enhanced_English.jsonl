{"id": "2508.10126", "pdf": "https://arxiv.org/pdf/2508.10126", "abs": "https://arxiv.org/abs/2508.10126", "authors": ["Arvind K. Saibaba", "Misha E. Kilmer", "Khalil Hall-Hooper", "Fan Tian", "Alex Mize"], "title": "A tensor-based dynamic mode decomposition based on the $\\star_{\\boldsymbol{M}}$-product", "categories": ["math.NA", "cs.NA", "15A69, 65F99, 93B30"], "comment": null, "summary": "Dynamic mode decomposition (DMD) is a data-driven method for estimating the\ndynamics of a discrete dynamical system. This paper proposes a tensor-based\napproach to DMD for applications in which the states can be viewed as tensors.\nSpecifically, we use the $\\star_{\\boldsymbol{M}}$-product framework for tensor\ndecompositions which we demonstrate offers excellent compression compared to\nmatrix-based methods and can be implemented in a computationally efficient\nmanner. We show how the proposed approach is connected to the traditional DMD\nand physics-informed DMD frameworks. We give a computational framework for\ncomputing the tensor-based DMD and detail the computational costs. We also give\na randomized algorithm that enables efficient $\\star_{\\boldsymbol{M}}$-DMD\ncomputations in the streaming setting. The numerical results show that the\nproposed method achieves equal or better accuracy for the same storage compared\nto the standard DMD on these examples and is more efficient to compute.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.10158", "pdf": "https://arxiv.org/pdf/2508.10158", "abs": "https://arxiv.org/abs/2508.10158", "authors": ["Yunhui He", "Santolo Leveque"], "title": "A Generalized Alternating Anderson Acceleration Method", "categories": ["math.NA", "cs.NA", "65F10, 65H10, 65K10"], "comment": "24 pages, 9 figures", "summary": "In this work, we propose a generalized alternating Anderson acceleration\nmethod, a periodic scheme composed of $t$ fixed-point iteration steps,\ninterleaved with $s$ steps of Anderson acceleration with window size $m$, to\nsolve linear and nonlinear problems. This allows flexibility to use different\ncombinations of fixed-point iteration and Anderson iteration. We present a\nconvergence analysis of the proposed scheme for accelerating the Richardson\niteration in the linear case, with a focus on specific parameter choices of\ninterest. Specifically, we prove convergence of the proposed method under\ncontractive fixed-point iteration and provide a sufficient condition for\nconvergence when the Richardson iteration matrix is diagonalizable and\nnoncontractive. To demonstrate the broader applicability of our proposed\nmethod, we use it to accelerate Jacobi iteration, Picard iteration, gradient\ndescent, and the alternating direction method of multipliers in solving partial\ndifferential equations and nonlinear, nonsmooth optimization problems. The\nnumerical results illustrate that the proposed scheme is more efficient than\nthe existing windowed Anderson acceleration and alternating Anderson ($s=1$) in\nterms of iteration number and CPU time for careful choice of parameters $m, s,\nt$.", "AI": {"tldr": "A generalized alternating Anderson acceleration method is proposed, combining fixed-point and Anderson iterations for solving linear and nonlinear problems, with proven convergence and improved efficiency.", "motivation": "To provide a flexible and efficient iterative method for solving linear and nonlinear problems by combining fixed-point and Anderson acceleration steps.", "method": "Proposes a periodic scheme with $t$ fixed-point steps and $s$ Anderson acceleration steps (window size $m$). Analyzes convergence for Richardson iteration and extends to other methods like Jacobi, Picard, gradient descent, and ADMM.", "result": "Convergence proven for contractive cases; sufficient condition given for noncontractive cases. Numerical results show improved efficiency over existing methods for optimal parameter choices.", "conclusion": "The method is versatile and efficient for various problems, outperforming existing acceleration techniques with careful parameter selection."}}
{"id": "2508.10322", "pdf": "https://arxiv.org/pdf/2508.10322", "abs": "https://arxiv.org/abs/2508.10322", "authors": ["Qixuan Zhou", "Chuqi Chen", "Tao Luo", "Yang Xiang"], "title": "SSBE-PINN: A Sobolev Boundary Scheme Boosting Stability and Accuracy in Elliptic/Parabolic PDE Learning", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving partial differential equations (PDEs), yet they often fail to\nachieve accurate convergence in the H1 norm, especially in the presence of\nboundary approximation errors. In this work, we propose a novel method called\nSobolev-Stable Boundary Enforcement (SSBE), which redefines the boundary loss\nusing Sobolev norms to incorporate boundary regularity directly into the\ntraining process. We provide rigorous theoretical analysis demonstrating that\nSSBE ensures bounded H1 error via a stability guarantee and derive\ngeneralization bounds that characterize its robustness under finite-sample\nregimes. Extensive numerical experiments on linear and nonlinear PDEs,\nincluding Poisson, heat, and elliptic problems, show that SSBE consistently\noutperforms standard PINNs in terms of both relative L2 and H1 errors, even in\nhigh-dimensional settings. The proposed approach offers a principled and\npractical solution for improving gradient fidelity and overall solution\naccuracy in neural network based PDE solvers.", "AI": {"tldr": "A novel method, Sobolev-Stable Boundary Enforcement (SSBE), improves PINNs by enforcing boundary regularity using Sobolev norms, ensuring better H1 error convergence and robustness.", "motivation": "Standard PINNs often fail to achieve accurate convergence in the H1 norm due to boundary approximation errors.", "method": "SSBE redefines boundary loss using Sobolev norms, incorporating boundary regularity directly into training, with theoretical guarantees for stability and generalization.", "result": "SSBE outperforms standard PINNs in relative L2 and H1 errors across various PDEs, including high-dimensional cases.", "conclusion": "SSBE provides a principled and practical solution for enhancing gradient fidelity and solution accuracy in neural network-based PDE solvers."}}
{"id": "2508.10344", "pdf": "https://arxiv.org/pdf/2508.10344", "abs": "https://arxiv.org/abs/2508.10344", "authors": ["Thomas Hangelbroek", "Christian Rieger", "Grady B. Wright"], "title": "A Semi-Lagrangian scheme on embedded manifolds using generalized local polynomial reproductions", "categories": ["math.NA", "cs.NA", "65M12, 65M15, 65M25, 41A25, 41A63"], "comment": null, "summary": "We analyze rates of uniform convergence for a class of high-order\nsemi-Lagrangian schemes for first-order, time-dependent partial differential\nequations on embedded submanifolds of $\\mathbb{R}^d$ (including advection\nequations on surfaces) by extending the error analysis of Falcone and Ferretti.\nA central requirement in our analysis is a remapping operator that achieves\nboth high approximation orders and strong stability, a combination that is\nchallenging to obtain and of independent interest. For this task, we propose a\nnovel mesh-free remapping operator based on $\\ell_1$ minimizing generalized\npolynomial reproduction, which uses only point values and requires no\nadditional geometric information from the manifold (such as access to tangent\nspaces or curvature). Our framework also rigorously addresses the numerical\nsolution of ordinary differential equations on manifolds via projection\nmethods. We include numerical experiments that support the theoretical results\nand also suggest some new directions for future research.", "AI": {"tldr": "The paper extends error analysis for high-order semi-Lagrangian schemes on submanifolds, introducing a stable, mesh-free remapping operator using \u2113\u2081 minimization.", "motivation": "To improve convergence rates and stability for solving PDEs on manifolds without requiring geometric details like tangent spaces.", "method": "Proposes a mesh-free remapping operator based on \u2113\u2081 minimizing generalized polynomial reproduction, using only point values.", "result": "The framework achieves high approximation orders and strong stability, validated by numerical experiments.", "conclusion": "The method is effective and opens new research directions for solving PDEs and ODEs on manifolds."}}
{"id": "2508.10277", "pdf": "https://arxiv.org/pdf/2508.10277", "abs": "https://arxiv.org/abs/2508.10277", "authors": ["Yi Huang", "Bowen Zheng", "Yunxi Dong", "Hong Tang", "Huan Zhao", "Rakibul Hasan Shawon", "Sensong An", "Hualiang Zhang"], "title": "MCP-Enabled LLM for Meta-optics Inverse Design: Leveraging Differentiable Solver without LLM Expertise", "categories": ["physics.comp-ph", "physics.optics"], "comment": null, "summary": "Automatic differentiation (AD) enables powerful metasurface inverse design\nbut requires extensive theoretical and programming expertise. We present a\nModel Context Protocol (MCP) assisted framework that allows researchers to\nconduct inverse design with differentiable solvers through large language\nmodels (LLMs). Since LLMs inherently lack knowledge of specialized solvers, our\nproposed solution provides dynamic access to verified code templates and\ncomprehensive documentation through dedicated servers. The LLM autonomously\naccesses these resources to generate complete inverse design codes without\nprescribed coordination rules. Evaluation on the Huygens meta-atom design task\nwith the differentiable TorchRDIT solver shows that while both natural language\nand structured prompting strategies achieve high success rates, structured\nprompting significantly outperforms in design quality, workflow efficiency,\ncomputational cost, and error reduction. The minimalist server design, using\nonly 5 APIs, demonstrates how MCP makes sophisticated computational tools\naccessible to researchers without programming expertise, offering a\ngeneralizable integration solution for other scientific tasks.", "AI": {"tldr": "A framework using Model Context Protocol (MCP) and LLMs simplifies inverse design for metasurfaces by providing dynamic access to verified code templates and documentation, eliminating the need for programming expertise.", "motivation": "To make automatic differentiation (AD) and inverse design accessible to researchers without extensive theoretical or programming knowledge.", "method": "Proposes an MCP-assisted framework where LLMs autonomously access verified code templates and documentation from dedicated servers to generate inverse design codes. Evaluated using the Huygens meta-atom design task with the TorchRDIT solver.", "result": "Structured prompting outperforms natural language in design quality, efficiency, computational cost, and error reduction. The minimalist server design (5 APIs) demonstrates accessibility.", "conclusion": "MCP enables researchers without programming expertise to use sophisticated tools, offering a generalizable solution for other scientific tasks."}}
{"id": "2508.10121", "pdf": "https://arxiv.org/pdf/2508.10121", "abs": "https://arxiv.org/abs/2508.10121", "authors": ["Sergei Avdonin", "Julian Edward"], "title": "An inverse problem on a metric graph with cycle", "categories": ["math.AP", "math.OC", "math.SP", "35R30 (primary), 35L05, 93B05 (secondary)"], "comment": null, "summary": "Consider a quantum graph consisting of a ring with two attached edges, and\nassume Kirchhoff-Neumann conditions hold at the internal vertices. Associated\nto this graph is a Schr\\\"{o}dinger type operator $L=-\\Delta +q(x)$ with\nDirichlet boundary conditions at the two boundary nodes. Let $\\{ \\omega_n^2, \\\n\\varphi_n(x)\\}$ be the eigenvalues and associated normalized eigenfunctions.\nLet $v_1$ be a boundary vertex, and $v_2$ the adjacent internal vertex. Assume\nwe know the following data: $\\{ \\omega_n^2,\\partial_x\n\\varphi_n(v_1),\\partial_x\\varphi_n(v_2)\\}.$ Here $\\partial_x\\varphi_n(v_2)$\nrefers to an outward normal derivative at $v_2$ along one of the edges incident\nto the other internal vertex. From this data we determine the following unknown\nquantities: the lengths of edges and the potential functions on each edge.", "AI": {"tldr": "The paper analyzes a quantum graph with a ring and two edges, using Schr\u00f6dinger operator eigenvalues and eigenfunction derivatives to determine edge lengths and potential functions.", "motivation": "To solve the inverse problem of determining unknown geometric and potential properties of a quantum graph from given spectral data.", "method": "Uses eigenvalues and derivatives of eigenfunctions at boundary and internal vertices to reconstruct edge lengths and potential functions.", "result": "Demonstrates that the given data (eigenvalues and derivatives) suffice to uniquely determine the edge lengths and potential functions.", "conclusion": "The study provides a method to solve inverse problems for quantum graphs using spectral data, advancing understanding of such systems."}}
{"id": "2508.10513", "pdf": "https://arxiv.org/pdf/2508.10513", "abs": "https://arxiv.org/abs/2508.10513", "authors": ["Andreas Mueller"], "title": "Product Of Exponentials (POE) Splines on Lie-Groups: Limitations, Extensions, and Application to SO(3) and SE(3)", "categories": ["math.NA", "cs.NA", "math.DG", "math.GR"], "comment": null, "summary": "Existing methods for constructing splines and Bezier curves on a Lie group G\ninvolve repeated products of exponentials deduced from local geodesics, w.r.t.\na Riemannian metric, or rely on general polynomials. Moreover, each of these\nlocal curves is supposed to start at the identity of $G$. Both assumptions may\nnot reflect the actual curve to be interpolated. This paper pursues a different\napproach to construct splines on $G$. Local curves are expressed as solutions\nof the Poisson equation on G. Therewith, the local interpolations satisfies the\nboundary conditions while respecting the geometry of $G$. A $k$th-order\napproximation of the solutions gives rise to a $k$th-order product of\nexponential (POE) spline. Algorithms for constructing 3rd- and 4th-order\nsplines are derived from closed form expressions for the approximate solutions.\nAdditionally, spline algorithms are introduced that allow prescribing a vector\nfield the curve must follow at the interpolation points. It is shown that the\nestablished algorithms, where $k$th-order POE-splines are constructed by\nconcatenating local curves starting at the identity, cannot exactly reconstruct\na $k$th-order motion. To tackle this issue, the formulations are extended by\nallowing for local curves between arbitrary points, rather than curves\nemanating from the identity. This gives rise to a global $k$th-order spline\nwith arbitrary initial conditions. Several examples are presented, in\nparticular the shape reconstruction of slender rods modeled as geometrically\nnon-linear Cosserat rods.", "AI": {"tldr": "The paper introduces a new method for constructing splines on Lie groups using solutions of the Poisson equation, addressing limitations of existing methods that rely on local geodesics or polynomials.", "motivation": "Existing methods for spline construction on Lie groups assume local curves start at the identity and may not accurately reflect the actual curve, motivating a more flexible approach.", "method": "Local curves are expressed as solutions of the Poisson equation on the Lie group, enabling boundary condition satisfaction and geometric respect. Higher-order approximations yield product of exponential (POE) splines.", "result": "Algorithms for 3rd- and 4th-order splines are derived, and a new approach allows arbitrary initial conditions, improving reconstruction accuracy.", "conclusion": "The proposed method overcomes limitations of existing techniques, enabling more accurate and flexible spline construction on Lie groups, demonstrated through examples like Cosserat rods."}}
{"id": "2508.10454", "pdf": "https://arxiv.org/pdf/2508.10454", "abs": "https://arxiv.org/abs/2508.10454", "authors": ["Qi Zhou", "Teng Wu", "Jianghao Liu", "Qingyuan Sun", "Hehu Xie", "Zhenli Xu"], "title": "Sum-of-Gaussians tensor neural networks for high-dimensional Schr\u00f6dinger equation", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "35Q40, 65D40, 65N25, 68W25, 68W40"], "comment": "22 pages, 6 figures", "summary": "We propose an accurate, efficient, and low-memory sum-of-Gaussians tensor\nneural network (SOG-TNN) algorithm for solving the high-dimensional\nSchr\\\"odinger equation. The SOG-TNN utilizes a low-rank tensor product\nrepresentation of the solution to overcome the curse of dimensionality\nassociated with high-dimensional integration. To handle the Coulomb\ninteraction, we introduce an SOG decomposition to approximate the interaction\nkernel such that it is dimensionally separable, leading to a tensor\nrepresentation with rapid convergence. We further develop a range-splitting\nscheme that partitions the Gaussian terms into short-, long-, and mid-range\ncomponents. They are treated with the asymptotic expansion, the low-rank\nChebyshev expansion, and the model reduction with singular-value decomposition,\nrespectively, significantly reducing the number of two-dimensional integrals in\ncomputing electron-electron interactions. The SOG decomposition well resolves\nthe computational challenge due to the singularity of the Coulomb interaction,\nleading to an efficient algorithm for the high-dimensional problem under the\nTNN framework. Numerical results demonstrate the outstanding performance of the\nnew method, revealing that the SOG-TNN is a promising way for tackling large\nand complex quantum systems.", "AI": {"tldr": "The paper introduces SOG-TNN, a sum-of-Gaussians tensor neural network, to solve high-dimensional Schr\u00f6dinger equations efficiently by overcoming dimensionality challenges and handling Coulomb interactions.", "motivation": "High-dimensional Schr\u00f6dinger equations are computationally challenging due to the curse of dimensionality and singular Coulomb interactions. The goal is to develop an efficient, accurate, and low-memory method.", "method": "SOG-TNN uses a low-rank tensor product representation and SOG decomposition for Coulomb interactions. A range-splitting scheme divides Gaussian terms into short-, long-, and mid-range components, each treated with specialized techniques (asymptotic expansion, Chebyshev expansion, SVD).", "result": "The method significantly reduces computational costs, resolves Coulomb singularity issues, and demonstrates outstanding performance in numerical tests.", "conclusion": "SOG-TNN is a promising approach for solving large and complex quantum systems efficiently."}}
{"id": "2508.10254", "pdf": "https://arxiv.org/pdf/2508.10254", "abs": "https://arxiv.org/abs/2508.10254", "authors": ["David M. Ambrose", "Ryan Aschoff", "Elaine Cozzi", "James P. Kelliher"], "title": "Non-Decaying Solutions to the 2D Dissipative Quasi-Geostrophic Equations", "categories": ["math.AP"], "comment": null, "summary": "We consider the surface quasi-geostrophic equation in two spatial dimensions,\nwith subcritical diffusion (i.e. with fractional diffusion of order $2\\alpha$\nfor $\\alpha>\\frac{1}{2}$.) We establish existence of solutions without assuming\neither decay at spatial infinity or spatial periodicity. One obstacle is that\nfor $L^{\\infty}$ data, the constitutive law may not be applicable, as Riesz\ntransforms are unbounded. However, for $L^{\\infty}$ initial data for which the\nconstitutive law does converge, we demonstrate that there exists a unique\nsolution locally in time, and that the constitutive law continues to hold at\npositive times. In the case that $\\alpha\\in(\\frac{1}{2},1]$ and that the\ninitial data has some smoothness (specifically, if the data is in $C^{2}$), we\ndemonstrate a maximum principle and show that this unique solution is actually\nclassical and global in time. Then, a density argument allows us to show that\nmild solutions with only $L^{\\infty}$ data are also global in time, and also\npossess this maximum principle. Finally, we introduce a related problem in\nwhich we replace the usual constitutive law for the surface quasi-geostrophic\nequation with a generalization of Sertfati type, and prove the same results for\nthis relaxed model.", "AI": {"tldr": "The paper establishes existence and uniqueness of solutions for the 2D surface quasi-geostrophic equation with subcritical diffusion, addressing challenges like unbounded Riesz transforms and $L^{\\infty}$ data. It proves local and global solutions, a maximum principle, and extends results to a relaxed model.", "motivation": "To solve the surface quasi-geostrophic equation without decay or periodicity assumptions, especially for $L^{\\infty}$ data where Riesz transforms complicate the constitutive law.", "method": "Analyze solutions for $L^{\\infty}$ data, prove local existence and uniqueness, extend to global solutions for smooth data, and generalize results to a relaxed model.", "result": "Existence of unique local solutions for $L^{\\infty}$ data, global classical solutions for smooth data, and extension to a relaxed model with similar properties.", "conclusion": "The paper successfully addresses the challenges of the quasi-geostrophic equation, proving key results for both standard and relaxed models."}}
{"id": "2508.10547", "pdf": "https://arxiv.org/pdf/2508.10547", "abs": "https://arxiv.org/abs/2508.10547", "authors": ["Hameed Ullah Jan", "Marjan Uddin", "Irshad Ali Shah", "Salam Ullah Khan"], "title": "On The Eventual Periodicity of Fractional Order Dispersive Wave Equations Using RBFs and Transform", "categories": ["math.NA", "cs.NA", "34K28, 35G61, 35Q53, 34A08, 34K13"], "comment": "16 pages, 9 figures", "summary": "In this research work, let us focus on the construction of numerical scheme\nbased on radial basis functions finite difference (RBF-FD) method combined with\nthe Laplace transform for the solution of fractional order dispersive wave\nequations. The numerical scheme is then applied to examine the eventual\nperiodicity of the proposed model subject to the periodic boundary conditions.\nThe implementation of proposed technique for high order fractional and integer\ntype nonlinear partial differential equations (PDEs) is beneficial because this\nmethod is local in nature, therefore it yields and resulted in sparse\ndifferentiation matrices instead of full and dense matrices. Only small\ndimensions of linear systems of equations are to be solved for every center in\nthe domain and hence this procedure is more reliable and efficient to solve\nlarge scale physical and engineering problems in complex domain. Laplace\ntransform is utilized for obtaining the equivalent time-independent equation in\nLaplace space and also valuable to handle time-fractional derivatives in the\nCaputo sense. Application of Laplace transform avoids the time steeping\nprocedure which commonly encounters the time instability issues. The solution\nto the transformed model is then obtained by computing the inversion of Laplace\ntransform with an appropriate contour in a complex space, which is approximated\nby trapezoidal rule with high accuracy. Also since the Laplace transform\noperator is linear, it cannot be used to transform non-linear terms therefore\nlet us use a linearization approach and an appropriate iterative scheme. The\nproposed approach is tasted for some nonlinear fractional order KdV and Burgers\nequations. The capacity, high order accuracy and efficiency of our approach are\ndemonstrated using examples and results", "AI": {"tldr": "The paper proposes a numerical scheme combining radial basis functions finite difference (RBF-FD) method and Laplace transform to solve fractional order dispersive wave equations, demonstrating efficiency and accuracy for nonlinear PDEs.", "motivation": "To address challenges in solving high-order fractional and integer-type nonlinear PDEs, particularly avoiding dense matrices and time instability issues.", "method": "Combines RBF-FD (local nature, sparse matrices) with Laplace transform (time-independent equations, avoids time-stepping) and linearization for nonlinear terms.", "result": "The method efficiently solves large-scale problems, demonstrated via nonlinear fractional KdV and Burgers equations, showing high accuracy.", "conclusion": "The proposed approach is reliable, efficient, and accurate for complex domains, avoiding common numerical instability issues."}}
{"id": "2508.10515", "pdf": "https://arxiv.org/pdf/2508.10515", "abs": "https://arxiv.org/abs/2508.10515", "authors": ["Andrea Urgolo", "Monika Stipsitz", "Helios Sanchis-Alepuz"], "title": "Virtual Sensing for Solder Layer Degradation and Temperature Monitoring in IGBT Modules", "categories": ["physics.comp-ph", "cs.CE", "cs.LG", "cs.SY", "eess.SY"], "comment": "Andrea Urgolo and Monika Stipsitz contributed equally to this work", "summary": "Monitoring the degradation state of Insulated Gate Bipolar Transistor (IGBT)\nmodules is essential for ensuring the reliability and longevity of power\nelectronic systems, especially in safety-critical and high-performance\napplications. However, direct measurement of key degradation indicators - such\nas junction temperature, solder fatigue or delamination - remains challenging\ndue to the physical inaccessibility of internal components and the harsh\nenvironment. In this context, machine learning-based virtual sensing offers a\npromising alternative by bridging the gap from feasible sensor placement to the\nrelevant but inaccessible locations. This paper explores the feasibility of\nestimating the degradation state of solder layers, and the corresponding full\ntemperature maps based on a limited number of physical sensors. Based on\nsynthetic data of a specific degradation mode, we obtain a high accuracy in the\nestimation of the degraded solder area (1.17% mean absolute error), and are\nable to reproduce the surface temperature of the IGBT with a maximum relative\nerror of 4.56% (corresponding to an average relative error of 0.37%).", "AI": {"tldr": "Machine learning-based virtual sensing accurately estimates IGBT module degradation and temperature maps using limited physical sensors.", "motivation": "Ensuring reliability of power electronic systems by monitoring IGBT degradation, despite challenges in direct measurement.", "method": "Uses synthetic data and machine learning to estimate solder layer degradation and temperature maps from limited sensor data.", "result": "Achieves 1.17% mean absolute error in degraded solder area estimation and 4.56% max relative error in temperature reproduction.", "conclusion": "Machine learning-based virtual sensing is feasible for accurate IGBT degradation monitoring."}}
{"id": "2508.10314", "pdf": "https://arxiv.org/pdf/2508.10314", "abs": "https://arxiv.org/abs/2508.10314", "authors": ["Tatsuya Miura", "Kensuke Yoshizawa"], "title": "Stability of flat-core pinned p-elasticae", "categories": ["math.AP", "math.DG", "49Q10 and 53A04"], "comment": "12 pages, 3 figures", "summary": "We classify the stability of flat-core $p$-elasticae in $\\mathbf{R}^d$\nsubject to the pinned boundary condition. Together with previous work, this\ncompletes the classification of stable pinned $p$-elasticae in $\\mathbf{R}^d$\nfor all $p\\in(1,\\infty)$ and $d\\geq2$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.10558", "pdf": "https://arxiv.org/pdf/2508.10558", "abs": "https://arxiv.org/abs/2508.10558", "authors": ["Marjan Uddin", "Hameed Ullah Jan", "Muhammad Usman"], "title": "RBF-FD Method for Some Dispersive Wave Equations and Their Eventual Periodicity", "categories": ["math.NA", "cs.NA", "33F05, 34K10, 34K13, 34K28, 35Q51, 35Q53"], "comment": "23 pages, 10 figures", "summary": "In this paper, we approximate the solution and also discuss the periodic\nbehavior termed as eventual periodicity of solutions of (IBVPs) for some\ndispersive wave equations on a bounded domain corresponding to periodic\nforcing. The constructed numerical scheme is based on radial kernels and local\nin nature like finite difference method. The temporal variable is executed\nthrough RK4 scheme. Due to the local nature and sparse differentiation matrices\nour numerical scheme efficiently recovers the solution. The results achieved\nare validated and examined with other methods accessible in the literature.", "AI": {"tldr": "The paper approximates solutions and analyzes eventual periodicity for dispersive wave equations under periodic forcing, using a local numerical scheme with radial kernels and RK4 time integration.", "motivation": "To study periodic behavior and approximate solutions for dispersive wave equations on bounded domains with periodic forcing.", "method": "A local numerical scheme based on radial kernels, sparse differentiation matrices, and RK4 for temporal integration.", "result": "Efficient solution recovery validated against existing methods.", "conclusion": "The proposed scheme effectively approximates solutions and captures eventual periodicity."}}
{"id": "2508.10555", "pdf": "https://arxiv.org/pdf/2508.10555", "abs": "https://arxiv.org/abs/2508.10555", "authors": ["Haoran Sun", "Daoqi Liu", "Hongyu Zhou", "Maokun Li", "Shenheng Xu", "Fan Yang"], "title": "Physics-Informed Deep Contrast Source Inversion: A Unified Framework for Inverse Scattering Problems", "categories": ["physics.comp-ph", "cs.CE", "cs.LG"], "comment": null, "summary": "Inverse scattering problems are critical in electromagnetic imaging and\nmedical diagnostics but are challenged by their nonlinearity and diverse\nmeasurement scenarios. This paper proposes a physics-informed deep contrast\nsource inversion framework (DeepCSI) for fast and accurate medium\nreconstruction across various measurement conditions. Inspired by contrast\nsource inversion (CSI) and neural operator methods, a residual multilayer\nperceptron (ResMLP) is employed to model current distributions in the region of\ninterest under different transmitter excitations, effectively linearizing the\nnonlinear inverse scattering problem and significantly reducing the\ncomputational cost of traditional full-waveform inversion. By modeling medium\nparameters as learnable tensors and utilizing a hybrid loss function that\nintegrates state equation loss, data equation loss, and total variation\nregularization, DeepCSI establishes a fully differentiable framework for joint\noptimization of network parameters and medium properties. Compared with\nconventional methods, DeepCSI offers advantages in terms of simplicity and\nuniversal modeling capabilities for diverse measurement scenarios, including\nphase-less and multi-frequency observation. Simulations and experiments\ndemonstrate that DeepCSI achieves high-precision, robust reconstruction under\nfull-data, phaseless data, and multifrequency conditions, outperforming\ntraditional CSI methods and providing an efficient and universal solution for\ncomplex inverse scattering problems.", "AI": {"tldr": "DeepCSI, a physics-informed deep learning framework, linearizes nonlinear inverse scattering problems for fast, accurate medium reconstruction across diverse measurement scenarios.", "motivation": "Addressing the challenges of nonlinearity and varied measurement conditions in inverse scattering problems for electromagnetic imaging and medical diagnostics.", "method": "Combines contrast source inversion (CSI) and neural operator methods using a residual multilayer perceptron (ResMLP) to model current distributions, with a hybrid loss function for joint optimization.", "result": "Outperforms traditional CSI methods, achieving high-precision, robust reconstruction under full-data, phaseless, and multifrequency conditions.", "conclusion": "DeepCSI provides an efficient, universal solution for complex inverse scattering problems, simplifying and improving accuracy in diverse scenarios."}}
{"id": "2508.10347", "pdf": "https://arxiv.org/pdf/2508.10347", "abs": "https://arxiv.org/abs/2508.10347", "authors": ["Josh Culver", "Aubrey Ayres", "Evan Halloran", "Ryan Lin", "Emily Peng", "Charis Tsikkou"], "title": "An Analysis of the Riemann Problem for a $2 \\times 2$ System of Keyfitz-Kranzer Type Balance Laws With a Time-Dependent Source Term", "categories": ["math.AP", "math-ph", "math.CA", "math.DS", "math.MP", "34A05, 34C37, 34C45, 34E15, 35L45, 35L65, 35L67, 35L80, 35Q92,\n  65M06, 74L10, 76A30"], "comment": "35 pages. arXiv admin note: text overlap with arXiv:2508.05927", "summary": "We consider a system consisting of one conservation law and one balance law\nwith a time-dependent source term, and provide a comprehensive analysis of\nRiemann solutions, including the non-classical overcompressive delta shocks.\nThe minimal yet representative structure of the system captures essential\nfeatures of transport under density constraints and, despite its simplicity,\nserves as a versatile prototype for crowd-limited transport processes across\ndiverse contexts, including biological aggregation, ecological dispersal,\ngranular compaction, and traffic congestion. In addition to non-self-similar\nsolutions mentioned above, the associated Riemann problem admits solution\nstructures that traverse vacuum states ($\\rho = 0$) and the critical density\nthreshold ($\\rho = \\bar{\\rho}$), where mobility vanishes and characteristic\nspeed degenerates. Moreover, the explicit time dependence in the source term\nleads to the breakdown of self-similarity, resulting in distinct Riemann\nsolutions over successive time intervals and highlighting the dynamic nature of\nthe solution landscape. The theoretical findings are numerically confirmed\nusing the Local Lax-Friedrichs scheme.", "AI": {"tldr": "Analysis of Riemann solutions for a system with a conservation law and a balance law, including non-classical delta shocks and dynamic solutions due to a time-dependent source term.", "motivation": "To understand transport processes under density constraints, applicable to diverse fields like biology, ecology, and traffic.", "method": "Comprehensive analysis of Riemann solutions, including non-self-similar structures and numerical validation using the Local Lax-Friedrichs scheme.", "result": "Discovery of dynamic solutions traversing vacuum and critical density states, with explicit time dependence breaking self-similarity.", "conclusion": "The system serves as a versatile prototype for crowd-limited transport, with theoretical insights confirmed numerically."}}
{"id": "2508.10570", "pdf": "https://arxiv.org/pdf/2508.10570", "abs": "https://arxiv.org/abs/2508.10570", "authors": ["Ramsharan Rangarajan", "N. Sukumar"], "title": "CutVEM: Conforming virtual element method on embedded domains with shape-agnostic element agglomeration", "categories": ["math.NA", "cs.NA"], "comment": "35 pages, 20 figures", "summary": "The virtual element method (VEM) is a stabilized Galerkin method that is\nrobust and accurate on general polygonal meshes. This feature makes it an\nappealing candidate for simulations involving meshes with embedded interfaces\nand evolving geometries. However, the method can yield poorly conditioned\nstiffness matrices in such scenarios due to meshes having cut cells. We propose\na novel element agglomeration algorithm for the virtual element method to\naddress this issue. The agglomeration algorithm renders the VEM robust over\nplanar polygonal meshes, particularly on finite element meshes cut by immersed\ngeometries. The algorithm relies on the element stability ratio, which we\ndefine using the extreme eigenvalues of the element stiffness matrix. The\nresulting element agglomeration criterion is free from nebulous polygon quality\nmetrics and is defined independently of polygon shapes. The algorithm proceeds\niteratively and element-wise to maximize the minimum element stability ratio,\neven at the expense of degrading elements with better ratios. Crucially,\nelement agglomeration alters the number of elements, not the degree of freedom\ncount. The resulting method, which we label as CutVEM, retains node locations\nof cut elements unchanged, and yields discretizations that conform to embedded\ninterfaces. This, in turn, facilitates straightforward imposition of boundary\nconditions and interfacial constraints. Through detailed numerical experiments\nthat sample varied element-interface intersections, we demonstrate that CutVEM\nenjoys dramatically improved condition numbers of global stiffness matrices\nover the VEM. Furthermore, simulations of prototypical heat conduction problems\nwith Dirichlet and Neumann boundary conditions on domains with immersed\ngeometries show that element agglomeration does not noticeably degrade solution\naccuracy and that CutVEM retains the VEM's optimal convergence rate.", "AI": {"tldr": "The paper introduces CutVEM, a novel element agglomeration algorithm for the virtual element method (VEM) to improve conditioning on polygonal meshes with cut cells, maintaining accuracy and optimal convergence.", "motivation": "The VEM is robust on polygonal meshes but suffers from poor conditioning in scenarios with cut cells, necessitating a solution to retain its advantages.", "method": "The proposed CutVEM uses an element agglomeration algorithm based on the element stability ratio, iteratively maximizing stability without altering degrees of freedom.", "result": "CutVEM significantly improves condition numbers of stiffness matrices while preserving solution accuracy and optimal convergence rates.", "conclusion": "CutVEM effectively addresses conditioning issues in VEM for cut-cell meshes, making it a practical choice for simulations with embedded interfaces."}}
{"id": "2508.10237", "pdf": "https://arxiv.org/pdf/2508.10237", "abs": "https://arxiv.org/abs/2508.10237", "authors": ["Ray Yang", "Junchi Chen", "Douglas Thibodeaux", "Robert B. Wexler"], "title": "FreeBird.jl: An Extensible Toolbox for Simulating Interfacial Phase Equilibria", "categories": ["cond-mat.stat-mech", "cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph"], "comment": "17 pages, 5 figures", "summary": "We present FreeBird.jl, an extensible Julia-based platform for computational\nstudies of phase equilibria at generic interfaces. The package supports a range\nof system configurations, from atomistic solid surfaces to coarse-grained\nlattice$-$gas models, with energies evaluated using classical interatomic\npotentials or lattice Hamiltonians. Both atomistic and lattice systems\naccommodate single- or multi-component mixtures with flexibly definable surface\nand lattice geometries. Implemented sampling algorithms include nested\nsampling, Wang$-$Landau sampling, Metropolis Monte Carlo, and, for tractable\nlattice systems, exact enumeration. Leveraging Julia's type hierarchies and\nmultiple dispatch, FreeBird.jl provides a modular interface that allows\nseamless integration of system definitions, energy evaluators, and sampling\nschemes. Designed for flexibility, extensibility, and performance, FreeBird.jl\noffers a versatile framework for exploring the thermodynamics of interfacial\nphenomena.", "AI": {"tldr": "FreeBird.jl is a Julia-based platform for computational studies of phase equilibria at interfaces, supporting various system configurations and sampling algorithms.", "motivation": "To provide a flexible and extensible tool for studying interfacial thermodynamics across diverse systems, from atomistic to coarse-grained models.", "method": "Uses Julia's type hierarchies and multiple dispatch for modular integration of system definitions, energy evaluators, and sampling schemes (e.g., nested sampling, Wang-Landau, Metropolis Monte Carlo).", "result": "A versatile framework capable of handling single- or multi-component mixtures with customizable geometries and energy evaluations.", "conclusion": "FreeBird.jl is a powerful, adaptable platform for exploring interfacial phenomena, combining flexibility, extensibility, and performance."}}
{"id": "2508.10387", "pdf": "https://arxiv.org/pdf/2508.10387", "abs": "https://arxiv.org/abs/2508.10387", "authors": ["Giusi Vaira"], "title": "Blow-up phenomena for a boundary Yamabe problem with umbilic boundary", "categories": ["math.AP"], "comment": null, "summary": "We consider a linear perturbation of the classical geometric problem of\nprescribing the scalar and the boundary mean curvature problem in a Riemannian\nmanifold with umbilic boundary provided the Weyl tensor is non-zero everywhere.\nWe will deal with the case of negative scalar curvature showing the existence\nof a positive solutions when $n\\geq 8$.", "AI": {"tldr": "Existence of positive solutions for a linear perturbation of the scalar and boundary mean curvature problem in Riemannian manifolds with umbilic boundary, given non-zero Weyl tensor and negative scalar curvature for dimensions n\u22658.", "motivation": "To address the classical geometric problem of prescribing scalar and boundary mean curvature in Riemannian manifolds with umbilic boundary, particularly under the condition of non-zero Weyl tensor and negative scalar curvature.", "method": "Linear perturbation approach applied to the problem, focusing on manifolds with umbilic boundary and non-zero Weyl tensor.", "result": "Demonstrates the existence of positive solutions for dimensions n\u22658 under the specified conditions.", "conclusion": "The study successfully establishes the existence of solutions for the perturbed problem in higher dimensions (n\u22658) with negative scalar curvature and non-zero Weyl tensor."}}
{"id": "2508.10578", "pdf": "https://arxiv.org/pdf/2508.10578", "abs": "https://arxiv.org/abs/2508.10578", "authors": ["Brandiece N. Berry", "Md Mahmudul Islam", "Muhammad Mohebujjaman", "Neethu Suma Raveendran"], "title": "Efficient and Optimally Accurate Numerical Algorithms for Stochastic Turbulent Flow Problems", "categories": ["math.NA", "cs.NA", "65M12, 65M22, 65M60, 76W05"], "comment": "26 pages, 8 figures", "summary": "In this paper, we first propose a filter-based continuous Ensemble Eddy\nViscosity (EEV) model for stochastic turbulent flow problems. We then propose a\ngeneric algorithm for a family of fully discrete, grad-div regularized,\nefficient ensemble parameterized schemes for this model. The linearized\nImplicit-Explicit (IMEX) EEV generic algorithm shares a common coefficient\nmatrix for each realization per time-step, but with different right-hand-side\nvectors, which reduces the computational cost and memory requirements to the\norder of solving deterministic flow problems. Two family members of the\nproposed time-stepping algorithm are analyzed and proven to be stable. It is\nfound that one is first-order and the other is second-order accurate in time\nfor any stable finite element pairs. Avoiding the discrete inverse inequality,\nthe optimal convergence of both schemes is proven rigorously for both 2D and 3D\nproblems. For appropriately large grad-div parameters, both schemes are\nunconditionally stable and allow weakly divergence-free elements. Several\nnumerical tests are given for high expected Reynolds number ($\\textbf{E}[Re]$)\nproblems. The convergence rates are verified using manufactured solutions with\n$\\textbf{E}[Re]=10^{3},10^{4},\\;\\text{and}\\; 10^{5}$. For various high\n$\\textbf{E}[Re]$, the schemes are implemented on benchmark problems which\nincludes: A 2D channel flow over a unit step problem, a non-intrusive\nStochastic Collocation Method (SCM) is used to examine the performance of the\nschemes on a 2D Regularized Lid Driven Cavity (RLDC) problem, and a 3D RLDC\nproblem, and found them perform well.", "AI": {"tldr": "Proposes a filter-based EEV model for stochastic turbulent flows and a grad-div regularized, efficient ensemble algorithm. Two stable, accurate schemes are analyzed and tested on high Reynolds number problems.", "motivation": "Address computational cost and memory issues in stochastic turbulent flow problems by developing efficient ensemble schemes.", "method": "Introduces a linearized IMEX EEV algorithm with shared coefficient matrices and different right-hand-side vectors. Analyzes two time-stepping schemes (first and second-order accurate) for stability and convergence.", "result": "Proven stability and optimal convergence for 2D/3D problems. Schemes perform well on high Reynolds number benchmark tests.", "conclusion": "The proposed schemes are efficient, stable, and accurate for stochastic turbulent flows, validated through numerical tests."}}
{"id": "2508.10380", "pdf": "https://arxiv.org/pdf/2508.10380", "abs": "https://arxiv.org/abs/2508.10380", "authors": ["Qisheng Yu", "Boyu Liu", "Hongjun Xiang", "Shi Liu"], "title": "Type-I Multiferroic VHfO$_4$ with Strain-Switchable Magnetic Orders and Magnetoelectric Coupling", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Motivated by the complementary properties of vanadium-based ferromagnets and\nHfO$_2$-based ferroelectrics, we propose a novel multiferroic oxide, VHfO$_4$,\nthrough 50\\% Hf$^{4+}$ substitution with V$^{4+}$ in the ferroelectric $Pca2_1$\nphase of HfO$_2$. First-principles DFT calculations reveal that the\n$Pca2_1$-like VHfO$_4$ phase exhibits dynamic stability and concurrent ferroic\norders: robust ferroelectric polarization comparable to HfO$_2$ and V-driven\nmagnetism. Parallel tempering Monte Carlo simulations identify an\nantiferromagnetic ground state, while strain engineering enables tunable\nmagnetoelectric coupling. Biaxial in-plane strain induces four magnetic states:\nintralayer FM/interlayer AFM, intralayer AFM/interlayer FM, spiral-like\nnon-collinear order, and discrete alternating spin alignment. Critically,\n$c$-axis strain modulates magnetic energy landscapes, demonstrating\nelectromechanical control of magnetism. This work establishes VHfO$_4$ as a\nType-I multiferroic with coexisting atomic-scale ferroic origins and\nstrain-tunable cross-coupling, offering a platform for voltage-controlled\nspintronics devices.", "AI": {"tldr": "A novel multiferroic oxide, VHfO4, is proposed by substituting Hf4+ with V4+ in HfO2, exhibiting dynamic stability, ferroelectricity, and magnetism. Strain engineering enables tunable magnetoelectric coupling, making it promising for spintronics.", "motivation": "To combine the properties of vanadium-based ferromagnets and HfO2-based ferroelectrics into a single multiferroic material for advanced applications.", "method": "First-principles DFT calculations and parallel tempering Monte Carlo simulations are used to analyze VHfO4's stability, ferroic orders, and strain effects.", "result": "VHfO4 shows dynamic stability, robust ferroelectric polarization, and V-driven magnetism. Strain engineering reveals tunable magnetoelectric coupling and multiple magnetic states.", "conclusion": "VHfO4 is a Type-I multiferroic with coexisting ferroic orders and strain-tunable properties, suitable for voltage-controlled spintronics."}}
{"id": "2508.10448", "pdf": "https://arxiv.org/pdf/2508.10448", "abs": "https://arxiv.org/abs/2508.10448", "authors": ["Romain Petrides"], "title": "Regularity estimates on harmonic eigenmaps with arbitrary number of coordinates", "categories": ["math.AP", "math.DG"], "comment": null, "summary": "We revisit the well-established regularity estimates on harmonic maps on\nsurfaces to question their independence with respect to the dimension of the\ntarget manifold. We are mainly interested in harmonic maps into target\nellipsoids, that we call Laplace harmonic eigenmaps. These maps are related to\ncritical metrics in the context of eigenvalue optimization. The tools that we\ngather here are useful to handle convergence of almost critical metrics via\nPalais-Smale sequences of (almost harmonic) eigenmaps. They could also be a\npreliminary step for a general regularity theory for critical points of\ninfinite combinations of eigenvalues.", "AI": {"tldr": "The paper investigates the dimension independence of regularity estimates for harmonic maps into ellipsoids, termed Laplace harmonic eigenmaps, and their role in eigenvalue optimization.", "motivation": "To explore the relationship between harmonic maps and critical metrics in eigenvalue optimization, and to develop tools for analyzing convergence of almost critical metrics.", "method": "Revisits regularity estimates for harmonic maps, focusing on Laplace harmonic eigenmaps into ellipsoids, and uses Palais-Smale sequences for analysis.", "result": "Provides tools for handling convergence of almost critical metrics and suggests preliminary steps for a broader regularity theory for eigenvalue combinations.", "conclusion": "The study advances understanding of harmonic maps in eigenvalue optimization and lays groundwork for future research on infinite eigenvalue combinations."}}
{"id": "2508.10630", "pdf": "https://arxiv.org/pdf/2508.10630", "abs": "https://arxiv.org/abs/2508.10630", "authors": ["Kasper B\u00e5gmark", "Adam Andersson", "Stig Larsson"], "title": "Nonlinear filtering based on density approximation and deep BSDE prediction", "categories": ["math.NA", "cs.NA", "stat.CO", "stat.ML", "60G25, 60G35, 62F15, 62G07, 62M20, 65C30, 65M75, 68T07"], "comment": "19 pages, 6 figures", "summary": "A novel approximate Bayesian filter based on backward stochastic differential\nequations is introduced. It uses a nonlinear Feynman--Kac representation of the\nfiltering problem and the approximation of an unnormalized filtering density\nusing the well-known deep BSDE method and neural networks. The method is\ntrained offline, which means that it can be applied online with new\nobservations. A mixed a priori-a posteriori error bound is proved under an\nelliptic condition. The theoretical convergence rate is confirmed in two\nnumerical examples.", "AI": {"tldr": "A new Bayesian filter using backward stochastic differential equations (BSDEs) and neural networks is introduced, with offline training for online application. Theoretical error bounds and numerical validation are provided.", "motivation": "To develop an efficient Bayesian filtering method leveraging BSDEs and neural networks for practical online applications.", "method": "Uses nonlinear Feynman-Kac representation and deep BSDE method with neural networks to approximate unnormalized filtering density. Trained offline for online use.", "result": "Proves mixed a priori-a posteriori error bound under elliptic condition. Numerical examples confirm theoretical convergence rate.", "conclusion": "The method is effective, with theoretical and numerical validation supporting its practical applicability."}}
{"id": "2508.10418", "pdf": "https://arxiv.org/pdf/2508.10418", "abs": "https://arxiv.org/abs/2508.10418", "authors": ["Feng-Feng Song", "Naoki Kawashima"], "title": "Variational boundary based tensor network renormalization group", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "comment": "7 pages, 5 figures", "summary": "We propose a real-space renormalization group algorithm for accurately\ncoarse-graining two-dimensional tensor networks. The central innovation of our\nmethod lies in utilizing variational boundary tensors as a globally optimized\nenvironment for the entire system. Based on this optimized environment, we\nconstruct renormalization projectors that significantly enhance accuracy. By\nleveraging the canonical form of tensors, our algorithm maintains the same\ncomputational complexity as the original tensor renormalization group (TRG)\nmethod, yet achieves higher accuracy than existing approaches that do not\nincorporate entanglement filtering. Our work offers a practical pathway for\nextending TRG methods to higher dimensions while keeping computational costs\nmanageable.", "AI": {"tldr": "A new real-space renormalization group algorithm for 2D tensor networks improves accuracy using variational boundary tensors and maintains computational efficiency.", "motivation": "To enhance the accuracy of coarse-graining 2D tensor networks while keeping computational costs manageable.", "method": "Utilizes variational boundary tensors for global optimization and constructs renormalization projectors based on this environment, leveraging tensor canonical forms.", "result": "Achieves higher accuracy than existing TRG methods without entanglement filtering, with the same computational complexity.", "conclusion": "Provides a practical way to extend TRG methods to higher dimensions efficiently."}}
{"id": "2508.10508", "pdf": "https://arxiv.org/pdf/2508.10508", "abs": "https://arxiv.org/abs/2508.10508", "authors": ["Ferdinand Eitler", "Peter Lewintan"], "title": "On $\\mathrm{BV}^{\\mathbb{A}}$-Minimisers in two Dimensions", "categories": ["math.AP", "35B65, 35J60, 49J45, 35A15"], "comment": null, "summary": "We investigate into the regularity of $\\mathrm{BV}^{\\mathbb{A}}$-minimisers\nfor $\\mathbb{C}$-elliptic differential operators $\\mathbb{A}$ in $2$\ndimensions. Our studies strongly rely on the special structure of such\ndifferential operators. The gradient integrability is established for the sharp\nellipticity range known from the (symmetric) gradient case.", "AI": {"tldr": "The paper explores the regularity of BV^\ud835\udd38-minimisers for \u2102-elliptic operators in 2D, leveraging their structure to establish gradient integrability.", "motivation": "To understand the regularity properties of minimisers for \u2102-elliptic differential operators in two dimensions.", "method": "Relies on the special structure of \u2102-elliptic operators and extends techniques from the symmetric gradient case.", "result": "Gradient integrability is proven for the sharp ellipticity range.", "conclusion": "The study confirms the regularity of BV^\ud835\udd38-minimisers for \u2102-elliptic operators in 2D, matching known results for symmetric gradients."}}
{"id": "2508.10648", "pdf": "https://arxiv.org/pdf/2508.10648", "abs": "https://arxiv.org/abs/2508.10648", "authors": ["Hugo M. Verhelst", "Angelos Mantzaflaris", "Matthias M\u00f6ller"], "title": "Isogeometric multi-patch shell analysis using the Geometry + Simulation Modules", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Isogeometric Analysis (IGA) bridges Computer-Aided Design (CAD) and Finite\nElement Analysis (FEA) by employing splines as a common basis for geometry and\nanalysis. One of the advantages of IGA is in the realm of thin shell analysis:\ndue to the arbitrary continuity of the spline basis, Kirchhoff-Love shells can\nbe modeled without the need to introduce unknowns for the mid-plane rotations,\nleading to a reduction in the number of unknowns. In this paper, we provide the\nbackground of an implementation of Isogeometric Kirchhoff--Love shells within\nthe Geometry + Simulation Modules (G+Smo). This paper accompanies multiple\nprevious publications and elaborates on the design of the software used in\nthese papers, rather than the novelty of the methods presented therein. The\npresented implementation provides patch coupling via penalty methods and\nunstructured splines, goal-oriented error estimators, several algorithms for\nstructural analysis and advanced algorithms for the modeling of wrinkling in\nhyperelastic membranes. These methods are all contained in three new modules in\nG+Smo: a module for Kirchhoff-Love shells, a module for structural analysis,\nand a module for unstructured spline constructions. As motivated in this paper,\nthe modules are implemented to be compatible with future developments. For\nexample, by providing base implementations of material laws, by using black-box\nfunctions for the structural analysis module, or by providing a standardized\napproach for the implementation of unstructured spline constructions. Overall,\nthis paper demonstrates that the new modules contribute to a versatile\necosystem for the modeling of multi-patch shell problems through fast\noff-the-shelf solvers with a simple interface, designed to be extended in\nfuture research.", "AI": {"tldr": "The paper details the implementation of Isogeometric Kirchhoff-Love shells in G+Smo, focusing on software design and compatibility with future developments rather than novel methods.", "motivation": "To bridge CAD and FEA using splines for thin shell analysis, reducing unknowns and enhancing computational efficiency.", "method": "Implementation includes patch coupling via penalty methods, unstructured splines, goal-oriented error estimators, and algorithms for structural analysis and wrinkling modeling.", "result": "Three new modules in G+Smo enable versatile modeling of multi-patch shell problems with fast solvers and extendable interfaces.", "conclusion": "The modules provide a robust foundation for future research in multi-patch shell modeling, emphasizing compatibility and extensibility."}}
{"id": "2508.10422", "pdf": "https://arxiv.org/pdf/2508.10422", "abs": "https://arxiv.org/abs/2508.10422", "authors": ["Ludovico Foss\u00e0", "Pierre Ricco"], "title": "Compressible boundary layers over isotropic porous surfaces", "categories": ["physics.flu-dyn", "physics.app-ph", "physics.comp-ph", "76J20, 76N20, 76S05"], "comment": null, "summary": "A compressible laminar boundary layer developing over an isotropic porous\nsubstrate is investigated by asymptotic and numerical methods. The substrate is\nmodeled as an array of cubes. The momentum and enthalpy balance equations are\nderived by volume averaging. The self-similar solution proposed by Tsiberkin\n(2018) [Transp. Porous Media 121(1):109-120] for streamwise-growing\npermeability is extended to include compressibility, heat conduction and a\nnonlinear drag. The velocity profile shows an inflection point at the free\nfluid-porous interfacial layer, below which it decreases to zero. A marked\nreduction of the adiabatic recovery temperature of the fluid and the velocity\ngradient at the interface is observed for high porosity, large grains and\nrelatively high Mach numbers. The temperature imposed at the bottom of the\nporous substrate has a negligible influence on the shear stresses.", "AI": {"tldr": "The paper investigates a compressible laminar boundary layer over an isotropic porous substrate using asymptotic and numerical methods, extending Tsiberkin's self-similar solution to include compressibility, heat conduction, and nonlinear drag.", "motivation": "To understand the behavior of compressible laminar boundary layers over porous substrates, particularly the effects of compressibility, heat conduction, and nonlinear drag on velocity and temperature profiles.", "method": "Asymptotic and numerical methods are used to analyze the boundary layer. The substrate is modeled as an array of cubes, and momentum and enthalpy balance equations are derived via volume averaging. Tsiberkin's self-similar solution is extended to include additional factors.", "result": "The velocity profile exhibits an inflection point at the interfacial layer, decreasing to zero below. High porosity, large grains, and high Mach numbers reduce the adiabatic recovery temperature and velocity gradient. The bottom temperature of the substrate has negligible impact on shear stresses.", "conclusion": "The study highlights the influence of porosity, grain size, and Mach number on boundary layer behavior, with minimal effect from substrate temperature on shear stresses."}}
{"id": "2508.10690", "pdf": "https://arxiv.org/pdf/2508.10690", "abs": "https://arxiv.org/abs/2508.10690", "authors": ["Filomena De Filippis", "Antonella Nastasi", "Cintia Pacchiano Camacho"], "title": "Vectorial Double Phase Obstacle Problems", "categories": ["math.AP"], "comment": null, "summary": "We investigate partial regularity for vector valued local minimizers of\ndouble phase functionals, under vectorial obstacle type constraints satisfying\nappropriate topological properties.", "AI": {"tldr": "Study of partial regularity for vector-valued minimizers of double phase functionals under obstacle constraints.", "motivation": "To understand regularity properties of minimizers in constrained settings with topological conditions.", "method": "Analyze vector-valued local minimizers of double phase functionals with obstacle constraints.", "result": "Partial regularity is established under suitable topological properties of the constraints.", "conclusion": "The findings extend understanding of regularity in constrained variational problems."}}
{"id": "2508.10674", "pdf": "https://arxiv.org/pdf/2508.10674", "abs": "https://arxiv.org/abs/2508.10674", "authors": ["Wei Chen", "Xinyuan Du", "Jun Hu"], "title": "The Hu-Zhang element for linear elasticity on curved domains", "categories": ["math.NA", "cs.NA", "65N12, 65N30, 74S05"], "comment": null, "summary": "This paper extends the Hu-Zhang element for linear elasticity problems to\ncurved domains, preserving strong symmetry and H(div)-conformity. The\nnon-polynomial structure of the curved Hu-Zhang element makes it difficult to\nanalyze the stability result, which is overcome by establishing a novel inf-sup\ncondition. Optimal convergence rates are achieved for all variables except the\nstress $L^2$-error. This suboptimality originates from the fact that the\ndivergence space of the curved Hu-Zhang element is not contained in the\ndiscrete displacement space, which is rectified by local $p$-enrichment in the\nHu-Zhang space on curved boundary elements. Some numerical experiments validate\nthe theoretical results.", "AI": {"tldr": "The paper extends the Hu-Zhang element to curved domains, ensuring symmetry and H(div)-conformity, and addresses stability and convergence issues with a new inf-sup condition and local enrichment.", "motivation": "To adapt the Hu-Zhang element for curved domains while maintaining key properties like symmetry and H(div)-conformity, and to resolve stability and convergence challenges.", "method": "Extends the Hu-Zhang element to curved domains, introduces a novel inf-sup condition for stability, and uses local p-enrichment to improve convergence.", "result": "Optimal convergence rates achieved for most variables, though stress L\u00b2-error remains suboptimal. Numerical experiments support the findings.", "conclusion": "The curved Hu-Zhang element is successfully extended and stabilized, with local enrichment addressing convergence issues, validated by numerical results."}}
{"id": "2508.10505", "pdf": "https://arxiv.org/pdf/2508.10505", "abs": "https://arxiv.org/abs/2508.10505", "authors": ["Hanwen Kang", "Tenglong Lu", "Zhanbin Qi", "Jiandong Guo", "Sheng Meng", "Miao Liu"], "title": "FastTrack: a fast method to evaluate mass transport in solid leveraging universal machine learning interatomic potential", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "We introduce a rapid, accurate framework for computing atomic migration\nbarriers in crystals by combining universal machine learning force fields\n(MLFFs) with 3D potential energy surface sampling and interpolation. Our method\nsuppresses periodic self interactions via supercell expansion, builds a\ncontinuous PES from MLFF energies on a spatial grid, and extracts minimum\nenergy pathways without predefined NEB images. Across twelve benchmark\nelectrode and electrolyte materials including LiCoO2, LiFePO4, and LGPS our\nMLFF-derived barriers lie within tens of meV of DFT and experiment, while\nachieving ~10^2 x speedups over DFT-NEB. We benchmark GPTFF, CHGNet, and MACE,\nshow that fine-tuning on PBE/PBE+U data further enhances accuracy, and provide\nan open-source package for high-throughput materials screening and interactive\nPES visualization.", "AI": {"tldr": "A fast, accurate framework for computing atomic migration barriers in crystals using MLFFs and 3D PES sampling, achieving DFT-level accuracy with significant speedups.", "motivation": "To overcome the computational cost and limitations of traditional DFT-NEB methods for atomic migration barrier calculations.", "method": "Combines universal MLFFs with 3D PES sampling and interpolation, suppresses periodic self-interactions via supercell expansion, and extracts minimum energy pathways without predefined NEB images.", "result": "MLFF-derived barriers are within tens of meV of DFT and experiment, with ~100x speedups over DFT-NEB. Benchmarked GPTFF, CHGNet, and MACE, showing improved accuracy with fine-tuning.", "conclusion": "The framework provides a rapid, accurate alternative to DFT-NEB, with an open-source package for high-throughput screening and PES visualization."}}
{"id": "2508.10697", "pdf": "https://arxiv.org/pdf/2508.10697", "abs": "https://arxiv.org/abs/2508.10697", "authors": ["Shuchen Guo"], "title": "From Kac particles to the Landau equation with hard potentials: BBGKY hierarchy method", "categories": ["math.AP"], "comment": "30 pages", "summary": "We study the Kac particle model for the space-homogenous Landau equation with\nhard potentials. By showing a sharper Povzner-type inequality, we obtain the\nuniform-in-time and uniform-in-N propagation of exponential moment for the\nfirst marginal of the solution of the many-particle Liouville equation. This\nkey property enables us to show the uniqueness of weak solutions of the\ncorresponding infinite Landau hierarchy by coupling method. As a result, we\nprove the propagation of chaos for the Landau equation with hard potentials.", "AI": {"tldr": "The paper proves propagation of chaos for the Landau equation with hard potentials using a sharper Povzner-type inequality and coupling methods.", "motivation": "To understand the behavior of the Kac particle model for the Landau equation with hard potentials and establish uniqueness of weak solutions.", "method": "Uses a sharper Povzner-type inequality to show uniform propagation of exponential moments and employs coupling methods for uniqueness.", "result": "Demonstrates uniform-in-time propagation of exponential moments and proves propagation of chaos for the Landau equation.", "conclusion": "The study successfully establishes propagation of chaos and uniqueness of solutions for the Landau equation with hard potentials."}}
{"id": "2508.10125", "pdf": "https://arxiv.org/pdf/2508.10125", "abs": "https://arxiv.org/abs/2508.10125", "authors": ["Christian Engwer", "Carsten Gr\u00e4ser", "Steffen M\u00fcthing", "Simon Praetorius", "Oliver Sander"], "title": "Concepts for Composing Finite Element Function Space Bases", "categories": ["cs.MS", "cs.NA", "math.NA", "68U20, 65N30, 65N08", "G.4; G.1.8"], "comment": "arXiv admin note: substantial text overlap with arXiv:1806.09545", "summary": "Finite Element discretizations of coupled multi-physics partial differential\nequation models require the handling of composed function spaces. In this paper\nwe discuss software concepts and abstractions to handle the composition of\nfunction spaces, based on a representation of product spaces as trees of\nsimpler bases. From this description, many different numberings of degrees of\nfreedom by multi-indices can be derived in a natural way, allowing to adapt the\nfunction spaces to very different data layouts, so that it opens the\npossibility to directly use the finite element code with very different linear\nalgebra codes, different data structures, and different algebraic solvers.\n  A recurring example throughout the paper is the stationary Stokes equation\nwith Taylor--Hood elements as these are naturally formulated as product spaces\nand highlight why different storage patterns are desirable.\n  In the second half of the paper we discuss a particular realization of most\nof these concepts in the \\dunemodule{dune-functions} module, as part of the\nDUNE ecosystem.", "AI": {"tldr": "The paper discusses software abstractions for handling composed function spaces in finite element discretizations, using tree-based representations to enable flexible degree-of-freedom numbering and compatibility with various linear algebra codes.", "motivation": "To address the need for adaptable and efficient handling of composed function spaces in multi-physics PDE models, enabling compatibility with diverse data layouts and solvers.", "method": "Proposes representing product spaces as trees of simpler bases, allowing derivation of multi-index-based degree-of-freedom numberings. Uses the Stokes equation with Taylor-Hood elements as an example.", "result": "Demonstrates the feasibility of flexible function space composition and numbering, facilitating integration with different linear algebra frameworks.", "conclusion": "The approach is realized in the DUNE-Functions module, showcasing practical applicability in the DUNE ecosystem."}}
{"id": "2508.10590", "pdf": "https://arxiv.org/pdf/2508.10590", "abs": "https://arxiv.org/abs/2508.10590", "authors": ["Viswak R Balaji", "Samuel Punch"], "title": "Simulating Mass-Dependent Decoherence in Quantum Computers: Baseline Signatures for Testing Gravity-Induced Collapse", "categories": ["quant-ph", "cs.ET", "physics.comp-ph"], "comment": null, "summary": "We present a quantum computing simulation study of mass-dependent decoherence\nmodels inspired by Penrose's gravity-induced collapse hypothesis. According to\nobjective reduction (OR) theory, quantum superpositions become unstable when\nthe gravitational self-energy difference between branches exceeds a certain\nthreshold, leading to a collapse time $\\tau \\approx \\hbar / E_G$. In this work,\nwe implement a mass-dependent dephasing noise channel, $p(m) = 1 - e^{-k\nm^{\\alpha}}$, within the Qiskit AerSimulator, where $m$ is a proxy for the\neffective mass of a superposition, mapped to circuit parameters such as the\nnumber of entangled qubits or branch size. We apply this model to three\ncanonical quantum computing experiments: GHZ state parity measurements,\nbranch-mass entanglement tests, and Grover's search to generate distinctive\ncollapse signatures that differ qualitatively from constant-rate dephasing. The\nresulting patterns serve as a baseline reference: if future hardware\nexperiments exhibit the same scaling trends under ideal isolation, this could\nindicate a contribution from mass-dependent collapse processes. Conversely,\ndeviation toward constant-noise behaviour would suggest the absence of such\ngravitationally induced effects. Our results provide a reproducible protocol\nand reference for using quantum computers as potential testbeds for probing\nfundamental questions in quantum mechanics.", "AI": {"tldr": "A quantum simulation study explores mass-dependent decoherence models inspired by Penrose's gravity-induced collapse hypothesis, using Qiskit AerSimulator to test collapse signatures in quantum experiments.", "motivation": "To investigate whether quantum superpositions collapse due to gravitational effects, as suggested by Penrose's objective reduction (OR) theory, and to provide a protocol for testing this in quantum computing experiments.", "method": "Implemented a mass-dependent dephasing noise channel in Qiskit AerSimulator, applied to GHZ state parity measurements, branch-mass entanglement tests, and Grover's search to identify collapse signatures.", "result": "Generated distinctive collapse patterns differing from constant-rate dephasing, serving as a baseline for future hardware experiments to detect mass-dependent collapse processes.", "conclusion": "The study offers a reproducible protocol for using quantum computers to probe fundamental quantum mechanics questions, with potential to confirm or rule out gravitationally induced collapse effects."}}
{"id": "2508.10722", "pdf": "https://arxiv.org/pdf/2508.10722", "abs": "https://arxiv.org/abs/2508.10722", "authors": ["Moritz Immanuel Gau", "Katharina Hopf"], "title": "Well-posedness and relaxation in a simplified model for viscoelastic phase separation via Hilbertian gradients flows", "categories": ["math.AP"], "comment": null, "summary": "This article is concerned with a gradient-flow approach to a Cahn-Hilliard\nmodel for viscoelastic phase separation introduced by Zhou et al. (Phys. Rev.\nE, 2006) in its variant with constant mobility. By means of time-incremental\nminimisation and generalised contractivity estimates, we establish the global\nwell-posedness of the Cauchy problem for moderately regular initial data. For\ngeneral finite-energy data we obtain the existence of gradient-flow solutions\nand a stability estimate of weak-strong type. We further study the asymptotic\nbehaviour for relaxation time and bulk modulus depending on a small parameter.\nDepending on the scaling, we recover the Cahn-Hilliard, the mass-conserving\nAllen-Cahn or the viscous Cahn-Hilliard equation. A challenge in the\nwell-posedness analysis is the failure of semiconvexity of the appropriate\ndriving functional, which is caused by a phase-dependence of the bulk modulus.", "AI": {"tldr": "The paper analyzes a gradient-flow approach to a Cahn-Hilliard model for viscoelastic phase separation, proving global well-posedness for moderately regular initial data and existence of gradient-flow solutions for finite-energy data. It also examines asymptotic behavior under parameter scaling.", "motivation": "The study aims to address the well-posedness and stability of a Cahn-Hilliard model for viscoelastic phase separation, particularly focusing on challenges like the lack of semiconvexity in the driving functional.", "method": "The authors use time-incremental minimization and generalized contractivity estimates to analyze the model. They also study asymptotic behavior under parameter scaling.", "result": "Global well-posedness is established for moderately regular initial data, and gradient-flow solutions are obtained for finite-energy data. The asymptotic analysis recovers known equations like Cahn-Hilliard and mass-conserving Allen-Cahn.", "conclusion": "The work successfully addresses the well-posedness and stability of the model, despite the challenge of non-semiconvexity, and provides insights into its asymptotic behavior under parameter scaling."}}
{"id": "2508.10202", "pdf": "https://arxiv.org/pdf/2508.10202", "abs": "https://arxiv.org/abs/2508.10202", "authors": ["Sreeram Venkat", "Kasia Swirydowicz", "Noah Wolfe", "Omar Ghattas"], "title": "Mixed-Precision Performance Portability of FFT-Based GPU-Accelerated Algorithms for Block-Triangular Toeplitz Matrices", "categories": ["cs.DC", "cs.NA", "cs.PF", "math.NA", "65Y20, 65Y05, 65Y10, 68Q25, 68W40, 65M32, 5B05", "F.2; G.4; C.4"], "comment": null, "summary": "The hardware diversity displayed in leadership-class computing facilities,\nalongside the immense performance boosts exhibited by today's GPUs when\ncomputing in lower precision, provide a strong incentive for scientific HPC\nworkflows to adopt mixed-precision algorithms and performance portability\nmodels. We present an on-the-fly framework using Hipify for performance\nportability and apply it to FFTMatvec-an HPC application that computes\nmatrix-vector products with block-triangular Toeplitz matrices. Our approach\nenables FFTMatvec, initially a CUDA-only application, to run seamlessly on AMD\nGPUs with excellent observed performance. Performance optimizations for AMD\nGPUs are integrated directly into the open-source rocBLAS library, keeping the\napplication code unchanged. We then present a dynamic mixed-precision framework\nfor FFTMatvec; a Pareto front analysis determines the optimal mixed-precision\nconfiguration for a desired error tolerance. Results are shown for AMD Instinct\nMI250X, MI300X, and the newly launched MI355X GPUs. The performance-portable,\nmixed-precision FFTMatvec is scaled to 2,048 GPUs on the OLCF Frontier\nsupercomputer.", "AI": {"tldr": "A framework using Hipify enables performance portability and mixed-precision for FFTMatvec, scaling it to 2,048 GPUs on Frontier.", "motivation": "Hardware diversity and GPU performance boosts in lower precision motivate mixed-precision adoption in HPC workflows.", "method": "Uses Hipify for portability, integrates optimizations into rocBLAS, and employs a dynamic mixed-precision framework with Pareto front analysis.", "result": "FFTMatvec runs on AMD GPUs with excellent performance, scaling to 2,048 GPUs on Frontier.", "conclusion": "The approach successfully combines performance portability and mixed-precision for HPC applications."}}
{"id": "2508.10666", "pdf": "https://arxiv.org/pdf/2508.10666", "abs": "https://arxiv.org/abs/2508.10666", "authors": ["Timothy Heightman", "Marcin P\u0142odzie\u0144"], "title": "Deep Learning in Classical and Quantum Physics", "categories": ["quant-ph", "cs.AI", "cs.NE", "physics.comp-ph"], "comment": null, "summary": "Scientific progress is tightly coupled to the emergence of new research\ntools. Today, machine learning (ML)-especially deep learning (DL)-has become a\ntransformative instrument for quantum science and technology. Owing to the\nintrinsic complexity of quantum systems, DL enables efficient exploration of\nlarge parameter spaces, extraction of patterns from experimental data, and\ndata-driven guidance for research directions. These capabilities already\nsupport tasks such as refining quantum control protocols and accelerating the\ndiscovery of materials with targeted quantum properties, making ML/DL literacy\nan essential skill for the next generation of quantum scientists. At the same\ntime, DL's power brings risks: models can overfit noisy data, obscure causal\nstructure, and yield results with limited physical interpretability.\nRecognizing these limitations and deploying mitigation strategies is crucial\nfor scientific rigor. These lecture notes provide a comprehensive,\ngraduate-level introduction to DL for quantum applications, combining\nconceptual exposition with hands-on examples. Organized as a progressive\nsequence, they aim to equip readers to decide when and how to apply DL\neffectively, to understand its practical constraints, and to adapt AI methods\nresponsibly to problems across quantum physics, chemistry, and engineering.", "AI": {"tldr": "The paper discusses the transformative role of deep learning (DL) in quantum science, highlighting its benefits and risks, and provides a graduate-level guide for its responsible application.", "motivation": "To address the growing importance of DL in quantum science and technology, while acknowledging its potential pitfalls, the paper aims to educate the next generation of quantum scientists on effective and responsible DL use.", "method": "The lecture notes combine conceptual explanations with practical examples, structured as a progressive sequence to teach DL applications in quantum physics, chemistry, and engineering.", "result": "DL aids in exploring quantum parameter spaces, extracting patterns from data, and guiding research, but risks like overfitting and limited interpretability must be managed.", "conclusion": "DL literacy is essential for quantum scientists, but its application must be informed by an understanding of its limitations and mitigation strategies to ensure scientific rigor."}}
{"id": "2508.10773", "pdf": "https://arxiv.org/pdf/2508.10773", "abs": "https://arxiv.org/abs/2508.10773", "authors": ["Yuxiang Qiao"], "title": "$\\mathrm{C}^2$ estimates for general $p$-Hessian equations on closed Riemannian manifolds", "categories": ["math.AP", "math.DG", "35B45, 58J05 (Primary) 35J60, 35R01 (Secondary)"], "comment": "Any comments welcome!", "summary": "We study the $\\mathrm{C}^2$ estimates for $p$-Hessian equations with general\nleft-hand and right-hand terms on closed Riemannian manifolds of dimension $n$.\nTo overcome the constraints of closed manifolds, we advance a new kind of\n\"subsolution\", called pseudo-solution, which generalizes\n\"$\\mathcal{C}$-subsolution\" to some extent and is well-defined for fully\ngeneral $p$-Hessian equations. Based on pseudo-solutions, we prove the\n$\\mathrm{C}^0$ estimates, first-order estimates for general $p$-Hessian\nequations, and the corresponding second-order estimates when $p\\in\\{2, n-1,\nn\\}$, under sharp conditions -- we don't impose curvature restrictions,\nconvexity conditions or \"MTW condition\" on our main results. Some other\nconclusions related to a priori estimates and different kinds of \"subsolutions\"\nare also given, including estimates for \"semi-convex\" solutions and when there\nexists a pseudo-solution.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.10320", "pdf": "https://arxiv.org/pdf/2508.10320", "abs": "https://arxiv.org/abs/2508.10320", "authors": ["Aaditya Chandrasekhar", "Stefan Knapik", "Deepak Sharma", "John Reidy", "Ian McCue", "Jian Cao", "Wei Chen"], "title": "TOBACO: Topology Optimization via Band-limited Coordinate Networks for Compositionally Graded Alloys", "categories": ["cs.CE", "cs.NA", "math.NA"], "comment": "Submitted to Structural and Multidisciplinary Optimization", "summary": "Compositionally Graded Alloys (CGAs) offer unprecedented design flexibility\nby enabling spatial variations in composition; tailoring material properties to\nlocal loading conditions. This flexibility leads to components that are\nstronger, lighter, and more cost-effective than traditional monolithic\ncounterparts. The fabrication of CGAs have become increasingly feasible owing\nto recent advancements in additive manufacturing (AM), particularly in\nmulti-material printing and improved precision in material deposition. However,\nAM of CGAs requires imposition of manufacturing constraints; in particular\nlimits on the maximum spatial gradation of composition.\n  This paper introduces a topology optimization (TO) based framework for\ndesigning optimized CGA components with controlled compositional gradation. In\nparticular, we represent the constrained composition distribution using a\nband-limited coordinate neural network. By regulating the network's bandwidth,\nwe ensure implicit compliance with gradation limits, eliminating the need for\nexplicit constraints. The proposed approach also benefits from the inherent\nadvantages of TO using coordinate networks, including mesh independence,\nhigh-resolution design extraction, and end-to-end differentiability. The\neffectiveness of our framework is demonstrated through various elastic and\nthermo-elastic TO examples.", "AI": {"tldr": "A topology optimization framework using neural networks to design Compositionally Graded Alloys (CGAs) with controlled gradation, ensuring compliance with manufacturing constraints.", "motivation": "CGAs offer superior material properties but require controlled gradation for feasible additive manufacturing.", "method": "Uses a band-limited coordinate neural network to represent and regulate composition distribution, ensuring implicit compliance with gradation limits.", "result": "Demonstrated effectiveness through elastic and thermo-elastic topology optimization examples.", "conclusion": "The framework enables optimized CGA designs with controlled gradation, leveraging neural networks for compliance and efficiency."}}
{"id": "2508.10671", "pdf": "https://arxiv.org/pdf/2508.10671", "abs": "https://arxiv.org/abs/2508.10671", "authors": ["Fabio Tarocco", "Pi A. B. Haase", "Fabijan Pavo\u0161evi\u0107", "Vijay Krishna", "Leonardo Guidoni", "Stefan Knecht", "Martina Stella"], "title": "AEGISS -- Atomic orbital and Entropy-based Guided Inference for Space Selection -- A novel semi-automated active space selection workflow for quantum chemistry and quantum computing applications", "categories": ["physics.chem-ph", "cond-mat.str-el", "physics.comp-ph", "quant-ph"], "comment": null, "summary": "The selection of a balanced active space is a critical step in\nmulti-reference quantum chemistry calculations, particularly for systems with\nstrong electron correlation. Likewise, active space selection is a key to\nunlock the potential of contemporary quantum computing in quantum chemistry.\nAlbeit recent progress, there remains a lack of a unified, robust, and fully\nautomated framework for active space selection that performs reliably across a\nwide range of molecular systems.\n  In this work, we present a novel approach inspired by both the AVAS (Atomic\nValence Active Space) and AutoCAS methods. Our method unifies orbital entropy\nanalysis with atomic orbital projections to guide the construction of\nchemically and physically meaningful active spaces. This integrated scheme\nenables a more consistent and flexible selection of active orbitals while\nretaining automation and scalability. We validate our approach on a set of\nmolecular systems relevant to photodynamic therapy, in particular a set of\nRu(II)-complexes, selected to span increasing levels of electron correlation\nand structural complexity. These molecules serve as challenging test cases due\nto the presence of strong static correlation and the need for highly accurate\nelectronic structure descriptions. Our results demonstrate that the method can\nreliably identify compact, chemically intuitive active spaces that capture the\nessential physics, making it suitable for both classical and quantum\ncomputational frameworks.\n  Furthermore, we have developed this approach in a package that is intuitive\nto use for users and can be interfaced with both standard quantum chemistry and\nquantum computing applications, making it accessible to a broad research\ncommunity.", "AI": {"tldr": "A novel automated method for active space selection in quantum chemistry combines orbital entropy analysis and atomic orbital projections, validated on challenging Ru(II)-complexes.", "motivation": "Addressing the lack of a unified, robust, and automated framework for active space selection in systems with strong electron correlation, crucial for quantum chemistry and quantum computing.", "method": "Integrates orbital entropy analysis with atomic orbital projections, inspired by AVAS and AutoCAS methods, for flexible and consistent active space selection.", "result": "Reliably identifies compact, chemically intuitive active spaces for challenging systems like Ru(II)-complexes, suitable for classical and quantum frameworks.", "conclusion": "The method is scalable, automated, and accessible, with potential applications in both quantum chemistry and quantum computing."}}
{"id": "2508.10892", "pdf": "https://arxiv.org/pdf/2508.10892", "abs": "https://arxiv.org/abs/2508.10892", "authors": ["S. E. Boutiah", "D. Kinzebulatov"], "title": "Upper bound on heat kernels of finite particle systems of Keller-Segel type", "categories": ["math.AP", "math-ph", "math.MP", "math.PR"], "comment": null, "summary": "We obtain an upper bound on the heat kernel of the Keller-Segel finite\nparticle system that exhibits blow up effects. The proof exploits a connection\nbetween Keller-Segel finite particles and certain non-local operators. The\nlatter allows to address some aspects of the critical behaviour of the\nKeller-Segel system resulting from its two-dimensionality.", "AI": {"tldr": "Upper bound on the heat kernel of the Keller-Segel finite particle system, showing blow-up effects.", "motivation": "Understand the critical behavior of the Keller-Segel system due to its two-dimensionality.", "method": "Exploits a connection between Keller-Segel finite particles and non-local operators.", "result": "Establishes an upper bound on the heat kernel, revealing blow-up effects.", "conclusion": "Provides insights into the critical behavior of the Keller-Segel system in two dimensions."}}
{"id": "2508.10452", "pdf": "https://arxiv.org/pdf/2508.10452", "abs": "https://arxiv.org/abs/2508.10452", "authors": ["Zhiqiang Xu"], "title": "New Lower Bounds for the Minimum Singular Value in Matrix Selection", "categories": ["math.FA", "cs.NA", "math.NA"], "comment": "13 pages", "summary": "The objective of the matrix selection problem is to select a submatrix\n$A_{S}\\in \\mathbb{R}^{n\\times k}$ from $A\\in \\mathbb{R}^{n\\times m}$ such that\nits minimum singular value is maximized. In this paper, we employ the\ninterlacing polynomial method to investigate this problem. This approach allows\nus to identify a submatrix $A_{S_0}\\in \\mathbb{R}^{n\\times k}$ and establish a\nlower bound for its minimum singular value. Specifically, unlike common\ninterlacing polynomial approaches that estimate the smallest root of the\nexpected characteristic polynomial via barrier functions, we leverage the\ndirect relationship between roots and coefficients. This leads to a tighter\nlower bound when $k$ is close to $n$. For the case where\n$AA^{\\top}=\\mathbb{I}_n$ and $k=n$, our result improves the well-known result\nby Hong-Pan, which involves extracting a basis from a tight frame and\nestablishing a lower bound for the minimum singular value of the basis matrix.", "AI": {"tldr": "The paper uses interlacing polynomials to maximize the minimum singular value of a submatrix, improving bounds for specific cases.", "motivation": "To address the matrix selection problem by maximizing the minimum singular value of a submatrix, enhancing existing methods.", "method": "Employs interlacing polynomial method, leveraging root-coefficient relationships for tighter bounds.", "result": "Achieves a tighter lower bound for the minimum singular value, improving on the Hong-Pan result for certain cases.", "conclusion": "The approach provides a better solution for matrix selection, particularly when the submatrix size is close to the original matrix dimensions."}}
{"id": "2508.10718", "pdf": "https://arxiv.org/pdf/2508.10718", "abs": "https://arxiv.org/abs/2508.10718", "authors": ["Wei Shan Lee", "I Hang Kwok", "Kam Ian Leong", "Chi Kiu Althina Chau", "Kei Chon Sio"], "title": "Symmetry-Constrained Multi-Scale Physics-Informed Neural Networks for Graphene Electronic Band Structure Prediction", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": "36 pages and 14 figures", "summary": "Accurate prediction of electronic band structures in two-dimensional\nmaterials remains a fundamental challenge, with existing methods struggling to\nbalance computational efficiency and physical accuracy. We present the\nSymmetry-Constrained Multi-Scale Physics-Informed Neural Network (SCMS-PINN)\nv35, which directly learns graphene band structures while rigorously enforcing\ncrystallographic symmetries through a multi-head architecture. Our approach\nintroduces three specialized ResNet-6 pathways -- K-head for Dirac physics,\nM-head for saddle points, and General head for smooth interpolation --\noperating on 31 physics-informed features extracted from k-points. Progressive\nDirac constraint scheduling systematically increases the weight parameter from\n5.0 to 25.0, enabling hierarchical learning from global topology to local\ncritical physics. Training on 10,000 k-points over 300 epochs achieves 99.99\\%\nreduction in training loss (34.597 to 0.003) with validation loss of 0.0085.\nThe model predicts Dirac point gaps within 30.3 $\\mu$eV of theoretical zero and\nachieves average errors of 53.9 meV (valence) and 40.5 meV (conduction) across\nthe Brillouin zone. All twelve C$_{6v}$ operations are enforced through\nsystematic averaging, guaranteeing exact symmetry preservation. This framework\nestablishes a foundation for extending physics-informed learning to broader\ntwo-dimensional materials for accelerated discovery.", "AI": {"tldr": "The paper introduces SCMS-PINN v35, a neural network model for predicting graphene band structures by enforcing crystallographic symmetries, achieving high accuracy and efficiency.", "motivation": "Existing methods for predicting electronic band structures in 2D materials struggle with balancing computational efficiency and physical accuracy, prompting the need for a better approach.", "method": "The SCMS-PINN v35 model uses a multi-head architecture with specialized ResNet-6 pathways (K-head, M-head, General head) and physics-informed features, enforcing symmetries through systematic averaging and progressive constraint scheduling.", "result": "The model achieves a 99.99% reduction in training loss, predicts Dirac point gaps within 30.3 \u03bceV, and maintains average errors of 53.9 meV (valence) and 40.5 meV (conduction).", "conclusion": "The framework successfully combines physics-informed learning with symmetry constraints, paving the way for broader applications in 2D materials research."}}
{"id": "2508.10306", "pdf": "https://arxiv.org/pdf/2508.10306", "abs": "https://arxiv.org/abs/2508.10306", "authors": ["Pawel Gajer", "Jacques Ravel"], "title": "Intrinsic and Normal Mean Ricci Curvatures: A Bochner--Weitzenboeck Identity for Simple d-Vectors", "categories": ["math.DG", "math.AP", "math.SP", "53C20 (Primary), 58J50, 53C65, 53C21, 35P15 53C20 (Primary), 58J50,\n  53C65, 53C21, 35P15 (Secondary) 53C20 (Primary), 58J50, 53C65, 53C21, 35P15\n  (Secondary)"], "comment": "12 pages, 1 figure", "summary": "We introduce two pointwise subspace averages of sectional curvature on a\nd-dimensional plane Pi in T_p M: (i) the intrinsic mean Ricci (the average of\nsectional curvatures of 2-planes contained in Pi); and (ii) the normal (mixed)\nmean Ricci (the average of sectional curvatures of 2-planes spanned by one\nvector in Pi and one in Pi^perp). Using Jacobi-field expansions, these means\noccur as the r^2/6 coefficients in the intrinsic (d-1)-sphere and normal\n(n-d-1)-sphere volume elements. A direct consequence is a Bochner--Weitzenboeck\nidentity for simple d-vectors V (built from an orthonormal frame X_1,...,X_d\nwith Pi = span{X_i}): the curvature term equals d(n-d) times the normal mean\nRicci of Pi. This yields two immediate applications: (a) a Bochner vanishing\ncriterion for harmonic simple d-vectors under a positive lower bound on the\nnormal mean Ricci; and (b) a Lichnerowicz-type lower bound for the first\neigenvalue of the Hodge Laplacian on simple d-eigenfields.", "AI": {"tldr": "The paper introduces two pointwise subspace averages of sectional curvature, analyzes their role in volume elements, and derives applications in Bochner vanishing and eigenvalue bounds.", "motivation": "To explore the geometric implications of intrinsic and normal mean Ricci curvatures in the context of Jacobi-field expansions and their applications in differential geometry.", "method": "Uses Jacobi-field expansions to derive curvature terms and applies them to Bochner--Weitzenboeck identities and Hodge Laplacian eigenvalue problems.", "result": "Derives a Bochner--Weitzenboeck identity and applications including a vanishing criterion for harmonic simple d-vectors and a Lichnerowicz-type eigenvalue bound.", "conclusion": "The introduced curvature averages provide geometric insights and practical tools for analyzing harmonic forms and eigenvalue problems in differential geometry."}}
{"id": "2508.10727", "pdf": "https://arxiv.org/pdf/2508.10727", "abs": "https://arxiv.org/abs/2508.10727", "authors": ["Segun Goh", "Dennis Haustein", "Gerhard Gompper"], "title": "Run-and-Tumble Escape in Pursuit-Evasion Dynamics of Intelligent Active Particles", "categories": ["physics.bio-ph", "cond-mat.stat-mech", "physics.comp-ph"], "comment": "6 figures", "summary": "The pursuit-evasion game is studied for two adversarial active agents,\nmodelled as a deterministic self-steering pursuer and a stochastic, cognitive\nevader. The pursuer chases the evader by reorienting its propulsion direction\nwith limited maneuverability, while the evader escapes by executing sharp,\nunpredictable turns, whose timing and direction the pursuer cannot anticipate.\nTo make the target responsive and agile when the threat level is high, the\ntumbling frequency is set to increase with decreasing distance from the\npursuer; furthermore, the range of preferred tumbling directions is varied.\nNumerical simulations of such a pursuit-target pair in two spatial dimensions\nreveal two important scenarios. For dominant pursuers, the evader is compelled\nto adopt a high-risk strategy that allows the pursuer to approach closely\nbefore the evader executes a potentially game-changing backward maneuver to\npull away from the pursuer. Otherwise, a strategy where the evader tumbles\nforward with continuous slight adjustments of the propulsion direction can\nsignificantly increase the capture time by preventing the pursuer from aligning\nwith the target propulsion direction, while maintaining the persistence of the\ntarget motion. Our results can guide the design of bioinspired robotic systems\nwith efficient evasion capabilities.", "AI": {"tldr": "The paper studies a pursuit-evasion game between a deterministic pursuer and a stochastic evader, revealing strategies for evasion and capture based on maneuverability and unpredictability.", "motivation": "To understand the dynamics of adversarial interactions between a pursuer and evader, particularly in bioinspired robotic systems.", "method": "Numerical simulations of a deterministic pursuer and stochastic evader in 2D, analyzing evasion strategies like tumbling frequency and direction adjustments.", "result": "Two scenarios emerge: high-risk backward maneuvers for dominant pursuers and continuous slight adjustments to prolong capture time.", "conclusion": "The findings can inform the design of agile robotic systems with effective evasion capabilities."}}
{"id": "2508.10694", "pdf": "https://arxiv.org/pdf/2508.10694", "abs": "https://arxiv.org/abs/2508.10694", "authors": ["Molly Brennan", "Edwina F. Yeo", "Philip Pearce", "Mohit P. Dalwadi"], "title": "Effective permeability conditions for diffusive transport through impermeable membranes with gaps", "categories": ["cond-mat.soft", "math.AP", "math.DS", "physics.bio-ph"], "comment": null, "summary": "Membranes regulate transport in a wide variety of industrial and biological\napplications. The microscale geometry of the membrane can significantly affect\noverall transport through the membrane, but the precise nature of this\nmultiscale coupling is not well characterised in general. Motivated by the\napplication of transport across a bacterial membrane, in this paper we use\nformal multiscale analysis to derive explicit effective coupling conditions for\nmacroscale transport across a two-dimensional impermeable membrane with\nperiodically spaced gaps, and validate these with numerical simulations. We\nderive analytic expressions for effective macroscale quantities associated with\nthe membrane, such as the permeability, in terms of the microscale geometry.\nOur results generalise the classic constitutive membrane coupling conditions to\na wider range of membrane geometries and time-varying scenarios. Specifically,\nwe demonstrate that if the exterior concentration varies in time, for membranes\nwith long channels, the transport gains a memory property where the coupling\nconditions depend on the system history. By applying our effective conditions\nin the context of small molecule transport through gaps in bacterial membranes\ncalled porins, we predict that bacterial membrane permeability is primarily\ndominated by the thickness of the membrane. Furthermore, we predict how\nalterations to membrane microstructure, for example via changes to porin\nexpression, might affect overall transport, including when external\nconcentrations vary in time. These results will apply to a broad range of\nphysical applications with similar membrane structures, from medical and\nindustrial filtration to carbon capture.", "AI": {"tldr": "The paper uses multiscale analysis to derive effective coupling conditions for macroscale transport across membranes with periodic gaps, validating results with simulations and predicting membrane permeability dominated by thickness.", "motivation": "To understand and characterize the multiscale coupling of membrane geometry and transport, especially for bacterial membranes with periodically spaced gaps.", "method": "Formal multiscale analysis to derive explicit effective coupling conditions, validated with numerical simulations.", "result": "Derived analytic expressions for macroscale quantities like permeability, showing memory properties for time-varying concentrations and predicting bacterial membrane permeability is dominated by thickness.", "conclusion": "The results generalize classic membrane coupling conditions and apply to various applications, including bacterial membranes and industrial filtration."}}
{"id": "2508.10587", "pdf": "https://arxiv.org/pdf/2508.10587", "abs": "https://arxiv.org/abs/2508.10587", "authors": ["Xuanhao Mu", "G\u00f6khan Demirel", "Yuzhe Zhang", "Jianlei Liu", "Thorsten Schlachter", "Veit Hagenmeyer"], "title": "Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer", "categories": ["cs.LG", "cs.NA", "eess.SP", "math.NA"], "comment": null, "summary": "To bridge the temporal granularity gap in energy network design and operation\nbased on Energy System Models, resampling of time series is required. While\nconventional upsampling methods are computationally efficient, they often\nresult in significant information loss or increased noise. Advanced models such\nas time series generation models, Super-Resolution models and imputation models\nshow potential, but also face fundamental challenges. The goal of time series\ngenerative models is to learn the distribution of the original data to generate\nhigh-resolution series with similar statistical characteristics. This is not\nentirely consistent with the definition of upsampling. Time series\nSuper-Resolution models or imputation models can degrade the accuracy of\nupsampling because the input low-resolution time series are sparse and may have\ninsufficient context. Moreover, such models usually rely on supervised learning\nparadigms. This presents a fundamental application paradox: their training\nrequires the high-resolution time series that is intrinsically absent in\nupsampling application scenarios. To address the mentioned upsampling issue,\nthis paper introduces a new method utilizing Generative Adversarial\nTransformers (GATs), which can be trained without access to any ground-truth\nhigh-resolution data. Compared with conventional interpolation methods, the\nintroduced method can reduce the root mean square error (RMSE) of upsampling\ntasks by 9%, and the accuracy of a model predictive control (MPC) application\nscenario is improved by 13%.", "AI": {"tldr": "The paper introduces a Generative Adversarial Transformers (GATs) method for upsampling energy time series, reducing RMSE by 9% and improving MPC accuracy by 13%, without needing high-resolution ground-truth data.", "motivation": "To address the limitations of conventional upsampling methods and advanced models (e.g., generative, Super-Resolution, imputation) in energy network design, which suffer from information loss, noise, or reliance on unavailable high-resolution data.", "method": "Proposes a Generative Adversarial Transformers (GATs) approach that learns data distributions to generate high-resolution time series without requiring ground-truth high-resolution data.", "result": "Reduces RMSE by 9% in upsampling tasks and improves MPC accuracy by 13%.", "conclusion": "GATs offer a viable solution for upsampling in energy systems, overcoming key challenges of existing methods."}}
{"id": "2508.10808", "pdf": "https://arxiv.org/pdf/2508.10808", "abs": "https://arxiv.org/abs/2508.10808", "authors": ["Akash Rodhiya", "Shashwat Bhattacharya", "Mahendra K Verma"], "title": "Relative accuracy of turbulence simulations using pseudo-spectral and finite difference solvers", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": "10 pages, 7 figures", "summary": "For a single timestep, a spectral solver is known to be more accurate than\nits finite-difference counterpart. However, as we show in this paper,\nturbulence simulations using the two methods have nearly the same accuracy. In\nthis paper, we simulate forced hydrodynamic turbulence on a uniform 256$^3$\ngrid for Reynolds numbers 965, 1231, 1515, and 1994. We show that the two\nmethods yield nearly the same evolution for the total energy and the flow\nprofiles. In addition, the steady-state energy spectrum, energy flux, and\nprobability distribution functions of the velocity and its derivatives are very\nsimilar. We argue that within a turbulence attractor, the numerical errors are\nlikely to get cancelled (rather than get added up), which leads to similar\nresults for the finite-difference and spectral methods. These findings are very\nvaluable, considering that a parallel finite-difference simulation is more\nversatile and efficient (for large grids) than its spectral counterpart.", "AI": {"tldr": "Spectral and finite-difference methods yield similar accuracy in turbulence simulations, despite spectral methods being more accurate for single timesteps.", "motivation": "To compare the accuracy of spectral and finite-difference methods in turbulence simulations, challenging the assumption that spectral methods are always superior.", "method": "Simulated forced hydrodynamic turbulence on a uniform 256\u00b3 grid for Reynolds numbers 965, 1231, 1515, and 1994, comparing energy evolution, flow profiles, and statistical measures.", "result": "Both methods produced nearly identical results for energy, energy spectrum, flux, and velocity distributions, suggesting numerical errors cancel out in turbulence attractors.", "conclusion": "Finite-difference methods are equally accurate for turbulence simulations and more efficient for large grids, making them a practical alternative to spectral methods."}}
{"id": "2508.10721", "pdf": "https://arxiv.org/pdf/2508.10721", "abs": "https://arxiv.org/abs/2508.10721", "authors": ["Romain Petrides"], "title": "Isoperimetric inequalities involving Steklov eigenvalues on surfaces", "categories": ["math.DG", "math.AP", "math.SP"], "comment": null, "summary": "We give results on optimal constants of isoperimetric inequalities involving\nSteklov eigenvalues on surfaces with boundary. We both consider this question\non Riemannian surfaces with a same given topology or more specifically\nbelonging to the same conformal class. We provide new examples of topological\ndisks that realize optimal constants. We prove inequalities that relate\nconformal invariants associated to combinations of Steklov eigenvalues on a\ncompact Riemannian surface with boundary and the ones on the disk. In the\nappendix, we show rigidity of the first conformal Steklov eigenvalue on annuli\nand M\\\"obius bands.", "AI": {"tldr": "The paper explores optimal constants for isoperimetric inequalities related to Steklov eigenvalues on surfaces with boundary, focusing on Riemannian surfaces with shared topology or conformal class. It provides new examples of optimal topological disks and proves inequalities linking conformal invariants of Steklov eigenvalues on surfaces and disks. Rigidity results for the first conformal Steklov eigenvalue on annuli and M\u00f6bius bands are also presented.", "motivation": "To advance understanding of isoperimetric inequalities and Steklov eigenvalues on surfaces with boundary, particularly in shared topological or conformal contexts.", "method": "Analysis of Riemannian surfaces with boundary, focusing on shared topology or conformal class. Examination of optimal constants and inequalities involving Steklov eigenvalues.", "result": "New examples of optimal topological disks and inequalities relating conformal invariants of Steklov eigenvalues on surfaces and disks. Rigidity of the first conformal Steklov eigenvalue on annuli and M\u00f6bius bands.", "conclusion": "The study enhances knowledge of isoperimetric inequalities and Steklov eigenvalues, providing concrete examples and rigidity results for specific surfaces."}}
{"id": "2508.10596", "pdf": "https://arxiv.org/pdf/2508.10596", "abs": "https://arxiv.org/abs/2508.10596", "authors": ["Andreas E. Kyprianou", "Aaron Pim", "Tristan Pryer"], "title": "A Unified Framework from Boltzmann Transport to Proton Treatment Planning", "categories": ["math.PR", "cs.NA", "math.NA", "math.OC", "physics.med-ph"], "comment": "23 pages, 3 figures", "summary": "This work develops a rigorous mathematical formulation of proton transport by\nintegrating both deterministic and stochastic perspectives. The deterministic\nframework is based on the Boltzmann-Fokker-Planck equation, formulated as an\noperator equation in a suitable functional setting. The stochastic approach\nmodels proton evolution via a track-length parameterised diffusion process,\nwhose infinitesimal generator provides an alternative description of transport.\n  A key result is the duality between the stochastic and deterministic\nformulations, established through the adjoint relationship between the\ntransport operator and the stochastic generator. We prove that the resolvent of\nthe stochastic process corresponds to the Green's function of the deterministic\nequation, providing a natural link between fluence-based and particle-based\ntransport descriptions. The theory is applied to dose computation, where we\nshow that the classical relation: dose = (fluence * mass stopping power) arises\nconsistently in both approaches.\n  Building on this foundation, we formulate a hybrid optimisation framework for\ntreatment planning, in which dose is computed using a stochastic model while\noptimisation proceeds via adjoint-based PDE methods. We prove existence and\ndifferentiability of the objective functional and derive the first-order\noptimality system. This framework bridges stochastic simulation with\ndeterministic control theory and provides a foundation for future work in\nconstrained, adaptive and uncertainty-aware optimisation in proton therapy.", "AI": {"tldr": "The paper integrates deterministic and stochastic models for proton transport, establishes their duality, and applies the theory to dose computation and treatment planning.", "motivation": "To rigorously unify deterministic and stochastic perspectives of proton transport for improved accuracy in dose computation and treatment planning.", "method": "Uses the Boltzmann-Fokker-Planck equation (deterministic) and a diffusion process (stochastic), proving their duality. Applies this to dose computation and hybrid optimization for treatment planning.", "result": "Demonstrates duality between stochastic and deterministic models, consistency in dose computation, and formulates a hybrid optimization framework.", "conclusion": "The unified framework bridges stochastic simulation with deterministic control, enabling advanced optimization in proton therapy."}}
{"id": "2508.10841", "pdf": "https://arxiv.org/pdf/2508.10841", "abs": "https://arxiv.org/abs/2508.10841", "authors": ["Viktor Zaverkin", "Matheus Ferraz", "Francesco Alesiani", "Mathias Niepert"], "title": "Performance of universal machine-learned potentials with explicit long-range interactions in biomolecular simulations", "categories": ["physics.chem-ph", "cond-mat.soft", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Universal machine-learned potentials promise transferable accuracy across\ncompositional and vibrational degrees of freedom, yet their application to\nbiomolecular simulations remains underexplored. This work systematically\nevaluates equivariant message-passing architectures trained on the SPICE-v2\ndataset with and without explicit long-range dispersion and electrostatics. We\nassess the impact of model size, training data composition, and electrostatic\ntreatment across in- and out-of-distribution benchmark datasets, as well as\nmolecular simulations of bulk liquid water, aqueous NaCl solutions, and\nbiomolecules, including alanine tripeptide, the mini-protein Trp-cage, and\nCrambin. While larger models improve accuracy on benchmark datasets, this trend\ndoes not consistently extend to properties obtained from simulations. Predicted\nproperties also depend on the composition of the training dataset. Long-range\nelectrostatics show no systematic impact across systems. However, for Trp-cage,\ntheir inclusion yields increased conformational variability. Our results\nsuggest that imbalanced datasets and immature evaluation practices currently\nchallenge the applicability of universal machine-learned potentials to\nbiomolecular simulations.", "AI": {"tldr": "The paper evaluates equivariant message-passing architectures for biomolecular simulations, finding that larger models and training data composition affect accuracy, but long-range electrostatics have inconsistent impacts.", "motivation": "To assess the applicability of universal machine-learned potentials in biomolecular simulations, addressing gaps in current evaluation practices.", "method": "Systematic evaluation of equivariant message-passing architectures trained on SPICE-v2, with and without long-range dispersion and electrostatics, tested on various benchmark datasets and molecular simulations.", "result": "Larger models improve benchmark accuracy but not simulation properties; training data composition affects predictions; long-range electrostatics inconsistently impact systems, except for Trp-cage.", "conclusion": "Imbalanced datasets and immature evaluation practices limit the current applicability of universal machine-learned potentials to biomolecular simulations."}}
