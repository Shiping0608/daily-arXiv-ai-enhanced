{"id": "2508.10126", "pdf": "https://arxiv.org/pdf/2508.10126", "abs": "https://arxiv.org/abs/2508.10126", "authors": ["Arvind K. Saibaba", "Misha E. Kilmer", "Khalil Hall-Hooper", "Fan Tian", "Alex Mize"], "title": "A tensor-based dynamic mode decomposition based on the $\\star_{\\boldsymbol{M}}$-product", "categories": ["math.NA", "cs.NA", "15A69, 65F99, 93B30"], "comment": null, "summary": "Dynamic mode decomposition (DMD) is a data-driven method for estimating the\ndynamics of a discrete dynamical system. This paper proposes a tensor-based\napproach to DMD for applications in which the states can be viewed as tensors.\nSpecifically, we use the $\\star_{\\boldsymbol{M}}$-product framework for tensor\ndecompositions which we demonstrate offers excellent compression compared to\nmatrix-based methods and can be implemented in a computationally efficient\nmanner. We show how the proposed approach is connected to the traditional DMD\nand physics-informed DMD frameworks. We give a computational framework for\ncomputing the tensor-based DMD and detail the computational costs. We also give\na randomized algorithm that enables efficient $\\star_{\\boldsymbol{M}}$-DMD\ncomputations in the streaming setting. The numerical results show that the\nproposed method achieves equal or better accuracy for the same storage compared\nto the standard DMD on these examples and is more efficient to compute.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.10158", "pdf": "https://arxiv.org/pdf/2508.10158", "abs": "https://arxiv.org/abs/2508.10158", "authors": ["Yunhui He", "Santolo Leveque"], "title": "A Generalized Alternating Anderson Acceleration Method", "categories": ["math.NA", "cs.NA", "65F10, 65H10, 65K10"], "comment": "24 pages, 9 figures", "summary": "In this work, we propose a generalized alternating Anderson acceleration\nmethod, a periodic scheme composed of $t$ fixed-point iteration steps,\ninterleaved with $s$ steps of Anderson acceleration with window size $m$, to\nsolve linear and nonlinear problems. This allows flexibility to use different\ncombinations of fixed-point iteration and Anderson iteration. We present a\nconvergence analysis of the proposed scheme for accelerating the Richardson\niteration in the linear case, with a focus on specific parameter choices of\ninterest. Specifically, we prove convergence of the proposed method under\ncontractive fixed-point iteration and provide a sufficient condition for\nconvergence when the Richardson iteration matrix is diagonalizable and\nnoncontractive. To demonstrate the broader applicability of our proposed\nmethod, we use it to accelerate Jacobi iteration, Picard iteration, gradient\ndescent, and the alternating direction method of multipliers in solving partial\ndifferential equations and nonlinear, nonsmooth optimization problems. The\nnumerical results illustrate that the proposed scheme is more efficient than\nthe existing windowed Anderson acceleration and alternating Anderson ($s=1$) in\nterms of iteration number and CPU time for careful choice of parameters $m, s,\nt$.", "AI": {"tldr": "A generalized alternating Anderson acceleration method is proposed, combining fixed-point iteration and Anderson acceleration for solving linear and nonlinear problems, with proven convergence and improved efficiency over existing methods.", "motivation": "To enhance flexibility and efficiency in solving linear and nonlinear problems by combining fixed-point iteration and Anderson acceleration in a periodic scheme.", "method": "A periodic scheme with $t$ fixed-point iteration steps interleaved with $s$ Anderson acceleration steps (window size $m$), analyzed for convergence in linear cases and applied to various iterative methods.", "result": "Convergence is proven for contractive fixed-point iteration, and a sufficient condition is provided for noncontractive cases. Numerical results show improved efficiency over existing methods.", "conclusion": "The proposed method offers a flexible and efficient approach for accelerating iterative solvers, outperforming existing techniques with careful parameter choices."}}
{"id": "2508.10322", "pdf": "https://arxiv.org/pdf/2508.10322", "abs": "https://arxiv.org/abs/2508.10322", "authors": ["Qixuan Zhou", "Chuqi Chen", "Tao Luo", "Yang Xiang"], "title": "SSBE-PINN: A Sobolev Boundary Scheme Boosting Stability and Accuracy in Elliptic/Parabolic PDE Learning", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving partial differential equations (PDEs), yet they often fail to\nachieve accurate convergence in the H1 norm, especially in the presence of\nboundary approximation errors. In this work, we propose a novel method called\nSobolev-Stable Boundary Enforcement (SSBE), which redefines the boundary loss\nusing Sobolev norms to incorporate boundary regularity directly into the\ntraining process. We provide rigorous theoretical analysis demonstrating that\nSSBE ensures bounded H1 error via a stability guarantee and derive\ngeneralization bounds that characterize its robustness under finite-sample\nregimes. Extensive numerical experiments on linear and nonlinear PDEs,\nincluding Poisson, heat, and elliptic problems, show that SSBE consistently\noutperforms standard PINNs in terms of both relative L2 and H1 errors, even in\nhigh-dimensional settings. The proposed approach offers a principled and\npractical solution for improving gradient fidelity and overall solution\naccuracy in neural network based PDE solvers.", "AI": {"tldr": "Proposes Sobolev-Stable Boundary Enforcement (SSBE) to improve PINNs' accuracy by redefining boundary loss using Sobolev norms, ensuring bounded H1 error and better performance in PDE solving.", "motivation": "PINNs often fail to achieve accurate convergence in the H1 norm due to boundary approximation errors, motivating a need for improved boundary enforcement methods.", "method": "Introduces SSBE, which redefines boundary loss using Sobolev norms to incorporate boundary regularity directly into training, backed by theoretical analysis.", "result": "SSBE outperforms standard PINNs in relative L2 and H1 errors across linear/nonlinear PDEs, including Poisson, heat, and elliptic problems.", "conclusion": "SSBE provides a principled, practical solution for enhancing gradient fidelity and accuracy in neural network-based PDE solvers."}}
{"id": "2508.10344", "pdf": "https://arxiv.org/pdf/2508.10344", "abs": "https://arxiv.org/abs/2508.10344", "authors": ["Thomas Hangelbroek", "Christian Rieger", "Grady B. Wright"], "title": "A Semi-Lagrangian scheme on embedded manifolds using generalized local polynomial reproductions", "categories": ["math.NA", "cs.NA", "65M12, 65M15, 65M25, 41A25, 41A63"], "comment": null, "summary": "We analyze rates of uniform convergence for a class of high-order\nsemi-Lagrangian schemes for first-order, time-dependent partial differential\nequations on embedded submanifolds of $\\mathbb{R}^d$ (including advection\nequations on surfaces) by extending the error analysis of Falcone and Ferretti.\nA central requirement in our analysis is a remapping operator that achieves\nboth high approximation orders and strong stability, a combination that is\nchallenging to obtain and of independent interest. For this task, we propose a\nnovel mesh-free remapping operator based on $\\ell_1$ minimizing generalized\npolynomial reproduction, which uses only point values and requires no\nadditional geometric information from the manifold (such as access to tangent\nspaces or curvature). Our framework also rigorously addresses the numerical\nsolution of ordinary differential equations on manifolds via projection\nmethods. We include numerical experiments that support the theoretical results\nand also suggest some new directions for future research.", "AI": {"tldr": "The paper analyzes high-order semi-Lagrangian schemes for PDEs on manifolds, introducing a stable remapping operator and numerical experiments.", "motivation": "To extend error analysis for PDEs on manifolds and address challenges in achieving high approximation orders with stability.", "method": "Proposes a mesh-free remapping operator using \u21131 minimizing generalized polynomial reproduction, requiring only point values.", "result": "The framework supports high-order convergence and stability, validated by numerical experiments.", "conclusion": "The approach is effective for PDEs on manifolds and opens new research directions."}}
{"id": "2508.10277", "pdf": "https://arxiv.org/pdf/2508.10277", "abs": "https://arxiv.org/abs/2508.10277", "authors": ["Yi Huang", "Bowen Zheng", "Yunxi Dong", "Hong Tang", "Huan Zhao", "Rakibul Hasan Shawon", "Sensong An", "Hualiang Zhang"], "title": "MCP-Enabled LLM for Meta-optics Inverse Design: Leveraging Differentiable Solver without LLM Expertise", "categories": ["physics.comp-ph", "physics.optics"], "comment": null, "summary": "Automatic differentiation (AD) enables powerful metasurface inverse design\nbut requires extensive theoretical and programming expertise. We present a\nModel Context Protocol (MCP) assisted framework that allows researchers to\nconduct inverse design with differentiable solvers through large language\nmodels (LLMs). Since LLMs inherently lack knowledge of specialized solvers, our\nproposed solution provides dynamic access to verified code templates and\ncomprehensive documentation through dedicated servers. The LLM autonomously\naccesses these resources to generate complete inverse design codes without\nprescribed coordination rules. Evaluation on the Huygens meta-atom design task\nwith the differentiable TorchRDIT solver shows that while both natural language\nand structured prompting strategies achieve high success rates, structured\nprompting significantly outperforms in design quality, workflow efficiency,\ncomputational cost, and error reduction. The minimalist server design, using\nonly 5 APIs, demonstrates how MCP makes sophisticated computational tools\naccessible to researchers without programming expertise, offering a\ngeneralizable integration solution for other scientific tasks.", "AI": {"tldr": "A framework using Model Context Protocol (MCP) and LLMs simplifies inverse design for metasurfaces by dynamically accessing verified code templates, eliminating the need for programming expertise.", "motivation": "To make automatic differentiation (AD) and inverse design accessible to researchers lacking theoretical and programming expertise.", "method": "Proposes MCP-assisted framework with LLMs, providing dynamic access to verified code templates and documentation for generating inverse design codes.", "result": "Structured prompting outperforms natural language in design quality, efficiency, cost, and error reduction. Minimalist server design (5 APIs) proves effective.", "conclusion": "MCP democratizes sophisticated computational tools, offering a generalizable solution for scientific tasks beyond metasurface design."}}
{"id": "2508.10121", "pdf": "https://arxiv.org/pdf/2508.10121", "abs": "https://arxiv.org/abs/2508.10121", "authors": ["Sergei Avdonin", "Julian Edward"], "title": "An inverse problem on a metric graph with cycle", "categories": ["math.AP", "math.OC", "math.SP", "35R30 (primary), 35L05, 93B05 (secondary)"], "comment": null, "summary": "Consider a quantum graph consisting of a ring with two attached edges, and\nassume Kirchhoff-Neumann conditions hold at the internal vertices. Associated\nto this graph is a Schr\\\"{o}dinger type operator $L=-\\Delta +q(x)$ with\nDirichlet boundary conditions at the two boundary nodes. Let $\\{ \\omega_n^2, \\\n\\varphi_n(x)\\}$ be the eigenvalues and associated normalized eigenfunctions.\nLet $v_1$ be a boundary vertex, and $v_2$ the adjacent internal vertex. Assume\nwe know the following data: $\\{ \\omega_n^2,\\partial_x\n\\varphi_n(v_1),\\partial_x\\varphi_n(v_2)\\}.$ Here $\\partial_x\\varphi_n(v_2)$\nrefers to an outward normal derivative at $v_2$ along one of the edges incident\nto the other internal vertex. From this data we determine the following unknown\nquantities: the lengths of edges and the potential functions on each edge.", "AI": {"tldr": "The paper studies a quantum graph with a ring and two edges, using given eigenvalue and eigenfunction derivative data to determine edge lengths and potential functions.", "motivation": "To solve the inverse problem of determining unknown geometric and potential properties of a quantum graph from spectral data.", "method": "Uses a Schr\u00f6dinger-type operator with Dirichlet boundary conditions and given eigenvalue and eigenfunction derivative data at specific vertices.", "result": "The lengths of edges and potential functions on each edge are determined from the provided data.", "conclusion": "The approach successfully reconstructs the quantum graph's geometric and potential properties from spectral information."}}
{"id": "2508.10513", "pdf": "https://arxiv.org/pdf/2508.10513", "abs": "https://arxiv.org/abs/2508.10513", "authors": ["Andreas Mueller"], "title": "Product Of Exponentials (POE) Splines on Lie-Groups: Limitations, Extensions, and Application to SO(3) and SE(3)", "categories": ["math.NA", "cs.NA", "math.DG", "math.GR"], "comment": null, "summary": "Existing methods for constructing splines and Bezier curves on a Lie group G\ninvolve repeated products of exponentials deduced from local geodesics, w.r.t.\na Riemannian metric, or rely on general polynomials. Moreover, each of these\nlocal curves is supposed to start at the identity of $G$. Both assumptions may\nnot reflect the actual curve to be interpolated. This paper pursues a different\napproach to construct splines on $G$. Local curves are expressed as solutions\nof the Poisson equation on G. Therewith, the local interpolations satisfies the\nboundary conditions while respecting the geometry of $G$. A $k$th-order\napproximation of the solutions gives rise to a $k$th-order product of\nexponential (POE) spline. Algorithms for constructing 3rd- and 4th-order\nsplines are derived from closed form expressions for the approximate solutions.\nAdditionally, spline algorithms are introduced that allow prescribing a vector\nfield the curve must follow at the interpolation points. It is shown that the\nestablished algorithms, where $k$th-order POE-splines are constructed by\nconcatenating local curves starting at the identity, cannot exactly reconstruct\na $k$th-order motion. To tackle this issue, the formulations are extended by\nallowing for local curves between arbitrary points, rather than curves\nemanating from the identity. This gives rise to a global $k$th-order spline\nwith arbitrary initial conditions. Several examples are presented, in\nparticular the shape reconstruction of slender rods modeled as geometrically\nnon-linear Cosserat rods.", "AI": {"tldr": "The paper introduces a new method for constructing splines on Lie groups by solving the Poisson equation, addressing limitations of existing methods that rely on local geodesics or polynomials starting at the identity.", "motivation": "Existing methods for spline construction on Lie groups often assume curves start at the identity and use local geodesics or polynomials, which may not accurately reflect the actual curve to be interpolated.", "method": "Local curves are derived as solutions to the Poisson equation on the Lie group, ensuring boundary conditions and geometric integrity. Higher-order approximations yield product of exponential (POE) splines, with algorithms for 3rd- and 4th-order splines.", "result": "The new approach allows for splines with arbitrary initial conditions, overcoming the limitation of existing methods that cannot exactly reconstruct higher-order motions. Examples include shape reconstruction of slender rods.", "conclusion": "The proposed method provides a more flexible and accurate framework for spline construction on Lie groups, with practical applications in geometric modeling."}}
{"id": "2508.10454", "pdf": "https://arxiv.org/pdf/2508.10454", "abs": "https://arxiv.org/abs/2508.10454", "authors": ["Qi Zhou", "Teng Wu", "Jianghao Liu", "Qingyuan Sun", "Hehu Xie", "Zhenli Xu"], "title": "Sum-of-Gaussians tensor neural networks for high-dimensional Schr\u00f6dinger equation", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "35Q40, 65D40, 65N25, 68W25, 68W40"], "comment": "22 pages, 6 figures", "summary": "We propose an accurate, efficient, and low-memory sum-of-Gaussians tensor\nneural network (SOG-TNN) algorithm for solving the high-dimensional\nSchr\\\"odinger equation. The SOG-TNN utilizes a low-rank tensor product\nrepresentation of the solution to overcome the curse of dimensionality\nassociated with high-dimensional integration. To handle the Coulomb\ninteraction, we introduce an SOG decomposition to approximate the interaction\nkernel such that it is dimensionally separable, leading to a tensor\nrepresentation with rapid convergence. We further develop a range-splitting\nscheme that partitions the Gaussian terms into short-, long-, and mid-range\ncomponents. They are treated with the asymptotic expansion, the low-rank\nChebyshev expansion, and the model reduction with singular-value decomposition,\nrespectively, significantly reducing the number of two-dimensional integrals in\ncomputing electron-electron interactions. The SOG decomposition well resolves\nthe computational challenge due to the singularity of the Coulomb interaction,\nleading to an efficient algorithm for the high-dimensional problem under the\nTNN framework. Numerical results demonstrate the outstanding performance of the\nnew method, revealing that the SOG-TNN is a promising way for tackling large\nand complex quantum systems.", "AI": {"tldr": "The paper introduces SOG-TNN, a tensor neural network method for solving high-dimensional Schr\u00f6dinger equations efficiently by decomposing the Coulomb interaction into separable components and using range-splitting techniques.", "motivation": "The motivation is to overcome the curse of dimensionality in solving high-dimensional Schr\u00f6dinger equations and handle the computational challenges of Coulomb interactions.", "method": "The method involves a sum-of-Gaussians tensor neural network (SOG-TNN) with low-rank tensor representation, SOG decomposition for Coulomb interaction, and range-splitting for efficient computation.", "result": "Numerical results show SOG-TNN performs outstandingly, efficiently solving high-dimensional problems.", "conclusion": "SOG-TNN is a promising approach for large and complex quantum systems."}}
{"id": "2508.10254", "pdf": "https://arxiv.org/pdf/2508.10254", "abs": "https://arxiv.org/abs/2508.10254", "authors": ["David M. Ambrose", "Ryan Aschoff", "Elaine Cozzi", "James P. Kelliher"], "title": "Non-Decaying Solutions to the 2D Dissipative Quasi-Geostrophic Equations", "categories": ["math.AP"], "comment": null, "summary": "We consider the surface quasi-geostrophic equation in two spatial dimensions,\nwith subcritical diffusion (i.e. with fractional diffusion of order $2\\alpha$\nfor $\\alpha>\\frac{1}{2}$.) We establish existence of solutions without assuming\neither decay at spatial infinity or spatial periodicity. One obstacle is that\nfor $L^{\\infty}$ data, the constitutive law may not be applicable, as Riesz\ntransforms are unbounded. However, for $L^{\\infty}$ initial data for which the\nconstitutive law does converge, we demonstrate that there exists a unique\nsolution locally in time, and that the constitutive law continues to hold at\npositive times. In the case that $\\alpha\\in(\\frac{1}{2},1]$ and that the\ninitial data has some smoothness (specifically, if the data is in $C^{2}$), we\ndemonstrate a maximum principle and show that this unique solution is actually\nclassical and global in time. Then, a density argument allows us to show that\nmild solutions with only $L^{\\infty}$ data are also global in time, and also\npossess this maximum principle. Finally, we introduce a related problem in\nwhich we replace the usual constitutive law for the surface quasi-geostrophic\nequation with a generalization of Sertfati type, and prove the same results for\nthis relaxed model.", "AI": {"tldr": "Existence and uniqueness of solutions for the 2D surface quasi-geostrophic equation with subcritical diffusion, including global solutions for smooth initial data and extension to $L^{\\infty}$ data via density arguments.", "motivation": "To address the challenge of solving the surface quasi-geostrophic equation without decay or periodicity assumptions, especially for $L^{\\infty}$ data where Riesz transforms are unbounded.", "method": "Analyze solutions for $L^{\\infty}$ data, prove local existence and uniqueness, extend to global solutions for smooth data, and generalize results to a relaxed model with a Sertfati-type constitutive law.", "result": "Local existence and uniqueness for $L^{\\infty}$ data, global classical solutions for smooth data, and extension to $L^{\\infty}$ data via density arguments.", "conclusion": "The study successfully establishes solutions under relaxed conditions and extends results to a generalized model, demonstrating robustness in handling non-decaying and non-periodic data."}}
{"id": "2508.10547", "pdf": "https://arxiv.org/pdf/2508.10547", "abs": "https://arxiv.org/abs/2508.10547", "authors": ["Hameed Ullah Jan", "Marjan Uddin", "Irshad Ali Shah", "Salam Ullah Khan"], "title": "On The Eventual Periodicity of Fractional Order Dispersive Wave Equations Using RBFs and Transform", "categories": ["math.NA", "cs.NA", "34K28, 35G61, 35Q53, 34A08, 34K13"], "comment": "16 pages, 9 figures", "summary": "In this research work, let us focus on the construction of numerical scheme\nbased on radial basis functions finite difference (RBF-FD) method combined with\nthe Laplace transform for the solution of fractional order dispersive wave\nequations. The numerical scheme is then applied to examine the eventual\nperiodicity of the proposed model subject to the periodic boundary conditions.\nThe implementation of proposed technique for high order fractional and integer\ntype nonlinear partial differential equations (PDEs) is beneficial because this\nmethod is local in nature, therefore it yields and resulted in sparse\ndifferentiation matrices instead of full and dense matrices. Only small\ndimensions of linear systems of equations are to be solved for every center in\nthe domain and hence this procedure is more reliable and efficient to solve\nlarge scale physical and engineering problems in complex domain. Laplace\ntransform is utilized for obtaining the equivalent time-independent equation in\nLaplace space and also valuable to handle time-fractional derivatives in the\nCaputo sense. Application of Laplace transform avoids the time steeping\nprocedure which commonly encounters the time instability issues. The solution\nto the transformed model is then obtained by computing the inversion of Laplace\ntransform with an appropriate contour in a complex space, which is approximated\nby trapezoidal rule with high accuracy. Also since the Laplace transform\noperator is linear, it cannot be used to transform non-linear terms therefore\nlet us use a linearization approach and an appropriate iterative scheme. The\nproposed approach is tasted for some nonlinear fractional order KdV and Burgers\nequations. The capacity, high order accuracy and efficiency of our approach are\ndemonstrated using examples and results", "AI": {"tldr": "The paper proposes a numerical scheme combining radial basis functions finite difference (RBF-FD) and Laplace transform to solve fractional order dispersive wave equations, demonstrating efficiency and accuracy for nonlinear PDEs.", "motivation": "To address the challenges of solving high-order fractional and integer-type nonlinear PDEs efficiently, avoiding dense matrices and time instability issues.", "method": "Uses RBF-FD for spatial discretization, Laplace transform for time-independent equations, and an iterative scheme for nonlinear terms.", "result": "The method yields sparse matrices, avoids time-stepping instability, and achieves high accuracy in solving nonlinear fractional PDEs like KdV and Burgers equations.", "conclusion": "The proposed approach is efficient, reliable, and accurate for large-scale problems, validated through examples."}}
{"id": "2508.10515", "pdf": "https://arxiv.org/pdf/2508.10515", "abs": "https://arxiv.org/abs/2508.10515", "authors": ["Andrea Urgolo", "Monika Stipsitz", "Helios Sanchis-Alepuz"], "title": "Virtual Sensing for Solder Layer Degradation and Temperature Monitoring in IGBT Modules", "categories": ["physics.comp-ph", "cs.CE", "cs.LG", "cs.SY", "eess.SY"], "comment": "Andrea Urgolo and Monika Stipsitz contributed equally to this work", "summary": "Monitoring the degradation state of Insulated Gate Bipolar Transistor (IGBT)\nmodules is essential for ensuring the reliability and longevity of power\nelectronic systems, especially in safety-critical and high-performance\napplications. However, direct measurement of key degradation indicators - such\nas junction temperature, solder fatigue or delamination - remains challenging\ndue to the physical inaccessibility of internal components and the harsh\nenvironment. In this context, machine learning-based virtual sensing offers a\npromising alternative by bridging the gap from feasible sensor placement to the\nrelevant but inaccessible locations. This paper explores the feasibility of\nestimating the degradation state of solder layers, and the corresponding full\ntemperature maps based on a limited number of physical sensors. Based on\nsynthetic data of a specific degradation mode, we obtain a high accuracy in the\nestimation of the degraded solder area (1.17% mean absolute error), and are\nable to reproduce the surface temperature of the IGBT with a maximum relative\nerror of 4.56% (corresponding to an average relative error of 0.37%).", "AI": {"tldr": "The paper proposes a machine learning-based virtual sensing method to estimate IGBT module degradation, achieving high accuracy in predicting solder degradation and temperature maps.", "motivation": "Direct measurement of IGBT degradation indicators is challenging due to physical inaccessibility and harsh environments, necessitating alternative methods.", "method": "Uses synthetic data and machine learning to estimate solder layer degradation and full temperature maps from limited physical sensors.", "result": "Achieves 1.17% mean absolute error in degraded solder area estimation and 4.56% maximum relative error in temperature reproduction.", "conclusion": "Machine learning-based virtual sensing is feasible and accurate for monitoring IGBT degradation, offering a practical alternative to direct measurements."}}
{"id": "2508.10314", "pdf": "https://arxiv.org/pdf/2508.10314", "abs": "https://arxiv.org/abs/2508.10314", "authors": ["Tatsuya Miura", "Kensuke Yoshizawa"], "title": "Stability of flat-core pinned p-elasticae", "categories": ["math.AP", "math.DG", "49Q10 and 53A04"], "comment": "12 pages, 3 figures", "summary": "We classify the stability of flat-core $p$-elasticae in $\\mathbf{R}^d$\nsubject to the pinned boundary condition. Together with previous work, this\ncompletes the classification of stable pinned $p$-elasticae in $\\mathbf{R}^d$\nfor all $p\\in(1,\\infty)$ and $d\\geq2$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.10558", "pdf": "https://arxiv.org/pdf/2508.10558", "abs": "https://arxiv.org/abs/2508.10558", "authors": ["Marjan Uddin", "Hameed Ullah Jan", "Muhammad Usman"], "title": "RBF-FD Method for Some Dispersive Wave Equations and Their Eventual Periodicity", "categories": ["math.NA", "cs.NA", "33F05, 34K10, 34K13, 34K28, 35Q51, 35Q53"], "comment": "23 pages, 10 figures", "summary": "In this paper, we approximate the solution and also discuss the periodic\nbehavior termed as eventual periodicity of solutions of (IBVPs) for some\ndispersive wave equations on a bounded domain corresponding to periodic\nforcing. The constructed numerical scheme is based on radial kernels and local\nin nature like finite difference method. The temporal variable is executed\nthrough RK4 scheme. Due to the local nature and sparse differentiation matrices\nour numerical scheme efficiently recovers the solution. The results achieved\nare validated and examined with other methods accessible in the literature.", "AI": {"tldr": "The paper approximates solutions and analyzes eventual periodicity for dispersive wave equations with periodic forcing, using a radial kernel-based numerical scheme and RK4 for temporal execution.", "motivation": "To efficiently solve initial-boundary value problems (IBVPs) for dispersive wave equations on bounded domains with periodic forcing, leveraging local numerical methods.", "method": "A radial kernel-based numerical scheme, locally implemented like finite differences, with temporal execution via RK4. Uses sparse differentiation matrices for efficiency.", "result": "The scheme efficiently recovers solutions, validated against existing methods in literature.", "conclusion": "The proposed local numerical method effectively approximates solutions and captures eventual periodicity for the studied IBVPs."}}
{"id": "2508.10555", "pdf": "https://arxiv.org/pdf/2508.10555", "abs": "https://arxiv.org/abs/2508.10555", "authors": ["Haoran Sun", "Daoqi Liu", "Hongyu Zhou", "Maokun Li", "Shenheng Xu", "Fan Yang"], "title": "Physics-Informed Deep Contrast Source Inversion: A Unified Framework for Inverse Scattering Problems", "categories": ["physics.comp-ph", "cs.CE", "cs.LG"], "comment": null, "summary": "Inverse scattering problems are critical in electromagnetic imaging and\nmedical diagnostics but are challenged by their nonlinearity and diverse\nmeasurement scenarios. This paper proposes a physics-informed deep contrast\nsource inversion framework (DeepCSI) for fast and accurate medium\nreconstruction across various measurement conditions. Inspired by contrast\nsource inversion (CSI) and neural operator methods, a residual multilayer\nperceptron (ResMLP) is employed to model current distributions in the region of\ninterest under different transmitter excitations, effectively linearizing the\nnonlinear inverse scattering problem and significantly reducing the\ncomputational cost of traditional full-waveform inversion. By modeling medium\nparameters as learnable tensors and utilizing a hybrid loss function that\nintegrates state equation loss, data equation loss, and total variation\nregularization, DeepCSI establishes a fully differentiable framework for joint\noptimization of network parameters and medium properties. Compared with\nconventional methods, DeepCSI offers advantages in terms of simplicity and\nuniversal modeling capabilities for diverse measurement scenarios, including\nphase-less and multi-frequency observation. Simulations and experiments\ndemonstrate that DeepCSI achieves high-precision, robust reconstruction under\nfull-data, phaseless data, and multifrequency conditions, outperforming\ntraditional CSI methods and providing an efficient and universal solution for\ncomplex inverse scattering problems.", "AI": {"tldr": "DeepCSI, a physics-informed deep contrast source inversion framework, linearizes nonlinear inverse scattering problems using ResMLP, reducing computational costs and achieving high-precision reconstructions across diverse measurement scenarios.", "motivation": "Addressing the challenges of nonlinearity and diverse measurement conditions in inverse scattering problems, crucial for electromagnetic imaging and medical diagnostics.", "method": "Proposes DeepCSI, combining contrast source inversion and neural operator methods with ResMLP to model current distributions, using a hybrid loss function for joint optimization of network and medium parameters.", "result": "Outperforms traditional CSI methods, achieving robust reconstructions under full-data, phaseless, and multi-frequency conditions.", "conclusion": "DeepCSI provides an efficient, universal solution for complex inverse scattering problems, simplifying modeling and improving accuracy."}}
{"id": "2508.10347", "pdf": "https://arxiv.org/pdf/2508.10347", "abs": "https://arxiv.org/abs/2508.10347", "authors": ["Josh Culver", "Aubrey Ayres", "Evan Halloran", "Ryan Lin", "Emily Peng", "Charis Tsikkou"], "title": "An Analysis of the Riemann Problem for a $2 \\times 2$ System of Keyfitz-Kranzer Type Balance Laws With a Time-Dependent Source Term", "categories": ["math.AP", "math-ph", "math.CA", "math.DS", "math.MP", "34A05, 34C37, 34C45, 34E15, 35L45, 35L65, 35L67, 35L80, 35Q92,\n  65M06, 74L10, 76A30"], "comment": "35 pages. arXiv admin note: text overlap with arXiv:2508.05927", "summary": "We consider a system consisting of one conservation law and one balance law\nwith a time-dependent source term, and provide a comprehensive analysis of\nRiemann solutions, including the non-classical overcompressive delta shocks.\nThe minimal yet representative structure of the system captures essential\nfeatures of transport under density constraints and, despite its simplicity,\nserves as a versatile prototype for crowd-limited transport processes across\ndiverse contexts, including biological aggregation, ecological dispersal,\ngranular compaction, and traffic congestion. In addition to non-self-similar\nsolutions mentioned above, the associated Riemann problem admits solution\nstructures that traverse vacuum states ($\\rho = 0$) and the critical density\nthreshold ($\\rho = \\bar{\\rho}$), where mobility vanishes and characteristic\nspeed degenerates. Moreover, the explicit time dependence in the source term\nleads to the breakdown of self-similarity, resulting in distinct Riemann\nsolutions over successive time intervals and highlighting the dynamic nature of\nthe solution landscape. The theoretical findings are numerically confirmed\nusing the Local Lax-Friedrichs scheme.", "AI": {"tldr": "Analysis of Riemann solutions for a system with a conservation law and a balance law, featuring non-classical delta shocks, vacuum states, and dynamic solutions due to a time-dependent source term.", "motivation": "To understand transport processes under density constraints, applicable to diverse fields like biology, ecology, and traffic.", "method": "Comprehensive analysis of Riemann solutions, including non-self-similar structures, and numerical validation using the Local Lax-Friedrichs scheme.", "result": "Discovery of dynamic solution landscapes, including vacuum states and critical density thresholds, with non-classical delta shocks.", "conclusion": "The system serves as a versatile prototype for density-constrained transport, with theoretical insights confirmed numerically."}}
{"id": "2508.10570", "pdf": "https://arxiv.org/pdf/2508.10570", "abs": "https://arxiv.org/abs/2508.10570", "authors": ["Ramsharan Rangarajan", "N. Sukumar"], "title": "CutVEM: Conforming virtual element method on embedded domains with shape-agnostic element agglomeration", "categories": ["math.NA", "cs.NA"], "comment": "35 pages, 20 figures", "summary": "The virtual element method (VEM) is a stabilized Galerkin method that is\nrobust and accurate on general polygonal meshes. This feature makes it an\nappealing candidate for simulations involving meshes with embedded interfaces\nand evolving geometries. However, the method can yield poorly conditioned\nstiffness matrices in such scenarios due to meshes having cut cells. We propose\na novel element agglomeration algorithm for the virtual element method to\naddress this issue. The agglomeration algorithm renders the VEM robust over\nplanar polygonal meshes, particularly on finite element meshes cut by immersed\ngeometries. The algorithm relies on the element stability ratio, which we\ndefine using the extreme eigenvalues of the element stiffness matrix. The\nresulting element agglomeration criterion is free from nebulous polygon quality\nmetrics and is defined independently of polygon shapes. The algorithm proceeds\niteratively and element-wise to maximize the minimum element stability ratio,\neven at the expense of degrading elements with better ratios. Crucially,\nelement agglomeration alters the number of elements, not the degree of freedom\ncount. The resulting method, which we label as CutVEM, retains node locations\nof cut elements unchanged, and yields discretizations that conform to embedded\ninterfaces. This, in turn, facilitates straightforward imposition of boundary\nconditions and interfacial constraints. Through detailed numerical experiments\nthat sample varied element-interface intersections, we demonstrate that CutVEM\nenjoys dramatically improved condition numbers of global stiffness matrices\nover the VEM. Furthermore, simulations of prototypical heat conduction problems\nwith Dirichlet and Neumann boundary conditions on domains with immersed\ngeometries show that element agglomeration does not noticeably degrade solution\naccuracy and that CutVEM retains the VEM's optimal convergence rate.", "AI": {"tldr": "The paper introduces CutVEM, a novel element agglomeration algorithm for the virtual element method (VEM) to improve conditioning on cut-cell meshes, maintaining accuracy and optimal convergence.", "motivation": "The VEM's robustness on polygonal meshes is compromised by poor conditioning in cut-cell scenarios, necessitating a solution to retain its advantages for evolving geometries.", "method": "Proposes an element agglomeration algorithm based on element stability ratios, iteratively optimizing mesh conditioning without altering degrees of freedom.", "result": "CutVEM significantly improves stiffness matrix conditioning while preserving solution accuracy and optimal convergence rates.", "conclusion": "CutVEM effectively addresses VEM's conditioning issues on cut-cell meshes, enhancing its applicability for complex geometries without sacrificing performance."}}
{"id": "2508.10237", "pdf": "https://arxiv.org/pdf/2508.10237", "abs": "https://arxiv.org/abs/2508.10237", "authors": ["Ray Yang", "Junchi Chen", "Douglas Thibodeaux", "Robert B. Wexler"], "title": "FreeBird.jl: An Extensible Toolbox for Simulating Interfacial Phase Equilibria", "categories": ["cond-mat.stat-mech", "cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph"], "comment": "17 pages, 5 figures", "summary": "We present FreeBird.jl, an extensible Julia-based platform for computational\nstudies of phase equilibria at generic interfaces. The package supports a range\nof system configurations, from atomistic solid surfaces to coarse-grained\nlattice$-$gas models, with energies evaluated using classical interatomic\npotentials or lattice Hamiltonians. Both atomistic and lattice systems\naccommodate single- or multi-component mixtures with flexibly definable surface\nand lattice geometries. Implemented sampling algorithms include nested\nsampling, Wang$-$Landau sampling, Metropolis Monte Carlo, and, for tractable\nlattice systems, exact enumeration. Leveraging Julia's type hierarchies and\nmultiple dispatch, FreeBird.jl provides a modular interface that allows\nseamless integration of system definitions, energy evaluators, and sampling\nschemes. Designed for flexibility, extensibility, and performance, FreeBird.jl\noffers a versatile framework for exploring the thermodynamics of interfacial\nphenomena.", "AI": {"tldr": "FreeBird.jl is a Julia-based platform for computational studies of phase equilibria at interfaces, supporting various system configurations and sampling algorithms.", "motivation": "To provide a flexible and extensible tool for studying interfacial thermodynamics across diverse systems and methods.", "method": "Uses Julia's type hierarchies and multiple dispatch for modular integration of system definitions, energy evaluators, and sampling schemes (e.g., nested sampling, Wang-Landau, Metropolis Monte Carlo).", "result": "A versatile framework capable of handling atomistic and lattice systems with customizable geometries and energy evaluations.", "conclusion": "FreeBird.jl offers a powerful, adaptable solution for computational studies of interfacial phenomena."}}
{"id": "2508.10387", "pdf": "https://arxiv.org/pdf/2508.10387", "abs": "https://arxiv.org/abs/2508.10387", "authors": ["Giusi Vaira"], "title": "Blow-up phenomena for a boundary Yamabe problem with umbilic boundary", "categories": ["math.AP"], "comment": null, "summary": "We consider a linear perturbation of the classical geometric problem of\nprescribing the scalar and the boundary mean curvature problem in a Riemannian\nmanifold with umbilic boundary provided the Weyl tensor is non-zero everywhere.\nWe will deal with the case of negative scalar curvature showing the existence\nof a positive solutions when $n\\geq 8$.", "AI": {"tldr": "The paper explores a linear perturbation of the geometric problem of prescribing scalar and boundary mean curvature in a Riemannian manifold with umbilic boundary, focusing on negative scalar curvature and proving existence of positive solutions for dimensions n\u22658.", "motivation": "The study aims to extend understanding of geometric problems involving scalar and boundary mean curvature in Riemannian manifolds, particularly when the Weyl tensor is non-zero and the scalar curvature is negative.", "method": "The authors employ a linear perturbation approach to address the problem, specifically analyzing the case of negative scalar curvature in manifolds with umbilic boundaries.", "result": "The key result is the existence of positive solutions to the problem for dimensions n\u22658, under the given conditions.", "conclusion": "The findings contribute to the broader field of geometric analysis by providing solutions to curvature prescription problems in higher dimensions under specific constraints."}}
{"id": "2508.10578", "pdf": "https://arxiv.org/pdf/2508.10578", "abs": "https://arxiv.org/abs/2508.10578", "authors": ["Brandiece N. Berry", "Md Mahmudul Islam", "Muhammad Mohebujjaman", "Neethu Suma Raveendran"], "title": "Efficient and Optimally Accurate Numerical Algorithms for Stochastic Turbulent Flow Problems", "categories": ["math.NA", "cs.NA", "65M12, 65M22, 65M60, 76W05"], "comment": "26 pages, 8 figures", "summary": "In this paper, we first propose a filter-based continuous Ensemble Eddy\nViscosity (EEV) model for stochastic turbulent flow problems. We then propose a\ngeneric algorithm for a family of fully discrete, grad-div regularized,\nefficient ensemble parameterized schemes for this model. The linearized\nImplicit-Explicit (IMEX) EEV generic algorithm shares a common coefficient\nmatrix for each realization per time-step, but with different right-hand-side\nvectors, which reduces the computational cost and memory requirements to the\norder of solving deterministic flow problems. Two family members of the\nproposed time-stepping algorithm are analyzed and proven to be stable. It is\nfound that one is first-order and the other is second-order accurate in time\nfor any stable finite element pairs. Avoiding the discrete inverse inequality,\nthe optimal convergence of both schemes is proven rigorously for both 2D and 3D\nproblems. For appropriately large grad-div parameters, both schemes are\nunconditionally stable and allow weakly divergence-free elements. Several\nnumerical tests are given for high expected Reynolds number ($\\textbf{E}[Re]$)\nproblems. The convergence rates are verified using manufactured solutions with\n$\\textbf{E}[Re]=10^{3},10^{4},\\;\\text{and}\\; 10^{5}$. For various high\n$\\textbf{E}[Re]$, the schemes are implemented on benchmark problems which\nincludes: A 2D channel flow over a unit step problem, a non-intrusive\nStochastic Collocation Method (SCM) is used to examine the performance of the\nschemes on a 2D Regularized Lid Driven Cavity (RLDC) problem, and a 3D RLDC\nproblem, and found them perform well.", "AI": {"tldr": "Proposed a filter-based Ensemble Eddy Viscosity model and a grad-div regularized, efficient ensemble algorithm for stochastic turbulent flows, proving stability and accuracy for high Reynolds numbers.", "motivation": "Address computational challenges in stochastic turbulent flow problems by reducing costs and memory requirements while maintaining accuracy.", "method": "Developed a linearized IMEX EEV algorithm with shared coefficient matrices and different right-hand-side vectors, analyzed two stable time-stepping schemes (first and second-order).", "result": "Proven stability and optimal convergence for 2D/3D problems; validated with high Reynolds number tests, showing good performance.", "conclusion": "The proposed schemes are efficient, stable, and accurate for high Reynolds number stochastic turbulent flows."}}
{"id": "2508.10380", "pdf": "https://arxiv.org/pdf/2508.10380", "abs": "https://arxiv.org/abs/2508.10380", "authors": ["Qisheng Yu", "Boyu Liu", "Hongjun Xiang", "Shi Liu"], "title": "Type-I Multiferroic VHfO$_4$ with Strain-Switchable Magnetic Orders and Magnetoelectric Coupling", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Motivated by the complementary properties of vanadium-based ferromagnets and\nHfO$_2$-based ferroelectrics, we propose a novel multiferroic oxide, VHfO$_4$,\nthrough 50\\% Hf$^{4+}$ substitution with V$^{4+}$ in the ferroelectric $Pca2_1$\nphase of HfO$_2$. First-principles DFT calculations reveal that the\n$Pca2_1$-like VHfO$_4$ phase exhibits dynamic stability and concurrent ferroic\norders: robust ferroelectric polarization comparable to HfO$_2$ and V-driven\nmagnetism. Parallel tempering Monte Carlo simulations identify an\nantiferromagnetic ground state, while strain engineering enables tunable\nmagnetoelectric coupling. Biaxial in-plane strain induces four magnetic states:\nintralayer FM/interlayer AFM, intralayer AFM/interlayer FM, spiral-like\nnon-collinear order, and discrete alternating spin alignment. Critically,\n$c$-axis strain modulates magnetic energy landscapes, demonstrating\nelectromechanical control of magnetism. This work establishes VHfO$_4$ as a\nType-I multiferroic with coexisting atomic-scale ferroic origins and\nstrain-tunable cross-coupling, offering a platform for voltage-controlled\nspintronics devices.", "AI": {"tldr": "The paper proposes VHfO$_4$ as a novel multiferroic oxide, combining ferroelectric and magnetic properties, with strain-tunable magnetoelectric coupling for spintronics applications.", "motivation": "To leverage the complementary properties of vanadium-based ferromagnets and HfO$_2$-based ferroelectrics for creating a new multiferroic material.", "method": "First-principles DFT calculations and parallel tempering Monte Carlo simulations were used to study the stability, ferroic orders, and strain effects on VHfO$_4$.", "result": "VHfO$_4$ exhibits dynamic stability, robust ferroelectric polarization, and V-driven magnetism. Strain engineering enables tunable magnetoelectric coupling and multiple magnetic states.", "conclusion": "VHfO$_4$ is a Type-I multiferroic with coexisting ferroic orders and strain-tunable cross-coupling, promising for voltage-controlled spintronics."}}
{"id": "2508.10448", "pdf": "https://arxiv.org/pdf/2508.10448", "abs": "https://arxiv.org/abs/2508.10448", "authors": ["Romain Petrides"], "title": "Regularity estimates on harmonic eigenmaps with arbitrary number of coordinates", "categories": ["math.AP", "math.DG"], "comment": null, "summary": "We revisit the well-established regularity estimates on harmonic maps on\nsurfaces to question their independence with respect to the dimension of the\ntarget manifold. We are mainly interested in harmonic maps into target\nellipsoids, that we call Laplace harmonic eigenmaps. These maps are related to\ncritical metrics in the context of eigenvalue optimization. The tools that we\ngather here are useful to handle convergence of almost critical metrics via\nPalais-Smale sequences of (almost harmonic) eigenmaps. They could also be a\npreliminary step for a general regularity theory for critical points of\ninfinite combinations of eigenvalues.", "AI": {"tldr": "The paper investigates the regularity of harmonic maps into ellipsoids (Laplace harmonic eigenmaps) and their independence from the target manifold's dimension, with implications for eigenvalue optimization.", "motivation": "To explore the dimension independence of regularity estimates for harmonic maps and their relevance in eigenvalue optimization and critical metrics.", "method": "Focuses on harmonic maps into ellipsoids, termed Laplace harmonic eigenmaps, and analyzes their properties using tools for handling convergence of almost critical metrics.", "result": "Provides insights into the regularity of such maps and their behavior in Palais-Smale sequences, aiding in the study of eigenvalue optimization.", "conclusion": "The findings contribute to understanding harmonic maps and lay groundwork for a broader regularity theory for critical points of eigenvalue combinations."}}
{"id": "2508.10630", "pdf": "https://arxiv.org/pdf/2508.10630", "abs": "https://arxiv.org/abs/2508.10630", "authors": ["Kasper B\u00e5gmark", "Adam Andersson", "Stig Larsson"], "title": "Nonlinear filtering based on density approximation and deep BSDE prediction", "categories": ["math.NA", "cs.NA", "stat.CO", "stat.ML", "60G25, 60G35, 62F15, 62G07, 62M20, 65C30, 65M75, 68T07"], "comment": "19 pages, 6 figures", "summary": "A novel approximate Bayesian filter based on backward stochastic differential\nequations is introduced. It uses a nonlinear Feynman--Kac representation of the\nfiltering problem and the approximation of an unnormalized filtering density\nusing the well-known deep BSDE method and neural networks. The method is\ntrained offline, which means that it can be applied online with new\nobservations. A mixed a priori-a posteriori error bound is proved under an\nelliptic condition. The theoretical convergence rate is confirmed in two\nnumerical examples.", "AI": {"tldr": "A new Bayesian filter using backward stochastic differential equations (BSDEs) and neural networks is introduced, with offline training for online application.", "motivation": "To address the filtering problem by leveraging nonlinear Feynman-Kac representation and deep BSDE methods for efficient approximation.", "method": "Uses deep BSDE and neural networks to approximate unnormalized filtering density, trained offline for online use.", "result": "Proves a mixed error bound under elliptic conditions and confirms theoretical convergence in numerical examples.", "conclusion": "The method is effective, with proven error bounds and practical validation through numerical tests."}}
{"id": "2508.10418", "pdf": "https://arxiv.org/pdf/2508.10418", "abs": "https://arxiv.org/abs/2508.10418", "authors": ["Feng-Feng Song", "Naoki Kawashima"], "title": "Variational boundary based tensor network renormalization group", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "comment": "7 pages, 5 figures", "summary": "We propose a real-space renormalization group algorithm for accurately\ncoarse-graining two-dimensional tensor networks. The central innovation of our\nmethod lies in utilizing variational boundary tensors as a globally optimized\nenvironment for the entire system. Based on this optimized environment, we\nconstruct renormalization projectors that significantly enhance accuracy. By\nleveraging the canonical form of tensors, our algorithm maintains the same\ncomputational complexity as the original tensor renormalization group (TRG)\nmethod, yet achieves higher accuracy than existing approaches that do not\nincorporate entanglement filtering. Our work offers a practical pathway for\nextending TRG methods to higher dimensions while keeping computational costs\nmanageable.", "AI": {"tldr": "A new real-space renormalization group algorithm for 2D tensor networks uses variational boundary tensors for global optimization, improving accuracy without increasing computational complexity.", "motivation": "To enhance the accuracy of tensor renormalization group (TRG) methods in higher dimensions while maintaining manageable computational costs.", "method": "Utilizes variational boundary tensors for global optimization and constructs renormalization projectors based on the canonical form of tensors.", "result": "Achieves higher accuracy than existing TRG methods without entanglement filtering, with the same computational complexity.", "conclusion": "Provides a practical approach for extending TRG methods to higher dimensions efficiently."}}
{"id": "2508.10508", "pdf": "https://arxiv.org/pdf/2508.10508", "abs": "https://arxiv.org/abs/2508.10508", "authors": ["Ferdinand Eitler", "Peter Lewintan"], "title": "On $\\mathrm{BV}^{\\mathbb{A}}$-Minimisers in two Dimensions", "categories": ["math.AP", "35B65, 35J60, 49J45, 35A15"], "comment": null, "summary": "We investigate into the regularity of $\\mathrm{BV}^{\\mathbb{A}}$-minimisers\nfor $\\mathbb{C}$-elliptic differential operators $\\mathbb{A}$ in $2$\ndimensions. Our studies strongly rely on the special structure of such\ndifferential operators. The gradient integrability is established for the sharp\nellipticity range known from the (symmetric) gradient case.", "AI": {"tldr": "Study of regularity and gradient integrability for BV^\ud835\udd38-minimisers of \u2102-elliptic operators in 2D.", "motivation": "To understand the regularity properties of minimisers for \u2102-elliptic differential operators in two dimensions.", "method": "Relies on the special structure of \u2102-elliptic operators, building on known ellipticity ranges from the symmetric gradient case.", "result": "Gradient integrability is established for the sharp ellipticity range.", "conclusion": "The findings confirm the regularity of BV^\ud835\udd38-minimisers for \u2102-elliptic operators in 2D."}}
{"id": "2508.10648", "pdf": "https://arxiv.org/pdf/2508.10648", "abs": "https://arxiv.org/abs/2508.10648", "authors": ["Hugo M. Verhelst", "Angelos Mantzaflaris", "Matthias M\u00f6ller"], "title": "Isogeometric multi-patch shell analysis using the Geometry + Simulation Modules", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Isogeometric Analysis (IGA) bridges Computer-Aided Design (CAD) and Finite\nElement Analysis (FEA) by employing splines as a common basis for geometry and\nanalysis. One of the advantages of IGA is in the realm of thin shell analysis:\ndue to the arbitrary continuity of the spline basis, Kirchhoff-Love shells can\nbe modeled without the need to introduce unknowns for the mid-plane rotations,\nleading to a reduction in the number of unknowns. In this paper, we provide the\nbackground of an implementation of Isogeometric Kirchhoff--Love shells within\nthe Geometry + Simulation Modules (G+Smo). This paper accompanies multiple\nprevious publications and elaborates on the design of the software used in\nthese papers, rather than the novelty of the methods presented therein. The\npresented implementation provides patch coupling via penalty methods and\nunstructured splines, goal-oriented error estimators, several algorithms for\nstructural analysis and advanced algorithms for the modeling of wrinkling in\nhyperelastic membranes. These methods are all contained in three new modules in\nG+Smo: a module for Kirchhoff-Love shells, a module for structural analysis,\nand a module for unstructured spline constructions. As motivated in this paper,\nthe modules are implemented to be compatible with future developments. For\nexample, by providing base implementations of material laws, by using black-box\nfunctions for the structural analysis module, or by providing a standardized\napproach for the implementation of unstructured spline constructions. Overall,\nthis paper demonstrates that the new modules contribute to a versatile\necosystem for the modeling of multi-patch shell problems through fast\noff-the-shelf solvers with a simple interface, designed to be extended in\nfuture research.", "AI": {"tldr": "The paper details the implementation of Isogeometric Kirchhoff-Love shells in G+Smo, focusing on software design and compatibility with future developments, rather than novel methods.", "motivation": "To bridge CAD and FEA using splines for thin shell analysis, reducing unknowns by leveraging spline continuity.", "method": "Implementation includes patch coupling, error estimators, structural analysis algorithms, and wrinkling modeling, organized into three new G+Smo modules.", "result": "The modules enable versatile modeling of multi-patch shell problems with fast solvers and extensible interfaces.", "conclusion": "The implementation supports future research by providing a flexible and extensible framework for shell analysis."}}
{"id": "2508.10422", "pdf": "https://arxiv.org/pdf/2508.10422", "abs": "https://arxiv.org/abs/2508.10422", "authors": ["Ludovico Foss\u00e0", "Pierre Ricco"], "title": "Compressible boundary layers over isotropic porous surfaces", "categories": ["physics.flu-dyn", "physics.app-ph", "physics.comp-ph", "76J20, 76N20, 76S05"], "comment": null, "summary": "A compressible laminar boundary layer developing over an isotropic porous\nsubstrate is investigated by asymptotic and numerical methods. The substrate is\nmodeled as an array of cubes. The momentum and enthalpy balance equations are\nderived by volume averaging. The self-similar solution proposed by Tsiberkin\n(2018) [Transp. Porous Media 121(1):109-120] for streamwise-growing\npermeability is extended to include compressibility, heat conduction and a\nnonlinear drag. The velocity profile shows an inflection point at the free\nfluid-porous interfacial layer, below which it decreases to zero. A marked\nreduction of the adiabatic recovery temperature of the fluid and the velocity\ngradient at the interface is observed for high porosity, large grains and\nrelatively high Mach numbers. The temperature imposed at the bottom of the\nporous substrate has a negligible influence on the shear stresses.", "AI": {"tldr": "The paper investigates a compressible laminar boundary layer over an isotropic porous substrate using asymptotic and numerical methods, extending Tsiberkin's self-similar solution to include compressibility, heat conduction, and nonlinear drag.", "motivation": "To understand the behavior of compressible laminar boundary layers over porous substrates, including effects of compressibility, heat conduction, and nonlinear drag.", "method": "Asymptotic and numerical methods are used to analyze the boundary layer, extending Tsiberkin's self-similar solution with additional factors.", "result": "The velocity profile shows an inflection point at the interface, with reduced adiabatic recovery temperature and velocity gradient for high porosity, large grains, and high Mach numbers. Bottom temperature has negligible impact on shear stresses.", "conclusion": "The study highlights the influence of porosity, grain size, and Mach number on boundary layer behavior, with minimal effect from substrate temperature on shear stresses."}}
{"id": "2508.10690", "pdf": "https://arxiv.org/pdf/2508.10690", "abs": "https://arxiv.org/abs/2508.10690", "authors": ["Filomena De Filippis", "Antonella Nastasi", "Cintia Pacchiano Camacho"], "title": "Vectorial Double Phase Obstacle Problems", "categories": ["math.AP"], "comment": null, "summary": "We investigate partial regularity for vector valued local minimizers of\ndouble phase functionals, under vectorial obstacle type constraints satisfying\nappropriate topological properties.", "AI": {"tldr": "Study of partial regularity for vector-valued local minimizers of double phase functionals under vectorial obstacle constraints.", "motivation": "To understand the regularity properties of minimizers in constrained settings, particularly for double phase functionals.", "method": "Analysis of vector-valued local minimizers under topological constraints.", "result": "Partial regularity results are derived for the minimizers under the given constraints.", "conclusion": "The study provides insights into the regularity of solutions in constrained variational problems."}}
{"id": "2508.10674", "pdf": "https://arxiv.org/pdf/2508.10674", "abs": "https://arxiv.org/abs/2508.10674", "authors": ["Wei Chen", "Xinyuan Du", "Jun Hu"], "title": "The Hu-Zhang element for linear elasticity on curved domains", "categories": ["math.NA", "cs.NA", "65N12, 65N30, 74S05"], "comment": null, "summary": "This paper extends the Hu-Zhang element for linear elasticity problems to\ncurved domains, preserving strong symmetry and H(div)-conformity. The\nnon-polynomial structure of the curved Hu-Zhang element makes it difficult to\nanalyze the stability result, which is overcome by establishing a novel inf-sup\ncondition. Optimal convergence rates are achieved for all variables except the\nstress $L^2$-error. This suboptimality originates from the fact that the\ndivergence space of the curved Hu-Zhang element is not contained in the\ndiscrete displacement space, which is rectified by local $p$-enrichment in the\nHu-Zhang space on curved boundary elements. Some numerical experiments validate\nthe theoretical results.", "AI": {"tldr": "The paper extends the Hu-Zhang element to curved domains, ensuring symmetry and H(div)-conformity, and addresses stability and convergence challenges.", "motivation": "To adapt the Hu-Zhang element for curved domains while maintaining key properties like symmetry and H(div)-conformity.", "method": "Introduces a non-polynomial curved Hu-Zhang element, establishes a novel inf-sup condition for stability, and uses local p-enrichment to improve convergence.", "result": "Achieves optimal convergence rates for most variables, though stress L\u00b2-error remains suboptimal. Numerical experiments support the theory.", "conclusion": "The curved Hu-Zhang element is successfully extended, with local p-enrichment resolving divergence space issues, validated by numerical results."}}
{"id": "2508.10505", "pdf": "https://arxiv.org/pdf/2508.10505", "abs": "https://arxiv.org/abs/2508.10505", "authors": ["Hanwen Kang", "Tenglong Lu", "Zhanbin Qi", "Jiandong Guo", "Sheng Meng", "Miao Liu"], "title": "FastTrack: a fast method to evaluate mass transport in solid leveraging universal machine learning interatomic potential", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "We introduce a rapid, accurate framework for computing atomic migration\nbarriers in crystals by combining universal machine learning force fields\n(MLFFs) with 3D potential energy surface sampling and interpolation. Our method\nsuppresses periodic self interactions via supercell expansion, builds a\ncontinuous PES from MLFF energies on a spatial grid, and extracts minimum\nenergy pathways without predefined NEB images. Across twelve benchmark\nelectrode and electrolyte materials including LiCoO2, LiFePO4, and LGPS our\nMLFF-derived barriers lie within tens of meV of DFT and experiment, while\nachieving ~10^2 x speedups over DFT-NEB. We benchmark GPTFF, CHGNet, and MACE,\nshow that fine-tuning on PBE/PBE+U data further enhances accuracy, and provide\nan open-source package for high-throughput materials screening and interactive\nPES visualization.", "AI": {"tldr": "A fast, accurate framework using MLFFs for atomic migration barrier computation in crystals, achieving high speed and accuracy compared to DFT and experiments.", "motivation": "To address the computational inefficiency of DFT-NEB methods while maintaining accuracy in predicting atomic migration barriers in materials.", "method": "Combines MLFFs with 3D potential energy surface sampling, supercell expansion to suppress periodic self-interactions, and extracts minimum energy pathways without predefined NEB images.", "result": "MLFF-derived barriers match DFT and experimental results within tens of meV, with ~100x speedups over DFT-NEB. Fine-tuning on PBE/PBE+U data improves accuracy.", "conclusion": "The framework offers a rapid, accurate alternative to DFT-NEB, with potential for high-throughput materials screening and PES visualization."}}
{"id": "2508.10697", "pdf": "https://arxiv.org/pdf/2508.10697", "abs": "https://arxiv.org/abs/2508.10697", "authors": ["Shuchen Guo"], "title": "From Kac particles to the Landau equation with hard potentials: BBGKY hierarchy method", "categories": ["math.AP"], "comment": "30 pages", "summary": "We study the Kac particle model for the space-homogenous Landau equation with\nhard potentials. By showing a sharper Povzner-type inequality, we obtain the\nuniform-in-time and uniform-in-N propagation of exponential moment for the\nfirst marginal of the solution of the many-particle Liouville equation. This\nkey property enables us to show the uniqueness of weak solutions of the\ncorresponding infinite Landau hierarchy by coupling method. As a result, we\nprove the propagation of chaos for the Landau equation with hard potentials.", "AI": {"tldr": "The paper proves propagation of chaos for the Landau equation with hard potentials using a sharper Povzner-type inequality and coupling methods.", "motivation": "To analyze the Kac particle model for the space-homogenous Landau equation with hard potentials and establish uniform-in-time properties.", "method": "Uses a sharper Povzner-type inequality to show uniform propagation of exponential moments and coupling methods for uniqueness of weak solutions.", "result": "Demonstrates uniform-in-time propagation of exponential moments and proves propagation of chaos for the Landau equation.", "conclusion": "The study successfully establishes propagation of chaos for the Landau equation with hard potentials, leveraging key analytical tools."}}
{"id": "2508.10125", "pdf": "https://arxiv.org/pdf/2508.10125", "abs": "https://arxiv.org/abs/2508.10125", "authors": ["Christian Engwer", "Carsten Gr\u00e4ser", "Steffen M\u00fcthing", "Simon Praetorius", "Oliver Sander"], "title": "Concepts for Composing Finite Element Function Space Bases", "categories": ["cs.MS", "cs.NA", "math.NA", "68U20, 65N30, 65N08", "G.4; G.1.8"], "comment": "arXiv admin note: substantial text overlap with arXiv:1806.09545", "summary": "Finite Element discretizations of coupled multi-physics partial differential\nequation models require the handling of composed function spaces. In this paper\nwe discuss software concepts and abstractions to handle the composition of\nfunction spaces, based on a representation of product spaces as trees of\nsimpler bases. From this description, many different numberings of degrees of\nfreedom by multi-indices can be derived in a natural way, allowing to adapt the\nfunction spaces to very different data layouts, so that it opens the\npossibility to directly use the finite element code with very different linear\nalgebra codes, different data structures, and different algebraic solvers.\n  A recurring example throughout the paper is the stationary Stokes equation\nwith Taylor--Hood elements as these are naturally formulated as product spaces\nand highlight why different storage patterns are desirable.\n  In the second half of the paper we discuss a particular realization of most\nof these concepts in the \\dunemodule{dune-functions} module, as part of the\nDUNE ecosystem.", "AI": {"tldr": "The paper discusses software abstractions for handling composed function spaces in finite element discretizations, using tree structures for product spaces to enable flexible degree-of-freedom numbering and compatibility with diverse linear algebra tools.", "motivation": "To address the need for adaptable function space representations in multi-physics PDE models, enabling compatibility with various data layouts and solvers.", "method": "Representation of product spaces as trees of simpler bases, allowing derivation of multi-index degree-of-freedom numberings. The stationary Stokes equation with Taylor-Hood elements serves as an example.", "result": "The approach facilitates flexible function space adaptation for diverse data structures and algebraic solvers, demonstrated in the DUNE module dune-functions.", "conclusion": "The proposed abstractions and software concepts enhance the versatility of finite element codes for multi-physics applications, as showcased in the DUNE ecosystem."}}
{"id": "2508.10590", "pdf": "https://arxiv.org/pdf/2508.10590", "abs": "https://arxiv.org/abs/2508.10590", "authors": ["Viswak R Balaji", "Samuel Punch"], "title": "Simulating Mass-Dependent Decoherence in Quantum Computers: Baseline Signatures for Testing Gravity-Induced Collapse", "categories": ["quant-ph", "cs.ET", "physics.comp-ph"], "comment": null, "summary": "We present a quantum computing simulation study of mass-dependent decoherence\nmodels inspired by Penrose's gravity-induced collapse hypothesis. According to\nobjective reduction (OR) theory, quantum superpositions become unstable when\nthe gravitational self-energy difference between branches exceeds a certain\nthreshold, leading to a collapse time $\\tau \\approx \\hbar / E_G$. In this work,\nwe implement a mass-dependent dephasing noise channel, $p(m) = 1 - e^{-k\nm^{\\alpha}}$, within the Qiskit AerSimulator, where $m$ is a proxy for the\neffective mass of a superposition, mapped to circuit parameters such as the\nnumber of entangled qubits or branch size. We apply this model to three\ncanonical quantum computing experiments: GHZ state parity measurements,\nbranch-mass entanglement tests, and Grover's search to generate distinctive\ncollapse signatures that differ qualitatively from constant-rate dephasing. The\nresulting patterns serve as a baseline reference: if future hardware\nexperiments exhibit the same scaling trends under ideal isolation, this could\nindicate a contribution from mass-dependent collapse processes. Conversely,\ndeviation toward constant-noise behaviour would suggest the absence of such\ngravitationally induced effects. Our results provide a reproducible protocol\nand reference for using quantum computers as potential testbeds for probing\nfundamental questions in quantum mechanics.", "AI": {"tldr": "Simulation study of mass-dependent decoherence models inspired by Penrose's gravity-induced collapse hypothesis, using Qiskit AerSimulator to test collapse signatures in quantum computing experiments.", "motivation": "To explore whether quantum superpositions collapse due to gravitational effects, as suggested by objective reduction (OR) theory, and to provide a protocol for testing this in quantum computers.", "method": "Implemented a mass-dependent dephasing noise channel in Qiskit AerSimulator, applied to GHZ state parity measurements, branch-mass entanglement tests, and Grover's search.", "result": "Generated distinctive collapse signatures differing from constant-rate dephasing, serving as a reference for future hardware experiments.", "conclusion": "The study offers a reproducible protocol for using quantum computers to probe fundamental questions in quantum mechanics, with potential implications for gravity-induced collapse theories."}}
{"id": "2508.10722", "pdf": "https://arxiv.org/pdf/2508.10722", "abs": "https://arxiv.org/abs/2508.10722", "authors": ["Moritz Immanuel Gau", "Katharina Hopf"], "title": "Well-posedness and relaxation in a simplified model for viscoelastic phase separation via Hilbertian gradients flows", "categories": ["math.AP"], "comment": null, "summary": "This article is concerned with a gradient-flow approach to a Cahn-Hilliard\nmodel for viscoelastic phase separation introduced by Zhou et al. (Phys. Rev.\nE, 2006) in its variant with constant mobility. By means of time-incremental\nminimisation and generalised contractivity estimates, we establish the global\nwell-posedness of the Cauchy problem for moderately regular initial data. For\ngeneral finite-energy data we obtain the existence of gradient-flow solutions\nand a stability estimate of weak-strong type. We further study the asymptotic\nbehaviour for relaxation time and bulk modulus depending on a small parameter.\nDepending on the scaling, we recover the Cahn-Hilliard, the mass-conserving\nAllen-Cahn or the viscous Cahn-Hilliard equation. A challenge in the\nwell-posedness analysis is the failure of semiconvexity of the appropriate\ndriving functional, which is caused by a phase-dependence of the bulk modulus.", "AI": {"tldr": "The paper analyzes a gradient-flow approach to a Cahn-Hilliard model for viscoelastic phase separation, proving global well-posedness for moderately regular initial data and existence of gradient-flow solutions for finite-energy data. It also explores asymptotic behavior under parameter scaling.", "motivation": "To address the well-posedness and stability of a Cahn-Hilliard model for viscoelastic phase separation, particularly overcoming challenges like the lack of semiconvexity in the driving functional.", "method": "Uses time-incremental minimization and generalized contractivity estimates to establish well-posedness and stability. Studies asymptotic behavior under parameter scaling.", "result": "Global well-posedness for moderately regular initial data, existence of gradient-flow solutions for finite-energy data, and recovery of known equations (Cahn-Hilliard, mass-conserving Allen-Cahn, viscous Cahn-Hilliard) under specific scalings.", "conclusion": "The gradient-flow approach successfully addresses the model's challenges, providing well-posedness and stability results, and revealing connections to other equations through asymptotic analysis."}}
{"id": "2508.10202", "pdf": "https://arxiv.org/pdf/2508.10202", "abs": "https://arxiv.org/abs/2508.10202", "authors": ["Sreeram Venkat", "Kasia Swirydowicz", "Noah Wolfe", "Omar Ghattas"], "title": "Mixed-Precision Performance Portability of FFT-Based GPU-Accelerated Algorithms for Block-Triangular Toeplitz Matrices", "categories": ["cs.DC", "cs.NA", "cs.PF", "math.NA", "65Y20, 65Y05, 65Y10, 68Q25, 68W40, 65M32, 5B05", "F.2; G.4; C.4"], "comment": null, "summary": "The hardware diversity displayed in leadership-class computing facilities,\nalongside the immense performance boosts exhibited by today's GPUs when\ncomputing in lower precision, provide a strong incentive for scientific HPC\nworkflows to adopt mixed-precision algorithms and performance portability\nmodels. We present an on-the-fly framework using Hipify for performance\nportability and apply it to FFTMatvec-an HPC application that computes\nmatrix-vector products with block-triangular Toeplitz matrices. Our approach\nenables FFTMatvec, initially a CUDA-only application, to run seamlessly on AMD\nGPUs with excellent observed performance. Performance optimizations for AMD\nGPUs are integrated directly into the open-source rocBLAS library, keeping the\napplication code unchanged. We then present a dynamic mixed-precision framework\nfor FFTMatvec; a Pareto front analysis determines the optimal mixed-precision\nconfiguration for a desired error tolerance. Results are shown for AMD Instinct\nMI250X, MI300X, and the newly launched MI355X GPUs. The performance-portable,\nmixed-precision FFTMatvec is scaled to 2,048 GPUs on the OLCF Frontier\nsupercomputer.", "AI": {"tldr": "A framework using Hipify enables performance portability for FFTMatvec on AMD GPUs, with mixed-precision optimization for HPC workflows.", "motivation": "Leveraging hardware diversity and GPU performance in lower precision for scientific HPC workflows.", "method": "On-the-fly Hipify framework for porting CUDA-only FFTMatvec to AMD GPUs, integrating optimizations into rocBLAS, and dynamic mixed-precision analysis.", "result": "Seamless performance on AMD GPUs (MI250X, MI300X, MI355X) and scaling to 2,048 GPUs on Frontier.", "conclusion": "The framework successfully combines performance portability and mixed-precision optimization for HPC applications."}}
{"id": "2508.10666", "pdf": "https://arxiv.org/pdf/2508.10666", "abs": "https://arxiv.org/abs/2508.10666", "authors": ["Timothy Heightman", "Marcin P\u0142odzie\u0144"], "title": "Deep Learning in Classical and Quantum Physics", "categories": ["quant-ph", "cs.AI", "cs.NE", "physics.comp-ph"], "comment": null, "summary": "Scientific progress is tightly coupled to the emergence of new research\ntools. Today, machine learning (ML)-especially deep learning (DL)-has become a\ntransformative instrument for quantum science and technology. Owing to the\nintrinsic complexity of quantum systems, DL enables efficient exploration of\nlarge parameter spaces, extraction of patterns from experimental data, and\ndata-driven guidance for research directions. These capabilities already\nsupport tasks such as refining quantum control protocols and accelerating the\ndiscovery of materials with targeted quantum properties, making ML/DL literacy\nan essential skill for the next generation of quantum scientists. At the same\ntime, DL's power brings risks: models can overfit noisy data, obscure causal\nstructure, and yield results with limited physical interpretability.\nRecognizing these limitations and deploying mitigation strategies is crucial\nfor scientific rigor. These lecture notes provide a comprehensive,\ngraduate-level introduction to DL for quantum applications, combining\nconceptual exposition with hands-on examples. Organized as a progressive\nsequence, they aim to equip readers to decide when and how to apply DL\neffectively, to understand its practical constraints, and to adapt AI methods\nresponsibly to problems across quantum physics, chemistry, and engineering.", "AI": {"tldr": "The paper discusses the transformative role of deep learning (DL) in quantum science, highlighting its benefits and risks, and provides a graduate-level guide for its responsible application.", "motivation": "The motivation is to address the growing importance of DL in quantum science and technology, emphasizing its potential to solve complex problems while acknowledging its limitations.", "method": "The method involves a comprehensive, graduate-level introduction to DL for quantum applications, combining conceptual explanations with practical examples.", "result": "The result is an educational resource that equips quantum scientists with the skills to apply DL effectively and responsibly.", "conclusion": "The conclusion underscores the necessity of DL literacy in quantum science, balanced with awareness of its risks and limitations."}}
{"id": "2508.10773", "pdf": "https://arxiv.org/pdf/2508.10773", "abs": "https://arxiv.org/abs/2508.10773", "authors": ["Yuxiang Qiao"], "title": "$\\mathrm{C}^2$ estimates for general $p$-Hessian equations on closed Riemannian manifolds", "categories": ["math.AP", "math.DG", "35B45, 58J05 (Primary) 35J60, 35R01 (Secondary)"], "comment": "Any comments welcome!", "summary": "We study the $\\mathrm{C}^2$ estimates for $p$-Hessian equations with general\nleft-hand and right-hand terms on closed Riemannian manifolds of dimension $n$.\nTo overcome the constraints of closed manifolds, we advance a new kind of\n\"subsolution\", called pseudo-solution, which generalizes\n\"$\\mathcal{C}$-subsolution\" to some extent and is well-defined for fully\ngeneral $p$-Hessian equations. Based on pseudo-solutions, we prove the\n$\\mathrm{C}^0$ estimates, first-order estimates for general $p$-Hessian\nequations, and the corresponding second-order estimates when $p\\in\\{2, n-1,\nn\\}$, under sharp conditions -- we don't impose curvature restrictions,\nconvexity conditions or \"MTW condition\" on our main results. Some other\nconclusions related to a priori estimates and different kinds of \"subsolutions\"\nare also given, including estimates for \"semi-convex\" solutions and when there\nexists a pseudo-solution.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.10320", "pdf": "https://arxiv.org/pdf/2508.10320", "abs": "https://arxiv.org/abs/2508.10320", "authors": ["Aaditya Chandrasekhar", "Stefan Knapik", "Deepak Sharma", "John Reidy", "Ian McCue", "Jian Cao", "Wei Chen"], "title": "TOBACO: Topology Optimization via Band-limited Coordinate Networks for Compositionally Graded Alloys", "categories": ["cs.CE", "cs.NA", "math.NA"], "comment": "Submitted to Structural and Multidisciplinary Optimization", "summary": "Compositionally Graded Alloys (CGAs) offer unprecedented design flexibility\nby enabling spatial variations in composition; tailoring material properties to\nlocal loading conditions. This flexibility leads to components that are\nstronger, lighter, and more cost-effective than traditional monolithic\ncounterparts. The fabrication of CGAs have become increasingly feasible owing\nto recent advancements in additive manufacturing (AM), particularly in\nmulti-material printing and improved precision in material deposition. However,\nAM of CGAs requires imposition of manufacturing constraints; in particular\nlimits on the maximum spatial gradation of composition.\n  This paper introduces a topology optimization (TO) based framework for\ndesigning optimized CGA components with controlled compositional gradation. In\nparticular, we represent the constrained composition distribution using a\nband-limited coordinate neural network. By regulating the network's bandwidth,\nwe ensure implicit compliance with gradation limits, eliminating the need for\nexplicit constraints. The proposed approach also benefits from the inherent\nadvantages of TO using coordinate networks, including mesh independence,\nhigh-resolution design extraction, and end-to-end differentiability. The\neffectiveness of our framework is demonstrated through various elastic and\nthermo-elastic TO examples.", "AI": {"tldr": "A topology optimization framework using neural networks for designing Compositionally Graded Alloys (CGAs) with controlled gradation, leveraging additive manufacturing advancements.", "motivation": "CGAs offer superior material properties but require controlled gradation during additive manufacturing, necessitating a design framework to optimize composition distribution.", "method": "Uses a band-limited coordinate neural network to represent composition distribution, ensuring compliance with gradation limits without explicit constraints. Benefits include mesh independence and high-resolution design.", "result": "Demonstrated effectiveness through elastic and thermo-elastic topology optimization examples.", "conclusion": "The framework successfully designs optimized CGA components with controlled gradation, leveraging neural networks and additive manufacturing capabilities."}}
{"id": "2508.10671", "pdf": "https://arxiv.org/pdf/2508.10671", "abs": "https://arxiv.org/abs/2508.10671", "authors": ["Fabio Tarocco", "Pi A. B. Haase", "Fabijan Pavo\u0161evi\u0107", "Vijay Krishna", "Leonardo Guidoni", "Stefan Knecht", "Martina Stella"], "title": "AEGISS -- Atomic orbital and Entropy-based Guided Inference for Space Selection -- A novel semi-automated active space selection workflow for quantum chemistry and quantum computing applications", "categories": ["physics.chem-ph", "cond-mat.str-el", "physics.comp-ph", "quant-ph"], "comment": null, "summary": "The selection of a balanced active space is a critical step in\nmulti-reference quantum chemistry calculations, particularly for systems with\nstrong electron correlation. Likewise, active space selection is a key to\nunlock the potential of contemporary quantum computing in quantum chemistry.\nAlbeit recent progress, there remains a lack of a unified, robust, and fully\nautomated framework for active space selection that performs reliably across a\nwide range of molecular systems.\n  In this work, we present a novel approach inspired by both the AVAS (Atomic\nValence Active Space) and AutoCAS methods. Our method unifies orbital entropy\nanalysis with atomic orbital projections to guide the construction of\nchemically and physically meaningful active spaces. This integrated scheme\nenables a more consistent and flexible selection of active orbitals while\nretaining automation and scalability. We validate our approach on a set of\nmolecular systems relevant to photodynamic therapy, in particular a set of\nRu(II)-complexes, selected to span increasing levels of electron correlation\nand structural complexity. These molecules serve as challenging test cases due\nto the presence of strong static correlation and the need for highly accurate\nelectronic structure descriptions. Our results demonstrate that the method can\nreliably identify compact, chemically intuitive active spaces that capture the\nessential physics, making it suitable for both classical and quantum\ncomputational frameworks.\n  Furthermore, we have developed this approach in a package that is intuitive\nto use for users and can be interfaced with both standard quantum chemistry and\nquantum computing applications, making it accessible to a broad research\ncommunity.", "AI": {"tldr": "A novel automated method for selecting balanced active spaces in quantum chemistry, combining orbital entropy analysis and atomic orbital projections, validated on Ru(II)-complexes for photodynamic therapy.", "motivation": "Addressing the lack of a unified, robust, and automated framework for active space selection in systems with strong electron correlation, crucial for both classical and quantum computing applications.", "method": "Integrates orbital entropy analysis with atomic orbital projections, inspired by AVAS and AutoCAS, to guide the construction of chemically meaningful active spaces.", "result": "Reliably identifies compact, chemically intuitive active spaces for challenging systems like Ru(II)-complexes, capturing essential physics.", "conclusion": "The method is scalable, automated, and suitable for both classical and quantum computational frameworks, with a user-friendly package for broad accessibility."}}
{"id": "2508.10892", "pdf": "https://arxiv.org/pdf/2508.10892", "abs": "https://arxiv.org/abs/2508.10892", "authors": ["S. E. Boutiah", "D. Kinzebulatov"], "title": "Upper bound on heat kernels of finite particle systems of Keller-Segel type", "categories": ["math.AP", "math-ph", "math.MP", "math.PR"], "comment": null, "summary": "We obtain an upper bound on the heat kernel of the Keller-Segel finite\nparticle system that exhibits blow up effects. The proof exploits a connection\nbetween Keller-Segel finite particles and certain non-local operators. The\nlatter allows to address some aspects of the critical behaviour of the\nKeller-Segel system resulting from its two-dimensionality.", "AI": {"tldr": "Upper bound on the heat kernel of Keller-Segel finite particle system, showing blow-up effects.", "motivation": "To understand the critical behavior of the Keller-Segel system in two dimensions.", "method": "Exploits a connection between Keller-Segel finite particles and non-local operators.", "result": "Established an upper bound on the heat kernel, revealing blow-up effects.", "conclusion": "The approach provides insights into the critical behavior of the Keller-Segel system due to its two-dimensionality."}}
{"id": "2508.10452", "pdf": "https://arxiv.org/pdf/2508.10452", "abs": "https://arxiv.org/abs/2508.10452", "authors": ["Zhiqiang Xu"], "title": "New Lower Bounds for the Minimum Singular Value in Matrix Selection", "categories": ["math.FA", "cs.NA", "math.NA"], "comment": "13 pages", "summary": "The objective of the matrix selection problem is to select a submatrix\n$A_{S}\\in \\mathbb{R}^{n\\times k}$ from $A\\in \\mathbb{R}^{n\\times m}$ such that\nits minimum singular value is maximized. In this paper, we employ the\ninterlacing polynomial method to investigate this problem. This approach allows\nus to identify a submatrix $A_{S_0}\\in \\mathbb{R}^{n\\times k}$ and establish a\nlower bound for its minimum singular value. Specifically, unlike common\ninterlacing polynomial approaches that estimate the smallest root of the\nexpected characteristic polynomial via barrier functions, we leverage the\ndirect relationship between roots and coefficients. This leads to a tighter\nlower bound when $k$ is close to $n$. For the case where\n$AA^{\\top}=\\mathbb{I}_n$ and $k=n$, our result improves the well-known result\nby Hong-Pan, which involves extracting a basis from a tight frame and\nestablishing a lower bound for the minimum singular value of the basis matrix.", "AI": {"tldr": "The paper uses interlacing polynomials to maximize the minimum singular value of a submatrix, improving bounds for specific cases.", "motivation": "To address the matrix selection problem by maximizing the minimum singular value of a submatrix, enhancing existing results.", "method": "Employs the interlacing polynomial method, focusing on direct root-coefficient relationships for tighter bounds.", "result": "Achieves a tighter lower bound for the minimum singular value, especially when $k$ is close to $n$, improving prior work by Hong-Pan.", "conclusion": "The interlacing polynomial method provides a stronger lower bound for the matrix selection problem, particularly in critical cases."}}
{"id": "2508.10718", "pdf": "https://arxiv.org/pdf/2508.10718", "abs": "https://arxiv.org/abs/2508.10718", "authors": ["Wei Shan Lee", "I Hang Kwok", "Kam Ian Leong", "Chi Kiu Althina Chau", "Kei Chon Sio"], "title": "Symmetry-Constrained Multi-Scale Physics-Informed Neural Networks for Graphene Electronic Band Structure Prediction", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": "36 pages and 14 figures", "summary": "Accurate prediction of electronic band structures in two-dimensional\nmaterials remains a fundamental challenge, with existing methods struggling to\nbalance computational efficiency and physical accuracy. We present the\nSymmetry-Constrained Multi-Scale Physics-Informed Neural Network (SCMS-PINN)\nv35, which directly learns graphene band structures while rigorously enforcing\ncrystallographic symmetries through a multi-head architecture. Our approach\nintroduces three specialized ResNet-6 pathways -- K-head for Dirac physics,\nM-head for saddle points, and General head for smooth interpolation --\noperating on 31 physics-informed features extracted from k-points. Progressive\nDirac constraint scheduling systematically increases the weight parameter from\n5.0 to 25.0, enabling hierarchical learning from global topology to local\ncritical physics. Training on 10,000 k-points over 300 epochs achieves 99.99\\%\nreduction in training loss (34.597 to 0.003) with validation loss of 0.0085.\nThe model predicts Dirac point gaps within 30.3 $\\mu$eV of theoretical zero and\nachieves average errors of 53.9 meV (valence) and 40.5 meV (conduction) across\nthe Brillouin zone. All twelve C$_{6v}$ operations are enforced through\nsystematic averaging, guaranteeing exact symmetry preservation. This framework\nestablishes a foundation for extending physics-informed learning to broader\ntwo-dimensional materials for accelerated discovery.", "AI": {"tldr": "SCMS-PINN v35 predicts graphene band structures with high accuracy by enforcing crystallographic symmetries and using multi-head ResNet-6 pathways.", "motivation": "Existing methods struggle to balance computational efficiency and accuracy in predicting electronic band structures of 2D materials.", "method": "Uses Symmetry-Constrained Multi-Scale Physics-Informed Neural Network (SCMS-PINN) with three ResNet-6 pathways (K-head, M-head, General head) and progressive Dirac constraint scheduling.", "result": "Achieves 99.99% training loss reduction, predicts Dirac point gaps within 30.3 \u00b5eV, and enforces all twelve C6v operations.", "conclusion": "The framework enables accurate band structure prediction and can be extended to other 2D materials."}}
{"id": "2508.10306", "pdf": "https://arxiv.org/pdf/2508.10306", "abs": "https://arxiv.org/abs/2508.10306", "authors": ["Pawel Gajer", "Jacques Ravel"], "title": "Intrinsic and Normal Mean Ricci Curvatures: A Bochner--Weitzenboeck Identity for Simple d-Vectors", "categories": ["math.DG", "math.AP", "math.SP", "53C20 (Primary), 58J50, 53C65, 53C21, 35P15 53C20 (Primary), 58J50,\n  53C65, 53C21, 35P15 (Secondary) 53C20 (Primary), 58J50, 53C65, 53C21, 35P15\n  (Secondary)"], "comment": "12 pages, 1 figure", "summary": "We introduce two pointwise subspace averages of sectional curvature on a\nd-dimensional plane Pi in T_p M: (i) the intrinsic mean Ricci (the average of\nsectional curvatures of 2-planes contained in Pi); and (ii) the normal (mixed)\nmean Ricci (the average of sectional curvatures of 2-planes spanned by one\nvector in Pi and one in Pi^perp). Using Jacobi-field expansions, these means\noccur as the r^2/6 coefficients in the intrinsic (d-1)-sphere and normal\n(n-d-1)-sphere volume elements. A direct consequence is a Bochner--Weitzenboeck\nidentity for simple d-vectors V (built from an orthonormal frame X_1,...,X_d\nwith Pi = span{X_i}): the curvature term equals d(n-d) times the normal mean\nRicci of Pi. This yields two immediate applications: (a) a Bochner vanishing\ncriterion for harmonic simple d-vectors under a positive lower bound on the\nnormal mean Ricci; and (b) a Lichnerowicz-type lower bound for the first\neigenvalue of the Hodge Laplacian on simple d-eigenfields.", "AI": {"tldr": "The paper introduces two pointwise subspace averages of sectional curvature and uses Jacobi-field expansions to derive Bochner--Weitzenboeck identities and applications in harmonic analysis.", "motivation": "To generalize curvature averages and derive new identities for geometric analysis, particularly for harmonic simple d-vectors and Hodge Laplacian eigenvalues.", "method": "Defines intrinsic and normal mean Ricci averages, uses Jacobi-field expansions to relate these to volume elements, and derives Bochner--Weitzenboeck identities.", "result": "Establishes a curvature term identity and provides applications like a Bochner vanishing criterion and a Lichnerowicz-type eigenvalue bound.", "conclusion": "The introduced curvature averages and derived identities offer tools for analyzing harmonic forms and eigenvalues in geometric contexts."}}
{"id": "2508.10727", "pdf": "https://arxiv.org/pdf/2508.10727", "abs": "https://arxiv.org/abs/2508.10727", "authors": ["Segun Goh", "Dennis Haustein", "Gerhard Gompper"], "title": "Run-and-Tumble Escape in Pursuit-Evasion Dynamics of Intelligent Active Particles", "categories": ["physics.bio-ph", "cond-mat.stat-mech", "physics.comp-ph"], "comment": "6 figures", "summary": "The pursuit-evasion game is studied for two adversarial active agents,\nmodelled as a deterministic self-steering pursuer and a stochastic, cognitive\nevader. The pursuer chases the evader by reorienting its propulsion direction\nwith limited maneuverability, while the evader escapes by executing sharp,\nunpredictable turns, whose timing and direction the pursuer cannot anticipate.\nTo make the target responsive and agile when the threat level is high, the\ntumbling frequency is set to increase with decreasing distance from the\npursuer; furthermore, the range of preferred tumbling directions is varied.\nNumerical simulations of such a pursuit-target pair in two spatial dimensions\nreveal two important scenarios. For dominant pursuers, the evader is compelled\nto adopt a high-risk strategy that allows the pursuer to approach closely\nbefore the evader executes a potentially game-changing backward maneuver to\npull away from the pursuer. Otherwise, a strategy where the evader tumbles\nforward with continuous slight adjustments of the propulsion direction can\nsignificantly increase the capture time by preventing the pursuer from aligning\nwith the target propulsion direction, while maintaining the persistence of the\ntarget motion. Our results can guide the design of bioinspired robotic systems\nwith efficient evasion capabilities.", "AI": {"tldr": "The paper studies a pursuit-evasion game between a deterministic pursuer and a stochastic evader, analyzing strategies and outcomes in 2D simulations.", "motivation": "To understand adversarial dynamics between a pursuer with limited maneuverability and an evader with unpredictable, threat-responsive behavior, and to inform bioinspired robotic designs.", "method": "Numerical simulations in two spatial dimensions model the pursuer's deterministic steering and the evader's stochastic, distance-dependent tumbling behavior.", "result": "Two key scenarios emerge: high-risk backward maneuvers for dominant pursuers and forward tumbling with slight adjustments to prolong capture time.", "conclusion": "The findings provide insights for designing agile robotic systems with effective evasion strategies."}}
{"id": "2508.10694", "pdf": "https://arxiv.org/pdf/2508.10694", "abs": "https://arxiv.org/abs/2508.10694", "authors": ["Molly Brennan", "Edwina F. Yeo", "Philip Pearce", "Mohit P. Dalwadi"], "title": "Effective permeability conditions for diffusive transport through impermeable membranes with gaps", "categories": ["cond-mat.soft", "math.AP", "math.DS", "physics.bio-ph"], "comment": null, "summary": "Membranes regulate transport in a wide variety of industrial and biological\napplications. The microscale geometry of the membrane can significantly affect\noverall transport through the membrane, but the precise nature of this\nmultiscale coupling is not well characterised in general. Motivated by the\napplication of transport across a bacterial membrane, in this paper we use\nformal multiscale analysis to derive explicit effective coupling conditions for\nmacroscale transport across a two-dimensional impermeable membrane with\nperiodically spaced gaps, and validate these with numerical simulations. We\nderive analytic expressions for effective macroscale quantities associated with\nthe membrane, such as the permeability, in terms of the microscale geometry.\nOur results generalise the classic constitutive membrane coupling conditions to\na wider range of membrane geometries and time-varying scenarios. Specifically,\nwe demonstrate that if the exterior concentration varies in time, for membranes\nwith long channels, the transport gains a memory property where the coupling\nconditions depend on the system history. By applying our effective conditions\nin the context of small molecule transport through gaps in bacterial membranes\ncalled porins, we predict that bacterial membrane permeability is primarily\ndominated by the thickness of the membrane. Furthermore, we predict how\nalterations to membrane microstructure, for example via changes to porin\nexpression, might affect overall transport, including when external\nconcentrations vary in time. These results will apply to a broad range of\nphysical applications with similar membrane structures, from medical and\nindustrial filtration to carbon capture.", "AI": {"tldr": "The paper uses multiscale analysis to derive effective coupling conditions for transport across membranes with periodic gaps, validated by simulations. It generalizes classic conditions and reveals a memory effect for time-varying scenarios, predicting bacterial membrane permeability is dominated by thickness.", "motivation": "To understand the multiscale coupling between microscale membrane geometry and macroscale transport, particularly for bacterial membranes with periodic gaps.", "method": "Formal multiscale analysis and numerical simulations to derive and validate effective macroscale coupling conditions.", "result": "Derived analytic expressions for membrane permeability, showing a memory effect for time-varying scenarios. Predicted bacterial membrane permeability is dominated by thickness.", "conclusion": "The findings generalize membrane coupling conditions and apply to various applications like filtration and carbon capture, with implications for understanding bacterial transport."}}
{"id": "2508.10587", "pdf": "https://arxiv.org/pdf/2508.10587", "abs": "https://arxiv.org/abs/2508.10587", "authors": ["Xuanhao Mu", "G\u00f6khan Demirel", "Yuzhe Zhang", "Jianlei Liu", "Thorsten Schlachter", "Veit Hagenmeyer"], "title": "Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer", "categories": ["cs.LG", "cs.NA", "eess.SP", "math.NA"], "comment": null, "summary": "To bridge the temporal granularity gap in energy network design and operation\nbased on Energy System Models, resampling of time series is required. While\nconventional upsampling methods are computationally efficient, they often\nresult in significant information loss or increased noise. Advanced models such\nas time series generation models, Super-Resolution models and imputation models\nshow potential, but also face fundamental challenges. The goal of time series\ngenerative models is to learn the distribution of the original data to generate\nhigh-resolution series with similar statistical characteristics. This is not\nentirely consistent with the definition of upsampling. Time series\nSuper-Resolution models or imputation models can degrade the accuracy of\nupsampling because the input low-resolution time series are sparse and may have\ninsufficient context. Moreover, such models usually rely on supervised learning\nparadigms. This presents a fundamental application paradox: their training\nrequires the high-resolution time series that is intrinsically absent in\nupsampling application scenarios. To address the mentioned upsampling issue,\nthis paper introduces a new method utilizing Generative Adversarial\nTransformers (GATs), which can be trained without access to any ground-truth\nhigh-resolution data. Compared with conventional interpolation methods, the\nintroduced method can reduce the root mean square error (RMSE) of upsampling\ntasks by 9%, and the accuracy of a model predictive control (MPC) application\nscenario is improved by 13%.", "AI": {"tldr": "The paper introduces a new method using Generative Adversarial Transformers (GATs) for upsampling energy network time series, reducing RMSE by 9% and improving MPC accuracy by 13%.", "motivation": "To address the limitations of conventional upsampling methods and advanced models (e.g., time series generation, Super-Resolution, imputation) in energy network design, which suffer from information loss, noise, or reliance on unavailable high-resolution data.", "method": "Proposes Generative Adversarial Transformers (GATs), a method that learns the distribution of original data to generate high-resolution series without needing ground-truth high-resolution data for training.", "result": "GATs reduce RMSE by 9% in upsampling tasks and improve MPC accuracy by 13% compared to conventional interpolation methods.", "conclusion": "The GATs method effectively addresses the upsampling paradox and outperforms existing approaches, offering a viable solution for energy network applications."}}
{"id": "2508.10808", "pdf": "https://arxiv.org/pdf/2508.10808", "abs": "https://arxiv.org/abs/2508.10808", "authors": ["Akash Rodhiya", "Shashwat Bhattacharya", "Mahendra K Verma"], "title": "Relative accuracy of turbulence simulations using pseudo-spectral and finite difference solvers", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": "10 pages, 7 figures", "summary": "For a single timestep, a spectral solver is known to be more accurate than\nits finite-difference counterpart. However, as we show in this paper,\nturbulence simulations using the two methods have nearly the same accuracy. In\nthis paper, we simulate forced hydrodynamic turbulence on a uniform 256$^3$\ngrid for Reynolds numbers 965, 1231, 1515, and 1994. We show that the two\nmethods yield nearly the same evolution for the total energy and the flow\nprofiles. In addition, the steady-state energy spectrum, energy flux, and\nprobability distribution functions of the velocity and its derivatives are very\nsimilar. We argue that within a turbulence attractor, the numerical errors are\nlikely to get cancelled (rather than get added up), which leads to similar\nresults for the finite-difference and spectral methods. These findings are very\nvaluable, considering that a parallel finite-difference simulation is more\nversatile and efficient (for large grids) than its spectral counterpart.", "AI": {"tldr": "Spectral and finite-difference methods yield similar accuracy in turbulence simulations despite spectral methods being more accurate per timestep.", "motivation": "To compare the accuracy of spectral and finite-difference methods in turbulence simulations, challenging the assumption that spectral methods are always superior.", "method": "Simulated forced hydrodynamic turbulence on a 256\u00b3 grid for varying Reynolds numbers, comparing energy evolution, flow profiles, and statistical measures.", "result": "Both methods produced nearly identical results in energy, spectra, flux, and velocity distributions, suggesting error cancellation in turbulence attractors.", "conclusion": "Finite-difference methods are equally effective for turbulence simulations and more efficient for large grids, making them a practical alternative to spectral methods."}}
{"id": "2508.10721", "pdf": "https://arxiv.org/pdf/2508.10721", "abs": "https://arxiv.org/abs/2508.10721", "authors": ["Romain Petrides"], "title": "Isoperimetric inequalities involving Steklov eigenvalues on surfaces", "categories": ["math.DG", "math.AP", "math.SP"], "comment": null, "summary": "We give results on optimal constants of isoperimetric inequalities involving\nSteklov eigenvalues on surfaces with boundary. We both consider this question\non Riemannian surfaces with a same given topology or more specifically\nbelonging to the same conformal class. We provide new examples of topological\ndisks that realize optimal constants. We prove inequalities that relate\nconformal invariants associated to combinations of Steklov eigenvalues on a\ncompact Riemannian surface with boundary and the ones on the disk. In the\nappendix, we show rigidity of the first conformal Steklov eigenvalue on annuli\nand M\\\"obius bands.", "AI": {"tldr": "The paper explores optimal constants for isoperimetric inequalities related to Steklov eigenvalues on surfaces with boundary, focusing on Riemannian surfaces with specific topologies or conformal classes. It provides new examples of optimal topological disks and proves inequalities linking conformal invariants of Steklov eigenvalues on surfaces and disks. The appendix addresses rigidity of the first conformal Steklov eigenvalue on annuli and M\u00f6bius bands.", "motivation": "To advance understanding of isoperimetric inequalities and Steklov eigenvalues on surfaces with boundary, particularly in specific topological or conformal contexts.", "method": "The study involves analyzing Riemannian surfaces with given topologies or conformal classes, proving inequalities, and examining rigidity in specific cases like annuli and M\u00f6bius bands.", "result": "New examples of optimal topological disks are identified, and inequalities relating conformal invariants of Steklov eigenvalues are established. Rigidity results for the first conformal Steklov eigenvalue are also presented.", "conclusion": "The findings contribute to the theoretical framework of isoperimetric inequalities and Steklov eigenvalues, with implications for understanding geometric and conformal properties of surfaces."}}
{"id": "2508.10596", "pdf": "https://arxiv.org/pdf/2508.10596", "abs": "https://arxiv.org/abs/2508.10596", "authors": ["Andreas E. Kyprianou", "Aaron Pim", "Tristan Pryer"], "title": "A Unified Framework from Boltzmann Transport to Proton Treatment Planning", "categories": ["math.PR", "cs.NA", "math.NA", "math.OC", "physics.med-ph"], "comment": "23 pages, 3 figures", "summary": "This work develops a rigorous mathematical formulation of proton transport by\nintegrating both deterministic and stochastic perspectives. The deterministic\nframework is based on the Boltzmann-Fokker-Planck equation, formulated as an\noperator equation in a suitable functional setting. The stochastic approach\nmodels proton evolution via a track-length parameterised diffusion process,\nwhose infinitesimal generator provides an alternative description of transport.\n  A key result is the duality between the stochastic and deterministic\nformulations, established through the adjoint relationship between the\ntransport operator and the stochastic generator. We prove that the resolvent of\nthe stochastic process corresponds to the Green's function of the deterministic\nequation, providing a natural link between fluence-based and particle-based\ntransport descriptions. The theory is applied to dose computation, where we\nshow that the classical relation: dose = (fluence * mass stopping power) arises\nconsistently in both approaches.\n  Building on this foundation, we formulate a hybrid optimisation framework for\ntreatment planning, in which dose is computed using a stochastic model while\noptimisation proceeds via adjoint-based PDE methods. We prove existence and\ndifferentiability of the objective functional and derive the first-order\noptimality system. This framework bridges stochastic simulation with\ndeterministic control theory and provides a foundation for future work in\nconstrained, adaptive and uncertainty-aware optimisation in proton therapy.", "AI": {"tldr": "The paper integrates deterministic and stochastic models for proton transport, establishes duality between them, and applies the theory to dose computation and treatment planning.", "motivation": "To rigorously unify deterministic and stochastic perspectives of proton transport for improved accuracy in dose computation and treatment planning.", "method": "Combines the Boltzmann-Fokker-Planck equation (deterministic) with a stochastic diffusion process, proving duality and resolvent-Green's function equivalence. Applies this to dose computation and hybrid optimization for treatment planning.", "result": "Duality between stochastic and deterministic models is proven, and the classical dose-fluence relationship is validated. A hybrid optimization framework for treatment planning is developed.", "conclusion": "The framework bridges stochastic simulation with deterministic control, enabling future advancements in proton therapy optimization."}}
{"id": "2508.10841", "pdf": "https://arxiv.org/pdf/2508.10841", "abs": "https://arxiv.org/abs/2508.10841", "authors": ["Viktor Zaverkin", "Matheus Ferraz", "Francesco Alesiani", "Mathias Niepert"], "title": "Performance of universal machine-learned potentials with explicit long-range interactions in biomolecular simulations", "categories": ["physics.chem-ph", "cond-mat.soft", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Universal machine-learned potentials promise transferable accuracy across\ncompositional and vibrational degrees of freedom, yet their application to\nbiomolecular simulations remains underexplored. This work systematically\nevaluates equivariant message-passing architectures trained on the SPICE-v2\ndataset with and without explicit long-range dispersion and electrostatics. We\nassess the impact of model size, training data composition, and electrostatic\ntreatment across in- and out-of-distribution benchmark datasets, as well as\nmolecular simulations of bulk liquid water, aqueous NaCl solutions, and\nbiomolecules, including alanine tripeptide, the mini-protein Trp-cage, and\nCrambin. While larger models improve accuracy on benchmark datasets, this trend\ndoes not consistently extend to properties obtained from simulations. Predicted\nproperties also depend on the composition of the training dataset. Long-range\nelectrostatics show no systematic impact across systems. However, for Trp-cage,\ntheir inclusion yields increased conformational variability. Our results\nsuggest that imbalanced datasets and immature evaluation practices currently\nchallenge the applicability of universal machine-learned potentials to\nbiomolecular simulations.", "AI": {"tldr": "The paper evaluates machine-learned potentials for biomolecular simulations, focusing on model size, training data, and electrostatic effects, finding challenges in transferability and evaluation practices.", "motivation": "To assess the applicability of universal machine-learned potentials in biomolecular simulations, addressing gaps in transferability and evaluation.", "method": "Systematic evaluation of equivariant message-passing architectures trained on SPICE-v2 dataset, testing model size, training data composition, and electrostatic treatments.", "result": "Larger models improve benchmark accuracy but not simulation properties. Training data composition affects predictions. Long-range electrostatics show inconsistent impact, except for Trp-cage.", "conclusion": "Imbalanced datasets and immature evaluation practices limit the current applicability of universal machine-learned potentials in biomolecular simulations."}}
