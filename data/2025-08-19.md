<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 12]
- [math.AP](#math.AP) [Total: 21]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 6]
- [stat.ML](#stat.ML) [Total: 1]
- [math.FA](#math.FA) [Total: 2]
- [physics.chem-ph](#physics.chem-ph) [Total: 2]
- [math.PR](#math.PR) [Total: 2]
- [math.SP](#math.SP) [Total: 1]
- [physics.acc-ph](#physics.acc-ph) [Total: 2]
- [hep-ph](#hep-ph) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [quant-ph](#quant-ph) [Total: 2]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [nlin.AO](#nlin.AO) [Total: 1]
- [math.CA](#math.CA) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]
- [physics.app-ph](#physics.app-ph) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Reduced-order modeling of Hamiltonian dynamics based on symplectic neural networks](https://arxiv.org/abs/2508.11911)
*Yongsheng Chen,Wei Guo,Qi Tang,Xinghui Zhong*

Main category: math.NA

TL;DR: A novel symplectic reduced-order modeling framework that combines latent-space discovery and dynamics learning in a single neural architecture using HenonNets, preserving Hamiltonian structure for enhanced stability and accuracy.


<details>
  <summary>Details</summary>
Motivation: To develop a unified framework for Hamiltonian systems that maintains exact symplectic structure at the reduced-order level, addressing the need for long-term stability and fidelity in reduced-order models.

Method: Uses Henon neural networks (HenonNets) with optional SGS-reflector layers to create exact symplectic maps between full and latent phase spaces, with latent dynamics advanced by symplectic flow maps implemented as HenonNets.

Result: Demonstrates accurate trajectory reconstruction, robust predictive performance beyond training horizon, and accurate Hamiltonian preservation in canonical Hamiltonian systems through comprehensive numerical experiments.

Conclusion: The framework shows promising effectiveness and broad applicability potential for complex dynamical systems across scientific and engineering disciplines due to its structure-preserving properties.

Abstract: We introduce a novel data-driven symplectic induced-order modeling (ROM)
framework for high-dimensional Hamiltonian systems that unifies latent-space
discovery and dynamics learning within a single, end-to-end neural
architecture. The encoder-decoder is built from Henon neural networks
(HenonNets) and may be augmented with linear SGS-reflector layers. This yields
an exact symplectic map between full and latent phase spaces. Latent dynamics
are advanced by a symplectic flow map implemented as a HenonNet. This unified
neural architecture ensures exact preservation of the underlying symplectic
structure at the reduced-order level, significantly enhancing the fidelity and
long-term stability of the resulting ROM. We validate our method through
comprehensive numerical experiments on canonical Hamiltonian systems. The
results demonstrate the method's capability for accurate trajectory
reconstruction, robust predictive performance beyond the training horizon, and
accurate Hamiltonian preservation. These promising outcomes underscore the
effectiveness and potential applicability of our symplectic ROM framework for
complex dynamical systems across a broad range of scientific and engineering
disciplines.

</details>


### [2] [Implicit-Explicit Scheme with Multiscale Vanka Two-Grid Solver for Heterogeneous Unsaturated Poroelasticity](https://arxiv.org/abs/2508.12197)
*Maria Vasilyeva,Ben S. Southworth,Yunhui He,Min Wang*

Main category: math.NA

TL;DR: Efficient multiscale two-grid solver for unsaturated flow in heterogeneous poroelastic media using implicit-explicit time integration with fixed linear components and explicit nonlinear residuals.


<details>
  <summary>Details</summary>
Motivation: Solve coupled nonlinear equations for unsaturated flow in heterogeneous poroelastic media efficiently, avoiding expensive solver reconstruction for each time step/nonlinear iteration.

Method: Finite element space approximation with two-grid solver: (i) local spectral spaces for coarse grid, (ii) overlapping multiscale Vanka method for coupled smoothing. Implicit-explicit time integration separates stiff linear components (fixed) from nonlinear residuals (explicit).

Result: Robust two-grid solver demonstrated for 2D nonlinear coupled test problem, showing efficacy of block smoothing over pointwise smoothing, and accuracy/stability of implicit-explicit integration.

Conclusion: The proposed method provides efficient online time integration with linear stability, making it suitable for complex unsaturated flow problems in heterogeneous poroelastic media.

Abstract: We consider a coupled nonlinear system of equations that describe unsaturated
flow in heterogeneous poroelastic media. For the numerical solution, we use a
finite element approximation in space and present an efficient multiscale
two-grid solver for solving the coupled system of equations. The proposed
two-grid solver contains two main parts: (i) accurate coarse grid approximation
based on local spectral spaces and (ii) coupled smoothing iterations based on
an overlapping multiscale Vanka method. A Vanka smoother and local spectral
coarse grids come with significant computational cost in the setup phase. To
avoid constructing a new solver for each time step and/or nonlinear iteration,
we utilize an implicit-explicit integration scheme in time, where we partition
the nonlinear operator as a sum of linear and nonlinear parts. In particular,
we construct an implicit linear approximation of the stiff components that
remains fixed across all time, while treating the remaining nonlinear residual
explicitly. This allows us to construct a robust two-grid solver offline and
utilize it for fast and efficient online time integration. A linear stability
analysis of the proposed novel coupled scheme is presented based on the
representation of the system as a two-step scheme. We show that the careful
decomposition of linear and nonlinear parts guarantees a linearly stable
scheme. A numerical study is presented for a two-dimensional nonlinear coupled
test problem of unsaturated flow in heterogeneous poroelastic media. We
demonstrate the robustness of the two-grid solver, particularly the efficacy of
block smoothing compared with simple pointwise smoothing, and illustrate the
accuracy and stability of implicit-explicit time integration.

</details>


### [3] [Structure-preserving parametric finite element methods for two-phase Stokes flow based on Lagrange multiplier approaches](https://arxiv.org/abs/2508.12326)
*Harald Garcke,Dennis Trautwein,Ganghui Zhang*

Main category: math.NA

TL;DR: Novel parametric finite element method for two-phase Stokes flow with exact energy-decaying and volume-preserving properties at discrete level using Lagrange multipliers and higher-order time discretizations.


<details>
  <summary>Details</summary>
Motivation: To develop numerical methods that exactly preserve the physical structures (energy-decaying and volume-preserving properties) of two-phase Stokes flow at the fully discrete level, which is crucial for accurate long-term simulations.

Method: New formulation based on classical Stokes equation with novel interface conditions using additional Lagrange multipliers. Employs higher-order time discretization methods (Crank-Nicolson and second-order backward differentiation formula) and solves resulting nonlinear schemes efficiently with Newton method and decoupling technique.

Result: Extensive numerical experiments demonstrate that the methods achieve desired temporal accuracy while exactly preserving the two physical structures (energy-decaying and volume-preserving properties) of the two-phase Stokes system.

Conclusion: The proposed Lagrange multiplier approach successfully ensures exact preservation of physical structures in two-phase Stokes flow simulations, with efficient nonlinear solution techniques and demonstrated temporal accuracy.

Abstract: We present a novel formulation for parametric finite element methods to
approximate two-phase Stokes flow. The new formulation is based on the
classical Stokes equation in the bulk and a novel choice of interface
conditions with additional Lagrange multipliers. This new Lagrange multiplier
approach ensures that the numerical methods exactly preserve two physical
structures of two-phase Stokes flow at the fully discrete level: (i) the
energy-decaying and (ii) the volume-preserving properties. Moreover, different
types of higher-order time discretization methods are employed, including the
Crank--Nicolson method and the second-order backward differentiation formula
approach. The resulting schemes are nonlinear and can be efficiently solved by
using the Newton method with a decoupling technique. Extensive numerical
experiments demonstrate that our methods achieve the desired temporal accuracy
while preserving the two physical structures of the two-phase Stokes system.

</details>


### [4] [Adaptive time-domain boundary element methods for the wave equation with Neumann boundary conditions](https://arxiv.org/abs/2508.12332)
*Alessandra Aimi,Giulia Di Credico,Heiko Gimperlein,Chiara Guardasoni*

Main category: math.NA

TL;DR: Adaptive mesh refinement methods for wave equation with Neumann boundary conditions using hypersingular boundary integral equations and space-time boundary element method with a posteriori error estimates.


<details>
  <summary>Details</summary>
Motivation: To develop efficient adaptive mesh refinement procedures for solving time-domain wave equations with Neumann boundary conditions, which are challenging due to the hypersingular nature of boundary integral equations.

Method: Space-adaptive and time-adaptive versions of a space-time boundary element method based on reliable a posteriori error estimates of residual type.

Result: Numerical experiments demonstrate the performance of the proposed adaptive approach.

Conclusion: The adaptive mesh refinement procedures effectively handle the hypersingular boundary integral formulation of wave equations with Neumann conditions.

Abstract: This article investigates adaptive mesh refinement procedures for the
time-domain wave equation with Neumann boundary conditions, formulated as an
equivalent hypersingular boundary integral equation. Space-adaptive and
time-adaptive versions of a space-time boundary element method are presented,
based on a reliable a posteriori error estimate of residual type. Numerical
experiments illustrate the performance of the proposed approach.

</details>


### [5] [Convergence analysis of Left-Right splitting surface scattering method](https://arxiv.org/abs/2508.12342)
*Paul E Parbone,Mark Spivack,Orsola Rath Spivack*

Main category: math.NA

TL;DR: Analysis of convergence behavior and improvement strategies for Left-Right splitting method in wave scattering by rough surfaces, including eigenvalue analysis and Shanks transformation for overcoming divergence.


<details>
  <summary>Details</summary>
Motivation: To understand why the Left-Right splitting method converges rapidly in some cases but fails in others, and to develop strategies to improve convergence or overcome divergence in wave scattering problems.

Method: Two approaches: (1) Examining eigenvalues by subtracting dominant eigenvectors from incident field to analyze convergence mechanisms, (2) Applying generalized Shanks' transformation to the operator series to improve convergence and provide stopping criteria.

Result: The method explains why rapid convergence occurs for large incident angles, provides analytical solutions for divergent eigenvectors, and shows that exact well-behaved solutions can be recovered from divergent series using Shanks transformation.

Conclusion: The study provides theoretical insight into convergence regimes, offers practical strategies for convergence improvement that generalize to 3D problems, and demonstrates that exact solutions can be extracted from divergent series through transformation techniques.

Abstract: We study the convergence of the Left-Right splitting method (equivalent in
key respects to the Method of Multiple Ordered Interactions and
Forward-Backward method) for wave scattering by rough surfaces. This is an
operator series method primarily designed for low grazing incidence and found
in many cases to converge rapidly, often within one or two terms even for large
incident angles. However, convergence is not guaranteed and semi-convergence
may be observed.
  Our aims are two-fold: (1) To obtain theoretical and physical insight into
the regimes in which rapid convergence occurs and the mechanisms by which it
fails, by examining and modifying eigenvalues of the operator; (2) provide a
strategy for increasing the speed of convergence or more crucially for
overcoming divergence, and providing a stopping criterion. The first is
addressed by subtracting successive dominant eigenvectors from the incident
field, to examine the impact on divergence and on the incident spectrum. For
the second, we apply a generalisation of Shanks' transformation to the operator
series; this effectively improves convergence and (unlike eigenvalue
subtraction) readily generalises to 3D and composite problems. These results
also explain why the method converges so rapidly for much larger incident
angles. Finally we ask and give an analytical solution to a key question: For a
divergent eigenvector of the iterating operator, what is the exact solution and
can it be deduced from the divergent series? We show that the exact solution is
well-behaved and can be found from the series in a way which is related to the
Shanks transformation.

</details>


### [6] [Anderson Acceleration For Perturbed Newton Methods](https://arxiv.org/abs/2508.12513)
*Matt Dallas*

Main category: math.NA

TL;DR: Convergence theory for Anderson acceleration applied to perturbed Newton methods with safeguarding, showing improved linear convergence rates for 2-regular problems including Newton and Levenberg-Marquardt methods.


<details>
  <summary>Details</summary>
Motivation: To develop a theoretical foundation for accelerating perturbed Newton methods using Anderson acceleration while ensuring convergence through safeguarding techniques.

Method: Anderson acceleration coupled with γ-safeguarding applied to perturbed Newton methods, with analysis of local linear convergence in starlike domains for 2-regular problems.

Result: Proved that Anderson accelerated perturbed Newton methods with safeguarding converge locally linearly with improved rates compared to standard methods, and demonstrated effectiveness on benchmark problems.

Conclusion: Anderson acceleration with safeguarding provides accelerated convergence for perturbed Newton methods while maintaining stability, with applications to both classical Newton and Levenberg-Marquardt methods.

Abstract: We present a convergence theory For Anderson acceleration (AA) applied to
perturbed Newton methods (pNMs) For computing roots of nonlinear problems. Two
important special cases are the classical Newton method and the
Levenberg-Marquardt method. We prove that if a problem is 2-regular, then
Anderson accelerated pNMs coupled with a safeguarding scheme, known as
$\gamma$-safeguarding, converge locally linearly in a starlike domain of
convergence, but with an improved rate of convergence compared to standard
perturbed Newton methods. Since Levenberg-Marquardt methods are a special case
of pNMs, we obtain a novel acceleration and local convergence result For
Anderson accelerated Levenberg-Marquardt. We further show that the safeguarding
technique can detect if the underlying perturbed Newton method is converging
superlinearly, and respond by tuning the Anderson step down. We demonstrate the
methods on several benchmark problems in the literature.

</details>


### [7] [Comparison of three random field sampling methods for high-resolution Bayesian inversion with application to a plane stress problem](https://arxiv.org/abs/2508.12876)
*Pieter Vanmechelen,Geert Lombaert,Giovanni Samaey*

Main category: math.NA

TL;DR: Comparison of three random field sampling approaches (Karhunen-Loeve, wavelet expansions, local average subdivision) for Bayesian inversion in high-dimensional spatial parameter estimation, finding comparable posterior estimates with local average subdivision being slightly more numerically efficient.


<details>
  <summary>Details</summary>
Motivation: Bayesian inversion requires uncertainty quantification for posterior estimates of continuous spatial functions, and different random field sampling strategies need evaluation for numerical efficiency and impact on posterior distributions in high-dimensional problems.

Method: Used multilevel Markov chain Monte Carlo algorithm with three approaches: (i) Karhunen-Loeve expansion, (ii) wavelet expansion, and (iii) local average subdivision, applied to 2D plane stress model with static displacement observations for material parameter reconstruction.

Result: All three methods provided comparable posterior estimates. The local average subdivision method achieved slightly better numerical efficiency than the Karhunen-Loeve and wavelet expansion approaches.

Conclusion: Local average subdivision is the most numerically efficient approach among the three random field sampling methods tested for high-dimensional Bayesian inversion problems, while all methods yield similar posterior estimation quality.

Abstract: Bayesian inversion aims to provide uncertainty quantification of posterior
estimates conditional on observations. When the inferred parameter is a
continuous spatial function, one common strategy is to model it as a random
field. Several random field sampling strategies exist. In this article, we
investigate three different approaches in terms of numerical efficiency and
influence on the posterior distribution. These approaches are based on (i)
Karhunen-Loeve and (ii) wavelet expansions, and (iii) local average
subdivision. We use the multilevel Markov chain Monte Carlo algorithm to
construct posterior estimates with all approaches. This enables a focus on
high-dimensional problems discretised on high-resolution finite element grids.
As an application, we consider the reconstruction of material parameters in a
2D plane stress model, conditional on static displacement observations. Through
these numerical experiments, we deduce that the methods provide comparable
posterior estimates and that the local average subdivision method attains
slightly better numerical efficiency than the other two approaches.

</details>


### [8] [$\boldsymbol{H}(\textbf{curl})$-reconstruction of piecewise polynomial fields with application to $hp$-a posteriori nonconforming error analysis for Maxwell's equations](https://arxiv.org/abs/2508.12904)
*Zhaonan Dong,Alexandre Ern*

Main category: math.NA

TL;DR: Novel H(curl)-reconstruction operator for piecewise polynomial fields on simplicial meshes with optimal error bounds and applications to Maxwell's equations.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient reconstruction operator for H(curl) fields that can handle homogeneous tangential boundary conditions and provide optimal error estimates for discontinuous Galerkin methods in electromagnetics.

Method: Uses partition of unity from hat basis functions combined with local Helmholtz decompositions over mesh vertex patches, with focus on homogeneous tangential boundary conditions.

Result: Achieves h-optimal and p-suboptimal error bounds (1/2-order for broken curl norm, 3/2-order for L²-norm), with improved bounds under elliptic regularity assumptions. Provides novel broken-curl Poincaré inequality.

Conclusion: The reconstruction operator enables accurate error analysis for discontinuous Galerkin approximations of Maxwell's equations and can be extended to mixed boundary conditions and polytopal meshes.

Abstract: We devise and analyse a novel $\boldsymbol{H}(\textbf{curl})$-reconstruction
operator for piecewise polynomial fields on shape-regular simplicial meshes.
The (non-polynomial) reconstruction is devised over the mesh vertex patches
using the partition of unity induced by hat basis functions in combination with
local Helmholtz decompositions. Our main focus is on homogeneous tangential
boundary conditions. We prove that the difference between the reconstructed
$\boldsymbol{H}_0(\textbf{curl})$-field and the original, piecewise polynomial
field, measured in the broken curl norm and in the $\boldsymbol{L}^2$-norm, can
be bounded in terms of suitable jump norms of the original field. The bounds
are always $h$-optimal, and $p$-suboptimal by $\frac12$-order for the broken
curl norm and by $\frac32$-order for the $\boldsymbol{L}^2$-norm. An auxiliary
result of independent interest is a novel broken-curl, divergence-preserving
Poincar\'{e} inequality on vertex patches. Moreover, the
$\boldsymbol{L}^2$-norm estimate can be improved to $\frac12$-order
suboptimality under a (reasonable) assumption on the uniform elliptic
regularity pickup for a Poisson problem with Neumann conditions over the vertex
patches. We also discuss extensions of the
$\boldsymbol{H}_0(\textbf{curl})$-reconstruction operator to the prescription
of mixed boundary conditions, to agglomerated polytopal meshes, and to convex
domains. Finally, we showcase an important application of the
$\boldsymbol{H}(\textbf{curl})$-reconstruction operator to the $hp$-a
posteriori nonconforming error analysis of Maxwell's equations. We focus on the
(symmetric) interior penalty discontinuous Galerkin (dG) approximation of some
simplified forms of Maxwell's equations.

</details>


### [9] [Basis construction for polynomial spline spaces over arbitrary T-meshe](https://arxiv.org/abs/2508.12950)
*Shicong Zhong,Falai Chen,Bingru Huang*

Main category: math.NA

TL;DR: First method for constructing polynomial spline bases over arbitrary T-meshes (PT-splines) using edge extension and elimination techniques to ensure linear independence and completeness.


<details>
  <summary>Details</summary>
Motivation: Existing spline methods like LR B-splines lack linear independence and are limited to specific mesh types, while dimensional instability in spline spaces causes basis function degradation.

Method: Convert arbitrary T-meshes to diagonalizable ones via edge extension, construct basis functions from three components (cross-cuts, rays, T l-edges), then use Extended Edge Elimination to remove redundant edges and construct basis for original mesh.

Result: PT-spline basis ensures linear independence and completeness across any T-mesh, outperforming LR B-splines and HB-splines for certain hierarchical T-meshes.

Conclusion: PT-splines provide the first versatile basis construction method for arbitrary T-meshes with guaranteed linear independence, addressing limitations of existing approaches.

Abstract: This paper presents the first method for constructing bases for polynomial
spline spaces over an arbitrary T-meshes (PT-splines for short). We construct
spline basis functions for an arbitrary T-mesh by first converting the T-mesh
into a diagonalizable one via edge extension, ensuring a stable dimension of
the spline space. Basis functions over the diagoalizable T-mesh are constructed
according to the three components in the dimension formula corresponding to
cross-cuts, rays, and T $l$-edges in the diagonalizable T-mesh, and each
component is assigned some local tensor product B-splines as the basis
functions. We prove this set of functions constitutes a basis for the
diagonalizable T-mesh. To remove redundant edges from extension, we introduce a
technique, termed Extended Edge Elimination (EEE) to construct a basis for an
arbitrary T-mesh while reducing structural constraints and unnecessary
refinements. The resulting PT-spline basis ensures linear independence and
completeness, supported by a dedicated construction algorithm. A comparison
with LR B-splines, which may lack linear independence and are limited to
LR-meshes, highlights the PT-spline's versatility across any T-mesh. Examples
are also provided to demonstrate that dimensional instability in spline spaces
is related with basis function degradation and that PT-splines are advantageous
over HB-splines for certain hierarchical T-meshes.

</details>


### [10] [Preconditioning of a hybridizable discontinuous Galerkin method for Biot's consolidation model](https://arxiv.org/abs/2508.12991)
*Esteban Henríquez,Jeonghun J. Lee,Sander Rhebergen*

Main category: math.NA

TL;DR: Parameter-robust preconditioner for HDG discretization of Biot's consolidation model with four-field formulation, working for both full and reduced (statically condensed) systems.


<details>
  <summary>Details</summary>
Motivation: To develop a preconditioner that maintains robustness across parameter variations for hybridizable discontinuous Galerkin methods applied to Biot's consolidation problems, enabling efficient solution of both full and reduced systems.

Method: Developed a parameter-robust preconditioner for four-field Biot's model using HDG discretization, then applied a framework from previous work to show robustness extends to the statically condensed reduced system.

Result: Numerical examples in 2D and 3D demonstrate the preconditioner's parameter-robustness for both full and reduced HDG discretizations of Biot's consolidation model.

Conclusion: The proposed preconditioner is effective and parameter-robust for HDG discretizations of Biot's consolidation model, working successfully for both the full system and the statically condensed reduced system across various parameter regimes.

Abstract: We present a parameter-robust preconditioner for a hybridizable discontinuous
Galerkin (HDG) discretization of a four-field formulation of Biot's
consolidation model. We first determine a parameter-robust preconditioner for
the full discretization. HDG methods, however, allow for static condensation.
We therefore apply the framework presented in our previous work
[arXiv:2503.05918, 2025] to show that a reduced form of the preconditioner is
also parameter-robust for the reduced HDG discretization. We verify the
parameter-robustness of the preconditioner through numerical examples in both
two and three dimensions.

</details>


### [11] [Some semi-decoupled algorithms with optimal convergence for a four-field linear thermo-poroelastic model](https://arxiv.org/abs/2508.13109)
*Ziliang Li,Mingchao Cai,Jingzhi Li,Qiang Liu*

Main category: math.NA

TL;DR: Three semi-decoupled algorithms for solving four-field thermo-poroelastic models with sequential and parallel approaches, all achieving unconditional stability and optimal convergence without stabilization techniques.


<details>
  <summary>Details</summary>
Motivation: To develop efficient computational methods for solving complex four-field thermo-poroelastic models that avoid the computational burden of fully monolithic approaches while maintaining stability and accuracy.

Method: Proposed three algorithms: two sequential variants (differing in subproblem solving order) and one parallel approach. All start with monolithic solve at initial time step, then split into mixed linear elasticity and pressure-temperature reaction-diffusion subproblems for subsequent steps.

Result: All algorithms achieve unconditional stability, optimal convergence rates, and robustness across wide physical parameter ranges without requiring stabilization techniques or iterative procedures at each time step.

Conclusion: The semi-decoupled algorithms provide computationally efficient alternatives to fully monolithic solvers for thermo-poroelastic problems, maintaining theoretical guarantees while significantly reducing computational complexity.

Abstract: We propose three semi-decoupled algorithms for efficiently solving a
four-field thermo-poroelastic model. The first two algorithms adopt a
sequential strategy: at the initial time step, all variables are computed
simultaneously using a monolithic solver; thereafter, the system is split into
a mixed linear elasticity subproblem and a coupled pressure-temperature
reaction-diffusion subproblem. The two variants differ in the order in which
these subproblems are solved. To further improve computational efficiency, we
introduce a parallel semi-decoupled algorithm. In this approach, the four-field
system is solved monolithically only at the first time step, and the two
subproblems are then solved in parallel at subsequent time levels. All three
algorithms are free from stabilization techniques and do not require iterative
procedures at each time step. Rigorous analysis confirms their unconditional
stability, optimal convergence rates, and robustness under a wide range of
physical parameter settings. These theoretical results are further validated by
numerical experiments.

</details>


### [12] [A time-adaptive optimization approach for reconstructing immune response in a mathematical model of acute HIV infection using clinical data](https://arxiv.org/abs/2508.13123)
*L. Beilina,I. Gainova,G. Bocharov*

Main category: math.NA

TL;DR: Time-adaptive optimization method for reconstructing immune response function in HIV infection model using patient data and adaptive mesh refinement.


<details>
  <summary>Details</summary>
Motivation: To improve the reconstruction of time-dependent immune response function in acute HIV infection models using clinical patient data, addressing limitations of uniform time mesh approaches.

Method: Tikhonov's regularization with Lagrangian approach for parameter identification in ODE system, deriving optimality conditions and three posteriori error estimates to formulate time-adaptive optimization algorithm with local mesh refinement.

Result: Numerical experiments demonstrate effective reconstruction of immune response function during acute HIV phase, showing improvement over standard conjugate gradient method on uniform time mesh.

Conclusion: The proposed time-adaptive optimization approach successfully reconstructs patient-specific immune response functions and outperforms traditional uniform mesh methods for HIV infection modeling.

Abstract: The paper proposes a time-adaptive optimization approach for determining the
time-dependent immune response function in a mathematical model of acute HIV
infection, using clinical data from four untreated patients. We formulate the
problem as a parameter identification problem for an immune response system of
ODE which includes novel component integrated into the third equation of the
classical three-equation HIV model.
  Tikhonov's regularization method, Lagrangian approach, from which we derive
the optimality conditions, and a numerical scheme to solve the forward
  and adjoint problems, as well as parameter identification problem, are
presented.
  Three different a posteriori error estimates are derived and based on these
estimates, a time adaptive optimization algorithm is formulated. Numerical
experiments demonstrate the effectiveness of the proposed adaptive method in
reconstructing the immune response function during the acute phase of HIV
infection, using patient-specific clinical data. Computational results show
improvement of
  reconstruction of immune response function using the local
  time-adaptive mesh refinement method compared to the standard conjugate
gradient method applied on a uniform time mesh.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [13] [Subsolution theorem in weighted energy classes of $m$-subharmonic functions with given boundary value](https://arxiv.org/abs/2508.11821)
*Nguyen Van Phu*

Main category: math.AP

TL;DR: Existence of solutions for weighted complex m-Hessian equations with given boundary values when subsolutions exist in the specified class


<details>
  <summary>Details</summary>
Motivation: To generalize previous results on subsolution theorems for complex m-Hessian equations by extending to broader classes of boundary values

Method: Mathematical analysis of weighted complex m-Hessian equations, building upon previous work in χ-weighted classes with different boundary value conditions

Result: Established existence of solutions in class χ_m,χ(f,Ω) when subsolutions exist, generalizing previous results from narrower boundary value classes

Conclusion: Successfully extended the subsolution theorem to handle more general boundary values f ∈ χ_m(Ω)∩MSH_m(Ω), demonstrating broader applicability of the existence theory

Abstract: In this paper, we concern with the existence of solutions of the weighted
complex $m$-Hessian equation $-\chi(u)H_{m}(u)=\mu$ in the class
$\mathcal{E}_{m,\chi}(f,\Omega)$ if there exists subsolution in this class,
where the given boundary value $f\in\mathcal{E}_m(\Omega)\cap MSH_m(\Om).$ This
is a generalization of the result in the paper \cite{PDtaiwan} where we proved
that the subsolution theorem is true in the class
$\mathcal{E}_{m,\chi}(f,\Omega)$ in the case when the given boundary value
$f\in\mathcal{N}_m(\Omega)\cap MSH_m(\Om).$

</details>


### [14] [Well- and Ill-posedness of the Cauchy problem for derivative fractional nonlinear Schrödinger equations on the torus](https://arxiv.org/abs/2508.11866)
*Takamori Kato,Toshiki Kondo,Mamoru Okamoto*

Main category: math.AP

TL;DR: The paper extends well-posedness criteria from semi-linear Schrödinger equations to derivative fractional Schrödinger equations on the torus, using modified energy methods instead of gauge transformations.


<details>
  <summary>Details</summary>
Motivation: To establish necessary and sufficient conditions for well-posedness of derivative fractional Schrödinger equations, building on previous work for semi-linear Schrödinger equations.

Method: Modified energy method with inductive construction of correction terms for fractional Laplacian orders between 1 and 3/2. For ill-posedness, uses Cauchy-Riemann-type operator analysis.

Result: Proves that the necessary and sufficient condition on nonlinearity is identical to that for semi-linear Schrödinger equations, despite different technical approaches required.

Conclusion: Successfully extends well-posedness theory to derivative fractional Schrödinger equations using alternative methods when gauge transformations are unavailable.

Abstract: We consider the Cauchy problem for derivative fractional Schr\"odinger
equations (fNLS) on the torus $\mathbb T$. Recently, the second and third
authors established a necessary and sufficient condition on the nonlinearity
for well-posedness of semi-linear Schr\"odinger equations on $\mathbb T$. In
this paper, we extend this result to derivative fNLS. More precisely, we prove
that the necessary and sufficient condition on the nonlinearity is the same as
that for semi-linear Schr\"odinger equations. However, since we can not employ
a gauge transformation for derivative fNLS, we use the modified energy method
to prove well-posedness. We need to inductively construct correction terms for
the modified energy when the fractional Laplacian is of order between $1$ and
$\frac 32$. For the ill-posedness, we prove the non-existence of solutions to
the Cauchy problem by exploiting a Cauchy-Riemann-type operator that appears in
nonlinear interactions.

</details>


### [15] [Solving the Laplace Equation and Applications in Imaging](https://arxiv.org/abs/2508.11896)
*Arina Oberoi*

Main category: math.AP

TL;DR: Analytical and probabilistic methods for solving Laplace equation applied to imaging tasks like noise reduction and resolution enhancement.


<details>
  <summary>Details</summary>
Motivation: To bridge theoretical mathematical concepts of Laplace equation with practical imaging applications by exploring both analytical techniques and probabilistic approaches.

Method: Uses separation of variables, Poisson integral formula (analytical methods) and Brownian motion (probabilistic method) to solve Laplace equation.

Result: Develops mathematical framework connecting harmonic functions, mean value property, and maximum principle to practical imaging workflows.

Conclusion: Theoretical concepts from Laplace equation provide effective mathematical foundation for imaging applications including noise reduction, data interpolation, and resolution enhancement.

Abstract: This paper examines solutions to the Laplace equation using analytical
techniques, including separation of variables and the Poisson integral formula,
and probabilistic methods, such as Brownian motion. We address applications to
imaging, including noise reduction, data interpolation, and resolution
enhancement, as well as discuss theoretical connections between the Laplace
equation, specifically concepts such as harmonic functions, the mean value
property, and the maximum principle, to provide a mathematical framework for
practical implementation in imaging workflows.

</details>


### [16] [Stability threshold of Couette flow for Boussinesq equations in $\mathbb{R}^2$](https://arxiv.org/abs/2508.11908)
*Yubo Chen,Wendong Wang,Guoxu Yang*

Main category: math.AP

TL;DR: Establishes asymptotic stability threshold for Couette flow in 2D Boussinesq system on R², extending known periodic case results to whole space with threshold at most {1/3+, 2/3+}.


<details>
  <summary>Details</summary>
Motivation: To extend the stability threshold results for Couette flow from the periodic case (T_x × R_y) to the whole space (R²) under the 2D Boussinesq system, addressing horizontal frequency singularities and temperature equation challenges.

Method: Uses controlled low horizontal frequencies in Sobolev spaces for initial perturbations, introduces ⟨D_x⁻¹⟩ control to resolve frequency singularities and optimize integral indices, and develops modified multiplier M₃ to handle |D_x|^{1/3} derivative structure from temperature equation while managing nonlinear echo cascades.

Result: Proved that the asymptotic stability threshold for Couette flow is at most {1/3+, 2/3+} for initial perturbations with controlled low horizontal frequencies in Sobolev spaces, successfully extending periodic case results to whole space.

Conclusion: The paper successfully establishes the stability threshold for Couette flow in 2D Boussinesq system on R², with key innovations in handling horizontal frequency control and developing effective multipliers to address derivative structures from temperature equations.

Abstract: This paper establishes the asymptotic stability threshold for the Couette
flow $(y,0)$ under the 2D Boussinesq system in $\mathbb{R}^2$. It was proved
that for initial perturbations in Sobolev spaces with controlled low horizontal
frequencies, the stability threshold is at most $\left\{\frac{1}{3}+,
\frac{2}{3}+\right\}$, extending the known threshold results from the periodic
case $\mathbb{T}_x \times \mathbb{R}_y$ to the whole space. The core
innovations are twofold: First, the $\langle D_x^{-1} \rangle$ control on the
initial data simultaneously resolves horizontal frequency singularities and
optimizes integral indices when applying Young's convolution inequality.
Second, we develop a modified multiplier $\mathcal{M}_3$ that effectively
absorbs the $|D_x|^{1/3}$ derivative structure induced by the temperature
equation while handling nonlinear echo cascades.

</details>


### [17] [Decay estimates of wave equations in un-isotropic media](https://arxiv.org/abs/2508.12049)
*Sergiu Klainerman,Xuecheng Wang*

Main category: math.AP

TL;DR: Decay estimates for non-isotropic wave equations based on scaling commutation properties, with applications to small data global regularity for cubic semilinear systems in 3D.


<details>
  <summary>Details</summary>
Motivation: To develop decay estimates that depend only on commutation properties with scaling vector fields, enabling simpler proofs for global regularity in non-isotropic wave systems.

Method: Proving decay estimates for non-isotropic linear wave equation systems by leveraging their commutation properties with the scaling vector field.

Result: Obtained decay estimates that lead to two surprisingly simple proofs for small data global regularity results in cubic semilinear nonlinear wave systems in R^(1+3).

Conclusion: The techniques developed are potentially relevant for addressing the more challenging case of biaxial refraction in crystal optics.

Abstract: We prove decay estimates for solutions to non-isotropic linear systems of
wave equations. The defining feature of these estimates is that they depend
only on the commutation properties of the system with the scaling vector field.
As application we give two surprisingly simple proofs for small data global
regularity results non-isotropic systems of wave equations in
$\mathbb{R}^{1+3}$ with cubic semilinear nonlinearities. We hope that the
techniques presented here are relevant for the more difficult and important
case of biaxial refraction in crystal optics.

</details>


### [18] [Solvability of Euler equations in the fractional Sobolev spaces in a bounded smooth domain](https://arxiv.org/abs/2508.12130)
*Feng Li*

Main category: math.AP

TL;DR: Well-posedness of Euler equations in fractional Sobolev spaces on bounded domains, extending classical results from integer to fractional spaces.


<details>
  <summary>Details</summary>
Motivation: Euler equations are fundamental in fluid dynamics but classical well-posedness results are limited to integer Sobolev spaces. This research extends the analysis to fractional Sobolev spaces to provide a more comprehensive understanding.

Method: Used energy method for fractional Hilbert-Sobolev spaces, and characteristic method with elliptic estimates for general fractional Sobolev spaces to obtain a priori estimates.

Result: Established solvability of Euler equations in fractional Sobolev spaces, with global existence in 2D and local existence in 3D, similar to classical integer space results.

Conclusion: The study successfully extends the well-posedness theory of Euler equations from integer to fractional Sobolev spaces, maintaining the same temporal behavior (global in 2D, local in 3D) as the classical case.

Abstract: Euler equations are the basic system in fluid dynamics describing the motion
of incompressible and inviscid ideal fluids. For a bounded smooth domain
$\Omega$ in $\mathbb{R}^n$. The well-posedness of Euler equations is well-known
in Sobolev spaces $W^{k,p}(\Omega)$ with the integer $k>\frac{n}{p}+1,\,
1<p<\infty$. In this article, we study the well-posedness of Euler equations in
fractional Sobolev spaces on a bounded smooth domain. We first give a priori
estimates of Euler equations in fractional Hilbert-Sobolev spaces by using the
energy method. For the general case of fractional Sobolev spaces, we use the
characteristic method together with elliptic estimates to give similar
estimates. Finally, using the a priori estimate obtained we give solvability of
Euler equations in fractional Sobolev spaces. Similar to the classical case,
our result is global in time in the case of two dimensions and local in the
three dimensions.

</details>


### [19] [Hölder extension for fractional Laplacian](https://arxiv.org/abs/2508.12134)
*Feng Li*

Main category: math.AP

TL;DR: Characterization of sharp boundary conditions for fractional harmonic extensions to be globally Hölder continuous


<details>
  <summary>Details</summary>
Motivation: To establish precise boundary conditions that ensure fractional harmonic extensions maintain Hölder regularity up to the boundary and remain globally Hölder continuous

Method: Based on estimates of fractional harmonic measure decay and uniform fractional fatness of the domain's complement

Result: Provides a characterization of the sharp boundary condition for global Hölder continuity

Conclusion: The paper successfully characterizes the necessary boundary conditions for fractional harmonic extensions to achieve global Hölder continuity through harmonic measure decay and domain complement properties

Abstract: In this note, we characterize the sharp boundary condition such that the
fractional harmonic extensions with H\"older regularity up to the boundary is
globally H\"older continuous. The proofs are based on estimates of fractional
harmonic measure decay and uniform fractional fatness of the complement of the
domain.

</details>


### [20] [A min-max variational approach to the existence of gravity water waves](https://arxiv.org/abs/2508.12159)
*Dennis Kriventsov,Georg S. Weiss*

Main category: math.AP

TL;DR: Existence of gravity water waves proven using mountain pass theorem on singular perturbation of Alt-Caffarelli functional, working entirely in physical coordinates without requiring connected air phase or symmetry assumptions.


<details>
  <summary>Details</summary>
Motivation: To establish the existence of gravity water waves through a variational approach that avoids traditional limitations like requiring connected air phase, symmetry, or monotonicity assumptions in the coordinate directions.

Method: Applied mountain pass theorem to a singular perturbation of the Alt-Caffarelli functional associated with 2D water wave equations, formulated entirely in physical coordinates.

Result: Successfully established existence of gravity water waves without requiring the air phase to be connected, and without relying on symmetry or monotonicity in x or y directions.

Conclusion: The framework provides both a variational approach for fluid equilibrium problems and enables construction of min-max solutions to Bernoulli-type free boundary problems.

Abstract: We establish the existence of gravity water waves by applying a mountain pass
theorem to a singular perturbation of the Alt-Caffarelli functional associated
with the two-dimensional water wave equations. Our approach is formulated
entirely in physical coordinates and does not require the air phase to be
connected, nor does it rely on symmetry or monotonicity in the $x$ or $y$
directions. The framework presented allows for both a variational approach to a
variety of fluid equilibrium problems and for construction of min-max solutions
to Bernoulli-type free boundary problems.

</details>


### [21] [Positive Solutions to the Lane-Emden Type Equation on the Upper Half Space Under Nonlinear Boundary Condition](https://arxiv.org/abs/2508.12218)
*Azam Nouri*

Main category: math.AP

TL;DR: Classification of all positive solutions to a semilinear elliptic PDE with nonlinear boundary condition on the upper half-space, showing they are all of specific radial form.


<details>
  <summary>Details</summary>
Motivation: To characterize all positive solutions of a semilinear elliptic equation with nonlinear Neumann boundary condition on the upper half-space, which arises in geometric analysis and conformal geometry problems.

Method: Mathematical analysis using techniques from elliptic PDE theory, maximum principles, and geometric methods to classify solutions by showing they must have the specific radial symmetry form.

Result: Proved that all positive solutions are exactly of the form u(x) = a(λ/(λ²+|x-y|²))^{(n-2)/2} with a = a(n), λ > 0, and y in the lower half-space (y_n < 0).

Conclusion: Complete classification of positive solutions to this boundary value problem, demonstrating that only radial solutions (with respect to appropriate points) exist, which has implications for understanding symmetry properties in elliptic PDEs with nonlinear boundary conditions.

Abstract: We prove that all positive solutions of $-\Delta u = u^{\frac{2n}{n-2}}$ on
the upper half space $\mathbb{R}^n_{+}$ (for $n \geq 3$) satisfying the
boundary condition $D_{x_n}u = -u^{\frac{n}{n-2}}$ are of the form $u(x) = a
\left( \frac{\lambda}{\lambda^2 + |x-y|^2} \right)^{\frac{n-2}{2}}$, where $a =
a(n)$, $\lambda > 0$, and $y = (y_1, \ldots, y_n)$ is a point in the lower
half-space with $y_n < 0$.

</details>


### [22] [Long time behavior of the Vlasov-Maxwell-Fokker-Planck system with a strong external magnetic field](https://arxiv.org/abs/2508.12231)
*Anh-Tuan Vu*

Main category: math.AP

TL;DR: Analysis of plasma confinement using Vlasov-Maxwell-Fokker-Planck system under strong magnetic fields, deriving reduced 2D spatial model with rigorous mathematical justification.


<details>
  <summary>Details</summary>
Motivation: To understand long-term plasma behavior under strong magnetic confinement, which is crucial for fusion energy applications and plasma physics research.

Method: Formal derivation of asymptotically reduced model from Vlasov-Maxwell-Fokker-Planck system, constraint elimination in 3D, analysis in 2D spatial/3D velocity dimensions using modulated energy method.

Result: Successfully derived well-posed asymptotic model that defines a proper dynamical system, with rigorous mathematical justification of the formally derived system.

Conclusion: The reduced 2D spatial model provides a mathematically sound framework for studying plasma confinement under strong magnetic fields, validated through energy-based proof techniques.

Abstract: The subject matter of this paper concerns the magnetic confinement of plasma.
We investigate the long time behavior of the Vlasov-Maxwell-Fokker-Planck
system under the effect of a strong external magnetic field. We first formally
derive an asymptotically reduced model. In three space dimensions, a constraint
occurs along the parallel direction to the magnetic field. To eliminate the
corresponding Lagrange multiplier, we then study the
Vlasov-Maxwell-Fokker-Planck system in two spatial dimensions and three
velocity dimensions. In this setting, we show that the obtained asymptotic
model defines a well-posed dynamical system, and we provide a rigorous
mathematical justification of the formally derived system. Our proofs rely on
the modulated energy method.

</details>


### [23] [Partial regularity of suitable weak solutions to the incompressible magnetohydrodynamic equations](https://arxiv.org/abs/2508.12317)
*Mengyao Ding,Wenwen Huo,Chao Zhang*

Main category: math.AP

TL;DR: Regularity theory for MHD equations with external forces using scaling analysis, extending Navier-Stokes techniques to prove singular points have zero 1D parabolic Hausdorff measure.


<details>
  <summary>Details</summary>
Motivation: To establish a regularity theory for magnetohydrodynamics equations with external forces by extending existing Navier-Stokes techniques to handle the MHD coupling.

Method: Utilizes scaling analysis, linearized approximations, and monotonicity property of harmonic functions to construct iterative sequences that capture scaling properties.

Result: Successfully demonstrates that the one dimensional parabolic Hausdorff measure of possible singular points for suitable weak solutions is zero.

Conclusion: The paper extends Navier-Stokes regularity techniques to MHD equations, providing a framework for analyzing singularities and establishing important regularity properties through scaling analysis.

Abstract: This paper establishes a regularity theory for the magnetohydrodynamics (MHD)
equations with external forces through scaling analysis. Inspired by the
existing methodology, we utilize linearized approximations and the monotonicity
property of harmonic functions to construct iterative sequences capturing
scaling properties. This work successfully extends Navier-Stokes techniques to
MHD coupling and demonstrates that the one dimensional parabolic Hausdorff
measure of the possible singular points for the suitable weak solutions is
zero.

</details>


### [24] [Dielectric scattering resonances for high-refractive resonators with cubic nonlinearity](https://arxiv.org/abs/2508.12364)
*Habib Ammari,Bowen Li*

Main category: math.AP

TL;DR: Mathematical framework for analyzing nonlinear dielectric resonances in high-index resonators with Kerr nonlinearities, showing symmetry-breaking bifurcations in 3D but not in 2D due to different scaling behaviors.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous mathematical foundations for understanding nonlinear wave scattering phenomena in high-index dielectric resonators with Kerr-type nonlinearities, particularly focusing on subwavelength regime behavior and symmetry properties.

Method: Developed mathematical framework for both 2D and 3D settings, proved existence of nonlinear dielectric resonances bifurcating from linear resonances, derived asymptotic expansions using high contrast parameter and normalization constant, analyzed symmetric dimer configurations.

Result: Proved existence of nonlinear resonances in subwavelength regime, showed symmetric/antisymmetric profiles in dimer structures, demonstrated symmetry-breaking bifurcation in 3D with mode hybridization creating asymmetric states, proved no symmetry-breaking in 2D due to logarithmic singularity effects.

Conclusion: The work provides rigorous mathematical foundation for nonlinear dielectric resonances, revealing fundamental dimensional differences in symmetry-breaking behavior between 2D and 3D systems, with important implications for designing nonlinear photonic devices and understanding wave-matter interactions in resonant structures.

Abstract: This work establishes a rigorous mathematical framework for the analysis of
nonlinear dielectric resonances in wave scattering by high-index resonators
with Kerr-type nonlinearities. We consider both two- and three-dimensional
settings and prove the existence of nonlinear dielectric resonances in the
subwavelength regime, bifurcating from the zero solution at the corresponding
linear resonances. Furthermore, we derive asymptotic expansions for the
nonlinear resonances and states in terms of the high contrast parameter $\tau$
and the normalization constant. For a symmetric dimer of resonators, these
small-amplitude nonlinear resonant states exhibit either symmetric or
antisymmetric profiles. In three dimensions, under conditions valid in the
dilute regime, we prove that as the field amplitude increases, mode
hybridization induces a symmetry-breaking bifurcation along the principal
symmetric solution branch at a critical amplitude. This bifurcation gives rise
to two asymmetric resonant states, each localized on one of the particles in
the dimer. Remarkably, in two dimensions, we show that no such
symmetry-breaking bifurcation exists along the principal solution branches,
owing to the distinct scaling behavior of the principal nonlinear subwavelength
resonance arising from the logarithmic singularity.

</details>


### [25] [Prey-taxis VS a Shortwave External Signal in Multiple Dimensions](https://arxiv.org/abs/2508.12432)
*Andrey Morgulis,Karrar Malal*

Main category: math.AP

TL;DR: Analysis of predator-prey community model with prey-taxis and external signal response using Patlak-Keller-Segel law, with complete asymptotic expansions for short-wave solutions.


<details>
  <summary>Details</summary>
Motivation: To study predator-prey dynamics where predators respond to prey density gradients and external environmental signals, extending previous work to multiple dimensions and non-traveling wave forms.

Method: Employed Patlak-Keller-Segel law for predator responses to both prey density gradients and external signals. Constructed complete asymptotic expansions for short-wave solutions, generalizing prior results to multiple dimensions and removing traveling wave assumptions.

Result: Developed complete asymptotic expansions for short-wave solutions in multiple dimensions, providing a more general framework than previous one-dimensional traveling wave approaches.

Conclusion: The model successfully generalizes predator-prey taxis dynamics to handle multi-dimensional scenarios and non-traveling wave forms, with applications to stability analysis using Kapitza's theory for external signal effects.

Abstract: We consider a model of the predator--prey community with prey-taxis. By that
we mean the capability of the predators to get moving in a certain direction on
the macroscopic level in response to the prey density gradients. Additionally,
we suppose the same kind of sensitivity with respect to one more signal, called
external, the production of which goes on independently of the community state.
Such a signal can be due to the spatiotemporal inhomogeneity of the environment
that results from the natural or artificial reasons. The model employs the
Patlak--Keller--Segel law for responses to both ones. We assume that the
external signal takes a general short-wave form, and we construct the complete
asymptotic expansions of the short-wave solutions. This result generalizes the
prior one by Morgulis \& Malal (2025) in two respects. First, we have addressed
the case of multiple dimensions. Second, we have got rid of assuming the signal
and corresponding solutions to take the form of a traveling wave, that makes
our result novel even in one dimension. Further, we apply the short wave
asymptotic to studying the stability or instability imposed by the external
signal following Kapitza' theory for upside-down pendulum.

</details>


### [26] [Recovering asymptotics of potentials from the scattering of relativistic Schrödinger operators](https://arxiv.org/abs/2508.12463)
*Gunther Uhlmann,Yiran Wang*

Main category: math.AP

TL;DR: The paper studies stationary scattering for the fractional Laplacian operator with potential on R^3, proving that potential asymptotics can be recovered from scattering matrix data at fixed energy.


<details>
  <summary>Details</summary>
Motivation: To understand inverse scattering problems for fractional Laplacian operators with potentials, specifically determining whether potential asymptotics can be reconstructed from scattering data.

Method: Analysis of stationary scattering for (-Δ)^(1/2) + V(x) on R^3 using poly-homogeneous potentials that decay at infinity, employing mathematical scattering theory techniques.

Result: Proved that the asymptotic behavior of poly-homogeneous potentials can be completely recovered from the scattering matrix at a fixed energy level.

Conclusion: The scattering matrix at a single energy contains sufficient information to reconstruct the asymptotic structure of decaying poly-homogeneous potentials for fractional Laplacian operators in three dimensions.

Abstract: We study the stationary scattering for $(-\Delta)^{\frac 12} + V(x)$ on
$\mathbb{R}^3$. For poly-homogeneous potentials decaying at infinity, we prove
that the asymptotics of the potential can be recovered from the scattering
matrix at a fixed energy.

</details>


### [27] [Spherically symmetric collapsing solution in the form of shadow wave](https://arxiv.org/abs/2508.12492)
*Marko Nedeljkov,Sanja Ružičić*

Main category: math.AP

TL;DR: Existence of stable shadow wave solutions with unbounded density at origin for isothermal Euler-Poisson system with density-dependent viscosity, extended to vanishing pressure case.


<details>
  <summary>Details</summary>
Motivation: To model collapse of self-gravitating Newtonian stars and analyze stable solutions with singular density profiles.

Method: Added density-dependent viscosity term to momentum equation in isothermal Euler-Poisson system and proved existence of stable shadow wave solutions.

Result: Demonstrated existence of stable shadow wave solutions with unbounded density at the origin.

Conclusion: The approach successfully extends to vanishing pressure case, providing stable solutions for gravitational collapse modeling.

Abstract: This paper deals with isothermal Euler-Poisson system which is used to model
collapse of self-gravitating Newtonian star. Density dependent viscosity term
is added on the right-hand side of momentum equation and it has been proved
that there exists stable shadow wave solution with unbounded density at the
origin. This results is extended to the vanishing pressure case.

</details>


### [28] [Nonlinear nonlocal equations in Reifenberg flat domains](https://arxiv.org/abs/2508.12595)
*Sun-Sig Byun,Kyeongbae Kim,Kyeong Song*

Main category: math.AP

TL;DR: Boundary regularity analysis for fractional p-Laplace equations on non-Lipschitz domains under Reifenberg flatness conditions


<details>
  <summary>Details</summary>
Motivation: To extend boundary regularity results for fractional p-Laplace equations to more general non-smooth domains beyond the Lipschitz category

Method: Using Reifenberg flatness assumptions on the domain boundary to establish fine boundary regularity properties

Result: New boundary regularity results for solutions and their gradients near the boundary, even in the linear case

Conclusion: The approach successfully extends boundary regularity theory to more general domain geometries using Reifenberg flatness conditions

Abstract: We consider nonhomogeneous fractional $p$-Laplace equations defined on a
bounded nonsmooth domain which goes beyond the Lipschitz category. Under a
sufficient flatness assumption on the domain in the sense of Reifenberg, we
establish several fine boundary regularity results for solutions, and their
gradient, near the boundary. To the best of our knowledge, each of our results
is new even in the linear case.

</details>


### [29] [Gradient estimates for the insulated conductivity problem with partially flat inclusions](https://arxiv.org/abs/2508.12700)
*Hongjie Dong,Zhuolun Yang,Hanye Zhu*

Main category: math.AP

TL;DR: Study shows gradient of solutions does not blow up for partially flat inclusions in insulated conductivity problems, unlike strictly convex inclusions where blow-up occurs.


<details>
  <summary>Details</summary>
Motivation: Previous research showed gradient blow-up occurs as distance between strictly convex inclusions approaches zero, but it was unknown if this phenomenon persists for partially flat inclusions.

Method: Analysis of insulated conductivity problem with inclusions embedded in bounded domains, comparing behavior of strictly convex vs partially flat inclusions under uniform background gradient fields.

Result: When inclusions are partially flat, the gradient of solutions does not blow up regardless of uniform background fields, contrasting with the blow-up observed for strictly convex inclusions.

Conclusion: The geometry of inclusions (partially flat vs strictly convex) significantly affects gradient behavior in insulated conductivity problems, with flat surfaces preventing blow-up phenomena.

Abstract: We study the insulated conductivity problem with inclusions embedded in a
bounded domain in $\mathbb{R}^n$. It was known that in the setting of strictly
convex inclusions, the gradient of solutions may blow up as the distance
between inclusions approaches 0. The optimal blow-up rate was proved in [10]
and was achieved in the presence of a uniform background gradient field. In
this paper, we demonstrate that when the inclusions are partially flat, the
gradient of solutions does not blow up under any uniform background fields.

</details>


### [30] [The new observations about the parameter-dependent Schrödinger-Poisson system](https://arxiv.org/abs/2508.12732)
*Chen Huang,Sihua Liang,Lei Ma*

Main category: math.AP

TL;DR: Existence of solutions for Schrodinger-Poisson systems with different potential types - positive radial and coercive sign-changing potentials, using mountain pass theorem and Morse theory with local linking.


<details>
  <summary>Details</summary>
Motivation: Study existence of solutions for Schrodinger-Poisson systems with different potential types, particularly addressing the challenging case where the Schrodinger operator is indefinite due to sign-changing potentials.

Method: Used mountain pass theorem for positive radial potentials, and local linking argument with Morse theory for coercive sign-changing potentials. Developed new observations for Poisson equation solutions.

Result: Proved existence of nontrivial solutions for both cases and showed asymptotical behavior results. Only required super-linear growth condition at origin for f, which is a weaker assumption than previous works.

Conclusion: Successfully established existence results for Schrodinger-Poisson systems with different potential types using novel methodologies that can be adapted to study related problems.

Abstract: In this paper, we study the existence results of solutions for the following
Schr\"{o}dinger-Poisson system involving different potentials:
  \begin{equation*}
  \begin{cases}
  -\Delta u+V(x)u-\lambda \phi u=f(u)&\quad\text{in}~\mathbb R^3,
  -\Delta\phi=u^2&\quad\text{in}~\mathbb R^3.
  \end{cases} \end{equation*}
  We first consider the case that the potential $V$ is positive and radial so
that the mountain pass theorem could be implied. The other case is that the
potential $V$ is coercive and sign-changing, which means that the
Schr\"{o}dinger operator $-\Delta +V$ is allowed to be indefinite. To deal with
this more difficult case, by a local linking argument and Morse theory, the
system has a nontrivial solution. Furthermore, we also show the asymptotical
behavior result of this solution. Additionally, the proofs rely on new
observations regarding the solutions of the Poisson equation. As a main novelty
with respect to corresponding results in \cite{MR4527586,MR3148130,MR2810583},
we only assume that $f$ satisfies the super-linear growth condition at the
origin. We believe that the methodology developed here can be adapted to study
related problems concerning the existence of solutions for
Schr\"{o}dinger-Poisson system.

</details>


### [31] [Right and Wrong Ansätze for Nonlinear Waves in Stochastic PDEs](https://arxiv.org/abs/2508.12786)
*C. H. S. Hamster*

Main category: math.AP

TL;DR: The paper investigates the validity of using deterministic travelling waves multiplied by stochastic exponents as solutions for stochastic reaction-diffusion equations, concluding this approach only works for NLS-type equations in Stratonovich interpretation.


<details>
  <summary>Details</summary>
Motivation: To examine the widespread practice in literature of using deterministic travelling waves with stochastic exponents as explicit solutions for stochastic reaction-diffusion equations.

Method: The author investigates the mathematical validity of the approach by analyzing whether multiplying deterministic travelling waves with stochastic exponents produces valid solutions across different equation types and interpretations.

Result: The approach is found to be generally invalid and only works specifically for Nonlinear Schrödinger (NLS)-type equations when using the Stratonovich interpretation of stochastic calculus.

Conclusion: The common practice of using deterministic travelling waves with stochastic exponents is not a generally valid solution method for stochastic reaction-diffusion equations, with limited applicability only to specific equation types and interpretations.

Abstract: I investigate the possibility that explicit solutions of stochastic
reaction-diffusion equations can be found by multiplying the deterministic
travelling waves with a stochastic exponent. This approach has become
widespread in the literature in recent years. I will conclude that this
approach is, in general, not a valid Ansatz and only works in the case of
NLS-type equations in the Stratonovich interpretation.

</details>


### [32] [Well-posedness and ill-posedness of the primitive equations with fractional horizontal dissipation](https://arxiv.org/abs/2508.12883)
*Elie Abdo,Quyuan Lin,Changhui Tan*

Main category: math.AP

TL;DR: Study of 2D incompressible primitive equations with fractional horizontal dissipation, identifying critical transition at α=1 between well-posedness and ill-posedness, with global well-posedness achieved for α≥6/5.


<details>
  <summary>Details</summary>
Motivation: The primitive equations are fundamental in geophysical fluid dynamics, but while viscous versions are globally well-posed, inviscid counterparts are ill-posed. This paper aims to understand the transition between these states with fractional dissipation.

Method: Analysis of two-dimensional incompressible primitive equations with fractional horizontal dissipation, examining critical dissipation exponent α=1 and establishing mathematical framework to quantify the transition between stability regimes.

Result: Identified sharp transition at critical dissipation exponent α=1, where the balance between initial data size and viscosity coefficient determines well-posedness. Established global well-posedness for sufficient dissipation (α≥6/5).

Conclusion: The study provides precise quantification of horizontal dissipation needed for viscous regularity, revealing a delicate dependence on initial conditions and viscosity at the critical threshold, with clear dissipation requirements for global stability.

Abstract: The primitive equations (PE) are a fundamental model in geophysical fluid
dynamics. While the viscous PE are globally well-posed, their inviscid
counterparts are known to be ill-posed.
  In this paper, we study the two-dimensional incompressible PE with fractional
horizontal dissipation. We identify a sharp transition between local
well-posedness and ill-posedness at the critical dissipation exponent $\alpha =
1$. In the critical regime, this dichotomy exhibits a new phenomenon: the
transition depends delicately on the balance between the size of the initial
data and the viscosity coefficient. Our results precisely quantify the
horizontal dissipation required to transition from inviscid instability to
viscous regularity. We also establish a global well-posedness theory to the
fractional PE, with sufficient dissipation $\alpha\geq\frac65$.

</details>


### [33] [Existence and Uniqueness of Solutions for Steady Triple-Deck Equations](https://arxiv.org/abs/2508.12965)
*Ming Dong,Chao Wang,Qin Wu,Zhifei Zhang*

Main category: math.AP

TL;DR: First rigorous proof of existence and uniqueness for steady triple-deck equations, overcoming Airy equation degeneracy at zero frequency using Bessel function zeros and elliptic multipliers.


<details>
  <summary>Details</summary>
Motivation: Triple-deck structures in boundary-layer flows have been studied asymptotically and numerically, but lack rigorous mathematical foundations. Previous research focused on derivations and solutions without establishing formal existence and uniqueness proofs.

Method: Reduced steady triple-deck equations to Airy equation via Fourier transformation. Overcame degeneracy at zero frequency by analyzing Airy function structure and using Bessel function zero distribution. Developed higher-frequency estimates and modified elliptic multipliers for uniform solution estimates.

Result: Successfully established the existence and uniqueness of solutions to steady triple-deck equations, providing the first rigorous mathematical foundation for this important boundary-layer flow problem.

Conclusion: The paper provides a complete mathematical theory for triple-deck equations, resolving the long-standing degeneracy problem at zero frequency and opening avenues for further rigorous analysis of boundary-layer perturbation problems.

Abstract: Triple-deck structures arise in boundary-layer flows when small localized
wall perturbations induce moderate mean-flow distortion. Most existing studies
in this field focus on the derivations of the asymptotic and numerical
solutions of this system, while rigorous mathematical results remain scarce. In
this paper, we establish, for the first time, the existence and uniqueness of
the solutions to the steady triple-deck equations. The steady triple-deck
equations can be reduced to an Airy equation with frequency as a parameter via
Fourier transformation. The main difficulty is that the Airy equation
degenerates at zero frequency, hindering uniform estimates of the solution with
respect to the frequency parameter. A key contribution is that we find a subtle
function involving the distribution of zeros of the Bessel function to overcome
the degeneracy by analyzing the structure of the Airy function. Additionally,
we derive a higher-frequency estimate and modify an elliptic multiplier to
obtain uniform estimates of the solution.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [34] [Hyperparameter Optimization in the Estimation of PDE and Delay-PDE models from data](https://arxiv.org/abs/2508.12715)
*Oliver Mai,Tim W. Kroll,Uwe Thiele,Oliver Kamps*

Main category: physics.comp-ph

TL;DR: Improved method for estimating PDEs and delay PDEs from data using Bayesian optimization and BIC for automatic hyperparameter selection, with time integration for increased robustness.


<details>
  <summary>Details</summary>
Motivation: To develop a more robust and automated approach for estimating partial differential equations from data, particularly handling complex cases like time-delay systems and improving model scope.

Method: Combines Bayesian optimization and Bayesian information criterion to automatically find optimal hyperparameters, integrates time integration into model estimation, and handles both standard PDEs and delay PDEs.

Result: Method demonstrates increased robustness and predictive capability across various synthetic benchmark problems including Allen-Cahn, Cahn-Hilliard, and reaction-diffusion systems with/without time-delay.

Conclusion: The approach successfully expands modeling scope through automated hyperparameter optimization and time integration, providing robust estimation for complex physical systems including time-delay PDEs.

Abstract: We propose an improved method for estimating partial differential equations
and delay partial differential equations from data, using Bayesian optimization
and the Bayesian information criterion to automatically find suitable
hyperparameters for the method itself or for the equations (such as a
time-delay). We show that combining time integration into an established model
estimation method increases robustness and yields predictive models. Allowing
hyperparameters to be optimized as part of the model estimation results in a
wider modelling scope. We demonstrate the method's performance on a number of
synthetic benchmark problems of different complexity, representing different
classes of physical behaviour. This includes the Allen-Cahn and Cahn-Hilliard
models, as well as different reaction-diffusion systems without and with
time-delay.

</details>


### [35] [Rapid Variable Resolution Particle Initialization for Complex Geometries](https://arxiv.org/abs/2508.12835)
*Navaneet Villodi,Prabhu Ramachandran*

Main category: physics.comp-ph

TL;DR: A fast and robust particle initialization method for SPH that achieves adaptive resolution, handles complex boundaries, and generates well-packed distributions efficiently using standard SPH components.


<details>
  <summary>Details</summary>
Motivation: Existing particle initialization techniques struggle with adaptive resolution, intricate boundaries, and efficient generation of well-packed distributions both inside and outside boundaries for meshless methods like SPH.

Method: Uses standard SPH building blocks to enable simultaneous initialization of fluid and solid regions, supports arbitrary geometries, and achieves quasi-uniform particle arrangements without complex procedures like surface bonding.

Result: The method produces particle distributions with good boundary conformity, low spatial disorder, and minimal density variation in both 2D and 3D, with significantly reduced computational cost compared to existing approaches.

Conclusion: This work enables automated particle initialization for accurate flow modeling in and around bodies using meshless methods, particularly SPH, by providing a fast, robust initialization solution.

Abstract: The accuracy of meshless methods like Smoothed Particle Hydrodynamics (SPH)
is highly dependent on the quality of the particle distribution. Existing
particle initialization techniques often struggle to simultaneously achieve
adaptive resolution, handle intricate boundaries, and efficiently generate
well-packed distributions inside and outside a boundary. This work presents a
fast and robust particle initialization method that achieves these goals using
standard SPH building blocks. Our approach enables simultaneous initialization
of fluid and solid regions, supports arbitrary geometries, and achieves
high-quality, quasi-uniform particle arrangements without complex procedures
like surface bonding. Extensive results in both 2D and 3D demonstrate that the
obtained particle distributions exhibit good boundary conformity, low spatial
disorder, and minimal density variation, all with significantly reduced
computational cost compared to existing approaches. This work paves the way for
automated particle initialization to accurately model flow in and around bodies
with meshless methods, particularly with SPH.

</details>


### [36] [Time Reversible Integration of the Landau-Lifshitz-Gilbert Equation](https://arxiv.org/abs/2508.12994)
*Moritz Sallermann,Thorsteinn Freygardsson,Sergei Egorov,Pavel Bessarab,Grzegorz Kwiatkowski,Hannes Jónsson*

Main category: physics.comp-ph

TL;DR: Time-reversible numerical integration method for Landau-Lifshitz Gilbert equation using second order Suzuki-Trotter decomposition outperforms predictor-corrector methods in time-reversibility while maintaining similar computational cost.


<details>
  <summary>Details</summary>
Motivation: To develop a more accurate time-reversible integration method for the deterministic Landau-Lifshitz Gilbert equation, which is useful for applications like calculating dynamical corrections to transition state theory.

Method: Second order Suzuki-Trotter decomposition for numerical integration, compared against commonly used second order predictor-corrector methods.

Result: The Suzuki-Trotter integrator demonstrated superior time-reversibility by several orders of magnitude compared to predictor-corrector methods, while requiring similar computational effort.

Conclusion: The Suzuki-Trotter decomposition provides a significantly better time-reversible integration approach for the Landau-Lifshitz Gilbert equation, making it particularly valuable for applications requiring backward time trajectory calculations.

Abstract: A method for time-reversible numerical integration of the deterministic
Landau-Lifshitz Gilbert equation by means of a second order Suzuki-Trotter
decomposition is presented and tested against commonly used second order
predictor-corrector methods. We find the time-reversibility of the
Suzuki-Trotter integrator to be superior by several orders of magnitude while
the computational effort is similar. Calculations of trajectories backwards in
time are useful, for example, when evaluating dynamical corrections to
transition state theory.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [37] [A Detailed Configuration Accounting for the Hot Plasma Bound-Free Opacity Calculation](https://arxiv.org/abs/2508.11815)
*Alina Nadezhkina,Mikhail Vronskiy*

Main category: physics.plasm-ph

TL;DR: Probabilistic method for calculating bound-free opacity that accounts for ionization threshold spread due to shell occupation fluctuations


<details>
  <summary>Details</summary>
Motivation: Average atom models show noticeable initial configuration effects on shell ionization thresholds, requiring better methods to account for configuration impacts in bound-free opacity calculations

Method: Probabilistic reformulation approach based on Fourier transform method adaptation for Detailed Configurations Accounting, accounting for ionization threshold spread from shell occupation number fluctuations

Result: Developed expressions for bound-free opacity coefficient that incorporate the spread of ionization thresholds

Conclusion: The probabilistic method successfully addresses the challenge of accounting for configuration impacts in bound-free opacity calculations by handling ionization threshold variations

Abstract: The calculation of the hot plasma bound-free opacity according to the average
atom models often leads to a noticeable effect of initial configuration on the
shell ionization threshold. For the related problem of taking into account the
impact of configurations while calculating bound-bound opacity, G. Hazak and Y.
Kurzweil developed a method within the Super Transition Arrays approach.
Fourier transform method is the adaptation of their method for a Detailed
Configurations Accounting. The bound--free opacity coefficient qualitative
behavior makes it somewhat difficult to construct a direct analogue of Fourier
transform method of Detailed Configurations Accounting for its calculation. We
use the probabilistic reformulation of the method to obtain the expressions for
the bound--free opacity coefficient that take into account the spread of
ionization thresholds due to the shell occupation numbers fluctuations.

</details>


### [38] [The Chapman-Enskog Divergence Problem in Plasma Transport: Structural Limitations and a Practical Regularization Approach](https://arxiv.org/abs/2508.12390)
*Justo Karell*

Main category: physics.plasm-ph

TL;DR: The paper identifies and addresses the 1/ν divergence problem in Chapman-Enskog transport coefficients, showing it's fundamental to the approach rather than a closure artifact, and proposes a phenomenological regularization method.


<details>
  <summary>Details</summary>
Motivation: To understand and resolve the known divergence problem in kinetic theory where transport coefficients diverge as 1/ν (inverse collision frequency) in the Chapman-Enskog expansion approach.

Method: Used Chapman-Enskog expansion with BGK collision operators, maximum entropy closure analysis, structural arguments for general collision operators, and proposed a phenomenological effective collision frequency ν_eff = ν√(1 + Kn²) based on gradient-driven decorrelation.

Result: Found that both Chapman-Enskog and maximum entropy closure yield identical κ = 5nT/(2mν) with 1/ν divergence, confirmed this extends to general local collision operators, and showed the proposed regularization maintains conservation laws while yielding finite transport coefficients across all collisionality regimes.

Conclusion: The 1/ν divergence is fundamental to Chapman-Enskog approach, not a closure artifact, and the proposed phenomenological regularization provides a mathematically consistent solution that compares well with exact solutions of bounded kinetic models.

Abstract: We calculate transport coefficients from the Chapman--Enskog expansion with
BGK collision operators, obtaining exactly $\kappa = \frac{5nT}{2m\nu}$, and
show that maximum entropy closure yields identical results when applied with
the same collision operator. Through structural arguments, we suggest that this
$1/\nu$ divergence extends to other local collision operators of the form
$\mathcal{L} = \nu\hat{L}$, making the divergence fundamental to the
Chapman--Enskog approach rather than a closure artifact. To address this
limitation, we propose a phenomenological effective collision frequency
$\nu_{\eff} = \nu\sqrt{1 + \Kn^2}$ motivated by gradient-driven decorrelation,
where $\Kn$ is the Knudsen number. We verify that this regularization maintains
conservation laws and thermodynamic consistency while yielding finite transport
coefficients across all collisionality regimes. Comparison with exact solutions
of a bounded kinetic model shows similar functional form, providing limited
validation of our approach. This work provides explicit calculation of a known
divergence problem in kinetic theory and offers one phenomenological
regularization method with transparent treatment of mathematical assumptions
versus physical approximations.

</details>


### [39] [A geometric approach to constructing quasi-isodynamic fields](https://arxiv.org/abs/2508.12820)
*G. G. Plunk,E. Rodríguez*

Main category: physics.plasm-ph

TL;DR: Reformulated near-axis theory for quasi-isodynamic stellarators using geometric inputs for better control and understanding of equilibrium space, including methods for axis construction and surface shaping control.


<details>
  <summary>Details</summary>
Motivation: To enable greater control over direct construction of quasi-isodynamic stellarator configurations and facilitate understanding of the space of such equilibria, overcoming previous limitations in parameter selection and optimization.

Method: Reformulated near-axis theory using geometric inputs, developed method to construct magnetic axis curves by solving Frenet-Serret equations, and created approach to control magnetic surface shaping at first order (plasma elongation).

Result: Successfully demonstrated the approach with a family of configurations having per-field-period axis helicity equal to one half, revealing an approximate scaling symmetry relating different field period numbers.

Conclusion: The reformulated theory provides a robust framework for studying different classes of quasi-isodynamic stellarators, including various axis helicities and topologies, and serves as a basis for future systematic surveys using higher-order near-axis theory.

Abstract: The near-axis theory for quasi-isodynamic stellarator equilibria is
reformulated in terms of geometric inputs, to allow greater control of the
``direct construction'' of quasi-isodynamic configurations, and to facilitate
understanding of the space of such equilibria. This includes a method to
construct suitable magnetic axis curves by solving Frenet-Serret equations, and
an approach to controlling magnetic surface shaping at first order (plasma
elongation), which previously has required careful parameter selection or
additional optimization steps. The approach is suitable for studying different
classes of quasi-isodynamic stellarators including different axis
``helicities'' and topologies (e.g. knotted solutions), and as the basis for
future systematic surveys using higher order near-axis theory. As an example
application, we explore a family of configurations with per-field-period axis
helicity equal to one half, demonstrating an approximate scaling symmetry
relating different field period numbers.

</details>


### [40] [Density and Particle Sourcing Optimization in a Helicon Plasma Source Prototype For Wakefield Accelerator Applications](https://arxiv.org/abs/2508.12929)
*Michael Zepp,Marcel Granetzny,Oliver Schmitz*

Main category: physics.plasm-ph

TL;DR: Helicon plasma density homogeneity improved by using dual antennas and optimizing neutral flow configuration, achieving 5% axial density deviation but still 20x above required specification.


<details>
  <summary>Details</summary>
Motivation: Helicon plasmas are being considered as plasma sources for wakefield accelerators that require strict density homogeneity, but current systems lack sufficient axial uniformity.

Method: Experimental study using various background neutral flow configurations with single and dual identical antennas in a 2m long plasma chamber with homogeneous magnetic field to optimize axial density profiles.

Result: Dual antennas expanded plasma axially and increased dependence on neutral flow. No background flow achieved 2x better homogeneity than flow configurations. Minimum axial density deviation was 5% through optimization.

Conclusion: While 5% deviation is still 20x above nominal requirements, the study established methods to further improve helicon plasma density homogeneity for wakefield accelerator applications.

Abstract: Helicon plasmas are being considered as plasma sources for wakefield
accelerators, subject to strict density requirements. We present various
mechanisms to increase axial density homogeneity in a helicon plasma for
implementation in such an accelerator. We consider various background neutral
flow configurations for helicons generated with first one antenna and then two
identical antennas in a 2 meter long, 52 mm diameter plasma chamber with
homogeneous magnetic field. In the case of a single antenna, the ionization
source rate and density profiles are not significantly influenced by the
background neutral flow. The use of a second antenna expands the plasma axially
along the device, and results in an increased dependence of the axial density
profile on the background neutral flow. We find an increase in axial
homogeneity by a factor of two when there is no background neutral flow
compared to when there is flow in either direction relative to the plasma. The
minimum axial density deviation accomplished by optimization of RF antenna and
neutral flow was 5%. This is still a factor of 20 above the nominal homogeneity
requirement, but means to further improve this have been established in this
study.

</details>


### [41] [Current sheet formation under radiative cooling](https://arxiv.org/abs/2508.13081)
*Simran Chowdhry,Nuno F. Loureiro*

Main category: physics.plasm-ph

TL;DR: Cooling accelerates X-point collapse along inflows but can arrest/reverse current sheet elongation in outflows, leading to shorter current sheets and higher reconnection rates than classical Sweet-Parker.


<details>
  <summary>Details</summary>
Motivation: To understand how optically thin radiative cooling affects magnetic reconnection and current sheet formation in X-point collapse scenarios.

Method: Developed a simple, analytically solvable MHD model of current sheet formation through X-point collapse under radiative cooling, modifying the radiatively-cooled Sweet-Parker model to allow varying current sheet length.

Result: Cooling accelerates collapse along inflows but can arrest/reverse elongation in outflows. When cooling dominates compressional heating, current sheets are shorter than system size with increased reconnection rates compared to classical Sweet-Parker.

Conclusion: The model provides groundwork for better theoretical understanding of magnetic reconnection in regimes dominated by optically thin radiative cooling.

Abstract: We present a simple, analytically solvable MHD model of current sheet
formation through X-point collapse under optically thin radiative cooling. Our
results show that cooling accelerates the collapse of the X-point along the
inflows, but strong cooling can arrest or even reverse the current sheet
elongation in the outflow direction. Hence, we detail a modification to the
radiatively-cooled Sweet-Parker model developed by Uzdensky & McKinney (2011)
to allow for varying current sheet length. The steady-state solution shows that
when radiative cooling dominates compressional heating, the current sheet
length is shorter than the system size, with an increased reconnection rate
compared to the classical Sweet-Parker rate. The model and subsequent results
lay out the groundwork for a more complete theoretical understanding of
magnetic reconnection in regimes dominated by optically thin radiative cooling.

</details>


### [42] [Eliminating Tokamak Disruptions with Feedback](https://arxiv.org/abs/2508.13105)
*H. R. Strauss*

Main category: physics.plasm-ph

TL;DR: RWTM disruptions can be prevented by keeping q=2 surface away from resistive wall and controlling current profile peaking through active feedback systems.


<details>
  <summary>Details</summary>
Motivation: To understand and prevent resistive wall tearing mode (RWTM) disruptions in tokamaks, which are a major cause of plasma instabilities.

Method: Analysis of DIII-D locked mode disruption database, simulations, and NSTX data to identify RWTM disruption criteria and test feedback stabilization.

Result: Two main criteria identified: q=2 surface proximity to resistive wall and current profile peaking caused by edge cooling. Feedback systems successfully stabilize RWTMs at high beta.

Conclusion: RWTM disruptions in ITER could potentially be prevented using existing resonant magnetic perturbation (RMP) coils with proper feedback control.

Abstract: Many disruptions are caused by resistive wall tearing modes (RWTM). A
database of DIII-D locked mode disruptions provides two main disruption
criteria, which are shown to be signatures of RWTMs. The first is that the q =
2 rational surface must be sufficiently close the resistive wall surrounding
the plasma to interact with it. If active feedback is used, this implies that
RWTMs can be prevented from causing major disruptions. This is demonstrated in
simulations. The second criterion is that the current profile is sufficiently
peaked. This is caused by edge cooling, such as by impurity radiation and
turbulence, which suppress edge current and temperature. This implies the
disruptions are not caused by neoclassical tearing modes (NTM), because the
bootstrap current is also suppressed. At high $\beta,$ resistive wall modes
(RWM) can be stabilized with feedback. Feedback also stabilizes high $\beta$
RWTMs, as shown in NSTX data and in simulations. These results suggest that
RWTM disruptions in ITER might be prevented using the resonant magnetic
perturbation (RMP) coils.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [43] [On computing and the complexity of computing higher-order $U$-statistics, exactly](https://arxiv.org/abs/2508.12627)
*Xingyu Chen,Ruiqi Zhang,Lin Liu*

Main category: stat.ML

TL;DR: New algorithm and Python package for efficient computation of higher-order U-statistics using decomposition to V-statistics and Einstein summation techniques, achieving significant runtime improvements.


<details>
  <summary>Details</summary>
Motivation: Higher-order U-statistics are computationally expensive and widely used in statistics, machine learning, and computer science, but their computational complexity has not been comprehensively studied, creating a need for more efficient computation methods.

Method: Developed a decomposition from m-th order U-statistics to linear combinations of V-statistics, leveraged Einstein summation techniques from computational mathematics and quantum computing, and used graph theory concepts (treewidth) to estimate time complexity.

Result: Created a new runtime-efficient algorithm for exactly computing general higher-order U-statistics, implemented as an open-source Python package called u-stats, which demonstrates impressive runtime performance compared to existing benchmarks in three statistical applications.

Conclusion: The research advances algorithmic development for U-statistics and provides a valuable tool for practitioners, making implementation of methods based on higher-order U-statistics more efficient and accessible.

Abstract: Higher-order $U$-statistics abound in fields such as statistics, machine
learning, and computer science, but are known to be highly time-consuming to
compute in practice. Despite their widespread appearance, a comprehensive study
of their computational complexity is surprisingly lacking. This paper aims to
fill that gap by presenting several results related to the computational aspect
of $U$-statistics. First, we derive a useful decomposition from an $m$-th order
$U$-statistic to a linear combination of $V$-statistics with orders not
exceeding $m$, which are generally more feasible to compute. Second, we explore
the connection between exactly computing $V$-statistics and Einstein summation,
a tool often used in computational mathematics, quantum computing, and quantum
information sciences for accelerating tensor computations. Third, we provide an
optimistic estimate of the time complexity for exactly computing
$U$-statistics, based on the treewidth of a particular graph associated with
the $U$-statistic kernel. The above ingredients lead to a new, much more
runtime-efficient algorithm of exactly computing general higher-order
$U$-statistics. We also wrap our new algorithm into an open-source Python
package called $\texttt{u-stats}$. We demonstrate via three statistical
applications that $\texttt{u-stats}$ achieves impressive runtime performance
compared to existing benchmarks. This paper aspires to achieve two goals: (1)
to capture the interest of researchers in both statistics and other related
areas further to advance the algorithmic development of $U$-statistics, and (2)
to offer the package $\texttt{u-stats}$ as a valuable tool for practitioners,
making the implementation of methods based on higher-order $U$-statistics a
more delightful experience.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [44] [A New Proof that the Numerical Range is a Complete 2-Spectral Set for Weighted Shift Matrices](https://arxiv.org/abs/2508.12768)
*Michel Crouzeix,Anne Greenbaum*

Main category: math.FA

TL;DR: Alternative proof that Daeshik Choi's matrix family satisfies Crouzeix's conjecture, plus proof of completely bounded version


<details>
  <summary>Details</summary>
Motivation: To provide an alternative proof approach for the established result that Choi's matrix family satisfies Crouzeix's conjecture, and extend this to prove the completely bounded version of the conjecture

Method: Alternative mathematical proof methodology building upon Daeshik Choi's original work on specific matrix families

Result: Successfully demonstrated that the matrix family satisfies both Crouzeix's conjecture and its completely bounded version

Conclusion: The paper provides additional validation of Crouzeix's conjecture for this matrix class and extends the result to the completely bounded case, strengthening the mathematical foundation

Abstract: In this paper we give an alternative proof that the family of matrices
studied by Daeshik Choi in A proof of Crouzeix's conjecture for a class of
matrices, Linear Algebra and its Applications, 438, no. 8 (2013), pp.
3247-3257, satisfy Crouzeix's conjecture. We also show that they satisfy the
completely bounded version of the conjecture.

</details>


### [45] [The Gaussian Minkowski problem for epigraphs of convex functions](https://arxiv.org/abs/2508.12028)
*Xiao Li,Deping Ye*

Main category: math.FA

TL;DR: A variational formula combining Gaussian volume and infimal convolution leads to new Borel measures and solves a Minkowski-type problem under mild conditions.


<details>
  <summary>Details</summary>
Motivation: To develop a mathematical framework connecting Gaussian volume of convex function epigraphs with infimal convolution perturbations, leading to new Borel measures and solving related Minkowski problems.

Method: Derived a variational formula combining Gaussian volume of convex function epigraphs and infimal convolution perturbations, resulting in Euclidean Gaussian moment measures on R^n and the unit sphere.

Result: Established the existence of a Borel measure on R^n (Euclidean Gaussian moment measure) and a Borel measure on S^{n-1}, and solved the newly posed Minkowski problem under mild natural conditions.

Conclusion: The variational approach successfully connects Gaussian geometry with convex analysis, providing new measures and solving the associated Minkowski problem with natural regularity conditions.

Abstract: A variational formula is derived by combining the Gaussian volume of the
epigraph of a convex function $\varphi$ and the perturbation of $\varphi$ via
the infimal convolution. This formula naturally leads to a Borel measure on
$\mathbb{R}^n$ and a Borel measure on the unit sphere $S^{n-1}$. The resulting
Borel measure on $\mathbb{R}^n$ will be called the Euclidean Gaussian moment
measure of the convex function $\varphi$, and the related Minkowski-type
problem will be studied. In particular, the newly posed Minkowski problem is
solved under some mild and natural conditions on the pre-given measure.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [46] [Load-Balanced Diffusion Monte Carlo Method with Lattice Regularization](https://arxiv.org/abs/2508.12033)
*Kousuke Nakano,Sandro Sorella,Michele Casula*

Main category: physics.chem-ph

TL;DR: A load-balanced Lattice Regularized Diffusion Monte Carlo (LRDMC) algorithm that eliminates the logarithmic load imbalance of conventional methods, achieving 98% parallel efficiency on 512 GPUs with 1.24x speedup.


<details>
  <summary>Details</summary>
Motivation: Conventional LRDMC suffers from load imbalance that grows logarithmically with walker count, reducing hardware utilization on modern parallel architectures.

Method: Developed a new LRDMC algorithm that inherently addresses load imbalance through improved synchronization and workload distribution techniques.

Result: Consistent results with conventional LRDMC on water-methane complex binding energy, while achieving 98% parallel efficiency on 512 GPUs with 51200 walkers and 1.24x speedup.

Conclusion: The load-balanced LRDMC algorithm enables highly efficient large-scale quantum Monte Carlo simulations on modern GPU supercomputers while maintaining accuracy.

Abstract: Ab initio quantum Monte Carlo (QMC) is a stochastic approach for solving the
many-body Schr\"odinger equation without resorting to one-body approximations.
QMC algorithms are readily parallelizable via ensembles of $N_w$ walkers,
making them well suited to large-scale high-performance computing. Among the
QMC techniques, Diffusion Monte Carlo (DMC) is widely regarded as the most
reliable, since it provides the projection onto the ground state of a given
Hamiltonian under the fixed-node approximation. One practical realization of
DMC is the Lattice Regularized Diffusion Monte Carlo (LRDMC) method, which
discretizes the Hamiltonian within the Green's Function Monte Carlo framework.
DMC methods - including LRDMC - employ the so-called branching technique to
stabilize walker weights and populations. At the branching step, walkers must
be synchronized globally; any imbalance in per-walker workload can leave CPU or
GPU cores idle, thereby degrading overall hardware utilization. The
conventional LRDMC algorithm intrinsically suffers from such load imbalance,
which grows as $\log(N_w)$, rendering it less efficient on modern parallel
architectures. In this work, we present an LRDMC algorithm that inherently
addresses the load imbalance issue and achieves significantly improved
weak-scaling parallel efficiency. Using the binding energy calculation of a
water-methane complex as a test case, we demonstrated that the conventional and
load-balanced LRDMC algorithms yield consistent results. Furthermore, by
utilizing the Leonardo supercomputer equipped with NVIDIA A100 GPUs, we
demonstrated that the load-balanced LRDMC algorithm can maintain extremely high
parallel efficiency ($\sim$98\%) up to 512 GPUs (corresponding to $N_{\rm w}=
51200$), together with a speedup of $\times~1.24$ if directly compared with the
conventional LRDMC algorithm with the same number of walkers.

</details>


### [47] [Quantum Many-Body Simulations of Catalytic Metal Surfaces](https://arxiv.org/abs/2508.13036)
*Changsu Cao,Hung Q. Pham,Zhen Guo,Yutan Zhang,Zigeng Huang,Xuelan Wen,Ji Chen,Dingshun Lv*

Main category: physics.chem-ph

TL;DR: FEMION is a quantum embedding framework that combines accurate many-body solvers with nonlocal screening to achieve chemical accuracy for catalytic systems where DFT fails, resolving long-standing challenges in heterogeneous catalysis.


<details>
  <summary>Details</summary>
Motivation: Existing methods like DFT lack accuracy for adsorption and reaction energetics at metal surfaces, while wavefunction-based theories are too computationally expensive for realistic catalytic systems.

Method: FEMION combines auxiliary-field quantum Monte Carlo for many-body effects at catalytic sites with global random phase approximation treatment of nonlocal screening, providing a scalable quantum embedding framework.

Result: Achieves chemical accuracy for CO adsorption preference and H2 desorption barrier on Cu(111) surface - problems where conventional methods have struggled for decades. Provides many-body bonding analysis revealing why DFT fails.

Conclusion: FEMION establishes a robust, systematically improvable framework for predictive first-principles modeling of complex catalytic systems, highlighting the critical role of electron correlation in surface energetics.

Abstract: Accurate quantum simulations of catalysis on metal surfaces are critical for
advancing energy and materials science. Yet most existing methods fall short:
density functional theory (DFT), although widely used for its computational
efficiency, often lacks the accuracy needed for adsorption and reaction
energetics at heterogeneous metal surfaces. Wavefunction-based theories, in
contrast, are more accurate in principle but remain prohibitively costly when
applied to realistic catalytic systems. Here we introduce FEMION (Fragment
Embedding for Metals and Insulators with Onsite and Nonlocal correlation), a
quantum embedding framework that resolves the long-standing challenge of
accurately describing partially filled electronic states in metals while
retaining accuracy for insulators. FEMION combines highly accurate solvers such
as auxiliary-field quantum Monte Carlo to capture many-body effects at
catalytic sites, together with a global random phase approximation treatment of
nonlocal screening, providing a scalable and systematically improvable
framework for accurate quantum simulations. We demonstrate chemical accuracy
for two long-standing challenges in heterogeneous catalysis: the preference
site of CO adsorption and the H2 desorption barrier on the Cu(111) surface,
where conventional methods have struggled for decades. Beyond achieving
quantitative accuracy, FEMION offers a many-body bonding analysis that reveals
why DFT fails to capture the CO adsorption preference, highlighting the
critical role of electron correlation in governing surface energetics. FEMION
thus establishes a robust route to predictive, first-principles modeling of
complex catalytic systems.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [48] [$α$-scaled strong convergence of stochastic theta method for stochastic differential equations driven by time-changed Lévy noise beyond Lipschitz continuity](https://arxiv.org/abs/2508.12909)
*Jingwei Chen*

Main category: math.PR

TL;DR: Strong convergence analysis of stochastic theta method for time-changed Lévy noise SDEs with local Lipschitz coefficients, establishing convergence order min{η_F,η_G,η_H,α/2}.


<details>
  <summary>Details</summary>
Motivation: To extend numerical analysis to stochastic differential equations driven by time-changed Lévy noise, which are prevalent in finance and biology applications but lack comprehensive convergence analysis.

Method: Developed an α-parametrized framework, investigated inverse subordinator properties, derived explicit moment bounds for exact solution with jump rate, analyzed stochastic theta method convergence.

Result: Proved strong convergence with order min{η_F,η_G,η_H,α/2}, establishing precise relationship between numerical accuracy and time-change mechanism.

Conclusion: Theoretical advancement extends existing results and facilitates applications in finance and biology where time-changed Lévy models are widely used.

Abstract: This paper develops an $\alpha$-parametrized framework for analyzing the
strong convergence of the stochastic theta (ST) method for stochastic
differential equations driven by time-changed L\'evy noise (TCSDEwLNs) with
time-space-dependent coefficients satisfying local Lipschitz conditions.
Properties of the inverse subordinator are investigated and explicit moment
bounds for the exact solution are derived with jump rate incorporated. The
analysis demonstrates that the ST method converges strongly with order of
$min\{\eta_{F},\eta_{G},\eta_{H},\alpha/2\}$, establishing a precise
relationship between numerical accuracy and the time-change mechanism. This
theoretical advancement extends existing results and would facilitate
applications in finance and biology where time-changed L\'evy models are
prevalent.

</details>


### [49] [The Leibenson process](https://arxiv.org/abs/2508.12979)
*Viorel Barbu,Sebastian Grube,Marco Rehmeier,Michael Röckner*

Main category: math.PR

TL;DR: The paper establishes the Leibenson equation as a nonlinear Fokker-Planck equation and proves it has a nonlinear Markov process counterpart, providing probabilistic representations of Barenblatt solutions through McKean-Vlasov SDEs.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between the Leibenson equation (generalizing porous media and p-Laplace equations) and stochastic processes by identifying its probabilistic counterpart and establishing strong solution properties despite degeneracy.

Method: The authors identify the Leibenson equation as a nonlinear Fokker-Planck equation and construct associated McKean-Vlasov SDEs with coefficients depending on solution's marginal densities and their derivatives. They prove existence of probabilistically strong solutions.

Result: Obtained probabilistic representation of Barenblatt solutions as one-dimensional marginal densities of unique solutions to McKean-Vlasov SDEs. Showed these solutions form a nonlinear Markov process (Leibenson process) and proved strong solution properties despite diffusion degeneracy and irregular drift.

Conclusion: The Leibenson equation has a well-defined nonlinear Markov process counterpart with strong probabilistic solutions, establishing a fundamental connection between this PDE class and stochastic processes even under challenging coefficient conditions.

Abstract: Consider the Leibenson equation \begin{equation*} \partial_t u = \Delta_p
u^q, \end{equation*} where $\Delta_p f = div(|\nabla f|^{p-2}\nabla f)$ for
$p>1$ and $q>0$, which is a simultaneous generalization of the porous media and
the $p$-Laplace equation. In this paper we identify the Leibenson equation as a
nonlinear Fokker--Planck equation and prove that it has a nonlinear Markov
process in the sense of McKean as its probabilistic counterpart. More
precisely, we obtain a probabilistic representation of its Barenblatt solutions
as the one-dimensional marginal density curve of the unique solutions to the
associated McKean--Vlasov SDE. The latter is of novel type, since its
coefficients depend pointwise both on its solution's time marginal densities
and also on their first and second order derivatives. Moreover, we show that
these solutions constitute the aforementioned nonlinear Markov process, which
we call the Leibenson process. A further main result of this work is to prove
that despite the strong degeneracy of the diffusion and the irregularity of the
drift coefficient (which is merely of bounded variation) of the McKean--Vlasov
SDE these solutions are probabilistically strong, i.e., measurable functionals
of the driving Brownian motion and the initial condition.

</details>


<div id='math.SP'></div>

# math.SP [[Back]](#toc)

### [50] [Monotonicity of Discrete spectra of Dirichlet Laplacian in 3-dimensional layers](https://arxiv.org/abs/2508.12696)
*Fedor Bakharev,Sergey Matveenko*

Main category: math.SP

TL;DR: Analysis of eigenvalue monotonicity in polyhedral layers showing both monotonic dependence on geometric parameters and unexpected non-monotonic behavior from asymmetric perturbations.


<details>
  <summary>Details</summary>
Motivation: To extend understanding of eigenvalue monotonicity from simple planar and conical waveguides to more complex polyhedral layers, and to investigate how geometric parameters affect spectral properties in these structures.

Method: Mathematical analysis of Dirichlet Laplacian eigenvalues in polyhedral layers of fixed width, examining dependence on geometric parameters and studying limiting behavior as parameters approach critical configurations.

Result: Established monotonic dependence of eigenvalues below essential spectrum threshold on geometric parameters, while demonstrating non-monotone spectral behavior from asymmetric perturbations with explicit examples of discrete eigenvalue emergence.

Conclusion: Polyhedral layers exhibit complex spectral behavior with both monotonic and non-monotonic eigenvalue dependence on geometry, providing new insights beyond simpler waveguide structures and revealing unexpected spectral phenomena.

Abstract: We investigate monotonicity properties of eigenvalues of the Dirichlet
Laplacian in polyhedral layers of fixed width. We establish that eigenvalues
below the essential spectrum threshold monotonically depend on geometric
parameters defining the polyhedral layer, generalizing previous results known
for planar V-shaped waveguides and conical layers. Moreover, we demonstrate
non-monotone spectral behavior arising from asymmetric geometric perturbations,
providing an explicit example where unfolding the polyhedral angle unexpectedly
leads to the emergence of discrete eigenvalues. The limiting behavior of
eigenvalues as the geometric parameters approach critical configurations is
also rigorously analyzed.

</details>


<div id='physics.acc-ph'></div>

# physics.acc-ph [[Back]](#toc)

### [51] [Simulation Study of Energy Chirp Induced Effects in Laser Wakefield Accelerator Driven Free Electron Laser](https://arxiv.org/abs/2508.11852)
*Shan-You Teng,Wai-Keung Lau,Shih-Hung Chen,Wei-Yuan Chiang*

Main category: physics.acc-ph

TL;DR: Energy compression in laser wakefield accelerators introduces strong energy chirp that degrades FEL performance by causing multi-frequency interactions and bunch elongation, requiring dechirpers for optimal performance.


<details>
  <summary>Details</summary>
Motivation: Beam energy compression reduces slice energy spread in LWFA electron beams but introduces strong energy chirp that hinders microbunching and spectral coherence in FEL applications, requiring detailed analysis.

Method: Detailed, unaveraged three-dimensional simulation examining effects of energy chirp on FEL performance, comparing scenarios with and without chirp removal.

Result: Energy chirp causes FEL interactions at multiple resonant frequencies simultaneously, prevents sustained power growth, degrades spectral purity, elongates bunch length via undulator dispersion, and causes radiation frequency redshift.

Conclusion: Implementation of beam dechirper is crucial for improving radiation power saturation; insights will aid developing compensation strategies to optimize LWFA-driven FEL designs.

Abstract: Beam energy compression via chicane magnets has been proved to be an
effective method to reduce the slice energy spread of electron beams generated
by laser wakefield accelerators (LWFAs). This technique has been widely adopted
by leading research teams in experiments targeting future compact, high-gain
free electron lasers (FELs). However, after energy compression, a strong beam
energy chirp is introduced into the electron beam, which substantially hinders
the microbunching process and impairs spectral coherence. Here, we present a
detailed, unaveraged three-dimensional simulation that examines the effects of
this energy chirp, and the results can be applied to the design of a proposed
LWFA-driven VUV FEL. The energy chirp in a LWFA-produced electron beam causes
FEL interactions at multiple resonant frequencies across the entire electron
bunch, simultaneously, which prevents sustained radiation power growth at the
designed frequency along the undulator. Consequently, spectral purity is
significantly degraded. Additionally, due to undulator dispersion, the energy
chirp leads to an elongation of the bunch length, which increases microbunch
separation. This results in a noticeable redshift in the radiation frequency
and further disruption of spectral purity. These effects are compared to the
ideal scenario in which the energy chirp is removed following energy
compression. Simulation results indicate that the implementation of a beam
dechirper is a crucial step for improving the saturation of radiation power.
Insights gained from this simulation of energy chirp-induced mechanisms will
aid in the development of more effective compensation strategies, ultimately
optimizing LWFA-driven FEL designs.

</details>


### [52] [Description of electromagnetic fields in inhomogeneous accelerating sections. III Beam loading](https://arxiv.org/abs/2508.12955)
*M. I. Ayzatsky*

Main category: physics.acc-ph

TL;DR: Semi-analytical theory for beam loading in inhomogeneous accelerating structures using coupled modes approach with single-mode approximation


<details>
  <summary>Details</summary>
Motivation: To develop a self-consistent theoretical framework for understanding beam loading effects in inhomogeneous accelerating structures, where traditional approaches may not fully capture the complex field distributions

Method: Generalized theory of coupled modes with single-mode approximation, representing fields as sum of right-travelling eigen wave and a second component (not necessarily left-travelling), applied to relativistic electron beam excitation

Result: The theory enables calculation of electric field distributions excited by relativistic electron beams in inhomogeneous structures, revealing complex spatial patterns that don't conform to simple left/right travelling wave assumptions

Conclusion: The proposed semi-analytical approach provides a more accurate framework for analyzing beam loading in inhomogeneous accelerating structures, accounting for complex field distributions that traditional methods may miss

Abstract: A self-consistent semi-analytical theory of beam loading in inhomogeneous
accelerating structures based on the generalized theory of coupled modes is
proposed. A single-mode approximation was used when the fields are represented
as a sum of two components, one of which is associated with the right
travelling eigen wave, and the second with the left. However, this second
component is not always a left travelling. When a field is excited by an
electron beam it can have complex spatial distribution. The results of
calculation of the distribution of electric fields excited by a relativistic
electron beam are presented.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [53] [Transfer Learning for Neutrino Scattering: Domain Adaptation with GANs](https://arxiv.org/abs/2508.12987)
*Jose L. Bonilla,Krzysztof M. Graczyk,Artur M. Ankowski,Rwik Dharmapal Banerjee,Beata E. Kowal,Hemant Prasad,Jan T. Sobczyk*

Main category: hep-ph

TL;DR: Transfer learning enables efficient generation of neutrino scattering events using GANs, outperforming training from scratch especially with limited data.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of sparse experimental data for neutrino scattering events by leveraging transfer learning to adapt existing generative models to new interaction types and nuclei.

Method: Utilize transfer learning to adapt a GAN model trained on synthetic charged-current neutrino-carbon scattering data to generate events for neutrino-argon and antineutrino-carbon interactions, testing with 10,000 and 100,000 event datasets.

Result: Transfer learning significantly outperforms training generative models from scratch, with models performing well even with smaller training datasets of 10,000 events.

Conclusion: Transfer learning provides a promising approach for building neutrino scattering event generators when experimental data is limited, enabling efficient adaptation to new interaction types and target nuclei.

Abstract: We utilize transfer learning to extrapolate the physics knowledge encoded in
a Generative Adversarial Network (GAN) model trained on synthetic
charged-current (CC) neutrino-carbon inclusive scattering data. This base model
is adapted to generate CC inclusive scattering events (lepton kinematics only)
for neutrino-argon and antineutrino-carbon interactions. Furthermore, we assess
the effectiveness of transfer learning in re-optimizing a custom model when new
data comes from a different neutrino-nucleus interaction model. Our results
demonstrate that transfer learning significantly outperforms training
generative models from scratch. To study this, we consider two training data
sets: one with 10,000 and another with 100,000 events. The models obtained via
transfer learning perform well even with smaller training data. The proposed
method provides a promising approach for constructing neutrino scattering event
generators in scenarios where experimental data is sparse.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [54] [Extraction of classical ergotropy](https://arxiv.org/abs/2508.12797)
*Michele Campisi*

Main category: cond-mat.stat-mech

TL;DR: Classical ergotropy extraction method derived from quantum analogy, using instantaneous quench followed by adiabatic return to maximize energy extraction from thermally isolated systems.


<details>
  <summary>Details</summary>
Motivation: While quantum ergotropy extraction is well-solved, classical systems lack a general solution despite long-standing study in fields like plasma physics. The paper aims to bridge this gap by building on quantum solutions.

Method: Developed classical ergotropy extraction driving based on quantum analogy, consisting of an instantaneous quench followed by an adiabatic return, valid under ergodic assumption.

Result: Successfully derived the classical ergotropy extraction protocol and showed that classical ergotropy splits into coherent and incoherent parts similar to quantum case.

Conclusion: The results enable practical energy recovery in classical regimes and suggest that quantum ergotropy problems don't have genuinely quantum aspects - classical systems can achieve similar energy extraction.

Abstract: Finding the time dependent perturbation that extracts the maximal amount of
energy (a.k.a. ergotropy) from a thermally isolated quantum system is a
central, solved, problem in quantum thermodynamics. Notably, the same problem
has been long studied for classical systems as well, e.g., in the field of
plasma physics, but a general solution is still missing there. By building on
the analogy with the quantum solution, we provide the classical ergotropy
extraction driving: it consists of an instantaneous quench followed by an
adiabatic return. We illustrate how the solution, which is valid under an
ergodic assumption, is instrumental to finding the ergotropy extracting driving
in more general cases. We also show that, just like in the quantum case, the
classical ergotropy splits into a coherent and an incoherent part. The
presented results open new ways for practical energy recovery in the classical
regime while suggesting that there is nothing genuinely quantum in the quantum
ergotropy problem.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [55] [Conditional mutual information: A generalization of causal inference in quantum systems](https://arxiv.org/abs/2508.12160)
*Anupam Ghosh*

Main category: quant-ph

TL;DR: Development of a quantum causal index using asymmetric quantum conditional mutual information to measure causal influence in quantum many-body systems, revealing finite-speed causal propagation with coherent oscillations.


<details>
  <summary>Details</summary>
Motivation: Extend classical causal inference frameworks to quantum systems to rigorously explore causality in the quantum regime, which remains largely unexplored.

Method: Use asymmetric quantum conditional mutual information (QCMI) with von Neumann entropy as directional causal metric. Analyze spin chains by implementing projective measurements on one site and monitoring effects on distant sites conditioned on intermediate spins. Study effective causal propagation velocity.

Result: Findings show finite-speed propagation of causal influence in quantum systems along with the emergence of coherent oscillations. QCMI becomes significant at distant sites at a measurable velocity.

Conclusion: The quantum causal index successfully extends causal inference to quantum systems, demonstrating measurable causal propagation speeds and revealing quantum-specific phenomena like coherent oscillations in causal relationships.

Abstract: The concept of causality is fundamental to numerous scientific explanations;
nonetheless, its extension to the quantum regime has yet to be explored
rigorously. This paper introduces the development of a quantum causal index, a
novel extension of the classical causal inference framework, tailored to grasp
the causal relationships inherent in quantum systems. Our study focuses on the
asymmetric quantum conditional mutual information (QCMI), incorporating the von
Neumann entropy, as a directional metric of causal influence in quantum
many-body systems. We analyze spin chains using the QCMI, implementing a
projective measurement on one site as the intervention and monitoring its
effect on a distant site conditioned on intermediate spins. Additionally, we
study the effective causal propagation velocity, which is the speed at which
QCMI becomes significant at distant sites. These findings indicate the presence
of finite-speed propagation of causal influence, along with the emergence of
coherent oscillations.

</details>


### [56] [Simulating Quantum Turbulence with Matrix Product States](https://arxiv.org/abs/2508.12191)
*Felipe Gómez-Lozada,Nicolas Perico-García,Nikita Gourianov,Hayder Salman,Juan José Mendoza-Arenas*

Main category: quant-ph

TL;DR: MPS solver for GP equation enables efficient quantum turbulence simulations by compressing wavefunction, achieving 10-10,000x memory reduction while accurately capturing vortex dynamics and energy spectra.


<details>
  <summary>Details</summary>
Motivation: Direct numerical simulations of quantum turbulence become computationally expensive when system size L greatly exceeds healing length ξ, requiring new efficient methods.

Method: Matrix product state (MPS) solver that compresses wavefunction by truncating weak interlength-scale correlations in the Gross-Pitaevskii equation.

Result: Achieves 10x to over 10,000x memory reduction compared to DNS, accurately captures vortex dynamics (Kelvin waves, reconnection), and reproduces energy spectra with minimal overhead.

Conclusion: MPS ansatz is highly effective for quantum turbulence studies, enabling previously impossible system sizes and potentially revealing new physics in nonequilibrium states.

Abstract: Quantum turbulence spans length scales from the system size $L$ to the
healing length $\xi$, making direct numerical simulations (DNS) of the
Gross-Pitaevskii (GP) equation computationally expensive when $L \gg \xi$. We
present a matrix product state (MPS) solver for the GP equation that
efficiently compresses the wavefunction by truncating weak interlength-scale
correlations. This approach reduces memory use by factors ranging from 10x to
over 10,000x compared to DNS. We benchmark our approach on nonlinear
excitations, namely dark solitons (1D) and quantized vortices (2D, 3D),
capturing key dynamics like Kelvin wave propagation and vortex ring emission in
the case of vortex line reconnection. For turbulent states composed of multiple
nonlinear excitations, we find that the memory compression of the MPS
representation is directly proportional to the soliton or vortex densities. We
also accurately reproduce established results from two-point correlation
functions and energy spectra, where we recover the incompressible kinetic
energy spectrum with little memory overhead. These results demonstrate the
representative capabilities of the MPS ansatz for quantum turbulence and pave
the way for studying this nonequilibrium state using previously-prohibited
system sizes to uncover possible new physics.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [57] [Collective ballistic motion explains fast aggregation in adhesive active matter](https://arxiv.org/abs/2508.11793)
*Emanuel F. Teixeira,Pablo de Castro,Carine P. Beatrici,Heitor C. M. Fernandes,Leonardo G. Brunnet*

Main category: cond-mat.soft

TL;DR: Active self-aligning adhesive particles undergo ballistic aggregation through flocking transition when cluster persistence length grows faster than intercluster distance with mass.


<details>
  <summary>Details</summary>
Motivation: Inspired by motile cells during tissue formation, to understand the mechanism of ballistic aggregation in active systems.

Method: Analysis of active systems with self-aligning adhesive particles, studying cluster persistence length growth relative to intercluster distance.

Result: Identified flocking transition mechanism for ballistic aggregation and characterized distinct non-collective kinetic regimes including long-lived transients relevant to biological systems.

Conclusion: Provides a unified framework explaining broad range of aggregation exponents observed in cellular systems and uncovers physical principles for timely tissue organization.

Abstract: Inspired by motile cells during tissue formation, we identify a mechanism by
which active systems of self-aligning adhesive particles undergo ballistic
aggregation via a flocking transition. This kinetic regime emerges when the
cluster persistence length grows faster with cluster mass than the intercluster
distance does. We also characterize and explain the emergence of distinct
non-collective kinetic regimes, including long-lived transients relevant to
biological systems. Our results provide a unified framework consistent with the
broad range of aggregation exponents experimentally observed in cellular
systems and uncover physical principles which may enable timely tissue
organization

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [58] [The Mathematical Theory of Behavioural Swarms: Towards Modelling the Collective Dynamics of Living Systems](https://arxiv.org/abs/2508.12183)
*Rene Fabregas,Jie Liao,Nisrine Outada*

Main category: nlin.AO

TL;DR: A new mathematical framework called Behavioural Swarms that extends classical swarm models by incorporating dynamic internal activity variables that co-evolve with position and velocity through nonlocal interactions, enabling modeling of adaptive decision-making and heterogeneous behaviors.


<details>
  <summary>Details</summary>
Motivation: Classical swarm models like Cucker-Smale have fundamental limitations in capturing the adaptive, heterogeneous behaviors intrinsic to living systems, requiring a more comprehensive framework.

Method: Formalizes mathematical theory where each particle's state includes a dynamic internal activity variable that co-evolves with position and velocity through nonlocal interactions, integrating adaptive decision-making mechanisms into rigorous differential systems.

Result: The framework demonstrates capacity to predict emergent macroscopic patterns from individual behavioral states through applications in behavioral economics and crowd dynamics.

Conclusion: This approach transcends prior models and reveals distinct advantages over kinetic theories of active particles and agent-based approaches for modeling systems where individual agency drives collective outcomes.

Abstract: Classical swarm models, exemplified by the Cucker--Smale framework, provide
foundational insights into collective alignment but exhibit fundamental
limitations in capturing the adaptive, heterogeneous behaviours intrinsic to
living systems. This paper formalises the mathematical theory of
\textit{Behavioural Swarms}, a comprehensive framework where each particle's
state incorporates a dynamic internal variable, the \textit{activity} that
co-evolves with position and velocity through nonlocal interactions. We
demonstrate how this approach transcends prior models by integrating adaptive
decision-making mechanisms and heterogeneous behavioural states into rigorous
differential systems. Through applications in behavioural economics and crowd
dynamics, we establish the theory's capacity to predict emergent macroscopic
patterns from individual behavioural states. Our critical analysis positions
this framework against kinetic theories of active particles and agent-based
approaches, revealing distinct advantages for modelling systems where
individual agency drives collective outcomes.

</details>


<div id='math.CA'></div>

# math.CA [[Back]](#toc)

### [59] [Regularity and pointwise convergence for dispersive equations on $\mathbb{H}^2$](https://arxiv.org/abs/2508.12284)
*Utsav Dewan*

Main category: math.CA

TL;DR: Improved Sobolev regularity threshold to β ≥ 1/2 for pointwise convergence of Schrodinger equation solutions in 2D hyperbolic space, extending to other dispersive equations.


<details>
  <summary>Details</summary>
Motivation: To establish better regularity conditions for pointwise convergence of solutions to dispersive equations in non-Euclidean geometry settings, specifically improving upon previous results by Wang-Zhang and Cowling.

Method: Analysis of Carleson's problem for Schrodinger equation and other dispersive equations (fractional Schrodinger with convex phase, Boussinesq equation, Beam equation) in 2-dimensional real hyperbolic space.

Result: Proved that Sobolev regularity threshold β ≥ 1/2 is sufficient for pointwise convergence almost everywhere on hyperbolic space, improving previous bounds.

Conclusion: The study demonstrates that a lower regularity threshold than previously known is sufficient for pointwise convergence in non-Euclidean geometric settings, with implications for various dispersive equations.

Abstract: In the prototypical setting of non-Euclidean geometry, the 2-dimensional Real
Hyperbolic space $\mathbb{H}^2$, we consider the Carleson's problem for the
Schr\"odinger equation and improve the best known result until now by proving
that the Sobolev regularity threshold $\beta \ge 1/2$ for the initial data, is
sufficient to obtain pointwise convergence of the solution a.e. on
$\mathbb{H}^2$. In fact, we prove the same bound for a wide class of dispersive
equations that include the fractional Schr\"odinger equations with convex
phase, the Boussinesq equation and the Beam equation, also known as the fourth
order Wave equation. For the Schr\"odinger equation, we improve the result of
Wang-Zhang (Canad J Math 71(4), 983-995, 2019) and for the fractional
Schr\"odinger equations with convex phase, we improve the result of Cowling
(Lecture Notes Math 992, 83-90, 1983).

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [60] [Stochastic Modeling of Filtration with Sieving in Graded Pore Networks](https://arxiv.org/abs/2508.11820)
*Binan Gu,Pejman Sanaei,Lou Kondic,Linda J. Cummings*

Main category: physics.flu-dyn

TL;DR: Modeling membrane filtration with simultaneous adsorption of small particles and sieving of large particles through pore networks, showing how sieving qualitatively alters flux decline and reveals phase transitions in filter lifetime.


<details>
  <summary>Details</summary>
Motivation: To understand the relative influences and coupling effects of two fouling mechanisms (adsorption of small particles and sieving of large particles) in membrane filtration, particularly for filters with pore-size gradients.

Method: First-principles continuum PDEs model small particle transport and adsorptive fouling in each pore, while sieving particles follow discrete Poisson arrival process with biased random walk through pore network. Analyzed banded filters with different pore sizes.

Result: Sieving alters flux decline rate qualitatively due to discrete pore blockage nature. Size difference between sieving particles and initial pore radius indicates onset/disappearance of sieving-adsorption competition. Phase transition in filter lifetime observed as sieving particle arrival frequency increases.

Conclusion: The discrete nature of pore blockage from sieving significantly impacts filtration performance, with particle-pore size relationships determining fouling mechanism competition, and filter lifetime exhibits phase transitions based on sieving particle frequency.

Abstract: We model filtration of a feed solution, containing both small and large
foulant particles, by a membrane filter. The membrane interior is modeled as a
network of pores, allowing for the simultaneous adsorption of small particles
and sieving of large particles, two fouling mechanisms typically observed
during the early stages of commercial filtration applications. In our model,
first-principles continuum partial differential equations model transport of
the small particles and adsorptive fouling in each pore, while sieving
particles are assumed to follow a discrete Poisson arrival process with a
biased random walk through the pore network. Our goals are to understand the
relative influences of each fouling mode and highlight the effect of their
coupling on the performance of filters with a pore-size gradient (specifically,
we consider a banded filter with different pore sizes in each band). Our
results suggest that, due to the discrete nature of pore blockage, sieving
alters qualitatively the rate of the flux decline. Moreover, the difference
between sieving particle sizes and the initial pore size (radius) in each band
plays a crucial role in indicating the onset and disappearance of
sieving-adsorption competition. Lastly, we demonstrate a phase transition in
the filter lifetime as the arrival frequency of sieving particles increases.

</details>


### [61] [Modeling wind farm noise emission and propagation: effects of flow layout](https://arxiv.org/abs/2508.13128)
*J. Colas,A. Emmanuelli,D. Dragna,R. J. A. M. Stevens*

Main category: physics.flu-dyn

TL;DR: Wind farm flow physics significantly affect noise generation and propagation, with staggered layouts producing more overall noise but aligned layouts showing stronger wake interactions. Integrated flow-acoustic modeling is essential for accurate environmental impact assessment.


<details>
  <summary>Details</summary>
Motivation: To understand how wind farm flow physics influence noise generation and downstream propagation, which is crucial for accurate environmental impact assessment of wind farms.

Method: Used large-eddy simulations (LES) to model flow field, with time-averaged output serving as input to acoustic models for wind turbine noise prediction. Compared aligned vs staggered wind farm layouts.

Result: First row turbines show equal TIN and TEN contributions (TIN dominant at low frequencies, TEN at high frequencies). Downstream, TEN decreases due to lower wind speeds while TIN persists. Staggered farms produce more overall noise but aligned layouts have stronger wake interactions. Wake superposition modifies sound focusing patterns.

Conclusion: Wind farm flow significantly affects sound propagation and noise characteristics. Models based on isolated turbines fail to capture these effects, underscoring the importance of integrated flow-acoustic modeling for accurate environmental impact assessment.

Abstract: This study demonstrates how wind farm flow physics influence noise generation
and downstream propagation through numerical simulations. The flow field is
modeled using large-eddy simulations (LES), and the time-averaged output serves
as input to acoustic models that predict wind turbine noise. In the first
turbine row, turbulence-induced noise (TIN) and trailing edge noise (TEN)
contribute equally, with TIN dominating at low frequencies and TEN at higher
frequencies. Downstream, TEN decreases due to lower wind speeds, while TIN
mostly persists due to increased turbulence dissipation. These effects are more
pronounced in aligned wind farms, where stronger wake interactions occur, than
in staggered layouts. However, staggered farms produce more noise overall
because turbines operate at higher wind speeds.Additionally, wind farm flow
significantly affects sound propagation downwind. The wake superposition
modifies sound focusing leading to different amplification area than for an
isolated turbine. For a staggered layout it particularly shows enhanced sound
focusing downwind due to the position of the turbine wakes. This leads to
higher sound levels and higher amplitude modulation downwind for the wind farm
compared to an aligned layout. These phenomena are not captured by models based
on isolated turbines. These findings underscore the importance of integrating
flow and acoustic models to more accurately assess the environmental impact of
wind farms.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [62] [Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems](https://arxiv.org/abs/2508.12569)
*Quercus Hernandez,Max Win,Thomas C. O'Connor,Paulo E. Arratia,Nathaniel Trask*

Main category: cs.LG

TL;DR: A machine learning framework for coarse-graining multiscale systems using metriplectic bracket formalism that preserves thermodynamic laws and fluctuation-dissipation balance while learning from particle trajectory data.


<details>
  <summary>Details</summary>
Motivation: Multiscale systems are challenging to simulate due to the need to link short spatiotemporal scales with emergent bulk physics. Traditional coarse-graining loses information, leading to dissipative, history-dependent, and stochastic emergent physics that are difficult to capture accurately.

Method: Proposes a framework using metriplectic bracket formalism that guarantees discrete notions of first and second laws of thermodynamics, momentum conservation, and fluctuation-dissipation balance. Uses self-supervised learning to identify emergent structural variables when labels are unavailable, with implementations in PyTorch and LAMMPS.

Result: Validated on benchmark systems and demonstrated utility on challenging examples: coarse-graining star polymers at difficult levels while preserving non-equilibrium statistics, and learning models from high-speed video of colloidal suspensions capturing coupling between local rearrangement events and emergent stochastic dynamics.

Conclusion: The framework successfully bridges scales in multiscale systems by preserving crucial thermodynamic properties and fluctuation-dissipation balance, enabling accurate coarse-grained modeling from particle trajectory observations with open-source implementations for extensibility.

Abstract: Multiscale systems are ubiquitous in science and technology, but are
notoriously challenging to simulate as short spatiotemporal scales must be
appropriately linked to emergent bulk physics. When expensive high-dimensional
dynamical systems are coarse-grained into low-dimensional models, the entropic
loss of information leads to emergent physics which are dissipative,
history-dependent, and stochastic. To machine learn coarse-grained dynamics
from time-series observations of particle trajectories, we propose a framework
using the metriplectic bracket formalism that preserves these properties by
construction; most notably, the framework guarantees discrete notions of the
first and second laws of thermodynamics, conservation of momentum, and a
discrete fluctuation-dissipation balance crucial for capturing non-equilibrium
statistics. We introduce the mathematical framework abstractly before
specializing to a particle discretization. As labels are generally unavailable
for entropic state variables, we introduce a novel self-supervised learning
strategy to identify emergent structural variables. We validate the method on
benchmark systems and demonstrate its utility on two challenging examples: (1)
coarse-graining star polymers at challenging levels of coarse-graining while
preserving non-equilibrium statistics, and (2) learning models from high-speed
video of colloidal suspensions that capture coupling between local
rearrangement events and emergent stochastic dynamics. We provide open-source
implementations in both PyTorch and LAMMPS, enabling large-scale inference and
extensibility to diverse particle-based systems.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [63] [From plasma to pattern: observation and characterization of periodic structure formation in dielectric breakdown channels of electron-irradiated insulators](https://arxiv.org/abs/2508.12592)
*Nick R. Schwartz,Bryson C. Clifford,Carolyn Chun,Emily H. Frashure,Kathryn M. Sturge,Noah Hoppis,Holly Wilson,Meryl Wiratmo,Jack R. FitzGibbon,Ethan T. Basinger,Brian L. Beaudoin,Raymond J. Phaneuf,John Cumings,Timothy W. Koeth*

Main category: physics.app-ph

TL;DR: Periodic structures in dielectric breakdown channels are caused by z-pinch entropy mode plasma instability during nanosecond discharge phase, not post-discharge processes.


<details>
  <summary>Details</summary>
Motivation: Understand the mechanics of dielectric breakdown in insulators for space electronics, particularly the origin of periodic structures in ivy-mode channels that offer insights into ultra-fast breakdown physics.

Method: Materials characterization (Raman spectroscopy) and theoretical modeling to evaluate three candidate instability mechanisms: Asaro-Tiller-Grinfeld, Plateau-Rayleigh, and z-pinch entropy mode.

Result: Z-pinch entropy mode operates during nanosecond discharge phase, producing wavelengths consistent with plasma densities of 0.1-1% solid density and temperatures of 10-100 eV. Current measurements (~200 A) validate theoretical predictions.

Conclusion: Entropy mode plasma instability during discharge phase governs periodic structure formation, providing new insights into dielectric breakdown physics and a framework for predicting discharge morphology in insulators.

Abstract: Dielectric breakdown of insulators is one of the most common failure modes of
electronics in the high-radiation environment of space, but its mechanics
remain poorly understood. When electron-irradiated polymethyl methacrylate
(PMMA) undergoes breakdown, the resulting channels exhibit striking periodic
structures with characteristic wavelengths ~80 {\mu}m in the recently
identified ivy-mode channels. These previously unobserved modulations offer
unique insights into the physics of ultra-fast dielectric breakdown. Through
materials characterization and theoretical modeling, we identify the physical
instability mechanism responsible for these structures. Raman spectroscopy
reveals that carbon deposition correlates with channel width variations,
indicating that periodic structure formation occurs during the plasma discharge
phase. We evaluated three candidate instability mechanisms: the
Asaro-Tiller-Grinfeld instability, the Plateau-Rayleigh instability, and the
z-pinch entropy mode. The first two mechanisms operate on incompatible
timescales and require unphysical material parameters to match observations. In
contrast, the z-pinch entropy mode operates during the nanosecond discharge
phase and produces wavelengths consistent with plasma densities of 0.1-1% of
solid density and temperatures of 10-100 eV. Current measurements from isolated
discharge channels (~200 A) validate theoretical predictions for the entropy
mode. These findings establish that the entropy mode plasma instability during
the discharge phase, rather than post discharge thermal or mechanical
processes, govern periodic structure formation in breakdown channels. This work
provides new insights into the physics of dielectric breakdown and establishes
a framework for predicting discharge morphology and characteristics in
insulators.

</details>
