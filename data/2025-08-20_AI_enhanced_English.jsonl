{"id": "2508.13190", "pdf": "https://arxiv.org/pdf/2508.13190", "abs": "https://arxiv.org/abs/2508.13190", "authors": ["Jinrui Zhou", "Yiqi Gu", "Song Jiang", "Hua Shen", "Liwei Xu", "Guanyu Zhou"], "title": "Data-driven optimized high-order WENO schemes with low-dissipation and low-dispersion", "categories": ["math.NA", "cs.NA"], "comment": "22 pages, 34 figures", "summary": "Classical high-order weighted essentially non-oscillatory (WENO) schemes are\ndesigned to achieve optimal convergence order for smooth solutions and to\nmaintain non-oscillatory behaviors for discontinuities. However, their spectral\nproperties are not optimal, which limits the ability to capture high-frequency\nwaves and small-scale features. In this paper, we propose a data-driven\noptimized method to improve the spectral properties of the WENO schemes. By\nanalyzing the approximate dispersion relation (ADR), the spectral error of the\nschemes can be bounded by the reconstructed errors of a series of trigonometric\nfunctions with different wavenumbers. Therefore, we propose the new schemes\nWENO5-JS/Z-NN that introduce a compensation term parameterized by a neural\nnetwork to the weight function of the WENO5-JS/Z schemes. The neural network is\ntrained such that the generated weights can minimize the reconstructed errors\nover a large number of spatial stencils, and furthermore, improve the spectral\naccuracy. Meanwhile, the Total Variation Diminishing (TVD) constraint and\nanti-dissipation penalization are incorporated into the loss function to\nenhance the shock-capturing capability and preserve stability in simulating\nhigh-frequency waves. Compared to WENO5-JS/Z, our schemes maintain the ability\nto capture discontinuities while providing higher resolution for fine-scale\nflow features. The ADR indicates that the new schemes can match the exact\nspectrum more accurately over a broader range of wavenumbers.", "AI": {"tldr": "Data-driven optimized WENO schemes using neural networks to improve spectral properties while maintaining shock-capturing capabilities", "motivation": "Classical WENO schemes have suboptimal spectral properties that limit their ability to capture high-frequency waves and small-scale features, despite achieving optimal convergence order for smooth solutions and non-oscillatory behavior for discontinuities", "method": "Propose WENO5-JS/Z-NN schemes that introduce a neural network-parameterized compensation term to the weight function. The neural network is trained to minimize reconstructed errors over spatial stencils while incorporating TVD constraints and anti-dissipation penalization in the loss function to enhance shock-capturing and stability", "result": "The new schemes maintain discontinuity capture ability while providing higher resolution for fine-scale flow features. ADR analysis shows the schemes match the exact spectrum more accurately over a broader range of wavenumbers compared to WENO5-JS/Z", "conclusion": "The data-driven optimized approach successfully improves spectral properties of WENO schemes while preserving their essential non-oscillatory characteristics and stability for high-frequency wave simulation"}}
{"id": "2508.13289", "pdf": "https://arxiv.org/pdf/2508.13289", "abs": "https://arxiv.org/abs/2508.13289", "authors": ["Hakop Hakopian", "Gagik Vardanyan", "Navasard Vardanyan"], "title": "On the usage of $2$-node lines in $n$-correct and $GC_n$ sets", "categories": ["math.NA", "cs.NA", "41A05, 41A63, 14H50"], "comment": "18 pages, 6figures", "summary": "An $n$-correct set $\\mathcal{X}$ in the plane is a set of nodes admitting\nunique\n  interpolation with bivariate polynomials of total degree at most $n$. A\n$k$-node line is a line passing through exactly $k$ nodes of $\\mathcal{X}.$ A\nline can pass through at most $n+1$ nodes of an $n$-correct set. An\n$(n+1)$-node line is called maximal line (C. de Boor, 2007). We say that a node\n$A\\in\\mathcal{X}$ uses a line $\\ell,$ if $\\ell$ is a factor of the fundamental\npolynomial of the node $A.$\n  Let $\\mathcal{X}$ be an $n$-correct set. One of the main problems we study in\nthis paper is to determine the maximum possible number of used $2$-node lines\nthat share a common node $B \\in\\mathcal{X}.$ We show that this number equals\n$n$. Moreover, if there are $n$ such $2$-node lines, then $\\mathcal{X}$\ncontains exactly $n$ maximal lines not passing through the common node $B$.\nFurthermore, if $\\mathcal{X}$ is $GC_n$ set, there exists an additional maximal\nline passing through $B$. Hence, in this case, $\\mathcal{X}$ has $n+1$ maximal\nlines and is Carnicer~Gasca set of degree $n$. Note that Carnicer~Gasca sets of\ndegree $n$ with a prescribed set of $n$ used $2$-node lines can be readily\nconstructed.", "AI": {"tldr": "Maximum number of used 2-node lines sharing a common node in an n-correct set is n, and this leads to Carnicer-Gasca sets with n+1 maximal lines.", "motivation": "To study interpolation properties of bivariate polynomials on n-correct sets and determine the maximum possible number of used 2-node lines sharing a common node.", "method": "Analysis of n-correct sets in the plane, studying lines passing through nodes and their relationship with fundamental polynomials of nodes.", "result": "The maximum number of used 2-node lines sharing a common node B equals n. If there are n such lines, then the set contains exactly n maximal lines not passing through B, and if it's a GC_n set, there's an additional maximal line through B making it a Carnicer-Gasca set.", "conclusion": "The structure of n-correct sets with maximum used 2-node lines leads to Carnicer-Gasca sets, which can be constructed with prescribed sets of used 2-node lines."}}
{"id": "2508.13342", "pdf": "https://arxiv.org/pdf/2508.13342", "abs": "https://arxiv.org/abs/2508.13342", "authors": ["Ricardo H. Nochetto", "Mansur Shakipov"], "title": "Surface Stokes Without Inf-Sup Condition", "categories": ["math.NA", "cs.NA", "math.AP", "65N30, 58J05, 35J47, 35J50", "G.1.8"], "comment": "22 pages, 1 figure", "summary": "For a $d$-dimensional hypersurface of class $C^3$ without boundary, we\nreformulate the surface Stokes equations as a nonsymmetric indefinite elliptic\nproblem governed by two Laplacians. We then use this elliptic reformulation as\na basis for a numerical method based on lifted parametric FEM. Assuming no\ngeometric error for simplicity, we prove its well-posedness, quasi-best\napproximation in a robust mesh-dependent $H^1$-norm for any polynomial degree,\nas well as an optimal $L^2$ error estimate for both velocity and pressure. This\nentails a sufficiently small mesh size that solely depends on the Weingarten\nmap and circumvents the usual discrete inf-sup condition. We present numerical\nexperiments for velocity-pressure pairs with equal and disparate polynomial\ndegrees, demonstrating that the proposed method is both accurate and practical.", "AI": {"tldr": "A new FEM method for surface Stokes equations using elliptic reformulation and lifted parametric approach, achieving robust error estimates without discrete inf-sup condition.", "motivation": "To develop a numerical method for surface Stokes equations that circumvents the usual discrete inf-sup condition and provides robust error estimates for velocity-pressure pairs.", "method": "Reformulate surface Stokes equations as a nonsymmetric indefinite elliptic problem governed by two Laplacians, then use lifted parametric FEM with no geometric error assumption.", "result": "Proved well-posedness, quasi-best approximation in robust mesh-dependent H1-norm for any polynomial degree, and optimal L2 error estimates for velocity and pressure with mesh size depending only on Weingarten map.", "conclusion": "The proposed method is both accurate and practical, working effectively for velocity-pressure pairs with equal and disparate polynomial degrees as demonstrated in numerical experiments."}}
{"id": "2508.13416", "pdf": "https://arxiv.org/pdf/2508.13416", "abs": "https://arxiv.org/abs/2508.13416", "authors": ["Franziska Weber"], "title": "A convergence proof for a finite element discretization of Chorin's projection method of the incompressible Navier-Stokes equations", "categories": ["math.NA", "cs.NA", "math.AP"], "comment": null, "summary": "We study Chorin's projection method combined with a finite element spatial\ndiscretization for the time-dependent incompressible Navier-Stokes equations.\nThe scheme advances the solution in two steps: a prediction step, which\ncomputes an intermediate velocity field that is generally not divergence-free,\nand a projection step, which enforces incompressibility by projecting this\nvelocity onto the divergence-free subspace. We establish convergence, up to a\nsubsequence, of the numerical approximations generated by this scheme to a\nLeray-Hopf weak solution of the Navier-Stokes equations, without any additional\nregularity assumptions beyond square-integrable initial data. A discrete energy\ninequality yields a priori estimates, which we combine with a new compactness\nresult to prove precompactness of the approximations in\n$L^2([0,T]\\times\\Omega)$, where $[0,T]$ is the time interval and $\\Omega$ is\nthe spatial domain. Passing to the limit as the discretization parameters\nvanish, we obtain a weak solution of the Navier-Stokes equations. A central\ndifficulty is that different a priori bounds are available for the intermediate\nand projected velocity fields; our compactness argument carefully integrates\nthese estimates to complete the convergence proof.", "AI": {"tldr": "Convergence proof for Chorin's projection method with finite elements for Navier-Stokes equations, showing numerical approximations converge to weak solutions without additional regularity assumptions.", "motivation": "To establish rigorous mathematical convergence of the widely used Chorin's projection method combined with finite element discretization for incompressible Navier-Stokes equations, particularly without requiring additional regularity beyond standard assumptions.", "method": "Two-step projection method: prediction step computes intermediate velocity field, projection step enforces incompressibility by projecting onto divergence-free subspace. Uses discrete energy inequality for a priori estimates and new compactness result in L^2([0,T]\u00d7\u03a9).", "result": "Proved convergence (up to subsequence) of numerical approximations to Leray-Hopf weak solutions of Navier-Stokes equations. Established precompactness in L^2 space and successfully passed to limit as discretization parameters vanish.", "conclusion": "The paper provides a complete convergence proof for Chorin's projection method with finite elements, handling the challenge of different a priori bounds for intermediate and projected velocity fields through careful integration of estimates."}}
{"id": "2508.13230", "pdf": "https://arxiv.org/pdf/2508.13230", "abs": "https://arxiv.org/abs/2508.13230", "authors": ["Fanchen Meng"], "title": "The vanishing viscosity process for an eikonal equation in the radially symmetric setting", "categories": ["math.AP"], "comment": null, "summary": "We study the vanishing viscosity method for the eikonal equation $|Du|=V$ in\n$B(0,1)$ with homogeneous Dirichlet boundary value condition. By assuming $V$\nis radially symmetric and restricting attention to radially symmetric\nsolutions, we construct explicit formulas for both the viscous solution\n$u^{\\epsilon}$ and the limiting solution $u$. We prove $u^{\\epsilon}\\rightarrow\nu$ as $\\epsilon \\rightarrow 0^+$ qualitatively and quantitatively derive an\n$\\epsilon |\\log \\epsilon|$ type local convergence rate. Finally, we discuss the\nuniqueness of viscosity solutions for the eikonal equation and give some\nexamples.", "AI": {"tldr": "Study of vanishing viscosity method for eikonal equation with radial symmetry, providing explicit formulas and proving convergence with \u03f5|log\u03f5| rate.", "motivation": "To understand the behavior of viscous solutions approaching the eikonal equation limit and establish convergence rates for radially symmetric cases.", "method": "Construct explicit formulas for viscous solutions u^\u03f5 and limiting solution u under radial symmetry assumption, then prove qualitative and quantitative convergence.", "result": "Proved u^\u03f5 \u2192 u as \u03f5\u21920+ with local convergence rate of order \u03f5|log\u03f5|, and discussed uniqueness of viscosity solutions.", "conclusion": "The vanishing viscosity method converges for radially symmetric eikonal equations with explicit convergence rate, providing insights into solution uniqueness."}}
{"id": "2508.13310", "pdf": "https://arxiv.org/pdf/2508.13310", "abs": "https://arxiv.org/abs/2508.13310", "authors": ["R. Datta", "E. Neill", "E. Freeman", "E. S. Lavine", "S. Chowdhry", "L. Horan IV", "W. M. Potter", "D. A. Hammer", "B. R. Kusse", "J. D. Hare"], "title": "Resistive diffusion and radiative cooling effects in magnetized oblique shocks", "categories": ["physics.plasm-ph"], "comment": "16 pages", "summary": "Magnetized oblique shocks are of interest in various plasmas, including in\nastrophysical systems, magneto-inertial confinement fusion experiments, and in\naerospace applications. Through experiments on the COBRA pulsed power facility\n(Cornell University, 1~MA peak current, 100~ns rise time), we investigate\noblique shock formation in a system with a magnetic field, and where both\nradiative cooling and resistive diffusion are important. Compared to previous\npulsed power experiments, which have investigated quasi-parallel oblique\nshocks, here we consider perpendicular-type shocks, which can support magnetic\nfield compression. In our experiments, supersonic, super-Alfv\\'enic,\ncollisional plasma flows, generated using an aluminum exploding wire array, are\ndeflected by angled obstacles to generate oblique shocks. The shocks are imaged\nusing laser shadowgraphy and Mach-Zehnder interferometry, while optical Thomson\nscattering provides measurements of the flow velocity and temperature. The\nshocks exhibit shallower shock angles and higher density compression, when\ncompared to canonical Rankine-Hugoniot predictions. These results are best\ndescribed by a model that includes both resistive diffusion and radiative\ncooling, consistent with the values of the cooling parameter and the resistive\ndiffusion length in the experiment.", "AI": {"tldr": "Experimental investigation of magnetized oblique shocks in plasma flows showing shallower shock angles and higher density compression than predicted by standard models, requiring inclusion of resistive diffusion and radiative cooling effects.", "motivation": "Magnetized oblique shocks are important in astrophysical systems, fusion experiments, and aerospace applications, but previous experiments focused on quasi-parallel shocks while perpendicular-type shocks with magnetic field compression need investigation.", "method": "Experiments on COBRA pulsed power facility using aluminum exploding wire arrays to generate supersonic plasma flows deflected by angled obstacles. Shock imaging via laser shadowgraphy and interferometry, with flow velocity and temperature measured by optical Thomson scattering.", "result": "Observed shocks exhibit shallower shock angles and higher density compression compared to canonical Rankine-Hugoniot predictions. Results are best explained by a model incorporating both resistive diffusion and radiative cooling effects.", "conclusion": "Perpendicular-type magnetized oblique shocks require models that account for both resistive diffusion and radiative cooling, as these effects significantly impact shock behavior and compression characteristics in experimental conditions."}}
{"id": "2508.13705", "pdf": "https://arxiv.org/pdf/2508.13705", "abs": "https://arxiv.org/abs/2508.13705", "authors": ["Junlei Mu", "Hong Zhang", "Xing Ji", "Yang Zhang", "Gang Chen", "Kun Xu"], "title": "Very High-order Compact Gas-kinetic Scheme With Discontinuity Feedback Factor", "categories": ["physics.comp-ph"], "comment": null, "summary": "This paper presents a robust and efficient very high-order scheme for\ncompressible flow simulation, addressing critical limitations of existing\nhigh-order methods. The proposed scheme combines the compact gas-kinetic scheme\n(CGKS) with an adaptive stencil extension reconstruction with discontinuity\nfeedback factor (ASE-DFF), achieving significant improvements in both\nrobustness and computational efficiency. Traditional weighted essentially\nnon-oscillatory (WENO) schemes suffer from reduced robustness at higher order\nand require costly smoothness indicators for large stencils. Meanwhile, compact\nmethods based on Discontinuous Galerkin (DG) and Flux Reconstruction (FR)\nstruggle with poor time-marching efficiency. In contrast, the ASE-DFF-CGKS\nintroduces two key innovations: (1) a unified framework enabling arbitrarily\nhigh-order compact gas-kinetic scheme without sacrificing large CFL number, and\n(2) a discontinuity feedback factor that eliminates the need for expensive\nsmoothness indicator calculations while essentially keeping first-order\nrobustness near discontinuities. The scheme's advantages are demonstrated\nthrough benchmark simulations. It maintains a CFL number above 0.5 for up to\n9th-order case, unlike conventional compact methods that restrict a CFL less\nthan 0.05. Also it delivers high-resolution results for flow involving strong\nshock and rarefaction wave. This work provides a practically impactful solution\nfor high-fidelity compressible flow simulation, balancing computational\nefficiency, high-order accuracy and robustness in challenging flow regimes.", "AI": {"tldr": "A robust high-order compact gas-kinetic scheme with adaptive stencil extension and discontinuity feedback factor that overcomes limitations of traditional WENO and compact methods, achieving high CFL numbers (0.5+ for 9th-order) and excellent shock resolution.", "motivation": "Existing high-order methods have critical limitations - WENO schemes suffer from reduced robustness at higher orders and require expensive smoothness indicators, while compact methods like DG and FR have poor time-marching efficiency with very low CFL numbers (<0.05).", "method": "Combines compact gas-kinetic scheme (CGKS) with adaptive stencil extension reconstruction with discontinuity feedback factor (ASE-DFF). Uses unified framework for arbitrarily high-order compact scheme without sacrificing CFL number, and discontinuity feedback factor to eliminate expensive smoothness indicator calculations.", "result": "Achieves CFL number above 0.5 for up to 9th-order cases (vs <0.05 for conventional methods), maintains first-order robustness near discontinuities, and delivers high-resolution results for flows with strong shocks and rarefaction waves.", "conclusion": "Provides a practically impactful solution for high-fidelity compressible flow simulation that balances computational efficiency, high-order accuracy, and robustness in challenging flow regimes."}}
{"id": "2508.13536", "pdf": "https://arxiv.org/pdf/2508.13536", "abs": "https://arxiv.org/abs/2508.13536", "authors": ["Toshihiko Abe"], "title": "Stabilization of BiCGSTAB by the generalized residual cutting method", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "The residual cutting (RC) method has been proposed as an outer-inner loop\niteration for efficiently solving large and sparse linear systems of equations\narising in solving numerically problems of elliptic partial differential\nequations. Then based on RC the generalized residual cutting (GRC) method has\nbeen introduced, which can be applied to more general sparse linear systems\nproblems. In this paper, we show that GRC can stabilize the BiCGSTAB, which is\nalso an iterative algorithm for solving large, sparse, and nonsymmetric linear\nsystems, and widely used in scientific computing and engineering simulations,\ndue to its robustness. BiCGSTAB converges faster and more smoothly than the\noriginal BiCG method, by reducing irregular convergence behavior by stabilizing\nresiduals. However, it sometimes fails to converge due to stagnation or\nbreakdown. We attempt to emphasize its robustness by further stabililizing it\nby GRC, avoiding such failures.", "AI": {"tldr": "Generalized Residual Cutting (GRC) method stabilizes BiCGSTAB algorithm to prevent convergence failures in solving large sparse nonsymmetric linear systems.", "motivation": "BiCGSTAB, while robust and widely used for solving large sparse nonsymmetric linear systems, sometimes fails to converge due to stagnation or breakdown issues, despite being more stable than the original BiCG method.", "method": "Apply the Generalized Residual Cutting (GRC) method, which was developed from the Residual Cutting method for elliptic PDEs, to stabilize the BiCGSTAB iterative algorithm and prevent convergence failures.", "result": "GRC successfully stabilizes BiCGSTAB, allowing it to avoid convergence failures (stagnation or breakdown) that sometimes occur in the standard implementation.", "conclusion": "The combination of GRC with BiCGSTAB enhances the robustness of the iterative solver for large sparse nonsymmetric linear systems, making it more reliable for scientific computing and engineering applications."}}
{"id": "2508.13243", "pdf": "https://arxiv.org/pdf/2508.13243", "abs": "https://arxiv.org/abs/2508.13243", "authors": ["Naijia Liu", "Jan Rozendaal", "Liang Song"], "title": "The Hardy spaces $\\mathcal{H}^{p}_{FIO}(\\mathbb{R}^{n})$ for Fourier integral operators for $p<1$", "categories": ["math.AP", "math.CA", "Primary 42B35. Secondary 35S30, 42B30, 42B37"], "comment": "31 pages. Originally part of arXiv:2502.02511. This part of the\n  manuscript was split off and turned into a separate article", "summary": "We introduce the Hardy spaces $\\mathcal{H}^{p}_{FIO}(\\mathbb{R}^{n})$ for\nFourier integral operators for $0<p<1$, thereby extending earlier constructions\nfor $1\\leq p\\leq \\infty$. We then establish various properties of these spaces,\nincluding their behavior under complex interpolation and duality, and their\ninvariance under Fourier integral operators. We also obtain Sobolev embeddings,\nequivalent characterizations, and a molecular decomposition. These spaces are\nused in the companion article arXiv:2502.02511 to determine the sharp\n$\\mathcal{H}^{1}(\\mathbb{R}^{n})$ and $\\mathrm{bmo}(\\mathbb{R}^{n})$ regularity\nof wave equations with rough coefficients.", "AI": {"tldr": "Extension of Hardy spaces for Fourier integral operators to 0<p<1 range, establishing properties like interpolation, duality, invariance, embeddings, characterizations, and molecular decompositions.", "motivation": "To extend the theory of Hardy spaces for Fourier integral operators beyond the 1\u2264p\u2264\u221e range to include 0<p<1, enabling broader applications in PDE analysis.", "method": "Introduce and construct Hardy spaces H^p_FIO(R^n) for 0<p<1, then systematically establish their mathematical properties through theoretical analysis including complex interpolation, duality proofs, invariance under Fourier integral operators, Sobolev embeddings, equivalent characterizations, and molecular decomposition.", "result": "Successfully constructed Hardy spaces for Fourier integral operators in the 0<p<1 range and proved various fundamental properties including interpolation behavior, duality relations, operator invariance, embedding theorems, and decomposition structures.", "conclusion": "The developed Hardy spaces H^p_FIO(R^n) for 0<p<1 provide a complete extension of the theory and are applied in companion work to establish sharp regularity results for wave equations with rough coefficients in H^1 and bmo spaces."}}
{"id": "2508.13372", "pdf": "https://arxiv.org/pdf/2508.13372", "abs": "https://arxiv.org/abs/2508.13372", "authors": ["Nourhan Hendawy", "Harold McQuaid", "Somhairle Mag Uidhir", "David Rutherford", "Declan Diver", "Davide Mariotti", "Paul Maguire"], "title": "Free electron charging of microdroplets in a plasma at atmospheric pressure", "categories": ["physics.plasm-ph"], "comment": "Main manuscript 7 pages. Supplementary information 15 pages.\n  Submission to", "summary": "Gas phase microdroplets have recently demonstrated exceptional chemical\nproperties via suspected mechanisms such as contact electrification and surface\ncharge pinning leading, in turn, to high electric fields at the surface. In\nthis work, microdroplets are injected into a low temperature flowing gas plasma\nat atmospheric pressure and during flight they are subject to an excess free\nelectron flux. We report the first measurements of particle charge acquired in\na fully collisional plasma with average values up to 2.5E5 electrons, dependent\non absorbed power, for droplets with an average diameter of 15 um. Simulations\nindicate that for similar plasma conditions, the acquired charge on solid\nparticles would be ~40% lower, at 1.5 x 105 electrons, with the difference\nlikely due in part to low mobility water cluster ion formation around the\nevaporating droplet. Simulation also indicates surface electric fields up to\n1E7 V m-1 for the smallest droplets (3 um). The formation of H2O2 was observed\nin the liquid with measured values up to 33 mM, equivalent to a remarkable\ngeneration rate of over 275 M s-1. The microdroplet system involves a complex\ninterplay of various potential mechanisms, yet to be elucidated. The inclusion\nof a controlled plasma environment offers the capability for creating known\ncharge levels and defined exposure times to allow more systematic study as well\nas enhancing their already exceptional characteristics.", "AI": {"tldr": "Microdroplets in low-temperature plasma acquire high charges (up to 2.5E5 electrons) and generate H2O2 at remarkable rates, with plasma enabling controlled charge levels for systematic study.", "motivation": "To investigate how microdroplets interact with low-temperature plasma environments and understand the exceptional chemical properties observed in gas phase microdroplets, particularly focusing on charge acquisition and reactive species generation.", "method": "Injecting microdroplets (average 15 um diameter) into a low-temperature flowing gas plasma at atmospheric pressure, measuring acquired charge, simulating particle behavior, and quantifying H2O2 formation in the liquid.", "result": "Measured charges up to 2.5E5 electrons per droplet, simulations show 40% lower charge for solid particles, surface electric fields up to 1E7 V m-1 for smallest droplets, and H2O2 generation rates exceeding 275 M s-1 with concentrations up to 33 mM.", "conclusion": "Plasma exposure enables controlled charging of microdroplets and enhances their exceptional chemical characteristics, though the complex interplay of mechanisms requires further systematic study using this controlled environment approach."}}
{"id": "2508.13383", "pdf": "https://arxiv.org/pdf/2508.13383", "abs": "https://arxiv.org/abs/2508.13383", "authors": ["Val\u00e9rian Jacques-Dumas", "Henk A. Dijkstra"], "title": "Quantification of the cascading tipping probability from the AMOC to the Amazon rainforest", "categories": ["physics.ao-ph", "physics.comp-ph"], "comment": null, "summary": "The Amazon rainforest and the AMOC are two key components of the Earth system\nand may both collapse under climate change. Due to its influence on\nprecipitation patterns, a collapsed AMOC influences the dynamics of the Amazon\nrainforest. We investigate this effect using a coupled conceptual AMOC-Amazon\nmodel. The Amazon model is based on empirical hydrological data controlled by\nthe AMOC strength. The AMOC model and its influence on the Amazon are tuned\nusing a simulated AMOC collapse in the Community Earth System Model (CESM).\nSince the collapse of both systems is very rare, we study it using a\n``rare-event'' algorithm, which samples such events much more efficiently than\ndirect numerical simulation. This algorithm also allows us to track many\nobservables of interest of the coupled model. We find that in the centre of the\nAmazon basin an AMOC collapse is a necessary condition for the Amazon\nrainforest to collapse, due to its important drying effect. Moreover, we are\nable to quantify the importance of the AMOC in this tipping cascade by\ncomputing the conditional probability that the collapse of the Amazon\nrainforest follows that of the AMOC, given that the Amazon rainforest turns\ninto a savannah within $200$ years.", "AI": {"tldr": "Study shows AMOC collapse is necessary for Amazon rainforest collapse due to drying effect, using coupled climate model and rare-event algorithm.", "motivation": "Investigate how AMOC collapse influences Amazon rainforest dynamics under climate change, as both are critical Earth system components at risk of tipping.", "method": "Used coupled conceptual AMOC-Amazon model tuned with CESM simulations, employing rare-event algorithm to efficiently sample collapse scenarios.", "result": "AMOC collapse is a necessary condition for Amazon rainforest collapse in the basin center due to significant drying effect; quantified conditional probability of tipping cascade.", "conclusion": "The study demonstrates critical interdependence between AMOC and Amazon systems, with AMOC collapse being prerequisite for Amazon collapse, highlighting cascading tipping risks in climate system."}}
{"id": "2508.13538", "pdf": "https://arxiv.org/pdf/2508.13538", "abs": "https://arxiv.org/abs/2508.13538", "authors": ["J\u00fcrgen Geiser"], "title": "Hybrid solver methods for ODEs: Machine-Learning combined with standard methods", "categories": ["math.NA", "cs.NA", "35J60", "F.1.2"], "comment": "8 pages", "summary": "In this article, we consider combined standard and machine learning methods\nto solve ODEs and PDEs. We deal with the minimisation problems for the machine\nlearning algorithms and standard discretization methods, which are related to\nRunge-Kutta methods and finite difference methods. We show, that we could solve\nthe ODEs with additional ML methods, e.g., feedforward network, such that it\nwill accelerate the solver process.", "AI": {"tldr": "Combining standard numerical methods with machine learning to accelerate ODE/PDE solvers", "motivation": "To enhance traditional numerical methods for solving ODEs and PDEs by integrating machine learning techniques to accelerate the solution process", "method": "Integration of standard discretization methods (Runge-Kutta, finite difference) with machine learning algorithms, particularly feedforward networks, through minimization problems", "result": "Demonstrated that machine learning methods can accelerate the solver process for ODEs", "conclusion": "Machine learning techniques can be effectively combined with traditional numerical methods to improve computational efficiency in solving differential equations"}}
{"id": "2508.13299", "pdf": "https://arxiv.org/pdf/2508.13299", "abs": "https://arxiv.org/abs/2508.13299", "authors": ["Dennis Kriventsov", "Mar\u00eda Soria-Carro"], "title": "An Elliptic-Parabolic Free Boundary Problem with Discontinuous Data", "categories": ["math.AP", "35R35, 35K65 (Primary) 35B65 (Secondary)"], "comment": "27 pages, 2 figures", "summary": "We consider an elliptic-parabolic free boundary problem that models the fluid\nflow through a partially saturated porous medium. The free boundary arises as\nthe interface separating the saturated and unsaturated regions. Our main goal\nis to investigate, for the 1+1 dimensional model, how jump discontinuities on\nthe boundary and initial data influence the regularity of both the solution and\nthe free boundary. We show that if the data is merely bounded, then weak\nsolutions are Lipschitz in space and $C^{1/2}$ in time in the unsaturated\nregion. Moreover, the free boundary is locally the graph of a $C^{1/2}$\nfunction, and this regularity is optimal. We view this analysis as a stepping\nstone towards the study of local regularization for higher-dimensional\nelliptic-parabolic free boundaries.", "AI": {"tldr": "Analysis of a 1+1D elliptic-parabolic free boundary problem modeling fluid flow in partially saturated porous media, showing optimal regularity results for solutions and free boundaries with bounded data.", "motivation": "To understand how jump discontinuities in boundary and initial data affect the regularity of solutions and free boundaries in porous media flow problems, serving as foundation for higher-dimensional studies.", "method": "Mathematical analysis of the 1+1 dimensional elliptic-parabolic free boundary problem, examining weak solutions and interface regularity properties.", "result": "Weak solutions are Lipschitz in space and C^{1/2} in time in unsaturated regions; free boundary is locally a C^{1/2} graph, with this regularity being optimal.", "conclusion": "The study provides optimal regularity results for 1D free boundary problems and establishes groundwork for analyzing local regularization in higher-dimensional elliptic-parabolic free boundaries."}}
{"id": "2508.13649", "pdf": "https://arxiv.org/pdf/2508.13649", "abs": "https://arxiv.org/abs/2508.13649", "authors": ["Sagar Dam", "Jian Fuh Ong", "Sk Rakeeb", "Ameya Parab", "Aparajit C", "Anandam", "Amit D Lad", "Yash M Ved", "M Krishnamurthy", "Kazuo A Tanaka", "G Ravindra Kumar"], "title": "Impulsive excitation of a solid by extreme contrast, high intensity femtosecond laser pulses", "categories": ["physics.plasm-ph"], "comment": "5 pages, 4 figures", "summary": "We present the ultra-fast dynamics of the interaction between a\nhigh-intensity extreme contrast (expected to be around 1e-18 at hundreds of\npicoseconds timescale) femtosecond laser and a solid. Simultaneous measurements\nof probe Doppler spectrometry and reflectivity in pump-probe experiments reveal\nthe presence of extreme pressure in the solid density region, which triggers a\nlong-lived (about 15 ps) strong inward shock. Hydrodynamic simulations\naccurately replicate these observations, providing a detailed explanation of\nthe underlying physics", "AI": {"tldr": "Ultra-fast dynamics of high-intensity femtosecond laser-solid interaction reveals extreme pressure and long-lived inward shock formation through pump-probe experiments and hydrodynamic simulations.", "motivation": "To understand the complex interaction dynamics between high-intensity extreme contrast femtosecond lasers and solid materials, particularly the generation of extreme pressures and shock phenomena at ultra-fast timescales.", "method": "Used pump-probe experiments with simultaneous Doppler spectrometry and reflectivity measurements, combined with hydrodynamic simulations to model and explain the observed physical phenomena.", "result": "Discovered the presence of extreme pressure in solid density regions that triggers a long-lived (~15 ps) strong inward shock, with hydrodynamic simulations accurately replicating these experimental observations.", "conclusion": "The study successfully reveals and explains the underlying physics of ultra-fast laser-solid interactions, demonstrating that extreme contrast femtosecond lasers can generate sustained shock phenomena in solids that persist for picosecond timescales."}}
{"id": "2508.13391", "pdf": "https://arxiv.org/pdf/2508.13391", "abs": "https://arxiv.org/abs/2508.13391", "authors": ["Niamh O'Neill", "Benjamin X. Shi", "William Baldwin", "William C. Witt", "G\u00e1bor Cs\u00e1nyi", "Julian D. Gale", "Angelos Michaelides", "Christoph Schran"], "title": "Towards Routine Condensed Phase Simulations with Delta-Learned Coupled Cluster Accuracy: Application to Liquid Water", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Simulating liquid water to an accuracy that matches its wealth of available\nexperimental data requires both precise electronic structure methods and\nreliable sampling of nuclear (quantum) motion. This is challenging because\napplying the electronic structure method of choice - coupled cluster theory\nwith single, double and perturbative triple excitations [CCSD(T)] - to\ncondensed phase systems is currently limited by its computational cost and\ncomplexity. Recent tour-de-force efforts have demonstrated that this accuracy\ncan indeed bring simulated liquid water into close agreement with experiment\nusing machine learning potentials (MLPs). However, achieving this remains far\nfrom routine, requiring large datasets and significant computational cost. In\nthis work, we introduce a practical approach that combines developments in MLPs\nwith local correlation approximations to enable routine CCSD(T)-level\nsimulations of liquid water. When combined with nuclear quantum effects, we\nachieve agreement to experiments for structural and transport properties.\nCrucially, this approach extends beyond constant volume to constant pressure\nsimulations, allowing fundamental properties such as the density to now be\npredicted by MLP-based CCSD(T) models. Importantly, the approach also handles\nconstant pressure simulations, enabling MLP-based CCSD(T) models to predict\nisothermal-isobaric bulk properties, such as water's density maximum in close\nagreement with experiment. Encompassing tests across electronic structure,\ndatasets and MLP architecture, this work provides a practical blueprint towards\nroutinely developing CCSD(T)-based MLPs for the condensed phase.", "AI": {"tldr": "A practical approach combining machine learning potentials with local correlation approximations enables routine CCSD(T)-level simulations of liquid water with quantum nuclear effects, achieving experimental agreement for structural, transport properties and density predictions.", "motivation": "Simulating liquid water accurately requires precise CCSD(T) electronic structure methods but current approaches are computationally expensive and not routine. Recent MLP efforts show promise but remain challenging due to large datasets and high computational costs.", "method": "Combines machine learning potentials (MLPs) with local correlation approximations to enable CCSD(T)-level simulations. Includes nuclear quantum effects and extends to constant pressure simulations for predicting bulk properties like density.", "result": "Achieves agreement with experiments for structural and transport properties. Successfully predicts water's density maximum in close agreement with experiment. Enables routine CCSD(T)-based MLP development for condensed phase systems.", "conclusion": "Provides a practical blueprint for routinely developing CCSD(T)-based machine learning potentials for condensed phase simulations, overcoming previous computational limitations while maintaining high accuracy comparable to experimental data."}}
{"id": "2508.13542", "pdf": "https://arxiv.org/pdf/2508.13542", "abs": "https://arxiv.org/abs/2508.13542", "authors": ["Shweta Kumari", "Mani Mehra"], "title": "A stability-enhanced nonstandard finite difference framework for solving one and two-dimensional nonlocal differential equations", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Standard finite difference (SFD) schemes often suffer from limited stability\nregions, especially when applied in explicit setup to partial differential\nequations. To address this challenge, this study investigates the efficacy of\nnonstandard finite difference (NSFD) schemes in enhancing stability of explicit\nSFD schemes for 1D and 2D Caputo-type time-fractional diffusion equations\n(TFDEs). A nonstandard L1approximation is proposed for the Caputo fractional\nderivative, and its local truncation error is derived analytically. This\nnonstandard L1 formulation is used to construct the NSFD scheme for a\nCaputo-type time-fractional initial value problem. The absolute stability of\nthe resulting scheme is rigorously examined using the boundary locus method,\nand its performance is validated through numerical simulations on test examples\nfor various choices of denominator functions. Based on this framework, two\nexplicit NSFD schemes are developed for 1D and 2D cases of the Caputo-type\nTFDE. Their stability is further assessed through the discrete energy method,\nwith particular focus on the expansion of stability region relative to SFD\nschemes. The convergence of the proposed NSFD schemes is also established.\nFinally, a comprehensive set of numerical experiments is conducted to\ndemonstrate the accuracy and stability advantages of proposed methods, with\nresults presented through tables and graphical illustrations.", "AI": {"tldr": "NSFD schemes enhance stability of explicit finite difference methods for time-fractional diffusion equations using nonstandard L1 approximation for Caputo derivatives, showing expanded stability regions and improved accuracy.", "motivation": "Standard finite difference schemes suffer from limited stability regions when applied explicitly to partial differential equations, particularly for time-fractional diffusion equations.", "method": "Proposed nonstandard L1 approximation for Caputo fractional derivative, constructed NSFD schemes for 1D/2D TFDEs, analyzed stability using boundary locus and discrete energy methods, validated through numerical simulations.", "result": "The NSFD schemes demonstrated expanded stability regions compared to standard FD schemes, maintained convergence, and showed improved accuracy and stability in numerical experiments across various denominator functions.", "conclusion": "Nonstandard finite difference schemes provide an effective approach to enhance stability of explicit methods for time-fractional diffusion equations while maintaining accuracy and convergence properties."}}
{"id": "2508.13322", "pdf": "https://arxiv.org/pdf/2508.13322", "abs": "https://arxiv.org/abs/2508.13322", "authors": ["Oluwadamilola Fasina"], "title": "D-tensor paraproducts and its caricatures", "categories": ["math.AP", "cs.NA", "math.NA"], "comment": "25 pages, 4 figures, 1 table", "summary": "We generalize the $2$-tensor paraproduct decomposition result of\narXiv:2503.12629 to $d$-tensors and expound on its caricatures. In particular,\nwe show that for $A \\in C^{d}, f \\in \\Lambda^{\\alpha}([0,1]^d)$, $A(f)$ has an\napproximation $\\tilde{A}(f) = (\\sum_{\\alpha=1}^d A^{\\alpha}(P^{j_1,j_2, \\ldots,\nj_d}(f)) \\tilde{\\mathbf{v}}^{\\alpha}(f) ) $ for a fixed sequence of scales,\n$\\mathbf{j} = (j_1, j_2, \\ldots, j_d)$, and the series $\\sum_{\\alpha=1}^d\nA^{\\alpha}(P^{j_1,j_2, \\ldots, j_d}(f)) \\tilde{\\mathbf{v}}^{\\alpha}(f) $ is a\ntaylor expansion of $A$. Additionally, we show the sequence of operators\n$(\\tilde{\\mathbf{v}}^1(f),\\tilde{\\mathbf{v}}^2(f), \\ldots,\n\\tilde{\\mathbf{v}}^d(f))$ form a basis for the subspace comprised of linear\nfunctionals of the form $A(f)$, and the residual, $\\Delta(A,f) = \\tilde{A}(f) -\nA(f) \\in \\Lambda^{2\\alpha}([0,1]^d)$. Consequentially, we show one can obtain a\nCalderon-Zygmund type decomposition, $\\Delta(A,f)_\\lambda +\n\\tilde{A}(f)_{\\lambda}$ with the obtained paraproduct decomposition $A(f) =\n\\Delta(A,f) + \\tilde{A}(f)$. Our theoretical findings are supported by\ncomputational examples for d=2,3.", "AI": {"tldr": "Generalization of 2-tensor paraproduct decomposition to d-tensors with Taylor expansion approximation and Calderon-Zygmund type decomposition", "motivation": "Extend previous 2-tensor paraproduct decomposition results to higher-dimensional d-tensors and establish theoretical foundations for approximation methods", "method": "Develop d-tensor paraproduct decomposition showing A(f) can be approximated by sum of A^\u03b1(P^{j}(f))v^\u03b1(f) terms, forming a basis for linear functionals, with residual analysis", "result": "Successfully generalized decomposition to d-tensors, proved residual \u0394(A,f) \u2208 \u039b^{2\u03b1}, obtained Calderon-Zygmund type decomposition, and validated with computational examples for d=2,3", "conclusion": "The d-tensor paraproduct decomposition provides a complete theoretical framework with approximation guarantees and basis representation properties, supported by computational evidence"}}
{"id": "2508.13695", "pdf": "https://arxiv.org/pdf/2508.13695", "abs": "https://arxiv.org/abs/2508.13695", "authors": ["J. R. Allison", "R. Bordas", "J. Read", "G. Burdiak", "V. Beltr\u00e1n", "N. Joiner", "H. Doyle", "N. Hawker", "J. Skidmore", "T. Ao", "A. Porwitzky", "D. Dolan", "B. Farfan", "C. Johnson", "A. Hansen"], "title": "A Bayesian approach to time-domain Photonic Doppler Velocimetry", "categories": ["physics.plasm-ph", "physics.data-an", "physics.ins-det"], "comment": "14 pages, 9 figures, manuscript accepted on 23rd July 2025 for\n  publication in Review of Scientific Instruments", "summary": "Photonic Doppler Velocimetry (PDV) is an established technique for measuring\nthe velocities of fast-moving surfaces in high-energy-density experiments. In\nthe standard approach to PDV analysis, a short-time Fourier transform (STFT) is\nused to generate a spectrogram from which the velocity history of the target is\ninferred. The user chooses the form, duration and separation of the window\nfunction. Here we present a Bayesian approach to infer the velocity directly\nfrom the PDV oscilloscope trace, without using the spectrogram for analysis.\nThis is clearly a difficult inference problem due to the highly-periodic nature\nof the data, but we find that with carefully chosen prior distributions for the\nmodel parameters we can accurately recover the injected velocity from synthetic\ndata. We validate this method using PDV data collected at the STAR two-stage\nlight gas gun at Sandia National Laboratories, recovering shock-front\nvelocities in quartz that are consistent with those inferred using the\nSTFT-based approach, and are interpolated across regions of low signal-to-noise\ndata. Although this method does not rely on the same user choices as the STFT,\nwe caution that it can be prone to misspecification if the chosen model is not\nsufficient to capture the velocity behavior. Analysis using posterior\npredictive checks can be used to establish if a better model is required,\nalthough more complex models come with additional computational cost, often\ntaking more than several hours to converge when sampling the Bayesian\nposterior. We therefore recommend it be viewed as a complementary method to\nthat of the STFT-based approach.", "AI": {"tldr": "Bayesian approach for Photonic Doppler Velocimetry analysis that infers velocity directly from oscilloscope data without spectrograms, validated against traditional STFT methods with consistent results but longer computation times.", "motivation": "Standard PDV analysis using short-time Fourier transform requires user-chosen window parameters and can be affected by low signal-to-noise regions, motivating a more direct inference method.", "method": "Bayesian inference approach that directly analyzes PDV oscilloscope traces using carefully chosen prior distributions for model parameters, avoiding spectrogram generation.", "result": "Successfully recovered shock-front velocities in quartz consistent with STFT-based approach, with improved interpolation across low signal-to-noise regions, though computationally intensive (several hours for convergence).", "conclusion": "The Bayesian method serves as a complementary approach to STFT-based analysis, requiring careful model specification and posterior predictive checks, but providing direct velocity inference without user-defined window parameters."}}
{"id": "2508.13468", "pdf": "https://arxiv.org/pdf/2508.13468", "abs": "https://arxiv.org/abs/2508.13468", "authors": ["Jiashu Liang", "Martin Head-Gordon"], "title": "Gold-Standard Chemical Database 138 (GSCDB138): A diverse set of accurate energy differences for assessing and developing density functionals", "categories": ["physics.chem-ph", "physics.comp-ph", "quant-ph"], "comment": null, "summary": "We present GSCDB138, a rigorously curated benchmark library of 138 data sets\n(8383 entries) covering main-group and transition-metal reaction energies and\nbarrier heights, non-covalent interactions, dipole moments, polarizabilities,\nelectric-field response energies, and vibrational frequencies. Legacy data from\nGMTKN55 and MGCDB84 have been updated to today's best reference values;\nredundant, spincontaminated, or low-quality points were removed, and many new,\nproperty-focused sets were added. Testing 29 popular density-functional\napproximations shows the expected Jacob's-ladder hierarchy overall, yet reveals\ninteresting exceptions: r2SCAN-D4 (meta-GGA) rivals hybrids for frequencies,\nand electric-field errors correlate poorly with ground-state energetics.\n{\\omega}B97M-V and {\\omega}B97X-V are the most balanced hybrid meta-GGA and\nhybrid GGA, respectively; B97M-V and revPBE-D4 lead the metaGGA and GGA\nclasses. Double hybrids lower mean errors by about 25 % versus the best hybrids\nbut demand careful frozen-core, basis-set, and multi-reference treatment.\nGSCDB138 offers a comprehensive, openly documented platform for stringent DFA\nvalidation and for training the next generation of non-empirical and\nmachine-learned functionals.", "AI": {"tldr": "GSCDB138 is a comprehensive benchmark library of 138 datasets with 8383 entries covering various chemical properties, providing updated reference values and serving as a rigorous platform for density functional approximation validation and training.", "motivation": "To create a rigorously curated benchmark for validating density functional approximations (DFAs) by updating legacy data, removing low-quality entries, and adding new property-focused datasets to address gaps in existing benchmarks.", "method": "Curated 138 datasets (8383 entries) covering main-group and transition-metal reaction energies, barrier heights, non-covalent interactions, dipole moments, polarizabilities, electric-field response energies, and vibrational frequencies. Updated legacy data from GMTKN55 and MGCDB84 to current best reference values, removed redundant/spin-contaminated/low-quality points, and added new property-focused sets.", "result": "Testing 29 popular DFAs revealed expected Jacob's-ladder hierarchy with exceptions: r2SCAN-D4 rivals hybrids for frequencies, electric-field errors poorly correlate with ground-state energetics. \u03c9B97M-V and \u03c9B97X-V are most balanced hybrid meta-GGA and hybrid GGA respectively; B97M-V and revPBE-D4 lead meta-GGA and GGA classes. Double hybrids reduce mean errors by ~25% vs best hybrids but require careful treatment.", "conclusion": "GSCDB138 provides a comprehensive, openly documented platform for stringent DFA validation and training next-generation non-empirical and machine-learned functionals, addressing the need for rigorous benchmarking across diverse chemical properties."}}
{"id": "2508.13550", "pdf": "https://arxiv.org/pdf/2508.13550", "abs": "https://arxiv.org/abs/2508.13550", "authors": ["Anthony Chen", "Robert Krasny"], "title": "A Cubed Sphere Fast Multipole Method", "categories": ["math.NA", "cs.NA", "65D30 (primary), 65N80, 86-08 (Secondary)"], "comment": null, "summary": "This work describes a new version of the Fast Multipole Method for summing\npairwise particle interactions that arise from discretizing integral transforms\nand convolutions on the sphere. The kernel approximations use barycentric\nLagrange interpolation on a quadtree composed of cubed sphere grid cells. The\nscheme is kernel-independent and requires kernel evaluations only at points on\nthe sphere. Results are presented for the Poisson and biharmonic equations on\nthe sphere, barotropic vorticity equation on a rotating sphere, and\nself-attraction and loading potential in tidal calculations. A tree code\nversion is also described for comparison, and both schemes are tested in serial\nand parallel calculations.", "AI": {"tldr": "New Fast Multipole Method for spherical pairwise particle interactions using barycentric Lagrange interpolation on cubed sphere grid cells, kernel-independent approach with applications to Poisson/biharmonic equations, vorticity, and tidal calculations.", "motivation": "To develop an efficient method for summing pairwise particle interactions on spherical surfaces that arise from discretizing integral transforms and convolutions, with applications in geophysical and mathematical problems.", "method": "Uses barycentric Lagrange interpolation on a quadtree structure composed of cubed sphere grid cells, creating a kernel-independent scheme that only requires kernel evaluations at points on the sphere.", "result": "Successfully applied to Poisson and biharmonic equations on the sphere, barotropic vorticity equation on rotating sphere, and self-attraction/loading potential in tidal calculations. Both serial and parallel implementations tested.", "conclusion": "The method provides an efficient, kernel-independent approach for spherical pairwise interactions with broad applicability to geophysical and mathematical problems involving spherical domains."}}
{"id": "2508.13338", "pdf": "https://arxiv.org/pdf/2508.13338", "abs": "https://arxiv.org/abs/2508.13338", "authors": ["Duv\u00e1n Cardona", "Manuel Mart\u00ednez"], "title": "Estimates for pseudo-differential operators on the torus revisited. III", "categories": ["math.AP", "22E30, 58J40"], "comment": "19 pages", "summary": "This paper finishes the goal of the authors started in two previous\nmanuscripts dedicated to revisiting the continuity properties of toroidal\npseudo-differential operators with symbols in the H\\\"ormander classes. Here we\nprove pointwise estimates in terms of the Fefferman-Stein sharp maximal\nfunction and of the Hardy-Littlewood maximal function. Combining these\nestimates with the properties of Muckenhoupt's weight class $A_p$ we obtain\nboundedness theorems for pseudo-differential operators between weighted\nLebesgue spaces on the torus $L^p(w)$. These results are given in the context\nof the global symbolic analysis defined on $\\mathbb{T}^n\\times \\mathbb{Z}^n$ as\ndeveloped by Ruzhansky and Turunen by using discrete Fourier analysis, and\nextend those of Park and Tomita available in the Euclidean case. Moreover, we\ninclude continuity results on Sobolev spaces $W^s_p$ and on Besov spaces\n$B^s_{p,q}$ on the torus. Our techniques are taken from Park and Tomita\n\\cite{park-tomita} and we consider its toroidal extension here for the\ncompleteness of the boundedness of toroidal pseudo-differential operators with\nrespect to the current literature.", "AI": {"tldr": "This paper completes the authors' work on continuity properties of toroidal pseudo-differential operators, proving pointwise estimates using Fefferman-Stein sharp maximal function and Hardy-Littlewood maximal function, and establishing boundedness theorems for weighted Lebesgue spaces on the torus.", "motivation": "To extend and complete the analysis of continuity properties for toroidal pseudo-differential operators that was started in previous manuscripts, and to provide boundedness results in the context of global symbolic analysis on the torus.", "method": "The authors use techniques from Park and Tomita, proving pointwise estimates with Fefferman-Stein sharp maximal function and Hardy-Littlewood maximal function, combined with properties of Muckenhoupt's weight class A_p.", "result": "Boundedness theorems for pseudo-differential operators between weighted Lebesgue spaces L^p(w) on the torus, along with continuity results on Sobolev spaces W^s_p and Besolev spaces B^s_{p,q}.", "conclusion": "The paper successfully extends Euclidean case results to the toroidal setting, providing comprehensive boundedness results for toroidal pseudo-differential operators and completing the authors' previous work on this topic."}}
{"id": "2508.13858", "pdf": "https://arxiv.org/pdf/2508.13858", "abs": "https://arxiv.org/abs/2508.13858", "authors": ["Loann Terraz", "Biruk Alemu", "Santiago Eizaguirre"], "title": "Numerical simulations of a RF-RF hybrid plasma torch with argon at atmospheric pressure", "categories": ["physics.plasm-ph"], "comment": null, "summary": "We report numerical results regarding the minimum sustaining coil excitation\ncurrent for a RF-RF hybrid torch operating at two different frequencies. The\nfirst coil is excited at a high-frequency, while the second coil is set at a\nmedium frequency. The filling gas is argon, at atmospheric pressure. We use the\nmodeling software COMSOL Multiphysics to describe the evolution of key\nparameters when: (i) the distance between the two coils changes, (ii) the power\nof the high frequency coil changes. We discuss the radial temperature profiles,\nthe axial velocities and the heat convected at the end of the medium-frequency\ncoil. The latter is compared with the total heat conduction to the plasma\nconfinement tube wall.", "AI": {"tldr": "Numerical analysis of RF-RF hybrid torch operation showing how coil distance and high-frequency power affect minimum sustaining current, temperature profiles, velocities, and heat transfer.", "motivation": "To understand the operational characteristics and optimize the performance of RF-RF hybrid torches operating at different frequencies by studying key parameters under varying conditions.", "method": "Used COMSOL Multiphysics modeling software to simulate argon plasma at atmospheric pressure, analyzing coil distance variations and high-frequency power changes on sustaining current requirements.", "result": "Obtained detailed evolution of radial temperature profiles, axial velocities, and heat convection at medium-frequency coil end, with comparison to total heat conduction to plasma confinement tube wall.", "conclusion": "The study provides valuable numerical insights into RF-RF hybrid torch behavior, demonstrating how coil configuration and power settings influence plasma sustainability and heat transfer characteristics."}}
{"id": "2508.13521", "pdf": "https://arxiv.org/pdf/2508.13521", "abs": "https://arxiv.org/abs/2508.13521", "authors": ["Ahasan Ahamed", "Htet Myat", "Amita Rawat", "Lisa N McPhillips", "M Saif Islam"], "title": "AI-Augmented Photon-Trapping Spectrometer-on-a-Chip on Silicon Platform with Extended Near-Infrared Sensitivity", "categories": ["physics.optics", "eess.SP", "physics.comp-ph"], "comment": "Article: 24 pages, 8 figures, 1 table Supplementary: 8 pages, 6\n  figures, 1 table Submitted to Advanced Photonics (SPIE), currently under\n  review", "summary": "We present a compact, noise-resilient reconstructive spectrometer-on-a-chip\nthat achieves high-resolution hyperspectral imaging across an extended\nnear-infrared (NIR) range up to 1100nm. The device integrates monolithically\nfabricated silicon photodiodes enhanced with photon-trapping surface textures\n(PTST), enabling improved responsivity in the low-absorption NIR regime.\nLeveraging a fully connected neural network, we demonstrate accurate spectral\nreconstruction from only 16 uniquely engineered detectors, achieving <0.05 RMSE\nand 8nm resolution over a wide spectral range of 640nm to 1100nm. Our system\noutperforms conventional spectrometers, maintaining signal-to-noise ratio above\n30dB even with 40dB of added detector noise; extending functionality to longer\nwavelengths up to 1100nm, while the traditional spectrometers fail to perform\nbeyond 950nm due to poor detector efficiency and noise performance. With a\nfootprint of 0.4mm2, dynamic range of 50dB, ultrafast time response (57ps), and\nhigh photodiode gain (>7000), this AI-augmented silicon spectrometer is\nwell-suited for portable, real-time, and low-light applications in biomedical\nimaging, environmental monitoring, and remote sensing. The results establish a\npathway toward fully integrated, high-performance hyperspectral sensing in a\nCMOS-compatible platform.", "AI": {"tldr": "Compact AI-enhanced silicon spectrometer with photon-trapping photodiodes achieves high-resolution NIR hyperspectral imaging up to 1100nm using only 16 detectors and neural network reconstruction.", "motivation": "Traditional spectrometers fail beyond 950nm due to poor detector efficiency and noise, limiting NIR applications. There's a need for compact, noise-resilient spectrometers for portable real-time applications.", "method": "Monolithically fabricated silicon photodiodes with photon-trapping surface textures for improved NIR responsivity, combined with a fully connected neural network for spectral reconstruction from 16 engineered detectors.", "result": "Achieves <0.05 RMSE and 8nm resolution over 640-1100nm range, maintains >30dB SNR even with 40dB added noise, 0.4mm2 footprint, 50dB dynamic range, 57ps response time, and >7000 photodiode gain.", "conclusion": "The AI-augmented silicon spectrometer enables high-performance hyperspectral sensing in CMOS-compatible platform, suitable for biomedical imaging, environmental monitoring, and remote sensing applications."}}
{"id": "2508.13631", "pdf": "https://arxiv.org/pdf/2508.13631", "abs": "https://arxiv.org/abs/2508.13631", "authors": ["Jonas Beddrich", "Barbara Wohlmuth"], "title": "A kernel compression method for distributed-order fractional partial differential equations", "categories": ["math.NA", "cs.NA", "34A08, 35R11, 65R10, 74S40"], "comment": null, "summary": "We propose a kernel compression method for solving Distributed-Order (DO)\nFractional Partial Differential Equations (DOFPDEs) at the cost of solving\ncorresponding local-in-time PDEs. The key concepts are (1) discretization of\nthe integral over the order of the fractional derivative and (2) approximation\nof linear combinations of integral kernels with exponential sums, expressing\nthe non-local history term as a sum of auxiliary variables that solve a weakly\ncoupled, local in time system of PDEs. For the second step, we introduce an\nimproved algorithm that approximates the occurring integral kernels with double\nprecision accuracy using only a moderate number (<100) of exponential terms.\nAfter temporal discretization using implicit Runge--Kutta methods, we exploit\nthe inherent structure of the PDE system to obtain the solution at each time\nstep by solving a single PDE. At the same time, the auxiliary variables are\ncomputed by a linear update, not even requiring a matrix-vector multiplication.\nChoosing temporal meshes with a grading factor corresponding to the convergence\norder of the Runge--Kutta schemes, we achieve the optimal decay of the temporal\ndiscretization error. The flexibility and robustness of our numerical scheme\nare illustrated by recreating well-studied test cases and solving linear and\nnonlinear DOFPDEs in 2D and 3D with up to 40 million spatial degrees of\nfreedom.", "AI": {"tldr": "A kernel compression method for solving distributed-order fractional PDEs by approximating non-local history terms with exponential sums, enabling efficient solution as local-in-time PDE systems with optimal temporal error decay.", "motivation": "To efficiently solve distributed-order fractional PDEs which are computationally expensive due to their non-local nature, by transforming them into equivalent local-in-time systems that are more tractable.", "method": "Discretize the fractional derivative order integral, approximate integral kernels with exponential sums using an improved algorithm, use implicit Runge-Kutta temporal discretization, and exploit PDE structure to solve single PDE per time step with linear updates for auxiliary variables.", "result": "Achieved double precision accuracy with <100 exponential terms, solved linear and nonlinear DOFPDEs in 2D/3D with up to 40 million spatial degrees of freedom, demonstrating optimal temporal error decay with graded meshes.", "conclusion": "The method provides a flexible and robust numerical scheme that effectively handles the computational challenges of distributed-order fractional PDEs by converting non-local problems into local systems while maintaining high accuracy and efficiency."}}
{"id": "2508.13441", "pdf": "https://arxiv.org/pdf/2508.13441", "abs": "https://arxiv.org/abs/2508.13441", "authors": ["Olga Turanova", "Yuming Paul Zhang"], "title": "A Hele-Shaw problem with interior and free boundary oscillation: well-posedness and homogenization", "categories": ["math.AP"], "comment": "50 pages, 2 figures", "summary": "We investigate a Hele-Shaw type free boundary problem in one spatial\ndimension, where heterogeneities appear both on the free boundary and within\nthe interior of the positivity set. Our contributions are twofold. First, we\nestablish well-posedness and a comparison principle for the problem by\nintroducing a novel notion of viscosity flows. Second, under the assumption\nthat the coefficients are stationary ergodic, we prove a stochastic\nhomogenization result. Our results are new even in the periodic setting. To\nderive the effective free boundary velocity, we use a new approximation that\naccounts for both interior homogenization and free boundary propagation.", "AI": {"tldr": "Analysis of a 1D Hele-Shaw free boundary problem with heterogeneities on both boundary and interior, establishing well-posedness and stochastic homogenization results.", "motivation": "To address free boundary problems with heterogeneities appearing both on the free boundary and within the interior domain, which presents unique mathematical challenges not fully covered by existing literature.", "method": "Introduces novel viscosity flows concept for well-posedness and comparison principle, and develops a new approximation approach combining interior homogenization with free boundary propagation for stochastic homogenization.", "result": "Established well-posedness and comparison principle for the heterogeneous free boundary problem, and proved stochastic homogenization under stationary ergodic coefficients assumption, with results being novel even for periodic settings.", "conclusion": "The paper provides fundamental mathematical foundations for heterogeneous free boundary problems through innovative viscosity flow concepts and effective homogenization techniques that handle both interior and boundary heterogeneities simultaneously."}}
{"id": "2508.13494", "pdf": "https://arxiv.org/pdf/2508.13494", "abs": "https://arxiv.org/abs/2508.13494", "authors": ["Jiazhen Gan", "Chuanbing Wang"], "title": "A Monte Carlo simulation on the scattering coefficients of solar radio wave propagation", "categories": ["astro-ph.SR", "physics.plasm-ph", "physics.space-ph"], "comment": null, "summary": "Radio waves undergo scattering by small-scale density fluctuations during\npropagation through the solar-terrestrial environment, substantially affecting\nthe observed characteristics of solar radio bursts. This scattering process can\nbe effectively modeled as photon diffusion in phase space. In this study, we\npresent a comprehensive comparison between the quasilinear diffusion\ncoefficients and those calculated by ray-tracing the photon trajectories in\nnumerically generated, broadband, isotropic density fluctuation fields in both\ntwo-dimensional (2D) and three-dimensional (3D) configurations. The comparative\nanalysis demonstrates that for weak scattering, the simulated diffusion\ncoefficients agree well with the quasilinear theoretical predictions. However,\nwhen the radio frequency approaches the electron plasma frequency and/or the\ndensity fluctuation amplitude becomes significant, photons experience strong\nscattering. Under such conditions, the quasilinear theory tends to\nunderestimate the scattering strength of photons induced by 2D density\nfluctuations while overestimating the scattering strength in 3D cases.\nFurthermore, we implement a group velocity correction to the theoretical\ndiffusion coefficients, based on the effective propagation speed averaged over\nall test photons. The corrected coefficients provide an accurate quantification\nof the scattering strength for radio waves propagating through 3D density\nfluctuations. The physical mechanisms underlying these phenomena are elucidated\nin the discussion.", "AI": {"tldr": "Comparison of quasilinear diffusion coefficients with ray-tracing simulations for radio wave scattering in solar-terrestrial environment, showing agreement for weak scattering but discrepancies in strong scattering conditions between 2D and 3D density fluctuations.", "motivation": "Radio wave scattering by small-scale density fluctuations significantly affects solar radio burst observations, and current quasilinear theory may not accurately model strong scattering conditions.", "method": "Comprehensive comparison between quasilinear diffusion coefficients and ray-tracing simulations of photon trajectories in numerically generated broadband isotropic density fluctuation fields in both 2D and 3D configurations.", "result": "For weak scattering, simulations agree with quasilinear theory. For strong scattering (radio frequency near electron plasma frequency or large density fluctuations), quasilinear theory underestimates scattering in 2D but overestimates in 3D. Group velocity correction improves accuracy for 3D cases.", "conclusion": "Quasilinear theory has limitations in strong scattering regimes, requiring corrections for accurate modeling. The study provides improved quantification of radio wave scattering strength through density fluctuations with physical mechanisms explained."}}
{"id": "2508.13523", "pdf": "https://arxiv.org/pdf/2508.13523", "abs": "https://arxiv.org/abs/2508.13523", "authors": ["Anders Johansson", "Evan Weinberg", "Christian R. Trott", "Megan J. McCarthy", "Stan G. Moore"], "title": "LAMMPS-KOKKOS: Performance Portable Molecular Dynamics Across Exascale Architectures", "categories": ["cs.DC", "cs.PF", "physics.comp-ph", "C.1.4; C.2.4; C.4; D.1.3; D.3.4; E.1; I.6; I.6.8; J.2"], "comment": "14 pages, 6 figures", "summary": "Since its inception in 1995, LAMMPS has grown to be a world-class molecular\ndynamics code, with thousands of users, over one million lines of code, and\nmulti-scale simulation capabilities. We discuss how LAMMPS has adapted to the\nmodern heterogeneous computing landscape by integrating the Kokkos performance\nportability library into the existing C++ code. We investigate performance\nportability of simple pairwise, many-body reactive, and machine-learned\nforce-field interatomic potentials. We present results on GPUs across different\nvendors and generations, and analyze performance trends, probing FLOPS\nthroughput, memory bandwidths, cache capabilities, and thread-atomic operation\nperformance. Finally, we demonstrate strong scaling on all current US exascale\nmachines -- OLCF Frontier, and ALCF Aurora, and NNSA El Capitan -- for the\nthree potentials.", "AI": {"tldr": "LAMMPS molecular dynamics code integrates Kokkos library for performance portability across modern heterogeneous computing systems, demonstrating strong scaling on exascale machines with various interatomic potentials.", "motivation": "To adapt the widely-used LAMMPS molecular dynamics code to modern heterogeneous computing environments and achieve performance portability across different hardware architectures including GPUs from various vendors.", "method": "Integration of the Kokkos performance portability library into the existing C++ LAMMPS codebase, with performance analysis of pairwise, many-body reactive, and machine-learned force-field interatomic potentials across different GPU architectures.", "result": "Achieved strong scaling performance on all current US exascale machines (OLCF Frontier, ALCF Aurora, NNSA El Capitan) for the three types of interatomic potentials, with detailed analysis of FLOPS throughput, memory bandwidths, cache capabilities, and thread-atomic operation performance.", "conclusion": "The integration of Kokkos successfully enables LAMMPS to achieve performance portability across modern heterogeneous computing systems, making it capable of efficiently utilizing current and future exascale computing resources."}}
{"id": "2508.13683", "pdf": "https://arxiv.org/pdf/2508.13683", "abs": "https://arxiv.org/abs/2508.13683", "authors": ["Mukul Dwivedi", "Andreas Rupp"], "title": "A convergent Fourier spectral Galerkin method for the fractional Camassa-Holm equation", "categories": ["math.NA", "cs.NA", "35R11, 65M12, 65M60, 35L65"], "comment": null, "summary": "We analyze a Fourier spectral Galerkin method for the fractional Camassa-Holm\n(fCH) equation involving a fractional Laplacian of exponent $\\alpha \\in [1,2]$\nwith periodic boundary conditions. The semi-discrete scheme preserves both mass\nand energy invariants of the fCH equation. For the fractional\nBenjamin-Bona-Mahony reduction, we establish existence and uniqueness of\nsemi-discrete solutions and prove strong convergence to the unique solution in\n$ C^1([0, T];H^{\\alpha}_{\\mathrm{per}}(I))$ for given $T>0$. For the general\nfCH equation, we demonstrate spectral accuracy in spatial discretization with\noptimal error estimates $\\mathcal{O}(N^{-r})$ for initial data $u_0 \\in H^r(I)$\nwith $r \\geq \\alpha + 2$ and exponential convergence $\\mathcal{O}(e^{-cN})$ for\nsmooth solutions. Numerical experiments validate orbital stability of solitary\nwaves achieving optimal convergence, confirming theoretical findings.", "AI": {"tldr": "Fourier spectral Galerkin method for fractional Camassa-Holm equation preserves mass/energy invariants, achieves spectral accuracy with optimal error estimates and exponential convergence for smooth solutions.", "motivation": "To develop a numerical method for the fractional Camassa-Holm equation that preserves its fundamental invariants (mass and energy) while providing high accuracy and convergence properties.", "method": "Fourier spectral Galerkin method with periodic boundary conditions for fractional Camassa-Holm equation involving fractional Laplacian (\u03b1 \u2208 [1,2]), preserving mass and energy invariants.", "result": "Semi-discrete scheme preserves invariants; achieves optimal error estimates O(N^{-r}) for H^r initial data (r \u2265 \u03b1+2) and exponential convergence O(e^{-cN}) for smooth solutions; numerical experiments confirm orbital stability and optimal convergence.", "conclusion": "The Fourier spectral Galerkin method is effective for fractional Camassa-Holm equation, preserving invariants while providing spectral accuracy and optimal convergence rates, validated by numerical experiments."}}
{"id": "2508.13539", "pdf": "https://arxiv.org/pdf/2508.13539", "abs": "https://arxiv.org/abs/2508.13539", "authors": ["Wei Dai", "Lixiu Duan", "Changfeng Gui", "Yuan Li"], "title": "Non-radial solutions for the critical quasi-linear H\u00e9non equation involving $p$-Laplacian in $\\R^N$", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we investigate the following $D^{1,p}$-critical quasi-linear\nH\\'enon equation involving $p$-Laplacian \\begin{equation*}\\label{00} \\left\\{\n\\begin{aligned} &-\\Delta_p u=|x|^{\\alpha}u^{p_\\al^*-1}, & x\\in \\R^N, \\\\ &u>0, &\nx\\in \\R^N, \\end{aligned} \\right. \\end{equation*} where $N\\geq2$, $1<p<N$,\n$p_\\al^*:=\\frac{p(N+\\al)}{N-p}$ and $\\alpha>0$. By carefully studying the\nlinearized problem and applying the approximation method and bifurcation\ntheory, we prove that, when the parameter $\\al$ takes the critical values\n$\\al(k):=\\frac{p\\sqrt{(N+p-2)^2+4(k-1)(p-1)(k+N-1)}-p(N+p-2)}{2(p-1)}$ for\n$k\\geq2$, the above quasi-linear H\\'enon equation admits non-radial solutions\n$u$ such that $u\\sim |x|^{-\\frac{N-p}{p-1}}$ and $|\\nabla u|\\sim\n|x|^{-\\frac{N-1}{p-1}}$ at $\\infty$. One should note that, $\\alpha(k)=2(k-1)$\nfor $k\\geq2$ when $p=2$. Our results successfully extend the classical work of\nF. Gladiali, M. Grossi, and S. L. N. Neves in \\cite{GGN} concerning the Laplace\noperator (i.e., the case $p=2$) to the more general setting of the nonlinear\n$p$-Laplace operator ($1<p<N$). We overcome a series of crucial difficulties,\nincluding the nonlinear feature of the $p$-Laplacian $\\Delta_p$, the absence of\nKelvin type transforms and the lack of the Green integral representation\nformula.", "AI": {"tldr": "This paper extends classical results on non-radial solutions for H\u00e9non equations from the Laplace operator (p=2) to the p-Laplace operator (1<p<N), proving existence of non-radial solutions at critical parameter values \u03b1(k) with specific asymptotic behavior.", "motivation": "To generalize the classical work on H\u00e9non equations involving Laplace operators to the more challenging nonlinear p-Laplace operator setting, overcoming difficulties like nonlinearity, absence of Kelvin transforms, and lack of Green representation formulas.", "method": "Careful study of the linearized problem combined with approximation methods and bifurcation theory to analyze the D^{1,p}-critical quasi-linear H\u00e9non equation with p-Laplacian.", "result": "Proved that when \u03b1 takes critical values \u03b1(k) for k\u22652, the equation admits non-radial solutions with specific asymptotic behavior u~|x|^{-(N-p)/(p-1)} and |\u2207u|~|x|^{-(N-1)/(p-1)} at infinity.", "conclusion": "Successfully extended classical Laplace operator results to p-Laplace operators, providing a significant generalization while overcoming substantial technical challenges inherent to the nonlinear p-Laplacian framework."}}
{"id": "2508.13559", "pdf": "https://arxiv.org/pdf/2508.13559", "abs": "https://arxiv.org/abs/2508.13559", "authors": ["Sukheon Kang", "Youngkwon Kim", "Jinkyu Yang", "Seunghwa Ryu"], "title": "Physics-Informed Neural Networks for Programmable Origami Metamaterials with Controlled Deployment", "categories": ["cond-mat.soft", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "Origami-inspired structures provide unprecedented opportunities for creating\nlightweight, deployable systems with programmable mechanical responses.\nHowever, their design remains challenging due to complex nonlinear mechanics,\nmultistability, and the need for precise control of deployment forces. Here, we\npresent a physics-informed neural network (PINN) framework for both forward\nprediction and inverse design of conical Kresling origami (CKO) without\nrequiring pre-collected training data. By embedding mechanical equilibrium\nequations directly into the learning process, the model predicts complete\nenergy landscapes with high accuracy while minimizing non-physical artifacts.\nThe inverse design routine specifies both target stable-state heights and\nseparating energy barriers, enabling freeform programming of the entire energy\ncurve. This capability is extended to hierarchical CKO assemblies, where\nsequential layer-by-layer deployment is achieved through programmed barrier\nmagnitudes. Finite element simulations and experiments on physical prototypes\nvalidate the designed deployment sequences and barrier ratios, confirming the\nrobustness of the approach. This work establishes a versatile, data-free route\nfor programming complex mechanical energy landscapes in origami-inspired\nmetamaterials, offering broad potential for deployable aerospace systems,\nmorphing structures, and soft robotic actuators.", "AI": {"tldr": "A physics-informed neural network framework for forward prediction and inverse design of conical Kresling origami without training data, enabling programmable energy landscapes and hierarchical deployment sequences.", "motivation": "Origami-inspired structures offer lightweight, deployable systems but face design challenges due to complex nonlinear mechanics, multistability, and precise deployment force control requirements.", "method": "Physics-informed neural network (PINN) framework that embeds mechanical equilibrium equations directly into learning, enabling both forward prediction and inverse design without pre-collected training data.", "result": "The model accurately predicts complete energy landscapes, enables freeform programming of entire energy curves with specified stable-state heights and energy barriers, and successfully designs hierarchical assemblies with sequential deployment.", "conclusion": "This work establishes a versatile, data-free approach for programming complex mechanical energy landscapes in origami metamaterials, with broad applications in aerospace systems, morphing structures, and soft robotics."}}
{"id": "2508.13824", "pdf": "https://arxiv.org/pdf/2508.13824", "abs": "https://arxiv.org/abs/2508.13824", "authors": ["I. S. Popov"], "title": "Theory and internal structure of ADER-DG method for ordinary differential equations", "categories": ["math.NA", "cs.NA", "math.SP", "physics.app-ph", "physics.comp-ph", "65L05, 65L60, 65L20, 65L06"], "comment": "20 pages, 2 figures, 2 tables", "summary": "Investigation of the approximation properties, convergence, and stability of\nthe ADER-DG method for solving an ODE system is carried out. The ADER-DG method\ngenerates a new implicit RK method, which is similar in its properties to the\noriginal ADER-DG method. The ADER-DG method has an approximation order $2N+1$\nwhen using polynomials of degree $N$ for the numerical solution at grid nodes,\nand demonstrates superconvergence. The local solution obtained by the local DG\npredictor has an approximation order $N+1$ and has a subgrid resolution. The\nADER-DG method is $A$- and $AN$-stable, $L$-stable, $B$- and $BN$-stable, and\nalgebraically stable. Applications of the ADER-DG method demonstrated\ncompliance with the expected theoretical results.", "AI": {"tldr": "Analysis of ADER-DG method's approximation properties, convergence, and stability for ODE systems, showing high-order accuracy and multiple stability properties.", "motivation": "To investigate the theoretical properties of the ADER-DG method when applied to ODE systems, including its approximation capabilities, convergence behavior, and various stability characteristics.", "method": "The ADER-DG method generates an implicit Runge-Kutta method and uses polynomials of degree N for numerical solutions. The analysis examines approximation order, superconvergence properties, and multiple stability criteria including A-stability, AN-stability, L-stability, B-stability, BN-stability, and algebraic stability.", "result": "The method achieves approximation order 2N+1 at grid nodes using degree N polynomials, demonstrates superconvergence, and shows subgrid resolution with order N+1 for local solutions. It exhibits comprehensive stability properties across multiple stability criteria.", "conclusion": "The ADER-DG method demonstrates excellent theoretical properties for ODE systems with high-order accuracy, superconvergence, and robust stability across multiple stability definitions, with applications confirming theoretical expectations."}}
{"id": "2508.13545", "pdf": "https://arxiv.org/pdf/2508.13545", "abs": "https://arxiv.org/abs/2508.13545", "authors": ["Peter Hintz", "Aaron Moser"], "title": "The asymptotic behavior of simple eigenvalues of particle-in-well systems", "categories": ["math.AP", "math-ph", "math.MP", "math.SP"], "comment": null, "summary": "The particle in a well in dimension one is a classical problem in quantum\nmechanics. We study higher-dimensional analogues of the problem, where the well\nis a smooth domain in $\\mathbb{R}^d$. We show that simple eigenvalues and\neigenfunctions of the corresponding Schr\\\"odinger operator depend smoothly on\nthe square root $h$ of the inverse depth of the well and provide an explicit\nfirst-order expansion of the eigenvalues at $h = 0$.\n  Our proof consists of two steps. In the first step, we construct\n$\\mathcal{O}(h^\\infty)$ quasimodes (approximate eigenfunctions) on a resolution\nof $[0, 1)_h\\times\\mathbb{R}^d$ which allows us to capture fine structure near\nthe boundary of the well. The second step corrects these quasimodes to true\neigenfunctions via a fixed point argument.", "AI": {"tldr": "Study of higher-dimensional quantum wells showing smooth dependence of eigenvalues/eigenfunctions on well depth parameter h, with explicit first-order expansion at h=0", "motivation": "Extend classical 1D particle-in-a-well quantum mechanics problem to higher dimensions with smooth domains, analyzing spectral properties dependence on well depth", "method": "Two-step approach: 1) Construct high-order quasimodes on resolved space to capture boundary structure, 2) Correct quasimodes to true eigenfunctions via fixed point argument", "result": "Proved smooth dependence of simple eigenvalues and eigenfunctions on square root of inverse well depth h, provided explicit first-order eigenvalue expansion at h=0", "conclusion": "Successfully extended classical quantum well analysis to higher dimensions, establishing smooth spectral dependence on well depth parameter with precise asymptotic behavior"}}
{"id": "2508.13770", "pdf": "https://arxiv.org/pdf/2508.13770", "abs": "https://arxiv.org/abs/2508.13770", "authors": ["Martin Schi\u00f8dt", "Nikolaj Takata M\u00fccke", "Clara Marika Velte"], "title": "Generative Super-Resolution of Turbulent Flows via Stochastic Interpolants", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": "12 pages, 7 figures, 1 table", "summary": "Capturing the intricate multiscale features of turbulent flows remains a\nfundamental challenge due to the limited resolution of experimental data and\nthe computational cost of high-fidelity simulations. In many practical\nscenarios only coarse representations of the flows are feasible, leaving\ncrucial fine-scale dynamics unresolved. This study addresses that limitation by\nleveraging generative models to perform super-resolution of velocity fields and\nreconstruct the unresolved scales from low-resolution conditionals. In\nparticular, the recently formalized stochastic interpolants are employed to\nsuper-resolve a case study of two-dimensional turbulence. Key to our approach\nis the iterative application of stochastic interpolants over local patches of\nthe flow field, that enables efficient reconstruction without the need to\nprocess the full domain simultaneously. The patch-wise strategy is shown to\nyield physically consistent super-resolved flow snapshots, and key statistical\nquantities -- such as the kinetic energy spectrum and the spatially averaged\ndissipation rate -- are accurately recovered. Moreover, compared with\nfull-field reconstruction, the patch-wise approach produces higher-quality\nsuper-resolutions, and, in general, stochastic interpolants are observed to\noutperform contesting generative models across a range of metrics. These\nresults establish stochastic interpolants as a viable tool for super-resolving\nturbulent flows and highlight their potential for future applications.", "AI": {"tldr": "Stochastic interpolants enable patch-wise super-resolution of turbulent flows, outperforming other generative models in reconstructing fine-scale dynamics from low-resolution data.", "motivation": "Turbulent flows have complex multiscale features that are challenging to capture due to limited experimental resolution and high computational costs of simulations, leaving fine-scale dynamics unresolved in practical scenarios.", "method": "Uses stochastic interpolants applied iteratively over local patches of flow fields to perform super-resolution, enabling efficient reconstruction without processing the full domain simultaneously.", "result": "Patch-wise approach produces physically consistent super-resolved flow snapshots, accurately recovering key statistical quantities like kinetic energy spectrum and dissipation rate, with higher quality than full-field reconstruction.", "conclusion": "Stochastic interpolants are established as a viable tool for super-resolving turbulent flows and show potential for future applications in flow reconstruction."}}
{"id": "2508.13886", "pdf": "https://arxiv.org/pdf/2508.13886", "abs": "https://arxiv.org/abs/2508.13886", "authors": ["Philipp Weder", "Annalisa Buffa"], "title": "Analysis-Aware Defeaturing of Dirichlet Features", "categories": ["math.NA", "cs.NA", "65N50, 65N30"], "comment": null, "summary": "Feature removal from computational geometries, or defeaturing, is an integral\npart of industrial simulation pipelines. Defeaturing simplifies the otherwise\ncostly or even impossible meshing process, speeds up the simulation, and lowers\nits memory footprint. Current defeaturing operators are often based on\nheuristic criteria and ignore the impact of the simplifications on the PDE\nsolution. This work extends the mathematically rigorous framework developed by\nBuffa, Chanon, and V\\'azquez (2022) to features subject to Dirichlet boundary\nconditions in Poisson problems. We derive a posteriori error estimators for\nnegative features in the interior or on the boundary of the computational\ndomain. The estimators' dependence on the feature size is explicit, and their\nevaluation only involves boundary integrals over the feature boundary.\nNumerical experiments in two and three dimensions showcase the validity and\nefficiency of the estimators.", "AI": {"tldr": "This paper extends mathematical defeaturing framework to handle Dirichlet boundary conditions in Poisson problems, providing explicit error estimators for feature removal that only require boundary integrals.", "motivation": "Current defeaturing operators use heuristic criteria and ignore PDE solution impact. Industrial simulation pipelines need rigorous mathematical methods to simplify geometries while maintaining solution accuracy.", "method": "Extends Buffa, Chanon, and Vazquez (2022) framework to features with Dirichlet BCs. Derives a posteriori error estimators with explicit dependence on feature size, using only boundary integrals over feature boundaries.", "result": "Developed error estimators successfully validated through 2D and 3D numerical experiments, showing validity and efficiency for defeaturing operations.", "conclusion": "The proposed mathematical framework provides rigorous error control for defeaturing operations with Dirichlet boundary conditions, enabling more reliable geometry simplification in industrial simulations."}}
{"id": "2508.13591", "pdf": "https://arxiv.org/pdf/2508.13591", "abs": "https://arxiv.org/abs/2508.13591", "authors": ["Philippe Briet", "Maxence Cassier", "Thomas Ourmi\u00e8res-Bonafos", "Michele Zaccaron"], "title": "Geometric spectral properties of electromagnetic waveguides", "categories": ["math.AP", "math-ph", "math.MP", "math.SP"], "comment": null, "summary": "Consider a reference homogeneous and isotropic electromagnetic waveguide with\na simply connected cross-section embedded in a perfect conductor. In this\nsetting, when the waveguide is straight, the spectrum of the associated\nself-adjoint Maxwell operator with a constant twist (which may be zero) lies on\nthe real line and is symmetric with respect to zero and exhibits a spectral gap\naround the origin. Moreover, the spectrum is purely essential, and contains 0\nwhich is an eigenvalue of infinite multiplicity. In this work, we present new\nresults on the effects of geometric deformations, specifically bending and\ntwisting, on the spectrum of the Maxwell operator. More precisely, we provide,\non the one hand, sufficient conditions on the asymptotic behavior of curvature\nand twist that ensure the preservation of the essential spectrum of the\nreference waveguide. Our approach relies on a Birman-Schwinger-type principle,\nwhich may be of independent interest and applicable in other contexts. On the\nother hand, we give sufficient conditions (involving in particular the\ngeometrical shape of the cross-section of the waveguide) so that the\ngeometrical deformation creates discrete spectrum (namely isolated eigenvalues\nof finite multiplicity) within the gap of the essential spectrum. In addition,\nwe give some results on the localization of these discrete eigenvalues. The\nsufficient condition involving the cross-section is then studied both\nanalytically and numerically. Finally, we examine its stability under shape\ndeformations of the cross-section, focusing in particular on the case of a\nwaveguide with a rectangular cross-section.", "AI": {"tldr": "Analysis of how geometric deformations (bending and twisting) affect the spectrum of Maxwell operators in waveguides, showing conditions for preserving essential spectrum and creating discrete eigenvalues within spectral gaps.", "motivation": "To understand how geometric deformations in waveguides impact the electromagnetic spectrum, particularly how bending and twisting can create discrete eigenvalues within spectral gaps that weren't present in straight waveguides.", "method": "Uses Birman-Schwinger-type principle to analyze asymptotic behavior of curvature and twist, provides sufficient conditions for spectrum preservation, and studies cross-section geometry effects both analytically and numerically.", "result": "Establishes conditions where geometric deformations preserve essential spectrum while creating discrete eigenvalues within spectral gaps, with localization results and stability analysis under cross-section shape deformations.", "conclusion": "Geometric deformations significantly impact waveguide spectra, with specific conditions determining whether essential spectrum is preserved and discrete eigenvalues are created, particularly relevant for rectangular cross-section waveguides."}}
{"id": "2508.13779", "pdf": "https://arxiv.org/pdf/2508.13779", "abs": "https://arxiv.org/abs/2508.13779", "authors": ["Ryosuke Akashi", "Hiroshi Shinaoka"], "title": "Uniform electron benchmark for the first-principles $GW_{0}$-Eliashberg theory", "categories": ["cond-mat.supr-con", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "11 pages, 6 figures, 2 tables", "summary": "We investigate the numerical behavior of the Eliashberg equations for\nphonon-mediated superconductivity, incorporating normal-state self-energy\ncalculations within the consistent $GW_{0}$ approximation. We account for the\nfull wavenumber and frequency dependences of both the screened Coulomb\ninteraction and phonon-mediated attraction. We present results for the\nprototypical uniform electron gas system with model Einstein phonons at\ntemperatures of a few kelvin. At extremely low temperatures, we efficiently\nexecute the required convolutions of Green's functions and interactions in\nMatsubara frequency and wavenumber using intermediate representation and\nFourier convolution techniques. In particular, we elucidate the interplay\nbetween electron-phonon $\\omega$-mass and $k$-mass renormalizations of the\nelectronic self-energy in determining the normal-state effective mass, spectral\nweight and the superconducting transition temperature. The electron density\nregimes where the plasmon effect enhances or suppresses the phonon-mediated\nsuperconductivity on top of the static Coulomb effect are revealed. We compare\nour comprehensive Eliashberg calculation results with those from density\nfunctional theory for superconductors, where the functionals have been\nconstructed with reference to Eliashberg theory. Our model, methods, and\nresults provide a valuable benchmark for first-principles superconducting\ncalculations that treat screened Coulomb interaction effects non-empirically.", "AI": {"tldr": "Numerical study of Eliashberg equations for phonon-mediated superconductivity using consistent GW0 approximation, revealing interplay between electron-phonon interactions and plasmon effects on superconducting transition temperature.", "motivation": "To investigate the numerical behavior of Eliashberg equations and understand how electron-phonon interactions and screened Coulomb effects influence superconductivity, providing benchmarks for first-principles calculations.", "method": "Used consistent GW0 approximation with full wavenumber and frequency dependences of screened Coulomb interaction and phonon-mediated attraction. Applied intermediate representation and Fourier convolution techniques for efficient computation at low temperatures on uniform electron gas with model Einstein phonons.", "result": "Revealed interplay between electron-phonon \u03c9-mass and k-mass renormalizations in determining normal-state effective mass, spectral weight, and superconducting transition temperature. Identified electron density regimes where plasmon effect enhances or suppresses phonon-mediated superconductivity beyond static Coulomb effects.", "conclusion": "The comprehensive Eliashberg calculations provide valuable benchmarks for first-principles superconducting calculations that treat screened Coulomb interaction effects non-empirically, with comparisons to density functional theory for superconductors."}}
{"id": "2508.13997", "pdf": "https://arxiv.org/pdf/2508.13997", "abs": "https://arxiv.org/abs/2508.13997", "authors": ["Sijing Liu", "Jinjin Zhang"], "title": "Convergence analysis of a balancing domain decomposition method for an elliptic optimal control problem with HDG discretizations", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this work, a balancing domain decomposition by constraints (BDDC)\nalgorithm is applied to the nonsymmetric positive definite linear system\narising from the hybridizable discontinuous Galerkin (HDG) discretization of an\nelliptic distributed optimal control problem. Convergence analysis for the BDDC\npreconditioned generalized minimal residual (GMRES) solver demonstrates that,\nwhen the subdomain size is small enough, the algorithm is robust with respect\nto the regularization parameter, and the number of iterations is independent of\nthe number of subdomains and depends only slightly on the subdomain problem\nsize. Numerical experiments are performed to confirm the theoretical results.", "AI": {"tldr": "BDDC algorithm applied to HDG discretization of elliptic optimal control problems shows robustness with regularization parameter and good scalability properties.", "motivation": "To develop an efficient domain decomposition method for solving nonsymmetric positive definite linear systems arising from HDG discretization of elliptic distributed optimal control problems, addressing challenges with regularization parameter sensitivity and scalability.", "method": "Applied balancing domain decomposition by constraints (BDDC) algorithm to hybridizable discontinuous Galerkin (HDG) discretization, using BDDC-preconditioned GMRES solver for the nonsymmetric system.", "result": "Convergence analysis shows algorithm robustness with respect to regularization parameter when subdomain size is sufficiently small. Number of iterations is independent of number of subdomains and only slightly dependent on subdomain problem size. Numerical experiments confirm theoretical findings.", "conclusion": "The BDDC preconditioner is effective for HDG discretizations of elliptic optimal control problems, providing parameter robustness and good parallel scalability properties."}}
{"id": "2508.13627", "pdf": "https://arxiv.org/pdf/2508.13627", "abs": "https://arxiv.org/abs/2508.13627", "authors": ["Jinkai Li", "Liening Qiao"], "title": "Global well-posedness of the inviscid resistive isentropic compressible MHD system", "categories": ["math.AP"], "comment": null, "summary": "Due to the absence of dissipation mechanism to the inviscid compressible\nsystems, it is a challenging problem to prove their global solvability. In this\npaper, we are concerned with the initial-boundary value problem to the inviscid\nand resistive isentropic compressible magnetohydrodynamic (MHD) system on three\ndimensional torus $\\mathbb T^3$. Global well-posedness and large time behavior\nof solutions are established in the first time for the isentropic setting,\nunder the condition that the initial data $(\\rho_0, u_0, H_0)$ is a small\nperturbation around the constant state $(1, 0, w)$, with $w$ satisfying the\nDiophantine condition. The main observation of this paper is that the spatial\nderivatives of the density along directions perpendicular to $w$ are\ndissipated. Such dissipation mechanism is generated from the interaction\nbetween the velocity field and the background magnetic field. This verifies the\nweak stabilizing effects of the magnetic filed on the dynamics in the scenario\nof inviscid isentropic flows. Due to different dissipation mechanisms for the\ndensity, velocity, and magnetic field, three ties of dissipative energies are\ndesigned, that is, high order Sobolev norms of the perturbed magnetic field,\nintermediate order Sobolev norms of the perturbed density, and low order\nSobolev norms of the velocity field.", "AI": {"tldr": "Global well-posedness and large time behavior established for inviscid resistive isentropic compressible MHD system on 3D torus with small perturbations around constant state satisfying Diophantine condition.", "motivation": "Address the challenging problem of proving global solvability for inviscid compressible systems which lack dissipation mechanisms.", "method": "Three-tier dissipative energy design with different Sobolev norms: high order for magnetic field, intermediate for density, low order for velocity field. Key observation is dissipation of spatial density derivatives perpendicular to magnetic field direction.", "result": "First global well-posedness result for isentropic setting, demonstrating weak stabilizing effects of magnetic field on inviscid isentropic flows through generated dissipation mechanisms.", "conclusion": "Magnetic field interaction with velocity field generates dissipation mechanism that stabilizes the system, enabling global solutions despite absence of viscous dissipation."}}
{"id": "2508.14007", "pdf": "https://arxiv.org/pdf/2508.14007", "abs": "https://arxiv.org/abs/2508.14007", "authors": ["Cao-Kha Doan", "Thi-Thao-Phuong Hoang", "Lili Ju", "Rihui Lan"], "title": "Convergence analysis of the dynamically regularized Lagrange multiplier method for the incompressible Navier-Stokes equations", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper is concerned with temporal convergence analysis of the recently\nintroduced Dynamically Regularized Lagrange Multiplier (DRLM) method for the\nincompressible Navier-Stokes equations. A key feature of the DRLM approach is\nthe incorporation of the kinetic energy evolution through a quadratic dynamic\nequation involving a time-dependent Lagrange multiplier and a regularization\nparameter. We apply the backward Euler method with an explicit treatment of the\nnonlinear convection term and show the unique solvability of the resulting\nfirst-order DRLM scheme. Optimal error estimates for the velocity and pressure\nare established based on a uniform bound on the Lagrange multiplier and\nmathematical induction. Numerical results confirm the theoretical convergence\nrates and error bounds that decay with respect to the regularization parameter.", "AI": {"tldr": "Temporal convergence analysis of Dynamically Regularized Lagrange Multiplier method for incompressible Navier-Stokes equations with optimal error estimates and numerical validation.", "motivation": "To provide rigorous temporal convergence analysis for the recently introduced DRLM method, which incorporates kinetic energy evolution through dynamic regularization.", "method": "Applied backward Euler method with explicit treatment of nonlinear convection term; established unique solvability and optimal error estimates using uniform bound on Lagrange multiplier and mathematical induction.", "result": "Proved unique solvability of first-order DRLM scheme and established optimal error estimates for velocity and pressure; numerical results confirmed theoretical convergence rates and error bounds decaying with regularization parameter.", "conclusion": "The DRLM method demonstrates strong theoretical convergence properties with optimal error estimates that are validated numerically, showing the effectiveness of the dynamic regularization approach."}}
{"id": "2508.13688", "pdf": "https://arxiv.org/pdf/2508.13688", "abs": "https://arxiv.org/abs/2508.13688", "authors": ["Jordan Serres"], "title": "Contractive transport maps from $\\mathbb{S}^2$ to nearly spherical surfaces with positive Ricci curvature", "categories": ["math.AP", "math.DG", "math.FA"], "comment": null, "summary": "We prove that every nearly spherical, positively curved surface is the\ncontractive, volume-preserving image of a round sphere. The proof combines\nthree main tools: the Ricci flow on surfaces, the Kim-Milman construction, and\na multiscale Bakry-\\'Emery criterion.", "AI": {"tldr": "Every nearly spherical, positively curved surface is a contractive, volume-preserving image of a round sphere", "motivation": "To establish a fundamental geometric relationship between nearly spherical surfaces with positive curvature and round spheres, providing a characterization theorem in differential geometry", "method": "Combines three mathematical tools: Ricci flow on surfaces, the Kim-Milman construction, and a multiscale Bakry-\u00c9mery criterion to prove the main result", "result": "Successfully proves that any nearly spherical surface with positive curvature can be obtained as a contractive, volume-preserving transformation of a round sphere", "conclusion": "This establishes a deep geometric connection between nearly spherical positively curved surfaces and round spheres, with implications for understanding surface geometry and transformation properties"}}
{"id": "2508.13845", "pdf": "https://arxiv.org/pdf/2508.13845", "abs": "https://arxiv.org/abs/2508.13845", "authors": ["Thomas P. van Waas", "Christophe Berthod", "Jan Berges", "Nicola Marzari", "J. Hugo Dil", "Samuel Ponc\u00e9"], "title": "Extraction of the self energy and Eliashberg function from angle resolved photoemission spectroscopy using the \\textsc{xARPES} code", "categories": ["cond-mat.mtrl-sci", "cond-mat.supr-con", "physics.comp-ph"], "comment": "10 pages, 7 figures", "summary": "Angle-resolved photoemission spectroscopy is a powerful experimental\ntechnique for studying anisotropic many-body interactions through the electron\nspectral function. Existing attempts to decompose the spectral function into\nnon-interacting dispersions and electron-phonon, electron-electron, and\nelectron-impurity self-energies rely on linearization of the bands and manual\nassignment of self-energy magnitudes. Here, we show how self-energies can be\nextracted consistently for curved dispersions. We extend the maximum-entropy\nmethod to Eliashberg-function extraction with Bayesian inference, optimizing\nthe parameters describing the dispersions and the magnitudes of\nelectron-electron and electron-impurity interactions. We compare these novel\nmethodologies with state-of-the-art approaches on model data, then demonstrate\ntheir applicability with two high-quality experimental data sets. With the\nfirst set, we identify the phonon modes of a two-dimensional electron liquid on\nTiO$_2$-terminated SrTiO$_3$. With the second set, we obtain unprecedented\nagreement between two Eliashberg functions of Li-doped graphene extracted from\nseparate dispersions. We release these functionalities in the novel Python code\n\\textsc{xARPES}.", "AI": {"tldr": "Novel method for extracting self-energies from angle-resolved photoemission spectroscopy data using maximum-entropy method and Bayesian inference, enabling consistent analysis of curved dispersions without manual parameter assignment.", "motivation": "Existing methods for decomposing spectral functions rely on linearization of bands and manual assignment of self-energy magnitudes, which limits accuracy and consistency in analyzing anisotropic many-body interactions.", "method": "Extended maximum-entropy method to Eliashberg-function extraction with Bayesian inference, optimizing dispersion parameters and magnitudes of electron-electron and electron-impurity interactions. Developed Python code xARPES to implement these functionalities.", "result": "Successfully identified phonon modes of 2D electron liquid on TiO2-terminated SrTiO3 and achieved unprecedented agreement between two Eliashberg functions of Li-doped graphene extracted from separate dispersions. Demonstrated superior performance compared to state-of-the-art approaches on model data.", "conclusion": "The novel methodology provides a consistent framework for extracting self-energies from curved dispersions, enabling more accurate analysis of many-body interactions in angle-resolved photoemission spectroscopy data."}}
{"id": "2508.13232", "pdf": "https://arxiv.org/pdf/2508.13232", "abs": "https://arxiv.org/abs/2508.13232", "authors": ["Liliane Basso Barichello"], "title": "On Modeling and Solving the Boltzmann Equation", "categories": ["math-ph", "cs.NA", "math.MP", "math.NA", "76P05, 76M22, 65N35"], "comment": null, "summary": "The Boltzmann equation has been a driving force behind significant\nmathematical research over the years. Its challenging theoretical complexity,\ncombined with a wide variety of current scientific and technological problems\nthat require numerical simulations based on this model, justifies such\ninterest. This work provides a brief overview of studies and advances related\nto the solution of the linear Boltzmann equation in one- and two-dimensional\nspatial dimensions. In particular, relevant aspects of the discrete ordinates\napproximation of the model are highlighted for neutron and photon transport\napplications, including nuclear safeguards, nuclear reactor shielding problems,\nand optical tomography. In addition, a short discussion on rarefied gas\ndynamics problems, which are relevant, for instance, in the studies of\nmicro-electro-mechanical systems, and their connection with the linearized\nBoltzmann equation, is presented. A primary goal of the work is to establish as\nmuch as possible the connections between the different phenomena described by\nthe model and the versatility of the analytical methodology, the ADO method, in\nproviding concise and accurate solutions, which are fundamental for numerical\nsimulations.", "AI": {"tldr": "Overview of linear Boltzmann equation solutions in 1D/2D spatial dimensions, focusing on discrete ordinates approximation for neutron/photon transport and rarefied gas dynamics applications.", "motivation": "The Boltzmann equation's theoretical complexity and wide applicability in scientific/technological problems requiring numerical simulations justify research interest and the need for concise, accurate solution methods.", "method": "Discrete ordinates approximation of the linear Boltzmann equation, using the ADO (Analytical Discrete Ordinates) method to provide concise and accurate solutions for numerical simulations.", "result": "The work establishes connections between different phenomena described by the model and demonstrates the versatility of the ADO methodology in providing fundamental solutions for applications including nuclear safeguards, reactor shielding, optical tomography, and micro-electro-mechanical systems.", "conclusion": "The ADO method proves to be a versatile analytical methodology capable of providing concise and accurate solutions to the linear Boltzmann equation, making it fundamental for numerical simulations across various scientific and technological applications."}}
{"id": "2508.13694", "pdf": "https://arxiv.org/pdf/2508.13694", "abs": "https://arxiv.org/abs/2508.13694", "authors": ["Goro Akagi", "Giacomo Enrico Sodini", "Ulisse Stefanelli"], "title": "Global well-posedness for a time-fractional doubly nonlinear equation", "categories": ["math.AP", "35K55"], "comment": "23 pages", "summary": "We consider a time-fractional parabolic equation of doubly nonlinear type,\nfeaturing nonlinear terms both inside and outside the differential operator in\ntime. The main nonlinearities are maximal monotone graphs, without restrictions\non the growth. In addition, a Lipschitz continuous perturbation is considered.\nThe existence of global weak solutions is obtained via a regularization and\nGalerkin approximation method. Uniqueness is also discussed under some\nadditional assumptions.", "AI": {"tldr": "Analysis of time-fractional parabolic equations with doubly nonlinear structure and maximal monotone graphs, establishing existence of global weak solutions via regularization and Galerkin methods.", "motivation": "To study time-fractional parabolic equations with doubly nonlinear structure, featuring nonlinear terms both inside and outside the time differential operator, with maximal monotone graphs without growth restrictions and Lipschitz perturbations.", "method": "Regularization and Galerkin approximation method to establish the existence of global weak solutions for the doubly nonlinear time-fractional parabolic equation.", "result": "Existence of global weak solutions is obtained for the time-fractional parabolic equation with doubly nonlinear structure and maximal monotone graphs. Uniqueness is also discussed under additional assumptions.", "conclusion": "The paper successfully establishes existence results for doubly nonlinear time-fractional parabolic equations with maximal monotone graphs, providing a foundation for further analysis of such complex nonlinear fractional models."}}
{"id": "2508.13867", "pdf": "https://arxiv.org/pdf/2508.13867", "abs": "https://arxiv.org/abs/2508.13867", "authors": ["Mingliang Zhong", "Adrian Kummerl\u00e4nder", "Shota Ito", "Mathias J. Krause", "Martin Frank", "Stephan Simonis"], "title": "OpenLB-UQ: An Uncertainty Quantification Framework for Incompressible Fluid Flow Simulations", "categories": ["physics.flu-dyn", "cs.MS", "cs.NA", "math.NA", "physics.comp-ph"], "comment": null, "summary": "Uncertainty quantification (UQ) is crucial in computational fluid dynamics to\nassess the reliability and robustness of simulations, given the uncertainties\nin input parameters. OpenLB is an open-source lattice Boltzmann method library\ndesigned for efficient and extensible simulations of complex fluid dynamics on\nhigh-performance computers. In this work, we leverage the efficiency of OpenLB\nfor large-scale flow sampling with a dedicated and integrated UQ module. To\nthis end, we focus on non-intrusive stochastic collocation methods based on\ngeneralized polynomial chaos and Monte Carlo sampling. The OpenLB-UQ framework\nis extensively validated in convergence tests with respect to statistical\nmetrics and sample efficiency using selected benchmark cases, including\ntwo-dimensional Taylor--Green vortex flows with up to four-dimensional\nuncertainty and a flow past a cylinder. Our results confirm the expected\nconvergence rates and show promising scalability, demonstrating robust\nstatistical accuracy as well as computational efficiency. OpenLB-UQ enhances\nthe capability of the OpenLB library, offering researchers a scalable framework\nfor UQ in incompressible fluid flow simulations and beyond.", "AI": {"tldr": "OpenLB-UQ integrates uncertainty quantification into the OpenLB lattice Boltzmann library using non-intrusive stochastic collocation methods and Monte Carlo sampling, validated on benchmark cases with promising scalability and accuracy.", "motivation": "Uncertainty quantification is crucial for assessing reliability in computational fluid dynamics simulations due to input parameter uncertainties, but existing tools need efficient integration with large-scale flow simulation libraries.", "method": "Leverages OpenLB's efficiency for large-scale flow sampling with integrated UQ module using non-intrusive stochastic collocation methods based on generalized polynomial chaos and Monte Carlo sampling.", "result": "Extensive validation shows expected convergence rates, promising scalability, robust statistical accuracy, and computational efficiency on benchmark cases including 2D Taylor-Green vortex flows and flow past a cylinder.", "conclusion": "OpenLB-UQ successfully enhances OpenLB's capabilities, providing researchers with a scalable framework for uncertainty quantification in incompressible fluid flow simulations and beyond."}}
{"id": "2508.13698", "pdf": "https://arxiv.org/pdf/2508.13698", "abs": "https://arxiv.org/abs/2508.13698", "authors": ["Louis-Pierre Chaintron", "Daniel Lacker"], "title": "Geodesic convexity and strengthened functional inequalities in submanifolds of Wasserstein space", "categories": ["math.AP", "math.FA"], "comment": null, "summary": "We study the geodesic convexity of various energy and entropy functionals\nrestricted to (non-geodesically convex) submanifolds of Wasserstein spaces with\ntheir induced geometry. We prove a variety of convexity results by means of a\nsimple general principle, which holds in the metric space setting, and which\ncrucially requires no knowledge of the structure of geodesics in the\nsubmanifold: If the EVI gradient flow of a functional exists and leaves the\nsubmanifold invariant, then the restriction of the functional to the\nsubmanifold is geodesically convex. This leads to short new proofs of several\nknown results, such as one of Carlen and Gangbo on strong convexity of entropy\non sphere-like submanifolds, and several new results, such as the\n$\\lambda$-convexity of entropy on the space of couplings of\n$\\lambda$-log-concave marginals. Along the way, we develop sufficient\nconditions for existence of geodesics in Wasserstein submanifolds. Submanifold\nconvexity results lead systematically to improvements of Talagrand and HWI\ninequalities which we speculate to be closely related to concentration of\nmeasure estimates for conditioned empirical measures, and we prove one rigorous\nresult in this direction in the Carlen-Gangbo setting.", "AI": {"tldr": "The paper presents a general principle for proving geodesic convexity of functionals on submanifolds of Wasserstein spaces, showing that if the EVI gradient flow exists and leaves the submanifold invariant, then the functional is geodesically convex on that submanifold.", "motivation": "To study geodesic convexity of energy and entropy functionals on non-geodesically convex submanifolds of Wasserstein spaces, which has applications in improving functional inequalities and understanding concentration of measure phenomena.", "method": "Develops a general metric space principle that requires no knowledge of submanifold geodesic structure, using existence of EVI gradient flows that preserve the submanifold to prove convexity. Applies this to various settings including sphere-like submanifolds and couplings of log-concave marginals.", "result": "Provides new proofs of known results (Carlen-Gangbo theorem) and new convexity results (\u03bb-convexity on couplings of \u03bb-log-concave marginals). Develops sufficient conditions for geodesic existence in Wasserstein submanifolds and systematically improves Talagrand and HWI inequalities.", "conclusion": "The general principle offers a powerful tool for establishing convexity on submanifolds without detailed geodesic knowledge, leading to both theoretical advances and potential applications in concentration of measure estimates for conditioned empirical measures."}}
{"id": "2508.13906", "pdf": "https://arxiv.org/pdf/2508.13906", "abs": "https://arxiv.org/abs/2508.13906", "authors": ["Kapil Goswami", "Peter Schmelcher", "Rick Mukherjee"], "title": "Qudit-based scalable quantum algorithm for solving the integer programming problem", "categories": ["quant-ph", "math.OC", "physics.comp-ph"], "comment": "20 pages, 6 figures, and 1 table", "summary": "Integer programming (IP) is an NP-hard combinatorial optimization problem\nthat is widely used to represent a diverse set of real-world problems spanning\nmultiple fields, such as finance, engineering, logistics, and operations\nresearch. It is a hard problem to solve using classical algorithms, as its\ncomplexity increases exponentially with problem size. Most quantum algorithms\nfor solving IP are highly resource inefficient because they encode integers\ninto qubits. In [1], the issue of resource inefficiency was addressed by\nmapping integer variables to qudits. However, [1] has limited practical value\ndue to a lack of scalability to multiple qudits to encode larger problems. In\nthis work, by extending upon the ideas of [1], a circuit-based scalable quantum\nalgorithm is presented using multiple interacting qudits for which we show a\nquantum speed-up. The quantum algorithm consists of a distillation function\nthat efficiently separates the feasible from the infeasible regions, a\nphase-amplitude encoding for the cost function, and a quantum phase estimation\ncoupled with a multi-controlled single-qubit rotation for optimization. We\nprove that the optimal solution has the maximum probability of being measured\nin our algorithm. The time complexity for the quantum algorithm is shown to be\n$O(d^{n/2} + m\\cdot n^2\\cdot \\log{d} + n/\\epsilon_{QPE})$ for a problem with\nthe number of variables $n$ taking $d$ integer values, satisfying $m$\nconstraints with a precision of $\\epsilon_{QPE}$. Compared to the classical\ntime complexity of brute force $O(d^n)$ and the best classical exact algorithm\n$O((\\log{n})^{3n})$, it incurs a reduction of $d^{n/2}$ in the time complexity\nin terms of $n$ for solving a general polynomial IP problem.", "AI": {"tldr": "A scalable quantum algorithm using multiple qudits for integer programming that achieves quantum speed-up with time complexity O(d^{n/2}) compared to classical brute force O(d^n).", "motivation": "Integer programming is NP-hard and classical algorithms struggle with exponential complexity. Existing quantum approaches are resource-inefficient when encoding integers into qubits, and previous qudit-based methods lacked scalability to larger problems.", "method": "Extends qudit-based encoding with a circuit-based scalable algorithm using multiple interacting qudits. Includes a distillation function to separate feasible/infeasible regions, phase-amplitude encoding for cost function, and quantum phase estimation with multi-controlled single-qubit rotation for optimization.", "result": "Proves optimal solution has maximum measurement probability. Achieves time complexity O(d^{n/2} + m\u00b7n\u00b2\u00b7log d + n/\u03b5_QPE) for n variables with d integer values and m constraints, representing a d^{n/2} reduction compared to classical brute force O(d^n).", "conclusion": "The quantum algorithm provides a scalable solution for integer programming with demonstrated quantum speed-up, overcoming resource inefficiency and scalability limitations of previous quantum approaches."}}
{"id": "2508.13653", "pdf": "https://arxiv.org/pdf/2508.13653", "abs": "https://arxiv.org/abs/2508.13653", "authors": ["Ashish Jha", "Anh huy Phan", "Razan Dibo", "Valentin Leplat"], "title": "GRAFT: Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": null, "summary": "Training modern neural networks on large datasets is computationally and\nenvironmentally costly. We introduce GRAFT, a scalable in-training subset\nselection method that (i) extracts a low-rank feature representation for each\nbatch, (ii) applies a Fast MaxVol sampler to select a small, diverse subset\nthat spans the batch's dominant subspace, and (iii) dynamically adjusts the\nsubset size using a gradient-approximation criterion. By operating in low-rank\nsubspaces and training on carefully chosen examples instead of full batches,\nGRAFT preserves the training trajectory while reducing wall-clock time, energy\nconsumption, and $\\mathrm{CO}_2$ emissions. Across multiple benchmarks, GRAFT\nmatches or exceeds recent selection baselines in both accuracy and efficiency,\nproviding a favorable trade-off between accuracy, efficiency, and emissions.", "AI": {"tldr": "GRAFT is an efficient in-training subset selection method that reduces computational costs and environmental impact by selecting diverse, representative examples from low-rank feature representations instead of using full batches.", "motivation": "Training modern neural networks on large datasets is computationally intensive and environmentally costly due to high energy consumption and CO2 emissions. There's a need for methods that can reduce these costs while maintaining training effectiveness.", "method": "GRAFT extracts low-rank feature representations for each batch, applies a Fast MaxVol sampler to select a small diverse subset that spans the batch's dominant subspace, and dynamically adjusts subset size using a gradient-approximation criterion.", "result": "GRAFT matches or exceeds recent selection baselines in both accuracy and efficiency across multiple benchmarks, while significantly reducing wall-clock time, energy consumption, and CO2 emissions.", "conclusion": "GRAFT provides a favorable trade-off between accuracy, efficiency, and environmental impact, making it a scalable solution for reducing the computational and environmental costs of neural network training."}}
{"id": "2508.13704", "pdf": "https://arxiv.org/pdf/2508.13704", "abs": "https://arxiv.org/abs/2508.13704", "authors": ["Jing An", "Alexander Kiselev", "Yao Yao"], "title": "Reaction enhancement by flux-limited chemotaxis", "categories": ["math.AP"], "comment": "21 pages, 2 figures", "summary": "Chemotaxis plays a crucial role in a variety of processes in biology and\necology. Quite often it acts to improve efficiency of biological reactions; one\nexample is the immune system signalling, where infected tissues release\nchemokines attracting monocytes to fight invading bacteria. Another example is\nreproduction, where eggs release pheromones that attract sperm. In this paper,\nwe analyze a system of two reacting densities, one of which is chemotactic on\nanother. Since the speed of any biological agents is limited, we employ flux\nlimited chemotaxis model. Our main result is the rigorous derivation of the\nscaling laws showing how presence of chemotaxis affects the typical reaction\ntime scale. This work builds on the results of \\cite{kiselev2022chemotaxis},\nwhich employed a classical Keller-Segel chemotaxis term (not flux limited) -\nleading to the effect of possible over concentration and restricting the\nresults to radial data. The model presented here is more reasonable\nbiologically and covers broader parameter regimes.", "AI": {"tldr": "Analysis of chemotaxis effects on reaction times using flux-limited model to address biological realism and broader parameter regimes", "motivation": "Chemotaxis improves efficiency in biological processes like immune response and reproduction, but classical models have limitations like over-concentration and radial data restrictions", "method": "Employed flux-limited chemotaxis model for two reacting densities, building on previous Keller-Segel approach but addressing speed limitations of biological agents", "result": "Rigorous derivation of scaling laws showing how chemotaxis affects typical reaction time scale", "conclusion": "The flux-limited model is more biologically reasonable and covers broader parameter regimes than classical chemotaxis models"}}
{"id": "2508.13659", "pdf": "https://arxiv.org/pdf/2508.13659", "abs": "https://arxiv.org/abs/2508.13659", "authors": ["Weisheng Zhou", "Huaian Diao", "Hongyu Liu"], "title": "Quasi-Minnaert Resonances in High-contrast acoustic Structures and Applications to Invisibility Cloaking", "categories": ["physics.optics", "cs.NA", "math.AP", "math.NA"], "comment": null, "summary": "This paper investigates a novel quasi-Minnaert resonance phenomenon in\nacoustic wave propagation through high-contrast medium in both two and three\ndimensions, occurring in the sub-wavelength regime. These media are\ncharacterized by physical properties significantly distinct from those of a\nhomogeneous background. The quasi-Minnaert resonance is defined by two primary\nfeatures: boundary localization, where the $L^2$-norms of the internal total\nfield and the external scattered field exhibit pronounced concentration near\nthe boundary, and surface resonance, marked by highly oscillatory behavior of\nthe fields near the boundary. In contrast to classical Minnaert resonances,\nwhich are associated with a discrete spectral spectrum tied to physical\nparameters, quasi-Minnaert resonances exhibit analogous physical phenomena but\nwith a continuous spectral spectrum. Using layer potential theory and rigorous\nasymptotic analysis, we demonstrate that the coupling between a high-contrast\nmaterial structure, particularly with radial geometries, and a carefully\ndesigned incident wave is critical for inducing quasi-Minnaert resonances.\nExtensive numerical experiments, involving radial geometries (e.g., unit disks\nand spheres) and general-shaped geometries (e.g., hearts, Cassini ovals, and\nclovers in $\\mathbb{R}^2$, and spheres in $\\mathbb{R}^3$), validate the\noccurrence of these resonances. Furthermore, we numerically demonstrate that\nquasi-Minnaert resonances induce an invisibility cloaking effect in the\nhigh-contrast medium. These findings have significant implications for\nmathematical material science and the development of acoustic cloaking\ntechnologies.", "AI": {"tldr": "Novel quasi-Minnaert resonance in acoustic wave propagation through high-contrast media, featuring boundary localization and surface resonance with continuous spectral spectrum, enabling invisibility cloaking effects.", "motivation": "To investigate acoustic wave phenomena in high-contrast media that differ significantly from homogeneous backgrounds, particularly exploring resonance effects that could enable advanced acoustic technologies like cloaking.", "method": "Used layer potential theory and rigorous asymptotic analysis to study wave coupling with high-contrast material structures, validated through extensive numerical experiments with radial geometries (disks, spheres) and general-shaped geometries (hearts, Cassini ovals, clovers).", "result": "Demonstrated that quasi-Minnaert resonances occur through specific coupling between high-contrast structures and incident waves, showing boundary localization and surface resonance phenomena, and numerically confirmed these resonances induce invisibility cloaking effects.", "conclusion": "Quasi-Minnaert resonances represent a significant advancement in acoustic wave manipulation with continuous spectral spectrum, offering promising applications in mathematical material science and acoustic cloaking technology development."}}
{"id": "2508.13753", "pdf": "https://arxiv.org/pdf/2508.13753", "abs": "https://arxiv.org/abs/2508.13753", "authors": ["Radu Ignat", "Roger Moser"], "title": "Asymptotic minimality of one-dimensional transition profiles in Aviles-Giga type models: an approach via 1-currents", "categories": ["math.AP"], "comment": null, "summary": "For vector fields on a two-dimensional domain, we study the asymptotic\nbehaviour of Modica-Mortola (or Allen-Cahn) type functionals under the\nassumption that the divergence converges to $0$ at a certain rate, which\neffectively produces a model of Aviles-Giga type. This problem will typically\ngive rise to transition layers, which degenerate into discontinuities in the\nlimit. We analyse the energy concentration at these discontinuities and the\ncorresponding transition profiles.\n  We derive an estimate for the energy concentration in terms of a novel\ngeometric variational problem involving the notion of $\\mathbb{R}^2$-valued\n$1$-currents from geometric measure theory. This in turn leads to criteria,\nunder which the energetically favourable transition profiles are essentially\none-dimensional.", "AI": {"tldr": "Analysis of Modica-Mortola functionals for 2D vector fields with vanishing divergence, showing transition layers become discontinuities and deriving energy concentration estimates using geometric measure theory.", "motivation": "To understand the asymptotic behavior of Modica-Mortola type functionals for vector fields when divergence converges to zero, which creates Aviles-Giga type models with degenerate transition layers.", "method": "Studied energy concentration at discontinuities using geometric variational problems involving \u211d\u00b2-valued 1-currents from geometric measure theory to analyze transition profiles.", "result": "Derived energy concentration estimates and established criteria determining when energetically favorable transition profiles are essentially one-dimensional.", "conclusion": "The analysis provides geometric variational framework for understanding energy concentration in degenerate transition layers and identifies conditions for one-dimensional transition profiles."}}
{"id": "2508.13802", "pdf": "https://arxiv.org/pdf/2508.13802", "abs": "https://arxiv.org/abs/2508.13802", "authors": ["Andreas Mueller"], "title": "A Screw Approach to the Approximation of the Local Geometry of the Configuration Space and of the set of Configurations of Certain Rank of Lower Pair Linkages", "categories": ["math.DG", "cs.NA", "cs.RO", "math.NA"], "comment": null, "summary": "A motion of a mechanism is a curve in its configuration space (c-space).\nSingularities of the c-space are kinematic singularities of the mechanism. Any\nmobility analysis of a particular mechanism amounts to investigating the\nc-space geometry at a given configuration. A higher-order analysis is necessary\nto determine the finite mobility. To this end, past research lead to approaches\nusing higher-order time derivatives of loop closure constraints assuming\n(implicitly) that all possible motions are smooth. This continuity assumption\nlimits the generality of these methods. In this paper an approach to the\nhigher-order local mobility analysis of lower pair multi-loop linkages is\npresented. This is based on a higher-order Taylor series expansion of the\ngeometric constraint mapping, for which a recursive algebraic expression in\nterms of joint screws is presented. An exhaustive local analysis includes\nanalysis of the set of constraint singularities (configurations where the\nconstraint Jacobian has certain corank). A local approximation of the set of\nconfigurations with certain rank is presented, along with an explicit\nexpression for the differentials of Jacobian minors in terms of instantaneous\njoint screws. The c-space and the set of points of certain corank are therewith\nlocally approximated by an algebraic variety determined algebraically from the\nmechanism's screw system. Results are shown for a simple planar 4-bar linkage,\nwhich exhibits a bifurcation singularity, and for a planar three-loop linkage\nexhibiting a cusp in c-space. The latter cannot be treated by the higher-order\nlocal analysis methods proposed in the literature.", "AI": {"tldr": "Higher-order local mobility analysis for multi-loop linkages using Taylor expansion of geometric constraints and joint screws, addressing limitations of smooth motion assumptions in existing methods.", "motivation": "Existing higher-order mobility analysis methods assume smooth motions, limiting their generality. The paper aims to develop a more comprehensive approach that can handle constraint singularities and non-smooth motions in multi-loop linkages.", "method": "Uses higher-order Taylor series expansion of geometric constraint mapping with recursive algebraic expressions in terms of joint screws. Includes local approximation of configurations with certain rank and explicit expressions for differentials of Jacobian minors.", "result": "The approach successfully analyzes complex singularities including bifurcation singularities in 4-bar linkages and cusps in c-space for planar three-loop linkages that cannot be handled by existing methods.", "conclusion": "The presented higher-order local mobility analysis method provides a more general framework that can handle constraint singularities and complex c-space geometries beyond the limitations of smooth motion assumptions in previous approaches."}}
{"id": "2508.13772", "pdf": "https://arxiv.org/pdf/2508.13772", "abs": "https://arxiv.org/abs/2508.13772", "authors": ["Alexandros Matsoukas", "Nikos Yannakakis"], "title": "A double-phase Neumann problem with $p=1$", "categories": ["math.AP", "Primary 35J60, 35J25, 35J75 Secondary 46E35, 35J92, 35D30"], "comment": "18 pages", "summary": "We study a double-phase Neumann problem with non-homogeneous boundary\nconditions, where the lowest exponent $p$ is equal to 1. The existence of a\nsolution is established as the limit of solutions to corresponding double-phase\nproblems with $p>1$. We also provide a variational characterization of the\nlimit.", "AI": {"tldr": "Existence and variational characterization of solutions for double-phase Neumann problems with p=1 via limit of p>1 solutions", "motivation": "Study double-phase Neumann problems with non-homogeneous boundary conditions where the lowest exponent p equals 1, which presents mathematical challenges requiring special treatment", "method": "Establish solution existence as the limit of solutions to corresponding double-phase problems with p>1, and provide variational characterization of this limit", "result": "Proved existence of solutions for the p=1 case through limiting process from p>1 problems, and obtained variational characterization of the limiting solution", "conclusion": "The approach successfully handles the challenging p=1 case by connecting it to better-understood p>1 problems through limit analysis and variational methods"}}
{"id": "2508.13793", "pdf": "https://arxiv.org/pdf/2508.13793", "abs": "https://arxiv.org/abs/2508.13793", "authors": ["S\u00e1ndor Kaj\u00e1nt\u00f3"], "title": "Sharp Hardy and spectral gap inequalities on special irreversible Finsler manifolds", "categories": ["math.AP", "math.DG", "math.FA"], "comment": null, "summary": "The sharpness of various Hardy-type inequalities is well-understood in the\nreversible Finsler setting; while infinite reversibility implies the failure of\nthese functional inequalities, cf. Krist\\'aly, Huang, and Zhao [Trans. Am.\nMath. Soc., 2020]. However, in the remaining case of irreversible manifolds\nwith finite reversibility, there is no evidence on the sharpness of Hardy-type\ninequalities. In fact, we are not aware of any particular examples where the\nsharpness persists. In this paper we present two such examples involving two\ncelebrated inequalities: the classical/weighted Hardy inequality (assuming\nnon-positive flag curvature) and the McKean-type spectral gap estimate\n(assuming strong negative flag curvature). In both cases, we provide a family\nof Finsler metric measure manifolds on which these inequalities are sharp. We\nalso establish some sufficient conditions, which guarantee the sharpness of\nmore involved Hardy-type inequalities on these spaces. Our relevant technical\ntool is a Finslerian extension of the method of Riccati pairs (for proving\nHardy inequalities), which also inspires the main ideas of our constructions.", "AI": {"tldr": "This paper provides the first examples of sharp Hardy-type inequalities on irreversible Finsler manifolds with finite reversibility, addressing a gap in the literature where sharpness was only known for reversible cases.", "motivation": "Previous research showed Hardy-type inequalities fail on manifolds with infinite reversibility, but there was no evidence of sharpness on irreversible manifolds with finite reversibility. The authors aimed to find specific examples where these inequalities remain sharp.", "method": "The authors constructed families of Finsler metric measure manifolds and used a Finslerian extension of the method of Riccati pairs to prove sharpness of Hardy inequalities. They established sufficient conditions for sharpness of more complex Hardy-type inequalities.", "result": "The paper successfully provides two concrete examples where classical/weighted Hardy inequality (with non-positive flag curvature) and McKean-type spectral gap estimate (with strong negative flag curvature) are sharp on irreversible Finsler manifolds.", "conclusion": "This work fills an important gap by demonstrating that Hardy-type inequalities can be sharp on irreversible Finsler manifolds with finite reversibility, using novel construction methods and Riccati pair techniques adapted to the Finsler setting."}}
{"id": "2508.13879", "pdf": "https://arxiv.org/pdf/2508.13879", "abs": "https://arxiv.org/abs/2508.13879", "authors": ["Matthias Deiml", "Daniel Peterseim"], "title": "Quantum Sampling and Moment Estimation for Transformed Gaussian Random Fields", "categories": ["quant-ph", "cs.NA", "math.NA", "math.PR", "68Q12, 81P68, 60G15, 65C30, 35R60"], "comment": null, "summary": "We present a quantum algorithm for efficiently sampling transformed Gaussian\nrandom fields on $d$-dimensional domains, based on an enhanced version of the\nclassical moving average method. Pointwise transformations enforcing\nboundedness are essential for using Gaussian random fields in quantum\ncomputation and arise naturally, for example, in modeling coefficient fields\nrepresenting microstructures in partial differential equations. Generating this\nmicrostructure from its few statistical parameters directly on the quantum\ndevice bypasses the input bottleneck. Our method enables an efficient quantum\nrepresentation of the resulting random field and prepares a quantum state\napproximating it to accuracy $\\mathtt{tol} > 0$ in time\n$\\mathcal{O}(\\operatorname{polylog} \\mathtt{tol}^{-1})$. Combined with\namplitude estimation and a quantum pseudorandom number generator, this leads to\nalgorithms for estimating linear and nonlinear observables, including mixed and\nhigher-order moments, with total complexity $\\mathcal{O}(\\mathtt{tol}^{-1}\n\\operatorname{polylog} \\mathtt{tol}^{-1})$. We illustrate the theoretical\nfindings through numerical experiments on simulated quantum hardware.", "AI": {"tldr": "Quantum algorithm for efficient sampling of transformed Gaussian random fields with polylogarithmic time complexity in accuracy tolerance.", "motivation": "To overcome the input bottleneck in quantum computation by generating microstructure fields directly on quantum devices from statistical parameters, enabling efficient representation of bounded Gaussian random fields essential for modeling microstructures in PDEs.", "method": "Enhanced classical moving average method combined with pointwise transformations for boundedness, using amplitude estimation and quantum pseudorandom number generation for observable estimation.", "result": "Achieves quantum state preparation in O(polylog tol\u207b\u00b9) time and total complexity O(tol\u207b\u00b9 polylog tol\u207b\u00b9) for estimating linear/nonlinear observables including mixed/higher-order moments, validated through numerical experiments.", "conclusion": "The method provides efficient quantum representation of transformed Gaussian fields with superior scaling compared to classical approaches, enabling practical quantum computation applications in microstructure modeling and PDE coefficient field generation."}}
{"id": "2508.13871", "pdf": "https://arxiv.org/pdf/2508.13871", "abs": "https://arxiv.org/abs/2508.13871", "authors": ["Manh Hong Duong", "Zihui He"], "title": "GENERIC formulation and small-angle limit for Kinetic wave equations", "categories": ["math.AP", "math-ph", "math.MP"], "comment": null, "summary": "In this paper, we formulate the three-wave and four-wave kinetic equations\ninto the GENERIC framework and formally derive a small-angle limit for the\nfour-wave equation. This limit is akin to the well-known grazing limit from the\nkinetic Boltzmann equation to the kinetic Landau equation. We also show the\nGENERIC structure of the limiting system.", "AI": {"tldr": "Formulating wave kinetic equations into GENERIC framework and deriving small-angle limit for four-wave equation similar to Boltzmann-Landau grazing limit", "motivation": "To establish a connection between wave kinetic equations and the GENERIC (General Equation for Non-Equilibrium Reversible-Irreversible Coupling) framework, and to derive a small-angle limit analogous to the classical grazing collision limit in kinetic theory", "method": "Formulating three-wave and four-wave kinetic equations within the GENERIC framework, and formally deriving a small-angle limit for the four-wave equation that parallels the Boltzmann-to-Landau grazing collision limit", "result": "Successfully formulated both three-wave and four-wave kinetic equations into the GENERIC structure, derived the small-angle limit for the four-wave equation, and demonstrated that the limiting system maintains the GENERIC structure", "conclusion": "The work provides a systematic framework for wave kinetic equations through GENERIC formalism and establishes a rigorous connection between four-wave kinetics and small-angle scattering limits, analogous to established results in particle kinetic theory"}}
{"id": "2508.13991", "pdf": "https://arxiv.org/pdf/2508.13991", "abs": "https://arxiv.org/abs/2508.13991", "authors": ["Jonathan W. Siegel"], "title": "Nearly Optimal Bounds on the Fourier sampling numbers of Besov Spaces", "categories": ["math.FA", "cs.IT", "cs.NA", "math.IT", "math.NA", "41A46, 42A05, 46B09, 46N40, 65T40"], "comment": null, "summary": "Let $\\mathbb{T}^d$ denote the $d$-dimensional torus. We consider the problem\nof optimally recovering a target function $f^*:\\mathbb{T}^d\\rightarrow\n\\mathbb{C}$ from samples of its Fourier coefficients. We make classical\nsmoothness assumptions on $f^*$, specifically that $f^*$ lies in a Besov space\n$B^s_\\infty(L_q)$ with $s > 0$ and $1\\leq q\\leq \\infty$, and measure recovery\nerror in the $L_p$-norm with $1\\leq p\\leq \\infty$. Abstractly, the optimal\nrecovery error is characterized by a `restricted' version of the Gelfand\nwidths, which we call the Fourier sampling numbers. Up to logarithmic factors,\nwe determine the correct asymptotics of the Fourier sampling numbers in the\nregime $s/d > 1 - 1/p$. We also give a description of nearly optimal Fourier\nmeasurements and recovery algorithms in each of these cases. In the other\ndirection, we prove a novel lower bound showing that there is an asymptotic gap\nbetween the Fourier sampling numbers and the Gelfand widths when $q = 1$ and\n$p_0 < p\\leq 2$ with $p_0 \\approx 1.535$. Finally, we discuss the practical\nimplications of our results, which imply a sharper recovery of edges, and\nprovide numerical results demonstrating this phenomenon.", "AI": {"tldr": "Optimal recovery of functions from Fourier samples on d-dimensional torus using Besov space smoothness assumptions, with characterization via Fourier sampling numbers and asymptotic gap analysis.", "motivation": "To understand the fundamental limits of recovering functions from Fourier coefficient samples, particularly for functions with classical smoothness properties in Besov spaces, and to characterize optimal recovery error.", "method": "Theoretical analysis using restricted Gelfand widths (Fourier sampling numbers), asymptotic analysis of sampling numbers, construction of nearly optimal Fourier measurements and recovery algorithms, and novel lower bound proofs.", "result": "Determined correct asymptotics of Fourier sampling numbers (up to logarithmic factors) for regime s/d > 1 - 1/p, identified asymptotic gap between Fourier sampling numbers and Gelfand widths for specific parameter ranges (q=1, p0<p\u22642), and provided practical implications for edge recovery.", "conclusion": "The paper establishes fundamental limits for Fourier-based function recovery, provides optimal measurement strategies, and reveals important gaps between different complexity measures, with practical applications in edge-preserving reconstruction."}}
{"id": "2508.13916", "pdf": "https://arxiv.org/pdf/2508.13916", "abs": "https://arxiv.org/abs/2508.13916", "authors": ["Emanuele Tasso", "Tobias Unterberger"], "title": "Effective theories for incompressible magnetoelastic shallow shells", "categories": ["math.AP"], "comment": "33 pages", "summary": "We characterize the asymptotic behaviour, in the sense of\n$\\Gamma$-convergence, of a thin magnetoelastic shallow shell. The compactness\nis achieved up to rigid motions. For deformations, it relies on an\napproximation by rigid movements, whereas for magnetizations it is based on a\ncareful consideration of the geometry of the deformed domain. The result is\nobtained by a combination of variational methods ($\\Gamma$-convergence) with\ndegree theory, fixed-point and geometrical arguments. The proof strategy relies\non an adaptation of an analogous result for incompressible magnetoelastic\nplates from M. Bresciani in arXiv:2007.14122 and an application of results by\nI.Velcic on elastic shallow shells in arXiv:1102.2647.", "AI": {"tldr": "Analysis of asymptotic behavior of thin magnetoelastic shallow shells using \u0393-convergence, combining variational methods with degree theory and geometric arguments.", "motivation": "To characterize the asymptotic behavior of thin magnetoelastic shallow shells, extending previous work on incompressible magnetoelastic plates and elastic shallow shells.", "method": "Combination of variational methods (\u0393-convergence) with degree theory, fixed-point arguments, and geometric analysis. Uses approximation by rigid movements for deformations and careful consideration of deformed domain geometry for magnetizations.", "result": "Achieved compactness up to rigid motions and characterized the asymptotic behavior through \u0393-convergence.", "conclusion": "Successfully extended analytical framework from previous works to thin magnetoelastic shallow shells, providing rigorous mathematical characterization of their asymptotic behavior."}}
{"id": "2508.14004", "pdf": "https://arxiv.org/pdf/2508.14004", "abs": "https://arxiv.org/abs/2508.14004", "authors": ["Sergey Salishev", "Ian Akhremchik"], "title": "GDNSQ: Gradual Differentiable Noise Scale Quantization for Low-bit Neural Networks", "categories": ["cs.LG", "cs.IT", "cs.NA", "math.IT", "math.NA", "68T07, 90C26", "I.2.6; E.4; G.1.6"], "comment": "9 pages, 6 figures, 7 tables", "summary": "Quantized neural networks can be viewed as a chain of noisy channels, where\nrounding in each layer reduces capacity as bit-width shrinks; the\nfloating-point (FP) checkpoint sets the maximum input rate. We track capacity\ndynamics as the average bit-width decreases and identify resulting quantization\nbottlenecks by casting fine-tuning as a smooth, constrained optimization\nproblem. Our approach employs a fully differentiable Straight-Through Estimator\n(STE) with learnable bit-width, noise scale and clamp bounds, and enforces a\ntarget bit-width via an exterior-point penalty; mild metric smoothing (via\ndistillation) stabilizes training. Despite its simplicity, the method attains\ncompetitive accuracy down to the extreme W1A1 setting while retaining the\nefficiency of STE.", "AI": {"tldr": "A novel quantization method that treats neural networks as noisy channels, using differentiable STE with learnable parameters and exterior-point penalty to achieve competitive accuracy even at extreme W1A1 quantization while maintaining efficiency.", "motivation": "Quantization reduces neural network capacity as bit-width decreases, creating bottlenecks. The paper aims to track capacity dynamics and identify quantization bottlenecks by framing fine-tuning as a constrained optimization problem.", "method": "Uses a fully differentiable Straight-Through Estimator (STE) with learnable bit-width, noise scale and clamp bounds. Enforces target bit-width via exterior-point penalty and stabilizes training with metric smoothing through distillation.", "result": "Achieves competitive accuracy down to the extreme W1A1 (1-bit weights, 1-bit activations) quantization setting while retaining the computational efficiency of STE-based approaches.", "conclusion": "The proposed method successfully addresses quantization bottlenecks through a constrained optimization framework with learnable parameters, demonstrating that simple yet effective techniques can achieve extreme quantization without sacrificing too much accuracy."}}
{"id": "2508.13971", "pdf": "https://arxiv.org/pdf/2508.13971", "abs": "https://arxiv.org/abs/2508.13971", "authors": ["Dian Hu", "Qianfeng Li", "Yongqian Zhang"], "title": "On the one-dimensional piston model with Large Velocity Variations", "categories": ["math.AP"], "comment": null, "summary": "This paper investigates the dynamics of a one-dimensional piston expanding\ninto a static rarefied gas. Using asymptotic analysis in the limit of vanishing\ninitial density, we derive sharp estimates for the piston-shock distance, the\nseparation of characteristic speeds, and the reflection coefficient associated\nwith characteristic waves interacting with the leading shock front. Based on\nthese estimates, we apply the method of characteristics to prove the\nglobal-in-time existence of piecewise smooth solutions. The resulting flow\nstructure exhibits significant velocity variations. The analysis reveals a\nstable mechanism that operates in the vanishing-density limit of the piston\nmodel.", "AI": {"tldr": "Analysis of 1D piston expanding into rarefied gas using asymptotic methods to prove global existence of piecewise smooth solutions with significant velocity variations.", "motivation": "Investigate the dynamics of a one-dimensional piston expanding into static rarefied gas and understand the flow structure in the vanishing-density limit.", "method": "Asymptotic analysis in vanishing initial density limit, derivation of sharp estimates for piston-shock distance, characteristic speed separation, and reflection coefficients. Application of method of characteristics.", "result": "Proved global-in-time existence of piecewise smooth solutions with significant velocity variations. Revealed a stable mechanism operating in the vanishing-density limit.", "conclusion": "The analysis successfully demonstrates the existence and stability of solutions for piston expansion in rarefied gas, providing insights into characteristic wave interactions and shock front dynamics."}}
{"id": "2508.13353", "pdf": "https://arxiv.org/pdf/2508.13353", "abs": "https://arxiv.org/abs/2508.13353", "authors": ["Lawford Hatcher"], "title": "Hot spots in domains of constant curvature", "categories": ["math.SP", "math.AP", "math.DG", "35P05, 35B38, 35J05, 35J25, 58J50"], "comment": "29 pages, 0 figures", "summary": "We prove constant-curvature analogues of several results regarding the hot\nspots conjecture in dimension two. Our main theorem shows that the hot spots\nconjecture holds for all non-acute geodesic triangles of constant negative\ncurvature. We also prove that, under certain circumstances, on constant\n(positive or negative) curvature triangles, first mixed Dirichlet-Neumann\nLaplace eigenfunctions have no non-vertex critical points. Moreover, we show\nthat each of these eigenfunctions is monotonic with respect to some Killing\nfield. Finally, we show that for general simply connected polygons of non-zero\nconstant curvature--with exactly one family of exceptions--second Neumann\neigenfunctions of the Laplacian have at most finitely many critical points.", "AI": {"tldr": "The paper proves constant-curvature versions of hot spots conjecture results in 2D, showing it holds for non-acute geodesic triangles in negative curvature, establishes properties of eigenfunctions on constant curvature triangles, and shows second Neumann eigenfunctions have finite critical points in most simply connected polygons.", "motivation": "To extend the hot spots conjecture and related eigenfunction analysis from Euclidean geometry to constant curvature spaces (both positive and negative curvature), providing geometric insights in non-Euclidean settings.", "method": "Mathematical proof techniques involving geometric analysis on constant curvature surfaces, studying Laplace eigenfunctions on geodesic triangles and polygons with Dirichlet-Neumann boundary conditions, and employing Killing field monotonicity properties.", "result": "Proved hot spots conjecture for non-acute geodesic triangles in constant negative curvature; showed first mixed Dirichlet-Neumann eigenfunctions have no non-vertex critical points and are monotonic with respect to some Killing field; demonstrated second Neumann eigenfunctions have finitely many critical points in most simply connected polygons.", "conclusion": "The hot spots conjecture and related eigenfunction properties can be successfully extended to constant curvature geometries, with most results holding analogously to the Euclidean case, though with some specific exceptions in certain geometric configurations."}}
{"id": "2508.13658", "pdf": "https://arxiv.org/pdf/2508.13658", "abs": "https://arxiv.org/abs/2508.13658", "authors": ["Faruk Alpay", "Hamdi Alakkad"], "title": "Calibrated Semantic Diffusion: A p-Laplacian Synthesis with Learnable Dissipation, Quantified Constants, and Graph-Aware Calibration", "categories": ["math.OC", "math.AP", "math.DS", "68T07, 35K55, 93D20, 35B40, 05C50"], "comment": "15 pages, 5 tables", "summary": "We develop a calibrated diffusion framework by synthesizing three established\nconcepts: linear Laplacian smoothing, nonlinear graph p-Laplacian flows, and a\nlearnable dissipation term derived from a strongly convex potential. This\nsynthesis provides a general model for graph-based diffusion with controllable\ndynamics. Our key theoretical results include a quantified two-regime decay\nanalysis for $p>2$, which provides stronger, p-dependent transient bounds not\ncaptured by standard ISS templates, and the first formalization of a\n\"non-synonymy\" impossibility principle, which proves that fixed-parameter\nmodels cannot meet universal performance targets across graphs with varying\nspectral properties. To address this, we propose a constructive calibration\nalgorithm (SGPS) with formal guarantees for achieving target rates and mass. We\nderive explicit, closed-form lower bounds for the graph p-gap on canonical\ngraphs a notable improvement over prior implicit estimates and provide sharp\nconstants for discrete-time and stochastic stability, including a\ncontextualized restatement of the necessary and sufficient Euler step-size and\na strengthened analysis of the stochastic noise floor. Illustrative,\nsmall-scale empirical validations confirm the tightness of key theoretical\nbounds.", "AI": {"tldr": "A calibrated diffusion framework combining linear Laplacian smoothing, nonlinear graph p-Laplacian flows, and learnable dissipation for controllable graph-based diffusion dynamics.", "motivation": "To develop a general model for graph-based diffusion with controllable dynamics that addresses limitations of fixed-parameter models in handling graphs with varying spectral properties.", "method": "Synthesizes linear Laplacian smoothing, nonlinear graph p-Laplacian flows, and a learnable dissipation term from strongly convex potential. Proposes constructive calibration algorithm (SGPS) with formal guarantees.", "result": "Quantified two-regime decay analysis for p>2 with p-dependent transient bounds, formalization of \"non-synonymy\" impossibility principle, explicit closed-form lower bounds for graph p-gap, and sharp constants for discrete-time/stochastic stability.", "conclusion": "The framework provides stronger theoretical bounds and practical calibration methods for graph diffusion, with empirical validation confirming tightness of theoretical results."}}
{"id": "2508.13671", "pdf": "https://arxiv.org/pdf/2508.13671", "abs": "https://arxiv.org/abs/2508.13671", "authors": ["Hongyi Chen", "Cheuk Yin Lee"], "title": "Propagation of Singularities for the Damped Stochastic Klein-Gordon Equation", "categories": ["math.PR", "math.AP"], "comment": null, "summary": "For the $1+1$ dimensional damped stochastic Klein-Gordon equation, we show\nthat random singularities associated with the law of the iterated logarithm\nexist and propogate in the same way as the stochastic wave equation. This\nprovides evidence for possible connections to microlocal analysis, ie. the\nexact regularity and singularities described in this paper should admit\nwavefront set type descriptions whose propagation is determined by the highest\norder terms of the linear operator. Despite the results being exactly the same\nas those of the wave equation, our proofs are significantly different than the\nproofs for the wave equation. Miraculously, proving our results for the\ncritically damped equation implies them for the general equation, which\nsignificantly simplifies the problem. Even after this simplification, many\nimportant parts of the proof are significantly different than (and we think are\nmore intuitive from the PDE viewpoint compared to) existing proofs for the wave\nequation.", "AI": {"tldr": "Random singularities with law of iterated logarithm behavior exist and propagate in 1+1 dimensional damped stochastic Klein-Gordon equation, similar to stochastic wave equation.", "motivation": "To investigate the connection between damped stochastic Klein-Gordon equations and microlocal analysis, particularly wavefront set descriptions of singularities determined by highest order terms of the linear operator.", "method": "Analysis of the 1+1 dimensional damped stochastic Klein-Gordon equation, with proofs that differ significantly from those for the wave equation. The approach shows that proving results for the critically damped equation implies them for the general equation.", "result": "The paper demonstrates that random singularities associated with the law of iterated logarithm exist and propagate in the same manner as in the stochastic wave equation.", "conclusion": "The findings provide evidence for connections to microlocal analysis and show that despite identical results to the wave equation, the proofs are substantially different and more intuitive from a PDE perspective."}}
{"id": "2508.13717", "pdf": "https://arxiv.org/pdf/2508.13717", "abs": "https://arxiv.org/abs/2508.13717", "authors": ["Sebastiano Nicolussi Golo", "Francesco Serra Cassano", "Mattia Vedovato"], "title": "The Bernstein problem for Sobolev intrinsic graphs in the Heisenberg group", "categories": ["math.DG", "math.AP", "53C17, 49Q20"], "comment": "16 pages", "summary": "In the first Heisenberg group, we study entire, locally Sobolev intrinsic\ngraphs that are stable for the sub-Riemannian area. We show that, under\nappropriate integrability conditions for the derivatives, the intrinsic graph\nmust be an intrinsic plane, i.e., a coset of a two dimensional subgroup. This\nresult extends \\cite{arXiv:1809.04586} beyond the Lipschitz class.", "AI": {"tldr": "Stable intrinsic graphs in the Heisenberg group must be intrinsic planes under appropriate integrability conditions, extending previous Lipschitz results.", "motivation": "To extend the understanding of stable minimal surfaces in sub-Riemannian geometry beyond the Lipschitz class, particularly in the Heisenberg group where previous results were limited to Lipschitz functions.", "method": "Study entire, locally Sobolev intrinsic graphs that are stable for the sub-Riemannian area in the first Heisenberg group. Apply appropriate integrability conditions for the derivatives to analyze stability properties.", "result": "Under the specified integrability conditions, any such stable intrinsic graph must be an intrinsic plane - specifically, a coset of a two-dimensional subgroup. This generalizes previous results from the Lipschitz class to a broader function class.", "conclusion": "The research successfully extends the classification of stable minimal surfaces in the Heisenberg group, showing that intrinsic planes are the only possible stable configurations under given conditions, even beyond the Lipschitz framework."}}
