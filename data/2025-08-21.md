<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 5]
- [math.AP](#math.AP) [Total: 11]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [quant-ph](#quant-ph) [Total: 2]
- [cs.DS](#cs.DS) [Total: 1]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [math.PR](#math.PR) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 2]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Band-Limited Equivalence of Convolution Operators and its Application to Filtered Vorticity Dynamics](https://arxiv.org/abs/2508.14108)
*Satori Tsuzuki*

Main category: math.NA

TL;DR: Two convolution kernels with identical Fourier transforms within a spectral band act equivalently on band-limited functions, regardless of differences outside the band. This explains why real-space diagnostics can underestimate spectral proportionality in filtered vorticity dynamics.


<details>
  <summary>Details</summary>
Motivation: To establish a fundamental theorem about convolution operator equivalence in finite spectral bands, addressing practical challenges in applied mathematics and computational physics where measurements are spectrally truncated.

Method: Developed a general theorem proving equivalence of convolution operators restricted to finite spectral bands, and applied it to analyze filtered vorticity dynamics with numerical validation using synthetic data.

Result: Demonstrated that kernels with identical Fourier transforms over a resolved band produce identical effects on band-limited functions. Showed that real-space diagnostics underestimate spectral proportionality due to unobservable degrees of freedom.

Conclusion: The equivalence theorem provides important insights for spectral truncation scenarios in computational physics, explaining limitations of real-space measurements and offering theoretical foundation for filtered dynamics analysis.

Abstract: In this study, we established a general theorem regarding the equivalence of
convolution operators restricted to a finite spectral band. We demonstrated
that two kernels with identical Fourier transforms over the resolved band act
identically on all band-limited functions, even if their kernels differ outside
the band. This property is significant in applied mathematics and computational
physics, particularly in scenarios where measurements or simulations are
spectrally truncated. As an application, we examine the proportionality
relation $S(\boldsymbol {r}) \approx \zeta\,\omega(\boldsymbol{r})$ in filtered
vorticity dynamics and clarify why real-space diagnostics can underestimate the
spectral proportionality due to unobservable degrees of freedom. Our
theoretical findings were supported by numerical illustrations using synthetic
data.

</details>


### [2] [A High Performance GPU CountSketch Implementation and Its Application to Multisketching and Least Squares Problems](https://arxiv.org/abs/2508.14209)
*Andrew J. Higgins,Erik G. Boman,Ichitaro Yamazaki*

Main category: math.NA

TL;DR: Efficient GPU implementation of CountSketch for multisketching, achieving up to 77% faster least squares solving with better numerical stability than normal equations.


<details>
  <summary>Details</summary>
Motivation: Random sketching techniques like CountSketch offer dimensionality reduction but lack high-performance implementations, particularly for GPU environments where they could provide significant speedups.

Method: Developed an optimized GPU implementation of CountSketch and combined it with Gaussian sketching (multisketching) to create an efficient dimensionality reduction approach for matrix operations.

Result: The implementation enables multisketched least squares solving that is up to 77% faster than normal equations while maintaining better numerical stability, with only an O(1) multiplicative factor introduced into the relative residual norm.

Conclusion: GPU-optimized CountSketch implementation enables efficient multisketching that significantly accelerates least squares problems while preserving numerical stability, making it a practical alternative to traditional methods.

Abstract: Random sketching is a dimensionality reduction technique that approximately
preserves norms and singular values up to some $O(1)$ distortion factor with
high probability. The most popular sketches in literature are the Gaussian
sketch and the subsampled randomized Hadamard transform, while the CountSketch
has lower complexity. Combining two sketches, known as multisketching, offers
an inexpensive means of quickly reducing the dimension of a matrix by combining
a CountSketch and Gaussian sketch.
  However, there has been little investigation into high performance
CountSketch implementations. In this work, we develop an efficient GPU
implementation of the CountSketch, and demonstrate the performance of
multisketching using this technique. We also demonstrate the potential for
using this implementation within a multisketched least squares solver that is
up to $77\%$ faster than the normal equations with significantly better
numerical stability, at the cost of an $O(1)$ multiplicative factor introduced
into the relative residual norm.

</details>


### [3] [A well-balanced gas-kinetic scheme with adaptive mesh refinement for shallow water equations](https://arxiv.org/abs/2508.14216)
*Gaocheng Liu,Fengxiang Zhao,Jianping Gan,Kun Xu*

Main category: math.NA

TL;DR: A well-balanced gas-kinetic scheme with space-time adaptive mesh refinement for shallow water equations on arbitrary quadrilateral meshes with hanging nodes, achieving improved computational efficiency and robust performance.


<details>
  <summary>Details</summary>
Motivation: To extend well-balanced gas-kinetic schemes to arbitrary quadrilateral meshes with hanging nodes in space-time adaptive mesh refinement frameworks, addressing challenges in maintaining well-balanced properties while improving computational efficiency.

Method: Developed a gas-kinetic scheme with space-time adaptive mesh refinement using arbitrary quadrilateral meshes with hanging nodes, incorporating temporal adaptivity through adaptive time steps for different refinement levels, and adaptive flux transitions between equilibrium and non-equilibrium states.

Result: The proposed scheme demonstrates strong robustness, high accuracy, and high resolution in standard benchmarks and realistic cases, effectively capturing interfaces and simulating complex flows.

Conclusion: The GKS-based STAMR framework successfully handles arbitrary quadrilateral meshes with hanging nodes while maintaining well-balanced properties, offering significant improvements in computational efficiency and performance for shallow water equation simulations.

Abstract: This paper is about the construction of a well-balanced gas-kinetic scheme
(GKS) with space-time adaptive mesh refinement (STAMR) for the shallow water
equations (SWE). While the well-balanced GKS has been established on Cartesian
and triangular meshes, the present STAMR framework employs arbitrary
quadrilateral meshes with hanging nodes, posing additional challenges for
constructing well-balanced schemes. Complementing spatial adaptivity, temporal
adaptivity is achieved by selecting adaptive time steps for cells of different
refinement levels; the resulting STAMR further improves computational
efficiency. Moreover, the numerical flux of the GKS adaptively makes
transitions between equilibrium fluxes for smooth flows and non-equilibrium
fluxes for discontinuities, endowing the proposed GKS-based AMR method with
strong robustness, high accuracy, and high resolution. Standard benchmarks and
realistic cases validate the GKS-based STAMR and highlight its potential for
interface capturing and complex flow simulations.

</details>


### [4] [Basis Construction for Spline Spaces over Arbitrary Partitions from a Dimensional Stable Perspective](https://arxiv.org/abs/2508.14649)
*Bingru Huang,Falai Chen*

Main category: math.NA

TL;DR: Novel framework for constructing C^r basis functions for polynomial spline spaces over arbitrary polygonal partitions, overcoming dimensional instability limitations


<details>
  <summary>Details</summary>
Motivation: To overcome the long-standing belief that basis functions cannot be constructed on dimensionally unstable meshes and provide a comprehensive solution for spline spaces

Method: Semi-explicit construction using Extended Edge Elimination conditions to ensure complete basis functions

Result: Successfully constructed basis functions for spline space over Morgan-Scott partition (previously unachieved) and resolved dimensional instability issues

Conclusion: The framework provides the first complete solution for basis construction in spline spaces, overturning previous limitations and enabling new applications

Abstract: This paper introduces a novel framework for constructing $C^r$ basis
functions for polynomial spline spaces of degree $d$ over arbitrary planar
polygonal partitions, overturning the belief that basis functions cannot be
constructed on dimensionally unstable meshes. We provide a comprehensive
comparison of basis construction methods, classifying them as explicit,
semi-explicit, and implicit. Our method, a semi-explicit construction using
Extended Edge Elimination conditions, uniquely resolves all theoretical
challenges in spline spaces by ensuring a complete basis. For the first time,
we construct basis functions for the spline space over the Morgan-Scott
partition, previously unachieved, and elucidate dimensional instability through
this construction.

</details>


### [5] [Exact $\ell^\infty$-separation radius of Sobol' sequences in dimension 2](https://arxiv.org/abs/2508.14803)
*Kosuke Suzuki*

Main category: math.NA

TL;DR: The paper analyzes the quasi-uniformity of 2D Sobol' sequences, disproving a previous conjecture about optimal separation rates and showing suboptimal mesh ratio growth.


<details>
  <summary>Details</summary>
Motivation: Understanding quasi-uniformity of Sobol' sequences is crucial for applications like kernel interpolation and Gaussian process regression, but previous conjectures about optimal separation rates needed verification.

Method: Derived exact expressions for the ℓ∞-separation radius of the first N=2^m points of the two-dimensional Sobol' sequence for all natural numbers m.

Result: Showed that the separation radius of Sobol' points is O(N^{-3/4}), strictly worse than the optimal rate N^{-1/2}, revealing suboptimal mesh ratio growth of at least N^{1/4}.

Conclusion: The two-dimensional Sobol' sequence has suboptimal quasi-uniformity properties with mesh ratio growing at least as N^{1/4}, contrary to previous conjectures about optimal performance.

Abstract: Quasi-uniformity is a fundamental geometric property of point sets, crucial
for applications such as kernel interpolation, Gaussian process regression, and
space-filling experimental designs. While quasi-Monte Carlo methods are widely
recognized for their low-discrepancy characteristics, understanding their
quasi-uniformity remains important for practical applications. For the
two-dimensional Sobol' sequence, Sobol' and Shukhman (2007) conjectured that
the separation radius of the first $N$ points achieves the optimal rate
$N^{-1/2}$, which would imply quasi-uniformity. This conjecture was disproved
by Goda (2024), who computed exact values of the $\ell^2$-separation radius for
a sparse subsequence $N = 2^{2^v-1}$. However, the general behavior of the
Sobol' sequence for arbitrary $N$ remained unclear. In this paper, we derive
exact expressions for the $\ell^\infty$-separation radius of the first $N =
2^m$ points of the two-dimensional Sobol' sequence for all $m \in \mathbb{N}$.
As an immediate consequence, we show that the separation radius of Sobol'
points is $O(N^{-3/4})$, which is strictly worse than the optimal rate
$N^{-1/2}$, revealing that the two-dimensional Sobol' sequence has a suboptimal
mesh ratio that grows at least as $N^{1/4}$.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [6] [Three-dimensional Navier-Stokes-Biot coupling via a moving reticular plate interface: existence of weak solutions](https://arxiv.org/abs/2508.14310)
*Felix Brandt,Sunčica Čanić,Boris Muha*

Main category: math.AP

TL;DR: Existence of finite-energy weak solutions for 3D fluid-structure interaction with multilayered poro(visco)elastic structure and nonlinear free-boundary coupling, using regularization and operator-splitting.


<details>
  <summary>Details</summary>
Motivation: To address the ill-defined classical weak formulation at finite energy caused by nonlinear free-boundary coupling and limited regularity of Biot displacement in 3D fluid-structure interaction problems.

Method: Introduce minimally invasive regularization via extension and convolution of Biot displacement, construct approximate solutions using Lie operator-splitting scheme, derive uniform energy bounds, and use refined compactness arguments including Aubin-Lions lemma variants.

Result: Proved existence of finite-energy weak solutions for the regularized 3D FSI problem, applicable to both purely elastic and poroviscoelastic cases.

Conclusion: First existence result for nonlinearly coupled, multilayer 3D Navier-Stokes-Biot FSI system with permeable interface, extending previous 2D analysis to full 3D setting.

Abstract: We prove the existence of finite-energy weak solutions to a regularized
three-dimensional fluid-structure interaction (FSI) problem involving an
incompressible, viscous, Newtonian fluid and a multilayered poro(visco)elastic
structure. The structure consists of a thick layer modeled by the Biot
equations and a thin reticular plate with inertia and elastic energy,
transparent to fluid flow. The coupling is nonlinear in the sense that it takes
place on a moving interface that is not known a priori but is defined by the
solution itself, making the problem a moving-boundary problem. This nonlinear
free-boundary coupling, combined with the limited regularity of the Biot
displacement, renders the classical weak formulation ill-defined at finite
energy. To address this, we introduce a minimally invasive regularization based
on a suitable extension and convolution of the Biot displacement, chosen so
that the regularized problem remains consistent with the original model. We
then construct approximate solutions to the regularized problem via a Lie
operator-splitting scheme and derive uniform energy bounds. While these bounds
ensure weak and weak* convergence, passing to the limit in the nonlinear terms
requires refined compactness arguments, including variants of the Aubin-Lions
lemma and tools adapted to moving non-Lipschitz interfaces. The result applies
in particular to the purely elastic case (without structural damping) as well
as the poroviscoelastic case. This work extends the two-dimensional analysis of
Kuan-\v{C}ani\'c-Muha 2024 to the fully three-dimensional setting and, to our
knowledge, provides the first existence result for a nonlinearly coupled,
multilayer 3D Navier-Stokes-Biot FSI system with a permeable interface.

</details>


### [7] [Carleman estimates for stationary $Q$-valued maps: a variational approach](https://arxiv.org/abs/2508.14388)
*Aria Halavati,Luca Spolaor*

Main category: math.AP

TL;DR: Carleman estimate for Dirichlet-stationary multivalued functions used to prove optimal dimension of singular set for Dir-minimizing functions


<details>
  <summary>Details</summary>
Motivation: To provide an alternative proof for the optimal dimension of singular sets in Dir-minimizing multivalued functions, building on previous work by Almgren and De Lellis-Spadaro

Method: Developed a Carleman-type estimate specifically for Dirichlet-stationary multivalued functions and applied this estimate to analyze singular sets

Result: Successfully established an alternative proof for determining the optimal dimension of singular sets in Dir-minimizing multivalued functions

Conclusion: The Carleman estimate technique provides a valid alternative approach to proving results about singular sets in multivalued function theory, confirming previous findings through different mathematical machinery

Abstract: We prove a Carleman-type estimate for Dirichlet-stationary multivalued
functions and apply it to give a different proof of the optimal dimension of
the singular set of Dir-minimizing multivalued functions, originally due to
Almgren and to De Lellis-Spadaro.

</details>


### [8] [The Liouville-type equation and an Onofri-type inequality on closed 4-manifolds](https://arxiv.org/abs/2508.14494)
*Xi-Nan Ma,Tian Wu,Xiao Zhou*

Main category: math.AP

TL;DR: Classification of solutions to a fourth-order Liouville-type equation on closed 4D Riemannian manifolds with Ricci curvature bounds, leading to an Onofri-type inequality on the 4-sphere.


<details>
  <summary>Details</summary>
Motivation: Study fourth-order elliptic equations on Riemannian manifolds with curvature constraints to understand solution structures and derive geometric inequalities.

Method: Using invariant tensors to derive differential identities, employing second-order derivative estimates via continuity method, and classifying solutions for parameter ranges.

Result: Complete classification of solutions within certain parameter ranges, derivation of Onofri-type inequality on 4-sphere, and proof of its rigidity.

Conclusion: The method provides a systematic approach to classify solutions of fourth-order equations and establishes geometric inequalities with rigidity results on curved spaces.

Abstract: In this paper, we study the Liouville-type equation
  \[\Delta ^2 u-\lambda_1\kappa\Delta u+\lambda_2\kappa^2(1-\mathrm e^{4u})=0\]
  on a closed Riemannian manifold \((M^4,g)\) with
\(\operatorname{Ric}\geqslant 3\kappa g\) and \(\kappa>0\). Using the method of
invariant tensors, we derive a differential identity to classify solutions
within certain ranges of the parameters \(\lambda_1,\lambda_2\). A key step in
our proof is a second-order derivative estimate, which is established via the
continuity method. As an application of the classification results, we derive
an Onofri-type inequality on the 4-sphere and prove its rigidity.

</details>


### [9] [Liouville theorem of the subcritical biharmonic equation on complete manifolds](https://arxiv.org/abs/2508.14497)
*Xi-Nan Ma,Tian Wu,Wangzhe Wu*

Main category: math.AP

TL;DR: Liouville theorem for subcritical biharmonic equations on non-compact Riemannian manifolds with nonnegative Ricci curvature


<details>
  <summary>Details</summary>
Motivation: Study the existence of positive solutions to subcritical biharmonic equations on complete non-compact Riemannian manifolds with nonnegative Ricci curvature

Method: Using invariant tensors method to derive differential identity, Bernstein's technique and continuity method for second-order derivative estimates

Result: No positive C^4 solutions exist when n≥5 and 1<α<(n+4)/(n-4)

Conclusion: Established Liouville-type theorem for subcritical biharmonic equations under specified geometric conditions and parameter range

Abstract: In this paper, we study the subcritical biharmonic equation \[\Delta ^2
u=u^\alpha\] on a complete, connected, and non-compact Riemannian manifold
$(M^n,g)$ with nonnegative Ricci curvature. Using the method of invariant
tensors, we derive a differential identity to obtain a Liouville theorem, i.e.,
there is no positive $C^4$ solution if $n\geqslant5$ and
$1<\alpha<\frac{n+4}{n-4}$. We establish a crucial second-order derivative
estimate, which is established via Bernstein's technique and the continuity
method.

</details>


### [10] [Global well-posedness of the NLS hierarchy with nonzero boundary condition](https://arxiv.org/abs/2508.14572)
*Xian Liao,Robert Wegner*

Main category: math.AP

TL;DR: Global well-posedness for NLS hierarchy with nonzero boundary conditions using perturbation approach and conserved energies.


<details>
  <summary>Details</summary>
Motivation: To establish well-posedness for the nonlinear Schrödinger (NLS) hierarchy with nonzero boundary conditions, which has applications in various physical systems including Bose-Einstein condensates and nonlinear optics.

Method: Perturbation approach from time-independent front, recurrence relations from Jost solutions, local well-posedness theory in weighted Sobolev spaces with smoothing estimates, and globalization using conserved energies.

Result: Proved global well-posedness for high regularity initial data, established explicit formulas for NLS hierarchy terms, and developed local well-posedness theory for dispersive nonlinear systems.

Conclusion: The NLS hierarchy with nonzero boundary conditions is globally well-posed for sufficiently regular initial data, leveraging conserved energies and perturbation techniques.

Abstract: We consider the NLS hierarchy with the nonzero boundary condition $q(t, x)
\rightarrow q_\pm \in \mathbb{S}^1$ as $x \rightarrow \pm \infty$ and prove
that it is global well-posedness for initial data of high regularity.
Specifically, we prove well-posedness of the problem for the perturbation $p =
q - q_\ast$ from a time-independent front $q_\ast$ connecting $q_-$ to $q_+$.
The equations in the NLS hierarchy are defined using a recurrence relation
derived from the expansion of the logarithmic derivative of the Jost solutions
associated to the Lax operator. Using this recurrence relation, we are able to
determine explicit formulas for all terms in the NLS hierarchy with at most one
factor that is $q_x$, $\bar{q}_x$, or a derivative thereof. We then view the
equation for $p$ as part of a large class of dispersive nonlinear systems, for
which we develop a local well-posedness theory in weighted Sobolev spaces. This
involves certain local smoothing and maximal function estimates, which we
establish for a large class of dispersion relations with finitely many critical
points. Finally, we globalize the solutions using the conserved energies
constructed in [1, 2].
  [1] H. Koch and X. Liao. "Conserved energies for the one dimensional
Gross-Pitaevskii equation". In: Adv. Math. 377, 107467 (2021).
  [2] H. Koch and X. Liao. "Conserved energies for the one dimensional
Gross-Pitaevskii equation: low regularity case". In: Adv. Math. 420, 108996
(2023).

</details>


### [11] [Biharmonic nonlinear vector field equations in $\mathbb{R}^4$](https://arxiv.org/abs/2508.14640)
*Ioannis Arkoudis,Panayotis Smyrnelis*

Main category: math.AP

TL;DR: Existence of ground state solutions for biharmonic nonlinear vector field equations in 4D, completing previous results for dimensions ≥5, and extending biharmonic logarithmic Sobolev inequality to 4D.


<details>
  <summary>Details</summary>
Motivation: To complete the analysis of biharmonic nonlinear vector field equations across all relevant dimensions, specifically addressing the limiting case of space dimension 4 which was not covered by previous work for dimensions ≥5.

Method: Following the approach of Brezis and Lieb, the authors prove the existence of ground state solutions for biharmonic nonlinear vector field equations in 4D.

Result: Successfully proved the existence of ground state solutions in dimension 4, completing the results obtained by Mederski and Siemianowski for higher dimensions. Also extended the biharmonic logarithmic Sobolev inequality to dimension 4.

Conclusion: The work provides a complete picture of ground state solutions for biharmonic nonlinear vector field equations across all relevant dimensions, with specific contributions for the limiting 4D case and extension of important Sobolev inequalities.

Abstract: Following the approach of Brezis and Lieb, we prove the existence of a ground
state solution for the biharmonic nonlinear vector field equations in the
limiting case of space dimension $4$. Our results complete those obtained by
Mederski and Siemianowski for dimensions $d\geq 5$. We also extend the
biharmonic logarithmic Sobolev inequality to dimension $4$.

</details>


### [12] [Borderline regularity in singular free boundary problems](https://arxiv.org/abs/2508.14736)
*Damião J. Araújo,Aelson Sobral,Eduardo V. Teixeira,José Miguel Urbano*

Main category: math.AP

TL;DR: Paper analyzes regularity of local minimizers under minimal assumptions on potential term σ. Shows sign-changing minimizers are Log-Lipschitz continuous when σ is bounded/measurable. For one-phase case, establishes gradient bounds along free boundaries. Proves C¹ regularity along free boundary when σ is continuous.


<details>
  <summary>Details</summary>
Motivation: To understand the borderline regularity of energy functional minimizers under minimal assumptions on the potential term σ, identifying sharp thresholds for differentiability based on σ's regularity.

Method: Mathematical analysis of local minimizers of energy functionals, investigating different cases: general bounded measurable σ, one-phase case, and continuous σ scenarios.

Result: Sign-changing minimizers achieve optimal Log-Lipschitz continuity with bounded measurable σ. One-phase minimizers show structural regularity gain with gradient bounds. Continuous σ yields C¹ regularity along free boundaries.

Conclusion: The study identifies sharp regularity thresholds: Log-Lipschitz continuity represents optimal regularity for general σ, while continuity of σ provides the precise condition for C¹ differentiability along free boundaries.

Abstract: In this paper, we investigate the borderline regularity of local minimizers
of energy functionals under minimal assumptions on the potential term $\sigma$.
When $\sigma$ is merely bounded and measurable, we show that sign-changing
minimizers are Log-Lipschitz continuous, which represents the optimal
regularity in this general setting. In the one-phase case, however, we
establish gradient bounds for minimizers along their free boundaries, revealing
a structural gain in regularity. Most notably, we prove that if $\sigma$ is
continuous, then minimizers are of class $C^1$ along the free boundary, thereby
identifying a sharp threshold for differentiability in terms of the regularity
of the potential.

</details>


### [13] [A State-Space Representation of Coupled Linear Multivariate PDEs and Stability Analysis using SDP](https://arxiv.org/abs/2508.14840)
*Declan S. Jagt,Matthew M. Peet*

Main category: math.AP

TL;DR: Extension of Partial Integral Equation (PIE) framework to multivariate PDEs with multiple spatial variables, enabling stability analysis and control through operator algebra and convex optimization.


<details>
  <summary>Details</summary>
Motivation: To enable more convenient stability analysis and control of coupled PDEs with multiple spatial variables by extending the univariate PIE representation to multivariate cases.

Method: Inductive extension of univariate PIE representation to multiple spatial variables by representing the domain as intersection of lifted univariate domains, using operator algebra of Partial Integral operators with polynomial semi-separable kernels.

Result: Developed necessary and sufficient consistency condition for existence of inverse to multivariate spatial differential operator, created PIE representation for well-posed linear multivariate PDEs, and implemented software (PIETOOLS) for automated representation and stability analysis.

Conclusion: The proposed framework successfully extends PIE methodology to multivariate PDEs, providing computational tools for stability analysis with accurate decay rate bounds, as demonstrated on 2D heat, wave, and plate equations.

Abstract: Physical processes evolving in both time and space are often modeled using
Partial Differential Equations (PDEs). Recently, it has been shown how
stability analysis and control of coupled PDEs in a single spatial variable can
be more conveniently performed using an equivalent Partial Integral Equation
(PIE) representation. The construction of this PIE representation is based on
an analytic expression for the inverse of the spatial differential operator,
$\partial_s^{d}$, on the domain defined by boundary conditions. In this paper,
we show how this univariate representation may be extended inductively to
multiple spatial variables by representing the domain as the intersection of
lifted univariate domains. Specifically, we show that if each univariate domain
is well-posed, then there exists a readily verified consistency condition which
is necessary and sufficient for existence of an inverse to the multivariate
spatial differential operator,
$D^\alpha=\partial_{s_1}^{\alpha_1}\cdots\partial_{s_N}^{\alpha_N}$, on the PDE
domain. Furthermore, we show that this inverse is an element of a $*$-algebra
of Partial Integral (PI) operators defined by polynomial semi-separable
kernels. Based on this operator algebra, we show that the evolution of any
suitably well-posed linear multivariate PDE may be described by a PIE,
parameterized by elements of the PI algebra. A convex computational test for
PDE stability is then proposed using a positive matrix parameterization of
positive PI operators, and software (PIETOOLS) is provided which automates the
process of representation and stability analysis of such PDEs. This software is
used to analyze stability of 2D heat, wave, and plate equations, obtaining
accurate bounds on the rate of decay.

</details>


### [14] [Steady states of FitzHugh-Nagumo-type systems with sign-changing coefficients](https://arxiv.org/abs/2508.14854)
*João Marcos do Ó,Evelina Shamarova,Victor V. Silva*

Main category: math.AP

TL;DR: Existence and multiplicity results for steady-state solutions of spatially heterogeneous FitzHugh-Nagumo systems with variable coefficients that may change sign.


<details>
  <summary>Details</summary>
Motivation: Extend existing theory from constant to variable coefficients in FitzHugh-Nagumo systems, allowing for sign changes and non-coercive behavior in the coefficients.

Method: Study a system of PDEs with variable coefficients using mountain pass techniques and variational methods to prove existence of solutions under subcritical growth conditions.

Result: Proved existence of mountain pass solutions when coefficients may change sign, and established existence of componentwise positive/negative solutions when coefficients do not change sign (though still non-coercive).

Conclusion: Successfully extended the theory to handle spatially heterogeneous coefficients with sign changes, providing existence and multiplicity results for FitzHugh-Nagumo-type systems with variable coefficients.

Abstract: We establish existence and multiplicity results for steady-state solutions of
spatially heterogeneous FitzHugh-Nagumo-type systems, extending the existing
theory from constant to variable coefficients that may change sign.
Specifically, we study the system Specifically, we study the system
\begin{align*} -\Delta u + a(x)v &= f(x,u) && \text{in } \mathbb{R}^N, \\
-\Delta v + b(x)v &= c(x)u && \text{in } \mathbb{R}^N. \end{align*} where $N
\geqslant 3$, the coefficients $a,b,c : \mathbb{R}^N \to \mathbb{R}$ are
$L^\infty_{\mathrm{loc}}$-functions bounded from below, and $f:\mathbb{R}^N
\times \mathbb{R} \to \mathbb{R}$ is a Carath\'eodory function with subcritical
growth. For assumptions permitting sign changes and non-coercivity of the
coefficients, we prove the existence of a mountain pass solution. In the case
where $a,b,c$ do not change sign, still allowing non-coercive behavior, we
additionally establish the existence of componentwise positive and negative
solutions.

</details>


### [15] [Pulled fronts are not (just) pulled](https://arxiv.org/abs/2508.14864)
*Montie Avery,Matt Holzer,Arnd Scheel*

Main category: math.AP

TL;DR: The paper demonstrates that linear spreading speed theory for pulled fronts is incomplete, showing examples where leading edge behavior predicts only two invasion scenarios but actual dynamics exhibit three or more distinct invasion fronts with different wake states.


<details>
  <summary>Details</summary>
Motivation: To challenge the conventional understanding that front propagation into unstable states is solely determined by linearization and leading edge Gaussian tail behavior, revealing limitations in the pulled front paradigm.

Method: The authors analyze a class of examples where invasion fronts exhibit more complex dynamics than predicted by linear theory, specifically showing cases with three or more distinct invasion fronts with different wake states.

Result: The study finds that leading edge behavior (Gaussian tail propagation) predicts at most two possible invasion scenarios, but actual systems can exhibit three or more invasion fronts with different states left behind in the wake.

Conclusion: Invasion processes can leave behind states that are not solely determined by leading edge behavior, indicating that front dynamics in the wake are not completely described by linearization effects and that fronts are not simply "pulled" by the Gaussian tail.

Abstract: Front propagation into unstable states is often determined by the
linearization, that is, propagation speeds agree with predictions from the
linearized equation at the unstable state. The leading edge behavior is then a
Gaussian tail propagating with the linear spreading speed. Fronts following
this leading edge are commonly referred to as pulled fronts, alluding to the
idea that they are ``pulled'' by this leading-edge Gaussian tail. We describe
here a class of examples that exhibits how these leading-order effects do not
completely describe the dynamics in the wake of the front. In fact, leading
edge behavior predicts at most two possible invasion scenarios, associated with
positive and negative amplitudes of the Gaussian tail, but our examples exhibit
three or more invasion fronts with different states in the wake. The resulting
invasion process therefore leaves behind a state that is not solely determined
by the leading edge, and thus not just pulled by the Gaussian tail.

</details>


### [16] [Critical trajectories in kinetic geometry](https://arxiv.org/abs/2508.14868)
*Helge Dietert,Clément Mouhot,Lukas Niebel,Rico Zacher*

Main category: math.AP

TL;DR: Construction of critical trajectories in kinetic geometry using Newton's laws with power scaling and logarithmic oscillations, enabling kinetic mollification, Sobolev inequalities, and Harnack inequalities for Kolmogorov equations with rough coefficients.


<details>
  <summary>Details</summary>
Motivation: To develop robust geometric tools for analyzing kinetic equations by constructing critical trajectories that respect kinetic scaling and connect arbitrary points in phase space, enabling functional analytic estimates without relying on fundamental solutions.

Method: Based on Newton's laws of motion with forcing functions combining power scaling and desynchronized logarithmic oscillations to create critical trajectories that serve as an 'almost exponential map'. Applied to kinetic mollification, Sobolev inequalities, and Moser-type estimates for Kolmogorov equations.

Result: Successfully constructed critical trajectories providing versatile geometric framework. Proved kinetic Sobolev inequality with optimal exponent. Established universal estimate for logarithm of positive supersolutions. Derived optimal weak Harnack inequality for Kolmogorov equations with rough coefficients.

Conclusion: The critical trajectory approach provides a powerful geometric method for kinetic equations, yielding optimal functional estimates and Harnack inequalities without fundamental solutions, with applications to Kolmogorov equations with rough coefficients.

Abstract: We construct critical trajectories in kinetic geometry, i.e. curves in
$\mathbb{R}^{1+2n}$ that are: tangential to the vector fields
$\partial_t+v\cdot \nabla_x$ and $\nabla_v$, connecting any two given points,
respecting the underlying kinetic scaling, and with the property, that the
singularity of the $v$-tangent vector near the starting point equates the
degeneracy of the dependency of the curve velocity in terms of the endpoint
velocity.
  The construction is based on Newton's laws of motion, where the ansatz for
the forcing of the kinetic trajectory is the superposition of functions
combining the correct power scaling with desynchronised logarithmic
oscillations.
  These critical trajectories provide a robust and versatile ''almost
exponential map'' that allows to prove several functional analytic estimates.
We introduce a notion of kinetic mollification and, as an application, deduce
the kinetic Sobolev inequality with optimal exponent without relying on the
fundamental solution.
  Moreover, we establish a universal estimate for the logarithm of positive
supersolutions to the Kolmogorov equation with rough coefficients inspired by
the work of Moser (1961, 1964) on elliptic and parabolic problems. Combining
this estimate with De Giorgi-Moser iterations and a lemma due to Bombieri and
Giusti, we give an alternative proof of the (weak) Harnack inequality for the
Kolmogorov equation with rough coefficients, following the ideas of Moser
(1971). Our result gives the optimal range of exponents in the weak Harnack
inequality and the optimal (geometric) dependency of the Harnack constant on
the bounds of the diffusion matrix.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [17] [Suppression of two stream instability in relativistic electron-ion plasmas](https://arxiv.org/abs/2508.14362)
*Vivek Shrivastav,Mani K Chettri,Hemam D Singh,Rupak Mukherjee*

Main category: physics.plasm-ph

TL;DR: Relativistic velocities suppress two-stream instabilities in electron-ion plasmas, with growth rate reduction at higher plasma frequencies and realistic mass ratios, providing insights for high-energy plasma applications.


<details>
  <summary>Details</summary>
Motivation: To understand how relativistic effects suppress two-stream instabilities in electron-ion plasmas, particularly relevant for high-energy plasmas, laser-plasma interactions, and relativistic particle beam physics.

Method: Analysis of two-stream instabilities in relativistic electron-ion plasmas, examining parameter space of growth rates at different plasma frequencies and realistic ion-electron mass ratios through unified four-regime analysis.

Result: Suppression of growth rate occurs consistently even with neutralizing ion background. Growth rate parameter space squeezes for relativistic electrons at higher plasma frequencies. Further suppression observed as ion-electron mass ratio approaches realistic limits.

Conclusion: Relativistic effects fundamentally modify two-stream instability behavior, providing essential scaling laws and extending understanding of suppression mechanisms in high-energy plasma applications through unified regime analysis.

Abstract: This paper investigates the suppression of two stream instabilities in
electron ion plasmas when the individual species attain relativistic
velocities. This suppression of the growth rate of two stream instability is
consistent even when the ions form a neutralizing background. It is found that
the parameter space of the growth rate reasonably squeezes for relativistic
electrons at higher plasma frequencies. We further report the suppression of
the growth rate of the said instability as the ion electron mass ratio reaches
the realistic limit. Our results have implications for high-energy plasmas,
laser-plasma interactions, and relativistic particle beam physics, providing
insights into the complex interplay of linear and nonlinear processes governing
the two-stream instability. Our unified four-regime analysis extends previous
understanding of how realistic mass ratios fundamentally modify relativistic
suppression effects, providing essential scaling laws for high-energy plasma
applications.

</details>


### [18] [Excitation of toroidal Alfvén eigenmode by energetic particles in DTT and effect of negative triangularity](https://arxiv.org/abs/2508.14622)
*Guangyu Wei,Fulvio Zonca,Matteo Valerio Falessi,Zhiyong Qiu*

Main category: physics.plasm-ph

TL;DR: A gyrokinetic eigenvalue code is developed to study toroidal Alfvén eigenmode stability with self-consistent treatment of energetic particle drive and Landau damping, including finite Larmor radius effects. The code is applied to analyze triangularity effects on TAE stability in tokamaks.


<details>
  <summary>Details</summary>
Motivation: To develop a comprehensive tool for studying TAE stability in axisymmetric toroidal geometry with accurate treatment of energetic particle dynamics and wave-particle interactions, particularly to understand how geometric factors like triangularity affect plasma stability.

Method: Developed a linear gyrokinetic eigenvalue code using action-angle approach for particle responses, ballooning-mode representation for computational efficiency, and systematic numerical diagnostics for detailed wave-particle interaction analysis. Applied to DTT reference equilibrium.

Result: The code successfully demonstrates that triangularity affects TAE growth rates through geometric couplings, resonance conditions, mode frequency and structure modifications. Negative triangularity can either stabilize or destabilize TAE depending on dominant mechanisms.

Conclusion: Negative triangularity's effect on TAE stability is complex and mechanism-dependent. The developed code provides systematic analysis capabilities to assess overall triangularity effects for specific tokamak scenarios, offering clear physical insights into wave-particle interactions.

Abstract: A linear gyrokinetic eigenvalue code is developed to study the stability of
toroidal Alfv\'en eigenmode (TAE) in general axisymmetric toroidal geometry,
with the self-consistent treatment of energetic particle drive and core plasma
Landau damping in a non-perturbative way. The general particle responses of
both circulating and trapped particles are incorporated in the calculation by
means of the action-angle approach, and, particularly, the finite Larmor radius
and orbit width effects of energetic particles are fully taken into account.
The ballooning-mode representation is adopted to solve the eigenmode equations
in order to reduce the computational resource while obtaining a high resolution
of the fine radial structure. Furthermore, the code is able to study the
physics of wave-particle interaction in great detail, thanks to the development
of systematic theory-based numerical diagnostics, including effective mode
structure and phase space resonance structure. As an application of the code,
we perform an in-depth study of the triangularity effect on TAE stability based
on the reference equilibrium of the Divertor Tokamak Test facility. It is
demonstrated that TAE growth rate can be affected by the triangularity through
the modifications of geometric couplings, resonance condition, as well as mode
frequency and mode structure. As a result, negative triangularity can either
stabilize or destabilize the energetic particle driven TAE depending on the
dominant mechanism. The relative importance of these mechanisms under different
circumstances is systematically analyzed, providing clear physical insights.
The overall effect of negative triangularity for a specific tokamak scenario
can be assessed based on these studies.

</details>


### [19] [Phase space transport, quasilinear diffusion and locality in phase velocity](https://arxiv.org/abs/2508.14657)
*Didier Bénisti*

Main category: physics.plasm-ph

TL;DR: Analysis of charged particle transport in electrostatic waves, distinguishing between perturbative quasilinear diffusion (requires local wave-particle interaction) and chaotic diffusion (can occur non-locally), with analytical model for velocity distribution evolution.


<details>
  <summary>Details</summary>
Motivation: To understand the conditions under which particle transport in electrostatic waves can be modeled as diffusion, and to evaluate the validity of quasilinear diffusion coefficients in different regimes.

Method: Numerical and theoretical analysis of charged particle motion in discrete spectrum electrostatic waves, examining wave-particle interaction locality and phase space boundaries.

Result: Quasilinear diffusion only occurs with local wave-particle interaction, while chaotic diffusion can occur non-locally. Developed analytical expression for velocity distribution evolution accounting for phase space boundaries.

Conclusion: Transport modeling must distinguish between perturbative and chaotic regimes, with locality being crucial for quasilinear diffusion but not for chaotic diffusion. The analytical model provides improved description of velocity distribution evolution.

Abstract: In this paper, we address the motion of charged particles subjected to a
discrete spectrum of electrostatic waves. We focus on situations when transport
dominates, leading to significant variations in particle velocity. Nonetheless,
these velocity changes remain finite due to the presence of KAM tori bounding
phase space. We analyze the conditions under which transport can be modeled as
a diffusion process and evaluate the relevance of the so-called quasilinear
value of the diffusion coefficient. We distinguish between traditional
quasilinear diffusion, when wave-particle interaction is perturbative, and the
so-called chaotic regime of diffusion, when the particle motion looks erratic.
In the perturbative regime, we demonstrate both numerically and theoretically
that diffusion occurs only when wave-particle interaction is local in phase
velocity; that is, when wave contributions from phase velocities far from the
particles instantaneous velocities are negligible. Conversely, numerical
results indicate that chaotic diffusion can occur even when wave-particle
interaction is not local. Furthermore, in regimes when quasilinear diffusion is
applicable, we introduce a simple analytical expression for the time evolution
of the velocity distribution function, that accounts for phase space
boundaries.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [20] [Using Frame Randomization to Mitigate Errors in Quantum Optimization](https://arxiv.org/abs/2508.14142)
*Rachel E. Johnson,Joshua A. Job,Steve Adachi*

Main category: quant-ph

TL;DR: Frame randomization techniques applied to QAOA p=1 show error mitigation benefits for quantum energy calculations on superconducting hardware, with Pauli frame randomization performing best.


<details>
  <summary>Details</summary>
Motivation: Error mitigation is crucial for near-term quantum devices, and frame randomization offers a promising approach to reduce errors while preserving circuit unitarity and depth.

Method: Applied frame randomization to QAOA p=1 on superconducting quantum circuits, testing two techniques: Randomized Compilation and Pauli frame randomization on a frustrated Ising ring system.

Result: Both methods mitigated errors - Randomized Compilation achieved 5.25±0.145, Pauli frame randomization achieved 4.08±0.36, compared to 2.63±0.068 without randomization and 5.676±0.006 with noiseless simulator.

Conclusion: Frame randomization techniques, particularly Pauli frame randomization, effectively mitigate errors in QAOA energy calculations, bringing results closer to noiseless simulation values.

Abstract: Error mitigation is essential for near-term quantum devices, and one
promising technique is frame randomization. This method inserts random twirling
gates into a circuit to reduce errors while preserving unitarity and depth. We
apply frame randomization to the quantum approximate optimization algorithm
(QAOA) with $p=1$ on a superconducting quantum circuit system, demonstrating
its potential to improve energy calculations. Specifically, we investigate the
use of QAOA to calculate the lowest energy state of a frustrated Ising ring
system and compare the results of randomized circuits generated using two
different randomized techniques. Our results show that both methods can
mitigate errors, with expected extremal energy values of $5.25\pm0.145$ and
$4.08\pm0.36$, for Randomized Compilation and Pauli frame randomization
respectively, compared to $2.63\pm0.068$ without randomization and
$5.676\pm0.006$ with a noiseless simulator.

</details>


### [21] [Stoquasticity is not enough: towards a sharper diagnostic for Quantum Monte Carlo simulability](https://arxiv.org/abs/2508.14382)
*Arman Babakhani,Armen Karakashian*

Main category: quant-ph

TL;DR: The paper introduces Vanishing Geometric Phases (VGP) as a geometric criterion for diagnosing quantum Monte Carlo simulability, providing both classification tools and quantitative diagnostics for sign problem severity.


<details>
  <summary>Details</summary>
Motivation: Quantum Monte Carlo methods are limited by the sign problem, and existing stoquasticity-based heuristics have limitations in identifying sign-problem-free Hamiltonians efficiently.

Method: The authors characterize VGP Hamiltonians, analyze recognition complexity, propose VGP-inspired quantitative diagnostics, and demonstrate scaling analysis for average sign under unitary transformations.

Result: VGP criterion efficiently identifies specific sign-problem-free Hamiltonians that are difficult to classify via stoquasticity, and provides mathematical tools for analyzing sign problem severity.

Conclusion: VGP offers both conceptual foundation and practical tools for understanding and mitigating the sign problem in quantum Monte Carlo simulations, outperforming traditional stoquasticity-based approaches.

Abstract: Quantum Monte Carlo (QMC) methods are powerful tools for simulating quantum
many-body systems, yet their applicability is limited by the infamous sign
problem. We approach this challenge through the lens of Vanishing Geometric
Phases (VGP) \cite{Hen_2021}, introducing it as a `geometric' criterion for
diagnosing QMC simulability. We characterize the class of VGP Hamiltonians, and
analyze the complexity of recognizing this class, identifying both hard and
efficiently identifiable cases. We further highlight the practical advantage of
the VGP criterion by exhibiting specific Hamiltonians that are readily
identified as sign-problem-free through VGP, yet whose stoquasticity is
difficult to ascertain. These examples underscore the efficiency and sharpness
of VGP as a diagnostic tool compared to stoquasticity-based heuristics. Beyond
classification, we propose a family of VGP-inspired diagnostics that serve as
quantitative indicators of sign problem severity. While exact evaluation of
these quantities is generically intractable, we demonstrate their mathematical
power in performing scaling analysis for the average sign under unitary
transformations. Our results provide both a conceptual foundation and practical
tools for understanding and mitigating the sign problem.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [22] [Optimal Subspace Embeddings: Resolving Nelson-Nguyen Conjecture Up to Sub-Polylogarithmic Factors](https://arxiv.org/abs/2508.14234)
*Shabarish Chenakkod,Michał Dereziński,Xiaoyu Dong*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We give a proof of the conjecture of Nelson and Nguyen [FOCS 2013] on the
optimal dimension and sparsity of oblivious subspace embeddings, up to
sub-polylogarithmic factors: For any $n\geq d$ and $\epsilon\geq d^{-O(1)}$,
there is a random $\tilde O(d/\epsilon^2)\times n$ matrix $\Pi$ with $\tilde
O(\log(d)/\epsilon)$ non-zeros per column such that for any
$A\in\mathbb{R}^{n\times d}$, with high probability,
$(1-\epsilon)\|Ax\|\leq\|\Pi Ax\|\leq(1+\epsilon)\|Ax\|$ for all
$x\in\mathbb{R}^d$, where $\tilde O(\cdot)$ hides only sub-polylogarithmic
factors in $d$. Our result in particular implies a new fastest sub-current
matrix multiplication time reduction of size $\tilde O(d/\epsilon^2)$ for a
broad class of $n\times d$ linear regression tasks.
  A key novelty in our analysis is a matrix concentration technique we call
iterative decoupling, which we use to fine-tune the higher-order trace moment
bounds attainable via existing random matrix universality tools [Brailovskaya
and van Handel, GAFA 2024].

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [23] [A framework for finite-strain viscoelasticity based on rheological representations](https://arxiv.org/abs/2508.14518)
*Chongran Zhao,Hongyan Yuan,Ju Liu*

Main category: cond-mat.soft

TL;DR: A new constitutive framework using strain-like internal variables and two rheological models (Maxwell and Kelvin-Voigt) with efficient computational integration via Sherman-Morrison-Woodbury formula extension.


<details>
  <summary>Details</summary>
Motivation: To develop a flexible modeling framework for materials with multiple non-equilibrium processes and complex rheological architectures under finite strain, addressing computational challenges in constitutive integration.

Method: Uses strain-like internal variables in Sym(3) space, derives constitutive theory from thermomechanical principles with free energies and dissipation potentials, applies maximum dissipation principle for evolution equations, and extends Sherman-Morrison-Woodbury formula for efficient tensorial integration.

Result: Developed an efficient integration strategy with explicit update formulas where algorithmic complexity scales linearly with number of non-equilibrium processes, enabling computational feasibility for complex rheological architectures.

Conclusion: The framework successfully combines modeling flexibility with computational efficiency for simulating materials with multiple non-equilibrium processes under finite strain conditions.

Abstract: This work presents a new constitutive and computational framework based on
strain-like internal variables belonging to Sym(3) and two representative
rheological configurations. The generalized Maxwell and generalized
Kelvin-Voigt models are considered as prototypes for parallelly and serially
connected rheological devices, respectively. For each configuration, distinct
kinematic assumptions are introduced. The constitutive theory is derived based
on thermomechanical principles, where the free energies capture recoverable
elastic responses and dissipation potentials govern irreversible mechanisms.
The evolution equations for the internal variables arise from the principle of
maximum dissipation. A key insight is the structural distinction in the
constitutive laws resulted from the two rheological architectures. In
particular, the Kelvin-Voigt model leads to evolution equations with
non-equilibrium processes coupled, which pose computational challenges for the
constitutive integration. To address this, we exploit the
Sherman-Morrison-Woodbury formula and extend it to tensorial equations to
design an efficient strategy during constitutive integration. With that
strategy, the integration can be performed based on an explicit update formula,
and the algorithmic complexity scales linearly with the number of
non-equilibrium processes. This framework offers both modeling flexibility and
computational feasibility for simulating materials with multiple
non-equilibrium processes and complex rheological architectures under finite
strain.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [24] [Time-Incremented Multiscale Evolution (TIME): A Code-Independent Method for Time-Domain 3D Hydrodynamics and its Application to Roche Lobe Overflow](https://arxiv.org/abs/2508.14144)
*David Dickson*

Main category: astro-ph.HE

TL;DR: First grid-based 3D model of Roche lobe overflow using novel time-domain simulation method with variable resolution, identifying critical stability point at f~1.01.


<details>
  <summary>Details</summary>
Motivation: Many critical physical processes like Roche lobe overflow strain modern simulation methods due to their long durations and multidimensional nature, requiring new approaches.

Method: Piecewise approach alternating between high-resolution 3D dynamic modeling and fast evolutionary modeling using VH-1, enabling self-scaling variable time resolution at reduced computational cost.

Result: Mass transfer in M33 X-7 binary is unstable and fully conservative beyond f>~1.01, accelerating to <100 yrs beyond f>=1.1, while stable phase f<~1.01 occurs on nuclear timescales.

Conclusion: Identified critical point f~1.01 that terminates stable overflow, potentially corresponding to Mdot_L1 ~ Mdot_wind or Mdot_L1 ~ 10^-6 M_solar/yr in general cases.

Abstract: Context. Many critical physical processes, such as Roche lobe overflow,
strain modern simulation methods due to their durations and
multidimensionality. Aims. We employ a novel method of time-domain
multidimensional simulations to provide the first grid-based time domain 3D
model of Roche lobe overflow using VH-1. Methods. Using a piecewise approach
which alternates between high-resolution 3D dynamic modeling and
computationally fast evolutionary modeling, we present and test a method
capable of self-scaling variable time resolution at greatly reduced
computational cost. Results. We find mass transfer in the test high mass x-ray
binary M33 X-7 to be unstable and fully conservative in both mass and angular
momentum transport onto the accretion disk beyond f >~ 1.01. This phase begins
on thermal timescales and accelerates to span < 100 yrs beyond f >= 1.1, while
the non-conservative stable phase of f <~ 1.01 occurs on roughly nuclear
timescales. Conclusions. We identify a critical point f ~ 1.01 which terminates
stable overflow, which may correspond to the point Mdot_L1 ~ Mdot_wind or
Mdot_L1 ~ 10^-6 M_solar/yr in the general case.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [25] [Deep BSDE Solver on Bounded Domains Part I: General Loss Rate](https://arxiv.org/abs/2508.14215)
*Maximilian Würschmidt*

Main category: math.PR

TL;DR: The paper proposes a modified deep BSDE loss functional for bounded domains with random time horizons and derives convergence rates for weighted modifications.


<details>
  <summary>Details</summary>
Motivation: To extend deep BSDE methods to handle bounded domains with random (potentially unbounded) time horizons, which requires specialized loss functionals.

Method: Develops a ramification of the deep BSDE loss functional with weighted modifications designed for bounded domains and random time horizons, then analyzes convergence properties.

Result: Derives a general convergence rate expressed in terms of discrete-time stepsize and universal approximation distance for a class of weighted modifications of the functional.

Conclusion: The proposed modified loss functional enables effective application of deep BSDE methods to problems with bounded domains and random time horizons, with proven convergence guarantees.

Abstract: We consider a ramification of the deep BSDE loss functional designed to apply
for BSDEs on bounded domains, i.e. with random (unbounded) time horizons. We
derive a general convergence rate of the loss functional; precisely for a class
of (randomly) weighted modifications of the functional. The rate is expressed
in terms of the underlying discrete-time stepsize and a universal approximation
distance.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [26] [A generalized Hurwitz stability criterion via rectangular block Hankel matrices for nonmonic matrix polynomials](https://arxiv.org/abs/2508.14376)
*Xuzhou Zhan,Zixiang Ni*

Main category: math.OC

TL;DR: Develops Hurwitz stability criterion for nonmonic matrix polynomials using column reduction and Markov parameters, generalizing classical monic approaches.


<details>
  <summary>Details</summary>
Motivation: Existing Hurwitz stability criteria are constrained by the monic assumption, limiting their applicability to nonmonic matrix polynomials. The paper aims to generalize classical stability criteria like Gantmacher's approach.

Method: Uses column reduction and redefines Markov parameters through column-wise adaptive splitting. Constructs structured matrices with rectangular Hankel blocks from extracted parameters. Establishes inertia relationships between column reduced polynomials and derived matrices.

Result: Shows that Hurwitz stability of column reduced matrix polynomials can be determined by Hermitian positive definiteness of the constructed rectangular block Hankel matrices.

Conclusion: Provides a generalized framework for Hurwitz stability analysis of nonmonic matrix polynomials, extending classical monic-based criteria through column reduction and Markov parameter redefinition.

Abstract: We develop a Hurwitz stability criterion for nonmonic matrix polynomials via
column reduction, generalizing existing approaches constrained by the monic
assumption, as well as Gantmacher's classical stability criterion via Markov
parameters. Starting from redefining the associated Markov parameters through a
column-wise adaptive splitting method, our framework constructs two structured
matrices whose rectangular Hankel blocks are obtained via the extraction of
these parameters. We establish an explicit interrelation between the inertias
of column reduced matrix polynomials and the derived structured matrices.
Furthermore, we demonstrate that the Hurwitz stability of column reduced matrix
polynomials can be determined by the Hermitian positive definiteness of these
rectangular block Hankel matrices.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [27] [Electron charge dynamics and charge separation: A response theory approach](https://arxiv.org/abs/2508.14551)
*Lionel Lacombe,Lucia Reining,Vitaly Gorelov*

Main category: cond-mat.mtrl-sci

TL;DR: Application of response theory to electron charge dynamics, showing quadratic response is essential for accurate charge separation description while linear response works for optical properties.


<details>
  <summary>Details</summary>
Motivation: To investigate electron charge dynamics and separation using response theory, assessing the capabilities of linear vs. quadratic approaches for describing charge transfer systems.

Method: Applied linear and quadratic response theories to analyze charge density and current, using a model simulating charge transfer systems. Proposed and tested approximations to quadratic response, examined higher-order terms and on-site interaction effects.

Result: Linear response accurately captures optical properties but quadratic response contains minimal ingredients required for charge dynamics and separation. Quadratic response closely matches exact time propagation results in certain regimes.

Conclusion: Quadratic response theory is crucial for describing charge separation dynamics, outperforming linear response which is only sufficient for optical properties. The study identifies regimes where quadratic response provides accurate results comparable to exact time propagation.

Abstract: This study applies response theory to investigate electron charge dynamics,
with a particular focus on charge separation. We analytically assess the
strengths and limitations of linear and quadratic response theories in
describing charge density and current, illustrated by a model that simulates
charge transfer systems. While linear response accurately captures optical
properties, the quadratic response contains the minimal ingredients required to
describe charge dynamics and separation. Notably, it closely matches exact time
propagation results in some regime that we identify. We propose and test
several approximations to the quadratic response and explore the influence of
higher-order terms and the effect of an on-site interaction $U$.

</details>


### [28] [A practical route to donor binding energies: The DFT-1/2 method for shallow defects](https://arxiv.org/abs/2508.14738)
*Joshua Claes,Bart Partoens,Dirk Lamoen,Marcelo Marques,Lara K. Teles*

Main category: cond-mat.mtrl-sci

TL;DR: DFT-1/2 method enables efficient calculation of shallow defect binding energies in large supercells (up to 4096 atoms) for group V donors in silicon, overcoming DFT limitations while maintaining computational feasibility.


<details>
  <summary>Details</summary>
Motivation: Standard DFT fails for shallow defects due to band gap underestimation and delocalization errors, while hybrid functionals are computationally impractical for large supercells needed to capture extended wavefunctions.

Method: Employed DFT-1/2 method with practical procedure for shallow defects, using extrapolation scheme to infinite supercell size for group V donors (P, As, Sb, Bi) in silicon.

Result: Achieved accurate binding energies with minimal computational overhead, demonstrating effectiveness through large supercell calculations up to 4096 atoms.

Conclusion: DFT-1/2 provides a simple and direct method for calculating donor binding energies, addressing DFT deficiencies while maintaining computational efficiency for shallow defect studies.

Abstract: Accurately calculating the binding energies of shallow defects requires large
supercells to capture the extended nature of their wavefunctions. This makes
many beyond-DFT methods, such as hybrid functionals, impractical for direct
calculations, often requiring indirect or approximate approaches. However,
standard DFT alone fails to provide reliable results due to the well-known band
gap underestimation and delocalization errors. In this work, we employ the
DFT-1/2 method to address these deficiencies while maintaining computational
efficiency allowing us to reach supercells of up to 4096 atoms. We develop a
practical procedure for applying DFT-1/2 to shallow defects and demonstrate its
effectiveness for group V donors in silicon (P, As, Sb, Bi). By using an
extrapolation scheme to infinite supercell size, we obtain accurate binding
energies with minimal computational overhead. This approach offers a simple and
direct method for calculating donor binding energies.

</details>
