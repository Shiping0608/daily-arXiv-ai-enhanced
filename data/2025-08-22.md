<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 11]
- [math.AP](#math.AP) [Total: 15]
- [physics.comp-ph](#physics.comp-ph) [Total: 5]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 2]
- [math.FA](#math.FA) [Total: 1]
- [math.PR](#math.PR) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [gr-qc](#gr-qc) [Total: 2]
- [math.DS](#math.DS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Semi-discrete Active Flux as a Petrov-Galerkin method](https://arxiv.org/abs/2508.15017)
*Wasilij Barsukow*

Main category: math.NA

TL;DR: Active Flux method bridges Finite Volume/DG and continuous Finite Element methods through variational formulation with biorthogonal test functions.


<details>
  <summary>Details</summary>
Motivation: To establish a rigorous mathematical foundation for the Active Flux method by deriving it from a variational formulation, clarifying its intermediate position between discontinuous and continuous numerical approaches.

Method: Develops a variational formulation using biorthogonal test functions on Cartesian meshes to obtain the semi-discrete Active Flux method, emphasizing its discontinuous nature despite continuous approximations.

Result: Successfully demonstrates that the Active Flux method can be derived from a variational approach, confirming its hybrid nature between Discontinuous Galerkin and continuous Finite Element methods.

Conclusion: The variational formulation provides a solid theoretical basis for Active Flux, positioning it as an intermediate method that combines advantages of both discontinuous and continuous numerical approaches for hyperbolic conservation laws.

Abstract: Active Flux (AF) is a recent numerical method for hyperbolic conservation
laws, whose degrees of freedom are averages/moments and (shared) point values
at cell interfaces. It has been noted previously in a heuristic fashion that it
thus combines ideas from Finite Volume/Discontinuous Galerkin (DG) methods with
a continuous approximation common in continuous Finite Element (CG) methods.
This work shows that the semi-discrete Active Flux method on Cartesian meshes
can be obtained from a variational formulation through a particular choice of
(biorthogonal) test functions. These latter being discontinuous, the new
formulation emphasizes the intermediate nature of AF between DG and CG.

</details>


### [2] [Error Estimation for Adaptive Mesh Refinement in Droplet Simulations](https://arxiv.org/abs/2508.15081)
*Darsh Nathawani,Matthew Knepley*

Main category: math.NA

TL;DR: A 1D shear force driven droplet formation model with flux-based error estimation using asymptotic expansion and front-tracking, discretized with Galerkin FEM in mixed form to handle gradient discontinuities during pinch-off.


<details>
  <summary>Details</summary>
Motivation: To accurately simulate droplet interface formation under shear forces, particularly addressing the challenge of discontinuous solution gradients and erroneous curvature calculations during the highly convective pinch-off process.

Method: Derived using asymptotic expansion and front-tracking method, discretized with Galerkin finite element method in mixed form, with adaptive mesh refinement driven by flux-based error estimation from smooth interface gradients.

Result: The mixed form provides smooth interface gradients for accurate error estimation, enabling adaptive mesh refinement to capture the droplet interface accurately during pinch-off.

Conclusion: The proposed model successfully addresses gradient discontinuity issues in droplet formation simulations through mixed-form FEM and adaptive mesh refinement based on flux error estimates.

Abstract: We present a one-dimensional shear force driven droplet formation model with
a flux-based error estimation. The presented model is derived using asymptotic
expansion and a front-tracking method to simulate the droplet interface. The
model is then discretized using the Galerkin finite element method in the mixed
form. However, the jumps in the solution gradients are discontinuous and can
grow faster due to the highly convective pinch-off process. This leads to an
erroneous droplet interface and incorrect curvature. Therefore, the mesh must
be sufficiently refined to capture the interface accurately. The mixed form of
the governing equation naturally provides smooth interface gradients that can
be used to compute the error estimate. The computed error estimate is then used
to drive the adaptive mesh refinement algorithm.

</details>


### [3] [A Note on the Convergence of Symmetric Triangle Quadrature Rules](https://arxiv.org/abs/2508.15133)
*Brian A. Freno,Neil R. Matula,Joseph E. Bishop*

Main category: math.NA

TL;DR: Symmetric triangle quadrature rules with even maximum polynomial degree d achieve convergence rate p=d+2 instead of conventional p=d+1, allowing fewer quadrature points for same accuracy in finite-element problems.


<details>
  <summary>Details</summary>
Motivation: To optimize computational cost in finite-element problems by balancing integration accuracy and computational efficiency, especially for smooth integrands that are not finite-degree polynomials.

Method: Analysis of symmetric polynomial quadrature rules for triangles, examining error implications and convergence rates for both 1D and triangular domains, supported by numerical examples on regular meshes.

Result: Quadrature rules with even maximum degree d achieve p=d+2 convergence rate rather than conventional p=d+1, enabling significant computational savings particularly for global integral operators that yield dense matrices.

Conclusion: Symmetric triangle quadrature rules with even maximum polynomial degrees provide superior convergence properties, allowing reduced computational cost while maintaining accuracy in finite-element applications.

Abstract: Symmetric polynomial quadrature rules for triangles are commonly used to
efficiently integrate two-dimensional domains in finite-element-type problems.
While the development of such rules focuses on the maximum degree a given
number of points can exactly integrate, smooth integrands are generally not
polynomials of finite degree. Therefore, for such integrands, one needs to
balance integration accuracy and computational cost. A natural approach to this
balance is to choose the number of points such that the convergence rate with
respect to the mesh size $h$ matches that of the other properties of the
scheme, such as the planar or curved triangles that approximate the geometry or
the basis functions that approximate the solution.
  In general, it is expected that a quadrature rule capable of integrating
polynomials up to degree $d$ yields an integration error that is
$\mathcal{O}(h^p)$, where $p=d+1$. However, as we describe in this paper, for
symmetric triangle quadrature rules, when $d$ is even, $p=d+2$; therefore, for
a $p^\text{th}$-order-accurate quadrature rule, fewer quadrature points are
necessary, reducing the time required for matrix assembly in
finite-element-type problems. This reduction in cost is modest for local
differential operators that yield sparse matrices but appreciable for global
integral operators that yield dense matrices.
  In this paper, we briefly summarize the details of symmetric triangle
quadrature rules, discuss error implications for quadrature rules for one
dimension and triangles, and we provide numerical examples that support our
observation that polynomials that exactly integrate even maximum degrees
converge faster than the conventional expectation for sequences of regular
meshes.

</details>


### [4] [Reduced basis solvers for unfitted methods on parameterized domains](https://arxiv.org/abs/2508.15320)
*Nicholas Mueller,Santiago Badia,Yiran Zhao*

Main category: math.NA

TL;DR: A unified framework combining unfitted finite element methods with reduced basis techniques for parametrized PDEs on parameter-dependent domains, using deformation mapping and localization for efficient model reduction.


<details>
  <summary>Details</summary>
Motivation: To enable efficient and accurate model reduction for parametrized PDEs on general geometries with parameter-dependent domains, addressing the challenge of geometric variability with fixed-dimensional snapshot representations.

Method: Combines unfitted finite element methods with classical and tensor-based reduced basis techniques (particularly tensor-train method). Uses deformation-based strategy to map reference configuration to parameterized domains, and introduces localization procedure for reduced subspaces and hyper-reduction via matrix discrete empirical interpolation. Extends to saddle-point problems with supremizer enrichment adapted to unfitted methods.

Result: Numerical experiments on 2D and 3D problems (Poisson, linear elasticity, incompressible Stokes, Navier-Stokes equations) demonstrate the framework's flexibility, accuracy and efficiency.

Conclusion: The proposed unified framework successfully enables efficient model reduction for parametrized PDEs on parameter-dependent domains, with demonstrated effectiveness across various problem types and dimensions.

Abstract: In this paper, we present a unified framework for reduced basis
approximations of parametrized partial differential equations defined on
parameter-dependent domains. Our approach combines unfitted finite element
methods with both classical and tensor-based reduced basis techniques --
particularly the tensor-train reduced basis method -- to enable efficient and
accurate model reduction on general geometries. To address the challenge of
reconciling geometric variability with fixed-dimensional snapshot
representations, we adopt a deformation-based strategy that maps a reference
configuration to each parameterized domain. Furthermore, we introduce a
localization procedure to construct dictionaries of reduced subspaces and
hyper-reduction approximations, which are obtained via matrix discrete
empirical interpolation in our work. We extend the proposed framework to
saddle-point problems by adapting the supremizer enrichment strategy to
unfitted methods and deformed configurations, demonstrating that the supremizer
operator can be defined on the reference configuration without loss of
stability. Numerical experiments on two- and three-dimensional problems --
including Poisson, linear elasticity, incompressible Stokes and Navier-Stokes
equations -- demonstrate the flexibility, accuracy and efficiency of the
proposed methodology.

</details>


### [5] [Eig-PIELM: A Mesh-Free Approach for Efficient Eigen-Analysis with Physics-Informed Extreme Learning Machines](https://arxiv.org/abs/2508.15343)
*Rishi Mishra,Smriti,Ganapathy Krishnamurthi,Balaji Srinivasan,Sundararajan Natarajan*

Main category: math.NA

TL;DR: Eig-PIELM is a novel mesh-free framework that extends physics-informed extreme learning machines to efficiently solve linear eigenvalue problems in one linear solve, eliminating penalty parameters and backpropagation while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient and accurate method for solving linear eigenvalue problems that avoids computational overhead from penalty parameters and backpropagation, while being suitable for rapid frequency spectrum analysis in mechanical, acoustic, and electromechanical systems.

Method: Reformulates governing differential equations into a compact algebraic system solvable in one step, enforces boundary conditions exactly via algebraic projection onto boundary-admissible subspace, and leverages the computational advantages of extreme learning machines in a mesh-free approach.

Result: The framework simultaneously yields both eigenvalues and mode shapes through a single linear solve, demonstrating robustness and accuracy across various benchmark problems.

Conclusion: Eig-PIELM's mesh-free nature, solution structure, and accuracy make it particularly valuable for parametric studies requiring rapid frequency spectrum analysis in various engineering systems.

Abstract: In this work, a novel Eig-PIELM framework is proposed that extends
physics-informed extreme learning machine for an efficient and accurate
solution of linear eigenvalue problems. The method reformulates the governing
differential equations into a compact algebraic system solvable in a single
step. Boundary conditions are enforced exactly via an algebraic projection onto
the boundary-admissible subspace, eliminating the computational overhead of
penalty parameters, and backpropagation while preserving the computational
advantages of extreme learning machines. The proposed framework is mesh-free
and yields both eigenvalues and mode shapes simultaneously in one linear solve.
The robustness and accuracy of the proposed framework is demonstrated through a
range of benchmark problems. We believe that the mesh-free nature, solution
structure and accuracy of Eig-PIELM makes it particularly valuable for
parametric studies in mechanical, acoustic, and electromechanical systems where
rapid frequency spectrum analysis is critical.

</details>


### [6] [Implementation of Milstein Schemes for Stochastic Delay-Differential Equations with Arbitrary Fixed Delays](https://arxiv.org/abs/2508.15365)
*Mitchell T. Griggs,Kevin Burrage,Pamela M. Burrage*

Main category: math.NA

TL;DR: Develops numerical methods for solving stochastic delay-differential equations with multiple fixed delays that don't align with uniform time meshes, using Euler-Maruyama and Milstein schemes with interpolation and augmented time meshes.


<details>
  <summary>Details</summary>
Motivation: Previous simulations of SDDE schemes were restricted to divisible delays, limiting practical applications for general cases with indivisible delays that don't align with uniform time meshes.

Method: For order 1/2 convergence: fixed step size with linear interpolation. For order 1 convergence: augmented time mesh with varying step sizes and extended technique for simulating delayed iterated stochastic integrals.

Result: The numerical schemes achieve their theoretical convergence orders (1/2 and 1) as confirmed through computational examples.

Conclusion: The developed methods successfully handle SDDEs with multiple fixed indivisible delays, overcoming previous limitations and providing practical simulation techniques for general delay configurations.

Abstract: This paper develops methods for numerically solving stochastic
delay-differential equations (SDDEs) with multiple fixed delays that do not
align with a uniform time mesh. We focus on numerical schemes of strong
convergence orders $1/2$ and $1$, such as the Euler--Maruyama and Milstein
schemes, respectively. Although numerical schemes for SDDEs with delays
$\tau_1,\ldots,\tau_K$ are theoretically established, their implementations
require evaluations at both present times such as $t_n$, and also at delayed
times such as $t_n-\tau_k$ and $t_n-\tau_l-\tau_k$. As a result, previous
simulations of these schemes have been largely restricted to the case of
divisible delays. We develop simulation techniques for the general case of
indivisible delays where delayed times such as $t_n-\tau_k$ are not restricted
to a uniform time mesh. To achieve order of convergence (OoC) $1/2$, we
implement the schemes with a fixed step size while using linear interpolation
to approximate delayed scheme values. To achieve OoC $1$, we construct an
augmented time mesh that includes all time points required to evaluate the
schemes, which necessitates using a varying step size. We also introduce a
technique to simulate delayed iterated stochastic integrals on the augmented
time mesh, by extending an established method from the divisible-delays
setting. We then confirm that the numerical schemes achieve their theoretical
convergence orders with computational examples.

</details>


### [7] [Numerical Analysis of Unsupervised Learning Approaches for Parameter Identification in PDEs](https://arxiv.org/abs/2508.15381)
*Siyu Cen,Bangti Jin,Qimeng Quan,Zhi Zhou*

Main category: math.NA

TL;DR: Survey of unsupervised neural network methods for PDE parameter identification, focusing on diffusion coefficient problems, with error analysis framework using finite elements and conditional stability estimates.


<details>
  <summary>Details</summary>
Motivation: To provide rigorous mathematical analysis and error bounds for unsupervised learning approaches that use neural networks to solve PDE parameter identification problems, which have shown impressive empirical performance but lack theoretical foundations.

Method: Comprehensive survey of unsupervised learning techniques applied to diffusion coefficient identification, analyzing methods from numerical analysis perspective including Galerkin finite element method, hybrid approaches, and deep neural networks with error analysis framework.

Result: Development of a general framework for deriving rigorous error bounds on discrete approximations, highlighting the crucial role of conditional stability estimates in the error analysis of PDE parameter identification methods.

Conclusion: The paper establishes theoretical foundations for neural network-based PDE parameter identification methods through rigorous error analysis, emphasizing the importance of conditional stability estimates for ensuring reliable performance of these unsupervised learning approaches.

Abstract: Identifying parameters in partial differential equations (PDEs) represents a
very broad class of applied inverse problems. In recent years, several
unsupervised learning approaches using (deep) neural networks have been
developed to solve PDE parameter identifications. These approaches employ
neural networks as ansatz functions to approximate the parameters and / or the
states, and have demonstrated impressive empirical performance. In this paper,
we provide a comprehensive survey on these unsupervised learning techniques on
one model problem, diffusion coefficient identification, from the classical
numerical analysis perspective, and outline a general framework for deriving
rigorous error bounds on the discrete approximations obtained using the
Galerkin finite element method, hybrid method and deep neural networks.
Throughout we highlight the crucial role of conditional stability estimates in
the error analysis.

</details>


### [8] [Conditional Stability and Numerical Reconstruction of a Parabolic Inverse Source Problem Using Carleman Estimates](https://arxiv.org/abs/2508.15406)
*Tianhao Hu,Xinchi Huang,Bangti Jin,Qimeng Quan,Zhi Zhou*

Main category: math.NA

TL;DR: Novel numerical method for recovering spatial sources in parabolic equations from partial interior measurements with proven stability and error bounds.


<details>
  <summary>Details</summary>
Motivation: To develop an effective numerical approach for solving inverse source problems in parabolic equations with rigorous mathematical foundations and practical applicability.

Method: Uses Carleman estimates to establish conditional Lipschitz and Hölder stability, then employs conforming finite element approximations in both time and space dimensions.

Result: Successfully developed a numerical method with proven stability properties and rigorous error bounds for discrete approximations, validated through numerical experiments.

Conclusion: The proposed approach provides an effective and mathematically sound solution for inverse source problems in parabolic equations with practical numerical implementation.

Abstract: In this work we develop a new numerical approach for recovering a spatially
dependent source component in a standard parabolic equation from partial
interior measurements. We establish novel conditional Lipschitz stability and
H\"{o}lder stability for the inverse problem with and without boundary
conditions, respectively, using suitable Carleman estimates. Then we propose a
numerical approach for solving the inverse problem using conforming finite
element approximations in both time and space. Moreover, by utilizing the
conditional stability estimates, we prove rigorous error bounds on the discrete
approximation. We present several numerical experiments to illustrate the
effectiveness of the approach.

</details>


### [9] [A Structure-Preserving Scheme for the Euler System with Potential Temperature Transport](https://arxiv.org/abs/2508.15416)
*K. R. Arun,Rahuldev Ghorai*

Main category: math.NA

TL;DR: Developed an asymptotic preserving, positivity-preserving semi-implicit finite volume scheme for compressible Euler equations with potential temperature transport that works across all Mach number regimes.


<details>
  <summary>Details</summary>
Motivation: The compressible Euler equations with potential temperature transport become stiff in the low Mach number regime, posing significant numerical challenges for atmospheric modeling applications.

Method: All-speed semi-implicit finite volume scheme that is asymptotic preserving in the low Mach limit and strictly positivity preserving for density and potential temperature.

Result: The scheme ensures stability and accuracy across a broad range of Mach numbers, from fully compressible to nearly incompressible regimes, and maintains consistency with both compressible and incompressible limits.

Conclusion: Numerical experiments confirm the method robustly captures complex flow features while preserving essential physical and mathematical structures, making it suitable for atmospheric modeling applications.

Abstract: We consider the compressible Euler equations with potential temperature
transport, a system widely used in atmospheric modelling to describe adiabatic,
inviscid flows. In the low Mach number regime, the equations become stiff and
pose significant numerical challenges. We develop an all-speed, semi-implicit
finite volume scheme that is asymptotic preserving (AP) in the low Mach limit
and strictly positivity preserving for density and potential temperature. The
scheme ensures stability and accuracy across a broad range of Mach numbers,
from fully compressible to nearly incompressible regimes. We rigorously
establish consistency with both the compressible system and its incompressible,
density-dependent limit. Numerical experiments confirm that the method robustly
captures complex flow features while preserving the essential physical and
mathematical structures of the model.

</details>


### [10] [Exponential decay of the discrete energy for the wave-wave coupled system](https://arxiv.org/abs/2508.15514)
*Toni Sayah,Toufic El Arwadi*

Main category: math.NA

TL;DR: Numerical analysis of discrete energy decay for dissipative coupled wave system using P1 FEM and implicit Euler scheme, showing linear convergence and exponential energy decay.


<details>
  <summary>Details</summary>
Motivation: To analyze the asymptotic behavior of discrete energy in dissipative coupled wave systems and establish convergence properties of numerical approximations.

Method: P1 finite element method for spatial discretization combined with implicit Euler scheme for time integration, with a priori error analysis and energy method.

Result: Numerical scheme exhibits linear convergence under extra regularity assumptions, and exponential decay of fully discrete energy is demonstrated for the first time.

Conclusion: The proposed numerical method effectively captures the energy decay behavior of dissipative coupled wave systems with proven convergence and stability properties.

Abstract: In this article, a numerical analysis of the asymptotic behavior of the
discrete energy associated to a dissipative coupled wave system is conducted.
The numerical approximation of the system is constructed using the P1 finite
element method for spatial discretization, combined with the implicit Euler
scheme for time integration. An a priori error analysis is established, showing
that, under extra regularity assumptions on the continuous solution, the
numerical scheme exhibits linear convergence. Then, for the first time in the
literature, the exponential decay of the fully discrete energy is shown using
the energy method.

</details>


### [11] [Weighted finite difference methods for the semiclassical nonlinear Schrödinger equation with multiphase oscillatory initial data](https://arxiv.org/abs/2508.15683)
*Yanyan Shi,Christian Lubich*

Main category: math.NA

TL;DR: Weighted finite difference methods for solving highly oscillatory dispersive evolution equations without needing prohibitively fine grids.


<details>
  <summary>Details</summary>
Motivation: Standard finite difference methods require extremely fine grids to resolve high-frequency oscillations in both space and time for semiclassically scaled nonlinear Schrödinger equations, which is computationally prohibitive.

Method: Modified traditional finite difference methods with appropriate exponential weights, specifically proposing weighted leapfrog and weighted Crank-Nicolson methods.

Result: Both proposed methods achieve second-order accuracy with time steps and mesh sizes that are not restricted by the small semiclassical parameter.

Conclusion: The weighted finite difference approach successfully handles highly oscillatory solutions without the computational burden of extremely fine grids, as demonstrated by numerical experiments.

Abstract: This paper introduces weighted finite difference methods for numerically
solving dispersive evolution equations with solutions that are highly
oscillatory in both space and time. We consider a semiclassically scaled cubic
nonlinear Schr\"odinger equation with highly oscillatory initial data, first in
the single-phase case and then in the general multiphase case. The proposed
methods do not need to resolve high-frequency oscillations in both space and
time by prohibitively fine grids as would be required by standard finite
difference methods. The approach taken here modifies traditional finite
difference methods by appropriate exponential weights. Specifically, we propose
the weighted leapfrog and weighted Crank--Nicolson methods, both of which
achieve second-order accuracy with time steps and mesh sizes that are not
restricted in magnitude by the small semiclassical parameter. Numerical
experiments illustrate the theoretical results.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [12] [Brezis-Nirenberg type problem for fractional sub-Laplacian on the Heisenberg group](https://arxiv.org/abs/2508.14990)
*Vikram Yallapa Naik,Gaurav Dwivedi*

Main category: math.AP

TL;DR: Existence of weak solutions for fractional sub-Laplace equations with critical Sobolev exponent in the Heisenberg group setting


<details>
  <summary>Details</summary>
Motivation: Extending the celebrated Brezis-Nirenberg problem to the fractional sub-Laplace framework in the Heisenberg group context

Method: Analysis of fractional sub-Laplace equations with critical Sobolev exponent terms on bounded domains in the Heisenberg group

Result: Demonstrates the existence of weak solutions for this class of equations

Conclusion: Establishes solvability results for fractional sub-Laplace equations with critical growth in Heisenberg group settings

Abstract: In this paper, we show the existence of a weak solution for a fractional
sub-Laplace equation involving a term with the critical Sobolev exponent,
namely, \begin{align*} (-\Delta_\mathbb{H})^su - \lambda u &= |u|^{Q^*_s -2}u
\text{ in } \Omega,\\ u &= 0 \text{ in } \mathbb{H}^N \setminus \Omega,
\end{align*} where $\Omega \subseteq \mathbb{H}^N$ is bounded and has
continuous boundary, $(-\Delta_\mathbb{H})^s$ is the horizontal fractional
Laplacian, $s \in (0,1), \lambda > 0,$ and $Q^*_s=\frac{2Q}{Q-2s}$ is the
Sobolev critical exponent. This problem is motivated by the celebrated
Brezis-Nirenberg problem \cite{brezis1983positive}.

</details>


### [13] [Optimal Interference Signal for Masking an Acoustic Source](https://arxiv.org/abs/2508.15023)
*Hongyun Wang,Hong Zhou*

Main category: math.AP

TL;DR: A framework for designing acoustic interference signals to mask acoustic sources from detection in target regions, with analytical solutions for spherical cases and numerical methods for general cases.


<details>
  <summary>Details</summary>
Motivation: To address acoustic privacy and signal obfuscation needs in environments where acoustic signatures need to be hidden from detection sensors.

Method: Developed theoretical and computational framework using analytical quasi-steady periodic solutions for spherical symmetric cases, superposition methods, and efficient numerical methods for 3D wave equation in general cases. Also examined self-masking phenomena and optimized point-force deployments.

Result: Derived analytical solutions for canonical spherical cases, demonstrated self-masking capabilities, and developed effective numerical methods for general acoustic masking scenarios.

Conclusion: The framework provides effective acoustic masking solutions with applications in undersea communication security, vehicle stealth, and protection against acoustic surveillance.

Abstract: In an environment where acoustic privacy or deliberate signal obfuscation is
desired, it is necessary to mask the acoustic signature generated in essential
operations. We consider the problem of masking the effect of an acoustic source
in a target region where possible detection sensors are located. Masking is
achieved by placing interference signals near the acoustic source. We introduce
a theoretical and computational framework for designing such interference
signals with the goal of minimizing the residual amplitude in the target
region. For the three-dimensional (3D) forced wave equation with spherical
symmetry, we derive analytical quasi-steady periodic solutions for several
canonical cases. We examine the phenomenon of self-masking where an acoustic
source with certain spatial forcing profile masks itself from detection outside
its forcing footprint. We then use superposition of spherically symmetric
solutions to investigate masking in a given target region. We analyze and
optimize the performance of using one or two point-forces deployed near the
acoustic source for masking in the target region. For the general case where
the spatial forcing profile of the acoustic source lacks spherical symmetry, we
develop an efficient numerical method for solving the 3D wave equation.
Potential applications of this work include undersea acoustic communication
security, undersea vehicles stealth, and protection against acoustic
surveillance.

</details>


### [14] [Analysis of mean field games via Fokker-Planck-Kolmogorov equations: existence of equilibria](https://arxiv.org/abs/2508.15029)
*Stanislav V. Shaposhnikov,Dmitry V. Shatilovich*

Main category: math.AP

TL;DR: Existence proof for mean field games with unbounded coefficients using Fokker-Planck-Kolmogorov equations and Lyapunov functions


<details>
  <summary>Details</summary>
Motivation: To address the challenge of mean field games with unbounded coefficients where standard existence results may not apply

Method: Novel approach combining Fokker-Planck-Kolmogorov equations, Ambrosio-Figalli-Trevisan superposition principle, and a priori estimates with Lyapunov functions

Result: Successfully proved the existence of solutions for mean field games with unbounded coefficients

Conclusion: The proposed methodology provides a robust framework for handling mean field games with unbounded coefficients and establishes existence results

Abstract: We study mean field games with unbounded coefficients. The existence of a
solution is proved. We propose a new approach based on Fokker-Planck-Kolmogorov
equations, the Ambrosio-Figalli-Trevisan superposition principle and a priory
estimates with Lyapunov functions.

</details>


### [15] [On the Fermi-Dirac-type Fisher information](https://arxiv.org/abs/2508.15054)
*Yuzhe Zhu*

Main category: math.AP

TL;DR: Analysis of Fisher information for Fermi-Dirac particles in kinetic models, showing monotonicity under initial data bounds and discussing evolution in heat and Landau equations.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of Fisher information in kinetic models for Fermi-Dirac particles that obey the exclusion principle, particularly how it evolves over time in different equations.

Method: Introduce a generalized Fisher information concept tailored for Fermi-Dirac-Fokker-Planck equations, analyze its dissipation identity, and examine time evolution under specific initial data constraints.

Result: The Fisher information decreases along solutions when initial data is bounded above, but monotonicity fails without such bounds. Evolution patterns are also characterized for heat equation and Landau-Fermi-Dirac equation.

Conclusion: Initial data constraints are crucial for Fisher information monotonicity in Fermi-Dirac kinetic models, with different evolution behaviors observed across various equation types.

Abstract: We consider kinetic models for Fermi-Dirac-like particles obeying the
exclusion principle. A generalized notion of Fisher information, tailored to
kinetic equations of Fermi-Dirac-Fokker-Planck type, is introduced via the
associated entropy dissipation identity. We show that, subject to a suitable
upper bound on the initial data, this quantity decreases along solutions of the
Fermi-Dirac-Fokker-Planck equation, while monotonicity can fail in the absence
of such a bound. We also discuss the time evolution of this Fermi-Dirac-type
Fisher information for the heat equation and the linear-type Landau-Fermi-Dirac
equation with Maxwell molecules.

</details>


### [16] [Non-linear degenerate parabolic flow equations and a finer differential structure on Wasserstein spaces](https://arxiv.org/abs/2508.15140)
*Arthur Schichl*

Main category: math.AP

TL;DR: New differential structures on Wasserstein spaces for p>2 on Riemannian manifolds, with generalized flow equations and smooth solution construction via Average Flow Approximation Series.


<details>
  <summary>Details</summary>
Motivation: To expand the notion of smooth curves in Wasserstein spaces and develop a finer differential structure than classical approaches, enabling generalized analysis of flow equations with measure-dependent coefficients.

Method: Define new differential structures on Wasserstein spaces, use degenerate second order PDE flow equations with measure-dependent coefficients, construct smooth solutions as uniform limits of Average Flow Approximation Series (variant of explicit Euler-scheme approximations).

Result: Successfully constructed smooth solutions as uniform limits, proved a generalized version of the Central Limit Theorem, and established uniqueness of smooth solutions under stronger assumptions.

Conclusion: The proposed framework provides a refined differential structure for Wasserstein spaces that enables rigorous analysis of flow equations and extends classical results like the Central Limit Theorem to more general settings.

Abstract: We define new differential structures on the Wasserstein spaces
$\mathcal{W}_p(M)$ for $p > 2$ and a general Riemannian manifold $(M,g)$. We
consider a very general and possibly degenerate second order partial
differential flow equation with measure dependent coefficients to expand the
notion of smooth curves and to ensure that the new differential structure is
finer than the classical one. Under weak assumptions, we explicitly construct
smooth solutions as uniform limits of Average Flow Approximation Series (a
variant of explicit Euler--scheme approximations) in $\mathcal{W}_p(M)$ and,
thus, prove a generalzed version of the Central Limit Theorem. Under slightly
stronger assumptions, we prove that smooth solutions of our newly introduced
flow--equation are unique.

</details>


### [17] [Multiple nodal solutions to a scalar field equation with double-power nonlinearity and zero mass at infinity](https://arxiv.org/abs/2508.15167)
*Mónica Clapp,Carlos Culebro*

Main category: math.AP

TL;DR: Existence of sign-changing solutions for nonlinear elliptic equations in exterior domains with decaying potential and asymmetric nonlinearity


<details>
  <summary>Details</summary>
Motivation: Study nonlinear elliptic equations in exterior domains with decaying potentials and asymmetric nonlinearities to understand existence and multiplicity of sign-changing solutions under weak symmetry conditions

Method: Analysis of the nonlinear elliptic equation -Δu + V(x)u = f(u) in exterior domains Ω of ℝᴺ, where V decays to zero at infinity, f is subcritical at infinity and supercritical near origin, using variational methods and symmetry assumptions

Result: Established conditions guaranteeing existence of prescribed number of sign-changing solutions, particularly showing that in dimensions N≥4, numerous exterior domains with finite symmetries admit predetermined number of nodal solutions

Conclusion: The paper provides existence results for multiple sign-changing solutions in exterior domains with decaying potentials, demonstrating rich solution structures even under weak symmetry assumptions, especially in higher dimensions

Abstract: We consider the nonlinear elliptic equation \begin{equation*} -\Delta u +
V(x)u = f(u), \qquad u\in D^{1,2}_0(\Omega), \end{equation*} in an exterior
domain $\Omega$ of $\mathbb{R}^N$, where $V$ is a scalar potential that decays
to zero at infinity and the nonlinearity $f$ is subcritical at infinity and
supercritical near the origin. Under weak symmetry assumptions, we provide
conditions that guarantee that this problem has a prescribed number of
sign-changing solutions. In particular, we show that in dimensions $N\geq 4$
there are numerous examples of exterior domains with finite symmetries in which
the problem has a predetermined number of nodal solutions.

</details>


### [18] [Constructing characteristic initial data for three dimensional compressible Euler equations](https://arxiv.org/abs/2508.15199)
*Yuxuan Wang,Sifan Yu,Pin Yu*

Main category: math.AP

TL;DR: Resolves characteristic initial data problem for 3D compressible Euler equations using acoustical geometry framework, providing complete data construction for admissible hypersurfaces.


<details>
  <summary>Details</summary>
Motivation: Addresses an open problem analogous to Christodoulou's characteristic initial value formulation in general relativity, aiming to provide tools for studying long-time dynamics of compressible Euler flow.

Method: Uses vector field method within acoustical geometry framework to recursively determine all order derivatives of solutions along characteristic cones via transport equations and wave equations.

Result: Proves that arbitrary smooth entropy function and angular velocity determine smooth initial data on initial cones that render them characteristic, differing from previous approaches by Speck-Yu and Lisibach.

Conclusion: Provides complete characteristic data construction for 3D compressible Euler system, introducing novel tools and aspects for studying long-time flow dynamics.

Abstract: This paper resolves the characteristic initial data problem for the
three-dimensional compressible Euler equations - an open problem analogous to
Christodoulou's characteristic initial value formulation for the vacuum
Einstein field equations in general relativity. Within the framework of
acoustical geometry, we prove that for any "initial cone" $C_0\subset
\mathcal{D}=[0,T]\times\mathbb{R}^3$ with initial data
$(\mathring{\rho},\mathring{v},\mathring{s})$ given at $S_{0,0}=C_0\cap
\Sigma_0$, arbitrary smooth entropy function and angular velocity determine
smooth initial data $(\rho,v,s)$ on $C_0$ that render $C_0$ characteristic.
Differing from the intersecting-hypersurface case by Speck-Yu [19] and the
symmetric reduction case by Lisibach [11], our vector field method recursively
determines all (including $0$-th) order derivatives of the solution along $C_0$
via transport equations and wave equations. This work provides a complete
characteristic data construction for admissible hypersurfaces in the 3D
compressible Euler system, introducing useful tools and providing novel aspects
for studies of the long-time dynamics of the compressible Euler flow.

</details>


### [19] [On the extremal functions of second order uncertainty principles: symmetry and symmetry breaking](https://arxiv.org/abs/2508.15221)
*Xiao-Ping Chen,Chun-Lei Tang*

Main category: math.AP

TL;DR: This paper addresses symmetry breaking in the second order Hydrogen Uncertainty Principle, disproving a conjecture for dimensions 2 and 3, and establishes sharp weighted uncertainty principles with radial extremal functions.


<details>
  <summary>Details</summary>
Motivation: To investigate symmetry properties and symmetry breaking phenomena in the second order Hydrogen Uncertainty Principle, building on previous conjectures and extending recent work on sharp inequalities.

Method: The authors use suitable test functions to disprove the conjecture for N=2,3 dimensions, and then derive a family of sharp weighted second order uncertainty principles, proving that the extremal functions are radial.

Result: The paper provides a negative answer to the conjecture by Cazacu, Flynn and Lam for dimensions 2 and 3, demonstrates symmetry breaking, and obtains a family of sharp weighted second order Hydrogen Uncertainty Principles with radial extremal functions.

Conclusion: This work advances the understanding of symmetry in higher-order uncertainty principles, disproves an important conjecture, and extends previous results by establishing sharp inequalities with radial extremal functions.

Abstract: This paper focus on the symmetry and symmetry breaking about the second order
Hydrogen Uncertainty Principle. \emph{Firstly}, by choosing a suitable test
function, we give a negative answer to the conjecture presented by Cazacu,
Flynn and Lam in [\emph{J. Funct. Anal.} \textbf{283} (2022), Paper No. 109659,
37 pp] for $N\in\{2,3\}$, and emphasizing the symmetry breaking phenomenon.
\emph{Secondly}, we obtain a family of sharp weighted second order Hydrogen
Uncertainty Principle, and prove the extremal functions are radial, which
extends the work of Duong and Nguyen [The sharp second order
Caffareli-Kohn-Nirenberg inequality and stability estimates for the sharp
second order uncertainty principle, arXiv:2102.01425].

</details>


### [20] [Statistical conservation laws for scalar model problems: Hierarchical evolution equations](https://arxiv.org/abs/2508.15359)
*Qian Huang,Christian Rohde*

Main category: math.AP

TL;DR: New hierarchical evolution equations for probability density functions (PDFs) of scalar conservation laws with random initial data, developing frameworks for multi-point PDFs and single-point higher-order derivative PDFs.


<details>
  <summary>Details</summary>
Motivation: To develop mathematical frameworks that can represent and analyze the probability density functions of solutions to scalar conservation laws with random initial conditions, building on similar approaches used for the incompressible Navier-Stokes equations.

Method: Developed two hierarchical frameworks: 1) multi-point PDF evolution equations that capture statistical correlations across spatial locations, and 2) single-point higher-order derivative PDF evolution equations that focus on local statistical properties.

Result: Created new hierarchical evolution equations that can represent the statistical behavior of scalar conservation laws with random initial data, providing mathematical tools to analyze probability density functions of the solutions.

Conclusion: The developed hierarchical frameworks provide systematic approaches for studying PDFs of scalar conservation laws, offering insights into statistical correlations and serving as guidance for closure strategies in turbulence modeling and stochastic PDE analysis.

Abstract: The probability density functions (PDFs) for the solution of the
incompressible Navier-Stokes equation can be represented by a hierarchy of
linear equations. This article develops new hierarchical evolution equations
for PDFs of a scalar conservation law with random initial data as a model
problem. Two frameworks are developed, including multi-point PDFs and
single-point higher-order derivative PDFs. These hierarchies capture
statistical correlations and guide closure strategies.

</details>


### [21] [Coupled Vlasov and non-Newtonian fluid dynamics: existence and large-time behavior](https://arxiv.org/abs/2508.15460)
*Young-Pil Choi,Jinwook Jung,Aneta Wróblewska-Kamińska*

Main category: math.AP

TL;DR: Global existence of weak solutions for coupled kinetic-non-Newtonian fluid system on periodic domain, with large-time decay of modulated energy functional under additional assumptions.


<details>
  <summary>Details</summary>
Motivation: Study the interaction between particles described by Vlasov equation and incompressible power-law fluid through drag force, focusing on existence and long-time behavior of solutions.

Method: Mathematical analysis of coupled system using weak solution framework, with modulated energy functional to measure deviation from velocity alignment.

Result: Proved global existence of weak solutions for all p > 8/5. Under uniform boundedness of particle density, established algebraic decay (p > 2) or exponential decay (6/5 ≤ p ≤ 2) of modulated energy functional.

Conclusion: Fluid dissipation plays crucial role in large-time dynamics, with different decay regimes depending on power-law exponent p, providing comprehensive understanding of coupled system behavior.

Abstract: We study a coupled kinetic-non-Newtonian fluid system on the periodic domain
${\mathbb T}^3$, where particles evolve by a Vlasov equation and interact with
an incompressible power-law fluid through a drag force. We prove the global
existence of weak solutions for all $p > \frac{8}{5}$, where $p > 1$ denotes
the power-law exponent of the fluid's stress-strain relation. Under an
additional uniform boundedness assumption on the particle density, we also
establish large-time decay of a modulated energy functional measuring deviation
from velocity alignment. The decay rate is algebraic when $p > 2$ and
exponential when $\frac{6}{5} \le p \le 2$, reflecting the role of fluid
dissipation in the large-time dynamics.

</details>


### [22] [A potential theory approach to the capillarity-driven Hele-Shaw problem](https://arxiv.org/abs/2508.15491)
*Bogdan-Vasile Matioc,Christoph Walker*

Main category: math.AP

TL;DR: Potential theory framework for quasistationary fluid flows in bounded geometries, applied to 2D Hele-Shaw problem with surface tension, proving local well-posedness, parabolic smoothing, and exponential stability of stationary solutions.


<details>
  <summary>Details</summary>
Motivation: To develop a mathematical framework using potential theory for analyzing quasistationary fluid flows governed by elliptic equations with constant coefficients in bounded geometries.

Method: Applied potential theory to the two-dimensional Hele-Shaw problem with surface tension, derived local well-posedness and parabolic smoothing in optimal function spaces, and established a generalized principle of linearized stability for abstract quasilinear parabolic problems.

Result: Successfully demonstrated that potential theory provides a powerful framework for fluid flow analysis, proved local well-posedness and parabolic smoothing for Hele-Shaw problem, and showed exponential stability of stationary solutions.

Conclusion: Potential theory offers an effective mathematical approach for studying quasistationary fluid flows, with applications to Hele-Shaw problems and broader classes of abstract quasilinear parabolic problems, enabling stability analysis of stationary solutions.

Abstract: In this paper, we demonstrate that potential theory provides a powerful
framework for analyzing quasistationary fluid flows in bounded geometries,
where the bulk dynamics are governed by elliptic equations with constant
coefficients. This approach is illustrated by the two-dimensional Hele-Shaw
problem with surface tension, for which we derive local well-posedness and
parabolic smoothing in (almost) optimal function spaces. In addition, we
establish a generalized principle of linearized stability for a particular
class of abstract quasilinear parabolic problems, which enables us to show that
the stationary solutions to the Hele-Shaw problem are exponentially stable.

</details>


### [23] [Well-posedness and Rayleigh-Taylor instability of the two-phase periodic quasistationary Stokes flow](https://arxiv.org/abs/2508.15502)
*Daniel Böhme,Bogdan-Vasile Matioc*

Main category: math.AP

TL;DR: Analysis of two-phase quasistationary Stokes flow with surface tension and gravity effects, focusing on interface evolution, well-posedness, and stability properties.


<details>
  <summary>Details</summary>
Motivation: To understand the mathematical properties of two-phase fluid flows with different viscosities and densities, particularly how surface tension and gravity affect interface evolution and stability.

Method: Recast the mathematical model as a fully nonlinear nonlocal evolution equation for the interface function, then analyze well-posedness, parabolic smoothing, and equilibrium solutions in subcritical Sobolev spaces.

Result: Established well-posedness and parabolic smoothing properties, demonstrated Rayleigh-Taylor instability of small finger-shaped equilibria, and determined that flat interface stability depends on a specific parameter's sign.

Conclusion: The study provides rigorous mathematical framework for analyzing two-phase Stokes flows, revealing important stability properties of fluid interfaces under surface tension and gravity effects.

Abstract: We study the two-phase, horizontally periodic, quasistationary Stokes flow in
two dimensions driven by surface tension and gravity effects in the general
context of fluids with (possibly) different viscosities and densities. The
sharp interface which separates the fluids is assumed to be the graph of a
periodic function. The mathematical model is then recast as a fully nonlinear
and nonlocal evolution equation involving only the function parametrizing the
interface. Our main results include well-posedness and a parabolic smoothing
property, as well as a study of equilibrium solutions in subcritical Sobolev
spaces. In particular, we establish the Rayleigh-Taylor instability of small,
finger-shaped equilibria and prove that the stability properties of flat
interfaces depend on the sign of a certain parameter.

</details>


### [24] [Maz'ya-type bounds for sharp constants in fractional Poincaré-Sobolev inequalities](https://arxiv.org/abs/2508.15564)
*Francesco Bozzola,Matteo Talluri*

Main category: math.AP

TL;DR: Sharp estimates for fractional Poincaré-Sobolev inequalities using nonlocal capacitary extension of inradius, with new Maz'ya-Poincaré inequality and fractional Poincaré-Wirtinger estimates.


<details>
  <summary>Details</summary>
Motivation: To extend previous local results by Maz'ya-Shubin and others to the fractional case, establishing sharp constants in fractional Poincaré-Sobolev inequalities and understanding their limiting behaviors with respect to fractional order.

Method: Develops a new Maz'ya-Poincaré inequality and fractional Poincaré-Wirtinger estimates, using nonlocal capacitary extension of inradius to prove sharp estimates for fractional Poincaré-Sobolev constants.

Result: Obtains sharp estimates for fractional Poincaré-Sobolev inequalities, new embedding criteria for homogeneous Sobolev spaces in subcritical regime, and optimal characterization for positivity of fractional Cheeger's constant.

Conclusion: The work provides fundamental advances in fractional analysis, with applications to fractional Laplacian eigenvalues and establishing connections between geometric properties and functional inequalities in the nonlocal setting.

Abstract: We prove estimates for the sharp constants in fractional Poincar\'e-Sobolev
inequalities associated to an open set, in terms of a nonlocal capacitary
extension of its inradius. This work builds upon previous results obtained in
the local case by Maz'ya and Shubin and by the first author and Brasco. We rely
on a new Maz'ya-Poincar\'e inequality and, incidentally, we also prove new
fractional Poincar\'e-Wirtinger-type estimates. These inequalities display
sharp limiting behaviours with respect to the fractional order of
differentiability. As a byproduct, we obtain a new criterion for the embedding
of the homogeneous Sobolev space $\mathcal{D}^{s,p}_0(\Omega)$ in
$L^q(\Omega)$, valid in the subcritical regime and for $p \le q < p^*_s$. Our
results are new even for the first eigenvalue of the fractional Laplacian and
contain an optimal characterization for the positivity of the fractional
Cheeger's constant.

</details>


### [25] [Strichartz estimates for higher order Schrödinger equations with Partial regular initial data](https://arxiv.org/abs/2508.15670)
*Vishvesh Kumar,Shyam Swarup Mondal,Iswarya Sitiraju,Manli Song*

Main category: math.AP

TL;DR: Refined Strichartz estimates for higher-order Schrödinger equations with partially regular initial data, applied to nonlinear well-posedness and extended to Dunkl Schrödinger equations with new stationary phase method adaptation.


<details>
  <summary>Details</summary>
Motivation: To establish Strichartz estimates for Schrödinger equations where initial data only has partial regularity (regularity in subset of spatial variables), rather than requiring full Sobolev regularity, and extend this analysis to Dunkl Schrödinger equations.

Method: Develop refined Strichartz estimates for higher-order Schrödinger equations with partial regularity, apply these to study nonlinear well-posedness, and extend to Dunkl Schrödinger equations by creating a new adaptation of stationary phase method suitable for Dunkl analysis framework.

Result: Successful establishment of refined Strichartz estimates under partial regularity conditions, application to nonlinear Schrödinger equation well-posedness, and extension to Dunkl Schrödinger equations with two distinct root systems despite challenges from lack of stationary phase method.

Conclusion: The paper provides significant advances in understanding Schrödinger equations with partial regularity, develops crucial tools for Dunkl analysis, and establishes well-posedness results for nonlinear problems with reduced regularity requirements on initial data.

Abstract: In this paper, we establish refined Strichartz estimates for higher-order
Schr\"odinger equations with initial data exhibiting partial regularity. By
partial regularity, we mean that the initial data are not required to have full
Sobolev regularity but only regularity with respect to a subset of the spatial
variables. As an application of these estimates, we investigate the
well-posedness of nonlinear Schr\"odinger equations with power-type
nonlinearities. In addition, we extend our analysis to the Dunkl Schr\"odinger
equations under partial regularity, defined with respect to two distinct root
systems. This extension poses significant challenges, mainly due to the lack of
a suitable stationary phase method in the Dunkl setting. To overcome this
difficulty, we develop a new result that provides an adaptation of the
stationary phase method to the framework of Dunkl analysis.

</details>


### [26] [Existence of hyperbolic blow-up to the generalized quasi-geostrophic equation](https://arxiv.org/abs/2508.15708)
*Lucas C. F. Ferreira,Ricardo M. M. Guimarães*

Main category: math.AP

TL;DR: Analysis of blow-up behavior in generalized surface quasi-geostrophic equations with hyperbolic saddle geometry leading to singularity formation in Hölder spaces.


<details>
  <summary>Details</summary>
Motivation: To investigate singularity formation in the generalized surface quasi-geostrophic (gSQG) equation for the more singular parameter range β∈(1,2), building on Córdoba's framework for classical SQG equations.

Method: Using hyperbolic setting framework with assumption that solution level sets contain hyperbolic saddle geometry. Deriving conditions at origin and analyzing geometric degeneration through collapse of saddle opening angle.

Result: Existence of blow-up time T* where saddle angle collapses, with lower bound for T*. Blow-up of Hölder norm ||θ(t)||_C^σ for σ∈(0,β-1) as t→T*, proving singularity formation in Hölder space.

Conclusion: First rigorous proof of singularity formation (finite or infinite time) for smooth solutions to gSQG equation, demonstrating geometric degeneration mechanism through hyperbolic saddle collapse.

Abstract: In this work, we investigate the blow-up of solutions to the generalized
surface quasi-geostrophic (gSQG) equation in $\mathbb{R}^{2}$, within the more
singular range $\beta\in(1,2)$ for the coupling of the velocity field. This
behavior is studied under a hyperbolic setting based on the framework
originally introduced by C\'{o}rdoba (1998, Annals of Math. 148, 1135--52) for
the classical SQG equation. Assuming that the level sets of the solution
contains a hyperbolic saddle, and under suitable conditions on the solution at
the origin, we obtain the existence of a time
$T^{\ast}\in\mathbb{R}^{+}\cup\{\infty\}$ at which the opening angle of the
saddle collapses. Moreover, we derive a lower bound for the blow-up time
$T^\ast$. This geometric degeneration leads to the blow-up of the H\"{o}lder
norm $\Vert\theta(t)\Vert_{C^{\sigma}}$ as $t\rightarrow T^{\ast}$, for
$\sigma\in(0, \beta -1)$, showing the formation of singularity in the
H\"{o}lder space at time $T^{\ast}$. To the best of our knowledge, these are
the first results in the literature to rigorously prove the formation of a
singularity, whether in finite or infinite time, for a class of smooth
solutions to the gSQG equation.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [27] [GEN2: A Generative Prediction-Correction Framework for Long-time Emulations of Spatially-Resolved Climate Extremes](https://arxiv.org/abs/2508.15196)
*Mengze Wang,Benedikt Barthel Sorensen,Themistoklis Sapsis*

Main category: physics.comp-ph

TL;DR: GEN2 is a generative prediction-correction framework that combines Gaussian emulation with machine learning correction to efficiently forecast extreme climate event statistics across various emissions scenarios.


<details>
  <summary>Details</summary>
Motivation: Conventional Earth System Models are computationally expensive for generating large ensembles needed to quantify climate extreme risks across multiple emissions scenarios, requiring a more efficient approach.

Method: Two-step framework: 1) Conditional Gaussian emulator for prediction, 2) Non-Gaussian machine learning correction trained on reference data and emulated fields nudged toward reference to ensure robustness to chaos.

Result: Model accurately predicts extreme event statistics on historical ERA5 data and successfully extrapolates to different future climate scenarios beyond training data distribution.

Conclusion: GEN2 provides an efficient and accurate method for forecasting climate extreme statistics, enabling extrapolation to unseen scenarios with training from just one realization of a single warming scenario.

Abstract: Accurately quantifying the increased risks of climate extremes requires
generating large ensembles of climate realization across a wide range of
emissions scenarios, which is computationally challenging for conventional
Earth System Models. We propose GEN2, a generative prediction-correction
framework for an efficient and accurate forecast of the extreme event
statistics. The prediction step is constructed as a conditional Gaussian
emulator, followed by a non-Gaussian machine-learning (ML) correction step. The
ML model is trained on pairs of the reference data and the emulated fields
nudged towards the reference, to ensure the training is robust to chaos. We
first validate the accuracy of our model on historical ERA5 data and then
demonstrate the extrapolation capabilities on various future climate change
scenarios. When trained on a single realization of one warming scenario, our
model accurately predicts the statistics of extreme events in different
scenarios, successfully extrapolating beyond the distribution of training data.

</details>


### [28] [Bridging the Analog and the Probabilistic Computing Divide: Configuring Oscillator Ising Machines as P-bit Engines](https://arxiv.org/abs/2508.15234)
*E. M. H. E. B. Ekanayake,Nikhat Khan,Nikhil Shukla*

Main category: physics.comp-ph

TL;DR: A framework for configuring Oscillator Ising Machines as p-bit engines using harmonic injection, creating synergies between two distinct computing paradigms.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between Oscillator Ising Machines and p-bit-based computing platforms, traditionally viewed as separate approaches, by developing a unified theoretical framework.

Method: Using a novel interplay between first- and second harmonic injection to oscillators to enable OIMs to function as p-bit engines.

Result: Successfully demonstrated that OIMs can be configured as p-bit engines, identified new synergies between the two methods, and broadened application scope for OIMs.

Conclusion: The approach is generalizable and can be applied to other analog dynamical systems like the Dynamical Ising Machine, creating new possibilities for hybrid computing platforms.

Abstract: Oscillator Ising Machines (OIMs) and probabilistic bit (p-bit)-based
computing platforms have emerged as promising paradigms for tackling complex
combinatorial optimization problems. Although traditionally viewed as distinct
approaches, this work presents a theoretically grounded framework for
configuring OIMs as p-bit engines. We demonstrate that this functionality can
be enabled through a novel interplay between first- and second harmonic
injection to the oscillators. Our work identifies new synergies between the two
methods and broadens the scope of applications for OIMs. We further show that
the proposed approach can be applied to other analog dynamical systems, such as
the Dynamical Ising Machine.

</details>


### [29] [The CP2K Program Package Made Simple](https://arxiv.org/abs/2508.15559)
*Marcella Iannuzzi,Jan Wilhelm,Frederick Stein,Augustin Bussy,Hossam Elgabarty,Dorothea Golze,Anna Hehn,Maximilian Graml,Stepan Marek,Beliz Sertcan Gökmen,Christoph Schran,Harald Forbert,Rustam Z. Khaliullin,Anton Kozhevnikov,Mathieu Taillefumier,Rocco Meli,Vladimir Rybkin,Martin Brehm,Robert Schade,Ole Schütt,Johann V. Pototschnig,Hossein Mirhosseini,Andreas Knüpfer,Dominik Marx,Matthias Krack,Jürg Hutter,Thomas D. Kühne*

Main category: physics.comp-ph

TL;DR: CP2K is an open-source atomistic simulation software capable of handling diverse systems from molecules to materials, with both quantum-mechanical and classical methods.


<details>
  <summary>Details</summary>
Motivation: To present CP2K's practical applications and usage for computing static and dynamical properties across various atomistic systems, complementing the theoretical foundation paper.

Method: Review of CP2K's capabilities focusing on practical implementation rather than theoretical concepts, covering quantum-mechanical and classical simulation approaches.

Result: Demonstrates CP2K's versatility in simulating isolated molecules, functional materials, interfaces, crystalline solids, amorphous glasses, and soft-matter systems in different states.

Conclusion: CP2K serves as a comprehensive tool for atomistic simulations across diverse chemical and material systems, with practical applications taking precedence over theoretical exposition in this review.

Abstract: CP2K is a versatile open-source software package for simulations across a
wide range of atomistic systems, from isolated molecules in the gas phase to
low-dimensional functional materials and interfaces, as well as highly
symmetric crystalline solids, disordered amorphous glasses, and weakly
interacting soft-matter systems in the liquid state and in solution. This
review highlights CP2K's capabilities for computing both static and dynamical
properties using quantum-mechanical and classical simulation methods. In
contrast to the accompanying theory and code paper [J. Chem. Phys. 152, 194103
(2020)], the focus here is on the practical usage and applications of CP2K,
with underlying theoretical concepts introduced only as needed.

</details>


### [30] [Investigating the sliding behavior of graphene nanoribbons](https://arxiv.org/abs/2508.15587)
*Gourav Yadav,Aningi Mokhalingam,Roger A. Sauer,Shakti S. Gupta*

Main category: physics.comp-ph

TL;DR: FE model studies graphene nanoribbon-substrate interaction, revealing critical strain and length parameters affecting sliding behavior and strain transfer.


<details>
  <summary>Details</summary>
Motivation: To understand interlayer interaction mechanics between graphene nanoribbons and substrates under biaxial deformations, particularly focusing on boundary condition effects.

Method: Developed Euler-Bernoulli beam finite element model calibrated with molecular dynamics simulations using Kolmogorov-Crespi potential, studying sliding behavior and strain transfer under uniform biaxial deformations.

Result: Identified critical strain (ec) beyond which strain transfer decreases suddenly, critical GNR length (Lc ≈ 10 nm) for strain transfer, dissipative sliding length (Ld ≈ 10 nm), and edge pulling force saturation at GNR length ≥ 17 nm. Maximum transferable strain between 0.57%-1.15%. FE results match MD within ~10% error.

Conclusion: The FE model successfully captures graphene interlayer mechanics, revealing critical length and strain parameters that govern sliding behavior and strain transfer, with good agreement to MD simulations despite parameter sensitivity.

Abstract: This work presents a Euler-Bernoulli beam finite element (FE) model to study
the interlayer interaction mechanics of graphene nanoribbon (GNR) over a
graphene substrate. The FE model is calibrated using molecular dynamics (MD)
simulations employing the potential of Kolmogorov and Crespi. This study
focuses mainly on the effect of boundary conditions on sliding behavior and
strain transfer between layers when the substrate is subjected to uniform
biaxial deformations. The interlayer shearing or sliding behavior is found to
depend on the presence of critical parameters, namely, the applied strain to
the substrate and the length of the GNR. The FE results indicate that the
applied strain transferred from the substrate to the GNR varies linearly up to
a critical value ec beyond which it decreases suddenly. Further, ec is found to
appear beyond a critical GNR length, Le is approximately 10 nm. Furthermore, a
length parameter Ld is approximately 10 nm is computed, beyond which the
sliding of GNR is dissipative. Through FE simulations, it is also found that
for a GNR length is greater than or equal to 17 nm, the edge pulling force
saturates. Our results also highlight the importance of the inertia of GNR on
its sliding for different boundary conditions. It is also concluded that the
maximum strain that can be transferred to GNR lies between 0.57% and 1.15%. The
results of the FE approach align with MD simulations within an error of
approximately 10% that can be attributed to the choice of material parameters
and the simulation setup.

</details>


### [31] [Pseudo-spectral model of elastic-wave propagation through toothed-whale head anatomy, and implications for biosonar](https://arxiv.org/abs/2508.15739)
*Fawad Ali,Carlos García A.,Aida Hejazi-Nooghabi,Lapo Boschi*

Main category: physics.comp-ph

TL;DR: Numerical modeling reveals how toothed whales localize sound sources on the median plane without pinnae, using head anatomy to create distinctive waveform patterns at the ear locations.


<details>
  <summary>Details</summary>
Motivation: Toothed whales have exceptional sound localization abilities despite lacking pinnae, and the specific mechanism enabling this performance remains unclear despite detailed anatomical studies.

Method: Used 3D PSTD numerical modeling with CT-scanned head anatomy (1.11mm voxel resolution) to simulate elastic wave propagation from dolphin-like clicks at various elevation angles along the midsagittal plane.

Result: The study found that sound localization is possible through correlation analysis of the reverberated time-domain waveforms recorded at the tympano-periotic complex locations.

Conclusion: Toothed whales' head anatomy serves as an effective sound localization mechanism, creating distinctive waveform patterns that enable source localization on the median plane without requiring pinnae.

Abstract: The sound-localization and, in particular, biosonar system of toothed whales
is exceptionally performant. How this is achieved is not clear, given that: (i)
toothed whales have no pinnae; (ii) while their auditory pathways have been
studied in detail, no specific feature apparently replacing the pinna has been
identified. In this study, we employ a pseudo-spectral time domain (PSTD)
numerical scheme to model three-dimensional elastic wave propagation through a
toothed-whale head including soft tissues. Computed tomography (CT) scans were
utilized to build a three-dimensional velocity-density model of the specimen's
head, parametrized on a high-resolution $1.11$ mm voxel grid. We first validate
our wave propagation solver, identifying a range of frequencies and spatial
scale lengths where the PSTD scheme captures the complexities of elastic wave
propagation through toothed-whale anatomy. We next focus on the toothed whale's
ability to locate sources on the median plane, where the role of anatomy is
crucial. A 45 kHz central frequency burst (dolphin-like click) was modeled and
directed at elevation angles from $-90^\circ$ to $+90^\circ$ in $5^\circ$ steps
along the midsagittal plane. We find that the incoming sound can be localized,
via correlation, from the reverberated portion of the time-domain waveforms
recorded at the tympano-periotic complex locations.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [32] [Simulation Studies of Resonant Excitation of Electron Bernstein Waves in Capacitive Discharges](https://arxiv.org/abs/2508.15269)
*Deepak Gautam,Sarveshwar Sharma,Igor Kaganovich,Bhooshan Paradkar*

Main category: physics.plasm-ph

TL;DR: Study of capacitive coupled plasma discharges in mildly magnetized regime showing asymmetric density profiles and electron Bernstein wave excitation, with numerical simulations revealing transition behaviors.


<details>
  <summary>Details</summary>
Motivation: To understand the complex plasma dynamics in capacitive coupled plasma discharges under mildly magnetized conditions where RF fields interact with external magnetic fields, particularly investigating asymmetric density distributions and wave phenomena.

Method: Used particle-in-cell Monte Carlo collision (PIC-MCC) technique for detailed numerical simulations to capture kinetic behavior of electrons and ions, including collisionless effects and sheath dynamics.

Result: Observed asymmetric plasma density profiles and excitation of electron Bernstein waves along steep density gradients. Found transition from symmetric to asymmetric and back to symmetric configuration with increasing magnetic field strength. EBWs strongly correlated with discharge asymmetry and play significant role in energy transport and electron heating.

Conclusion: Weak magnetic fields significantly shape plasma behavior in CCP discharges, with electron Bernstein waves playing crucial role in energy transport under mildly magnetized conditions, highlighting importance of wave-particle interactions.

Abstract: The behavior of capacitive coupled plasma (CCP) discharges is investigated in
a mildly magnetized regime, defined by the condition 1 $\leq$ $f_{ce}/f_{rf}$
$\lt$ 2, where $f_{ce}$ and $f_{rf}$ are the cyclotron and radio-frequencies
(RF), respectively. This regime exhibits complex and distinctive plasma
dynamics due to the interplay between RF fields and the externally applied
magnetic field. Two prominent phenomena are observed in this regime. First, the
plasma density profile becomes asymmetric across the discharge, deviating from
the typical symmetric distribution seen in unmagnetized CCPs. Second, electron
Bernstein waves (EBWs), high-frequency electrostatic waves, are excited and
propagate within the bulk plasma, particularly along steep electron density
gradients. As the strength of the magnetic field increases within this regime,
the CCP discharge undergoes a transition from a symmetric configuration to an
asymmetric one, and then returns to a symmetric profile at higher field
strengths. Notably, the excitation and propagation of EBWs are strongly
correlated with the presence of discharge asymmetry and localized density
gradients. These waves play a significant role in energy transport and electron
heating under mildly magnetized conditions. To gain deeper insight into the
underlying physics, detailed numerical simulations are carried out using the
particle-in-cell Monte Carlo collision (PIC-MCC) technique. These simulations
capture the kinetic behavior of electrons and ions, including the collisionless
effects and sheath dynamics essential to understanding the excitation of EBWs
and the evolution of discharge symmetry. The study thus sheds light on the role
of weak magnetic fields in shaping plasma behavior and highlights the
importance of wave-particle interactions in magnetized CCPs.

</details>


### [33] [THz emission from multiple ionized plasma](https://arxiv.org/abs/2508.15462)
*Lucie Jurkovičová,David Štok,Caroline Juliano,Matyáš Staněk,Jaroslav Nejdl,Ondřej Hort*

Main category: physics.plasm-ph

TL;DR: Developed photocurrent model for high-intensity laser-gas THz generation that explains high conversion efficiency and achieved 0.2 mJ THz pulses with >1% efficiency.


<details>
  <summary>Details</summary>
Motivation: Need for high-energy THz pulses (μJ to mJ level) for nonlinear interaction studies, but current methods are limited by material damage thresholds and incomplete understanding of laser-gas interaction mechanisms.

Method: Established photocurrent model accounting for high-ionization states of target gas in laser-driven plasma THz generation at high-intensity regime.

Result: Model shows excellent agreement with experiments, explains spectral/temporal phenomena, and achieves 0.2 mJ THz pulses with conversion efficiency exceeding 1% using Ti:sapphire laser.

Conclusion: The photocurrent model successfully explains high conversion efficiency in laser-gas THz generation and enables production of high-energy THz pulses needed for nonlinear interaction studies.

Abstract: Studies employing nonlinear interactions of THz pulses are nowadays a
promising scientific research field. To capture these phenomena, THz pulses
with energy ranging from hundreds of \muJ to the mJ level are necessary.
However, techniques that provide pulses with such energy levels are still not
widely established. Upscaling methods of laser-solid interaction is limited by
the damage threshold of materials, while the mechanism of THz generation from
high intensity laser-gas interactions is not fully understood yet. Here, we
establish the photocurrent model of laser-driven plasma THz generation in the
high-intensity regime by accounting for high-ionization states of the target
gas. Our model shows excellent agreement with experimental observations,
provides a clear explanation of phenomena in both spectral and temporal
domains, and explains the high conversion efficiency from laser to THz. In the
experiments, we achieved a generation of 0.2 mJ THz pulses, driven by a
Ti:sapphire laser with a conversion efficiency exceeding 1 %.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [34] [Matrix-Weighted Campanato Spaces: Duality and Calderón--Zygmund Operators](https://arxiv.org/abs/2508.15195)
*Yiqun Chen,Dachun Yang,Wen Yuan*

Main category: math.FA

TL;DR: This paper introduces matrix-weighted Campanato spaces and establishes their duality with matrix-weighted Hardy spaces, providing equivalent characterizations and boundedness conditions for Calderón-Zygmund operators.


<details>
  <summary>Details</summary>
Motivation: To extend the theory of weighted function spaces to the matrix-weighted setting and establish duality relationships between matrix-weighted Hardy spaces and Campanato spaces.

Method: Using reducing operators of matrix weights to define matrix-weighted Campanato spaces, applying atomic and finite atomic characterizations of matrix-weighted Hardy spaces, and analyzing boundedness of Calderón-Zygmund operators.

Result: Proved that the dual space of matrix-weighted Hardy space H^p_W is precisely the matrix-weighted Campanato space L_{p,q,s,W} for p in (0,1], and obtained necessary and sufficient conditions for boundedness of Calderón-Zygmund operators on these spaces.

Conclusion: The paper successfully establishes the duality between matrix-weighted Hardy and Campanato spaces and provides complete characterizations of boundedness for Calderón-Zygmund operators in this matrix-weighted framework.

Abstract: Let $p\in(0,\infty)$, $q\in[1,\infty)$, $s\in\mathbb Z_+$, and $W$ be an
$A_p$-matrix weight, which in the scalar case is exactly a Muckenhoupt
$A_{\max\{1,p\}}$ weight. In this article, by using the reducing operators of
$W$, we introduce matrix-weighted Campanato spaces $\mathcal L_{p,q,s,W}$. When
$p\in(0,1]$, applying the atomic and the finite atomic characterizations of the
matrix-weighted Hardy space $H^p_W$, we prove that the dual space of $H^p_W$ is
precisely $\mathcal L_{p,q,s,W}$, which further induces several equivalent
characterizations of $\mathcal L_{p,q,s,W}$. In addition, we obtain a necessary
and sufficient condition for the boundedness of modified Calder\'on--Zygmund
operators on $\mathcal L_{p,q,s,W}$ with $p\in(0,\infty)$, which, combined with
the duality, further gives a necessary and sufficient condition for the
boundedness of Calder\'on--Zygmund operators on $H^p_W$ with $p\in(0,1]$.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [35] [Interface fluctuations for $1$D stochastic Allen-Cahn equation -- singular regime](https://arxiv.org/abs/2508.15319)
*Weijun Xu,Shuhan Zhou*

Main category: math.PR

TL;DR: Analysis of 1D stochastic Allen-Cahn equation with half-derivative white noise, showing interface fluctuations behave like classical results despite singular regime, with cancellation of infinite quantities enabling valid SDE derivation.


<details>
  <summary>Details</summary>
Motivation: To understand interface fluctuations in singular stochastic PDEs where the noise makes solutions distribution-valued, extending classical Allen-Cahn interface results to this more challenging regime.

Method: Study the 1D stochastic Allen-Cahn equation perturbed by half spatial derivative of spacetime white noise, using renormalization techniques and long time scaling analysis for initial data near traveling wave solutions.

Result: For sufficiently small noise, solutions stay close to traveling wave family and interface location follows approximate diffusion process. Two infinite quantities (from noise singularity and renormalization) cancel each other, enabling valid SDE derivation in the limit.

Conclusion: Classical interface fluctuation results extend to singular stochastic Allen-Cahn regime through miraculous cancellation of divergent terms, allowing rigorous derivation of interface SDE despite distribution-valued solutions.

Abstract: We study interface fluctuations for the $1$D stochastic Allen-Cahn equation
perturbed by half a spatial derivative of the spacetime white noise. This half
derivative makes the solution distribution-valued, so that proper
renormalization is needed to make sense of the solution.
  We show that if the noise is sufficiently small, then an analogue of the
classical results by \cite{Fun95,BBDMP98} holds in this singular regime. More
precisely, for initial data close to the traveling wave solution of the
deterministic equation, under proper long time scaling, the solution still
stays close to the family of traveling waves, and the interface location moves
according to an approximate diffusion process. There is one interesting
difference between our singular regime and the classical situation: even if the
solution and its approximate phase separation point are both well defined, the
intended diffusion describing the movement of the canonical candidate of the
phase point is not (even for fixed $\eps$). Two infinite quantities arise from
the derivation of such an SDE, one due to singularity of the noise, and the
other from renormalization. Magically, it turns out that they cancel out each
other, thus making the derivation of the interface SDE valid in the $\eps
\rightarrow 0$ limit.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [36] [Trotter-based quantum algorithm for solving transport equations with exponentially fewer time-steps](https://arxiv.org/abs/2508.15691)
*Julien Zylberman,Thibault Fredon,Nuno F. Loureiro,Fabrice Debbasch*

Main category: quant-ph

TL;DR: Quantum algorithm for simulating transport PDEs using state preparation, evolution with finite differences and Trotterization, and measurement, showing improved efficiency with vector-norm analysis.


<details>
  <summary>Details</summary>
Motivation: To address the open question of whether quantum computers can efficiently simulate physical phenomena governed by PDEs, specifically focusing on the fundamental multidimensional transport equation with variable coefficients.

Method: Three-step quantum numerical scheme: quantum state preparation, evolution combining high-order centered finite difference with time-splitting using product formula approximations (Trotterization), and measurement of observables with novel vector-norm error analysis.

Result: Vector-norm analysis provides similar accuracy with exponentially fewer time steps than operator-norm approaches, reducing computational resources. Efficient quantum circuits and numerical simulations confirm the scaling, with real hardware results for 1D convection and nonlinear ODE solutions.

Conclusion: Provides a practical framework for efficient quantum simulation of transport phenomena with applications in plasma physics, gas dynamics, and chaotic systems, demonstrating significant computational advantages over classical approaches.

Abstract: The extent to which quantum computers can simulate physical phenomena and
solve the partial differential equations (PDEs) that govern them remains a
central open question. In this work, one of the most fundamental PDEs is
addressed: the multidimensional transport equation with space- and
time-dependent coefficients. We present a quantum numerical scheme based on
three steps: quantum state preparation, evolution, and measurement of relevant
observables. The evolution step combines a high-order centered finite
difference with a time-splitting scheme based on product formula
approximations, also known as Trotterization. Novel numerical analysis is
introduced to bound the different sources of error and we prove that, for the
product formula approximations, vector norm analysis guarantees similar
accuracy with exponentially fewer time steps than operator-norm-based
approaches, thereby significantly reducing the projected computational
resources. We also present efficient quantum circuits and numerical simulations
that confirm the predicted vector-norm scaling. We report results on real
quantum hardware for the one-dimensional convection equation, and solve a
non-linear ordinary differential equation via its associated Liouville
equation, a particular case of transport equations. This work provides a
practical framework for efficiently simulating transport phenomena on quantum
computers, with potential applications in plasma physics, molecular gas
dynamics and non-linear dynamical systems, including chaotic systems.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [37] [Future Stability of Tilted Two-Fluid Bianchi I Spacetimes](https://arxiv.org/abs/2508.15155)
*Grigorios Fournodavlos,Elliot Marshall,Todd A. Oliynyk*

Main category: gr-qc

TL;DR: Nonlinear stability analysis of tilted two-fluid Bianchi I solutions in Einstein-Euler equations with cosmological constant and specific equation of state parameters.


<details>
  <summary>Details</summary>
Motivation: To establish future stability of cosmological solutions involving multiple fluids with tilted velocities in Bianchi I spacetimes, which is important for understanding the long-term behavior of anisotropic universe models.

Method: Analysis of Einstein-Euler equations with positive cosmological constant, using tilted two-fluid Bianchi I solutions with linear equations of state p = Kρ where 1/3 < K < 5/7.

Result: Demonstrated nonlinear stability to the future for these tilted two-fluid Bianchi I solutions.

Conclusion: The tilted two-fluid Bianchi I cosmological models remain stable in the future evolution when the equation of state parameters satisfy the specified range, providing important insights into anisotropic universe stability.

Abstract: We establish the nonlinear stability to the future of tilted two-fluid
Bianchi I solutions to the Einstein-Euler equations with positive cosmological
constant and linear equations of state
$p_{(\mathfrak{a})}=K_{(\mathfrak{a})}\rho_{(\mathfrak{a})}$,
$\mathfrak{a}\in\{1,2\}$, where $\frac{1}{3}<K_{(\mathfrak{a})}<\frac{5}{7}$.

</details>


### [38] [Future stability of solutions of the Einstein-nonlinear scalar field system with decelerated expansion](https://arxiv.org/abs/2508.15303)
*Louie Bernhardt*

Main category: gr-qc

TL;DR: Future stability of FLRW spacetimes with exponential scalar field potential is proven for decelerated expansion parameters p in (2/3,1), showing geodesic completeness and convergence to homogeneity.


<details>
  <summary>Details</summary>
Motivation: To establish mathematical stability of cosmological solutions to Einstein equations with nonlinear scalar fields, particularly FLRW spacetimes with exponential potentials that undergo decelerated expansion.

Method: Decompose metric and scalar field perturbations into spatial averages and oscillatory remainders with zero average. Analyze initial data sufficiently close to FLRW data and prove future-causal geodesic completeness.

Result: For each p in (2/3,1), the corresponding FLRW spacetime is future-stable. Perturbed solutions remain close to FLRW, are geodesically complete, and metric/scalar field components converge to spatially homogeneous functions as t→∞.

Conclusion: FLRW spacetimes with exponential scalar field potential and decelerated expansion are mathematically stable against small perturbations, providing rigorous foundation for such cosmological models.

Abstract: We study solutions to the Einstein equations coupled to a nonlinear scalar
field with exponential potential. This system admits
Friedmann-Lema\^itre-Robertson-Walker solutions undergoing decelerated
expansion, with $\mathbb{T}^3$ spatial topology and scale factor $a(t) = t^p$
for $1/3 < p < 1$. For each $p \in (2/3,1)$, we prove that the corresponding
FLRW spacetime is future-stable as a solution to the Einstein-nonlinear scalar
field system. Given initial data on a spacelike hypersurface that is
sufficiently close to the FLRW data, we show the resulting solution is
future-causal geodesically complete, and remains close to the FLRW solution for
all time. Moreover, we show the perturbed metric components and scalar field
converge to spatially homogeneous functions as $t \rightarrow \infty$. A key
feature of our analysis is the decomposition of the metric and scalar field
perturbations into their spatial averages and oscillatory remainders with zero
average.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [39] [Relative periodic solutions in spatial Kepler problem with symmetric perturbation](https://arxiv.org/abs/2508.15209)
*Xijun Hu,Zhiwen Qiao,Guowei Yu*

Main category: math.DS

TL;DR: Existence of infinitely many relative periodic solutions and a unique z-symmetric brake orbit in perturbed spatial Kepler problem with rotational and reflection symmetries


<details>
  <summary>Details</summary>
Motivation: Study spatial Kepler problem under perturbations with rotational symmetry and reflection symmetry about a plane perpendicular to the rotational axis

Method: Apply recent results from CHHL23 combined with Franks Theorem to prove existence of solutions under small perturbations and technical conditions

Result: Proved existence of infinitely many relative periodic solutions in compact energy surfaces, and a unique z-symmetric brake orbit forming a hopf link with plane relative periodic solutions

Conclusion: Results apply to satellite motion around ellipsoid with uniform mass distribution and n-pyramidal problem with specific mass configurations

Abstract: We study the spatial Kepler problem under a perturbation satisfying both
rotational symmetry and reflection symmetry with respect to a plane
perpendicular to the rotational axis. By applying recent results from
\cite{CHHL23} combined with Franks Theorem, we prove the existence of
infinitely many relative periodic solutions contained in compact energy surface
when the perturbation is sufficiently small and certain technical conditions
hold. In addition, we also demonstrate the existence of a unique $z$-symmetric
brake orbit which forms a hopf link with a plane relative periodic solutions
contained in compact energy surface only requires the perturbation sufficiently
small. Our results apply to the motion of a satellite around an ellipsoid with
uniform mass distribution and to the $n$-pyramidal problem with one point mass
moving along $z$-axis and other $n$ equal masses forming a regular $n$-gon
perpendicular to the $z$-axis at all times.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [40] [Generative Neural Operators of Log-Complexity Can Simultaneously Solve Infinitely Many Convex Programs](https://arxiv.org/abs/2508.14995)
*Anastasis Kratsios,Ariel Neufeld,Philipp Schmocker*

Main category: cs.LG

TL;DR: This paper bridges the theory-practice gap for neural operators by showing that generative equilibrium operators (GEOs) can approximate solutions to convex optimization problems with logarithmic parameter growth in error, contrary to worst-case theoretical bounds.


<details>
  <summary>Details</summary>
Motivation: There's a significant disconnect between theoretical worst-case parameter bounds for neural operators (suggesting unrealistically large parameter requirements) and experimental evidence showing their practical effectiveness. This paper aims to resolve this contradiction.

Method: The authors use generative equilibrium operators (GEOs) with finite-dimensional deep equilibrium layers to solve families of convex optimization problems over separable Hilbert spaces. Inputs are smooth convex loss functions, outputs are approximate solutions.

Result: When input losses lie in suitable infinite-dimensional compact sets, GEOs can uniformly approximate solutions with arbitrary precision, requiring only logarithmic growth in rank, depth, and width relative to approximation error. Validated on nonlinear PDEs, stochastic optimal control, and financial hedging problems.

Conclusion: The paper successfully closes the theory-practice gap for a specific class of neural operators, demonstrating that realistic finite-dimensional architectures can achieve strong approximation results with efficient parameter scaling, making neural operators more theoretically grounded and practically viable.

Abstract: Neural operators (NOs) are a class of deep learning models designed to
simultaneously solve infinitely many related problems by casting them into an
infinite-dimensional space, whereon these NOs operate. A significant gap
remains between theory and practice: worst-case parameter bounds from universal
approximation theorems suggest that NOs may require an unrealistically large
number of parameters to solve most operator learning problems, which stands in
direct opposition to a slew of experimental evidence. This paper closes that
gap for a specific class of {NOs}, generative {equilibrium operators} (GEOs),
using (realistic) finite-dimensional deep equilibrium layers, when solving
families of convex optimization problems over a separable Hilbert space $X$.
Here, the inputs are smooth, convex loss functions on $X$, and outputs are the
associated (approximate) solutions to the optimization problem defined by each
input loss.
  We show that when the input losses lie in suitable infinite-dimensional
compact sets, our GEO can uniformly approximate the corresponding solutions to
arbitrary precision, with rank, depth, and width growing only logarithmically
in the reciprocal of the approximation error. We then validate both our
theoretical results and the trainability of GEOs on three applications: (1)
nonlinear PDEs, (2) stochastic optimal control problems, and (3) hedging
problems in mathematical finance under liquidity constraints.

</details>


### [41] [Hybrid Least Squares/Gradient Descent Methods for DeepONets](https://arxiv.org/abs/2508.15394)
*Jun Choi,Chang-Ock Lee,Minam Moon*

Main category: cs.LG

TL;DR: Hybrid least squares/gradient descent method to accelerate DeepONet training by decomposing large linear system into smaller subproblems for branch and trunk networks.


<details>
  <summary>Details</summary>
Motivation: DeepONet training can be accelerated by leveraging the linear relationship between output and last layer parameters, but direct least squares solution is computationally infeasible due to large system size.

Method: Decompose the prohibitively large least squares system into two smaller subproblems for branch and trunk networks separately, and solve them with regularization support for unsupervised physics-informed learning.

Result: Efficient training method that handles the computational challenge of large linear systems while maintaining the mathematical structure of DeepONet optimization.

Conclusion: The proposed hybrid approach enables practical DeepONet training by breaking down the computationally intensive least squares problem into manageable components while supporting various loss formulations including physics-informed cases.

Abstract: We propose an efficient hybrid least squares/gradient descent method to
accelerate DeepONet training. Since the output of DeepONet can be viewed as
linear with respect to the last layer parameters of the branch network, these
parameters can be optimized using a least squares (LS) solve, and the remaining
hidden layer parameters are updated by means of gradient descent form. However,
building the LS system for all possible combinations of branch and trunk inputs
yields a prohibitively large linear problem that is infeasible to solve
directly. To address this issue, our method decomposes the large LS system into
two smaller, more manageable subproblems $\unicode{x2014}$ one for the branch
network and one for the trunk network $\unicode{x2014}$ and solves them
separately. This method is generalized to a broader type of $L^2$ loss with a
regularization term for the last layer parameters, including the case of
unsupervised learning with physics-informed loss.

</details>
