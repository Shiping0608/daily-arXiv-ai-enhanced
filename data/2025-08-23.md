<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 11]
- [math.AP](#math.AP) [Total: 15]
- [physics.comp-ph](#physics.comp-ph) [Total: 5]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 2]
- [math.PR](#math.PR) [Total: 1]
- [gr-qc](#gr-qc) [Total: 2]
- [math.DS](#math.DS) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [math.FA](#math.FA) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Semi-discrete Active Flux as a Petrov-Galerkin method](https://arxiv.org/abs/2508.15017)
*Wasilij Barsukow*

Main category: math.NA

TL;DR: Active Flux method bridges Finite Volume/DG and continuous Finite Element methods through variational formulation with biorthogonal test functions.


<details>
  <summary>Details</summary>
Motivation: To provide a rigorous mathematical foundation for the Active Flux method by deriving it from a variational formulation, clarifying its position between discontinuous and continuous numerical approaches.

Method: Developed a variational formulation using biorthogonal test functions on Cartesian meshes to obtain the semi-discrete Active Flux method, emphasizing its intermediate nature between DG and CG methods.

Result: Successfully derived the Active Flux method from a variational framework, demonstrating that it combines ideas from both discontinuous (DG) and continuous (CG) finite element methods through specific test function choices.

Conclusion: The Active Flux method represents a hybrid approach that bridges discontinuous and continuous numerical methods, with the variational formulation providing mathematical justification for its intermediate position between DG and CG methods.

Abstract: Active Flux (AF) is a recent numerical method for hyperbolic conservation
laws, whose degrees of freedom are averages/moments and (shared) point values
at cell interfaces. It has been noted previously in a heuristic fashion that it
thus combines ideas from Finite Volume/Discontinuous Galerkin (DG) methods with
a continuous approximation common in continuous Finite Element (CG) methods.
This work shows that the semi-discrete Active Flux method on Cartesian meshes
can be obtained from a variational formulation through a particular choice of
(biorthogonal) test functions. These latter being discontinuous, the new
formulation emphasizes the intermediate nature of AF between DG and CG.

</details>


### [2] [Error Estimation for Adaptive Mesh Refinement in Droplet Simulations](https://arxiv.org/abs/2508.15081)
*Darsh Nathawani,Matthew Knepley*

Main category: math.NA

TL;DR: A 1D shear force driven droplet formation model with flux-based error estimation using asymptotic expansion and front-tracking method, discretized with Galerkin FEM in mixed form to handle discontinuous gradient jumps during pinch-off.


<details>
  <summary>Details</summary>
Motivation: To accurately simulate droplet interface formation under shear forces, addressing the challenge of discontinuous solution gradients and erroneous curvature calculations during the highly convective pinch-off process.

Method: Derived using asymptotic expansion and front-tracking method for interface simulation, discretized with Galerkin finite element method in mixed form, with adaptive mesh refinement driven by flux-based error estimation.

Result: The mixed form provides smooth interface gradients for accurate error estimation, enabling adaptive mesh refinement to capture the droplet interface accurately during pinch-off.

Conclusion: The proposed model with flux-based error estimation and adaptive mesh refinement effectively addresses gradient discontinuity issues in shear force driven droplet formation simulations, ensuring accurate interface tracking and curvature computation.

Abstract: We present a one-dimensional shear force driven droplet formation model with
a flux-based error estimation. The presented model is derived using asymptotic
expansion and a front-tracking method to simulate the droplet interface. The
model is then discretized using the Galerkin finite element method in the mixed
form. However, the jumps in the solution gradients are discontinuous and can
grow faster due to the highly convective pinch-off process. This leads to an
erroneous droplet interface and incorrect curvature. Therefore, the mesh must
be sufficiently refined to capture the interface accurately. The mixed form of
the governing equation naturally provides smooth interface gradients that can
be used to compute the error estimate. The computed error estimate is then used
to drive the adaptive mesh refinement algorithm.

</details>


### [3] [A Note on the Convergence of Symmetric Triangle Quadrature Rules](https://arxiv.org/abs/2508.15133)
*Brian A. Freno,Neil R. Matula,Joseph E. Bishop*

Main category: math.NA

TL;DR: Symmetric triangle quadrature rules with even-degree polynomial integration capability achieve higher convergence rates (p=d+2) than conventional expectation (p=d+1), reducing quadrature points needed for finite-element problems.


<details>
  <summary>Details</summary>
Motivation: To optimize the balance between integration accuracy and computational cost in finite-element problems, particularly for smooth integrands that are not finite-degree polynomials.

Method: Analysis of symmetric triangle quadrature rules, discussion of error implications for 1D and triangular quadrature, and numerical validation on regular mesh sequences.

Result: Quadrature rules that exactly integrate polynomials up to even degree d achieve O(h^{d+2}) convergence instead of the expected O(h^{d+1}), allowing fewer quadrature points for the same accuracy.

Conclusion: Using symmetric triangle quadrature rules with even maximum degrees provides computational savings, especially beneficial for global integral operators that yield dense matrices in finite-element problems.

Abstract: Symmetric polynomial quadrature rules for triangles are commonly used to
efficiently integrate two-dimensional domains in finite-element-type problems.
While the development of such rules focuses on the maximum degree a given
number of points can exactly integrate, smooth integrands are generally not
polynomials of finite degree. Therefore, for such integrands, one needs to
balance integration accuracy and computational cost. A natural approach to this
balance is to choose the number of points such that the convergence rate with
respect to the mesh size $h$ matches that of the other properties of the
scheme, such as the planar or curved triangles that approximate the geometry or
the basis functions that approximate the solution.
  In general, it is expected that a quadrature rule capable of integrating
polynomials up to degree $d$ yields an integration error that is
$\mathcal{O}(h^p)$, where $p=d+1$. However, as we describe in this paper, for
symmetric triangle quadrature rules, when $d$ is even, $p=d+2$; therefore, for
a $p^\text{th}$-order-accurate quadrature rule, fewer quadrature points are
necessary, reducing the time required for matrix assembly in
finite-element-type problems. This reduction in cost is modest for local
differential operators that yield sparse matrices but appreciable for global
integral operators that yield dense matrices.
  In this paper, we briefly summarize the details of symmetric triangle
quadrature rules, discuss error implications for quadrature rules for one
dimension and triangles, and we provide numerical examples that support our
observation that polynomials that exactly integrate even maximum degrees
converge faster than the conventional expectation for sequences of regular
meshes.

</details>


### [4] [Reduced basis solvers for unfitted methods on parameterized domains](https://arxiv.org/abs/2508.15320)
*Nicholas Mueller,Santiago Badia,Yiran Zhao*

Main category: math.NA

TL;DR: A unified framework combining unfitted finite element methods with reduced basis techniques for parametrized PDEs on parameter-dependent domains, using deformation mapping and localization for efficient model reduction.


<details>
  <summary>Details</summary>
Motivation: To enable efficient and accurate model reduction for parametrized PDEs on general geometries with parameter-dependent domains, addressing the challenge of geometric variability with fixed-dimensional snapshot representations.

Method: Combines unfitted finite element methods with classical and tensor-based reduced basis techniques (particularly tensor-train method). Uses deformation-based strategy to map reference configuration to parameterized domains, and introduces localization procedure for constructing reduced subspaces and hyper-reduction approximations via matrix discrete empirical interpolation.

Result: Numerical experiments on 2D and 3D problems (Poisson, linear elasticity, incompressible Stokes and Navier-Stokes equations) demonstrate the framework's flexibility, accuracy and efficiency. The supremizer enrichment strategy is successfully adapted to unfitted methods and deformed configurations.

Conclusion: The proposed framework provides an effective approach for reduced basis approximations on parameter-dependent domains, with demonstrated stability and performance across various PDE types and dimensions.

Abstract: In this paper, we present a unified framework for reduced basis
approximations of parametrized partial differential equations defined on
parameter-dependent domains. Our approach combines unfitted finite element
methods with both classical and tensor-based reduced basis techniques --
particularly the tensor-train reduced basis method -- to enable efficient and
accurate model reduction on general geometries. To address the challenge of
reconciling geometric variability with fixed-dimensional snapshot
representations, we adopt a deformation-based strategy that maps a reference
configuration to each parameterized domain. Furthermore, we introduce a
localization procedure to construct dictionaries of reduced subspaces and
hyper-reduction approximations, which are obtained via matrix discrete
empirical interpolation in our work. We extend the proposed framework to
saddle-point problems by adapting the supremizer enrichment strategy to
unfitted methods and deformed configurations, demonstrating that the supremizer
operator can be defined on the reference configuration without loss of
stability. Numerical experiments on two- and three-dimensional problems --
including Poisson, linear elasticity, incompressible Stokes and Navier-Stokes
equations -- demonstrate the flexibility, accuracy and efficiency of the
proposed methodology.

</details>


### [5] [Eig-PIELM: A Mesh-Free Approach for Efficient Eigen-Analysis with Physics-Informed Extreme Learning Machines](https://arxiv.org/abs/2508.15343)
*Rishi Mishra,Smriti,Ganapathy Krishnamurthi,Balaji Srinivasan,Sundararajan Natarajan*

Main category: math.NA

TL;DR: Eig-PIELM is a novel mesh-free framework that extends physics-informed extreme learning machines to efficiently solve linear eigenvalue problems in a single linear solve, eliminating penalty parameters and backpropagation while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient and accurate method for solving linear eigenvalue problems that avoids computational overhead from penalty parameters and backpropagation, particularly valuable for rapid frequency spectrum analysis in mechanical, acoustic, and electromechanical systems.

Method: Reformulates governing differential equations into a compact algebraic system solvable in one step, enforces boundary conditions exactly via algebraic projection onto boundary-admissible subspace, and preserves computational advantages of extreme learning machines while being mesh-free.

Result: The framework demonstrates robustness and accuracy across benchmark problems, yielding both eigenvalues and mode shapes simultaneously in a single linear solve.

Conclusion: Eig-PIELM's mesh-free nature, solution structure, and accuracy make it particularly valuable for parametric studies requiring rapid frequency spectrum analysis in various engineering systems.

Abstract: In this work, a novel Eig-PIELM framework is proposed that extends
physics-informed extreme learning machine for an efficient and accurate
solution of linear eigenvalue problems. The method reformulates the governing
differential equations into a compact algebraic system solvable in a single
step. Boundary conditions are enforced exactly via an algebraic projection onto
the boundary-admissible subspace, eliminating the computational overhead of
penalty parameters, and backpropagation while preserving the computational
advantages of extreme learning machines. The proposed framework is mesh-free
and yields both eigenvalues and mode shapes simultaneously in one linear solve.
The robustness and accuracy of the proposed framework is demonstrated through a
range of benchmark problems. We believe that the mesh-free nature, solution
structure and accuracy of Eig-PIELM makes it particularly valuable for
parametric studies in mechanical, acoustic, and electromechanical systems where
rapid frequency spectrum analysis is critical.

</details>


### [6] [Implementation of Milstein Schemes for Stochastic Delay-Differential Equations with Arbitrary Fixed Delays](https://arxiv.org/abs/2508.15365)
*Mitchell T. Griggs,Kevin Burrage,Pamela M. Burrage*

Main category: math.NA

TL;DR: Numerical methods for solving stochastic delay-differential equations with multiple fixed delays that don't align with uniform time meshes, using Euler-Maruyama and Milstein schemes with interpolation and augmented time meshes.


<details>
  <summary>Details</summary>
Motivation: Previous simulations of SDDE schemes were limited to divisible delays, but many real-world applications involve indivisible delays that don't align with uniform time grids, requiring new computational approaches.

Method: For order 1/2 convergence: fixed step size with linear interpolation for delayed values. For order 1 convergence: augmented time mesh with varying step sizes that includes all required time points, plus technique for simulating delayed iterated stochastic integrals.

Result: The developed methods successfully achieve the theoretical convergence orders (1/2 and 1) for both Euler-Maruyama and Milstein schemes in the general case of indivisible delays.

Conclusion: The paper provides practical numerical techniques for solving SDDEs with arbitrary fixed delays, overcoming previous limitations to divisible delays and enabling broader application of these mathematical models.

Abstract: This paper develops methods for numerically solving stochastic
delay-differential equations (SDDEs) with multiple fixed delays that do not
align with a uniform time mesh. We focus on numerical schemes of strong
convergence orders $1/2$ and $1$, such as the Euler--Maruyama and Milstein
schemes, respectively. Although numerical schemes for SDDEs with delays
$\tau_1,\ldots,\tau_K$ are theoretically established, their implementations
require evaluations at both present times such as $t_n$, and also at delayed
times such as $t_n-\tau_k$ and $t_n-\tau_l-\tau_k$. As a result, previous
simulations of these schemes have been largely restricted to the case of
divisible delays. We develop simulation techniques for the general case of
indivisible delays where delayed times such as $t_n-\tau_k$ are not restricted
to a uniform time mesh. To achieve order of convergence (OoC) $1/2$, we
implement the schemes with a fixed step size while using linear interpolation
to approximate delayed scheme values. To achieve OoC $1$, we construct an
augmented time mesh that includes all time points required to evaluate the
schemes, which necessitates using a varying step size. We also introduce a
technique to simulate delayed iterated stochastic integrals on the augmented
time mesh, by extending an established method from the divisible-delays
setting. We then confirm that the numerical schemes achieve their theoretical
convergence orders with computational examples.

</details>


### [7] [Numerical Analysis of Unsupervised Learning Approaches for Parameter Identification in PDEs](https://arxiv.org/abs/2508.15381)
*Siyu Cen,Bangti Jin,Qimeng Quan,Zhi Zhou*

Main category: math.NA

TL;DR: Survey of unsupervised learning methods for PDE parameter identification, focusing on diffusion coefficient problems, with error analysis framework using finite element methods and neural networks.


<details>
  <summary>Details</summary>
Motivation: To provide rigorous mathematical analysis and error bounds for unsupervised neural network approaches in PDE parameter identification problems, which have shown impressive empirical performance but lack theoretical foundations.

Method: Comprehensive survey and analysis framework using Galerkin finite element method, hybrid methods, and deep neural networks, with emphasis on conditional stability estimates for error analysis.

Result: Development of a general framework for deriving rigorous error bounds on discrete approximations obtained through various numerical methods for PDE parameter identification.

Conclusion: Conditional stability estimates play a crucial role in error analysis for PDE parameter identification using neural networks and traditional numerical methods, providing theoretical foundation for empirical successes.

Abstract: Identifying parameters in partial differential equations (PDEs) represents a
very broad class of applied inverse problems. In recent years, several
unsupervised learning approaches using (deep) neural networks have been
developed to solve PDE parameter identifications. These approaches employ
neural networks as ansatz functions to approximate the parameters and / or the
states, and have demonstrated impressive empirical performance. In this paper,
we provide a comprehensive survey on these unsupervised learning techniques on
one model problem, diffusion coefficient identification, from the classical
numerical analysis perspective, and outline a general framework for deriving
rigorous error bounds on the discrete approximations obtained using the
Galerkin finite element method, hybrid method and deep neural networks.
Throughout we highlight the crucial role of conditional stability estimates in
the error analysis.

</details>


### [8] [Conditional Stability and Numerical Reconstruction of a Parabolic Inverse Source Problem Using Carleman Estimates](https://arxiv.org/abs/2508.15406)
*Tianhao Hu,Xinchi Huang,Bangti Jin,Qimeng Quan,Zhi Zhou*

Main category: math.NA

TL;DR: New numerical method for recovering spatial source in parabolic equations from partial interior measurements with proven stability and error bounds.


<details>
  <summary>Details</summary>
Motivation: To develop an effective numerical approach for solving inverse source problems in parabolic equations with rigorous stability guarantees and error analysis.

Method: Uses Carleman estimates to establish conditional Lipschitz and Hölder stability, then implements conforming finite element approximations in both time and space with proven error bounds.

Result: Developed a numerical approach that successfully recovers spatially dependent sources from partial measurements, with theoretical stability guarantees and demonstrated effectiveness through numerical experiments.

Conclusion: The proposed method provides a rigorous and effective numerical framework for solving inverse source problems in parabolic equations with proven stability and convergence properties.

Abstract: In this work we develop a new numerical approach for recovering a spatially
dependent source component in a standard parabolic equation from partial
interior measurements. We establish novel conditional Lipschitz stability and
H\"{o}lder stability for the inverse problem with and without boundary
conditions, respectively, using suitable Carleman estimates. Then we propose a
numerical approach for solving the inverse problem using conforming finite
element approximations in both time and space. Moreover, by utilizing the
conditional stability estimates, we prove rigorous error bounds on the discrete
approximation. We present several numerical experiments to illustrate the
effectiveness of the approach.

</details>


### [9] [A Structure-Preserving Scheme for the Euler System with Potential Temperature Transport](https://arxiv.org/abs/2508.15416)
*K. R. Arun,Rahuldev Ghorai*

Main category: math.NA

TL;DR: An all-speed semi-implicit finite volume scheme for compressible Euler equations with potential temperature transport that is asymptotic preserving in low Mach limit and positivity preserving for density and temperature.


<details>
  <summary>Details</summary>
Motivation: The compressible Euler equations become stiff in low Mach number regimes, posing significant numerical challenges for atmospheric modeling applications.

Method: Developed a semi-implicit finite volume scheme that is asymptotic preserving (AP) in the low Mach limit and strictly positivity preserving for density and potential temperature.

Result: The scheme ensures stability and accuracy across broad Mach number ranges, from compressible to nearly incompressible regimes, with rigorous consistency proofs.

Conclusion: Numerical experiments confirm the method robustly captures complex flow features while preserving essential physical and mathematical structures of the atmospheric model.

Abstract: We consider the compressible Euler equations with potential temperature
transport, a system widely used in atmospheric modelling to describe adiabatic,
inviscid flows. In the low Mach number regime, the equations become stiff and
pose significant numerical challenges. We develop an all-speed, semi-implicit
finite volume scheme that is asymptotic preserving (AP) in the low Mach limit
and strictly positivity preserving for density and potential temperature. The
scheme ensures stability and accuracy across a broad range of Mach numbers,
from fully compressible to nearly incompressible regimes. We rigorously
establish consistency with both the compressible system and its incompressible,
density-dependent limit. Numerical experiments confirm that the method robustly
captures complex flow features while preserving the essential physical and
mathematical structures of the model.

</details>


### [10] [Exponential decay of the discrete energy for the wave-wave coupled system](https://arxiv.org/abs/2508.15514)
*Toni Sayah,Toufic El Arwadi*

Main category: math.NA

TL;DR: Numerical analysis of discrete energy decay in dissipative coupled wave systems using P1 FEM and implicit Euler scheme, showing linear convergence and exponential energy decay.


<details>
  <summary>Details</summary>
Motivation: To analyze the asymptotic behavior of discrete energy in dissipative coupled wave systems and establish numerical convergence properties.

Method: P1 finite element method for spatial discretization combined with implicit Euler scheme for time integration, with a priori error analysis and energy method.

Result: Numerical scheme exhibits linear convergence under extra regularity assumptions, and exponential decay of fully discrete energy is demonstrated for the first time.

Conclusion: The proposed numerical approach successfully captures the energy decay behavior of dissipative coupled wave systems with proven convergence properties.

Abstract: In this article, a numerical analysis of the asymptotic behavior of the
discrete energy associated to a dissipative coupled wave system is conducted.
The numerical approximation of the system is constructed using the P1 finite
element method for spatial discretization, combined with the implicit Euler
scheme for time integration. An a priori error analysis is established, showing
that, under extra regularity assumptions on the continuous solution, the
numerical scheme exhibits linear convergence. Then, for the first time in the
literature, the exponential decay of the fully discrete energy is shown using
the energy method.

</details>


### [11] [Weighted finite difference methods for the semiclassical nonlinear Schrödinger equation with multiphase oscillatory initial data](https://arxiv.org/abs/2508.15683)
*Yanyan Shi,Christian Lubich*

Main category: math.NA

TL;DR: Weighted finite difference methods for solving highly oscillatory dispersive evolution equations without needing prohibitively fine grids.


<details>
  <summary>Details</summary>
Motivation: Standard finite difference methods require extremely fine grids to resolve high-frequency oscillations in both space and time, which is computationally prohibitive for semiclassically scaled nonlinear Schrödinger equations with oscillatory initial data.

Method: Modified traditional finite difference methods with appropriate exponential weights, specifically proposing weighted leapfrog and weighted Crank-Nicolson methods that achieve second-order accuracy.

Result: The proposed methods achieve second-order accuracy without time steps and mesh sizes being restricted by the small semiclassical parameter, enabling efficient computation of highly oscillatory solutions.

Conclusion: Weighted finite difference methods provide an effective approach for numerically solving highly oscillatory dispersive evolution equations, overcoming the computational limitations of standard methods while maintaining accuracy.

Abstract: This paper introduces weighted finite difference methods for numerically
solving dispersive evolution equations with solutions that are highly
oscillatory in both space and time. We consider a semiclassically scaled cubic
nonlinear Schr\"odinger equation with highly oscillatory initial data, first in
the single-phase case and then in the general multiphase case. The proposed
methods do not need to resolve high-frequency oscillations in both space and
time by prohibitively fine grids as would be required by standard finite
difference methods. The approach taken here modifies traditional finite
difference methods by appropriate exponential weights. Specifically, we propose
the weighted leapfrog and weighted Crank--Nicolson methods, both of which
achieve second-order accuracy with time steps and mesh sizes that are not
restricted in magnitude by the small semiclassical parameter. Numerical
experiments illustrate the theoretical results.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [12] [Brezis-Nirenberg type problem for fractional sub-Laplacian on the Heisenberg group](https://arxiv.org/abs/2508.14990)
*Vikram Yallapa Naik,Gaurav Dwivedi*

Main category: math.AP

TL;DR: Existence of weak solutions for fractional sub-Laplace equations with critical Sobolev exponent in Heisenberg groups


<details>
  <summary>Details</summary>
Motivation: Extending the celebrated Brezis-Nirenberg problem to the context of fractional sub-Laplace equations on Heisenberg groups with critical Sobolev exponents

Method: Mathematical analysis of fractional sub-Laplace equations involving critical Sobolev exponents on bounded domains in Heisenberg groups with continuous boundaries

Result: Demonstrates the existence of weak solutions for the fractional sub-Laplace equation with critical exponent and positive parameter λ

Conclusion: Successfully establishes solution existence for this class of fractional PDEs, generalizing the Brezis-Nirenberg problem to the Heisenberg group setting

Abstract: In this paper, we show the existence of a weak solution for a fractional
sub-Laplace equation involving a term with the critical Sobolev exponent,
namely, \begin{align*} (-\Delta_\mathbb{H})^su - \lambda u &= |u|^{Q^*_s -2}u
\text{ in } \Omega,\\ u &= 0 \text{ in } \mathbb{H}^N \setminus \Omega,
\end{align*} where $\Omega \subseteq \mathbb{H}^N$ is bounded and has
continuous boundary, $(-\Delta_\mathbb{H})^s$ is the horizontal fractional
Laplacian, $s \in (0,1), \lambda > 0,$ and $Q^*_s=\frac{2Q}{Q-2s}$ is the
Sobolev critical exponent. This problem is motivated by the celebrated
Brezis-Nirenberg problem \cite{brezis1983positive}.

</details>


### [13] [Optimal Interference Signal for Masking an Acoustic Source](https://arxiv.org/abs/2508.15023)
*Hongyun Wang,Hong Zhou*

Main category: math.AP

TL;DR: A framework for designing interference signals to mask acoustic sources from detection in target regions, with analytical solutions for spherical cases and numerical methods for general 3D wave equations.


<details>
  <summary>Details</summary>
Motivation: To address acoustic privacy and signal obfuscation needs in environments where masking acoustic signatures is essential for security and stealth applications.

Method: Developed theoretical and computational framework using analytical quasi-steady periodic solutions for spherical symmetric cases, superposition methods, and efficient numerical solutions for general 3D wave equations with optimization of point-force deployments.

Result: Derived analytical solutions for canonical cases, demonstrated self-masking phenomenon, and developed optimization techniques for effective masking using interference signals near acoustic sources.

Conclusion: The framework provides effective acoustic masking solutions with applications in undersea communication security, vehicle stealth, and protection against acoustic surveillance.

Abstract: In an environment where acoustic privacy or deliberate signal obfuscation is
desired, it is necessary to mask the acoustic signature generated in essential
operations. We consider the problem of masking the effect of an acoustic source
in a target region where possible detection sensors are located. Masking is
achieved by placing interference signals near the acoustic source. We introduce
a theoretical and computational framework for designing such interference
signals with the goal of minimizing the residual amplitude in the target
region. For the three-dimensional (3D) forced wave equation with spherical
symmetry, we derive analytical quasi-steady periodic solutions for several
canonical cases. We examine the phenomenon of self-masking where an acoustic
source with certain spatial forcing profile masks itself from detection outside
its forcing footprint. We then use superposition of spherically symmetric
solutions to investigate masking in a given target region. We analyze and
optimize the performance of using one or two point-forces deployed near the
acoustic source for masking in the target region. For the general case where
the spatial forcing profile of the acoustic source lacks spherical symmetry, we
develop an efficient numerical method for solving the 3D wave equation.
Potential applications of this work include undersea acoustic communication
security, undersea vehicles stealth, and protection against acoustic
surveillance.

</details>


### [14] [Analysis of mean field games via Fokker-Planck-Kolmogorov equations: existence of equilibria](https://arxiv.org/abs/2508.15029)
*Stanislav V. Shaposhnikov,Dmitry V. Shatilovich*

Main category: math.AP

TL;DR: Existence proof for mean field games with unbounded coefficients using Fokker-Planck-Kolmogorov equations and superposition principle


<details>
  <summary>Details</summary>
Motivation: To address mean field games with unbounded coefficients where traditional methods may fail, requiring new analytical approaches

Method: Novel approach combining Fokker-Planck-Kolmogorov equations, Ambrosio-Figalli-Trevisan superposition principle, and Lyapunov function-based a priori estimates

Result: Successfully proved the existence of solutions for mean field games with unbounded coefficients

Conclusion: The proposed methodology provides a robust framework for analyzing mean field games with challenging coefficient structures, extending the applicability of mean field game theory

Abstract: We study mean field games with unbounded coefficients. The existence of a
solution is proved. We propose a new approach based on Fokker-Planck-Kolmogorov
equations, the Ambrosio-Figalli-Trevisan superposition principle and a priory
estimates with Lyapunov functions.

</details>


### [15] [On the Fermi-Dirac-type Fisher information](https://arxiv.org/abs/2508.15054)
*Yuzhe Zhu*

Main category: math.AP

TL;DR: The paper introduces a generalized Fisher information concept for Fermi-Dirac particles and shows it decreases along solutions of the Fermi-Dirac-Fokker-Planck equation under suitable initial data bounds.


<details>
  <summary>Details</summary>
Motivation: To develop mathematical tools for analyzing kinetic models of Fermi-Dirac particles that obey quantum exclusion principles, extending classical Fisher information concepts to quantum statistical systems.

Method: Introduces a generalized Fisher information tailored for Fermi-Dirac-Fokker-Planck equations via entropy dissipation identities, and analyzes its time evolution behavior under various conditions including initial data bounds.

Result: The generalized Fisher information decreases along solutions of the Fermi-Dirac-Fokker-Planck equation when initial data satisfies a suitable upper bound, but monotonicity fails without such bounds. The behavior is also studied for the heat equation and linear Landau-Fermi-Dirac equation.

Conclusion: The proposed generalized Fisher information provides a useful tool for analyzing Fermi-Dirac kinetic equations, with monotonicity properties that depend critically on initial data constraints, offering insights into quantum statistical systems with exclusion principles.

Abstract: We consider kinetic models for Fermi-Dirac-like particles obeying the
exclusion principle. A generalized notion of Fisher information, tailored to
kinetic equations of Fermi-Dirac-Fokker-Planck type, is introduced via the
associated entropy dissipation identity. We show that, subject to a suitable
upper bound on the initial data, this quantity decreases along solutions of the
Fermi-Dirac-Fokker-Planck equation, while monotonicity can fail in the absence
of such a bound. We also discuss the time evolution of this Fermi-Dirac-type
Fisher information for the heat equation and the linear-type Landau-Fermi-Dirac
equation with Maxwell molecules.

</details>


### [16] [Non-linear degenerate parabolic flow equations and a finer differential structure on Wasserstein spaces](https://arxiv.org/abs/2508.15140)
*Arthur Schichl*

Main category: math.AP

TL;DR: New differential structures on Wasserstein spaces for p>2 on Riemannian manifolds, with generalized flow equations and smooth solution construction via Average Flow Approximation Series.


<details>
  <summary>Details</summary>
Motivation: To develop finer differential structures on Wasserstein spaces beyond the classical framework, enabling more sophisticated analysis of measure-valued flows and extending the Central Limit Theorem.

Method: Define new differential structures using degenerate second order PDEs with measure-dependent coefficients, construct smooth solutions as uniform limits of Average Flow Approximation Series (Euler-scheme variant).

Result: Successfully constructed smooth solutions under weak assumptions, proved generalized Central Limit Theorem, and established uniqueness of smooth solutions under stronger assumptions.

Conclusion: The framework provides a refined differential structure for Wasserstein spaces that extends classical results and enables new analytical capabilities for measure-dependent flow equations.

Abstract: We define new differential structures on the Wasserstein spaces
$\mathcal{W}_p(M)$ for $p > 2$ and a general Riemannian manifold $(M,g)$. We
consider a very general and possibly degenerate second order partial
differential flow equation with measure dependent coefficients to expand the
notion of smooth curves and to ensure that the new differential structure is
finer than the classical one. Under weak assumptions, we explicitly construct
smooth solutions as uniform limits of Average Flow Approximation Series (a
variant of explicit Euler--scheme approximations) in $\mathcal{W}_p(M)$ and,
thus, prove a generalzed version of the Central Limit Theorem. Under slightly
stronger assumptions, we prove that smooth solutions of our newly introduced
flow--equation are unique.

</details>


### [17] [Multiple nodal solutions to a scalar field equation with double-power nonlinearity and zero mass at infinity](https://arxiv.org/abs/2508.15167)
*Mónica Clapp,Carlos Culebro*

Main category: math.AP

TL;DR: Existence of multiple sign-changing solutions for nonlinear elliptic equations in exterior domains with finite symmetries


<details>
  <summary>Details</summary>
Motivation: Study nonlinear elliptic equations in exterior domains with decaying potentials and mixed criticality nonlinearities, aiming to establish conditions for existence of prescribed numbers of sign-changing solutions

Method: Analysis of nonlinear elliptic equations with subcritical-at-infinity and supercritical-near-origin nonlinearities in exterior domains, using weak symmetry assumptions and variational methods

Result: Provides conditions guaranteeing existence of prescribed number of sign-changing solutions, particularly showing numerous examples in dimensions N≥4 where exterior domains with finite symmetries yield predetermined numbers of nodal solutions

Conclusion: The paper establishes theoretical framework for existence of multiple nodal solutions in exterior domains with finite symmetry properties, extending understanding of nonlinear elliptic equations with mixed criticality behavior

Abstract: We consider the nonlinear elliptic equation \begin{equation*} -\Delta u +
V(x)u = f(u), \qquad u\in D^{1,2}_0(\Omega), \end{equation*} in an exterior
domain $\Omega$ of $\mathbb{R}^N$, where $V$ is a scalar potential that decays
to zero at infinity and the nonlinearity $f$ is subcritical at infinity and
supercritical near the origin. Under weak symmetry assumptions, we provide
conditions that guarantee that this problem has a prescribed number of
sign-changing solutions. In particular, we show that in dimensions $N\geq 4$
there are numerous examples of exterior domains with finite symmetries in which
the problem has a predetermined number of nodal solutions.

</details>


### [18] [Constructing characteristic initial data for three dimensional compressible Euler equations](https://arxiv.org/abs/2508.15199)
*Yuxuan Wang,Sifan Yu,Pin Yu*

Main category: math.AP

TL;DR: Resolves characteristic initial data problem for 3D compressible Euler equations using acoustical geometry framework and vector field method


<details>
  <summary>Details</summary>
Motivation: Address an open problem analogous to Christodoulou's characteristic initial value formulation in general relativity, providing complete characteristic data construction for 3D compressible Euler system

Method: Uses acoustical geometry framework and vector field method to recursively determine all order derivatives of solutions along characteristic cones via transport equations and wave equations

Result: Proves that arbitrary smooth entropy function and angular velocity determine smooth initial data on characteristic cones, differing from previous intersecting-hypersurface and symmetric reduction approaches

Conclusion: Provides complete characteristic data construction for admissible hypersurfaces, introducing useful tools and novel aspects for studying long-time dynamics of compressible Euler flow

Abstract: This paper resolves the characteristic initial data problem for the
three-dimensional compressible Euler equations - an open problem analogous to
Christodoulou's characteristic initial value formulation for the vacuum
Einstein field equations in general relativity. Within the framework of
acoustical geometry, we prove that for any "initial cone" $C_0\subset
\mathcal{D}=[0,T]\times\mathbb{R}^3$ with initial data
$(\mathring{\rho},\mathring{v},\mathring{s})$ given at $S_{0,0}=C_0\cap
\Sigma_0$, arbitrary smooth entropy function and angular velocity determine
smooth initial data $(\rho,v,s)$ on $C_0$ that render $C_0$ characteristic.
Differing from the intersecting-hypersurface case by Speck-Yu [19] and the
symmetric reduction case by Lisibach [11], our vector field method recursively
determines all (including $0$-th) order derivatives of the solution along $C_0$
via transport equations and wave equations. This work provides a complete
characteristic data construction for admissible hypersurfaces in the 3D
compressible Euler system, introducing useful tools and providing novel aspects
for studies of the long-time dynamics of the compressible Euler flow.

</details>


### [19] [On the extremal functions of second order uncertainty principles: symmetry and symmetry breaking](https://arxiv.org/abs/2508.15221)
*Xiao-Ping Chen,Chun-Lei Tang*

Main category: math.AP

TL;DR: This paper disproves a conjecture about second order Hydrogen Uncertainty Principle symmetry for dimensions 2 and 3, showing symmetry breaking, and establishes sharp weighted second order inequalities with radial extremal functions.


<details>
  <summary>Details</summary>
Motivation: To investigate symmetry properties and symmetry breaking in the second order Hydrogen Uncertainty Principle, addressing a specific conjecture and extending previous work on sharp inequalities.

Method: Using suitable test functions to provide counterexamples for the conjecture, and mathematical analysis to derive sharp weighted second order Hydrogen Uncertainty Principles and prove radiality of extremal functions.

Result: Negative answer to the conjecture for N=2,3 dimensions showing symmetry breaking phenomenon, and establishment of a family of sharp weighted second order Hydrogen Uncertainty Principles with radial extremal functions.

Conclusion: The work demonstrates symmetry breaking in certain dimensions, provides sharp inequalities, and extends previous results by showing radial symmetry of extremal functions in the second order Hydrogen Uncertainty Principle framework.

Abstract: This paper focus on the symmetry and symmetry breaking about the second order
Hydrogen Uncertainty Principle. \emph{Firstly}, by choosing a suitable test
function, we give a negative answer to the conjecture presented by Cazacu,
Flynn and Lam in [\emph{J. Funct. Anal.} \textbf{283} (2022), Paper No. 109659,
37 pp] for $N\in\{2,3\}$, and emphasizing the symmetry breaking phenomenon.
\emph{Secondly}, we obtain a family of sharp weighted second order Hydrogen
Uncertainty Principle, and prove the extremal functions are radial, which
extends the work of Duong and Nguyen [The sharp second order
Caffareli-Kohn-Nirenberg inequality and stability estimates for the sharp
second order uncertainty principle, arXiv:2102.01425].

</details>


### [20] [Statistical conservation laws for scalar model problems: Hierarchical evolution equations](https://arxiv.org/abs/2508.15359)
*Qian Huang,Christian Rohde*

Main category: math.AP

TL;DR: New hierarchical evolution equations for probability density functions (PDFs) of scalar conservation laws with random initial data, developing multi-point and single-point derivative PDF frameworks.


<details>
  <summary>Details</summary>
Motivation: To represent and analyze the statistical properties of solutions to scalar conservation laws with random initial conditions through hierarchical PDF equations, similar to approaches used for Navier-Stokes equations.

Method: Developed two hierarchical frameworks: 1) multi-point PDF equations that capture statistical correlations across different spatial points, and 2) single-point higher-order derivative PDF equations that focus on local statistical properties.

Result: Created systematic hierarchical evolution equations that can represent the statistical behavior of scalar conservation laws with random initial data, providing mathematical structures that facilitate closure strategies.

Conclusion: The developed hierarchical PDF frameworks provide valuable tools for understanding and modeling statistical correlations in conservation laws with randomness, offering guidance for closure approaches in complex systems.

Abstract: The probability density functions (PDFs) for the solution of the
incompressible Navier-Stokes equation can be represented by a hierarchy of
linear equations. This article develops new hierarchical evolution equations
for PDFs of a scalar conservation law with random initial data as a model
problem. Two frameworks are developed, including multi-point PDFs and
single-point higher-order derivative PDFs. These hierarchies capture
statistical correlations and guide closure strategies.

</details>


### [21] [Coupled Vlasov and non-Newtonian fluid dynamics: existence and large-time behavior](https://arxiv.org/abs/2508.15460)
*Young-Pil Choi,Jinwook Jung,Aneta Wróblewska-Kamińska*

Main category: math.AP

TL;DR: Global existence of weak solutions for coupled kinetic-non-Newtonian fluid system with power-law exponent p > 8/5, and large-time decay of modulated energy functional under additional boundedness assumption.


<details>
  <summary>Details</summary>
Motivation: Study the interaction between particles governed by Vlasov equation and incompressible power-law fluid through drag force, analyzing existence and long-time behavior of solutions.

Method: Mathematical analysis of coupled kinetic-fluid system on periodic domain, proving global existence of weak solutions and establishing decay rates for modulated energy functional measuring velocity alignment deviation.

Result: Global weak solutions exist for all p > 8/5. Under uniform boundedness of particle density, modulated energy decays algebraically when p > 2 and exponentially when 6/5 ≤ p ≤ 2, showing fluid dissipation's role in dynamics.

Conclusion: The power-law exponent p significantly influences both existence and long-time behavior, with fluid dissipation driving different decay regimes based on p values.

Abstract: We study a coupled kinetic-non-Newtonian fluid system on the periodic domain
${\mathbb T}^3$, where particles evolve by a Vlasov equation and interact with
an incompressible power-law fluid through a drag force. We prove the global
existence of weak solutions for all $p > \frac{8}{5}$, where $p > 1$ denotes
the power-law exponent of the fluid's stress-strain relation. Under an
additional uniform boundedness assumption on the particle density, we also
establish large-time decay of a modulated energy functional measuring deviation
from velocity alignment. The decay rate is algebraic when $p > 2$ and
exponential when $\frac{6}{5} \le p \le 2$, reflecting the role of fluid
dissipation in the large-time dynamics.

</details>


### [22] [A potential theory approach to the capillarity-driven Hele-Shaw problem](https://arxiv.org/abs/2508.15491)
*Bogdan-Vasile Matioc,Christoph Walker*

Main category: math.AP

TL;DR: Potential theory framework for quasistationary fluid flows in bounded geometries, applied to 2D Hele-Shaw problem with surface tension, proving local well-posedness, parabolic smoothing, and exponential stability of stationary solutions.


<details>
  <summary>Details</summary>
Motivation: To develop a mathematical framework using potential theory for analyzing quasistationary fluid flows governed by elliptic equations with constant coefficients in bounded geometries.

Method: Applied potential theory to the two-dimensional Hele-Shaw problem with surface tension, derived local well-posedness and parabolic smoothing in optimal function spaces, and established a generalized principle of linearized stability for abstract quasilinear parabolic problems.

Result: Successfully demonstrated that potential theory provides a powerful framework for fluid flow analysis, proved local well-posedness and parabolic smoothing for Hele-Shaw problem, and showed exponential stability of stationary solutions.

Conclusion: Potential theory is an effective mathematical framework for analyzing quasistationary fluid flows, particularly for the Hele-Shaw problem, enabling rigorous proofs of well-posedness, smoothing properties, and stability of stationary solutions.

Abstract: In this paper, we demonstrate that potential theory provides a powerful
framework for analyzing quasistationary fluid flows in bounded geometries,
where the bulk dynamics are governed by elliptic equations with constant
coefficients. This approach is illustrated by the two-dimensional Hele-Shaw
problem with surface tension, for which we derive local well-posedness and
parabolic smoothing in (almost) optimal function spaces. In addition, we
establish a generalized principle of linearized stability for a particular
class of abstract quasilinear parabolic problems, which enables us to show that
the stationary solutions to the Hele-Shaw problem are exponentially stable.

</details>


### [23] [Well-posedness and Rayleigh-Taylor instability of the two-phase periodic quasistationary Stokes flow](https://arxiv.org/abs/2508.15502)
*Daniel Böhme,Bogdan-Vasile Matioc*

Main category: math.AP

TL;DR: Analysis of two-phase quasistationary Stokes flow with surface tension and gravity effects, focusing on interface evolution, well-posedness, and stability properties including Rayleigh-Taylor instability.


<details>
  <summary>Details</summary>
Motivation: To understand the mathematical properties and stability of two-phase fluid interfaces with different viscosities and densities under surface tension and gravity effects, which has applications in various physical and engineering contexts.

Method: Recast the mathematical model as a fully nonlinear nonlocal evolution equation for the interface function, then analyze well-posedness, parabolic smoothing, and study equilibrium solutions in subcritical Sobolev spaces.

Result: Established well-posedness and parabolic smoothing properties, demonstrated Rayleigh-Taylor instability of small finger-shaped equilibria, and showed that stability of flat interfaces depends on a specific parameter's sign.

Conclusion: The study provides rigorous mathematical analysis of two-phase Stokes flow interfaces, revealing important stability properties and instability mechanisms that depend on fluid properties and geometric configurations.

Abstract: We study the two-phase, horizontally periodic, quasistationary Stokes flow in
two dimensions driven by surface tension and gravity effects in the general
context of fluids with (possibly) different viscosities and densities. The
sharp interface which separates the fluids is assumed to be the graph of a
periodic function. The mathematical model is then recast as a fully nonlinear
and nonlocal evolution equation involving only the function parametrizing the
interface. Our main results include well-posedness and a parabolic smoothing
property, as well as a study of equilibrium solutions in subcritical Sobolev
spaces. In particular, we establish the Rayleigh-Taylor instability of small,
finger-shaped equilibria and prove that the stability properties of flat
interfaces depend on the sign of a certain parameter.

</details>


### [24] [Maz'ya-type bounds for sharp constants in fractional Poincaré-Sobolev inequalities](https://arxiv.org/abs/2508.15564)
*Francesco Bozzola,Matteo Talluri*

Main category: math.AP

TL;DR: Sharp estimates for fractional Poincaré-Sobolev inequalities in terms of nonlocal capacitary extension of inradius, with new Maz'ya-Poincaré inequality and fractional Poincaré-Wirtinger estimates.


<details>
  <summary>Details</summary>
Motivation: To extend previous local results by Maz'ya and Shubin to the fractional case, providing sharp constants and understanding the limiting behavior with respect to fractional order.

Method: Proves new Maz'ya-Poincaré inequality and fractional Poincaré-Wirtinger estimates, analyzing sharp limiting behaviors with respect to fractional differentiability order.

Result: Obtains sharp estimates for fractional Poincaré-Sobolev inequalities, new criterion for Sobolev space embedding in subcritical regime, and optimal characterization for fractional Cheeger's constant positivity.

Conclusion: The work provides comprehensive results for fractional inequalities with sharp constants, extending local theory to nonlocal setting and offering new embedding criteria and characterizations.

Abstract: We prove estimates for the sharp constants in fractional Poincar\'e-Sobolev
inequalities associated to an open set, in terms of a nonlocal capacitary
extension of its inradius. This work builds upon previous results obtained in
the local case by Maz'ya and Shubin and by the first author and Brasco. We rely
on a new Maz'ya-Poincar\'e inequality and, incidentally, we also prove new
fractional Poincar\'e-Wirtinger-type estimates. These inequalities display
sharp limiting behaviours with respect to the fractional order of
differentiability. As a byproduct, we obtain a new criterion for the embedding
of the homogeneous Sobolev space $\mathcal{D}^{s,p}_0(\Omega)$ in
$L^q(\Omega)$, valid in the subcritical regime and for $p \le q < p^*_s$. Our
results are new even for the first eigenvalue of the fractional Laplacian and
contain an optimal characterization for the positivity of the fractional
Cheeger's constant.

</details>


### [25] [Strichartz estimates for higher order Schrödinger equations with Partial regular initial data](https://arxiv.org/abs/2508.15670)
*Vishvesh Kumar,Shyam Swarup Mondal,Iswarya Sitiraju,Manli Song*

Main category: math.AP

TL;DR: Refined Strichartz estimates for higher-order Schrödinger equations with partially regular initial data, applied to nonlinear well-posedness and extended to Dunkl Schrödinger equations with new stationary phase method adaptation.


<details>
  <summary>Details</summary>
Motivation: To establish Strichartz estimates for Schrödinger equations where initial data only has regularity in a subset of spatial variables, rather than requiring full Sobolev regularity, and extend this analysis to the more complex Dunkl setting.

Method: Develop refined Strichartz estimates for partial regularity initial data, apply these to study nonlinear Schrödinger equations with power-type nonlinearities, and create a new adaptation of the stationary phase method specifically for Dunkl analysis to handle the extension to Dunkl Schrödinger equations.

Result: Successful establishment of Strichartz estimates under partial regularity conditions, demonstration of well-posedness for nonlinear Schrödinger equations, and extension of results to Dunkl Schrödinger equations with two distinct root systems despite the lack of existing stationary phase methods in this setting.

Conclusion: The paper provides significant advances in understanding Schrödinger equations with partially regular data and successfully extends the analysis to the challenging Dunkl framework by developing new mathematical tools, particularly an adapted stationary phase method for Dunkl analysis.

Abstract: In this paper, we establish refined Strichartz estimates for higher-order
Schr\"odinger equations with initial data exhibiting partial regularity. By
partial regularity, we mean that the initial data are not required to have full
Sobolev regularity but only regularity with respect to a subset of the spatial
variables. As an application of these estimates, we investigate the
well-posedness of nonlinear Schr\"odinger equations with power-type
nonlinearities. In addition, we extend our analysis to the Dunkl Schr\"odinger
equations under partial regularity, defined with respect to two distinct root
systems. This extension poses significant challenges, mainly due to the lack of
a suitable stationary phase method in the Dunkl setting. To overcome this
difficulty, we develop a new result that provides an adaptation of the
stationary phase method to the framework of Dunkl analysis.

</details>


### [26] [Existence of hyperbolic blow-up to the generalized quasi-geostrophic equation](https://arxiv.org/abs/2508.15708)
*Lucas C. F. Ferreira,Ricardo M. M. Guimarães*

Main category: math.AP

TL;DR: Analysis of blow-up behavior in generalized surface quasi-geostrophic equations with hyperbolic saddle geometry leading to singularity formation in Hölder spaces.


<details>
  <summary>Details</summary>
Motivation: To investigate singularity formation in the generalized surface quasi-geostrophic equation for the more singular parameter range β∈(1,2), extending previous work on classical SQG equations.

Method: Using a hyperbolic framework based on Córdoba's approach, assuming level sets contain hyperbolic saddles and imposing conditions at the origin to study geometric degeneration and collapse of opening angles.

Result: Proved existence of blow-up time T* with lower bound, showing collapse of saddle opening angle and blow-up of Hölder norm ∥θ(t)∥_C^σ for σ∈(0,β-1) as t→T*.

Conclusion: First rigorous proof of singularity formation (finite or infinite time) for smooth solutions to gSQG equation, demonstrating geometric degeneration leads to blow-up in Hölder spaces.

Abstract: In this work, we investigate the blow-up of solutions to the generalized
surface quasi-geostrophic (gSQG) equation in $\mathbb{R}^{2}$, within the more
singular range $\beta\in(1,2)$ for the coupling of the velocity field. This
behavior is studied under a hyperbolic setting based on the framework
originally introduced by C\'{o}rdoba (1998, Annals of Math. 148, 1135--52) for
the classical SQG equation. Assuming that the level sets of the solution
contains a hyperbolic saddle, and under suitable conditions on the solution at
the origin, we obtain the existence of a time
$T^{\ast}\in\mathbb{R}^{+}\cup\{\infty\}$ at which the opening angle of the
saddle collapses. Moreover, we derive a lower bound for the blow-up time
$T^\ast$. This geometric degeneration leads to the blow-up of the H\"{o}lder
norm $\Vert\theta(t)\Vert_{C^{\sigma}}$ as $t\rightarrow T^{\ast}$, for
$\sigma\in(0, \beta -1)$, showing the formation of singularity in the
H\"{o}lder space at time $T^{\ast}$. To the best of our knowledge, these are
the first results in the literature to rigorously prove the formation of a
singularity, whether in finite or infinite time, for a class of smooth
solutions to the gSQG equation.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [27] [GEN2: A Generative Prediction-Correction Framework for Long-time Emulations of Spatially-Resolved Climate Extremes](https://arxiv.org/abs/2508.15196)
*Mengze Wang,Benedikt Barthel Sorensen,Themistoklis Sapsis*

Main category: physics.comp-ph

TL;DR: GEN2 is a generative prediction-correction framework that combines Gaussian emulation with ML correction to efficiently forecast extreme climate event statistics across different emissions scenarios, enabling accurate extrapolation beyond training data distributions.


<details>
  <summary>Details</summary>
Motivation: Conventional Earth System Models are computationally expensive for generating large ensembles needed to quantify climate extreme risks across various emissions scenarios, requiring more efficient and accurate forecasting methods.

Method: Two-step framework: 1) Conditional Gaussian emulator for prediction, 2) Non-Gaussian machine learning correction trained on reference data and emulated fields nudged toward reference to ensure robustness to chaos.

Result: Validated on historical ERA5 data and demonstrated extrapolation capabilities on future climate scenarios. Model accurately predicts extreme event statistics in different scenarios when trained on single realization of one warming scenario.

Conclusion: GEN2 successfully enables efficient and accurate forecasting of climate extreme statistics, demonstrating strong extrapolation capabilities beyond training data distributions for various climate change scenarios.

Abstract: Accurately quantifying the increased risks of climate extremes requires
generating large ensembles of climate realization across a wide range of
emissions scenarios, which is computationally challenging for conventional
Earth System Models. We propose GEN2, a generative prediction-correction
framework for an efficient and accurate forecast of the extreme event
statistics. The prediction step is constructed as a conditional Gaussian
emulator, followed by a non-Gaussian machine-learning (ML) correction step. The
ML model is trained on pairs of the reference data and the emulated fields
nudged towards the reference, to ensure the training is robust to chaos. We
first validate the accuracy of our model on historical ERA5 data and then
demonstrate the extrapolation capabilities on various future climate change
scenarios. When trained on a single realization of one warming scenario, our
model accurately predicts the statistics of extreme events in different
scenarios, successfully extrapolating beyond the distribution of training data.

</details>


### [28] [Bridging the Analog and the Probabilistic Computing Divide: Configuring Oscillator Ising Machines as P-bit Engines](https://arxiv.org/abs/2508.15234)
*E. M. H. E. B. Ekanayake,Nikhat Khan,Nikhil Shukla*

Main category: physics.comp-ph

TL;DR: A framework for configuring Oscillator Ising Machines as p-bit engines using harmonic injection, creating synergies between two previously distinct approaches to combinatorial optimization.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between Oscillator Ising Machines and p-bit-based computing platforms, traditionally viewed as separate methods for solving complex combinatorial optimization problems.

Method: Using a novel interplay between first- and second harmonic injection to oscillators to enable OIMs to function as p-bit engines.

Result: Successfully demonstrated that OIMs can be configured as p-bit engines, identifying new synergies between the two methods and expanding application scope for OIMs.

Conclusion: The proposed harmonic injection approach enables OIMs to function as p-bit engines and can be extended to other analog dynamical systems like Dynamical Ising Machines, creating new computational possibilities.

Abstract: Oscillator Ising Machines (OIMs) and probabilistic bit (p-bit)-based
computing platforms have emerged as promising paradigms for tackling complex
combinatorial optimization problems. Although traditionally viewed as distinct
approaches, this work presents a theoretically grounded framework for
configuring OIMs as p-bit engines. We demonstrate that this functionality can
be enabled through a novel interplay between first- and second harmonic
injection to the oscillators. Our work identifies new synergies between the two
methods and broadens the scope of applications for OIMs. We further show that
the proposed approach can be applied to other analog dynamical systems, such as
the Dynamical Ising Machine.

</details>


### [29] [The CP2K Program Package Made Simple](https://arxiv.org/abs/2508.15559)
*Marcella Iannuzzi,Jan Wilhelm,Frederick Stein,Augustin Bussy,Hossam Elgabarty,Dorothea Golze,Anna Hehn,Maximilian Graml,Stepan Marek,Beliz Sertcan Gökmen,Christoph Schran,Harald Forbert,Rustam Z. Khaliullin,Anton Kozhevnikov,Mathieu Taillefumier,Rocco Meli,Vladimir Rybkin,Martin Brehm,Robert Schade,Ole Schütt,Johann V. Pototschnig,Hossein Mirhosseini,Andreas Knüpfer,Dominik Marx,Matthias Krack,Jürg Hutter,Thomas D. Kühne*

Main category: physics.comp-ph

TL;DR: CP2K is a versatile open-source software package for atomistic simulations across various systems including molecules, materials, interfaces, solids, glasses, and soft-matter systems.


<details>
  <summary>Details</summary>
Motivation: To provide a practical guide for using CP2K's capabilities in computing static and dynamical properties through quantum-mechanical and classical simulation methods.

Method: The paper focuses on practical usage and applications of CP2K, introducing theoretical concepts only as needed, rather than detailed theory and code implementation.

Result: The review highlights CP2K's versatility in simulating diverse atomistic systems and its ability to compute both static and dynamic properties.

Conclusion: CP2K serves as a comprehensive tool for atomistic simulations across multiple domains, with this paper providing practical guidance for users rather than theoretical foundations.

Abstract: CP2K is a versatile open-source software package for simulations across a
wide range of atomistic systems, from isolated molecules in the gas phase to
low-dimensional functional materials and interfaces, as well as highly
symmetric crystalline solids, disordered amorphous glasses, and weakly
interacting soft-matter systems in the liquid state and in solution. This
review highlights CP2K's capabilities for computing both static and dynamical
properties using quantum-mechanical and classical simulation methods. In
contrast to the accompanying theory and code paper [J. Chem. Phys. 152, 194103
(2020)], the focus here is on the practical usage and applications of CP2K,
with underlying theoretical concepts introduced only as needed.

</details>


### [30] [Investigating the sliding behavior of graphene nanoribbons](https://arxiv.org/abs/2508.15587)
*Gourav Yadav,Aningi Mokhalingam,Roger A. Sauer,Shakti S. Gupta*

Main category: physics.comp-ph

TL;DR: FE model studies graphene nanoribbon-substrate interaction, revealing critical strain thresholds and length parameters affecting sliding behavior and strain transfer.


<details>
  <summary>Details</summary>
Motivation: To understand interlayer interaction mechanics between graphene nanoribbons and graphene substrates, particularly how boundary conditions affect sliding behavior and strain transfer under biaxial deformations.

Method: Developed Euler-Bernoulli beam finite element model calibrated with molecular dynamics simulations using Kolmogorov and Crespi potential, focusing on boundary conditions and uniform biaxial substrate deformations.

Result: Identified critical strain threshold (ec) beyond which strain transfer decreases suddenly, critical GNR length (Lc ≈ 10 nm) for strain transfer, dissipative sliding length (Ld ≈ 10 nm), and edge pulling force saturation at GNR length ≥ 17 nm. Maximum transferable strain between 0.57%-1.15%. FE results match MD within ~10% error.

Conclusion: The FE model successfully captures graphene interlayer mechanics, revealing critical length and strain parameters that govern sliding behavior and strain transfer, with good agreement to MD simulations despite parameter and setup variations.

Abstract: This work presents a Euler-Bernoulli beam finite element (FE) model to study
the interlayer interaction mechanics of graphene nanoribbon (GNR) over a
graphene substrate. The FE model is calibrated using molecular dynamics (MD)
simulations employing the potential of Kolmogorov and Crespi. This study
focuses mainly on the effect of boundary conditions on sliding behavior and
strain transfer between layers when the substrate is subjected to uniform
biaxial deformations. The interlayer shearing or sliding behavior is found to
depend on the presence of critical parameters, namely, the applied strain to
the substrate and the length of the GNR. The FE results indicate that the
applied strain transferred from the substrate to the GNR varies linearly up to
a critical value ec beyond which it decreases suddenly. Further, ec is found to
appear beyond a critical GNR length, Le is approximately 10 nm. Furthermore, a
length parameter Ld is approximately 10 nm is computed, beyond which the
sliding of GNR is dissipative. Through FE simulations, it is also found that
for a GNR length is greater than or equal to 17 nm, the edge pulling force
saturates. Our results also highlight the importance of the inertia of GNR on
its sliding for different boundary conditions. It is also concluded that the
maximum strain that can be transferred to GNR lies between 0.57% and 1.15%. The
results of the FE approach align with MD simulations within an error of
approximately 10% that can be attributed to the choice of material parameters
and the simulation setup.

</details>


### [31] [Pseudo-spectral model of elastic-wave propagation through toothed-whale head anatomy, and implications for biosonar](https://arxiv.org/abs/2508.15739)
*Fawad Ali,Carlos García A.,Aida Hejazi-Nooghabi,Lapo Boschi*

Main category: physics.comp-ph

TL;DR: Toothed whales can localize sound sources on the median plane using head anatomy and reverberated sound waves, despite lacking pinnae, as demonstrated through 3D elastic wave modeling.


<details>
  <summary>Details</summary>
Motivation: Toothed whales have exceptional sound-localization capabilities without pinnae, and the specific anatomical features enabling this performance remain unclear despite detailed studies of their auditory pathways.

Method: Used pseudo-spectral time domain (PSTD) numerical scheme to model 3D elastic wave propagation through toothed-whale head anatomy based on CT scans, with high-resolution voxel grid. Validated the solver and tested with 45 kHz dolphin-like clicks at various elevation angles.

Result: The study found that incoming sound can be localized via correlation analysis of the reverberated portion of time-domain waveforms recorded at the tympano-periotic complex locations, enabling median plane source localization.

Conclusion: Toothed whales' head anatomy serves as an effective sound-localization mechanism that compensates for the absence of pinnae, allowing precise source localization through analysis of reverberated sound waves at the auditory complex.

Abstract: The sound-localization and, in particular, biosonar system of toothed whales
is exceptionally performant. How this is achieved is not clear, given that: (i)
toothed whales have no pinnae; (ii) while their auditory pathways have been
studied in detail, no specific feature apparently replacing the pinna has been
identified. In this study, we employ a pseudo-spectral time domain (PSTD)
numerical scheme to model three-dimensional elastic wave propagation through a
toothed-whale head including soft tissues. Computed tomography (CT) scans were
utilized to build a three-dimensional velocity-density model of the specimen's
head, parametrized on a high-resolution $1.11$ mm voxel grid. We first validate
our wave propagation solver, identifying a range of frequencies and spatial
scale lengths where the PSTD scheme captures the complexities of elastic wave
propagation through toothed-whale anatomy. We next focus on the toothed whale's
ability to locate sources on the median plane, where the role of anatomy is
crucial. A 45 kHz central frequency burst (dolphin-like click) was modeled and
directed at elevation angles from $-90^\circ$ to $+90^\circ$ in $5^\circ$ steps
along the midsagittal plane. We find that the incoming sound can be localized,
via correlation, from the reverberated portion of the time-domain waveforms
recorded at the tympano-periotic complex locations.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [32] [Simulation Studies of Resonant Excitation of Electron Bernstein Waves in Capacitive Discharges](https://arxiv.org/abs/2508.15269)
*Deepak Gautam,Sarveshwar Sharma,Igor Kaganovich,Bhooshan Paradkar*

Main category: physics.plasm-ph

TL;DR: Study of capacitive coupled plasma discharges in mildly magnetized regime showing asymmetric density profiles and electron Bernstein wave excitation, with detailed PIC-MCC simulations revealing transition behaviors.


<details>
  <summary>Details</summary>
Motivation: To understand the complex plasma dynamics in capacitive coupled plasma discharges under mildly magnetized conditions where RF fields interact with external magnetic fields, particularly investigating asymmetric density distributions and wave phenomena.

Method: Used particle-in-cell Monte Carlo collision (PIC-MCC) technique for detailed numerical simulations to capture kinetic behavior of electrons and ions, including collisionless effects and sheath dynamics.

Result: Observed asymmetric plasma density profiles and excitation of electron Bernstein waves along steep density gradients. Found that discharge transitions from symmetric to asymmetric and back to symmetric configuration with increasing magnetic field strength. EBW excitation strongly correlated with discharge asymmetry and localized density gradients.

Conclusion: Weak magnetic fields significantly shape plasma behavior in CCP discharges, with electron Bernstein waves playing crucial role in energy transport and electron heating under mildly magnetized conditions, highlighting importance of wave-particle interactions.

Abstract: The behavior of capacitive coupled plasma (CCP) discharges is investigated in
a mildly magnetized regime, defined by the condition 1 $\leq$ $f_{ce}/f_{rf}$
$\lt$ 2, where $f_{ce}$ and $f_{rf}$ are the cyclotron and radio-frequencies
(RF), respectively. This regime exhibits complex and distinctive plasma
dynamics due to the interplay between RF fields and the externally applied
magnetic field. Two prominent phenomena are observed in this regime. First, the
plasma density profile becomes asymmetric across the discharge, deviating from
the typical symmetric distribution seen in unmagnetized CCPs. Second, electron
Bernstein waves (EBWs), high-frequency electrostatic waves, are excited and
propagate within the bulk plasma, particularly along steep electron density
gradients. As the strength of the magnetic field increases within this regime,
the CCP discharge undergoes a transition from a symmetric configuration to an
asymmetric one, and then returns to a symmetric profile at higher field
strengths. Notably, the excitation and propagation of EBWs are strongly
correlated with the presence of discharge asymmetry and localized density
gradients. These waves play a significant role in energy transport and electron
heating under mildly magnetized conditions. To gain deeper insight into the
underlying physics, detailed numerical simulations are carried out using the
particle-in-cell Monte Carlo collision (PIC-MCC) technique. These simulations
capture the kinetic behavior of electrons and ions, including the collisionless
effects and sheath dynamics essential to understanding the excitation of EBWs
and the evolution of discharge symmetry. The study thus sheds light on the role
of weak magnetic fields in shaping plasma behavior and highlights the
importance of wave-particle interactions in magnetized CCPs.

</details>


### [33] [THz emission from multiple ionized plasma](https://arxiv.org/abs/2508.15462)
*Lucie Jurkovičová,David Štok,Caroline Juliano,Matyáš Staněk,Jaroslav Nejdl,Ondřej Hort*

Main category: physics.plasm-ph

TL;DR: Researchers developed a photocurrent model for high-intensity laser-gas interaction THz generation that explains high conversion efficiency and achieved 0.2 mJ THz pulses with >1% efficiency.


<details>
  <summary>Details</summary>
Motivation: There is a need for high-energy THz pulses (hundreds of μJ to mJ level) for nonlinear interaction studies, but current methods face limitations with material damage thresholds and incomplete understanding of laser-gas interaction mechanisms.

Method: Established a photocurrent model for laser-driven plasma THz generation that accounts for high-ionization states of target gas in the high-intensity regime.

Result: The model shows excellent agreement with experimental observations, explains spectral and temporal phenomena, and demonstrates high conversion efficiency. Experiments achieved 0.2 mJ THz pulses with conversion efficiency exceeding 1% using a Ti:sapphire laser.

Conclusion: The developed photocurrent model successfully explains THz generation mechanisms in high-intensity laser-gas interactions and enables efficient production of high-energy THz pulses needed for nonlinear studies.

Abstract: Studies employing nonlinear interactions of THz pulses are nowadays a
promising scientific research field. To capture these phenomena, THz pulses
with energy ranging from hundreds of \muJ to the mJ level are necessary.
However, techniques that provide pulses with such energy levels are still not
widely established. Upscaling methods of laser-solid interaction is limited by
the damage threshold of materials, while the mechanism of THz generation from
high intensity laser-gas interactions is not fully understood yet. Here, we
establish the photocurrent model of laser-driven plasma THz generation in the
high-intensity regime by accounting for high-ionization states of the target
gas. Our model shows excellent agreement with experimental observations,
provides a clear explanation of phenomena in both spectral and temporal
domains, and explains the high conversion efficiency from laser to THz. In the
experiments, we achieved a generation of 0.2 mJ THz pulses, driven by a
Ti:sapphire laser with a conversion efficiency exceeding 1 %.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [34] [Interface fluctuations for $1$D stochastic Allen-Cahn equation -- singular regime](https://arxiv.org/abs/2508.15319)
*Weijun Xu,Shuhan Zhou*

Main category: math.PR

TL;DR: Analysis of interface fluctuations in 1D stochastic Allen-Cahn equation with half-derivative white noise, showing diffusion behavior despite singular regime.


<details>
  <summary>Details</summary>
Motivation: To understand interface fluctuations in singular stochastic PDEs where noise makes solutions distribution-valued, requiring renormalization.

Method: Study the 1D stochastic Allen-Cahn equation perturbed by half spatial derivative of spacetime white noise, using renormalization techniques and long-time scaling analysis.

Result: For small noise and initial data near traveling waves, solution stays close to traveling wave family with interface moving via approximate diffusion. Two infinite quantities from noise singularity and renormalization cancel each other.

Conclusion: Interface SDE derivation becomes valid in the singular limit due to cancellation of infinite quantities, establishing diffusion behavior despite distribution-valued solutions.

Abstract: We study interface fluctuations for the $1$D stochastic Allen-Cahn equation
perturbed by half a spatial derivative of the spacetime white noise. This half
derivative makes the solution distribution-valued, so that proper
renormalization is needed to make sense of the solution.
  We show that if the noise is sufficiently small, then an analogue of the
classical results by \cite{Fun95,BBDMP98} holds in this singular regime. More
precisely, for initial data close to the traveling wave solution of the
deterministic equation, under proper long time scaling, the solution still
stays close to the family of traveling waves, and the interface location moves
according to an approximate diffusion process. There is one interesting
difference between our singular regime and the classical situation: even if the
solution and its approximate phase separation point are both well defined, the
intended diffusion describing the movement of the canonical candidate of the
phase point is not (even for fixed $\eps$). Two infinite quantities arise from
the derivation of such an SDE, one due to singularity of the noise, and the
other from renormalization. Magically, it turns out that they cancel out each
other, thus making the derivation of the interface SDE valid in the $\eps
\rightarrow 0$ limit.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [35] [Future Stability of Tilted Two-Fluid Bianchi I Spacetimes](https://arxiv.org/abs/2508.15155)
*Grigorios Fournodavlos,Elliot Marshall,Todd A. Oliynyk*

Main category: gr-qc

TL;DR: Nonlinear stability of tilted two-fluid Bianchi I solutions in Einstein-Euler equations with cosmological constant and specific equation of state parameters


<details>
  <summary>Details</summary>
Motivation: To establish the future nonlinear stability of cosmological solutions involving two fluids with tilted velocities in Bianchi I spacetimes, which is important for understanding the long-term behavior of cosmological models with multiple matter components

Method: Analysis of Einstein-Euler equations with positive cosmological constant, using linear equations of state p=Kρ for two fluids, with parameter range 1/3 < K < 5/7, focusing on tilted Bianchi I solutions

Result: Demonstrated nonlinear stability to the future for these tilted two-fluid Bianchi I cosmological solutions

Conclusion: The tilted two-fluid Bianchi I solutions remain stable in the future evolution under the specified conditions, providing important insights into cosmological stability with multiple matter components

Abstract: We establish the nonlinear stability to the future of tilted two-fluid
Bianchi I solutions to the Einstein-Euler equations with positive cosmological
constant and linear equations of state
$p_{(\mathfrak{a})}=K_{(\mathfrak{a})}\rho_{(\mathfrak{a})}$,
$\mathfrak{a}\in\{1,2\}$, where $\frac{1}{3}<K_{(\mathfrak{a})}<\frac{5}{7}$.

</details>


### [36] [Future stability of solutions of the Einstein-nonlinear scalar field system with decelerated expansion](https://arxiv.org/abs/2508.15303)
*Louie Bernhardt*

Main category: gr-qc

TL;DR: Future stability proof for FLRW spacetimes with exponential scalar field potential, showing perturbed solutions remain close to homogeneous backgrounds and converge to homogeneous states.


<details>
  <summary>Details</summary>
Motivation: To establish mathematical stability of accelerating cosmological solutions (FLRW with exponential potential) against nonlinear perturbations in Einstein-scalar field systems.

Method: Decompose metric and scalar field perturbations into spatial averages and oscillatory remainders with zero average. Prove future-causal geodesic completeness and convergence to homogeneity.

Result: For each p in (2/3,1), corresponding FLRW spacetime is future-stable. Perturbed solutions remain close to FLRW, are geodesically complete, and converge to spatially homogeneous functions as t→∞.

Conclusion: FLRW solutions with exponential scalar field potential are stable against nonlinear perturbations, providing mathematical foundation for such cosmological models.

Abstract: We study solutions to the Einstein equations coupled to a nonlinear scalar
field with exponential potential. This system admits
Friedmann-Lema\^itre-Robertson-Walker solutions undergoing decelerated
expansion, with $\mathbb{T}^3$ spatial topology and scale factor $a(t) = t^p$
for $1/3 < p < 1$. For each $p \in (2/3,1)$, we prove that the corresponding
FLRW spacetime is future-stable as a solution to the Einstein-nonlinear scalar
field system. Given initial data on a spacelike hypersurface that is
sufficiently close to the FLRW data, we show the resulting solution is
future-causal geodesically complete, and remains close to the FLRW solution for
all time. Moreover, we show the perturbed metric components and scalar field
converge to spatially homogeneous functions as $t \rightarrow \infty$. A key
feature of our analysis is the decomposition of the metric and scalar field
perturbations into their spatial averages and oscillatory remainders with zero
average.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [37] [Relative periodic solutions in spatial Kepler problem with symmetric perturbation](https://arxiv.org/abs/2508.15209)
*Xijun Hu,Zhiwen Qiao,Guowei Yu*

Main category: math.DS

TL;DR: Existence of infinitely many relative periodic solutions and a unique z-symmetric brake orbit in perturbed spatial Kepler problems with rotational and reflection symmetries.


<details>
  <summary>Details</summary>
Motivation: To study the spatial Kepler problem under perturbations that maintain rotational symmetry and reflection symmetry about a plane perpendicular to the rotational axis, extending understanding of celestial mechanics and symmetric systems.

Method: Application of recent results from CHHL23 combined with Franks Theorem to prove existence of solutions under small perturbations and technical conditions.

Result: Proved existence of infinitely many relative periodic solutions in compact energy surfaces and a unique z-symmetric brake orbit forming a hopf link with plane relative periodic solutions.

Conclusion: The results apply to satellite motion around ellipsoids with uniform mass distribution and n-pyramidal problems, demonstrating rich dynamics in symmetric perturbed Kepler systems.

Abstract: We study the spatial Kepler problem under a perturbation satisfying both
rotational symmetry and reflection symmetry with respect to a plane
perpendicular to the rotational axis. By applying recent results from
\cite{CHHL23} combined with Franks Theorem, we prove the existence of
infinitely many relative periodic solutions contained in compact energy surface
when the perturbation is sufficiently small and certain technical conditions
hold. In addition, we also demonstrate the existence of a unique $z$-symmetric
brake orbit which forms a hopf link with a plane relative periodic solutions
contained in compact energy surface only requires the perturbation sufficiently
small. Our results apply to the motion of a satellite around an ellipsoid with
uniform mass distribution and to the $n$-pyramidal problem with one point mass
moving along $z$-axis and other $n$ equal masses forming a regular $n$-gon
perpendicular to the $z$-axis at all times.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [38] [Trotter-based quantum algorithm for solving transport equations with exponentially fewer time-steps](https://arxiv.org/abs/2508.15691)
*Julien Zylberman,Thibault Fredon,Nuno F. Loureiro,Fabrice Debbasch*

Main category: quant-ph

TL;DR: Quantum algorithm for simulating multidimensional transport PDEs using state preparation, evolution with finite differences and Trotterization, and measurement, showing improved efficiency with vector-norm analysis.


<details>
  <summary>Details</summary>
Motivation: To address the open question of quantum computers' capability in simulating physical phenomena and solving PDEs, particularly focusing on the fundamental multidimensional transport equation with variable coefficients.

Method: Three-step quantum numerical scheme: state preparation, evolution combining high-order finite differences with time-splitting via product formula approximations (Trotterization), and measurement of observables with novel vector-norm error analysis.

Result: Vector-norm analysis provides similar accuracy with exponentially fewer time steps than operator-norm approaches, reducing computational resources. Efficient quantum circuits and numerical simulations confirm the scaling, with real hardware results for 1D convection and non-linear ODE solutions.

Conclusion: Provides a practical framework for efficient quantum simulation of transport phenomena with applications in plasma physics, gas dynamics, and chaotic systems, demonstrating significant computational resource reduction.

Abstract: The extent to which quantum computers can simulate physical phenomena and
solve the partial differential equations (PDEs) that govern them remains a
central open question. In this work, one of the most fundamental PDEs is
addressed: the multidimensional transport equation with space- and
time-dependent coefficients. We present a quantum numerical scheme based on
three steps: quantum state preparation, evolution, and measurement of relevant
observables. The evolution step combines a high-order centered finite
difference with a time-splitting scheme based on product formula
approximations, also known as Trotterization. Novel numerical analysis is
introduced to bound the different sources of error and we prove that, for the
product formula approximations, vector norm analysis guarantees similar
accuracy with exponentially fewer time steps than operator-norm-based
approaches, thereby significantly reducing the projected computational
resources. We also present efficient quantum circuits and numerical simulations
that confirm the predicted vector-norm scaling. We report results on real
quantum hardware for the one-dimensional convection equation, and solve a
non-linear ordinary differential equation via its associated Liouville
equation, a particular case of transport equations. This work provides a
practical framework for efficiently simulating transport phenomena on quantum
computers, with potential applications in plasma physics, molecular gas
dynamics and non-linear dynamical systems, including chaotic systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [39] [Generative Neural Operators of Log-Complexity Can Simultaneously Solve Infinitely Many Convex Programs](https://arxiv.org/abs/2508.14995)
*Anastasis Kratsios,Ariel Neufeld,Philipp Schmocker*

Main category: cs.LG

TL;DR: This paper bridges the theory-practice gap for neural operators by showing that generative equilibrium operators (GEOs) can approximate solutions to convex optimization problems with logarithmic parameter growth in error, validated on PDEs, optimal control, and finance problems.


<details>
  <summary>Details</summary>
Motivation: There's a significant gap between theoretical worst-case parameter bounds for neural operators (suggesting unrealistically large models) and experimental evidence showing their practical effectiveness. The paper aims to close this gap for a specific class of neural operators.

Method: The authors use generative equilibrium operators (GEOs) with finite-dimensional deep equilibrium layers to solve families of convex optimization problems over separable Hilbert spaces. They analyze approximation capabilities when input losses lie in suitable infinite-dimensional compact sets.

Result: The GEOs can uniformly approximate solutions to arbitrary precision with rank, depth, and width growing only logarithmically in the reciprocal of the approximation error. The approach is validated on nonlinear PDEs, stochastic optimal control, and financial hedging problems.

Conclusion: The paper successfully bridges the theory-practice gap for neural operators by demonstrating that GEOs require only logarithmic parameter growth for accurate approximations, making them practically feasible for solving infinite-dimensional operator learning problems.

Abstract: Neural operators (NOs) are a class of deep learning models designed to
simultaneously solve infinitely many related problems by casting them into an
infinite-dimensional space, whereon these NOs operate. A significant gap
remains between theory and practice: worst-case parameter bounds from universal
approximation theorems suggest that NOs may require an unrealistically large
number of parameters to solve most operator learning problems, which stands in
direct opposition to a slew of experimental evidence. This paper closes that
gap for a specific class of {NOs}, generative {equilibrium operators} (GEOs),
using (realistic) finite-dimensional deep equilibrium layers, when solving
families of convex optimization problems over a separable Hilbert space $X$.
Here, the inputs are smooth, convex loss functions on $X$, and outputs are the
associated (approximate) solutions to the optimization problem defined by each
input loss.
  We show that when the input losses lie in suitable infinite-dimensional
compact sets, our GEO can uniformly approximate the corresponding solutions to
arbitrary precision, with rank, depth, and width growing only logarithmically
in the reciprocal of the approximation error. We then validate both our
theoretical results and the trainability of GEOs on three applications: (1)
nonlinear PDEs, (2) stochastic optimal control problems, and (3) hedging
problems in mathematical finance under liquidity constraints.

</details>


### [40] [Hybrid Least Squares/Gradient Descent Methods for DeepONets](https://arxiv.org/abs/2508.15394)
*Jun Choi,Chang-Ock Lee,Minam Moon*

Main category: cs.LG

TL;DR: Hybrid LS/gradient descent method to accelerate DeepONet training by decomposing large least squares system into smaller branch and trunk subproblems.


<details>
  <summary>Details</summary>
Motivation: DeepONet output is linear with respect to last layer parameters, but building full LS system for all branch-trunk combinations is computationally prohibitive.

Method: Decompose large LS system into two smaller subproblems for branch and trunk networks, solve separately. Extends to L^2 loss with regularization and physics-informed unsupervised learning.

Result: Efficient training method that avoids infeasible large linear problems while maintaining optimization quality.

Conclusion: Proposed hybrid approach enables practical DeepONet training by breaking down computationally intensive LS optimization into manageable components.

Abstract: We propose an efficient hybrid least squares/gradient descent method to
accelerate DeepONet training. Since the output of DeepONet can be viewed as
linear with respect to the last layer parameters of the branch network, these
parameters can be optimized using a least squares (LS) solve, and the remaining
hidden layer parameters are updated by means of gradient descent form. However,
building the LS system for all possible combinations of branch and trunk inputs
yields a prohibitively large linear problem that is infeasible to solve
directly. To address this issue, our method decomposes the large LS system into
two smaller, more manageable subproblems $\unicode{x2014}$ one for the branch
network and one for the trunk network $\unicode{x2014}$ and solves them
separately. This method is generalized to a broader type of $L^2$ loss with a
regularization term for the last layer parameters, including the case of
unsupervised learning with physics-informed loss.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [41] [Matrix-Weighted Campanato Spaces: Duality and Calderón--Zygmund Operators](https://arxiv.org/abs/2508.15195)
*Yiqun Chen,Dachun Yang,Wen Yuan*

Main category: math.FA

TL;DR: This paper introduces matrix-weighted Campanato spaces and establishes their duality with matrix-weighted Hardy spaces, providing equivalent characterizations and boundedness conditions for Calderón-Zygmund operators.


<details>
  <summary>Details</summary>
Motivation: To extend the theory of weighted function spaces to the matrix-weighted setting, particularly establishing duality relationships between matrix-weighted Hardy spaces and newly defined Campanato spaces.

Method: Using reducing operators of matrix weights to define matrix-weighted Campanato spaces, then applying atomic and finite atomic characterizations of matrix-weighted Hardy spaces to prove duality results.

Result: Proved that the dual space of matrix-weighted Hardy space H^p_W is precisely the matrix-weighted Campanato space L_{p,q,s,W} for p in (0,1], and obtained necessary and sufficient conditions for boundedness of Calderón-Zygmund operators on these spaces.

Conclusion: The paper successfully establishes the duality between matrix-weighted Hardy and Campanato spaces, providing complete characterizations and boundedness criteria for operators on these function spaces in the matrix-weighted setting.

Abstract: Let $p\in(0,\infty)$, $q\in[1,\infty)$, $s\in\mathbb Z_+$, and $W$ be an
$A_p$-matrix weight, which in the scalar case is exactly a Muckenhoupt
$A_{\max\{1,p\}}$ weight. In this article, by using the reducing operators of
$W$, we introduce matrix-weighted Campanato spaces $\mathcal L_{p,q,s,W}$. When
$p\in(0,1]$, applying the atomic and the finite atomic characterizations of the
matrix-weighted Hardy space $H^p_W$, we prove that the dual space of $H^p_W$ is
precisely $\mathcal L_{p,q,s,W}$, which further induces several equivalent
characterizations of $\mathcal L_{p,q,s,W}$. In addition, we obtain a necessary
and sufficient condition for the boundedness of modified Calder\'on--Zygmund
operators on $\mathcal L_{p,q,s,W}$ with $p\in(0,\infty)$, which, combined with
the duality, further gives a necessary and sufficient condition for the
boundedness of Calder\'on--Zygmund operators on $H^p_W$ with $p\in(0,1]$.

</details>
