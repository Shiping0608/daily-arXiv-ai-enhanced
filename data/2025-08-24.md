<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 11]
- [math.AP](#math.AP) [Total: 15]
- [physics.comp-ph](#physics.comp-ph) [Total: 5]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 2]
- [math.FA](#math.FA) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [math.PR](#math.PR) [Total: 1]
- [gr-qc](#gr-qc) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [math.DS](#math.DS) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Semi-discrete Active Flux as a Petrov-Galerkin method](https://arxiv.org/abs/2508.15017)
*Wasilij Barsukow*

Main category: math.NA

TL;DR: Active Flux method bridges Finite Volume/DG and continuous Finite Element methods through variational formulation with biorthogonal test functions.


<details>
  <summary>Details</summary>
Motivation: To provide a rigorous mathematical foundation for the Active Flux method by deriving it from a variational formulation, showing its intermediate position between discontinuous and continuous numerical methods.

Method: Developed a variational formulation using biorthogonal test functions on Cartesian meshes to obtain the semi-discrete Active Flux method, emphasizing its discontinuous nature despite continuous approximations.

Result: Successfully derived the Active Flux method from a variational approach, demonstrating its hybrid character combining features from both DG (discontinuous) and CG (continuous) methods.

Conclusion: The Active Flux method represents an intermediate approach between discontinuous and continuous numerical methods for hyperbolic conservation laws, with a solid variational foundation established through biorthogonal test functions.

Abstract: Active Flux (AF) is a recent numerical method for hyperbolic conservation
laws, whose degrees of freedom are averages/moments and (shared) point values
at cell interfaces. It has been noted previously in a heuristic fashion that it
thus combines ideas from Finite Volume/Discontinuous Galerkin (DG) methods with
a continuous approximation common in continuous Finite Element (CG) methods.
This work shows that the semi-discrete Active Flux method on Cartesian meshes
can be obtained from a variational formulation through a particular choice of
(biorthogonal) test functions. These latter being discontinuous, the new
formulation emphasizes the intermediate nature of AF between DG and CG.

</details>


### [2] [Error Estimation for Adaptive Mesh Refinement in Droplet Simulations](https://arxiv.org/abs/2508.15081)
*Darsh Nathawani,Matthew Knepley*

Main category: math.NA

TL;DR: A 1D shear force driven droplet formation model with flux-based error estimation using asymptotic expansion and front-tracking method, discretized with Galerkin FEM in mixed form to handle discontinuous gradient jumps during pinch-off.


<details>
  <summary>Details</summary>
Motivation: To accurately simulate droplet interface formation under shear forces while addressing the challenge of discontinuous solution gradients that grow rapidly during the highly convective pinch-off process, which leads to erroneous interface representation and incorrect curvature calculations.

Method: Derived using asymptotic expansion and front-tracking method for interface simulation, discretized with Galerkin finite element method in mixed form, with adaptive mesh refinement driven by flux-based error estimation from smooth interface gradients.

Result: The mixed form of governing equations provides smooth interface gradients that enable accurate error estimation, which successfully drives adaptive mesh refinement to capture the droplet interface accurately during pinch-off.

Conclusion: The proposed flux-based error estimation with adaptive mesh refinement effectively addresses the challenges of discontinuous gradient jumps in shear force driven droplet formation, ensuring accurate interface representation and curvature computation throughout the pinch-off process.

Abstract: We present a one-dimensional shear force driven droplet formation model with
a flux-based error estimation. The presented model is derived using asymptotic
expansion and a front-tracking method to simulate the droplet interface. The
model is then discretized using the Galerkin finite element method in the mixed
form. However, the jumps in the solution gradients are discontinuous and can
grow faster due to the highly convective pinch-off process. This leads to an
erroneous droplet interface and incorrect curvature. Therefore, the mesh must
be sufficiently refined to capture the interface accurately. The mixed form of
the governing equation naturally provides smooth interface gradients that can
be used to compute the error estimate. The computed error estimate is then used
to drive the adaptive mesh refinement algorithm.

</details>


### [3] [A Note on the Convergence of Symmetric Triangle Quadrature Rules](https://arxiv.org/abs/2508.15133)
*Brian A. Freno,Neil R. Matula,Joseph E. Bishop*

Main category: math.NA

TL;DR: Symmetric triangle quadrature rules with even-degree polynomial integration capability achieve higher convergence rates (p=d+2) than conventional expectation (p=d+1), reducing quadrature points needed for finite-element problems.


<details>
  <summary>Details</summary>
Motivation: To optimize integration accuracy vs computational cost in finite-element problems by understanding the true convergence behavior of symmetric triangle quadrature rules, particularly for smooth non-polynomial integrands.

Method: Analysis of symmetric triangle quadrature rules, discussion of error implications for 1D and triangular domains, and numerical experiments on sequences of regular meshes to verify convergence rates.

Result: Quadrature rules that exactly integrate polynomials up to even degree d achieve convergence rate p=d+2 instead of the conventional p=d+1, allowing fewer quadrature points for the same accuracy.

Conclusion: The improved convergence rate for even-degree symmetric triangle quadrature rules enables significant computational savings, especially for global integral operators producing dense matrices in finite-element applications.

Abstract: Symmetric polynomial quadrature rules for triangles are commonly used to
efficiently integrate two-dimensional domains in finite-element-type problems.
While the development of such rules focuses on the maximum degree a given
number of points can exactly integrate, smooth integrands are generally not
polynomials of finite degree. Therefore, for such integrands, one needs to
balance integration accuracy and computational cost. A natural approach to this
balance is to choose the number of points such that the convergence rate with
respect to the mesh size $h$ matches that of the other properties of the
scheme, such as the planar or curved triangles that approximate the geometry or
the basis functions that approximate the solution.
  In general, it is expected that a quadrature rule capable of integrating
polynomials up to degree $d$ yields an integration error that is
$\mathcal{O}(h^p)$, where $p=d+1$. However, as we describe in this paper, for
symmetric triangle quadrature rules, when $d$ is even, $p=d+2$; therefore, for
a $p^\text{th}$-order-accurate quadrature rule, fewer quadrature points are
necessary, reducing the time required for matrix assembly in
finite-element-type problems. This reduction in cost is modest for local
differential operators that yield sparse matrices but appreciable for global
integral operators that yield dense matrices.
  In this paper, we briefly summarize the details of symmetric triangle
quadrature rules, discuss error implications for quadrature rules for one
dimension and triangles, and we provide numerical examples that support our
observation that polynomials that exactly integrate even maximum degrees
converge faster than the conventional expectation for sequences of regular
meshes.

</details>


### [4] [Reduced basis solvers for unfitted methods on parameterized domains](https://arxiv.org/abs/2508.15320)
*Nicholas Mueller,Santiago Badia,Yiran Zhao*

Main category: math.NA

TL;DR: A unified framework combining unfitted finite element methods with reduced basis techniques for parametrized PDEs on parameter-dependent domains, using deformation mapping and localization for efficient model reduction.


<details>
  <summary>Details</summary>
Motivation: To enable efficient and accurate model reduction of parametrized PDEs on general, parameter-dependent geometries by addressing the challenge of reconciling geometric variability with fixed-dimensional snapshot representations.

Method: Combines unfitted finite element methods with classical and tensor-based reduced basis techniques (particularly tensor-train method). Uses deformation-based strategy to map reference configuration to parameterized domains, localization procedure for reduced subspaces, and matrix discrete empirical interpolation for hyper-reduction. Extends to saddle-point problems with supremizer enrichment adapted to unfitted methods.

Result: Numerical experiments on 2D and 3D problems (Poisson, linear elasticity, incompressible Stokes, Navier-Stokes equations) demonstrate the framework's flexibility, accuracy and efficiency.

Conclusion: The proposed unified framework successfully enables efficient model reduction for parametrized PDEs on parameter-dependent domains, with demonstrated effectiveness across various problem types and dimensions.

Abstract: In this paper, we present a unified framework for reduced basis
approximations of parametrized partial differential equations defined on
parameter-dependent domains. Our approach combines unfitted finite element
methods with both classical and tensor-based reduced basis techniques --
particularly the tensor-train reduced basis method -- to enable efficient and
accurate model reduction on general geometries. To address the challenge of
reconciling geometric variability with fixed-dimensional snapshot
representations, we adopt a deformation-based strategy that maps a reference
configuration to each parameterized domain. Furthermore, we introduce a
localization procedure to construct dictionaries of reduced subspaces and
hyper-reduction approximations, which are obtained via matrix discrete
empirical interpolation in our work. We extend the proposed framework to
saddle-point problems by adapting the supremizer enrichment strategy to
unfitted methods and deformed configurations, demonstrating that the supremizer
operator can be defined on the reference configuration without loss of
stability. Numerical experiments on two- and three-dimensional problems --
including Poisson, linear elasticity, incompressible Stokes and Navier-Stokes
equations -- demonstrate the flexibility, accuracy and efficiency of the
proposed methodology.

</details>


### [5] [Eig-PIELM: A Mesh-Free Approach for Efficient Eigen-Analysis with Physics-Informed Extreme Learning Machines](https://arxiv.org/abs/2508.15343)
*Rishi Mishra,Smriti,Ganapathy Krishnamurthi,Balaji Srinivasan,Sundararajan Natarajan*

Main category: math.NA

TL;DR: Eig-PIELM is a novel mesh-free framework that extends physics-informed extreme learning machines to efficiently solve linear eigenvalue problems in one linear solve, eliminating penalty parameters and backpropagation while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient and accurate method for solving linear eigenvalue problems that avoids computational overhead from penalty parameters and backpropagation, while being particularly valuable for rapid frequency spectrum analysis in mechanical, acoustic, and electromechanical systems.

Method: Reformulates governing differential equations into a compact algebraic system solvable in one step, enforces boundary conditions exactly via algebraic projection onto boundary-admissible subspace, and leverages the computational advantages of extreme learning machines in a mesh-free framework.

Result: The framework simultaneously yields both eigenvalues and mode shapes in one linear solve, demonstrating robustness and accuracy across a range of benchmark problems.

Conclusion: Eig-PIELM's mesh-free nature, solution structure, and accuracy make it particularly valuable for parametric studies requiring rapid frequency spectrum analysis in various engineering systems.

Abstract: In this work, a novel Eig-PIELM framework is proposed that extends
physics-informed extreme learning machine for an efficient and accurate
solution of linear eigenvalue problems. The method reformulates the governing
differential equations into a compact algebraic system solvable in a single
step. Boundary conditions are enforced exactly via an algebraic projection onto
the boundary-admissible subspace, eliminating the computational overhead of
penalty parameters, and backpropagation while preserving the computational
advantages of extreme learning machines. The proposed framework is mesh-free
and yields both eigenvalues and mode shapes simultaneously in one linear solve.
The robustness and accuracy of the proposed framework is demonstrated through a
range of benchmark problems. We believe that the mesh-free nature, solution
structure and accuracy of Eig-PIELM makes it particularly valuable for
parametric studies in mechanical, acoustic, and electromechanical systems where
rapid frequency spectrum analysis is critical.

</details>


### [6] [Implementation of Milstein Schemes for Stochastic Delay-Differential Equations with Arbitrary Fixed Delays](https://arxiv.org/abs/2508.15365)
*Mitchell T. Griggs,Kevin Burrage,Pamela M. Burrage*

Main category: math.NA

TL;DR: Develops numerical methods for solving stochastic delay-differential equations with multiple fixed delays that don't align with uniform time meshes, using Euler-Maruyama and Milstein schemes with interpolation and augmented meshes.


<details>
  <summary>Details</summary>
Motivation: Previous SDDE simulations were restricted to divisible delays due to implementation challenges. This work addresses the general case of indivisible delays where delayed times don't align with uniform time meshes.

Method: For order 1/2 convergence: fixed step size with linear interpolation. For order 1 convergence: augmented time mesh with varying step sizes and extended technique for simulating delayed iterated stochastic integrals.

Result: The numerical schemes achieve their theoretical convergence orders (1/2 and 1) as confirmed through computational examples.

Conclusion: Successfully developed simulation techniques for SDDEs with indivisible delays, overcoming previous limitations and achieving theoretical convergence orders through interpolation and augmented mesh approaches.

Abstract: This paper develops methods for numerically solving stochastic
delay-differential equations (SDDEs) with multiple fixed delays that do not
align with a uniform time mesh. We focus on numerical schemes of strong
convergence orders $1/2$ and $1$, such as the Euler--Maruyama and Milstein
schemes, respectively. Although numerical schemes for SDDEs with delays
$\tau_1,\ldots,\tau_K$ are theoretically established, their implementations
require evaluations at both present times such as $t_n$, and also at delayed
times such as $t_n-\tau_k$ and $t_n-\tau_l-\tau_k$. As a result, previous
simulations of these schemes have been largely restricted to the case of
divisible delays. We develop simulation techniques for the general case of
indivisible delays where delayed times such as $t_n-\tau_k$ are not restricted
to a uniform time mesh. To achieve order of convergence (OoC) $1/2$, we
implement the schemes with a fixed step size while using linear interpolation
to approximate delayed scheme values. To achieve OoC $1$, we construct an
augmented time mesh that includes all time points required to evaluate the
schemes, which necessitates using a varying step size. We also introduce a
technique to simulate delayed iterated stochastic integrals on the augmented
time mesh, by extending an established method from the divisible-delays
setting. We then confirm that the numerical schemes achieve their theoretical
convergence orders with computational examples.

</details>


### [7] [Numerical Analysis of Unsupervised Learning Approaches for Parameter Identification in PDEs](https://arxiv.org/abs/2508.15381)
*Siyu Cen,Bangti Jin,Qimeng Quan,Zhi Zhou*

Main category: math.NA

TL;DR: Survey of unsupervised neural network methods for PDE parameter identification, focusing on diffusion coefficient problems, with error analysis framework using Galerkin FEM and conditional stability estimates.


<details>
  <summary>Details</summary>
Motivation: To provide rigorous mathematical analysis and error bounds for unsupervised learning approaches that use neural networks to solve PDE parameter identification problems, which have shown impressive empirical performance but lack theoretical foundations.

Method: Comprehensive survey and analysis framework using Galerkin finite element method, hybrid methods, and deep neural networks, with emphasis on conditional stability estimates for error analysis.

Result: Development of a general framework for deriving rigorous error bounds on discrete approximations obtained through various numerical methods including neural network approaches.

Conclusion: Conditional stability estimates play a crucial role in error analysis for PDE parameter identification problems, and the framework provides theoretical foundation for unsupervised learning methods in this domain.

Abstract: Identifying parameters in partial differential equations (PDEs) represents a
very broad class of applied inverse problems. In recent years, several
unsupervised learning approaches using (deep) neural networks have been
developed to solve PDE parameter identifications. These approaches employ
neural networks as ansatz functions to approximate the parameters and / or the
states, and have demonstrated impressive empirical performance. In this paper,
we provide a comprehensive survey on these unsupervised learning techniques on
one model problem, diffusion coefficient identification, from the classical
numerical analysis perspective, and outline a general framework for deriving
rigorous error bounds on the discrete approximations obtained using the
Galerkin finite element method, hybrid method and deep neural networks.
Throughout we highlight the crucial role of conditional stability estimates in
the error analysis.

</details>


### [8] [Conditional Stability and Numerical Reconstruction of a Parabolic Inverse Source Problem Using Carleman Estimates](https://arxiv.org/abs/2508.15406)
*Tianhao Hu,Xinchi Huang,Bangti Jin,Qimeng Quan,Zhi Zhou*

Main category: math.NA

TL;DR: New numerical method for recovering spatial source in parabolic equations from partial interior measurements with proven stability and error bounds.


<details>
  <summary>Details</summary>
Motivation: Develop an effective numerical approach for solving inverse source problems in parabolic equations with partial interior measurements, addressing the need for rigorous error analysis and stability guarantees.

Method: Uses Carleman estimates to establish conditional Lipschitz and Hölder stability, then implements conforming finite element approximations in both time and space with rigorous error bounds derived from stability estimates.

Result: Successfully developed a numerical approach with proven conditional stability properties and demonstrated effectiveness through multiple numerical experiments.

Conclusion: The proposed method provides a reliable numerical framework for solving inverse source problems in parabolic equations with theoretical guarantees and practical effectiveness.

Abstract: In this work we develop a new numerical approach for recovering a spatially
dependent source component in a standard parabolic equation from partial
interior measurements. We establish novel conditional Lipschitz stability and
H\"{o}lder stability for the inverse problem with and without boundary
conditions, respectively, using suitable Carleman estimates. Then we propose a
numerical approach for solving the inverse problem using conforming finite
element approximations in both time and space. Moreover, by utilizing the
conditional stability estimates, we prove rigorous error bounds on the discrete
approximation. We present several numerical experiments to illustrate the
effectiveness of the approach.

</details>


### [9] [A Structure-Preserving Scheme for the Euler System with Potential Temperature Transport](https://arxiv.org/abs/2508.15416)
*K. R. Arun,Rahuldev Ghorai*

Main category: math.NA

TL;DR: An asymptotic preserving, positivity-preserving finite volume scheme for compressible Euler equations with potential temperature transport that works across all Mach numbers from compressible to incompressible regimes.


<details>
  <summary>Details</summary>
Motivation: To address numerical challenges in atmospheric modeling where low Mach number flows become stiff, requiring stable and accurate schemes that preserve physical properties across different flow regimes.

Method: Developed an all-speed, semi-implicit finite volume scheme that is asymptotic preserving in the low Mach limit and strictly positivity preserving for density and potential temperature.

Result: The scheme maintains stability and accuracy across broad Mach number ranges, consistently capturing both compressible and incompressible limits while preserving physical structures.

Conclusion: The method successfully handles stiff low Mach number flows in atmospheric modeling, providing robust numerical performance while preserving essential mathematical and physical properties of the system.

Abstract: We consider the compressible Euler equations with potential temperature
transport, a system widely used in atmospheric modelling to describe adiabatic,
inviscid flows. In the low Mach number regime, the equations become stiff and
pose significant numerical challenges. We develop an all-speed, semi-implicit
finite volume scheme that is asymptotic preserving (AP) in the low Mach limit
and strictly positivity preserving for density and potential temperature. The
scheme ensures stability and accuracy across a broad range of Mach numbers,
from fully compressible to nearly incompressible regimes. We rigorously
establish consistency with both the compressible system and its incompressible,
density-dependent limit. Numerical experiments confirm that the method robustly
captures complex flow features while preserving the essential physical and
mathematical structures of the model.

</details>


### [10] [Exponential decay of the discrete energy for the wave-wave coupled system](https://arxiv.org/abs/2508.15514)
*Toni Sayah,Toufic El Arwadi*

Main category: math.NA

TL;DR: Numerical analysis of discrete energy decay in dissipative coupled wave systems using P1 FEM and implicit Euler scheme, showing linear convergence and exponential energy decay.


<details>
  <summary>Details</summary>
Motivation: To analyze the asymptotic behavior of discrete energy in dissipative coupled wave systems and establish convergence properties of numerical approximations.

Method: P1 finite element method for spatial discretization combined with implicit Euler scheme for time integration, with a priori error analysis and energy method.

Result: Numerical scheme exhibits linear convergence under extra regularity assumptions, and exponential decay of fully discrete energy is demonstrated for the first time.

Conclusion: The proposed numerical approach successfully captures the energy decay behavior of dissipative coupled wave systems with proven convergence and decay properties.

Abstract: In this article, a numerical analysis of the asymptotic behavior of the
discrete energy associated to a dissipative coupled wave system is conducted.
The numerical approximation of the system is constructed using the P1 finite
element method for spatial discretization, combined with the implicit Euler
scheme for time integration. An a priori error analysis is established, showing
that, under extra regularity assumptions on the continuous solution, the
numerical scheme exhibits linear convergence. Then, for the first time in the
literature, the exponential decay of the fully discrete energy is shown using
the energy method.

</details>


### [11] [Weighted finite difference methods for the semiclassical nonlinear Schrödinger equation with multiphase oscillatory initial data](https://arxiv.org/abs/2508.15683)
*Yanyan Shi,Christian Lubich*

Main category: math.NA

TL;DR: Weighted finite difference methods for solving highly oscillatory dispersive evolution equations without needing prohibitively fine grids


<details>
  <summary>Details</summary>
Motivation: Standard finite difference methods require extremely fine grids to resolve high-frequency oscillations in both space and time for semiclassically scaled nonlinear Schrödinger equations, which is computationally prohibitive

Method: Modified traditional finite difference methods with appropriate exponential weights, specifically proposing weighted leapfrog and weighted Crank-Nicolson methods

Result: Both proposed methods achieve second-order accuracy with time steps and mesh sizes that are not restricted by the small semiclassical parameter

Conclusion: The weighted finite difference approach successfully handles highly oscillatory solutions without the computational burden of extremely fine grids, as demonstrated by numerical experiments

Abstract: This paper introduces weighted finite difference methods for numerically
solving dispersive evolution equations with solutions that are highly
oscillatory in both space and time. We consider a semiclassically scaled cubic
nonlinear Schr\"odinger equation with highly oscillatory initial data, first in
the single-phase case and then in the general multiphase case. The proposed
methods do not need to resolve high-frequency oscillations in both space and
time by prohibitively fine grids as would be required by standard finite
difference methods. The approach taken here modifies traditional finite
difference methods by appropriate exponential weights. Specifically, we propose
the weighted leapfrog and weighted Crank--Nicolson methods, both of which
achieve second-order accuracy with time steps and mesh sizes that are not
restricted in magnitude by the small semiclassical parameter. Numerical
experiments illustrate the theoretical results.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [12] [Brezis-Nirenberg type problem for fractional sub-Laplacian on the Heisenberg group](https://arxiv.org/abs/2508.14990)
*Vikram Yallapa Naik,Gaurav Dwivedi*

Main category: math.AP

TL;DR: Existence of weak solutions for fractional sub-Laplacian equations with critical Sobolev exponent on Heisenberg groups


<details>
  <summary>Details</summary>
Motivation: Extending the celebrated Brezis-Nirenberg problem to the fractional setting on Heisenberg groups, addressing critical exponent cases

Method: Analysis of fractional sub-Laplace equations with critical Sobolev exponent terms, using functional analysis and variational methods on bounded domains in Heisenberg groups

Result: Proves the existence of weak solutions for the fractional sub-Laplacian equation with critical exponent under specified conditions

Conclusion: The paper successfully establishes existence results for critical exponent problems in the fractional Heisenberg group setting, extending classical Brezis-Nirenberg theory

Abstract: In this paper, we show the existence of a weak solution for a fractional
sub-Laplace equation involving a term with the critical Sobolev exponent,
namely, \begin{align*} (-\Delta_\mathbb{H})^su - \lambda u &= |u|^{Q^*_s -2}u
\text{ in } \Omega,\\ u &= 0 \text{ in } \mathbb{H}^N \setminus \Omega,
\end{align*} where $\Omega \subseteq \mathbb{H}^N$ is bounded and has
continuous boundary, $(-\Delta_\mathbb{H})^s$ is the horizontal fractional
Laplacian, $s \in (0,1), \lambda > 0,$ and $Q^*_s=\frac{2Q}{Q-2s}$ is the
Sobolev critical exponent. This problem is motivated by the celebrated
Brezis-Nirenberg problem \cite{brezis1983positive}.

</details>


### [13] [Optimal Interference Signal for Masking an Acoustic Source](https://arxiv.org/abs/2508.15023)
*Hongyun Wang,Hong Zhou*

Main category: math.AP

TL;DR: A framework for designing interference signals to mask acoustic sources from detection in target regions, using analytical solutions for spherical symmetry and numerical methods for general cases.


<details>
  <summary>Details</summary>
Motivation: To address acoustic privacy and signal obfuscation needs in environments where acoustic signatures need to be concealed from detection sensors.

Method: Developed theoretical and computational framework using analytical quasi-steady periodic solutions for 3D wave equation with spherical symmetry, and numerical methods for asymmetric cases. Examined self-masking phenomena and superposition of solutions.

Result: Derived analytical solutions for canonical cases, investigated self-masking capabilities, and optimized performance using one or two point-forces for effective masking in target regions.

Conclusion: The framework provides effective acoustic masking solutions with applications in undersea communication security, vehicle stealth, and protection against acoustic surveillance.

Abstract: In an environment where acoustic privacy or deliberate signal obfuscation is
desired, it is necessary to mask the acoustic signature generated in essential
operations. We consider the problem of masking the effect of an acoustic source
in a target region where possible detection sensors are located. Masking is
achieved by placing interference signals near the acoustic source. We introduce
a theoretical and computational framework for designing such interference
signals with the goal of minimizing the residual amplitude in the target
region. For the three-dimensional (3D) forced wave equation with spherical
symmetry, we derive analytical quasi-steady periodic solutions for several
canonical cases. We examine the phenomenon of self-masking where an acoustic
source with certain spatial forcing profile masks itself from detection outside
its forcing footprint. We then use superposition of spherically symmetric
solutions to investigate masking in a given target region. We analyze and
optimize the performance of using one or two point-forces deployed near the
acoustic source for masking in the target region. For the general case where
the spatial forcing profile of the acoustic source lacks spherical symmetry, we
develop an efficient numerical method for solving the 3D wave equation.
Potential applications of this work include undersea acoustic communication
security, undersea vehicles stealth, and protection against acoustic
surveillance.

</details>


### [14] [Analysis of mean field games via Fokker-Planck-Kolmogorov equations: existence of equilibria](https://arxiv.org/abs/2508.15029)
*Stanislav V. Shaposhnikov,Dmitry V. Shatilovich*

Main category: math.AP

TL;DR: Existence proof for mean field games with unbounded coefficients using Fokker-Planck-Kolmogorov equations, superposition principle, and Lyapunov function estimates


<details>
  <summary>Details</summary>
Motivation: To address the challenge of mean field games with unbounded coefficients, where traditional methods may fail due to the lack of boundedness constraints

Method: Novel approach combining Fokker-Planck-Kolmogorov equations, Ambrosio-Figalli-Trevisan superposition principle, and a priori estimates using Lyapunov functions

Result: Successful proof of solution existence for mean field games with unbounded coefficients

Conclusion: The proposed methodology provides a robust framework for handling mean field games with unbounded coefficients, expanding the applicability of mean field game theory

Abstract: We study mean field games with unbounded coefficients. The existence of a
solution is proved. We propose a new approach based on Fokker-Planck-Kolmogorov
equations, the Ambrosio-Figalli-Trevisan superposition principle and a priory
estimates with Lyapunov functions.

</details>


### [15] [On the Fermi-Dirac-type Fisher information](https://arxiv.org/abs/2508.15054)
*Yuzhe Zhu*

Main category: math.AP

TL;DR: Analysis of Fisher information for Fermi-Dirac-Fokker-Planck equations showing monotonicity under initial data bounds, with applications to heat equation and Landau-Fermi-Dirac models.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of Fisher information in kinetic models for Fermi-Dirac particles subject to exclusion principles, and establish conditions for its monotonic decay.

Method: Introduce generalized Fisher information concept tailored to Fermi-Dirac-Fokker-Planck equations, prove entropy dissipation identity, and analyze time evolution under different initial conditions.

Result: Fisher information decreases along solutions when initial data satisfies an upper bound, but monotonicity fails without this bound. Results extended to heat equation and linear Landau-Fermi-Dirac equation.

Conclusion: The generalized Fisher information provides a useful tool for analyzing Fermi-Dirac kinetic equations, with monotonic decay behavior dependent on initial data constraints.

Abstract: We consider kinetic models for Fermi-Dirac-like particles obeying the
exclusion principle. A generalized notion of Fisher information, tailored to
kinetic equations of Fermi-Dirac-Fokker-Planck type, is introduced via the
associated entropy dissipation identity. We show that, subject to a suitable
upper bound on the initial data, this quantity decreases along solutions of the
Fermi-Dirac-Fokker-Planck equation, while monotonicity can fail in the absence
of such a bound. We also discuss the time evolution of this Fermi-Dirac-type
Fisher information for the heat equation and the linear-type Landau-Fermi-Dirac
equation with Maxwell molecules.

</details>


### [16] [Non-linear degenerate parabolic flow equations and a finer differential structure on Wasserstein spaces](https://arxiv.org/abs/2508.15140)
*Arthur Schichl*

Main category: math.AP

TL;DR: New differential structures on Wasserstein spaces for p>2 on Riemannian manifolds, with generalized flow equations and smooth solution construction via Average Flow Approximation Series.


<details>
  <summary>Details</summary>
Motivation: To develop finer differential structures on Wasserstein spaces beyond the classical framework, enabling more sophisticated analysis of measure-valued flows and extending the Central Limit Theorem.

Method: Define new differential structures using degenerate second order PDEs with measure-dependent coefficients. Construct smooth solutions as uniform limits of Average Flow Approximation Series (variant of explicit Euler-scheme approximations).

Result: Successfully constructed smooth solutions in Wasserstein spaces under weak assumptions, proving a generalized version of the Central Limit Theorem. Demonstrated uniqueness of smooth solutions under stronger assumptions.

Conclusion: The proposed differential framework provides a refined structure for analyzing Wasserstein spaces, with practical computational methods and theoretical guarantees including solution existence and uniqueness.

Abstract: We define new differential structures on the Wasserstein spaces
$\mathcal{W}_p(M)$ for $p > 2$ and a general Riemannian manifold $(M,g)$. We
consider a very general and possibly degenerate second order partial
differential flow equation with measure dependent coefficients to expand the
notion of smooth curves and to ensure that the new differential structure is
finer than the classical one. Under weak assumptions, we explicitly construct
smooth solutions as uniform limits of Average Flow Approximation Series (a
variant of explicit Euler--scheme approximations) in $\mathcal{W}_p(M)$ and,
thus, prove a generalzed version of the Central Limit Theorem. Under slightly
stronger assumptions, we prove that smooth solutions of our newly introduced
flow--equation are unique.

</details>


### [17] [Multiple nodal solutions to a scalar field equation with double-power nonlinearity and zero mass at infinity](https://arxiv.org/abs/2508.15167)
*Mónica Clapp,Carlos Culebro*

Main category: math.AP

TL;DR: Existence of sign-changing solutions for nonlinear elliptic equations in exterior domains with decaying potentials and asymmetric nonlinearities


<details>
  <summary>Details</summary>
Motivation: Study nonlinear elliptic equations in exterior domains to understand existence and multiplicity of sign-changing solutions under weak symmetry conditions, particularly in higher dimensions

Method: Analysis of the equation -Δu + V(x)u = f(u) in exterior domains Ω of ℝᴺ, where V decays to zero at infinity and f is subcritical at infinity and supercritical near the origin, using weak symmetry assumptions

Result: Established conditions guaranteeing a prescribed number of sign-changing solutions, with numerous examples in dimensions N≥4 showing exterior domains with finite symmetries can yield predetermined numbers of nodal solutions

Conclusion: The paper demonstrates that nonlinear elliptic equations in exterior domains can have multiple sign-changing solutions even under weak symmetry conditions, particularly in higher dimensions, providing significant existence results for such problems

Abstract: We consider the nonlinear elliptic equation \begin{equation*} -\Delta u +
V(x)u = f(u), \qquad u\in D^{1,2}_0(\Omega), \end{equation*} in an exterior
domain $\Omega$ of $\mathbb{R}^N$, where $V$ is a scalar potential that decays
to zero at infinity and the nonlinearity $f$ is subcritical at infinity and
supercritical near the origin. Under weak symmetry assumptions, we provide
conditions that guarantee that this problem has a prescribed number of
sign-changing solutions. In particular, we show that in dimensions $N\geq 4$
there are numerous examples of exterior domains with finite symmetries in which
the problem has a predetermined number of nodal solutions.

</details>


### [18] [Constructing characteristic initial data for three dimensional compressible Euler equations](https://arxiv.org/abs/2508.15199)
*Yuxuan Wang,Sifan Yu,Pin Yu*

Main category: math.AP

TL;DR: This paper solves the characteristic initial data problem for 3D compressible Euler equations using acoustical geometry framework, providing complete data construction for admissible hypersurfaces.


<details>
  <summary>Details</summary>
Motivation: To resolve the open problem analogous to Christodoulou's characteristic initial value formulation in general relativity, but for compressible Euler equations, enabling studies of long-time dynamics.

Method: Uses vector field method within acoustical geometry framework to recursively determine all order derivatives of solutions along characteristic cones via transport and wave equations.

Result: Proves that arbitrary smooth entropy function and angular velocity determine smooth initial data on characteristic cones, providing complete characteristic data construction.

Conclusion: The work successfully resolves the characteristic initial data problem for 3D compressible Euler equations, introducing novel tools for studying compressible Euler flow dynamics.

Abstract: This paper resolves the characteristic initial data problem for the
three-dimensional compressible Euler equations - an open problem analogous to
Christodoulou's characteristic initial value formulation for the vacuum
Einstein field equations in general relativity. Within the framework of
acoustical geometry, we prove that for any "initial cone" $C_0\subset
\mathcal{D}=[0,T]\times\mathbb{R}^3$ with initial data
$(\mathring{\rho},\mathring{v},\mathring{s})$ given at $S_{0,0}=C_0\cap
\Sigma_0$, arbitrary smooth entropy function and angular velocity determine
smooth initial data $(\rho,v,s)$ on $C_0$ that render $C_0$ characteristic.
Differing from the intersecting-hypersurface case by Speck-Yu [19] and the
symmetric reduction case by Lisibach [11], our vector field method recursively
determines all (including $0$-th) order derivatives of the solution along $C_0$
via transport equations and wave equations. This work provides a complete
characteristic data construction for admissible hypersurfaces in the 3D
compressible Euler system, introducing useful tools and providing novel aspects
for studies of the long-time dynamics of the compressible Euler flow.

</details>


### [19] [On the extremal functions of second order uncertainty principles: symmetry and symmetry breaking](https://arxiv.org/abs/2508.15221)
*Xiao-Ping Chen,Chun-Lei Tang*

Main category: math.AP

TL;DR: This paper disproves a conjecture about symmetry in second order Hydrogen Uncertainty Principle for dimensions 2 and 3, showing symmetry breaking, and extends previous work by establishing sharp weighted inequalities with radial extremal functions.


<details>
  <summary>Details</summary>
Motivation: To investigate the symmetry properties and symmetry breaking phenomena in the second order Hydrogen Uncertainty Principle, addressing a specific conjecture and extending previous mathematical results in this area.

Method: The authors use mathematical analysis techniques including selection of suitable test functions to disprove the conjecture, and develop weighted second order Hydrogen Uncertainty Principles to establish sharp inequalities with radial extremal functions.

Result: The paper provides a negative answer to the conjecture by Cazacu, Flynn and Lam for dimensions N=2 and 3, demonstrating symmetry breaking. It also obtains a family of sharp weighted second order Hydrogen Uncertainty Principles and proves that the extremal functions are radial.

Conclusion: The research reveals important symmetry breaking phenomena in the second order Hydrogen Uncertainty Principle and extends previous work by establishing new sharp inequalities with radial extremal functions, contributing to the mathematical understanding of uncertainty principles in quantum mechanics.

Abstract: This paper focus on the symmetry and symmetry breaking about the second order
Hydrogen Uncertainty Principle. \emph{Firstly}, by choosing a suitable test
function, we give a negative answer to the conjecture presented by Cazacu,
Flynn and Lam in [\emph{J. Funct. Anal.} \textbf{283} (2022), Paper No. 109659,
37 pp] for $N\in\{2,3\}$, and emphasizing the symmetry breaking phenomenon.
\emph{Secondly}, we obtain a family of sharp weighted second order Hydrogen
Uncertainty Principle, and prove the extremal functions are radial, which
extends the work of Duong and Nguyen [The sharp second order
Caffareli-Kohn-Nirenberg inequality and stability estimates for the sharp
second order uncertainty principle, arXiv:2102.01425].

</details>


### [20] [Statistical conservation laws for scalar model problems: Hierarchical evolution equations](https://arxiv.org/abs/2508.15359)
*Qian Huang,Christian Rohde*

Main category: math.AP

TL;DR: New hierarchical evolution equations for probability density functions (PDFs) of scalar conservation laws with random initial data


<details>
  <summary>Details</summary>
Motivation: To develop mathematical frameworks for representing and analyzing PDFs of solutions to scalar conservation laws with random initial conditions, building on similar approaches used for incompressible Navier-Stokes equations

Method: Developed two hierarchical frameworks: multi-point PDFs and single-point higher-order derivative PDFs to capture statistical correlations and guide closure strategies

Result: Created new hierarchical evolution equations that can represent the probability density functions for solutions of scalar conservation laws with random initial data

Conclusion: The developed hierarchical frameworks provide mathematical tools for analyzing statistical properties of scalar conservation laws with random initial conditions and offer guidance for closure strategies in such systems

Abstract: The probability density functions (PDFs) for the solution of the
incompressible Navier-Stokes equation can be represented by a hierarchy of
linear equations. This article develops new hierarchical evolution equations
for PDFs of a scalar conservation law with random initial data as a model
problem. Two frameworks are developed, including multi-point PDFs and
single-point higher-order derivative PDFs. These hierarchies capture
statistical correlations and guide closure strategies.

</details>


### [21] [Coupled Vlasov and non-Newtonian fluid dynamics: existence and large-time behavior](https://arxiv.org/abs/2508.15460)
*Young-Pil Choi,Jinwook Jung,Aneta Wróblewska-Kamińska*

Main category: math.AP

TL;DR: Global existence of weak solutions for coupled kinetic-non-Newtonian fluid system with power-law exponent p > 8/5, and large-time decay of modulated energy with algebraic (p>2) or exponential (6/5≤p≤2) rates under additional boundedness assumption.


<details>
  <summary>Details</summary>
Motivation: Study the interaction between particles described by Vlasov equation and incompressible power-law fluid through drag forces, analyzing existence and long-time behavior of solutions.

Method: Mathematical analysis of coupled kinetic-fluid system on periodic domain, proving global existence of weak solutions and establishing decay properties of modulated energy functional measuring velocity alignment deviation.

Result: Global weak solutions exist for all p > 8/5. Under uniform boundedness of particle density, modulated energy decays algebraically when p > 2 and exponentially when 6/5 ≤ p ≤ 2.

Conclusion: The fluid dissipation plays a crucial role in large-time dynamics, with different decay regimes depending on the power-law exponent, providing complete mathematical framework for this coupled system.

Abstract: We study a coupled kinetic-non-Newtonian fluid system on the periodic domain
${\mathbb T}^3$, where particles evolve by a Vlasov equation and interact with
an incompressible power-law fluid through a drag force. We prove the global
existence of weak solutions for all $p > \frac{8}{5}$, where $p > 1$ denotes
the power-law exponent of the fluid's stress-strain relation. Under an
additional uniform boundedness assumption on the particle density, we also
establish large-time decay of a modulated energy functional measuring deviation
from velocity alignment. The decay rate is algebraic when $p > 2$ and
exponential when $\frac{6}{5} \le p \le 2$, reflecting the role of fluid
dissipation in the large-time dynamics.

</details>


### [22] [A potential theory approach to the capillarity-driven Hele-Shaw problem](https://arxiv.org/abs/2508.15491)
*Bogdan-Vasile Matioc,Christoph Walker*

Main category: math.AP

TL;DR: Potential theory framework for quasistationary fluid flows in bounded geometries, applied to 2D Hele-Shaw problem with surface tension, proving local well-posedness, parabolic smoothing, and exponential stability of stationary solutions.


<details>
  <summary>Details</summary>
Motivation: To develop a mathematical framework using potential theory for analyzing quasistationary fluid flows governed by elliptic equations with constant coefficients in bounded geometries.

Method: Applied potential theory to the two-dimensional Hele-Shaw problem with surface tension, derived local well-posedness and parabolic smoothing in optimal function spaces, and established a generalized principle of linearized stability for abstract quasilinear parabolic problems.

Result: Successfully demonstrated that potential theory provides a powerful framework for fluid flow analysis, proved local well-posedness and parabolic smoothing for Hele-Shaw problem, and showed exponential stability of stationary solutions.

Conclusion: Potential theory offers an effective mathematical approach for studying quasistationary fluid flows, with applications yielding rigorous results including well-posedness, smoothing properties, and stability analysis for complex fluid dynamics problems.

Abstract: In this paper, we demonstrate that potential theory provides a powerful
framework for analyzing quasistationary fluid flows in bounded geometries,
where the bulk dynamics are governed by elliptic equations with constant
coefficients. This approach is illustrated by the two-dimensional Hele-Shaw
problem with surface tension, for which we derive local well-posedness and
parabolic smoothing in (almost) optimal function spaces. In addition, we
establish a generalized principle of linearized stability for a particular
class of abstract quasilinear parabolic problems, which enables us to show that
the stationary solutions to the Hele-Shaw problem are exponentially stable.

</details>


### [23] [Well-posedness and Rayleigh-Taylor instability of the two-phase periodic quasistationary Stokes flow](https://arxiv.org/abs/2508.15502)
*Daniel Böhme,Bogdan-Vasile Matioc*

Main category: math.AP

TL;DR: Analysis of two-phase quasistationary Stokes flow with surface tension and gravity effects, focusing on interface evolution, well-posedness, and stability properties including Rayleigh-Taylor instability.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of two-phase fluid interfaces with different viscosities and densities under surface tension and gravity effects, particularly focusing on stability properties and equilibrium solutions.

Method: Recast the mathematical model as a fully nonlinear nonlocal evolution equation for the interface function, analyze well-posedness and parabolic smoothing, study equilibrium solutions in subcritical Sobolev spaces.

Result: Established well-posedness and parabolic smoothing properties, demonstrated Rayleigh-Taylor instability of small finger-shaped equilibria, and determined that stability of flat interfaces depends on the sign of a specific parameter.

Conclusion: The study provides comprehensive mathematical analysis of two-phase Stokes flow interfaces, revealing important stability criteria and instability phenomena that depend on fluid properties and interface geometry.

Abstract: We study the two-phase, horizontally periodic, quasistationary Stokes flow in
two dimensions driven by surface tension and gravity effects in the general
context of fluids with (possibly) different viscosities and densities. The
sharp interface which separates the fluids is assumed to be the graph of a
periodic function. The mathematical model is then recast as a fully nonlinear
and nonlocal evolution equation involving only the function parametrizing the
interface. Our main results include well-posedness and a parabolic smoothing
property, as well as a study of equilibrium solutions in subcritical Sobolev
spaces. In particular, we establish the Rayleigh-Taylor instability of small,
finger-shaped equilibria and prove that the stability properties of flat
interfaces depend on the sign of a certain parameter.

</details>


### [24] [Maz'ya-type bounds for sharp constants in fractional Poincaré-Sobolev inequalities](https://arxiv.org/abs/2508.15564)
*Francesco Bozzola,Matteo Talluri*

Main category: math.AP

TL;DR: Sharp estimates for fractional Poincaré-Sobolev inequalities using nonlocal capacitary extension of inradius, with new Maz'ya-Poincaré inequality and Poincaré-Wirtinger estimates.


<details>
  <summary>Details</summary>
Motivation: Extend previous local results by Maz'ya-Shubin and Brasco to fractional case, establishing sharp constants and limiting behaviors for fractional differentiability orders.

Method: Prove new Maz'ya-Poincaré inequality, develop fractional Poincaré-Wirtinger estimates, analyze sharp limiting behaviors with respect to fractional order.

Result: Obtain sharp estimates for fractional Poincaré-Sobolev constants, new embedding criterion for homogeneous Sobolev spaces, optimal characterization of fractional Cheeger's constant positivity.

Conclusion: Novel framework for fractional inequalities with sharp constants, applicable to fractional Laplacian eigenvalues and providing fundamental insights into fractional Sobolev embeddings.

Abstract: We prove estimates for the sharp constants in fractional Poincar\'e-Sobolev
inequalities associated to an open set, in terms of a nonlocal capacitary
extension of its inradius. This work builds upon previous results obtained in
the local case by Maz'ya and Shubin and by the first author and Brasco. We rely
on a new Maz'ya-Poincar\'e inequality and, incidentally, we also prove new
fractional Poincar\'e-Wirtinger-type estimates. These inequalities display
sharp limiting behaviours with respect to the fractional order of
differentiability. As a byproduct, we obtain a new criterion for the embedding
of the homogeneous Sobolev space $\mathcal{D}^{s,p}_0(\Omega)$ in
$L^q(\Omega)$, valid in the subcritical regime and for $p \le q < p^*_s$. Our
results are new even for the first eigenvalue of the fractional Laplacian and
contain an optimal characterization for the positivity of the fractional
Cheeger's constant.

</details>


### [25] [Strichartz estimates for higher order Schrödinger equations with Partial regular initial data](https://arxiv.org/abs/2508.15670)
*Vishvesh Kumar,Shyam Swarup Mondal,Iswarya Sitiraju,Manli Song*

Main category: math.AP

TL;DR: Refined Strichartz estimates for higher-order Schrödinger equations with partially regular initial data, extended to Dunkl Schrödinger equations with new stationary phase method adaptation.


<details>
  <summary>Details</summary>
Motivation: To establish Strichartz estimates for Schrödinger equations where initial data only has regularity in a subset of spatial variables, and extend this analysis to the more complex Dunkl setting which lacks standard analytical tools.

Method: Develop refined Strichartz estimates for partial regularity cases, then extend to Dunkl Schrödinger equations by creating a new stationary phase method adaptation specifically for Dunkl analysis framework.

Result: Successfully established Strichartz estimates for higher-order Schrödinger equations with partial regularity and applied them to prove well-posedness of nonlinear equations. Extended results to Dunkl setting by overcoming the stationary phase method limitation.

Conclusion: The paper provides significant advances in understanding Schrödinger equations with partial regularity and extends the analysis to Dunkl framework, offering new tools and results for both classical and generalized settings.

Abstract: In this paper, we establish refined Strichartz estimates for higher-order
Schr\"odinger equations with initial data exhibiting partial regularity. By
partial regularity, we mean that the initial data are not required to have full
Sobolev regularity but only regularity with respect to a subset of the spatial
variables. As an application of these estimates, we investigate the
well-posedness of nonlinear Schr\"odinger equations with power-type
nonlinearities. In addition, we extend our analysis to the Dunkl Schr\"odinger
equations under partial regularity, defined with respect to two distinct root
systems. This extension poses significant challenges, mainly due to the lack of
a suitable stationary phase method in the Dunkl setting. To overcome this
difficulty, we develop a new result that provides an adaptation of the
stationary phase method to the framework of Dunkl analysis.

</details>


### [26] [Existence of hyperbolic blow-up to the generalized quasi-geostrophic equation](https://arxiv.org/abs/2508.15708)
*Lucas C. F. Ferreira,Ricardo M. M. Guimarães*

Main category: math.AP

TL;DR: Analysis of blow-up solutions for generalized surface quasi-geostrophic equation with hyperbolic saddle geometry, showing singularity formation in Hölder spaces.


<details>
  <summary>Details</summary>
Motivation: To investigate singularity formation in the generalized surface quasi-geostrophic equation for the more singular parameter range β∈(1,2), extending previous work on classical SQG equations.

Method: Uses hyperbolic framework introduced by Córdoba (1998), assuming level sets contain hyperbolic saddle geometry with specific conditions at origin. Analyzes geometric degeneration through collapse of saddle opening angle.

Result: Proves existence of blow-up time T* where opening angle collapses, provides lower bound for T*, and shows blow-up of Hölder norm ||θ(t)||_C^σ for σ∈(0,β-1) as t→T*.

Conclusion: First rigorous proof of singularity formation (finite or infinite time) for smooth solutions to gSQG equation, demonstrating geometric degeneration leads to Hölder norm blow-up.

Abstract: In this work, we investigate the blow-up of solutions to the generalized
surface quasi-geostrophic (gSQG) equation in $\mathbb{R}^{2}$, within the more
singular range $\beta\in(1,2)$ for the coupling of the velocity field. This
behavior is studied under a hyperbolic setting based on the framework
originally introduced by C\'{o}rdoba (1998, Annals of Math. 148, 1135--52) for
the classical SQG equation. Assuming that the level sets of the solution
contains a hyperbolic saddle, and under suitable conditions on the solution at
the origin, we obtain the existence of a time
$T^{\ast}\in\mathbb{R}^{+}\cup\{\infty\}$ at which the opening angle of the
saddle collapses. Moreover, we derive a lower bound for the blow-up time
$T^\ast$. This geometric degeneration leads to the blow-up of the H\"{o}lder
norm $\Vert\theta(t)\Vert_{C^{\sigma}}$ as $t\rightarrow T^{\ast}$, for
$\sigma\in(0, \beta -1)$, showing the formation of singularity in the
H\"{o}lder space at time $T^{\ast}$. To the best of our knowledge, these are
the first results in the literature to rigorously prove the formation of a
singularity, whether in finite or infinite time, for a class of smooth
solutions to the gSQG equation.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [27] [GEN2: A Generative Prediction-Correction Framework for Long-time Emulations of Spatially-Resolved Climate Extremes](https://arxiv.org/abs/2508.15196)
*Mengze Wang,Benedikt Barthel Sorensen,Themistoklis Sapsis*

Main category: physics.comp-ph

TL;DR: GEN2 is a generative prediction-correction framework that combines Gaussian emulation with ML correction to efficiently forecast extreme climate event statistics across various emissions scenarios, enabling accurate extrapolation beyond training data distributions.


<details>
  <summary>Details</summary>
Motivation: Conventional Earth System Models are computationally expensive for generating large ensembles needed to quantify climate extreme risks across multiple emissions scenarios, requiring a more efficient and accurate approach.

Method: Two-step framework: 1) Conditional Gaussian emulator for prediction, 2) Non-Gaussian machine learning correction trained on reference data and emulated fields nudged toward reference to ensure robustness to chaos.

Result: Validated on historical ERA5 data and demonstrated extrapolation capabilities on future climate scenarios. When trained on single realization of one warming scenario, accurately predicts extreme event statistics in different scenarios beyond training data distribution.

Conclusion: GEN2 provides an efficient and accurate method for forecasting extreme climate event statistics, successfully extrapolating to different emissions scenarios while being robust to chaotic climate dynamics.

Abstract: Accurately quantifying the increased risks of climate extremes requires
generating large ensembles of climate realization across a wide range of
emissions scenarios, which is computationally challenging for conventional
Earth System Models. We propose GEN2, a generative prediction-correction
framework for an efficient and accurate forecast of the extreme event
statistics. The prediction step is constructed as a conditional Gaussian
emulator, followed by a non-Gaussian machine-learning (ML) correction step. The
ML model is trained on pairs of the reference data and the emulated fields
nudged towards the reference, to ensure the training is robust to chaos. We
first validate the accuracy of our model on historical ERA5 data and then
demonstrate the extrapolation capabilities on various future climate change
scenarios. When trained on a single realization of one warming scenario, our
model accurately predicts the statistics of extreme events in different
scenarios, successfully extrapolating beyond the distribution of training data.

</details>


### [28] [Bridging the Analog and the Probabilistic Computing Divide: Configuring Oscillator Ising Machines as P-bit Engines](https://arxiv.org/abs/2508.15234)
*E. M. H. E. B. Ekanayake,Nikhat Khan,Nikhil Shukla*

Main category: physics.comp-ph

TL;DR: Framework for configuring Oscillator Ising Machines as p-bit engines using harmonic injection techniques, creating synergies between two previously distinct optimization approaches.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between Oscillator Ising Machines and p-bit-based computing platforms, traditionally viewed as separate methods for solving combinatorial optimization problems.

Method: Novel interplay between first- and second harmonic injection to oscillators, enabling OIMs to function as p-bit engines. The approach is also applicable to other analog dynamical systems like Dynamical Ising Machine.

Result: Successfully demonstrated that OIMs can be configured as p-bit engines, identifying new synergies between the two methods and expanding application scope for OIMs.

Conclusion: The work provides a theoretically grounded framework that unifies OIMs and p-bit computing, broadening the applicability of oscillator-based systems for combinatorial optimization problems.

Abstract: Oscillator Ising Machines (OIMs) and probabilistic bit (p-bit)-based
computing platforms have emerged as promising paradigms for tackling complex
combinatorial optimization problems. Although traditionally viewed as distinct
approaches, this work presents a theoretically grounded framework for
configuring OIMs as p-bit engines. We demonstrate that this functionality can
be enabled through a novel interplay between first- and second harmonic
injection to the oscillators. Our work identifies new synergies between the two
methods and broadens the scope of applications for OIMs. We further show that
the proposed approach can be applied to other analog dynamical systems, such as
the Dynamical Ising Machine.

</details>


### [29] [The CP2K Program Package Made Simple](https://arxiv.org/abs/2508.15559)
*Marcella Iannuzzi,Jan Wilhelm,Frederick Stein,Augustin Bussy,Hossam Elgabarty,Dorothea Golze,Anna Hehn,Maximilian Graml,Stepan Marek,Beliz Sertcan Gökmen,Christoph Schran,Harald Forbert,Rustam Z. Khaliullin,Anton Kozhevnikov,Mathieu Taillefumier,Rocco Meli,Vladimir Rybkin,Martin Brehm,Robert Schade,Ole Schütt,Johann V. Pototschnig,Hossein Mirhosseini,Andreas Knüpfer,Dominik Marx,Matthias Krack,Jürg Hutter,Thomas D. Kühne*

Main category: physics.comp-ph

TL;DR: CP2K is an open-source software package for atomistic simulations across various systems, offering both quantum-mechanical and classical methods for computing static and dynamical properties.


<details>
  <summary>Details</summary>
Motivation: To provide a versatile simulation tool that can handle diverse atomistic systems from isolated molecules to complex materials and interfaces, making advanced computational methods accessible for practical applications.

Method: CP2K combines quantum-mechanical and classical simulation methods to compute both static and dynamical properties of atomistic systems, with a focus on practical implementation rather than theoretical foundations.

Result: The software enables simulations across a wide spectrum of systems including gas-phase molecules, functional materials, crystalline solids, amorphous glasses, and soft-matter systems in various states.

Conclusion: CP2K serves as a comprehensive and accessible tool for practical atomistic simulations, bridging the gap between theoretical concepts and real-world applications across diverse chemical and material systems.

Abstract: CP2K is a versatile open-source software package for simulations across a
wide range of atomistic systems, from isolated molecules in the gas phase to
low-dimensional functional materials and interfaces, as well as highly
symmetric crystalline solids, disordered amorphous glasses, and weakly
interacting soft-matter systems in the liquid state and in solution. This
review highlights CP2K's capabilities for computing both static and dynamical
properties using quantum-mechanical and classical simulation methods. In
contrast to the accompanying theory and code paper [J. Chem. Phys. 152, 194103
(2020)], the focus here is on the practical usage and applications of CP2K,
with underlying theoretical concepts introduced only as needed.

</details>


### [30] [Investigating the sliding behavior of graphene nanoribbons](https://arxiv.org/abs/2508.15587)
*Gourav Yadav,Aningi Mokhalingam,Roger A. Sauer,Shakti S. Gupta*

Main category: physics.comp-ph

TL;DR: FE model studies graphene nanoribbon-substrate interaction, revealing critical strain and length parameters affecting sliding behavior and strain transfer.


<details>
  <summary>Details</summary>
Motivation: To understand interlayer mechanics and strain transfer between graphene nanoribbons and substrates under biaxial deformations using computational modeling.

Method: Developed Euler-Bernoulli beam finite element model calibrated with molecular dynamics simulations using Kolmogorov-Crespi potential, focusing on boundary condition effects.

Result: Identified critical strain (ec) and length (Lc ≈10nm) parameters, found strain transfer linear up to ec then sudden decrease, sliding becomes dissipative beyond Ld ≈10nm, edge force saturates at ≥17nm length.

Conclusion: FE model validated with MD simulations (10% error), maximum transferable strain between 0.57%-1.15%, inertia significantly affects sliding behavior under different boundary conditions.

Abstract: This work presents a Euler-Bernoulli beam finite element (FE) model to study
the interlayer interaction mechanics of graphene nanoribbon (GNR) over a
graphene substrate. The FE model is calibrated using molecular dynamics (MD)
simulations employing the potential of Kolmogorov and Crespi. This study
focuses mainly on the effect of boundary conditions on sliding behavior and
strain transfer between layers when the substrate is subjected to uniform
biaxial deformations. The interlayer shearing or sliding behavior is found to
depend on the presence of critical parameters, namely, the applied strain to
the substrate and the length of the GNR. The FE results indicate that the
applied strain transferred from the substrate to the GNR varies linearly up to
a critical value ec beyond which it decreases suddenly. Further, ec is found to
appear beyond a critical GNR length, Le is approximately 10 nm. Furthermore, a
length parameter Ld is approximately 10 nm is computed, beyond which the
sliding of GNR is dissipative. Through FE simulations, it is also found that
for a GNR length is greater than or equal to 17 nm, the edge pulling force
saturates. Our results also highlight the importance of the inertia of GNR on
its sliding for different boundary conditions. It is also concluded that the
maximum strain that can be transferred to GNR lies between 0.57% and 1.15%. The
results of the FE approach align with MD simulations within an error of
approximately 10% that can be attributed to the choice of material parameters
and the simulation setup.

</details>


### [31] [Pseudo-spectral model of elastic-wave propagation through toothed-whale head anatomy, and implications for biosonar](https://arxiv.org/abs/2508.15739)
*Fawad Ali,Carlos García A.,Aida Hejazi-Nooghabi,Lapo Boschi*

Main category: physics.comp-ph

TL;DR: Numerical modeling reveals how toothed whales localize sound sources on the median plane without pinnae, using head anatomy to create unique waveform patterns at each ear.


<details>
  <summary>Details</summary>
Motivation: Toothed whales have exceptional sound localization abilities despite lacking pinnae, and the specific mechanisms enabling this performance remain unclear despite detailed anatomical studies.

Method: Used pseudo-spectral time domain (PSTD) numerical scheme to model 3D elastic wave propagation through toothed whale head anatomy based on CT scans (1.11mm voxel resolution), validated the solver, and simulated dolphin-like clicks at various elevation angles.

Result: Found that incoming sound can be localized via correlation analysis of the reverberated portion of time-domain waveforms recorded at the tympano-periotic complex locations, with unique patterns generated for different elevation angles.

Conclusion: Toothed whales leverage their head anatomy to create distinctive acoustic signatures at each ear, enabling sound source localization on the median plane through waveform correlation rather than relying on pinnae-based mechanisms.

Abstract: The sound-localization and, in particular, biosonar system of toothed whales
is exceptionally performant. How this is achieved is not clear, given that: (i)
toothed whales have no pinnae; (ii) while their auditory pathways have been
studied in detail, no specific feature apparently replacing the pinna has been
identified. In this study, we employ a pseudo-spectral time domain (PSTD)
numerical scheme to model three-dimensional elastic wave propagation through a
toothed-whale head including soft tissues. Computed tomography (CT) scans were
utilized to build a three-dimensional velocity-density model of the specimen's
head, parametrized on a high-resolution $1.11$ mm voxel grid. We first validate
our wave propagation solver, identifying a range of frequencies and spatial
scale lengths where the PSTD scheme captures the complexities of elastic wave
propagation through toothed-whale anatomy. We next focus on the toothed whale's
ability to locate sources on the median plane, where the role of anatomy is
crucial. A 45 kHz central frequency burst (dolphin-like click) was modeled and
directed at elevation angles from $-90^\circ$ to $+90^\circ$ in $5^\circ$ steps
along the midsagittal plane. We find that the incoming sound can be localized,
via correlation, from the reverberated portion of the time-domain waveforms
recorded at the tympano-periotic complex locations.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [32] [Simulation Studies of Resonant Excitation of Electron Bernstein Waves in Capacitive Discharges](https://arxiv.org/abs/2508.15269)
*Deepak Gautam,Sarveshwar Sharma,Igor Kaganovich,Bhooshan Paradkar*

Main category: physics.plasm-ph

TL;DR: Study of capacitive coupled plasma (CCP) discharges in mildly magnetized regime (1 ≤ f_ce/f_rf < 2) showing asymmetric density profiles and electron Bernstein wave excitation.


<details>
  <summary>Details</summary>
Motivation: To understand complex plasma dynamics in mildly magnetized CCP discharges where RF fields interact with external magnetic fields, particularly investigating asymmetric density distributions and wave phenomena.

Method: Used particle-in-cell Monte Carlo collision (PIC-MCC) numerical simulations to capture kinetic behavior of electrons and ions, including collisionless effects and sheath dynamics.

Result: Observed transition from symmetric to asymmetric plasma density profiles and back to symmetric at higher field strengths. Electron Bernstein waves were excited along steep density gradients and strongly correlated with discharge asymmetry, playing significant role in energy transport and electron heating.

Conclusion: Weak magnetic fields significantly shape plasma behavior in CCP discharges, with wave-particle interactions being crucial in magnetized conditions. Electron Bernstein waves are important for energy transport and heating in mildly magnetized regimes.

Abstract: The behavior of capacitive coupled plasma (CCP) discharges is investigated in
a mildly magnetized regime, defined by the condition 1 $\leq$ $f_{ce}/f_{rf}$
$\lt$ 2, where $f_{ce}$ and $f_{rf}$ are the cyclotron and radio-frequencies
(RF), respectively. This regime exhibits complex and distinctive plasma
dynamics due to the interplay between RF fields and the externally applied
magnetic field. Two prominent phenomena are observed in this regime. First, the
plasma density profile becomes asymmetric across the discharge, deviating from
the typical symmetric distribution seen in unmagnetized CCPs. Second, electron
Bernstein waves (EBWs), high-frequency electrostatic waves, are excited and
propagate within the bulk plasma, particularly along steep electron density
gradients. As the strength of the magnetic field increases within this regime,
the CCP discharge undergoes a transition from a symmetric configuration to an
asymmetric one, and then returns to a symmetric profile at higher field
strengths. Notably, the excitation and propagation of EBWs are strongly
correlated with the presence of discharge asymmetry and localized density
gradients. These waves play a significant role in energy transport and electron
heating under mildly magnetized conditions. To gain deeper insight into the
underlying physics, detailed numerical simulations are carried out using the
particle-in-cell Monte Carlo collision (PIC-MCC) technique. These simulations
capture the kinetic behavior of electrons and ions, including the collisionless
effects and sheath dynamics essential to understanding the excitation of EBWs
and the evolution of discharge symmetry. The study thus sheds light on the role
of weak magnetic fields in shaping plasma behavior and highlights the
importance of wave-particle interactions in magnetized CCPs.

</details>


### [33] [THz emission from multiple ionized plasma](https://arxiv.org/abs/2508.15462)
*Lucie Jurkovičová,David Štok,Caroline Juliano,Matyáš Staněk,Jaroslav Nejdl,Ondřej Hort*

Main category: physics.plasm-ph

TL;DR: Developed photocurrent model for high-intensity laser-gas THz generation explaining high conversion efficiency, achieved 0.2 mJ THz pulses with >1% efficiency.


<details>
  <summary>Details</summary>
Motivation: Need for high-energy THz pulses (hundreds of μJ to mJ level) for nonlinear interaction studies, but current methods are limited by material damage thresholds and incomplete understanding of laser-gas interaction mechanisms.

Method: Established photocurrent model accounting for high-ionization states of target gas in laser-driven plasma THz generation at high-intensity regime.

Result: Model shows excellent agreement with experimental observations, explains spectral/temporal phenomena, and achieves 0.2 mJ THz pulses with conversion efficiency exceeding 1% using Ti:sapphire laser.

Conclusion: The photocurrent model successfully explains high conversion efficiency in laser-gas THz generation and enables production of mJ-level THz pulses, advancing nonlinear THz interaction research.

Abstract: Studies employing nonlinear interactions of THz pulses are nowadays a
promising scientific research field. To capture these phenomena, THz pulses
with energy ranging from hundreds of \muJ to the mJ level are necessary.
However, techniques that provide pulses with such energy levels are still not
widely established. Upscaling methods of laser-solid interaction is limited by
the damage threshold of materials, while the mechanism of THz generation from
high intensity laser-gas interactions is not fully understood yet. Here, we
establish the photocurrent model of laser-driven plasma THz generation in the
high-intensity regime by accounting for high-ionization states of the target
gas. Our model shows excellent agreement with experimental observations,
provides a clear explanation of phenomena in both spectral and temporal
domains, and explains the high conversion efficiency from laser to THz. In the
experiments, we achieved a generation of 0.2 mJ THz pulses, driven by a
Ti:sapphire laser with a conversion efficiency exceeding 1 %.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [34] [Matrix-Weighted Campanato Spaces: Duality and Calderón--Zygmund Operators](https://arxiv.org/abs/2508.15195)
*Yiqun Chen,Dachun Yang,Wen Yuan*

Main category: math.FA

TL;DR: This paper introduces matrix-weighted Campanato spaces and establishes their duality with matrix-weighted Hardy spaces, providing equivalent characterizations and boundedness conditions for Calderón-Zygmund operators.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend the theory of weighted function spaces to the matrix-weighted setting, specifically establishing duality relationships between matrix-weighted Hardy spaces and newly defined Campanato spaces, which has applications in harmonic analysis and operator theory.

Method: The authors use reducing operators of matrix weights to define matrix-weighted Campanato spaces. They apply atomic and finite atomic characterizations of matrix-weighted Hardy spaces to prove duality results. They also analyze boundedness conditions for modified Calderón-Zygmund operators.

Result: The main result shows that for p ∈ (0,1], the dual space of the matrix-weighted Hardy space H^p_W is precisely the matrix-weighted Campanato space L_{p,q,s,W}. The paper also provides necessary and sufficient conditions for boundedness of Calderón-Zygmund operators on both spaces.

Conclusion: The work establishes fundamental duality relationships in matrix-weighted function spaces and provides complete characterizations of boundedness for important operators, extending classical results to the matrix-weighted setting and opening new avenues in harmonic analysis.

Abstract: Let $p\in(0,\infty)$, $q\in[1,\infty)$, $s\in\mathbb Z_+$, and $W$ be an
$A_p$-matrix weight, which in the scalar case is exactly a Muckenhoupt
$A_{\max\{1,p\}}$ weight. In this article, by using the reducing operators of
$W$, we introduce matrix-weighted Campanato spaces $\mathcal L_{p,q,s,W}$. When
$p\in(0,1]$, applying the atomic and the finite atomic characterizations of the
matrix-weighted Hardy space $H^p_W$, we prove that the dual space of $H^p_W$ is
precisely $\mathcal L_{p,q,s,W}$, which further induces several equivalent
characterizations of $\mathcal L_{p,q,s,W}$. In addition, we obtain a necessary
and sufficient condition for the boundedness of modified Calder\'on--Zygmund
operators on $\mathcal L_{p,q,s,W}$ with $p\in(0,\infty)$, which, combined with
the duality, further gives a necessary and sufficient condition for the
boundedness of Calder\'on--Zygmund operators on $H^p_W$ with $p\in(0,1]$.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [35] [Generative Neural Operators of Log-Complexity Can Simultaneously Solve Infinitely Many Convex Programs](https://arxiv.org/abs/2508.14995)
*Anastasis Kratsios,Ariel Neufeld,Philipp Schmocker*

Main category: cs.LG

TL;DR: This paper bridges the theory-practice gap for neural operators by showing that generative equilibrium operators (GEOs) can approximate solutions to convex optimization problems with logarithmic parameter growth in error, rather than the unrealistic worst-case bounds suggested by universal approximation theorems.


<details>
  <summary>Details</summary>
Motivation: There is a significant disconnect between theoretical worst-case parameter bounds for neural operators (which suggest unrealistically large parameter requirements) and experimental evidence showing their practical effectiveness. This paper aims to close this gap for a specific class of neural operators.

Method: The authors use generative equilibrium operators (GEOs) with finite-dimensional deep equilibrium layers to solve families of convex optimization problems over separable Hilbert spaces. The inputs are smooth convex loss functions, and outputs are approximate solutions to the optimization problems.

Result: The paper demonstrates that when input losses lie in suitable infinite-dimensional compact sets, GEOs can uniformly approximate solutions with arbitrary precision, requiring only logarithmic growth in rank, depth, and width relative to the approximation error. Experimental validation on nonlinear PDEs, stochastic optimal control, and financial hedging problems confirms both theoretical results and trainability.

Conclusion: This work successfully bridges the theory-practice gap for neural operators by providing realistic parameter bounds for GEOs, showing they can achieve high precision approximations with manageable computational requirements, making them practically viable for solving families of convex optimization problems.

Abstract: Neural operators (NOs) are a class of deep learning models designed to
simultaneously solve infinitely many related problems by casting them into an
infinite-dimensional space, whereon these NOs operate. A significant gap
remains between theory and practice: worst-case parameter bounds from universal
approximation theorems suggest that NOs may require an unrealistically large
number of parameters to solve most operator learning problems, which stands in
direct opposition to a slew of experimental evidence. This paper closes that
gap for a specific class of {NOs}, generative {equilibrium operators} (GEOs),
using (realistic) finite-dimensional deep equilibrium layers, when solving
families of convex optimization problems over a separable Hilbert space $X$.
Here, the inputs are smooth, convex loss functions on $X$, and outputs are the
associated (approximate) solutions to the optimization problem defined by each
input loss.
  We show that when the input losses lie in suitable infinite-dimensional
compact sets, our GEO can uniformly approximate the corresponding solutions to
arbitrary precision, with rank, depth, and width growing only logarithmically
in the reciprocal of the approximation error. We then validate both our
theoretical results and the trainability of GEOs on three applications: (1)
nonlinear PDEs, (2) stochastic optimal control problems, and (3) hedging
problems in mathematical finance under liquidity constraints.

</details>


### [36] [Hybrid Least Squares/Gradient Descent Methods for DeepONets](https://arxiv.org/abs/2508.15394)
*Jun Choi,Chang-Ock Lee,Minam Moon*

Main category: cs.LG

TL;DR: Hybrid LS/gradient descent method to accelerate DeepONet training by decomposing large linear system into smaller branch and trunk subproblems.


<details>
  <summary>Details</summary>
Motivation: DeepONet's output is linear wrt last layer parameters, making LS optimization possible, but direct LS solve is infeasible due to large system size from branch-trunk input combinations.

Method: Decompose large LS system into two smaller subproblems for branch and trunk networks, solve separately. Generalizes to L^2 loss with regularization, including physics-informed unsupervised learning.

Result: Efficient training acceleration method that makes LS optimization feasible by avoiding direct solution of prohibitively large linear system.

Conclusion: Proposed hybrid approach enables practical LS optimization for DeepONet training through decomposition strategy, extending to regularized and physics-informed loss cases.

Abstract: We propose an efficient hybrid least squares/gradient descent method to
accelerate DeepONet training. Since the output of DeepONet can be viewed as
linear with respect to the last layer parameters of the branch network, these
parameters can be optimized using a least squares (LS) solve, and the remaining
hidden layer parameters are updated by means of gradient descent form. However,
building the LS system for all possible combinations of branch and trunk inputs
yields a prohibitively large linear problem that is infeasible to solve
directly. To address this issue, our method decomposes the large LS system into
two smaller, more manageable subproblems $\unicode{x2014}$ one for the branch
network and one for the trunk network $\unicode{x2014}$ and solves them
separately. This method is generalized to a broader type of $L^2$ loss with a
regularization term for the last layer parameters, including the case of
unsupervised learning with physics-informed loss.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [37] [Interface fluctuations for $1$D stochastic Allen-Cahn equation -- singular regime](https://arxiv.org/abs/2508.15319)
*Weijun Xu,Shuhan Zhou*

Main category: math.PR

TL;DR: Analysis of interface fluctuations in 1D stochastic Allen-Cahn equation with half-derivative white noise, showing noise cancellation enables valid SDE derivation despite singular regime.


<details>
  <summary>Details</summary>
Motivation: To understand interface behavior in singular stochastic PDEs where half-derivative noise makes solutions distribution-valued, requiring renormalization and posing challenges for classical interface fluctuation theories.

Method: Study the 1D stochastic Allen-Cahn equation perturbed by half spatial derivative of spacetime white noise, using renormalization techniques and long-time scaling analysis for initial data near traveling wave solutions.

Result: For sufficiently small noise, solutions stay close to traveling wave family and interface location follows approximate diffusion process. Two infinite quantities from noise singularity and renormalization cancel each other, enabling valid SDE derivation in the limit.

Conclusion: Despite the singular nature of half-derivative noise, the magical cancellation of infinite quantities allows extension of classical interface fluctuation results to this challenging regime, providing mathematical validation for SDE descriptions of interface movement.

Abstract: We study interface fluctuations for the $1$D stochastic Allen-Cahn equation
perturbed by half a spatial derivative of the spacetime white noise. This half
derivative makes the solution distribution-valued, so that proper
renormalization is needed to make sense of the solution.
  We show that if the noise is sufficiently small, then an analogue of the
classical results by \cite{Fun95,BBDMP98} holds in this singular regime. More
precisely, for initial data close to the traveling wave solution of the
deterministic equation, under proper long time scaling, the solution still
stays close to the family of traveling waves, and the interface location moves
according to an approximate diffusion process. There is one interesting
difference between our singular regime and the classical situation: even if the
solution and its approximate phase separation point are both well defined, the
intended diffusion describing the movement of the canonical candidate of the
phase point is not (even for fixed $\eps$). Two infinite quantities arise from
the derivation of such an SDE, one due to singularity of the noise, and the
other from renormalization. Magically, it turns out that they cancel out each
other, thus making the derivation of the interface SDE valid in the $\eps
\rightarrow 0$ limit.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [38] [Future Stability of Tilted Two-Fluid Bianchi I Spacetimes](https://arxiv.org/abs/2508.15155)
*Grigorios Fournodavlos,Elliot Marshall,Todd A. Oliynyk*

Main category: gr-qc

TL;DR: Nonlinear stability analysis of tilted two-fluid Bianchi I solutions in Einstein-Euler equations with cosmological constant and specific equation of state parameters.


<details>
  <summary>Details</summary>
Motivation: To establish the future nonlinear stability of cosmological solutions involving two fluids with tilted velocities in Bianchi I spacetimes, which is important for understanding the long-term behavior of such cosmological models.

Method: Analysis of Einstein-Euler equations with positive cosmological constant and linear equations of state for two fluids, focusing on tilted Bianchi I solutions with specific parameter ranges.

Result: Demonstrated nonlinear stability to the future for tilted two-fluid Bianchi I solutions when the equation of state parameters satisfy 1/3 < K < 5/7 for both fluids.

Conclusion: The tilted two-fluid Bianchi I cosmological models are nonlinearly stable in the future direction under the specified parameter constraints, providing important insights into the stability properties of multi-fluid cosmological scenarios.

Abstract: We establish the nonlinear stability to the future of tilted two-fluid
Bianchi I solutions to the Einstein-Euler equations with positive cosmological
constant and linear equations of state
$p_{(\mathfrak{a})}=K_{(\mathfrak{a})}\rho_{(\mathfrak{a})}$,
$\mathfrak{a}\in\{1,2\}$, where $\frac{1}{3}<K_{(\mathfrak{a})}<\frac{5}{7}$.

</details>


### [39] [Future stability of solutions of the Einstein-nonlinear scalar field system with decelerated expansion](https://arxiv.org/abs/2508.15303)
*Louie Bernhardt*

Main category: gr-qc

TL;DR: Future stability of FLRW spacetimes with exponential scalar field potential is proven for decelerated expansion parameters p in (2/3,1), showing geodesic completeness and convergence to homogeneity.


<details>
  <summary>Details</summary>
Motivation: To establish mathematical stability of cosmological solutions to Einstein equations with nonlinear scalar fields, particularly FLRW spacetimes with exponential potentials that undergo decelerated expansion.

Method: Decompose metric and scalar field perturbations into spatial averages and oscillatory remainders with zero average. Analyze initial data sufficiently close to FLRW data and prove future stability properties.

Result: For each p in (2/3,1), the corresponding FLRW spacetime is future-stable. Perturbed solutions remain close to FLRW, are future-causal geodesically complete, and metric/scalar field components converge to spatially homogeneous functions as t→∞.

Conclusion: FLRW spacetimes with exponential scalar field potential and decelerated expansion (p in (2/3,1)) are mathematically stable against small perturbations, maintaining key cosmological properties and converging to homogeneity over time.

Abstract: We study solutions to the Einstein equations coupled to a nonlinear scalar
field with exponential potential. This system admits
Friedmann-Lema\^itre-Robertson-Walker solutions undergoing decelerated
expansion, with $\mathbb{T}^3$ spatial topology and scale factor $a(t) = t^p$
for $1/3 < p < 1$. For each $p \in (2/3,1)$, we prove that the corresponding
FLRW spacetime is future-stable as a solution to the Einstein-nonlinear scalar
field system. Given initial data on a spacelike hypersurface that is
sufficiently close to the FLRW data, we show the resulting solution is
future-causal geodesically complete, and remains close to the FLRW solution for
all time. Moreover, we show the perturbed metric components and scalar field
converge to spatially homogeneous functions as $t \rightarrow \infty$. A key
feature of our analysis is the decomposition of the metric and scalar field
perturbations into their spatial averages and oscillatory remainders with zero
average.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [40] [Trotter-based quantum algorithm for solving transport equations with exponentially fewer time-steps](https://arxiv.org/abs/2508.15691)
*Julien Zylberman,Thibault Fredon,Nuno F. Loureiro,Fabrice Debbasch*

Main category: quant-ph

TL;DR: Quantum algorithm for simulating multidimensional transport PDEs using state preparation, evolution with high-order finite differences and Trotterization, and measurement, showing improved efficiency with vector-norm analysis.


<details>
  <summary>Details</summary>
Motivation: To address the open question of quantum computers' capability in simulating physical phenomena and solving PDEs, particularly focusing on the fundamental multidimensional transport equation with variable coefficients.

Method: Three-step quantum numerical scheme: quantum state preparation, evolution combining high-order centered finite difference with time-splitting via product formula approximations (Trotterization), and measurement of observables with novel vector-norm error analysis.

Result: Vector-norm analysis provides similar accuracy with exponentially fewer time steps than operator-norm approaches, reducing computational resources. Efficient quantum circuits and numerical simulations confirm the scaling, with real hardware results for 1D convection and non-linear ODE solutions.

Conclusion: Provides a practical framework for efficient quantum simulation of transport phenomena with applications in plasma physics, gas dynamics, and chaotic systems, demonstrating significant resource reduction through vector-norm analysis.

Abstract: The extent to which quantum computers can simulate physical phenomena and
solve the partial differential equations (PDEs) that govern them remains a
central open question. In this work, one of the most fundamental PDEs is
addressed: the multidimensional transport equation with space- and
time-dependent coefficients. We present a quantum numerical scheme based on
three steps: quantum state preparation, evolution, and measurement of relevant
observables. The evolution step combines a high-order centered finite
difference with a time-splitting scheme based on product formula
approximations, also known as Trotterization. Novel numerical analysis is
introduced to bound the different sources of error and we prove that, for the
product formula approximations, vector norm analysis guarantees similar
accuracy with exponentially fewer time steps than operator-norm-based
approaches, thereby significantly reducing the projected computational
resources. We also present efficient quantum circuits and numerical simulations
that confirm the predicted vector-norm scaling. We report results on real
quantum hardware for the one-dimensional convection equation, and solve a
non-linear ordinary differential equation via its associated Liouville
equation, a particular case of transport equations. This work provides a
practical framework for efficiently simulating transport phenomena on quantum
computers, with potential applications in plasma physics, molecular gas
dynamics and non-linear dynamical systems, including chaotic systems.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [41] [Relative periodic solutions in spatial Kepler problem with symmetric perturbation](https://arxiv.org/abs/2508.15209)
*Xijun Hu,Zhiwen Qiao,Guowei Yu*

Main category: math.DS

TL;DR: Existence of infinitely many relative periodic solutions and a unique z-symmetric brake orbit in perturbed spatial Kepler problems with rotational and reflection symmetries under small perturbations.


<details>
  <summary>Details</summary>
Motivation: To study the spatial Kepler problem under perturbations that maintain rotational symmetry and reflection symmetry about a plane perpendicular to the rotational axis, extending classical results to more complex gravitational systems.

Method: Apply recent results from CHHL23 combined with Franks Theorem to analyze compact energy surfaces under small perturbations with specific technical conditions. Also demonstrates existence of z-symmetric brake orbits forming hopf links.

Result: Proves existence of infinitely many relative periodic solutions in compact energy surfaces for sufficiently small perturbations. Shows existence of unique z-symmetric brake orbit forming hopf link with plane relative periodic solutions.

Conclusion: The results apply to satellite motion around ellipsoids with uniform mass distribution and n-pyramidal problems with specific mass configurations, providing new insights into periodic solutions in symmetric perturbed Kepler systems.

Abstract: We study the spatial Kepler problem under a perturbation satisfying both
rotational symmetry and reflection symmetry with respect to a plane
perpendicular to the rotational axis. By applying recent results from
\cite{CHHL23} combined with Franks Theorem, we prove the existence of
infinitely many relative periodic solutions contained in compact energy surface
when the perturbation is sufficiently small and certain technical conditions
hold. In addition, we also demonstrate the existence of a unique $z$-symmetric
brake orbit which forms a hopf link with a plane relative periodic solutions
contained in compact energy surface only requires the perturbation sufficiently
small. Our results apply to the motion of a satellite around an ellipsoid with
uniform mass distribution and to the $n$-pyramidal problem with one point mass
moving along $z$-axis and other $n$ equal masses forming a regular $n$-gon
perpendicular to the $z$-axis at all times.

</details>
