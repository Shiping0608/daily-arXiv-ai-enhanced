{"id": "2508.16032", "pdf": "https://arxiv.org/pdf/2508.16032", "abs": "https://arxiv.org/abs/2508.16032", "authors": ["Yan Shen", "Jingrun Chen", "Keke Wu"], "title": "A Hybrid Discontinuous Galerkin Neural Network Method for Solving Hyperbolic Conservation Laws with Temporal Progressive Learning", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "For hyperbolic conservation laws, traditional methods and physics-informed\nneural networks (PINNs) often encounter difficulties in capturing sharp\ndiscontinuities and maintaining temporal consistency. To address these\nchallenges, we introduce a hybrid computational framework by coupling\ndiscontinuous Galerkin (DG) discretizations with a temporally progressive\nneural network architecture. Our method incorporates a structure-preserving\nweak-form loss -- combining DG residuals and Rankine-Hugoniot jump conditions\n-- with a causality-respecting progressive training strategy. The proposed\nframework trains neural networks sequentially across temporally decomposed\nsubintervals, leveraging pseudo-label supervision to ensure temporal coherence\nand solution continuity. This approach mitigates error accumulation and\nenhances the model's capacity to resolve shock waves and steep gradients\nwithout explicit limiters. Besides, a theoretical analysis establishes error\nbounds for the proposed framework, demonstrating convergence toward the\nphysical solution under mesh refinement and regularized training. Numerical\nexperiments on Burgers and Euler equations show that our method consistently\noutperforms standard PINNs, PINNs-WE, and first-order DG schemes in both\naccuracy and robustness, particularly in capturing shocks and steep gradients.\nThese results highlight the promise of combining classical discretization\ntechniques with machine learning to develop robust and accurate solvers for\nnonlinear hyperbolic systems.", "AI": {"tldr": "Hybrid framework combining discontinuous Galerkin discretizations with progressive neural networks for hyperbolic conservation laws, achieving better shock capture and temporal consistency than standard methods.", "motivation": "Traditional methods and PINNs struggle with capturing sharp discontinuities and maintaining temporal consistency in hyperbolic conservation laws.", "method": "Couples DG discretizations with temporally progressive neural network architecture using structure-preserving weak-form loss (DG residuals + Rankine-Hugoniot conditions) and causality-respecting progressive training across temporal subintervals.", "result": "Outperforms standard PINNs, PINNs-WE, and first-order DG schemes in accuracy and robustness for Burgers and Euler equations, particularly in shock and steep gradient capture.", "conclusion": "Combining classical discretization techniques with machine learning shows promise for developing robust and accurate solvers for nonlinear hyperbolic systems."}}
{"id": "2508.16060", "pdf": "https://arxiv.org/pdf/2508.16060", "abs": "https://arxiv.org/abs/2508.16060", "authors": ["Aussie Greene", "Larry L. Schumaker"], "title": "Using the Immersed Penalized Boundary Method with Splines to Solve PDE's on Curved Domains in 3D", "categories": ["math.NA", "cs.NA", "65D07 (Primary), 65N99 (Secondary)"], "comment": "Submitted to International Journal for Numerical Methods in\n  Engineering on 5/27/2025. 25 pages, 5 figures", "summary": "Second-order elliptic boundary-value problems defined on curved domains in 2D\nand 3D arise frequently in practice. A lot of work has gone into developing\nnumerical methods for solving such problems. One of the newest and most\npromising methods is the $\\textit{immersed penalized boundary method}$ (IPBM)\nintroduced in [Schumaker, L. L., Solving elliptic PDE's on domains with curved\nboundaries with an immersed penalized boundary method, J. Sci. Comp. ${\\bf\n80(3)}$ (2019), 1369--1394]. For a comprehensive discussion of the use of these\nmethods with various bivariate spline spaces, see the recent book [Schumaker,\nL. L.: $\\textit{Spline Functions: More Computational Methods}$, SIAM\n(Philadelphia), 2024]. The purpose of this paper is to show how to use IPBM\nmethods with trivariate spline spaces to solve boundary-value problems on\ncurved domains in 3D.", "AI": {"tldr": "This paper extends the immersed penalized boundary method (IPBM) to trivariate spline spaces for solving 3D elliptic boundary-value problems on curved domains.", "motivation": "Second-order elliptic boundary-value problems on curved 3D domains are common in practice, and there's a need for effective numerical methods to solve them. The IPBM method has shown promise for 2D problems, and this work aims to extend it to 3D.", "method": "The paper uses the immersed penalized boundary method (IPBM) with trivariate spline spaces to handle boundary-value problems on curved 3D domains.", "result": "The paper demonstrates how IPBM methods can be successfully applied to solve boundary-value problems in three-dimensional curved domains using trivariate spline spaces.", "conclusion": "IPBM methods with trivariate spline spaces provide an effective approach for solving elliptic PDEs on curved 3D domains, extending the successful 2D methodology to three dimensions."}}
{"id": "2508.16061", "pdf": "https://arxiv.org/pdf/2508.16061", "abs": "https://arxiv.org/abs/2508.16061", "authors": ["Pengsong Yin", "Wenjun YIng", "Yulin Zhang", "Han Zhou"], "title": "A kernel-free boundary integral method for elliptic interface problems on surfaces", "categories": ["math.NA", "cs.NA", "65N06, 35R01, 35J25"], "comment": "39 pages, 10 figures", "summary": "This work presents a generalized boundary integral method for elliptic\nequations on surfaces, encompassing both boundary value and interface problems.\nThe method is kernel-free, implying that the explicit analytical expression of\nthe kernel function is not required when solving the boundary integral\nequations. The numerical integration of single- and double-layer potentials or\nvolume integrals at the boundary is replaced by interpolation of the solution\nto an equivalent interface problem, which is then solved using a fast multigrid\nsolver on Cartesian grids. This paper provides detailed implementation of the\nsecond-order version of the kernel-free boundary integral method for elliptic\nPDEs defined on an embedding surface in $\\mathbb{R}^3$ and presents numerical\nexperiments to demonstrate the efficiency and accuracy of the method for both\nboundary value and interface problems.", "AI": {"tldr": "A kernel-free boundary integral method for solving elliptic equations on surfaces, eliminating the need for explicit kernel functions and using Cartesian grid multigrid solvers instead.", "motivation": "To develop a more efficient and accurate method for solving boundary value and interface problems for elliptic PDEs on surfaces without requiring explicit analytical kernel expressions.", "method": "Replaces numerical integration of layer potentials with interpolation of solutions to equivalent interface problems, solved using fast multigrid solvers on Cartesian grids. Second-order implementation for 3D surfaces.", "result": "The method demonstrates efficiency and accuracy for both boundary value and interface problems through numerical experiments.", "conclusion": "The kernel-free boundary integral method provides an effective approach for solving elliptic equations on surfaces, offering advantages over traditional methods that require explicit kernel functions."}}
{"id": "2508.15984", "pdf": "https://arxiv.org/pdf/2508.15984", "abs": "https://arxiv.org/abs/2508.15984", "authors": ["M. A. Serebryakov", "E. N. Nerush", "L. Ji", "X. Geng", "I. Yu. Kostyukov"], "title": "QED cascade initiation via reflection of a multipetawatt laser pulse from a self-organized parabolic plasma mirror", "categories": ["physics.plasm-ph", "physics.comp-ph"], "comment": "9 pages with 6 PDF figures", "summary": "The self-sustained or avalanche-type cascade is an intriguing prediction of\nstrong-field quantum electrodynamics (QED) that has yet to be observed in\nlaboratories. It is accompanied by the conversion of electromagnetic energy\ninto gamma photons and electron-positron ($e^-e^+$) pairs, whose number\nincreases exponentially over time. We investigate a simple configuration to\ninitiate a QED cascades: it is based on the superposition of an incident\nmultipetawatt laser pulse and its reflection from a solid target. The incident\nlaser pulse <<deforms>> the initially flat target surface, creating a parabolic\nmirror that focuses the reflected radiation. For the considered setup the\nthreshold laser power is about $7\\,\\text{PW}$. With a $27\\,\\text{PW}$ laser\npulse, positron production exhibits clear signatures of an avalanche-type\ncascade, including exponential growth and more than 15 positron generations\nwith similar energy spectra. Therefore, observing an avalanche-type QED cascade\ndoes not require the use of multiple laser channels with precise\nspatio-temporal synchronization, as previously supposed.", "AI": {"tldr": "A simple setup using a single multipetawatt laser pulse reflecting off a deformed solid target can initiate QED cascades at 7 PW threshold, with 27 PW producing clear avalanche signatures including exponential growth and 15+ positron generations.", "motivation": "To demonstrate a simpler method for observing self-sustained QED cascades without requiring complex multi-laser synchronization, making experimental observation more feasible.", "method": "Using superposition of an incident multipetawatt laser pulse and its reflection from a solid target that deforms into a parabolic mirror, focusing the reflected radiation to initiate QED cascades.", "result": "At 7 PW threshold power, cascade initiation occurs. With 27 PW laser pulse, clear avalanche signatures emerge: exponential growth, over 15 positron generations with similar energy spectra.", "conclusion": "Avalanche-type QED cascades can be observed using a single laser channel without precise spatio-temporal synchronization, simplifying experimental requirements compared to previous assumptions."}}
{"id": "2508.16163", "pdf": "https://arxiv.org/pdf/2508.16163", "abs": "https://arxiv.org/abs/2508.16163", "authors": ["Long Li", "Liang Ding"], "title": "$\\ell_{1}^{2}-\u03b7\\ell_{2}^{2}$ sparsity regularization for nonlinear ill-posed problems", "categories": ["math.NA", "cs.NA", "math.OC", "47A52", "G.1.6"], "comment": "33 pages, 3 figures", "summary": "In this study, we investigate the\n$\\left\\|\\cdot\\right\\|_{\\ell_{1}}^{2}-\\eta\\left\\|\\cdot\\right\\|_{\\ell_{2}}^{2}$\nsparsity regularization with $0< \\eta\\leq 1$, in the context of nonlinear\nill-posed inverse problems. We focus on the examination of the well-posedness\nassociated with this regularization approach. Notably, the case where $\\eta=1$\npresents weaker theoretical outcomes than $0< \\eta<1$, primarily due to the\nabsence of coercivity and the Radon-Riesz property associated with the\nregularization term. Under specific conditions pertaining to the nonlinearity\nof the operator $F$, we establish that every minimizer of the\n$\\left\\|\\cdot\\right\\|_{\\ell_{1}}^{2}-\\eta\\left\\|\\cdot\\right\\|_{\\ell_{2}}^{2}$\nregularization exhibits sparsity. Moreover, for the case where $0<\\eta<1$, we\ndemonstrate convergence rates of $\\mathcal{O}\\left(\\delta^{1/2}\\right)$ and\n$\\mathcal{O}\\left(\\delta\\right)$ for the regularized solution, concerning a\nsparse exact solution, under differing yet widely accepted conditions related\nto the nonlinearity of $F$. Additionally, we present the iterative half\nvariation algorithm as an effective method for addressing the\n$\\left\\|\\cdot\\right\\|_{\\ell_{1}}^{2}-\\eta\\left\\|\\cdot\\right\\|_{\\ell_{2}}^{2}$\nregularization in the domain of nonlinear ill-posed equations. Numerical\nresults provided corroborate the effectiveness of the proposed methodology.", "AI": {"tldr": "Analysis of \u2113\u2081\u00b2-\u03b7\u2113\u2082\u00b2 sparsity regularization for nonlinear ill-posed inverse problems, showing better theoretical results for 0<\u03b7<1 than \u03b7=1, with proven sparsity and convergence rates.", "motivation": "To investigate the well-posedness and effectiveness of \u2113\u2081\u00b2-\u03b7\u2113\u2082\u00b2 sparsity regularization in nonlinear ill-posed inverse problems, addressing limitations when \u03b7=1 and providing theoretical guarantees for sparsity and convergence.", "method": "Theoretical analysis of \u2113\u2081\u00b2-\u03b7\u2113\u2082\u00b2 regularization properties, examination of coercivity and Radon-Riesz properties, development of convergence rate proofs for 0<\u03b7<1, and proposal of iterative half variation algorithm for practical implementation.", "result": "Proved that all minimizers exhibit sparsity, established O(\u03b4\u00b9/\u00b2) and O(\u03b4) convergence rates for 0<\u03b7<1, showed weaker theoretical outcomes for \u03b7=1 due to lack of coercivity, and demonstrated numerical effectiveness of the proposed iterative algorithm.", "conclusion": "The \u2113\u2081\u00b2-\u03b7\u2113\u2082\u00b2 regularization with 0<\u03b7<1 provides strong theoretical guarantees for sparsity and convergence in nonlinear ill-posed inverse problems, outperforming the \u03b7=1 case, with practical implementation through the iterative half variation algorithm."}}
{"id": "2508.16208", "pdf": "https://arxiv.org/pdf/2508.16208", "abs": "https://arxiv.org/abs/2508.16208", "authors": ["Deepak Gautam", "Sarveshwar Sharma", "Igor Kaganovich", "Bhooshan Paradkar"], "title": "Resonantly Driven Electron Bernstein Waves in Magnetized Low-Pressure Capacitive Discharges", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The physics of capacitively coupled plasma (CCP) discharges is investigated\nin a mildly magnetized regime, defined by $1 \\le f_{ce}/f_{rf} < 2$, where\n$f_{ce}$ and $f_{rf}$ denote the electron cyclotron frequency and the applied\nradio-frequency (RF), respectively. A distinctive feature of this regime is the\nexcitation of electron Bernstein waves (EBWs) that propagate into the bulk\nplasma. As the applied magnetic field increases, notable changes in the\ndischarge characteristics occur, with EBWs observed to propagate along the\nplasma density gradient inside the bulk. The underlying physics of CCP\noperation in this regime is analyzed in detail using particle-in-cell Monte\nCarlo collisions (PIC-MCC) simulations.", "AI": {"tldr": "Investigation of capacitively coupled plasma discharges in mildly magnetized regime where electron Bernstein waves propagate into bulk plasma, analyzed using PIC-MCC simulations.", "motivation": "To understand the physics of CCP discharges in the mildly magnetized regime (1 \u2264 f_ce/f_rf < 2) where electron Bernstein waves are excited and propagate into the plasma bulk.", "method": "Using particle-in-cell Monte Carlo collisions (PIC-MCC) simulations to analyze the detailed physics of CCP operation in this specific magnetic field regime.", "result": "As magnetic field increases, notable changes in discharge characteristics occur with EBWs observed to propagate along plasma density gradient inside the bulk plasma.", "conclusion": "The mildly magnetized regime exhibits distinctive EBW excitation and propagation behavior that significantly impacts CCP discharge characteristics, requiring detailed simulation analysis."}}
{"id": "2508.15812", "pdf": "https://arxiv.org/pdf/2508.15812", "abs": "https://arxiv.org/abs/2508.15812", "authors": ["Karen Yagdjian"], "title": "Spherical solutions to the Klein-Gordon equation in the expanding universe", "categories": ["math.AP", "gr-qc", "math-ph", "math.MP", "quant-ph", "35Q40, 35Q75, 35C15, 81T20"], "comment": null, "summary": "We produce an explicit formula for the wave function of the spherically\nsymmetric fields emitted to the FLRW universe with the scale factor generated\nby the de Sitter universe. As an application of these explicitly written\nsolutions of the Klein-Gordon equation, we test the decay in time of the field\ngenerated by a pionic atom.", "AI": {"tldr": "Explicit wave function formula for spherically symmetric fields in FLRW universe with de Sitter-generated scale factor, applied to test decay of pionic atom field.", "motivation": "To derive explicit solutions for wave functions in cosmological contexts and apply them to study field decay phenomena in quantum systems.", "method": "Developed explicit formula for wave function of spherically symmetric fields in FLRW universe with scale factor from de Sitter universe, solving Klein-Gordon equation.", "result": "Obtained explicit solutions that can be used to analyze time decay behavior of fields, specifically demonstrated for pionic atom field decay.", "conclusion": "The explicit wave function solutions provide a valuable tool for studying field dynamics in cosmological settings and quantum decay processes."}}
{"id": "2508.15948", "pdf": "https://arxiv.org/pdf/2508.15948", "abs": "https://arxiv.org/abs/2508.15948", "authors": ["Chayanon Wichitrnithed", "Eirik Valseth", "Shintaro Bunya", "Ethan J. Kubatko", "Clint Dawson"], "title": "Coupled Continuous-Discontinuous Galerkin Finite Element Solver for Compound Flood Simulations", "categories": ["physics.comp-ph"], "comment": null, "summary": "Several recent tropical cyclones, e.g., Hurricane Harvey (2017), have lead to\nsignificant rainfall and resulting runoff. When the runoff interacts with storm\nsurge, the resulting floods can be greatly amplified and lead to effects that\ncannot be correctly modeled by simple superposition of its distinctive sources.\nIn an effort to develop accurate numerical simulations of runoff, surge, and\ncompounding floods, we develop a locally conservative coupled DG-CG\ndiscretization of the shallow water equations and integrate it into the\nAdvanced Circulation Model (ADCIRC). We also modify the continuity equation to\ninclude spatially and temporally variable rainfall into the model using\nparametric rainfall models. We demonstrate the capabilities of the scheme\nthough a sequence of physically relevant numerical tests, including small scale\ntest cases based on laboratory measurements and large scale experiments with\nHurricane Harvey in the Gulf of Mexico. The results highlight the conservation\nproperties and robustness of the developed method and show the potential of\ncompound flood modeling using our approach.", "AI": {"tldr": "A coupled DG-CG discretization method for shallow water equations is developed to accurately model compound flooding from tropical cyclones, integrating rainfall and runoff with storm surge.", "motivation": "Recent tropical cyclones like Hurricane Harvey (2017) have shown that runoff interacting with storm surge creates amplified flooding effects that cannot be modeled by simple superposition of individual flood sources, requiring more accurate numerical simulations.", "method": "Developed a locally conservative coupled Discontinuous Galerkin-Continuous Galerkin (DG-CG) discretization of shallow water equations integrated into ADCIRC, with modified continuity equation to include spatially and temporally variable rainfall using parametric rainfall models.", "result": "The method demonstrated conservation properties and robustness through numerical tests including small-scale laboratory-based cases and large-scale Hurricane Harvey experiments in the Gulf of Mexico, showing effective compound flood modeling capabilities.", "conclusion": "The developed coupled DG-CG approach shows strong potential for accurate compound flood modeling by effectively capturing the interaction between rainfall runoff and storm surge in tropical cyclone events."}}
{"id": "2508.16241", "pdf": "https://arxiv.org/pdf/2508.16241", "abs": "https://arxiv.org/abs/2508.16241", "authors": ["Theodore V. Gortsas"], "title": "Numerical solution of the time fractional nonlinear Fisher-KPP diffusion-reaction equation using the local domain boundary element method", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "comment": null, "summary": "The Fisher-KPP partial differential equation has been employed in science to\nmodel various biological, chemical, and thermal phenomena. Time fractional\nextensions of Fisher's equation have also appeared in the literature, aiming to\nmodel systems with memory. The solution of the time fractional Fisher-KPP\nequation is challenging due to the interplay between the nonlinearity and the\nnonlocality imposed by the fractional derivatives. An accurate method that for\nthe solution of time fractional diffusion problems is the Boundary Element\nMethod (BEM). The conventional BEM has a high computational cost and memory\nrequirements since it leads to dense coefficient matrices. For nonlinear\ntransient problems, its efficiency is further reduced due to the appearance of\nvolume integrals. In the present work an extension of the recently proposed\nLocal Domain Boundary Element Method (LD-BEM) is presented for the solution of\nnonlinear time fractional Fisher-KPP problems. The implemented numerical method\nis used to examine various two-dimensional problems related to the Fisher-KPP\nequation using different definitions of the fractional derivative.", "AI": {"tldr": "Extension of Local Domain Boundary Element Method (LD-BEM) for solving nonlinear time fractional Fisher-KPP equations in 2D problems with reduced computational cost compared to conventional BEM.", "motivation": "Time fractional Fisher-KPP equations model biological/chemical systems with memory effects, but solving them is challenging due to nonlinearity and fractional derivative nonlocality. Conventional BEM has high computational cost and memory requirements.", "method": "Extended Local Domain Boundary Element Method (LD-BEM) to handle nonlinear time fractional Fisher-KPP problems, addressing computational efficiency issues of conventional BEM.", "result": "Successfully implemented numerical method for examining various 2D Fisher-KPP problems using different fractional derivative definitions with improved computational efficiency.", "conclusion": "The LD-BEM extension provides an efficient computational approach for solving challenging nonlinear time fractional Fisher-KPP equations in two dimensions."}}
{"id": "2508.16533", "pdf": "https://arxiv.org/pdf/2508.16533", "abs": "https://arxiv.org/abs/2508.16533", "authors": ["Christopher Arran", "Stuart Morris", "Christopher P. Ridgers"], "title": "Bayesian Optimisation of Breit-Wheeler Pair Production in Simulated Laser Experiments", "categories": ["physics.plasm-ph"], "comment": "19 pages, 6 figures", "summary": "High laser intensities enable the production of electron-positron pairs from\nbright gamma rays passing through strong fields. Potentially the most promising\napproach for all-optical experiments in the near term uses dense but higher\ndivergence electron beams from laser wakefield acceleration to produce gamma\nrays through inverse Compton scattering. Achieving many-photon collisions\nbetween these gamma rays and the high intensity laser pulse in practice is\nextremely difficult, however, due to significant shot-to-shot jitter in laser\npointing and timing.\n  We model these practical difficulties using simulated Monte-Carlo\nexperiments. By using a more efficient algorithm for sampling infrequent pair\nproduction with particle splitting, we enable the exploration of a\nmulti-dimensional parameter space. Using Gaussian Process Regression we then\nefficiently find optimal conditions for maximising pair production by changing\nthe laser spot size, the energy in the colliding beam, and the stand-off\ndistance between the laser wakefield accelerator and the focus of the colliding\nlaser pulse. We find that the optimal stand-off distance increases with the\ndegree of laser jitter and that the best conditions for producing\nelectron-positron pairs are not the same as the best conditions for maximising\nthe energy in the gamma rays. With \\unit[100]{J} of laser energy, we estimate\nrates of pair production of around 1 pair per 100 electrons are achievable even\nwith jitter of 10s of microns and 10s of femtoseconds.", "AI": {"tldr": "Optimizing laser parameters for electron-positron pair production using Monte Carlo simulations and Gaussian Process Regression to overcome laser jitter challenges.", "motivation": "Laser wakefield acceleration produces gamma rays for pair production, but practical difficulties like laser pointing and timing jitter make many-photon collisions extremely challenging to achieve.", "method": "Used simulated Monte-Carlo experiments with efficient sampling algorithm for infrequent pair production, employed Gaussian Process Regression to explore multi-dimensional parameter space and find optimal conditions by varying laser spot size, colliding beam energy, and stand-off distance.", "result": "Optimal stand-off distance increases with laser jitter degree; best pair production conditions differ from optimal gamma ray energy conditions; with 100J laser energy, achievable rates of ~1 pair per 100 electrons even with 10s of microns and femtoseconds jitter.", "conclusion": "The methodology enables practical optimization of laser parameters for electron-positron pair production despite significant jitter, demonstrating feasibility of achieving measurable pair production rates in near-term all-optical experiments."}}
{"id": "2508.15961", "pdf": "https://arxiv.org/pdf/2508.15961", "abs": "https://arxiv.org/abs/2508.15961", "authors": ["Nikolaos Papadopoulos", "Thibaud Taillefumier"], "title": "Physical blowups via buffered time change in a mean-field neural network", "categories": ["math.AP", "math.DS", "math.PR", "60G99, 60K15, 35Q92, 35D30, 35K67, 45H99"], "comment": "70 pages, 4 figures", "summary": "Idealized networks of integrate-and-fire neurons with impulse-like\ninteractions obey McKean-Vlasov diffusion equations in the mean-field limit.\nThese equations are prone to blowups: for a strong enough interaction coupling,\nthe mean-field rate of interaction diverges in finite time with a finite\nfraction of neurons spiking simultaneously, thereby marking a macroscopic\nsynchronous event. Characterizing these blowup singularities analytically is\nthe key to understanding the emergence and persistence of spiking synchrony in\nmean-field neural models. Such a treatment is possible via time change\ntechniques for a Poissonian variation of the classically considered\nintegrate-and-fire dynamics. However, just as for shock solutions for nonlinear\nconservation laws, there are several admissible blowup solutions to the\ncorresponding McKean-Vlasov equations. Because of this ambiguity, it is unclear\nwhich notion of blowup solutions shall be adopted. Here, we unambiguously\ndefine physical blowup dynamics as solutions to a fixed-point problem bearing\non the time change associated to the McKean-Vlasov equation. To justify the\nphysicality of this formulation, we introduce a buffering mechanism that\nregularizes blowup dynamics, while satisfying the same conservation principles\nas the finite-dimensional particle-system dynamics. We then show that physical\nblowup dynamics are recovered from these regularized solutions in the limit of\nvanishing buffering. Our approach also shows that these physical solutions are\nunique, globally defined, and avoid the so-called eternal blowup phenomenon, as\nlong as the neurons exhibit nonzero, distributed refractory periods, a\nreasonable modeling assumption.", "AI": {"tldr": "The paper analyzes blowup singularities in mean-field neural models with integrate-and-fire neurons, proposing a physical definition for blowup solutions via time change techniques and showing uniqueness when neurons have distributed refractory periods.", "motivation": "To resolve ambiguity in admissible blowup solutions for McKean-Vlasov equations describing neural networks, as multiple solutions exist similar to shock solutions in nonlinear conservation laws, making it unclear which notion of blowup solutions should be adopted.", "method": "Define physical blowup dynamics as solutions to a fixed-point problem based on time change associated with McKean-Vlasov equations. Introduce a buffering mechanism that regularizes blowup dynamics while conserving principles of finite-dimensional particle systems, then recover physical solutions in vanishing buffering limit.", "result": "Physical blowup solutions are shown to be unique, globally defined, and avoid eternal blowup phenomenon when neurons exhibit nonzero, distributed refractory periods. The approach provides unambiguous characterization of blowup singularities.", "conclusion": "The proposed formulation unambiguously defines physical blowup dynamics for mean-field neural models, with uniqueness and global existence guaranteed under realistic modeling assumptions of distributed refractory periods, resolving previous ambiguities in blowup solution selection."}}
{"id": "2508.15967", "pdf": "https://arxiv.org/pdf/2508.15967", "abs": "https://arxiv.org/abs/2508.15967", "authors": ["M. Cianciosa", "D. Batchelor", "W. Elwasif"], "title": "graph framework: A Domain Specific Compiler for Building Physics Applications", "categories": ["physics.comp-ph"], "comment": "16 Pages, 5 Figures", "summary": "Modern supercomputers are increasingly relying on Graphic Processing Units\n(GPUs) and other accelerators to achieve exa-scale performance at reasonable\nenergy usage. The challenge of exploiting these accelerators is the\nincompatibility between different vendors. A scientific code written using CUDA\nwill not operate on a AMD gpu. Frameworks that can abstract the physics from\nthe accelerator kernel code are needed to exploit the current and future\nhardware. In the world of machine learning, several auto differentiation\nframeworks have been developed that have the promise of abstracting the math\nfrom the compute hardware. However in practice, these framework often lag in\nsupporting non-CUDA platforms. Their reliance on python makes them challenging\nto embed within non python based applications. In this paper we present the\ndevelopment of a graph computation framework which compiles physics equations\nto optimized kernel code for the central processing unit (CPUs), Apple GPUs,\nand NVidia GPUs. The utility of this framework will be demonstrated for a Radio\nFrequency (RF) ray tracing problems in fusion energy.", "AI": {"tldr": "A graph computation framework that compiles physics equations to optimized kernel code for CPUs, Apple GPUs, and NVIDIA GPUs, demonstrated on RF ray tracing in fusion energy.", "motivation": "Address hardware incompatibility issues between different GPU vendors and enable scientific codes to run across multiple accelerator platforms without vendor lock-in.", "method": "Developed a graph computation framework that abstracts physics equations from hardware-specific implementations, compiling them to optimized kernel code for multiple platforms including CPUs, Apple GPUs, and NVIDIA GPUs.", "result": "Created a framework capable of generating optimized kernel code for diverse hardware platforms, successfully demonstrated through application to Radio Frequency (RF) ray tracing problems in fusion energy research.", "conclusion": "The framework provides a solution to hardware vendor incompatibility problems, enabling scientific applications to leverage multiple accelerator platforms while maintaining performance and avoiding dependency on Python-based machine learning frameworks."}}
{"id": "2508.16564", "pdf": "https://arxiv.org/pdf/2508.16564", "abs": "https://arxiv.org/abs/2508.16564", "authors": ["Andres Galindo-Olarte", "Joseph Nakao", "Mirjeta Pasha", "Jing-Mei Qiu", "William Taitano"], "title": "A Nodal Discontinuous Galerkin Method with Low-Rank Velocity Space Representation for the Multi-Scale BGK Model", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "A novel hybrid algorithm is presented for the Boltzmann-BGK equation, in\nwhich a low-rank decomposition is applied solely in the velocity subspace,\nwhile a full-rank representation is maintained in the physical (position)\nspace. This approach establishes a foundation for extending modern low-rank\ntechniques to solve the Boltzmann equation in realistic settings, particularly\nwhere structured representations -- such as conformal geometries -- may not be\nfeasible in practical engineering applications. A nodal discontinuous Galerkin\nmethod is employed for spatial discretization, coupled with a low-rank\ndecomposition over the velocity grid, as well as implicit-explicit Runge-Kutta\nmethods for time integration. To handle the limit of vanishing collision time,\na multiscale implicit integrator based on an auxiliary moment equation is\nutilized. The algorithm's order of accuracy, reduced computational complexity,\nand robustness are demonstrated on a suite of canonical gas kinetics problems\nwith increasing complexity.", "AI": {"tldr": "Hybrid algorithm combining low-rank velocity decomposition with full-rank spatial representation for Boltzmann-BGK equation, using DG spatial discretization and IMEX time integration with multiscale handling.", "motivation": "Extend low-rank techniques to realistic Boltzmann equation settings where structured representations like conformal geometries are impractical in engineering applications.", "method": "Nodal discontinuous Galerkin for spatial discretization, low-rank decomposition over velocity grid, IMEX Runge-Kutta time integration, and multiscale implicit integrator using auxiliary moment equation for vanishing collision time.", "result": "Demonstrated algorithm's accuracy order, reduced computational complexity, and robustness on canonical gas kinetics problems with increasing complexity.", "conclusion": "Establishes foundation for applying modern low-rank techniques to solve Boltzmann equation in practical engineering scenarios without requiring structured geometric representations."}}
{"id": "2508.15879", "pdf": "https://arxiv.org/pdf/2508.15879", "abs": "https://arxiv.org/abs/2508.15879", "authors": ["Filipe S. Ribeiro", "Pedro D. S. Silva", "Rodolfo Casana", "Manoel M. Ferreira Jr"], "title": "On the hypothesis of a bi-isotropic plasma permeating the interstellar space", "categories": ["astro-ph.HE", "physics.plasm-ph"], "comment": "11 pages, 8 figures", "summary": "In this work, we study the propagation of electromagnetic waves in a\nmagnetized chiral plasma that pervades the interstellar space. The Maxwell\nequations, supplemented by bi-isotropic constitutive relations, are rewritten\nto describe a cold, uniform, and collisionless plasma model that yields new\ncollective electromagnetic modes for distinct pairs of refractive indices\nassociated with right- and left-handed circularly polarized waves. We have\ninvestigated the optical behavior through the rotatory power (RP) and dichroism\ncoefficient, reporting that the finite chiral parameter induces double RP sign\nreversal, an exotic optical signature that takes place in chiral dielectrics\nand rotating plasmas. In the low-frequency regime, a modified propagating\nhelicon with right-handed circular polarization is obtained. Next, supposing\nthat the interstellar medium behaves as a bi-isotropic cold plasma, we employ\nAstrophysical data of radio pulsars to achieve upper limits on the\nmagnetoelectric parameters magnitude. In particular, by using dispersion\nmeasure and rotation measure data from five pulsars, we constrain the magnitude\nof the chiral parameter to the order of $10^{-16}$ and $10^{-22}$,\nrespectively.", "AI": {"tldr": "Study of electromagnetic wave propagation in magnetized chiral plasma, revealing exotic optical signatures and constraining chiral parameter using pulsar data.", "motivation": "To understand electromagnetic wave behavior in interstellar magnetized chiral plasma and establish observational constraints on magnetoelectric parameters using astrophysical data.", "method": "Maxwell equations with bi-isotropic constitutive relations for cold uniform collisionless plasma model, analyzing rotatory power and dichroism coefficients, then applying astrophysical pulsar data for parameter constraints.", "result": "Finite chiral parameter induces double rotatory power sign reversal (exotic optical signature), modified right-handed helicon propagation at low frequencies, and chiral parameter constraints of order 10^-16 to 10^-22 from pulsar dispersion and rotation measures.", "conclusion": "Interstellar medium as bi-isotropic cold plasma exhibits unique electromagnetic modes with observable optical signatures, and astrophysical observations provide stringent upper limits on magnetoelectric chiral parameters."}}
{"id": "2508.15996", "pdf": "https://arxiv.org/pdf/2508.15996", "abs": "https://arxiv.org/abs/2508.15996", "authors": ["Guher Camliyurt", "Carlos E. Kenig"], "title": "Scattering for radial bounded solutions of focusing supercritical wave equations in four dimensions", "categories": ["math.AP"], "comment": null, "summary": "We consider the focusing wave equation with energy supercritical nonlinearity\nin dimension four. We prove that any radial solution that remains bounded in\nthe critical Sobolev space is global and scatters to free waves as $t \\to \\pm\n\\infty$.", "AI": {"tldr": "Global existence and scattering for radial solutions of focusing wave equation with energy supercritical nonlinearity in dimension 4, under boundedness in critical Sobolev space", "motivation": "Study the long-time behavior of solutions to energy supercritical wave equations, which are challenging due to the lack of conservation laws and potential finite-time blow-up", "method": "Analysis of radial solutions to the focusing wave equation with energy supercritical nonlinearity in 4D, using boundedness in critical Sobolev space as a key condition", "result": "Proves that any radial solution remaining bounded in the critical Sobolev space is global in time and scatters to free waves as time approaches positive and negative infinity", "conclusion": "Boundedness in the critical Sobolev space serves as a sufficient condition to ensure global existence and scattering behavior for radial solutions of energy supercritical wave equations in 4D"}}
{"id": "2508.16067", "pdf": "https://arxiv.org/pdf/2508.16067", "abs": "https://arxiv.org/abs/2508.16067", "authors": ["Teddy Koker", "Tess Smidt"], "title": "Training a Foundation Model for Materials on a Budget", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "Foundation models for materials modeling are advancing quickly, but their\ntraining remains expensive, often placing state-of-the-art methods out of reach\nfor many research groups. We introduce Nequix, a compact E(3)-equivariant\npotential that pairs a simplified NequIP design with modern training practices,\nincluding equivariant root-mean-square layer normalization and the Muon\noptimizer, to retain accuracy while substantially reducing compute\nrequirements. Built in JAX, Nequix has 700K parameters and was trained in 500\nA100-GPU hours. On the Matbench-Discovery and MDR Phonon benchmarks, Nequix\nranks third overall while requiring less than one quarter of the training cost\nof most other methods, and it delivers an order-of-magnitude faster inference\nspeed than the current top-ranked model. We release model weights and fully\nreproducible codebase at https://github.com/atomicarchitects/nequix", "AI": {"tldr": "Nequix is a compact E(3)-equivariant potential that achieves state-of-the-art accuracy with significantly reduced computational costs, requiring only 500 A100-GPU hours for training and offering fast inference speeds.", "motivation": "Foundation models for materials modeling are advancing but remain computationally expensive, making state-of-the-art methods inaccessible to many research groups due to high training costs.", "method": "Pairs a simplified NequIP design with modern training practices including equivariant root-mean-square layer normalization and the Muon optimizer, built in JAX with 700K parameters.", "result": "Ranks third overall on Matbench-Discovery and MDR Phonon benchmarks while requiring less than one quarter of the training cost of most other methods, with order-of-magnitude faster inference speed than the top-ranked model.", "conclusion": "Nequix demonstrates that compact models with efficient training practices can achieve competitive accuracy in materials modeling while dramatically reducing computational requirements, making advanced methods more accessible."}}
{"id": "2508.15951", "pdf": "https://arxiv.org/pdf/2508.15951", "abs": "https://arxiv.org/abs/2508.15951", "authors": ["Jacob Aguirre", "Diego Cifuentes", "Vincent Guigues", "Renato D. C. Monteiro", "Victor Hugo Nascimento", "Arnesh Sujanani"], "title": "A User Manual for cuHALLaR: A GPU Accelerated Low-Rank Semidefinite Programming Solver", "categories": ["math.OC", "cs.LG", "cs.MS", "cs.NA", "math.NA", "90C30, 65K10, 90C26, 90C60, 90C25"], "comment": null, "summary": "We present a Julia-based interface to the precompiled HALLaR and cuHALLaR\nbinaries for large-scale semidefinite programs (SDPs). Both solvers are\nestablished as fast and numerically stable, and accept problem data in formats\ncompatible with SDPA and a new enhanced data format taking advantage of Hybrid\nSparse Low-Rank (HSLR) structure. The interface allows users to load custom\ndata files, configure solver options, and execute experiments directly from\nJulia. A collection of example problems is included, including the SDP\nrelaxations of the Matrix Completion and Maximum Stable Set problems.", "AI": {"tldr": "Julia interface for HALLaR and cuHALLaR SDP solvers with support for SDPA and HSLR data formats", "motivation": "Provide a user-friendly Julia interface to leverage the speed and numerical stability of established HALLaR and cuHALLaR semidefinite programming solvers for large-scale problems", "method": "Developed a Julia-based interface that allows loading custom data files, configuring solver options, and executing experiments directly from Julia, with support for both SDPA-compatible formats and enhanced HSLR structure formats", "result": "Created a functional interface that includes example problems such as SDP relaxations of Matrix Completion and Maximum Stable Set problems, enabling users to work with large-scale SDPs efficiently", "conclusion": "The Julia interface successfully bridges the gap between powerful precompiled SDP solvers and the Julia ecosystem, making advanced semidefinite programming capabilities more accessible to researchers and practitioners"}}
{"id": "2508.16220", "pdf": "https://arxiv.org/pdf/2508.16220", "abs": "https://arxiv.org/abs/2508.16220", "authors": ["Yue Cao", "Kun Xue", "Si-Man Liu", "Zhong-Peng Li", "Li-Xiang Hu", "Xin-Yu Liu", "Zhen-Ke Dou", "Feng Wan", "Qian Zhao", "Tong-Pu Yu", "Jian-Xing Li"], "title": "Generating Cylindrical Vector \u03b3 Rays via Beam-Target Interactions: Towards Structured Light at High Energies", "categories": ["physics.optics", "physics.plasm-ph"], "comment": null, "summary": "Structured {\\gamma} rays, particularly cylindrical vector {\\gamma} rays,\noffer promising tools for sub-nuclear imaging and polarization-sensitive probes\nin fundamental research and applications, but conventional optical methods face\ngreat challenges at such photon energy. Here, we put forward a novel method\ngenerating such {\\gamma} rays through relativistic beam-target interactions.\nFor instance, radially polarized {\\gamma} rays can be generated by using a\ndense electron beam striking a multifoil target. We find that the radial\npolarization is transferred from the generated coherent transition radiation\n(CTR) fields to $\\gamma$ photons through nonlinear Compton scattering, with the\nhigh polarization preserved by phase matching. Three-dimensional spin-resolved\nsimulations demonstrate radial polarization degrees approaching 60\\%.\nFurthermore, these {\\gamma} rays can decay into azimuthally spin-polarized\npositrons via the nonlinear Breit-Wheeler process, with their spins aligning\nalong the CTR magnetic field. Our work extends the concept of structured light\ninto the {\\gamma}-ray regime, offering new prospects for broad fields such as\nnuclear structure probing, fundamental symmetries tests, polarization-sensitive\nstudies in extreme conditions, and laboratory astrophysical observations.", "AI": {"tldr": "Novel method generates structured gamma rays (cylindrical vector beams) using relativistic electron beams hitting multifoil targets, achieving ~60% radial polarization through nonlinear Compton scattering of coherent transition radiation.", "motivation": "Structured gamma rays are valuable for sub-nuclear imaging and polarization-sensitive applications, but conventional optical methods struggle at gamma-ray energies.", "method": "Uses dense electron beams striking multifoil targets to generate coherent transition radiation (CTR), then converts this to gamma photons through nonlinear Compton scattering while preserving polarization via phase matching.", "result": "Achieves radial polarization degrees approaching 60% in gamma rays, and these can decay into azimuthally spin-polarized positrons via nonlinear Breit-Wheeler process.", "conclusion": "Extends structured light concept to gamma-ray regime, enabling new applications in nuclear structure probing, fundamental symmetry tests, and extreme condition studies."}}
{"id": "2508.15997", "pdf": "https://arxiv.org/pdf/2508.15997", "abs": "https://arxiv.org/abs/2508.15997", "authors": ["Mark Allen", "Gilles Bokolo-Tamba"], "title": "Regularity of the free boundary in an unstable parabolic problem", "categories": ["math.AP", "35R35, 35K05"], "comment": null, "summary": "We study the free boundary in an unstable parabolic problem arising from a\nmodel in combustion. We consider the physical situation in which the heat\nadvances and prove that the free boundary is a $C^{1,\\alpha/2}$ hypersurface.", "AI": {"tldr": "Analysis of free boundary regularity in an unstable parabolic combustion model, showing C^{1,\u03b1/2} smoothness for advancing heat fronts.", "motivation": "To understand the mathematical properties of free boundaries in combustion models, particularly the regularity and smoothness of the interface where heat advances in unstable parabolic systems.", "method": "Studied the physical scenario of advancing heat in an unstable parabolic problem derived from combustion modeling, employing mathematical analysis techniques to examine free boundary regularity.", "result": "Proved that the free boundary is a C^{1,\u03b1/2} hypersurface, establishing the smoothness and regularity properties of the interface in this combustion context.", "conclusion": "The free boundary in unstable parabolic combustion problems exhibits C^{1,\u03b1/2} regularity when heat advances, providing important mathematical characterization of interface behavior in such physical systems."}}
{"id": "2508.16105", "pdf": "https://arxiv.org/pdf/2508.16105", "abs": "https://arxiv.org/abs/2508.16105", "authors": ["Keunjae Kwak", "Hyoungwoo Kim", "Je Ir Ryu", "Donh-Hyuk Shin"], "title": "Application of a Pressured-Based OpenFOAM Solver for Rotating Detonation Engines", "categories": ["physics.comp-ph", "physics.flu-dyn"], "comment": "36 pages, 17 figures, 12 tables", "summary": "This study aims to develop a simulation framework for rotating detonation\nengines (RDEs) using multicomponentFluid solver in OpenFOAM v12 and to\ndemonstrate reducing the computational costs by adaptive mesh refinement (AMR)\nand dynamic load balancing (DLB). RDEs have been extensively studied for\nimprovements in efficiency for power generation and aircraft propulsion\nsystems. A well-established framework, showing both high accuracy and cost\nefficiency, is required to facilitate further research and development in RDEs.\nThe multicomponentFluid solver is validated against two problems:\none-dimensional planar detonation simulation and two-dimensional RDE\nsimulation, in which the present study's results are compared to reference\nresults of experiments and simulations, respectively. In the problems, the\npresent simulation results agree well with the validation data both\nqualitatively (e.g., pressure distribution and temperature field) and\nquantitatively (e.g., detonation velocity, mass flux, and specific impulse and\nthrust). In the two-dimensional RDE simulation, we propose a detonation\nvelocity correction method for fair comparison with Chapman-Jouguet (CJ)\ndetonation velocity. Moreover, the two-dimensional RDE simulation is optimized\nusing AMR and DLB. By adopting both, computational costs decrease by up to 11.2\ntimes. The effect of each of them is examined as well, which highlights the\nimportance of DLB.", "AI": {"tldr": "Developed OpenFOAM-based simulation framework for rotating detonation engines with adaptive mesh refinement and dynamic load balancing, achieving 11.2x computational cost reduction while maintaining accuracy.", "motivation": "Rotating detonation engines (RDEs) show promise for improved efficiency in power generation and aircraft propulsion, but require accurate and cost-efficient simulation frameworks to facilitate further research and development.", "method": "Used multicomponentFluid solver in OpenFOAM v12 with validation against 1D planar detonation and 2D RDE simulations. Implemented adaptive mesh refinement (AMR) and dynamic load balancing (DLB) for optimization. Proposed detonation velocity correction method for fair comparison with CJ detonation velocity.", "result": "Simulation results agreed well with validation data both qualitatively (pressure distribution, temperature field) and quantitatively (detonation velocity, mass flux, specific impulse, thrust). Combined AMR and DLB reduced computational costs by up to 11.2 times, with DLB showing particularly important impact.", "conclusion": "The developed framework provides both high accuracy and cost efficiency for RDE simulations, enabling more accessible research and development of rotating detonation engine technology through significant computational cost reductions."}}
{"id": "2508.16458", "pdf": "https://arxiv.org/pdf/2508.16458", "abs": "https://arxiv.org/abs/2508.16458", "authors": ["\u00d8yvind Stormark Auestad"], "title": "An $L^0$-approach to stochastic evolution equations", "categories": ["math.PR", "cs.NA", "math.NA", "60H05, 60H15, 60H35, 65C30, 35K10"], "comment": null, "summary": "We introduce a framework for studying pathwise time regularity and numerical\napproximation of $L^0$-valued stochastic evolution equations. At the core of\nour framework are two Burkholder--Davis--Gundy type inequalities accommodating\nIt\\^o integrals with respect to only stochastically integrable processes. The\nfirst of these inequalities is formulated in suitable metrics which metrize\nconvergence in probability on the space of integrands and integrals. The second\nis a modified version, tailored for deriving pathwise properties of the\nintegral. By combining it with a refined version of the Kolmogorov continuity\ntest, we obtain a powerful method for deriving H\\\"older regularity of It\\^o\nintegrals in their most general form. Moreover, it provides a simple and\npowerful way of deriving rates of pathwise convergence of numerical\napproximations of stochastic evolution equations. Both applications are\nillustrated for a class of linear parabolic stochastic evolution equations with\ngeneralized Whittle--Mat\\'ern type noise, and our findings are verified by\nnumerical experiments from this setting.", "AI": {"tldr": "Framework for analyzing pathwise time regularity and numerical approximation of L^0-valued stochastic evolution equations using BDG inequalities and Kolmogorov continuity test.", "motivation": "To develop a comprehensive framework for studying pathwise properties of stochastic evolution equations, particularly focusing on time regularity and numerical approximation methods for equations with only stochastically integrable processes.", "method": "Developed two Burkholder-Davis-Gundy type inequalities for It\u00f4 integrals with stochastically integrable processes: one in metrics for convergence in probability, and a modified version for pathwise properties. Combined with refined Kolmogorov continuity test to derive H\u00f6lder regularity and pathwise convergence rates.", "result": "Obtained powerful method for deriving H\u00f6lder regularity of It\u00f4 integrals in general form and simple way to derive pathwise convergence rates for numerical approximations. Verified findings through numerical experiments on linear parabolic stochastic evolution equations with generalized Whittle-Mat\u00e9rn type noise.", "conclusion": "The framework provides effective tools for analyzing pathwise time regularity and numerical approximation of stochastic evolution equations, with applications demonstrated for specific classes of equations and validated through numerical experiments."}}
{"id": "2508.16349", "pdf": "https://arxiv.org/pdf/2508.16349", "abs": "https://arxiv.org/abs/2508.16349", "authors": ["Sihui Zhong", "Andrew Hillier", "I\u00f1igo Arregui"], "title": "Identification of Nonlinear Damping of Transverse Loop Oscillations by KHI-induced Turbulence", "categories": ["astro-ph.SR", "physics.plasm-ph"], "comment": "21 pages, 9 figures, 3 tables, accepted by ApJ", "summary": "Kink oscillations in coronal loops have been extensively studied for their\npotential contributions to coronal heating and their role in plasma diagnostics\nthrough coronal seismology. A key focus is the strong damping of\nlarge-amplitude kink oscillations, which observational evidence suggests is\nnonlinear. However, directly identifying the nonlinearity is a challenge. This\nwork presents an analytic formula describing nonlinear standing kink\noscillations dissipated by turbulence, characterised by a time-varying damping\nrate and period drift. We investigate how the damping behaviour depends on the\ndriving amplitude and loop properties, showing that the initial damping time\n$\\tau$ is inversely proportional to the velocity disturbance over the loop\nradius, $V_i/R$. Using MCMC fitting with Bayesian inference, the nonlinear\nfunction better fits an observed decaying kink oscillation than traditional\nlinear models, including exponential damping, suggesting its nonlinear nature.\nBy applying a Bayesian model comparison, we establish regimes in which\nnonlinear and linear resonant absorption mechanisms dominate based on the\nrelationship between the damping rate $\\tau/P$ and $V_i/R$. Additionally,\nanalysis of two specific events reveals that while one favours the nonlinear\nmodel, the other is better explained by the linear model. Our results suggest\nthat this analytical approximation of nonlinear damping due to turbulence\nprovides a valid and reliable description of large-amplitude decaying kink\noscillations in coronal loops.", "AI": {"tldr": "Analytical model for nonlinear damping of kink oscillations in coronal loops shows better fit than linear models, with damping time inversely proportional to velocity disturbance over loop radius.", "motivation": "To understand the strong damping of large-amplitude kink oscillations in coronal loops, which observational evidence suggests is nonlinear but challenging to directly identify.", "method": "Developed analytic formula for nonlinear standing kink oscillations dissipated by turbulence, used MCMC fitting with Bayesian inference, and performed Bayesian model comparison on observed data.", "result": "Nonlinear function fits observed decaying kink oscillations better than traditional linear models. Initial damping time \u03c4 is inversely proportional to Vi/R. Analysis of two events shows one favors nonlinear model while the other fits linear model.", "conclusion": "The analytical approximation of nonlinear damping due to turbulence provides a valid and reliable description of large-amplitude decaying kink oscillations in coronal loops."}}
{"id": "2508.16003", "pdf": "https://arxiv.org/pdf/2508.16003", "abs": "https://arxiv.org/abs/2508.16003", "authors": ["Leonid Berlyand", "Spencer Dang", "Pierre-Emmanuel Jabin", "Mykhailo Potomkin"], "title": "Multiscale Analysis of a Kinetic Model of Confined Suspensions of Self-Propelled Rods", "categories": ["math.AP", "cond-mat.soft"], "comment": null, "summary": "The behavior of active matter under confinement poses significant challenges\ndue to the intricate coupling between dynamics near boundaries and those in the\nbulk. A defining feature of active matter systems is that a substantial portion\nof their dynamics takes place near confining boundaries. In our previous work,\nwe developed a kinetic framework that enables direct computation of the\nprobability distribution functions for both the position and orientation of\nactive rods. A distinguishing aspect of this approach is its explicit treatment\nof wall accumulation through the use of two coupled probability distribution\nfunctions: one describing the bulk population and the other representing rods\naccumulated at the boundary. Another novel feature is the structure of the\ngoverning equation, which is degenerate: it is second-order in one non-temporal\nvariable and first-order in another. The main focus of this paper is to\nrigorously justify this model via multi-scale analysis. We first establish\nwell-posedness of the system and then employ two distinct multi-scale\nderivations to obtain the model as a singular limit of a more classical kinetic\nsystem in the regime of vanishing translational diffusion. For analytical\nclarity, we consider the case in which active rods, once accumulated at the\nwall, remain permanently confined there. This work provides a rigorous\nmathematical foundation for reduced kinetic models of confined active matter,\nbridging microscopic dynamics and macroscopic accumulation phenomena.", "AI": {"tldr": "Rigorous mathematical justification of a kinetic model for confined active matter using multi-scale analysis to bridge microscopic dynamics and macroscopic wall accumulation phenomena.", "motivation": "Active matter systems exhibit complex dynamics near boundaries, with significant portions of their behavior occurring at confining walls. Previous work developed a kinetic framework but lacked rigorous mathematical foundation.", "method": "Multi-scale analysis of a classical kinetic system with vanishing translational diffusion. Two distinct derivations were employed to obtain the degenerate governing equation as a singular limit. The analysis considered permanently wall-confined active rods for clarity.", "result": "Established well-posedness of the system and successfully derived the reduced kinetic model through rigorous mathematical justification. The model explicitly treats wall accumulation using coupled probability distribution functions.", "conclusion": "This work provides a solid mathematical foundation for reduced kinetic models of confined active matter, enabling better understanding of the coupling between boundary dynamics and bulk behavior in active systems."}}
{"id": "2507.07366", "pdf": "https://arxiv.org/pdf/2507.07366", "abs": "https://arxiv.org/abs/2507.07366", "authors": ["Yi-Cheng Lin", "Ken-Ming Lin", "Yu-Chang Chen"], "title": "Advancing Quantum Transport Calculations: An Effective Medium Theory with Plane-Wave Basis and PAW Potentials in Eigenstates", "categories": ["cond-mat.mes-hall", "physics.comp-ph"], "comment": "6 Figures", "summary": "We present an effective medium theory based on density functional theory that\nis implemented in VASP using the PAW method with a plane wave basis set. The\ntransmission coefficient is derived through three complementary approaches: the\ncurrent density relation J=nqv, the field operator method, and the\nnonquilibrium Green's function formalism. We compare transmission coefficients\ncalculated using EMT-PW with results from NEGF-DFT, based on the NanoDCAL\npackage utilizing a linear combination of atomic orbitals (LCAO) basis set, for\nboth periodic and nonperiodic boundary conditions. The minor discrepancies\nobserved are attributed to differences in basis sets, pseudopotentials, and the\ntreatment of lead regions. Notably, the EMT-PW framework avoids the common\nissue of overcompleteness encountered in non-equilibrium transport theories and\nallows for the decomposition of the total transmission coefficient into\ncontributions from individual eigenstates. Furthermore, when combined with an\neffective gate model, EMT-PW is shown to be a powerful tool for analyzing\ncurrent characteristics in nanodevices under applied gate voltages. By\nleveraging one-electron wavefunctions in eigenstates, this method provides a\nrobust foundation for exploring the quantum statistics of electrons and current\nquantum correlations within the second quantization framework.", "AI": {"tldr": "Effective medium theory implemented in VASP using PAW method with plane wave basis for transmission coefficient calculation, compared with NEGF-DFT using LCAO basis, showing minor discrepancies due to basis set differences.", "motivation": "To develop an effective medium theory framework that avoids overcompleteness issues in non-equilibrium transport theories and enables decomposition of transmission coefficients into individual eigenstate contributions.", "method": "Implemented EMT-PW in VASP using PAW method with plane wave basis set. Derived transmission coefficient through three approaches: current density relation, field operator method, and nonquilibrium Green's function formalism. Compared with NEGF-DFT using NanoDCAL package with LCAO basis.", "result": "Minor discrepancies observed between EMT-PW and NEGF-DFT results, attributed to differences in basis sets, pseudopotentials, and lead region treatment. EMT-PW avoids overcompleteness issues and allows eigenstate decomposition of transmission.", "conclusion": "EMT-PW combined with effective gate model provides powerful tool for analyzing current characteristics in nanodevices under gate voltages, offering robust foundation for exploring quantum statistics and current correlations within second quantization framework."}}
{"id": "2508.16485", "pdf": "https://arxiv.org/pdf/2508.16485", "abs": "https://arxiv.org/abs/2508.16485", "authors": ["Maximilian Scott", "D\u00e1ire O'Kane", "Andra\u017e Jelin\u010di\u010d", "James Foster"], "title": "Underdamped Langevin MCMC with third order convergence", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "math.PR", "math.ST", "stat.TH", "60J22, 60L90, 62F15, 65C30"], "comment": "62 pages, 7 figures", "summary": "In this paper, we propose a new numerical method for the underdamped Langevin\ndiffusion (ULD) and present a non-asymptotic analysis of its sampling error in\nthe 2-Wasserstein distance when the $d$-dimensional target distribution\n$p(x)\\propto e^{-f(x)}$ is strongly log-concave and has varying degrees of\nsmoothness. Precisely, under the assumptions that the gradient and Hessian of\n$f$ are Lipschitz continuous, our algorithm achieves a 2-Wasserstein error of\n$\\varepsilon$ in $\\mathcal{O}(\\sqrt{d}/\\varepsilon)$ and\n$\\mathcal{O}(\\sqrt{d}/\\sqrt{\\varepsilon})$ steps respectively. Therefore, our\nalgorithm has a similar complexity as other popular Langevin MCMC algorithms\nunder matching assumptions. However, if we additionally assume that the third\nderivative of $f$ is Lipschitz continuous, then our algorithm achieves a\n2-Wasserstein error of $\\varepsilon$ in\n$\\mathcal{O}(\\sqrt{d}/\\varepsilon^{\\frac{1}{3}})$ steps. To the best of our\nknowledge, this is the first gradient-only method for ULD with third order\nconvergence. To support our theory, we perform Bayesian logistic regression\nacross a range of real-world datasets, where our algorithm achieves competitive\nperformance compared to an existing underdamped Langevin MCMC algorithm and the\npopular No U-Turn Sampler (NUTS).", "AI": {"tldr": "Proposed a new numerical method for underdamped Langevin diffusion with non-asymptotic analysis in 2-Wasserstein distance for strongly log-concave distributions. Achieves improved convergence rates when third derivatives are Lipschitz continuous.", "motivation": "To develop a more efficient gradient-only method for underdamped Langevin diffusion that can leverage higher-order smoothness assumptions for improved convergence rates in sampling from strongly log-concave distributions.", "method": "A new numerical method for underdamped Langevin diffusion (ULD) with non-asymptotic analysis. The method assumes Lipschitz continuous gradients and Hessians, and optionally Lipschitz continuous third derivatives for enhanced performance.", "result": "Achieves 2-Wasserstein error \u03b5 in O(\u221ad/\u03b5) and O(\u221ad/\u221a\u03b5) steps under standard assumptions. With third derivative Lipschitz continuity, achieves O(\u221ad/\u03b5^(1/3)) steps - the first gradient-only ULD method with third-order convergence. Competitive performance in Bayesian logistic regression on real datasets.", "conclusion": "The proposed algorithm matches complexity of existing Langevin MCMC methods under standard assumptions but provides superior convergence when third derivatives are Lipschitz continuous, making it the first gradient-only ULD method with third-order convergence."}}
{"id": "2508.16407", "pdf": "https://arxiv.org/pdf/2508.16407", "abs": "https://arxiv.org/abs/2508.16407", "authors": ["Vladimir Mikhailovskii", "Natalija Sheth", "Guofeng Qu", "Michal Hejduk", "Niklas Vilhelm Lausti", "K. T. Satyajith", "Christian Smorra", "G\u00fcnther Werth", "Neha Yadav", "Qian Yu", "Clemens Matthiesen", "Hartmut H\u00e4ffner", "Ferdinand Schmidt-Kaler", "Hendrik Bekker", "Dmitry Budker"], "title": "Trapping of electrons and $^{40}\\textrm{Ca}^+$ ions in a dual-frequency Paul trap", "categories": ["physics.atom-ph", "physics.plasm-ph"], "comment": "11 pages, 13 figures", "summary": "We demonstrate the operation of a dual-frequency Paul trap and characterize\nits performance by storing either electrons or calcium ions while applying two\nquadrupole fields simultaneously which oscillate at $\\Omega_\\textrm{fast} =\n2\\pi \\times 1.6$ GHz and $\\Omega_\\textrm{slow} = 2\\pi \\times 2$ MHz. The\nparticles are loaded and stored in the trap under various conditions followed\nby detection employing an electron multiplier tube. We find that tens of\nelectrons or ions can be trapped for up to ten milliseconds and a small\nfraction remains trapped even after hundreds of milliseconds. During\ndual-frequency operation we find that while the number of trapped electrons\nrapidly decreases with increase of the $\\Omega_\\textrm{slow}$ field amplitude,\nthe number of trapped ions shows no dependence on the $\\Omega_\\textrm{fast}$\nfield amplitude as supported by our extensive numerical simulations. We aim to\nuse a similar trap for synthesising antihydrogen from antiprotons and\npositrons. Accordingly, we discuss open challenges such as the co-trapping of\noppositely charged species and particle trap duration.", "AI": {"tldr": "Operation and performance characterization of a dual-frequency Paul trap capable of storing electrons and calcium ions simultaneously using two quadrupole fields at different frequencies (1.6 GHz and 2 MHz).", "motivation": "To develop and characterize a dual-frequency Paul trap for potential use in synthesizing antihydrogen from antiprotons and positrons, addressing challenges in co-trapping oppositely charged species.", "method": "Loading and storing electrons or calcium ions under various conditions while applying two simultaneous quadrupole fields at different frequencies, followed by detection using an electron multiplier tube. Extensive numerical simulations were conducted to support experimental findings.", "result": "Tens of electrons or ions can be trapped for up to 10 milliseconds, with a small fraction remaining trapped for hundreds of milliseconds. Electron trapping decreases rapidly with increased slow field amplitude, while ion trapping shows no dependence on fast field amplitude.", "conclusion": "The dual-frequency Paul trap successfully demonstrates trapping capabilities for both electrons and ions, though challenges remain for co-trapping oppositely charged species and extending particle trap duration for antihydrogen synthesis applications."}}
{"id": "2508.16010", "pdf": "https://arxiv.org/pdf/2508.16010", "abs": "https://arxiv.org/abs/2508.16010", "authors": ["Lifeng Yin", "Fan Wang"], "title": "Ground state and multiple solutions for modified autonomous fourth-order elliptic equations with Berestycki-Lions type conditions", "categories": ["math.AP"], "comment": null, "summary": "This article establishes the existence of a ground state and infinitely many\nsolutions for the modified fourth-order elliptic equation:\n  \\[\n  \\begin{aligned}\n  \\left\\{\n  \\begin{array}{ll}\n  \\Delta^2 u - \\Delta u + u - \\frac{1}{2}u\\Delta(u^2) = f(u), & \\text{in }\n\\mathbb{R}^N,\n  u \\in H^2(\\mathbb{R}^N),\n  \\end{array}\n  \\right.\n  \\end{aligned}\n  \\]\n  where $4 < N \\leq 6$ and$f:\\mathbb{R}\\rightarrow\\mathbb{R}$ is a nonlinearity\nof Berestycki-Lions type.\n  For the ground state solution, we develop a novel approach that combines\nJeanjean's technique with a Pohozaev-Palais-Smale sequence construction. When\n$f$ is odd, we prove infinite multiplicity of radially symmetric solutions via\nminimax methods on a topologically constrained comparison functional. This work\nresolves the lack of results for this autonomous problem under almost the\nweakest nonlinearity conditions.", "AI": {"tldr": "Existence of ground state and infinitely many solutions for modified fourth-order elliptic equation in R^N (4<N\u22646) with Berestycki-Lions type nonlinearity.", "motivation": "Address the lack of results for autonomous modified fourth-order elliptic equations under weak nonlinearity conditions.", "method": "Novel approach combining Jeanjean's technique with Pohozaev-Palais-Smale sequence construction for ground state; minimax methods on topologically constrained comparison functional for infinite multiplicity when f is odd.", "result": "Proved existence of ground state solution and infinite multiplicity of radially symmetric solutions when f is odd.", "conclusion": "Resolves the gap in results for this autonomous problem under nearly weakest possible nonlinearity conditions."}}
{"id": "2508.15695", "pdf": "https://arxiv.org/pdf/2508.15695", "abs": "https://arxiv.org/abs/2508.15695", "authors": ["Qifeng Hu", "Shamsulhaq Basir", "Inanc Senocak"], "title": "Conditionally adaptive augmented Lagrangian method for physics-informed learning of forward and inverse problems using artificial neural networks", "categories": ["cs.LG", "math.OC", "physics.comp-ph"], "comment": "37 pages, 23 figures", "summary": "We present several advances to the physics and equality constrained\nartificial neural networks (PECANN) framework that substantially improve its\ncapability to learn solutions of canonical partial differential equations\n(PDEs). First, we generalize the augmented Lagrangian method (ALM) to support\nmultiple independent penalty parameters, enabling simultaneous enforcement of\nheterogeneous constraints. Second, we reformulate pointwise constraint\nenforcement and Lagrange multipliers as expectations over constraint terms,\nreducing memory overhead and permitting efficient mini-batch training. Third,\nto address PDEs with oscillatory, multi-scale features, we incorporate Fourier\nfeature mappings and show that a single mapping suffices where multiple\nmappings or more costly architectures were required in related methods. Fourth,\nwe introduce a time-windowing strategy for long-time evolution in which the\nterminal state of each window is enforced as an initial-condition constraint\nfor the next, ensuring continuity without discrete time models. Crucially, we\npropose a conditionally adaptive penalty update (CAPU) strategy for ALM, which\npreserves the principle that larger constraint violations incur stronger\npenalties. CAPU accelerates the growth of Lagrange multipliers for selectively\nchallenging constraints, enhancing constraint enforcement during training. We\ndemonstrate the effectiveness of PECANN-CAPU on problems including the\ntransonic rarefaction problem, reversible advection of a passive by a vortex,\nhigh-wavenumber Helmholtz and Poisson equations, and inverse identification of\nspatially varying heat sources. Comparisons with established methods and recent\nKolmogorov-Arnold network approaches show that PECANN-CAPU achieves competitive\naccuracy across all cases. Collectively, these advances improve PECANN's\nrobustness, efficiency, and applicability to demanding problems in scientific\ncomputing.", "AI": {"tldr": "Enhanced PECANN framework with multiple penalty parameters, expectation-based constraint enforcement, Fourier features, time-windowing strategy, and adaptive penalty updates for improved PDE learning.", "motivation": "To improve the capability of physics and equality constrained artificial neural networks (PECANN) for learning solutions of canonical partial differential equations with better robustness, efficiency, and applicability to demanding scientific computing problems.", "method": "Generalized augmented Lagrangian method with multiple penalty parameters, reformulated constraint enforcement as expectations, incorporated Fourier feature mappings, introduced time-windowing strategy for long-time evolution, and developed conditionally adaptive penalty update (CAPU) strategy.", "result": "PECANN-CAPU achieves competitive accuracy across various problems including transonic rarefaction, reversible advection, high-wavenumber Helmholtz/Poisson equations, and inverse heat source identification, outperforming established methods and recent Kolmogorov-Arnold network approaches.", "conclusion": "The collective advances substantially improve PECANN's robustness, efficiency, and applicability to demanding PDE problems in scientific computing, demonstrating competitive performance across diverse test cases."}}
{"id": "2508.16567", "pdf": "https://arxiv.org/pdf/2508.16567", "abs": "https://arxiv.org/abs/2508.16567", "authors": ["Shay Gilpin"], "title": "Inaccuracy of Ensemble-Based Covariance Propagation, Beyond Sampling Error", "categories": ["math.AP", "cs.NA", "math.NA"], "comment": null, "summary": "Modern data assimilation schemes typically use the same discrete dynamical\nmodel to evolve the state estimate in time also to approximate the evolution,\nor propagation, of the estimation error covariance. Ensemble-based methods,\nsuch as the ensemble Kalman filter, approximate the evolution of the covariance\nthrough the propagation of individual ensemble members. Thus, it is tacitly\nassumed that if the discrete state propagation and resulting mean state\nestimates are accurate, then the ensemble-based discrete covariance propagation\nwill be accurate as well, apart from sampling errors due to limited ensemble\nsize. Through a series of numerical experiments supported by analytical\nresults, we demonstrate that this assumption is false when correlation length\nscales approach grid resolution. We show for states that satisfy advective\ndynamics, that while the discrete state propagation and ensemble mean state\nestimates are accurate, the corresponding ensemble covariances can be\nremarkably inaccurate, well beyond that expected from sampling errors or\ntypical numerical discretization errors. The underlying problem is a\nfundamental discrepancy between discrete covariance propagation and the\ncontinuum covariance dynamics, which we can identify because the exact\ncontinuum covariance dynamics are known. Errors in the ensemble covariances,\nwhich can be at least one order of magnitude larger than those of the mean\nstate when correlation lengths begin to approach grid scale, cannot be\nrectified by the usual methods, such as covariance inflation and localization.\nThis work brings to light a fundamental problem for data assimilation schemes\nthat propagate covariances using the same discrete dynamical model used to\npropagate the state.", "AI": {"tldr": "Ensemble-based data assimilation methods show significant covariance propagation errors when correlation length scales approach grid resolution, despite accurate state propagation, revealing a fundamental discrepancy between discrete and continuum covariance dynamics.", "motivation": "To investigate the assumption that accurate discrete state propagation in ensemble Kalman filters implies accurate covariance propagation, particularly when correlation length scales are near grid resolution.", "method": "Numerical experiments and analytical analysis comparing discrete covariance propagation with known exact continuum covariance dynamics for advective systems.", "result": "Ensemble covariances show remarkably large errors (at least one order of magnitude larger than mean state errors) when correlation lengths approach grid scale, beyond typical sampling or discretization errors.", "conclusion": "There is a fundamental problem in data assimilation schemes that use the same discrete model for both state and covariance propagation, as covariance errors cannot be fixed by standard methods like inflation and localization."}}
{"id": "2508.16080", "pdf": "https://arxiv.org/pdf/2508.16080", "abs": "https://arxiv.org/abs/2508.16080", "authors": ["Xia Huang", "Yuan Li", "Dong Ye", "Feng Zhou"], "title": "Quantization of blow-up masses for the Finsler $N$-Liouville equation", "categories": ["math.AP", "35B44, 35J92"], "comment": null, "summary": "The quantization results for blow-up phenomena play crucial roles in the\nanalysis of partial differential equations. Here we quantify the blow-up masses\nto the following Finsler $N$-Liouville equation\n$$-Q_{N}u_{n}=V_{n}e^{u_{n}}\\quad\\mbox{in}~ \\Omega\\subset \\mathbb{R}^{N}, N \\ge\n2.$$ Our study generalizes the classical result of Li-Shafrir [Indiana Univ.\nMath.J.,1994] for Liouville equation, Wang-Xia's work for anisotropic Liouville\nequation in $\\mathbb{R}^2$ [JDE, 2012], and Esposito-Lucia's for the\n$N$-Laplacian case in $\\mathbb{R}^N$ ($N \\geq 3$) in their recent paper [CVPDE,\n2024].", "AI": {"tldr": "Quantification of blow-up masses for Finsler N-Liouville equation, generalizing previous results for Liouville equations and N-Laplacian cases.", "motivation": "Blow-up phenomena quantization is crucial for PDE analysis. This work extends classical results from Li-Shafrir (1994), Wang-Xia (2012), and Esposito-Lucia (2024) to the Finsler N-Liouville equation context.", "method": "Analysis of the Finsler N-Liouville equation -Q_N u_n = V_n e^{u_n} in \u03a9 \u2282 \u211d^N (N \u2265 2), quantifying blow-up masses through mathematical analysis techniques.", "result": "The paper provides quantified blow-up mass results for the Finsler N-Liouville equation, establishing generalizations of previous classical results in this area.", "conclusion": "This work successfully generalizes quantization results for blow-up phenomena to the Finsler N-Liouville equation framework, extending the scope of previous classical theorems in PDE analysis."}}
{"id": "2508.15983", "pdf": "https://arxiv.org/pdf/2508.15983", "abs": "https://arxiv.org/abs/2508.15983", "authors": ["MengXing Na", "Chris Zhou", "Sydney K. Y. Dufresne", "Matteo Michiardi", "Andrea Damascelli"], "title": "A simulation-based training framework for machine-learning applications in ARPES", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": "9 pages, 6 figures", "summary": "In recent years, angle-resolved photoemission spectroscopy (ARPES) has\nadvanced significantly in its ability to probe more observables and\nsimultaneously generate multi-dimensional datasets. These advances present new\nchallenges in data acquisition, processing, and analysis. Machine learning (ML)\nmodels can drastically reduce the workload of experimentalists; however, the\nlack of training data for ML -- and in particular deep learning -- is a\nsignificant obstacle. In this work, we introduce an open-source synthetic ARPES\nspectra simulator - aurelia - for the purpose of generating the large datasets\nnecessary to train ML models. As a demonstration, we train a convolutional\nneural network to evaluate ARPES spectra quality -- a critical task performed\nduring the initial sample alignment phase of the experiment. We benchmark the\nsimulation-trained model against actual experimental data and find that it can\nassess the spectra quality more accurately than human analysis, and swiftly\nidentify the optimal measurement region with high precision. Thus, we establish\nthat simulated ARPES spectra can be an effective proxy for experimental spectra\nin training ML models.", "AI": {"tldr": "Aurelia - an open-source synthetic ARPES spectra simulator that generates training data for machine learning models to automate ARPES data analysis tasks like spectra quality assessment.", "motivation": "Recent advances in ARPES technology create multi-dimensional datasets that present challenges in data processing and analysis. Machine learning could help but lacks sufficient training data, particularly for deep learning applications.", "method": "Developed an open-source synthetic ARPES spectra simulator called aurelia to generate large training datasets. Used this to train a convolutional neural network for evaluating ARPES spectra quality during sample alignment.", "result": "The simulation-trained model outperformed human analysis in assessing spectra quality and could quickly identify optimal measurement regions with high precision.", "conclusion": "Simulated ARPES spectra can effectively serve as proxies for experimental spectra when training machine learning models, overcoming the data scarcity problem in ARPES analysis automation."}}
{"id": "2508.16102", "pdf": "https://arxiv.org/pdf/2508.16102", "abs": "https://arxiv.org/abs/2508.16102", "authors": ["Jin Bong Lee", "Sanghyuk Lee", "Luz Roncal"], "title": "Strichartz and local smoothing estimates for the fractional Schr\u00f6dinger equations over fractal time", "categories": ["math.AP", "math.CA", "35J10, 42B20, 28A80"], "comment": null, "summary": "We obtain Strichartz-type estimates for the fractional Schr\\\"odinger operator\n$f \\mapsto e^{it(-\\Delta)^{\\gamma/2}} f$ over a time set $E$ of fractal\ndimension. To obtain those estimates capturing fractal nature of $E$, we employ\nthe notions in the spirit of the Assouad dimension, such as, bounded Assouad\ncharacteristic and Assouad specturm. We also prove the estimate $$ \\|\ne^{it(-\\Delta)^{\\gamma/2}} f \\|_{L_t^q(\\mathrm{d}\\mu; L_x^r(\\mathbb{R}^d))} \\le\nC \\|f\\|_{H^s}, $$ where $\\mu$ is a measure satisfying an $\\alpha$-dimensional\ngrowth condition. In addition, we establish related inhomogeneous estimates and\n$L^2$ local smoothing estimates. A surprising feature of our work is that,\ndespite dealing with rough fractal sets, we extend the known estimates for the\nfractional Schr\\\"odinger operators in a natural way, precisely consistent with\nthe associated fractal dimensions.", "AI": {"tldr": "Strichartz estimates for fractional Schr\u00f6dinger operators over fractal time sets using Assouad dimension concepts, with extensions to measures satisfying dimensional growth conditions and related inhomogeneous estimates.", "motivation": "To extend Strichartz-type estimates for fractional Schr\u00f6dinger operators to fractal time sets, capturing their geometric nature through Assouad dimension concepts and providing estimates consistent with fractal dimensions.", "method": "Employ notions of bounded Assouad characteristic and Assouad spectrum to handle fractal time sets. Prove estimates for measures satisfying \u03b1-dimensional growth conditions, establish inhomogeneous estimates, and derive L\u00b2 local smoothing estimates.", "result": "Obtained Strichartz estimates that naturally extend known results for fractional Schr\u00f6dinger operators while precisely accounting for fractal dimensions, even when dealing with rough fractal sets.", "conclusion": "The work successfully extends fractional Schr\u00f6dinger operator estimates to fractal settings using Assouad dimension concepts, maintaining natural consistency with associated fractal dimensions despite the roughness of the sets involved."}}
{"id": "2508.16103", "pdf": "https://arxiv.org/pdf/2508.16103", "abs": "https://arxiv.org/abs/2508.16103", "authors": ["Se-Chan Lee"], "title": "Nonlocal Harnack inequality in a disconnected region", "categories": ["math.AP", "35B45, 35B65, 35R09"], "comment": "15 pages", "summary": "We establish a Harnack inequality for weak solutions of nonlocal equations in\na disconnected region. The inequality compares the value of a solution on one\nconnected component with its value on another, capturing a purely nonlocal\nphenomenon with no local analogue. We provide two different approaches: one\nbased on the localized maximum principle and another on the Poisson kernel\nestimates.", "AI": {"tldr": "Harnack inequality for nonlocal equations in disconnected regions, comparing solutions across different connected components - a purely nonlocal phenomenon", "motivation": "To establish mathematical tools for analyzing nonlocal equations in disconnected domains, capturing phenomena that don't exist in local PDE theory", "method": "Two approaches: one based on localized maximum principle and another using Poisson kernel estimates", "result": "Successfully established Harnack inequality that compares solution values across disconnected components", "conclusion": "This work provides fundamental analytical tools for nonlocal equations in disconnected regions, revealing unique nonlocal phenomena without local counterparts"}}
{"id": "2508.16012", "pdf": "https://arxiv.org/pdf/2508.16012", "abs": "https://arxiv.org/abs/2508.16012", "authors": ["Circe Hsu", "Claire Schlesinger", "Karan Mudaliar", "Jordan Leung", "Robin Walters", "Peter Schindler"], "title": "FIRE-GNN: Force-informed, Relaxed Equivariance Graph Neural Network for Rapid and Accurate Prediction of Surface Properties", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "The work function and cleavage energy of a surface are critical properties\nthat determine the viability of materials in electronic emission applications,\nsemiconductor devices, and heterogeneous catalysis. While first principles\ncalculations are accurate in predicting these properties, their computational\nexpense combined with the vast search space of surfaces make a comprehensive\nscreening approach with density functional theory (DFT) infeasible. Here, we\nintroduce FIRE-GNN (Force-Informed, Relaxed Equivariance Graph Neural Network),\nwhich integrates surface-normal symmetry breaking and machine learning\ninteratomic potential (MLIP)-derived force information, achieving a twofold\nreduction in mean absolute error (down to 0.065 eV) over the previous\nstate-of-the-art for work function prediction. We additionally benchmark recent\ninvariant and equivariant architectures, analyze the impact of symmetry\nbreaking, and evaluate out-of-distribution generalization, demonstrating that\nFIRE-GNN consistently outperforms competing models for work function\npredictions. This model enables accurate and rapid predictions of the work\nfunction and cleavage energy across a vast chemical space and facilitates the\ndiscovery of materials with tuned surface properties", "AI": {"tldr": "FIRE-GNN is a new graph neural network that combines surface-normal symmetry breaking and machine learning interatomic potential force information to achieve state-of-the-art accuracy for work function prediction with 0.065 eV MAE.", "motivation": "First principles calculations like DFT are accurate for predicting work function and cleavage energy but computationally expensive, making comprehensive screening of materials surfaces infeasible.", "method": "Developed FIRE-GNN (Force-Informed, Relaxed Equivariance Graph Neural Network) that integrates surface-normal symmetry breaking and MLIP-derived force information. Benchmarked against recent invariant and equivariant architectures.", "result": "Achieved twofold reduction in mean absolute error (0.065 eV) over previous state-of-the-art for work function prediction. Consistently outperforms competing models and shows good out-of-distribution generalization.", "conclusion": "FIRE-GNN enables accurate and rapid predictions of work function and cleavage energy across vast chemical space, facilitating discovery of materials with tuned surface properties for electronic emission, semiconductors, and catalysis applications."}}
{"id": "2508.16108", "pdf": "https://arxiv.org/pdf/2508.16108", "abs": "https://arxiv.org/abs/2508.16108", "authors": ["S. Cano-Casanova", "J. L\u00f3pez-G\u00f3mez", "M. Molina-Meyer"], "title": "Limiting behavior of principal eigenvalues for a class of elliptic operators with degenerate large advection", "categories": ["math.AP", "math.CA", "34B09, 34D15, 34L15"], "comment": null, "summary": "In this paper we show that, in a number of circumstances, Theorem 1.2 of Chen\nand Lou \\cite{ChLo} remains valid even when the function $m(x)$ of the\nadvection term $-2sm'(x)$ is highly degenerate at its maximum. Our main result\nestablishes that the limiting behavior of the principal eigenvalue is\nindependent of the order of the zero of $m(x)-m(x_0)$ at $x=x_0$, where\n$m(x_0)=\\|m\\|_\\infty$. Theorem 1.2 of Chen and Lou \\cite{ChLo} imposed\n$m''(x_0)<0$.", "AI": {"tldr": "The paper extends Chen and Lou's Theorem 1.2 to cases where the advection function m(x) is highly degenerate at its maximum, showing principal eigenvalue behavior is independent of the zero order.", "motivation": "To generalize previous results that required m''(x_0)<0, allowing for more degenerate cases where m(x) has higher order zeros at its maximum point.", "method": "Mathematical analysis of principal eigenvalues in degenerate advection problems, extending existing theorems to handle highly degenerate functions m(x).", "result": "The limiting behavior of the principal eigenvalue remains valid even when m(x) is highly degenerate at its maximum, independent of the order of the zero.", "conclusion": "Chen and Lou's Theorem 1.2 holds under more general conditions, removing the strict concavity requirement m''(x_0)<0 at the maximum point."}}
{"id": "2508.16203", "pdf": "https://arxiv.org/pdf/2508.16203", "abs": "https://arxiv.org/abs/2508.16203", "authors": ["Yan Jiang", "Hongyu Liu", "Kai Zhang", "Haoran Zheng"], "title": "Spectral density estimates of surface-localized eigenmodes for transmission eigenvalue problems", "categories": ["math.AP"], "comment": null, "summary": "This paper investigates a distinctive spectral pattern exhibited by\ntransmission eigenfunctions in wave scattering theory. Building upon the\ndiscovery in [7, 8] that these eigenfunctions localize near the domain\nboundary, we derive sharp spectral density estimates--establishing both lower\nand upper bounds--to demonstrate that a significant proportion of transmission\neigenfunctions manifest this surface-localizing behavior. Our analysis\nelucidates the connection between the geometric rigidity of eigenfunctions and\ntheir spectral properties. Though primarily explored within a radially\nsymmetric framework, this study provides rigorous theoretical insights,\nadvances new perspectives in this emerging field, and offers meaningful\nimplications for inverse scattering theory.", "AI": {"tldr": "Transmission eigenfunctions exhibit surface-localization near domain boundaries, with sharp spectral density bounds showing this behavior occurs in a significant proportion of cases, connecting geometric rigidity to spectral properties.", "motivation": "To understand the distinctive spectral patterns of transmission eigenfunctions in wave scattering theory, particularly their boundary-localizing behavior discovered in prior studies, and to establish rigorous connections between geometric properties and spectral characteristics.", "method": "Derived sharp spectral density estimates (both lower and upper bounds) to quantify the proportion of transmission eigenfunctions exhibiting surface-localization behavior, primarily analyzed within a radially symmetric framework.", "result": "Established that a significant proportion of transmission eigenfunctions manifest surface-localizing behavior near domain boundaries, with rigorous bounds on the spectral density.", "conclusion": "The study provides rigorous theoretical insights into transmission eigenfunctions' geometric-spectral relationships, advances new perspectives in wave scattering theory, and offers meaningful implications for inverse scattering applications."}}
{"id": "2508.16262", "pdf": "https://arxiv.org/pdf/2508.16262", "abs": "https://arxiv.org/abs/2508.16262", "authors": ["Namana Venkatareddy", "Victor Ghosh", "H. R. Krishnamurthy", "Manish Jain"], "title": "Double excitations in molecules", "categories": ["physics.chem-ph", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cond-mat.str-el", "physics.comp-ph"], "comment": null, "summary": "Double excitations in organic molecules have garnered significant interest as\na result of their importance in singlet fission and photophysics. These\nexcitations play a crucial role in understanding the photoexcitation processes\nin polyenes. To describe photoexcited states with both single and double\nexcitation character, we use a first-principles many-body theory that combines\nthe GW / Bethe-Salpeter equation and the configuration interaction (CI)\nmethods. Specifically, we develop and employ two CI-based methods: screened\nconfiguration interaction singles and doubles (scrCISD) and screened\nconfiguration interaction singles with perturbative doubles (scrCIS(D)),\napplied to an effective many-body Hamiltonian that incorporates screening. We\napply these methods to Thiel's set of molecules, which exhibit excited states\npredominantly characterized by single excitations with a partial double\nexcitation character. Our results indicate that the scrCISD method\nsystematically underestimates the excitation energies compared to the best\ntheoretical estimates, while the scrCIS(D) method shows good agreement with\nthese estimates. Furthermore, we used the scrCISD method to calculate the\nbinding energies of the dominantly doubly excited correlated triplet pair\nstates, $\\mathrm{TT^1}$, in pentacene dimers, finding that the $\\mathrm{TT^1}$\nbinding energies agree well with empirical calculations.", "AI": {"tldr": "The paper develops two screened configuration interaction methods (scrCISD and scrCIS(D)) to study double excitations in organic molecules, finding that scrCIS(D) performs better for excitation energies while scrCISD works well for triplet pair binding energies.", "motivation": "Double excitations are important for understanding singlet fission and photophysics in organic molecules like polyenes, but existing methods struggle to accurately describe states with both single and double excitation character.", "method": "Developed two CI-based methods: screened configuration interaction singles and doubles (scrCISD) and screened configuration interaction singles with perturbative doubles (scrCIS(D)), applied to an effective many-body Hamiltonian that incorporates screening.", "result": "scrCISD systematically underestimates excitation energies compared to best theoretical estimates, while scrCIS(D) shows good agreement. scrCISD also accurately calculates binding energies of correlated triplet pair states in pentacene dimers.", "conclusion": "The scrCIS(D) method is more accurate for excitation energies, while scrCISD remains useful for calculating binding energies of doubly excited states, providing valuable tools for studying photophysical processes in organic molecules."}}
{"id": "2508.16229", "pdf": "https://arxiv.org/pdf/2508.16229", "abs": "https://arxiv.org/abs/2508.16229", "authors": ["Jiao Luo", "Zhipeng Yang"], "title": "Existence and concentration phenomenon of multiple solutions for the fractional logarithmic Schr\u00f6dinger-Poisson system via penalization method", "categories": ["math.AP"], "comment": "38 pages, comments are welcome", "summary": "This paper concerns the existence of multiple solutions for the fractional\nlogarithmic Schr\\\"odinger-Possion system of the form\n  \\begin{equation*}\n  \\begin{cases}\n  {\\varepsilon}^{2\\alpha} (-\\Delta )^{\\alpha}u+V(x) u+\\phi u=u \\log\nu^{2}+u^{q-1}, & \\text{in}\\quad \\mathbb{R}^{3},\n  {\\varepsilon}^{2\\alpha} (-\\Delta )^{\\alpha}\\phi=u^2, & \\text{in}\\quad\n\\mathbb{R}^{3}.\n  \\end{cases}\n  \\end{equation*} where $\\varepsilon>0$ is a small parameter, $q \\in (4,\n2_\\alpha^*)$ with $\\alpha\\in(\\frac{3}{4},1)$, $V: \\mathbb{R}^{3} \\rightarrow\n\\mathbb{R}$ is a continuous function that satisfies some local potential\nhypothesis. By introducing a new Banach space, the energy functional become\n$C^{1}$, which create the conditions for studying the multiplicity of solutions\ninvolving Lusternik-Schnirelmann category. We prove that for $\\varepsilon>0$\nsmall enough, the system has a positive ground state solution and each positive\nsolution concentrates around a local minimum point of $V$.", "AI": {"tldr": "Existence of multiple solutions for fractional logarithmic Schrodinger-Poisson system with concentration around local minima of potential.", "motivation": "Study multiplicity of solutions for fractional logarithmic Schrodinger-Poisson systems with small parameter epsilon, addressing challenges in energy functional analysis.", "method": "Introduce new Banach space to make energy functional C^1, use Lusternik-Schnirelmann category theory to study solution multiplicity, prove concentration around local minima.", "result": "For sufficiently small epsilon > 0, the system has positive ground state solution and each positive solution concentrates around local minimum points of potential V.", "conclusion": "The fractional logarithmic Schrodinger-Poisson system exhibits multiple solutions that concentrate near local minima of the potential function when epsilon is sufficiently small."}}
{"id": "2508.16387", "pdf": "https://arxiv.org/pdf/2508.16387", "abs": "https://arxiv.org/abs/2508.16387", "authors": ["Xuning Zhao", "Wentao Ma", "Shafquat Islam", "Aditya Narkhede", "Kevin Wang"], "title": "M2C: An Open-Source Software for Multiphysics Simulation of Compressible Multi-Material Flows and Fluid-Structure Interactions", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": null, "summary": "M2C (Multiphysics Modeling and Computation) is an open-source software for\nsimulating multi-material fluid flows and fluid-structure interactions under\nextreme conditions, such as high pressures, high temperatures, shock waves, and\nlarge interface deformations. It employs a finite volume method to solve the\ncompressible Navier-Stokes equations and supports a wide range of thermodynamic\nequations of state. M2C incorporates models of laser radiation and absorption,\nphase transition, and ionization, coupled with continuum dynamics.\nMulti-material interfaces are evolved using a level set method, while\nfluid-structure interfaces are tracked using an embedded boundary method.\nAdvective fluxes across interfaces are computed using FIVER (FInite Volume\nmethod based on Exact multi-material Riemann problems). For two-way\nfluid-structure interaction, M2C is coupled with the open-source structural\ndynamics solver Aero-S using a partitioned procedure. The M2C code is written\nin C++ and parallelized with MPI for high-performance computing. The source\npackage includes a set of example problems for demonstration and user training.\nAccuracy is verified through benchmark cases such as Riemann problems,\ninterface evolution, single-bubble dynamics, and ionization response. Several\nmultiphysics applications are also presented, including laser-induced thermal\ncavitation, explosion and blast mitigation, and hypervelocity impact.", "AI": {"tldr": "M2C is an open-source multiphysics simulation software for extreme conditions fluid flows and fluid-structure interactions using finite volume methods, level set tracking, and exact Riemann solvers.", "motivation": "To develop a comprehensive open-source tool for simulating complex multiphysics phenomena under extreme conditions like high pressures, temperatures, shock waves, and large deformations that require accurate multi-material interface handling.", "method": "Finite volume method for compressible Navier-Stokes equations, level set method for multi-material interfaces, embedded boundary method for fluid-structure interfaces, FIVER for advective fluxes, coupled with Aero-S structural solver using partitioned procedure, parallelized with MPI.", "result": "Developed a high-performance C++ code with verified accuracy through benchmark cases (Riemann problems, interface evolution, bubble dynamics, ionization) and demonstrated applications including laser-induced cavitation, explosion mitigation, and hypervelocity impact.", "conclusion": "M2C provides a robust open-source framework for accurate simulation of extreme multiphysics phenomena with verified performance across various benchmark cases and practical applications."}}
{"id": "2508.16247", "pdf": "https://arxiv.org/pdf/2508.16247", "abs": "https://arxiv.org/abs/2508.16247", "authors": ["Simone Ciani", "Kenta Nakamura"], "title": "Diverse regularities for nonlocal parabolic De Giorgi classes I", "categories": ["math.AP", "35B65, 35R09, 47G20"], "comment": null, "summary": "In this paper we establish diverse Harnack inequalities for elements of a\nspecific energy class, called the nonlocal parabolic (p-homogenous) De Giorgi\nclass. This class encompasses the nonlinear parabolic counterpart of the\nseminal work of M. Cozzi (J. Funct. Anal., 2017) and embodies local weak\nsolutions to the fractional heat equation. More precisely, we first derive the\nlocal boundedness and subsequently prove under minimal tail conditions several\nweak Harnack inequalities, measure theoretical propagation lemmas, and a full\nHarnack inequality for nonnegative members of the aforementioned class.\nFinally, we present a full proof of the local H\\\"older modulus of continuity,\nthereby establishing a Liouville-type rigidity property. The results are new\neven for the linear case, thereby showing that the recent achievements of\nKassmann and Weidner (Duke Math. J., 2024) are structural properties, valid\nregardless of any equation. The techniques and ideas presented in this paper\nwill open the door for further extensions to many natural directions.", "AI": {"tldr": "This paper establishes Harnack inequalities for nonlocal parabolic De Giorgi classes, extending results to nonlinear fractional heat equations and proving structural properties like local boundedness, weak Harnack inequalities, and H\u00f6lder continuity.", "motivation": "To extend Harnack inequality theory to nonlocal parabolic equations and demonstrate that recent results by Kassmann and Weidner are structural properties valid beyond specific equations.", "method": "Develops nonlocal parabolic De Giorgi classes, derives local boundedness, proves weak Harnack inequalities under minimal tail conditions, establishes measure propagation lemmas, and provides full Harnack inequality proofs.", "result": "New Harnack inequalities and H\u00f6lder continuity results for nonnegative solutions in nonlocal parabolic De Giorgi classes, including a Liouville-type rigidity property. Results are novel even for linear cases.", "conclusion": "The techniques establish that Harnack inequalities are structural properties of the energy class rather than equation-dependent, opening avenues for extensions to various natural directions in nonlocal analysis."}}
{"id": "2508.16413", "pdf": "https://arxiv.org/pdf/2508.16413", "abs": "https://arxiv.org/abs/2508.16413", "authors": ["Daniele Parlato", "Grazia Di Bello", "Fabrizio Pavan", "Giulio De Filippis", "Carmine Antonio Perroni"], "title": "Quantum Fisher information as a witness of non-Markovianity and criticality in the spin-boson model", "categories": ["quant-ph", "cond-mat.stat-mech", "physics.comp-ph"], "comment": "6 pages, 3 figures, end matter and supplemental material", "summary": "The quantum Fisher information, the quantum analogue of the classical Fisher\ninformation, is a central quantity in quantum metrology and quantum sensing\nbecause of its connection to parameter estimation and fidelity susceptibility.\nUsing numerically exact methods applied to a paradigmatic open quantum system,\nthe spin-boson model, we calculate both static and dynamical quantum Fisher\ninformation matrix elements with respect to spin-bath couplings and magnetic\nfield strengths. As the spin-bath interaction increases, we first show that the\ncoupling-coupling matrix elements relative to the ground state of the\nHamiltonian serve as a genuine witness of bipartite entanglement and the\nBerezinskii-Kosterlitz-Thouless quantum phase transition through their\nnon-monotonic behavior. Furthermore, we demonstrate that the time-dependent\nmatrix elements can reveal non-Markovian effects as well as the transition from\nthe coherent to incoherent regime at the Toulouse point. In the paradigmatic\nspin-boson model, the non-monotonic features of the quantum Fisher information\nmatrix signal changes in quantum resources such as entanglement and coherence,\nquantify non-Markovian behavior, and enable criticality-enhanced quantum\nsensing, thereby shedding light on key features of open quantum systems.", "AI": {"tldr": "Quantum Fisher information matrix analysis in spin-boson model reveals entanglement, quantum phase transitions, non-Markovian effects, and enables criticality-enhanced quantum sensing.", "motivation": "To understand how quantum Fisher information, a key quantity in quantum metrology, behaves in open quantum systems and how it can reveal quantum resources and critical phenomena.", "method": "Used numerically exact methods to calculate static and dynamical quantum Fisher information matrix elements for the spin-boson model with respect to spin-bath couplings and magnetic field strengths.", "result": "Coupling-coupling matrix elements serve as entanglement witness and detect Berezinskii-Kosterlitz-Thouless quantum phase transition through non-monotonic behavior. Time-dependent elements reveal non-Markovian effects and coherent-to-incoherent regime transition.", "conclusion": "Quantum Fisher information matrix non-monotonic features signal changes in quantum resources (entanglement, coherence), quantify non-Markovian behavior, and enable criticality-enhanced quantum sensing in open quantum systems."}}
{"id": "2508.16281", "pdf": "https://arxiv.org/pdf/2508.16281", "abs": "https://arxiv.org/abs/2508.16281", "authors": ["Lisbeth Carrero", "Pedro Hern\u00e1ndez-Llanos"], "title": "Kirchhoff-type equations involving the Fractional $(p,q)-$Laplacian", "categories": ["math.AP", "35A15, 35J20, 35J60, 35R11"], "comment": null, "summary": "In this paper, we study the existence and nonexistence of solutions for the\nfollowing Kirchhoff-type fractional $(p\\text{-}q)$-Laplacian problem:\n  \\begin{equation*} \\begin{cases}\n  M\\left([u]^p_{p,s_1}\\right)(-\\Delta)^{s_1}_p u +\nM\\left([u]^q_{q,s_2}\\right)(-\\Delta)^{s_2}_q u = \\lambda\\big[a(x)|u|^{p-2}u +\nb(x)|u|^{q-2}u\\big] + h(x), & \\text{in } \\Omega, \\\\ u = 0, & \\text{on }\n\\mathbb{R}^N \\setminus \\Omega, \\end{cases} \\end{equation*}\n  where $\\Omega \\subset \\mathbb{R}^N$ ($N \\geq 1$) is a bounded domain with\nsmooth boundary, $0 < s_1 < s_2 < 1$, and $s_1 p < N$. We assume $1 < q \\leq p\n< \\theta p < p^{*}_{s_1} := \\dfrac{Np}{N - s_1 p}$, and $\\lambda \\in\n\\mathbb{R}$. The functions $a(x), b(x)$, and $h(x)$ are non-negative, with $a,\nb \\in L^\\infty(\\Omega)$ and $h \\in L^q(\\Omega)$.\n  Using variational methods, we establish the existence of at least two weak\nsolutions. The first solution is obtained via the direct minimization of the\nassociated energy functional, and the second is obtained by applying the\nMountain Pass Theorem. We also prove a nonexistence result for small values of\nthe parameter $\\lambda > 0$.", "AI": {"tldr": "Existence and nonexistence of solutions for Kirchhoff-type fractional (p-q)-Laplacian problems using variational methods", "motivation": "Study complex nonlinear fractional problems involving two different fractional Laplacian operators with Kirchhoff-type terms, which arise in various physical phenomena and require advanced mathematical analysis", "method": "Variational methods including direct minimization of energy functional for first solution and Mountain Pass Theorem for second solution; also prove nonexistence for small lambda values", "result": "Established existence of at least two weak solutions: one via direct minimization and another via Mountain Pass Theorem; proved nonexistence result for small positive lambda values", "conclusion": "The paper successfully demonstrates both existence and nonexistence results for this complex fractional (p-q)-Laplacian problem, providing complete mathematical characterization of solution behavior depending on parameter lambda"}}
{"id": "2508.16436", "pdf": "https://arxiv.org/pdf/2508.16436", "abs": "https://arxiv.org/abs/2508.16436", "authors": ["Yue He", "Daniel Escudero"], "title": "Universal Multistate Kinetic Models for the In-Silico Discovery of Thermally Activated Delayed Fluorescence Emitters", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "physics.app-ph", "physics.comp-ph"], "comment": null, "summary": "Many thermally activated delayed fluorescence (TADF) emitters exhibit complex\nphotophysical behaviors that cannot be fully captured by the conventional three\nstate model (S0, S1, T1). The lack of kinetic models that incorporate vibronic\ncoupling effects and high lying excited states has long limited the systematic\nunderstanding and rational design of these materials. To address this, we\ndeveloped KinLuv, an extended multistate kinetic model that not only includes\nhigher lying excited states (S2, T2) but also accounts for the Herzberg Teller\n(HT) vibronic coupling in the rate constant calculations. Applied to two\nrepresentative TADF emitters, i.e., DOBNA and DiKTa, KinLuv successfully\npredicts photoluminescence quantum yields (PLQY) and prompt/delayed\nfluorescence lifetimes in good agreement with reported experimental results.\nThese findings highlight that incorporating HT vibronic coupling effects and\nhigher lying excited states is essential for quantitatively modeling TADF\nmechanisms and guiding the design of high performance emitters.", "AI": {"tldr": "KinLuv - extended multistate kinetic model incorporating higher excited states (S2, T2) and Herzberg-Teller vibronic coupling for accurate TADF emitter modeling", "motivation": "Conventional three-state model (S0, S1, T1) fails to capture complex photophysical behaviors in TADF emitters, lacking vibronic coupling effects and high-lying excited states", "method": "Developed KinLuv model that includes S2, T2 states and accounts for Herzberg-Teller vibronic coupling in rate constant calculations", "result": "Successfully predicted PLQY and prompt/delayed fluorescence lifetimes for DOBNA and DiKTA emitters, matching experimental results", "conclusion": "Incorporating HT vibronic coupling and higher excited states is essential for quantitative TADF modeling and designing high-performance emitters"}}
{"id": "2508.16380", "pdf": "https://arxiv.org/pdf/2508.16380", "abs": "https://arxiv.org/abs/2508.16380", "authors": ["Yerkin Shaimerdenov", "Nurgissa Yessirkegenov", "Amir Zhangirbayev"], "title": "Sharp remainder terms of weighted Hardy-Poincar\u00e9 and Heisenberg-Pauli-Weyl inequalities related to the Baouendi-Grushin operator", "categories": ["math.AP", "26D10, 35J70"], "comment": "33 pages", "summary": "In this paper, we obtain sharp remainder terms for the Hardy-Poincar\\'e type\ninequality with general non-radial weights in the setting of Baouendi-Grushin\nvector fields (see Theorem 2.5). It is worth emphasizing that all of our\nresults are new both in the Grushin and standard Euclidean setting. The method\nemployed allows us to not only unify, but also improve the results of Kombe and\nYener [KY18] for any $1<p<\\infty$ while holding true for complex-valued\nfunctions and providing explicit constants (Corollary 2.7). As a result, we are\nable to obtain sharp remainder terms to many known weighted Hardy-type\ninequalities (see Section 3.1). Aside from weighted Hardy-type inequalities, we\nalso recover sharp remainder formula for the $L^{p}$-Poincar\\'e inequality\n(Corollary 3.5). In the special case of radial weights, we are naturally able\nto introduce the notion of Grushin $p$-Bessel pairs (see Definition 2.9).\nFinally, we are able to apply the technique to establish the sharp remainder\nterm of the Heisenberg-Pauli-Weyl inequality in $L^{p}$ (Corollary 3.13) that\nincludes the sharp constant.", "AI": {"tldr": "Sharp remainder terms for Hardy-Poincar\u00e9 inequalities with non-radial weights in Baouendi-Grushin vector fields, unifying and improving previous results with explicit constants.", "motivation": "To obtain precise remainder terms for Hardy-Poincar\u00e9 type inequalities with general weights in the Baouendi-Grushin setting, extending beyond previous radial weight limitations.", "method": "Developed analytical techniques for Baouendi-Grushin vector fields that handle non-radial weights, enabling unification and improvement of existing results with explicit constants for complex-valued functions.", "result": "Achieved sharp remainder terms for weighted Hardy-type inequalities, recovered sharp remainder formula for L^p-Poincar\u00e9 inequality, introduced Grushin p-Bessel pairs concept for radial weights, and established sharp remainder term for Heisenberg-Pauli-Weyl inequality with sharp constant.", "conclusion": "The method provides a unified framework that significantly advances the theory of Hardy-Poincar\u00e9 inequalities in both Grushin and Euclidean settings, offering explicit constants and handling complex-valued functions with non-radial weights."}}
{"id": "2508.16554", "pdf": "https://arxiv.org/pdf/2508.16554", "abs": "https://arxiv.org/abs/2508.16554", "authors": ["Karan Shah", "Attila Cangi"], "title": "Machine Learning Time Propagators for Time-Dependent Density Functional Theory Simulations", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": "20 pages, 5 figures", "summary": "Time-dependent density functional theory (TDDFT) is a widely used method to\ninvestigate electron dynamics under external time-dependent perturbations such\nas laser fields. In this work, we present a novel approach to accelerate\nelectron dynamics simulations based on real time TDDFT using autoregressive\nneural operators as time-propagators for the electron density. By leveraging\nphysics-informed constraints and featurization, and high-resolution training\ndata, our model achieves superior accuracy and computational speed compared to\ntraditional numerical solvers. We demonstrate the effectiveness of our model on\na class of one-dimensional diatomic molecules under the influence of a range of\nlaser parameters. This method has potential in enabling real-time, on-the-fly\nmodeling of laser-irradiated molecules and materials with varying experimental\nparameters.", "AI": {"tldr": "Novel neural operator approach accelerates real-time TDDFT electron dynamics simulations using autoregressive neural operators as density propagators, achieving superior accuracy and speed over traditional solvers.", "motivation": "Time-dependent density functional theory (TDDFT) is widely used for electron dynamics but computationally expensive. There's a need for faster methods to enable real-time modeling of laser-irradiated molecules with varying experimental parameters.", "method": "Uses autoregressive neural operators as time-propagators for electron density in real-time TDDFT, with physics-informed constraints, featurization, and high-resolution training data.", "result": "Achieves superior accuracy and computational speed compared to traditional numerical solvers, demonstrated on 1D diatomic molecules under various laser parameters.", "conclusion": "This neural operator approach has potential for enabling real-time, on-the-fly modeling of laser-irradiated molecules and materials with varying experimental conditions."}}
{"id": "2508.16391", "pdf": "https://arxiv.org/pdf/2508.16391", "abs": "https://arxiv.org/abs/2508.16391", "authors": ["Abhrojyoti Sen", "Jarkko Siltakoski"], "title": "Lipschitz regularity for parabolic double phase equations with gradient nonlinearity", "categories": ["math.AP"], "comment": "58 pages, comments are welcome", "summary": "We establish the local Lipschitz regularity in space for the viscosity\nsolutions to the parabolic double phase equation of the form \\[\n\\smash{\\partial_{t}u-\\operatorname{div} \\left(|Du|^{p-2}D u+a(z)|D u|^{q-2}D\nu\\right)=f(z, Du)} \\] by employing the Ishii-Lions method. In addition, we\nobtain H\\\"{o}lder estimate in time which turns out to be sharp in the\ndegenerate regime. Here, $1< p\\leq q<\\infty,$ and the coefficient $a\\geq 0$ is\nassumed to be bounded, locally Lipschitz continuous in space, and continuous in\ntime. Furthermore, the non-homogeneity $f$ is assumed to be continuous on\n$\\Omega\\times \\mathbb{R}\\times \\mathbb{R}^N,$ and to satisfy a suitable\ngradient growth condition. We also establish the equivalence between bounded\nviscosity solutions and weak solutions, under appropriate additional regularity\nassumption on the coefficient $a.$", "AI": {"tldr": "This paper establishes local Lipschitz regularity in space and sharp H\u00f6lder estimates in time for viscosity solutions to parabolic double phase equations using the Ishii-Lions method.", "motivation": "To analyze the regularity properties of solutions to parabolic double phase equations, which combine p-Laplacian and q-Laplacian type operators with variable coefficients, and to understand the relationship between viscosity and weak solutions.", "method": "Employing the Ishii-Lions method to prove local Lipschitz regularity in space and obtaining H\u00f6lder estimates in time. Also establishing equivalence between bounded viscosity solutions and weak solutions under appropriate regularity assumptions on coefficients.", "result": "Proved local Lipschitz regularity in space and sharp H\u00f6lder estimates in time for viscosity solutions. Established equivalence between bounded viscosity solutions and weak solutions when the coefficient a has sufficient regularity.", "conclusion": "The paper successfully demonstrates regularity results for parabolic double phase equations and provides a connection between different solution concepts (viscosity and weak solutions) for these types of equations."}}
{"id": "2508.16537", "pdf": "https://arxiv.org/pdf/2508.16537", "abs": "https://arxiv.org/abs/2508.16537", "authors": ["Stefan Dingel", "Karoline Disser"], "title": "Global existence and uniqueness for Hibler's visco-plastic sea-ice model", "categories": ["math.AP", "35Q86 (primary), 35A01, 35A02, 86A40, 86A08, 74C05, 74H20, 74H25\n  (secondary)"], "comment": null, "summary": "In this paper, we prove global existence and uniqueness of weak solutions to\nthe momentum equations of Hibler's visco-plastic model for the dynamics of the\narctic sea-ice covers. Although Hibler's model is standardly used in global\nclimate simulations, there are only few rigorous mathematical results so far\nthat mainly concern local-in-time well-posedness of globally regularized\nvariants. Here, we consider Hibler's original model with local cut-off for\narbitrarily small and large strain rates. Degeneracy and plasticity of the\nstress tensor hold in this range.", "AI": {"tldr": "Global existence and uniqueness of weak solutions for Hibler's original visco-plastic sea-ice model with local cut-off for all strain rates.", "motivation": "Hibler's model is standardly used in global climate simulations but lacks rigorous mathematical foundation, with previous results mainly concerning local-in-time well-posedness of regularized variants.", "method": "Consider Hibler's original model with local cut-off for arbitrarily small and large strain rates, addressing degeneracy and plasticity of the stress tensor in this range.", "result": "Prove global existence and uniqueness of weak solutions to the momentum equations of Hibler's visco-plastic model.", "conclusion": "Provides rigorous mathematical foundation for Hibler's original sea-ice dynamics model used in climate simulations, extending beyond previous local-in-time results for regularized variants."}}
{"id": "2508.16152", "pdf": "https://arxiv.org/pdf/2508.16152", "abs": "https://arxiv.org/abs/2508.16152", "authors": ["David Krejcirik"], "title": "Is the optimal magnetic rectangle a square?", "categories": ["math.SP", "math-ph", "math.AP", "math.MP", "math.OC"], "comment": "8 pages", "summary": "We are concerned with the dependence of the lowest eigenvalue of the magnetic\nDirichlet Laplacian on the geometry of rectangles, subject to homogeneous\nfields. We conjecture that the square is a global minimiser both under the area\nor perimeter constraints. Contrary to the well-known magnetic-free analogue,\nthe present spectral problem does not admit explicit solutions. By establishing\nlower and upper bound to the eigenvalue, we establish the conjecture for weak\nmagnetic fields. Moreover, we relate the validity of the conjecture to the\nsimplicity of the eigenvalue and symmetries of minimisers of a non-convex\nminimisation problem.", "AI": {"tldr": "The paper investigates how the lowest eigenvalue of magnetic Dirichlet Laplacian depends on rectangle geometry under magnetic fields, conjecturing that squares minimize this eigenvalue under area/perimeter constraints.", "motivation": "To understand the geometric dependence of magnetic Dirichlet Laplacian eigenvalues, particularly whether squares serve as optimal shapes under magnetic fields, unlike the magnetic-free case which has explicit solutions.", "method": "Established lower and upper bounds for the eigenvalue, analyzed the problem for weak magnetic fields, and related the conjecture to eigenvalue simplicity and symmetry properties of minimizers in a non-convex minimization problem.", "result": "Confirmed the conjecture (square as global minimizer) for weak magnetic fields, and established connections between the conjecture's validity and eigenvalue simplicity/symmetry properties.", "conclusion": "The square appears to be the optimal shape minimizing the lowest magnetic Dirichlet Laplacian eigenvalue under area/perimeter constraints, particularly for weak fields, with deeper connections to spectral properties and symmetry."}}
{"id": "2508.16306", "pdf": "https://arxiv.org/pdf/2508.16306", "abs": "https://arxiv.org/abs/2508.16306", "authors": ["Nishant Jain", "Tong Zhang"], "title": "A Sharp KL-Convergence Analysis for Diffusion Models under Minimal Assumptions", "categories": ["stat.ML", "cs.LG", "math.AP", "math.ST", "stat.TH"], "comment": "30 pages, 1 figure", "summary": "Diffusion-based generative models have emerged as highly effective methods\nfor synthesizing high-quality samples. Recent works have focused on analyzing\nthe convergence of their generation process with minimal assumptions, either\nthrough reverse SDEs or Probability Flow ODEs. The best known guarantees,\nwithout any smoothness assumptions, for the KL divergence so far achieve a\nlinear dependence on the data dimension $d$ and an inverse quadratic dependence\non $\\varepsilon$. In this work, we present a refined analysis that improves the\ndependence on $\\varepsilon$. We model the generation process as a composition\nof two steps: a reverse ODE step, followed by a smaller noising step along the\nforward process. This design leverages the fact that the ODE step enables\ncontrol in Wasserstein-type error, which can then be converted into a KL\ndivergence bound via noise addition, leading to a better dependence on the\ndiscretization step size. We further provide a novel analysis to achieve the\nlinear $d$-dependence for the error due to discretizing this Probability Flow\nODE in absence of any smoothness assumptions. We show that\n$\\tilde{O}\\left(\\tfrac{d\\log^{3/2}(\\frac{1}{\\delta})}{\\varepsilon}\\right)$\nsteps suffice to approximate the target distribution corrupted with Gaussian\nnoise of variance $\\delta$ within $O(\\varepsilon^2)$ in KL divergence,\nimproving upon the previous best result, requiring\n$\\tilde{O}\\left(\\tfrac{d\\log^2(\\frac{1}{\\delta})}{\\varepsilon^2}\\right)$ steps.", "AI": {"tldr": "Improved convergence analysis for diffusion models with better dependence on discretization step size, reducing steps from O(d log\u00b2(1/\u03b4)/\u03b5\u00b2) to O(d log\u00b3/\u00b2(1/\u03b4)/\u03b5) to achieve O(\u03b5\u00b2) KL divergence error.", "motivation": "Existing diffusion model convergence guarantees have suboptimal dependence on \u03b5 (inverse quadratic) and discretization step size. The paper aims to provide refined analysis with improved error bounds.", "method": "Models generation as composition of reverse ODE step followed by smaller noising step. Leverages Wasserstein-type error control from ODE step, converted to KL divergence bound via noise addition. Novel analysis for discretizing Probability Flow ODE without smoothness assumptions.", "result": "Achieves O(d log\u00b3/\u00b2(1/\u03b4)/\u03b5) steps to approximate target distribution corrupted with Gaussian noise of variance \u03b4 within O(\u03b5\u00b2) KL divergence, improving from previous O(d log\u00b2(1/\u03b4)/\u03b5\u00b2) steps.", "conclusion": "The refined analysis provides significantly better convergence guarantees for diffusion models, with improved dependence on \u03b5 and step size, enabling more efficient sampling with fewer discretization steps."}}
{"id": "2508.16321", "pdf": "https://arxiv.org/pdf/2508.16321", "abs": "https://arxiv.org/abs/2508.16321", "authors": ["Jaume de Dios Pont", "Alexander W. Hsu", "Mitchell A. Taylor"], "title": "Sharp bounds on the failure of the hot spots conjecture", "categories": ["math.SP", "math-ph", "math.AP", "math.MP"], "comment": "17 pages, 4 figures", "summary": "The hot spots ratio of a domain $\\Omega\\subset \\mathbb{R}^d$ measures the\ndegree of failure of Rauch's hot spots conjecture on that domain. We identify\nthe largest possible value of this ratio over all connected Lipschitz domains\n$\\Omega\\subset \\mathbb{R}^d$, for any dimension $d$. As $d\\to \\infty$, we show\nthat this maximal ratio converges to $\\sqrt{e}$, which asymptotically matches\nthe previous best known upper bound by Mariano, Panzo and Wang. For $d\\ge 2$,\nwe show that sets extremizing the hot spots ratio do not exist, and extremizing\nsequences must converge to a ball at a quantitative rate. We then give a sharp\nbound on the measure of the set for which the first Neumann eigenfunction\nexceeds its maximal boundary value. From this we deduce that the hot spots\nconjecture is asymptotically true \"in measure'' as $d\\to \\infty$.", "AI": {"tldr": "This paper analyzes the hot spots ratio, which measures the failure of Rauch's hot spots conjecture. The authors identify the maximal possible ratio over connected Lipschitz domains in R^d, showing it converges to \u221ae as d\u2192\u221e, matching previous upper bounds. They prove extremizing sets don't exist for d\u22652 and extremizing sequences converge to balls at quantitative rates. The paper also provides sharp bounds on where Neumann eigenfunctions exceed boundary values, showing the conjecture becomes asymptotically true in measure as d\u2192\u221e.", "motivation": "To understand the degree of failure of Rauch's hot spots conjecture across different dimensions and domain types, and to identify the maximal possible hot spots ratio while studying the asymptotic behavior of this conjecture.", "method": "Mathematical analysis of the hot spots ratio over connected Lipschitz domains in R^d, using techniques from spectral theory, geometric analysis, and asymptotic methods to study convergence properties and extremal behavior.", "result": "The maximal hot spots ratio converges to \u221ae as d\u2192\u221e, matching previous upper bounds. For d\u22652, extremizing sets do not exist but extremizing sequences converge quantitatively to balls. The paper provides sharp bounds on eigenfunction behavior and shows the hot spots conjecture becomes asymptotically true in measure.", "conclusion": "The hot spots conjecture fails maximally with ratio approaching \u221ae in high dimensions, but extremal domains approach balls and the conjecture holds asymptotically in measure, providing a nuanced understanding of Rauch's conjecture across different dimensional settings."}}
