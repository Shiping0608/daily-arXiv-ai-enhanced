{"id": "2508.20187", "pdf": "https://arxiv.org/pdf/2508.20187", "abs": "https://arxiv.org/abs/2508.20187", "authors": ["Giulia Bertaglia", "Walter Boscheri", "Lorenzo Pareschi"], "title": "Multi-Order Monte Carlo IMEX hierarchies for uncertainty quantification in multiscale hyperbolic systems", "categories": ["math.NA", "cs.NA", "65C05, 65L04, 65L06, 65C30, 35L65, 35B40"], "comment": null, "summary": "We introduce a novel Multi-Order Monte Carlo approach for uncertainty\nquantification in the context of multiscale time-dependent partial differential\nequations. The new framework leverages Implicit-Explicit Runge-Kutta time\nintegrators to satisfy the asymptotic-preserving property across different\ndiscretization orders of accuracy. In contrast to traditional Multi-Level Monte\nCarlo methods, which require costly hierarchical re-meshing, our method\nconstructs a multi-order hierarchy by varying both spatial and temporal\ndiscretization orders within the Monte Carlo framework. This enables efficient\nvariance reduction while naturally adapting to the multiple scales inherent in\nthe problem. The proposed method is particularly well-suited for hyperbolic\nsystems with stiff relaxation, kinetic equations, and low Mach number flows,\nwhere standard Multi-Level Monte Carlo techniques often encounter computational\nchallenges. Numerical experiments demonstrate that the novel Multi-Order Monte\nCarlo approach achieves substantial reduction of both error and variance while\nmaintaining asymptotic consistency in the asymptotic limit.", "AI": {"tldr": "Novel Multi-Order Monte Carlo method for uncertainty quantification in multiscale time-dependent PDEs using Implicit-Explicit Runge-Kutta integrators with varying spatial/temporal discretization orders instead of hierarchical re-meshing.", "motivation": "Traditional Multi-Level Monte Carlo methods require costly hierarchical re-meshing and face computational challenges with hyperbolic systems, kinetic equations, and low Mach number flows with multiple scales.", "method": "Uses Implicit-Explicit Runge-Kutta time integrators to create multi-order hierarchy by varying both spatial and temporal discretization orders within Monte Carlo framework, satisfying asymptotic-preserving property.", "result": "Achieves substantial reduction of both error and variance while maintaining asymptotic consistency in the asymptotic limit, with efficient variance reduction.", "conclusion": "The Multi-Order Monte Carlo approach is particularly well-suited for multiscale problems and provides an effective alternative to traditional Multi-Level Monte Carlo with better computational efficiency."}}
{"id": "2508.20207", "pdf": "https://arxiv.org/pdf/2508.20207", "abs": "https://arxiv.org/abs/2508.20207", "authors": ["Nicholas H. Nelsen", "Yunan Yang"], "title": "Operator learning meets inverse problems: A probabilistic perspective", "categories": ["math.NA", "cs.LG", "cs.NA", "math.ST", "stat.TH", "35R30 (Primary) 68T07, 65N21 (Secondary)"], "comment": "87 pages, 5 figures", "summary": "Operator learning offers a robust framework for approximating mappings\nbetween infinite-dimensional function spaces. It has also become a powerful\ntool for solving inverse problems in the computational sciences. This chapter\nsurveys methodological and theoretical developments at the intersection of\noperator learning and inverse problems. It begins by summarizing the\nprobabilistic and deterministic approaches to inverse problems, and pays\nspecial attention to emerging measure-centric formulations that treat observed\ndata or unknown parameters as probability distributions. The discussion then\nturns to operator learning by covering essential components such as data\ngeneration, loss functions, and widely used architectures for representing\nfunction-to-function maps. The core of the chapter centers on the end-to-end\ninverse operator learning paradigm, which aims to directly map observed data to\nthe solution of the inverse problem without requiring explicit knowledge of the\nforward map. It highlights the unique challenge that noise plays in this\ndata-driven inversion setting, presents structure-aware architectures for both\npoint predictions and posterior estimates, and surveys relevant theory for\nlinear and nonlinear inverse problems. The chapter also discusses the\nestimation of priors and regularizers, where operator learning is used more\nselectively within classical inversion algorithms.", "AI": {"tldr": "Survey of operator learning methods for solving inverse problems, focusing on end-to-end approaches that map data directly to solutions without explicit forward models, and covering both probabilistic and deterministic frameworks.", "motivation": "To provide a comprehensive overview of the intersection between operator learning and inverse problems, addressing the need for efficient data-driven methods that can handle infinite-dimensional function spaces and complex mappings.", "method": "Covers probabilistic and deterministic approaches to inverse problems, measure-centric formulations, operator learning components (data generation, loss functions, architectures), and end-to-end inverse operator learning paradigms.", "result": "Presents a structured framework for understanding how operator learning can be applied to inverse problems, highlighting both point prediction and posterior estimation methods with structure-aware architectures.", "conclusion": "Operator learning provides powerful tools for solving inverse problems through direct data-to-solution mapping, with emerging theoretical foundations and applications across linear and nonlinear problems, including prior and regularizer estimation."}}
{"id": "2508.20255", "pdf": "https://arxiv.org/pdf/2508.20255", "abs": "https://arxiv.org/abs/2508.20255", "authors": ["Robert C. Kirby", "Scott P. MacLachlan", "Pablo D. Brubeck"], "title": "Automated Runge-Kutta-Nystr\u00f6m time stepping for finite element methods in Irksome", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Irksome is a library based on the Unified Form Language (UFL) that automates\nthe application of Runge-Kutta time-stepping methods for finite element spatial\ndiscretizations of partial differential equations (PDEs). This paper describes\nrecent updates to Irksome that allow users to express semidiscrete forms of\nPDEs that contain second-order temporal derivatives, whence it generates\nstage-coupled variational problems to be solved at each time step for\nRunge-Kutta-Nystr\\\"om methods. Firedrake then generates code for these\nvariational problems and provides a rich interface to PETSc for solving them.\nDirectly discretizing second-order time derivatives with Runge-Kutta-Nystr\\\"om\nmethods provides several advantages relative to discretizing a rewritten\nfirst-order system with a standard Runge-Kutta method. Besides working with an\ninterface closer to the problem formulation in UFL, avoiding these auxiliary\nvariables means that Runge-Kutta-Nystr\\\"om methods lead to smaller algebraic\nsystems and better run-time. Our numerical results indicate that, with\neffective preconditioning, fully implicit Runge-Kutta-Nystr\\\"om methods can be\nmade competitive with more traditional explicit methods for wave equations.\nThey are also (essentially) required to discretize wave-type equations with\nhigher-order spatial derivatives. We also provide numerical experiments for\nfully dynamic poroelasticity, a system of mixed temporal order, where our\ntime-stepping and algebraic solvers perform effectively even as we approach the\nincompressible limit.", "AI": {"tldr": "Irksome library now supports second-order temporal derivatives in PDEs using Runge-Kutta-Nystr\u00f6m methods, generating smaller algebraic systems and better performance compared to first-order reformulations.", "motivation": "To enable direct discretization of second-order time derivatives in PDEs without needing to rewrite them as first-order systems, providing more efficient and natural problem formulation.", "method": "Extends Irksome library based on UFL to generate stage-coupled variational problems for Runge-Kutta-Nystr\u00f6m methods, with Firedrake generating code and PETSc integration for solving.", "result": "Numerical results show fully implicit Runge-Kutta-Nystr\u00f6m methods can be competitive with explicit methods for wave equations when properly preconditioned, and effectively handle mixed temporal order systems like poroelasticity.", "conclusion": "The updates enable efficient solution of second-order temporal derivative problems with advantages in system size, runtime, and problem formulation fidelity, making implicit methods viable for wave-type equations."}}
{"id": "2508.20269", "pdf": "https://arxiv.org/pdf/2508.20269", "abs": "https://arxiv.org/abs/2508.20269", "authors": ["Julianne Chung", "Silvia Gazzola"], "title": "Randomized Krylov methods for inverse problems", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper we develop randomized Krylov subspace methods for efficiently\ncomputing regularized solutions to large-scale linear inverse problems.\nBuilding on the recently developed randomized Gram-Schmidt process, where\nsketched inner products are used to estimate inner products of high-dimensional\nvectors, we propose a randomized Golub-Kahan approach that works for general\nrectangular matrices. We describe new iterative solvers based on the randomized\nGolub-Kahan approach and show how they can be used for solving inverse problems\nwith rectangular matrices, thus extending the capabilities of the recently\nproposed randomized GMRES method. We also consider hybrid projection methods\nthat combine iterative projection methods, based on both the randomized Arnoldi\nand randomized Golub-Kahan factorizations, with Tikhonov regularization, where\nregularization parameters can be selected automatically during the iterative\nprocess. Numerical results from image deblurring and seismic tomography show\nthe potential benefits of these approaches.", "AI": {"tldr": "Randomized Krylov subspace methods using sketched inner products for efficient regularized solutions to large-scale linear inverse problems with rectangular matrices.", "motivation": "To develop efficient computational methods for solving large-scale linear inverse problems with rectangular matrices, extending beyond the capabilities of existing randomized GMRES methods.", "method": "Proposes randomized Golub-Kahan approach based on randomized Gram-Schmidt process, with iterative solvers and hybrid projection methods combining randomized Arnoldi/Golub-Kahan factorizations with Tikhonov regularization.", "result": "Numerical results from image deblurring and seismic tomography demonstrate the potential benefits of these randomized approaches.", "conclusion": "The proposed randomized Krylov subspace methods provide efficient solutions for large-scale linear inverse problems with rectangular matrices, showing promise in practical applications like image processing and seismic tomography."}}
{"id": "2508.20299", "pdf": "https://arxiv.org/pdf/2508.20299", "abs": "https://arxiv.org/abs/2508.20299", "authors": ["Peter P. Pronko", "Paul A. Van Rompay"], "title": "Isotope Enrichment and Element Separation by Self Generated Magnetic Centrifuge Fields in Ultrafast Laser Ablation", "categories": ["physics.plasm-ph", "physics.app-ph"], "comment": null, "summary": "A self-consistent model is developed to explain the anomalously large\nenrichment of nickel isotopes observed in ablation plumes from ultrafast laser\nirradiation of solid surfaces. The model is based on the spontaneous creation\nof a magnetic centrifuge in the ablation plume and the associated cyclotron\nrotation of plasma ions with rotation rates on the order of 10^9 radians per\nsecond. Mass separation occurs around the radial coordinate of cylindrical\nsymmetry with longitudinal axis normal to the ablating surface. A Gaussian\nshaped radial magnetic field distribution is extracted for Ni isotopes with\npeak field of 53 Megagauss and average field of 20 Megagauss. In addition to\ncyclotron rotation of ions, a rigid rotor model is also presented that is\nassociated with the hydrodynamic rotation of the entire plasma and is shown to\nbe of little consequence for the isotope enrichment. Cyclotron rotations\ndominate the process. A profound resonance of enrichment is observed for\nspecific cyclotron charge states and is shown to be associated with Ion\nBernstein Wave (IBW) coupling that provides electrostatic acceleration to these\nresonant orbits.", "AI": {"tldr": "A model explains nickel isotope enrichment in laser ablation plumes through magnetic centrifuge effects and cyclotron rotation of plasma ions, with resonance effects from Ion Bernstein Wave coupling.", "motivation": "To explain the anomalously large enrichment of nickel isotopes observed in ablation plumes from ultrafast laser irradiation of solid surfaces.", "method": "Developed a self-consistent model based on spontaneous creation of a magnetic centrifuge in the ablation plume, cyclotron rotation of plasma ions, and analysis of both cyclotron rotation and rigid rotor hydrodynamic models.", "result": "Extracted Gaussian-shaped radial magnetic field distribution for Ni isotopes with peak field of 53 Megagauss and average field of 20 Megagauss. Found cyclotron rotations dominate the process with profound resonance enrichment for specific charge states due to Ion Bernstein Wave coupling.", "conclusion": "The magnetic centrifuge mechanism and cyclotron rotation of ions (not hydrodynamic rotation) are the primary drivers of nickel isotope enrichment in laser ablation plumes, with resonant effects enhanced by Ion Bernstein Wave coupling."}}
{"id": "2508.20446", "pdf": "https://arxiv.org/pdf/2508.20446", "abs": "https://arxiv.org/abs/2508.20446", "authors": ["Menglei Li", "Haolin Li", "Bing Wang", "Bing Wang"], "title": "Self-consistent clustering analysis for homogenisation of heterogeneous plates", "categories": ["physics.comp-ph", "cs.CE", "physics.app-ph"], "comment": null, "summary": "This work introduces a reduced-order model for plate structures with periodic\nmicro-structures by coupling self-consistent clustering analysis (SCA) with the\nLippmann-Schwinger equation, enabling rapid multiscale homogenisation of\nheterogeneous plates. A plate-specific SCA scheme is derived for the first time\nand features two key elements: (i) an offline-online strategy that combines\nGreen's functions with k-means data compression, and (ii) an online\nself-consistent update that exploits the weak sensitivity of the reference\nmedium. The framework handles both linear and nonlinear problems in classical\nplate theory and first-order shear deformation theory, and its performance is\nverified on linear isotropic perforated plates and woven composites, as well as\non non-linear elasto-plastic perforated plates and woven composites with\ndamage. Across all cases the proposed model matches the accuracy of FFT-based\ndirect numerical simulation while reducing computational cost by over an order\nof magnitude.", "AI": {"tldr": "A reduced-order model for periodic micro-structured plates using self-consistent clustering analysis coupled with Lippmann-Schwinger equation for efficient multiscale homogenization.", "motivation": "To enable rapid multiscale homogenization of heterogeneous plate structures with periodic micro-structures while maintaining accuracy and reducing computational costs.", "method": "Developed a plate-specific SCA scheme with offline-online strategy combining Green's functions with k-means data compression, and online self-consistent update exploiting weak sensitivity of reference medium. Handles both linear/nonlinear problems in classical plate theory and first-order shear deformation theory.", "result": "The model matches FFT-based direct numerical simulation accuracy while reducing computational cost by over an order of magnitude. Verified on linear isotropic perforated plates, woven composites, and non-linear elasto-plastic cases with damage.", "conclusion": "The proposed framework provides an efficient and accurate reduced-order modeling approach for multiscale analysis of heterogeneous plate structures with significant computational savings."}}
{"id": "2508.20436", "pdf": "https://arxiv.org/pdf/2508.20436", "abs": "https://arxiv.org/abs/2508.20436", "authors": ["Reika Fukuizumi", "Tsukasa Iwabuchi"], "title": "Besov spaces associated with the Harmonic oscillator", "categories": ["math.AP", "math.FA", "30H25"], "comment": null, "summary": "The Besov space associated with the harmonic oscillator is introduced and\nthoroughly explored in this paper. It provides a comprehensive summary of the\nfundamental concepts of the Besov spaces, their embedding properties, bilinear\nestimates, and related topics.", "AI": {"tldr": "Introduction and exploration of Besov spaces associated with harmonic oscillators, covering fundamental concepts, embedding properties, and bilinear estimates.", "motivation": "To establish and systematically study Besov spaces specifically associated with harmonic oscillators, which are fundamental mathematical objects in analysis and quantum mechanics.", "method": "Mathematical analysis and theoretical development of Besov space theory in the context of harmonic oscillators, including proofs of embedding properties and bilinear estimates.", "result": "Comprehensive framework for Besov spaces linked to harmonic oscillators with established fundamental properties, embedding theorems, and bilinear estimation results.", "conclusion": "Successfully developed the theory of Besov spaces for harmonic oscillators, providing essential mathematical tools for analysis in this context with proven properties and estimates."}}
{"id": "2508.20311", "pdf": "https://arxiv.org/pdf/2508.20311", "abs": "https://arxiv.org/abs/2508.20311", "authors": ["Renu Chaudhary", "Kai Diethelm", "Afshin Farhadi", "Fred A. Fuchs"], "title": "An Efficient Exponential Sum Approximation of Power-Law Kernels for Solving Fractional Differential Equation", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this work, we present a comprehensive framework for approximating the\nweakly singular power-law kernel $t^{\\alpha-1}$ of fractional integral and\ndifferential operators, where $\\alpha \\in (0,1)$ and $t \\in [\\delta,T]$ with\n$0<\\delta<T<\\infty$, using a finite sum of exponentials. This approximation\nmethod begins by substituting an exponential function into the Laplace\ntransform of the power function, followed by the application of the trapezoidal\nrule to approximate the resulting integral. To ensure computational\nfeasibility, the integral limits are truncated, leading to a finite exponential\nsum representation of the kernel. In contrast to earlier approaches, we\npre-specify the admitted computational cost (measured in terms of the number of\nexponentials) and minimize the approximation error. Furthermore, to reduce the\ncomputational cost while maintaining accuracy, we present a two-stage algorithm\nbased on Prony's method that compresses the exponential sum. The compressed\nkernel is then embedded into the Riemann-Liouville fractional integral and\napplied to solve fractional differential equations. To this end, we discuss two\nsolution strategies, namely (a) method based on piecewise constant\ninterpolation and (b) a transformation of the original fractional differential\nequation into a system of first-order ordinary differential equations (ODEs).\nThis reformulation makes the problem solvable by standard ODE solvers with low\ncomputational cost while retaining the accuracy benefits of the\nexponential-sum-approximation. Finally, we apply the proposed strategies to\nsolve some well-known fractional differential equations and demonstrate the\nadvantages, accuracy, and the experimental order of convergence of the methods\nthrough numerical results.", "AI": {"tldr": "A framework for approximating fractional integral/differential operators using exponential sums with controlled computational cost and error minimization, featuring compression techniques and application to solving fractional differential equations.", "motivation": "To develop an efficient and accurate method for approximating weakly singular power-law kernels in fractional calculus, enabling practical solution of fractional differential equations with controlled computational complexity.", "method": "Uses exponential sum approximation of the power-law kernel via Laplace transform and trapezoidal rule, with truncation for feasibility. Implements a two-stage compression algorithm using Prony's method. Embeds compressed kernel into Riemann-Liouville fractional integral and applies two solution strategies: piecewise constant interpolation and transformation to ODE systems.", "result": "The method achieves accurate approximation of fractional operators with pre-specified computational cost. Numerical results demonstrate advantages, accuracy, and experimental order of convergence when applied to well-known fractional differential equations.", "conclusion": "The proposed framework provides an efficient and accurate approach for solving fractional differential equations using exponential sum approximations with controlled computational complexity, making them solvable by standard ODE solvers while maintaining accuracy."}}
{"id": "2508.20303", "pdf": "https://arxiv.org/pdf/2508.20303", "abs": "https://arxiv.org/abs/2508.20303", "authors": ["W. Yao", "I. Cohen", "P. Suarez Gerona", "H. Ahmed", "A. F. A. Bott", "S. N. Chen", "M. Cook", "R. Leli\u00e8vre", "P. Martin", "T. Waltenspiel", "P. Antici", "J. B\u00e9ard", "M. Borghesi", "D. Caprioli", "A. Ciardi", "E. d'Humi\u00e8res", "M. Fran\u00e7ois", "L. Gremillet", "A. Marcowith", "M. Miceli", "T. Seebaruth", "S. Orlando", "J. Fuchs"], "title": "Efficient ion re-acceleration in laboratory-produced interpenetrating collisionless shocks", "categories": ["physics.plasm-ph", "astro-ph.HE"], "comment": null, "summary": "Although the origin of cosmic rays (CRs) remains an open question,\ncollisionless magnetized shock waves are widely regarded as key sites for\nparticle acceleration. Recent theories further suggest that shock-shock\ncollisions in stellar clusters could provide the additional acceleration needed\nto explain the observed high-energy CR spectrum. Here, we investigate this\nhypothesis through a laser-based experiment that creates magnetized plasma\nconditions similar to astrophysical environments. Our results demonstrate that\ninterpenetrating collisionless shocks can significantly boost the energy of\nambient protons previously energized by the individual shocks, while also\nimproving the overall acceleration efficiency. Numerical kinetic simulations\ncorroborate these findings, revealing that protons are reaccelerated via their\nbouncing motion in the convective electric fields of the colliding magnetized\nflows. By allowing to highly energize ambient protons, our novel\ncolliding-shock platform opens the prospect to test the long-discussed\nmechanism of diffusive shock acceleration in a controlled laboratory setting.", "AI": {"tldr": "Laser experiment shows colliding magnetized shocks boost proton acceleration, supporting cosmic ray theories.", "motivation": "To test the hypothesis that shock-shock collisions in stellar clusters could explain high-energy cosmic ray spectra through additional particle acceleration.", "method": "Laser-based experiment creating magnetized plasma conditions similar to astrophysical environments, combined with numerical kinetic simulations.", "result": "Interpenetrating collisionless shocks significantly boost ambient proton energy and improve acceleration efficiency; protons are reaccelerated via bouncing motion in convective electric fields.", "conclusion": "The colliding-shock platform provides a controlled laboratory setting to test diffusive shock acceleration mechanisms for cosmic ray origins."}}
{"id": "2508.21012", "pdf": "https://arxiv.org/pdf/2508.21012", "abs": "https://arxiv.org/abs/2508.21012", "authors": ["Magnus F Ivarsen"], "title": "Spectral density characteristics of self-organized structuring in phase-synchronized oscillator ensembles", "categories": ["physics.comp-ph", "nlin.CD"], "comment": "7 pages, 4 figures", "summary": "Self-organized turbulence represents a way for structuring in nature to arise\nthrough sheer complexity rather than through linear instability theory.\nSimulating ensembles of oscillators that undergo phase synchronization through\na propagating Kuramoto-interaction field, we present the spectral\ncharacteristics of spontaneous, self-organized structures of locally coupled\noscillators. We demonstrate that the spectral density of emergent structures\ncan exhibit universal scaling laws, in line with expectations from nature,\nindicating that observed statistical outcomes of complex physical interactions\ncan be achieved through a more general principle of self-organization. We\nsuggest that spontaneously generated structures may provide nuance to the\nreigning reductionist explanations for the observed structure in coupled\nsystems of astrophysical and geophysical plasmas.", "AI": {"tldr": "Self-organized turbulence emerges from complex oscillator systems through phase synchronization, exhibiting universal scaling laws that challenge reductionist explanations in astrophysical and geophysical plasmas.", "motivation": "To understand how structured patterns in nature can arise through complexity rather than linear instability theory, particularly in coupled systems like astrophysical and geophysical plasmas.", "method": "Simulating ensembles of oscillators with phase synchronization through a propagating Kuramoto-interaction field to study spectral characteristics of spontaneous structures.", "result": "The spectral density of emergent structures shows universal scaling laws that align with natural observations, demonstrating complex physical interactions can be achieved through self-organization principles.", "conclusion": "Spontaneously generated structures provide alternative explanations to reductionist approaches for observed structures in coupled plasma systems, suggesting self-organization as a fundamental principle."}}
{"id": "2508.20523", "pdf": "https://arxiv.org/pdf/2508.20523", "abs": "https://arxiv.org/abs/2508.20523", "authors": ["Francesco Bozzola", "Edoardo Mainini"], "title": "Equilibria of aggregation-diffusion models with nonlinear potentials", "categories": ["math.AP", "35K44, 35R11, 49K20"], "comment": "37 pages", "summary": "We consider an evolution model with nonlinear diffusion of porous medium type\nin competition with a nonlocal drift term favoring mass aggregation. The\ndistinguishing trait of the model is the choice of a nonlinear $(s,p)$ Riesz\npotential for describing the overall aggregation effect. We investigate radial\nstationary states of the dynamics, showing their relation with extremals of\nsuitable Hardy-Littlewood-Sobolev inequalities. In the case that aggregation\ndoes not dominate over diffusion, radial stationary states also relate to\nglobal minimizers of a homogeneous free energy functional featuring the $(s,p)$\nenergy associated to the nonlinear potential. In the limit as the fractional\nparameter $s$ tends to zero, the nonlocal interaction term becomes a backward\ndiffusion and we describe the asymptotic behavior of the stationary states.", "AI": {"tldr": "Analysis of a nonlinear diffusion-aggregation model with (s,p) Riesz potential, focusing on radial stationary states and their connection to Hardy-Littlewood-Sobolev inequalities and free energy minimization.", "motivation": "To understand the competition between nonlinear diffusion (porous medium type) and nonlocal aggregation effects described by nonlinear Riesz potentials, and to characterize stationary states in such systems.", "method": "Investigation of radial stationary states, analysis of their relation to extremals of Hardy-Littlewood-Sobolev inequalities, study of global minimizers of homogeneous free energy functionals, and asymptotic analysis as the fractional parameter s approaches zero.", "result": "Established connections between radial stationary states and extremals of Hardy-Littlewood-Sobolev inequalities. Showed that when aggregation doesn't dominate diffusion, these states relate to global minimizers of free energy. Described asymptotic behavior of stationary states as s\u21920, where nonlocal interaction becomes backward diffusion.", "conclusion": "The model reveals rich mathematical structure connecting nonlinear diffusion-aggregation dynamics with functional inequalities and free energy minimization principles, with interesting asymptotic behavior in the fractional parameter limit."}}
{"id": "2508.20339", "pdf": "https://arxiv.org/pdf/2508.20339", "abs": "https://arxiv.org/abs/2508.20339", "authors": ["Max Kreider", "Peter J. Thomas", "Yao Li"], "title": "Artificial neural network solver for Fokker-Planck and Koopman eigenfunctions", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "For a stochastic differential equation (SDE) that is an It\\^{o} diffusion or\nLangevin equation, the Fokker-Planck operator governs the evolution of the\nprobability density, while its adjoint, the infinitesimal generator of the\nstochastic Koopman operator, governs the evolution of system observables, in\nthe mean. The eigenfunctions of these operators provide a powerful framework to\nanalyze SDEs, and have shown to be particularly useful for systems of\nstochastic oscillators. However, computing these eigenfunctions typically\nrequires solving high-dimensional PDEs on unbounded domains, which is\nnumerically challenging. Building on previous work, we propose a data-driven\nartificial neural network solver for Koopman and Fokker-Planck eigenfunctions.\nOur approach incorporates the differential operator into the loss function,\nimproving accuracy and reducing dependence on large amounts of accurate\ntraining data. We demonstrate our approach on several numerical examples in\ntwo, three, and four dimensions.", "AI": {"tldr": "Neural network solver for computing eigenfunctions of Fokker-Planck and Koopman operators in stochastic differential equations, using operator-based loss functions to reduce data dependency.", "motivation": "Traditional methods for computing eigenfunctions of Fokker-Planck and stochastic Koopman operators require solving high-dimensional PDEs on unbounded domains, which is numerically challenging and computationally expensive.", "method": "Data-driven artificial neural network solver that incorporates the differential operator directly into the loss function, improving accuracy while reducing the need for large amounts of accurate training data.", "result": "The approach was successfully demonstrated on several numerical examples in two, three, and four dimensions, showing effective computation of eigenfunctions for stochastic systems.", "conclusion": "The proposed neural network method provides an effective alternative to traditional PDE solvers for computing eigenfunctions in stochastic systems, offering improved accuracy with reduced data requirements."}}
{"id": "2508.20502", "pdf": "https://arxiv.org/pdf/2508.20502", "abs": "https://arxiv.org/abs/2508.20502", "authors": ["L. Singh", "M. De Bastiani", "R. Bonifetto", "F. Subba", "D. Borgogno"], "title": "Assessment of the Runaway Electrons induced damage to the Tokamak First Wall", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The study assessed the damage caused by Runaway Electrons (RE) on First Wall\ntiles, comparing the effects on Beryllium and Tungsten. This was done by using\nrealistic RE energy distribution functions to replicate RE impacts through the\nFLUKA code. These energy distribution functions are based on the ASDEX Upgrade\nexperiment # 39012. The parametric analysis carried out with FLUKA in the\npresence of magnetic fields indicated a clear relationship between the beam\nimpact angle and the material deposited energy, demonstrating that higher\nimpact angles lead to deeper electron penetration and greater deposited\nenergies. A finite element model based on apparent heat capacity formulation in\nFreeFem++ was developed to analyze the material thermal response to such\nthermal loads using volumetric energy density profiles from FLUKA simulations\nas input. Different RE current values were simulated to show its influence on\nthe evolution of the material temperature and melting thickness", "AI": {"tldr": "Comparison of Beryllium vs Tungsten first wall tile damage from Runaway Electrons using FLUKA simulations and thermal analysis", "motivation": "To assess and compare the damage caused by Runaway Electrons on different first wall materials (Beryllium and Tungsten) in fusion reactors", "method": "Used FLUKA code with realistic RE energy distributions from ASDEX Upgrade experiment to simulate impacts, then developed finite element thermal model in FreeFem++ to analyze thermal response using volumetric energy density profiles", "result": "Found clear relationship between beam impact angle and deposited energy - higher angles lead to deeper penetration and greater energy deposition. Different RE current values significantly influence material temperature evolution and melting thickness", "conclusion": "The study provides quantitative analysis of RE damage mechanisms on first wall materials, showing Tungsten and Beryllium respond differently to RE impacts, with implications for fusion reactor material selection and design"}}
{"id": "2508.20347", "pdf": "https://arxiv.org/pdf/2508.20347", "abs": "https://arxiv.org/abs/2508.20347", "authors": ["Fumika Suzuki", "Ying Wai Li", "Wojciech H. Zurek"], "title": "Machine learning topological defect formation", "categories": ["cond-mat.stat-mech", "gr-qc", "hep-ph", "hep-th", "physics.comp-ph"], "comment": "7 pages, 5 figures", "summary": "According to the Kibble-Zurek mechanism (KZM), the density of topological\ndefects created during a second-order phase transition is determined by the\ncorrelation length at the freeze-out time. This suggests that the final\nconfiguration of topological defects in such a transition is largely\nestablished during the impulse regime, soon after the critical point is\ntraversed. Motivated by this, we conjecture that machine learning (ML) can\npredict the final configuration of topological defects based on the time\nevolution of the order parameter over a short interval in the vicinity of the\ncritical point, well before the order parameter settles into the emerging new\nminima resulting from spontaneous symmetry breaking. Furthermore, we show that\nthe predictability of ML also follows the power law scaling dictated by KZM. We\ndemonstrate these using a Recurrent Neural Network.", "AI": {"tldr": "Machine learning can predict final topological defect configurations from early order parameter evolution near critical points, following Kibble-Zurek mechanism scaling laws.", "motivation": "The Kibble-Zurek mechanism suggests topological defect formation is determined early in phase transitions, motivating investigation of whether machine learning can predict final defect configurations from early-stage data.", "method": "Used a Recurrent Neural Network to analyze the time evolution of the order parameter during a short interval near the critical point of second-order phase transitions.", "result": "Machine learning successfully predicts final topological defect configurations based on early order parameter evolution, and this predictability follows the same power law scaling as dictated by the Kibble-Zurek mechanism.", "conclusion": "ML can accurately forecast topological defect outcomes from limited early data, demonstrating that defect formation patterns are encoded in the initial dynamics near critical points, consistent with KZM predictions."}}
{"id": "2508.20548", "pdf": "https://arxiv.org/pdf/2508.20548", "abs": "https://arxiv.org/abs/2508.20548", "authors": ["Alexandra V. Antoniouk", "Anatoly N. Kochubei"], "title": "Non-Archimedean Neumann problem: weak and strong solutions", "categories": ["math.AP", "math.NT", "35S15, 11S80"], "comment": null, "summary": "We consider the Neumann problem for the equation with the\nVladimirov-Taibleson fractional differentiation operator over a non-Archimedean\nlocal field. We study weak solutions following the method by Dipierro, Ros-Oton\nand Valdinoci (2017). Our investigation of strong solutions is based on the\nultrametric identities for the operator under consideration.", "AI": {"tldr": "Analysis of Neumann problem for fractional differentiation operator in non-Archimedean local fields, examining both weak and strong solutions using different mathematical approaches.", "motivation": "To extend the understanding of fractional differentiation operators to non-Archimedean local fields and develop solution methods for Neumann problems in this mathematical context.", "method": "For weak solutions: followed the approach by Dipierro, Ros-Oton and Valdinoci (2017). For strong solutions: utilized ultrametric identities specific to the Vladimirov-Taibleson fractional differentiation operator.", "result": "Developed analytical frameworks for both weak and strong solutions to the Neumann problem involving the Vladimirov-Taibleson operator in non-Archimedean settings.", "conclusion": "The paper establishes mathematical foundations for solving Neumann problems with fractional differentiation operators in non-Archimedean local fields, providing both weak and strong solution methodologies."}}
{"id": "2508.20361", "pdf": "https://arxiv.org/pdf/2508.20361", "abs": "https://arxiv.org/abs/2508.20361", "authors": ["Tengteng Cui", "Chengtao Sheng", "Bihao Su", "Zhi Zhou"], "title": "Numerical Method for Space-Time Fractional Diffusion: A Stochastic Approach", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we develop and analyze a stochastic algorithm for solving\nspace-time fractional diffusion models, which are widely used to describe\nanomalous diffusion dynamics. These models pose substantial numerical\nchallenges due to the memory effect of the time-fractional derivative and the\nnonlocal nature of the spatial fractional Laplacian and the, leading to\nsignificant computational costs and storage demands, particularly in\nhigh-dimensional settings. To overcome these difficulties, we propose a Monte\nCarlo method based on the Feynman--Kac formula for space-time fractional\nmodels. The novel algorithm combines the simulation of the monotone path of a\nstable subordinator in time with the ``walk-on-spheres'' method that\nefficiently simulates the stable Levy jumping process in space. We rigorously\nderive error bounds for the proposed scheme, explicitly expressed in terms of\nthe number of simulation paths and the time step size. Numerical experiments\nconfirm the theoretical error bounds and demonstrate the computational\nefficiency of the method, particularly in domains with complex geometries or\nhigh-dimensional spaces. Furthermore, both theoretical and numerical results\nemphasize the robustness of the proposed approach across a range of fractional\norders, particularly for small fractional values, a capability often absent in\ntraditional numerical methods.", "AI": {"tldr": "A stochastic Monte Carlo algorithm combining stable subordinator simulation and walk-on-spheres method for solving space-time fractional diffusion models with proven error bounds and computational efficiency.", "motivation": "Space-time fractional diffusion models present significant computational challenges due to memory effects and nonlocal operators, especially in high dimensions, requiring efficient numerical methods.", "method": "Monte Carlo method based on Feynman-Kac formula, combining simulation of monotone path of stable subordinator for time and walk-on-spheres method for spatial stable Levy jumping process.", "result": "Rigorous error bounds derived in terms of simulation paths and time step size. Numerical experiments confirm theoretical bounds and show efficiency in complex geometries and high-dimensional spaces.", "conclusion": "The proposed stochastic algorithm is robust across fractional orders, particularly effective for small fractional values, and outperforms traditional methods in computational efficiency."}}
{"id": "2508.20627", "pdf": "https://arxiv.org/pdf/2508.20627", "abs": "https://arxiv.org/abs/2508.20627", "authors": ["Kentaro Sakai", "Kentaro Tomita", "Takeo Hoshi", "Ryo Yasuhara"], "title": "Monte Carlo simulation method for incoherent Thomson scattering spectra from arbitrary electron distribution functions", "categories": ["physics.plasm-ph"], "comment": "13 pages, 6 figures", "summary": "We developed a Monte Carlo simulation method to calculate incoherent Thomson\nscattering spectra in high temperature plasmas. The basic idea is to treat the\nentire scattering process as the superposition of individual photon-electron\ninteractions. We introduce macro-particles, referred from particle-in-cell\nsimulations, to reduce the computational cost, and obtain scattered spectra\nwithin a reasonable computational time. Since the velocity of the interacting\nelectron is randomly sampled from an electron distribution function, the method\ncan be applied to arbitrary electron distribution functions provided an\nappropriate sampling scheme is available. We present simulation results for\nrelativistic Maxwellian and kappa distribution functions, and compare them with\nboth analytical and numerical spectra for validation. The simulated spectra\nshow good agreement with both analytical and numerical results, demonstrating\nthat the Monte Carlo simulation method can reliably reproduce incoherent\nThomson scattering spectra.", "AI": {"tldr": "Monte Carlo simulation method for calculating incoherent Thomson scattering spectra in high-temperature plasmas using macro-particles and random sampling from electron distribution functions.", "motivation": "To develop an efficient computational method for calculating incoherent Thomson scattering spectra that can handle arbitrary electron distribution functions with reasonable computational cost.", "method": "Treats scattering as superposition of individual photon-electron interactions, uses macro-particles from particle-in-cell simulations to reduce computational cost, and randomly samples electron velocities from distribution functions.", "result": "Simulated spectra for relativistic Maxwellian and kappa distribution functions show good agreement with both analytical and numerical results.", "conclusion": "The Monte Carlo simulation method reliably reproduces incoherent Thomson scattering spectra and can be applied to arbitrary electron distribution functions with appropriate sampling."}}
{"id": "2508.20422", "pdf": "https://arxiv.org/pdf/2508.20422", "abs": "https://arxiv.org/abs/2508.20422", "authors": ["Tatsuya Wada", "Masakiyo Kitazawa", "Kazuyuki Kanaya"], "title": "Lee-Yang-zero ratio method in three-dimensional Ising model", "categories": ["cond-mat.stat-mech", "hep-lat", "hep-ph", "physics.comp-ph"], "comment": "27 pages, 7 figures", "summary": "By performing Monte Carlo simulations of the three-dimensional Ising model,\nwe apply the recently proposed Lee-Yang-zero ratio (LYZR) method to determine\nthe location of the critical point in this model. We demonstrate that the LYZR\nmethod is as powerful as the conventional Binder-cumulant method in studying\nthe critical point, while the LYZR method has the advantage of suppressing the\nviolation of the finite-size scaling and non-linearity near the critical point.\nWe also achieve a precise determination of the values of the LYZRs at the\ncritical point, which are universal numbers. In addition, we propose an\nalternative method that uses only a single Lee-Yang zero and show that it is\nalso useful for the search for the critical point.", "AI": {"tldr": "The paper applies the Lee-Yang-zero ratio method to determine the critical point in the 3D Ising model, showing it's as effective as conventional methods with better suppression of finite-size scaling violations.", "motivation": "To develop and validate the Lee-Yang-zero ratio method as an alternative approach for precisely locating critical points in statistical physics models, particularly addressing limitations of existing methods.", "method": "Monte Carlo simulations of the three-dimensional Ising model combined with the Lee-Yang-zero ratio method, comparing it with the conventional Binder-cumulant method.", "result": "The LYZR method proved equally powerful as Binder-cumulant method for critical point determination, with superior suppression of finite-size scaling violations and non-linearity near criticality. Precise universal values of LYZRs were obtained.", "conclusion": "The Lee-Yang-zero ratio method is a robust alternative for critical point analysis, offering advantages over traditional methods, and a single-zero variant also shows promise for critical point searches."}}
{"id": "2508.20624", "pdf": "https://arxiv.org/pdf/2508.20624", "abs": "https://arxiv.org/abs/2508.20624", "authors": ["Chenxi Deng", "Zhaobin Kuang", "Zhuangyi Liu", "Qiong Zhang"], "title": "Regularity Analysis for Two Coupled Second Order Evolution Equations", "categories": ["math.AP", "35B65, 35K90, 35L90, 47D03, 93D05"], "comment": null, "summary": "We investigate the regularity of the strongly continuous semigroup associated\nwith a system of two coupled second order evolution equations with indirect\ndamping, whose stability was recently studied by Hao et al. By deriving the\nasymptotic expression of the eigenvalues the generator, we partition the\nparameter space into several disjoint regions, where the semigroup exhibits\neither analyticity or Gevrey class regularity. Together with the estimate of\nthe resolvent of the generator on the imaginary axis, we give a complete and\nsharp regularity characterization for this system.", "AI": {"tldr": "Analysis of regularity properties for a semigroup from coupled second-order evolution equations with indirect damping, showing analyticity or Gevrey class regularity in different parameter regions.", "motivation": "To provide a complete and sharp characterization of the regularity properties of the semigroup associated with coupled second-order evolution equations with indirect damping, building on recent stability studies.", "method": "Derived asymptotic expressions of eigenvalues of the generator, partitioned parameter space into disjoint regions, and estimated the resolvent of the generator on the imaginary axis.", "result": "Successfully partitioned parameter space into regions where the semigroup exhibits either analyticity or Gevrey class regularity, providing a complete regularity characterization.", "conclusion": "The study offers a comprehensive and sharp regularity analysis for the semigroup of coupled second-order evolution equations with indirect damping, with different regularity properties emerging in distinct parameter regions."}}
{"id": "2508.20440", "pdf": "https://arxiv.org/pdf/2508.20440", "abs": "https://arxiv.org/abs/2508.20440", "authors": ["Xun Yang", "Guanqiu Ma"], "title": "D3PINNs: A Novel Physics-Informed Neural Network Framework for Staged Solving of Time-Dependent Partial Differential Equations", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we propose a novel framework, Dynamic Domain Decomposition\nPhysics-Informed Neural Networks (D3PINNs), for solving time-dependent partial\ndifferential equations (PDEs). In this framework, solutions of time-dependent\nPDEs are dynamically captured. First, an approximate\n  solution is obtained by the Physics-Informed Neural Networks (PINNs)\ncontaining the domain decomposition, then the time derivative terms in the PDE\nwill be retained and the other terms associated with the solution will be\nreplaced with the approximate solution. As a result, the PDE reduces to an\nordinary differential equations (ODEs). Finally, the time-varying solution will\nbe solved by the classical numerical methods for ODEs. D3PINNs retain the\ncomputational efffciency and ffexibility inherent to PINNs and enhance the\nability for capturing solutions of time-dependent PDEs. Numerical experiments\nvalidate the effectiveness of the proposed methods.", "AI": {"tldr": "D3PINNs framework combines PINNs with dynamic domain decomposition to solve time-dependent PDEs by reducing them to ODEs, maintaining PINN efficiency while improving time-dependent solution capture.", "motivation": "To enhance Physics-Informed Neural Networks' ability to solve time-dependent PDEs more effectively while retaining computational efficiency.", "method": "Uses PINNs with domain decomposition to get approximate solution, then reduces PDE to ODE by replacing spatial terms, and solves with classical ODE numerical methods.", "result": "Framework successfully captures dynamic solutions of time-dependent PDEs while maintaining computational efficiency of PINNs.", "conclusion": "D3PINNs provide an effective approach for solving time-dependent PDEs by combining neural networks with classical numerical methods, validated through numerical experiments."}}
{"id": "2508.20878", "pdf": "https://arxiv.org/pdf/2508.20878", "abs": "https://arxiv.org/abs/2508.20878", "authors": ["A. J. Crilly", "P. W. Moloney", "D. Shi", "E. A. Ferdinandi"], "title": "Automated simulation-based design via multi-fidelity active learning and optimisation for laser direct drive implosions", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The design of inertial fusion experiments is a complex task as driver energy\nmust be delivered in a precise manner to a structured target to achieve a fast,\nbut hydrodynamically stable, implosion. Radiation-hydrodynamics simulation\ncodes are an essential tool in this design process. However, multi-dimensional\nsimulations that capture hydrodynamic instabilities are more computationally\nexpensive than optimistic, 1D, spherically symmetric simulations which are\noften the primary design tool. In this work, we develop a machine learning\nframework that aims to effectively use information from a large number of 1D\nsimulations to inform design in the presence of hydrodynamic instabilities. We\nuse an ensemble of neural network surrogate models trained on both 1D and 2D\ndata to capture the space of good designs, i.e. those that are robust to\nhydrodynamic instabilities. We use this surrogate to perform Bayesian\noptimisation to find optimal designs for a 25 kJ laser driver. We perform\nhydrodynamic scaling on these designs to confirm the achievement of high gain\nfor a 2 MJ laser driver, using 2D simulations including alpha heating effects.", "AI": {"tldr": "Machine learning framework using neural network surrogates trained on 1D and 2D simulations to optimize inertial fusion designs robust to hydrodynamic instabilities, achieving high gain for laser drivers.", "motivation": "Inertial fusion design requires balancing computational efficiency (1D simulations) with accuracy in capturing hydrodynamic instabilities (expensive 2D simulations). Current methods rely heavily on optimistic 1D designs that may not account for instability effects.", "method": "Developed ensemble neural network surrogate models trained on both 1D and 2D simulation data to identify robust designs. Used Bayesian optimization with the surrogate to find optimal designs for 25 kJ laser driver, then performed hydrodynamic scaling to 2 MJ driver.", "result": "Successfully identified optimal designs that are robust to hydrodynamic instabilities. Achieved high gain for 2 MJ laser driver using 2D simulations that include alpha heating effects.", "conclusion": "The machine learning framework effectively bridges the gap between computationally cheap 1D simulations and expensive 2D simulations, enabling efficient identification of robust inertial fusion designs that maintain performance under realistic hydrodynamic instability conditions."}}
{"id": "2508.20448", "pdf": "https://arxiv.org/pdf/2508.20448", "abs": "https://arxiv.org/abs/2508.20448", "authors": ["Takumi Kojima", "Ikki Yasuda", "Takumi Sato", "Noriyoshi Arai", "Kenji Yasuoka"], "title": "Enhanced premelting at the ice-rubber interface using all-atom molecular dynamics simulation", "categories": ["cond-mat.soft", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "The ice-rubber interface is critical in applications such as tires and shoe\noutsoles, yet its molecular tribology remains unclear. Using all-atom molecular\ndynamics simulations, we studied premelting layers at the basal face of ice in\ncontact with styrene-butadiene rubber from 254 to 269 K. Despite its\nhydrophobicity, rubber enhances structural disorder of interfacial water,\npromoting premelting. In contrast, water mobility is suppressed by confinement\nfrom polymer chains, leading to glassy dynamics distinct from the ice-vapor\ninterface. Near the melting point, rubber chains become more flexible and\npenetrate the premelting layer, forming a mixed rubber-water region that\ncouples the dynamics of both components. These results suggest that nanoscale\nroughness and morphology of hydrophobic polymers disrupt ice hydrogen-bond\nnetworks, thereby enhancing premelting. Our findings provide molecular-level\ninsight into ice slipperiness and inform the design of polymer materials with\ncontrolled ice adhesion and friction.", "AI": {"tldr": "Molecular dynamics simulations reveal how hydrophobic rubber enhances ice premelting by disrupting water structure while suppressing water mobility through confinement, creating a mixed rubber-water interface near melting point.", "motivation": "Understanding the molecular tribology of ice-rubber interfaces is critical for applications like tires and shoe outsoles, but the fundamental mechanisms remain unclear.", "method": "All-atom molecular dynamics simulations of styrene-butadiene rubber in contact with basal face of ice across temperatures from 254 to 269 K.", "result": "Rubber enhances structural disorder of interfacial water (promoting premelting) but suppresses water mobility through confinement. Near melting point, rubber chains penetrate premelting layer forming mixed rubber-water region that couples dynamics.", "conclusion": "Nanoscale roughness and morphology of hydrophobic polymers disrupt ice hydrogen-bond networks to enhance premelting, providing insights for designing polymer materials with controlled ice adhesion and friction."}}
{"id": "2508.20690", "pdf": "https://arxiv.org/pdf/2508.20690", "abs": "https://arxiv.org/abs/2508.20690", "authors": ["Catherine Choquet", "Mohamed Ouhadan", "Mouhcine Tilioua"], "title": "Homogenized phase transition model for perforated ferromagnetic media", "categories": ["math.AP", "78M40, 78A25, 35Q60, 82C26"], "comment": null, "summary": "This work presents a rigorous prediction of the effective equations governing\nthe paramagnetic-ferromagnetic phase transition in a perforated\nthree-dimensional body. Assuming a periodic distribution of perforations, we\ninvestigate the asymptotic behavior of solutions to the equations describing\nthe thermodynamic and electromagnetic properties of the material as the period\nof the microstructure tends to zero. The microscopic model is a phase-field\nmodel within the Ginzburg-Landau framework for second-order phase transitions,\nwhere the phase-field is directly related to the magnetization vector. This\nmodel couples a nonlinear equation for the magnetization with the quasi-static\nMaxwell system and another nonlinear equation for the temperature. The primary\nmathematical challenge lies in homogenizing these equations, which exhibit a\ncomplex doubly non-linear structure. Additionally, the extension operators used\nwithin the homogenization framework precludes the application of standard\nAubin--Lions compactness arguments. Our analysis employs two-scale convergence\nin conjunction with a two-scale decomposition based on an appropriate dilation\noperator. The nonlinearities are primarily addressed by means of a variant of\ncompensated compactness and a Vitali compactness argument. From the perspective\nof practical applications, this work enables the explicit calculation of a\nCurie temperature tensor, capturing at the macroscopic scale the coupled effect\nof the material's geometric structure and its magnetic permeability tensor.", "AI": {"tldr": "Homogenization of phase-field model for paramagnetic-ferromagnetic transition in perforated 3D materials, deriving effective macroscopic equations and Curie temperature tensor.", "motivation": "To rigorously predict effective equations governing phase transitions in perforated magnetic materials with periodic microstructures, enabling macroscopic characterization of coupled geometric and magnetic properties.", "method": "Uses two-scale convergence with dilation operator, compensated compactness, and Vitali compactness to homogenize coupled nonlinear equations (Ginzburg-Landau phase-field model with Maxwell system and temperature equation) as microstructure period tends to zero.", "result": "Successfully derived macroscopic effective equations and enables explicit calculation of Curie temperature tensor that captures coupled effects of material geometry and magnetic permeability at macroscopic scale.", "conclusion": "The work provides a mathematical framework for homogenizing complex doubly nonlinear phase transition models in perforated materials, overcoming challenges from extension operators and enabling practical computation of macroscopic magnetic properties."}}
{"id": "2508.20456", "pdf": "https://arxiv.org/pdf/2508.20456", "abs": "https://arxiv.org/abs/2508.20456", "authors": ["Zhongxiao Jia", "Tianhang Liu"], "title": "A Chebyshev--Jackson series based block SS--RR algorithm for computing partial eigenpairs of real symmetric matrices", "categories": ["math.NA", "cs.NA", "65F15, 15A18, 65F10, 41A10"], "comment": "26 pages, 6 figures", "summary": "This paper considers eigenpair computations of large symmetric matrices with\nthe desired eigenvalues lying in a given interval using the contour\nintegral-based block SS--RR method, a Rayleigh--Ritz projection onto a certain\nsubspace generated by moment matrices. Instead of using a numerical quadrature\nto approximately compute the moments by solving a number of large shifted\ncomplex linear systems at each iteration, we make use of the Chebyshev--Jackson\n(CJ) series expansion to approximate the moments, which only involves\nmatrix-vector products and avoids expensive solutions of the linear systems. We\nprove that the CJ series expansions pointwise converge to the moments as the\nseries degree increases, but at different convergence rates depending on point\npositions and moment orders. These extend the available convergence results on\nthe zeroth moment of CJ series expansions to higher order ones. Based on the\nresults established, we develop a CJ--SS--RR algorithm. Numerical experiments\nillustrate that the new algorithm is more efficient than the contour\nintegral-based block SS--RR algorithm with the trapezoidal rule.", "AI": {"tldr": "A new algorithm using Chebyshev-Jackson series expansion for eigenpair computations that avoids solving expensive linear systems and is more efficient than traditional contour integral methods.", "motivation": "To improve computational efficiency for eigenpair computations of large symmetric matrices by avoiding the expensive solution of large shifted complex linear systems required in traditional contour integral methods.", "method": "Uses Chebyshev-Jackson series expansion to approximate moments instead of numerical quadrature, which only involves matrix-vector products. Proves convergence of CJ series for higher order moments and develops a CJ-SS-RR algorithm.", "result": "The CJ series expansions pointwise converge to moments with different convergence rates. Numerical experiments show the new algorithm is more efficient than the contour integral-based block SS-RR algorithm with trapezoidal rule.", "conclusion": "The Chebyshev-Jackson series expansion approach provides an efficient alternative to traditional contour integral methods for eigenpair computations, avoiding expensive linear system solutions while maintaining convergence properties."}}
{"id": "2504.18350", "pdf": "https://arxiv.org/pdf/2504.18350", "abs": "https://arxiv.org/abs/2504.18350", "authors": ["B. L. Alterman"], "title": "Characterizing the Impact of Alfv\u00e9n Wave Forcing in Interplanetary Space on the Distribution of near-Earth Solar Wind Speeds", "categories": ["astro-ph.SR", "astro-ph.EP", "physics.plasm-ph", "physics.space-ph"], "comment": null, "summary": "Broadly, solar wind source regions can be classified by their magnetic\ntopology as intermittently and continuously open to the heliosphere. Early\nmodels of solar wind acceleration do not account for the fastest, non-transient\nsolar wind speeds observed near-Earth and energy must be deposited into the\nsolar wind after it leaves the Sun. Alfv\\'en wave energy deposition and thermal\npressure gradients are likely candidates and the relative contribution of each\nacceleration mechanism likely depends on the source region. Although solar wind\nspeed is a rough proxy for solar wind source region, it cannot unambiguously\nidentify source region topology.\n  Using near-Sun observations of the solar wind's kinetic energy flux, we\npredict the expected kinetic energy flux near-Earth. This predicted kinetic\nenergy flux corresponds to the range of solar wind speeds observed in the fast\nsolar wind and infer that the solar wind's near-Sun kinetic energy flux is\nsufficient to predict the distribution of fastest, non-transient speeds\nobserved near Earth. Applying a recently developed model of solar wind\nevolution in the inner heliosphere, we suggest that the acceleration required\nto generate this distribution of fastest, non-transient speeds is likely due to\nthe continuous deposition of energy by Alfv\\'en wave forcing during the solar\nwind's propagation through interplanetary space. We infer that the solar wind's\nAlfv\\'enicity can statistically map near-Earth observations to their source\nregions because the Alfv\\'en wave forcing that the solar wind experiences in\ntransit is a consequence of the source region topology.", "AI": {"tldr": "Solar wind's near-Sun kinetic energy flux can predict fastest speeds observed near Earth, with Alfv\u00e9n wave forcing identified as the primary acceleration mechanism during interplanetary propagation.", "motivation": "Early solar wind acceleration models cannot account for the fastest non-transient solar wind speeds observed near-Earth, requiring identification of the energy deposition mechanisms and their dependence on source region topology.", "method": "Used near-Sun observations of solar wind's kinetic energy flux to predict expected kinetic energy flux near-Earth, applied a recently developed model of solar wind evolution in the inner heliosphere to analyze acceleration mechanisms.", "result": "The solar wind's near-Sun kinetic energy flux is sufficient to predict the distribution of fastest non-transient speeds observed near Earth, with continuous energy deposition by Alfv\u00e9n wave forcing identified as the primary acceleration mechanism during interplanetary propagation.", "conclusion": "Alfv\u00e9n wave forcing during solar wind propagation is a consequence of source region topology, allowing statistical mapping of near-Earth observations to their source regions using the solar wind's Alfv\u00e9nicity."}}
{"id": "2508.20596", "pdf": "https://arxiv.org/pdf/2508.20596", "abs": "https://arxiv.org/abs/2508.20596", "authors": ["Thomas Melkior", "Harsha S Bhat", "Faisal Amlani"], "title": "Tsunami modeling with dynamic seafloors: a high-order solver validated with shallow water benchmarks", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "physics.flu-dyn", "physics.geo-ph"], "comment": null, "summary": "Recent scientific studies have suggested that, in certain physical\nconfigurations, the time-dependent behavior of earthquake rupture and seafloor\n(bathymetry) motion can leave observable near-field signatures in tsunami wave\ngeneration and propagation. However, dynamic ground movement is often neglected\nin conventional tsunami models, which commonly assume instantaneous ground\ndisplacement (sourcing). This work introduces a pseudo-spectral algorithm for\nthe solution of the nonlinear shallow water equations with timedependent\nseafloor displacement and velocity. Based on a Fourier continuation (FC)\nmethodology for the accurate trigonometric interpolation of a non-periodic\nfunction, the solver provides high-order convergence in space and time; mild\n(linear) Courant-Friedrichs-Lewy (CFL) constraints for explicit time\nintegration; and results that are effectively free of numerical dispersion (or\n''pollution'') errors. Such properties enable the efficient and robust\nresolution of the different space-time scales involved modeling tsunamis\ngenerated by dynamic earthquake ground motion (including over long distances).\nNumerical experiments attesting to accuracy and computational performance are\npresented with direct comparisons to high-order finite difference\nmethodologies. The solver is physically validated by a number of classical and\nsemi-classical benchmark cases based on simulated or experimental data.\nAdditionally, a seismologically realistic, first-of-its-kind parametric study\nbased on earthquake speed is introduced, whose results-easily facilitated by\nthe FC-based approach proposed herein, with minimal numerical tuning-further\ndemonstrate the potential importance of (and the motivation herein for)\nincorporating time-dependent seafloor behavior in quantitative tsunami hazard\nassessment.", "AI": {"tldr": "A pseudo-spectral algorithm using Fourier continuation is developed to model tsunami generation with time-dependent seafloor motion, providing high accuracy and efficiency compared to conventional instantaneous displacement models.", "motivation": "Conventional tsunami models neglect dynamic ground movement and assume instantaneous seafloor displacement, missing observable near-field signatures in tsunami wave generation from earthquake rupture dynamics.", "method": "Pseudo-spectral algorithm based on Fourier continuation methodology for solving nonlinear shallow water equations with time-dependent seafloor displacement and velocity, providing high-order convergence and minimal numerical dispersion.", "result": "The solver achieves high accuracy, computational efficiency, and effectively eliminates numerical pollution errors. It enables efficient resolution of different space-time scales in tsunami modeling and facilitates parametric studies on earthquake speed effects.", "conclusion": "The proposed Fourier continuation-based approach demonstrates the critical importance of incorporating time-dependent seafloor behavior in quantitative tsunami hazard assessment, with minimal numerical tuning required."}}
{"id": "2508.20730", "pdf": "https://arxiv.org/pdf/2508.20730", "abs": "https://arxiv.org/abs/2508.20730", "authors": ["Hai-Liang Li", "Ling-Yun Shou", "Yue Zhang"], "title": "Large-friction and incompressible limits for pressureless Euler/isentropic Navier-Stokes flows", "categories": ["math.AP", "35Q35, 76N10, 76T17"], "comment": "54 pages", "summary": "We investigate the large-friction and incompressible limits for a two-phase\nflow (Euler-NS) system which couples the pressureless Euler equations and the\nisentropic compressible Navier-Stokes equations through a drag force term with\nthe friction coefficient $\\frac{1}{\\tau}>0$ in $\\mathbb{R}^{d}$ ($d\\geq2$). We\nestablish the uniform regularity estimates with respect to $\\tau$ so that the\nsolution of the Cauchy problem for the Euler-NS system exists globally in time,\nprovided that the initial data are uniformly close to the equilibrium state in\na critical Besov space. These uniform estimates allow us to rigorously justify\nthe strong convergence of the Euler-NS system to a one-velocity two-phase\ndrift-flux (DF) model as $\\tau \\to 0$, with an explicit convergence rate of\norder $\\sqrt{\\tau}$. We also study the large-time asymptotic behavior of\nsolutions for the Euler-NS system, uniformly with respect to $\\tau$. Moreover,\nwhen the Mach number $\\varepsilon>0$ is considered, we prove the incompressible\nlimit of the DF model toward the Transport-Navier-Stokes (TNS) system as\n$\\varepsilon\\rightarrow 0$, and justify the combined large-friction and\nincompressible limit for the Euler-NS system toward the TNS system in the\nregime $\\tau=\\varepsilon\\rightarrow 0$. Each singular limit process is globally\nvalid in time for {\\emph{ill-prepared}} initial data.", "AI": {"tldr": "Analysis of large-friction and incompressible limits for a two-phase Euler-NS system, establishing uniform regularity estimates and proving convergence to drift-flux and Transport-Navier-Stokes models with explicit rates.", "motivation": "To rigorously study the mathematical behavior of two-phase flow systems under extreme conditions (large friction and incompressible limits) and establish global-in-time convergence results for ill-prepared initial data.", "method": "Established uniform regularity estimates with respect to friction coefficient \u03c4, proved strong convergence to drift-flux model as \u03c4\u21920 with \u221a\u03c4 convergence rate, studied large-time asymptotic behavior, and analyzed incompressible limit as Mach number \u03b5\u21920.", "result": "Successfully justified strong convergence of Euler-NS system to one-velocity two-phase drift-flux model with explicit convergence rate \u221a\u03c4. Proved incompressible limit of DF model to Transport-Navier-Stokes system and combined large-friction/incompressible limit for Euler-NS to TNS system.", "conclusion": "The paper provides complete mathematical justification for singular limit processes in two-phase flow systems, establishing global-in-time convergence results with explicit rates for ill-prepared initial data in critical Besov spaces."}}
{"id": "2508.20590", "pdf": "https://arxiv.org/pdf/2508.20590", "abs": "https://arxiv.org/abs/2508.20590", "authors": ["Nam Anh Nguyen", "Arnold Reusken"], "title": "A comparative study of finite element methods for a class of harmonic map heat flow problems", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we review and systematically compare three finite element\ndiscretization methods for a harmonic map heat flow problem from the unit disk\nin $\\mathbb{R}^2$ to the unit sphere in $\\mathbb{R}^3$ in an unified framework.\nNumerical tests validate the convergence rates in a regime of smooth solutions\nand are used to compare the methods in terms of computational efficiency. For\none of the methods a discrete inf-sup stability result is derived.", "AI": {"tldr": "Systematic comparison of three finite element methods for harmonic map heat flow from disk to sphere, with convergence validation and efficiency analysis", "motivation": "To provide a unified framework for comparing different finite element discretization approaches for harmonic map heat flow problems and establish their theoretical and practical performance", "method": "Review and systematic comparison of three finite element discretization methods in a unified framework, including numerical tests for convergence rates and computational efficiency analysis, with derivation of discrete inf-sup stability for one method", "result": "Numerical tests validated convergence rates for smooth solutions and provided comparative analysis of computational efficiency across the three methods", "conclusion": "The study provides a comprehensive framework for evaluating finite element methods for harmonic map heat flow, with established convergence properties and efficiency comparisons, including stability results for one method"}}
{"id": "2508.20391", "pdf": "https://arxiv.org/pdf/2508.20391", "abs": "https://arxiv.org/abs/2508.20391", "authors": ["B. L. Alterman", "R. D'Amicis"], "title": "On the Regulation of the Solar Wind Helium Abundance by the Hydrogen Compressibility", "categories": ["physics.space-ph", "astro-ph.SR", "physics.plasm-ph"], "comment": null, "summary": "Traditionally, fast solar wind is considered to originate in solar source\nregions that are continuously open to the heliosphere and slow wind originates\nin regions that are intermittently open to it. In fast wind, the gradient of\nthe solar wind helium abundance ($A_\\mathrm{He}$) with increasing solar wind\nspeed ($v_\\mathrm{sw}$) is $\\sim0$ and $A_\\mathrm{He}$ is fixed at $\\sim50\\%$\nof the photospheric value. In slow wind, this gradient is large,\n$A_\\mathrm{He}$ is highly variable, and it doesn't exceed this $\\sim50\\%$\nvalue. Although the normalized cross helicity in fast wind typically approaches\n1, this is not universally true and Alterman & D'Amicis (2025) show that\n$\\nabla_{v_\\mathrm{sw}} \\! A_\\mathrm{He}$ in fast wind unexpectedly increases\nwith decreasing $\\left|\\sigma_c\\right|$. We show that these large gradients are\ndue to the presence of compressive fluctuations. Accounting for the solar\nwind's compressibility ($\\left|\\delta n/n\\right|$), there are two subsets of\nenhanced $A_\\mathrm{He}$ in excess of typical fast wind values. The subset with\na large compressibility is likely from neither continuously nor intermittently\nopen sources. The portion of the solar wind speed distribution over which these\nfluctuations are most significant corresponds to the range of Alfv\\'en\nwave-poor solar wind from continuously open source regions, which is likely\nanalogous to the Alfv\\'enic slow wind. Mapping the results of this work to\nAlterman & D'Amicis (2025) and vice versa shows that, in any given\n$\\left|\\delta n/n\\right|$ quantile, $\\left|\\sigma_c\\right| \\lesssim 0.65$, an\nupper bound on non-Alfv\\'enic cross helicity. Similarly, $\\left|\\delta\nn/n\\right| \\lesssim 0.15$ in any given $\\left|\\sigma_c\\right|$ quantile, is an\nupper bound on incompressible fluctuations. We conclude that $\\left|\\delta\nn/n\\right|$ is essential for characterizing the solar wind helium abundance and\npossibly regulating it.", "AI": {"tldr": "Solar wind helium abundance behavior differs between fast and slow wind, with unexpected large gradients in fast wind linked to compressive fluctuations and non-Alfvenic cross helicity.", "motivation": "To understand the unexpected relationship between solar wind helium abundance gradients and cross helicity in fast solar wind, challenging traditional views of solar wind origins.", "method": "Analysis of solar wind compressibility (|\u03b4n/n|) and cross helicity (|\u03c3c|) to identify subsets of enhanced helium abundance and their relationship to solar wind sources.", "result": "Found two subsets of enhanced helium abundance: one with large compressibility from non-traditional sources, and another in Alfven wave-poor wind. Established upper bounds: |\u03c3c| \u2272 0.65 for non-Alfvenic cross helicity and |\u03b4n/n| \u2272 0.15 for incompressible fluctuations.", "conclusion": "Compressibility (|\u03b4n/n|) is essential for characterizing and possibly regulating solar wind helium abundance, providing new insights into solar wind origins beyond traditional fast/slow wind dichotomy."}}
{"id": "2508.20729", "pdf": "https://arxiv.org/pdf/2508.20729", "abs": "https://arxiv.org/abs/2508.20729", "authors": ["Ao Cheng", "Lei Zhang", "Guowei He"], "title": "Re4: Scientific Computing Agent with Rewriting, Resolution, Review and Revision", "categories": ["cs.AI", "physics.comp-ph"], "comment": null, "summary": "Large language models (LLMs) serve as an active and promising field of\ngenerative artificial intelligence and have demonstrated abilities to perform\ncomplex tasks in multiple domains, including mathematical and scientific\nreasoning. In this work, we construct a novel agent framework for solving\nrepresentative problems in scientific computing. The proposed agent,\nincorporating a \"rewriting-resolution-review-revision\" logical chain via three\nreasoning LLMs (functioning as the Consultant, Reviewer, and Programmer,\nrespectively), is integrated in a collaborative and interactive manner. The\nConsultant module endows the agent with knowledge transfer capabilities to link\nproblems to professional domain insights, thereby rewriting problem\ndescriptions through text augmentation. The Programmer module is responsible\nfor generating and executing well-structured code to deliver the problem\nresolution. The Reviewer module equips the agent with the capacity for\nself-debugging and self-refinement through interactive feedback with code\nruntime outputs. By leveraging the end-to-end review mechanism, the executable\ncode provided by the Programmer attains the iterative revision. A comprehensive\nevaluation is conducted on the performance of the proposed agent framework in\nsolving PDEs, ill-conditioned linear systems, and data-driven physical analysis\nproblems. Compared to single-model, this collaborative framework significantly\nimproves the bug-free code generation rate and reduces the occurrence of\nnon-physical solutions, thereby establishing a highly reliable framework for\nautonomous code generation based on natural language descriptions. The review\nmechanism improved the average execution success (bug-free code and non-NaN\nsolutions) rate of the latest reasoning models. In summary, our agent framework\nestablishes automatic code generation and review as a promising scientific\ncomputing paradigm.", "AI": {"tldr": "A novel agent framework using three LLMs (Consultant, Reviewer, Programmer) in a collaborative 'rewriting-resolution-review-revision' chain for scientific computing code generation, significantly improving bug-free code rates and reducing non-physical solutions.", "motivation": "To address the challenges of generating reliable, bug-free code for scientific computing problems from natural language descriptions by leveraging collaborative reasoning among multiple LLMs rather than relying on single models.", "method": "Three-agent framework with Consultant (knowledge transfer and text augmentation), Programmer (code generation/execution), and Reviewer (self-debugging/refinement through interactive feedback). Uses end-to-end review mechanism for iterative code revision.", "result": "Significantly improved bug-free code generation rate and reduced occurrence of non-physical solutions compared to single-model approaches. Enhanced execution success rates for solving PDEs, ill-conditioned linear systems, and data-driven physical analysis problems.", "conclusion": "The collaborative multi-agent framework establishes automatic code generation and review as a promising paradigm for scientific computing, providing highly reliable autonomous code generation based on natural language descriptions."}}
{"id": "2508.20768", "pdf": "https://arxiv.org/pdf/2508.20768", "abs": "https://arxiv.org/abs/2508.20768", "authors": ["Isaac Harris", "Andreas Kleefeld", "Heejin Lee"], "title": "Existence of transmission eigenvalues for biharmonic scattering by a clamped planar region", "categories": ["math.AP", "math-ph", "math.MP"], "comment": null, "summary": "In this paper, we study the so-called clamped transmission eigenvalue\nproblem. This is a new transmission eigenvalue problem that is derived from the\nscattering of an impenetrable clamped obstacle in a thin elastic plate. The\nscattering problem is modeled by a biharmonic wave operator given by the\nKirchhoff--Love infinite plate problem in the frequency domain. These\nscattering problems have not been studied to the extent of other models. Unlike\nother transmission eigenvalue problems, the problem studied here is a system of\nhomogeneous PDEs defined in all of $\\mathbb{R}^2$. This provides unique\nanalytical and computational difficulties when studying the clamped\ntransmission eigenvalue problem. We are able to prove that there exist\ninfinitely many real clamped transmission eigenvalues. This is done by studying\nthe equivalent variational formulation. We also investigate the relationship of\nthe clamped transmission eigenvalues to the Dirichlet and Neumann eigenvalues\nof the negative Laplacian for the bounded scattering obstacle.", "AI": {"tldr": "Study of clamped transmission eigenvalue problem from elastic plate scattering, proving existence of infinitely many real eigenvalues and their relationship to Dirichlet/Neumann eigenvalues.", "motivation": "Analyze a new transmission eigenvalue problem derived from scattering of clamped obstacles in thin elastic plates, which presents unique analytical and computational challenges compared to other models.", "method": "Study the variational formulation of the clamped transmission eigenvalue problem, which is a system of homogeneous PDEs defined throughout R\u00b2, and investigate connections to Dirichlet/Neumann eigenvalues of the negative Laplacian.", "result": "Proved existence of infinitely many real clamped transmission eigenvalues through analysis of the equivalent variational formulation.", "conclusion": "The clamped transmission eigenvalue problem exhibits rich mathematical structure with infinitely many real eigenvalues, providing important connections to classical eigenvalue problems for scattering analysis."}}
{"id": "2508.20678", "pdf": "https://arxiv.org/pdf/2508.20678", "abs": "https://arxiv.org/abs/2508.20678", "authors": ["Rajakrishna Kalvala", "Anton Golovanov", "Arnaud Courvoisier", "Tomer Friling", "Eyal Kroupp", "Lidan Grishko", "Victor Malka"], "title": "Start-to-end modelling of laser-plasma acceleration, beam transport and dose deposition of very high-energy electrons for radiotherapy", "categories": ["physics.med-ph", "physics.acc-ph", "physics.plasm-ph"], "comment": "12 pages, 8 figures", "summary": "Radiotherapy using very high-energy electron (VHEE) beams generated by a\nlaser-plasma accelerator has garnered significant interest due to its dose\ndistribution capabilities and potential to address limitations of traditional\nphoton-based radiotherapy. To explore the feasibility of such approach, the\npresented study uses the parameters of OONA, the commercial <1.3\\,J, <25\\,fs\npulse duration laser recently installed at the Weizmann Institute of Science.\nThrough particle-in-cell simulations of laser-plasma interaction, realistic\nelectron beams were obtained. After filtering and collimation with a beamline\nand arranging them into an array of pencil beams, their radiotherapeutic\npotential was investigated. GEANT4 simulations were used to calculate the dose\ndeposition in water phantoms and heterogeneous phantoms with bone inserts,\nconsidering realistic beam parameters for laser-plasma accelerators. Multifield\nirradiation setup and the dose distribution at the isocenter through different\nincidence angles were studied, simulating an intensity-modulated delivery. Our\nfindings demonstrate that polychromatic VHEE beams generated from laser-plasma\naccelerators, when collimated using a compact beamline of quadrupoles and\ndipoles, can deliver an on-axis dose with enhanced precision and uniformity.\nThis study highlights the transformative potential of laser-plasma accelerators\nin advancing radiotherapy modalities, paving the way for further research and\nclinical implementation.", "AI": {"tldr": "Study demonstrates that polychromatic very high-energy electron beams from laser-plasma accelerators can deliver precise radiotherapy doses when properly collimated and arranged in array configurations.", "motivation": "To explore the feasibility of using laser-plasma accelerator-generated VHEE beams for radiotherapy, addressing limitations of traditional photon-based approaches with enhanced dose distribution capabilities.", "method": "Used particle-in-cell simulations for laser-plasma interaction, filtered/collimated beams with beamline, arranged into pencil beam arrays, and conducted GEANT4 simulations for dose deposition in water and heterogeneous phantoms with multifield irradiation setups.", "result": "Polychromatic VHEE beams from laser-plasma accelerators can deliver on-axis dose with enhanced precision and uniformity when collimated using compact beamline of quadrupoles and dipoles.", "conclusion": "Laser-plasma accelerators show transformative potential for advancing radiotherapy modalities, paving the way for further research and clinical implementation."}}
{"id": "2508.20804", "pdf": "https://arxiv.org/pdf/2508.20804", "abs": "https://arxiv.org/abs/2508.20804", "authors": ["Lucas Amoudruz", "Gregory Buti", "Luciano Rivetti", "Ali Ajdari", "Gregory Sharp", "Petros Koumoutsakos", "Simon Spohn", "Anca L Grosu", "Thomas Bortfeld"], "title": "Ising energy model for the stochastic prediction of tumor islets", "categories": ["physics.med-ph", "physics.comp-ph", "q-bio.QM"], "comment": null, "summary": "A major challenge in diagnosing and treating cancer is the infiltrative\ngrowth of tumors into surrounding tissues.\n  This microscopic spread of the disease is invisible on most diagnostic\nimaging modalities and can often only be detected histologically in biopsies.\n  The purpose of this paper is to develop a physically based model of tumor\nspread that captures the histologically observed behavior in terms of seeding\nsmall tumor islets in prostate cancer.\n  The model is based on three elementary events: a tumor cell can move,\nduplicate, or die.\n  The propensity of each event is given by an Ising-like Hamiltonian that\ncaptures correlations between neighboring cells.\n  The model parameters were fitted to clinical data obtained from surgical\nspecimens taken from 23 prostate cancer patients.\n  The results demonstrate that this straightforward physical model effectively\ndescribes the distribution of the size and the number of tumor islets in\nprostate cancer.\n  The simulated tumor islets exhibit a regular, approximately spherical shape,\ncorrectly mimicking the shapes observed in histology.\n  This is due to the Ising interaction term between neighboring cells acting as\na surface tension that gives rise to regularly shaped islets.\n  The model addresses the important clinical need of calculating the\nprobability of tumor involvement in specific sub-volumes of the prostate, which\nis required for radiation treatment planning and other applications.", "AI": {"tldr": "A physics-based model using Ising-like interactions to simulate prostate cancer tumor spread through cell movement, duplication, and death, fitted to clinical data from 23 patients.", "motivation": "To address the challenge of detecting microscopic tumor spread invisible on diagnostic imaging by developing a model that captures histologically observed tumor islet behavior in prostate cancer.", "method": "Three-event model (cell movement, duplication, death) with Ising-like Hamiltonian capturing neighbor correlations. Parameters fitted to surgical specimen data from 23 prostate cancer patients.", "result": "Model effectively describes tumor islet size/number distributions and produces regularly shaped spherical islets that mimic histological observations, with Ising interactions acting as surface tension.", "conclusion": "The straightforward physical model successfully addresses clinical needs for calculating tumor involvement probabilities in specific prostate sub-volumes for radiation treatment planning."}}
{"id": "2508.20841", "pdf": "https://arxiv.org/pdf/2508.20841", "abs": "https://arxiv.org/abs/2508.20841", "authors": ["Dami\u00e3o J. Ara\u00fajo", "Aelson Sobral"], "title": "On a nonlocal superconductivity problem", "categories": ["math.AP", "35B65, 35R11, 35J70, 35R09"], "comment": null, "summary": "This paper investigates degenerate nonlocal free boundary problems arising in\nthe context of superconductivity, extending the nonlocal counterpart to the\nwork of Caffarelli, Salazar, and Shahgholian \\cite{CS02, CSS04} in the local\nsetting. In these models, no partial differential equation governs the moving\nsets where the gradient vanishes, meaning that test functions are only required\nto have a nonzero gradient. Our main results provide interior gradient H\\\"older\nregularity estimates for viscosity solutions.", "AI": {"tldr": "Interior gradient H\u00f6lder regularity estimates for viscosity solutions of degenerate nonlocal free boundary problems in superconductivity models", "motivation": "Extend nonlocal counterparts to previous local free boundary problems in superconductivity, addressing models where no PDE governs the moving sets with vanishing gradients", "method": "Analysis of degenerate nonlocal free boundary problems using viscosity solutions approach, where test functions only require nonzero gradient", "result": "Main results establish interior gradient H\u00f6lder regularity estimates for viscosity solutions", "conclusion": "Successfully extends regularity theory to nonlocal setting for superconductivity free boundary problems with degenerate conditions"}}
{"id": "2508.20638", "pdf": "https://arxiv.org/pdf/2508.20638", "abs": "https://arxiv.org/abs/2508.20638", "authors": ["Ernesto Pimentel-Garc\u00eda", "Lucas O. M\u00fcller", "Carlos Par\u00e9s"], "title": "High-order fully well-balanced numerical methods for one-dimensional blood flow with discontinuous properties, friction and gravity", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "65N08, 76M12 (Primary)", "G.1.8"], "comment": null, "summary": "We present well-balanced, high-order, semi-discrete numerical schemes for\none-dimensional blood flow models with discontinuous mechanical properties and\nalgebraic source terms representing friction and gravity. While discontinuities\nin model parameters are handled using the Generalized Hydrostatic\nReconstruction, the presence of algebraic source terms implies that steady\nstate solutions cannot always be computed analytically. In fact, steady states\nare defined by an ordinary differential equation that needs to be integrated\nnumerically. Therefore, we resort on a numerical reconstruction operator to\nidentify and, where appropriate, preserve steady states with an accuracy that\ndepends on the reconstruction operator's numerical scheme. We extend our\nmethods to deal with networks of vessels and show numerical results for single-\nand multiple-vessel tests, including a network of 118 vessels, demonstrating\nthe capacity of the presented methods to outperform naive discretizations of\nthe equations under study.", "AI": {"tldr": "High-order numerical schemes for blood flow models with discontinuous properties and source terms, using Generalized Hydrostatic Reconstruction and numerical steady state preservation.", "motivation": "To develop accurate numerical methods for blood flow modeling that can handle discontinuous mechanical properties and algebraic source terms (friction/gravity) while preserving steady states.", "method": "Generalized Hydrostatic Reconstruction for parameter discontinuities, numerical reconstruction operator for steady state identification/preservation, extension to vessel networks.", "result": "Methods outperform naive discretizations in single- and multiple-vessel tests, including a 118-vessel network, demonstrating improved accuracy and performance.", "conclusion": "The presented well-balanced, high-order schemes effectively handle blood flow models with discontinuities and source terms, providing superior performance over basic discretization approaches."}}
{"id": "2508.20714", "pdf": "https://arxiv.org/pdf/2508.20714", "abs": "https://arxiv.org/abs/2508.20714", "authors": ["S. V. Sintsov", "N. V. Chekmarev", "K. I. Rybakov", "A. A. Sorokin", "E. I. Preobrazhenskii", "A. V. Vodopyanov"], "title": "Ultrafast solid-state chemical synthesis of BaTiO3 initiated by gyrotron microwave radiation", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph", "physics.plasm-ph"], "comment": null, "summary": "This work presents the results of a study on the solid-state synthesis of\nbarium titanate under continuous microwave radiation from a 24 GHz gyrotron in\na multimode cavity reactor. It is shown that in localized domains where\nfine-scale thermal instabilities develop, initiated by microwave radiation\nwithin the initial stoichiometric reaction mixture of ultrafine barium\ncarbonate and titanium dioxide powders, the synthesis can proceed within 1,5 -\n7 minutes, achieving a target product yield of up to 90%. Based on a developed\nrealistic numerical model of the multimode reactor, involving an iterative\nsolution of stationary Maxwell and heat conduction equations, it is\ndemonstrated that the specific absorbed power in the domains where fine-scale\nthermal instabilities develop can reach 670 W/cm3 under an input microwave\npower of 400 W.", "AI": {"tldr": "Microwave synthesis of barium titanate using 24 GHz gyrotron achieves 90% yield in 1.5-7 minutes through localized thermal instabilities.", "motivation": "To develop an efficient solid-state synthesis method for barium titanate using continuous microwave radiation to significantly reduce reaction time while maintaining high product yield.", "method": "Used 24 GHz gyrotron microwave radiation in a multimode cavity reactor with stoichiometric mixture of ultrafine barium carbonate and titanium dioxide powders. Developed numerical model solving stationary Maxwell and heat conduction equations to analyze power absorption.", "result": "Synthesis completed in 1.5-7 minutes with up to 90% product yield. Specific absorbed power reached 670 W/cm\u00b3 in localized thermal instability domains under 400 W input power.", "conclusion": "Continuous microwave radiation enables rapid barium titanate synthesis through localized thermal effects, with numerical modeling confirming high power absorption efficiency in specific domains."}}
{"id": "2508.21056", "pdf": "https://arxiv.org/pdf/2508.21056", "abs": "https://arxiv.org/abs/2508.21056", "authors": ["Jiaqi Wu", "Alaric Sanders", "Rundong Yuan", "Bo Peng"], "title": "Altermagnetic Shastry-Sutherland fullerene networks", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "physics.atm-clus", "physics.chem-ph", "physics.comp-ph"], "comment": "7 pages, 3 figures", "summary": "Molecular building blocks provide a versatile platform for realising exotic\nquantum phases. Using charge neutral, pure carbon fullerene molecules as an\nexample, we design altermagnetic C$_{40}$ monolayers in Shastry-Sutherland\nlattice. The resonance structure of one unpaired electron leads to an effective\nspin-1/2 cluster on both long sides of the molecule, which, after rotating into\na 2D rutile-like crystal structure, forms altermagnetic ground state. We show\n$d$-wave spitting of the spin-polarised electronic band structure and strong\nchiral-split magnon bands. Most interestingly, the effective spin-1/2 clusters\nform the Shastry-Sutherland model with a rich phase diagram including\naltermagenti, quantum spin liquid, plaquette, and dimer phases, which can be\neasily accessed to via moderate bi-axial strains. Our findings present magnetic\nfullerene monolayers as a tunable platform for exotic quantum magnetism and\nspintronic applications.", "AI": {"tldr": "Design of altermagnetic C40 fullerene monolayers in Shastry-Sutherland lattice with tunable quantum phases accessible via strain", "motivation": "To create versatile molecular building blocks for realizing exotic quantum phases using pure carbon fullerene molecules", "method": "Using charge neutral C40 fullerene molecules to form effective spin-1/2 clusters arranged in 2D rutile-like crystal structure within Shastry-Sutherland lattice", "result": "Achieved d-wave splitting of spin-polarized electronic band structure, strong chiral-split magnon bands, and demonstrated tunable phases including altermagnetic, quantum spin liquid, plaquette, and dimer phases via bi-axial strains", "conclusion": "Magnetic fullerene monolayers serve as a tunable platform for exotic quantum magnetism and spintronic applications"}}
{"id": "2508.20845", "pdf": "https://arxiv.org/pdf/2508.20845", "abs": "https://arxiv.org/abs/2508.20845", "authors": ["Francesco Colasanto", "Matteo Focardi", "Caterina Ida Zeppieri"], "title": "Homogenisation of phase-field functionals with linear growth", "categories": ["math.AP"], "comment": null, "summary": "We propose a first rigorous homogenisation procedure in image-segmentation\nmodels by analysing the relative impact of (possibly random) fine-scale\noscillations and phase-field regularisations for a family of elliptic\nfunctionals of Ambrosio and Tortorelli type, when the regularised volume term\ngrows \\emph{linearly} in the gradient variable. In contrast to the more\nclassical case of superlinear growth, we show that our functionals homogenise\nto a free-discontinuity energy whose surface term explicitly depends on the\njump amplitude of the limit variable. The convergence result as above is\nobtained under very mild assumptions which allow us to treat, among other, the\ncase of \\emph{stationary random integrands}.", "AI": {"tldr": "Homogenisation analysis of elliptic Ambrosio-Tortorelli functionals with linear gradient growth, showing convergence to free-discontinuity energy with jump-dependent surface term.", "motivation": "To establish rigorous homogenisation for image-segmentation models with fine-scale oscillations and phase-field regularisations, particularly for functionals with linear gradient growth rather than classical superlinear growth.", "method": "Analysis of elliptic functionals of Ambrosio-Tortorelli type with linear growth in gradient variable, under mild assumptions including stationary random integrands.", "result": "The functionals homogenise to a free-discontinuity energy where the surface term explicitly depends on the jump amplitude of the limit variable.", "conclusion": "This provides the first rigorous homogenisation procedure for such image-segmentation models, extending results to the linear growth case and random media."}}
{"id": "2508.20852", "pdf": "https://arxiv.org/pdf/2508.20852", "abs": "https://arxiv.org/abs/2508.20852", "authors": ["Johannes Krotz", "Ryan G. McClarren"], "title": "Curvilinear coordinates and curvature in radiative transport", "categories": ["math.NA", "cs.NA", "math.AP", "nucl-th"], "comment": null, "summary": "We derive a general expression for the streaming term in radiative transport\nequa- tions and other transport problems when formulated in curvilinear\ncoordinates, emphasizing coordinate systems adapted to the geometry of the\ndomain and the directional dependence of particle transport. By parametrizing\nthe angular vari- able using a local orthonormal frame, we express directional\nderivatives in terms of curvature-related quantities that reflect the geometry\nof underlying spatial man- ifolds. Our formulation highlights how the\ninteraction between coordinate choices and curvature influences the streaming\noperator, offering geometric interpretations of its components. The resulting\nframework offers intuitive insight into when and how angular dependence can be\nsimplified and may guide the selection of coordinate systems that balance\nanalytical tractability and computational efficiency.", "AI": {"tldr": "General expression for streaming term in radiative transport equations using curvilinear coordinates adapted to domain geometry and directional dependence, with geometric interpretation of curvature effects.", "motivation": "To develop a mathematical framework that captures how coordinate system choices and curvature interact in transport problems, providing geometric insights for simplifying angular dependence.", "method": "Parametrize angular variable using local orthonormal frame, express directional derivatives in terms of curvature-related quantities reflecting spatial manifold geometry.", "result": "Derived general expression for streaming term that highlights geometric interpretation of components and shows interaction between coordinate choices and curvature.", "conclusion": "The framework provides intuitive insight for simplifying angular dependence and guides selection of coordinate systems balancing analytical tractability with computational efficiency."}}
{"id": "2508.20921", "pdf": "https://arxiv.org/pdf/2508.20921", "abs": "https://arxiv.org/abs/2508.20921", "authors": ["Paola Loreti", "Daniela Sforza"], "title": "Energy decay for evolution equations with glassy type memory", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we address the question of estimating the energy decay of\nintegro-differential evolution equations with glassy memory. This class of\nmemory kernel was not analyzed in previous studies. Moreover, a detailed\nanalysis provides an explicit estimate of the connection between the kernel\nfunction's decay constant and the energy's decay constant.", "AI": {"tldr": "Analysis of energy decay in integro-differential equations with glassy memory kernels, providing explicit connection between kernel decay and energy decay constants.", "motivation": "To study energy decay in integro-differential evolution equations with glassy memory kernels, which have not been previously analyzed in existing literature.", "method": "Detailed mathematical analysis of integro-differential equations with glassy memory kernels to establish decay properties.", "result": "Obtained explicit estimates showing the relationship between the decay constant of the kernel function and the decay constant of the energy.", "conclusion": "Successfully analyzed glassy memory kernels and established quantitative connection between kernel decay properties and energy decay rates in integro-differential equations."}}
{"id": "2508.20857", "pdf": "https://arxiv.org/pdf/2508.20857", "abs": "https://arxiv.org/abs/2508.20857", "authors": ["Xiangyun Meng", "Martin Stynes"], "title": "Uniform error analysis of a rectangular Morley finite element method on a Shishkin mesh for a 4th-order singularly perturbed boundary value problem", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "The singularly perturbed reaction-diffusion problem $\\varepsilon^2\\Delta^2 u\n- \\mathrm{div}\\left(c\\nabla u\\right) = f$ is considered on the unit square\n$\\Omega$ in $\\mathbb{R}^2$ with homogenous Dirichlet boundary conditions. Its\nsolution typically contains boundary layers on all sides of~$\\Omega$. It is\ndiscretised by a finite element method that uses rectangular Morley elements on\na Shishkin mesh. In an associated energy-type norm that is natural for this\nproblem, we prove an $O(\\varepsilon^{1/2}N^{-1}+\\varepsilon N^{-1}\\ln N +\nN^{-3/2})$ rate of convergence for the error in the computed solution, where\n$N$~is the number of mesh intervals in each coordinate direction. Thus in the\nmost troublesome regime when $\\varepsilon \\approx N^{-1}$, our method is proved\nto attain an $O(N^{-3/2})$ rate of convergence, which is shown to be sharp by\nour numerical experiments and is superior to the $O(N^{-1/2})$ rate that is\nproved in Meng & Stynes, Adv. Comput. Math. 2019 when Adini finite elements are\nused to solve the same problem on the same mesh.", "AI": {"tldr": "Finite element method using rectangular Morley elements on Shishkin mesh achieves O(N^{-3/2}) convergence for singularly perturbed reaction-diffusion problems, outperforming previous Adini element methods.", "motivation": "Solve singularly perturbed reaction-diffusion problems with boundary layers more efficiently using improved finite element methods that provide better convergence rates than existing approaches.", "method": "Discretize the problem using rectangular Morley finite elements on a Shishkin mesh, with analysis in an energy-type norm natural for this class of problems.", "result": "Proved O(\u03b5^{1/2}N^{-1} + \u03b5N^{-1}lnN + N^{-3/2}) convergence rate, achieving superior O(N^{-3/2}) performance when \u03b5 \u2248 N^{-1}, compared to O(N^{-1/2}) from previous Adini element methods.", "conclusion": "The Morley element method on Shishkin mesh provides significantly better convergence rates for singularly perturbed reaction-diffusion problems with boundary layers, as validated by numerical experiments showing the sharpness of the proved bounds."}}
{"id": "2508.20938", "pdf": "https://arxiv.org/pdf/2508.20938", "abs": "https://arxiv.org/abs/2508.20938", "authors": ["Sebastian Ohrem"], "title": "Breather solutions to nonlinear Maxwell equations with retarded material laws", "categories": ["math.AP", "Primary: 35Q61, 49J10, Secondary: 35C07, 78A50"], "comment": "28 pages, 0 figures", "summary": "We consider Maxwell's equations for Kerr-type optical materials, which are\nmagnetically inactive and have a nonlinear response to electric fields. This\nresponse consists of a linear plus a cubic term, which are both inhomogeneous\nwith bounded coefficients. The cubic term is temporally retarded while the\nlinear term has instantaneous and retarded contributions. For slab waveguides\nwe show existence of breathers, which are time-periodic, real-valued solutions\nthat are localized in the direction perpendicular to the waveguide, and\nmoreover they are traveling along one direction of the waveguide. We find these\nbreathers using a variational method which relies on the assumption that an\neffective operator related to the linear part of Maxwell's equations has a\nspectral gap about $0$. We also give examples of material coefficients,\nincluding nonperiodic materials, where such a spectral gap is present.", "AI": {"tldr": "Existence of breathers in Kerr-type optical slab waveguides with nonlinear electric response, found using variational methods under spectral gap conditions.", "motivation": "To prove the existence of time-periodic, spatially localized traveling wave solutions (breathers) in nonlinear optical waveguides described by Maxwell's equations with Kerr-type nonlinearities.", "method": "Variational method that assumes the linear part of Maxwell's equations has a spectral gap around 0. Analysis considers inhomogeneous materials with bounded coefficients, including instantaneous and temporally retarded linear terms plus cubic nonlinear response.", "result": "Demonstrated existence of breathers - time-periodic, real-valued solutions localized perpendicular to the waveguide and traveling along it. Provided examples of material coefficients (including nonperiodic materials) where the required spectral gap condition is satisfied.", "conclusion": "Breathers exist in Kerr-type optical slab waveguides under spectral gap conditions, with the variational approach successfully identifying these nonlinear wave solutions in both periodic and nonperiodic material configurations."}}
{"id": "2508.20876", "pdf": "https://arxiv.org/pdf/2508.20876", "abs": "https://arxiv.org/abs/2508.20876", "authors": ["Zhenyu Zhao", "Yanfei Wang", "Xinran Liu"], "title": "Fast numerical derivatives based on multi-interval Fourier extension", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We present a computationally efficient algorithm for stable numerical\ndifferentiation from noisy, uniformly-sampled data on a bounded interval. The\nmethod combines multi-interval Fourier extension approximations with an\nadaptive domain partitioning strategy: a global precomputation of local Fourier\nsampling matrices and their thin SVDs is reused throughout a recursive\nbisection procedure that selects locally-resolved Fourier fits. Each accepted\nsubinterval stores a compact set of Fourier coefficients that are subsequently\nused to reconstruct the derivative via a precomputed differentiation operator.\nThe stopping criterion balances fitting error and an explicit noise-level\nbound, and the algorithm automatically refines the partition where the function\nexhibits rapid oscillations or boundary activity. Numerical experiments\ndemonstrate significant improvements over existing methods, achieving accurate\nderivative reconstruction for challenging functions. The approach provides a\nrobust framework for ill-posed differentiation problems while maintaining\ncomputational efficiency.", "AI": {"tldr": "Efficient algorithm for stable numerical differentiation from noisy data using Fourier extension approximations with adaptive domain partitioning and recursive bisection.", "motivation": "To address the ill-posed problem of numerical differentiation from noisy, uniformly-sampled data by developing a computationally efficient and stable method that can handle challenging functions with rapid oscillations or boundary activity.", "method": "Combines multi-interval Fourier extension approximations with adaptive domain partitioning strategy. Uses global precomputation of local Fourier sampling matrices and their thin SVDs, recursive bisection procedure to select locally-resolved Fourier fits, and precomputed differentiation operator for derivative reconstruction.", "result": "Numerical experiments show significant improvements over existing methods, achieving accurate derivative reconstruction for challenging functions while maintaining computational efficiency.", "conclusion": "The approach provides a robust framework for ill-posed differentiation problems, offering stable and efficient derivative computation from noisy data through adaptive Fourier extension techniques."}}
{"id": "2508.20951", "pdf": "https://arxiv.org/pdf/2508.20951", "abs": "https://arxiv.org/abs/2508.20951", "authors": ["Uriel Kaufmann", "Ra\u00fal Vidal"], "title": "A local and nonlocal coupling model involving the $p$-Laplacian", "categories": ["math.AP", "35R11, 45K05, 47G20"], "comment": null, "summary": "In this paper we extend some results presented in \\cite{julio} to the case of\nthe $p$-Laplacian operator. More precisely, we consider a model that couples a\nlocal $p$-Laplacian operator with a nonlocal $p$-Laplacian operator through\nsource terms in the equation. The resulting problem is associated with an\nenergy functional. We establish the existence and uniqueness of a solution,\nwhich is obtained via the direct minimization of the corresponding energy\nfunctional.", "AI": {"tldr": "Extension of previous results to p-Laplacian operator with coupled local and nonlocal terms, establishing existence and uniqueness via energy minimization.", "motivation": "To generalize existing mathematical results from previous work to the more complex p-Laplacian operator case, specifically addressing coupled local and nonlocal operators.", "method": "Couples local p-Laplacian with nonlocal p-Laplacian through source terms, analyzes the resulting energy functional, and uses direct minimization approach to prove solution properties.", "result": "Established existence and uniqueness of solutions for the coupled p-Laplacian problem through energy functional minimization.", "conclusion": "Successfully extended previous mathematical framework to handle p-Laplacian operators with both local and nonlocal coupling, providing rigorous existence and uniqueness proofs."}}
{"id": "2508.20883", "pdf": "https://arxiv.org/pdf/2508.20883", "abs": "https://arxiv.org/abs/2508.20883", "authors": ["Samuel Duffield", "Maxwell Aifer", "Denis Melanson", "Zach Belateche", "Patrick J. Coles"], "title": "Lattice Random Walk Discretisations of Stochastic Differential Equations", "categories": ["math.NA", "cs.ET", "cs.NA", "stat.CO"], "comment": "16 pages, 6 figures", "summary": "We introduce a lattice random walk discretisation scheme for stochastic\ndifferential equations (SDEs) that samples binary or ternary increments at each\nstep, suppressing complex drift and diffusion computations to simple 1 or 2 bit\nrandom values. This approach is a significant departure from traditional\nfloating point discretisations and offers several advantages; including\ncompatibility with stochastic computing architectures that avoid floating-point\narithmetic in place of directly manipulating the underlying probability\ndistribution of a bitstream, elimination of Gaussian sampling requirements,\nrobustness to quantisation errors, and handling of non-Lipschitz drifts. We\nprove weak convergence and demonstrate the advantages through experiments on\nvarious SDEs, including state-of-the-art diffusion models.", "AI": {"tldr": "A lattice random walk discretization scheme for SDEs using binary/ternary increments instead of floating-point computations, offering hardware compatibility, Gaussian sampling elimination, and robustness.", "motivation": "To overcome limitations of traditional floating-point discretizations by developing a simple bit-based approach compatible with stochastic computing architectures and eliminating complex drift/diffusion computations.", "method": "Uses lattice random walk with binary or ternary increments (1-2 bit random values) instead of floating-point operations, suppressing complex computations to simple probability distribution manipulations.", "result": "Proven weak convergence and demonstrated advantages through experiments on various SDEs including state-of-the-art diffusion models, showing robustness to quantization errors and handling of non-Lipschitz drifts.", "conclusion": "The approach provides a significant departure from traditional methods with advantages in hardware compatibility, computational simplicity, and robustness, making it suitable for modern stochastic computing architectures."}}
{"id": "2508.20486", "pdf": "https://arxiv.org/pdf/2508.20486", "abs": "https://arxiv.org/abs/2508.20486", "authors": ["Ting-Jung Kuo", "Xuanpu Liang", "Ping-Hsiang Wu"], "title": "Monodromy Equivalence for Lam\u00e9-type Equations I: Finite-gap Structures and Cone Spherical Metrics", "categories": ["math.CA", "math.AP", "math.DG", "58J10, 53A10"], "comment": "60pages, 2 figures", "summary": "Motivated by the finite-gap structure of the classical Lam\\'{e} equation\n(1.2) and its central role in mathematical physics, generalized Lam\\'{e}-type\nequations (1.12) are investigated. For the fundamental case $n=1$, a monodromy\nequivalence between the classical Lam\\'{e} equation (1.18) and the generalized\nLam\\'{e}-type equation (1.19) is established. Two main applications are\nobtained: (i) the finite-gap structure of \\ (1.19) is derived, together with a\ncomplete classification of the spectral curves $\\sigma_{1}$ and $\\sigma_{2}$\nfor $\\tau\\in i\\mathbb{R}_{>0}$; and (ii) the monodromy equivalence is applied\nto the construction of cone spherical metrics with three large conical\nsingularities, each with cone angle exceeding $2\\pi$. A family of such metrics\nis shown to exhibits a blow-up configuration, which is described explicitly in\nterms of the monodromy data.", "AI": {"tldr": "Analysis of generalized Lam\u00e9-type equations showing monodromy equivalence with classical Lam\u00e9 equation, leading to finite-gap structure classification and applications in constructing cone spherical metrics with large conical singularities.", "motivation": "Motivated by the finite-gap structure of the classical Lam\u00e9 equation and its importance in mathematical physics, the paper investigates generalized Lam\u00e9-type equations to establish deeper mathematical connections and applications.", "method": "Establishes monodromy equivalence between classical Lam\u00e9 equation and generalized Lam\u00e9-type equation for the fundamental case n=1. Uses this equivalence to derive finite-gap structure and classify spectral curves for \u03c4 \u2208 i\u211d>0.", "result": "Obtained complete classification of spectral curves \u03c3\u2081 and \u03c3\u2082. Applied monodromy equivalence to construct cone spherical metrics with three large conical singularities (each with cone angle > 2\u03c0). Showed that a family of such metrics exhibits a blow-up configuration described explicitly in terms of monodromy data.", "conclusion": "The monodromy equivalence provides a powerful tool for understanding finite-gap structures and enables explicit construction of geometric objects (cone spherical metrics) with specific singularity properties, revealing blow-up configurations through monodromy data analysis."}}
{"id": "2508.20928", "pdf": "https://arxiv.org/pdf/2508.20928", "abs": "https://arxiv.org/abs/2508.20928", "authors": ["Alexander Molozhavenko", "Maxim Rakhuba"], "title": "Optimization on the Extended Tensor-Train Manifold with Shared Factors", "categories": ["math.NA", "cs.NA", "53Z50, 65F15, 15A23, 15A69"], "comment": null, "summary": "This paper studies tensors that admit decomposition in the Extended Tensor\nTrain (ETT) format, with a key focus on the case where some decomposition\nfactors are constrained to be equal. This factor sharing introduces additional\nchallenges, as it breaks the multilinear structure of the decomposition.\nNevertheless, we show that Riemannian optimization methods can naturally handle\nsuch constraints and prove that the underlying manifold is indeed smooth. We\ndevelop efficient algorithms for key Riemannian optimization components,\nincluding a retraction operation based on quasi-optimal approximation in the\nnew format, as well as tangent space projection using automatic\ndifferentiation. Finally, we demonstrate the practical effectiveness of our\napproach through tensor approximation tasks and multidimensional eigenvalue\nproblem.", "AI": {"tldr": "Riemannian optimization for Extended Tensor Train format with factor sharing constraints, proving smooth manifold structure and developing efficient algorithms for tensor approximation and eigenvalue problems.", "motivation": "To handle tensor decompositions in Extended Tensor Train format where some factors are constrained to be equal, which breaks the multilinear structure and presents optimization challenges.", "method": "Developed Riemannian optimization methods that naturally handle factor sharing constraints, proved the underlying manifold is smooth, created efficient algorithms including quasi-optimal retraction and tangent space projection using automatic differentiation.", "result": "Successfully demonstrated practical effectiveness through tensor approximation tasks and multidimensional eigenvalue problems.", "conclusion": "Riemannian optimization provides an effective framework for handling factor sharing constraints in Extended Tensor Train decompositions, with efficient algorithms enabling practical applications."}}
{"id": "2508.20290", "pdf": "https://arxiv.org/pdf/2508.20290", "abs": "https://arxiv.org/abs/2508.20290", "authors": ["Pengcheng Xie", "Zihao Zhou", "Zijian Zhou"], "title": "Objective Value Change and Shape-Based Accelerated Optimization for the Neural Network Approximation", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "math.OC", "68T07, 65K05, 65D15, 90C30"], "comment": "27 pages", "summary": "This paper introduce a novel metric of an objective function f, we say VC\n(value change) to measure the difficulty and approximation affection when\nconducting an neural network approximation task, and it numerically supports\ncharacterizing the local performance and behavior of neural network\napproximation. Neural networks often suffer from unpredictable local\nperformance, which can hinder their reliability in critical applications. VC\naddresses this issue by providing a quantifiable measure of local value changes\nin network behavior, offering insights into the stability and performance for\nachieving the neural-network approximation. We investigate some fundamental\ntheoretical properties of VC and identified two intriguing phenomena in neural\nnetwork approximation: the VC-tendency and the minority-tendency. These trends\nrespectively characterize how pointwise errors evolve in relation to the\ndistribution of VC during the approximation process.In addition, we propose a\nnovel metric based on VC, which measures the distance between two functions\nfrom the perspective of variation. Building upon this metric, we further\npropose a new preprocessing framework for neural network approximation.\nNumerical results including the real-world experiment and the PDE-related\nscientific problem support our discovery and pre-processing acceleration\nmethod.", "AI": {"tldr": "Proposes VC metric to measure neural network approximation difficulty and local performance, identifies VC-tendency and minority-tendency phenomena, and introduces preprocessing framework for acceleration.", "motivation": "Neural networks suffer from unpredictable local performance that hinders reliability in critical applications, requiring quantifiable measures of local value changes.", "method": "Introduces VC (value change) metric to characterize local network behavior, investigates theoretical properties, identifies approximation trends, and proposes variation-based distance metric with preprocessing framework.", "result": "Numerical results from real-world experiments and PDE-related scientific problems support the VC metric's effectiveness and the preprocessing acceleration method.", "conclusion": "VC provides quantifiable insights into neural network approximation stability and performance, with identified trends and preprocessing framework offering practical improvements for reliability."}}
{"id": "2508.21013", "pdf": "https://arxiv.org/pdf/2508.21013", "abs": "https://arxiv.org/abs/2508.21013", "authors": ["Simon Becker", "Setsuro Fujii\u00e9", "Jens Wittsten"], "title": "Bohr--Sommerfeld rules for systems", "categories": ["math-ph", "cond-mat.mes-hall", "math.AP", "math.MP", "math.SP", "quant-ph"], "comment": "30 pages, 5 figures, comments welcome!", "summary": "We present a complete, self-contained formulation of the Bohr--Sommerfeld\nquantization rule for a semiclassical self-adjoint $2 \\times 2$ system on the\nreal line, arising from a simple closed curve in phase space. We focus on the\ncase where the principal symbol exhibits eigenvalue crossings within the domain\nenclosed by the curve -- a situation commonly encountered in Dirac-type\noperators. Building on earlier work on scalar Bohr--Sommerfeld rules and\nsemiclassical treatments of the Harper operator near rational flux quanta, we\nidentify additional contributions to the quantization condition, and derive\nconcise expressions for general self-adjoint $2 \\times 2$ systems. The\nresulting formulas give explicit geometric phase corrections and clarify when\nthese phases take quantized values.", "AI": {"tldr": "Complete formulation of Bohr-Sommerfeld quantization rule for 2x2 semiclassical systems with eigenvalue crossings, providing geometric phase corrections and quantization conditions.", "motivation": "To address eigenvalue crossings in Dirac-type operators and extend Bohr-Sommerfeld quantization to 2x2 systems where previous scalar formulations are insufficient.", "method": "Builds on earlier work on scalar Bohr-Sommerfeld rules and semiclassical treatments of Harper operator, deriving additional contributions to quantization condition for general self-adjoint 2x2 systems.", "result": "Derived concise expressions for quantization conditions with explicit geometric phase corrections, clarifying when these phases take quantized values.", "conclusion": "Provides a complete formulation that handles eigenvalue crossings in phase space, offering geometric insights into quantization conditions for 2x2 semiclassical systems."}}
{"id": "2508.20633", "pdf": "https://arxiv.org/pdf/2508.20633", "abs": "https://arxiv.org/abs/2508.20633", "authors": ["Arash Hajisharifi", "Rahul Halder", "Michele Girfoglio", "Giovanni Stabile", "Gianluigi Rozza"], "title": "A Deep-Learning Enhanced Gappy Proper Orthogonal Decomposition Method for Conjugate Heat Transfer Problem", "categories": ["physics.flu-dyn", "cs.NA", "math.NA"], "comment": null, "summary": "The current study aims to develop a non-intrusive Reduced Order Model (ROM)\nto reconstruct the full temperature field for a large-scale industrial\napplication based on both numerical and experimental datasets. The proposed\napproach is validated against a domestic refrigerator. At the full order level,\nair circulation and heat transfer in fluid and between fluid and surrounding\nsolids in the fridge were numerically studied using the Conjugated Heat\nTransfer (CHT) method to explore both the natural and forced convection-based\nfridge model followed by a parametric study-based on the ambient temperature,\nfridge fan velocity, and evaporator temperature. The main novelty of the\ncurrent work is the introduction of a stable Artificial Neural Network (ANN)\nenhanced Gappy Proper Orthogonal Decomposition (GPOD) method which shows better\nperformance than the conventional GPOD approach in such large-scale industrial\napplications. The full-order model is validated with the experimental results\nand the prediction accuracy of the surrogate model associated with different\nreduced-order approaches is compared with the benchmark numerical results or\nhigh-fidelity results. In our current work, we show that a prediction error of\none degree centigrade and computational speed-up of 5000 is achieved even at a\nvery sparse training dataset using the proposed deep-learning enhanced GPOD\napproach.", "AI": {"tldr": "Developed a stable ANN-enhanced Gappy POD method for temperature field reconstruction in industrial refrigerators, achieving 1\u00b0C prediction error and 5000x speedup with sparse training data.", "motivation": "To create a non-intrusive Reduced Order Model for large-scale industrial applications that can accurately reconstruct full temperature fields from both numerical and experimental data, specifically for domestic refrigerator analysis.", "method": "Combined Artificial Neural Network with Gappy Proper Orthogonal Decomposition (GPOD) method. Used Conjugated Heat Transfer method at full-order level to study air circulation and heat transfer. Conducted parametric studies on ambient temperature, fan velocity, and evaporator temperature.", "result": "Achieved prediction error of 1 degree centigrade and computational speed-up of 5000x, even with very sparse training datasets. Outperformed conventional GPOD approach in large-scale industrial applications.", "conclusion": "The ANN-enhanced GPOD method provides a stable and efficient approach for temperature field reconstruction in industrial applications, offering significant improvements in accuracy and computational efficiency compared to traditional methods."}}
{"id": "2508.21045", "pdf": "https://arxiv.org/pdf/2508.21045", "abs": "https://arxiv.org/abs/2508.21045", "authors": ["Zhenhua Liu"], "title": "The Hasse Principle for Geometric Variational Problems: An Illustration via Area-minimizing Submanifolds", "categories": ["math.DG", "math.AP", "math.NT"], "comment": "Supersedes arXiv:2310.19860 and arXiv:2401.18074", "summary": "The Hasse principle in number theory states that information about integral\nsolutions to Diophantine equations can be pieced together from real solutions\nand solutions modulo prime powers. We show that the Hasse principle holds for\narea-minimizing submanifolds: information about area-minimizing submanifolds in\nintegral homology can be fully recovered from those in real homology and mod\n$n$ homology for all $n\\in \\mathbb{Z}_{\\ge 2}.$ As a consequence we derive\nseveral surprising conclusions, including: area-minimizing submanifolds in mod\n$n$ homology are asymptotically much smoother than expected and area-minimizing\nsubmanifolds are not generically calibrated. We conjecture that the Hasse\nprinciple holds for all geometric variational problems that can be formulated\non chain space over different coeffiicients, e.g., Almgren-Pitts min-max, mean\ncurvature flow, Song's spherical Plateau problem, minimizers of elliptic and\nother general functionals, etc.", "AI": {"tldr": "The paper extends the Hasse principle from number theory to geometric analysis, showing that area-minimizing submanifolds in integral homology can be fully determined from real and mod n homology information.", "motivation": "To bridge concepts from number theory (Hasse principle) to geometric variational problems, specifically understanding how information about area-minimizing submanifolds can be reconstructed from different coefficient systems.", "method": "The authors demonstrate that the Hasse principle holds for area-minimizing submanifolds by showing that integral homology information can be completely recovered from real homology and mod n homology data for all n \u2265 2.", "result": "Several surprising conclusions: area-minimizing submanifolds in mod n homology are asymptotically much smoother than expected, and area-minimizing submanifolds are not generically calibrated.", "conclusion": "The Hasse principle likely applies to all geometric variational problems formulated on chain spaces over different coefficients, including Almgren-Pitts min-max, mean curvature flow, spherical Plateau problems, and minimizers of elliptic functionals."}}
{"id": "2508.21002", "pdf": "https://arxiv.org/pdf/2508.21002", "abs": "https://arxiv.org/abs/2508.21002", "authors": ["Almudena Carrera Vazquez", "Aleksandros Sobczyk"], "title": "Spectral Gaps with Quantum Counting Queries and Oblivious State Preparation", "categories": ["quant-ph", "cs.DS", "cs.NA", "math.NA"], "comment": null, "summary": "Approximating the $k$-th spectral gap $\\Delta_k=|\\lambda_k-\\lambda_{k+1}|$\nand the corresponding midpoint $\\mu_k=\\frac{\\lambda_k+\\lambda_{k+1}}{2}$ of an\n$N\\times N$ Hermitian matrix with eigenvalues\n$\\lambda_1\\geq\\lambda_2\\geq\\ldots\\geq\\lambda_N$, is an important special case\nof the eigenproblem with numerous applications in science and engineering. In\nthis work, we present a quantum algorithm which approximates these values up to\nadditive error $\\epsilon\\Delta_k$ using a logarithmic number of qubits.\nNotably, in the QRAM model, its total complexity (queries and gates) is bounded\nby $O\\left( \\frac{N^2}{\\epsilon^{2}\\Delta_k^2}\\mathrm{polylog}\\left(\nN,\\frac{1}{\\Delta_k},\\frac{1}{\\epsilon},\\frac{1}{\\delta}\\right)\\right)$, where\n$\\epsilon,\\delta\\in(0,1)$ are the accuracy and the success probability,\nrespectively. For large gaps $\\Delta_k$, this provides a speed-up against the\nbest-known complexities of classical algorithms, namely, $O \\left(\nN^{\\omega}\\mathrm{polylog} \\left(\nN,\\frac{1}{\\Delta_k},\\frac{1}{\\epsilon}\\right)\\right)$, where $\\omega\\lesssim\n2.371$ is the matrix multiplication exponent. A key technical step in the\nanalysis is the preparation of a suitable random initial state, which\nultimately allows us to efficiently count the number of eigenvalues that are\nsmaller than a threshold, while maintaining a quadratic complexity in $N$. In\nthe black-box access model, we also report an $\\Omega(N^2)$ query lower bound\nfor deciding the existence of a spectral gap in a binary (albeit non-symmetric)\nmatrix.", "AI": {"tldr": "Quantum algorithm for approximating spectral gaps with logarithmic qubits and quadratic complexity in N, providing speed-up over classical methods for large gaps.", "motivation": "Approximating spectral gaps is crucial for many scientific and engineering applications, but classical algorithms have high complexity (O(N^\u03c9)). Quantum computing offers potential speed-up.", "method": "Uses quantum algorithm with random initial state preparation to efficiently count eigenvalues below threshold. Operates in QRAM model with polylogarithmic complexity factors.", "result": "Achieves additive error \u03b5\u0394_k approximation with complexity O(N\u00b2/\u03b5\u00b2\u0394_k\u00b2 polylog(N,1/\u0394_k,1/\u03b5,1/\u03b4)), providing speed-up over classical O(N^\u03c9) for large spectral gaps.", "conclusion": "Quantum algorithm enables efficient spectral gap approximation with quadratic complexity in N, demonstrating quantum advantage for this important eigenproblem."}}
