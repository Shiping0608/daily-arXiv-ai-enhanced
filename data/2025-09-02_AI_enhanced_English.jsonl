{"id": "2508.21155", "pdf": "https://arxiv.org/pdf/2508.21155", "abs": "https://arxiv.org/abs/2508.21155", "authors": ["Joseph Hart", "Alen Alexanderian", "Bart van Bloemen Waanders"], "title": "Preconditioned pseudo-time continuation for parameterized inverse problems", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We consider parametrized variational inverse problems that are constrained by\npartial differential equations (PDEs). We seek to efficiently compute the\nsolution of the inverse problem when auxiliary model parameters, which appear\nin the governing PDE, are varied. Computing the solution of the inverse problem\nfor different auxiliary parameter values is crucial for uncertainty\nquantification. This, however, is computationally challenging since it requires\nsolving many optimization problems for different realizations of the auxiliary\nparameters. We leverage pseudo-time continuation and solve an initial value\nproblem to evolve the optimal solution along an auxiliary parameter path. This\narticle introduces the use of an adaptive quasi-Newton Hessian preconditioner\nto accelerate the computation. Our proposed preconditioner exploits properties\nof the pseudo-time continuation process to achieve reliable and efficient\ncomputation. We elaborate our proposed framework and elucidate its properties\nfor two nonlinear inverse problems.", "AI": {"tldr": "A method using pseudo-time continuation with adaptive quasi-Newton Hessian preconditioning to efficiently solve parametrized PDE-constrained inverse problems for uncertainty quantification.", "motivation": "Solving inverse problems for different auxiliary parameter values is computationally expensive but crucial for uncertainty quantification, requiring solving many optimization problems.", "method": "Leverage pseudo-time continuation to solve an initial value problem that evolves optimal solutions along parameter paths, using an adaptive quasi-Newton Hessian preconditioner to accelerate computation.", "result": "The proposed preconditioner exploits properties of the pseudo-time continuation process to achieve reliable and efficient computation, demonstrated on two nonlinear inverse problems.", "conclusion": "The framework provides an efficient approach for solving parametrized variational inverse problems constrained by PDEs, particularly useful for uncertainty quantification applications."}}
{"id": "2508.21226", "pdf": "https://arxiv.org/pdf/2508.21226", "abs": "https://arxiv.org/abs/2508.21226", "authors": ["Brian Christner", "Jesse Chan"], "title": "Entropy stable finite difference (ESFD) methods via entropy correction artificial viscosity (ECAV) and knapsack limiting (KL) techniques", "categories": ["math.NA", "cs.NA", "68Q25, 68R10, 68U05"], "comment": null, "summary": "Entropy stable methods have become increasingly popular in the field of\ncomputational fluid dynamics. They often work by satisfying some form of a\ndiscrete entropy inequality: a discrete form of the 2nd law of thermodynamics.\nSchemes which satisfy a (semi-)discrete entropy inequality typically behave\nmuch more robustly, and do so in a way that is hyperparameter free. Recently, a\nnew strategy was introduced to construct entropy stable discontinuous Galerkin\nmethods: knapsack limiting, which blends together a low order, positivity\npreserving, and entropy stable scheme with a high order accurate scheme, in\norder to produce a high order accurate, entropy stable, and positivity\npreserving scheme. Another recent strategy introduces an entropy correction\nartificial viscosity into a high order scheme, aiming to satisfy a cell entropy\ninequality.\n  In this work, we introduce the techniques of knapsack limiting and artificial\nviscosity for finite difference discretizations. The proposed schemes preserve\nhigh order accuracy in sufficiently smooth conditions, are entropy stable, and\nare hyperparameter free. Moreover, the proposed knapsack limiting scheme\nprovably preserves positivity for the compressible Euler and Navier-Stokes\nequations. Both schemes achieve this goal without significant performance\ntradeoffs compared to state of the art stabilized schemes.", "AI": {"tldr": "This paper introduces knapsack limiting and artificial viscosity techniques for finite difference discretizations to achieve entropy stability, high-order accuracy, and positivity preservation in computational fluid dynamics.", "motivation": "Entropy stable methods provide robust, hyperparameter-free solutions in computational fluid dynamics, but existing approaches like discontinuous Galerkin methods need adaptation for finite difference discretizations to achieve similar benefits.", "method": "The authors adapt knapsack limiting (blending low-order positivity-preserving schemes with high-order schemes) and entropy correction artificial viscosity techniques from discontinuous Galerkin methods to finite difference discretizations.", "result": "The proposed finite difference schemes preserve high-order accuracy in smooth conditions, are entropy stable, hyperparameter-free, and the knapsack limiting scheme provably preserves positivity for compressible Euler and Navier-Stokes equations without significant performance tradeoffs.", "conclusion": "The work successfully extends entropy stabilization techniques to finite difference methods, providing robust, high-order accurate, and positivity-preserving schemes for computational fluid dynamics applications."}}
{"id": "2508.21279", "pdf": "https://arxiv.org/pdf/2508.21279", "abs": "https://arxiv.org/abs/2508.21279", "authors": ["Chris Vales", "Siu Wun Cheung", "Dylan M. Copeland", "Youngsoo Choi"], "title": "Machine-precision energy conservative quadrature hyperreduction of Lagrangian hydrodynamics", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "physics.flu-dyn"], "comment": "24 pages, 1 figure", "summary": "We present an energy conservative, quadrature based model reduction framework\nfor the compressible Euler equations of Lagrangian hydrodynamics. Building on a\nhigh order finite element discretization of the governing equations, we develop\na projection based reduced model using data driven reduced basis functions and\nhyperreduction via the empirical quadrature procedure (EQP). We introduce a\nstrongly energy conservative variant of EQP that enforces exact discrete total\nenergy conservation during the hyperreduction process. Numerical experiments\nfor four benchmark problems -- Sedov blast, Gresho vortex, triple point and\nTaylor-Green vortex -- demonstrate that the numerical implementation of our\nproposed method conserves total energy to near machine precision while\nmaintaining accuracy comparable to the basic EQP formulation. These results\nestablish the energy conservative EQP (CEQP) method as an effective structure\npreserving hyperreduction strategy for the reduced simulation of nonlinear\nLagrangian hydrodynamics.", "AI": {"tldr": "Energy conservative quadrature-based model reduction for compressible Euler equations using data-driven reduced basis and hyperreduction with exact discrete total energy conservation.", "motivation": "To develop a structure-preserving reduced order model for Lagrangian hydrodynamics that maintains exact energy conservation while achieving computational efficiency.", "method": "Projection-based reduced model using data-driven reduced basis functions and hyperreduction via empirical quadrature procedure (EQP) with energy conservation enforcement.", "result": "Numerical experiments on four benchmark problems show total energy conservation to near machine precision while maintaining accuracy comparable to basic EQP formulation.", "conclusion": "The energy conservative EQP (CEQP) method is an effective structure-preserving hyperreduction strategy for nonlinear Lagrangian hydrodynamics simulation."}}
{"id": "2508.21390", "pdf": "https://arxiv.org/pdf/2508.21390", "abs": "https://arxiv.org/abs/2508.21390", "authors": ["Yu-Qiu Liu", "Hefeng Wang", "Hua Xiang"], "title": "Generalized quantum singular value transformation with application in quantum bi-conjugate gradient method", "categories": ["math.NA", "cs.NA", "quant-ph"], "comment": null, "summary": "Quantum signal processing (QSP) and generalized quantum signal processing\n(GQSP) are essential tools for implementing the block encoding of matrix\nfunctions. The achievable polynomials of QSP have restrictions on parity, while\nGQSP eliminates these restrictions. In this paper, we further investigate GQSP\nand present a quantum bi-conjugate gradient (BiCG) algorithm as an application.\nFirst, we extend GQSP, which constructs functions of unitary matrices, to\ngeneral matrices. We refer to this extension as generalized quantum singular\nvalue transformation (GQSVT). Subsequently, we implement the quantum BiCG\nmethod, utilizing GQSVT and swap test, which has a relatively shallow circuit\ndepth and requires a small number of ancilla qubits.", "AI": {"tldr": "Extends GQSP to general matrices as GQSVT and applies it to implement quantum BiCG algorithm with shallow circuits and few ancilla qubits.", "motivation": "QSP and GQSP have polynomial parity restrictions; need to extend these techniques to general matrices and develop practical quantum algorithms with efficient resource usage.", "method": "Extends GQSP to handle general matrices (GQSVT), then implements quantum BiCG method using GQSVT and swap test techniques.", "result": "Developed GQSVT framework and demonstrated quantum BiCG algorithm with relatively shallow circuit depth and minimal ancilla qubit requirements.", "conclusion": "GQSVT successfully generalizes quantum signal processing to arbitrary matrices, enabling efficient quantum algorithms like BiCG with practical circuit implementations."}}
{"id": "2508.21293", "pdf": "https://arxiv.org/pdf/2508.21293", "abs": "https://arxiv.org/abs/2508.21293", "authors": ["H. Peng", "T. W. Huang", "C. N. Wu", "K. Jiang", "R. Li", "C. Riconda", "S. Weber", "C. T. Zhou"], "title": "Coherent attosecond pulses generated by a relativistic electron beam interacting with an intense laser at a grazing angle", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The interaction between relativistic electron beams and intense laser fields\nhas been extensively studied for generating high-energy radiation. However,\nachieving coherent radiation from such interactions needs to precisely control\nthe phase matching of the radiationg electrons, which has proven to be\nexceptionally challenging. In this study, we demonstrate that coherent\nattosecond radiation can be produced when a laser pulse interacts at grazing\nangle with a relativistic electron beam. The electrons oscillate in the laser\nfield and are modulated with a superluminal phase, coherent ultrashort pulse\ntrains are produced in the far field at the Cherenkov angle. This is verified\nby theoretical modeling and numerical simulations, including three-dimensional\nparticle-in-cell (PIC) simulations and far-field time-domain radiation\nsimulations. Based on our proposed scheme, high-repetition-rate, compact, and\nhigh-energy attosecond pulse sources are feasible.", "AI": {"tldr": "Coherent attosecond radiation achieved through grazing-angle interaction between laser pulse and relativistic electron beam, enabling compact high-energy attosecond sources.", "motivation": "Generating coherent radiation from relativistic electron beams and intense laser fields has been challenging due to difficulties in precise phase matching control of radiating electrons.", "method": "Laser pulse interacts at grazing angle with relativistic electron beam, causing electrons to oscillate and be modulated with superluminal phase, producing coherent ultrashort pulse trains at Cherenkov angle. Verified through theoretical modeling, 3D particle-in-cell simulations, and far-field time-domain radiation simulations.", "result": "Successful demonstration of coherent attosecond radiation production through the proposed grazing-angle interaction scheme.", "conclusion": "The proposed scheme enables feasible development of high-repetition-rate, compact, and high-energy attosecond pulse sources."}}
{"id": "2508.21136", "pdf": "https://arxiv.org/pdf/2508.21136", "abs": "https://arxiv.org/abs/2508.21136", "authors": ["Tian Qiu", "Joseph E. Subotnik"], "title": "Fast Methods For Multisite Charge Transfer Processes I: Constrained, State Averaged CASSCF(1,M) and CASSCF(2M-1,M) Simulations", "categories": ["physics.comp-ph"], "comment": null, "summary": "We design a dynamically-weighted state-averaged constrained CASSCF to treat\n\\ul{e}lectrons or \\ul{h}oles moving between $n$ molecular fragments (where $n$\ncan be larger than 2). Within such a so-called eDSCn/hDSCn approach, we\nconsider configurations that are mutually single excitations of each other, and\nwe apply a generalized set of constraints to tailor the method for studying\ncharge transfer problems. The constrained optimization problem is efficiently\nsolved using a DIIS-SQP algorithm, thus maintaining computational efficiency.\nWe demonstrate the method for a finite Su-Schrieffer-Heeger (SSH) chain,\nsuccessfully reproducing the expected exponential decay of diabatic couplings\nwith distance. When combined with a gradient, the current extension immediately\nenables efficient nonadiabatic dynamics simulations of complex multi-state\ncharge transfer processes.", "AI": {"tldr": "A new dynamically-weighted state-averaged constrained CASSCF method (eDSCn/hDSCn) is developed for studying charge transfer between multiple molecular fragments, with efficient DIIS-SQP optimization and demonstrated success on SSH chains.", "motivation": "To develop an efficient method for treating electrons or holes moving between multiple molecular fragments (n>2) in charge transfer problems, which requires handling configurations that are mutually single excitations of each other.", "method": "Dynamically-weighted state-averaged constrained CASSCF approach with generalized constraints tailored for charge transfer, solved efficiently using DIIS-SQP algorithm.", "result": "Successfully demonstrated on finite Su-Schrieffer-Heeger chains, reproducing expected exponential decay of diabatic couplings with distance.", "conclusion": "The method enables efficient nonadiabatic dynamics simulations of complex multi-state charge transfer processes when combined with gradients."}}
{"id": "2508.21151", "pdf": "https://arxiv.org/pdf/2508.21151", "abs": "https://arxiv.org/abs/2508.21151", "authors": ["Bego\u00f1a Barrios", "Bryan Pichucho", "Alexander Quaas"], "title": "Propagation in the Fisher-KPP equation with Mixed Operator", "categories": ["math.AP"], "comment": "21 Pages, 2 figures", "summary": "Our investigation focuses on the asymptotic spreading behavior of the\nFisher-KPP equation with a mixed local-nonlocal operator in the diffusion (see\nthe work by X. Cabr\\'e and J.-M. Roquejoffre, 2013, ref.[8]) to the setting of\nmixed diffusion, which involves both the classical and the fractional Laplacian\nin order to analyze the long-time dynamics of the equation. A key step in our\napproach involves the construction and detailed study of the heat kernel\nassociated with the mixed operator, which we use to develop a theory of mild\nsolutions and establish a comparison principle in suitable weighted function\nspaces.\n  This framework allows us to rigorously establish the non-existence of\ntraveling waves and characterize the large-time spreading rate of solutions. We\nshow that the influence of the fractional Laplacian dominates over the\nclassical Laplacian, especially in the initial layer, where it dictates the\nexponential propagation rate and the thickness of the solution tails.", "AI": {"tldr": "Analysis of Fisher-KPP equation with mixed local-nonlocal diffusion operator, showing fractional Laplacian dominates classical Laplacian in determining propagation rates and tail behavior.", "motivation": "To understand the asymptotic spreading behavior and long-time dynamics of the Fisher-KPP equation with mixed diffusion involving both classical and fractional Laplacian operators.", "method": "Construction and study of heat kernel for mixed operator, development of mild solutions theory, establishment of comparison principle in weighted function spaces.", "result": "Non-existence of traveling waves, characterization of large-time spreading rate, demonstration that fractional Laplacian dominates classical Laplacian in determining exponential propagation rate and tail thickness.", "conclusion": "The fractional diffusion component plays a dominant role in the spreading dynamics, particularly in the initial layer, controlling both propagation speed and solution tail behavior."}}
{"id": "2508.21410", "pdf": "https://arxiv.org/pdf/2508.21410", "abs": "https://arxiv.org/abs/2508.21410", "authors": ["Shubhangini Gupta", "Sourav Banerjee", "Tamal Pramanick"], "title": "A Biologically Motivated Finite Difference Approach for Simulating Singularly Perturbed Vertical Motion in Human Gait", "categories": ["math.NA", "cs.NA", "65L11, 65L70, 65L80 } 65L11, 65L70, 65L80 } 65L11, 65L70, 65L80"], "comment": null, "summary": "In this study, we present a simulation-based numerical method for solving a\nclass of singularly perturbed second-order differential equations that come\nfrom a simplified biologically motivated model of human gait. Important\nphysical factors such as gravity, damping, and leg stiffness are included in\nthe model, which also depicts the vertical motion of the center of mass of the\nbody during walking or running. Most of the time, standard numerical methods\nare ineffective in resolving boundary layer behavior that occurs due to the\nsmall perturbation parameter in the governing equation. We use a domain\ndecomposition technique to divide the problem domain into inner and outer\nregions to tackle this difficulty. The boundary layer resolves the steep\ngradients. We applied a time-rescaling transformation to the inner region. Each\nsubdomain is discretized, and the resulting tridiagonal systems are efficiently\nsolved using the Thomas algorithm within the mixed finite difference framework.\nA detailed convergence analysis demonstrates second-order accuracy in space.\nThe numerical results validate the proposed scheme's accuracy, stability, and\nefficiency through experiments based on modified human gait models. The\nframework serves as a fundamental tool for biomechanical simulation. The\nmodeling is a foundation for future research, incorporating nonlinearities,\ntime delays, and real-world scenarios data on how people walk.", "AI": {"tldr": "A simulation-based numerical method for solving singularly perturbed second-order differential equations from human gait models, using domain decomposition and time-rescaling to handle boundary layers with second-order accuracy.", "motivation": "Standard numerical methods fail to resolve boundary layer behavior in singularly perturbed differential equations from human gait models, which include important physical factors like gravity, damping, and leg stiffness.", "method": "Domain decomposition technique dividing the problem into inner and outer regions, time-rescaling transformation for the inner region, discretization with mixed finite difference framework, and solving tridiagonal systems using Thomas algorithm.", "result": "The method achieves second-order accuracy in space, validated through numerical experiments on modified human gait models, demonstrating accuracy, stability, and efficiency.", "conclusion": "The framework serves as a fundamental tool for biomechanical simulation and provides a foundation for future research incorporating nonlinearities, time delays, and real-world walking data."}}
{"id": "2508.21532", "pdf": "https://arxiv.org/pdf/2508.21532", "abs": "https://arxiv.org/abs/2508.21532", "authors": ["Manohar Teja Kalluri", "Andrew Hillier", "Ben Snow"], "title": "Quantifying Reconnection and it's Dynamical Role in 2D Magnetic Rayleigh-Taylor Turbulence", "categories": ["physics.plasm-ph", "astro-ph.SR", "physics.flu-dyn", "physics.geo-ph"], "comment": "22 pages, 27 figures", "summary": "Magnetic Rayleigh-Taylor instability (MRTI) governs material transport and\nmixing in astrophysical and laboratory plasmas under the influence of gravity\nand magnetic fields. While magnetic reconnection is known to occur during MRTI\nevolution, its role in the evolution and energy dynamics remains poorly\nunderstood. Here, we present a comprehensive analysis of the role of\nreconnection in the two-dimensional MRTI dynamics, using high-resolution\nsimulations. We establish that reconnection, through facilitating plume merger,\nrelieving magnetic tension, and enabling continued instability growth, forms an\nessential component for the long-term instability evolution. To quantify the\nrole of reconnection in energy dynamics, we develop a robust automated\nreconnection detection algorithm and perform a statistical analysis across a\nrange of magnetic field strengths. We find that reconnection accounts for up to\n$80\\%$ of the magnetic-to-kinetic energy transfer in the weak magnetic field\nregime, while contributing minimally ($\\approx 3\\%$) to magnetic energy\ndissipation. Our results establish magnetic reconnection as a critical\nmechanism that regulates large-scale MRTI dynamics, with implications for\nastrophysical plasmas and turbulent mixing in magnetized flows.", "AI": {"tldr": "Magnetic reconnection plays a critical role in magnetic Rayleigh-Taylor instability evolution, facilitating plume merger and enabling continued growth, accounting for up to 80% of magnetic-to-kinetic energy transfer in weak field regimes.", "motivation": "Magnetic reconnection occurs during MRTI evolution but its role in energy dynamics and instability evolution remains poorly understood, particularly in astrophysical and laboratory plasmas.", "method": "High-resolution 2D simulations with a robust automated reconnection detection algorithm, performing statistical analysis across various magnetic field strengths.", "result": "Reconnection accounts for up to 80% of magnetic-to-kinetic energy transfer in weak magnetic field regimes, but only contributes minimally (~3%) to magnetic energy dissipation.", "conclusion": "Magnetic reconnection is established as a critical mechanism regulating large-scale MRTI dynamics, with significant implications for astrophysical plasmas and turbulent mixing in magnetized flows."}}
{"id": "2508.21139", "pdf": "https://arxiv.org/pdf/2508.21139", "abs": "https://arxiv.org/abs/2508.21139", "authors": ["Tian Qiu", "Joseph E. Subotnik"], "title": "Fast Methods For Multisite Charge Transfer Processes II: Analytic Nuclear Gradients and Nonadiabatic Dynamics For cCASSCF(1,M) and cCASSCF(2M-1,M) Wavefunctions", "categories": ["physics.comp-ph"], "comment": null, "summary": "We derive and implement analytic nuclear gradients and derivative couplings\nfor a constrained Complete Active Space Self-Consistent Field with a small\nactive space designed to model electron or hole transfer. Using a Lagrangian\nformalism, we are able to differentiate both the CASSCF energy and the\nconstraint (which is required for globally smooth surfaces), and the resulting\nefficient algorithm can be immediately applied to nonadiabatic dynamics\nsimulations of charge transfer processes. Here, we run initial surface-hopping\nsimulations of a proton coupled electron transfer event for a phenoxyl-phenol\nsystem.", "AI": {"tldr": "Analytic nuclear gradients and derivative couplings for constrained CASSCF with small active spaces for electron/hole transfer modeling", "motivation": "To enable efficient nonadiabatic dynamics simulations of charge transfer processes by providing analytic gradients and couplings for constrained CASSCF methods", "method": "Used Lagrangian formalism to differentiate both CASSCF energy and constraints, ensuring globally smooth surfaces. Implemented efficient algorithm for nuclear gradients and derivative couplings", "result": "Successfully derived and implemented analytic nuclear gradients and derivative couplings. Applied to surface-hopping simulations of proton coupled electron transfer in phenoxyl-phenol system", "conclusion": "The developed method provides an efficient approach for modeling charge transfer dynamics and can be immediately applied to nonadiabatic simulations of electron/hole transfer processes"}}
{"id": "2508.21174", "pdf": "https://arxiv.org/pdf/2508.21174", "abs": "https://arxiv.org/abs/2508.21174", "authors": ["Fioralba Cakoni", "Shari Moskow"], "title": "Asymptotic expansions for the transmission eigenvalues of periodic scatterers of bounded support", "categories": ["math.AP"], "comment": null, "summary": "We consider the transmission eigenvalues for a bounded scatterer with a\nperiodically varying index of refraction, and derive the first order\ncorrections to the limiting transmission eigenvalues. We assume the scatterer\ncontrast to be of one sign, in which case the transmission eigenvalue problem\ncan be written in terms of operators corresponding to a fourth order PDE with\nperiodic coefficients. We perform two-scale asymptotics for this biharmonic\ntype homogenization problem and show convergence estimates which require a\nboundary corrector function, and this boundary corrector function appears in\nthe formula for the transmission eigenvalues correction.", "AI": {"tldr": "First-order corrections to transmission eigenvalues for scatterers with periodic refractive index variations, using two-scale asymptotics for biharmonic homogenization with boundary correctors.", "motivation": "To analyze transmission eigenvalues in bounded scatterers with periodically varying refractive indices, particularly when the contrast has one sign, enabling formulation as a fourth-order PDE problem.", "method": "Two-scale asymptotics for biharmonic-type homogenization problem, incorporating boundary corrector functions to derive convergence estimates and eigenvalue corrections.", "result": "Derived first-order corrections to limiting transmission eigenvalues, with the boundary corrector function appearing explicitly in the correction formula.", "conclusion": "The method successfully provides first-order eigenvalue corrections for periodic scatterers through biharmonic homogenization with boundary correctors, establishing convergence estimates."}}
{"id": "2508.21427", "pdf": "https://arxiv.org/pdf/2508.21427", "abs": "https://arxiv.org/abs/2508.21427", "authors": ["Ferdinand Thein", "Hendrik Ranocha"], "title": "Computing Radially-Symmetric Solutions of the Ultra-Relativistic Euler Equations with Entropy-Stable Discontinuous Galerkin Methods", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "65M06, 65M20, 65M70, 35L45"], "comment": null, "summary": "The ultra--relativistic Euler equations describe gases in the relativistic\ncase when the thermal energy dominates. These equations for an ideal gas are\ngiven in terms of the pressure, the spatial part of the dimensionless\nfour-velocity, and the particle density. Kunik et al.\\ (2024,\nhttps://doi.org/10.1016/j.jcp.2024.113330) proposed genuine multi--dimensional\nbenchmark problems for the ultra--relativistic Euler equations. In particular,\nthey compared full two-dimensional discontinuous Galerkin simulations for\nradially symmetric problems with solutions computed using a specific\none-dimensional scheme. Of particular interest in the solutions are the\nformation of shock waves and a pressure blow-up. In the present work we derive\nan entropy-stable flux for the ultra--relativistic Euler equations. Therefore,\nwe derive the main field (or entropy variables) and the corresponding\npotentials. We then present the entropy-stable flux and conclude with\nsimulation results for different test cases both in 2D and in 3D.", "AI": {"tldr": "Derived entropy-stable flux for ultra-relativistic Euler equations using main field/entropy variables and potentials, with 2D/3D simulation results.", "motivation": "To address shock wave formation and pressure blow-up in ultra-relativistic gases by developing entropy-stable numerical methods, building on previous benchmark problems by Kunik et al.", "method": "Derived main field (entropy variables) and corresponding potentials for ultra-relativistic Euler equations, then developed an entropy-stable flux formulation. Validated with 2D and 3D simulations.", "result": "Successfully developed entropy-stable flux formulation and demonstrated its performance through simulations of various test cases in both 2D and 3D configurations.", "conclusion": "The proposed entropy-stable flux provides a robust numerical framework for solving ultra-relativistic Euler equations, effectively handling shock formation and pressure blow-up phenomena."}}
{"id": "2508.21208", "pdf": "https://arxiv.org/pdf/2508.21208", "abs": "https://arxiv.org/abs/2508.21208", "authors": ["Chayanon Wichitrnithed", "Eirik Valseth", "Clint Dawson"], "title": "GPU-acceleration of the Discontinuous Galerkin Shallow Water Equations Solver (DG-SWEM) using CUDA and OpenACC", "categories": ["physics.comp-ph"], "comment": null, "summary": "This paper presents a porting of DG-SWEM, a discontinuous Galerkin solver for\ncoastal ocean circulation, and in particular storm surge, to GPU using two\nseparate approaches: CUDA Fortran and OpenACC. Time-explicit discontinuous\nGalerkin methods have been shown to exhibit a large amount of data parallelism\ndue to the loose coupling between elements, and thus are naturally mapped to\nthe GPU architecture. For each porting approach, we discuss the code design,\nease of programming, and performance when running on realistic use cases.\nSpecifically for the OpenACC version, we also aim to preserve maintainability\nwithin the same codebase through using Unified Memory. We test the codes on\nNVIDIA's Grace Hopper chip and compare the GPU performance on each node to the\nMPI version on a single CPU node (144 cores).", "AI": {"tldr": "Porting of DG-SWEM coastal ocean solver to GPU using CUDA Fortran and OpenACC, comparing code design, programming ease, and performance on NVIDIA Grace Hopper vs CPU MPI version.", "motivation": "Discontinuous Galerkin methods exhibit high data parallelism due to loose element coupling, making them naturally suitable for GPU architectures to accelerate coastal ocean circulation and storm surge simulations.", "method": "Two separate GPU porting approaches: CUDA Fortran and OpenACC. OpenACC version uses Unified Memory to maintain codebase maintainability. Performance tested on NVIDIA Grace Hopper chip compared to MPI version on single CPU node (144 cores).", "result": "Performance comparison between GPU implementations (CUDA Fortran and OpenACC) and CPU MPI version on realistic use cases, evaluating computational efficiency on modern GPU architecture.", "conclusion": "Demonstrates successful GPU porting strategies for discontinuous Galerkin coastal ocean solvers, providing insights into code design trade-offs and performance benefits of GPU acceleration for scientific computing applications."}}
{"id": "2508.21183", "pdf": "https://arxiv.org/pdf/2508.21183", "abs": "https://arxiv.org/abs/2508.21183", "authors": ["Bastian Hilder", "Christian Kuehn"], "title": "Pattern formation and nonlinear waves close to a 1:1 resonant Turing and Turing--Hopf instability", "categories": ["math.AP", "nlin.PS", "35B32, 35B34, 35B36, 34E15, 34C37, 37L10"], "comment": "45 pages, 16 Figures", "summary": "In this paper, we analyse the dynamics of a pattern-forming system close to\nsimultaneous Turing and Turing--Hopf instabilities, which have a 1:1 spatial\nresonance, that is, they have the same critical wave number. For this, we\nconsider a system of coupled Swift--Hohenberg equations with dispersive terms\nand general, smooth nonlinearities. Close to the onset of instability, we\nderive a system of two coupled complex Ginzburg--Landau equations with a\nsingular advection term as amplitude equations and justify the approximation by\nproviding error estimates. We then construct space-time periodic solutions to\nthe amplitude equations, as well as fast-travelling front solutions, which\nconnect different space-time periodic states. This yields the existence of\nsolutions to the pattern-forming system on a finite, but long time interval,\nwhich model the spatial transition between different patterns. The construction\nis based on geometric singular perturbation theory exploiting the fast\ntravelling speed of the fronts. Finally, we construct global, spatially\nperiodic solutions to the pattern-forming system by using centre manifold\nreduction, normal form theory and a variant of singular perturbation theory to\nhandle fast oscillatory higher-order terms.", "AI": {"tldr": "Analysis of pattern-forming systems near simultaneous Turing and Turing-Hopf instabilities with 1:1 spatial resonance, using coupled Swift-Hohenberg equations and deriving amplitude equations.", "motivation": "To understand the dynamics of pattern-forming systems when both Turing and Turing-Hopf instabilities occur simultaneously with the same critical wave number, which is relevant for studying pattern transitions in various physical and biological systems.", "method": "Use coupled Swift-Hohenberg equations with dispersive terms and general nonlinearities. Derive coupled complex Ginzburg-Landau equations as amplitude equations near instability onset. Construct space-time periodic solutions and fast-travelling front solutions using geometric singular perturbation theory. Apply center manifold reduction and normal form theory for global solutions.", "result": "Successfully derived amplitude equations with error estimates, constructed space-time periodic solutions and fast-travelling fronts that connect different patterns, and obtained solutions modeling spatial pattern transitions on long time intervals.", "conclusion": "The approach provides a framework for analyzing pattern transitions in systems with simultaneous instabilities, demonstrating the existence of various solution types including periodic patterns and connecting fronts, with applications to understanding pattern formation dynamics."}}
{"id": "2508.21478", "pdf": "https://arxiv.org/pdf/2508.21478", "abs": "https://arxiv.org/abs/2508.21478", "authors": ["Qiao-Ping Chen", "Hongyu Liu", "Zejun Sun", "Li-Li Wang", "Guang-Hui Zheng"], "title": "Inverse Random Source Problem for the Helmholtz Equation from Statistical Phaseless Data", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper investigates the problem of reconstructing a random source from\nstatistical phaseless data for the two-dimensional Helmholtz equation. The\nmajor challenge of this problem is non-uniqueness, which we overcome through a\nreference source technique. Firstly, we introduce some artificially added point\nsources into the inverse random source system and derive phase retrieval (PR)\nformulas for the expectation and variance of the radiated fields. This paper\nrigorously analyze the uniqueness and stability of the recovered statistics of\nthe radiated fields. Afterwards, since the direct problem has a unique mild\nsolution, by examining the expectation and variance of this solution and\ncombined with the phase retrieval formulas, we derive the Fredholm integral\nequations to solve the inverse random source problem (IRSP). We prove the\nstability of the corresponding integral equations. To quantify the uncertainty\nof the random source, we utilize the Bayesian method to reconstruct the random\nsource and establish the well-posedness of the posterior distribution. Finally,\nnumerical experiments demonstrate the effectiveness of the proposed method and\nvalidate the theoretical results.", "AI": {"tldr": "This paper presents a method for reconstructing random sources from phaseless data in 2D Helmholtz equations using reference sources and Bayesian inference to overcome non-uniqueness issues.", "motivation": "The main challenge in reconstructing random sources from statistical phaseless data is non-uniqueness, which this research aims to overcome through innovative techniques.", "method": "Introduces artificial point sources as references, derives phase retrieval formulas for field statistics, analyzes uniqueness/stability, uses Fredholm integral equations, and applies Bayesian methods for uncertainty quantification.", "result": "The method successfully reconstructs random sources with proven stability and well-posed posterior distributions, validated through numerical experiments.", "conclusion": "The proposed approach effectively solves the inverse random source problem for 2D Helmholtz equations with phaseless data, providing both theoretical guarantees and practical validation."}}
{"id": "2508.21200", "pdf": "https://arxiv.org/pdf/2508.21200", "abs": "https://arxiv.org/abs/2508.21200", "authors": ["Davoud Mirzaei", "Behnam Hashemi", "Vahid Azimi-Mousolou"], "title": "LREI: A fast numerical solver for quantum Landau-Lifshitz equations", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cs.NA", "math.NA", "physics.comp-ph"], "comment": "23 pages and 12 figures", "summary": "We develop LREI (Low-Rank Eigenmode Integration), a memory- and\ntime-efficient scheme for solving quantum Landau-Lifshitz (q-LL) and quantum\nLandau-Lifshitz-Gilbert (q-LLG) equations, which govern spin dynamics in open\nquantum systems. Although system size grows exponentially with the number of\nspins, our approach exploits the low-rank structure of the density matrix and\nthe sparsity of Hamiltonians to avoid full matrix computations. By representing\ndensity matrices via low-rank factors and applying Krylov subspace methods for\npartial eigendecompositions, we reduce the per-step complexity of Runge-Kutta\nand Adams-Bashforth schemes from $\\mathcal{O}(N^3)$ to $\\mathcal{O}(r^2N)$,\nwhere $N = 2^n$ is the Hilbert space dimension for $n$ spins and $r \\ll N$ the\neffective rank. Similarly, memory costs shrink from $\\mathcal{O}(N^2)$ to\n$\\mathcal{O}(rN)$, since no full $N\\times N$ matrices are formed. A key advance\nis handling the invariant subspace of zero eigenvalues. By using Householder\nreflectors built for the dominant eigenspace, we perform the solution entirely\nwithout large matrices. For example, a time step of a twenty-spin system, with\ndensity matrix size over one million, now takes only seconds on a standard\nlaptop. Both Runge-Kutta and Adams-Bashforth methods are reformulated to\npreserve physical properties of the density matrix throughout evolution. This\nlow-rank algorithm enables simulations of much larger spin systems, which were\npreviously infeasible, providing a powerful tool for comparing q-LL and q-LLG\ndynamics, testing each model validity, and probing how quantum features such as\ncorrelations and entanglement evolve across different regimes of system size\nand damping.", "AI": {"tldr": "LREI enables efficient quantum spin dynamics simulations by exploiting low-rank density matrix structure and Hamiltonian sparsity, reducing computational complexity from O(N\u00b3) to O(r\u00b2N) and memory from O(N\u00b2) to O(rN).", "motivation": "Traditional methods for solving quantum Landau-Lifshitz equations become computationally infeasible as system size grows exponentially with spin count, requiring memory-efficient approaches for large quantum spin systems.", "method": "Uses low-rank factorization of density matrices, Krylov subspace methods for partial eigendecompositions, and Householder reflectors to handle invariant subspaces without forming full matrices. Reformulates Runge-Kutta and Adams-Bashforth schemes to preserve physical properties.", "result": "Achieves dramatic speedup - a 20-spin system (1M+ matrix size) now takes seconds per time step on a standard laptop instead of being computationally prohibitive.", "conclusion": "LREI enables previously infeasible simulations of large quantum spin systems, providing a powerful tool for comparing q-LL/q-LLG dynamics and studying quantum features like entanglement across different system regimes."}}
{"id": "2508.21198", "pdf": "https://arxiv.org/pdf/2508.21198", "abs": "https://arxiv.org/abs/2508.21198", "authors": ["Elena M\u00e4der-Baumdicker", "Robin Neumayer", "Jiewon Park", "Melanie Rupflin"], "title": "Quantitative estimates for the relative isoperimetric problem and its gradient flow outside convex bodies in the plane", "categories": ["math.AP", "math.DG"], "comment": null, "summary": "We prove three related quantitative results for the relative isoperimetric\nproblem outside a convex body $\\Omega$ in the plane: (1) {\\L}ojasiewicz\nestimates and quantitative rigidity for critical points, (2) rates of\nconvergence for the gradient flow, and (3) quantitative stability for\nminimizers. These results come with explicit constants and optimal\nexponents/rates, and hold whenever a simple two-dimensional auxiliary\nvariational problem for circular arcs outside of $\\Omega$ is nondegenerate. The\nproofs are inter-related, and in particular, for the first time in the context\nof isoperimetric problems, a flow approach is used to prove quantitative\nstability for minimizers.", "AI": {"tldr": "Quantitative analysis of relative isoperimetric problems outside convex bodies in the plane, proving three related results with explicit constants and optimal rates.", "motivation": "To establish rigorous quantitative estimates for relative isoperimetric problems, addressing critical points, gradient flow convergence, and stability of minimizers with precise mathematical bounds.", "method": "Using a flow approach combined with analysis of a two-dimensional auxiliary variational problem for circular arcs outside convex bodies, proving \u0141ojasiewicz estimates, quantitative rigidity, and convergence rates.", "result": "Proved three quantitative results: (1) \u0141ojasiewicz estimates and quantitative rigidity for critical points, (2) rates of convergence for gradient flow, and (3) quantitative stability for minimizers - all with explicit constants and optimal exponents/rates.", "conclusion": "The flow approach successfully proves quantitative stability for minimizers in isoperimetric problems for the first time, with results holding when the auxiliary variational problem is nondegenerate, providing comprehensive quantitative analysis with optimal parameters."}}
{"id": "2508.21506", "pdf": "https://arxiv.org/pdf/2508.21506", "abs": "https://arxiv.org/abs/2508.21506", "authors": ["Dario A. Bini", "Beatrice Meini", "Federico Poloni"], "title": "The Derivative of Kemeny's Constant as a Centrality Measure in Undirected Graphs", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Kemeny's constant quantifies a graph's connectivity by measuring the average\ntime for a random walker to reach any other vertex. We introduce two concepts\nof the directional derivative of Kemeny's constant with respect to an edge and\nuse them to define centrality measures for edges and non-edges in the graph.\nAdditionally, we present a sensitivity measure of Kemeny's constant. An\nexplicit expression for these quantities involving the inverse of the modified\ngraph Laplacian is provided, which is valid even for cut-edges. These measures\nare connected to the one introduced in [Altafini et al., SIMAX 2023], and\nalgorithms for their computation are included. The benefits of these measures\nare discussed, along with applications to road networks and link prediction\nanalysis. For one-path graphs, an explicit expression for these measures is\ngiven in terms of the edge weights.", "AI": {"tldr": "This paper introduces directional derivatives of Kemeny's constant to define edge/non-edge centrality measures and sensitivity analysis, providing explicit formulas using graph Laplacian inverses that work even for cut-edges.", "motivation": "To quantify how individual edges affect graph connectivity by measuring their impact on Kemeny's constant, which represents the average random walk time between vertices.", "method": "Defined two concepts of directional derivative of Kemeny's constant with respect to edges, derived explicit expressions using modified graph Laplacian inverses, developed computational algorithms, and applied to road networks and link prediction.", "result": "Obtained explicit formulas for edge centrality measures that remain valid for cut-edges, established connections to existing measures, and provided specific expressions for one-path graphs in terms of edge weights.", "conclusion": "The introduced directional derivative measures provide effective tools for analyzing edge importance in graph connectivity, with practical applications in network analysis and link prediction problems."}}
{"id": "2508.21214", "pdf": "https://arxiv.org/pdf/2508.21214", "abs": "https://arxiv.org/abs/2508.21214", "authors": ["Benjamin Foster", "Josep Gallegos"], "title": "Propagation of smallness near codimension two for gradients of harmonic functions", "categories": ["math.AP", "31B05"], "comment": "14 pages", "summary": "Let $u$ be a harmonic function in the unit ball $B_1 \\subset \\mathbb R^n$,\nnormalized so that its gradient has magnitude at most 1 on the unit ball. We\nshow that if the gradient of $u$ is $\\epsilon$-small in size on a set $E\\subset\nB_{1/2}$ with positive $(n-2+\\delta)$-dimensional Hausdorff content for some\n$\\delta>0$, then $\\sup_{B_{1/2}} |\\nabla u| \\leq C \\epsilon^\\alpha$ with\n$C,\\alpha>0$ depending only on $n,\\delta$ and the $(n-2+\\delta)$-Hausdorff\ncontent of $E$. This is an improvement over a similar result of Logunov and\nMalinnikova that required $\\delta>1-c_n$ for a small dimensional constant $c_n$\nand reaches the sharp threshold for the dimension of the smallness sets from\nwhich propagation of smallness can occur.", "AI": {"tldr": "Harmonic functions with gradient bounded by 1 in unit ball show that if gradient is \u03b5-small on a set with positive (n-2+\u03b4)-dimensional Hausdorff content, then maximum gradient in half-ball is bounded by C\u03b5^\u03b1.", "motivation": "To improve previous results on propagation of smallness for harmonic functions by reaching the sharp threshold for the dimension of smallness sets, overcoming limitations of prior work that required \u03b4>1-c_n.", "method": "Analysis of harmonic functions in the unit ball with bounded gradient, studying how small gradient values on sets with specific dimensional Hausdorff content propagate to control the maximum gradient in a smaller region.", "result": "Established that sup_{B_{1/2}} |\u2207u| \u2264 C\u03b5^\u03b1, where C and \u03b1 depend only on n, \u03b4 and the (n-2+\u03b4)-Hausdorff content of E, achieving the sharp dimensional threshold for propagation of smallness.", "conclusion": "This work provides an optimal result for propagation of smallness in harmonic functions, extending and improving previous bounds by reaching the critical dimension n-2+\u03b4 for the smallness sets."}}
{"id": "2508.21557", "pdf": "https://arxiv.org/pdf/2508.21557", "abs": "https://arxiv.org/abs/2508.21557", "authors": ["Mart\u00edn Hern\u00e1ndez"], "title": "Random domain decomposition for parabolic PDEs on graphs", "categories": ["math.NA", "cs.NA", "math.AP", "35R02, 65C99, 65M55, 65M75, 68Q25"], "comment": null, "summary": "The simulation of complex systems, such as gas transport in large pipeline\nnetworks, often involves solving PDEs posed on intricate graph structures. Such\nproblems require considerable computational and memory resources. The Random\nBatch Method (RBM) has shown promise in addressing these challenges via\nstochastic decomposition techniques. In this paper, we apply the RBM at the PDE\nlevel for parabolic equations on graphs, without assuming any preliminary\ndiscretization in space or time. We consider a non-overlapping domain\ndecomposition in which the PDE coefficients and source terms are randomized. We\nprove that the resulting RBM-based scheme converges, in the mean-square sense\nand uniformly in time, to the true PDE solution with first-order accuracy in\nthe RBM step size. Numerical experiments confirm this convergence rate and\ndemonstrate substantial reductions in both memory usage and computational time\ncompared to solving on the full graph. Moreover, these advantages persist\nacross different time discretization schemes.", "AI": {"tldr": "RBM applied to parabolic PDEs on graphs via stochastic domain decomposition, achieving first-order convergence with significant computational/memory savings.", "motivation": "Simulating complex systems like gas pipeline networks requires solving PDEs on intricate graphs, which demands substantial computational and memory resources that current methods struggle with.", "method": "Apply Random Batch Method (RBM) at PDE level for parabolic equations on graphs using non-overlapping domain decomposition with randomized coefficients and source terms, without preliminary space/time discretization.", "result": "Proven mean-square convergence to true PDE solution with first-order accuracy in RBM step size. Numerical experiments confirm convergence rate and show substantial reductions in memory usage and computational time compared to full graph solving.", "conclusion": "RBM provides an effective stochastic approach for solving parabolic PDEs on graphs, offering computational efficiency and memory savings while maintaining mathematical convergence guarantees across different time discretization schemes."}}
{"id": "2508.21425", "pdf": "https://arxiv.org/pdf/2508.21425", "abs": "https://arxiv.org/abs/2508.21425", "authors": ["Long Zhang", "Ziqi Ren", "Li Sun", "Yihua Gao", "Deli Wang", "Junjie He", "Guoying Gao"], "title": "When Energy and Information Revolutions Meet 2D Janus", "categories": ["physics.app-ph", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph"], "comment": "114 pages, 21 figures, and 7 tables", "summary": "The depletion of energy sources, worsening environmental issues, and the\nquantum limitations of integrated circuits for information storage in the\npost-Moore era, are pressing global concerns. Fortunately, two-dimensional (2D)\nJanus materials, possessing broken spatial symmetry, with emerging\npressure-dependent and non-linear optical response, piezoelectricity, valley\npolarization, Rashba spin splitting and more, have established a substantial\nplatform for exploring and applying modifiable physical, chemical and\nbiological properties in material science and offered a promising solution for\nthese energy and information issues. To furnish researchers with a\ncomprehensive repository of 2D Janus family, this review systematically\nsummarizes their theoretical predictions, experimental preparations, and\nmodulation strategies. It also retrospectively outlines the recent advances in\nmodifiable properties, applications, and inherent mechanisms in optics,\ncatalysis, piezoelectricity, electrochemistry, thermoelectricity, magnetism,\nand electronics, with a focus on experimentally realized hexagonal and trigonal\nJanus structures. Additionally, their current research state is summarized, and\npotential opportunities and challenges that may arise are highlighted. Overall,\nthis review aims to serve as a valuable resource for designing, fabricating,\nregulating, and applying 2D Janus systems, both theoretically and\nexperimentally. This review will strongly promote the advanced academic\ninvestigations and industrial applications of 2D Janus materials in energy and\ninformation fields.", "AI": {"tldr": "This review paper provides a comprehensive analysis of 2D Janus materials, covering their theoretical predictions, experimental preparations, modulation strategies, and applications in energy and information fields.", "motivation": "Addressing global concerns of energy depletion, environmental issues, and quantum limitations in post-Moore era integrated circuits by exploring 2D Janus materials with unique asymmetric properties.", "method": "Systematic review summarizing theoretical predictions, experimental preparations, modulation strategies, and recent advances in modifiable properties of 2D Janus materials, focusing on experimentally realized hexagonal and trigonal structures.", "result": "The review establishes a comprehensive repository of 2D Janus family materials, outlining their applications in optics, catalysis, piezoelectricity, electrochemistry, thermoelectricity, magnetism, and electronics.", "conclusion": "2D Janus materials offer promising solutions for energy and information challenges, and this review serves as a valuable resource for designing, fabricating, regulating, and applying these materials in both theoretical and experimental contexts."}}
{"id": "2508.21464", "pdf": "https://arxiv.org/pdf/2508.21464", "abs": "https://arxiv.org/abs/2508.21464", "authors": ["Nicolas Rougerie", "Qiyun Yang"], "title": "1D quasi-solutions of the 2D Chern-Simons-Schr{\u00f6}dinger system", "categories": ["math.AP", "cond-mat.mes-hall", "cond-mat.quant-gas", "math-ph", "math.MP"], "comment": null, "summary": "We study a mean-field model for a system of 2D abelian anyons, given by the\ndynamics of a Schr{\\\"o}dinger matter field coupled to a Chern-Simons gauge\nfield. We derive an effective 1D equation by adding a strongly anisotropic\ntrapping potential (wave-guide) acting on the Schr{\\\"o}dinger field, and\ntracing out the tight confinement direction. The effective dynamics in the\nloose direction of the wave-guide turns out to be governed by the classical 1D\nquintic NLS equation.", "AI": {"tldr": "Study of 2D abelian anyons using Schrodinger-Chern-Simons model, deriving effective 1D quintic NLS equation through anisotropic trapping potential.", "motivation": "To understand the dynamics of 2D abelian anyon systems and derive simplified effective equations that capture their essential behavior in confined geometries.", "method": "Used a mean-field model combining Schrodinger matter field with Chern-Simons gauge field, applied strongly anisotropic trapping potential (wave-guide), and traced out the tight confinement direction to obtain 1D effective dynamics.", "result": "The effective dynamics in the loose direction of the wave-guide is governed by the classical 1D quintic nonlinear Schrodinger (NLS) equation.", "conclusion": "The study successfully derived a simplified 1D effective equation from a complex 2D anyon system, showing that anisotropic confinement leads to quintic NLS dynamics, providing insights into reduced-dimensional anyon behavior."}}
{"id": "2508.21630", "pdf": "https://arxiv.org/pdf/2508.21630", "abs": "https://arxiv.org/abs/2508.21630", "authors": ["Stefano Bonetti", "Michele Botti", "Paola F. Antonietti"], "title": "Conforming and discontinuous discretizations of non-isothermal Darcy-Forchheimer flows", "categories": ["math.NA", "cs.NA", "65N12, 65N30, 74F05, 76S05"], "comment": null, "summary": "We present and analyze in a unified setting two schemes for the numerical\ndiscretization of a Darcy-Forchheimer fluid flow model coupled with an\nadvection-diffusion equation modeling the temperature distribution in the\nfluid. The first approach is based on fully discontinuous Galerkin\ndiscretization spaces. In contrast, in the second approach, the velocity is\napproximated in the Raviart-Thomas space, and the pressure and temperature are\nstill piecewise discontinuous. A fixed-point linearization strategy, naturally\ninducing an iterative splitting solution, is proposed for treating the\nnonlinearities of the problem. We present a unified stability analysis and\nprove the convergence of the iterative algorithm under mild requirements on the\nproblem data. A wide set of two- and three-dimensional simulations is presented\nto assess the error decay and demonstrate the practical performance of the\nproposed approaches in physically sound test cases.", "AI": {"tldr": "Two numerical schemes for Darcy-Forchheimer flow coupled with advection-diffusion temperature modeling, using different discretization approaches with fixed-point linearization for nonlinearities.", "motivation": "To develop efficient numerical methods for simulating coupled fluid flow and heat transfer problems involving Darcy-Forchheimer flow with temperature-dependent properties, which are common in porous media applications.", "method": "Two discretization approaches: 1) fully discontinuous Galerkin spaces, and 2) Raviart-Thomas space for velocity with discontinuous pressure/temperature. Both use fixed-point linearization iterative splitting for nonlinearities.", "result": "Unified stability analysis and convergence proof under mild data requirements. Comprehensive 2D/3D simulations demonstrate error decay and practical performance in physically sound test cases.", "conclusion": "Both proposed numerical schemes are effective for Darcy-Forchheimer flow with thermal coupling, with proven stability and convergence, validated through extensive numerical experiments."}}
{"id": "2508.21492", "pdf": "https://arxiv.org/pdf/2508.21492", "abs": "https://arxiv.org/abs/2508.21492", "authors": ["Samuel Aldana", "Michael Nolan"], "title": "Control of growth morphology of deposited fcc metals through tuning substrate-metal interactions", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "physics.comp-ph"], "comment": "58 pages, 10 figures", "summary": "Precise control over thin film morphology is critical for optimizing material\nproperties across diverse technological applications, as the growth mode\n(whether 2D layer-by-layer or 3D island formation)determines key functional\nproperties such as electrical conductivity in CMOS interconnect applications\nand catalytic activity, where island distribution and size dictate performance.\nTo explore the role of the substrate on the morphology of deposited metals, we\npresent extensive kinetic Monte Carlo simulations on six fcc metals growing in\nthe (111) direction: Ag, Au, Cu, Ni, Pd and Pt. Our simulation framework\nenables screening and evaluation of their growth mode under homoepitaxial\ngrowth scenarios and proposes morphology control strategies by variation of\nsubstrate-metal interaction strengths, modeled by modifying the activation\nenergies for upward and downward migration, combined with thermal vacuum\nannealing within typical back end of line (BEOL) integration thermal budget.\nOur simulation results demonstrate that modulation of the substrate interaction\nstrength can be effectively employed to promote island formation or\nlayer-by-layer growth modes overcoming limitations in achieving large flat\nsurface areas. Au, Pd and Pt exhibit the highest sensitivity to substrate\ninteraction strength variations, followed by Ag, showing that strongly\ninteracting substrates decrease the root mean square (RMS) roughness,\n(uncovered) substrate exposure, island number and island aspect ratios, with\nmoderate increases in flat surface areas and atomic coordination numbers.\nAdditionally, interconnect relevant metrics are improved through thermal vacuum\nannealing particularly when sufficiently strong metal-substrate interactions\nare employed, reducing surface roughness, achieving larger flat surface areas,\nmerging and smoothing islands, and decreasing defect density...", "AI": {"tldr": "Kinetic Monte Carlo simulations show that substrate interaction strength and thermal annealing can control thin film morphology (2D vs 3D growth) in six fcc metals, enabling optimization for interconnect and catalytic applications.", "motivation": "Precise control over thin film morphology is critical for optimizing material properties in technological applications like CMOS interconnects and catalysis, where growth mode determines key functional properties.", "method": "Extensive kinetic Monte Carlo simulations on six fcc metals (Ag, Au, Cu, Ni, Pd, Pt) growing in (111) direction, varying substrate-metal interaction strengths by modifying activation energies for migration, combined with thermal vacuum annealing within BEOL thermal budget.", "result": "Modulation of substrate interaction strength effectively promotes island formation or layer-by-layer growth. Au, Pd and Pt show highest sensitivity. Strong interactions decrease RMS roughness, substrate exposure, island number and aspect ratios, while increasing flat surface areas and coordination numbers. Thermal annealing further improves interconnect metrics when combined with strong interactions.", "conclusion": "Substrate interaction strength control combined with thermal annealing provides effective strategies for morphology control in metal thin films, enabling optimization for specific applications by overcoming limitations in achieving desired surface characteristics."}}
{"id": "2508.21552", "pdf": "https://arxiv.org/pdf/2508.21552", "abs": "https://arxiv.org/abs/2508.21552", "authors": ["Zolt\u00e1n M. Balogh", "Alexandru Krist\u00e1ly"], "title": "Sharp stability in hypercontractivity estimates and logarithmic Sobolev inequalities", "categories": ["math.AP"], "comment": "28 pages", "summary": "We prove stability results in hypercontractivity estimates for the Hopf--Lax\nsemigroup in $\\mathbb R^n$ and apply them to deduce stability results for the\nEuclidean $L^p$-logarithmic Sobolev inequality for any $p>1$. As a main tool,\nwe use recent stability results for the Pr\\'ekopa--Leindler inequality, due to\nB\\\"or\\\"oczky and De (2021), Figalli and Ramos (2024) and Figalli, van Hintum,\nand Tiba (2025). Under mild assumptions on the functions, most of our stability\nresults turn out to be sharp, as they are reflected in the optimal exponent\n$1/2$ both in the hypercontractivity and $L^p$-logarithmic Sobolev deficits,\nrespectively. This approach also works for establishing stability of Gaussian\nhypercontractivity estimates and Gaussian logarithmic Sobolev inequality,\nrespectively.", "AI": {"tldr": "Stability analysis for hypercontractivity and logarithmic Sobolev inequalities using Hopf-Lax semigroup and Pr\u00e9kopa-Leindler inequality stability results, achieving sharp optimal exponent 1/2.", "motivation": "To establish stability results in hypercontractivity estimates and extend them to prove stability for Euclidean L^p-logarithmic Sobolev inequalities, building on recent advances in Pr\u00e9kopa-Leindler inequality stability.", "method": "Using the Hopf-Lax semigroup in R^n and applying recent stability results for the Pr\u00e9kopa-Leindler inequality from multiple sources (B\u00f6r\u00f6czky & De 2021, Figalli & Ramos 2024, Figalli et al. 2025) under mild function assumptions.", "result": "Proved sharp stability results with optimal exponent 1/2 in both hypercontractivity and L^p-logarithmic Sobolev deficits. The approach also successfully establishes stability for Gaussian hypercontractivity and logarithmic Sobolev inequality.", "conclusion": "The method provides sharp stability bounds for fundamental inequalities in analysis, demonstrating the effectiveness of combining Hopf-Lax semigroup techniques with recent Pr\u00e9kopa-Leindler stability results across both Euclidean and Gaussian settings."}}
{"id": "2508.21653", "pdf": "https://arxiv.org/pdf/2508.21653", "abs": "https://arxiv.org/abs/2508.21653", "authors": ["Gaurav Mittal"], "title": "Analogy between Learning With Error Problem and Ill-Posed Inverse Problems", "categories": ["math.NA", "cs.CR", "cs.NA", "94A60, 65J22"], "comment": null, "summary": "In this work, we unveil an analogy between well-known lattice based learning\nwith error problem and ill-posed inverse problems. We show that LWE problem is\na structured inverse problem. Further, we propose a symmetric encryption scheme\nbased on ill-posed problems and thoroughly discuss its security. Finally, we\npropose a public key encryption scheme based on our symmetric encryption scheme\nand CRYSTALS-Kyber KEM (key encapsulation mechanism) and discuss its security.", "AI": {"tldr": "LWE problem is analogous to ill-posed inverse problems, enabling new encryption schemes based on this connection.", "motivation": "To establish a connection between lattice-based learning with error (LWE) problems and ill-posed inverse problems, and leverage this analogy to develop new encryption schemes.", "method": "Demonstrated that LWE is a structured inverse problem, proposed a symmetric encryption scheme based on ill-posed problems, and extended it to a public key encryption scheme using CRYSTALS-Kyber KEM.", "result": "Successfully established the analogy between LWE and ill-posed inverse problems, and developed both symmetric and public key encryption schemes with security analysis.", "conclusion": "The work provides a novel perspective on LWE problems through the lens of inverse problems, offering new cryptographic constructions with potential security benefits."}}
{"id": "2508.21663", "pdf": "https://arxiv.org/pdf/2508.21663", "abs": "https://arxiv.org/abs/2508.21663", "authors": ["Ardavan Mehdizadeh", "Peter Schindler"], "title": "Surface Stability Modeling with Universal Machine Learning Interatomic Potentials: A Comprehensive Cleavage Energy Benchmarking Study", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": "70 pages total (main paper + supplementary information), 4 figures in\n  main text, multiple supplementary figures and tables", "summary": "Machine learning interatomic potentials (MLIPs) have revolutionized\ncomputational materials science by bridging the gap between quantum mechanical\naccuracy and classical simulation efficiency, enabling unprecedented\nexploration of materials properties across the periodic table. Despite their\nremarkable success in predicting bulk properties, no systematic evaluation has\nassessed how well these universal MLIPs (uMLIPs) can predict cleavage energies,\na critical property governing fracture, catalysis, surface stability, and\ninterfacial phenomena. Here, we present a comprehensive benchmark of 19\nstate-of-the-art uMLIPs for cleavage energy prediction using our previously\nestablished density functional theory (DFT) database of 36,718 slab structures\nspanning elemental, binary, and ternary metallic compounds. We evaluate diverse\narchitectural paradigms, analyzing their performance across chemical\ncompositions, crystal systems, thickness, and surface orientations. Our results\nreveal that training data composition dominates architectural sophistication:\nmodels trained on the Open Materials 2024 (OMat24) dataset, which emphasizes\nnon-equilibrium configurations, achieve mean absolute percentage errors below\n6% and correctly identify the thermodynamically most stable surface\nterminations in 87% of cases, without any explicit surface energy training. In\ncontrast, architecturally identical models trained on equilibrium-only datasets\nshow five-fold higher errors, while models trained on surface-adsorbate data\nfail catastrophically with a 17-fold degradation. Remarkably, simpler\narchitectures trained on appropriate data achieve comparable accuracy to\ncomplex transformers while offering 10-100x computational speedup. These\nfindings show that the community should focus on strategic training data\ngeneration that captures the relevant physical phenomena.", "AI": {"tldr": "Systematic benchmark reveals that training data composition, not architectural complexity, is the key factor for accurate cleavage energy prediction in universal machine learning interatomic potentials. Models trained on non-equilibrium configurations achieve 6% error while equilibrium-only trained models show 5x higher errors.", "motivation": "Despite MLIPs' success in predicting bulk properties, there has been no systematic evaluation of their ability to predict cleavage energies - a critical property for fracture, catalysis, surface stability, and interfacial phenomena.", "method": "Comprehensive benchmark of 19 state-of-the-art universal MLIPs using a DFT database of 36,718 slab structures across elemental, binary, and ternary metallic compounds. Evaluated diverse architectural paradigms across chemical compositions, crystal systems, thickness, and surface orientations.", "result": "Training data composition dominates performance: OMat24-trained models achieve <6% MAPE and identify most stable surfaces in 87% of cases without explicit training. Equilibrium-only trained models show 5x higher errors. Simpler architectures with appropriate data match complex transformers' accuracy with 10-100x speedup.", "conclusion": "The community should focus on strategic training data generation that captures relevant physical phenomena rather than architectural complexity, as data quality significantly outperforms model sophistication for cleavage energy prediction."}}
{"id": "2508.21605", "pdf": "https://arxiv.org/pdf/2508.21605", "abs": "https://arxiv.org/abs/2508.21605", "authors": ["Vincent Boulard", "Amaury Hayat"], "title": "F-equivalence for parabolic systems and applications to the stabilization of nonlinear PDE", "categories": ["math.AP", "93D15, 35K58"], "comment": null, "summary": "We consider the $F$-equivalence problem for parabolic systems: under which\nconditions a control system, governed by a parabolic operator $A$ and a control\noperator $B$, can be made equivalent to an arbitrarily exponentially stable\nevolution system through an appropriate control feedback law? While this\nproblem has been resolved for finite-dimensional systems fifty years ago, good\nconditions for infinite-dimensional systems remain a challenge, especially for\nsystems in spatial dimension larger than one. Our main result establishes\noptimal conditions for the existence of an $F$-equivalence pair $(T,K)$ for a\ngiven parabolic control system $(A,B)$. We introduce an extended framework for\n$F$-equivalence of parabolic operators, addressing key limitations of existing\napproaches, and we prove that the pair $(T,K)$ is unique if and only if $(A,B)$\nis approximately controllable. As a consequence, this provides a method to\nconstruct feedback operators for the rapid stabilization of semilinear\nparabolic systems, possibly multi-dimensional in space. We provide several\nillustrative examples, including the rapid stabilization of the heat equation,\nthe Kuramoto-Sivashinsky equation, the Navier-Stokes equations and the\nquasilinear heat equation.", "AI": {"tldr": "Optimal conditions for F-equivalence of parabolic control systems, enabling rapid stabilization through unique feedback operators for multi-dimensional systems.", "motivation": "Address the challenge of finding good conditions for F-equivalence in infinite-dimensional parabolic systems, especially in spatial dimensions larger than one, which remains unresolved despite being solved for finite-dimensional systems 50 years ago.", "method": "Introduce an extended framework for F-equivalence of parabolic operators, establish optimal conditions for existence of F-equivalence pair (T,K), and prove uniqueness when the system is approximately controllable.", "result": "Main result provides optimal conditions for existence of F-equivalence pair, with uniqueness guaranteed for approximately controllable systems, enabling construction of feedback operators for rapid stabilization.", "conclusion": "The framework allows rapid stabilization of various semilinear parabolic systems including heat equation, Kuramoto-Sivashinsky equation, Navier-Stokes equations, and quasilinear heat equation in multi-dimensional spaces."}}
{"id": "2508.21659", "pdf": "https://arxiv.org/pdf/2508.21659", "abs": "https://arxiv.org/abs/2508.21659", "authors": ["Takuya Tsuchiya", "Makoto Nakamura"], "title": "Quantitative evaluations of stability and convergence for solutions of semilinear Klein--Gordon equation", "categories": ["math.NA", "cs.NA", "math.AP", "quant-ph"], "comment": "7 pages, 4 figures, 2 tables", "summary": "We perform some simulations of the semilinear Klein--Gordon equation with a\npower-law nonlinear term and propose each of the quantitative evaluation\nmethods for the stability and convergence of numerical solutions. We also\ninvestigate each of the thresholds in the methods by varying the amplitude of\nthe initial value and the mass, and propose appropriate values.", "AI": {"tldr": "Simulation study of semilinear Klein-Gordon equation with power-law nonlinearity, proposing quantitative evaluation methods for stability and convergence of numerical solutions, and investigating thresholds through amplitude and mass variations.", "motivation": "To develop reliable quantitative evaluation methods for assessing the stability and convergence of numerical solutions to the semilinear Klein-Gordon equation with power-law nonlinear terms, which is important for accurate numerical simulations in physics and engineering applications.", "method": "Performed simulations of the semilinear Klein-Gordon equation with power-law nonlinearity, varied the amplitude of initial values and mass parameters to investigate thresholds, and proposed quantitative evaluation methods for stability and convergence analysis.", "result": "Developed quantitative evaluation methods for stability and convergence assessment, identified thresholds through systematic parameter variation studies, and proposed appropriate values for these thresholds based on simulation results.", "conclusion": "The study successfully established quantitative evaluation frameworks for numerical solution analysis of semilinear Klein-Gordon equations, providing practical threshold values that can guide future numerical simulations and ensure solution reliability."}}
{"id": "2508.21729", "pdf": "https://arxiv.org/pdf/2508.21729", "abs": "https://arxiv.org/abs/2508.21729", "authors": ["Yannic Rath", "Massimo Bortone", "George H. Booth"], "title": "Bayesian perspectives for quantum states and application to ab initio quantum chemistry", "categories": ["cond-mat.str-el", "physics.chem-ph", "physics.comp-ph", "quant-ph"], "comment": "To appear in \"Machine Learning in Condensed Matter Physics -\n  Significance, Challenges, and Future Directions\", a Springer Series in\n  Solid-State Sciences", "summary": "The quantum many-electron problem is not just at the heart of condensed\nmatter phenomena, but also essential for first-principles simulation of\nchemical phenomena. Strong correlation in chemical systems are prevalent and\npresent a formidable challenge in the simulation of these systems, while\npredictive phenomena in this domain often also requires a demanding level of\naccuracy to inform chemical behavior. Efficient representations of the\nmany-electron states of chemical systems are therefore also being inspired by\nmachine learning principles to provide an alternative to established\napproaches. In this chapter, we review recent progress in this endeavor for\nquantum chemical problems represented in second quantization, and the\nparticular challenges present in this field. In particular, we focus on the\napplication of Gaussian Process States emerging from efficient representations\nof the many-body wavefunction with rigorous Bayesian modeling frameworks,\nallowing for the unification of multiple paradigms under a common umbrella. We\nshow how such models (and other representations derived from machine learning)\ncan be used as novel tools to compute ab initio chemical properties, while in\nturn also informing the design of machine learning models to extract\ncorrelation patterns in classical data.", "AI": {"tldr": "Review of machine learning-inspired approaches for quantum chemical simulations, focusing on Gaussian Process States for efficient many-electron wavefunction representation and Bayesian modeling frameworks.", "motivation": "Strong electron correlation in chemical systems presents challenges for accurate simulation, requiring new efficient representations beyond traditional methods.", "method": "Application of Gaussian Process States derived from machine learning principles to represent many-body wavefunctions using Bayesian modeling frameworks in second quantization.", "result": "Development of novel tools for computing ab initio chemical properties and informing machine learning models to extract correlation patterns from classical data.", "conclusion": "Machine learning-inspired representations provide promising alternatives to established quantum chemical approaches, unifying multiple paradigms under Bayesian frameworks for improved accuracy in strongly correlated systems."}}
{"id": "2508.21822", "pdf": "https://arxiv.org/pdf/2508.21822", "abs": "https://arxiv.org/abs/2508.21822", "authors": ["Carlos M. Guzm\u00e1n", "Suerlan Silva", "Gabriel Pe\u00e7anha"], "title": "Scattering for the non-radial inhomogeneous Hartree equation with a potential", "categories": ["math.AP"], "comment": "20 pages", "summary": "In this work, we consider the focusing generalized inhomogeneous Hartree\nequation with potential \\[ i u_t + \\Delta u - V(x)u + \\left(I_{\\gamma} *\n|x|^{-b}|u|^{p}\\right)|x|^{-b}|u|^{p-2}u = 0, \\] where $0<\\gamma<3$ and\n$0<b<\\frac{1+\\gamma}{2}$. We prove scattering in the intercritical case for\nnonradial initial data, under a mass-potential condition that generalizes the\nusual mass-energy threshold. The main new points compared to previous works are\nthe inhomogeneous weight $|x|^{-b}$ and the presence of a potential $V$, which\nlead us to study the perturbed operator $-\\Delta + V$.\n  Our proof follows the general strategy of Murphy, but we need to adapt\nseveral steps to deal with the weight and the potential. We use Tao's\nscattering criterion together with localized Morawetz estimates in this\nsetting. As a preliminary step, we establish global well-posedness for small\ndata, which, in the presence of $V$, requires careful analysis using\nappropriate admissible Strichartz pairs.", "AI": {"tldr": "Scattering proof for generalized inhomogeneous Hartree equation with potential and weight, extending previous results to nonradial data under mass-potential condition.", "motivation": "Extend scattering theory to include inhomogeneous weight |x|^{-b} and potential V(x) in Hartree equation, generalizing mass-energy threshold condition.", "method": "Adapt Murphy's strategy with Tao's scattering criterion and localized Morawetz estimates. Establish global well-posedness for small data using admissible Strichartz pairs.", "result": "Proved scattering in intercritical case for nonradial initial data under generalized mass-potential condition.", "conclusion": "Successfully handled inhomogeneous weight and potential perturbations, extending scattering results to more general Hartree equations."}}
{"id": "2508.21664", "pdf": "https://arxiv.org/pdf/2508.21664", "abs": "https://arxiv.org/abs/2508.21664", "authors": ["Sagy Ephrati", "James Woodfield"], "title": "Trajectory learning for ensemble forecasts via the continuous ranked probability score: a Lorenz '96 case study", "categories": ["math.NA", "cs.LG", "cs.NA", "65M75, 37M05"], "comment": "19 pages, 9 figures. All comments are welcome!", "summary": "This paper demonstrates the feasibility of trajectory learning for ensemble\nforecasts by employing the continuous ranked probability score (CRPS) as a loss\nfunction. Using the two-scale Lorenz '96 system as a case study, we develop and\ntrain both additive and multiplicative stochastic parametrizations to generate\nensemble predictions. Results indicate that CRPS-based trajectory learning\nproduces parametrizations that are both accurate and sharp. The resulting\nparametrizations are straightforward to calibrate and outperform\nderivative-fitting-based parametrizations in short-term forecasts. This\napproach is particularly promising for data assimilation applications due to\nits accuracy over short lead times.", "AI": {"tldr": "CRPS-based trajectory learning enables accurate ensemble forecasts using stochastic parametrizations in Lorenz '96 system", "motivation": "To develop effective ensemble forecasting methods using trajectory learning with continuous ranked probability score as loss function for improved short-term predictions", "method": "Employed CRPS as loss function to train both additive and multiplicative stochastic parametrizations in two-scale Lorenz '96 system for ensemble predictions", "result": "CRPS-based trajectory learning produces accurate and sharp parametrizations that outperform derivative-fitting-based approaches in short-term forecasts and are easy to calibrate", "conclusion": "This approach shows strong promise for data assimilation applications due to its accuracy over short lead times and effective ensemble forecasting capabilities"}}
{"id": "2508.21158", "pdf": "https://arxiv.org/pdf/2508.21158", "abs": "https://arxiv.org/abs/2508.21158", "authors": ["Phanuel Mariano", "Jing Wang"], "title": "Survival probability for jump processes in unbounded domains on metric measure spaces", "categories": ["math.PR", "math.AP", "math.SP"], "comment": "20 pages, 3 figures", "summary": "We study the large time behavior of the survival probability\n$\\mathbb{P}_x\\left(\\tau_D>t\\right)$ for symmetric jump processes in unbounded\ndomains with a positive bottom of the spectrum. We prove asymptotic upper and\nlower bounds with explicit constants in terms of the bottom of the spectrum\n$\\lambda(D)$. Our main result applies to symmetric jump processes in general\nmetric measure spaces. For $\\alpha$-stable processes in unbounded uniformly\n$C^{1,1}$ domains, our results provide a probabilistic interpretation and an\nequivalent geometric condition for $\\lambda(D)>0$. In the case of increasing\nhorn-shaped domains, the exponential rate of decay for the survival probability\nis sharp. We also present examples of unbounded domains where our results\napply.", "AI": {"tldr": "Analysis of survival probability decay rates for symmetric jump processes in unbounded domains with positive spectrum bottom, providing probabilistic interpretation and geometric conditions.", "motivation": "To understand the large time behavior of survival probabilities in unbounded domains for symmetric jump processes, particularly establishing connections between spectral properties and geometric domain characteristics.", "method": "Proved asymptotic upper and lower bounds with explicit constants using the bottom of spectrum \u03bb(D), applied to symmetric jump processes in general metric measure spaces, with specific focus on \u03b1-stable processes in uniformly C\u00b9\u00b9 domains.", "result": "Established probabilistic interpretation and equivalent geometric condition for \u03bb(D)>0, demonstrated sharp exponential decay rates in horn-shaped domains, and provided examples of applicable unbounded domains.", "conclusion": "The study successfully links spectral properties with geometric domain characteristics for symmetric jump processes, providing explicit bounds and interpretations that advance understanding of survival probability decay in unbounded settings."}}
{"id": "2508.21765", "pdf": "https://arxiv.org/pdf/2508.21765", "abs": "https://arxiv.org/abs/2508.21765", "authors": ["Mohamed El Guide", "Anas El Hachimi", "Khalide Jbilou", "Lothar Reichel"], "title": "Low-Rank Regularized Convex-Non-Convex Problems for Image Segmentation or Completion", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This work proposes a novel convex-non-convex formulation of the image\nsegmentation and the image completion problems. The proposed approach is based\non the minimization of a functional involving two distinct regularization\nterms: one promotes low-rank structure in the solution, while the other one\nenforces smoothness. To solve the resulting optimization problem, we employ the\nalternating direction method of multipliers (ADMM). A detailed convergence\nanalysis of the algorithm is provided, and the performance of the methods is\ndemonstrated through a series of numerical experiments.", "AI": {"tldr": "Convex-non-convex formulation for image segmentation and completion using low-rank and smoothness regularization, solved with ADMM", "motivation": "To develop an effective approach for image segmentation and completion problems that combines both low-rank structure promotion and smoothness enforcement in a unified optimization framework", "method": "Proposes a convex-non-convex functional minimization with two regularization terms (low-rank and smoothness), solved using alternating direction method of multipliers (ADMM)", "result": "The method demonstrates performance through numerical experiments and includes detailed convergence analysis of the algorithm", "conclusion": "The proposed convex-non-convex formulation with ADMM provides an effective solution for image segmentation and completion tasks by leveraging both low-rank and smoothness properties"}}
{"id": "2508.21269", "pdf": "https://arxiv.org/pdf/2508.21269", "abs": "https://arxiv.org/abs/2508.21269", "authors": ["Feng Dai", "Eero Saksman", "Dachun Yang", "Wen Yuan", "Yangyang Zhang"], "title": "Fractional Heat Semigroup Characterization of Distances from Functions in Lipschitz Spaces to Their Subspaces", "categories": ["math.FA", "math.AP", "math.CA", "Primary 46E35, Secondary 26A16, 35K08, 42C40, 42E35"], "comment": "46 pages; Submitted", "summary": "Let $\\Lambda_s$ denote the inhomogeneous Lipschitz space of order\n$s\\in(0,\\infty)$ on $\\mathbb{R}^n$. This article characterizes the distance\n$d(f, V)_{\\Lambda_s}: = \\inf_{g\\in V} \\|f-g\\|_{\\Lambda_s}$ from a function\n$f\\in \\Lambda_s$ to a non-dense subspace $V\\subset \\Lambda_s$ via the\nfractional semigroup $\\{T_{\\alpha, t}: =e^{-t (-\\Delta)^{\\alpha/2}}: t\\in (0,\n\\infty)\\}$ for any $\\alpha\\in(0,\\infty)$. Given an integer $ r >s/\\alpha$, a\nuniformly bounded continuous function $f$ on $\\mathbb{R}^n$ belongs to the\nspace $\\Lambda_s$ if and only if there exists a constant $\\lambda\\in(0,\\infty)$\nsuch that \\begin{align*} \\left|(-\\Delta)^{\\frac {\\alpha r}2} (T_{\\alpha,\nt^\\alpha } f)(x) \\right|\\leq \\lambda t^{s -r\\alpha }\\ \\ \\text{for any\n$x\\in\\mathbb{R}^n$ and $t\\in (0, 1]$}.\\end{align*} The least such constant is\ndenoted by $\\lambda_{ \\alpha, r, s}(f)$. For each $f\\in \\Lambda_s$ and\n$0<\\varepsilon< \\lambda_{\\alpha,r, s}(f)$, let $$ D_{\\alpha,\nr}(s,f,\\varepsilon):=\\left\\{ (x,t)\\in \\mathbb{R}^n\\times (0,1]:\\ \\left|\n(-\\Delta)^{\\frac {\\alpha r}2} (T_{\\alpha, t^\\alpha} f)(x) \\right|> \\varepsilon\nt^{s -r \\alpha }\\right\\}$$ be the set of ``bad'' points. To quantify its size,\nwe introduce a class of extended nonnegative \\emph{admissible set functions}\n$\\nu$ on the Borel $\\sigma$-algebra $\\mathcal{B}(\\mathbb{R}^n\\times [0, 1])$\nand define, for any admissible function $\\nu$, the \\emph{critical index} $\n\\varepsilon_{\\alpha, r, s,\\nu}(f):=\\inf\\{\\varepsilon\\in(0,\\infty):\\\n\\nu(D_{\\alpha, r}(s,f,\\varepsilon))<\\infty\\}.$ Our result shows that, for a\nbroad class of subspaces $V\\subset \\Lambda_s$, including intersections of\n$\\Lambda_s$ with Sobolev, Besov, Triebel--Lizorkin, and Besov-type spaces,\nthere exists an admissible function $\\nu$ depending on $V$ such that\n$\\varepsilon_{\\alpha, r, s,\\nu}(f)\\sim \\mathrm{dist}(f, V)_{\\Lambda_s}.$", "AI": {"tldr": "Characterizes distance from functions in inhomogeneous Lipschitz spaces to non-dense subspaces using fractional semigroups and critical indices from 'bad' point sets.", "motivation": "To develop a quantitative method for measuring the distance between functions in Lipschitz spaces and various subspaces (Sobolev, Besov, etc.) using fractional semigroup techniques.", "method": "Uses fractional semigroup operators and defines 'bad' point sets D_\u03b1,r(s,f,\u03b5) where fractional derivatives exceed threshold. Introduces admissible set functions \u03bd to measure these sets and defines critical index \u03b5_\u03b1,r,s,\u03bd(f).", "result": "Shows that for broad classes of subspaces V \u2282 \u039b_s, there exists an admissible function \u03bd such that the critical index \u03b5_\u03b1,r,s,\u03bd(f) is equivalent to the distance dist(f, V)_\u039b_s.", "conclusion": "Provides a novel characterization of distances in Lipschitz spaces through fractional semigroup analysis and critical indices, applicable to various function space intersections including Sobolev and Besov spaces."}}
{"id": "2508.21165", "pdf": "https://arxiv.org/pdf/2508.21165", "abs": "https://arxiv.org/abs/2508.21165", "authors": ["Natalia L. Rubio", "Eric F. Darve", "Alison L. Marsden"], "title": "Data-Driven Bifurcation Handling in Physics-Based Reduced-Order Vascular Hemodynamic Models", "categories": ["cs.CE", "cs.LG", "cs.NA", "math.NA", "76Z05", "J.2"], "comment": "32 pages, 13 figures", "summary": "Three-dimensional (3D) finite-element simulations of cardiovascular flows\nprovide high-fidelity predictions to support cardiovascular medicine, but their\nhigh computational cost limits clinical practicality. Reduced-order models\n(ROMs) offer computationally efficient alternatives but suffer reduced\naccuracy, particularly at vessel bifurcations where complex flow physics are\ninadequately captured by standard Poiseuille flow assumptions. We present an\nenhanced numerical framework that integrates machine learning-predicted\nbifurcation coefficients into zero-dimensional (0D) hemodynamic ROMs to improve\naccuracy while maintaining computational efficiency. We develop a\nresistor-resistor-inductor (RRI) model that uses neural networks to predict\npressure-flow relationships from bifurcation geometry, incorporating linear and\nquadratic resistances along with inductive effects. The method employs\nnon-dimensionalization to reduce training data requirements and apriori flow\nsplit prediction for improved bifurcation characterization. We incorporate the\nRRI model into a 0D model using an optimization-based solution strategy. We\nvalidate the approach in isolated bifurcations and vascular trees, across\nReynolds numbers from 0 to 5,500, defining ROM accuracy by comparison to 3D\nfinite element simulation. Results demonstrate substantial accuracy\nimprovements: averaged across all trees and Reynolds numbers, the RRI method\nreduces inlet pressure errors from 54 mmHg (45%) for standard 0D models to 25\nmmHg (17%), while a simplified resistor-inductor (RI) variant achieves 31 mmHg\n(26%) error. The enhanced 0D models show particular effectiveness at high\nReynolds numbers and in extensive vascular networks. This hybrid numerical\napproach enables accurate, real-time hemodynamic modeling for clinical decision\nsupport, uncertainty quantification, and digital twins in cardiovascular\nbiomedical engineering.", "AI": {"tldr": "Machine learning-enhanced 0D hemodynamic model improves accuracy at vessel bifurcations while maintaining computational efficiency for cardiovascular flow simulations.", "motivation": "3D finite-element simulations are computationally expensive for clinical use, while standard reduced-order models lack accuracy at vessel bifurcations where complex flow physics occur.", "method": "Developed a resistor-resistor-inductor (RRI) model using neural networks to predict pressure-flow relationships from bifurcation geometry, incorporating non-dimensionalization and flow split prediction, integrated into 0D models with optimization-based solution.", "result": "Substantial accuracy improvements: RRI method reduced inlet pressure errors from 54 mmHg (45%) to 25 mmHg (17%) across various Reynolds numbers and vascular trees compared to 3D simulations.", "conclusion": "The hybrid machine learning-enhanced 0D modeling approach enables accurate, real-time hemodynamic modeling suitable for clinical decision support and cardiovascular biomedical engineering applications."}}
{"id": "2508.21189", "pdf": "https://arxiv.org/pdf/2508.21189", "abs": "https://arxiv.org/abs/2508.21189", "authors": ["Chris Cama\u00f1o", "Ethan N. Epperly", "Raphael A. Meyer", "Joel A. Tropp"], "title": "Faster Linear Algebra Algorithms with Structured Random Matrices", "categories": ["cs.DS", "cs.NA", "math.NA", "65F55, 65F20, 68W20", "G.1.3"], "comment": null, "summary": "To achieve the greatest possible speed, practitioners regularly implement\nrandomized algorithms for low-rank approximation and least-squares regression\nwith structured dimension reduction maps. Despite significant research effort,\nbasic questions remain about the design and analysis of randomized linear\nalgebra algorithms that employ structured random matrices.\n  This paper develops a new perspective on structured dimension reduction,\nbased on the oblivious subspace injection (OSI) property. The OSI property is a\nrelatively weak assumption on a random matrix that holds when the matrix\npreserves the length of vectors on average and, with high probability, does not\nannihilate any vector in a low-dimensional subspace. With the OSI abstraction,\nthe analysis of a randomized linear algebra algorithm factors into two parts:\n(i) proving that the algorithm works when implemented with an OSI; and (ii)\nproving that a given random matrix model has the OSI property.\n  This paper develops both parts of the program. First, it analyzes standard\nrandomized algorithms for low-rank approximation and least-squares regression\nunder the OSI assumption. Second, it identifies many examples of OSIs,\nincluding random sparse matrices, randomized trigonometric transforms, and\nrandom matrices with tensor product structure. These theoretical results imply\nfaster, near-optimal runtimes for several fundamental linear algebra tasks. The\npaper also provides guidance on implementation, along with empirical evidence\nthat structured random matrices offer exemplary performance for a range of\nsynthetic problems and contemporary scientific applications.", "AI": {"tldr": "This paper introduces the Oblivious Subspace Injection (OSI) property as a unified framework for analyzing structured random matrices in randomized linear algebra algorithms, providing theoretical guarantees and practical implementations for faster low-rank approximation and least-squares regression.", "motivation": "Despite extensive research on structured random matrices for randomized linear algebra, basic questions remain about their design and analysis. Practitioners need faster, near-optimal algorithms for fundamental linear algebra tasks using structured dimension reduction maps.", "method": "Develops the OSI property framework that factors analysis into: (1) proving algorithms work with OSI matrices, and (2) proving specific random matrix models satisfy OSI. Analyzes standard randomized algorithms under OSI assumption and identifies various OSI examples including sparse matrices, trigonometric transforms, and tensor product structures.", "result": "Theoretical results show faster, near-optimal runtimes for fundamental linear algebra tasks. Provides implementation guidance and empirical evidence demonstrating exemplary performance for synthetic problems and scientific applications using structured random matrices.", "conclusion": "The OSI framework provides a unified approach to analyze structured random matrices, enabling faster randomized linear algebra algorithms with theoretical guarantees and practical performance benefits across various applications."}}
{"id": "2508.21642", "pdf": "https://arxiv.org/pdf/2508.21642", "abs": "https://arxiv.org/abs/2508.21642", "authors": ["P. Jameson Graber", "Kyle Rosengartner"], "title": "Mean Field Games of Controls with Dirichlet \\& Neumann Boundary Conditions", "categories": ["math.OC", "math.AP"], "comment": null, "summary": "In a mean field game of controls, a large population of identical players\nseek to minimize a cost that depends on the joint distribution of the states of\nthe players and their controls. We consider the classes of mean field games of\ncontrols in which the value function and the distribution of player states\nsatisfy either Dirichlet or Neumann boundary conditions. We prove that such\nsystems are well-posed either with sufficient smallness conditions or in the\ncase of monotone couplings.", "AI": {"tldr": "Analysis of mean field games with controls under Dirichlet/Neumann boundary conditions, proving well-posedness with smallness conditions or monotone couplings", "motivation": "To establish rigorous mathematical foundations for mean field games of controls with boundary conditions, addressing the challenge of analyzing systems where player costs depend on joint state and control distributions", "method": "Mathematical analysis of mean field game systems with Dirichlet and Neumann boundary conditions, employing techniques to prove well-posedness through smallness conditions and monotonicity assumptions", "result": "Proved that such mean field game systems are well-posed either when sufficient smallness conditions are satisfied or in cases with monotone couplings", "conclusion": "The paper provides important theoretical guarantees for mean field games of controls with boundary conditions, establishing conditions under which these complex systems have well-defined solutions"}}
{"id": "2508.21249", "pdf": "https://arxiv.org/pdf/2508.21249", "abs": "https://arxiv.org/abs/2508.21249", "authors": ["Mohammad Amin Nabian", "Sanjay Choudhry"], "title": "A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "physics.flu-dyn"], "comment": null, "summary": "The computational cost associated with high-fidelity CFD simulations remains\na significant bottleneck in the automotive design and optimization cycle. While\nML-based surrogate models have emerged as a promising alternative to accelerate\naerodynamic predictions, the field is characterized by a diverse and rapidly\nevolving landscape of specialized neural network architectures, with no single\nmodel demonstrating universal superiority. This paper introduces a novel\nmeta-learning framework that leverages this architectural diversity as a\nstrength. We propose a Mixture of Experts (MoE) model that employs a dedicated\ngating network to dynamically and optimally combine the predictions from three\nheterogeneous, state-of-the-art surrogate models: DoMINO, a decomposable\nmulti-scale neural operator; X-MeshGraphNet, a scalable multi-scale graph\nneural network; and FigConvNet, a factorized implicit global convolution\nnetwork. The gating network learns a spatially-variant weighting strategy,\nassigning credibility to each expert based on its localized performance in\npredicting surface pressure and wall shear stress fields. To prevent model\ncollapse and encourage balanced expert contributions, we integrate an entropy\nregularization term into the training loss function. The entire system is\ntrained and validated on the DrivAerML dataset, a large-scale, public benchmark\nof high-fidelity CFD simulations for automotive aerodynamics. Quantitative\nresults demonstrate that the MoE model achieves a significant reduction in L-2\nprediction error, outperforming not only the ensemble average but also the most\naccurate individual expert model across all evaluated physical quantities. This\nwork establishes the MoE framework as a powerful and effective strategy for\ncreating more robust and accurate composite surrogate models by synergistically\ncombining the complementary strengths of specialized architectures.", "AI": {"tldr": "A meta-learning Mixture of Experts framework that combines three state-of-the-art CFD surrogate models (DoMINO, X-MeshGraphNet, FigConvNet) using a gating network to achieve superior aerodynamic prediction accuracy.", "motivation": "High computational cost of CFD simulations is a bottleneck in automotive design. While ML-based surrogates offer acceleration, no single architecture demonstrates universal superiority across diverse scenarios.", "method": "Proposes a Mixture of Experts model with a gating network that dynamically combines predictions from three heterogeneous neural networks. Uses entropy regularization to prevent model collapse and ensure balanced expert contributions. Trained on DrivAerML dataset.", "result": "Achieves significant reduction in L-2 prediction error, outperforming both ensemble average and the most accurate individual expert model across all evaluated physical quantities (surface pressure and wall shear stress fields).", "conclusion": "The MoE framework establishes an effective strategy for creating robust composite surrogate models by synergistically combining complementary strengths of specialized architectures in automotive aerodynamics."}}
{"id": "2508.21571", "pdf": "https://arxiv.org/pdf/2508.21571", "abs": "https://arxiv.org/abs/2508.21571", "authors": ["Bangti Jin", "Longjun Wu"], "title": "Convergence of Stochastic Gradient Methods for Wide Two-Layer Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": "24 pages", "summary": "Physics informed neural networks (PINNs) represent a very popular class of\nneural solvers for partial differential equations. In practice, one often\nemploys stochastic gradient descent type algorithms to train the neural\nnetwork. Therefore, the convergence guarantee of stochastic gradient descent is\nof fundamental importance. In this work, we establish the linear convergence of\nstochastic gradient descent / flow in training over-parameterized two layer\nPINNs for a general class of activation functions in the sense of high\nprobability. These results extend the existing result [18] in which gradient\ndescent was analyzed. The challenge of the analysis lies in handling the\ndynamic randomness introduced by stochastic optimization methods. The key of\nthe analysis lies in ensuring the positive definiteness of suitable Gram\nmatrices during the training. The analysis sheds insight into the dynamics of\nthe optimization process, and provides guarantees on the neural networks\ntrained by stochastic algorithms.", "AI": {"tldr": "Establishes linear convergence of stochastic gradient descent for over-parameterized two-layer Physics Informed Neural Networks (PINNs) with general activation functions, extending previous gradient descent results.", "motivation": "PINNs are popular neural solvers for PDEs, typically trained with stochastic gradient descent methods. However, convergence guarantees for stochastic optimization in PINNs were lacking compared to deterministic gradient descent.", "method": "Analyzed stochastic gradient descent/flow for over-parameterized two-layer PINNs, focusing on maintaining positive definiteness of Gram matrices during training to handle dynamic randomness from stochastic optimization.", "result": "Proved linear convergence in high probability for stochastic gradient descent in training PINNs with general activation functions, extending previous gradient descent convergence results.", "conclusion": "The analysis provides theoretical guarantees for stochastic optimization methods in PINNs, offering insights into optimization dynamics and ensuring neural networks trained by stochastic algorithms have convergence guarantees."}}
{"id": "2508.21667", "pdf": "https://arxiv.org/pdf/2508.21667", "abs": "https://arxiv.org/abs/2508.21667", "authors": ["Abhishek Setty"], "title": "Block Encoding of Sparse Matrices via Coherent Permutation", "categories": ["quant-ph", "cs.DS", "cs.NA", "math.NA"], "comment": null, "summary": "Block encoding of sparse matrices underpins powerful quantum algorithms such\nas quantum singular value transformation, Hamiltonian simulation, and quantum\nlinear solvers, but its efficient gate-level implementation for arbitrary\nsparse matrices remains a major challenge. We introduce a unified framework\nthat overcomes the key obstacles of multi-controlled X gates overhead,\namplitude reordering, and hardware connectivity, enabling efficient block\nencoding for arbitrary sparse matrices with explicit gate-level constructions.\nCentral to our approach are a novel connection with combinatorial optimization,\nwhich enables systematic assignment of control qubits to achieve\nnearest-neighbor connectivity, and coherent permutation operators that preserve\nsuperposition while enabling amplitude reordering. We demonstrate our methods\non structured sparse matrices, showing significant reductions in circuit depth\nand control overhead, thereby bridging the gap between theoretical formulations\nand practical circuit implementations for quantum algorithms.", "AI": {"tldr": "A unified framework for efficient block encoding of arbitrary sparse matrices using combinatorial optimization and coherent permutation operators to overcome key implementation challenges.", "motivation": "Block encoding of sparse matrices is crucial for quantum algorithms like singular value transformation and Hamiltonian simulation, but efficient gate-level implementations for arbitrary sparse matrices remain challenging due to multi-controlled X gates overhead, amplitude reordering issues, and hardware connectivity constraints.", "method": "Novel connection with combinatorial optimization for systematic control qubit assignment to achieve nearest-neighbor connectivity, combined with coherent permutation operators that preserve superposition while enabling amplitude reordering.", "result": "Significant reductions in circuit depth and control overhead for structured sparse matrices, providing explicit gate-level constructions that bridge theoretical formulations with practical circuit implementations.", "conclusion": "The framework enables efficient block encoding for arbitrary sparse matrices, overcoming key obstacles and making quantum algorithms more practical for real-world implementation."}}
