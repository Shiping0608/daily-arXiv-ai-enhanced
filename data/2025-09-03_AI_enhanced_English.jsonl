{"id": "2509.00193", "pdf": "https://arxiv.org/pdf/2509.00193", "abs": "https://arxiv.org/abs/2509.00193", "authors": ["Lise-Marie Imbert-G\u00e9rard"], "title": "A quasi-Trefftz space for a second order time-harmonic Maxwell's equation", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Quasi-Trefftz methods are a family of Discontinuous Galerkin methods relying\non equation-dependent function spaces. This work is the first study of the\nnotion of local Taylor-based polynomial quasi-Trefftz space for a system of\nPartial Differential Equations (PDEs). These discrete spaces are introduced\nhere for electro-magnetic wave propagation in inhomogeneous media, governed by\na second order formulation of Maxwell's equation with variable coefficients.\nThanks to an adequate Helmholtz decomposition for spaces of homogeneous\npolynomial vector fields, the outcome is the explicit dimension of the proposed\nquasi-Trefftz space as well as a procedure to construct quasi-Trefftz\nfunctions.", "AI": {"tldr": "First study of local Taylor-based polynomial quasi-Trefftz spaces for systems of PDEs, specifically for electromagnetic wave propagation in inhomogeneous media using second-order Maxwell's equations.", "motivation": "To develop quasi-Trefftz methods (a family of Discontinuous Galerkin methods) that rely on equation-dependent function spaces for solving systems of partial differential equations, particularly for electromagnetic applications with variable coefficients.", "method": "Uses local Taylor-based polynomial quasi-Trefftz spaces and an adequate Helmholtz decomposition for spaces of homogeneous polynomial vector fields to construct quasi-Trefftz functions.", "result": "Obtained explicit dimension of the proposed quasi-Trefftz space and developed a procedure to construct quasi-Trefftz functions for the second-order formulation of Maxwell's equations with variable coefficients.", "conclusion": "Successfully established the foundation for quasi-Trefftz methods applied to systems of PDEs, providing both theoretical dimension analysis and practical construction methods for electromagnetic wave propagation problems in inhomogeneous media."}}
{"id": "2509.00204", "pdf": "https://arxiv.org/pdf/2509.00204", "abs": "https://arxiv.org/abs/2509.00204", "authors": ["Silei Song", "Arash Fahim", "Michael Mascagni"], "title": "WoSNN: Stochastic Solver for PDEs with Machine Learning", "categories": ["math.NA", "cs.LG", "cs.NA", "math.PR", "68U01, 65N75", "G.3; G.1.8"], "comment": null, "summary": "Solving elliptic partial differential equations (PDEs) is a fundamental step\nin various scientific and engineering studies. As a classic stochastic solver,\nthe Walk-on-Spheres (WoS) method is a well-established and efficient algorithm\nthat provides accurate local estimates for PDEs. In this paper, by integrating\nmachine learning techniques with WoS and space discretization approaches, we\ndevelop a novel stochastic solver, WoS-NN. This new method solves elliptic\nproblems with Dirichlet boundary conditions, facilitating precise and rapid\nglobal solutions and gradient approximations. The method inherits excellent\ncharacteristics from the original WoS method, such as being meshless and robust\nto irregular regions. By integrating neural networks, WoS-NN also gives instant\nlocal predictions after training without re-sampling, which is especially\nsuitable for intense requests on a static region. A typical experimental result\ndemonstrates that the proposed WoS-NN method provides accurate field\nestimations, reducing errors by around $75\\%$ while using only $8\\%$ of path\nsamples compared to the conventional WoS method, which saves abundant\ncomputational time and resource consumption.", "AI": {"tldr": "WoS-NN integrates machine learning with Walk-on-Spheres method to solve elliptic PDEs with Dirichlet boundary conditions, achieving 75% error reduction using only 8% of path samples compared to traditional WoS.", "motivation": "To develop an efficient stochastic solver for elliptic PDEs that combines the strengths of traditional Walk-on-Spheres method with machine learning for faster and more accurate global solutions.", "method": "Integration of neural networks with Walk-on-Spheres method and space discretization approaches to create WoS-NN, a meshless method that works well with irregular regions.", "result": "WoS-NN provides accurate field estimations with 75% error reduction while using only 8% of path samples compared to conventional WoS method, saving computational time and resources.", "conclusion": "The proposed WoS-NN method successfully combines machine learning with traditional stochastic solvers to achieve superior performance in solving elliptic PDEs with significant computational efficiency gains."}}
{"id": "2509.00296", "pdf": "https://arxiv.org/pdf/2509.00296", "abs": "https://arxiv.org/abs/2509.00296", "authors": ["Andres Galindo-Olarte", "Zhichao Peng", "Jennifer K. Ryan"], "title": "Superconvergence Extraction of Upwind Discontinuous Galerkin Method Solving the Radiative Transfer Equation", "categories": ["math.NA", "cs.NA"], "comment": "29 pages, 4 figures", "summary": "We theoretically analyze the superconvergence of the upwind discontinuous\nGalerkin (DG) method for both the steady-state and time-dependent radiative\ntransfer equation (RTE), and apply the Smooth-Increasing Accuracy-Conserving\n(SIAC) filters to enhance the accuracy order. Direct application of SIAC\nfilters on low-dimensional macroscopic moments, often the quantities of\npractical interest, can effectively improve the approximation accuracy with\nmarginal computational overhead.\n  Using piecewise $k$-th order polynomials for the approximation and assuming\nconstant cross sections, we prove $(2k+2)$-th order superconvergence for the\nsteady-state problem at Radau points on each element and $(2k+1/2)$-th order\nsuperconvergence for the global $L^2$ and negative-order Sobolev norms for the\ntime-dependent problem.\n  Numerical experiments confirm the efficacy of the filtering, demonstrating\npost-filter convergence orders of $2k+2$ for steady-state and $2k+1$ for\ntime-dependent problems. More significantly, the SIAC filter delivers\nsubstantial gains in computational efficiency. For a time-dependent problem, we\nobserved an approximately $2.22 \\times$ accuracy improvement and a $19.94\n\\times$ reduction in computational time. For the steady-state problems, the\nfilter achieved a $4$--$9 \\times$ acceleration without any loss of accuracy.", "AI": {"tldr": "The paper analyzes superconvergence of upwind DG methods for radiative transfer equations and applies SIAC filters to enhance accuracy orders with minimal computational overhead, achieving significant efficiency gains.", "motivation": "To improve the accuracy and computational efficiency of discontinuous Galerkin methods for solving radiative transfer equations, particularly for low-dimensional macroscopic moments that are of practical interest.", "method": "Theoretical analysis of superconvergence properties combined with application of Smooth-Increasing Accuracy-Conserving (SIAC) filters on upwind discontinuous Galerkin methods for both steady-state and time-dependent radiative transfer equations.", "result": "Proved (2k+2)-th order superconvergence for steady-state problems and (2k+1/2)-th order for time-dependent problems. Numerical experiments confirmed post-filter convergence orders of 2k+2 (steady-state) and 2k+1 (time-dependent), with substantial computational efficiency improvements: 2.22\u00d7 accuracy improvement and 19.94\u00d7 time reduction for time-dependent problems, and 4-9\u00d7 acceleration for steady-state problems.", "conclusion": "SIAC filtering effectively enhances both accuracy and computational efficiency for DG methods in radiative transfer problems, providing substantial performance gains without accuracy loss, making it a valuable technique for practical applications."}}
{"id": "2509.00475", "pdf": "https://arxiv.org/pdf/2509.00475", "abs": "https://arxiv.org/abs/2509.00475", "authors": ["Guozhen Li", "Xiaoyue Li", "Xuerong Mao"], "title": "Development of numerical methods for nonlinear hybrid stochastic functional differential equations with infinite delay", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper focuses on explicit numerical approximations for nonlinear hybrid\nstochastic functional differential equations with infinite delay. Precisely,\nexplicit truncated Euler-Maruyama schemes are proposed, $2p$th $(p \\ge 1)$\nmoment boundedness and strong convergence of the numerical solutions are\nobtained. Under slightly stronger conditions, the $1/2$ order convergence rate\nis established. Furthermore, the exponential stability, including moment and\nalmost sure exponential stability, is examined. Finally, an example is provided\nto illustrate our results.", "AI": {"tldr": "Explicit truncated Euler-Maruyama schemes for nonlinear hybrid stochastic functional differential equations with infinite delay, achieving 2pth moment boundedness, strong convergence, and 1/2 order convergence rate with exponential stability analysis.", "motivation": "To develop explicit numerical approximations for complex nonlinear hybrid stochastic functional differential equations with infinite delay, which are challenging to solve analytically and require reliable computational methods.", "method": "Proposed explicit truncated Euler-Maruyama schemes, analyzed 2pth moment boundedness and strong convergence of numerical solutions, established 1/2 order convergence rate under stronger conditions, and examined exponential stability properties.", "result": "Successfully obtained 2pth moment boundedness and strong convergence of numerical solutions, achieved 1/2 order convergence rate, and demonstrated exponential stability including moment and almost sure exponential stability.", "conclusion": "The explicit truncated Euler-Maruyama schemes provide effective numerical solutions for nonlinear hybrid stochastic functional differential equations with infinite delay, with proven convergence properties and stability guarantees."}}
{"id": "2509.00292", "pdf": "https://arxiv.org/pdf/2509.00292", "abs": "https://arxiv.org/abs/2509.00292", "authors": ["Zhongwei Shen"], "title": "Boundary Value Problems for the Magnetic Laplacian in Semiclassical Analysis", "categories": ["math.AP", "35P25"], "comment": null, "summary": "This paper is concerned with the magnetic Laplacian $P^h (\\A)=(h D+\\A)^2$ in\nsemiclassical analysis, where $h$ is a semiclassical parameter. We study the\n$L^2$ Neumann and Dirichlet problems for the equation $P^h(\\A)u=0$ in a bounded\nLipschitz domain $\\Omega$. Under the assumption that the magnetic field $\\nabla\n\\times \\A$ is of finite type on $\\overline{\\Omega}$, we establish the\nnontangential maximal function estimates for $(h D+\\A)u$, which are uniform for\n$0< h< h_0$. This extends a well-known result due to D. Jerison and C. Kenig\nfor the Laplacian in Lipschitz domains to the magnetic Laplacian in the\nsemiclassical setting. Our results are new even for smooth domains.", "AI": {"tldr": "Magnetic Laplacian analysis in semiclassical setting with uniform nontangential maximal function estimates for Neumann/Dirichlet problems in Lipschitz domains under finite type magnetic field assumption.", "motivation": "Extend Jerison and Kenig's classical result for Laplacian in Lipschitz domains to magnetic Laplacian in semiclassical setting, providing new insights even for smooth domains.", "method": "Study L^2 Neumann and Dirichlet problems for magnetic Laplacian P^h(A) = (hD + A)^2 in bounded Lipschitz domains, assuming magnetic field \u2207\u00d7A is of finite type on closure.", "result": "Established uniform nontangential maximal function estimates for (hD + A)u for 0 < h < h_0, extending classical Laplacian results to magnetic case.", "conclusion": "Successfully generalized Jerison-Kenig's Lipschitz domain results to semiclassical magnetic Laplacian, providing new uniform estimates that hold even for smooth domains."}}
{"id": "2509.00358", "pdf": "https://arxiv.org/pdf/2509.00358", "abs": "https://arxiv.org/abs/2509.00358", "authors": ["Priyanka Verma", "Subhojit Bose", "Harshita Raj", "Joydeep Ghosh"], "title": "PRISM: A MATLAB-Based Application for Structured Probe Data Management and Visualization in Tokamak Diagnostics", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The successful operation of tokamak experiments requires accurate\ndocumentation, tracking, and visualization of diagnostic instruments,\nparticularly electrical probes. Traditionally, this metadata is maintained\nmanually through handwritten logbooks or semi-digital spreadsheets, leading to\ninefficiencies and human errors. In response to these challenges, we present\nPRISM (Probe Registration and Information System for Monitoring)-a MATLAB-based\napplication developed using App Designer. PRISM provides a graphical user\ninterface (GUI) that facilitates structured probe registration, metadata\nstorage, and both 2D and 3D spatial visualization in tokamak geometries. Tested\nwith data from the ADITYA-U tokamak, PRISM helps users enter information\naccurately, retrieve metadata easily, and visualize probe setups. The tool is\nbuilt in a flexible way, is not limited to a specific setup, and could\npotentially support future developments such as digital twins and real-time\ncontrol systems.", "AI": {"tldr": "PRISM is a MATLAB-based GUI application that automates probe registration, metadata management, and 2D/3D visualization for tokamak experiments, replacing manual documentation methods.", "motivation": "Traditional manual documentation methods (handwritten logbooks, spreadsheets) for tokamak diagnostic instruments lead to inefficiencies and human errors, requiring a more systematic digital solution.", "method": "Developed a MATLAB-based application using App Designer with a graphical user interface for structured probe registration, metadata storage, and spatial visualization in tokamak geometries.", "result": "Successfully tested with ADITYA-U tokamak data, enabling accurate information entry, easy metadata retrieval, and probe setup visualization. The tool is flexible and not limited to specific setups.", "conclusion": "PRISM provides an efficient digital solution for probe management in tokamak experiments and has potential for future integration with digital twins and real-time control systems."}}
{"id": "2509.00014", "pdf": "https://arxiv.org/pdf/2509.00014", "abs": "https://arxiv.org/abs/2509.00014", "authors": ["Pengfei Ma", "Li Cai", "Xuan Wang", "Hao Gao"], "title": "AFSI: Automated Fluid-Structure Interaction Solver Development for Nonlinear Solid Mechanics", "categories": ["physics.comp-ph"], "comment": null, "summary": "AFSI is a novel, open-source fluid-structure interaction (FSI) solver\n  that extends the capabilities of the FEniCS finite element library through\n  an immersed boundary (IB) framework. Designed to simulate large deformations\n  in hyperelastic materials (such as cardiac tissue), AFSI avoids the need for\nexpensive remeshing by coupling a Lagrangian representation of the solid with\nan Eulerian description of the surrounding fluid. This approach retains the\nfull expressiveness of FEniCS's variational formulations, function spaces, and\ntime integration schemes.\n  Implemented in a hybrid Python/C++ architecture, AFSI allows users to define\ngeometries, constitutive models (e.g., the Holzapfel-Ogden law for myocardium),\nand strain energy functions directly in Python, while delegating\nperformance-critical tasks such as assembly and linear solvers to optimized C++\nbackends. Its concise and modular Python API facilitates the setup of FSI\nsimulations, enabling users to easily modify discretization strategies or\nanalyze results using standard FEniCS post-processing tools.\n  By combining the flexibility of FEniCS with a robust immersed boundary\nformulation, AFSI empowers rapid prototyping of complex nonlinear solid-fluid\ninteraction problems, making it a powerful tool for simulating biomechanical\nsystems and other applications involving highly deformable structures in flow.", "AI": {"tldr": "AFSI is an open-source FSI solver that extends FEniCS with immersed boundary framework for simulating large deformations in hyperelastic materials without expensive remeshing.", "motivation": "To enable simulation of large deformations in hyperelastic materials (like cardiac tissue) while avoiding costly remeshing operations typically required in traditional FSI approaches.", "method": "Uses immersed boundary framework coupling Lagrangian solid representation with Eulerian fluid description. Implemented as hybrid Python/C++ architecture - Python for user interface/geometry definition, C++ for performance-critical tasks like assembly and linear solvers.", "result": "Developed a concise modular Python API that facilitates FSI simulation setup and allows easy modification of discretization strategies while leveraging FEniCS's variational formulations and post-processing tools.", "conclusion": "AFSI combines FEniCS flexibility with robust immersed boundary formulation, enabling rapid prototyping of complex nonlinear solid-fluid interaction problems for biomechanical systems and highly deformable structures in flow."}}
{"id": "2509.00495", "pdf": "https://arxiv.org/pdf/2509.00495", "abs": "https://arxiv.org/abs/2509.00495", "authors": ["Zhengbo Zhou"], "title": "A Mixed Precision Eigensolver Based on the Jacobi Algorithm", "categories": ["math.NA", "cs.NA"], "comment": "81 pages, 12 figures, MSc Thesis", "summary": "The classic method for computing the spectral decomposition of a real\nsymmetric matrix, the Jacobi algorithm, can be accelerated by using mixed\nprecision arithmetic. The Jacobi algorithm is aiming to reduce the off-diagonal\nentries iteratively using Givens rotations. We investigate how to use the low\nprecision to speed up this algorithm based on the approximate spectral\ndecomposition in low precision.\n  We first study two different index choosing techniques, classical and\ncyclic-by-row, for the Jacobi algorithm. Numerical testing suggests that\ncyclic-by-row is more efficient. Then we discuss two different methods of\northogonalizing an almost orthogonal matrix: the QR factorization and the polar\ndecomposition. For polar decomposition, we speed up the Newton iteration by\nusing the one-step Schulz iteration. Based on numerical testing, using the\npolar decomposition approach (Newton--Schulz iteration) is not only faster but\nalso more accurate than using the QR factorization.\n  A mixed precision algorithm for computing the spectral decomposition of a\nreal symmetric matrix at double precision is provided. In doing so we compute\nthe approximate eigenvector matrix $Q_\\ell$ of $A$ in single precision using\n$\\texttt{eig}$ and $\\texttt{single}$ in MATLAB. We then use the Newton--Schulz\niteration to orthogonalize the eigenvector matrix $Q_\\ell$ into an orthogonal\nmatrix $Q_d$ in double precision. Finally, we apply the cyclic-by-row Jacobi\nalgorithm on $Q_d^TAQ_d$ and obtain the spectral decomposition of $A$. At this\nstage, we will see, from the testings, the cyclic-by-row Jacobi algorithm only\nneed less than 10 iterations to converge by utilizing the quadratic\nconvergence. The new mixed precision algorithm requires roughly 30\\% of the\ntime used by the Jacobi algorithm on its own.", "AI": {"tldr": "Mixed precision Jacobi algorithm using single precision for approximate eigenvectors and double precision Newton-Schulz iteration for orthogonalization, achieving 30% speedup over traditional Jacobi.", "motivation": "Accelerate the classic Jacobi algorithm for symmetric matrix spectral decomposition by leveraging mixed precision arithmetic while maintaining accuracy.", "method": "Compute approximate eigenvectors in single precision, orthogonalize using Newton-Schulz iteration in double precision, then apply cyclic-by-row Jacobi algorithm on the transformed matrix.", "result": "The mixed precision approach requires less than 10 Jacobi iterations due to quadratic convergence and achieves roughly 30% time reduction compared to standard Jacobi algorithm.", "conclusion": "Mixed precision arithmetic combined with cyclic-by-row Jacobi and Newton-Schulz orthogonalization provides significant computational savings while maintaining accuracy for symmetric matrix spectral decomposition."}}
{"id": "2509.00455", "pdf": "https://arxiv.org/pdf/2509.00455", "abs": "https://arxiv.org/abs/2509.00455", "authors": ["Miles H. Wheeler"], "title": "Non-symmetric solutions to an overdetermined problem for the Helmholtz equation in the plane", "categories": ["math.AP"], "comment": "11 pages, 2 figures", "summary": "In this note we construct smooth bounded domains $\\Omega \\subset \\mathbb\nR^2$, other than disks, for which the overdetermined problem $$\n  \\left\\{\n  \\begin{alignedat}{2}\n  \\Delta u + \\lambda u &= 0 &\\qquad& \\text{ in } \\Omega, \\newline\n  u &= b &\\qquad& \\text{ on } \\partial \\Omega, \\newline\n  \\frac{\\partial u}{\\partial n} &= c &\\qquad& \\text{ on } \\partial \\Omega\n  \\end{alignedat}\n  \\right. $$ has a solution for some constants $\\lambda,b,c \\ne 0$. These\nappear to be the first counterexamples to a conjecture of Willms and Gladwell\n[WG94].", "AI": {"tldr": "Construction of smooth bounded domains in R\u00b2 (other than disks) where the overdetermined elliptic problem with Dirichlet and Neumann boundary conditions has non-trivial solutions, providing counterexamples to a conjecture by Willms and Gladwell.", "motivation": "To challenge and disprove the conjecture by Willms and Gladwell [WG94] that only disks can support non-trivial solutions to the overdetermined boundary value problem with both Dirichlet and Neumann conditions specified.", "method": "Construct explicit examples of smooth bounded domains in the plane (R\u00b2) that are not disks, and demonstrate that these domains admit solutions to the overdetermined problem with non-zero constants \u03bb, b, c.", "result": "Successful construction of counterexample domains showing that non-disk domains can indeed support solutions to the overdetermined boundary value problem, contradicting the previous conjecture.", "conclusion": "The conjecture that only disks can have solutions to this overdetermined problem is false, as demonstrated by the constructed counterexamples of smooth bounded domains in R\u00b2."}}
{"id": "2509.00659", "pdf": "https://arxiv.org/pdf/2509.00659", "abs": "https://arxiv.org/abs/2509.00659", "authors": ["Jie Feng", "Hao Xu", "Mingxuan Wei", "Mingyang Zhu", "Xichen Hu", "Bingzhan Shi", "Fuyuan Wu", "Weijun Zhou", "Wenchao Yan", "Guoqiang Zhang", "Jinguang Wang", "Yifei Li", "Xin Lu", "Liming Chen"], "title": "Ultrashort Time-Integrated Diagnosis of Laser-Heated Deuterium Ions in Dense Plasma via Fusion Neutron Spectra", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The ultrashort time-integrated diagnosis of ions plays a vital role in high\nenergy density physics research. However, it is extremely challenging to\nmeasure in experiment. Here, we demonstrate a reliable approach for\ninvestigating the dynamics of deuterium ions in dense plasma. By irradiating a\nheavy water stream with the hundred Hertz repetitive intense femtosecond laser\npulses, the neutrons from D(D,n)3He reaction can be detected via a single\nTime-of-Flight detector to accumulate the spectrum with a fine\nenergy-resolution. This spectrum has been utilized to calculate the temperature\nand angular distribution of deuterium ions transported in plasma. And the\ncalculated results are well verified by particle-in-cell simulations of\ndeuterium ions dynamics. Our method paves a new way for diagnosing ions\npicoseconds time-integrated dynamics in plasma and holds great potential for\nunderstanding the ions transport process in high-energy density matters and\nstudying laser plasma ion acceleration.", "AI": {"tldr": "A new method using femtosecond laser pulses and neutron detection to measure deuterium ion dynamics in dense plasma with picosecond time resolution.", "motivation": "Ultrashort time-integrated diagnosis of ions is crucial for high energy density physics research but extremely challenging to measure experimentally.", "method": "Irradiate heavy water stream with hundred Hertz repetitive intense femtosecond laser pulses, detect neutrons from D(D,n)3He reaction using single Time-of-Flight detector to accumulate high-resolution energy spectrum.", "result": "Successfully calculated temperature and angular distribution of deuterium ions transported in plasma, with results well verified by particle-in-cell simulations.", "conclusion": "This method provides a new way for picosecond time-integrated ion dynamics diagnosis in plasma, with potential applications in understanding ion transport processes and laser plasma ion acceleration studies."}}
{"id": "2509.00024", "pdf": "https://arxiv.org/pdf/2509.00024", "abs": "https://arxiv.org/abs/2509.00024", "authors": ["James Amarel", "Nicolas Hengartner", "Robyn Miller", "Kamaljeet Singh", "Siddharth Mansingh", "Arvind Mohan", "Benjamin Migliori", "Emily Casleton", "Alexei Skurikhin", "Earl Lawrence", "Gerd J. Kunde"], "title": "Generalization vs. Memorization in Autoregressive Deep Learning: Or, Examining Temporal Decay of Gradient Coherence", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "Foundation models trained as autoregressive PDE surrogates hold significant\npromise for accelerating scientific discovery through their capacity to both\nextrapolate beyond training regimes and efficiently adapt to downstream tasks\ndespite a paucity of examples for fine-tuning. However, reliably achieving\ngenuine generalization - a necessary capability for producing novel scientific\ninsights and robustly performing during deployment - remains a critical\nchallenge. Establishing whether or not these requirements are met demands\nevaluation metrics capable of clearly distinguishing genuine model\ngeneralization from mere memorization.\n  We apply the influence function formalism to systematically characterize how\nautoregressive PDE surrogates assimilate and propagate information derived from\ndiverse physical scenarios, revealing fundamental limitations of standard\nmodels and training routines in addition to providing actionable insights\nregarding the design of improved surrogates.", "AI": {"tldr": "The paper analyzes autoregressive PDE surrogate models using influence functions to distinguish genuine generalization from memorization, revealing limitations in standard models and providing insights for improved surrogate design.", "motivation": "Foundation models for PDE surrogates promise scientific acceleration through extrapolation and adaptation, but reliably achieving genuine generalization remains challenging. Current evaluation metrics cannot clearly distinguish true generalization from memorization.", "method": "The authors apply the influence function formalism to systematically characterize how autoregressive PDE surrogates assimilate and propagate information from diverse physical scenarios.", "result": "The analysis reveals fundamental limitations of standard models and training routines, showing they often fail to achieve genuine generalization despite appearing to perform well.", "conclusion": "The influence function approach provides actionable insights for designing improved PDE surrogates that can reliably achieve genuine generalization, which is crucial for producing novel scientific insights and robust deployment."}}
{"id": "2509.00505", "pdf": "https://arxiv.org/pdf/2509.00505", "abs": "https://arxiv.org/abs/2509.00505", "authors": ["Hiroki Ishizaka"], "title": "On discrete Sobolev inequalities for nonconforming finite elements under a semi-regular mesh condition", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We derive a discrete $ L^q-L^p$ Sobolev inequality tailored for the\nCrouzeix--Raviart and discontinuous Crouzeix--Raviart finite element spaces on\nanisotropic meshes in both two and three dimensions. Subject to a semi-regular\nmesh condition, this discrete Sobolev inequality is applicable to all pairs\n$(q,p)$ that align with the local Sobolev embedding, including scenarios where\n$q \\leq p$. Importantly, the constant is influenced solely by the domain and\nthe semi-regular parameter, ensuring robustness against variations in aspect\nratios and interior angles of the mesh. The proof employs an\nanisotropy-sensitive trace inequality that leverages the element height, a\ntwo-step affine/Piola mapping approach, the stability of the Raviart--Thomas\ninterpolation, and a discrete integration-by-parts identity augmented with\nweighted jump/trace terms on faces. This Sobolev inequality serves as a\nmesh-robust foundation for the stability and error analysis of nonconforming\nand discontinuous Galerkin methods on highly anisotropic meshes.", "AI": {"tldr": "Discrete L^q-L^p Sobolev inequality for Crouzeix-Raviart and discontinuous Crouzeix-Raviart finite elements on anisotropic meshes in 2D/3D, with mesh-robust constant depending only on domain and semi-regular parameter.", "motivation": "To provide a robust mathematical foundation for stability and error analysis of nonconforming and discontinuous Galerkin methods on highly anisotropic meshes, where traditional isotropic approaches fail.", "method": "Uses anisotropy-sensitive trace inequality with element height, two-step affine/Piola mapping, Raviart--Thomas interpolation stability, and discrete integration-by-parts with weighted jump/trace terms on faces.", "result": "Derived discrete Sobolev inequality applicable to all (q,p) pairs satisfying local Sobolev embedding (including q \u2264 p), with constant robust against mesh aspect ratios and interior angles.", "conclusion": "The inequality provides a mesh-robust foundation for analyzing nonconforming and discontinuous Galerkin methods on anisotropic meshes, enabling reliable numerical simulations on complex geometries."}}
{"id": "2509.00470", "pdf": "https://arxiv.org/pdf/2509.00470", "abs": "https://arxiv.org/abs/2509.00470", "authors": ["Divya Goel", "Sarika Goyal", "Diksha Saini"], "title": "$p$-biharmonic Kirchhoff equations with critical Choquard nonlinearity", "categories": ["math.AP", "35J20, 35J30, 35J62"], "comment": null, "summary": "In this article, we deal with the following involving $p$-biharmonic critical\nChoquard-Kirchhoff equation\n  $$\n  \\left(a+b\\left(\\int_{\\mathbb R^N}|\\Delta u|^p dx\\right)^{\\theta-1}\\right)\n\\Delta_{p}^{2}u = \\alpha \\left(|x|^{-\\mu}*u^{p^*_\\mu}\\right)|u|^{p^*_\\mu-2}u+\n\\lambda f(x) |u|^{r-2} u \\; \\text{in}\\; \\mathbb R^N,\n  $$\n  where $a\\geq 0$, $b> 0$, $0<\\mu<N$, $N>2p$, $p\\geq 2$, $\\theta\\geq1$,\n$\\alpha$ and $\\lambda$ are positive real parameters, $p_{\\mu}^{*}=\n\\frac{p(2N-\\mu)}{2(N-2p)}$ is the upper critical exponent in the sense of\nHardy-Littlewood-Sobolev inequality. The function $f \\in L^{t}(\\mathbb R^N)$\nwith $t= \\frac{p^{*}}{(p^* -r)}$ if $p<r<p^*:=\\frac{Np}{N-2p}$ and $t=\\infty$\nif $r\\geq p^{*}$. We first prove the concentration compactness principle for\nthe $p$-biharmonic Choquard-type equation. Then using the variational method\ntogether with the concentration-compactness, we established the existence and\nmultiplicity of solutions to the above problem with respect to parameters\n$\\lambda$ and \\(\\alpha\\) for different values of $r$. The results obtained here\nare new even for $p-$Laplacian.", "AI": {"tldr": "Study of p-biharmonic critical Choquard-Kirchhoff equation with Hardy-Littlewood-Sobolev critical exponent. Proves concentration compactness principle and establishes existence/multiplicity of solutions via variational methods.", "motivation": "To address the p-biharmonic Choquard-Kirchhoff equation with critical exponent, which combines nonlocal Choquard terms with Kirchhoff-type nonlocal coefficients, presenting mathematical challenges in analysis.", "method": "First proves concentration compactness principle for p-biharmonic Choquard-type equations, then uses variational methods combined with concentration-compactness techniques to analyze existence and multiplicity of solutions.", "result": "Establishes existence and multiplicity of solutions with respect to parameters \u03bb and \u03b1 for different values of r. Results are novel even for the p-Laplacian case.", "conclusion": "The paper successfully develops new mathematical tools (concentration compactness principle) and obtains significant results for critical p-biharmonic Choquard-Kirchhoff equations, extending previous work on related problems."}}
{"id": "2509.00878", "pdf": "https://arxiv.org/pdf/2509.00878", "abs": "https://arxiv.org/abs/2509.00878", "authors": ["Ritu Dey", "Ayushi Agrawal", "Reetesh Kumar Gangwar", "Deepti Sharma", "Rajesh Srivastava", "Malay B. Chowdhuri", "Joydeep Ghosh"], "title": "Simulation study of neutral tungsten emissions for fusion applications", "categories": ["physics.plasm-ph", "physics.atom-ph"], "comment": "4 pages, 4 figures, submitted to Plasma and Fusion Research", "summary": "The article reports electron-impact excitation cross-sections and rate\ncoefficients for neutral tungsten for three transitions (400.87 nm, 429.46 nm,\nand 430.21 nm) using the relativistic distorted wave approach within the\nflexible atomic code. Some of these lines are also observed in tokamak plasma.\nCross-sections are computed for incident electron energy up to 30 keV. The\nenergy levels in flexible atomic code were corrected to match the NIST\ndatabase. The electron impact excitation rate coefficients are also provided.", "AI": {"tldr": "Electron-impact excitation cross-sections and rate coefficients for neutral tungsten transitions calculated using relativistic distorted wave approach.", "motivation": "To provide accurate electron-impact excitation data for neutral tungsten transitions relevant to tokamak plasma observations.", "method": "Used relativistic distorted wave approach within flexible atomic code, with energy levels corrected to match NIST database. Computed cross-sections for electron energies up to 30 keV.", "result": "Calculated excitation cross-sections and rate coefficients for three tungsten transitions (400.87 nm, 429.46 nm, and 430.21 nm).", "conclusion": "Provides valuable atomic data for tungsten transitions observed in tokamak plasmas, with NIST-corrected energy levels ensuring accuracy."}}
{"id": "2509.00169", "pdf": "https://arxiv.org/pdf/2509.00169", "abs": "https://arxiv.org/abs/2509.00169", "authors": ["Yuan Chiang", "Youngsoo Choi", "Daniel Osei-Kuffuor"], "title": "Generative Latent Space Dynamics of Electron Density", "categories": ["physics.comp-ph", "physics.chem-ph"], "comment": null, "summary": "Modeling the time-dependent evolution of electron density is essential for\nunderstanding quantum mechanical behaviors of condensed matter and enabling\npredictive simulations in spectroscopy, photochemistry, and ultrafast science.\nYet, while machine learning methods have advanced static density prediction,\nmodeling its spatiotemporal dynamics remains largely unexplored. In this work,\nwe introduce a generative framework that combines a 3D convolutional\nautoencoder with a latent diffusion model (LDM) to learn electron density\ntrajectories from ab-initio molecular dynamics (AIMD) simulations. Our method\nencodes electron densities into a compact latent space and predicts their\nfuture states by sampling from the learned conditional distribution, enabling\nstable long-horizon rollouts without drift or collapse. To preserve statistical\nfidelity, we incorporate a scaled Jensen-Shannon divergence regularization that\naligns generated and reference density distributions. On AIMD trajectories of\nliquid lithium at 800 K, our model accurately captures both the spatial\ncorrelations and the log-normal-like statistical structure of the density. The\nproposed framework has the potential to accelerate the simulation of quantum\ndynamics and overcome key challenges faced by current spatiotemporal machine\nlearning methods as surrogates of quantum mechanical simulators.", "AI": {"tldr": "A generative framework combining 3D convolutional autoencoder with latent diffusion model to predict electron density trajectories from quantum simulations, enabling stable long-term predictions while preserving statistical properties.", "motivation": "Modeling time-dependent electron density evolution is crucial for understanding quantum mechanical behaviors in condensed matter and enabling predictive simulations in spectroscopy and ultrafast science, but current machine learning methods only handle static density prediction.", "method": "Combines 3D convolutional autoencoder with latent diffusion model to encode electron densities into compact latent space and predict future states by sampling from learned conditional distribution. Uses scaled Jensen-Shannon divergence regularization to preserve statistical fidelity.", "result": "Accurately captures both spatial correlations and log-normal-like statistical structure of electron density in liquid lithium at 800 K, enabling stable long-horizon rollouts without drift or collapse.", "conclusion": "The framework has potential to accelerate quantum dynamics simulation and overcome key challenges faced by current spatiotemporal machine learning methods as surrogates for quantum mechanical simulators."}}
{"id": "2509.00521", "pdf": "https://arxiv.org/pdf/2509.00521", "abs": "https://arxiv.org/abs/2509.00521", "authors": ["Hu Liu", "Shuaibin Gao", "Junhao Hu"], "title": "The adaptive EM schemes for McKean-Vlasov SDEs with common noise in finite and infinite horizons", "categories": ["math.NA", "cs.NA", "math.PR"], "comment": null, "summary": "This paper is dedicated to investigating the adaptive Euler-Maruyama (EM)\nschemes for the approximation of McKean-Vlasov stochastic differential\nequations (SDEs) with common noise. When the drift and diffusion coefficients\nboth satisfy the superlinear growth conditions, the $L^p$ convergence rates in\nfinite and infinite horizons are revealed, which reacts to the particle number\nand step size. Subsequently, there is an illustration of the theory results by\nmeans of two numerical examples.", "AI": {"tldr": "Adaptive Euler-Maruyama schemes for McKean-Vlasov SDEs with common noise, achieving L^p convergence rates under superlinear growth conditions.", "motivation": "To develop efficient numerical approximation methods for McKean-Vlasov stochastic differential equations with common noise, particularly when dealing with superlinear growth conditions in drift and diffusion coefficients.", "method": "Adaptive Euler-Maruyama schemes are employed to approximate solutions of McKean-Vlasov SDEs with common noise, analyzing convergence under superlinear growth conditions.", "result": "The paper establishes L^p convergence rates in both finite and infinite time horizons, with rates depending on particle number and step size. Numerical examples validate the theoretical results.", "conclusion": "The adaptive EM schemes provide effective approximation for McKean-Vlasov SDEs with common noise, with proven convergence rates under challenging superlinear growth conditions."}}
{"id": "2509.00565", "pdf": "https://arxiv.org/pdf/2509.00565", "abs": "https://arxiv.org/abs/2509.00565", "authors": ["Athulya P", "Sandeep Kumar Verma"], "title": "Caccioppoli-type inequalities for the Dunkl-$A$-Laplacian and their application to nonexistence result", "categories": ["math.AP", "math.FA"], "comment": "21 pages", "summary": "For a suitable function $A:\\mathbb{R}^n\\to \\mathbb{R}^n$, we introduce the\n$A$-Laplacian in the Dunkl framework as $\\Delta_{k,A}(u)\n=\\text{div}_k(A(\\nabla_ku))$, where $\\nabla_k$ is the Dunkl-gradient operator\nassociated with the multiplicity function $k$ and the root system\n$\\mathcal{R}$. We derive the local and global Caccioppoli-type inequality for\nan element $u$ in the Dunkl-Orlicz-Sobolev space, satisfying the\nDunkl-differential inequality $$ -\\Delta_{k, A}(u) \\geq b\\Phi(u)\\chi_{\\{u>0\\}}.\n$$ Using the Caccioppoli inequality, we establish a sufficient condition for\nthe nonexistence of a nonzero solution $u$ to the Dunkl-differential\ninequality.", "AI": {"tldr": "Introduces A-Laplacian in Dunkl framework, derives Caccioppoli inequalities for Dunkl-Orlicz-Sobolev spaces, and establishes nonexistence conditions for solutions to Dunkl-differential inequalities.", "motivation": "To extend the theory of A-Laplacian operators to the Dunkl framework, which generalizes classical differential operators by incorporating reflection groups and multiplicity functions, enabling analysis in non-Euclidean settings.", "method": "Defines A-Laplacian operator \u0394_{k,A}(u) = div_k(A(\u2207_k u)) using Dunkl-gradient operator. Derives local and global Caccioppoli-type inequalities for Dunkl-Orlicz-Sobolev spaces satisfying Dunkl-differential inequalities.", "result": "Obtains Caccioppoli inequalities that provide control over solutions. Establishes sufficient conditions ensuring nonexistence of nonzero solutions to the Dunkl-differential inequality -\u0394_{k,A}(u) \u2265 b\u03a6(u)\u03c7_{u>0}.", "conclusion": "The developed framework and inequalities provide powerful tools for analyzing Dunkl-type differential operators and establishing nonexistence results for solutions to associated differential inequalities in Dunkl-Orlicz-Sobolev spaces."}}
{"id": "2509.00915", "pdf": "https://arxiv.org/pdf/2509.00915", "abs": "https://arxiv.org/abs/2509.00915", "authors": ["Maximilian M. Richter", "Patricio A. Mu\u00f1oz", "Felix Spanier"], "title": "Local extraction of three-dimensional magnetic reconnection X-lines", "categories": ["physics.plasm-ph", "astro-ph.SR", "physics.comp-ph"], "comment": "Accepted for publication in Physics of Plasmas (AIP)", "summary": "Magnetic reconnection is one of the most important magnetic energy conversion\nprocesses observed in laboratory and space plasmas. It describes the breaking\nand joining of magnetic field lines, leading to the release of magnetic energy\nand the acceleration of charged particles. Finding regions where fast\nreconnection occurs is key to understanding this process. However, identifying\nsuch reconnection events within a turbulent environment in three dimensions\nremains a challenge. In this work, we develop a new framework for identifying\nmagnetic reconnection using 3D turbulent plasma simulations. First, we apply\nbifurcation lines from fluid visualization to magnetic fields and show that\nthey can be identified with X-lines of magnetic reconnection. For reconnection\nconfigurations with magnetic guide fields, we introduce a novel concept of\nquasi X-lines (QXL). Using the spatial information of X-lines in numerical\nsimulations, we present a local technique to estimate the reconnection rate,\nobtaining a distribution that features a local maximum near the normalized\nvalue 0.1. Additionally, we provide an alternative tool to highlight current\nsheets in turbulent plasma by measuring magnetic shear layers as the second\ninvariant of the shear strain tensor. These methods, avoiding traditional\nreliance on global methods, electric fields and current density, offer a new\nperspective to the quantitative study of magnetic reconnection in plasmas with\ncomplex magnetic field topologies. Validated across various plasma simulation\nmodels, including kinetic particle-in-cell (PIC) and resistive\nmagnetohydrodynamics (MHD), our approach enables efficient exploration of\nmagnetic field dynamics in turbulent plasma environments.", "AI": {"tldr": "New framework for identifying magnetic reconnection in 3D turbulent plasmas using bifurcation lines as X-lines and introducing quasi X-lines for guide field configurations, with local reconnection rate estimation and magnetic shear layer measurement.", "motivation": "Identifying fast magnetic reconnection events in 3D turbulent plasma environments remains challenging, requiring new methods beyond traditional global approaches and electric field/current density reliance.", "method": "Applied bifurcation lines from fluid visualization to magnetic fields to identify X-lines, introduced quasi X-lines for guide field configurations, developed local reconnection rate estimation technique, and measured magnetic shear layers as second invariant of shear strain tensor.", "result": "Obtained reconnection rate distribution with local maximum near normalized value 0.1, validated across various plasma simulation models including kinetic PIC and resistive MHD.", "conclusion": "The framework provides efficient tools for quantitative study of magnetic reconnection in complex magnetic field topologies, enabling better exploration of magnetic field dynamics in turbulent plasma environments."}}
{"id": "2509.00206", "pdf": "https://arxiv.org/pdf/2509.00206", "abs": "https://arxiv.org/abs/2509.00206", "authors": ["H. Frerichs"], "title": "Particle swarm optimization of divertor targets for heat load control", "categories": ["physics.comp-ph", "physics.plasm-ph"], "comment": "13 pages, 8 figures", "summary": "Divertor targets in magnetic confinement fusion devices must be designed to\nhandle extreme heat loads. Fast approximation of heat loads with FLARE based on\nfield line reconstruction from an unstructured flux tube mesh is utilized in\nparticle swarm optimization (PSO) of the divertor target geometry. Optimization\nof the outer divertor target in ITER is evaluated with a constraint for the\nhead loads onto baffles. The optimal configuration is found to depend on\nassumptions for the background plasma in the heat load proxy simulation.", "AI": {"tldr": "Using FLARE for fast heat load approximation and particle swarm optimization to optimize ITER outer divertor target geometry with baffle heat load constraints.", "motivation": "Divertor targets in fusion devices need to handle extreme heat loads, requiring optimized geometry designs that can be efficiently evaluated.", "method": "Utilizes FLARE for fast heat load approximation based on field line reconstruction from unstructured flux tube mesh, combined with particle swarm optimization (PSO) for divertor target geometry optimization.", "result": "The optimal divertor target configuration for ITER depends on assumptions made about the background plasma in the heat load proxy simulations.", "conclusion": "PSO with FLARE provides an effective approach for divertor optimization, but results are sensitive to plasma background assumptions, highlighting the need for careful parameter selection in heat load simulations."}}
{"id": "2509.00522", "pdf": "https://arxiv.org/pdf/2509.00522", "abs": "https://arxiv.org/abs/2509.00522", "authors": ["Giuliano Guarino", "Yannis Voet", "Pablo Antolin", "Annalisa Buffa"], "title": "Stabilization techniques for immersogeometric analysis of plate and shell problems in explicit dynamics", "categories": ["math.NA", "cs.CE", "cs.NA"], "comment": null, "summary": "Finite element plate and shell formulations are ubiquitous in structural\nanalysis for modeling all kinds of slender structures, both for static and\ndynamic analyses. The latter are particularly challenging as the high order\nnature of the underlying partial differential equations and the slenderness of\nthe structures all impose a stringent constraint on the critical time step in\nexplicit dynamics. Unfortunately, badly cut elements in immersed finite element\ndiscretizations further aggravate the issue. While lumping the mass matrix\noften increases the critical time step, it might also trigger spurious\noscillations in the approximate solution thereby compromising the numerical\nsolution. In this article, we extend our previous work in\n\\cite{voet2025stabilization} to allow stable immersogeometric analysis of plate\nand shell problems with lumped mass matrices. This technique is based on\npolynomial extensions and restores a level of accuracy comparable to\nboundary-fitted discretizations.", "AI": {"tldr": "Extension of previous work to enable stable immersogeometric analysis of plates and shells using lumped mass matrices, addressing time step constraints in explicit dynamics.", "motivation": "Finite element plate/shell formulations face stringent time step constraints in explicit dynamics due to high-order PDEs and structural slenderness, worsened by badly cut elements in immersed discretizations. Lumped mass matrices can increase critical time step but may cause spurious oscillations.", "method": "Based on polynomial extensions technique from previous work, this approach allows stable immersogeometric analysis with lumped mass matrices while maintaining accuracy comparable to boundary-fitted discretizations.", "result": "The method enables stable analysis of plate and shell problems using lumped mass matrices in immersed finite element settings, overcoming the spurious oscillation issues.", "conclusion": "This extension provides a stable framework for immersogeometric analysis of slender structures with lumped mass matrices, achieving accuracy levels similar to traditional boundary-fitted approaches while addressing time step constraints."}}
{"id": "2509.00609", "pdf": "https://arxiv.org/pdf/2509.00609", "abs": "https://arxiv.org/abs/2509.00609", "authors": ["Runcao Lyu"], "title": "$C^{\\infty}$ Regularity for the free boundary of one-phase Fractional Laplacian problem", "categories": ["math.AP"], "comment": null, "summary": "We consider a one-phase free boundary problem involving fractional Laplacian\n$(-\\Delta)^s$, $0<s<1$. D. De Silva, O. Savin, and Y. Sire proved that the flat\nboundaries are $C^{1,\\alpha}$. We raise the regularity to $C^{\\infty}$,\nextending the result known for $(-\\Delta)^{1/2}$ by D. De Silva and O. Savin.", "AI": {"tldr": "The paper extends regularity results for free boundary problems with fractional Laplacian from C\u00b9,\u03b1 to C\u221e smoothness.", "motivation": "Previous work by De Silva, Savin, and Sire established that flat boundaries are C\u00b9,\u03b1 regular for fractional Laplacian free boundary problems. The authors aim to improve this regularity to C\u221e smoothness, generalizing the known result for the half-Laplacian case.", "method": "The authors work with a one-phase free boundary problem involving fractional Laplacian (-\u0394)^s for 0<s<1. They build upon existing results and techniques to achieve higher regularity.", "result": "Successfully proved that flat boundaries in the fractional Laplacian free boundary problem are C\u221e smooth, extending the previous C\u00b9,\u03b1 regularity result.", "conclusion": "The research demonstrates that optimal regularity for free boundary problems with fractional Laplacian operators is C\u221e, significantly improving upon prior results and completing the regularity theory for these problems."}}
{"id": "2509.01171", "pdf": "https://arxiv.org/pdf/2509.01171", "abs": "https://arxiv.org/abs/2509.01171", "authors": ["Jonas Giesekus", "Anton Pletzer", "Florian Beckfeld", "Katharina Noesges", "Claudia Bock", "Julian Schulze"], "title": "Multi-diagnostic characterization of inductively coupled discharges with tailored waveform substrate bias for precise control of plasma etching", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Precise control of ion energy distribution functions (IEDF) is crucial for\nselectivity as well as control over sputter rate and substrate damage in\nnanoscale plasma processes. In this work, a low frequency (100 kHz) tailored\npulse-wave-shaped bias voltage waveform is applied to the substrate electrode\nof an inductively coupled plasma (ICP) and its effects on the IEDF, electron\ndensity, electron dynamics and the etch rates of silicon dioxide as well as\namorphous silicon are investigated in a commercial 200 mm reactive ion etching\n(RIE) reactor. While the tailored waveform substrate bias hardly affects the\nelectron density above the substrate and the spatio-temporally resolved\nelectron power absorption dynamics, it is found to affect the ion flux to the\nsubstrate at high ICP source powers. Monoenergetic IEDFs with a full width at\nhalf maximum (FWHM) below 10 eV are realized with mean ion energies ranging\nfrom 20 eV to 100 eV in both argon and SF6. Such monoenergetic IEDFs are used\nto determine the Ar ion sputter threshold energies of amorphous silicon and\nsilicon dioxide to be 23 eV and 37 eV, respectively, and to realize selective\netching of these two materials by Ar ion sputtering based on tailoring the IEDF\nto ensure that all incident ions are within this narrow ion energy selectivity\nwindow.", "AI": {"tldr": "Low frequency tailored pulse-wave-shaped bias voltage enables precise control of ion energy distribution for selective etching of silicon dioxide and amorphous silicon with monoenergetic ions.", "motivation": "Precise control of ion energy distribution functions is crucial for selectivity, sputter rate control, and minimizing substrate damage in nanoscale plasma processes.", "method": "Applied 100 kHz tailored pulse-wave-shaped bias voltage to substrate electrode in ICP reactor, investigated effects on IEDF, electron density, dynamics, and etch rates of SiO2 and a-Si in commercial 200mm RIE reactor.", "result": "Achieved monoenergetic IEDFs with FWHM below 10 eV (20-100 eV range) in both argon and SF6. Determined Ar ion sputter thresholds: 23 eV for a-Si and 37 eV for SiO2. Enabled selective etching by tailoring IEDF within narrow energy window.", "conclusion": "Tailored waveform substrate bias provides precise ion energy control for selective material processing without affecting electron density or power absorption dynamics, enabling new capabilities in nanoscale plasma etching."}}
{"id": "2509.00459", "pdf": "https://arxiv.org/pdf/2509.00459", "abs": "https://arxiv.org/abs/2509.00459", "authors": ["Jakub Fojt", "Tuomas P. Rossi", "Paul Erhart"], "title": "rhodent: A Python package for analyzing real-time TDDFT response", "categories": ["physics.comp-ph", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "physics.chem-ph"], "comment": "13 pages, 8 figures", "summary": "Real-time time-dependent density functional theory (rt-TDDFT) is a\nwell-established method for studying the dynamic response of matter in the\nfemtosecond or optical range. In this method, the Kohn-Sham (KS) wave functions\nare propagated forward in time, and in principle, one can extract any\nobservable at any given time. Alternatively, by taking a Fourier transform,\nspectroscopic quantities can be extracted. There are many publicly available\ncodes implementing rt-TDDFT, which differ in their numeric solution of the KS\nequations, their available exchange-correlation functionals, and in their\nanalysis capabilities. For users of rt-TDDFT, this is an inconvenient situation\nbecause they may need to use a numerical method that is available in one code,\nbut an analysis method available in another. Here, we introduce rhodent, a\nmodular Python package for processing the output of rt-TDDFT calculations. Our\npackage can be used to calculate hot-carrier distributions, energies, induced\ndensities, and dipole moments, and various decompositions thereof. In its\ncurrent version, rhodent handles calculation results from the gpaw code, but\ncan readily be extended to support other rt-TDDFT codes. Additionally, under\nthe assumption of linear response, rhodent can be used to calculate the\nresponse to a narrow-band laser, from the response to a broad-band\nperturbation, greatly speeding up the analysis of frequency-dependent\nexcitations. We demonstrate the capabilities of rhodent via a set of examples,\nfor systems consisting of Al and Ag clusters and organic molecules.", "AI": {"tldr": "rhodent is a modular Python package for processing rt-TDDFT calculation outputs, enabling calculation of various observables and decompositions, with support for multiple codes and efficient frequency-dependent analysis.", "motivation": "Existing rt-TDDFT codes have different numerical methods, exchange-correlation functionals, and analysis capabilities, creating inconvenience for users who need features from different codes.", "method": "Developed a modular Python package that processes rt-TDDFT outputs to calculate hot-carrier distributions, energies, induced densities, dipole moments, and their decompositions. Supports gpaw code and can be extended to others. Uses linear response assumption for efficient narrow-band laser response calculation from broad-band perturbations.", "result": "The package successfully processes rt-TDDFT calculations and demonstrates capabilities through examples with Al/Ag clusters and organic molecules, enabling efficient analysis of frequency-dependent excitations.", "conclusion": "rhodent provides a unified, extensible solution for rt-TDDFT analysis, overcoming limitations of individual codes and significantly speeding up frequency-dependent excitation analysis."}}
{"id": "2509.00557", "pdf": "https://arxiv.org/pdf/2509.00557", "abs": "https://arxiv.org/abs/2509.00557", "authors": ["M. M. Chernyshov", "P. N. Vabishchevich"], "title": "Numerical solution of 2D boundary value problems on merged Voronoi-Delaunay meshes", "categories": ["math.NA", "cs.NA", "35J25, 65N08, 65D18, 65N06"], "comment": "18 pages, 12 figures", "summary": "Computational technologies for the approximate solution of multidimensional\nboundary value problems often rely on irregular computational meshes and\nfinite-volume approximations. In this framework, the discrete problem\nrepresents the corresponding conservation law for control volumes associated\nwith the nodes of the mesh. This approach is most naturally and consistently\nimplemented using Delaunay triangulations together with Voronoi diagrams as\ncontrol volumes. In this paper, we employ meshes with nodes located both at the\nvertices of Delaunay triangulations and at the generators of Voronoi\npartitions. The cells of the merged Voronoi-Delaunay mesh are orthodiagonal\nquadrilaterals. On such meshes, scalar and vector functions, as well as\ninvariant gradient and divergence operators of vector calculus, can be\nconveniently approximated. We illustrate the capabilities of this approach by\nsolving a steady-state diffusion-reaction problem in an anisotropic medium.", "AI": {"tldr": "Novel mesh approach combining Delaunay triangulations and Voronoi partitions to create orthodiagonal quadrilateral cells for solving multidimensional boundary value problems.", "motivation": "To develop a more natural and consistent computational framework for finite-volume approximations of conservation laws using irregular meshes, particularly for anisotropic media problems.", "method": "Employ meshes with nodes at both Delaunay triangulation vertices and Voronoi partition generators, creating merged Voronoi-Delaunay meshes with orthodiagonal quadrilateral cells for approximating scalar/vector functions and gradient/divergence operators.", "result": "The approach enables convenient approximation of mathematical operators and demonstrates capability through solution of a steady-state diffusion-reaction problem in anisotropic medium.", "conclusion": "The Voronoi-Delaunay mesh framework provides an effective computational technology for multidimensional boundary value problems with irregular meshes and finite-volume approximations."}}
{"id": "2509.00694", "pdf": "https://arxiv.org/pdf/2509.00694", "abs": "https://arxiv.org/abs/2509.00694", "authors": ["Tao Liang", "Jiahong Wu", "Xiaoping Zhai"], "title": "Improved stability threshold for 2D Navier-Stokes Couette flow in a infinite channel", "categories": ["math.AP"], "comment": "Any comments are welcome", "summary": "We study the nonlinear stability of the two-dimensional Navier-Stokes\nequations around the Couette shear flow in the channel domain\n$\\mathbb{R}\\times[-1,1]$ subject to Navier slip boundary conditions. We\nestablish a quantitative stability threshold for perturbations of the initial\nvorticity $\\omega_{in}$, showing that stability holds for perturbations of\norder $\\nu^{1/2}$ measured in an anisotropic Sobolev space. This sharpens the\nrecent work of Arbon and Bedrossian [Comm. Math. Phys., 406 (2025), Paper No.\n129] who proved stability under the threshold $\\nu^{1/2}(1+\\ln(1/\\nu))^{-1/2}$.\nOur result removes the logarithmic loss and identifies the natural scaling\n$\\nu^{1/2}$ as the critical size of perturbations for nonlinear stability in\nthis setting.", "AI": {"tldr": "Nonlinear stability of 2D Navier-Stokes around Couette flow with Navier slip boundary conditions, establishing sharp stability threshold of \u03bd\u00b9\u141f\u00b2 without logarithmic loss.", "motivation": "To improve the understanding of hydrodynamic stability by establishing the precise critical perturbation size for nonlinear stability of Couette shear flow, removing the logarithmic loss from previous work.", "method": "Analysis of 2D Navier-Stokes equations in channel domain with Navier slip boundary conditions, studying perturbations of initial vorticity measured in anisotropic Sobolev spaces.", "result": "Proved quantitative stability threshold of order \u03bd\u00b9\u141f\u00b2 for perturbations, sharpening previous result of \u03bd\u00b9\u141f\u00b2(1+ln(1/\u03bd))\u207b\u00b9\u141f\u00b2 by removing the logarithmic factor.", "conclusion": "The natural scaling \u03bd\u00b9\u141f\u00b2 is identified as the critical size of perturbations for nonlinear stability in this setting, providing the optimal stability threshold."}}
{"id": "2509.01273", "pdf": "https://arxiv.org/pdf/2509.01273", "abs": "https://arxiv.org/abs/2509.01273", "authors": ["Genri Norman", "Ilnur Saitov"], "title": "Ionization/dissociation-driven first order phase transitions: on a new class of first order phase transitions", "categories": ["physics.plasm-ph", "cond-mat.mtrl-sci"], "comment": "13 pages, 18 figures", "summary": "In this work, we compare various models for describing the phase transition\nof the fluid hydrogen into a conducting state, including both chemical models\nof plasma and first-principle simulations within the framework of the density\nfunctional theory (DFT). The comparison of the results indicates the plasma\nnature of the phase transition in warm dense hydrogen. We propose a concept of\na new class of first-order phase transitions: ionization or dissociation-driven\nphase transitions, with which the plasma phase transition in fluid hydrogen can\nbe associated.", "AI": {"tldr": "Comparison of plasma chemical models and DFT simulations reveals plasma nature of hydrogen's phase transition to conducting state, proposing a new class of ionization-driven first-order phase transitions.", "motivation": "To understand the nature of phase transition in fluid hydrogen when it transforms into a conducting state, and to compare different modeling approaches for this phenomenon.", "method": "Compared various models including chemical models of plasma and first-principle simulations using density functional theory (DFT) to describe hydrogen's phase transition.", "result": "Results indicate the plasma nature of the phase transition in warm dense hydrogen, suggesting it belongs to a new class of first-order phase transitions.", "conclusion": "Proposed concept of ionization or dissociation-driven phase transitions as a new class, with plasma phase transition in fluid hydrogen being associated with this category."}}
{"id": "2509.00739", "pdf": "https://arxiv.org/pdf/2509.00739", "abs": "https://arxiv.org/abs/2509.00739", "authors": ["Tarkes Dora Pallicity"], "title": "Statistics of Residual Stress in Random Microstructures: Mean-Field Estimates and Full-Field Validations", "categories": ["physics.comp-ph"], "comment": "33 pages, 2 tables, 6 figures", "summary": "Fluctuations of local fields are crucial for the prediction of failure in\nrandom composites across different scales as well as estimating the inelastic\nbehaviour of it. This can be quantified statistically through second moments of\nthe local fields, which can be quickly estimated using mean field\nhomogenization (MFH). However, the exact fluctuation field can be estimated\nusing full-field methods though it comes at the cost of intensive computational\nresources and limited scalability to complex microstructures. In this work, MFH\nis used to estimate the statistical variation of the field quantities and then\ncross-verified with full-field methods for a linear-thermoelastic\nhomogenization problem. An analytical expression to calculate the second\nmoments of the local fields for a linear thermo-elastic problem using MFH is\nobtained based on the Hill-Mandel condition. The expressions fundamentally rely\non the solution of linear elastic problem which in turn depends on the\nderivatives of Hill's polarization tensor. Solution of this derivative term has\nbeen analytically and semianalytically derived in previous work [1]. The\nstatistical distribution of residual stress tensor components and equivalent\nstress in particulate and unidirectional fibrous composites, arising purely due\nto differential thermal expansion, is computed and compared with full-field\nhomogenization. Full-field simulations indicated a non-Gaussian distribution of\nstress components, whereas Weibull-like distributions for equivalent residual\nstress. Nevertheless, the assumed Gaussian distribution in mean-field estimates\ncaptures the essential features.", "AI": {"tldr": "This paper presents a mean-field homogenization (MFH) method to efficiently estimate second moments of local stress fields in thermo-elastic composites, validated against computationally intensive full-field simulations.", "motivation": "Local field fluctuations are critical for predicting failure and inelastic behavior in random composites, but full-field methods are computationally expensive and limited in scalability to complex microstructures.", "method": "Developed analytical expressions based on Hill-Mandel condition to calculate second moments of local fields for linear thermo-elastic problems using MFH, relying on derivatives of Hill's polarization tensor from previous work.", "result": "MFH successfully captured essential features of stress distributions compared to full-field simulations, which showed non-Gaussian stress components and Weibull-like distributions for equivalent residual stress.", "conclusion": "The mean-field approach with assumed Gaussian distribution provides efficient and reasonably accurate estimation of field fluctuations, offering a practical alternative to computationally intensive full-field methods."}}
{"id": "2509.00668", "pdf": "https://arxiv.org/pdf/2509.00668", "abs": "https://arxiv.org/abs/2509.00668", "authors": ["Hwi Lee", "Yingjie Liu"], "title": "A level-set based finite difference method for the ground state Bose-Einstein condensates in smooth bounded domains", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We present a level-set based finite difference method to calculate the ground\nstates of Bose Einstein condensates in domains with curved boundaries. Our\nmethod draws on the variational and level set approaches, benefiting from both\nof their long-standing success. More specifically, we use the normalized\ngradient flow, where the spatial discretization is based on the simple\nCartesian grid with fictitious values in the outer vicinity of the domains. We\ndevelop a PDE-based extension technique that systematically and automatically\nconstructs ghost point values with third-order accuracy near irregular\nboundaries, effectively circumventing the computational complexity of\ninterpolation in these regions. Another novel aspect of our work is the\napplication of the PDE-based extension technique to a nodal basis function,\nresulting in an explicit ghost value mapping that can be seamlessly\nincorporated into implicit time-stepping methods where the extended function\nvalues are treated as unknowns at the next time step. We present numerical\nexamples to demonstrate the effectiveness of our method, including its\napplication to domains with corners and to problems involving higher-order\ninteraction terms.", "AI": {"tldr": "A level-set finite difference method for computing Bose-Einstein condensate ground states in curved domains using Cartesian grids with ghost points and PDE-based extension techniques.", "motivation": "To develop an efficient computational method for solving Bose-Einstein condensate ground state problems in domains with complex curved boundaries, overcoming the challenges of traditional interpolation methods near irregular boundaries.", "method": "Uses normalized gradient flow with Cartesian grid discretization, PDE-based extension technique for third-order accurate ghost point values near boundaries, and explicit ghost value mapping for seamless integration with implicit time-stepping methods.", "result": "The method effectively handles domains with curved boundaries and corners, demonstrating third-order accuracy and computational efficiency while avoiding complex interpolation procedures.", "conclusion": "The proposed level-set based finite difference method provides an accurate and efficient approach for computing ground states of Bose-Einstein condensates in complex domains, with potential applications to problems involving higher-order interaction terms."}}
{"id": "2509.00726", "pdf": "https://arxiv.org/pdf/2509.00726", "abs": "https://arxiv.org/abs/2509.00726", "authors": ["Gianni Dal Maso", "Rita Ferreira", "Irene Fonseca"], "title": "$\u0393$-convergence and stochastic homogenization for functionals in the $\\mathcal{A}$-free setting", "categories": ["math.AP", "35B27, 60H30, 49J45, 74A40"], "comment": "31 pages", "summary": "We obtain a compactness result for $\\Gamma$-convergence of integral\nfunctionals defined on $\\mathcal{A}$-free vector fields. This is used to study\nhomogenization problems for these functionals without periodicity assumptions.\nMore precisely, we prove that the homogenized integrand can be obtained by\ntaking limits of minimum values of suitable minimization problems on large\ncubes, when the side length of these cubes tends to $+\\infty$, assuming that\nthese limit values do not depend on the center of the cube. Under the usual\nstochastic periodicity assumptions, this result is then used to solve the\nstochastic homogenization problem by means of the subadditive ergodic theorem.", "AI": {"tldr": "Compactness result for \u0393-convergence of integral functionals on A-free vector fields, enabling homogenization without periodicity assumptions by taking limits of minimization problems on large cubes.", "motivation": "To study homogenization problems for integral functionals defined on A-free vector fields without requiring periodicity assumptions, which extends classical homogenization theory to more general settings.", "method": "Prove compactness for \u0393-convergence, then obtain homogenized integrand by taking limits of minimum values from minimization problems on large cubes as side length tends to infinity, assuming limit values are independent of cube center.", "result": "Established that homogenized integrand can be derived through limit procedures on large cubes, and under stochastic periodicity assumptions, solved stochastic homogenization problem using subadditive ergodic theorem.", "conclusion": "The approach provides a framework for homogenization of A-free vector field functionals without periodicity, with applications to stochastic homogenization through ergodic methods."}}
{"id": "2509.01502", "pdf": "https://arxiv.org/pdf/2509.01502", "abs": "https://arxiv.org/abs/2509.01502", "authors": ["Sui Wan", "Ping Zhu", "Linjin Zheng"], "title": "Effects of reversed magnetic shear on the plasma rotation stabilization of resistive wall modes in tokamaks", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Effects of reversed magnetic shear on the plasma rotation stabilization of\nresistive wall modes in tokamaks are investigated using the AEGIS code. MHD\nequilibria in toroidal configuration from circular cross-sections to realistic\nCFETR-like scenarios with various magnetic shear profiles are considered. Two\ncritical aspects of the $n=1$ RWM are examined: the influence of toroidal\nrotation on the unstable regime and the toroidal rotation frequency thresholds\nrequired for complete stabilization. It is found that strongly reversed\nmagnetic shear consistently broadens the unstable $\\beta_{\\rm N}$ window in\nboth circular and CFETR equilibria when toroidal rotation is included.\nFurthermore, reversed magnetic shear significantly reduces the rotational\nstabilization, resulting in narrower stability windows and notably higher\ntoroidal rotation frequency thresholds required for complete RWM suppression\ncompared to the cases with positive shear only. These results clearly\ndemonstrate that the reversed magnetic shear in the advanced tokamak\nconfiguration imposes more stringent requirement for the effective toroidal\nrotation stabilization of the $n=1$ RWM.", "AI": {"tldr": "Reversed magnetic shear worsens resistive wall mode stabilization in tokamaks, requiring higher rotation speeds and narrowing stability windows compared to positive shear configurations.", "motivation": "To understand how reversed magnetic shear affects plasma rotation stabilization of resistive wall modes (RWMs) in tokamak fusion devices, particularly for advanced configurations like CFETR.", "method": "Used AEGIS code to analyze MHD equilibria from circular cross-sections to realistic CFETR-like scenarios with various magnetic shear profiles, examining n=1 RWM stability under toroidal rotation.", "result": "Strongly reversed magnetic shear broadens the unstable beta_N window and significantly reduces rotational stabilization, requiring notably higher toroidal rotation frequency thresholds for complete RWM suppression.", "conclusion": "Reversed magnetic shear imposes more stringent requirements for effective toroidal rotation stabilization of n=1 RWMs in advanced tokamak configurations."}}
{"id": "2509.00867", "pdf": "https://arxiv.org/pdf/2509.00867", "abs": "https://arxiv.org/abs/2509.00867", "authors": ["Wen You", "Shaoqian Zhou", "Xuhui Meng"], "title": "Self-supervised neural operator for solving partial differential equations", "categories": ["physics.comp-ph"], "comment": null, "summary": "Neural operators (NOs) provide a new paradigm for efficiently solving partial\ndifferential equations (PDEs), but their training depends on costly\nhigh-fidelity data from numerical solvers, limiting applications in complex\nsystems. We propose a self-supervised neural operator (SNO) that generates\naccurate and diverse training data on the fly without numerical solvers. SNO\nconsists of three parts: a physics-informed sampler (PI-sampler) based on\nBayesian PINNs for efficient data generation, a function encoder (FE) for\ncompact input-output representations, and an encoder-only Transformer for\noperator learning, mapping boundary/initial conditions, source terms, and\ngeometries to PDE solutions. We validate SNO on 1D steady/unsteady nonlinear\nreaction-diffusion equations, a 2D nonlinear PDE with varying geometries, and\nvortex-induced vibration of a flexible cylinder in fluid dynamics. SNO achieves\nhigh accuracy in all cases, and lightweight finetuning (O(100) trainable\nvariables) further improves predictions with only a few hundred steps. This\nwork provides a new route toward pretrained foundation models as efficient PDE\nsurrogates.", "AI": {"tldr": "Self-supervised neural operator (SNO) that generates training data on-the-fly without numerical solvers, using physics-informed sampling and encoder-only Transformer for PDE solving.", "motivation": "Neural operators require costly high-fidelity data from numerical solvers, limiting applications in complex systems. Need self-supervised approach to eliminate dependency on solver data.", "method": "Three-part architecture: 1) Physics-informed sampler based on Bayesian PINNs for data generation, 2) Function encoder for compact representations, 3) Encoder-only Transformer for operator learning mapping boundary conditions to PDE solutions.", "result": "High accuracy achieved on 1D/2D nonlinear PDEs and fluid dynamics problems. Lightweight finetuning (O(100) variables) improves predictions with few hundred steps.", "conclusion": "Provides new route toward pretrained foundation models as efficient PDE surrogates without numerical solver dependency."}}
{"id": "2509.00794", "pdf": "https://arxiv.org/pdf/2509.00794", "abs": "https://arxiv.org/abs/2509.00794", "authors": ["R. N. K\u00f6hle", "K. T. W. Menting", "K. Mitra", "J. H. M. ten Thije Boonkkamp"], "title": "Robust and fast iterative method for the elliptic Monge-Amp\u00e8re equation", "categories": ["math.NA", "cs.NA", "math.AP", "35J96, 65J15, 47J25, 65F08"], "comment": "27 pages, 8 figures", "summary": "This paper introduces a fast and robust iterative scheme for the elliptic\nMonge-Amp\\`ere equation with Dirichlet boundary conditions. The Monge-Amp\\`ere\nequation is a nonlinear and degenerate equation, with applications in optimal\ntransport, geometric optics, and differential geometry. The proposed method\nlinearises the equation and uses a fixed-point iteration (L-scheme), solving a\nPoisson problem in each step with a weighted residual as the right-hand side.\nThis algorithm is robust against discretisation, nonlinearities, and\ndegeneracies. For a weight greater than the largest eigenvalue of the Hessian,\ncontraction in $H^2$ and $L^\\infty$ is proven for both classical and\ngeneralised solutions, respectively. The method's performance can be enhanced\nby using preconditioners or Green's functions. Test cases demonstrate that the\nscheme outperforms Newton's method in speed and stability.", "AI": {"tldr": "Fast iterative scheme for elliptic Monge-Amp\u00e8re equation using linearization and fixed-point iteration with Poisson solves", "motivation": "The Monge-Amp\u00e8re equation is nonlinear and degenerate but has important applications in optimal transport, geometric optics, and differential geometry, requiring robust numerical methods", "method": "Linearizes the equation using fixed-point iteration (L-scheme), solving a Poisson problem in each step with weighted residual as right-hand side", "result": "Proven contraction in H\u00b2 and L\u221e for weight greater than largest Hessian eigenvalue; outperforms Newton's method in speed and stability in test cases", "conclusion": "The proposed iterative scheme is robust against discretization, nonlinearities, and degeneracies, with performance enhanced by preconditioners or Green's functions"}}
{"id": "2509.00750", "pdf": "https://arxiv.org/pdf/2509.00750", "abs": "https://arxiv.org/abs/2509.00750", "authors": ["Guodong Wang"], "title": "Orbital Stability of First Laplacian Eigenstates for the Euler Equation on Flat 2-Tori", "categories": ["math.AP"], "comment": null, "summary": "On a two-dimensional flat torus, the Laplacian eigenfunctions can be\nexpressed explicitly in terms of sinusoidal functions. For a rectangular or\nsquare torus, it is known that every first eigenstate is orbitally stable up to\ntranslation under the Euler dynamics. In this paper, we extend this result to\nflat tori of arbitrary shape. As a consequence, we obtain for the first time a\nfamily of orbitally stable sinusoidal Euler flows on a hexagonal torus. The\nproof is carried out within the framework of Burton's stability criterion and\nconsists of two key ingredients: (i) establishing a suitable variational\ncharacterization for each equimeasurable class in the first eigenspace, and\n(ii) analyzing the number of translational orbits within each equimeasurable\nclass. The second ingredient, particularly for the case of a hexagonal torus,\nis very challenging, as it requires analyzing a sophisticated system of\npolynomial equations related to the symmetry of the torus and the structure of\nthe first eigenspace.", "AI": {"tldr": "Extension of orbital stability results for first Laplacian eigenstates from rectangular/square tori to arbitrary flat tori, including hexagonal tori, under Euler dynamics.", "motivation": "Previous work showed orbital stability of first eigenstates on rectangular/square tori, but the stability on arbitrary flat tori (particularly hexagonal) remained an open problem that needed generalization.", "method": "Using Burton's stability criterion framework with two key steps: (1) variational characterization for equimeasurable classes in first eigenspace, (2) analysis of translational orbits within each equimeasurable class, involving complex polynomial equations for hexagonal torus symmetry.", "result": "Successfully proved orbital stability for first eigenstates on arbitrary flat tori, obtaining the first family of orbitally stable sinusoidal Euler flows on hexagonal tori.", "conclusion": "The framework extends stability results to general flat tori, with the hexagonal case presenting particularly challenging mathematical problems involving symmetry analysis and polynomial systems."}}
{"id": "2509.01741", "pdf": "https://arxiv.org/pdf/2509.01741", "abs": "https://arxiv.org/abs/2509.01741", "authors": ["Nour El Houda Hissi", "Gregory K. Ngirmang", "Joseph Smith", "Enam A. Chowdhury"], "title": "Forward and Backward Electron Acceleration by Radially Polarized Ultra-Intense Laser Focus Seeded By Field Ionization of High Charge States of Neon", "categories": ["physics.plasm-ph", "physics.atom-ph"], "comment": null, "summary": "Thanks to the fabrication of large aperture phase optics, ultra-intense\nrelativistic laser plasma interaction (RLPI) experiments with complex\npolarization states are becoming feasible. In this work, we perform a\ncomputational investigation of direct acceleration of electrons produced during\nionization of underdense neon gas using a tightly focused and radially\npolarized Petawatt-class short pulse lasers by numerically solving the\nrelativistically invariant Lorentz equations, incorporating semi-classical\ntunneling ionization and Monte Carlo type sampling of the focal volume. The\naccelerated electrons energy gain increases at longer laser wavelengths and GeV\nenergies are reached for electrons ionized from the neon inner shells, which\nare field ionized near the peak of the pulse. Backward acceleration of\nelectrons is observed for a range of initial positions and phases of ionization\nof neon charge states. This apparent counterintuitive phenomenon is directly\nlinked to the radial polarization state of the incident laser beam that results\nin a strong longitudinal electric field Ez when tightly focused, where\nelectrons ionized near the focal center at the phase when Ez is pointed toward\nthe forward propagation direction experiences an initial push in the backward\ndirection. A parametric study of the phenomenon by varying laser parameters is\npresented, and a 3D particle in cell (PIC) simulation is considered to confirm\nthe existence of this phenomenon.", "AI": {"tldr": "Computational study shows backward electron acceleration in radially polarized laser beams due to strong longitudinal electric fields, with GeV energies achieved for inner shell neon electrons.", "motivation": "With advances in large aperture phase optics enabling ultra-intense laser plasma experiments with complex polarization states, this research investigates electron acceleration phenomena in radially polarized Petawatt-class lasers.", "method": "Numerically solved relativistically invariant Lorentz equations with semi-classical tunneling ionization and Monte Carlo sampling of focal volume. Conducted parametric study of laser parameters and performed 3D particle-in-cell (PIC) simulations for validation.", "result": "Electrons reached GeV energies, particularly those ionized from neon inner shells near pulse peak. Counterintuitive backward acceleration observed due to radial polarization creating strong longitudinal electric field Ez that initially pushes electrons backward when ionized at specific phases.", "conclusion": "Radially polarized laser beams produce unique backward electron acceleration phenomena through strong longitudinal electric fields, with significant energy gains observed at longer wavelengths, opening new possibilities for laser-plasma interaction experiments."}}
{"id": "2509.00966", "pdf": "https://arxiv.org/pdf/2509.00966", "abs": "https://arxiv.org/abs/2509.00966", "authors": ["Taufeq Mohammed Razakh", "Thomas Linker", "Ye Luo", "Nariman Piroozan", "John Pennycook", "Nalini Kumar", "Albert Musaelian", "Anders Johansson", "Boris Kozinsky", "Rajiv K. Kalia", "Priya Vashishta", "Fuyuki Shimojo", "Shinnosuke Hattori", "Ken-ichi Nomura", "Aiichiro Nakano"], "title": "Multiscale light-matter dynamics in quantum materials: from electrons to topological superlattices", "categories": ["physics.comp-ph"], "comment": null, "summary": "Light-matter dynamics in topological quantum materials enables\nultralow-power, ultrafast devices. A challenge is simulating multiple field and\nparticle equations for light, electrons, and atoms over vast spatiotemporal\nscales on Exaflop/s computers with increased heterogeneity and low-precision\nfocus. We present a paradigm shift that solves the\nmultiscale/multiphysics/heterogeneity challenge harnessing hardware\nheterogeneity and low-precision arithmetic. Divide-conquer-recombine algorithms\ndivide the problem into not only spatial but also physical subproblems of small\ndynamic ranges and minimal mutual information, which are mapped onto\nbest-characteristics-matching hardware units, while metamodel-space algebra\nminimizes communication and precision requirements. Using 60,000 GPUs of\nAurora, DC-MESH (divide-and-conquer Maxwell-Ehrenfest-surface hopping) and\nXS-NNQMD (excited-state neural-network quantum molecular dynamics) modules of\nMLMD (multiscale light-matter dynamics) software were 152- and 3,780-times\nfaster than the state-of-the-art for 15.4 million-electron and 1.23\ntrillion-atom PbTiO3 material, achieving 1.87 EFLOP/s for the former. This\nenabled the first study of light-induced switching of topological superlattices\nfor future ferroelectric 'topotronics'.", "AI": {"tldr": "A new computational paradigm using hardware heterogeneity and low-precision arithmetic achieves massive speedups for simulating light-matter dynamics in topological quantum materials, enabling the first study of light-induced switching in topological superlattices.", "motivation": "To overcome the challenge of simulating multiple field and particle equations for light, electrons, and atoms over vast spatiotemporal scales on modern heterogeneous computers with low-precision focus, particularly for topological quantum materials.", "method": "Divide-conquer-recombine algorithms that partition problems into physical subproblems with small dynamic ranges, mapped onto best-matching hardware units, combined with metamodel-space algebra to minimize communication and precision requirements.", "result": "Achieved 152x and 3,780x speedups over state-of-the-art for 15.4 million-electron and 1.23 trillion-atom PbTiO3 material simulations, reaching 1.87 EFLOP/s performance on 60,000 GPUs of Aurora supercomputer.", "conclusion": "The approach enables the first study of light-induced switching of topological superlattices, paving the way for future ferroelectric 'topotronics' devices with ultralow-power and ultrafast operation."}}
{"id": "2509.00805", "pdf": "https://arxiv.org/pdf/2509.00805", "abs": "https://arxiv.org/abs/2509.00805", "authors": ["Wei Guo", "Zhichao Peng"], "title": "An Inexact Low-Rank Source Iteration for Steady-State Radiative Transfer Equation with Diffusion Synthetic Acceleration", "categories": ["math.NA", "cs.NA"], "comment": "29 pages, 15 figures", "summary": "We propose an inexact low-rank source iteration with diffusion synthetic\nacceleration (SI-DSA) for solving the multidimensional steady-state radiative\ntransfer equation (RTE) in the second-order formulation. The angular flux is\nrepresented in either a low-rank matrix or hierarchical Tucker tensor (HTT)\nformat, enabling substantial reductions in computational resources. Each SI\nstep is solved using a preconditioned low-rank conjugate gradient (CG) method\nwith a diffusion preconditioner. To further improve efficiency, we introduce an\nadaptive inexact strategy that dynamically relaxes the inner CG tolerance\nduring early SI iterations. The method exploits the tensor-product structure of\nthe discretized operators to perform all matrix-vector operations in low-rank\nform. Numerical experiments on 2D2V benchmark problems, including\ndiffusion-dominated, transport-dominated, and multiscale problems, demonstrate\nthat the proposed approach achieves errors on the order of $10^{-4}$ to\n$10^{-5}$ relative to full-rank reference solutions, while reducing the degrees\nof freedom by up to two orders of magnitude. In the diffusion-dominated case,\nthe low-rank solver achieves speedups exceeding $90\\times$ over its full-rank\ncounterpart and remains competitive in solving challenging transport-dominated\nand multiscale problems while providing substantial storage savings. To our\nknowledge, this work provides the first low-rank SI-DSA framework for\nmultidimensional steady-state RTE.", "AI": {"tldr": "Inexact low-rank source iteration with diffusion synthetic acceleration for solving multidimensional radiative transfer equations, achieving 90x speedup and 100x storage reduction.", "motivation": "To solve multidimensional steady-state radiative transfer equations more efficiently by reducing computational resources through low-rank representations.", "method": "Uses low-rank matrix or hierarchical Tucker tensor format for angular flux representation, preconditioned low-rank conjugate gradient method with diffusion preconditioner, and adaptive inexact strategy with dynamic tolerance relaxation.", "result": "Achieves errors of 10^-4 to 10^-5 relative to full-rank solutions, reduces degrees of freedom by up to 100x, and achieves over 90x speedup in diffusion-dominated cases while remaining competitive in transport-dominated problems.", "conclusion": "First low-rank SI-DSA framework for multidimensional steady-state RTE that provides substantial computational and storage efficiency gains across various problem types."}}
{"id": "2509.00814", "pdf": "https://arxiv.org/pdf/2509.00814", "abs": "https://arxiv.org/abs/2509.00814", "authors": ["Wei Dai", "Jingze Fu", "An Zhang"], "title": "Sharp gradient stability for a class of Hardy-Sobolev-Maz'ya inequalities", "categories": ["math.AP", "math.CA"], "comment": "48 pages, no figure", "summary": "This paper investigates the stability problem for a class of\nHardy-Sobolev-Maz'ya inequalities with non-radial extremal functions. We prove\nthat the Euler-Lagrange equations are non-degenerate and obtain a sharp global\nquantitative stability. The presence of partial (stronger) singular weight\nbrings substantial new challenges, requiring us to significantly refine the\ntechniques from \\cite{DT1,FN,FZ} and introduce some new ideas to handle both\nthe cylindrical symmetry of non-radial extremal functions and the partial\n(stronger) singular weight structure. Key technical innovations include new\ncompact embedding with strong singularity and new refined spectral inequalities\nthat are crucial for our analysis.", "AI": {"tldr": "Stability analysis for Hardy-Sobolev-Maz'ya inequalities with non-radial extremal functions, proving non-degeneracy and sharp global quantitative stability.", "motivation": "To address the stability problem for Hardy-Sobolev-Maz'ya inequalities that have non-radial extremal functions, particularly dealing with challenges posed by partial (stronger) singular weights.", "method": "Refined techniques from previous works and introduced new ideas to handle cylindrical symmetry of non-radial extremal functions and partial singular weight structure. Key innovations include new compact embedding with strong singularity and refined spectral inequalities.", "result": "Proved that Euler-Lagrange equations are non-degenerate and obtained sharp global quantitative stability for the inequalities.", "conclusion": "The paper successfully addresses substantial challenges from partial singular weights and non-radial extremal functions, providing important stability results with novel technical approaches."}}
{"id": "2509.01789", "pdf": "https://arxiv.org/pdf/2509.01789", "abs": "https://arxiv.org/abs/2509.01789", "authors": ["Pedro Cavestany", "Alasdair Ross", "Adriano Agnello", "Aran Garrod", "Nicola C. Amorisco", "George K. Holt", "Kamran Pentland", "James Buchanan"], "title": "Real-Time Applicability of Emulated Virtual Circuits for Tokamak Plasma Shape Control", "categories": ["physics.plasm-ph", "cs.LG", "cs.SY", "eess.SY", "physics.data-an", "I.2; I.6"], "comment": "6 pages, 4 figures, as submitted to CCTA25", "summary": "Machine learning has recently been adopted to emulate sensitivity matrices\nfor real-time magnetic control of tokamak plasmas. However, these approaches\nwould benefit from a quantification of possible inaccuracies. We report on two\naspects of real-time applicability of emulators. First, we quantify the\nagreement of target displacement from VCs computed via Jacobians of the shape\nemulators with those from finite differences Jacobians on exact Grad-Shafranov\nsolutions. Good agreement ($\\approx$5-10%) can be achieved on a selection of\ngeometric targets using combinations of neural network emulators with\n$\\approx10^5$ parameters. A sample of $\\approx10^{5}-10^{6}$ synthetic\nequilibria is essential to train emulators that are not over-regularised or\noverfitting. Smaller models trained on the shape targets may be further\nfine-tuned to better fit the Jacobians. Second, we address the effect of vessel\ncurrents that are not directly measured in real-time and are typically subsumed\ninto effective \"shaping currents\" when designing virtual circuits. We\ndemonstrate that shaping currents can be inferred via simple linear regression\non a trailing window of active coil current measurements with residuals of only\na few Amp\\`eres, enabling a choice for the most appropriate shaping currents at\nany point in a shot. While these results are based on historic shot data and\nsimulations tailored to MAST-U, they indicate that emulators with\nfew-millisecond latency can be developed for robust real-time plasma shape\ncontrol in existing and upcoming tokamaks.", "AI": {"tldr": "Machine learning emulators for tokamak plasma control achieve 5-10% accuracy with neural networks trained on 100k-1M synthetic equilibria, and vessel currents can be inferred via linear regression with few-Ampere residuals.", "motivation": "To improve real-time magnetic control of tokamak plasmas by quantifying emulator accuracy and addressing unmeasured vessel currents for robust shape control.", "method": "Used neural network emulators with ~100k parameters trained on large synthetic equilibrium datasets, compared Jacobians with finite differences on exact solutions, and employed linear regression on trailing coil current measurements to infer shaping currents.", "result": "Achieved 5-10% agreement on geometric targets, demonstrated that shaping currents can be inferred with few-Ampere residuals, and showed emulators can achieve few-millisecond latency.", "conclusion": "Machine learning emulators can be developed for robust real-time plasma shape control in existing and future tokamaks with appropriate training data and current inference methods."}}
{"id": "2509.01296", "pdf": "https://arxiv.org/pdf/2509.01296", "abs": "https://arxiv.org/abs/2509.01296", "authors": ["Mengjie Zu", "Carl P. Goodrich"], "title": "Learning by training: emergent return-point memory from cyclically tuning disordered sphere packings", "categories": ["physics.comp-ph", "cond-mat.dis-nn", "cond-mat.soft"], "comment": null, "summary": "Many living and artificial systems improve their fitness or performance by\nadapting to changing environments or diverse training data. However, it remains\nunclear how such environmental variation influences adaptation, what is learned\nin the process, and whether memory of past conditions is retained. In this\nwork, we investigate these questions using athermal disordered systems that are\nsubject to cyclic inverse design, enabling them to attain target elastic\nproperties spanning a chosen range. We demonstrate that such systems evolve\ntoward a marginally absorbing manifold (MAM), which encodes memory of the\ntraining range that closely resembles return-point memory observed in\ncyclically driven systems. We further propose a general mechanism for the\nformation of MAMs and the corresponding memory that is based on gradient\ndiscontinuities in the trained quantities. Our model provides a simple and\nbroadly applicable physical framework for understanding how adaptive systems\nlearn under environmental change and how they retain memory of past\nexperiences.", "AI": {"tldr": "Systems adapt to changing environments through cyclic inverse design, evolving toward a marginally absorbing manifold that encodes memory of training ranges, resembling return-point memory in driven systems.", "motivation": "To understand how environmental variation influences adaptation, what is learned during the process, and whether memory of past conditions is retained in adaptive systems.", "method": "Using athermal disordered systems subjected to cyclic inverse design to attain target elastic properties across a chosen range, and analyzing the formation of marginally absorbing manifolds.", "result": "Systems evolve toward a marginally absorbing manifold (MAM) that encodes memory of the training range, closely resembling return-point memory observed in cyclically driven systems.", "conclusion": "The proposed model provides a simple and broadly applicable physical framework for understanding how adaptive systems learn under environmental change and retain memory of past experiences."}}
{"id": "2509.00847", "pdf": "https://arxiv.org/pdf/2509.00847", "abs": "https://arxiv.org/abs/2509.00847", "authors": ["Dimitri Breda", "Simone De Reggi", "Jordi Ripoll"], "title": "On the numerical computation of $R_0$ in periodic environments", "categories": ["math.NA", "cs.NA", "math.DS", "34L16, 37N25, 41A10, 47D06, 47B07, 65L60, 65L70, 92D25"], "comment": "29 pages, 5 figures", "summary": "We propose a novel approach to approximate the basic reproduction number\n$R_0$ as spectral radius of the Next-Generation Operator in time-periodic\npopulation models by characterizing the latter via evolution semigroups. Once\nbirth/infection and transition operators are identified, we discretize them via\neither Fourier or Chebyshev collocation methods. Then $R_0$ is obtained by\nsolving a generalized matrix eigenvalue problem. The order of convergence of\nthe approximating reproduction numbers to the true one is shown to depend on\nthe regularity of the model coefficients, and spectral accuracy is proved. We\nvalidate the theoretical results by discussing applications to epidemiology,\nviz. a large-size multi-group epidemic model with periodic contact rates, and a\nvector-borne disease model with seasonal vector recruitment. We illustrate how\nthe method facilitates implementation compared to existing approaches and how\nit can be easily adapted to also compute type-reproduction numbers.", "AI": {"tldr": "A novel spectral method using evolution semigroups to approximate R0 in periodic epidemic models via Fourier/Chebyshev discretization, achieving spectral accuracy with validation on multi-group and vector-borne disease models.", "motivation": "Existing approaches for computing the basic reproduction number R0 in time-periodic population models can be complex to implement. The paper aims to develop a more straightforward method that characterizes R0 via evolution semigroups and provides efficient numerical approximation.", "method": "Characterize the Next-Generation Operator via evolution semigroups, identify birth/infection and transition operators, discretize them using Fourier or Chebyshev collocation methods, and solve a generalized matrix eigenvalue problem to obtain R0.", "result": "The method achieves spectral accuracy with convergence order depending on model coefficient regularity. Validated on multi-group epidemic models with periodic contact rates and seasonal vector-borne disease models, showing improved implementation ease compared to existing approaches.", "conclusion": "The proposed evolution semigroup approach provides an efficient and accurate method for computing R0 in periodic epidemic models, with easy implementation and adaptability to compute type-reproduction numbers as well."}}
{"id": "2509.00817", "pdf": "https://arxiv.org/pdf/2509.00817", "abs": "https://arxiv.org/abs/2509.00817", "authors": ["Souvik Bhowmick", "Sekhar Ghosh", "Vishvesh Kumar"], "title": "Superlinear problems involving nonlinear superposition operators of mixed fractional order", "categories": ["math.AP", "35M12, 35J60, 35R11, 35A15, 35S15, 35J60"], "comment": "23 pages", "summary": "In this work, we study a class of elliptic problems involving nonlinear\nsuperpositions of fractional operators of the form \\[ A_{\\mu,p}u :=\n\\int_{[0,1]} (-\\Delta)_{p}^{s} u \\, d\\mu(s), \\] where $\\mu$ is a signed measure\non $[0,1]$, coupled with nonlinearities of superlinear type. Our analysis\ncovers a variety of superlinear growth assumptions, beginning with the\nclassical Ambrosetti--Rabinowitz condition. Within this framework, we construct\na suitable variational setting and apply the Fountain Theorem to establish the\nexistence of infinitely many weak solutions. The results obtained are novel\neven in the special cases of superpositions of fractional $p$-Laplacians, or\ncombinations of the fractional $p$-Laplacian with the $p$-Laplacian. More\ngenerally, our approach applies to finite sums of fractional $p$-Laplacians\nwith different orders, as well as to operators in which fractional Laplacians\nappear with ``wrong'' signs. A distinctive contribution of the paper lies in\nproviding a unified variational framework that systematically accommodates this\nbroad class of operators.", "AI": {"tldr": "Study of elliptic problems with nonlinear superpositions of fractional operators and superlinear nonlinearities, establishing existence of infinitely many weak solutions using variational methods.", "motivation": "To develop a unified variational framework for analyzing elliptic problems involving complex superpositions of fractional operators with different orders and signs, which haven't been systematically studied before.", "method": "Constructed a suitable variational setting and applied the Fountain Theorem to establish the existence of infinitely many weak solutions. The approach covers various superlinear growth assumptions including the classical Ambrosetti-Rabinowitz condition.", "result": "Proved the existence of infinitely many weak solutions for this broad class of operators. The results are novel even for special cases like superpositions of fractional p-Laplacians or combinations with p-Laplacians.", "conclusion": "Provides a unified variational framework that systematically accommodates a broad class of operators including finite sums of fractional p-Laplacians with different orders and operators with fractional Laplacians having 'wrong' signs."}}
{"id": "2509.02214", "pdf": "https://arxiv.org/pdf/2509.02214", "abs": "https://arxiv.org/abs/2509.02214", "authors": ["G. S. Kurskiev", "V. B. Minaev", "N. V. Sakharov", "V. K. Gusev", "Yu. V. Petrov", "I. V. Miroshnikov", "F. V. Chernyshev", "N. N. Bakharev", "E. O. Kiselev", "A. Yu. Telnova", "E. E. Tkachenko", "N. S. Zhiltsov", "Globus- M2 Team"], "title": "Hot-Ion Modes in Globus-M2 and Saturation of Energy Confinement Time Scaling in Spherical Tokamaks with Toroidal Magnetic Field of 1 T and Above", "categories": ["physics.plasm-ph"], "comment": null, "summary": "In a small spherical tokamak with minor radius of 0.22 m and toroidal\nmagnetic field of 1 T, it is possible to heat ions of a sufficiently dense\nplasma to an extremely high temperature up to 50 million Kelvin. To do this, it\nis necessary to transfer a sufficiently large torque to stabilize ion-scale\nturbulence and achieve ion heat transport at neoclassical level reaching\nextremely low values of plasma collisionality. It is also necessary to ensure\ngood thermal insulation of electrons, which is always determined by turbulent\ntransport. In a spherical tokamak, the toroidal magnetic field has a strong\nbeneficial effect on suppressing turbulent electron heat fluxes. In the\nGlobus-M2 tokamak, when heating plasma with high-energy atomic beams, a\nsignificant improvement in the plasma thermal energy confinement is observed\nwith an increase in the toroidal magnetic field from 0.5 to 1 T. The comparison\nof our results with experiments on ST40 tokamak operating with toroidal\nmagnetic field of 2 T indicates that further strong improvement of thermal\ninsulation of spherical tokamak plasma in the region of higher magnetic fields\nis not expected.", "AI": {"tldr": "Spherical tokamaks can achieve extremely high ion temperatures (up to 50 million K) with proper torque transfer and magnetic field optimization, but electron thermal insulation improvements plateau above 1T magnetic fields.", "motivation": "To explore how spherical tokamaks can achieve extremely high ion temperatures through optimized magnetic field configurations and turbulence control for improved plasma confinement.", "method": "Experimental study using the Globus-M2 spherical tokamak with minor radius of 0.22m, varying toroidal magnetic fields from 0.5T to 1T, and comparing results with ST40 tokamak operating at 2T. High-energy atomic beam heating was used to study plasma thermal energy confinement.", "result": "Significant improvement in plasma thermal energy confinement observed when increasing toroidal magnetic field from 0.5T to 1T. Ion temperatures up to 50 million Kelvin achieved with proper torque transfer to stabilize turbulence. However, comparison with ST40 at 2T indicates no further strong improvement in thermal insulation at higher magnetic fields.", "conclusion": "Spherical tokamaks can reach extremely high ion temperatures through optimized magnetic fields and turbulence control, but electron thermal insulation improvements reach a plateau around 1T, suggesting diminishing returns for further magnetic field increases."}}
{"id": "2509.01636", "pdf": "https://arxiv.org/pdf/2509.01636", "abs": "https://arxiv.org/abs/2509.01636", "authors": ["Ankush Gogoi", "Vikram Pakrashi", "Joanna A. Zielinska"], "title": "Explaining Optomechanical Libration Spectra: A Stochastic Simulation Approach", "categories": ["physics.comp-ph"], "comment": null, "summary": "We present a practical and computationally effective Ito-Taylor expansion\nbased stochastic simulation framework for modeling rotational optomechanics\nexperiments. By developing a model using this framework, we could capture the\nnonlinear orientation dynamics of an optically levitated, nearly cylindrically\nsymmetric nanodumbbell. It successfully reproduces and explains shoulder-like\nfeatures observed in the power spectral density of libration, which we show\narising from the interplay between confined libration and thermally driven\nrotation around the particle symmetry axis.", "AI": {"tldr": "Ito-Taylor expansion framework for simulating rotational optomechanics experiments, explaining nonlinear orientation dynamics and spectral features in nanodumbbell systems.", "motivation": "To develop a practical computational framework for modeling complex rotational dynamics in optomechanics experiments, particularly to explain observed spectral features that existing models couldn't capture.", "method": "Developed an Ito-Taylor expansion based stochastic simulation framework to model nonlinear orientation dynamics of optically levitated cylindrically symmetric nanodumbbells.", "result": "Successfully reproduced and explained shoulder-like features in power spectral density of libration, showing they arise from interplay between confined libration and thermally driven rotation around symmetry axis.", "conclusion": "The Ito-Taylor expansion framework provides an effective computational approach for simulating and understanding complex rotational dynamics in optomechanical systems, particularly for explaining previously unexplained spectral features."}}
{"id": "2509.00932", "pdf": "https://arxiv.org/pdf/2509.00932", "abs": "https://arxiv.org/abs/2509.00932", "authors": ["Andrei Draganescu", "L. Ridgway Scott"], "title": "Sufficient conditions for strong discrete maximum principles in finite element solutions of linear and semilinear elliptic equations", "categories": ["math.NA", "cs.NA", "65N30"], "comment": "35 pages, 12 figures", "summary": "We introduce a novel technique for proving global strong discrete maximum\nprinciples for finite element discretizations of linear and semilinear elliptic\nequations for cases when the common, matrix-based sufficient conditions are not\nsatisfied. The basic argument consists of extending the strong form of discrete\nmaximum principle from macroelements to the entire domain via a connectivity\nargument. The method is applied to discretizations of elliptic equations with\ncertain pathological meshes, and to semilinear elliptic equations.", "AI": {"tldr": "Novel technique proves global strong discrete maximum principles for finite element discretizations when standard matrix-based conditions fail, using macroelement extension and connectivity arguments.", "motivation": "Existing matrix-based sufficient conditions for discrete maximum principles are often not satisfied, requiring alternative approaches to prove these fundamental properties for finite element methods.", "method": "Extends strong form of discrete maximum principle from macroelements to entire domain using connectivity arguments, applied to elliptic equations with pathological meshes and semilinear cases.", "result": "Successfully establishes global strong discrete maximum principles for finite element discretizations that would otherwise fail standard matrix-based verification conditions.", "conclusion": "The connectivity-based approach provides a powerful alternative to matrix-based conditions for proving discrete maximum principles, enabling analysis of challenging cases including pathological meshes and semilinear elliptic equations."}}
{"id": "2509.00927", "pdf": "https://arxiv.org/pdf/2509.00927", "abs": "https://arxiv.org/abs/2509.00927", "authors": ["Masoud Bayrami", "Morteza Fotouhi", "Parisa Vosooqnejad"], "title": "Non-minimizing Axially Symmetric Cavity Flow", "categories": ["math.AP"], "comment": null, "summary": "Cavity flow problems in two dimensions, as well as in the axially symmetric\nthree-dimensional case, have been extensively studied in the literature from a\nqualitative perspective. While numerous results exist concerning minimizers or\nstable solutions-particularly regarding the regularity of the free boundary and\nthe analysis of singularities-much less is known about the critical points of\nthe corresponding energy functional. In this paper, we focus on investigating\nthe properties of such critical points in the axially symmetric cavity flow\nproblem with a free boundary, in relation to the known variational solutions.\nMoreover, our approach extends naturally to the case of jet flow problems.", "AI": {"tldr": "Analysis of critical points in axially symmetric cavity flow problems with free boundaries, extending to jet flow problems.", "motivation": "While cavity flow problems have been extensively studied for minimizers and stable solutions, there is limited understanding of critical points of the energy functional in axially symmetric cases with free boundaries.", "method": "The paper investigates properties of critical points in axially symmetric cavity flow problems with free boundaries, relating them to known variational solutions.", "result": "The approach provides insights into critical points beyond minimizers and stable solutions, and naturally extends to jet flow problems.", "conclusion": "This work fills a gap in understanding critical points in cavity flow problems and demonstrates applicability to related jet flow scenarios."}}
{"id": "2509.02390", "pdf": "https://arxiv.org/pdf/2509.02390", "abs": "https://arxiv.org/abs/2509.02390", "authors": ["G. S. Demyanov", "P. R. Levashov"], "title": "One--Component Plasma Equation of State Revisited via Angular--Averaged Ewald Potential", "categories": ["physics.plasm-ph"], "comment": null, "summary": "We present analytic fits of classical one--component plasma (OCP) internal\nenergy over a wide range of coupling parameter $0.01\\le\\Gamma\\le 170$ using\nMonte--Carlo data in the thermodynamic limit. We extend the dataset obtained in\n[Demyanov and Levashov, Phys. Rev. E 106, 015204 (2022)] using the\nangular--averaged Ewald potential with additional points at strong coupling\n($\\Gamma=120,\\ 150,\\ 170$). We then fit two frequently used functional forms\nfor the OCP equation of state: (i) a five-parameter equation by Caillol [J.\nChem. Phys. 111, 6538--6547 (1999)] and (ii) the equation by Potekhin and\nChabrier [Phys. Rev. E 62, 8554 (2000)] that enforces the Debye--H\\\"uckel\nlimit. The presented fits reproduce our MC data within statistical\nuncertainties, recovering the correct weak-coupling behavior. Coefficients,\nrecommended validity ranges, and comparisons to prior analytical and simulation\nresults are provided.", "AI": {"tldr": "Analytic fits for classical one-component plasma internal energy using Monte-Carlo data across coupling parameters \u0393=0.01-170, extending previous datasets and validating two functional forms.", "motivation": "To provide accurate analytical fits for one-component plasma internal energy over a wide range of coupling strengths, building upon previous Monte-Carlo data and ensuring correct weak-coupling behavior.", "method": "Extended Monte-Carlo dataset using angular-averaged Ewald potential with additional strong coupling points (\u0393=120,150,170), then fitted two established functional forms: Caillol's 5-parameter equation and Potekhin-Chabrier equation that enforces Debye-H\u00fcckel limit.", "result": "Fits reproduce MC data within statistical uncertainties while recovering correct weak-coupling behavior. Provided coefficients, validity ranges, and comparisons with prior analytical and simulation results.", "conclusion": "Successfully developed accurate analytic fits for OCP internal energy across broad coupling parameter range, validating both functional forms against extended Monte-Carlo dataset and ensuring proper asymptotic behavior."}}
{"id": "2509.01871", "pdf": "https://arxiv.org/pdf/2509.01871", "abs": "https://arxiv.org/abs/2509.01871", "authors": ["Oscar Fajardo-Fontiveros", "Carl J. E. Suster", "Eduardo G. Altmann"], "title": "Inference of epidemic networks: the effect of different data types", "categories": ["physics.comp-ph", "cond-mat.stat-mech", "physics.data-an", "physics.soc-ph", "stat.AP"], "comment": "15 pages, 8 figures", "summary": "We investigate how the properties of epidemic networks change depending on\nthe availability of different types of data on a disease outbreak. This is\nachieved by introducing mathematical and computational methods that estimate\nthe probability of transmission trees by combining generative models that\njointly determine the number of infected hosts, the probability of infection\nbetween them depending on location and genetic information, and their time of\ninfection and sampling. We introduce a suitable Markov Chain Monte Carlo method\nthat we show to sample trees according to their probability. Statistics\nperformed over the sampled trees lead to probabilistic estimations of network\nproperties and other quantities of interest, such as the number of unobserved\nhosts and the depth of the infection tree. We confirm the validity of our\napproach by comparing the numerical results with analytically solvable\nexamples. Finally, we apply our methodology to data from COVID-19 in Australia.\nWe find that network properties that are important for the management of the\noutbreak depend sensitively on the type of data used in the inference.", "AI": {"tldr": "The paper develops computational methods to estimate epidemic transmission probabilities by combining different data types (location, genetic, temporal) using MCMC sampling, and shows that outbreak management depends critically on the data used for inference.", "motivation": "To understand how epidemic network properties change based on available outbreak data types, and to develop methods for estimating transmission probabilities and unobserved infection parameters.", "method": "Introduced mathematical and computational methods using generative models that combine location, genetic, and temporal infection data. Developed a Markov Chain Monte Carlo method to sample transmission trees according to their probability, enabling statistical estimation of network properties.", "result": "The approach was validated against analytically solvable examples and applied to COVID-19 data from Australia. Results showed that important network properties for outbreak management depend sensitively on the type of data used in the inference process.", "conclusion": "The methodology provides probabilistic estimations of epidemic network properties and demonstrates that outbreak management strategies should consider the specific types of data available, as different data sources significantly impact the inferred transmission network characteristics."}}
{"id": "2509.00957", "pdf": "https://arxiv.org/pdf/2509.00957", "abs": "https://arxiv.org/abs/2509.00957", "authors": ["Hao Wu", "Haomin Zhou"], "title": "Deep Tangent Bundle (DTB) method: a Deep Neural Network approach to compute solutions of PDES", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We develop a numerical framework, the Deep Tangent Bundle (DTB) method, that\nis suitable for computing solutions of evolutionary partial differential\nequations (PDEs) in high dimensions. The main idea is to use the tangent bundle\nof an adaptively updated deep neural network (DNN) to approximate the vector\nfield in the spatial variables while applying the traditional schemes for time\ndiscretization. The DTB method takes advantage of the expression power of DNNs\nand the simplicity of the tangent bundle approximation. It does not involve\nnonconvex optimization. Several numerical examples demonstrate that the DTB is\nsimple, flexible, and efficient for various PDEs of higher dimensions.", "AI": {"tldr": "The Deep Tangent Bundle (DTB) method is a numerical framework for solving high-dimensional evolutionary PDEs using deep neural networks and tangent bundle approximation without nonconvex optimization.", "motivation": "To address the challenge of solving evolutionary partial differential equations in high dimensions by leveraging the expressive power of deep neural networks while avoiding complex optimization problems.", "method": "Uses the tangent bundle of an adaptively updated deep neural network to approximate the vector field in spatial variables, combined with traditional time discretization schemes.", "result": "The method demonstrates simplicity, flexibility, and efficiency for various high-dimensional PDEs through several numerical examples.", "conclusion": "DTB provides an effective approach for high-dimensional PDE solutions by combining neural network expressiveness with tangent bundle simplicity, avoiding nonconvex optimization challenges."}}
{"id": "2509.00977", "pdf": "https://arxiv.org/pdf/2509.00977", "abs": "https://arxiv.org/abs/2509.00977", "authors": ["Fabio Ancona", "Laura Caravenna", "Alexander J. Cliffe", "Elio Marconi"], "title": "On the regularity of continuous solutions to multidimensional scalar conservation laws with bounded source", "categories": ["math.AP", "35L60, 35L65, 35B65"], "comment": null, "summary": "We prove the H\\\"older regularity of continuous isentropic solutions to\nmulti-dimensional scalar balance laws when the source term is bounded and the\nflux satisfies general assumptions of nonlinearity. The results are achieved by\nexploiting the kinetic formulation of the balance law.", "AI": {"tldr": "H\u00f6lder regularity of continuous isentropic solutions for multi-dimensional scalar balance laws with bounded source terms and general nonlinear flux assumptions", "motivation": "To establish regularity properties for solutions to multi-dimensional scalar balance laws, which is important for understanding the behavior and stability of such solutions in various physical applications", "method": "Exploiting the kinetic formulation of the balance law to prove regularity results", "result": "Proved H\u00f6lder regularity for continuous isentropic solutions under bounded source terms and general nonlinear flux assumptions", "conclusion": "The kinetic formulation provides an effective framework for establishing regularity properties in multi-dimensional scalar balance laws with general nonlinear flux conditions"}}
{"id": "2509.02455", "pdf": "https://arxiv.org/pdf/2509.02455", "abs": "https://arxiv.org/abs/2509.02455", "authors": ["H. S. Wu", "F. Subba", "M. R. K. Wigram", "O. Pan", "R. Lo Frano", "A. Pucciarelli", "R. Zanino"], "title": "SOLPS-ITER Numerical Simulations of ITER-scale Snowflake Divertors: Low-Field-Side SF-/SF+ and High-Field-Side SF-/SF+ Configurations", "categories": ["physics.plasm-ph"], "comment": null, "summary": "With edge plasma code SOLS-ITER, we study four Snowflake (SF) configurations\nfor an ITER-size tokamak, with toroidal magnetic field BT=5T, major radius R=5m\nand plasma current Ip=10MA. Our aim is to provide insights on SF divertor\ndesign for future devices. In this work, the impacts of magnetic geometry and\ndivertor target geometry in the four types of SF configurations on plasma\nbehavior and power exhaust performance are investigated in detail.\nLow-recycling regime, high-recycling and detachment in the four types of SF\ndivertors are obtained through an upstream density scan. The secondary X-point\npositions of SF divertors are systematically varied to examine their impact.\nFor Low-Field-Side (LFS) SF- and High-Field-Side (HFS) SF- divertors the\nobserved power splitting, induced by the secondary X-point, is consistent with\nexperimental observations. The effect of target geometry is studied by\ncomparing the flat target plates with the ITER-like divertor shape. The overall\nsimulation results reveal a notable consequence of the LFS SF- divertor: closed\nstructure of the inner target with high inclined plate can compress recycling\nneutrals originating from the HFS divertor region into the LFS SOL and PFR\nregions. This results in considerable volumetric dissipation through strong\nionization and recombination, causing the connected outer target region to\ndetach. This feature can be considered in the design of the LFS SF- divertor\nfor future devices. For the LFS and HFS SF+ divertors, the region between the\ntwo X-points exhibits strong ionization and recombination sources close to the\nprimary X-point. This feature might be beneficial for the formation of an\nX-point radiator, but would require further impurity seeding simulation study.", "AI": {"tldr": "Study of four Snowflake divertor configurations for ITER-size tokamak shows LFS SF- divertor compresses recycling neutrals causing outer target detachment, while SF+ configurations show potential for X-point radiator formation.", "motivation": "Provide insights on Snowflake divertor design for future fusion devices by investigating impacts of magnetic geometry and divertor target geometry on plasma behavior and power exhaust performance.", "method": "Used SOLS-ITER edge plasma code to simulate four SF configurations with systematic variation of secondary X-point positions and comparison of flat vs ITER-like divertor shapes through upstream density scans.", "result": "LFS SF- divertor with closed inner target structure compresses recycling neutrals into LFS SOL/PFR regions, causing volumetric dissipation and outer target detachment. SF+ configurations show strong ionization/recombination near primary X-point, potentially beneficial for X-point radiator formation.", "conclusion": "LFS SF- divertor design shows promising detachment characteristics, while SF+ configurations may enable X-point radiator formation, though impurity seeding studies are needed for further validation."}}
{"id": "2509.02361", "pdf": "https://arxiv.org/pdf/2509.02361", "abs": "https://arxiv.org/abs/2509.02361", "authors": ["Lune Maillard", "Philippe Depondt", "Fabio Finocchi", "Simon Huppert", "Thomas Pl\u00e9", "Julien Salomon", "Martino Trassinelli"], "title": "Probing the partition function for temperature-dependent potentials with nested sampling", "categories": ["physics.comp-ph"], "comment": null, "summary": "Thermodynamic properties can be in principle derived from the partition\nfunction, which, in many-atom systems, is hard to evaluate as it involves a sum\non the accessible microscopic states. Recently, the partition function has been\ncomputed via nested sampling, relying on Bayesian statistics, which is able to\nprovide the density of states as a function of the energy in a single run,\nindependently of the temperature. This appealing property is lost whenever the\npotential energy that appears in the partition function is\ntemperature-dependent: for instance, mean-field effective potential energies or\nthe quantum partition function in the path-integral formalism. For these cases,\nthe nested sampling must be carried out at each temperature, which results in a\nmassive increase of computational time. Here, we introduce and implement a new\nmethod, that is based on an extended partition function where the temperature\nis considered as an additional parameter to be sampled. The extended partition\nfunction can be evaluated by nested sampling in a single run, so to restore\nthis highly desirable property even for temperature-dependent effective\npotential energies. We apply this original method to compute the quantum\npartition function for harmonic potentials and Lennard-Jones clusters at low\ntemperatures and show that it outperforms the straightforward application of\nnested sampling for each temperature within several temperature ranges.", "AI": {"tldr": "A new method using extended partition function with temperature as sampling parameter enables single-run nested sampling for temperature-dependent potentials, outperforming traditional approaches.", "motivation": "Traditional nested sampling requires separate runs for each temperature when dealing with temperature-dependent potential energies, leading to massive computational time increases.", "method": "Introduces an extended partition function where temperature is treated as an additional sampling parameter, allowing nested sampling to be performed in a single run for temperature-dependent systems.", "result": "The method successfully computes quantum partition functions for harmonic potentials and Lennard-Jones clusters at low temperatures, outperforming traditional nested sampling across multiple temperature ranges.", "conclusion": "The extended partition function approach restores the single-run efficiency of nested sampling for temperature-dependent systems, providing significant computational advantages over conventional methods."}}
{"id": "2509.01059", "pdf": "https://arxiv.org/pdf/2509.01059", "abs": "https://arxiv.org/abs/2509.01059", "authors": ["Yulei Liao", "Yang Liu", "Pingbing Ming"], "title": "A concurrent global-local numerical method for multiscale parabolic equations", "categories": ["math.NA", "cs.NA", "35B27, 35K10, 65M12, 65M60"], "comment": "25 pages,1 figure, 8 tables", "summary": "This paper presents a concurrent global-local numerical method for solving\nmultiscale parabolic equations in divergence form. The proposed method employs\nhybrid coefficient to provide accurate macroscopic information while preserving\nessential microscopic details within specified local defects. Both the\nmacroscopic and microscopic errors have been improved compared to existing\nresults, eliminating the factor of $\\Delta t^{-1/2}$ when the diffusion\ncoefficient is time-independent. Numerical experiments demonstrate that the\nproposed method effectively captures both global and local solution behaviors.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.01067", "pdf": "https://arxiv.org/pdf/2509.01067", "abs": "https://arxiv.org/abs/2509.01067", "authors": ["Benjamin Ingimarson", "Igor Kukavica", "Amjad Tuffaha"], "title": "The Euler equations with variable coefficients", "categories": ["math.AP"], "comment": "25 pages", "summary": "We establish local-in-time existence for the Euler equations on a bounded\ndomain with space-time dependent variable coefficients, given initial data $v_0\n\\in H^r$ under the optimal regularity condition $r > 2.5$. In the case $r = 3$,\nwe further prove a Beale-Kato-Majda criterion that relates blow-up in the $H^r$\nnorm to the BMO norm of the variable vorticity $\\zeta$.", "AI": {"tldr": "Local existence for Euler equations with variable coefficients in bounded domains, optimal regularity r>2.5, plus Beale-Kato-Majda criterion for r=3 relating blow-up to BMO vorticity norm.", "motivation": "To establish existence theory for Euler equations with space-time dependent variable coefficients on bounded domains, extending classical results to more general settings with optimal regularity conditions.", "method": "Mathematical analysis of Euler equations with variable coefficients, using techniques from partial differential equations and functional analysis to prove local-in-time existence under optimal regularity conditions.", "result": "Proved local existence for initial data v0 \u2208 H^r with optimal condition r > 2.5. For r = 3, established a Beale-Kato-Majda type criterion linking H^r norm blow-up to the BMO norm of variable vorticity \u03b6.", "conclusion": "The paper provides optimal regularity conditions for local existence of Euler equations with variable coefficients and extends the classical Beale-Kato-Majda criterion to this more general setting, offering important theoretical foundations for studying fluid dynamics in variable coefficient environments."}}
{"id": "2509.02378", "pdf": "https://arxiv.org/pdf/2509.02378", "abs": "https://arxiv.org/abs/2509.02378", "authors": ["Benjamin Terschanski", "Robert Kl\u00f6fkorn", "Andreas Dedner", "Julia Kowalski"], "title": "Bryne: sustainable prototyping of finite element models", "categories": ["physics.comp-ph", "cs.NA", "math.NA"], "comment": null, "summary": "Open-source simulation frameworks are evolving rapidly to provide accessible\ntools for the numerical solution of partial differential equations. Modern\nfinite element (FEM) software such as FEniCS, Firedrake, or dune-fem alleviates\nthe need for modelers to recode the discretization and linear solver backend\nfor each application and enables rapid prototyping of solvers. However, while\nit has become easier to build prototype FEM models, creating a solver reusable\nbeyond its specific initial simulation setup remains difficult. Moreover,\nsimulation setups typically cover an ample input parameter space, and tracking\ncomplex metadata on research project time scales has become a challenge. This\nimplies the need to supplement model development with a coding-intensive\ncomplementary workstream, seldom developed for sustainable reuse. To address\nthese issues, we introduce our open-source Python package Bryne. Bryne is an\nobject-oriented framework for FEM solvers built with the dune-fem Python API.\nIn this article, we describe how it helps to evolve rapid-prototyping solver\ndevelopment into sustainable simulation building. First, we show how to\ntranslate a minimal dune-fem solver into a Bryne FEM model to build\nhuman-readable, metadata-enriched simulations. Bryne then offers a simulation\ndriver and model coupling interfaces to combine implemented solvers in\noperator-split multiphysics simulations. The resulting reproducibility-enabled\ninfrastructure allows users to tackle complex simulation setups without\nsacrificing backend flexibility. We demonstrate the workflow on a\nconvection-coupled phase-change simulation, where a discontinuous Galerkin flow\nsolver is coupled with a solver for solidification phase change.", "AI": {"tldr": "Bryne is an open-source Python framework that extends dune-fem to create reusable, metadata-enriched FEM solvers for sustainable multiphysics simulations.", "motivation": "Modern FEM software enables rapid prototyping but lacks sustainability - solvers are hard to reuse beyond initial setups, and managing complex metadata across parameter spaces is challenging without extensive coding.", "method": "Object-oriented framework built on dune-fem Python API that translates minimal solvers into human-readable, metadata-enriched simulations with simulation drivers and model coupling interfaces for operator-split multiphysics.", "result": "Enables building reproducible infrastructure for complex simulation setups without sacrificing backend flexibility, demonstrated through convection-coupled phase-change simulation.", "conclusion": "Bryne bridges the gap between rapid prototyping and sustainable simulation building by providing structured framework for reusable, metadata-rich FEM solvers in multiphysics applications."}}
{"id": "2509.01256", "pdf": "https://arxiv.org/pdf/2509.01256", "abs": "https://arxiv.org/abs/2509.01256", "authors": ["Zhipeng Zhu", "Wai Yeung Lam", "Lok Ming Lui"], "title": "A Structure-Preserving Numerical Method for Harmonic Maps Between High-genus Surfaces", "categories": ["math.NA", "cs.NA", "math.OC"], "comment": null, "summary": "Motivated by geometry processing for surfaces with non-trivial topology, we\nstudy discrete harmonic maps between closed surfaces of genus at least two.\nHarmonic maps provide a natural framework for comparing surfaces by minimizing\ndistortion. Unlike conformal or isometric maps-which may not exist between\nsurfaces with different geometries-harmonic maps always exist within a fixed\nhomotopy class and yield optimal homeomorphisms when the target surface has\nnegative curvature. We develop a structure-preserving algorithm to compute\nharmonic maps from a triangulated surface to a reference hyperbolic surface.\nThe method minimizes Dirichlet energy over geodesic realizations of the surface\ngraph into the target hyperbolic surface in the homotopy class of a\nhomeomorphism. A central feature of our framework is the use of canonical edge\nweights derived from the hyperbolic metric, which generalize the classical\ncotangent weights from the Euclidean setting. These weights preserve\ninjectivity and ensure that isometries remain harmonic in the discrete theory,\nreflecting their classical behavior.", "AI": {"tldr": "A structure-preserving algorithm for computing harmonic maps between closed surfaces of genus \u22652 using hyperbolic geometry and generalized cotangent weights.", "motivation": "To develop a framework for comparing surfaces with non-trivial topology by minimizing distortion, addressing the limitation that conformal or isometric maps may not exist between surfaces with different geometries.", "method": "Minimizes Dirichlet energy over geodesic realizations of surface graphs into target hyperbolic surfaces within a fixed homotopy class, using canonical edge weights derived from hyperbolic metrics that generalize Euclidean cotangent weights.", "result": "The algorithm preserves injectivity and ensures that isometries remain harmonic in the discrete theory, reflecting classical harmonic map behavior.", "conclusion": "The developed framework provides optimal homeomorphisms between surfaces with negative curvature and generalizes classical harmonic map theory to the discrete hyperbolic setting."}}
{"id": "2509.01138", "pdf": "https://arxiv.org/pdf/2509.01138", "abs": "https://arxiv.org/abs/2509.01138", "authors": ["Zhenyu Fan"], "title": "A generalization of Savin's small perturbation theorem for fully nonlinear elliptic equations and applications", "categories": ["math.AP"], "comment": "25 pages", "summary": "In this note, we generalize Savin's small perturbation theorem to\nnonhomogeneous fully nonlinear equations $F(D^2u, Du, u,x)=f$ provided the\ncoefficients and the right-hand side terms are H\\\"older small perturbations. As\nan application, we establish a partial regularity result for the sigma-$k$\nHessian equation $\\sigma_{k}(D^2u)=f$.", "AI": {"tldr": "Generalization of Savin's small perturbation theorem to nonhomogeneous fully nonlinear equations with H\u00f6lder small perturbations, with application to partial regularity for sigma-k Hessian equations.", "motivation": "To extend Savin's perturbation results beyond homogeneous equations to more general nonhomogeneous fully nonlinear equations, enabling broader applications in PDE theory.", "method": "Generalize Savin's small perturbation theorem to handle nonhomogeneous fully nonlinear equations F(D\u00b2u, Du, u, x)=f where coefficients and right-hand side terms are H\u00f6lder small perturbations.", "result": "Successfully extended the perturbation theorem and established a partial regularity result specifically for the sigma-k Hessian equation \u03c3_k(D\u00b2u)=f.", "conclusion": "The generalization provides a framework for analyzing regularity properties of nonhomogeneous fully nonlinear equations and yields concrete results for sigma-k Hessian equations, expanding the scope of perturbation methods in PDE analysis."}}
{"id": "2509.00207", "pdf": "https://arxiv.org/pdf/2509.00207", "abs": "https://arxiv.org/abs/2509.00207", "authors": ["Jean-Christophe Pain", "Djamel Benredjem"], "title": "Corrections to radiative rates between atomic configurations", "categories": ["physics.atom-ph", "physics.plasm-ph"], "comment": "submitted to J. Quant. Spectrosc. Radiat. Transfer", "summary": "The computation of radiative opacity or emissivity of hot dense matter is a\nchallenging task. It requires accounting for an immense number of energy levels\nand lines across various excitation and ionization states. Whether in local\nthermodynamic equilibrium (LTE) or non-LTE plasmas, statistical methods provide\nsignificant assistance. Many computational codes are based on the Detailed\nConfiguration Accounting approximation, which involves averaged rates between\nconfigurations. In that approach, only the mean energies of the configurations\nare considered, and the effects of the energy distributions of the levels\nwithin the initial and final configurations are typically neglected. A long\ntime ago, Klapisch proposed a method to correct the rates. The corresponding\nformalism includes the energy shift and variance of the Unresolved Transition\nArray, as well as the average energies of the configurations. We extend this\nformalism and investigate its impact on opacity calculations in two specific\ncases: first, the iron experiment conducted at Sandia National Laboratories\nunder conditions similar to those at the base of the Sun's convective zone,\ndominated by L-shell 2p-$n$d transitions, and second, laser experiments--still\nfor iron--at much lower temperature. The latter measurements shed light on our\nunderstanding of the envelopes of $\\beta$-Cephei-type stars, where the relevant\ntransitions are intra-M-shell $\\Delta n=0$ (3-3) transitions, specifically\n3s-3p and 3p-3d, in the XUV range. The issue of ensuring the validity of\nKirchhoff's law when plasmas approach LTE is also addressed, and a prescription\nis proposed, applying both to the standard configuration-to-configuration case\nand to the aforementioned corrections, which account for the energy\ndistribution of the levels within a configuration.", "AI": {"tldr": "Extension of Klapisch's method to include energy distribution effects in opacity calculations, applied to iron experiments at solar and stellar envelope conditions, with Kirchhoff's law validation.", "motivation": "Radiative opacity calculations for hot dense matter are challenging due to immense number of energy levels and transitions. Standard methods neglect energy distributions within configurations, limiting accuracy.", "method": "Extended Klapisch's formalism to include energy shift and variance of Unresolved Transition Arrays, applied to iron opacity calculations for Sandia experiments (solar conditions) and laser experiments (stellar envelopes).", "result": "Improved opacity calculations accounting for level energy distributions within configurations, with specific applications to L-shell and M-shell transitions in iron under different temperature conditions.", "conclusion": "The extended formalism provides more accurate opacity calculations by including energy distribution effects, with proposed prescription to ensure Kirchhoff's law validity in LTE-approaching plasmas for both standard and corrected cases."}}
{"id": "2509.00090", "pdf": "https://arxiv.org/pdf/2509.00090", "abs": "https://arxiv.org/abs/2509.00090", "authors": ["Yi Cao", "Paulette Clancy"], "title": "Migration as a Probe: A Generalizable Benchmark Framework for Specialist vs. Generalist Machine-Learned Force Fields in Doped Materials", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Machine-learned force fields (MLFFs), particularly pre-trained foundation\nmodels, promise to bring ab initio-level accuracy to the length and time scales\nof molecular dynamics. Yet this shift raises a central question: is it better\nto build a specialist model from scratch or adapt a generalist foundation model\nfor a specific system? The trade-offs in data efficiency, predictive accuracy,\nand risks of out-of-distribution (OOD) failure remain unclear. Here, we present\na benchmarking framework that contrasts bespoke (from scratch) and fine-tuned\nfoundation models in a test case of a technologically relevant 2D material,\nCr-intercalated Sb2Te3, using the MACE architecture. Our framework employs\nmigration pathways, evaluated through nudged elastic band (NEB) trajectories,\nas a diagnostic probe that tests both interpolation and extrapolation. We\nassess accuracy for equilibrium, kinetic (atomic migration), and mechanical\n(interlayer sliding) tasks. While all models capture equilibrium structures,\npredictions for non-equilibrium processes diverge. Task-specific fine-tuning\nsubstantially improves kinetic accuracy compared with both from-scratch and\nzero-shot models, but can degrade learned representations of long-range\nphysics. Analysis of internal representations shows that training paradigms\nyield distinct, non-overlapping latent encodings of system physics. This work\noffers a practical guide for MLFF development, highlights migration-based\nprobes as efficient diagnostics, and suggests pathways toward uncertainty-aware\nactive learning strategies.", "AI": {"tldr": "Benchmarking framework compares specialist (from-scratch) vs fine-tuned foundation MLFFs for Cr-intercalated Sb2Te3, showing fine-tuning improves kinetic accuracy but may degrade long-range physics representations.", "motivation": "To determine whether building specialist models from scratch or adapting generalist foundation models is better for MLFFs, addressing trade-offs in data efficiency, accuracy, and OOD risks.", "method": "Developed benchmarking framework using MACE architecture on Cr-intercalated Sb2Te3, employing migration pathways via NEB trajectories to test interpolation/extrapolation, assessing equilibrium, kinetic, and mechanical properties.", "result": "All models captured equilibrium structures but diverged on non-equilibrium processes. Task-specific fine-tuning substantially improved kinetic accuracy over from-scratch and zero-shot models, but degraded long-range physics representations. Training paradigms produced distinct latent encodings.", "conclusion": "Provides practical guide for MLFF development, highlights migration-based probes as efficient diagnostics, and suggests pathways for uncertainty-aware active learning strategies."}}
{"id": "2509.01270", "pdf": "https://arxiv.org/pdf/2509.01270", "abs": "https://arxiv.org/abs/2509.01270", "authors": ["Wenxing Zhu", "Mingyang Pan", "Dongdong He"], "title": "Linear, decoupled, second-order and structure-preserving scheme for Carreau fluid equations coupled with steric Poisson-Nernst-Planck model", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, to study ionic steric effects, we present a linear, decoupled,\nsecond-order accurate in time and structure-preserving scheme with finite\nelement approximations for Carreau fluid equations coupled with steric\nPoisson-Nernst-Planck (SPNP) model. The logarithmic transformation for the ion\nconcentration is used to preserve positivity property. To deal with the\nnonlinear coupling terms in fluid equation, a nonlocal auxiliary variable with\nrespect to the free energy of SPNP equations and its associated ordinary\ndifferential equation are introduced. The obtained system is equivalent to the\noriginal system. The fully discrete scheme is proved to be mass conservative,\npositivity-preserving for ion concentration and energy dissipative at discrete\nlevel. Some numerical simulations are provided to demonstrate its stability and\naccuracy. Moreover, the ionic steric effects are numerically investigated.", "AI": {"tldr": "A linear, decoupled second-order accurate scheme for Carreau fluid equations coupled with steric Poisson-Nernst-Planck model, preserving positivity and energy dissipation.", "motivation": "To study ionic steric effects in complex fluid systems by developing a structure-preserving numerical scheme that can handle nonlinear coupling while maintaining physical properties.", "method": "Uses logarithmic transformation for ion concentration positivity, introduces nonlocal auxiliary variable for free energy to handle nonlinear coupling terms, and employs finite element approximations with second-order time accuracy.", "result": "The scheme is proven to be mass conservative, positivity-preserving for ion concentration, and energy dissipative at discrete level. Numerical simulations confirm stability and accuracy.", "conclusion": "The developed scheme successfully handles ionic steric effects in Carreau-SPNP systems while preserving essential physical properties, providing an effective tool for numerical investigation of steric effects."}}
{"id": "2509.01155", "pdf": "https://arxiv.org/pdf/2509.01155", "abs": "https://arxiv.org/abs/2509.01155", "authors": ["Huyuan Chen", "Bobo hua"], "title": "On finite-energy solutions of Kazan-Warner equations on the lattice graph", "categories": ["math.AP", "35J91, 05C22", "F.m"], "comment": "28 pages", "summary": "We investigate finite-energy solutions to Kazdan-Warner type equations in\n2-dimensional integer lattice graph $$ - \\Delta u= \\varepsilon e^{\\kappa u}\n+\\beta\\delta_0\\quad {\\rm in}\\ \\mathbb{Z}^2,$$ where $\\varepsilon=\\pm1$,\n$\\kappa>0$ and $\\beta\\in\\mathbb{R}$.\n  When $\\varepsilon=1$, we prove the existence of a continuous family of\nfinite-energy solutions for some parameter $\\kappa$. This provides a partial\nresolution of the open problem on the existence of finite-energy solutions to\nthe Liouville equation.\n  When $\\varepsilon=-1$ and $\\beta>\\frac{4\\pi}{\\kappa}$, we prove that the set\nof finite-energy solutions exhibits a layer structure. Moreover, we derive the\nextremal solution in this case.", "AI": {"tldr": "Analysis of finite-energy solutions to Kazdan-Warner equations on 2D lattice graphs, with existence results for positive parameter case and layer structure characterization for negative parameter case.", "motivation": "To address the open problem of finite-energy solutions to Liouville equations on discrete lattice structures and understand the solution behavior for different parameter regimes.", "method": "Mathematical analysis of the discrete Kazdan-Warner equation on 2D integer lattice graphs, employing techniques from discrete analysis and potential theory to study solution existence and structure.", "result": "For \u03b5=1, proved existence of continuous family of finite-energy solutions for certain \u03ba values. For \u03b5=-1 with \u03b2>4\u03c0/\u03ba, demonstrated layer structure of solution set and derived extremal solution.", "conclusion": "The study provides partial resolution to the Liouville equation existence problem and reveals structural properties of solutions in different parameter regimes on discrete lattice graphs."}}
{"id": "2509.01237", "pdf": "https://arxiv.org/pdf/2509.01237", "abs": "https://arxiv.org/abs/2509.01237", "authors": ["Alexander J. B. Russell", "Vanessa Polito", "Paola Testa", "Bart De Pontieu", "Sergey A. Belov"], "title": "Solar Flare Ion Temperatures", "categories": ["astro-ph.SR", "physics.plasm-ph"], "comment": "Accepted by ApJ Letters", "summary": "This paper proposes that the ion temperature is several times the local\nelectron temperature in the hot onset phase and at the above-the-loop region of\nsolar flares. The paper considers: the evidence of spectral line Doppler widths\n(\"non-thermal\" broadening); evidence for \"universal\" ion and electron\ntemperature increase scaling relations for magnetic reconnection in the solar\nwind, Earth's magnetopause, Earth's magnetotail and numerical simulations; and\nthermal equilibration times for onset and above-the-loop densities, which are\nmuch longer than previous estimates based on soft X-ray flare loops. We\nconclude that the ion temperature is likely to reach 60 MK or greater and that\nit may represent a substantial part of spectral line widths, significantly\ncontributing to solving the long-standing issue of the excess nonthermal\nbroadening in flare lines.", "AI": {"tldr": "Ion temperatures in solar flares are several times higher than electron temperatures, reaching up to 60 MK, which helps explain excess nonthermal broadening in spectral lines.", "motivation": "To address the long-standing issue of excess nonthermal broadening in solar flare spectral lines by investigating ion temperature characteristics during flare onset and above-the-loop regions.", "method": "Analysis of spectral line Doppler widths, examination of universal temperature scaling relations from solar wind and magnetospheric reconnection events, and calculation of thermal equilibration times for different flare densities.", "result": "Ion temperatures are found to be several times higher than local electron temperatures, potentially reaching 60 MK or greater in the hot onset phase and above-the-loop regions.", "conclusion": "High ion temperatures represent a substantial component of spectral line widths, providing a significant contribution to solving the problem of excess nonthermal broadening in flare lines."}}
{"id": "2509.00854", "pdf": "https://arxiv.org/pdf/2509.00854", "abs": "https://arxiv.org/abs/2509.00854", "authors": ["Gubio G. de Limaa", "Tiago de S. Farias", "Alexandre C. Ricardo", "Celso Jorge Villa Boas"], "title": "Assessing the Advantages and Limitations of Quantum Neural Networks in Regression Tasks", "categories": ["quant-ph", "physics.comp-ph"], "comment": null, "summary": "The development of quantum neural networks (QNNs) has attracted considerable\nattention due to their potential to surpass classical models in certain machine\nlearning tasks. Nonetheless, it remains unclear under which conditions QNNs\nprovide concrete benefits over classical neural networks (CNNs). This study\naddresses this question by performing both qualitative and quantitative\nanalyses of classical and quantum models applied to regression problems, using\ntwo target functions with contrasting properties. Additionally, the work\nexplores the methodological difficulties inherent in making fair comparisons\nbetween QNNs and CNNs. The findings reveal a distinct advantage of QNNs in a\nspecific quantum machine learning context. In particular, QNNs excelled at\napproximating the sinusoidal function, achieving errors up to seven orders of\nmagnitude lower than their classical counterparts. However, their performance\nwas limited in other cases, emphasizing that QNNs are highly effective for\ncertain tasks but not universally sPuperior. These results reinforce the\nprinciples of the ``No Free Lunch'' theorem, highlighting that no single model\noutperforms all others across every problem domain.", "AI": {"tldr": "QNNs show significant advantage over classical neural networks for specific quantum machine learning tasks (7 orders of magnitude lower error for sinusoidal functions), but are not universally superior, reinforcing the No Free Lunch theorem.", "motivation": "To determine under what conditions quantum neural networks (QNNs) provide concrete benefits over classical neural networks (CNNs) and address methodological challenges in fair comparisons.", "method": "Qualitative and quantitative analyses of classical and quantum models applied to regression problems using two target functions with contrasting properties.", "result": "QNNs excelled at approximating sinusoidal functions with errors up to seven orders of magnitude lower than classical counterparts, but showed limited performance in other cases.", "conclusion": "QNNs are highly effective for certain specific tasks but not universally superior, reinforcing that no single model outperforms all others across every problem domain."}}
{"id": "2509.01278", "pdf": "https://arxiv.org/pdf/2509.01278", "abs": "https://arxiv.org/abs/2509.01278", "authors": ["Wenxing Zhu", "Mingyang Pan", "Dongdong He"], "title": "Linear, decoupled, positivity preserving, positive-definiteness preserving and energy stable schemes for the diffusive Oldroyd-B coupled with PNP model", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we present a first-order finite element scheme for the\nviscoelastic electrohydrodynamic model. The model incorporates the\nPoisson-Nernst-Planck equations to describe the transport of ions and the\nOldroyd-B constitutive model to capture the behavior of viscoelastic fluids. To\npreserve the positive-definiteness of the conformation tensor and the\npositivity of ion concentrations, we employ both logarithmic transformations.\nThe decoupled scheme is achieved by introducing a nonlocal auxiliary variable\nand using the splitting technique. The proposed schemes are rigorously proven\nto be mass conservative and energy stable at the fully discrete level. To\nvalidate the theoretical analysis, we present numerical examples that\ndemonstrate the convergence rates and the robust performance of the schemes.\nThe results confirm that the proposed methods accurately handle the high\nWeissenberg number problem (HWNP) at moderately high Weissenberg numbers.\nFinally, the flow structure influenced by the elastic effect within the\nelectro-convection phenomena has been studied.", "AI": {"tldr": "A first-order finite element scheme for viscoelastic electrohydrodynamic modeling using Poisson-Nernst-Planck equations and Oldroyd-B model with logarithmic transformations to preserve positivity and energy stability.", "motivation": "To develop a numerical scheme that can accurately handle viscoelastic electrohydrodynamic problems while preserving physical properties like positive-definiteness of conformation tensor and positivity of ion concentrations, particularly addressing the high Weissenberg number problem.", "method": "Uses finite element method with logarithmic transformations for conformation tensor and ion concentrations, introduces nonlocal auxiliary variable and splitting technique for decoupled scheme, ensuring mass conservation and energy stability at discrete level.", "result": "The scheme demonstrates convergence rates and robust performance in numerical examples, successfully handles high Weissenberg number problem at moderately high Weissenberg numbers, and captures elastic effects in electro-convection phenomena.", "conclusion": "The proposed first-order finite element scheme provides an effective and stable numerical approach for viscoelastic electrohydrodynamic modeling, preserving essential physical properties while addressing challenging high Weissenberg number scenarios."}}
{"id": "2509.01196", "pdf": "https://arxiv.org/pdf/2509.01196", "abs": "https://arxiv.org/abs/2509.01196", "authors": ["Jin Tan", "Yan-Lin Wang", "Lan Zhang"], "title": "Regularity and dynamics of weak solutions for one-dimensional compressible Navier-Stokes equations with vacuum", "categories": ["math.AP"], "comment": "29 pages, 1 figure", "summary": "In the spirit of D. Hoff's weak solution theory for the compressible\nNavier-Stokes equations (CNS) with bounded density, in this paper we establish\nthe global existence and regularity properties of finite-energy weak solutions\nto an initial boundary value problem of one-dimensional CNS with general\ninitial data and vacuum. The core of our proof is a global in time a priori\nestimate for one-dimensional CNS that holds for any $H^1$ initial velocity and\nbounded initial density not necessarily strictly positive: it could be a\ndensity patch or a vacuum bubble. We also establish that the velocity and\ndensity decay exponentially to equilibrium. As a by-product, we obtain the\nquantitative dynamics of aforementioned two vacuum states.", "AI": {"tldr": "Global existence and regularity of finite-energy weak solutions for 1D compressible Navier-Stokes equations with vacuum and general initial data, including density patches and vacuum bubbles.", "motivation": "Extend D. Hoff's weak solution theory for compressible Navier-Stokes equations with bounded density to handle vacuum states and general initial conditions in one dimension.", "method": "Establish global a priori time estimates for 1D CNS with H^1 initial velocity and bounded initial density (including vacuum states), analyze quantitative dynamics of vacuum states.", "result": "Proved global existence and regularity of finite-energy weak solutions, showed exponential decay of velocity and density to equilibrium, obtained quantitative dynamics of density patches and vacuum bubbles.", "conclusion": "Successfully developed weak solution theory for 1D compressible Navier-Stokes equations that handles vacuum states and provides complete quantitative description of solution behavior including exponential convergence to equilibrium."}}
{"id": "2509.01747", "pdf": "https://arxiv.org/pdf/2509.01747", "abs": "https://arxiv.org/abs/2509.01747", "authors": ["R. Ariniello", "V. Lee", "M. D. Litos"], "title": "Demonstration of a tandem lens for producing shaped laser-ionized plasmas for plasma wakefield acceleration", "categories": ["physics.optics", "physics.acc-ph", "physics.plasm-ph"], "comment": null, "summary": "We demonstrate a tandem lens optical setup, comprising two diffractive\noptics, that focuses a high-power ultrafast laser with a shaped on-axis\nintensity profile, producing a meter-long Bessel focus. The intended use of the\noptical setup is to produce a laser-ionized plasma source for plasma wakefield\nacceleration. By controlling the on-axis intensity, the density profile of the\nplasma ramps at the entrance and exit of the plasma can be tailored to optimize\nmatching of the electron beam into the plasma. In addition to demonstrating the\noptical system, we describe the algorithm used to calculate the lens phases and\npresent detailed calculations of the lenses' expected performance.", "AI": {"tldr": "A tandem lens optical system using two diffractive optics creates meter-long Bessel focus for plasma wakefield acceleration applications, enabling tailored plasma density profiles through controlled on-axis intensity.", "motivation": "To develop an optical system that produces optimal plasma sources for plasma wakefield acceleration by controlling the on-axis intensity profile to tailor plasma density ramps for better electron beam matching.", "method": "Uses a tandem lens setup with two diffractive optics to focus high-power ultrafast lasers, creating shaped on-axis intensity profiles that generate meter-long Bessel focus. Includes algorithm for calculating lens phases and detailed performance calculations.", "result": "Successfully demonstrated the optical system capable of producing meter-long Bessel focus with controlled on-axis intensity, enabling tailored plasma density profiles at plasma entrance and exit.", "conclusion": "The tandem diffractive optics approach provides an effective method for creating optimized plasma sources for wakefield acceleration applications through precise control of laser intensity profiles."}}
{"id": "2509.01287", "pdf": "https://arxiv.org/pdf/2509.01287", "abs": "https://arxiv.org/abs/2509.01287", "authors": ["S\u00f6ren Bartels", "Bal\u00e1zs Kov\u00e1cs", "Dominik Schneider"], "title": "Quasi-optimal error estimates for the approximation of stable stationary states of the elastic energy of inextensible curves", "categories": ["math.NA", "cs.NA", "74B20, 65M15, 35K55"], "comment": null, "summary": "We establish local existence and a quasi-optimal error estimate for piecewise\ncubic minimizers to the bending energy under a discretized inextensibility\nconstraint. In previous research a discretization is used where the\ninextensibility constraint is only enforced at the nodes of the discretization.\nWe show why this discretization leads to suboptimal convergence rates and we\nimprove on it by also enforcing the constraint in the midpoints of each\nsubinterval. We then use the inverse function theorem to prove existence and an\nerror estimate for stationary states of the bending energy that yields\nquasi-optimal convergence. We use numerical simulations to verify the\ntheoretical results experimentally.", "AI": {"tldr": "Local existence and quasi-optimal error estimate for piecewise cubic minimizers of bending energy with improved discretized inextensibility constraint enforcement.", "motivation": "Previous discretization methods only enforced inextensibility constraints at nodes, leading to suboptimal convergence rates. This research aims to improve convergence by better constraint enforcement.", "method": "Enforce inextensibility constraint at both nodes and midpoints of each subinterval. Use inverse function theorem to prove existence and error estimate for stationary states of bending energy.", "result": "Achieved quasi-optimal convergence rates for piecewise cubic minimizers. Numerical simulations verified the theoretical results experimentally.", "conclusion": "The improved discretization method with constraint enforcement at both nodes and midpoints provides superior convergence performance compared to previous approaches that only enforced constraints at nodes."}}
{"id": "2509.01268", "pdf": "https://arxiv.org/pdf/2509.01268", "abs": "https://arxiv.org/abs/2509.01268", "authors": ["Luigi De Rosa", "Micka\u00ebl Latocca", "Jaemin Park"], "title": "Global Existence, Hamiltonian Conservation and Vanishing Viscosity for the Surface Quasi-Geostrophic Equation", "categories": ["math.AP"], "comment": null, "summary": "For any initial datum $\\theta_0\\in L^{\\frac{4}{3}}_x$ it is proved the\nexistence of a global-in-time weak solution $\\theta \\in L^\\infty_t\nL^{\\frac43}_x$ to the surface quasi-geostrophic equation whose Hamiltonian,\ni.e. the $\\dot{H}^{-\\frac{1}{2}}_x$ norm, is constant in time. The solution is\nobtained as a vanishing viscosity limit. Outside the classical strong\ncompactness setting, the main idea is to propagate in time the\nnon-concentration of the $L^{\\frac{4}{3}}_x$ norm of the initial data, from\nwhich strong compactness in the Hamiltonian norm is deduced. General no\nanomalous dissipation results under minimal Onsager supercritical assumptions\nare also obtained.", "AI": {"tldr": "Global weak solutions for surface quasi-geostrophic equation with constant Hamiltonian, obtained via vanishing viscosity limit and non-concentration propagation", "motivation": "To prove existence of global weak solutions for the surface quasi-geostrophic equation with initial data in L^{4/3} space, maintaining constant Hamiltonian over time", "method": "Vanishing viscosity limit approach, propagating non-concentration of L^{4/3} norm from initial data to deduce strong compactness in Hamiltonian norm", "result": "Existence of global-in-time weak solutions \u03b8 \u2208 L^\u221e_t L^{4/3}_x with constant Hamiltonian (H^{-1/2} norm), general no anomalous dissipation results under minimal Onsager supercritical assumptions", "conclusion": "Successful construction of global weak solutions through careful handling of non-concentration properties, extending results beyond classical strong compactness settings"}}
{"id": "2509.01036", "pdf": "https://arxiv.org/pdf/2509.01036", "abs": "https://arxiv.org/abs/2509.01036", "authors": ["Mohd Yasir Khan"], "title": "Emergent Rotational Order and Re-entrant Global Order of Vicsek Agents in a Complex Noise Environment", "categories": ["cond-mat.soft", "cond-mat.stat-mech", "physics.comp-ph"], "comment": null, "summary": "Noisy pursuit in complex environments drives emergent collective behaviors in\nactive matter systems. A compelling platform to study the impact of environment\ncues is provided by the standard Vicsek model for studying flocking and\nswarming phenomena. In this study, we explore the collective dynamics of Vicsek\nagents in a complex noise environment, featuring a noiseless circular region\n($\\eta_{\\text{c}} = 0.0$) surrounded by a noisy outer region ($\\eta_{\\text{b}}\n= 1.0$, tunable), with a mutually repelling interactions. By varying the outer\nnoise intensity, we observe an emergent rotational order ($\\phi_r$) that peaks\nat higher noise levels ($\\eta_{\\text{b}}\\sim 1$), as revealed by phase and\nsusceptibility plots. Global order follows ($\\phi$) follows a `U' shaped curve,\n$\\phi \\sim 0.965$ at $\\eta_b=0$, dies down to $\\phi \\sim 0.57$ at $\\eta_b=0.9$\nand re-enters at $\\eta_b > 1$ and peaks $\\phi \\sim 0.960$ at $\\eta_b=1.5$. The\nlatter rise attributing to $\\phi_r$ increase. Higher particle velocities\nenhance escape rates ($\\kappa$) from the circular region, with slower-moving\nagents exhibiting greater virtual confinement. We quantify escape dynamics\nthrough time-averaged and first-passage escape rates, demonstrating\nvelocity-dependent retention on the probability of finding the bi-motility\nagent flocks at a give time resulting in segregation and trapping. Introducing\na gradual noise increase from the circle's center to the outer region reduces\nboth global ($\\phi$) and rotational ($\\phi_r$) order, underscoring the impact\nof environmental heterogeneity and sudden annealing over gradual change. These\nfindings offer insights into predicting and manipulating active agent dynamics\nin heterogeneous environments, with applications in biological and synthetic\nswarming systems.", "AI": {"tldr": "Study of Vicsek model agents in complex noise environments shows emergent rotational order and U-shaped global order patterns, with velocity-dependent escape dynamics and environmental heterogeneity effects on collective behaviors.", "motivation": "To understand how complex noise environments and environmental heterogeneity impact collective dynamics in active matter systems, using the Vicsek model as a platform to study flocking and swarming phenomena.", "method": "Modified Vicsek model with a noiseless circular region surrounded by a noisy outer region, featuring mutually repelling interactions. Varied outer noise intensity and analyzed phase/susceptibility plots, escape rates, and order parameters.", "result": "Emergent rotational order peaks at higher noise levels; global order follows U-shaped curve; higher velocities enhance escape rates from circular region; gradual noise increase reduces both global and rotational order.", "conclusion": "Environmental heterogeneity and sudden noise changes significantly impact collective dynamics, with applications for predicting and manipulating active agent behaviors in biological and synthetic swarming systems."}}
{"id": "2509.01353", "pdf": "https://arxiv.org/pdf/2509.01353", "abs": "https://arxiv.org/abs/2509.01353", "authors": ["Ema \u010ce\u0161ek", "Ale\u0161 Vavpeti\u010d"], "title": "Curvature-Based Optimal Polynomial Geometric Interpolation of Circular Arcs", "categories": ["math.NA", "cs.NA", "65D05, 65D07, 65D17"], "comment": null, "summary": "The problem of the optimal approximation of circular arcs by parametric\npolynomial curves is considered. The optimality relates to the curvature error.\nParametric polynomial curves of low degree are used and a geometric continuity\nis prescribed at the boundary points of the circular arc. Analysis is done for\ncases of parabolic $G^0$, cubic $G^1$ and quartic $G^2$ interpolation. The\ncomparison of the approximation of circular arcs based on curvature with the\napproximation based on radial error is provided.", "AI": {"tldr": "Optimal approximation of circular arcs using parametric polynomial curves with curvature error minimization, analyzed for parabolic G\u2070, cubic G\u00b9, and quartic G\u00b2 interpolation cases.", "motivation": "To develop efficient and accurate methods for approximating circular arcs using low-degree parametric polynomial curves while minimizing curvature error, which is important for CAD/CAM systems and geometric modeling.", "method": "Uses parametric polynomial curves of low degrees (parabolic, cubic, quartic) with prescribed geometric continuity (G\u2070, G\u00b9, G\u00b2) at boundary points. Analyzes optimal approximation based on curvature error minimization rather than traditional radial error approaches.", "result": "Provides analysis and comparison of approximation quality for different polynomial degrees and continuity conditions. Shows that curvature-based approximation can yield different results compared to radial error-based methods.", "conclusion": "Curvature error minimization provides an alternative and potentially superior approach to circular arc approximation compared to traditional radial error methods, with different polynomial degrees and continuity conditions offering trade-offs between accuracy and computational complexity."}}
{"id": "2509.01316", "pdf": "https://arxiv.org/pdf/2509.01316", "abs": "https://arxiv.org/abs/2509.01316", "authors": ["Prasanta K. Barik", "Fernando P. da Costa", "Jo\u00e3o T. Pinto", "Rafael Sasportes"], "title": "The continuous version of the generalized exchange-driven growth model", "categories": ["math.AP"], "comment": null, "summary": "In this article, we discuss the continuous version of the generalized\nexchange-driven growth model which is a variant of the coagulation model in\nwhich a smaller size particle is detached from a bigger one and merges with\nanother particle. This new model is a continuous extension of the generalized\nexchange-driven growth model originally formulated in a discrete context [4].\nIn this work, we examine the existence of weak solutions to the continuous\nversion of the generalized exchange-driven growth model under a suitable\nreaction rate. Under an additional condition on the reaction rates, a\nuniqueness result is established. Finally, we prove that solutions satisfy the\nmass-conserving property and the conservation of the total number of particles\nfor coagulation rates with linear bounds.", "AI": {"tldr": "Existence and uniqueness of weak solutions for continuous generalized exchange-driven growth model with mass conservation properties.", "motivation": "To extend the discrete generalized exchange-driven growth model to a continuous framework and establish mathematical foundations for this coagulation variant where smaller particles detach from larger ones and merge with other particles.", "method": "Examined existence of weak solutions under suitable reaction rates, established uniqueness under additional rate conditions, and proved mass conservation properties for coagulation rates with linear bounds.", "result": "Proved existence of weak solutions, established uniqueness under specific conditions, and demonstrated that solutions conserve both mass and total number of particles for linearly bounded coagulation rates.", "conclusion": "The continuous version of the generalized exchange-driven growth model has well-defined mathematical properties including existence, uniqueness under certain conditions, and conservation laws, providing a solid foundation for further study of this coagulation variant."}}
{"id": "2509.01099", "pdf": "https://arxiv.org/pdf/2509.01099", "abs": "https://arxiv.org/abs/2509.01099", "authors": ["Ao Xu", "Zheng Zhao", "Ben-Rui Xu", "Li-Sheng Jiang"], "title": "Interpolation-supplemented lattice Boltzmann simulation of thermal convection on non-uniform meshes", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": "50 pages, 14 figures", "summary": "We present a systematic evaluation of an interpolation-supplemented lattice\nBoltzmann method (ISLBM) for simulating buoyancy-driven thermal convection on\nnon-uniform meshes. The ISLBM extends the standard lattice Boltzmann framework\nby incorporating quadratic interpolation during the streaming step, enabling\nflexible mesh refinement near solid boundaries while maintaining algorithmic\nsimplicity and parallel scalability. The method is implemented for a\ntwo-dimensional side-heated cavity at high Rayleigh numbers $10^6 \\leq Ra \\leq\n10^8$, and for a three-dimensional side-heated cavity at $10^5 \\leq Ra \\leq\n10^7$, with the Prandtl number fixed at $Pr=0.71$. Benchmark results show that\nthe ISLBM accurately captures thermal and velocity boundary layers, yielding\nNusselt and Reynolds numbers in close agreement with high-fidelity reference\ndata. Grid-convergence studies demonstrate nearly third-order accuracy for\nglobal quantities and about second-order for local fields. We further assess\nthe computational performance of the in-house LBM solver against two\nopen-source solvers: Nek5000 based on the spectral element method, and OpenFOAM\nbased on the finite volume method. Performance metrics, including million\nlattice updates per second (MLUPS) and wall-clock time per dimensionless time\nunit (WCTpDT), indicate that the ISLBM offers one to three orders of magnitude\nhigher efficiency in large-scale simulations. On GPU architectures, the ISLBM\nretains high computational performance: throughput on non-uniform meshes\nreaches 60 -- 70\\% of that on uniform meshes in terms of MLUPS, while the cost\nin WCTpDT is about three times higher. These results highlight the potential of\ninterpolation-based LBM approaches for high-fidelity simulations of thermal\nconvection on non-uniform meshes, providing a robust foundation for future\nextensions to turbulent flows.", "AI": {"tldr": "ISLBM extends lattice Boltzmann method with quadratic interpolation for buoyancy-driven thermal convection on non-uniform meshes, achieving high accuracy and 1-3 orders of magnitude higher efficiency compared to spectral element and finite volume methods.", "motivation": "To develop an efficient and accurate method for simulating thermal convection on non-uniform meshes while maintaining algorithmic simplicity and parallel scalability, particularly for high Rayleigh number flows.", "method": "Interpolation-supplemented lattice Boltzmann method (ISLBM) incorporating quadratic interpolation during streaming step, enabling flexible mesh refinement near boundaries. Tested on 2D/3D side-heated cavities at Ra=10^6-10^8 and Ra=10^5-10^7 respectively with Pr=0.71.", "result": "ISLBM accurately captures thermal/velocity boundary layers with close agreement to reference data. Achieves nearly third-order accuracy for global quantities, second-order for local fields. Shows 1-3 orders magnitude higher efficiency than Nek5000 and OpenFOAM. GPU performance reaches 60-70% of uniform mesh throughput.", "conclusion": "ISLBM provides a robust foundation for high-fidelity thermal convection simulations on non-uniform meshes with excellent computational efficiency, demonstrating potential for future turbulent flow applications."}}
{"id": "2509.01380", "pdf": "https://arxiv.org/pdf/2509.01380", "abs": "https://arxiv.org/abs/2509.01380", "authors": ["Qing Xia"], "title": "A geometrically robust unfitted boundary algebraic equation method based on discrete potentials and local basis functions", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "comment": null, "summary": "We present an unfitted boundary algebraic equation (BAE) method for solving\nelliptic partial differential equations in complex geometries. The method\nemploys lattice Green's functions on infinite regular grids combined with\ndiscrete potential theory to construct single and double layer potentials,\nwhich is a discrete analog to boundary integral method. Local basis functions\non cut cells accommodate arbitrary boundary conditions and seamlessly integrate\nwith the boundary algebraic equations. The difference potentials framework\nenables efficient treatment of nonhomogeneous terms and fast computation of\nlayer potentials via FFT-based solvers. We establish theoretical stability and\nconvergence through a novel interpolation operator framework. Key advantages of\nthe developed method include: dimension reduction, geometric flexibility,\nmesh-independent conditioning, small-cut stability, and uniform treatment of\nsmooth and non-smooth geometries. Numerical experiments validate accuracy and\nrobustness across ellipses and diamonds with varying aspect ratios and sharp\ncorners, and an application of potential flows in unbounded domains.", "AI": {"tldr": "Unfitted boundary algebraic equation method using lattice Green's functions and discrete potential theory for solving elliptic PDEs in complex geometries with dimension reduction and geometric flexibility.", "motivation": "To develop an efficient method for solving elliptic partial differential equations in complex geometries that avoids traditional mesh generation challenges and handles both smooth and non-smooth boundaries.", "method": "Uses lattice Green's functions on infinite regular grids with discrete potential theory to construct single/double layer potentials (discrete boundary integral method). Employs local basis functions on cut cells and difference potentials framework with FFT-based solvers for efficient computation.", "result": "Method achieves dimension reduction, geometric flexibility, mesh-independent conditioning, and small-cut stability. Numerical experiments show accuracy and robustness for ellipses, diamonds with varying aspect ratios, sharp corners, and potential flows in unbounded domains.", "conclusion": "The developed unfitted BAE method provides an effective approach for elliptic PDEs in complex geometries with theoretical stability, convergence guarantees, and practical advantages over traditional methods."}}
{"id": "2509.01355", "pdf": "https://arxiv.org/pdf/2509.01355", "abs": "https://arxiv.org/abs/2509.01355", "authors": ["Jos\u00e9 Carmona Tapia", "Paolo Malanchini", "Antonio J. Mart\u00ednez Aparicio", "Pedro J. Mart\u00ednez-Aparicio"], "title": "Regularizing effect of the natural growth term in quasilinear problems with sign-changing nonlinearities", "categories": ["math.AP"], "comment": null, "summary": "We investigate the existence and nonexistence of solutions to the Dirichlet\nproblem \\begin{equation*} \\tag{$P$} \\label{pba} \\left\\{ \\begin{alignedat}{2}\n-\\Delta_p u + g(u) |\\nabla u|^p &= \\lambda f(u) \\quad &&\\mbox{in} \\;\\; \\Omega,\n\\\\ u &= 0 \\quad &&\\mbox{on} \\;\\; \\partial\\Omega, \\end{alignedat} \\right.\n\\end{equation*} where $\\Omega\\subset \\mathbb{R}^N$ is a smooth bounded domain,\n$p\\in (1,\\infty)$, $\\lambda>0$ and $g\\in C(\\mathbb{R})$. Our main assumption is\nthat $:f \\mathbb{R}\\to \\mathbb{R}$ is a continuous function such that $f(s)>0$\nfor all $s\\in (\\alpha,\\beta)$, where $0<\\alpha<\\beta$ are two zeros of $f$.\n  If $f(0)\\geq 0$, we show that an area condition involving $f$ and $g$ is both\nsufficient and necessary in order to have a pair $(\\lambda,u)\\in\n\\mathbb{R}^+\\times C_0^1(\\overline{\\Omega})$, with $u\\geq 0$ and\n$\\|u\\|_{C(\\overline{\\Omega})}\\in (\\alpha,\\beta]$, solving~\\eqref{pba}.\n  We also study how the presence of the gradient term affects the existence of\nsolution. Roughly speaking, the more negative $g$ is, the stronger its\nregularizing effect on~\\eqref{pba}. We prove that, regardless of the shape of\n$f$, for any fixed $\\lambda$, there always exists a function $g$ such\nthat~\\eqref{pba} admits a nonnegative solution with maximum in\n$(\\alpha,\\beta]$.", "AI": {"tldr": "Study of existence/nonexistence of solutions to a Dirichlet problem with p-Laplacian and gradient-dependent nonlinearity, focusing on area conditions and regularization effects.", "motivation": "To understand how gradient terms affect the solvability of nonlinear elliptic PDEs with p-Laplacian operators, particularly examining the interplay between the nonlinearity f and gradient coefficient g.", "method": "Mathematical analysis of the Dirichlet problem using area conditions involving f and g, studying sufficient and necessary conditions for existence of nonnegative solutions with specific maximum bounds.", "result": "An area condition is both sufficient and necessary for solution existence when f(0)\u22650. The gradient term g has a regularizing effect - more negative g strengthens regularization. For any fixed \u03bb, there exists g such that a nonnegative solution exists with maximum in (\u03b1,\u03b2].", "conclusion": "The gradient term plays a crucial regularizing role in the p-Laplacian Dirichlet problem, with negative g values enhancing solution existence regardless of f's shape, and area conditions provide complete characterization of solvability."}}
{"id": "2509.01234", "pdf": "https://arxiv.org/pdf/2509.01234", "abs": "https://arxiv.org/abs/2509.01234", "authors": ["Weihang Ouyang", "Min Zhu", "Wei Xiong", "Si-Wei Liu", "Lu Lu"], "title": "RAMS: Residual-based adversarial-gradient moving sample method for scientific machine learning in solving partial differential equations", "categories": ["cs.CE", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Physics-informed neural networks (PINNs) and neural operators, two leading\nscientific machine learning (SciML) paradigms, have emerged as powerful tools\nfor solving partial differential equations (PDEs). Although increasing the\ntraining sample size generally enhances network performance, it also increases\ncomputational costs for physics-informed or data-driven training. To address\nthis trade-off, different sampling strategies have been developed to sample\nmore points in regions with high PDE residuals. However, existing sampling\nmethods are computationally demanding for high-dimensional problems, such as\nhigh-dimensional PDEs or operator learning tasks. Here, we propose a\nresidual-based adversarial-gradient moving sample (RAMS) method, which moves\nsamples according to the adversarial gradient direction to maximize the PDE\nresidual via gradient-based optimization. RAMS can be easily integrated into\nexisting sampling methods. Extensive experiments, ranging from PINN applied to\nhigh-dimensional PDEs to physics-informed and data-driven operator learning\nproblems, have been conducted to demonstrate the effectiveness of RAMS.\nNotably, RAMS represents the first efficient adaptive sampling approach for\noperator learning, marking a significant advancement in the SciML field.", "AI": {"tldr": "RAMS is a novel adaptive sampling method that moves samples along adversarial gradient directions to maximize PDE residuals, improving efficiency for high-dimensional SciML problems.", "motivation": "Existing sampling methods for physics-informed neural networks and neural operators are computationally expensive for high-dimensional PDEs and operator learning tasks, creating a need for more efficient adaptive sampling approaches.", "method": "Proposed Residual-based Adversarial-gradient Moving Sample (RAMS) method that optimizes sample placement by moving samples along adversarial gradient directions to maximize PDE residuals, compatible with existing sampling frameworks.", "result": "Extensive experiments show RAMS effectively improves performance for high-dimensional PINNs and both physics-informed and data-driven operator learning problems, demonstrating computational efficiency.", "conclusion": "RAMS represents the first efficient adaptive sampling approach for operator learning and marks a significant advancement in scientific machine learning by providing an effective solution for high-dimensional problems."}}
{"id": "2509.01531", "pdf": "https://arxiv.org/pdf/2509.01531", "abs": "https://arxiv.org/abs/2509.01531", "authors": ["Philipp Bringmann", "Dirk Praetorius"], "title": "Global convergence of adaptive least-squares finite element methods for nonlinear PDEs", "categories": ["math.NA", "cs.NA", "65N30, 65N50, 65N15"], "comment": null, "summary": "The Zarantonello fixed-point iteration is an established linearization scheme\nfor quasilinear PDEs with strongly monotone and Lipschitz continuous\nnonlinearity. This paper presents a weighted least-squares minimization for the\ncomputation of the update of this scheme. The resulting formulation allows for\na conforming finite element discretization of the primal and dual variable of\nthe PDE with arbitrary polynomial degree. The least-squares functional provides\na built-in a posteriori discretization error estimator in each linearization\nstep motivating an adaptive Uzawa-type algorithm with an outer linearization\nloop and an inner adaptive mesh-refinement loop. We prove R-linear convergence\nof the linearization iterates for arbitrary initial guesses. Particular focus\nis on the role of the weights in the least-squares functional of the linearized\nproblem and their influence on the robustness of the Zarantonello damping\nparameter. Numerical experiments illustrate the performance of the proposed\nalgorithm.", "AI": {"tldr": "Weighted least-squares minimization for Zarantonello fixed-point iteration updates, enabling conforming FEM discretization with built-in error estimators and adaptive mesh refinement.", "motivation": "To develop an efficient computational framework for quasilinear PDEs with strongly monotone and Lipschitz continuous nonlinearity using the established Zarantonello fixed-point iteration scheme.", "method": "Proposes a weighted least-squares minimization approach for computing updates in the Zarantonello scheme, allowing conforming finite element discretization with arbitrary polynomial degrees. Includes an adaptive Uzawa-type algorithm with outer linearization and inner adaptive mesh-refinement loops.", "result": "The method provides built-in a posteriori discretization error estimators and proves R-linear convergence of linearization iterates for arbitrary initial guesses. Numerical experiments demonstrate the algorithm's performance.", "conclusion": "The weighted least-squares formulation enhances the robustness of the Zarantonello damping parameter and enables efficient adaptive computation for quasilinear PDEs with strong theoretical convergence guarantees."}}
{"id": "2509.01475", "pdf": "https://arxiv.org/pdf/2509.01475", "abs": "https://arxiv.org/abs/2509.01475", "authors": ["Tomasz Cie\u015blak", "Kentaro Fujie", "Tatsuya Hosono"], "title": "Nonlinear Fisher information, corresponding functional inequalities and applications", "categories": ["math.AP", "35K59 (Primary) 35B45, 35K92, 35Q92 (Secondary)"], "comment": null, "summary": "We study the evolution of the nonlinear version of the Fisher information\nalong the quasilinear heat equation. We also provide a nonlinear version of a\nrecent functional inequality (Cie\\'slak--Fuest--Hajduk--Sier\\.z\\k{e}ga, 2024),\ncorresponding to the nonlinear heat equation. Next, applications of our version\nof nonlinear Fisher information to the 1D critical quasilinear fully parabolic\nKeller--Segel system are given. In particular, the global existence of\nsolutions to the critical nonlinear diffusion/nonlinear sensitivity 1D fully\nparabolic Keller--Segel system is obtained for certain type of diffusion. Last,\nbut not least, we also study the version of the Fisher information along the\n$p$-Laplace equation.", "AI": {"tldr": "Analysis of nonlinear Fisher information evolution in quasilinear heat equations, extension of functional inequalities, and applications to 1D Keller-Segel systems with global existence results.", "motivation": "To extend the concept of Fisher information to nonlinear settings and establish functional inequalities for quasilinear heat equations, with applications to biological systems modeled by Keller-Segel equations.", "method": "Studied evolution of nonlinear Fisher information along quasilinear heat equation, developed nonlinear version of functional inequality, applied to 1D critical quasilinear fully parabolic Keller-Segel system, and analyzed Fisher information for p-Laplace equation.", "result": "Obtained global existence of solutions for critical nonlinear diffusion/nonlinear sensitivity 1D fully parabolic Keller-Segel system for certain diffusion types, and established nonlinear functional inequalities.", "conclusion": "The nonlinear Fisher information framework provides powerful tools for analyzing quasilinear parabolic equations and establishes global existence results for critical biological systems with specific diffusion properties."}}
{"id": "2509.01293", "pdf": "https://arxiv.org/pdf/2509.01293", "abs": "https://arxiv.org/abs/2509.01293", "authors": ["Xiao Xue", "M. F. P. ten Eikelder", "Tianyue Yang", "Yiqing Li", "Kan He", "Shuo Wang", "Peter V. Coveney"], "title": "Equivariant U-Shaped Neural Operators for the Cahn-Hilliard Phase-Field Model", "categories": ["cs.LG", "physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "Phase separation in binary mixtures, governed by the Cahn-Hilliard equation,\nplays a central role in interfacial dynamics across materials science and soft\nmatter. While numerical solvers are accurate, they are often computationally\nexpensive and lack flexibility across varying initial conditions and\ngeometries. Neural operators provide a data-driven alternative by learning\nsolution operators between function spaces, but current architectures often\nfail to capture multiscale behavior and neglect underlying physical symmetries.\nHere we show that an equivariant U-shaped neural operator (E-UNO) can learn the\nevolution of the phase-field variable from short histories of past dynamics,\nachieving accurate predictions across space and time. The model combines global\nspectral convolution with a multi-resolution U-shaped architecture and\nregulates translation equivariance to align with the underlying physics. E-UNO\noutperforms standard Fourier neural operator and U-shaped neural operator\nbaselines, particularly on fine-scale and high-frequency structures. By\nencoding symmetry and scale hierarchy, the model generalizes better, requires\nless training data, and yields physically consistent dynamics. This establishes\nE-UNO as an efficient surrogate for complex phase-field systems.", "AI": {"tldr": "E-UNO: equivariant U-shaped neural operator for phase separation modeling that combines spectral convolution with multi-resolution architecture and translation equivariance, outperforming standard neural operators.", "motivation": "Numerical solvers for Cahn-Hilliard equation are computationally expensive and lack flexibility, while current neural operators fail to capture multiscale behavior and physical symmetries.", "method": "Uses equivariant U-shaped neural operator with global spectral convolution, multi-resolution architecture, and translation equivariance regulation to learn phase-field evolution from short historical dynamics.", "result": "Outperforms standard Fourier neural operator and U-shaped neural operator baselines, especially on fine-scale and high-frequency structures, with better generalization and less training data.", "conclusion": "E-UNO establishes an efficient surrogate for complex phase-field systems by encoding symmetry and scale hierarchy for physically consistent dynamics."}}
{"id": "2509.01572", "pdf": "https://arxiv.org/pdf/2509.01572", "abs": "https://arxiv.org/abs/2509.01572", "authors": ["Xiaodong Wang"], "title": "User Manual for Model-based Imaging Inverse Problem", "categories": ["math.NA", "cs.CV", "cs.NA"], "comment": null, "summary": "This user manual is intended to provide a detailed description on model-based\noptimization for imaging inverse problem. Theseproblems can be particularly\ncomplex and challenging, especially for individuals without prior exposure to\nconvex optimization orinverse problem theory, like myself. In light of this, I\nam writing this manual to clarify and systematically organize the\nmathematicalrationale underlying imaging inverse problems. This manual might\nnot be accurate in mathmatical notion but more focus on the logicalthinking on\nhow to solve and proceed to solve the problems. If you want to think deep about\nsomething, try to raise questions! Thismanual is seaprated into four sections,\naiming to answer the following four questions: (1) What is inverse imaging\nproblem? (2) Why optimization is used to solve the inverse imaging problem? (3)\nHow to solve the optimization problem? (4) How to implement the optimization\nalgorithm in real imaging system?", "AI": {"tldr": "A user manual explaining model-based optimization for imaging inverse problems, targeting beginners without prior optimization knowledge, organized into four key questions about problem definition, optimization rationale, solution methods, and practical implementation.", "motivation": "To provide accessible guidance on complex imaging inverse problems for individuals lacking background in convex optimization or inverse problem theory, focusing on logical thinking rather than rigorous mathematical notation.", "method": "Structured manual divided into four sections addressing: 1) defining inverse imaging problems, 2) explaining why optimization is used, 3) detailing solution methods for optimization problems, and 4) implementing optimization algorithms in real imaging systems.", "result": "A systematic educational resource that clarifies the mathematical rationale behind imaging inverse problems through a question-driven approach, making complex optimization concepts more accessible to beginners.", "conclusion": "This manual serves as a practical guide for understanding and solving imaging inverse problems through model-based optimization, emphasizing logical progression and practical implementation over mathematical rigor."}}
{"id": "2509.01505", "pdf": "https://arxiv.org/pdf/2509.01505", "abs": "https://arxiv.org/abs/2509.01505", "authors": ["Zuyu Ma"], "title": "Scattering norm estimate near the threshold for the energy-subcrtical NLS", "categories": ["math.AP", "35Q55"], "comment": "20 pages", "summary": "We consider the focusing energy-subcritical Schr\\\"odinger equations. In\nearlier works by Holmer-Roudenko \\cite{holmer}, Duyckaerts-Holmer-Roudenko\n\\cite{duyckaerts2}, Fang-Xie-Cazenave \\cite{fang}, Guevara \\cite{guevara} and\nlater by Dodson-Murphy \\cite{dodson1,dodson2} and Arora-Dodson-Murphy\n\\cite{arora}, they proved that scattering is the only dynamical behavior if the\n$H^1$ initial data satisfies\n$M(u_0)^{1-s_c}E(u_0)^{s_c}<M(Q)^{1-s_c}E(Q)^{s_c}$ and $\\| u\\|^{1-s_c}_{L^2}\\|\nu\\|^{s_c}_{\\dot{H}^1}<\\| Q\\|^{1-s_c}_{L^2}\\|Q\\|^{s_c}_{\\dot{H}^1}$, where $Q$\nis the ground state. In this paper, we establish asymptotic estimates for the\nupper bound of the scattering norms as $M(u_0)^{1-s_c}E(u_0)^{s_c}$ approaches\nthe threshold mass-energy threshold $M(Q)^{1-s_c}E(Q)^{s_c}$, which generalizes\nthe work of Duyckaerts-Merle \\cite{duyckaerts} on the energy-critical\nSchr\\\"odinger equation($s_c=1$).", "AI": {"tldr": "Asymptotic estimates for scattering norms in energy-subcritical Schr\u00f6dinger equations as mass-energy approaches threshold", "motivation": "Previous works established scattering behavior below mass-energy threshold, but no quantitative estimates near the threshold were available", "method": "Establish asymptotic estimates for upper bounds of scattering norms as mass-energy approaches the critical threshold M(Q)^{1-s_c}E(Q)^{s_c}", "result": "Generalizes Duyckaerts-Merle's work on energy-critical case to energy-subcritical Schr\u00f6dinger equations", "conclusion": "Provides quantitative scattering norm estimates near the mass-energy threshold, extending previous qualitative results"}}
{"id": "2509.01575", "pdf": "https://arxiv.org/pdf/2509.01575", "abs": "https://arxiv.org/abs/2509.01575", "authors": ["Kousalya Ramanujam", "Vembu Shanthi"], "title": "An efficient spline-based scheme on Shishkin-type meshes for solving singularly perturbed coupled systems with Robin boundary conditions", "categories": ["math.NA", "cs.NA", "65H10, 65L10, 65L11"], "comment": "20 pages, 6 figures", "summary": "In this paper, we investigate a weakly coupled system of singularly perturbed\nlinear reaction-diffusion equations with Robin boundary conditions, where the\nleading terms are multiplied by small positive parameters that may differ in\nmagnitude. The solution to this system exhibits overlapping and interacting\nboundary layers. To appropriately resolve these layers, we employ a standard\nShishkin mesh and propose a novel modification of Bakhvalov-Shishkin mesh. A\ncubic spline approximation is applied at the boundary conditions, while a\ncentral difference scheme is used at the interior points. The problem is then\nsolved on both meshes. It is demonstrated that the proposed scheme achieves\nalmost second-order convergence upto a logarithmic factor on the Shishkin mesh\nand exact second-order convergence on the modified Bakhvalov-Shishkin mesh. We\npresent numerical results to validate the accuracy of our findings.", "AI": {"tldr": "A numerical scheme for weakly coupled singularly perturbed reaction-diffusion equations with Robin boundary conditions using specialized meshes to handle boundary layers, achieving second-order convergence.", "motivation": "To solve systems of singularly perturbed reaction-diffusion equations with different small parameters and Robin boundary conditions, where solutions exhibit complex overlapping boundary layers that require specialized numerical treatment.", "method": "Employed standard Shishkin mesh and proposed a modified Bakhvalov-Shishkin mesh. Used cubic spline approximation at boundary conditions and central difference scheme at interior points to resolve the boundary layers.", "result": "The scheme achieves almost second-order convergence (up to logarithmic factor) on Shishkin mesh and exact second-order convergence on the modified Bakhvalov-Shishkin mesh, validated by numerical results.", "conclusion": "The proposed numerical approach effectively handles the challenging boundary layer problems in weakly coupled singularly perturbed systems with Robin boundary conditions, demonstrating high-order convergence on specialized meshes."}}
{"id": "2509.01650", "pdf": "https://arxiv.org/pdf/2509.01650", "abs": "https://arxiv.org/abs/2509.01650", "authors": ["Engin Ba\u015fako\u011flu", "Tadahiro Oh", "Yuzhao Wang"], "title": "Sharp unconditional well-posedness of the 2-$d$ periodic cubic hyperbolic nonlinear Schr\u00f6dinger equation", "categories": ["math.AP", "35Q55, 37G05"], "comment": "31 pages", "summary": "We study semilinear local well-posedness of the two-dimensional periodic\ncubic hyperbolic nonlinear Schr\\\"odinger equation (HNLS) in Fourier-Lebesgue\nspaces. By employing the Fourier restriction norm method, we first establish\nsharp semilinear local well-posedness of HNLS in Fourier-Lebesgue spaces\n(modulo the endpoint case), including almost scaling-critical Fourier-Lebesgue\nspaces. Then, by adapting the normal form approach, developed by the second\nauthor with Guo and Kwon (2013) and by the second and third authors (2021), to\nthe current hyperbolic setting, we establish sharp unconditional uniqueness of\nHNLS within the semilinear local well-posedness regime. As a key ingredient to\nboth results, we establish sharp counting estimates for the hyperbolic\nSchr\\\"odinger equation. As a byproduct of our analysis, we also obtain sharp\nunconditional uniqueness of the (usual) two-dimensional periodic cubic\nnonlinear Schr\\\"odinger equation in Fourier--Lebesgue spaces for $p \\ge 3$.", "AI": {"tldr": "Sharp semilinear local well-posedness and unconditional uniqueness for 2D periodic cubic hyperbolic NLS in Fourier-Lebesgue spaces using Fourier restriction norm method and normal form approach.", "motivation": "To establish precise local well-posedness and unconditional uniqueness results for the two-dimensional periodic cubic hyperbolic nonlinear Schr\u00f6dinger equation in Fourier-Lebesgue spaces, extending previous work on the standard NLS.", "method": "Employed Fourier restriction norm method for local well-posedness and adapted normal form approach for unconditional uniqueness, with sharp counting estimates for the hyperbolic Schr\u00f6dinger equation as a key ingredient.", "result": "Achieved sharp semilinear local well-posedness (modulo endpoint case) including almost scaling-critical Fourier-Lebesgue spaces, and established sharp unconditional uniqueness within the semilinear regime.", "conclusion": "Successfully obtained sharp results for both local well-posedness and unconditional uniqueness of 2D periodic cubic hyperbolic NLS, with the additional benefit of proving sharp unconditional uniqueness for the standard 2D periodic cubic NLS in Fourier-Lebesgue spaces for p \u2265 3."}}
{"id": "2509.01464", "pdf": "https://arxiv.org/pdf/2509.01464", "abs": "https://arxiv.org/abs/2509.01464", "authors": ["Yuan-Jinsheng Liu", "Tyler C. Sterling", "Shi Liu"], "title": "Dipolar Nematic State in Relaxor Ferroelectrics", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Relaxor ferroelectrics exhibit exceptional dielectric and electromechanical\nproperties, yet their microscopic origins remain elusive due to the interplay\nof hierarchical polar structures and chemical complexity. While models based on\npolar nanoregions or nanodomains offer valuable phenomenological insights, they\noften lack the first-principles predictive capability necessary for\nquantitatively describing functional properties such as piezoelectric\ncoefficients. Here, we use large-scale molecular dynamics simulations, enabled\nby a universal first-principles-based machine-learning interatomic potential,\nto investigate atomic-scale polar dynamics in canonical Pb-, Bi-, and Ba-based\nrelaxors. Across all systems, we uncover a universal dipolar nematic state,\ncharacterized by long-range orientational order of local polarizations without\nlocal alignment, challenging conventional polar cluster-based paradigms. We\nintroduce a universal order parameter, derived from the skewness of the\ndistributions of the local polarization autocorrelation functions, that\ncaptures the thermal evolution of both lead-based and lead-free systems within\na single master curve. This nematic order, and its robust structural memory\nunder electric field cycling, underpins key relaxor phenomena, including\ndiffuse phase transition, frequency-dependent dielectric dispersion, and\nreversible giant piezoelectricity. Our findings establish a unified microscopic\nframework for relaxors and present a broadly applicable statistical approach to\nunderstanding complex disordered materials.", "AI": {"tldr": "Universal dipolar nematic state discovered in relaxor ferroelectrics through large-scale MD simulations, challenging conventional polar cluster models and providing unified framework for understanding relaxor properties.", "motivation": "Relaxor ferroelectrics show exceptional dielectric and electromechanical properties but their microscopic origins remain unclear due to hierarchical polar structures and chemical complexity. Existing models lack first-principles predictive capability.", "method": "Large-scale molecular dynamics simulations using a universal first-principles-based machine-learning interatomic potential to investigate atomic-scale polar dynamics in Pb-, Bi-, and Ba-based relaxors.", "result": "Discovered a universal dipolar nematic state with long-range orientational order but no local alignment. Introduced universal order parameter based on skewness of local polarization autocorrelation functions that captures thermal evolution across all systems. Found robust structural memory under electric field cycling.", "conclusion": "Establishes a unified microscopic framework for relaxors with a broadly applicable statistical approach for understanding complex disordered materials, explaining key phenomena like diffuse phase transitions and giant piezoelectricity."}}
{"id": "2509.01855", "pdf": "https://arxiv.org/pdf/2509.01855", "abs": "https://arxiv.org/abs/2509.01855", "authors": ["A. Javeed", "D. P. Kouri", "D. Ridzal", "J. D. Steinman", "I. M. Ross"], "title": "A Million-Point Fast Trajectory Optimization Solver", "categories": ["math.NA", "cs.MS", "cs.NA", "cs.SY", "eess.SY", "math.OC"], "comment": "20 pages, 7 figures, AAS Paper 25-689", "summary": "One might argue that solving a trajectory optimization problem over a million\ngrid points is preposterous. How about solving such a problem at an incredibly\nfast computational time? On a small form-factor processor? Algorithmic details\nthat make possible this trifecta of breakthroughs are presented in this paper.\nThe computational mathematics that deliver these advancements are: (i) a\nBirkhoff-theoretic discretization of optimal control problems, (ii) matrix-free\nlinear algebra leveraging Krylov-subspace methods, and (iii) a near-perfect\nBirkhoff preconditioner that helps achieve $\\mathcal{O}(1)$ iteration speed\nwith respect to the grid size,~$N$. A key enabler of this high performance is\nthe computation of Birkhoff matrix-vector products at $\\mathcal{O}(N\\log(N))$\ntime using fast Fourier transform techniques that eliminate traditional\ncomputational bottlenecks. A numerical demonstration of this unprecedented\nscale and speed is illustrated for a practical astrodynamics problem.", "AI": {"tldr": "This paper presents a breakthrough method for solving million-point trajectory optimization problems at unprecedented speed on small processors using Birkhoff-theoretic discretization, matrix-free Krylov methods, and near-perfect preconditioning.", "motivation": "To overcome the computational challenges of solving large-scale trajectory optimization problems with millions of grid points, which are traditionally considered computationally prohibitive.", "method": "Uses three key mathematical advancements: (1) Birkhoff-theoretic discretization of optimal control problems, (2) matrix-free linear algebra with Krylov-subspace methods, and (3) a near-perfect Birkhoff preconditioner that enables O(1) iteration speed. Leverages FFT techniques for O(N log N) Birkhoff matrix-vector products.", "result": "Achieves unprecedented computational scale and speed, demonstrated through numerical experiments on practical astrodynamics problems with million-point grids.", "conclusion": "The proposed algorithmic framework enables solving previously intractable large-scale trajectory optimization problems efficiently on small form-factor processors, representing a significant advancement in computational optimal control."}}
{"id": "2509.01687", "pdf": "https://arxiv.org/pdf/2509.01687", "abs": "https://arxiv.org/abs/2509.01687", "authors": ["Junekey Jeon", "Andrej Zlatos"], "title": "Well-Posedness and Finite Time Singularity for Touching g-SQG Patches on the Plane", "categories": ["math.AP"], "comment": null, "summary": "We prove local well-posedness as well as singularity formation for the g-SQG\npatch model on the plane (so on a domain without a boundary), with\n$\\alpha\\in(0,\\frac 16]$ and patches being allowed to touch each other. We do\nthis by bypassing any auxiliary contour equations and tracking patch boundary\ncurves directly instead of their parametrizations. In our results, which are\nsharp in terms of $\\alpha$, the patch boundaries have $L^2$ curvatures and a\nsingularity occurs when at least one of these $L^2$-norms blows up in finite\ntime.", "AI": {"tldr": "Local well-posedness and singularity formation for g-SQG patch model on plane with \u03b1\u2208(0,1/6], allowing touching patches", "motivation": "Study the generalized surface quasi-geostrophic (g-SQG) patch model to understand local existence and finite-time singularity formation in fluid dynamics", "method": "Bypass auxiliary contour equations and directly track patch boundary curves instead of their parametrizations", "result": "Proved sharp results: patch boundaries have L\u00b2 curvatures, singularity occurs when L\u00b2-norms blow up in finite time", "conclusion": "The approach provides sharp analysis of g-SQG patch dynamics with direct boundary tracking method"}}
{"id": "2509.01754", "pdf": "https://arxiv.org/pdf/2509.01754", "abs": "https://arxiv.org/abs/2509.01754", "authors": ["Mohsen Asghari Ilani", "Yaser Mike Banad"], "title": "TransMatch: A Transfer-Learning Framework for Defect Detection in Laser Powder Bed Fusion Additive Manufacturing", "categories": ["cs.CV", "physics.comp-ph"], "comment": null, "summary": "Surface defects in Laser Powder Bed Fusion (LPBF) pose significant risks to\nthe structural integrity of additively manufactured components. This paper\nintroduces TransMatch, a novel framework that merges transfer learning and\nsemi-supervised few-shot learning to address the scarcity of labeled AM defect\ndata. By effectively leveraging both labeled and unlabeled novel-class images,\nTransMatch circumvents the limitations of previous meta-learning approaches.\nExperimental evaluations on a Surface Defects dataset of 8,284 images\ndemonstrate the efficacy of TransMatch, achieving 98.91% accuracy with minimal\nloss, alongside high precision, recall, and F1-scores for multiple defect\nclasses. These findings underscore its robustness in accurately identifying\ndiverse defects, such as cracks, pinholes, holes, and spatter. TransMatch thus\nrepresents a significant leap forward in additive manufacturing defect\ndetection, offering a practical and scalable solution for quality assurance and\nreliability across a wide range of industrial applications.", "AI": {"tldr": "TransMatch framework combines transfer learning and semi-supervised few-shot learning to detect surface defects in LPBF additive manufacturing with high accuracy using limited labeled data.", "motivation": "Surface defects in Laser Powder Bed Fusion pose significant risks to structural integrity, and there's a scarcity of labeled AM defect data that limits traditional detection methods.", "method": "TransMatch merges transfer learning and semi-supervised few-shot learning to leverage both labeled and unlabeled novel-class images, overcoming limitations of previous meta-learning approaches.", "result": "Achieved 98.91% accuracy with minimal loss on 8,284 image dataset, with high precision, recall, and F1-scores for multiple defect classes including cracks, pinholes, holes, and spatter.", "conclusion": "TransMatch represents a significant advancement in additive manufacturing defect detection, offering a practical and scalable solution for quality assurance across industrial applications."}}
{"id": "2509.01978", "pdf": "https://arxiv.org/pdf/2509.01978", "abs": "https://arxiv.org/abs/2509.01978", "authors": ["H. Hakula", "A. Rasila", "Y. Zheng"], "title": "The Conjugate Function Method for Surfaces with Elaborate Topological Types", "categories": ["math.NA", "cs.NA", "math.CV", "math.DG", "30Cxx, 30Fxx, 65E10, 65N30"], "comment": "19 pages, 13 figures", "summary": "The conjugate function method is an algorithm for numerical computation of\nconformal mappings for simply and multiply connected domains on surfaces. In\nthis paper the conjugate function method is generalized and refined to achieve\nthe same level of accuracy on simply and multiply connected planar domains and\nRiemann surfaces. The main challenge addressed here is the accurate and\nefficient construction of the conjugate problem for multiply connected domains.\nThe method relies on high-order finite element methods which allow for highly\naccurate computations of mappings on surfaces, including domains of complex\nboundary geometry containing strong singularities and cusps. The efficacy of\nthe proposed method is illustrated via an extensive set of numerical\nexperiments with error estimates.", "AI": {"tldr": "Generalization and refinement of conjugate function method for accurate conformal mapping computation on simply/multiply connected planar domains and Riemann surfaces using high-order finite elements", "motivation": "To address the challenge of accurate and efficient construction of conjugate problems for multiply connected domains, enabling highly accurate computations of conformal mappings on surfaces with complex geometries and singularities", "method": "High-order finite element methods applied to the conjugate function method, generalized for both simply and multiply connected planar domains and Riemann surfaces", "result": "Highly accurate computations achieved for domains with complex boundary geometry containing strong singularities and cusps, demonstrated through extensive numerical experiments with error estimates", "conclusion": "The refined conjugate function method provides effective numerical computation of conformal mappings with high accuracy on various domain types, including challenging multiply connected cases with complex geometries"}}
{"id": "2509.01715", "pdf": "https://arxiv.org/pdf/2509.01715", "abs": "https://arxiv.org/abs/2509.01715", "authors": ["Wonhyung Choi", "Junsik Bae", "Yong-Jung Kim"], "title": "Quadratic Growth Model with Discontinuity: A Link between Monostable and Bistable Traveling Waves", "categories": ["math.AP", "math.CA"], "comment": "26 pages, 11 figures", "summary": "We classify traveling waves and stationary solutions of a reaction-diffusion\nequation arising in population dynamics with Allee-type effects. The reaction\nterm is given by a quadratic polynomial with a discontinuity at zero, which\ncaptures finite-time extinction for sub-threshold populations. This\ndiscontinuity induces a free boundary in the wave profile, a phenomenon that\ndistinguishes the model from the classical logistic or Allen-Cahn equations. A\ncomplete scenario is presented that connects monostable and bistable traveling\nwaves through the wave speed parameter, thereby providing a unified framework\nfor their dynamics.", "AI": {"tldr": "Classification of traveling waves and stationary solutions in a reaction-diffusion equation with Allee effects and finite-time extinction discontinuity.", "motivation": "To understand population dynamics with Allee-type effects where sub-threshold populations face finite-time extinction, which creates free boundaries in wave profiles unlike classical models.", "method": "Analysis of a reaction-diffusion equation with quadratic polynomial reaction term featuring a discontinuity at zero, classifying traveling waves and stationary solutions through wave speed parameter.", "result": "A complete scenario connecting monostable and bistable traveling waves through wave speed parameter, providing a unified framework for their dynamics.", "conclusion": "The discontinuity-induced free boundary distinguishes this model from classical equations and enables a unified classification of wave dynamics in population systems with Allee effects."}}
{"id": "2509.01799", "pdf": "https://arxiv.org/pdf/2509.01799", "abs": "https://arxiv.org/abs/2509.01799", "authors": ["Mario U. Gaimann", "Miriam Klopotek"], "title": "Optimal information injection and transfer mechanisms for active matter reservoir computing", "categories": ["nlin.AO", "cond-mat.soft", "cs.LG", "physics.comp-ph"], "comment": "53 pages, 23 figures. Supplementary Videos:\n  https://doi.org/10.18419/DARUS-4806. Replication Data:\n  https://doi.org/10.18419/DARUS-4805", "summary": "Reservoir computing (RC) is a state-of-the-art machine learning method that\nmakes use of the power of dynamical systems (the reservoir) for real-time\ninference. When using biological complex systems as reservoir substrates, it\nserves as a testbed for basic questions about bio-inspired computation -- of\nhow self-organization generates proper spatiotemporal patterning. Here, we use\na simulation of an active matter system, driven by a chaotically moving input\nsignal, as a reservoir. So far, it has been unclear whether such complex\nsystems possess the capacity to process information efficiently and\nindependently of the method by which it was introduced. We find that when\nswitching from a repulsive to an attractive driving force, the system\ncompletely changes the way it computes, while the predictive performance\nlandscapes remain nearly identical. The nonlinearity of the driver's injection\nforce improves computation by decoupling the single-agent dynamics from that of\nthe driver. Triggered are the (re-)growth, deformation, and active motion of\nsmooth structural boundaries (interfaces), and the emergence of coherent\ngradients in speed -- features found in many soft materials and biological\nsystems. The nonlinear driving force activates emergent regulatory mechanisms,\nwhich manifest enhanced morphological and dynamic diversity -- arguably\nimproving fading memory, nonlinearity, expressivity, and thus, performance. We\nfurther perform RC in a broad variety of non-equilibrium active matter phases\nthat arise when tuning internal (repulsive) forces for information transfer.\nOverall, we find that active matter agents forming liquid droplets are\nparticularly well suited for RC. The consistently convex shape of the\npredictive performance landscapes, together with the observed phenomenological\nrichness, conveys robustness and adaptivity.", "AI": {"tldr": "Active matter systems can serve as effective reservoirs for computing when driven by chaotic inputs, with attractive forces triggering emergent structural patterns that enhance computational performance through improved fading memory and nonlinearity.", "motivation": "To understand how biological complex systems and active matter can process information efficiently as reservoir computing substrates, and to test whether such systems compute independently of the driving method.", "method": "Using simulations of active matter systems driven by chaotically moving input signals, switching between repulsive and attractive driving forces, and performing reservoir computing across various non-equilibrium active matter phases.", "result": "Attractive driving forces completely change computation methods while maintaining similar predictive performance. Nonlinear driving improves computation by decoupling agent dynamics, triggering emergent structural boundaries and coherent speed gradients. Liquid droplet formations show particularly good performance with consistently convex performance landscapes.", "conclusion": "Active matter systems, especially those forming liquid droplets, are well-suited for reservoir computing due to their robustness, adaptivity, and emergent regulatory mechanisms that enhance computational properties like fading memory and nonlinearity."}}
{"id": "2509.02091", "pdf": "https://arxiv.org/pdf/2509.02091", "abs": "https://arxiv.org/abs/2509.02091", "authors": ["Weiheng Zeng", "Ruoxi Lu", "Tiegang Liu"], "title": "CLINN: Conservation Law Informed Neural Network for Approximating Discontinuous Solutions", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Physics-informed Neural Network (PINN) faces significant challenges when\napproximating solutions to conservation laws, particularly in ensuring\nconservation and accurately resolving discontinuities. To address these\nlimitations, we propose Conservation Law-informed Neural Network (CLINN), a\nnovel framework that incorporates the boundedness constraint, implicit solution\nform, and Rankine-Hugoniot condition of scalar conservation laws into the loss\nfunction, thereby enforcing exact conservation properties. Furthermore, we\nintegrate a residual-based adaptive refinement (RAR) strategy to dynamically\nprioritize training near discontinuities, substantially improving the network's\nability to capture sharp gradients. Numerical experiments are conducted on\nbenchmark problems, including the inviscid Burgers equation, the\nLighthill-Whitham-Richards (LWR) traffic flow model, and the Buckley-Leverett\nproblem. Results demonstrate that CLINN achieves superior accuracy in resolving\nsolution profiles and discontinuity locations while reducing numeral\noscillations. Compared to conventional PINN, CLINN yields a maximum reduction\nof 99.2% in mean squared error (MSE).", "AI": {"tldr": "CLINN is a novel neural network framework that improves upon PINN by incorporating conservation law constraints and adaptive refinement to better handle discontinuities in conservation laws.", "motivation": "Physics-informed Neural Networks (PINN) struggle with conservation properties and discontinuity resolution when solving conservation laws, requiring a more robust approach.", "method": "Proposes Conservation Law-informed Neural Network (CLINN) that integrates boundedness constraint, implicit solution form, and Rankine-Hugoniot condition into loss function, plus residual-based adaptive refinement (RAR) for discontinuity handling.", "result": "CLINN achieves superior accuracy in resolving solution profiles and discontinuity locations with reduced oscillations, showing up to 99.2% reduction in mean squared error compared to conventional PINN.", "conclusion": "CLINN effectively addresses PINN's limitations in conservation law problems by enforcing exact conservation properties and improving discontinuity resolution through adaptive refinement strategies."}}
{"id": "2509.01783", "pdf": "https://arxiv.org/pdf/2509.01783", "abs": "https://arxiv.org/abs/2509.01783", "authors": ["Abdelkrim Barbara", "Ahmed Bousmaha", "Mohammed Shimi"], "title": "Embedding Results and Fractional $p(x,.)$-Laplacian Problem in Unbounded Domains", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we prove a new continuous embedding theorem for fractional\nSobolev spaces with variable exponents into variable exponent Lebesgue spaces\non unbounded domains. As an application, we study a class of nonlocal elliptic\nproblems driven by the fractional $p(x, \\cdot)$-Laplacian operator. Using\nvariational methods combined with the established embedding result, we prove\nthe existence of nontrivial weak solutions under suitable growth and regularity\nconditions on the nonlinearity.\\\\ A significant analytical challenge addressed\nin this work arises from both the nonlocal behavior of the fractional $p(x,\n\\cdot)$-Laplacian and the lack of compactness induced by the unboundedness of\nthe domain.", "AI": {"tldr": "New continuous embedding theorem for fractional Sobolev spaces with variable exponents into Lebesgue spaces on unbounded domains, applied to prove existence of nontrivial solutions for nonlocal elliptic problems.", "motivation": "Address analytical challenges from nonlocal behavior of fractional p(x,\u00b7)-Laplacian and lack of compactness due to unbounded domains in variable exponent function spaces.", "method": "Prove new continuous embedding theorem, then use variational methods combined with the embedding result to study nonlocal elliptic problems.", "result": "Established embedding theorem and proved existence of nontrivial weak solutions under suitable growth and regularity conditions on the nonlinearity.", "conclusion": "Successfully developed embedding results and variational techniques to handle nonlocal operators with variable exponents on unbounded domains, overcoming compactness issues."}}
{"id": "2509.02061", "pdf": "https://arxiv.org/pdf/2509.02061", "abs": "https://arxiv.org/abs/2509.02061", "authors": ["Haiwen Guan", "Troy Arcomano", "Ashesh Chattopadhyay", "Romit Maulik"], "title": "LUCIE-3D: A three-dimensional climate emulator for forced responses", "categories": ["cs.LG", "physics.ao-ph", "physics.comp-ph"], "comment": null, "summary": "We introduce LUCIE-3D, a lightweight three-dimensional climate emulator\ndesigned to capture the vertical structure of the atmosphere, respond to\nclimate change forcings, and maintain computational efficiency with long-term\nstability. Building on the original LUCIE-2D framework, LUCIE-3D employs a\nSpherical Fourier Neural Operator (SFNO) backbone and is trained on 30 years of\nERA5 reanalysis data spanning eight vertical {\\sigma}-levels. The model\nincorporates atmospheric CO2 as a forcing variable and optionally integrates\nprescribed sea surface temperature (SST) to simulate coupled ocean--atmosphere\ndynamics. Results demonstrate that LUCIE-3D successfully reproduces\nclimatological means, variability, and long-term climate change signals,\nincluding surface warming and stratospheric cooling under increasing CO2\nconcentrations. The model further captures key dynamical processes such as\nequatorial Kelvin waves, the Madden--Julian Oscillation, and annular modes,\nwhile showing credible behavior in the statistics of extreme events. Despite\nrequiring longer training than its 2D predecessor, LUCIE-3D remains efficient,\ntraining in under five hours on four GPUs. Its combination of stability,\nphysical consistency, and accessibility makes it a valuable tool for rapid\nexperimentation, ablation studies, and the exploration of coupled climate\ndynamics, with potential applications extending to paleoclimate research and\nfuture Earth system emulation.", "AI": {"tldr": "LUCIE-3D is a lightweight 3D climate emulator that captures atmospheric vertical structure, responds to climate forcings like CO2, and maintains computational efficiency while reproducing key climate patterns and dynamics.", "motivation": "To develop an efficient 3D climate model that captures vertical atmospheric structure and responds to climate change forcings while maintaining computational efficiency for rapid experimentation and research applications.", "method": "Built on LUCIE-2D framework using Spherical Fourier Neural Operator (SFNO) backbone, trained on 30 years of ERA5 reanalysis data across 8 vertical \u03c3-levels, with CO2 as forcing variable and optional sea surface temperature integration.", "result": "Successfully reproduces climatological means, variability, long-term climate change signals (surface warming, stratospheric cooling), captures key dynamical processes (equatorial Kelvin waves, MJO, annular modes), and shows credible extreme event statistics.", "conclusion": "LUCIE-3D provides a stable, physically consistent, and accessible tool for rapid climate experimentation with applications in coupled climate dynamics, paleoclimate research, and future Earth system emulation, training efficiently in under 5 hours on 4 GPUs."}}
{"id": "2509.02107", "pdf": "https://arxiv.org/pdf/2509.02107", "abs": "https://arxiv.org/abs/2509.02107", "authors": ["Shaoshuai Chu", "Michael Herty"], "title": "High-Order Schemes for Hyperbolic Conservation Laws Using Young Measures", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We develop high-order numerical schemes to solve random hyperbolic\nconservation laws using linear programming. The proposed schemes are high-order\nextensions of the existing first-order scheme introduced in [{\\sc S. Chu, M.\nHerty, M. Luk\\'a\\v{c}ov\\'a-Medvi{\\softd}ov\\'a, and Y. Zhou}, solving random\nhyperbolic conservation laws using linear programming], where a novel\nstructure-preserving numerical method using a concept of generalized,\nmeasure-valued solutions to solve random hyperbolic systems of conservation\nlaws is proposed, yielding a linear partial differential equation concerning\nthe Young measure and allowing the computation of approximations based on\nlinear programming problems. The second-order extension is obtained using\npiecewise linear reconstructions of the one-sided point values of the unknowns.\nThe fifth-order scheme is developed using the finite-difference alternative\nweighted essentially non-oscillatory (A-WENO) framework. These extensions\nsignificantly improve the resolution of discontinuities, as demonstrated by a\nseries of numerical experiments on both random (Burgers equation, isentropic\nEuler equations) and deterministic (discontinuous flux, pressureless gas\ndynamics, Burgers equation with non-atomic support) hyperbolic conservation\nlaws.", "AI": {"tldr": "High-order numerical schemes for random hyperbolic conservation laws using linear programming, extending first-order methods to second and fifth-order with improved discontinuity resolution.", "motivation": "To improve upon existing first-order schemes for solving random hyperbolic conservation laws by developing higher-order numerical methods that better resolve discontinuities.", "method": "Developed second-order scheme using piecewise linear reconstructions and fifth-order scheme using finite-difference alternative weighted essentially non-oscillatory (A-WENO) framework, both building on linear programming approach for generalized measure-valued solutions.", "result": "The high-order extensions significantly improve resolution of discontinuities in numerical experiments on various hyperbolic conservation laws including random Burgers equation, isentropic Euler equations, and deterministic problems.", "conclusion": "The proposed high-order schemes successfully extend the linear programming approach to random hyperbolic conservation laws, providing improved accuracy and discontinuity resolution compared to first-order methods."}}
{"id": "2509.01973", "pdf": "https://arxiv.org/pdf/2509.01973", "abs": "https://arxiv.org/abs/2509.01973", "authors": ["Alessandro Goffi"], "title": "Rate of convergence of the vanishing viscosity method for Hamilton-Jacobi equations with Neumann boundary conditions", "categories": ["math.AP"], "comment": null, "summary": "We study the quantitative small noise limit in the $L^\\infty$ norm of certain\ntime-dependent Hamilton-Jacobi equations equipped with Neumann boundary\nconditions, depending on the regularity of the data and the geometric\nproperties of the domain. We first provide a $\\mathcal{O}(\\sqrt{\\eps})$ rate of\nconvergence for Hamilton-Jacobi equations with locally Lipschitz Hamiltonians\nposed on convex domains of the Euclidean space. We then enhance this speed of\nconvergence in the case of quadratic Hamiltonians proving one-side rates of\norder $\\mathcal{O}(\\eps)$ and $\\mathcal{O}(\\eps^\\beta)$, $\\beta\\in(1/2,1)$. The\nresults exploit recent $L^1$ contraction estimates for Fokker-Planck equations\nwith bounded velocity fields on unbounded domains used to derive differential\nHarnack estimates for the corresponding Neumann heat flow.", "AI": {"tldr": "Study of convergence rates for Hamilton-Jacobi equations with Neumann boundary conditions in small noise limit, showing O(\u221a\u03b5) rates for Lipschitz Hamiltonians on convex domains and enhanced O(\u03b5) and O(\u03b5^\u03b2) rates for quadratic Hamiltonians.", "motivation": "To understand the quantitative behavior of small noise limits in Hamilton-Jacobi equations with Neumann boundary conditions, particularly how convergence rates depend on data regularity and domain geometry.", "method": "Uses recent L^1 contraction estimates for Fokker-Planck equations with bounded velocity fields on unbounded domains to derive differential Harnack estimates for the corresponding Neumann heat flow.", "result": "Achieved O(\u221a\u03b5) convergence rate for locally Lipschitz Hamiltonians on convex Euclidean domains, and improved rates of O(\u03b5) and O(\u03b5^\u03b2) for \u03b2\u2208(1/2,1) for quadratic Hamiltonians.", "conclusion": "The study provides quantitative convergence rates for small noise limits in Hamilton-Jacobi equations, demonstrating that better rates can be obtained for specific Hamiltonian structures and leveraging modern PDE techniques."}}
{"id": "2509.02131", "pdf": "https://arxiv.org/pdf/2509.02131", "abs": "https://arxiv.org/abs/2509.02131", "authors": ["Victorita Dolean", "Mark Fry", "Matthias Langer", "Emile Parolin", "Pierre-Henri Tournier"], "title": "Achieving wavenumber robustness in domain decomposition for heterogeneous Helmholtz equation: an overview of spectral coarse spaces", "categories": ["math.NA", "cs.NA", "65N55, 65N35, 65F10"], "comment": null, "summary": "Solving time-harmonic wave propagation problems in the frequency domain\nwithin heterogeneous media poses significant mathematical and computational\nchallenges, particularly in the high-frequency regime. Among the available\nnumerical approaches, domain decomposition methods are widely regarded as\neffective due to their suitability for parallel computing and their capacity to\nmaintain robustness with respect to physical parameters, such as the\nwavenumber. These methods can achieve near-constant time-to-solution as the\nwavenumber increases, though often at the expense of a computationally\nintensive coarse correction step. This work focuses on identifying the best\nalgorithms and numerical strategies for benchmark problems modelled by the\nHelmholtz equation. Specifically, we examine and compare several coarse spaces\nwhich are part of different families, e.g. GenEO (Generalised Eigenvalue\nOverlap) type coarse spaces and harmonic coarse spaces, that underpin two-level\ndomain decomposition methods. By leveraging spectral information and multiscale\napproaches, we aim to provide a comprehensive overview of the strengths and\nweaknesses of these methods. Numerical experiments demonstrate that the\neffectiveness of these coarse spaces depends on the specific problem and\nnumerical configuration, highlighting the trade-offs between computational\ncost, robustness, and practical applicability.", "AI": {"tldr": "Analysis of coarse space methods for Helmholtz equation domain decomposition, comparing GenEO and harmonic approaches for high-frequency wave propagation problems.", "motivation": "Solving time-harmonic wave problems in heterogeneous media at high frequencies is computationally challenging, requiring robust domain decomposition methods that maintain performance as wavenumber increases.", "method": "Examination and comparison of different coarse space families (GenEO type and harmonic coarse spaces) for two-level domain decomposition methods, using spectral information and multiscale approaches.", "result": "Numerical experiments show coarse space effectiveness depends on specific problem and configuration, revealing trade-offs between computational cost, robustness, and practical applicability.", "conclusion": "No single coarse space method is universally best; performance varies by problem type, highlighting the need for careful selection based on specific computational requirements and problem characteristics."}}
{"id": "2509.02023", "pdf": "https://arxiv.org/pdf/2509.02023", "abs": "https://arxiv.org/abs/2509.02023", "authors": ["Uwe Brauer", "Lavi Karp"], "title": "Global existence of the irrotational Euler-Norstrom equations with a positive cosmological constant: The gravitational field equation", "categories": ["math.AP", "35Q31"], "comment": null, "summary": "Our objective is to demonstrate the global existence of classical solutions\nfor the nonlinear irrotational Euler-Nordstroem system, which includes a linear\nequation of state and a cosmological constant. In this framework, the\ngravitational field is represented by a single scalar function that satisfies a\nspecific semi-linear wave equation. We focus on spatially periodic deviations\nfrom the background metric, which is why we study the semi-linear wave equation\non the three-dimensional torus $\\mathbb{T}^3$ within the Sobolev spaces\n$H^m(\\mathbb{T}^3)$. This work is divided into two parts. First, we examine the\nNordstroem equation with a source term generated by an irrotational fluid\ngoverned by a linear equation of state. In the second part, we analyze the full\ncoupled system. One reason for this separation is that an irrotational fluid\nwith a linear equation of state introduces a source term for the Nordstroem\nequation containing a nonlinear term of fractional order. This nonlinearity\nprecludes the direct application of the techniques used in our earlier work\n\\cite{Brauer_Karp_23}, where we relied on symmetric hyperbolic systems, energy\nestimates, and homogeneous Sobolev spaces. Instead, we develop an appropriate\nenergy functional and establish the corresponding energy estimates tailored to\nthe wave equation under consideration.", "AI": {"tldr": "Global existence of classical solutions for nonlinear irrotational Euler-Nordstroem system with linear equation of state and cosmological constant on 3D torus", "motivation": "To prove global existence of classical solutions for the coupled Euler-Nordstroem system with gravitational scalar field and cosmological constant, focusing on spatially periodic deviations from background metric", "method": "Two-part approach: 1) Analysis of Nordstroem equation with source term from irrotational fluid, 2) Analysis of full coupled system. Developed specialized energy functional and energy estimates tailored to the wave equation, as traditional symmetric hyperbolic system techniques were inadequate due to fractional-order nonlinearity", "result": "Established framework for proving global existence of classical solutions in Sobolev spaces H^m(T^3) by developing appropriate energy methods for the semi-linear wave equation", "conclusion": "Successfully developed specialized energy estimates to handle the fractional-order nonlinearity in the Euler-Nordstroem system, enabling proof of global existence for classical solutions on the three-dimensional torus"}}
{"id": "2509.02253", "pdf": "https://arxiv.org/pdf/2509.02253", "abs": "https://arxiv.org/abs/2509.02253", "authors": ["Erik Burman", "Fabian Heimann"], "title": "Higher Order Unfitted Space-Time Methods for Transport Problems", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this article, we present an Unfitted Space-Time Finite Element method for\nthe scalar transport equation posed on moving domains. We consider the case of\nthe domain boundary being transported by the same velocity field as the scalar\nconcentration inside the physical domain. A standard continuous Galerkin Finite\nelement space is considered on a fixed background mesh, as well as tensor\nproduct Space-Time elements, which can be discontinuous along time slice\nboundaries. For the computational geometry, we opt for a spatially second-order\naccurate approximation variant in the mathematical analysis. In particular, we\nestablish stability in a problem-specific norm and prove a priori error bounds\nof high order. Numerical examples illustrate these theoretical findings.", "AI": {"tldr": "Unfitted Space-Time FEM for scalar transport on moving domains with boundary moving at same velocity as concentration. Uses continuous Galerkin on fixed background mesh and tensor product elements.", "motivation": "To develop an accurate numerical method for scalar transport equations on domains with moving boundaries, where the boundary motion is governed by the same velocity field as the interior transport.", "method": "Unfitted Space-Time Finite Element method with continuous Galerkin on fixed background mesh and tensor product elements (discontinuous along time boundaries). Second-order spatially accurate geometry approximation.", "result": "Established stability in problem-specific norm and proved high-order a priori error bounds. Numerical examples validate theoretical findings.", "conclusion": "The proposed method provides stable and high-order accurate numerical solution for scalar transport problems on moving domains with consistent velocity fields."}}
{"id": "2509.02037", "pdf": "https://arxiv.org/pdf/2509.02037", "abs": "https://arxiv.org/abs/2509.02037", "authors": ["Seung-Yeon Cho", "Byung-Hoon Hwang", "Myeong-Su Lee", "Seok-Bae Yun"], "title": "Relativistic BGK model for reactive gas mixtures", "categories": ["math.AP", "35Q20, 82C40, 83A05, 80A32, 35Q75"], "comment": "21 pages, 10 figures", "summary": "We propose a BGK-type kinetic model for relativistic reactive gas mixtures.\nThis model serves as a computationally tractable yet physically consistent\nalternative to the corresponding Boltzmann equation. The relaxation operator is\nconstructed to ensure that the model correctly satisfies the conservation laws\nand relaxes to the proper equilibrium: a J\\\"{u}ttner distribution characterized\nby a common temperature, velocity, and chemical potentials that obey the law of\nmass action. Furthermore, we prove that the model satisfies an H-theorem with\nthe same entropy functional as the original Boltzmann equation. Finally,\nnumerical simulations are presented, which confirm that the model preserves the\nconserved quantities and exhibits entropy decay towards the proper J\\\"{u}ttner\nequilibrium.", "AI": {"tldr": "A BGK-type kinetic model for relativistic reactive gas mixtures that provides a computationally tractable alternative to the Boltzmann equation while maintaining physical consistency, conservation laws, and proper equilibrium behavior.", "motivation": "To develop a computationally efficient yet physically accurate model for relativistic reactive gas mixtures that can serve as an alternative to the complex Boltzmann equation while preserving key physical properties.", "method": "Constructed a BGK-type relaxation operator that ensures conservation laws are satisfied and the system relaxes to the proper J\u00fcttner equilibrium distribution characterized by common temperature, velocity, and chemical potentials obeying mass action law.", "result": "The model correctly satisfies conservation laws, relaxes to proper J\u00fcttner equilibrium, obeys an H-theorem with the same entropy functional as the original Boltzmann equation, and numerical simulations confirm preservation of conserved quantities and entropy decay.", "conclusion": "The proposed BGK-type kinetic model successfully provides a computationally tractable framework for relativistic reactive gas mixtures that maintains physical consistency, conservation properties, and proper thermodynamic behavior while being more practical than the full Boltzmann equation."}}
{"id": "2509.02288", "pdf": "https://arxiv.org/pdf/2509.02288", "abs": "https://arxiv.org/abs/2509.02288", "authors": ["Daniel Hoonhout", "Richard L\u00f6scher", "Carolina Urz\u00faa-Torres"], "title": "Paving the way to a $\\operatorname{T}$-coercive method for the wave equation", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we take a first step toward introducing a space-time\ntransformation operator $\\operatorname{T}$ that establishes\n$\\operatorname{T}$-coercivity for the weak variational formulation of the wave\nequation in space and time on bounded Lipschitz domains. As a model problem, we\nstudy the ordinary differential equation (ODE) $u'' + \\mu u = f$ for $\\mu>0$,\nwhich is linked to the wave equation via a Fourier expansion in space. For its\nweak formulation, we introduce a transformation operator $\\operatorname{T}_\\mu$\nthat establishes $\\operatorname{T}_\\mu$-coercivity of the bilinear form\nyielding an unconditionally stable Galerkin-Bubnov formulation with error\nestimates independent of $\\mu$. The novelty of the current approach is the\nexplicit dependence of the transformation on $\\mu$ which, when extended to the\nframework of partial differential equations, yields an operator acting in both\ntime and space. We pay particular attention to keeping the trial space as a\nstandard Sobolev space, simplifying the error analysis, while only the test\nspace is modified. The theoretical results are complemented by numerical\nexamples.", "AI": {"tldr": "Introduces a space-time transformation operator T for T-coercivity in wave equation weak formulations, providing unconditionally stable Galerkin-Bubnov methods with \u03bc-independent error estimates.", "motivation": "To develop stable variational formulations for wave equations that avoid parameter-dependent stability issues and simplify error analysis by keeping trial spaces as standard Sobolev spaces.", "method": "Proposes a transformation operator T_\u03bc that establishes T_\u03bc-coercivity for weak formulations, modifying only the test space while maintaining standard trial spaces. Uses ODE model u'' + \u03bcu = f linked to wave equations via Fourier expansion.", "result": "Achieves unconditionally stable Galerkin-Bubnov formulation with error estimates independent of parameter \u03bc. Numerical examples validate the theoretical results.", "conclusion": "The \u03bc-dependent transformation operator successfully establishes T-coercivity, providing stable formulations for wave equations with simplified analysis framework applicable to space-time problems."}}
{"id": "2509.02064", "pdf": "https://arxiv.org/pdf/2509.02064", "abs": "https://arxiv.org/abs/2509.02064", "authors": ["Yamin Wang", "Hui Yu"], "title": "Tangential touch between free and fixed boundaries for the fully nonlinear Alt-Phillips problem", "categories": ["math.AP"], "comment": null, "summary": "For the fully nonlinear Alt-Phillips problem with parameter $\\gamma\\in(1,2)$,\nwe show that the free boundary intersects the fixed boundary tangentially where\nthe Dirichlet data vanish.\n  For this range of $\\gamma$, this result is new even when the operator is the\nLaplacian.", "AI": {"tldr": "Free boundary intersects fixed boundary tangentially where Dirichlet data vanish for fully nonlinear Alt-Phillips problem with \u03b3\u2208(1,2)", "motivation": "Study the behavior of free boundaries in fully nonlinear Alt-Phillips problems, particularly focusing on the intersection points between free and fixed boundaries", "method": "Analysis of fully nonlinear Alt-Phillips problem with parameter \u03b3 in the range (1,2), examining boundary intersection behavior", "result": "Free boundary meets fixed boundary tangentially at points where Dirichlet boundary conditions vanish", "conclusion": "This tangential intersection result is novel even for the Laplacian case when \u03b3\u2208(1,2), providing new insights into free boundary behavior"}}
{"id": "2509.02307", "pdf": "https://arxiv.org/pdf/2509.02307", "abs": "https://arxiv.org/abs/2509.02307", "authors": ["Minghua Chen", "Jiankang Shi", "Fan Yu", "Zhi Zhou"], "title": "Correction of weighted and shifted seven-step BDF for parabolic equations with nonsmooth data", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "It is well known that the seven-step backward difference formula (BDF) is\nunstable for the parabolic equations, since it is not even zero-stable.\nHowever, a linear combination of two non zero-stable schemes, namely the\nseven-step BDF and its shifted counterpart, can yield $A(\\alpha)$ stable. Based\non this observation, the authors [Akrivis, Chen, and Yu, IMA J. Numer. Anal.,\nDOI:10.1093/imanum/drae089] propose the weighted and shifted seven-step BDF\nmethods for the parabolic equations, which stability regions are larger than\nthe standard BDF. Nonetheless, this approach is not directly applicable for the\nparabolic equations with nonsmooth data, which may suffer from severe order\nreduction. This motivates us to design proper correction time-stepping schemes\nto restore the desired $k$th-order convergence rate of the $k$-step weighted\nand shifted BDF ($k\\leq 7$) convolution quadrature for the parabolic problems.\nWe prove that the desired $k$th-order convergence can be recovered even if the\nsource term is discontinuous and the initial value is nonsmooth data. Numerical\nexperiments illustrate the theoretical results.", "AI": {"tldr": "The paper proposes correction schemes for weighted and shifted BDF methods to restore kth-order convergence for parabolic equations with nonsmooth data, overcoming order reduction issues.", "motivation": "Standard seven-step BDF is unstable for parabolic equations, and while weighted/shifted BDF methods improve stability, they suffer from severe order reduction with nonsmooth data like discontinuous source terms or rough initial values.", "method": "Design proper correction time-stepping schemes for k-step weighted and shifted BDF convolution quadrature (k\u22647) to handle parabolic problems with nonsmooth data.", "result": "The proposed correction schemes successfully restore the desired kth-order convergence rate even with discontinuous source terms and nonsmooth initial data.", "conclusion": "Numerical experiments confirm that the correction methods effectively recover optimal convergence rates for parabolic equations with challenging nonsmooth data conditions."}}
{"id": "2509.02081", "pdf": "https://arxiv.org/pdf/2509.02081", "abs": "https://arxiv.org/abs/2509.02081", "authors": ["Keefer Rowan"], "title": "Superexponential dissipation enhancement on $\\mathbb{T}^d$", "categories": ["math.AP"], "comment": "32 pages", "summary": "We construct incompressible velocity fields that exhibit faster than\nexponential dissipation for particular solutions to the advection-diffusion\nequation on $\\mathbb{T}^d$. In 2D, we construct a velocity field in\n$L^\\infty_{t,x}$ and exhibit a solution that decays with double exponential\nrate $e^{-C^{-1} e^{C^{-1}t}}$. In 3D, we construct a velocity field in\n$L^\\infty_t W^{1,\\infty}_x$ and exhibit a solution that decays with rate\n$e^{-C^{-1} t^2}$. In 4D, we construct a velocity field in $L^\\infty_t\nC^\\infty_x$ and exhibit a solution that decays with *some* superexponential\nrate.", "AI": {"tldr": "Construction of incompressible velocity fields that cause faster-than-exponential dissipation in advection-diffusion equations across different dimensions (2D, 3D, 4D) with varying velocity field regularities.", "motivation": "To demonstrate the existence of velocity fields that can produce accelerated dissipation rates beyond exponential decay in advection-diffusion processes, exploring the relationship between spatial dimension, velocity field regularity, and dissipation rates.", "method": "Construct specific incompressible velocity fields with different regularity properties (L\u221e, W1,\u221e, C\u221e) in 2D, 3D, and 4D, then analyze particular solutions to the advection-diffusion equation that exhibit the accelerated dissipation behavior.", "result": "Successfully constructed velocity fields: in 2D (L\u221e) producing double exponential decay e^{-C^{-1}e^{C^{-1}t}}, in 3D (W1,\u221e) producing t\u00b2 exponential decay e^{-C^{-1}t\u00b2}, and in 4D (C\u221e) producing some superexponential decay rate.", "conclusion": "The dimension and regularity of velocity fields significantly impact dissipation rates in advection-diffusion equations, with higher dimensions and smoother fields enabling increasingly rapid (superexponential) dissipation behavior."}}
{"id": "2509.02342", "pdf": "https://arxiv.org/pdf/2509.02342", "abs": "https://arxiv.org/abs/2509.02342", "authors": ["Ksenia Slepova", "Ivan Etoku Oiye", "Martin B. van Gijzen"], "title": "Multi-stage PDE-based image processing techniques for noisy MRI scans", "categories": ["math.NA", "cs.NA"], "comment": "24 pages, 7 figures", "summary": "Image denoising and image segmentation play essential roles in image\nprocessing. Partial differential equations (PDE)-based methods have proven to\nshow reliable results when incorporated in both denoising and segmentation of\nimages. In our work, we discuss a multi-stage PDE-based image processing\napproach. It relies upon the nonlinear diffusion for noise removal and\nclustering and region growing for segmentation. In the first stage of the\napproach, the raw image is computed from noisy measurement data. The second\nstage aims to filter out the noise using anisotropic diffusion. We couple these\nstages into one optimisation problem which allows us to incorporate a diffusion\ncoefficient based on a presegmented image. The third stage performs the final\nsegmentation of the image. We demonstrate our approach on both images for which\nthe ground truth is known and on MR measurements made by an experimental,\ninexpensive scanner.", "AI": {"tldr": "A multi-stage PDE-based approach combining image denoising and segmentation using nonlinear diffusion for noise removal and clustering/region growing for segmentation.", "motivation": "PDE-based methods have shown reliable results for both image denoising and segmentation, but combining them effectively into a unified optimization framework can improve performance.", "method": "Three-stage approach: 1) Compute raw image from noisy data, 2) Filter noise using anisotropic diffusion coupled with optimization incorporating diffusion coefficient from presegmented image, 3) Final segmentation using clustering and region growing.", "result": "The approach was demonstrated on both ground truth images and MR measurements from an experimental, inexpensive scanner, showing effective performance.", "conclusion": "The proposed multi-stage PDE-based framework successfully integrates denoising and segmentation into a unified optimization problem, providing reliable results for image processing applications."}}
{"id": "2509.02140", "pdf": "https://arxiv.org/pdf/2509.02140", "abs": "https://arxiv.org/abs/2509.02140", "authors": ["Mohamed Ben Ayed", "Habib Fourti"], "title": "Non existence of solutions for a slightly super-critical elliptic problem with non-power nonlinearity", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we are concerned with the following elliptic equation $$ (\nSC_\\varepsilon ) \\qquad\n  \\begin{cases} -\\Delta u = |u|^{4/(n-2)}u [\\ln (e+|u|)]^\\varepsilon & \\hbox{\nin } \\Omega,\\\\ u = 0 & \\hbox{ on }\\partial \\Omega, \\end{cases} $$ where $\\Omega\n$ is a smooth bounded open domain in $\\mathbb{R}^n, \\ n\\geq 3$ and $\\varepsilon\n>0$. In Comm. Contemp. Math. (2003), Ben Ayed et al. showed that the slightly\nsupercritical usual elliptic problem has no single peaked solution. Here we\nextend their result for problem $( SC_\\varepsilon )$ when $\\varepsilon$ is\nsmall enough, and that by assuming a new assumption.", "AI": {"tldr": "The paper extends previous results by showing that the slightly supercritical elliptic problem with logarithmic perturbation has no single-peaked solutions for small enough \u03b5 under a new assumption.", "motivation": "To extend the non-existence result for single-peaked solutions from the standard supercritical elliptic problem to the logarithmic perturbation case, addressing a gap in the understanding of such nonlinear elliptic equations.", "method": "Mathematical analysis of the elliptic equation with logarithmic perturbation term, building on previous work by Ben Ayed et al. and introducing a new assumption to handle the logarithmic nonlinearity.", "result": "The authors prove that for sufficiently small \u03b5 > 0, the slightly supercritical elliptic problem with logarithmic term has no single-peaked solutions.", "conclusion": "The logarithmic perturbation preserves the non-existence property of single-peaked solutions observed in the standard supercritical case, extending previous mathematical results to this more complex nonlinear setting."}}
{"id": "2509.02435", "pdf": "https://arxiv.org/pdf/2509.02435", "abs": "https://arxiv.org/abs/2509.02435", "authors": ["Yingjian Liu", "Monish Yadav Pabbala", "Jiachen Guo", "Chanwook Park", "Gino Domel", "Wing Kam Liu", "Dong Qian"], "title": "A Convolutional Hierarchical Deep-learning Neural Network (C-HiDeNN) Framework for Non-linear Finite Element/Meshfree Analysis", "categories": ["math.NA", "cs.NA", "math.AP"], "comment": null, "summary": "We present a framework for the Convolutional Hierarchical Deep Neural Network\n(C-HiDeNN) tailored for nonlinear finite element and meshfree analysis.\nBuilding upon the structured foundation of HiDeNN, which includes the\nevaluation of shape function derivatives, adaptivity, and material derivatives,\nC-HiDeNN introduces a convolution operator to enhance the HiDeNN approximation.\nA distinctive feature of C-HiDeNN is its expanded set of optimization\nparameters, such as the polynomial order 'p,' dilation parameter 'a,' patch\nsize 's,' and nodal position 'X'. These parameters function as the weights and\nbiases within the C-HiDeNN patch. In addition, C-HiDeNN can be prescribed in\nregions where high resolution is desired to adaptively improve prediction\naccuracy. To demonstrate the effectiveness of this framework, we provide\nnumerical examples in the context of nonlinear finite element and meshfree\nanalysis. The results show that our approach achieves significantly higher\naccuracy compared to the standard Finite Element Method (FEM) while\nsubstantially reducing computational costs.", "AI": {"tldr": "C-HiDeNN is a convolutional hierarchical deep neural network framework that enhances nonlinear finite element and meshfree analysis through convolution operators and expanded optimization parameters, achieving higher accuracy than standard FEM with reduced computational costs.", "motivation": "To improve upon existing HiDeNN framework by introducing convolution operations and additional optimization parameters to enhance approximation capabilities for nonlinear finite element and meshfree analysis, addressing the need for higher accuracy with lower computational costs.", "method": "Extends HiDeNN with convolution operators and introduces additional optimization parameters including polynomial order 'p', dilation parameter 'a', patch size 's', and nodal position 'X'. These parameters serve as weights and biases within the C-HiDeNN patch structure, enabling adaptive refinement in regions requiring high resolution.", "result": "The framework demonstrates significantly higher accuracy compared to standard Finite Element Method (FEM) while substantially reducing computational costs in numerical examples of nonlinear finite element and meshfree analysis.", "conclusion": "C-HiDeNN provides an effective convolutional hierarchical deep learning framework that successfully enhances nonlinear computational mechanics analysis through improved approximation capabilities and adaptive optimization parameters, offering superior accuracy with reduced computational burden."}}
{"id": "2509.02158", "pdf": "https://arxiv.org/pdf/2509.02158", "abs": "https://arxiv.org/abs/2509.02158", "authors": ["Zhi-Yuan Cui", "Yuan Li", "Dun Zhao"], "title": "Well-posedness and scattering of odd solutions for the defocusing INLS in one dimension", "categories": ["math.AP"], "comment": null, "summary": "We consider the defocusing inhomogeneous nonlinear Schr\\\"{o}dinger equation\n  $i\\partial_tu+\\Delta u= |x|^{-b}|u|^{\\alpha}u,$\n  where $0<b<1$ and $0<\\alpha<\\infty$. This problem has been extensively\nstudied for initial data in $H^1(\\R^N)$ with $N\\geq 2$. However, in the\none-dimensional setting, due to the difficulty in dealing with the singularity\nfactor $|x|^{-b}$, the well-posedness and scattering in $H^1(\\R)$ are scarce,\nand almost known results have been established in $H^s(\\R)$ with $s<1$. In this\npaper, we focus on the odd initial data in $H^1(\\R)$. For this case, we\nestablish local well-posedness for $0<\\alpha<\\infty$, as well as global\nwell-posedness and scattering for $4-2b<\\alpha<\\infty$, which corresponds to\nthe mass-supercritical case. The key ingredient is the application of the\none-dimensional Hardy inequality for odd functions to overcome the singularity\ninduced by $|x|^{-b}$. Our proof is based on the Strichartz estimates and\nemploys the concentration-compactness/rigidity method developed by Kenig-Merle\nas well as the technique for handling initial data living far from the origin,\nas proposed by Miao-Murphy-Zheng. Our results fill a gap in the theory of\nwell-posedness and energy scattering for the inhomogeneous nonlinear\nSchr\\\"{o}dinger equation in one dimension.", "AI": {"tldr": "This paper establishes local and global well-posedness and scattering results for the defocusing inhomogeneous nonlinear Schr\u00f6dinger equation in one dimension with odd initial data in H^1(R), overcoming the singularity issue using Hardy inequality for odd functions.", "motivation": "Previous studies on the defocusing inhomogeneous nonlinear Schr\u00f6dinger equation have been limited in one dimension due to difficulties handling the singularity factor |x|^{-b}, with most results established in H^s(R) with s<1 rather than H^1(R).", "method": "The authors use the one-dimensional Hardy inequality for odd functions to overcome the singularity, combined with Strichartz estimates, the concentration-compactness/rigidity method by Kenig-Merle, and techniques for handling initial data far from the origin by Miao-Murphy-Zheng.", "result": "Local well-posedness is established for 0<\u03b1<\u221e, and global well-posedness and scattering are proven for 4-2b<\u03b1<\u221e (mass-supercritical case) for odd initial data in H^1(R).", "conclusion": "The results fill a significant gap in the theory of well-posedness and energy scattering for the inhomogeneous nonlinear Schr\u00f6dinger equation in one dimension, providing the first comprehensive treatment for odd initial data in H^1(R)."}}
{"id": "2509.02465", "pdf": "https://arxiv.org/pdf/2509.02465", "abs": "https://arxiv.org/abs/2509.02465", "authors": ["Ruben Aylwin", "G\u00f6ksu Oruc", "Karsten Urban"], "title": "Fractional differential equations: non-constant coefficients, simulation and model reduction", "categories": ["math.NA", "cs.NA", "26A33, 34K37, 65N30"], "comment": null, "summary": "We consider boundary value problems with Riemann-Liouville fractional\nderivatives of order $s\\in (1, 2)$ with non-constant diffusion and reaction\ncoefficients. A variational formulation is derived and analyzed leading to the\nwell-posedness of the continuous problem and its Finite Element discretization.\nThen, the Reduced Basis Method through a greedy algorithm for parametric\ndiffusion and reaction coefficients is analyzed. Its convergence properties,\nand in particular the decay of the Kolmogorov $n$-width, are seen to depend on\nthe fractional order $s$. Finally, numerical results confirming our findings\nare presented.", "AI": {"tldr": "Analysis of boundary value problems with Riemann-Liouville fractional derivatives (order 1-2) using variational formulation, finite element discretization, and reduced basis method with greedy algorithm for parametric coefficients.", "motivation": "To address boundary value problems involving fractional derivatives with non-constant diffusion and reaction coefficients, developing efficient computational methods for parametric analysis.", "method": "Derived variational formulation, analyzed well-posedness, implemented finite element discretization, and applied reduced basis method with greedy algorithm for parametric coefficients.", "result": "Established well-posedness of continuous problem and discretization, demonstrated convergence properties dependent on fractional order s, and presented numerical validation.", "conclusion": "The reduced basis method with greedy algorithm effectively handles parametric fractional derivative problems, with convergence behavior directly influenced by the fractional order parameter s."}}
{"id": "2509.02176", "pdf": "https://arxiv.org/pdf/2509.02176", "abs": "https://arxiv.org/abs/2509.02176", "authors": ["Anna Rozanova-Pierrat"], "title": "On analysis of problems of mathematical physics with non-Lipschitz boundaries", "categories": ["math.AP", "math.FA"], "comment": null, "summary": "We review recent advances in solving problems of mathematical physics on\ndomains with irregular boundaries in Rn. We distinguish two frameworks: a\nmeasure-free approach in the image of the trace operator spaces for extension\ndomains and an L2-approach depending on a d-upper regular boundary measure. In\nboth cases, the domains can have boundaries with different Hausdorff dimensions\ninside the interval (n -- 2, n). The generalization of the\nPoincar{\\'e}-Steklov/Dirichlet-to-Neumann operator for these two contexts is\ngiven. To illustrate the established convergence of spectral problems for\nelliptic operators with Robin boundary conditions, we give a numerical example\nof the stability of localized eigenfunctions, using results of M. Graffin.", "AI": {"tldr": "Review of mathematical physics methods for domains with irregular boundaries using measure-free and L2 approaches, with generalization of Poincar\u00e9-Steklov operators and numerical validation.", "motivation": "To address the challenge of solving mathematical physics problems on domains with irregular boundaries that may have varying Hausdorff dimensions, requiring specialized analytical frameworks.", "method": "Two frameworks: measure-free approach using trace operator spaces for extension domains, and L2-approach based on d-upper regular boundary measure. Both handle boundaries with Hausdorff dimensions in (n-2, n).", "result": "Successful generalization of Poincar\u00e9-Steklov/Dirichlet-to-Neumann operators for both contexts. Numerical example demonstrates stability of localized eigenfunctions for elliptic operators with Robin boundary conditions.", "conclusion": "The paper establishes effective mathematical frameworks for handling irregular boundary problems and validates the convergence of spectral problems through numerical evidence, advancing computational methods for complex domain geometries."}}
{"id": "2509.00020", "pdf": "https://arxiv.org/pdf/2509.00020", "abs": "https://arxiv.org/abs/2509.00020", "authors": ["Sabiju Valiya Valappil", "Alejandro M. Aragon", "Johannes F. L. Goosen"], "title": "A semi-analytical approach to characterize high-frequency three-dimensional wave propagation through clamp-on flowmeters", "categories": ["physics.flu-dyn", "cs.NA", "math.NA"], "comment": null, "summary": "Wave propagation analysis at high frequencies is essential for applications\ninvolving ultrasound waves, such as clamp-on ultrasonic flowmeters. However, it\nis extremely challenging to perform a 3D transient analysis of a clamp-on\nflowmeter using standard tools such as finite element analysis (FEA) due to the\nenormous associated computational cost. In this study, we separate the clamp-on\nflowmeter into different domains and analyze them separately. Wave propagation\nin the fluid domain is analyzed via FEA at low frequencies (100 kHz, 200 kHz,\nand 500 kHz) and using ray tracing at high frequencies (1 MHz). The behavior in\nthe solid domain (wedges and pipe wall) is analytically characterized via\ngeometric projection. All these individual analyses provide us with different\nscaling factors with which the waves in the respective domains scale when 3D\neffects are considered. The complete clamp-on system is then analyzed in 2D via\nthe Discontinuous Galerkin (DG) method to obtain the response at the receiver.\nThe receiving signal is then scaled using the aforementioned scaling factors to\naccurately capture the wave propagation behavior of the clamp-on system in 3D.\nThe output signal from the 2D analysis then becomes much clearer so that the\nfluid signal can be identified straightforwardly, which would be nearly\nimpossible otherwise.", "AI": {"tldr": "A hybrid computational approach combining FEA, ray tracing, analytical methods, and 2D DG analysis with scaling factors to efficiently model 3D wave propagation in clamp-on ultrasonic flowmeters at high frequencies.", "motivation": "Traditional 3D transient analysis of clamp-on ultrasonic flowmeters using finite element analysis is computationally prohibitive at high frequencies, creating a need for more efficient modeling approaches.", "method": "Separated the system into fluid and solid domains, analyzed fluid domain with FEA at low frequencies and ray tracing at high frequencies, characterized solid domain analytically via geometric projection, then performed 2D DG analysis and applied scaling factors to capture 3D effects.", "result": "The hybrid approach successfully captured 3D wave propagation behavior, producing clearer output signals that enable straightforward identification of fluid signals that would be nearly impossible with traditional methods.", "conclusion": "The proposed multi-domain hybrid computational framework provides an efficient and accurate alternative to computationally expensive 3D FEA for high-frequency wave propagation analysis in clamp-on ultrasonic flowmeters."}}
{"id": "2509.02205", "pdf": "https://arxiv.org/pdf/2509.02205", "abs": "https://arxiv.org/abs/2509.02205", "authors": ["Jo{\u00e3}o Miguel Machado", "Guilherme Mazanti", "Laurent Pfeiffer"], "title": "From Nash to Cournot--Nash via $\u0393$-convergence", "categories": ["math.AP"], "comment": null, "summary": "This work addresses the issue of the convergence of an $N$-player game\ntowards a limit model involving a continuum of players, as the number of agents\n$N$ goes to infinity. More precisely, we investigate the convergence of Nash\nequilibria to a Cournot--Nash equilibrium of the limit model. When the cost\nfunction of the players is the first variation of some potential function,\nequilibria can be characterized by a stationarity condition, satisfied in\nparticular by the minimizers of the potential. We demonstrate such a\ncharacterization under low regularity assumptions. Then we focus on the case\nwhere the players interact in a pairwise fashion; in this case we show that the\noriginal sequence of $N$-player games also admit a potential structure and\nprove that their corresponding potential functions converge in the sense of\n$\\Gamma$-convergence to the potential function of the limit game.", "AI": {"tldr": "Analysis of convergence from N-player games to continuum models, focusing on Nash equilibria convergence to Cournot-Nash equilibria and potential function structure.", "motivation": "To understand how finite-player game equilibria converge to continuum limit models as the number of players approaches infinity, particularly for games with potential structure.", "method": "Characterize equilibria via stationarity conditions under low regularity assumptions, analyze pairwise interaction games, and prove \u0393-convergence of potential functions.", "result": "Demonstrated characterization of equilibria through stationarity conditions, showed N-player games maintain potential structure, and proved convergence of potential functions to the limit game's potential.", "conclusion": "The work establishes rigorous convergence results from finite to continuum player models, providing mathematical foundation for analyzing large population games through potential function methods."}}
{"id": "2509.00171", "pdf": "https://arxiv.org/pdf/2509.00171", "abs": "https://arxiv.org/abs/2509.00171", "authors": ["Dong An", "Pedro C. S. Costa", "Dominic W. Berry"], "title": "Large time-step discretisation of adiabatic quantum dynamics", "categories": ["quant-ph", "cs.NA", "math.NA"], "comment": "48 pages, 5 figures", "summary": "Adiabatic quantum computing is a general framework for preparing eigenstates\nof Hamiltonians on quantum devices. However, its digital implementation\nrequires an efficient Hamiltonian simulation subroutine, which may introduce\nextra computational overhead or complicated quantum control logic. In this\nwork, we show that the time step sizes in time discretization can be much\nlarger than expected, and the overall complexity is greatly reduced.\nRemarkably, regardless of the general convergence order of the numerical\nmethod, we can choose a uniform time step size independent of tolerated error\nand evolution time for sufficiently accurate simulation. Furthermore, with the\nboundary cancellation condition where the continuous diabatic errors are\nexponentially suppressed, we provide strong evidence on an exponential\nconvergence of even first-order Trotter with uniform time step size. We apply\nour analysis to the example of adiabatic unstructured search and show several\npreferable features of the Trotterized adiabatic approach: it can match the\nGrover lower bound, it does not require a priori knowledge on the number of\nmarked states, and its performance can be asymptotically comparable with that\nof the quantum approximate optimization algorithm.", "AI": {"tldr": "Digital adiabatic quantum computing can use much larger time steps than expected, reducing complexity. Uniform time steps independent of error tolerance and evolution time are possible, with evidence of exponential convergence for first-order Trotter methods.", "motivation": "Digital implementation of adiabatic quantum computing requires efficient Hamiltonian simulation, which often introduces computational overhead and complex quantum control logic. The goal is to simplify this process and reduce complexity.", "method": "The paper shows that time step sizes in time discretization can be much larger than expected. It demonstrates that uniform time step sizes independent of tolerated error and evolution time can be chosen for sufficiently accurate simulation, with boundary cancellation conditions that exponentially suppress continuous diabatic errors.", "result": "The analysis reveals an exponential convergence of even first-order Trotter methods with uniform time step size. When applied to adiabatic unstructured search, the Trotterized adiabatic approach matches the Grover lower bound, doesn't require prior knowledge of marked states, and performs comparably to quantum approximate optimization algorithms.", "conclusion": "The findings significantly reduce the complexity of digital adiabatic quantum computing by allowing larger, uniform time steps while maintaining accuracy, making the approach more practical and efficient for quantum computation."}}
{"id": "2509.02215", "pdf": "https://arxiv.org/pdf/2509.02215", "abs": "https://arxiv.org/abs/2509.02215", "authors": ["Xushan Huang", "Hobin Lee", "HyeonSeop Oh"], "title": "Stability of viscous shock for the Navier-Stokes-Fourier system: outflow and impermeable wall problems", "categories": ["math.AP"], "comment": null, "summary": "We investigate the time-asymptotic stability of solutions to the\none-dimensional Navier-Stokes-Fourier system in the half space, focusing on the\noutflow and impermeable wall problems. When the asymptotic profile determined\nby the prescribed constant states at the boundary and at the far field is a\nviscous shock, we show that the solution converges asymptotically to the\nviscous shock profile, up to a dynamical shift, provided the initial\nperturbation and the shock amplitude are sufficiently small. In order to obtain\nour results, we employ the method of a-contraction with shifts. Although the\nimpermeable wall problem is technically simpler to analyze in Lagrangian mass\ncoordinates, the outflow problem leads to a free boundary in that framework.\nTherefore, we use Eulerian coordinates to provide a unified approach to both\nproblems. This is the first result on the time-asymptotic stability of viscous\nshocks for initial-boundary value problems of the Navier-Stokes-Fourier system\nfor the outflow and impermeable wall cases.", "AI": {"tldr": "Stability analysis of viscous shocks in 1D Navier-Stokes-Fourier system for outflow and impermeable wall boundary problems, showing convergence to shock profiles with small perturbations.", "motivation": "To establish time-asymptotic stability of viscous shock solutions in the Navier-Stokes-Fourier system for boundary value problems, particularly addressing outflow and impermeable wall cases which haven't been previously studied.", "method": "Employed the method of a-contraction with shifts in Eulerian coordinates to provide a unified approach for both outflow and impermeable wall problems, avoiding free boundary issues that arise in Lagrangian coordinates.", "result": "Proved that solutions converge asymptotically to viscous shock profiles (up to a dynamical shift) when initial perturbations and shock amplitude are sufficiently small.", "conclusion": "This represents the first stability result for viscous shocks in initial-boundary value problems of the Navier-Stokes-Fourier system for outflow and impermeable wall cases, demonstrating successful application of a-contraction methods in Eulerian coordinates."}}
{"id": "2509.00224", "pdf": "https://arxiv.org/pdf/2509.00224", "abs": "https://arxiv.org/abs/2509.00224", "authors": ["Alejandro N. Diaz", "Jacob T. Needels", "Irina K. Tezaur", "Patrick J. Blonigan"], "title": "Kernel manifolds: nonlinear-augmentation dimensionality reduction using reproducing kernel Hilbert spaces", "categories": ["cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "This paper generalizes recent advances on quadratic manifold (QM)\ndimensionality reduction by developing kernel methods-based\nnonlinear-augmentation dimensionality reduction. QMs, and more generally\nfeature map-based nonlinear corrections, augment linear dimensionality\nreduction with a nonlinear correction term in the reconstruction map to\novercome approximation accuracy limitations of purely linear approaches. While\nfeature map-based approaches typically learn a least-squares optimal polynomial\ncorrection term, we generalize this approach by learning an optimal nonlinear\ncorrection from a user-defined reproducing kernel Hilbert space. Our approach\nallows one to impose arbitrary nonlinear structure on the correction term,\nincluding polynomial structure, and includes feature map and radial basis\nfunction-based corrections as special cases. Furthermore, our method has\nrelatively low training cost and has monotonically decreasing error as the\nlatent space dimension increases. We compare our approach to proper orthogonal\ndecomposition and several recent QM approaches on data from several example\nproblems.", "AI": {"tldr": "Generalizes quadratic manifold dimensionality reduction using kernel methods to learn optimal nonlinear corrections from reproducing kernel Hilbert spaces, overcoming limitations of linear approaches with better accuracy and flexibility.", "motivation": "To overcome approximation accuracy limitations of purely linear dimensionality reduction approaches by developing a more flexible nonlinear augmentation framework that can impose arbitrary nonlinear structure.", "method": "Develops kernel methods-based nonlinear-augmentation dimensionality reduction that learns optimal nonlinear corrections from user-defined reproducing kernel Hilbert spaces, generalizing feature map-based approaches.", "result": "The approach allows imposing arbitrary nonlinear structure, includes existing methods as special cases, has low training cost, and shows monotonically decreasing error with increasing latent dimension.", "conclusion": "The kernel-based nonlinear augmentation provides a flexible and effective framework for dimensionality reduction that outperforms traditional linear methods and recent quadratic manifold approaches across various test problems."}}
{"id": "2509.02236", "pdf": "https://arxiv.org/pdf/2509.02236", "abs": "https://arxiv.org/abs/2509.02236", "authors": ["Meriem Bahhi", "Jonas Lampart", "Christian Klein", "Simona Rota Nodari"], "title": "A numerical study of stability for solitary waves of a quasi-linear Schr{\u00f6}dinger equation", "categories": ["math.AP"], "comment": null, "summary": "We discuss the (in)stability of solitary waves for a quasi-linear\nSchr{\\\"o}dinger equation. The equation contains a quasi-linear term,\nresponsible for a saturation effect, as well as a power nonlinearity. For\ndifferent exponents of the nonlinearity, we determine analytically the\nasymptotic behavior of the $L^2$-mass of the solution as a function of the\nfrequency close to the critical frequencies, which leads to natural conjectures\nconcerning their stability. Depending on the exponent and the dimension, we\nexpect all solitary waves to be stable, or the emergence of both a stable and\nan unstable branch of solutions. We investigate our conjectures numerically,\nand find compatible results both for the mass-energy relation and the dynamics.\nWe observe that perturbations of solitary waves on the unstable branch may\nconverge dynamically to the stable solution of a similar mass, or disperse.\nMore general initial conditions show a similar behavior.", "AI": {"tldr": "Analysis of stability of solitary waves in quasi-linear Schr\u00f6dinger equations with saturation effects and power nonlinearities, examining mass-energy relations and dynamic behavior across different dimensions and exponents.", "motivation": "To understand the stability properties of solitary waves in quasi-linear Schr\u00f6dinger equations, which combine saturation effects from quasi-linear terms with power nonlinearities, and to determine how stability depends on nonlinearity exponents and spatial dimensions.", "method": "Analytical determination of asymptotic behavior of L\u00b2-mass as function of frequency near critical frequencies, followed by numerical investigation of mass-energy relations and dynamic evolution of perturbations to solitary waves.", "result": "Found that stability depends on exponent and dimension - some cases show all solitary waves stable, others show emergence of both stable and unstable branches. Perturbations of unstable waves may converge to stable solutions with similar mass or disperse.", "conclusion": "The study provides analytical and numerical evidence for stability conjectures in quasi-linear Schr\u00f6dinger equations, demonstrating complex dynamic behavior including convergence to stable solutions and dispersion, with implications depending on nonlinearity exponents and spatial dimensions."}}
{"id": "2509.00265", "pdf": "https://arxiv.org/pdf/2509.00265", "abs": "https://arxiv.org/abs/2509.00265", "authors": ["Andrew McCormack"], "title": "The Nondecreasing Rank", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "math.OC", "15-02"], "comment": "29 pages, 6 figures", "summary": "In this article the notion of the nondecreasing (ND) rank of a matrix or\ntensor is introduced. A tensor has an ND rank of r if it can be represented as\na sum of r outer products of vectors, with each vector satisfying a\nmonotonicity constraint. It is shown that for certain poset orderings finding\nan ND factorization of rank $r$ is equivalent to finding a nonnegative rank-r\nfactorization of a transformed tensor. However, not every tensor that is\nmonotonic has a finite ND rank. Theory is developed describing the properties\nof the ND rank, including typical, maximum, and border ND ranks. Highlighted\nalso are the special settings where a matrix or tensor has an ND rank of one or\ntwo. As a means of finding low ND rank approximations to a data tensor we\nintroduce a variant of the hierarchical alternating least squares algorithm.\nLow ND rank factorizations are found and interpreted for two datasets\nconcerning the weight of pigs and a mental health survey during the COVID-19\npandemic.", "AI": {"tldr": "Introduces nondecreasing (ND) rank for matrices/tensors, which requires vector monotonicity in outer product representations. Develops theory on ND rank properties and presents algorithm for low ND rank approximations with applications to pig weight and COVID mental health data.", "motivation": "To develop a tensor factorization framework that incorporates monotonicity constraints, which is relevant for analyzing ordered data where variables naturally exhibit non-decreasing patterns (e.g., growth measurements, survey responses with ordered categories).", "method": "Introduces ND rank concept, develops theoretical properties (typical, maximum, border ranks), and proposes a variant of hierarchical alternating least squares algorithm for finding low ND rank approximations.", "result": "Shows equivalence between ND factorization and nonnegative factorization for certain poset orderings, demonstrates that not all monotonic tensors have finite ND rank, and provides successful applications to real datasets including pig weight measurements and COVID-19 mental health survey data.", "conclusion": "The ND rank provides a useful constrained factorization approach for ordered data analysis, with theoretical foundations established and practical algorithm developed that successfully captures monotonic patterns in real-world applications."}}
{"id": "2509.02286", "pdf": "https://arxiv.org/pdf/2509.02286", "abs": "https://arxiv.org/abs/2509.02286", "authors": ["Hongjie Dong", "Junhee Ryu"], "title": "On nondivergence form linear parabolic and elliptic equations with degenerate coefficients", "categories": ["math.AP", "35J70, 35K65, 35D30, 35R05"], "comment": "27 pages", "summary": "We establish the unique solvability in weighted mixed-norm Sobolev spaces for\na class of degenerate parabolic and elliptic equations in the upper half space.\nThe operators are in nondivergence form, with the leading coefficients given by\n$x_d^2a_{ij}$, where $a_{ij}$ is bounded, uniformly nondegenerate, and\nmeasurable in $(t,x_d)$ except $a_{dd}$, which is measurable in $t$ or $x_d$.\nIn the remaining spatial variables, they have weighted small mean oscillations.\nIn addition, we investigate the optimality of the function spaces associated\nwith our results.", "AI": {"tldr": "Unique solvability established for degenerate parabolic/elliptic equations in weighted mixed-norm Sobolev spaces, with optimal function space analysis.", "motivation": "To establish well-posedness and optimal regularity results for degenerate PDEs with coefficients having limited regularity, particularly those with x_d^2 degeneracy in the upper half space.", "method": "Analysis of degenerate parabolic and elliptic equations in nondivergence form with coefficients x_d^2a_{ij}, where a_{ij} are bounded, uniformly nondegenerate, and measurable in (t,x_d) except a_dd which is measurable in t or x_d. Uses weighted mixed-norm Sobolev spaces and weighted small mean oscillations conditions.", "result": "Proved unique solvability in weighted mixed-norm Sobolev spaces for the class of degenerate equations. Investigated and established the optimality of the associated function spaces.", "conclusion": "The paper provides complete well-posedness theory and optimal regularity results for degenerate parabolic and elliptic equations with coefficients having specific measurable and oscillation properties in the upper half space."}}
{"id": "2509.00547", "pdf": "https://arxiv.org/pdf/2509.00547", "abs": "https://arxiv.org/abs/2509.00547", "authors": ["Nata\u0161a Kreji\u0107", "Nata\u0161a Krklec Jerinki\u0107", "Tijana Ostoji\u0107", "Nemanja Vu\u010di\u0107evi\u0107"], "title": "AS-BOX: Additional Sampling Method for Weighted Sum Problems with Box Constraints", "categories": ["math.OC", "cs.NA", "math.NA", "90C15, 90C26, 90C30, 65K05"], "comment": "28 pages, 6 figures", "summary": "A class of optimization problems characterized by a weighted finite-sum\nobjective function subject to box constraints is considered. We propose a novel\nstochastic optimization method, named AS-BOX (\\text{A}ddi\\-ti\\-onal\n\\text{S}ampling for \\text{BOX} constraints), that combines projected gradient\ndirections with adaptive variable sample size strategies and nonmonotone line\nsearch. The method dynamically adjusts the batch size based on progress with\nrespect to the additional sampling function and on structural consistency of\nthe projected direction, enabling practical adaptivity of AS-BOX, while\nensuring theoretical support. We establish almost sure convergence under\nstandard assumptions and provide complexity bounds. Numerical experiments\ndemonstrate the efficiency and competitiveness of the proposed method compared\nto state-of-the-art algorithms.", "AI": {"tldr": "AS-BOX is a stochastic optimization method for box-constrained weighted finite-sum problems that combines projected gradients with adaptive batch sizing and nonmonotone line search, ensuring convergence and competitive performance.", "motivation": "To develop an efficient stochastic optimization method for box-constrained problems that can dynamically adjust sample sizes while maintaining theoretical guarantees and practical performance.", "method": "Combines projected gradient directions with adaptive variable sample size strategies and nonmonotone line search. Dynamically adjusts batch size based on progress with the additional sampling function and structural consistency of the projected direction.", "result": "The method establishes almost sure convergence under standard assumptions and provides complexity bounds. Numerical experiments show efficiency and competitiveness compared to state-of-the-art algorithms.", "conclusion": "AS-BOX provides a theoretically sound and practically effective approach for stochastic optimization with box constraints, demonstrating both convergence guarantees and competitive numerical performance."}}
{"id": "2509.02344", "pdf": "https://arxiv.org/pdf/2509.02344", "abs": "https://arxiv.org/abs/2509.02344", "authors": ["Guopeng Li", "Jiawei Li", "Tadahiro Oh", "Nikolay Tzvetkov"], "title": "Probabilistic well-posedness of dispersive PDEs beyond variance blowup I: Benjamin-Bona-Mahony equation", "categories": ["math.AP", "math.PR", "35Q35, 35R60, 60H15, 60H30"], "comment": "45 pages", "summary": "We investigate a possible extension of probabilistic well-posedness theory of\nnonlinear dispersive PDEs with random initial data beyond variance blowup. As a\nmodel equation, we study the Benjamin-Bona-Mahony equation (BBM) with Gaussian\nrandom initial data. By introducing a suitable vanishing multiplicative\nrenormalization constant on the initial data, we show that solutions to BBM\nwith the renormalized Gaussian random initial data beyond variance blowup\nconverge in law to a solution to the stochastic BBM forced by the derivative of\na spatial white noise. By considering alternative renormalization, we show that\nsolutions to the renormalized BBM with the frequency-truncated Gaussian initial\ndata converges in law to a solution to the linear stochastic BBM with the full\nGaussian initial data, forced by the derivative of a spatial white noise. This\nlatter result holds for the Gaussian random initial data of arbitrarily low\nregularity. We also establish analogous results for the stochastic BBM forced\nby a fractional derivative of a space-time white noise.", "AI": {"tldr": "Extends probabilistic well-posedness theory beyond variance blowup for BBM equation with Gaussian random initial data using renormalization techniques.", "motivation": "To develop a framework for handling nonlinear dispersive PDEs with random initial data when traditional variance blowup occurs, enabling analysis beyond this limitation.", "method": "Introduces vanishing multiplicative renormalization constants on initial data and studies convergence in law of solutions to stochastic BBM forced by spatial white noise derivatives. Also considers frequency-truncated Gaussian initial data and fractional derivatives of space-time white noise.", "result": "Shows that renormalized solutions converge to solutions of stochastic BBM forced by spatial white noise derivatives. For frequency-truncated cases, convergence to linear stochastic BBM with full Gaussian initial data is established, even for arbitrarily low regularity data.", "conclusion": "Renormalization techniques successfully extend probabilistic well-posedness theory beyond variance blowup for BBM equation, providing convergence results to stochastic versions forced by white noise derivatives for various initial data regularities."}}
{"id": "2509.00733", "pdf": "https://arxiv.org/pdf/2509.00733", "abs": "https://arxiv.org/abs/2509.00733", "authors": ["Fei Xu"], "title": "Effective approximations for Hartree-Fock exchange potential", "categories": ["physics.chem-ph", "cs.NA", "math.NA"], "comment": null, "summary": "The Hartree-Fock exchange potential is fundamental for capturing quantum\nmechanical exchange effects but faces critical challenges in large-scale\napplications due to its nonlocal and computationally intensive nature. This\nstudy introduces a generalized framework for constructing approximate Fock\nexchange operators in Hartree-Fock theory, addressing the computational\nbottlenecks caused by the nonlocal nature. By employing low-rank decomposition\nand incorporating adjustable variables, the proposed method ensures high\naccuracy for occupied orbitals while maintaining Hermiticity and structural\nconsistency with the exact Fock exchange operator. Meanwhile, a two-level\nnested self-consistent field iteration strategy is developed to decouple the\nexchange operator stabilization (outer loop) and electron density refinement\n(inner loop), significantly reducing computational costs. Numerical experiments\non several molecules demonstrate that the approximate exchange operators\nachieve near-identical energies compared to that of the exact exchange operator\nand the NWChem references, with substantial improvements in computational\nefficiency.", "AI": {"tldr": "A generalized framework for approximate Fock exchange operators in Hartree-Fock theory using low-rank decomposition and adjustable variables, achieving near-exact accuracy with significantly improved computational efficiency.", "motivation": "Address computational bottlenecks of nonlocal Hartree-Fock exchange potential in large-scale applications while maintaining quantum mechanical exchange effects.", "method": "Low-rank decomposition with adjustable variables to ensure accuracy for occupied orbitals, plus two-level nested self-consistent field iteration strategy to decouple exchange operator stabilization and electron density refinement.", "result": "Numerical experiments show near-identical energies compared to exact exchange operator and NWChem references, with substantial computational efficiency improvements.", "conclusion": "The proposed approximate exchange operators provide an effective solution to computational challenges of nonlocal exchange while maintaining high accuracy in Hartree-Fock calculations."}}
{"id": "2509.02443", "pdf": "https://arxiv.org/pdf/2509.02443", "abs": "https://arxiv.org/abs/2509.02443", "authors": ["A. S. Mikhaylov", "V. S. Mikhaylov"], "title": "On the complex moment problem as a dynamic inverse problem for a discrete system", "categories": ["math.AP"], "comment": null, "summary": "We consider the complex moment problem, that is the problem of constructing a\npositive Borel measure on $\\mathbb{C}$ from a given set of moments. We relate\nthis problem to the dynamic inverse problem for the discrete system associated\nwith the complex Jacobi matrix. We show how the characterization of dynamic\ninverse data in solving the inverse problem provides sufficient conditions for\nsolving the complex moment problem.", "AI": {"tldr": "The paper connects the complex moment problem to dynamic inverse problems for discrete systems with complex Jacobi matrices, showing how inverse problem characterizations provide sufficient conditions for solving moment problems.", "motivation": "To establish a relationship between the complex moment problem (constructing measures from moments) and dynamic inverse problems for discrete systems, leveraging insights from one domain to solve problems in the other.", "method": "Relates the complex moment problem to the dynamic inverse problem for discrete systems associated with complex Jacobi matrices, using characterizations of dynamic inverse data.", "result": "Demonstrates that characterization of dynamic inverse data in solving inverse problems provides sufficient conditions for solving the complex moment problem.", "conclusion": "The connection between complex moment problems and dynamic inverse problems offers a new approach and sufficient conditions for constructing positive Borel measures from given moments."}}
{"id": "2509.00888", "pdf": "https://arxiv.org/pdf/2509.00888", "abs": "https://arxiv.org/abs/2509.00888", "authors": ["Frank E. Curtis", "Daniel P. Robinson", "Lara Zebiane"], "title": "Active-Set Identification in Noisy and Stochastic Optimization", "categories": ["math.OC", "cs.NA", "math.NA"], "comment": null, "summary": "Identifying active constraints from a point near an optimal solution is\nimportant both theoretically and practically in constrained continuous\noptimization, as it can help identify optimal Lagrange multipliers and\nessentially reduces an inequality-constrained problem to an\nequality-constrained one. Traditional active-set identification guarantees have\nbeen proved under assumptions of smoothness and constraint qualifications, and\nassume exact function and derivative values. This work extends these results to\nsettings when both objective and constraint function and derivative values have\ndeterministic or stochastic noise. Two strategies are proposed that, under mild\nconditions, are proved to identify the active set of a local minimizer\ncorrectly when a point is close enough to the local minimizer and the noise is\nsufficiently small. Guarantees are also stated for the use of active-set\nidentification strategies within a stochastic algorithm. We demonstrate our\nfindings with two simple illustrative examples and a more realistic constrained\nneural-network training task.", "AI": {"tldr": "Active-set identification for constrained optimization extended to noisy function and derivative evaluations, with theoretical guarantees and practical demonstrations.", "motivation": "Traditional active-set identification methods require exact function and derivative values and assume smoothness and constraint qualifications. This work addresses the practical need to handle noisy evaluations in real-world optimization problems.", "method": "Proposed two strategies for active-set identification that work with deterministic or stochastic noise in both objective and constraint functions and their derivatives. Theoretical analysis under mild conditions shows correct identification when close to local minimizer with small noise.", "result": "The strategies successfully identify active constraints near optimal solutions even with noise. Guarantees are provided for use within stochastic algorithms. Demonstrated effectiveness through simple examples and a constrained neural-network training task.", "conclusion": "The proposed methods extend active-set identification to noisy optimization settings, providing theoretical foundations and practical utility for real-world constrained optimization problems with imperfect function evaluations."}}
{"id": "2509.02536", "pdf": "https://arxiv.org/pdf/2509.02536", "abs": "https://arxiv.org/abs/2509.02536", "authors": ["Yuzhe Zhu"], "title": "Sharp boundary regularity properties for hypoelliptic kinetic equations", "categories": ["math.AP"], "comment": null, "summary": "We establish sharp boundary regularity results for solutions to kinetic\nFokker-Planck equations under prescribed inflow boundary conditions, providing\nprecise quantification of the boundary hypoelliptic regularization effect. For\nequations with rough coefficients, we characterize the behaviours for solutions\non grazing and incoming boundaries. In particular, in the absence of influxes\nand sources, an explicit exponential infinite-order vanishing estimate is\nderived near incoming boundaries. When the coefficients are regular, we\nobtained the optimal H\\\"older regularity on grazing boundaries and general\nSchauder-type estimates away from them.", "AI": {"tldr": "Sharp boundary regularity analysis for kinetic Fokker-Planck equations with inflow boundary conditions, quantifying hypoelliptic regularization effects.", "motivation": "To establish precise boundary regularity results for kinetic Fokker-Planck equations, particularly understanding how solutions behave near boundaries under different coefficient conditions and boundary types.", "method": "Mathematical analysis of kinetic Fokker-Planck equations with prescribed inflow boundary conditions, examining both rough and regular coefficients, and characterizing solution behaviors on grazing and incoming boundaries.", "result": "For rough coefficients: characterized solution behaviors on grazing/incoming boundaries; derived explicit exponential infinite-order vanishing estimate near incoming boundaries without influxes/sources. For regular coefficients: obtained optimal H\u00f6lder regularity on grazing boundaries and general Schauder-type estimates away from boundaries.", "conclusion": "The paper provides comprehensive boundary regularity results for kinetic Fokker-Planck equations, quantifying the hypoelliptic regularization effect and establishing optimal regularity estimates under various coefficient and boundary conditions."}}
{"id": "2509.00904", "pdf": "https://arxiv.org/pdf/2509.00904", "abs": "https://arxiv.org/abs/2509.00904", "authors": ["Christoph Reisinger", "Wolfgang Stockinger", "Maria Olympia Tsianni", "Yufei Zhang"], "title": "Convergence Rates of Time Discretization in Extended Mean Field Control", "categories": ["math.OC", "cs.NA", "math.NA", "49N80, 49N60, 60H35, 65L70"], "comment": "This is an improved version of arXiv:2009.08175, with new results on\n  the first-order convergence rate and numerical experiments", "summary": "Piecewise constant control approximation provides a practical framework for\ndesigning numerical schemes of continuous-time control problems. We analyze the\naccuracy of such approximations for extended mean field control (MFC) problems,\nwhere the dynamics and costs depend on the joint distribution of states and\ncontrols. For linear-convex extended MFC problems, we show that the optimal\ncontrol is $1/2$-H\\\"older continuous in time. Using this regularity, we prove\nthat the optimal cost of the continuous-time problem can be approximated by\npiecewise constant controls with order $1/2$, while the optimal control itself\ncan be approximated with order $1/4$. For general extended MFC problems, we\nfurther show that, under sufficient regularity of the value functions, the\nvalue functions converge with an improved first-order rate, matching the\nbest-known rate for classical control problems without mean field interaction,\nand consistent with the numerical observations for MFC of Cucker-Smale models.", "AI": {"tldr": "Piecewise constant control approximation achieves order 1/2 cost approximation and order 1/4 control approximation for linear-convex extended mean field control problems, with improved first-order convergence under sufficient regularity.", "motivation": "To analyze the accuracy of piecewise constant control approximations for extended mean field control problems where dynamics and costs depend on joint state-control distributions.", "method": "Proving 1/2-H\u00f6lder continuity of optimal controls for linear-convex extended MFC problems, then using this regularity to establish approximation rates for optimal cost and control.", "result": "For linear-convex extended MFC: optimal cost approximated with order 1/2, optimal control with order 1/4. For general extended MFC: value functions converge with first-order rate under sufficient regularity.", "conclusion": "Piecewise constant approximations provide effective numerical schemes for extended MFC problems, with convergence rates matching classical control problems and consistent with numerical observations."}}
{"id": "2509.00188", "pdf": "https://arxiv.org/pdf/2509.00188", "abs": "https://arxiv.org/abs/2509.00188", "authors": ["Ruojing Jiang", "Franco Vargas Pallete"], "title": "On the stability of Ricci flow on hyperbolic 3-manifolds of finite volume", "categories": ["math.DG", "math.AP", "53E20"], "comment": null, "summary": "On a hyperbolic 3-manifold of finite volume, we prove that if the initial\nmetric is sufficiently close to the hyperbolic metric $h_0$, then the\nnormalized Ricci-DeTurck flow exists for all time and converges exponentially\nfast to $h_0$ in a weighted H\\\"older norm. A key ingredient of our approach is\nthe application of interpolation theory.\n  Furthermore, this result is a valuable tool for investigating minimal surface\nentropy, which quantifies the growth rate of the number of closed minimal\nsurfaces in terms of genus. We explore this in [17].", "AI": {"tldr": "Normalized Ricci-DeTurck flow converges exponentially to hyperbolic metric on finite-volume 3-manifolds when initial metric is sufficiently close to hyperbolic metric, using interpolation theory.", "motivation": "To establish stability of hyperbolic metrics under Ricci flow and provide tools for studying minimal surface entropy, which quantifies growth of closed minimal surfaces by genus.", "method": "Applied normalized Ricci-DeTurck flow with interpolation theory to analyze convergence in weighted H\u00f6lder norms on hyperbolic 3-manifolds of finite volume.", "result": "Proved that for initial metrics sufficiently close to hyperbolic metric, the flow exists for all time and converges exponentially fast to the hyperbolic metric.", "conclusion": "The convergence result provides a valuable tool for investigating minimal surface entropy and understanding the stability of hyperbolic metrics under Ricci flow."}}
{"id": "2509.00924", "pdf": "https://arxiv.org/pdf/2509.00924", "abs": "https://arxiv.org/abs/2509.00924", "authors": ["Anastasis Kratsios", "Tin Sum Cheng", "Daniel Roy"], "title": "Beyond Universal Approximation Theorems: Algorithmic Uniform Approximation by Neural Networks Trained with Noisy Data", "categories": ["stat.ML", "cs.LG", "cs.NA", "cs.NE", "math.NA", "math.PR", "68T07, 68Q32, 68T05, 41A65", "F.1.3; G.1.2; F.1.3"], "comment": null, "summary": "At its core, machine learning seeks to train models that reliably generalize\nbeyond noisy observations; however, the theoretical vacuum in which\nstate-of-the-art universal approximation theorems (UATs) operate isolates them\nfrom this goal, as they assume noiseless data and allow network parameters to\nbe chosen freely, independent of algorithmic realism. This paper bridges that\ngap by introducing an architecture-specific randomized training algorithm that\nconstructs a uniform approximator from $N$ noisy training samples on the\n$d$-dimensional cube $[0,1]^d$. Our trained neural networks attain the\nminimax-optimal quantity of \\textit{trainable} (non-random) parameters, subject\nto logarithmic factors which vanish under the idealized noiseless sampling\nassumed in classical UATs.\n  Additionally, our trained models replicate key behaviours of real-world\nneural networks, absent in standard UAT constructions, by: (1) exhibiting\nsub-linear parametric complexity when fine-tuning on structurally related and\nfavourable out-of-distribution tasks, (2) exactly interpolating the training\ndata, and (3) maintaining reasonable Lipschitz regularity (after the initial\nclustering attention layer). These properties bring state-of-the-art UATs\ncloser to practical machine learning, shifting the central open question from\nalgorithmic implementability with noisy samples to whether stochastic gradient\ndescent can achieve comparable guarantees.", "AI": {"tldr": "This paper bridges the gap between theoretical universal approximation theorems and practical machine learning by introducing a randomized training algorithm that constructs neural networks from noisy data, achieving minimax-optimal parameter complexity while exhibiting real-world network behaviors.", "motivation": "Classical universal approximation theorems operate in theoretical vacuums assuming noiseless data and free parameter selection, isolating them from practical machine learning goals of reliable generalization from noisy observations.", "method": "The authors introduce an architecture-specific randomized training algorithm that constructs uniform approximators from N noisy training samples on d-dimensional cubes, achieving minimax-optimal trainable parameters.", "result": "The trained neural networks attain minimax-optimal parameter complexity (subject to logarithmic factors), exhibit sub-linear parametric complexity on related tasks, exactly interpolate training data, and maintain reasonable Lipschitz regularity.", "conclusion": "This work brings state-of-the-art UATs closer to practical machine learning, shifting the open question from algorithmic implementability with noisy samples to whether stochastic gradient descent can achieve comparable guarantees."}}
{"id": "2509.00327", "pdf": "https://arxiv.org/pdf/2509.00327", "abs": "https://arxiv.org/abs/2509.00327", "authors": ["Riju Basak", "K. Jotsaroop"], "title": "On Hardy spaces associated with the twisted Laplacian and sharp estimates for the corresponding wave operator", "categories": ["math.FA", "math.AP", "math.CA"], "comment": "43 pages", "summary": "We prove various equivalent characterisations of the Hardy space\n$H^p_{\\mathcal{L}}(\\mathbb{C}^n)$ for $0<p<1$ associated with the twisted\nLaplacian $\\mathcal{L}$ which generalises the result of [MPR81] for the case\n$p=1$. Using the atomic characterisation of $H^p_{\\mathcal{L}}(\\mathbb{C}^n)$\ncorresponding to the twisted convolution, we prove sharp boundedness result for\nthe wave operator $\\mathcal{L}^{-\\delta/2}e^{\\pm it\\sqrt{\\mathcal{L}}}$ for a\nfixed $t>0$ on $H^p_{\\mathcal{L}}(\\mathbb{C}^n)$. More precisely we prove that\nit is a bounded operator from $H^p_{\\mathcal{L}}(\\mathbb{C}^n)$ to\n$L^p(\\mathbb{C}^n)$ for $ 0<p\\leq 1$ and $\\delta\\geq\n(2n-1)\\left(1/p-1/2\\right)$.", "AI": {"tldr": "Characterization of Hardy spaces H^p_L(C^n) for 0<p<1 associated with twisted Laplacian, extending previous work for p=1. Using atomic decomposition, proves sharp boundedness of wave operator from H^p_L to L^p spaces.", "motivation": "Generalize Hardy space characterizations from p=1 case to 0<p<1 range for twisted Laplacian, and establish sharp boundedness results for wave operators on these Hardy spaces.", "method": "Proves equivalent characterizations of H^p_L(C^n) spaces using atomic decomposition approach based on twisted convolution. Applies this atomic characterization to analyze wave operator boundedness.", "result": "Obtains sharp boundedness condition: wave operator L^{-\u03b4/2}e^{\u00b1it\u221aL} is bounded from H^p_L(C^n) to L^p(C^n) for 0<p\u22641 when \u03b4 \u2265 (2n-1)(1/p-1/2).", "conclusion": "Successfully extends Hardy space theory to 0<p<1 case for twisted Laplacian and establishes optimal boundedness results for wave operators on these function spaces."}}
{"id": "2509.01090", "pdf": "https://arxiv.org/pdf/2509.01090", "abs": "https://arxiv.org/abs/2509.01090", "authors": ["James Tian"], "title": "A Class of Random-Kernel Network Models", "categories": ["cs.LG", "cs.NA", "math.FA", "math.NA", "Primary 68T07. Secondary 41A25, 41A30, 46E22"], "comment": null, "summary": "We introduce random-kernel networks, a multilayer extension of random feature\nmodels where depth is created by deterministic kernel composition and\nrandomness enters only in the outermost layer. We prove that deeper\nconstructions can approximate certain functions with fewer Monte Carlo samples\nthan any shallow counterpart, establishing a depth separation theorem in sample\ncomplexity.", "AI": {"tldr": "Random-kernel networks use deterministic kernel composition for depth with randomness only in the outermost layer, showing deeper networks can approximate functions with fewer samples than shallow ones.", "motivation": "To explore whether deeper neural network architectures can achieve better sample efficiency than shallow networks when using random feature models, specifically examining if depth provides advantages in Monte Carlo sampling requirements.", "method": "Develop multilayer random-kernel networks where depth is created through deterministic kernel composition, with randomness introduced only in the outermost layer. Prove theoretical results comparing sample complexity between deep and shallow architectures.", "result": "Established a depth separation theorem showing that deeper random-kernel network constructions can approximate certain functions with fewer Monte Carlo samples than any shallow counterpart.", "conclusion": "Depth in neural network architectures provides concrete advantages in sample complexity, with deeper random-kernel networks demonstrating superior efficiency over shallow models for function approximation tasks."}}
{"id": "2509.01629", "pdf": "https://arxiv.org/pdf/2509.01629", "abs": "https://arxiv.org/abs/2509.01629", "authors": ["Yifan Chen", "Eric Vanden-Eijnden", "Jiawei Xu"], "title": "Lipschitz-Guided Design of Interpolation Schedules in Generative Models", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We study the design of interpolation schedules in the stochastic interpolants\nframework for flow and diffusion-based generative models. We show that while\nall scalar interpolation schedules achieve identical statistical efficiency\nunder Kullback-Leibler divergence in path space after optimal diffusion\ncoefficient tuning, their numerical efficiency can differ substantially. This\nobservation motivates focusing on numerical properties of the resulting drift\nfields rather than statistical criteria for schedule design. We propose\naveraged squared Lipschitzness minimization as a principled criterion for\nnumerical optimization, providing an alternative to kinetic energy minimization\nused in optimal transport approaches. A transfer formula is derived that\nenables conversion between different schedules at inference time without\nretraining neural networks. For Gaussian distributions, our optimized schedules\nachieve exponential improvements in Lipschitz constants over standard linear\nschedules, while for Gaussian mixtures, they reduce mode collapse in few-step\nsampling. We also validate our approach on high-dimensional invariant\ndistributions from stochastic Allen-Cahn equations and Navier-Stokes equations,\ndemonstrating robust performance improvements across resolutions.", "AI": {"tldr": "Optimizing interpolation schedules in generative models by minimizing averaged squared Lipschitzness rather than kinetic energy, achieving exponential improvements in numerical efficiency and reduced mode collapse without requiring neural network retraining.", "motivation": "While all scalar interpolation schedules achieve identical statistical efficiency after optimal diffusion coefficient tuning, their numerical efficiency differs substantially, motivating focus on numerical properties of drift fields rather than statistical criteria.", "method": "Propose averaged squared Lipschitzness minimization as a principled criterion for numerical optimization, derive transfer formula for schedule conversion at inference time without retraining, and validate on Gaussian distributions, Gaussian mixtures, and high-dimensional invariant distributions.", "result": "Exponential improvements in Lipschitz constants over standard linear schedules for Gaussian distributions, reduced mode collapse in few-step sampling for Gaussian mixtures, and robust performance improvements across resolutions on stochastic Allen-Cahn and Navier-Stokes equations.", "conclusion": "Numerical optimization through Lipschitzness minimization provides superior schedule design for generative models, enabling efficient inference without retraining and demonstrating consistent performance gains across various distribution types and resolutions."}}
{"id": "2509.00809", "pdf": "https://arxiv.org/pdf/2509.00809", "abs": "https://arxiv.org/abs/2509.00809", "authors": ["Baris Ata", "Yaosheng Xu"], "title": "Dynamic control of stochastic matching systems in heavy traffic: An effective computational method for high-dimensional problems", "categories": ["math.OC", "cs.SY", "math.AP"], "comment": null, "summary": "Bipartite matching systems arise in many settings where agents or tasks from\ntwo distinct sets must be paired dynamically under compatibility constraints.\nWe consider a high-dimensional bipartite matching system under uncertainty and\nseek an effective dynamic control policy that maximizes the expected discounted\ntotal value generated by the matches minus the congestion-related costs. To\nderive a tractable approximation, we focus attention on balanced, high-volume\nsystems, i.e., the heavy-traffic regime, and derive an approximating Brownian\ncontrol problem. We then develop a computational method that relies on deep\nneural network technology for solving this problem. To show the effectiveness\nof the policy derived from our computational method, we compare it to the\nbenchmark policies available in the extant literature in the context of the\noriginal matching problem. In the test problems attempted thus far, our\nproposed policy outperforms the benchmarks, and its derivation is\ncomputationally feasible for dimensions up to 100 or more.", "AI": {"tldr": "Proposes a deep neural network-based computational method for solving high-dimensional bipartite matching systems in heavy-traffic regimes, outperforming existing benchmarks.", "motivation": "Bipartite matching systems with uncertainty require effective dynamic control policies to maximize value while minimizing congestion costs, but existing methods struggle with high-dimensional problems.", "method": "Focuses on balanced, high-volume systems in heavy-traffic regime, derives approximating Brownian control problem, and develops computational method using deep neural networks.", "result": "The proposed policy outperforms benchmark policies in test problems and is computationally feasible for dimensions up to 100 or more.", "conclusion": "Deep neural network technology provides an effective and computationally feasible approach for solving high-dimensional bipartite matching control problems in heavy-traffic settings."}}
{"id": "2509.01679", "pdf": "https://arxiv.org/pdf/2509.01679", "abs": "https://arxiv.org/abs/2509.01679", "authors": ["Zhi-Feng Wei", "Wenqian Chen", "Panos Stinis"], "title": "Efficient Transformer-Inspired Variants of Physics-Informed Deep Operator Networks", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": "Code will be released upon acceptance", "summary": "Operator learning has emerged as a promising tool for accelerating the\nsolution of partial differential equations (PDEs). The Deep Operator Networks\n(DeepONets) represent a pioneering framework in this area: the \"vanilla\"\nDeepONet is valued for its simplicity and efficiency, while the modified\nDeepONet achieves higher accuracy at the cost of increased training time. In\nthis work, we propose a series of Transformer-inspired DeepONet variants that\nintroduce bidirectional cross-conditioning between the branch and trunk\nnetworks in DeepONet. Query-point information is injected into the branch\nnetwork and input-function information into the trunk network, enabling dynamic\ndependencies while preserving the simplicity and efficiency of the \"vanilla\"\nDeepONet in a non-intrusive manner. Experiments on four PDE benchmarks --\nadvection, diffusion-reaction, Burgers', and Korteweg-de Vries equations --\nshow that for each case, there exists a variant that matches or surpasses the\naccuracy of the modified DeepONet while offering improved training efficiency.\nMoreover, the best-performing variant for each equation aligns naturally with\nthe equation's underlying characteristics, suggesting that the effectiveness of\ncross-conditioning depends on the characteristics of the equation and its\nunderlying physics. To ensure robustness, we validate the effectiveness of our\nvariants through a range of rigorous statistical analyses, among them the\nWilcoxon Two One-Sided Test, Glass's Delta, and Spearman's rank correlation.", "AI": {"tldr": "Transformer-inspired DeepONet variants with bidirectional cross-conditioning between branch and trunk networks achieve improved accuracy and training efficiency compared to existing DeepONet architectures.", "motivation": "To develop more efficient and accurate operator learning frameworks for PDEs that maintain the simplicity of vanilla DeepONet while achieving the accuracy of modified DeepONet through better information exchange between network components.", "method": "Proposed Transformer-inspired DeepONet variants that introduce bidirectional cross-conditioning - injecting query-point information into branch network and input-function information into trunk network, enabling dynamic dependencies while preserving efficiency.", "result": "Experiments on four PDE benchmarks (advection, diffusion-reaction, Burgers', Korteweg-de Vries equations) show variants match or surpass modified DeepONet accuracy with improved training efficiency. Best variant for each equation aligns with equation characteristics.", "conclusion": "Cross-conditioning effectiveness depends on equation characteristics and underlying physics. The proposed variants provide robust, efficient, and accurate alternatives to existing DeepONet architectures, validated through rigorous statistical analyses."}}
{"id": "2509.01115", "pdf": "https://arxiv.org/pdf/2509.01115", "abs": "https://arxiv.org/abs/2509.01115", "authors": ["Aobo Chen", "Zhenyu Yu"], "title": "Spectral bounds and heat kernel upper estimates for Dirichlet forms", "categories": ["math.PR", "math.AP", "31C25, 30L15, 35K08"], "comment": "23 pages", "summary": "We use a Harnack-type inequality on exit times and spectral bounds to\ncharacterize upper bounds of the heat kernel associated with any regular\nDirichlet form without killing part, where the scale function may vary with\nposition. We further show that this Harnack-type inequality is preserved under\nquasi-symmetric changes of metric on uniformly perfect metric spaces. This\ngeneralised the work of Mariano and Wang [Stochastic Process. Appl. 189 (2025)\n104707)].", "AI": {"tldr": "Characterizes heat kernel bounds using Harnack-type inequalities and spectral methods for Dirichlet forms with variable scale functions, generalizing previous work.", "motivation": "To extend heat kernel analysis to more general Dirichlet forms where scale functions vary with position, building upon existing work by Mariano and Wang.", "method": "Uses Harnack-type inequalities on exit times and spectral bounds to characterize upper bounds of heat kernels for regular Dirichlet forms without killing part.", "result": "Shows that the Harnack-type inequality is preserved under quasi-symmetric changes of metric on uniformly perfect metric spaces.", "conclusion": "Generalizes previous results and provides a framework for analyzing heat kernels in more flexible geometric settings with variable scale functions."}}
{"id": "2509.02230", "pdf": "https://arxiv.org/pdf/2509.02230", "abs": "https://arxiv.org/abs/2509.02230", "authors": ["Victor Kozyakin"], "title": "Notes on Simplifying the Construction of Barabanov Norms", "categories": ["math.RA", "cs.NA", "math.NA", "15A18, 15A60, 65F15"], "comment": "22 pages, 3 figures, 32 bibliography", "summary": "To answer the question about the growth rate of matrix products, the concepts\nof joint and generalized spectral radius were introduced in the 1960s. A common\ntool for finding the joint/generalized spectral radius is the so-called\nextremal norms and, in particular, the Barabanov norm. The goal of this paper\nis to try to combine the advantages of different approaches based on the\nconcept of extremality in order to obtain results that are simpler for everyday\nuse. It is shown how the Dranishnikov-Konyagin theorem on the existence of a\nspecial invariant body for a set of matrices can be used to construct a\nBarabanov norm. A modified max-relaxation algorithm for constructing Barabanov\nnorms, which follows from this theorem, is described. Additional techniques are\nalso described that simplify the construction of Barabanov norms under the\nassumption that", "AI": {"tldr": "This paper presents methods for constructing Barabanov norms to compute joint/generalized spectral radii of matrix sets, combining theoretical foundations with practical algorithms.", "motivation": "To develop simpler, more practical approaches for computing joint and generalized spectral radii using extremal norms, making these mathematical tools more accessible for everyday use.", "method": "Uses the Dranishnikov-Konyagin theorem on invariant bodies to construct Barabanov norms, and describes a modified max-relaxation algorithm along with additional techniques for simplification.", "result": "Provides a theoretical framework and practical algorithm for constructing Barabanov norms, enabling easier computation of spectral radii for matrix sets.", "conclusion": "The paper successfully bridges theoretical mathematics with practical computation, offering improved methods for determining growth rates of matrix products through extremal norm construction."}}
{"id": "2509.01116", "pdf": "https://arxiv.org/pdf/2509.01116", "abs": "https://arxiv.org/abs/2509.01116", "authors": ["Chuanwei Gao", "Shukun Wu", "Yakun Xi"], "title": "Sharp microlocal Kakeya--Nikodym estimates for H\u00f6rmander operators and spectral projectors", "categories": ["math.CA", "math.AP", "math.SP"], "comment": "32 pages", "summary": "We establish sharp microlocal Kakeya--Nikodym estimates for H\\\"ormander\noperators with positive-definite Carleson--Sj\\\"olin phases and for spectral\nprojectors on smooth, compact Riemannian manifolds. As an application, we\nobtain sharp $L^q\\to L^p$ estimates for the aforementioned H\\\"ormander\noperators in odd dimensions, thereby completing the analysis in the\nodd-dimensional case. Further applications include $L^q\\to L^p$ estimates for\nthe Fourier extension operator, $L^p$ estimates for the Bochner--Riesz\noperator, microlocal Kakeya--Nikodym estimates for Laplace eigenfunctions, and\n$L^p$ estimates for Hecke--Maass forms on compact $3$-dimensional arithmetic\nhyperbolic manifolds.", "AI": {"tldr": "Sharp microlocal Kakeya-Nikodym estimates for H\u00f6rmander operators and spectral projectors, with applications to various L^p estimates in odd dimensions.", "motivation": "To establish precise microlocal Kakeya-Nikodym bounds for H\u00f6rmander operators with positive-definite Carleson-Sj\u00f6lin phases and spectral projectors on Riemannian manifolds, completing the analysis in odd-dimensional cases.", "method": "Develop sharp microlocal Kakeya-Nikodym estimates for H\u00f6rmander operators and spectral projectors, then apply these to derive various L^q to L^p estimates.", "result": "Obtained sharp L^q\u2192L^p estimates for H\u00f6rmander operators in odd dimensions, along with estimates for Fourier extension operators, Bochner-Riesz operators, Laplace eigenfunctions, and Hecke-Maass forms.", "conclusion": "The established microlocal Kakeya-Nikodym estimates provide a powerful framework that yields sharp results across multiple areas of harmonic analysis and spectral theory, particularly completing the odd-dimensional case analysis."}}
{"id": "2509.01392", "pdf": "https://arxiv.org/pdf/2509.01392", "abs": "https://arxiv.org/abs/2509.01392", "authors": ["Alessandro Calamai", "Gennaro Infante", "Jorge Rodr\u00edguez-L\u00f3pez"], "title": "Birkhoff-Kellogg type results in product spaces and their application to differential systems", "categories": ["math.FA", "math.AP", "math.CA", "Primary 47H10, secondary 34B08, 35J57, 45G15, 47H11"], "comment": "13", "summary": "We provide a new version of the well-known Birkhoff-Kellogg\ninvariant-direction Theorem in product spaces. Our results concern operator\nsystems and give the existence of component-wise eigenvalues, instead of scalar\neigenvalues as in the classical case, that have corresponding eigenvectors with\nall components nontrivial and localized by their norm. We also show that, when\napplied to nonlinear eigenvalue problems for differential equations, this\nlocalization property of the eigenvectors provides, in turn, qualitative\nproperties of the solutions. This is illustrated in two context of systems of\nPDEs and ODEs. We illustrate the applicability of our theoretical results with\ntwo explicit examples.", "AI": {"tldr": "New Birkhoff-Kellogg theorem extension in product spaces providing component-wise eigenvalues with nontrivial eigenvectors having norm localization, applied to PDE/ODE systems.", "motivation": "Extend classical Birkhoff-Kellogg invariant-direction theorem to handle operator systems in product spaces, seeking component-wise eigenvalues rather than scalar eigenvalues with better localization properties.", "method": "Develop theoretical framework for operator systems in product spaces, proving existence of component-wise eigenvalues with corresponding eigenvectors having all nontrivial components and norm localization properties.", "result": "Successfully established new version of Birkhoff-Kellogg theorem that provides component-wise eigenvalues with localized eigenvectors, applicable to nonlinear eigenvalue problems in differential equations.", "conclusion": "The new theorem offers improved localization properties for eigenvectors and provides qualitative solution properties for systems of PDEs and ODEs, demonstrated through explicit examples."}}
{"id": "2509.01707", "pdf": "https://arxiv.org/pdf/2509.01707", "abs": "https://arxiv.org/abs/2509.01707", "authors": ["Ao Sun", "Zhihan Wang", "Jinxin Xue"], "title": "Regularity of cylindrical singular sets of mean curvature flow", "categories": ["math.DG", "math.AP"], "comment": "61 pages, comments are welcome!", "summary": "In this paper, we study the $k$-cylindrical singular set of mean curvature\nflow in $\\mathbb R^{n+1}$ for each $1\\leq k\\leq n-1$. We prove that they are\nlocally contained in a $k$-dimensional $C^{2,\\alpha}$-submanifold after\nremoving some lower-dimensional parts. Moreover, if the $k$-cylindrical\nsingular set is a $k$-submanifold, then its curvature is determined by the\nasymptotic profile of the flow at these singularities. As a byproduct, we\nprovide a detailed asymptotic profile and graphical radius estimate at these\nsingularities. The proof is based on a new $L^2$-distance non-concentration\nproperty that we introduced in [SWX25], modified into a relative version that\nallows us to modulo those low eigenmodes that are not decaying fast enough and\ndo not contribute to the curvature of the singular set.", "AI": {"tldr": "Analysis of k-cylindrical singular sets in mean curvature flow, showing they are locally contained in k-dimensional C^{2,\u03b1}-submanifolds after removing lower-dimensional parts, with curvature determined by asymptotic flow profiles.", "motivation": "To understand the structure and behavior of k-cylindrical singular sets in mean curvature flow, which are important for characterizing flow singularities and their geometric properties.", "method": "Based on a new L^2-distance non-concentration property introduced in previous work, modified into a relative version to handle low eigenmodes that don't decay fast enough and don't contribute to curvature.", "result": "Proved that k-cylindrical singular sets are locally contained in k-dimensional C^{2,\u03b1}-submanifolds after removing lower-dimensional parts, with curvature determined by asymptotic flow profiles. Also provided detailed asymptotic profile and graphical radius estimates.", "conclusion": "The study provides a comprehensive understanding of k-cylindrical singular sets in mean curvature flow, establishing their submanifold structure and connecting their curvature to the asymptotic behavior of the flow at singularities."}}
{"id": "2509.02050", "pdf": "https://arxiv.org/pdf/2509.02050", "abs": "https://arxiv.org/abs/2509.02050", "authors": ["Ugur G. Abdulla", "Jose H. Rodrigues"], "title": "Cancer Detection via Electrical Impedance Tomography and Optimal Control of Elliptic PDEs", "categories": ["math.OC", "math.AP", "49M41, 49K20, 65M30"], "comment": "26 pages, 22 figures, 7 tables", "summary": "We pursue a computational analysis of the biomedical problem on the\nidentification of the cancerous tumor at an early stage of development based on\nthe Electrical Impedance Tomography (EIT) and optimal control of elliptic\npartial differential equations. Relying on the fact that the electrical\nconductivity of the cancerous tumor is significantly higher than the\nconductivity of the healthy tissue, we consider an inverse EIT problem on the\nidentification of the conductivity map in the complete electrode model based on\nthe $m$ current-to-voltage measurements on the boundary electrodes. A\nvariational formulation as a PDE-constrained optimal control problem is\nintroduced based on the novel idea of increasing the size of the input data by\nadding \"voltage-to-current\" measurements through various permutations of the\nsingle \"current-to-voltage\" measurement. The idea of permutation preserves the\nsize of the unknown parameters on the expense of increase of the number of PDE\nconstraints. We apply a gradient projection (GPM) method based on the Fr\\'echet\ndifferentiability in Besov-Hilbert spaces. Numerical simulations of 2D and 3D\nmodel examples demonstrate the sharp increase of the resolution of the\ncancerous tumor by increasing the number of measurements from $m$ to $m^2$", "AI": {"tldr": "Computational method for early cancer detection using EIT and optimal control, increasing measurement data through permutations to improve tumor identification resolution.", "motivation": "Early detection of cancerous tumors is critical for treatment success. The method leverages the fact that cancerous tissue has significantly higher electrical conductivity than healthy tissue, using Electrical Impedance Tomography (EIT) for non-invasive identification.", "method": "Formulates an inverse EIT problem as a PDE-constrained optimal control problem. Introduces novel permutation approach to increase input data from m to m\u00b2 measurements by adding \"voltage-to-current\" measurements. Uses gradient projection method (GPM) based on Fr\u00e9chet differentiability in Besov-Hilbert spaces.", "result": "Numerical simulations in 2D and 3D models demonstrate a sharp increase in resolution for identifying cancerous tumors when increasing the number of measurements from m to m\u00b2 through the permutation approach.", "conclusion": "The proposed permutation method effectively enhances tumor identification capabilities in EIT by significantly increasing measurement data while maintaining the same number of unknown parameters, providing improved resolution for early cancer detection."}}
{"id": "2509.02239", "pdf": "https://arxiv.org/pdf/2509.02239", "abs": "https://arxiv.org/abs/2509.02239", "authors": ["Elia Mazzucchelli", "Prashanth Raman"], "title": "Canonical Forms as Dual Volumes", "categories": ["hep-th", "math.AG", "math.AP", "math.PR", "math.ST", "stat.TH"], "comment": "37 pages, 14 figures", "summary": "We study dual volume representations of canonical forms for positive\ngeometries in projective spaces, expressing their rational canonical functions\nas Laplace transforms of measures supported on the convex dual of the\nsemialgebraic set. When the measure is non-negative, we term the geometry\ncompletely monotone, reflecting the property of its canonical function. We\nidentify a class of positive geometries whose canonical functions admit such\ndual volume representations, characterized by the algebraic boundary cut out by\na hyperbolic polynomial, for which the geometry is a hyperbolicity region. In\nparticular, simplex-like minimal spectrahedra are completely monotone, with\nrepresenting measures related to the Wishart distribution, capturing volumes of\nspectrahedra or their boundaries. We explicitly compute these measures for\npositive geometries in the projective plane bounded by lines and conics or by a\nnodal cubic, revealing periods evaluating to transcendental functions. This\ndual volume perspective reinterprets positive geometries by replacing\nlogarithmic differential forms with probability measures on the dual, forging\nnew connections to partial differential equations, hyperbolicity, convexity,\npositivity, algebraic statistics, and convex optimization.", "AI": {"tldr": "Dual volume representations of canonical forms for positive geometries using Laplace transforms of measures on convex dual sets, identifying completely monotone geometries characterized by hyperbolic polynomials.", "motivation": "To establish connections between positive geometries and probability measures through dual volume representations, linking to PDEs, hyperbolicity, convexity, and optimization.", "method": "Expressing rational canonical functions as Laplace transforms of measures on convex duals of semialgebraic sets, focusing on hyperbolic polynomial boundaries and hyperbolicity regions.", "result": "Identified completely monotone geometries including simplex-like minimal spectrahedra with Wishart-related measures, computed explicit measures for projective plane geometries with transcendental period evaluations.", "conclusion": "Dual volume perspective reinterprets positive geometries by replacing logarithmic forms with probability measures, creating new connections across multiple mathematical disciplines."}}
{"id": "2509.02389", "pdf": "https://arxiv.org/pdf/2509.02389", "abs": "https://arxiv.org/abs/2509.02389", "authors": ["Matilde Gianocca"], "title": "Rigidity in the Ginzburg--Landau approximation of harmonic spheres", "categories": ["math.DG", "math.AP", "53C43, 58E20, 35J60, 35Q56"], "comment": null, "summary": "We prove that not every harmonic map from $S^{2}$ to $S^{2}$ can arise as a\nlimit of Ginzburg--Landau critical points. More precisely, we show that the\nonly degree-one harmonic maps that can be approximated in this way are\nrotations.\n  This conclusion follows from a rigidity theorem: we show that for every\n$\\gamma>0$ and $\\varepsilon$ small enough, the only critical points\n$u_\\varepsilon:S^{2}\\to\\mathbb R^{3}$ of the Ginzburg--Landau energy\n$E_\\varepsilon$ with energy below $8\\pi-\\gamma$ are (up to conjugation)\nrotations, that is\n$u_\\varepsilon(x)=\\sqrt{1-2\\varepsilon^{2}}\\;R_\\varepsilon\\,x$.", "AI": {"tldr": "Degree-one harmonic maps from S\u00b2 to S\u00b2 cannot all be approximated by Ginzburg-Landau critical points; only rotations can be approximated.", "motivation": "To understand which harmonic maps from the 2-sphere to itself can be obtained as limits of Ginzburg-Landau critical points, particularly investigating the approximation capabilities of these energy minimizers.", "method": "Prove a rigidity theorem showing that for small \u03b5 and energy below 8\u03c0-\u03b3, the only critical points of the Ginzburg-Landau energy are rotations (up to conjugation), using energy estimates and geometric analysis.", "result": "Only rotations (degree-one harmonic maps that are rotations) can be approximated by Ginzburg-Landau critical points; other harmonic maps cannot arise as such limits.", "conclusion": "There is a fundamental limitation in approximating harmonic maps via Ginzburg-Landau theory - only a specific subclass (rotations) can be captured, revealing structural constraints in this approximation scheme."}}
{"id": "2509.02448", "pdf": "https://arxiv.org/pdf/2509.02448", "abs": "https://arxiv.org/abs/2509.02448", "authors": ["Shimaa Elesaely", "David P. Herzog", "Kyle L. Liss"], "title": "Quantitative positivity of transition densities for random perturbations of Hamiltonian systems", "categories": ["math.PR", "math.AP", "60J60, 60H10, 35H10, 37A25"], "comment": "61 pages", "summary": "We study a class of diffusion processes arising from random perturbations of\nconservative Hamiltonian systems. Under a set of abstract hypotheses --\nincluding basic structural assumptions on the Hamiltonian, a weak Lyapunov\nstructure, and a quantitative notion of hypoellipticity -- we prove that\ntransition densities satisfy a sharp, uniform pointwise lower bound over\nHamiltonian sublevel sets in the small noise limit $\\epsilon \\to 0$. By\napplying our general theorem, we obtain quantitative minorization estimates for\na variety of models including Langevin dynamics, chains of oscillators coupled\nto heat bathes at different temperatures, and finite-dimensional fluid models\nsuch as stochastically forced Galerkin truncations of the Navier-Stokes\nequations and the Lorenz '96 system. As a corollary, assuming a stronger\nLyapunov structure, our main result yields a sharp exponential rate of\nconvergence to equilibrium for $0 < \\epsilon \\ll 1$ in a weighted total\nvariation norm. A central feature of our approach is that it does not require\nknowledge of the explicit form of the invariant measure, nor even its\nexistence, and hence is broadly applicable to deduce minorization for\nphysically relevant systems where invariant measures are inaccessible.", "AI": {"tldr": "The paper establishes uniform pointwise lower bounds for transition densities of perturbed Hamiltonian systems, providing quantitative minorization estimates without requiring knowledge of invariant measures.", "motivation": "To develop a general framework for analyzing diffusion processes from random perturbations of conservative Hamiltonian systems, particularly for physically relevant systems where invariant measures are inaccessible.", "method": "Under abstract hypotheses including Hamiltonian structural assumptions, weak Lyapunov structure, and quantitative hypoellipticity, the authors prove sharp uniform pointwise lower bounds on transition densities in the small noise limit.", "result": "The general theorem yields quantitative minorization estimates for various models including Langevin dynamics, oscillator chains, and finite-dimensional fluid models like Navier-Stokes truncations and Lorenz '96 system.", "conclusion": "The approach provides sharp exponential convergence rates to equilibrium without requiring explicit knowledge of invariant measures, making it broadly applicable to physically relevant systems."}}
{"id": "2509.02490", "pdf": "https://arxiv.org/pdf/2509.02490", "abs": "https://arxiv.org/abs/2509.02490", "authors": ["Arian L. von Blanckenburg", "Domenico Giulini", "Philip K. Schwartz"], "title": "The trace-free Einstein tensor is not variational for the metric as field variable", "categories": ["gr-qc", "hep-th", "math-ph", "math.AP", "math.MP"], "comment": "3+1 pages (main text + references)", "summary": "It is well-known that the trace-free Einstein tensor of a pseudo-Riemannian\nmetric cannot arise by variation of a local diffeomorphism-invariant action\nfunctional with the (inverse) metric as field variable. We show that this\nstatement remains true even for general local actions, without the assumption\nof diffeomorphism invariance.", "AI": {"tldr": "The trace-free Einstein tensor cannot be derived from any local action functional, even without requiring diffeomorphism invariance.", "motivation": "To investigate whether the trace-free Einstein tensor can be obtained from variational principles of local actions, extending beyond the well-known restriction that applies to diffeomorphism-invariant actions.", "method": "The authors employ mathematical analysis of variational principles and action functionals, examining the conditions under which the trace-free Einstein tensor could arise as Euler-Lagrange equations from local actions.", "result": "The study demonstrates that the trace-free Einstein tensor cannot be obtained from any local action functional, regardless of whether the action is diffeomorphism-invariant or not.", "conclusion": "This result establishes a fundamental limitation: the trace-free Einstein tensor is not variational from any local action, which has implications for gravitational theories and variational formulations of Einstein's equations."}}
