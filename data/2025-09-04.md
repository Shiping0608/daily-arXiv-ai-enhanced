<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 8]
- [math.AP](#math.AP) [Total: 20]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 5]
- [cs.LG](#cs.LG) [Total: 3]
- [quant-ph](#quant-ph) [Total: 4]
- [math.DG](#math.DG) [Total: 1]
- [physics.acc-ph](#physics.acc-ph) [Total: 1]
- [q-fin.ST](#q-fin.ST) [Total: 1]
- [math.CV](#math.CV) [Total: 1]
- [physics.ins-det](#physics.ins-det) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [math-ph](#math-ph) [Total: 2]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [gr-qc](#gr-qc) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Spacetime Wavelet Method for Linear Boundary-Value Problems in Sylvester Matrix Equation Form](https://arxiv.org/abs/2509.02720)
*Cody D. Cochran,Karel Matous*

Main category: math.NA

TL;DR: A high-order spacetime numerical method using wavelet techniques with prescribed error estimates for linear PDEs, solved via Sylvester matrix equations with Global GMRES and recursive wavelet algorithms.


<details>
  <summary>Details</summary>
Motivation: To develop an accurate and efficient numerical method for solving linear initial-boundary value problems with user-controlled error estimates, addressing the need for high-order convergence in both solutions and derivatives.

Method: Wavelet-based spacetime discretization that produces Sylvester matrix equations, solved using Global GMRES method enhanced with a recursive wavelet algorithm for generating improved initial guesses to accelerate convergence.

Result: The method achieves high-order convergence rates for both solution and derivative approximations as predicted by wavelet theory, and demonstrates superior performance compared to traditional Kronecker product formulations.

Conclusion: The wavelet-based recursive algorithm significantly improves solver performance for Sylvester equations, making this approach effective for high-accuracy solutions of linear PDEs with convective and diffusive terms.

Abstract: We present a high-order spacetime numerical method for discretizing and
solving linear initial-boundary value problems using wavelet-based techniques
with user-prescribed error estimates. The spacetime wavelet discretization
yields a system of algebraic equations resulting in a Sylvester matrix
equation. We solve this system with a Global Generalized Minimal Residual
(GMRES) method in conjunction with a wavelet-based recursive algorithm to
improve convergence. We perform rigorous verification studies using linear
partial differential equations (PDEs) with both convective and diffusive terms.
The results of these simulations show the high-order convergence rates for the
solution and derivative approximations predicted by wavelet theory. We
demonstrate the utility of solving the Sylvester equation through comparisons
to the commonly-used Kronecker product formulation. We show that our recursive
wavelet-based algorithm that generates initial guesses for the iterative Global
GMRES method improves the performance of the solver.

</details>


### [2] [Fast and Accurate SVD-Type Updating in Streaming Data](https://arxiv.org/abs/2509.02840)
*Johannes J. Brust,Michael A. Saunders*

Main category: math.NA

TL;DR: Efficient algorithms for updating bidiagonal factorization to handle low-rank changes in streaming matrix data, with reduced memory and computational costs compared to standard SVD methods.


<details>
  <summary>Details</summary>
Motivation: Standard SVD updating is computationally prohibitive for high-throughput streaming data where changes are often low-rank, and existing incremental methods don't scale well for large truncation ranks.

Method: Developed two algorithms: 1) compact Householder-type algorithm that decouples sparse parts from low-rank updates with reduced memory requirements, 2) Givens rotation-based algorithm with quadratic scaling (10 flops per rotation) instead of cubic scaling.

Result: Algorithms are similarly accurate to SVD methods but more efficient - Householder method uses half the memory of standard bidiagonalization, Givens method scales quadratically rather than cubically.

Conclusion: Proposed algorithms effectively handle high-throughput updates in applications like recommendation systems and network tracking, outperforming standard software like LAPACK and incremental SVD.

Abstract: For a datastream, the change over a short interval is often of low rank. For
high throughput information arranged in matrix format, recomputing an optimal
SVD approximation after each step is typically prohibitive. Instead,
incremental and truncated updating strategies are used, which may not scale for
large truncation ranks. Therefore, we propose a set of efficient new algorithms
that update a bidiagonal factorization, and which are similarly accurate as the
SVD methods. In particular, we develop a compact Householder-type algorithm
that decouples a sparse part from a low-rank update and has about half the
memory requirements of standard bidiagonalization methods. A second algorithm
based on Givens rotations has only about 10 flops per rotation and scales
quadratically with the problem size, compared to a typical cubic scaling. The
algorithm is therefore effective for processing high-throughput updates, as we
demonstrate in tracking large subspaces of recommendation systems and networks,
and when compared to well known software such as LAPACK or the incremental SVD.

</details>


### [3] [Generalized Golub-Kahan bidiagonalization for generalized saddle point systems](https://arxiv.org/abs/2509.02936)
*Na-Na Wang,Ji-Cheng Li*

Main category: math.NA

TL;DR: Extension of CRAIG and nsCRAIG algorithms for generalized saddle point systems with nonzero bottom blocks, maintaining equivalence to Schur complement reduction methods with improved computational efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing CRAIG and nsCRAIG algorithms only handle saddle point systems with zero bottom blocks. There's a need to extend these efficient methods to handle more general cases where the bottom block is nonzero.

Method: Extend generalized Golub-Kahan bidiagonalization (GKB) and its nonsymmetric counterpart to handle nonzero bottom blocks. Develop new CRAIG and nsCRAIG algorithms for SPD and NSPD leading blocks respectively, with appropriate stopping criteria based on energy norm estimates.

Result: Proposed algorithms maintain theoretical equivalence to Schur complement reduction methods with inner CG/FOM iterations. Numerical comparisons show advantages over MINRES/GMRES in computational efficiency and memory requirements.

Conclusion: The extended CRAIG and nsCRAIG algorithms provide efficient solvers for generalized saddle point problems with nonzero bottom blocks, offering improved performance compared to existing methods.

Abstract: We consider the iterative solution of generalized saddle point systems. When
the right bottom block is zero, Arioli [SIAM J. Matrix Anal. Appl., 34 (2013),
pp. 571--592] proposed a CRAIG algorithm based on generalized Golub-Kahan
Bidiagonalization (GKB) for the augmented systems with the leading block being
symmetric and positive definite (SPD), and then Dumitrasc et al. [SIAM J.
Matrix Anal. Appl., 46 (2025), pp. 370--392] extended the GKB for the case
where the symmetry condition of the leading block no longer holds and then
proposed nonsymmetric version of the CRAIG (nsCRAIG) algorithm. The CRAIG and
nsCRAIG algorithms are theoretically equivalent to the Schur complement
reduction (SCR) methods where the Conjugate Gradient (CG) method and the Full
Orthogonalization Method (FOM) are applied to the associated Schur-complement
equation, respectively. We extend the GKB and its nonsymmetric counterpart used
separately in CRAIG and nsCRAIG algorithms for the case where the right bottom
block of saddle point system is nonzero. On this basis, we propose CRAIG and
nsCRAIG algorithms for the solution of the generalized saddle point problems
with the leading block being SPD and nonsymmetric positive definite (NSPD),
respectively. They are also theoretically equivalent to the SCR methods with
inner CG and FOM iterations for the associated Schur-complement equation,
respectively. Moreover, we give algorithm steps of the two new solvers and
propose appropriate stopping criteria based on an estimate of the energy norm
for the error and the residual norm. Numerical comparison with MINRES or GMRES
highlights the advantages of our proposed strategies regarding its high
computational efficiency and/or low memory requirements and the associated
implications.

</details>


### [4] [Complex Scaling for the Junction of Semi-infinite Gratings](https://arxiv.org/abs/2509.02951)
*Fruzsina J. Agocs,Tristan Goodwill,Jeremy Hoskins*

Main category: math.NA

TL;DR: Integral equation method for scattering from two joined semi-infinite periodic structures in 2D, with analytical continuation for exponential accuracy and efficient high-order solver.


<details>
  <summary>Details</summary>
Motivation: To solve scattering problems from geometries where two different periodic structures are joined together, which requires handling infinite interfaces and slow-decaying Green's functions.

Method: Developed an integral equation method using kernels from each structure's Green's function, analytically continued into complex plane for truncation with exponential accuracy, and proved Fredholm index zero.

Result: Successfully created a method that handles the infinite interface between periodic structures, achieves exponential accuracy through analytical continuation, and satisfies radiation conditions.

Conclusion: The presented integral equation approach provides an efficient and high-order accurate solution for scattering from joined periodic structures, with rigorous mathematical foundation and practical computational implementation.

Abstract: We present and analyze an integral equation method for the scattering of a
non-periodic source from a geometry consisting of two semi-infinite, periodic
structures glued together in two dimensions. The two structures may involve a
periodic wall, several layers of transmission surfaces with a shared period, or
periodic sets of obstacles. This integral equation is posed on the infinite
interface between the two periodic structures using kernels built out of the
Green's function for each structure. To combat the slow decay of the Green's
function, we also show that our integral equation can be analytically continued
into the complex plane, where it can be truncated with exponential accuracy. A
careful analysis of the domain Green's functions far from the periodic
structure is then used to prove that the analytically continued equation is
Fredholm index zero. Finally, we show that the solution we generate satisfies a
radiation condition and demonstrate an efficient and high order solver for this
problem.

</details>


### [5] [Convergence for adaptive resampling of random Fourier features](https://arxiv.org/abs/2509.03151)
*Xin Huang,Aku Kammonen,Anamika Pandey,Mattias Sandberg,Erik von Schwerin,Anders Szepessy,Raúl Tempone*

Main category: math.NA

TL;DR: Data-adaptive random Fourier feature method with resampling achieves optimal convergence for high-dimensional machine learning problems.


<details>
  <summary>Details</summary>
Motivation: Random Fourier features provide convex optimization benefits but require effective frequency sampling strategies for optimal performance in high-dimensional data.

Method: Proposes a data-adaptive method that resamples Fourier frequencies optimally and uses adaptive random walk steps with conjugate gradient approximations for least squares problems.

Result: Proves asymptotic optimal convergence as nodes and data increase to infinity, with numerical validation showing effectiveness for regression and classification tasks.

Conclusion: The resampling-based adaptive approach provides theoretically sound and practically effective frequency sampling for random Fourier feature methods in high dimensions.

Abstract: The machine learning random Fourier feature method for data in high dimension
is computationally and theoretically attractive since the optimization is based
on a convex standard least squares problem and independent sampling of Fourier
frequencies. The challenge is to sample the Fourier frequencies well. This work
proves convergence of a data adaptive method based on resampling the
frequencies asymptotically optimally, as the number of nodes and amount of data
tend to infinity. Numerical results based on resampling and adaptive random
walk steps together with approximations of the least squares problem by
conjugate gradient iterations confirm the analysis for regression and
classification problems.

</details>


### [6] [Efficient QR-based Column Subset Selection through Randomized Sparse Embeddings](https://arxiv.org/abs/2509.03198)
*Israa Fakih,Laura Grigori*

Main category: math.NA

TL;DR: Efficient column subset selection algorithm combining QR factorization with sparse subspace embeddings for wide matrices.


<details>
  <summary>Details</summary>
Motivation: To develop a more efficient method for column subset selection in wide matrices (more columns than rows) with reduced dependence on column dimension.

Method: SE-QRSC algorithm: selects columns from sketched matrix B = AΩ^T using sparse subspace embedding Ω, maps pivots back to original columns, and produces final subset with strong rank-revealing properties.

Result: Algorithm yields factorization with strong rank-revealing properties revealing matrix spectrum, with reduced dependence on column count compared to traditional methods. For matrices with known leverage scores, bounds become independent of column dimension.

Conclusion: SE-QRSC provides an efficient column subset selection method with improved theoretical bounds, particularly effective for wide matrices and cases where leverage scores are available or approximable.

Abstract: In this paper, we introduce an efficient algorithm for column subset
selection that combines the column-pivoted QR factorization with sparse
subspace embeddings. The proposed method, SE-QRSC, is particularly effective
for wide matrices with significantly more columns than rows. Starting from a
matrix $A$, the algorithm selects $k$ columns from the sketched matrix $B = A
\Omega^T$, where $\Omega$ is a sparse subspace embedding of
$\mathrm{range}(A^T)$. The sparsity structure of $\Omega$ is then exploited to
map the selected pivots back to the corresponding columns of $A$, which are
then used to produce the final subset of selected columns. We prove that this
procedure yields a factorization with strong rank-revealing properties, thus
revealing the spectrum of $A$. The resulting bounds exhibit a reduced
dependence on the number of columns of $A$ compared to those obtained from the
strong rank-revealing QR factorization of $A$. Moreover, when the leverage
scores are known, such as for orthogonal matrices, or can be efficiently
approximated, the bounds become entirely independent of the column dimension.
For general matrices, the algorithm can be extended by first applying an
additional subspace embedding of $range(A)$.

</details>


### [7] [A New Approach to Direct Discretization of Wave Kinetic Equations with Application to a Nonlinear Schrodinger System in 2D](https://arxiv.org/abs/2509.03432)
*J. W. Banks,J. Shatah*

Main category: math.NA

TL;DR: A new numerical method for simulating Wave Kinetic Equations using piecewise polynomial approximation of resonant manifolds and numerical quadrature, achieving 2nd-order accuracy and validated against nonlinear Schrodinger model ensemble averages.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient and accurate direct numerical simulation approach for Wave Kinetic Equations, which are commonly used to describe ensemble averaged wave amplitudes in nonlinear wave systems.

Method: Piecewise polynomial approximation of the resonant manifold followed by numerical quadrature of the collision integral, specifically applied to a 2D nonlinear Schrodinger model.

Result: The method demonstrates 2nd-order accuracy for model collision integrals and near 2nd-order convergence rates for WKE simulations. Comparisons show good agreement between WKE approximations and ensemble averages of NLS for both isotropic and anisotropic solutions.

Conclusion: The proposed approach provides an effective and general method for direct numerical simulation of Wave Kinetic Equations, validating both the numerical technique and the underlying WKE framework.

Abstract: Wave Kinetic Equations (WKEs) are often used to describe the evolution of
ensemble averaged wave amplitudes for nonlinear wave systems. In the present
manuscript we describe a new approach to direct numerical simulation of
solutions to WKEs. This new method relies on a piecewise polynomial
approximation of the resonant manifold, followed by numerical quadrature of the
collision integral. The approach is general in nature, and is discussed in
detail here for a particular nonlinear Schrodinger model in 2 spatial
dimensions. Detailed convergence studies demonstrate 2nd-order accuracy for
model collision integrals, and self-convergence studies for the WKE show near
2nd-order rates. Furthermore, comparison of the WKE approximation to ensemble
averages of the NLS illustrate the efficacy of the method and the validity of
the WKE, for both isotropic and an-isotropic solutions.

</details>


### [8] [Linear Relaxation Schemes with Asymptotically Compatible Energy Law for Time-Fractional Phase-Field Models](https://arxiv.org/abs/2509.03471)
*Hui Yu,Zhaoyang Wang,Ping Lin*

Main category: math.NA

TL;DR: A variable time-step linear relaxation scheme for time-fractional phase-field equations using L1+-CN discretization and auxiliary variables for nonlinear terms, achieving second-order accuracy and energy stability.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient numerical scheme for time-fractional phase-field equations that avoids solving differential-algebraic equations like IEQ/SAV approaches and maintains consistency between auxiliary and original variables.

Method: Uses L1+-CN formula for fractional derivative discretization, introduces auxiliary variable to approximate nonlinear terms by solving algebraic equations directly, and applies variable time-stepping.

Result: The scheme achieves second-order accuracy, energy stability, and asymptotic compatibility with classical energy dissipation when fractional order approaches 1. Numerical tests confirm auxiliary variable remains well-aligned with original variable.

Conclusion: The proposed method provides an effective approach for solving time-fractional phase-field equations with improved consistency and stability properties compared to existing IEQ/SAV methods.

Abstract: In this paper, we propose a variable time-step linear relaxation scheme for
time-fractional phase-field equations with a free energy density in general
polynomial form. The $L1^{+}$-CN formula is used to discretize the fractional
derivative, and an auxiliary variable is introduced to approximate the
nonlinear term by directly solving algebraic equations rather than
differential-algebraic equations as in the invariant energy quadratization
(IEQ) and the scalar auxiliary variable (SAV) approaches. The developed
semi-discrete scheme is second-order accurate in time, and the inconsistency
between the auxiliary and the original variables does not deteriorate over
time. Furthermore, we take the time-fractional volume-conserved Allen-Cahn
equation, the time-fractional Cahn-Hilliard equation, and the time-fractional
Swift-Hohenberg equation as examples to demonstrate that the constructed
schemes are energy stable and that the discrete energy dissipation law is
asymptotically compatible with the classical one when the fractional-order
parameter $\alpha\rightarrow 1^{-}$. Several numerical examples demonstrate the
effectiveness of the proposed scheme. In particular, numerical results confirm
that the auxiliary variable remains well aligned with the original variable,
and the error between them does not continue to increase over time before the
system reaches steady state.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [9] [From Age-Structured Trophic Networks to Applied Control : Stabilization and Harvesting Strategies for Non-Transitive Competition and the Dynamics of Mosquitoes](https://arxiv.org/abs/2509.02704)
*Marius Bargo,Yacouba Simpore*

Main category: math.AP

TL;DR: A nonlinear age-structured multi-species model for ecological and biotechnological systems with nonlocal interactions, featuring theoretical guarantees and practical applications in multi-species competition and malaria vector control.


<details>
  <summary>Details</summary>
Motivation: To create a unifying framework for modeling complex ecological and biotechnological systems (microbial communities, bioreactors) that incorporates environmental covariates and nonlocal interactions between species.

Method: Developed a nonlinear age-structured multi-species model with nonlocal intra- and interspecific interactions. Established existence, uniqueness and positivity of solutions under general assumptions. Applied to multi-species competition models and malaria-vector mosquito dynamics with biological and genetic control strategies.

Result: Proved that a single control applied to one species can achieve global stabilization in non-transitive competition systems. Demonstrated global asymptotic stability in biological control scenarios using explicit Lyapunov functions. Numerical simulations validated theoretical results and showed effectiveness in reducing vector density and malaria transmission.

Conclusion: The proposed model provides a robust theoretical foundation for complex ecological systems and offers practical control strategies with proven stability properties, making it valuable for both ecological research and biotechnological applications.

Abstract: We propose and analyze a nonlinear age-structured multi-species model that
serves as a unifying framework for ecological and biotechnological systems in
complex environments (microbial communities, bioreactors, etc.). The
formulation incorporates nonlocal intra- and interspecific interactions
modulated by environmental covariates; under general assumptions on mortality,
reproduction rates and interaction kernels, we establish existence, uniqueness
and positivity of solutions. We illustrate the model's practical relevance
along two lines: (i) multi-species examples, notably a non-transitive (cyclic)
competition model, for which we show that, under the model assumptions, a
control applied to a single species can achieve global stabilization of the
system; furthermore, verification of the Kalman condition in this context
provides an essential theoretical prerequisite and highlights that this single
control acts indirectly on all other species; and (ii) the population dynamics
of malaria-vector mosquitoes, for which we develop two control strategies
(biological and genetic) and, in the biological-control scenario, prove global
asymptotic stability of the aquatic compartment by constructing an explicit
Lyapunov function. Numerical simulations validate the theoretical results and
compare the effectiveness of the proposed strategies in reducing vector density
and malaria transmission.

</details>


### [10] [Superdiffusive fractional dynamics: Unveiling regularity results in systems with general positive self-adjoint operators](https://arxiv.org/abs/2509.02733)
*Edgardo Alvarez,Ciprian G. Gal,Valentin Keyantuo,Mahamadi Warma*

Main category: math.AP

TL;DR: Analysis of fractional order Cauchy problems with Caputo derivatives for memory effect modeling, focusing on existence and regularity of solutions without compact resolvent assumptions.


<details>
  <summary>Details</summary>
Motivation: Study fractional differential equations with memory effects that are increasingly used in applied sciences, extending previous results to more general operator classes.

Method: Analyze weak and strong energy solutions using positive self-adjoint operators in Hilbert spaces with nonlinearities satisfying growth conditions, without requiring compact resolvent.

Result: Obtained existence and regularity results for fractional order problems with Caputo derivatives, applicable to various differential and nonlocal operators including Schrödinger operators.

Conclusion: Successfully extended regularity theory to broader class of operators, providing framework for analyzing fractional differential equations in applied sciences with memory effects.

Abstract: We investigate the following fractional order in time Cauchy problem
\begin{equation*} \begin{cases} \mathbb{D}_{t}^{\alpha }u(t)+Au(t)=f(u(t)), &
1<\alpha <2, \\ u(0)=u_{0},\,\,\,u^{\prime }(0)=u_{1}. & \end{cases}%
\end{equation*}% where $\mathbb{D}_{t}^{\alpha }u(\cdot )$ is the Caputo
time-fractional derivative of order $\alpha\in (1, 2)$ of the function $u$.
Such problems are increasingly used in concrete models in applied sciences,
notably phenomena with memory effects. We obtain results on existence and
regularity of weak and strong energy solutions assuming that $A$ is any
positive self-adjoint operator in a Hilbert space, when the nonlinearity $f\in
C^{1}({\mathbb{R}}) $ satisfies suitable growth conditions. Our aim is to
obtain regularity results {without} assuming that the operator $A$ has compact
resolvent readily extending our recent results from our previous paper
\cite{AGKW}. Examples of operators $A$ are considered, mainly differential
operators such as Schr\"odinger operators, as well as various nonlocal
operators.

</details>


### [11] [Modeling of radiating curved cables via coupled telegrapher's and Maxwell's equations](https://arxiv.org/abs/2509.02736)
*Markus Clemens,Michael Günther,Timo Reis,Nathanael Skrepek*

Main category: math.AP

TL;DR: Novel time-domain model for electromagnetic interactions in curved cable harnesses that couples transmission line equations with Maxwell's equations while maintaining energetic consistency.


<details>
  <summary>Details</summary>
Motivation: Standard transmission line modeling typically assumes straight cables and doesn't fully account for electromagnetic radiation effects in curved cable configurations, which is important for realistic cable harness analysis.

Method: Developed a coupled system using telegrapher's equations for cable description with appropriate boundary conditions, and Maxwell's equations for electromagnetic radiation, ensuring energetic consistency through proper boundary condition coupling.

Result: The model successfully extends transmission line modeling to curved cables and incorporates electromagnetic interactions while maintaining a global power balance, demonstrating energetic consistency in the coupled system.

Conclusion: The presented approach provides a physically consistent framework for analyzing electromagnetic interactions in complex cable harness configurations with curved geometries, bridging transmission line theory with full-wave electromagnetic modeling.

Abstract: We investigate the electromagnetic interactions of cable harnesses in the
time domain. We present a novel model that allows for curved cables, extending
the standard assumptions typically made in transmission line modeling. The
cables are described by the telegrapher's equations, the classical model for
transmission lines, driven by input signals implemented through appropriate
boundary conditions, such as imposed voltages at cable ends. The cables
interact via electromagnetic radiation; the latter is determined by Maxwell's
equations. This interaction is incorporated into the model through boundary
conditions imposed on the electromagnetic field. The resulting coupling between
the transmission lines and Maxwell's equations is energetically consistent. In
particular, we show that the coupled system satisfies a global power balance.

</details>


### [12] [On stable solutions to the Allen-Cahn equation with bounded energy density in $\mathbb{R}^4$](https://arxiv.org/abs/2509.02739)
*Enric Florit-Simon,Joaquim Serra*

Main category: math.AP

TL;DR: Stable solutions to Allen-Cahn equation in R^4 with bounded energy density are one-dimensional, leading to geometric consequences including curvature estimates and proofs of multiplicity one and Morse index conjectures.


<details>
  <summary>Details</summary>
Motivation: To establish that stable solutions with bounded energy density in 4-dimensional space are one-dimensional, which has significant implications for understanding phase transitions and minimal hypersurfaces.

Method: Analysis of stable solutions to the Allen-Cahn equation in R^4 with bounded energy density (cubic energy growth), using mathematical techniques to prove one-dimensionality.

Result: Proved that stable solutions with bounded energy density are one-dimensional in R^4, which provides robust curvature estimates for stable phase transitions.

Conclusion: This result confirms the multiplicity one and Morse index conjectures by Marques-Neves for Allen-Cahn approximations of minimal hypersurfaces in closed 4-manifolds, establishing important geometric properties.

Abstract: We show that stable solutions $u:\mathbb{R}^4\to (-1,1)$ to the Allen-Cahn
equation with bounded energy density (or equivalently, with cubic energy
growth) are one-dimensional.
  This is known to entail important geometric consequences, such as robust
curvature estimates for stable phase transitions, and the multiplicity one and
Morse index conjectures of Marques-Neves for Allen-Cahn approximations of
minimal hypersurfaces in closed 4-manifolds.

</details>


### [13] [Nonunique tangent maps at isolated singularities of minimizing $p$-harmonic maps](https://arxiv.org/abs/2509.02740)
*Jonas Hirsch*

Main category: math.AP

TL;DR: First example of a minimizing p-harmonic map with nonunique tangent maps at an isolated singularity


<details>
  <summary>Details</summary>
Motivation: Understanding the fine structure of singular sets in energy minimizing maps requires analysis of tangent maps at singular points

Method: Construct an n-dimensional manifold N such that for every admissible tuple p < m ≤ n+2, there exists a map from B₁^m into N that minimizes p-energy, has isolated singularity at origin, and admits continuum of distinct tangent maps

Result: Successfully built the first example of a minimizing (not just stationary) p-harmonic map with nonunique tangent maps at an isolated singularity

Conclusion: The construction extends B. White's example for p=2 in the stationary case and demonstrates that minimizing p-harmonic maps can exhibit nonunique tangent behavior at singularities

Abstract: The analysis of ``tangent maps'' at singular points of energy minimizing maps
plays an important role in our understanding of the fine structure of the
singular set. This note presents the first example of a minimizing (not just
stationary) $p$-harmonic map with nonunique tangent maps at an isolated
singularity. We construct a $n$-dimensional manifold $N$ such that for every
admissible tuple $p< m\le n+2$, there exists a map from $B_1^m$ into $N$ that
minimizes the $p$-energy, has an isolated singularity at the origin and admits
a continuum of distinct tangent maps. The construction builds upon and extends
B.~ White's example for $p=2$ in the stationary case.

</details>


### [14] [Overdetermined fractional Serrin problem](https://arxiv.org/abs/2509.02742)
*Nicola Garofalo,Dimiter Vassilev*

Main category: math.AP

TL;DR: Solves Serrin overdetermined problem for Weinstein operator with Bessel operator


<details>
  <summary>Details</summary>
Motivation: Extend Serrin overdetermined problem analysis to Weinstein operator involving Bessel operators

Method: Mathematical analysis of the Weinstein operator with Bessel operator components, applying techniques from overdetermined boundary value problems

Result: Successfully solved the Serrin overdetermined problem for this specific operator configuration

Conclusion: The solution extends classical Serrin problem results to Weinstein operators with Bessel components, contributing to the theory of overdetermined boundary value problems

Abstract: We solve a version of the Serrin overdetermined problem for the Weinstein
operator involving a Bessel operator.

</details>


### [15] [Sampling methods for the inverse cavity scattering problem of biharmonic waves](https://arxiv.org/abs/2509.02773)
*Isaac Harris,Peijun Li,General Ozochiawaeze*

Main category: math.AP

TL;DR: Strengthened analysis of linear sampling method for recovering clamped cavities in thin elastic plates using far-field measurements, with implementation and numerical validation.


<details>
  <summary>Details</summary>
Motivation: To address the inverse problem of qualitatively recovering clamped cavities in thin elastic plates using far-field measurements, improving upon existing linear sampling methods.

Method: Strengthened analysis of linear sampling method by examining far-field operator range and using reciprocity relation of biharmonic far-field pattern. Implemented both linear sampling method for cavity reconstruction and extended sampling method for cavity localization under limited-aperture data.

Result: Numerical experiments demonstrate the effectiveness and robustness of both methods for cavity recovery and localization.

Conclusion: The proposed strengthened analysis and implementation of linear and extended sampling methods provide effective and robust approaches for solving the inverse cavity recovery problem in thin elastic plates using far-field measurements.

Abstract: This paper addresses the inverse problem of qualitatively recovering a
clamped cavity in a thin elastic plate using far-field measurements. We present
a strengthened analysis of the linear sampling method by carefully examining
the range of the far-field operator and employing the reciprocity relation of
the biharmonic far-field pattern. In addition, we implement both the linear
sampling method for reconstructing the cavity and the extended sampling method
for localizing the cavity under limited-aperture data. Numerical experiments
demonstrate the effectiveness and robustness of both methods.

</details>


### [16] [A novel approach to study the wellposedness of the 3D fluid-2D plate interaction PDE System](https://arxiv.org/abs/2509.03431)
*George Avalos,Pelin G. Geredeli,Hemanta Kunwar,Hyesuk Lee*

Main category: math.AP

TL;DR: Novel inf-sup approach for fluid-structure interaction semigroup wellposedness, enabling more efficient finite element methods by avoiding computationally intensive nonlocal operators.


<details>
  <summary>Details</summary>
Motivation: To establish an alternative methodology for proving strongly continuous semigroup wellposedness of a fluid-structure interaction system describing vibrations of incompressible fluid interacting with elastic membrane, which appears in biomedicine, aeroelasticity, and fluid dynamics.

Method: Application of Lumer Phillips Theorem with a nonstandard inf-sup approach that avoids technical nonlocal maps in bilinear forms, allowing simultaneous solution of fluid and plate variables, leading to a more efficient mixed finite element method.

Result: Successful proof of C0-semigroup wellposedness and development of a novel variational formulation that avoids computationally-intensive nonlocal solution operators, with numerical tests demonstrating effectiveness.

Conclusion: The new inf-sup strategy provides a more efficient computational framework for FSI problems compared to previous approaches, enabling better numerical approximation while maintaining mathematical rigor.

Abstract: We consider a certain fluid-structure interaction (FSI) system with a view of
obtaining an alternative methodology for establishing its strongly continuous
semigroup wellposedness. (Semigroup generation for this FSI was originally
considered in Avalos-Clark (2014).) The FSI model under consideration describes
the vibrations of an incompressible fluid within a 3D cavity as it interacts
with the elastic membrane on the ``free" upper boundary of the cavity. Such
coupled PDE systems appear in variety of natural settings such as biomedicine,
aeroelasticity, and fluid dynamics.
  Our proof of $C_0$-semigroup wellposedness is based on a proper application
of Lumer Phillips Theorem. In this regard, our main challenge is to show the
maximality of the corresponding semigroup generator. To this end, we develop a
``nonstandard" inf-sup approach which avoids the use of technical nonlocal maps
in the associated bilinear forms--unlike the earlier paper Avalos-Clark
(2014)--and allows for the solution of the fluid and plate solution variables
simultanously. Our new inf-sup strategy will lead to a more efficient mixed
finite element method (FEM) for approximating solutions to the FSI problem,
inasmuch our novel variational formulation avoids bilinear forms which are free
from the computationally-intensive nonlocal solution operators invoked in
Avalos-Clark (2014). We also perform numerical tests based on this formulation
using a benchmark problem
  and present numerical results to demonstrate the effectiveness of our
approach.

</details>


### [17] [Long time asymptotics for the KPII equation](https://arxiv.org/abs/2509.02907)
*Derchyi Wu*

Main category: math.AP

TL;DR: Long-time asymptotics of small KPII solutions derived using inverse scattering theory and stationary phase method


<details>
  <summary>Details</summary>
Motivation: To understand the long-time behavior of small solutions to the Kadomtsev-Petviashvili II equation, which is important for studying nonlinear wave phenomena in two dimensions

Method: Used inverse scattering theory combined with the stationary phase method to analyze the asymptotic behavior

Result: Successfully derived the long-time asymptotics for small KPII solutions

Conclusion: The combination of inverse scattering theory and stationary phase method provides an effective approach for studying long-time behavior of KPII solutions

Abstract: The long-time asymptotics of small Kadomtsev-Petviashvili II (KPII) solutions
is derived using the inverse scattering theory and the stationary phase method.

</details>


### [18] [On the geometry of measures with density bounds in a Hölder anisotropic setting](https://arxiv.org/abs/2509.02954)
*Ignacio Tejeda*

Main category: math.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study the regularity of the support of a Radon measure $\mu$ on $\mathbb
R^{n+1}$ for which anisotropic versions of its $n$-dimensional density ratio
and its doubling character are assumed to converge with H\"older rate. We show
that in either case, if the support of $\mu$ is flat enough, then it is a
$C^{1,\gamma}$ $n$-dimensional submanifold of $\mathbb R^{n+1}$, for some
$\gamma\in (0,1)$. If the flatness assumption is dropped, then the support of
$\mu$ is the union of a $C^{1,\gamma}$ $n$-dimensional submanifold of $\mathbb
R^{n+1}$ and a set of $n$-Hausdorff measure zero.

</details>


### [19] [$L^2$-contraction and asymptotic stability of large shock for scalar viscous conservation laws](https://arxiv.org/abs/2509.02965)
*Alexis F. Vasseur,Yi Wang,Jian Zhang*

Main category: math.AP

TL;DR: Analysis of L^2-contraction and stability of large shocks in scalar viscous conservation laws with polynomial flux, particularly for convex flux f(u)=u^p (2≤p≤4), using a-contraction method with time-dependent shift and weight functions.


<details>
  <summary>Details</summary>
Motivation: To establish mathematical foundations for understanding the stability and contraction properties of large shock profiles in scalar viscous conservation laws with polynomial flux functions, which has implications for fluid dynamics and other physical systems.

Method: Using a-contraction method with time-dependent shift and suitable weight function in H^1-framework to prove L^2-contraction and time-asymptotic stability of arbitrarily large viscous shock profiles.

Result: Successfully proved L^2-contraction and time-asymptotic stability for strictly convex flux f(u)=u^p with 2≤p≤4. Additionally obtained L^2 time-asymptotic decay rate t^{-1/4} when initial perturbation belongs to L^1.

Conclusion: The a-contraction method with time-dependent shift and appropriate weight functions provides an effective framework for analyzing stability and contraction properties of large shock profiles in scalar viscous conservation laws with polynomial flux, with specific decay rates established under certain initial conditions.

Abstract: We investigate $L^2$-contraction and time-asymptotic stability of large shock
for scalar viscous conservation laws with polynomial flux. For the strictly
convex flux $f(u)=u^p $ with $2\leq p \leq 4$, we can prove $L^2$-contraction
and time-asymptotic stability of arbitrarily large viscous shock profile in
$H^1$-framework by using $a$-contraction method with time-dependent shift and
suitable weight function. Additionally, if the initial perturbation belongs to
$L^1$, then $L^2$ time-asymptotic decay rate $t^{-\frac{1}{4}}$ can be
obtained.

</details>


### [20] [A note on Wang's conjecture for harmonic functions with nonlinear boundary condition](https://arxiv.org/abs/2509.02978)
*Xiaohan Cai*

Main category: math.AP

TL;DR: Liouville theorems for positive harmonic functions on compact Riemannian manifolds with nonnegative Ricci curvature and convex boundary, verifying Wang's conjecture. New proof for specific manifold using P-function method, with extensions to nonlinear equations.


<details>
  <summary>Details</summary>
Motivation: To prove Wang's conjecture about uniqueness of positive harmonic functions on certain Riemannian manifolds and develop a general method for such uniqueness results.

Method: P-function method applied to harmonic functions on compact Riemannian manifolds with nonnegative Ricci curvature and strictly convex boundary, with extension to nonlinear source and boundary conditions.

Result: Liouville type theorems obtained, partially verifying Wang's conjecture. New proof provided for specific manifold case, and method extended to nonlinear equations.

Conclusion: The P-function method provides an effective approach for proving uniqueness results for harmonic functions and can be extended to handle nonlinear equations with boundary conditions.

Abstract: We obtain some Liouville type theorems for positive harmonic functions on
compact Riemannian manifolds with nonnegative Ricci curvature and strictly
convex boundary and partially verifies Wang's conjecture (J. Geom. Anal. 31
(2021)).
  For the specific manifold $\mathbb{B}^n$, we present a new proof of this
conjecture, which has been resolved by Gu-Li (Math. Ann. 391 (2025)). Our proof
is based on a general principle of applying the P-function method to such
uniqueness results. As a further application of this method, we obtain some
Liouville type results for nonnegative solutions of equations with both a
nonlinear source term and a nonlinear boundary condition.

</details>


### [21] [Boundary layer effects induced by the fluid in a chemotaxis-Navier-Stokes system](https://arxiv.org/abs/2509.03028)
*Qianqian Hou*

Main category: math.AP

TL;DR: Study shows fluid dynamics in chemotaxis-Navier-Stokes system creates boundary layer effects in bacterial oxygen gradients under Neumann boundary conditions, which disappear when fluid influence is removed.


<details>
  <summary>Details</summary>
Motivation: To understand boundary layer formation in aerobic bacteria-fluid systems and investigate how fluid dynamics influences chemotaxis boundary layer effects under Neumann oxygen boundary conditions.

Method: Analyzed chemotaxis-Navier-Stokes system with Neumann boundary conditions on oxygen in half-plane of R², compared with chemotaxis-only subsystem without fluid influence.

Result: Gradients of second solution component exhibit boundary layer effects as oxygen diffusion rate approaches zero, but these effects vanish when fluid influence is neglected in chemotaxis-only subsystem.

Conclusion: Boundary layer effects in chemotaxis-Navier-Stokes systems under Neumann oxygen boundary conditions are induced by the presence of fluids, not inherent to chemotaxis alone.

Abstract: This paper is concerned with the boundary layer problem on a
chemotaxis-Navier-Stokes system modelling the boundary layer formation of
aerobic bacteria in fluids. Completing this system with Neumann boundary
conditions on oxygen, we show that gradients of its second solution component
in the half plane of $\mathbb{R}^2$ possess boundary layer effects as the
oxygen diffusion rate goes to zero. However, neglecting the influence of the
fluid, gradients of solutions to the chemotaxis-only subsystem no longer
present such boundary layer effects. It seems that the boundary layer effect
for the chemotaxis-Navier-Stokes system under Neumann boundary conditions on
oxygen is induced by the presence of fluids.45

</details>


### [22] [Fisher information for solutions of the Boltzmann equation](https://arxiv.org/abs/2509.03045)
*Cyril Imbert*

Main category: math.AP

TL;DR: Fisher information decreases over time for the space-homogeneous Boltzmann equation, enabling global well-posedness for singular interactions.


<details>
  <summary>Details</summary>
Motivation: To establish that Fisher information, a classical functional from information theory, is nonincreasing along solutions of the space-homogeneous Boltzmann equation for all physically relevant particle interactions.

Method: Proving a new functional inequality on the sphere of Log-Sobolev type to establish the monotonicity of Fisher information along the flow of the non-linear PDE.

Result: The Fisher information is shown to be nonincreasing, which provides a new a priori estimate on solutions that yields global-in-time well-posedness of the equation.

Conclusion: This work resolves the previously open question of global well-posedness for the Boltzmann equation with very singular interactions through the establishment of Fisher information monotonicity.

Abstract: This note reviews a recent contribution about the Fisher information for the
space-homogeneous Boltzmann equation by L. Silvestre, C. Villani and the author
(arXiv, 2024). This classical functional from information theory is shown to be
nonincreasing along the flow of the non-linear PDE for all physically relevant
particle interactions. The proof consists in establishing a new functional
inequality on the sphere of Log-Sobolev type. This new a priori estimate on
solutions yields global-in-time well posedness of the equation, in particular
in the case of very singular interactions, a left open question up to this
work. L'information de Fisher des solutions de l'{\'e}quation de Boltzmann
R{\'e}sum{\'e}.

</details>


### [23] [Range characterization of the ray transform on Sobolev spaces of symmetric tensor fields in two dimensions](https://arxiv.org/abs/2509.03046)
*Divyansh Agrawal,Venkateswaran P. Krishnan,Vladimir A. Sharafutdinov*

Main category: math.AP

TL;DR: Range characterization of ray transform for symmetric tensor fields in 2D weighted Sobolev spaces using Reshetnyak formula


<details>
  <summary>Details</summary>
Motivation: Previous work characterized the range of ray transform operator I_m for n≥3, but the 2D case requires different approach and allows characterization in higher order weighted Sobolev spaces

Method: Utilize Reshetnyak formula which provides norm equivalence between the ray transform and original tensor field for solenoidal fields, enabling range characterization in H^{r,s}_t spaces

Result: Obtained range characterization result for ray transform I_m in higher order weighted Sobolev spaces H^{r,s}_t(R^2) for any real r in two dimensions

Conclusion: The 2D case differs significantly from higher dimensions and allows complete range characterization in weighted Sobolev spaces using the Reshetnyak formula approach

Abstract: The ray transform $I_m$ integrates a symmetric $m$ rank tensor field $f$ on
$\mathbb{R}^n$ over lines. In the case of $n\ge3$, the range characterization
of the operator $I_m$ on weighted Sobolev spaces $H^{s}_t({{\mathbb
R}}^n;S^m{{\mathbb R}}^n)$ was obtained in [V. Krishnan and V. Sharafutdinov.
Range characterization of ray transform on Sobolev spaces of symmetric tensor
fields. Inverse Problems and Imaging, 18(6), 1272--1293, 2024]. Here we obtain
a range characterization result in higher order weighted Sobolev spaces in two
dimensions. Range characterization in the case of $n=2$ is very different from
that for $n\ge3$, and this allows us to obtain such a result in higher order
weighted Sobolev spaces $H^{r,s}_t(\mathbb{R}^2)$ for any real $r$.
Nevertheless, our main tool is again the Reshetnyak formula stating that
$\lVert I_mf\rVert_{H^{(r,s+1/2)}_{t+1/2}(T{{\mathbb S}}^{n-1})}=\lVert
f\rVert_{H^{(r,s)}_t({{\mathbb R}}^n;S^m{{\mathbb R}}^n)}$ for a solenoidal
tensor field $f$.

</details>


### [24] [Bounded imaginary powers of generalized diffusion operators](https://arxiv.org/abs/2509.03105)
*Alexandre Thorel*

Main category: math.AP

TL;DR: Analysis of boundedness of imaginary powers for four generalized diffusion operators, enabling solution of linear and semilinear Cauchy problems with maximal regularity.


<details>
  <summary>Details</summary>
Motivation: To establish the key property of bounded imaginary powers for generalized diffusion operators, which implies maximal regularity and enables solving both linear and semilinear Cauchy problems.

Method: Uses semigroup theory, functional calculus, operator sum theory, and R-boundedness techniques to prove boundedness of imaginary powers. Applies Dore-Venni theorem for linear problems and extends to semilinear cases.

Result: Successfully establishes boundedness of imaginary powers for the four operators, obtains unique solutions with maximal regularity for linear problems, and proves existence of unique global solutions for semilinear problems.

Conclusion: The developed framework provides a comprehensive approach for analyzing generalized diffusion operators and solving associated Cauchy problems with maximal regularity properties.

Abstract: In this paper, we investigate the boundedness of the imaginary powers of four
generalized diffusion operators. This key property, which implies the maximal
regularity property, allows us to solve both the linear and semilinear Cauchy
problems associated with each operator. Our approach relies on semigroup
theory, functional calculus, operator sum theory and R-boundedness techniques
to establish the boundedness of the imaginary powers of generalized diffusion
operators. We then apply the Dore-Venni theorem to solve the linear problem,
obtaining a unique solution with maximal regularity. Finally, we tackle the
semilinear problem and prove the existence of a unique global solution.

</details>


### [25] [Exponential ergodicity of mean-field Langevin dynamics by synchronous coupling](https://arxiv.org/abs/2509.03124)
*Mohamed Alfaki Aboubacrine Assadek*

Main category: math.AP

TL;DR: Analysis of long-time behavior and uniform propagation of chaos for mean-field Langevin dynamics using synchronous coupling methods


<details>
  <summary>Details</summary>
Motivation: The mean field Langevin dynamics is important due to its connection to gradient descent on infinitely wide neural networks in the mean field regime, making convergence properties theoretically significant

Method: Synchronous coupling approach for analyzing both over-damped and under-damped mean-field Langevin dynamics, building on previous work [1, 2]

Result: Study focuses on long-time behavior and uniform in time propagation of chaos properties

Conclusion: This research contributes to understanding convergence properties of mean-field Langevin dynamics relevant to neural network optimization

Abstract: As an example of the nonlinear Fokker-Planck equation, the mean field
Langevin dynamics recently attracts attention due to its connection to (noisy)
gradient descent on infinitely wide neural networks in the mean field regime,
and hence the convergence property of the dynamics is of great theoretical
interest. In this paper, In the continuity of [1, 2], we are interested by the
long-time behavior and uniform in time propagation of chaos by synchronous
coupling for mean-field Langevin dynamics (over- and under-damped).

</details>


### [26] [Hyperbolic Keller-Segel equations with weak dissipation in Besov spaces: Global well-posedness and blow-up criteria](https://arxiv.org/abs/2509.03125)
*Bo Bi,Lei Zhang*

Main category: math.AP

TL;DR: Global well-posedness for weakly dissipative hyperbolic Keller-Segel equations in Besov spaces with large dissipation or small initial data, plus blow-up criteria and time-dependent parameter analysis.


<details>
  <summary>Details</summary>
Motivation: Address open questions about global well-posedness in Besov spaces for hyperbolic Keller-Segel equations left by previous works, and understand how time-dependent parameters affect solution existence.

Method: Analysis of Cauchy problem in non-critical and critical inhomogeneous Besov spaces, establishing conditions for global strong solutions and deriving blow-up criteria with explicit lower bounds for blow-up time.

Result: Proves unique global strong solutions exist with sufficiently large dissipation parameter or sufficiently small initial data; extends results to time-dependent parameter cases; provides explicit blow-up criteria and characterization of blow-up time lower bounds.

Conclusion: The work partially answers open questions about global well-posedness, demonstrates how time-dependent parameters (particularly dissipation) ensure global existence, and provides comprehensive blow-up analysis for hyperbolic Keller-Segel equations.

Abstract: This paper considers the Cauchy problem for weakly dissipative hyperbolic
Keller-Segel (HKS) equations in both non-critical and critical inhomogeneous
Besov spaces. We first show that the problem admits a unique global strong
solution if either the dissipation parameter $\lambda$ is sufficiently large or
the initial data norm is sufficiently small. This provides a partial
affirmative answer to the open question of global well-posedness in Besov
spaces left by \cite{Zhang2022,Zhou2021,Meng2024}. An interesting observation
is that these results can be extended to HKS equations with time-dependent
parameters involving the weakly dissipative HKS equations as a special case,
where global solvability depends solely on the $L^1$-integrability of the
variable coefficients. Furthermore, we derive two types of blow-up criteria for
strong solutions in both critical and non-critical Besov spaces, and explicitly
characterize the lower bound of blow-up time. These findings partly clarify how
time-dependent parameters (especially, the dissipation parameter $\lambda$)
guarantee global existence of solutions.

</details>


### [27] [Hessian Estimates for the Sigma-2 Equation with Variable Right-Hand Side Terms in Dimension 4](https://arxiv.org/abs/2509.03217)
*Zhenyu Fan*

Main category: math.AP

TL;DR: A priori interior Hessian estimates and regularity for sigma-2 Hessian equations in dimension 4 and higher dimensions with additional conditions.


<details>
  <summary>Details</summary>
Motivation: To generalize previous results by Qiu and Shankar-Yuan on sigma-2 Hessian equations and establish regularity under broader conditions.

Method: Deriving interior Hessian estimates for the sigma-2 Hessian equation σ₂(D²u)=f(x,u,Du) with positive C¹¹ right-hand side, using dynamic semi-convexity conditions in higher dimensions.

Result: Successfully obtained interior Hessian estimates and regularity results in dimension 4, with extension to higher dimensions under additional dynamic semi-convexity conditions on solutions.

Conclusion: The work generalizes previous findings and provides comprehensive regularity results for sigma-2 Hessian equations across different dimensions with appropriate conditions.

Abstract: We derive a priori interior Hessian estimates and regularity for the sigma-2
Hessian equation $\sigma_{2}(D^2u)=f(x,u,Du)$ with positive $C^{1,1}$ right
hand side in dimension 4. In higher dimensions, the same result holds under an
additional dynamic semi-convexity condition on solutions. This generalizes
Qiu's and Shankar-Yuan's results.

</details>


### [28] [Local boundary conditions in nonlocal hyperelasticity via heterogeneous horizons](https://arxiv.org/abs/2509.03468)
*Carolin Kreisbeck,Hidde Schönberger*

Main category: math.AP

TL;DR: This paper develops a comprehensive mathematical theory for nonlocal gradient models with space-dependent interaction ranges that vanish at boundaries, enabling seamless integration with local boundary conditions and establishing existence of minimizers for various functional types.


<details>
  <summary>Details</summary>
Motivation: To refine classical hyperelasticity by capturing discontinuous and singular material effects through nonlocal gradient models, while ensuring compatibility with local boundary conditions through vanishing interaction ranges at boundaries.

Method: Develops Sobolev spaces for nonlocal gradients, uses pseudo-differential operator theory to rigorously treat trace operators and Poincaré inequalities, and establishes existence of minimizers for quasiconvex and polyconvex functionals with heterogeneous nonlocal gradients under various boundary conditions.

Result: A comprehensive mathematical framework for nonlocal gradient models with boundary-vanishing interaction ranges, including well-defined Sobolev spaces, trace operators, Poincaré inequalities, and existence proofs for minimizers under Dirichlet, Neumann, and mixed boundary conditions.

Conclusion: The proposed nonlocal gradient framework successfully bridges local and nonlocal modeling by ensuring boundary localization to classical gradients while capturing material singularities, providing a rigorous mathematical foundation for applications in hyperelasticity and beyond.

Abstract: In this paper, we consider a class of variational problems with integral
functionals involving nonlocal gradients. These models have been recently
proposed as refinements of classical hyperelasticity, aiming for an effective
framework to capture also discontinuous and singular material effects. Specific
to our set-up is a space-dependent interaction range that vanishes at the
boundary of the reference domain. This ensures that the nonlocal operator
depends only on values within the domain and localizes to the classical
gradient at the boundary, which allows for a seamless integration of nonlocal
modeling with local boundary values. The main contribution of this work is a
comprehensive theory for the newly introduced associated Sobolev spaces,
including the rigorous treatment of a trace operator and Poincar\'e
inequalities. A central aspect of our technical approach lies in exploiting
connections with pseudo-differential operator theory. As an application, we
establish the existence of minimizers for functionals with quasiconvex or
polyconvex integrands depending on heterogeneous nonlocal gradients, subject to
local Dirichlet, Neumann or mixed-type boundary conditions.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [29] [Collision operator for electron runaway in cold weakly-ionized plasmas](https://arxiv.org/abs/2509.03092)
*Yeongsun Lee,Pavel Aleynikov,Peter de Vries,Jong-Kyu Park,Yong-Su Na*

Main category: physics.plasm-ph

TL;DR: A collision operator combining Fokker-Planck and Boltzmann operators is developed to accurately model non-diffusive electron kinetics in cold weakly-ionized plasmas, particularly for runaway electron prediction in tokamak startup.


<details>
  <summary>Details</summary>
Motivation: To address the non-diffusive nature of Dreicer generation mechanism in cold weakly-ionized plasmas and enable precise prediction of runaway electrons for designing runaway-free reactor tokamak startup.

Method: Developed a proper collision operator that appropriately combines Fokker-Planck operator and Boltzmann operator, using free-bound collision cross sections valid in low energy regions.

Result: The proposed operator provides detailed description of non-diffusive electron kinetics, expanding on previous work that demonstrated non-diffusive Dreicer generation.

Conclusion: The collision operator is designed to accurately predict runaway electron generation in cold weakly-ionized plasmas, with specific application to designing safe reactor tokamak startup scenarios.

Abstract: In cold weakly-ionized plasmas, Dreicer generation mechanism can be
non-diffusive as demonstrated in [Y. Lee et. al. Phys. Rev. Lett. 133 17 175102
(2024)]. By expanding the previous letter, we present the detailed description
of a proper collision operator to precisely account for the non-diffusive
electron kinetics. The operator appropriately combines the Fokker-Planck
operator and Boltzmann operator where free-bound collision cross sections are
valid in low energy region. The proposed operator is envisaged to predict
runaway electrons generations in cold weakly-ionized plasmas, particularly to
design a runaway-free reactor tokamak startup.

</details>


### [30] [Self-consistent generation of the ambipolar electric field in collisionless plasmas via multi-mode electrostatics](https://arxiv.org/abs/2509.03142)
*Luca Barbieri*

Main category: physics.plasm-ph

TL;DR: Self-consistent method for generating ambipolar electric field in gravitationally stratified collisionless plasma using multi-mode Fourier expansion of electrostatic interaction.


<details>
  <summary>Details</summary>
Motivation: Gravity separates charged species in stratified plasma atmospheres, requiring electric fields to maintain charge neutrality. Current approaches impose the Pannekoek-Rosseland field externally rather than self-consistently.

Method: Multi-mode Fourier expansion of electrostatic interaction to self-consistently recover the ambipolar electric field and restore charge neutrality.

Result: Method successfully generates ambipolar electric field under suitable conditions and works for both isothermal and multi-temperature plasma configurations.

Conclusion: Provides foundation for modeling realistic stellar atmospheres with future extensions including collisions, ionization, and asymmetric boundary conditions.

Abstract: In this work, we investigate the generation of the ambipolar electric field
in a gravitationally stratified, collisionless plasma atmosphere. In such
environments, gravity tends to separate charged species. To prevent separation
an electric field, classically described by the Pannekoek-Rosseland expression,
is usually imposed externally. Here, we propose a self-consistent method to
recover this field based on a multi-mode Fourier expansion of the electrostatic
interaction. We show that, under suitable conditions, this approach naturally
leads to the ambipolar electric field and restores charge neutrality. The
method is tested in both isothermal and multi-temperature plasma
configurations. This framework provides a foundation for future developments
that may include collisions, ionization, and asymmetric boundary conditions to
model more realistic stellar atmospheres.

</details>


### [31] [Extended temporal coarse-graining in a stratified and confined plasma under thermal fluctuations](https://arxiv.org/abs/2509.03149)
*Luca Barbieri,Simone Landi,Lapo Casetti,Andrea Verdini*

Main category: physics.plasm-ph

TL;DR: Extended investigation of gravitationally confined collisionless plasma showing temperature inversion driven by rapid base temperature fluctuations, with generalized coarse-graining formalism for broader timescale regimes.


<details>
  <summary>Details</summary>
Motivation: To understand how temperature inversion in gravitationally confined plasma behaves when temperature fluctuation timescales are comparable to or exceed electron crossing time, extending previous work that only covered much shorter timescales.

Method: Developed generalized temporal coarse-graining formalism, derived kinetic equations with additional coarse-graining term, and conducted numerical simulations to analyze plasma dynamics across different fluctuation timescales.

Result: Electric field influences system when fluctuation timescales approach electron crossing time, but becomes negligible for timescales much larger than proton crossing time. Temperature inversion persists under specific regimes and conditions identified.

Conclusion: The extended coarse-graining theory successfully describes plasma behavior across broader timescale regimes, identifying when temperature inversion occurs and how electric field effects vary with fluctuation timescales.

Abstract: We present an extended investigation of a recently introduced model of
gravitationally confined, collisionless plasma (Barbieri et al. 2024a), which
showed that rapid temperature fluctuations at the base of the plasma, occurring
on timescales much shorter than the electron crossing time, can drive the
system into a non-thermal state characterized by anti-correlated temperature
and density profiles, commonly referred to as temperature inversion. To
describe this phenomenon, a temporal coarse-graining formalism was developed
(Barbieri et al. 2024b). In this work, we generalize that approach to cover
regimes where the timescales of temperature fluctuations are comparable to or
exceed the electron crossing time. We derive a set of kinetic equations that
incorporate an additional term arising from the coarse-graining procedure,
which was not present in the earlier formulation. Through numerical
simulations, we analyze the plasma dynamics under these broader conditions,
showing that the electric field influences the system when fluctuation
timescales approach the electron crossing time. However, for timescales much
larger than the proton crossing time, the electric field becomes negligible.
The observed behaviours are interpreted within the framework of the extended
temporal coarse-graining theory, and we identify the regimes and conditions in
which temperature inversion persists.

</details>


### [32] [Plasma lens for the focusing of positron bunches](https://arxiv.org/abs/2509.03225)
*D. S. Bondar,C. A. Lindstrøm,V. I. Maslov,I. N. Onishchenko*

Main category: physics.plasm-ph

TL;DR: A method for focusing positron bunches using plasma lens in linear regime achieves high-quality transverse focusing and potential energy spread reduction.


<details>
  <summary>Details</summary>
Motivation: Nonlinear regimes fail to create stable focusing channels for positron bunches in plasma accelerators, requiring effective focusing schemes.

Method: Numerical simulations of two positron bunch profiles (Gaussian and elongated flat-top with Gaussian edges) using plasma lens in linear regime.

Result: Both configurations demonstrate capability to achieve high-quality transverse focusing and potential energy spread reduction for positron bunches.

Conclusion: Plasma lens operating in linear regime provides effective focusing solution for positron bunches, overcoming limitations of nonlinear regimes.

Abstract: The development of effective focusing schemes for positron bunches in plasma
accelerators remains a significant challenge, as nonlinear regimes fail to
create stable focusing channels for positrons. This work presents a method for
focusing and improving the quality of positron bunches using a plasma lens
operating in the linear regime. Through numerical simulations, we investigate
two distinct focused positron bunch profiles: a purely Gaussian bunch and an
elongated, flat-top bunch with Gaussian rising and falling edges. For both
configurations, the results demonstrate the capability to achieve high-quality
transverse focusing. Furthermore, beyond focusing, the proposed system enables
potential possibility to reduce energy spread of positron bunches of the
sequence after precursor.

</details>


### [33] [The properties of resistive MHD modes and unstable spectra in advanced tokamak regimes](https://arxiv.org/abs/2509.03429)
*M. Coste-Sarguet,J. P. Graves*

Main category: physics.plasm-ph

TL;DR: Analysis of resistive infernal modes in advanced tokamak regimes with low magnetic shear, showing how these fast-growing MHD instabilities emerge and their significance for fusion reactor stability.


<details>
  <summary>Details</summary>
Motivation: Advanced tokamak regimes with low magnetic shear are promising for future fusion reactors but are prone to specific MHD instabilities. Understanding these resistive infernal modes is crucial for developing stable reactor scenarios and comprehending global reconnection events like sawteeth.

Method: Derived new analytic solutions including generalization of ideal interchange dispersion relation to non-monotonic q profiles, and extended a modular linear resistive MHD solver to investigate effects of resistivity, compressibility, toroidal effects, and shaping on stability.

Result: Found that proximity to rational surfaces in low shear regions weakens field line bending stabilization and amplifies toroidal coupling, leading to emergence of long-wavelength resistive infernal modes that grow collectively as discrete spectra with oscillatory radial structures.

Conclusion: Common assumptions in numerical calculations prevent observation of the full variety of modes in advanced scenarios, highlighting the need for deeper investigation into fundamental physics of these instabilities for stable fusion reactor development.

Abstract: Advanced tokamak regimes, featuring extended regions of low magnetic shear,
are promising candidates for future fusion reactors but are also more prone to
specific kinds of MHD instabilities. The proximity to a rational surface in a
very low shear region weakens field line bending stabilisation and amplifies
the effects of toroidal coupling between modes, leading to the emergence of
long-wavelength resistive infernal modes. These modes can grow collectively as
a discrete spectrum, leading to a cascade of different perturbations for single
mode numbers $(m, n)$, with subdominant modes showing increasingly oscillatory
radial structures. These spectra of fast-growing modes are significant for
developing stable scenarios in future reactors, and for the understanding of
global reconnection events like sawteeth, motivating a deeper investigation
into their fundamental physics. Deriving new analytic solutions, including a
generalisation of the ideal interchange dispersion relation to non monotonic
$q$ profiles, and extending a modular linear resistive MHD solver, we
investigate how resistivity, compressibility, toroidal effects, and shaping
influence stability, especially in reversed shear $q$ profiles. It is also
shown that common assumptions in numerical calculations prevent the observation
of the full variety of modes present in these advanced scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [34] [Towards Reasoning for PDE Foundation Models: A Reward-Model-Driven Inference-Time-Scaling Algorithm](https://arxiv.org/abs/2509.02846)
*Siddharth Mansingh,James Amarel,Ragib Arnab,Arvind Mohan,Kamaljeet Singh,Gerd J. Kunde,Nicolas Hengartner,Benjamin Migliori,Emily Casleton,Nathan A. Debarledeben,Ayan Biswas,Diane Oyen,Earl Lawrence*

Main category: cs.LG

TL;DR: A test-time computing strategy for PDEs that uses computational resources during inference to improve prediction accuracy with fewer training samples and smaller models, using reward models for spatio-temporal consistency evaluation.


<details>
  <summary>Details</summary>
Motivation: Existing PDE foundation models are constrained by pretraining datasets, struggle with auto-regressive rollout performance in OOD cases, and have high compute/training data requirements that limit critical applications.

Method: Introduces test-time computing (TTC) strategy inspired by LLM thinking strategies, using two types of reward models to evaluate predictions of a stochastic model for spatio-temporal consistency.

Result: Demonstrated on compressible Euler-equation simulations from PDEGym benchmark, showing TTC captures improved predictions compared to standard non-adaptive auto-regressive inference.

Conclusion: TTC framework represents a foundational step toward advanced reasoning algorithms for PDE modeling, including RL-based approaches, potentially transforming computational workflows in physics and engineering.

Abstract: Partial Differential Equations (PDEs) are the bedrock for modern
computational sciences and engineering, and inherently computationally
expensive. While PDE foundation models have shown much promise for simulating
such complex spatio-temporal phenomena, existing models remain constrained by
the pretraining datasets and struggle with auto-regressive rollout performance,
especially in out-of-distribution (OOD) cases. Furthermore, they have
significant compute and training data requirements which hamper their use in
many critical applications. Inspired by recent advances in ``thinking"
strategies used in large language models (LLMs), we introduce the first
test-time computing (TTC) strategy for PDEs that utilizes computational
resources during inference to achieve more accurate predictions with fewer
training samples and smaller models. We accomplish this with two types of
reward models that evaluate predictions of a stochastic based model for
spatio-temporal consistency. We demonstrate this method on compressible
Euler-equation simulations from the PDEGym benchmark and show that TTC captures
improved predictions relative to standard non-adaptive auto-regressive
inference. This TTC framework marks a foundational step towards more advanced
reasoning algorithms or PDE modeling, inluding building
reinforcement-learning-based approaches, potentially transforming computational
workflows in physics and engineering.

</details>


### [35] [A Neural Network Approach to Multi-radionuclide TDCR Beta Spectroscopy](https://arxiv.org/abs/2509.03137)
*Li Yi,Qian Yang*

Main category: cs.LG

TL;DR: AI framework combining numerical spectral simulation and deep learning for automated, standard-free analysis of multiradionuclide mixtures using TDCR spectroscopy.


<details>
  <summary>Details</summary>
Motivation: Traditional TDCR spectroscopy faces challenges with limited automation and reliance on mixture-specific standards that may not be readily available, requiring a standard-free automated solution.

Method: Geant4 simulations coupled with statistically modeled detector response sampling to generate β spectra for training, combined with a tailored neural network architecture trained on various nuclei mix ratios and quenching scenarios.

Result: High accuracy across tasks: activity proportions (MAE=0.009), detection efficiencies (MAE=0.002), and spectral reconstruction (SSIM=0.9998), demonstrating physical plausibility for quenched β spectroscopy.

Conclusion: The AI-driven methodology shows significant potential for automated safety-compliant multiradionuclide analysis with robust generalization, real-time processing, and engineering feasibility, especially when reference materials are unavailable or rapid field analysis is needed.

Abstract: Liquid scintillation triple-to-doubly coincident ratio (TDCR) spectroscopy is
widely adopted as a standard method for radionuclide quantification because of
its inherent advantages such as high precision, self-calibrating capability,
and independence from radioactive reference sources. However, multiradionuclide
analysis via TDCR faces the challenges of limited automation and reliance on
mixture-specific standards, which may not be easily available. Here, we present
an Artificial Intelligence (AI) framework that combines numerical spectral
simulation and deep learning for standard-free automated analysis. $\beta$
spectra for model training were generated using Geant4 simulations coupled with
statistically modeled detector response sampling. A tailored neural network
architecture, trained on this dataset covering various nuclei mix ratio and
quenching scenarios, enables autonomous resolution of individual radionuclide
activities and detecting efficiency through end-to-end learning paradigms. The
model delivers consistent high accuracy across tasks: activity proportions
(mean absolute error = 0.009), detection efficiencies (mean absolute error =
0.002), and spectral reconstruction (Structural Similarity Index = 0.9998),
validating its physical plausibility for quenched $\beta$ spectroscopy. This
AI-driven methodology exhibits significant potential for automated
safety-compliant multiradionuclide analysis with robust generalization,
real-time processing capabilities, and engineering feasibility, particularly in
scenarios where reference materials are unavailable or rapid field analysis is
required.

</details>


### [36] [Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems](https://arxiv.org/abs/2509.03340)
*Fleur Hendriks,Ondřej Rokoš,Martin Doškář,Marc G. D. Geers,Vlado Menkovski*

Main category: cs.LG

TL;DR: Flow matching framework for modeling multimodal distributions in bifurcation systems, preserving symmetries through equivariant modeling and outperforming non-probabilistic methods.


<details>
  <summary>Details</summary>
Motivation: Deterministic machine learning models fail to capture multiple coexisting stable solutions in nonlinear dynamical systems with symmetry breaking, averaging over solutions and missing lower-symmetry outcomes.

Method: Generative framework based on flow matching with symmetric matching strategy that aligns predicted and target outputs under group actions for equivariant modeling of probability distributions over bifurcation outcomes.

Result: Validated on toy models and complex physical problems (buckling beams, Allen-Cahn equation), flow matching significantly outperforms non-probabilistic and variational methods in capturing multimodal distributions and symmetry-breaking bifurcations.

Conclusion: Provides a principled and scalable solution for modeling multistability in high-dimensional systems through direct sampling of multiple valid solutions while preserving system symmetries.

Abstract: Bifurcation phenomena in nonlinear dynamical systems often lead to multiple
coexisting stable solutions, particularly in the presence of symmetry breaking.
Deterministic machine learning models struggle to capture this multiplicity,
averaging over solutions and failing to represent lower-symmetry outcomes. In
this work, we propose a generative framework based on flow matching to model
the full probability distribution over bifurcation outcomes. Our method enables
direct sampling of multiple valid solutions while preserving system symmetries
through equivariant modeling. We introduce a symmetric matching strategy that
aligns predicted and target outputs under group actions, allowing accurate
learning in equivariant settings. We validate our approach on a range of
systems, from toy models to complex physical problems such as buckling beams
and the Allen-Cahn equation. Our results demonstrate that flow matching
significantly outperforms non-probabilistic and variational methods in
capturing multimodal distributions and symmetry-breaking bifurcations, offering
a principled and scalable solution for modeling multistability in
high-dimensional systems.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [37] [Simultaneous approximation of multiple degenerate states using a single neural network quantum state](https://arxiv.org/abs/2509.02658)
*Waleed Sherif*

Main category: quant-ph

TL;DR: A single-trunk multi-head neural network quantum state ensemble that efficiently approximates degenerate quantum ground states by sharing feature extraction while using lightweight heads for each state, reducing computational costs significantly.


<details>
  <summary>Details</summary>
Motivation: Neural network quantum states are effective for ground state approximation but computationally expensive for degenerate manifolds. There's a need for more efficient methods to handle multiple degenerate states simultaneously.

Method: Proposes ST-MH NQS ensemble with shared feature-extracting trunk and individual lightweight heads for each target state. Uses cost function with orthogonality term and derives exact analytic gradients for variational Monte Carlo training.

Result: ST-MH reduces parameter count and computational cost by factor equal to degeneracy K. Validated on frustrated spin-1/2 J1-J2 Heisenberg model, achieving high fidelity and energy accuracy with significantly lower computing resources.

Conclusion: The ST-MH approach provides an efficient framework for approximating degenerate quantum states, reducing computational costs while maintaining accuracy, making it particularly valuable for systems with modest degeneracy.

Abstract: Neural network quantum states (NQS) excel at approximating ground states of
quantum many-body systems, but approximating all states of a degenerate
manifold is nevertheless computationally expensive. We propose a single-trunk
multi-head (ST-MH) NQS ensemble that share a feature extracting trunk while
attaching lightweight heads for each target state. Using a cost function which
also has an orthogonality term, we derive exact analytic gradients and overlap
derivatives needed to train ST-MH within standard variational Monte Carlo (VMC)
workflows. We prove that ST-MH can represent every degenerate eigenstate
exactly whenever the feature map of latent width $h$, augmented with a
constant, has column space containing the linear span of the targets'
log-moduli and (chosen) phase branches together with the constant on the common
support where all states are non-vanishing. Under this condition, ST-MH reduces
the parameter count and can reduce the leading VMC cost by a factor equal to
the degeneracy $K$ relative to other algorithms when $K$ is modest and in trunk
dominated regimes. As a numerical proof-of-principle, we validate and benchmark
the ST-MH approach on the frustrated spin-$\tfrac{1}{2}$ $J_1-J_2$ Heisenberg
model at the Majumdar-Ghosh point on periodic ring lattices of up to 8 sites.
By obtaining the momentum eigenstates, we demonstrate that ST-MH attains high
fidelity and energy accuracy across degenerate ground state manifolds while
using significantly lower computing resources. Lastly we provide a qualitative
computational cost analysis which incentivise the applicability of the ST-MH
ensemble under certain criteria on the latent width.

</details>


### [38] [Entanglement Complexity in Many-body Systems from Positivity Scaling Laws](https://arxiv.org/abs/2509.02944)
*Anna O. Schouten,David A. Mazziotti*

Main category: quant-ph

TL;DR: The paper introduces a framework using p-particle positivity conditions from RDM theory to measure computational complexity, proving that systems solvable with level-p positivity independent of size have polynomial entanglement complexity scaling with order p.


<details>
  <summary>Details</summary>
Motivation: Area laws provide necessary conditions for efficient quantum simulation but don't directly measure computational complexity. The authors aim to develop a complementary framework that connects structural RDM constraints with computational tractability.

Method: The approach uses p-particle positivity conditions from reduced density matrix theory, which form a hierarchy of N-representability constraints. These become exact when the Hamiltonian can be expressed as a convex combination of positive semidefinite p-particle operators.

Result: The authors prove a general complexity bound: if a quantum system is solvable with level-p positivity independent of its size, then its entanglement complexity scales polynomially with order p.

Conclusion: This framework provides rigorous certification for when many-body methods including RDM methods can efficiently simulate correlated quantum matter and materials, connecting structural RDM constraints with computational tractability.

Abstract: Area laws describe how entanglement entropy scales and thus provide important
necessary conditions for efficient quantum many-body simulation, but they do
not, by themselves, yield a direct measure of computational complexity. Here we
introduce a complementary framework based on $p$-particle positivity conditions
from reduced density matrix (RDM) theory. These conditions form a hierarchy of
$N$-representability constraints for an RDM to correspond to a valid
$N$-particle quantum system, becoming exact when the Hamiltonian can be
expressed as a convex combination of positive semidefinite $p$-particle
operators. We prove a general complexity bound: if a quantum system is solvable
with level-$p$ positivity independent of its size, then its entanglement
complexity scales polynomially with order $p$. This theorem connects structural
constraints on RDMs with computational tractability and provides a rigorous
framework for certifying when many-body methods including RDM methods can
efficiently simulate correlated quantum matter and materials.

</details>


### [39] [Chirality-Induced Orbital-Angular-Momentum Selectivity in Electron Transmission and Scattering](https://arxiv.org/abs/2509.02997)
*Yun Chen,Oded Hod,Joel Gersten,Abraham Nitzan*

Main category: quant-ph

TL;DR: Study shows chirality-induced orbital-angular-momentum selectivity in electron transmission through chiral media, with potential applications in quantum technologies.


<details>
  <summary>Details</summary>
Motivation: To investigate how chirality affects electron orbital angular momentum (OAM) during transmission and scattering processes, particularly in relation to chirality-induced spin selectivity phenomena.

Method: Used time-dependent Schrödinger equation for electronic wavepacket propagation through chiral media, and demonstrated spatial resolution of wavepackets with opposite OAM after scattering from corrugated surfaces.

Result: Found that orbital angular momentum plays a significant role in chirality-induced spin selectivity mechanisms observed in electron transmission through chiral media.

Conclusion: Chirality-induced orbital-angular-momentum selectivity has promising potential for exploitation in emerging quantum technologies.

Abstract: Chirality-induced orbital-angular-momentum selectivity (CIOAMS) in electron
transmission and scattering processes is investigated. Polarization of the OAM
of an electron traversing chiral media is first studied via electronic
wavepacket propagation using the time-dependent Schr\"odinger equation. Next,
spatial resolution of wavepackets carrying opposite OAM, following scattering
from a corrugated surface is demonstrated. This suggests that OAM may play a
significant role in the mechanisms underlying chirality induced spin
selectivity, measured for electrons crossing chiral media in setups involving
Mott polarimetry. Our results highlight the potential to exploit CIOAMS in
innovative emerging quantum technologies.

</details>


### [40] [Theory of dynamical superradiance in organic materials](https://arxiv.org/abs/2509.03067)
*Lukas Freter,Piper Fowler-Wright,Javier Cuerda,Brendon W. Lovett,Jonathan Keeling,Päivi Törmä*

Main category: quant-ph

TL;DR: Dynamical superradiance theory for organic materials with vibrational coupling, showing vibrationally assisted superradiance is possible and can be enhanced with negative cavity detunings.


<details>
  <summary>Details</summary>
Motivation: To understand how vibrational modes affect collective energy exchange between excited emitters and cavities in organic materials, going beyond simple dephasing effects.

Method: Two models: Markovian bath treatment via Lindblad master equation, and direct inclusion via Holstein-Tavis-Cummings Hamiltonian. Used permutation symmetry and weak U(1) symmetry for exact numerical solutions up to 140 emitters, validated mean-field and cumulant approximations.

Result: Superradiance is possible with vibrational coupling; negative cavity detunings can enhance superradiance. Vibrational effects go beyond simple dephasing. Asymmetric photon number rise time vs detuning serves as experimental signature.

Conclusion: Vibrational coupling enables and can enhance superradiance in organic materials, with identifiable experimental signatures for vibrationally assisted superradiance.

Abstract: We develop the theory of dynamical superradiance -- the collective exchange
of energy between an ensemble of initially excited emitters and a single-mode
cavity -- for organic materials where electronic states are coupled to
vibrational modes. We consider two models to capture the vibrational effects:
first, vibrations treated as a Markovian bath for two-level emitters, via a
pure dephasing term in the Lindblad master equation for the system; second,
vibrational modes directly included in the system via the
Holstein--Tavis--Cummings Hamiltonian. By exploiting the permutation symmetry
of the emitters and weak U(1) symmetry, we develop a numerical method capable
of exactly solving the Tavis-Cummings model with local dissipation for up to
140 emitters. Using the exact method, we validate mean-field and second-order
cumulant approximations and use them to describe macroscopic numbers of
emitters. We analyse the dynamics of the average cavity photon number,
electronic coherence, and Bloch vector length, and show that the effect of
vibrational mode coupling goes beyond simple dephasing. Our results show that
superradiance is possible in the presence of vibrational mode coupling; for
negative cavity detunings, the vibrational coupling may even enhance
superradiance. We identify asymmetry of the photon number rise time as a
function of the detuning of the cavity frequency as an experimentally
accessible signature of such vibrationally assisted superradiance.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [41] [On linking numbers and Biot-Savart kernels](https://arxiv.org/abs/2509.02802)
*Daniel Cibotaru,Luciano Mari*

Main category: math.DG

TL;DR: The paper constructs solutions to the exterior derivative equation using heat equation techniques and develops a differential linking form for 3D compact Riemannian manifolds that generalizes the Gauss linking formula.


<details>
  <summary>Details</summary>
Motivation: To develop a mathematical framework for solving the exterior derivative equation dω = L using heat equation methods, and to create a differential linking form that works on general compact Riemannian manifolds, extending the classical Gauss linking formula beyond Euclidean space.

Method: Uses solutions of the heat equation with currential initial conditions on compact manifolds. For exact submanifold L, integrates the heat equation solution family to obtain smooth form Ω, then takes d*Ω to solve dω = L. Introduces asymptotic approximations for small t to study extendibility properties. Adapts these techniques to the diagonal case in M×M to construct a differential linking form.

Result: Shows that d*Ω extends to the oriented blow-up of L in codimension 1 and 3 (and codimension 2 when L is minimal). For the diagonal case in M×M, obtains a differential linking form for 3D compact Riemannian manifolds that coincides with the Biot-Savart operator kernel and recovers the Gauss linking formula in R³.

Conclusion: The heat equation approach provides a powerful method for constructing solutions to exterior derivative problems and yields a natural generalization of linking forms to arbitrary compact Riemannian 3-manifolds, with the classical Gauss formula appearing as a special case in Euclidean space.

Abstract: On a compact manifold, the solutions of the initial value problem for the
heat equation with currential initial conditions are smooth families of forms
for $t>0$. If the initial condition is an exact submanifold $L$ then the
integral in $t$ of this family gives a smooth form $\Omega$ on the complement
of $L$ such that $\omega:=d^*\Omega$ is a solution for the exterior derivative
equation $d\omega=L$. We introduce, for small $t$, an asymptotic approximation
of these solutions in order to show that $d^*\Omega$ is extendible to the
oriented blow-up of $L$ in codimension $1$ and $3$ and also $2$ when $L$ is
minimal. When $L$ is the diagonal in $M\times M$ we adapt these ideas to obtain
a differential linking form for any compact, ambient Riemannian manifold $M$ of
dimension $3$. This coincides up to sign with the kernel of the Biot-Savart
operator $d^*G$ and recovers the well-known Gauss formula for linking numbers
in $\mathbb{R}^3$.

</details>


<div id='physics.acc-ph'></div>

# physics.acc-ph [[Back]](#toc)

### [42] [Wakefield acceleration of self-injected bunch in a conical plasma channels](https://arxiv.org/abs/2509.03229)
*D. S. Bondar,W. Leemans,V. I. Maslov,I. N. Onishchenko*

Main category: physics.acc-ph

TL;DR: Using tapering cone channels to maintain laser wakefield acceleration synchronization by reducing bubble size as particle bunches accelerate beyond driver velocity.


<details>
  <summary>Details</summary>
Motivation: Address the problem of particle bunches shifting out of the optimal accelerating wakefield phase as they accelerate beyond the driver velocity in laser wakefield acceleration.

Method: Proposes using a tapering cone channel that gradually narrows to reduce bubble size and synchronize the particle bunch with the accelerating wakefield phase.

Result: Obtained dependencies of bunch length, field Ez, and mean longitudinal momentum pz on channel radius, providing useful data for further research.

Conclusion: Tapering cone channels effectively maintain synchronization between accelerating particle bunches and wakefield phase, enabling continued optimal acceleration.

Abstract: Laser wakefield acceleration is a widely studied method for accelerating
charged particle bunches, with selfinjection being a key feature. However, as
the bunch accelerates beyond the driver velocity, it shifts out of the maximal
accelerating wakefield phase. This work proposes using a tapering cone channel
to address this issue. The gradual narrowing synchronizes the bunch with the
wake phase by reducing the bubble size, keeping the bunch in the accelerating
phase. The obtained dependencies of the bunch length, field Ez, and mean
longitudinal momentum pz on the channel radius are useful for further
researches.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [43] [Non-Linear and Meta-Stable Dynamics in Financial Markets: Evidence from High Frequency Crypto Currency Market Makers](https://arxiv.org/abs/2509.02941)
*Igor Halperin*

Main category: q-fin.ST

TL;DR: Experimental validation that market dynamics require higher-order non-linear drifts rather than linear diffusion models, with evidence from crypto data showing single/double-well potentials indicating market states.


<details>
  <summary>Details</summary>
Motivation: To validate the long-standing conjecture that linear diffusion models are inadequate for complex market dynamics and prove that realistic markets are governed by higher-order non-linearities in drift terms.

Method: Analyzed high-frequency cryptocurrency data across multiple time scales (minutes to months) to characterize market dynamics through potential function analysis derived from diffusion drift gradients.

Result: Found that markets exhibit either single-well or double-well potential structures depending on time period and sampling frequency, with double-well potentials potentially indicating market uncertainty or stress.

Conclusion: Market dynamics are better described by non-linear drift models with non-quadratic potentials, providing direct experimental confirmation of prior theoretical arguments about complex market behavior.

Abstract: This work builds upon the long-standing conjecture that linear diffusion
models are inadequate for complex market dynamics. Specifically, it provides
experimental validation for the author's prior arguments that realistic market
dynamics are governed by higher-order (cubic and higher) non-linearities in the
drift. As the diffusion drift is given by the negative gradient of a potential
function, this means that a non-linear drift translates into a non-quadratic
potential. These arguments were based both on general theoretical grounds as
well as a structured approach to modeling the price dynamics which incorporates
money flows and their impact on market prices. Here, we find direct
confirmation of this view by analyzing high-frequency crypto currency data at
different time scales ranging from minutes to months. We find that markets can
be characterized by either a single-well or a double-well potential, depending
on the time period and sampling frequency, where a double-well potential may
signal market uncertainty or stress.

</details>


<div id='math.CV'></div>

# math.CV [[Back]](#toc)

### [44] [Bruck conjecture for solutions of first-order partial differential equations in Cm](https://arxiv.org/abs/2509.02576)
*Sujoy Majumder,Nabadwip Sarkar,Debabrata Pramanik*

Main category: math.CV

TL;DR: Brück conjecture in several complex variables is proven valid under additional conditions, with new results including a Borel-Caratheodory theorem in C^m and extensions of order/hyper-order concepts to higher dimensions.


<details>
  <summary>Details</summary>
Motivation: To investigate Brück conjecture concerning solutions of first-order partial differential equations in several complex variables and extend classical complex analysis results to higher dimensions.

Method: Established the Borel-Caratheodory theorem in C^m and derived fundamental results concerning order and hyper-order in higher dimensions to analyze the conjecture.

Result: Brück conjecture in C^m is valid under some additional conditions, with new higher-dimensional extensions of classical complex analysis theorems.

Conclusion: The paper successfully extends Brück conjecture to several complex variables and provides important generalizations of complex analysis tools to higher dimensions.

Abstract: In the paper, we consider Br\"{u}ck conjecture as the solutions of
first-order partial differential equations in several complex variables. Our
results ensure that Br\"{u}ck conjecture in $\mathbb{C}^m$ is valid under some
additional conditions. In pursuit of this goal, we have also established the
Borel-Caratheodory theorem in $\mathbb{C}^m$ and derived several fundamental
results concerning order and hyper-order into higher dimensions.

</details>


<div id='physics.ins-det'></div>

# physics.ins-det [[Back]](#toc)

### [45] [Measured Properties of an Antihydrogen Beam](https://arxiv.org/abs/2509.02583)
*E. D. Hunter,M. Bumbar,C. Amsler,M. N. Bayo,H. Breuker,M. Cerwenka,G. Costantini,R. Ferragut,M. Giammarchi,A. Gligorova,G. Gosta,M. Hori,C. Killian,V. Kraxberger,N. Kuroda,A. Lanz,M. Leali,G. Maero,C. Malbrunot,V. Mascagna,Y. Matsuda,S. Migliorati,D. J. Murtagh,M. Romé,R. E. Sheldon,M. C. Simon,M. Tajima,V. Toso,S. Ulmer,L. Venturelli,A. Weiser,E. Widmann*

Main category: physics.ins-det

TL;DR: 100x increase in antihydrogen beam intensity with 320 atoms detected per 15-minute run, featuring Rydberg atoms analyzed through selective ionization to determine velocity and binding energy distributions.


<details>
  <summary>Details</summary>
Motivation: To enhance the production and detection efficiency of antihydrogen atoms for fundamental physics research, particularly in studying antimatter properties and symmetry violations.

Method: Used ASACUSA's Cusp trap to generate antihydrogen beams, selectively ionized Rydberg atoms to measure velocity and binding energy, modeled time of flight with 1D Maxwellian velocity distribution, and performed numerical simulations to analyze energy states.

Result: Achieved 320 antihydrogen atoms detected per 15-minute run (100x intensity increase), determined velocity distribution temperature of 1500K matching antiproton plasma temperature, and estimated 16% of atoms may be in ground state through simulation.

Conclusion: Significant improvement in antihydrogen beam production enables detailed characterization of atom properties, with simulations suggesting substantial ground state population, advancing antimatter research capabilities.

Abstract: We report a factor of $100$ increase in the antihydrogen beam intensity
downstream of ASACUSA's Cusp trap: $320$ atoms detected per $15$-minute run.
The beam contains many Rydberg atoms, which we selectively ionize to determine
their velocity and binding energy. The time of flight signal is modeled using a
$1\mathrm{D}$ Maxwellian velocity distribution with a temperature of
$1500\,\mathrm{K}$, which is close to the measured antiproton plasma
temperature. A numerical simulation reproduces the observed distribution of
binding energies and suggests that about $16\%$ of the atoms may be in the
ground state.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [46] [Network connectivity analysis via shortest paths](https://arxiv.org/abs/2509.03230)
*Silvia Noschese,Lothar Reichel*

Main category: physics.soc-ph

TL;DR: This paper analyzes information flow in graphs using path length matrices and introduces novel connectivity measures to assess edge importance for network simplification and sensitivity analysis.


<details>
  <summary>Details</summary>
Motivation: To understand how well information flows through shortest paths in complex networks and to develop methods for assessing the importance of specific edges for network connectivity and robustness.

Method: Uses adjacency matrices and their powers to construct path length matrices, defines global K-efficiency measures for paths of at most K edges, and introduces new connectivity concepts to evaluate edge significance.

Result: Develops mathematical framework for analyzing shortest path communication in networks, provides measures to quantify information flow efficiency, and creates tools to identify critical edges that impact network connectivity.

Conclusion: The proposed path length matrix analysis and novel connectivity measures provide valuable insights for network simplification, sensitivity assessment, and understanding information flow dynamics in complex systems.

Abstract: Complex systems of interacting components often can be modeled by a simple
graph $\mathcal{G}$ that consists of a set of $n$ nodes and a set of $m$ edges.
Such a graph can be represented by an adjacency matrix $A\in\R^{n\times n}$,
whose $(ij)$th entry is one if there is an edge pointing from node $i$ to node
$j$, and is zero otherwise. The matrix $A$ and its positive integer powers
reveal important properties of the graph and allow the construction of the path
length matrix $L$ for the graph. The $(ij)$th entry of $L$ is the length of the
shortest path from node $i$ to node $j$; if there is no path between these
nodes, then the value of the entry is set to $\infty$. We are interested in how
well information flows via shortest paths of the graph. This can be studied
with the aid of the path length matrix. The path length matrix allows the
definition of several measures of communication in the network defined by the
graph such as the global $K$-efficiency, which considers shortest paths that
are made up of at most $K$ edges for some $K<n$, as well as the number of such
shortest paths. Novel notions of connectivity introduced in this paper help us
understand the importance of specific edges for the flow of information through
the graph. This is of interest when seeking to simplify a network by removing
selected edges or trying to assess the sensitivity of the flow of information
to changes due to exterior causes such as a traffic stoppage on a road network.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [47] [Numerical Modeling of Galactic Cosmic Ray Modulation in the Heliosphere](https://arxiv.org/abs/2509.03326)
*D. A. Shestakov,V. V. Izmodenov*

Main category: astro-ph.HE

TL;DR: Numerical modeling of galactic cosmic rays penetration through the heliosphere using finite-difference and stochastic differential equation methods to solve the Parker transport equation.


<details>
  <summary>Details</summary>
Motivation: Galactic cosmic rays are high-energy charged particles from beyond our Solar System that interact strongly with the interplanetary magnetic field as they penetrate through the heliosphere, requiring accurate numerical modeling.

Method: Used finite-difference method (Crank-Nicolson scheme) and stochastic differential equations (SDE) method to solve the Parker transport equation, which includes convective terms, anisotropic diffusion, adiabatic cooling, and drifts with spatially and energy-dependent diffusion coefficients.

Result: Numerical methods were validated against analytical solutions and compared with data from previous works (Kota & Jokipii 1983, Burger 2012), with special attention to incorporating drift along the heliospheric current sheet.

Conclusion: The SDE method proved to be the most efficient and flexible approach for modeling galactic cosmic ray penetration through the heliosphere with anisotropic diffusion and Parker spiral magnetic field configuration.

Abstract: Numerical modeling of galactic cosmic rays (GCRs) penetration through the
heliosphere to the vicinity of the Sun is considered. Galactic cosmic rays are
charged particles with energies exceeding 10 MeV/nucl., originating from far
beyond the boundaries of our Solar System. As they penetrate through the
heliosphere - the region of space filled by the solar wind - they interact
strongly with the interplanetary magnetic field. In this paper, we present
numerical approaches to solving the so-called Parker transport equation for the
isotropic velocity distribution function of GCRs. This equation includes a
convective term, anisotropic diffusion, adiabatic cooling, and drifts.
Additionally, the diffusion coefficient is spatially and energy-dependent,
varying by several orders of magnitude. Our numerical approaches are based on
the finite-difference method (Crank-Nicolson scheme) and the stochastic
differential equations (SDE) method. The numerical methods were validated
against a known analytical solution under simplified conditions. For the
general problem formulation, which involves anisotropic diffusion and the
Parker spiral interplanetary magnetic field configuration, we used the most
efficient and flexible SDE method and compared the numerical results with the
data from the works of Kota & Jokipii (1983) and Burger (2012). Special
attention was devoted to incorporating drift along the heliospheric current
sheet in the model.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [48] [Scale-Adaptive Generative Flows for Multiscale Scientific Data](https://arxiv.org/abs/2509.02971)
*Yifan Chen,Eric Vanden-Eijnden*

Main category: stat.ML

TL;DR: Flow-based models struggle with scientific data having multiscale Fourier spectra. The paper addresses this by designing noise distributions and interpolation schedules that match the target data's spectral properties, improving numerical efficiency and sample fidelity.


<details>
  <summary>Details</summary>
Motivation: Flow-based generative models produce large errors in fine-scale features when modeling scientific data with multiscale Fourier spectra, limiting their effectiveness for scientific applications.

Method: The authors use stochastic interpolants framework with principled design of noise distributions and interpolation schedules. They match noise spectrum to target data distribution and develop scale-adaptive interpolation schedules for complex non-Gaussian distributions.

Result: Spectrum-matched noise improves numerical efficiency for Gaussian distributions, and scale-adaptive schedules address ill-conditioning for non-Gaussian cases. Experiments on Gaussian random fields and solutions to stochastic Allen-Cahn and Navier-Stokes equations show high-fidelity samples at lower computational cost.

Conclusion: Proper noise distribution design and interpolation scheduling are crucial for flow-based models to handle multiscale scientific data effectively, enabling more efficient and accurate generation of complex scientific data distributions.

Abstract: Flow-based generative models can face significant challenges when modeling
scientific data with multiscale Fourier spectra, often producing large errors
in fine-scale features. We address this problem within the framework of
stochastic interpolants, via principled design of noise distributions and
interpolation schedules. The key insight is that the noise should not be
smoother than the target data distribution -- measured by Fourier spectrum
decay rates -- to ensure bounded drift fields near the initial time. For
Gaussian and near-Gaussian distributions whose fine-scale structure is known,
we show that spectrum-matched noise improves numerical efficiency compared to
standard white-noise approaches. For complex non-Gaussian distributions, we
develop scale-adaptive interpolation schedules that address the numerical
ill-conditioning arising from rougher-than-data noise. Numerical experiments on
synthetic Gaussian random fields and solutions to the stochastic Allen-Cahn and
Navier-Stokes equations validate our approach and demonstrate its ability to
generate high-fidelity samples at lower computational cost than traditional
approaches.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [49] [The frustrated Ising model on the honeycomb lattice: Metastability and universality](https://arxiv.org/abs/2509.03414)
*Denis Gessert,Martin Weigel,Wolfhard Janke*

Main category: cond-mat.stat-mech

TL;DR: The study investigates the Ising model on a honeycomb lattice with competing ferromagnetic nearest-neighbor and antiferromagnetic next-nearest-neighbor interactions. Using advanced Monte Carlo simulations, the research shows that the phase transition remains second-order within the Ising universality class down to J2 = -0.23J1, contrary to previous suggestions of first-order transitions.


<details>
  <summary>Details</summary>
Motivation: To resolve conflicting reports about the nature of phase transitions in the Ising model with competing interactions on honeycomb lattices, particularly whether transitions become first-order at low J2 values or remain second-order.

Method: Population annealing Monte Carlo simulations with rejection-free and adaptive update techniques were employed to equilibrate systems with J2 as low as -0.23J1, followed by finite-size scaling analysis.

Result: The system undergoes second-order phase transitions within the Ising universality class at least down to J2 = -0.23J1, and likely for all J2 > -J1/4. The observed first-order-like behavior in previous studies was due to long-lived metastable states in partially equilibrated systems.

Conclusion: The phase transition in this Ising model remains second-order across the studied parameter range, with apparent first-order behavior being an artifact of insufficient equilibration caused by metastable states.

Abstract: We study the Ising model with competing ferromagnetic nearest- and
antiferromagnetic next-nearest-neighbor interactions of strengths $J_1 > 0$ and
$J_2 < 0$, respectively, on the honeycomb lattice. For $J_2 > - J_1 / 4$ it has
a ferromagnetic ground state, and previous work has shown that at least for
$J_2 \gtrsim -0.2 J_1$ the transition is in the Ising universality class. For
even lower $J_2$ some indicators pointing towards a first-order transition were
reported. By utilizing population annealing Monte Carlo simulations together
with a rejection-free and adaptive update, we can equilibrate systems with
$J_2$ as low as $-0.23 J_1$. By means of a finite-size scaling analysis we show
that the system undergoes a second-order phase transition within the Ising
universality class at least down to $J_2 =-0.23 J_1$ and, most likely, for all
$J_2 > - J_1 / 4$. As we show here, there exist very long-lived metastable
states in this system explaining the first-order like behavior seen in only
partially equilibrated systems.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [50] [On the Spectrum of Schrödinger Operators Interacting at Two Distinct Scales](https://arxiv.org/abs/2509.02587)
*Emmanuel Fleurantin,Jeremy L. Marzuola,Christopher K. R. T. Jones*

Main category: math-ph

TL;DR: Study of eigenvalue count for Schrodinger operators with two-scale potentials on radial functions in 3D, showing total eigenvalues equal sum from separate scale problems.


<details>
  <summary>Details</summary>
Motivation: To understand how eigenvalue spectra emerge from interactions between distinct spatial scales in quantum systems with radially symmetric potentials.

Method: Combines dynamical systems techniques with separation of scales argument to analyze Schrodinger operators with two-component potentials having different spatial scales.

Result: Total number of eigenvalues equals sum of positive eigenvalues from the separate reduced problems for each potential component (V0 and V1).

Conclusion: Provides novel framework for studying spectral properties when multiple spatial scales interact in differential operators, with applications to quantum physics.

Abstract: Schr\"{o}dinger operators of the form $\Delta - W$ on
$L^2_{\text{rad}}(\mathbb{R}^3)$, the space of radially symmetric square
integrable functions are relevant in a variety of physical contexts. The
potential $W$ is taken to be radially symmetric (i.e. $W(x) = W(|x|)$) and to
decompose into two components with distinct spatial scales: $W=W_\varepsilon=
V_0+V_{1,\varepsilon}$. The second component $V_{1,\varepsilon}(|x|) =
\varepsilon^2V_1(\varepsilon |x|)$ represents a scaled potential that becomes
increasingly delocalized as $\varepsilon \to 0$. We will assume that both
potentials $V_0(r), V_1(r)$ exhibit certain decay properties as $r \to \infty$.
We show how the eigenvalue count on the positive real axis is built out of the
spectra associated with the two reduced eigenvalue problems on their separate
scales. The result is that the total number of eigenvalues of $\Delta - W$ is
the sum of the number of positive eigenvalues of $\Delta - V_0$ and $\Delta -
V_1$. Our analysis combines dynamical systems techniques with a separation of
scales argument, providing a novel framework for studying spectral properties
of differential operators where multiple spatial scales interact.

</details>


### [51] [Magnetic Double-Wells: Absence of Tunneling](https://arxiv.org/abs/2509.02857)
*Charles L. Fefferman,Jacob Shapiro,Michael I. Weinstein*

Main category: math-ph

TL;DR: Magnetic double-well Hamiltonian with vanishing tunneling between wells


<details>
  <summary>Details</summary>
Motivation: To study quantum systems where tunneling between potential wells is eliminated, which could have implications for quantum coherence and state preservation

Method: Development of a magnetic double-well Hamiltonian model where the tunneling term is designed to vanish

Result: Successful creation of a Hamiltonian system where tunneling between the two wells is completely suppressed

Conclusion: This vanishing tunneling Hamiltonian provides a framework for studying quantum systems without inter-well transitions, potentially useful for quantum information applications

Abstract: We present a magnetic double-well Hamiltonian where the tunneling between the
two wells vanishes, as recently announced.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [52] [Solar Vortices as Conduits for Magnetoacoustic Waves: Multi-Layer Coupling and Their Role in Atmospheric Heating](https://arxiv.org/abs/2509.02895)
*Suzana S. A. Silva,Ioannis Dakanalis,Luiz A. C. A. Schiavo,Kostas Tziotziou,Istvan Ballai,Shahin Jafarzadeh,Tiago M. D. Pereira,Georgia Tsiropoula,Gary Verth,Iñaki Esnaola,James A. McLaughlin,Gert J. J. Botha,Viktor Fedun*

Main category: astro-ph.SR

TL;DR: First direct evidence that solar vortices act as waveguides carrying magnetoacoustic waves that heat the Sun's atmosphere, challenging previous assumptions about Alfven waves.


<details>
  <summary>Details</summary>
Motivation: To provide direct observational evidence of solar vortices' role in atmospheric heating, which had been theorized but never confirmed.

Method: Mapping vortex regions at multiple heights and analyzing the waves they contain to identify wave-heating signatures.

Result: Magnetoacoustic waves efficiently transfer energy, offset radiation losses, and dominate energy transport in the lower chromosphere.

Conclusion: Solar vortices primarily support magnetoacoustic waves rather than Alfven waves, redefining their role in plasma heating and wave-plasma interactions.

Abstract: The Sun's atmosphere hosts swirling plasma structures, known as solar
vortices, which have long been thought to channel wave energy into higher
layers. Until now, no direct observations have confirmed their role in the
heating of the atmosphere. Here, we present the first direct evidence that
solar vortices act as structured waveguides, carrying magnetoacoustic modes
(waves that behave like sound waves but travel through magnetized plasma) that
leave clear wave-heating signatures. By mapping vortex regions at multiple
heights and analysing the waves they contain, we show that magnetoacoustic
waves efficiently transfer energy, offset losses from radiation, and dominate
energy transport in the lower chromosphere. These results challenge the
long-standing assumption that vortices primarily support twisting disturbances
traveling along magnetic field lines (Alfven waves), revealing instead that
magnetoacoustic modes play the leading role in the lower atmosphere. This
redefines the role of vortices in magnetized plasmas and has broader
implications for wave-plasma interactions in regions of strong magnetic fields.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [53] [Local Well-Posedness for the Bartnik Stationary Extension Problem near Schwarzschild Spheres](https://arxiv.org/abs/2509.03478)
*Ahmed Ellithy*

Main category: gr-qc

TL;DR: The paper proves local well-posedness for the Bartnik stationary extension conjecture, showing existence and uniqueness of stationary vacuum spacetimes containing prescribed initial data with boundary conditions on metric, mean curvature, and extrinsic curvature components.


<details>
  <summary>Details</summary>
Motivation: To investigate the Bartnik stationary extension conjecture which arises from defining spacetime Bartnik mass for compact regions in general initial data sets satisfying the dominant energy condition.

Method: Uses a double geodesic gauge approach to reduce stationary vacuum Einstein equations to coupled elliptic and transport-type equations. Employs geodesic gauge for quotient metric and θ-geodesic gauge for the 1-form θ. Linearized equations decouple into static case for metric/potential and independent boundary value problem for θ.

Result: Established local well-posedness for Bartnik stationary metric extension problem for data close to coordinate spheres in Schwarzschild t=0 slices, including data with arbitrarily small mean curvature. Solvability proved in Bochner-measurable function spaces with uniform estimates for θ's vector spherical harmonic decomposition.

Conclusion: The framework successfully addresses the stationary extension problem by decoupling the equations and providing a systematic approach to handle both static and genuinely stationary components through appropriate gauges and function spaces.

Abstract: We investigate the Bartnik stationary extension conjecture, which arises from
the definition of the spacetime Bartnik mass for a compact region in a general
initial data set satisfying the dominant energy condition. This conjecture
posits the existence and uniqueness (up to isometry) of an asymptotically flat
stationary vacuum spacetime containing an initial data set $(M, \mathfrak{g},
\Pi)$ that realizes prescribed Bartnik boundary data on $\partial M$,
consisting of the induced metric, mean curvature, and appropriate components of
the spacetime extrinsic curvature $\Pi$.
  Building on the analytic framework developed in arXiv:2411.02801 for the
static case, we show that, in a double geodesic gauge, the stationary vacuum
Einstein equations reduce to a coupled system comprising elliptic and
transport-type equations, with the genuinely stationary contributions encoded
in an additional boundary value problem for a $1$-form $\theta$. Our approach
employs both a geodesic gauge for the quotient metric $g$ in the quotient
formalism and a $\theta$-geodesic gauge for the $1$-form $\theta$.
  We establish local well-posedness for the Bartnik stationary metric extension
problem for Bartnik data sufficiently close to that of any coordinate sphere in
a Schwarzschild ${t=0}$ slice, including data with arbitrarily small mean
curvature. A key feature of our framework is that the linearized equations
decouple: the equations for the metric and potential reduce to the previously
solved static case, while the boundary value problem for $\theta$ is treated
independently. We prove solvability of this boundary value problem in the
Bochner-measurable function spaces adapted to the coupled system developed in
arXiv:2411.02801, establishing uniform estimates for the vector spherical
harmonic decomposition of $\theta$.

</details>
