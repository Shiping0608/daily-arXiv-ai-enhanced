{"id": "2509.03630", "pdf": "https://arxiv.org/pdf/2509.03630", "abs": "https://arxiv.org/abs/2509.03630", "authors": ["Bing-Bing Xu", "Peter Wriggers"], "title": "Stabilization-free virtual element method for 2D third medium contact", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "comment": null, "summary": "The third medium contact has been proven to be an effective approach for\nsimulating contact problems involving large deformations. Unlike traditional\ncontact algorithms, the third medium contact introduces a third medium between\ntwo contacting bodies, thereby avoiding the complex treatment of the contact\nconstraints. The approach has been successfully applied in different\napplications in the framework of the finite element method (FEM). As a\ngeneralization of the finite element method, the virtual element method (VEM)\ncan handle arbitrary polygonal elements, providing greater flexibility for\nmodeling third medium contact. However, due to the introduction of the\nprojection operator, VEM requires additional stabilization terms to control the\nrank of the stiffness matrix. Moreover, the regularization term in the third\nmedium contact formulation requires a second-order numerical scheme, which\nfurther complicates the application of VEM to such problems. In this work, the\nstabilization-free virtual element method (SFVEM) is developed and applied to\nsolve the third medium contact problems. Different from the traditional VEM,\nSFVEM does not require additional stabilization terms, which simplifies the\nconstruction of the regularization term in third medium contact. Building upon\nthe traditional second-order FEM framework, we present the specific format of\nSFVEM for solving third medium contact, including the construction of\nhigh-order projection operator and the tangent stiffness matrix. Numerical\nexamples are provided to demonstrate the effectiveness and applicability of\nSFVEM in solving complex 2D third medium contact problems.", "AI": {"tldr": "SFVEM enables efficient simulation of third medium contact problems without stabilization terms, simplifying implementation while handling complex geometries.", "motivation": "Third medium contact avoids complex contact constraints but traditional VEM requires stabilization terms and second-order schemes, making implementation complicated.", "method": "Developed stabilization-free virtual element method (SFVEM) that eliminates need for additional stabilization terms, simplifies regularization term construction, and uses high-order projection operators.", "result": "SFVEM effectively solves complex 2D third medium contact problems, demonstrating applicability and effectiveness through numerical examples.", "conclusion": "SFVEM provides a simplified and effective approach for third medium contact simulations, overcoming limitations of traditional VEM while maintaining flexibility for arbitrary polygonal elements."}}
{"id": "2509.03757", "pdf": "https://arxiv.org/pdf/2509.03757", "abs": "https://arxiv.org/abs/2509.03757", "authors": ["Wei Cai", "Andrew Qing He"], "title": "ARDO: A Weak Formulation Deep Neural Network Method for Elliptic and Parabolic PDEs Based on Random Differences of Test Functions", "categories": ["math.NA", "cs.AI", "cs.NA", "35Q68, 65N99, 68T07, 76M99"], "comment": null, "summary": "We propose ARDO method for solving PDEs and PDE-related problems with deep\nlearning techniques. This method uses a weak adversarial formulation but\ntransfers the random difference operator onto the test function. The main\nadvantage of this framework is that it is fully derivative-free with respect to\nthe solution neural network. This framework is particularly suitable for\nFokker-Planck type second-order elliptic and parabolic PDEs.", "AI": {"tldr": "ARDO method: derivative-free deep learning approach for PDEs using weak adversarial formulation with random difference operators on test functions, particularly effective for Fokker-Planck type equations.", "motivation": "To develop a deep learning method for solving PDEs that eliminates the need for computing derivatives of the solution neural network, making it more efficient and suitable for complex PDE problems.", "method": "Uses weak adversarial formulation with random difference operators applied to test functions instead of the solution network, creating a fully derivative-free framework.", "result": "The method is particularly well-suited for second-order elliptic and parabolic PDEs of Fokker-Planck type, providing an efficient alternative to traditional derivative-based approaches.", "conclusion": "ARDO offers a novel derivative-free deep learning framework for PDE solving that shows promise for Fokker-Planck type equations and could potentially extend to other PDE classes."}}
{"id": "2509.03886", "pdf": "https://arxiv.org/pdf/2509.03886", "abs": "https://arxiv.org/abs/2509.03886", "authors": ["Ting Li", "Bin Wang", "Ruili Zhang"], "title": "Error and long-term analysis of two-step symmetric methods for relativistic charged-particle dynamics", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this work, we consider the error estimates and the long-time conservation\nor near-conservation of geometric structures, including energy, mass shell and\nphase-space volume, for four two-step symmetric methods applied to relativistic\ncharged-particle dynamics. We begin by introducing a two-step symmetric\nnumerical method based on a splitting scheme that exactly preserves the mass\nshell and the phase-space volume of the relativistic system. Building on this\nformulation, we develop three additional two-step symmetric methods with\nfurther modifications, for which the long-time near-conservation of energy and\nmass shell can be rigorously established through the backward error analysis.\nAll methods are shown to achieve second-order accuracy. The theoretical results\nare illustrated and complemented by numerical experiments.", "AI": {"tldr": "Two-step symmetric methods for relativistic charged-particle dynamics that preserve geometric structures like mass shell and phase-space volume, with rigorous error analysis showing second-order accuracy and long-time conservation properties.", "motivation": "To develop numerical methods that preserve important geometric structures (energy, mass shell, phase-space volume) in relativistic charged-particle dynamics, which is crucial for long-term simulation accuracy.", "method": "Four two-step symmetric numerical methods based on splitting schemes, with one method exactly preserving mass shell and phase-space volume, and three modified methods analyzed through backward error analysis.", "result": "All methods achieve second-order accuracy, with rigorous establishment of long-time near-conservation of energy and mass shell through backward error analysis, supported by numerical experiments.", "conclusion": "The developed two-step symmetric methods successfully preserve geometric structures in relativistic charged-particle dynamics, providing accurate long-term simulations with proven conservation properties."}}
{"id": "2509.03942", "pdf": "https://arxiv.org/pdf/2509.03942", "abs": "https://arxiv.org/abs/2509.03942", "authors": ["Thijs Steel", "Vince Maes", "Giovanni Samaey"], "title": "Fluid boundary conditions in kinetic-diffusion Monte Carlo", "categories": ["math.NA", "cs.NA", "65M75", "G.1.8"], "comment": null, "summary": "The Kinetic-Diffusion Monte Carlo (KDMC) method is a powerful tool for\nsimulating neutral particles in fusion reactors. It is a hybrid fluid-kinetic\nmethod that is significantly faster than pure kinetic methods at the cost of a\nsmall bias due to fluid approximations. Unfortunately, when simulating\nparticles close to a boundary, it needs to switch to a purely kinetic method,\nwhich is significantly slower. In this paper, we will extend the method so that\nit can accurately take boundary conditions into account without switching to a\npurely kinetic method. Experiments show that this extension can lead to a\nspeedup of up to 500 times compared to a KDMC method that switches to a purely\nkinetic method, while not sacrificing too much accuracy.", "AI": {"tldr": "Extension of KDMC method to handle boundary conditions without switching to slower pure kinetic methods, achieving 500x speedup with minimal accuracy loss.", "motivation": "The KDMC method is efficient for simulating neutral particles in fusion reactors but becomes slow near boundaries where it must switch to purely kinetic methods.", "method": "Extended the KDMC method to accurately incorporate boundary conditions while maintaining the hybrid fluid-kinetic approach, eliminating the need for switching to pure kinetic methods.", "result": "The extended method achieves up to 500 times speedup compared to KDMC with switching, while maintaining acceptable accuracy levels.", "conclusion": "The proposed extension significantly improves computational efficiency for boundary condition handling in KDMC simulations without substantial accuracy compromise."}}
{"id": "2509.03622", "pdf": "https://arxiv.org/pdf/2509.03622", "abs": "https://arxiv.org/abs/2509.03622", "authors": ["Chenkai Mao", "Jonathan A. Fan"], "title": "Accurate and scalable deep Maxwell solvers using multilevel iterative methods", "categories": ["physics.comp-ph", "cs.CE", "cs.LG", "physics.app-ph"], "comment": null, "summary": "Neural networks have promise as surrogate partial differential equation (PDE)\nsolvers, but it remains a challenge to use these concepts to solve problems\nwith high accuracy and scalability. In this work, we show that neural network\nsurrogates can combine with iterative algorithms to accurately solve PDE\nproblems featuring different scales, resolutions, and boundary conditions. We\ndevelop a subdomain neural operator model that supports arbitrary Robin-type\nboundary condition inputs, and we show that it can be utilized as a flexible\npreconditioner to iteratively solve subdomain problems with bounded accuracy.\nWe further show that our subdomain models can facilitate the construction of\nglobal coarse spaces to enable accelerated, large scale PDE problem solving\nbased on iterative multilevel domain decomposition. With two-dimensional\nMaxwell's equations as a model system, we train a single network to simulate\nlarge scale problems with different sizes, resolutions, wavelengths, and\ndielectric media distribution. We further demonstrate the utility of our\nplatform in performing the accurate inverse design of multi-wavelength\nnanophotonic devices. Our work presents a promising path to building accurate\nand scalable multi-physics surrogate solvers for large practical problems.", "AI": {"tldr": "Neural network surrogates combined with iterative algorithms can accurately solve PDE problems with different scales, resolutions, and boundary conditions, enabling large-scale multi-physics simulations and inverse design applications.", "motivation": "To address the challenge of using neural networks as surrogate PDE solvers with high accuracy and scalability for practical large-scale problems.", "method": "Developed a subdomain neural operator model supporting arbitrary Robin-type boundary conditions, used as flexible preconditioner in iterative algorithms, and constructed global coarse spaces for multilevel domain decomposition.", "result": "Successfully trained a single network to simulate large-scale 2D Maxwell's equations with varying sizes, resolutions, wavelengths, and dielectric media distributions, and demonstrated accurate inverse design of multi-wavelength nanophotonic devices.", "conclusion": "The approach presents a promising path for building accurate and scalable multi-physics surrogate solvers for large practical problems."}}
{"id": "2509.03637", "pdf": "https://arxiv.org/pdf/2509.03637", "abs": "https://arxiv.org/abs/2509.03637", "authors": ["Gong Chen", "Abdon Moutinho"], "title": "Asymptotic Stability of multi-solitons for $1$d Supercritical NLS", "categories": ["math.AP", "math-ph", "math.MP", "35B40, 35B35"], "comment": "First version, 75 pages. Keywords: Scattering, Asymptotic Stability\n  on $H^{1}$ norm, 1d supercritical NLS, multi-solitons, non-integrable, H1\n  norm, Center-stable Manifold; Comments are welcome", "summary": "Consider the one-dimensional $L^2$ supercritical nonlinear Schr\\\"odinger\nequation \\begin{equation} i\\partial_{t}\\psi+\\partial^{2}_{x}\\psi+\\vert\n\\psi\\vert^{2k}\\psi=0 \\text{, $k>2$}. \\end{equation} It is well known that\nsolitary waves for this equation are unstable. In the pioneering work of\nKrieger and Schlag \\cite{KriegerSchlag}, the asymptotic stability of a solitary\nwave was established on a codimension-one center-stable manifold. In the\npresent paper, using linear estimates developed for one-dimensional matrix\ncharge transfer models in our previous work, \\cite{dispanalysis1}, we prove\nasymptotic stability of multi-solitons on a finite-codimension manifold for\n$k>\\frac{11}{4}$, provided that the soliton velocities are sufficiently\nseparated.", "AI": {"tldr": "Asymptotic stability of multi-solitons for 1D supercritical NLS equation with k>11/4 on finite-codimension manifold when soliton velocities are sufficiently separated.", "motivation": "Solitary waves for the 1D L^2 supercritical nonlinear Schr\u00f6dinger equation are known to be unstable. Previous work established asymptotic stability on a codimension-one manifold for single solitary waves, but multi-soliton stability remained an open problem.", "method": "Using linear estimates developed for one-dimensional matrix charge transfer models from previous work, the authors prove asymptotic stability of multi-soliton configurations.", "result": "Asymptotic stability is established for multi-solitons on a finite-codimension manifold when k > 11/4 and the soliton velocities are sufficiently separated.", "conclusion": "The paper extends stability results from single solitary waves to multi-soliton configurations in the supercritical regime, providing conditions under which multi-solitons remain asymptotically stable."}}
{"id": "2509.03520", "pdf": "https://arxiv.org/pdf/2509.03520", "abs": "https://arxiv.org/abs/2509.03520", "authors": ["Ting Xiao", "Qiaolin He"], "title": "Thermodynamically consistent modelling and simulation of two-fluid magnetohydrodynamic equations", "categories": ["physics.plasm-ph", "cs.NA", "math.NA"], "comment": null, "summary": "In this paper, we proposes a thermodynamically consistent two-fluid\nmagnetohydrodynamic model based on the Helmholtz free energy framework, which\nstrictly satisfies both the principles of energy conservation and entropy\nincrease in the two-fluid model. By constructing the convexe-concave\ncharacteristics of the free energy density (convexity with respect to plasma\nnumber density and concavity with respect to temperature), the model\nself-consistently derives key thermodynamic quantities such as chemical\npotential, entropy density, and internal energy. Based on the proposed modeling\nframework and the convex-concave properties of the Helmholtz free energy\ndensity, we develop a temporally discrete numerical scheme with thermodynamic\nconsistency. We rigorously prove that the proposed method satisfies the first\nlaw of thermodynamics (global energy conservation) and the second law\n(non-decreasing total entropy). Additionally, we provide spatiotemporal error\nestimates for the 2D degenerate system used in practical computations.\nNumerical experiments validate the effectiveness of the proposed method in\ncapturing key plasma phenomena.", "AI": {"tldr": "A thermodynamically consistent two-fluid magnetohydrodynamic model based on Helmholtz free energy framework that ensures energy conservation and entropy increase.", "motivation": "To develop a two-fluid MHD model that strictly satisfies both energy conservation and entropy increase principles, addressing thermodynamic consistency in plasma modeling.", "method": "Constructed convexe-concave characteristics of free energy density (convex in plasma number density, concave in temperature) to derive thermodynamic quantities. Developed a temporally discrete numerical scheme with thermodynamic consistency.", "result": "The proposed method satisfies both first law (global energy conservation) and second law (non-decreasing total entropy) of thermodynamics. Numerical experiments validate effectiveness in capturing key plasma phenomena.", "conclusion": "The Helmholtz free energy framework provides a thermodynamically consistent approach for two-fluid MHD modeling with proven energy conservation and entropy increase properties, supported by numerical validation."}}
{"id": "2509.04113", "pdf": "https://arxiv.org/pdf/2509.04113", "abs": "https://arxiv.org/abs/2509.04113", "authors": ["Sudheer Mishra", "E Natarajan"], "title": "A unified stabilized virtual element method for the generalized Oseen equation: stability and robustness", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this thesis, we investigate a novel local projection based stabilized\nconforming virtual element method for the generalized Oseen problem using\nequal-order element pairs on general polygonal meshes. To ensure the stability,\nparticularly in the presence of convection-dominated regimes and the\nutilization of equal-order element pairs, we introduce local projections based\nstabilization techniques. We demonstrate the discrete inf-sup condition in the\nenergy norm. Moreover, the stability of the proposed method also guarantees the\nstability properties for the Brinkman equation and the Stokes equation without\nintroducing any additional conditions. Furthermore, we derive an optimal error\nestimates in the energy norm that underline the uniform convergence in the\nenergy norm for the generalized Oseen problem with small diffusion. In\naddition, the error estimates remain valid and uniform for the Brinkman\nequation and the Stokes equation. Additionally, the convergence study shows\nthat the proposed method is quasi-robust with respect to parameters. The\nproposed method offers several advantages, including simplicity in\nconstruction, easier implementation compared to residual-based stabilization\ntechniques, and avoiding coupling between element pairs. We validate our\ntheoretical findings through a series of numerical experiments, including\ndiffusion-dominated and convection-dominated regimes.", "AI": {"tldr": "A novel local projection stabilized conforming virtual element method for generalized Oseen problem using equal-order element pairs on polygonal meshes, with proven stability and optimal error estimates.", "motivation": "To develop a stable numerical method for generalized Oseen problems that can handle convection-dominated regimes and equal-order element pairs on general polygonal meshes, addressing stability issues in such challenging scenarios.", "method": "Local projection based stabilization techniques applied to conforming virtual element method using equal-order element pairs on polygonal meshes, with demonstration of discrete inf-sup condition in energy norm.", "result": "Proven stability properties for generalized Oseen, Brinkman, and Stokes equations; optimal error estimates with uniform convergence for small diffusion; quasi-robust convergence with respect to parameters; simpler implementation than residual-based methods.", "conclusion": "The proposed method provides an effective, stable, and simple approach for solving generalized Oseen problems and related equations on polygonal meshes, with advantages in implementation and robustness across different parameter regimes."}}
{"id": "2509.03933", "pdf": "https://arxiv.org/pdf/2509.03933", "abs": "https://arxiv.org/abs/2509.03933", "authors": ["Seungchan Kim", "Jihoo Kim", "Sanghyun Ha", "Donghyun You"], "title": "A Highly Scalable TDMA for GPUs and Its Application to Flow Solver Optimization", "categories": ["physics.comp-ph"], "comment": "36pages, 22 figures, and 4 tables", "summary": "A tridiagonal matrix algorithm (TDMA), Pipelined-TDMA, is developed for\nmulti-GPU systems to resolve the scalability bottlenecks caused by the\nsequential structure of conventional divide-and-conquer TDMA. The proposed\nmethod pipelines multiple tridiagonal systems, overlapping communication with\ncomputation and executing GPU kernels concurrently to hide non-scalable stages\nbehind scalable compute stages. To maximize performance, the batch size is\noptimized to strike a balance between GPU occupancy and pipeline efficiency:\nlarger batches improve throughput for solving tridiagonal systems, while\nexcessively large batches reduce pipeline utilization. Performance evaluations\non up to 64 NVIDIA A100 GPUs using a one-dimensional (1D) slab-type domain\ndecomposition confirm that, except for the terminal phase of the pipeline, the\nproposed method successfully hides most of the non-scalable execution\ntime-specifically inter-GPU communication and low-occupancy computation. The\nsolver achieves ideal weak scaling up to 64 GPUs with one billion grid cells\nper GPU and reaches 74.7 percent of ideal performance in strong scaling tests\nfor a 4-billion-cell problem, relative to a 4-GPU baseline. The optimized TDMA\nis integrated into an ADI-based fractional-step method to remove the\nscalability bottleneck in the Poisson solver of the flow solver (Ha et al.,\n2021). In a 9-billion-cell simulation on 64 GPUs, the TDMA component in the\nPoisson solver is accelerated by 4.37x, contributing to a 1.31x overall speedup\nof the complete flow solver.", "AI": {"tldr": "Pipelined-TDMA algorithm for multi-GPU systems that pipelines multiple tridiagonal systems to hide communication latency and improve scalability, achieving near-ideal weak scaling on 64 GPUs and significant speedups in flow simulations.", "motivation": "To overcome scalability bottlenecks in conventional divide-and-conquer TDMA algorithms caused by their sequential structure and communication overhead in multi-GPU systems.", "method": "Developed a pipelined TDMA that overlaps communication with computation, executes GPU kernels concurrently, and optimizes batch size to balance GPU occupancy with pipeline efficiency for multiple tridiagonal systems.", "result": "Achieved ideal weak scaling up to 64 GPUs with 1B grid cells per GPU, 74.7% of ideal strong scaling performance for 4B-cell problems, and 4.37x acceleration in Poisson solver leading to 1.31x overall flow solver speedup on 64 GPUs.", "conclusion": "The pipelined approach successfully hides non-scalable execution time (communication and low-occupancy computation) and effectively removes scalability bottlenecks in TDMA-based solvers for large-scale multi-GPU systems."}}
{"id": "2509.03745", "pdf": "https://arxiv.org/pdf/2509.03745", "abs": "https://arxiv.org/abs/2509.03745", "authors": ["Fernando de \u00c1vila Silva", "Matteo Bonino", "Sandro Coriasco"], "title": "Global hypoellipticity for a class of time-periodic operators on asymptotically Euclidean manifolds", "categories": ["math.AP", "46F05, 35B10, 35B65, 35H10, 35S05"], "comment": "27 pages. This is the first version. Some changes might be performed\n  in the next versions", "summary": "We introduce time-periodic Gevrey-Sobolev-Kato spaces on asymptotically\nEuclidean manifolds and study their characterisation throughout Fourier\nexpansions associated with suitable elliptic operators. As an application, we\nstudy the global hypoellipticity problem for a naturally associated class of\ntime-periodic evolution equations.", "AI": {"tldr": "Introduction of time-periodic Gevrey-Sobolev-Kato spaces on asymptotically Euclidean manifolds with Fourier expansion characterization and application to global hypoellipticity of time-periodic evolution equations.", "motivation": "To develop specialized function spaces for studying time-periodic phenomena on asymptotically Euclidean manifolds and apply them to understand global hypoellipticity properties of evolution equations.", "method": "Define time-periodic Gevrey-Sobolev-Kato spaces, characterize them through Fourier expansions associated with suitable elliptic operators, and apply these spaces to analyze global hypoellipticity.", "result": "Established characterization of these function spaces via Fourier expansions and obtained results on global hypoellipticity for a class of time-periodic evolution equations.", "conclusion": "The introduced function spaces provide a useful framework for studying time-periodic problems on asymptotically Euclidean manifolds, with applications to understanding hypoellipticity properties of evolution equations."}}
{"id": "2509.03641", "pdf": "https://arxiv.org/pdf/2509.03641", "abs": "https://arxiv.org/abs/2509.03641", "authors": ["Michael Updike", "Joshua Burby"], "title": "Is There an Exact Magnetic-Moment for Charged Particle Motion in a Homogeneous, Time-Dependent Magnetic Field?", "categories": ["physics.plasm-ph", "math-ph", "math.MP"], "comment": "25 pages, 5 figures", "summary": "The nonperturbative guiding-center model provides an exact alternative to\nfull-orbit simulations of charged particle dynamics in situations where\ntraditional guiding-center theory may fail. We demonstrate that the charged\nparticle motion in a homogeneous, time-varying magnetic field is a solvable\nexample of the nonperturbative guiding-center model. This entails showing that\nthe exact magnetic moment of Qin and Davidson can be constructed to be\nasymptotic to the adiabatic invariant series of Kruskal. In contrast to the\nperturbative invariant, the exact invariant contains information about\nparametric resonances. These resonances destroy the conservation of the usual\nmagnetic moment over very long times. This refutes some previous claims about\nthe all-time invariance of the magnetic moment.", "AI": {"tldr": "Nonperturbative guiding-center model provides exact alternative to full-orbit simulations, showing magnetic moment contains parametric resonances that destroy long-term conservation, refuting previous claims about all-time invariance.", "motivation": "To provide an exact alternative to traditional guiding-center theory and full-orbit simulations for charged particle dynamics, particularly in cases where traditional approaches may fail.", "method": "Using the nonperturbative guiding-center model to analyze charged particle motion in homogeneous, time-varying magnetic fields, constructing exact magnetic moment invariant and comparing with adiabatic invariant series.", "result": "Demonstrated that exact magnetic moment contains information about parametric resonances that destroy conservation over very long times, showing contrast with perturbative invariant.", "conclusion": "The nonperturbative model reveals parametric resonances that undermine long-term magnetic moment conservation, refuting previous claims about its all-time invariance and providing more accurate modeling approach."}}
{"id": "2509.04217", "pdf": "https://arxiv.org/pdf/2509.04217", "abs": "https://arxiv.org/abs/2509.04217", "authors": ["Th\u00e9ophile Chaumont-Frelet", "Heiko Gimperlein", "Ignacio Labarca-Figueroa", "J\u00f6rg Nick"], "title": "A posteriori error estimates and space-adaptive mesh refinements for time-dependent scattering problems", "categories": ["math.NA", "cs.NA"], "comment": "20 pages, 9 figures", "summary": "This work studies a posteriori error estimates and their use for\ntime-dependent acoustic scattering problems, formulated as a time-dependent\nboundary integral equation based on a single-layer ansatz. The integral\nequation is discretized by the convolution quadrature method in time and by\nboundary elements in space. We prove the reliability of an error estimator of\nresidual type and study the resulting space-adaptive mesh refinements.\nMoreover, we present a simple modification of the convolution quadrature method\nbased on temporal shifts, which recovers, for the boundary densities, the full\nclassical temporal convergence order $2m-1$ of the temporal convolution\nquadrature method based on the $m$-stage convolution quadrature\nsemi-discretization. We numerically observe that the adaptive scheme yields\nasymptotically optimal meshes for an acoustic scattering problem in two\ndimensions.", "AI": {"tldr": "A posteriori error estimates for time-dependent acoustic scattering problems using boundary integral equations, with adaptive mesh refinement and a modified convolution quadrature method that improves temporal convergence.", "motivation": "To develop reliable error estimators and adaptive mesh refinement strategies for time-dependent acoustic scattering problems, addressing the need for efficient and accurate numerical methods in this domain.", "method": "Discretization using convolution quadrature method in time and boundary elements in space, with residual-type error estimator and space-adaptive mesh refinements. A modified convolution quadrature method with temporal shifts is introduced to improve convergence.", "result": "Proved reliability of the error estimator and demonstrated that adaptive scheme yields asymptotically optimal meshes for 2D acoustic scattering problems. The modified method recovers full classical temporal convergence order.", "conclusion": "The proposed error estimation and adaptive refinement approach provides effective numerical solutions for time-dependent acoustic scattering, with the temporal shift modification significantly improving convergence rates."}}
{"id": "2509.04291", "pdf": "https://arxiv.org/pdf/2509.04291", "abs": "https://arxiv.org/abs/2509.04291", "authors": ["Kai Zhu", "Enrico Trizio", "Jintu Zhang", "Renling Hu", "Linlong Jiang", "Tingjun Hou", "Luigi Bonati"], "title": "Enhanced Sampling in the Age of Machine Learning: Algorithms and Applications", "categories": ["physics.comp-ph"], "comment": null, "summary": "Molecular dynamics simulations hold great promise for providing insight into\nthe microscopic behavior of complex molecular systems. However, their\neffectiveness is often constrained by long timescales associated with rare\nevents. Enhanced sampling methods have been developed to address these\nchallenges, and recent years have seen a growing integration with machine\nlearning techniques. This review provides a comprehensive overview of how they\nare reshaping the field, with a particular focus on the data-driven\nconstruction of collective variables. Furthermore, these techniques have also\nimproved biasing schemes and unlocked novel strategies via reinforcement\nlearning and generative approaches. In addition to methodological advances, we\nhighlight applications spanning different areas such as biomolecular processes,\nligand binding, catalytic reactions, and phase transitions. We conclude by\noutlining future directions aimed at enabling more automated strategies for\nrare-event sampling.", "AI": {"tldr": "Review of machine learning-enhanced molecular dynamics methods for rare-event sampling, focusing on data-driven collective variables, improved biasing schemes, and applications across biomolecular processes and chemical reactions.", "motivation": "Molecular dynamics simulations are limited by rare events with long timescales. Enhanced sampling methods integrated with machine learning can overcome these limitations and provide better insights into complex molecular systems.", "method": "Comprehensive review of machine learning techniques integrated with enhanced sampling methods, including data-driven construction of collective variables, improved biasing schemes, reinforcement learning, and generative approaches.", "result": "The integration of machine learning has significantly advanced enhanced sampling methods, enabling better rare-event sampling and applications across diverse areas including biomolecular processes, ligand binding, catalytic reactions, and phase transitions.", "conclusion": "Machine learning is reshaping molecular dynamics by enabling more automated strategies for rare-event sampling, with future directions focused on developing increasingly automated approaches for complex molecular systems."}}
{"id": "2509.03760", "pdf": "https://arxiv.org/pdf/2509.03760", "abs": "https://arxiv.org/abs/2509.03760", "authors": ["Rodrigo Lecaros", "Ariel A. P\u00e9rez", "Manuel F. Prado"], "title": "Inverse problem for semidiscrete stochastic parabolic operators in arbitrary dimensions", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we study two types of inverse problems for space semidiscrete\nstochastic parabolic equations in arbitrary dimensions. The first problem\nconcerns a semidiscrete inverse source problem, which involves determining the\nrandom source term of the white noise in the stochastic parabolic equation\nusing observation data of the solution at the terminal time and the trace of\nthe discrete spatial derivative of the solution on a subdomain at the boundary\nof the space. The second problem addresses a semidiscrete Cauchy inverse\nproblem, which involves determining the solution of the stochastic parabolic\nequation in a subdomain of space-time, from the data of the solution and the\ntrace of the discrete spatial derivative on a subdomain of the boundary of\nspace and time. To address these problems, we establish two Carleman estimates\nfor a semidiscrete stochastic parabolic operator in arbitrary dimensions: one\nfor the homogeneous boundary condition and the other for the nonhomogeneous\nboundary condition. Applying these Carleman estimates, we obtain Lipschitz and\nH\\\"older stability for the first and second inverse problems, respectively.", "AI": {"tldr": "Analysis of inverse problems for semidiscrete stochastic parabolic equations using Carleman estimates to establish stability for source identification and Cauchy problems.", "motivation": "To develop mathematical tools for solving two types of inverse problems in stochastic parabolic equations - identifying random source terms and reconstructing solutions from boundary data, which have applications in various fields including physics and engineering.", "method": "Established two Carleman estimates for semidiscrete stochastic parabolic operators (homogeneous and nonhomogeneous boundary conditions) and applied them to prove stability results for the inverse problems.", "result": "Obtained Lipschitz stability for the semidiscrete inverse source problem and H\u00f6lder stability for the semidiscrete Cauchy inverse problem.", "conclusion": "The developed Carleman estimates provide effective tools for analyzing stability in inverse problems for semidiscrete stochastic parabolic equations, with different stability results depending on the problem type."}}
{"id": "2509.03664", "pdf": "https://arxiv.org/pdf/2509.03664", "abs": "https://arxiv.org/abs/2509.03664", "authors": ["Joseph G. Theis", "Gregory R. Werner", "Thomas G. Jenkins", "Daniel Main", "John R. Cary"], "title": "Pressure dependence of magnetron sputtering: 2D-RZ particle-in-cell and 1D fluid modeling", "categories": ["physics.plasm-ph"], "comment": null, "summary": "We reproduce the consistently-seen experimental voltage versus pressure (V-P)\ndependence of DC magnetron sputtering (DCMS) with 2D-RZ particle-in-cell (PIC)\nsimulation. Informed by PIC simulation, we develop a steady-state, 1D-axial\nfluid model of the sheath and presheath that also reproduces this V-P\ndependence. The V-P dependence is the relationship between the steady-state\nvoltage needed to maintain a constant discharge current and the neutral gas\npressure. V-P dependence is fundamental to device performance, but has not\npreviously been reproduced with simulation or satisfactorily explained. In this\nwork, we compare the V-P curve of our simulated device and fluid model with\npast experiments and then present a theoretical explanation for this V-P\ndependence. We find that the decrease in voltage with increasing pressure is\nnot due to electron recapture at the cathode. Rather, the constant current\ndictates a constant global ionization rate, so the voltage decrease compensates\nfor the increase in neutral gas density by lowering the energy of the plasma\nelectrons, which decreases their ionization probability. The PIC simulations\nalso reveal that the presheath and bulk plasma are unaffected by the electron\nreflection coefficient at the cathode; the only effect of increasing reflection\nis a reduction in the sheath voltage and width. In addition to the potential\nstructure, we explore how pressure affects the plasma density, particle drifts,\nand particle energy distributions.", "AI": {"tldr": "Reproduction of DC magnetron sputtering voltage-pressure dependence using 2D-RZ PIC simulation and 1D fluid model, revealing voltage decrease compensates for higher neutral density by lowering electron energy rather than electron recapture.", "motivation": "The voltage-pressure (V-P) dependence in DC magnetron sputtering is fundamental to device performance but has not been satisfactorily explained or reproduced with simulation previously.", "method": "Used 2D-RZ particle-in-cell (PIC) simulation to reproduce experimental V-P dependence, then developed a steady-state 1D-axial fluid model of sheath and presheath informed by PIC results.", "result": "Found voltage decrease with increasing pressure is due to compensation for higher neutral density by lowering plasma electron energy (reducing ionization probability), not electron recapture. Also revealed presheath and bulk plasma are unaffected by electron reflection at cathode.", "conclusion": "Successfully reproduced and explained the fundamental V-P dependence in DCMS through combined PIC simulation and fluid modeling, providing new theoretical understanding of pressure effects on plasma characteristics."}}
{"id": "2509.04251", "pdf": "https://arxiv.org/pdf/2509.04251", "abs": "https://arxiv.org/abs/2509.04251", "authors": ["Lei Dai", "Yingsong Jiang", "Xiaojie Wang"], "title": "An explicit splitting SAV scheme for the kinetic Langevin dynamics", "categories": ["math.NA", "cs.NA", "60H35, 65C30"], "comment": null, "summary": "The kinetic Langevin dynamics finds diverse applications in various\ndisciplines such as molecular dynamics and Hamiltonian Monte Carlo sampling. In\nthis paper, a novel splitting scalar auxiliary variable (SSAV) scheme is\nproposed for the dynamics, where the gradient of the potential $U$ is possibly\nnon-globally Lipschitz continuous with superlinear growth. As an explicit\nscheme, the SSAV method is efficient, robust and is able to reproduce the\nenergy structure of the original dynamics. By an energy argument, the SSAV\nscheme is proved to possess an exponential integrability property, which is\ncrucial to establishing the order-one strong convergence without the global\nmonotonicity condition. Moreover, moments of the numerical approximations are\nshown to have polynomial growth with respect to the time length. This helps us\nto obtain weak error estimates of order one, with error constants polynomially\n(not exponentially) depending on the time length. Despite the obtained\npolynomial growth, the explicit scheme is shown to be computationally effective\nfor the approximation of the invariant distribution of the dynamics with\nexponential ergodicity. Numerical experiments are presented to confirm the\ntheoretical findings and to show the superiority of the algorithm in sampling.", "AI": {"tldr": "A novel explicit splitting scalar auxiliary variable (SSAV) scheme for kinetic Langevin dynamics that handles non-globally Lipschitz continuous gradients with superlinear growth, maintaining energy structure and achieving order-one strong convergence.", "motivation": "Kinetic Langevin dynamics has wide applications in molecular dynamics and Hamiltonian Monte Carlo sampling, but existing methods struggle with non-globally Lipschitz continuous gradients with superlinear growth.", "method": "Proposed a splitting scalar auxiliary variable (SSAV) scheme that is explicit, efficient, and preserves the energy structure of the original dynamics. Uses energy arguments to prove exponential integrability and polynomial growth properties.", "result": "The SSAV scheme achieves order-one strong convergence without requiring global monotonicity conditions. It shows polynomial growth of moments with respect to time length and provides weak error estimates with polynomial (not exponential) dependence on time.", "conclusion": "The explicit SSAV scheme is computationally effective for approximating invariant distributions of exponentially ergodic dynamics and demonstrates superiority in sampling applications through numerical experiments."}}
{"id": "2509.03539", "pdf": "https://arxiv.org/pdf/2509.03539", "abs": "https://arxiv.org/abs/2509.03539", "authors": ["Chatipat Lorpaiboon", "Jonathan Weare", "Aaron R. Dinner"], "title": "An exact multiple-time-step variational formulation for the committor and the transition rate", "categories": ["cond-mat.stat-mech", "cs.LG", "physics.comp-ph", "physics.data-an"], "comment": "42 pages, 3 figures", "summary": "For a transition between two stable states, the committor is the probability\nthat the dynamics leads to one stable state before the other. It can be\nestimated from trajectory data by minimizing an expression for the transition\nrate that depends on a lag time. We show that an existing such expression is\nminimized by the exact committor only when the lag time is a single time step,\nresulting in a biased estimate in practical applications. We introduce an\nalternative expression that is minimized by the exact committor at any lag\ntime. Numerical tests on benchmark systems demonstrate that our committor and\nresulting transition rate estimates are much less sensitive to the choice of\nlag time. We derive an additional expression for the transition rate, relate\nthe transition rate expression to a variational approach for kinetic statistics\nbased on the mean-squared residual, and discuss further numerical\nconsiderations with the aid of a decomposition of the error into dynamic modes.", "AI": {"tldr": "New committor estimation method that eliminates lag time bias in transition rate calculations between stable states.", "motivation": "Existing committor estimation methods from trajectory data are biased when using practical lag times, as they only yield exact results at single time steps.", "method": "Developed an alternative expression for transition rate that is minimized by the exact committor at any lag time, with numerical tests on benchmark systems and error decomposition analysis.", "result": "The new committor and transition rate estimates show significantly reduced sensitivity to lag time choice compared to existing methods.", "conclusion": "The proposed method provides more robust committor estimation and transition rate calculation, with connections to variational approaches and improved numerical stability through error mode decomposition."}}
{"id": "2509.03779", "pdf": "https://arxiv.org/pdf/2509.03779", "abs": "https://arxiv.org/abs/2509.03779", "authors": ["Kuang Huang", "Zhiyuan Li", "Zhidong Zhang", "Zhi Zhou"], "title": "H\u00f6lder Stable Recovery of the Source in Space-Time Fractional Wave Equations", "categories": ["math.AP"], "comment": null, "summary": "We study the recovery of a spatially dependent source in a one-dimensional\nspace-time fractional wave equation using boundary measurement data collected\nat a single endpoint. The main challenge arises from the fact that the\neigenfunctions of the Dirichlet eigenvalue problem do not form an orthogonal\nsystem, due to the presence of a fractional derivative in space. To address\nthis difficulty, we introduce a bi-orthogonal basis for the Mittag-Leffler\nfunctions and use it to establish uniqueness and H\\\"older-type stability\nresults, provided the measurement time is sufficiently large. A Tikhonov\nregularization method is then employed to numerically solve the inverse source\nproblem. Several numerical examples are presented to demonstrate the accuracy\nand efficiency of the proposed method and to validate our theoretical findings.", "AI": {"tldr": "Recovery of spatially dependent source in 1D space-time fractional wave equation using single endpoint boundary measurements, with bi-orthogonal basis approach for non-orthogonal eigenfunctions and Tikhonov regularization for numerical solution.", "motivation": "The main challenge is that eigenfunctions of the Dirichlet eigenvalue problem do not form an orthogonal system due to the fractional derivative in space, making source recovery difficult with boundary measurements.", "method": "Introduce a bi-orthogonal basis for Mittag-Leffler functions to address non-orthogonality, establish uniqueness and H\u00f6lder-type stability results, and employ Tikhonov regularization for numerical solution of the inverse source problem.", "result": "Successfully established uniqueness and stability results for sufficiently large measurement times, and demonstrated accuracy and efficiency of the proposed method through numerical examples.", "conclusion": "The bi-orthogonal basis approach effectively handles the non-orthogonal eigenfunction system in fractional wave equations, enabling successful source recovery with boundary measurements and providing validated theoretical and numerical results."}}
{"id": "2509.03880", "pdf": "https://arxiv.org/pdf/2509.03880", "abs": "https://arxiv.org/abs/2509.03880", "authors": ["Pisin Chen", "Yung-Kun Liu"], "title": "Plasma wakefield: from accelerators to black holes", "categories": ["physics.plasm-ph", "gr-qc", "hep-ex"], "comment": "71 pages, 14 figures. This review article is based on the lecture\n  delivered at the 2024 Chandrasekhar Prize ceremony in Malacca, Malaysia", "summary": "Commemorating the 2024 S. Chandrasekhar Prize, this review provides a\nretrospective on the genesis and evolution of plasma wakefield acceleration. It\ntraces the journey from prehistory and the invention of the Plasma Wakefield\nAccelerator (PWFA), the establishment of its theoretical cornerstones, to its\nprofound reverberations across fundamental physics, including astrophysics and\nanalog gravity. The narrative emphasizes conceptual evolution, key theoretical\nbreakthroughs, and future outlook, culminating in a vision for hybrid schemes\nand next-generation colliders. In addition to application to particle\naccelerators and high energy collider physics, it is found that plasma\nwakefield, with its ultra-intense acceleration, can also be applied to\ninvestigate gravity effects in the laboratory based on Einstein's equivalence\nprinciple. A specific example is accelerating flying relativistic plasma\nmirrors to investigate the celebrated black hole Hawking evaporation and the\nassociated information loss paradox. We describe an ongoing experiment, AnaBHEL\n(Analog Black Hole Evaporation via Lasers), which aims at shedding some lights\non the black hole information loss paradox.", "AI": {"tldr": "Review of plasma wakefield acceleration's evolution from invention to applications in particle physics, astrophysics, and analog gravity experiments like AnaBHEL for studying black hole information paradox.", "motivation": "To commemorate the 2024 S. Chandrasekhar Prize and provide a comprehensive retrospective on plasma wakefield acceleration's development, theoretical foundations, and broad applications across fundamental physics.", "method": "Historical review tracing conceptual evolution and theoretical breakthroughs in plasma wakefield acceleration, with focus on hybrid schemes and experimental applications like the AnaBHEL project using relativistic plasma mirrors.", "result": "Plasma wakefield acceleration demonstrates profound applications beyond particle accelerators, enabling laboratory investigation of gravity effects via Einstein's equivalence principle and study of black hole Hawking evaporation.", "conclusion": "Plasma wakefield acceleration has evolved into a transformative technology with far-reaching implications for next-generation colliders and fundamental physics research, particularly in analog gravity experiments addressing black hole information paradox."}}
{"id": "2509.04256", "pdf": "https://arxiv.org/pdf/2509.04256", "abs": "https://arxiv.org/abs/2509.04256", "authors": ["Ke Chen", "Meenakshi Krishnan", "Haizhao Yang"], "title": "Error analysis for learning the time-stepping operator of evolutionary PDEs", "categories": ["math.NA", "cs.NA", "65M12, 65M15, 68T01"], "comment": null, "summary": "Deep neural networks (DNNs) have recently emerged as effective tools for\napproximating solution operators of partial differential equations (PDEs)\nincluding evolutionary problems. Classical numerical solvers for such PDEs\noften face challenges of balancing stability constraints and the high\ncomputational cost of iterative solvers. In contrast, DNNs offer a data-driven\nalternative through direct learning of time-stepping operators to achieve this\nbalancing goal. In this work, we provide a rigorous theoretical framework for\nanalyzing the approximation of these operators using feedforward neural\nnetworks (FNNs). We derive explicit error estimates that characterize the\ndependence of the approximation error on the network architecture -- namely its\nwidth and depth -- as well as the number of training samples. Furthermore, we\nestablish Lipschitz continuity properties of time-stepping operators associated\nwith classical numerical schemes and identify low-complexity structures\ninherent in these operators for several classes of PDEs, including\nreaction-diffusion equations, parabolic equations with external forcing, and\nscalar conservation laws. Leveraging these structural insights, we obtain\ngeneralization bounds that demonstrate efficient learnability without incurring\nthe curse of dimensionality. Finally, we extend our analysis from single-input\noperator learning to a general multi-input setting, thereby broadening the\napplicability of our results.", "AI": {"tldr": "Theoretical analysis of feedforward neural networks for approximating PDE solution operators, with error bounds and generalization guarantees that avoid the curse of dimensionality.", "motivation": "Classical numerical PDE solvers face stability-computational cost tradeoffs, while DNNs offer data-driven alternatives through learning time-stepping operators, but lack rigorous theoretical foundations.", "method": "Develop theoretical framework for FNN approximation of time-stepping operators, derive explicit error estimates based on network architecture and training samples, analyze Lipschitz continuity and low-complexity structures in PDE operators.", "result": "Obtained explicit error bounds showing dependence on network width/depth and sample size, established Lipschitz properties of classical numerical schemes, identified low-complexity structures in various PDE classes, and proved generalization bounds without curse of dimensionality.", "conclusion": "The work provides rigorous theoretical foundation for neural network approximation of PDE solution operators, demonstrating efficient learnability and extending analysis to multi-input settings for broader applicability."}}
{"id": "2509.03776", "pdf": "https://arxiv.org/pdf/2509.03776", "abs": "https://arxiv.org/abs/2509.03776", "authors": ["Anbu Selvam Venkatachalam", "Loren Greenman", "Joshua Stallbaumer", "Artem Rudenko", "Daniel Rolles", "Huynh Van Sa Lam"], "title": "Exploiting correlations in multi-coincidence Coulomb explosion patterns for differentiating molecular structures using machine learning", "categories": ["physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Coulomb explosion imaging (CEI) is a powerful technique for capturing the\nreal-time motion of individual atoms during ultrafast photochemical reactions.\nCEI generates high-dimensional data with naturally embedded correlations that\nallow mapping the coordinated motion of nuclei in molecules. This enables\nreliable separation of competing reaction pathways and makes this approach\nuniquely suited for characterizing weak reaction channels. However, rich\ninformation contained in experimental CEI patterns remains largely\nunderexploited due to challenges in visualizing correlations between multiple\nobservables in multi-dimensional parameter space. Here we present a new\napproach to CEI of intermediate-sized polyatomic molecules, detecting up to\neight ionic fragments in coincidence and leveraging machine-learning-based\nanalysis to identify patterns and correlations in the resulting\nhigh-dimensional momentum-space data, enabling robust molecular structure\nidentification and differentiation. Our approach provides high-dimensional\nbackground-free data encoding exceptionally rich structural information and\nestablishes an automated, scalable framework for extracting insightful\ninformation from the data. As a demonstration, we apply this method to image\nand distinguish dichloroethylene isomers, showcasing its potential for broader\napplications in molecular imaging. Our results pave the way for\nchannel-specific analysis of ultrafast structural dynamics in chemically\nrelevant systems, particularly for disentangling mixed reaction pathways and\ndetecting contributions from weak channels and minority species.", "AI": {"tldr": "Machine learning-enhanced Coulomb explosion imaging enables automated analysis of high-dimensional molecular dynamics data for robust structure identification and pathway separation.", "motivation": "Coulomb explosion imaging generates rich high-dimensional data but faces challenges in visualizing correlations and extracting insights from multi-dimensional parameter space, limiting exploitation of its full potential.", "method": "Developed a new CEI approach detecting up to eight ionic fragments in coincidence, combined with machine-learning-based analysis to identify patterns and correlations in high-dimensional momentum-space data.", "result": "Successfully imaged and distinguished dichloroethylene isomers, providing high-dimensional background-free data with rich structural information and establishing an automated, scalable analysis framework.", "conclusion": "This approach enables channel-specific analysis of ultrafast structural dynamics, particularly for disentangling mixed reaction pathways and detecting weak channels and minority species in chemically relevant systems."}}
{"id": "2509.03799", "pdf": "https://arxiv.org/pdf/2509.03799", "abs": "https://arxiv.org/abs/2509.03799", "authors": ["Qingqing Peng", "Yikan Liu"], "title": "Energy decay and blow-up of viscoelastic wave equations with polynomial nonlinearity and damping", "categories": ["math.AP", "35L70, 35B40, 35B44"], "comment": "17 pages", "summary": "This paper is concerned with the energy decay and the finite time blow-up of\nthe solution to a viscoelastic wave equation with polynomial nonlinearity and\nweak damping. We establish explicit and general decay results for the solutions\nby imposing polynomial conditions on the relaxation function, provided that the\ninitial energy is sufficiently small. Furthermore, we derive an upper bound for\nthe blow-up time when the initial energy is less than the depth of the\npotential well by utilizing Levine's convexity method. Additionally, we provide\na lower bound for the blow-up time if the solution blows up.", "AI": {"tldr": "Analysis of energy decay and finite-time blow-up in viscoelastic wave equations with polynomial nonlinearity and weak damping, establishing decay results and blow-up time bounds.", "motivation": "To study the behavior of solutions to viscoelastic wave equations with polynomial nonlinearity and weak damping, specifically focusing on energy decay properties and conditions leading to finite-time blow-up.", "method": "Established explicit decay results by imposing polynomial conditions on the relaxation function with small initial energy. Used Levine's convexity method to derive upper bound for blow-up time when initial energy is below potential well depth. Also provided lower bound for blow-up time.", "result": "Obtained general decay results for solutions under polynomial relaxation function conditions with sufficiently small initial energy. Derived both upper and lower bounds for the blow-up time when solutions experience finite-time blow-up.", "conclusion": "The paper successfully characterizes both energy decay behavior and blow-up conditions for viscoelastic wave equations, providing comprehensive bounds on blow-up times and establishing conditions for solution stability through decay results."}}
{"id": "2509.04132", "pdf": "https://arxiv.org/pdf/2509.04132", "abs": "https://arxiv.org/abs/2509.04132", "authors": ["D. I. Palade"], "title": "Lagrangian features of turbulent transport in tokamak plasmas", "categories": ["physics.plasm-ph", "nlin.CD", "physics.data-an"], "comment": null, "summary": "This study investigates the Lagrangian properties of ion turbulent transport\ndriven by drift-type turbulence in tokamak plasmas. Despite the compressible\nand inhomogeneous nature of Eulerian gyrocenter drifts, numerical simulations\nwith the T3ST code reveal approximate ergodicity, stationarity, and\ntime-symmetry. These characteristics are attributed to broad initial\nphase-space distributions that support ergodic mixing. Moreover, relatively\nminor constraints on the initial distributions are found to have negligible\neffects on transport levels.", "AI": {"tldr": "Study shows ion turbulent transport in tokamak plasmas exhibits approximate ergodicity and stationarity despite compressible Eulerian drifts, with broad initial distributions enabling ergodic mixing and minimal transport impact from initial constraints.", "motivation": "To understand the Lagrangian properties of ion turbulent transport in tokamak plasmas, particularly investigating whether compressible and inhomogeneous Eulerian gyrocenter drifts lead to ergodic behavior and how initial conditions affect transport levels.", "method": "Numerical simulations using the T3ST code to analyze Lagrangian properties of drift-type turbulence in tokamak plasmas, examining phase-space distributions and transport characteristics.", "result": "Reveals approximate ergodicity, stationarity, and time-symmetry in transport despite compressible Eulerian drifts. Broad initial phase-space distributions support ergodic mixing, and relatively minor constraints on initial distributions have negligible effects on transport levels.", "conclusion": "Ion turbulent transport in tokamak plasmas demonstrates robust ergodic properties that are largely insensitive to initial distribution constraints, suggesting stable transport behavior under various initial conditions."}}
{"id": "2509.04352", "pdf": "https://arxiv.org/pdf/2509.04352", "abs": "https://arxiv.org/abs/2509.04352", "authors": ["Antonio Blanco-Casares", "Vishal Kumar", "Daniel Mira", "Oriol Lehmkuhl"], "title": "Projection-based stabilization for high-order incompressible flow solvers", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This work presents a novel stabilization strategy for the Galerkin\nformulation of the incompressible Navier-Stokes equations, developed to achieve\nhigh accuracy while ensuring convergence and compatibility with high-order\nelements on unstructured meshes. The numerical algorithm employs a fractional\nstep method with carefully defined boundary conditions to obtain a consistent\npressure field, enabling high-order temporal accuracy. The proposed\nstabilization is seamlessly integrated into the algorithm and shares the same\nunderlying principle as the natural stabilization inherent in the fractional\nstep method, both rely on the difference between the gradient operator and its\nprojection. The numerical dissipation associated to the stabilization term is\nfound to diminish with increasing polynomial order of the elements. Numerical\ntest cases confirm the effectiveness of the method, demonstrating convergence\nunder mesh refinement and increasing polynomial order.", "AI": {"tldr": "Novel stabilization strategy for incompressible Navier-Stokes Galerkin formulation that achieves high accuracy with convergence on unstructured meshes using high-order elements.", "motivation": "To develop a stabilization method that ensures convergence and compatibility with high-order elements on unstructured meshes while maintaining high accuracy in solving incompressible Navier-Stokes equations.", "method": "Fractional step method with carefully defined boundary conditions to obtain consistent pressure field, integrated with a stabilization strategy that shares the same principle as natural stabilization in fractional step methods (difference between gradient operator and its projection).", "result": "Numerical dissipation from stabilization diminishes with increasing polynomial order. Numerical tests confirm effectiveness, demonstrating convergence under both mesh refinement and increasing polynomial order.", "conclusion": "The proposed stabilization strategy successfully enables high-order temporal accuracy and convergence for incompressible Navier-Stokes equations on unstructured meshes with high-order elements."}}
{"id": "2509.04006", "pdf": "https://arxiv.org/pdf/2509.04006", "abs": "https://arxiv.org/abs/2509.04006", "authors": ["L. Salatino", "L. Mariani", "A. Giordano", "F. D'Amore", "C. Mastroianni", "L. Pontieri", "A. Vinci", "C. Gencarelli", "L. Primavera", "F. Plastina", "J. Settino", "F. Carbone"], "title": "Forecasting Low-Dimensional Turbulence via Multi-Dimensional Hybrid Quantum Reservoir Computing", "categories": ["quant-ph", "cond-mat.dis-nn", "nlin.CD", "physics.comp-ph"], "comment": "14 pages, 12 figures", "summary": "The prediction of complex dynamics remains an open problem across many\ndomains of physics, where nonlinearities and multiscale interactions severely\nlimit the reliability of conventional forecasting methods. Quantum reservoir\ncomputing (QRC) has emerged as a promising paradigm for information processing\nby exploiting the high dimensionality of the Hilbert space, where the dynamics\nof quantum systems take place. Here, we introduce a hybrid quantum-classical\nreservoir architecture capable of handling multivariate time series through\nquantum evolution combined with classical memory enhancement. Our model employs\na five-qubit transverse-field Ising Hamiltonian with input-modulated dynamics\nand temporal multiplexing, enabling the encoding of input signals over multiple\ntimescales. We apply this framework to two paradigmatic models of chaotic\nbehavior in fluid dynamics, where multiscale dynamics and nonlinearities play a\ndominant role: a low-dimensional truncation of the two-dimensional\nNavier-Stokes equations and the Lorenz-63 system. By systematically scanning\nthe quantum system's parameter space, we identify regions that maximize\nforecasting performance, as measured by the Valid Prediction Time. The observed\nrobustness and reliable performances for both dynamical systems suggest that\nthis hybrid quantum approach offers a flexible platform for modelling complex\nnonlinear time series.", "AI": {"tldr": "Hybrid quantum-classical reservoir computing using 5-qubit Ising Hamiltonian with temporal multiplexing for chaotic dynamics forecasting in fluid systems", "motivation": "Conventional forecasting methods struggle with complex nonlinear and multiscale dynamics in physics, particularly in fluid dynamics with chaotic behavior", "method": "Quantum reservoir computing with transverse-field Ising Hamiltonian, input-modulated dynamics, temporal multiplexing, and classical memory enhancement for multivariate time series", "result": "Identified optimal parameter regions maximizing forecasting performance (Valid Prediction Time) for both Navier-Stokes truncation and Lorenz-63 systems, showing robustness and reliable performance", "conclusion": "Hybrid quantum-classical reservoir architecture provides flexible platform for modeling complex nonlinear time series with multiscale dynamics"}}
{"id": "2509.04025", "pdf": "https://arxiv.org/pdf/2509.04025", "abs": "https://arxiv.org/abs/2509.04025", "authors": ["Emile Breton"], "title": "A note on the non-$L^1$ asymptotic completeness of the Vlasov-Maxwell system", "categories": ["math.AP", "math-ph", "math.MP", "35Q83 (Primary), 35B40 (Secondary)"], "comment": null, "summary": "We prove that under a generic asymptotic condition on the charge, the small\ndata solutions to the Vlasov-Maxwell system do not verify linear scattering. In\nother words, we show the non-$L^1$ asymptotic completeness of the system. The\nproof makes use of the Lorentz invariance of the equations.", "AI": {"tldr": "Small data solutions to Vlasov-Maxwell system do not exhibit linear scattering behavior under generic charge conditions, demonstrating non-L^1 asymptotic completeness.", "motivation": "To understand the scattering behavior and asymptotic completeness of solutions to the Vlasov-Maxwell system, particularly whether small data solutions follow linear scattering patterns.", "method": "The proof utilizes the Lorentz invariance property of the Vlasov-Maxwell equations to analyze the asymptotic behavior of solutions under generic charge conditions.", "result": "The study shows that small data solutions do not verify linear scattering, establishing the non-L^1 asymptotic completeness of the Vlasov-Maxwell system.", "conclusion": "The Vlasov-Maxwell system exhibits non-linear scattering behavior for small data solutions, with Lorentz invariance playing a crucial role in this asymptotic property."}}
{"id": "2509.04279", "pdf": "https://arxiv.org/pdf/2509.04279", "abs": "https://arxiv.org/abs/2509.04279", "authors": ["P. Lunia"], "title": "Energy Confinement Time Scaling for the Negative Triangularity Scenario in DIII-D", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Results from the 2023 negative triangularity campaign on DIII-D demonstrate\nencouraging energy confinement properties, similar to or exceeding the scaling\nof the IPB98(y,2) law. This paper describes the procedure with which a new\nscaling law was regressed specifically from the data from the DIII-D campaign.\nGiven the relatively small size of the single-machine dataset, measures were\ntaken to minimize sampling bias and give a realistic estimate of the large\nuncertainties from the regression. The resulting power law shows a robustly\nstronger dependence on plasma current and more severe power degradation as\ncompared to the H-mode scaling law.", "AI": {"tldr": "New scaling law developed from DIII-D negative triangularity campaign data shows stronger plasma current dependence and more severe power degradation than H-mode scaling.", "motivation": "To create a specific scaling law from the 2023 DIII-D negative triangularity campaign data that accurately represents energy confinement properties, addressing the challenges of small dataset size and potential sampling bias.", "method": "Developed a new regression procedure using data from the DIII-D campaign, implemented measures to minimize sampling bias, and provided realistic uncertainty estimates for the power law regression from the single-machine dataset.", "result": "The resulting scaling law demonstrates energy confinement similar to or exceeding IPB98(y,2) scaling, with a robustly stronger dependence on plasma current and more severe power degradation compared to H-mode scaling laws.", "conclusion": "The negative triangularity campaign on DIII-D shows promising energy confinement properties, and the newly developed scaling law provides a more accurate representation of these experimental results with appropriate uncertainty quantification."}}
{"id": "2509.04386", "pdf": "https://arxiv.org/pdf/2509.04386", "abs": "https://arxiv.org/abs/2509.04386", "authors": ["Laura Grigori", "Lorenzo Piccinini", "Igor Simunec"], "title": "Randomized biorthogonalization through a two-sided Gram-Schmidt process", "categories": ["math.NA", "cs.NA", "65F25 (Primary) 65F15 (Secondary)"], "comment": "26 pages, 5 figures, 3 tables", "summary": "We propose and analyze a randomized two-sided Gram-Schmidt process for the\nbiorthogonalization of two given matrices $X, Y \\in\\mathbb{R}^{n\\times m}$. The\nalgorithm aims to find two matrices $Q, P \\in\\mathbb{R}^{n\\times m}$ such that\n${\\rm range}(X) = {\\rm range}(Q)$, ${\\rm range}(Y) = {\\rm range}(P)$ and\n$(\\Omega Q)^T \\Omega P = I$, where $\\Omega \\in\\mathbb{R}^{s \\times n}$ is a\nsketching matrix satisfying an oblivious subspace $\\varepsilon$-embedding\nproperty; in other words, the biorthogonality condition on the columns of $Q$\nand $P$ is replaced by an equivalent condition on their sketches. This\nrandomized approach is computationally less expensive than the classical\ntwo-sided Gram-Schmidt process, has better numerical stability, and the\ncondition number of the computed bases $Q, P$ is often smaller than in the\ndeterministic case. Several different implementations of the randomized\nalgorithm are analyzed and compared numerically. The randomized two-sided\nGram-Schmidt process is applied to the nonsymmetric Lancozs algorithm for the\napproximation of eigenvalues and both left and right eigenvectors.", "AI": {"tldr": "Randomized two-sided Gram-Schmidt process for biorthogonalization using sketching matrices, offering computational efficiency, better stability, and improved condition numbers compared to classical methods.", "motivation": "To develop a computationally efficient and numerically stable alternative to the classical two-sided Gram-Schmidt process for biorthogonalization of matrices.", "method": "Uses randomized sketching with matrix \u03a9 satisfying oblivious subspace \u03b5-embedding to replace exact biorthogonality with sketch-based conditions, finding matrices Q and P that preserve ranges of original matrices.", "result": "The randomized approach is computationally less expensive, has better numerical stability, and produces bases with smaller condition numbers than deterministic methods. Multiple implementations were analyzed and compared.", "conclusion": "The randomized two-sided Gram-Schmidt process is effective for biorthogonalization and successfully applied to nonsymmetric Lanczos algorithm for eigenvalue and eigenvector approximation."}}
{"id": "2509.04064", "pdf": "https://arxiv.org/pdf/2509.04064", "abs": "https://arxiv.org/abs/2509.04064", "authors": ["Pedro Carvalho", "Bernd Ulmann", "Wolf Singer", "Felix Effenberger"], "title": "An analog-electronic implementation of a harmonic oscillator recurrent neural network", "categories": ["q-bio.NC", "physics.app-ph", "physics.comp-ph"], "comment": null, "summary": "Oscillatory recurrent networks, such as the Harmonic Oscillator Recurrent\nNetwork (HORN) model, offer advantages in parameter efficiency, learning speed,\nand robustness relative to traditional non-oscillating architectures. Yet,\nwhile many implementations of physical neural networks exploiting attractor\ndynamics have been studied, implementations of oscillatory models in\nanalog-electronic hardware that utilize the networks' transient dynamics so far\nare lacking. This study explores the feasibility of implementing HORNs in\nanalog-electronic hardware while maintaining the computational performance of\nthe digital counterpart. Using a digital twin approach, we trained a four-node\nHORN in silico for sequential MNIST classification and transferred the trained\nparameters to an analog electronic implementation. A set of custom error\nmetrics indicated that the analog system is able to successfully replicate the\ndynamics of the digital model in most test cases. However, despite the overall\nwell-matching dynamics, when using the readout layer of the digital model on\nthe data generated by the analog system, we only observed $28.39\\%$ agreement\nwith the predictions of the digital model. An analysis shows that this mismatch\nis due to a precision difference between the analog hardware and the\nfloating-point representation exploited by the digital model to perform\nclassification tasks. When the analog system was utilized as a reservoir with a\nre-trained linear readout, its classification performance could be recovered to\nthat of the digital twin, indicating preserved information content within the\nanalog dynamics. This proof-of-concept establishes that analog electronic\ncircuits can effectively implement oscillatory neural networks for computation,\nproviding a demonstration of energy-efficient analog systems that exploit\nbrain-inspired transient dynamics for computation.", "AI": {"tldr": "Analog electronic implementation of oscillatory neural networks (HORNs) successfully replicates digital model dynamics but requires retraining of readout layer due to precision differences, achieving comparable performance to digital counterpart.", "motivation": "To explore the feasibility of implementing oscillatory recurrent networks (HORNs) in analog-electronic hardware while maintaining computational performance, as previous implementations focused on attractor dynamics rather than transient dynamics.", "method": "Used digital twin approach - trained a four-node HORN in silico for sequential MNIST classification, then transferred parameters to analog electronic implementation. Employed custom error metrics and compared performance with both original and retrained readout layers.", "result": "Analog system successfully replicated digital model dynamics in most cases, but only 28.39% agreement when using digital readout layer. With retrained linear readout, classification performance recovered to digital twin levels, indicating preserved information content.", "conclusion": "Analog electronic circuits can effectively implement oscillatory neural networks for computation, demonstrating energy-efficient analog systems that exploit brain-inspired transient dynamics."}}
{"id": "2509.04099", "pdf": "https://arxiv.org/pdf/2509.04099", "abs": "https://arxiv.org/abs/2509.04099", "authors": ["Dragos-Patru Covei"], "title": "Existence and large radial solutions for an elliptic system under finite new Keller-Osserman integral conditions", "categories": ["math.AP"], "comment": "14 Pages", "summary": "We investigate the existence and qualitative behavior of entire positive\nradial solutions to the semilinear elliptic system% \\begin{equation*} \\Delta\nu=p(|x|)\\,g(v),\\qquad \\Delta v=q(|x|)\\,f(u),\\qquad x\\in \\mathbb{R}% ^{n},\\\nn\\geq 3, \\end{equation*}% under finite Keller--Osserman-type integral\nconditions on the nonlinearities $f$ and $g$, and integrability constraints on\nthe radial weights $p$ and $q$% . The nonlinearities are assumed continuous on\n$[0,\\infty )$, differentiable on $(0,\\infty )$, vanish at the origin, and are\nstrictly positive elsewhere, with% \\begin{equation*} \\int_{1}^{\\infty\n}\\frac{dt}{g(f(t))}<\\infty ,\\qquad \\int_{1}^{\\infty }\\frac{%\ndt}{f(g(t))}<\\infty . \\end{equation*}% The weights satisfy $\\int_{0}^{\\infty\n}s\\,p(s)\\,ds<\\infty $, $% \\int_{0}^{\\infty }s\\,q(s)\\,ds<\\infty $, and $\\min\n(p,q)$ is not compactly supported. Within this framework, we establish: (i) the\nexistence of infinitely many entire positive radial solutions for a nonempty\nset of central values; (ii) closedness of the set of admissible central values;\nand (iii) largeness (blow-up at infinity) of solutions corresponding to\nboundary points of this set. The approach is based on a novel subharmonic\nfunctional tailored to the reciprocal integral conditions, extending classical\nKeller--Osserman theory to a broad class of coupled systems with general\nnonlinearities and weight functions.", "AI": {"tldr": "Existence and behavior of entire positive radial solutions for semilinear elliptic systems with Keller-Osserman conditions and integrable weights", "motivation": "Extend classical Keller-Osserman theory to coupled elliptic systems with general nonlinearities and weight functions, establishing existence and qualitative properties of solutions", "method": "Novel subharmonic functional tailored to reciprocal integral conditions, analyzing radial solutions under finite Keller-Osserman-type integral conditions on nonlinearities and integrability constraints on radial weights", "result": "Established: (i) existence of infinitely many entire positive radial solutions for nonempty set of central values; (ii) closedness of admissible central values set; (iii) blow-up at infinity for boundary solutions", "conclusion": "Successfully extended classical theory to broad class of coupled systems, providing comprehensive framework for existence and qualitative analysis of entire positive radial solutions"}}
{"id": "2509.04359", "pdf": "https://arxiv.org/pdf/2509.04359", "abs": "https://arxiv.org/abs/2509.04359", "authors": ["J. B. Lestz", "G. Avdeeva", "T. F. Neiser", "M. V. Gorelenkova", "F. D. Halpern", "S. M. Kaye", "J. McClenaghan", "A. Y. Pankin", "K. E. Thome"], "title": "Assessing time-dependent temperature profile predictions using reduced transport models for high performing NSTX plasmas", "categories": ["physics.plasm-ph"], "comment": "30 pages, 13 figures. Submitted to Plasma Physics and Controlled\n  Fusion", "summary": "Time-dependent, predictive simulations were performed with the 1.5D tokamak\nintegrated modeling code TRANSP on a large set of well-analyzed, high\nperforming discharges from the National Spherical Torus Experiment (NSTX) in\norder to evaluate how well modern reduced transport models can reproduce\nexperimentally observed temperature profiles in spherical tokamaks. Overall, it\nis found that simulations using the Multi-Mode Model (MMM) more consistently\nagree with the NSTX observations than those using the Trapped Gyro-Landau Fluid\n(TGLF) model, despite TGLF requiring orders of magnitude greater computational\ncost. When considering all examined discharges, MMM has median overpredictions\nof electron temperature ($T_e$) and ion temperature ($T_i$) profiles of 28% and\n27%, respectively, relative to the experiment. TGLF overpredicts $T_e$ by 46%,\nwith much larger variance than MMM, and underpredicts $T_i$ by 25%. As $\\beta$\nis increased across NSTX discharges, TGLF predicts lower $T_e$ and significant\nflattening of the $T_i$ profile, conflicting with NSTX observations. When using\nan electrostatic version of TGLF, both $T_e$ and $T_i$ are substantially\noverpredicted, underscoring the importance of electromagnetic turbulence in the\nhigh $\\beta$ spherical tokamak regime. Additionally, calculations with neural\nnet surrogate models for TGLF were performed outside of TRANSP with a time\nslice flux matching transport solver, finding better agreement with experiment\nthan the TRANSP simulations, highlighting the impact of different transport\nsolvers and simulation techniques. Altogether, the reasonable agreement with\nexperiment of temperature profiles predicted by MMM motivates a more detailed\nexamination of the sensitivities of the TRANSP simulations with MMM to\ndifferent NSTX plasma regimes in a companion paper, in preparation for\nself-consistent, time-dependent predictive modeling of NSTX-U scenarios.", "AI": {"tldr": "TRANSP simulations show Multi-Mode Model (MMM) outperforms Trapped Gyro-Landau Fluid (TGLF) in predicting temperature profiles for NSTX spherical tokamak, with MMM showing 27-28% overprediction vs TGLF's 25-46% errors and greater variance.", "motivation": "To evaluate how well modern reduced transport models can reproduce experimentally observed temperature profiles in spherical tokamaks using NSTX discharge data.", "method": "Time-dependent predictive simulations using 1.5D tokamak integrated modeling code TRANSP on high-performing NSTX discharges, comparing MMM and TGLF transport models, with additional neural network surrogate model analysis.", "result": "MMM consistently agreed better with experiments than TGLF (28% vs 46% Te overprediction, 27% vs 25% Ti error). TGLF showed worse performance at high beta and electromagnetic effects proved crucial. Neural network surrogates showed improved agreement.", "conclusion": "MMM's reasonable agreement motivates detailed examination of TRANSP simulation sensitivities for future NSTX-U predictive modeling, highlighting MMM as more reliable despite TGLF's higher computational cost."}}
{"id": "2509.04409", "pdf": "https://arxiv.org/pdf/2509.04409", "abs": "https://arxiv.org/abs/2509.04409", "authors": ["Matthew E Hubbard", "Thomas J Radley"], "title": "An Arbitrary-Order Moving-Mesh Finite Element Algorithm for One-Dimensional Implicit Moving Boundary Problems", "categories": ["math.NA", "cs.NA", "35K61, 35R37, 65M60", "G.1.8"], "comment": "30 pages, 7 figures", "summary": "We present a one-dimensional high-order moving-mesh finite element method for\nmoving boundary problems where the boundary velocity depends implicitly on the\nsolution in the interior of the domain. The method employs a conservative\narbitrary Lagrangian-Eulerian approach to predict the evolution of the\napproximate solution. It retains the order of accuracy of the underlying\nfixed-mesh method by (i) computing the boundary velocities using a high-order\napproximation to a distributed local conservation principle which generates a\nLagrangian `flow' velocity and (ii) assuming a continuous piecewise linear\nvariation of the mesh velocity field in the interior of the computational\ndomain.\n  Within each time-step the algorithm consists of two stages: the computation\nof a velocity field with which to move both the domain boundary and the\ninternal mesh, and the approximation of the solution to the PDE on the updated\nmesh. Both internal and boundary velocities are generated within the same\nframework, though it would be simple to replace the internal mesh velocity\nfield by applying a more traditional mesh movement strategy (for example, one\nwhich seeks to equidistribute an error indicator at each time-step): the\nhigh-order accuracy should be retained as long the discrete velocity which is\nused in the solution update is assumed to vary linearly within mesh elements.\nThe proposed method is explicit in time, requires only the inversion of linear\nsystems of equations within each time-step, and is implemented fully in the\nphysical domain, so no mapping to a reference domain is employed. It attains\narbitrary-order accuracy in both space and time without the need to satisfy a\ndiscrete geometric conservation law.", "AI": {"tldr": "A high-order moving-mesh finite element method for 1D moving boundary problems with implicit boundary velocity dependence, using conservative ALE approach and achieving arbitrary-order accuracy without geometric conservation law constraints.", "motivation": "To develop an accurate and efficient numerical method for moving boundary problems where boundary movement depends on the interior solution, addressing challenges in maintaining high-order accuracy while handling mesh deformation.", "method": "Conservative arbitrary Lagrangian-Eulerian approach with two-stage algorithm: compute velocity field for mesh movement (boundary and interior), then solve PDE on updated mesh. Uses high-order approximation for boundary velocities and linear mesh velocity variation internally.", "result": "Method achieves arbitrary-order accuracy in space and time, is explicit in time, requires only linear system inversions per time-step, operates fully in physical domain without reference mapping, and avoids discrete geometric conservation law requirements.", "conclusion": "The proposed method provides an effective high-order accurate framework for moving boundary problems with implicit boundary velocity dependence, offering computational efficiency and flexibility in mesh movement strategies while maintaining accuracy."}}
{"id": "2509.04138", "pdf": "https://arxiv.org/pdf/2509.04138", "abs": "https://arxiv.org/abs/2509.04138", "authors": ["Hadiya Abdul Hameed", "Jaroslaw Paturej", "Aykut Erbas"], "title": "Shape spectra of elastic shells with surface-adsorbed semiflexible polymers", "categories": ["cond-mat.soft", "physics.comp-ph"], "comment": "11 pages, 5 figures Supplementary information, 10 pages, 10 figures", "summary": "The shape of biological shells, such as cell nuclei, membranes, and vesicles,\noften deviates from a perfect sphere due to an interplay of complex\ninteractions with a myriad of molecular structures. In particular, semiflexible\nbiopolymers adsorbed to the surfaces of such shells seem to affect their\nmorphological properties. While the effect of a single, long, semiflexible\nchain is relatively well characterized, the mechanisms by which a high density\nof such surface-adsorbed polymers can alter the morphology of a spherical, soft\nconfinement, akin to biological shells, remain relatively poorly understood.\nHere, we use coarse-grained molecular dynamics simulations to investigate how\nsurface adsorption of many semiflexible polymers affects the morphology of a\npressurized bead-spring shell, which is spherical in the absence of these\nchains. By varying the attraction strength between the chains and the shell\nsurface, chain concentration, and the polymerization degree of chains, we\ndemonstrate that strong surface localization of the chains can induce severe\nshape distortions and shrinkage, depending on the chain length and\nconcentration. Conversely, weak localization does not induce significant shape\nfluctuations, yet nematically ordered phases appear on the surface. Notably,\nthese ordered phases lead to elliptic shell shapes for chains with sizes\ncomparable to or longer than the radius of the confinement when the elastic\nshell is composed of extensible, harmonic bonds. Overall, our findings offer a\nstrategy to control the shape of synthetic shells by manipulating peripheral\nlocalization and length of semiflexible polymers while suggesting a mechanism\nfor non-spherical shapes appearing in some biological systems.", "AI": {"tldr": "Semiflexible polymers adsorbed on spherical shells can induce shape distortions and nematic ordering, with strong attraction causing shrinkage and weak attraction leading to elliptic shapes through surface ordering.", "motivation": "Understand how high density of surface-adsorbed semiflexible polymers affects morphology of spherical biological shells like cell nuclei and vesicles, which remains poorly characterized.", "method": "Coarse-grained molecular dynamics simulations of pressurized bead-spring shells with varying attraction strength, chain concentration, and polymerization degree of adsorbed semiflexible polymers.", "result": "Strong surface localization causes severe shape distortions and shrinkage depending on chain length/concentration. Weak localization produces nematically ordered phases leading to elliptic shell shapes for chains comparable to/longer than shell radius.", "conclusion": "Findings provide strategy to control synthetic shell shapes by manipulating polymer localization and length, and suggest mechanism for non-spherical shapes in biological systems."}}
{"id": "2509.04110", "pdf": "https://arxiv.org/pdf/2509.04110", "abs": "https://arxiv.org/abs/2509.04110", "authors": ["Jakub Wo\u017anicki"], "title": "Vlasov equation coupled with non-Newtonian fluids with discontinuous-in-time stress tensor", "categories": ["math.AP", "35K51, 35Q30, 35Q70, 76A05, 76D05"], "comment": null, "summary": "We analyze the system of equations describing the flow of a dilute particle\nsystem coupled with an incompressible non-Newtonian fluid in a bounded domain.\nIn this setting, both PDEs are connected via a drag force, or the friction\nforce. We are interested in a thin spray regime, which means that we neglect\nthe inter-particle interactions. When it comes to the fluid system, the Cauchy\nstress tensor is supposed to be a monotone mapping and has asymptotically\n$(s-1)$-growth with the parameter $s$ depending on the spatial and time\nvariable. We do not assume any smoothness of $s$ with respect to time variable\nand assume the log-H\\\"{o}lder continuity with respect to spatial variable. An\nexample of materials, which satisfy those assumptions, are those whose\nproperties are instantaneous, e.g. changed by the switched electric field. We\nshow the long time and the large data existence of weak solution provided that\n$s\\ge\\frac{3d+2}{d+2}$.", "AI": {"tldr": "Analysis of dilute particle system coupled with incompressible non-Newtonian fluid via drag force in bounded domain, showing long-time large-data existence of weak solutions for certain parameter ranges.", "motivation": "To study the mathematical behavior of particle-fluid systems where the fluid exhibits non-Newtonian properties with variable growth parameters, particularly relevant for materials whose properties change instantaneously (e.g., under electric field switching).", "method": "Analysis of PDE system describing particle flow coupled with incompressible non-Newtonian fluid through drag force interaction, assuming thin spray regime (neglecting inter-particle interactions) and specific growth conditions on the stress tensor.", "result": "Proved existence of weak solutions for long time and large data when the growth parameter s satisfies s \u2265 (3d+2)/(d+2), where d is spatial dimension.", "conclusion": "The mathematical framework establishes well-posedness for coupled particle-non-Newtonian fluid systems with variable growth parameters, providing theoretical foundation for modeling materials with instantaneous property changes."}}
{"id": "2509.04360", "pdf": "https://arxiv.org/pdf/2509.04360", "abs": "https://arxiv.org/abs/2509.04360", "authors": ["J. B. Lestz", "G. Avdeeva", "S. M. Kaye", "M. V. Gorelenkova", "F. D. Halpern", "J. McClenaghan", "A. Y. Pankin", "K. E. Thome"], "title": "Sensitivities of time-dependent temperature profile predictions for NSTX with the Multi-Mode Model", "categories": ["physics.plasm-ph"], "comment": "26 pages, 15 figures. Submitted to Plasma Physics and Controlled\n  Fusion", "summary": "The Multi-Mode Model (MMM) for turbulent transport was applied to a large set\nof well-analyzed discharges from the National Spherical Torus Experiment (NSTX)\nin order to evaluate its sensitivities to a wide range of plasma conditions.\nMMM calculations were performed for hundreds of milliseconds in each discharge\nby performing time-dependent predictive simulations with the 1.5D tokamak\nintegrated modeling code TRANSP. A closely related study concluded that MMM\npredicted electron ($T_e$) and ion ($T_i$) temperature profiles that were in\nreasonable agreement with NSTX observations, generally outperforming a\ndifferent reduced transport model, TGLF, motivating a more thorough\ninvestigation of the characteristics of the MMM predictions. The simulations\nwith MMM have electron energy transport dominated by electron temperature\ngradient modes for relatively low plasma $\\beta$ and high collisionality,\ntransitioning to a mixture of different modes for higher $\\beta$ and lower\ncollisionality. The thermal ion diffusivity predicted by MMM is much smaller\nthan the neoclassical contribution, in line with previous experimental analysis\nof NSTX. Nonetheless, the $T_e$ and $T_i$ profiles are coupled via collisional\nenergy exchange and thus sensitive to which transport channels are predicted.\nThe simulations with MMM are robust to the simulation start time, converging to\nremarkably similar temperatures later during the discharge. MMM typically\noverpredicts confinement relative to NSTX observations, leading to the\nprediction of overly steep profiles. Plasmas with spatially broader $T_e$\nprofiles, higher $\\beta$, and longer energy confinement times tend to be\npredicted by MMM with better agreement with the experiment. These findings\nprovide useful context for understanding the regime-dependent tendencies of MMM\nin anticipation of self-consistent, time-dependent predictive simulations of\nNSTX-U discharges.", "AI": {"tldr": "MMM turbulent transport model applied to NSTX experiments shows reasonable temperature profile predictions, outperforming TGLF, but tends to overpredict confinement with steep profiles. Performance varies with plasma conditions like beta and collisionality.", "motivation": "To evaluate the Multi-Mode Model (MMM) sensitivities across various plasma conditions in NSTX discharges and understand its regime-dependent performance characteristics for future NSTX-U simulations.", "method": "Time-dependent predictive simulations using 1.5D tokamak integrated modeling code TRANSP, applying MMM to hundreds of milliseconds of NSTX discharge data across various plasma conditions.", "result": "MMM predicted reasonable Te and Ti temperature profiles generally outperforming TGLF. Electron energy transport dominated by ETG modes at low beta/high collisionality, transitioning to mixed modes at higher beta/lower collisionality. MMM overpredicted confinement leading to overly steep profiles, with better agreement for broader Te profiles, higher beta, and longer confinement times.", "conclusion": "MMM shows robust performance with regime-dependent tendencies, providing useful context for future NSTX-U predictive simulations. The model converges to similar temperatures regardless of start time but typically overpredicts confinement relative to experimental observations."}}
{"id": "2509.04311", "pdf": "https://arxiv.org/pdf/2509.04311", "abs": "https://arxiv.org/abs/2509.04311", "authors": ["Sara Najem", "Dima Mrad"], "title": "The Non-commutative Spaces of Higher-Order Networks of Bach's Solo Violin Compositions: Dimension, Curvature, and Distance through the Spectral Triplet", "categories": ["cond-mat.stat-mech", "physics.app-ph", "physics.comp-ph", "physics.data-an"], "comment": null, "summary": "Our work is concerned with simplicial complexes that describe higher-order\ninteractions in real complex systems. This description allows to go beyond the\npairwise node-to-node representation that simple networks provide and to\ncapture a hierarchy of interactions of different orders. The prime contribution\nof this work is the introduction of geometric measures for these simplicial\ncomplexes. We do so by noting the non-commutativity of the algebra associated\nwith their matrix representations and consequently we bring to bear the\nspectral triplet formalism of Connes on these structures and then notions of\nassociated dimensions, curvature, and distance can be computed to serve as\ncharacterizing features in addition to known topological metrics.", "AI": {"tldr": "Introduces geometric measures for simplicial complexes using non-commutative algebra and Connes' spectral triplet formalism to compute dimensions, curvature, and distance as characterizing features.", "motivation": "To go beyond pairwise network representations and capture higher-order interactions in complex systems through simplicial complexes, which require new geometric characterization methods.", "method": "Leverages the non-commutativity of algebra in matrix representations of simplicial complexes and applies Connes' spectral triplet formalism to derive geometric measures.", "result": "Develops computational methods for associated dimensions, curvature, and distance metrics that serve as additional characterizing features alongside traditional topological metrics.", "conclusion": "The spectral triplet formalism provides a powerful framework for geometric analysis of simplicial complexes, enabling richer characterization of higher-order interactions in complex systems."}}
{"id": "2509.04167", "pdf": "https://arxiv.org/pdf/2509.04167", "abs": "https://arxiv.org/abs/2509.04167", "authors": ["Peng Zhao", "Xiaoning Wu"], "title": "On the local existence for the characteristic initial value problem for the Einstein-Dirac system", "categories": ["math.AP", "gr-qc"], "comment": "38 pages, 1 figure", "summary": "In this paper, we investigate the characteristic initial value problem for\nthe Einstein-Dirac system, a model governing the interaction between gravity\nand spin-$1/2$ fields. We apply Luk's strategy \\cite{Luk12} and prove a\nsemi-global existence result for this coupled Einstein-Dirac system without\nimposing symmetry conditions. More precisely, we construct smooth solutions in\na rectangular region to the future of two intersecting null hypersurfaces, on\nwhich characteristic initial data are specified. The key novelty is to promote\nthe symmetric spinorial derivatives of the Dirac field to independent variables\nand to derive a commuted \"Weyl-curvature-free\" evolution system for them. This\neliminates the coupling to the curvature in the energy estimates and closes the\nbootstrap at the optimal derivative levels. The analysis relies on a double\nnull foliation and incorporates spinor-specific techniques essential to\nhandling the structure of the Dirac field.", "AI": {"tldr": "Semi-global existence proof for Einstein-Dirac system using characteristic initial data on intersecting null hypersurfaces without symmetry assumptions", "motivation": "To investigate the characteristic initial value problem for the Einstein-Dirac system governing gravity-spin-1/2 field interactions", "method": "Apply Luk's strategy with double null foliation, promote symmetric spinorial derivatives to independent variables, derive Weyl-curvature-free evolution system, use spinor-specific techniques", "result": "Construct smooth solutions in rectangular region to future of intersecting null hypersurfaces with characteristic initial data", "conclusion": "Successfully proves semi-global existence for coupled Einstein-Dirac system by eliminating curvature coupling in energy estimates and closing bootstrap at optimal derivative levels"}}
{"id": "2509.04374", "pdf": "https://arxiv.org/pdf/2509.04374", "abs": "https://arxiv.org/abs/2509.04374", "authors": ["Subash Adhikari", "Carlos Gonzalez", "Yan Yang", "Sean Oughton", "Francesco Pecora", "Riddhi Bandyopadhyay", "William H. Matthaeus"], "title": "Estimation of Effective Viscosity to Quantify Collisional Behavior in Collisionless Plasma", "categories": ["physics.plasm-ph", "physics.space-ph"], "comment": "Submitted to ApJ (10 pages, 5 figures)", "summary": "While dissipation in collisional plasma is defined in terms of viscosity and\nresistivity, the exact functional form of dissipation i.e., the so-called\ndissipation function in nearly collisionless plasma is unknown. Nevertheless,\nprevious studies have suggested that there exists viscous-like energy\nconversion in collisionless plasma with scaling characteristics analogous to\ncollisional plasma, and in particular that the average dissipation is\nproportional to the square of the rate of strain as in hydrodynamics. In this\nstudy, using 2.5D kinetic particle-in-cell (PIC) simulation of collisionless\nplasma turbulence, we provide an estimate of effective viscosity at each scale,\nobtained via a scale-filtering approach. We then compare the turbulent dynamics\nof the PIC simulation with that from MHD and two-fluid simulations in which\nwith the viscosity is equal to the effective viscosity estimate obtained from\nthe PIC simulation. We find that the global behavior in these MHD and two-fluid\nsimulations has a striking similarity with that in its kinetic/PIC counterpart.\nIn addition, we explore the scale dependence of the effective viscosity, and\ndiscuss implications of this approach for space plasmas.", "AI": {"tldr": "Study estimates effective viscosity in collisionless plasma turbulence using PIC simulations, finding similar turbulent dynamics to MHD/two-fluid simulations with equivalent viscosity.", "motivation": "To understand dissipation mechanisms in nearly collisionless plasma where traditional viscosity and resistivity definitions don't apply, but viscous-like energy conversion has been observed.", "method": "Used 2.5D kinetic particle-in-cell (PIC) simulation of collisionless plasma turbulence with scale-filtering approach to estimate effective viscosity at each scale, then compared with MHD and two-fluid simulations using the same viscosity estimates.", "result": "Found striking similarity in global behavior between kinetic/PIC simulations and MHD/two-fluid simulations when using equivalent effective viscosity. Also explored scale dependence of effective viscosity.", "conclusion": "The approach provides insights into dissipation in collisionless plasma turbulence and has implications for understanding space plasmas, showing that effective viscosity concepts can bridge kinetic and fluid descriptions."}}
{"id": "2509.03758", "pdf": "https://arxiv.org/pdf/2509.03758", "abs": "https://arxiv.org/abs/2509.03758", "authors": ["Alvaro Almeida Gomez"], "title": "Learning functions through Diffusion Maps", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": "Comments are welcome", "summary": "We propose a data-driven method for approximating real-valued functions on\nsmooth manifolds, building on the Diffusion Maps framework under the manifold\nhypothesis. Given pointwise evaluations of a function, the method constructs a\nsmooth extension to the ambient space by exploiting diffusion geometry and its\nconnection to the heat equation and the Laplace-Beltrami operator.\n  To address the computational challenges of high-dimensional data, we\nintroduce a dimensionality reduction strategy based on the low-rank structure\nof the distance matrix, revealed via singular value decomposition (SVD). In\naddition, we develop an online updating mechanism that enables efficient\nincorporation of new data, thereby improving scalability and reducing\ncomputational cost.\n  Numerical experiments, including applications to sparse CT reconstruction,\ndemonstrate that the proposed methodology outperforms classical feedforward\nneural networks and interpolation methods in terms of both accuracy and\nefficiency.", "AI": {"tldr": "A data-driven method for approximating functions on smooth manifolds using Diffusion Maps framework with dimensionality reduction via SVD and online updating for scalability.", "motivation": "To develop an efficient method for function approximation on manifolds that handles high-dimensional data challenges and enables scalable processing with new data.", "method": "Builds on Diffusion Maps framework, uses SVD for dimensionality reduction of distance matrices, and implements online updating mechanism for incorporating new data efficiently.", "result": "Outperforms classical feedforward neural networks and interpolation methods in both accuracy and efficiency, demonstrated through numerical experiments including sparse CT reconstruction.", "conclusion": "The proposed methodology provides an effective and scalable approach for function approximation on manifolds with superior performance compared to traditional methods."}}
{"id": "2509.04189", "pdf": "https://arxiv.org/pdf/2509.04189", "abs": "https://arxiv.org/abs/2509.04189", "authors": ["Max Goering", "Anna Skorobogatova"], "title": "On the geometric properties of multi-operator two-phase elliptic measure", "categories": ["math.AP"], "comment": "26 pages, comments welcome!", "summary": "We provide a structural characterization of a given boundary using two-phase\nelliptic measure in a multi-operator setting, extending to this novel setting\nresults of Kenig, Preiss & Toro, Toro & Zhao and Azzam & Mourgoglou, including\na partial answer to Bishop's question regarding the validity of Oksendal's\nconjecture under the assumption of mutual absolute continuity of the elliptic\nmeasures. Our techniques rely on a reduction to a multi-operator two-phase\nfree-boundary problem combined with an extension of the powerful tools\nintroduced by Preiss in his Density Theorem.", "AI": {"tldr": "Structural characterization of boundaries using two-phase elliptic measures in multi-operator setting, extending previous results and addressing Bishop's question on Oksendal's conjecture.", "motivation": "Extend boundary characterization results to multi-operator settings and provide partial answer to Bishop's question about Oksendal's conjecture under mutual absolute continuity of elliptic measures.", "method": "Reduction to multi-operator two-phase free-boundary problem combined with extension of Preiss's Density Theorem tools.", "result": "Structural characterization achieved for boundaries using two-phase elliptic measure in multi-operator context.", "conclusion": "The approach successfully extends previous boundary analysis techniques to multi-operator settings and makes progress on Oksendal's conjecture problem."}}
{"id": "2509.03945", "pdf": "https://arxiv.org/pdf/2509.03945", "abs": "https://arxiv.org/abs/2509.03945", "authors": ["Guglielmo Gattiglio", "Lyudmila Grigoryeva", "Massimiliano Tamborrino"], "title": "Prob-GParareal: A Probabilistic Numerical Parallel-in-Time Solver for Differential Equations", "categories": ["stat.CO", "cs.DC", "cs.NA", "math.NA", "stat.ML", "65M55, 65M22, 65L05, 50G15, 65Y05"], "comment": null, "summary": "We introduce Prob-GParareal, a probabilistic extension of the GParareal\nalgorithm designed to provide uncertainty quantification for the\nParallel-in-Time (PinT) solution of (ordinary and partial) differential\nequations (ODEs, PDEs). The method employs Gaussian processes (GPs) to model\nthe Parareal correction function, as GParareal does, further enabling the\npropagation of numerical uncertainty across time and yielding probabilistic\nforecasts of system's evolution. Furthermore, Prob-GParareal accommodates\nprobabilistic initial conditions and maintains compatibility with classical\nnumerical solvers, ensuring its straightforward integration into existing\nParareal frameworks. Here, we first conduct a theoretical analysis of the\ncomputational complexity and derive error bounds of Prob-GParareal. Then, we\nnumerically demonstrate the accuracy and robustness of the proposed algorithm\non five benchmark ODE systems, including chaotic, stiff, and bifurcation\nproblems. To showcase the flexibility and potential scalability of the proposed\nalgorithm, we also consider Prob-nnGParareal, a variant obtained by replacing\nthe GPs in Parareal with the nearest-neighbors GPs, illustrating its increased\nperformance on an additional PDE example. This work bridges a critical gap in\nthe development of probabilistic counterparts to established PinT methods.", "AI": {"tldr": "Prob-GParareal is a probabilistic extension of GParareal that uses Gaussian processes to provide uncertainty quantification for parallel-in-time solutions of differential equations, with theoretical analysis and numerical validation on benchmark problems.", "motivation": "To bridge the gap in developing probabilistic counterparts to established Parallel-in-Time methods by enabling uncertainty quantification and probabilistic forecasting for differential equation solutions.", "method": "Extends GParareal using Gaussian processes to model the Parareal correction function, allowing uncertainty propagation across time. Also introduces Prob-nnGParareal variant with nearest-neighbors GPs for improved performance.", "result": "Theoretical analysis shows computational complexity and error bounds. Numerical experiments demonstrate accuracy and robustness on five benchmark ODE systems (chaotic, stiff, bifurcation) and showcase flexibility with a PDE example.", "conclusion": "Prob-GParareal successfully provides probabilistic uncertainty quantification for PinT methods while maintaining compatibility with existing numerical solvers, offering a robust framework for probabilistic forecasting of differential equation solutions."}}
{"id": "2509.04289", "pdf": "https://arxiv.org/pdf/2509.04289", "abs": "https://arxiv.org/abs/2509.04289", "authors": ["Ali Feizmohammadi", "Yavar Kian"], "title": "Recovery of Sturm-Liouville operators from partial boundary spectral data and applications", "categories": ["math.AP", "math.SP"], "comment": "27 pages. Comments are welcome", "summary": "We study the inverse Sturm-Liouville problem on a finite interval from\npartial knowledge of spectral data. Specifically, we show that the potential\ncan be uniquely reconstructed from the knowledge of a fraction of Dirichlet\neigenvalues together with the normal derivatives of the corresponding\neigenfunctions at both endpoints. We present two novel applications of our\nspectral result in inverse coefficient determination problems for evolutionary\nPDEs that include passive wave-based imaging of a medium and active imaging for\nthe time-dependent Schr\\\"odinger equation with unknown internal sources. Our\nresults yield optimal time measurement bounds for such inverse coefficient\ndetermination problems. A central innovation is the use of Kahane's\ninterpolation theorem to analyze endpoint time traces of solutions, enabling\nthe recovery without requiring analyticity assumptions or infinite-time data,\nas in previous approaches. Finally, in the appendix, we present a spectral\ninterpolation theorem for one-dimensional Schr\\\"odinger operators, which may be\nof independent interest.", "AI": {"tldr": "Unique reconstruction of potential from partial spectral data using Dirichlet eigenvalues and eigenfunction normal derivatives, with applications to inverse coefficient problems in wave imaging and Schrodinger equation.", "motivation": "To solve inverse Sturm-Liouville problems from partial spectral data and address inverse coefficient determination problems in evolutionary PDEs for imaging applications.", "method": "Uses Kahane's interpolation theorem to analyze endpoint time traces of solutions, enabling recovery without analyticity assumptions or infinite-time data requirements.", "result": "Demonstrates unique reconstruction of potential from fractional Dirichlet eigenvalues and corresponding eigenfunction normal derivatives at endpoints, yielding optimal time measurement bounds.", "conclusion": "Presents novel spectral results with practical applications in passive and active imaging, and includes a spectral interpolation theorem for Schrodinger operators as additional contribution."}}
{"id": "2509.04024", "pdf": "https://arxiv.org/pdf/2509.04024", "abs": "https://arxiv.org/abs/2509.04024", "authors": ["Milad Hasani", "Alireza Rezania", "Sam Riahi"], "title": "Electromechanical human heart modeling for predicting endocardial heart motion", "categories": ["physics.med-ph", "cs.NA", "math.NA"], "comment": null, "summary": "This work presents a biventricular electromechanical human heart model that\nis comprehensive and clinically relevant, integrating a realistic 3D heart\ngeometry with both systemic and pulmonary hemodynamics. The model uses a\ntwo-way fluid-structure-interaction (FSI) formulation with actual 3D blood\nmeshes to accurately investigate the effect of blood flow on the myocardium. It\ncouples a reaction-diffusion framework and a voltage-dependent active stress\nterm to replicate the link between electrical excitation and mechanical\ncontraction. Additionally, the model incorporates innovative epicardial\nboundary conditions to mimic the stiffness and viscosity of neighboring\ntissues. The model's ability to replicate physiological heart motion was\nvalidated against Cine magnetic resonance imaging (MRI) data, which\ndemonstrated a high degree of consistency in regional displacement patterns.\nThe analysis of the right ventricle showed that the basal and mid free walls\nexperience the largest motion, making these regions ideal for implanting\nmotion-driven energy harvesting devices. This validated model is a robust tool\nfor enhancing our understanding of cardiac physiology and optimizing\ntherapeutic interventions before clinical implementation.", "AI": {"tldr": "A comprehensive biventricular electromechanical heart model with realistic 3D geometry, fluid-structure interaction, and physiological validation using MRI data.", "motivation": "To create a clinically relevant heart model that integrates electrical excitation, mechanical contraction, and hemodynamics for better understanding of cardiac physiology and therapeutic optimization.", "method": "Uses two-way fluid-structure interaction with 3D blood meshes, couples reaction-diffusion framework with voltage-dependent active stress, and incorporates innovative epicardial boundary conditions to mimic tissue stiffness and viscosity.", "result": "Model validated against Cine MRI data showing high consistency in regional displacement patterns. Right ventricle analysis revealed basal and mid free walls experience largest motion, ideal for motion-driven energy harvesting devices.", "conclusion": "The validated model serves as a robust tool for enhancing cardiac physiology understanding and optimizing therapeutic interventions before clinical implementation."}}
{"id": "2509.04428", "pdf": "https://arxiv.org/pdf/2509.04428", "abs": "https://arxiv.org/abs/2509.04428", "authors": ["Maicon Hespanha", "Renzo Scarpelli"], "title": "Energy critical fourth-order Schr\u00f6dinger equation system with power-type nonlinearities in the radial case", "categories": ["math.AP", "35Q44, 35P25, 35B44"], "comment": "31 pages", "summary": "In this paper, we study a system of focusing fourth-order Schr\\\"odinger\nequations in the energy-critical setting with radial initial data and general\npower-type nonlinearities. The main idea is to generalize the analysis of such\nsystems: we first establish several hypotheses on the nonlinearities and prove\ntheir implications. These implications are then used to establish a local\nwell-posedness result in $H^2(\\mathbb{R}^d)$ and and to prove the existence of\nground state solutions. Using a virial argument, we demonstrate a blow-up\nresult for initial data with negative energy or with kinetic energy exceeding\nthat of the ground state. Finally, employing the\nconcentration-compactness/rigidity method, we prove a scattering result for\nsolutions whose energy and kinetic energy are below those of the ground state.", "AI": {"tldr": "Analysis of focusing fourth-order Schrodinger equations with radial data and power-type nonlinearities, establishing well-posedness, ground states, blow-up conditions, and scattering results.", "motivation": "To generalize the analysis of focusing fourth-order Schrodinger equation systems in the energy-critical setting with radial initial data and general power-type nonlinearities, extending previous work on such systems.", "method": "Established hypotheses on nonlinearities and proved their implications; used these to prove local well-posedness in H^2 space and existence of ground state solutions; employed virial argument for blow-up results; used concentration-compactness/rigidity method for scattering results.", "result": "Proved local well-posedness in H^2(R^d), existence of ground state solutions, blow-up for negative energy or kinetic energy exceeding ground state, and scattering for solutions with energy/kinetic energy below ground state levels.", "conclusion": "The paper provides a comprehensive analysis framework for focusing fourth-order Schrodinger equations, establishing fundamental properties including well-posedness, existence of special solutions, and classification of solution behavior based on energy comparisons with ground states."}}
{"id": "2509.04188", "pdf": "https://arxiv.org/pdf/2509.04188", "abs": "https://arxiv.org/abs/2509.04188", "authors": ["Ma. Cristina R. Bargo"], "title": "Sensitivity analysis of an epidemic model with a mass vaccination program of a homogeneous population", "categories": ["q-bio.PE", "cs.NA", "math.NA", "92D30 (Primary), 65L05, 90C31 (Secondary)"], "comment": "23 pages, 15 figures, accepted for publication to SciEnggJ", "summary": "The COVID-19 pandemic forced the rapid development of vaccines and the\nimplementation of mass vaccination programs around the world. However, many\nhesitated to take the vaccine due to concerns about its effectiveness. By\nlooking at an ordinary differential equation (ODE) model of disease spread that\nincorporates a mass vaccination program, this study aims to determine the\nsensitivity of the cumulative count of infected individuals ($W$) and the\ncumulative death count ($D$) to the following model parameters: disease\ntransmission rate ($\\beta$), reciprocal of the disease latency period\n($\\kappa$), reciprocal of the infectious period ($\\gamma$), death ratio\n($\\alpha$), vaccine efficacy rate ($r$), and vaccine rollout rate ($\\delta$).\nThis was implemented using Latin hypercube sampling and partial rank\ncorrelation coefficient. Results show that $D$ is highly sensitive to $\\alpha$\nand shows increasing sensitivity to $\\delta$ in the long run. On the other\nhand, $W$ is highly sensitive to $\\kappa$ at the beginning of the simulation,\nbut this weakens over time. In contrast, $W$ is not very sensitive to $\\delta$\ninitially but becomes very significant in the long run. This supports the\nimportance of the vaccine rollout rate over the vaccine efficacy rate in\ncurbing the spread of the disease in the population. It is also worthwhile to\nreduce the death ratio by developing a cure for the disease or improving the\nhealthcare system as a whole.", "AI": {"tldr": "Sensitivity analysis of COVID-19 vaccination parameters shows vaccine rollout rate becomes more important than efficacy over time, and death ratio is crucial for reducing mortality.", "motivation": "To address vaccine hesitancy and determine which vaccination parameters most influence infection and death counts in COVID-19 spread models.", "method": "Used ordinary differential equation (ODE) model with Latin hypercube sampling and partial rank correlation coefficient to analyze sensitivity to transmission rate, latency period, infectious period, death ratio, vaccine efficacy, and rollout rate.", "result": "Death count highly sensitive to death ratio (\u03b1); cumulative infections sensitive to latency period (\u03ba) initially but vaccine rollout rate (\u03b4) becomes dominant long-term; vaccine efficacy less significant than rollout rate.", "conclusion": "Vaccine rollout rate is more critical than efficacy for controlling disease spread, and reducing death ratio through medical treatments/healthcare improvements is essential for minimizing mortality."}}
{"id": "2509.03627", "pdf": "https://arxiv.org/pdf/2509.03627", "abs": "https://arxiv.org/abs/2509.03627", "authors": ["Naiara Arrizabalaga", "Lucrezia Cossetti", "Matias Morales"], "title": "Absence of eigenvalues of electromagnetic Dirac operators", "categories": ["math.SP", "math-ph", "math.AP", "math.MP"], "comment": "19 pages", "summary": "In this work, we develop the method of multipliers for electromagnetic Dirac\noperators and establish sufficient conditions on the magnetic and electric\nfields that guarantee the absence of point spectrum. Our results can be viewed\nas a generalization of those obtained by Cossetti, Fanelli and\nKrej\\v{c}i\\v{r}\\'ik (2020), which treated the purely magnetic case. We also\nemphasize that, in the massless case, our approach covers Coulomb-type\npotentials of the form $V(x) = \\frac{1}{|x|} \\big(\\nu \\mathbb{I} + \\mu \\beta +\ni \\delta \\beta \\big(\\boldsymbol{\\alpha}\\cdot \\frac{x}{|x|} \\big) \\big).$", "AI": {"tldr": "Generalization of multiplier method for electromagnetic Dirac operators to establish conditions for absence of point spectrum, extending previous magnetic-only results and covering Coulomb-type potentials in massless case.", "motivation": "To extend the method of multipliers approach from purely magnetic Dirac operators to electromagnetic cases, providing sufficient conditions for absence of point spectrum and covering more general potential types including Coulomb-type interactions.", "method": "Developed the method of multipliers specifically for electromagnetic Dirac operators, establishing mathematical conditions on both magnetic and electric fields that guarantee the absence of point spectrum in the operator's spectrum.", "result": "Successfully generalized previous results from purely magnetic cases to electromagnetic Dirac operators, with the approach particularly effective for massless cases where it can handle Coulomb-type potentials with specific matrix structures.", "conclusion": "The method provides a comprehensive framework for analyzing point spectrum absence in electromagnetic Dirac operators, extending previous work and demonstrating applicability to physically relevant Coulomb-type potentials in quantum mechanics."}}
{"id": "2509.03777", "pdf": "https://arxiv.org/pdf/2509.03777", "abs": "https://arxiv.org/abs/2509.03777", "authors": ["Andrew J. Graven", "Nikolai G. Makarov"], "title": "Quadrature Domains and the Faber Transform", "categories": ["math.CV", "math-ph", "math.AP", "math.MP", "31A25 (Primary) 30E25, 30C20, 31A15 (Secondary)"], "comment": "60 Pages, 21 Figures", "summary": "We present a framework for reconstructing any simply connected bounded or\nunbounded, quadrature domain $\\Omega$ from its quadrature function $h$. Using\nthe Faber transform, we derive formulae directly relating $h$ to the Riemann\nmap for $\\Omega$. Through this approach, we obtain a complete classification of\none point quadrature domains with complex charge. We proceed to develop a\ntheory of weighted quadrature domains with respect to weights of the form\n$\\rho_a(w)=|w|^{2(a-1)}$ when $a > 0$ (\"power-weighted\" quadrature domains) and\nthe limiting case of $a=0$ (\"log-weighted\" quadrature domains). We obtain Faber\ntransform formulae for reconstructing these from their respective quadrature\nfunctions as well. Several examples are presented throughout to illustrate this\napproach both in the simply connected setting and in the presence of rotational\nsymmetry.", "AI": {"tldr": "A framework for reconstructing quadrature domains from quadrature functions using Faber transform, with applications to one-point domains and weighted quadrature domains.", "motivation": "To develop a systematic approach for reconstructing simply connected quadrature domains from their quadrature functions, extending to weighted cases and providing complete classification.", "method": "Uses Faber transform to derive formulae relating quadrature function h to Riemann map for \u03a9. Develops theory for power-weighted (\u03c1_a(w)=|w|^{2(a-1)}) and log-weighted quadrature domains.", "result": "Obtains complete classification of one point quadrature domains with complex charge. Derives reconstruction formulae for both power-weighted and log-weighted quadrature domains from their quadrature functions.", "conclusion": "The Faber transform provides an effective framework for reconstructing quadrature domains and their weighted variants, with demonstrated applications in simply connected and rotationally symmetric settings."}}
{"id": "2509.04176", "pdf": "https://arxiv.org/pdf/2509.04176", "abs": "https://arxiv.org/abs/2509.04176", "authors": ["Paz Hashash", "Arkady Poliakovsky"], "title": "BMO-Interpolations and Jump Detection for Functions in $BV\\cap BMO$", "categories": ["math.FA", "math.AP"], "comment": null, "summary": "In this article, we prove interpolation results for $BMO$ in Lorentz spaces.\nFrom these results, we derive interpolation theorems in Besov spaces, the space\n$BV$, and fractional Sobolev spaces. As an application, we obtain geometric\ninformation about the jump set of functions in $BV \\cap BMO$.", "AI": {"tldr": "Interpolation results for BMO in Lorentz spaces, extended to Besov spaces, BV space, and fractional Sobolev spaces, with applications to geometric analysis of jump sets in BV \u2229 BMO functions.", "motivation": "To establish interpolation theorems that connect BMO (Bounded Mean Oscillation) with various function spaces including Lorentz, Besov, BV (Bounded Variation), and fractional Sobolev spaces, enabling deeper analysis of function properties.", "method": "Proving interpolation results for BMO in Lorentz spaces first, then deriving interpolation theorems for other function spaces (Besov, BV, fractional Sobolev) from these foundational results.", "result": "Successful development of interpolation theorems across multiple function spaces, with practical application to obtain geometric information about jump sets of functions belonging to both BV and BMO spaces.", "conclusion": "The interpolation framework provides powerful tools for analyzing function spaces and yields valuable geometric insights, particularly for understanding the structure of jump sets in functions with both bounded variation and bounded mean oscillation properties."}}
{"id": "2509.04184", "pdf": "https://arxiv.org/pdf/2509.04184", "abs": "https://arxiv.org/abs/2509.04184", "authors": ["Habib Ammari", "Jiayu Qiu"], "title": "Analysis of nonlinear resonances in resonator crystals: Tight-binding approximation and existence of subwavelength soliton-like solutions", "categories": ["math-ph", "math.AP", "math.MP"], "comment": null, "summary": "This work provides a mathematical framework for elucidating physical\nmechanisms for confining waves at subwavelength scales in periodic systems of\nnonlinear resonators. A discrete approximation in terms of the linear\ncapacitance operator is provided to characterize the nonlinear subwavelength\nresonances. Moreover, the existence of subwavelength soliton-like localized\nwaves in periodic systems of nonlinear resonators is proven. As a by-product, a\ntight-binding approximation of the capacitance operator is shown to be valid\nfor crystals of subwavelength resonators. Both full- and half-space crystals\nare considered. The framework developed in this work opens the door to the\nstudy of topological properties of periodic lattices of subwavelength nonlinear\nresonators, such as the emergence of nonlinearity-induced topological edge\nstates, and to elucidate the interplay between nonlinearity and disorder.", "AI": {"tldr": "Mathematical framework for confining waves at subwavelength scales in periodic nonlinear resonator systems, proving existence of soliton-like localized waves and validating tight-binding approximations.", "motivation": "To understand physical mechanisms for wave confinement at subwavelength scales in periodic systems of nonlinear resonators, enabling study of topological properties and nonlinearity-disorder interplay.", "method": "Develops discrete approximation using linear capacitance operator to characterize nonlinear subwavelength resonances, proves existence of soliton-like waves, and validates tight-binding approximation for subwavelength resonator crystals.", "result": "Successfully provides mathematical framework for subwavelength wave confinement, proves existence of localized soliton-like waves, and demonstrates validity of tight-binding approximation for both full- and half-space crystals.", "conclusion": "The framework enables future study of topological properties in nonlinear resonator lattices, including nonlinearity-induced topological edge states and the interplay between nonlinearity and disorder."}}
{"id": "2509.04275", "pdf": "https://arxiv.org/pdf/2509.04275", "abs": "https://arxiv.org/abs/2509.04275", "authors": ["Lassi Paunonen", "David Seifert"], "title": "Polynomial Stability of Non-Linearly Damped Contraction Semigroups", "categories": ["math.FA", "math.AP", "math.OC", "34G20, 47H20, 93D15, 93D20, 93B07 (47D06, 35B35, 35L20)"], "comment": "13 pages, submitted", "summary": "We investigate the stability properties of an abstract class of semi-linear\nsystems. Our main result establishes rational rates of decay for classical\nsolutions assuming a certain non-uniform observability estimate for the linear\npart and suitable conditions on the non-linearity. We illustrate the strength\nof our abstract results by applying them to a one-dimensional wave equation\nwith weak non-linear damping and to an Euler-Bernoulli beam with a tip mass\nsubject to non-linear damping.", "AI": {"tldr": "The paper analyzes stability of semi-linear systems, establishing rational decay rates for classical solutions using non-uniform observability estimates and non-linearity conditions, with applications to wave equations and Euler-Bernoulli beams.", "motivation": "To develop a general framework for analyzing stability properties of semi-linear systems, particularly focusing on decay rates of solutions, which can be applied to various physical systems with non-linear damping.", "method": "The authors use abstract mathematical analysis of semi-linear systems, employing non-uniform observability estimates for the linear part and imposing suitable conditions on the non-linearity to establish decay properties.", "result": "The main result shows that classical solutions exhibit rational rates of decay under the specified conditions, demonstrating the effectiveness of the abstract framework through applications to one-dimensional wave equations with weak non-linear damping and Euler-Bernoulli beams with tip mass and non-linear damping.", "conclusion": "The abstract framework provides a powerful tool for analyzing stability and decay properties in semi-linear systems, with demonstrated applicability to important physical models involving non-linear damping mechanisms."}}
