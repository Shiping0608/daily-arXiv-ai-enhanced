<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 10]
- [math.AP](#math.AP) [Total: 17]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 3]
- [physics.ins-det](#physics.ins-det) [Total: 1]
- [cs.GR](#cs.GR) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [math.DS](#math.DS) [Total: 1]
- [gr-qc](#gr-qc) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A matrix-free convex limiting framework for continuous Galerkin methods with nonlinear stabilization](https://arxiv.org/abs/2509.04673)
*Dmitri Kuzmin,Hennes Hajduk,Joshua Vedral*

Main category: math.NA

TL;DR: A high-order continuous Galerkin method with nonlinear stabilization and invariant domain preservation using WENO-based artificial viscosity and convex limiting techniques.


<details>
  <summary>Details</summary>
Motivation: To develop a continuous Galerkin discretization that preserves invariant domains while maintaining high-order accuracy and shock-capturing capabilities for hyperbolic problems.

Method: Combines WENO-based smoothness sensor for artificial viscosity with adaptive convex limiting of nodal states using Bernstein polynomials and cell average constraints, adapting DG-WENO techniques to continuous setting.

Result: The method achieves invariant domain preservation under a time step restriction that can be weakened with flux limiting, with matrix-free and hardware-aware implementation.

Conclusion: The proposed element-based limiting strategy effectively preserves invariant domains in continuous Galerkin methods while maintaining computational efficiency and high-order accuracy.

Abstract: We equip a high-order continuous Galerkin discretization of a general
hyperbolic problem with a nonlinear stabilization term and introduce a new
methodology for enforcing preservation of invariant domains. The amount of
shock-capturing artificial viscosity is determined by a smoothness sensor that
measures deviations from a weighted essentially nonoscillatory (WENO)
reconstruction. Since this kind of dissipative stabilization does not guarantee
that the nodal states of the finite element approximation stay in a convex
admissible set, we adaptively constrain deviations of these states from
intermediate cell averages. The representation of our scheme in terms of such
cell averages makes it possible to apply convex limiting techniques originally
designed for positivity-preserving discontinuous Galerkin (DG) methods.
Adapting these techniques to the continuous Galerkin setting and using
Bernstein polynomials as local basis functions, we prove the invariant domain
preservation property under a time step restriction that can be significantly
weakened by using a flux limiter for the auxiliary cell averages. The close
relationship to DG-WENO schemes is exploited and discussed. All algorithmic
steps can be implemented in a matrix-free and hardware-aware manner. The
effectiveness of the new element-based limiting strategy is illustrated by
numerical examples.

</details>


### [2] [On convergence of upwinding Petrov-Galerkin methods for convection-diffusion](https://arxiv.org/abs/2509.04703)
*Constantin Bacuta*

Main category: math.NA

TL;DR: Analysis of upwinding Petrov-Galerkin methods for convection-diffusion problems with exact inverse matrix derivation and optimal error estimates.


<details>
  <summary>Details</summary>
Motivation: To develop efficient discretization methods for convection-diffusion problems that provide optimal approximation orders while avoiding complex exponential test functions.

Method: Special upwinding Petrov-Galerkin discretizations using exponential bubble test spaces in 1D, quadratic bubble method with scaling parameter, and extension to 2D with tensor product approach combining streamline upwinding with standard orthogonal discretizations.

Result: Derived exact inverse of discretization matrix, established optimal error estimates in L² and H¹ norms, achieved optimal approximation order in discrete infinity norm, and obtained optimal convergence on subdomains avoiding boundary layers in 2D.

Conclusion: The quadratic bubble upwinding method provides efficient and optimal discretization for convection-diffusion problems, with potential for extension to multidimensional convection-dominated models through tensor product approaches.

Abstract: We consider special upwinding Petrov-Galerkin discretizations for
convection-diffusion problems. For the one dimensional case with a standard
continuous linear element as the trial space and a special exponential bubble
test space, we prove that the Green function associated to the continuous
solution can generate the test space. In this case, we find a formula for the
exact inverse of the discretization matrix, that is used for establishing new
error estimates for other bubble upwinding Petrov-Galerkin discretizations. We
introduce a quadratic bubble upwinding method with a special scaling parameter
that provides optimal approximation order for the solution in the discrete
infinity norm. % while avoiding exponential test functions. Provided the linear
interpolant has standard approximation properties, we prove optimal
approximation estimates in $L^2$ and $H^1$ norms. The quadratic bubble method
is extended to a two dimensional convection diffusion problem. The proposed
discretization produces optimal $L^2$ and $H^1$ convergence orders on
subdomains that avoid the boundary layers. The tensor idea of using an
efficient upwinding Petrov-Galerkin discretization along each stream line
direction in combination with a standard discretizations for the orthogonal
direction(s) can lead to new and efficient discretization methods for
multidimensional convection dominated models.

</details>


### [3] [Solving Inverse Acoustic Obstacle Scattering Problem with Phaseless Far-Field Measurement Using Deep Neural Network Surrogates](https://arxiv.org/abs/2509.04747)
*Yuxin Fan,Jiho Hong,Bangti Jin*

Main category: math.NA

TL;DR: DNN surrogates for inverse acoustic scattering problems using phaseless far-field data, with theoretical approximation rates and Bayesian inference applications.


<details>
  <summary>Details</summary>
Motivation: To efficiently solve inverse acoustic scattering problems by developing accurate neural network surrogates that can handle variable coefficients and speed up Bayesian inference.

Method: Approximate forward maps from obstacle to far-field data using fully connected ReLU networks, analyze expression rates based on weak formulation, and validate with numerical experiments in 2D/3D.

Result: DNN surrogates accurately approximate forward maps and significantly accelerate Bayesian posterior exploration using MCMC in both 2D and 3D cases.

Conclusion: Deep neural networks serve as effective surrogates for inverse scattering problems, providing theoretical guarantees and practical computational benefits for Bayesian inference.

Abstract: In this work, we investigate the use of deep neural networks (DNNs) as
surrogates for solving the inverse acoustic scattering problem of recovering a
sound-soft obstacle from phaseless far-field measurements. We approximate the
forward maps from the obstacle to the far-field data using DNNs, and for
star-shaped domains in two and three dimensions, we establish the expression
rates for fully connected feedforward neural networks with the ReLU activation
for approximating the forward maps. The analysis is based on the weak
formulation of the direct problem, and can handle variable coefficients.
Numerically we validate the accuracy of the DNN surrogates of the forward maps,
and demonstrate the use of DNN surrogates in the Bayesian treatment of the
inverse obstacle scattering problem. Numerical experiments indicate that the
surrogates are effective in both two- and three-dimensional cases, and can
significantly speed up the exploration of the posterior distribution of the
shape parameters using Markov chain Monte Carlo.

</details>


### [4] [Filtering with Randomised Observations: Sequential Learning of Relevant Subspace Properties and Accuracy Analysis](https://arxiv.org/abs/2509.04867)
*Nazanin Abedini,Jana de Wiljes,Svetlana Dubinkina*

Main category: math.NA

TL;DR: Analysis of continuous ensemble Kalman filter performance under different observation scenarios with rigorous error bounds and an adaptive learning scheme for optimal subspace dimension selection.


<details>
  <summary>Details</summary>
Motivation: To improve state estimation by combining observational data with mathematical models, particularly examining how different observation strategies affect signal-tracking performance in ensemble Kalman filters.

Method: Rigorous mathematical analysis of continuous ensemble Kalman filtering under fixed, randomized, and adaptively varying partial observations, establishing error bounds relative to observation randomness, plus a sequential learning scheme for adaptive subspace dimension determination.

Result: Established rigorous bounds for expected signal-tracking error relative to observation operator randomness, and developed an adaptive scheme that balances observation complexity with estimation accuracy to ensure bounded filtering error.

Conclusion: The adaptive learning scheme provides both error control and a systematic approach to identifying the optimal filter-relevant subspace dimension, enhancing the performance and reliability of ensemble Kalman filtering for state estimation applications.

Abstract: State estimation that combines observational data with mathematical models is
central to many applications and is commonly addressed through filtering
methods, such as ensemble Kalman filters. In this article, we examine the
signal-tracking performance of a continuous ensemble Kalman filtering under
fixed, randomised, and adaptively varying partial observations. Rigorous bounds
are established for the expected signal-tracking error relative to the
randomness of the observation operator. In addition, we propose a sequential
learning scheme that adaptively determines the dimension of a state subspace
sufficient to ensure bounded filtering error, by balancing observation
complexity with estimation accuracy. Beyond error control, the adaptive scheme
provides a systematic approach to identifying the appropriate size of the
filter-relevant subspace of the underlying dynamics.

</details>


### [5] [Synthetic Acceleration Preconditioners for Parametric Radiative Transfer Equations based on Trajectory-Aware Reduced Order Models](https://arxiv.org/abs/2509.05001)
*Ning Tang,Zhichao Peng*

Main category: math.NA

TL;DR: A trajectory-aware reduced-order model framework for parametric radiative transfer equations that improves preconditioner efficiency by eliminating mismatch between offline and online residual trajectories.


<details>
  <summary>Details</summary>
Motivation: Classical synthetic acceleration preconditioners rely on empirical physical assumptions and don't leverage low-rank structures across parameters. Existing ROM-enhanced methods suffer from efficiency reduction due to preconditioner-dependence of residual trajectories.

Method: Iterative construction of reduced-order models that are trajectory-aware, eliminating the mismatch between offline and online residual trajectories in parametric radiative transfer problems.

Result: Numerical tests show superior efficiency over diffusion synthetic acceleration (DSA) and substantial gains in both efficiency and robustness over previous ROMSAD method. For parametric lattice problems, achieves rapid convergence within 2-3 iterations.

Conclusion: The trajectory-aware framework successfully addresses the limitations of previous methods by accounting for preconditioner-dependence, resulting in more efficient and robust reduced-order model preconditioners for parametric radiative transfer equations.

Abstract: The parametric radiative transfer equation (RTE) arises in multi-query
applications, such as design optimization, inverse problems, and uncertainty
quantification, which require solving the RTE multiple times for various
parameters. Classical synthetic acceleration (SA) preconditioners are designed
based on low-order approximations of a kinetic correction equation, e.g., its
diffusion limit in diffusion synthetic acceleration (DSA). Despite their
widespread success, these methods rely on empirical physical assumptions and do
not leverage low-rank structures across parameters of the parametric problem.
  To address these limitations, our previous work introduced a reduced-order
model (ROM) enhanced preconditioner called ROMSAD, which exploits low-rank
structures across parameters and the original kinetic description of the
correction equation. While ROMSAD improves overall efficiency compared with
DSA, its efficiency reduces after the first iteration, because the construction
of the underlying ROM ignores the preconditioner-dependence of the residual
trajectory, leading to a mismatch between the offline and online residual
trajectories.
  To overcome this issue, we introduce a trajectory-aware framework that
iteratively constructs ROMs to eliminate the mismatch between offline and
online residual trajectories. Numerical tests demonstrate superior efficiency
over DSA, and substantial gains in both efficiency and robustness over ROMSAD.
For a parametric lattice problem, trajectory-aware ROM preconditioners achieve
rapid convergence within only $2$-$3$ iterations online.

</details>


### [6] [Numerical approximations to statistical conservation laws for scalar hyperbolic equations](https://arxiv.org/abs/2509.05039)
*Qian Huang,Christian Rohde*

Main category: math.NA

TL;DR: Study of statistical conservation laws for PDFs/CDFs in scalar balance laws, showing dissipative anomaly in viscous terms and proposing sampling-based estimator for unclosed terms.


<details>
  <summary>Details</summary>
Motivation: Motivated by statistical description of turbulence to understand statistical conservation laws for joint probability density functions and cumulative distribution functions associated with solutions of scalar balance laws.

Method: Starting from viscous balance laws, analyze PDF/CDF equations with unclosed conditional averages. Propose novel sampling-based estimator constructed from numerical or exact realizations of balance-law solutions to approximate unclosed terms.

Result: Viscous terms exhibit dissipative anomaly - remain non-negligible in vanishing viscosity limit and essential for preserving PDF nonnegativity. Sampling-based approximation converges satisfactorily with number of samples in numerical experiments.

Conclusion: The sampling-based estimator provides a unified framework for approximating PDF/CDF equations, with a priori error bounds showing deviation between true and approximate CDFs is controlled by estimation error of unclosed terms.

Abstract: Motivated by the statistical description of turbulence, we study statistical
conservation laws in the form of kinetic-type PDEs for joint probability
density functions (PDFs) and cumulative distribution functions (CDFs)
associated with solutions of scalar balance laws. Starting from viscous balance
laws, the resulting PDF/CDF equations involve unclosed conditional averages
arising in the viscous terms. We show that these terms exhibit a dissipative
anomaly: they remain non-negligible in the vanishing viscosity limit and are
essential to preserve the nonnegativity of evolving PDFs. To approximate these
PDF/CDF equations in a unified framework, we propose a novel sampling-based
estimator for the unclosed terms, constructed from numerical or exact
realizations of the underlying balance-law solutions. In certain cases, a
priori error bounds can be derived, demonstrating that the deviation between
the true and approximate CDFs is controlled by the estimation error of the
unclosed terms. Numerical experiments with analytically solvable test problems
confirm that the sampling-based approximation converges satisfactorily with the
number of samples.

</details>


### [7] [Two Precision-controlled Numerical Algorithms for the CDF of Doubly Non-central Beta Distribution Based on the Segmentation of the Infinite Double Series Matrix](https://arxiv.org/abs/2509.05045)
*Han Li,Fangfang Ma,Junjie Wang,Yinhua Tian,Baoli Dai,Tianyan Dong*

Main category: math.NA

TL;DR: Two new numerical methods (DIV1 and DIV2) for computing the doubly non-central beta distribution CDF with automated error control and comparable computation times.


<details>
  <summary>Details</summary>
Motivation: Existing methods for non-central beta distribution allow error control, but no such methods exist for the doubly non-central beta distribution which requires handling infinite double series.

Method: Proposed DIV1 and DIV2 methods based on segmentation of the infinite double series, enabling automated calculations with error control parameters without pre-determining truncation range.

Result: Established upper bounds of errors for both methods, ensuring precision determinability. Both methods have comparable computational times.

Conclusion: The proposed methods provide the first automated numerical computation approach for doubly non-central beta distribution with controlled error bounds and efficient computation.

Abstract: The cumulative distribution function (CDF) of the doubly non-central beta
distribution can be expressed as an infinite double series. By truncating the
sum of this series, one can obtain an approximate value of the CDF. Although
numerous methods exist for calculating the non-central beta distribution, which
allow for the control of the truncation range and estimation of the
computational error, no such methods have been developed for the doubly
non-central beta distribution. In this paper, we propose two new numerical
computation methods based on the segmentation of the infinite double series,
termed DIV1 and DIV2. Both methods enable automated calculations once the error
control parameters are set; there is no need to predetermine the truncation
range, and their computational times are comparable. Following detailed
derivations, we have established the upper bounds of the errors for both
methods, thus ensuring the determinability of the precision.

</details>


### [8] [New Constructions of Cubature Formulas on Wiener Space](https://arxiv.org/abs/2509.05236)
*Timothy Herschell*

Main category: math.NA

TL;DR: First explicit construction of degree-7 cubature formula for Wiener space over R³, comparing stochastic Taylor expansion vs Log-ODE methods for SDE weak approximations.


<details>
  <summary>Details</summary>
Motivation: To develop explicit cubature formulas for Wiener space and examine different computational approaches for approximating solutions to stochastic differential equations.

Method: Building on Lyons-Victoir techniques, constructed degree-7 cubature formula, then compared stochastic Taylor expansion and Log-ODE methods through numerical experiments.

Result: Successfully created first explicit degree-7 cubature for R³ Wiener space, demonstrated how cubature degree affects convergence order, showed utility for SDE weak approximations.

Conclusion: Cubature methods are effective for weak SDE approximations, with construction techniques providing foundation for subsequent more general multidimensional work by other researchers.

Abstract: Building on techniques developed by Lyons and Victoir, we present the first
explicit construction of a degree-7 cubature formula for Wiener space over
$\mathbb{R}^3$. We then examine and compare two approaches for computing
cubature approximations: one based on the stochastic Taylor expansion and the
other on the Log-ODE method. Our numerical experiments illustrate how the
cubature degree influences the order of convergence and demonstrate the utility
of cubature methods for weak approximations of stochastic differential
equations (SDEs). These results were originally part of a Master's thesis and
are provided here as context and a reference point for subsequent work. A more
general construction in arbitrary dimensions has since been obtained by
Ferrucci, Herschell, Litterer and Lyons arXiv:2411.13707 using different
techniques.

</details>


### [9] [Uncertain but Useful: Leveraging CNN Variability into Data Augmentation](https://arxiv.org/abs/2509.05238)
*Inés Gonzalez-Pepe,Vinuyan Sivakolunthu,Yohan Chatelain,Tristan Glatard*

Main category: math.NA

TL;DR: DL training introduces variability through stochastic optimization, with FastSurfer showing higher variability than traditional methods. This variability can be harnessed for ensembles and data augmentation.


<details>
  <summary>Details</summary>
Motivation: To investigate the numerical stability and training-time variability of deep learning models in neuroimaging, particularly CNN-based segmentation pipelines like FastSurfer.

Method: Used FastSurfer CNN pipeline with controlled perturbations via floating point changes and random seeds to study training variability and create numerical ensembles.

Result: Found higher variability in DL compared to traditional methods, ensembles achieved similar performance to baseline, and variability can be repurposed for downstream applications like brain age regression.

Conclusion: Training-time variability is not just a reproducibility issue but can be leveraged as a resource to improve robustness and enable new neuroimaging applications.

Abstract: Deep learning (DL) is rapidly advancing neuroimaging by achieving
state-of-the-art performance with reduced computation times. Yet the numerical
stability of DL models -- particularly during training -- remains
underexplored. While inference with DL is relatively stable, training
introduces additional variability primarily through iterative stochastic
optimization. We investigate this training-time variability using FastSurfer, a
CNN-based whole-brain segmentation pipeline. Controlled perturbations are
introduced via floating point perturbations and random seeds. We find that: (i)
FastSurfer exhibits higher variability compared to that of a traditional
neuroimaging pipeline, suggesting that DL inherits and is particularly
susceptible to sources of instability present in its predecessors; (ii)
ensembles generated with perturbations achieve performance similar to an
unperturbed baseline; and (iii) variability effectively produces ensembles of
numerical model families that can be repurposed for downstream applications. As
a proof of concept, we demonstrate that numerical ensembles can be used as a
data augmentation strategy for brain age regression. These findings position
training-time variability not only as a reproducibility concern but also as a
resource that can be harnessed to improve robustness and enable new
applications in neuroimaging.

</details>


### [10] [Inverse problem for the Navier-Stokes equations and identification of immersed obstacles in the Mediterranean Sea](https://arxiv.org/abs/2509.05287)
*Mourad Hrizi,Marwa Ouni,Maatoug Hassine*

Main category: math.NA

TL;DR: Theoretical and numerical study of detecting objects in 3D Navier-Stokes fluid flow using localized velocity measurements, with a non-iterative topological derivative method.


<details>
  <summary>Details</summary>
Motivation: To solve the inverse problem of obstacle detection in fluid dynamics where only interior velocity measurements from a localized subregion are available, which has practical applications in ocean modeling and fluid systems.

Method: Formulated as shape optimization with nonlinear least-squares criterion and perimeter regularization. Developed non-iterative identification using topological derivative with asymptotic expansion computed via penalty method.

Result: Proved existence and stability of minimizer. Demonstrated robustness and effectiveness through numerical experiments using realistic Mediterranean ocean model (INSTMCOTRHD) with bathymetry, stratification, and forcing conditions.

Conclusion: The proposed non-iterative topological derivative method effectively identifies obstacles in 3D Navier-Stokes fluid flows using limited localized measurements, showing practical applicability in realistic ocean modeling scenarios.

Abstract: This paper presents a theoretical and numerical investigation of object
detection in a fluid governed by the three-dimensional evolutionary
Navier--Stokes equations. To solve this inverse problem, we assume that
interior velocity measurements are available only within a localized subregion
of the fluid domain. First, we present an identifiability result. We then
formulate the problem as a shape optimization task: to identify the obstacle,
we minimize a nonlinear least-squares criterion with a regularization term that
penalizes the perimeter of the obstacle to be identified. We prove the
existence and stability of a minimizer of the least-squares functional. To
recover the unknown obstacle, we present a non-iterative identification method
based on the topological derivative. The corresponding asymptotic expansion of
the least-squares functional is computed in a straightforward manner using a
penalty method. Finally, as a realistic application, we demonstrate the
robustness and effectiveness of the proposed non-iterative procedure through
numerical experiments using the INSTMCOTRHD ocean model, which incorporates
realistic Mediterranean bathymetry, stratification, and forcing conditions.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [11] [Integral formulas for under/overdetermined differential operators via recovery on curves and the finite-dimensional cokernel condition I: General theory](https://arxiv.org/abs/2509.04617)
*Philip Isett,Yuchen Mao,Sung-Jin Oh,Zhongkai Tao*

Main category: math.AP

TL;DR: New method for constructing solution operators for underdetermined PDEs and integral representation formulas for overdetermined PDEs with prescribed support properties, using a recovery on curves condition and finite-dimensional cokernel condition.


<details>
  <summary>Details</summary>
Motivation: To develop a versatile approach for constructing regularizing solution operators for underdetermined PDEs and representation formulas for overdetermined PDEs with specific support properties, generalizing previous constructions.

Method: Introduces recovery on curves condition (RC) leading to Green's functions supported on curves, then obtains integral operators through smooth averages over curve families. Identifies algebraic sufficient condition (FC) - principal symbol full-rank for non-zero complex vectors.

Result: Method applies to various operators including divergence, gradient, Hessian, Killing operators, etc. Provides optimal order regularization and Poincaré/Korn-type inequalities through duality.

Conclusion: The approach generalizes previous constructions and provides a unified framework for handling both underdetermined and overdetermined PDE systems with prescribed support properties.

Abstract: We introduce a new versatile method for constructing solution operators
(i.e., right-inverses up to a finite rank operator) for a wide class of
underdetermined PDEs $P u = f$, which are regularizing of optimal order and,
more interestingly, whose integral kernels have certain prescribed support
properties. By duality, we simultaneously obtain integral representation
formulas (i.e., left-inverses up to a finite rank operator) for overdetermined
PDEs $P^{\ast} v = g$ with analogous properties, which lead to Poincar\'e- or
Korn-type inequalities. Our method applies to operators such as the divergence,
linearized scalar curvature, and linearized Einstein constraint operators
(which are underdetermined), as well as the gradient, Hessian, trace-free part
of the Hessian, Killing, and conformal Killing operators (which are
overdetermined).
  The starting point for our construction is a condition - dubbed the recovery
on curves condition (RC) - that leads to Green's functions for $P$ supported on
prescribed curves. Then the desired integral solution operators (and, by
duality, integral representation formulas) are obtained by taking smooth
averages over a suitable family of curves. This procedure generalizes the
previous constructions of Bogovskii, Oh-Tataru, and Reshetnyak. We furthermore
identify a simple algebraic sufficient condition for (RC), namely, that the
principal symbol $p(x, \xi)$ of $P$ is full-rank for all non-zero complex
vectors $\xi$ (as opposed to real, as in ellipticity). When the principal
symbol has constant coefficients, this is equivalent to (RC) and also to the
condition that the formal cokernel of $P$ (without any boundary conditions) is
finite-dimensional; for this reason, we call it the finite-dimensional cokernel
condition (FC). We give a short proof that all operators above satisfy (FC),
and thus (RC).
  Various applications will be considered in subsequent papers.

</details>


### [12] [Mean Field Games of Controls with Fractional Laplacian](https://arxiv.org/abs/2509.04647)
*P. Jameson Graber,Elizabeth Matter,Jesus Ruiz Bolanos*

Main category: math.AP

TL;DR: Existence of solutions for fractional mean field game of controls with fractional Laplacian order s ∈ (1/2,1), using Lasry-Lions monotonicity and Leray-Schauder fixed point theorem.


<details>
  <summary>Details</summary>
Motivation: To establish existence of solutions for fractional mean field games where the running cost depends on both state distributions and optimal strategies, extending classical results to fractional settings.

Method: Derived three types of a priori estimates: moment estimates via monotonicity, abstract estimates on fractional parabolic equations, and time regularity estimates via Lévy process analysis. Applied Leray-Schauder fixed point theorem.

Result: Successfully established existence of solutions for the fractional mean field game system when the fractional Laplacian order is in (1/2,1).

Conclusion: The paper provides a rigorous framework for analyzing fractional mean field games of controls, demonstrating solution existence under appropriate conditions and offering new analytical tools for such systems.

Abstract: We analyze a fractional mean field game of controls system, showing existence
of solutions when the order of the fractional Laplacian is
$s\in(\frac{1}{2},1)$. Here the running cost depends on the distribution $\mu$
of not only the states but also optimal strategies. The coupling is assumed to
satisfy the Lasry-Lions monotonicity condition. We derive three types of a
priori estimates on solutions. First, we use the monotonicity condition to
derive moment estimates on $\mu$. Second, we derive abstract estimates on
fractional parabolic equations and apply them to the mean field game. Third, we
derive new estimates on the time regularity of the distribution $\mu$ by
analyzing the associated L\'evy process. We apply these estimates and the
Leray-Schauder fixed point theorem to establish existence of solutions.

</details>


### [13] [A Characterization of Solvability of the Parabolic $L^p$ Dirichlet Problem on Lipschitz Graph Domains Via Carleson Measure Estimates of Bounded Solutions](https://arxiv.org/abs/2509.04701)
*James Warta,Steve Hofmann*

Main category: math.AP

TL;DR: Parabolic Dirichlet problem solutions satisfying Carleson measure estimate imply A∞ parabolic measure, equivalent to Lp solvability, improving previous results requiring additional rectifiability assumptions.


<details>
  <summary>Details</summary>
Motivation: To establish a connection between Carleson measure estimates for bounded solutions and the A∞ property of parabolic measure, eliminating the need for additional parabolic uniform rectifiability conditions.

Method: Analysis of bounded solutions to parabolic Dirichlet problems on Lipshitz-[1,1/2] domains, examining Carleson measure estimates and their implications for parabolic measure properties.

Result: Shows that Carleson measure estimate for bounded solutions implies parabolic measure belongs to A∞ class, which is equivalent to Lp solvability for some finite p.

Conclusion: This work provides an improved characterization of parabolic measure properties by removing previous requirements for parabolic uniform rectifiability or half-order time derivative conditions on boundary-defining functions.

Abstract: In this paper, we show that if the bounded solutions to the parabolic
Dirichlet problem on a Lipshitz-$\left[1,\frac{1}{2}\right]$ domain obey a
Carleson measure estimate, then the corresponding parabolic measure on the
boundary will belong to class $A^\infty$, which is equivalent to $L^p$
solvability for some $p<\infty$. This improves the existing literature which
places additional assumptions on the parabolic uniform rectifiability or,
equivalently, on the half-order time derivative of the function whose graph
defines the boundary of the domain.

</details>


### [14] [Stability and Self-Organized Patterns in Coupled Ecohydrological--Fire Dynamics: A Model of Vegetation--Rainfall--Bushfire Interactions](https://arxiv.org/abs/2509.04766)
*Serena Dipierro,Enrico Valdinoci*

Main category: math.AP

TL;DR: Analysis of pattern stability in a three-component reaction-diffusion system modeling water, vegetation, and bushfire interactions, revealing novel stabilization mechanisms different from classical Turing/Hopf bifurcations.


<details>
  <summary>Details</summary>
Motivation: To understand pattern formation and stability conditions in ecosystems where water reservoirs, vegetation, and bushfire activity coexist and interact through reaction-diffusion processes.

Method: Performed detailed stability analysis to identify parameter spaces where homogeneous equilibrium becomes stable against spatial perturbations, and used diffusion to generate traveling periodic orbits from linearized system analysis.

Result: Found that diffusion stabilizes rather than destabilizes homogeneous equilibria, with patterns emerging from nonsingular eigenvalue crossings while maintaining linear stability for monochromatic waves. Also identified Turing instability for slow-frequency oscillations in low rainfall regimes with plant competition.

Conclusion: The system exhibits unique pattern formation mechanisms distinct from classical Turing and Hopf bifurcations, where diffusion plays a stabilizing role rather than destabilizing, and plant competition enables Turing instability in specific rainfall conditions.

Abstract: This paper investigates the conditions for the stability and emergence of
patterns in a new three-component reaction-diffusion system. The system
describes the coexistence and interaction of water reservoirs, vegetation, and
bushfire activity in a given ecosystem.
  We perform a detailed stability analysis to determine the parameter space
where an unstable homogeneous equilibrium becomes stable with respect to
spatially nonuniform perturbations.
  We also use diffusion to generate traveling trains in the form of periodic
orbits of the linearized system. These orbits are remnants of an unstable
equilibrium in the absence of diffusion and arise from a nonsingular eigenvalue
crossing of the imaginary axis, while a third eigenvalue remains real and
negative, thereby ensuring linear stability for monocromatic waves.
  These phenomena differ from ``classical'' Turing and Hopf bifurcations, as
the model does not involve distinct ``activators'' and ``inhibitors'', and the
effects observed are not the byproduct of diffusion with necessarily differing
speeds. Also, differently from the classical Turing pattern, the role of
diffusion in this context is to stabilize, rather than destabilize, homogeneous
equilibria.
  We also consider the case of plant competition, showing a suitable form of
Turing instability for slow-frequency oscillations in a small rainfall regime.

</details>


### [15] [Regularity and existence for a mixed local-nonlocal parabolic equation with variable singularities and measure data](https://arxiv.org/abs/2509.04797)
*Stuti Das*

Main category: math.AP

TL;DR: Existence, non-existence, regularity and asymptotic behavior of weak solutions for mixed local-nonlocal parabolic problems with singular nonlinearities and measure data, including variable singular exponents.


<details>
  <summary>Details</summary>
Motivation: Extend previous works by including variable singular exponents and handling measure-valued data where source terms can simultaneously be measures, addressing a new phenomenon even for constant singular exponents with local operators.

Method: Analysis of mixed local-nonlocal parabolic problems involving singular nonlinearities and measure data, examining both purely singular and perturbed singular cases with measure-valued source terms.

Result: Proves existence, non-existence, regularity and asymptotic behavior of weak solutions for the described class of problems, with results applicable to purely local operators as well.

Conclusion: The work provides comprehensive analysis of mixed local-nonlocal parabolic problems with singularities and measure data, introducing novel treatment of variable singular exponents and simultaneous measure-valued source terms, extending results to purely local operators.

Abstract: This article proves the existence, non-existence, regularity and asymptotic
behavior of weak solutions for a class of mixed local-nonlocal parabolic
problems involving singular nonlinearities and measure data extending the works
of \cite{sanjitgarain,lazermc}. A central contribution of this work is the
inclusion of a variable singular exponent. We examine both the purely singular
and perturbed singular cases in the context of measure-valued data, where the
source terms can simultaneously take the form of measures. To the best of our
knowledge, this phenomenon is new, even in the case of a constant singular
exponent involving only a local operator. Further, all our results are also
true for the operator being local only.

</details>


### [16] [Determining a parabolic-elliptic-elliptic system by boundary observation of its non-negative solutions under chemotaxis background](https://arxiv.org/abs/2509.04850)
*Yuhan Li,Hongyu Liu,Catharine W. K. Lo*

Main category: math.AP

TL;DR: Unique identification of unknown coefficients in coupled nonlinear mixed parabolic-elliptic-elliptic systems using boundary measurements, with application to attraction-repulsion chemotaxis models.


<details>
  <summary>Details</summary>
Motivation: Addresses an unexplored inverse problem in mathematical biology with practical importance for studying cellular processes through chemotaxis modeling, where conventional methods fail due to the system's mixed-type nature and complexity.

Method: Develops a complete theoretical framework with rigorous unique identifiability results that establish one-to-one correspondence between boundary data and model parameters, overcoming analytical complications from parabolic-elliptic coupling and nonlinear structure.

Result: Establishes unique identifiability for the challenging inverse problem and demonstrates full parameter recovery for attraction-repulsion chemotaxis model with logistic growth.

Conclusion: Provides foundational theoretical framework for quantitative analysis in mathematical biology, opening new avenues for parameter identification in complex mixed-type systems using boundary measurements.

Abstract: This paper addresses a profoundly challenging inverse problem that has
remained largely unexplored due to its mathematical complexity: the unique
identification of all unknown coefficients in a coupled nonlinear system of
mixed parabolic-elliptic-elliptic type using only boundary measurements. The
system models attraction-repulsion chemotaxis--an advanced mathematical biology
framework for studying sophisticated cellular processes--yet despite its
significant practical importance, the corresponding inverse problem has never
been investigated, representing a true frontier in the field. The mixed-type
nature of this system introduces significant theoretical difficulties that
render conventional methodologies inadequate, demanding fundamental extensions
beyond existing techniques developed for simpler, purely parabolic models.
Technically, the problem presents formidable obstacles: the coupling between
parabolic and elliptic components creates inherent analytical complications,
while the nonlinear structure resists standard approaches. From an applied
perspective, the biological relevance adds another layer of complexity, as
solutions must maintain physical interpretability through non-negativity
constraints. Our work provides a complete theoretical framework for this
challenging problem, establishing rigorous unique identifiability results that
create a one-to-one correspondence between boundary data and the model's
parameters. We demonstrate the power of our general theory through a central
biological application: the full parameter recovery for an attraction-repulsion
chemotaxis model with logistic growth, thus opening new avenues for
quantitative analysis in mathematical biology.

</details>


### [17] [Spectral scheme for an energetic Fokker-Planck equation with $κ$-distribution steady states](https://arxiv.org/abs/2509.04911)
*Hugo Parada,Claudia Negulescu*

Main category: math.AP

TL;DR: Efficient spectral methods for Fokker-Planck equations modeling energetic particles in fusion plasmas, using rational Chebyshev and Gram-Schmidt orthogonalized polynomial bases to handle non-Maxwellian κ-distributions with algebraic decay.


<details>
  <summary>Details</summary>
Motivation: To develop numerical schemes for simulating energetic particle dynamics in thermonuclear fusion plasmas (like runaway electrons) where velocity distributions approach κ-distributions that decay algebraically rather than exponentially, requiring specialized basis functions beyond traditional Hermite polynomials.

Method: Two spectral methods: 1) Based on rational Chebyshev basis functions instead of Hermite polynomials, 2) Using polynomial basis constructed via Gram-Schmidt orthogonalization process, both specifically designed for κ-distributions.

Result: The proposed methods are designed to efficiently handle the long-time asymptotics of non-equilibrium κ-distributions without significant numerical costs, overcoming limitations of traditional Maxwellian-optimized approaches.

Conclusion: These specialized spectral schemes provide efficient numerical solutions for Fokker-Planck equations describing suprathermal particle populations in fusion plasmas, particularly well-suited for the algebraic decay characteristics of κ-distributions.

Abstract: The concern of the present paper is the design of efficient numerical schemes
for a specific Fokker-Planck equation describing the dynamics of energetic
particles occurring in thermonuclear fusion plasmas (runaway electrons for
example). In the long-time limit, the velocity distribution function of these
particles tends towards a thermal non-equilibrium $\kappa$-distribution
function which is a steady-state of the considered Fokker-Planck equation.
These $\kappa$-distribution functions have the particularity of being only
algebraically decaying for large velocities, thus describing very well
suprathermal particle populations. Our aim is to present two efficient spectral
methods for the simulation of such energetic particle dynamics. The first
method will be based on rational Chebyshev basis functions, rather than on
Hermite basis sets, which are the basis of choice for Maxwellian steady states.
The second method is based on a different polynomial basis set, constructed via
the Gram-Schmidt orthogonalisation process. These two new spectral schemes,
specifically adapted to the here considered physical context, shall permit to
cope with the long-time asymptotics without significant numerical costs.

</details>


### [18] [Blowup of solutions for compressible viscoelastic fluid](https://arxiv.org/abs/2509.04924)
*Sébastien Boyaval,Na Wang,Yuxi Hu*

Main category: math.AP

TL;DR: Finite-time blowup proven for compressible Upper Convective Maxwell viscoelastic fluids using energy identity and Sideris' method adaptation.


<details>
  <summary>Details</summary>
Motivation: To establish the first rigorous blowup result for multidimensional compressible viscoelastic fluid systems, addressing a gap in understanding their finite-time singularity formation.

Method: Established a key energy identity and adapted Sideris' method for compressible flows to derive a Riccati-type inequality for a momentum functional.

Result: For initial data with compactly supported perturbations satisfying sufficiently large conditions, all classical solutions lose regularity in finite time.

Conclusion: This work provides the first rigorous proof of finite-time blowup in multidimensional compressible viscoelastic fluids, demonstrating singularity formation under specific initial conditions.

Abstract: We prove finite-time blowup of classical solutions for the compressible Upper
Convective Maxwell (UCM) viscoelastic fluid system. By establishing a key
energy identity and adapting Sideris' method for compressible flows, we derive
a Riccati-type inequality for a momentum functional. For initial data with
compactly supported perturbations satisfying a sufficiently large condition,
all classical solutions lose regularity in finite time. This constitutes the
first rigorous blowup result for multidimensional compressible viscoelastic
fluids.

</details>


### [19] [Existence and non-existence of minimizers for a multi-particle model with concave nonlinearity](https://arxiv.org/abs/2509.04952)
*David Gontier,Salma Lahbabi,Simona Rota Nodari*

Main category: math.AP

TL;DR: Multi-particle model with kinetic energy and nonlinear local self-interaction studied for bosonic and fermionic cases. Model is well-posed for large enough particle numbers, with specific nonlinearity where N=2 is well-posed but N=1 is not.


<details>
  <summary>Details</summary>
Motivation: To understand the well-posedness of quantum models with nonlinear local self-interactions in both bosonic and fermionic systems, particularly examining how particle number affects model stability.

Method: Mathematical analysis of multi-particle quantum models with kinetic energy terms and nonlinear local self-interactions, examining both bosonic and fermionic cases through theoretical proofs.

Result: Proved that the model is well-posed when the number of particles is sufficiently large. Found a specific nonlinearity where the model with 2 particles is well-posed, while the single-particle case is not well-posed.

Conclusion: Particle number plays a crucial role in the well-posedness of quantum models with nonlinear self-interactions, with multi-particle systems exhibiting stability properties that single-particle systems lack for certain nonlinearities.

Abstract: We study a multi--particle model including a kinetic energy and a non linear
local self-interaction, both in the bosonic and fermionic cases. In both cases,
we prove that the model is well-posed if the number of particles is large
enough. In particular, we show that there is a nonlinearity for which the model
with $N=2$ particles is well-posed, while the model with $N=1$ is not.

</details>


### [20] [A Formal Derivation of the Thick Spray Model from the Enskog-Boltzmann System](https://arxiv.org/abs/2509.05118)
*Zhe Chen*

Main category: math.AP

TL;DR: Formal derivation of Euler-Vlasov model for thick sprays from Boltzmann-Enskog equations, identifying higher-order viscous corrections related to dispersed phase volume.


<details>
  <summary>Details</summary>
Motivation: To validate the kinetic-fluid equations used in engineering for thick sprays and identify neglected higher-order corrections in the viscous force that arise from volume fraction considerations.

Method: Proposes a specific scaling approach that formally derives the Euler-Vlasov model from the Boltzmann-Enskog model, building on previous work that connected Boltzmann equations for binary mixtures to Vlasov-Euler systems for thin sprays.

Result: Successfully derives the Euler-Vlasov model for thick sprays and identifies higher-order corrections to the viscous force that are of the order of the dispersed phase volume, which are typically neglected due to the volume fraction function.

Conclusion: The work provides a formal validation of the kinetic-fluid equations for thick sprays while revealing important higher-order viscous corrections that should be considered for more accurate modeling of dispersed phase systems.

Abstract: We propose a specific scaling that formally derives the Euler-Vlasov model
for thick sprays which is widely adopted in engineering from the
Boltzmann-Enskog model. Beyond validating the kinetic-fluid equations
underlying this model, we also identify higher-order corrections of the viscous
force (of the order of the volume of the dispersed phase), which is neglected
due to the incorporation of the volume fraction (void) function. Our approach
builds on the work [Laurent Desvillettes, Fran\c{c}ois Golse, and Valeria
Ricci. A formal passage from a system of Boltzmann equations for mixtures
towards a Vlasov-Euler system of compressible fluids. Acta Mathematicae
Applicatae Sinica, English Series, 35(1):158-173, Jan 2019.], who formally
connected a system of coupled Boltzmann equations for binary mixtures to a
Vlasov-Euler system for thin sprays.

</details>


### [21] [Serrin's overdetermined theorem within Lipschitz domains](https://arxiv.org/abs/2509.05155)
*Hongjie Dong,Yi Ru-Ya Zhang*

Main category: math.AP

TL;DR: The paper proves that a Lipschitz domain satisfies a Serrin-type overdetermined system with anisotropic Laplacian if and only if the domain is homothetic to the given ellipsoid K.


<details>
  <summary>Details</summary>
Motivation: To establish necessary and sufficient conditions for Lipschitz domains to satisfy anisotropic overdetermined boundary value problems, extending classical Serrin-type results to anisotropic settings.

Method: Uses weak formulation of the anisotropic Laplacian and Hausdorff measures, working under L^2-Dini-VMO and non-degeneracy conditions on the gradient near the boundary.

Result: Shows equivalence: the overdetermined system holds weakly if and only if the domain is homothetic to the given ellipsoid K.

Conclusion: Provides an alternative proof for Lipschitz domains and settles a specific question about anisotropic overdetermined problems, with special Euclidean case implications.

Abstract: Let $\Omega\subset\mathbb R^n$ be a Lipschitz domain, $K$ be a (bounded)
ellipsoid centered at the origin and $H$ be the associated Wulff potential. We
prove that, % under a $L^2$-Dini-VMO condition and a non-degeneracy condition
on $|Du|$ near the boundary, $\Omega$ satisfies the following Serrin-type
overdetermined system
  $$u \in W^{1,2}(\mathbb R^n), \quad u=0\ \text{ a.e. in }\R^n\setminus
\Omega,\quad \Delta_H u=\mathbf{c}\mathscr{H}^{n-1}|_{\partial^*\Omega} -
\mathbf{1}_{\Omega}\,dx,$$
  in the weak sense if and only if $\Omega$ is homothetic to $K$. Here
$\Delta_H$ denotes the anisotropic Laplacian associated to $H$, and $\mathscr
H^{n-1}$ denotes the $(n-1)$-dimensional Hausdorff measure. % Furthermore, the
two conditions on $|Du|$ become redundant when $\Delta_H$ reduces to the
standard Euclidean Laplacian. Our approach offers an alternative proof to [11]
in the case of Lipschitz domains, introducing a novel viewpoint to settle [13,
Question 7.1].

</details>


### [22] [Saddle Point Configurations for Spherical Ferromagnets](https://arxiv.org/abs/2509.05159)
*Stephen Gustafson,Daniel Meinert,Christof Melcher*

Main category: math.AP

TL;DR: Existence of two distinct saddle point configurations in spherical ferromagnets with perpendicular anisotropy, using parabolic flow approach to obtain solutions of Euler-Lagrange equations.


<details>
  <summary>Details</summary>
Motivation: To investigate saddle point configurations in spherical ferromagnets and understand the emergence of curvature induced Dzyaloshinskii-Moriya interaction, contrasting with harmonic maps between two-spheres where every map is a local minimizer.

Method: Parabolic flow approach inspired by harmonic map heat flow, using highly symmetric initial conditions to rule out finite and infinite time blowup, obtaining solutions in the long time limit.

Result: Established existence of two distinct types of saddle points with zero mapping degree in the micromagnetic energy functional on the unit sphere.

Conclusion: The study reveals fundamental differences in energy landscape between micromagnetic systems and harmonic maps, demonstrating successful application of parabolic flow methods to obtain saddle point solutions.

Abstract: We investigate saddle point configurations in spherical ferromagnets with
perpendicular anisotropy. These are modeled by a micromagnetic energy
functional on the unit sphere that leads to the emergence of the so-called
curvature induced Dzyaloshinskii--Moriya interaction. For this functional we
establish the existence of two distinct types of saddle points with zero
mapping degree. We use a parabolic flow approach inspired by the harmonic map
heat flow where for certain highly symmetric initial conditions we can rule out
finite and infinite time blowup. Hence, we obtain solutions of the underlying
Euler--Lagrange equation in the long time limit. This is in contrast to
harmonic maps between two-spheres, where every map is a local minimizer of the
energy functional.

</details>


### [23] [A Gutzwiller trace formula for singular potentials](https://arxiv.org/abs/2509.05220)
*Jared Wunsch,Mengxuan Yang,Yuzhou Joey Zou*

Main category: math.AP

TL;DR: Generalization of Gutzwiller trace formula to non-smooth potentials with derivative discontinuities, incorporating partial reflection effects through branching dynamics.


<details>
  <summary>Details</summary>
Motivation: Extend the Gutzwiller trace formula beyond smooth potentials to handle cases with derivative discontinuities where partial energy reflection occurs, which is common in realistic physical systems.

Method: Develop a mathematical framework that accounts for branching dynamics from derivative discontinuities, analyzing periodic trajectories in this generalized setting to derive asymptotic spacing contributions.

Result: Obtained a precise description of how periodic trajectories in the branching dynamics contribute to trace asymptotics for non-smooth potentials with derivative discontinuities.

Conclusion: Successfully generalized the Gutzwiller trace formula to non-smooth potentials, providing a complete framework for analyzing quantum energy level spacing in systems with partial reflection from potential discontinuities.

Abstract: The Gutzwiller trace formula relates the asymptotic spacing of
quantum-mechanical energy levels in the semiclassical limit to the dynamics of
periodic classical particle trajectories. We generalize this result to the case
of non-smooth potentials, for which there is partial reflection of energy from
derivative discontinuities of the potential. It is the periodic trajectories of
an associated branching dynamics that contribute to the trace asymptotics in
this more general setting; we obtain a precise description of their
contribution.

</details>


### [24] [Abstract Volterra integral equations of wave type with almost sectorial operators](https://arxiv.org/abs/2509.05229)
*Joel E. Restrepo*

Main category: math.AP

TL;DR: Analysis of classical solutions for abstract Volterra integral equations of wave type with almost sectorial operators using functional calculus to construct propagators.


<details>
  <summary>Details</summary>
Motivation: To establish existence, uniqueness, and explicit solution operators for homogeneous, linear, and semilinear abstract Volterra integral equations of wave type with almost sectorial operators.

Method: Using functional calculus for almost sectorial operators to construct a general class of bounded linear operators that contain the propagators (solution operators) of the considered equations.

Result: Development of a general class of bounded linear operators that serve as propagators for the equations, along with analysis of their properties.

Conclusion: The functional calculus approach successfully provides solution operators for abstract Volterra integral equations of wave type with almost sectorial operators, establishing classical solution theory.

Abstract: We study classical solutions (existence, uniqueness, and explicit solution
operator) for homogeneous, linear, and semilinear abstract Volterra integral
equations of wave type with almost sectorial operators. We use a functional
calculus for the latter type of operators to construct a general class of
bounded linear operators that in particular contains the propagators (solution
operators) of the considered equations. Some properties of this family of
operators are also given.

</details>


### [25] [Geometry of wave damping on the torus](https://arxiv.org/abs/2509.05239)
*Kiril Datchev,Perry Kleinhenz,Antoine Prouff*

Main category: math.AP

TL;DR: This paper refines energy decay rate estimates for damped waves on the torus by introducing the concept of 'order of a glancing undamped point' and showing how decay rates depend on this geometric property.


<details>
  <summary>Details</summary>
Motivation: To provide more precise estimates of energy decay rates for damped waves by better understanding the geometric relationship between the damping region and undamped points, particularly focusing on glancing behavior.

Method: Generalizing an averaging argument originally developed by Sun, and introducing the concept of 'order of a glancing undamped point' to quantify geometric properties of the damped set.

Result: The authors establish refined decay rate estimates in terms of the order of glancing undamped points and demonstrate that damping sets achieving these improved rates are generic among polygons and smooth curves.

Conclusion: The geometric considerations of damping sets, particularly the order of glancing undamped points, significantly influence energy decay rates, and optimal damping configurations are common in both polygonal and smooth curve settings.

Abstract: Energy decay rates of damped waves on the torus depend on the behavior of the
damping near the undamped region and on the geometry of the damped set. In this
paper we refine these geometric considerations, by introducing the concept of
order of a glancing undamped point, and estimating decay rates in terms of this
order. The proof is based on generalizing an averaging argument due to Sun. We
also show that damping sets which attain these improvements are generic among
polygons and smooth curves.

</details>


### [26] [Compactness for the Hardy-Sobolev equation on manifolds](https://arxiv.org/abs/2509.05255)
*Hussein Cheikh Ali,Saikat Mazumdar*

Main category: math.AP

TL;DR: Uniform bounds for solutions to critical Hardy-Sobolev equations on closed Riemannian manifolds with coercive operators, under optimal curvature conditions.


<details>
  <summary>Details</summary>
Motivation: To establish uniform bounds on solutions of critical Hardy-Sobolev equations on Riemannian manifolds without assuming energy or Sobolev norm bounds, addressing optimal curvature conditions.

Method: Analysis of solutions to the critical Hardy-Sobolev equation Δ_g u + hu = u^(2(n-s)/(n-2)-1 / d_g(x_0,x)^s on closed Riemannian manifolds with coercive operators, under specific curvature conditions at the singular point x_0.

Result: Obtained uniform bounds on solutions under the conditions: h(x_0) < (n-2)(6-s)/(12(2n-2-s))Scal_g(x_0) for n≥4, and h≤1/8Scal_g, h(x_0)<1/8Scal_g(x_0) for n=3.

Conclusion: The curvature conditions introduced are optimal and sufficient to obtain uniform bounds for solutions to critical Hardy-Sobolev equations, extending previous results and validating the optimality of these conditions.

Abstract: Let $(M, g)$ be a closed Riemannian manifold of dimension $n \geq 3$, and let
$h \in C^1(M)$ be such that the operator $\Delta_g + h$ is coercive. Fix $x_0
\in M$ and $s \in (0, 2)$. We obtain uniform bounds on the solutions of the
critical \emph{Hardy-Sobolev equation}: \begin{equation}\label{HS0}
\tag{{\color{MainRed}HS}} \left\{\begin{array}{ll} \Delta_{g}u + hu =
\frac{u^{\crits-1}}{d_{g}(\xo,x)^{s}} & \hbox{ in }M\setminus\{\xo\}, \\ \qquad
u > 0 &\hbox{ in }M\setminus\{\xo\}, \end{array}\right. \end{equation} where
$\Delta_{g}:=-\diver_{g}(\nabla)$ and $\crits:=2(n-s)/(n-2)$. More precisely,
we assume $h(x_0)<\frac{(n-2)(6-s)}{12(2n-2-s)}\mathrm{Scal}_g(x_0),$ when $n
\geq 4$, and $h\le\frac{1}{8}\sg$, $h(\xo)<\frac{1}{8}\sg(\xo)$ when $n = 3$.
Here, $\mathrm{Scal}_g$ denotes the scalar curvature of $(M, g)$. These
conditions were introduced in \cite{HCA4}, and shown to be optimal in
\cite{CAR} for a single bubble configuration when $n\ge7$ .
  \noindent We do not assume any bounds on the energy or the Sobolev norm of
the solutions.

</details>


### [27] [Existence and Non-existence for Continuous Generalized Exchange-Driven Growth model](https://arxiv.org/abs/2509.05262)
*Chun Yin Lam,André Schlichting*

Main category: math.AP

TL;DR: Existence and uniqueness results for continuous generalized exchange-driven growth model with superlinear kernels, plus non-existence results for rapidly growing kernels via gelation phenomena.


<details>
  <summary>Details</summary>
Motivation: The CGEDG model describes cluster evolution through binary mass exchanges, relevant for droplet formation, migration dynamics, and asset exchanges. It generalizes Smoluchowski equations but requires rigorous mathematical analysis of solution existence for various kernel types.

Method: Mathematical analysis of the coagulation-fragmentation equation, examining kernels with superlinear growth at infinity and singularity at origin. Used techniques to prove solution existence/uniqueness and demonstrated non-existence via finite-time and instantaneous gelation through moment blow-up analysis.

Result: Proved existence and uniqueness of solutions for kernels with superlinear growth and singularity. Showed non-existence of solutions for kernels with sufficiently rapid growth, demonstrated through finite-time gelation and instantaneous gelation phenomena.

Conclusion: The study establishes rigorous mathematical foundations for the CGEDG model, providing existence/uniqueness results for certain kernel classes while identifying limitations through gelation phenomena for rapidly growing kernels.

Abstract: The continuous generalized exchange-driven growth model (CGEDG) is a
coagulation-fragmentation equation that describes the evolution of the
macroscopic cluster size distribution induced by a microscopic dynamic of
binary exchanges of masses between clusters. It models droplet formation,
migration dynamics, and asset exchanges in various scientific and
socio-economic contexts. It can also be viewed as a generalization of the
continuous Smoluchowski equations. In this work, we show the existence and
uniqueness of solutions for kernels with superlinear growth at infinity and
singularity at the origin and show the non-existence of solutions for kernels
with sufficiently rapid growth. The latter result is shown via the finite-time
gelation and instantaneous gelation in the sense of moment blow-up.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [28] [Deep learning for the semi-classical limit of the Schrödinger equation](https://arxiv.org/abs/2509.04453)
*Jizu Huang,Rukang You,Tao Zhou*

Main category: physics.comp-ph

TL;DR: Neural networks combined with Gaussian wave packets solve Schrödinger equation in semi-classical limit, achieving high accuracy with MscaleDNNs and operator learning via physics-informed DeepONets.


<details>
  <summary>Details</summary>
Motivation: To accurately solve the Schrödinger equation with smooth potentials near the semi-classical limit (ε small) and construct an operator that maps initial values to solutions with multiscale properties.

Method: Reformulate Schrödinger equation as ODE system using Gaussian wave packets. Use PINNs or MscaleDNNs for single initial conditions, and physics-informed DeepONets for operator learning with multiple initial conditions.

Result: MscaleDNNs outperform PINNs, improving accuracy by 1-2 orders of magnitude. Physics-informed DeepONets with Gaussian wave packets effectively map initial conditions to solutions.

Conclusion: The integration of neural networks with Gaussian wave packets provides an effective framework for solving multiscale Schrödinger equations, with MscaleDNNs showing superior performance and DeepONets enabling efficient operator learning.

Abstract: In this paper, we integrate neural networks and Gaussian wave packets to
numerically solve the Schr\"odinger equation with a smooth potential near the
semi-classical limit. Our focus is not only on accurately obtaining solutions
when the non-dimensional Planck's constant, $\varepsilon$, is small, but also
on constructing an operator that maps initial values to solutions for the
Schr\"odinger equation with multiscale properties. Using Gaussian wave packets
framework, we first reformulate the Schr\"odinger equation as a system of
ordinary differential equations. For a single initial condition, we solve the
resulting system using PINNs or MscaleDNNs. Numerical simulations indicate that
MscaleDNNs outperform PINNs, improving accuracy by one to two orders of
magnitude. When dealing with a set of initial conditions, we adopt an
operator-learning approach, such as physics-informed DeepONets. Numerical
examples validate the effectiveness of physics-informed DeepONets with Gaussian
wave packets in accurately mapping initial conditions to solutions.

</details>


### [29] [An S-matrix Formalism for the Nonclassical Optical Response of Plasmonic Sphere Aggregates](https://arxiv.org/abs/2509.04589)
*Xin Zheng,Christos Mystilidis,Christos Tserkezis,Guy A. E. Vandenbosch,Xuezhi Zheng*

Main category: physics.comp-ph

TL;DR: A computational method for light scattering by multiple layered plasmonic nanospheres using mesoscopic models (NLHDM, GNOR, SRM) with validation against BEM solver and physical checks.


<details>
  <summary>Details</summary>
Motivation: To develop an accurate computational approach for analyzing light scattering in complex plasmonic nanostructures with multiple layers and nonclassical electron response effects.

Method: Uses S-matrix evaluation for individual spherical interfaces and their interactions, implementing three mesoscopic models: hydrodynamic Drude model (NLHDM), generalized nonlocal optical response (GNOR), and surface response model (SRM).

Result: Excellent agreement with boundary element method (BEM) solver for validation case (spherical NP with two embedded spheres) and physical checks on trimer configuration, showing accurate frequency shifts and field enhancements.

Conclusion: The presented method provides reliable computational framework for studying light scattering in complex multi-layered plasmonic nanostructures with nonclassical electron response effects.

Abstract: A computational method for the scattering of light by multiple nonclassical
plasmonic nanospheres, each of which has multiple (non-)concentric dielectric
or metallic layers, is presented. The electromagnetic (EM) response of the free
electrons in the metals is described by three popular mesoscopic models: the
nonlocal hydrodynamic Drude model (NLHDM) and its diffusive variant, namely the
generalized nonlocal optical response (GNOR) model, as well as the surface
response model (SRM). The main equation behind the method is set up by
detailing the evaluation of the S-matrix for each individual spherical
interface and the interactions amongst the interfaces. The algorithm is
numerically validated by comparing with an in-house boundary element method
(BEM) solver for a spherical NP with two smaller embedded spheres, and
physically checked on a trimer configuration, where the responses from the
NLHDM and SRM are contrasted with the local response model (LRM). In both cases
a very good agreement is seen regarding frequency shifts and field
enhancements.

</details>


### [30] [Hot-Ham: an accurate and efficient E(3)-equivariant machine-learning electronic structures calculation framework](https://arxiv.org/abs/2509.04875)
*Zhixin Liang,Yunlong Wang,Chi Ding,Junjie Wang,Hui-Tian Wang,Dingyu Xing,Jian Sun*

Main category: physics.comp-ph

TL;DR: Hot-Ham is an E(3) equivariant message passing neural network that uses local coordinate transformation and Gaunt tensor product to efficiently model DFT Hamiltonians, reducing computational complexity from O(L^6) to O(L^3) or O(L^2 log^2 L) while maintaining state-of-the-art accuracy.


<details>
  <summary>Details</summary>
Motivation: To resolve the accuracy-efficiency dilemma in machine learning combined with ab initio methods, particularly addressing the high computational complexity of equivariant MPNNs due to Clebsch-Gordan tensor products that hinder performance.

Method: Developed Hot-Ham framework combining local coordinate transformation and Gaunt tensor product (GTP) to efficiently model DFT Hamiltonians in an E(3) equivariant message passing neural network architecture.

Result: Significantly reduces tensor product complexity from O(L^6) to O(L^3) or O(L^2 log^2 L), achieves state-of-the-art accuracy with few parameters, and demonstrates strong generalization on multilayer twisted moiré systems, heterostructures, and allotropes.

Conclusion: Hot-Ham provides an efficient approach for developing equivariant neural networks and shows promise for investigating electronic properties of large-scale materials systems with high computational efficiency.

Abstract: The combinations of machine learning with ab initio methods have attracted
much attention for their potential to resolve the accuracy-efficiency dilemma
and facilitate calculations for large-scale systems. Recently, equivariant
message passing neural networks (MPNNs) that explicitly incorporate symmetry
constraints have demonstrated promise for interatomic potential and density
functional theory (DFT) Hamiltonian predictions. However, the high-order
tensors used to represent node and edge information are coupled through the
Clebsch-Gordan tensor product (CGTP), leading to steep increases in
computational complexity and seriously hindering the performance of equivariant
MPNNs. Here, we develop High-order Tensor machine-learning Hamiltonian
(Hot-Ham), an E(3) equivariant MPNN framework that combines two advanced
technologies local coordinate transformation and Gaunt tensor product (GTP) to
efficiently model DFT Hamiltonians. These two innovations significantly reduce
the complexity of tensor products from O(L^6) to O(L^3) or O(L^2 log^2 L) for
the max tensor order L, and enhance the performance of MPNNs. Benchmarks on
several public datasets demonstrate its state-of-the-art accuracy with
relatively few parameters, and the applications to multilayer twisted moir\'e
systems, heterostructures and allotropes showcase its generalization ability
and high efficiency. Our Hot-Ham method provides a new perspective for
developing efficient equivariant neural networks and would be a promising
approach for investigating the electronic properties of large-scale materials
systems.

</details>


### [31] [A second-order volumetric boundary treatment for the lattice Boltzmann method](https://arxiv.org/abs/2509.05035)
*Kaj Hoefnagel,Damiano Casalino,Steven Hulshoff,Frits de Prenter*

Main category: physics.comp-ph

TL;DR: New volumetric boundary treatment for lattice Boltzmann method using discontinuous piecewise linear basis and exact geometrical mapping, achieving improved accuracy and better flow predictions.


<details>
  <summary>Details</summary>
Motivation: To develop a more accurate boundary treatment method for the lattice Boltzmann method that improves flow predictions around complex geometries.

Method: Populations are projected onto a discontinuous piecewise linear basis and streamed using an exact geometrical mapping, implemented in 2D for convex stationary geometries with stability verified through eigenvalue analysis.

Result: Achieved convergence rate of ≥2, indicating improved accuracy over precursor methods, and yielded better lift and drag predictions for flow around a 2D airfoil.

Conclusion: The proposed volumetric boundary treatment method successfully enhances accuracy in lattice Boltzmann simulations and provides superior flow prediction capabilities for aerodynamic applications.

Abstract: A new volumetric-type boundary treatment is introduced for the lattice
Boltzmann method. Populations are projected onto a discontinuous piecewise
linear basis and streamed using an exact geometrical mapping. The method is
implemented in 2D for convex, stationary geometries. Stability is verified
through a novel analysis tool based on the eigenvalues of the streaming
operation. A convergence rate of $\geq2$ is achieved, indicating improved
accuracy over precursor methods. For flow around a 2D airfoil, the method
yields better lift and drag predictions.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [32] [Discharge structure hierarchy of highly electronegative plasma at low pressure and quasi-cold ion approximation](https://arxiv.org/abs/2509.04728)
*Rui-Ji Tang,Shu-Xia Zhao,Yu Tian*

Main category: physics.plasm-ph

TL;DR: Fluid simulation study of Ar and SF inductively coupled plasma discharge structure at low pressure using quasi cold ion approximation with room temperature


<details>
  <summary>Details</summary>
Motivation: To investigate the discharge structure of Ar and SF inductively coupled plasma at low pressure conditions

Method: Fluid simulation approach using quasi cold ion approximation with room temperature magnitude

Result: Analysis of plasma discharge structure characteristics for Ar and SF gases

Conclusion: The study provides insights into low-pressure inductively coupled plasma discharge behavior using fluid simulation techniques

Abstract: In this paper, the discharge structure of an Ar and SF inductively coupled
plasma at the low pressure is investigated by mean of a fluid simulation at the
quasi cold ion approximation with the room temperature magnitude.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [33] [Instance-Wise Adaptive Sampling for Dataset Construction in Approximating Inverse Problem Solutions](https://arxiv.org/abs/2509.04583)
*Jiequn Han,Kui Ren,Nathan Soedjak*

Main category: cs.LG

TL;DR: Instance-wise adaptive sampling framework for efficient training dataset construction in inverse problem learning, dynamically allocating samples based on specific test instances rather than using fixed datasets.


<details>
  <summary>Details</summary>
Motivation: Traditional learning-based inverse problem approaches require large training datasets from prior distributions, which becomes costly when priors have high intrinsic dimensions or high accuracy is needed. The method aims to reduce data collection costs.

Method: Iterative adaptive sampling that dynamically allocates sampling effort based on specific test instances, refining training datasets conditioned on latest predictions to tailor to the geometry of inverse map around each test instance.

Result: Demonstrated effectiveness in inverse scattering problem with structured priors, showing significant sample efficiency gains that become more pronounced with complex priors or higher accuracy requirements.

Conclusion: The adaptive sampling strategy provides a scalable and practical alternative to conventional fixed-dataset training, broadly applicable to various inverse problems beyond the demonstrated scattering problem.

Abstract: We propose an instance-wise adaptive sampling framework for constructing
compact and informative training datasets for supervised learning of inverse
problem solutions. Typical learning-based approaches aim to learn a
general-purpose inverse map from datasets drawn from a prior distribution, with
the training process independent of the specific test instance. When the prior
has a high intrinsic dimension or when high accuracy of the learned solution is
required, a large number of training samples may be needed, resulting in
substantial data collection costs. In contrast, our method dynamically
allocates sampling effort based on the specific test instance, enabling
significant gains in sample efficiency. By iteratively refining the training
dataset conditioned on the latest prediction, the proposed strategy tailors the
dataset to the geometry of the inverse map around each test instance. We
demonstrate the effectiveness of our approach in the inverse scattering problem
under two types of structured priors. Our results show that the advantage of
the adaptive method becomes more pronounced in settings with more complex
priors or higher accuracy requirements. While our experiments focus on a
particular inverse problem, the adaptive sampling strategy is broadly
applicable and readily extends to other inverse problems, offering a scalable
and practical alternative to conventional fixed-dataset training regimes.

</details>


### [34] [Interpreting Transformer Architectures as Implicit Multinomial Regression](https://arxiv.org/abs/2509.04653)
*Jonas A. Actor,Anthony Gruber,Eric C. Cyr*

Main category: cs.LG

TL;DR: Attention mechanisms in transformers are connected to multinomial regression, showing that optimal feature learning through attention aligns with classification-optimal features.


<details>
  <summary>Details</summary>
Motivation: To understand the opaque attention mechanism in transformers and its relationship to concepts like feature polysemanticity and superposition, which remain poorly understood despite attention's central role.

Method: Establishes a connection between attention mechanisms and multinomial regression by showing that optimizing over latent features in a fixed multinomial regression setting yields solutions that align with attention block dynamics.

Result: Demonstrates that the evolution of representations through a transformer can be interpreted as a trajectory that recovers the optimal features for classification.

Conclusion: Attention mechanisms in transformers can be understood through the lens of multinomial regression, providing new insights into how attention learns optimal classification features.

Abstract: Mechanistic interpretability aims to understand how internal components of
modern machine learning models, such as weights, activations, and layers, give
rise to the model's overall behavior. One particularly opaque mechanism is
attention: despite its central role in transformer models, its mathematical
underpinnings and relationship to concepts like feature polysemanticity,
superposition, and model performance remain poorly understood. This paper
establishes a novel connection between attention mechanisms and multinomial
regression. Specifically, we show that in a fixed multinomial regression
setting, optimizing over latent features yields optimal solutions that align
with the dynamics induced by attention blocks. In other words, the evolution of
representations through a transformer can be interpreted as a trajectory that
recovers the optimal features for classification.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [35] [Glassy interphases reinforce elastomeric nanocomposites by enhancing percolation-driven volume expansion under strain](https://arxiv.org/abs/2509.04755)
*Pierre Kawak,Harshad Bhapkar,David S. Simmons*

Main category: cond-mat.soft

TL;DR: Nanoparticle reinforcement in elastomers works through volumetric competition between filler and elastomer networks, not glassy bridges as previously hypothesized, with bulk modulus playing a key role.


<details>
  <summary>Details</summary>
Motivation: To resolve the century-old debate about the mechanisms behind nanoparticle reinforcement in elastomers, particularly testing the glassy bridge hypothesis.

Method: Used molecular dynamics simulations to study the interaction between nanoparticles and elastomers under deformation.

Result: Found that glassy particle shells don't provide elongational cohesion but amplify volumetric competition between networks, engaging the elastomer's bulk modulus which is 1000x larger than Young's modulus.

Conclusion: Establishes a unified understanding of low-strain reinforcement through volumetric network competition, provides diagnostic for glassy bridging, and offers new design principles for tough nanocomposites.

Abstract: For nearly a century, introduction of nanoparticles to elastomers has yielded
extraordinarily tough nanocomposites that are critical to technologies from
actuators to tires. The mechanisms by which this reinforcement occurs have
nevertheless remained a central open question in material science. One widely
debated hypothesis posits that strong interactions between polymer and
particles induce "glassy bridges" that cement particles into a cohesive
percolating network that resists elongation. Here, molecular dynamics
simulations show that glassy particle shells do not primarily provide
elongational cohesion. Instead, they amplify an underlying mechanism wherein
competition between filler and elastomer networks causes the elastomer's volume
to increase on deformation. This induces contributions from the elastomer's
bulk modulus, which is of order 1000 times larger than its Young's modulus.
These findings establish a unified understanding of low-strain reinforcement in
filled elastomers as emanating from volumetric competition between coexisting
particulate and elastomeric networks. This reframes and unifies our
understanding of low-strain reinforcement, provides a clear-cut diagnostic for
the presence of glassy bridging, and offers a new design principle for tough
elastomeric nanocomposites.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [36] [Gas Sensing Properties of Novel Indium Oxide Monolayer: A First-Principles Study](https://arxiv.org/abs/2509.05121)
*Afreen Anamul Haque,Suraj G. Dhongade,Aniket Singha*

Main category: cond-mat.mtrl-sci

TL;DR: 2D In2O3 monolayer shows excellent gas sensing capabilities for hazardous gases like NO and H2S, with strain-tunable detection properties for environmental monitoring applications.


<details>
  <summary>Details</summary>
Motivation: To investigate the gas sensing potential of novel 2D Indium Oxide monolayer for detecting hazardous environmental gases using first-principles calculations.

Method: Density functional theory (DFT) calculations to evaluate interactions with ten hazardous gases and ambient molecules, analyzing both resistive-type and work function based detection mechanisms under mechanical strain.

Result: The monolayer shows pronounced sensitivity towards NO and H2S, work function modulation enables detection of NH3 and HCN, and mechanical strain enhances adsorption and selectivity.

Conclusion: 2D In2O3 is established as a tunable platform for next-generation miniaturized gas sensors for environmental monitoring and safety applications.

Abstract: We present a comprehensive first-principles investigation into the gas
sensing capabilities of a novel two-dimensional Indium Oxide (In2O3) monolayer,
using density functional theory (DFT) calculations. Targeting both
resistive-type and work function based detection mechanisms, we evaluate
interactions with ten hazardous gases (NH3, NO, NO2, SO2, CS2, H2S, HCN, CCl2O,
CH2O, CO) as well as ambient molecules (O2, CO2, H2O). The monolayer shows
pronounced sensitivity towards NO and H2S, and work function modulation enables
detection of NH3 and HCN. Mechanical strain further broadens detection
capability, enhancing adsorption and selectivity. These results establish 2D
In2O3 as a tunable platform for next-generation miniaturized gas sensors for
environmental monitoring and safety applications.

</details>


### [37] [Vanadium-Engineered Co2NiSe4 Nanomaterial: Coupled Thermoelectric, Piezoelectric, and Electronic Optimization via DFT+U for Advanced Energy Applications](https://arxiv.org/abs/2509.05266)
*Ayesha Riaz,Sikander Azam,Qaiser Rafiq,Amin Ur Rahman,Qazi Muhammad Ahkam,Rafaqat Hussain,Rajwali Khan*

Main category: cond-mat.mtrl-sci

TL;DR: Vanadium doping in Co2NiSe4 enhances multiple properties including electrical conductivity, magnetic ordering, thermoelectric performance (ZT ~1.1 at 900K), mechanical strength, and optical characteristics, making it suitable for energy storage, thermoelectric generation, and multifunctional sensors.


<details>
  <summary>Details</summary>
Motivation: To develop advanced multifunctional materials for energy storage and conversion technologies by tailoring material properties through vanadium doping to improve performance across multiple physical domains.

Method: First-principles density functional theory (DFT + U) calculations were used to evaluate structural, electronic, magnetic, thermodynamic, mechanical, thermoelectric, piezoelectric and optical properties of pristine and vanadium-doped Co2NiSe4.

Result: V doping significantly improves electrical conductivity and magnetic ordering due to higher density of states and stronger spin polarization. It enhances entropy stabilization, increases elastic moduli while maintaining ductility, achieves optimal thermoelectric ZT ~1.1 at 900K, expands optical absorption spectra, and improves piezoelectric coefficients.

Conclusion: Vanadium-doped Co2NiSe4 emerges as a versatile material platform suitable for next-generation energy storage, thermoelectric generation, and multifunctional sensor applications due to its enhanced and tunable properties across multiple domains.

Abstract: To realize the creation of advanced multifunctional materials in energy
storage and conversion technologies, the present research evaluates the
structural, electronic, magnetic, thermodynamic, mechanical, thermoelectric,
piezoelectric and optical properties of pristine and vanadium-doped Co2NiSe4 by
first-principles density functional theory (DFT + U ). It addresses the use of
vanadium substitution to tailor the material, its performance and the inclusion
of diverse fields by changing its electronic structure and its bonding
properties. It can be seen in the results that V doping improves electrical
conductivity and magnetic ordering because of a higher density of states and a
stronger spin polarization at the Fermi level. Thermodynamic calculations show
enhanced entropy stabilization at high temperatures and, mechanical analysis
suggests an enhanced elastic moduli that proves the enhanced structural
integrity without affecting ductility. The thermoelectric properties have been
greatly improved realize an optimal ZT of ~1.1 at 900 K with 5 at.% V doping
owing to an ideal combination of Seebeck coefficient, electrical conductivity,
and inhibited thermal conductivity. Also, optical analysis reveals that
expanded absorption spectra, increased dielectric response, adjustable
reflectivity and energy loss spectra, optical properties can be used in
photonic, and other optoelectronic devices. Better piezoelectric coefficients
due to its effectiveness when doped also appeal to the usefulness of its
application in nanoscale electromechanical systems. The combination of these
results makes V-doped Co2NiSe4, a versatile material platform of
next-generation energy storage, thermoelectric generation, and novel
multifunctional sensors.

</details>


### [38] [Illuminating Stability and Spectral Shifts: A DFT+U Study of Eu-Doped ZnWO$_4$ for Visible-Light Optoelectronics](https://arxiv.org/abs/2509.05278)
*Muhammad Tayyab,Sikander Azam,Qaiser Rafiq,Vineet Tirth,Ali Algahtani,Amin Ur Rahman,Syed Sheraz Ahmad,M. Tahir Khan*

Main category: cond-mat.mtrl-sci

TL;DR: DFT study shows Eu doping in ZnWO4 reduces bandgap, introduces localized states, enhances optical properties, and improves optoelectronic performance for w-LED applications.


<details>
  <summary>Details</summary>
Motivation: To investigate the underexplored role of europium substitution in modulating the optoelectronic behavior of ZnWO4, a promising tungstate-based oxide host matrix.

Method: Spin-polarized density functional theory (DFT) within the GGA+U framework was employed to analyze structural, electronic, and optical properties of pristine and Eu-doped ZnWO4 systems, including phonon dispersion analysis.

Result: Eu doping reduces bandgap, introduces new localized states near Fermi level, alters density of states, enhances electronic transitions, broadens dielectric function, red-shifts absorption edge, intensifies extinction coefficient, and improves photon-phonon coupling.

Conclusion: Eu incorporation stabilizes ZnWO4 lattice and tailors optoelectronic features, making Eu-doped ZnWO4 a potential candidate for white-light-emitting diodes and related optoelectronic technologies.

Abstract: Tungstate-based oxides have attracted significant attention owing to their
excellent structural stability, chemical robustness, and versatile optical
properties, making them suitable for next-generation optoelectronic and
phosphor applications. Among these, ZnWO$_4$ has emerged as a promising host
matrix; however, the role of europium (Eu) substitution in modulating its
optoelectronic behavior remains underexplored. In this work, we employ
spin-polarized density functional theory (DFT) within the GGA+U framework to
investigate the structural, electronic, and optical properties of pristine
ZnWO$_4$ and Eu-doped ZnWO4 systems. Phonon dispersion analysis confirms
dynamical stability for both pristine and doped structures. Eu doping reduces
the bandgap, introduces new localized states near the Fermi level, and
significantly alters the density of states, thereby enhancing electronic
transitions. The optical response reveals a broadened dielectric function,
red-shifted absorption edge, and intensified extinction coefficient, consistent
with the presence of Eu 4f states. Additionally, reflectivity and energy-loss
spectra indicate improved photon-phonon coupling and optical tunability upon
doping. These findings highlight that Eu incorporation not only stabilizes the
ZnWO$_4$ lattice but also tailors its optoelectronic features, positioning
Eu-doped ZnWO4 as a potential candidate for white-light-emitting diodes
(w-LEDs) and related optoelectronic technologies.

</details>


<div id='physics.ins-det'></div>

# physics.ins-det [[Back]](#toc)

### [39] [LEMURS dataset: Large-scale multi-detector ElectroMagnetic Universal Representation of Showers](https://arxiv.org/abs/2509.05108)
*Peter McKeown,Piyush Raikwar,Anna Zaborowska*

Main category: physics.ins-det

TL;DR: LEMURS is a comprehensive dataset of simulated calorimeter showers designed for developing and benchmarking fast simulation methods in high-energy physics, featuring improved statistics, wider incident angles, and multiple detector geometries compared to existing datasets.


<details>
  <summary>Details</summary>
Motivation: To provide a more robust dataset than the existing CaloChallenge dataset for developing foundation models in high-energy physics simulation, addressing limitations in statistics, incident angle range, and detector geometry diversity.

Method: Created an extensive dataset of simulated calorimeter showers with substantially greater statistics, wider range of incident angles, and multiple detector geometries including more realistic calorimeters. Data is provided in HDF5 format with enhanced shower representation variables.

Result: LEMURS dataset offers superior scale and diversity compared to CaloChallenge, making it particularly suitable for foundation model development. It has already been used in the CaloDiT-2 model within the Geant4 simulation toolkit.

Conclusion: LEMURS represents a significant advancement in calorimeter shower simulation datasets, providing open access to data and code to facilitate reproducibility and community-wide reuse for developing fast simulation methods and foundation models in high-energy physics.

Abstract: We present LEMURS: an extensive dataset of simulated calorimeter showers
designed to support the development and benchmarking of fast simulation methods
in high-energy physics, most notably providing a step towards the development
of foundation models. This new dataset is more robust than the well-established
CaloChallenge dataset 2, featuring substantially greater statistics, a wider
range of incident angles in the detector, and most crucially multiple detector
geometries (including more realistic calorimeters). The dataset is provided in
HDF5 format, with a file structure inspired by the CaloChallenge shower
representation while also including more variables. LEMURS scale and diversity
make it particularly suitable for development of foundation models and has been
used in the CaloDiT-2 model, a pre-trained model released in the community
standard simulation toolkit Geant4 (version 11.4.beta). All data and code for
generation and analysis are openly accessible, facilitating reproducibility and
reuse across the community.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [40] [Fidelity-preserving enhancement of ptychography with foundational text-to-image models](https://arxiv.org/abs/2509.04513)
*Ming Du,Volker Rose,Junjing Deng,Dileep Singh,Si Chen,Mathew J. Cherukara*

Main category: cs.GR

TL;DR: A plug-and-play framework combining physics-based phase retrieval with text-guided diffusion models to remove artifacts in ptychographic imaging using natural language instructions.


<details>
  <summary>Details</summary>
Motivation: Ptychographic phase retrieval suffers from artifacts like grid pathology and multislice crosstalk that degrade image quality, requiring effective artifact removal methods.

Method: Uses ADMM to integrate physics model-based phase retrieval with text-guided image editing via LEDITS++ diffusion model, allowing natural language specification of artifacts to remove.

Result: Significant improvements in artifact suppression and structural fidelity demonstrated on simulated and experimental datasets, validated by PSNR and diffraction pattern consistency metrics.

Conclusion: The combination of text-guided generative models and model-based phase retrieval provides a transferable, fidelity-preserving method for high-quality diffraction imaging.

Abstract: Ptychographic phase retrieval enables high-resolution imaging of complex
samples but often suffers from artifacts such as grid pathology and multislice
crosstalk, which degrade reconstructed images. We propose a plug-and-play (PnP)
framework that integrates physics model-based phase retrieval with text-guided
image editing using foundational diffusion models. By employing the alternating
direction method of multipliers (ADMM), our approach ensures consensus between
data fidelity and artifact removal subproblems, maintaining physics consistency
while enhancing image quality. Artifact removal is achieved using a text-guided
diffusion image editing method (LEDITS++) with a pre-trained foundational
diffusion model, allowing users to specify artifacts for removal in natural
language. Demonstrations on simulated and experimental datasets show
significant improvements in artifact suppression and structural fidelity,
validated by metrics such as peak signal-to-noise ratio (PSNR) and diffraction
pattern consistency. This work highlights the combination of text-guided
generative models and model-based phase retrieval algorithms as a transferable
and fidelity-preserving method for high-quality diffraction imaging.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [41] [Probabilistic operator learning: generative modeling and uncertainty quantification for foundation models of differential equations](https://arxiv.org/abs/2509.05186)
*Benjamin J. Zhang,Siting Liu,Stanley J. Osher,Markos A. Katsoulakis*

Main category: stat.ML

TL;DR: ICON learns solution operators for differential equations from example pairs, and this paper shows it implicitly performs Bayesian inference, leading to a generative extension (GenICON) for uncertainty quantification.


<details>
  <summary>Details</summary>
Motivation: To understand the probabilistic foundations of in-context operator networks (ICON) and extend them to generative settings for better uncertainty quantification in operator learning.

Method: Developed a probabilistic framework showing ICON computes the mean of posterior predictive distribution over solution operators. Extended to generative ICON (GenICON) that samples from this distribution.

Result: Revealed ICON's implicit Bayesian inference nature and created a generative version that captures solution operator uncertainty.

Conclusion: The probabilistic perspective provides theoretical foundation for ICON and enables principled uncertainty quantification through generative sampling.

Abstract: In-context operator networks (ICON) are a class of operator learning methods
based on the novel architectures of foundation models. Trained on a diverse set
of datasets of initial and boundary conditions paired with corresponding
solutions to ordinary and partial differential equations (ODEs and PDEs), ICON
learns to map example condition-solution pairs of a given differential equation
to an approximation of its solution operator. Here, we present a probabilistic
framework that reveals ICON as implicitly performing Bayesian inference, where
it computes the mean of the posterior predictive distribution over solution
operators conditioned on the provided context, i.e., example condition-solution
pairs. The formalism of random differential equations provides the
probabilistic framework for describing the tasks ICON accomplishes while also
providing a basis for understanding other multi-operator learning methods. This
probabilistic perspective provides a basis for extending ICON to
\emph{generative} settings, where one can sample from the posterior predictive
distribution of solution operators. The generative formulation of ICON
(GenICON) captures the underlying uncertainty in the solution operator, which
enables principled uncertainty quantification in the solution predictions in
operator learning.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [42] [Linearly Stable KAM Tori for One Dimensional Forced Kirchhoff Equations under Periodic Boundary Conditions](https://arxiv.org/abs/2509.04861)
*Yin Chen,Jiansheng Geng,Guangzhao Zhou*

Main category: math.DS

TL;DR: Abstract infinite dimensional KAM theorem applied to prove existence and linear stability of small-amplitude quasi-periodic solutions for 1D forced Kirchhoff equations with periodic boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To extend previous results from simple eigenvalues to double eigenvalues under quasi-linear perturbation for forced Kirchhoff equations.

Method: Develops an abstract infinite dimensional KAM theorem and applies it to analyze the forced Kirchhoff equation with periodic boundary conditions, real Fourier multiplier, and real analytic forcing with Diophantine frequencies.

Result: Proves existence and linear stability of small-amplitude quasi-periodic solutions for the given equation.

Conclusion: Generalizes previous work by handling double eigenvalues case under quasi-linear perturbation, providing a more comprehensive framework for analyzing such nonlinear PDEs.

Abstract: We prove an abstract infinite dimensional KAM theorem, which could be applied
to prove the existence and linear stability of small-amplitude quasi-periodic
solutions for one dimensional forced Kirchhoff equations with periodic boundary
conditions
  \[ u_{tt}-(1+\int_{0}^{2\pi} |u_x|^2 dx)u_{xx}+
  M_\xi u+\epsilon g(\bar{\omega}t,x) =0,\quad u(t,x+2\pi)=u(t,x),\]
  where $M_\xi$ is a real Fourier multiplier, $g(\bar{\omega}t,x)$ is real
analytic with forced Diophantine frequencies $\bar\omega$, $\epsilon$ is a
small parameter.
  The paper generalizes the previous results from the simple eigenvalue to the
double eigenvalues under the quasi-linear perturbation.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [43] [Measuring the properties of homogeneous turbulence in curved spacetimes](https://arxiv.org/abs/2509.04566)
*Rita Megale,Alejandro Cruz-Osorio,Giuseppe Ficarra,Mario Imbrogno,Claudio Meringolo,Leonardo Primavera,Luciano Rezzolla,Sergio Servidio*

Main category: gr-qc

TL;DR: Novel approach for analyzing turbulence in curved spacetimes using proper lengths/volumes instead of coordinate-based methods, revealing significant differences near black hole event horizons.


<details>
  <summary>Details</summary>
Motivation: Turbulence near black holes is poorly understood and typically analyzed using flat-spacetime techniques, which may not be accurate in strong gravitational fields.

Method: Developed a formalism to compute turbulence properties (structure functions, power spectral density) using proper lengths and volumes on generic manifolds, applied to magnetized disc accretion simulations around Kerr black holes.

Result: The new approach captures inertial-range cascade behavior and reveals 40-80% differences near event horizons compared to standard flat-spacetime methods, with smaller differences at larger distances.

Conclusion: Special care is needed when analyzing turbulence in strongly curved spacetimes, as traditional flat-spacetime approaches can yield significantly inaccurate results near black holes.

Abstract: Turbulence in curved spacetimes in general, and in the vicinity of black
holes (BHs) in particular, represents a poorly understood phenomenon that is
often analysed employing techniques developed for flat spacetimes. We here
propose a novel approach to study turbulence in strong gravitational fields
that is based on the computation of structure functions on generic manifolds
and is thus applicable to arbitrary curved spacetimes. In particular, we
introduce, for the first time, a formalism to compute the characteristic
properties of turbulence, such as the second-order structure function or the
power spectral density, in terms of proper lengths and volumes and not in terms
of coordinate lengths and volumes, as customarily done. By applying the new
approach to the turbulent rest-mass density field from simulations of
magnetised disc accretion onto a Kerr BH, we inspect in a rigorous way
turbulence in regions close to the event horizon, but also in the disc, the
wind, and in the jet. We demonstrate that the new approach can capture the
typical behavior of an inertial-range cascade and that differences up to
$40-80\%$ emerge in the vicinity of the event horizon with respect to the
standard flat-spacetime approach. While these differences become smaller at
larger distances, our study highlights that special care needs to be paid when
analysing turbulence in strongly curved spacetimes.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [44] [Multiscale Graph Neural Network for Turbulent Flow-Thermal Prediction Around a Complex-Shaped Pin-Fin](https://arxiv.org/abs/2509.04463)
*Riddhiman Raut,Evan M. Mihalko,Amrita Basak*

Main category: physics.flu-dyn

TL;DR: A graph neural network was developed to predict turbulent flow and thermal behavior in 2D channels with complex pin-fin geometries, achieving high accuracy while reducing computation time by 2-3 orders of magnitude.


<details>
  <summary>Details</summary>
Motivation: To create a fast and reliable surrogate model for simulating complex flow configurations with arbitrarily shaped pin-fin geometries, reducing the computational cost of traditional CFD simulations.

Method: Developed a domain-responsive edge-aware multiscale Graph Neural Network that takes graph structures as input, where nodes contain spatial coordinates, boundary indicators, and signed distance to boundaries. Training data was generated through automated ANSYS Fluent simulations of 1,000 diverse pin-fin configurations parameterized with cubic splines.

Result: The network predicted temperature, velocity magnitude, and pressure fields with outstanding accuracy, successfully capturing complex flow features including boundary layers, recirculation, and stagnation regions upstream of pin-fins.

Conclusion: The novel graph neural network provides a fast and reliable surrogate for simulations in complex flow configurations, significantly reducing computational time while maintaining high predictive accuracy.

Abstract: This study presents the development of a domain-responsive edge-aware
multiscale Graph Neural Network for predicting steady, turbulent flow and
thermal behavior in a two-dimensional channel containing arbitrarily shaped
complex pin-fin geometries. The training dataset was constructed through an
automated framework that integrated geometry generation, meshing, and
flow-field solutions in ANSYS Fluent. The pin-fin geometry was parameterized
using piecewise cubic splines, producing 1,000 diverse configurations through
Latin Hypercube Sampling. Each simulation was converted into a graph structure,
where nodes carried a feature vector containing spatial coordinates, a
normalized streamwise position, one-hot boundary indicators, and a signed
distance to the nearest boundary such as wall. This graph structure served as
input to the newly developed Graph Neural Network, which was trained to predict
temperature, velocity magnitude, and pressure at each node using data from
ANSYS. The network predicted fields with outstanding accuracy, capturing
boundary layers, recirculation, and the stagnation region upstream of the
pin-fins while reducing wall time by 2-3 orders of magnitude. In conclusion,
the novel graph neural network offered a fast and reliable surrogate for
simulations in complex flow configurations.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [45] [A computationally efficient subspace harmonic relaxation algorithm for coarse-graining of molecular systems with nearly exact thermodynamic consistency](https://arxiv.org/abs/2509.05279)
*João V. M. Pimentel,Vladimir A. Mandelshtam*

Main category: physics.chem-ph

TL;DR: Improved computational method for coarse-graining molecular clusters with algorithmic optimizations that make CG potential evaluation cost comparable to all-atom models while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: The original rigidification method for molecular clusters was computationally expensive, requiring costly subspace minimization and normal mode calculations that made CG potential evaluation more expensive than all-atom potential evaluation.

Method: Formulated a broader approach applicable to larger systems like proteins, introduced algorithmic improvements to reduce the cost of subspace minimization and normal mode calculations, and leveraged the fact that CG simulations require fewer Monte Carlo steps for similar statistical accuracy.

Result: The improved method achieves comparable overall computational cost to all-atom models while maintaining accuracy, as demonstrated on water clusters.

Conclusion: The algorithmic enhancements successfully address the computational expense of the original rigidification approach, making coarse-grained modeling of molecular clusters and larger systems like proteins computationally feasible and efficient.

Abstract: In a recent paper, J. Chem. Phys. 162, 214101 (2025), a novel approach for
the rigidification of a molecular cluster was proposed, in which starting with
an all-atom (AA) potential, a coarse-grained (CG) potential for the associated
cluster of rigid monomers was constructed directly. The method is based on
using the harmonic approximation for the fast intramolecular degrees of
freedom. While conceptually primitive, the resulting CG model turned out to be
surprisingly accurate for selected water and ammonia clusters. However, as
originally formulated, a single evaluation of the CG potential turned out to be
much more expensive than the evaluation of the AA potential, since the former
required a subspace minimization followed by a subspace normal mode
calculation. In this communication, we formulate the approach more broadly,
making it applicable, e.g., to coarse-graining a large protein. We also
introduce key algorithmic improvements, reducing the cost of the subspace
minimization and normal mode calculation. Combined with the fact that the CG
simulation requires roughly an order of magnitude fewer Monte Carlo steps to
reach similar statistical accuracy for selected observables compared to the AA
model, the overall computational cost becomes comparable. These improvements
are demonstrated on a water cluster.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [46] [Resolving Tangling in Multi-Conformer Refinement via Iterative Projections](https://arxiv.org/abs/2509.05189)
*Avinash Mandaiya,Veit Elser*

Main category: q-bio.QM

TL;DR: Automated refinement method using iterative projections to solve tangling issues in multi-conformational protein crystallography, enabling robust refinement even with poor initial models.


<details>
  <summary>Details</summary>
Motivation: Current crystallographic refinement protocols fail due to tangling phenomenon where conformational states become improperly intertwined during optimization, limiting the ability to extract cooperative motions from electron density maps.

Method: Iterative projections within the divide-and-concur framework that integrates geometric constraints with experimental density constraints, allowing each atom to satisfy density constraints independently.

Result: The framework effectively circumvents tangling artifacts and achieves robust refinement performance even for models initialized with R-factors as high as 12%.

Conclusion: Iterative projections provide a computational foundation for advancing crystallographic methodologies to resolve conformational heterogeneity and capture protein dynamics at atomic resolution, similar to how they revolutionized phase retrieval.

Abstract: The advent of advanced crystallographic techniques has shifted structural
biology from static, single-conformer models toward probing protein dynamics.
Extracting cooperative motions from temporally and spatially averaged electron
density maps requires both high-resolution data and refinement algorithms
capable of handling conformational heterogeneity. However, current refinement
protocols often fail due to the tangling phenomenon, in which conformational
states become improperly intertwined during optimization. Here, we present an
automated refinement methodology based on iterative projections within the
divide-and-concur framework. This approach enables seamless integration of
geometric constraints with experimental density constraints derived from
observed scattering amplitudes. By allowing each atom to satisfy density
constraints independently, we show that this framework effectively circumvents
tangling artifacts and achieves robust refinement performance, even for models
initialized with R-factors as high as 12%. Just as iterative projections
revolutionized phase retrieval in crystallography, we demonstrate that they can
also address the optimization challenges in multi-conformational refinement.
This work establishes a computational foundation for advancing crystallographic
methodologies to resolve conformational heterogeneity and ultimately capture
protein dynamics at atomic resolution.

</details>
