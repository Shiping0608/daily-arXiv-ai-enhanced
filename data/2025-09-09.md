<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 16]
- [math.AP](#math.AP) [Total: 36]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 8]
- [gr-qc](#gr-qc) [Total: 2]
- [stat.ML](#stat.ML) [Total: 2]
- [cs.CV](#cs.CV) [Total: 1]
- [math.DG](#math.DG) [Total: 2]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [math.DS](#math.DS) [Total: 1]
- [quant-ph](#quant-ph) [Total: 2]
- [math.PR](#math.PR) [Total: 2]
- [physics.atm-clus](#physics.atm-clus) [Total: 1]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [math.AG](#math.AG) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 2]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A class of regularization schemes for linear ill-posed problems in Banach spaces under low order source conditions](https://arxiv.org/abs/2509.05418)
*Robert Plato*

Main category: math.NA

TL;DR: Regularization methods for linear ill-posed problems with logarithmic source representations in Banach spaces, focusing on exponentially ill-posed problems like backwards heat equation.


<details>
  <summary>Details</summary>
Motivation: To address the recovery of solutions with logarithmic source representations that occur in exponentially ill-posed problems, which require specialized regularization approaches.

Method: Developed mathematical framework for logarithms of operators and analyzed convergence rates for parametric regularization schemes including iterated Lavrentiev's method and abstract Cauchy problem method, with both a priori and a posteriori parameter choice strategies.

Result: Established convergence rates for the regularization schemes and provided mathematical framework for handling logarithmic source representations in operator theory.

Conclusion: The proposed regularization methods effectively handle exponentially ill-posed problems with logarithmic source conditions, with demonstrated convergence properties and practical parameter selection strategies.

Abstract: In this work we consider, in a Banach space framework, the regularization of
linear ill-posed problems. Our focus is on the recovery of solutions that have
a logarithmic source representation. Such cases typically occur in
exponentially ill-posed problems like the backwards heat equation. The
mathematical framework on logarithms of operators is provided, and convergence
rates for a class of parametric regularization schemes are deduced. This class
includes the iterated version of Lavrentiev's method and the method of the
abstract Cauchy problem. The presentation includes both a priori and a
posteriori parameter choice strategies. Finally, we present an example for a
logarithmic source representable function with respect to the integration
operator.

</details>


### [2] [Fast Multipole Method with Complex Coordinates](https://arxiv.org/abs/2509.05458)
*Tristan Goodwill,Leslie Greengard,Jeremy Hoskins,Manas Rachh,Yuguan Wang*

Main category: math.NA

TL;DR: A complex-coordinate fast multipole method (FMM) variant for efficiently evaluating layer potentials on geometries with complex coordinates in 2D/3D, enabling large-scale scattering problems.


<details>
  <summary>Details</summary>
Motivation: Classical real-coordinate FMMs cannot handle complex point locations from discretized complex scaled boundary integral methods for scattering problems on unbounded domains.

Method: Develop complex-coordinate FMM based on analytic continuation of special function identities, construct hierarchical tree using real parts of complex points, derive convergence rates for truncated expansions.

Result: Achieves same linear time complexity as classical FMM, demonstrated efficiency through numerical examples for time-harmonic water wave and Helmholtz transmission problems.

Conclusion: The complex-coordinate FMM enables efficient solution of large-scale scattering problems with complex geometries that were previously hindered by classical FMM limitations.

Abstract: In this work we present a variant of the fast multipole method (FMM) for
efficiently evaluating standard layer potentials on geometries with complex
coordinates in two and three dimensions. The complex scaled boundary integral
method for the efficient solution of scattering problems on unbounded domains
results in complex point locations upon discretization. Classical
real-coordinate FMMs are no longer applicable, hindering the use of this
approach for large-scale problems. Here we develop the complex-coordinate FMM
based on the analytic continuation of certain special function identities used
in the construction of the classical FMM. To achieve the same linear time
complexity as the classical FMM, we construct a hierarchical tree based solely
on the real parts of the complex point locations, and derive convergence rates
for truncated expansions when the imaginary parts of the locations are a
Lipschitz function of the corresponding real parts. We demonstrate the
efficiency of our approach through several numerical examples and illustrate
its application for solving large-scale time-harmonic water wave problems and
Helmholtz transmission problems.

</details>


### [3] [Workflow for High-Fidelity Dynamic Analysis of Structures with Pile Foundation](https://arxiv.org/abs/2509.05675)
*Amin Pakzad,Pedro Arduino,Wenyang Zhang,Ertugrul Tacirouglu*

Main category: math.NA

TL;DR: A standardized workflow for high-fidelity soil-structure interaction analysis using Domain Reduction Method, Perfectly Matched Layer elements, Embedded interface elements, and domain decomposition.


<details>
  <summary>Details</summary>
Motivation: The rising demand for high-fidelity numerical simulations in soil-structure interaction analysis lacks a standardized workflow, creating a gap that needs to be addressed.

Method: Proposes a step-by-step workflow including Domain Reduction Method for loading reduction, Perfectly Matched Layer for wave absorption, Embedded interface elements for soil-structure interaction modeling, and domain decomposition for computational efficiency.

Result: The workflow effectively reduces simulation size without compromising fidelity, demonstrates precision in modeling infinite domains, establishes efficient soil-structure connections, and proves overall effectiveness in high-fidelity simulations.

Conclusion: While focused on simplified geometries and loading scenarios, this workflow serves as a foundational framework for future research on more complex structural configurations and dynamic loading conditions.

Abstract: The demand for high-fidelity numerical simulations in soil-structure
interaction analysis is on the rise, yet a standardized workflow to guide the
creation of such simulations remains elusive. This paper aims to bridge this
gap by presenting a step-by-step guideline proposing a workflow for dynamic
analysis of structures with pile foundations. The proposed workflow encompasses
instructions on how to use Domain Reduction Method for loading, Perfectly
Matched Layer elements for wave absorption, soil-structure interaction modeling
using Embedded interface elements, and domain decomposition for efficient use
of processing units. Through a series of numerical simulations, we showcase the
practical application of this workflow. Our results reveal the efficacy of the
Domain Reduction Method in reducing simulation size without compromising model
fidelity, show the precision of Perfectly Matched Layer elements in modeling
infinite domains, highlight the efficiency of Embedded Interface elements in
establishing connections between structures and the soil domain, and
demonstrate the overall effectiveness of the proposed workflow in conducting
high-fidelity simulations. While our study focuses on simplified geometries and
loading scenarios, it serves as a foundational framework for future research
endeavors aimed at exploring more intricate structural configurations and
dynamic loading conditions

</details>


### [4] [High-order staggered Lagrangian hydrodynamics (I): framework of the discretization scheme](https://arxiv.org/abs/2509.05944)
*Zhiyuan Sun,Jun Liu,Pei Wanga*

Main category: math.NA

TL;DR: A discretization framework for high-order staggered Lagrangian hydrodynamics that bridges curvilinear finite element methods with compatible hydrodynamics, addressing quadrature consistency issues and enabling diagonal mass matrices.


<details>
  <summary>Details</summary>
Motivation: To resolve consistency issues between density and internal energy variables defined at different physical points in high-order Lagrangian hydrodynamics, and to bridge two established algorithms for better computational efficiency.

Method: Unifies quadrature rules for discretization space to handle consistency issues, strategically arranges degrees of freedom for kinematic and thermodynamic variables, and addresses hourglass distortion introduced by this approach.

Result: The framework enhances computational efficiency through diagonal mass matrices in momentum and energy equations, and validation through smooth numerical examples demonstrates accurate high-order Lagrangian hydrodynamics.

Conclusion: The proposed discretization framework successfully resolves quadrature consistency issues in high-order staggered Lagrangian hydrodynamics while maintaining computational efficiency through strategic DOF arrangement and diagonal mass matrices.

Abstract: This paper presents a discretization framework for high-order staggered
Lagrangian hydrodynamics, bridging two well-established algorithms algorithms:
high-order curvilinear finite element Lagrangian hydrodynamics [Dobrev et al.
2012] and compatible hydrodynamics methods[Caramana et al.1998]. We emphasizes
the critical relationship between the degrees of freedom (DOFs) associated with
the density variable and the choice of numerical quadrature rules which is
employed in the mass conservation law. The precise quadrature rule will lead
the consistency issues arising from the density and internal energy variables
being defined at different physical points. Our approach resolves this by
unifying the quadrature rule for the specific discretization space, though this
inevitably introduces hourglass distortion. Another key feature of the proposed
framework is the strategic arrangement of DOFs for kinematic and thermodynamic
variables, which enhances computational efficiency and leads to diagonal mass
matrices in the momentum and energy equations. Finally, we present a smooth
numerical example that validate the accuracy of the proposed high-order
Lagrangian hydrodynamics framework.

</details>


### [5] [Transformation from Bi-CG into Bi-CR using a residual smoothing-like scheme](https://arxiv.org/abs/2509.05986)
*Arisa Kawase,Kensuke Aihara*

Main category: math.NA

TL;DR: Residual smoothing connects iterative solvers - minimal residual smoothing transforms CG residuals to CR for symmetric systems. This paper explores if similar Bi-CG to Bi-CR transformation exists for nonsymmetric systems.


<details>
  <summary>Details</summary>
Motivation: To investigate whether residual smoothing techniques that connect conjugate gradient (CG) and conjugate residual (CR) methods for symmetric matrices can be extended to connect Bi-CG and Bi-CR methods for nonsymmetric linear systems.

Method: The study applies residual smoothing techniques to analyze the relationship between Bi-CG and Bi-CR iterative methods for nonsymmetric systems, supported by numerical experiments.

Result: Numerical experiments demonstrate the validity of the insights, showing that a similar connection can be constructed between Bi-CG and Bi-CR methods for nonsymmetric linear systems.

Conclusion: Residual smoothing techniques successfully establish connections between Bi-CG and Bi-CR methods for nonsymmetric systems, extending the known relationship between CG and CR methods for symmetric matrices.

Abstract: Residual smoothing techniques, which produce a smooth convergence behavior of
linear iterative solvers, also form connections between different methods. For
example, minimal residual smoothing can transform the residuals of the
conjugate gradient (CG) method into those of the conjugate residual (CR) method
for linear systems with symmetric matrices. In this study, we investigate
whether a similar relationship can be constructed between the Bi-CG and Bi-CR
methods for nonsymmetric linear systems. Numerical experiments regarding the
aforementioned connection demonstrate the validity of our insights.

</details>


### [6] [Recursive vectorized computation of the Frobenius norm](https://arxiv.org/abs/2509.06220)
*Vedran Novaković*

Main category: math.NA

TL;DR: Proposed recursive algorithms using hypot function for computing Frobenius norm, showing potential for higher accuracy than BLAS DNRM2, with vectorization and parallelization capabilities.


<details>
  <summary>Details</summary>
Motivation: To develop more accurate alternatives to the standard BLAS DNRM2 routine for computing Frobenius norm, leveraging recursive algorithms and hypotenuse functions for improved precision.

Method: Developed recursive algorithms based on hypot (hypotenuse function), vectorized using Intel's vector instructions, and parallelized with OpenCilk. Some algorithms designed for bitwise reproducibility.

Result: The proposed algorithms demonstrate significantly higher accuracy than BLAS DNRM2 in many cases, achieve comparable performance through vectorization, and offer conditional reproducibility depending on vector width.

Conclusion: Recursive hypot-based algorithms provide a viable alternative to BLAS routines with improved accuracy, good performance through vectorization/parallelization, and reproducibility features for scientific computing applications.

Abstract: Recursive algorithms for computing the Frobenius norm of a real array are
proposed, based on hypot, a hypotenuse function. Comparing their relative
accuracy bounds with those of the BLAS routine DNRM2 it is shown that the
proposed algorithms could in many cases be significantly more accurate. The
scalar recursive algorithms are vectorized with the Intel's vector instructions
to achieve performance comparable to xNRM2, and are further parallelized with
OpenCilk. Some scalar algorithms are unconditionally bitwise reproducible,
while the reproducibility of the vector ones depends on the vector width.

</details>


### [7] [A High-order Backpropagation Algorithm for Neural Stochastic Differential Equation Model](https://arxiv.org/abs/2509.06292)
*Daili Sheng,Minghui Song,Xiang Peng,Xuanqi Dong*

Main category: math.NA

TL;DR: This paper develops a high-order backpropagation algorithm for neural stochastic differential equations to improve training accuracy and convergence rate, achieving first-order convergence under convexity assumptions.


<details>
  <summary>Details</summary>
Motivation: To improve the convergence rate of sample-wise backpropagation in neural SDE models, addressing challenges from information loss in backward equations and forward network limitations.

Method: Developed a high-order backpropagation algorithm for neural stochastic differential equation models with Brownian motion terms.

Result: Achieved first-order convergence when training steps are proportional to the cubic number of layers under convexity assumptions, validated by numerical examples.

Conclusion: The proposed high-order algorithm successfully improves training accuracy and convergence rate in neural SDE models, with theoretical results supported by numerical evidence.

Abstract: Neural stochastic differential equation model with a Brownian motion term can
capture epistemic uncertainty of deep neural network from the perspective of a
dynamical system. The goal of this paper is to improve the convergence rate of
the sample-wise backpropagation algorithm in neural stochastic differential
equation model which has been proposed in [Archibald et al., SIAM Journal on
Numerical Analysis, 62 (2024), pp. 593-621]. It is necessary to emphasize that,
improving the convergence order of the algorithm consisting of forward backward
stochastic differential equations remains challenging, due to the loss of
information of Z term in backward equations under sample-wise approximation and
the limitations of the forward network form. In this paper, we develop a
high-order backpropagation algorithm to improve the training accuracy. Under
the convexity assumption, the result indicates that the first-order convergence
is achieved when the number of training steps is proportional to the cubic
number of layers. Finally, numerical examples illustrate our theoretical
results.

</details>


### [8] [A Geometric Multigrid-Accelerated Compact Gas-Kinetic Scheme for Fast Convergence in High-Speed Flows on GPUs](https://arxiv.org/abs/2509.06347)
*Hongyu Liu,Xing Ji,Yuan Fu,Kun Xu*

Main category: math.NA

TL;DR: GPU-optimized implicit high-order CFD solver using geometric multigrid with multi-color LU-SGS, discontinuity-adaptive relaxation, and parallel V-cycle strategy for unstructured meshes, achieving 10-100x faster convergence while maintaining shock-capturing robustness.


<details>
  <summary>Details</summary>
Motivation: Integrate implicit methods and GPU parallelization for high-order CFD algorithms while preserving robustness with strong discontinuities and enabling massive thread parallelism under GPU memory constraints.

Method: Three key innovations: 1) multi-color LU-SGS scheme for conflict-free thread parallelism and memory efficiency, 2) discontinuity-adaptive relaxation with multigrid prolongation using discontinuous feedback factor, 3) three-layer V-cycle geometric parallel multigrid for unstructured meshes.

Result: Achieves 1-2 orders of magnitude faster convergence than explicit solvers, preserves shock-capturing robustness of explicit CGKS, and exhibits strong scalability on GPU architectures.

Conclusion: Presents a unified framework that synergistically combines implicit acceleration and GPU optimization for high-speed flow simulations, overcoming traditional trade-offs between parallelism, memory constraints, and numerical stability in high-order methods.

Abstract: Implicit methods and GPU parallelization are two distinct yet powerful
strategies for accelerating high-order CFD algorithms. However, few studies
have successfully integrated both approaches within high-speed flow solvers.
The core challenge lies in preserving the robustness of implicit algorithms in
the presence of strong discontinuities, while simultaneously enabling massive
thread parallelism under the constraints of limited GPU memory. To address
this, we propose a GPU-optimized, geometric multigrid-accelerated, high-order
compact gas kinetic scheme (CGKS) that incorporates three key innovations:
  (1) a multi-color lower-upper symmetric Gauss-Seidel scheme that eliminates
thread conflicts and preserves memory efficiency, serving as an implicit
smoother on coarse grids; (2) a discontinuity-adaptive relaxation technique and
a multigrid prolongation process, based on a discontinuous feedback factor,
which dynamically stabilize shock regions without compromising convergence in
smooth zones; and (3) a three-layer V-cycle geometric parallel multigrid
strategy specifically tailored for unstructured meshes. Extensive tests on
multi-dimensional subsonic to hypersonic flows demonstrate that our GPU-based
high-performance solver achieves one to two orders of magnitude faster
convergence compared to previous explicit solvers. More importantly, it
preserves the shock-capturing robustness of the explicit CGKS and exhibits
strong scalability on GPU architectures. This work presents a unified framework
that synergistically leverages implicit acceleration and GPU optimization for
high-speed flow simulations, effectively overcoming traditional trade-offs
between parallelism, memory constraints, and numerical stability in high-order
methods.

</details>


### [9] [Approximations of the mean curvature, and the Buet-Rumpf approximate mean curvature flow](https://arxiv.org/abs/2509.06438)
*Abdelmouksit Sagueni*

Main category: math.NA

TL;DR: Generalization of approximate mean curvature vector definition for varifolds and extension to second fundamental form, with comparison principles for mean curvature motion.


<details>
  <summary>Details</summary>
Motivation: To extend previous work by Buet and Rumpf on approximate mean curvature vectors for varifolds and mean curvature motions for point clouds.

Method: Proposed generalization of approximate mean curvature vector definition using linear operators and varifold regularity, extended to approximate second fundamental form.

Result: Developed generalized definitions and proved additional comparison principles for mean curvature motion in both discrete and continuous cases.

Conclusion: Successfully generalized previous work on mean curvature approximations and established new comparison principles for curvature-driven motions.

Abstract: The aim of this paper is to generalize the work of B. Buet and M. Rumpf on
some definition of the approximate mean curvature vector for varifolds, and its
associated mean curvature motions for points clouds. We propose a
generalization of the definition of the approximate mean curvature vector in
two terms: in terms of linear operators and in terms of regularity of the
varifold. We then extend the results to the approximate second fundamental
form. Finally, we prove some additional comparison principles satisfied by the
motion of points cloud by mean curvature (in the discrete and the continuous
cases).

</details>


### [10] [Sequential symmetric interior penalty discontinuous Galerkin method for fully coupled quasi-static thermo-poroelasticity problems](https://arxiv.org/abs/2509.06480)
*Fan Chen,Ming Cui,Chenguang Zhou*

Main category: math.NA

TL;DR: A sequentially decoupled numerical method for solving fully coupled quasi-static thermo-poroelasticity problems with nonlinear convective transport, using discontinuous Galerkin spatial discretization and backward Euler temporal discretization.


<details>
  <summary>Details</summary>
Motivation: To develop a more efficient numerical approach for thermo-poroelasticity problems that avoids the computational cost of fully implicit schemes while maintaining accuracy, without requiring internal iterations like other splitting algorithms.

Method: Symmetric interior penalty discontinuous Galerkin method for spatial discretization, backward Euler method for temporal discretization, with a sequential decoupling approach that eliminates the need for internal iterations.

Result: The method demonstrates higher computational efficiency than fully implicit nonlinear schemes, with proven existence and uniqueness of numerical solutions, stability analysis, and optimal convergence order estimates in both space and time.

Conclusion: The proposed sequentially decoupled method provides an accurate and efficient numerical solution for fully coupled quasi-static thermo-poroelasticity problems with nonlinear convective transport, validated through theoretical analysis and numerical examples.

Abstract: In this paper, we investigate a sequentially decoupled numerical method for
solving the fully coupled quasi-static thermo-poroelasticity problems with
nonlinear convective transport. The symmetric interior penalty discontinuous
Galerkin method is employed for spatial discretization and the backward Euler
method for temporal discretization. Unlike other splitting algorithms, this
type of sequential method does not require any internal iterations and the
computational efficiency is higher than that of the fully implicit nonlinear
numerical scheme. In the theoretical analysis, a cut-off operator is introduced
to prove the existence and uniqueness of numerical solution and the stability
analysis of numerical scheme is conducted. Then, we derive the optimal
convergence order estimates in space and time. Finally, several numerical
examples are presented to illustrate the accuracy and efficiency of our
proposed method.

</details>


### [11] [Solving PDEs on Surfaces of Pipe Geometries Using New Coordinate Transformations and High-order Compact Finite Differences](https://arxiv.org/abs/2509.06507)
*Shuaifei Hu,Yujian Jiao,Desong Kong,Li-Lian Wang*

Main category: math.NA

TL;DR: Developed curvilinear coordinate systems for pipe geometries to transform PDEs into fixed computational domains, with efficient fourth-order compact finite difference methods for variable coefficients.


<details>
  <summary>Details</summary>
Motivation: To handle PDEs on pipe surfaces and solid pipes by transforming them into computational domains with fixed limits, similar to polar/cylindrical coordinates for advantageous geometries.

Method: Created non-orthogonal curvilinear coordinate systems, developed fourth-order compact finite difference methods adaptable to variable coefficients from coordinate transformations and diverse surface geometries.

Result: Rigorously proved convergence for model problems, applied solver to various PDE types, demonstrated efficiency and accuracy with ample numerical results.

Conclusion: The approach provides an effective framework for solving PDEs on pipe geometries, with compact finite differences working well and potential for spectral-collocation methods to handle variable coefficient problems.

Abstract: We introduce suitable coordinate systems for pipes and their variants that
allow us to transform partial differential equations (PDEs) on the pipe
surfaces or in the solid pipes into computational domains with fixed
limits/ranges. Such a notion is reminiscent of the polar and cylindrical
coordinates for their advantageous geometries. The new curvilinear coordinates
are non-orthogonal in two directions, so the Laplace--Beltrami operators
involve mixed derivatives. To deal with the variable coefficients arising from
coordinate transformations and diverse surface geometries, we develop efficient
fourth-order compact finite difference methods adaptable to various scenarios.
We then rigorously prove the convergence of the proposed method for some model
problem, and apply the solver to several other types of PDEs. We further
demonstrate the efficiency and accuracy of our approach with ample numerical
results. Here, we only consider the compact finite differences for the
transformed PDEs for simplicity, but one can employ the spectral-collocation
methods to efficiently handle such variable coefficient problems.

</details>


### [12] [Fractal Based Rational Cubic Trigonometric Zipper Interpolation with Positivity Constraints](https://arxiv.org/abs/2509.06532)
*A. K. Sharma,K. R. Tyada*

Main category: math.NA

TL;DR: A novel rational cubic trigonometric zipper fractal interpolation method that preserves positivity in datasets through careful parameter selection and scaling factor constraints.


<details>
  <summary>Details</summary>
Motivation: To develop an interpolation scheme that can model and preserve the inherent geometric property of positivity in datasets, which traditional interpolants may violate.

Method: Combines rational cubic trigonometric functions within a zipper fractal framework using shape parameters and scaling factors, with rigorous error analysis and constraints to ensure positivity preservation.

Result: The method successfully constructs RCTZFIFs that preserve data positivity while offering fractal flexibility, outperforming reference interpolants that may violate this property.

Conclusion: The proposed RCTZFIFs provide an effective and robust approach for positivity-preserving interpolation with fractal characteristics, validated through numerical experiments and visualizations.

Abstract: We propose a novel fractal based interpolation scheme termed Rational Cubic
Trigonometric Zipper Fractal Interpolation Functions (RCTZFIFs) designed to
model and preserve the inherent geometric property, positivity, in given
datasets. The method employs a combination of rational cubic trigonometric
functions within a zipper fractal framework, offering enhanced flexibility
through shape parameters and scaling factors. Rigorous error analysis is
presented to establish the convergence of the proposed zipper fractal
interpolants to the underlying classical fractal functions, and subsequently,
to the data-generating function. We derive necessary constraints on the scaling
factors and shape parameters to ensure positivity preservation. By carefully
selecting the signature, shape parameters, and scaling factors within these
bounds, we construct a class of RCTZFIFs that effectively preserve the positive
nature of the data, as compared to a reference interpolant that may violate
this property. Numerical experiments and visualisations demonstrate the
efficacy and robustness of our approach in preserving positivity while offering
fractal flexibility.

</details>


### [13] [A novel time integration scheme for linear parabolic PDEs](https://arxiv.org/abs/2509.06556)
*Subhankar Nandi,Satyajit Pramanik*

Main category: math.NA

TL;DR: RBF-enhanced Crank-Nicolson schemes for parabolic PDEs that maintain CN simplicity while achieving higher-order accuracy through shape parameter optimization, with comparable accuracy to IRK methods but significantly lower computational cost.


<details>
  <summary>Details</summary>
Motivation: To develop time integration schemes for linear parabolic PDEs that combine the structural simplicity of classical Crank-Nicolson methods with higher-order temporal accuracy through radial basis function interpolation.

Method: Enhanced Crank-Nicolson schemes using radial basis function interpolation with optimized shape parameters, analyzed for consistency and stability, and tested numerically in 1D with various boundary conditions and initialization strategies.

Result: The schemes achieve at least second-order accuracy, with simple shape parameter choices increasing accuracy by two orders over standard CN. Further optimization enables even higher-order accuracy while maintaining similar stability conditions. Numerical experiments show comparable accuracy to implicit Runge-Kutta methods with nearly two orders of magnitude computational cost reduction.

Conclusion: RBF-enhanced Crank-Nicolson schemes provide an efficient alternative to implicit Runge-Kutta methods, offering high accuracy with significantly reduced computational cost while preserving the simplicity and stability of classical CN methods.

Abstract: This paper presents a class of Crank-Nicolson (CN) type schemes enhanced by
radial basis function (RBF) interpolation for the time integration of linear
parabolic partial differential equations (PDEs). The resulting RBF-CN schemes
preserve the structural simplicity of the classical CN method while enabling
higher-order temporal accuracy through the optimization of the shape parameter.
Consistency analysis shows that the schemes are always at least second-order
accurate and a simple choice of the shape parameter increases the accuracy by
two orders over the standard CN scheme. Further optimization can reduce the
next leading error term to attain even higher-order accuracy. A von Neumann
stability analysis confirms that the stability conditions are essentially the
same as those of the standard CN scheme. Several numerical experiments in 1D
are carried out to verify the theoretical results under different boundary
conditions. Particular focus is given to the startup stage, where several
strategies for computing the initial steps are examined, and Gauss-Legendre
implicit Runge-Kutta (IRK) methods are found to be the most effective. The
experiments further demonstrate that, with optimal initialization, the proposed
schemes deliver accuracy comparable to implicit Runge-Kutta methods while
achieving nearly two orders of magnitude reduction in computational cost.

</details>


### [14] [Fisher entropic Fokker-Planck model of monatomic rarefied gases](https://arxiv.org/abs/2509.06610)
*Veronica Montanaro,Lukas Netterdon,Manuel Torrilhon,Hossein Gorji*

Main category: math.NA

TL;DR: Proposes a Fisher Entropic Fokker-Planck framework that simultaneously achieves moment matching with Boltzmann equation and satisfies H-theorem for efficient non-equilibrium gas flow simulations.


<details>
  <summary>Details</summary>
Motivation: Particle-based Boltzmann equation simulations are computationally demanding in near-continuum regimes, while existing Fokker-Planck models struggle to balance moment consistency with entropy dissipation requirements.

Method: Introduces Fisher information-based entropic constraint and uses polynomial expansion of drift term to achieve weak moment matching while honoring H-theorem.

Result: Developed framework successfully achieves both moment consistency with Boltzmann operator and entropy dissipation, validated through numerical experiments on shock problems.

Conclusion: The Fisher Entropic Fokker-Planck framework provides an efficient and rigorous alternative to particle-based methods for non-equilibrium gas flow simulations, addressing both moment matching and entropy constraints.

Abstract: Particle-based stochastic approximations of the Boltzmann equation are
popular tools for simulations of non-equilibrium gas flows, for which the
Navier-Stokes-Fourier equations fail to provide accurate description. However,
these numerical methods are computationally demanding, especially in the
near-continuum regime, where the collisions become overwhelming. On the other
hand, the Fokker-Planck kinetic models offer an efficient alternative, as the
binary collisions are described by a diffusive process. Despite the intuitive
advantage, rigorous and efficient Fokker-Planck approximations of the Boltzmann
equation remain an open problem. On one hand, the moment projection of the
Fokker-Planck operator should be consistent with that of the Boltzmann
operator. On the other hand, the Fokker-Planck model should be constructed in
such a way that the H-theorem is satisfied. The central aim of this study is
fulfilling these two categorically different constraints, i.e. moment matching
and entropy dissipation, within a flexible and tractable Fokker-Planck
framework. To this end, we introduce a Fisher information-based entropic
constraint and demonstrate that, with a suitable polynomial expansion of the
drift term, it is possible to simultaneously achieve weak moment matching while
honouring the H-theorem. We support our theoretical result by numerical
experiments on the shock problem, validating our Fisher Entropic Fokker-Planck
framework.

</details>


### [15] [A Parallel Solver with Multiphysics Finite Element Method for Poroelasticity Coupled with Elasticity Model](https://arxiv.org/abs/2509.06673)
*Zhihao Ge,Chengxin Wang*

Main category: math.NA

TL;DR: Parallel solver for quasi-static linear poroelasticity coupled with linear elasticity using Lagrange multiplier framework and FETI method for efficient parallel computation.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient parallel computational method for solving coupled poroelasticity-elasticity problems with guaranteed numerical stability and accuracy.

Method: Reformulated model into nearly incompressible elasticity and unsteady advection-diffusion equations, introduced Lagrange multiplier for interface continuity, used mixed finite elements (Pk-P1-P1 for poroelasticity, Pk-P1 for elasticity), backward Euler time scheme, and FETI parallel solver.

Result: Numerical tests validated computational efficiency, convergence error order, and absence of pressure oscillations in Barry-Mercer's benchmark test.

Conclusion: The proposed parallel solver effectively handles coupled poroelasticity-elasticity problems with good computational performance and numerical stability.

Abstract: In this paper, we propose a parallel solver for solving the quasi-static
linear poroelasticity coupled with linear elasticity model in the Lagrange
multiplier framework. Firstly, we reformulate the model into a coupling of the
nearly incompressible elasticity and an unsteady affection-diffusion equations
by setting new variable ``elastic pressure" and ``volumetric fluid content".
And we introduce a Lagrange multiplier to guarantee the normal stress
continuity on the interface. Then, we give the variational formulations in each
subdomain and choose the $\boldsymbol{P}_k$-$P_1$-$P_1$ mixed finite element
tuple for poroelasticity subdomain, and $\boldsymbol{P}_k$-$P_1$ finite element
pair ($k=1,2$) for elasticity subdomain and the backward Euler scheme for time.
Also, we propose a parallel solver for solving the fully discrete scheme at
each time step -- the FETI method with a classical FETI preconditioner for
solving the Lagrange multiplier and calculating the subproblems in each
subdomain in parallel. And we show several numerical tests to validate the
computational efficiency and the convergence error order, and we consider
Barry-Mercer's model as the benchmark test to show that there no oscillation in
the computed pressure. Finally, we draw conclusions to summarize the main
results of this paper.

</details>


### [16] [Chebyshev smoothing with adaptive block-FSAI preconditioners for the multilevel solution of higher-order problems](https://arxiv.org/abs/2509.06744)
*Pablo Jiménez Recio,Marc Alexander Schweitzer*

Main category: math.NA

TL;DR: Performance evaluation of adaptive and nested factorized sparse approximate inverses as smoothers in multilevel V-cycles using Chebyshev iteration of the fourth kind, with new adaptive algorithm and simplified Chebyshev formulation.


<details>
  <summary>Details</summary>
Motivation: To assess the effectiveness of adaptive and nested factorized sparse approximate inverses as smoothers in multilevel V-cycles for solving biharmonic and triharmonic equations discretized via the partition of unity method.

Method: Uses partition of unity method for multilevel discretization, introduces new adaptive algorithm for sparse approximate inverse construction based on matrix block structure, and presents simplified formulation of Chebyshev iteration of the fourth kind.

Result: The paper presents performance assessment results for the proposed methods, though specific numerical results are not detailed in the abstract.

Conclusion: The work contributes new adaptive algorithms and simplified formulations for improving multilevel solution methods for high-order PDEs like biharmonic and triharmonic equations.

Abstract: In this paper, we assess the performance of adaptive and nested factorized
sparse approximate inverses as smoothers in multilevel V-cycles, when smoothing
is performed following the Chebyshev iteration of the fourth kind. For our test
problems, we rely on the partition of unity method to discretize the biharmonic
and triharmonic equations in a multilevel manner. Inspired by existing
algorithms, we introduce a new adaptive algorithm for the construction of
sparse approximate inverses, based on the block structure of matrices arising
in the partition of unity method. Additionally, we also present a new (and
arguably simpler) formulation of the Chebyshev iteration of the fourth kind.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [17] [Chemotaxis Models with Nonlinear/Porous Medium Diffusion, Consumption, and Logistic source on $\mathbb{R}^N$: I. Global Solvability and Boundedness](https://arxiv.org/abs/2509.05494)
*Zulaihat Hassan,Wenxian Shen,Yuming Paul Zhang*

Main category: math.AP

TL;DR: Global existence and boundedness of weak solutions for a parabolic-parabolic chemotaxis system with logistic source and chemical consumption in R^N


<details>
  <summary>Details</summary>
Motivation: To establish global solvability and boundedness properties for chemotaxis systems with logistic growth and chemical consumption, which are important in biological modeling of cell movement and pattern formation

Method: Deriving local L^p estimates uniform in time using a new continuity-type argument, and obtaining L^∞ bounds via Moser's iteration technique, with all estimates uniform as ε→0

Result: Proved existence of global weak solutions that remain uniformly bounded for all times, even for general bounded initial data that may be non-integrable

Conclusion: The paper successfully establishes global bounded weak solutions for the chemotaxis system, with techniques that work uniformly as the regularization parameter ε approaches zero

Abstract: This series of papers is concerned with the global solvability, boundedness,
regularity, and uniqueness of weak solutions to the following
parabolic-parabolic chemotaxis system with a logistic source and chemical
consumption: \begin{equation*} \begin{cases} u_t = m\nabla\cdot
\left((\eps+u)^{m-1}\nabla u\right) - \chi \nabla \cdot (u \nabla v) + u(a - b
u), & \text{ in } (0,\infty)\times\mathbb{R}^N, \\ v_t = \Delta v - uv, &
\text{ in } (0,\infty)\times\mathbb{R}^N, \end{cases} \end{equation*} where $m
> 1$ and $\eps \geq 0$. The present paper focuses on the global solvability and
boundedness of weak solutions. For general bounded initial data, which may be
non-integrable, we prove the existence of global weak solutions that remain
uniformly bounded for all times. The proof relies on deriving local $L^p$
estimates that are uniform in time via a new continuity-type argument and
obtaining $L^\infty$ bounds using Moser's iteration; all of these estimates are
uniform as $\eps\to0$. In part II, we will study the regularity and uniqueness
of weak solutions.

</details>


### [18] [Stability of Degenerate Schrödinger Equation with Harmonic Method](https://arxiv.org/abs/2509.05533)
*Khadidja Fekirini,Naima Louhibi,Abbes Benaissa*

Main category: math.AP

TL;DR: Study of well-posedness and stability for degenerate Schrödinger equation with boundary control at degeneracy point


<details>
  <summary>Details</summary>
Motivation: To analyze degenerate Schrödinger equations with boundary controls acting at the degeneracy point, establishing mathematical foundations for such systems

Method: Established well-posedness using Dirichlet-Neumann boundary conditions, then employed complex analysis methods to prove stability properties

Result: Proved well-posedness and established both exponential and polynomial decreasing properties of solutions, with results shown to be optimal

Conclusion: The degenerate Schrödinger equation with boundary control at degeneracy is well-posed and exhibits optimal stability properties with both exponential and polynomial decay rates

Abstract: This paper is devoted to study the well-posedness and stability of degenerate
Schr\"{o}dinger equation with a boundary control acting at the degeneracy.
First, we establish the well-posedness of the degenerate problem
$v_t(x,t)+\imath(x^\alpha v_x(x,t))_x=0, \hbox{ with } x \in (0,1)$, controlled
by Dirichlet-Neumann conditions. Then, exponential and polynomial decreasing of
the solution are established. This result is optimal and it is obtained using
complex analysis method.

</details>


### [19] [Energy Transfer Dynamics Generated by Non-Axisymmetric Tornado-Type Flows](https://arxiv.org/abs/2509.05546)
*Afifah Maya Iknaningrum,Pen-Yuan Hsu,Tsuyoshi Yoneda,Hirofumi Notsu*

Main category: math.AP

TL;DR: Study constructs tornado-type flow to reveal time-dependent elementary processes behind energy cascade in turbulence, moving beyond spatial statistics to identify specific vortex dynamics.


<details>
  <summary>Details</summary>
Motivation: Previous studies by Richardson, Kolmogorov, and recent numerical works lacked connection to underlying fluid dynamics and remained within spatial statistics, leaving the time-dependent elementary process of energy cascade unexplored.

Method: Constructed a tornado-type flow in a non-axisymmetric curved cylindrical domain to study vortex dynamics and energy transfer mechanisms.

Result: Revealed specific vortex dynamics responsible for energy transfer, providing new physical insights into turbulence mechanisms.

Conclusion: The approach successfully uncovers the time-dependent elementary process behind energy cascade, offering new understanding of turbulence physics beyond traditional spatial statistics.

Abstract: The energy cascade in turbulence, first statistically described by Richardson
(1922) and Kolmogorov (1941), lacked connection to the underlying fluid
dynamics. Recent numerical studies of Goto et al. (2017) and Yoneda et al.
(2022) revealed scale-local energy transfer via vortex stretching but remained
within spatial statistics. This study aims to uncover the time-dependent
elementary process behind the energy cascade by constructing a tornado-type
flow in a non-axisymmetric curved cylindrical domain. Our approach reveals
specific vortex dynamics responsible for energy transfer, offering new insight
into the physical mechanisms of turbulence.

</details>


### [20] [Multiple solutions to a class of $p$-Laplacian Schrödinger equations](https://arxiv.org/abs/2509.05556)
*Lin Zhang*

Main category: math.AP

TL;DR: Proves infinitely many solutions for a p-Laplacian type equation using variational perturbation method, addressing an open problem from Candela et al.


<details>
  <summary>Details</summary>
Motivation: The equation's functional doesn't satisfy Palais-Smale condition in standard Sobolev spaces, making multiplicity analysis challenging. The paper aims to resolve an open question about solution multiplicity for this class of equations.

Method: Uses variational perturbation method to construct novel perturbation space and functional. Leverages established results on classical p-Laplacian equations to analyze the target equation.

Result: Successfully proves the existence of infinitely many solutions to the given p-Laplacian equation with coercive potential.

Conclusion: The variational perturbation approach effectively addresses the multiplicity problem that couldn't be solved within the standard W^{1,p}∩L^∞ framework, positively answering the open question from Candela et al.

Abstract: In this paper, we will prove the existence of infinitely many solutions to
the following equation by utilizing the variational perturbation method
\begin{equation*} -div(A(x,u)|\nabla u|^{p-2}\nabla
u)+\frac{1}{p}A_{t}(x,u)|\nabla u|^{p}+V(x)|u|^{p-2}u=g(x, u), ~~
x\in\mathbb{R}^{N}, \end{equation*} where $2<p<N$, $V(x)$ represents a coercive
potential. It should be emphasized that the multiplicity of solutions is
unsuitable to be discussed under the framework of $W^{1,p}(\mathbb{R}^{N})\cap
L^{\infty}(\mathbb{R}^{N})$, as the functional corresponding to the above
equation does not satisfy the Palais-Smale condition in this space. To this
end, we will use the variational perturbation method to construct novel
perturbation space and perturbation functional. By relying on the established
conclusions regarding the multiplicity of solutions for classical $p$-Laplacian
equations, we shall analyze the equation in question. Our result addresses
positively the open question from Candela et. al in CVPDE.

</details>


### [21] [Nonradial normalized solutions for a quasilinear Schrödinger equation via dual approach](https://arxiv.org/abs/2509.05557)
*Lin Zhang*

Main category: math.AP

TL;DR: Using dual method to construct multiple nonradial normalized solutions for quasilinear Schrodinger equation with mass-subcritical constraint, introducing new workspace for compactness in nonradial case.


<details>
  <summary>Details</summary>
Motivation: To address the lack of nonradial results for quasilinear Schrodinger equations and develop methods to handle compactness issues in nonradial problems.

Method: Dual method approach with construction of new workspace to ensure compactness for nonradial solutions, building upon techniques from TMNA.

Result: Successful construction of multiple nonradial normalized solutions for the quasilinear Schrodinger equation with mass-subcritical constraint.

Conclusion: The paper provides novel nonradial results and methodological advancements for handling compactness in nonradial quasilinear Schrodinger problems, expanding existing techniques.

Abstract: In this paper, we will utilize the dual method to construct multiple
nonradial normalized solutions of the following quasilinear Schr\"{o}dinger
equation: \begin{equation*} -\Delta u-\Delta(|u|^{2})u-\mu u=|u|^{p-2}u, \qquad
in \quad \mathbb{R}^N, \end{equation*} subject to a mass-subcritical
constraint. It should be emphasized that the nonradial result of this equation
is new. Besides that, when considering the nonradial problem, it is necessary
to construct a new workspace to ensure the compactness. Meanwhile, in this
paper, we will expand on the method mentioned in TMNA.

</details>


### [22] [Construction of Exceptional Points in Time-Modulated High-Contrast Elastic Media](https://arxiv.org/abs/2509.05561)
*Yixian Gao,Shuguan Ji,Shangling Song*

Main category: math.AP

TL;DR: Analysis of subwavelength quasi-frequencies in high-contrast elastic metamaterials and derivation of ODE system for time-modulated structures, enabling construction of 3D exceptional points.


<details>
  <summary>Details</summary>
Motivation: To understand the rich physical phenomena in spatially periodic elastic metamaterials with hard inclusions in soft matrix, particularly focusing on subwavelength quasi-frequencies and their behavior under static and time-modulated conditions.

Method: Analyzed subwavelength quasi-frequencies under static conditions, derived a system of ordinary differential equations (ODEs) for time-modulated structures in subwavelength regime, and applied Floquet's theorem to construct exceptional points.

Result: Established functional dependence of quasi-frequencies on high-contrast parameter, demonstrated that derived ODE system accurately captures quasi-frequency behavior, and constructed concrete examples of first-order asymptotic exceptional points in three dimensions.

Conclusion: The developed framework provides effective tools for analyzing and designing elastic metamaterials with exceptional points, enabling precise control over wave propagation properties in high-contrast periodic structures.

Abstract: Spatially periodic elastic metamaterials, comprising hard inclusions within a
soft matrix in $d$-dimensional space ($d\geq 2$), exhibit a rich spectrum of
physical phenomena. This paper investigates such a model and presents the
following contributions. First, we analyze the system's subwavelength
quasi-frequencies under static conditions, establishing their functional
dependence on the high-contrast parameter. This analysis enables the
determination of the subwavelength quasi-frequency range. Second, for
time-modulated structures, we derive a system of ordinary differential
equations (ODEs) within the subwavelength regime. We demonstrate that this ODE
system accurately captures the quasi-frequency behavior of the original elastic
system. Finally, leveraging the derived ODEs and Floquet's theorem, we
construct concrete examples of first-order asymptotic exceptional points (EPs)
in three dimensions.

</details>


### [23] [Random Regularity of the Vlasov-Poisson System with Random Initial Inputs in the Quasineutral Regime](https://arxiv.org/abs/2509.05601)
*Wenyi Wang,Yiwen Lin*

Main category: math.AP

TL;DR: This paper analyzes the Vlasov-Poisson system with initial uncertainty in the quasineutral regime, proving uniform convergence of Wasserstein distance and establishing random regularity of solutions.


<details>
  <summary>Details</summary>
Motivation: To quantify the propagation of initial uncertainty in the Vlasov-Poisson system in the quasineutral regime, which is widely used in plasma physics but lacks theoretical understanding of uncertainty propagation.

Method: Proving uniform convergence of Wasserstein distance between uncertain system and its quasineutral limit, deriving upper bounds, defining new norm with respect to quasineutral parameter, and estimating distribution function and electric field using variable substitution.

Result: Established uniform convergence of Wasserstein distance and random regularity of solutions in the quasineutral regime.

Conclusion: Developed a novel framework for quantifying initial uncertainty propagation in Vlasov-Poisson systems, providing theoretical basis for designing high-performance numerical algorithms.

Abstract: The Vlasov-Poisson system is widely used in plasma physics and other related
fields. In this paper, we study the Vlasov-Poisson system with initial
uncertainty in the quasineutral regime. First, we prove the uniform convergence
of the Wasserstein distance between the uncertain Vlasov-Poisson system in the
quasineutral regime and its quasineutral limit system with random initial
inputs. This is achieved by deriving an upper bound for the Wasserstein
distance and rigorously estimating each component of this bound. Furthermore,
by defining a new norm with respect to the quasineutral parameter and
estimating the distribution function as well as the electric field in this norm
using a variable substitution, we establish the random regularity of the
solutions in the quasineutral regime. This work develops a novel framework for
quantifying the propagation of the initial uncertainty of the Vlasov-Poisson
system in the quasineutral regime, providing a theoretical basis for designing
high-performance numerical algorithms.

</details>


### [24] [Well-posedness and regularity theory for the fractional diffusion-wave equation in Lebesgue spaces](https://arxiv.org/abs/2509.05654)
*Bruno de Andrade,Naldisson Santos*

Main category: math.AP

TL;DR: Analysis of semilinear fractional diffusion-wave equations with focus on operator estimates, existence/uniqueness of local mild solutions, maximal continuation, spatial regularity, and continuous dependence on initial data.


<details>
  <summary>Details</summary>
Motivation: To study semilinear fractional diffusion-wave equations and establish rigorous mathematical foundations for understanding their behavior through operator theory and solution properties.

Method: Using fractional power scale associated with Laplace operator to provide estimates on linear operator families, then analyzing existence/uniqueness of local mild solutions and their continuation properties.

Result: Established estimates for linear operators, proved existence and uniqueness of local mild solutions, determined conditions for maximal continuation, and analyzed spatial regularity and continuous dependence on initial data.

Conclusion: The paper provides comprehensive mathematical analysis of semilinear fractional diffusion-wave equations, establishing fundamental properties including solution existence, uniqueness, regularity, and dependence on initial conditions.

Abstract: This paper is dedicated to the study of the semilinear fractional
diffusion-wave equation. We provide estimates on the families of linear
operators related to the problem in the fractional power scale associated with
the Laplace operator. Furthermore, we analyze the existence and uniqueness of
local mild solutions and their possible continuation to a maximal interval of
existence. We also consider the issue of spatial regularity and continuous
dependence with respect to initial data.

</details>


### [25] [$L^p$ Hardy inequalities with homogeneous weights](https://arxiv.org/abs/2509.05674)
*Subhajit Roy*

Main category: math.AP

TL;DR: Analysis of weighted Hardy inequalities with measurable functions on spheres, identifying optimal function spaces and establishing sharp constants for fractional Hardy inequalities with homogeneous weights.


<details>
  <summary>Details</summary>
Motivation: To extend Hardy inequalities by considering measurable functions on spheres as weights, determining the precise function spaces where such inequalities hold, and obtaining sharp constants particularly when the weight function is identically 1.

Method: Mathematical analysis of weighted Hardy inequalities involving functions g on the unit sphere, examining different parameter regimes (N, p, α) to identify suitable function spaces where the inequality holds with optimal constants.

Result: Identified appropriate function spaces for g depending on the parameters N, p, and α such that the weighted Hardy inequality holds. Obtained sharp constants, particularly proving optimality when g ≡ 1. Established sharp fractional Hardy inequalities with homogeneous weights.

Conclusion: The paper provides a complete characterization of weighted Hardy inequalities with sphere-based weights, determining the exact function spaces and sharp constants, extending classical Hardy inequalities to more general weighted settings with optimal results.

Abstract: For $p\in (1,\infty)$ and $\alpha\in\mathbb{R}$, we consider measurable
functions $g$ on $\mathbb{S}^{N-1}$ that satisfy the following weighted Hardy
inequality: \begin{equation}\label{abs}
  \int_{\mathbb{R}^N}\frac{ g (x/|x|)}{|x|^{p+\alpha}}|u(x)|^p dx \leq
C\int_{\mathbb{R}^N}\frac{|\nabla u(x)|^p}{|x|^\alpha} dx, \quad\forall\,u\in
\mathcal{C}_c^\infty(\mathbb{R}^N), \end{equation} for some constant $C>0$.
Depending on $N$, $p$, and $\alpha$, we identify suitable function spaces for
$g$ so that \eqref{abs} holds. The constant obtained is sharp, in the sense
that it is sharp when $g \equiv 1$. Furthermore, we establish the sharp
fractional Hardy inequality with homogeneous weights.

</details>


### [26] [High-friction limit for bipolar Euler-Riesz systems](https://arxiv.org/abs/2509.05742)
*Nuno J. Alves,Jan Haskovec*

Main category: math.AP

TL;DR: Rigorous justification of high-friction limit from bipolar Euler-Riesz system to bipolar aggregation-diffusion system with Riesz interactions using relative entropy method.


<details>
  <summary>Details</summary>
Motivation: Extend previous results on high-friction limits from Euler-Poisson systems to more general Riesz interactions, and from one-species to bipolar Euler-Riesz systems.

Method: Relative entropy method applied in the regime where smooth solutions of the limiting aggregation-diffusion equations exist.

Result: Successful justification of the high-friction limit from bipolar Euler-Riesz system to bipolar aggregation-diffusion system with Riesz interactions.

Conclusion: The work generalizes previous high-friction limit results to broader interaction classes and multi-species settings, establishing mathematical rigor for this important asymptotic limit.

Abstract: We consider a bipolar Euler-Riesz system and rigorously justify the
high-friction limit of weak solutions towards a bipolar aggregation-diffusion
system with Riesz interactions. The analysis is carried out via the relative
entropy method in the regime where smooth solutions of the limiting equations
exist. This extends previous results on the high-friction limit of bipolar
Euler-Poisson systems to a more general class of interactions, and extends the
one-species Euler-Riesz case to the bipolar setting.

</details>


### [27] [Hölder regularity of weak solutions to nonlocal doubly degenerate parabolic equations](https://arxiv.org/abs/2509.05914)
*Qifan Li*

Main category: math.AP

TL;DR: Local Hölder continuity for sign-changing solutions of nonlocal doubly degenerate parabolic equations under tail conditions


<details>
  <summary>Details</summary>
Motivation: Study local regularity properties for nonlocal doubly degenerate parabolic equations, which combine nonlocal operators with degenerate nonlinearities

Method: Nonlocal version of De Giorgi technique combined with the method of intrinsic scaling, applied under a parabolic tail condition

Result: Any locally bounded and sign-changing solution is locally Hölder continuous

Conclusion: The developed techniques successfully establish local Hölder continuity for solutions to this class of nonlocal degenerate parabolic equations

Abstract: We study local regularity for nonlocal doubly degenerate parabolic equations.
The model equation is
  \begin{equation*}\begin{split}
\partial_t(|u|^{q-1}u)+\mathrm{P}.\mathrm{V}.\int_{\mathbb{R}^n}\frac{|u(x,t)-u(y,t)|^{p-2}(u(x,t)-u(y,t))}{|x-y|^{n+sp}}\,\mathrm{d}y=0,
\end{split} \end{equation*} where $0<s<1$, $p>2$ and $0<q<p-1$. Under a
parabolic tail condition, we show that any locally bounded and sign-changing
solution is locally H\"older continuous. Our proof is based on a nonlocal
version of De Giorgi technique and the method of intrinsic scaling.

</details>


### [28] [The Gross-Pitaewsky equation with time and space dependent coefficients](https://arxiv.org/abs/2509.06001)
*Federico Lai*

Main category: math.AP

TL;DR: Analysis of existence and properties of solutions to a parabolic reaction-diffusion system (Gross-Pitaevskii equation) with time/space dependent coefficients that may blow up or vanish asymptotically, with non-segregated initial data.


<details>
  <summary>Details</summary>
Motivation: To study the mathematical properties of solutions to the Gross-Pitaevskii equation with variable coefficients, particularly addressing cases where solutions may exhibit blow-up or vanishing behavior over time, and extending analysis to non-segregated initial conditions.

Method: Mathematical analysis of parabolic reaction-diffusion systems, specifically the Gross-Pitaevskii equation with time and space dependent coefficients, examining solution existence and asymptotic behavior.

Result: The paper establishes conditions for solution existence and analyzes properties of solutions that may blow up or vanish asymptotically in time, including cases with non-segregated initial data.

Conclusion: The study provides important mathematical insights into the behavior of Gross-Pitaevskii equation solutions with variable coefficients, particularly addressing challenging cases of blow-up and vanishing phenomena with general initial conditions.

Abstract: In this work we study the existence and other properties of a solution of a
parabolic reaction-diffusion system, that is the the Gross-Pitaevskii equation
with time and space dependent coefficients, that could blow up or vanish
asymptotically in time, with an initial data not necessarily segregated.

</details>


### [29] [A Recursive Algorithm for Multi-Coefficient Inversion in Nonlinear Helmholtz Equations](https://arxiv.org/abs/2509.06008)
*Shuai Lu,Boxi Xu*

Main category: math.AP

TL;DR: Recursive algorithm for multi-coefficient inversion in nonlinear Helmholtz equations using Dirichlet-to-Neumann map measurements and Fourier-based approach with complex exponential solutions.


<details>
  <summary>Details</summary>
Motivation: To achieve effective recursive decoupling and simultaneous recovery of multiple coefficients in nonlinear Helmholtz equations with polynomial-type nonlinearities.

Method: Developed a novel Fourier-based approach combining inclusion-exclusion principle with carefully constructed complex exponential solutions, utilizing linearized Dirichlet-to-Neumann map as measurement data.

Result: Algorithm ensures unique identifiability and yields progressively increasing stability with enhanced wavenumbers. Numerical experiments demonstrate computational efficiency and excellent reconstruction accuracy.

Conclusion: The recursive algorithm successfully achieves multi-coefficient inversion with unique identifiability, improved stability, and high computational efficiency for nonlinear Helmholtz equations.

Abstract: We present a recursive algorithm for multi-coefficient inversion in nonlinear
Helmholtz equations with polynomial-type nonlinearities, utilizing the
linearized Dirichlet-to-Neumann map as measurement data. To achieve effective
recursive decoupling and simultaneous recovery of multiple coefficients, we
develop a novel Fourier-based approach that combines the principle of
inclusion-exclusion with carefully constructed complex exponential solutions.
This methodology not only ensures unique identifiability but also yields
progressively increasing stability with enhanced wavenumbers. Comprehensive
numerical experiments demonstrate the algorithm's computational efficiency and
excellent reconstruction accuracy.

</details>


### [30] [Well-Posedness of the Cauchy Problem for First-order Quasilinear Equations with Non-Lipschitz Source Terms and Its Applications](https://arxiv.org/abs/2509.06020)
*Gaowei Cao,Gui-Qiang G. Chen,Wei Xiang,Xiaozhou Yang*

Main category: math.AP

TL;DR: Analysis of well-posedness for quasilinear equations with non-Lipschitz source terms and global structures of multi-dimensional Riemann solutions, revealing novel wave behaviors including finite-time disappearance and interior discontinuities.


<details>
  <summary>Details</summary>
Motivation: To address the well-posedness of Cauchy problems for first-order quasilinear equations with non-Lipschitz source terms and understand the global structures of multi-dimensional Riemann solutions, particularly when source terms lack standard Lipschitz continuity properties.

Method: Prove that Kruzkov entropy condition guarantees well-posedness for entropy solutions with right-Lipschitz source terms; construct global multidimensional Riemann solutions with non-selfsimilar structures including shock and rarefaction waves; analyze these waves through implicit functions determined by initial discontinuity, flux functions, and non-Lipschitz source terms.

Result: Discovered two new phenomena: (1) basic waves can disappear in finite time, and (2) new-type rarefaction waves can contain weak interior discontinuities. These contrast with Lipschitz source cases where waves persist globally and remain smooth. Provided examples demonstrating uniqueness with left non-Lipschitz sources and non-uniqueness with right non-Lipschitz sources.

Conclusion: Non-Lipschitz source terms fundamentally alter the behavior of quasilinear equations, leading to finite-time wave disappearance and interior discontinuities in rarefaction waves, with solution uniqueness dependent on the specific non-Lipschitz properties of the source term.

Abstract: We are concerned with the well-posedness of the Cauchy problem for the
first-order quasilinear equations with non-Lipschitz source terms and the
global structures of the multi-dimensional Riemann solutions. For such
quasilinear equations with initial data in $L^\infty$, when the source term
$g(t, x, u)$ is only right-Lipschitz (not necessarily left-Lipschitz) in $u$,
we first prove that the Kruzkov entropy condition is sufficient to guarantee
the well-posdeness of entropy solutions. Next, we analyze the structures of
global multi-dimensional Riemann solutions for scalar conservation laws with
non-Lipschitz source terms, where the Riemann-type initial data consist of two
different constant states separated by a smooth hypersurface. More precisely,
we construct the global multidimensional Riemann solutions with non-selfsimilar
structures, including nonselfsimilar shock waves and nonselfsimilar rarefaction
waves, and prove that these two kinds of basic waves can be expressed via the
implicit functions of functional equation determined by the initial
discontinuity, the flux functions, and the non-Lipschitz source term. Moreover,
we discover two new phenomena: (i) such kinds of basic waves can disappear in a
finite time and (ii) the new-type rarefaction wave can contain some weak
discontinuities in its interior. These behaviors are in stark contrast to the
case of the Lipschitz source term, where these two kinds of basic waves persist
globally and the rarefaction waves remain smooth in the interior. Finally, we
provide two examples to respectively demonstrate the uniqueness of Riemann
solutions in the case of the source term being non-Lipschitz from left
(necessarily right-Lipschitz), and the non-uniqueness of Riemann solutions in
the case of the source term being non-Lipschitz from right.

</details>


### [31] [Global strong solutions to the $3$D rotating compressible Navier--Stokes--Korteweg system for large data in the critical $\widehat{L^p}$ framework](https://arxiv.org/abs/2509.06078)
*Mikihiro Fujii,Shunhang Zhang*

Main category: math.AP

TL;DR: Global existence of strong solutions for 3D compressible Navier-Stokes-Korteweg system with large initial data in critical Besov-type spaces based on Fourier-Lebesgue spaces, under large rotation speed and small Mach number conditions.


<details>
  <summary>Details</summary>
Motivation: While there is extensive literature on weak solutions for the 3D compressible Navier-Stokes-Korteweg system in rotational framework, no results exist for strong solutions, particularly for large initial data.

Method: Establish Strichartz-type estimates leveraging dispersion from rotation and acoustic waves in Fourier-Lebesgue spaces, and utilize improved dissipation structure from Korteweg term and divergence-form nonlinear terms in momentum formulation.

Result: Unique existence of global solutions for large initial data in critical Besov-type spaces based on Fourier-Lebesgue spaces with 2 ≤ p < 3, when rotation speed is sufficiently large and Mach number sufficiently small.

Conclusion: The paper successfully establishes strong solution theory for the rotational compressible Navier-Stokes-Korteweg system, overcoming previous limitations through careful analysis of dispersion effects and dissipation structures.

Abstract: Let us consider the $3$D compressible Navier--Stokes--Korteweg system in the
rotational framework. Although there is a wealth of literature on the weak
solutions to this system, there seem to be no results on the strong solutions.
In this paper, we show the unique existence of global solutions for {\it large}
initial data in the critical Besov-type spaces based on the Fourier--Lebesgue
spaces $\widehat{L^p}(\mathbb{R}^3)$ with $2 \leq p < 3$, provided that the
rotation speed and the Mach number are sufficiently large and small,
respectively. The key ingredient of the proof is to establish the
Strichartz-type estimates due to the dispersion caused by the mixture of the
rotation and acoustic waves in the Fourier--Lebesgue spaces, and focus on the
better structure of dissipation from the Korteweg term and the nonlinear terms
of the divergence form in the momentum formulation.

</details>


### [32] [From KP-I Lump Solution to Travelling wave of 3D Gravity Capillary Water wave problem](https://arxiv.org/abs/2509.06084)
*Changfeng Gui,Shanfa Lai,Yong Liu,Juncheng Wei,Wen Yang*

Main category: math.AP

TL;DR: The paper analyzes 3D gravity-capillary water waves and shows existence of fully localized solitary-wave solutions resembling KP-I lump solutions within specific parameter ranges.


<details>
  <summary>Details</summary>
Motivation: To study steady 3D water wave propagation with gravity and surface tension effects, focusing on finding localized solitary-wave solutions that maintain their shape while traveling.

Method: Used the Kadomtsev-Petviashvili (KP)-I equation as a simplified model, analyzed velocity potential and boundary conditions under constant wave speed and water depth assumptions.

Result: Demonstrated that the 3D gravity-capillary water wave problem admits fully localized solitary-wave solutions that resemble lump-type solutions of the KP-I equation within specific parameter ranges.

Conclusion: The study successfully identifies and characterizes three-dimensional localized solitary waves in gravity-capillary systems, connecting them to known mathematical solutions of the KP-I equation.

Abstract: In this paper, we study the three-dimensional gravity-capillary water wave
problem involving an irrotational, perfect fluid with gravity and surface
tension. We focus on steady waves propagating uniformly in one direction.
Assuming constant wave speed and water depth, we analyze the fluid's velocity
potential and boundary conditions. Using the Kadomtsev-Petviashvili (KP)-I
equation as a simplified model, we show that, within a specific parameter
range, the problem admits a fully localized solitary-wave solution resemble
lump type solutions of the KP-I equation.

</details>


### [33] [The role of the initial distribution in population survival within a bounded habitat](https://arxiv.org/abs/2509.06179)
*Rafael de la Rosa,Elena Medina*

Main category: math.AP

TL;DR: Analysis of population persistence in reaction-diffusion models shows survival depends on parameter Q = (a/D)l^(-μ+ν+2)n₀^(μ-ν), with critical threshold Q_c determining persistence.


<details>
  <summary>Details</summary>
Motivation: To understand how initial conditions affect population survival in reaction-diffusion models with hostile boundaries, building on previous work by Colombo and Anteneodo (2018).

Method: Analytical formulation of survival condition using parameter Q, and numerical estimation of critical Q_c using finite-difference schemes.

Result: Found that survival condition can be universally expressed as Q ≥ Q_c, with Q_c depending on μ, ν and initial distribution. For μ=ν+2, survival depends only on total population, not habitat size.

Conclusion: Parameter Q provides a universal framework for determining population persistence, with numerical methods enabling estimation of critical thresholds and optimal initial distributions for survival.

Abstract: In this paper, we analyze the role of initial conditions in population
persistence. Specifically, we consider the reaction-diffusion equation
$u_t\,=\,D\,(u^{\nu-1}\,u_x)_x\,+\,a\,u^{\mu}$, with $\mu,\nu>0$, accompanied
by hostile boundary conditions and examine two families of one-parametric
initial distributions, including homogeneous distributions. The model was
previously studied by Colombo and Anteneodo (2018). They determined appropriate
habitat sizes $l$ for the survival of a population, whose individuals are
initially placed homogeneously within the full habitat domain with a total
initial population $n_0$. We show that the survival condition can be naturally
formulated in terms of the parameter
$Q:=\frac{a}{D}l^{-\mu+\nu+2}n_0^{\mu-\nu}$. Indeed, there exists a critical
value $Q_c$ determined by $\mu$, $\nu$ and the initial distribution parameter
such that the survival condition can always be written as $Q\geq Q_c$. Notably,
from this point of view, one can derive a condition for $Q$ that holds
universally for our model under conditional persistence ($\mu\geq\nu$). It
applies, in particular, to the case $\mu=\nu+2$, which was not addressed in the
previously mentioned work. Nevertheless, in this case $Q=\frac{a}{D}n_0^2$,
therefore survival depends solely on the total population, not on the habitat
size. We apply a finite-difference scheme to estimate $Q_c$. Conversely, given
a population whose evolution is determined by $\mu$, $\nu$, $l$, $n_0$, and the
growth and diffusion coefficients $a$ and $D$ (and consequently the value of
$Q$) we use the numerical algorithm to estimate the initial distribution to
ensure population survival.

</details>


### [34] [Unstable mode around the 3D boundary layer flow](https://arxiv.org/abs/2509.06089)
*Cheng-Jie Liu,Mengjun Ma,Di Wu,Zhu Zhang*

Main category: math.AP

TL;DR: Three-dimensional Navier-Stokes boundary layer flows exhibit exponential instability (e^{t/√ν}) when streamwise and spanwise velocity profiles are linearly independent near boundaries, revealing a new analytic instability mechanism absent in 2D flows.


<details>
  <summary>Details</summary>
Motivation: To understand stability properties of boundary layer-type shear flows in 3D Navier-Stokes equations at small viscosity, particularly how three-dimensional effects and spanwise flow interactions create instabilities not present in two-dimensional cases.

Method: Mathematical analysis of three-dimensional Navier-Stokes equations with small viscosity parameter ν, constructing unstable modes through analytical methods when streamwise and spanwise velocity profiles are linearly independent near boundaries.

Result: Construction of an unstable mode that grows exponentially at rate e^{t/√ν}, demonstrating analytic instability in 3D Navier-Stokes equations around generic boundary layer profiles due to interplay between spanwise flow and 3D perturbations.

Conclusion: Three-dimensional boundary layer flows exhibit a fundamental instability mechanism driven by spanwise flow and 3D perturbations, which is absent in purely two-dimensional flows and grows rapidly with characteristic time scale √ν.

Abstract: We study the stability properties of boundary layer-type shear flows for the
three-dimensional Navier-Stokes equations in the limit of small viscosity
$0<\nu\ll 1$. When the streamwise and spanwise velocity profiles are linearly
independent near the boundary, we construct an unstable mode that exhibits
rapid growth at the rate of $e^{t/\sqrt{\nu}}$. Our results reveal an analytic
instability in the three-dimensional Navier-Stokes equations around generic
boundary layer profiles. This instability arises from the interplay between
spanwise flow and three-dimensional perturbations, and does not occur in purely
two-dimensional flows.

</details>


### [35] [Equivariant stability of vortices in Manton's Chern-Simons-Schrödinger system on the hyperbolic plane](https://arxiv.org/abs/2509.06090)
*Oussama Landoulsi,Sohrab Shahshahani*

Main category: math.AP

TL;DR: Asymptotic stability of magnetic vortices on hyperbolic plane for Chern-Simons-Schrödinger system under equivariance symmetry


<details>
  <summary>Details</summary>
Motivation: Study magnetic vortices in Chern-Simons-Schrödinger system as Schrödinger analogue of Abelian-Higgs model, focusing on self-dual case with equivariance symmetry

Method: Nonlinear Darboux transform to reveal favorable equation structure, analysis of elliptic operator relating original and transformed variables, prove stability for each degree m≥1

Result: Proved asymptotic stability of equivariant vortex of degree m for all m≥1

Conclusion: Successfully established stability results for magnetic vortices through novel approach using Darboux transform and operator analysis

Abstract: In this work we study magnetic vortices on the hyperbolic plane for a
Chern-Simons-Schr\"odinger system introduced by Manton. The model can be
thought of as the Schr\"odinger analogue of the Abalian-Higgs model. It
consists of a system of partial differential equations, where the complex Higgs
field $\Phi$ evolves according to a nonlinear Schr\"odinger equation coupled to
an electromagnetic field $A$. We restrict attention to the self-dual
(Bogomolny) case under equivariance symmetry. For each $m\geq 1$ we prove the
asymptotic stability of the equivariant vortex of degree $m$. The main
novelties are unraveling the favorable structure of the equations after a
nonlinear Darboux transform, and the analysis of the elliptic operator relating
the original and the transformed variables.

</details>


### [36] [Capillary $L_p$ Minkowski Flows](https://arxiv.org/abs/2509.06110)
*Jinrong Hu,Yingxiang Hu,Mohammad N. Ivaki*

Main category: math.AP

TL;DR: Analysis of anisotropic capillary Gauss curvature flows and their application to solving capillary L_p Minkowski problems in Euclidean half-space


<details>
  <summary>Details</summary>
Motivation: To study long-time existence and asymptotic behavior of anisotropic capillary Gauss curvature flows, and use these flows to establish existence of smooth solutions to capillary L_p Minkowski problems

Method: Employing anisotropic capillary Gauss curvature flows as a geometric flow approach to analyze and solve the capillary L_p Minkowski problems

Result: Provides existence of smooth solutions to capillary even L_p Minkowski problem in Euclidean half-space for all p ∈ (-n-1, ∞) and capillary L_p Minkowski problem for p > n+1

Conclusion: Geometric flows serve as an effective approach for solving capillary Minkowski problems, establishing existence results across broad parameter ranges

Abstract: We study the long-time existence and asymptotic behavior of a class of
anisotropic capillary Gauss curvature flows. As an application, we provide a
flow approach to the existence of smooth solutions to the capillary even $L_p$
Minkowski problem in the Euclidean half-space for all $p \in (-n-1, \infty)$
and capillary $L_p$ Minkowski problem for $p > n+1$.

</details>


### [37] [Curvature Flow of Networks with Triple Junction Drag and Grain Rotation](https://arxiv.org/abs/2509.06125)
*Yuchuan Yang,Selim Esedoglu*

Main category: math.AP

TL;DR: Local existence proof for PDE system modeling curvature motion of networks with triple junction drag, showing potential topological changes and studying stability with dynamic surface tension.


<details>
  <summary>Details</summary>
Motivation: Study grain boundary evolution in polycrystalline materials, addressing dynamic boundary conditions and crystallographic orientation effects.

Method: Prove local existence for PDE system with triple junction drag, incorporate dynamic surface tension model dependent on grain orientations, analyze stationary solution stability.

Result: Demonstrated possibility of new topological changes during network evolution, established local existence, and characterized stability dependence on surface tension choices.

Conclusion: The model captures important aspects of grain boundary evolution including topological transformations and orientation-dependent surface tension effects, with stability properties tied to surface tension selection.

Abstract: We prove a local existence result for a PDE system that describes curvature
motion of networks with a dynamic boundary condition known as triple junction
drag. This model arises in the study of grain boundary evolution in
polycrystalline materials. We demonstrate the possibility of a new type of
topological change during the evolution of the network. Moreover, we adopt a
dynamic surface tension model that depends on the crystallographic orientations
of the grains, which are allowed to rotate. Lastly, we study how the stability
of stationary solutions depend on the choice of surface tension.

</details>


### [38] [Quasilinear problems with critical Sobolev exponent for the Grushin p-Laplace operator](https://arxiv.org/abs/2509.06138)
*Somnath Gandal,Annunziata Loiudice,Jagmohan Tyagi*

Main category: math.AP

TL;DR: Study of quasilinear degenerate elliptic equations with critical nonlinearity involving Grushin p-Laplace operator, extending Brezis-Nirenberg type results to the p-case and establishing existence of extremals for Sobolev-type inequalities.


<details>
  <summary>Details</summary>
Motivation: To extend classical Brezis-Nirenberg results to the p-Laplace case in the context of Grushin geometry, which involves degenerate elliptic operators with critical nonlinearities. The research aims to understand existence and qualitative behavior of solutions to these equations.

Method: Analysis of quasilinear degenerate elliptic equations using Grushin p-Laplace operator. The approach involves establishing existence of extremals for Sobolev-type inequalities and studying positive entire solutions to the limit problem on R^N.

Result: Extension of Brezis-Nirenberg type results to the p-case in Grushin geometry framework. Preliminary establishment of extremals for the Sobolev-type inequality and characterization of their qualitative behavior as positive entire solutions.

Conclusion: The study successfully extends classical elliptic theory results to the degenerate Grushin p-Laplace setting, providing fundamental insights into the existence and properties of solutions for critical nonlinear equations in this geometric framework.

Abstract: We study the following class of quasilinear degenerate elliptic equations
with critical nonlinearity \begin{align*}
  \begin{cases}-\Delta_{\gamma,p} u= \lambda |u|^{q-2}u+|u|^{p_{\gamma}^{*}-2}u
& \text{ in } \Omega\subset \mathbb{R}^N, \\ u=0 & \text{ on } \partial \Omega,
\end{cases} \end{align*} where $\Delta_{\gamma, p}v:=\sum_{i=1}^N
X_i(|\nabla_\gamma u|^{p-2}X_i u)$ is the Grushin $p$-Laplace operator, $z:=(x,
y) \in \mathbb{R}^N$, $N=m+n,$ $m,n \geq 1,$, where $\nabla_\gamma=(X_1,
\ldots, X_N)$ is the Grushin gradient, defined as the system of vector fields
$X_i=\frac{\partial}{\partial x_i}, i=1, \ldots, m$, $X_{m+j}=|x|^\gamma
\frac{\partial}{\partial y_j}, j=1, \ldots, n$, where $\gamma>0$. Here, $\Omega
\subset \mathbb{R}^{N}$ is a smooth bounded domain such that $\Omega\cap
\{x=0\}\neq \emptyset$, $\lambda>0$, $q \in [p,p_\gamma^*)$, where
$p_{\gamma}^{*}=\frac{pN_\gamma}{N_\gamma-p}$ and $N_\gamma=m+(1+\gamma)n$
denotes the homogeneous dimension attached to the Grushin gradient. The results
extends to the $p$-case the Brezis-Nirenberg type results in
Alves-Gandal-Loiudice-Tyagi [J. Geom. Anal. 2024, 34(2),52]. The main crucial
step is to preliminarily establish the existence of the extremals for the
involved Sobolev-type inequality \begin{equation*} \int_{\mathbb{R}^N}
|\nabla_{\gamma} u|^p dz \geq S_{\gamma,p} \left ( \int_{\mathbb{R}^N}
|u|^{p_\gamma^*} dz \right )^{p/p_\gamma^*} \end{equation*} and their
qualitative behavior as positive entire solutions to the limit problem
\begin{equation*} -\Delta_{\gamma,p} u= u^{p_{\gamma}^{*}-1}\quad \mbox{on}\,
\mathbb{R}^N, \end{equation*} whose study has independent interest.

</details>


### [39] [Forward and inverse problems of a semilinear transport equation](https://arxiv.org/abs/2509.06183)
*Kui Ren,Yimin Zhong*

Main category: math.AP

TL;DR: Study of forward/inverse problems for semilinear radiative transport with absorption coefficient depending on angular average of solution. Developed well-posedness theory for general boundary data and stability results for nonlinear absorption coefficient reconstruction.


<details>
  <summary>Details</summary>
Motivation: Applications in photoacoustic imaging of multi-photon absorption in heterogeneous media, where accurate reconstruction of nonlinear absorption properties is crucial.

Method: Developed well-posedness theory for transport model with general boundary data, established stability results for inverse problem of reconstructing nonlinear absorption coefficient from internal data using weighted norm approach.

Result: Significantly improved previous theories for small boundary data, unified L^1 stability theory for both diffusion and transport regimes through weighted norm that penalizes boundary region contributions.

Conclusion: The framework provides robust mathematical foundation for semilinear radiative transport problems with practical applications in biomedical imaging, particularly photoacoustic imaging with multi-photon absorption phenomena.

Abstract: We study forward and inverse problems for a semilinear radiative transport
model where the absorption coefficient depends on the angular average of the
transport solution. Our first result is the well-posedness theory for the
transport model with general boundary data, which significantly improves
previous theories for small boundary data. For the inverse problem of
reconstructing the nonlinear absorption coefficient from internal data, we
develop stability results for the reconstructions and unify an $L^1$ stability
theory for both the diffusion and transport regimes by introducing a weighted
norm that penalizes the contribution from the boundary region. The problems
studied here are motivated by applications such as photoacoustic imaging of
multi-photon absorption of heterogeneous media.

</details>


### [40] [Global well-posedness and large time behavior of 3D incompressible inhomogeneous magnetohydrodynamic equations in the exterior of a cylinder](https://arxiv.org/abs/2509.06293)
*Jitao Liu,Min Liu*

Main category: math.AP

TL;DR: First proof of global existence and uniqueness of strong solutions for 3D axisymmetric incompressible inhomogeneous magnetohydrodynamic equations in exterior domains without small data assumptions


<details>
  <summary>Details</summary>
Motivation: Addressing the challenging open problem of whether global existence and uniqueness of strong solutions holds for 3D incompressible inhomogeneous magnetohydrodynamic equations, particularly for magnetofluids with special structures

Method: Deep exploration of internal structure and characteristics of axisymmetric flows, focusing on magnetofluids flowing in the exterior of a cylinder

Result: Proved that axisymmetric magnetofluids admit unique strong solutions that exist globally in time without compatibility conditions or small initial data assumptions, with established algebraic decay rates for time and spatial derivatives of velocity and magnetic fields

Conclusion: This work provides the first unique 3D large solution existing globally in time for magnetohydrodynamic equations, representing a significant breakthrough in addressing this longstanding open problem

Abstract: When the vaccum is allowed, if the global existence and uniqueness of strong
solutions to three dimensional incompressible inhomogeneous magnetohydrodynamic
equations holds true or not has always been a challenging open problem, even
for the magnetofluids with special structures. In this paper, through deeply
exploring the internal structure and characteristic of axisymmetric flows, we
obtain some new discoveries and give a partial answer to above issue. More
precisely, we prove that the axisymmetric magnetofluids flowing in the exterior
of a cylinder will definitely admits a unique strong solution that exists
globally in time without any compatibility conditions and small assumptions
imposed on the initial data. Furthermore, we establish the algebraic decay
rates for the time and spatial derivatives of both velocity and magnetic
fields. To the best of our knowledge, this result gives the first unique 3D
large solution existing globally in time.

</details>


### [41] [Schwarz-Pick type lemma and Landau type theorem for $α$-harmonic mappings](https://arxiv.org/abs/2509.06359)
*Vibhuti Arora,Jiaolong Chen,Shankey Kumar,Qianyun Li*

Main category: math.AP

TL;DR: This paper establishes Schwarz-Pick and Landau type theorems for α-harmonic mappings, providing explicit sharp bounds for gradient estimates and extending previous results.


<details>
  <summary>Details</summary>
Motivation: To generalize and extend existing results on Schwarz-Pick and Landau type theorems for harmonic mappings to the α-harmonic setting, building on work by Kalaj and Khalfallah et al.

Method: Obtains explicit sharp function for gradient inequality of α-harmonic mappings with L^p boundary data, and proves Landau type theorem for L^∞ boundary data.

Result: Derives explicit form of sharp function C_α,q(x) for gradient bounds, and establishes Landau type theorem for α-harmonic mappings with bounded boundary values.

Conclusion: The results successfully generalize previous theorems to α-harmonic mappings, providing sharp estimates and extending the scope of harmonic mapping theory.

Abstract: The aim of this paper is twofold.
  First, we obtain a Schwarz-Pick type lemma for the $\alpha$-harmonic mapping
$u=P_{\alpha}[\phi]$,
  where $\phi\in L^{p}(\mathbb{S}^{n-1},\mathbb{R} )$ and $p\in[1,\infty]$.
  We get an explicit form of the sharp function $\mathbf{C}_{\alpha, q}(x)$ in
the inequality
  $|\nabla u(x)| \leq \mathbf{C}_{\alpha, q}(x)\|\phi\|_{L^p(\mathbb{S}^{n-1},
\mathbb{ R} )}$.
  Second, we prove a Landau type theorem for $u=P_{\alpha}[\phi]$,
  where $\phi\in L^{\infty}(\mathbb{S}^{n-1},\mathbb{R}^{n})$.
  These results generalize and extend the corresponding
  results due to Kalaj (Complex Anal. Oper. Theory, 2024) and
  Khalfallah et al. (Mediterr. J. Math.,
  2021).

</details>


### [42] [Propagation of Wave Packets Close to Conical Interscetions](https://arxiv.org/abs/2509.06420)
*Marianne Curely*

Main category: math.AP

TL;DR: Analysis of wave packet propagation near conical intersections in 2D Schrödinger systems with codimension 2 crossings, providing explicit formulas for outgoing wave packets.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of wave packets passing through areas close to conical intersections in quantum systems, which is crucial for modeling molecular dynamics and quantum transitions.

Method: Studied the propagation of wave packets near conical intersections using a system of two Schrödinger equations with codimension 2 crossing, analyzing dynamics through mathematical modeling and derivation of explicit formulas.

Result: Derived an explicit formula for the outgoing wave packet in terms of the incoming one, with complete description of its phase and the classical trajectories it follows, including identification of a drift phenomenon.

Conclusion: The study provides comprehensive mathematical framework for understanding wave packet behavior near conical intersections, enabling precise prediction of quantum dynamics including phase evolution and trajectory modifications with drift effects.

Abstract: In this paper, we study the propagation of wave packets close to conical
intersections with respect to a system of two Schr{\"o}dinger equations
presenting a codimension 2 crossing. We focus on the dynamics that occur when
the wave packets pass through an area close to the crossing, and our main
results provide an explicit formula for the outgoing wave packet in terms of
the incoming one, with a complete description of its phase and of the classical
trajectories it follows, including a drift.

</details>


### [43] [Strong instability of standing waves for a system of nonlinear Klein-Gordon equations with quadratic interaction](https://arxiv.org/abs/2509.06583)
*Masahito Ohta*

Main category: math.AP

TL;DR: Analysis of nonlinear Klein-Gordon system instability without mass resonance condition


<details>
  <summary>Details</summary>
Motivation: To study the strong instability of standing wave solutions in nonlinear Klein-Gordon equations with quadratic interaction in 2D and 3D space dimensions, particularly when the mass resonance condition is not assumed

Method: Analysis of a system of nonlinear Klein-Gordon equations with quadratic interaction, focusing on standing wave solutions and their stability properties in two and three space dimensions

Result: The paper demonstrates strong instability of standing wave solutions in the absence of mass resonance condition

Conclusion: Standing wave solutions in nonlinear Klein-Gordon systems with quadratic interaction exhibit strong instability when the mass resonance condition is not satisfied, which has implications for understanding wave behavior in such systems

Abstract: We consider a system of nonlinear Klein-Gordon equations with quadratic
interaction in two and three space dimensions. The strong instability of
standing wave solutions is studied for the system without assuming the mass
resonance condition.

</details>


### [44] [The $L^p$ regularity problem for parabolic operators with transversally independent coefficients](https://arxiv.org/abs/2509.06627)
*Martin Dindoš,Jill Pipher,Martin Ulmer*

Main category: math.AP

TL;DR: This paper fully resolves the Regularity problem for parabolic PDEs with elliptic matrices having bounded measurable coefficients independent of the transversal spatial variable, proving solvability in the range (1, p₀) for some p₀ > 1.


<details>
  <summary>Details</summary>
Motivation: To determine whether the Regularity problem for parabolic PDEs is solvable under specific conditions where the matrix coefficients are elliptic, bounded, measurable, and independent of the transversal spatial variable, building on prior work for the Dirichlet problem and elliptic cases.

Method: The authors prove that for some p₀ > 1, the Regularity problem is solvable in the range (1, p₀), complementing recent work on solvability under Carleson conditions (a parabolic analog of the DKP-condition).

Result: The main result shows that the Regularity problem is solvable for the parabolic PDE in the range (1, p₀), addressing a step up in difficulty compared to the Dirichlet problem and extending prior elliptic case resolutions.

Conclusion: This work fully resolves the solvability question for the Regularity problem in parabolic PDEs under the given assumptions, providing a significant advancement in understanding these equations and complementing existing results for related problems.

Abstract: In this paper, we fully resolve the question of whether the Regularity
problem for the parabolic PDE $\partial_tu - \mbox{div}(A\nabla u)=0$ on the
domain $\mathbb R^{n+1}_+\times\mathbb R$ is solvable for some $p\in
(1,\infty)$ under the assumption that the matrix $A$ is elliptic, has bounded
and measurable coefficients and its coefficients are independent of the spatial
variable $x_{n+1}$ (which is transversal to the boundary). We prove that for
some $p_0>1$ the Regularity problem is solvable in the range $(1,p_0)$. An
analogous result for the Dirichlet problem has been considered earlier by
Auscher, Egert and Nystr\"om, however the Regularity problem represents an
additional step up in difficulty. In the elliptic case, the analog of the
question considered here was resolved for both Dirichlet and Regularity
problems by Hofmann, Kenig, Mayboroda and Pipher.
  The main result of this paper complements a recent work of two of the authors
with L. Li showing solvability of the parabolic Regularity problem for data in
some $L^p$ spaces when the coefficients satisfy a natural Carleson condition
(which is a parabolic analog of the so-called DKP-condition).

</details>


### [45] [Non-Existence of Solutions for a Fourth-Order Structurally Damped Equation Under Nonlinear Memory Effect](https://arxiv.org/abs/2509.06671)
*Luis Gustavo Longen*

Main category: math.AP

TL;DR: Non-existence of global solutions for mixed wave-plate equation with rotational inertia, fractional damping and memory non-linearity in subcritical and critical cases.


<details>
  <summary>Details</summary>
Motivation: This research serves as a non-existence counterpart to previous work by D'Abbicco and Longen, aiming to establish the critical exponent for global existence of small data solutions to the Cauchy problem.

Method: Employed a modified test function argument to demonstrate non-existence of solutions for arbitrarily small initial data in subcritical cases.

Result: Showed that there are no global solutions in the subcritical case, and also demonstrated non-existence in the critical case when the memory exponent exceeds (n-2)/n.

Conclusion: The study successfully establishes non-existence results that complement previous existence findings, providing a complete picture of the critical exponent threshold for this class of mixed wave-plate equations.

Abstract: In this paper, we study a mixed wave-plate equation with rotational inertia,
fractional damping and memory non-linearity. This research is a non-existence
counterpart to a paper by D'Abbicco and Longen, in search of the critical
exponent for the global in-time existence of small data solutions to the Cauchy
problem for a mixed wave-plate equation, with a rotational inertia and a
non-integer dissipation term and a memory-type non-linearity. We employ a
modified test function argument to show that there are arbitrarily small
initial data for which there are no solutions for the problem in the
subcritical case. Additionally, we show non-existence of global solutions in
the critical case when the memory exponent is greater than (n-2)/n.

</details>


### [46] [Eigenvalues of the discrete p-Laplacian via graph surgery](https://arxiv.org/abs/2509.06686)
*Gregory Berkolaiko,Matthias Hofmann*

Main category: math.AP

TL;DR: Hellmann-Feynman perturbation theory for signed p-Laplacian eigenvalues with edge cut parameterization


<details>
  <summary>Details</summary>
Motivation: To develop a perturbation theory approach for analyzing eigenvalues of the discrete signed p-Laplacian operator in graph theory

Method: Developed a Hellmann-Feynman type perturbation theory and applied it to parametrized perturbations by edge cuts, characterizing eigenvalues as critical values

Result: Showed that eigenvalues of the signed p-Laplacian can be characterized as critical values of parameter-dependent eigenvalues of a simpler graph

Conclusion: The perturbation theory approach provides a new characterization method for eigenvalues of the signed p-Laplacian through critical value analysis

Abstract: We develop a Hellmann--Feynman type perturbation theory for the discrete
signed $p$-Laplacian and apply it to a parametrized perturbation by edge cuts.
We show that the eigenvalues of the signed $p$-Laplacian can be characterized
as citical values of the parameter-dependent eigenvalues of a simpler graph.

</details>


### [47] [Synchronization of velocities in pipline flow of blended gas](https://arxiv.org/abs/2509.06742)
*Martin Gugat*

Main category: math.AP

TL;DR: Analysis of blended gas flow in pipelines showing velocity synchronization between components, with applications to hydrogen-natural gas blending for renewable energy transition.


<details>
  <summary>Details</summary>
Motivation: Study hydrogen blending in natural gas pipelines as part of renewable energy transition, examining when multiple gas components can be modeled with synchronized velocities.

Method: Used isothermal Euler equations with velocity coupling terms for each component, analyzed synchronization using Lyapunov function based on relative energy concept.

Result: Showed velocities synchronize exponentially fast under suitable boundary conditions, with synchronization error bounded by reciprocal of coupling strength, justifying drift-flux model assumptions.

Conclusion: For n-component gas mixtures, drift-flux models assuming equal velocities are justified when coupling is strong, with model error bounded by coupling strength reciprocal.

Abstract: We consider the pipeline flow of blended gas. The flow is governed by a
coupled system where for each component we have the isothermal Euler equations
with an additional velocity coupling term that couples the velocities of the
different components. Our motivation is hydrogen blending in natural gas
pipelines, which will play a role in the transition to renewable energies. We
show that with suitable boundary conditions the velocities of the gas
components synchronize exponentially fast, as long as the $L^2$-norm of the
synchronization error is outside of a certain interval where the size of the
interval is determined by the order of the interaction terms. This indicates
that in some cases for a mixture of $n$ components it is justified to use a
drift-flux model where it is assumed that all components flow with the same
velocity. The model error in the sense of the weighted L2-norm of the
difference between the barycentric velocity and the velocities of the component
is bounded above of the order of the reciprocal value of the coupling term.
  For the proofs we use an appropriately chosen Lyapunov function which is
based upon the idea of relative energy.

</details>


### [48] [Rates of convergence in long time asymptotics of an alignment model with symmetry breaking](https://arxiv.org/abs/2509.06765)
*Alexandre Surin*

Main category: math.AP

TL;DR: Analysis of nonlinear Fokker-Planck equation from Cucker-Smale flocking model with noise, showing phase transition between isotropic and polarized stationary solutions depending on noise level.


<details>
  <summary>Details</summary>
Motivation: To understand the phase transition behavior and convergence properties in flocking models with noise, specifically how noise levels affect symmetry breaking and the stability of stationary solutions.

Method: Mathematical analysis of a nonlinear Fokker-Planck equation derived from Cucker-Smale flocking model, examining stationary solutions, linear stability, and convergence rates in weighted L^2 norm.

Result: Proved exponential convergence to unique radial stationary solution above noise threshold, and exponential convergence to polarized stationary solutions with low entropy below threshold. Identified phase transition point where symmetry breaking occurs.

Conclusion: The noise parameter controls a clear phase transition between isotropic and polarized flocking states, with exponential convergence rates to stationary solutions in both regimes, providing rigorous mathematical foundation for understanding noise-induced symmetry breaking in collective behavior models.

Abstract: We consider a nonlinear Fokker-Planck equation derived from a Cucker-Smale
model for flocking with noise. There is a known phase transition depending on
the noise between a regime with a unique stationary solution which is isotropic
(symmetry) and a regime with a continuum of polarized stationary solutions
(symmetry breaking). If the value of the noise is larger than the threshold
value, the solution of the evolution equation converges to the unique radial
stationary solution. This solution is linearly unstable in the
symmetry-breaking range, while polarized stationary solutions attract all
solutions with sufficiently low entropy. We prove that the convergence measured
in a weighted $L^2$ norm occurs with an exponential rate and that the average
speed also converges with exponential rate to a unique limit which determines a
single polarized stationary solution.

</details>


### [49] [On decay and regularly of solutions of the Benjamin-Ono equation](https://arxiv.org/abs/2509.06816)
*Felipe Linares,Gustavo Ponce*

Main category: math.AP

TL;DR: Persistence properties of Benjamin-Ono equation solutions in weighted Sobolev spaces for β < 7/2


<details>
  <summary>Details</summary>
Motivation: To understand how solutions of the Benjamin-Ono equation behave in weighted Sobolev spaces and determine the conditions under which solutions remain in these spaces over time

Method: Studying persistence properties by analyzing solutions in weighted L^2 spaces with weight |x|^{2β} and requiring initial data to be in both the weighted space and sufficiently regular Sobolev space H^β

Result: For β < 7/2, the solution u(x,t) remains in L^2(|x|^{2β} dx) if and only if the initial data u(x,0) belongs to this space and is regular enough (u₀ ∈ H^β(ℝ))

Conclusion: The Benjamin-Ono equation exhibits persistence in weighted Sobolev spaces up to β < 7/2, with the requirement that initial data must have both the appropriate weighted decay and sufficient regularity

Abstract: We study persistence properties of solutions of the Benjamin-Ono equation in
weighted Sobolev spaces. Roughly, we show that for $\beta<7/2$, the solution
$u(x,t)$ of the BO remains in the space $L^2(|x|^{2\beta} dx)$ if and only if
its data $u(x,0)$ belongs to this space and it is regular enough, i.e. $u_0\in
H^{\beta}(\mathbb R)$.

</details>


### [50] [The High Energy Distribution of Scattering Phase Shifts of Schrödinger operators in Hyperbolic Space](https://arxiv.org/abs/2509.06821)
*Antônio Sá Barreto*

Main category: math.AP

TL;DR: Trace formula for scattering phase shifts in hyperbolic space Schrödinger operators, relating scattering shifts to geodesic X-ray transform of potential. Extends Euclidean result and proves unique determination for radial monotone super-exponentially decaying potentials.


<details>
  <summary>Details</summary>
Motivation: Extend results from Euclidean space to hyperbolic space for Schrödinger operators with short-range potentials, establishing connections between scattering phase shifts and geodesic X-ray transforms.

Method: Prove a trace formula connecting high energy limit of scattering phase shifts with geodesic X-ray transform of the potential in hyperbolic space.

Result: Established trace formula for hyperbolic space Schrödinger operators, extending Bulger-Pushnitski's Euclidean result. Proved unique determination of radial monotone super-exponentially decaying potentials from high energy phase shifts.

Conclusion: Successfully generalized Euclidean scattering results to hyperbolic space, providing new trace formula and uniqueness results for a special class of potentials in hyperbolic geometry.

Abstract: We prove a trace formula for the high energy limit of the scattering phase
shifts of Schr\"odinger operators with short range real valued potentials in
hyperbolic space; it relates the scattering shifts and the geodesic X-ray
transform of the potential. This extends a result of Bulger and Pushnitski for
Schr\"odinger operators in Euclidean space. As an application, we prove that
the high energy limit of the phase shifts uniquely determines radial potentials
which are monotone and decay super-exponentially. This extends a result of
Levinson for potential perturbations of the Euclidean Laplacian to this special
class of potentials in hyperbolic space.

</details>


### [51] [Nonuniqueness for high-dimensional ideal MHD equations via differential inclusion](https://arxiv.org/abs/2509.06866)
*Changxing Miao,Zhiwen Zhao*

Main category: math.AP

TL;DR: Non-uniqueness of solutions in ideal magnetohydrodynamics equations for dimensions >3, with infinitely many compactly supported weak solutions that don't conserve energy.


<details>
  <summary>Details</summary>
Motivation: To establish the non-uniqueness property of solutions in ideal magnetohydrodynamics equations, particularly showing that energy conservation fails for certain weak solutions.

Method: Using differential inclusion framework adapted to ideal MHD geometry, combining Baire category method and convex integration scheme.

Result: Existence of infinitely many compactly supported weak solutions that fail to conserve total energy in dimensions greater than three.

Conclusion: The ideal MHD equations exhibit non-uniqueness of solutions in higher dimensions, with weak solutions that violate energy conservation principles.

Abstract: In this paper, we establish the non-uniqueness of solutions to the ideal
magnetohydrodynamics equations in any dimension greater than three by proving
the existence of infinitely many compactly supported weak solutions. In
particular, these solutions fail to conserve the total energy. Our proof relies
on the differential inclusion framework tailored to the geometry of ideal MHD
system, which enables the simultaneous use of Baire category method and convex
integration scheme.

</details>


### [52] [Homogenisation of a Passive Scalar Transported by Locally Supported White Noise](https://arxiv.org/abs/2509.06878)
*Federico Butori,Avi Mayorcas,Silvia Morlacchi*

Main category: math.AP

TL;DR: Analysis of transport noise in passive scalar models with anisotropic vector fields, showing how Stratonovich noise leads to effective diffusion with non-constant coefficients and nonlinear behavior in small diffusivity regimes.


<details>
  <summary>Details</summary>
Motivation: To understand how anisotropic transport noise affects passive scalar models in stratified turbulence, particularly in boundary layers and Boussinesq models, where traditional isotropic approaches don't apply.

Method: Uses homogenization theory to analyze transport noise composed of independent compactly supported vector fields, studies the Ito-Stratonovich corrector as a second-order elliptic operator, and examines asymptotics as diffusivity κ→0 across different vector field support regimes.

Result: Obtained representation for limiting effective diffusivity matrix, discovered nonlinear behavior in κ→0 regime through numerical analysis, showing different scaling behaviors depending on vector field support radius.

Conclusion: Anisotropic transport noise produces complex effective diffusion with non-constant coefficients, exhibiting nonlinear scaling in small diffusivity limits, which has implications for modeling stratified turbulence in geophysical flows.

Abstract: Stochastic perturbations of transport type are a common and widely accepted
way of representing turbulent effects in fluid dynamics models. In many known
examples, it even leads to improved solution theory, a phenomenon known as
\emph{regularization by noise}. A common thread in the recent literature on the
topic is the so-called \emph{It\^o-Stratonovich diffusion limit}. By selecting
Stratonovich transport noise with carefully arranged vector fields, one can
show that the solution of certain SPDEs are close, in an appropriate topology,
to an effective, deterministic, equation with a new effective second order
elliptic operator, linked to the Ito-Stratonovich corrector. In this work, we
deal with a passive scalar model with molecular diffusivity $\kappa$. Starting
from the results in [Flandoli \emph{et al.}, 2022, \emph{Philos. Trans. Roy.
Soc. A}, 380(2219)], we consider a transport noise made by a sum of independent
and compactly supported vector fields. This setting is relevant for models of
stratified turbulence which naturally occur in boundary layers and Boussinesq
models. Due to the anisotropic nature of the noise, the identification of the
limit equation is not straightforward as in all other examples known in
literature, as the Ito-Stratonovich corrector is a generic second order
elliptic operator with non-constant coefficients. Using tools from
Homogenisation theory, we obtain a representation for the limiting effective
diffusivity matrix. Exploiting this representation, we study asymptotics, in
the $\kappa \rightarrow 0$ regime, of the effective diffusivity across a number
of vector field regimes parametrised by the radius of their support. Finally,
we provide a careful numerical analysis of the effective diffusivity,
discovering a nonlinear behavior for $\kappa \rightarrow 0$, in some regimes.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [53] [Causal Multi-fidelity Surrogate Forward and Inverse Models for ICF Implosions](https://arxiv.org/abs/2509.05510)
*Tyler E. Maltba,Ben S. Southworth,Jeffrey R. Haack,Marc L. Klasky*

Main category: physics.comp-ph

TL;DR: Developed a causal dynamic multifidelity surrogate model for inertial confinement fusion capsule interface dynamics, enabling efficient inverse problem solving and radiation drive optimization using machine learning.


<details>
  <summary>Details</summary>
Motivation: Solving high-dimensional dynamic PDE-constrained optimization problems in inertial confinement fusion is extremely challenging, requiring new approaches to relate experimental observations to simulation parameters and enable design optimization.

Method: Constructed a causal, dynamic, multifidelity reduced-order surrogate that maps time-dependent radiation temperature drive to interface radius and velocity dynamics. Used operator learning with low- and high-fidelity simulation data to learn a controller for a base analytical model.

Result: Achieved excellent accuracy in the surrogate interface model. Successfully used machine learning models with surrogate-generated data to solve inverse problems optimizing radiation temperature drive to reproduce observed interface dynamics. Identified most informative sampling times for sparse temporal snapshots.

Conclusion: Demonstrated integration of operator learning, causal architectures, and physical inductive bias to accelerate discovery, design, and diagnostics in high-energy-density systems like inertial confinement fusion.

Abstract: Continued progress in inertial confinement fusion (ICF) requires solving
inverse problems relating experimental observations to simulation input
parameters, followed by design optimization. However, such high dimensional
dynamic PDE-constrained optimization problems are extremely challenging or even
intractable. It has been recently shown that inverse problems can be solved by
only considering certain robust features. Here we consider the ICF capsule's
deuterium-tritium (DT) interface, and construct a causal, dynamic,
multifidelity reduced-order surrogate that maps from a time-dependent radiation
temperature drive to the interface's radius and velocity dynamics. The
surrogate targets an ODE embedding of DT interface dynamics, and is constructed
by learning a controller for a base analytical model using low- and
high-fidelity simulation training data with respect to radiation energy group
structure. After demonstrating excellent accuracy of the surrogate interface
model, we use machine learning (ML) models with surrogate-generated data to
solve inverse problems optimizing radiation temperature drive to reproduce
observed interface dynamics. For sparse snapshots in time, the ML model further
characterizes the most informative times at which to sample dynamics.
Altogether we demonstrate how operator learning, causal architectures, and
physical inductive bias can be integrated to accelerate discovery, design, and
diagnostics in high-energy-density systems.

</details>


### [54] [Modeling Magnetoelastic Wave Interactions in Magnetic Films and Heterostructures: A finite-difference approach](https://arxiv.org/abs/2509.06007)
*Peter Flauger,Matthias Küß,Michael Karl Steinbauer,Florian Bruckner,Bernhard Emhofer,Emeline Nysten,Matthias Weiß,Dieter Suess,Hubert J. Krenner,Manfred Albrecht,Claas Abert*

Main category: physics.comp-ph

TL;DR: A computational method for simulating coupled magnetoelastic dynamics that extends micromagnetism with strain effects and properly handles material interface discontinuities.


<details>
  <summary>Details</summary>
Motivation: To enable accurate simulation of magnetostrictive effects in ferromagnetic materials, particularly addressing the challenge of properly handling stress and strain discontinuities at material interfaces in coupled magnetoelastic systems.

Method: Developed a time-integration scheme within finite-difference micromagnetism framework that extends the Landau-Lifshitz-Gilbert equation with strain-induced effective field and concurrently solves the elastic equation of motion.

Result: The implementation successfully handles stress/strain discontinuities at interfaces and was validated through various examples including static stress configurations and surface acoustic wave attenuation simulations in magnetic films.

Conclusion: Proper treatment of jump and boundary conditions is crucial for accurate magnon-phonon interaction studies, and the presented method provides a comprehensive framework for coupled magnetoelastic dynamics simulations.

Abstract: The (inverse) magnetostrictive effect in ferromagnets couples the magnetic
properties to the mechanical stress, allowing for an interaction between the
magnetic and mechanical degrees of freedom. In this work, we present a
time-integration scheme for the self-consistent simulation of coupled
magnetoelastic dynamics within the framework of finite-difference
micromagnetism. The proposed implementation extends the Landau-Lifshitz-Gilbert
equation by a strain-induced effective field and concurrently solves the
elastic equation of motion, while correctly incorporating stress and strain
discontinuities at material interfaces. We then present a comprehensive set of
examples, ranging from static stress configurations over material boundaries to
simulations of surface acoustic wave attenuation in magnetically structured
thin and thick films. These computational experiments both validate the
implementation and underscore the importance of properly handling jump and
boundary conditions in magnon-phonon interaction studies.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [55] [Perpendicular ion heating in turbulence and reconnection: magnetic moment breaking by coherent fluctuations](https://arxiv.org/abs/2509.05518)
*Alfred Mallet,Kristopher G. Klein,Benjamin D. G. Chandran,Tamar Ervin,Trevor A. Bowen*

Main category: physics.plasm-ph

TL;DR: Study of ion interactions with localized electromagnetic fluctuations, showing energy diffusion and unifying various heating mechanisms.


<details>
  <summary>Details</summary>
Motivation: To understand how ions interact with electromagnetic fluctuations that are localized in both space and time, and to develop a unified framework for different plasma heating phenomena.

Method: Derived a generic form for ion energy change with exponential cutoff based on fluctuation timescale, analyzed scale-dependence in space and time, and applied to Alfvénic turbulence and reconnection.

Result: Found that localized electromagnetic fluctuations cause diffusion in both perpendicular and parallel velocity components (v⊥ and v∥), with energy change dependent on fluctuation timescale.

Conclusion: Provides a unified theoretical framework that connects stochastic ion heating, cyclotron heating, and reconnection heating, applicable to various plasma physics phenomena.

Abstract: We study the interaction of an ion with a fluctuation in the electromagnetic
fields that is localized in both space and time. We study the scale-dependence
of the interaction in both space and time, deriving a generic form for the
ion's energy change, which involves an exponential cutoff based on the
characteristic timescale of the electromagnetic fluctuation. This leads to
diffusion in energy in both $v_\perp$ and $v_\parallel$. We show how to apply
our results to general plasma physics phenomena, and specifically to Alfv\'enic
turbulence and to reconnection. Our theory can be viewed as a unification of
previous models of stochastic ion heating, cyclotron heating, and reconnection
heating in a single theoretical framework.

</details>


### [56] [Energy partitioning in electrostatic discharge with variable series load resistor](https://arxiv.org/abs/2509.05791)
*Claudia A. M. Schrama,Calvin Bavor,P. David Flammer,Charles G. Durfee*

Main category: physics.plasm-ph

TL;DR: Experimental study shows energy partitioning in electrostatic discharges is independent of gap length and follows Rompe-Weizel spark resistance model, providing predictive framework for ESD safety requirements.


<details>
  <summary>Details</summary>
Motivation: To understand how energy is distributed during quasi-static electrostatic discharge events in air, particularly how much energy is transferred to victim loads across different circuit parameters, which is crucial for protecting sensitive electronic components and energetic materials.

Method: Systematic experimental investigation of energy transfer to victim loads across a broad resistance range (0.1 to 10,000 Ohm) while varying circuit parameters including capacitance and gap length in fixed-gap air discharges.

Result: The fraction of stored energy delivered to victim loads is largely independent of gap length, and the classic Rompe-Weizel spark resistance model effectively predicts the scaling of energy transfer, establishing a clear link between spark resistance and energy partitioning.

Conclusion: The findings provide a valuable predictive framework for guiding safety requirements for sensitive electronic components and energetic materials, and will inform the development of more accurate circuit models for ESD events.

Abstract: This paper presents an experimental investigation into the energy
partitioning of quasi-static electrostatic discharge (ESD) events in air, a
scenario in which the discharge occurs across a fixed gap. We systematically
characterize the energy transferred to a series victim load across a broad
range of resistances (0.1 to 10,000Ohm) and circuit parameters, including
capacitance and gap length. Our results show that the fraction of stored energy
delivered to the victim load is largely independent of gap length. We
demonstrate that the classic Rompe-Weizel spark resistance model effectively
predicts the scaling of this energy transfer, establishing a clear link between
spark resistance and energy partitioning. These findings provide a valuable,
predictive framework for guiding safety requirements for sensitive electronic
components and energetic materials and will inform the development of more
accurate circuit models for ESD events.

</details>


### [57] [Hybrid Fourier Neural Operator-Plasma Fluid Model for Fast and Accurate Multiscale Simulations of High Power Microwave Breakdown](https://arxiv.org/abs/2509.05799)
*Kalp Pandya,Pratik Ghosh,Ajeya Mandikal,Shivam Gandha,Bhaskar Chaudhury*

Main category: physics.plasm-ph

TL;DR: Hybrid model combining FNO-based EM solver with differential plasma solver achieves 60X acceleration for HPM breakdown simulations while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: High Power Microwave breakdown simulation is computationally expensive due to multiscale nature requiring coupled Maxwell's equations and plasma continuity equations.

Method: Hybrid approach using Fourier Neural Operator (FNO) for EM field updates (trained on FDTD data) coupled with traditional plasma fluid solver for dynamic plasma response.

Result: Excellent agreement with FDTD simulations for unseen electric fields, 60X acceleration, successful validation on 2D microwave streamer formation with diffusion ionization.

Conclusion: Hybrid FNO strategy provides efficient alternative for multiscale HPM simulations and demonstrates integration of C-based codes with Python ML frameworks for plasma science.

Abstract: Modeling and simulation of High Power Microwave (HPM) breakdown, a multiscale
phenomenon, is computationally expensive and requires solving Maxwell's
equations (EM solver) coupled with a plasma continuity equation (plasma
solver). In this work, we present a hybrid modeling approach that combines the
accuracy of a differential equation-based plasma fluid solver with the
computational efficiency of FNO (Fourier Neural Operator) based EM solver.
Trained on data from an in-house FDTD-based plasma-fluid solver, the FNO
replaces computationally expensive EM field updates, while the plasma solver
governs the dynamic plasma response. The hybrid model is validated on microwave
streamer formation, due to diffusion ionization mechanism, in a 2D scenario for
unseen incident electric fields corresponding to entirely new plasma streamer
simulations not included in model training, showing excellent agreement with
FDTD based fluid simulations in terms of streamer shape, velocity, and temporal
evolution. This hybrid FNO based strategy delivers significant acceleration of
the order of 60X compared to traditional simulations for the specified problem
size and offers an efficient alternative for computationally demanding
multiscale and multiphysics simulations involved in HPM breakdown. Our work
also demonstrate how such hybrid pipelines can be used to seamlessly to
integrate existing C-based simulation codes with Python-based machine learning
frameworks for simulations of plasma science and engineering problems.

</details>


### [58] [Resonance density range of absolute two-plasmon decay instability](https://arxiv.org/abs/2509.06021)
*C. Yao,J. Li,L. Hao,R. Yan,Q. Jia,Y-K. Ding,J. Zheng*

Main category: physics.plasm-ph

TL;DR: The paper identifies resonance density range as the key parameter governing absolute two-plasmon decay instability growth in nonuniform plasmas, and establishes its relationship with laser pulse intensity modulation thresholds.


<details>
  <summary>Details</summary>
Motivation: To provide new insights into absolute two-plasmon decay instability in nonuniform plasmas and understand how laser intensity modulations affect the growth of resonant absolute modes.

Method: Linear fluid simulations across broad parameter spaces to characterize spatial growth regions, and investigation of TPD modes driven by laser pulses with intensity modulations.

Result: The resonance density range properly characterizes spatial growth regions of resonant absolute modes. A relationship is established between this range and the threshold time interval between intensity peaks for absolute growth suppression.

Conclusion: The resonance density range is the key governing parameter for absolute TPD instability growth, and understanding its relationship with laser intensity modulation thresholds provides insights for suppressing laser plasma instabilities.

Abstract: We present a new insight into absolute two-plasmon decay (TPD) instability in
nonuniform plasmas by identifying the resonance density range as the key
parameter governing the growth of the resonant absolute modes. This range is
defined as the density interval within which these resonant modes still exhibit
growth in homogeneous plasmas. This range properly characterizes the spatial
growth region of the resonant absolute modes in a series of linear fluid
simulations across broad parameter spaces. Building on this insight, we
investigate the absolute growth of TPD modes driven by laser pulses with
intensity modulations, a common feature in broadband lasers used to suppress
laser plasma instabilities. We establish the relationship between the resonance
density range and the threshold time interval between intensity peaks, beyond
which absolute growth is suppressed.

</details>


### [59] [Time-Embedded Convolutional Neural Networks for Modeling Plasma Heat Transport](https://arxiv.org/abs/2509.06088)
*Mufei Luo,Charles Heaton,Yizhen Wang,Daniel Plummer,Mila Fitzgerald,Francesco Miniati,Sam M. Vinko,Gianluca Gregori*

Main category: physics.plasm-ph

TL;DR: TCNN is a time-embedded convolutional neural network that improves heat transport modeling in plasmas under strongly nonlocal conditions, overcoming limitations of previous quasi-stationary approaches.


<details>
  <summary>Details</summary>
Motivation: Previous LMV-Informed Neural Network (LINN) produced physically inconsistent kernels in strongly time-dependent regimes due to reliance on quasi-stationary formulation, requiring a more robust approach for nonlocal plasma transport.

Method: Time-embedded convolutional neural network (TCNN) that captures coupled evolution of normalized heat flux and nonlocality parameter using unified neural architecture informed by physical principles, trained on fully kinetic PIC simulations.

Result: TCNN accurately reproduces nonlocal dynamics across broad range of collisionalities, with time modulation, coupled prediction, and convolutional depth significantly enhancing predictive performance.

Conclusion: TCNN provides a data-driven yet physically consistent framework for multiscale plasma transport problems, effectively handling strongly time-dependent nonlocal conditions.

Abstract: We introduce a time-embedded convolutional neural network (TCNN) for modeling
spatiotemporal heat transport in plasmas, particularly under strongly nonlocal
conditions. In our earlier work, the LMV-Informed Neural Network (LINN) (Luo et
al., arXiv:2506.16619) combined prior knowledge from the LMV model with kinetic
Particle-in-Cell (PIC) data to improve kernel-based heat-flux predictions.
While effective under moderately nonlocal conditions, LINN produced physically
inconsistent kernels in strongly time-dependent regimes due to its reliance on
the quasi-stationary LMV formulation. To overcome this limitation, TCNN is
designed to capture the coupled evolution of both the normalized heat flux and
the characteristic nonlocality parameter using a unified neural architecture
informed by underlying physical principles. Trained on fully kinetic PIC
simulations, TCNN accurately reproduces nonlocal dynamics across a broad range
of collisionalities. Our results demonstrate that the combination of time
modulation, coupled prediction, and convolutional depth significantly enhances
predictive performance, offering a data-driven yet physically consistent
framework for multiscale plasma transport problems.

</details>


### [60] [Complete reflection of nonlinear electromagnetic waves in underdense pair plasmas enabled by dynamically formed Bragg-like structures](https://arxiv.org/abs/2509.06230)
*Kavin Tangtartharakul,Alexey Arefiev,Maxim Lyutikov*

Main category: physics.plasm-ph

TL;DR: Nonlinear electromagnetic waves can make strongly underdense pair plasmas fully reflective through a Bragg-like grating mechanism


<details>
  <summary>Details</summary>
Motivation: To understand how electromagnetic waves interact with underdense pair plasmas and achieve complete reflection despite low density

Method: Used kinetic simulations and theoretical analysis to study wave-plasma interactions, compression, acceleration, and density spike formation

Result: Discovered that weak reflection seeds periodic density spikes that grow rapidly due to mass symmetry, creating a moving Bragg-like grating that enables complete reflection even in underdense plasmas

Conclusion: Nonlinear effects allow electromagnetic waves to achieve full reflection in underdense pair plasmas through self-generated density structures, with finite temperature raising but not eliminating this effect

Abstract: Using kinetic simulations and theory, we show that nonlinear electromagnetic
waves can make even strongly underdense pair plasmas fully reflective. As the
wave compresses and accelerates the plasma, weak reflection seeds a periodic
train of density spikes that grow rapidly due to mass symmetry. This moving
Bragg-like grating increases reflection and momentum transfer, enabling a
transition to a regime where the relativistic plasma-vacuum interface sustains
complete reflection. Finite temperature raises the full-reflection density
threshold, yet the corresponding density can remain underdense.

</details>


### [61] [Effect of superthermal electrons on the Quantum electron acoustic double layers in dense astrophysical plasmas](https://arxiv.org/abs/2509.06366)
*Aakanksha Singh,Punit Kumar*

Main category: physics.plasm-ph

TL;DR: Analysis of electron acoustic double layers in quantum plasmas with superthermal kappa-distributed electrons, showing how spectral index and density ratios affect wave properties.


<details>
  <summary>Details</summary>
Motivation: To understand how superthermal electron distributions influence electron acoustic double layers in dense quantum plasmas, particularly relevant to astrophysical environments.

Method: Used quantum hydrodynamic model and reductive perturbation technique to derive generalized KdV equation and obtain stationary analytical solutions, supplemented with numerical analysis.

Result: Superthermal electrons significantly affect EADL amplitude, width, and polarity. Decreasing spectral index kappa or increasing relative density of kappa electrons intensifies nonlinear effects, producing stronger compressive/rarefactive structures.

Conclusion: Kappa spectral index plays a more dominant role than density ratio in controlling EADL properties in dense astrophysical plasmas.

Abstract: Electron acoustic double layers (EADLs) have been investigated in four
component unmagnetized dense quantum plasmas consisting of stationary
background ions and two electron populations, cold and hot, with the
superthermal kappa distributed electrons. Using the quantum hydrodynamic (QHD)
model and the reductive perturbation technique, a generalized Korteweg de Vries
(KdV) equation was derived, and stationary analytical solutions were obtained.
The analysis revealed that superthermal electrons substantially influence the
amplitude, width, and polarity of EADLs. Numerical results indicated that
decreasing the spectral index kappa or increasing the relative density of kappa
electrons to hot electrons intensifies nonlinear effects, producing stronger
compressive and rarefactive structures. It is also found that kappa plays a
more dominant role than the density ratio in controlling EADL properties in
dense astrophysical environments.

</details>


### [62] [Study of a coaxial vacuum arc thruster plume and its interaction with applied magnetic field](https://arxiv.org/abs/2509.06432)
*M Jimenez Diaz,L Garrigues,G J M Hagelaar,F Gaboriau,L Liard,L Herrero,A Blanchet*

Main category: physics.plasm-ph

TL;DR: Hybrid particle-fluid model simulates vacuum arc source for satellite propulsion, showing magnetic collimation overestimation compared to experiments.


<details>
  <summary>Details</summary>
Motivation: To develop simulation capabilities for vacuum arc sources used in micro/nano-satellite solid propellant propulsion systems.

Method: Hybrid model with ions as particles and electrons treated with fluid equations for magnetized electron flux, simulating with/without magnetic field influence.

Result: Preliminary results show plume and interelectrode region properties, but magnetic collimation is overestimated compared to experimental data.

Conclusion: The simulation approach shows promise but requires refinement to better match experimental magnetic field effects on collimation.

Abstract: A hybrid model where ions are treated as particles and electrons with fluid
equations for magnetized electron flux is adapted in order to simulate a vacuum
arc source. This source is a candidate for solid propellant propulsion system
of micro- and nano-satellites. We show preliminary results of the plume and
interelectrode region properties with and without the influence of an imposed
magnetic field. We compare the results with experimental data, and we find that
the magnetic collimation is overestimated in the simulation

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [63] [On the uniqueness of Kerr-de Sitter spacetimes](https://arxiv.org/abs/2509.05789)
*Allen Juntao Fang*

Main category: gr-qc

TL;DR: Proves Kerr-de Sitter uniqueness as stationary black hole solutions to Einstein vacuum equations with positive cosmological constant, without requiring analyticity.


<details>
  <summary>Details</summary>
Motivation: To establish the uniqueness of Kerr-de Sitter black hole solutions in the context of general relativity with positive cosmological constant, moving beyond the restrictive assumption of analyticity that previous results required.

Method: Uses a two-sided rigidity approach with assumptions on both event horizon and cosmological horizon, employing unique continuation arguments to prove rigidity without requiring analyticity of solutions.

Result: Successfully proves that Kerr-de Sitter is the unique family of smooth stationary black hole solutions to the nonlinear Einstein vacuum equations with positive cosmological constant.

Conclusion: The paper establishes a more general uniqueness result for Kerr-de Sitter black holes by only assuming smoothness rather than analyticity, using a novel two-sided horizon approach with unique continuation techniques.

Abstract: In this paper, we prove a series of results concerning the uniqueness of
Kerr-de Sitter as a family of smooth stationary black hole solutions to the
nonlinear Einstein vacuum equations with positive cosmological constant
$\Lambda$. The results only assume smoothness rather than analyticity of the
solution in question. The results use a two-sided approach to rigidity,
requiring assumptions on both the event horizon and the cosmological horizon
(or a neighborhood thereof) to formulate an appropriate unique continuation
argument to prove the rigidity of Kerr-de Sitter.

</details>


### [64] [Elliptic curvature estimates for linearised gravitational perturbations of Kerr in the full sub-extremal range $|a|<M$](https://arxiv.org/abs/2509.06828)
*Gabriele Benomio,Rita Teixeira da Costa*

Main category: gr-qc

TL;DR: Elliptic L^2-estimates for linearised curvature quantities in vacuum Einstein equations around Kerr spacetime


<details>
  <summary>Details</summary>
Motivation: To establish rigorous mathematical estimates for linearised curvature quantities in the context of Einstein's equations around Kerr black hole solutions

Method: Uses linearised system of equations from previous work and applies elliptic L^2(S^2)-estimates approach

Result: The scheme works for the full sub-extremal range of Kerr parameters (0 ≤ |a| < M)

Conclusion: Successfully developed a method to prove elliptic estimates for linearised curvature in Kerr spacetime

Abstract: We consider the linearised vacuum Einstein equations around a Kerr exterior
solution and present a scheme to prove elliptic $L^2(\mathbb{S}^2)$-estimates
for the linearised curvature quantities in the equations. The scheme employs
the linearised system of equations derived in the first author's doctoral
thesis and applies to the full sub-extremal range of Kerr parameters $0\leq
|a|<M$.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [65] [Cryo-EM as a Stochastic Inverse Problem](https://arxiv.org/abs/2509.05541)
*Diego Sanchez Espinosa,Erik H Thiede,Yunan Yang*

Main category: stat.ML

TL;DR: A novel cryo-EM reconstruction framework that models structural heterogeneity as continuous probability distributions using stochastic inverse problems and Wasserstein gradient flow, outperforming discrete conformation methods.


<details>
  <summary>Details</summary>
Motivation: Traditional cryo-EM methods assume discrete conformations, limiting their ability to capture continuous structural variability in biomolecules, which is a major challenge in 3D reconstruction.

Method: Formulates cryo-EM as a stochastic inverse problem over probability measures, minimizes variational discrepancy using statistical distances (KL divergence, MMD), and solves via Wasserstein gradient flow with particle representation of conformational ensembles.

Result: Validated on synthetic examples including realistic protein models, demonstrating successful recovery of continuous structural distributions and establishing connections to MAP approaches with consistency analysis.

Conclusion: Provides a general methodology for solving stochastic inverse problems with random forward operators, enabling continuous structural variability recovery in cryo-EM beyond discrete conformation limitations.

Abstract: Cryo-electron microscopy (Cryo-EM) enables high-resolution imaging of
biomolecules, but structural heterogeneity remains a major challenge in 3D
reconstruction. Traditional methods assume a discrete set of conformations,
limiting their ability to recover continuous structural variability. In this
work, we formulate cryo-EM reconstruction as a stochastic inverse problem (SIP)
over probability measures, where the observed images are modeled as the
push-forward of an unknown distribution over molecular structures via a random
forward operator. We pose the reconstruction problem as the minimization of a
variational discrepancy between observed and simulated image distributions,
using statistical distances such as the KL divergence and the Maximum Mean
Discrepancy. The resulting optimization is performed over the space of
probability measures via a Wasserstein gradient flow, which we numerically
solve using particles to represent and evolve conformational ensembles. We
validate our approach using synthetic examples, including a realistic protein
model, which demonstrates its ability to recover continuous distributions over
structural states. We analyze the connection between our formulation and
Maximum A Posteriori (MAP) approaches, which can be interpreted as instances of
the discretize-then-optimize (DTO) framework. We further provide a consistency
analysis, establishing conditions under which DTO methods, such as MAP
estimation, converge to the solution of the underlying infinite-dimensional
continuous problem. Beyond cryo-EM, the framework provides a general
methodology for solving SIPs involving random forward operators.

</details>


### [66] [Sequential Least-Squares Estimators with Fast Randomized Sketching for Linear Statistical Models](https://arxiv.org/abs/2509.06856)
*Guan-Yu Chen,Xi Yang*

Main category: stat.ML

TL;DR: SLSE-FRS is a novel randomized framework combining Sketch-and-Solve and Iterative-Sketching methods for large-scale linear model estimation, using iterative sketched least-squares subproblems with increasing precision to produce high-precision estimators.


<details>
  <summary>Details</summary>
Motivation: To address the estimation problem in large-scale linear statistical models by integrating two existing methods (Sketch-and-Solve and Iterative-Sketching) for improved performance over state-of-the-art approaches.

Method: Iteratively constructs and solves sketched least-squares subproblems with increasing sketch sizes, gradually refining estimators of the true parameter vector through sequential refinement.

Result: Numerical experiments demonstrate that SLSE-FRS outperforms state-of-the-art methods including Preconditioned Conjugate Gradient (PCG) and Iterative Double Sketching (IDS).

Conclusion: SLSE-FRS provides an effective framework for high-precision estimation in large-scale linear models, successfully combining and improving upon existing sketching methodologies with proven convergence properties.

Abstract: We propose a novel randomized framework for the estimation problem of
large-scale linear statistical models, namely Sequential Least-Squares
Estimators with Fast Randomized Sketching (SLSE-FRS), which integrates
Sketch-and-Solve and Iterative-Sketching methods for the first time. By
iteratively constructing and solving sketched least-squares (LS) subproblems
with increasing sketch sizes to achieve better precisions, SLSE-FRS gradually
refines the estimators of the true parameter vector, ultimately producing
high-precision estimators. We analyze the convergence properties of SLSE-FRS,
and provide its efficient implementation. Numerical experiments show that
SLSE-FRS outperforms the state-of-the-art methods, namely the Preconditioned
Conjugate Gradient (PCG) method, and the Iterative Double Sketching (IDS)
method.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [67] [Application of discrete Ricci curvature in pruning randomly wired neural networks: A case study with chest x-ray classification of COVID-19](https://arxiv.org/abs/2509.05322)
*Pavithra Elumalai,Sudharsan Vijayaraghavan,Madhumita Mondal,Areejit Samal*

Main category: cs.CV

TL;DR: Study compares three edge-centric network measures (FRC, ORC, EBC) for pruning randomly wired neural networks in COVID-19 chest x-ray classification, finding FRC offers computational efficiency with comparable performance to ORC.


<details>
  <summary>Details</summary>
Motivation: To investigate how different network connectivity patterns impact learning efficiency and model performance, and to explore edge-centric network measures for pruning and optimization in randomly wired neural networks.

Method: Used three edge-centric measures (Forman-Ricci curvature, Ollivier-Ricci curvature, edge betweenness centrality) to compress RWNNs by selectively retaining important synapses. Applied to three network generators (ER, WS, BA models) for COVID-19 chest x-ray classification.

Result: FRC-based pruning effectively simplifies RWNNs with significant computational advantages while maintaining performance comparable to ORC. Provides insights into trade-off between modular segregation and network efficiency.

Conclusion: Forman-Ricci curvature offers a computationally efficient alternative to Ollivier-Ricci curvature for network pruning while achieving comparable performance, making it suitable for optimizing randomly wired neural networks.

Abstract: Randomly Wired Neural Networks (RWNNs) serve as a valuable testbed for
investigating the impact of network topology in deep learning by capturing how
different connectivity patterns impact both learning efficiency and model
performance. At the same time, they provide a natural framework for exploring
edge-centric network measures as tools for pruning and optimization. In this
study, we investigate three edge-centric network measures: Forman-Ricci
curvature (FRC), Ollivier-Ricci curvature (ORC), and edge betweenness
centrality (EBC), to compress RWNNs by selectively retaining important synapses
(or edges) while pruning the rest. As a baseline, RWNNs are trained for
COVID-19 chest x-ray image classification, aiming to reduce network complexity
while preserving performance in terms of accuracy, specificity, and
sensitivity. We extend prior work on pruning RWNN using ORC by incorporating
two additional edge-centric measures, FRC and EBC, across three network
generators: Erd\"{o}s-R\'{e}nyi (ER) model, Watts-Strogatz (WS) model, and
Barab\'{a}si-Albert (BA) model. We provide a comparative analysis of the
pruning performance of the three measures in terms of compression ratio and
theoretical speedup. A central focus of our study is to evaluate whether FRC,
which is computationally more efficient than ORC, can achieve comparable
pruning effectiveness. Along with performance evaluation, we further
investigate the structural properties of the pruned networks through modularity
and global efficiency, offering insights into the trade-off between modular
segregation and network efficiency in compressed RWNNs. Our results provide
initial evidence that FRC-based pruning can effectively simplify RWNNs,
offering significant computational advantages while maintaining performance
comparable to ORC.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [68] [Measure $0$ of the singular set for $2$-valued stationary hypercurrents](https://arxiv.org/abs/2509.05544)
*Jonas Hirsch,Luca Spolaor*

Main category: math.DG

TL;DR: Singular set of multiplicity 2 integral hypercurrents stationary as varifolds has measure zero


<details>
  <summary>Details</summary>
Motivation: To establish regularity properties for stationary integral hypercurrents with multiplicity 2, specifically addressing the size and structure of their singular sets

Method: Mathematical proof using geometric measure theory and varifold theory to analyze stationary integral hypercurrents with multiplicity 2

Result: The singular set of such hypercurrents has Lebesgue measure zero

Conclusion: Multiplicity 2 integral hypercurrents that are stationary in the varifold sense exhibit improved regularity with negligible singular sets

Abstract: We prove that the singular set of a multiplicity $2$ integral hypercurrent
that is stationary in the sense of varifolds has a singular set of measure
zero.

</details>


### [69] [The linearized translator equation and applications](https://arxiv.org/abs/2509.06667)
*Kyeongsu Choi,Robert Haslhofer,Or Hershkovits*

Main category: math.DG

TL;DR: The paper develops a Fredholm theory for linearized translator equations in R^4 and uses it to classify all noncollapsed translators, showing they form a finite-dimensional analytic variety uniquely determined by tip curvature.


<details>
  <summary>Details</summary>
Motivation: To understand and classify noncollapsed translators in R^4, particularly since this is the first dimension where the Bernstein property fails for such surfaces.

Method: Derived barrier estimates (upper-lower and inner-outer estimates) to propagate L^∞-control, developed Fredholm theory for the linearized operator in weighted function spaces, and used Lyapunov-Schmidt reduction.

Result: The space of noncollapsed translators in R^4 is a finite-dimensional analytic variety, and the tip-curvature map is analytic, enabling complete classification.

Conclusion: The Hoffman-Ilmanen-Martin-White one-parameter family of translators is uniquely determined by the smallest principal curvature at the tip, completing the classification of noncollapsed translators in R^4.

Abstract: In this paper, we consider the linearized translator equation $L_\phi u=f$,
around entire convex translators $M=\textrm{graph}(\phi)\subset\mathbb{R}^4$,
i.e. in the first dimension where the Bernstein property fails. Here, $L_\phi
u=\mathrm{div} (a_\phi D u)+ b_\phi\cdot Du$ is a mean curvature type elliptic
operator, whose coefficients degenerate as the slope tends to infinity. We
derive two fundamental barrier estimates, specifically an upper-lower estimate
and an inner-outer estimate, which allow to propagate $L^\infty$-control
between different regions. Packaging these and further estimates together we
then develop a Fredholm theory for $L_\phi$ between carefully designed weighted
function spaces. Combined with Lyapunov-Schmidt reduction we infer that the
space $\mathcal{S}$ of noncollapsed translators in $\mathbb{R}^4$ is a finite
dimensional analytic variety and that the tip-curvature map
$\kappa:\mathcal{S}\to\mathbb{R}$ is analytic. Together with the main result
from our prior paper (Camb. J. Math. '23) this allows us to complete the
classification of noncollapsed translators in $\mathbb{R}^4$. In particular, we
conclude that the one-parameter family of translators constructed by
Hoffman-Ilmanen-Martin-White is uniquely determined by the smallest principal
curvature at the tip.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [70] [Self-learning QMC: application to the classical Holstein-Spin-Fermion model](https://arxiv.org/abs/2509.05876)
*Shaozhi Li*

Main category: cond-mat.str-el

TL;DR: Self-learning quantum Monte Carlo method uses machine learning to approximate free energy, reducing computational cost for phase transition simulations in Holstein-spin-fermion model.


<details>
  <summary>Details</summary>
Motivation: To evaluate machine learning effectiveness in systems with competing interactions and reduce computational costs by bypassing exact diagonalization.

Method: Developed SLQMC method using linear regression and neural network models to approximate free energy in classical Holstein-spin-fermion model simulations.

Result: Both models captured AFM to CDW phase transition, but sampling efficiency decreased near transition and with larger lattice sizes due to increased model error and finite-size effects.

Conclusion: Highly accurate machine learning models are necessary for simulating complex competing interactions on large lattices due to efficiency challenges near phase transitions and with scaling.

Abstract: To evaluate the effectiveness of machine learning in systems with competing
interactions, we developed a self-learning quantum Monte Carlo (SLQMC) method
to simulate the phase transition in the classical Holstein-spin-fermion model.
In SLQMC, machine learning techniques are employed to approximate the free
energy, thereby bypassing the need for exact diagonalization and significantly
reducing computational cost. We assess the performance of SLQMC using both
linear regression and neural network models. Our results show that both models
are capable of capturing the phase transition from the antiferromagnetic state
to the charge-density-wave state. However, the sampling efficiency decreases
near the AFM-CDW phase transition, which is attributed to the increased
mean-squared-error of the machine learning model. Additionally, the sampling
efficiency decreases with increasing lattice size. This suppression is due to
the increased root-mean-squared-error as the machine learning model is applied
to a large lattice and the finite-size effect, wherein the energy gap between
the ground state and low-energy excited states decreases as the lattice grows.
Our findings highlight the necessity of highly accurate machine learning models
to simulate theoretical models with complex, competing microscopic interactions
on a large lattice.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [71] [A topological approach to the Cahn-Hilliard equation and hyperuniform fields](https://arxiv.org/abs/2509.05339)
*Abel H. G. Milor,Otto Sumray,Heather A. Harrington,Axel Voigt,Marco Salvalaglio*

Main category: cond-mat.soft

TL;DR: Using persistent homology to analyze hyperuniform scalar fields from Cahn-Hilliard equation and Gaussian random fields, showing correlation between hyperuniformity and topological feature distributions.


<details>
  <summary>Details</summary>
Motivation: Hyperuniform structures have suppressed density fluctuations at large scales and appear across diverse physical systems. There's a need to characterize these patterns using topological methods to understand their structural properties.

Method: Leverage persistent homology to represent topological features in persistence diagrams, quantify pattern similarities using Wasserstein distances. Apply to Cahn-Hilliard equation solutions and Gaussian random fields with varying hyperuniformity.

Result: Validated approach against known Cahn-Hilliard features (scaling, sharp interface limit, self-similarity). Showed systematic correlation between hyperuniform characteristics and topological feature distributions. Demonstrated reconstruction of global properties from local topological information.

Conclusion: Persistent homology provides effective framework for characterizing hyperuniform scalar fields. The method is applicable to various scalar fields, especially those with interfaces and free boundaries, revealing connections between hyperuniformity and topological structure.

Abstract: Hyperuniform structures are disordered, correlated systems in which density
fluctuations are suppressed at large scales. Such a property generalizes the
concept of order in patterns and is relevant across diverse physical systems.
We present a numerical characterization of hyperuniform scalar fields that
leverages persistent homology. Topological features across different lengths
are represented in persistence diagrams, while similarities or differences
between patterns are quantified through Wasserstein distances between these
diagrams. We apply this framework to numerical solutions of the Cahn-Hilliard
equation, a canonical model for generating hyperuniform scalar fields. We
validate the approach against known features of the Cahn-Hilliard equation,
including its scaling properties, convergence to the sharp interface limit, and
self-similarity of the solutions. We then generalize the approach by studying
Gaussian random fields exhibiting different degrees and classes of
hyperuniformity, showing how the proposed approach can be exploited to
reconstruct global properties from local topological information. Overall, we
show how hyperuniform characteristics systematically correlate with
distributions of topological features in disordered correlated fields. We
expect this analysis to be applicable to a wide range of scalar fields,
particularly those involving interfaces and free boundaries.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [72] [Second-order multilane traffic flow models: from the microscopic to the macroscopic scale](https://arxiv.org/abs/2509.06083)
*Matteo Piu,Giuseppe Visconti,Gabriella Puppo*

Main category: physics.soc-ph

TL;DR: Derived two new multilane second-order macroscopic traffic models from microscopic Bando-Follow-the-Leader model, incorporating lane-changing through hyperbolic balance laws. Models reproduce congestion, non-equilibrium effects, and asymmetric lane usage, validated against real highway data.


<details>
  <summary>Details</summary>
Motivation: Address the gap in multilane traffic modeling by transitioning from microscopic to macroscopic descriptions, moving beyond first-order models to capture more complex traffic phenomena.

Method: Applied microscopic-to-macroscopic limit to multilane Bando-Follow-the-Leader model, resulting in hyperbolic system of balance laws with lane-changing source terms. Validated using numerical experiments and real-world highway datasets.

Result: Models successfully reproduce congestion propagation, non-equilibrium effects, and asymmetric lane usage. Faithfully capture critical density values and lane-dependent patterns when compared to empirical fundamental diagrams from real highways.

Conclusion: The derived second-order macroscopic models offer a robust and generalizable tool for realistic multilane traffic flow analysis, effectively bridging microscopic and macroscopic descriptions.

Abstract: This study addresses multilane vehicular traffic modelling, focusing on the
transition between microscopic (individual vehicle-based) to macroscopic
(aggregate flow-based) descriptions. While previous research on multilane
traffic has largely focused on first-order models, we derive two new multilane
second-order macroscopic models by applying a microscopic-to-macroscopic limit
to the multilane Bando-Follow-the-Leader model. The resulting models
incorporate lane-changing through source terms in a hyperbolic system of
balance laws. We propose several numerical experiments showing that the models
can reproduce complex traffic phenomena, including congestion propagation,
non-equilibrium effects, and asymmetric lane usage. Leveraging experimental
datasets from real-world highways, we further construct lane-specific empirical
fundamental diagrams and compare them with their simulated counterparts,
showing that our models can faithfully capture critical density values and
characteristic lane-dependent patterns, thus offering a robust and
generalizable tool for realistic traffic flow analysis

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [73] [Particle acceleration up to the synchrotron burn-off limit in relativistic magnetized turbulence](https://arxiv.org/abs/2509.06437)
*M. Lemoine,V. Bresci,L. Gremillet*

Main category: astro-ph.HE

TL;DR: Particle-in-cell simulations show that relativistic magnetized turbulent pair plasmas with synchrotron losses produce particle energy spectra extending beyond theoretical maximal energy with steepened power-law slopes (s=3 below cutoff, s=4 above), driven by generalized Fermi acceleration with strong electric fields.


<details>
  <summary>Details</summary>
Motivation: Understanding particle acceleration and radiative losses in high-energy astrophysics is crucial for interpreting observed spectra, particularly in environments like relativistic magnetized turbulent plasmas.

Method: Particle-in-cell simulations of particle acceleration in relativistic, magnetized turbulent pair plasmas including synchrotron radiative losses, with parameters: magnetization σ≈1 and amplitude δB/B₀≃1.

Result: Particle distribution follows γ⁻³ below maximal energy, steepens to γ⁻⁴ above. Strong variability near cutoff energy. Acceleration rate shows broken power-law distribution with maximal value at gyrofrequency. Highest energy particles accelerated by generalized Fermi process in ideal electric fields.

Conclusion: Stochastic acceleration in relativistic large-amplitude turbulence is promising for explaining highest-energy synchrotron spectra and variability, particularly applicable to environments like the Crab nebula.

Abstract: In high-energy astrophysics, interpreting observed spectra hinges on
understanding the competition between energy gains and radiative losses. To
progress along these lines, we report on particle-in-cell simulations of
particle acceleration in relativistic, magnetized turbulent pair plasmas
including synchrotron radiative losses. Our key finding is that the particle
energy spectrum does not terminate at this maximal energy but extends beyond
with a steepened spectrum, up to the synchrotron burn-off limit where particles
cool within a gyrotime. For our adopted parameters (magnetization $\sigma
\approx 1 $ and amplitude $\delta B/B_0\simeq 1$), the particle distribution
follows ${\rm d}n/{\rm d}\gamma\propto \gamma^{-s}$ with $s\simeq 3$ below the
predicted maximal energy, then steepens to $s\simeq 4$ above. The particle
distribution and the radiated synchrotron spectra display strong variability
near the cutoff energy down to timescales well below the largest eddy
turn-around time. We substantiate our results by demonstrating that the
acceleration rate itself displays a broken powerlaw-like distribution whose
maximal value is the gyrofrequency. The highest energy particles are
accelerated by a generalized Fermi process in ideal electric fields, driven by
a gradient of the $4$--velocity field $u_E$ of the magnetic field lines of
relativistic amplitude, $\delta u_E \gtrsim c$, ordered on a scale comparable
to the particle gyroradius. We contend that this is a generic feature of
relativistic, large-amplitude turbulence. Lastly, we apply our results to the
Crab nebula, which exhibits a hierarchy of characteristic Lorentz factors
similar to that studied here. We conclude that stochastic acceleration in this
environment is a promising mechanism for explaining the highest-energy part of
the synchrotron spectral energy distribution, and its variability. [Abridged]

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [74] [GPUTB: Efficient Machine Learning Tight-Binding Method for Large-Scale Electronic Properties Calculations](https://arxiv.org/abs/2509.06525)
*Yunlong Wang,Zhixin Liang,Chi Ding,Junjie Wang,Zheyong Fan,Hui-Tian Wang,Dingyu Xing,Jian Sun*

Main category: cond-mat.mtrl-sci

TL;DR: GPU-accelerated tight-binding ML framework for efficient electronic structure prediction of large systems up to 100 million atoms


<details>
  <summary>Details</summary>
Motivation: High computational cost of ab-initio methods limits electronic property prediction at device scale, requiring efficient atomic-to-electronic structure mapping

Method: GPUTB uses atomic environment descriptors with environmentally-dependent parameters, combined with linear scaling quantum transport method

Result: Successfully calculated DOS for 100M atoms in graphene, handles finite-temperature structures and h-BN/graphene heterojunctions, accurately reproduces carrier concentration-mobility relationship

Conclusion: GPUTB provides optimal balance between computational accuracy and efficiency for large-scale electronic property investigations

Abstract: The high computational cost of ab-initio methods limits their application in
predicting electronic properties at the device scale. Therefore, an efficient
method is needed to map the atomic structure to the electronic structure
quickly. Here, we develop GPUTB, a GPU-accelerated tight-binding (TB) machine
learning framework. GPUTB employs atomic environment descriptors, enabling the
model parameters to incorporate environmental dependence. This allows the model
to transfer to different basis, xc-functionals, and allotropes easily. Combined
with the linear scaling quantum transport method, we have calculated the
electronic density of states for up to 100 million atoms in pristine graphene.
Trained on finite-temperature structures, the model can be easily extended to
millions of atom finite-temperature systems. Furthermore, GPUTB can also
successfully describe h-BN/graphene heterojunction systems, demonstrating its
capability to handle complex material with high precision. We accurately
reproduce the relationship between carrier concentration and room temperature
mobility in graphene to verify the framework's accuracy. Therefore, our GPUTB
framework presents a delicate balance between computational accuracy and
efficiency, providing a powerful computational tool for investing electronic
properties for large systems with millions of atoms.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [75] [Universality of physical neural networks with multivariate nonlinearity](https://arxiv.org/abs/2509.05420)
*Benjamin Savinson,David J. Norris,Siddhartha Mishra,Samuel Lanthaler*

Main category: physics.optics

TL;DR: This paper presents a fundamental theorem establishing universality conditions for physical neural networks, particularly optical systems, and demonstrates a scalable free-space optical architecture that achieves high accuracy on image classification tasks.


<details>
  <summary>Details</summary>
Motivation: The enormous energy demand of AI is driving development of alternative hardware like physical neural networks. Optical systems can compute with light using negligible energy, but the inability to determine if they can learn arbitrary relationships (universality) hinders progress.

Method: The authors present a mathematical theorem that establishes universality conditions for physical neural networks, detailing device constraints and input encoding requirements. They propose a scalable free-space optics architecture and combine the theorem with temporal multiplexing for practical on-chip photonic devices.

Result: The proposed free-space optical architecture is provably universal and achieves high accuracy on image classification tasks. The temporal multiplexing approach enables potentially huge effective system sizes in practical on-chip photonic devices.

Conclusion: The theorem and scaling methods apply beyond optical systems and inform the design of universal, energy-efficient physical neural networks, justifying further development efforts in this field.

Abstract: The enormous energy demand of artificial intelligence is driving the
development of alternative hardware for deep learning. Physical neural networks
try to exploit physical systems to perform machine learning more efficiently.
In particular, optical systems can calculate with light using negligible
energy. While their computational capabilities were long limited by the
linearity of optical materials, nonlinear computations have recently been
demonstrated through modified input encoding. Despite this breakthrough, our
inability to determine if physical neural networks can learn arbitrary
relationships between data -- a key requirement for deep learning known as
universality -- hinders further progress. Here we present a fundamental theorem
that establishes a universality condition for physical neural networks. It
provides a powerful mathematical criterion that imposes device constraints,
detailing how inputs should be encoded in the tunable parameters of the
physical system. Based on this result, we propose a scalable architecture using
free-space optics that is provably universal and achieves high accuracy on
image classification tasks. Further, by combining the theorem with temporal
multiplexing, we present a route to potentially huge effective system sizes in
highly practical but poorly scalable on-chip photonic devices. Our theorem and
scaling methods apply beyond optical systems and inform the design of a wide
class of universal, energy-efficient physical neural networks, justifying
further efforts in their development.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [76] [Weak solutions of port-Hamiltonian systems](https://arxiv.org/abs/2509.05521)
*Timo Reis*

Main category: math.DS

TL;DR: Introduction of weak solution concept for port-Hamiltonian systems in Banach spaces, with state derivative in extrapolation space, consistent with PDE weak solution framework.


<details>
  <summary>Details</summary>
Motivation: To develop a geometric perspective for port-Hamiltonian systems in infinite-dimensional Banach spaces and establish a rigorous weak solution framework that aligns with PDE theory.

Method: Propose a weak solution concept where the state derivative naturally resides in an extrapolation space, using geometric approach for port-Hamiltonian systems in Banach spaces.

Result: The framework demonstrates consistency with conventional weak solution approaches used for partial differential equations through illustrative examples.

Conclusion: The introduced weak solution concept provides a mathematically rigorous foundation for analyzing port-Hamiltonian systems in infinite-dimensional settings, bridging the gap with established PDE weak solution theory.

Abstract: We consider port-Hamiltonian systems from a geometric perspective, where the
quantities involved such as state, flows, and efforts evolve in (possibly
infinite-dimensional) Banach spaces. The main contribution of this article is
the introduction of a weak solution concept. In this framework we show that the
derivative of the state naturally lives in a space that, for ordinary evolution
equations, plays the role of an extrapolation space. Through examples, we
demonstrate that this approach is consistent with the weak solution framework
commonly used for partial differential equations.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [77] [Classical Neural Networks on Quantum Devices via Tensor Network Disentanglers: A Case Study in Image Classification](https://arxiv.org/abs/2509.06653)
*Borja Aizpurua,Sukhbinder Singh,Román Orús*

Main category: quant-ph

TL;DR: Quantum implementation of classical neural network bottleneck layers using matrix product operator compression and disentangling for hybrid classical-quantum execution.


<details>
  <summary>Details</summary>
Motivation: To achieve quantum advantage on near-term devices by implementing bottleneck layers from pre-trained neural networks on quantum computers while maintaining performance.

Method: Two-step approach: 1) Compress target linear layer as matrix product operator (MPO) without performance degradation, 2) Disentangle MPO into compact form using variational tensor-network optimization and gradient-descent approaches.

Result: Proof-of-concept validation through translation of classical neural networks for MNIST and CIFAR-10 image classification into hybrid classical-quantum form.

Conclusion: The proposed methods enable effective hybrid execution where disentangling circuits run on quantum hardware while the rest of the network operates classically, demonstrating feasibility for near-term quantum advantage.

Abstract: We address the problem of implementing bottleneck layers from classical
pre-trained neural networks on a quantum computer, with the goal of achieving
quantum advantage on near-term devices. Our approach begins with a compression
step in which the target linear layer is represented as an effective matrix
product operator (MPO) without degrading model performance. The MPO is then
further disentangled into a more compact form. This enables a hybrid
classical-quantum execution scheme, where the disentangling circuits are
deployed on a quantum computer while the remainder of the network -- including
the disentangled MPO -- runs on classical hardware. We introduce two
complementary algorithms for MPO disentangling: (i) an explicitly disentangling
variational method leveraging standard tensor-network optimization techniques,
and (ii) an implicitly disentangling gradient-descent-based approach. We
validate these methods through a proof-of-concept translation of simple
classical neural networks for MNIST and CIFAR-10 image classification into a
hybrid classical-quantum form.

</details>


### [78] [High-order Magnus Expansion for Hamiltonian Simulation](https://arxiv.org/abs/2509.06054)
*Di Fang,Diyi Liu,Shuchen Zhu*

Main category: quant-ph

TL;DR: High-order quantum algorithm for time-dependent Hamiltonian simulation with commutator-scaling error bounds and logarithmic dependence on time variation.


<details>
  <summary>Details</summary>
Motivation: Efficient simulation of quantum dynamics with time-dependent Hamiltonians is challenging due to time ordering complexity, and existing algorithms have limitations in cost dependence on time derivatives or are limited to low-order accuracy.

Method: Established general commutator-scaling error bounds for truncated Magnus expansion at arbitrary order, then designed a high-order quantum algorithm with explicit circuit constructions that leverages this analysis.

Result: The algorithm achieves cost scaling with commutator structure in high-precision regime and depends only logarithmically on Hamiltonian's time variation, making it efficient for general time-dependent settings including interaction picture.

Conclusion: The proposed method provides an efficient high-order quantum algorithm for time-dependent Hamiltonian simulation with improved scaling properties compared to existing approaches.

Abstract: Efficient simulation of quantum dynamics with time-dependent Hamiltonians is
important not only for time-varying systems but also for time-independent
Hamiltonians in the interaction picture. Such simulations are more challenging
than their time-independent counterparts due to the complexity introduced by
time ordering. Existing algorithms that aim to capture commutator-based scaling
either exhibit polynomial cost dependence on the Hamiltonian's time derivatives
or are limited to low-order accuracy. In this work, we establish the general
commutator-scaling error bounds for the truncated Magnus expansion at arbitrary
order, where only Hamiltonian terms appear in the nested commutators, with no
time derivatives involved. Building on this analysis, we design a high-order
quantum algorithm with explicit circuit constructions. The algorithm achieves
cost scaling with the commutator structure in the high-precision regime and
depends only logarithmically on the Hamiltonian's time variation, making it
efficient for general time-dependent settings, including the interaction
picture.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [79] [McKean-Vlasov limits of scaling-critical reaction-diffusion equations with random initial data](https://arxiv.org/abs/2509.06260)
*Bryan Castillo,Alexander Dunlap*

Main category: math.PR

TL;DR: Study of scaling-critical reaction-diffusion equations in 2D with mollified white noise initial data and attenuated reaction terms, showing convergence to McKean-Vlasov equations


<details>
  <summary>Details</summary>
Motivation: To understand the limiting behavior of scaling-critical reaction-diffusion equations in two dimensions, particularly extending recent results on Allen-Cahn equation convergence

Method: Analyze equations with white noise initial data mollified at scale ε² and reaction terms attenuated by (logε⁻¹)⁻¹ factor, then study convergence as ε→0

Result: Solution converges to McKean-Vlasov equation solution, which is Gaussian with standard deviation given by ODE solution. Covers f(u)=u³ case, providing new proof for Allen-Cahn limiting behavior

Conclusion: Establishes convergence framework for scaling-critical 2D reaction-diffusion equations with mollified noise, generalizing and providing alternative proof for recent Allen-Cahn results

Abstract: We study a large class of scaling-critical reaction-diffusion equations in
two spatial dimensions, where the initial data is white noise mollified at
scale $\varepsilon^2$ and the reaction term is attenuated by a factor of
$(\log\varepsilon^{-1})^{-1}$. We show that as $\varepsilon\to 0$, the solution
converges to the solution of a McKean-Vlasov equation, which is Gaussian with
standard deviation given by the solution to an ODE. Our result covers the case
of the reaction term $f(u)=u^3$, and thus gives a new proof of the limiting
behavior for the Allen-Cahn equation discovered in the recent work of Gabriel,
Rosati, and Zygouras (Probab. Theory Related Fields 192: 1373-1446, 2025).

</details>


### [80] [Infinite Interacting Brownian Motions and EVI Gradient Flows](https://arxiv.org/abs/2509.06869)
*Kohei Suzuki*

Main category: math.PR

TL;DR: The paper establishes conditions where the time marginal of a diffusion process in infinite-dimensional configuration space is the unique Wasserstein gradient flow of relative entropy, with applications to Dyson-type SDEs and functional inequalities.


<details>
  <summary>Details</summary>
Motivation: To understand the gradient flow structure of diffusion processes in infinite-dimensional spaces and establish connections with important point processes like sine and Airy ensembles.

Method: Provides sufficient conditions using Wasserstein geometry and extended distance metrics on configuration spaces, analyzing μ-symmetric diffusion processes with ℓ2-matching extended distance.

Result: Shows that time marginals are unique EVI-gradient flows of relative entropy, proves RCD conditions, functional inequalities, and propagation of number rigidity and tail triviality.

Conclusion: The framework applies to important point processes and establishes rigorous geometric and analytical properties of infinite-dimensional diffusion processes.

Abstract: We provide a sufficient condition under which the time marginal of the law of
$\mu$-symmetric diffusion process $\mathsf{X}$ in the infinite dimensional
configuration space $\mathbf \Upsilon$ is the unique Wasserstein
$\mathsf{W}_{2, \mathsf{d}_\mathbf\Upsilon}$ $\mathsf{EVI}$-gradient flow of
the relative entropy (a.k.a. Kullback-Leibler divergence) $\mathrm{Ent}_{\mu}$
on the space $P(\mathbf \Upsilon)$ of probability measures on $\mathbf
\Upsilon$. Here, $\mathbf \Upsilon$ is equipped with the $\ell^2$-matching
extended distance $\mathsf d_\mathbf \Upsilon$ and a Borel probability $\mu$
while $P(\mathbf \Upsilon)$ is endowed with the transportation extended
distance $\mathsf W_{2, \mathsf d_\mathbf \Upsilon}$ with cost $\mathsf
d_\mathbf \Upsilon^2$. Our results include the cases $\mu=\mathsf{sine}_2$ and
$\mu= \mathsf{Airy}_2$ point processes, where the associated diffusion
processes are unlabelled solutions to the infinite-dimensional Dyson-type
stochastic differential equations in the bulk and soft-edge limit respectively.
As an application, we show that the extended metric measure space $(\mathbf
\Upsilon , \mathsf{d}_\mathbf \Upsilon, \mu)$ satisfies the Riemannian
curvature-dimension (RCD) condition as well as the distorted Brunn-Minkowski
inequality, the HWI inequality and several other functional inequalities.
Finally we prove that the time marginal of the law of $\mathsf{X}$ propagates
number rigidity and tail triviality.

</details>


<div id='physics.atm-clus'></div>

# physics.atm-clus [[Back]](#toc)

### [81] [Dissociative recombination of NeH+ with low-energy electrons: Multichannel quantum defect theory including non-adiabatic couplings](https://arxiv.org/abs/2509.05859)
*Riyad Hassaine,Janos Zsolt Mezei,Dahbia Talbi,Jonathan Tennyson,Ioan F. Schneider*

Main category: physics.atm-clus

TL;DR: Theoretical study of NeH+ dissociative recombination with low-energy electrons using advanced quantum defect theory with second-order non-adiabatic couplings.


<details>
  <summary>Details</summary>
Motivation: To investigate NeH+ dissociative recombination without direct potential energy curve crossings, addressing gaps in theoretical data below 4.5 eV where no detailed quantum calculations exist.

Method: Multichannel quantum defect theory incorporating non-adiabatic couplings between electronic states, including second-order terms B(R) and radial density of states, using previously characterized potential energy curves and couplings.

Result: Calculated cross sections show good agreement with available experimental data and provide theoretical data for the previously uncovered energy range below 4.5 eV.

Conclusion: The developed formulation successfully models NeH+ dissociative recombination, demonstrating the importance of including second-order non-adiabatic couplings for accurate theoretical predictions.

Abstract: Theoretical investigation of the dissociative recombination (DR) of NeH+ with
low-energy electrons in the regime where the process occurs without direct
potential energy curve crossings is presented. The calculations are performed
using multichannel quantum defect theory, incorporating non-adiabatic couplings
between electronic states. Unlike the previous treatment of the DR of HeH+,
where only first-order radial couplings A(R) were considered, our formulation
also incorporates the second-order terms B(R), together with a radial density
of states \b{eta}{\nu} (R) to describe the transition into the ionization
continuum. This development uses a large number of potential energy curves and
non-adiabatic couplings of NeH characterized by us previously, enabling a
consistent modeling of the DR process. The resulting cross sections show good
agreement with the available experimental data and fill a gap in theoretical
data below 4.5 eV, where no detailed quantum calculations are currently
available.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [82] [Adaptive time-stepping for the Super-Droplet Method Monte Carlo collision-coalescence scheme](https://arxiv.org/abs/2509.05536)
*Emma Ware,Piotr Bartman-Szwarc,Adele L. Igel,Sylwester Arabas*

Main category: physics.ao-ph

TL;DR: Adaptive time-stepping effectively eliminates collision deficit error in Super-Droplet Method simulations without significant computational cost, improving accuracy for cloud microphysics modeling.


<details>
  <summary>Details</summary>
Motivation: The Super-Droplet Method (SDM) for simulating particle coagulation suffers from a systematic underestimation error called 'collision deficit' when expected collision events are not realizable given superdroplet configurations, which can bias results and delay precipitation onset.

Method: Analyzed adaptive time-stepping scheme that dynamically adjusts simulation time steps to eliminate collision deficit. Tested across various timesteps, superdroplet counts, and initialization strategies using Safranov-Golovin test case. Proposed network connectivity graphs for visualization of attribute sampling and droplet interactions.

Result: Collision deficit increases with timestep and superdroplet count. Adaptive time-stepping effectively removes the error without significant cost. Deficit is sensitive to attribute-space sampling strategies, but adaptive time-stepping reduces these differences. In 2-D flow-coupled simulations, uncorrected deficit delays precipitation onset.

Conclusion: Adaptive time-stepping provides an efficient solution to the collision deficit problem in SDM, allowing users to choose initialization methods optimized for other processes while maintaining accuracy in cloud microphysics simulations.

Abstract: We present an analysis of an adaptive time-stepping scheme for the
Super-Droplet Method (SDM), a Monte Carlo algorithm for simulating particle
coagulation. SDM represents cloud droplets as weighted superdroplets, enabling
high-fidelity representations of microphysical processes such as
collision-coalescence. However, the algorithm can undercount collisions when
the expected number of events is not realizable given the superdroplet
configuration, introducing a biased error referred here as the collision
deficit. While SDM exhibits statistical spread inherent to Monte Carlo schemes,
the deficit is a systematic underestimation of collision events. This error can
be addressed with adaptive time-stepping, which dynamically adjusts simulation
time steps to eliminate this deficit. We analyze the behavior of the deficit
across a wide range of timesteps, superdroplet counts, and initialization
strategies, and explore trade-offs between accuracy and efficiency. Using the
classical Safranov-Golovin test case, we show that the deficit increases with
timestep and superdroplet count, and that adaptive time-stepping effectively
removes the associated error without significant cost. We test a smooth
continuum of initial distributions with extrema representing two different
initialization methods, and find that while the deficit is sensitive to the
choice of attribute-space sampling strategies, adaptive time-stepping
substantially reduces the difference, allowing for users to choose
initialization methods optimized for other processes. We also propose a method
of visualization, capturing both the attribute sampling, droplet interactions
over multiple timesteps, and the deficit using network connectivity graphs. In
2-D flow-coupled simulations, we find the deficit can have a stronger effect on
convergence than previously shown, with uncorrected deficit delaying the onset
of precipitation.

</details>


<div id='math.AG'></div>

# math.AG [[Back]](#toc)

### [83] [Quadrature rules with few nodes supported on algebraic curves](https://arxiv.org/abs/2509.06643)
*Cordian Riener,Ettore Teixeira Turatti*

Main category: math.AG

TL;DR: Optimal quadrature rules for measures on algebraic and rational curves, focusing on odd-degree cases with minimal nodes. Improved bounds based on curve degree and geometry.


<details>
  <summary>Details</summary>
Motivation: To develop efficient numerical integration methods for measures supported on algebraic curves by minimizing the number of quadrature nodes while maintaining accuracy.

Method: Optimization approach minimizing penalty functions over quadrature rules of strength 2s-1, using algebraic geometry of curves and parametrization geometry.

Result: Derived explicit node bounds for plane algebraic curves depending on degree and places at infinity, and refined bounds for rational curves using parametrization geometry.

Conclusion: Established connection between algebraic complexity of curves and minimal quadrature size, providing unified framework linking real algebraic geometry, polynomial optimization, and moment theory.

Abstract: We investigate quadrature rules for measures supported on real algebraic and
rational curves, focusing on the {odd-degree} case \(2s-1\). Adopting an
optimization viewpoint, we minimize suitable penalty functions over the space
of quadrature rules of strength \(2s-1\), so that optimal solutions yield rules
with the minimal number of nodes. For plane algebraic curves of degree \(d\),
we derive explicit node bounds depending on \(d\) and the number of places at
infinity, improving results of Riener--Schweighofer, and Zalar. For rational
curves in arbitrary dimension of degree \(d\), we further refine these bounds
using the geometry of the parametrization and recover the classical Gaussian
quadrature bound when \(d=1\). Our results reveal a direct link between the
algebraic complexity of the supporting curve and the minimal size of quadrature
formulas, providing a unified framework that connects real algebraic geometry,
polynomial optimization, and moment theory.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [84] [Persistent Charge and Spin Currents in a Ferromagnetic Hatano-Nelson Ring](https://arxiv.org/abs/2509.06109)
*Sourav Karmakar,Sudin Ganguly,Santanu K. Maiti*

Main category: cond-mat.mes-hall

TL;DR: Study of persistent charge and spin currents in a ferromagnetic Hatano-Nelson ring with non-Hermitian hopping, showing real/imaginary currents and disorder-enhanced spin transport.


<details>
  <summary>Details</summary>
Motivation: To investigate how non-Hermitian Aharonov-Bohm effects and ferromagnetic spin splitting enable novel persistent charge and spin currents in topological systems, particularly focusing on manipulation through disorder and system parameters.

Method: Used current operator method within a biorthogonal basis to compute currents, analyzed complex band structure to understand spectral characteristics, and studied evolution across topological regimes with varying chemical potential, ferromagnetic ordering, size, and disorder.

Result: System supports both real and imaginary persistent currents with all three spin-current components enabled by ferromagnetic spin splitting. Currents evolve across topological regimes and are tunable by various parameters. Strikingly, disorder can amplify spin currents.

Conclusion: Non-Hermitian ferromagnetic systems provide powerful new routes for manipulating spin transport, with disorder unexpectedly enhancing rather than suppressing spin currents, opening possibilities for advanced spintronic applications.

Abstract: We investigate persistent charge and spin currents in a ferromagnetic
Hatano-Nelson ring with anti-Hermitian intradimer hopping, where non-reciprocal
hopping generates a synthetic magnetic flux and drives a non-Hermitian
Aharonov-Bohm effect. The system supports both real and imaginary persistent
currents, with ferromagnetic spin splitting enabling all three spin-current
components, dictated by the orientation of magnetic moments. The currents are
computed using the current operator method within a biorthogonal basis. In
parallel, the complex band structure is analyzed to uncover the spectral
characteristics. We emphasize how the currents evolve across different
topological regimes, and how they are influenced by chemical potential,
ferromagnetic ordering, finite size, and disorder. Strikingly, disorder can
even amplify spin currents, opening powerful new routes for manipulating spin
transport in non-Hermitian systems.

</details>


### [85] [Crystallization in the Winterbottom shape and sharp fluctuation laws](https://arxiv.org/abs/2509.05642)
*Manuel Friedrich,Leonard Kreutz,Ulisse Stefanelli*

Main category: cond-mat.mes-hall

TL;DR: Finite crystallization in 2D with substrate interaction. Crystallization proven for all β>0, showing discrete Winterbottom configurations. Fluctuation bounds reveal substrate-driven scaling laws: N³/⁴ for rational β and N¹/³ for irrational algebraic β.


<details>
  <summary>Details</summary>
Motivation: Study crystallization phenomena in the presence of a crystalline substrate to understand how substrate interactions affect particle arrangement and fluctuation behavior in finite systems.

Method: Uses short-range two- and three-body potentials favoring square-lattice arrangements with additional substrate interaction term. Employs stratification technique to characterize bond graph topology of minimizing configurations.

Result: Proves crystallization for all β>0. Obtains fluctuation bounds showing different scaling laws: N³/⁴ for rational β and N¹/³ for irrational algebraic β, revealing substrate-driven effects.

Conclusion: Substrate interactions significantly impact fluctuation scaling laws in crystallization. The work establishes discrete-to-continuum convergence towards Winterbottom equilibrium shape in large-particle limit.

Abstract: We address finite crystallization in two dimensions in the presence of a flat
crystalline substrate. Particles interact through short-range two- and
three-body potentials favoring local square-lattice arrangements. An additional
interaction term of relative strength $\beta>0$ couples the particles and the
substrate. Our first main result proves crystallization for all $\beta>0$,
corresponding to
  the onset of discrete Winterbottom configurations. The proof relies on a
stratification technique from [31], characterizing the topology of the bond
graph of minimizing configurations.
  Our second main result concerns fluctuations estimates for $\beta\in (0,1)$.
We obtain bounds on the distance between distinct minimizers with the same
number $N$ of particles, showing a sharp scaling law $N^{3/4}$ when $\beta$ is
rational, and $N^{1/3}$ when $\beta$ is irrational and algebraic. This reveals
a genuine substrate-driven effect on fluctuation laws. As a corollary, we
derive a discrete-to-continuum convergence of minimizers towards the
Winterbottom equilibrium shape in the large-particle limit.

</details>
