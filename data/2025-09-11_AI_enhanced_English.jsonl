{"id": "2509.08070", "pdf": "https://arxiv.org/pdf/2509.08070", "abs": "https://arxiv.org/abs/2509.08070", "authors": ["Nira Dyn", "Nir Sharon"], "title": "Subdivision Schemes in Metric Spaces", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We develop a unified framework for nonlinear subdivision schemes on complete\nmetric spaces (CMS). We begin with CMS preliminaries and formalize refinement\nin CMS, retaining key structural properties, such as locality. We prove a\nconvergence theorem under contractivity and demonstrate its applicability. To\naddress schemes where contractivity is unknown, we introduce two notions of\nproximity. Our proximity methods relate a nonlinear scheme to another nonlinear\nscheme with known contractivity, rather than to a linear scheme, as in much of\nthe literature. Specifically, the first type proximity compares the two schemes\nafter a single refinement step and, as in the classical theory, yields\nconvergence from sufficiently dense initial data. The proximity of the second\ntype monitors alignment across all refinement levels and provides strong\nconvergence without density assumptions. We formulate and prove the\ncorresponding theorems, and illustrate them with various examples, such as\nschemes over metric spaces of compact sets in $\\R^n$ and schemes over the\nWasserstein space, as well as a geometric Hermite metric space. These results\nextend subdivision theory beyond Euclidean and manifold-valued data for data in\nmetric spaces.", "AI": {"tldr": "A unified framework for nonlinear subdivision schemes in complete metric spaces with convergence theorems and proximity methods.", "motivation": "Extend subdivision theory beyond Euclidean and manifold-valued data to handle data in general metric spaces.", "method": "Develop formal refinement in CMS, prove convergence under contractivity, introduce two proximity notions to relate nonlinear schemes, and provide theorems with examples.", "result": "Established convergence theorems and proximity methods that work for various metric spaces including compact sets in R^n, Wasserstein space, and geometric Hermite metric space.", "conclusion": "The framework successfully extends subdivision theory to complete metric spaces, enabling analysis of nonlinear schemes without relying on linear approximations."}}
{"id": "2509.08071", "pdf": "https://arxiv.org/pdf/2509.08071", "abs": "https://arxiv.org/abs/2509.08071", "authors": ["Engin Danis", "Duc Truong", "Kim \u00d8. Rasmussen\u00a7", "Boian S. Alexandrov"], "title": "Tensor-Train Operator Inference", "categories": ["math.NA", "cs.NA", "65F55, 15A69", "G.1.6; I.6.5"], "comment": "AIAA SciTech 2026", "summary": "In this study, we present a tensor--train framework for nonintrusive operator\ninference aimed at learning discrete operators and using them to predict\nsolutions of physical governing equations. Our framework comprises three\napproaches: full--order tensor--train operator inference, full--order quantized\ntensor--train operator inference, and reduced--order tensor--train operator\ninference. In each case, snapshot data is represented in tensor--train\nformat--either through compression or cross interpolation--enabling the\nefficient handling of extremely large datasets with significantly reduced\ncomputational effort compared to standard methods. The effectiveness of each\napproach is demonstrated through numerical experiments related to Computational\nFluid Dynamics and benchmarked against the standard reduced--order operator\ninference method, highlighting the advantages of the tensor--train\nrepresentations in both accuracy and scalability.", "AI": {"tldr": "Tensor-train framework for nonintrusive operator inference that learns discrete operators from physical governing equations using three approaches with efficient tensor-train data representation.", "motivation": "To enable efficient handling of extremely large datasets in physical simulations with reduced computational effort compared to standard methods.", "method": "Three tensor-train approaches: full-order tensor-train operator inference, full-order quantized tensor-train operator inference, and reduced-order tensor-train operator inference using tensor-train format representation through compression or cross interpolation.", "result": "Demonstrated effectiveness through numerical experiments in Computational Fluid Dynamics, showing advantages in accuracy and scalability compared to standard reduced-order operator inference methods.", "conclusion": "Tensor-train representations provide significant computational efficiency and accuracy improvements for operator inference in physical governing equations, making them suitable for large-scale simulations."}}
{"id": "2509.08103", "pdf": "https://arxiv.org/pdf/2509.08103", "abs": "https://arxiv.org/abs/2509.08103", "authors": ["Erik Burman", "Miguel A. Fernandez", "Johnny Guzman", "Sijing Liu"], "title": "An Improved Robin-Robin Coupling Method for Parabolic-Parabolic Interface Problems", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We consider a loosely coupled, non-iterative Robin-Robin coupling method\nproposed and analyzed in [Numer. Algorithms, 99:921-948, 2025] for a\nparabolic-parabolic interface problem. We modify the first step of the scheme\nso that several error difference quantities remain higher order convergence\nwithout requiring additional assumptions. Numerical results are presented to\nsupport our findings.", "AI": {"tldr": "Modified Robin-Robin coupling method for parabolic-parabolic interface problems achieves higher order convergence without extra assumptions", "motivation": "To improve the original loosely coupled, non-iterative Robin-Robin coupling method by modifying the first step to maintain higher order convergence of error difference quantities", "method": "Modified the first step of the existing Robin-Robin coupling scheme to ensure several error difference quantities achieve higher order convergence without requiring additional assumptions", "result": "Numerical results demonstrate that the modified scheme successfully maintains higher order convergence as theoretically predicted", "conclusion": "The proposed modification to the Robin-Robin coupling method effectively achieves higher order convergence for error difference quantities in parabolic-parabolic interface problems without imposing additional requirements"}}
{"id": "2509.08109", "pdf": "https://arxiv.org/pdf/2509.08109", "abs": "https://arxiv.org/abs/2509.08109", "authors": ["Nicolas Nytko", "Scott MacLachlan", "J. David Moulton", "Luke N. Olson", "Andrew Reisner", "Matthew West"], "title": "Unstructured to structured: geometric multigrid on complex geometries via domain remapping", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "For domains that are easily represented by structured meshes, robust\ngeometric multigrid solvers can quickly provide the numerical solution to many\ndiscretized elliptic PDEs. However, for complicated domains with unstructured\nmeshes, constructing suitable hierarchies of meshes becomes challenging. We\npropose a framework for mapping computations from such complex domains to\nregular computational domains via diffeomorphisms, enabling the use of robust\ngeometric-style multigrid. This mapping facilitates regular memory accesses\nduring solves, improving efficiency and scalability, especially on massively\nparallel processors such as GPUs. Moreover, we show that the diffeomorphic\nmapping itself may be approximately learned using an invertible neural network,\nfacilitating automated application to geometries where no analytic mapping is\nreadily available.", "AI": {"tldr": "A framework that maps complex unstructured mesh domains to regular computational domains using diffeomorphisms, enabling geometric multigrid solvers on GPUs with improved efficiency, and showing that the mapping can be learned via invertible neural networks.", "motivation": "Geometric multigrid solvers work well on structured meshes but face challenges with complex unstructured meshes where constructing mesh hierarchies is difficult.", "method": "Proposes using diffeomorphic mappings to transform complex domains into regular computational domains, allowing geometric-style multigrid methods. Also demonstrates that invertible neural networks can learn these mappings.", "result": "Enables robust geometric multigrid on unstructured meshes, improves memory access patterns for efficiency, and facilitates scalability on massively parallel processors like GPUs.", "conclusion": "The framework successfully bridges the gap between complex unstructured domains and efficient geometric multigrid solvers through diffeomorphic mappings, with neural networks providing automated mapping capabilities for geometries without analytic solutions."}}
{"id": "2509.08072", "pdf": "https://arxiv.org/pdf/2509.08072", "abs": "https://arxiv.org/abs/2509.08072", "authors": ["Younghun Hong", "Stephen Pankavich"], "title": "The non-relativistic limit of scattering states for the Vlasov equation with short-range interaction potentials", "categories": ["math.AP"], "comment": "33 pages", "summary": "We study the relativistic and non-relativistic Vlasov equation driven by\nshort-range interaction potentials and identify the large time dynamics of\nsolutions. In particular, we construct global-in-time solutions launched from\nsmall initial data and prove that they scatter along the forward free flow to\nwell-behaved limits as $t \\to \\infty$. Moreover, we prove the existence of wave\noperators for such a regime and, upon constructing the aforementioned time\nasymptotic limits, use the wave operator formulation to prove for the first\ntime that the relativistic scattering states converge to their non-relativistic\ncounterparts as $c \\to \\infty$.", "AI": {"tldr": "Analysis of Vlasov equations with short-range potentials, showing global solutions from small data scatter to free flow limits, with wave operators proving relativistic scattering states converge to non-relativistic ones as c\u2192\u221e", "motivation": "To understand the long-time dynamics of both relativistic and non-relativistic Vlasov equations with short-range interaction potentials and establish connections between their scattering behaviors", "method": "Construct global-in-time solutions from small initial data, prove scattering along forward free flow, establish wave operators, and analyze convergence of relativistic scattering states to non-relativistic counterparts in the infinite speed of light limit", "result": "Successfully constructed global solutions that scatter to well-behaved limits, proved existence of wave operators, and demonstrated for the first time that relativistic scattering states converge to non-relativistic ones as c\u2192\u221e", "conclusion": "The study provides complete scattering theory for Vlasov equations with short-range potentials and establishes fundamental connections between relativistic and non-relativistic scattering behaviors"}}
{"id": "2509.07988", "pdf": "https://arxiv.org/pdf/2509.07988", "abs": "https://arxiv.org/abs/2509.07988", "authors": ["Peiyi Chen", "Rogerio Jorge", "Qin Li", "Yukun Yue"], "title": "Control of a Uniformly Magnetized Plasma with External Electric Fields", "categories": ["physics.plasm-ph", "cs.NA", "math.AP", "math.NA"], "comment": null, "summary": "The stability of plasmas is a challenging topic. We study a control problem\nfor plasma living in a uniform external magnetic field. Linear analysis for any\nequilibrium $\\mu$ is investigated through the Laplace-Fourier transform\napproach. Moreover, the Penrose condition, which characterizes the stability of\nequilibrium, is derived for Bernstein modes and verified numerically. Based on\nthe linear analysis, a general control strategy is introduced, with recovering\nthe free-streaming solution as a specific example. We finally present several\nexamples to control instabilities, including Gaussian equilibria and\nDory-Guest-Harris instability.", "AI": {"tldr": "Analysis of plasma stability control using linear analysis and Penrose condition, with numerical verification and control strategy examples.", "motivation": "Plasma stability is challenging, especially in uniform external magnetic fields, requiring effective control strategies for instabilities.", "method": "Linear analysis via Laplace-Fourier transform, derivation of Penrose condition for Bernstein modes, numerical verification, and development of general control strategy.", "result": "Successfully characterized plasma stability conditions, verified numerically, and demonstrated control of instabilities including Gaussian equilibria and Dory-Guest-Harris instability.", "conclusion": "The developed linear analysis and control strategy provide effective tools for managing plasma instabilities in magnetic fields, with practical applications demonstrated through various examples."}}
{"id": "2509.07989", "pdf": "https://arxiv.org/pdf/2509.07989", "abs": "https://arxiv.org/abs/2509.07989", "authors": ["Lubom\u00edr Bure\u0161"], "title": "Residence-time theory applied to circulating-fuel reactors: zero-power analysis", "categories": ["physics.comp-ph"], "comment": "26 pages, 12 figures", "summary": "Circulating-fuel reactors (CFRs) lose reactivity when delayed-neutron\nprecursors (DNPs) drift out of the core and may regain part of it when the fuel\nre-enters the core. This paper formulates a physics-based description of both\neffects by combining DNP transport with residence-time theory. Then, treating\nthe core and ex-core regions as two mixing volumes in series, closed-form\nexpressions for (i) the static reactivity loss due to precursor drift and (ii)\nthe zero-power transfer function that governs linearised dynamics are derived.\nWhen the gamma residence-time distributions are used, the new framework is\nshown to reduce to the plug-flow and Continuous-Stirred-Tank-Reactor limits as\nspecial cases, while generalising to intermediate mixing regimes via a single\nparameter: the degree of mixing. Performed parameter studies show that DNP\nrecirculation has the highest impact when core and ex-core residence times are\ncomparable and the product of the DNP decay constant and the in-core residence\ntime is small. Benchmarks against the Molten-Salt Reactor Experiment are able\nto reproduce the measured static loss ($k_0 \\approx 0.32$ \\$) and its frequency\nresponse, with $\\approx$20% of the steady-state DNP worth arising from\nrecirculation. Additionally, for the EVOL reference Molten-Salt Fast Reactor\nthe model is shown to agree well with the results of high-fidelity Serpent-2\ncalculations coupled with Computational Fluid Dynamics. Overall, the\nresidence-time approach offers a computationally light yet versatile tool for\nsensitivity studies and generation of physical intuition for the behaviour of\nCFRs. Foundation for extensions to importance weighting of DNPs and application\nof the framework to time-domain analysis is also briefly sketched.", "AI": {"tldr": "This paper develops a residence-time theory framework to model delayed-neutron precursor drift and recirculation effects in circulating-fuel reactors, providing closed-form expressions for reactivity loss and transfer functions that work across different mixing regimes.", "motivation": "Circulating-fuel reactors experience reactivity changes when delayed-neutron precursors drift out of and re-enter the core, requiring a physics-based model to understand and predict these effects for reactor design and safety analysis.", "method": "Combines DNP transport with residence-time theory, treating core and ex-core regions as two mixing volumes in series to derive closed-form expressions for static reactivity loss and zero-power transfer function.", "result": "The model reproduces MSRE measurements (0.32 $ reactivity loss) and frequency response, shows 20% of DNP worth from recirculation, and agrees with high-fidelity Serpent-2/CFD calculations for EVOL MSFR. Most impact occurs when core/ex-core residence times are comparable.", "conclusion": "The residence-time approach provides a computationally efficient yet versatile tool for sensitivity studies and developing physical intuition about CFR behavior, with potential for extensions to importance weighting and time-domain analysis."}}
{"id": "2509.08158", "pdf": "https://arxiv.org/pdf/2509.08158", "abs": "https://arxiv.org/abs/2509.08158", "authors": ["Tony Wong", "Shingyu Leung", "Byungjoon Lee"], "title": "The Closest Point Heat Method for Solving Eikonal Equations on Implicit Surfaces", "categories": ["math.NA", "cs.NA", "58J05, 65M06, 65M20, 65N06, 65N40, 65D18"], "comment": null, "summary": "We introduce the Closest Point Heat Method (CPHM), a novel approach for\nsolving the surface Eikonal equation on general smooth surfaces. Building on\nthe strengths of the classical heat method, such as simplicity of\nimplementation and computational efficiency, CPHM integrates closest point\ntechniques to reduce dependence on surface meshes. This embedding framework\nnaturally extends the heat method to implicit surfaces while preserving both\nits efficiency and intrinsic geometric properties. Numerical experiments on\nbenchmark geometries confirm the accuracy and convergence of the proposed\nmethod and demonstrate its effectiveness on complex shapes.", "AI": {"tldr": "CPHM is a novel method that combines the heat method with closest point techniques to solve surface Eikonal equations on smooth surfaces, reducing mesh dependence while maintaining efficiency.", "motivation": "To extend the classical heat method to implicit surfaces while preserving its simplicity and computational efficiency, reducing dependence on surface meshes.", "method": "Integrates closest point techniques with the classical heat method framework, using an embedding approach to handle implicit surfaces while maintaining intrinsic geometric properties.", "result": "Numerical experiments on benchmark geometries confirm the method's accuracy, convergence, and effectiveness on complex shapes.", "conclusion": "CPHM successfully extends the heat method to implicit surfaces while preserving efficiency and geometric properties, demonstrating practical utility for complex geometries."}}
{"id": "2509.08111", "pdf": "https://arxiv.org/pdf/2509.08111", "abs": "https://arxiv.org/abs/2509.08111", "authors": ["Lia Bronsard", "\u00c9tienne Sandier", "Peter Sternberg"], "title": "Minimizing solutions of degenerate Allen-Cahn equations with three wells in $\\mathbb{R}^2$", "categories": ["math.AP", "49, 35"], "comment": null, "summary": "We characterize all minimizers of the vector-valued Allen-Cahn equation in\n$\\mathbb{R}^2$ under the assumption that the potential $W$ has three wells and\nthat the associated degenerate metric does not satisfy the usual strict\ntriangle inequality. These minimizers depend on one variable only in a suitable\ncoordinate system.\n  In particular, we show that no minimizing solutions to $ \\Delta u=\\nabla\nW(u)$ on $\\mathbb{R}^2$ can approach the three distinct values of the potential\nwells.", "AI": {"tldr": "Characterization of minimizers for vector-valued Allen-Cahn equation in R\u00b2 with three-well potential, showing they depend on one variable and cannot approach all three distinct potential well values.", "motivation": "To understand the behavior of minimizers in the vector-valued Allen-Cahn equation when the potential has three wells and the associated metric violates the strict triangle inequality, which is a non-standard condition in this context.", "method": "Analysis of minimizers of the vector-valued Allen-Cahn equation \u0394u = \u2207W(u) in R\u00b2, assuming W has three potential wells and the degenerate metric does not satisfy the strict triangle inequality. Using coordinate transformations to show dependence on a single variable.", "result": "All minimizers depend on only one variable in a suitable coordinate system. No minimizing solutions can approach all three distinct values of the potential wells simultaneously.", "conclusion": "The study reveals fundamental constraints on minimizer behavior in multi-well potential systems, showing that under these specific metric conditions, solutions are effectively one-dimensional and cannot connect all three potential wells."}}
{"id": "2509.08063", "pdf": "https://arxiv.org/pdf/2509.08063", "abs": "https://arxiv.org/abs/2509.08063", "authors": ["David Dubois", "Alexander W. Raymond", "Ella Sciamma-O'Brien", "Farid Salama"], "title": "Modeling Low-Temperature Plasmas Simulating Titan's Atmosphere", "categories": ["physics.plasm-ph", "astro-ph.EP", "astro-ph.IM"], "comment": "50 pages, 13 figures, 4 tables, accepted for publication in the\n  Planetary Science Journal", "summary": "In the study presented here, we model the gas phase chemistry induced by\nplasma discharge at low temperature (150 K) in the NASA Ames COSmIC Simulation\nChamber (COSmIC) using a 1-dimensional multi-fluid plasma model named CO-PRISM\n(COSmIC Plasma Reactivity and Ionization Simulation Model). Our model\nincorporates an extensive chemical reaction network to simulate the\nneutral-neutral and ion-neutral reactions occurring in the COSmIC experiments\nwhen using N2-CH4-based gas mixtures relevant to Titan's atmosphere. Our\nreaction network now includes crucial reactions involving the first\nelectronically-excited state of atomic nitrogen, recent electron collision\ncross-sections, and radical chemistry. In particular, we have investigated the\ninfluence of C2H2 on the gas phase polymeric growth and the elemental\ncomposition of the chemical products, and we have compared our findings to\nrecently published solid phase analyses. The modeling results are consistent\nwith experimental measurements of N2-CH4-C2H2 plasmas on COSmIC, showing the\nproduction of C6Hx intermediates and precursors of larger organics, as well as\nmethanimine in small concentration. Our numerical results point to cationic\npathways enabling efficient intermediate-sized and nitrogen-rich\n\\ce{C2H2}-driven chemistry driving tholin production. Comparison of the modeled\ngas phase elemental composition with elemental composition of the solid phase\nsamples produced in COSmIC reveal similar trends, with C/N increasing when C2H2\nis present in the gas mixture. Finally, our results demonstrate the importance\nof such synergistic studies using low-temperature plasma chemistry experiments\ncombined with modeling efforts to improve our understanding of cold planetary\nenvironments.", "AI": {"tldr": "Modeling plasma-induced gas phase chemistry in Titan-like N2-CH4-C2H2 mixtures using CO-PRISM, showing cationic pathways drive tholin production with C2H2 enhancing C/N ratios.", "motivation": "To understand gas phase chemistry in cold planetary environments like Titan using plasma discharge simulations, particularly investigating how C2H2 influences polymeric growth and elemental composition.", "method": "Used 1D multi-fluid plasma model (CO-PRISM) with extensive chemical reaction network including neutral-neutral, ion-neutral reactions, excited nitrogen states, and updated electron collision cross-sections for N2-CH4-C2H2 mixtures.", "result": "Model consistent with COSmIC experiments: produced C6Hx intermediates, methanimine, and showed cationic pathways enable efficient nitrogen-rich tholin production. C2H2 presence increases C/N ratio in both gas and solid phases.", "conclusion": "Synergistic low-temperature plasma experiments combined with modeling are crucial for understanding cold planetary chemistry, particularly Titan's atmospheric processes and tholin formation mechanisms."}}
{"id": "2509.08073", "pdf": "https://arxiv.org/pdf/2509.08073", "abs": "https://arxiv.org/abs/2509.08073", "authors": ["Roberto Riganti", "Matteo G. C. Alasio", "Enrico Bellotti", "Luca Dal Negro"], "title": "DDNet: A Unified Physics-Informed Deep Learning Framework for Semiconductor Device Modeling", "categories": ["physics.comp-ph", "cond-mat.dis-nn"], "comment": null, "summary": "The accurate modeling of semiconductor devices plays a critical role in the\ndevelopment of new technology nodes and next-generation devices. Semiconductor\ndevice designers largely rely on advanced simulation software to solve the\ndrift-diffusion equations, a coupled system of nonlinear partial differential\nequations that describe carrier transport in semiconductor devices. While these\ntools perform well for forward modeling, they are not suitable to address\ninverse problems, for example, determining doping profiles, material, and\ngeometrical parameters given a desired device performance. Meanwhile,\nphysics-informed neural networks (PINNs) have grown in popularity in recent\nyears thanks to their ability to efficiently and accurately solve inverse\nproblems at minimal computational cost compared to forward problems. In this\nstudy, we introduce the Drift-Diffusion Network (DDNet), a unified\nphysics-informed deep learning solver for the forward and inverse mesh-free\nsolutions of the drift-diffusion equations of semiconductor device modeling.\nUsing prototypical device configurations in one- and two spatial dimensions, we\nshow that DDNet achieves low absolute and relative error compared to\ntraditional simulation software while additionally solving user-defined inverse\nproblems with minimal computational overhead. We expect that DDNet will benefit\nsemiconductor device modeling by facilitating exploration and discovery of\nnovel device structures across comprehensive parameter sets in a fully\nautomated way.", "AI": {"tldr": "DDNet is a physics-informed neural network that solves both forward and inverse drift-diffusion equations for semiconductor device modeling with high accuracy and minimal computational overhead.", "motivation": "Traditional semiconductor simulation tools are good for forward modeling but unsuitable for inverse problems like determining doping profiles and material parameters from desired device performance.", "method": "Developed Drift-Diffusion Network (DDNet) - a unified physics-informed deep learning solver for mesh-free solutions of drift-diffusion equations in 1D and 2D device configurations.", "result": "DDNet achieves low absolute and relative error compared to traditional simulation software while solving inverse problems with minimal computational overhead.", "conclusion": "DDNet will benefit semiconductor device modeling by enabling automated exploration and discovery of novel device structures across comprehensive parameter sets."}}
{"id": "2509.08192", "pdf": "https://arxiv.org/pdf/2509.08192", "abs": "https://arxiv.org/abs/2509.08192", "authors": ["Gengchen Li", "Hongwei Lin"], "title": "Collocation and Mass Matrix in Least-squares Isogeometric Analysis", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we conduct a systematic numerical analysis of the spectral\nproperties of the collocation and mass matrices in the isogeometric\nleast-squares collocation method (IGA-L), for the approximation of the Poisson\nproblem with homogeneous Dirichlet boundary conditions. This study primarily\nfocuses on the spectral properties of the IGA-L collocation and mass matrices\nin relation to the isogeometric discretization parameters, such as the mesh\nsize, degree, regularity, spatial dimension, and the number and distribution of\nthe collocation points. Through a comprehensive numerical investigation, we\nprovide estimations for the condition number, as well as the maximum and\nminimum singular values, in relation to the mesh size, degree and regularity.\nMoreover, in this paper we also study the effect of the number and distribution\nof the collocation points on the spectral properties of the collocation matrix,\nproviding insights into the optimization of the collocation points for\nachieving better-conditioned linear systems.", "AI": {"tldr": "Numerical analysis of spectral properties of collocation and mass matrices in isogeometric least-squares collocation method for Poisson problem, focusing on condition number and singular values in relation to discretization parameters.", "motivation": "To systematically analyze the spectral properties of IGA-L collocation and mass matrices to understand how discretization parameters affect matrix conditioning and system stability.", "method": "Comprehensive numerical investigation examining spectral properties in relation to mesh size, degree, regularity, spatial dimension, and collocation point distribution.", "result": "Provides estimations for condition number, maximum and minimum singular values relative to mesh size, degree, and regularity parameters.", "conclusion": "The study offers insights into optimizing collocation point distribution to achieve better-conditioned linear systems in isogeometric least-squares collocation methods."}}
{"id": "2509.08168", "pdf": "https://arxiv.org/pdf/2509.08168", "abs": "https://arxiv.org/abs/2509.08168", "authors": ["Jan Burczak", "Antonio Hidalgo-Torn\u00e9"], "title": "Pathological solutions of Navier-Stokes equations on $\\mathbb{T}^2$ with gradients in Hardy spaces", "categories": ["math.AP", "math.FA"], "comment": null, "summary": "For an arbitrary smooth initial datum, we construct multiple nonzero\nsolutions to the $2$d Navier-Stokes equations, with their gradients in the\nHardy space $\\mathcal{H}^p$ with any $p \\in (0,1)$. Thus, in terms of the path\nspace $C(\\mathcal{H}^p)$ for vorticity, $p=1$ is the threshold value\ndistinguishing between non-uniqueness and uniqueness regimes. In order to\nobtain our result, we develop the needed theory of Hardy spaces on periodic\ndomains.", "AI": {"tldr": "Construction of multiple nonzero solutions to 2D Navier-Stokes equations with vorticity gradients in Hardy space H^p for p<1, establishing p=1 as uniqueness threshold.", "motivation": "To understand the uniqueness/non-uniqueness regimes for 2D Navier-Stokes equations in terms of vorticity path space regularity, specifically identifying the critical threshold in Hardy spaces.", "method": "Developed theory of Hardy spaces on periodic domains and constructed multiple solutions with vorticity gradients in H^p for p in (0,1) from arbitrary smooth initial data.", "result": "Demonstrated that p=1 is the critical threshold value distinguishing between non-uniqueness (p<1) and uniqueness regimes in the path space C(H^p) for vorticity.", "conclusion": "The study establishes a precise regularity threshold for solution uniqueness in 2D Navier-Stokes equations, with Hardy space H^1 serving as the boundary between unique and non-unique solution behavior."}}
{"id": "2509.08081", "pdf": "https://arxiv.org/pdf/2509.08081", "abs": "https://arxiv.org/abs/2509.08081", "authors": ["Haomin Sun", "Jian Chen", "Alexander Khrabrov", "Igor D. Kaganovich", "Wei Yang", "Dmytro Sydorenko", "Stephan Brunner"], "title": "Particle-In-Cell Informed Kinetic Modeling of Nonlinear Skin Effects in Low-Frequency Inductively Coupled Plasmas", "categories": ["physics.plasm-ph"], "comment": null, "summary": "We perform extensive 2D Particle-In-Cell (PIC) electromagnetic simulations of\nlow pressure Inductively Coupled Plasma (ICP) discharges with various coil\ncurrent and driving frequencies. Our simulations show that in low-frequency\ncases, electrons in the skin region near the coil can be predominantly\nmagnetized by the Radio Frequency (RF) magnetic field. More specifically, the\nelectrons are trapped in the combined potential well formed by the vector and\nelectrostatic potentials, where they oscillate for most of the RF period while\ndrifting perpendicular to the RF magnetic field. When the magnetic field\nweakens, electrons shortly demagnetize, leading to jet-like currents and\nperiodic bursts of energy deposition. Based on the newly discovered electron\ntrajectories, we develop a new kinetic theory for the plasma skin effect in\nlow-frequency Inductively Coupled Plasma (ICP) discharges, incorporating\nnonlinear electron motion in an RF magnetic field by integrating Vlasov\nequation along the unperturbed particle trajectory. This theory successfully\npredicts the time evolution of electron currents in low-frequency ICP plasmas,\nas well as a nonlinear relation between electron current and the RF inductive\nelectric field in the new regime we found. Furthermore, by coupling this new\nkinetic theory with a global model, we provide a straightforward method for\nestimating equilibrium electron temperature, plasma density and electron\ncurrent. These analytical predictions match well with our 2D PIC simulations\nand can be validated through future experimental studies.", "AI": {"tldr": "New kinetic theory for low-frequency ICP discharges reveals electron trapping in RF magnetic fields, predicting jet-like currents and periodic energy bursts, validated by 2D PIC simulations.", "motivation": "To understand electron behavior in low-frequency inductively coupled plasma discharges and develop a predictive theory for electron currents and energy deposition.", "method": "Extensive 2D Particle-In-Cell electromagnetic simulations combined with development of new kinetic theory integrating Vlasov equation along unperturbed particle trajectories, coupled with global modeling.", "result": "Discovery of electron trapping in combined vector/electrostatic potential wells, jet-like currents, periodic energy bursts, and successful prediction of electron current evolution and nonlinear current-field relationships.", "conclusion": "The new kinetic theory provides accurate predictions for low-frequency ICP behavior and offers straightforward methods for estimating key plasma parameters, with good agreement to simulations and potential for experimental validation."}}
{"id": "2509.08223", "pdf": "https://arxiv.org/pdf/2509.08223", "abs": "https://arxiv.org/abs/2509.08223", "authors": ["Bugra Yalcin", "Ishan Nadkarni", "Jinu Jeong", "Chenxing Liang", "Narayana R. Aluru"], "title": "Generative Quasi-Continuum Modeling of Confined Fluids at the Nanoscale", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "We present a data-efficient, multiscale framework for predicting the density\nprofiles of confined fluids at the nanoscale. While accurate density estimates\nrequire prohibitively long timescales that are inaccessible by ab initio\nmolecular dynamics (AIMD) simulations, machine-learned molecular dynamics\n(MLMD) offers a scalable alternative, enabling the generation of force\npredictions at ab initio accuracy with reduced computational cost. However,\ndespite their efficiency, MLMD simulations remain constrained by femtosecond\ntimesteps, which limit their practicality for computing long-time averages\nneeded for accurate density estimation. To address this, we propose a\nconditional denoising diffusion probabilistic model (DDPM) based\nquasi-continuum approach that predicts the long-time behavior of force profiles\nalong the confinement direction, conditioned on noisy forces extracted from a\nlimited AIMD dataset. The predicted smooth forces are then linked to continuum\ntheory via the Nernst-Planck equation to reveal the underlying density\nbehavior. We test the framework on water confined between two graphene\nnanoscale slits and demonstrate that density profiles for channel widths\noutside of the training domain can be recovered with ab initio accuracy.\nCompared to AIMD and MLMD simulations, our method achieves orders-of-magnitude\nspeed-up in runtime and requires significantly less training data than prior\nworks.", "AI": {"tldr": "A multiscale framework using conditional diffusion models to predict nanoscale confined fluid density profiles with ab initio accuracy but orders-of-magnitude faster than traditional methods.", "motivation": "Accurate density estimation for confined fluids requires prohibitively long AIMD simulations, and while MLMD offers better scalability, it's still constrained by femtosecond timesteps limiting practical long-time averaging.", "method": "Conditional denoising diffusion probabilistic model (DDPM) that predicts long-time force profiles from noisy AIMD data, coupled with continuum theory via Nernst-Planck equation to derive density behavior.", "result": "Successfully predicts density profiles for water confined in graphene slits outside training domain with ab initio accuracy, achieving orders-of-magnitude speed-up over AIMD/MLMD with significantly less training data.", "conclusion": "The proposed quasi-continuum approach provides an efficient and data-effective solution for predicting nanoscale confined fluid behavior, bridging molecular dynamics with continuum theory for practical applications."}}
{"id": "2509.08410", "pdf": "https://arxiv.org/pdf/2509.08410", "abs": "https://arxiv.org/abs/2509.08410", "authors": ["Zhihui Liu", "Xiaojie Wang", "Xiaoming Wu", "Xiaoyan Zhang"], "title": "Non-asymptotic Error Analysis of Explicit Modified Euler Methods for Superlinear and Non-contractive SODEs", "categories": ["math.NA", "cs.NA", "60H35, 37M25, 65C30"], "comment": "26 pages, 0 figue", "summary": "A family of explicit modified Euler methods (MEMs) is constructed for\nlong-time approximations of super-linear SODEs driven by multiplicative noise.\nThe proposed schemes can preserve the same Lyapunov structure as the continuous\nproblems. Under a non-contractive condition, we establish a non-asymptotic\nerror bound between the law of the numerical approximation and the target\ndistribution in Wasserstein-1 ($\\mathcal{W}_1$) distance through a\ntime-independent weak convergence rate for the proposed schemes. As a\nby-product of this weak error estimate, we obtain an $\\mathcal{O}(\\tau|\\ln\n\\tau|)$ convergence rate between the exact and numerical invariant measures.", "AI": {"tldr": "A family of explicit modified Euler methods for super-linear SODEs with multiplicative noise that preserves Lyapunov structure and achieves time-independent weak convergence rates.", "motivation": "To develop numerical methods for long-time approximations of super-linear stochastic differential equations with multiplicative noise that can preserve the same stability properties as the continuous system.", "method": "Construction of explicit modified Euler methods (MEMs) that preserve Lyapunov structure, with analysis under non-contractive conditions to establish non-asymptotic error bounds in Wasserstein-1 distance.", "result": "Achieved time-independent weak convergence rate and obtained O(\u03c4|ln \u03c4|) convergence rate between exact and numerical invariant measures.", "conclusion": "The proposed modified Euler methods provide effective long-time approximations for super-linear SODEs with multiplicative noise while preserving stability properties and achieving good convergence rates."}}
{"id": "2509.08212", "pdf": "https://arxiv.org/pdf/2509.08212", "abs": "https://arxiv.org/abs/2509.08212", "authors": ["Geng Lai"], "title": "Two-dimensional steady supersonic ramp flows of Bethe-Zel'dovich-Thompson fluids", "categories": ["math.AP"], "comment": "55 pages, 16 figures", "summary": "Two-dimensional steady supersonic ramp flows are important and well-studied\nflow patterns in aerodynamics. Vimercati, Kluwick and Guardone [J. Fluid Mech.,\n885 (2018) 445--468] constructed various self-similar composite wave solutions\nto the supersonic flow of Bethe-Zel'dovich-Thompson (BZT) fluids past\ncompressible and rarefactive ramps. We study the stabilities of the\nself-similar fan-shock-fan and shock-fan-shock composite waves constructed by\nVimercati et al. in that paper. %In order to study the stabilities of the\ncomposite waves, we solve some classes of shock free boundary problems. In\ncontrast to ideal gases, the flow downstream (or upstream) of a shock of a BZT\nfluid may possibly be sonic in the sense of the flow velocity relative to the\nshock front. In order to study the stabilities of the composite waves, we\nestablish some a priori estimates about the type of the shocks and solve some\nclasses of sonic shock free boundary problems. We find that the sonic shocks\nare envelopes of one out of the two families of wave characteristics, and not\ncharacteristics. This results in a fact that the flow downstream (or upstream)\na sonic shock is not $C^1$ smooth up to the shock boundary. We use a\ncharacteristic decomposition method and a hodograph transformation method to\novercome the difficulty cased by the singularity on sonic shocks, and derive\nseveral groups of structural conditions to establish the existence of curved\nsonic shocks.", "AI": {"tldr": "Analysis of stability of self-similar composite wave solutions in supersonic ramp flows of BZT fluids, focusing on sonic shocks and their unique properties compared to ideal gases.", "motivation": "To study the stability of self-similar fan-shock-fan and shock-fan-shock composite waves in supersonic BZT fluid flows, which exhibit different behavior from ideal gases due to sonic shock properties.", "method": "Established a priori estimates about shock types, solved sonic shock free boundary problems, used characteristic decomposition and hodograph transformation methods to handle sonic shock singularities, and derived structural conditions for curved sonic shocks.", "result": "Found that sonic shocks in BZT fluids are envelopes of wave characteristics rather than characteristics themselves, resulting in non-C^1 smooth flow at shock boundaries, and successfully established existence conditions for curved sonic shocks.", "conclusion": "The study provides stability analysis and mathematical framework for understanding composite wave solutions in BZT fluid flows, overcoming challenges posed by sonic shock singularities through advanced transformation methods."}}
{"id": "2509.08098", "pdf": "https://arxiv.org/pdf/2509.08098", "abs": "https://arxiv.org/abs/2509.08098", "authors": ["I. Y. Dodin", "N. A. Lopez", "Tingjing Xing", "Rune H\u00f8jlund Marholt", "Valerian H. Hall-Chen"], "title": "Geometrical optics in phase space", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Geometrical optics (GO) is widely used for reduced modeling of waves in\nplasmas but fails near reflection points, where it predicts a spurious\nsingularity of the wave amplitude. We show how to avoid this singularity by\nadopting a different representation of the wave equation. Instead of the\nphysical space $x$ and the wavevector $k$, we use the ray time $\\tau$ as the\nnew canonical coordinate and the ray energy $h$ as the associated canonical\nmomentum. To derive the envelope equation in the $\\tau$-representation, we\nconstruct the Weyl symbol calculus on the $(\\tau, h)$ space and show that the\ncorresponding Weyl symbols are related to their $(x, k)$ counterparts by the\nAiry transform. This allows us to express the coefficients in the envelope\nequation through the known properties of the original dispersion operator. When\nnecessary, solutions of this equation can be mapped to the $x$-space using a\ngeneralised metaplectic transform. But the field per se might not even be\nneeded in practice. Instead, knowing the corresponding Wigner function usually\nsuffices for linear and quasilinear calculations. As a Weyl symbol itself, the\nWigner function can be mapped analytically, using the aforementioned Airy\ntransform. We show that the standard Airy patterns that form in regions where\nconventional GO fails are successfully reproduced within MGO simply by\nremapping the field from the $\\tau$-space to the $x$-space. An extension to\nmode-converting waves is also presented. This formulation, which we call\ngeneralised metaplectic GO (MGO) offers a promising tool, for example, for\nreduced modeling of the O--X conversion in inhomogeneous plasma near the\ncritical density, an effect that is important for fusion applications and also\noccurs in the ionosphere. Aside from better handling reflection, MGO is similar\nto GO and can replace it for any practical purposes.", "AI": {"tldr": "MGO (generalised metaplectic GO) overcomes the amplitude singularity issue in traditional geometrical optics near reflection points by using ray time and energy as canonical coordinates instead of physical space and wavevector.", "motivation": "Traditional geometrical optics fails near reflection points where it predicts spurious singularities in wave amplitude, limiting its practical applications in plasma wave modeling.", "method": "Uses ray time \u03c4 as canonical coordinate and ray energy h as canonical momentum. Constructs Weyl symbol calculus on (\u03c4, h) space with Airy transform to relate to (x, k) counterparts. Derives envelope equation and maps solutions using generalized metaplectic transform.", "result": "Successfully reproduces standard Airy patterns in regions where conventional GO fails. Eliminates amplitude singularity problem at reflection points.", "conclusion": "MGO offers a promising tool for reduced modeling of wave phenomena in plasmas, particularly for O-X conversion near critical density, and can replace traditional GO for practical purposes with better reflection handling."}}
{"id": "2509.08765", "pdf": "https://arxiv.org/pdf/2509.08765", "abs": "https://arxiv.org/abs/2509.08765", "authors": ["Mikhail Khodak", "Min Ki Jung", "Brian Wynne", "Edmond chow", "Egemen Kolemen"], "title": "PCGBandit: One-shot acceleration of transient PDE solvers via online-learned preconditioners", "categories": ["physics.comp-ph", "cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": "25 pages, 11 figures", "summary": "Data-driven acceleration of scientific computing workflows has been a\nhigh-profile aim of machine learning (ML) for science, with numerical\nsimulation of transient partial differential equations (PDEs) being one of the\nmain applications. The focus thus far has been on methods that require\nclassical simulations to train, which when combined with the data-hungriness\nand optimization challenges of neural networks has caused difficulties in\ndemonstrating a convincing advantage against strong classical baselines. We\nconsider an alternative paradigm in which the learner uses a classical solver's\nown data to accelerate it, enabling a one-shot speedup of the simulation.\nConcretely, since transient PDEs often require solving a sequence of related\nlinear systems, the feedback from repeated calls to a linear solver such as\npreconditioned conjugate gradient (PCG) can be used by a bandit algorithm to\nonline-learn an adaptive sequence of solver configurations (e.g.\npreconditioners). The method we develop, PCGBandit, is implemented directly on\ntop of the popular open source software OpenFOAM, which we use to show its\neffectiveness on a set of fluid and magnetohydrodynamics (MHD) problems.", "AI": {"tldr": "PCGBandit - a bandit algorithm that learns adaptive solver configurations from linear solver feedback to accelerate PDE simulations in one-shot without requiring classical simulation training data.", "motivation": "Traditional ML approaches for accelerating scientific computing require classical simulations for training and face data-hungriness issues. The paper proposes an alternative paradigm where the solver's own data is used for real-time acceleration.", "method": "Uses a bandit algorithm to online-learn adaptive solver configurations (preconditioners) from feedback during repeated calls to preconditioned conjugate gradient (PCG) solver when solving sequences of related linear systems in transient PDEs.", "result": "Implemented on OpenFOAM and demonstrated effectiveness on fluid and magnetohydrodynamics (MHD) problems, showing one-shot speedup of simulations.", "conclusion": "PCGBandit provides a practical alternative to data-hungry ML methods by enabling real-time acceleration of PDE simulations using the solver's own feedback data, with successful implementation on industry-standard OpenFOAM software."}}
{"id": "2509.08413", "pdf": "https://arxiv.org/pdf/2509.08413", "abs": "https://arxiv.org/abs/2509.08413", "authors": ["Yunchuan Wu", "Xiuzheng Cheng", "Yi Duan", "Linsen Zhang", "Qin Li", "Pan Yan", "Mengyu Wang"], "title": "Accuracy analysis and optimization of scale-independent third-order WENO-Z scheme with critical-point accuracy preservation", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "comment": null, "summary": "To address the order degradation at critical points in the WENO3-Z scheme,\nsome improvements have been proposed , but these approaches generally fail to\nconsider the occurrence of critical points at arbitrary positions within grid\nintervals, resulting in their inability to maintain third-order accuracy when a\nfirst-order critical point (CP1) occurs. Also, most previous improved schemes\nsuffer from a relatively large exponent p of the ratio of global to local\nsmoothness indicators, which adversely affects the numerical resolution.\nConcerning these limitations, introduced here is an accuracy-optimization lemma\ndemonstrating that the accuracy of nonlinear weights can be enhanced providing\nthat smoothness indicators satisfy specific conditions, thereby establishing a\nmethodology for elevating the accuracy of nonlinear weights. Leveraging this\nlemma, a local smoothness indicator is constructed with error terms achieving\nsecond-order in smooth regions and fourth-order at CP1, alongside a global\nsmoothness indicator yielding fourth-order accuracy in smooth regions and\nfifth-order at CP1, enabling the derivation of new nonlinear weights that meet\naccuracy requirements even when employing p=1. Furthermore, a\nresolution-optimization lemma is proposed to analyze the relationship between\nparameters in local smoothness indicators and resolution. By integrating\ntheoretical analysis with numerical practices, free parameters in\nnon-normalized weights and local smoothness indicators are determined under the\nbalance of numerical resolution and robustness, which leads to the development\nof WENO3-ZES4, a new WENO3-Z improvement that preserves the optimal order at\nCP1 especially with p=1. 1D and 2D validating tests show that the new scheme\nconsistently achieves third-order in the case of CP1 regardless of its position\nand exhibits good resolution as well as preferable robustness.", "AI": {"tldr": "A new WENO3-ZES4 scheme is developed that maintains third-order accuracy at first-order critical points regardless of their position, using optimized smoothness indicators and p=1 parameter for better resolution.", "motivation": "To address limitations in existing WENO3-Z schemes that fail to maintain third-order accuracy when first-order critical points occur at arbitrary grid positions and suffer from poor numerical resolution due to large exponent parameters.", "method": "Developed an accuracy-optimization lemma to enhance nonlinear weights accuracy, constructed local and global smoothness indicators with specific error orders, and used a resolution-optimization lemma to determine optimal parameters balancing resolution and robustness.", "result": "The WENO3-ZES4 scheme consistently achieves third-order accuracy at first-order critical points regardless of position, shows good numerical resolution, and maintains preferable robustness in 1D and 2D validation tests.", "conclusion": "The proposed WENO3-ZES4 scheme successfully overcomes order degradation at critical points while maintaining good resolution and robustness, representing a significant improvement over previous WENO3-Z approaches."}}
{"id": "2509.08271", "pdf": "https://arxiv.org/pdf/2509.08271", "abs": "https://arxiv.org/abs/2509.08271", "authors": ["Yong Lu", "Fangzheng Huang"], "title": "Error estimates in the non-relativistic limit for the two-dimensional cubic Klein-Gordon equation", "categories": ["math.AP"], "comment": "29 pages", "summary": "In this paper, we study the non-relativistic limit of the two-dimensional\ncubic nonlinear Klein-Gordon equation with a small parameter $0<\\varepsilon \\ll\n1$ which is inversely proportional to the speed of light. We show the cubic\nnonlinear Klein-Gordon equation converges to the cubic nonlinear\nSchr\\\"{o}dinger equation with a convergence rate of order $O(\\varepsilon^2)$.\nIn particular, for the defocusing case with high regularity initial data, we\nshow error estimates of the form $C(1+t)^N \\varepsilon^2$ at time $t$ up to a\nlong time of order $\\varepsilon^{-\\frac{2}{N+1}}$, while for initial data with\nlimited regularity, we also show error estimates of the form\n$C(1+t)^M\\varepsilon$ at time $t$ up to a long time of order\n$\\varepsilon^{-\\frac{1}{M+1}}$. Here $N$ and $M$ are constants depending on\ninitial data. The idea of proof is to reformulate nonrelativistic limit\nproblems to stability problems in geometric optics, then employ the techniques\nin geometric optics to construct approximate solutions up to an arbitrary\norder, and finally, together with the decay estimates of the cubic\nSchr\\\"{o}dinger equation, derive the error estimates.", "AI": {"tldr": "Study of non-relativistic limit of 2D cubic nonlinear Klein-Gordon equation showing convergence to cubic nonlinear Schr\u00f6dinger equation with rate O(\u03b5\u00b2) for small parameter \u03b5.", "motivation": "To understand the relationship between relativistic (Klein-Gordon) and non-relativistic (Schr\u00f6dinger) quantum mechanical descriptions by examining their convergence behavior in the non-relativistic limit.", "method": "Reformulate nonrelativistic limit problems as stability problems in geometric optics, construct approximate solutions to arbitrary order using geometric optics techniques, and combine with decay estimates of cubic Schr\u00f6dinger equation.", "result": "For defocusing case with high regularity initial data: error estimates C(1+t)^N \u03b5\u00b2 up to time \u03b5^{-\u2154/(N+1)}. For limited regularity initial data: error estimates C(1+t)^M\u03b5 up to time \u03b5^{-\u2153/(M+1)}.", "conclusion": "The cubic nonlinear Klein-Gordon equation converges to the cubic nonlinear Schr\u00f6dinger equation in the non-relativistic limit with proven convergence rates and long-time validity estimates."}}
{"id": "2509.08106", "pdf": "https://arxiv.org/pdf/2509.08106", "abs": "https://arxiv.org/abs/2509.08106", "authors": ["Mart\u00edn A. Quijada", "Pablo S. Moya", "Roberto E. Navarro"], "title": "Proton-Acoustic Wave Effects on the Relaxation of Proton Transverse Heating in Magnetized Plasmas", "categories": ["physics.plasm-ph"], "comment": "19 pages, 5 figures, sent to Physica Scripta", "summary": "Transverse electromagnetic and electrostatic plasma wave modes propagating\nalong a background magnetic field $\\vec{B}_0$ are independent according to\nlinear kinetic theory. However, resonant interactions and energy exchange\nbetween waves and particles break this linear decoupling. This work tracks the\ncoupled evolution of Alfv\\'en-cyclotron (ACWs) and Ion-acoustic waves (IAWs) by\nsolving moment-based quasilinear equations for a collisionless plasma of\nbi-Maxwellian protons and Maxwellian electrons. Unlike earlier quasilinear\nstudies that adopt the cold-electron limit, our formulation retains the full\nkinetic response of both species, treating the electrons as a thermal reservoir\nto isolate proton heating. A parameter survey over $0.01\\leq\\beta_{\\parallel\np}\\leq10$ and $1\\le T_e/T_p\\le10$ shows that an ambient spectrum of ACWs can\ndrive significant perpendicular proton heating and raise the temperature\nanisotropy from initially isotropic conditions at low $\\beta_{\\parallel\np}\\lesssim0.1$, thereby triggering cyclotron instabilities. The quasilinear\nevolution self-regulates the ACW, driving the system toward a quasi-stationary\nstate with $\\gamma/\\Omega_p<10^{-1}$ and reduced anisotropy. As $T_e/T_p$\nincreases, IAWs become less damped and absorb a larger share of the fluctuation\nenergy through Landau resonance, reducing the efficiency of ACW-driven proton\nheating and thus regulating the instability. For sufficiently large\n$\\beta_{\\parallel p}$ or $T_e/T_p\\gtrsim5$, ACWs become inefficient drivers of\nperpendicular heating, leaving IAWs as the dominant dissipation channel. These\nresults explain how modest electrostatic activity in low-$\\beta$ environments\nsuch as the inner heliosphere and planetary magnetosheaths can regulate, but\nnot indefinitely sustain, cyclotron instabilities.", "AI": {"tldr": "Quasilinear analysis shows Alfv\u00e9n-cyclotron waves can drive proton heating and trigger cyclotron instabilities, but ion-acoustic waves regulate this process by absorbing energy through Landau damping, especially at higher electron-to-proton temperature ratios.", "motivation": "To understand how resonant wave-particle interactions break the linear decoupling between transverse electromagnetic and electrostatic plasma waves, and to track the coupled evolution of Alfv\u00e9n-cyclotron and ion-acoustic waves in collisionless plasmas.", "method": "Solving moment-based quasilinear equations for collisionless plasma with bi-Maxwellian protons and Maxwellian electrons, retaining full kinetic response of both species and treating electrons as thermal reservoir to isolate proton heating. Parameter survey over \u03b2\u2225p (0.01-10) and Te/Tp (1-10).", "result": "ACWs drive significant perpendicular proton heating and raise temperature anisotropy at low \u03b2\u2225p, triggering cyclotron instabilities. System self-regulates toward quasi-stationary state. As Te/Tp increases, IAWs absorb more energy through Landau resonance, reducing ACW-driven proton heating efficiency. For large \u03b2\u2225p or Te/Tp \u2265 5, IAWs become dominant dissipation channel.", "conclusion": "Modest electrostatic activity in low-\u03b2 environments regulates but cannot indefinitely sustain cyclotron instabilities, explaining wave behavior in inner heliosphere and planetary magnetosheaths."}}
{"id": "2509.08131", "pdf": "https://arxiv.org/pdf/2509.08131", "abs": "https://arxiv.org/abs/2509.08131", "authors": ["Luke K. Davis", "Karel Proesmans"], "title": "Insertion space in repulsive active matter", "categories": ["cond-mat.soft", "cond-mat.stat-mech", "physics.chem-ph", "physics.comp-ph"], "comment": "5 pages main text, 4 main figures, 9 pages total, 8 figures total", "summary": "For equilibrium hard spheres the stochastic geometry of the insertion space,\nthe room to accommodate another sphere, relates exactly to the equation of\nstate. We begin to extend this idea to active matter, analyzing insertion space\nfor repulsive active particles in one and two dimensions using both on- and\noff-lattice models. In 1D we derive closed-form expressions for the mean\ninsertion cavity size, cavity number, and total insertion volume, all in\nexcellent agreement with simulations. Strikingly, activity increases the total\ninsertion volume and tends to keep the insertion space more connected. These\nresults provide the first quantitative foundation for the stochastic geometry\nof active matter, and opens up a new route to building a thermodynamics of\nactive systems.", "AI": {"tldr": "Active matter insertion space analysis shows activity increases total insertion volume and connectivity, providing foundation for active matter thermodynamics.", "motivation": "Extend the stochastic geometry concept of insertion space from equilibrium hard spheres to active matter systems to understand how activity affects spatial organization.", "method": "Analyzed insertion space for repulsive active particles in 1D and 2D using both on- and off-lattice models. Derived closed-form expressions for mean insertion cavity size, cavity number, and total insertion volume.", "result": "Excellent agreement between derived expressions and simulations. Activity increases total insertion volume and tends to keep insertion space more connected compared to equilibrium systems.", "conclusion": "Provides first quantitative foundation for stochastic geometry of active matter and opens new route to building thermodynamics of active systems."}}
{"id": "2509.08453", "pdf": "https://arxiv.org/pdf/2509.08453", "abs": "https://arxiv.org/abs/2509.08453", "authors": ["Suprio Bhar", "Mrinmay Biswas", "Mangala Prasad"], "title": "Strong convergence of fully discrete finite element schemes for the stochastic semilinear generalized Benjamin-Bona-Mahony equation driven by additive Wiener noise", "categories": ["math.NA", "cs.NA", "math-ph", "math.AP", "math.MP", "math.PR", "60H15, 65N30, 65M60, 60H35, 65C30"], "comment": "20 pages, comments welcome!", "summary": "In this article, we have analyzed semi-discrete finite element approximation\nand full discretization of the Stochastic semilinear generalized\nBenjamin-Bona-Mahony equation in a bounded convex polygonal domain driven by\nadditive Wiener noise. We use the finite element method for spatial\ndiscretization and the semi-implicit method for time discretization and derive\na strong convergence rate with respect to both parameters (spatial and\ntemporal). Numerical experiments have also been performed to support\ntheoretical bounds.", "AI": {"tldr": "Analysis of semi-discrete and full discretization methods for Stochastic semilinear generalized Benjamin-Bona-Mahony equation with additive Wiener noise, using FEM for spatial and semi-implicit method for temporal discretization.", "motivation": "To develop and analyze numerical methods for solving stochastic semilinear generalized Benjamin-Bona-Mahony equations driven by additive Wiener noise in bounded convex polygonal domains.", "method": "Finite element method for spatial discretization and semi-implicit method for time discretization, with analysis of strong convergence rates for both spatial and temporal parameters.", "result": "Derived strong convergence rates with respect to both spatial and temporal discretization parameters, supported by numerical experiments that validate theoretical bounds.", "conclusion": "The proposed numerical methods provide effective discretization approaches for stochastic semilinear generalized Benjamin-Bona-Mahony equations with proven convergence rates and experimental validation."}}
{"id": "2509.08348", "pdf": "https://arxiv.org/pdf/2509.08348", "abs": "https://arxiv.org/abs/2509.08348", "authors": ["Yanqing Wang", "Wei Wei", "Yulin Ye"], "title": "On anisotropic energy conservation criteria of incompressible fluids", "categories": ["math.AP"], "comment": "25 pages", "summary": "In this paper, by means of divergence-free condition, we establish an\nanisotropic energy conservation class enabling one component of velocity in the\nlargest space $L^{3} (0,T; B^{1/3}_{3,\\infty})$ for the 3D inviscid\nincompressible fluids, which extends the celebrated result obtained by\nCheskidov, Constantin, Friedlander and Shvydkoy in [15, Nonlinearity 21\n(2008)]. For viscous flows, we generalize famous Lions's energy conservation\ncriteria to allow the horizontal components and vertical part of velocity to\nhave different integrability.", "AI": {"tldr": "Establishes anisotropic energy conservation criteria for 3D inviscid incompressible fluids, extending previous results by allowing one velocity component in larger space L\u00b3(0,T;B^{1/3}_{3,\u221e}). Also generalizes Lions's criteria for viscous flows with different integrability for horizontal and vertical velocity components.", "motivation": "To extend and improve existing energy conservation results for 3D incompressible fluids by leveraging divergence-free conditions and anisotropic analysis, providing more flexible and comprehensive criteria.", "method": "Uses divergence-free condition to establish anisotropic energy conservation classes. For inviscid flows, extends previous results to allow one velocity component in larger function space. For viscous flows, generalizes Lions's criteria by permitting different integrability conditions for horizontal and vertical velocity components.", "result": "Developed new anisotropic energy conservation criteria that: 1) Allow one velocity component to belong to L\u00b3(0,T;B^{1/3}_{3,\u221e}) space for inviscid 3D fluids, extending Cheskidov et al.'s result; 2) Generalize Lions's energy conservation criteria for viscous flows with different integrability requirements for horizontal vs vertical velocity components.", "conclusion": "The paper successfully establishes more flexible anisotropic energy conservation conditions for both inviscid and viscous 3D incompressible fluids, providing significant extensions to classical results and enabling different mathematical treatments for different velocity components."}}
{"id": "2509.08178", "pdf": "https://arxiv.org/pdf/2509.08178", "abs": "https://arxiv.org/abs/2509.08178", "authors": ["M. V. Umansky", "B. D. Dudson", "T. G. Jenkins", "J. R. Myra", "D. N. Smithe"], "title": "Modeling of convective cells, turbulence, and transport induced by a radio-frequency antenna in the tokamak boundary plasma", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The edge turbulence model Hermes (Dudson et al., 2017 Plasma Phys. Control.\nFusion 59 05401) is set up for plasma boundary simulations with an RF antenna,\nusing parameters characteristic of a tokamak edge. Cartesian slab geometry is\nused with thin plate limiters representing the ICRF antenna side-wall limiters.\nAd-hoc DC electric biasing of the limiters, motivated by calculations with VSim\n(Nieter et al., J. Comput. Phys. 196, 448 (2004)), represents an induced RF\nsheath rectified potential in the plasma turbulence model. Flux-driven\nturbulence simulations demonstrate a realistic distribution of plasma profiles\nand fluctuations. There is a clear effect of the antenna sheath voltage leading\nto formation of convective cells; bias-induced convective transport flattens\nthe SOL density profile and fluctuations penetrate into the shadow region of\nthe limiters as the bias voltage increases. Turbulent transport for impurity\nions is inferred by following ion trajectories in the simulated plasma\nturbulence fields, showing Bohm-like effective diffusion rates. All in all, the\nmodel elucidates the key physical phenomena governing the effects of\nICRF-induced antenna biasing on the tokamak boundary plasma.", "AI": {"tldr": "Simulation of RF antenna effects on tokamak edge plasma using Hermes turbulence model with DC biasing representing RF sheath rectification, showing convective cell formation and Bohm-like impurity transport.", "motivation": "To understand how ICRF antenna-induced sheath rectification affects tokamak boundary plasma turbulence and transport phenomena.", "method": "Used Hermes edge turbulence model with Cartesian slab geometry, thin plate limiters representing ICRF antenna side-walls, and ad-hoc DC electric biasing based on VSim calculations to represent RF sheath rectified potential.", "result": "RF sheath voltage forms convective cells, flattens SOL density profile, allows fluctuations into limiter shadow regions, and produces Bohm-like effective diffusion rates for impurity ions.", "conclusion": "The model successfully captures key physical phenomena of ICRF-induced antenna biasing effects on tokamak boundary plasma transport and turbulence."}}
{"id": "2509.08368", "pdf": "https://arxiv.org/pdf/2509.08368", "abs": "https://arxiv.org/abs/2509.08368", "authors": ["Jia-Wen Li", "Xin-Wei Yi", "Jin Zhang", "Gang Su", "Bo Gu"], "title": "Diameter-Controlled High-Order Vortex States and Magnon Hybridization in VSe2 Nanotubes", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "physics.comp-ph"], "comment": null, "summary": "Curved magnets offer a rich phase diagram and hold great promise for\nnext-generation spintronic technologies. This study establishes the paramount\nsignificance of high-order vortex states (e.g., 3$\\varphi$ with winding number\n$n$ > 1) in VSe2 nanotubes, which uniquely enable magnonic functionalities\nfundamentally inaccessible to conventional magnetic systems. These states arise\nfrom diameter-dependent competition between the nearest-neighbor ferromagnetic\n($J_1$) and longer-range antiferromagnetic ($J_2$/$J_3$) couplings, as\nrigorously validated through density-functional theory calculations and\nHeisenberg modeling of phase diagrams. Critically, by the\nLandau-Lifshitz-Gilbert equation, we find that high-order vortex configurations\nunlock an intrinsic hybridization mechanism governed by strict orbital angular\nmomentum (OAM) selection rules ($\\Delta l = \\pm 2(n-1)$) -- a process strictly\nforbidden in fundamental vortices ($n$ = 1) -- generating complex high-OAM\nmagnons with measurable topological charge. This is vividly demonstrated in the\n3$\\varphi$ state, where hybridization between $l$ = -4, 0 and 4 modes produces\neight-petal magnon density patterns. Such states provide an essential\nplatform-free solution for generating high-OAM magnons, wchich is crucial for\nspin-wave-based information transport. These findings establish a predictive\ntheoretical framework for controlling high-order vortex states in curved\nmagnets and highlight VSe2 nanotubes as a promising platform for exploring\ncomplex magnetism and developing future magnonic and spintronic devices.", "AI": {"tldr": "High-order vortex states in VSe2 nanotubes enable unique magnonic functionalities through orbital angular momentum selection rules, generating complex high-OAM magnons crucial for spin-wave information transport.", "motivation": "Curved magnets offer rich phase diagrams and promise for next-generation spintronic technologies, but the significance of high-order vortex states with winding numbers >1 remains unexplored for enabling fundamentally inaccessible magnonic functionalities.", "method": "Used density-functional theory calculations and Heisenberg modeling to study phase diagrams, and Landau-Lifshitz-Gilbert equation to analyze hybridization mechanisms governed by orbital angular momentum selection rules in VSe2 nanotubes.", "result": "Discovered that high-order vortex configurations unlock intrinsic hybridization with strict OAM selection rules (\u0394l = \u00b12(n-1)), generating complex high-OAM magnons with measurable topological charge, demonstrated by eight-petal magnon density patterns in 3\u03c6 state.", "conclusion": "VSe2 nanotubes provide a platform-free solution for generating high-OAM magnons, establishing a predictive framework for controlling high-order vortex states and highlighting their promise for future magnonic and spintronic devices."}}
{"id": "2509.08474", "pdf": "https://arxiv.org/pdf/2509.08474", "abs": "https://arxiv.org/abs/2509.08474", "authors": ["Rostislav-Paul Wilhelm", "Katharina Kormann"], "title": "Restarting the Numerical Flow Iteration through low rank tensor approximations", "categories": ["math.NA", "cs.NA", "physics.plasm-ph"], "comment": null, "summary": "The numerical flow iteration method has recently been proposed as a\nmemory-slim solution method for the Vlasov-Poisson equation. It stores the\ntemporal evolution of the electric field and reconstructs the solution in each\ntime step by following the characteristics backwards in time and reconstructing\nthe solution from the initial distribution. If the number of time steps gets\nlarge, the computational cost of this reconstruction may get prohibitive. Given\na representation of the intermediate solution, the time intervals over which\nthe characteristic curves need to be solved backwards in time can be reduced by\nrestarting the numerical flow iteration after certain time intervals. In this\npaper, we propose an algorithm that reconstructs a low-rank representation of\nthe solution at the restart times using the blackbox approximation. The\nproposed algorithm reduces the computational complexity compared to the pure\nnumerical flow iteration from quadratic to linear in the number of times step\nwhile still keeping its memory complexity. On the other hand, our numerical\nresults demonstrate that the methods preserves the property of the numerical\nflow iteration of showing much less dissipation of filaments compared to the\nsemi-Lagrangian method.", "AI": {"tldr": "Proposes a restart algorithm with low-rank approximation for numerical flow iteration to reduce computational cost from quadratic to linear while maintaining memory efficiency and preserving low dissipation properties.", "motivation": "The numerical flow iteration method for Vlasov-Poisson equation becomes computationally expensive for large time steps due to characteristic curve reconstruction. A restart mechanism is needed to reduce computational complexity while maintaining memory efficiency.", "method": "Develops an algorithm that reconstructs low-rank representations of solutions at restart times using blackbox approximation, reducing the time intervals for characteristic curve solving.", "result": "The proposed method reduces computational complexity from quadratic to linear in number of time steps while maintaining memory complexity and preserving the low dissipation property of numerical flow iteration.", "conclusion": "The restart algorithm with low-rank approximation successfully addresses computational cost issues in numerical flow iteration while maintaining its advantages over semi-Lagrangian methods in filament dissipation."}}
{"id": "2509.08415", "pdf": "https://arxiv.org/pdf/2509.08415", "abs": "https://arxiv.org/abs/2509.08415", "authors": ["Wei Zhang", "Qi Zhou"], "title": "A Liouville theorem for the $2$-Hessian equation on the Heisenberg group", "categories": ["math.AP", "35B08, 35B53, 35R03"], "comment": "17 pages", "summary": "In this paper, we prove a Liouville theorem for the $2$-Hessian equation on\nthe Heisenberg group $\\mathbb{H}^n$. The result is obtained by choosing a\nsuitable test function and using integration by parts to derive the necessary\nintegral estimates.", "AI": {"tldr": "Liouville theorem for 2-Hessian equation on Heisenberg group proved using test functions and integration by parts", "motivation": "To establish a Liouville-type result for the 2-Hessian equation on the Heisenberg group, extending classical Liouville theorems to sub-Riemannian settings", "method": "Selection of suitable test functions combined with integration by parts techniques to derive integral estimates", "result": "Successful proof of the Liouville theorem for the 2-Hessian equation on the Heisenberg group", "conclusion": "The approach using test functions and integration by parts is effective for proving Liouville theorems in sub-Riemannian geometry contexts"}}
{"id": "2509.08525", "pdf": "https://arxiv.org/pdf/2509.08525", "abs": "https://arxiv.org/abs/2509.08525", "authors": ["Simon Lautenbach", "Jeremiah L\u00fcbke", "Maria Elena Innocenti", "Katharina Kormann", "Rainer Grauer"], "title": "Optimal Landau-type closure parameters for two-fluid simulations of plasma turbulence at kinetic scales", "categories": ["physics.plasm-ph", "physics.comp-ph", "physics.space-ph"], "comment": null, "summary": "Two fluid simulations using local Landau-fluid closures derived from linear\ntheory provide an efficient computational framework for plasma modelling, since\nthey bridge the gap between computationally intensive kinetic simulations and\nfluid descriptions. Their accuracy in representing kinetic effects depends\ncritically on the validity of the linear approximation used in the derivation:\nthe plasma should not be too far from local thermodynamic equilibrium, LTE.\nHowever, many of the problems where these models are of particular interest\n(such as plasma turbulence and instabilities) are in fact quite far from LTE.\nThe question then arises, if kinetic scale processes are still sufficiently\nwell captured outside of the theoretical regime of applicability of the\nclosure. In this paper, we show that two fluid simulations with Landau fluid\nclosures can effectively reproduce the energy spectra obtained with fully\nkinetic Vlasov simulations, used as references, as long as the local closure\nparameter is appropriately chosen. Our findings validate the usage of two fluid\nsimulations with Landau-fluid closure as a possible alternative to fully\nkinetic simulations of turbulence, in cases where being able to simulate\nextremely large domains is of particular interest.", "AI": {"tldr": "Two-fluid simulations with Landau-fluid closures can effectively reproduce kinetic energy spectra when closure parameters are properly chosen, validating their use as efficient alternatives to fully kinetic simulations for large-scale turbulence studies.", "motivation": "To bridge the gap between computationally intensive kinetic simulations and fluid descriptions while maintaining accuracy in representing kinetic effects, particularly for plasma turbulence and instabilities that operate far from local thermodynamic equilibrium.", "method": "Using two-fluid simulations with local Landau-fluid closures derived from linear theory, comparing results against fully kinetic Vlasov simulations as reference benchmarks, with careful selection of local closure parameters.", "result": "The simulations successfully reproduce the energy spectra obtained from fully kinetic Vlasov simulations when appropriate closure parameters are chosen, demonstrating good capture of kinetic scale processes even outside the theoretical regime of applicability.", "conclusion": "Two-fluid simulations with Landau-fluid closures provide a validated efficient alternative to fully kinetic simulations for turbulence studies, particularly beneficial when simulating extremely large domains where computational efficiency is crucial."}}
{"id": "2509.08537", "pdf": "https://arxiv.org/pdf/2509.08537", "abs": "https://arxiv.org/abs/2509.08537", "authors": ["Zhaonan Dong", "Emmanuil H. Georgoulis", "Lorenzo Mascotto", "Zuodong Wang"], "title": "A posteriori error analysis and adaptivity of a space-time finite element method for the wave equation in second order formulation", "categories": ["math.NA", "cs.NA", "65N30, 65M50, 65M60, 65J10"], "comment": null, "summary": "We establish rigorous \\emph{a posteriori} error bounds for a space-time\nfinite element method of arbitrary order discretising linear wave problems in\nsecond order formulation. The method combines standard finite elements in space\nand continuous piecewise polynomials in time with an upwind discontinuous\nGalerkin-type approximation for the second temporal derivative. The proposed\nscheme accepts dynamic mesh modification, as required by space-time adaptive\nalgorithms, resulting in a discontinuous temporal discretisation when mesh\nchanges occur. We prove \\emph{a posteriori} error bounds in the\n$L^\\infty(L^2)$-norm, using carefully designed temporal and spatial\nreconstructions; explicit control on the constants (including the spatial and\ntemporal orders of the method) in those error bounds is shown. The convergence\nbehaviour of an error estimator is verified numerically, also taking into\naccount the effect of the mesh change. A space-time adaptive algorithm is\nproposed and tested numerically.", "AI": {"tldr": "A posteriori error bounds for space-time finite element methods for linear wave problems with arbitrary order discretization, supporting dynamic mesh modification and adaptive algorithms.", "motivation": "To provide rigorous error analysis for space-time finite element methods that can handle dynamic mesh changes required by adaptive algorithms, ensuring reliable error control for wave propagation problems.", "method": "Combines standard finite elements in space with continuous piecewise polynomials in time and upwind discontinuous Galerkin-type approximation for second temporal derivative. Uses carefully designed temporal and spatial reconstructions to prove error bounds.", "result": "Established a posteriori error bounds in L\u221e(L\u00b2)-norm with explicit control on constants and orders. Numerical verification shows convergence of error estimator, including mesh change effects.", "conclusion": "The proposed space-time adaptive algorithm with rigorous error bounds enables reliable simulation of wave problems with dynamic mesh modifications, providing explicit error control for practical applications."}}
{"id": "2509.08431", "pdf": "https://arxiv.org/pdf/2509.08431", "abs": "https://arxiv.org/abs/2509.08431", "authors": ["Nicolas Beuvin", "Alberto Farina"], "title": "One-dimensional symmetry results for semilinear equations and inequalities on half-spaces", "categories": ["math.AP"], "comment": null, "summary": "We prove new one-dimensional symmetry results for non-negative solutions,\npossibly unbounded, to the semilinear equation $ -\\Delta u= f(u)$ in the upper\nhalf-space $\\mathbb{R}^{N}_{+}$. Some Liouville-type theorems are also proven\nin the case of differential inequalities in $\\mathbb{R}^{N}_{+}$, even without\nimposing any boundary condition. Although subject to dimensional restrictions,\nour results apply to a broad family of functions $f$. In particular, they apply\nto all non-negative $f$ that behaves at least linearly at infinity.", "AI": {"tldr": "New one-dimensional symmetry results for non-negative solutions to semilinear equations in the upper half-space, with Liouville-type theorems for differential inequalities without boundary conditions.", "motivation": "To establish symmetry properties and classification results for solutions to semilinear elliptic equations in unbounded domains, particularly the upper half-space, which has applications in various PDE problems.", "method": "Analytical proof techniques for semilinear elliptic equations, focusing on one-dimensional symmetry and Liouville-type theorems for non-negative solutions, possibly unbounded, without requiring boundary conditions.", "result": "Proved new one-dimensional symmetry results for non-negative solutions to -\u0394u = f(u) in \u211d\u207f\u208a, and established Liouville-type theorems for differential inequalities in \u211d\u207f\u208a even without boundary conditions, applicable to broad families of functions f including those with at least linear growth at infinity.", "conclusion": "The paper provides significant advances in understanding symmetry properties of solutions to semilinear elliptic equations in half-spaces, with results that apply to a wide range of nonlinearities and work under minimal assumptions, including cases without boundary conditions."}}
{"id": "2509.08061", "pdf": "https://arxiv.org/pdf/2509.08061", "abs": "https://arxiv.org/abs/2509.08061", "authors": ["Damiano Caprioli", "Luca Orusa", "Miha Cernetic", "Colby C. Haggerty", "Bricker Ostler"], "title": "Acceleration of Heavy Ions at Non-Relativistic Collisionless Shocks", "categories": ["astro-ph.HE", "physics.plasm-ph"], "comment": "6 pages, 3 figures. Submitted to ApJL", "summary": "We investigate the process of Diffusive Shock Acceleration (DSA) of particles\nwith mass number to charge number ratios $A/Q > 1$, e.g., partially-ionized\nheavy ions. To this end, we introduce helium- and carbon-like ions at solar\nabundances into two-dimensional hybrid (kinetic ions--fluid electrons)\nsimulations of non-relativistic collisionless shocks. This study yields three\nmain results: 1) Heavy ions are preferentially accelerated compared to\nhydrogen. For typical solar abundances, the energy transferred to accelerated\nhelium ions is comparable to, or even exceeds, that of hydrogen, thereby\nenhancing the overall shock acceleration efficiency. 2) Accelerated helium ions\ncontribute to magnetic field amplification, which increases the maximum\nattainable particle energy and steepen the spectra of accelerated particles. 3)\nThe efficient acceleration of helium significantly enhances the production of\nhadronic gamma rays and neutrinos, likely dominating the one due to hydrogen.\nThese effects should be taken into account, especially when modeling strong\nspace and astrophysical shocks.", "AI": {"tldr": "Heavy ions like helium and carbon are preferentially accelerated in collisionless shocks compared to hydrogen, enhancing overall acceleration efficiency, magnetic field amplification, and production of gamma rays and neutrinos.", "motivation": "To investigate how partially-ionized heavy ions with A/Q > 1 undergo Diffusive Shock Acceleration (DSA) and understand their impact on shock acceleration processes in astrophysical contexts.", "method": "Two-dimensional hybrid simulations (kinetic ions, fluid electrons) of non-relativistic collisionless shocks with helium- and carbon-like ions introduced at solar abundances.", "result": "1) Heavy ions are preferentially accelerated over hydrogen, with helium energy comparable/exceeding hydrogen; 2) Helium ions amplify magnetic fields, increasing maximum particle energy and steepening spectra; 3) Efficient helium acceleration significantly enhances hadronic gamma ray and neutrino production.", "conclusion": "Heavy ion acceleration effects must be considered when modeling strong space and astrophysical shocks due to their substantial impact on acceleration efficiency, magnetic field dynamics, and high-energy particle production."}}
{"id": "2509.08563", "pdf": "https://arxiv.org/pdf/2509.08563", "abs": "https://arxiv.org/abs/2509.08563", "authors": ["Qian Qian Xue", "Xiao Qiang Yue", "Xian-Ming Gu"], "title": "Error Analysis of Krylov Subspace approximation Based on IDR($s$) Method for Matrix Function Bilinear Forms", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "The bilinear form u^\\top f(A) v of matrix functions appears in many\napplication problems, where u, v \\in R^n\\), A \\in R^{n * n}\\), and f(z) is a\ngiven analytic function.The IDR(s) method effectively reduces computational\ncomplexity and storage requirements by introducing dimension reduction\ntechniques, while maintaining the numerical stability of the algorithm. This\npaper studies the numerical algorithm and posterior error estimation for the\nmatrix function bilinear form u^{\\top} f(A) v based on the IDR(s) method.\nThrough the error analysis of the IDR(s) algorithm, the corresponding error\nexpansion is derived, and it is verified that the leading term of the error\nexpansion serves as a reliable posterior error estimate. Based on this, in this\npaper a corresponding stopping criterion is proposed. This approach is\ndedicated to improving computational efficiency, especially by showing\nexcellent performance in handling ill-posed and large-scale problems.", "AI": {"tldr": "This paper presents an efficient algorithm for computing matrix function bilinear forms u^T f(A)v using IDR(s) method with error analysis and posterior error estimation.", "motivation": "Matrix function bilinear forms appear in many applications, but traditional methods have high computational complexity and storage requirements. The IDR(s) method offers dimension reduction while maintaining numerical stability.", "method": "Uses IDR(s) method to compute u^T f(A)v, performs error analysis to derive error expansion, and develops posterior error estimation with a stopping criterion based on the leading error term.", "result": "The method effectively reduces computational complexity and storage requirements while maintaining numerical stability. The error analysis shows the leading term provides reliable posterior error estimation.", "conclusion": "The proposed approach improves computational efficiency and shows excellent performance for ill-posed and large-scale problems, making it suitable for practical applications requiring matrix function bilinear forms."}}
{"id": "2509.08462", "pdf": "https://arxiv.org/pdf/2509.08462", "abs": "https://arxiv.org/abs/2509.08462", "authors": ["Haiyang Lin", "Jinqi Yan", "Bo You"], "title": "Global behavior of the energy to the hyperbolic equation of viscoelasticity with combined power-type nonlinearities", "categories": ["math.AP"], "comment": null, "summary": "The main objective of this manuscript is to investigate the global behavior\nof the solutions to the viscoelastic wave equation with a linear memory term of\nBoltzmann type, and a nonlinear damping modeling friction, as well as a\nsupercritical source term which is a combined power-type nonlinearities. The\nglobal existence of the solutions is obtained provided that the energy sink\ndominates the energy source in an appropriate sense. In more general scenarios,\nwe prove the global existence of the solutions if the initial history value\n$u_0$ is taken from a subset of a suitable potential well. Based on global\nexistence results, the energy decay rate is derived which depends on the\nrelaxation kernel as well as the growth rate of the damping term. In addition,\nwe study blow-up of solutions when the source is stronger than dissipation.", "AI": {"tldr": "Analysis of global behavior and blow-up for viscoelastic wave equations with memory, nonlinear damping, and supercritical source terms", "motivation": "To investigate the global existence, energy decay, and blow-up phenomena in viscoelastic wave equations with complex nonlinear interactions between memory effects, damping, and source terms", "method": "Mathematical analysis of PDEs with Boltzmann-type memory term, nonlinear friction damping, and combined power-type nonlinear source terms using energy methods and potential well theory", "result": "Global existence proven when energy sink dominates source or initial data is in suitable potential well subset; energy decay rates derived; blow-up shown when source dominates dissipation", "conclusion": "The interplay between memory effects, nonlinear damping, and source terms determines solution behavior - either global existence with decay or finite-time blow-up depending on energy balance"}}
{"id": "2509.08420", "pdf": "https://arxiv.org/pdf/2509.08420", "abs": "https://arxiv.org/abs/2509.08420", "authors": ["J. Bj\u00f6rklund Svensson", "J. Beinortait\u0117", "L. Boulton", "B. Foster", "J. M. Garland", "P. Gonz\u00e1lez Caminal", "M. Huck", "H. Jones", "A. Kanekar", "G. Loisch", "J. Osterhoff", "F. Pe\u00f1a", "S. Schr\u00f6der", "M. Th\u00e9venet", "S. Wesch", "M. Wing", "J. C. Wood", "R. D'Arcy"], "title": "Slice Emittance Preservation and Focus Control in a Passive Plasma Lens", "categories": ["physics.acc-ph", "physics.plasm-ph"], "comment": "10 pages, 7 figures", "summary": "Strong, symmetrically focusing plasma lenses are promising for accommodating\nthe small beams associated with plasma-based accelerators and collider final\nfoci. However, while focusing with active and passive plasma lenses has been\nexperimentally demonstrated, compatibility with high-brightness beams relevant\nfor applications has not. In this Letter, we show experimentally that passive\nplasma lenses can preserve free-electron-laser-quality slice emittance while\nfocusing two orders of magnitude more strongly than quadrupole magnets, and\nthat the focal parameters can be controlled.", "AI": {"tldr": "Passive plasma lenses can strongly focus high-brightness FEL-quality beams while preserving slice emittance, outperforming quadrupole magnets by two orders of magnitude.", "motivation": "Strong focusing plasma lenses are needed for plasma-based accelerators and collider final foci, but compatibility with high-brightness beams hasn't been demonstrated.", "method": "Experimental demonstration of passive plasma lenses focusing capabilities with free-electron-laser-quality beams.", "result": "Passive plasma lenses preserved slice emittance while focusing two orders of magnitude more strongly than quadrupole magnets, with controllable focal parameters.", "conclusion": "Passive plasma lenses are compatible with high-brightness beams and offer superior focusing performance compared to traditional quadrupole magnets."}}
{"id": "2509.08620", "pdf": "https://arxiv.org/pdf/2509.08620", "abs": "https://arxiv.org/abs/2509.08620", "authors": ["Ze Tao", "Fujun Liu"], "title": "A Unified Symmetry-Constrained Framework for Band Inversions in Photonic Crystals with $C_n$ Symmetry", "categories": ["physics.optics", "cond-mat.mtrl-sci", "math-ph", "math.MP", "physics.comp-ph"], "comment": "7 pages, 5 figures", "summary": "The lack of a unified theoretical framework for characterizing band\ninversions across different crystal symmetries hinders the rapid development of\ntopological photonic band engineering. To address this issue, we have\nconstructed a framework constrained by symmetry $k \\cdot p$ that universally\nmodels bands near high-symmetry points for symmetric photonic crystals $C_6$,\n$C_4$, $C_3$, and $C_2$. This framework enables a coefficient-free quantitative\ndiagnosis of band topology. We have demonstrated the power of this framework by\nsystematically engineering band inversions. In $C_6$ crystals, we induce a\nreopening of the linear gap at $\\Gamma$. In $C_4$ systems, mirror symmetry\nenforces a characteristic quadratic coupling leading to distinct spectral\nfeatures. Our analysis further reveals that a lone $E$ doublet prevents\ninversion at the $\\Gamma$ point in $C_3$ symmetry, while $C_2$ symmetry\nfacilitates a unique inversion of $Y$ pointsints with anisotropic gap. This\nsymmetry-first, fit-free approach establishes a direct link between\nexperimental band maps and the extraction of fundamental topological\nparameters. It offers a universal tool for inversion and coupling-order\nidentification.", "AI": {"tldr": "A unified symmetry-constrained k\u00b7p framework for characterizing band inversions across C\u2086, C\u2084, C\u2083, and C\u2082 photonic crystals, enabling coefficient-free topological diagnosis and systematic band engineering.", "motivation": "The lack of a unified theoretical framework for characterizing band inversions across different crystal symmetries hinders the development of topological photonic band engineering.", "method": "Constructed a symmetry-constrained k\u00b7p framework that universally models bands near high-symmetry points for symmetric photonic crystals with C\u2086, C\u2084, C\u2083, and C\u2082 symmetries.", "result": "Demonstrated systematic band inversion engineering: reopening linear gap at \u0393 in C\u2086 crystals, quadratic coupling in C\u2084 systems, prevention of inversion at \u0393 in C\u2083 symmetry, and unique anisotropic gap inversion in C\u2082 symmetry.", "conclusion": "This symmetry-first, fit-free approach establishes a direct link between experimental band maps and topological parameter extraction, providing a universal tool for inversion and coupling-order identification."}}
{"id": "2509.08574", "pdf": "https://arxiv.org/pdf/2509.08574", "abs": "https://arxiv.org/abs/2509.08574", "authors": ["Fred Vickers Hastings", "S M Ragib Shahriar Islam", "Malena Sabat\u00e9 Landman", "Sepideh Hatamikia", "Carola-Bibiane Sch\u00f6nlieb", "Ander Biguri"], "title": "Real-time CBCT reconstructions using Krylov solvers in repeated scanning procedures", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This work introduces a new efficient iterative solver for the reconstruction\nof real-time cone-beam computed tomography (CBCT), which is based on the Prior\nImage Constrained Compressed Sensing (PICCS) regularization and leverages the\nefficiency of Krylov subspace methods. In particular, we focus on the setting\nwhere a sequence of under-sampled CT scans are taken on the same object with\nonly local changes (e.g. changes in a tumour size or the introduction of a\nsurgical tool). This is very common, for example, in image-guided surgery,\nwhere the amount of measurements is limited to ensure the safety of the\npatient. In this case, we can also typically assume that a (good) initial\nreconstruction for the solution exists, coming from a previously over-sampled\nscan, so we can use this information to aid the subsequent reconstructions. The\neffectiveness of this method is demonstrated in both a synthetic scan and using\nreal CT data, where it can be observed that the PICCS framework is very\neffective for the reduction of artifacts, and that the new method is faster\nthan other common alternatives used in the same setting.", "AI": {"tldr": "New efficient iterative solver for real-time CBCT reconstruction using PICCS regularization and Krylov subspace methods, particularly effective for sequential scans with local changes like in image-guided surgery.", "motivation": "Need for efficient real-time CBCT reconstruction in medical applications where sequential under-sampled scans are taken on the same object with only local changes, such as tumor monitoring or surgical procedures with limited measurements for patient safety.", "method": "Prior Image Constrained Compressed Sensing (PICCS) regularization combined with Krylov subspace methods, leveraging existing good initial reconstructions from previous over-sampled scans to aid subsequent reconstructions.", "result": "Method effectively reduces artifacts in both synthetic and real CT data, and demonstrates faster performance compared to other common alternatives in the same setting.", "conclusion": "The PICCS framework with Krylov subspace methods provides an efficient and effective solution for real-time CBCT reconstruction in sequential scanning scenarios with local changes, offering improved artifact reduction and computational speed."}}
{"id": "2509.08543", "pdf": "https://arxiv.org/pdf/2509.08543", "abs": "https://arxiv.org/abs/2509.08543", "authors": ["Ch\u00e9rif Amrouche", "Mohand Moussaoui"], "title": "Maximal regularity of Dirichlet problem for the Laplacian in Lipschitz domains", "categories": ["math.AP"], "comment": null, "summary": "The focus of this work is on the homogeneous and non-homogeneous Dirichlet\nproblem for the Laplacian in bounded Lipschitz domains (BLD). Although it has\nbeen extensively studied by many authors, we would like to return to a number\nof fundamental questions and known results, such as the traces and the maximal\nregularity of solutions. First, to treat non-homogeneous boundary conditions,\nwe rigorously define the notion of traces for non regular functions. This\napproach replaces the non-tangential trace notion that has dominated the\nliterature since the 1980s. We identify a functional space E = \\{v\\in\nH^{1/2}(\\Omega);\\nabla v\\in [H^1/2(\\Omega)]'\\} for which the trace operator is\ncontinuous from $E$ into $L^2(\\Gamma)$. Second, we address the regularity of\nsolutions to the Laplace equation with homogeneous Dirichlet conditions. Using\nspecific equivalent norms in fractional Sobolev spaces and Grisvard's results\nfor polygons and polyhedral domains, we prove that maximal regularity $H^{3/2}$\nholds in any BLD $\\Omega$, for all right-hand sides in the dual of\n$H^{1/2}_{00}(\\Omega)$. This conclusion contradicts the prevailing claims in\nthe literature since the 1990s. Third, we describe some criteria which\nestablish new uniqueness results for harmonic functions in Lipschitz domains.\nIn particular, we show that if $u\\in H^{1/2}(\\Omega)$ or $u\\in W^{1,\n2N/(N+1)}(\\Omega)$, is harmonic in $\\Omega$ and vanishes on $\\Gamma$, then $u=\n0$. These criteria play a central role in deriving regularity properties.\nFinally, we revisit the classical Area Integral Estimate. Using Grisvard's work\nand an explicit function given by Necas, we show that this inequality cannot\nhold in its stated form. Since this estimate has been widely used to argue that\n$H^{3/2}$-regularity is unattainable for data in the dual of\n$H^{1/2}_{00}(\\Omega)$, our counterexample provides a decisive clarification.", "AI": {"tldr": "Revisits fundamental questions about Laplace equation in bounded Lipschitz domains, challenges established results from 1980s-1990s, introduces new trace definitions, proves maximal H^{3/2} regularity, provides uniqueness criteria for harmonic functions, and refutes classical Area Integral Estimate.", "motivation": "To address fundamental gaps and contradictions in the literature regarding the Dirichlet problem for Laplacian in bounded Lipschitz domains, particularly concerning trace definitions, solution regularity, and established estimates that have been widely accepted since the 1980s-1990s.", "method": "Introduces new functional space E for rigorous trace definition, uses equivalent norms in fractional Sobolev spaces, applies Grisvard's results for polygons/polyhedra, provides counterexamples using explicit functions, and develops uniqueness criteria for harmonic functions.", "result": "Proves maximal H^{3/2} regularity holds for all right-hand sides in dual of H^{1/2}_{00}(\u03a9), contradicts prevailing claims since 1990s, establishes new uniqueness results for harmonic functions, and demonstrates that classical Area Integral Estimate cannot hold as stated.", "conclusion": "The paper fundamentally challenges and corrects long-standing misconceptions in the field, providing rigorous mathematical foundations for trace definitions, proving optimal regularity results, and clarifying the limitations of previously accepted estimates that have influenced the literature for decades."}}
{"id": "2509.08708", "pdf": "https://arxiv.org/pdf/2509.08708", "abs": "https://arxiv.org/abs/2509.08708", "authors": ["Teresa Portone", "Rebekah D. White", "Joseph L. Hart"], "title": "Quantifying model prediction sensitivity to model-form uncertainty", "categories": ["cs.CE", "physics.comp-ph", "physics.data-an", "stat.AP"], "comment": null, "summary": "Model-form uncertainty (MFU) in assumptions made during physics-based model\ndevelopment is widely considered a significant source of uncertainty; however,\nthere are limited approaches that can quantify MFU in predictions extrapolating\nbeyond available data. As a result, it is challenging to know how important MFU\nis in practice, especially relative to other sources of uncertainty in a model,\nmaking it difficult to prioritize resources and efforts to drive down error in\nmodel predictions. To address these challenges, we present a novel method to\nquantify the importance of uncertainties associated with model assumptions. We\ncombine parameterized modifications to assumptions (called MFU representations)\nwith grouped variance-based sensitivity analysis to measure the importance of\nassumptions. We demonstrate how, in contrast to existing methods addressing\nMFU, our approach can be applied without access to calibration data. However,\nif calibration data is available, we demonstrate how it can be used to inform\nthe MFU representation, and how variance-based sensitivity analysis can be\nmeaningfully applied even in the presence of dependence between parameters (a\ncommon byproduct of calibration).", "AI": {"tldr": "Novel method to quantify importance of model-form uncertainty in physics-based models using parameterized assumption modifications and grouped variance-based sensitivity analysis.", "motivation": "Model-form uncertainty is a significant but hard-to-quantify source of error in predictions beyond available data, making it difficult to prioritize resources for error reduction.", "method": "Combines parameterized modifications to assumptions (MFU representations) with grouped variance-based sensitivity analysis to measure assumption importance, applicable with or without calibration data.", "result": "The approach can quantify assumption importance without calibration data, and when data is available, it can inform MFU representations and handle parameter dependence from calibration.", "conclusion": "Provides a practical framework for quantifying model-form uncertainty importance relative to other uncertainty sources, enabling better resource allocation for model improvement."}}
{"id": "2509.08645", "pdf": "https://arxiv.org/pdf/2509.08645", "abs": "https://arxiv.org/abs/2509.08645", "authors": ["Nina Beranek", "Robin Smeets", "Rob Stevenson"], "title": "Quasi-optimal time-space discretizations for a class of nonlinear parabolic PDEs", "categories": ["math.NA", "cs.NA", "35A15, 35B35, 35K90, 65M12, 65M15, 65M60"], "comment": "24 pages", "summary": "We consider parabolic evolution equations with Lipschitz continuous and\nstrongly monotone spatial operators. By introducing an additional variable, we\nconstruct an equivalent system where the operator is a Lipschitz continuous\nmapping from a Hilbert space $Y \\times X$ to its dual, with a Lipschitz\ncontinuous inverse. Resulting Galerkin discretizations can be solved with an\ninexact Uzawa type algorithm. Quasi-optimality of the Galerkin approximations\nis guaranteed under an inf-sup condition on the selected `test' and `trial'\nsubspaces of $Y$ and $X$. To circumvent the restriction imposed by this inf-sup\ncondition, an a posteriori condition for quasi-optimality is developed that is\nshown to be satisfied whenever the test space is sufficiently large.", "AI": {"tldr": "A method for solving parabolic evolution equations with Lipschitz continuous strongly monotone operators using an equivalent system formulation and inexact Uzawa algorithm, with quasi-optimality conditions for Galerkin approximations.", "motivation": "To develop an efficient numerical approach for parabolic evolution equations with Lipschitz continuous and strongly monotone spatial operators by constructing an equivalent system that enables the use of inexact Uzawa algorithms and ensures quasi-optimal Galerkin approximations.", "method": "Introduce an additional variable to construct an equivalent system where the operator becomes a Lipschitz continuous mapping from Hilbert space Y\u00d7X to its dual with Lipschitz continuous inverse. Use Galerkin discretizations solvable with inexact Uzawa algorithm. Develop quasi-optimality conditions including an inf-sup condition and an a posteriori condition for when test spaces are sufficiently large.", "result": "The method produces quasi-optimal Galerkin approximations under inf-sup conditions on test and trial subspaces. An a posteriori condition is developed that guarantees quasi-optimality when the test space is sufficiently large, circumventing the inf-sup condition restriction.", "conclusion": "The proposed approach successfully enables efficient numerical solution of parabolic evolution equations through system reformulation, inexact Uzawa algorithms, and flexible quasi-optimality conditions that work with sufficiently large test spaces."}}
{"id": "2509.08735", "pdf": "https://arxiv.org/pdf/2509.08735", "abs": "https://arxiv.org/abs/2509.08735", "authors": ["Marius M\u00fcller"], "title": "Lipschitz regularity for $p$-harmonic interface transmission problems", "categories": ["math.AP"], "comment": "18 pages, comments welcome!", "summary": "We prove optimal Lipschitz regularity for weak solutions of the\nmeasure-valued $p$-Poisson equation $-\\Delta_p u = Q \\; \\mathcal{H}^{n-1}\n\\llcorner \\Gamma$. Here $p \\in (1,2)$, $\\Gamma$ is a compact and connected\n$C^2$-hypersurface without boundary, and $Q$ is a positive\n$W^{2,\\infty}$-density. This equation can be understood as a nonlinear\ninterface transmission problem. Our main result extends previous studies of the\nlinear case and provides further insights on a delicate limit case of (linear\nand nonlinear) potential theory.", "AI": {"tldr": "Optimal Lipschitz regularity proved for weak solutions of measure-valued p-Poisson equation with interface transmission, extending linear case results.", "motivation": "To understand nonlinear interface transmission problems and provide insights on a delicate limit case in potential theory, building on previous linear case studies.", "method": "Analysis of weak solutions for the measure-valued p-Poisson equation with p in (1,2), using a compact connected C\u00b2-hypersurface without boundary and positive W\u00b2,\u221e-density.", "result": "Proved optimal Lipschitz regularity for weak solutions of the nonlinear interface transmission problem.", "conclusion": "The study successfully extends previous linear case results and provides valuable insights into a delicate limit case of potential theory, both linear and nonlinear."}}
{"id": "2509.08790", "pdf": "https://arxiv.org/pdf/2509.08790", "abs": "https://arxiv.org/abs/2509.08790", "authors": ["Tristan Montoya", "Andr\u00e9s M. Rueda-Ram\u00edrez", "Gregor J. Gassner"], "title": "Entropy-Stable Discontinuous Spectral-Element Methods for the Spherical Shallow Water Equations in Covariant Form", "categories": ["math.NA", "cs.NA", "physics.ao-ph", "physics.comp-ph", "65M60 (Primary), 65M12, 65M70, 58J45, 76U60 (Secondary)"], "comment": "34 pages, 8 figures. Reproducibility repository:\n  https://github.com/tristanmontoya/paper-2025-spherical-shallow-water/", "summary": "We introduce discontinuous spectral-element methods of arbitrary order that\nare well balanced, conservative of mass, and conservative or dissipative of\ntotal energy (i.e., a mathematical entropy function) for a covariant flux\nformulation of the rotating shallow water equations with variable bottom\ntopography on curved manifolds such as the sphere. The proposed methods are\nbased on a skew-symmetric splitting of the tensor divergence in covariant form,\nwhich we implement and analyze within a general flux-differencing framework\nusing tensor-product summation-by-parts operators. Such schemes are proven to\nsatisfy semi-discrete mass and energy conservation on general unstructured\nquadrilateral grids in addition to well balancing for arbitrary continuous\nbottom topographies, with energy dissipation resulting from a suitable choice\nof numerical interface flux. Furthermore, the proposed covariant formulation\npermits an analytical representation of the geometry and associated metric\nterms while satisfying the aforementioned entropy stability, conservation, and\nwell-balancing properties without the need to approximate the metric terms so\nas to enforce discrete metric identities. Numerical experiments on cubed-sphere\ngrids are presented in order to verify the schemes' structure-preservation\nproperties as well as to assess their accuracy and robustness within the\ncontext of several standard test cases characteristic of idealized atmospheric\nflows. Our theoretical and numerical results support the further development of\nthe proposed methodology towards a full dynamical core for numerical weather\nprediction and climate modelling, as well as broader applications to other\nhyperbolic and advection-dominated systems of partial differential equations on\ncurved manifolds.", "AI": {"tldr": "Discontinuous spectral-element methods for rotating shallow water equations on curved manifolds that are well-balanced, mass-conservative, and energy-conservative/dissipative using skew-symmetric splitting and flux-differencing framework.", "motivation": "To develop structure-preserving numerical methods for atmospheric flows and geophysical fluid dynamics on curved manifolds like spheres, which maintain conservation properties and well-balancing for numerical weather prediction and climate modeling.", "method": "Skew-symmetric splitting of tensor divergence in covariant form within a flux-differencing framework using tensor-product summation-by-parts operators on unstructured quadrilateral grids.", "result": "The methods achieve semi-discrete mass and energy conservation, well-balancing for arbitrary continuous bottom topographies, and energy dissipation through appropriate numerical interface flux choices, while handling geometry analytically without approximating metric terms.", "conclusion": "The proposed methodology shows promise for developing full dynamical cores for numerical weather prediction and climate modeling, with potential applications to other hyperbolic and advection-dominated systems on curved manifolds."}}
{"id": "2509.08745", "pdf": "https://arxiv.org/pdf/2509.08745", "abs": "https://arxiv.org/abs/2509.08745", "authors": ["Po-Yi Wu"], "title": "On the Lebesgue Constant of Extended-Domain Spectral Methods for Elliptic PDEs", "categories": ["math.NA", "cs.NA", "65N12, 65N35, 65T40"], "comment": null, "summary": "The extended-domain method is an appealingly simple strategy for applying\nspectral methods to complex geometries, but its theoretical stability\nproperties, particularly for non-normal operators, are not fully understood.\nThis paper provides a rigorous stability analysis based on the Lebesgue\nconstant and reveals a fundamental stability dichotomy at the heart of the\nmethod. We first prove a surprising result: for the self-adjoint Poisson\nequation, the method is unstable, with a Lebesgue constant that grows\nsuper-polynomially due to the ill-conditioning of spectral differentiation. In\nstark contrast, we prove that for the non-self-adjoint convection-diffusion\nequation, the method becomes stable. We show that the first-order convection\nterm regularizes the operator, leading to a provably polynomial bound on the\nLebesgue constant. These results, extended here to multiple dimensions and\nvariable coefficients, provide a complete theoretical foundation for this\npractical method, establishing the precise conditions under which it is stable\nand highlighting a non-trivial interplay between operator components.", "AI": {"tldr": "Extended-domain spectral method shows stability dichotomy: unstable for self-adjoint Poisson equation but stable for non-self-adjoint convection-diffusion due to convection regularization.", "motivation": "To provide rigorous stability analysis of extended-domain spectral methods for complex geometries, particularly understanding stability properties for non-normal operators which were not fully understood.", "method": "Rigorous stability analysis based on Lebesgue constant, theoretical proofs for both self-adjoint Poisson equation and non-self-adjoint convection-diffusion equation, extended to multiple dimensions and variable coefficients.", "result": "Found fundamental stability dichotomy - method is unstable for Poisson equation (super-polynomial Lebesgue constant growth) but stable for convection-diffusion equation (polynomial Lebesgue constant bound due to convection regularization).", "conclusion": "Provides complete theoretical foundation for extended-domain spectral methods, establishing precise stability conditions and revealing non-trivial interplay between operator components."}}
{"id": "2509.08761", "pdf": "https://arxiv.org/pdf/2509.08761", "abs": "https://arxiv.org/abs/2509.08761", "authors": ["Ruiwen Shu"], "title": "Existence of minimizers for interaction energies with external potentials", "categories": ["math.AP", "math.CA", "31B15, 49K20, 42B10"], "comment": null, "summary": "In this paper we study the existence of minimizers for interaction energies\nwith the presence of external potentials. We consider a class of subharmonic\ninteraction potentials, which include the Riesz potentials $|{\\bf\nx}|^{-s},\\,\\max\\{0,d-2\\}<s<d$ and its anisotropic counterparts. The underlying\nspace is taken as $\\mathbb{R}^d$ or a half-space with possibly curved boundary.\nWe give a sufficient and almost necessary condition for the existence of\nminimizers, as well as the uniqueness of minimizers. The proof is based on the\nobservation that the Euler-Lagrange condition for the energy minimizer is\nalmost the same as that for the maximizer of the height functional, defined as\nthe essential infimum of the generated potential. We also give two\ncomplimentary results: a simple sufficient condition for the existence of\nminimizers for general interaction/external potentials, and a slight\nimprovement to the known result on the existence of minimizers without external\npotentials.", "AI": {"tldr": "Existence and uniqueness of minimizers for interaction energies with external potentials, focusing on subharmonic interaction potentials including Riesz potentials and anisotropic versions in various domains.", "motivation": "To establish sufficient and almost necessary conditions for the existence and uniqueness of minimizers in interaction energy problems with external potentials, extending previous results and providing practical criteria.", "method": "Based on the observation that Euler-Lagrange conditions for energy minimizers are nearly identical to those for maximizers of the height functional (essential infimum of generated potential), with analysis of subharmonic interaction potentials.", "result": "Provides sufficient and almost necessary conditions for minimizer existence and uniqueness, along with a simple sufficient condition for general interaction/external potentials and an improvement to existing results without external potentials.", "conclusion": "The paper establishes comprehensive conditions for minimizer existence and uniqueness in interaction energy problems with external potentials, offering both theoretical insights and practical criteria for a broad class of subharmonic interaction potentials."}}
{"id": "2509.08807", "pdf": "https://arxiv.org/pdf/2509.08807", "abs": "https://arxiv.org/abs/2509.08807", "authors": ["Xi-Ning Zhuang", "Zhao-Yun Chen", "Ming-Yang Tan", "Jiaxuan Zhang", "Chuang-Chao Ye", "Tian-Hao Wei", "Teng-Yang Ma", "Cheng Xue", "Huan-Yu Liu", "Qing-Song Li", "Tai-Ping Sun", "Xiao-Fan Xu", "Yun-Jie Wang", "Yu-Chun Wu", "Guo-Ping Guo"], "title": "A Pathway to Practical Quantum Advantage in Solving Navier-Stokes Equations", "categories": ["quant-ph", "cs.NA", "math.NA", "physics.comp-ph", "physics.flu-dyn"], "comment": "57 pages, 21 figures", "summary": "The advent of fault-tolerant quantum computing (FTQC) promises to tackle\nclassically intractable problems. A key milestone is solving the Navier-Stokes\nequations (NSE), which has remained formidable for quantum algorithms due to\ntheir high input-output overhead and nonlinearity. Here, we establish a\nfull-stack framework that charts a practical pathway to a quantum advantage for\nlarge-scale NSE simulation. Our approach integrates a spectral-based\ninput/output algorithm, an explicit and synthesized quantum circuit, and a\nrefined error-correction protocol. The algorithm achieves an end-to-end\nexponential speedup in asymptotic complexity, meeting the lower bound for\ngeneral quantum linear system solvers. Through symmetry-based circuit synthesis\nand optimized error correction, we reduce the required logical and physical\nresources by two orders of magnitude. Our concrete resource analysis\ndemonstrates that solving NSE on a $2^{80}$-grid is feasible with 8.71 million\nphysical qubits (at an error rate of $5 \\times 10^{-4}$) in 42.6 days --\noutperforming a state-of-the-art supercomputer, which would require over a\ncentury. This work bridges the gap between theoretical quantum speedup and the\npractical deployment of high-performance scientific computing.", "AI": {"tldr": "Quantum framework achieves exponential speedup for Navier-Stokes equations, reducing resource requirements by 100x and enabling 2^80-grid simulation in 42.6 days vs. century on supercomputers.", "motivation": "Navier-Stokes equations have remained formidable for quantum algorithms due to high input-output overhead and nonlinearity, despite the promise of fault-tolerant quantum computing for solving classically intractable problems.", "method": "Full-stack framework integrating spectral-based input/output algorithm, explicit synthesized quantum circuit using symmetry-based synthesis, and refined error-correction protocol to optimize resource requirements.", "result": "Achieves end-to-end exponential speedup meeting lower bound for quantum linear system solvers, reduces logical and physical resources by two orders of magnitude. 2^80-grid simulation feasible with 8.71M physical qubits in 42.6 days.", "conclusion": "Bridges gap between theoretical quantum speedup and practical deployment of high-performance scientific computing, demonstrating quantum advantage for large-scale NSE simulation that outperforms state-of-the-art supercomputers by orders of magnitude."}}
{"id": "2509.08768", "pdf": "https://arxiv.org/pdf/2509.08768", "abs": "https://arxiv.org/abs/2509.08768", "authors": ["Qingyou He"], "title": "Sharp power concavity of two relevant free boundary problems of reaction-diffusion type", "categories": ["math.AP"], "comment": null, "summary": "The porous medium type reaction-diffusion equation and the Hele-Shaw problem\nare two free boundary problems linked through the incompressible (Hele-Shaw)\nlimit. We investigate and compare the sharp power concavities of the pressures\non their respective supports for the two free boundary problems. For the\npressure of the porous medium type reaction-diffusion equation, the\n$\\frac{1}{2}$-concavity preserves all the time, while $\\alpha$-concavity for\n$\\alpha\\in[0,\\frac{1}{2})\\cup(\\frac{1}{2},1]$ does not persist in time. In\ncontrast, in the case of the pressure for the Hele-Shaw problem,\n$\\alpha$-concavity with $\\alpha\\in[0,\\frac{1}{2}]$ is maintained all the while\nand $\\frac{1}{2}$ acts as the largest index. The intuitive explanation for the\ndifference between the two free boundary problems is that, although the\nHele-Shaw problem is the incompressible limit of the porous medium-type\nreaction-diffusion equation, it is no longer a degenerate parabolic equation.\nFurthermore, for the pressure of the porous medium type reaction-diffusion\nequation, the non-degenerate estimate is established by means of the derived\nconcave properties, indicating that the spatial Lipschitz regularity in the\nwhole space is sharp.", "AI": {"tldr": "Comparison of power concavity properties between porous medium reaction-diffusion equation and Hele-Shaw problem pressures, showing different concavity preservation patterns and establishing sharp spatial Lipschitz regularity.", "motivation": "To investigate and compare the sharp power concavity properties of pressures in two related free boundary problems - the porous medium type reaction-diffusion equation and the Hele-Shaw problem - which are connected through the incompressible limit.", "method": "Analyzing the preservation of \u03b1-concavity for different \u03b1 values in both problems, comparing their mathematical properties, and establishing non-degenerate estimates using derived concave properties.", "result": "For porous medium equation, only 1/2-concavity persists over time while other \u03b1-concavities (\u03b1\u2208[0,1/2)\u222a(1/2,1]) do not. For Hele-Shaw problem, \u03b1-concavity with \u03b1\u2208[0,1/2] is maintained, with 1/2 as the largest index. Sharp spatial Lipschitz regularity is established.", "conclusion": "The Hele-Shaw problem, despite being the incompressible limit of the porous medium equation, behaves differently due to not being a degenerate parabolic equation. The 1/2-concavity represents a fundamental mathematical property distinguishing these two related free boundary problems."}}
{"id": "2509.08155", "pdf": "https://arxiv.org/pdf/2509.08155", "abs": "https://arxiv.org/abs/2509.08155", "authors": ["Kai Yang"], "title": "Contributions to Robust and Efficient Methods for Analysis of High Dimensional Data", "categories": ["math.ST", "cs.LG", "cs.NA", "math.NA", "math.OC", "physics.data-an", "stat.TH"], "comment": "PhD thesis . Available at\n  https://escholarship.mcgill.ca/concern/theses/5t34sq859", "summary": "A ubiquitous feature of data of our era is their extra-large sizes and\ndimensions. Analyzing such high-dimensional data poses significant challenges,\nsince the feature dimension is often much larger than the sample size. This\nthesis introduces robust and computationally efficient methods to address\nseveral common challenges associated with high-dimensional data. In my first\nmanuscript, I propose a coherent approach to variable screening that\naccommodates nonlinear associations. I develop a novel variable screening\nmethod that transcends traditional linear assumptions by leveraging mutual\ninformation, with an intended application in neuroimaging data. This approach\nallows for accurate identification of important variables by capturing\nnonlinear as well as linear relationships between the outcome and covariates.\nBuilding on this foundation, I develop new optimization methods for sparse\nestimation using nonconvex penalties in my second manuscript. These methods\naddress notable challenges in current statistical computing practices,\nfacilitating computationally efficient and robust analyses of complex datasets.\nThe proposed method can be applied to a general class of optimization problems.\nIn my third manuscript, I contribute to robust modeling of high-dimensional\ncorrelated observations by developing a mixed-effects model based on Tsallis\npower-law entropy maximization and discussed the theoretical properties of such\ndistribution. This model surpasses the constraints of conventional Gaussian\nmodels by accommodating a broader class of distributions with enhanced\nrobustness to outliers. Additionally, I develop a proximal nonlinear conjugate\ngradient algorithm that accelerates convergence while maintaining numerical\nstability, along with rigorous statistical properties for the proposed\nframework.", "AI": {"tldr": "Robust computational methods for high-dimensional data analysis, including nonlinear variable screening, nonconvex sparse estimation, and robust mixed-effects modeling with Tsallis entropy.", "motivation": "High-dimensional data with feature dimensions much larger than sample sizes pose significant analytical challenges that require robust and computationally efficient methods beyond traditional linear assumptions.", "method": "Three main approaches: 1) Mutual information-based variable screening for nonlinear associations, 2) Nonconvex penalty optimization for sparse estimation, 3) Tsallis entropy-based mixed-effects modeling with proximal nonlinear conjugate gradient algorithm.", "result": "Developed methods that accommodate nonlinear relationships, provide computational efficiency, enhance robustness to outliers, and maintain numerical stability while handling high-dimensional correlated observations.", "conclusion": "The proposed coherent framework addresses key challenges in high-dimensional data analysis through robust, computationally efficient methods that transcend traditional linear and Gaussian assumptions, with applications in neuroimaging and complex datasets."}}
{"id": "2509.08334", "pdf": "https://arxiv.org/pdf/2509.08334", "abs": "https://arxiv.org/abs/2509.08334", "authors": ["Bernhard Haak", "El-Maati Ouhabaz"], "title": "A weak type $(p,a)$ criterion for operators, and applications", "categories": ["math.FA", "math.AP", "math.CA", "42B20, 47G10, 42B30, 47A60"], "comment": "25 pages", "summary": "Let $(X, d, \\mu)$ be a space of homogeneous type and $\\Omega$ an open subset\nof $X$. Given a bounded operator $T: L^p(\\Omega) \\to L^q(\\Omega)$ for some $1\n\\le p \\le q < \\infty$, we give a criterion for $T$ to be of weak type $(p_0,\na)$ for $p_0$ and $a$ such that $\\frac{1}{p_0} - \\frac{1}{a} =\n\\frac{1}{p}-\\frac{1}{q}$. These results are illustrated by several applications\nincluding estimates of weak type $(p_0, a)$ for Riesz potentials\n$L^{-\\frac{\\alpha}{2}}$ or for Riesz transform type operators $\\nabla\n\\Delta^{-\\frac{\\alpha}{2}}$ as well as $L^p-L^q$ boundedness of spectral\nmultipliers $F(L)$ when the heat kernel of $L$ satisfies a Gaussian upper bound\nor an off-diagonal bound. We also prove boundedness of these operators from the\nHardy space $H^1_L$ associated with $L$ into $L^a(X)$. By duality this gives\nboundedness from $L^{a'}(X)$ into $\\text{BMO}_L$.", "AI": {"tldr": "A criterion for weak type (p0,a) estimates of bounded operators on homogeneous type spaces, with applications to Riesz potentials, Riesz transforms, and spectral multipliers.", "motivation": "To establish a general framework for proving weak type estimates for operators acting on function spaces over homogeneous type spaces, particularly for operators arising from spectral theory and potential theory.", "method": "Develops a criterion for weak type (p0,a) estimates for bounded operators T: L^p(\u03a9) \u2192 L^q(\u03a9) where 1/p0 - 1/a = 1/p - 1/q. Applies this to Riesz potentials, Riesz transform type operators, and spectral multipliers under Gaussian or off-diagonal heat kernel bounds.", "result": "Proves weak type estimates for various operators including L^{-\u03b1/2}, \u2207\u0394^{-\u03b1/2}, and spectral multipliers F(L). Also establishes boundedness from Hardy space H^1_L to L^a(X) and from L^{a'}(X) to BMO_L by duality.", "conclusion": "The paper provides a unified approach to obtaining weak type estimates for a broad class of operators on homogeneous type spaces, with significant applications in harmonic analysis and spectral theory."}}
{"id": "2509.08256", "pdf": "https://arxiv.org/pdf/2509.08256", "abs": "https://arxiv.org/abs/2509.08256", "authors": ["Yitong He", "Pengcheng Xie"], "title": "Model-Driven Subspaces for Large-Scale Optimization with Local Approximation Strategy", "categories": ["math.OC", "cs.NA", "math.NA", "90C26, 90C30, 65K05, 49M37"], "comment": "27 pages, 6 figures", "summary": "Solving large-scale optimization problems is a bottleneck and is very\nimportant for machine learning and multiple kinds of scientific problems.\nSubspace-based methods using the local approximation strategy are one of the\nmost important methods. This paper discusses different and novel kinds of\nadvanced subspaces for such methods and presents a new algorithm with such\nsubspaces, called MD-LAMBO. Theoretical analysis including the subspaces'\nproperties, sufficient function value decrease, and global convergence is given\nfor the new algorithm. The related model construction on the subspaces is given\nunder derivative-free settings. In numerical results, performance profiles, and\ntruncated Newton step errors of MD-LAMBO using different model-driven subspaces\nare provided, which show subspace-dependent numerical differences and\nadvantages of our methods and subspaces.", "AI": {"tldr": "MD-LAMBO: A new subspace optimization algorithm with advanced model-driven subspaces for large-scale problems, featuring theoretical convergence guarantees and strong numerical performance.", "motivation": "Large-scale optimization is critical for machine learning and scientific problems, but remains computationally challenging. Subspace methods using local approximation are important but need improved subspace constructions.", "method": "Proposes MD-LAMBO algorithm with novel model-driven subspaces. Provides theoretical analysis of subspace properties, sufficient function decrease, and global convergence. Includes derivative-free model construction on subspaces.", "result": "Numerical results show subspace-dependent performance differences and advantages of the proposed methods. Performance profiles and truncated Newton step errors demonstrate effectiveness.", "conclusion": "The new MD-LAMBO algorithm with advanced subspaces provides theoretical guarantees and practical advantages for large-scale optimization problems, outperforming existing subspace methods."}}
{"id": "2509.08412", "pdf": "https://arxiv.org/pdf/2509.08412", "abs": "https://arxiv.org/abs/2509.08412", "authors": ["Vladimir Lotoreichik", "L\u00e9o Morin"], "title": "On shape optimization with large magnetic fields in two dimensions", "categories": ["math.SP", "math.AP"], "comment": "15 pages", "summary": "This paper aims to show that, in the limit of strong magnetic fields, the\noptimal domains for eigenvalues of magnetic Laplacians tend to exhibit\nsymmetry. We establish several asymptotic bounds on magnetic eigenvalues to\nsupport this conclusion. Our main result implies that if, for a bounded\nsimply-connected planar domain, the n-th eigenvalue of the magnetic Dirichlet\nLaplacian with uniform magnetic field is smaller than the corresponding\neigenvalue for a disk of the same area, then the Fraenkel asymmetry of that\ndomain tends to zero in the strong magnetic field limit. Comparable results are\nalso derived for the magnetic Dirichlet Laplacian on rectangles, as well as the\nmagnetic Dirac operator with infinite mass boundary conditions on smooth\ndomains. As part of our analysis, we additionally provide a new estimate for\nthe torsion function on rectangles.", "AI": {"tldr": "In strong magnetic fields, optimal domains for magnetic Laplacian eigenvalues become symmetric. If a domain's nth eigenvalue is smaller than a disk's, its asymmetry tends to zero in strong field limit.", "motivation": "To demonstrate that symmetry emerges as the optimal configuration for magnetic Laplacian eigenvalues in the limit of strong magnetic fields.", "method": "Established asymptotic bounds on magnetic eigenvalues, analyzed magnetic Dirichlet Laplacian on bounded simply-connected planar domains and rectangles, and studied magnetic Dirac operator with infinite mass boundary conditions.", "result": "Main result shows that when a domain's nth magnetic eigenvalue is smaller than a disk's equivalent, the domain's Fraenkel asymmetry approaches zero in strong magnetic field limit. Also provided new torsion function estimate for rectangles.", "conclusion": "Strong magnetic fields drive optimal domains toward symmetry, with domain asymmetry vanishing when eigenvalues outperform those of symmetric reference domains."}}
{"id": "2509.08429", "pdf": "https://arxiv.org/pdf/2509.08429", "abs": "https://arxiv.org/abs/2509.08429", "authors": ["Yiran Xu", "Guangbin Wang", "Changqing Xu"], "title": "Tensor Forms of Derivatives of Matrices and their applications in the Solutions to Differential Equations", "categories": ["math.CA", "cs.NA", "math.AG", "math.NA", "53A45, 15A69"], "comment": "35 pages, 0 figures", "summary": "We introduce and extend the outer product and contractive product of tensors\nand matrices, and present some identities in terms of these products. We offer\ntensor expressions of derivatives of tensors, focus on the tensor forms of\nderivatives of a matrix w.r.t. another matrix. This tensor form makes possible\nfor us to unify ordinary differential equations (ODEs) with partial\ndifferential equations (PDEs), and facilitates solution to them in some cases.\nFor our purpose, we also extend the outer product and contractive product of\ntensors (matrices) to a more general case through any partition of the modes,\npresent some identities in terms of these products, initialize the definition\nof partial Tucker decompositions (TuckD) of a tensor, and use the partial TuckD\nto simplify the PDEs. We also present a tensor form for the Lyapunov function.\nOur results in the products of tensors and matrices help us to establish some\nimportant equalities on the derivatives of matrices and tensors. An algorithm\nbased on the partial Tucker decompositions (TuckD) to solve the PDEs is given,\nand a numerical example is presented to illustrate the efficiency of the\nalgorithm.", "AI": {"tldr": "The paper introduces extended tensor products (outer and contractive) and uses them to unify ODEs and PDEs through tensor calculus, developing a partial Tucker decomposition-based algorithm for solving PDEs.", "motivation": "To develop tensor calculus tools that can unify ordinary and partial differential equations and facilitate their solution through tensor-based methods.", "method": "Extends outer and contractive tensor products, defines partial Tucker decompositions, derives tensor expressions for matrix derivatives, and develops an algorithm using partial TuckD for PDE solutions.", "result": "Establishes tensor identities for derivatives, provides a unified framework for ODEs and PDEs, presents tensor form for Lyapunov function, and demonstrates efficient PDE solution algorithm with numerical example.", "conclusion": "The extended tensor products and partial Tucker decompositions provide powerful tools for unifying differential equations and developing efficient numerical solutions for PDEs."}}
{"id": "2509.08483", "pdf": "https://arxiv.org/pdf/2509.08483", "abs": "https://arxiv.org/abs/2509.08483", "authors": ["Matias D. Cattaneo", "Boris Shigida"], "title": "Modified Loss of Momentum Gradient Descent: Fine-Grained Analysis", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "stat.CO", "stat.ML"], "comment": null, "summary": "We analyze gradient descent with Polyak heavy-ball momentum (HB) whose fixed\nmomentum parameter $\\beta \\in (0, 1)$ provides exponential decay of memory.\nBuilding on Kovachki and Stuart (2021), we prove that on an exponentially\nattractive invariant manifold the algorithm is exactly plain gradient descent\nwith a modified loss, provided that the step size $h$ is small enough. Although\nthe modified loss does not admit a closed-form expression, we describe it with\narbitrary precision and prove global (finite \"time\" horizon) approximation\nbounds $O(h^{R})$ for any finite order $R \\geq 2$. We then conduct a\nfine-grained analysis of the combinatorics underlying the memoryless\napproximations of HB, in particular, finding a rich family of polynomials in\n$\\beta$ hidden inside which contains Eulerian and Narayana polynomials. We\nderive continuous modified equations of arbitrary approximation order (with\nrigorous bounds) and the principal flow that approximates the HB dynamics,\ngeneralizing Rosca et al. (2023). Approximation theorems cover both full-batch\nand mini-batch HB. Our theoretical results shed new light on the main features\nof gradient descent with heavy-ball momentum, and outline a road-map for\nsimilar analysis of other optimization algorithms.", "AI": {"tldr": "Analysis of Polyak heavy-ball momentum gradient descent showing it's equivalent to plain gradient descent with a modified loss on attractive manifolds, with high-order approximation bounds and combinatorial insights.", "motivation": "To understand the mathematical structure and behavior of gradient descent with heavy-ball momentum, particularly its equivalence to plain gradient descent with modified loss and the combinatorial properties underlying its memoryless approximations.", "method": "Proved that on exponentially attractive invariant manifolds, HB is exactly plain GD with modified loss for small step sizes. Derived global approximation bounds O(h^R) for any finite order R. Conducted combinatorial analysis of memoryless approximations and derived continuous modified equations.", "result": "Established rigorous approximation bounds, revealed rich polynomial family containing Eulerian and Narayana polynomials, derived continuous modified equations of arbitrary order, and generalized principal flow approximation for HB dynamics.", "conclusion": "The analysis provides new insights into heavy-ball momentum features and establishes a framework for similar analysis of other optimization algorithms, with applications covering both full-batch and mini-batch settings."}}
{"id": "2509.08471", "pdf": "https://arxiv.org/pdf/2509.08471", "abs": "https://arxiv.org/abs/2509.08471", "authors": ["Haiyang Lin", "Bo You"], "title": "Hierarchical exact controllability for a parabolic equation with Hardy potential", "categories": ["math.OC", "math.AP"], "comment": null, "summary": "The main objective of this paper is to study the hierarchical exact\ncontrollability for a parabolic equation with Hardy potential by\nStackelberg-Nash strategy. In linear case, we employ Lax-Milgram theorem to\nprove the existence of an associated Nash equilibrium pair corresponding to a\nbi-objective optimal control problem for each leader, which is responsible for\nan exact controllability property. Then the observability inequality of a\ncoupled parabolic system is established by using global Carleman inequalities,\nwhich results in the existence of a leader that drives the controlled system\nexactly to any prescribed trajectory. In semilinear case, we first prove the\nwell-posedness of the coupled parabolic system to obtain the existence of Nash\nquasi-equilibrium pair and show that Nash quasi-equilibrium is equivalent to\nNash equilibrium. Based on these results, we establish the existence of a\nleader that drives the controlled system exactly to a prescribed (but\narbitrary) trajectory by Leray-Schauder fixed point theorem.", "AI": {"tldr": "Hierarchical exact controllability study for parabolic equations with Hardy potential using Stackelberg-Nash strategy, covering both linear and semilinear cases with different mathematical approaches.", "motivation": "To investigate exact controllability for parabolic equations with Hardy potential through a hierarchical control framework using Stackelberg-Nash strategy, addressing both linear and nonlinear cases.", "method": "For linear case: Lax-Milgram theorem for Nash equilibrium existence, global Carleman inequalities for observability. For semilinear case: well-posedness analysis of coupled systems, Leray-Schauder fixed point theorem for exact controllability.", "result": "Proved existence of Nash equilibrium pairs for bi-objective optimal control, established observability inequalities, and demonstrated exact controllability to arbitrary prescribed trajectories in both linear and semilinear cases.", "conclusion": "The Stackelberg-Nash strategy successfully achieves hierarchical exact controllability for parabolic equations with Hardy potential, with mathematical foundations established for both linear and semilinear formulations."}}
{"id": "2509.08547", "pdf": "https://arxiv.org/pdf/2509.08547", "abs": "https://arxiv.org/abs/2509.08547", "authors": ["Alberto Gonz\u00e1lez-Sanz", "Marcel Nutz", "Andr\u00e9s Riveros Valdevenito"], "title": "Linear Convergence of Gradient Descent for Quadratically Regularized Optimal Transport", "categories": ["math.OC", "math.AP", "math.FA", "math.PR", "49N10, 49N05, 90C25"], "comment": null, "summary": "In optimal transport, quadratic regularization is an alternative to entropic\nregularization when sparse couplings or small regularization parameters are\ndesired. Here quadratic regularization means that transport couplings are\npenalized by the squared $L^2$ norm, or equivalently the $\\chi^2$ divergence.\nWhile a number of computational approaches have been shown to work in practice,\nquadratic regularization is analytically less tractable than entropic, and we\nare not aware of a previous theoretical convergence rate analysis. We focus on\nthe gradient descent algorithm for the dual transport problem in continuous and\nsemi-discrete settings. This problem is convex but not strongly convex; its\nsolutions are the potential functions that approximate the Kantorovich\npotentials of unregularized optimal transport. The gradient descent steps are\nstraightforward to implement, and stable for small regularization parameter --\nin contrast to Sinkhorn's algorithm in the entropic setting. Our main result is\nthat gradient descent converges linearly; that is, the $L^2$ distance between\nthe iterates and the limiting potentials decreases exponentially fast. Our\nanalysis centers on the linearization of the gradient descent operator at the\noptimum and uses functional-analytic arguments to bound its spectrum. These\ntechniques seem to be novel in this area and are substantially different from\nthe approaches familiar in entropic optimal transport.", "AI": {"tldr": "Quadratic regularization in optimal transport enables sparse couplings and small regularization parameters. Gradient descent for the dual problem converges linearly with exponential error reduction, unlike entropic regularization approaches.", "motivation": "Quadratic regularization is preferred over entropic regularization when sparse transport couplings or small regularization parameters are needed, but it lacks theoretical convergence analysis despite practical computational approaches.", "method": "Gradient descent algorithm applied to the dual transport problem in continuous and semi-discrete settings. The method involves analyzing the linearization of the gradient descent operator at the optimum using functional-analytic arguments to bound its spectrum.", "result": "Gradient descent converges linearly - the L\u00b2 distance between iterates and limiting potentials decreases exponentially fast. The algorithm is stable for small regularization parameters and straightforward to implement.", "conclusion": "Quadratic regularization with gradient descent provides an analytically tractable alternative to entropic regularization, offering linear convergence and stability for small regularization parameters, with novel functional-analytic techniques for convergence analysis."}}
{"id": "2509.08799", "pdf": "https://arxiv.org/pdf/2509.08799", "abs": "https://arxiv.org/abs/2509.08799", "authors": ["Adrien Cances", "Hugo Leclerc"], "title": "Unidimensional semi-discrete partial optimal transport", "categories": ["math.OC", "cs.NA", "math.NA"], "comment": null, "summary": "We study the semi-discrete formulation of one-dimensional partial optimal\ntransport with quadratic cost, where a probability density is partially\ntransported to a finite sum of Dirac masses of smaller total mass. This problem\narises naturally in applications such as risk management, the modeling of crowd\nmotion, and sliced partial transport algorithms for point cloud registration.\nUnlike higher-dimensional settings, the dual functional in the unidimensional\ncase exhibits reduced regularity. To overcome this difficulty, we introduce a\nregularization procedure based on thickening the density along an auxiliary\ndimension. We prove that the maximizers of the regularized dual problem\nconverge to those of the original dual problem, with quadratic rate in the\nintroduced thickness. We further provide a numerical scheme that leverages the\nregularized functional, and we validate our analysis with simulations that\nconfirm the quadratic convergence rate. Finally, we compare the semi-discrete\nand fully discrete settings, demonstrating that our approach offers both\nimproved stability and computational efficiency for unidimensional partial\ntransport problems.", "AI": {"tldr": "This paper studies 1D partial optimal transport with quadratic cost, introducing a regularization method using auxiliary dimension thickening to handle reduced dual functional regularity, proving quadratic convergence and demonstrating improved stability and efficiency.", "motivation": "Addressing the reduced regularity of dual functionals in unidimensional partial optimal transport problems that arise in risk management, crowd motion modeling, and point cloud registration applications.", "method": "Introduce a regularization procedure based on thickening the probability density along an auxiliary dimension, prove convergence of maximizers with quadratic rate, and develop a numerical scheme leveraging the regularized functional.", "result": "The maximizers of the regularized dual problem converge to those of the original dual problem with quadratic rate in thickness, and simulations confirm this quadratic convergence rate.", "conclusion": "The proposed approach offers both improved stability and computational efficiency for unidimensional partial transport problems compared to fully discrete settings."}}
{"id": "2509.08560", "pdf": "https://arxiv.org/pdf/2509.08560", "abs": "https://arxiv.org/abs/2509.08560", "authors": ["Francesco Pedrotti", "Justin Salez"], "title": "A transport approach to the cutoff phenomenon", "categories": ["math.PR", "math.AP", "math.ST", "stat.ML", "stat.TH"], "comment": "11 pages", "summary": "Substantial progress has recently been made in the understanding of the\ncutoff phenomenon for Markov processes, using an information-theoretic\nstatistics known as varentropy [Sal23; Sal24; Sal25a; PS25]. In the present\npaper, we propose an alternative approach which bypasses the use of varentropy\nand exploits instead a new W-TV transport inequality, combined with a classical\nparabolic regularization estimate [BGL01; OV01]. While currently restricted to\nnon-negatively curved processes on smooth spaces, our argument no longer\nrequires the chain rule, nor any approximate version thereof. As applications,\nwe recover the main result of [Sal25a] establishing cutoff for the log-concave\nLangevin dynamics, and extend the conclusion to a widely-used discrete-time\nsampling algorithm known as the Proximal Sampler.", "AI": {"tldr": "New approach for cutoff phenomenon analysis using W-TV transport inequality instead of varentropy, applicable to non-negatively curved processes on smooth spaces.", "motivation": "Recent progress in understanding cutoff phenomenon for Markov processes relied on varentropy statistics, but this approach requires chain rule approximations. The authors seek an alternative method that bypasses these limitations.", "method": "Proposes a new approach using W-TV transport inequality combined with classical parabolic regularization estimates. This method eliminates the need for chain rule or approximate versions thereof, though currently restricted to non-negatively curved processes on smooth spaces.", "result": "Successfully recovers the main result establishing cutoff for log-concave Langevin dynamics from previous work, and extends the conclusion to the Proximal Sampler discrete-time sampling algorithm.", "conclusion": "The new W-TV transport inequality approach provides an effective alternative to varentropy-based methods for analyzing cutoff phenomena, with broader applicability to both continuous and discrete-time sampling algorithms."}}
{"id": "2509.08588", "pdf": "https://arxiv.org/pdf/2509.08588", "abs": "https://arxiv.org/abs/2509.08588", "authors": ["Yao Wan"], "title": "Uniqueness of $S_2$-isotropic solutions to the isotropic $L_p$ Minkowski problem", "categories": ["math.DG", "math.AP", "math.MG", "53A07, 35A02, 52A20"], "comment": "21 pages. All comments are welcome", "summary": "This paper investigates the spectral properties of the\nHilbert-Brunn-Minkowski operator $L_K$ to derive stability estimates for\ngeometric inequalities, including the local Brunn-Minkowski inequality. By\nanalyzing the eigenvalues of $L_K$, we establish the uniqueness of\n$S_2$-isotropic solutions to the isotropic $L_p$ Minkowski problem in\n$\\mathbb{R}^{n}$ for $\\frac{1-3n^2}{2n}\\leq p<-n$ with $\\lambda_2(-L_K)\\geq\n\\frac{n-1}{2n-1+p}$. Furthermore, we extend this uniqueness result to the range\n$-2n-1 \\leq p<-n$ with $\\lambda_2(-L_K)\\geq \\frac{-p-1}{n-1}$, assuming the\norigin-centred condition.", "AI": {"tldr": "Spectral analysis of Hilbert-Brunn-Minkowski operator provides stability estimates for geometric inequalities and establishes uniqueness of S\u2082-isotropic solutions to L_p Minkowski problem in specific parameter ranges.", "motivation": "To derive stability estimates for geometric inequalities and establish uniqueness results for solutions to the isotropic L_p Minkowski problem through spectral analysis of the Hilbert-Brunn-Minkowski operator.", "method": "Analyzing eigenvalues of the Hilbert-Brunn-Minkowski operator L_K to establish spectral properties and derive stability estimates for geometric inequalities.", "result": "Proved uniqueness of S\u2082-isotropic solutions to isotropic L_p Minkowski problem for (1-3n\u00b2)/2n \u2264 p < -n with \u03bb\u2082(-L_K) \u2265 (n-1)/(2n-1+p), and extended to -2n-1 \u2264 p < -n with \u03bb\u2082(-L_K) \u2265 (-p-1)/(n-1) under origin-centered condition.", "conclusion": "Spectral analysis of the Hilbert-Brunn-Minkowski operator provides powerful tools for establishing stability of geometric inequalities and uniqueness results for Minkowski problems across extended parameter ranges."}}
{"id": "2509.08641", "pdf": "https://arxiv.org/pdf/2509.08641", "abs": "https://arxiv.org/abs/2509.08641", "authors": ["Meng Yang"], "title": "On the dichotomy of $p$-walk dimensions on metric measure spaces", "categories": ["math.FA", "math.AP", "math.MG", "31E05, 28A80"], "comment": "21 pages", "summary": "On a volume doubling metric measure space endowed with a family of\n$p$-energies such that the Poincar\\'e inequality and the cutoff Sobolev\ninequality with $p$-walk dimension $\\beta_p$ hold, for $p$ in an open interval\n$I\\subseteq (1,+\\infty)$, we prove the following dichotomy: either $\\beta_p=p$\nfor all $p\\in I$, or $\\beta_p>p$ for all $p\\in I$.", "AI": {"tldr": "The paper establishes a dichotomy for p-energy functionals on metric measure spaces: either the p-walk dimension \u03b2_p equals p for all p in an interval I, or \u03b2_p is strictly greater than p for all p in I.", "motivation": "To understand the relationship between p-energy functionals and geometric properties of metric measure spaces, particularly how the p-walk dimension \u03b2_p behaves across different values of p.", "method": "The analysis is conducted on volume doubling metric measure spaces with p-energies satisfying Poincar\u00e9 inequality and cutoff Sobolev inequality with p-walk dimension \u03b2_p.", "result": "A clear dichotomy is proven: for p in an open interval I \u2286 (1,\u221e), either \u03b2_p = p for all p \u2208 I, or \u03b2_p > p for all p \u2208 I.", "conclusion": "The p-walk dimension \u03b2_p cannot exhibit mixed behavior within an interval - it must either consistently equal p or consistently exceed p throughout the entire interval."}}
