{"id": "2509.12209", "pdf": "https://arxiv.org/pdf/2509.12209", "abs": "https://arxiv.org/abs/2509.12209", "authors": ["Devank Mishra", "Sheerin Kayenat", "Amit K. Verma"], "title": "Generalized Non-Standard Finite Difference Method for Fractional PDEs on Non-Uniform Grids", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper proposes a novel Generalized Non-Standard Finite Difference\n(GNSFD) scheme for the numerical solution of a class of fractional partial\ndifferential equations (FrPDEs). The formulation of the method is grounded in\noptimization and leverages the fractional Taylor series (FrTS) expansion\nassociated with Caputo fractional derivatives (FrDs). To discretize the time\nderivatives, the non-trivial denominator functions are utilized. The\ntheoretical analysis establishes the consistency, stability, and convergence of\nthe proposed scheme. Results are compared against existing methods to\nsubstantiate the accuracy and computational efficiency of the approach.", "AI": {"tldr": "A novel Generalized Non-Standard Finite Difference (GNSFD) scheme for solving fractional partial differential equations using optimization and fractional Taylor series with Caputo derivatives.", "motivation": "To develop an accurate and computationally efficient numerical method for solving fractional partial differential equations, addressing limitations of existing approaches.", "method": "Uses optimization and fractional Taylor series expansion with Caputo fractional derivatives, employing non-trivial denominator functions for time derivative discretization.", "result": "Theoretical analysis confirms consistency, stability, and convergence. Comparisons show improved accuracy and computational efficiency over existing methods.", "conclusion": "The proposed GNSFD scheme provides an effective numerical solution for fractional PDEs with proven theoretical properties and superior performance compared to current methods."}}
{"id": "2509.12220", "pdf": "https://arxiv.org/pdf/2509.12220", "abs": "https://arxiv.org/abs/2509.12220", "authors": ["Hardeep Bassi", "Yuanran Zhu", "Erika Ye", "Pu Ren", "Alec Dektor", "Harish S. Bhat", "Chao Yang"], "title": "SRaFTE: Super-Resolution and Future Time Extrapolation for Time-Dependent PDEs", "categories": ["math.NA", "cs.NA", "math.AP"], "comment": null, "summary": "We present SRaFTE (Super-Resolution and Future Time Extrapolation), a\ntwo-phase learning framework that couples coarse grid solvers with neural\noperators to super-resolve and forecast fine grid dynamics for time-dependent\npartial differential equations (PDEs). In our construction, Phase 1 learns a\nsuper-resolution map from coarse to fine solutions, while Phase 2 embeds this\noperator in a predictor-corrector loop with the coarse solver, forming an\noperator composition that serves as a surrogate fine grid propagator for\nfuture-time extrapolation. We benchmark SRaFTE on three canonical\ntwo-dimensional PDEs of increasing dynamical complexity: the heat equation, the\nwave equation, and the incompressible Navier-Stokes equations. Compared to\nwell-known benchmarks, SRaFTE provides reliable super-resolution in Phase 1 and\ndelivers consistently accurate long-term forecasts in Phase 2 across all three\nexamples for new test data. Our results suggest that coupling a learned\nsuper-resolution operator with a coarse grid solver provides an effective and\nefficient means of modeling high-resolution spatiotemporal dynamics,\nparticularly when the dynamics of the PDEs at the coarse and fine resolutions\nexhibit pronounced scale separation.", "AI": {"tldr": "SRaFTE is a two-phase framework that combines coarse grid solvers with neural operators to super-resolve and forecast fine grid dynamics for time-dependent PDEs, achieving reliable super-resolution and accurate long-term forecasts.", "motivation": "To develop an efficient method for modeling high-resolution spatiotemporal dynamics of PDEs by coupling learned super-resolution operators with coarse grid solvers, particularly when there's scale separation between coarse and fine resolutions.", "method": "Two-phase learning: Phase 1 learns super-resolution map from coarse to fine solutions; Phase 2 embeds this operator in predictor-corrector loop with coarse solver to form surrogate fine grid propagator for future-time extrapolation.", "result": "Benchmarked on heat equation, wave equation, and Navier-Stokes equations, SRaFTE provides reliable super-resolution and consistently accurate long-term forecasts across all three examples for new test data.", "conclusion": "Coupling learned super-resolution operators with coarse grid solvers provides effective and efficient means for modeling high-resolution spatiotemporal dynamics, especially when pronounced scale separation exists between coarse and fine resolutions."}}
{"id": "2509.12228", "pdf": "https://arxiv.org/pdf/2509.12228", "abs": "https://arxiv.org/abs/2509.12228", "authors": ["Cameron Rodriguez", "Irina Tezaur", "Alejandro Mota", "Anthony Gruber", "Eric Parish", "Christopher Wentland"], "title": "Transmission Conditions for the Non-Overlapping Schwarz Coupling of Full Order and Operator Inference Models", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This work investigates transmission conditions for the domain\ndecomposition-based coupling of subdomain-local models using the\nnon-overlapping Schwarz alternating method (NO-SAM). Building on prior efforts\ninvolving overlapping SAM (O-SAM), we formulate and assess two NO-SAM variants,\nbased on alternating Dirichlet-Neumann and Robin-Robin transmission conditions.\nFor the subdomain-local models, we consider a mix of full order models (FOMs)\nand non-intrusive reduced order models (ROMs) constructed via an emerging model\nreduction technique known as operator inference (OpInf). Of particular novelty\nis the first application of NO-SAM to couple non-intrusive OpInf ROMs with each\nother, and with FOMs. Numerical studies on a one-dimensional linear elastic\nwave propagation benchmark problem demonstrate that transmission condition\nchoice and parameter tuning significantly impact convergence rate, accuracy,\nand stability. Robin-Robin coupling often yields faster convergence than\nalternating Dirichlet-Neumann, though improper parameter selection can induce\nspurious oscillations at subdomain interfaces. For FOM-OpInf and OpInf-OpInf\ncouplings, sufficient modal content in the ROM basis improves accuracy and\nmitigates instability, in some cases outperforming the coupled FOM-FOM\nreference solutions in both accuracy and efficiency. These findings highlight\nNO-SAM's potential for enabling flexible, non-intrusive, and efficient\nmulti-model coupling across independently meshed subdomains, while emphasizing\nthe need for careful interface condition design in higher-dimensional and\npredictive settings.", "AI": {"tldr": "This paper investigates non-overlapping Schwarz alternating method (NO-SAM) for coupling different computational models using Dirichlet-Neumann and Robin-Robin transmission conditions, with focus on coupling full order models with non-intrusive reduced order models via operator inference.", "motivation": "To develop flexible and efficient domain decomposition methods for coupling different computational models (FOMs and ROMs) across independently meshed subdomains using non-overlapping Schwarz methods, building on previous overlapping SAM research.", "method": "Formulated and assessed two NO-SAM variants with alternating Dirichlet-Neumann and Robin-Robin transmission conditions. Used operator inference (OpInf) for non-intrusive ROM construction. Tested on 1D linear elastic wave propagation benchmark.", "result": "Robin-Robin coupling often yields faster convergence than alternating Dirichlet-Neumann, but improper parameter selection can cause interface oscillations. FOM-OpInf and OpInf-OpInf couplings with sufficient modal content can outperform FOM-FOM references in accuracy and efficiency.", "conclusion": "NO-SAM shows potential for flexible, non-intrusive multi-model coupling across independently meshed subdomains, but requires careful interface condition design, especially for higher-dimensional applications."}}
{"id": "2509.12243", "pdf": "https://arxiv.org/pdf/2509.12243", "abs": "https://arxiv.org/abs/2509.12243", "authors": ["Murray Cutforth", "Tiffany Fan", "Tony Zahtila", "Alireza Doostan", "Eric Darve"], "title": "Bi-fidelity Interpolative Decomposition for Multimodal Data", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Multi-fidelity simulation is a widely used strategy to reduce the\ncomputational cost of many-query numerical simulation tasks such as uncertainty\nquantification, design space exploration, and design optimization. The reduced\nbasis approach based on bi-fidelity interpolative decomposition is one such\napproach, which identifies a reduced basis, along with an interpolation rule in\nthat basis, from low-fidelity samples to approximate the corresponding\nhigh-fidelity samples. However, as illustrated in the present study, when the\nmodel response is multi-modal and mode occupancy is stochastic, the assumptions\nunderpinning this approach may not hold, thus leading to inaccurate estimates.\nWe introduce the multi-modal interpolative decomposition method using\nbi-fidelity data, an extension tailored for this use case. Our work is\nmotivated by a complex engineering application: a laser-ignited methane-oxygen\nrocket combustor evaluated over uncertain input parameters, exhibiting a\nbifurcation-like phenomenon in some regions of parameter space. Unlike the\nstandard bi-fidelity interpolative decomposition approach, the proposed method\ncan approximate a dataset of high-fidelity simulations for 16\\% of the cost,\nwhile maintaining relatively high correlation (0.70--0.90) with parameter\nsensitivities.", "AI": {"tldr": "A new multi-modal interpolative decomposition method for bi-fidelity simulations that handles stochastic multi-modal responses, achieving 16% cost reduction while maintaining high correlation with parameter sensitivities.", "motivation": "Standard bi-fidelity interpolative decomposition fails when model response is multi-modal with stochastic mode occupancy, as in laser-ignited methane-oxygen rocket combustor applications with bifurcation phenomena.", "method": "Multi-modal interpolative decomposition method using bi-fidelity data, specifically designed to handle stochastic multi-modal responses where traditional approaches break down.", "result": "The method approximates high-fidelity simulations for only 16% of the cost while maintaining high correlation (0.70-0.90) with parameter sensitivities.", "conclusion": "The proposed multi-modal extension successfully addresses limitations of standard bi-fidelity approaches for complex engineering applications with stochastic multi-modal behavior."}}
{"id": "2509.12349", "pdf": "https://arxiv.org/pdf/2509.12349", "abs": "https://arxiv.org/abs/2509.12349", "authors": ["Tommaso Bruno", "Effie Papageorgiou"], "title": "Blow-up exponents and a semilinear elliptic equation for the fractional Laplacian on hyperbolic spaces", "categories": ["math.AP", "35J60, 26A33, 43A85, 22E30"], "comment": null, "summary": "Let $\\mathbb{H}^n$ be the $n$-dimensional real hyperbolic space, $\\Delta$ its\nnonnegative Laplace--Beltrami operator whose bottom of the spectrum we denote\nby $\\lambda_{0}$, and $\\sigma \\in (0,1)$.\n  The aim of this paper is twofold. On the one hand, we determine the Fujita\nexponent for the fractional heat equation \\[\\partial_{t} u + \\Delta^{\\sigma}u =\ne^{\\beta t}|u|^{\\gamma-1}u,\\] by proving that nontrivial positive global\nsolutions exist if and only if $\\gamma\\geq 1 + \\beta/ \\lambda_{0}^{\\sigma}$. On\nthe other hand, we prove the existence of non-negative, bounded and finite\nenergy solutions of the semilinear fractional elliptic equation \\[\n  \\Delta^{\\sigma} v - \\lambda^{\\sigma} v - v^{\\gamma}=0 \\] for $0\\leq \\lambda\n\\leq \\lambda_{0}$ and $1<\\gamma< \\frac{n+2\\sigma}{n-2\\sigma}$. The two problems\nare known to be connected and the latter, aside from its independent interest,\nis actually instrumental to the former.\n  \\smallskip\n  At the core of our results stands a novel fractional Poincar\\'e-type\ninequality expressed in terms of a new scale of $L^{2}$ fractional Sobolev\nspaces, which sharpens those known so far, and which holds more generally on\nRiemannian symmetric spaces of non-compact type. We also establish an\nassociated Rellich--Kondrachov-like compact embedding theorem for radial\nfunctions, along with other related properties.", "AI": {"tldr": "This paper determines the Fujita exponent for fractional heat equations and proves existence of solutions for semilinear fractional elliptic equations on hyperbolic spaces, using novel fractional Poincar\u00e9 inequalities and Sobolev space theory.", "motivation": "To establish precise conditions for existence of global solutions to fractional heat equations and semilinear fractional elliptic equations on hyperbolic spaces, addressing gaps in understanding nonlinear fractional PDEs on non-compact manifolds.", "method": "Develops a new fractional Poincar\u00e9-type inequality using a novel scale of L\u00b2 fractional Sobolev spaces, proves Rellich-Kondrachov-like compact embedding for radial functions, and connects the elliptic and parabolic problems through analytical techniques.", "result": "Determined that nontrivial positive global solutions exist for the fractional heat equation if and only if \u03b3 \u2265 1 + \u03b2/\u03bb\u2080^\u03c3. Proved existence of bounded finite-energy solutions for the semilinear elliptic equation for 0 \u2264 \u03bb \u2264 \u03bb\u2080 and 1 < \u03b3 < (n+2\u03c3)/(n-2\u03c3).", "conclusion": "The paper establishes fundamental existence criteria for fractional nonlinear PDEs on hyperbolic spaces through innovative fractional Sobolev space theory and Poincar\u00e9 inequalities, with applications extending to Riemannian symmetric spaces of non-compact type."}}
{"id": "2509.12665", "pdf": "https://arxiv.org/pdf/2509.12665", "abs": "https://arxiv.org/abs/2509.12665", "authors": ["Domagoj Fijan", "Maria R. Ward Rashidi", "Sharon C. Glotzer"], "title": "Quantifying Local Point-Group-Symmetry Order in Complex Particle Systems", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "cond-mat.soft", "physics.chem-ph"], "comment": null, "summary": "Crystals and other condensed phases are defined primarily by their inherent\nsymmetries, which play a crucial role in dictating their structural properties.\nIn crystallization studies, local order parameters (OPs) that describe bond\norientational order are widely employed to investigate crystal formation.\nDespite their utility, these traditional metrics do not directly quantify\nsymmetry, an important aspect for understanding the development of order during\ncrystallization. To address this gap, we introduce a new set of OPs, called\nPoint Group Order Parameters (PGOPs), designed to continuously quantify point\ngroup symmetry order. We demonstrate the strength and utility of PGOP in\ndetecting order across different crystalline systems and compare its\nperformance to commonly used bond-orientational order metrics. PGOP\ncalculations for all non-infinite point groups are implemented in the\nopen-source package SPATULA (Symmetry Pattern Analysis Toolkit for\nUnderstanding Local Arrangements), written in parallelized C++ with a Python\ninterface. The code is publicly available on GitHub.", "AI": {"tldr": "New Point Group Order Parameters (PGOPs) quantify point group symmetry order in crystals, addressing limitations of traditional bond-orientational order metrics that don't directly measure symmetry.", "motivation": "Traditional local order parameters used in crystallization studies don't directly quantify symmetry, which is crucial for understanding order development during crystallization.", "method": "Developed Point Group Order Parameters (PGOPs) to continuously quantify point group symmetry order, implemented in open-source SPATULA package (parallelized C++ with Python interface).", "result": "PGOPs demonstrate strength in detecting order across different crystalline systems and outperform commonly used bond-orientational order metrics.", "conclusion": "PGOPs provide a more direct and effective way to quantify symmetry in crystallization studies, with publicly available implementation for all non-infinite point groups."}}
{"id": "2509.12397", "pdf": "https://arxiv.org/pdf/2509.12397", "abs": "https://arxiv.org/abs/2509.12397", "authors": ["Sachin Sharma", "Rauoof Wani", "Prabhakar Srivastav", "Meenakshee Sharma", "Sayak Bose", "Sanat Tiwari", "Abhijit Sen"], "title": "Shock wave bending around a dusty plasma void", "categories": ["physics.plasm-ph"], "comment": "10 pages, 8 figures, 2 tables", "summary": "We report on experimental observations of the bending of a dust acoustic\nshock wave around a dust void region. This phenomenon occurs as a planar shock\nwavefront encounters a compressible obstacle in the form of a void whose size\nis larger than the wavelength of the wave. As they collide, the central portion\nof the wavefront, that is the first to touch the void, is blocked while the\nrest of the front continues to propagate, resulting in an inward bending of the\nshock wave. The bent shock wave eventually collapses, leading to the transient\ntrapping of dust particles in the void. Subsequently, a Coulomb explosion of\nthe trapped particles generates a bow shock. The experiments have been carried\nout in a DC glow discharge plasma, where the shock wave and the void are\nsimultaneously created as self-excited modes of a three-dimensional dust cloud.\nThe salient features of this phenomenon are reproduced in molecular dynamics\nsimulations, which provide valuable insights into the underlying dynamics of\nthis interaction.", "AI": {"tldr": "Experimental observation of dust acoustic shock wave bending around a dust void region, showing wavefront deformation, particle trapping, and subsequent Coulomb explosion with bow shock formation.", "motivation": "To study the interaction between planar shock waves and compressible obstacles (voids) in plasma environments, particularly how wavefronts behave when encountering obstacles larger than their wavelength.", "method": "Experiments conducted in a DC glow discharge plasma where shock waves and voids are created as self-excited modes of a three-dimensional dust cloud, complemented by molecular dynamics simulations to reproduce and analyze the phenomenon.", "result": "Observed inward bending of shock wave when encountering void, transient trapping of dust particles in the void, Coulomb explosion of trapped particles, and generation of a bow shock. Molecular dynamics simulations successfully reproduced the key features.", "conclusion": "The study demonstrates complex wave-obstacle interactions in plasma environments, revealing mechanisms of wave bending, particle trapping, and subsequent explosive phenomena that provide insights into fundamental plasma dynamics."}}
{"id": "2509.12271", "pdf": "https://arxiv.org/pdf/2509.12271", "abs": "https://arxiv.org/abs/2509.12271", "authors": ["Vijay Kumar", "Gautam Singh"], "title": "A Variational Physics-Informed Neural Network Framework Using Petrov-Galerkin Method for Solving Singularly Perturbed Boundary Value Problems", "categories": ["math.NA", "cs.AI", "cs.NA", "34D15, 35B25, 65M12, 68T07"], "comment": null, "summary": "This work proposes a Variational Physics-Informed Neural Network (VPINN)\nframework that integrates the Petrov-Galerkin formulation with deep neural\nnetworks (DNNs) for solving one-dimensional singularly perturbed boundary value\nproblems (BVPs) and parabolic partial differential equations (PDEs) involving\none or two small parameters. The method adopts a nonlinear approximation in\nwhich the trial space is defined by neural network functions, while the test\nspace is constructed from hat functions. The weak formulation is constructed\nusing localized test functions, with interface penalty terms introduced to\nenhance numerical stability and accurately capture boundary layers. Dirichlet\nboundary conditions are imposed via hard constraints, and source terms are\ncomputed using automatic differentiation. Numerical experiments on benchmark\nproblems demonstrate the effectiveness of the proposed method, showing\nsignificantly improved accuracy in both the $L_2$ and maximum norms compared to\nthe standard VPINN approach for one-dimensional singularly perturbed\ndifferential equations (SPDEs).", "AI": {"tldr": "VPINN framework combines Petrov-Galerkin formulation with neural networks for solving 1D singularly perturbed BVPs and parabolic PDEs with small parameters, using neural network trial functions and hat function test spaces with interface penalties for stability.", "motivation": "To address the challenges of solving singularly perturbed boundary value problems and parabolic PDEs with small parameters, which often exhibit boundary layers and require specialized numerical methods for accurate resolution.", "method": "Uses variational physics-informed neural networks with Petrov-Galerkin formulation, neural network trial functions, hat function test spaces, localized test functions with interface penalty terms, hard Dirichlet boundary constraints, and automatic differentiation for source terms.", "result": "Numerical experiments show significantly improved accuracy in both L2 and maximum norms compared to standard VPINN approach for one-dimensional singularly perturbed differential equations.", "conclusion": "The proposed VPINN framework with Petrov-Galerkin formulation and specialized test functions effectively handles singularly perturbed problems with improved accuracy and stability over conventional methods."}}
{"id": "2509.12413", "pdf": "https://arxiv.org/pdf/2509.12413", "abs": "https://arxiv.org/abs/2509.12413", "authors": ["Mariya Ptashnyk", "Chandrasekhar Venkataraman"], "title": "Multiscale modelling, analysis and simulation of cancer invasion mediated by bound and soluble enzymes", "categories": ["math.AP", "35Kxx, 92Bxx, 65M60"], "comment": null, "summary": "We formulate a cell-scale model for the degradation of the extra-cellular\nmatrix by membrane-bound and soluble matrix degrading enzymes produced by\ncancer cells. Based on the microscopic model and using tools from the theory of\nhomogenisation we propose a macroscopic model for cancer cell invasion into the\nextra-cellular matrix mediated by bound and soluble matrix degrading enzymes.\nFor suitable and biologically relevant initial data we prove the macroscopic\nmodel is well-posed. We propose a finite element method for the numerical\napproximation of the macroscopic model and report on simulation results\nillustrating the role of the bound and soluble enzymes in cancer invasion\nprocesses.", "AI": {"tldr": "A mathematical model for cancer cell invasion through ECM degradation by membrane-bound and soluble enzymes, with homogenization from microscopic to macroscopic scale, well-posedness proof, and FEM simulations.", "motivation": "To understand how cancer cells invade extracellular matrix through both membrane-bound and soluble matrix degrading enzymes, which is crucial for understanding metastasis mechanisms.", "method": "Developed cell-scale microscopic model, used homogenization theory to derive macroscopic model, proved well-posedness for biologically relevant initial data, implemented finite element method for numerical approximation.", "result": "Established a well-posed macroscopic model for cancer invasion mediated by bound and soluble enzymes, with simulation results demonstrating the roles of different enzyme types in invasion processes.", "conclusion": "The model successfully captures cancer cell invasion dynamics through ECM degradation, providing insights into the distinct contributions of membrane-bound versus soluble enzymes in metastatic processes."}}
{"id": "2509.12837", "pdf": "https://arxiv.org/pdf/2509.12837", "abs": "https://arxiv.org/abs/2509.12837", "authors": ["Kumpei Shiraishi", "Emi Minamitani", "Kang Kim"], "title": "Benchmarking thermostat algorithms in molecular dynamics simulations of a binary Lennard-Jones glass-former model", "categories": ["physics.comp-ph", "cond-mat.soft"], "comment": "25 pages, 14 figures", "summary": "A systematic comparison was carried out to assess the influence of\nrepresentative thermostat methods in constant-temperature molecular dynamics\nsimulations. The thermostat schemes considered include the Nos\\'e--Hoover\nthermostat and its chain generalisation, the Bussi velocity rescaling method,\nand several implementations of the Langevin dynamics. Using a binary\nLennard-Jones liquid as a model glass former, we investigated how the sampling\nof physical observables, such as particle velocities and potential energy,\nresponds to changes in time step across these thermostats. While the\nNos\\'e--Hoover chain and Bussi thermostats provide reliable temperature\ncontrol, a pronounced time-step dependence was observed in the potential\nenergy. Amongst the Langevin methods, the Gr{\\o}nbech-Jensen--Farago scheme\nprovided the most consistent sampling of both temperature and potential energy.\nNonetheless, Langevin dynamics typically incurs approximately twice the\ncomputational cost due to the overhead of random number generation, and\nexhibits a systematic decrease in diffusion coefficients with increasing\nfriction. This study presents a broad comparison of thermostat methods using a\nbinary Lennard-Jones glass-former model, offering practical guidance for the\nchoice of thermostats in classical molecular dynamics simulations. These\nfindings provide useful insights for diverse applications, including glass\ntransition, phase separation, and nucleation.", "AI": {"tldr": "Systematic comparison of thermostat methods in molecular dynamics simulations shows Nos\u00e9-Hoover chain and Bussi thermostats provide reliable temperature control but exhibit time-step dependence in potential energy. Langevin methods, particularly Gr\u00f8nbech-Jensen-Farago scheme, offer consistent sampling but at higher computational cost.", "motivation": "To assess the influence of different thermostat methods in constant-temperature molecular dynamics simulations and provide practical guidance for thermostat selection in classical MD simulations.", "method": "Used a binary Lennard-Jones liquid as a model glass former to investigate how sampling of physical observables (particle velocities and potential energy) responds to time step changes across various thermostat schemes including Nos\u00e9-Hoover, Bussi velocity rescaling, and Langevin dynamics implementations.", "result": "Nos\u00e9-Hoover chain and Bussi thermostats provide reliable temperature control but show pronounced time-step dependence in potential energy. Langevin methods, especially Gr\u00f8nbech-Jensen-Farago scheme, provide most consistent sampling but incur ~2x computational cost and show systematic decrease in diffusion coefficients with increasing friction.", "conclusion": "The study offers practical guidance for thermostat choice in molecular dynamics simulations, with findings applicable to diverse areas including glass transition, phase separation, and nucleation processes."}}
{"id": "2509.12599", "pdf": "https://arxiv.org/pdf/2509.12599", "abs": "https://arxiv.org/abs/2509.12599", "authors": ["M. Yang", "J. F. Parisi", "M. S. Anastopoulos Tzanis", "G. M. Staebler"], "title": "Validation of the GFS model for Gyrokinetic Stability of NSTX Pedestal Data", "categories": ["physics.plasm-ph"], "comment": null, "summary": "This study presents a large database validation of the Gyro Fluid System\n(GFS) model for linear gyrokinetic stability for high-mode (H-mode) edge\ntransport barrier conditions in the National Spherical Torus Experiment (NSTX)\ntokamak. The database of linear stability calculations with the CGYRO\ngyrokinetic code was produced using plasma profile measurements from NSTX\ndischarges to identify kinetic ballooning modes (KBM), trapped electron modes\n(TEM), and micro-tearing modes (MTM) that limit the pressure profile gradient\nin the H-mode barrier. A novel Bayesian optimization approach determines\noptimal resolution parameters for GFS specifically for spherical tokamak\npedestal conditions. Our results demonstrate that GFS, with optimized\nresolution, can achieve accurate linear stability analysis in NSTX pedestal\nconditions for reduced resolution compared to CGYRO. GFS can accurately find\nthe KBM, TEM, and MTM instability branches. Parametric analysis reveals that\nGFS accuracy in this extreme pedestal parameter range is degraded for low\nmagnetic shear and near the separatrix conditions. These findings establish GFS\nas a fast linear eigenmode solver for spherical tokamak pedestal gyrokinetic\nstability and demonstrate a systematic methodology for determining the optimum\nresolution settings.", "AI": {"tldr": "Validation of Gyro Fluid System (GFS) model for linear gyrokinetic stability in NSTX H-mode edge conditions using Bayesian optimization for resolution parameters.", "motivation": "To validate the GFS model for accurate linear stability analysis in spherical tokamak pedestal conditions with reduced computational cost compared to full gyrokinetic codes like CGYRO.", "method": "Used Bayesian optimization to determine optimal resolution parameters for GFS, validated against a database of CGYRO gyrokinetic calculations using NSTX plasma profile measurements to identify various instability modes.", "result": "GFS with optimized resolution achieves accurate linear stability analysis for KBM, TEM, and MTM instability branches in NSTX pedestal conditions, though accuracy degrades for low magnetic shear and near separatrix conditions.", "conclusion": "GFS is established as a fast linear eigenmode solver for spherical tokamak pedestal gyrokinetic stability with a systematic methodology for determining optimal resolution settings."}}
{"id": "2509.12272", "pdf": "https://arxiv.org/pdf/2509.12272", "abs": "https://arxiv.org/abs/2509.12272", "authors": ["Yasuhiro Takei", "Yoritaka Iwata"], "title": "Dynamical symmetry breaking described by cubic nonlinear Klein-Gordon equations", "categories": ["math.NA", "cs.NA", "hep-th", "nlin.AO", "nlin.CD", "Primary 81R40, 81Q05, Secondary 65M70, 65L06"], "comment": "to be published in Springer Proceedings in Mathematics and Statistics\n  (SPMS)", "summary": "The dynamical symmetry breaking associated with the existence and\nnon-existence of breather solutions is studied. Here, nonlinear hyperbolic\nevolution equations are calculated using a high-precision numerical scheme. %%%\nFirst, for clarifying the dynamical symmetry breaking, it is necessary to use a\nsufficiently high-precision scheme in the time-dependent framework. Second, the\nerror of numerical calculations is generally more easily accumulated for\ncalculating hyperbolic equations rather than parabolic equations. Third,\nnumerical calculations become easily unstable for nonlinear cases. Our strategy\nfor the high-precision and stable scheme is to implement the implicit\nRunge-Kutta method for time, and the Fourier spectral decomposition for space.\n%%% In this paper, focusing on the breather solutions, the relationship between\nthe velocity, mass, and the amplitude of the perturbation is clarified. As a\nresult, the conditions for transitioning from one state to another are\nclarified.", "AI": {"tldr": "Study of dynamical symmetry breaking through breather solutions in nonlinear hyperbolic equations using high-precision numerical methods", "motivation": "To understand dynamical symmetry breaking associated with breather solutions, which requires high-precision numerical schemes due to error accumulation and instability issues in nonlinear hyperbolic equations", "method": "Implicit Runge-Kutta method for time integration and Fourier spectral decomposition for spatial discretization to achieve high precision and stability", "result": "Clarified the relationship between velocity, mass, and perturbation amplitude for breather solutions, identifying conditions for state transitions", "conclusion": "Successfully established transition conditions between different states through high-precision numerical analysis of breather solutions in nonlinear hyperbolic equations"}}
{"id": "2509.12424", "pdf": "https://arxiv.org/pdf/2509.12424", "abs": "https://arxiv.org/abs/2509.12424", "authors": ["Benjamin Dodson", "Shi-Zhuo Looi"], "title": "Quantitative Scattering for the Energy-Critical Wave Equation on Asymptotically Flat Spacetimes", "categories": ["math.AP"], "comment": "22 pages", "summary": "The scattering theory for the energy-critical wave equation on asymptotically\nflat spacetimes has, to date, been qualitative. While the qualitative\nscattering of solutions is well-understood, explicit bounds on the solution's\nglobal spacetime norms have been unavailable in this geometric setting.\n  This paper establishes an explicit, exponential-type global bound on the\nStrichartz norm $\\| u\\|_{L^8_{t,x}}$ for solutions to the defocusing equation\n$\\Box_g u=u^5$, where $\\Box_g$ is the d'Alembertian associated with the\nperturbed metric. The bound depends on the solution's energy and an \\textit{a\npriori} $\\dot H^5 \\times \\dot H^4$ regularity bound on the solution.\n  The proof develops a strategy that bypasses the need for vector-field\ncommutators. It combines an interaction Morawetz estimate adapted to variable\ncoefficients to control the solution's recent history with a dispersive\nanalysis founded on integrated local energy decay to control the remote past.\nThis strategy, in turn, necessitates the regularity and specific decay\nassumptions on the metric.\n  As a result, this work upgrades the existing qualitative scattering theory to\na fully quantitative statement, which provides a concrete measure of the global\nbehavior of solutions in this geometric setting.", "AI": {"tldr": "Explicit exponential-type bound on Strichartz norm for energy-critical wave equation on asymptotically flat spacetimes, upgrading qualitative scattering to quantitative.", "motivation": "While qualitative scattering theory for energy-critical wave equation was established, explicit bounds on global spacetime norms were unavailable in geometric settings with perturbed metrics.", "method": "Develops strategy bypassing vector-field commutators, combining interaction Morawetz estimate adapted to variable coefficients with dispersive analysis based on integrated local energy decay.", "result": "Establishes explicit exponential-type global bound on Strichartz norm ||u||_{L^8_{t,x}} depending on solution's energy and a priori regularity bound.", "conclusion": "Upgrades existing qualitative scattering theory to fully quantitative statement, providing concrete measure of global solution behavior in geometric setting."}}
{"id": "2509.12841", "pdf": "https://arxiv.org/pdf/2509.12841", "abs": "https://arxiv.org/abs/2509.12841", "authors": ["Zhiqiang Cai", "Chengyu Liu", "Xiang Zhou"], "title": "Weak Generative Sampler for Stationary Distributions of McKean-Vlasov System", "categories": ["physics.comp-ph"], "comment": "17 pages, 10 figures", "summary": "Stochastic interacting particle systems are widely used to model collective\nphenomena across diverse fields, including statistical physics, biology, and\nsocial dynamics. The McKean-Vlasov equation arises as the mean-field limit of\nsuch systems as the number of particles tends to infinity, while its long-time\nbehaviour is characterized by stationary distributions as time tends to\ninfinity. However, the validity of interchanging the infinite-time and\ninfinite-particle limits is not guaranteed. Consequently, simulation methods\nthat rely on a finite-particle truncation may fail to accurately capture the\nmean-field system's stationary distributions, particularly when the coexistence\nof multiple metastable states leads to phase transitions. In this paper, we\nadapt the framework of the Weak Generative Sampler (WGS) -- a generative\ntechnique based on normalizing flows and a weak formulation of the nonlinear\nFokker-Planck equation -- to compute and generate i.i.d. samples satisfying the\nstationary distributions of McKean-Vlasov processes. Extensive numerical\nexperiments validate the efficacy of the proposed methods, showcasing their\nability to accurately approximate stationary distributions and capture phase\ntransitions in complex systems.", "AI": {"tldr": "Proposes a Weak Generative Sampler (WGS) method using normalizing flows to compute stationary distributions of McKean-Vlasov processes, addressing limitations of finite-particle simulations in capturing phase transitions.", "motivation": "Finite-particle simulations often fail to accurately capture stationary distributions of mean-field systems, especially when multiple metastable states cause phase transitions, due to the non-interchangeability of infinite-time and infinite-particle limits.", "method": "Adapts the Weak Generative Sampler framework based on normalizing flows and a weak formulation of the nonlinear Fokker-Planck equation to generate i.i.d. samples from stationary distributions.", "result": "Extensive numerical experiments validate the method's efficacy in accurately approximating stationary distributions and capturing phase transitions in complex systems.", "conclusion": "The proposed WGS method provides an effective generative technique for computing stationary distributions of McKean-Vlasov processes, overcoming limitations of traditional finite-particle simulation approaches."}}
{"id": "2509.12945", "pdf": "https://arxiv.org/pdf/2509.12945", "abs": "https://arxiv.org/abs/2509.12945", "authors": ["Zongyu Yang", "Zhenghao Yang", "Wenjing Tian", "Jiyuan Li", "Xiang Sun", "Guohui Zheng", "Songfen Liu", "Niannian Wu", "Rongpeng Li", "Zhaohe Xu", "Bo Li", "Zhongbing Shi", "Zhe Gao", "Wei Chen", "Xiaoquan Ji", "Min Xu", "Wulyu Zhong"], "title": "FusionMAE: large-scale pretrained model to optimize and simplify diagnostic and control of fusion plasma", "categories": ["physics.plasm-ph", "cs.AI"], "comment": null, "summary": "In magnetically confined fusion device, the complex, multiscale, and\nnonlinear dynamics of plasmas necessitate the integration of extensive\ndiagnostic systems to effectively monitor and control plasma behaviour. The\ncomplexity and uncertainty arising from these extensive systems and their\ntangled interrelations has long posed a significant obstacle to the\nacceleration of fusion energy development. In this work, a large-scale model,\nfusion masked auto-encoder (FusionMAE) is pre-trained to compress the\ninformation from 88 diagnostic signals into a concrete embedding, to provide a\nunified interface between diagnostic systems and control actuators. Two\nmechanisms are proposed to ensure a meaningful embedding: compression-reduction\nand missing-signal reconstruction. Upon completion of pre-training, the model\nacquires the capability for 'virtual backup diagnosis', enabling the inference\nof missing diagnostic data with 96.7% reliability. Furthermore, the model\ndemonstrates three emergent capabilities: automatic data analysis, universal\ncontrol-diagnosis interface, and enhancement of control performance on multiple\ntasks. This work pioneers large-scale AI model integration in fusion energy,\ndemonstrating how pre-trained embeddings can simplify the system interface,\nreducing necessary diagnostic systems and optimize operation performance for\nfuture fusion reactors.", "AI": {"tldr": "FusionMAE model compresses 88 diagnostic signals into unified embeddings, enabling virtual backup diagnosis with 96.7% reliability and emergent capabilities for fusion energy systems.", "motivation": "Complex multiscale plasma dynamics in fusion devices require extensive diagnostic systems, but their complexity and uncertainty hinder fusion energy development acceleration.", "method": "Large-scale masked autoencoder (FusionMAE) pre-trained with compression-reduction and missing-signal reconstruction mechanisms to create unified diagnostic embeddings.", "result": "Achieves 96.7% reliability in virtual backup diagnosis, demonstrates emergent capabilities including automatic data analysis, universal interface, and enhanced control performance.", "conclusion": "Pioneers large-scale AI integration in fusion energy, showing pre-trained embeddings can simplify system interfaces, reduce diagnostic needs, and optimize reactor operations."}}
{"id": "2509.12299", "pdf": "https://arxiv.org/pdf/2509.12299", "abs": "https://arxiv.org/abs/2509.12299", "authors": ["A. E. D. Castillo", "G. A. Lobos", "V. Ramos Batista"], "title": "The Green's Function on Rhombic Flat Tori", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We obtain the Green's function $G$ for any flat rhombic torus $T$, always\nwith numerical values of significant digits up to the fourth decimal place\n(noting that $G$ is unique for $|T|=1$ and $\\int_TGdA=0$). This precision is\nguaranteed by the strategies we adopt, which include theorems such as the\nLegendre Relation, properties of the Weierstra\\ss\\,P-Function, and also the\nalgorithmic control of numerical errors. Our code uses complex integration\nroutines developed by H. Karcher, who also introduced the symmetric\nP-Weierstra\\ss\\,function, and these resources simplify the computation of\nelliptic functions considerably.", "AI": {"tldr": "Numerical computation of Green's function for flat rhombic tori with 4-decimal precision using elliptic function theory and complex integration.", "motivation": "To accurately compute the Green's function for flat rhombic tori, which is fundamental for solving Poisson equations and studying harmonic analysis on these surfaces.", "method": "Uses Legendre Relation, Weierstra\u00df P-function properties, and complex integration routines developed by H. Karcher, including symmetric P-Weierstra\u00df function for simplified elliptic function computation.", "result": "Achieves numerical values with precision up to the fourth decimal place for the Green's function on unit area tori with zero mean.", "conclusion": "The adopted strategies and mathematical tools enable reliable and precise computation of Green's functions for flat rhombic tori, with error control ensuring numerical accuracy."}}
{"id": "2509.12432", "pdf": "https://arxiv.org/pdf/2509.12432", "abs": "https://arxiv.org/abs/2509.12432", "authors": ["Claude Bardos", "Daniel W. Boutros", "Edriss S. Titi"], "title": "On the absence of anomalous dissipation for the Navier-Stokes equations with Navier boundary conditions: a sufficient condition", "categories": ["math.AP", "35Q30 (primary), 35D30, 35Q31, 35Q35, 76D05, 76D10 (secondary)"], "comment": "14 pages", "summary": "We consider the three-dimensional incompressible Navier-Stokes equations in a\nbounded domain with Navier boundary conditions. We provide a sufficient\ncondition for the absence of anomalous energy dissipation without making\nassumptions on the behaviour of the corresponding pressure near the boundary or\nthe existence of a strong solution to the incompressible Euler equations with\nthe same initial data. We establish our result by using our recent regularity\nresults for the pressure corresponding to weak solutions of the incompressible\nEuler equations [Arch. Ration. Mech. Anal., 249 (2025), 28].", "AI": {"tldr": "Sufficient condition for absence of anomalous energy dissipation in 3D Navier-Stokes equations with Navier boundary conditions, without requiring pressure behavior assumptions or Euler solution existence.", "motivation": "To establish conditions preventing anomalous energy dissipation in bounded domains with Navier boundary conditions, avoiding restrictive assumptions about pressure behavior near boundaries or requiring strong Euler solutions.", "method": "Uses recent regularity results for pressure corresponding to weak solutions of incompressible Euler equations from previous work [Arch. Ration. Mech. Anal., 249 (2025), 28].", "result": "Provides a sufficient condition that guarantees absence of anomalous energy dissipation in the described setting.", "conclusion": "The approach successfully establishes conditions to prevent anomalous energy dissipation without relying on traditional restrictive assumptions about boundary pressure behavior or Euler solution requirements."}}
{"id": "2509.13140", "pdf": "https://arxiv.org/pdf/2509.13140", "abs": "https://arxiv.org/abs/2509.13140", "authors": ["Yunhao Liu", "Wenjie Dou"], "title": "From higher-order moments to time correlation functions in strongly correlated systems: A DMRG-based memory kernel coupling theory", "categories": ["physics.comp-ph", "cond-mat.str-el"], "comment": "10 pages, 6 figures", "summary": "We introduce a hybrid approach for computing dynamical observables in\nstrongly correlated systems using higher-order moments. This method integrates\nmemory kernel coupling theory (MKCT) with the density matrix renormalization\ngroup (DMRG), extending our recent work on MKCT to strongly correlated systems.\nThe method establishes that correlation functions can be derived from the\nmoments. Within our framework, operators and wavefunctions are represented as\nmatrix product operators (MPOs) and matrix product states (MPSs), respectively.\nCrucially, the repeated application of the Liouville operator is achieved\nthrough an iterative procedure analogous to the DMRG algorithm itself. We\ndemonstrate the effectiveness and efficiency of MKCT-DMRG by computing the\nspectral function of the Hubbard model. Furthermore, we successfully apply the\nmethod to compute the electronic friction in the Hubbard-Holstein model. In all\ncases, the results show excellent agreement with time-dependent DMRG (TD-DMRG)\nbenchmarks. The advantage of MKCT-DMRG over TD-DMRG is the computational\nefficiency, which avoids expensive real-time propagation in TD-DMRG. These\nfindings establish MKCT-DMRG as a promising and accurate framework for\nsimulating challenging dynamical properties in strongly correlated quantum\nsystems.", "AI": {"tldr": "Hybrid approach combining memory kernel coupling theory (MKCT) with DMRG for efficient computation of dynamical observables in strongly correlated systems, avoiding expensive real-time propagation.", "motivation": "To develop an efficient method for computing dynamical observables in strongly correlated quantum systems that avoids the computational expense of real-time propagation required in time-dependent DMRG.", "method": "Integrates MKCT with DMRG using matrix product operators (MPOs) and matrix product states (MPSs). Repeated application of Liouville operator achieved through iterative DMRG-like procedure. Computes correlation functions from higher-order moments.", "result": "Successfully computed spectral function of Hubbard model and electronic friction in Hubbard-Holstein model. Results show excellent agreement with TD-DMRG benchmarks while being computationally more efficient.", "conclusion": "MKCT-DMRG establishes a promising and accurate framework for simulating challenging dynamical properties in strongly correlated quantum systems with superior computational efficiency compared to TD-DMRG."}}
{"id": "2509.13271", "pdf": "https://arxiv.org/pdf/2509.13271", "abs": "https://arxiv.org/abs/2509.13271", "authors": ["Yashika Ghai", "D. Del-Castillo-Negrete", "D. A. Spong", "M. T. Beidler"], "title": "Runaway electron interactions with whistler waves in tokamak plasmas: energy-dependent transport scaling", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Resonant interactions between high energy runaway electrons (REs) and\nwhistler waves are a promising mechanism for RE mitigation in tokamak plasmas.\nWhile prior studies have largely relied on quasi-linear diffusion models in\nsimplified geometries, we present a first-principles-informed framework that\nmodels RE-whistler interactions in a 3D tokamak equilibrium. This is achieved\nby coupling AORSA, which computes whistler eigenmodes for a given tokamak\nplasma equilibrium, and KORC, a kinetic orbit code that tracks full orbit RE\ntrajectories in prescribed wave fields. Our results demonstrate that REs\nundergo scattering to large pitch angles and exhibit anomalous diffusion in\nboth pitch-angle and kinetic energy space. Crucially, we observe a transition\nbetween diffusive, sub-diffusive, and super-diffusive transport regimes as a\nfunction of initial RE energy - an effect not captured by existing quasi-linear\nmodels. This anomalous transport behavior represents a significant advancement\nin understanding RE dynamics in the presence of wave - particle interactions.\nBy identifying the conditions under which anomalous diffusion arises, this work\nlays the theoretical foundation for designing targeted, wave-based mitigation\nstrategies in future tokamak experiments.", "AI": {"tldr": "First-principles modeling of runaway electron-whistler wave interactions in 3D tokamak geometry reveals anomalous diffusion and transport regime transitions not captured by quasi-linear models.", "motivation": "Resonant interactions between runaway electrons and whistler waves are promising for runaway electron mitigation in tokamaks, but prior studies relied on simplified quasi-linear models in simplified geometries.", "method": "Coupled AORSA (computes whistler eigenmodes) with KORC (kinetic orbit code) to model full-orbit runaway electron trajectories in 3D tokamak equilibrium wave fields.", "result": "Runaway electrons undergo scattering to large pitch angles and exhibit anomalous diffusion in both pitch-angle and kinetic energy space, with transitions between diffusive, sub-diffusive, and super-diffusive transport regimes based on initial energy.", "conclusion": "This anomalous transport behavior advances understanding of runaway electron dynamics and provides theoretical foundation for designing targeted wave-based mitigation strategies in future tokamak experiments."}}
{"id": "2509.12393", "pdf": "https://arxiv.org/pdf/2509.12393", "abs": "https://arxiv.org/abs/2509.12393", "authors": ["Reetish Padhi", "Ion Victor Gosea", "Igor Pontes Duff", "Serkan Gugercin"], "title": "Data-driven balanced truncation for linear systems with quadratic outputs", "categories": ["math.NA", "cs.NA", "math.DS"], "comment": null, "summary": "We develop the framework for a non-intrusive, quadrature-based method for\napproximate balanced truncation (QuadBT) of linear systems with quadratic\noutputs, thus extending the applicability of QuadBT, which was originally\ndesigned for data-driven balanced truncation of standard linear systems with\nlinear outputs only. The new approach makes use of the time-domain and\nfrequency-domain quadrature-based representation of the system's infinite\nGramians, only implicitly. We show that by sampling solely the extended impulse\nresponses of the original system and their derivatives (or the corresponding\ntransfer functions), we construct a reduced-order model that mimics the\napproximation quality of the intrusive (projection-based) balanced truncation.\nWe validate the proposed framework on a numerical example.", "AI": {"tldr": "Non-intrusive quadrature-based balanced truncation method extended to linear systems with quadratic outputs, using sampled impulse responses and transfer functions to achieve projection-based quality without intrusive methods.", "motivation": "Extend QuadBT framework from standard linear systems with linear outputs to handle quadratic outputs, maintaining non-intrusive approach while preserving approximation quality.", "method": "Quadrature-based representation of infinite Gramians using sampled extended impulse responses and their derivatives (or corresponding transfer functions) to construct reduced-order models.", "result": "The method achieves approximation quality comparable to intrusive projection-based balanced truncation, validated through numerical examples.", "conclusion": "The proposed QuadBT framework successfully extends balanced truncation to quadratic output systems while maintaining non-intrusive, data-driven advantages with quality matching intrusive methods."}}
{"id": "2509.12435", "pdf": "https://arxiv.org/pdf/2509.12435", "abs": "https://arxiv.org/abs/2509.12435", "authors": ["Yan Guo", "Mahir Hadzic", "Juhi Jang", "Matthew Schrecker"], "title": "Nonlinear stability of the Larson-Penston collapse", "categories": ["math.AP", "math-ph", "math.MP", "35Q35, 35Q75, 35Q85, 35L67, 35P05, 35B44"], "comment": "149 pages, 1 figure", "summary": "We prove nonlinear stability of the Larson-Penston family of self-similarly\ncollapsing solutions to the isothermal Euler-Poisson system. Our result applies\nto radially symmetric perturbations and it is the first full nonlinear\nstability result for radially imploding compressible flows. At the heart of the\nproof is the ground state character of the Larson-Penston solution, which\nexhibits important global monotonicity properties used throughout the proof.\n  One of the key challenges is the proof of mode-stability for the non\nself-adjoint spectral problem which arises when linearising the dynamics around\nthe Larson-Penston collapsing solution. To exclude the presence of complex\ngrowing modes other than the trivial one associated with time translation\nsymmetry, we use a high-order energy method in low and high frequency regimes,\nfor which the monotonicity properties are crucially exploited, and use rigorous\ncomputer-assisted techniques in the intermediate regime. In addition, the\nmaximal dissipativity of the linearised operator is proven on arbitrary large\nbackward light cones emanating from the singular point using the global\nmonotonicity of the Larson-Penston solutions. Such a flexibility in linear\nanalysis also facilitates nonlinear analysis and allows us to identify the\nexact number of derivatives necessary for the nonlinear stability statement.\nThe proof is based on a two-tier high-order weighted energy method which ties\nbounds derived from the Duhamel formula to quasilinear top order estimates. To\nprove global existence we further use the Brouwer fixed point theorem to\nidentify the final collapse time, which suppresses the trivial instability\ncaused by the time-translation symmetry of the system.", "AI": {"tldr": "Nonlinear stability proof for Larson-Penston self-similar collapsing solutions in isothermal Euler-Poisson system under radial perturbations", "motivation": "To establish the first full nonlinear stability result for radially imploding compressible flows and prove stability of Larson-Penston collapsing solutions", "method": "High-order energy method in frequency regimes, rigorous computer-assisted techniques, two-tier high-order weighted energy method, Duhamel formula, and Brouwer fixed point theorem", "result": "Successfully proved nonlinear stability of Larson-Penston solutions against radially symmetric perturbations and identified the exact number of derivatives needed for stability", "conclusion": "The Larson-Penston family exhibits ground state character with global monotonicity properties that enable full nonlinear stability analysis and suppression of time-translation symmetry instability"}}
{"id": "2509.13187", "pdf": "https://arxiv.org/pdf/2509.13187", "abs": "https://arxiv.org/abs/2509.13187", "authors": ["Jithin Vijaykumar", "Loyad Joseph Losan", "Saddala Reddy Tharun", "Murthi Ram Chandra Reddy", "Mood Rahul", "Jagadeesha T"], "title": "Enhancement of torque transmission capability in Magneto-Rheological fluid-based Clutch using novel hybrid corrugated plane transmission surface strategy", "categories": ["physics.comp-ph"], "comment": null, "summary": "In an increased automated world, miniaturization is the key to widespread\ndeployment of advanced technologies. Enhancing the torque transmissibility by\nabiding to the spatial constraints imposed by radial space availability has\nconsistently remained a hurdle in the implementation of Magneto-Rheological\n(MR) clutches that use shear mode of MR fluid (MRF). This proves the necessity\nof a novel design capable of providing required transmission capability with a\nreduced transmission surface area. The present study analyzes a corrugated\ntransmissible surface design which improves torque transmissibility with the\nhelp of increased transmission area and proper alignment of field lines passing\nthrough the MRF gap. In this paper, the impact of various dimensional\nparameters of a hybrid corrugated plane type MR clutch (MRC) design was studied\nwith the aid of magnetic analysis performed on COMSOL Multiphysics software.\nThe results obtained shows that various parameters in the design of MR\nclutches, such as annular and radial MR gaps, disc width, individual\ncorrugation heights, corrugation width, bobbin thickness and radii of plane\nsurface influences the torque transmission capability of MR clutches. Also, an\noptimization of the hybrid corrugated plane MR Clutch of the chosen geometry\nhas been conducted with the transmission capability increasing by 39.37%\ncompared with the non-optimized geometrical configuration.", "AI": {"tldr": "A novel corrugated surface design for MR clutches improves torque transmission by 39.37% through increased surface area and optimized magnetic field alignment.", "motivation": "Miniaturization requires MR clutches to transmit higher torque within limited radial space constraints, necessitating innovative designs that enhance torque transmissibility with reduced transmission surface area.", "method": "Magnetic analysis using COMSOL Multiphysics software to study dimensional parameters of a hybrid corrugated plane type MR clutch design, including annular/radial gaps, disc width, corrugation dimensions, and bobbin thickness.", "result": "The corrugated design significantly improves torque transmission capability, with optimization achieving a 39.37% increase compared to non-optimized configurations. Various dimensional parameters were found to critically influence performance.", "conclusion": "The corrugated transmissible surface design effectively addresses spatial constraints in MR clutches by maximizing transmission area and optimizing magnetic field alignment, enabling higher torque transmission in miniaturized applications."}}
{"id": "2509.12608", "pdf": "https://arxiv.org/pdf/2509.12608", "abs": "https://arxiv.org/abs/2509.12608", "authors": ["Tamar Ervin", "Alfred Mallet", "Stefan Eriksson", "Marc Swisdak", "James Juno", "Orlando M. Romeo", "Tai Phan", "Trevor A. Bowen", "Roberto Livi", "Phyllis L. Whittlesey", "Davin E. Larson", "Stuart D. Bake"], "title": "The impact of Alfvenic shear flow on magnetic reconnection and turbulence", "categories": ["physics.space-ph", "astro-ph.SR", "physics.plasm-ph"], "comment": "1o pages, 5 figures", "summary": "Magnetic reconnection is a fundamental and omnipresent energy conversion\nprocess in plasma physics. Novel observations of fields and particles from\nParker Solar Probe (PSP) have shown the absence of reconnection in a large\nnumber of current sheets in the near-Sun solar wind. Using near-Sun\nobservations from PSP Encounters 4 to 11 (Jan 2020 to March 2022), we\ninvestigate whether reconnection onset might be suppressed by velocity shear.\nWe compare estimates of the tearing mode growth rate in the presence of shear\nflow for time periods identified as containing reconnecting current sheets\nversus non-reconnecting times, finding systematically larger growth rates for\nreconnection periods. Upon examination of the parameters associated with\nreconnection onset, we find that 85% of the reconnection events are embedded in\nslow, non-Alfvenic wind streams. We compare with fast, slow non-Alfvenic, and\nslow Alfvenic streams, finding that the growth rate is suppressed in highly\nAlfvenic fast and slow wind and reconnection is not seen in these wind types,\nas would be expected from our theoretical expressions. These wind streams have\nstrong Alfvenic} flow shear, consistent with the idea of reconnection\nsuppression by such flows. This could help explain the frequent absence of\nreconnection events in the highly Alfvenic, near-Sun solar wind observed by\nPSP. Finally, we find a steepening of both the trace and magnitude magnetic\nfield spectra within reconnection periods in comparison to ambient wind. We tie\nthis to the dynamics of relatively balanced turbulence within these\nreconnection periods and the potential generation of compressible fluctuations.", "AI": {"tldr": "PSP observations show magnetic reconnection absence in near-Sun solar wind current sheets, with velocity shear identified as a key suppression mechanism through tearing mode growth rate analysis.", "motivation": "To understand why Parker Solar Probe observations show frequent absence of magnetic reconnection in near-Sun solar wind current sheets, and investigate whether velocity shear suppresses reconnection onset.", "method": "Analyzed PSP Encounters 4-11 data (Jan 2020-March 2022), compared tearing mode growth rates with/without shear flow for reconnecting vs non-reconnecting periods, and examined wind stream types and magnetic field spectra.", "result": "85% of reconnection events occur in slow, non-Alfvenic wind; growth rates systematically larger during reconnection; reconnection suppressed in highly Alfvenic fast/slow wind with strong flow shear; magnetic field spectra steepen during reconnection periods.", "conclusion": "Velocity shear from Alfvenic flows suppresses magnetic reconnection onset, explaining PSP's frequent observation of reconnection absence in near-Sun solar wind, with implications for turbulence dynamics and compressible fluctuation generation."}}
{"id": "2509.12500", "pdf": "https://arxiv.org/pdf/2509.12500", "abs": "https://arxiv.org/abs/2509.12500", "authors": ["Haiyang Wang", "Fredrik Fryklund", "Samuel Potter", "Leslie Greengard"], "title": "Scattering theory for Stokes flow in complex branched structures", "categories": ["math.NA", "cs.NA", "physics.flu-dyn"], "comment": "10 pages, 7 figures", "summary": "Slow, viscous flow in branched structures arises in many biological and\nengineering settings. Direct numerical simulation of flow in such complicated\nmulti-scale geometry, however, is a computationally intensive task. We propose\na scattering theory framework that dramatically reduces this cost by\ndecomposing networks into components connected by short straight channels.\nExploiting the phenomenon of rapid return to Poiseuille flow (Saint-Venant's\nprinciple in the context of elasticity), we compute a high-order accurate\nscattering matrix for each component via boundary integral equations. These\nprecomputed components can then be assembled into arbitrary branched\nstructures, and the precomputed local solutions on each component can be\nassembled into an accurate global solution. The method is modular, has\nnegligible cost, and appears to be the first full-fidelity solver that makes\nuse of the return to Poiseuille flow phenomenon. In our two-dimensional\nexamples, it matches the accuracy of full-domain solvers while requiring only a\nfraction of the computational effort.", "AI": {"tldr": "A scattering theory framework for efficient simulation of viscous flow in branched structures by decomposing networks into components with precomputed scattering matrices.", "motivation": "Direct numerical simulation of viscous flow in complex multi-scale branched geometries is computationally intensive, requiring a more efficient approach.", "method": "Decompose networks into components connected by straight channels, compute high-order accurate scattering matrices for each component using boundary integral equations, then assemble precomputed components into arbitrary branched structures.", "result": "The method matches full-domain solver accuracy while requiring only a fraction of computational effort, is modular, and has negligible cost after precomputation.", "conclusion": "This scattering theory framework provides the first full-fidelity solver that exploits the return to Poiseuille flow phenomenon, dramatically reducing computational costs for viscous flow simulation in branched structures."}}
{"id": "2509.12472", "pdf": "https://arxiv.org/pdf/2509.12472", "abs": "https://arxiv.org/abs/2509.12472", "authors": ["Weiwei Ding", "Zhanghua Liang"], "title": "Effects of temporal variations on wave speeds of bistable traveling waves for Lotka-Volterra competition systems", "categories": ["math.AP"], "comment": null, "summary": "This paper investigates the bistable traveling waves for two-species\nLotka-Volterra competition systems in time periodic environments. We focus\nespecially on the influence of the temporal period, with existence results\nestablished for both small and large periods.We also show the existence of, and\nderive explicit formulas for, the limiting speeds as the period tends to zero\nor infinity, and provide estimates for the corresponding rates of convergence.\nFurthermore, we analyze the sign of wave speed. Assuming that both species\nshare identical diffusion rates and intraspecific competition rates, we obtain\na criterion for determining the sign of wave speed by comparing the intrinsic\ngrowth rates and interspecific competition strengths. More intriguingly, based\non our explicit formulas for the limiting speeds, we construct an example in\nwhich the sign of wave speed changes with the temporal period. This example\nreveals that temporal variations can significantly influence competition\noutcomes,enabling different species to become dominant under different periods.", "AI": {"tldr": "Analysis of bistable traveling waves in two-species Lotka-Volterra competition systems with time periodic environments, focusing on period influence, limiting speeds, and sign changes of wave speed.", "motivation": "To understand how temporal periodicity affects competition outcomes in ecological systems, specifically investigating how different time periods can influence which species becomes dominant.", "method": "Mathematical analysis of bistable traveling waves, establishing existence results for small and large periods, deriving explicit formulas for limiting speeds, and analyzing wave speed sign through comparison of intrinsic growth rates and interspecific competition strengths.", "result": "Found that temporal variations significantly influence competition outcomes, with wave speed sign changing with temporal period, enabling different species to dominate under different periods. Derived explicit formulas for limiting speeds and convergence rates.", "conclusion": "Temporal periodicity plays a crucial role in species competition dynamics, as demonstrated by the constructed example showing that different temporal periods can lead to different dominant species, highlighting the importance of environmental timing in ecological systems."}}
{"id": "2509.12323", "pdf": "https://arxiv.org/pdf/2509.12323", "abs": "https://arxiv.org/abs/2509.12323", "authors": ["Thomas Spriggs", "Eliska Greplova", "Juan Carrasquilla", "Jannes Nys"], "title": "Accurate ground states of $SU(2)$ lattice gauge theory in 2+1D and 3+1D", "categories": ["hep-lat", "physics.comp-ph", "quant-ph"], "comment": "19 pages, 7 figures", "summary": "We present a neural network wavefunction framework for solving non-Abelian\nlattice gauge theories in a continuous group representation. Using a\ncombination of $SU(2)$ equivariant neural networks alongside an $SU(2)$\ninvariant, physics-inspired ansatz, we learn a parameterization of the ground\nstate wavefunction of $SU(2)$ lattice gauge theory in 2+1 and 3+1 dimensions.\nOur method, performed in the Hamiltonian formulation, has a straightforward\ngeneralization to $SU(N)$. We benchmark our approach against a solely invariant\nansatz by computing the ground state energy, demonstrating the need for bespoke\ngauge equivariant transformations. We evaluate the Creutz ratio and average\nWilson loop, and obtain results in strong agreement with perturbative\nexpansions. Our method opens up an avenue for studying lattice gauge theories\nbeyond one dimension, with efficient scaling to larger systems, and in a way\nthat avoids both the sign problem and any discretization of the gauge group.", "AI": {"tldr": "Neural network wavefunction framework for solving non-Abelian lattice gauge theories using SU(2) equivariant neural networks and physics-inspired ansatz to parameterize ground state wavefunctions in 2+1D and 3+1D.", "motivation": "To develop a method for studying lattice gauge theories beyond one dimension that avoids the sign problem and gauge group discretization, while enabling efficient scaling to larger systems.", "method": "Combination of SU(2) equivariant neural networks with SU(2) invariant physics-inspired ansatz to learn ground state wavefunction parameterization in Hamiltonian formulation, benchmarked against invariant-only ansatz.", "result": "Achieved strong agreement with perturbative expansions for ground state energy, Creutz ratio, and average Wilson loop. Demonstrated superiority of gauge equivariant transformations over invariant-only approaches.", "conclusion": "The framework successfully opens new avenues for studying higher-dimensional lattice gauge theories with efficient scaling, while avoiding sign problems and gauge group discretization issues."}}
{"id": "2509.13206", "pdf": "https://arxiv.org/pdf/2509.13206", "abs": "https://arxiv.org/abs/2509.13206", "authors": ["A. V. Kopyev", "A. S. Il'yn", "V. A. Sirota", "K. P. Zybin"], "title": "Virtual states and exponential decay in small-scale dynamo", "categories": ["physics.flu-dyn", "astro-ph.SR", "physics.plasm-ph"], "comment": null, "summary": "We develop the Kazantsev theory of small-scale dynamo generation at small\nPrandtl numbers near the generation threshold and restore the concordance\nbetween the theory and numerical simulations: the theory predicted a power-law\ndecay below the threshold, while simulations demonstrate exponential decay. We\nshow that the exponential decay is temporary and owes its existence to the\nflattening of the velocity correlator at large scales. This effect corresponds\nto the existence of a long-living virtual level in the corresponding\nSchrodinger type equation. We also find the critical Reynolds number and the\nincrement of growth/decay above and under the threshold; we express them in\nterms of the quantitative characteristic properties of the velocity correlator,\nwhich makes it possible to compare the results with the data of different\nsimulations.", "AI": {"tldr": "Kazantsev theory of small-scale dynamo generation at low Prandtl numbers near threshold shows power-law decay, but simulations show exponential decay. This discrepancy is resolved by showing exponential decay is temporary due to velocity correlator flattening at large scales.", "motivation": "To reconcile the discrepancy between theoretical predictions (power-law decay below threshold) and numerical simulations (exponential decay) in small-scale dynamo generation at low Prandtl numbers.", "method": "Developed Kazantsev theory near generation threshold, analyzed velocity correlator flattening effects, and solved corresponding Schrodinger-type equation to identify virtual level effects.", "result": "Found that exponential decay is temporary and caused by flattening of velocity correlator at large scales, corresponding to a long-living virtual level. Determined critical Reynolds number and growth/decay increments in terms of velocity correlator properties.", "conclusion": "The study restores concordance between theory and simulations by explaining the apparent exponential decay as a temporary effect, providing quantitative expressions for critical parameters that enable comparison across different simulation data."}}
{"id": "2509.12547", "pdf": "https://arxiv.org/pdf/2509.12547", "abs": "https://arxiv.org/abs/2509.12547", "authors": ["Victoria L. Fisher", "Leo G. Rebholz", "Duygu Vargun"], "title": "An efficient splitting iteration for a CDA-accelerated solver for incompressible flow problems", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We propose, analyze, and test an efficient splitting iteration for solving\nthe incompressible, steady Navier-Stokes equations in the setting where partial\nsolution data is known. The (possibly noisy) solution data is incorporated into\na Picard-type solver via continuous data assimilation (CDA). Efficiency is\ngained over the usual Picard iteration through an algebraic splitting of\nYosida-type that produces easier linear solves, and accuracy/consistency is\nshown to be maintained through the use of an incremental pressure and grad-div\nstabilization. We prove that CDA scales the Lipschitz constant of the\nassociated fixed point operator by $H^{1/2}$, where $H$ is the characteristic\nspacing of the known solution data. This implies that CDA accelerates an\nalready converging solver (and the more data, the more acceleration) and\nenables convergence of solvers in parameter regimes where the solver would fail\n(and the more data, the larger the parameter regime). Numerical tests\nillustrate the theory on several benchmark test problems and show that the\nproposed efficient solver gives nearly identical results in terms of number of\niterations to converge; in other words, the proposed solver gives an efficiency\ngain with no loss in convergence rate.", "AI": {"tldr": "Efficient splitting iteration method for solving incompressible steady Navier-Stokes equations using continuous data assimilation, providing faster convergence and enabling solver success in challenging parameter regimes.", "motivation": "To develop an efficient solver for incompressible steady Navier-Stokes equations that can incorporate partial (possibly noisy) solution data to accelerate convergence and enable solution in parameter regimes where standard methods fail.", "method": "Proposes a Picard-type solver with continuous data assimilation (CDA) using an algebraic splitting of Yosida-type for easier linear solves, combined with incremental pressure and grad-div stabilization for accuracy and consistency.", "result": "CDA scales the Lipschitz constant by H^{1/2} (where H is data spacing), accelerating convergence and enabling solver success in challenging regimes. Numerical tests show nearly identical iteration counts with efficiency gains.", "conclusion": "The proposed efficient splitting iteration with CDA provides significant computational efficiency improvements without sacrificing convergence rate, making it particularly valuable for solving Navier-Stokes equations in difficult parameter regimes."}}
{"id": "2509.12614", "pdf": "https://arxiv.org/pdf/2509.12614", "abs": "https://arxiv.org/abs/2509.12614", "authors": ["Qinghao Lei"], "title": "Global Existence and Incompressible Limit for the Three-Dimensional Axisymmetric Compressible Navier-Stokes Equations with Large Bulk Viscosity and Large Initial Data", "categories": ["math.AP"], "comment": "arXiv admin note: substantial text overlap with arXiv:2509.11260", "summary": "In this paper, we study the three-dimensional axisymmetric compressible\nNavier-Stokes equations with slip boundary conditions in a cylindrical domain\nexcluding the axis. We establish the global existence and exponential decay of\nweak, strong, and classical solutions with large initial data and vacuum, under\nthe assumption that the bulk viscosity coefficient is sufficiently large.\nMoreover, we demonstrate that as the bulk viscosity coefficient tends to\ninfinity, the solutions of the compressible Navier-Stokes equations converge to\nthose of the inhomogeneous incompressible Navier-Stokes equations.", "AI": {"tldr": "Global existence and exponential decay of solutions for 3D axisymmetric compressible Navier-Stokes equations with slip boundary conditions and large initial data/vacuum, given sufficiently large bulk viscosity. Solutions converge to inhomogeneous incompressible Navier-Stokes as bulk viscosity approaches infinity.", "motivation": "To establish rigorous mathematical foundations for compressible fluid flows in cylindrical domains with slip boundary conditions, particularly addressing challenges with large initial data, vacuum regions, and understanding the relationship between compressible and incompressible models through viscosity limits.", "method": "Mathematical analysis of three-dimensional axisymmetric compressible Navier-Stokes equations in cylindrical domains excluding the axis, using slip boundary conditions and assuming sufficiently large bulk viscosity coefficient.", "result": "Proved global existence and exponential decay of weak, strong, and classical solutions even with large initial data and vacuum. Showed convergence to inhomogeneous incompressible Navier-Stokes equations as bulk viscosity coefficient tends to infinity.", "conclusion": "The study provides comprehensive existence and decay results for compressible flows with practical boundary conditions, and establishes a rigorous mathematical connection between compressible and incompressible fluid models through the viscosity limit, offering insights into fluid behavior across different viscosity regimes."}}
{"id": "2509.12381", "pdf": "https://arxiv.org/pdf/2509.12381", "abs": "https://arxiv.org/abs/2509.12381", "authors": ["Saajid Chowdhury", "Jes\u00fas P\u00e9rez-R\u00edos"], "title": "GPU-Accelerated MATLAB Software for Atom-Ion Dynamics", "categories": ["physics.atom-ph", "cond-mat.quant-gas", "physics.comp-ph"], "comment": null, "summary": "We present a MATLAB script which can use GPU acceleration to simulate a\ntrapped ion interacting with a low-density cloud of atoms. This script, called\natomiongpu.m, can massively parallelize MD simulations of trajectories of a\ntrapped ion and an atom starting far away. The script uses ode45gpu, which is\nour optimized and specialized implementation of the Runge-Kutta algorithm used\nin MATLAB's ODE solver ode45. We first discuss the physical system and show how\node45gpu can solve it up to 22x faster than MATLAB's ode45. Then, we show how\nto easily modify the inputs to atomiongpu.m to account for different kinds of\natoms, ions, atom-ion interactions, trap potentials, simulation parameters,\ninitial conditions, and computational hardware, so that atomiongpu.m\nautomatically finds the probability of complex formation, the distribution of\nobservables such as the scattering angle and complex lifetime, and plots of\nspecific trajectories.", "AI": {"tldr": "A MATLAB script called atomiongpu.m that uses GPU acceleration to simulate trapped ion-atom interactions, achieving up to 22x speedup over standard MATLAB ode45 solver.", "motivation": "To enable efficient and massively parallel molecular dynamics simulations of trapped ion interactions with low-density atom clouds, which require solving complex trajectory calculations.", "method": "Developed a specialized GPU-accelerated implementation (ode45gpu) of the Runge-Kutta algorithm optimized for MATLAB, packaged in atomiongpu.m script that handles various physical parameters and initial conditions.", "result": "Achieved up to 22x faster simulation speeds compared to MATLAB's standard ode45 solver while maintaining flexibility for different atomic systems, interactions, and computational hardware.", "conclusion": "The atomiongpu.m script provides an efficient, customizable, and high-performance solution for simulating trapped ion-atom interactions with GPU acceleration, enabling faster computation of complex formation probabilities and trajectory analysis."}}
{"id": "2509.13272", "pdf": "https://arxiv.org/pdf/2509.13272", "abs": "https://arxiv.org/abs/2509.13272", "authors": ["T. Cordova", "E. V. Marley", "D. A. Chin", "R. A. London", "H. A. Scott", "T. D\u00f6ppner", "F. N. Beg", "F. Coppari", "M. Millot", "J. Emig", "S. B. Hansen", "P. M. Nilson", "P. Sterne", "M. J. MacDonald"], "title": "Ionization and temperature measurements in warm dense copper using x-ray absorption spectroscopy", "categories": ["hep-ex", "physics.plasm-ph"], "comment": "10 Pages, 7 Figures, In submission for Physical Review Research", "summary": "We detail experimental results inferring ionization and temperature for warm\ndense copper plasmas at several times solid density (15 to 25 g/cm$^3$) and\ntemperatures of 10 to 21 eV. Experiments performed at the OMEGA Laser Facility\ngenerate uniform warm dense matter conditions via symmetric shock compression\nof a buried copper layer. The plasma is probed with a laser-generated x-ray\nsource to collect the K-shell x-ray absorption spectrum. Fitting bound-bound\nabsorption contributions from constituent charge states of copper provides an\nestimated $\\overline{Z}$ of approximately 4 to 7 for these warm dense copper\nplasmas. We find that these partially ionized plasmas have K-edge shifts of 12\nto 30 eV and bound-bound resonance 1s$\\rightarrow$3p absorption shifts of 4 to\n26 eV with respect to the cold K-edge. This study provides necessary\nexperimental data to improve ionization and opacity models in the warm dense\nmatter regime.", "AI": {"tldr": "Experimental study of warm dense copper plasmas at 15-25 g/cm\u00b3 density and 10-21 eV temperatures, measuring ionization states and K-shell absorption shifts using x-ray spectroscopy.", "motivation": "To provide experimental data for improving ionization and opacity models in the warm dense matter regime, which is crucial for understanding high-energy density physics and astrophysical phenomena.", "method": "Symmetric shock compression of buried copper layers at OMEGA Laser Facility to generate uniform warm dense matter conditions, followed by probing with laser-generated x-ray source to collect K-shell absorption spectra and fitting bound-bound absorption contributions.", "result": "Estimated average ionization state (Z\u0304) of 4-7, K-edge shifts of 12-30 eV, and bound-bound resonance absorption shifts of 4-26 eV relative to cold copper K-edge.", "conclusion": "The study provides essential experimental validation data that will help refine theoretical models of ionization and opacity in warm dense matter systems."}}
{"id": "2509.12555", "pdf": "https://arxiv.org/pdf/2509.12555", "abs": "https://arxiv.org/abs/2509.12555", "authors": ["Yuan Chen", "Xu Zhang"], "title": "An Immersed $C^0$ Interior Penalty Method for Biharmonic Interface Problems", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we introduce an immersed $C^0$ interior penalty method for\nsolving two-dimensional biharmonic interface problems on unfitted meshes. To\naccommodate the biharmonic interface conditions, high-order immersed finite\nelement (IFE) spaces are constructed in the least-squares sense. We establish\nkey properties of these spaces including unisolvency and partition of unity\nare, and verify their optimal approximation capability. These spaces are\nfurther incorporated into a modified $C^0$ interior penalty scheme with\nadditional penalty terms on interface segments. The well-posedness of the\ndiscrete solution is proved. Numerical experiments with various interface\ngeometries confirm optimal convergence of the proposed method in $L^2$, $H^1$\nand $H^2$ norms.", "AI": {"tldr": "An immersed C^0 interior penalty method for 2D biharmonic interface problems on unfitted meshes using high-order immersed finite element spaces constructed via least-squares.", "motivation": "To solve two-dimensional biharmonic interface problems efficiently on unfitted meshes, which requires accommodating complex interface conditions and maintaining optimal convergence properties.", "method": "Construct high-order immersed finite element spaces in least-squares sense, incorporate into modified C^0 interior penalty scheme with additional penalty terms on interface segments, and prove well-posedness.", "result": "Numerical experiments with various interface geometries confirm optimal convergence in L^2, H^1 and H^2 norms, demonstrating the method's effectiveness.", "conclusion": "The proposed immersed C^0 interior penalty method with high-order IFE spaces provides an effective approach for solving biharmonic interface problems on unfitted meshes with optimal convergence rates."}}
{"id": "2509.12619", "pdf": "https://arxiv.org/pdf/2509.12619", "abs": "https://arxiv.org/abs/2509.12619", "authors": ["Jinlu Li", "Yanghai Yu"], "title": "Ill-posedness in $B^s_{p,\\infty}$ of the Euler equations: Non-continuous dependence", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we solve an open problem left in the monographs\n\\cite[Bahouri-Chemin-Danchin, (2011)]{BCD}. Precisely speaking, it was obtained\nin \\cite[Theorem 7.1 on pp293, (2011)]{BCD} the existence and uniqueness of\n$B^s_{p,\\infty}$ solution for the Euler equations. We furthermore prove that\nthe solution map of the Euler equation is not continuous in the Besov spaces\nfrom $B^s_{p,\\infty}$ to $L_T^\\infty B^s_{p,\\infty}$ for $s>1+d/p$ with $1\\leq\np\\leq \\infty$ and in the H\\\"{o}lder spaces from $C^{k,\\alpha}$ to $L_T^\\infty\nC^{k,\\alpha}$ with $k\\in \\mathbb{N}^+$ and $\\alpha\\in(0,1)$, which later covers\nparticularly the ill-posedness of $C^{1,\\alpha}$ solution in \\cite[Trans. Amer.\nMath. Soc., (2018)]{MYtams}. Beyond purely technical aspects on the choice of\ninitial data, a remarkable novelty of the proof is the construction of an\napproximate solution to the Burgers equation.", "AI": {"tldr": "This paper solves an open problem from Bahouri-Chemin-Danchin (2011) by proving that the solution map for Euler equations is discontinuous in Besov spaces B^s_{p,\u221e} and H\u00f6lder spaces C^{k,\u03b1} for certain parameter ranges.", "motivation": "To address an unresolved problem left in the monographs by Bahouri-Chemin-Danchin (2011) regarding the continuity properties of Euler equation solution maps in specific function spaces.", "method": "The authors construct an approximate solution to the Burgers equation and use technical choices of initial data to demonstrate the discontinuity of the solution map.", "result": "Proved that the Euler equation solution map is not continuous from B^s_{p,\u221e} to L_T^\u221e B^s_{p,\u221e} for s>1+d/p, and from C^{k,\u03b1} to L_T^\u221e C^{k,\u03b1} for k\u2208\u2115\u207a and \u03b1\u2208(0,1).", "conclusion": "The paper successfully resolves the open problem and provides novel insights into the ill-posedness properties of Euler equations in these function spaces, with particular emphasis on the construction technique for Burgers equation approximations."}}
{"id": "2509.12509", "pdf": "https://arxiv.org/pdf/2509.12509", "abs": "https://arxiv.org/abs/2509.12509", "authors": ["S\u00f8ren Smidstrup", "Shela Aboud", "Ricardo Borges", "Anders Blom", "Pankaj Aggarwal", "Robert Freeman", "Jamil Kawa"], "title": "Leveraging Machine Learning Force Fields (MLFFs) to Simulate Large Atomistic Systems for Fidelity Improvement of Superconducting Qubits and Sensors", "categories": ["quant-ph", "cond-mat.mtrl-sci", "cond-mat.supr-con", "physics.comp-ph"], "comment": "Published at GoMACTech 2025", "summary": "Materials engineering using atomistic modeling is an essential tool for the\ndevelopment of qubits and quantum sensors. Traditional density-functional\ntheory (DFT) does however not adequately capture the complete physics involved,\nincluding key aspects and dynamics of superconductivity, surface states, etc.\nThere are also significant challenges regarding the system sizes that can be\nsimulated, not least for thermal properties which are key in quantum-computing\napplications. The QuantumATK tool combines DFT, based on LCAO basis sets, with\nnon-equilibrium Green's functions, to compute the characteristics of interfaces\nbetween superconductors and insulators, as well as the surface states of\ntopological insulators. Additionally, the software leverages machine-learned\nforce-fields to simulate thermal properties and to generate realistic amorphous\ngeometries in large-scale systems. Finally, the description of superconducting\nqubits and sensors as two-level systems modeled with a double-well potential\nrequires many-body physics, and this paper demonstrates how electron-electron\ninteraction can be added to the single-particle energy levels from an atomistic\ntight-binding model to describe a realistic double-quantum dot system.", "AI": {"tldr": "QuantumATK tool combines DFT with machine learning and many-body physics to address limitations in modeling quantum materials for qubits and sensors, enabling large-scale simulations of interfaces, surface states, and thermal properties.", "motivation": "Traditional DFT fails to capture complete physics for quantum materials including superconductivity dynamics, surface states, and has limitations in system size for thermal property simulations needed in quantum computing applications.", "method": "Combines DFT with LCAO basis sets, non-equilibrium Green's functions, machine-learned force fields, and adds electron-electron interactions to single-particle tight-binding models to create realistic double-quantum dot systems.", "result": "Enables computation of superconductor-insulator interface characteristics, topological insulator surface states, large-scale thermal property simulations, and realistic modeling of superconducting qubits as two-level systems.", "conclusion": "The integrated approach provides comprehensive atomistic modeling capabilities for quantum material development, overcoming traditional DFT limitations and enabling accurate simulation of key quantum computing components."}}
{"id": "2509.12896", "pdf": "https://arxiv.org/pdf/2509.12896", "abs": "https://arxiv.org/abs/2509.12896", "authors": ["Fabian Kr\u00f6pfl", "Daniel Peterseim", "Elisabeth Ullmann"], "title": "Neural Network Localized Orthogonal Decomposition for Numerical Homogenization of Diffusion Operators with Random Coefficients", "categories": ["math.NA", "cs.NA", "65N25, 60G60, 68T07"], "comment": null, "summary": "This paper presents a neural network--enhanced surrogate modeling approach\nfor diffusion problems with spatially varying random field coefficients. The\nmethod builds on numerical homogenization, which compresses fine-scale\ncoefficients into coarse-scale surrogates without requiring periodicity. To\novercome computational bottlenecks, we train a neural network to map fine-scale\ncoefficient samples to effective coarse-scale information, enabling the\nconstruction of accurate surrogates at the target resolution. This framework\nallows for the fast and efficient compression of new coefficient realizations,\nthereby ensuring reliable coarse models and supporting scalable computations\nfor large ensembles of random coefficients. We demonstrate the efficacy of our\napproach through systematic numerical experiments for two classes of\ncoefficients, emphasizing the influence of coefficient contrast: (i) lognormal\ndiffusion coefficients, a standard model for uncertain subsurface structures in\ngeophysics, and (ii) hierarchical Gaussian random fields with random\ncorrelation lengths.", "AI": {"tldr": "Neural network-enhanced surrogate modeling for diffusion problems with spatially varying random field coefficients, using numerical homogenization and neural networks to map fine-scale coefficients to coarse-scale surrogates efficiently.", "motivation": "To overcome computational bottlenecks in diffusion problems with spatially varying random field coefficients by developing fast and efficient compression methods for large ensembles of random coefficients.", "method": "Combines numerical homogenization (compressing fine-scale coefficients into coarse-scale surrogates) with neural network training to map fine-scale coefficient samples to effective coarse-scale information, enabling accurate surrogate construction at target resolution.", "result": "The approach enables fast and efficient compression of new coefficient realizations, ensuring reliable coarse models and supporting scalable computations for large ensembles of random coefficients.", "conclusion": "The method demonstrates efficacy through systematic numerical experiments for lognormal diffusion coefficients and hierarchical Gaussian random fields with random correlation lengths, emphasizing its ability to handle coefficient contrast effectively."}}
{"id": "2509.12685", "pdf": "https://arxiv.org/pdf/2509.12685", "abs": "https://arxiv.org/abs/2509.12685", "authors": ["Saumyajit Das", "Tuhin Ghosh", "Shiqi Ma"], "title": "Inverse scattering for the fractional Schr\u00f6dinger equation", "categories": ["math.AP"], "comment": "19 pages", "summary": "This article is devoted to studying the inverse scattering for the fractional\nSchr\\\"{o}dinger equation, and in particular we solve the Born approximation\nproblem. Based on the ($p$,$q$)-type resolvent estimate for the fractional\nLaplacian, we derive an expression for the scattering amplitude of the\nscattered solution of the fractional Schr\\\"{o}dinger equation. We prove the\nuniqueness of the potential using the scattering amplitude data.", "AI": {"tldr": "Study of inverse scattering for fractional Schr\u00f6dinger equation, solving Born approximation problem using resolvent estimates to derive scattering amplitude expression and prove potential uniqueness.", "motivation": "To address the inverse scattering problem for fractional Schr\u00f6dinger equations and establish theoretical foundations for determining potentials from scattering data.", "method": "Utilized (p,q)-type resolvent estimates for fractional Laplacian to derive scattering amplitude expressions and prove uniqueness of potential from scattering amplitude data.", "result": "Successfully derived an expression for scattering amplitude and proved uniqueness of the potential using scattering amplitude information.", "conclusion": "The study provides a mathematical framework for solving inverse scattering problems in fractional quantum systems through resolvent estimates and scattering amplitude analysis."}}
{"id": "2509.12873", "pdf": "https://arxiv.org/pdf/2509.12873", "abs": "https://arxiv.org/abs/2509.12873", "authors": ["Gianluca Gaglioti", "Alessandra Cardinale", "Cosimo Lupo", "Thierry Nieus", "Federico Marmoreo", "Robin Gutzen", "Michael Denker", "Andrea Pigorini", "Marcello Massimini", "Simone Sarasso", "Pier Stanislao Paolucci", "Giulia De Bonis"], "title": "Emergent complexity and rhythms in evoked and spontaneous dynamics of human whole-brain models after tuning through analysis tools", "categories": ["q-bio.NC", "cs.DC", "physics.comp-ph"], "comment": "44 pages and 6 figures, plus 6 supplementary figures", "summary": "The simulation of whole-brain dynamics should reproduce realistic spontaneous\nand evoked neural activity across different scales, including emergent rhythms,\nspatio-temporal activation patterns, and macroscale complexity. Once a\nmathematical model is selected, its configuration must be determined by\nproperly setting its parameters. A critical preliminary step in this process is\ndefining an appropriate set of observables to guide the selection of model\nconfigurations (parameter tuning), laying the groundwork for quantitative\ncalibration of accurate whole-brain models. Here, we address this challenge by\npresenting a framework that integrates two complementary tools: The Virtual\nBrain (TVB) platform for simulating whole-brain dynamics, and the Collaborative\nBrain Wave Analysis Pipeline (Cobrawap) for analyzing the simulations using a\nset of standardized metrics. We apply this framework to a 998-node human\nconnectome, using two configurations of the Larter-Breakspear neural mass\nmodel: one with the TVB default parameters, the other tuned using Cobrawap. The\nresults reveal that the tuned configuration exhibits several biologically\nrelevant features, absent in the default model for both spontaneous and evoked\ndynamics. In response to external perturbations, the tuned model generates\nnon-stereotyped, complex spatio-temporal activity, as measured by the\nperturbational complexity index. In spontaneous activity, it displays robust\nalpha-band oscillations, infra-slow rhythms, scale-free characteristics,\ngreater spatio-temporal heterogeneity, and asymmetric functional connectivity.\nThis work demonstrates the potential of combining TVB and Cobrawap to guide\nparameter tuning and lays the groundwork for data-driven calibration and\nvalidation of accurate whole-brain models.", "AI": {"tldr": "A framework combining TVB simulation platform and Cobrawap analysis pipeline enables effective parameter tuning for whole-brain models, producing more biologically realistic neural activity compared to default configurations.", "motivation": "To develop a systematic approach for parameter tuning in whole-brain models that can reproduce realistic spontaneous and evoked neural activity across different scales, addressing the challenge of proper model configuration.", "method": "Integrated The Virtual Brain (TVB) platform for whole-brain simulation with Collaborative Brain Wave Analysis Pipeline (Cobrawap) for standardized metric analysis. Applied to 998-node human connectome using Larter-Breakspear neural mass model with both default and Cobrawap-tuned parameters.", "result": "The tuned configuration showed biologically relevant features absent in default model: non-stereotyped complex spatio-temporal activity in response to perturbations, robust alpha-band oscillations, infra-slow rhythms, scale-free characteristics, greater spatio-temporal heterogeneity, and asymmetric functional connectivity in spontaneous activity.", "conclusion": "The TVB-Cobrawap combination demonstrates strong potential for guiding parameter tuning and provides groundwork for data-driven calibration and validation of accurate whole-brain models."}}
{"id": "2509.13052", "pdf": "https://arxiv.org/pdf/2509.13052", "abs": "https://arxiv.org/abs/2509.13052", "authors": ["Weiping Bu", "Chen Nie", "Weizhi Liao"], "title": "Finite element method for a constant time delay subdiffusion equation with Riemann-Liouville fractional derivative", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This work considers to numerically solve a subdiffusion equation involving\nconstant time delay $\\tau$ and Riemann-Liouville fractional derivative. First,\na fully discrete finite element scheme is developed for the considered problem\nunder the symmetric graded time mesh, where the Caputo fractional derivative is\napproximated via the L1 formula, while the Riemann-Liouville integral is\ndiscretized using the fractional right rectangular rule. Under the assumption\nthat the exact solution has low regularities at $t=0$ and $\\tau$, the local\ntruncation errors of both the L1 formula and the fractional right rectangular\nrule are analyzed. It is worth noting that, by setting the mesh parameter\n$r=1$, the symmetric graded time mesh will degenerate to a uniform mesh.\nConsequently, we proceed to discuss the stability and convergence of the\nproposed numerical scheme under two scenarios. For the uniform time mesh, by\nintroducing a discrete sequence $\\{P_k\\}$, the unconditional stability and\nlocal time error estimate for the developed scheme is established. Conversely,\non the symmetric graded time mesh, through the introduction of a discrete\nfractional Gronwall inequality, the stability and globally optimal time error\nestimate can be obtained. Finally, some numerical tests are presented to\nvalidate the theoretical results.", "AI": {"tldr": "Numerical solution of subdiffusion equation with time delay using finite element method with L1 formula and fractional right rectangular rule on symmetric graded time mesh, analyzing stability and convergence under different mesh scenarios.", "motivation": "To develop accurate numerical methods for solving subdiffusion equations with time delay and Riemann-Liouville fractional derivatives, addressing challenges posed by solution singularities at t=0 and \u03c4.", "method": "Fully discrete finite element scheme using L1 formula for Caputo derivative approximation and fractional right rectangular rule for Riemann-Liouville integral discretization on symmetric graded time mesh.", "result": "Established unconditional stability and local time error estimates for uniform mesh, and stability with globally optimal time error estimates for symmetric graded mesh through discrete fractional Gronwall inequality.", "conclusion": "The proposed numerical scheme effectively handles solution singularities and provides reliable results for subdiffusion equations with time delay, as validated by numerical tests."}}
{"id": "2509.12707", "pdf": "https://arxiv.org/pdf/2509.12707", "abs": "https://arxiv.org/abs/2509.12707", "authors": ["Ru Yan"], "title": "Normalized solutions of quasilinear Schr\u00f6dinger equation with Sobolev critical exponent on star-shaped bounded domains", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we consider a quasilinear Schr\\\"odinger equation with critical\nexponent on bounded domains. Via a dual approach, we establish the existence of\ntwo positive normalized solutions: one is a ground state and the other is a\nmountain pass solution.", "AI": {"tldr": "Existence of two positive normalized solutions for quasilinear Schrodinger equation with critical exponent on bounded domains", "motivation": "Study quasilinear Schrodinger equations with critical exponent, which are important in mathematical physics but challenging due to critical nonlinearity and normalization constraints", "method": "Dual approach to establish existence of solutions, focusing on ground state and mountain pass solutions with normalization constraints", "result": "Proved existence of two distinct positive normalized solutions: one ground state solution and one mountain pass solution", "conclusion": "Successful demonstration of multiple normalized solutions existence for critical quasilinear Schrodinger equations using dual methods"}}
{"id": "2509.12885", "pdf": "https://arxiv.org/pdf/2509.12885", "abs": "https://arxiv.org/abs/2509.12885", "authors": ["A. B. Kukushkin"], "title": "Generalization of the viscous stress tensor to the case of non-small gradients of hydrodynamic velocity: a path to numerical modeling of turbulence non-locality", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": "8 pages", "summary": "Generalization of the Chapman-Enskog method to the case of large gradients of\nhydrodynamic velocity allowed us to obtain an integral (over spatial\ncoordinates) representation of the viscous stress tensor in the Navier-Stokes\nequation. In the case of small path lengths of the medium disturbance, the\ntensor goes over to the standard form, which, as is known, is difficult to\napply to the description of tangential discontinuities and separated flows. The\nobtained expression can allow numerical modeling of the nonlocality of\nturbulence, expressed by the empirical Richardson t^3 law for pair correlations\nin a turbulent medium.", "AI": {"tldr": "Extended Chapman-Enskog method for large velocity gradients to derive nonlocal viscous stress tensor, enabling better modeling of turbulence nonlocality and handling tangential discontinuities.", "motivation": "Standard viscous stress tensor formulations struggle with describing tangential discontinuities and separated flows, particularly in turbulent media where nonlocal effects are important.", "method": "Generalized the Chapman-Enskog method to accommodate large hydrodynamic velocity gradients, deriving an integral representation of the viscous stress tensor over spatial coordinates.", "result": "Obtained a nonlocal viscous stress tensor that reduces to standard form for small disturbance path lengths, but can better handle complex flow phenomena and turbulence nonlocality.", "conclusion": "The derived integral representation enables numerical modeling of turbulence nonlocality and can describe empirical Richardson t^3 law for pair correlations in turbulent media."}}
{"id": "2509.13108", "pdf": "https://arxiv.org/pdf/2509.13108", "abs": "https://arxiv.org/abs/2509.13108", "authors": ["Erik Burman", "Janosch Preuss", "Tim van Beeck"], "title": "Variational data assimilation for the wave equation in heterogeneous media: Numerical investigation of stability", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In recent years, several numerical methods for solving the unique\ncontinuation problem for the wave equation in a homogeneous medium with given\ndata on the lateral boundary of the space-time cylinder have been proposed.\nThis problem enjoys Lipschitz stability if the geometric control condition is\nfulfilled, which allows devising optimally convergent numerical methods. In\nthis article, we investigate whether these results carry over to the case in\nwhich the medium exhibits a jump discontinuity. Our numerical experiments\nsuggest a positive answer. However, we also observe that the presence of\ndiscontinuities in the medium renders the computations far more demanding than\nin the homogeneous case.", "AI": {"tldr": "Numerical methods for wave equation unique continuation in homogeneous media extend to discontinuous media with jump discontinuities, though computational demands increase significantly.", "motivation": "To investigate whether existing numerical methods for solving the unique continuation problem in homogeneous wave equations can be extended to handle media with jump discontinuities while maintaining optimal convergence properties.", "method": "The authors conducted numerical experiments to test whether the Lipschitz stability and optimal convergence properties observed in homogeneous media under geometric control conditions carry over to discontinuous media cases.", "result": "Numerical experiments suggest positive results - the methods appear to work for discontinuous media, but computations become far more demanding compared to the homogeneous case.", "conclusion": "While the numerical methods for unique continuation in wave equations can be extended to handle jump discontinuities in the medium, the presence of such discontinuities significantly increases computational complexity and resource requirements."}}
{"id": "2509.12779", "pdf": "https://arxiv.org/pdf/2509.12779", "abs": "https://arxiv.org/abs/2509.12779", "authors": ["Jean-Michel Coron", "Joachim Krieger", "Shengquan Xiang"], "title": "Wave maps from circle to Riemannian manifold: global controllability is equivalent to homotopy", "categories": ["math.AP", "math.DG", "math.OC"], "comment": null, "summary": "We study wave maps from the circle to a general compact Riemannian manifold.\nWe prove that the global controllability of this geometric equation is\ncharacterized precisely by the homotopy class of the data. As a remarkable\nintermediate result, we establish uniform-time global controllability between\nsteady states, providing a partial answer to an open problem raised by Dehman,\nLebeau and Zuazua (2003). Finally, we obtain quantitative exponential stability\naround closed geodesics with negative sectional curvature. This work highlights\nthe rich interplay between partial differential equations, differential\ngeometry, and control theory.", "AI": {"tldr": "Global controllability of wave maps from circle to compact Riemannian manifolds is characterized by homotopy class, with uniform-time controllability between steady states and exponential stability around closed geodesics with negative curvature.", "motivation": "To understand the controllability properties of wave maps, a geometric PDE, and address an open problem raised by Dehman, Lebeau and Zuazua (2003) regarding uniform-time global controllability between steady states.", "method": "Study wave maps from the circle to compact Riemannian manifolds, analyzing global controllability through homotopy class characterization and establishing uniform-time controllability results.", "result": "Proved that global controllability is precisely characterized by homotopy class of data, established uniform-time global controllability between steady states, and obtained quantitative exponential stability around closed geodesics with negative sectional curvature.", "conclusion": "This work demonstrates the deep connections between PDEs, differential geometry, and control theory, solving a long-standing open problem and providing new insights into the controllability of geometric wave equations."}}
{"id": "2509.13017", "pdf": "https://arxiv.org/pdf/2509.13017", "abs": "https://arxiv.org/abs/2509.13017", "authors": ["Kwai-Kong Ng", "Min-Fong Yang"], "title": "Mitigating the sign problem by quantum computing", "categories": ["quant-ph", "cond-mat.other", "physics.comp-ph"], "comment": "9 pages, 4 figures", "summary": "The notorious sign problem severely limits the applicability of quantum Monte\nCarlo (QMC) simulations, as statistical errors grow exponentially with system\nsize and inverse temperature. A recent proposal of a quantum-computing\nstochastic series expansion (qc-SSE) method suggested that the problem could be\navoided by introducing constant energy shifts into the Hamiltonian. Here we\ncritically examine this framework and show that it does not strictly resolve\nthe sign problem for Hamiltonians with non-commuting terms. Instead, it\nprovides a practical mitigation strategy that suppresses the occurrence of\nnegative weights. Using the antiferromagnetic anisotropic XY chain as a test\ncase, we analyze the dependence of the average sign on system size,\ntemperature, anisotropy, and shift parameters. An operator contraction method\nis introduced to improve efficiency. Our results demonstrate that moderate\nshifts optimally balance sign mitigation and statistical accuracy, while large\nshifts amplify errors, leaving the sign problem unresolved but alleviated.", "AI": {"tldr": "The paper critically examines the qc-SSE method's claim of resolving the sign problem in quantum Monte Carlo simulations, showing it doesn't strictly solve the issue but provides mitigation through energy shifts that suppress negative weights.", "motivation": "To address the severe limitations of quantum Monte Carlo simulations caused by the sign problem, which makes statistical errors grow exponentially with system size and inverse temperature.", "method": "Analyzed the qc-SSE framework using antiferromagnetic anisotropic XY chain as test case, examined dependence of average sign on various parameters, and introduced operator contraction method to improve efficiency.", "result": "Moderate energy shifts optimally balance sign mitigation and statistical accuracy, while large shifts amplify errors. The method alleviates but does not resolve the sign problem for Hamiltonians with non-commuting terms.", "conclusion": "The qc-SSE method provides practical mitigation rather than strict resolution of the sign problem, offering a strategy to suppress negative weights through carefully tuned energy shifts."}}
{"id": "2509.13118", "pdf": "https://arxiv.org/pdf/2509.13118", "abs": "https://arxiv.org/abs/2509.13118", "authors": ["Yvain Bruned", "Paul Laubie"], "title": "Elementary differentials from multi-indices to rooted trees", "categories": ["math.NA", "cs.NA", "math.CO", "math.PR", "math.RT"], "comment": "24 pages", "summary": "Rooted trees are essential for describing numerical schemes via the so-called\nB-series. They have also been used extensively in rough analysis for expanding\nsolutions of singular Stochastic Partial Differential Equations (SPDEs). When\none considers scalar-valued equations, the most efficient combinatorial set is\nmulti-indices. In this paper, we investigate the existence of intermediate\ncombinatorial sets that will lie between multi-indices and rooted trees. We\nprovide a negative result stating that there is no combinatorial set encoding\nelementary differentials in dimension $d\\neq 1$, and compatible with the rooted\ntrees and the multi-indices aside from the rooted trees. This does not close\nthe debate of the existence of such combinatorial sets, but it shows that it\ncannot be obtained via a naive and natural approach.", "AI": {"tldr": "No intermediate combinatorial sets exist between multi-indices and rooted trees for encoding elementary differentials in dimensions d\u22601, showing naive approaches won't work.", "motivation": "To find intermediate combinatorial sets between multi-indices and rooted trees that could more efficiently describe numerical schemes and expand solutions of singular SPDEs.", "method": "Investigated the existence of combinatorial sets lying between multi-indices and rooted trees, focusing on encoding elementary differentials while maintaining compatibility with both existing structures.", "result": "Negative result - no such intermediate combinatorial sets exist for dimensions d\u22601 aside from rooted trees themselves.", "conclusion": "While this doesn't completely close the debate, it demonstrates that intermediate combinatorial sets cannot be obtained through naive or natural approaches, suggesting more sophisticated methods would be needed."}}
{"id": "2509.12848", "pdf": "https://arxiv.org/pdf/2509.12848", "abs": "https://arxiv.org/abs/2509.12848", "authors": ["Guy Barles", "Olivier Ley", "Erwin Topp"], "title": "Degenerate Elliptic PDEs on a Network with Kirchhoff Conditions", "categories": ["math.AP"], "comment": null, "summary": "In this article, we are interested in semilinear, possibly degenerate\nelliptic equations posed on a general network, with nonlinear Kirchhoff-type\nconditions for its interior vertices and Dirichlet boundary conditions for the\nboundary ones. The novelty here is the generality of the equations posed on\neach edge that is incident to a particular vertex, ranging from first-order\nequations to uniformly elliptic ones. Our main result is a strong comparison\nprinciple, i.e., a comparison result between discontinuous viscosity sub and\nsupersolutions of such problems, from which we conclude the existence and\nuniqueness of a continuous viscosity by Perron's method. Further extensions are\nalso discussed.", "AI": {"tldr": "Strong comparison principle for semilinear degenerate elliptic equations on networks with nonlinear Kirchhoff conditions, enabling existence and uniqueness of continuous viscosity solutions via Perron's method.", "motivation": "To establish comparison principles for general semilinear elliptic equations on networks with varying equation types (from first-order to uniformly elliptic) incident to vertices, particularly with nonlinear Kirchhoff-type interior vertex conditions.", "method": "Develops a strong comparison principle between discontinuous viscosity sub- and supersolutions for the network problem, then applies Perron's method to obtain continuous viscosity solutions.", "result": "Proves a strong comparison principle that allows concluding existence and uniqueness of continuous viscosity solutions for the general network problem.", "conclusion": "The framework successfully handles general semilinear degenerate elliptic equations on networks with mixed equation types and nonlinear vertex conditions, providing fundamental comparison tools and solution existence/uniqueness results."}}
{"id": "2509.13138", "pdf": "https://arxiv.org/pdf/2509.13138", "abs": "https://arxiv.org/abs/2509.13138", "authors": ["Paul Garnier", "Vincent Lannelongue", "Elie Hachem"], "title": "Curriculum Learning for Mesh-based simulations", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Graph neural networks (GNNs) have emerged as powerful surrogates for\nmesh-based computational fluid dynamics (CFD), but training them on\nhigh-resolution unstructured meshes with hundreds of thousands of nodes remains\nprohibitively expensive. We study a \\emph{coarse-to-fine curriculum} that\naccelerates convergence by first training on very coarse meshes and then\nprogressively introducing medium and high resolutions (up to \\(3\\times10^5\\)\nnodes). Unlike multiscale GNN architectures, the model itself is unchanged;\nonly the fidelity of the training data varies over time. We achieve comparable\ngeneralization accuracy while reducing total wall-clock time by up to 50\\%.\nFurthermore, on datasets where our model lacks the capacity to learn the\nunderlying physics, using curriculum learning enables it to break through\nplateaus.", "AI": {"tldr": "Coarse-to-fine curriculum learning accelerates GNN training for CFD by starting with coarse meshes and progressively increasing resolution, reducing training time by 50% while maintaining accuracy.", "motivation": "Training graph neural networks on high-resolution unstructured meshes for computational fluid dynamics is computationally expensive and time-consuming.", "method": "A coarse-to-fine curriculum approach where the model trains first on very coarse meshes, then progressively introduces medium and high resolutions (up to 300,000 nodes) without changing the model architecture.", "result": "Achieved comparable generalization accuracy while reducing total wall-clock training time by up to 50%. Also enabled models to break through plateaus when lacking capacity to learn underlying physics.", "conclusion": "Curriculum learning with progressive mesh resolution provides an effective way to accelerate GNN training for CFD applications without architectural changes, offering significant time savings and improved learning capability."}}
{"id": "2509.13223", "pdf": "https://arxiv.org/pdf/2509.13223", "abs": "https://arxiv.org/abs/2509.13223", "authors": ["Veronika Chronholm", "Tristan Pryer"], "title": "Geometry, Energy and Sensitivity in Stochastic Proton Dynamics", "categories": ["math.NA", "cs.NA"], "comment": "28 pages, 12 figures", "summary": "We develop numerical schemes and sensitivity methods for stochastic models of\nproton transport that couple energy loss, range straggling and angular\ndiffusion. For the energy equation we introduce a logarithmic Milstein scheme\nthat guarantees positivity and achieves strong order one convergence. For the\nangular dynamics we construct a Lie-group integrator. The combined method\nmaintains the natural geometric invariants of the system.\n  We formulate dose deposition as a regularised path-dependent functional,\nobtaining a pathwise sensitivity estimator that is consistent and\nimplementable. Numerical experiments confirm that the proposed schemes achieve\nthe expected convergence rates and provide stable estimates of dose\nsensitivities.", "AI": {"tldr": "Numerical schemes and sensitivity methods for proton transport models with energy loss, range straggling, and angular diffusion, featuring positivity-preserving logarithmic Milstein scheme and Lie-group integrator.", "motivation": "To develop accurate and stable numerical methods for stochastic proton transport models that maintain geometric invariants and enable reliable dose sensitivity estimation.", "method": "Logarithmic Milstein scheme for energy equation (positivity guarantee, strong order one convergence), Lie-group integrator for angular dynamics, combined approach preserving geometric invariants, and regularized path-dependent functional for dose deposition.", "result": "Numerical experiments confirm expected convergence rates and provide stable estimates of dose sensitivities.", "conclusion": "The proposed schemes successfully achieve the desired convergence properties while maintaining system invariants and enabling consistent, implementable sensitivity estimation for proton transport modeling."}}
{"id": "2509.12935", "pdf": "https://arxiv.org/pdf/2509.12935", "abs": "https://arxiv.org/abs/2509.12935", "authors": ["Noureddine Igbida", "Fahd Karami", "Driss Meskine"], "title": "Mathematical Study of Reaction-Diffusion in Congested Crowd Motion", "categories": ["math.AP"], "comment": null, "summary": "This paper establishes existence, uniqueness, and an L^1-comparison principle\nfor weak solutions of a PDE system modeling phase transition reaction-diffusion\nin congested crowd motion. We consider a general reaction term and mixed\nhomogeneous (Dirichlet and Neumann) boundary conditions. This model is\napplicable to various problems, including multi-species diffusion-segregation\nand pedestrian dynamics with congestion. Furthermore, our analysis of the\nreaction term yields sufficient conditions combining the drift with the\nreaction that guarantee the absence of congestion, reducing the dynamics to a\nconstrained linear reaction-transport equation.", "AI": {"tldr": "Existence, uniqueness and L^1-comparison principle for weak solutions of PDE system modeling phase transition reaction-diffusion in congested crowd motion with general reaction terms and mixed boundary conditions.", "motivation": "To develop a mathematical framework for modeling phase transition reaction-diffusion in congested crowd motion, applicable to multi-species diffusion-segregation and pedestrian dynamics with congestion constraints.", "method": "Analysis of PDE system with general reaction term and mixed homogeneous (Dirichlet and Neumann) boundary conditions, establishing existence and uniqueness of weak solutions through L^1-comparison principle.", "result": "Established existence, uniqueness, and L^1-comparison principle for weak solutions. Derived sufficient conditions combining drift with reaction that guarantee absence of congestion, reducing dynamics to constrained linear reaction-transport equation.", "conclusion": "The paper provides rigorous mathematical foundations for congested crowd motion models with phase transitions, offering both general solutions and specific conditions where congestion constraints can be simplified to linear transport equations."}}
{"id": "2509.13224", "pdf": "https://arxiv.org/pdf/2509.13224", "abs": "https://arxiv.org/abs/2509.13224", "authors": ["Quoc Thai Tran", "Duc P. Truong", "Kim \u00d8. Rasmussen", "Boian Alexandrov"], "title": "A Tensor Train-Based Isogeometric Solver for Large-Scale 3D Poisson Problems on Complex Geometries", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We introduce a three-dimensional (3D) fully tensor train (TT)-assembled\nisogeometric analysis (IGA) framework, TT-IGA, for solving partial differential\nequations (PDEs) on complex geometries. Our method reformulates IGA discrete\noperators into TT format, enabling efficient compression and computation while\nretaining geometric flexibility and accuracy. Unlike previous low-rank\napproaches that typically rely on structured domains, our framework\naccommodates general 3D geometries through low-rank TT representations of both\nthe geometry mapping and the PDE discretization. We demonstrate the\neffectiveness of the proposed TT-IGA framework on the 3D Poisson equation,\nachieving substantial reductions in memory usage and computational cost without\ncompromising solution quality.", "AI": {"tldr": "TT-IGA: A 3D tensor train-based isogeometric analysis framework that compresses PDE operators for efficient computation on complex geometries while maintaining accuracy.", "motivation": "To enable efficient solution of PDEs on complex 3D geometries by combining tensor train compression with isogeometric analysis, overcoming limitations of previous low-rank methods that required structured domains.", "method": "Reformulates IGA discrete operators into tensor train (TT) format, creating low-rank TT representations for both geometry mapping and PDE discretization to handle general 3D geometries.", "result": "Achieves substantial reductions in memory usage and computational cost for solving 3D Poisson equation without compromising solution quality.", "conclusion": "The TT-IGA framework successfully enables efficient PDE solving on complex 3D geometries through tensor train compression while retaining geometric flexibility and accuracy."}}
{"id": "2509.13005", "pdf": "https://arxiv.org/pdf/2509.13005", "abs": "https://arxiv.org/abs/2509.13005", "authors": ["Mi-Song Dupuy", "Virginie Ehrlacher", "Cl\u00e9ment Guillot"], "title": "Low-complexity approximations with least-squares formulation of the time-dependent Schr{\u00f6}dinger equation", "categories": ["math.AP"], "comment": null, "summary": "We propose new methods designed to numerically approximate the solution to\nthe time dependent Schr{\\\"o}dinger equation, based on two types of ansatz:\ntensors, and approximation by a linear combination of gaussian wave packets. In\nboth cases, the method can be seen as a restricted optimization problem, which\ncan be solved by adapting either the Alternating Least Square algorithm in the\ntensor case, or some greedy algorithm in the gaussian wavepacket case. We also\ndiscuss the efficiency of both approaches.", "AI": {"tldr": "New numerical methods for solving time-dependent Schr\u00f6dinger equation using tensor and gaussian wavepacket approximations with optimization algorithms.", "motivation": "To develop efficient numerical approximation methods for solving the time-dependent Schr\u00f6dinger equation, which is fundamental in quantum mechanics.", "method": "Two approaches: 1) Tensor-based approximation solved with Alternating Least Square algorithm, 2) Linear combination of gaussian wave packets solved with greedy algorithms.", "result": "Proposed methods provide numerical approximation solutions to the time-dependent Schr\u00f6dinger equation through restricted optimization problems.", "conclusion": "Both tensor and gaussian wavepacket approaches offer viable methods for approximating solutions to the Schr\u00f6dinger equation, with efficiency considerations discussed for each approach."}}
{"id": "2509.13259", "pdf": "https://arxiv.org/pdf/2509.13259", "abs": "https://arxiv.org/abs/2509.13259", "authors": ["Matthew Goeckner", "Donovan Harcey", "Rainier Q Pederson", "Axel Niyonzima", "John Zweck"], "title": "A generalized reduction scheme for the Stochastic Weighted Particle Method", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "65C05, 65Z05, 76P05, 82C22"], "comment": "26 pages", "summary": "The Stochastic Weighted Particle Method (SWPM) of Rjasanow and Wagner is a\ngeneralization of the Direct Simulation Monte Carlo method for computing the\nprobability density function of the velocities of a system of interacting\nparticles for applications that include rarefied gas dynamics and plasma\nprocessing systems. Key components of a SWPM simulation are a particle grouping\ntechnique and particle reduction scheme. These are periodically applied to\nreduce the computational cost of simulations due to the gradual increase in the\nnumber of stochastic particles. A general framework for designing particle\nreduction schemes is introduced that enforces the preservation of a prescribed\nset of moments of the distribution through the construction and explicit\nsolution of a system of linear equations for particle weights in terms of\nparticle velocities and the moments to be preserved. This framework is applied\nto preserve all moments of the distribution up to order three. Numerical\nsimulations are performed to verify the scheme and quantify the degree to which\neven higher-order moments and tail functionals are preserved. These results\nreveal an unexpected trade off between the preservation of these higher-order\nmoments and tail functionals.", "AI": {"tldr": "A general framework for particle reduction in Stochastic Weighted Particle Method that preserves moments up to order 3, with analysis showing trade-offs between preserving higher-order moments and tail functionals.", "motivation": "To reduce computational cost in SWPM simulations by developing particle reduction schemes that preserve key statistical moments of the particle distribution.", "method": "Developed a framework using linear equations to preserve prescribed moments during particle reduction, specifically applied to preserve all moments up to third order.", "result": "Numerical simulations verified the scheme and revealed an unexpected trade-off between preserving higher-order moments and tail functionals of the distribution.", "conclusion": "The framework successfully enables moment-preserving particle reduction but shows limitations in simultaneously preserving both high-order moments and tail characteristics."}}
{"id": "2509.13012", "pdf": "https://arxiv.org/pdf/2509.13012", "abs": "https://arxiv.org/abs/2509.13012", "authors": ["Kazuyuki Tsuda"], "title": "Perturbation theory of the compressible Navier-Stokes equations and its application", "categories": ["math.AP", "35Q30, 35B20, 76N06, 35L05"], "comment": null, "summary": "In this article, a perturbation theory of the compressible Navier-Stokes\nequations in $\\mathbb{R}^n$ $(n \\geq 3)$ is studied to investigate decay\nestimate of solutions around a non-constant state. As a concrete problem,\nstability is considered for a perturbation system from a stationary solution\n$u_\\omega$ belonging to the weak $L^n$ space. Decay rates of the perturbation\nincluding $L^\\infty$ norm are obtained which coincide with those of the heat\nkernel. The proof is based on deriving suitable resolvent estimates with\nperturbation terms in the low frequency part having a parabolic spectral curve.\nOur method can be applicable to dispersive hyperbolic systems like wave\nequations with strong damping. Indeed, a parabolic type decay rate of a\nsolution is obtained for a damped wave equation including variable coefficients\nwhich satisfy spatial decay conditions.", "AI": {"tldr": "Perturbation theory for compressible Navier-Stokes equations in R^n (n\u22653) showing decay estimates around non-constant states, with stability analysis from weak L^n stationary solutions.", "motivation": "To investigate decay properties and stability of solutions around non-constant stationary states in compressible Navier-Stokes equations, extending beyond constant state analysis.", "method": "Deriving resolvent estimates with perturbation terms in low frequency part having parabolic spectral curve, applicable to dispersive hyperbolic systems like damped wave equations.", "result": "Obtained decay rates for perturbations (including L\u221e norm) that coincide with heat kernel decay rates, with method applicable to damped wave equations with variable coefficients.", "conclusion": "The perturbation theory successfully establishes decay estimates around non-constant states, with methodology extendable to other dispersive hyperbolic systems, demonstrating parabolic-type decay rates."}}
{"id": "2509.13260", "pdf": "https://arxiv.org/pdf/2509.13260", "abs": "https://arxiv.org/abs/2509.13260", "authors": ["Yewei Xu", "Qin Li"], "title": "Forward Euler for Wasserstein Gradient Flows: Breakdown and Regularization", "categories": ["math.NA", "cs.NA", "math.OC", "65J20, 35Q49"], "comment": null, "summary": "Wasserstein gradient flows have become a central tool for optimization\nproblems over probability measures. A natural numerical approach is\nforward-Euler time discretization. We show, however, that even in the simple\ncase where the energy functional is the Kullback-Leibler (KL) divergence\nagainst a smooth target density, forward-Euler can fail dramatically: the\nscheme does not converge to the gradient flow, despite the fact that the first\nvariation $\\nabla\\frac{\\delta F}{\\delta\\rho}$ remains formally well defined at\nevery step. We identify the root cause as a loss of regularity induced by the\ndiscretization, and prove that a suitable regularization of the functional\nrestores the necessary smoothness, making forward-Euler a viable solver that\nconverges in discrete time to the global minimizer.", "AI": {"tldr": "Forward-Euler discretization fails for Wasserstein gradient flows with KL divergence due to loss of regularity, but regularization restores convergence.", "motivation": "Wasserstein gradient flows are important for optimization over probability measures, but standard numerical approaches like forward-Euler can fail even in simple cases like KL divergence minimization.", "method": "Analysis of forward-Euler time discretization for Wasserstein gradient flows with KL divergence, identification of regularity loss issue, and proposal of functional regularization to restore smoothness.", "result": "Forward-Euler discretization does not converge to the gradient flow for KL divergence minimization due to loss of regularity, but with proper regularization, forward-Euler becomes a viable solver that converges to the global minimizer.", "conclusion": "Regularization is necessary to make forward-Euler a convergent numerical scheme for Wasserstein gradient flows with KL divergence, addressing the fundamental issue of lost smoothness in discretization."}}
{"id": "2509.13188", "pdf": "https://arxiv.org/pdf/2509.13188", "abs": "https://arxiv.org/abs/2509.13188", "authors": ["Louis Gar\u00e9naux", "Bj\u00f6rn de Rijk"], "title": "Global existence and decay of small solutions in a viscous half Klein-Gordon equation", "categories": ["math.AP"], "comment": "17 pages", "summary": "We establish global existence and decay of solutions of a viscous half\nKlein-Gordon equation with a quadratic nonlinearity considering initial data,\nwhose Fourier transform is small in L1 cap Linfty. Our analysis relies on the\nobservation that nonresonant dispersive effects yield a transformation of the\nquadratic nonlinearity into a subcritical nonlocal quartic one, which can be\ncontrolled by the linear diffusive dynamics through a standard L1 - Linfty\nargument. This transformation can be realized by applying the normal form\nmethod of Shatah or, equivalently, through integration by parts in time in the\nassociated Duhamel formula.", "AI": {"tldr": "Global existence and decay for viscous half Klein-Gordon equation with quadratic nonlinearity using normal form transformation to handle nonlinear terms", "motivation": "To establish global existence and decay properties for solutions of viscous half Klein-Gordon equations with quadratic nonlinearities, particularly for initial data with small Fourier transforms in L1\u2229L\u221e spaces", "method": "Apply normal form method (Shatah) or integration by parts in time in Duhamel formula to transform quadratic nonlinearity into subcritical nonlocal quartic nonlinearity, then use standard L1-L\u221e argument to control it via linear diffusive dynamics", "result": "Successfully established global existence and decay of solutions by leveraging nonresonant dispersive effects to transform the problematic quadratic nonlinearity into a more manageable quartic form", "conclusion": "The transformation approach through normal form methods effectively handles quadratic nonlinearities in viscous half Klein-Gordon equations, enabling global existence and decay results for small initial data"}}
{"id": "2509.12467", "pdf": "https://arxiv.org/pdf/2509.12467", "abs": "https://arxiv.org/abs/2509.12467", "authors": ["Sriram Nagaraj", "Vishakh Hari"], "title": "Nonlocal Neural Tangent Kernels via Parameter-Space Interactions", "categories": ["cs.LG", "cs.NA", "math.NA", "90C56"], "comment": null, "summary": "The Neural Tangent Kernel (NTK) framework has provided deep insights into the\ntraining dynamics of neural networks under gradient flow. However, it relies on\nthe assumption that the network is differentiable with respect to its\nparameters, an assumption that breaks down when considering non-smooth target\nfunctions or parameterized models exhibiting non-differentiable behavior. In\nthis work, we propose a Nonlocal Neural Tangent Kernel (NNTK) that replaces the\nlocal gradient with a nonlocal interaction-based approximation in parameter\nspace. Nonlocal gradients are known to exist for a wider class of functions\nthan the standard gradient. This allows NTK theory to be extended to nonsmooth\nfunctions, stochastic estimators, and broader families of models. We explore\nboth fixed-kernel and attention-based formulations of this nonlocal operator.\nWe illustrate the new formulation with numerical studies.", "AI": {"tldr": "Proposes Nonlocal Neural Tangent Kernel (NNTK) to extend NTK theory to non-smooth functions and broader model classes by replacing local gradients with nonlocal approximations.", "motivation": "The standard Neural Tangent Kernel framework assumes differentiability, which breaks down for non-smooth target functions and models with non-differentiable behavior, limiting its applicability.", "method": "Introduces a Nonlocal Neural Tangent Kernel that uses nonlocal interaction-based approximations instead of local gradients, enabling analysis of nonsmooth functions and stochastic estimators through fixed-kernel and attention-based formulations.", "result": "The NNTK framework extends NTK theory to handle non-smooth functions and broader model families, with numerical studies demonstrating its effectiveness.", "conclusion": "The proposed Nonlocal Neural Tangent Kernel successfully generalizes the NTK framework to non-smooth settings, expanding its theoretical reach and practical applicability to a wider range of neural network behaviors."}}
{"id": "2509.13226", "pdf": "https://arxiv.org/pdf/2509.13226", "abs": "https://arxiv.org/abs/2509.13226", "authors": ["Wenjie Deng", "Song Jiang", "Minling Li", "Zhaonan Lou"], "title": "Vorticity blow-up for the 3D incompressible Euler equations", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we study the finite-time blow-up for classical solutions of\nthe 3D incompressible Euler equations with low-regularity initial vorticity.\nApplying the self-similar method and stability analysis of the self-similar\nsystem in critical Sobolev space, we prove that the vorticity of the\naxi-symmetric 3D Euler equations develops a finite-time singularity with\ncertain scaling indices. Furthermore, we investigate the time integrability of\nthe solutions. The proof is based on the new observations for the null\nstructure of the transport term, and the parameter stability of the fundamental\nself-similar models.", "AI": {"tldr": "Finite-time blow-up analysis for 3D Euler equations with low-regularity initial vorticity using self-similar methods and stability analysis.", "motivation": "To understand the formation of finite-time singularities in 3D incompressible Euler equations, particularly for axi-symmetric cases with low-regularity initial conditions.", "method": "Applied self-similar method and stability analysis in critical Sobolev space, investigated null structure of transport term, and analyzed parameter stability of fundamental self-similar models.", "result": "Proved that vorticity of axi-symmetric 3D Euler equations develops finite-time singularity with specific scaling indices, and examined time integrability of solutions.", "conclusion": "The study provides rigorous mathematical proof of finite-time blow-up in 3D Euler equations using novel analytical techniques focused on self-similar structures and stability properties."}}
{"id": "2509.12666", "pdf": "https://arxiv.org/pdf/2509.12666", "abs": "https://arxiv.org/abs/2509.12666", "authors": ["Charuka D. Wickramasinghe", "Krishanthi C. Weerasinghe", "Pradeep K. Ranaweera"], "title": "PBPK-iPINNs : Inverse Physics-Informed Neural Networks for Physiologically Based Pharmacokinetic Brain Models", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "65L04, 65L09, 92B20"], "comment": "24 pages, 11 figures", "summary": "Physics-Informed Neural Networks (PINNs) leverage machine learning with\ndifferential equations to solve direct and inverse problems, ensuring\npredictions follow physical laws. Physiologically based pharmacokinetic (PBPK)\nmodeling advances beyond classical compartmental approaches by using a\nmechanistic, physiology focused framework. A PBPK model is based on a system of\nODEs, with each equation representing the mass balance of a drug in a\ncompartment, such as an organ or tissue. These ODEs include parameters that\nreflect physiological, biochemical, and drug-specific characteristics to\nsimulate how the drug moves through the body. In this paper, we introduce\nPBPK-iPINN, a method to estimate drug-specific or patient-specific parameters\nand drug concentration profiles in PBPK brain compartment models using inverse\nPINNs. We demonstrate that, for the inverse problem to converge to the correct\nsolution, the loss function components (data loss, initial conditions loss, and\nresidual loss) must be appropriately weighted, and parameters (including number\nof layers, number of neurons, activation functions, learning rate, optimizer,\nand collocation points) must be carefully tuned. The performance of the\nPBPK-iPINN approach is then compared with established traditional numerical and\nstatistical methods.", "AI": {"tldr": "PBPK-iPINN uses inverse Physics-Informed Neural Networks to estimate drug/patient parameters and concentration profiles in brain PBPK models, requiring careful loss weighting and parameter tuning for convergence.", "motivation": "To advance PBPK modeling beyond classical compartmental approaches by leveraging PINNs for parameter estimation while ensuring predictions follow physical laws described by ODEs.", "method": "Inverse PINNs approach with weighted loss function components (data loss, initial conditions loss, residual loss) and careful tuning of neural network parameters and collocation points.", "result": "Demonstrates that appropriate loss weighting and parameter tuning are crucial for convergence to correct solutions in inverse PBPK problems.", "conclusion": "PBPK-iPINN provides an effective framework for parameter estimation in PBPK brain compartment models, comparable to traditional numerical and statistical methods when properly configured."}}
{"id": "2309.05581", "pdf": "https://arxiv.org/pdf/2309.05581", "abs": "https://arxiv.org/abs/2309.05581", "authors": ["Lloyd Dafydd", "Richard Porter"], "title": "Attenuation of long waves through regions of irregular floating ice and bathymetry", "categories": ["physics.flu-dyn", "math.AP"], "comment": null, "summary": "Existing theoretical results for attenuation of surface waves propagating on\nwater of random fluctuating depth are shown to over predict the rate of decay\ndue to the way in which ensemble averaging is performed. A revised approach is\npresented which corrects this and is shown to conserve energy. New theoretical\npredictions are supported by numerical results which use averaging of\nsimulations of wave scattering over finite sections of random bathymetry for\nwhich transfer matrix eigenvalues are used to accurately measure decay. The\nmodel of wave propagation used in this paper is derived from a linearised long\nwavelength assumption whereby depth averaging leads to time harmonic waves\nbeing represented as solutions to a simple ordinary differential equation. In\nthis paper it is shown how this can be adapted to incorporate a model of a\ncontinuous covering of the surface by fragmented floating ice. Attenuation of\nwaves through broken ice of random thickness is then analysed in a similar\nmanner as bed variations previously and some comparisons are made with\npublished field data for attenuation of waves in the marginal ice zones. Key\nfeatures of the data are reproduced by theory including the attenuation being\nproportional to a power of frequency between 2 and 4 as well as capturing the\n\"roll-over effect\" at high frequencies.", "AI": {"tldr": "Revised theory for surface wave attenuation on random bathymetry that conserves energy, with applications to wave propagation through fragmented ice showing good agreement with field data.", "motivation": "Existing theoretical models overpredict wave attenuation rates due to improper ensemble averaging methods in random depth fluctuations.", "method": "Developed a revised approach using transfer matrix eigenvalues to accurately measure decay through finite sections of random bathymetry, adapting linearized long wavelength assumptions for both water depth variations and fragmented ice cover.", "result": "New theory conserves energy and numerical simulations support predictions. For broken ice, theory reproduces key field data features including frequency-dependent attenuation (power 2-4) and high-frequency roll-over effect.", "conclusion": "The corrected approach provides more accurate attenuation predictions for both random bathymetry and fragmented ice environments, successfully capturing observed physical phenomena in marginal ice zones."}}
{"id": "2508.20099", "pdf": "https://arxiv.org/pdf/2508.20099", "abs": "https://arxiv.org/abs/2508.20099", "authors": ["Lloyd Dafydd", "Richard Porter"], "title": "On the attenuation of waves through broken ice of randomly-varying thickness on water of finite depth", "categories": ["physics.ao-ph", "math.AP", "physics.flu-dyn"], "comment": "17 pages, 6 figures", "summary": "The recent work of Dafydd and Porter [2024] on the attenuation of waves\npropagating through floating broken ice of random thickness is extended to\nconsider water of non-shallow depth. A theoretical model of broken floating ice\nis analysed using a multiple scales analysis to provide an explicit expression\nfor the attenuation of waves as they propagate from a region of constant\nthickness ice into a semi-infinite region of ice whose thickness is a\nslowly-varying random function of distance. Theoretical predictions are shown\nto compare well to numerical simulations of scattering over long finite regions\nof ice of randomly-varying thickness computed from an approximate\ndepth-averaged model derived under a mild-slope assumption. The theory predicts\na low-frequency attenuation proportional to the eighth power of frequency and a\nroll-over effect at higher frequencies. The relationship between the results\nand field measurements are discussed.", "AI": {"tldr": "Extension of wave attenuation theory in floating broken ice to non-shallow water depths, showing good agreement between theoretical predictions and numerical simulations with frequency-dependent attenuation patterns.", "motivation": "To extend previous work on wave attenuation in floating broken ice with random thickness to account for non-shallow water depths, providing more realistic modeling of wave propagation in ice-covered waters.", "method": "Multiple scales analysis of a theoretical model for broken floating ice, comparing theoretical predictions with numerical simulations from an approximate depth-averaged model derived under mild-slope assumption.", "result": "Theoretical predictions show good agreement with numerical simulations. The theory predicts low-frequency attenuation proportional to the eighth power of frequency and a roll-over effect at higher frequencies.", "conclusion": "The extended model successfully captures wave attenuation in non-shallow water conditions, with frequency-dependent behavior that aligns with numerical simulations and has implications for interpreting field measurements."}}
{"id": "2509.13228", "pdf": "https://arxiv.org/pdf/2509.13228", "abs": "https://arxiv.org/abs/2509.13228", "authors": ["Lu\u00eds Baptista", "Matthias Hofmann"], "title": "On Courant-type bounds and spectral partitioning via Neumann domains on quantum graphs", "categories": ["math.SP", "math.AP", "34B45, 35P15, 35R02, 49Q10, 81Q35"], "comment": null, "summary": "We study the structure of eigenfunctions of the Laplacian on quantum graphs,\nwith a particular focus on Morse eigenfunctions via nodal and Neumann domains.\nBuilding on Courant-type arguments, we establish upper bounds for the number of\nnodal points and explore conditions under which Neumann domains of\neigenfunctions correspond to minimizers to a class of spectral partition\nproblems often known as spectral minimal partitions. The main focus will be the\nanalysis on tree graphs, where we characterize the spectral energies of such\npartitions and relate them to the eigenvalues of the Laplacian under genericity\nassumptions. Notably, we introduce a notion analogous to Courant-sharpness for\nNeumann counts and demonstrate when spectral minimal partitions coincide with\npartitions formed by Neumann domains of eigenfunctions.", "AI": {"tldr": "Analysis of eigenfunctions on quantum graphs, focusing on Morse eigenfunctions and their nodal/Neumann domains. Establishes upper bounds for nodal points and connects Neumann domains to spectral minimal partitions, particularly on tree graphs.", "motivation": "To understand the structure of Laplacian eigenfunctions on quantum graphs and explore the relationship between Neumann domains of eigenfunctions and spectral minimal partition problems.", "method": "Uses Courant-type arguments to establish bounds on nodal points, analyzes conditions where Neumann domains correspond to minimizers of spectral partition problems, and focuses on tree graphs with genericity assumptions.", "result": "Characterizes spectral energies of partitions on tree graphs and relates them to Laplacian eigenvalues. Introduces a Courant-sharpness analog for Neumann counts and shows when spectral minimal partitions coincide with Neumann domain partitions.", "conclusion": "The paper provides new insights into the connection between eigenfunction structure and spectral partition problems on quantum graphs, particularly establishing relationships between Neumann domains and optimal partitions on tree graphs."}}
