{"id": "2509.14359", "pdf": "https://arxiv.org/pdf/2509.14359", "abs": "https://arxiv.org/abs/2509.14359", "authors": ["Hakop Hakopian", "Anush Khachatryan"], "title": "On the extension of a class of Hermite bivariate interpolation problems", "categories": ["math.NA", "cs.NA", "41A05, 41A63"], "comment": "17 pages", "summary": "We characterize the sets of solvability for Hermite bivariate interpolation\nproblems when the sum of multiplicities is at most $2n + 2$, with $n$ the\ndegree of the polynomial space. This result extends an earlier theorem (2000)\nby one of the authors concerning the case $2n+1$. The latter theorem, in turn,\ncan be regarded as a natural generalization of a classical theorem of Severi\n(1921).", "AI": {"tldr": "Characterization of solvability sets for Hermite bivariate interpolation problems when sum of multiplicities \u2264 2n+2, extending previous 2n+1 result and generalizing Severi's classical theorem.", "motivation": "To extend the understanding of Hermite bivariate interpolation solvability beyond the previously established 2n+1 multiplicity sum limit to 2n+2, building on earlier work and classical foundations.", "method": "Mathematical characterization and analysis of solvability conditions for Hermite bivariate interpolation problems using polynomial spaces of degree n.", "result": "Successfully characterized the sets of solvability for Hermite bivariate interpolation when the sum of multiplicities is at most 2n+2.", "conclusion": "This work provides an important extension of interpolation theory, generalizing previous results and connecting to classical mathematical foundations in the field."}}
{"id": "2509.14486", "pdf": "https://arxiv.org/pdf/2509.14486", "abs": "https://arxiv.org/abs/2509.14486", "authors": ["Agus L. Soenjaya", "Ping Lin", "Thanh Tran"], "title": "Error analysis of a fully discrete structure-preserving finite element scheme for a diffuse-interface model of tumour growth", "categories": ["math.NA", "cs.NA", "65M12, 65M15, 65M60, 35Q92"], "comment": null, "summary": "We develop a fully discrete structure-preserving finite element method for a\ndiffuse-interface model of tumour growth. The system couples a Cahn--Hilliard\ntype equation with a nonlinear reaction-diffusion equation for nutrient\nconcentration and admits a dissipative energy law at the continuous level. For\nthe discretisation, we employ a scalar auxiliary variable (SAV) formulation\ntogether with a mixed finite element method for the Cahn--Hilliard part and\nstandard conforming finite elements for the reaction-diffusion equation in\nspace, combined with a first-order Euler time-stepping scheme. The resulting\nmethod is linear, unconditionally energy-stable, mass-preserving, and inherits\na discrete energy dissipation law associated with the SAV-based approximate\nenergy functional, while requiring the solution of only linear systems at each\ntime step. Under suitable regularity assumptions on the exact solution, we\nderive rigorous error estimates in $L^2$, $H^1$, and $L^\\infty$ norms,\nestablishing first-order accuracy in time and optimal-order accuracy in space.\nA key step in this analysis is the proof of boundedness of the numerical\nsolutions in $L^\\infty$. Numerical experiments validate the theoretical\nconvergence rates and demonstrate the robustness of the method in capturing\ncharacteristic phenomena such as aggregation and chemotactic tumour growth.", "AI": {"tldr": "A structure-preserving finite element method for tumor growth modeling using Cahn-Hilliard and reaction-diffusion equations with SAV formulation, achieving linear, energy-stable, mass-preserving discretization with optimal convergence rates.", "motivation": "To develop a numerical method for tumor growth modeling that preserves the dissipative energy structure of the continuous diffuse-interface model while maintaining computational efficiency and stability.", "method": "Combines scalar auxiliary variable (SAV) formulation with mixed finite elements for Cahn-Hilliard and standard conforming elements for reaction-diffusion, using first-order Euler time-stepping. The method is linear, energy-stable, and mass-preserving.", "result": "The method achieves unconditional energy stability, preserves mass, requires only linear systems per time step, and demonstrates first-order time accuracy and optimal-order spatial accuracy with rigorous error estimates in L2, H1, and L\u221e norms.", "conclusion": "The developed method successfully captures tumor growth phenomena like aggregation and chemotaxis while maintaining mathematical structure preservation, computational efficiency, and proven convergence properties."}}
{"id": "2509.14491", "pdf": "https://arxiv.org/pdf/2509.14491", "abs": "https://arxiv.org/abs/2509.14491", "authors": ["Shi-Liang Wu", "Cui-Xia Li"], "title": "The extended horizontal linear complementarity problem: iterative methods and error analysis", "categories": ["math.NA", "cs.NA", "90C33, 65G50, 65G20"], "comment": "28 pages, 3 figures", "summary": "To the best of our knowledge, since the extended horizontal linear\ncomplementarity problem (EHLCP) was first introduced and studied by Kaneko in\n1977, no iterative methods or error analysis have been developed for it due to\nthe interdependence of its multiple unknowns in a 'chain-like' structure. This\npaper aims to address these gaps by:\n  (1) proposing an equivalent fixed-point formulation of the EHLCP by using a\nvariable transformation technique with the max-min function;\n  (2) developing efficient iterative methods for solving the EHLCP based on\nthis fixed-point form, along with their convergence analysis;\n  (3) deriving global error bounds and computable estimates for the EHLCP.\n  Several numerical examples from applications such as multicommodity market\nequilibrium and bilateral obstacle problems are given to demonstrate the\neffectiveness of the proposed methods and bounds.", "AI": {"tldr": "This paper addresses the extended horizontal linear complementarity problem (EHLCP) by developing iterative methods, convergence analysis, and error bounds for the first time since its introduction in 1977.", "motivation": "The EHLCP has remained unsolved with iterative methods for decades due to its complex 'chain-like' structure with interdependent multiple unknowns, creating a significant research gap.", "method": "Proposed an equivalent fixed-point formulation using variable transformation with max-min function, developed efficient iterative methods with convergence analysis, and derived global error bounds and computable estimates.", "result": "Successfully developed the first iterative methods for EHLCP with proven convergence properties and established error bounds, validated through numerical examples from multicommodity market equilibrium and bilateral obstacle problems.", "conclusion": "The paper fills a 40+ year research gap by providing effective computational methods and theoretical foundations for solving EHLCP, demonstrating practical applicability across various domains."}}
{"id": "2509.14500", "pdf": "https://arxiv.org/pdf/2509.14500", "abs": "https://arxiv.org/abs/2509.14500", "authors": ["Joseph Coyle", "Nilima Nigam"], "title": "The whys and hows of conditioning of DG plane wave Trefftz methods: a single element", "categories": ["math.NA", "cs.NA", "65F08, 65N30, 65N22"], "comment": "34 pages, 17 figures", "summary": "Plane-wave Trefftz methods (PWB) for the Helmholtz equation offer significant\nadvantages over standard discretization approaches whose implementation employs\nmore general polynomial basis functions. A disadvantage of these methods is the\npoor conditioning of the system matrices. In the present paper, we carefully\nexamine the conditioning of the plane-wave discontinuous Galerkin method with\nreference to a single element. The properties of the mass and stiffness\nmatrices depend on the size and geometry of the element. We study the mass and\nsystem matrices arising from a PWB on a single disk-shaped element. We then\nexamine some preconditioning strategies, and present results showing their\nbehaviour with three different criteria: conditioning, the behaviour of GMRES\nresiduals, and impact on the $L^2$-error.", "AI": {"tldr": "Analysis of plane-wave Trefftz methods for Helmholtz equation, focusing on conditioning issues and preconditioning strategies for single disk-shaped elements.", "motivation": "Plane-wave Trefftz methods offer advantages over standard polynomial-based approaches but suffer from poor conditioning of system matrices, which needs to be addressed.", "method": "Study conditioning of plane-wave discontinuous Galerkin method on single disk-shaped element, examining mass and stiffness matrices, and testing preconditioning strategies using conditioning metrics, GMRES residuals, and L^2-error impact.", "result": "The paper examines how element size and geometry affect matrix properties and evaluates preconditioning effectiveness through multiple criteria.", "conclusion": "Preconditioning strategies can improve the performance of plane-wave Trefftz methods by addressing conditioning issues, though effectiveness depends on element characteristics."}}
{"id": "2509.14400", "pdf": "https://arxiv.org/pdf/2509.14400", "abs": "https://arxiv.org/abs/2509.14400", "authors": ["Allen H Boozer"], "title": "Electron Inertia and Magnetic Reconnection", "categories": ["physics.plasm-ph", "astro-ph.SR"], "comment": null, "summary": "The finite electron mass can cause magnetic reconnection even in the absence\nof any other non-ideal effect in a magnetic evolution. It will be shown that\nwhen electron inertia is the only non-ideal effect in the evolution of the\nmagnetic field $\\vec{B}$, there is a related field that evolves ideally. This\nfield is $\\vec{\\mathcal{B}} \\equiv \\vec{B} + \\vec{\\nabla}\\times \\left( (m_e/n\ne^2) \\vec{j} \\right)$ with $m_e$ the electron mass, $n$ the electron number\ndensity, and $\\vec{j}$ the current density. Although the magnetic field is\nmodified from its ideal evolution form by the electron inertia, the effect on\nparticle trajectories, even electron trajectories, is small unless the current\nlies in thin sheets, which make $\\vec{j}$ extremely large. The field\n$\\vec{\\mathcal{B}}$ is closely related to Voigt normalized magnetic field,\nwhich is defined by a Laplacian smoothing of $\\vec{B}$. The difference between\n$\\vec{\\mathcal{B}}$ and $\\vec{B}$ involves the relativistically invariant\nfour-space Laplacian acting on $\\vec{B}$ with a $c/\\omega_{pe}$ smoothing\ndistance; $\\omega_{pe}$ is the plasma frequency.", "AI": {"tldr": "Electron inertia enables magnetic reconnection without other non-ideal effects, with a modified field evolving ideally while particle trajectories remain largely unaffected except in thin current sheets.", "motivation": "To understand how finite electron mass alone can cause magnetic reconnection and identify a related magnetic field that evolves ideally despite electron inertia effects.", "method": "Analysis of magnetic field evolution with electron inertia as the only non-ideal effect, introducing a modified field \u03b2 = B + \u2207\u00d7((m_e/ne\u00b2)j) that evolves ideally, and examining its relationship to Voigt normalized magnetic field.", "result": "Electron inertia enables magnetic reconnection without other non-ideal mechanisms. The field \u03b2 evolves ideally while B does not. Particle trajectories are minimally affected except in thin current sheets where currents become extremely large.", "conclusion": "Finite electron mass provides a fundamental mechanism for magnetic reconnection through electron inertia effects, with the modified field \u03b2 offering an ideal evolution framework while preserving most particle trajectory characteristics."}}
{"id": "2509.14352", "pdf": "https://arxiv.org/pdf/2509.14352", "abs": "https://arxiv.org/abs/2509.14352", "authors": ["Luan Hoang", "Akif Ibragimov"], "title": "Linear non-divergence elliptic equations in a bounded, infinitely winding planar domain", "categories": ["math.AP", "35A09, 35B30, 35B40, 35B50"], "comment": "submitted for publication, 27 pages, 2 figures", "summary": "We study the second order elliptic equations of non-divergence form in a\nplanar domain with complicated geometry. In this case the domain winds around a\nfixed circle infinitely many times and converges to it when the rotating angle\ngoes to infinity. For the homogeneous equation and the homogeneous Dirichlet\nboundary condition, in the case of bounded drifts, we prove that the maximum of\nthe solution on the cross-section corresponding to a given rotating angle\neither grows or decays exponentially as the angle goes to infinity. Results for\nthe oscillation and its asymptotic estimates are also obtained for\ninhomogeneous Dirichlet data. If the drift is unbounded but does not grow to\ninfinity too fast, then the above maximum also goes to either zero or infinity.\nFor the inhomogeneous equation, we obtain the estimates in the case of bounded\nforcing functions. Moreover, we establish the uniqueness of the solution and\nits continuous dependence on the boundary data and the forcing function.", "AI": {"tldr": "Analysis of second order elliptic equations in complex planar domains that wind infinitely around a circle, with results on solution behavior, oscillation estimates, and uniqueness for both homogeneous and inhomogeneous cases.", "motivation": "To understand how solutions to elliptic equations behave in domains with complicated geometry, particularly those that wind infinitely around a fixed circle, which presents unique mathematical challenges for boundary value problems.", "method": "Studied second order elliptic equations of non-divergence form in planar domains with complex winding geometry. Analyzed homogeneous equations with Dirichlet boundary conditions, examined cases with bounded and unbounded drifts, and investigated inhomogeneous equations with bounded forcing functions.", "result": "Proved that solutions exhibit exponential growth or decay behavior as the rotating angle approaches infinity. Obtained oscillation estimates for inhomogeneous Dirichlet data. Showed that even with unbounded drifts (if not growing too fast), solutions converge to zero or infinity. Established solution uniqueness and continuous dependence on boundary data and forcing functions.", "conclusion": "The complex winding geometry significantly impacts solution behavior of elliptic equations, leading to exponential growth/decay patterns. The research provides comprehensive understanding of solution properties in such geometrically challenging domains, with implications for mathematical analysis of partial differential equations in non-standard geometries."}}
{"id": "2509.14462", "pdf": "https://arxiv.org/pdf/2509.14462", "abs": "https://arxiv.org/abs/2509.14462", "authors": ["Marlyn Boke", "Timothy Sorochkin", "Jesse Anttila-Hughes", "Alan O. Jamison"], "title": "The Varieties of Schelling Model Experience", "categories": ["cond-mat.stat-mech", "physics.comp-ph"], "comment": null, "summary": "The Schelling model is a prototype for agent-based modeling in social\nsystems. A comprehensive analysis of Schelling model rule variants is achieved\nby classification of the space of macroscopic outcomes via phase diagrams.\nAmong 54 rule variants, only 3 phase diagram classes are found, characterized\nby the number of phase transitions. This classification scheme is found to be\nrobust to the use of sociological and percolation-inspired measures of\nsegregation. The statistical and dynamic drivers of these transitions are\nelucidated by analyzing the roles of vision, movement criteria, vacancies, the\ninitial state, and rivalry. Schelling's original step function dictating\nsatisfaction is found to be pathological at high thresholds, producing\ncoordination failures as satisfactory sites become increasingly rare. This\ncomprehensive classification gives new insight into the drivers of transitions\nin the Schelling model and creates a basis for studying more complex\nSchelling-like models.", "AI": {"tldr": "Comprehensive analysis of 54 Schelling model rule variants reveals only 3 distinct phase diagram classes based on number of phase transitions, with robust classification across different segregation measures.", "motivation": "To systematically classify and understand the macroscopic outcomes of various Schelling model rule variants, which serve as prototypes for agent-based social system modeling.", "method": "Classification of phase diagrams for 54 different rule variants, analyzing statistical and dynamic drivers including vision, movement criteria, vacancies, initial state, and rivalry. Used both sociological and percolation-inspired segregation measures.", "result": "Only 3 distinct phase diagram classes were identified, characterized by the number of phase transitions. Schelling's original step function was found to be pathological at high thresholds, causing coordination failures. The classification scheme proved robust across different segregation measurement approaches.", "conclusion": "This comprehensive classification provides new insights into transition drivers in the Schelling model and establishes a foundation for studying more complex Schelling-like models in social systems."}}
{"id": "2509.14575", "pdf": "https://arxiv.org/pdf/2509.14575", "abs": "https://arxiv.org/abs/2509.14575", "authors": ["Andrew Qing He", "Wei Cai"], "title": "Weak Adversarial Neural Pushforward Mappings for Fokker-Planck Equations", "categories": ["math.NA", "cs.NA", "65N75, 68T07, 35Q84"], "comment": "10 pages, 2 figures", "summary": "This paper presents a novel method for solving Fokker-Planck equations by\nlearning neural samplers via a weak adversarial framework. We represent the\nsolution distribution through a neural pushforward map, bypassing the\nlimitations of density-based methods. A key innovation is our use of\ncomputationally efficient plane-wave test functions, whose derivatives are\nexplicitly computed -- a treatment distinct from prior work. This approach\nhandles distributions without densities and naturally enforces probability\nconservation.", "AI": {"tldr": "Novel method for solving Fokker-Planck equations using neural samplers via weak adversarial framework with plane-wave test functions", "motivation": "To overcome limitations of density-based methods for solving Fokker-Planck equations and handle distributions without densities while enforcing probability conservation", "method": "Represent solution distribution through neural pushforward map, use computationally efficient plane-wave test functions with explicitly computed derivatives in a weak adversarial framework", "result": "Method can handle distributions without densities and naturally enforces probability conservation", "conclusion": "The approach provides an effective framework for solving Fokker-Planck equations with improved computational efficiency and broader applicability compared to traditional density-based methods"}}
{"id": "2509.14490", "pdf": "https://arxiv.org/pdf/2509.14490", "abs": "https://arxiv.org/abs/2509.14490", "authors": ["Agus L. Soenjaya", "Thanh Tran"], "title": "Strong solutions for a class of stochastic thermo-magneto-hydrodynamic-type systems with multiplicative noise", "categories": ["math.AP", "math.PR", "35Q30, 35Q35, 35Q60, 60H15"], "comment": null, "summary": "We study the existence and uniqueness of strong solutions, in the sense of\nPDEs and probability, for a broad class of nonlinear stochastic partial\ndifferential equations (SPDEs) on a bounded domain $\\mathscr{O}\\subset\n\\mathbb{R}^d$ ($d\\leq 3$), perturbed by spatially correlated multiplicative\nnoise. Our framework applies to many physically relevant systems, including\nstochastic convective Brinkman--Forchheimer equations, stochastic\nmagnetohydrodynamics (MHD), stochastic B\\'enard convection in porous media,\nstochastic convective dynamo models, and stochastic magneto-micropolar fluids,\namong others. The analysis relies on Galerkin approximations and compactness\narguments. Up to a suitable stopping time, we derive strong moment bounds and\nverify a Cauchy property for the approximate solutions, in the absence of any\ninherent cancellation structure. By applying a Gronwall-type lemma for\nstochastic processes, we establish the existence and uniqueness of maximal\nstrong pathwise solutions, which are global in two spatial dimensions. These\nresults provide a unified treatment of a wide class of nonlinear stochastic\nthermo-magneto-fluid models in the literature.", "AI": {"tldr": "Existence and uniqueness of strong solutions for nonlinear stochastic PDEs with multiplicative noise on bounded domains, covering various physical systems including fluid dynamics and magnetohydrodynamics.", "motivation": "To develop a unified framework for analyzing a broad class of nonlinear stochastic thermo-magneto-fluid models that appear in various physical applications, providing rigorous mathematical foundations for these complex systems.", "method": "Uses Galerkin approximations and compactness arguments, derives strong moment bounds and verifies Cauchy property for approximate solutions, applies Gronwall-type lemma for stochastic processes to establish maximal strong pathwise solutions.", "result": "Establishes existence and uniqueness of maximal strong pathwise solutions that are global in two spatial dimensions, providing a unified treatment for various stochastic thermo-magneto-fluid models.", "conclusion": "The paper provides a comprehensive mathematical framework for analyzing nonlinear stochastic PDEs with multiplicative noise, offering rigorous existence and uniqueness results for a wide range of physically relevant systems in fluid dynamics and magnetohydrodynamics."}}
{"id": "2509.14568", "pdf": "https://arxiv.org/pdf/2509.14568", "abs": "https://arxiv.org/abs/2509.14568", "authors": ["Hai Siong Tan", "Kuancheng Wang", "Rafe McBeth"], "title": "Evidential Physics-Informed Neural Networks for Scientific Discovery", "categories": ["cs.LG", "physics.comp-ph"], "comment": "15 pages, 4 figures", "summary": "We present the fundamental theory and implementation guidelines underlying\nEvidential Physics-Informed Neural Network (E-PINN) -- a novel class of\nuncertainty-aware PINN. It leverages the marginal distribution loss function of\nevidential deep learning for estimating uncertainty of outputs, and infers\nunknown parameters of the PDE via a learned posterior distribution. Validating\nour model on two illustrative case studies -- the 1D Poisson equation with a\nGaussian source and the 2D Fisher-KPP equation, we found that E-PINN generated\nempirical coverage probabilities that were calibrated significantly better than\nBayesian PINN and Deep Ensemble methods. To demonstrate real-world\napplicability, we also present a brief case study on applying E-PINN to analyze\nclinical glucose-insulin datasets that have featured in medical research on\ndiabetes pathophysiology.", "AI": {"tldr": "E-PINN is a novel uncertainty-aware Physics-Informed Neural Network that uses evidential deep learning for uncertainty estimation and parameter inference, outperforming Bayesian PINN and Deep Ensemble methods in calibration.", "motivation": "To develop a more reliable uncertainty-aware PINN framework that can better estimate output uncertainties and infer unknown PDE parameters through posterior distributions, addressing limitations of existing methods.", "method": "Leverages marginal distribution loss function from evidential deep learning for uncertainty estimation, infers unknown PDE parameters via learned posterior distribution, validated on 1D Poisson equation and 2D Fisher-KPP equation.", "result": "E-PINN generated significantly better calibrated empirical coverage probabilities compared to Bayesian PINN and Deep Ensemble methods, and demonstrated real-world applicability in clinical glucose-insulin dataset analysis.", "conclusion": "E-PINN represents an effective uncertainty-aware framework that provides well-calibrated uncertainty estimates and practical applicability to real-world problems, particularly in medical research contexts."}}
{"id": "2509.14580", "pdf": "https://arxiv.org/pdf/2509.14580", "abs": "https://arxiv.org/abs/2509.14580", "authors": ["Fuqun Han", "Kazufumi Ito"], "title": "A Weighted Sampling Method for Inverse Medium Problem with Limited Aperture", "categories": ["math.NA", "cs.NA", "35R30, 78A46"], "comment": null, "summary": "Inverse medium scattering problems arise in many applications, but in\npractice, the measurement data are often restricted to a limited aperture by\nphysical or experimental constraints. Classical sampling methods, such as MUSIC\nand the linear sampling method, are well understood for full-aperture data, yet\ntheir performance deteriorates severely under limited-aperture conditions,\nespecially in the presence of noise. We propose a new sampling method tailored\nto the inverse medium problem with limited-aperture data. The method is\nmotivated by the linear sampling framework and incorporates a weight function\ninto the index function. The weight is designed so that the modified kernel\nreproduces the full-aperture behavior using only limited data, which both\nlocalizes oscillations and improves the conditioning of the far-field system,\nthereby yielding more accurate and stable reconstructions. We provide a\ntheoretical justification of the method under the Born approximation and an\nefficient algorithm for computing the weight. Numerical experiments in two and\nthree dimensions demonstrate that the proposed method achieves greater accuracy\nand robustness than existing sampling-type methods, particularly for noisy,\nlimited-aperture data.", "AI": {"tldr": "A new sampling method for inverse medium scattering problems with limited-aperture data that improves reconstruction accuracy and stability compared to classical methods like MUSIC and linear sampling.", "motivation": "Measurement data in practical applications are often restricted to limited apertures due to physical or experimental constraints, causing classical sampling methods to perform poorly, especially with noise.", "method": "Proposes a weighted sampling method based on linear sampling framework that incorporates a weight function into the index function. The weight is designed to reproduce full-aperture behavior using limited data, localizing oscillations and improving system conditioning.", "result": "Numerical experiments in 2D and 3D demonstrate the method achieves greater accuracy and robustness than existing sampling-type methods, particularly for noisy limited-aperture data.", "conclusion": "The proposed weighted sampling method effectively addresses limitations of classical approaches for inverse medium scattering with limited-aperture measurements, providing more accurate and stable reconstructions."}}
{"id": "2509.14538", "pdf": "https://arxiv.org/pdf/2509.14538", "abs": "https://arxiv.org/abs/2509.14538", "authors": ["Honggang Liu"], "title": "Existence, asymptotic behaviors, and high-dimensional uniqueness of topological solutions to the skew-symmetric Chern-Simons system on lattice graphs", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we consider the topological solutions to the skew-symmetric\nChern-Simons system on lattice graphs: $$\\left\\{\\begin{aligned} \\Delta u\n&=\\lambda\\mathrm{e}^{\\upsilon}(\\mathrm{e}^{u}-1)+4\\pi\\sum\\limits_{j=1}^{k_1}m_j\\delta_{p_j},\n\\Delta\n\\upsilon&=\\lambda\\mathrm{e}^{u}(\\mathrm{e}^{\\upsilon}-1)+4\\pi\\sum\\limits_{j=1}^{k_2}n_j\\delta_{q_j},\n\\end{aligned} \\right. $$ here, $\\lambda\\in\\mathbb{R}_+$, $k_1$ and $k_2$ are\ntwo positive integers, $m_j\\in\\mathbb{N}\\, (j=1,2,\\cdot\\cdot\\cdot,k_1)$,\n$n_j\\in\\mathbb{N}\\,(j=1,2,\\cdot\\cdot\\cdot,k_2)$, and $\\delta_{p}$ denotes the\nDirac mass at vertex $p$. Write $$g=4\\pi\\sum_{j=1}^{k_1}m_j\\delta_{p_j},\\\nh=4\\pi\\sum_{j=1}^{k_2}n_j\\delta_{q_j},\\ B = 4\\pi\\sum_{j=1}^{k_1}m_j +\n4\\pi\\sum_{j=1}^{k_2}n_j.$$ For any fixed $g,h$, we prove the existence of the\ntopological solutions to the systems, then obtain the asymptotic behaviors of\ntopological solutions as $\\lambda \\rightarrow 0_+$ and $\\lambda \\rightarrow\n+\\infty$, and finally prove the uniqueness of the topological solutions when\nthe dimension of lattice graph $\\mathbb{Z}^n$ is large enough or $\\lambda$ is\nlarge enough.", "AI": {"tldr": "Existence and uniqueness of topological solutions to skew-symmetric Chern-Simons system on lattice graphs with asymptotic behavior analysis as \u03bb approaches 0 and infinity.", "motivation": "To study topological solutions of the coupled Chern-Simons system on discrete lattice graphs, which has applications in theoretical physics and mathematical physics, particularly in gauge field theories.", "method": "Mathematical analysis of the nonlinear system using techniques from partial differential equations and discrete analysis on lattice graphs. The approach involves proving existence, analyzing asymptotic behaviors as \u03bb\u21920+ and \u03bb\u2192\u221e, and establishing uniqueness conditions.", "result": "Proved existence of topological solutions for any fixed g and h, obtained complete asymptotic behaviors of solutions in both \u03bb\u21920+ and \u03bb\u2192\u221e limits, and established uniqueness when the lattice dimension is large enough or \u03bb is sufficiently large.", "conclusion": "The paper provides a comprehensive analysis of topological solutions to the skew-symmetric Chern-Simons system on lattice graphs, establishing existence, asymptotic properties, and uniqueness under certain conditions, contributing to the understanding of such systems in discrete settings."}}
{"id": "2509.14690", "pdf": "https://arxiv.org/pdf/2509.14690", "abs": "https://arxiv.org/abs/2509.14690", "authors": ["Aleksander O. Makarenko", "Maxim A. Yurkin", "Alexey A. Shcherbakov", "Mikhail Lapine"], "title": "Electromagnetics of deeply subwavelength metamaterial particles", "categories": ["physics.app-ph", "physics.class-ph", "physics.comp-ph"], "comment": null, "summary": "This article discusses electromagnetic properties of volumetric metamaterial\nsamples with essentially discrete structure, that is, assembled as a periodic\narray of electromagnetic resonators. We develop an efficient numerical\nprocedure for calculating quasi-static electromagnetic response precisely to\nanalyse samples containing several million meta-atoms. We demonstrate that,\ncontrary to a common belief, even million-``atoms'' samples with sharp edges\nare still quite different from uniform (``homogenised'') materials, and their\nproperties are critically sensitive to their shape and boundary structure. We\nalso compare our results with calculations based on the discrete dipole\napproximation as well as with an integral model for continuous particles, and\nanalyse distinctions and similarities between the different approaches. In\nparticular, discrete metamaterials present themselves as a stringent platform\nfor assessing continuous models developed for finite objects with sharp edges.\nOverall, the reported results should be important for understanding mesoscopic\nsystems with strongly interacting elements.", "AI": {"tldr": "Numerical analysis shows million-atom metamaterial samples with sharp edges differ significantly from homogenized materials and are critically sensitive to shape and boundary structure, providing a platform for testing continuous models.", "motivation": "To understand electromagnetic properties of discrete metamaterials and challenge the common belief that large samples behave like uniform homogenized materials.", "method": "Developed an efficient numerical procedure for calculating quasi-static electromagnetic response in samples containing several million meta-atoms, comparing results with discrete dipole approximation and continuous particle integral models.", "result": "Even million-atom samples with sharp edges remain distinct from uniform materials and show critical sensitivity to shape and boundary structure. Discrete metamaterials serve as a stringent test for continuous models.", "conclusion": "The findings are important for understanding mesoscopic systems with strongly interacting elements and demonstrate that discrete structure effects persist even in large metamaterial samples."}}
{"id": "2509.14602", "pdf": "https://arxiv.org/pdf/2509.14602", "abs": "https://arxiv.org/abs/2509.14602", "authors": ["Krishna Yamanappa Poojara", "Sabhrant Sachan", "Ambuj Pandey"], "title": "Decay of Chebyshev coefficients and error estimates of associated quadrature on shrinking intervals", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We analyze decay of Chebyshev coefficients and local Chebyshev approximations\nfor functions of finite regularity on finite intervals, focusing on the\nframework where the interval length tends to zero while the number of\napproximation nodes remains fixed. For all four families of Chebyshev\npolynomials, we derive error estimates that quantify the dependence on the\ninterval length for (i) the decay of Chebyshev coefficients, (ii) the\napproximation error between continuous and discrete Chebyshev coefficients, and\n(iii) the convergence of Chebyshev-based quadrature rules. These results fill a\ngap in the existing theory and provide a unified and rigorous description of\nhow approximation accuracy scales on shrinking intervals, offering new\ntheoretical insight and practical guidance for high-order numerical methods on\ndecomposed domains. Numerical experiments corroborate the theoretical results,\nconfirming the decay rates and illustrating the error behavior in practice.", "AI": {"tldr": "Analysis of Chebyshev coefficient decay and local approximations for functions on shrinking intervals with fixed node count, deriving error estimates for coefficient decay, approximation errors, and quadrature convergence.", "motivation": "To fill a gap in existing theory by providing a unified rigorous framework for understanding how Chebyshev approximation accuracy scales on shrinking intervals, which is crucial for high-order numerical methods on decomposed domains.", "method": "Analyzed decay of Chebyshev coefficients and local approximations for functions of finite regularity, focusing on the asymptotic framework where interval length tends to zero while number of approximation nodes remains fixed. Derived error estimates for all four families of Chebyshev polynomials.", "result": "Derived comprehensive error estimates quantifying dependence on interval length for: (i) Chebyshev coefficient decay, (ii) approximation error between continuous/discrete coefficients, and (iii) convergence of Chebyshev-based quadrature rules. Numerical experiments confirmed theoretical decay rates and error behavior.", "conclusion": "The results provide rigorous theoretical foundation and practical guidance for high-order numerical methods on decomposed domains, offering new insights into Chebyshev approximation scaling behavior on shrinking intervals."}}
{"id": "2509.14541", "pdf": "https://arxiv.org/pdf/2509.14541", "abs": "https://arxiv.org/abs/2509.14541", "authors": ["Renato Iturriaga", "Cristian Mendico", "Kaizhi Wang", "Yuchen Xu"], "title": "Discretization and Vanishing Discount Problems for First-order Mean Field Games", "categories": ["math.AP", "35Q89, 37J51, 49N80"], "comment": "46 pages", "summary": "This article focuses two issues related to the first-order discounted mean\nfield games system. The first is the time discretization problem. The time\ndiscretization approach enables us to prove the existence of solutions (u,m) of\nthe system, where u is a viscosity solution of the discounted Hamilton-Jacobi\nequation and m is a projected minimizing measure satisfying the continuity\nequation in the sense of distributions. The second is the vanishing discount\nproblems for both the discounted mean field games system and its discretized\nsystem. The methods we use primarily derive from weak KAM theory. Moreover, we\nprovide an example demonstrating the non-uniqueness of solutions to the\ndiscounted mean field games system.", "AI": {"tldr": "Analysis of time discretization and vanishing discount problems for first-order discounted mean field games systems using weak KAM theory, including existence proofs and demonstration of solution non-uniqueness.", "motivation": "To address two key issues in first-order discounted mean field games: time discretization for proving solution existence, and vanishing discount problems for both the original and discretized systems.", "method": "Time discretization approach combined with weak KAM theory to prove existence of solutions (viscosity solution u and projected minimizing measure m), and analysis of vanishing discount limits.", "result": "Proved existence of solutions to the discounted mean field games system and provided an example showing non-uniqueness of solutions.", "conclusion": "The time discretization method is effective for establishing solution existence in discounted mean field games, but solutions may not be unique, as demonstrated by the provided counterexample."}}
{"id": "2509.14702", "pdf": "https://arxiv.org/pdf/2509.14702", "abs": "https://arxiv.org/abs/2509.14702", "authors": ["Yagyank Srivastava", "Amey G. Gokhale", "Ankit Jain"], "title": "Computational uncertainties in lattice thermal conductivity prediction of crystalline solids", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "physics.comp-ph"], "comment": null, "summary": "We report computational uncertainties in Boltzmann Transport Equation\n(BTE)-based lattice thermal conductivity prediction of 50 diverse\nsemiconductors from the use of different BTE solvers (ShengBTE, Phono3Py, and\nin-house code) and interatomic forces. The interatomic forces are obtained\neither using the density functional theory (DFT) as implemented in packages\nQuantum Espresso and VASP employing commonly used exchange correlation\nfunctionals (PBE, LDA, PBEsol, and rSCAN) or using the pre-trained foundational\nmachine learning forcefields trained on two different material datasets.\n  We find that the considered BTE solvers introduce minimal uncertainties and,\nusing the same interatomic force constants, all solvers result in an excellent\nagreement with each other, with a mean absolute percentage error (MAPE) of only\n1%. While this error increases to around 10% with the use of different DFT\npackages, the error is still small and can be reduced further with the use of\nstringent planewave energy cutoffs. On the other hand, the differences in\nthermal conductivity due to the use of different exchange correlation\nfunctionals are large, with a MAPE of more than 20%. The currently available\npre-trained foundational ML models predict the right trend for thermal\nconductivity, but the associated errors are high, limiting their applications\nfor coarse screening of materials.", "AI": {"tldr": "Analysis of computational uncertainties in lattice thermal conductivity predictions using different Boltzmann Transport Equation solvers, DFT packages, exchange-correlation functionals, and machine learning forcefields across 50 semiconductors.", "motivation": "To quantify and compare the uncertainties introduced by different computational methods and tools in predicting lattice thermal conductivity, which is crucial for materials screening and design.", "method": "Used three BTE solvers (ShengBTE, Phono3Py, in-house code) with interatomic forces from DFT packages (Quantum Espresso, VASP) employing various exchange-correlation functionals (PBE, LDA, PBEsol, rSCAN) and pre-trained machine learning forcefields on different material datasets.", "result": "BTE solvers showed minimal uncertainty (1% MAPE), DFT packages caused ~10% error, exchange-correlation functionals introduced large differences (>20% MAPE), and ML models predicted correct trends but with high errors.", "conclusion": "While BTE solvers and DFT packages show good agreement, choice of exchange-correlation functional significantly impacts results, and current ML models need improvement for reliable materials screening applications."}}
{"id": "2509.14736", "pdf": "https://arxiv.org/pdf/2509.14736", "abs": "https://arxiv.org/abs/2509.14736", "authors": ["Tingchun Wang", "Jingye Yan"], "title": "Unconditional and optimal error analysis of two linearized finite difference schemes for the logarithmic Schr\u00f6dinger equation", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we propose two linearized finite difference schemes for\nsolving the logarithmic Schr\\\"odinger equation (LogSE) without the need for\nregularization of the logarithmic term. These two schemes employ the\nfirst-order and the second-order backward difference formula, respectively, for\ntemporal discretization of the LogSE, while using the second-order central\nfinite difference method for spatial discretization. We overcome the\nsingularity posed by the logarithmic nonlinearity $f(u)=u\\ln|u|$ in\nestablishing optimal $l^{2}$-error estimates for the first-order scheme, and an\nalmost optimal $l^{2}$-error estimate for the second-order scheme. Compared to\nthe error estimates of the LogSE in the literature, our error bounds not only\ngreatly improve the convergence rate but also get rid of the time step\nrestriction. Furthermore, without enhancing the regularity of the exact\nsolution or imposing any requirements on the grid ratio, we establish error\nestimates of the two proposed schemes in the discrete $H^{1}$ norm. However,\nthe existing results available in the literature either fail to provide $H^{1}$\nerror estimates or require certain restrictions on the grid ratio. Numerical\nresults are reported to confirm our error estimates and demonstrate rich\ndynamics of the LogSE.", "AI": {"tldr": "Two linearized finite difference schemes for solving logarithmic Schr\u00f6dinger equation without regularization, with improved error estimates and no time step restrictions.", "motivation": "To develop efficient numerical methods for the logarithmic Schr\u00f6dinger equation that overcome the singularity of the logarithmic term and provide better error estimates without restrictive conditions.", "method": "First-order and second-order backward difference formulas for temporal discretization combined with second-order central finite difference for spatial discretization.", "result": "Optimal l\u00b2-error estimates for first-order scheme, almost optimal for second-order scheme, plus H\u00b9 error estimates without grid ratio restrictions or enhanced regularity requirements.", "conclusion": "The proposed schemes significantly improve convergence rates, eliminate time step restrictions, and provide superior error estimates compared to existing methods."}}
{"id": "2509.14648", "pdf": "https://arxiv.org/pdf/2509.14648", "abs": "https://arxiv.org/abs/2509.14648", "authors": ["Qinfeng Li", "Juncheng Wei", "Ruofei Yao"], "title": "Monotonicity properties of the Robin torsion function in a class of symmetric planar domains", "categories": ["math.AP"], "comment": "12 pages, 2 figures", "summary": "We prove the monotonicity property of the Robin torsion function in a smooth\nplanar domain $\\Omega$ with a line of symmetry, provided that the Robin\ncoefficient $\\beta$ is greater than or equal to the negative of the boundary\ncurvature $\\kappa$ (i.e., $\\beta \\geq -\\kappa$ on $\\partial\\Omega$). We also\nshow that this condition is, in a certain sense, sharp by constructing a\ncounterexample.", "AI": {"tldr": "Monotonicity of Robin torsion function in symmetric planar domains when Robin coefficient \u03b2 \u2265 -\u03ba (boundary curvature), with counterexample showing sharpness.", "motivation": "To establish conditions under which the Robin torsion function exhibits monotonicity properties in symmetric planar domains, which has implications for understanding the behavior of solutions to Robin boundary value problems.", "method": "Mathematical proof using symmetry arguments and analysis of the Robin boundary condition, combined with construction of a counterexample to demonstrate the sharpness of the condition.", "result": "Proved that the Robin torsion function is monotonic in smooth symmetric planar domains when \u03b2 \u2265 -\u03ba, and showed this condition is sharp through a counterexample.", "conclusion": "The condition \u03b2 \u2265 -\u03ba is both sufficient and essentially necessary for monotonicity of the Robin torsion function in symmetric planar domains."}}
{"id": "2509.14713", "pdf": "https://arxiv.org/pdf/2509.14713", "abs": "https://arxiv.org/abs/2509.14713", "authors": ["Takehiro Fujii", "Takeshi Omori"], "title": "Immersed Boundary Projection Method for Navier Slip Boundaries", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": "50 pages with double line spacing (14 pages for the appendix and the\n  reference), 22 figures", "summary": "A formulation of the immersed boundary method for incompressible flow over\nbodies with surface slip described by the Navier boundary condition is\npresented. In the present method, the wall slip velocity and the boundary force\nare determined implicitly through a projection to satisfy the boundary\nconditions and the divergence-free condition of the velocity field as\nconstraints. The present method is first-order accurate in space and\nfourth-order accurate in time, overcoming the difficulty of the conventional\ncontinuous forcing approaches to accurately evaluate the velocity gradient on\nthe boundary. Results from the simulation of the flow past stationary and\nmoving circular cylinders are in good agreement with previous experimental and\nnumerical results for a wide range of slip length on the surface, including the\nno-slip case.", "AI": {"tldr": "A new immersed boundary method for simulating incompressible flow over bodies with surface slip, using implicit projection to determine slip velocity and boundary forces while maintaining divergence-free velocity field.", "motivation": "To overcome limitations of conventional continuous forcing approaches in accurately evaluating velocity gradients on boundaries for flows with surface slip described by Navier boundary conditions.", "method": "Implicit projection approach that simultaneously determines wall slip velocity and boundary force to satisfy boundary conditions and divergence-free constraint. The method achieves first-order spatial accuracy and fourth-order temporal accuracy.", "result": "Simulations of flow past stationary and moving circular cylinders show good agreement with previous experimental and numerical results across a wide range of slip lengths, including no-slip cases.", "conclusion": "The presented immersed boundary method successfully handles surface slip conditions while maintaining accuracy, overcoming previous difficulties with velocity gradient evaluation on boundaries."}}
{"id": "2509.14771", "pdf": "https://arxiv.org/pdf/2509.14771", "abs": "https://arxiv.org/abs/2509.14771", "authors": ["Jan Glaubitz", "Tongtong Li", "Jennifer Ryan", "Roman Stuhlmacher"], "title": "The Bayesian SIAC filter", "categories": ["math.NA", "cs.NA", "65D10, 65F22, 62F15, 65K10, 68U10"], "comment": "20 pages", "summary": "We propose the Bayesian smoothness-increasing accuracy-conserving (SIAC)\nfilter -- a hierarchical Bayesian extension of the existing deterministic SIAC\nfilter. The SIAC filter is a powerful numerical tool for removing\nhigh-frequency noise from data or numerical solutions without degrading\naccuracy. However, current SIAC methodology is limited to (i) nodal data\n(direct, typically noisy function values) and (ii) deterministic point\nestimates that do not account for uncertainty propagation from input data to\nthe SIAC reconstruction. The proposed Bayesian SIAC filter overcomes these\nlimitations by (i) supporting general (non-nodal) data models and (ii) enabling\nrigorous uncertainty quantification (UQ), thereby broadening the applicability\nof SIAC filtering. We also develop structure-exploiting algorithms for\nefficient maximum a posteriori (MAP) estimation and Markov chain Monte Carlo\n(MCMC) sampling, with a focus on linear data models with additive Gaussian\nnoise. Computational experiments demonstrate the effectiveness of the Bayesian\nSIAC filter across several applications, including signal denoising, image\ndeblurring, and post-processing of numerical solutions to hyperbolic\nconservation laws. The results show that the Bayesian approach produces point\nestimates with accuracy comparable to, and in some cases exceeding, that of the\ndeterministic SIAC filter. In addition, it extends naturally to general data\nmodels and provides built-in UQ.", "AI": {"tldr": "Bayesian extension of SIAC filter that supports general data models and provides uncertainty quantification, with efficient algorithms for MAP estimation and MCMC sampling.", "motivation": "Current SIAC filter is limited to nodal data and deterministic point estimates without uncertainty quantification, restricting its applicability.", "method": "Hierarchical Bayesian extension of SIAC filter with structure-exploiting algorithms for efficient MAP estimation and MCMC sampling, focusing on linear data models with additive Gaussian noise.", "result": "Produces point estimates with accuracy comparable to or exceeding deterministic SIAC filter, while supporting general data models and providing built-in uncertainty quantification.", "conclusion": "Bayesian SIAC filter overcomes limitations of deterministic version, broadens applicability, and enables rigorous uncertainty quantification across various applications including signal denoising, image deblurring, and numerical solution post-processing."}}
{"id": "2509.14681", "pdf": "https://arxiv.org/pdf/2509.14681", "abs": "https://arxiv.org/abs/2509.14681", "authors": ["Jinyuan Shang", "Wenting Zhao", "Xianjiu Huang"], "title": "Normalized solution for Kirchhoff equation with upper critical exponent and mixed Choquard type nonlinearities", "categories": ["math.AP"], "comment": "21 pages", "summary": "In this paper, we consider the existence of normalized solution to the\nfollowing Kirchhoff equation with mixed Choquard type nonlinearities:\n\\begin{equation*} \\begin{cases} -\\left(a + b \\int_{\\mathbb{R}^3} |\\nabla u|^2\n\\, dx\\right) \\Delta u - \\lambda u = \\mu |u|^{q-2} u + (I_\\alpha * |u|^{\\alpha +\n3}) |u|^{\\alpha +1} u, \\quad x \\in \\mathbb{R}^3, \\\\ \\int_{\\mathbb{R}^3} u^2 \\,\ndx = \\rho^2, \\end{cases} \\end{equation*} where $a,b,\\rho >0$, $\\alpha \\in\n\\left(0, 3\\right)$, $\\frac{14}{3} < q < 6$ and $\\lambda \\in \\mathbb{R}$ will\narise as a Lagrange multiplier. The quantity $\\alpha + 3$ here represents the\nupper critical exponent relevant to the Hardy-Littlewood-Sobolev inequality,\nand this exponent can be regarded as equivalent to the Sobolev critical\nexponent $2^*$. We generalize the results by Wang et al.(Discrete and\nContinuous Dynamical Systems, 2025), which focused on nonlinear Kirchhoff\nequations with combined nonlinearities when $2< q< \\frac{10}{3}$. The primary\nchallenge lies in the necessity for subtle energy estimates under the\n\\(L^2\\)-constraint to achieve compactness recovery. Meanwhile, we need to deal\nwith the difficulties created by the two nonlocal terms appearing in the\nequation.", "AI": {"tldr": "Existence of normalized solutions for Kirchhoff equations with mixed Choquard nonlinearities in R\u00b3, extending previous results to higher exponent ranges.", "motivation": "To study normalized solutions (L\u00b2-constrained) for Kirchhoff equations with combined nonlocal nonlinearities, generalizing previous work by Wang et al. to cover the critical exponent range 14/3 < q < 6.", "method": "Mathematical analysis using energy estimates under L\u00b2-constraint, handling two nonlocal terms (Kirchhoff nonlocality and Choquard nonlocality), and employing techniques related to Hardy-Littlewood-Sobolev inequality.", "result": "Proves existence of normalized solutions for the Kirchhoff-Choquard equation with mixed nonlinearities in the specified parameter ranges.", "conclusion": "The paper successfully extends previous results to higher exponent cases, overcoming challenges from dual nonlocal terms and compactness issues under L\u00b2 constraints."}}
{"id": "2509.14762", "pdf": "https://arxiv.org/pdf/2509.14762", "abs": "https://arxiv.org/abs/2509.14762", "authors": ["Luigi Cigarini", "Urszula Danuta Wdowik", "Dominik Legut"], "title": "Thermoelectric properties of defective scandium nitride nanostructures", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "physics.app-ph", "physics.chem-ph", "physics.comp-ph"], "comment": "12 pages, 13 figures", "summary": "Transition-metal nitrides (TMNs) are currently being studied for potential\napplications in energy conversion. In this work, we used the Landauer approach\nto relate the various effects contributing to the thermoelectric efficiency of\nscandium nitride (ScN) to their microscopic origins. We model the impact of\nelectronic and structural modifications induced by oxygen impurities and\nspatial vacancies on electronic transport in ScN nanostructures. Taking\nadvantage of the results of our calculations, we propose a theoretical\ninterpretation of recent experimental results revealing a strong dependence of\nthe thermoelectric properties of ScN thin films on procedural variations during\nfabrication. The thermoelectric properties of ScN are decisively influenced by\nstructural and electronic factors arising from defects or impurities. Our\nfindings highlight the potential of this theoretical approach in studying\nthermoelectricity and uncovering future strategies to improve thermoelectric\nefficiency.", "AI": {"tldr": "Theoretical study using Landauer approach to analyze how oxygen impurities and vacancies affect thermoelectric properties of scandium nitride nanostructures, explaining experimental results and proposing strategies for efficiency improvement.", "motivation": "To understand the microscopic origins of thermoelectric efficiency in transition-metal nitrides, particularly scandium nitride, and explain experimental observations of fabrication-dependent thermoelectric properties.", "method": "Used Landauer approach to model electronic and structural modifications from oxygen impurities and spatial vacancies in ScN nanostructures, relating these to electronic transport properties.", "result": "Found that thermoelectric properties of ScN are strongly influenced by structural and electronic factors from defects/impurities, providing theoretical interpretation of experimental fabrication-dependent results.", "conclusion": "This theoretical approach shows potential for studying thermoelectricity and uncovering strategies to improve thermoelectric efficiency in materials like ScN."}}
{"id": "2509.14847", "pdf": "https://arxiv.org/pdf/2509.14847", "abs": "https://arxiv.org/abs/2509.14847", "authors": ["Xiao Tang", "Junwei Huang"], "title": "A class of flexible and efficient partitioned Runge-Kutta-Chebyshev methods for some time-dependent partial differential equations", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Many time-dependent partial differential equations (PDEs) can be transformed\ninto an ordinary differential equations (ODEs) containing moderately stiff and\nnon-stiff terms after spatial semi-discretization. In the present paper, we\nconstruct a new class of second-order partitioned explicit stabilized methods\nfor the above ODEs. We treat the moderately stiff term with an s-stage\nRunge-Kutta-Chebyshev (RKC) method and treat the non-stiff term with a 4m-stage\nexplicit Runge-Kutta (RK) method. Different from several existing partitioned\nexplicit stabilized methods that employ fixed-stage RK methods to handle the\nnon-stiff term, both the parameters $s$ and $m$ in our methods can be flexibly\nadjusted as needed for the problems. This feature endows our methods with\nsuperior flexibility and applicability compared to several existing partitioned\nexplicit stabilized methods, as demonstrated in several specific numerical\nexamples (including the advection-diffusion equations, the Burgers equations,\nthe Brusselator equations and the damped wave equations).", "AI": {"tldr": "A new class of second-order partitioned explicit stabilized methods for time-dependent PDEs transformed into ODEs with moderately stiff and non-stiff terms, using flexible s-stage RKC for stiff terms and 4m-stage RK for non-stiff terms.", "motivation": "Many time-dependent PDEs become ODEs with both moderately stiff and non-stiff terms after spatial discretization, requiring efficient numerical methods that can handle both components effectively with flexibility.", "method": "Construct partitioned explicit stabilized methods combining s-stage Runge-Kutta-Chebyshev (RKC) for moderately stiff terms and 4m-stage explicit Runge-Kutta (RK) for non-stiff terms, with both parameters s and m being flexibly adjustable.", "result": "The proposed methods demonstrate superior flexibility and applicability compared to existing partitioned explicit stabilized methods, as validated through numerical examples including advection-diffusion, Burgers, Brusselator, and damped wave equations.", "conclusion": "The new class of second-order partitioned explicit stabilized methods offers enhanced flexibility and broad applicability for solving ODEs derived from time-dependent PDEs with mixed stiff/non-stiff characteristics."}}
{"id": "2509.14767", "pdf": "https://arxiv.org/pdf/2509.14767", "abs": "https://arxiv.org/abs/2509.14767", "authors": ["Tuan Anh Dao", "Anh Tuan Duong"], "title": "Blow up results and lifespan estimates for nonlinear damped wave equations on weighted graphs", "categories": ["math.AP", "05C12, 35B44, 35L15, 35R02"], "comment": "21 pages", "summary": "In this article, we are interested in studying the Cauchy problems for\nnonlinear damped wave equations and their systems on a weighted graph. Our main\npurpose is two-fold, namely, under certain conditions for volume growth of a\nball and the initial data we would like to not only prove nonexistence of\nglobal (in time) weak solutions but also indicate lifespan estimates for local\n(in time) weak solutions when a blow-up phenomenon in finite time occurs.\nThroughout the present paper, we will partially give a positive answer for the\noptimality of our results by an application to the $n$-dimensional integer\nlattice graph $\\Z^n$ to recover the well-known results in the Euclidean\nsetting.", "AI": {"tldr": "Study of Cauchy problems for nonlinear damped wave equations on weighted graphs, focusing on blow-up phenomena and lifespan estimates.", "motivation": "To understand the behavior of nonlinear damped wave equations on weighted graphs, particularly examining conditions under which global solutions fail to exist and determining lifespan estimates for local solutions that blow up in finite time.", "method": "Analysis under specific conditions for volume growth of balls and initial data, with application to n-dimensional integer lattice graphs to validate results against known Euclidean setting outcomes.", "result": "Proof of nonexistence of global weak solutions under certain conditions, along with lifespan estimates for local weak solutions that experience finite-time blow-up.", "conclusion": "The results provide partial confirmation of optimality, particularly through application to Z^n lattice graphs, recovering established results in Euclidean settings and extending them to graph frameworks."}}
{"id": "2509.14991", "pdf": "https://arxiv.org/pdf/2509.14991", "abs": "https://arxiv.org/abs/2509.14991", "authors": ["Zhaobo Zhou", "Sangeeta Sharma", "Junjie He"], "title": "Ultrafast controlling net magnetization in g-wave altermagnets via laser fields", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "The diverse nodal spin structures in d/g/i-wave altermagnets (AM) may cause\ndistinct light-induced spin responses yet remain poorly understood. Using\ntime-dependent density functional theory (TDDFT), we reveal that laser induced\nultrafast demagnetization dynamics in the g-wave AM CrSb are strongly governed\nby the laser incidence direction. Under normal incidence along the [0001] axis,\ntwo Cr sublattices exhibit symmetric temporal demagnetization but with\ndifferent amplitudes, preserving the net-zero magnetization, unlike the\nbehavior in d-wave AM. Off-normal incidence, however, induces pronounced\nasymmetric demagnetization between sublattices, transiently driving the system\ninto a ferrimagnetic-like state with a sizable net magnetization. This\ndirection-dependent response arises from the characteristic nodal structures in\nbulk g-wave AM electronic structure, which enable anisotropic optical intersite\nspin transfer (OISTR). By comparing g-wave and d-wave AMs, we propose that\nlight-induced magnetization arises when laser polarization aligns with\nspin-uncompensated regions in electronic structures. This can be readily\ndetermined from the local spin density of states along specific band paths. Our\nresults provide a fundamental understanding for laser-induced ultrafast\ndynamics in AM.", "AI": {"tldr": "Laser-induced demagnetization in g-wave altermagnet CrSb shows direction-dependent behavior - normal incidence preserves zero net magnetization while off-normal incidence creates transient ferrimagnetic-like state with net magnetization, due to anisotropic optical intersite spin transfer from nodal structures.", "motivation": "To understand how diverse nodal spin structures in d/g/i-wave altermagnets affect light-induced spin responses, particularly the direction-dependent ultrafast demagnetization dynamics that remain poorly understood.", "method": "Used time-dependent density functional theory (TDDFT) to study laser-induced ultrafast demagnetization dynamics in g-wave altermagnet CrSb, comparing different laser incidence directions and polarization alignments.", "result": "Normal incidence along [0001] axis produces symmetric demagnetization with different amplitudes but preserves net-zero magnetization. Off-normal incidence induces asymmetric demagnetization, creating transient ferrimagnetic-like state with sizable net magnetization due to anisotropic OISTR from nodal structures.", "conclusion": "Light-induced magnetization occurs when laser polarization aligns with spin-uncompensated regions in electronic structures, which can be determined from local spin density of states along specific band paths, providing fundamental understanding of ultrafast dynamics in altermagnets."}}
{"id": "2509.14864", "pdf": "https://arxiv.org/pdf/2509.14864", "abs": "https://arxiv.org/abs/2509.14864", "authors": ["Maurice S. Fabien"], "title": "A cell centered Galerkin method for miscible displacement in heterogeneous porous media", "categories": ["math.NA", "cs.CE", "cs.NA"], "comment": "28 pages", "summary": "In this paper we present a cell centered Galerkin (CCG) method applied to\nmiscible displacement problems in heterogeneous porous media. The CCG approach\ncombines concepts from finite volume and discontinuous Galerkin (DG) methods to\narrive at an efficient lowest-order approximation (one unknown per cell). We\ndemonstrate that the CCG method can be defined using classical DG weak\nformulations, only requires one unknown per cell, and is able to deliver\ncomparable accuracy and improved efficiency over traditional higher-order\ninterior penalty DG methods. In addition, we prove that the CCG method for a\nmodel Poisson problem gives rise to a inverse-positive matrix in 1D. A plethora\nof computational experiments in 2D and 3D showcase the effectiveness of the CCG\nmethod for highly heterogeneous flow and transport problems in porous media.\nComparisons between CCG and classical DG methods are included.", "AI": {"tldr": "A cell centered Galerkin method combining finite volume and discontinuous Galerkin approaches for miscible displacement in porous media, offering comparable accuracy to higher-order DG methods with only one unknown per cell.", "motivation": "To develop an efficient computational method for miscible displacement problems in heterogeneous porous media that maintains accuracy while reducing computational complexity compared to traditional higher-order discontinuous Galerkin methods.", "method": "Cell centered Galerkin (CCG) method that combines finite volume and discontinuous Galerkin concepts, using classical DG weak formulations with only one unknown per cell, and proves inverse-positive matrix properties for Poisson problems in 1D.", "result": "The CCG method delivers comparable accuracy and improved efficiency over traditional higher-order interior penalty DG methods, as demonstrated through computational experiments in 2D and 3D for highly heterogeneous flow and transport problems.", "conclusion": "The CCG method provides an effective lowest-order approximation approach for porous media problems that maintains accuracy while offering computational efficiency advantages over conventional DG methods."}}
{"id": "2509.14811", "pdf": "https://arxiv.org/pdf/2509.14811", "abs": "https://arxiv.org/abs/2509.14811", "authors": ["Marco Picerni"], "title": "Existence and summability of solutions to nonlinear X-elliptic equations with measurable coefficients", "categories": ["math.AP", "35H20, 35J60, 35J70, 35B35, 35B45, 35B65, 35R05"], "comment": null, "summary": "We prove an existence result for solutions to a class of nonlinear\ndegenerate-elliptic equations with measurable coefficients and zero Dirichlet\nboundary condition. The main term is given by a nonlinear operator in\ndivergence form associated to a family of vector fields which satisfy a\nPoincar\\'e inequality and the doubling condition.\n  Furthermore, we prove that the solutions satisfy a generalization of the\n$L^p$-regularity results which hold for the solutions to Leray-Lions type\nequations.", "AI": {"tldr": "Existence and regularity results for solutions to nonlinear degenerate-elliptic equations with measurable coefficients and zero Dirichlet boundary conditions", "motivation": "To establish existence and regularity properties for solutions to a class of nonlinear degenerate-elliptic equations that generalize Leray-Lions type equations, particularly when dealing with measurable coefficients and degenerate operators", "method": "Proving existence results using nonlinear operators in divergence form associated with vector fields satisfying Poincar\u00e9 inequality and doubling condition, then establishing L^p-regularity generalizations", "result": "Successfully proved existence of solutions and demonstrated that these solutions satisfy generalized L^p-regularity results similar to those known for Leray-Lions type equations", "conclusion": "The paper provides important existence and regularity theorems for degenerate-elliptic equations with measurable coefficients, extending known results to more general settings with degenerate operators"}}
{"id": "2509.15022", "pdf": "https://arxiv.org/pdf/2509.15022", "abs": "https://arxiv.org/abs/2509.15022", "authors": ["Simon A. Mason", "Megna N. Shah", "Jeffrey P. Simmons", "Dennis M. Dimiduk", "Stephen R. Niezgoda"], "title": "Mapping Microstructure: Manifold Construction for Accelerated Materials Exploration", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Accelerating materials development requires quantitative linkages between\nprocessing, microstructure, and properties. In this work, we introduce a\nframework for mapping microstructure onto a low-dimensional material manifold\nthat is parametrized by processing conditions. A key innovation is treating\nmicrostructure as a stochastic process, defined as a distribution of\nmicrostructural instances rather than a single image, enabling the extraction\nof material state descriptors that capture the essential process-dependent\nfeatures. We leverage the manifold hypothesis to assert that microstructural\noutcomes lie on a low-dimensional latent space controlled by only a few\nparameters. Using phase-field simulations of spinodal decomposition as a model\nmaterial system, we compare multiple microstructure descriptors (two-point\nstatistics, chord-length distributions, and persistent homology) in terms of\ntwo criteria: (1) intrinsic dimensionality of the latent space, and (2)\ninvertibility of the processing-to-structure mapping. The results demonstrate\nthat distribution-based descriptors can recover a two-dimensional latent\nstructure aligned with the true processing parameters, yielding an invertible\nand physically interpretable mapping between processing and microstructure. In\ncontrast, descriptors that do not account for microstructure variability either\noverestimate dimensionality or lose predictive fidelity. The constructed\nmaterial manifold is shown to be locally continuous, wherein small changes in\nprocess variables correspond to smooth changes in microstructure descriptors.\nThis data-driven manifold mapping approach provides a quantitative foundation\nfor microstructure-informed process design and paves the way toward closed-loop\noptimization of processing--structure--property relationships in an integrated\nmaterials engineering context.", "AI": {"tldr": "A framework for mapping microstructure onto a low-dimensional material manifold parametrized by processing conditions, treating microstructure as a stochastic process distribution rather than single images.", "motivation": "Accelerate materials development by creating quantitative linkages between processing, microstructure, and properties through low-dimensional material manifolds.", "method": "Treat microstructure as stochastic process distributions, compare multiple descriptors (two-point statistics, chord-length distributions, persistent homology) using phase-field simulations of spinodal decomposition, evaluate dimensionality and invertibility.", "result": "Distribution-based descriptors recover two-dimensional latent structure aligned with true processing parameters, creating invertible and interpretable mapping. Non-variability-aware descriptors overestimate dimensionality or lose fidelity.", "conclusion": "The material manifold approach provides quantitative foundation for microstructure-informed process design and enables closed-loop optimization of processing-structure-property relationships."}}
{"id": "2509.14896", "pdf": "https://arxiv.org/pdf/2509.14896", "abs": "https://arxiv.org/abs/2509.14896", "authors": ["Matteo Croci", "Abdul-Lateef Haji-Ali", "Ian C. J. Powell"], "title": "An Adaptive Sampling Algorithm for Level-set Approximation", "categories": ["math.NA", "cs.NA", "65Y20, 65D15, 65C05"], "comment": null, "summary": "We propose a new numerical scheme for approximating level-sets of Lipschitz\nmultivariate functions which is robust to stochastic noise. The algorithm's\nmain feature is an adaptive grid-based stochastic approximation strategy which\nautomatically refines the approximation over regions close to the level set.\nThis strategy combines a local function approximation method with a noise\nreduction scheme and produces $\\varepsilon$-accurate approximations with an\nexpected cost complexity reduction of $\\varepsilon^{-\\left(\\frac{p+1}{\\alpha\np}\\right)}$ compared to a non-adaptive scheme, where $\\alpha$ is the\nconvergence rate of the function approximation method and we assume that the\nnoise can be controlled in $L^p$. We provide numerical experiments in support\nof our theoretical findings. These include 2- and 3-dimensional functions with\na complex level set structure, as well as a failure region estimation problem\ndescribed by a hyperelasticity partial differential equation with random field\ncoefficients.", "AI": {"tldr": "Adaptive grid-based stochastic approximation scheme for approximating level-sets of Lipschitz multivariate functions with noise robustness and improved computational efficiency.", "motivation": "To develop a robust numerical method for approximating level-sets of Lipschitz multivariate functions that can handle stochastic noise while maintaining computational efficiency through adaptive refinement.", "method": "Combines local function approximation with noise reduction in an adaptive grid-based stochastic approximation strategy that automatically refines regions near the level set.", "result": "Achieves \u03b5-accurate approximations with expected cost complexity reduction of \u03b5^{-\u2212(\u03b1p + 1)/(\u03b1p)} compared to non-adaptive schemes, where \u03b1 is the convergence rate and p relates to noise control in L^p space.", "conclusion": "The proposed adaptive scheme significantly reduces computational cost while maintaining accuracy for level-set approximation in noisy environments, validated through 2D/3D experiments and PDE-based failure region estimation problems."}}
{"id": "2509.14845", "pdf": "https://arxiv.org/pdf/2509.14845", "abs": "https://arxiv.org/abs/2509.14845", "authors": ["Ke Chen", "Quoc-Hung Nguyen", "Tong Yang"], "title": "Well-posedness of the Boltzmann and Landau Equations in Critical Spaces", "categories": ["math.AP"], "comment": "All comments are welcome", "summary": "This paper investigates the well-posedness of the inhomogeneous Boltzmann and\nLandau equations in critical function spaces, a fundamental open problem in\nkinetic theory. We develop a new analytical framework to establish local\nwell-posedness near a global Maxwellian for both equations, under the\nassumption that the initial perturbation is small in a critical norm. A major\ncontribution lies in the introduction of a novel anisotropic norm adapted to\nthe intrinsic scaling invariance of the equations, which provides precise\ncontrol over the high-frequency behavior of solutions. By leveraging the\nregularizing effect and a decomposition of the linearized collision operator,\nwe further extend the local solution globally in time and establish pointwise\ndecay estimates. Our work not only resolves a fundamental issue in the theory\nof kinetic equations in critical spaces, but also provides a new approach\napplicable to a broader class of kinetic models.", "AI": {"tldr": "Establishes local and global well-posedness for inhomogeneous Boltzmann and Landau equations in critical function spaces using a novel anisotropic norm framework", "motivation": "To solve the fundamental open problem of well-posedness for kinetic equations in critical spaces, which is essential for understanding the mathematical foundations of kinetic theory", "method": "Develops a new analytical framework with anisotropic norms adapted to scaling invariance, leverages regularizing effects and decomposition of linearized collision operator", "result": "Proves local well-posedness near global Maxwellian for small initial perturbations, extends to global solutions with pointwise decay estimates", "conclusion": "Resolves a fundamental issue in kinetic theory and provides a new approach applicable to broader classes of kinetic models"}}
{"id": "2509.15029", "pdf": "https://arxiv.org/pdf/2509.15029", "abs": "https://arxiv.org/abs/2509.15029", "authors": ["Hamidreza Razavi", "Nele Moelans"], "title": "Physics-Informed GCN-LSTM Framework for Long-Term Forecasting of 2D and 3D Microstructure Evolution", "categories": ["cond-mat.mtrl-sci", "cs.CE", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "This paper presents a physics-informed framework that integrates graph\nconvolutional networks (GCN) with long short-term memory (LSTM) architecture to\nforecast microstructure evolution over long time horizons in both 2D and 3D\nwith remarkable performance across varied metrics. The proposed framework is\ncomposition-aware, trained jointly on datasets with different compositions, and\noperates in latent graph space, which enables the model to capture compositions\nand morphological dynamics while remaining computationally efficient.\nCompressing and encoding phase-field simulation data with convolutional\nautoencoders and operating in Latent graph space facilitates efficient modeling\nof microstructural evolution across composition, dimensions, and long-term\nhorizons. The framework captures the spatial and temporal patterns of evolving\nmicrostructures while enabling long-range forecasting at reduced computational\ncost after training.", "AI": {"tldr": "Physics-informed GCN-LSTM framework for efficient long-term microstructure evolution forecasting in 2D/3D with composition awareness and latent space modeling.", "motivation": "To develop an efficient computational framework for predicting microstructure evolution over long time horizons while capturing composition effects and morphological dynamics, addressing the computational cost challenges of traditional phase-field simulations.", "method": "Integrates graph convolutional networks (GCN) with LSTM architecture, uses convolutional autoencoders to compress phase-field simulation data, operates in latent graph space, and is trained jointly on datasets with different compositions.", "result": "Achieves remarkable performance across varied metrics, enables long-range forecasting at reduced computational cost after training, and captures spatial and temporal patterns of evolving microstructures efficiently.", "conclusion": "The proposed framework successfully enables computationally efficient forecasting of microstructure evolution across different compositions, dimensions, and long time horizons while maintaining physics-informed accuracy."}}
{"id": "2509.14908", "pdf": "https://arxiv.org/pdf/2509.14908", "abs": "https://arxiv.org/abs/2509.14908", "authors": ["Cl\u00e9ment Canc\u00e8s", "Claire Chainais-Hillairet", "Am\u00e9lie Dupouy"], "title": "Finite Volumes for a dissipative free boundary problem", "categories": ["math.NA", "cs.NA", "35R35, 65M08, 65M12"], "comment": null, "summary": "We study a toy model for the evolution of the oxygen concentration in an\noxide layer. It consists in a transient convection diffusion equation in a\none-dimensional domain of variable width. The motions of the boundaries are\ngoverned by the traces of the concentration. We exhibit a necessary and\nsufficient condition on the parameters involved in the model for the existence\nof a unique traveling-wave solution. Moreover, we show that the model admits\nsome universal entropy structure, in the sense that any convex function of the\nconcentration\n  yields a dissipated free energy (up to exchanges with the outer environment\nat the boundaries). We propose then an implicit in time arbitrary\nLagrangian-Eulerian finite volume scheme based on Scharfetter-Gummel fluxes. It\nis shown to be unconditionally convergent, to preserve exactly the travelling\nwave, and to dissipate all the aforementioned free energies. Numerical\nexperiments show that our scheme is first order accurate in time and second\norder in space, and that the transient solution converges in the long-time\nlimit towards the traveling-wave solution.", "AI": {"tldr": "Study of oxygen concentration evolution in oxide layer using convection-diffusion model with moving boundaries, showing existence of traveling-wave solutions and universal entropy structure, with development of unconditionally convergent numerical scheme.", "motivation": "To understand the evolution of oxygen concentration in oxide layers through mathematical modeling and develop accurate numerical methods that preserve physical properties like traveling waves and energy dissipation.", "method": "Transient convection-diffusion equation in 1D variable-width domain with boundary motions governed by concentration traces. Analysis of traveling-wave solutions and entropy structure. Development of implicit ALE finite volume scheme with Scharfetter-Gummel fluxes.", "result": "Established necessary/sufficient condition for unique traveling-wave solution existence. Demonstrated universal entropy structure with convex functions dissipating free energy. Numerical scheme preserves traveling waves exactly and dissipates all free energies unconditionally.", "conclusion": "The model successfully captures oxide layer evolution physics, with the proposed numerical scheme providing accurate, structure-preserving simulations that converge to traveling-wave solutions and maintain energy dissipation properties."}}
{"id": "2509.14861", "pdf": "https://arxiv.org/pdf/2509.14861", "abs": "https://arxiv.org/abs/2509.14861", "authors": ["Justin Forlano", "Yuzhao Wang"], "title": "Invariant Gibbs dynamics for the nonlinear Schr\u00f6dinger equations on the disc", "categories": ["math.AP", "35Q55, 35R01, 35R60, 37K99"], "comment": "50 pages", "summary": "We consider the two-dimensional defocusing nonlinear Schr\\\"odinger equation\n(NLS) on the unit disc in the plane with the Gibbs initial data under radial\nsymmetry. By using a type of random averaging operator ansatz, we build a\nstrong local-in-time solution theory, and thus prove almost sure global\nwell-posedness and invariance of the Gibbs measure via Bourgain's invariant\nmeasure argument. This work completes the program initiated by Tzvetkov (2006,\n2008) on the construction of invariant Gibbs dynamics (of strong solutions) for\nNLS on the disc.", "AI": {"tldr": "Construction of invariant Gibbs dynamics for 2D defocusing nonlinear Schr\u00f6dinger equation on unit disc with radial symmetry using random averaging operator ansatz", "motivation": "Complete the program initiated by Tzvetkov (2006, 2008) on constructing invariant Gibbs dynamics for NLS on the disc", "method": "Using random averaging operator ansatz to build strong local-in-time solution theory, then applying Bourgain's invariant measure argument", "result": "Proves almost sure global well-posedness and invariance of the Gibbs measure", "conclusion": "Successfully completes the construction of invariant Gibbs dynamics for NLS on the disc with radial symmetry"}}
{"id": "2509.14995", "pdf": "https://arxiv.org/pdf/2509.14995", "abs": "https://arxiv.org/abs/2509.14995", "authors": ["Van Chien Le", "Viviana Giunzioni", "Pierrick Cordel", "Francesco P. Andriulli", "Kristof Cools"], "title": "On the Late-Time Instability of MOT solution to the Time-Domain PMCHWT Equation", "categories": ["math.NA", "cs.NA", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper investigates the late-time instability of marching-on-in-time\nsolution to the time-domain PMCHWT equation. The stability analysis identifies\nthe static solenoidal nullspace of the time-domain electric field integral\noperator as the primary cause of instability. Furthermore, it reveals that the\ninstability mechanisms of the time-domain PMCHWT equation are fundamentally\ndifferent from those of the time-domain electric field integral equation. In\nparticular, the PMCHWT's instability is much more sensitive to numerical\nquadrature errors, and its spectral characteristics are strongly influenced by\nthe topology and smoothness of the scatterer surface.", "AI": {"tldr": "The paper analyzes late-time instability in marching-on-in-time solutions for the time-domain PMCHWT equation, identifying the static solenoidal nullspace of the electric field integral operator as the main cause.", "motivation": "To understand and address the stability issues in time-domain PMCHWT equation solutions, particularly the late-time instability that differs from conventional EFIE instability mechanisms.", "method": "Stability analysis of marching-on-in-time solutions, focusing on the spectral characteristics and numerical quadrature errors in the context of scatterer surface topology and smoothness.", "result": "Identified that PMCHWT instability is fundamentally different from EFIE instability, more sensitive to quadrature errors, and strongly influenced by scatterer surface characteristics.", "conclusion": "The time-domain PMCHWT equation has unique instability mechanisms requiring specialized treatment different from traditional EFIE approaches, with surface topology and numerical precision playing critical roles."}}
{"id": "2509.14870", "pdf": "https://arxiv.org/pdf/2509.14870", "abs": "https://arxiv.org/abs/2509.14870", "authors": ["Argenis J. M\u00e9ndez", "Oscar Ria\u00f1o"], "title": "A monotonicity formula for the fractional Laplacian and instability results for the Shrira equation", "categories": ["math.AP", "35Q53, 37K40, 37K45"], "comment": "35 pages. Comments are welcome", "summary": "By employing a new class of pseudo-differential operators introduced in a\nprevious work, we establish a novel monotonicity formula for the fractional\nLaplacian $|\\nabla_x|^\\alpha$ in $\\mathbb{R}^n$, with $n \\geq 2$ and $\\alpha\n\\in [1,2)$, This framework enables us to localize our analysis to specific\nregions of Euclidean space where monotonicity properties of the $L^2$-mass of\nsolutions to dispersive equations with fractional dispersion are preserved.\n  As an application, we focus on the Shrira equation, proving conditional\ninstability results for its traveling wave solutions in the critical regime. We\ndeduce key virial-type estimates that govern the long-time behavior of the\n$L^2$-mass. As a consequence, we establish instability results without\nrequiring pointwise decay estimates employed in previous works. Our approach\nprovides a robust and flexible method for monotonicity techniques to higher\ndimensions, shedding light on the delicate interplay between nonlocal\ndispersion and spatial localization in nonlinear dispersive models.", "AI": {"tldr": "New monotonicity formula for fractional Laplacian enables localized analysis of L^2-mass preservation in dispersive equations, applied to prove conditional instability of Shrira equation traveling waves without pointwise decay estimates.", "motivation": "To develop a robust framework for analyzing monotonicity properties of solutions to dispersive equations with fractional dispersion, particularly addressing the challenge of extending monotonicity techniques to higher dimensions and understanding nonlocal dispersion effects.", "method": "Employed a new class of pseudo-differential operators to establish a novel monotonicity formula for the fractional Laplacian |\u2207\u2093|\u1d45 in \u211d\u207f (n\u22652, \u03b1\u2208[1,2)), enabling localized analysis of L^2-mass preservation and derivation of virial-type estimates.", "result": "Proved conditional instability results for traveling wave solutions of the Shrira equation in the critical regime, establishing instability without requiring pointwise decay estimates used in previous works.", "conclusion": "The approach provides a flexible method for extending monotonicity techniques to higher dimensions and reveals the delicate interplay between nonlocal dispersion and spatial localization in nonlinear dispersive models."}}
{"id": "2509.15004", "pdf": "https://arxiv.org/pdf/2509.15004", "abs": "https://arxiv.org/abs/2509.15004", "authors": ["Yujia Huang", "Xi'an Li ansd Jinran Wu"], "title": "Fourier heuristic PINNs to solve the biharmonic equations based on its coupled scheme", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "comment": "8", "summary": "Physics-informed neural networks (PINNs) have been widely utilized for\nsolving a range of partial differential equations (PDEs) in various scientific\nand engineering disciplines. This paper presents a Fourier heuristic-enhanced\nPINN (termed FCPINN) designed to address a specific class of biharmonic\nequations with Dirichlet and Navier boundary conditions. The method achieves\nthis by decomposing the high-order equations into two Poisson equations. FCPINN\nintegrates Fourier spectral theory with a reduced-order formulation for\nhigh-order PDEs, significantly improving approximation accuracy and reducing\ncomputational complexity. This approach is especially beneficial for problems\nwith intricate boundary constraints and high-dimensional inputs. To assess the\neffectiveness and robustness of the FCPINN algorithm, we conducted several\nnumerical experiments on both linear and nonlinear biharmonic problems across\ndifferent Euclidean spaces. The results show that FCPINN provides an optimal\ntrade-off between speed and accuracy for high-order PDEs, surpassing the\nperformance of conventional PINN and deep mixed residual method (MIM)\napproaches, while also maintaining stability and robustness with varying\nnumbers of hidden layer nodes.", "AI": {"tldr": "FCPINN is a Fourier-enhanced physics-informed neural network that solves biharmonic equations by decomposing them into Poisson equations, achieving better speed-accuracy trade-off than traditional methods.", "motivation": "To address the challenges of solving high-order PDEs with complex boundary conditions using PINNs, particularly for biharmonic equations with Dirichlet and Navier boundary conditions.", "method": "Decomposes high-order biharmonic equations into two Poisson equations, integrates Fourier spectral theory with reduced-order formulation, and uses neural networks to approximate solutions while reducing computational complexity.", "result": "FCPINN demonstrates superior performance over conventional PINN and deep mixed residual methods, providing optimal speed-accuracy trade-off and maintaining stability across varying network architectures.", "conclusion": "The Fourier heuristic-enhanced approach significantly improves PINN performance for high-order PDEs, making it particularly effective for problems with intricate boundary constraints and high-dimensional inputs."}}
{"id": "2509.14913", "pdf": "https://arxiv.org/pdf/2509.14913", "abs": "https://arxiv.org/abs/2509.14913", "authors": ["Mitsuo Higaki", "Jiajiang Liao", "Franck Sueur"], "title": "Lagrangian controllability in perforated domains", "categories": ["math.AP"], "comment": "25 pages", "summary": "The question at stake in Lagrangian controllability is whether one can move a\npatch of fluid particles to a target location by means of remote action in a\ngiven time interval. In the last two decades, positive results have been\nobtained both for the incompressible Euler and Navier-Stokes equations.\nHowever, for the latter, the case where the fluid is contained within domains\nbounded by solid boundaries with the no-slip condition has not been addressed,\nwith respect to the difficulty caused by viscous boundary layers. In this\npaper, we investigate the Lagrangian controllability of viscous incompressible\nfluid in perforated domains for which the fraction of volume occupied by the\nholes is sufficiently small. Moreover, we quantitatively distinguish situations\ndepending on the parameters for holes (diameter and distance) and for fluid\n(size of the initial data). Our approach relies on recent results on\nhomogenization for evolutionary problems and on weak-strong stability estimates\nin measure of flows, alongside classical results on Runge-type approximations\nfor elliptic equations and on Cauchy-Kowalevsky-type theorems for equations\nwith analytic coefficients. Here, homogenization refers to the vanishing\nviscosity limit outside a porous medium, where (after scaling in time) the\nNavier-Stokes equations are homogenized to the Euler or Darcy equations.", "AI": {"tldr": "Study of Lagrangian controllability for viscous incompressible fluids in perforated domains with small holes, addressing boundary layer challenges through homogenization and stability estimates.", "motivation": "Previous research on Lagrangian controllability for Euler and Navier-Stokes equations hasn't addressed the case with solid boundaries and no-slip conditions due to viscous boundary layer difficulties.", "method": "Uses homogenization for evolutionary problems, weak-strong stability estimates, Runge-type approximations for elliptic equations, and Cauchy-Kowalevsky theorems for analytic coefficients.", "result": "Develops quantitative framework distinguishing situations based on hole parameters (diameter, distance) and fluid parameters (initial data size).", "conclusion": "Provides approach to Lagrangian controllability in perforated domains by connecting Navier-Stokes homogenization to Euler/Darcy equations through vanishing viscosity limit."}}
{"id": "2509.14245", "pdf": "https://arxiv.org/pdf/2509.14245", "abs": "https://arxiv.org/abs/2509.14245", "authors": ["Zhiliang Deng", "Chen Li", "Xiaomei Yang"], "title": "A Bayesian thinning algorithm for the point source identification of heat equation", "categories": ["stat.CO", "cs.NA", "math.NA", "35R30, 62F15, 86A22"], "comment": "6 pages", "summary": "In this work, we propose a Bayesian thinning algorithm for recovering\nweighted point source functions in the heat equation from boundary flux\nobservations. The major challenge in the classical Bayesian framework lies in\nconstructing suitable priors for such highly structured unknowns. To address\nthis, we introduce a level set representation on a discretized mesh for the\nunknown, which enables the infinite-dimensional Bayesian framework to the\nreconstruction. From another perspective, the point source configuration can be\nmodeled as a marked Poisson point process (PPP), then a thinning mechanism is\nemployed to selectively retain points. These two proposals are complementary\nwith the Bayesian level set sampling generating candidate point sources and the\nthinning process acting as a filter to refine them. This combined framework is\nvalidated through numerical experiments, which demonstrate its accuracy in\nreconstructing point sources.", "AI": {"tldr": "Bayesian thinning algorithm for recovering weighted point sources in heat equations from boundary flux data using level set representation and Poisson point process thinning", "motivation": "Addressing the challenge of constructing suitable priors for highly structured unknowns in classical Bayesian framework for point source recovery", "method": "Combines level set representation on discretized mesh with marked Poisson point process modeling and thinning mechanism to generate and refine candidate point sources", "result": "Numerical experiments demonstrate accurate reconstruction of point sources", "conclusion": "The combined Bayesian level set sampling and thinning framework effectively recovers weighted point source functions from boundary flux observations"}}
{"id": "2509.15171", "pdf": "https://arxiv.org/pdf/2509.15171", "abs": "https://arxiv.org/abs/2509.15171", "authors": ["Govanni Granados", "Jeremy L. Marzuola", "Casey Rodriguez"], "title": "Recovering elastic subdomains with strain-gradient elastic interfaces from force measurements: the antiplane shear setting", "categories": ["math.AP", "cond-mat.mtrl-sci", "math-ph", "math.MP", "74G75, 74B05, 35R30"], "comment": "36 pages, 5 figures, comments welcome!", "summary": "We introduce and study a new inverse problem for antiplane shear in elastic\nbodies with strain-gradient interfaces. The setting is a homogeneous isotropic\nelastic body containing an inclusion separated by a thin interface endowed with\nhigher-order surface energy. Using displacement-stress measurements on the\nexterior boundary, expressed through a certain Dirichlet-to-Neumann map, we\nshow uniqueness in recovering both the shear and interface parameters, as well\nas the shape of the inclusion. To address the inverse shape problem, we adapt\nthe factorization method to account for the complications introduced by the\nhigher-order boundary operator and its nontrivial null space. Numerical\nexperiments illustrate the feasibility of the approach, indicating that the\nframework potentially provides a practical tool for nondestructive detection of\ninterior inhomogeneities, including damaged subvolumes.", "AI": {"tldr": "Inverse problem for antiplane shear in elastic bodies with strain-gradient interfaces using boundary measurements to recover inclusion shape and material parameters.", "motivation": "Develop a practical tool for nondestructive detection of interior inhomogeneities and damaged subvolumes in elastic materials with complex interfaces.", "method": "Adapt the factorization method to handle higher-order boundary operators and their nontrivial null spaces, using displacement-stress measurements on exterior boundary through Dirichlet-to-Neumann map.", "result": "Shows uniqueness in recovering shear parameters, interface parameters, and inclusion shape. Numerical experiments demonstrate feasibility of the approach.", "conclusion": "The framework provides a viable method for detecting interior inhomogeneities in elastic bodies with strain-gradient interfaces, potentially useful for nondestructive evaluation applications."}}
{"id": "2509.14384", "pdf": "https://arxiv.org/pdf/2509.14384", "abs": "https://arxiv.org/abs/2509.14384", "authors": ["Nishantak Panigrahi", "Mayank Patwal"], "title": "A Neural Network for the Identical Kuramoto Equation: Architectural Considerations and Performance Evaluation", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": "6 pages, 10 figures. Presented at IEEE International Conference on\n  Compute, Control, Network & Photonics (ICCCNP), 2025", "summary": "In this paper, we investigate the efficiency of Deep Neural Networks (DNNs)\nto approximate the solution of a nonlocal conservation law derived from the\nidentical-oscillator Kuramoto model, focusing on the evaluation of an\narchitectural choice and its impact on solution accuracy based on the energy\nnorm and computation time. Through systematic experimentation, we demonstrate\nthat network configuration parameters-specifically, activation function\nselection (tanh vs. sin vs. ReLU), network depth (4-8 hidden layers), width\n(64-256 neurons), and training methodology (collocation points, epoch\ncount)-significantly influence convergence characteristics. We observe that\ntanh activation yields stable convergence across configurations, whereas sine\nactivation can attain marginally lower errors and training times in isolated\ncases, but occasionally produce nonphysical artefacts. Our comparative analysis\nwith traditional numerical methods shows that optimally configured DNNs offer\ncompetitive accuracy with notably different computational trade-offs.\nFurthermore, we identify fundamental limitations of standard feed-forward\narchitectures when handling singular or piecewise-constant solutions, providing\nempirical evidence that such networks inherently oversmooth sharp features due\nto the natural function space limitations of standard activation functions.\nThis work contributes to the growing body of research on neural network-based\nscientific computing by providing practitioners with empirical guidelines for\nDNN implementation while illuminating fundamental theoretical constraints that\nmust be overcome to expand their applicability to more challenging physical\nsystems with discontinuities.", "AI": {"tldr": "DNNs for approximating nonlocal conservation law solutions from Kuramoto model, showing tanh activation provides stable convergence while sine can achieve lower errors but may produce artifacts. Identifies limitations in handling sharp features due to activation function constraints.", "motivation": "To investigate the efficiency of Deep Neural Networks for solving nonlocal conservation laws derived from the Kuramoto model, and evaluate how architectural choices impact solution accuracy and computational performance compared to traditional methods.", "method": "Systematic experimentation with different network configurations: activation functions (tanh, sin, ReLU), network depth (4-8 hidden layers), width (64-256 neurons), and training methodology (collocation points, epoch count). Comparative analysis with traditional numerical methods.", "result": "Tanh activation yields stable convergence across configurations, while sine activation can achieve marginally lower errors and training times in some cases but may produce nonphysical artifacts. Optimally configured DNNs offer competitive accuracy with different computational trade-offs compared to traditional methods.", "conclusion": "The work provides empirical guidelines for DNN implementation in scientific computing while revealing fundamental limitations of standard feed-forward architectures in handling singular or piecewise-constant solutions due to activation function constraints that cause oversmoothing of sharp features."}}
{"id": "2509.14703", "pdf": "https://arxiv.org/pdf/2509.14703", "abs": "https://arxiv.org/abs/2509.14703", "authors": ["Alberto Maione"], "title": "Fractional Sobolev spaces via interpolation, and applications to mixed local-nonlocal operators", "categories": ["math.FA", "math.AP"], "comment": null, "summary": "In this note, we present a well-known connection between the\nSobolev-Slobodeckij spaces, also known as Fractional Sobolev spaces, and\ninterpolation theory. We show how Sobolev spaces can be equivalently\ncharacterized as real and complex interpolation spaces between Lebesgue spaces\nand integer-order Sobolev spaces. We also state a spectral theorem for the\nso-called mixed local-nonlocal operators, and show how interpolation theory\nleads to its proof. This note is intended for early-career researchers, and\naims to provide a concise and accessible introduction to the subject.", "AI": {"tldr": "Connection between Sobolev-Slobodeckij spaces and interpolation theory, showing equivalence with real/complex interpolation spaces between Lebesgue and integer-order Sobolev spaces, with application to mixed local-nonlocal operators.", "motivation": "To provide a concise and accessible introduction to the connection between fractional Sobolev spaces and interpolation theory for early-career researchers.", "method": "Presenting well-known connections showing how Sobolev spaces can be equivalently characterized as real and complex interpolation spaces between Lebesgue spaces and integer-order Sobolev spaces.", "result": "Establishes the equivalence characterization and provides a spectral theorem for mixed local-nonlocal operators using interpolation theory.", "conclusion": "Interpolation theory provides a powerful framework for understanding and characterizing fractional Sobolev spaces, with applications to spectral analysis of mixed operators."}}
{"id": "2509.14698", "pdf": "https://arxiv.org/pdf/2509.14698", "abs": "https://arxiv.org/abs/2509.14698", "authors": ["Andreas Mueller"], "title": "Wohlhart's Three-Loop Mechanism: An Overconstrained and Shaky Linkage", "categories": ["cs.RO", "cs.NA", "math.DG", "math.GR", "math.NA"], "comment": null, "summary": "This paper revisits a three-loop spatial linkage that was proposed in an ARK\n2004 paper by Karl Wohlhart (as extension of a two-loop linkage proposed by\nEddie Baker in 1980) and later analyzed in an ARK 2006 paper by Diez-Martinez\net. al. A local analysis shows that this linkage has a finite degree of freedom\n(DOF) 3 (and is thus overconstrained) while in its reference configuration the\ndifferential DOF is 5. It is shown that its configuration space is locally a\nsmooth manifold so that the reference configuration is not a c-space\nsingularity. It is shown that the differential DOF is locally constant, which\nmakes this linkage shaky (so that the reference configuration is not a\nsingularity). The higher-order local analysis is facilitated by the computation\nof the kinematic tangent cone as well as a local approximation of the c-space.", "AI": {"tldr": "Reanalysis of a three-loop spatial linkage showing it has finite DOF 3 (overconstrained) but differential DOF 5 in reference configuration, with smooth manifold c-space and constant differential DOF indicating shakiness.", "motivation": "To revisit and provide deeper analysis of a previously studied three-loop spatial linkage to understand its kinematic properties, particularly the discrepancy between finite and differential degrees of freedom.", "method": "Local analysis using kinematic tangent cone computation and local approximation of configuration space to examine the linkage's properties around its reference configuration.", "result": "The linkage has finite DOF 3 (overconstrained) but differential DOF 5 in reference configuration. The configuration space is locally a smooth manifold, making the reference configuration not a singularity. The constant differential DOF indicates the linkage is shaky.", "conclusion": "The three-loop spatial linkage exhibits shakiness with constant differential DOF, and the reference configuration is not a c-space singularity despite the DOF discrepancy, providing new insights into its kinematic behavior."}}
{"id": "2509.14743", "pdf": "https://arxiv.org/pdf/2509.14743", "abs": "https://arxiv.org/abs/2509.14743", "authors": ["Jin Sun", "Kui Wang"], "title": "Sharp Fundamental Gap Estimate on Convex Domains of Gaussian Spaces", "categories": ["math.SP", "math.AP"], "comment": "14 pages, 1 figure, 1 table. All comments are welcome!", "summary": "We prove a sharp lower bound for the fundamental gap of convex domains in\nGaussian space, the difference between the first two eigenvalues of the\nOrnstein-Uhlenbeck operator with Dirichlet boundary conditions. Our main result\nestablishes that the gap is bounded below by the gap of a corresponding\none-dimensional Schr\\\"odinger operator, confirming the Gaussian analogue of the\nfundamental gap conjecture. Furthermore, we demonstrate that the normalized gap\nof the one dimensional model is monotonically increasing with the diameter and\nprove the sharpness of our estimate. This work extends the seminal results of\nAndrews and Clutterbuck for Euclidean domains and Seto, Wang and Wei for\nspherical domains to the fundamentally important setting of Gaussian spaces.", "AI": {"tldr": "Sharp lower bound established for fundamental gap of convex domains in Gaussian space, confirming Gaussian analogue of fundamental gap conjecture", "motivation": "Extend fundamental gap results from Euclidean and spherical domains to Gaussian spaces, which are fundamentally important settings", "method": "Prove sharp lower bound by bounding the gap below by corresponding one-dimensional Schr\u00f6dinger operator gap, show monotonicity of normalized gap with diameter", "result": "Fundamental gap is bounded below by one-dimensional model gap, normalized gap increases monotonically with diameter, estimate is sharp", "conclusion": "Successfully extends previous seminal results to Gaussian space setting, confirming the Gaussian fundamental gap conjecture with sharp bounds"}}
{"id": "2509.14817", "pdf": "https://arxiv.org/pdf/2509.14817", "abs": "https://arxiv.org/abs/2509.14817", "authors": ["Liheng Wang", "Licheng Zhang", "Hailin Xu", "Jingxin Zhao", "Xiuyun Su", "Jiantao Li", "Miutian Tang", "Weilu Gao", "Chong Chen"], "title": "Fracture interactive geodesic active contours for bone segmentation", "categories": ["cs.CV", "cs.NA", "math.NA", "68U10, 94A08"], "comment": "27 pages, 10 figures, 1 table", "summary": "For bone segmentation, the classical geodesic active contour model is usually\nlimited by its indiscriminate feature extraction, and then struggles to handle\nthe phenomena of edge obstruction, edge leakage and bone fracture. Thus, we\npropose a fracture interactive geodesic active contour algorithm tailored for\nbone segmentation, which can better capture bone features and perform robustly\nto the presence of bone fractures and soft tissues. Inspired by orthopedic\nknowledge, we construct a novel edge-detector function that combines the\nintensity and gradient norm, which guides the contour towards bone edges\nwithout being obstructed by other soft tissues and therefore reduces\nmis-segmentation. Furthermore, distance information, where fracture prompts can\nbe embedded, is introduced into the contour evolution as an adaptive step size\nto stabilize the evolution and help the contour stop at bone edges and\nfractures. This embedding provides a way to interact with bone fractures and\nimproves the accuracy in the fracture regions. Experiments in pelvic and ankle\nsegmentation demonstrate the effectiveness on addressing the aforementioned\nproblems and show an accurate, stable and consistent performance, indicating a\nbroader application in other bone anatomies. Our algorithm also provides\ninsights into combining the domain knowledge and deep neural networks.", "AI": {"tldr": "A fracture interactive geodesic active contour algorithm for bone segmentation that addresses edge obstruction, leakage, and fracture handling using orthopedic knowledge-inspired edge detection and adaptive step size with fracture prompts.", "motivation": "Classical geodesic active contour models struggle with indiscriminate feature extraction, edge obstruction, edge leakage, and bone fracture handling in bone segmentation tasks.", "method": "Proposed a novel edge-detector function combining intensity and gradient norm to guide contours toward bone edges without soft tissue obstruction. Introduced distance information with embedded fracture prompts as adaptive step size to stabilize contour evolution and improve fracture region accuracy.", "result": "Experiments on pelvic and ankle segmentation demonstrated effective handling of edge obstruction, leakage, and fracture problems with accurate, stable, and consistent performance.", "conclusion": "The algorithm shows broader application potential in other bone anatomies and provides insights for combining domain knowledge with deep neural networks."}}
{"id": "2509.14844", "pdf": "https://arxiv.org/pdf/2509.14844", "abs": "https://arxiv.org/abs/2509.14844", "authors": ["Francesco C. Mantegazza", "Federica Caforio", "Christoph Augustin", "Matthias A. F. Gsell", "Gundolf Haase", "Elias Karabelas"], "title": "Non-Intrusive Parametrized-Background Data-Weak Reconstruction of Cardiac Displacement Fields from Sparse MRI-like Observations", "categories": ["physics.med-ph", "cs.LG", "cs.NA", "math.NA", "65M60, 74L15, 92C10", "G.1.8; J.3"], "comment": "42 pages, 12 figures, 6 tables", "summary": "Personalized cardiac diagnostics require accurate reconstruction of\nmyocardial displacement fields from sparse clinical imaging data, yet current\nmethods often demand intrusive access to computational models. In this work, we\napply the non-intrusive Parametrized-Background Data-Weak (PBDW) approach to\nthree-dimensional (3D) cardiac displacement field reconstruction from limited\nMagnetic Resonance Image (MRI)-like observations. Our implementation requires\nonly solution snapshots -- no governing equations, assembly routines, or solver\naccess -- enabling immediate deployment across commercial and research codes\nusing different constitutive models. Additionally, we introduce two\nenhancements: an H-size minibatch worst-case Orthogonal Matching Pursuit (wOMP)\nalgorithm that improves Sensor Selection (SS) computational efficiency while\nmaintaining reconstruction accuracy, and memory optimization techniques\nexploiting block matrix structures in vectorial problems. We demonstrate the\neffectiveness of the method through validation on a 3D left ventricular model\nwith simulated scar tissue. Starting with noise-free reconstruction, we\nsystematically incorporate Gaussian noise and spatial sparsity mimicking\nrealistic MRI acquisition protocols. Results show exceptional accuracy in\nnoise-free conditions (relative L2 error of order O(1e-5)), robust performance\nwith 10% noise (relative L2 error of order O(1e-2)), and effective\nreconstruction from sparse measurements (relative L2 error of order O(1e-2)).\nThe online reconstruction achieves four-order-of-magnitude computational\nspeed-up compared to full Finite Element (FE) simulations, with reconstruction\ntimes under one tenth of second for sparse scenarios, demonstrating significant\npotential for integration into clinical cardiac modeling workflows.", "AI": {"tldr": "Non-intrusive PBDW method for 3D cardiac displacement field reconstruction from sparse MRI data with enhanced computational efficiency and memory optimization, achieving high accuracy and significant speed-up.", "motivation": "Personalized cardiac diagnostics require accurate myocardial displacement reconstruction from sparse clinical imaging, but current methods demand intrusive access to computational models.", "method": "Applied non-intrusive Parametrized-Background Data-Weak (PBDW) approach using only solution snapshots, introduced H-size minibatch worst-case Orthogonal Matching Pursuit for efficient sensor selection, and memory optimization techniques for vectorial problems.", "result": "Exceptional accuracy in noise-free conditions (relative L2 error O(1e-5)), robust performance with 10% noise (O(1e-2)), effective reconstruction from sparse measurements (O(1e-2)), and 4-order-of-magnitude computational speed-up compared to full FE simulations.", "conclusion": "The method demonstrates significant potential for clinical integration with fast reconstruction times (under 0.1s) and immediate deployment across commercial/research codes without requiring governing equations or solver access."}}
{"id": "2509.15069", "pdf": "https://arxiv.org/pdf/2509.15069", "abs": "https://arxiv.org/abs/2509.15069", "authors": ["Deijany Rodriguez Linares", "Oksana Moryakova", "H\u00e5kan Johansson"], "title": "Efficient Computation of Time-Index Powered Weighted Sums Using Cascaded Accumulators", "categories": ["eess.SP", "cs.DS", "cs.NA", "math.NA"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This letter presents a novel approach for \\mbox{efficiently} computing\ntime-index powered weighted sums of the form $\\sum_{n=0}^{N-1} n^{K} v[n]$\nusing cascaded accumulators. Traditional direct computation requires\n$K{\\times}N$ general multiplications, which become prohibitive for large $N$,\nwhile alternative strategies based on lookup tables or signal reversal require\nstoring entire data blocks. By exploiting accumulator properties, the proposed\nmethod eliminates the need for such storage and reduces the multiplicative cost\nto only $K{+}1$ constant multiplications, enabling efficient real-time\nimplementation. The approach is particularly useful when such sums need to be\nefficiently computed in sample-by-sample processing systems.", "AI": {"tldr": "A novel method for efficiently computing time-index powered weighted sums using cascaded accumulators, reducing computational cost from K\u00d7N to K+1 multiplications without requiring data storage.", "motivation": "Traditional computation of time-index powered weighted sums requires K\u00d7N multiplications which becomes prohibitive for large N, and alternative methods need to store entire data blocks, making real-time implementation challenging.", "method": "The proposed approach uses cascaded accumulators to exploit accumulator properties, eliminating the need for data storage and reducing the multiplicative operations to only K+1 constant multiplications.", "result": "The method enables efficient computation of sums in the form \u2211_{n=0}^{N-1} n^K v[n] with significantly reduced computational complexity and no storage requirements compared to traditional approaches.", "conclusion": "This cascaded accumulator approach provides an efficient solution for real-time implementation of time-index powered weighted sums in sample-by-sample processing systems, overcoming the limitations of previous methods."}}
