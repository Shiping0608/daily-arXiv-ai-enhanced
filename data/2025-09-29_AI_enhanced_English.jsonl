{"id": "2509.21442", "pdf": "https://arxiv.org/pdf/2509.21442", "abs": "https://arxiv.org/abs/2509.21442", "authors": ["Jan Glaubitz", "Joshua Lampert", "Andrew R. Winters", "Jan Nordstr\u00f6m"], "title": "Towards provable energy-stable overset grid methods using sub-cell summation-by-parts operators", "categories": ["math.NA", "cs.NA", "65N35, 65N12, 65D12, 65D25"], "comment": "24 pages", "summary": "Overset grid methods handle complex geometries by overlapping simpler,\ngeometry-fitted grids to cover the original, more complex domain. However,\nensuring their stability -- particularly at high orders -- remains a practical\nand theoretical challenge. In this work, we address this gap by developing a\ndiscrete counterpart to the recent well-posedness analysis of Kopriva, Gassner,\nand Nordstr\\\"om for continuous overset domain initial-boundary-value problems.\nTo this end, we introduce the novel concept of sub-cell summation-by-parts\n(SBP) operators. These discrete derivative operators mimic integration by parts\nat a sub-cell level. By exploiting this sub-cell SBP property, we develop\nprovably conservative and energy-stable overset grid methods, thereby resolving\nlongstanding stability issues in the field.", "AI": {"tldr": "Developed sub-cell summation-by-parts operators to create provably conservative and energy-stable overset grid methods, resolving longstanding stability issues.", "motivation": "Overset grid methods for complex geometries have practical and theoretical stability challenges, especially at high orders.", "method": "Introduced sub-cell summation-by-parts (SBP) operators that mimic integration by parts at sub-cell level, creating a discrete counterpart to continuous overset domain analysis.", "result": "Developed provably conservative and energy-stable overset grid methods.", "conclusion": "Resolved longstanding stability issues in overset grid methods through novel sub-cell SBP operators."}}
{"id": "2509.21449", "pdf": "https://arxiv.org/pdf/2509.21449", "abs": "https://arxiv.org/abs/2509.21449", "authors": ["Daniele A. Di Pietro", "J\u00e9r\u00f4me Droniou", "Silvano Pitassi"], "title": "Conforming lifting and adjoint consistency for the Discrete de Rham complex of differential forms", "categories": ["math.NA", "cs.NA", "65N30, 65N12"], "comment": null, "summary": "Discrete de Rham (DDR) methods provide non-conforming but compatible\napproximations of the continuous de Rham complex on general polytopal meshes.\nOwing to the non-conformity, several challenges arise in the analysis of these\nmethods. In this work, we design conforming liftings on the DDR spaces, that\nare right-inverse of the interpolators and can be used to solve some of these\nchallenges. We illustrate this by tackling the question of the global\nintegration-by-part formula. By non-conformity of the discrete complex, this\nformula involves a residual -- which can be interpreted as a consistency error\non the adjoint of the discrete exterior derivative -- on which we obtain, using\nthe conforming lifting, an optimal bound in terms of the mesh size. Our\nanalysis is carried out in the polytopal exterior calculus framework, which\nallows for unified proofs for all the spaces and operators in the DDR complex.\nMoreover, the liftings are explicitly constructed in finite element spaces on a\nsimplicial submesh of the underlying polytopal mesh, which gives more control\non the resulting functions (e.g., discrete trace and inverse inequalities).", "AI": {"tldr": "The paper introduces conforming liftings for Discrete de Rham (DDR) methods to address challenges from non-conformity, enabling optimal bounds on consistency errors in integration-by-parts formulas on polytopal meshes.", "motivation": "DDR methods provide compatible approximations on polytopal meshes but face analytical challenges due to non-conformity. The work aims to solve these issues by designing conforming liftings that are right-inverse of interpolators.", "method": "Design conforming liftings on DDR spaces using finite element spaces on a simplicial submesh of the polytopal mesh. Analysis is carried out in the polytopal exterior calculus framework for unified proofs.", "result": "Using conforming liftings, the authors obtain an optimal bound on the residual in the global integration-by-parts formula in terms of mesh size, addressing consistency errors from non-conformity.", "conclusion": "Conforming liftings effectively resolve analytical challenges in DDR methods, providing control over functions and enabling optimal error bounds for integration-by-parts formulas on general polytopal meshes."}}
{"id": "2509.21471", "pdf": "https://arxiv.org/pdf/2509.21471", "abs": "https://arxiv.org/abs/2509.21471", "authors": ["Ludvig af Klinteberg", "Leslie Greengard", "Shidong Jiang", "Anna-Karin Tornberg"], "title": "Fast summation of Stokes potentials using a new kernel-splitting in the DMK framework", "categories": ["math.NA", "cs.NA", "physics.flu-dyn"], "comment": "33 pages, 15 figures", "summary": "Classical Ewald methods for Coulomb and Stokes interactions rely on\n``kernel-splitting,\" using decompositions based on Gaussians to divide the\nresulting potential into a near field and a far field component. Here, we show\nthat a more efficient splitting for the scalar biharmonic Green's function can\nbe derived using zeroth-order prolate spheroidal wave functions (PSWFs), which\nin turn yields new efficient splittings for the Stokeslet, stresslet, and\nelastic kernels, since these Green's tensors can all be derived from the\nbiharmonic kernel. This benefits all fast summation methods based on kernel\nsplitting, including FFT-based Ewald summation methods, that are suitable for\nuniform point distributions, and DMK-based methods that allow for nonuniform\npoint distributions. The DMK (dual-space multilevel kernel-splitting) algorithm\nwe develop here is fast, adaptive, and linear-scaling, both in free space and\nin a periodic cube. We demonstrate its performance with numerical examples in\ntwo and three dimensions.", "AI": {"tldr": "A new efficient kernel splitting method using prolate spheroidal wave functions for biharmonic Green's function, enabling faster Ewald summation and DMK algorithms for Stokes and elastic interactions.", "motivation": "Classical Ewald methods use Gaussian-based kernel splitting, which is inefficient for biharmonic Green's functions. More efficient splitting methods are needed for faster computation of Stokeslet, stresslet, and elastic kernels.", "method": "Developed kernel splitting using zeroth-order prolate spheroidal wave functions for biharmonic Green's function. Created DMK (dual-space multilevel kernel-splitting) algorithm that is adaptive and linear-scaling for both uniform and nonuniform point distributions.", "result": "The DMK algorithm demonstrates efficient performance in numerical examples for both 2D and 3D cases, working in free space and periodic cubes with linear scaling.", "conclusion": "PSWF-based kernel splitting provides more efficient alternatives to Gaussian-based methods for biharmonic-related kernels, enabling faster computational methods for Stokes and elastic interactions."}}
{"id": "2509.21480", "pdf": "https://arxiv.org/pdf/2509.21480", "abs": "https://arxiv.org/abs/2509.21480", "authors": ["Grishma Palkar", "Hessam Babaee"], "title": "An Adaptive CUR Algorithm and its Application to Reduced-Order Modeling of Random PDEs", "categories": ["math.NA", "cs.NA", "math.AP"], "comment": null, "summary": "Certain classes of CUR algorithms, also referred to as cross or\npseudoskeleton algorithms, are widely used for low-rank matrix approximation\nwhen direct access to all matrix entries is costly. Their key advantage lies in\nconstructing a rank-r approximation by sampling only r columns and r rows of\nthe target matrix. This property makes them particularly attractive for\nreduced-order modeling of nonlinear matrix differential equations, where\nnonlinear operations on low-rank matrices can otherwise produce high-rank or\neven full-rank intermediates that must subsequently be truncated to rank $r$.\nCUR cross algorithms bypass the intermediate step and directly form the\nrank-$r$ matrix. However, standard cross algorithms may suffer from loss of\naccuracy in some settings, limiting their robustness and broad applicability.\nIn this work, we propose a cross oversampling algorithm that augments the\nintersection with additional sampled columns and rows. We provide an error\nanalysis demonstrating that the proposed oversampling improves robustness. We\nalso present an algorithm that adaptively selects the number of oversampling\nentries based on efficiently computable indicators. We demonstrate the\nperformance of the proposed CUR algorithm for time integration of several\nnonlinear stochastic PDEs on low-rank matrix manifolds.", "AI": {"tldr": "Proposes a cross oversampling algorithm for CUR matrix approximation that improves robustness by augmenting the intersection with additional sampled columns and rows, with adaptive oversampling selection.", "motivation": "Standard CUR algorithms suffer from accuracy loss in some settings, limiting their robustness for applications like reduced-order modeling of nonlinear matrix differential equations.", "method": "Cross oversampling algorithm that augments the intersection with additional sampled columns and rows, with adaptive selection of oversampling entries based on efficiently computable indicators.", "result": "Error analysis demonstrates improved robustness, and performance is validated for time integration of nonlinear stochastic PDEs on low-rank matrix manifolds.", "conclusion": "The proposed oversampling approach enhances CUR algorithm robustness while maintaining efficiency for nonlinear matrix approximation problems."}}
{"id": "2509.21524", "pdf": "https://arxiv.org/pdf/2509.21524", "abs": "https://arxiv.org/abs/2509.21524", "authors": ["Deissy Marcela Pizo", "Juan Carlos Mu\u00f1oz Grajales"], "title": "An inverse problem for linear system of dispersive equations", "categories": ["math.AP"], "comment": null, "summary": "This paper addresses the inverse problem of identifying the linear velocity\ncoefficient in a linear system governed by two Benjamin-Bona-Mahony-type\nequations, which model the displacement of water waves propagating along the\nsurface of a shallow channel, incorporating effects of dispersion and\ntopography. To solve this, we reformulate the inverse problem as a restricted\nminimization problem (RMP), aimed at optimizing a suitably regularized\nobjective functional. We use numerical techniques, specifically the iterative\nL-BFGS-B algorithm implemented in the Dolfin-Adjoint-Python-SciPy libraries, to\nsolve the RMP effectively. Following methodologies similar to those in Pipicano\net al., we establish a local stability result for the RMP. Additionally,\nthrough numerical simulations, we demonstrate the effectiveness of the proposed\nidentification method in determining the linear velocity coefficient in\nBoussinesq-type systems.", "AI": {"tldr": "This paper presents an inverse problem approach to identify the linear velocity coefficient in Benjamin-Bona-Mahony-type equations using a restricted minimization problem and numerical optimization with L-BFGS-B algorithm.", "motivation": "To solve the inverse problem of identifying linear velocity coefficients in water wave models that account for dispersion and topography effects in shallow channels.", "method": "Reformulate the inverse problem as a restricted minimization problem with regularization, then solve using L-BFGS-B algorithm implemented in Dolfin-Adjoint-Python-SciPy libraries.", "result": "Established local stability for the minimization problem and demonstrated effective identification of linear velocity coefficients through numerical simulations in Boussinesq-type systems.", "conclusion": "The proposed method successfully identifies linear velocity coefficients in water wave models, with proven local stability and practical effectiveness shown through numerical experiments."}}
{"id": "2509.21506", "pdf": "https://arxiv.org/pdf/2509.21506", "abs": "https://arxiv.org/abs/2509.21506", "authors": ["Simon Tischmann", "Rudi Gaelzer", "Dustin Schr\u00f6der", "Marian Lazar", "Horst Fichtner"], "title": "Electrostatic waves in astrophysical Druyvesteyn plasmas: I. Langmuir waves", "categories": ["physics.plasm-ph", "astro-ph.SR"], "comment": null, "summary": "Plasmas in various astrophysical systems are in non-equilibrium states as\nevidenced by direct in-situ measurements in the solar wind, solar corona and\nplanetary environments as well as by indirect observations of various sources\nof waves and emissions. Specific are non-Maxwellian velocity distributions with\nsuprathermal tails, for whose description the most-used are the Kappa\n(power-law) distributions. With this paper we introduce a modeling alternative\nfor linear waves in plasmas described by another non-equilibrium model, namely\nthe generalized Druyvesteyn distribution. This can reproduce not only the\nhigh-energy tails, but also the low-energy flat-tops of velocity distributions,\nlike those of electrons associated with the Earth's bow shock and\ninterplanetary shocks or of electrons in the solar transition region. We derive\nthe corresponding dispersion relation for longitudinal waves in terms of the\nnewly introduced Druyvsteyn dispersion function, numerically compute, for the\nisotropic case, the dispersion curves as well as damping rates, and provide\nanalytical approximation in the limit of weak damping. Thereby, we provide a\nnew modeling tool that facilitates the quantitative treatment of a variety of\nnon-Maxwellian plasmas.", "AI": {"tldr": "This paper introduces a new modeling approach using generalized Druyvesteyn distributions to study linear waves in non-equilibrium plasmas, providing an alternative to Kappa distributions that can capture both high-energy tails and low-energy flat-tops observed in various astrophysical environments.", "motivation": "Astrophysical plasmas are often in non-equilibrium states with non-Maxwellian velocity distributions, as evidenced by direct measurements in solar wind, solar corona, and planetary environments. Current models like Kappa distributions have limitations in capturing the full complexity of these distributions.", "method": "The authors use generalized Druyvesteyn distributions to model non-equilibrium plasmas, derive the corresponding dispersion relation for longitudinal waves in terms of a newly introduced Druyvesteyn dispersion function, numerically compute dispersion curves and damping rates for isotropic cases, and provide analytical approximations for weak damping limits.", "result": "The study successfully develops a new modeling framework that can reproduce both high-energy tails and low-energy flat-tops of velocity distributions observed in various astrophysical contexts, such as electrons associated with Earth's bow shock, interplanetary shocks, and solar transition region.", "conclusion": "This work provides a new quantitative modeling tool for treating a variety of non-Maxwellian plasmas, offering an alternative approach that better captures the complex characteristics of velocity distributions in astrophysical environments beyond what traditional Kappa distributions can achieve."}}
{"id": "2509.22439", "pdf": "https://arxiv.org/pdf/2509.22439", "abs": "https://arxiv.org/abs/2509.22439", "authors": ["Regina Katsman"], "title": "Fracture-Driven Single Bubble Grows and Migration Model in Aquatic Muds", "categories": ["physics.comp-ph", "physics.chem-ph"], "comment": "20 pages, 3 figures", "summary": "Methane (CH$_4$) is the most prevalent hydrocarbon and a significant\ngreenhouse gas found in the atmosphere. Buoyancy-driven CH$_4$ bubble growth\nand migration within muddy aquatic sediments are closely associated with\nsediment fracturing. This paper presents a model of buoyancy-driven CH$_4$\nsingle bubble growth in fine-grained cohesive (muddy) aquatic sediment. * Solid\nmechanics model component simulates bubble elastic expansion caused by solute\nsupply from the surrounding mud, followed by differential fracturing of the mud\nby the evolving bubble front, a process governed by the principles of Linear\nElastic Fracture Mechanics (LEFM). This differential fracturing controls the\nevolving shape and size of the bubble. * The model integrates the LEFM with the\ndynamics of solute exchange between the bubble and the surrounding mud,\nalongside the conservation of CH$_4$ gas within the bubble. * An advanced\nmeshing strategy allows balancing between the geometry resolution and the\namount of mesh elements, thereby optimizing for both solution accuracy and\ncomputational efficiency. This model is intended to be a foundational tool for\nproper upscaling of single bubble characteristics to effective gassy medium\ntheories. This will enhance the accuracy of the acoustic applications and could\ncontribute to evaluation of overall CH$_4$ emission from the aquatic muds.", "AI": {"tldr": "Model of buoyancy-driven methane bubble growth in muddy aquatic sediments that integrates solid mechanics with solute exchange dynamics and fracture mechanics.", "motivation": "To understand methane bubble growth and migration in sediments, which is important for greenhouse gas emissions and sediment fracturing processes.", "method": "Combines Linear Elastic Fracture Mechanics (LEFM) with solute exchange dynamics and gas conservation, using an advanced meshing strategy for computational efficiency.", "result": "Developed a comprehensive model that simulates bubble elastic expansion, differential fracturing, and evolving bubble shape/size in cohesive sediments.", "conclusion": "This model serves as a foundational tool for upscaling single bubble characteristics to effective gassy medium theories, improving accuracy in acoustic applications and methane emission evaluations."}}
{"id": "2509.21832", "pdf": "https://arxiv.org/pdf/2509.21832", "abs": "https://arxiv.org/abs/2509.21832", "authors": ["James A. Rossmanith", "Preeti Sar"], "title": "Micro-macro kinetic flux-vector splitting schemes for the multidimensional Boltzmann-ES-BGK equation", "categories": ["math.NA", "cs.NA", "physics.flu-dyn", "65M08, 82C40, 82M12"], "comment": "31 pages, 7 figures, 2 tables", "summary": "The kinetic Boltzmann equation models gas dynamics over a wide range of\nspatial and temporal scales. Simplified versions of the full Boltzmann\ncollision operator, such as the classical Bhatnagar-Gross-Krook and the closely\nrelated Ellipsoidal-Statistical-BGK operators, can dramatically decrease the\ncomputational costs of numerical solving kinetic equations. Classical BGK\nyields incorrect transport coefficients (relative to the full Boltzmann\ncollision operator) at low Knudsen numbers, whereas ES-BGK captures them\ncorrectly. In this work, we develop a finite volume method using a micro-macro\ndecomposition of the distribution function, which requires a smaller velocity\nmesh relative to direct kinetic methods for low and intermediate Knudsen\nnumbers. The macro portion of the model is a fluid model with a moment closure\nprovided from the heat flux tensor calculated from the micro portion. The micro\nportion is obtained by applying to the original kinetic equation a projector\ninto the orthogonal complement of the null space of the collision operator -\nthis projector depends on the macro portion. In particular, we extend the\ntechnique of Bennoune, Lemou, and Mieussens [Uniformly stable schemes for the\nBoltzmann equation preserving the compressible Navier-Stokes asymptotics, J.\nComput. Phys. (2008)] to two-space dimensions, the ES-BGK collision operator,\nand problems with reflecting wall boundary conditions. As it appears in both\nthe micro and macro equations, the collision operator is handled via L-stable\nimplicit time discretizations. At the same time, the remaining transport terms\nare computed via kinetic flux vector splitting (for macro) and upwind\ndifferencing (for micro). The resulting scheme is applied to various test cases\nin 1D and 2D. The 2D version of the code is parallelized via MPI, and we\npresent weak and strong scaling studies with varying numbers of processors.", "AI": {"tldr": "Developed a finite volume method using micro-macro decomposition for solving Boltzmann equations with ES-BGK collision operator, extending previous work to 2D and implementing parallel MPI scaling.", "motivation": "To create efficient numerical methods for kinetic Boltzmann equations that maintain accuracy across spatial/temporal scales while reducing computational costs compared to direct kinetic methods, particularly for low/intermediate Knudsen numbers.", "method": "Finite volume method with micro-macro decomposition of distribution function; macro portion uses fluid model with moment closure from micro heat flux; micro portion uses orthogonal projector; implicit time discretization for collision operator; kinetic flux vector splitting for macro transport; upwind differencing for micro transport; extended to 2D, ES-BGK operator, and reflecting wall boundaries.", "result": "Successfully applied to various 1D and 2D test cases; implemented parallel MPI version with demonstrated weak and strong scaling performance across multiple processors.", "conclusion": "The developed method provides an efficient and accurate approach for solving kinetic equations with ES-BGK collision operator, maintaining correct transport coefficients while reducing computational requirements through micro-macro decomposition and parallel implementation."}}
{"id": "2509.21806", "pdf": "https://arxiv.org/pdf/2509.21806", "abs": "https://arxiv.org/abs/2509.21806", "authors": ["Liying Shan", "Wei Shuai", "Leyun Wu"], "title": "Multiple solutions to the nonlinear Schr\u00f6dinger equation with a partial confinement", "categories": ["math.AP"], "comment": null, "summary": "We consider multiple solutions to the nonlinear Schr\\\"odinger equation (NLS)\nwith a partial confinement, which is physically relevant to dynamics of the\nBose-Einstein condensate. Our study not only verifies the existence of positive\nground state solutions and the nonexistence of least energy sign-changing\nsolutions but also sheds light on the symmetry associated with these solutions.\nA novel finding is the existence of saddle type nodal solutions with their\nnodal domains intersecting at the origin. Furthermore, we have developed some\ninnovative techniques such as the method of moving planes and the Hopf lemma\nfor nonlinear Schr\\\"odinger equations with partial confinement.", "AI": {"tldr": "The paper studies multiple solutions to the nonlinear Schr\u00f6dinger equation with partial confinement, relevant to Bose-Einstein condensate dynamics, including ground states, sign-changing solutions, and novel saddle-type nodal solutions.", "motivation": "To understand the dynamics of Bose-Einstein condensates through the nonlinear Schr\u00f6dinger equation with partial confinement, and to investigate the existence and symmetry properties of various solution types.", "method": "Developed innovative techniques including the method of moving planes and the Hopf lemma specifically adapted for nonlinear Schr\u00f6dinger equations with partial confinement.", "result": "Verified existence of positive ground state solutions, proved nonexistence of least energy sign-changing solutions, discovered saddle-type nodal solutions with nodal domains intersecting at the origin, and revealed symmetry properties of these solutions.", "conclusion": "The study provides comprehensive understanding of solution types for partially confined NLS, with novel findings about saddle-type nodal solutions and development of specialized analytical techniques for this class of equations."}}
{"id": "2509.21645", "pdf": "https://arxiv.org/pdf/2509.21645", "abs": "https://arxiv.org/abs/2509.21645", "authors": ["Marianna Lytova", "Fran\u00e7ois Fillion-Gourdeau", "Simon Valli\u00e8res", "Sylvain Fourmaux", "St\u00e9phane Payeur", "Fran\u00e7ois L\u00e9gar\u00e9", "Steve MacLean"], "title": "Generation of directed electron beams by tight focusing of an ultrashort IR laser in a near-critical plasma", "categories": ["physics.plasm-ph", "physics.optics"], "comment": "12 pages, 14 figures", "summary": "Recent studies have demonstrated the possibility of accelerating electrons to\nMeV energies in ambient air using tightly focused laser configurations. In this\narticle, we explore possible strategies to control and optimize the resulting\nelectron beams using laser and gas parameters. Our theoretical analysis shows\nthat in near-critical plasmas, linearly and circularly polarized pulses are\nmore efficient than radially polarized pulses for electron acceleration. In\naddition, electron beams obtained from linearly polarized pulses have lower\ndivergence angles. By studying the efficiency of the acceleration process -\ncharacterized by the maximum kinetic energy of electrons and their total number\n- we identify optimal conditions in ambient air at wavelength lambda_0\napproximately 1.5 micrometers and a_0 >= 15. We also scale our results to\nlower-density air and demonstrate that some noble gases (Ne, Ar) are suitable\nmedia for accelerating electrons. Our investigations show that this\nacceleration scheme enables multi-MeV electrons with low divergence using\nmillijoule-class high-repetition rate lasers, making it a promising candidate\nfor applications in medical sciences and ultrafast imaging.", "AI": {"tldr": "Optimizing laser-driven electron acceleration in ambient air using laser and gas parameters to achieve multi-MeV electrons with low divergence for medical and imaging applications.", "motivation": "To control and optimize electron beams generated by laser acceleration in ambient air, exploring strategies using laser polarization and gas parameters for practical applications.", "method": "Theoretical analysis comparing linearly, circularly, and radially polarized laser pulses in near-critical plasmas, studying acceleration efficiency through maximum kinetic energy and electron count, and scaling to different gas densities.", "result": "Linearly and circularly polarized pulses are more efficient than radially polarized ones; linearly polarized pulses produce lower divergence electron beams; optimal conditions found at 1.5\u03bcm wavelength with a_0\u226515; noble gases (Ne, Ar) identified as suitable media.", "conclusion": "This acceleration scheme enables multi-MeV electrons with low divergence using millijoule-class high-repetition rate lasers, making it promising for medical sciences and ultrafast imaging applications."}}
{"id": "2509.21338", "pdf": "https://arxiv.org/pdf/2509.21338", "abs": "https://arxiv.org/abs/2509.21338", "authors": ["Pei-Jie Chang", "Dong Ruan", "Gui-Lu Long"], "title": "Dimer-driven multiple reentrant localization with composite potential", "categories": ["cond-mat.dis-nn", "physics.comp-ph", "quant-ph"], "comment": null, "summary": "Recent studies have revealed reentrant localization transitions in\nquasi-periodic one-dimensional lattices, where the competition between\ndimerized hopping and staggered disorder plays a central role. Yet the extent\nto which such reentrant localization persists under more general conditions,\nsuch as additional periodic potentials, modified quasi-periodic modulations\nremains unclear. Here we investigate localization phenomena in a\none-dimensional lattice subject to a periodic potential and an additional\nquasi-periodic modulation. Using both eigenstate-based indicators and\nexperimentally accessible dynamical observables, we identify robust reentrant,\nor multiple, localization transitions. We show that these transitions are\nuniquely stabilized by the dimer structure of the unit cell, where the\ncompetition between the onsite periodic potential and the quasi-periodic\nmodulation becomes most pronounced. By systematically varying the periodicity\nparameter $\\alpha$ and the quasi-periodic frequency $\\beta$, we find that the\nrobust multiple reentrant localization behavior disappears for any deviation\nfrom the dimer configuration, confirming its essential role. Our results\nsuggest that the interplay between these competing factors drives the multiple\nreentrant localization transitions.", "AI": {"tldr": "The paper investigates reentrant localization transitions in 1D lattices with periodic potentials and quasi-periodic modulations, showing multiple localization transitions stabilized by dimer structures.", "motivation": "To understand how reentrant localization persists under more general conditions beyond simple dimerized hopping and staggered disorder, specifically with additional periodic potentials and modified quasi-periodic modulations.", "method": "Used eigenstate-based indicators and experimentally accessible dynamical observables to study localization in 1D lattices with periodic potential and quasi-periodic modulation, systematically varying periodicity parameter \u03b1 and quasi-periodic frequency \u03b2.", "result": "Identified robust multiple reentrant localization transitions uniquely stabilized by dimer structure, where competition between onsite periodic potential and quasi-periodic modulation is most pronounced. The behavior disappears for any deviation from dimer configuration.", "conclusion": "The interplay between competing factors (periodic potential and quasi-periodic modulation) drives multiple reentrant localization transitions, with dimer structure playing an essential role in stabilizing these transitions."}}
{"id": "2509.21963", "pdf": "https://arxiv.org/pdf/2509.21963", "abs": "https://arxiv.org/abs/2509.21963", "authors": ["Nathaniel Pritchard", "Taejun Park", "Yuji Nakatsukasa", "Per-Gunnar Martinsson"], "title": "Fast Rank Adaptive CUR via a Recycled Small Sketch", "categories": ["math.NA", "cs.NA", "stat.CO", "65F55, 15A23, 68W20"], "comment": "24 pages, 8 figures", "summary": "The computation of accurate low-rank matrix approximations is central to\nimproving the scalability of various techniques in machine learning,\nuncertainty quantification, and control. Traditionally, low-rank approximations\nare constructed using SVD-based approaches such as truncated SVD or\nRandomizedSVD. Although these SVD approaches -- especially RandomizedSVD --\nhave proven to be very computationally efficient, other low-rank approximation\nmethods can offer even greater performance. One such approach is the CUR\ndecomposition, which forms a low-rank approximation using direct row and column\nsubsets of a matrix. Because CUR uses direct matrix subsets, it is also often\nbetter able to preserve native matrix structures like sparsity or\nnon-negativity than SVD-based approaches and can facilitate data interpretation\nin many contexts. This paper introduces IterativeCUR, which draws on previous\nwork in randomized numerical linear algebra to build a new algorithm that is\nhighly competitive compared to prior work: (1) It is adaptive in the sense that\nit takes as an input parameter the desired tolerance, rather than an a priori\nguess of the numerical rank. (2) It typically runs significantly faster than\nboth existing CUR algorithms and techniques such as RandomizedSVD, in\nparticular when these methods are run in an adaptive rank mode. Its asymptotic\ncomplexity is $\\mathcal{O}(mn + (m+n)r^2 + r^3)$ for an $m\\times n$ matrix of\nnumerical rank $r$. (3) It relies on a single small sketch from the matrix that\nis successively downdated as the algorithm proceeds.\n  We demonstrate through extensive experiments that IterativeCUR achieves up to\n$4\\times$ speed-up over state-of-the-art pivoting-on-sketch approaches with no\nloss of accuracy, and up to $40\\times$ speed-up over rank-adaptive randomized\nSVD approaches.", "AI": {"tldr": "IterativeCUR is a new adaptive algorithm for low-rank matrix approximation that uses CUR decomposition, offering significant speed improvements over existing methods while maintaining accuracy.", "motivation": "Traditional SVD-based approaches for low-rank matrix approximations have computational limitations, and CUR decomposition can better preserve matrix structures like sparsity and facilitate data interpretation, but existing CUR methods need improvement in efficiency and adaptivity.", "method": "IterativeCUR uses randomized numerical linear algebra techniques with a single small sketch that is successively downdated, providing an adaptive approach that takes desired tolerance as input rather than requiring an a priori rank guess.", "result": "The algorithm achieves up to 4x speed-up over state-of-the-art pivoting-on-sketch approaches and up to 40x speed-up over rank-adaptive randomized SVD approaches, with asymptotic complexity of O(mn + (m+n)r\u00b2 + r\u00b3) for an m\u00d7n matrix of numerical rank r.", "conclusion": "IterativeCUR is a highly competitive low-rank approximation method that combines the structural preservation benefits of CUR decomposition with superior computational efficiency compared to existing approaches."}}
{"id": "2509.21909", "pdf": "https://arxiv.org/pdf/2509.21909", "abs": "https://arxiv.org/abs/2509.21909", "authors": ["Masakazu Yamamoto"], "title": "Logarithmic evolutions in solutions to the convection-diffusion equation of Burgers type", "categories": ["math.AP", "35B05, 35B06, 35C20, 35Q35, 35Q79"], "comment": "21 pages", "summary": "In this paper, the initial value problem of the convection-diffusion equation\nof Burgers type is treated. In the asymptotic profile of solutions, the\nnonlinearity of the equation is reflected. A characteristic component derived\nfrom nonlinearity develops logarithmically over time, and the rate of decay\nvaries depending on the spatial dimensions. The rate of this component\npredicted from the scale of the equation. In even dimensions, the logarithmic\ncomponent decays at the expected rate, but in odd dimensions, it decays much\nfaster than expected. These results suggest that there are differences in the\nsymmetry of nonlinearity depending on the parity of dimensions. This\ninterpretation is supported by comparison with similar Navier--Stokes\nequations. The Burgers type is applicable as an indicator for considering\nseveral bilinear problems.", "AI": {"tldr": "This paper analyzes the convection-diffusion equation of Burgers type, showing that nonlinearity creates logarithmic time development in solutions with decay rates varying by spatial dimension parity.", "motivation": "To understand how nonlinearity affects the asymptotic behavior of Burgers-type convection-diffusion equations and investigate dimensional parity effects on solution symmetry.", "method": "Analysis of the initial value problem for Burgers-type convection-diffusion equation, examining asymptotic profiles and comparing with Navier-Stokes equations.", "result": "Nonlinearity creates logarithmic time development; decay rates differ by dimension parity - even dimensions show expected decay rates while odd dimensions decay faster than expected.", "conclusion": "Dimensional parity affects nonlinearity symmetry in Burgers-type equations, with implications for understanding bilinear problems and similar Navier-Stokes equations."}}
{"id": "2509.21680", "pdf": "https://arxiv.org/pdf/2509.21680", "abs": "https://arxiv.org/abs/2509.21680", "authors": ["Yang Chen", "Scott E. Parker"], "title": "Saturation of the kinetic ballooning instability due to the electron parallel nonlinearity", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The electron parallel nonlinearity (EPN) is implemented in the gyrokinetic\nParticle-in-Cell turbulence code GEM [Y. Chen and S. E. Parker, J. Comp. Phys.\n220, 839 (2007)]. Application to the Cyclone Base Case reveals a strong effect\nof EPN on the saturated heat transport above the kinetic ballooning mode\nthreshold. Evidence is provided to show that the strong effect is associated\nwith the electron radial motion due to magnetic fluttering, which turns fine\nstructures of the KBM eigenmode in radius into fine structures in velocity and\nincreases the magnitude of the EPN term in the kinetic equation.", "AI": {"tldr": "Implementation of electron parallel nonlinearity (EPN) in GEM gyrokinetic PIC code shows strong impact on heat transport above KBM threshold, linked to electron radial motion from magnetic fluttering.", "motivation": "To study the effects of electron parallel nonlinearity on plasma turbulence and heat transport in gyrokinetic simulations, particularly for kinetic ballooning modes.", "method": "Implemented EPN in the GEM gyrokinetic Particle-in-Cell turbulence code and applied it to the Cyclone Base Case scenario.", "result": "EPN has strong effect on saturated heat transport above KBM threshold, with evidence showing this is due to electron radial motion from magnetic fluttering creating fine structures in velocity space.", "conclusion": "Electron parallel nonlinearity significantly influences plasma turbulence and heat transport through mechanisms involving magnetic fluttering and velocity space structures."}}
{"id": "2509.21527", "pdf": "https://arxiv.org/pdf/2509.21527", "abs": "https://arxiv.org/abs/2509.21527", "authors": ["Mahesh Doijade", "Andrey Alekseenko", "Ania Brown", "Alan Gray", "Szil\u00e1rd P\u00e1ll"], "title": "Redesigning GROMACS Halo Exchange: Improving Strong Scaling with GPU-initiated NVSHMEM", "categories": ["cs.DC", "cs.PF", "physics.comp-ph"], "comment": "17 pages, 8 figures, submitted to PAW-ATM Workshop, SC 2025", "summary": "Improving time-to-solution in molecular dynamics simulations often requires\nstrong scaling due to fixed-sized problems. GROMACS is highly\nlatency-sensitive, with peak iteration rates in the sub-millisecond, making\nscalability on heterogeneous supercomputers challenging. MPI's CPU-centric\nnature introduces additional latencies on GPU-resident applications' critical\npath, hindering GPU utilization and scalability. To address these limitations,\nwe present an NVSHMEM-based GPU kernel-initiated redesign of the GROMACS domain\ndecomposition halo-exchange algorithm. Highly tuned GPU kernels fuse data\npacking and communication, leveraging hardware latency-hiding for fine-grained\noverlap. We employ kernel fusion across overlapped data forwarding\ncommunication phases and utilize the asynchronous copy engine over NVLink to\noptimize latency and bandwidth. Our GPU-resident formulation greatly increases\ncommunication-computation overlap, improving GROMACS strong scaling performance\nacross NVLink by up to 1.5x (intra-node) and 2x (multi-node), and up to 1.3x\nmulti-node over NVLink+InfiniBand. This demonstrates the profound benefits of\nGPU-initiated communication for strong-scaling a broad range of\nlatency-sensitive applications.", "AI": {"tldr": "GPU-initiated communication redesign of GROMACS halo-exchange using NVSHMEM, achieving up to 2x performance improvement through better communication-computation overlap.", "motivation": "GROMACS is latency-sensitive with sub-millisecond iteration rates, and MPI's CPU-centric nature introduces latencies that hinder GPU utilization and scalability on heterogeneous supercomputers.", "method": "NVSHMEM-based GPU kernel-initiated redesign of domain decomposition halo-exchange algorithm, with fused data packing/communication, hardware latency-hiding, kernel fusion across communication phases, and asynchronous copy engine over NVLink.", "result": "1.5x improvement in intra-node scaling, 2x in multi-node scaling over NVLink, and 1.3x multi-node over NVLink+InfiniBand.", "conclusion": "GPU-initiated communication provides significant benefits for strong-scaling latency-sensitive applications like molecular dynamics simulations."}}
{"id": "2509.22156", "pdf": "https://arxiv.org/pdf/2509.22156", "abs": "https://arxiv.org/abs/2509.22156", "authors": ["Michael Griebel", "Marc Alexander Schweitzer", "Lukas Troska"], "title": "A Parallel-in-Time Combination Method for Parabolic Problems", "categories": ["math.NA", "cs.NA", "65M55, 65M22, 65M99, 65F08, 65Y05, 65Y99"], "comment": null, "summary": "In this article, we present a parallel discretization and solution method for\nparabolic problems with a higher number of space dimensions. It consists of a\nparallel-in-time approach using the multigrid reduction-in-time algorithm MGRIT\nwith its implementation in the library XBraid, the sparse grid combination\nmethod for discretizing the resulting elliptic problems in space, and a domain\ndecomposition method for each of the subproblems in the combination method\nbased on the space-filling curve approach. As a result, we obtain an extremely\nfast and embarrassingly parallel solver with excellent speedup and scale-up\nqualities, which is perfectly suited for parabolic problems with up to six\nspace dimensions. We describe our new parallel approach and show its superior\nparallelization properties for the heat equation, the chemical master equation\nand some exemplary stochastic differential equations.", "AI": {"tldr": "A parallel solver for high-dimensional parabolic problems combining MGRIT for time, sparse grids for space, and domain decomposition, achieving excellent scalability up to 6D.", "motivation": "To solve parabolic problems with many space dimensions efficiently using parallel computing methods.", "method": "Combines MGRIT (multigrid reduction-in-time) from XBraid for time parallelism, sparse grid combination method for spatial discretization, and domain decomposition via space-filling curves.", "result": "Extremely fast and embarrassingly parallel solver with excellent speedup and scale-up, demonstrated on heat equation, chemical master equation, and stochastic differential equations.", "conclusion": "The approach is highly effective for parabolic problems with up to six space dimensions, showing superior parallelization properties."}}
{"id": "2509.22003", "pdf": "https://arxiv.org/pdf/2509.22003", "abs": "https://arxiv.org/abs/2509.22003", "authors": ["Kshitij Sinha"], "title": "Quantitative periodic homogenization of parabolic equations with large drift and potential", "categories": ["math.AP"], "comment": "14 pages, no figure, comments welcome", "summary": "This work aims to study the rates in the context of periodic homogenization\nof parabolic problems with large lower order terms (both drift and potential).\nWe demonstrate that the solution is a product of three terms: (i) a function of\ntime, (ii) the ground-state of an exponential cell eigenvalue problem and (iii)\nthe solution to a parabolic equation with zero effective drift. For the latter,\nwe derive $\\mathrm L^2$ rates in the homogenization limit.", "AI": {"tldr": "The paper studies homogenization rates for parabolic problems with large drift and potential terms, showing the solution decomposes into three multiplicative components.", "motivation": "To understand homogenization behavior for parabolic equations with significant lower order terms (drift and potential) in periodic settings.", "method": "Decompose solution into three parts: time function, ground-state of exponential cell eigenvalue problem, and solution to parabolic equation with zero effective drift. Derive L\u00b2 convergence rates.", "result": "Established that the solution factors into three multiplicative components and obtained L\u00b2 convergence rates in the homogenization limit.", "conclusion": "The three-part decomposition provides a framework for analyzing homogenization of parabolic problems with large lower order terms, with explicit convergence rates."}}
{"id": "2509.21417", "pdf": "https://arxiv.org/pdf/2509.21417", "abs": "https://arxiv.org/abs/2509.21417", "authors": ["Xiangyan An", "Min Chen", "Jianglai Liu", "Zhengming Sheng", "Jie Zhang"], "title": "Enhanced Axion-Photon Conversion via Seeded Photons instead of Resonant Cavities for Short-Pulse Axion Detection", "categories": ["hep-ph", "physics.plasm-ph"], "comment": null, "summary": "We propose a seeded axion-photon conversion scheme to enhance the sensitivity\nof light-shining-through-wall (LSW) experiments for axion detection, where the\naxions are generated from short pulse lasers and the usual resonant cavity is\nnot applicable. By injecting a small, coherent seed electromagnetic field (EM\nfield) into the axion-photon conversion region, the axion-induced EM field can\nconstructively interfere with the seed field, amplifying the regenerated photon\nnumber beyond the unseeded case. Starting from the axion-modified Maxwell\nequations, we derive the axion-photon conversion probability and show how an\ninitial seed field boosts the final photon amplitude. The relative phase\nbetween the seed field and the axion field can cause constructive or\ndestructive interference, though the measurable quantity is the net photon\nnumber variation. We evaluate the expected signal enhancement, signal-to-noise\nconsiderations (including seed shot noise), and the potential improvement in\ncoupling sensitivity. Compared to a standard LSW setup, the seeded scheme can\nachieve orders-of-magnitude higher photon yield per axion, potentially\nsurpassing resonance-enhanced experiments in certain parameter regimes. This\napproach offers a promising route to extend the reach of laboratory axion\nsearches, especially for the case where the resonant cavities are impractical.", "AI": {"tldr": "A seeded axion-photon conversion scheme enhances LSW experiment sensitivity by using coherent seed EM fields to amplify axion-induced signals through constructive interference, potentially achieving orders-of-magnitude higher photon yields.", "motivation": "To improve sensitivity of light-shining-through-wall experiments for axion detection, especially when resonant cavities are impractical, by overcoming limitations of standard unseeded approaches.", "method": "Inject a small, coherent seed EM field into the axion-photon conversion region, allowing axion-induced EM fields to constructively interfere with the seed field. Derived conversion probability from axion-modified Maxwell equations and analyzed phase-dependent interference effects.", "result": "The seeded scheme can achieve orders-of-magnitude higher photon yield per axion compared to standard LSW setups, potentially surpassing resonance-enhanced experiments in certain parameter regimes.", "conclusion": "This seeded approach offers a promising route to extend laboratory axion search reach, particularly when resonant cavities are impractical, with significant sensitivity improvements through constructive interference amplification."}}
{"id": "2509.21624", "pdf": "https://arxiv.org/pdf/2509.21624", "abs": "https://arxiv.org/abs/2509.21624", "authors": ["Andreas Burger", "Luca Thiede", "Nikolaj R\u00f8nne", "Varinia Bernales", "Nandita Vijaykumar", "Tejs Vegge", "Arghya Bhowmik", "Alan Aspuru-Guzik"], "title": "Shoot from the HIP: Hessian Interatomic Potentials without derivatives", "categories": ["cs.LG", "physics.chem-ph", "physics.comp-ph"], "comment": "https://github.com/BurgerAndreas/hip", "summary": "Fundamental tasks in computational chemistry, from transition state search to\nvibrational analysis, rely on molecular Hessians, which are the second\nderivatives of the potential energy. Yet, Hessians are computationally\nexpensive to calculate and scale poorly with system size, with both quantum\nmechanical methods and neural networks. In this work, we demonstrate that\nHessians can be predicted directly from a deep learning model, without relying\non automatic differentiation or finite differences. We observe that one can\nconstruct SE(3)-equivariant, symmetric Hessians from irreducible\nrepresentations (irrep) features up to degree $l$=2 computed during message\npassing in graph neural networks. This makes HIP Hessians one to two orders of\nmagnitude faster, more accurate, more memory efficient, easier to train, and\nenables more favorable scaling with system size. We validate our predictions\nacross a wide range of downstream tasks, demonstrating consistently superior\nperformance for transition state search, accelerated geometry optimization,\nzero-point energy corrections, and vibrational analysis benchmarks. We\nopen-source the HIP codebase and model weights to enable further development of\nthe direct prediction of Hessians at https://github.com/BurgerAndreas/hip", "AI": {"tldr": "HIP is a deep learning model that directly predicts molecular Hessians (second derivatives of potential energy) without using automatic differentiation or finite differences, achieving significant speed and accuracy improvements.", "motivation": "Molecular Hessians are computationally expensive to calculate with traditional quantum mechanical methods and neural networks, and they scale poorly with system size, limiting their practical use in computational chemistry tasks.", "method": "Construct SE(3)-equivariant, symmetric Hessians from irreducible representation (irrep) features up to degree l=2 computed during message passing in graph neural networks, enabling direct prediction without differentiation.", "result": "HIP Hessians are one to two orders of magnitude faster, more accurate, more memory efficient, easier to train, and enable more favorable scaling with system size compared to existing methods.", "conclusion": "The direct prediction approach for Hessians demonstrates superior performance across various computational chemistry tasks including transition state search, geometry optimization, zero-point energy corrections, and vibrational analysis."}}
{"id": "2509.22190", "pdf": "https://arxiv.org/pdf/2509.22190", "abs": "https://arxiv.org/abs/2509.22190", "authors": ["Chiara Colombo", "Caterina Dalmaso", "Lucas O. M\u00fcller", "Annunziato Siviglia"], "title": "Well-balanced high-order method for non-conservative hyperbolic PDEs with source terms: application to one-dimensional blood flow equations with gravity", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "The present work proposes a well-balanced finite volume-type numerical method\nfor the solution of non-conservative hyperbolic partial differential equations\n(PDEs) with source terms. The method is characterized, first, by the use of a\nrecently introduced high-order spatial reconstruction, based on generalized\nRiemann problem information from the previous time level. Such reconstruction\nis well-balanced up to order three, compact, efficient and easy to implement.\nSecond, the method incorporates a well-balanced space-time evolution operator,\nwhich allows for well-balanced fully explicit time evolution. The accuracy and\nefficiency of the method are assessed on both a scalar problem (Burgers'\nequation) and a nonlinear PDE system (hyperbolized one-dimensional blood flow\nequations with gravity and friction, and with variable mechanical and\ngeometrical properties). The well-balanced property is verified by showing that\nnumerically-determined stationary solutions are preserved up to machine\nprecision. The order of accuracy in space and time is validated through\nempirical convergence rate studies. Additionally, the performance of the method\nis assessed on a network of 86 arteries, under both stationary and transient\nconditions.", "AI": {"tldr": "A well-balanced finite volume method for non-conservative hyperbolic PDEs with source terms, using high-order spatial reconstruction and explicit time evolution.", "motivation": "To develop accurate numerical methods that preserve stationary solutions for hyperbolic PDEs with source terms, particularly in applications like blood flow modeling.", "method": "Combines high-order spatial reconstruction based on generalized Riemann problems with a well-balanced space-time evolution operator for explicit time stepping.", "result": "Method preserves stationary solutions up to machine precision, achieves high-order accuracy, and performs well on complex networks like 86 arteries under various conditions.", "conclusion": "The proposed method is effective, efficient, and well-balanced for solving hyperbolic PDEs with source terms, demonstrating practical utility in biomedical applications."}}
{"id": "2509.22029", "pdf": "https://arxiv.org/pdf/2509.22029", "abs": "https://arxiv.org/abs/2509.22029", "authors": ["Yuxi Hu", "Reinhard Racke"], "title": "Initial boundary value problems for 3-d Navier-Stokes equations with hyperbolic heat conduction", "categories": ["math.AP"], "comment": null, "summary": "We study an initial boundary value problem for the 3-dimensional compressible\nNavier-Stokes equations with hyperbolic heat conduction, where the classical\nFourier law is replaced by the Cattaneo-Christov constitutive relation. We\nfocus on spherically symmetric solutions. We establish the existence of uniform\nglobal small solutions to the resulting system. Furthermore, based on uniform a\npriori estimates, we rigorously justify both the relaxation limit and the\nvanishing viscosity limit.", "AI": {"tldr": "Existence of global small solutions for 3D compressible Navier-Stokes equations with hyperbolic heat conduction in spherical symmetry, with justification of relaxation and vanishing viscosity limits.", "motivation": "To study compressible fluid flow with hyperbolic heat conduction (Cattaneo-Christov model) instead of classical Fourier law, focusing on spherical symmetry for mathematical tractability.", "method": "Analysis of initial boundary value problem for 3D compressible Navier-Stokes equations with Cattaneo-Christov heat conduction, using uniform a priori estimates and spherical symmetry reduction.", "result": "Established existence of uniform global small solutions and rigorously justified both relaxation limit (to Fourier law) and vanishing viscosity limit.", "conclusion": "The hyperbolic heat conduction model admits global small solutions in spherical symmetry, with valid relaxation and vanishing viscosity limits that connect to classical models."}}
{"id": "2509.22031", "pdf": "https://arxiv.org/pdf/2509.22031", "abs": "https://arxiv.org/abs/2509.22031", "authors": ["R. Li", "G. \u00c1lvarez", "A. Ipakchi", "L. Cupertino-Malheiros", "M. R. Gilbert", "E. Mart\u00ednez-Pa\u00f1eda", "E. Prestat"], "title": "Understanding the oxidation of pure Tungsten in air and its impact on the lifecycle of a fusion power plant", "categories": ["physics.app-ph", "cond-mat.mtrl-sci", "physics.plasm-ph"], "comment": null, "summary": "The oxidation of pure W and the sublimation of W oxide have been investigated\nto assess their impact on the lifecycle of a fusion power plant. Pure W has\nbeen oxidised at temperatures between 400 and 1050C and for durations ranging\nbetween 1 and 70 h. The formation of voids and cracks has been observed at\ntemperatures above 600C, leading to the formation of dust or oxide spalling,\nwhich could be problematic in maintenance and waste-handling scenarios of a\nfusion power plant. Preferential oxidation taking place at the edge of the\nspecimen was characterised, and its impact is discussed in relation to\ncomponent design. Characterisation using electron microscopy and Raman\nspectroscopy revealed that the oxide scale is formed of three main layers: the\ninner layer is 30-50 nm thick WO2 oxide, the middle layer is a 10-20 um of\nWO_2.72 and the outer layer is formed of WO2.9/WO3 phases - whose thickness\nvaries according to the total thickness of the oxide scale. The observed\nmicrostructure is discussed in relation to the parabolic-to-linear kinetics and\nits potential impact on tritium permeation and detritiation efficiency.", "AI": {"tldr": "Study of tungsten oxidation and oxide sublimation effects on fusion power plant lifecycle, revealing void/crack formation above 600\u00b0C that creates dust and spalling issues.", "motivation": "To assess the impact of tungsten oxidation and oxide sublimation on fusion power plant lifecycle, particularly for maintenance and waste-handling scenarios.", "method": "Oxidized pure W at 400-1050\u00b0C for 1-70 hours, characterized using electron microscopy and Raman spectroscopy to analyze oxide layer structure.", "result": "Found void/crack formation above 600\u00b0C leading to dust/spalling; identified three-layer oxide structure: inner WO2 (30-50nm), middle WO2.72 (10-20\u03bcm), outer WO2.9/WO3 phases.", "conclusion": "Oxidation-induced microstructure affects parabolic-to-linear kinetics and potentially impacts tritium permeation and detritiation efficiency in fusion components."}}
{"id": "2509.21670", "pdf": "https://arxiv.org/pdf/2509.21670", "abs": "https://arxiv.org/abs/2509.21670", "authors": ["Mahindra Singh Rautela", "Alexander Most", "Siddharth Mansingh", "Bradley C. Love", "Ayan Biswas", "Diane Oyen", "Earl Lawrence"], "title": "MORPH: Shape-agnostic PDE Foundation Models", "categories": ["cs.CV", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "We introduce MORPH, a shape-agnostic, autoregressive foundation model for\npartial differential equations (PDEs). MORPH is built on a convolutional vision\ntransformer backbone that seamlessly handles heterogeneous spatiotemporal\ndatasets of varying data dimensionality (1D--3D) at different resolutions,\nmultiple fields with mixed scalar and vector components. The architecture\ncombines (i) component-wise convolution, which jointly processes scalar and\nvector channels to capture local interactions, (ii) inter-field\ncross-attention, which models and selectively propagates information between\ndifferent physical fields, (iii) axial attentions, which factorizes full\nspatiotemporal self-attention along individual spatial and temporal axes to\nreduce computational burden while retaining expressivity. We pretrain multiple\nmodel variants on a diverse collection of heterogeneous PDE datasets and\nevaluate transfer to a range of downstream prediction tasks. Using both\nfull-model fine-tuning and parameter-efficient low-rank adapters (LoRA), MORPH\noutperforms models trained from scratch in both zero-shot and full-shot\ngeneralization. Across extensive evaluations, MORPH matches or surpasses strong\nbaselines and recent state-of-the-art models. Collectively, these capabilities\npresent a flexible and powerful backbone for learning from heterogeneous and\nmultimodal nature of scientific observations, charting a path toward scalable\nand data-efficient scientific machine learning.", "AI": {"tldr": "MORPH is a shape-agnostic, autoregressive foundation model for PDEs that handles heterogeneous spatiotemporal datasets of varying dimensions and fields through a convolutional vision transformer architecture with component-wise convolution, inter-field cross-attention, and axial attention mechanisms.", "motivation": "To create a flexible foundation model that can handle the heterogeneous and multimodal nature of scientific observations in PDEs, addressing challenges of varying data dimensionality, resolutions, and mixed scalar/vector fields.", "method": "Built on convolutional vision transformer backbone with three key components: (1) component-wise convolution for joint processing of scalar/vector channels, (2) inter-field cross-attention for information propagation between physical fields, (3) axial attention for computational efficiency. Pretrained on diverse PDE datasets and evaluated with fine-tuning and LoRA adapters.", "result": "MORPH outperforms models trained from scratch in both zero-shot and full-shot generalization, matching or surpassing strong baselines and state-of-the-art models across extensive evaluations.", "conclusion": "MORPH presents a flexible and powerful backbone for learning from heterogeneous scientific observations, charting a path toward scalable and data-efficient scientific machine learning."}}
{"id": "2509.22269", "pdf": "https://arxiv.org/pdf/2509.22269", "abs": "https://arxiv.org/abs/2509.22269", "authors": ["Shu-Yung Liu", "Mei-Heng Yueh"], "title": "Square-Domain Area-Preserving Parameterization for Genus-Zero and Genus-One Closed Surfaces", "categories": ["math.NA", "cs.CG", "cs.NA", "65D17, 65D18, 68U01, 68U05"], "comment": "22 pages, 13 figures", "summary": "The parameterization of closed surfaces typically requires either multiple\ncharts or a non-planar domain to achieve a seamless global mapping. In this\npaper, we propose a numerical framework for the seamless parameterization of\ngenus-zero and genus-one closed simplicial surfaces onto a unit square domain.\nThe process begins by slicing the surface with either the shortest-path or the\nReeb graph method. The sliced surface is then mapped onto the unit square using\na globally convergent algorithm that minimizes the weighted variance of\nper-triangle area ratios to achieve area preservation. Numerical experiments on\nbenchmark models demonstrate that our method achieves high accuracy and\nefficiency. Furthermore, the proposed method enables applications such as\ngeometry images, producing accurate and high-quality surface reconstructions.", "AI": {"tldr": "A numerical framework for seamless parameterization of genus-zero and genus-one closed surfaces onto a unit square domain using slicing and area-preserving mapping.", "motivation": "To overcome the limitations of existing parameterization methods that require multiple charts or non-planar domains for closed surfaces.", "method": "Slice the surface using shortest-path or Reeb graph method, then map onto unit square using globally convergent algorithm that minimizes weighted variance of per-triangle area ratios for area preservation.", "result": "High accuracy and efficiency demonstrated on benchmark models, enabling applications like geometry images with accurate surface reconstructions.", "conclusion": "The proposed method provides an effective framework for seamless parameterization of closed surfaces with practical applications in surface reconstruction."}}
{"id": "2509.22048", "pdf": "https://arxiv.org/pdf/2509.22048", "abs": "https://arxiv.org/abs/2509.22048", "authors": ["Roman Novikov", "Vladimir Sivkin"], "title": "A two-point phase recovering from holographic data on a single plane", "categories": ["math.AP", "math.SP"], "comment": null, "summary": "We consider a plane wave, a radiation solution, and the sum of these\nsolutions (total solution) for the Helmholtz equation in an exterior region in\n$\\mathbb{R}^d,$ $d\\geq 2$. In this region, we consider a hyperplane $X$ with\nsufficiently large distance $s$ from the origin in ${\\mathbb R}^d.$ We give\ntwo-point local formulas for approximate recovering the radiation solution\nrestricted to the plane $X$ from the intensity of the total solution at $X$,\nthat is, from holographic data. The recovering is given in terms of the\nfar-field pattern of the radiation solution with a decaying error term as $s\n\\to +\\infty.$ A numerical implementation is also presented.", "AI": {"tldr": "The paper presents two-point local formulas for recovering radiation solutions from holographic intensity data on a distant hyperplane, with error decaying as distance increases.", "motivation": "To develop efficient methods for reconstructing radiation solutions from intensity measurements (holographic data) in exterior regions, which has applications in wave propagation and imaging.", "method": "Uses two-point local formulas applied to the intensity of total solutions (plane wave + radiation solution) on a distant hyperplane, leveraging the Helmholtz equation in exterior regions.", "result": "Successfully recovers radiation solutions restricted to the hyperplane with decaying error as distance increases, and provides numerical implementation demonstrating the approach.", "conclusion": "The proposed two-point formulas effectively reconstruct radiation solutions from holographic intensity data with accuracy improving with distance, validated through numerical experiments."}}
{"id": "2509.22172", "pdf": "https://arxiv.org/pdf/2509.22172", "abs": "https://arxiv.org/abs/2509.22172", "authors": ["Mohammad G. H. Alijani", "Alessio Monti", "Stefano Vellucci", "Mirko Barbuto", "Alessandro Toscano", "Filiberto Bilotti"], "title": "Tunable Transmissive Metagratings Using Single Layer Cylindrical Plasma Discharges", "categories": ["physics.app-ph", "physics.optics", "physics.plasm-ph"], "comment": null, "summary": "In this paper, we propose a novel single-layer reconfigurable transmissive\nmetagrating based on plasma discharges. Each unit-cell consists of two\nside-by-side core-shell cylinders, with a tunable plasma core and a high-index\ndielectric shell. The structure is modeled using a free-electron plasma\npermittivity with adjustable plasma frequency. Analytical and numerical results\nshow that the main transmission lobe can be switched between -41{\\deg}, 0{\\deg}\nand 41{\\deg} by tuning the plasma frequencies. Transmission efficiency remains\nabove 80% at broadside and 90% in the steered direction. This tunability\nenables effective directional control with low reflection and high overall\npower efficiency.", "AI": {"tldr": "A reconfigurable transmissive metagrating using plasma discharges achieves beam steering from -41\u00b0 to 41\u00b0 with high transmission efficiency above 80-90%.", "motivation": "To develop a tunable metagrating that enables effective directional control of electromagnetic waves with high efficiency and low reflection.", "method": "Single-layer metagrating with unit-cells containing two side-by-side core-shell cylinders (tunable plasma core, high-index dielectric shell), modeled using free-electron plasma permittivity with adjustable plasma frequency.", "result": "Main transmission lobe can be switched between -41\u00b0, 0\u00b0 and 41\u00b0 by tuning plasma frequencies, with transmission efficiency above 80% at broadside and 90% in steered direction.", "conclusion": "The proposed plasma-based metagrating provides effective directional control with low reflection and high power efficiency through tunable plasma frequency adjustment."}}
{"id": "2509.21751", "pdf": "https://arxiv.org/pdf/2509.21751", "abs": "https://arxiv.org/abs/2509.21751", "authors": ["Jaemin Oh"], "title": "Reparameterizing 4DVAR with neural fields", "categories": ["cs.LG", "physics.comp-ph", "physics.flu-dyn"], "comment": "22 pages, 10 figures, 6 tables", "summary": "Four-dimensional variational data assimilation (4DVAR) is a cornerstone of\nnumerical weather prediction, but its cost function is difficult to optimize\nand computationally intensive. We propose a neural field-based reformulation in\nwhich the full spatiotemporal state is represented as a continuous function\nparameterized by a neural network. This reparameterization removes the\ntime-sequential dependency of classical 4DVAR, enabling parallel-in-time\noptimization in parameter space. Physical constraints are incorporated directly\nthrough a physics-informed loss, simplifying implementation and reducing\ncomputational cost. We evaluate the method on the two-dimensional\nincompressible Navier--Stokes equations with Kolmogorov forcing. Compared to a\nbaseline 4DVAR implementation, the neural reparameterized variants produce more\nstable initial condition estimates without spurious oscillations. Notably,\nunlike most machine learning-based approaches, our framework does not require\naccess to ground-truth states or reanalysis data, broadening its applicability\nto settings with limited reference information.", "AI": {"tldr": "Neural field-based 4DVAR reformulation enables parallel-in-time optimization for weather prediction, removing sequential dependencies and incorporating physics constraints through neural networks.", "motivation": "Classical 4DVAR is computationally intensive and difficult to optimize due to time-sequential dependencies, requiring a more efficient approach.", "method": "Represent spatiotemporal state as continuous function parameterized by neural network, enabling parallel optimization with physics-informed loss constraints.", "result": "Produces more stable initial condition estimates without spurious oscillations compared to baseline 4DVAR, tested on 2D Navier-Stokes equations.", "conclusion": "Neural reparameterization framework works without ground-truth data, broadening applicability to settings with limited reference information."}}
{"id": "2509.22373", "pdf": "https://arxiv.org/pdf/2509.22373", "abs": "https://arxiv.org/abs/2509.22373", "authors": ["Daizhan Cheng"], "title": "Universal Solution to Kronecker Product Decomposition", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper provides a general solution for the Kronecker product\ndecomposition (KPD) of vectors, matrices, and hypermatrices. First, an\nalgorithm, namely, monic decomposition algorithm (MDA), is reviewed. It\nconsists of a set of projections from a higher dimension Euclidian space to its\nfactor-dimension subspaces. It is then proved that the KPD of vectors is\nsolvable, if and only if, the project mappings provide the required decomposed\nvectors. Hence it provides an easily verifiable necessary and sufficient\ncondition for the KPD of vectors. Then an algorithm is proposed to calculate\nthe least square error approximated decomposition. Using it finite times a\nfinite sum (precise) KPD of any vectors can be obtained. Then the swap matrix\nis used to make the elements of a matrix re-arranging, and then provides a\nmethod to convert the KPD of matrices to its corresponding KPD of vectors. It\nis proved that the KPD of a matrix is solvable, if and only if, the KPD of its\ncorresponding vector is solvable. In this way, the necessary and sufficient\ncondition, and the followed algorithms for approximate and finite sum KPDs for\nmatrices are also obtained. Finally, the permutation matrix is introduced and\nused to convert the KPD of any hypermatrix to KPD of its corresponding vector.\nSimilarly to matrix case, the necessary and sufficient conditions for\nsolvability and the techniques for vectors and matrices are also applicable for\nhypermatrices, though some additional algorithms are necessary. Several\nnumerical examples are included to demonstrate this universal KPD solving\nmethod.", "AI": {"tldr": "The paper presents a universal method for Kronecker product decomposition (KPD) of vectors, matrices, and hypermatrices using monic decomposition algorithm, swap matrices, and permutation matrices.", "motivation": "To provide a general solution framework for KPD problems across different mathematical objects (vectors, matrices, hypermatrices) with verifiable necessary and sufficient conditions.", "method": "Uses monic decomposition algorithm (MDA) with projections, swap matrices for matrix rearrangement, and permutation matrices for hypermatrix conversion to vector KPD problems.", "result": "Established necessary and sufficient conditions for KPD solvability and developed algorithms for both approximate and finite sum decompositions that work universally across vectors, matrices, and hypermatrices.", "conclusion": "The proposed universal KPD solving method successfully handles decomposition problems for various mathematical structures with proven conditions and demonstrated effectiveness through numerical examples."}}
{"id": "2509.22069", "pdf": "https://arxiv.org/pdf/2509.22069", "abs": "https://arxiv.org/abs/2509.22069", "authors": ["Andrea Signori", "Hao Wu"], "title": "Optimal Control of a Navier-Stokes-Cahn-Hilliard System for Membrane-fluid Interaction", "categories": ["math.AP"], "comment": null, "summary": "We consider an optimal control problem for a two-dimensional\nNavier-Stokes-Cahn-Hilliard system arising in the modeling of fluid-membrane\ninteraction. The fluid dynamics is governed by the incompressible Navier-Stokes\nequations, which are nonlinearly coupled with a sixth-order Cahn-Hilliard type\nequation representing the deformation of a flexible membrane through a\nphase-field variable. Building on the previously established existence and\nuniqueness of global strong solutions for the coupled system, we introduce an\nexternal forcing term acting on the fluid as the control variable. Then we seek\nto minimize a tracking-type cost functional, demonstrating the existence of an\noptimal control and deriving the associated first-order necessary optimality\nconditions. A key issue is to establish sufficient regularity for solutions of\nthe adjoint system, which is crucial for the rigorous derivation of optimality\nconditions in the fluid dynamic setting.", "AI": {"tldr": "Analysis of optimal control for a 2D Navier-Stokes-Cahn-Hilliard system modeling fluid-membrane interaction, focusing on existence of optimal controls and derivation of optimality conditions.", "motivation": "To study optimal control problems for fluid-membrane interaction systems, where fluid dynamics (Navier-Stokes) is coupled with membrane deformation (Cahn-Hilliard) through a phase-field variable.", "method": "Introduce external forcing term as control variable, minimize tracking-type cost functional, establish existence of optimal control, and derive first-order necessary optimality conditions using adjoint system analysis.", "result": "Proved existence of optimal control and derived rigorous first-order necessary optimality conditions by establishing sufficient regularity for solutions of the adjoint system.", "conclusion": "Successfully formulated and analyzed optimal control problem for coupled fluid-membrane system, providing mathematical foundation for control applications in such complex physical systems."}}
{"id": "2509.22503", "pdf": "https://arxiv.org/pdf/2509.22503", "abs": "https://arxiv.org/abs/2509.22503", "authors": ["Hayato Higuchi", "Yuki Ito", "Kazuki Sakamoto", "Keisuke Fujii", "Akimasa Yoshikawa"], "title": "A Quantum Algorithm for Nonlinear Electromagnetic Fluid Dynamics via Koopman-von Neumann Linearization", "categories": ["quant-ph", "physics.plasm-ph"], "comment": "16 pages, 6 figures", "summary": "To simulate plasma phenomena, large-scale computational resources have been\nemployed in developing high-precision and high-resolution plasma simulations.\nOne of the main obstacles in plasma simulations is the requirement of\ncomputational resources that scale polynomially with the number of spatial\ngrids, which poses a significant challenge for large-scale modeling. To address\nthis issue, this study presents a quantum algorithm for simulating the\nnonlinear electromagnetic fluid dynamics that govern space plasmas. We map it,\nby applying Koopman-von Neumann linearization, to the Schr\\\"{o}dinger equation\nand evolve the system using Hamiltonian simulation via quantum singular value\ntransformation. Our algorithm scales $O \\left(s N_x \\, \\mathrm{polylog} \\left(\nN_x \\right) T \\right)$ in time complexity with $s$, $N_x$, and $T$ being the\nspatial dimension, the number of spatial grid points per dimension, and the\nevolution time, respectively. Comparing the scaling $O \\left( s N_x^s\n\\left(T^{5/4}+T N_x\\right) \\right)$ for the classical method with the finite\nvolume scheme, this algorithm achieves polynomial speedup in $N_x$. The space\ncomplexity of this algorithm is exponentially reduced from $O\\left( s N_x^s\n\\right)$ to $O\\left( s \\, \\mathrm{polylog} \\left( N_x \\right) \\right)$.\nNumerical experiments validate that accurate solutions are attainable with\nsmaller $m$ than theoretically anticipated and with practical values of $m$ and\n$R$, underscoring the feasibility of the approach. As a practical\ndemonstration, the method accurately reproduces the Kelvin-Helmholtz\ninstability, underscoring its capability to tackle more intricate nonlinear\ndynamics. These results suggest that quantum computing can offer a viable\npathway to overcome the computational barriers of multiscale plasma modeling.", "AI": {"tldr": "Quantum algorithm for plasma simulation using Koopman-von Neumann linearization and Hamiltonian simulation via quantum singular value transformation, achieving polynomial speedup over classical methods.", "motivation": "To overcome computational resource limitations in plasma simulations that scale polynomially with spatial grids, enabling large-scale plasma modeling.", "method": "Map nonlinear electromagnetic fluid dynamics to Schr\u00f6dinger equation using Koopman-von Neumann linearization, then evolve system via Hamiltonian simulation with quantum singular value transformation.", "result": "Achieves O(sN_x polylog(N_x)T) time complexity (vs classical O(sN_x^s(T^{5/4}+TN_x))) and exponential space complexity reduction from O(sN_x^s) to O(s polylog(N_x)). Validated with Kelvin-Helmholtz instability simulation.", "conclusion": "Quantum computing provides viable pathway to overcome computational barriers in multiscale plasma modeling, with practical feasibility demonstrated."}}
{"id": "2509.22324", "pdf": "https://arxiv.org/pdf/2509.22324", "abs": "https://arxiv.org/abs/2509.22324", "authors": ["Andrea Montessori", "Marco Lauricella", "Aritra Mukherjee", "Luca Brandt"], "title": "Breakdown of Kolmogorov Scaling and Modified Energy Transfer in Bubble-Laden Turbulence", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": null, "summary": "We investigate the effect of a dispersed bubble phase on forced homogeneous\nand isotropic turbulence using high-resolution high-performance simulations\nbased on the lattice Boltzmann method. While the classical Kolmogorov energy\ncascade is largely preserved when considering the system as a whole, a\nphase-specific analysis reveals striking deviations from the classical\nturbulence scaling. In particular, the gas phase exhibits significant\ndepartures from Kolmogorov's predictions, whereas the continuous liquid phase\nretains a turbulence structure consistent with classical expectations up to 24%\nin gas volume fractions. These findings suggest that, despite the presence of a\ndispersed phase, the global energy transfer remains close to a universal\nbehavior. At the same time, phase-specific interactions are shown to introduce\nmodifications to the turbulent dynamics at small scales. In particular, the\ngas-phase exhibits a nearly flat spectrum at low wave numbers followed by a\nk^{-3} scaling at intermediate scales pointing to the presence of patterns of\nlocalized bursts uniformly distributed between two finite wavelengths.Our\nresults aim at deepening the understanding of multiphase turbulence,\nparticularly in the context of energy transfer mechanisms and phase\ninteractions in bubble-laden flows. This study provides a framework for future\ninvestigations into the fundamental properties of multiphase turbulence and its\nimplications for environmental, atmospheric, and industrial flows.", "AI": {"tldr": "Study shows dispersed bubbles in turbulence preserve global energy cascade but cause phase-specific deviations, with gas phase showing non-classical scaling while liquid phase remains classical.", "motivation": "To understand how dispersed bubble phases affect turbulence structure and energy transfer mechanisms in multiphase flows, particularly bubble-laden flows relevant to environmental, atmospheric, and industrial applications.", "method": "High-resolution high-performance simulations using lattice Boltzmann method to analyze forced homogeneous and isotropic turbulence with dispersed bubble phase.", "result": "Global energy cascade follows Kolmogorov predictions, but phase-specific analysis reveals gas phase exhibits significant deviations with nearly flat spectrum at low wave numbers and k^{-3} scaling at intermediate scales, while liquid phase maintains classical turbulence structure up to 24% gas volume fractions.", "conclusion": "Despite dispersed phase presence, global energy transfer remains universal, but phase-specific interactions modify turbulent dynamics at small scales, providing insights for understanding multiphase turbulence in various applications."}}
{"id": "2509.22587", "pdf": "https://arxiv.org/pdf/2509.22587", "abs": "https://arxiv.org/abs/2509.22587", "authors": ["Bernardo Cockburn"], "title": "The discretizations of the derivative by the continuous Galerkin and the discontinuous Galerkin methods are exactly the same", "categories": ["math.NA", "cs.NA", "Primary 65N30, 65M60, 35L65", "F.2.1"], "comment": "7 pages, no figures", "summary": "In the framework of ODEs, we uncover a new link between the continuous\nGalerkin method (see Math. Comp. (1972), 26 (118 and 120), 415-426 and 881-891)\nand the discontinuous Galerkin method (see Mathematical Aspects of Finite\nelements in PDEs, (1974), 89-123), namely, that the discretizations of the\nderivative by these two methods are the same. A direct consequence of this\nresult is the construction of a new elementwise post-processing of the\napproximate solution provided by the Discontinuous Galerkin method. When the DG\nmethod uses polynomials of degree $k\\ge0$, the post-processing consists in\nadding, to the DG approximate solution, the (scaled) left-Radau polynomial of\ndegree $k+1$ multiplied by the jump of the approximate solution at the left\nboundary of the interval. No extra computation is required. The resulting new\napproximation is continuous and, for $k>0$, converges with order $k+2$, that\nis, with one order more than the original discontinuous Galerkin approximation.\nFor $k=0$, the order remains the same.", "AI": {"tldr": "The paper reveals that continuous and discontinuous Galerkin methods share the same derivative discretization, leading to a new post-processing technique for DG solutions that enhances convergence without extra computation.", "motivation": "To establish a connection between continuous and discontinuous Galerkin methods in ODE frameworks and leverage this relationship to improve DG solution accuracy.", "method": "Developed an elementwise post-processing technique that adds a scaled left-Radau polynomial (degree k+1) multiplied by solution jumps at interval boundaries to the DG approximation.", "result": "The post-processed solution becomes continuous and achieves convergence order k+2 for k>0 (one order higher than original DG), while maintaining the same order for k=0.", "conclusion": "The discovered link between Galerkin methods enables efficient post-processing that significantly improves DG solution accuracy and continuity without additional computational cost."}}
{"id": "2509.22078", "pdf": "https://arxiv.org/pdf/2509.22078", "abs": "https://arxiv.org/abs/2509.22078", "authors": ["Tony Liimatainen", "Janne Nurminen"], "title": "An Inverse Problem for the Prescribed Mean Curvature", "categories": ["math.AP", "35R30 (Primary) 35J25, 35J62 (Secondary)"], "comment": "25 pages", "summary": "We extend the study of inverse problems for minimal surfaces by considering\nthe inverse source problem for the prescribed mean curvature equation\n\\begin{equation*}\n  \\nabla \\cdot \\left[ \\frac{\\nabla u}{(1 + |\\nabla u|^2)^{1/2}} \\right] = H(x).\n\\end{equation*} We prove that in two dimensions, the source function $H$ is\nuniquely determined by the associated Dirichlet-to-Neumann map. A notable\nfeature of this problem is that although the equation is posed on an Euclidean\ndomain, its linearization yields an anisotropic conductivity equation where the\ncoefficient matrix corresponds to a Riemannian metric $g$ depending on the\nbackground solution. This work represents the first treatments of inverse\nsource problems for quasilinear equations.\n  The proof relies on the higher order linearization method. The main\nmethodological contribution is the development of an approach to decouple the\nresulting system of nonlinear algebraic and geometric equations, which enables\nthe complete determination of the source term from boundary measurements. The\ndecoupling uses a Liouville type uniqueness result for conformal mappings.", "AI": {"tldr": "The paper proves that in 2D, the source function H in the prescribed mean curvature equation is uniquely determined by the Dirichlet-to-Neumann map, representing the first treatment of inverse source problems for quasilinear equations.", "motivation": "To extend the study of inverse problems for minimal surfaces by considering the inverse source problem for the prescribed mean curvature equation, which has applications in geometric analysis and PDE theory.", "method": "Uses the higher order linearization method and develops a novel approach to decouple the resulting system of nonlinear algebraic and geometric equations, leveraging a Liouville type uniqueness result for conformal mappings.", "result": "Proves that in two dimensions, the source function H is uniquely determined by the associated Dirichlet-to-Neumann map.", "conclusion": "This work establishes the first inverse source result for quasilinear equations and provides a methodological framework for handling such problems through geometric and algebraic decoupling techniques."}}
{"id": "2509.22340", "pdf": "https://arxiv.org/pdf/2509.22340", "abs": "https://arxiv.org/abs/2509.22340", "authors": ["Anna Zaborowska", "Peter McKeown"], "title": "step2point dataset: Detailed shower simulation for data representation studies", "categories": ["hep-ex", "physics.comp-ph", "physics.ins-det"], "comment": null, "summary": "This dataset contains a detailed simulation output that allows the\nconstruction and study of different data representations for electromagnetic\nand hadronic showers in calorimeters. It is published so that optimal data\nrepresentations can be studied, with the ultimate goal of constructing a\ngeneral tool that takes detailed simulation output and translates it into an\noptimal representation that can serve as the input to surrogate simulators\nbased on generative models.", "AI": {"tldr": "The paper presents a simulation dataset for studying optimal data representations of electromagnetic and hadronic showers in calorimeters, aiming to develop tools for creating inputs for generative model-based surrogate simulators.", "motivation": "To enable the study and development of optimal data representations for calorimeter shower simulations, with the goal of creating general tools that can translate detailed simulation outputs into formats suitable for generative surrogate models.", "method": "The authors created and published a detailed simulation dataset containing electromagnetic and hadronic shower data from calorimeters, which can be used to construct and analyze different data representation approaches.", "result": "A comprehensive simulation dataset is made available that allows researchers to study various data representation methods for calorimeter shower simulations.", "conclusion": "This dataset serves as a foundation for developing optimal data representations that can be used as inputs for surrogate simulators based on generative models, potentially improving the efficiency of calorimeter simulation workflows."}}
{"id": "2509.21605", "pdf": "https://arxiv.org/pdf/2509.21605", "abs": "https://arxiv.org/abs/2509.21605", "authors": ["Tian Yu Yen", "Reese E. Jones", "Ravi G. Patel"], "title": "GenUQ: Predictive Uncertainty Estimates via Generative Hyper-Networks", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": "9 pages, 6 figures", "summary": "Operator learning is a recently developed generalization of regression to\nmappings between functions. It promises to drastically reduce expensive\nnumerical integration of PDEs to fast evaluations of mappings between\nfunctional states of a system, i.e., surrogate and reduced-order modeling.\nOperator learning has already found applications in several areas such as\nmodeling sea ice, combustion, and atmospheric physics. Recent approaches\ntowards integrating uncertainty quantification into the operator models have\nrelied on likelihood based methods to infer parameter distributions from noisy\ndata. However, stochastic operators may yield actions from which a likelihood\nis difficult or impossible to construct. In this paper, we introduce, GenUQ, a\nmeasure-theoretic approach to UQ that avoids constructing a likelihood by\nintroducing a generative hyper-network model that produces parameter\ndistributions consistent with observed data. We demonstrate that GenUQ\noutperforms other UQ methods in three example problems, recovering a\nmanufactured operator, learning the solution operator to a stochastic elliptic\nPDE, and modeling the failure location of porous steel under tension.", "AI": {"tldr": "GenUQ introduces a measure-theoretic approach to uncertainty quantification for operator learning that uses generative hyper-networks to produce parameter distributions without requiring likelihood construction, outperforming other UQ methods in three test problems.", "motivation": "Traditional likelihood-based UQ methods for operator learning are limited when stochastic operators produce actions where likelihoods are difficult or impossible to construct, creating a need for alternative UQ approaches.", "method": "GenUQ uses a generative hyper-network model that produces parameter distributions consistent with observed data, avoiding the need for likelihood construction through a measure-theoretic approach to uncertainty quantification.", "result": "GenUQ outperforms other UQ methods in three example problems: recovering a manufactured operator, learning the solution operator to a stochastic elliptic PDE, and modeling failure location of porous steel under tension.", "conclusion": "The measure-theoretic generative approach provides an effective alternative to likelihood-based UQ methods for operator learning, enabling uncertainty quantification in cases where traditional methods fail."}}
{"id": "2509.22234", "pdf": "https://arxiv.org/pdf/2509.22234", "abs": "https://arxiv.org/abs/2509.22234", "authors": ["Sebasti\u00e1n Flores-Sep\u00falveda", "Gabrielle Nornberg", "Alexander Quaas"], "title": "The moving patch model with fractional diffusion", "categories": ["math.AP", "35K57, 35B40, 92D25, 47G20"], "comment": "26 pages, 1 figure", "summary": "In this paper we study the following one-dimensional reaction-diffusion\nproblem $$ u_t+(-\\Delta)^s u=f(x-c t, u) \\;\\:\\textrm{ in } \\mathbb{R}\\times\n(0,+\\infty), $$ where $s>\\frac{1}{2}$, $c \\in \\mathbb{R}$ is a prescribed\nvelocity, and $f$ is of KPP type, which describes the evolution of a population\nin an advective environment subjected to nonlocal diffusion. We suppose the\nenvironment is such that it is only advantageous in a bounded ``patch\", outside\nof which the species dies at an asymptotically constant rate.\n  We first derive an optimal solvability criteria for the corresponding\ntraveling waves problem $$\\Delta^s u+c u^{\\prime}+f(x, u)=0 \\;\\:\\textrm{ in }\n\\mathbb{R},$$ through the first eigenvalue of the associated linearized\nelliptic operator with drift. Then we use this criteria to establish the long\ntime behavior of the solution to the parabolic problem, for any continuous\nbounded nonnegative initial data, leading the species either through their\nextinction or survival. Moreover, assuming that for $c=0$ the population\nsurvives, we show that there exist two positive critical speeds $c^{*}$ and\n$c^{**}$ such that for all $|c| <c^{*}$ the population persists, whereas and it\nperishes for $|c| >c^{**}$.", "AI": {"tldr": "This paper analyzes a reaction-diffusion equation with nonlocal diffusion in an advective environment, focusing on population dynamics in bounded advantageous patches with surrounding hostile regions.", "motivation": "To understand how populations evolve in environments with localized favorable conditions and nonlocal dispersal mechanisms, particularly how advection affects survival and extinction.", "method": "Derived optimal solvability criteria for traveling waves using eigenvalue analysis of linearized elliptic operators, then applied these criteria to study long-term behavior of parabolic solutions.", "result": "Established that when population survives without advection (c=0), there exist two critical speeds c* and c** such that persistence occurs for |c| < c* and extinction for |c| > c**.", "conclusion": "The study provides mathematical criteria for population persistence versus extinction in advective environments with nonlocal diffusion, quantifying the impact of environmental velocity on species survival."}}
{"id": "2509.22411", "pdf": "https://arxiv.org/pdf/2509.22411", "abs": "https://arxiv.org/abs/2509.22411", "authors": ["Xiao Xue", "Marco F. P. ten Eikelder", "Mingyang Gao", "Xiaoyuan Cheng", "Yiming Yang", "Yi He", "Shuo Wang", "Sibo Cheng", "Yukun Hu", "Peter V. Coveney"], "title": "Fast-Forward Lattice Boltzmann: Learning Kinetic Behaviour with Physics-Informed Neural Operators", "categories": ["cs.LG", "nlin.CG", "physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "The lattice Boltzmann equation (LBE), rooted in kinetic theory, provides a\npowerful framework for capturing complex flow behaviour by describing the\nevolution of single-particle distribution functions (PDFs). Despite its\nsuccess, solving the LBE numerically remains computationally intensive due to\nstrict time-step restrictions imposed by collision kernels. Here, we introduce\na physics-informed neural operator framework for the LBE that enables\nprediction over large time horizons without step-by-step integration,\neffectively bypassing the need to explicitly solve the collision kernel. We\nincorporate intrinsic moment-matching constraints of the LBE, along with global\nequivariance of the full distribution field, enabling the model to capture the\ncomplex dynamics of the underlying kinetic system. Our framework is\ndiscretization-invariant, enabling models trained on coarse lattices to\ngeneralise to finer ones (kinetic super-resolution). In addition, it is\nagnostic to the specific form of the underlying collision model, which makes it\nnaturally applicable across different kinetic datasets regardless of the\ngoverning dynamics. Our results demonstrate robustness across complex flow\nscenarios, including von Karman vortex shedding, ligament breakup, and bubble\nadhesion. This establishes a new data-driven pathway for modelling kinetic\nsystems.", "AI": {"tldr": "A physics-informed neural operator framework for the lattice Boltzmann equation that enables long-term prediction without step-by-step integration, bypassing computational bottlenecks of traditional methods.", "motivation": "Traditional lattice Boltzmann equation (LBE) solving is computationally intensive due to strict time-step restrictions from collision kernels, limiting practical applications.", "method": "Physics-informed neural operator framework incorporating moment-matching constraints and global equivariance, enabling discretization-invariant predictions and kinetic super-resolution without explicit collision kernel solving.", "result": "Demonstrated robustness across complex flow scenarios including von Karman vortex shedding, ligament breakup, and bubble adhesion, with models trained on coarse lattices generalizing to finer ones.", "conclusion": "Establishes a new data-driven pathway for modeling kinetic systems that is collision model-agnostic and overcomes computational limitations of traditional LBE methods."}}
{"id": "2509.21653", "pdf": "https://arxiv.org/pdf/2509.21653", "abs": "https://arxiv.org/abs/2509.21653", "authors": ["Joon Kwon"], "title": "A regret minimization approach to fixed-point iterations", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "47J26, 65K10, 68W27", "G.1.6"], "comment": null, "summary": "We propose a conversion scheme that turns regret minimizing algorithms into\nfixed point iterations, with convergence guarantees following from regret\nbounds. The resulting iterations can be seen as a grand extension of the\nclassical Krasnoselskii--Mann iterations, as the latter are recovered by\nconverting the Online Gradient Descent algorithm. This approach yields new\nsimple iterations for finding fixed points of non-self operators. We also focus\non converting algorithms from the AdaGrad family of regret minimizers, and thus\nobtain fixed point iterations with adaptive guarantees of a new kind. Numerical\nexperiments on various problems demonstrate faster convergence of AdaGrad-based\nfixed point iterations over Krasnoselskii--Mann iterations.", "AI": {"tldr": "A conversion scheme that transforms regret-minimizing algorithms into fixed point iterations with convergence guarantees, extending classical Krasnoselskii-Mann iterations and enabling new adaptive methods.", "motivation": "To develop a general framework for converting regret-minimizing algorithms into fixed point iterations, extending beyond classical methods and enabling adaptive convergence guarantees.", "method": "Proposed conversion scheme that transforms regret minimizing algorithms into fixed point iterations, with specific focus on converting Online Gradient Descent (recovering classical Krasnoselskii-Mann) and AdaGrad family algorithms.", "result": "The approach yields new simple iterations for finding fixed points of non-self operators and provides fixed point iterations with adaptive guarantees. Numerical experiments show faster convergence of AdaGrad-based iterations compared to classical Krasnoselskii-Mann iterations.", "conclusion": "The conversion scheme successfully bridges regret minimization and fixed point theory, providing a unified framework that extends classical methods and enables adaptive algorithms with improved convergence properties."}}
{"id": "2509.22305", "pdf": "https://arxiv.org/pdf/2509.22305", "abs": "https://arxiv.org/abs/2509.22305", "authors": ["Emanuele Cristoforoni", "Federico Villone"], "title": "Remarks on the reinforcement of the spectrum of an elliptic problem with Robin boundary condition", "categories": ["math.AP", "math.SP", "35P20, 49R05, 35J25, 80A19"], "comment": null, "summary": "We investigate the spectral properties of a differential elliptic operator on\n$H^1(\\bar{\\Omega}\\cup \\Sigma)$, where $\\Omega$ is a smooth domain surrounded by\na layer $\\Sigma$. The thickness of the layer is given by $\\varepsilon h$, where\n$h$ is a positive function defined on the boundary $\\partial \\Omega$ and\n$\\varepsilon$ is the ellipticity constant of the operator in $\\Sigma$. We prove\nthat, in the limit for $\\varepsilon$ going to $0$, the spectrum converges to\nthe spectrum of a differential elliptic operator in $H^1(\\Omega)$, and we\ninvestigate a first-order asymptotic development.", "AI": {"tldr": "Study of spectral properties of elliptic operators on domains with thin boundary layers, showing convergence to limit operator spectrum as layer thickness vanishes.", "motivation": "To understand how the spectrum of elliptic operators behaves when the domain includes a thin boundary layer that shrinks to zero, which has applications in mathematical physics and boundary value problems.", "method": "Mathematical analysis of differential elliptic operators on H^1 spaces with thin layers, using asymptotic analysis and spectral theory to study the limit as the layer thickness parameter \u03b5 approaches 0.", "result": "Proved that the spectrum converges to the spectrum of a differential elliptic operator in H^1(\u03a9) as \u03b5\u21920, and established first-order asymptotic development for the spectrum.", "conclusion": "The spectral properties of elliptic operators with thin boundary layers converge to those of the limiting operator on the main domain, with quantifiable asymptotic behavior as the layer thickness vanishes."}}
{"id": "2509.22435", "pdf": "https://arxiv.org/pdf/2509.22435", "abs": "https://arxiv.org/abs/2509.22435", "authors": ["William Colglazier", "Nicholas Lubbers", "Sergei Tretiak", "Anders M. N. Niklasson", "Maksim Kulichenko"], "title": "Enhancing Molecular Dipole Moment Prediction with Multitask Machine Learning", "categories": ["physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "We present a multitask machine learning strategy for improving the prediction\nof molecular dipole moments by simultaneously training on quantum dipole\nmagnitudes and inexpensive Mulliken atomic charges. With dipole magnitudes as\nthe primary target and assuming only scalar dipole values are available without\nvector components we examine whether incorporating lower quality labels that do\nnot quantitatively reproduce the target property can still enhance model\naccuracy. Mulliken charges were chosen intentionally as an auxiliary task,\nsince they lack quantitative accuracy yet encode qualitative physical\ninformation about charge distribution. Our results show that including Mulliken\ncharges with a small weight in the loss function yields up to a 30% improvement\nin dipole prediction accuracy. This multitask approach enables the model to\nlearn a more physically grounded representation of charge distributions,\nthereby improving both the accuracy and consistency of dipole magnitude\npredictions. These findings highlight that even auxiliary data of limited\nquantitative reliability can provide valuable qualitative physical insights,\nultimately strengthening the predictive power of machine learning models for\nmolecular properties.", "AI": {"tldr": "Multitask learning using dipole magnitudes and Mulliken charges improves molecular dipole prediction by 30%, showing that auxiliary data with limited quantitative reliability can enhance model accuracy through qualitative physical insights.", "motivation": "To improve molecular dipole moment predictions by leveraging auxiliary data (Mulliken charges) that lack quantitative accuracy but contain qualitative physical information about charge distribution, testing whether lower quality labels can enhance model performance.", "method": "Multitask machine learning strategy that simultaneously trains on quantum dipole magnitudes (primary target) and inexpensive Mulliken atomic charges (auxiliary task), with Mulliken charges given small weight in the loss function.", "result": "Including Mulliken charges with small weight in loss function yields up to 30% improvement in dipole prediction accuracy, enabling the model to learn more physically grounded representations of charge distributions.", "conclusion": "Even auxiliary data of limited quantitative reliability can provide valuable qualitative physical insights, strengthening ML models for molecular properties by improving both accuracy and consistency of predictions."}}
{"id": "2509.21920", "pdf": "https://arxiv.org/pdf/2509.21920", "abs": "https://arxiv.org/abs/2509.21920", "authors": ["Umberto Biccari"], "title": "Spiking Neural Networks: a theoretical framework for Universal Approximation and training", "categories": ["math.OC", "cs.NA", "math.NA"], "comment": null, "summary": "Spiking Neural Networks (SNNs) are widely regarded as a biologically-inspired\nand energy-efficient alternative to classical artificial neural networks. Yet,\ntheir theoretical foundations remain only partially understood. In this work,\nwe develop a rigorous mathematical analysis of a representative SNN\narchitecture based on Leaky Integrate-and-Fire (LIF) neurons with\nthreshold-reset dynamics. Our contributions are twofold. First, we establish a\nuniversal approximation theorem showing that SNNs can approximate continuous\nfunctions on compact domains to arbitrary accuracy. The proof relies on a\nconstructive encoding of target values via spike timing and a careful interplay\nbetween idealized $\\delta$-driven dynamics and smooth Gaussian-regularized\nmodels. Second, we analyze the quantitative behavior of spike times across\nlayers, proving well-posedness of the hybrid dynamics and deriving conditions\nunder which spike counts remain stable, decrease, or in exceptional cases\nincrease due to resonance phenomena or overlapping inputs. Together, these\nresults provide a principled foundation for understanding both the expressive\npower and the dynamical constraints of SNNs, offering theoretical guarantees\nfor their use in classification and signal processing tasks.", "AI": {"tldr": "This paper provides rigorous mathematical analysis of Spiking Neural Networks (SNNs) with Leaky Integrate-and-Fire neurons, proving universal approximation capabilities and analyzing spike timing dynamics across layers.", "motivation": "SNNs are biologically-inspired and energy-efficient alternatives to traditional neural networks, but their theoretical foundations remain poorly understood. The authors aim to establish rigorous mathematical understanding of SNN capabilities and limitations.", "method": "The authors develop mathematical analysis of SNN architecture with LIF neurons and threshold-reset dynamics. They use constructive encoding of target values via spike timing and analyze the interplay between idealized \u03b4-driven dynamics and smooth Gaussian-regularized models.", "result": "The paper proves a universal approximation theorem showing SNNs can approximate continuous functions to arbitrary accuracy. It also analyzes spike time behavior across layers, proving well-posedness of hybrid dynamics and deriving conditions for stable, decreasing, or increasing spike counts due to resonance or overlapping inputs.", "conclusion": "The results provide principled theoretical foundation for understanding both the expressive power and dynamical constraints of SNNs, offering theoretical guarantees for their use in classification and signal processing tasks."}}
{"id": "2509.22487", "pdf": "https://arxiv.org/pdf/2509.22487", "abs": "https://arxiv.org/abs/2509.22487", "authors": ["Rupert L. Frank"], "title": "Openness of shape optimizers in higher-order and non-scalar problems", "categories": ["math.AP", "math.SP"], "comment": "12 pages", "summary": "We consider the first eigenvalues of the polyharmonic, Lam\\'e and Stokes\noperators with Dirichlet boundary conditions on sets of given finite measure.\nIt is shown that a quasi-open set for which this eigenvalue is minimal is open.\nThis removes dimensional restrictions in earlier works. We use Campanato\ntheory, which works well in the present higher order or non-scalar setting.", "AI": {"tldr": "The paper proves that quasi-open sets minimizing the first eigenvalues of polyharmonic, Lam\u00e9 and Stokes operators with Dirichlet boundary conditions are actually open sets, removing previous dimensional restrictions.", "motivation": "To establish that eigenvalue-minimizing sets for higher-order and non-scalar operators are open, extending previous results that had dimensional limitations.", "method": "Uses Campanato theory, which is well-suited for analyzing higher-order and non-scalar operators in the context of eigenvalue minimization problems.", "result": "Shows that quasi-open sets minimizing the first eigenvalues of polyharmonic, Lam\u00e9 and Stokes operators with Dirichlet boundary conditions are open sets.", "conclusion": "The study successfully removes dimensional restrictions from earlier works and demonstrates that eigenvalue-minimizing sets for these operators are open, using Campanato theory as an effective analytical tool."}}
{"id": "2509.22532", "pdf": "https://arxiv.org/pdf/2509.22532", "abs": "https://arxiv.org/abs/2509.22532", "authors": ["Antonio De Rosa", "Robin Neumayer", "Reinaldo Resende"], "title": "Rigidity of critical points of hydrophobic capillary functionals", "categories": ["math.AP", "math.DG", "49Q10, 49Q20, 53A10"], "comment": null, "summary": "We prove the rigidity, among sets of finite perimeter, of volume-preserving\ncritical points of the capillary energy in the half space, in the case where\nthe prescribed interior contact angle is between $90^\\circ$ and $120^\\circ$. No\nstructural or regularity assumption is required on the finite perimeter sets.\nAssuming that the ``tangential'' part of the capillary boundary is\n$\\mathcal{H}^n$-null, this rigidity theorem extends to the full hydrophobic\nregime of interior contact angles between $90^\\circ$ and $180^\\circ$.\nFurthermore, we establish the anisotropic counterpart of this theorem under the\nassumption of lower density bounds.", "AI": {"tldr": "Rigidity of volume-preserving critical points of capillary energy in half space for contact angles 90\u00b0-120\u00b0, extending to 90\u00b0-180\u00b0 under additional conditions.", "motivation": "To establish rigidity theorems for capillary energy critical points without structural or regularity assumptions on finite perimeter sets.", "method": "Mathematical analysis of sets of finite perimeter, proving rigidity through geometric measure theory and capillary energy minimization.", "result": "Proved rigidity for contact angles 90\u00b0-120\u00b0, extended to 90\u00b0-180\u00b0 when tangential capillary boundary is null; established anisotropic counterpart with density bounds.", "conclusion": "Critical points of capillary energy exhibit rigidity in specified contact angle ranges, with extensions under additional geometric conditions."}}
{"id": "2509.21378", "pdf": "https://arxiv.org/pdf/2509.21378", "abs": "https://arxiv.org/abs/2509.21378", "authors": ["Christian Puntini"], "title": "Instability of the halocline at the North Pole", "categories": ["physics.geo-ph", "math.AP", "physics.ao-ph", "35Q31, 76B15, 76B55, 76U60, 76E20, 35B99"], "comment": null, "summary": "In this paper we address the issue of stability for the near-inertial Pollard\nwaves, as a model for the halocline in the region of the Arctic Ocean centered\naround the North Pole, derived in Puntini (2025a). Adopting the\nshort-wavelength instability approach, the stability of such flows reduces to\nstudy the stability of a system of ODEs along fluid trajectories, leading to\nthe result that, when the steepness of the near-inertial Pollard waves exceeds\na specific threshold, those waves are linearly unstable. The explicit\ndispersion relation of the model allows to easily compute such threshold,\nknowing the physical properties of the water column.", "AI": {"tldr": "The paper analyzes the stability of near-inertial Pollard waves in the Arctic Ocean halocline, finding they become linearly unstable when wave steepness exceeds a specific computable threshold.", "motivation": "To address stability issues of near-inertial Pollard waves in the Arctic Ocean halocline region, building on previous work by Puntini (2025a).", "method": "Adopts the short-wavelength instability approach, reducing stability analysis to studying ODEs along fluid trajectories.", "result": "Near-inertial Pollard waves become linearly unstable when their steepness exceeds a specific threshold that can be computed using the explicit dispersion relation.", "conclusion": "The explicit dispersion relation enables easy computation of the instability threshold based on water column physical properties."}}
{"id": "2509.21508", "pdf": "https://arxiv.org/pdf/2509.21508", "abs": "https://arxiv.org/abs/2509.21508", "authors": ["Camillo De Lellis", "Jonas Hirsch", "Luca Spolaor"], "title": "Stationary and stable varifolds with singularities", "categories": ["math.DG", "math.AP", "49Q20, 53A10, 35J60"], "comment": "14 pages, comments welcome", "summary": "We construct minimal $m$-dimensional immersions in $\\mathbb{R}^{m+1}$,\nequipped with a $C^{m-1, \\alpha}$ metric, $\\alpha\\in [0,1)$, with a sequence of\ncatenoidal necks or floating disks converging to an isolated, multiplicity $2$,\nsingular flat point.", "AI": {"tldr": "Construction of minimal m-dimensional immersions in R^{m+1} with C^{m-1,\u03b1} metrics, featuring catenoidal necks or floating disks converging to isolated multiplicity 2 singular flat points.", "motivation": "To study minimal immersions with specific geometric structures (catenoidal necks or floating disks) that converge to singular flat points, exploring the behavior of minimal surfaces near singularities.", "method": "Construct minimal m-dimensional immersions in R^{m+1} spaces with C^{m-1,\u03b1} metrics, where the immersions contain sequences of catenoidal necks or floating disks.", "result": "Successfully constructed minimal immersions where the catenoidal necks or floating disks converge to isolated, multiplicity 2 singular flat points.", "conclusion": "The construction demonstrates the existence of minimal immersions with specific geometric features converging to singular points, contributing to understanding minimal surface behavior near singularities."}}
{"id": "2509.21608", "pdf": "https://arxiv.org/pdf/2509.21608", "abs": "https://arxiv.org/abs/2509.21608", "authors": ["Ioannis Gasteratos", "Alexandre Pannier"], "title": "Kolmogorov equations for stochastic Volterra processes with singular kernels", "categories": ["math.PR", "math.AP", "q-fin.MF", "60G22, 60H15, 60H20, 45D05, 35K10, 91G20"], "comment": null, "summary": "We associate backward and forward Kolmogorov equations to a class of fully\nnonlinear Stochastic Volterra Equations (SVEs) with convolution kernels $K$\nthat are singular at the origin. Working on a carefully chosen Hilbert space\n$\\mathcal{H}_1$, we rigorously establish a link between solutions of SVEs and\nMarkovian mild solutions of a Stochastic Partial Differential Equation (SPDE)\nof transport-type. Then, we obtain two novel It\\^o formulae for functionals of\nmild solutions and, as a byproduct, show that their laws solve corresponding\nFokker-Planck equations. Finally, we introduce a natural notion of \"singular\"\ndirectional derivatives along $K$ and prove that (conditional) expectations of\nSVE solutions can be expressed in terms of the unique solution to a backward\nKolmogorov equation on $\\mathcal{H}_1$. Our analysis relies on stochastic\ncalculus in Hilbert spaces, the reproducing kernel property of the state space\n$\\mathcal{H}_1,$ as well as crucial invariance and smoothing properties that\nare specific to the SPDEs of interest. In the special case of singular\npower-law kernels, our conditions guarantee well-posedness of the backward\nequation either for all values of the Hurst parameter $H,$ when the noise is\nadditive, or for all $H>1/4$ when the noise is multiplicative.", "AI": {"tldr": "The paper establishes connections between fully nonlinear Stochastic Volterra Equations (SVEs) with singular kernels and Markovian SPDEs, develops novel It\u00f4 formulas, and proves that SVE solutions solve Fokker-Planck equations.", "motivation": "To rigorously link solutions of SVEs with singular convolution kernels to Markovian SPDEs and develop stochastic calculus tools for analyzing their probabilistic properties.", "method": "Using stochastic calculus in Hilbert spaces, reproducing kernel properties, and establishing invariance/smoothing properties for transport-type SPDEs on a carefully chosen Hilbert space H\u2081.", "result": "Proved two novel It\u00f4 formulas, showed SVE solution laws solve Fokker-Planck equations, and established backward Kolmogorov equations for conditional expectations. For power-law kernels, obtained well-posedness for all H with additive noise and H>1/4 with multiplicative noise.", "conclusion": "The analysis provides a comprehensive framework connecting SVEs with singular kernels to Markovian SPDEs, enabling probabilistic analysis through backward/forward Kolmogorov equations and novel stochastic calculus tools."}}
{"id": "2509.21830", "pdf": "https://arxiv.org/pdf/2509.21830", "abs": "https://arxiv.org/abs/2509.21830", "authors": ["Weimin Sheng", "Ye Zhu"], "title": "Noncollapsing for Curvature Flows with Inhomogeneous Speeds", "categories": ["math.DG", "math.AP"], "comment": "19 pages", "summary": "We study closed, embedded hypersurfaces in Euclidean space evolving by fully\nnonlinear curvature flows, whose speed is given by a symmetric, monotone\nincreasing, $1$-homogeneous, positive underlying speed function $F$ composed\nwith a modulating function $\\Psi$. Under the assumption that $F$ is convex or\ninverse-concave and that $\\Psi$ satisfies the corresponding structural\nconditions, we establish exterior noncollapsing estimates for the flow. The\nmain difficulty stems from the nonlinearity of the evolution equation satisfied\nin the viscosity sense by the exscribed curvature, whereas in previous works it\nis a solution to the linearized flow. Moreover, in the case where $F$ is\ninverse-concave, we refine Andrews and Langford's argument for the interior\ncase.", "AI": {"tldr": "The paper establishes exterior noncollapsing estimates for fully nonlinear curvature flows of hypersurfaces in Euclidean space, addressing the challenge of nonlinear evolution equations for exscribed curvature.", "motivation": "To extend noncollapsing estimates to fully nonlinear curvature flows where the speed function is nonlinear, unlike previous linearized approaches, and to refine interior estimates for inverse-concave speed functions.", "method": "The authors study hypersurfaces evolving by symmetric, monotone increasing, 1-homogeneous, positive speed functions F composed with modulating functions \u03a8. They assume F is convex or inverse-concave and \u03a8 satisfies corresponding structural conditions.", "result": "Exterior noncollapsing estimates are established for the flow, overcoming the difficulty of nonlinear evolution equations for exscribed curvature. For inverse-concave F, interior estimates are refined using Andrews and Langford's argument.", "conclusion": "The paper successfully extends noncollapsing theory to fully nonlinear curvature flows and provides refined interior estimates for inverse-concave speed functions, advancing the understanding of geometric evolution equations."}}
{"id": "2509.22238", "pdf": "https://arxiv.org/pdf/2509.22238", "abs": "https://arxiv.org/abs/2509.22238", "authors": ["Dmitriy Dmitrishin", "Alexander Stokolos", "Walter Trebels"], "title": "Extremal polynomials for the Rogosinski--Szeg\u0151 estimates of the third coefficient of nonnegative sine polynomials", "categories": ["math.CV", "math.AP", "42A05"], "comment": null, "summary": "In the class of normalized sine-polynomials $S(t),$ non-negative on\n$[0,\\pi],$ W.Rogosinski and G.Szeg\\H{o} 1950 considered a number of extremal\nproblems and proved, among other things, sharp upper and lower estimates for\nthe coefficient $a_3.$ Their proof is based on the Luk\\'acs representation of\nnon-negative algebraic polynomials. This method does not lead to the\nconstruction of polynomials attaining the extreme values.\n  We consider the corresponding problem in the framework of normalized\ntypically real polynomials $P(z)$ on the unit disc in $\\mathbb C.$ By\nL.Fej\\'er's method with the additional use of the Chebyshev polynomials of the\nsecond kind and their derivatives, we regain the sharp upper and lower\nestimates for $a_3$ and identify the extremal polynomials. The corresponding\nstatements for sine polynomials follow by the observation\n$S(t)=\\text{Im}\\{P(e^{it})\\}$. For odd $N$ the extremizers are unique, for even\n$N$ there is a one-parameter family of extremizers.", "AI": {"tldr": "Sharp upper and lower bounds for coefficient a\u2083 in normalized sine-polynomials and typically real polynomials, with identification of extremal polynomials.", "motivation": "Previous work by Rogosinski and Szeg\u0151 provided bounds for a\u2083 but couldn't construct the extremal polynomials. This paper aims to find these extremal polynomials.", "method": "Uses Fej\u00e9r's method with Chebyshev polynomials of the second kind and their derivatives, working in the framework of normalized typically real polynomials on the unit disc.", "result": "Regained sharp upper and lower estimates for a\u2083 and identified extremal polynomials. For odd N, extremizers are unique; for even N, there's a one-parameter family.", "conclusion": "Successfully constructed the extremal polynomials that attain the bounds for coefficient a\u2083, solving the problem left open by previous research."}}
{"id": "2509.22494", "pdf": "https://arxiv.org/pdf/2509.22494", "abs": "https://arxiv.org/abs/2509.22494", "authors": ["Brendan Pass", "Yair Shenfeld"], "title": "A dynamical formulation of multi-marginal optimal transport", "categories": ["math.OC", "math.AP", "math.PR", "49Q22, 35F21, 49N15, 90C46"], "comment": null, "summary": "We present a primal-dual dynamical formulation of the multi-marginal optimal\ntransport problem for (semi-)convex cost functions. Even in the two-marginal\nsetting, this formulation applies to cost functions not covered by the\nclassical dynamical approach of Benamou-Brenier. Our dynamical formulation\nyields a convex optimization problem, enabling the use of convex optimization\ntools to find quasi-Monge solutions of the static multi-marginal problem for\ntranslation-invariant costs. We illustrate our results numerically with\nproximal splitting methods.", "AI": {"tldr": "A primal-dual dynamical formulation for multi-marginal optimal transport with (semi-)convex costs, extending beyond classical approaches and enabling convex optimization methods.", "motivation": "To address limitations of classical dynamical approaches like Benamou-Brenier, which don't cover certain cost functions in multi-marginal optimal transport problems.", "method": "Developed a primal-dual dynamical formulation that yields a convex optimization problem, allowing use of convex optimization tools and proximal splitting methods.", "result": "The formulation applies to cost functions not covered by classical approaches and enables finding quasi-Monge solutions for translation-invariant costs.", "conclusion": "The proposed dynamical formulation provides a convex optimization framework for multi-marginal optimal transport, extending applicability beyond classical methods and demonstrating practical utility through numerical implementation."}}
