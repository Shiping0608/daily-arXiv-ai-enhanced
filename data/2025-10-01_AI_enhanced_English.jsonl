{"id": "2509.25262", "pdf": "https://arxiv.org/pdf/2509.25262", "abs": "https://arxiv.org/abs/2509.25262", "authors": ["Chuandong Li", "Runtian Zeng"], "title": "AW-EL-PINNs: A Multi-Task Learning Physics-Informed Neural Network for Euler-Lagrange Systems in Optimal Control Problems", "categories": ["math.NA", "cs.NA", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper presents adaptive weighted Euler-Lagrange theorem combined\nphysics-informed neural networks (AW-EL-PINNs) for solving Euler-Lagrange\nsystems in optimal control problems. The framework systematically converts\noptimal control frameworks into two-point boundary value problems (TPBVPs)\nwhile establishing a multi-task learning paradigm through innovative\nintegration of the Euler-Lagrange theorem with deep learning architecture. An\nadaptive loss weighting mechanism dynamically balances loss function components\nduring training, decreasing tedious manual tuning of weighting the loss\nfunctions compared to the conventional physics-informed neural networks\n(PINNs). Based on six numerical examples, it's clear that AW-EL-PINNs achieve\nenhanced solution accuracy compared to baseline methods while maintaining\nstability throughout the optimization process. These results highlight the\nframework's capability to improve precision and ensure stability in solving\nEuler-Lagrange systems in optimal control problems, offering potential\nstrategies for problems under physical applications.", "AI": {"tldr": "AW-EL-PINNs combine Euler-Lagrange theorem with physics-informed neural networks to solve optimal control problems, using adaptive loss weighting to improve accuracy and stability.", "motivation": "To address the tedious manual tuning of loss function weights in conventional PINNs and improve solution accuracy for Euler-Lagrange systems in optimal control problems.", "method": "Systematically converts optimal control problems into two-point boundary value problems, integrates Euler-Lagrange theorem with deep learning architecture, and uses adaptive loss weighting mechanism to dynamically balance loss components during training.", "result": "Achieves enhanced solution accuracy compared to baseline methods while maintaining stability throughout optimization, as demonstrated in six numerical examples.", "conclusion": "The framework improves precision and ensures stability in solving Euler-Lagrange systems, offering potential strategies for physical applications in optimal control problems."}}
{"id": "2509.25354", "pdf": "https://arxiv.org/pdf/2509.25354", "abs": "https://arxiv.org/abs/2509.25354", "authors": ["Asad Freihet", "Mohammed Alabedalhadi"], "title": "The Asad Correctional Power Series Method: A Novel Approach to Solving Fractional Differential Equations", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper introduces the Asad Correctional Power Series Method (ACPS), a\nnovel and groundbreaking approach designed to simplify and optimize the\nsolution of fractional differential equations. The ACPS combines algebraic\nmanipulation with iterative refinement to achieve greater accuracy and\ncomputational efficiency than mainstream methods. By incorporating principles\nfrom both fractional calculus and functional analysis, the method offers a\nflexible framework capable of addressing a wide range of fractional equations,\nfrom linear to highly nonlinear cases. Additionally, a representative\ncounterexample is provided to indicate that the conformable fractional\nderivative does not fulfill the mathematical criteria for a valid definition of\nfractional differentiation. The Asad Correctional Power Series (ACPS) method is\nemployed to construct an analytic solution of the fractional SIR model in the\nform of a rapidly convergent power series. Its performance is validated through\ncomparisons with the classical fourth-order Runge Kutta method, where both\nnumerical and graphical analyses corroborate the method's precision and\nefficiency. The application of ACPS to the fractional epidemic model highlights\nits ability to capture memory and hereditary effects, offering more realistic\ninsights into disease transmission dynamics than integer-order models. These\nfindings demonstrate that ACPS can serve as a useful tool for solving\nfractional differential equations arising in real world applications", "AI": {"tldr": "The paper introduces ACPS method for solving fractional differential equations, showing it's more accurate and efficient than existing methods like Runge-Kutta, with applications to epidemic modeling.", "motivation": "To develop a more accurate and computationally efficient method for solving fractional differential equations, particularly for capturing memory effects in real-world applications like epidemic modeling.", "method": "ACPS combines algebraic manipulation with iterative refinement, incorporating principles from fractional calculus and functional analysis to handle linear to highly nonlinear fractional equations.", "result": "ACPS demonstrated superior performance compared to classical Runge-Kutta method, validated through numerical and graphical analysis. Successfully applied to fractional SIR epidemic model, capturing memory effects better than integer-order models.", "conclusion": "ACPS is a useful tool for solving fractional differential equations in real-world applications, offering improved accuracy and efficiency while better capturing hereditary effects in systems like disease transmission."}}
{"id": "2509.25753", "pdf": "https://arxiv.org/pdf/2509.25753", "abs": "https://arxiv.org/abs/2509.25753", "authors": ["Alexander D. Gilbert", "Frances Y. Kuo", "Dirk Nuyens", "Graham Pash", "Ian H. Sloan", "Karen E. Willcox"], "title": "Quasi-Monte Carlo methods for uncertainty quantification of tumor growth modeled by a parametric semi-linear parabolic reaction-diffusion equation", "categories": ["math.NA", "cs.CE", "cs.NA", "stat.CO", "65D30, 65D32, 92B05, 92C50, 35K58"], "comment": null, "summary": "We study the application of a quasi-Monte Carlo (QMC) method to a class of\nsemi-linear parabolic reaction-diffusion partial differential equations used to\nmodel tumor growth. Mathematical models of tumor growth are largely\nphenomenological in nature, capturing infiltration of the tumor into\nsurrounding healthy tissue, proliferation of the existing tumor, and patient\nresponse to therapies, such as chemotherapy and radiotherapy. Considerable\ninter-patient variability, inherent heterogeneity of the disease, sparse and\nnoisy data collection, and model inadequacy all contribute to significant\nuncertainty in the model parameters. It is crucial that these uncertainties can\nbe efficiently propagated through the model to compute quantities of interest\n(QoIs), which in turn may be used to inform clinical decisions. We show that\nQMC methods can be successful in computing expectations of meaningful QoIs.\nWell-posedness results are developed for the model and used to show a\ntheoretical error bound for the case of uniform random fields. The theoretical\nlinear error rate, which is superior to that of standard Monte Carlo, is\nverified numerically. Encouraging computational results are also provided for\nlognormal random fields, prompting further theoretical development.", "AI": {"tldr": "Application of quasi-Monte Carlo methods to efficiently propagate parameter uncertainties in tumor growth models for computing clinically relevant quantities of interest.", "motivation": "Tumor growth models have significant parameter uncertainties due to inter-patient variability, disease heterogeneity, sparse data, and model inadequacy. These uncertainties need efficient propagation through models to inform clinical decisions.", "method": "Use quasi-Monte Carlo (QMC) methods for uncertainty propagation in semi-linear parabolic reaction-diffusion PDEs modeling tumor growth. Theoretical analysis includes well-posedness results and error bounds for uniform random fields.", "result": "QMC methods successfully compute expectations of meaningful quantities of interest. Theoretical linear error rate superior to standard Monte Carlo is verified numerically. Promising results for lognormal random fields suggest further theoretical development.", "conclusion": "QMC methods are effective for uncertainty quantification in tumor growth models, providing superior error rates compared to standard Monte Carlo methods, with potential for clinical decision support."}}
{"id": "2509.25799", "pdf": "https://arxiv.org/pdf/2509.25799", "abs": "https://arxiv.org/abs/2509.25799", "authors": ["Wei Liu", "Jie Xu"], "title": "Numerical approximations to invariant measures of hybrid stochastic differential equations with superlinear coefficients via the backward Euler-Maruyama method", "categories": ["math.NA", "cs.NA", "math.PR", "65C30, 60H10"], "comment": "14 pages, 3 figures", "summary": "For stochastic stochastic differential equations with Markovian switching,\nwhose drift and diffusion coefficients are allowed to contain superlinear\nterms, the backward Euler-Maruyama (BEM) method is proposed to approximate the\ninvariant measure. The existence and uniqueness of the invariant measure of the\nnumerical solution generated by the BEM method is proved. Then the convergence\nof the numerical invariant measure to its underlying counterpart is shown. The\nresults obtained in this work release the requirement of the global Lipschitz\ncondition on the diffusion coefficient in [X. Li et al. SIAM J. Numer. Anal.\n56(3)(2018), pp. 1435-1455]. Numerical simulations are provided to demonstrate\nthose theoretical results.", "AI": {"tldr": "The paper proposes a backward Euler-Maruyama method for approximating invariant measures in stochastic differential equations with Markovian switching, relaxing the global Lipschitz condition requirement.", "motivation": "To address stochastic differential equations with Markovian switching that have superlinear drift and diffusion coefficients, where existing methods require global Lipschitz conditions on the diffusion coefficient.", "method": "Backward Euler-Maruyama (BEM) method is proposed for numerical approximation of invariant measures, with proofs of existence and uniqueness of numerical invariant measures.", "result": "The method successfully approximates invariant measures and converges to the underlying counterpart, while relaxing the global Lipschitz condition requirement from previous work.", "conclusion": "The BEM method provides an effective numerical approach for invariant measure approximation in stochastic systems with Markovian switching and superlinear coefficients, with theoretical convergence guarantees."}}
{"id": "2509.26269", "pdf": "https://arxiv.org/pdf/2509.26269", "abs": "https://arxiv.org/abs/2509.26269", "authors": ["Qichen Xu", "Anna Delin"], "title": "A general optimization framework for mapping local transition-state networks", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "cs.NE"], "comment": null, "summary": "Understanding how complex systems transition between states requires mapping\nthe energy landscape that governs these changes. Local transition-state\nnetworks reveal the barrier architecture that explains observed behaviour and\nenables mechanism-based prediction across computational chemistry, biology, and\nphysics, yet current practice either prescribes endpoints or randomly samples\nonly a few saddles around an initial guess. We present a general optimization\nframework that systematically expands local coverage by coupling a\nmulti-objective explorer with a bilayer minimum-mode kernel. The inner layer\nuses Hessian-vector products to recover the lowest-curvature subspace (smallest\nk eigenpairs), the outer layer optimizes on a reflected force to reach index-1\nsaddles, then a two-sided descent certifies connectivity. The GPU-based\npipeline is portable across autodiff backends and eigensolvers and, on large\natomistic-spin tests, matches explicit-Hessian accuracy while cutting peak\nmemory and wall time by orders of magnitude. Applied to a DFT-parameterized\nN\\'eel-type skyrmionic model, it recovers known routes and reveals previously\nunreported mechanisms, including meron-antimeron-mediated N\\'eel-type\nskyrmionic duplication, annihilation, and chiral-droplet formation, enabling up\nto 32 pathways between biskyrmion (Q=2) and biantiskyrmion (Q=-2). The same\ncore transfers to Cartesian atoms, automatically mapping canonical\nrearrangements of a Ni(111) heptamer, underscoring the framework's generality.", "AI": {"tldr": "A general optimization framework for systematically mapping energy landscapes and transition-state networks using multi-objective exploration with bilayer minimum-mode kernel, enabling efficient discovery of transition pathways in complex systems.", "motivation": "Current methods for understanding state transitions in complex systems either prescribe endpoints or randomly sample limited saddles, lacking systematic coverage of energy landscapes needed for mechanism-based prediction.", "method": "Uses a multi-objective explorer coupled with bilayer minimum-mode kernel: inner layer recovers lowest-curvature subspace via Hessian-vector products, outer layer optimizes on reflected force to reach index-1 saddles, with two-sided descent for connectivity certification. GPU-based pipeline works across autodiff backends.", "result": "On atomistic-spin tests, matches explicit-Hessian accuracy while reducing peak memory and wall time by orders of magnitude. Applied to skyrmionic model, recovers known routes and reveals new mechanisms including meron-antimeron-mediated processes. Same core transfers to Cartesian atoms, mapping Ni(111) heptamer rearrangements.", "conclusion": "The framework provides general, efficient approach for systematically expanding local coverage of energy landscapes, enabling discovery of previously unreported transition mechanisms across diverse physical systems."}}
{"id": "2509.25508", "pdf": "https://arxiv.org/pdf/2509.25508", "abs": "https://arxiv.org/abs/2509.25508", "authors": ["Fan Cheng", "Robert Lasarzik", "Marita Thomas"], "title": "Analysis of a Cahn--Hilliard model for viscoelastoplastic two-phase flows", "categories": ["math.AP", "35A15, 35A35, 35M86, 35Q86, 76Txx, 76M30"], "comment": "54 pages", "summary": "We study a Cahn--Hilliard two-phase model describing the flow of two\nviscoelastoplastic fluids, which arises in geodynamics. A phase-field variable\nindicates the proportional distribution of the two fluids in the mixture. The\nmotion of the incompressible mixture is described in terms of the\nvolume-averaged velocity. Besides a volume-averaged Stokes-like viscous\ncontribution, the Cauchy stress tensor in the momentum balance contains an\nadditional volume-averaged internal stress tensor to model the elastoplastic\nbehavior. This internal stress has its own evolution law featuring the\nnonlinear Zaremba-Jaumann time-derivative and the subdifferential of a\nnon-smooth plastic potential. The well-posedness of this system is studied in\ntwo cases: Based on a regularization by stress-diffusion we obtain the\nexistence of Leray-Hopf-type weak solutions. In order to deduce existence\nresults also in the absence of the regularization, we introduce the concept of\ndissipative solutions, which is based on an estimate for the relative energy.\n  We discuss general properties of dissipative solutions and show their\nexistence for the viscoelastoplastic two-phase model in the setting of\nstress-diffusion. By a limit passage in the relative energy inequality for\nvanishing stress-diffusion, we conclude an existence result for the\nnon-regularized model.", "AI": {"tldr": "This paper analyzes a Cahn-Hilliard two-phase model for viscoelastoplastic fluid flow in geodynamics, proving existence of weak solutions via stress-diffusion regularization and introducing dissipative solutions for the non-regularized case.", "motivation": "To study the well-posedness of a two-phase flow model for viscoelastoplastic fluids in geodynamics, addressing the mathematical challenges posed by the nonlinear Zaremba-Jaumann derivative and non-smooth plastic potential.", "method": "Two approaches: 1) Regularization via stress-diffusion to obtain Leray-Hopf-type weak solutions; 2) Introduction of dissipative solutions based on relative energy estimates, with limit passage for vanishing stress-diffusion.", "result": "Existence of Leray-Hopf-type weak solutions with stress-diffusion regularization, and existence of dissipative solutions for the non-regularized model via relative energy inequality limit passage.", "conclusion": "The paper establishes mathematical foundations for viscoelastoplastic two-phase flow models, providing existence results through both regularization and dissipative solution concepts."}}
{"id": "2509.25506", "pdf": "https://arxiv.org/pdf/2509.25506", "abs": "https://arxiv.org/abs/2509.25506", "authors": ["J. W. S. Cook", "H. Ali", "J. F. Parisi", "A. Diallo", "N. Faatz"], "title": "Persistence of Deuterium and Tritium Nuclear Spin-Polarization in Presence of High-Frequency Plasma Waves", "categories": ["physics.plasm-ph"], "comment": null, "summary": "We present first-principles numerical calculations of the depolarization rate\nof spin-polarized deuterium and tritium nuclei in realistic tokamak plasmas,\ndriven by resonant interactions with plasma waves. Backed up by first-of-a-kind\nlinear and nonlinear simulations, we find that alpha particle-driven Alfv\\'enic\nmodes cause only negligible depolarization, which is contrary to expectations\nin prior literature. Other Alfv\\'enic instabilities can in principle degrade\npolarization, but only under conditions unlikely to be realized on transport\ntimescales. By combining full-orbit particle tracing with a dedicated\ndepolarization solver, we demonstrate that wave-driven depolarization is\nsurprisingly weak in SPARC and ITER-scale devices. These results provide strong\nevidence that spin-polarized fuel can maintain its polarization long enough to\nboost fusion reactivity, opening a viable path toward substantially enhanced\nperformance in magnetic confinement fusion power plants.", "AI": {"tldr": "First-principles calculations show wave-driven depolarization of spin-polarized deuterium and tritium nuclei is surprisingly weak in tokamak plasmas, contrary to prior expectations, enabling polarization maintenance for enhanced fusion reactivity.", "motivation": "To investigate whether spin-polarized nuclear fuel can maintain its polarization in realistic tokamak plasmas long enough to boost fusion reactivity, addressing concerns about wave-driven depolarization that could undermine this performance enhancement approach.", "method": "Combined first-principles numerical calculations with linear and nonlinear simulations, using full-orbit particle tracing integrated with a dedicated depolarization solver to analyze resonant interactions between spin-polarized nuclei and plasma waves in realistic tokamak conditions.", "result": "Alpha particle-driven Alfv\u00e9nic modes cause negligible depolarization, contrary to prior literature expectations. Other Alfv\u00e9nic instabilities can degrade polarization but only under conditions unlikely to occur on transport timescales. Wave-driven depolarization is surprisingly weak in SPARC and ITER-scale devices.", "conclusion": "Spin-polarized fuel can maintain polarization long enough to significantly boost fusion reactivity, providing a viable path for enhanced performance in magnetic confinement fusion power plants."}}
{"id": "2509.25909", "pdf": "https://arxiv.org/pdf/2509.25909", "abs": "https://arxiv.org/abs/2509.25909", "authors": ["Andrea Scaglioni", "Michael Feischl", "Fernando Henr\u00edquez"], "title": "A Reduced Basis Method for the Stochastic Landau-Lifshitz-Gilbert Equation", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this work, we consider the construction of efficient surrogates for the\nstochastic version of the Landau-Lifshitz-Gilbert (LLG) equation using model\norder reduction techniques, in particular, the Reduced Basis (RB) method. The\nStochastic LLG (SLLG) equation is a widely used phenomenological model for the\ntime evolution of the magnetization field confined to a ferromagnetic body\nwhile taking into account the effect of random heat perturbations. This\nphenomenon is mathematically formulated as a nonlinear parabolic problem, where\nthe stochastic component is represented as a parameter-dependent datum\ndepending on a non-compact and high-dimensional parameter. In an\n$\\textit{offline}$ phase, we use Proper Orthogonal Decomposition (POD) on\nhigh-fidelity samples of the unbounded parameter space. To that end, we use the\nso-called $\\textit{tangent plane scheme}$. For the $\\textit{online}$ phase of\nthe RB method, we again employ the tangent plane scheme in the RB space. This\nis possible due to our particular construction that reduces both spaces of the\nmagnetization and of its time derivative. Due to the saddle-point nature of\nthis scheme, a stabilization that appropriately enriches the RB space is\nrequired. Numerical experiments show a clear advantage over earlier approaches\nusing sparse grid interpolation. In a complementary approach, we test a sparse\ngrid approximation of the reduced coefficients in a purely data-driven method,\nexhibiting the weaknesses of earlier sparse grid approaches, but benefiting\nfrom increased stability.", "AI": {"tldr": "This paper develops efficient surrogates for the Stochastic Landau-Lifshitz-Gilbert equation using Reduced Basis method with Proper Orthogonal Decomposition, employing a tangent plane scheme and stabilization techniques.", "motivation": "The Stochastic LLG equation models magnetization evolution in ferromagnetic bodies under random heat perturbations, but solving it directly is computationally expensive due to its nonlinear parabolic nature and high-dimensional parameter space.", "method": "Uses Reduced Basis method with Proper Orthogonal Decomposition on high-fidelity samples in offline phase, and tangent plane scheme in reduced space during online phase. Includes stabilization for saddle-point structure and compares with sparse grid interpolation approaches.", "result": "Numerical experiments show clear advantage over earlier sparse grid interpolation approaches. A complementary data-driven sparse grid approximation exhibits weaknesses but benefits from increased stability.", "conclusion": "The proposed RB method with POD and tangent plane scheme provides an efficient surrogate for SLLG equation, outperforming previous sparse grid methods while maintaining computational efficiency through proper space reduction and stabilization."}}
{"id": "2509.26304", "pdf": "https://arxiv.org/pdf/2509.26304", "abs": "https://arxiv.org/abs/2509.26304", "authors": ["Johan Helsing", "Anders Karlsson"], "title": "The uniqueness of inverse scattering problems, reciprocity principles, and nonradiating sources related to low-signature structures", "categories": ["physics.comp-ph", "78A50, 78M15, 65N38, 31A10"], "comment": "18 pages, 11 figures", "summary": "This paper is about perfectly electrically conducting structures designed to\nproduce negligible scattered power when exposed to a time-harmonic plane\nelectromagnetic wave. The structures feature cavities capable of concealing\nobjects. Theoretical investigations of the properties of the structures\ncombined with accurate numerical computations lead to three key findings: the\nfirst concerns the uniqueness of the solution to an inverse scattering problem,\nthe second establishes a reciprocity relation for the far-field scattering\namplitude, and the third reveals the existence of non-radiating sources that\ngenerate substantial electromagnetic fields near the source region. The results\nhave applications in low-observable technology.", "AI": {"tldr": "Perfectly conducting structures with cavities that produce negligible scattered power when exposed to electromagnetic waves, enabling object concealment.", "motivation": "To develop structures that can conceal objects by producing minimal scattered electromagnetic power, with applications in low-observable technology.", "method": "Theoretical investigation combined with accurate numerical computations of perfectly electrically conducting structures with cavities.", "result": "Three key findings: uniqueness of inverse scattering solution, reciprocity relation for far-field scattering amplitude, and existence of non-radiating sources generating strong near-field electromagnetic fields.", "conclusion": "The structures effectively conceal objects with minimal scattering, with important implications for low-observable applications."}}
{"id": "2509.25553", "pdf": "https://arxiv.org/pdf/2509.25553", "abs": "https://arxiv.org/abs/2509.25553", "authors": ["Maria Deliyianni", "Shankar C. Venkataramani"], "title": "Hyperbolic Monge-Amp\u00e8re Equation on a Cylinder: Well-Posedness and Stability", "categories": ["math.AP", "math-ph", "math.DG", "math.MP", "35L70, 53A05, 35L20, 45D05, 35Q74"], "comment": "43 pages, 2 figures", "summary": "This paper develops a rigorous analytic framework for the hyperbolic\nMonge-Amp\\`ere equation on strip-like domains, which model wrinkled patterns in\nthin elastic sheets. Our work addresses the rigid side of the classical\nrigidity-flexibility dichotomy by defining this regime not by high smoothness,\nbut by the more fundamental property of partial convexity. The hodograph\ntransformation is the natural tool for this setting, as its validity is\npredicated on partial convexity. It converts the nonlinear Monge-Amp\\`ere\nequation into a linear damped wave equation, allowing us to formulate a\nwell-posed Cauchy-Goursat problem. A key challenge is the corner singularity\nthat arises where characteristic and non-characteristic boundary data meet. To\nresolve this, we develop a parametrix-corrector decomposition that captures the\nsolution's inherent singular behavior. This method recasts the problem as a\nsingular Volterra integral equation, for which we prove the existence and\nuniqueness of a new class of hodograph weak solutions. Finally, we derive\nenergy estimates to establish the quantitative stability of these rigid\nsolutions under perturbations of the underlying curvature function.", "AI": {"tldr": "Develops analytic framework for hyperbolic Monge-Amp\u00e8re equation on strip domains modeling elastic wrinkles, using hodograph transformation to convert nonlinear PDE to linear wave equation, resolving corner singularities via parametrix-corrector decomposition.", "motivation": "Address the rigidity side of rigidity-flexibility dichotomy in thin elastic sheets by defining rigidity through partial convexity rather than high smoothness, providing fundamental understanding of wrinkled patterns.", "method": "Use hodograph transformation to convert nonlinear Monge-Amp\u00e8re equation to linear damped wave equation, formulate Cauchy-Goursat problem, develop parametrix-corrector decomposition to handle corner singularities, and recast as singular Volterra integral equation.", "result": "Prove existence and uniqueness of new class of hodograph weak solutions, establish well-posedness of Cauchy-Goursat problem, and derive energy estimates showing quantitative stability under curvature perturbations.", "conclusion": "Provides rigorous analytic framework for hyperbolic Monge-Amp\u00e8re equation with corner singularities, establishing new solution class with proven stability properties, advancing understanding of rigid patterns in elastic sheets."}}
{"id": "2509.26357", "pdf": "https://arxiv.org/pdf/2509.26357", "abs": "https://arxiv.org/abs/2509.26357", "authors": ["Ruben Otin", "Ying Hao Matthew Liang", "Thomas Wilson", "Simon Freethy", "Valerian Hall-Chen"], "title": "Validation of ERMES 20.0 finite element code for MAST Upgrade O-X mode conversion", "categories": ["physics.plasm-ph"], "comment": null, "summary": "This study presents the validation of the frequency-domain finite element\ncode ERMES 20.0, benchmarked against Finite Difference Time Domain (FDTD)\nsolvers. The simulations focus on Ordinary-Extraordinary (O-X) mode conversion\nin the Electron Bernstein Wave (EBW) regime of the MAST Upgrade experiment.\nValidation is performed in terms of mode conversion efficiency and wave\npropagation characteristics. Several finite element formulations are tested and\ncompared with the FDTD results. The simulations demonstrate excellent agreement\nbetween the different approaches, confirming the accuracy and robustness of\nERMES 20.0 for modeling cold plasma wave interactions.", "AI": {"tldr": "Validation of ERMES 20.0 finite element code against FDTD solvers for O-X mode conversion in EBW regime shows excellent agreement.", "motivation": "To validate the accuracy and robustness of the frequency-domain finite element code ERMES 20.0 for modeling cold plasma wave interactions.", "method": "Benchmarked ERMES 20.0 against Finite Difference Time Domain (FDTD) solvers, focusing on Ordinary-Extraordinary (O-X) mode conversion in Electron Bernstein Wave regime. Tested several finite element formulations.", "result": "Simulations demonstrated excellent agreement between ERMES 20.0 and FDTD approaches in terms of mode conversion efficiency and wave propagation characteristics.", "conclusion": "ERMES 20.0 is confirmed as accurate and robust for modeling cold plasma wave interactions, validated through comparison with established FDTD methods."}}
{"id": "2509.25942", "pdf": "https://arxiv.org/pdf/2509.25942", "abs": "https://arxiv.org/abs/2509.25942", "authors": ["Zhen-Chen Guo", "Xin Liang"], "title": "Flexible fixed-point iteration and its applications for nonsymmetric algebraic Riccati equations", "categories": ["math.NA", "cs.NA", "65F45, 15A24, 49N10, 93B52"], "comment": "21 pages, 1 figure", "summary": "In this paper, we reveal the intrinsic Toeplitz structure in the unique\nstabilizing solution for nonsymmetric algebraic Riccati equations by employing\na shift-involved fixed-point iteration, and propose an RADI-type method for\ncomputing this solution for large-scale equations of this type with sparse and\nlow-rank structure by incorporating flexible shifts into the fixed-point\niteration. We present a shift-selection strategy, termed Leja shifts, based on\nrational approximation theory, which is incorporated into the RADI-type method.\nWe further discuss important implementation aspects for the method, such as\nlow-rank factorization of residuals, implicit update of large-scale sparse\nmatrices, real arithmetics with complex shifts, and related equations of other\ntype.\n  Numerical experiments demonstrate the efficiency of both the proposed method\nand the introduced shift-selection strategy.", "AI": {"tldr": "The paper reveals the Toeplitz structure in nonsymmetric algebraic Riccati equations and proposes a RADI-type method with Leja shifts for efficient large-scale computation.", "motivation": "To address the computational challenges of solving large-scale nonsymmetric algebraic Riccati equations with sparse and low-rank structure by leveraging their intrinsic mathematical properties.", "method": "Uses shift-involved fixed-point iteration and proposes a RADI-type method incorporating flexible Leja shifts based on rational approximation theory, with implementations for low-rank factorization, implicit matrix updates, and complex shift handling.", "result": "Numerical experiments demonstrate the efficiency of both the proposed RADI-type method and the Leja shift-selection strategy.", "conclusion": "The method successfully computes stabilizing solutions for large-scale nonsymmetric algebraic Riccati equations by exploiting their Toeplitz structure and using advanced shift strategies."}}
{"id": "2509.26309", "pdf": "https://arxiv.org/pdf/2509.26309", "abs": "https://arxiv.org/abs/2509.26309", "authors": ["Yunhai Li", "Zewen Wu", "Miao Zhang", "Junyi Wang", "Shengjun Yuan"], "title": "TBPLaS 2.0: a Tight-Binding Package for Large-scale Simulation", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci"], "comment": null, "summary": "We introduce version 2.0 of TBPLaS, a package for large-scale simulation\nbased on the tight-binding propagation method (TBPM). This new version brings\nsignificant improvements with many new features. Existing Python/Cython\nmodeling tools have been thoroughly optimized, and a compatible C++\nimplementation of the modeling tools is now available, offering efficiency\nenhancement of several orders. The solvers have been rewritten in C++ from\nscratch, with the efficiency enhanced by several times or even by an order. The\nworkflow of utilizing solvers has also been unified into a more comprehensive\nand consistent manner. New features include spin texture, Berry curvature and\nChern number calculation, search of eigenvalues within a specific energy range,\nanalytical Hamiltonian, and GPU computing support. The documentation and\ntutorials have also been updated to the new version. In this paper, we discuss\nthe revisions with respect to version 1.3 and demonstrate the new features.\nBenchmarks on modeling tools and solvers are also provided.", "AI": {"tldr": "TBPLaS 2.0 introduces major upgrades including C++ implementation, GPU support, new physics features, and significant performance improvements over version 1.3.", "motivation": "To enhance the efficiency and capabilities of large-scale tight-binding simulations by providing optimized implementations and new computational features.", "method": "Rewrote solvers in C++ from scratch, added C++ modeling tools, implemented GPU computing support, and introduced new physics features like spin texture and Berry curvature calculations.", "result": "Achieved efficiency improvements of several orders for modeling tools and several times to an order for solvers, with unified workflow and comprehensive new features.", "conclusion": "TBPLaS 2.0 represents a significant advancement in large-scale tight-binding simulations with enhanced performance, new capabilities, and improved user experience."}}
{"id": "2509.25581", "pdf": "https://arxiv.org/pdf/2509.25581", "abs": "https://arxiv.org/abs/2509.25581", "authors": ["Eduardo Colorado", "Giovanni Monica Bisci", "Alejandro Ortega", "Luca Vilasi"], "title": "Nonlocal critical problems with mixed boundary conditions and nearly resonant perturbations", "categories": ["math.AP", "Primary: 35R11, 35A15, 35S15, 49J35, Secondary: 35J61, 35B33, 58E05"], "comment": "18 pages", "summary": "We consider the following nonlocal critical problem with mixed\nDirichlet-Neumann boundary conditions, \\begin{equation} \\left\\{\n  \\begin{array}{ll}\n  (-\\Delta)^su=\\lambda u+|u|^{2_s^*-2}u &\\text{in}\\ \\Omega,\\\\ \\mkern+38.5mu\nu=0& \\text{on}\\ \\Sigma_{\\mathcal{D}},\\\\ \\mkern+24mu \\displaystyle\n\\frac{\\partial u}{\\partial \\nu}=0 &\\text{on}\\ \\Sigma_{\\mathcal{N}},\n  \\end{array}\n  \\right. \\end{equation} where $(-\\Delta)^s$, $s\\in (1/2,1)$, is the spectral\nfractional Laplacian operator, $\\Omega\\subset\\mathbb{R}^N$, $N>2s$, is a smooth\nbounded domain, $2_s^*=\\frac{2N}{N-2s}$ denotes the critical fractional Sobolev\nexponent, $\\lambda>0$ is a real parameter, $\\nu$ is the outwards normal to\n$\\partial\\Omega$, $\\Sigma_{\\mathcal{D}}$, $\\Sigma_{\\mathcal{N}}$ are smooth\n$(N-1)$--dimensional submanifolds of $\\partial\\Omega$ such that\n$\\Sigma_{\\mathcal{D}}\\cup\\Sigma_{\\mathcal{N}}=\\partial\\Omega$,\n$\\Sigma_{\\mathcal{D}}\\cap\\Sigma_{\\mathcal{N}}=\\emptyset$ and\n$\\Sigma_{\\mathcal{D}}\\cap\\overline{\\Sigma}_{\\mathcal{N}}=\\Gamma$ is a smooth\n$(N-2)$--dimensional submanifold of $\\partial\\Omega$. By employing both a\n$\\nabla$-theorem combined with a linking-type theorem, we prove the existence\nof multiple solutions when the parameter $\\lambda$ is in a left neighborhood of\na given eigenvalue of $(-\\Delta)^s$.", "AI": {"tldr": "Existence of multiple solutions for a nonlocal critical problem with mixed Dirichlet-Neumann boundary conditions using spectral fractional Laplacian operator and variational methods.", "motivation": "To study the existence of multiple solutions for critical fractional Sobolev problems with mixed boundary conditions, which combines nonlocal operators with complex boundary behavior.", "method": "Employed a \u2207-theorem combined with a linking-type theorem to prove existence of multiple solutions when parameter \u03bb is near eigenvalues of the spectral fractional Laplacian.", "result": "Proved the existence of multiple solutions for the critical nonlocal problem with mixed Dirichlet-Neumann boundary conditions when \u03bb is in a left neighborhood of eigenvalues.", "conclusion": "The combination of \u2207-theorem and linking-type methods successfully establishes multiplicity results for critical fractional problems with mixed boundary conditions."}}
{"id": "2509.25870", "pdf": "https://arxiv.org/pdf/2509.25870", "abs": "https://arxiv.org/abs/2509.25870", "authors": ["Rui-Qi Qin", "Peng-Pei Xie", "Yan-Fei Li", "Xian-Zhang Wu", "Zheng-Yang Zuo", "Bing-Jun Li", "Jun Liu", "Liang-Liang Ji", "Yu-Tong Li"], "title": "All-Optical Generation of Dense, Multi-GeV, Longitudinally-Polarized Positron Beams", "categories": ["physics.acc-ph", "physics.plasm-ph"], "comment": null, "summary": "The production of high-yield, longitudinally polarized positron beams\nrepresents an outstanding challenge in advanced accelerator science.\nLaser-driven schemes offer a compact alternative but typically yield only\ntransverse polarization, or require pre-polarized electron beams, and struggle\nto efficiently accelerate positrons to high energies. Here, we introduce an\nall-optical scheme that overcomes these limitations by integrating positron\ngeneration, acceleration, and spin manipulation in a unified framework. Through\na head-on collision between an ultraintense, circularly polarized laser pulse\nand a counterpropagating unpolarized electron beam, we drive a robust QED\ncascade. The nonlinear Breit-Wheeler process within the cascade produces\npositrons that are born directly within the strong laser field. Crucially,\nthese positrons are instantaneously captured and accelerated to multi-GeV\nenergies (up to $\\sim$9 GeV) via a direct laser acceleration mechanism, while\ntheir spins are simultaneously rotated to longitudinal alignment by the field\ndynamics. Our Monte-Carlo simulations confirm the simultaneous achievement of a\nhigh positron yield ($\\sim$20 $e^+/e^-$), a high average longitudinal\npolarization ($\\sim$50\\%), and GeV-scale energies. This all-optical source,\nfeasible at upcoming ultraintense laser facilities, presents a compact and\nefficient solution for applications in collider physics and fundamental\nhigh-energy experiments.", "AI": {"tldr": "An all-optical scheme for producing high-yield, longitudinally polarized positron beams using laser-driven QED cascades that simultaneously generates, accelerates, and spin-polarizes positrons to multi-GeV energies.", "motivation": "Current laser-driven positron beam schemes typically yield only transverse polarization, require pre-polarized electron beams, and struggle to efficiently accelerate positrons to high energies, creating a need for more compact and efficient solutions.", "method": "Head-on collision between an ultraintense circularly polarized laser pulse and counterpropagating unpolarized electron beam drives a QED cascade where positrons are generated via nonlinear Breit-Wheeler process, then instantly captured and accelerated via direct laser acceleration while their spins are rotated to longitudinal alignment by field dynamics.", "result": "Monte-Carlo simulations confirm simultaneous achievement of high positron yield (~20 e+/e-), high average longitudinal polarization (~50%), and GeV-scale energies (up to ~9 GeV).", "conclusion": "This all-optical source provides a compact and efficient solution for collider physics and fundamental high-energy experiments, feasible at upcoming ultraintense laser facilities."}}
{"id": "2509.25967", "pdf": "https://arxiv.org/pdf/2509.25967", "abs": "https://arxiv.org/abs/2509.25967", "authors": ["R\u00e9mi Abgrall", "Pierre-Henri Maire", "Mario Ricchiuto"], "title": "Embedding General Conservation Constraints in Discretizations of Hyperbolic Systems on Arbitrary Meshes: A Multidimensional Framework", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "The purpose of this review is to discuss the notion of conservation in\nhyperbolic systems and how one can formulate it at the discrete level depending\non the solution representation of the solution. A general theory is difficult.\nWe discuss several possibilities: if the solution is represented by average in\nvolumes; if the mesh is staggerred; if the solution is solely represented by\npoint values and an example where all the previous options are mixed.\n  We show how each configuration can provide, or not, enough flexibility. The\ndiscussion could be adapted to any hyperbolic system endowed with an entropy,\nbut we focus on compressible fluid mechanics, in its Eulerian and Lagrangian\nformulations. The unifying element is that we systematically express the update\nof conserved variables as $u^{n+1}=u^n- \\Delta t\\; \\delta u$, where the\nfunctional $\\delta u$ depends on the value of $u$ in the stencil of the scheme.\nThen, one can naturally define a graph connecting the states defining $\\delta\nu$. The notion of local conservation can be defined from this graph. We are\naware of only two possible situations: either the graph is constructed from the\nfaces of the mesh elements (or the dual mesh), or it is defined from the mesh\nitself. Two notions of local conservation then emerge: either we define a\nnumerical flux, or we define a \"residual\" attached to elements and the degrees\nof freedom within the element. We show that this two notions are in a way\nequivalent, but the one with residual allows much more flexibility, especially\nif additional algebraic constraints must be satisfied. Examples of specific\nadditional conservation constraints are provided to illustrate this. We also\nshow that this notion of conservation gives a very clear framework for the\ndesign of scheme in the Lagrangian framework. We end by providing a number of\nongoing research questions, and highlight some open questions.", "AI": {"tldr": "This paper reviews conservation formulations in hyperbolic systems at discrete levels, focusing on different solution representations and mesh types. It introduces a unified framework using graph theory to define local conservation through numerical fluxes or residuals.", "motivation": "To establish a systematic framework for defining conservation in discrete hyperbolic systems, addressing the challenge of formulating conservation principles across different solution representations and mesh configurations.", "method": "The authors propose a unified approach where conserved variable updates are expressed as u^{n+1}=u^n-\u0394t \u03b4u, with \u03b4u depending on the scheme's stencil. They define conservation using graph theory - either through mesh faces (numerical fluxes) or mesh elements (residuals).", "result": "The paper demonstrates that both numerical flux and residual-based approaches are equivalent, but the residual method offers more flexibility, especially for satisfying additional algebraic constraints. The framework provides clear guidance for scheme design in Lagrangian formulations.", "conclusion": "The residual-based conservation definition provides superior flexibility compared to flux-based approaches, particularly for complex constraints. The framework offers a unified perspective for conservation in discrete hyperbolic systems, with ongoing research questions identified."}}
{"id": "2509.26408", "pdf": "https://arxiv.org/pdf/2509.26408", "abs": "https://arxiv.org/abs/2509.26408", "authors": ["Aigbe Awenlimobor", "Jiajun Xu"], "title": "Method for backtracking the layer thermal conductivities of multilayer thin film structure using coupled Newton Raphson approach and 3-omega approach", "categories": ["physics.comp-ph"], "comment": null, "summary": "The thermal conductivity of thin films is commonly estimated using the\n3-omega experimental method. When calibrating the test setup, it is customary\nto use a specimen with a known thermal conductivity for validation. However,\nwhen determining the thermal conductivity of samples with unknown values,\nnumerical approximations can provide a means to validate experimental results\nand ensure the integrity of the setup. A simple analytical or finite element\nanalysis (FEA) method can be used to achieve this. For multilayer systems of\nunknown layer thermal conductivities, the 3-omega experimental setup only\nprovides information about the overall bulk thermal conductivity of the system.\nTo obtain the individual layer thermal conductivities, a combined experimental\nand numerical approach can be used. This article presents a novel method for\nbacktracking the layer thermal conductivities of a multilayer thin film\nstructure using a coupled 3-omega experimental and Newton-Raphson numerical\napproach. The method is validated using high-fidelity data obtained from\nliterature.", "AI": {"tldr": "A novel method combining 3-omega experiments with Newton-Raphson numerical approach to determine individual layer thermal conductivities in multilayer thin films.", "motivation": "Standard 3-omega method only provides bulk thermal conductivity for multilayer systems, making it impossible to determine individual layer properties without additional approaches.", "method": "Coupled 3-omega experimental setup with Newton-Raphson numerical optimization to backtrack individual layer thermal conductivities in multilayer thin films.", "result": "The method successfully determines individual layer thermal conductivities and is validated using high-fidelity literature data.", "conclusion": "The combined experimental-numerical approach provides an effective solution for obtaining individual layer thermal properties in multilayer systems where standard methods only yield bulk values."}}
{"id": "2509.25650", "pdf": "https://arxiv.org/pdf/2509.25650", "abs": "https://arxiv.org/abs/2509.25650", "authors": ["Dirk Hennig", "Nikos I. Karachalios", "Dionyssios Mantzavinos", "Dimitrios Mitsotakis"], "title": "Discrete Nonlinear Schr\u00f6dinger versus Ablowitz-Ladik: Existence and dynamics of generalized NLS-type lattices over a nonzero background", "categories": ["math.AP", "nlin.SI", "37K60, 35Q55, 37K40, 35B35"], "comment": "37 pages, 15 figures, 2 tables", "summary": "The question of well-posedness of the generalized Ablowitz-Ladik and Discrete\nNonlinear Schr\\\"{o}dinger equations with \\textit{nonzero} boundary conditions\non the infinite lattice is far less understood than in the case where the\nmodels are supplemented with vanishing boundary conditions. This question\nremains largely unexplored even in the standard case of cubic nonlinearities in\nwhich, in particular, the Ablowitz-Ladik equation is completely integrable\nwhile the Discrete Nonlinear Schr\\\"{o}dinger equation is not (in contrast with\nits continuous counterpart). We establish local well-posedness for both of\nthese generalized nonlinear systems supplemented with a broad class of nonzero\nboundary conditions and, in addition, derive analytical upper bounds for the\nminimal guaranteed lifespan of their solutions. These bounds depend explicitly\non the norm of the initial data, the background, and the nonlinearity\nexponents. In particular, they suggest the possibility of finite-time collapse\n(blow-up) of solutions. Furthermore, by comparing models with different\nnonlinearity exponents, we prove estimates for the distance between their\nrespective solutions (measured in suitable metrics), valid up to their common\nminimal guaranteed lifespan. Highly accurate numerical studies illustrate that\nsolutions of the generalized Ablowitz-Ladik equation may collapse in finite\ntime. Importantly, the numerically observed blow-up time is in excellent\nagreement with the theoretically predicted order of the minimal guaranteed\nlifespan. Furthermore, in the case of the Discrete Nonlinear Schr\\\"odinger\nequation on a finite lattice we prove global existence of solutions; this is\nconsistent with our numerical observations of the phenomenon of\n\\textit{quasi-collapse}, manifested by narrow oscillatory spikes that\nnevertheless persist throughout time -- continued in pdf ...", "AI": {"tldr": "The paper establishes local well-posedness for generalized Ablowitz-Ladik and Discrete Nonlinear Schr\u00f6dinger equations with nonzero boundary conditions, derives lifespan bounds, and shows potential for finite-time blow-up through theoretical analysis and numerical verification.", "motivation": "To address the poorly understood well-posedness of generalized Ablowitz-Ladik and Discrete Nonlinear Schr\u00f6dinger equations with nonzero boundary conditions on infinite lattices, which remains largely unexplored compared to vanishing boundary conditions.", "method": "Theoretical analysis establishing local well-posedness, deriving analytical upper bounds for minimal guaranteed lifespan, proving distance estimates between solutions of different models, and conducting highly accurate numerical studies to verify theoretical predictions.", "result": "Proved local well-posedness for both systems with nonzero boundary conditions, derived explicit lifespan bounds suggesting finite-time collapse, and numerically confirmed blow-up in Ablowitz-Ladik equation with excellent agreement between observed and predicted blow-up times.", "conclusion": "The analysis reveals fundamental differences between the two models: Ablowitz-Ladik equation exhibits finite-time blow-up while Discrete Nonlinear Schr\u00f6dinger equation shows global existence on finite lattices with quasi-collapse behavior manifested as persistent narrow oscillatory spikes."}}
{"id": "2509.26174", "pdf": "https://arxiv.org/pdf/2509.26174", "abs": "https://arxiv.org/abs/2509.26174", "authors": ["R\u00e9mi Delaporte-Mathurin", "Nikola Goles", "Collin Dunn", "Emily Edwards", "Sara Ferry", "Ross MacDonald", "Ethan Peterson", "Davide Pettinari", "Stefano Segantin", "Weiyue Zhou", "Kevin B. Woller"], "title": "BABY 1L: First Tritium Breeding Campaign Results", "categories": ["physics.ins-det", "physics.plasm-ph"], "comment": null, "summary": "Achieving tritium self-sufficiency is a critical challenge for future fusion\npower plants. The BABY 1L experiment, part of the LIBRA project at MIT, aims to\nbenchmark tritium breeding and release in molten salt breeder systems under\ndeuterium-tritium (DT) neutron irradiation. Building on the initial\n\\SI{100}{mL} campaign, BABY 1L introduces a tenfold increase in breeder volume,\nimproved thermal and gas handling systems, and enhanced neutron diagnostics,\nincluding a proton recoil telescope. We report on results from four irradiation\nexperiments using sealed-tube DT neutron generators, with tritium collected by\nwater bubblers measured via liquid scintillation counting. Experimentally\ndetermined Tritium Breeding Ratios (TBRs) were compared to OpenMC neutronics\nsimulations, showing very good agreement. The measured TBR values demonstrate a\nsix-fold improvement over the \\SI{100}{mL} experiments, largely attributed to\nthe increased solid angle and improved measurement fidelity. We also\ninvestigate tritium release dynamics and identify diffusion-limited transport\nas the dominant regime in the salt volume in the temperature range 630-750\n\\si{\\celsius}. Additionally, we observe that the introduction of hydrogen in\nthe helium carrier gas significantly accelerates tritium release, consistent\nwith an isotopic exchange mechanism. All analysis is conducted through the\nopen-source \\texttt{libra-toolbox} \\cite{libra-toolbox}, which streamlines\nsimulation, data processing, and validation across experimental campaigns.\nThese results provide critical insights into the design and operation of future\nliquid breeder systems and demonstrate the maturity of the BABY platform as a\ntestbed for tritium breeding studies.", "AI": {"tldr": "BABY 1L experiment demonstrates improved tritium breeding in molten salt systems with 10x larger volume, achieving six-fold TBR improvement over previous experiments and identifying diffusion-limited transport as dominant tritium release mechanism.", "motivation": "Achieving tritium self-sufficiency is critical for future fusion power plants, requiring experimental validation of tritium breeding and release in molten salt breeder systems.", "method": "Used sealed-tube DT neutron generators with 10x larger breeder volume, improved thermal/gas systems, enhanced neutron diagnostics including proton recoil telescope. Tritium collected via water bubblers and measured by liquid scintillation counting. Compared experimental TBRs with OpenMC neutronics simulations.", "result": "Experimental TBRs showed very good agreement with simulations, achieving six-fold improvement over previous 100mL experiments. Identified diffusion-limited transport as dominant tritium release mechanism at 630-750\u00b0C. Hydrogen in carrier gas significantly accelerated tritium release via isotopic exchange.", "conclusion": "Results provide critical insights for future liquid breeder system design and demonstrate BABY platform maturity as a testbed for tritium breeding studies, with all analysis conducted through open-source libra-toolbox."}}
{"id": "2509.26122", "pdf": "https://arxiv.org/pdf/2509.26122", "abs": "https://arxiv.org/abs/2509.26122", "authors": ["Emil Haugen", "Alexei Stepanenko", "Anders C. Hansen"], "title": "Trustworthy AI in numerics: On verification algorithms for neural network-based PDE solvers", "categories": ["math.NA", "cs.NA", "65M15, 68T07 (Primary), 26D10, 41A55, 65D32 (Secondary)"], "comment": "25 pages, 3 figures", "summary": "We present new algorithms for a posteriori verification of neural networks\n(NNs) approximating solutions to PDEs. These verification algorithms compute\naccurate estimates of $L^p$ norms of NNs and their derivatives. When combined\nwith residual bounds for specific PDEs, the algorithms provide guarantees of\n$\\eps$-accuracy (in a suitable norm) with respect to the true, but unknown,\nsolution of the PDE -- for arbitrary $\\eps >0$. In particular, if the NN fails\nto meet the desired accuracy, our algorithms will detect that and reject it,\nwhereas any NN that passes the verification algorithms is certified to be\n$\\eps$-accurate. This framework enables trustworthy algorithms for NN-based PDE\nsolvers, regardless of how the NN is initially computed. Such a posteriori\nverification is essential, since a priori error bounds in general cannot\nguarantee the accuracy of computed solutions, due to algorithmic undecidability\nof the optimization problems used to train NNs.", "AI": {"tldr": "New algorithms for a posteriori verification of neural networks approximating PDE solutions, providing accuracy guarantees and rejection of inaccurate solutions.", "motivation": "To enable trustworthy NN-based PDE solvers by providing verification that can guarantee solution accuracy, addressing limitations of a priori error bounds due to undecidability in NN training optimization.", "method": "Algorithms that compute accurate estimates of L^p norms of NNs and their derivatives, combined with residual bounds for specific PDEs to verify solution accuracy.", "result": "The framework provides guarantees of \u03b5-accuracy with respect to the true PDE solution for arbitrary \u03b5>0, with algorithms that detect and reject inaccurate NNs while certifying accurate ones.", "conclusion": "A posteriori verification is essential for trustworthy NN-based PDE solvers as it overcomes the limitations of a priori error bounds and ensures solution reliability regardless of how the NN was initially computed."}}
{"id": "2509.20833", "pdf": "https://arxiv.org/pdf/2509.20833", "abs": "https://arxiv.org/abs/2509.20833", "authors": ["Nidia Reyes-Gil", "Greg Thomsen", "Kristopher Rowe", "Peter Diamessis"], "title": "A Fourier/Modal-Spectral-Element Method for the Simulation of High-Reynolds Number Incompressible Stratified Flows in Domains with a Single Non-Periodic Direction", "categories": ["physics.flu-dyn", "cs.NA", "math.NA", "physics.comp-ph"], "comment": "41 pages, 24 figures", "summary": "We present the components of a high-order accurate Navier-Stokes solver\ndesigned to simulate high-Reynolds-number stratified flows. The proposed\nnumerical model addresses some of the numerical and computational challenges\nthat high-Reynolds-number simulations pose, facilitating the reproduction of\nstratified turbulent fluid dynamics typically observed in oceanic and\natmospheric flows, namely the development of thin regions of high vertical\nshear, strongly layered turbulence at high Reynolds numbers and internal wave\nradiation. This Navier-Stokes solver utilizes a Fourier pseudo-spectral method\nin the horizontal direction and a modal spectral element discretization in the\nvertical. We adopt an implicit-explicit time discretization scheme that\ninvolves solving several one-dimensional Helmholtz problems at each time step.\nStatic condensation and modal boundary-adapted basis functions result in an\ninexpensive algorithm based on solving many small tridiagonal systems. A series\nof benchmark studies is presented to demonstrate the robustness of the flow\nsolver. These include two-dimensional and three-dimensional problems,\nconcluding with a turbulent stratified wake generated by a sphere in linear\nstratification.", "AI": {"tldr": "A high-order accurate Navier-Stokes solver for simulating high-Reynolds-number stratified flows, using Fourier pseudo-spectral method horizontally and modal spectral element discretization vertically with implicit-explicit time stepping.", "motivation": "To address numerical and computational challenges in simulating high-Reynolds-number stratified flows, particularly for reproducing stratified turbulent dynamics observed in oceanic and atmospheric flows like thin high-shear regions, layered turbulence, and internal wave radiation.", "method": "Uses Fourier pseudo-spectral method in horizontal direction and modal spectral element discretization in vertical direction. Implements implicit-explicit time discretization solving one-dimensional Helmholtz problems with static condensation and modal boundary-adapted basis functions, resulting in efficient tridiagonal system solutions.", "result": "The solver demonstrates robustness through benchmark studies including 2D and 3D problems, successfully simulating turbulent stratified wake generated by a sphere in linear stratification.", "conclusion": "The proposed numerical model effectively handles high-Reynolds-number stratified flow simulations, providing an efficient computational approach for studying complex stratified turbulent phenomena relevant to oceanic and atmospheric applications."}}
{"id": "2509.25677", "pdf": "https://arxiv.org/pdf/2509.25677", "abs": "https://arxiv.org/abs/2509.25677", "authors": ["Tianxiang Gou"], "title": "Non-degeneracy and uniqueness of ground states to nonlinear elliptic equations with mixed local and nonlocal operators", "categories": ["math.AP", "35A01, 35B65, 35R11"], "comment": "28 pages", "summary": "This paper concerns the non-degeneracy and uniqueness of ground states to the\nfollowing nonlinear elliptic equation with mixed local and nonlocal operators,\n$$ -\\Delta u +(-\\Delta)^s u + \\lambda u=|u|^{p-2}u \\quad \\mbox{in} \\,\\,\\, B,\n\\quad u=0 \\quad \\mbox{in} \\,\\,\\, \\R^N \\backslash {B}, $$ where $N \\geq 2$,\n$0<s<1$, $2<p<2^*:=\\frac{2N}{(N-2)^+}$, $\\lambda > -\\lambda_1$, $(-\\Delta)^s$\ndenotes the fractional Laplacian, $\\lambda_1>0$ denotes the first Dirichlet\neigenvalue of the operator $-\\Delta +(-\\Delta)^s$ in $B$ and $B$ denotes the\nunit ball in $\\R^N$. We prove that the second eigenvalue to the linearized\noperator $-\\Delta +(-\\Delta)^s -(p-1)u^{p-2}$ in the space of radially\nsymmetric functions is simple, the corresponding eigenfunction changes sign\nprecisely once in the radial direction, where $u$ is a ground state. By\napplying a new Hopf type lemma, we then get that $-\\lambda$ cannot be an\neigenvalue of the linearized operator, which in turns leads to the\nnon-degeneracy of the ground state. Moreover, by establishing a Picone type\nidentity with respect to antisymmetric functions, we then derive the\nnon-degeneracy of the ground state in the space of non-radially symmetric\nfunctions. Relying on the non-degeneracy of ground states and adapting a\nblow-up argument together with a continuation argument, we then obtain the\nuniqueness of ground states.", "AI": {"tldr": "This paper proves the non-degeneracy and uniqueness of ground states for a nonlinear elliptic equation with mixed local and nonlocal operators in the unit ball.", "motivation": "To establish rigorous mathematical properties of ground states for equations combining classical Laplacian and fractional Laplacian operators, which have applications in various physical and biological models.", "method": "Proving the second eigenvalue of the linearized operator is simple and its eigenfunction changes sign once; applying a new Hopf type lemma; establishing a Picone type identity for antisymmetric functions; using blow-up and continuation arguments.", "result": "The ground state is non-degenerate in both radially symmetric and non-radially symmetric function spaces, and uniqueness of ground states is established.", "conclusion": "The paper successfully proves non-degeneracy and uniqueness of ground states for the mixed local-nonlocal elliptic equation in the unit ball under the given parameter conditions."}}
{"id": "2509.26586", "pdf": "https://arxiv.org/pdf/2509.26586", "abs": "https://arxiv.org/abs/2509.26586", "authors": ["L. P. Chitta", "D. Calchetti", "J. Hirzberger", "G. Valori", "E. R. Priest", "S. K. Solanki", "D. Berghmans", "C. Verbeeck", "E. Kraaikamp", "K. Albert", "T. Appourchaux", "F. J. Bail\u00e9n", "L. R. Bellot Rubio", "J. Blanco Rodr\u00edguez", "A. Feller", "A. Gandorfer", "L. Gizon", "A. Lagg", "A. Moreno Vacas", "D. Orozco Su\u00e1rez", "J. Schou", "U. Sch\u00fchle", "J. Sinjan", "H. Strecker", "R. Volkmer", "J. Woch", "X. Li", "T. Oba", "A. Ulyanov"], "title": "Supergranulation and poleward migration of the magnetic field at high latitudes of the Sun", "categories": ["astro-ph.SR", "physics.plasm-ph", "physics.space-ph"], "comment": "Submitted to the Astrophysical Journal Letters (Online animations\n  available from the corresponding author)", "summary": "Magnetoconvection at the solar surface governs the dynamics in the upper\nsolar atmosphere and sustains the heliosphere. Properties of this fundamental\nprocess are poorly described near the solar poles. Here we report the first\nout-of-ecliptic remote-sensing observations of the south pole of the Sun from a\nhigh-latitude campaign of the Solar Orbiter spacecraft which reveal spatial and\ntemporal evolution of supergranular convective cells. The supergranular cells\nhave spatial scales of 20--40\\,Mm. From eight days of observations starting on\n2025 March 16, our analysis shows that the magnetic network migrates poleward,\non average, at high latitudes (above 60\\textdegree), with speeds in the range\nof 10--20\\,m\\,s$^{-1}$, depending on the structures being tracked. These\nresults shed light on the buildup of the polar magnetic field that is central\nto our understanding of the solar cycle and the heliospheric magnetic field.", "AI": {"tldr": "First out-of-ecliptic observations of solar south pole reveal supergranular cells (20-40 Mm) and poleward magnetic network migration at 10-20 m/s above 60\u00b0 latitude.", "motivation": "Magnetoconvection at solar surface governs upper atmosphere dynamics but is poorly understood near solar poles, crucial for understanding solar cycle and heliospheric magnetic field.", "method": "Remote-sensing observations from Solar Orbiter spacecraft high-latitude campaign, analyzing spatial and temporal evolution of supergranular convective cells over 8 days starting March 16, 2025.", "result": "Supergranular cells have 20-40 Mm spatial scales; magnetic network migrates poleward at 10-20 m/s above 60\u00b0 latitude depending on tracked structures.", "conclusion": "Results provide insights into polar magnetic field buildup, which is central to understanding solar cycle dynamics and heliospheric magnetic field."}}
{"id": "2509.26274", "pdf": "https://arxiv.org/pdf/2509.26274", "abs": "https://arxiv.org/abs/2509.26274", "authors": ["Andreas A. Buchheit", "Jonathan K. Busse", "Torsten Ke\u00dfler", "Filipp N. Rybakov"], "title": "Zeta expansion for long-range interactions under periodic boundary conditions with applications to micromagnetics", "categories": ["math.NA", "cond-mat.str-el", "cs.NA"], "comment": null, "summary": "We address the efficient computation of power-law-based interaction\npotentials of homogeneous $d$-dimensional bodies with an infinite\n$n$-dimensional array of copies, including their higher-order derivatives. This\nproblem forms a serious challenge in micromagnetics with periodic boundary\nconditions and related fields. Nowadays, it is common practice to truncate the\nassociated infinite lattice sum to a finite number of images, introducing\nuncontrolled errors. We show that, for general interacting geometries, the\nexact infinite sum for both dipolar interactions and generalized Riesz\npower-law potentials can be obtained by complementing a small direct sum by a\ncorrection term that involves efficiently computable derivatives of generalized\nzeta functions. We show that the resulting representation converges\nexponentially in the derivative order, reaching machine precision at a\ncomputational cost no greater than that of truncated summation schemes. In\norder to compute the generalized zeta functions efficiently, we provide a\nsuperexponentially convergent algorithm for their evaluation, as well as for\nall required special functions, such as incomplete Bessel functions. Magnetic\nfields can thus be evaluated to machine precision in arbitrary cuboidal domains\nperiodically extended along one or two dimensions. We benchmark our method\nagainst known formulas for magnetic interactions and against direct summation\nfor Riesz potentials with large exponents, consistently achieving full\nprecision. In addition, we identify new corrections to the asymptotic limit of\nthe demagnetization field and tabulate high-precision benchmark values that can\nbe used as a reliable reference for micromagnetic solvers. The techniques\ndeveloped are broadly applicable, with direct impact in other areas such as\nmolecular dynamics.", "AI": {"tldr": "Efficient computation of power-law-based interaction potentials for periodic systems using generalized zeta functions instead of truncated lattice sums, achieving machine precision with exponential convergence.", "motivation": "Current practice of truncating infinite lattice sums in micromagnetics with periodic boundary conditions introduces uncontrolled errors, requiring an exact method for computing these interactions.", "method": "Complement a small direct sum with correction terms involving efficiently computable derivatives of generalized zeta functions, using a superexponentially convergent algorithm for evaluation.", "result": "Achieves machine precision at computational cost comparable to truncated schemes, with exponential convergence in derivative order. Validated against known formulas and direct summation.", "conclusion": "The method provides exact infinite sums for periodic interactions, enabling high-precision computations in micromagnetics and other fields like molecular dynamics, with broad applicability."}}
{"id": "2509.25194", "pdf": "https://arxiv.org/pdf/2509.25194", "abs": "https://arxiv.org/abs/2509.25194", "authors": ["Haoyang Wu", "Xinxin Zhang", "Lailai Zhu"], "title": "Automated Code Development for PDE Solvers Using Large Language Models", "categories": ["cs.SE", "physics.comp-ph"], "comment": null, "summary": "Foundation models -- large language models (LLMs) in particular -- have\nbecome ubiquitous, shaping daily life and driving breakthroughs across science,\nengineering, and technology. Harnessing their broad cross-domain knowledge,\ntext-processing, and reasoning abilities for software development, e.g.,\nnumerical libraries for solving partial differential equations (PDEs), is\ntherefore attracting growing interest. Yet existing studies mainly automate\ncase setup and execution for end users. We introduce LLM-PDEveloper, a\nzero-shot, multi-agent LLM framework that automates code development for PDE\nlibraries, specifically targeting secondary developers. By translating\nmathematical and algorithmic descriptions directly into source code,\nLLM-PDEveloper generates new solvers/modules and adapts existing ones. This\nend-to-end math-to-code approach enables a self-augmenting pipeline that\ncontinuously expands the codebase of a library, extends its capacities, and\nbroadens its scope. We demonstrate LLM-PDEveloper on three tasks: 1) build a\nsolver for a new PDE, 2) implement new BCs for a given PDE, and 3) modify an\nexisting solver to incorporate additional terms, achieving moderate success\nrates. Failures due to syntactic errors made by LLMs are analyzed and we\npropose effective fixes. We also identify the mechanisms underlying certain\nsemantic errors, guiding future research.", "AI": {"tldr": "LLM-PDEveloper is a zero-shot multi-agent LLM framework that automates code development for PDE libraries by translating mathematical descriptions into source code, enabling continuous library expansion.", "motivation": "To leverage LLMs' cross-domain knowledge and reasoning abilities for automating software development in numerical PDE libraries, specifically targeting secondary developers rather than just end users.", "method": "A zero-shot, multi-agent LLM framework that translates mathematical and algorithmic descriptions directly into source code, generating new solvers/modules and adapting existing ones through an end-to-end math-to-code approach.", "result": "Demonstrated on three tasks: building solvers for new PDEs, implementing new boundary conditions, and modifying existing solvers with additional terms, achieving moderate success rates. Identified and fixed syntactic errors, and analyzed mechanisms behind semantic errors.", "conclusion": "LLM-PDEveloper enables a self-augmenting pipeline for continuous library expansion and provides insights for future research on semantic error mechanisms in automated code generation."}}
{"id": "2509.25875", "pdf": "https://arxiv.org/pdf/2509.25875", "abs": "https://arxiv.org/abs/2509.25875", "authors": ["Yoshifumi Mimura"], "title": "The Mimura Integral: A Unified Framework for Riemann and Lebesgue Integration", "categories": ["math.AP"], "comment": null, "summary": "An integral on Euclidean space, equivalent to the Lebesgue integral, is\nconstructed by extending the notion of Riemann sums. In contrast to the\nHenstock--Kurzweil and McShane integrals, the construction recovers the full\nmeasure-theoretic structure -- outer measure, inner measure, and measurable\nsets -- rather than merely reproducing integration with respect to the Lebesgue\nmeasure. Whereas the classical approach to Lebesgue theory proceeds through a\ntwo-layer framework of measure and integration, these layers are unified here\ninto a single framework, thereby avoiding duplication. Compared with the\nDaniell integral, the method is more concrete and accessible, serving both as\nan alternative to the Riemann integral and as a natural bridge to abstract\nLebesgue theory.", "AI": {"tldr": "A new integral equivalent to Lebesgue integral is constructed using extended Riemann sums, unifying measure theory and integration into a single framework.", "motivation": "To create a more accessible and concrete alternative to the Lebesgue integral that avoids the traditional two-layer framework of measure and integration, while recovering the full measure-theoretic structure.", "method": "Extending the notion of Riemann sums to construct an integral equivalent to the Lebesgue integral, unifying measure theory and integration into a single framework.", "result": "Successfully constructed an integral equivalent to the Lebesgue integral that recovers outer measure, inner measure, and measurable sets, avoiding duplication in the classical approach.", "conclusion": "This method provides a concrete and accessible alternative to the Riemann integral and serves as a natural bridge to abstract Lebesgue theory, unifying measure and integration layers."}}
{"id": "2509.26284", "pdf": "https://arxiv.org/pdf/2509.26284", "abs": "https://arxiv.org/abs/2509.26284", "authors": ["Giuseppe Orlando", "Ward Haegeman", "Marica Pelanti", "Marc Massot"], "title": "A robust computational framework for the mixture-energy-consistent six-equation two-phase model with instantaneous mechanical relaxation terms", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We present a robust computational framework for the numerical solution of a\nhyperbolic 6-equation single-velocity two-phase model. The model's main\ninterest is that, when combined with instantaneous mechanical relaxation, it\nrecovers the solution of the 5-equation model of Kapila. Several numerical\nmethods based on this strategy have been developed over the years. However,\nneither the 5- nor 6-equation model admits a complete set of jump conditions\nbecause they involve non-conservative products. Different discretizations of\nthese terms in the 6-equation model exist. The precise impact of these\ndiscretizations on the numerical solutions of the 5-equation model, in\nparticular for shocks, is still an open question to which this work provides\nnew insights. We consider the phasic total energies as prognostic variables to\nnaturally enforce discrete conservation of total energy and compare the\naccuracy and robustness of different discretizations for the hyperbolic\noperator. Namely, we discuss the construction of an HLLC approximate Riemann\nsolver in relation to jump conditions. We then compare an HLLC wave-propagation\nscheme which includes the non-conservative terms, with Rusanov and HLLC solvers\nfor the conservative part in combination with suitable approaches for the\nnon-conservative terms. We show that some approaches for the discretization of\nnon-conservative terms fit within the framework of path-conservative schemes\nfor hyperbolic problems. We then analyze the use of various numerical\nstrategies on several relevant test cases, showing both the impact of the\ntheoretical shortcomings of the models as well as the importance of the choice\nof a robust framework for the global numerical strategy.", "AI": {"tldr": "A computational framework for solving hyperbolic 6-equation two-phase models, analyzing different discretizations of non-conservative terms and their impact on 5-equation model solutions, particularly for shocks.", "motivation": "To understand how different discretizations of non-conservative terms in 6-equation two-phase models affect numerical solutions of the 5-equation Kapila model, especially for shock problems where jump conditions are incomplete.", "method": "Uses phasic total energies as prognostic variables for discrete conservation, compares HLLC approximate Riemann solver with Rusanov and HLLC solvers for conservative parts, and analyzes path-conservative schemes for non-conservative terms.", "result": "Shows that some discretization approaches fit within path-conservative schemes framework, and demonstrates the impact of theoretical model shortcomings and the importance of robust numerical strategies through test cases.", "conclusion": "The choice of discretization for non-conservative terms significantly impacts solution accuracy and robustness, with some methods fitting path-conservative frameworks, highlighting the need for careful numerical strategy selection."}}
{"id": "2509.25311", "pdf": "https://arxiv.org/pdf/2509.25311", "abs": "https://arxiv.org/abs/2509.25311", "authors": ["Anirudh Deb", "Yaman Sanghavi"], "title": "Aspects of holographic entanglement using physics-informed-neural-networks", "categories": ["hep-th", "cs.LG", "physics.comp-ph"], "comment": "18 pages, 14 figures", "summary": "We implement physics-informed-neural-networks (PINNs) to compute holographic\nentanglement entropy and entanglement wedge cross section. This technique\nallows us to compute these quantities for arbitrary shapes of the subregions in\nany asymptotically AdS metric. We test our computations against some known\nresults and further demonstrate the utility of PINNs in examples, where it is\nnot straightforward to perform such computations.", "AI": {"tldr": "PINNs are used to compute holographic entanglement entropy and entanglement wedge cross section for arbitrary subregion shapes in asymptotically AdS metrics.", "motivation": "To develop a method that can compute holographic entanglement quantities for arbitrary subregion shapes where traditional approaches face difficulties.", "method": "Implementation of Physics-Informed Neural Networks (PINNs) to solve the holographic entanglement entropy and entanglement wedge cross section problems.", "result": "Successfully tested against known results and demonstrated utility in cases where conventional computations are not straightforward.", "conclusion": "PINNs provide an effective computational approach for holographic entanglement analysis in complex scenarios with arbitrary subregion geometries."}}
{"id": "2509.25891", "pdf": "https://arxiv.org/pdf/2509.25891", "abs": "https://arxiv.org/abs/2509.25891", "authors": ["Fausto Ferrari", "Davide Giovagnoli", "Enzo Maria Merlino"], "title": "On a fractional Alt-Caffarelli-Friedman-type monotonicity formula", "categories": ["math.AP", "35R35, 35R11, 34K37"], "comment": null, "summary": "In this note, by exploiting mean value properties of $s$-harmonic functions,\nwe introduce some monotonicity formulas in the nonlocal setting. We take into\naccount intrinsically nonlocal functionals mimicking those introduced by Alt,\nCaffarelli and Friedman in the seminal work [Alt-Caffarelli-Friedman, Trans.\nAmer. Math. Soc. (1984)]. Our approach is purely nonlocal and does not rely on\nthe extension technique. As a byproduct we also established interior nonlocal\ngradient estimates and a nonlocal analogue of the Bochner identity.", "AI": {"tldr": "The paper introduces monotonicity formulas for nonlocal functionals using mean value properties of s-harmonic functions, without relying on extension techniques.", "motivation": "To develop intrinsically nonlocal methods that mimic classical monotonicity formulas from Alt-Caffarelli-Friedman work, avoiding dependence on extension techniques.", "method": "Exploits mean value properties of s-harmonic functions to derive monotonicity formulas in nonlocal settings, using purely nonlocal approaches.", "result": "Established monotonicity formulas for nonlocal functionals, interior nonlocal gradient estimates, and a nonlocal analogue of the Bochner identity.", "conclusion": "The paper successfully develops a framework for monotonicity formulas in nonlocal analysis that is independent of extension methods and provides important tools like nonlocal gradient estimates and Bochner identity analogues."}}
{"id": "2509.26344", "pdf": "https://arxiv.org/pdf/2509.26344", "abs": "https://arxiv.org/abs/2509.26344", "authors": ["Vanni Noferini", "Lauri Nyman", "Federico Poloni"], "title": "Nearest matrix with multiple eigenvalues by Riemannian optimization", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Given a square complex matrix $A$, we tackle the problem of finding the\nnearest matrix with multiple eigenvalues or, equivalently when $A$ had distinct\neigenvalues, the nearest defective matrix. To this goal, we extend the general\nframework described in [M. Gnazzo, V. Noferini, L. Nyman, F. Poloni,\n\\emph{Riemann-Oracle: A general-purpose Riemannian optimizer to solve nearness\nproblems in matrix theory}, Found. Comput. Math., To appear] and based on\nvariable projection and Riemannian optimization, allowing the ambient manifold\nto simultaneously track left and right eigenvectors. Our method also allows us\nto impose arbitrary complex-linear constraints on either the perturbation or\nthe perturbed matrix; this can be useful to study structured eigenvalue\ncondition numbers. We present numerical experiments, comparing with preexisting\nalgorithms.", "AI": {"tldr": "This paper extends a Riemannian optimization framework to find the nearest defective matrix by tracking both left and right eigenvectors simultaneously, with support for complex-linear constraints.", "motivation": "To solve the problem of finding the nearest matrix with multiple eigenvalues (defective matrix) from a given square complex matrix with distinct eigenvalues.", "method": "Extends a Riemannian optimization framework using variable projection to simultaneously track left and right eigenvectors, allowing arbitrary complex-linear constraints on perturbations or perturbed matrices.", "result": "The method enables computation of nearest defective matrices and can be used to study structured eigenvalue condition numbers.", "conclusion": "The extended framework provides an effective approach for finding nearest defective matrices and analyzing structured eigenvalue problems, with numerical experiments showing comparisons to existing algorithms."}}
{"id": "2509.25386", "pdf": "https://arxiv.org/pdf/2509.25386", "abs": "https://arxiv.org/abs/2509.25386", "authors": ["Alexander Leibenzon", "Samuel W. S. Johnson", "Ruth E. Baker", "Michael Assaf"], "title": "Spatial correlations in SIS processes on regular random graphs", "categories": ["cond-mat.stat-mech", "physics.comp-ph", "q-bio.PE"], "comment": "10 pages, 5 figures", "summary": "In network-based SIS models of infectious disease transmission, infection can\nonly occur between directly connected individuals. This constraint naturally\ngives rise to spatial correlations between the states of neighboring nodes, as\nthe infection status of connected individuals becomes interdependent. Although\nmean-field approximations are commonly invoked to simplify disease forecasting\non networks, they fail to account for these correlations by assuming that\ninfectious individuals are well-mixed within a population, leading to\ninaccurate predictions of infection numbers over time. As such, the development\nof mathematical frameworks that account for spatially correlated infections is\nof great interest, as they offer a compromise between accurate disease\nforecasting and analytic tractability. Here, we use existing corrections to\nmean-field theory on the regular lattice to construct a more general framework\nfor equivalent corrections on regular random graph topologies. We derive and\nsimulate a system of ordinary differential equations for the time evolution of\nthe spatial correlation function at various geodesic distances on random\nnetworks, and use solutions to this hierarchy of ordinary differential\nequations to predict the global infection density as a function of time,\nfinding good agreement with corresponding numerical simulations. Our results\nconstitute a substantial development on existing corrections to mean-field\ntheory for infectious individuals in SIS processes and provide an in-depth\ncharacterization of how structural randomness in networks affects the dynamical\ntrajectories of infectious diseases on networks.", "AI": {"tldr": "The paper develops a mathematical framework that accounts for spatial correlations in SIS disease transmission on networks, improving upon mean-field approximations by incorporating spatial dependencies between connected individuals.", "motivation": "Mean-field approximations fail to capture spatial correlations between neighboring nodes in network-based SIS models, leading to inaccurate infection predictions. There's a need for frameworks that balance accuracy with analytic tractability.", "method": "Used existing corrections to mean-field theory on regular lattices to construct a general framework for regular random graphs. Derived and simulated ODEs for spatial correlation functions at different geodesic distances.", "result": "The framework accurately predicts global infection density over time, showing good agreement with numerical simulations. It characterizes how network structural randomness affects disease dynamics.", "conclusion": "This work significantly advances mean-field corrections for SIS processes and provides detailed understanding of how network structure randomness influences infectious disease trajectories."}}
{"id": "2509.25971", "pdf": "https://arxiv.org/pdf/2509.25971", "abs": "https://arxiv.org/abs/2509.25971", "authors": ["Lauri Oksanen", "Ruochong Zhang"], "title": "Inverse problem for connections in semi-linear wave equations on Lorentzian manifolds", "categories": ["math.AP"], "comment": null, "summary": "This paper recovers Hermitian connections of semi-linear wave equations with\ncubic nonlinearity. The main novelty is in the geometric generality: we treat\nthe case of an arbitrary globally hyperbolic Lorentzian manifold. Our approach\nis based on microlocal analysis of nonlinear wave interactions, which recovers\na non-abelian broken light-ray transform, and the inversion of broken light-ray\ntransforms on globally hyperbolic Lorentzian manifolds.", "AI": {"tldr": "Recovery of Hermitian connections for semi-linear wave equations with cubic nonlinearity on arbitrary globally hyperbolic Lorentzian manifolds using microlocal analysis.", "motivation": "To extend the recovery of Hermitian connections to more general geometric settings, specifically arbitrary globally hyperbolic Lorentzian manifolds, beyond previous limited cases.", "method": "Uses microlocal analysis of nonlinear wave interactions to recover a non-abelian broken light-ray transform, and inverts broken light-ray transforms on globally hyperbolic Lorentzian manifolds.", "result": "Successfully recovers Hermitian connections for semi-linear wave equations with cubic nonlinearity in the general geometric setting of globally hyperbolic Lorentzian manifolds.", "conclusion": "The approach demonstrates that microlocal analysis and inversion of broken light-ray transforms provide an effective method for recovering Hermitian connections in general globally hyperbolic Lorentzian settings."}}
{"id": "2509.26358", "pdf": "https://arxiv.org/pdf/2509.26358", "abs": "https://arxiv.org/abs/2509.26358", "authors": ["Ling-Zhe Zai", "Lei-Lei Guo", "Zhi-Yong Zhang"], "title": "HANN: Homotopy auxiliary neural network for solving nonlinear algebraic equations", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Solving nonlinear algebraic equations is a fundamental but challenging\nproblem in scientific computations and also has many applications in system\nengineering. Though traditional iterative methods and modern optimization\nalgorithms have exerted effective roles in addressing certain specific\nproblems, there still exist certain weaknesses such as the initial value\nsensitivity, limited accuracy and slow convergence rate, particulary without\nflexible input for the neural network methods. In this paper, we propose a\nhomotopy auxiliary neural network (HANN) for solving nonlinear algebraic\nequations which integrates the classical homotopy continuation method and\npopular physics-informed neural network. Consequently, the HANN-1 has strong\nlearning ability and can rapidly give an acceptable solution for the problem\nwhich outperforms some known methods, while the HANN-2 can further improve its\naccuracy. Numerical results on the benchmark problems confirm that the HANN\nmethod can effectively solve the problems of determining the total number of\nsolutions of a single equation, finding solutions of transcendental systems\ninvolving the absolute value function or trigonometric function,\nill-conditioned and normal high-dimensional nonlinear systems and time-varying\nnonlinear problems, for which the Python's built-in Fsolve function exhibits\nsignificant limitations, even fails to work.", "AI": {"tldr": "The paper proposes a Homotopy Auxiliary Neural Network (HANN) that combines classical homotopy continuation with physics-informed neural networks to solve nonlinear algebraic equations more effectively than traditional methods.", "motivation": "Traditional iterative methods and optimization algorithms have limitations like initial value sensitivity, limited accuracy, slow convergence, and inflexible neural network inputs for solving nonlinear algebraic equations.", "method": "The HANN method integrates classical homotopy continuation with physics-informed neural networks, featuring two versions: HANN-1 for rapid acceptable solutions and HANN-2 for improved accuracy.", "result": "Numerical results show HANN effectively solves various problems including single equation solutions, transcendental systems with absolute value/trigonometric functions, ill-conditioned high-dimensional systems, and time-varying nonlinear problems, outperforming Python's Fsolve function.", "conclusion": "The HANN method demonstrates strong learning ability and effectiveness in solving challenging nonlinear algebraic equations where traditional methods like Fsolve exhibit significant limitations or fail completely."}}
{"id": "2509.25404", "pdf": "https://arxiv.org/pdf/2509.25404", "abs": "https://arxiv.org/abs/2509.25404", "authors": ["Malaquias Correa Anguita", "Teun Roelink", "Sara Marzban", "Wim Briels", "Claudia Filippi", "Jelmer Renema"], "title": "Experimental demonstration of boson sampling as a hardware accelerator for monte carlo integration", "categories": ["quant-ph", "physics.atm-clus", "physics.comp-ph", "physics.optics"], "comment": "15 pages, 9 figures", "summary": "We present an experimental demonstration of boson sampling as a hardware\naccelerator for Monte Carlo integration. Our approach leverages importance\nsampling to factorize an integrand into a distribution that can be sampled\nusing quantum hardware and a function that can be evaluated classically,\nenabling hybrid quantum-classical computation. We argue that for certain\nclasses of integrals, this method offers a quantum advantage by efficiently\nsampling from probability distributions that are hard to simulate classically.\nWe also identify structural criteria that must be satisfied to preserve\ncomputational hardness, notably the sensitivity of the classical\npost-processing function to high-order quantum correlations. To validate our\nprotocol, we implement a proof-of-principle experiment on a programmable\nphotonic platform to compute the first-order energy correction of a three-boson\nsystem in a harmonic trap under an Efimov-inspired three-body perturbation. The\nexperimental results are consistent with theoretical predictions and numerical\nsimulations, with deviations explained by photon distinguishability,\ndiscretization, and unitary imperfections. Additionally, we provide an error\nbudget quantifying the impact of these same sources of noise. Our work\nestablishes a concrete use case for near-term photonic quantum devices and\nhighlights a viable path toward practical quantum advantage in scientific\ncomputing.", "AI": {"tldr": "Experimental demonstration of boson sampling as hardware accelerator for Monte Carlo integration using hybrid quantum-classical approach with potential quantum advantage.", "motivation": "To establish concrete use cases for near-term photonic quantum devices and demonstrate practical quantum advantage in scientific computing through efficient sampling from hard-to-simulate probability distributions.", "method": "Hybrid quantum-classical computation using importance sampling to factorize integrands into quantum-sampled distributions and classically-evaluated functions, implemented on programmable photonic platform.", "result": "Experimental results consistent with theoretical predictions and numerical simulations for computing first-order energy correction of three-boson system, with deviations explained by photon distinguishability, discretization, and unitary imperfections.", "conclusion": "This work establishes a viable path toward practical quantum advantage in scientific computing and provides a concrete use case for near-term photonic quantum devices."}}
{"id": "2509.25978", "pdf": "https://arxiv.org/pdf/2509.25978", "abs": "https://arxiv.org/abs/2509.25978", "authors": ["Maria Heitzinger", "Ansgar J\u00fcngel"], "title": "Weak-strong uniqueness for general cross-diffusion systems with volume filling", "categories": ["math.AP", "35A02, 35K51, 35K55, 35Q79, 35Q92"], "comment": null, "summary": "The weak-strong uniqueness of solutions to a broad class of cross-diffusion\nsystems with volume filling is established. In general, the diffusion matrices\nare neither symmetric nor positive definite. This issue is overcome by\nsupposing that the equations possess a Boltzmann-type entropy structure, which\nensures the existence of bounded weak solutions. In this framework, general\nconditions on the mobility matrix are identified that allow for the proof of\nthe weak-strong uniqueness property by means of the relative entropy method.\nThe core idea consists in analyzing an augmented mobility matrix that is\npositive definite only on a specific subspace. Several examples that meet the\nrequired assumptions are provided, together with a discussion on possible\nextensions.", "AI": {"tldr": "Establishes weak-strong uniqueness for cross-diffusion systems with volume filling using relative entropy method, overcoming non-symmetric/non-positive definite diffusion matrices through Boltzmann-type entropy structure.", "motivation": "To prove weak-strong uniqueness for cross-diffusion systems where diffusion matrices are generally neither symmetric nor positive definite, which presents mathematical challenges.", "method": "Uses relative entropy method with Boltzmann-type entropy structure; analyzes augmented mobility matrix that is positive definite only on specific subspaces; identifies general conditions on mobility matrix.", "result": "Successfully establishes weak-strong uniqueness property for broad class of cross-diffusion systems with volume filling; provides several examples meeting required assumptions.", "conclusion": "The approach effectively overcomes challenges posed by non-symmetric/non-positive definite diffusion matrices through entropy structure and augmented mobility analysis, with potential for extensions."}}
{"id": "2509.26438", "pdf": "https://arxiv.org/pdf/2509.26438", "abs": "https://arxiv.org/abs/2509.26438", "authors": ["Klaus B\u00f6hnlein", "Stefan Neukamm", "Oliver Sander"], "title": "Finite element discretizations of bending plates with prestrained microstructure", "categories": ["math.NA", "cs.NA", "math.AP", "74B20 35B27 74Q05 74S05"], "comment": "32 pages, 2 figures", "summary": "We investigate a finite element discretization of an elastic bending-plate\nmodel with an effective prestrain. The model has been obtained via\nhomogenization and dimension reduction by B\\\"onlein at al. (2023). Its energy\nfunctional is the $\\Gamma$-limit of a three-dimensional nonlinear\nmicrostructured elasticity functional. In the derived effective model, the\nmicrostructure is incorporated as a local corrector problem, a system of linear\nelliptic partial differential equations posed on a three-dimensional\nrepresentative volume element. The discretization uses Discrete Kirchhoff\nTriangle elements for the macroscopic bending-plate problem on a mesh of scale\n$H$, and first-order Lagrange elements for the microscopic corrector problem on\nan axis-aligned mesh of scale $h$. We show that the discretized model\n$\\Gamma$-converges to the continuous one as $(h,H)\\to 0$,provided that there\nexists a microstructure mesh such that the elasticity tensor is Lipschitz\ncontinuous on each mesh element. This extends earlier results by Rumpf et al.\n(2024) to prestrained composites. Our argument does not require any rate of\nconvergence for the microscopic discretization error. As a corollary, we also\nobtain convergence when $h \\to 0$ and $H \\to 0$ consecutively, and we prove\nthat these limit processes commute.", "AI": {"tldr": "Finite element discretization of an elastic bending-plate model with prestrain using Discrete Kirchhoff Triangle elements for macroscopic problem and Lagrange elements for microscopic corrector problem, showing \u0393-convergence to continuous model.", "motivation": "To develop and analyze a numerical discretization scheme for a homogenized elastic bending-plate model with prestrain that was derived from three-dimensional microstructured elasticity.", "method": "Uses Discrete Kirchhoff Triangle elements for macroscopic bending-plate problem (mesh scale H) and first-order Lagrange elements for microscopic corrector problem (mesh scale h), with \u0393-convergence analysis.", "result": "The discretized model \u0393-converges to the continuous model as (h,H)\u21920, provided Lipschitz continuity of elasticity tensor on microstructure mesh elements. Convergence holds for consecutive limits h\u21920 and H\u21920, and these limits commute.", "conclusion": "The discretization scheme is mathematically sound and extends previous results to prestrained composites, providing a rigorous foundation for numerical simulations of such materials."}}
{"id": "2509.25450", "pdf": "https://arxiv.org/pdf/2509.25450", "abs": "https://arxiv.org/abs/2509.25450", "authors": ["Moritz von Tresckow", "Ion Gabriel Ion", "Dimitrios Loukrezis"], "title": "Multi-patch isogeometric neural solver for partial differential equations on computer-aided design domains", "categories": ["cs.CE", "cs.AI", "cs.NA", "math.NA", "physics.comp-ph", "68T07 (Primary), 78A30 (Secondary)", "J.2; J.6; I.2.m"], "comment": "33 pages, 15 figures", "summary": "This work develops a computational framework that combines physics-informed\nneural networks with multi-patch isogeometric analysis to solve partial\ndifferential equations on complex computer-aided design geometries. The method\nutilizes patch-local neural networks that operate on the reference domain of\nisogeometric analysis. A custom output layer enables the strong imposition of\nDirichlet boundary conditions. Solution conformity across interfaces between\nnon-uniform rational B-spline patches is enforced using dedicated interface\nneural networks. Training is performed using the variational framework by\nminimizing the energy functional derived after the weak form of the partial\ndifferential equation. The effectiveness of the suggested method is\ndemonstrated on two highly non-trivial and practically relevant use-cases,\nnamely, a 2D magnetostatics model of a quadrupole magnet and a 3D nonlinear\nsolid and contact mechanics model of a mechanical holder. The results show\nexcellent agreement to reference solutions obtained with high-fidelity finite\nelement solvers, thus highlighting the potential of the suggested neural solver\nto tackle complex engineering problems given the corresponding computer-aided\ndesign models.", "AI": {"tldr": "A computational framework combining physics-informed neural networks with multi-patch isogeometric analysis to solve PDEs on complex CAD geometries, demonstrating effectiveness on 2D magnetostatics and 3D nonlinear mechanics problems.", "motivation": "To develop an efficient neural solver for partial differential equations on complex computer-aided design geometries, bridging the gap between CAD models and computational analysis.", "method": "Uses patch-local neural networks on isogeometric analysis reference domains with custom output layers for Dirichlet boundary conditions, interface networks for patch conformity, and variational training by minimizing energy functionals.", "result": "Excellent agreement with high-fidelity finite element reference solutions for both 2D magnetostatics (quadrupole magnet) and 3D nonlinear solid/contact mechanics (mechanical holder) test cases.", "conclusion": "The method shows strong potential for tackling complex engineering problems directly from CAD models, providing accurate solutions comparable to traditional high-fidelity finite element solvers."}}
{"id": "2509.26046", "pdf": "https://arxiv.org/pdf/2509.26046", "abs": "https://arxiv.org/abs/2509.26046", "authors": ["Seungjae Lee"], "title": "Sharp local well-posedness of $C^1$ vortex patches", "categories": ["math.AP"], "comment": null, "summary": "It is well known that the boundary dynamics of vortex patches is globally\nwell-posed in the H\\\"older space $C^{1,\\alpha}$ for $0<\\alpha<1$, whereas the\nwell-posedness in $C^1$ remains an open problem, even locally. In this paper,\nwe establish the local well-posedness for vortex patches in the space\n$C^{1,\\varphi}$ defined via a modulus of continuity $\\varphi$ that satisfies\ncertain structural assumptions. Our class includes curves that are strictly\nrougher than the H\\\"older-continuous ones, with prototypical examples being\n$\\varphi(r) = (-\\log r)^{-s}$ for $s>3$. Motivated by the fact that the\nvelocity operator in the contour dynamics equation is a nonlinear variant of\nthe Hilbert transform, we study the system of equations satisfied by the curve\nparametrization $\\gamma \\in C^{1,\\varphi}$ and its Hilbert transform. In doing\nso, we derive several properties of the Hilbert transform and its variants in\ncritical spaces, which are essential for controlling the velocity operator and\nits Hilbert transform.", "AI": {"tldr": "Establishes local well-posedness for vortex patches in C^{1,\u03c6} spaces with modulus \u03c6(r) = (-log r)^{-s} for s>3, which are rougher than H\u00f6lder spaces.", "motivation": "The well-posedness of vortex patch boundary dynamics in C^1 remains an open problem, while C^{1,\u03b1} for 0<\u03b1<1 is known to be globally well-posed.", "method": "Study the system of equations for curve parametrization \u03b3 \u2208 C^{1,\u03c6} and its Hilbert transform, deriving properties of Hilbert transform variants in critical spaces.", "result": "Proved local well-posedness for vortex patches in C^{1,\u03c6} spaces with specific modulus functions that are strictly rougher than H\u00f6lder-continuous curves.", "conclusion": "The approach successfully handles vortex patches with boundary curves that are more singular than H\u00f6lder-continuous ones, advancing beyond previous results."}}
{"id": "2509.26475", "pdf": "https://arxiv.org/pdf/2509.26475", "abs": "https://arxiv.org/abs/2509.26475", "authors": ["Awad H. Al-Mohy"], "title": "Computing Linear Combinations of $\\varphi$-Function Actions for Exponential Integrators", "categories": ["math.NA", "cs.NA"], "comment": "17 pages, 3 figures", "summary": "We propose a matrix-free algorithm for evaluating linear combinations of\n$\\varphi$-function actions, $w_i := \\sum_{j=0}^{p}\n\\alpha_i^{\\,j}\\,\\varphi_j(t_i A)v_j$ for $i=1\\colon r$, arising in exponential\nintegrators. The method combines the scaling and recovering method with a\ntruncated Taylor series, choosing a spectral shift and a scaling parameter by\nminimizing a power-based objective of the shifted operator. Accuracy is\nuser-controlled and ultimately limited by the working precision. The algorithm\ndecouples the stage abscissae $t_i$ from the polynomial weights $\\alpha_i^j$,\nand a block variant enables simultaneous evaluation of $\\{w_i\\}_{i=1}^r$.\nAcross standard benchmarks, including stiff and highly nonnormal matrices, the\nalgorithm attains near-machine accuracy (IEEE double precision in our tests)\nfor small step sizes and maintains reliable accuracy for larger steps where\nseveral existing Krylov-based algorithms deteriorate, providing a favorable\nbalance of reliability and computational cost.", "AI": {"tldr": "A matrix-free algorithm for evaluating linear combinations of \u03c6-function actions in exponential integrators, combining scaling/recovering with truncated Taylor series and spectral shifting for improved accuracy and reliability.", "motivation": "To develop a more reliable and accurate method for evaluating \u03c6-function actions in exponential integrators, especially for stiff and nonnormal matrices where existing Krylov-based methods deteriorate.", "method": "Combines scaling and recovering method with truncated Taylor series, uses spectral shift and scaling parameter optimization, decouples stage abscissae from polynomial weights, and includes block variant for simultaneous evaluation.", "result": "Achieves near-machine accuracy (IEEE double precision) for small step sizes and maintains reliable accuracy for larger steps where other Krylov-based algorithms fail, providing good balance of reliability and computational cost.", "conclusion": "The proposed algorithm offers improved reliability and accuracy for \u03c6-function evaluations in exponential integrators across various matrix types, outperforming existing Krylov-based methods especially for larger step sizes."}}
{"id": "2509.25730", "pdf": "https://arxiv.org/pdf/2509.25730", "abs": "https://arxiv.org/abs/2509.25730", "authors": ["Indu Kant Deo", "Akash Venkateshwaran", "Rajeev K. Jaiman"], "title": "A Physics-Guided Probabilistic Surrogate Modeling Framework for Digital Twins of Underwater Radiated Noise", "categories": ["cs.LG", "physics.comp-ph"], "comment": "26 pages, 13 figures", "summary": "Ship traffic is an increasing source of underwater radiated noise in coastal\nwaters, motivating real-time digital twins of ocean acoustics for operational\nnoise mitigation. We present a physics-guided probabilistic framework to\npredict three-dimensional transmission loss in realistic ocean environments. As\na case study, we consider the Salish Sea along shipping routes from the Pacific\nOcean to the Port of Vancouver. A dataset of over 30 million source-receiver\npairs was generated with a Gaussian beam solver across seasonal sound speed\nprofiles and one-third-octave frequency bands spanning 12.5 Hz to 8 kHz. We\nfirst assess sparse variational Gaussian processes (SVGP) and then incorporate\nphysics-based mean functions combining spherical spreading with\nfrequency-dependent absorption. To capture nonlinear effects, we examine deep\nsigma-point processes and stochastic variational deep kernel learning. The\nfinal framework integrates four components: (i) a learnable physics-informed\nmean that represents dominant propagation trends, (ii) a convolutional encoder\nfor bathymetry along the source-receiver track, (iii) a neural encoder for\nsource, receiver, and frequency coordinates, and (iv) a residual SVGP layer\nthat provides calibrated predictive uncertainty. This probabilistic digital\ntwin facilitates the construction of sound-exposure bounds and worst-case\nscenarios for received levels. We further demonstrate the application of the\nframework to ship speed optimization, where predicted transmission loss\ncombined with near-field source models provides sound exposure level estimates\nfor minimizing acoustic impacts on marine mammals. The proposed framework\nadvances uncertainty-aware digital twins for ocean acoustics and illustrates\nhow physics-guided machine learning can support sustainable maritime\noperations.", "AI": {"tldr": "A physics-guided probabilistic framework for predicting 3D underwater transmission loss using machine learning, applied to ship noise mitigation in the Salish Sea.", "motivation": "Ship traffic is increasing underwater radiated noise in coastal waters, creating need for real-time digital twins of ocean acoustics for operational noise mitigation.", "method": "Combines physics-based mean functions with deep learning: learnable physics-informed mean, convolutional encoder for bathymetry, neural encoder for coordinates, and residual SVGP layer for uncertainty.", "result": "Developed probabilistic digital twin that facilitates sound-exposure bounds and worst-case scenarios, demonstrated application to ship speed optimization for minimizing acoustic impacts on marine mammals.", "conclusion": "The framework advances uncertainty-aware digital twins for ocean acoustics and shows how physics-guided machine learning can support sustainable maritime operations."}}
{"id": "2509.26054", "pdf": "https://arxiv.org/pdf/2509.26054", "abs": "https://arxiv.org/abs/2509.26054", "authors": ["Kazuhiro Ishige", "Nobuhito Miyake"], "title": "Initial traces and solvability of the fast diffusion equation with power-type nonlinearity", "categories": ["math.AP", "35K67, 35K15, 35B33"], "comment": null, "summary": "We investigate the qualitative behavior of the initial traces of nonnegative\nsolutions to the fast diffusion equation with power-type nonlinearity.\nNecessary conditions for the existence of solutions to the corresponding Cauchy\nproblem are identified. Moreover, sharp sufficient conditions for the existence\nof solutions are established by employing uniform local Morrey spaces and their\ngeneralizations.", "AI": {"tldr": "Analysis of initial traces for nonnegative solutions to fast diffusion equation with power-type nonlinearity, identifying necessary conditions and establishing sharp sufficient conditions for solution existence using Morrey spaces.", "motivation": "To understand the qualitative behavior of initial traces for nonnegative solutions to the fast diffusion equation with power-type nonlinearity and determine precise conditions for solution existence.", "method": "Employ uniform local Morrey spaces and their generalizations to establish sharp sufficient conditions for solution existence.", "result": "Identified necessary conditions for solution existence and established sharp sufficient conditions using Morrey space framework.", "conclusion": "The paper provides comprehensive analysis of initial trace behavior and establishes precise conditions for existence of solutions to the fast diffusion equation with power-type nonlinearity."}}
{"id": "2509.26504", "pdf": "https://arxiv.org/pdf/2509.26504", "abs": "https://arxiv.org/abs/2509.26504", "authors": ["Takuya Tsuchiya"], "title": "Structure-preserving numerical calculation of wave equation for a vector field", "categories": ["math.NA", "cs.NA", "math.AP", "quant-ph"], "comment": "6 pages, 4 figures", "summary": "For the Proca equation, which is a wave equation for a vector field, we\nderive the canonical formulation including constraints from the Stueckelberg\naction and propose discrete equations with a structure-preserving scheme for\nconserving the constraints at the discrete level. Numerical simulations are\nperformed using these discrete equations and other discrete equations with a\nstandard scheme. We show the results obtained using the structure-preserving\nscheme and provide more accurate and stable numerical solutions.", "AI": {"tldr": "Derived canonical formulation with constraints for Proca equation from Stueckelberg action, developed structure-preserving discrete scheme to conserve constraints, and showed it provides more accurate and stable numerical solutions compared to standard schemes.", "motivation": "To develop a structure-preserving numerical scheme for the Proca equation that can conserve constraints at the discrete level, addressing the need for more accurate and stable numerical solutions.", "method": "Derived canonical formulation including constraints from Stueckelberg action, proposed discrete equations with structure-preserving scheme to conserve constraints, performed numerical simulations comparing with standard scheme.", "result": "The structure-preserving scheme provided more accurate and stable numerical solutions compared to standard discrete equations.", "conclusion": "Structure-preserving schemes are effective for maintaining constraints in discrete formulations of the Proca equation, leading to improved numerical accuracy and stability."}}
{"id": "2509.26139", "pdf": "https://arxiv.org/pdf/2509.26139", "abs": "https://arxiv.org/abs/2509.26139", "authors": ["James Panayis", "Matt Field", "Vignesh Gopakumar", "Andrew Lahiff", "Kristian Zarebski", "Aby Abraham", "Jonathan L. Hodges"], "title": "Leveraging AI modelling for FDS with Simvue: monitor and optimise for more sustainable simulations", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": "12 pages, 17 figures, Interflam Conference", "summary": "There is high demand on fire simulations, in both scale and quantity. We\npresent a multi-pronged approach to improving the time and energy required to\nmeet these demands. We show the ability of a custom machine learning surrogate\nmodel to predict the dynamics of heat propagation orders of magnitude faster\nthan state-of-the-art CFD software for this application. We also demonstrate\nhow a guided optimisation procedure can decrease the number of simulations\nrequired to meet an objective; using lightweight models to decide which\nsimulations to run, we see a tenfold reduction when locating the most dangerous\nlocation for a fire to occur within a building based on the impact of smoke on\nvisibility. Finally we present a framework and product, Simvue, through which\nwe access these tools along with a host of automatic organisational and\ntracking features which enables future reuse of data and more savings through\nbetter management of simulations and combating redundancy.", "AI": {"tldr": "A multi-pronged approach using ML surrogate models and guided optimization to dramatically improve fire simulation efficiency, with a 10x reduction in simulations needed and orders of magnitude faster predictions.", "motivation": "High demand for fire simulations in both scale and quantity requires improvements in time and energy efficiency for meeting these computational demands.", "method": "Uses custom machine learning surrogate model for fast heat propagation prediction, guided optimization with lightweight models to select simulations, and Simvue framework for simulation management and data reuse.", "result": "ML surrogate predicts heat dynamics orders of magnitude faster than CFD software; guided optimization reduces required simulations by 10x for locating most dangerous fire locations based on smoke impact on visibility.", "conclusion": "The presented multi-pronged approach and Simvue framework enable significant efficiency gains in fire simulations through ML acceleration, intelligent simulation selection, and better data management."}}
{"id": "2509.26098", "pdf": "https://arxiv.org/pdf/2509.26098", "abs": "https://arxiv.org/abs/2509.26098", "authors": ["Diego Chamorro", "Maxence Mansais"], "title": "Global mild solutions in a critical setting for a forced fractional Boussinesq system", "categories": ["math.AP"], "comment": null, "summary": "We study here mild solutions for the forced, incompressible fractional\nBoussinesq system. Under suitable estimates for the terms involved (in an\nadapted functional framework) we can invoque a fixed point argument in order to\nobtain mild solutions. Although many functional spaces can be considered, we\nare interested here in a critical setting which ensures the existence of global\nsolutions and we will work in particular with parabolic Morrey spaces which\nprovide one of the largest critical functional frameworks available for\nconstructing mild solutions for the fractional Boussinesq equations.", "AI": {"tldr": "Study of mild solutions for forced incompressible fractional Boussinesq system using fixed point arguments in critical functional frameworks, particularly parabolic Morrey spaces.", "motivation": "To establish existence of global solutions for the fractional Boussinesq system by working in critical functional settings that provide the largest available frameworks for constructing mild solutions.", "method": "Using fixed point arguments in an adapted functional framework with suitable estimates for the involved terms, working specifically with parabolic Morrey spaces as the critical functional framework.", "result": "Obtained mild solutions for the forced incompressible fractional Boussinesq system through the fixed point approach in critical settings.", "conclusion": "Parabolic Morrey spaces provide one of the largest critical functional frameworks for constructing mild solutions for fractional Boussinesq equations, enabling the existence of global solutions."}}
{"id": "2509.26624", "pdf": "https://arxiv.org/pdf/2509.26624", "abs": "https://arxiv.org/abs/2509.26624", "authors": ["Tiangang Cui", "Josef Dick", "Friedrich Pillichshammer"], "title": "Second order interlaced polynomial lattice rules for integration over $\\mathbb{R}^s$", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We study numerical integration of functions $f: \\mathbb{R}^{s} \\to\n\\mathbb{R}$ with respect to a probability measure. By applying the\ncorresponding inverse cumulative distribution function, the problem is\ntransformed into integrating an induced function over the unit cube\n$(0,1)^{s}$. We introduce a new orthonormal system: \\emph{order~2 localized\nWalsh functions}. These basis functions retain the approximation power of\nclassical Walsh functions for twice-differentiable integrands while inheriting\nthe spatial localization of Haar wavelets. Localization is crucial because the\ntransformed integrand is typically unbounded at the boundary. We show that the\nworst-case quasi-Monte Carlo integration error decays like\n$\\mathcal{O}(N^{-1/\\lambda})$ for every $\\lambda \\in (1/2,1]$. As an\napplication, we consider elliptic partial differential equations with a finite\nnumber of log-normal random coefficients and show that our error estimates\nremain valid for their stochastic Galerkin discretizations by applying a\nsuitable importance sampling density.", "AI": {"tldr": "The paper introduces order-2 localized Walsh functions for numerical integration of functions over probability measures, achieving improved error decay rates for quasi-Monte Carlo methods while handling boundary singularities.", "motivation": "To address the challenge of integrating functions with respect to probability measures, particularly when transformed integrands become unbounded at boundaries, requiring localized basis functions that combine approximation power with spatial localization.", "method": "Transforms integration problems using inverse cumulative distribution functions to unit cubes, then introduces order-2 localized Walsh functions that combine classical Walsh function approximation power with Haar wavelet spatial localization properties.", "result": "Shows that worst-case quasi-Monte Carlo integration error decays as O(N^{-1/\u03bb}) for every \u03bb \u2208 (1/2,1], and applies the method to elliptic PDEs with log-normal random coefficients using stochastic Galerkin discretizations with importance sampling.", "conclusion": "The new localized Walsh function system provides effective numerical integration for probability measures, handling boundary singularities while maintaining good convergence rates, with successful application to stochastic PDE problems."}}
{"id": "2509.26179", "pdf": "https://arxiv.org/pdf/2509.26179", "abs": "https://arxiv.org/abs/2509.26179", "authors": ["Shivasubramanian Gopinath", "Joseph Rosen", "Vijayakumar Anand"], "title": "Axial resolution post-processing engineering in Fresnel incoherent correlation holography", "categories": ["physics.optics", "physics.comp-ph"], "comment": null, "summary": "Fresnel incoherent correlation holography (FINCH) is a\nself-interference-based incoherent digital holography method. In FINCH, light\nfrom an object point is split into two beams, modulated differently using two\nlenses with different focal distances, and creates a self-interference\nhologram. At least three phase-shifted holograms are recorded and synthesized\ninto a complex hologram, which reconstructs the object image without twin image\nand bias noises. Compared with conventional imaging, FINCH exhibits a longer\ndepth of focus (DOF) and higher lateral resolution. In this study, we propose\nand demonstrate a new method termed post-engineering of axial resolution in\nFINCH (PEAR-FINCH), which enables post-recording DOF engineering for the first\ntime. In PEAR-FINCH, a library of FINCH holograms catalogued with unique axial\ncharacteristics, DOF, and focus location is recorded by changing the focal\ndistance of one of the diffractive lenses. Selected holograms from this library\nare combined to engineer new axial characteristics not achievable in FINCH. A\ntwo-step reconstruction, involving numerical back-propagation and deconvolution\nwith a point spread hologram, is implemented. Experiments with multiplane\nobjects having large axial separations confirm that PEAR-FINCH achieves a\nsubstantially extended DOF compared with direct imaging and FINCH. PEAR-FINCH\nwill be promising for applications in biomedical imaging, holography, and\nfluorescence microscopy.", "AI": {"tldr": "PEAR-FINCH enables post-recording depth of focus engineering in Fresnel incoherent correlation holography by combining holograms from a library with different axial characteristics.", "motivation": "To overcome the limitations of conventional FINCH by enabling post-recording engineering of axial resolution and depth of focus, which was not previously possible.", "method": "Record a library of FINCH holograms with different focal distances, then combine selected holograms and use two-step reconstruction (numerical back-propagation and deconvolution with point spread hologram).", "result": "PEAR-FINCH achieves substantially extended depth of focus compared to both direct imaging and conventional FINCH, as confirmed by experiments with multiplane objects.", "conclusion": "PEAR-FINCH is a promising method for biomedical imaging, holography, and fluorescence microscopy applications due to its ability to engineer axial characteristics post-recording."}}
{"id": "2509.26113", "pdf": "https://arxiv.org/pdf/2509.26113", "abs": "https://arxiv.org/abs/2509.26113", "authors": ["Ali Haider Shah", "Naveed R. Butt", "Asif Ahmad", "Muhammad Omer Bin Saeed"], "title": "Enhancing PINN Performance Through Lie Symmetry Group", "categories": ["math.AP", "cs.AI"], "comment": null, "summary": "This paper presents intersection of Physics informed neural networks (PINNs)\nand Lie symmetry group to enhance the accuracy and efficiency of solving\npartial differential equation (PDEs). Various methods have been developed to\nsolve these equations. A Lie group is an efficient method that can lead to\nexact solutions for the PDEs that possessing Lie Symmetry. Leveraging the\nconcept of infinitesimal generators from Lie symmetry group in a novel manner\nwithin PINN leads to significant improvements in solution of PDEs. In this\nstudy three distinct cases are discussed, each showing progressive improvements\nachieved through Lie symmetry modifications and adaptive techniques.\nState-of-the-art numerical methods are adopted for comparing the progressive\nPINN models. Numerical experiments demonstrate the key role of Lie symmetry in\nenhancing PINNs performance, emphasizing the importance of integrating abstract\nmathematical concepts into deep learning for addressing complex scientific\nproblems adequately.", "AI": {"tldr": "Integrating Lie symmetry groups with Physics-Informed Neural Networks (PINNs) significantly improves PDE solving accuracy and efficiency through infinitesimal generators and adaptive techniques.", "motivation": "To enhance PINN performance for solving partial differential equations by incorporating Lie symmetry group theory, which can provide exact solutions for symmetric PDEs.", "method": "Combines PINNs with Lie symmetry group concepts using infinitesimal generators and adaptive techniques, tested on three distinct cases with progressive modifications.", "result": "Numerical experiments show substantial improvements in PINN performance when Lie symmetry is incorporated, outperforming state-of-the-art numerical methods.", "conclusion": "Integrating abstract mathematical concepts like Lie symmetry into deep learning frameworks is crucial for effectively solving complex scientific problems with PINNs."}}
{"id": "2509.25269", "pdf": "https://arxiv.org/pdf/2509.25269", "abs": "https://arxiv.org/abs/2509.25269", "authors": ["Simon Welker", "Lorenz Kuger", "Tim Roith", "Berthy Feng", "Martin Burger", "Timo Gerkmann", "Henry Chapman"], "title": "Position-Blind Ptychography: Viability of image reconstruction via data-driven variational inference", "categories": ["eess.IV", "cs.CV", "cs.LG", "cs.NA", "math.NA", "physics.optics", "94A08, 68U10, 78A46, 68T07"], "comment": null, "summary": "In this work, we present and investigate the novel blind inverse problem of\nposition-blind ptychography, i.e., ptychographic phase retrieval without any\nknowledge of scan positions, which then must be recovered jointly with the\nimage. The motivation for this problem comes from single-particle diffractive\nX-ray imaging, where particles in random orientations are illuminated and a set\nof diffraction patterns is collected. If one uses a highly focused X-ray beam,\nthe measurements would also become sensitive to the beam positions relative to\neach particle and therefore ptychographic, but these positions are also\nunknown. We investigate the viability of image reconstruction in a simulated,\nsimplified 2-D variant of this difficult problem, using variational inference\nwith modern data-driven image priors in the form of score-based diffusion\nmodels. We find that, with the right illumination structure and a strong prior,\none can achieve reliable and successful image reconstructions even under\nmeasurement noise, in all except the most difficult evaluated imaging scenario.", "AI": {"tldr": "The paper introduces position-blind ptychography, a novel blind inverse problem where both the image and unknown scan positions must be jointly recovered from diffraction patterns without position knowledge.", "motivation": "The problem is motivated by single-particle diffractive X-ray imaging, where particles in random orientations are illuminated and diffraction patterns are collected. With focused X-ray beams, measurements become ptychographic but positions relative to particles remain unknown.", "method": "The authors use variational inference with modern data-driven image priors in the form of score-based diffusion models to investigate image reconstruction in a simulated 2-D variant of this problem.", "result": "With appropriate illumination structure and strong priors, reliable and successful image reconstructions can be achieved even under measurement noise, except in the most difficult imaging scenarios.", "conclusion": "Position-blind ptychography is viable for image reconstruction when using strong data-driven priors and proper illumination, demonstrating potential for applications in single-particle X-ray imaging despite the challenging nature of the problem."}}
{"id": "2509.26397", "pdf": "https://arxiv.org/pdf/2509.26397", "abs": "https://arxiv.org/abs/2509.26397", "authors": ["Siwoo Lee", "Adji Bousso Dieng"], "title": "Are neural scaling laws leading quantum chemistry astray?", "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Neural scaling laws are driving the machine learning community toward\ntraining ever-larger foundation models across domains, assuring high accuracy\nand transferable representations for extrapolative tasks. We test this promise\nin quantum chemistry by scaling model capacity and training data from quantum\nchemical calculations. As a generalization task, we evaluate the resulting\nmodels' predictions of the bond dissociation energy of neutral H$_2$, the\nsimplest possible molecule. We find that, regardless of dataset size or model\ncapacity, models trained only on stable structures fail dramatically to even\nqualitatively reproduce the H$_2$ energy curve. Only when compressed and\nstretched geometries are explicitly included in training do the predictions\nroughly resemble the correct shape. Nonetheless, the largest foundation models\ntrained on the largest and most diverse datasets containing dissociating\ndiatomics exhibit serious failures on simple diatomic molecules. Most\nstrikingly, they cannot reproduce the trivial repulsive energy curve of two\nbare protons, revealing their failure to learn the basic Coulomb's law involved\nin electronic structure theory. These results suggest that scaling alone is\ninsufficient for building reliable quantum chemical models.", "AI": {"tldr": "Neural scaling laws fail to produce reliable quantum chemical models even with large datasets and model capacity. Models trained only on stable structures cannot reproduce H2 energy curves, and foundation models fail to learn basic Coulomb's law.", "motivation": "To test whether neural scaling laws can produce accurate and transferable quantum chemical models for predicting molecular properties like bond dissociation energy.", "method": "Scaling model capacity and training data from quantum chemical calculations, evaluating models' predictions of H2 bond dissociation energy curves, and testing on various molecular geometries including compressed and stretched structures.", "result": "Models trained only on stable structures fail dramatically to reproduce H2 energy curves. Only with explicit inclusion of compressed/stretched geometries do predictions resemble correct shape. Largest foundation models fail on simple diatomic molecules and cannot reproduce repulsive energy curve of two protons.", "conclusion": "Scaling alone is insufficient for building reliable quantum chemical models. Models fail to learn basic electronic structure theory principles like Coulomb's law, highlighting limitations of current neural scaling approaches in quantum chemistry."}}
{"id": "2509.26125", "pdf": "https://arxiv.org/pdf/2509.26125", "abs": "https://arxiv.org/abs/2509.26125", "authors": ["Adrian Constantin", "J\u00f6rg Weber"], "title": "On the propagation of mountain waves: linear theory", "categories": ["math.AP", "math-ph", "math.MP", "86A10, 34B20"], "comment": null, "summary": "We derive and establish a solution concept for the linear mountain wave\nproblem in two dimensions. After linearizing the governing equations and a\nchange of variables, the problem can be stated as a Dirichlet boundary value\nproblem for a Helmholtz equation in terms of the vertical wind profile in the\nupper half-plane, with altitude-dependent potential (the Scorer parameter). To\nsingle out the correct solution, we have to make use of a radiation condition\nwhich is, due to the different physical situation, different from the classical\nSommerfeld radiation condition for electromagnetic or acoustic waves. We\nrigorously develop a transform method and construct the physically correct\nsolution, following Lyra's monotonicity criterion for mountain waves. In this\nprocedure, we clearly recognize the two typical types of mountain waves:\nvertically propagating waves and trapped lee waves. This paper is the first\nrigorous work on Helmholtz-like equations in the upper half-plane subject to\nsuch a non-classical radiation condition.", "AI": {"tldr": "A rigorous solution concept for linear mountain waves in 2D using Helmholtz equation with altitude-dependent potential and non-classical radiation condition.", "motivation": "To establish a physically correct solution for mountain wave problems that differs from classical wave radiation conditions due to different physical situations.", "method": "Linearized governing equations with variable change, Dirichlet boundary value problem for Helmholtz equation, transform method construction following Lyra's monotonicity criterion.", "result": "Successfully derived and constructed the physically correct solution that distinguishes between vertically propagating waves and trapped lee waves.", "conclusion": "First rigorous work on Helmholtz-like equations in upper half-plane with non-classical radiation condition, providing clear recognition of two mountain wave types."}}
{"id": "2509.26298", "pdf": "https://arxiv.org/pdf/2509.26298", "abs": "https://arxiv.org/abs/2509.26298", "authors": ["Ward Haegeman", "Giuseppe Orlando", "Samuel Kokh", "Marc Massot"], "title": "An all-topology two-fluid model for two-phase flows derived through Hamilton's Stationary Action Principle", "categories": ["math.AP"], "comment": null, "summary": "We present a novel multi-fluid model for compressible two-phase flows. The\nmodel is derived through a newly developed Stationary Action Principle\nframework. It is fully closed and introduces a new interfacial quantity, the\ninterfacial work. The closures for the interfacial quantities are provided by\nthe variational principle. They are physically sound and well-defined for all\ntype of flow topologies. The model is shown to be hyperbolic, symmetrizable,\nand admits an entropy conservation law. Its non-conservative products yield\nuniquely defined jump conditions which are provided. As such, it allows for the\nproper treatment of weak solutions. In the multi-dimensional setting, the model\npresents lift forces which are discussed. The model constitutes a sound basis\nfor future numerical simulations.", "AI": {"tldr": "A novel multi-fluid model for compressible two-phase flows derived using Stationary Action Principle, featuring full closure, hyperbolicity, and proper treatment of weak solutions.", "motivation": "To develop a physically sound and mathematically rigorous model for compressible two-phase flows that is fully closed and handles all flow topologies properly.", "method": "Derived through a newly developed Stationary Action Principle framework, introducing interfacial work as a new quantity and providing closures for interfacial quantities via the variational principle.", "result": "The model is hyperbolic, symmetrizable, admits an entropy conservation law, has uniquely defined jump conditions for non-conservative products, includes lift forces in multi-dimensional settings, and provides proper treatment of weak solutions.", "conclusion": "The model constitutes a sound basis for future numerical simulations of compressible two-phase flows."}}
{"id": "2509.25569", "pdf": "https://arxiv.org/pdf/2509.25569", "abs": "https://arxiv.org/abs/2509.25569", "authors": ["Arturo Rodriguez", "Avinash Potluri", "Aryan Singh", "Vyom Kumar", "Kate Reza", "Francisco O. Aguirre Ortega", "Vineeth Vijaya Kumar", "Noah L. Estrada"], "title": "Cross-Model Verification of Wall-Bounded Flows using Finite-JAX", "categories": ["physics.flu-dyn", "cs.NA", "math.NA"], "comment": "9 pages", "summary": "Accurate prediction of wall-bounded flows remains central to advancing both\ntheoretical understanding and computational methods in fluid mechanics. In this\nstudy, we perform a numerical simulation of channel flow using a complementary\napproach: a high-performance, differentiable finite-difference solver developed\nin JAX (Finite-JAX) and an analytical solution derived from the Navier-Stokes\nEquations, also referred to as the Hagen-Poiseuille equation. The solver is\napplied to the incompressible Navier-Stokes equations, along with appropriate\nboundary conditions, to capture canonical flow features such as velocity\nprofiles and pressure gradients. Cross-model verification is conducted by\nsystematically comparing numerical results between Finite-JAX and the\nanalytical solution, with a focus on velocity distributions. In addition,\nnumerical results are benchmarked against analytical solutions for laminar\nregimes, allowing for the direct quantification of verification accuracy\nerrors. Our findings demonstrate that cross-model verification not only\nstrengthens confidence in simulation fidelity but also provides a pathway for\nintegrating differentiable solvers with established computational fluid\ndynamics platforms, paving the way for future fluid flow research.", "AI": {"tldr": "Numerical simulation of channel flow using a differentiable finite-difference solver (Finite-JAX) and analytical Hagen-Poiseuille solution, with cross-model verification showing high accuracy.", "motivation": "Accurate prediction of wall-bounded flows is crucial for advancing theoretical understanding and computational methods in fluid mechanics.", "method": "Used a high-performance differentiable finite-difference solver (Finite-JAX) applied to incompressible Navier-Stokes equations with boundary conditions, and compared results with analytical Hagen-Poiseuille solution through systematic cross-model verification.", "result": "Cross-model verification demonstrated strong agreement between numerical and analytical solutions, quantifying verification accuracy errors and confirming simulation fidelity.", "conclusion": "Cross-model verification strengthens confidence in simulation results and provides a pathway for integrating differentiable solvers with established CFD platforms for future fluid flow research."}}
{"id": "2509.26367", "pdf": "https://arxiv.org/pdf/2509.26367", "abs": "https://arxiv.org/abs/2509.26367", "authors": ["Denis S. Grebenkov", "Michael J. Ward"], "title": "Competition of small targets in planar domains: from Dirichlet to Robin and Steklov boundary condition", "categories": ["math.AP", "math-ph", "math.MP", "math.SP"], "comment": null, "summary": "We consider steady-state diffusion in a bounded planar domain with multiple\nsmall targets on a smooth boundary. Using the method of matched asymptotic\nexpansions, we investigate the competition of these targets for a diffusing\nparticle and the crucial role of surface reactions on the targets. We start\nfrom the classical problem of splitting probabilities for perfectly reactive\ntargets with Dirichlet boundary condition and improve some earlier results. We\ndiscuss how this approach can be generalized to partially reactive targets\ncharacterized by a Robin boundary condition. In particular, we show how partial\nreactivity reduces the effective size of the target. In addition, we consider\nmore intricate surface reactions modeled by mixed Steklov-Neumann or\nSteklov-Neumann-Dirichlet problems. We provide the first derivation of the\nasymptotic behavior of the eigenvalues and eigenfunctions for these spectral\nproblems in the small-target limit. Finally, we show how our asymptotic\napproach can be extended to interior targets in the bulk and to exterior\nproblems where diffusion occurs in an unbounded planar domain outside a compact\nset. Direct applications of these results to diffusion-controlled reactions are\ndiscussed.", "AI": {"tldr": "Asymptotic analysis of diffusion to small targets with various boundary conditions, including partial reactivity effects and extensions to interior/exterior domains.", "motivation": "To understand competition between multiple small targets for diffusing particles and the role of surface reactions in diffusion-controlled processes.", "method": "Method of matched asymptotic expansions applied to diffusion problems with small targets, analyzing Dirichlet, Robin, and mixed Steklov-Neumann boundary conditions.", "result": "Derived asymptotic behavior of splitting probabilities, showed how partial reactivity reduces effective target size, and obtained first asymptotic results for eigenvalues/eigenfunctions in small-target limit.", "conclusion": "The asymptotic approach successfully handles various boundary conditions and can be extended to interior targets and exterior domains, with direct applications to diffusion-controlled reactions."}}
{"id": "2509.25630", "pdf": "https://arxiv.org/pdf/2509.25630", "abs": "https://arxiv.org/abs/2509.25630", "authors": ["Xiaojie Wang", "Bin Yang"], "title": "When Langevin Monte Carlo Meets Randomization: Non-asymptotic Error Bounds beyond Log-Concavity and Gradient Lipschitzness", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Efficient sampling from complex and high dimensional target distributions\nturns out to be a fundamental task in diverse disciplines such as scientific\ncomputing, statistics and machine learning. In this paper, we revisit the\nrandomized Langevin Monte Carlo (RLMC) for sampling from high dimensional\ndistributions without log-concavity. Under the gradient Lipschitz condition and\nthe log-Sobolev inequality, we prove a uniform-in-time error bound in\n$\\mathcal{W}_2$-distance of order $O(\\sqrt{d}h)$ for the RLMC sampling\nalgorithm, which matches the best one in the literature under the log-concavity\ncondition. Moreover, when the gradient of the potential $U$ is non-globally\nLipschitz with superlinear growth, modified RLMC algorithms are proposed and\nanalyzed, with non-asymptotic error bounds established. To the best of our\nknowledge, the modified RLMC algorithms and their non-asymptotic error bounds\nare new in the non-globally Lipschitz setting.", "AI": {"tldr": "The paper analyzes randomized Langevin Monte Carlo (RLMC) for sampling from high-dimensional distributions without log-concavity, proving uniform-in-time error bounds and proposing modified algorithms for non-globally Lipschitz gradients.", "motivation": "Efficient sampling from complex high-dimensional distributions is fundamental in scientific computing, statistics, and machine learning, but existing methods often assume log-concavity or globally Lipschitz gradients.", "method": "Revisits randomized Langevin Monte Carlo (RLMC) and proposes modified RLMC algorithms for cases where gradient of potential U is non-globally Lipschitz with superlinear growth.", "result": "Proves uniform-in-time error bound of O(\u221ad h) in W\u2082-distance under gradient Lipschitz condition and log-Sobolev inequality, matching best known bounds under log-concavity. For non-globally Lipschitz cases, establishes non-asymptotic error bounds for modified RLMC algorithms.", "conclusion": "The paper provides improved theoretical guarantees for RLMC sampling in non-log-concave settings and introduces new modified algorithms with error bounds for non-globally Lipschitz gradients, advancing the state-of-the-art in high-dimensional sampling."}}
{"id": "2509.26381", "pdf": "https://arxiv.org/pdf/2509.26381", "abs": "https://arxiv.org/abs/2509.26381", "authors": ["Denis S. Grebenkov", "Michael J. Ward"], "title": "The Effective Reactivity for Capturing Brownian Motion by Partially Reactive Patches on a Spherical Surface", "categories": ["math.AP", "math-ph", "math.MP", "physics.chem-ph"], "comment": null, "summary": "We analyze the trapping of diffusing ligands, modeled as Brownian particles,\nby a sphere that has $N$ partially reactive boundary patches, each of small\narea, on an otherwise reflecting boundary. For such a structured target, the\npartial reactivity of each boundary patch is characterized by a Robin boundary\ncondition, with a local boundary reactivity $\\kappa_i$ for $i=1,\\ldots,N$. For\nany spatial arrangement of well-separated patches on the surface of the sphere,\nthe method of matched asymptotic expansions is used to derive explicit results\nfor the capacitance $C_{\\rm T}$ of the structured target, which is valid for\nany $\\kappa_i>0$. This target capacitance $C_{\\rm T}$ is defined in terms of a\nGreen's matrix, which depends on the spatial configuration of patches, the\nlocal reactive capacitance $C_i(\\kappa_i)$ of each patch and another\ncoefficient that depends on the local geometry near a patch. The analytical\ndependence of $C_{i}(\\kappa_i)$ on $\\kappa_i$ is uncovered via a spectral\nexpansion over Steklov eigenfunctions. For circular patches, the latter are\nreadily computed numerically and provide an accurate fully explicit sigmoidal\napproximation for $C_{i}(\\kappa_i)$. In the homogenization limit of $N\\gg 1$\nidentical uniformly-spaced patches with $\\kappa_i=\\kappa$, we derive an\nexplicit scaling law for the effective capacitance and the effective reactivity\nof the structured target that is valid in the limit of small patch area\nfraction. From a comparison with numerical simulations, we show that this\nscaling law provides a highly accurate approximation over the full range\n$\\kappa>0$, even when there is only a moderately large number of reactive\npatches.", "AI": {"tldr": "The paper analyzes ligand trapping by a sphere with multiple small reactive patches using matched asymptotic expansions, deriving explicit formulas for target capacitance and effective reactivity that work for any patch reactivity.", "motivation": "To understand how diffusing ligands are trapped by structured targets with multiple small reactive patches on an otherwise reflecting boundary, which has applications in chemical and biological systems.", "method": "Used method of matched asymptotic expansions to derive target capacitance formulas, spectral expansion over Steklov eigenfunctions for local reactive capacitance, and homogenization limit for many patches.", "result": "Derived explicit results for target capacitance valid for any patch reactivity, developed accurate sigmoidal approximation for local reactive capacitance, and established scaling law for effective capacitance and reactivity in homogenization limit.", "conclusion": "The derived scaling law provides highly accurate approximation for effective capacitance and reactivity over full range of patch reactivities, even with moderately large number of reactive patches."}}
{"id": "2509.25646", "pdf": "https://arxiv.org/pdf/2509.25646", "abs": "https://arxiv.org/abs/2509.25646", "authors": ["Lei Ma", "Ling Guo", "Hao Wu", "Tao Zhou"], "title": "Deep set based operator learning with uncertainty quantification", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Learning operators from data is central to scientific machine learning. While\nDeepONets are widely used for their ability to handle complex domains, they\nrequire fixed sensor numbers and locations, lack mechanisms for uncertainty\nquantification (UQ), and are thus limited in practical applicability. Recent\npermutationinvariant extensions, such as the Variable-Input Deep Operator\nNetwork (VIDON), relax these sensor constraints but still rely on sufficiently\ndense observations and cannot capture uncertainties arising from incomplete\nmeasurements or from operators with inherent randomness. To address these\nchallenges, we propose UQ-SONet, a permutation-invariant operator learning\nframework with built-in UQ. Our model integrates a set transformer embedding to\nhandle sparse and variable sensor locations, and employs a conditional\nvariational autoencoder (cVAE) to approximate the conditional distribution of\nthe solution operator. By minimizing the negative ELBO, UQ-SONet provides\nprincipled uncertainty estimation while maintaining predictive accuracy.\nNumerical experiments on deterministic and stochastic PDEs, including the\nNavier-Stokes equation, demonstrate the robustness and effectiveness of the\nproposed framework.", "AI": {"tldr": "UQ-SONet is a permutation-invariant operator learning framework with built-in uncertainty quantification that handles sparse and variable sensor locations using set transformer embeddings and conditional variational autoencoders.", "motivation": "Existing operator learning methods like DeepONets have limitations: they require fixed sensor configurations, lack uncertainty quantification mechanisms, and cannot handle sparse measurements or operators with inherent randomness.", "method": "Integrates set transformer embedding for handling variable sensor locations and uses conditional variational autoencoder (cVAE) to approximate the conditional distribution of solution operators, minimizing negative ELBO for principled uncertainty estimation.", "result": "Numerical experiments on deterministic and stochastic PDEs, including Navier-Stokes equation, demonstrate robustness and effectiveness of the framework in providing uncertainty quantification while maintaining predictive accuracy.", "conclusion": "UQ-SONet successfully addresses key limitations of existing operator learning methods by providing built-in uncertainty quantification and handling sparse, variable sensor configurations through a principled probabilistic framework."}}
{"id": "2509.26414", "pdf": "https://arxiv.org/pdf/2509.26414", "abs": "https://arxiv.org/abs/2509.26414", "authors": ["R\u00e9mi Carles", "Quentin Chauleur", "Guillaume Ferriere"], "title": "On the dependence of the nonlinear Schrodinger flow upon the power of the nonlinearity", "categories": ["math.AP", "math-ph", "math.MP"], "comment": "46 pages", "summary": "We prove continuity properties for the flow map associated to the defocusing\nenergy-subcritical power-like nonlinear Schr{\\\"o}dinger equation, when the\npower varies. We show local in time continuity in the energy space for any\npower, and global in time continuity for sufficiently large powers. When the\nlinear dispersive rate is counterbalanced by a time-dependent rescaling, we\nshow a uniform in time continuity of the squared modulus of this rescaled\nfunction, in Kantorovich distance, for any power, including long range cases in\nterms of scattering. The most difficult result addresses the convergence of\nsuitably renormalized solutions to the solution of the logarithmic\nSchr{\\\"o}dinger equation, when the power goes to zero, uniformly in time, in\nKantorovich distance. The proof relies on estimates for perturbed porous medium\nequations, involving the harmonic Fokker-Planck operator.", "AI": {"tldr": "The paper analyzes continuity properties of the flow map for defocusing energy-subcritical nonlinear Schr\u00f6dinger equations with varying power, including local/global time continuity and convergence to logarithmic Schr\u00f6dinger equation when power approaches zero.", "motivation": "To understand how the flow map continuity behaves as the nonlinear power parameter varies in Schr\u00f6dinger equations, particularly addressing the challenging case of convergence to the logarithmic Schr\u00f6dinger equation when power goes to zero.", "method": "The proof uses estimates for perturbed porous medium equations involving the harmonic Fokker-Planck operator, and analyzes time-dependent rescalings with uniform continuity in Kantorovich distance.", "result": "Shows local time continuity in energy space for any power, global time continuity for large powers, and uniform convergence of renormalized solutions to logarithmic Schr\u00f6dinger equation when power approaches zero.", "conclusion": "The study establishes comprehensive continuity properties for nonlinear Schr\u00f6dinger equations with varying power parameters, including the delicate limiting case of convergence to the logarithmic equation."}}
{"id": "2509.26186", "pdf": "https://arxiv.org/pdf/2509.26186", "abs": "https://arxiv.org/abs/2509.26186", "authors": ["Chun-Wun Cheng", "Bin Dong", "Carola-Bibiane Sch\u00f6nlieb", "Angelica I Aviles-Rivero"], "title": "PDE Solvers Should Be Local: Fast, Stable Rollouts with Learned Local Stencils", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Neural operator models for solving partial differential equations (PDEs)\noften rely on global mixing mechanisms-such as spectral convolutions or\nattention-which tend to oversmooth sharp local dynamics and introduce high\ncomputational cost. We present FINO, a finite-difference-inspired neural\narchitecture that enforces strict locality while retaining multiscale\nrepresentational power. FINO replaces fixed finite-difference stencil\ncoefficients with learnable convolutional kernels and evolves states via an\nexplicit, learnable time-stepping scheme. A central Local Operator Block\nleverage a differential stencil layer, a gating mask, and a linear fuse step to\nconstruct adaptive derivative-like local features that propagate forward in\ntime. Embedded in an encoder-decoder with a bottleneck, FINO captures\nfine-grained local structures while preserving interpretability. We establish\n(i) a composition error bound linking one-step approximation error to stable\nlong-horizon rollouts under a Lipschitz condition, and (ii) a universal\napproximation theorem for discrete time-stepped PDE dynamics. (iii) Across six\nbenchmarks and a climate modelling task, FINO achieves up to 44\\% lower error\nand up to around 2\\times speedups over state-of-the-art operator-learning\nbaselines, demonstrating that strict locality with learnable time-stepping\nyields an accurate and scalable foundation for neural PDE solvers.", "AI": {"tldr": "FINO is a finite-difference-inspired neural architecture for solving PDEs that enforces strict locality while maintaining multiscale representational power, achieving better accuracy and computational efficiency than global mixing approaches.", "motivation": "Existing neural operator models for PDEs rely on global mixing mechanisms that oversmooth sharp local dynamics and introduce high computational costs.", "method": "FINO replaces fixed finite-difference stencil coefficients with learnable convolutional kernels and uses an explicit, learnable time-stepping scheme. It features a Local Operator Block with differential stencil layer, gating mask, and linear fuse step to construct adaptive derivative-like local features.", "result": "FINO achieves up to 44% lower error and around 2x speedups over state-of-the-art operator-learning baselines across six benchmarks and a climate modeling task.", "conclusion": "Strict locality with learnable time-stepping provides an accurate and scalable foundation for neural PDE solvers, demonstrating that local approaches can outperform global mixing mechanisms."}}
{"id": "2509.26465", "pdf": "https://arxiv.org/pdf/2509.26465", "abs": "https://arxiv.org/abs/2509.26465", "authors": ["Gui-Qiang G. Chen", "Franz Gmeineder", "Monica Torres"], "title": "Curl Measure Fields, the Generalized Stokes Theorem and Vorticity Fluxes", "categories": ["math.AP"], "comment": "10 Figures, 1 Table", "summary": "We introduce and analyze the class $\\mathscr{CM}^{p}$ of curl-measure fields\nthat are $p$-integrable vector fields whose distributional curl is a\nvector-valued finite Radon measure. These spaces provide a unifying framework\nfor problems involving vorticity. A central focus of this paper is the\ndevelopment of Stokes-type theorems in low-regularity regimes, made possible by\nnew trace theorems for curl-measure fields. To this end, we introduce Stokes\nfunctionals on so-called good manifolds, defined by the finiteness of\nmanifold-adapted maximal operators. Using novel techniques that may be of\nindependent interest, we establish results that are new even in classical\nsettings, such as Sobolev spaces or their curl-variants\n$\\mathrm{H}^{\\mathrm{curl}}(\\mathbb{R}^{3})$, which arise, for example, in the\nstudy of Maxwell's equations. The sharpness of our theorems is illustrated\nthrough several fundamental examples.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.26289", "pdf": "https://arxiv.org/pdf/2509.26289", "abs": "https://arxiv.org/abs/2509.26289", "authors": ["Xiaozhou Wang", "Bruno F. Louren\u00e7o", "Ting Kei Pong"], "title": "Error bounds for perspective cones of a class of nonnegative Legendre functions", "categories": ["math.OC", "cs.NA", "math.MG", "math.NA"], "comment": "45 pages, comments welcome", "summary": "Error bounds play a central role in the study of conic optimization problems,\nincluding the analysis of convergence rates for numerous algorithms. Curiously,\nthose error bounds are often H\\\"olderian with exponent 1/2. In this paper, we\ntry to explain the prevalence of the 1/2 exponent by investigating generic\nproperties of error bounds for conic feasibility problems where the underlying\ncone is a perspective cone constructed from a nonnegative Legendre function on\n$\\mathbb{R}$. Our analysis relies on the facial reduction technique and the\ncomputation of one-step facial residual functions (1-FRFs). Specifically, under\nappropriate assumptions on the Legendre function, we show that 1-FRFs can be\ntaken to be H\\\"olderian of exponent 1/2 almost everywhere with respect to the\ntwo-dimensional Hausdorff measure. This enables us to further establish that\nhaving a uniform H\\\"olderian error bound with exponent 1/2 is a generic\nproperty for a class of feasibility problems involving these cones.", "AI": {"tldr": "This paper explains why error bounds in conic optimization often have H\u00f6lder exponent 1/2 by analyzing perspective cones from Legendre functions, showing this property is generic.", "motivation": "To explain the prevalence of the 1/2 exponent in H\u00f6lderian error bounds for conic optimization problems, which is crucial for analyzing algorithm convergence rates.", "method": "Uses facial reduction technique and computation of one-step facial residual functions (1-FRFs) for perspective cones constructed from nonnegative Legendre functions on \u211d.", "result": "Under appropriate assumptions, 1-FRFs are H\u00f6lderian with exponent 1/2 almost everywhere with respect to 2D Hausdorff measure, establishing uniform H\u00f6lderian error bounds with exponent 1/2 as a generic property.", "conclusion": "The 1/2 exponent in error bounds is a generic phenomenon for feasibility problems involving perspective cones from Legendre functions, explaining its frequent appearance in conic optimization."}}
{"id": "2509.26485", "pdf": "https://arxiv.org/pdf/2509.26485", "abs": "https://arxiv.org/abs/2509.26485", "authors": ["Damien Gobin", "Beno\u00eet Gr\u00e9bert", "Bernard Helffer", "Fran\u00e7ois Nicoleau"], "title": "On uniqueness of radial potentials for given Dirichlet spectra with distinct angular momenta", "categories": ["math.AP", "math-ph", "math.MP", "math.SP"], "comment": null, "summary": "We consider an inverse spectral problem for radial Schr\\\" odinger operators\nwith singular potentials. First, we show that the knowledge of the Dirichlet\nspectra for infinitely many angular momenta~$\\ell$ satisfying a M\\\"untz-type\ncondition uniquely determines the potential. Then, in a neighborhood of the\nzero potential, we prove that the potential is uniquely determined by two\nDirichlet spectra associated with distinct angular momenta in the cases\n\\((\\ell_1,\\ell_2) = (0,1)\\) and \\((0,2)\\). Our approach relies on an explicit\nanalysis of the corresponding singular differential equation, combined with the\nclassical Kneser--Sommerfeld formula. These results confirm, in the linearized\nsetting and in these configurations, a conjecture originally formulated by\nRundell and Sacks (2001).", "AI": {"tldr": "The paper solves an inverse spectral problem for radial Schr\u00f6dinger operators with singular potentials, showing that Dirichlet spectra for infinitely many angular momenta uniquely determine the potential, and proving uniqueness with just two spectra near zero potential.", "motivation": "To address the inverse spectral problem for radial Schr\u00f6dinger operators with singular potentials and verify Rundell and Sacks' conjecture about potential determination from spectral data.", "method": "Explicit analysis of singular differential equations combined with the classical Kneser-Sommerfeld formula, using Dirichlet spectra for different angular momenta.", "result": "Proved that: (1) infinitely many angular momenta spectra uniquely determine the potential; (2) near zero potential, two spectra (for angular momenta pairs (0,1) and (0,2)) suffice for unique determination.", "conclusion": "The results confirm Rundell and Sacks' conjecture in linearized settings for specific angular momentum configurations, establishing rigorous uniqueness results for inverse spectral problems."}}
{"id": "2509.26293", "pdf": "https://arxiv.org/pdf/2509.26293", "abs": "https://arxiv.org/abs/2509.26293", "authors": ["Harshith Gowrachari", "Mattia Giuseppe Barra", "Giovanni Stabile", "Gianluca Bazzaro", "Gianluigi Rozza"], "title": "Reservoir computing based predictive reduced order model for steel grade intermixing in an industrial continuous casting tundish", "categories": ["physics.flu-dyn", "cs.NA", "math.NA"], "comment": null, "summary": "Continuous casting is a widely adopted process in the steel industry, where\nmaintaining high steel quality is paramount. Efficient prediction of grade\nintermixing during ladle changeover operations is critical for maintaining\nsteel quality and minimizing material losses in the continuous casting process.\nAmong various factors influencing grade intermixing, operating parameters play\na significant role, in addition to tundish geometry and flow control devices.\nIn this study, three-dimensional, transient, two-phase turbulent flow\nsimulations are conducted to investigate the ladle changeover operation. During\nthis process, the molten steel level in the tundish typically varies over time,\nsignificantly affecting the grade intermixing phenomena. The influence of ladle\nchange time on intermixing time has been presented. However, high-fidelity\nfull-order simulations of such complex transient phenomena are computationally\nexpensive and are impractical for real-time monitoring or design-space\nexploration in industrial-scale applications. To address this issue, a reduced\norder modelling approach based on proper orthogonal decomposition (POD) and\nreservoir computing (RC) is employed to efficiently predict intermixing time.\nThe proposed reduced order model (ROM) demonstrates excellent predictive\naccuracy using limited training data while requiring significantly less\ncomputational resources and training time. The results demonstrate the\npotential of the proposed methodology as a fast, reliable tool for real-time\nprocess monitoring and optimization in industrial continuous casting\noperations.", "AI": {"tldr": "A reduced order model combining proper orthogonal decomposition and reservoir computing is developed to efficiently predict grade intermixing time during ladle changeover in continuous casting, enabling real-time monitoring with high accuracy and low computational cost.", "motivation": "High-fidelity simulations of grade intermixing during ladle changeover are computationally expensive and impractical for real-time monitoring in industrial continuous casting operations.", "method": "Three-dimensional transient two-phase turbulent flow simulations combined with a reduced order modeling approach using proper orthogonal decomposition (POD) and reservoir computing (RC).", "result": "The ROM demonstrates excellent predictive accuracy with limited training data while requiring significantly less computational resources and training time compared to full-order simulations.", "conclusion": "The proposed methodology shows potential as a fast, reliable tool for real-time process monitoring and optimization in industrial continuous casting operations."}}
{"id": "2509.26526", "pdf": "https://arxiv.org/pdf/2509.26526", "abs": "https://arxiv.org/abs/2509.26526", "authors": ["Franz Gmeineder", "Endre S\u00fcli", "Tabea Tscherpel"], "title": "On Korn inequalities with lower order trace terms", "categories": ["math.AP", "35A23, 35E20, 42B37, 46-04"], "comment": "24 pages, 3 figures, 1 table", "summary": "We give an elementary estimate that entails and generalises numerous Korn\ninequalities scattered in the literature. As special instances, we obtain\ngeneral Korn-type inequalities involving normal or tangential trace components,\nor lower dimensional trace integrals.", "AI": {"tldr": "Elementary estimate generalizing various Korn inequalities from literature, including inequalities with normal/tangential trace components and lower dimensional trace integrals.", "motivation": "To provide a unified framework that encompasses and extends numerous scattered Korn inequalities found in the literature.", "method": "Developed an elementary estimate that serves as a generalization tool for various Korn-type inequalities.", "result": "Successfully derived a general estimate that yields Korn-type inequalities involving normal/tangential trace components and lower dimensional trace integrals as special cases.", "conclusion": "The elementary estimate provides a comprehensive framework that unifies and extends existing Korn inequalities, offering broader applicability in mathematical analysis."}}
{"id": "2509.26565", "pdf": "https://arxiv.org/pdf/2509.26565", "abs": "https://arxiv.org/abs/2509.26565", "authors": ["Davide Giovagnoli", "David Jesus", "Luis Silvestre"], "title": "$C^{1+\u03b1}$ regularity for fractional $p$-harmonic functions", "categories": ["math.AP", "35B65, 35J70, 35R09"], "comment": null, "summary": "We establish interior $C^{1,\\alpha}$ regularity estimates for some $\\alpha >\n0$, for solutions of the fractional $p$-Laplace equation $(-\\Delta_p)^s u = 0$\nwhen $p$ is in the range $p \\in [2,2/(1-s))$.", "AI": {"tldr": "Interior C^{1,\u03b1} regularity estimates for solutions of fractional p-Laplace equations when p \u2208 [2,2/(1-s))", "motivation": "To establish higher regularity estimates for solutions of fractional p-Laplace equations, extending classical regularity theory to the nonlocal setting", "method": "Mathematical analysis of the fractional p-Laplace operator (-\u0394_p)^s u = 0, focusing on the parameter range p \u2208 [2,2/(1-s))", "result": "Proved interior C^{1,\u03b1} regularity for some \u03b1 > 0 for solutions in the specified parameter range", "conclusion": "Solutions of fractional p-Laplace equations exhibit C^{1,\u03b1} interior regularity when p is in the range [2,2/(1-s)), providing important regularity results for this class of nonlocal equations"}}
{"id": "2509.26590", "pdf": "https://arxiv.org/pdf/2509.26590", "abs": "https://arxiv.org/abs/2509.26590", "authors": ["Oussama Landoulsi", "Sohrab Shahshahani"], "title": "The distorted Fourier transform for the linearized Gross-Pitaevskii equation in the Hyperbolic plane", "categories": ["math.AP"], "comment": null, "summary": "Motivated by the stability problem for Ginzburg-Landau vortices on the\nhyperbolic plane, we develop the distorted Fourier transform for a general\nclass of radial non-self-adjoint matrix Schr\\\"odinger operators on the\nhyperbolic plane. This applies in particular to the operator obtained by\nlinearizing the equivariant Ginzburg-Landau equation on the hyperbolic plane\naround the degree one vortex. We systematically\n  construct the distorted Fourier transform by writing the Stone formula for\ncomplex energies and taking the limit as the energy tends to the spectrum of\nthe operator on the real line. This approach entails a careful analysis of the\nresolvent for complex energies in a neighborhood of the real line. It is the\nanalogue of the approaches used in \\cite{KS,ES2, LSS25}, where the limiting\noperator as $r\\to\\infty$ is not self-adjoint and which we carry out for all\nenergies. Our analysis serves as the starting point for the study of the\nstability of the Ginzburg-Landau vortex under equivariant perturbations.", "AI": {"tldr": "Developed distorted Fourier transform for radial non-self-adjoint matrix Schr\u00f6dinger operators on hyperbolic plane, motivated by Ginzburg-Landau vortex stability problem.", "motivation": "Study stability problem for Ginzburg-Landau vortices on hyperbolic plane, particularly linearizing equivariant Ginzburg-Landau equation around degree one vortex.", "method": "Systematically construct distorted Fourier transform using Stone formula for complex energies, taking limit as energy approaches real spectrum. Carefully analyze resolvent for complex energies near real line.", "result": "Successfully developed distorted Fourier transform framework for general class of radial non-self-adjoint matrix Schr\u00f6dinger operators on hyperbolic plane.", "conclusion": "This analysis provides foundation for studying stability of Ginzburg-Landau vortex under equivariant perturbations, extending approaches from previous works to non-self-adjoint limiting operators."}}
{"id": "2509.25965", "pdf": "https://arxiv.org/pdf/2509.25965", "abs": "https://arxiv.org/abs/2509.25965", "authors": ["Jianbo Cui", "Tonghe Dang"], "title": "Hamilton--Jacobi--Bellman equation for optimal control of stochastic Wasserstein--Hamiltonian system on graphs", "categories": ["math.OC", "math.AP", "math.PR", "49L25, 35R02, 93E20, 35Q55, 60H30"], "comment": "43 pages", "summary": "Stochastic optimal control problems for Hamiltonian dynamics on graphs have\nwide-ranging applications in mechanics and quantum field theory, particularly\nin systems with graph-based structures. In this paper, we establish the\nexistence and uniqueness of viscosity solutions for a new class of\nHamilton--Jacobi--Bellman (HJB) equations arising from the optimal control of\nstochastic Wasserstein--Hamiltonian systems (SWHSs) on graphs. One distinctive\nfeature of these HJB equations is the simultaneous involvement of the\nWasserstein geometry on the Wasserstein space over graphs and the Euclidean\ngeometry in physical space. The nonlinear geometric structure, along with the\nlogarithmic potential induced by the graph-based state equation, adds further\ncomplexity to the analysis. To address these challenges, we introduce an\nenergy-truncation technique within the doubling of variables framework,\nspecifically designed to handle the interaction between the interiorly defined\nWasserstein space on graphs and the unbounded Euclidean space. In particular,\nour findings demonstrate the well-posedness of HJB equations related to optimal\ncontrol problems for both stochastic Schr\\\"odinger equation with polynomial\nnonlinearity and stochastic logarithmic Schr\\\"odinger equation on graphs. To\nthe best of our knowledge, this work is the first to develop HJB equations for\nthe optimal control of SWHSs on graphs.", "AI": {"tldr": "Establishes existence and uniqueness of viscosity solutions for Hamilton-Jacobi-Bellman equations in optimal control of stochastic Wasserstein-Hamiltonian systems on graphs, combining Wasserstein and Euclidean geometries.", "motivation": "Address optimal control problems for Hamiltonian dynamics on graphs with applications in mechanics and quantum field theory, particularly for systems with graph-based structures.", "method": "Introduces energy-truncation technique within doubling of variables framework to handle interaction between Wasserstein space on graphs and unbounded Euclidean space, dealing with nonlinear geometric structure and logarithmic potential.", "result": "Demonstrates well-posedness of HJB equations for optimal control of both stochastic Schr\u00f6dinger equation with polynomial nonlinearity and stochastic logarithmic Schr\u00f6dinger equation on graphs.", "conclusion": "First development of HJB equations for optimal control of stochastic Wasserstein-Hamiltonian systems on graphs, providing theoretical foundation for controlling such complex systems."}}
{"id": "2509.25993", "pdf": "https://arxiv.org/pdf/2509.25993", "abs": "https://arxiv.org/abs/2509.25993", "authors": ["Yurong Wei", "Huaqiao Wang"], "title": "Weak Martingale Solutions of the Stochastic Schr\u00f6dinger-Poisson-Landau-Lifshitz-Gilbert System", "categories": ["math.PR", "math.AP"], "comment": "48 pages", "summary": "The Schr\\\"{o}dinger-Poisson-Landau-Lifshitz-Gilbert (SPLLG) system can\ncharacterize the spin transfer torque mechanism transferring the spin angular\nmomentum to the magnetization dynamics through spin-magnetization coupling. We\nstudy the three-dimensional stochastic SPLLG system driven by a multiplicative\nstochastic force containing a continuous noise and a small jump noise. We\nestablish the existence of weak martingale solutions based on the penalized\nfunctional technique, the Faedo-Galerkin approximation, stochastic compactness\nmethod, and a careful identification of the limit. Due to the strong coupling\nand strong nonlinearity caused by the SPLLG system and stochastic effects, some\ncrucial difficulties have been encountered in obtaining energy estimates and\navoiding non-negativity of the test function. We mainly utilize the structure\nof equations and the property of martingales developing the new energy\nestimates, and apply the three-layer approximation to overcome these\ndifficulties. In particular, we extend the results by Z. Brze\\'{z}niak and U.\nManna (Comm. Math. Phys., 2019) and by L.H. Chai, C.J. Garc\\'{\\i}a-Cervera and\nX. Yang (Arch. Ration. Mech. Anal., 2018) to both the stochastic case and the\ncoupling case.", "AI": {"tldr": "Existence of weak martingale solutions for 3D stochastic SPLLG system with continuous and jump noise, extending previous deterministic results to stochastic coupling case.", "motivation": "Study spin transfer torque mechanism through spin-magnetization coupling in stochastic SPLLG system with multiplicative noise containing both continuous and jump components.", "method": "Penalized functional technique, Faedo-Galerkin approximation, stochastic compactness method, three-layer approximation, new energy estimates using equation structure and martingale properties.", "result": "Established existence of weak martingale solutions for the strongly coupled and nonlinear stochastic SPLLG system despite difficulties with energy estimates and test function non-negativity.", "conclusion": "Successfully extended deterministic results by Brze\u017aniak & Manna and Chai et al. to both stochastic and coupling cases, overcoming challenges from strong nonlinearity and coupling effects."}}
{"id": "2509.26035", "pdf": "https://arxiv.org/pdf/2509.26035", "abs": "https://arxiv.org/abs/2509.26035", "authors": ["B. Costeri", "C. Dappiaggi", "B. A. Ju\u00e1rez-Aubry", "R. D. Singh"], "title": "The Hadamard parametrix on half-Minkowski with Robin boundary conditions: Fundamental solutions and Hadamard states", "categories": ["math-ph", "hep-th", "math.AP", "math.MP"], "comment": "41 pages", "summary": "We address the problem of constructing fundamental solutions and Hadamard\nstates for a Klein-Gordon field in half-Minkowski spacetime with Robin boundary\nconditions in $d \\geq 2$ spacetime dimensions. First, using a generalisation of\nthe Robin-to-Dirichlet map exploited by Bondurant and Fulling [J. Phys. A:\nMath. Theor. {\\bf 38} 7 (2005)] in dimension $2$, we obtain a representation\nfor the advanced and retarded Green operators in terms of a convolution with\nthe kernel of the inverse Robin-to-Dirichlet map. This allows us to prove the\nuniqueness and support properties of the Green operators. Second, we obtain a\nlocal representation for the Hadamard parametrix that provides the correct\nlocal definition of Hadamard states in $d \\geq 2$ dimensions, capturing\n`reflected' singularities from the spacetime boundary. We show that our\nfundamental solutions abide by this local parametrix representation. Finally,\nwe prove the equivalence of our local Hadamard condition and the global\nHadamard condition with a wave-front set described in terms of generalized\nbroken bi-characteristics, obtaining a Radzikowski-like theorem in\nhalf-Minkowski spacetime.", "AI": {"tldr": "Construction of fundamental solutions and Hadamard states for Klein-Gordon field in half-Minkowski spacetime with Robin boundary conditions in d\u22652 dimensions, including Green operators representation and local/global Hadamard condition equivalence.", "motivation": "To address the problem of constructing fundamental solutions and defining Hadamard states for Klein-Gordon fields in half-Minkowski spacetime with Robin boundary conditions, which is important for quantum field theory in bounded domains.", "method": "Used generalization of Robin-to-Dirichlet map to obtain Green operator representations via convolution with inverse map kernel, developed local Hadamard parametrix capturing boundary reflections, and proved equivalence between local and global Hadamard conditions.", "result": "Successfully constructed fundamental solutions with proven uniqueness and support properties, obtained local Hadamard parametrix representation that captures boundary reflections, and established equivalence between local and global Hadamard conditions (Radzikowski-like theorem).", "conclusion": "The paper provides a complete framework for fundamental solutions and Hadamard states in half-Minkowski spacetime with Robin boundary conditions, with rigorous mathematical foundations for both local and global properties."}}
{"id": "2509.26395", "pdf": "https://arxiv.org/pdf/2509.26395", "abs": "https://arxiv.org/abs/2509.26395", "authors": ["Ugo Boscain", "Xiangyu Ma", "Dario Prandi", "Giuseppina Turco"], "title": "A solution to the mystery of the sub-harmonic series and to the combination tone via a linear mathematical model of the cochlea", "categories": ["eess.SP", "math.AP", "physics.bio-ph", "physics.class-ph", "physics.med-ph"], "comment": null, "summary": "In this paper, we study a simple linear model of the cochlea as a set of\nvibrating strings. We make hypothesis that the information sent to the auditory\ncortex is the energy stored in the strings and consider all oscillation modes\nof the strings. We show the emergence of the sub-harmonic series whose\nexistence was hypothesized in the XVI century to explain the consonance of the\nminor chord. We additionally show how the nonlinearity of the energy can be\nused to study the emergence of the combination tone (Tartini's third sound)\nshedding new light on this long debated subject.", "AI": {"tldr": "A linear cochlea model using vibrating strings shows emergence of sub-harmonic series explaining minor chord consonance and combination tones.", "motivation": "To understand how the cochlea processes sound information and explain historical musical phenomena like minor chord consonance and Tartini's third sound.", "method": "Modeling the cochlea as a set of vibrating strings, analyzing energy stored in strings across all oscillation modes using a linear model approach.", "result": "Demonstrated emergence of sub-harmonic series that explains minor chord consonance, and showed how nonlinear energy characteristics can explain combination tones (Tartini's third sound).", "conclusion": "The simple linear cochlea model successfully explains long-debated musical phenomena, providing new insights into auditory processing and historical music theory concepts."}}
