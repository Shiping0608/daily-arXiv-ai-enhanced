{"id": "2510.00221", "pdf": "https://arxiv.org/pdf/2510.00221", "abs": "https://arxiv.org/abs/2510.00221", "authors": ["Nicola De Nitti", "Kuang Huang"], "title": "Asymptotically compatible entropy-consistent discretization for a class of nonlocal conservation laws", "categories": ["math.NA", "cs.NA", "math.AP", "35L65"], "comment": null, "summary": "We consider a class of nonlocal conservation laws modeling traffic flows,\ngiven by $ \\partial_t \\rho_\\varepsilon + \\partial_x(V(\\rho_\\varepsilon \\ast\n\\gamma_\\varepsilon) \\rho_\\varepsilon) = 0 $ with a suitable convex kernel $\n\\gamma_\\varepsilon $, and its Godunov-type numerical discretization. We prove\nthat, as the nonlocal parameter $ \\varepsilon $ and mesh size $ h $ tend to\nzero simultaneously, the discrete approximation $ W_{\\varepsilon,h} $ of $\nW_\\varepsilon := \\rho_\\varepsilon \\ast \\gamma_\\varepsilon $ converges to the\nentropy solution of the (local) scalar conservation law $ \\partial_t \\rho +\n\\partial_x(V(\\rho) \\rho) = 0 $, with an explicit convergence rate estimate of\norder $ \\varepsilon+h+\\sqrt{\\varepsilon\\, t}+\\sqrt{h\\,t} $. In particular, with\nan exponential kernel, we establish the same convergence result for the\ndiscrete approximation $ \\rho_{\\varepsilon,h} $ of $ \\rho_\\varepsilon $, along\nwith an $ \\mathrm{L}^1 $-contraction property for $ W_\\varepsilon $. The key\ningredients in proving these results are uniform $ \\mathrm{L}^\\infty $- and\n$\\mathrm{TV}$-estimates that ensure compactness of approximate solutions, and\ndiscrete entropy inequalities that ensure the entropy admissibility of the\nlimit solution.", "AI": {"tldr": "The paper analyzes convergence of numerical approximations for nonlocal traffic flow conservation laws to local conservation laws, with explicit convergence rates.", "motivation": "To establish rigorous convergence results for numerical discretizations of nonlocal conservation laws modeling traffic flows, showing they converge to solutions of local conservation laws as nonlocal parameters and mesh sizes vanish.", "method": "Uses Godunov-type numerical discretization for nonlocal conservation laws with convex kernels, proving uniform L\u221e- and TV-estimates for compactness and discrete entropy inequalities for entropy admissibility.", "result": "Proves discrete approximations converge to entropy solutions of local conservation laws with explicit convergence rate of order \u03b5+h+\u221a(\u03b5t)+\u221a(ht), and establishes L\u00b9-contraction for W\u03b5 with exponential kernels.", "conclusion": "The numerical scheme provides a reliable approximation framework for nonlocal traffic flow models, with proven convergence to local conservation law solutions under appropriate parameter limits."}}
{"id": "2510.00354", "pdf": "https://arxiv.org/pdf/2510.00354", "abs": "https://arxiv.org/abs/2510.00354", "authors": ["Shicheng Liu", "Qilong Zhai"], "title": "A posteriori error estimation for weak Galerkin method of the fourth-order singularly perturbed problem", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we present a posteriori error estimation for weak Galerkin\nmethod applied to fourth order singularly perturbed problem. The weak Galerkin\ndiscretization space and numerical scheme are first described. A fully\ncomputable residual type error estimator is then constructed. Both the\nreliability and efficiency of the proposed estimator are rigorously\ndemonstrated. Numerical experiments are provided to validate the theoretical\nfindings.", "AI": {"tldr": "Posteriori error estimation for weak Galerkin method applied to fourth order singularly perturbed problems", "motivation": "To develop reliable error estimation for weak Galerkin methods in solving fourth order singularly perturbed problems", "method": "Constructed a fully computable residual type error estimator for weak Galerkin discretization", "result": "Proved both reliability and efficiency of the proposed error estimator", "conclusion": "Numerical experiments validated the theoretical findings for the error estimator"}}
{"id": "2510.00393", "pdf": "https://arxiv.org/pdf/2510.00393", "abs": "https://arxiv.org/abs/2510.00393", "authors": ["Buyang Li", "Qiqi Rao", "Hui Zhang", "Zhi Zhou"], "title": "Numerical analysis of 2D Navier--Stokes equations with nonsmooth initial value in the critical space", "categories": ["math.NA", "cs.NA", "65M12, 65M15, 76D05"], "comment": "27 pages", "summary": "This paper addresses the numerical solution of the two-dimensional\nNavier--Stokes (NS) equations with nonsmooth initial data in the $L^2$ space,\nwhich is the critical space for the two-dimensional NS equations to be\nwell-posed. In this case, the solutions of the NS equations exhibit certain\nsingularities at $t=0$, e.g., the $H^s$ norm of the solution blows up as\n$t\\rightarrow 0$ when $s>0$. To date, the best convergence result proved in the\nliterature are first-order accuracy in both time and space for the\nsemi-implicit Euler time-stepping scheme and divergence-free finite elements\n(even high-order finite elements are used), while numerical results demonstrate\nthat second-order convergence in time and space may be achieved. Therefore,\nthere is still a gap between numerical analysis and numerical computation for\nthe NS equations with $L^2$ initial data. The primary challenge to realizing\nhigh-order convergence is the insufficient regularity in the solutions due to\nthe rough initial condition and the nonlinearity of the equations. In this\nwork, we propose a fully discrete numerical scheme that utilizes the\nTaylor--Hood or Stokes-MINI finite element method for spatial discretization\nand an implicit-explicit Runge--Kutta time-stepping method in conjunction with\ngraded stepsizes. By employing discrete semigroup techniques, sharp regularity\nestimates, negative norm estimates and the $L^2$ projection onto the\ndivergence-free Raviart--Thomas element space, we prove that the proposed\nscheme attains second-order convergence in both space and time. Numerical\nexamples are presented to support the theoretical analysis. In particular, the\nconvergence in space is at most second order even higher-order finite elements\nare used. This shows the sharpness of the convergence order proved in this\narticle.", "AI": {"tldr": "This paper presents a fully discrete numerical scheme for 2D Navier-Stokes equations with nonsmooth L\u00b2 initial data, achieving second-order convergence in both space and time through graded time steps and discrete semigroup techniques.", "motivation": "There is a gap between numerical analysis and computation for NS equations with L\u00b2 initial data - while numerical results show second-order convergence, existing analysis only proves first-order accuracy. Solutions exhibit singularities at t=0 due to rough initial conditions.", "method": "Uses Taylor-Hood or Stokes-MINI finite elements for spatial discretization, implicit-explicit Runge-Kutta time-stepping with graded stepsizes, discrete semigroup techniques, sharp regularity estimates, negative norm estimates, and L\u00b2 projection onto divergence-free Raviart-Thomas element space.", "result": "The proposed scheme achieves second-order convergence in both space and time, which is verified by numerical examples. The convergence in space is at most second order even with higher-order finite elements, showing the sharpness of the proved convergence order.", "conclusion": "The work successfully bridges the gap between numerical analysis and computation for NS equations with L\u00b2 initial data by developing a method that theoretically proves second-order convergence, matching what was previously only observed numerically."}}
{"id": "2510.00511", "pdf": "https://arxiv.org/pdf/2510.00511", "abs": "https://arxiv.org/abs/2510.00511", "authors": ["Hua Shen", "Bangwei She"], "title": "A multi-resolution limiter for the Runge-Kutta discontinuous Galerkin method", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We propose a novel multi-resolution (MR) limiter for the Runge-Kutta\ndiscontinuous Galerkin (RKDG) method for solving hyperbolic conservation laws\non a general unstructured mesh. Unlike classical limiters, which detects only\nsolution discontinuities to dichotomize cells into good or troubled, the\nproposed MR limiter also takes into account the derivative discontinuities to\ndivide cells into several groups. The method operates by performing a\nsuccessive comparison of the local DG polynomial's derivatives, from high-order\nto low-order, against a baseline constructed from neighboring cell averages. If\na $k$th-order derivative of the DG polynomial is larger than the baseline,\n  then we reduce the order to $k-1$ and set the corresponding $k$th-order terms\nto be 0; Otherwise, the remaining $k$th-order DG polynomial is used to\nrepresent the final solution. Only if all the derivatives are larger than the\nbaseline, a TVD slope limiter is used to reconstruct the solution. In this\nmanner, the limiter dynamically selects an optimal polynomial suited to the\nlocal solution smoothness without problem-dependent parameter to tune. Notably,\nit also possesses a scale-invariance property that is absent in most classical\nlimiters. A series of numerical examples demonstrate the accuracy and\nrobustness of the proposed MR limiter.", "AI": {"tldr": "A multi-resolution limiter for RKDG methods that dynamically adjusts polynomial order based on local solution smoothness by comparing derivatives against neighbor-based baselines.", "motivation": "Classical limiters only detect solution discontinuities and dichotomize cells, lacking sensitivity to derivative discontinuities and requiring parameter tuning.", "method": "Successively compares DG polynomial derivatives from high to low order against neighbor-based baselines. Reduces polynomial order when derivatives exceed baseline, otherwise keeps current order. Uses TVD limiter only when all derivatives exceed baseline.", "result": "The limiter achieves optimal polynomial selection for local smoothness without parameter tuning, exhibits scale-invariance, and demonstrates accuracy and robustness in numerical tests.", "conclusion": "The proposed MR limiter provides an effective, parameter-free approach for handling solution and derivative discontinuities in RKDG methods while maintaining accuracy and robustness."}}
{"id": "2510.00146", "pdf": "https://arxiv.org/pdf/2510.00146", "abs": "https://arxiv.org/abs/2510.00146", "authors": ["Alessio Porretta", "Philippe Souplet"], "title": "Classification of solutions of an elliptic Hamilton-Jacobi equation", "categories": ["math.AP"], "comment": null, "summary": "We show that any classical solution of the diffusive Hamilton-Jacobi (DHJ)\nequation $-\\Delta u= |\\nabla u|^p$ in a half-space with zero boundary\nconditions for $1<p\\le 2$ is necessarily one-dimensional. This improves the\npreviously known result, which required an extra assumption of boundedness from\nabove. Combined with the existing analogous result for $p>2$, our result\ncompletes the full classification picture of the Dirichlet problem for equation\n(DHJ) in a half-space.", "AI": {"tldr": "The paper proves that all classical solutions of the diffusive Hamilton-Jacobi equation in a half-space with zero boundary conditions are one-dimensional for 1<p\u22642, removing the previous boundedness assumption.", "motivation": "To complete the classification of Dirichlet problem solutions for the diffusive Hamilton-Jacobi equation in half-spaces by extending the result to the range 1<p\u22642 without requiring boundedness assumptions.", "method": "Mathematical analysis of the diffusive Hamilton-Jacobi equation -\u0394u = |\u2207u|^p in half-spaces with zero boundary conditions, building on existing techniques but removing the boundedness constraint.", "result": "Showed that any classical solution for 1<p\u22642 is necessarily one-dimensional, improving previous results that required boundedness from above.", "conclusion": "This result, combined with existing results for p>2, completes the full classification of Dirichlet problem solutions for the diffusive Hamilton-Jacobi equation in half-spaces."}}
{"id": "2510.00282", "pdf": "https://arxiv.org/pdf/2510.00282", "abs": "https://arxiv.org/abs/2510.00282", "authors": ["George Miloshevich", "Luka Vranckx", "Felipe Nathan de Oliveira Lopes", "Pietro Dazzi", "Giuseppe Arr\u00f2", "Giovanni Lapenta"], "title": "Electron neural closure for turbulent magnetosheath simulations: energy channels", "categories": ["physics.plasm-ph", "cs.LG", "physics.comp-ph"], "comment": "16 pages, 9 figures, 4 tables", "summary": "In this work, we introduce a non-local five-moment electron pressure tensor\nclosure parametrized by a Fully Convolutional Neural Network (FCNN). Electron\npressure plays an important role in generalized Ohm's law, competing with\nelectron inertia. This model is used in the development of a surrogate model\nfor a fully kinetic energy-conserving semi-implicit Particle-in-Cell simulation\nof decaying magnetosheath turbulence. We achieve this by training FCNN on a\nrepresentative set of simulations with a smaller number of particles per cell\nand showing that our results generalise to a simulation with a large number of\nparticles per cell. We evaluate the statistical properties of the learned\nequation of state, with a focus on pressure-strain interaction, which is\ncrucial for understanding energy channels in turbulent plasmas. The resulting\nequation of state learned via FCNN significantly outperforms local closures,\nsuch as those learned by Multi-Layer Perceptron (MLP) or double adiabatic\nexpressions. We report that the overall spatial distribution of pressure-strain\nand its conditional averages are reconstructed well. However, some small-scale\nfeatures are missed, especially for the off-diagonal components of the pressure\ntensor. Nevertheless, the results are substantially improved with more training\ndata, indicating favorable scaling and potential for improvement, which will be\naddressed in future work.", "AI": {"tldr": "A non-local five-moment electron pressure tensor closure using Fully Convolutional Neural Network (FCNN) is developed for magnetosheath turbulence simulations, outperforming local closures and showing good reconstruction of pressure-strain interactions.", "motivation": "Electron pressure plays a crucial role in generalized Ohm's law and competes with electron inertia, making accurate pressure tensor closures essential for understanding energy channels in turbulent plasmas.", "method": "Trained FCNN on representative simulations with fewer particles per cell and validated generalization to simulations with more particles per cell, focusing on pressure-strain interaction for energy channel analysis.", "result": "The FCNN-learned equation of state significantly outperforms local closures (MLP and double adiabatic expressions), reconstructs overall spatial distribution of pressure-strain well, though misses some small-scale off-diagonal pressure tensor features.", "conclusion": "The method shows favorable scaling with more training data, indicating potential for improvement in capturing small-scale features, which will be addressed in future work."}}
{"id": "2510.00152", "pdf": "https://arxiv.org/pdf/2510.00152", "abs": "https://arxiv.org/abs/2510.00152", "authors": ["Joanna Piper Morgan", "Ilham Variansyah", "Kayla B. Clements", "Todd S. Palmer", "Kyle E. Niemeyer"], "title": "Hybrid Delta Tracking Schemes Using a Track-Length Estimator", "categories": ["physics.comp-ph"], "comment": "28 pages, 12 figures", "summary": "In Monte Carlo radiation transport calculations, Woodcock-delta tracking is a\ncommon alternative to the more popular surface tracking technique. In this work\nwe introduce a delta-tracking algorithm that tallies fluxes to a structured\nrectilinear mesh using the track-length estimator. This development also\nenables hybrid surface-delta tracking algorithms, because the track-length\ntally can be used everywhere for scalar flux estimation regardless of which\ntracking algorithm is employed. We use this tallying technique to develop a\nnovel hybrid-in-energy method. We also implement a hybrid-in-material method,\nlike what is implemented in Serpent2. We demonstrate that these delta tracking\nalgorithms can be used in conjunction with continuously moving surfaces. We\ncompare these methods showing figures of merit on four time-dependent problems\n(multi-group and continuous energy) solved with CPU- and GPU-based computers.\nOur implementation of delta tracking with a track length tally modestly\nimproves figures of merit compared to standard delta tracking with a collision\nestimator and surface tracking with a track length estimator (1.5X 2.5X) for a\nproblem with significant void regions. For both multi-group and continuous\nenergy pressurized water reactor benchmarks, standard delta tracking with a\ncollision estimator performs best. Hybrid-in-energy methods show significant\nimprovements (7X-11X) for a continuous energy reactor benchmark problem.", "AI": {"tldr": "This paper introduces a delta-tracking algorithm with track-length estimator for Monte Carlo radiation transport, enabling hybrid surface-delta tracking methods and showing performance improvements in various reactor benchmarks.", "motivation": "To develop improved delta-tracking algorithms for Monte Carlo radiation transport that can tally fluxes to structured meshes using track-length estimators, enabling hybrid methods and better performance.", "method": "Developed delta-tracking algorithm with track-length estimator for structured rectilinear mesh, implemented hybrid-in-energy and hybrid-in-material methods, and tested with continuously moving surfaces on CPU/GPU systems.", "result": "Delta tracking with track-length tally modestly improved figures of merit (1.5X-2.5X) for void regions. Standard delta tracking with collision estimator performed best for PWR benchmarks. Hybrid-in-energy methods showed significant improvements (7X-11X) for continuous energy reactor benchmark.", "conclusion": "The new delta-tracking algorithms with track-length estimators enable effective hybrid methods and show performance improvements, particularly hybrid-in-energy methods for continuous energy reactor problems."}}
{"id": "2510.00516", "pdf": "https://arxiv.org/pdf/2510.00516", "abs": "https://arxiv.org/abs/2510.00516", "authors": ["Xinyi Guan", "Jiayi Hu", "Lei Zhang", "Shaoqiang Tang", "Wing Kam Liu"], "title": "Time-marching multi-level variational multiscale tensor decomposition algorithm for heat conduction with moving heat source", "categories": ["math.NA", "cs.NA", "65M60, 80M10"], "comment": "27 pages, 17 figures", "summary": "In this paper, we propose a time-marching multi-level Variational\nMultiscale-Tensor Decomposition (VMS-TD) algorithm to solve the heat equation\nwith a moving heat source model that arises from additive manufacturing. First,\nwe take a second-order centered difference for time semi-discretization. The\ntemperature field is decomposed according to multiple space resolution levels,\neach represented by the TD method. Then we adopt the VMS formulation [T.J.R.\nHughes, G.R. Feijoo, L. Mazzei, J.B. Quincy. Comput. Methods Appl. Mech. Engrg.\n166:3-24 (1998)] for the resulting elliptic problem to obtain a Galerkin weak\nform, and design VMS-TD algorithm to solve it. Furthermore, to comply with the\nTD solution scheme, special inter-scale data transfers are made at the scale\ninterface and moving fine-scale subdomains. Numerical results demonstrate that\nthe multi-level VMS-TD algorithm is much more efficient than the fully resolved\nTD algorithm, let alone traditional direct numerical simulation methods such as\nfinite difference or finite element analysis. Compared with the well-known\nmulti-grid methods or more recent GO-MELT framework [J.P. Leonor, G.J. Wagner.\nComput. Methods Appl. Mech. Engrg, 426:116977 (2024)], the three-level VMS-TD\nuses much smaller degrees of freedom to reach accurate results. A\nmulti-time-scale extension of VMS-TD algorithm is also proposed.", "AI": {"tldr": "A multi-level VMS-TD algorithm for efficient simulation of heat equation with moving heat source in additive manufacturing, combining variational multiscale formulation with tensor decomposition.", "motivation": "To develop an efficient computational method for simulating heat transfer in additive manufacturing processes with moving heat sources, overcoming computational limitations of traditional methods.", "method": "Time-marching approach with second-order centered difference time discretization, multi-level space resolution using tensor decomposition, VMS formulation for elliptic problems, and special inter-scale data transfers at scale interfaces.", "result": "Multi-level VMS-TD algorithm is significantly more efficient than fully resolved TD algorithms and traditional methods, requiring much smaller degrees of freedom while maintaining accuracy compared to multi-grid methods and GO-MELT framework.", "conclusion": "The proposed VMS-TD algorithm provides an efficient and accurate computational framework for additive manufacturing simulations, with potential for multi-time-scale extensions."}}
{"id": "2510.00173", "pdf": "https://arxiv.org/pdf/2510.00173", "abs": "https://arxiv.org/abs/2510.00173", "authors": ["Alfredo S. Gamboa", "Juan Limaco", "Luis P. Yapu"], "title": "Stackelberg-Nash strategy for the null controllability of semilinear degenerate equations in non-cylindrical domains", "categories": ["math.AP"], "comment": "arXiv admin note: text overlap with arXiv:2509.19505", "summary": "In this paper we use a Stackelberg-Nash strategy to show the local null\ncontrollability of a semilinear parabolic equation in one-dimension defined in\na non-cylindrical domain where the diffusion coefficient degenerates at one\npoint of the boundary. The linearized degenerated system is treated using a\nCarleman inequality for degenerated non-autonomous systems proved by the autors\nin [19] and the local controllability of the semilinear system is obtained\nusing Liusterniks inverse function theorem.", "AI": {"tldr": "Local null controllability of semilinear parabolic equations in degenerated non-cylindrical domains using Stackelberg-Nash strategy", "motivation": "To study controllability of semilinear parabolic equations where diffusion coefficient degenerates at boundary points in non-cylindrical domains", "method": "Stackelberg-Nash strategy, Carleman inequality for degenerated non-autonomous systems, and Liusternik's inverse function theorem", "result": "Proved local null controllability for the semilinear degenerated system", "conclusion": "Successfully established local controllability using combined analytical techniques for degenerated parabolic systems"}}
{"id": "2510.00388", "pdf": "https://arxiv.org/pdf/2510.00388", "abs": "https://arxiv.org/abs/2510.00388", "authors": ["M. W. C. Dharma-wardana"], "title": "A study of the electronic and ionic structure, for co-existing states of fully and partially ionized hydrogen, using the neutral pseudo-atom method as well as a classical map for the electron subsystem", "categories": ["physics.plasm-ph", "cond-mat.stat-mech"], "comment": "Submitted to special issue: Contributions ro Plasma Physics, Bonitz\n  Felicitation volume", "summary": "Prof. Michael Bonitz and his collaborators have made seminal contributions to\nthe study of the uniform electron fluid and the electron-proton fluid, viz.,\nhydrogen, in using {\\it ab initio} simulations. These studies provide essential\ninputs to astrophysics as well as high-energy density physics. This is\nreflected in the contributions to this festshrift in his honour. The\nelectron-proton system becomes particularly difficult for theoretical modeling\nwhen the temperature becomes comparable to the Fermi energy $E_F$, when the\nwarm-dense matter (WDM) state of hydrogen is reached. In this study we briefly\nreview the theoretical methods available for the study of WDM systems, and use\nthe neutral-pseudo atom (NPA) method, and a classical map for quantum electrons\nto study fully and partially ionized hydrogen. It is shown that {\\it both}\nfully and partially ionized states can independently exist at the {\\it same\ndensity and temperature} in many cases. Recent studies using path-integral\nMonte Carlo methods, and $N$-atom Density Functional Theory (DFT) simulations\nhave provided essential structure data including the electron-electron\nstructure factor $S_{ee}(k)$ that enters into interpretation of X-ray Thomson\nscattering and other diagnostics. We show that these structure data can be\nrapidly and inexpensively evaluated, with sufficient accuracy, using\nclassical-map schemes for fully ionized plasmas, and more generally, using\none-atom (average-atom) DFT methods for partially ionized systems.", "AI": {"tldr": "The paper reviews theoretical methods for studying warm-dense matter (WDM) hydrogen, showing that both fully and partially ionized states can coexist at the same density and temperature. It presents efficient computational approaches using classical-map schemes and one-atom DFT methods.", "motivation": "To address the theoretical challenges in modeling electron-proton systems at temperatures comparable to the Fermi energy, particularly for warm-dense matter hydrogen, which is important for astrophysics and high-energy density physics.", "method": "Uses the neutral-pseudo atom (NPA) method and classical map for quantum electrons to study fully and partially ionized hydrogen. Also employs path-integral Monte Carlo methods and N-atom Density Functional Theory (DFT) simulations.", "result": "Shows that both fully and partially ionized states can independently exist at the same density and temperature in many cases. Demonstrates that structure data can be rapidly and inexpensively evaluated using classical-map schemes for fully ionized plasmas and one-atom DFT methods for partially ionized systems.", "conclusion": "Efficient computational methods using classical-map schemes and one-atom DFT approaches provide sufficient accuracy for studying warm-dense matter hydrogen systems, enabling rapid evaluation of essential structure data needed for experimental diagnostics."}}
{"id": "2510.00227", "pdf": "https://arxiv.org/pdf/2510.00227", "abs": "https://arxiv.org/abs/2510.00227", "authors": ["Sarvesh Joshi", "S. Mohammad Mousavi", "Craig M. Hamel", "Stavros Gaitanaros", "Prashant K. Purohit", "Ryan Alberdi", "Nikolaos Bouklas"], "title": "Instabilities and Phase Transformations in Architected Metamaterials: a Gradient-Enhanced Continuum Approach", "categories": ["physics.comp-ph"], "comment": null, "summary": "Architected metamaterials such as foams and lattices exhibit a wide range of\nproperties governed by microstructural instabilities and emerging phase\ntransformations. Their macroscopic response--including energy dissipation\nduring impact, large recoverable deformations, morphing between configurations,\nand auxetic behavior--remains difficult to capture with conventional continuum\nmodels, which often rely on discrete approaches that limit scalability. We\npropose a nonlocal continuum formulation that captures both stable and unstable\nresponses of elastic architected metamaterials. The framework extends\nanisotropic hyperelasticity by introducing nonlocal variables and internal\nlength scales reflective of microstructural features. Local polyconvex\nfree-energy models are systematically augmented with two families of\nnon-(poly)convex energies, enabling both metastable and bistable responses.\nImplementation in a finite element framework enables solution using a hybrid\nmonolithic--staggered strategy. Simulations capture densification fronts,\nforward and reverse transformations, hysteresis loops, imperfection\nsensitivity, and globally coordinated auxetic modes. Overall, this framework\nprovides a robust foundation for accelerated modeling of instability-driven\nphenomena in architected materials, while enabling extensions to anisotropic,\ndissipative, and active systems as well as integration with data-driven and\nmachine learning approaches.", "AI": {"tldr": "A nonlocal continuum framework for modeling elastic architected metamaterials that captures microstructural instabilities and phase transformations, enabling simulation of complex behaviors like densification fronts, hysteresis, and auxetic modes.", "motivation": "Conventional continuum models struggle to capture macroscopic responses of architected metamaterials governed by microstructural instabilities, limiting scalability and predictive capability for phenomena like energy dissipation, large deformations, and auxetic behavior.", "method": "Extends anisotropic hyperelasticity with nonlocal variables and internal length scales reflective of microstructure. Augments local polyconvex free-energy models with non-(poly)convex energies to enable metastable and bistable responses. Implemented in finite element framework using hybrid monolithic-staggered solution strategy.", "result": "Successfully captures densification fronts, forward/reverse transformations, hysteresis loops, imperfection sensitivity, and globally coordinated auxetic modes in simulations.", "conclusion": "Provides robust foundation for accelerated modeling of instability-driven phenomena in architected materials, with potential extensions to anisotropic, dissipative, active systems and integration with data-driven/machine learning approaches."}}
{"id": "2510.00597", "pdf": "https://arxiv.org/pdf/2510.00597", "abs": "https://arxiv.org/abs/2510.00597", "authors": ["Lefu Cai", "Zhixin Liu", "Minghui Song", "Xianchao Wang"], "title": "A Computationally Efficient Finite Element Method for Shape Reconstruction of Inverse Conductivity Problems", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "comment": null, "summary": "The inverse conductivity problem aims at determining the unknown conductivity\ninside a bounded domain from boundary measurements. In practical applications,\nalgorithms based on minimizing a regularized residual functional subject to PDE\nconstraints have been widely used to deal with this problem. However, such\napproaches typically require repeated iterations and solving the forward\nproblem at each iteration, which leads to a heavy computational cost. To\naddress this issue, we first reformulate the inverse conductivity problem as a\nminimization problem involving a regularized residual functional. We then\ntransform this minimization problem into a variational problem and establish\nthe equivalence between them. This reformulation enables the employment of the\nfinite element method to reconstruct the shape of the object from finitely many\nmeasurements. Notably, the proposed approach allows us to identify the object\ndirectly without requiring any iterative procedure. {\\it A prior} error\nestimates are rigorously established to demonstrate the theoretical soundness\nof the finite element method. Based on these estimates, we provide a criterion\nfor selecting the regularization parameter. Additionally, several numerical\nexamples are presented to verify the feasibility of the proposed approach in\nshape reconstruction.", "AI": {"tldr": "A non-iterative finite element method for solving the inverse conductivity problem that directly reconstructs object shapes from boundary measurements without requiring repeated forward problem solutions.", "motivation": "Traditional approaches for the inverse conductivity problem require repeated iterations and solving forward problems at each step, leading to high computational costs. This work aims to develop a more efficient method.", "method": "Reformulate the inverse conductivity problem as a minimization problem with regularized residual functional, then transform it into a variational problem. Use finite element method for direct shape reconstruction without iterative procedures.", "result": "The proposed approach successfully reconstructs object shapes from finite measurements without iterative procedures. A priori error estimates are established, and a criterion for regularization parameter selection is provided.", "conclusion": "The method provides a computationally efficient alternative to traditional iterative approaches for inverse conductivity problems, with theoretical soundness demonstrated through error estimates and numerical verification."}}
{"id": "2510.00179", "pdf": "https://arxiv.org/pdf/2510.00179", "abs": "https://arxiv.org/abs/2510.00179", "authors": ["Perry Kleinhenz", "Michael McNulty"], "title": "Integrated Local Energy Decay for Waves with Time-Dependent Damping", "categories": ["math.AP", "math-ph", "math.MP"], "comment": "84 pages, 1 figure", "summary": "We prove integrated local energy decay for solutions of the damped wave\nequation with time-dependent damping satisfying an appropriate generalization\nof the geometric control condition on asymptotically flat, stationary\nspace-times. We first obtain a high frequency estimate, which we prove via a\npositive commutator estimate using an escape function explicitly constructed in\nterms of the damping around individual space-time trajectories. We combine the\nhigh frequency estimate with low and medium frequency results for the undamped\nproblem, then we handle the damping term as a perturbation to obtain local\nenergy decay.", "AI": {"tldr": "Proves integrated local energy decay for damped wave equations on asymptotically flat stationary space-times with time-dependent damping satisfying a generalized geometric control condition.", "motivation": "To establish energy decay properties for wave equations with damping in curved space-time backgrounds, extending previous results to time-dependent damping scenarios.", "method": "Uses a positive commutator estimate with an escape function constructed around space-time trajectories, combining high frequency estimates with existing low/medium frequency results for undamped problems.", "result": "Successfully obtained local energy decay by treating the damping term as a perturbation after establishing the high frequency estimate.", "conclusion": "The paper demonstrates that integrated local energy decay holds for damped wave equations with time-dependent damping under appropriate geometric control conditions on asymptotically flat stationary space-times."}}
{"id": "2510.00493", "pdf": "https://arxiv.org/pdf/2510.00493", "abs": "https://arxiv.org/abs/2510.00493", "authors": ["Maximilian Peter B\u00f6hme", "Willow Martin", "Hannah Bellenbaum", "Magaret Berrens", "Jan Vorberger", "Sebastian Schwalbe", "Zhandos Moldabekov", "Thomas Gawne", "Sebastien Hamel", "Brianna Aguilar-Solis", "Abhiraj Sharma", "Frank Graziani", "Tilo D\u00f6ppner", "Siegfried Glenzer", "Tobias Dornheim", "David Bishel"], "title": "Correlation function metrology for warm dense matter: Recent developments and practical guidelines", "categories": ["physics.plasm-ph", "physics.comp-ph"], "comment": null, "summary": "X-ray Thomson scattering (XRTS) has emerged as a valuable diagnostic for\nmatter under extreme conditions, as it captures the intricate many-body physics\nof the probed sample. Recent advances, such as the model-free temperature\ndiagnostic of Dornheim et al. [Nat.Commun. 13, 7911 (2022)], have demonstrated\nhow much information can be extracted directly within the imaginary-time\nformalism. However, since the imaginary-time formalism is a concept often\ndifficult to grasp, we provide here a systematic overview of its theoretical\nfoundations and explicitly demonstrate its practical applications to\ntemperature inference, including relevant subtleties. Furthermore, we present\nrecent developments that enable the determination of the absolute\nnormalization, Rayleigh weight, and density from XRTS measurements without\nreliance on uncontrolled model assumptions. Finally, we outline a unified\nworkflow that guides the extraction of these key observables, offering a\npractical framework for applying the method to interpret experimental\nmeasurements.", "AI": {"tldr": "This paper provides a systematic overview of the imaginary-time formalism for X-ray Thomson scattering (XRTS) analysis, demonstrating practical applications for temperature inference and presenting new methods to determine absolute normalization, Rayleigh weight, and density without model assumptions.", "motivation": "XRTS is valuable for diagnosing matter under extreme conditions, but the imaginary-time formalism is difficult to understand. The authors aim to make this powerful method more accessible and demonstrate its practical applications.", "method": "The paper uses the imaginary-time formalism for XRTS analysis, providing systematic theoretical foundations and practical workflows. It includes methods for temperature inference, absolute normalization determination, Rayleigh weight extraction, and density estimation without relying on uncontrolled model assumptions.", "result": "The authors demonstrate how to extract key observables from XRTS measurements using the imaginary-time formalism, including temperature, absolute normalization, Rayleigh weight, and density, all without requiring model-dependent assumptions.", "conclusion": "The paper presents a unified workflow for extracting multiple key observables from XRTS measurements using the imaginary-time formalism, making this powerful diagnostic technique more practical and accessible for experimental applications."}}
{"id": "2510.00116", "pdf": "https://arxiv.org/pdf/2510.00116", "abs": "https://arxiv.org/abs/2510.00116", "authors": ["Akash Maurya", "Prayush Kumar", "Scott E. Field", "Chandra Kant Mishra", "Peter James Nee", "Kaushik Paul", "Harald P. Pfeiffer", "Adhrit Ravichandran", "Vijay Varma"], "title": "Chase Orbits, not Time: A Scalable Paradigm for Long-Duration Eccentric Gravitational-Wave Surrogates", "categories": ["gr-qc", "astro-ph.HE", "physics.comp-ph"], "comment": "12 pages, 7 figures", "summary": "Surrogate modeling of eccentric binary black hole waveforms has remained\nchallenging. The complicated morphology of these waveforms due to the eccentric\norbital timescale variations makes it difficult to construct accurate and\nefficient surrogate models, especially for waveforms long enough to cover the\nsensitivity band of the current ground-based gravitational wave detectors. We\npresent a novel and scalable surrogate building technique which makes surrogate\nmodeling of long-duration eccentric binary black hole waveforms both feasible\nand highly efficient. The technique aims to simplify the harmonic content of\nthe intermediate eccentric surrogate data pieces by modeling them in terms of\nan angular orbital element called the mean anomaly, instead of time. We show\nthat this novel parameterization yields an order of magnitude fewer surrogate\nbasis functions than using the contemporary parameterization in terms of time.\nWe show that variations in surrogate data-pieces across parameter space become\nmuch more regular when expressed in terms of the instantaneous waveform\neccentricity and mean anomaly, greatly easing their parameter-space fitting.\nThe methods presented in this work make it feasible to build long-duration\neccentric surrogates for the current as well as future third-generation\ngravitational wave detectors.", "AI": {"tldr": "A novel surrogate modeling technique for eccentric binary black hole waveforms using mean anomaly parameterization instead of time, achieving order-of-magnitude efficiency improvements.", "motivation": "Eccentric binary black hole waveforms are challenging to model due to complex morphology from orbital timescale variations, especially for long-duration waveforms needed for current gravitational wave detectors.", "method": "Parameterizes waveforms in terms of mean anomaly (angular orbital element) instead of time, simplifying harmonic content and making parameter-space variations more regular.", "result": "Achieves order of magnitude fewer surrogate basis functions compared to time-based parameterization, with more regular parameter-space fitting.", "conclusion": "Makes long-duration eccentric surrogate modeling feasible for current and future third-generation gravitational wave detectors."}}
{"id": "2510.00719", "pdf": "https://arxiv.org/pdf/2510.00719", "abs": "https://arxiv.org/abs/2510.00719", "authors": ["Mohamed Mostafa"], "title": "Symbolic and High-Accuracy Solutions to Differential and Integral Problems via a Novel Recursive Inverse Laplace Method", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we introduce a novel semi-analytical method for solving a\nbroad class of initial value problems involving differential,\nintegro-differential, and delay equations, including those with fractional and\nvariable-order derivatives. The proposed approach is based on the inverse\nLaplace transform, applied initially - unlike traditional Laplace-based\ntechniques which begin with a forward transformation. By assuming the unknown\nsolution is the Laplace transform of an auxiliary function, the method\nreformulates the problem in the time domain and recursively solves for this\nfunction using symbolic operations. The final solution is then obtained by\napplying the Laplace transform to the result. This strategy enables the\nconstruction of symbolic solutions as generalized logarithmic-power series with\narbitrary accuracy, and naturally accommodates complex terms. The method is\nhighly versatile and demonstrates superior speed and precision across a wide\nrange of linear and nonlinear problems, including singular, fractional, and\nchaotic systems. Several benchmark examples are provided to validate the\nreliability and efficiency of the proposed technique compared to classical\nnumerical methods. The results confirm that the new method offers a powerful\nand flexible framework for symbolic computation of initial value problems.", "AI": {"tldr": "A novel semi-analytical method using inverse Laplace transform to solve differential, integro-differential, and delay equations with fractional/variable-order derivatives, providing symbolic solutions as generalized logarithmic-power series.", "motivation": "To develop a more versatile and efficient approach for solving complex initial value problems that traditional Laplace-based methods struggle with, particularly for fractional, singular, and chaotic systems.", "method": "The method starts with inverse Laplace transform (unlike traditional forward Laplace), assumes the unknown solution is the Laplace transform of an auxiliary function, reformulates the problem in time domain, recursively solves for the auxiliary function using symbolic operations, then applies Laplace transform to obtain final solution.", "result": "The method constructs symbolic solutions as generalized logarithmic-power series with arbitrary accuracy, handles complex terms naturally, and demonstrates superior speed and precision across linear/nonlinear problems including singular, fractional, and chaotic systems compared to classical numerical methods.", "conclusion": "The proposed method provides a powerful and flexible framework for symbolic computation of initial value problems, offering high versatility and validated reliability through benchmark examples."}}
{"id": "2510.00265", "pdf": "https://arxiv.org/pdf/2510.00265", "abs": "https://arxiv.org/abs/2510.00265", "authors": ["Giovanni Paolo Galdi"], "title": "Very Weak Solutions and Asymptotic Behavior of Leray Solutions to the Stationary Navier-Stokes Equations", "categories": ["math.AP", "math-ph", "math.MP"], "comment": null, "summary": "Let $\\bfu$ be a Leray solution to the Navier-Stokes boundary-value problem in\nan exterior domain, vanishing at infinity and satisfying the generalized energy\ninequality. We show that if there exist $R>0$ and ${\\sf s}\\ge \\frac23 q$,\n$q>6$, such that the $L^{\\sf s}-$norm of $\\bfu$ on the spherical surface of\nradius $R$ divided by $R$ is less than a constant depending only on {\\sf s} and\n$q$, then $\\bfu(x)$ must decay as $|x|^{-1}$ for $|x|\\to\\infty$. This result is\nproved with an approach based on a new theory of very weak solutions in\nexterior domains which, as such, is of independent interest.", "AI": {"tldr": "The paper shows that if the L^s-norm of a Leray solution to the Navier-Stokes problem in an exterior domain is sufficiently small on a spherical surface, then the solution decays as |x|^{-1} at infinity.", "motivation": "To establish decay conditions for Navier-Stokes solutions in exterior domains, particularly understanding when solutions exhibit specific decay rates at infinity.", "method": "Uses an approach based on a new theory of very weak solutions in exterior domains, analyzing the L^s-norm of solutions on spherical surfaces.", "result": "Proves that under certain conditions on the L^s-norm of the solution on a spherical surface, the solution must decay as |x|^{-1} for large |x|.", "conclusion": "The paper provides a sufficient condition for |x|^{-1} decay of Navier-Stokes solutions in exterior domains, introducing a new approach with very weak solutions that has independent mathematical interest."}}
{"id": "2510.01060", "pdf": "https://arxiv.org/pdf/2510.01060", "abs": "https://arxiv.org/abs/2510.01060", "authors": ["G. H. Vicentin", "G. Kowal", "E. M. de Gouveia Dal Pino", "A. Lazarian"], "title": "Do plasmoids induce fast magnetic reconnection in well-resolved current sheets in 2D MHD simulations?", "categories": ["physics.plasm-ph", "astro-ph.HE", "hep-th"], "comment": "21 pages, 12 figures", "summary": "We investigate the development of tearing-mode instability using the highest\nresolution two-dimensional magnetohydrodynamic simulations of reconnecting\ncurrent sheets on a uniform grid, for Lundquist numbers $10^3 \\le S \\le 2\n\\times 10^5$. Although the tearing-mode instability is commonly thought to\ntrigger a plasmoid cascade that enables fast reconnection - i.e., independent\nof $S$ - our results, in broad agreement with the recent findings of Morillo \\&\nAlexakis (2025), challenge this belief. We demonstrate a Sweet-Parker scaling\nof the reconnection rate $V_{\\text{rec}} \\sim S^{-1/2}$ up to Lundquist numbers\n$S \\sim 10^4$. For larger values, plasmoid formation sets in leading to a\nslight enhancement of the reconnection rate, $V_{\\text{rec}} \\sim S^{-1/3}$,\nconsistent with the prediction from linear tearing mode induced reconnection,\nindicating that reconnection remains resistivity dependent, and therefore slow.\nIn our simulations, the plasmoids do not form a cascade of mergers, as they are\nrapidly advected out of the reconnection layer. Our findings call for the\nrevision of the role of plasmoid formation in 2D high Lundquist number magnetic\nreconnection. Even if future studies demonstrate that 2D plasmoid-reconnection\nbecomes resistivity-independent at sufficiently large $S$, directly extending\nthose results to 3D astrophysical environments is not justified, as in\nrealistic circumstances, the increase of $S$ also raises the Reynolds number of\nthe outflows, making it essential to account for the dominant role of\nturbulence.", "AI": {"tldr": "High-resolution 2D MHD simulations challenge the conventional belief that tearing-mode instability triggers plasmoid cascades enabling fast reconnection. Results show Sweet-Parker scaling persists up to S~10^4, with only slight enhancement to S^{-1/3} at higher S, indicating reconnection remains resistivity-dependent.", "motivation": "To investigate whether tearing-mode instability truly enables fast reconnection independent of Lundquist number, challenging the conventional plasmoid cascade theory.", "method": "Used highest resolution 2D magnetohydrodynamic simulations of reconnecting current sheets on uniform grid for Lundquist numbers 10^3 \u2264 S \u2264 2\u00d710^5.", "result": "Sweet-Parker scaling (V_rec ~ S^{-1/2}) persists up to S~10^4. At higher S, plasmoid formation provides only slight enhancement (V_rec ~ S^{-1/3}), not resistivity independence. Plasmoids are rapidly advected out without forming cascade mergers.", "conclusion": "Plasmoid formation's role in 2D high-S reconnection needs revision. Even if future studies show resistivity independence in 2D, extending to 3D astrophysical environments is not justified due to turbulence's dominant role at high Reynolds numbers."}}
{"id": "2510.00129", "pdf": "https://arxiv.org/pdf/2510.00129", "abs": "https://arxiv.org/abs/2510.00129", "authors": ["Hengkui Wu", "Liujiang Liu", "Jihua He", "Qihao Wang", "Keke Zhao", "Shuyang Hu", "Renle Fu", "Dahao Liang", "Lingyu Zeng", "Bruce Liu", "Yuan Liu", "Jin Zhan", "Jiaqiang Niu", "Xinglong Jia", "Yaqin Hu", "Wenjun Ji", "Panpan Chi", "Ken Chen", "Hengyuan Wu", "Yingsi Xin", "Yongfeng Zhu", "Yuexin Wang", "Manqi Ruan", "Ningtao Bian", "Xiaohua Wu", "Weipeng Xu"], "title": "BigBang-Proton Technical Report: Next-Word-Prediction is Scientific Multitask Learner", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "physics.comp-ph", "68T05, 68T50, 00A69, 94A99", "I.2.6; I.2.7; J.2; I.6.3; K.4.1"], "comment": "93 pages, 39 figures", "summary": "We introduce BigBang-Proton, a unified sequence-based architecture for\nauto-regressive language modeling pretrained on cross-scale, cross-structure,\ncross-discipline real-world scientific tasks to construct a scientific\nmulti-task learner. BigBang-Proton incorporates three fundamental innovations\ncompared to mainstream general-purpose LLMs: Theory-Experiment Learning\nparadigm aligns large-scale numerical experimental data with theoretical text\ncorpora; Binary Patch Encoding replaces byte pair encoding(BPE) tokenization;\nMonte Carlo Attention substitutes traditional transformer architectures.\nThrough next-word-prediction pretraining on cross-discipline scientific\ndatasets of real-world problems mixed with general textual corpus, followed by\nfine-tuning and inference on downstream tasks, BigBang-Proton demonstrates\n100\\% accuracy in up to 50-digit arithmetic addition operations, performance on\npar with leading specialized models in particle physics jet tagging, matching\nMAE of specialized models in inter-atomic potential simulation, performance\ncomparable to traditional spatiotemporal models in water quality prediction,\nand benchmark-exceeding performance in genome modeling. These results prove\nthat language-guided scientific computing can match or exceed the performance\nof task-specific scientific models while maintaining multitask learning\ncapabilities. We further hypothesize to scale the pretraining to the universe\nscale as a fundamental step toward developing material world foundational\nmodel.", "AI": {"tldr": "BigBang-Proton is a unified sequence-based architecture for auto-regressive language modeling pretrained on cross-scale scientific tasks, featuring Theory-Experiment Learning, Binary Patch Encoding, and Monte Carlo Attention innovations.", "motivation": "To create a scientific multi-task learner that can handle cross-discipline scientific tasks while maintaining multitask learning capabilities, moving toward developing a material world foundational model.", "method": "Uses next-word-prediction pretraining on cross-discipline scientific datasets mixed with general corpus, featuring Theory-Experiment Learning paradigm, Binary Patch Encoding instead of BPE tokenization, and Monte Carlo Attention replacing traditional transformers.", "result": "Achieves 100% accuracy in 50-digit arithmetic, par performance with specialized models in particle physics jet tagging, matches MAE of specialized models in inter-atomic potential simulation, comparable performance to traditional spatiotemporal models in water quality prediction, and benchmark-exceeding performance in genome modeling.", "conclusion": "Language-guided scientific computing can match or exceed task-specific scientific models while maintaining multitask learning capabilities, with plans to scale pretraining to universe scale for material world foundational model development."}}
{"id": "2510.00722", "pdf": "https://arxiv.org/pdf/2510.00722", "abs": "https://arxiv.org/abs/2510.00722", "authors": ["Bernhard Heinzelreiter", "John W. Pearson"], "title": "Carleman Linearization of Parabolic PDEs: Well-posedness, convergence, and efficient numerical methods", "categories": ["math.NA", "cs.NA"], "comment": "32 pages", "summary": "We explore how the analysis of the Carleman linearization can be extended to\ndynamical systems on infinite-dimensional Hilbert spaces with quadratic\nnonlinearities. We demonstrate the well-posedness and convergence of the\ntruncated Carleman linearization under suitable assumptions on the dynamical\nsystem, which encompass common parabolic semi-linear partial differential\nequations such as the Navier-Stokes equations and nonlinear\ndiffusion-advection-reaction equations. Upon discretization, we show that the\ntotal approximation error of the linearization decomposes into two independent\ncomponents: the discretization error and the linearization error. This\ndecomposition yields a convergence radius and convergence rate for the\ndiscretized linearization that are independent of the discretization. We thus\njustify the application of the linearization to parabolic PDE problems.\nFurthermore, it motivates the use of non-standard structure-exploiting\nnumerical methods, such as sparse grids, taming the curse of dimensionality\nassociated with the Carleman linearization. Finally, we verify the results with\nnumerical experiments.", "AI": {"tldr": "Extension of Carleman linearization to infinite-dimensional Hilbert spaces with quadratic nonlinearities, showing well-posedness and convergence for parabolic PDEs like Navier-Stokes equations.", "motivation": "To extend Carleman linearization analysis to infinite-dimensional systems with quadratic nonlinearities, particularly for common parabolic PDEs where traditional methods face challenges.", "method": "Analyze truncated Carleman linearization under suitable assumptions, demonstrate decomposition of total approximation error into discretization and linearization components, and use structure-exploiting numerical methods like sparse grids.", "result": "Established well-posedness and convergence of truncated Carleman linearization, with convergence radius and rate independent of discretization, verified through numerical experiments.", "conclusion": "The approach justifies Carleman linearization for parabolic PDE problems and motivates structure-exploiting methods to handle the curse of dimensionality."}}
{"id": "2510.00439", "pdf": "https://arxiv.org/pdf/2510.00439", "abs": "https://arxiv.org/abs/2510.00439", "authors": ["Koji Wada", "Kyouhei Wakasa"], "title": "Blow-up of solutions for discrete semilinear wave equation with the scale-invariant damping", "categories": ["math.AP", "cs.NA", "math.NA"], "comment": "11 pages", "summary": "We consider the blow-up problem for discretized scale-invariant nonlinear\ndissipative wave equations. It is known that the critical exponents for\nundiscretized equations (continuous equations) are given by Fujita and Strauss\nexponents depending on the space dimensions. Our purpose is to obtain results\nfor the discretized equations that correspond to those shown for the continuous\none. The proof is based on Matsuya [6], who showed the blow-up problem for\ndiscrete semilinear wave equations without dissipative terms, and we found that\nthe result is sharp in the case of one and two space dimensions compared to the\ncontinuous equations.", "AI": {"tldr": "Analysis of blow-up behavior in discretized scale-invariant nonlinear dissipative wave equations, comparing critical exponents with continuous equations.", "motivation": "To extend blow-up results from continuous scale-invariant nonlinear dissipative wave equations to their discretized counterparts, and compare critical exponents between discrete and continuous cases.", "method": "Based on Matsuya's approach for discrete semilinear wave equations without dissipative terms, adapted for dissipative cases. Focuses on critical exponents (Fujita and Strauss exponents) in relation to space dimensions.", "result": "Found that the blow-up results for discretized equations are sharp (match exactly) with continuous equations in one and two space dimensions.", "conclusion": "The discretized scale-invariant nonlinear dissipative wave equations exhibit blow-up behavior that corresponds precisely to their continuous counterparts in lower dimensions (1D and 2D), validating the discretization approach."}}
{"id": "2510.00998", "pdf": "https://arxiv.org/pdf/2510.00998", "abs": "https://arxiv.org/abs/2510.00998", "authors": ["Sean Baccas", "Alexander A. Belozerov", "Eike H. M\u00fcller", "Tobias Weinzierl"], "title": "Implementation techniques for multigrid solvers for high-order Discontinuous Galerkin methods", "categories": ["math.NA", "cs.NA", "35J05, 35J55, 65N30, 65N55, 65Y05, 65Y20", "G.1.3; G.1.8"], "comment": "46 pages, 12 figures, 6 tables", "summary": "Matrix-free geometric multigrid solvers for elliptic PDEs that have been\ndiscretised with Higher-order Discontinuous Galerkin (DG) methods are ideally\nsuited to exploit state-of-the-art computer architectures. Higher polynomial\ndegrees offer exponential convergence, while the workload fits to vector units,\nis straightforward to parallelise, and exhibits high arithmetic intensity. Yet,\nDG methods such as the interior penalty DG discreisation do not magically\nguarantee high performance: they require non-local memory access due to\ncoupling between neighbouring cells and break down into compute steps of widely\nvarying costs and compute character. We address these limitations by developing\nefficient execution strategies for $hp$-multigrid. Separating cell- and\nfacet-operations by introducing auxiliary facet variables localizes data\naccess, reduces the need for frequent synchronization, and enables overlap of\ncomputation and communication. Loop fusion results in a single-touch scheme\nwhich reads (cell) data only once per smoothing step. We interpret the\nresulting execution strategies in the context of a task formalism, which\nexposes additional concurreny. The target audience of this paper are\npractitioners in Scientific Computing who are not necessarily experts on\nmultigrid or familiar with sophisticated discretisation techniques. By\ndiscussing implementation techniques for a powerful solver algorithm we aim to\nmake it accessible to the wider community.", "AI": {"tldr": "The paper presents matrix-free geometric multigrid solvers for elliptic PDEs using Higher-order Discontinuous Galerkin methods, focusing on execution strategies to overcome performance limitations and improve efficiency on modern architectures.", "motivation": "Higher-order DG methods offer exponential convergence and suit modern computer architectures, but face performance issues due to non-local memory access, varying compute costs, and frequent synchronization requirements.", "method": "Developed efficient execution strategies for hp-multigrid by: 1) separating cell- and facet-operations using auxiliary facet variables, 2) localizing data access and reducing synchronization, 3) enabling computation-communication overlap, 4) implementing loop fusion for single-touch scheme, and 5) interpreting strategies in task formalism to expose additional concurrency.", "result": "The proposed strategies improve performance by localizing data access, reducing synchronization needs, enabling computation-communication overlap, and creating a single-touch scheme that reads cell data only once per smoothing step.", "conclusion": "The paper makes advanced multigrid solver algorithms more accessible to the wider scientific computing community by providing practical implementation techniques that address performance bottlenecks in DG methods."}}
{"id": "2510.00453", "pdf": "https://arxiv.org/pdf/2510.00453", "abs": "https://arxiv.org/abs/2510.00453", "authors": ["Xia Huang", "Dong Ye"], "title": "On Sharp Heisenberg Uncertainty Principle and the stability", "categories": ["math.AP"], "comment": null, "summary": "In this work, we summarize the linearization method to study the Heisenberg\nUncertainty Principles, and explain that the same approach can be used to\nhandle the stability problem. As examples of application, combining with\nspherical harmonic decomposition and the Hardy inequalities, we revise two\nfamilies of inequalities. We give firstly an affirmative answer in dimension\nfour to Cazacu-Flynn-Lam's conjecture [JFA, 2022] for the sharp Hydrogen\nUncertainty Principle, and improve the recent estimates of Chen-Tang\n[arXiv:2508.15221v1] in $\\mathbb{R}^2$ and $\\mathbb{R}^3$. On the other hand,\nwe identify the best constants and extremal functions for two stability\nestimates associated to $\\|\\Delta u\\|_2 \\|r\\nabla u\\|_2 - \\frac{N+2}{2}\\|\\nabla\nu\\|^2_2$ in $\\mathbb{R}^N$ ($N \\geq 2$), studied recently by Duong-Nguyen\n[CVPDE, 2025] and Do-Lam-Lu-Zhang [arXiv:2505.02758v1].", "AI": {"tldr": "The paper applies linearization methods to study Heisenberg Uncertainty Principles and stability problems, proving Cazacu-Flynn-Lam's conjecture in dimension 4 and improving recent estimates in R^2 and R^3, while also identifying best constants for stability estimates.", "motivation": "To extend linearization methods from studying Heisenberg Uncertainty Principles to stability problems, and to resolve conjectures and improve existing estimates in uncertainty principle inequalities.", "method": "Uses linearization method combined with spherical harmonic decomposition and Hardy inequalities to analyze uncertainty principles and stability problems.", "result": "Proved Cazacu-Flynn-Lam's conjecture for sharp Hydrogen Uncertainty Principle in dimension 4, improved Chen-Tang's estimates in R^2 and R^3, and identified best constants for stability estimates studied by Duong-Nguyen and Do-Lam-Lu-Zhang.", "conclusion": "Linearization methods are effective for both uncertainty principle analysis and stability problems, enabling resolution of conjectures and improvement of existing bounds across multiple dimensions."}}
{"id": "2510.00158", "pdf": "https://arxiv.org/pdf/2510.00158", "abs": "https://arxiv.org/abs/2510.00158", "authors": ["Frederic J. N. Jorgensen", "Youssef M. Marzouk"], "title": "A Bayesian Characterization of Ensemble Kalman Updates", "categories": ["math.ST", "cs.NA", "math.NA", "math.OC", "math.PR", "stat.TH", "65C35, 62F15, 93E11", "G.3; I.6.5"], "comment": "29 pages, 3 figures", "summary": "The update in the Ensemble Kalman Filter (EnKF), called the Ensemble Kalman\nUpdate (EnKU), is widely used for Bayesian inference in inverse problems and\ndata assimilation. At each filtering step, it approximates the solution to a\nlikelihood-free Bayesian inversion from an ensemble of particles\n$(X_i,Y_i)\\sim\\pi$ sampled from a joint measure $\\pi$ and an observation\n$y_\\ast\\in\\mathbb{R}^m$. The posterior ${\\pi}_{X|Y=y_\\ast}$ is approximated by\ntransporting $(X_i,Y_i)$ through an affine map\n$L^{\\mathrm{EnKU}}_{y_\\ast}(x,y)$ determined by the Kalman gain. While the EnKU\nis exact for Gaussian joints $\\pi$ in the mean-field limit, exactness alone\ndoes not fix the update: infinitely many affine maps $L_{y_\\ast}$ push a\nGaussian $\\pi$ to $\\pi_{X|Y=y_\\ast}$. This raises a question: which affine map\nshould estimate the posterior? We provide a characterization of the EnKU among\nall such maps. First, we describe the set $\\mathrm{E}^{\\mathrm{EnKU}}$ of laws\nwhere the EnKU yields exact conditioning, showing it is larger than the\nGaussian family. Next, we prove that, except for a small class of highly\nsymmetric distributions in $\\mathrm{E}^{\\mathrm{EnKU}}$ (including Gaussians),\nthe EnKU is the unique exact affine conditioning map. Finally, we ask for the\nlargest possible set $\\mathrm{F}$ where any measure-dependent affine transport\ncould be exact; after characterizing $\\mathrm{F}$, we show the EnKU's exactness\nset is almost maximal:\n$\\mathrm{F}=\\mathrm{E}^{\\mathrm{EnKU}}\\cup\\mathrm{S}_{\\mathrm{nl-dec}}$, where\n$\\mathrm{S}_{\\mathrm{nl-dec}}$ is a small symmetry class. Thus, among affine\ntransports, the EnKU is near-optimal for exact conditioning beyond Gaussians\nand is the unique affine update achieving exactness for any measure in\n$\\mathrm{F}$ except a subclass of strongly symmetric laws.", "AI": {"tldr": "The paper analyzes the Ensemble Kalman Update (EnKU) and characterizes it as the unique affine conditioning map that achieves exact Bayesian inference for a broad class of distributions beyond Gaussians.", "motivation": "To understand why the Ensemble Kalman Update is preferred among infinitely many possible affine conditioning maps for Bayesian inference, and to characterize its exactness properties beyond Gaussian distributions.", "method": "Mathematical analysis of affine conditioning maps, characterization of the exactness set E^EnKU where EnKU yields exact conditioning, and comparison with the maximal possible exactness set F for affine transports.", "result": "EnKU's exactness set is larger than Gaussian family, and EnKU is the unique exact affine conditioning map for most distributions in E^EnKU. The EnKU's exactness set is almost maximal, differing from the maximal set F only by a small symmetry class S_nl-dec.", "conclusion": "The Ensemble Kalman Update is near-optimal among affine transports for exact conditioning beyond Gaussians and is uniquely exact for most measures in the maximal possible exactness set."}}
{"id": "2510.00539", "pdf": "https://arxiv.org/pdf/2510.00539", "abs": "https://arxiv.org/abs/2510.00539", "authors": ["Ken Abe", "Kyudong Choi", "In-Jee Jeong"], "title": "Stability of Lamb dipoles for odd-symmetric and non-negative initial disturbances without the finite mass condition", "categories": ["math.AP"], "comment": "21 pages", "summary": "In this paper, we consider the stability of the Lamb dipole solution of the\ntwo-dimensional Euler equations in $\\mathbb{R}^{2}$ and question under which\ninitial disturbance the Lamb dipole is stable, motivated by experimental work\non the formation of a large vortex dipole in two-dimensional turbulence. We\nassume (O) odd symmetry for the $x_2$-variable and (N) non-negativity in the\nupper half plane for the initial disturbance of vorticity, and establish the\nstability theorem of the Lamb dipole without assuming (F) finite mass\ncondition. The proof is based on a new variational characterization of the Lamb\ndipole using an improved energy inequality.", "AI": {"tldr": "Stability analysis of Lamb dipole solution in 2D Euler equations under odd symmetry and non-negativity conditions for initial vorticity disturbances, without requiring finite mass condition.", "motivation": "Motivated by experimental observations of large vortex dipole formation in two-dimensional turbulence, to understand under what initial disturbance conditions the Lamb dipole remains stable.", "method": "Uses a new variational characterization of the Lamb dipole based on an improved energy inequality, assuming odd symmetry for x\u2082-variable and non-negativity in the upper half plane for initial vorticity disturbance.", "result": "Established stability theorem for the Lamb dipole without assuming finite mass condition for the initial disturbance.", "conclusion": "The Lamb dipole solution is stable under specified symmetry and non-negativity conditions, providing theoretical foundation for observed vortex dipole stability in 2D turbulence experiments."}}
{"id": "2510.00518", "pdf": "https://arxiv.org/pdf/2510.00518", "abs": "https://arxiv.org/abs/2510.00518", "authors": ["Ziqi Guo", "Xiulin Ruan", "Guang Lin"], "title": "FourPhonon_GPU: A GPU-accelerated framework for calculating phonon scattering rates and thermal conductivity", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Accurately predicting phonon scattering is crucial for understanding thermal\ntransport properties. However, the computational cost of such calculations,\nespecially for four-phonon scattering, can often be more prohibitive when large\nnumber of phonon branches and scattering processes are involved. In this work,\nwe present FourPhonon_GPU, a GPU-accelerated framework for three-phonon and\nfour-phonon scattering rate calculations based on the FourPhonon package. By\nleveraging OpenACC and adopting a heterogeneous CPU-GPU computing strategy, we\nefficiently offload massive, parallelizable tasks to the GPU while using the\nCPU for process enumeration and control-heavy operations. Our approach achieves\nover 25x acceleration for the scattering rate computation step and over 10x\ntotal runtime speedup without sacrificing accuracy. Benchmarking on various GPU\narchitectures confirms the method's scalability and highlights the importance\nof aligning parallelization strategies with hardware capabilities. This work\nprovides an efficient and accurate computational tool for phonon transport\nmodeling and opens pathways for accelerated materials discovery.", "AI": {"tldr": "FourPhonon_GPU is a GPU-accelerated framework that speeds up three-phonon and four-phonon scattering rate calculations by over 25x for computation and 10x overall runtime using OpenACC and heterogeneous CPU-GPU computing.", "motivation": "The computational cost of phonon scattering calculations, especially four-phonon scattering, becomes prohibitive when dealing with large numbers of phonon branches and scattering processes, limiting efficient thermal transport modeling.", "method": "Developed FourPhonon_GPU framework using OpenACC and heterogeneous CPU-GPU computing strategy, offloading parallelizable tasks to GPU while using CPU for process enumeration and control-heavy operations.", "result": "Achieved over 25x acceleration for scattering rate computation and over 10x total runtime speedup without accuracy loss. Benchmarks confirmed scalability across GPU architectures.", "conclusion": "The framework provides an efficient and accurate computational tool for phonon transport modeling and enables accelerated materials discovery through significant performance improvements."}}
{"id": "2510.00389", "pdf": "https://arxiv.org/pdf/2510.00389", "abs": "https://arxiv.org/abs/2510.00389", "authors": ["Art B. Owen"], "title": "Zero variance self-normalized importance sampling via estimating equations", "categories": ["math.ST", "cs.NA", "math.NA", "stat.CO", "stat.TH"], "comment": null, "summary": "In ordinary importance sampling with a nonnegative integrand there exists an\nimportance sampling strategy with zero variance. Practical sampling strategies\nare often based on approximating that optimal solution, potentially approaching\nzero variance. There is a positivisation extension of that method to handle\nintegrands that take both positive and negative values. Self-normalized\nimportance sampling uses a ratio estimate, for which the optimal sampler does\nnot have zero variance and so zero variance cannot even be approached in\npractice. Strategies that separately estimate the numerator and denominator of\nthat ratio can approach zero variance. This paper develops another zero\nvariance solution for self-normalized importance sampling. The first step is to\nwrite the desired expectation as the zero of an estimating equation using\nFieller's technique. Then we apply the positivisation strategy to the\nestimating equation. This paper give conditions for existence and uniqueness of\nthe sample solution to the estimating equation. Then it give conditions for\nconsistency and asymptotic normality and an expression for the asymptotic\nvariance. The sample size multiplied by the variance of the asymptotic formula\nbecomes arbitrarily close to zero for certain sampling strategies.", "AI": {"tldr": "This paper develops a zero variance solution for self-normalized importance sampling using Fieller's technique and positivisation strategy applied to estimating equations.", "motivation": "Self-normalized importance sampling uses ratio estimates where the optimal sampler cannot achieve zero variance, unlike ordinary importance sampling. The authors aim to develop a method that can approach zero variance.", "method": "The method writes the desired expectation as the zero of an estimating equation using Fieller's technique, then applies the positivisation strategy to the estimating equation.", "result": "The paper provides conditions for existence and uniqueness of the sample solution, conditions for consistency and asymptotic normality, and an expression for asymptotic variance. The sample size multiplied by variance becomes arbitrarily close to zero for certain sampling strategies.", "conclusion": "The proposed method achieves a zero variance solution for self-normalized importance sampling, overcoming the limitation that traditional approaches cannot approach zero variance."}}
{"id": "2510.00692", "pdf": "https://arxiv.org/pdf/2510.00692", "abs": "https://arxiv.org/abs/2510.00692", "authors": ["Hung Luong"], "title": "Revisiting the Cauchy problem for the Zakharov-Rubenchik/Benney-Roskes system", "categories": ["math.AP", "35Q35, 35Q55"], "comment": null, "summary": "In this paper, we revisit the Cauchy problem for the\nZakharov-Rubenchik/Benney-Roskes system. Our method is based on the dispersive\nestimates and the suitable Bourgain's spaces. We then, obtain the local\nwell-posedness of the solution with the main component $\\psi$ belongs to\n$H^1(\\mathbb{R}^d)$ ($d=2, 3$) which is actually the energy space corresponding\nto this component. Our result also suggests a potential approach to the problem\nof finding exact existence time scale for the solution of Benney-Roskes model\nin the context of water waves.", "AI": {"tldr": "Local well-posedness of Zakharov-Rubenchik/Benney-Roskes system in energy space H^1 for dimensions 2 and 3 using dispersive estimates and Bourgain spaces.", "motivation": "To establish local well-posedness for the Zakharov-Rubenchik/Benney-Roskes system in the energy space, and potentially find exact existence time scales for water wave models.", "method": "Based on dispersive estimates and suitable Bourgain's spaces to analyze the Cauchy problem.", "result": "Obtained local well-posedness with main component \u03c8 belonging to H^1(R^d) for d=2,3, which is the energy space for this component.", "conclusion": "The approach provides local well-posedness results and suggests a potential method for determining exact existence time scales in water wave contexts."}}
{"id": "2510.00533", "pdf": "https://arxiv.org/pdf/2510.00533", "abs": "https://arxiv.org/abs/2510.00533", "authors": ["Nazeela Aimen", "Patricio Maturana-Russel", "Avi Vajpeyi", "Nelson Christensen", "Renate Meyer"], "title": "Bayesian power spectral density estimation for LISA noise based on P-splines with a parametric boost", "categories": ["stat.CO", "physics.comp-ph"], "comment": null, "summary": "Flexible and efficient noise characterization is crucial for the precise\nestimation of gravitational wave parameters. We introduce a fast and accurate\nBayesian method for estimating the power spectral density (PSD) of long,\nstationary time series tailored specifically for LISA data analysis. Our\napproach models the PSD as a geometric mean of a parametric and a nonparametric\ncomponent, combining the computational efficiency of parametric models with the\nflexibility to capture deviations from theoretical expectations. The\nnonparametric component is expressed by a mixture of penalized B-splines.\nAdaptive, data-driven knot placement performed once during initialization\neliminates computationally expensive reversible-jump Markov Chain Monte Carlo,\nwhile hierarchical roughness penalty priors prevent overfitting. This design\nyields stable, flexible PSD estimates with runtimes of minutes instead of\nhours. Validation on simulated autoregressive AR(4) data demonstrates estimator\nconsistency. It shows that well-matched parametric components reduce the\nintegrated absolute error compared to an uninformative baseline, requiring\nfewer spline knots to achieve comparable accuracy. Applied to a year of\nsimulated LISA $X$-channel noise, our method achieves relative integrated\nabsolute errors of $\\mathcal{O}(10^{-2})$ with computation times less than\nthree minutes, which makes it suitable for iterative analysis pipelines and\nmulti-year mission datasets.", "AI": {"tldr": "A fast Bayesian method for estimating power spectral density (PSD) of stationary time series, combining parametric and nonparametric components using penalized B-splines for LISA gravitational wave data analysis.", "motivation": "Flexible and efficient noise characterization is crucial for precise gravitational wave parameter estimation, especially for long datasets like those from LISA mission.", "method": "Models PSD as geometric mean of parametric and nonparametric components. Uses mixture of penalized B-splines with adaptive knot placement and hierarchical roughness penalty priors to prevent overfitting.", "result": "Achieves relative integrated absolute errors of O(10^-2) with computation times under 3 minutes for simulated LISA data. Well-matched parametric components reduce error and require fewer spline knots.", "conclusion": "The method provides stable, flexible PSD estimates suitable for iterative analysis pipelines and multi-year mission datasets, significantly reducing runtime from hours to minutes."}}
{"id": "2510.00709", "pdf": "https://arxiv.org/pdf/2510.00709", "abs": "https://arxiv.org/abs/2510.00709", "authors": ["Hiroyuki Hirayama", "Yasuyuki Oka"], "title": "Strichartz estimates and its application to the well-posedness of the nonlinear Schr\u00f6dinger equations on H-type groups", "categories": ["math.AP", "35R03, 35Q55"], "comment": "27 pages", "summary": "The aim of this article is to give the well-posedness results for the Cauchy\nproblem of the nonlinear Schr\\\"odinger equation with power type nonlinearities\non H-type groups. To do this, we prove the dispersive estimate and Strichartz\nestimate. Although these estimates are given by Hierro (2005), its complete\nproofs cannot be find. We correct the statement of these estimates, give the\nproofs, and apply to the nonlinear problem. Our well-posedness results are an\nimprovement of the previous result by Bruno et al.", "AI": {"tldr": "Well-posedness results for nonlinear Schr\u00f6dinger equations with power nonlinearities on H-type groups, with corrected dispersive and Strichartz estimates.", "motivation": "To establish well-posedness for the Cauchy problem of nonlinear Schr\u00f6dinger equations on H-type groups, addressing gaps in previous proofs by Hierro (2005).", "method": "Prove corrected versions of dispersive and Strichartz estimates, then apply these to the nonlinear problem.", "result": "Improved well-posedness results that surpass previous work by Bruno et al.", "conclusion": "The paper successfully provides corrected proofs for key estimates and achieves improved well-posedness for nonlinear Schr\u00f6dinger equations on H-type groups."}}
{"id": "2510.00698", "pdf": "https://arxiv.org/pdf/2510.00698", "abs": "https://arxiv.org/abs/2510.00698", "authors": ["Fu-Chen Guo", "Pei-Zhi Zhuang", "Fei Ren", "Hong-Ya Yue", "He Yang"], "title": "Physics-Informed Extreme Learning Machine (PIELM) for Tunnelling-Induced Soil-Pile Interactions", "categories": ["cs.LG", "cs.NE", "physics.comp-ph", "physics.geo-ph"], "comment": null, "summary": "Physics-informed machine learning has been a promising data-driven and\nphysics-informed approach in geotechnical engineering. This study proposes a\nphysics-informed extreme learning machine (PIELM) framework for analyzing\ntunneling-induced soil-pile interactions. The pile foundation is modeled as an\nEuler-Bernoulli beam, and the surrounding soil is modeled as a Pasternak\nfoundation. The soil-pile interaction is formulated into a fourth-order\nordinary differential equation (ODE) that constitutes the physics-informed\ncomponent, while measured data are incorporated into PIELM as the data-driven\ncomponent. Combining physics and data yields a loss vector of the extreme\nlearning machine (ELM) network, which is trained within 1 second by the least\nsquares method. After validating the PIELM approach by the boundary element\nmethod (BEM) and finite difference method (FDM), parametric studies are carried\nout to examine the effects of ELM network architecture, data monitoring\nlocations and numbers on the performance of PIELM. The results indicate that\nmonitored data should be placed at positions where the gradients of pile\ndeflections are significant, such as at the pile tip/top and near tunneling\nzones. Two application examples highlight the critical role of physics-informed\nand data-driven approach for tunnelling-induced soil-pile interactions. The\nproposed approach shows great potential for real-time monitoring and safety\nassessment of pile foundations, and benefits for intelligent early-warning\nsystems in geotechnical engineering.", "AI": {"tldr": "Proposes a physics-informed extreme learning machine (PIELM) framework for analyzing tunneling-induced soil-pile interactions, combining Euler-Bernoulli beam theory with Pasternak foundation modeling through a fourth-order ODE.", "motivation": "To develop an efficient physics-informed machine learning approach for real-time monitoring and safety assessment of pile foundations during tunneling, addressing the need for intelligent early-warning systems in geotechnical engineering.", "method": "Combines physics (fourth-order ODE from Euler-Bernoulli beam and Pasternak foundation) with data-driven components in an extreme learning machine (ELM) network, trained within 1 second using least squares method. Validated with boundary element method and finite difference method.", "result": "PIELM achieves fast training (1 second) and shows that monitored data should be placed at positions with significant pile deflection gradients (pile tip/top and near tunneling zones). The approach effectively combines physics and data for soil-pile interaction analysis.", "conclusion": "The proposed PIELM framework demonstrates great potential for real-time monitoring and safety assessment of pile foundations, benefiting intelligent early-warning systems in geotechnical engineering by efficiently integrating physics and data-driven approaches."}}
{"id": "2510.00443", "pdf": "https://arxiv.org/pdf/2510.00443", "abs": "https://arxiv.org/abs/2510.00443", "authors": ["Lin Lin"], "title": "Mathematical and numerical analysis of quantum signal processing", "categories": ["quant-ph", "cs.NA", "math.CA", "math.NA", "68Q12, 81P68, 65T99, 65F05, 42C99"], "comment": null, "summary": "Quantum signal processing (QSP) provides a representation of scalar\npolynomials of degree $d$ as products of matrices in $\\mathrm{SU}(2)$,\nparameterized by $(d+1)$ real numbers known as phase factors. QSP is the\nmathematical foundation of quantum singular value transformation (QSVT), which\nis often regarded as one of the most important quantum algorithms of the past\ndecade, with a wide range of applications in scientific computing, from\nHamiltonian simulation to solving linear systems of equations and eigenvalue\nproblems. In this article we survey recent advances in the mathematical and\nnumerical analysis of QSP. In particular, we focus on its generalization beyond\npolynomials, the computational complexity of algorithms for phase factor\nevaluation, and the numerical stability of such algorithms. The resolution to\nsome of these problems relies on an unexpected interplay between QSP, nonlinear\nFourier analysis on $\\mathrm{SU}(2)$, fast polynomial multiplications, and\nGaussian elimination for matrices with displacement structure.", "AI": {"tldr": "This paper surveys recent advances in quantum signal processing (QSP), the mathematical foundation of quantum singular value transformation (QSVT), focusing on generalizations beyond polynomials, computational complexity of phase factor evaluation algorithms, and numerical stability.", "motivation": "QSP is fundamental to QSVT, one of the most important quantum algorithms with broad applications in scientific computing including Hamiltonian simulation, linear systems, and eigenvalue problems.", "method": "The analysis involves mathematical and numerical examination of QSP, exploring connections with nonlinear Fourier analysis on SU(2), fast polynomial multiplications, and Gaussian elimination for matrices with displacement structure.", "result": "The survey reveals unexpected interconnections between QSP and various mathematical techniques, providing insights into computational complexity and numerical stability of phase factor evaluation algorithms.", "conclusion": "Recent advances in QSP analysis demonstrate its deep mathematical connections and provide improved understanding of computational aspects crucial for practical quantum algorithm implementation."}}
{"id": "2510.00710", "pdf": "https://arxiv.org/pdf/2510.00710", "abs": "https://arxiv.org/abs/2510.00710", "authors": ["Yihong Du"], "title": "Lecture notes: Biological propagation via reaction-diffusion equations with nonlocal diffusion and free boundary", "categories": ["math.AP", "35K57, 35R20, 35R35"], "comment": null, "summary": "These notes are based on the lectures given in a mini-course at VIASM\n(Vietnam Institute for Advanced Study in Mathematics) 2025 Summer School. They\ngive a brief account of the theory (with detailed proofs) for propagation\ngoverned by a nonlocal reaction-diffusion model with free boundaries in one\nspace dimension. The main part is concerned with a KPP reaction term, though\nthe basic results on the existence and uniqueness of solutions as well as on\nthe comparison principles are for more general situations. The contents are\nmostly taken from published recent works of the author with several\ncollaborators, where the kernel function was assumed to be symmetric:\nJ(x)=J(-x). When J(x) is not symmetric, significant differences may arise in\nthe dynamics of the model, as shown in several preprints quoted in the\nreferences at the end of these notes, but many of the existing techniques can\nbe easily extended to cover the \"weakly non-symmetric case\", and this is done\nhere with all the necessary details.", "AI": {"tldr": "Lecture notes on nonlocal reaction-diffusion models with free boundaries in 1D, covering existence, uniqueness, comparison principles, and extending results to weakly non-symmetric kernels.", "motivation": "To provide a comprehensive theoretical foundation for nonlocal reaction-diffusion models with free boundaries, particularly addressing the gap in understanding asymmetric kernel cases.", "method": "Detailed mathematical proofs and theoretical analysis of propagation governed by nonlocal reaction-diffusion models, extending existing symmetric kernel results to weakly non-symmetric cases.", "result": "Established existence and uniqueness of solutions, comparison principles for general cases, and demonstrated that existing techniques can be extended to handle weakly non-symmetric kernel functions.", "conclusion": "The theory for nonlocal reaction-diffusion models with free boundaries can be successfully extended from symmetric to weakly non-symmetric kernels, though significant dynamical differences may arise in strongly asymmetric cases."}}
{"id": "2510.00779", "pdf": "https://arxiv.org/pdf/2510.00779", "abs": "https://arxiv.org/abs/2510.00779", "authors": ["Francesco Marson", "Orestis Malaspinas"], "title": "Kinetic closure of turbulence", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": null, "summary": "This letter presents a kinetic closure of the filtered Boltzmann-BGK\nequation, paving the way towards an alternative description of turbulence. The\nclosure naturally incorporates the turbulent subfilter stress tensor without\nthe need for explicit modeling, unlike in Navier-Stokes models. In contrast, it\naccounts for the subfilter turbulent diffusion in the nonconserved moments by\ngeneralizing the BGK collision operator. The model requires neither scale\nseparation nor a Smagorinsky-type ansatz for the subfilter stress tensor. The\nChapman-Enskog analysis shows that its hydrodynamic limit converges exactly to\nthe filtered Navier-Stokes equations, with velocity gradients isolating\nsubfilter contributions. Validations through lattice Boltzmann simulations of\nthe Taylor-Green vortex and the turbulent mixing layer demonstrate improved\nstability and reduced dissipation, benchmarked against the Smagorinsky model.", "AI": {"tldr": "A kinetic closure for the filtered Boltzmann-BGK equation that provides an alternative turbulence description without explicit subfilter stress modeling, improving stability and reducing dissipation compared to Smagorinsky model.", "motivation": "To develop an alternative turbulence description that naturally incorporates turbulent subfilter stress without explicit modeling, avoiding scale separation and Smagorinsky-type assumptions.", "method": "Generalizes the BGK collision operator to account for subfilter turbulent diffusion in nonconserved moments, using Chapman-Enskog analysis and lattice Boltzmann simulations for validation.", "result": "The model converges exactly to filtered Navier-Stokes equations in hydrodynamic limit, with velocity gradients isolating subfilter contributions. Validations show improved stability and reduced dissipation.", "conclusion": "The kinetic closure provides a viable alternative to traditional turbulence models, naturally handling subfilter stresses without explicit modeling and demonstrating superior performance in benchmark tests."}}
{"id": "2510.00734", "pdf": "https://arxiv.org/pdf/2510.00734", "abs": "https://arxiv.org/abs/2510.00734", "authors": ["Chuntao Chen", "Tapio Helin", "Nuutti Hyv\u00f6nen", "Yuya Suzuki"], "title": "Approximation of differential entropy in Bayesian optimal experimental design", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "stat.CO"], "comment": "28 pages, 3 figures", "summary": "Bayesian optimal experimental design provides a principled framework for\nselecting experimental settings that maximize obtained information. In this\nwork, we focus on estimating the expected information gain in the setting where\nthe differential entropy of the likelihood is either independent of the design\nor can be evaluated explicitly. This reduces the problem to maximum entropy\nestimation, alleviating several challenges inherent in expected information\ngain computation.\n  Our study is motivated by large-scale inference problems, such as inverse\nproblems, where the computational cost is dominated by expensive likelihood\nevaluations. We propose a computational approach in which the evidence density\nis approximated by a Monte Carlo or quasi-Monte Carlo surrogate, while the\ndifferential entropy is evaluated using standard methods without additional\nlikelihood evaluations. We prove that this strategy achieves convergence rates\nthat are comparable to, or better than, state-of-the-art methods for full\nexpected information gain estimation, particularly when the cost of entropy\nevaluation is negligible. Moreover, our approach relies only on mild smoothness\nof the forward map and avoids stronger technical assumptions required in\nearlier work. We also present numerical experiments, which confirm our\ntheoretical findings.", "AI": {"tldr": "A computational approach for estimating expected information gain in Bayesian optimal experimental design that separates likelihood entropy evaluation from evidence approximation, achieving efficient convergence rates.", "motivation": "Address computational challenges in large-scale inference problems like inverse problems where likelihood evaluations are expensive, by reducing the problem to maximum entropy estimation.", "method": "Approximate evidence density using Monte Carlo or quasi-Monte Carlo surrogates while evaluating differential entropy using standard methods without additional likelihood evaluations.", "result": "Achieves convergence rates comparable to or better than state-of-the-art methods for full expected information gain estimation, particularly when entropy evaluation cost is negligible.", "conclusion": "The proposed approach provides an efficient computational strategy for Bayesian optimal experimental design with mild smoothness requirements and avoids stronger technical assumptions of earlier work."}}
{"id": "2510.00715", "pdf": "https://arxiv.org/pdf/2510.00715", "abs": "https://arxiv.org/abs/2510.00715", "authors": ["Hongkai Cao", "Yihong Du", "Wenjie Ni"], "title": "Convergence to a receding wave in a monostable free boundary problem", "categories": ["math.AP", "35K57, 35R2035K57, 35R20 35K57, 35R20"], "comment": null, "summary": "We study a monostable reaction-diffusion equation of the form\n$u_t=du_{xx}+f(u)$ over a semi-infinite spatial domain $[g(t),\\infty)$, with\n$x=g(t)$ the free boundary whose evolution is governed by equations derived\nfrom a ``preferred population density'' principle, which postulates that the\nspecies with population density $u(t,x)$ and population range $[g(t),\\infty)$\nmaintains a certain density $\\delta$ at the habitat edge $x=g(t)$. In the\n``high-density'' regime, where $\\delta$ exceeds the carrying capacity of the\nfavourable environment represented by a monostable function $f(u)$, it is known\n(see \\cite{DLNS} for the case of a bounded population range $[g(t), h(t)]$)\nthat for large time, the front retreats as time advances. In this work, the\nunboundedness of the population range $[g(t),\\infty)$ allows us to prove that,\nas time $t$ converges to infinity, the free boundary $x=g(t)$ converges to\n$\\infty$ with a constant asymptotic speed $c(\\delta)>0$ determined by an\nassociated semi-wave problem, and the population density $u(t,x)$ has the\nproperty that $u(t,x+g(t))$ converges uniformly to $q_{c(\\delta)}(x)$, the\nsemi-wave profile function associated with the speed $c(\\delta)$. It turns out\nthat in the retreating situation considered here, some key techniques developed\nfor advancing fronts in related free boundary models do not work anymore. This\ndifficulty is overcome here by a ``touching method\", which uses a family of\nlower and upper solutions constructed from semi-waves of some carefully\ndesigned auxiliary problems to touch the solution $u(t,x)$ at the moving\nboundary $x=g(t)$, thereby generating a setting where the comparison principle\ncan be used to obtain the desired estimates for $g'(t)$ and $u(t,x)$. We\nbelieve this method will find applications elsewhere.", "AI": {"tldr": "The paper studies a monostable reaction-diffusion equation with a free boundary governed by a \"preferred population density\" principle, showing that in the high-density regime, the habitat edge retreats with constant asymptotic speed and the population density converges to a semi-wave profile.", "motivation": "To understand the dynamics of population fronts in unbounded domains with free boundaries, particularly in retreating scenarios where existing techniques for advancing fronts fail.", "method": "A \"touching method\" using lower and upper solutions constructed from semi-waves of auxiliary problems to apply comparison principles at the moving boundary.", "result": "The free boundary retreats to infinity with constant speed c(\u03b4)>0, and the population density converges uniformly to the semi-wave profile q_{c(\u03b4)}(x) when shifted by the boundary position.", "conclusion": "The developed touching method successfully overcomes limitations of previous techniques and provides a framework for analyzing retreating fronts in free boundary problems."}}
{"id": "2510.00863", "pdf": "https://arxiv.org/pdf/2510.00863", "abs": "https://arxiv.org/abs/2510.00863", "authors": ["Muhammad Tayyab", "Faiq Umar", "Sikander Azam", "Qaiser Rafiq", "Rajwali Khan", "Muhammad Tahir Khan", "Vineet Tirth", "Ali Algahtani"], "title": "Orbital-Engineered Spin Asymmetry and Multifunctionality in Eu-Activated CaAlSiN$_3$: A First-Principles Roadmap to Optical-Thermoelectric Fusion", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Rare-earth-doped nitride phosphors are promising materials for solid-state\nlighting and photonic applications due to their thermal stability, sharp\nemission lines, and strong UV-blue absorption. In this work, we present a\nfirst-principles density functional theory (DFT) study, using the GGA+U\napproach, of pristine and Eu3+-doped CaAlSiN3 at doping levels of 8.5% and 17%.\nElectronic structure calculations show that Eu incorporation introduces\nlocalized 4f states within the band gap, leading to band-gap narrowing and\nenabling red photoluminescence through the 5D0 -> 7F2 transition.\nSpin-polarized density of states and spin density mapping confirm the magnetic\nnature of Eu3+, while charge density, Bader analysis, and electron localization\nfunction (ELF) indicate mixed ionic-covalent bonding and charge transfer from\nEu to neighboring N and Al atoms, stabilizing the doped lattice. Optical\nspectra, including dielectric function, absorption, refractive index, and\nreflectivity, reveal red-shifted absorption edges and enhanced visible-range\nlight-matter interactions, consistent with experimental red to near-infrared\nemission. Formation energy analysis confirms the thermodynamic feasibility of\nEu substitution, while elastic constants and Pugh's ratio indicate mechanical\nrobustness and ductility. Thermoelectric transport properties, obtained using\nWIEN2k and BoltzTraP, suggest that moderate Eu3+ doping improves the power\nfactor and reduces lattice thermal conductivity through disorder scattering.\nThese results establish Eu-doped CaAlSiN3 as a stable and efficient\nred-emitting phosphor for white light-emitting diodes (WLEDs) and provide\ntheoretical insights for crystal site engineering in advanced optoelectronic\nmaterials.", "AI": {"tldr": "DFT study shows Eu3+-doped CaAlSiN3 is a stable red-emitting phosphor with improved optical and thermoelectric properties for white LED applications.", "motivation": "To understand the electronic, optical, and thermoelectric properties of Eu3+-doped CaAlSiN3 for solid-state lighting applications, particularly white LEDs.", "method": "First-principles DFT calculations using GGA+U approach, analyzing electronic structure, optical spectra, formation energy, elastic constants, and thermoelectric transport properties.", "result": "Eu doping introduces localized 4f states, narrows band gap, enables red photoluminescence, improves thermoelectric power factor, and maintains mechanical robustness.", "conclusion": "Eu-doped CaAlSiN3 is a promising stable red phosphor for WLEDs with enhanced optical and thermoelectric performance."}}
{"id": "2510.00768", "pdf": "https://arxiv.org/pdf/2510.00768", "abs": "https://arxiv.org/abs/2510.00768", "authors": ["Fabio Camilli", "Qing Tang", "Yong-shen Zhou"], "title": "A semi-Lagrangian method for solving state constraint Mean Field Games in Macroeconomics", "categories": ["math.OC", "cs.NA", "math.NA"], "comment": null, "summary": "We study continuous-time heterogeneous agent models cast as Mean Field Games,\nin the Aiyagari-Bewley-Huggett framework. The model couples a\nHamilton-Jacobi-Bellman equation for individual optimization with a\nFokker-Planck-Kolmogorov equation for the wealth distribution. We establish a\ncomparison principle for constrained viscosity solutions of the HJB equation\nand propose a semi-Lagrangian (SL) scheme for its numerical solution, proving\nconvergence via the Barles-Souganidis method. A policy iteration algorithm\nhandles state constraints, and a dual SL scheme is used for the FPK equation.\nNumerical methods are presented in a fully discrete, implementable form.", "AI": {"tldr": "The paper analyzes continuous-time heterogeneous agent models in the Aiyagari-Bewley-Huggett framework using Mean Field Games, coupling HJB and FPK equations with numerical solution methods.", "motivation": "To study continuous-time heterogeneous agent models in the Aiyagari-Bewley-Huggett framework using Mean Field Games approach, addressing the coupling between individual optimization and wealth distribution dynamics.", "method": "Establishes comparison principle for constrained viscosity solutions of HJB equation, proposes semi-Lagrangian scheme for numerical solution with convergence proof via Barles-Souganidis method, uses policy iteration for state constraints, and dual SL scheme for FPK equation.", "result": "Develops fully discrete, implementable numerical methods for solving the coupled HJB-FPK system in continuous-time heterogeneous agent models.", "conclusion": "The paper provides rigorous mathematical foundations and practical numerical methods for analyzing continuous-time heterogeneous agent models within the Mean Field Games framework, with proven convergence properties."}}
{"id": "2510.00737", "pdf": "https://arxiv.org/pdf/2510.00737", "abs": "https://arxiv.org/abs/2510.00737", "authors": ["Heikki Lohi"], "title": "High-order Regularity Theory for High-contrast Elliptic Homogenization", "categories": ["math.AP"], "comment": "37 pages", "summary": "The purpose of this article is to formulate and prove a global high-order\nregularity result within the high-contrast framework of elliptic\nhomogenization. In order to achieve this, we also present a version of the\nhigh-contrast Caccioppoli inequality.", "AI": {"tldr": "Global high-order regularity result in elliptic homogenization with high-contrast framework, including a high-contrast Caccioppoli inequality.", "motivation": "To establish global high-order regularity results within the high-contrast framework of elliptic homogenization, which requires developing specialized mathematical tools.", "method": "Formulate and prove a global high-order regularity result, and present a version of the high-contrast Caccioppoli inequality to support the analysis.", "result": "Successfully formulated and proved the global high-order regularity result within the high-contrast elliptic homogenization framework.", "conclusion": "The paper provides important mathematical foundations for high-contrast elliptic homogenization through the development of global regularity results and specialized inequalities."}}
{"id": "2510.00878", "pdf": "https://arxiv.org/pdf/2510.00878", "abs": "https://arxiv.org/abs/2510.00878", "authors": ["Radek Folprecht", "Franti\u0161ek Knapp", "Giovanni De Gregorio", "Riccardo Mancino", "Petr Vesel\u00fd", "Nicola Lo Iudice"], "title": "Bulk and spectroscopic nuclear properties within an ab initio renormalized random-phase approximation framework", "categories": ["nucl-th", "physics.comp-ph"], "comment": "6 pages, 5 figures", "summary": "A modern chiral potential incorporating the three-body force is adopted to\ninvestigate bulk properties, spectra, and nuclear responses of\nclosed-(sub)shell nuclei throughout the nuclear chart within a particle-hole\n(p-h) renormalized random-phase approximation (RRPA) scheme using a Hartree-\nFock (HF) single-particle basis. Our analysis shows that all instabilities\ninduced by the quasiboson approximation (QBA) underlying RPA are removed and an\noverall better consistency with the experiments is achieved for all observables\nof the investigated nuclei. The residual discrepancies point out the need of\ngoing beyond the p-h space.", "AI": {"tldr": "A chiral potential with three-body force is used in a particle-hole renormalized RPA scheme to study closed-shell nuclei properties, removing QBA instabilities and improving experimental agreement.", "motivation": "To address instabilities in traditional RPA methods and improve consistency with experimental data for nuclear properties.", "method": "Particle-hole renormalized random-phase approximation (RRPA) using Hartree-Fock single-particle basis with modern chiral potential including three-body force.", "result": "All quasiboson approximation instabilities are removed and better consistency with experiments achieved for all observables of investigated closed-shell nuclei.", "conclusion": "The approach successfully addresses RPA limitations but residual discrepancies indicate need to go beyond particle-hole space."}}
{"id": "2510.00937", "pdf": "https://arxiv.org/pdf/2510.00937", "abs": "https://arxiv.org/abs/2510.00937", "authors": ["Manfred Opper", "Sebastian Reich"], "title": "Digital Twins: McKean-Pontryagin Control for Partially Observed Physical Twins", "categories": ["math.OC", "cs.NA", "math.NA"], "comment": null, "summary": "Optimal control for fully observed diffusion processes is well established\nand has led to numerous numerical implementations based on, for example,\nBellman's principle, model free reinforcement learning, Pontryagin's maximum\nprinciple, and model predictive control. On the contrary, much fewer algorithms\nare available for optimal control of partially observed processes. However,\nthis scenario is central to the digital twin paradigm where a physical twin is\npartially observed and control laws are derived based on a digital twin. In\nthis paper, we contribute to this challenge by combining data assimilation in\nthe form of the ensemble Kalman filter with the recently proposed\nMcKean-Pontryagin approach to stochastic optimal control. We derive forward\nevolving mean-field evolution equations for states and co-states which\nsimultaneously allow for an online assimilation of data as well as an online\ncomputation of control laws. The proposed methodology is therefore perfectly\nsuited for real time applications of digital twins. We present numerical\nresults for a controlled Lorenz-63 system and an inverted pendulum.", "AI": {"tldr": "This paper proposes a novel approach for optimal control of partially observed diffusion processes by combining ensemble Kalman filter data assimilation with the McKean-Pontryagin stochastic optimal control method, enabling real-time digital twin applications.", "motivation": "While optimal control for fully observed diffusion processes is well-established, there are fewer algorithms available for partially observed processes, which is crucial for digital twin paradigms where physical systems are only partially observed and control is derived from digital models.", "method": "The methodology combines data assimilation using ensemble Kalman filter with the McKean-Pontryagin approach to stochastic optimal control, deriving forward-evolving mean-field evolution equations for states and co-states that enable simultaneous online data assimilation and control law computation.", "result": "The proposed method is demonstrated through numerical experiments on a controlled Lorenz-63 system and an inverted pendulum, showing its effectiveness for real-time applications.", "conclusion": "The combined approach of ensemble Kalman filter data assimilation with McKean-Pontryagin optimal control provides a practical solution for real-time digital twin applications where partial observations and online control computation are required."}}
{"id": "2510.00755", "pdf": "https://arxiv.org/pdf/2510.00755", "abs": "https://arxiv.org/abs/2510.00755", "authors": ["Jiayi Qiang", "Yawei Wei", "Mengnan Zhang"], "title": "Removable singularities and Harnack inequality for nonlinear H\u00f6rmander degenerate subelliptic equations", "categories": ["math.AP"], "comment": null, "summary": "This paper concerns the quasilinear subelliptic function derived from\nH\\\"ormander vector fields. Based on the significant work of J. Serrin in\n\\cite{SER}, M. Meier in \\cite{MM1}, and L. Capogna, D. Danielli and N. Garofalo\nin \\cite{LC1,LDN}, we obtain the removable singularities and Harnack inequality\nby a sharp Sobolev inequalities under weaker integrability of coefficients in\nstructure conditions. Furthermore, we get the H\\\"older continuity when domain\n$\\Omega$ is equiregular.", "AI": {"tldr": "This paper studies quasilinear subelliptic equations from H\u00f6rmander vector fields, proving removable singularities, Harnack inequality via sharp Sobolev inequalities, and H\u00f6lder continuity in equiregular domains.", "motivation": "To extend previous work by Serrin, Meier, Capogna, Danielli, and Garofalo on subelliptic equations by establishing key results under weaker integrability conditions for coefficients.", "method": "Uses sharp Sobolev inequalities and analysis of quasilinear subelliptic equations derived from H\u00f6rmander vector fields, with weaker coefficient integrability requirements.", "result": "Proves removable singularities, Harnack inequality, and obtains H\u00f6lder continuity when the domain is equiregular.", "conclusion": "The paper successfully establishes fundamental regularity results for quasilinear subelliptic equations under more general conditions than previous work."}}
{"id": "2510.00955", "pdf": "https://arxiv.org/pdf/2510.00955", "abs": "https://arxiv.org/abs/2510.00955", "authors": ["Ahmad Ali", "Haris Haider", "Sikander Azam", "Muhammad Talha", "Muhammad Jawad", "Imran Shakir"], "title": "Exploring Chalcogen Influence on Sc2BeX4 (X = S, Se) for Green Energy Applications Using DFT", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "We present a first-principles density functional theory study of the\nstructural, electronic, optical, and thermoelectric properties of Sc2BeX4 (X =\nS, Se) chalcogenides for energy applications. Both compounds are dynamically\nand thermodynamically stable, exhibiting negative formation energies of -2.6 eV\n(Sc2BeS4) and -2.2 eV (Sc2BeSe4). They feature direct band gaps of 1.8 eV and\n1.2 eV, respectively, within the TB-mBJ approximation, indicating strong\nvisible-light absorption. Optical analysis reveals high static dielectric\nconstants (9.0 for S and 16.5 for Se), absorption peaks near 13.5 eV, and\nreflectivity below 30 percent. Thermoelectric calculations predict p-type\nconduction with Seebeck coefficients reaching 2.5e-4 V/K and electrical\nconductivities of 2.45e18 and 1.91e18 (Ohm m s)^-1 at 300 K. Power factors\napproach 1.25e11 W/K^2 m s, with a maximum dimensionless figure of merit (ZT)\nof 0.80 at 800 K. Calculated Debye temperatures (420 K for Sc2BeS4 and 360 K\nfor Sc2BeSe4) imply low lattice thermal conductivity. These findings establish\nSc2BeX4 chalcogenides as promising materials for photovoltaic and\nthermoelectric applications.", "AI": {"tldr": "First-principles DFT study shows Sc2BeX4 (X=S,Se) chalcogenides are stable materials with direct band gaps (1.8 eV and 1.2 eV), strong visible-light absorption, and excellent thermoelectric properties, making them promising for photovoltaic and thermoelectric applications.", "motivation": "To investigate Sc2BeX4 chalcogenides for energy applications, specifically their potential in photovoltaic and thermoelectric devices, given the need for efficient energy conversion materials.", "method": "First-principles density functional theory calculations were used to study structural, electronic, optical, and thermoelectric properties, including TB-mBJ approximation for band gaps and various transport property calculations.", "result": "Both compounds are dynamically and thermodynamically stable with negative formation energies. They exhibit direct band gaps suitable for visible-light absorption, high dielectric constants, and promising thermoelectric performance with maximum ZT of 0.80 at 800 K.", "conclusion": "Sc2BeX4 chalcogenides are promising materials for photovoltaic and thermoelectric applications due to their stability, suitable band gaps, strong optical absorption, and excellent thermoelectric properties."}}
{"id": "2510.00999", "pdf": "https://arxiv.org/pdf/2510.00999", "abs": "https://arxiv.org/abs/2510.00999", "authors": ["Daniel Fadel", "Henrique N. S\u00e1 Earp", "Tom\u00e1s S. R. Silva"], "title": "The exterior derivative and the mean value equality in $\\mathbb{R}^n$", "categories": ["math.DG", "cs.NA", "math.NA", "26B05, 58A10, 65D25"], "comment": null, "summary": "This survey revisits classical results in vector calculus and analysis by\nexploring a generalised perspective on the exterior derivative, interpreting it\nas a measure of \"infinitesimal flux\". This viewpoint leads to a\nhigher-dimensional analogue of the Mean Value Theorem, valid for differential\n$k$-forms, and provides a natural formulation of Stokes' theorem that mirrors\nthe exact hypotheses of the Fundamental Theorem of Calculus - without requiring\nfull $C^1$ smoothness of the differential form.\n  As a numerical application, we propose an algorithm for exterior\ndifferentiation in $\\mathbb{R}^n$ that relies solely on black-box access to the\ndifferential form, offering a practical tool for computation without the need\nfor mesh discretization or explicit symbolic expressions.", "AI": {"tldr": "A survey that reinterprets the exterior derivative as infinitesimal flux, leading to a higher-dimensional Mean Value Theorem and a simplified Stokes' theorem formulation. Also proposes a mesh-free numerical algorithm for exterior differentiation.", "motivation": "To provide a fresh perspective on classical vector calculus by generalizing the concept of exterior derivative as a measure of infinitesimal flux, and to develop practical computational tools that don't require mesh discretization.", "method": "Reinterprets exterior derivative through the lens of infinitesimal flux, establishes a higher-dimensional analogue of the Mean Value Theorem for differential k-forms, and develops a numerical algorithm for exterior differentiation using only black-box access to differential forms.", "result": "Achieves a natural formulation of Stokes' theorem that mirrors the Fundamental Theorem of Calculus without requiring full C^1 smoothness, and creates a practical computational algorithm that operates without mesh discretization or symbolic expressions.", "conclusion": "The infinitesimal flux perspective provides a unified framework for classical vector calculus results and enables practical numerical computation of exterior derivatives in R^n through black-box access to differential forms."}}
{"id": "2510.00784", "pdf": "https://arxiv.org/pdf/2510.00784", "abs": "https://arxiv.org/abs/2510.00784", "authors": ["Isidro Benaroya", "Alberto Enciso", "Daniel Peralta-Salas"], "title": "Splitting and Merging of Stagnation Points of Solutions to the 2D Navier-Stokes Equations", "categories": ["math.AP"], "comment": null, "summary": "We construct solutions to the Navier-Stokes equations on $\\mathbf{R}^2$ with\nan arbitrary number of stagnation points which merge and split along\ntrajectories that can be prescribed freely, up to a small deformation.", "AI": {"tldr": "Construction of Navier-Stokes solutions on R\u00b2 with multiple stagnation points that merge and split along prescribed trajectories.", "motivation": "To demonstrate the existence of Navier-Stokes solutions with complex stagnation point dynamics that can be controlled and prescribed.", "method": "Constructing specific solutions to the Navier-Stokes equations that allow for arbitrary numbers of stagnation points with prescribed merging and splitting trajectories.", "result": "Successfully constructed solutions where stagnation points can merge and split along trajectories that can be freely prescribed up to small deformations.", "conclusion": "The paper shows that complex stagnation point dynamics in 2D Navier-Stokes flows can be engineered and controlled through appropriate solution construction."}}
{"id": "2510.01056", "pdf": "https://arxiv.org/pdf/2510.01056", "abs": "https://arxiv.org/abs/2510.01056", "authors": ["Muhammad Shahzad", "Sikander Azam", "Syed Awais Ahmad", "Ming Li"], "title": "High-Pressure DFT Study of BeX (X = S, Se, Te): Phonon Spectra, Optical Properties, and Thermodynamic Stability for Advanced Optoelectronic Applications", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "We present a comprehensive first-principles investigation of the structural,\nelectronic, optical, and thermodynamic properties of BeX compounds (X = S, Se,\nTe) under hydrostatic pressures ranging from 0 to 10 GPa. Calculations were\nperformed using density functional theory (DFT) within the Generalized Gradient\nApproximation (GGA) using the Perdew-Burke-Ernzerhof (PBE) functional, as\nimplemented in the CASTEP code. Phonon dispersion analyses confirm the\ndynamical stability of all compounds across the studied pressure range, as\nindicated by the absence of imaginary frequencies throughout the Brillouin\nzone. The electronic band structure reveals pressure-induced band\nmodifications, with BeS retaining the widest bandgap. Optical properties,\nincluding the dielectric function, absorption coefficient, reflectivity, and\nenergy loss spectra, were computed for photon energies up to 30 eV. The\nmaterials exhibit strong optical absorption in the ultraviolet region,\nsuggesting potential for UV optoelectronic applications. Thermodynamic\nparameters such as Debye temperature, heat capacity, and entropy were\nevaluated, showing pressure-dependent trends. Notably, increasing pressure\nleads to reduced atomic vibrations and heat capacity, while the Gibbs free\nenergy exhibits a consistent slope with temperature, reflecting entropy\nvariation. These results highlight the suitability of BeX compounds for\npressure-sensitive optoelectronic and thermoelectric devices, as well as\nthermal barrier applications.", "AI": {"tldr": "First-principles DFT study of BeX compounds (X=S, Se, Te) under 0-10 GPa pressure, showing structural stability, pressure-dependent electronic/optical properties, and thermodynamic behavior suitable for optoelectronic and thermoelectric applications.", "motivation": "To systematically investigate the pressure-dependent structural, electronic, optical, and thermodynamic properties of BeX compounds for potential applications in pressure-sensitive optoelectronic and thermoelectric devices.", "method": "Density functional theory (DFT) calculations using GGA-PBE functional implemented in CASTEP code, with phonon dispersion analysis and property calculations across 0-10 GPa pressure range.", "result": "All BeX compounds remain dynamically stable under pressure; BeS maintains widest bandgap; strong UV optical absorption observed; pressure reduces atomic vibrations and heat capacity while Gibbs free energy shows consistent temperature dependence.", "conclusion": "BeX compounds are suitable for pressure-sensitive optoelectronic and thermoelectric devices, with strong UV absorption making them promising for UV optoelectronic applications and thermal barrier coatings."}}
{"id": "2510.01153", "pdf": "https://arxiv.org/pdf/2510.01153", "abs": "https://arxiv.org/abs/2510.01153", "authors": ["Yesom Park", "Shu Liu", "Mo Zhou", "Stanley Osher"], "title": "Neural Hamilton--Jacobi Characteristic Flows for Optimal Transport", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We present a novel framework for solving optimal transport (OT) problems\nbased on the Hamilton--Jacobi (HJ) equation, whose viscosity solution uniquely\ncharacterizes the OT map. By leveraging the method of characteristics, we\nderive closed-form, bidirectional transport maps, thereby eliminating the need\nfor numerical integration. The proposed method adopts a pure minimization\nframework: a single neural network is trained with a loss function derived from\nthe method of characteristics of the HJ equation. This design guarantees\nconvergence to the optimal map while eliminating adversarial training stages,\nthereby substantially reducing computational complexity. Furthermore, the\nframework naturally extends to a wide class of cost functions and supports\nclass-conditional transport. Extensive experiments on diverse datasets\ndemonstrate the accuracy, scalability, and efficiency of the proposed method,\nestablishing it as a principled and versatile tool for OT applications with\nprovable optimality.", "AI": {"tldr": "A novel Hamilton-Jacobi equation-based framework for optimal transport that uses method of characteristics to derive closed-form bidirectional transport maps, eliminating numerical integration and adversarial training.", "motivation": "To develop a more efficient and principled approach to optimal transport problems that avoids computational complexity of numerical integration and adversarial training while guaranteeing convergence to optimal maps.", "method": "Uses Hamilton-Jacobi equation whose viscosity solution characterizes OT map, applies method of characteristics to derive closed-form bidirectional transport maps, trains single neural network with loss from HJ characteristics method.", "result": "Achieves accurate, scalable, and efficient optimal transport across diverse datasets, supports various cost functions and class-conditional transport, with provable optimality.", "conclusion": "The framework provides a principled and versatile tool for OT applications that eliminates adversarial training, reduces computational complexity, and guarantees convergence to optimal maps."}}
{"id": "2510.00812", "pdf": "https://arxiv.org/pdf/2510.00812", "abs": "https://arxiv.org/abs/2510.00812", "authors": ["Shuai Wang", "Guochun Wu", "Xin Zhong"], "title": "Global weak solutions and incompressible limit of two-dimensional isentropic compressible magnetohydrodynamic equations with ripped density and large initial data", "categories": ["math.AP"], "comment": "26 pages", "summary": "We establish the global existence of weak solutions to isentropic\ncompressible magnetohydrodynamic equations with ripped density in the whole\nplane provided the bulk viscosity coefficient is properly large. Moreover, we\nshow that such solutions converge globally in time to a weak solution of the\ninhomogeneous incompressible magnetohydrodynamic equations when the bulk\nviscosity coefficient tends to infinity. In particular, the initial data can be\narbitrarily large and vacuum states are allowed in interior regions. Our method\nrelies on the effective viscous flux and a Desjardins-type logarithmic\ninterpolation inequality. To the best of our knowledge, this is the first\nresult concerning incompressible limit of isentropic compressible\nmagnetohydrodynamic equations for the large bulk viscosity.", "AI": {"tldr": "Global existence of weak solutions for isentropic compressible magnetohydrodynamic equations with large bulk viscosity, and their convergence to incompressible equations when viscosity tends to infinity.", "motivation": "To establish existence results for compressible magnetohydrodynamic equations with large initial data and vacuum states, and study their incompressible limit behavior.", "method": "Uses effective viscous flux and Desjardins-type logarithmic interpolation inequality to prove global existence and convergence.", "result": "Proves global existence of weak solutions for large bulk viscosity, and shows convergence to inhomogeneous incompressible magnetohydrodynamic equations as viscosity approaches infinity.", "conclusion": "First result on incompressible limit of isentropic compressible magnetohydrodynamic equations for large bulk viscosity, allowing arbitrarily large initial data and interior vacuum states."}}
{"id": "2510.01170", "pdf": "https://arxiv.org/pdf/2510.01170", "abs": "https://arxiv.org/abs/2510.01170", "authors": ["Weiyi Xiaa", "Maxim Moraru", "Ying Wai Li", "Cai-Zhuang Wang"], "title": "exa-AMD: An Exascale-Ready Framework for Accelerating the Discovery and Design of Functional Materials", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Exascale computing is transforming the field of materials science by enabling\nsimulations of unprecedented scale and complexity. We present exa-AMD, an\nopen-source, high-performance simulation code specifically designed for\naccelerated materials discovery on modern supercomputers. exa-AMD addresses the\ncomputational challenges inherent in large-scale materials discovery by\nemploying task-based parallelization strategies and optimized data management\ntailored for high performance computers. The code features a modular design,\nsupports both distributed and on-node parallelism, and is designed for\nflexibility and extensibility to accommodate a wide range of materials science\napplications. We detail the underlying algorithms and implementation, and\nprovide comprehensive benchmark results demonstrating strong scaling across\nmultiple high performance computing platforms. We provide two example\napplications, the design of Fe-Co-Zr and Na-B-C compounds, to illustrate the\ncode's effectiveness in accelerating the discovery and characterization of\nnovel materials. With only a set of elements as input, exa-AMD automates the\nworkflow on CPU or GPU-enabled clusters, outputs the structures and energies of\npromising candidates, and updates the phase diagram. exa-AMD is publicly\navailable on GitHub, with detailed documentation and reproducible test cases to\nsupport community engagement and collaborative research. This work aims to\nadvance materials science by providing a robust, efficient, and extensible tool\nready for exascale platforms.ady for exascale platforms.", "AI": {"tldr": "exa-AMD is an open-source high-performance simulation code for accelerated materials discovery on exascale supercomputers, featuring task-based parallelization, modular design, and automated workflows for discovering novel materials.", "motivation": "To address computational challenges in large-scale materials discovery and leverage exascale computing for unprecedented simulations in materials science.", "method": "Employs task-based parallelization strategies, optimized data management, modular design supporting distributed and on-node parallelism, and automated workflows on CPU/GPU clusters.", "result": "Demonstrates strong scaling across multiple HPC platforms, successfully applied to design Fe-Co-Zr and Na-B-C compounds, automating structure discovery and phase diagram updates.", "conclusion": "exa-AMD provides a robust, efficient, and extensible tool for materials science research on exascale platforms, advancing accelerated materials discovery through community-accessible open-source software."}}
{"id": "2510.01168", "pdf": "https://arxiv.org/pdf/2510.01168", "abs": "https://arxiv.org/abs/2510.01168", "authors": ["Zhaosong Lu", "Xiangyuan Wang"], "title": "A first-order method for constrained nonconvex--nonconcave minimax problems under a local Kurdyka-\u0141ojasiewicz condition", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "stat.ML", "90C26, 90C30, 90C47, 90C99, 65K05"], "comment": "25 pages", "summary": "We study a class of constrained nonconvex--nonconcave minimax problems in\nwhich the inner maximization involves potentially complex constraints. Under\nthe assumption that the inner problem of a novel lifted minimax problem\nsatisfies a local Kurdyka-{\\L}ojasiewicz (KL) condition, we show that the\nmaximal function of the original problem enjoys a local H\\\"older smoothness\nproperty. We also propose a sequential convex programming (SCP) method for\nsolving constrained optimization problems and establish its convergence rate\nunder a local KL condition. Leveraging these results, we develop an inexact\nproximal gradient method for the original minimax problem, where the inexact\ngradient of the maximal function is computed via the SCP method applied to a\nlocally KL-structured subproblem. Finally, we establish complexity guarantees\nfor the proposed method in computing an approximate stationary point of the\noriginal minimax problem.", "AI": {"tldr": "The paper proposes an inexact proximal gradient method for constrained nonconvex-nonconcave minimax problems, using sequential convex programming to compute gradients and establishing convergence under local KL conditions.", "motivation": "To address constrained nonconvex-nonconcave minimax problems where the inner maximization involves complex constraints, which are challenging due to their non-smooth nature and lack of standard convexity assumptions.", "method": "Developed an inexact proximal gradient method where the gradient of the maximal function is computed via sequential convex programming applied to locally KL-structured subproblems.", "result": "Established that the maximal function enjoys local H\u00f6lder smoothness under local KL conditions, and provided complexity guarantees for computing approximate stationary points.", "conclusion": "The proposed method effectively handles constrained minimax problems with complex inner constraints by leveraging local KL structure and sequential convex programming, with proven convergence rates."}}
{"id": "2510.00888", "pdf": "https://arxiv.org/pdf/2510.00888", "abs": "https://arxiv.org/abs/2510.00888", "authors": ["Saikat Mazumdar", "Bruno Premoselli"], "title": "Compactness of conformal metrics with constant $Q$-curvature of higher order", "categories": ["math.AP", "math.DG"], "comment": "Comments are welcome", "summary": "Let $k\\ge1$ be a positive integer and let $P_g$ be the GJMS operator $P_{g}$\nof order $2k$ on a closed Riemannian manifold $(M,g)$ of dimension $n>2k$. We\ninvestigate the compactness of the set of conformal metrics to $g$ with\nprescribed constant positive $Q$-curvature of order $2k$- or, equivalently, of\nthe set of positive solutions for the $2k$-th order $Q$-curvature equation.\nUnder a natural positivity-preserving condition on $P_{g}$ we establish\ncompactness, for an arbitrary $1 \\le k < \\frac{n}{2}$, under the following\nassumptions: $(M,g)$ is locally conformally flat and $P_g$ has positive mass in\n$M$, or $2k+1 \\le n \\le 2k+5$ and $P_g$ has positive mass in $M$, or $n \\ge\n2k+4$ and $|\\text{W}_g|_g >0$ in $M$.\n  For an arbitrary $1 \\le k < \\frac{n}{2}$, the expression of $P_g$ is not\nexplicit, which is an obstacle to proving compactness. We overcome this by\nrelying on Juhl's celebrated recursive formulae for $P_g$ to perform a refined\nblow-up analysis for solutions of the $Q$-curvature equation and to prove a\nWeyl vanishing result for $P_g$. This is the first compactness result for an\narbitrary $1 \\le k < \\frac{n}{2}$ and the first successful instance where\nJuhl's formulae are used to yield compactness. Our result also hints that the\nthreshold dimension for compactness for the $2k$-th order $Q$-curvature\nequation diverges as $k \\to + \\infty$.", "AI": {"tldr": "The paper establishes compactness results for conformal metrics with prescribed constant positive Q-curvature of order 2k on closed Riemannian manifolds, overcoming the challenge of non-explicit GJMS operators using Juhl's recursive formulae.", "motivation": "To investigate the compactness of conformal metrics with prescribed constant positive Q-curvature, particularly addressing the challenge that GJMS operators P_g are not explicit for arbitrary k, which has been an obstacle to proving compactness results.", "method": "Uses Juhl's celebrated recursive formulae for the GJMS operator P_g to perform refined blow-up analysis for solutions of the Q-curvature equation and prove a Weyl vanishing result for P_g.", "result": "Proves compactness under three scenarios: (1) locally conformally flat manifolds with positive mass, (2) dimensions 2k+1 \u2264 n \u2264 2k+5 with positive mass, or (3) dimensions n \u2265 2k+4 with non-zero Weyl tensor. This is the first compactness result for arbitrary 1 \u2264 k < n/2.", "conclusion": "The paper successfully overcomes the non-explicit nature of GJMS operators using Juhl's formulae, establishing compactness and suggesting that the threshold dimension for compactness diverges as k \u2192 \u221e."}}
{"id": "2510.01181", "pdf": "https://arxiv.org/pdf/2510.01181", "abs": "https://arxiv.org/abs/2510.01181", "authors": ["Dawei Zhong", "William Munizzi", "Huo Chen", "Wibe Albert de Jong"], "title": "Combining Error Detection and Mitigation: A Hybrid Protocol for Near-Term Quantum Simulation", "categories": ["quant-ph", "physics.comp-ph"], "comment": "32 pages, 20 figures", "summary": "Practical implementation of quantum error correction is currently limited by\nnear-term quantum hardware. In contrast, quantum error mitigation has\ndemonstrated strong promise for improving the performance of noisy quantum\ncircuits without the requirement of full fault tolerance. In this work, we\ndevelop a hybrid error suppression protocol that integrates Pauli twirling,\nprobabilistic error cancellation, and the $[[n, n-2, 2]]$ quantum error\ndetecting code. In addition, to reduce overhead from error mitigation\ncomponents of our method, we modify Pauli twirling by lowering the number of\nPauli operators in the twirling set, and apply probabilistic error cancellation\nat the end of the encoded circuit to remove undetectable errors. Finally, we\ndemonstrate our protocol on a non-Clifford variational quantum eigensolver\ncircuit that estimates the ground state energy of $\\rm H_2$ using both\n\\texttt{qiskit} AerSimulator and the IBM quantum processor\n\\texttt{ibm\\_brussels}.", "AI": {"tldr": "A hybrid error suppression protocol combining Pauli twirling, probabilistic error cancellation, and quantum error detecting codes to improve performance of noisy quantum circuits without full fault tolerance.", "motivation": "Quantum error correction requires fault-tolerant hardware, while error mitigation offers practical improvements for near-term quantum devices without full fault tolerance requirements.", "method": "Developed a hybrid protocol integrating Pauli twirling, probabilistic error cancellation, and the [[n, n-2, 2]] quantum error detecting code. Modified Pauli twirling to reduce overhead by lowering the number of Pauli operators, and applied probabilistic error cancellation at the end of encoded circuits to remove undetectable errors.", "result": "Demonstrated the protocol on a non-Clifford variational quantum eigensolver circuit estimating the ground state energy of H\u2082 using both qiskit AerSimulator and IBM quantum processor ibm_brussels.", "conclusion": "The hybrid error suppression protocol effectively improves quantum circuit performance on near-term hardware by combining multiple error mitigation techniques with reduced overhead."}}
{"id": "2510.00893", "pdf": "https://arxiv.org/pdf/2510.00893", "abs": "https://arxiv.org/abs/2510.00893", "authors": ["Nidhi Nidhi", "K. Sreenadh"], "title": "Existence of multiple normalized solutions to a critical growth Choquard equation involving mixed operator", "categories": ["math.AP"], "comment": null, "summary": "In this paper we study the normalized solutions of the following critical\ngrowth Choquard equation with mixed local and non-local operators:\n  \\begin{equation*}\n  \\begin{array}{rcl}\n  -\\Delta u +(-\\Delta)^s u & = & \\lambda u +\\mu |u|^{p-2}u\n+(I_{\\alpha}*|u|^{2^*_{\\alpha}})|u|^{2^*_{\\alpha}-2}u \\text{ in }\n\\mathbb{R}^N;\\;\\;\n  \\left\\| u \\right\\|_2 & = & \\tau,\n  \\end{array}\n  \\end{equation*}\n  here $N\\geq 3$, $\\tau>0$, $I_{\\alpha}$ is the Riesz potential of order\n$\\alpha\\in (0,N)$, $2^*_{\\alpha}=\\frac{N+\\alpha}{N-2}$ is the critical exponent\ncorresponding to the Hardy Littlewood Sobolev inequality, $(-\\Delta)^s$ is the\nnon-local fractional Laplacian operator with $s\\in (0,1)$, $\\mu>0$ is a\nparameter and $\\lambda$ appears as Lagrange multiplier. We have shown the\nexistence of atleast two distinct solutions in the presence of mass subcritical\nperturbation, $\\mu |u|^{p-2}u$ with $2<p<2+\\frac{4s}{N}$ under some assumptions\non $\\tau$.", "AI": {"tldr": "Existence of normalized solutions for critical growth Choquard equation with mixed local and non-local operators, showing at least two distinct solutions under mass subcritical perturbation.", "motivation": "To study normalized solutions of critical Choquard equations combining local Laplacian and fractional Laplacian operators, addressing the challenge of critical exponents in the presence of mixed operators.", "method": "Analysis of the critical Choquard equation with mixed operators using variational methods, focusing on the mass constraint and Lagrange multiplier approach.", "result": "Proved existence of at least two distinct normalized solutions when the mass subcritical perturbation parameter satisfies 2 < p < 2 + 4s/N, under certain assumptions on \u03c4.", "conclusion": "The paper successfully establishes multiplicity results for normalized solutions in critical Choquard equations with mixed local and non-local operators, extending previous work to more complex operator combinations."}}
{"id": "2510.00917", "pdf": "https://arxiv.org/pdf/2510.00917", "abs": "https://arxiv.org/abs/2510.00917", "authors": ["Margaret Beck", "Ryan Goh", "Alanna Haslam-Hyde"], "title": "Exponential Dichotomies in Higher-Dimensional Spatial Dynamics for Elliptic Partial Differential Equations", "categories": ["math.AP", "math.DS", "35A24, 34D09, 37L10, 35B36"], "comment": null, "summary": "Exponential dichotomies, when they exist, provide powerful information about\nthe structure of bounded solutions even in the case of an ill-posed\nevolutionary equation. The method of spatial dynamics, in which one views a\nspatial variable as a time-like evolutionary variable, allows for the use of\nclassical dynamical systems techniques, such as exponential dichotomies, in\nbroader contexts. This has been utilized to study stationary, traveling wave,\ntime-periodic, and spiral wave solutions of PDEs on spatial domains with a\ndistinguished unbounded direction (e.g. the real line or a channel of the form\n$\\mathbb{R}\\times\\Omega$). Recent work has shown how to extend the spatial\ndynamics framework to elliptic PDEs posed on general multi-dimensional spatial\ndomains. In this paper, we show that, in the same context, exponential\ndichotomies exist, thus allowing for their use in future analyses of coherent\nstructures, such as spatial patterns in reaction-diffusion equations on more\ngeneral domains.", "AI": {"tldr": "The paper extends the spatial dynamics framework to prove that exponential dichotomies exist for elliptic PDEs on general multi-dimensional domains, enabling future analysis of coherent structures.", "motivation": "To leverage exponential dichotomies for studying bounded solutions in ill-posed evolutionary equations and extend spatial dynamics techniques to more general domains beyond simple unbounded directions.", "method": "Using spatial dynamics approach where spatial variables are treated as time-like evolutionary variables, applying classical dynamical systems techniques to elliptic PDEs on multi-dimensional domains.", "result": "Demonstrated that exponential dichotomies exist for elliptic PDEs posed on general multi-dimensional spatial domains, extending previous work limited to domains with distinguished unbounded directions.", "conclusion": "The existence of exponential dichotomies in this broader context enables future analysis of coherent structures like spatial patterns in reaction-diffusion equations on more general domains."}}
{"id": "2510.00949", "pdf": "https://arxiv.org/pdf/2510.00949", "abs": "https://arxiv.org/abs/2510.00949", "authors": ["Mengxia Dong"], "title": "A Unified H\u00f6lder Lebesgue Framework for Caffarelli Kohn Nirenberg Inequalities", "categories": ["math.AP", "math.FA"], "comment": null, "summary": "We develop a unified H\\\"older Lebesgue scale \\(X^p\\) and its weighted, higher\norder variants \\(X^{k,p,a}\\) to extend the Caffarelli Kohn Nirenberg (CKN)\ninequality beyond the classical Lebesgue regime. Within this framework we prove\na two parameter interpolation theorem that is continuous in the triplet\n\\((k,1/p,a)\\) and bridges integrability and regularity across the Lebesgue\nH\\\"older spectrum. As a consequence we obtain a generalized CKN inequality on\nbounded punctured domains \\(\\Omega\\subset\\mathbb{R}^n\\setminus\\{0\\}\\); the\ndependence of the constant on \\(\\Omega\\) is characterized precisely by the\n(non)integrability of the weights at the origin. At the critical endpoint\n\\(p=n\\) we establish a localized, weighted Brezis Wainger type bound via\nTrudinger Moser together with a localized weighted Hardy lemma, yielding an\nendpoint CKN inequality with a logarithmic loss. Sharp constants are not\npursued; rather, we prove existence of constants depending only on the\nstructural parameters and coarse geometry of \\(\\Omega\\). Several corollaries,\nincluding a unified Hardy--Sobolev inequality, follow from the same\ninterpolation mechanism.", "AI": {"tldr": "The paper develops a unified H\u00f6lder-Lebesgue scale framework to extend the Caffarelli-Kohn-Nirenberg inequality beyond classical Lebesgue spaces, proving interpolation theorems and establishing generalized CKN inequalities on bounded punctured domains with precise characterization of constants.", "motivation": "To extend the classical Caffarelli-Kohn-Nirenberg (CKN) inequality beyond the standard Lebesgue regime and develop a unified framework that bridges integrability and regularity across the Lebesgue-H\u00f6lder spectrum.", "method": "Developed a unified H\u00f6lder Lebesgue scale X^p and its weighted, higher order variants X^{k,p,a}. Proved a two-parameter interpolation theorem continuous in (k,1/p,a). Used Trudinger-Moser and localized weighted Hardy lemma for critical endpoint analysis.", "result": "Established generalized CKN inequality on bounded punctured domains with precise characterization of constants depending on weight integrability at origin. At critical endpoint p=n, obtained CKN inequality with logarithmic loss. Derived several corollaries including unified Hardy-Sobolev inequality.", "conclusion": "The framework successfully extends CKN inequality beyond classical Lebesgue spaces, providing interpolation mechanisms that bridge integrability and regularity. Constants depend only on structural parameters and coarse geometry of domains, with applications yielding unified inequalities."}}
{"id": "2510.01055", "pdf": "https://arxiv.org/pdf/2510.01055", "abs": "https://arxiv.org/abs/2510.01055", "authors": ["Florian Grube"], "title": "The inhomogeneous fractional Dirichlet problem", "categories": ["math.AP", "47G20, 35B65, 35S15, 35R09, 60G52"], "comment": "17 pages, 1 figure", "summary": "We study boundary regularity for the inhomogeneous Dirichlet problem for\n$2s$-stable operators in generalized H\\\"older spaces. Moreover, we provide\nexplicit counterexamples that showcase the sharpness of our results. Our\napproach directly addresses the inhomogeneous Dirichlet problem, rather than\nsubtracting an appropriate extension of the exterior data. Even for the\nfractional Laplacian, our result is new.", "AI": {"tldr": "The paper studies boundary regularity for inhomogeneous Dirichlet problems involving 2s-stable operators in generalized H\u00f6lder spaces, providing sharp results with explicit counterexamples.", "motivation": "To address boundary regularity for inhomogeneous Dirichlet problems directly, without subtracting extensions of exterior data, which is a new approach even for the fractional Laplacian.", "method": "The authors study 2s-stable operators in generalized H\u00f6lder spaces and develop a direct approach to the inhomogeneous Dirichlet problem, creating explicit counterexamples to demonstrate sharpness.", "result": "The paper establishes new boundary regularity results for inhomogeneous Dirichlet problems, with the findings being novel even for the fractional Laplacian case.", "conclusion": "The approach provides sharp boundary regularity results for 2s-stable operators in generalized H\u00f6lder spaces, with explicit counterexamples confirming optimality, offering a new perspective on the inhomogeneous Dirichlet problem."}}
{"id": "2510.01084", "pdf": "https://arxiv.org/pdf/2510.01084", "abs": "https://arxiv.org/abs/2510.01084", "authors": ["Shibing Chen", "Qi-Rui Li", "Yuanyuan Li"], "title": "The $L_p$ chord Minkowski problem for super-critical exponent", "categories": ["math.AP", "35A15", "F.2.2; G.1.8"], "comment": "22 pages", "summary": "The $L_p$ chord Minkowski problem was recently introduced by Lutwak, Xi, Yang\nand Zhang, which seeks to determine the necessary and sufficient conditions for\na given finite Borel measure such that it is the $L_p$ chord measure of a\nconvex body. In this paper, we solve the $L_p$ chord Minkowski problem for the\nsuper-critical exponents by combining a nonlocal Gauss curvature flow\nintroduced in \\cite{HHLW exi} and a topological argument developed in\n\\cite{GLW2022}. Notably, we provide a simplified argument for the topological\npart.", "AI": {"tldr": "The paper solves the $L_p$ chord Minkowski problem for super-critical exponents using a nonlocal Gauss curvature flow and topological methods.", "motivation": "To determine necessary and sufficient conditions for a finite Borel measure to be the $L_p$ chord measure of a convex body, as recently introduced by Lutwak, Xi, Yang and Zhang.", "method": "Combines a nonlocal Gauss curvature flow from previous work with a topological argument, providing a simplified approach for the topological part.", "result": "Successfully solves the $L_p$ chord Minkowski problem for super-critical exponents.", "conclusion": "The combination of nonlocal flow and topological methods provides an effective solution to this geometric problem, with simplified topological reasoning."}}
{"id": "2510.01101", "pdf": "https://arxiv.org/pdf/2510.01101", "abs": "https://arxiv.org/abs/2510.01101", "authors": ["Anna L. Mazzucato", "Dehua Wang", "Wei Wei"], "title": "On the vanishing viscosity limit for incompressible flows with inflow/outflow boundary conditions", "categories": ["math.AP", "35Q30, 35B25, 76N10, 76D10, 35B40"], "comment": "26 pages, submitted", "summary": "We study the vanishing viscosity limit for the incompressible Navier-Stokes\nequations (NSE) in a general bounded domain with inflow-outflow boundary\nconditions. Extending the work of Gie, Hamouda, and Temam ( Netw. Heterog.\nMedia 7, 2012) and also of Lombardo and Sammartino (SIAM J. Math. Anal. 33,\n2001), we allow for a general injection and suction angle, as long as it is\nbounded away from zero. We rigorously establish the convergence of NSE\nsolutions to those of the Euler equations (EE) as viscosity vanishes in the\nenergy norm. We prove interior convergence in both the $L^2$ and the Sobolev\n$H^1$ norms at the same rates as in the case of injection/suction normal to the\nboundary. The proof relies on the construction of boundary layer correctors via\nPrandtl-type equations and a higher-order asymptotic expansion that improves\nthe convergence rate.", "AI": {"tldr": "The paper studies the vanishing viscosity limit for incompressible Navier-Stokes equations in bounded domains with inflow-outflow boundary conditions, proving convergence to Euler equations in energy norm.", "motivation": "To extend previous work by allowing general injection and suction angles (bounded away from zero) and rigorously establish convergence from Navier-Stokes to Euler equations as viscosity vanishes.", "method": "Uses construction of boundary layer correctors via Prandtl-type equations and a higher-order asymptotic expansion to improve convergence rates.", "result": "Proves interior convergence in both L\u00b2 and Sobolev H\u00b9 norms at same rates as normal boundary case, establishing rigorous convergence of NSE solutions to Euler equations.", "conclusion": "The vanishing viscosity limit holds for general inflow-outflow boundary conditions with non-zero injection/suction angles, with boundary layer analysis providing the key convergence mechanism."}}
{"id": "2510.00362", "pdf": "https://arxiv.org/pdf/2510.00362", "abs": "https://arxiv.org/abs/2510.00362", "authors": ["Shao-Yuan Huang"], "title": "Bifurcation Curve Diagrams for a Diffusive Generalized Logistic Problem with Minkowski Curvature Operator and Constant-Yield Harvesting", "categories": ["math.CA", "math.AP"], "comment": null, "summary": "This paper investigates the bifurcation diagrams of positive solutions for a\none-dimensional diffusive generalized logistic boundary-value problem with the\nMinkowski curvature operator and constant yield harvesting. We prove that the\ncorresponding bifurcation curves on both the (lambda, sup-norm of u)-plane and\nthe (mu, sup-norm of u)-plane are C-shaped. Furthermore, by characterizing the\nbifurcation set on the (mu, lambda)-plane, we determine the exact multiplicity\nof positive solutions.", "AI": {"tldr": "Analysis of bifurcation diagrams for positive solutions in a 1D diffusive generalized logistic problem with Minkowski curvature operator and constant yield harvesting, showing C-shaped bifurcation curves and exact multiplicity of solutions.", "motivation": "To understand the structure of positive solutions in boundary-value problems involving Minkowski curvature operators and harvesting effects, which have applications in mathematical biology and physics.", "method": "Using bifurcation theory to analyze the diffusive generalized logistic boundary-value problem with Minkowski curvature operator and constant yield harvesting, characterizing bifurcation curves and sets.", "result": "Proved that bifurcation curves on (lambda, sup-norm of u)-plane and (mu, sup-norm of u)-plane are C-shaped, and determined exact multiplicity of positive solutions by characterizing the bifurcation set on (mu, lambda)-plane.", "conclusion": "The study provides complete characterization of solution multiplicity and bifurcation structure for this class of problems, revealing C-shaped bifurcation patterns and exact solution counts."}}
{"id": "2510.00420", "pdf": "https://arxiv.org/pdf/2510.00420", "abs": "https://arxiv.org/abs/2510.00420", "authors": ["Zetian Yan", "Xingyu Zhu"], "title": "Uniqueness of the asymptotic limits for Ricci-flat manifolds with linear volume growth", "categories": ["math.DG", "math.AP", "math.MG", "53C21, 53C25"], "comment": "42 pages", "summary": "Under natural assumptions on curvature and cross section, we establish the\nuniqueness of asymptotic limits and the exponential convergence rate for\ncomplete noncollapsed Ricci-flat manifolds with linear volume growth, which are\nknown to only admit cylindrical asymptotic limits. In dimension four, these\nassumptions hold automatically, yielding unconditional uniqueness and\nconvergence. In particular, our results show that all asymptotically\ncylindrical Calabi--Yau manifolds converge exponentially to their asymptotic\nlimits, thereby answering affirmatively a question by\nHaskins--Hein--Nordstr\\\"om. In dimension four our result strengthens those of\nChen--Chen, who proved exponential convergence to its asymptotic limit space\nfor any ALH instanton.", "AI": {"tldr": "The paper establishes uniqueness of asymptotic limits and exponential convergence for complete noncollapsed Ricci-flat manifolds with linear volume growth, which only admit cylindrical asymptotic limits. In dimension 4, these results are unconditional.", "motivation": "To prove uniqueness and exponential convergence for asymptotically cylindrical Calabi-Yau manifolds, answering a question by Haskins-Hein-Nordstr\u00f6m, and strengthening previous results in dimension 4.", "method": "Using natural assumptions on curvature and cross section to establish uniqueness of asymptotic limits and exponential convergence rate for complete noncollapsed Ricci-flat manifolds with linear volume growth.", "result": "Proved uniqueness of asymptotic limits and exponential convergence rate for such manifolds. In dimension 4, these results hold automatically without additional assumptions.", "conclusion": "All asymptotically cylindrical Calabi-Yau manifolds converge exponentially to their asymptotic limits, confirming Haskins-Hein-Nordstr\u00f6m's question and strengthening Chen-Chen's results in dimension 4."}}
{"id": "2510.00445", "pdf": "https://arxiv.org/pdf/2510.00445", "abs": "https://arxiv.org/abs/2510.00445", "authors": ["Song-Ung Ri", "Hyon-Hui Ju", "Jin-Myong Kim"], "title": "Frequent, disjoint hypercyclicity and strong topological transitivity of generalized weighted shift operators on Hilbert C-modules", "categories": ["math.FA", "math.AP", "47A16, 37B20, 47B37"], "comment": null, "summary": "In this paper we study some dynamical properties such as Frequent\nHypercyclicity Criterion, chaos, disjoint hypercyclicity and F-transitivity via\nFurstenberg family F for generalized bilateral weighted shift operator on the\nstandard Hilbert C-module over C-algebra of compact operators on a separable\nHilbert space.", "AI": {"tldr": "Study of dynamical properties for generalized bilateral weighted shift operators on Hilbert C*-modules over compact operators", "motivation": "To investigate various dynamical properties including hypercyclicity, chaos, and transitivity for shift operators in the context of Hilbert C*-modules", "method": "Analysis via Furstenberg family F for generalized bilateral weighted shift operators on standard Hilbert C*-module over C*-algebra of compact operators", "result": "Not specified in abstract", "conclusion": "Not specified in abstract"}}
{"id": "2510.00677", "pdf": "https://arxiv.org/pdf/2510.00677", "abs": "https://arxiv.org/abs/2510.00677", "authors": ["Jan Friedrich", "Michael Herty", "Claudia Nocita"], "title": "Control of Conservation Laws in the Nonlocal-to-Local Limit", "categories": ["math.OC", "math.AP", "35L65, 49J20, 65M08"], "comment": null, "summary": "We analyze a class of control problems where the initial datum acts as a\ncontrol and the state is given by the entropy solution of (local) conservation\nlaws by a nonlocal-to-local limiting strategy. In particular we characterize\nthe limit up to subsequence of minimizers to nonlocal control problems as\nminimizer of the corresponding local ones. Moreover, we also prove an analogous\nresult at a discrete level by means of a Eulerian-Lagrangian scheme.", "AI": {"tldr": "Analysis of control problems where initial data serves as control and state is given by entropy solutions of conservation laws via nonlocal-to-local limiting approach.", "motivation": "To study control problems involving conservation laws where initial conditions act as controls, and to understand the relationship between nonlocal and local control formulations.", "method": "Nonlocal-to-local limiting strategy and Eulerian-Lagrangian scheme for discrete analysis.", "result": "Characterization of limit minimizers from nonlocal to local control problems, with analogous discrete results.", "conclusion": "Minimizers of nonlocal control problems converge to minimizers of corresponding local ones, with consistent behavior at discrete level."}}
{"id": "2510.00811", "pdf": "https://arxiv.org/pdf/2510.00811", "abs": "https://arxiv.org/abs/2510.00811", "authors": ["Matthias Hofmann", "James B. Kennedy", "Hugo Tavares"], "title": "Spectral minimal partitions of unbounded domains", "categories": ["math.SP", "math.AP", "35J10, 35B65, 35J20, 49Q10, 81Q10"], "comment": null, "summary": "We study the problem of constructing $k$-spectral minimal partitions of\ndomains in $d$ dimensions, where the energy functional to be minimized is a\n$p$-norm ($1 \\le p \\le \\infty$) of the infimum of the spectrum of a suitable\nSchr\\\"odinger operator $-\\Delta +V$, with Dirichlet conditions on the boundary\nof the partition elements (cells). The main novelty of this paper is that the\ndomains may be unbounded, including of infinite volume.\n  First, we prove a sharp upper bound for the infimal energy among all\n$k$-partitions by a threshold value which involves the infimum $\\Sigma$ of the\nessential spectrum of the Schr\\\"odinger operator on the whole domain as well as\nthe infimal energy among all $k-1$-partitions. Strictly below such threshold,\nwe develop a concentration-compactness-type argument showing optimal partitions\nexist, and each cell admits ground states (i.e., the infimum of the spectrum on\neach cell is a simple isolated eigenvalue).\n  Second, for $p<\\infty$, when the energy and the threshold level coincide, we\nshow there may or may not be minimizing partitions. Moreover, even when these\nexist, they may not have ground states.\n  Third, for $p=\\infty$, minimal partitions always exist, even at the threshold\nlevel, but these may or may not admit ground states. Moreover, below the\nthreshold, we can always construct a minimizer, which is an equipartition. At\nthe threshold value we show that spectral minimal partitions may not need to be\nequipartitions.\n  We give a variety of examples of both domains and potentials to illustrate\nthe new phenomena that occur in this setting.", "AI": {"tldr": "This paper studies k-spectral minimal partitions for domains (including unbounded ones) using p-norms of Schr\u00f6dinger operator eigenvalues, proving existence results and threshold behaviors.", "motivation": "To extend spectral partition theory to unbounded domains and infinite volume cases, addressing new phenomena that arise when domains are not compact.", "method": "Uses concentration-compactness arguments to prove existence of optimal partitions below a threshold energy level, and analyzes different behaviors for p<\u221e and p=\u221e cases.", "result": "Proves sharp upper bounds for k-partition energies, shows existence of minimizing partitions below threshold, and demonstrates varied behaviors at threshold level depending on p-norm.", "conclusion": "Spectral minimal partitions exhibit complex behaviors in unbounded domains, with different threshold phenomena for finite vs infinite p-norms, and equipartition properties depend on energy level."}}
{"id": "2510.01027", "pdf": "https://arxiv.org/pdf/2510.01027", "abs": "https://arxiv.org/abs/2510.01027", "authors": ["Thavamani Govindaraj", "Anthony Hastir", "Lassi Paunonen", "Timo Reis"], "title": "Funnel control for passive infinite-dimensional systems", "categories": ["math.OC", "math.AP", "math.FA"], "comment": null, "summary": "We consider funnel control for linear infinite-dimensional systems that are\nimpedance passive, meaning that they satisfy an energy balance in which the\nstored energy equals the squared norm of the state and the supplied power is\nthe inner product of input and output. For the analysis we employ the system\nnode approach, which offers a unified framework for infinite-dimensional\nsystems with boundary and distributed control and observation. The resulting\nclosed-loop dynamics are governed by a nonlinear evolution equation; we\nestablish its solvability and hence the applicability of funnel control to this\nclass. The applicability is illustrated by an Euler-Bernoulli beam, which is\nstudied in two distinct scenarios: once with boundary control and once with\ndistributed control.", "AI": {"tldr": "Funnel control for linear infinite-dimensional impedance passive systems using system node approach, with applications to Euler-Bernoulli beam in boundary and distributed control scenarios.", "motivation": "To extend funnel control methodology to linear infinite-dimensional systems that are impedance passive, which satisfy energy balance conditions with stored energy as squared state norm and supplied power as input-output inner product.", "method": "Employ the system node approach as a unified framework for infinite-dimensional systems with boundary and distributed control and observation. Analyze closed-loop dynamics governed by nonlinear evolution equations and establish solvability.", "result": "Successfully established solvability of the nonlinear evolution equation governing closed-loop dynamics, demonstrating applicability of funnel control to impedance passive infinite-dimensional systems.", "conclusion": "Funnel control is applicable to linear infinite-dimensional impedance passive systems, as validated through analysis of Euler-Bernoulli beam examples with both boundary and distributed control configurations."}}
{"id": "2510.01166", "pdf": "https://arxiv.org/pdf/2510.01166", "abs": "https://arxiv.org/abs/2510.01166", "authors": ["Sagar Gautam", "Manil T. Mohan"], "title": "A viscosity solution approach to the large deviation principle for stochastic convective Brinkman-Forchheimer equations", "categories": ["math.PR", "math.AP"], "comment": null, "summary": "This article develops the viscosity solution approach to the large deviation\nprinciple for the following two- and three-dimensional stochastic convective\nBrinkman-Forchheimer equations on the torus $\\mathbb{T}^d,\\ d\\in\\{2,3\\}$ with\nsmall noise intensity:\n  \\begin{align*}\n  \\mathrm{d}\\boldsymbol{u}_n+[-\\mu\\Delta\\boldsymbol{u}_n+\n(\\boldsymbol{u}_n\\cdot\\nabla)\\boldsymbol{u}_n\n+\\alpha\\boldsymbol{u}_n+\\beta|\\boldsymbol{u}_n|^{r-1}\\boldsymbol{u}_n+\\nabla\np_n]\\mathrm{d} t=\\boldsymbol{f}\\mathrm{d}\nt+\\frac{1}{\\sqrt{n}}\\mathrm{Q}^{\\frac12}\\mathrm{d}\\mathrm{W}, \\\n\\nabla\\cdot\\boldsymbol{u}_n=0,\n  \\end{align*} where $\\mu,\\alpha,\\beta>0$, $r\\in[1,\\infty)$, $\\mathrm{Q}$ is a\ntrace class operator and $\\mathrm{W}$ is Hilbert-valued calendrical Wiener\nprocess. We build our analysis on the framework of Varadhan and Bryc, together\nwith the techniques of [J. Feng et.al., Large Deviations for Stochastic\nProcesses, American Mathematical Society (2006) vol. \\textbf{131}]. By\nemploying the techniques from the comparison principle, we identify the Laplace\nlimit as the convergence of the viscosity solution of the associated\nsecond-order singularly perturbed Hamilton-Jacobi-Bellman equation. A key\nadvantage of this method is that it establishes a Laplace principle without\nrelying on additional sufficient conditions such as Bryc's theorem, which the\nliterature commonly requires. For $r>3$ and $r=3$ with $2\\beta\\mu\\geq1$, we\nalso derive the exponential moment bounds without imposing the classical\northogonality condition\n$((\\boldsymbol{u}_n\\cdot\\nabla)\\boldsymbol{u}_n,\\mathrm{A}\\boldsymbol{u}_n)=0$,\nwhere $\\mathrm{A}=-\\Delta$, in both two-and three-dimensions. We first\nestablish the large deviation principle in the Skorohod space. Then, by using\nthe $\\mathrm{C}-$exponential tightness, we finally establish the large\ndeviation principle in the continuous space.", "AI": {"tldr": "Develops viscosity solution approach for large deviation principle of 2D/3D stochastic convective Brinkman-Forchheimer equations with small noise, establishing Laplace principle without Bryc's theorem and deriving exponential moment bounds.", "motivation": "To establish large deviation principles for stochastic convective Brinkman-Forchheimer equations using viscosity solution methods, avoiding reliance on additional sufficient conditions like Bryc's theorem.", "method": "Uses Varadhan and Bryc framework with Feng's techniques, employs comparison principle to identify Laplace limit as convergence of viscosity solution of associated Hamilton-Jacobi-Bellman equation.", "result": "Establishes large deviation principle in Skorohod space and continuous space via C-exponential tightness; derives exponential moment bounds for r>3 and r=3 with 2\u03b2\u03bc\u22651 without orthogonality condition.", "conclusion": "Viscosity solution approach successfully establishes large deviation principle for stochastic convective Brinkman-Forchheimer equations, providing advantages over traditional methods that require additional sufficient conditions."}}
