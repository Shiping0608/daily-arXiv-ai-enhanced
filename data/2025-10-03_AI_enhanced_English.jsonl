{"id": "2510.01442", "pdf": "https://arxiv.org/pdf/2510.01442", "abs": "https://arxiv.org/abs/2510.01442", "authors": ["Paola F. Antonietti", "Matteo Caldana", "Lorenzo Gentile", "Marco Verani"], "title": "Deep Learning Accelerated Algebraic Multigrid Methods for Polytopal Discretizations of Second-Order Differential Problems", "categories": ["math.NA", "cs.NA", "65N22, 65N30, 65N55, 68T01"], "comment": null, "summary": "Algebraic Multigrid (AMG) methods are state-of-the-art algebraic solvers for\npartial differential equations. Still, their efficiency depends heavily on the\nchoice of suitable parameters and/or ingredients. Paradigmatic examples include\nthe so-called strong threshold parameter $\\theta$, which controls the algebraic\ncoarse-grid hierarchy, as well as the smoother, i.e., the relaxation methods\nused on the fine grid to damp out high-frequency errors. In AMG, since the\ncoarse grids are constructed algebraically (without geometric intuition), the\nsmoother's performance is even more critical. For the linear systems stemming\nfrom polytopal discretizations, such as Polytopal Discontinuous Galerkin\n(PolyDG) and Virtual Element Methods (VEM), AMG sensitivity to such choices is\neven more critical due to the significant variability of the underlying meshes,\nwhich results in algebraic systems with different sparsity patterns. We propose\na novel deep learning approach that automatically tunes the strong threshold\nparameter, as well as the smoother choice in AMG solvers, for linear systems of\nequations arising from polytopal discretizations, thereby maximizing AMG\nperformance. We interpret the sparse matrix resulting from polytopal\ndiscretization as a grayscale image, and by applying pooling, our neural\nnetwork extracts compact features that preserve the necessary information at a\nlow computational cost. We test various differential problems in both two- and\nthree-dimensional settings, with heterogeneous coefficients and\npolygonal/polyhedral meshes, and demonstrate that the proposed approach\ngeneralizes well. In practice, we demonstrate that we can reduce AMG solver\ntime by up to $27\\%$ with minimal changes to existing PolyDG and VEM codes.", "AI": {"tldr": "A deep learning approach to automatically tune AMG parameters (strong threshold and smoother choice) for polytopal discretizations, treating sparse matrices as images and using pooling to extract features, achieving up to 27% solver time reduction.", "motivation": "AMG methods are sensitive to parameter choices, especially for polytopal discretizations (PolyDG/VEM) where mesh variability creates diverse sparsity patterns, making manual parameter tuning difficult and critical for performance.", "method": "Interpret sparse matrices from polytopal discretizations as grayscale images, apply pooling to extract compact features, and use neural networks to automatically select optimal AMG parameters (strong threshold and smoother choice).", "result": "The approach reduces AMG solver time by up to 27% across various 2D/3D differential problems with heterogeneous coefficients and polygonal/polyhedral meshes, demonstrating good generalization.", "conclusion": "Deep learning can effectively automate AMG parameter tuning for polytopal discretizations, significantly improving solver performance with minimal code modifications to existing PolyDG and VEM implementations."}}
{"id": "2510.01567", "pdf": "https://arxiv.org/pdf/2510.01567", "abs": "https://arxiv.org/abs/2510.01567", "authors": ["Kathrin Hellmuth", "Ruhui Jin", "Qin Li", "Stephen J. Wright"], "title": "Data selection: at the interface of PDE-based inverse problem and randomized linear algebra", "categories": ["math.NA", "cs.NA", "math.OC", "35R30, 65C60, 62Kxx, 65J22, 65Fxx, 60B20, 65M32, 90C31"], "comment": null, "summary": "All inverse problems rely on data to recover unknown parameters, yet not all\ndata are equally informative. This raises the central question of data\nselection. A distinctive challenge in PDE-based inverse problems is their\ninherently infinite-dimensional nature: both the parameter space and the design\nspace are infinite, which greatly complicates the selection process. Somewhat\nunexpectedly, randomized numerical linear algebra (RNLA), originally developed\nin very different contexts, has provided powerful tools for addressing this\nchallenge. These methods are inherently probabilistic, with guarantees\ntypically stating that information is preserved with probability at least 1-p\nwhen using N randomly selected, weighted samples. Here, the notion of\ninformation can take different mathematical forms depending on the setting. In\nthis review, we survey the problem of data selection in PDE-based inverse\nproblems, emphasize its unique infinite-dimensional aspects, and highlight how\nRNLA strategies have been adapted and applied in this context.", "AI": {"tldr": "This review explores data selection in PDE-based inverse problems, focusing on infinite-dimensional challenges and the application of randomized numerical linear algebra methods for efficient data sampling with probabilistic guarantees.", "motivation": "Inverse problems rely on data to recover unknown parameters, but not all data are equally informative. The central challenge is selecting the most informative data, particularly difficult in PDE-based inverse problems due to their inherently infinite-dimensional nature in both parameter and design spaces.", "method": "The paper surveys the adaptation and application of randomized numerical linear algebra (RNLA) strategies to address data selection in PDE-based inverse problems. These probabilistic methods use randomly selected, weighted samples to preserve information with mathematical guarantees.", "result": "RNLA methods provide powerful tools for data selection in infinite-dimensional settings, offering guarantees that information is preserved with probability at least 1-p when using N randomly selected samples, with different mathematical formulations of information depending on the specific problem context.", "conclusion": "Randomized numerical linear algebra, originally developed for different contexts, has proven to be an effective approach for addressing the unique challenges of data selection in PDE-based inverse problems, particularly their infinite-dimensional nature."}}
{"id": "2510.01696", "pdf": "https://arxiv.org/pdf/2510.01696", "abs": "https://arxiv.org/abs/2510.01696", "authors": ["Behnam Hashemi", "Yuji Nakatsukasa"], "title": "Instability of the Sherman-Morrison formula and stabilization by iterative refinement", "categories": ["math.NA", "cs.NA", "65Gxx"], "comment": null, "summary": "Owing to its simplicity and efficiency, the Sherman-Morrison (SM) formula has\nseen widespread use across various scientific and engineering applications for\nsolving rank-one perturbed linear systems of the form $(A+uv^T)x = b$. Although\nthe formula dates back at least to 1944, its numerical stability properties\nhave remained an open question and continue to be a topic of current research.\nWe analyze the backward stability of the SM, demonstrate its instability in a\nscenario increasingly common in scientific computing and address an open\nquestion posed by Nick Higham on the proportionality of the backward error\nbound to the condition number of $A$. We then incorporate fixed-precision\niterative refinement into the SM framework reusing the previously computed\ndecompositions and prove that, under reasonable assumptions, it achieves\nbackward stability without sacrificing the efficiency of the SM formula. While\nour theory does not prove the SM formula with iterative refinement always\noutputs a backward stable solution, empirically it is observed to eventually\nproduce a backward stable solution in all our numerical experiments. We\nconjecture that with iterative refinement, the SM formula yields a backward\nstable solution provided that $\\kappa_2(A), \\kappa_2(A+uv^T)$ are both bounded\nsafely away from $\\epsilon_M^{-1}$, where $\\epsilon_M$ is the unit roundoff.", "AI": {"tldr": "The Sherman-Morrison formula's numerical stability has been an open question. This paper analyzes its backward stability, demonstrates instability in common scenarios, and incorporates iterative refinement to achieve backward stability while maintaining efficiency.", "motivation": "The Sherman-Morrison formula is widely used for solving rank-one perturbed linear systems due to its simplicity and efficiency, but its numerical stability properties have remained an open research question for decades.", "method": "Analyzed backward stability of SM formula, addressed Higham's open question, and incorporated fixed-precision iterative refinement into SM framework while reusing previously computed decompositions.", "result": "Demonstrated SM formula's instability in common scenarios, proved that with iterative refinement it achieves backward stability under reasonable assumptions, and empirically observed backward stable solutions in all experiments.", "conclusion": "With iterative refinement, the SM formula yields backward stable solutions when the condition numbers of both A and A+uv^T are safely bounded away from the inverse of unit roundoff."}}
{"id": "2510.01790", "pdf": "https://arxiv.org/pdf/2510.01790", "abs": "https://arxiv.org/abs/2510.01790", "authors": ["Muhammad Ammad", "Leevan Ling"], "title": "Efficient manifold evolution algorithm using adaptive B-Spline interpolation", "categories": ["math.NA", "cs.NA", "math.AP", "math.DG"], "comment": null, "summary": "This paper explores an efficient Lagrangian approach for evolving point cloud\ndata on smooth manifolds. In this preliminary study, we focus on analyzing\nplane curves, and our ultimate goal is to provide an alternative to the\nconventional radial basis function (RBF) approach for manifolds in higher\ndimensions. In particular, we use the B-Spline as the basis function for all\nlocal interpolations. Just like RBF and other smooth basis functions, B-Splines\nenable the approximation of geometric features such as normal vectors and\ncurvature. Once properly set up, the advantage of using B-Splines is that their\ncoefficients carry geometric meanings. This allows the coefficients to be\nmanipulated like points, facilitates rapid updates of the interpolant, and\neliminates the need for frequent re-interpolation. Consequently, the removal\nand insertion of point cloud data become seamless processes, particularly\nadvantageous in regions experiencing significant fluctuations in point density.\nThe numerical results demonstrate the convergence of geometric quantities and\nthe effectiveness of our approach. Finally, we show simulations of curvature\nflows whose speeds depend on the solutions of coupled reaction--diffusion\nsystems for pattern formation.", "AI": {"tldr": "Efficient Lagrangian approach using B-Splines for evolving point clouds on manifolds, providing geometric coefficient manipulation and seamless point updates as an alternative to RBF methods.", "motivation": "To develop an alternative to conventional radial basis function (RBF) approaches for evolving point cloud data on smooth manifolds, particularly for higher-dimensional applications.", "method": "Uses B-Spline basis functions for local interpolations, enabling geometric feature approximation and coefficient manipulation that facilitates rapid updates without frequent re-interpolation.", "result": "Numerical results show convergence of geometric quantities and effective handling of regions with significant point density fluctuations, with successful simulations of curvature flows coupled with reaction-diffusion systems.", "conclusion": "The B-Spline approach provides an efficient alternative to RBF methods with geometric coefficient manipulation, seamless point updates, and successful application to complex pattern formation problems."}}
{"id": "2510.01401", "pdf": "https://arxiv.org/pdf/2510.01401", "abs": "https://arxiv.org/abs/2510.01401", "authors": ["Chunyi Gai", "Fahad Al Saadi"], "title": "Localized Pattern Formation and Oscillatory Instabilities in a Three-component Gierer Meinhardt Model", "categories": ["math.AP", "math.DS"], "comment": null, "summary": "In this paper, we introduce a three-component Gierer-Meinhardt model in the\nsemi-strong interaction regime, characterized by an asymptotically large\ndiffusivity ratio. A key feature of this model is that the interior spike can\nundergo Hopf bifurcations in both amplitude and position, leading to rich\noscillatory dynamics not present in classical two-component systems. Using\nasymptotic analysis and numerical path-following, we construct localized spike\nequilibria and analyze spike nucleation that occurs through slow passage beyond\na saddle-node bifurcation. Moreover, stability of spike equilibrium is analyzed\nby introducing time-scaling parameters, which reveal two distinct mechanisms:\namplitude oscillations triggered by large-eigenvalue instabilities and\noscillatory spike motion associated with small eigenvalues. Numerical\nsimulations illustrate these dynamics and their transition regimes. This dual\nmechanism highlights richer spike behavior in three-component systems and\nsuggests several open problems for future study.", "AI": {"tldr": "A three-component Gierer-Meinhardt model with large diffusivity ratio exhibits Hopf bifurcations in both amplitude and position of interior spikes, revealing richer oscillatory dynamics than classical two-component systems.", "motivation": "To explore richer spike behavior and oscillatory dynamics in three-component reaction-diffusion systems beyond classical two-component models, particularly focusing on dual Hopf bifurcations.", "method": "Asymptotic analysis and numerical path-following to construct localized spike equilibria, analyze spike nucleation through saddle-node bifurcations, and study stability using time-scaling parameters.", "result": "Identified two distinct instability mechanisms: amplitude oscillations from large-eigenvalue instabilities and oscillatory spike motion from small eigenvalues, with numerical simulations confirming these dynamics and transition regimes.", "conclusion": "Three-component systems exhibit richer spike behavior through dual instability mechanisms, suggesting several open problems for future study in reaction-diffusion pattern formation."}}
{"id": "2510.01205", "pdf": "https://arxiv.org/pdf/2510.01205", "abs": "https://arxiv.org/abs/2510.01205", "authors": ["Nicholas Bauman", "Ajay Panyala", "Libor Veis", "Jiri Brabec", "Paul Rigor", "Randy Meyer", "Skyler Windh", "Craig Warner", "Tony Brewer", "Karol Kowalski"], "title": "Integrated Software/Hardware Execution Models for High-Accuracy Methods in Chemistry", "categories": ["physics.comp-ph", "physics.chem-ph", "quant-ph"], "comment": null, "summary": "The effective deployment and application of advanced methodologies for\nquantum chemistry is inherently linked to the optimal usage of emerging and\nhighly diversified computational resources. This paper examines the synergistic\nutilization of Micron memory technologies and Azure Quantum Element cloud\ncomputing in Density Matrix Renormalization Group (DMRG) simulations leveraging\ncoupled-cluster (CC) downfolded/effective Hamiltonians based on the double\nunitary coupled cluster (DUCC) Ansatz. We analyze the performance of the\nDMRG-DUCC workflow, emphasizing the proper choice of hardware that reflects the\nnumerical overheads associated with specific components of the workflow. We\nreport a hybrid approach that takes advantage of Micron CXL hardware for the\nmemory capacity intensive CC downfolding phase while employing AQE cloud\ncomputing for the less resource-intensive DMRG simulations. Furthermore, we\nanalyze the performance of the scalable ExaChem suite of electronic simulations\nconducted on Micron prototype systems.", "AI": {"tldr": "The paper presents a hybrid approach combining Micron CXL memory technology and Azure Quantum Element cloud computing for efficient DMRG-DUCC quantum chemistry simulations, optimizing resource usage based on workflow component requirements.", "motivation": "To address the challenge of optimally utilizing diverse computational resources for quantum chemistry simulations, particularly for memory-intensive coupled-cluster calculations and DMRG simulations.", "method": "Developed a hybrid workflow using Micron CXL hardware for memory-intensive CC downfolding phase and Azure Quantum Element cloud computing for less resource-intensive DMRG simulations, leveraging the DMRG-DUCC approach with double unitary coupled cluster Ansatz.", "result": "The approach enables efficient resource allocation by matching hardware capabilities to specific workflow components, with performance analysis conducted using the scalable ExaChem suite on Micron prototype systems.", "conclusion": "The synergistic combination of specialized hardware technologies provides an effective strategy for optimizing quantum chemistry simulations by properly addressing the distinct computational requirements of different workflow components."}}
{"id": "2510.01289", "pdf": "https://arxiv.org/pdf/2510.01289", "abs": "https://arxiv.org/abs/2510.01289", "authors": ["Osama A. Marzouk"], "title": "Detailed Derivation of the Scalar Explicit Expressions Governing the Electric Field, Current Density, and Volumetric Power Density in the Four Types of Linear Divergent MHD Channels Under a Unidirectional Applied Magnetic Field", "categories": ["physics.plasm-ph", "00A79, 03H10"], "comment": "41 pages, 8 figures, 4 tables, published journal article,\n  peer-reviewed, open access", "summary": "The current study belongs to the field of applied mathematics in plasma\nphysics and electric power, where mathematical analysis of the algebraic\nequations governing the electric field vector, and the electric-current density\nfield vector within a Magnetohydrodynamic (MHD) linear two-dimensional\ndivergent supersonic channel is utilized to derive analytical expressions for\nthese important fields, as well as closed-form equations for the volumetric\npower density (output electric power per unit volume of the plasma channel).\nThe expressions presented here describe analytically the operation of the MHD\nchannel as an electric power source within an Open-Cycle Magnetohydrodynamic\n(OCMHD) generator. The four common types of the MHD linear channels are covered\nhere: namely, (1) continuous-electrode Faraday channel, (2) linear Hall\nchannel, (3) segmented-electrode Faraday channel, and (4) diagonal-electrode\nchannel. The mathematical results, their detailed derivation, and the companion\ngraphical illustrations aid in making a proper decision regarding which channel\ntype is the most suitable for a given application.Under typical operational\nconditions of 5 S/m plasma electric conductivity, 5 T magnetic field, and 2,000\nm/s plasma speed, as well as an optimized load factor of 0.5, we estimate the\nfollowing numerical values (unsigned magnitudes) for the continuous-electrode\nFaraday channel (with a Hall parameter of 1): useful electric field (across the\nexternal electric load): 5 kV/m, useful electric current-density (between the\nterminal electrodes within the channel): 12.5 kA/m2 , volumetric power density\n(dissipated by the load per unit volume of plasma): 62.5 MW/m3 , and electric\nefficiency (for the electric field or voltage): 50%. For the Halllinear channel\n(with a Hall parameter of 5), these quantitative performance values become25\nkV/m, 4.808 kA/m2, 120.19 MW/m3, and 46.30%.", "AI": {"tldr": "Analytical derivation of electric field, current density, and power density for four MHD channel types in Open-Cycle Magnetohydrodynamic generators, with performance comparisons under typical operational conditions.", "motivation": "To provide analytical expressions for electric field, current density, and power density in MHD channels to aid in selecting the most suitable channel type for specific applications in plasma physics and electric power generation.", "method": "Mathematical analysis of algebraic equations governing electric field and current density vectors in MHD linear two-dimensional divergent supersonic channels, deriving analytical expressions for four common channel types.", "result": "Under typical conditions (5 S/m conductivity, 5 T magnetic field, 2000 m/s plasma speed, 0.5 load factor): Continuous-electrode Faraday channel achieves 5 kV/m electric field, 12.5 kA/m\u00b2 current density, 62.5 MW/m\u00b3 power density, 50% efficiency; Hall-linear channel achieves 25 kV/m, 4.808 kA/m\u00b2, 120.19 MW/m\u00b3, 46.30% efficiency.", "conclusion": "The analytical expressions and performance comparisons help determine the optimal MHD channel type for specific applications, with Hall-linear channels showing higher power density but slightly lower efficiency compared to continuous-electrode Faraday channels."}}
{"id": "2510.01828", "pdf": "https://arxiv.org/pdf/2510.01828", "abs": "https://arxiv.org/abs/2510.01828", "authors": ["C Mahmoud", "H Mathis"], "title": "Asymptotic preserving schemes for hyperbolic systems with relaxation", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper presents the construction of two numerical schemes for the\nsolution of hyperbolic systems with relaxation source terms. The methods are\nbuilt by considering the relaxation system as a whole, without separating the\nresolution of the convective part from that of the source term. The first\nscheme combines the centered FORCE approach of Toro and co-authors with the\nunsplit strategy proposed by B{\\'e}reux and Sainsaulieu. The second scheme\nconsists of an approximate Riemann solver which carefully handles the source\nterm approximation. The two schemes are built to be asymptotic preserving, in\nthe sense that their limit schemes are consistent with the equilibrium model as\nthe relaxation parameter tends to zero, without any CFL restriction. For\nspecific models, it is possible to prove that they preserve invariant domains\nand admit a discrete entropy inequality.", "AI": {"tldr": "Construction of two asymptotic preserving numerical schemes for hyperbolic systems with relaxation source terms that handle convection and source terms together without separation.", "motivation": "To develop numerical methods that can handle hyperbolic systems with relaxation source terms as a unified system rather than separating convective and source term resolution, while maintaining asymptotic preservation properties.", "method": "First scheme combines centered FORCE approach with unsplit strategy; second scheme uses an approximate Riemann solver that carefully handles source term approximation. Both schemes are designed to be asymptotic preserving without CFL restrictions.", "result": "Two numerical schemes were successfully constructed that are asymptotic preserving - their limit schemes remain consistent with the equilibrium model as relaxation parameter approaches zero, without CFL restrictions. For specific models, they preserve invariant domains and admit discrete entropy inequalities.", "conclusion": "The proposed schemes provide effective numerical methods for hyperbolic relaxation systems that maintain important mathematical properties while handling convection and source terms in a unified manner."}}
{"id": "2510.01415", "pdf": "https://arxiv.org/pdf/2510.01415", "abs": "https://arxiv.org/abs/2510.01415", "authors": ["Dilara Siraeva", "Irina A. Kogan"], "title": "Symmetry analysis and new partially invariant solutions for the gas dynamics system with a special equation of state", "categories": ["math.AP", "35B06, 35A30"], "comment": null, "summary": "This paper is a contribution to the symmetry analysis of the gas dynamics\nsystem in the vein of the ''podmodeli'' (submodels) program outlined by\nOvsyannikov (1994). We consider the case of the special state equation,\nprescribing pressure to be the sum of entropy and an arbitrary function of\ndensity. Such a system has a 12-dimensional symmetry Lie algebra. This work\nadvances the study of its four-dimensional subalgebras, continuing the work\nstarted in Siraeva (2024). For a large subset of not previously considered,\nnon-similar four-dimensional subalgebras from an optimal list in Siraeva\n(2014), we compute a complete set of generating invariants. For one of the\nsubalgebras, we construct a partially symmetry-reduced system. We explicitly\nsolve this reduced system (submodel). This leads to new families of explicit\nsolutions of the original system. We analyze the trajectories of these\nsolutions. Additionally, we match each of the subalgebras considered in this\npaper with its isomorphism class, planting a seed for future study of the\nhierarchy of the reduced systems.", "AI": {"tldr": "Symmetry analysis of gas dynamics with special state equation, computing invariants for 4D subalgebras and constructing explicit solutions.", "motivation": "Advance the symmetry analysis of gas dynamics systems following Ovsyannikov's submodels program, continuing previous work on 4D subalgebras.", "method": "Compute complete sets of generating invariants for non-similar 4D subalgebras, construct partially symmetry-reduced systems, and explicitly solve them.", "result": "Obtained new families of explicit solutions for the original gas dynamics system and analyzed their trajectories.", "conclusion": "Successfully extended symmetry analysis, matched subalgebras with isomorphism classes, and laid groundwork for future study of reduced systems hierarchy."}}
{"id": "2510.01370", "pdf": "https://arxiv.org/pdf/2510.01370", "abs": "https://arxiv.org/abs/2510.01370", "authors": ["Abu Bucker Siddik", "Diane Oyen", "Alexander Most", "Michal Kucer", "Ayan Biswas"], "title": "SPUS: A Lightweight and Parameter-Efficient Foundation Model for PDEs", "categories": ["cs.CV", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "We introduce Small PDE U-Net Solver (SPUS), a compact and efficient\nfoundation model (FM) designed as a unified neural operator for solving a wide\nrange of partial differential equations (PDEs). Unlike existing\nstate-of-the-art PDE FMs-primarily based on large complex transformer\narchitectures with high computational and parameter overhead-SPUS leverages a\nlightweight residual U-Net-based architecture that has been largely\nunderexplored as a foundation model architecture in this domain. To enable\neffective learning in this minimalist framework, we utilize a simple yet\npowerful auto-regressive pretraining strategy which closely replicates the\nbehavior of numerical solvers to learn the underlying physics. SPUS is\npretrained on a diverse set of fluid dynamics PDEs and evaluated across 6\nchallenging unseen downstream PDEs spanning various physical systems.\nExperimental results demonstrate that SPUS using residual U-Net based\narchitecture achieves state-of-the-art generalization on these downstream tasks\nwhile requiring significantly fewer parameters and minimal fine-tuning data,\nhighlighting its potential as a highly parameter-efficient FM for solving\ndiverse PDE systems.", "AI": {"tldr": "SPUS is a compact foundation model using lightweight residual U-Net architecture for solving diverse PDEs, achieving SOTA generalization with fewer parameters and minimal fine-tuning.", "motivation": "Existing PDE foundation models rely on large transformer architectures with high computational overhead, creating a need for more parameter-efficient alternatives.", "method": "Uses lightweight residual U-Net architecture with auto-regressive pretraining strategy that replicates numerical solver behavior, pretrained on diverse fluid dynamics PDEs.", "result": "Achieves state-of-the-art generalization on 6 challenging unseen downstream PDEs while requiring significantly fewer parameters and minimal fine-tuning data.", "conclusion": "SPUS demonstrates potential as a highly parameter-efficient foundation model for solving diverse PDE systems, making U-Net a viable alternative to transformer-based architectures."}}
{"id": "2510.01573", "pdf": "https://arxiv.org/pdf/2510.01573", "abs": "https://arxiv.org/abs/2510.01573", "authors": ["Zhuo Liu", "Muni Zhou", "Nuno F. G. Loureiro"], "title": "Suppression of inverse magnetic energy transfer in collisionless marginally magnetized plasmas", "categories": ["physics.plasm-ph", "astro-ph.HE"], "comment": null, "summary": "We investigate the inverse cascade of magnetic energy in decaying,\ncollisionless plasmas with moderate to high-$\\beta$ values via first-principles\nnumerical simulations and analytical theory. We find that\npressure-anisotropy-driven instabilities, in particular the firehose\ninstability, suppress reconnection-driven coalescence of magnetic structures\n(i.e., inverse transfer) by nullifying magnetic tension. This suppression\nleaves such structures elongated and confined to scales comparable to the\nLarmor radius of the particles. The presence of a magnetic guide field of\nsufficient strength, or a greater scale separation between the initial size of\nthe magnetic structures and the Larmor radius, restores the system's ability to\ninverse transfer magnetic energy. These results reveal that inverse energy\ntransfer in collisionless plasmas is not guaranteed, but instead sensitively\ndepends on magnetization. In the astrophysical context, this identifies a\nkinetic mechanism by which Weibel-generated seed fields may fail to merge\nconsistently, potentially limiting their role in cosmic magnetogenesis.", "AI": {"tldr": "Inverse magnetic energy cascade in collisionless plasmas is suppressed by pressure-anisotropy-driven instabilities, particularly firehose instability, which nullifies magnetic tension and prevents reconnection-driven coalescence of magnetic structures.", "motivation": "To understand how magnetic energy transfers to larger scales in collisionless plasmas, particularly in astrophysical contexts where Weibel-generated seed fields may play a role in cosmic magnetogenesis.", "method": "First-principles numerical simulations and analytical theory investigating decaying collisionless plasmas with moderate to high-\u03b2 values.", "result": "Firehose instability suppresses inverse energy transfer by nullifying magnetic tension, leaving magnetic structures elongated and confined to Larmor-radius scales. Guide fields or larger scale separation can restore inverse transfer capability.", "conclusion": "Inverse energy transfer in collisionless plasmas is not guaranteed and sensitively depends on magnetization, identifying a kinetic mechanism that may limit Weibel-generated seed fields' role in cosmic magnetogenesis."}}
{"id": "2510.02094", "pdf": "https://arxiv.org/pdf/2510.02094", "abs": "https://arxiv.org/abs/2510.02094", "authors": ["Abdolreza Amiri", "Gabriel R. Barrenechea", "Emmanuil H. Georgoulis", "Tristan Pryer"], "title": "A nodally bound-preserving composite discontinuous Galerkin method on polytopic meshes", "categories": ["math.NA", "cs.NA"], "comment": "27 pages, 7 figures", "summary": "We introduce a nodally bound-preserving Galerkin method for second-order\nelliptic problems on general polygonal/polyhedral, henceforth collectively\ntermed as \\emph{polytopic}, meshes. Starting from an interior penalty\ndiscontinuous Galerkin (DG) formulation posed on a polytopic mesh, the method\nenforces preservation of \\emph{a priori} prescribed upper and lower bounds for\nthe numerical solution at an arbitrary number of user-defined points\n\\emph{within} each polytopic element. This is achieved by employing a\nsimplicial submesh and enforcing bound preservation at the submesh nodes via a\nnonlinear iteration. By construction, the submeshing procedure preserves the\norder of accuracy of the DG method, \\emph{without} introducing any additional\nglobal numerical degrees of freedom compared to the baseline DG method,\nthereby, falling into the category of composite finite element approaches. A\nsalient feature of the proposed method is that it automatically reverts to the\nstandard DG method on polytopic meshes when no prescribed bound violation\noccurs. In particular, the choice of the discontinuity-penalisation parameter\nis independent of the submesh granularity. The resulting composite method\ncombines the geometric flexibility of polytopic meshes with the accuracy and\nstability of discontinuous Galerkin discretisations, while rigorously\nguaranteeing bound preservation. The existence and uniqueness of the numerical\nsolution is proven. A priori error bounds, assuming sufficient regularity of\nthe exact solution are shown, employing a non-standard construction of discrete\nnodally bound-preserving interpolant. Numerical experiments confirm optimal\nconvergence for smooth problems and demonstrate robustness in the presence of\nsharp gradients, such as boundary and interior layers.", "AI": {"tldr": "A nodally bound-preserving Galerkin method for elliptic problems on polytopic meshes that enforces solution bounds at user-defined points using simplicial submeshes without adding global degrees of freedom.", "motivation": "To develop a method that combines geometric flexibility of polytopic meshes with bound preservation capabilities for numerical solutions, particularly important for problems with sharp gradients like boundary layers.", "method": "Uses interior penalty discontinuous Galerkin formulation on polytopic meshes with simplicial submeshes to enforce bound preservation at submesh nodes via nonlinear iteration, preserving accuracy without additional global degrees of freedom.", "result": "The method maintains optimal convergence for smooth problems, demonstrates robustness with sharp gradients, and automatically reverts to standard DG when no bounds are violated. Existence and uniqueness of solutions are proven.", "conclusion": "The composite method successfully combines polytopic mesh flexibility with DG accuracy and stability while guaranteeing bound preservation, with proven mathematical properties and demonstrated numerical performance."}}
{"id": "2510.01507", "pdf": "https://arxiv.org/pdf/2510.01507", "abs": "https://arxiv.org/abs/2510.01507", "authors": ["Mitia Duerinckx", "Pierre-Emmanuel Jabin"], "title": "Correlation estimates for Brownian particles with singular interactions", "categories": ["math.AP", "math-ph", "math.MP", "math.PR"], "comment": "22 pages", "summary": "We study particle systems with singular pairwise interactions and\nnon-vanishing diffusion in the mean-field scaling. A classical approach to\ndescribing corrections to mean-field behavior is through the analysis of\ncorrelation functions. For bounded interactions, the optimal estimates on\ncorrelations are well known: the $m$-particle correlation function is\n$G_{N,m}=O(N^{1-m})$ for all $m$. Such estimates, however, have remained out of\nreach for more singular interactions. In this work, we develop a new framework\nbased on linearized correlation functions, which allows us to derive robust\nbounds for systems with merely square-integrable interaction kernels, providing\nthe first systematic control of correlations in the singular setting. Although\nat first not optimal, our estimates can be partially refined a posteriori using\nthe BBGKY hierarchy: in the case of bounded interactions, our method recovers\nthe known optimal estimates with a simplified argument. As key applications, we\nestablish the validity of the Bogolyubov correction to mean field and prove a\ncentral limit theorem for the empirical measure, extending these results beyond\nthe bounded interaction regime for the first time.", "AI": {"tldr": "This paper develops a new framework using linearized correlation functions to analyze particle systems with singular pairwise interactions and non-vanishing diffusion, providing the first systematic control of correlations for square-integrable interaction kernels.", "motivation": "Previous approaches to describing corrections to mean-field behavior through correlation functions were limited to bounded interactions, leaving singular interactions out of reach. The goal is to extend correlation analysis to more singular interaction regimes.", "method": "The authors develop a new framework based on linearized correlation functions and use the BBGKY hierarchy to derive robust bounds for systems with square-integrable interaction kernels.", "result": "The method provides systematic control of correlations in singular settings, recovers optimal estimates for bounded interactions, and establishes validity of Bogolyubov correction to mean field and central limit theorem for empirical measure beyond bounded interaction regime.", "conclusion": "The proposed framework successfully extends correlation analysis to singular interactions, enabling rigorous treatment of mean-field corrections and statistical properties in previously inaccessible regimes."}}
{"id": "2510.01396", "pdf": "https://arxiv.org/pdf/2510.01396", "abs": "https://arxiv.org/abs/2510.01396", "authors": ["Wasut Pornpatcharapong"], "title": "Neural Network Surrogates for Free Energy Computation of Complex Chemical Systems", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "physics.comp-ph"], "comment": "6 pages, 4 figures. This work has already been accepted for\n  presentation in The 29th International Computer Science and Engineering\n  Conference (ICSEC) 2025, Chiang Mai, Thailand, and will be published in IEEE\n  Xplore", "summary": "Free energy reconstruction methods such as Gaussian Process Regression (GPR)\nrequire Jacobians of the collective variables (CVs), a bottleneck that\nrestricts the use of complex or machine-learned CVs. We introduce a neural\nnetwork surrogate framework that learns CVs directly from Cartesian coordinates\nand uses automatic differentiation to provide Jacobians, bypassing analytical\nforms. On an MgCl2 ion-pairing system, our method achieved high accuracy for\nboth a simple distance CV and a complex coordination-number CV. Moreover,\nJacobian errors also followed a near-Gaussian distribution, making them\nsuitable for GPR pipelines. This framework enables gradient-based free energy\nmethods to incorporate complex and machine-learned CVs, broadening the scope of\nbiochemistry and materials simulations.", "AI": {"tldr": "A neural network surrogate framework that learns collective variables from Cartesian coordinates and provides Jacobians via automatic differentiation, enabling gradient-based free energy methods to use complex CVs without analytical forms.", "motivation": "Traditional free energy reconstruction methods require analytical Jacobians of collective variables, which restricts the use of complex or machine-learned CVs in simulations.", "method": "Neural network surrogate framework that learns CVs directly from Cartesian coordinates and uses automatic differentiation to compute Jacobians, bypassing the need for analytical forms.", "result": "Achieved high accuracy for both simple distance CV and complex coordination-number CV on MgCl2 ion-pairing system. Jacobian errors followed near-Gaussian distribution suitable for GPR pipelines.", "conclusion": "This framework enables gradient-based free energy methods to incorporate complex and machine-learned CVs, broadening applications in biochemistry and materials simulations."}}
{"id": "2510.01977", "pdf": "https://arxiv.org/pdf/2510.01977", "abs": "https://arxiv.org/abs/2510.01977", "authors": ["Andrew T. Powis", "Domenica Corona Rivera", "Alexander Khrabry", "Igor D. Kaganovich"], "title": "Accelerating kinetic plasma simulations with machine learning generated initial conditions", "categories": ["physics.plasm-ph", "physics.comp-ph"], "comment": null, "summary": "Computer aided engineering of multi-time-scale plasma systems which exhibit a\nquasi-steady state solution are challenging due to the large number of time\nsteps required to reach convergence. Machine learning techniques combined with\ntraditional first-principles simulations and high-performance computing offer\nmany interesting pathways towards resolving this challenge. We consider\nacceleration of kinetic plasma simulations via machine learning generated\ninitial conditions. The approach is demonstrated through modeling of\ncapacitively coupled plasma discharges relevant to the microelectronics\nindustry. Three models are trained on simulations across a parameter space of\ndevice driving frequency and operating pressure. The models incorporate\nelements of a multi-layer perceptron, principal component analysis, and\nconvolutional neural networks to predict the final time-averaged profiles of\nion-density and velocity distribution functions. These data-driven initial\ncondition generators (ICGs) provide a mean speedup of 17.1x in convergence\ntime, when measured using an offline procedure, or a 4.4x speedup with an\nonline procedure, with convolutional neural networks leading to the best\nperformance. The paper also outlines a workflow for continuous data-driven\nmodel improvement and simulation speedup, with the aim of generating sufficient\ndata for full device digital twins.", "AI": {"tldr": "Machine learning accelerates kinetic plasma simulations by generating initial conditions, achieving up to 17.1x speedup in convergence time for capacitively coupled plasma discharge modeling.", "motivation": "Multi-time-scale plasma systems require many time steps to reach quasi-steady state, making computer-aided engineering challenging. Machine learning combined with traditional simulations offers pathways to resolve this computational challenge.", "method": "Three machine learning models (multi-layer perceptron, principal component analysis, convolutional neural networks) are trained on simulations across device driving frequency and pressure parameters to predict final time-averaged profiles of ion-density and velocity distribution functions.", "result": "The data-driven initial condition generators provide mean speedup of 17.1x with offline procedure or 4.4x with online procedure. Convolutional neural networks performed best among the three model types.", "conclusion": "The paper presents a workflow for continuous data-driven model improvement and simulation speedup, aiming to generate sufficient data for full device digital twins in plasma systems."}}
{"id": "2510.02111", "pdf": "https://arxiv.org/pdf/2510.02111", "abs": "https://arxiv.org/abs/2510.02111", "authors": ["Kosuke Suzuki"], "title": "Coarse scrambling for Sobol' and Niederreiter sequences", "categories": ["math.NA", "cs.NA", "65C05, 65D30"], "comment": null, "summary": "We introduce \\emph{coarse scrambling}, a novel randomization for digital\nsequences that permutes blocks of digits in a mixed-radix representation. This\nconstruction is designed to preserve the powerful\n$(0,\\boldsymbol{e},d)$-sequence property of the underlying points. For\nsufficiently smooth integrands, we prove that this method achieves the\ncanonical $O(n^{-3+\\epsilon})$ variance decay rate, matching that of standard\nOwen's scrambling. Crucially, we show that its maximal gain coefficient grows\nonly logarithmically with dimension, $O(\\log d)$, thus providing theoretical\nrobustness against the curse of dimensionality affecting scrambled Sobol'\nsequences. Numerical experiments validate these findings and illustrate a\npractical trade-off: while Owen's scrambling is superior for integrands\nsensitive to low-dimensional projections, coarse scrambling is competitive for\nfunctions with low effective truncation dimension.", "AI": {"tldr": "Coarse scrambling is a new randomization method for digital sequences that permutes blocks of digits while preserving (0,e,d)-sequence properties, achieving O(n^{-3+\u03b5}) variance decay with logarithmic dimension dependence O(log d).", "motivation": "To address the curse of dimensionality affecting scrambled Sobol' sequences by developing a randomization method with better dimension scaling.", "method": "Coarse scrambling permutes blocks of digits in mixed-radix representations while preserving the (0,e,d)-sequence property of the underlying points.", "result": "Achieves canonical O(n^{-3+\u03b5}) variance decay rate and shows maximal gain coefficient grows only logarithmically with dimension O(log d), providing robustness against curse of dimensionality.", "conclusion": "Coarse scrambling is competitive for functions with low effective truncation dimension, while Owen's scrambling remains superior for integrands sensitive to low-dimensional projections."}}
{"id": "2510.01515", "pdf": "https://arxiv.org/pdf/2510.01515", "abs": "https://arxiv.org/abs/2510.01515", "authors": ["David Meyer"], "title": "On the attainment of boundary data in variational problems with linear growth", "categories": ["math.AP"], "comment": null, "summary": "It is well-known that convex variational problems with linear growth and\nDirichlet boundary conditions might not have minimizers if the boundary\ncondition is not suitably relaxed.\n  We show that for a wide range of integrands, including the least gradient\nproblem and the non-parametric Plateau problem, and under suitable\nmean-convexity conditions of the boundary, minimizers of the relaxed problem\nattain the boundary data in the trace sense if it lies in $BV$ or\n$W^{\\alpha,p}$ with $\\alpha p\\geq 2$ without any kind of continuity assumption.\nUnlike previous works, our methods are also able to treat systems under a\ncertain quasi-isotropy assumption on the integrand. We further show that\nwithout this quasi-isotropy assumption, smooth counterexamples on uniformly\nconvex domains exist.\n  Further applications to the uniqueness of minimizers and to open problems\nabout the ROF functional with Dirichlet boundary conditions, and to the trace\nspace of functions of least gradient are given.", "AI": {"tldr": "The paper studies convex variational problems with linear growth and Dirichlet boundary conditions, showing that under mean-convexity conditions and for boundary data in BV or W^\u03b1,p with \u03b1p\u22652, minimizers attain boundary data in trace sense without continuity assumptions. The methods also handle systems under quasi-isotropy assumptions.", "motivation": "To address the well-known issue that convex variational problems with linear growth and Dirichlet boundary conditions might not have minimizers if boundary conditions are not properly relaxed, and to extend results to systems.", "method": "The authors use relaxed variational formulations and trace theory, working under mean-convexity conditions on the boundary. They develop methods that can treat systems under quasi-isotropy assumptions on the integrand.", "result": "For a wide range of integrands including least gradient and Plateau problems, minimizers attain boundary data in trace sense for BV or W^\u03b1,p data with \u03b1p\u22652. Without quasi-isotropy, smooth counterexamples exist on uniformly convex domains.", "conclusion": "The approach successfully handles boundary value problems for convex variational problems with linear growth, extends to systems under quasi-isotropy, and provides applications to uniqueness, ROF functional with Dirichlet conditions, and trace spaces of least gradient functions."}}
{"id": "2510.01419", "pdf": "https://arxiv.org/pdf/2510.01419", "abs": "https://arxiv.org/abs/2510.01419", "authors": ["Md Tusher Ahmed", "Chenhaoyue Wang", "Amartya S. Banerjee", "Nikhil Chandra Admal"], "title": "Multiscale analysis of large twist ferroelectricity and swirling dislocations in bilayer hexagonal boron nitride", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "With its atomically thin structure and intrinsic ferroelectric properties,\nheterodeformed bilayer hexagonal boron nitride (hBN) has gained prominence in\nnext-generation non-volatile memory applications. However, studies to date have\nfocused almost exclusively on small heterodeformations, leaving the question of\nwhether ferroelectricity can persist under large heterodeformation entirely\nunexplored. In this work, we establish the crystallographic origin of\nferroelectricity in bilayer hBN configurations heterodeformed relative to\nhigh-symmetry configurations such as the AA-stacking and the 21.786789 $\\circ$\ntwisted configuration, using Smith normal form bicrystallography. We then\ndemonstrate out-of-plane ferroelectricity in bilayer hBN across configurations\nvicinal to both the AA and $\\Sigma 7$ stacking. Atomistic simulations reveal\nthat AA-vicinal systems support ferroelectricity under both small twist and\nsmall strain, with polarization switching in the latter governed by the\ndeformation of swirling dislocations rather than the straight interface\ndislocations seen in the former. For $\\Sigma 7$-vicinal systems, where reliable\ninteratomic potentials are lacking, we develop a\ndensity-functional-theory-informed continuum framework--the\nbicrystallography-informed frame-invariant multiscale (BFIM) model, which\ncaptures out-of-plane ferroelectricity in heterodeformed configurations vicinal\nto the $\\Sigma 7$ stacking. Interface dislocations in these large\nheterodeformed bilayer configurations exhibit markedly smaller Burgers vectors\ncompared to the interface dislocations in small-twist and small-strain bilayer\nhBN. The BFIM model reproduces atomistic simulation results and provides a\npowerful, computationally efficient framework for predicting ferroelectricity\nin large-unit-cell heterostructures where atomistic simulations are\nprohibitively expensive.", "AI": {"tldr": "This paper demonstrates that ferroelectricity persists in bilayer hBN under large heterodeformations, not just small ones. It establishes the crystallographic origin using Smith normal form bicrystallography and develops a multiscale model to predict ferroelectricity in large-unit-cell heterostructures.", "motivation": "Previous studies focused only on small heterodeformations in bilayer hBN, leaving the persistence of ferroelectricity under large heterodeformations unexplored. This work aims to fill this gap and understand ferroelectric behavior across different stacking configurations.", "method": "Used Smith normal form bicrystallography to establish crystallographic origin, performed atomistic simulations for AA-vicinal systems, and developed a density-functional-theory-informed continuum framework (BFIM model) for \u03a37-vicinal systems where atomistic potentials are unreliable.", "result": "Demonstrated out-of-plane ferroelectricity in bilayer hBN across configurations vicinal to both AA and \u03a37 stacking. Found that AA-vicinal systems support ferroelectricity under small twist and strain, with different polarization switching mechanisms. Interface dislocations in large heterodeformations have smaller Burgers vectors.", "conclusion": "Ferroelectricity persists in bilayer hBN under large heterodeformations. The BFIM model provides an efficient computational framework for predicting ferroelectricity in large-unit-cell heterostructures where atomistic simulations are too expensive."}}
{"id": "2510.02088", "pdf": "https://arxiv.org/pdf/2510.02088", "abs": "https://arxiv.org/abs/2510.02088", "authors": ["Alexander Schmitz", "Andreas Petersen", "Franko Greiner"], "title": "A neural network approach to kinetic Mie polarimetry for particle size diagnostics in nanodusty plasmas", "categories": ["physics.plasm-ph"], "comment": "Accepted manuscript", "summary": "The analysis of the size of nanoparticles is an essential task in plasma\ntechnology and dusty plasmas. Light scattering techniques, based on Mie theory,\ncan be used as a non-invasive and in-situ diagnostic tool for this purpose.\nHowever, the standard back-calculation methods require expertise from the user.\nTo address this, we introduce a neural network that performs the same task. We\ndiscuss how we set up and trained the network to analyze the size of\nplasma-grown amorphous carbon nanoparticles (a:C-H) with a refractive index n\nin the range of real(n) = 1.4-2.2 and imag(n) = 0.04i-0.1i and a radius of up\nto several hundred nanometers, depending on the used wavelength. The diagnostic\napproach is kinetic, which means that the particles need to change in size due\nto growth or etching. An uncertainty analysis as well as a test with\nexperimental data are presented. Our neural network achieves results that agree\nwith those of prior fitting algorithms while offering higher methodical\nstability. The model also holds a major advantage in terms of computing speed\nand automation.", "AI": {"tldr": "A neural network is introduced to analyze nanoparticle sizes in plasma technology, replacing traditional back-calculation methods that require user expertise.", "motivation": "Standard light scattering techniques for nanoparticle size analysis require expertise and are not automated. The paper aims to develop a more accessible and efficient method.", "method": "A neural network is trained to analyze the size of plasma-grown amorphous carbon nanoparticles using light scattering data based on Mie theory.", "result": "The neural network achieves results comparable to prior fitting algorithms with higher stability, faster computation, and better automation.", "conclusion": "The neural network approach offers a superior alternative to traditional methods, providing methodical stability, speed, and automation for nanoparticle size analysis."}}
{"id": "2510.02126", "pdf": "https://arxiv.org/pdf/2510.02126", "abs": "https://arxiv.org/abs/2510.02126", "authors": ["Peter Benner", "Xiaobo Liu"], "title": "Mixed-precision iterative refinement for low-rank Lyapunov equations", "categories": ["math.NA", "cs.NA", "65F10, 65F45, 65G50, 15A24"], "comment": null, "summary": "We develop a mixed-precision iterative refinement framework for solving\nlow-rank Lyapunov matrix equations $AX + XA^T + W =0$, where $W=LL^T$ or\n$W=LSL^T$. Via rounding error analysis of the algorithms we derive sufficient\nconditions for the attainable normwise residuals in different precision\nsettings and show how the algorithmic parameters should be chosen. Using the\nsign function Newton iteration as the solver, we show that reduced precisions,\nsuch as the half precision, can be used as the solver precision (with unit\nroundoff $u_s$) to accelerate the solution of Lyapunov equations of condition\nnumber up to $1/u_s$ without compromising its quality.", "AI": {"tldr": "Mixed-precision iterative refinement framework for solving low-rank Lyapunov matrix equations using reduced precisions like half precision to accelerate computation while maintaining solution quality.", "motivation": "To accelerate the solution of Lyapunov matrix equations by using reduced precision computations without compromising solution quality, especially for equations with condition numbers up to the inverse of the solver precision's unit roundoff.", "method": "Developed a mixed-precision iterative refinement framework using the sign function Newton iteration as the solver. Performed rounding error analysis to derive sufficient conditions for attainable normwise residuals and determine optimal algorithmic parameters.", "result": "Showed that reduced precisions (such as half precision with unit roundoff u_s) can be used to accelerate Lyapunov equation solutions for condition numbers up to 1/u_s while maintaining solution quality.", "conclusion": "Mixed-precision iterative refinement with reduced precision solvers enables significant acceleration of Lyapunov equation solutions for a wide range of condition numbers without sacrificing accuracy."}}
{"id": "2510.01602", "pdf": "https://arxiv.org/pdf/2510.01602", "abs": "https://arxiv.org/abs/2510.01602", "authors": ["Yanlong Fan", "Daozhi Han", "Quan Wang"], "title": "Inertial instability of Couette flow with Coriolis force", "categories": ["math.AP"], "comment": null, "summary": "We analyze the nonlinear inertial instability of Couette flow under Coriolis\nforcing in \\(\\mathbb{R}^{3}\\). For the Coriolis coefficient \\(f \\in (0,1)\\), we\nshow that the non-normal operator associated with the linearized system admits\nonly continuous spectrum. Hence, there are no exponentially growing\neigenfunctions for the linearized system. Instead, we construct unstable\nsolutions in the form of pseudo-eigenfunctions that exhibit non-ideal spectral\nproperties. Then through a bootstrap argument and resolving the challenges\nposed by the non-ideal spectral behavior of pseudo-eigenfunctions, we establish\nthe velocity instability of Couette flow in the Hadamard sense for $ f \\in\n\\Big(\\frac{2}{17} \\left(5-2 \\sqrt{2}\\right), \\frac{2}{17} \\left(5 + 2\n\\sqrt{2}\\right) \\Big)$.", "AI": {"tldr": "The paper analyzes nonlinear inertial instability of Couette flow under Coriolis forcing in 3D, showing velocity instability for specific Coriolis coefficient ranges despite no exponential eigenfunction growth.", "motivation": "To understand the stability properties of Couette flow under Coriolis forcing, particularly when the linearized system lacks exponentially growing eigenfunctions but still exhibits instability through non-ideal spectral behavior.", "method": "Analysis of the non-normal operator's spectrum, construction of pseudo-eigenfunctions, and bootstrap arguments to handle non-ideal spectral properties and establish Hadamard instability.", "result": "Velocity instability of Couette flow is established in the Hadamard sense for Coriolis coefficients f in the interval (2/17(5-2\u221a2), 2/17(5+2\u221a2)), despite the linearized system having only continuous spectrum and no exponentially growing eigenfunctions.", "conclusion": "Couette flow under Coriolis forcing exhibits nonlinear inertial instability through pseudo-eigenfunctions even when traditional linear stability analysis suggests stability, demonstrating the importance of non-normal operators and non-ideal spectral behavior in fluid stability problems."}}
{"id": "2510.01543", "pdf": "https://arxiv.org/pdf/2510.01543", "abs": "https://arxiv.org/abs/2510.01543", "authors": ["Dawid A. Hryniuk", "Marzena H. Szyma\u0144ska"], "title": "Variational approach to open quantum systems with long-range competing interactions", "categories": ["quant-ph", "cond-mat.quant-gas", "physics.comp-ph"], "comment": null, "summary": "Competition between short- and long-range interactions underpins many\nemergent phenomena in nature. Despite rapid progress in their experimental\ncontrol, computational methods capable of accurately simulating open quantum\nmany-body systems with complex long-ranged interactions at scale remain scarce.\nHere, we address this limitation by introducing an efficient and scalable\napproach to dissipative quantum lattices in one and two dimensions, combining\nmatrix product operators and time-dependent variational Monte Carlo. We\nshowcase the versatility, effectiveness, and unique methodological advantages\nof our algorithm by simulating the non-equilibrium dynamics and steady states\nof spin-$\\frac{1}{2}$ lattices with competing algebraically-decaying\ninteractions for as many as $N=200$ sites, revealing the emergence of\nspatially-modulated magnetic order far from equilibrium. This approach offers\npromising prospects for advancing our understanding of the complex\nnon-equilibrium properties of a diverse variety of experimentally-realizable\nquantum systems with long-ranged interactions, including Rydberg atoms,\nultracold dipolar molecules, and trapped ions.", "AI": {"tldr": "Efficient computational method for simulating open quantum many-body systems with long-range interactions using matrix product operators and variational Monte Carlo.", "motivation": "Need for accurate computational methods to study quantum systems with competing short- and long-range interactions, which are experimentally accessible but computationally challenging.", "method": "Combines matrix product operators and time-dependent variational Monte Carlo to simulate dissipative quantum lattices in 1D and 2D.", "result": "Successfully simulated non-equilibrium dynamics and steady states of spin-1/2 lattices with algebraically-decaying interactions for up to 200 sites, revealing spatially-modulated magnetic order.", "conclusion": "This scalable approach enables study of complex non-equilibrium phenomena in quantum systems with long-range interactions, applicable to Rydberg atoms, dipolar molecules, and trapped ions."}}
{"id": "2510.01875", "pdf": "https://arxiv.org/pdf/2510.01875", "abs": "https://arxiv.org/abs/2510.01875", "authors": ["Zhandos A. Moldabekov", "Sebastian Schwalbe", "Uwe Hernandez Acosta", "Thomas Gawne", "Jan Vorberger", "Michele Pavanello", "Tobias Dornheim"], "title": "Enhancing the Efficiency of Time-Dependent Density Functional Theory Calculations of Dynamic Response Properties", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph", "physics.plasm-ph"], "comment": null, "summary": "X-ray Thomson scattering (XRTS) constitutes an essential technique for\ndiagnosing material properties under extreme conditions, such as high pressures\nand intense laser heating. Time-dependent density functional theory (TDDFT) is\none of the most accurate available ab initio methods for modeling XRTS spectra,\nas well as a host of other dynamic material properties. However, strong thermal\nexcitations, along with the need to account for variations in temperature and\ndensity as well as the finite size of the detector significantly increase the\ncomputational cost of TDDFT simulations compared to ambient conditions. In this\nwork, we present a broadly applicable method for optimizing and enhancing the\nefficiency of TDDFT calculations. Our approach is based on a one-to-one mapping\nbetween the dynamic structure factor and the imaginary time density--density\ncorrelation function, which naturally emerges in Feynman's path integral\nformulation of quantum many-body theory. Specifically, we combine rigorous\nconvergence tests in the imaginary time domain with a constraints-based noise\nattenuation technique to improve the efficiency of TDDFT modeling without the\nintroduction of any significant bias. As a result, we can report a speed-up by\nup to an order of magnitude, thus potentially saving millions of CPU hours for\nmodeling a single XRTS measurement of matter under extreme conditions.", "AI": {"tldr": "A method to speed up TDDFT calculations for X-ray Thomson scattering by using imaginary time mapping and noise attenuation, achieving up to 10x speed-up.", "motivation": "TDDFT is accurate for modeling XRTS spectra under extreme conditions, but computational costs are high due to thermal excitations, temperature/density variations, and detector size effects.", "method": "Uses mapping between dynamic structure factor and imaginary time density-density correlation function from Feynman's path integral theory, combined with convergence tests and constraints-based noise attenuation.", "result": "Achieves up to an order of magnitude speed-up in TDDFT calculations, potentially saving millions of CPU hours for single XRTS measurements.", "conclusion": "The method provides efficient TDDFT modeling for extreme conditions without significant bias, enabling more practical XRTS analysis."}}
{"id": "2510.02156", "pdf": "https://arxiv.org/pdf/2510.02156", "abs": "https://arxiv.org/abs/2510.02156", "authors": ["Suvendu Kar", "Murugesan Venkatapathi"], "title": "A Fast solver for high condition linear systems using randomized stable solutions of its blocks", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We present an enhanced version of the row-based randomized block-Kaczmarz\nmethod to solve a linear system of equations. This improvement makes use of a\nregularization during block updates in the solution, and a dynamic proposal\ndistribution based on the current residue and effective orthogonality between\nblocks. This improved method provides significant gains in solving\nhigh-condition number linear systems that are either sparse, or dense\nleast-squares problems that are significantly over/under determined.\nConsidering the poor generalizability of preconditioners for such problems, it\ncan also serve as a pre-solver for other iterative numerical methods when\nrequired, and as an inner iteration in certain types of GMRES solvers for\nlinear systems.", "AI": {"tldr": "Enhanced randomized block-Kaczmarz method with regularization and dynamic proposal distribution for solving linear systems, especially effective for high-condition number problems.", "motivation": "To improve solving high-condition number linear systems that are sparse or dense least-squares problems with poor preconditioner generalizability.", "method": "Uses regularization during block updates and dynamic proposal distribution based on current residue and effective orthogonality between blocks.", "result": "Provides significant gains in solving high-condition number linear systems, particularly for sparse systems or dense least-squares problems that are significantly over/under determined.", "conclusion": "The improved method can serve as a pre-solver for other iterative numerical methods and as an inner iteration in certain GMRES solvers for linear systems."}}
{"id": "2510.01647", "pdf": "https://arxiv.org/pdf/2510.01647", "abs": "https://arxiv.org/abs/2510.01647", "authors": ["Lu Chen", "Jiali Lan"], "title": "The weighted isoperimetric inequality and Sobolev inequality outside convex sets", "categories": ["math.AP"], "comment": "26 pages", "summary": "In this paper, we establish a weighted capillary isoperimetric inequality\noutside convex sets using the $\\lambda_w$-ABP method. The weight function $w$\nis assumed to be positive, even, and homogeneous of degree $\\alpha$, such that\n$w^{1/\\alpha}$ is concave on $\\R^n$.\n  Based on the weighted isoperimetric inequality, we develop a technique of\ncapillary Schwarz symmetrization outside convex sets, and establish a weighted\nP\\'{o}lya-Szeg\\\"{o} principle and a sharp weighted capillary Sobolev inequality\noutside convex domain. Our result can be seen as an extension of the weighted\nSobolev inequality in the half-space established by Ciraolo-Figalli-Roncoroni\nin \\cite{CFR}.", "AI": {"tldr": "Extension of weighted Sobolev inequalities to capillary settings outside convex sets using weighted isoperimetric inequalities and capillary Schwarz symmetrization.", "motivation": "To generalize weighted Sobolev inequalities from half-spaces to capillary settings outside convex sets, building on previous work by Ciraolo-Figalli-Roncoroni.", "method": "Uses weighted capillary isoperimetric inequality with \u03bbw-ABP method, capillary Schwarz symmetrization outside convex sets, and establishes weighted P\u00f3lya-Szeg\u0151 principle.", "result": "Proves sharp weighted capillary Sobolev inequality outside convex domains, extending previous results from half-spaces to more general capillary settings.", "conclusion": "Successfully extends weighted Sobolev inequalities to capillary contexts outside convex sets, providing a broader framework for such inequalities."}}
{"id": "2510.01957", "pdf": "https://arxiv.org/pdf/2510.01957", "abs": "https://arxiv.org/abs/2510.01957", "authors": ["David Martinez-del-Rio", "Robert S. MacKay"], "title": "Numerical tests of formulae for volume enclosed by flux surfaces of integrable magnetic fields", "categories": ["math.DS", "physics.plasm-ph"], "comment": "Keywords: Magnetic field, Flux surface, Volume", "summary": "Numerical tests of volume formulae are presented to compute efficiently the\nvolume enclosed between flux surfaces for integrable 3D vector fields with\nvarious degrees of symmetry. In the process, a new case is proposed and tested.", "AI": {"tldr": "Numerical tests of volume formulae for integrable 3D vector fields with various symmetries, including a new proposed case.", "motivation": "To efficiently compute volumes enclosed between flux surfaces for integrable 3D vector fields with different symmetry levels.", "method": "Present numerical tests of volume formulae and propose a new case for testing.", "result": "Successful numerical testing of volume formulae for various symmetry cases.", "conclusion": "The volume formulae are effective for computing volumes in integrable 3D vector fields with different symmetry properties."}}
{"id": "2510.01495", "pdf": "https://arxiv.org/pdf/2510.01495", "abs": "https://arxiv.org/abs/2510.01495", "authors": ["Kimmie Harding", "Daniel M. Dunlavy"], "title": "Improving Runtime Performance of Tensor Computations using Rust From Python", "categories": ["cs.MS", "cs.NA", "math.NA", "G.4"], "comment": "12 pages, 4 figures", "summary": "In this work, we investigate improving the runtime performance of key\ncomputational kernels in the Python Tensor Toolbox (pyttb), a package for\nanalyzing tensor data across a wide variety of applications. Recent runtime\nperformance improvements have been demonstrated using Rust, a compiled\nlanguage, from Python via extension modules leveraging the Python C API --\ne.g., web applications, data parsing, data validation, etc. Using this same\napproach, we study the runtime performance of key tensor kernels of increasing\ncomplexity, from simple kernels involving sums of products over data accessed\nthrough single and nested loops to more advanced tensor multiplication kernels\nthat are key in low-rank tensor decomposition and tensor regression algorithms.\nIn numerical experiments involving synthetically generated tensor data of\nvarious sizes and these tensor kernels, we demonstrate consistent improvements\nin runtime performance when using Rust from Python over 1) using Python alone,\n2) using Python and the Numba just-in-time Python compiler (for loop-based\nkernels), and 3) using the NumPy Python package for scientific computing (for\npyttb kernels).", "AI": {"tldr": "This paper investigates improving Python Tensor Toolbox performance by implementing key computational kernels in Rust via Python extension modules, showing consistent runtime improvements over Python alone, Numba JIT compilation, and NumPy implementations.", "motivation": "To enhance runtime performance of tensor computational kernels in the Python Tensor Toolbox (pyttb) for better tensor data analysis across various applications, leveraging Rust's compiled language advantages through Python extension modules.", "method": "Implemented key tensor kernels of increasing complexity in Rust using Python C API extension modules, ranging from simple sum-of-products operations to advanced tensor multiplication kernels used in low-rank tensor decomposition and tensor regression algorithms.", "result": "Numerical experiments with synthetic tensor data showed consistent runtime performance improvements when using Rust from Python compared to: 1) pure Python, 2) Python with Numba JIT compiler, and 3) NumPy implementations of pyttb kernels.", "conclusion": "Using Rust via Python extension modules provides significant runtime performance benefits for tensor computational kernels, making it a viable approach for optimizing Python-based tensor analysis packages."}}
{"id": "2510.01728", "pdf": "https://arxiv.org/pdf/2510.01728", "abs": "https://arxiv.org/abs/2510.01728", "authors": ["Matthew Kowalski", "Minjie Shan"], "title": "On dispersive decay for the generalized Korteweg--de Vries equation", "categories": ["math.AP", "35Q53"], "comment": "12 pages", "summary": "We prove pointwise-in-time dispersive estimates for solutions to the\ngeneralized Korteweg--de Vries (gKdV) equation. In particular, for solutions to\nthe mass-critical model, we assume only that initial data lie in\n$\\dot{H}^{\\frac{1}{4}} \\cap \\dot{H}^{-\\frac{1}{12}}$ and show that solutions\ndecay in $L^\\infty$ like $|t|^{-\\frac{1}{3}}$. To accomplish this, we develop a\npersistence of negative regularity for solutions to gKdV and extend\nLorentz--Strichartz estimates to the mixed norm case.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2510.01918", "pdf": "https://arxiv.org/pdf/2510.01918", "abs": "https://arxiv.org/abs/2510.01918", "authors": ["Adri\u00e1n Mar\u0131n", "Mauricio Soto-Gomez", "Giorgio Valentini", "Elena Casiraghi", "Carlos Cano", "Daniel Manzano"], "title": "Hybrid Quantum-Classical Walks for Graph Representation Learning in Community Detection", "categories": ["quant-ph", "physics.comp-ph"], "comment": "6 pages. Accepted at the 2025 IEEE International Conference on\n  Quantum Artificial Intelligence", "summary": "Graph Representation Learning (GRL) has emerged as a cornerstone technique\nfor analysing complex, networked data across diverse domains, including\nbiological systems, social networks, and data analysis. Traditional GRL methods\noften struggle to capture intricate relationships within complex graphs,\nparticularly those exhibiting non-trivial structural properties such as\npower-law distributions or hierarchical structures. This paper introduces a\nnovel quantum-inspired algorithm for GRL, utilizing hybrid Quantum-Classical\nWalks to overcome these limitations. Our approach combines the benefits of both\nquantum and classical dynamics, allowing the walker to simultaneously explore\nboth highly local and far-reaching connections within the graph. Preliminary\nresults for a case study in network community detection shows that this hybrid\ndynamic enables the algorithm to adapt effectively to complex graph topologies,\noffering a robust and versatile solution for GRL tasks.", "AI": {"tldr": "A quantum-inspired algorithm using hybrid Quantum-Classical Walks for Graph Representation Learning that adapts to complex graph topologies by exploring both local and global connections simultaneously.", "motivation": "Traditional GRL methods struggle to capture intricate relationships in complex graphs with non-trivial structural properties like power-law distributions or hierarchical structures.", "method": "Hybrid Quantum-Classical Walks that combine quantum and classical dynamics to allow simultaneous exploration of both local and far-reaching graph connections.", "result": "Preliminary results for network community detection show the hybrid dynamic enables effective adaptation to complex graph topologies.", "conclusion": "The approach offers a robust and versatile solution for GRL tasks by overcoming limitations of traditional methods through quantum-inspired dynamics."}}
{"id": "2510.02301", "pdf": "https://arxiv.org/pdf/2510.02301", "abs": "https://arxiv.org/abs/2510.02301", "authors": ["Andrew G. Sullivan", "Roger D. Blandford", "Anna Synani", "Philipe V. de la Parra", "No\u00e9mie Globus", "Mitchell C. Begelman", "Anthony C. S. Readhead"], "title": "Relativistic Jets and Winds in Radio-Identified Supermassive Black Hole Binary Candidates", "categories": ["astro-ph.HE", "astro-ph.GA", "physics.plasm-ph"], "comment": "13 pages, 8 figures, submitted to ApJ", "summary": "Supermassive black hole binary systems (SMBHBs) are thought to emit the\nrecently discovered nHz gravitational wave background; however, not a single\nindividual nHz source has been confirmed to date. Long-term radio-monitoring at\nthe Owens Valley Radio Observatory has revealed two potential SMBHB candidates:\nblazars PKS 2131-021 and PKS J0805-0111. These sources show periodic flux\ndensity variations across the electromagnetic spectrum, signaling the presence\nof a good clock. To explain the emission, we propose a generalizable jet model,\nwhere a mildly relativistic wind creates an outward-moving helical channel,\nalong which the ultra-relativistic jet propagates. The observed flux variation\nfrom the jet is mostly due to aberration. The emission at lower frequency\narises at larger radius and its variation is consequently delayed, as observed.\nOur model reproduces the main observable features of both sources and can be\napplied to other sources as they are discovered. We make predictions for radio\npolarization, direct imaging, and emission line variation, which can be tested\nwith forthcoming observations. Our results motivate future numerical\nsimulations of jetted SMBHB systems and have implications for the fueling,\nstructure, and evolution of blazar jets.", "AI": {"tldr": "Proposes a jet model to explain periodic flux variations in two SMBHB candidates, suggesting helical jet channels created by mildly relativistic winds cause observable aberrations and delays.", "motivation": "To explain the periodic flux density variations observed in potential supermassive black hole binary candidates PKS 2131-021 and PKS J0805-0111, which show clock-like behavior but lack confirmed individual nHz gravitational wave sources.", "method": "Developed a generalizable jet model where a mildly relativistic wind creates an outward-moving helical channel for ultra-relativistic jet propagation, with flux variations mainly due to aberration effects and delayed lower-frequency emission from larger radii.", "result": "The model successfully reproduces the main observable features of both SMBHB candidates, including periodic flux variations and frequency-dependent delays, and makes testable predictions for radio polarization, direct imaging, and emission line variations.", "conclusion": "The proposed model provides a viable explanation for SMBHB candidate observations, motivates future numerical simulations of jetted systems, and has implications for understanding blazar jet fueling, structure, and evolution."}}
{"id": "2510.01511", "pdf": "https://arxiv.org/pdf/2510.01511", "abs": "https://arxiv.org/abs/2510.01511", "authors": ["Nazar Emirov", "Guohui Song", "Qiyu Sun"], "title": "Exponential convergence of a distributed divide-and-conquer algorithm for constrained convex optimization on networks", "categories": ["math.OC", "cs.DC", "cs.NA", "math.NA"], "comment": null, "summary": "We propose a divide-and-conquer (DAC) algorithm for constrained convex\noptimization over networks, where the global objective is the sum of local\nobjectives attached to individual agents. The algorithm is fully distributed:\neach iteration solves local subproblems around selected fusion centers and\ncoordinates only with neighboring fusion centers. Under standard assumptions of\nsmoothness, strong convexity, and locality on the objective function, together\nwith polynomial growth conditions on the underlying graph, we establish\nexponential convergence of the DAC iterations and derive explicit bounds for\nboth exact and inexact local solvers. Numerical experiments on three\nrepresentative losses ($L_2$ distance, quadratic, and entropy) confirm the\ntheory and demonstrate scalability and effectiveness.", "AI": {"tldr": "A distributed divide-and-conquer algorithm for constrained convex optimization over networks with exponential convergence guarantees.", "motivation": "To solve large-scale constrained convex optimization problems where the global objective is distributed across multiple agents in a network, requiring fully distributed computation with minimal coordination.", "method": "Divide-and-conquer approach where each iteration solves local subproblems around selected fusion centers and coordinates only with neighboring fusion centers. Works under smoothness, strong convexity, and locality assumptions.", "result": "Established exponential convergence of DAC iterations with explicit bounds for both exact and inexact local solvers. Numerical experiments on L2 distance, quadratic, and entropy losses confirm theory and demonstrate scalability.", "conclusion": "The proposed DAC algorithm provides an effective and scalable distributed solution for constrained convex optimization over networks with provable exponential convergence rates."}}
{"id": "2510.01732", "pdf": "https://arxiv.org/pdf/2510.01732", "abs": "https://arxiv.org/abs/2510.01732", "authors": ["Anne-Laure Dalibard", "Fr\u00e9d\u00e9ric Marbach", "Jean Rax"], "title": "Nonlinear Forward-Backward Problems", "categories": ["math.AP"], "comment": "arXiv admin note: text overlap with arXiv:2203.11067", "summary": "We prove the existence and uniqueness of strong solutions to the equation $u\nu_x - u_{yy} = f$ in the vicinity of the linear shear flow, subject to\nperturbations of the source term and lateral boundary conditions. Since the\nsolutions we consider have opposite signs in the lower and upper half of the\ndomain, this is a quasilinear forward-backward parabolic problem, which changes\ntype across a critical curved line within the domain. In particular, lateral\nboundary conditions can be imposed only where the characteristics are inwards.\nThere are several difficulties associated with this problem. First, the\nforward-backward geometry depends on the solution itself. This requires to be\nquite careful with the approximation procedure used to construct solutions.\nSecond, and more importantly, the linearized equations solved at each step of\nthe iterative scheme admit a finite number of singular solutions, of which we\nprovide an explicit construction. This is similar to well-known phenomena in\nelliptic problems in nonsmooth domains. Hence, the solutions to the equation\nare regular if and only if the source terms satisfy a finite number of\northogonality conditions. A key difficulty of this work is to cope with these\northogonality conditions during the nonlinear fixed-point scheme. In\nparticular, we are led to prove their stability with respect to the underlying\nbase flow. To tackle this deceivingly simple problem, we develop a methodology\nwhich we believe to be both quite natural and adaptable to other situations in\nwhich one wishes to prove the existence of regular solutions to a nonlinear\nproblem for suitable data despite the existence of singular solutions at the\nlinear level. This paper is a shorter version of [3].", "AI": {"tldr": "Existence and uniqueness of strong solutions to a quasilinear forward-backward parabolic equation near linear shear flow, with orthogonality conditions for regularity.", "motivation": "Study a quasilinear forward-backward parabolic problem that changes type across a critical curved line, with solutions having opposite signs in different domain regions, requiring careful treatment of boundary conditions and singular solutions.", "method": "Developed an iterative approximation procedure with careful handling of finite singular solutions in linearized equations, proving stability of orthogonality conditions during nonlinear fixed-point scheme.", "result": "Proved existence and uniqueness of strong solutions for suitable data satisfying orthogonality conditions, with solutions regular only when source terms meet these conditions.", "conclusion": "Developed a natural and adaptable methodology for proving existence of regular solutions to nonlinear problems despite singular solutions at linear level, applicable to similar situations."}}
{"id": "2510.01563", "pdf": "https://arxiv.org/pdf/2510.01563", "abs": "https://arxiv.org/abs/2510.01563", "authors": ["Taehee Ko", "Sungbin Lim"], "title": "Quantum advantages in ground state preparation, combinatorial optimization, and quantum state preparation", "categories": ["quant-ph", "cs.NA", "math.NA", "math.PR"], "comment": null, "summary": "We show that for any quantum Hamiltonian with an inverse-polynomial gap, the\nground state can be prepared in a polynomial circuit depth to\ninverse-polynomial precision, if the system size is sufficiently large. The\nresulting circuit is composed of a polynomial number of Pauli rotations without\nancilla qubit. Extending this result, we prove that for sufficiently large\nqubit number, any quantum state can be approximately prepared with a constant\n(polynomial) number of Pauli rotations to constant (inverse-polynomial)\nprecision. Our theoretical findings reveal exponential quantum advantages in\nthe prominent applications: ground state preparation, combinatorial\noptimization, and quantum state preparation.", "AI": {"tldr": "Ground states of quantum Hamiltonians with inverse-polynomial gaps can be prepared with polynomial-depth circuits using Pauli rotations, and any quantum state can be approximated with constant Pauli rotations for large systems.", "motivation": "To demonstrate that quantum ground state preparation and general state preparation can be achieved efficiently with simple circuits for large system sizes, revealing exponential quantum advantages.", "method": "Using polynomial-depth circuits composed of Pauli rotations without ancilla qubits to prepare ground states of Hamiltonians with inverse-polynomial gaps, and extending to approximate any quantum state with constant Pauli rotations.", "result": "Ground states can be prepared to inverse-polynomial precision with polynomial circuit depth, and any quantum state can be approximated with constant Pauli rotations to constant precision for sufficiently large qubit numbers.", "conclusion": "The findings reveal exponential quantum advantages in ground state preparation, combinatorial optimization, and quantum state preparation, showing efficient preparation methods for large quantum systems."}}
{"id": "2510.01765", "pdf": "https://arxiv.org/pdf/2510.01765", "abs": "https://arxiv.org/abs/2510.01765", "authors": ["Stefano Vita"], "title": "Notes on Schauder estimates by scaling for elliptic PDEs in divergence form", "categories": ["math.AP", "35B65, 35B44, 35B45, 35B53, 35B30, 35B08"], "comment": "28 pages", "summary": "These are the notes of a part of the PhD course Regularity for free boundary\nproblems and for elliptic PDEs, held in Pavia in the spring of 2025. The aim is\nto provide a comprehensive and self-contained treatment of classical interior\nand local Schauder estimates for second-order linear elliptic PDEs in\ndivergence form via scaling in the spirit of Simon's work. The main techniques\npresented here are geometric in nature and were primarily developed in the\nstudy of geometric problems such as minimal surfaces. The adopted approach\nrelies on compactness and blow-up arguments, combined with rigidity results\n(Liouville theorems), and shares many features with the one used in the study\nof free boundary problems, which was the main topic of the other part of the\nPhD course.", "AI": {"tldr": "PhD course notes on classical Schauder estimates for elliptic PDEs using geometric techniques from minimal surfaces and free boundary problems.", "motivation": "To provide a comprehensive treatment of interior and local Schauder estimates for second-order linear elliptic PDEs in divergence form, connecting geometric methods with classical PDE theory.", "method": "Uses scaling techniques, compactness and blow-up arguments combined with rigidity results (Liouville theorems), adopting geometric approaches from minimal surfaces and free boundary problems.", "result": "Presents a self-contained framework for deriving Schauder estimates through geometric methods that bridge PDE theory and geometric analysis.", "conclusion": "The approach demonstrates how geometric techniques developed for minimal surfaces and free boundary problems can be effectively applied to classical elliptic PDE regularity theory."}}
{"id": "2510.02051", "pdf": "https://arxiv.org/pdf/2510.02051", "abs": "https://arxiv.org/abs/2510.02051", "authors": ["Xiaowei Ou", "Tianshu Huang", "Vidvuds Ozolins"], "title": "Improving neural network performance for solving quantum sign structure", "categories": ["quant-ph", "cond-mat.str-el", "physics.comp-ph"], "comment": "8 pages, 3 figures, to be published in Physical Review B", "summary": "Neural quantum states have emerged as a widely used approach to the numerical\nstudy of the ground states of non-stoquastic Hamiltonians. However, existing\napproaches often rely on a priori knowledge of the sign structure or require a\nseparately pre-trained phase network. We introduce a modified stochastic\nreconfiguration method that effectively uses differing imaginary time steps to\nevolve the amplitude and phase. Using a larger time step for phase\noptimization, this method enables a simultaneous and efficient training of\nphase and amplitude neural networks. The efficacy of our method is demonstrated\non the Heisenberg J_1-J_2 model.", "AI": {"tldr": "A modified stochastic reconfiguration method that uses different imaginary time steps for amplitude and phase optimization, enabling simultaneous training of phase and amplitude neural networks for non-stoquastic Hamiltonians.", "motivation": "Existing neural quantum state approaches for non-stoquastic Hamiltonians often require a priori knowledge of sign structure or separate pre-training of phase networks, which limits their efficiency and applicability.", "method": "Modified stochastic reconfiguration with differing imaginary time steps - larger time step for phase optimization and smaller for amplitude - allowing simultaneous training of phase and amplitude neural networks.", "result": "The method successfully demonstrates efficacy on the Heisenberg J_1-J_2 model, showing improved training efficiency for neural quantum states.", "conclusion": "The proposed approach provides an efficient alternative to existing methods by enabling simultaneous optimization of phase and amplitude networks without requiring pre-trained phase networks or prior sign structure knowledge."}}
{"id": "2510.01568", "pdf": "https://arxiv.org/pdf/2510.01568", "abs": "https://arxiv.org/abs/2510.01568", "authors": ["Zhenbing Zeng", "Yong Huang", "Lu Yang", "Yongsheng Rao"], "title": "A Novel Algorithm for Representing Positive Semi-Definite Polynomials as Sums of Squares with Rational Coefficients", "categories": ["cs.SC", "cs.NA", "math.AG", "math.NA"], "comment": "37 pages", "summary": "This paper presents a novel algorithm for constructing a sum-of-squares (SOS)\ndecomposition for positive semi-definite polynomials with rational\ncoefficients. Unlike previous methods that typically yield SOS decompositions\nwith floating-point coefficients, our approach ensures that all coefficients in\nthe decomposition remain rational. This is particularly useful in formal\nverification and symbolic computation, where exact arithmetic is required. We\nintroduce a stepwise reduction technique that transforms a given polynomial\ninto a sum of ladder-like squares while preserving rationality. Experimental\nresults demonstrate the effectiveness of our method compared to existing\nnumerical approaches. This artical is an extension of the following Chinnese\npaper: HUANG Yong , ZENG Zhenbing , YANG Lu , RAO Yongsheng. An Algorithm to\nRepresent Positive Semi-Definite Polynomials to Sum of Lader-Like Squares of\nPolynomials with Rational Coefficients (in Chinese). Journal of Systems Science\nand Mathematical Sciences, 2024, 44(5): 1241-1271\nhttps://doi.org/10.12341/jssms23584CM", "AI": {"tldr": "Novel algorithm for constructing sum-of-squares decomposition with rational coefficients for positive semi-definite polynomials, ensuring exact arithmetic for formal verification.", "motivation": "Existing methods produce SOS decompositions with floating-point coefficients, which are problematic for formal verification and symbolic computation where exact arithmetic is required.", "method": "Stepwise reduction technique that transforms polynomials into sum of ladder-like squares while preserving rationality of coefficients.", "result": "Experimental results show effectiveness compared to existing numerical approaches, providing exact rational coefficient decompositions.", "conclusion": "The method successfully generates SOS decompositions with rational coefficients, addressing limitations of numerical approaches in exact computation contexts."}}
{"id": "2510.01779", "pdf": "https://arxiv.org/pdf/2510.01779", "abs": "https://arxiv.org/abs/2510.01779", "authors": ["Oana Ivanovici"], "title": "Strichartz and dispersive estimates for quantum bouncing ball model: exponential sums and Van der Corput methods in 1d semi-classical Schr\u00f6dinger equations", "categories": ["math.AP", "math.NT"], "comment": null, "summary": "We analyze the one-dimensional semi-classical Schr\\\"odinger equation on the\nhalf-line with a linear potential and Dirichlet boundary conditions. Our main\nfocus is on establishing improved dispersive and Strichartz estimates for this\nmodel, which govern the space-time behavior of solutions. We prove refined\nStrichartz bounds using Van der Corput-type derivative tests, beating previous\nknown results where Strichartz estimates incur 1/4 losses. Moreover, assuming\nsharp bounds for certain exponential sums, our results indicate the possibility\nto reduce these losses further to $1/6 + \\epsilon$ for all $\\epsilon>0$, which\nwould be sharp. We further expect that analogous Strichartz bounds should hold\nwithin the Friedlander model domain in higher dimensions.", "AI": {"tldr": "Improved dispersive and Strichartz estimates for 1D semi-classical Schr\u00f6dinger equation with linear potential on half-line, reducing losses from 1/4 to potentially 1/6+\u03b5.", "motivation": "To establish better space-time behavior understanding of solutions to the semi-classical Schr\u00f6dinger equation with linear potential and Dirichlet boundary conditions, improving upon previous suboptimal estimates.", "method": "Using Van der Corput-type derivative tests to prove refined Strichartz bounds, and analyzing exponential sums to potentially achieve sharper estimates.", "result": "Proved improved Strichartz estimates that beat previous 1/4 losses, with potential to reduce losses to 1/6+\u03b5 for all \u03b5>0 under sharp exponential sum bounds.", "conclusion": "The refined Strichartz bounds represent significant improvement, and analogous results are expected to hold in higher dimensions within the Friedlander model domain."}}
{"id": "2510.01755", "pdf": "https://arxiv.org/pdf/2510.01755", "abs": "https://arxiv.org/abs/2510.01755", "authors": ["Johannes Hertrich", "Hok Shing Wong", "Alexander Denker", "Stanislas Ducotterd", "Zhenghan Fang", "Markus Haltmeier", "\u017deljko Kereta", "Erich Kobler", "Oscar Leong", "Mohammad Sadegh Salehi", "Carola-Bibiane Sch\u00f6nlieb", "Johannes Schwab", "Zakhar Shumaylov", "Jeremias Sulam", "German Sh\u00e2ma Wache", "Martin Zach", "Yasi Zhang", "Matthias J. Ehrhardt", "Sebastian Neumayer"], "title": "Learning Regularization Functionals for Inverse Problems: A Comparative Study", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC"], "comment": null, "summary": "In recent years, a variety of learned regularization frameworks for solving\ninverse problems in imaging have emerged. These offer flexible modeling\ntogether with mathematical insights. The proposed methods differ in their\narchitectural design and training strategies, making direct comparison\nchallenging due to non-modular implementations. We address this gap by\ncollecting and unifying the available code into a common framework. This\nunified view allows us to systematically compare the approaches and highlight\ntheir strengths and limitations, providing valuable insights into their future\npotential. We also provide concise descriptions of each method, complemented by\npractical guidelines.", "AI": {"tldr": "The paper presents a unified framework for comparing learned regularization methods in imaging inverse problems, addressing implementation disparities and providing systematic analysis.", "motivation": "To overcome challenges in comparing different learned regularization methods due to their varied architectural designs and non-modular implementations.", "method": "Collecting and unifying available code into a common framework to enable systematic comparison of different approaches.", "result": "The unified framework allows systematic comparison of methods, highlighting their strengths and limitations, and provides practical guidelines.", "conclusion": "The unified approach offers valuable insights into the future potential of learned regularization methods for imaging inverse problems."}}
{"id": "2510.01865", "pdf": "https://arxiv.org/pdf/2510.01865", "abs": "https://arxiv.org/abs/2510.01865", "authors": ["Berardino Sciunzi", "Domenico Vuono"], "title": "Monotonicity and Liouville-type theorems for semilinear elliptic problems in the half space", "categories": ["math.AP", "35B06, 35B51, 35J61"], "comment": null, "summary": "We consider classical solutions to $-\\Delta u = f(u)$ in half-spaces, under\nhomogeneous Dirichlet boundary conditions. We prove that any positive solution\nis strictly monotone increasing in the direction orthogonal to the boundary,\nprovided that it is directionally bounded on finite strips. As a corollary, we\ndeduce a new Liouville-type theorem for the Lane-Emden equation.", "AI": {"tldr": "Positive solutions to -\u0394u = f(u) in half-spaces with Dirichlet boundary conditions are strictly monotone increasing in the direction orthogonal to the boundary when directionally bounded on finite strips.", "motivation": "To establish monotonicity properties of solutions to semilinear elliptic equations in half-spaces and derive new Liouville-type theorems.", "method": "Analysis of classical solutions to -\u0394u = f(u) in half-spaces under homogeneous Dirichlet boundary conditions, with the key assumption of directional boundedness on finite strips.", "result": "Proved that any positive solution is strictly monotone increasing in the direction orthogonal to the boundary. Derived a new Liouville-type theorem for the Lane-Emden equation as a corollary.", "conclusion": "The paper establishes strong monotonicity results for semilinear elliptic equations in half-spaces and provides new Liouville-type theorems, advancing the understanding of solution behavior in unbounded domains."}}
{"id": "2510.01788", "pdf": "https://arxiv.org/pdf/2510.01788", "abs": "https://arxiv.org/abs/2510.01788", "authors": ["Cl\u00e9mentine Court\u00e8s", "Emmanuel Franck", "Michael Kraus", "Laurent Navoret", "L\u00e9opold Tr\u00e9mant"], "title": "Neural non-canonical Hamiltonian dynamics for long-time simulations", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "This work focuses on learning non-canonical Hamiltonian dynamics from data,\nwhere long-term predictions require the preservation of structure both in the\nlearned model and in numerical schemes. Previous research focused on either\nfacet, respectively with a potential-based architecture and with degenerate\nvariational integrators, but new issues arise when combining both. In\nexperiments, the learnt model is sometimes numerically unstable due to the\ngauge dependency of the scheme, rendering long-time simulations impossible. In\nthis paper, we identify this problem and propose two different training\nstrategies to address it, either by directly learning the vector field or by\nlearning a time-discrete dynamics through the scheme. Several numerical test\ncases assess the ability of the methods to learn complex physical dynamics,\nlike the guiding center from gyrokinetic plasma physics.", "AI": {"tldr": "This paper addresses numerical instability in learning non-canonical Hamiltonian dynamics by proposing two training strategies that overcome gauge dependency issues in combined potential-based architectures and degenerate variational integrators.", "motivation": "Previous research on learning non-canonical Hamiltonian dynamics focused separately on potential-based architectures and degenerate variational integrators, but combining both creates numerical instability due to gauge dependency, making long-term simulations impossible.", "method": "Two training strategies: 1) directly learning the vector field, or 2) learning time-discrete dynamics through the numerical scheme itself.", "result": "The methods successfully learn complex physical dynamics, including the guiding center from gyrokinetic plasma physics, as demonstrated through several numerical test cases.", "conclusion": "The proposed training strategies effectively address the numerical instability problem caused by gauge dependency, enabling stable long-term simulations of learned non-canonical Hamiltonian dynamics."}}
{"id": "2510.01886", "pdf": "https://arxiv.org/pdf/2510.01886", "abs": "https://arxiv.org/abs/2510.01886", "authors": ["Baoping Liu", "Xu Zheng"], "title": "On sharp Strichartz estimate for hyperbolic Schr\u00f6dinger equation on $\\mathbb{T}^3$", "categories": ["math.AP", "math.CA", "35Q55"], "comment": "22 pages, 3 figures", "summary": "We prove the sharp Strichartz estimate for hyperbolic Schr\\\"{o}dinger\nequation on $\\mathbb{T}^3 $ via an incidence geometry approach. As application,\nwe obtain optimal local well-posedness of nonlinear hyperbolic Schr\\\"{o}dinger\nequations.", "AI": {"tldr": "Sharp Strichartz estimate for hyperbolic Schr\u00f6dinger equation on 3D torus via incidence geometry, leading to optimal local well-posedness for nonlinear versions.", "motivation": "To establish precise mathematical bounds for hyperbolic Schr\u00f6dinger equations on three-dimensional torus domains, which are fundamental in understanding wave propagation and quantum mechanics in periodic settings.", "method": "Uses incidence geometry approach to prove sharp Strichartz estimates for hyperbolic Schr\u00f6dinger equation on \ud835\udd4b\u00b3.", "result": "Successfully proved the sharp Strichartz estimate for hyperbolic Schr\u00f6dinger equation on three-dimensional torus.", "conclusion": "The sharp estimates enable optimal local well-posedness results for nonlinear hyperbolic Schr\u00f6dinger equations, advancing the mathematical theory of these important PDEs."}}
{"id": "2510.02151", "pdf": "https://arxiv.org/pdf/2510.02151", "abs": "https://arxiv.org/abs/2510.02151", "authors": ["Eunou Lee"], "title": "A quantum analogue of convex optimization", "categories": ["quant-ph", "cs.NA", "math.NA"], "comment": "57 pages, submitted to QIP", "summary": "Convex optimization is the powerhouse behind the theory and practice of\noptimization. We introduce a quantum analogue of unconstrained convex\noptimization: computing the minimum eigenvalue of a Schr\\\"odinger operator $h =\n-\\Delta + V $ with convex potential $V:\\mathbb R^n \\rightarrow \\mathbb R_{\\ge\n0}$ such that $V(x)\\rightarrow\\infty $ as $\\|x\\|\\rightarrow\\infty$. For this\nproblem, we present an efficient quantum algorithm, called the Fundamental Gap\nAlgorithm (FGA), that computes the minimum eigenvalue of $h$ up to error\n$\\epsilon$ in polynomial time in $n$, $1/\\epsilon$, and parameters that depend\non $V$. Adiabatic evolution of the ground state is used as a key subroutine,\nwhich we analyze with novel techniques that allow us to focus on the low-energy\nspace. We apply the FGA to give the first known polynomial-time algorithm for\nfinding the lowest frequency of an $n$-dimensional convex drum, or\nmathematically, the minimum eigenvalue of the Dirichlet Laplacian on an\n$n$-dimensional region that is defined by $m$ linear constraints in polynomial\ntime in $n$, $m$, $1/\\epsilon$ and the radius $R$ of a ball encompassing the\nregion.", "AI": {"tldr": "A quantum algorithm called Fundamental Gap Algorithm (FGA) efficiently computes the minimum eigenvalue of Schr\u00f6dinger operators with convex potentials, achieving polynomial time complexity in dimension and accuracy.", "motivation": "To develop quantum analogues of classical convex optimization problems, specifically computing minimum eigenvalues of Schr\u00f6dinger operators with convex potentials that grow at infinity.", "method": "Uses adiabatic evolution of the ground state as a key subroutine, with novel techniques to focus on low-energy space. The FGA computes minimum eigenvalues up to error \u03b5 in polynomial time.", "result": "The algorithm achieves polynomial time complexity in dimension n, accuracy 1/\u03b5, and parameters depending on the potential V. Successfully applied to find lowest frequencies of n-dimensional convex drums.", "conclusion": "FGA provides the first polynomial-time quantum algorithm for computing minimum eigenvalues of Dirichlet Laplacians on convex regions defined by linear constraints, with applications in quantum optimization."}}
{"id": "2510.01893", "pdf": "https://arxiv.org/pdf/2510.01893", "abs": "https://arxiv.org/abs/2510.01893", "authors": ["Jakob Deutsch"], "title": "A note on the recovery sequence in the double gradient model for phase transitions", "categories": ["math.AP", "Primary: 49J45, Secondary: 35Q74, 49Q20, 74N99"], "comment": "28 pages, 2 figures", "summary": "We investigate the $\\limsup$ inequality in the double gradient model for\nphase transitions governed by a Modica--Mortola functional with a double-well\npotential in two dimensions. Specifically, we consider energy functionals of\nthe form \\[ E_\\varepsilon(u, \\Omega) = \\int_\\Omega \\left( \\frac{1}{\\varepsilon}\nW(\\nabla u) + \\varepsilon |\\nabla^2 u|^2 \\right) dx \\] for maps $ u \\in\nH^2(\\Omega; \\mathbb{R}^2) $, where $ W $ vanishes only at two wells. Assuming a\nbound on the optimal profile constant -- namely the cell problem on the unit\ncube -- in terms of the geodesic distance between the two wells, we\ncharacterise the limiting interfacial energy via periodic recovery sequences as\n$\\varepsilon \\to 0^+$.", "AI": {"tldr": "Analysis of the limsup inequality in the double gradient model for phase transitions using Modica-Mortola functionals with double-well potentials in 2D.", "motivation": "To characterize the limiting interfacial energy in phase transition models governed by double-well potentials and understand the behavior as the regularization parameter approaches zero.", "method": "Using energy functionals with double-well potentials and second-order gradients, analyzing recovery sequences and cell problems on unit cubes with bounds on optimal profile constants.", "result": "Successfully characterized the limiting interfacial energy through periodic recovery sequences as the regularization parameter \u03b5 approaches zero.", "conclusion": "The study provides a complete characterization of the interfacial energy limit in the double gradient phase transition model under the given assumptions."}}
{"id": "2510.02207", "pdf": "https://arxiv.org/pdf/2510.02207", "abs": "https://arxiv.org/abs/2510.02207", "authors": ["Adam Doliwa"], "title": "Non-commutative multiple bi-orthogonal polynomials: formal approach and integrability", "categories": ["nlin.SI", "cs.NA", "math-ph", "math.MP", "math.NA"], "comment": "16 pages", "summary": "We define the non-commutative multiple bi-orthogonal polynomial systems,\nwhich simultaneously generalize the concepts of multiple orthogonality, matrix\northogonal polynomials and of the bi-orthogonality. We present\nquasideterminantal expressions for such polynomial systems in terms of formal\nbi-moments. The normalization functions for such monic polynomials satisfy the\nnon-commutative Hirota equations, while the polynomials provide solution of the\ncorresponding linear system. This shows, in particular, that our polynomial\nsystems form a part of the theory of integrable systems. We study also a\nspecialization of the problem to non-commutative multiple orthogonal\npolynomials, what results in the corresponding Hankel-type quasideterminantal\nexpressions in terms of the moments. Moreover, such a reduction allows to\nintroduce in a standard way the discrete-time variable and gives rise to an\nintegrable system which is non-commutative version of the multidimensional\ndiscrete-time Toda equations.", "AI": {"tldr": "The paper introduces non-commutative multiple bi-orthogonal polynomial systems, which generalize multiple orthogonality, matrix orthogonal polynomials, and bi-orthogonality, and shows their connections to integrable systems.", "motivation": "To generalize concepts of multiple orthogonality, matrix orthogonal polynomials, and bi-orthogonality into a unified non-commutative framework and explore their connections to integrable systems theory.", "method": "Defines non-commutative multiple bi-orthogonal polynomial systems, presents quasideterminantal expressions using formal bi-moments, and studies normalization functions satisfying non-commutative Hirota equations.", "result": "The polynomial systems satisfy non-commutative Hirota equations and provide solutions to corresponding linear systems, establishing their role in integrable systems theory. Specialization to non-commutative multiple orthogonal polynomials yields Hankel-type quasideterminantal expressions.", "conclusion": "The introduced polynomial systems form part of integrable systems theory, with specialization leading to non-commutative versions of multidimensional discrete-time Toda equations."}}
{"id": "2510.01911", "pdf": "https://arxiv.org/pdf/2510.01911", "abs": "https://arxiv.org/abs/2510.01911", "authors": ["Yuanchun Ren", "Yixian Gao"], "title": "Subwavelength resonances in two-dimensional elastic media with high contrast", "categories": ["math.AP"], "comment": "23 pages", "summary": "This paper employs layer potential techniques to investigate wave scattering\nin two-dimensional elastic media exhibiting high contrasts in both Lam\\'{e}\nparameters and density. Our contributions are fourfold. First, we construct an\ninvertible operator based on the kernel spaces of boundary integral operators,\nwhich enables the characterization of resonant frequencies through an\northogonality condition. Second, we use asymptotic analysis to derive the\nequation governing the leading-order terms of these resonant frequencies.\nThird, we analyze the scattered field in the interior domain for incident\nfrequencies across different regimes and characterize the longitudinal and\ntransverse far-field patterns in the exterior domain. Finally, we examine the\nsubwavelength bandgap in the phononic crystal with a dilute structure.", "AI": {"tldr": "This paper uses layer potential techniques to study wave scattering in 2D elastic media with high parameter contrasts, characterizing resonant frequencies, analyzing scattered fields, and examining subwavelength bandgaps in phononic crystals.", "motivation": "To investigate wave scattering phenomena in two-dimensional elastic media that exhibit significant contrasts in both Lam\u00e9 parameters and density, which is relevant for understanding wave propagation in heterogeneous materials.", "method": "Employed layer potential techniques and boundary integral operators, constructed an invertible operator based on kernel spaces, used asymptotic analysis to derive resonant frequency equations, and analyzed scattered fields across different frequency regimes.", "result": "Developed characterization of resonant frequencies through orthogonality conditions, derived equations for leading-order resonant frequencies, analyzed interior scattered fields and exterior far-field patterns, and examined subwavelength bandgaps in dilute phononic crystals.", "conclusion": "The study provides comprehensive analytical tools for understanding wave scattering in high-contrast elastic media, with applications to phononic crystals and metamaterials design."}}
{"id": "2510.02112", "pdf": "https://arxiv.org/pdf/2510.02112", "abs": "https://arxiv.org/abs/2510.02112", "authors": ["In-Jee Jeong", "Sangwook Tae"], "title": "Low regularity Sobolev well-posedness for Vlasov--Poisson", "categories": ["math.AP"], "comment": "17 pages", "summary": "We consider the Vlasov--Poisson equation on $\\mathbb{R}^n \\times\n\\mathbb{R}^n$ with $n \\ge 3$. We prove local well-posedness in\n$H^{s}(\\mathbb{R}^n \\times \\mathbb{R}^n)$ with $s> n/2-1/4$, for initial\ndistribution $f_{0} \\in H^{s}(\\mathbb{R}^n \\times \\mathbb{R}^n)$ having compact\nsupport in $v$. In particular, data not belonging to $L^p(\\mathbb{R}^n \\times\n\\mathbb{R}^n)$ for large $p$ are allowed.", "AI": {"tldr": "Local well-posedness of Vlasov-Poisson equation in H^s spaces with s > n/2 - 1/4 for n \u2265 3, allowing data not in L^p for large p.", "motivation": "To establish local well-posedness for the Vlasov-Poisson equation in higher-dimensional settings with lower regularity requirements than previously known, particularly allowing initial distributions that don't belong to L^p spaces for large p.", "method": "Analysis of the Vlasov-Poisson equation on R^n \u00d7 R^n using Sobolev space techniques, specifically working in H^s spaces with compact support in velocity variable v.", "result": "Proved local well-posedness in H^s(R^n \u00d7 R^n) with s > n/2 - 1/4 for n \u2265 3, for initial distributions f_0 \u2208 H^s with compact support in v.", "conclusion": "The Vlasov-Poisson equation is locally well-posed in lower regularity Sobolev spaces than previously established, expanding the class of admissible initial data."}}
{"id": "2510.02242", "pdf": "https://arxiv.org/pdf/2510.02242", "abs": "https://arxiv.org/abs/2510.02242", "authors": ["Hendrik Baers", "Angkana R\u00fcland"], "title": "Transfer of Stability from the Classical to the Fractional Anisotropic Calder\u00f3n Problem", "categories": ["math.AP"], "comment": "54 pages, 4 figures, comments welcome", "summary": "We discuss two spectral fractional anisotropic Calder\\'on problems with\nsource-to-solution measurements and their quantitative relation to the\nclassical Calder\\'on problem. Firstly, we consider the anistropic fractional\nCalder\\'on problem from [FGKU25]. In this setting, we quantify the relation\nbetween the local and nonlocal Calder\\'on problems which had been deduced in\n[R25] and provide an associated stability estimate. As a consequence, any\nstability result which holds on the level of the local problem with\nsource-to-solution data has a direct nonlocal analogue (up to a logarithmic\nloss). Secondly, we introduce and discuss the fractional Calder\\'on problem\nwith source-to-solution measurements for the spectral fractional Dirichlet\nLaplacian on open, bounded, connected, Lipschitz sets on $\\mathbb{R}^n$. Also\nin this context, we provide a qualitative and quantitative transfer of\nuniqueness from the local to the nonlocal setting. As a consequence, we infer\nthe first stability results for the principal part for a fractional Calder\\'on\ntype problem for which no reduction of Liouville type is known. Our arguments\nrely on quantitative unique continuation arguments. As a result of independent\ninterest, we also prove a quantitative relation between source-to-solution and\nDirichlet-to-Neumann measurements for the classical Calder\\'on problem.", "AI": {"tldr": "This paper analyzes spectral fractional anisotropic Calder\u00f3n problems with source-to-solution measurements and establishes quantitative relationships between local and nonlocal Calder\u00f3n problems, providing stability estimates and uniqueness transfers.", "motivation": "To bridge the gap between local and nonlocal Calder\u00f3n problems by quantifying their relationships and establishing stability results for fractional Calder\u00f3n type problems where no Liouville-type reduction is known.", "method": "Uses quantitative unique continuation arguments to relate local and nonlocal Calder\u00f3n problems, and proves quantitative relations between source-to-solution and Dirichlet-to-Neumann measurements for classical Calder\u00f3n problems.", "result": "Established that any stability result for the local problem with source-to-solution data has a direct nonlocal analogue (with logarithmic loss), and obtained first stability results for the principal part of fractional Calder\u00f3n problems without known Liouville-type reductions.", "conclusion": "The paper successfully quantifies the relationship between local and nonlocal Calder\u00f3n problems, provides stability estimates, and demonstrates that uniqueness properties can be transferred from local to nonlocal settings using quantitative unique continuation techniques."}}
{"id": "2510.01352", "pdf": "https://arxiv.org/pdf/2510.01352", "abs": "https://arxiv.org/abs/2510.01352", "authors": ["Gordon Blower", "Simon J. A. Malham"], "title": "The noncommutative KP hierarchy and its solution via descent algebra", "categories": ["nlin.SI", "math-ph", "math.AP", "math.MP"], "comment": "38 pages, two-column format", "summary": "We give the solution to the complete noncommutative Kadomtsev--Petviashvili\n(KP) hierarchy. We achieve this via direct linearisation which involves the\nGelfand--Levitan--Marchenko (GLM) equation. This is a linear integral equation\nin which the scattering data satisfies the linearised KP hierarchy. The\nsolution to the GLM equation is then shown to coincide with the solution to the\nnoncommutative KP hierarchy. We achieve this using two approaches. In the first\napproach we use the standard Sato-Wilson dressing transformation. In the second\napproach, which was pioneered by Poppe, we assume the scattering data is\nsemi-additive and by direct substitution, we show that the solution to the GLM\nequation satisfies the infinite set of field equations representing the\nnoncommutative KP hierarchy. This approach relies on the augmented pre-Poppe\nalgebra. This is a representative algebra that underlies the field equations\nrepresenting the hierarchy. It is nonassociative and isomorphic to a descent\nalgebra equipped with a grafting product. While we perform computations in the\nnonassociative descent algebra, the final result which establishes the solution\nto the complete hierarchy, resides in the natural associative subalgebra. The\nadvantages of this second approach are that it is constructive, explicit,\nhighlights the underlying combinatorial structures within the hierarchy, and\nreveals the mechanisms underlying the solution procedure.", "AI": {"tldr": "The paper provides a complete solution to the noncommutative KP hierarchy using direct linearisation via the GLM equation, with two approaches: Sato-Wilson dressing transformation and Poppe's semi-additive scattering data method.", "motivation": "To solve the complete noncommutative Kadomtsev-Petviashvili (KP) hierarchy, which is an important integrable system in mathematical physics.", "method": "Uses direct linearisation through the Gelfand-Levitan-Marchenko (GLM) equation with two approaches: (1) standard Sato-Wilson dressing transformation, (2) Poppe's approach using semi-additive scattering data and augmented pre-Poppe algebra (nonassociative descent algebra).", "result": "Shows that the solution to the GLM equation coincides with the solution to the noncommutative KP hierarchy, establishing the complete solution to the hierarchy.", "conclusion": "The second approach using Poppe's method is constructive, explicit, reveals combinatorial structures, and shows the solution mechanism, with final results residing in the natural associative subalgebra."}}
{"id": "2510.01355", "pdf": "https://arxiv.org/pdf/2510.01355", "abs": "https://arxiv.org/abs/2510.01355", "authors": ["Robert Haslhofer"], "title": "Mean curvature flow through singularities", "categories": ["math.DG", "math.AP"], "comment": "submitted to the Proceedings of the ICM 2026", "summary": "We first give a general introduction to the mean curvature flow, and then\ndiscuss fundamental results established over the last 10 years that yield a\nprecise theory for the flow through singularities in $\\mathbb{R}^3$. With the\naim of developing a satisfying theory in higher dimensions, we then describe\nour recent classification of all noncollapsed singularities in $\\mathbb{R}^4$.\nFinally, we provide a detailed discussion of open problems and conjectures.", "AI": {"tldr": "This paper provides an overview of mean curvature flow, recent advances in singularity theory in R\u00b3, classification of noncollapsed singularities in R\u2074, and discusses open problems.", "motivation": "To develop a comprehensive theory for mean curvature flow through singularities, extending beyond R\u00b3 to higher dimensions like R\u2074.", "method": "General introduction to mean curvature flow, analysis of fundamental results from the last decade in R\u00b3, classification of noncollapsed singularities in R\u2074, and discussion of open problems.", "result": "Established a precise theory for mean curvature flow through singularities in R\u00b3 and provided classification of all noncollapsed singularities in R\u2074.", "conclusion": "The paper advances the understanding of mean curvature flow singularities and identifies key open problems for future research in higher dimensions."}}
{"id": "2510.01936", "pdf": "https://arxiv.org/pdf/2510.01936", "abs": "https://arxiv.org/abs/2510.01936", "authors": ["Panu Lahti", "Julian Weigt"], "title": "The centered maximal operator removes the non-concave Cantor part from the gradient", "categories": ["math.CA", "math.AP", "42B25, 26B30"], "comment": null, "summary": "We study regularity of the centered Hardy--Littlewood maximal function $M f$\nof a function $f$ of bounded variation in $\\mathbb R^d$, $d\\in \\mathbb N$. In\nparticular, we show that at $|D^c f|$-a.e. point $x$ where $f$ has a\nnon-concave blow-up, it holds that $M f(x)>f^*(x)$. We further deduce from this\nthat if the variation measure of $f$ has no jump part and its Cantor part has\nnon-concave blow-ups, then BV regularity of $M f$ can be upgraded to Sobolev\nregularity.", "AI": {"tldr": "The paper studies the regularity of the centered Hardy-Littlewood maximal function for functions of bounded variation in R^d, showing conditions under which BV regularity can be upgraded to Sobolev regularity.", "motivation": "To understand the regularity properties of the Hardy-Littlewood maximal function for functions of bounded variation, particularly when BV regularity can be improved to Sobolev regularity.", "method": "Analyze the behavior of the maximal function at points where the function has non-concave blow-ups, and study conditions on the variation measure.", "result": "At |D^c f|-a.e. point where f has a non-concave blow-up, M f(x) > f*(x). If the variation measure has no jump part and its Cantor part has non-concave blow-ups, then BV regularity of M f implies Sobolev regularity.", "conclusion": "The presence of non-concave blow-ups in the Cantor part of the variation measure (without jump part) enables the upgrade from BV to Sobolev regularity for the Hardy-Littlewood maximal function."}}
{"id": "2510.01964", "pdf": "https://arxiv.org/pdf/2510.01964", "abs": "https://arxiv.org/abs/2510.01964", "authors": ["Andrea N\u00fctzi"], "title": "Perturbations of Minkowski spacetime with regular conformal compactification", "categories": ["gr-qc", "math.AP"], "comment": null, "summary": "We construct perturbations of Minkowski spacetime in general relativity, when\ngiven initial data that decays inverse polynomially to initial data of a Kerr\nspacetime towards spacelike infinity. We show that the perturbations admit a\nregular conformal compactification at null and timelike infinity, where the\ndegree of regularity increases linearly with the rate of decay of the initial\ndata to Kerr initial data. In particular, the compactification is smooth if the\ninitial data decays rapidly to Kerr initial data. This generalizes results of\nFriedrich, who constructed spacetimes with a smooth conformal compactification\nin the case when the initial data is identical to Kerr initial data on the\ncomplement of a compact set. Our results rely on a novel formulation of the\nEinstein equations about Minkowski spacetime introduced by the author, that\nallows one to formulate the dynamic problem as a quasilinear, symmetric\nhyperbolic PDE that is regular at null infinity and with null infinity being at\na fixed locus. It is not regular at spacelike infinity, due to the asymptotics\nof Kerr. Thus the main technical task is the construction of solutions near\nspacelike infinity, using tailored energy estimates. To accomplish this, we\norganize the equations according to homogeneity with respect to scaling about\nspacelike infinity, which identifies terms that are leading, respectively lower\norder, near spacelike infinity, with contributions from Kerr being lower order.", "AI": {"tldr": "The paper constructs perturbations of Minkowski spacetime with initial data decaying to Kerr initial data, showing they admit regular conformal compactification at null and timelike infinity with regularity increasing with decay rate.", "motivation": "To generalize Friedrich's results on smooth conformal compactification by allowing initial data that decays to Kerr initial data rather than being identical to Kerr outside compact sets.", "method": "Uses a novel formulation of Einstein equations about Minkowski spacetime as quasilinear symmetric hyperbolic PDE regular at null infinity, with tailored energy estimates near spacelike infinity organized by scaling homogeneity.", "result": "Perturbations admit regular conformal compactification where regularity increases linearly with initial data decay rate to Kerr, with smooth compactification for rapidly decaying data.", "conclusion": "Successfully generalized Friedrich's results using a new formulation of Einstein equations and scaling-based analysis near spacelike infinity, handling Kerr asymptotics as lower-order contributions."}}
{"id": "2510.02192", "pdf": "https://arxiv.org/pdf/2510.02192", "abs": "https://arxiv.org/abs/2510.02192", "authors": ["Sabine B\u00f6gli", "Sukrid Petpradittha", "Franti\u0161ek \u0160tampach"], "title": "On Lieb-Thirring inequalities for multidimensional Schr\u00f6dinger operators with complex potentials", "categories": ["math.SP", "math-ph", "math.AP", "math.MP", "35P15, 47A10, 47A75, 81Q12"], "comment": "24 pages", "summary": "We solve the open problem by Demuth, Hansmann, and Katriel announced in\n[Integr. Equ. Oper. Theory 75 (2013), 1-5] by a counter-example construction.\nThe problem concerns a possible generalisation of the Lieb-Thirring inequality\nfor Schr\\\"odinger operators in to the case of complex-valued potentials. A\ncounter-example has already been found for the one-dimensional case by the\nfirst and third authors in [J. Spectr. Theory 11 (2021), 1391-1413]. Here we\ngeneralise the counter-example to higher dimensions.", "AI": {"tldr": "Counter-example construction disproves generalization of Lieb-Thirring inequality for complex-valued potentials in higher dimensions.", "motivation": "To solve the open problem by Demuth, Hansmann, and Katriel regarding generalization of Lieb-Thirring inequality to complex-valued potentials.", "method": "Counter-example construction, generalizing the one-dimensional counter-example to higher dimensions.", "result": "Successfully constructed counter-example showing the inequality does not hold for complex-valued potentials in higher dimensions.", "conclusion": "The Lieb-Thirring inequality cannot be generalized to complex-valued potentials in higher dimensions."}}
{"id": "2510.02288", "pdf": "https://arxiv.org/pdf/2510.02288", "abs": "https://arxiv.org/abs/2510.02288", "authors": ["Sabine B\u00f6gli", "Sukrid Petpradittha"], "title": "Optimal Lieb-Thirring type inequalities for Schr\u00f6dinger and Jacobi operators with complex potentials", "categories": ["math.SP", "math-ph", "math.AP", "math.MP", "47B36, 34L40, 47A10, 47A75"], "comment": "28 pages", "summary": "We prove optimal Lieb-Thirring type inequalities for Schr\\\"odinger and Jacobi\noperators with complex potentials. Our results bound eigenvalue power sums\n(Riesz means) by the $L^p$ norm of the potential, where in contrast to the\nself-adjoint case, each term needs to be weighted by a function of the ratio of\nthe distance of the eigenvalue to the essential spectrum and the distance to\nthe endpoint(s) thereof. Our Lieb-Thirring type bounds only hold for integrable\nweight functions. To prove optimality, we establish divergence estimates for\nnon-integrable weight functions. The divergence rates exhibit a logarithmic or\neven polynomial gain compared to semiclassical methods (Weyl asymptotics) for\nreal potentials.", "AI": {"tldr": "Optimal Lieb-Thirring inequalities for Schr\u00f6dinger and Jacobi operators with complex potentials, bounding eigenvalue power sums by L^p norms with essential spectrum-dependent weights.", "motivation": "To extend Lieb-Thirring inequalities from self-adjoint to complex potential operators, addressing the need for different weighting due to complex eigenvalues and their relationship to the essential spectrum.", "method": "Prove optimal bounds for eigenvalue power sums weighted by functions of the distance to essential spectrum endpoints, and establish divergence estimates for non-integrable weights to demonstrate optimality.", "result": "Achieved optimal Lieb-Thirring type inequalities that hold only for integrable weight functions, with divergence rates showing logarithmic/polynomial improvements over semiclassical methods for real potentials.", "conclusion": "Complex potentials require essential spectrum-dependent weighting in Lieb-Thirring inequalities, and the established bounds are optimal with improved divergence behavior compared to real potential cases."}}
{"id": "2510.02299", "pdf": "https://arxiv.org/pdf/2510.02299", "abs": "https://arxiv.org/abs/2510.02299", "authors": ["Bryan Dimler", "Chen-Kuan Lee"], "title": "Uniqueness in the Plateau problem for calibrated currents", "categories": ["math.DG", "math.AP"], "comment": null, "summary": "We show that every compactly supported calibrated integral current with\nconnected $C^{3,\\alpha}$ boundary is the unique solution to the oriented\nPlateau problem for its boundary data. This is proved as a consequence of the\nboundary regularity theory for area-minimizing currents and classical unique\ncontinuation principles adapted to the minimal surface system.", "AI": {"tldr": "Compactly supported calibrated integral currents with connected C\u00b3,\u03b1 boundary are unique solutions to the oriented Plateau problem for their boundary data.", "motivation": "To establish uniqueness of solutions to the oriented Plateau problem for certain classes of calibrated integral currents with regular boundaries.", "method": "Combines boundary regularity theory for area-minimizing currents with classical unique continuation principles adapted to the minimal surface system.", "result": "Proves that such currents are unique solutions to the oriented Plateau problem for their boundary data.", "conclusion": "The paper establishes a uniqueness result for the oriented Plateau problem under specific regularity conditions on the boundary."}}
