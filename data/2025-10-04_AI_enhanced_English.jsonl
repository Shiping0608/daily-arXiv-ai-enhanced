{"id": "2510.01205", "pdf": "https://arxiv.org/pdf/2510.01205", "abs": "https://arxiv.org/abs/2510.01205", "authors": ["Nicholas Bauman", "Ajay Panyala", "Libor Veis", "Jiri Brabec", "Paul Rigor", "Randy Meyer", "Skyler Windh", "Craig Warner", "Tony Brewer", "Karol Kowalski"], "title": "Integrated Software/Hardware Execution Models for High-Accuracy Methods in Chemistry", "categories": ["physics.comp-ph", "physics.chem-ph", "quant-ph"], "comment": null, "summary": "The effective deployment and application of advanced methodologies for\nquantum chemistry is inherently linked to the optimal usage of emerging and\nhighly diversified computational resources. This paper examines the synergistic\nutilization of Micron memory technologies and Azure Quantum Element cloud\ncomputing in Density Matrix Renormalization Group (DMRG) simulations leveraging\ncoupled-cluster (CC) downfolded/effective Hamiltonians based on the double\nunitary coupled cluster (DUCC) Ansatz. We analyze the performance of the\nDMRG-DUCC workflow, emphasizing the proper choice of hardware that reflects the\nnumerical overheads associated with specific components of the workflow. We\nreport a hybrid approach that takes advantage of Micron CXL hardware for the\nmemory capacity intensive CC downfolding phase while employing AQE cloud\ncomputing for the less resource-intensive DMRG simulations. Furthermore, we\nanalyze the performance of the scalable ExaChem suite of electronic simulations\nconducted on Micron prototype systems.", "AI": {"tldr": "This paper presents a hybrid approach combining Micron CXL memory hardware for CC downfolding and Azure Quantum Element cloud computing for DMRG simulations in quantum chemistry workflows.", "motivation": "To optimize quantum chemistry simulations by effectively utilizing emerging computational resources, particularly addressing the memory-intensive nature of coupled-cluster downfolding phases.", "method": "Synergistic utilization of Micron memory technologies and Azure Quantum Element cloud computing in DMRG simulations using DUCC-based effective Hamiltonians, with a hybrid approach allocating different computational resources based on workflow component requirements.", "result": "Developed a workflow that leverages Micron CXL hardware for memory-intensive CC downfolding and AQE cloud computing for less resource-intensive DMRG simulations, with performance analysis conducted on Micron prototype systems using the ExaChem suite.", "conclusion": "The hybrid resource allocation strategy effectively addresses the varying computational demands of different workflow components in quantum chemistry simulations, enabling optimized performance through proper hardware selection."}}
{"id": "2510.01370", "pdf": "https://arxiv.org/pdf/2510.01370", "abs": "https://arxiv.org/abs/2510.01370", "authors": ["Abu Bucker Siddik", "Diane Oyen", "Alexander Most", "Michal Kucer", "Ayan Biswas"], "title": "SPUS: A Lightweight and Parameter-Efficient Foundation Model for PDEs", "categories": ["cs.CV", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "We introduce Small PDE U-Net Solver (SPUS), a compact and efficient\nfoundation model (FM) designed as a unified neural operator for solving a wide\nrange of partial differential equations (PDEs). Unlike existing\nstate-of-the-art PDE FMs-primarily based on large complex transformer\narchitectures with high computational and parameter overhead-SPUS leverages a\nlightweight residual U-Net-based architecture that has been largely\nunderexplored as a foundation model architecture in this domain. To enable\neffective learning in this minimalist framework, we utilize a simple yet\npowerful auto-regressive pretraining strategy which closely replicates the\nbehavior of numerical solvers to learn the underlying physics. SPUS is\npretrained on a diverse set of fluid dynamics PDEs and evaluated across 6\nchallenging unseen downstream PDEs spanning various physical systems.\nExperimental results demonstrate that SPUS using residual U-Net based\narchitecture achieves state-of-the-art generalization on these downstream tasks\nwhile requiring significantly fewer parameters and minimal fine-tuning data,\nhighlighting its potential as a highly parameter-efficient FM for solving\ndiverse PDE systems.", "AI": {"tldr": "SPUS is a compact foundation model using residual U-Net architecture for solving diverse PDEs, achieving SOTA performance with fewer parameters and minimal fine-tuning.", "motivation": "Existing PDE foundation models use large transformer architectures with high computational overhead, while U-Net architectures remain underexplored despite their potential efficiency.", "method": "Lightweight residual U-Net architecture with auto-regressive pretraining strategy that mimics numerical solver behavior, pretrained on diverse fluid dynamics PDEs.", "result": "Achieves state-of-the-art generalization on 6 challenging unseen PDEs while requiring significantly fewer parameters and minimal fine-tuning data.", "conclusion": "SPUS demonstrates potential as a highly parameter-efficient foundation model for solving diverse PDE systems."}}
{"id": "2510.01396", "pdf": "https://arxiv.org/pdf/2510.01396", "abs": "https://arxiv.org/abs/2510.01396", "authors": ["Wasut Pornpatcharapong"], "title": "Neural Network Surrogates for Free Energy Computation of Complex Chemical Systems", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "physics.comp-ph"], "comment": "6 pages, 4 figures. This work has already been accepted for\n  presentation in The 29th International Computer Science and Engineering\n  Conference (ICSEC) 2025, Chiang Mai, Thailand, and will be published in IEEE\n  Xplore", "summary": "Free energy reconstruction methods such as Gaussian Process Regression (GPR)\nrequire Jacobians of the collective variables (CVs), a bottleneck that\nrestricts the use of complex or machine-learned CVs. We introduce a neural\nnetwork surrogate framework that learns CVs directly from Cartesian coordinates\nand uses automatic differentiation to provide Jacobians, bypassing analytical\nforms. On an MgCl2 ion-pairing system, our method achieved high accuracy for\nboth a simple distance CV and a complex coordination-number CV. Moreover,\nJacobian errors also followed a near-Gaussian distribution, making them\nsuitable for GPR pipelines. This framework enables gradient-based free energy\nmethods to incorporate complex and machine-learned CVs, broadening the scope of\nbiochemistry and materials simulations.", "AI": {"tldr": "A neural network surrogate framework that learns collective variables (CVs) from Cartesian coordinates and uses automatic differentiation for Jacobians, eliminating the need for analytical forms and enabling complex CVs in free energy reconstruction.", "motivation": "Traditional free energy reconstruction methods like Gaussian Process Regression require analytical Jacobians of CVs, which is a bottleneck for using complex or machine-learned CVs.", "method": "Neural network surrogate framework that learns CVs directly from Cartesian coordinates and uses automatic differentiation to compute Jacobians, bypassing the need for analytical forms.", "result": "Achieved high accuracy on MgCl2 ion-pairing system for both simple distance CV and complex coordination-number CV. Jacobian errors followed near-Gaussian distribution, making them suitable for GPR pipelines.", "conclusion": "This framework enables gradient-based free energy methods to incorporate complex and machine-learned CVs, broadening applications in biochemistry and materials simulations."}}
{"id": "2510.01401", "pdf": "https://arxiv.org/pdf/2510.01401", "abs": "https://arxiv.org/abs/2510.01401", "authors": ["Chunyi Gai", "Fahad Al Saadi"], "title": "Localized Pattern Formation and Oscillatory Instabilities in a Three-component Gierer Meinhardt Model", "categories": ["math.AP", "math.DS"], "comment": null, "summary": "In this paper, we introduce a three-component Gierer-Meinhardt model in the\nsemi-strong interaction regime, characterized by an asymptotically large\ndiffusivity ratio. A key feature of this model is that the interior spike can\nundergo Hopf bifurcations in both amplitude and position, leading to rich\noscillatory dynamics not present in classical two-component systems. Using\nasymptotic analysis and numerical path-following, we construct localized spike\nequilibria and analyze spike nucleation that occurs through slow passage beyond\na saddle-node bifurcation. Moreover, stability of spike equilibrium is analyzed\nby introducing time-scaling parameters, which reveal two distinct mechanisms:\namplitude oscillations triggered by large-eigenvalue instabilities and\noscillatory spike motion associated with small eigenvalues. Numerical\nsimulations illustrate these dynamics and their transition regimes. This dual\nmechanism highlights richer spike behavior in three-component systems and\nsuggests several open problems for future study.", "AI": {"tldr": "Three-component Gierer-Meinhardt model with large diffusivity ratio exhibits Hopf bifurcations in both amplitude and position of interior spikes, revealing richer oscillatory dynamics than two-component systems.", "motivation": "To explore richer spike behavior and oscillatory dynamics in three-component reaction-diffusion systems compared to classical two-component models, particularly focusing on dual Hopf bifurcations.", "method": "Asymptotic analysis and numerical path-following to construct localized spike equilibria, analyze spike nucleation through saddle-node bifurcation, and study stability using time-scaling parameters.", "result": "Identified two distinct instability mechanisms: amplitude oscillations from large-eigenvalue instabilities and oscillatory spike motion from small eigenvalues, with numerical simulations showing transition regimes.", "conclusion": "Three-component systems exhibit richer spike dynamics with dual oscillation mechanisms, suggesting several open problems for future investigation in complex pattern formation."}}
{"id": "2510.01419", "pdf": "https://arxiv.org/pdf/2510.01419", "abs": "https://arxiv.org/abs/2510.01419", "authors": ["Md Tusher Ahmed", "Chenhaoyue Wang", "Amartya S. Banerjee", "Nikhil Chandra Admal"], "title": "Multiscale analysis of large twist ferroelectricity and swirling dislocations in bilayer hexagonal boron nitride", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "With its atomically thin structure and intrinsic ferroelectric properties,\nheterodeformed bilayer hexagonal boron nitride (hBN) has gained prominence in\nnext-generation non-volatile memory applications. However, studies to date have\nfocused almost exclusively on small heterodeformations, leaving the question of\nwhether ferroelectricity can persist under large heterodeformation entirely\nunexplored. In this work, we establish the crystallographic origin of\nferroelectricity in bilayer hBN configurations heterodeformed relative to\nhigh-symmetry configurations such as the AA-stacking and the 21.786789 $\\circ$\ntwisted configuration, using Smith normal form bicrystallography. We then\ndemonstrate out-of-plane ferroelectricity in bilayer hBN across configurations\nvicinal to both the AA and $\\Sigma 7$ stacking. Atomistic simulations reveal\nthat AA-vicinal systems support ferroelectricity under both small twist and\nsmall strain, with polarization switching in the latter governed by the\ndeformation of swirling dislocations rather than the straight interface\ndislocations seen in the former. For $\\Sigma 7$-vicinal systems, where reliable\ninteratomic potentials are lacking, we develop a\ndensity-functional-theory-informed continuum framework--the\nbicrystallography-informed frame-invariant multiscale (BFIM) model, which\ncaptures out-of-plane ferroelectricity in heterodeformed configurations vicinal\nto the $\\Sigma 7$ stacking. Interface dislocations in these large\nheterodeformed bilayer configurations exhibit markedly smaller Burgers vectors\ncompared to the interface dislocations in small-twist and small-strain bilayer\nhBN. The BFIM model reproduces atomistic simulation results and provides a\npowerful, computationally efficient framework for predicting ferroelectricity\nin large-unit-cell heterostructures where atomistic simulations are\nprohibitively expensive.", "AI": {"tldr": "This paper demonstrates that ferroelectricity persists in bilayer hexagonal boron nitride (hBN) under large heterodeformations, not just small ones. The authors develop a bicrystallography-informed multiscale model to study ferroelectricity in configurations near both AA and \u03a37 stacking, revealing different polarization switching mechanisms.", "motivation": "Previous studies focused only on small heterodeformations in bilayer hBN, leaving the persistence of ferroelectricity under large heterodeformations unexplored. This work aims to address this gap and understand ferroelectric behavior across different deformation regimes.", "method": "Used Smith normal form bicrystallography to establish crystallographic origin of ferroelectricity. Conducted atomistic simulations for AA-vicinal systems, and developed a density-functional-theory-informed continuum framework (BFIM model) for \u03a37-vicinal systems where atomistic methods are unreliable.", "result": "Found that AA-vicinal systems support ferroelectricity under both small twist and small strain, with different polarization switching mechanisms. For \u03a37-vicinal systems, the BFIM model successfully captures out-of-plane ferroelectricity. Interface dislocations in large heterodeformations have smaller Burgers vectors compared to small-deformation cases.", "conclusion": "Ferroelectricity persists in bilayer hBN under large heterodeformations. The developed BFIM model provides an efficient computational framework for predicting ferroelectricity in large-unit-cell heterostructures where atomistic simulations are too expensive."}}
{"id": "2510.01415", "pdf": "https://arxiv.org/pdf/2510.01415", "abs": "https://arxiv.org/abs/2510.01415", "authors": ["Dilara Siraeva", "Irina A. Kogan"], "title": "Symmetry analysis and new partially invariant solutions for the gas dynamics system with a special equation of state", "categories": ["math.AP", "35B06, 35A30"], "comment": null, "summary": "This paper is a contribution to the symmetry analysis of the gas dynamics\nsystem in the vein of the ''podmodeli'' (submodels) program outlined by\nOvsyannikov (1994). We consider the case of the special state equation,\nprescribing pressure to be the sum of entropy and an arbitrary function of\ndensity. Such a system has a 12-dimensional symmetry Lie algebra. This work\nadvances the study of its four-dimensional subalgebras, continuing the work\nstarted in Siraeva (2024). For a large subset of not previously considered,\nnon-similar four-dimensional subalgebras from an optimal list in Siraeva\n(2014), we compute a complete set of generating invariants. For one of the\nsubalgebras, we construct a partially symmetry-reduced system. We explicitly\nsolve this reduced system (submodel). This leads to new families of explicit\nsolutions of the original system. We analyze the trajectories of these\nsolutions. Additionally, we match each of the subalgebras considered in this\npaper with its isomorphism class, planting a seed for future study of the\nhierarchy of the reduced systems.", "AI": {"tldr": "Symmetry analysis of gas dynamics with special state equation (pressure = entropy + function of density). Computes invariants for 4D subalgebras and constructs explicit solutions.", "motivation": "Continue the symmetry analysis program for gas dynamics systems, specifically studying 4D subalgebras not previously considered in earlier work.", "method": "Compute complete sets of generating invariants for non-similar 4D subalgebras from optimal list, construct partially symmetry-reduced system, and explicitly solve the reduced system.", "result": "Obtained new families of explicit solutions to the original gas dynamics system and analyzed their trajectories. Matched subalgebras with isomorphism classes.", "conclusion": "Advanced the symmetry analysis of gas dynamics systems, providing explicit solutions and establishing foundation for future study of reduced system hierarchy."}}
{"id": "2510.01442", "pdf": "https://arxiv.org/pdf/2510.01442", "abs": "https://arxiv.org/abs/2510.01442", "authors": ["Paola F. Antonietti", "Matteo Caldana", "Lorenzo Gentile", "Marco Verani"], "title": "Deep Learning Accelerated Algebraic Multigrid Methods for Polytopal Discretizations of Second-Order Differential Problems", "categories": ["math.NA", "cs.NA", "65N22, 65N30, 65N55, 68T01"], "comment": null, "summary": "Algebraic Multigrid (AMG) methods are state-of-the-art algebraic solvers for\npartial differential equations. Still, their efficiency depends heavily on the\nchoice of suitable parameters and/or ingredients. Paradigmatic examples include\nthe so-called strong threshold parameter $\\theta$, which controls the algebraic\ncoarse-grid hierarchy, as well as the smoother, i.e., the relaxation methods\nused on the fine grid to damp out high-frequency errors. In AMG, since the\ncoarse grids are constructed algebraically (without geometric intuition), the\nsmoother's performance is even more critical. For the linear systems stemming\nfrom polytopal discretizations, such as Polytopal Discontinuous Galerkin\n(PolyDG) and Virtual Element Methods (VEM), AMG sensitivity to such choices is\neven more critical due to the significant variability of the underlying meshes,\nwhich results in algebraic systems with different sparsity patterns. We propose\na novel deep learning approach that automatically tunes the strong threshold\nparameter, as well as the smoother choice in AMG solvers, for linear systems of\nequations arising from polytopal discretizations, thereby maximizing AMG\nperformance. We interpret the sparse matrix resulting from polytopal\ndiscretization as a grayscale image, and by applying pooling, our neural\nnetwork extracts compact features that preserve the necessary information at a\nlow computational cost. We test various differential problems in both two- and\nthree-dimensional settings, with heterogeneous coefficients and\npolygonal/polyhedral meshes, and demonstrate that the proposed approach\ngeneralizes well. In practice, we demonstrate that we can reduce AMG solver\ntime by up to $27\\%$ with minimal changes to existing PolyDG and VEM codes.", "AI": {"tldr": "A deep learning approach to automatically tune AMG parameters (strong threshold and smoother choice) for polytopal discretizations, treating sparse matrices as images and using pooling to extract features, achieving up to 27% solver time reduction.", "motivation": "AMG efficiency depends heavily on parameter choices like strong threshold and smoother selection, which is especially critical for polytopal discretizations (PolyDG/VEM) due to variable mesh structures and sparsity patterns.", "method": "Interpret sparse matrices from polytopal discretizations as grayscale images, apply pooling in neural networks to extract compact features, and use deep learning to automatically tune AMG parameters (strong threshold and smoother choice).", "result": "The approach reduces AMG solver time by up to 27% while maintaining good generalization across various 2D/3D differential problems with heterogeneous coefficients and polygonal/polyhedral meshes.", "conclusion": "Deep learning can effectively automate AMG parameter tuning for polytopal discretizations, significantly improving solver performance with minimal code modifications to existing PolyDG and VEM implementations."}}
{"id": "2510.01289", "pdf": "https://arxiv.org/pdf/2510.01289", "abs": "https://arxiv.org/abs/2510.01289", "authors": ["Osama A. Marzouk"], "title": "Detailed Derivation of the Scalar Explicit Expressions Governing the Electric Field, Current Density, and Volumetric Power Density in the Four Types of Linear Divergent MHD Channels Under a Unidirectional Applied Magnetic Field", "categories": ["physics.plasm-ph", "00A79, 03H10"], "comment": "41 pages, 8 figures, 4 tables, published journal article,\n  peer-reviewed, open access", "summary": "The current study belongs to the field of applied mathematics in plasma\nphysics and electric power, where mathematical analysis of the algebraic\nequations governing the electric field vector, and the electric-current density\nfield vector within a Magnetohydrodynamic (MHD) linear two-dimensional\ndivergent supersonic channel is utilized to derive analytical expressions for\nthese important fields, as well as closed-form equations for the volumetric\npower density (output electric power per unit volume of the plasma channel).\nThe expressions presented here describe analytically the operation of the MHD\nchannel as an electric power source within an Open-Cycle Magnetohydrodynamic\n(OCMHD) generator. The four common types of the MHD linear channels are covered\nhere: namely, (1) continuous-electrode Faraday channel, (2) linear Hall\nchannel, (3) segmented-electrode Faraday channel, and (4) diagonal-electrode\nchannel. The mathematical results, their detailed derivation, and the companion\ngraphical illustrations aid in making a proper decision regarding which channel\ntype is the most suitable for a given application.Under typical operational\nconditions of 5 S/m plasma electric conductivity, 5 T magnetic field, and 2,000\nm/s plasma speed, as well as an optimized load factor of 0.5, we estimate the\nfollowing numerical values (unsigned magnitudes) for the continuous-electrode\nFaraday channel (with a Hall parameter of 1): useful electric field (across the\nexternal electric load): 5 kV/m, useful electric current-density (between the\nterminal electrodes within the channel): 12.5 kA/m2 , volumetric power density\n(dissipated by the load per unit volume of plasma): 62.5 MW/m3 , and electric\nefficiency (for the electric field or voltage): 50%. For the Halllinear channel\n(with a Hall parameter of 5), these quantitative performance values become25\nkV/m, 4.808 kA/m2, 120.19 MW/m3, and 46.30%.", "AI": {"tldr": "Analytical derivation of electric field, current density, and power density expressions for four types of MHD linear channels in Open-Cycle Magnetohydrodynamic generators.", "motivation": "To provide mathematical analysis and analytical expressions for electric field, current density, and power density in MHD channels to aid in selecting the most suitable channel type for specific applications.", "method": "Mathematical analysis of algebraic equations governing electric field vector and electric-current density field vector in Magnetohydrodynamic linear two-dimensional divergent supersonic channels.", "result": "Derived analytical expressions for four MHD channel types with numerical estimates showing Hall-linear channel achieves higher power density (120.19 MW/m\u00b3) compared to Faraday channel (62.5 MW/m\u00b3) under typical conditions.", "conclusion": "The analytical framework and numerical results help determine optimal MHD channel type selection for electric power generation applications based on performance metrics."}}
{"id": "2510.01543", "pdf": "https://arxiv.org/pdf/2510.01543", "abs": "https://arxiv.org/abs/2510.01543", "authors": ["Dawid A. Hryniuk", "Marzena H. Szyma\u0144ska"], "title": "Variational approach to open quantum systems with long-range competing interactions", "categories": ["quant-ph", "cond-mat.quant-gas", "physics.comp-ph"], "comment": null, "summary": "Competition between short- and long-range interactions underpins many\nemergent phenomena in nature. Despite rapid progress in their experimental\ncontrol, computational methods capable of accurately simulating open quantum\nmany-body systems with complex long-ranged interactions at scale remain scarce.\nHere, we address this limitation by introducing an efficient and scalable\napproach to dissipative quantum lattices in one and two dimensions, combining\nmatrix product operators and time-dependent variational Monte Carlo. We\nshowcase the versatility, effectiveness, and unique methodological advantages\nof our algorithm by simulating the non-equilibrium dynamics and steady states\nof spin-$\\frac{1}{2}$ lattices with competing algebraically-decaying\ninteractions for as many as $N=200$ sites, revealing the emergence of\nspatially-modulated magnetic order far from equilibrium. This approach offers\npromising prospects for advancing our understanding of the complex\nnon-equilibrium properties of a diverse variety of experimentally-realizable\nquantum systems with long-ranged interactions, including Rydberg atoms,\nultracold dipolar molecules, and trapped ions.", "AI": {"tldr": "The paper introduces an efficient computational method combining matrix product operators and time-dependent variational Monte Carlo to simulate dissipative quantum lattices with long-range interactions, enabling study of non-equilibrium dynamics in systems up to 200 sites.", "motivation": "There is a need for accurate computational methods to simulate open quantum many-body systems with complex long-range interactions, which are experimentally controllable but computationally challenging.", "method": "Combination of matrix product operators and time-dependent variational Monte Carlo for simulating dissipative quantum lattices in 1D and 2D with competing algebraically-decaying interactions.", "result": "Successfully simulated non-equilibrium dynamics and steady states of spin-1/2 lattices with up to 200 sites, revealing emergence of spatially-modulated magnetic order far from equilibrium.", "conclusion": "This approach provides promising prospects for understanding complex non-equilibrium properties of various experimentally-realizable quantum systems with long-range interactions, including Rydberg atoms, ultracold dipolar molecules, and trapped ions."}}
{"id": "2510.01507", "pdf": "https://arxiv.org/pdf/2510.01507", "abs": "https://arxiv.org/abs/2510.01507", "authors": ["Mitia Duerinckx", "Pierre-Emmanuel Jabin"], "title": "Correlation estimates for Brownian particles with singular interactions", "categories": ["math.AP", "math-ph", "math.MP", "math.PR"], "comment": "22 pages", "summary": "We study particle systems with singular pairwise interactions and\nnon-vanishing diffusion in the mean-field scaling. A classical approach to\ndescribing corrections to mean-field behavior is through the analysis of\ncorrelation functions. For bounded interactions, the optimal estimates on\ncorrelations are well known: the $m$-particle correlation function is\n$G_{N,m}=O(N^{1-m})$ for all $m$. Such estimates, however, have remained out of\nreach for more singular interactions. In this work, we develop a new framework\nbased on linearized correlation functions, which allows us to derive robust\nbounds for systems with merely square-integrable interaction kernels, providing\nthe first systematic control of correlations in the singular setting. Although\nat first not optimal, our estimates can be partially refined a posteriori using\nthe BBGKY hierarchy: in the case of bounded interactions, our method recovers\nthe known optimal estimates with a simplified argument. As key applications, we\nestablish the validity of the Bogolyubov correction to mean field and prove a\ncentral limit theorem for the empirical measure, extending these results beyond\nthe bounded interaction regime for the first time.", "AI": {"tldr": "This paper develops a new framework using linearized correlation functions to analyze particle systems with singular pairwise interactions and non-vanishing diffusion, providing the first systematic control of correlations for square-integrable interaction kernels.", "motivation": "Previous approaches to describing corrections to mean-field behavior through correlation functions were limited to bounded interactions, with optimal estimates G_{N,m}=O(N^{1-m}) known only for bounded cases. More singular interactions remained out of reach.", "method": "The authors develop a new framework based on linearized correlation functions that allows derivation of robust bounds for systems with square-integrable interaction kernels. The estimates can be partially refined using the BBGKY hierarchy.", "result": "The method provides the first systematic control of correlations in the singular setting. For bounded interactions, it recovers known optimal estimates with simplified arguments. Key applications include establishing validity of Bogolyubov correction to mean field and proving a central limit theorem for the empirical measure.", "conclusion": "The framework extends correlation analysis beyond the bounded interaction regime, enabling rigorous treatment of singular interactions in particle systems with non-vanishing diffusion."}}
{"id": "2510.01567", "pdf": "https://arxiv.org/pdf/2510.01567", "abs": "https://arxiv.org/abs/2510.01567", "authors": ["Kathrin Hellmuth", "Ruhui Jin", "Qin Li", "Stephen J. Wright"], "title": "Data selection: at the interface of PDE-based inverse problem and randomized linear algebra", "categories": ["math.NA", "cs.NA", "math.OC", "35R30, 65C60, 62Kxx, 65J22, 65Fxx, 60B20, 65M32, 90C31"], "comment": null, "summary": "All inverse problems rely on data to recover unknown parameters, yet not all\ndata are equally informative. This raises the central question of data\nselection. A distinctive challenge in PDE-based inverse problems is their\ninherently infinite-dimensional nature: both the parameter space and the design\nspace are infinite, which greatly complicates the selection process. Somewhat\nunexpectedly, randomized numerical linear algebra (RNLA), originally developed\nin very different contexts, has provided powerful tools for addressing this\nchallenge. These methods are inherently probabilistic, with guarantees\ntypically stating that information is preserved with probability at least 1-p\nwhen using N randomly selected, weighted samples. Here, the notion of\ninformation can take different mathematical forms depending on the setting. In\nthis review, we survey the problem of data selection in PDE-based inverse\nproblems, emphasize its unique infinite-dimensional aspects, and highlight how\nRNLA strategies have been adapted and applied in this context.", "AI": {"tldr": "This review explores data selection in PDE-based inverse problems, emphasizing the challenge of infinite-dimensional parameter and design spaces, and how randomized numerical linear algebra provides probabilistic tools for efficient data selection.", "motivation": "Inverse problems rely on data to recover unknown parameters, but not all data are equally informative. The central challenge is selecting the most informative data, which is particularly difficult in PDE-based inverse problems due to their inherently infinite-dimensional nature.", "method": "The paper surveys how randomized numerical linear algebra (RNLA) methods, originally developed in different contexts, have been adapted to address data selection in PDE-based inverse problems. These methods use random sampling with probabilistic guarantees.", "result": "RNLA provides powerful tools for data selection with probabilistic guarantees that information is preserved with high probability (1-p) when using N randomly selected, weighted samples. The mathematical form of 'information' varies depending on the specific setting.", "conclusion": "Randomized numerical linear algebra offers effective strategies for addressing the unique challenges of data selection in infinite-dimensional PDE-based inverse problems, providing probabilistic guarantees for information preservation through carefully designed random sampling approaches."}}
{"id": "2510.01573", "pdf": "https://arxiv.org/pdf/2510.01573", "abs": "https://arxiv.org/abs/2510.01573", "authors": ["Zhuo Liu", "Muni Zhou", "Nuno F. G. Loureiro"], "title": "Suppression of inverse magnetic energy transfer in collisionless marginally magnetized plasmas", "categories": ["physics.plasm-ph", "astro-ph.HE"], "comment": null, "summary": "We investigate the inverse cascade of magnetic energy in decaying,\ncollisionless plasmas with moderate to high-$\\beta$ values via first-principles\nnumerical simulations and analytical theory. We find that\npressure-anisotropy-driven instabilities, in particular the firehose\ninstability, suppress reconnection-driven coalescence of magnetic structures\n(i.e., inverse transfer) by nullifying magnetic tension. This suppression\nleaves such structures elongated and confined to scales comparable to the\nLarmor radius of the particles. The presence of a magnetic guide field of\nsufficient strength, or a greater scale separation between the initial size of\nthe magnetic structures and the Larmor radius, restores the system's ability to\ninverse transfer magnetic energy. These results reveal that inverse energy\ntransfer in collisionless plasmas is not guaranteed, but instead sensitively\ndepends on magnetization. In the astrophysical context, this identifies a\nkinetic mechanism by which Weibel-generated seed fields may fail to merge\nconsistently, potentially limiting their role in cosmic magnetogenesis.", "AI": {"tldr": "Inverse magnetic energy cascade in collisionless plasmas is suppressed by pressure-anisotropy-driven instabilities like firehose instability, which nullify magnetic tension and prevent reconnection-driven coalescence of magnetic structures.", "motivation": "To understand the inverse transfer of magnetic energy in decaying collisionless plasmas and investigate why Weibel-generated seed fields may fail to merge consistently in astrophysical contexts.", "method": "First-principles numerical simulations and analytical theory to study decaying collisionless plasmas with moderate to high-\u03b2 values.", "result": "Firehose instability suppresses inverse energy transfer by nullifying magnetic tension, leaving magnetic structures elongated at Larmor radius scales. A strong magnetic guide field or greater scale separation between initial structure size and Larmor radius restores inverse transfer capability.", "conclusion": "Inverse energy transfer in collisionless plasmas is not guaranteed and sensitively depends on magnetization, revealing a kinetic mechanism that may limit the role of Weibel-generated fields in cosmic magnetogenesis."}}
{"id": "2510.01875", "pdf": "https://arxiv.org/pdf/2510.01875", "abs": "https://arxiv.org/abs/2510.01875", "authors": ["Zhandos A. Moldabekov", "Sebastian Schwalbe", "Uwe Hernandez Acosta", "Thomas Gawne", "Jan Vorberger", "Michele Pavanello", "Tobias Dornheim"], "title": "Enhancing the Efficiency of Time-Dependent Density Functional Theory Calculations of Dynamic Response Properties", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph", "physics.plasm-ph"], "comment": null, "summary": "X-ray Thomson scattering (XRTS) constitutes an essential technique for\ndiagnosing material properties under extreme conditions, such as high pressures\nand intense laser heating. Time-dependent density functional theory (TDDFT) is\none of the most accurate available ab initio methods for modeling XRTS spectra,\nas well as a host of other dynamic material properties. However, strong thermal\nexcitations, along with the need to account for variations in temperature and\ndensity as well as the finite size of the detector significantly increase the\ncomputational cost of TDDFT simulations compared to ambient conditions. In this\nwork, we present a broadly applicable method for optimizing and enhancing the\nefficiency of TDDFT calculations. Our approach is based on a one-to-one mapping\nbetween the dynamic structure factor and the imaginary time density--density\ncorrelation function, which naturally emerges in Feynman's path integral\nformulation of quantum many-body theory. Specifically, we combine rigorous\nconvergence tests in the imaginary time domain with a constraints-based noise\nattenuation technique to improve the efficiency of TDDFT modeling without the\nintroduction of any significant bias. As a result, we can report a speed-up by\nup to an order of magnitude, thus potentially saving millions of CPU hours for\nmodeling a single XRTS measurement of matter under extreme conditions.", "AI": {"tldr": "A method to speed up TDDFT calculations for X-ray Thomson scattering by using imaginary time mapping and noise attenuation, achieving up to 10x speed-up.", "motivation": "TDDFT is accurate for modeling XRTS spectra but computationally expensive under extreme conditions due to thermal excitations, temperature/density variations, and detector size.", "method": "Use one-to-one mapping between dynamic structure factor and imaginary time density-density correlation function from Feynman's path integral, combined with convergence tests and constraints-based noise attenuation.", "result": "Achieved speed-up by up to an order of magnitude, potentially saving millions of CPU hours for single XRTS measurements.", "conclusion": "The method significantly improves TDDFT efficiency for XRTS modeling under extreme conditions without introducing significant bias."}}
{"id": "2510.01515", "pdf": "https://arxiv.org/pdf/2510.01515", "abs": "https://arxiv.org/abs/2510.01515", "authors": ["David Meyer"], "title": "On the attainment of boundary data in variational problems with linear growth", "categories": ["math.AP"], "comment": null, "summary": "It is well-known that convex variational problems with linear growth and\nDirichlet boundary conditions might not have minimizers if the boundary\ncondition is not suitably relaxed.\n  We show that for a wide range of integrands, including the least gradient\nproblem and the non-parametric Plateau problem, and under suitable\nmean-convexity conditions of the boundary, minimizers of the relaxed problem\nattain the boundary data in the trace sense if it lies in $BV$ or\n$W^{\\alpha,p}$ with $\\alpha p\\geq 2$ without any kind of continuity assumption.\nUnlike previous works, our methods are also able to treat systems under a\ncertain quasi-isotropy assumption on the integrand. We further show that\nwithout this quasi-isotropy assumption, smooth counterexamples on uniformly\nconvex domains exist.\n  Further applications to the uniqueness of minimizers and to open problems\nabout the ROF functional with Dirichlet boundary conditions, and to the trace\nspace of functions of least gradient are given.", "AI": {"tldr": "The paper shows that for convex variational problems with linear growth and Dirichlet boundary conditions, minimizers attain boundary data in trace sense under mean-convexity conditions, without requiring continuity assumptions. The methods also work for systems under quasi-isotropy assumptions.", "motivation": "Convex variational problems with linear growth and Dirichlet boundary conditions may lack minimizers if boundary conditions aren't properly relaxed. The paper aims to establish conditions under which minimizers actually attain boundary data.", "method": "The authors use relaxed variational formulations and prove that under mean-convexity boundary conditions and for boundary data in BV or W^{\u03b1,p} with \u03b1p\u22652, minimizers attain boundary data in trace sense. They also treat systems under quasi-isotropy assumptions.", "result": "Minimizers of relaxed problems attain boundary data in trace sense for mean-convex boundaries when boundary data lies in BV or W^{\u03b1,p} with \u03b1p\u22652, without continuity requirements. Without quasi-isotropy, counterexamples exist on uniformly convex domains.", "conclusion": "The paper establishes sufficient conditions for boundary data attainment in variational problems, extends results to systems under quasi-isotropy, and provides applications to uniqueness problems and trace spaces of least gradient functions."}}
{"id": "2510.01696", "pdf": "https://arxiv.org/pdf/2510.01696", "abs": "https://arxiv.org/abs/2510.01696", "authors": ["Behnam Hashemi", "Yuji Nakatsukasa"], "title": "Instability of the Sherman-Morrison formula and stabilization by iterative refinement", "categories": ["math.NA", "cs.NA", "65Gxx"], "comment": null, "summary": "Owing to its simplicity and efficiency, the Sherman-Morrison (SM) formula has\nseen widespread use across various scientific and engineering applications for\nsolving rank-one perturbed linear systems of the form $(A+uv^T)x = b$. Although\nthe formula dates back at least to 1944, its numerical stability properties\nhave remained an open question and continue to be a topic of current research.\nWe analyze the backward stability of the SM, demonstrate its instability in a\nscenario increasingly common in scientific computing and address an open\nquestion posed by Nick Higham on the proportionality of the backward error\nbound to the condition number of $A$. We then incorporate fixed-precision\niterative refinement into the SM framework reusing the previously computed\ndecompositions and prove that, under reasonable assumptions, it achieves\nbackward stability without sacrificing the efficiency of the SM formula. While\nour theory does not prove the SM formula with iterative refinement always\noutputs a backward stable solution, empirically it is observed to eventually\nproduce a backward stable solution in all our numerical experiments. We\nconjecture that with iterative refinement, the SM formula yields a backward\nstable solution provided that $\\kappa_2(A), \\kappa_2(A+uv^T)$ are both bounded\nsafely away from $\\epsilon_M^{-1}$, where $\\epsilon_M$ is the unit roundoff.", "AI": {"tldr": "The Sherman-Morrison formula's numerical stability remains an open question. This paper analyzes its backward stability, demonstrates instability in common scenarios, and incorporates iterative refinement to achieve backward stability while maintaining efficiency.", "motivation": "The Sherman-Morrison formula is widely used for solving rank-one perturbed linear systems due to its simplicity and efficiency, but its numerical stability properties have remained an open question since 1944.", "method": "Analyzed backward stability of SM formula, demonstrated instability scenarios, and incorporated fixed-precision iterative refinement into SM framework while reusing previously computed decompositions.", "result": "The paper proves that with iterative refinement under reasonable assumptions, backward stability is achieved without sacrificing SM formula efficiency. Empirically observed to produce backward stable solutions in all numerical experiments.", "conclusion": "With iterative refinement, the SM formula yields backward stable solutions when both \u03ba\u2082(A) and \u03ba\u2082(A+uv\u1d40) are bounded safely away from \u03b5\u1d39\u207b\u00b9, where \u03b5\u1d39 is the unit roundoff."}}
{"id": "2510.01977", "pdf": "https://arxiv.org/pdf/2510.01977", "abs": "https://arxiv.org/abs/2510.01977", "authors": ["Andrew T. Powis", "Domenica Corona Rivera", "Alexander Khrabry", "Igor D. Kaganovich"], "title": "Accelerating kinetic plasma simulations with machine learning generated initial conditions", "categories": ["physics.plasm-ph", "physics.comp-ph"], "comment": null, "summary": "Computer aided engineering of multi-time-scale plasma systems which exhibit a\nquasi-steady state solution are challenging due to the large number of time\nsteps required to reach convergence. Machine learning techniques combined with\ntraditional first-principles simulations and high-performance computing offer\nmany interesting pathways towards resolving this challenge. We consider\nacceleration of kinetic plasma simulations via machine learning generated\ninitial conditions. The approach is demonstrated through modeling of\ncapacitively coupled plasma discharges relevant to the microelectronics\nindustry. Three models are trained on simulations across a parameter space of\ndevice driving frequency and operating pressure. The models incorporate\nelements of a multi-layer perceptron, principal component analysis, and\nconvolutional neural networks to predict the final time-averaged profiles of\nion-density and velocity distribution functions. These data-driven initial\ncondition generators (ICGs) provide a mean speedup of 17.1x in convergence\ntime, when measured using an offline procedure, or a 4.4x speedup with an\nonline procedure, with convolutional neural networks leading to the best\nperformance. The paper also outlines a workflow for continuous data-driven\nmodel improvement and simulation speedup, with the aim of generating sufficient\ndata for full device digital twins.", "AI": {"tldr": "Machine learning-generated initial conditions accelerate kinetic plasma simulations, achieving up to 17.1x speedup in convergence time for capacitively coupled plasma discharge modeling.", "motivation": "Multi-time-scale plasma systems require many time steps to reach quasi-steady state convergence, making computer-aided engineering challenging. Machine learning combined with traditional simulations offers pathways to resolve this computational bottleneck.", "method": "Three machine learning models (multi-layer perceptron, principal component analysis, and convolutional neural networks) are trained on simulations across device parameters to predict final time-averaged ion-density and velocity distribution profiles. A workflow for continuous model improvement is also outlined.", "result": "Data-driven initial condition generators provide mean speedup of 17.1x with offline procedure and 4.4x with online procedure. Convolutional neural networks performed best among the three model types.", "conclusion": "Machine learning-generated initial conditions effectively accelerate plasma simulations, with a proposed workflow for continuous improvement toward generating sufficient data for full device digital twins."}}
{"id": "2510.01918", "pdf": "https://arxiv.org/pdf/2510.01918", "abs": "https://arxiv.org/abs/2510.01918", "authors": ["Adri\u00e1n Mar\u0131n", "Mauricio Soto-Gomez", "Giorgio Valentini", "Elena Casiraghi", "Carlos Cano", "Daniel Manzano"], "title": "Hybrid Quantum-Classical Walks for Graph Representation Learning in Community Detection", "categories": ["quant-ph", "physics.comp-ph"], "comment": "6 pages. Accepted at the 2025 IEEE International Conference on\n  Quantum Artificial Intelligence", "summary": "Graph Representation Learning (GRL) has emerged as a cornerstone technique\nfor analysing complex, networked data across diverse domains, including\nbiological systems, social networks, and data analysis. Traditional GRL methods\noften struggle to capture intricate relationships within complex graphs,\nparticularly those exhibiting non-trivial structural properties such as\npower-law distributions or hierarchical structures. This paper introduces a\nnovel quantum-inspired algorithm for GRL, utilizing hybrid Quantum-Classical\nWalks to overcome these limitations. Our approach combines the benefits of both\nquantum and classical dynamics, allowing the walker to simultaneously explore\nboth highly local and far-reaching connections within the graph. Preliminary\nresults for a case study in network community detection shows that this hybrid\ndynamic enables the algorithm to adapt effectively to complex graph topologies,\noffering a robust and versatile solution for GRL tasks.", "AI": {"tldr": "A quantum-inspired algorithm using hybrid Quantum-Classical Walks for Graph Representation Learning that effectively captures complex graph relationships and adapts to various topologies.", "motivation": "Traditional GRL methods struggle with complex graphs exhibiting non-trivial structural properties like power-law distributions and hierarchical structures, requiring more sophisticated approaches to capture intricate relationships.", "method": "Hybrid Quantum-Classical Walks that combine quantum and classical dynamics, allowing simultaneous exploration of both local and far-reaching connections within graphs.", "result": "Preliminary results for network community detection show the hybrid dynamic enables effective adaptation to complex graph topologies.", "conclusion": "The approach offers a robust and versatile solution for GRL tasks by overcoming limitations of traditional methods through quantum-inspired hybrid dynamics."}}
{"id": "2510.01602", "pdf": "https://arxiv.org/pdf/2510.01602", "abs": "https://arxiv.org/abs/2510.01602", "authors": ["Yanlong Fan", "Daozhi Han", "Quan Wang"], "title": "Inertial instability of Couette flow with Coriolis force", "categories": ["math.AP"], "comment": null, "summary": "We analyze the nonlinear inertial instability of Couette flow under Coriolis\nforcing in \\(\\mathbb{R}^{3}\\). For the Coriolis coefficient \\(f \\in (0,1)\\), we\nshow that the non-normal operator associated with the linearized system admits\nonly continuous spectrum. Hence, there are no exponentially growing\neigenfunctions for the linearized system. Instead, we construct unstable\nsolutions in the form of pseudo-eigenfunctions that exhibit non-ideal spectral\nproperties. Then through a bootstrap argument and resolving the challenges\nposed by the non-ideal spectral behavior of pseudo-eigenfunctions, we establish\nthe velocity instability of Couette flow in the Hadamard sense for $ f \\in\n\\Big(\\frac{2}{17} \\left(5-2 \\sqrt{2}\\right), \\frac{2}{17} \\left(5 + 2\n\\sqrt{2}\\right) \\Big)$.", "AI": {"tldr": "Analysis of nonlinear inertial instability in Couette flow with Coriolis forcing, showing velocity instability through pseudo-eigenfunctions despite no exponential eigenfunction growth.", "motivation": "To understand the stability properties of Couette flow under Coriolis forcing, particularly investigating instability mechanisms when traditional linear analysis shows no exponentially growing eigenfunctions.", "method": "Used spectral analysis of the linearized system, constructed pseudo-eigenfunctions to demonstrate non-ideal spectral properties, and applied bootstrap arguments to establish instability.", "result": "Proved velocity instability in the Hadamard sense for Coriolis coefficient f in the interval (2/17(5-2\u221a2), 2/17(5+2\u221a2)), showing instability occurs through pseudo-eigenfunctions rather than traditional eigenfunction growth.", "conclusion": "Couette flow under Coriolis forcing exhibits nonlinear inertial instability through pseudo-eigenfunctions, demonstrating that instability can occur even when the linearized system lacks exponentially growing eigenfunctions."}}
{"id": "2510.01790", "pdf": "https://arxiv.org/pdf/2510.01790", "abs": "https://arxiv.org/abs/2510.01790", "authors": ["Muhammad Ammad", "Leevan Ling"], "title": "Efficient manifold evolution algorithm using adaptive B-Spline interpolation", "categories": ["math.NA", "cs.NA", "math.AP", "math.DG"], "comment": null, "summary": "This paper explores an efficient Lagrangian approach for evolving point cloud\ndata on smooth manifolds. In this preliminary study, we focus on analyzing\nplane curves, and our ultimate goal is to provide an alternative to the\nconventional radial basis function (RBF) approach for manifolds in higher\ndimensions. In particular, we use the B-Spline as the basis function for all\nlocal interpolations. Just like RBF and other smooth basis functions, B-Splines\nenable the approximation of geometric features such as normal vectors and\ncurvature. Once properly set up, the advantage of using B-Splines is that their\ncoefficients carry geometric meanings. This allows the coefficients to be\nmanipulated like points, facilitates rapid updates of the interpolant, and\neliminates the need for frequent re-interpolation. Consequently, the removal\nand insertion of point cloud data become seamless processes, particularly\nadvantageous in regions experiencing significant fluctuations in point density.\nThe numerical results demonstrate the convergence of geometric quantities and\nthe effectiveness of our approach. Finally, we show simulations of curvature\nflows whose speeds depend on the solutions of coupled reaction--diffusion\nsystems for pattern formation.", "AI": {"tldr": "An efficient Lagrangian approach using B-Splines for evolving point cloud data on manifolds, providing an alternative to RBF methods with geometric coefficient manipulation.", "motivation": "To provide an efficient alternative to conventional radial basis function (RBF) approaches for evolving point cloud data on smooth manifolds in higher dimensions.", "method": "Uses B-Spline basis functions for local interpolations, where coefficients carry geometric meanings and can be manipulated like points, enabling rapid updates without frequent re-interpolation.", "result": "Numerical results demonstrate convergence of geometric quantities and effectiveness of the approach, with successful simulations of curvature flows coupled with reaction-diffusion systems.", "conclusion": "The B-Spline approach offers advantages over RBF methods by enabling seamless point cloud manipulation, particularly in regions with fluctuating point density, and effectively handles complex geometric evolution problems."}}
{"id": "2510.02088", "pdf": "https://arxiv.org/pdf/2510.02088", "abs": "https://arxiv.org/abs/2510.02088", "authors": ["Alexander Schmitz", "Andreas Petersen", "Franko Greiner"], "title": "A neural network approach to kinetic Mie polarimetry for particle size diagnostics in nanodusty plasmas", "categories": ["physics.plasm-ph"], "comment": "Accepted manuscript", "summary": "The analysis of the size of nanoparticles is an essential task in plasma\ntechnology and dusty plasmas. Light scattering techniques, based on Mie theory,\ncan be used as a non-invasive and in-situ diagnostic tool for this purpose.\nHowever, the standard back-calculation methods require expertise from the user.\nTo address this, we introduce a neural network that performs the same task. We\ndiscuss how we set up and trained the network to analyze the size of\nplasma-grown amorphous carbon nanoparticles (a:C-H) with a refractive index n\nin the range of real(n) = 1.4-2.2 and imag(n) = 0.04i-0.1i and a radius of up\nto several hundred nanometers, depending on the used wavelength. The diagnostic\napproach is kinetic, which means that the particles need to change in size due\nto growth or etching. An uncertainty analysis as well as a test with\nexperimental data are presented. Our neural network achieves results that agree\nwith those of prior fitting algorithms while offering higher methodical\nstability. The model also holds a major advantage in terms of computing speed\nand automation.", "AI": {"tldr": "A neural network is introduced to analyze nanoparticle sizes in plasma technology, replacing traditional Mie theory back-calculation methods that require expertise.", "motivation": "Standard light scattering techniques for nanoparticle size analysis require user expertise and are not automated. The goal is to create a more accessible and efficient diagnostic tool.", "method": "A neural network is set up and trained to analyze plasma-grown amorphous carbon nanoparticles using kinetic diagnostic approach where particles change size due to growth or etching.", "result": "The neural network achieves results comparable to prior fitting algorithms but with higher methodical stability, faster computing speed, and better automation capabilities.", "conclusion": "The neural network approach provides a superior alternative to traditional methods for nanoparticle size analysis in plasma technology, offering improved stability, speed, and automation."}}
{"id": "2510.01647", "pdf": "https://arxiv.org/pdf/2510.01647", "abs": "https://arxiv.org/abs/2510.01647", "authors": ["Lu Chen", "Jiali Lan"], "title": "The weighted isoperimetric inequality and Sobolev inequality outside convex sets", "categories": ["math.AP"], "comment": "26 pages", "summary": "In this paper, we establish a weighted capillary isoperimetric inequality\noutside convex sets using the $\\lambda_w$-ABP method. The weight function $w$\nis assumed to be positive, even, and homogeneous of degree $\\alpha$, such that\n$w^{1/\\alpha}$ is concave on $\\R^n$.\n  Based on the weighted isoperimetric inequality, we develop a technique of\ncapillary Schwarz symmetrization outside convex sets, and establish a weighted\nP\\'{o}lya-Szeg\\\"{o} principle and a sharp weighted capillary Sobolev inequality\noutside convex domain. Our result can be seen as an extension of the weighted\nSobolev inequality in the half-space established by Ciraolo-Figalli-Roncoroni\nin \\cite{CFR}.", "AI": {"tldr": "Extension of weighted Sobolev inequalities to capillary settings outside convex sets using weighted isoperimetric inequalities and capillary Schwarz symmetrization.", "motivation": "To extend weighted Sobolev inequalities from half-spaces to more general capillary settings outside convex sets, building on previous work by Ciraolo-Figalli-Roncoroni.", "method": "Uses weighted capillary isoperimetric inequality via \u03bbw-ABP method, develops capillary Schwarz symmetrization outside convex sets, and establishes weighted P\u00f3lya-Szeg\u0151 principle.", "result": "Proves sharp weighted capillary Sobolev inequality outside convex domains, extending previous results from half-spaces to more general settings.", "conclusion": "Successfully extends weighted Sobolev inequalities to capillary contexts outside convex sets, providing new tools for analysis in these geometric settings."}}
{"id": "2510.01828", "pdf": "https://arxiv.org/pdf/2510.01828", "abs": "https://arxiv.org/abs/2510.01828", "authors": ["C Mahmoud", "H Mathis"], "title": "Asymptotic preserving schemes for hyperbolic systems with relaxation", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper presents the construction of two numerical schemes for the\nsolution of hyperbolic systems with relaxation source terms. The methods are\nbuilt by considering the relaxation system as a whole, without separating the\nresolution of the convective part from that of the source term. The first\nscheme combines the centered FORCE approach of Toro and co-authors with the\nunsplit strategy proposed by B{\\'e}reux and Sainsaulieu. The second scheme\nconsists of an approximate Riemann solver which carefully handles the source\nterm approximation. The two schemes are built to be asymptotic preserving, in\nthe sense that their limit schemes are consistent with the equilibrium model as\nthe relaxation parameter tends to zero, without any CFL restriction. For\nspecific models, it is possible to prove that they preserve invariant domains\nand admit a discrete entropy inequality.", "AI": {"tldr": "Two numerical schemes for hyperbolic systems with relaxation source terms that treat the system as a whole without separating convection from source terms, with asymptotic preserving properties.", "motivation": "To develop numerical methods that handle hyperbolic systems with relaxation source terms in a unified manner, avoiding the separation of convective and source term resolution.", "method": "First scheme combines FORCE approach with unsplit strategy; second scheme uses an approximate Riemann solver with careful source term approximation. Both are designed to be asymptotic preserving.", "result": "The schemes maintain consistency with equilibrium models as relaxation parameter approaches zero without CFL restrictions, and preserve invariant domains with discrete entropy inequalities for specific models.", "conclusion": "Two effective numerical schemes were developed that successfully handle hyperbolic relaxation systems as unified entities with desirable mathematical properties."}}
{"id": "2510.02051", "pdf": "https://arxiv.org/pdf/2510.02051", "abs": "https://arxiv.org/abs/2510.02051", "authors": ["Xiaowei Ou", "Tianshu Huang", "Vidvuds Ozolins"], "title": "Improving neural network performance for solving quantum sign structure", "categories": ["quant-ph", "cond-mat.str-el", "physics.comp-ph"], "comment": "8 pages, 3 figures, to be published in Physical Review B", "summary": "Neural quantum states have emerged as a widely used approach to the numerical\nstudy of the ground states of non-stoquastic Hamiltonians. However, existing\napproaches often rely on a priori knowledge of the sign structure or require a\nseparately pre-trained phase network. We introduce a modified stochastic\nreconfiguration method that effectively uses differing imaginary time steps to\nevolve the amplitude and phase. Using a larger time step for phase\noptimization, this method enables a simultaneous and efficient training of\nphase and amplitude neural networks. The efficacy of our method is demonstrated\non the Heisenberg J_1-J_2 model.", "AI": {"tldr": "Modified stochastic reconfiguration method with different imaginary time steps for amplitude and phase enables simultaneous training of neural quantum states without prior sign structure knowledge.", "motivation": "Existing neural quantum state approaches for non-stoquastic Hamiltonians often require a priori knowledge of sign structure or separate pre-training of phase networks, which limits their applicability.", "method": "Modified stochastic reconfiguration using different imaginary time steps - larger step for phase optimization and smaller step for amplitude optimization - to enable simultaneous training of phase and amplitude neural networks.", "result": "The method successfully demonstrated its efficacy on the Heisenberg J_1-J_2 model, showing it can handle complex sign structures without prior knowledge.", "conclusion": "The proposed approach provides an effective way to simultaneously train phase and amplitude networks for neural quantum states, eliminating the need for separate pre-training or prior sign structure knowledge."}}
{"id": "2510.01728", "pdf": "https://arxiv.org/pdf/2510.01728", "abs": "https://arxiv.org/abs/2510.01728", "authors": ["Matthew Kowalski", "Minjie Shan"], "title": "On dispersive decay for the generalized Korteweg--de Vries equation", "categories": ["math.AP", "35Q53"], "comment": "12 pages", "summary": "We prove pointwise-in-time dispersive estimates for solutions to the\ngeneralized Korteweg--de Vries (gKdV) equation. In particular, for solutions to\nthe mass-critical model, we assume only that initial data lie in\n$\\dot{H}^{\\frac{1}{4}} \\cap \\dot{H}^{-\\frac{1}{12}}$ and show that solutions\ndecay in $L^\\infty$ like $|t|^{-\\frac{1}{3}}$. To accomplish this, we develop a\npersistence of negative regularity for solutions to gKdV and extend\nLorentz--Strichartz estimates to the mixed norm case.", "AI": {"tldr": "Pointwise-in-time dispersive estimates for gKdV equation solutions, showing L^\u221e decay like |t|^{-1/3} for mass-critical model with initial data in specific Sobolev spaces.", "motivation": "To establish dispersive estimates for generalized Korteweg-de Vries equation solutions, particularly for the mass-critical case, extending understanding of solution behavior over time.", "method": "Developed persistence of negative regularity for gKdV solutions and extended Lorentz-Strichartz estimates to mixed norm cases.", "result": "Proved that solutions to mass-critical gKdV decay in L^\u221e like |t|^{-1/3} when initial data lie in H^{1/4} \u2229 H^{-1/12}.", "conclusion": "Successfully established pointwise-in-time dispersive estimates for gKdV equation, demonstrating specific decay rates for solutions with appropriate initial conditions."}}
{"id": "2510.02094", "pdf": "https://arxiv.org/pdf/2510.02094", "abs": "https://arxiv.org/abs/2510.02094", "authors": ["Abdolreza Amiri", "Gabriel R. Barrenechea", "Emmanuil H. Georgoulis", "Tristan Pryer"], "title": "A nodally bound-preserving composite discontinuous Galerkin method on polytopic meshes", "categories": ["math.NA", "cs.NA"], "comment": "27 pages, 7 figures", "summary": "We introduce a nodally bound-preserving Galerkin method for second-order\nelliptic problems on general polygonal/polyhedral, henceforth collectively\ntermed as \\emph{polytopic}, meshes. Starting from an interior penalty\ndiscontinuous Galerkin (DG) formulation posed on a polytopic mesh, the method\nenforces preservation of \\emph{a priori} prescribed upper and lower bounds for\nthe numerical solution at an arbitrary number of user-defined points\n\\emph{within} each polytopic element. This is achieved by employing a\nsimplicial submesh and enforcing bound preservation at the submesh nodes via a\nnonlinear iteration. By construction, the submeshing procedure preserves the\norder of accuracy of the DG method, \\emph{without} introducing any additional\nglobal numerical degrees of freedom compared to the baseline DG method,\nthereby, falling into the category of composite finite element approaches. A\nsalient feature of the proposed method is that it automatically reverts to the\nstandard DG method on polytopic meshes when no prescribed bound violation\noccurs. In particular, the choice of the discontinuity-penalisation parameter\nis independent of the submesh granularity. The resulting composite method\ncombines the geometric flexibility of polytopic meshes with the accuracy and\nstability of discontinuous Galerkin discretisations, while rigorously\nguaranteeing bound preservation. The existence and uniqueness of the numerical\nsolution is proven. A priori error bounds, assuming sufficient regularity of\nthe exact solution are shown, employing a non-standard construction of discrete\nnodally bound-preserving interpolant. Numerical experiments confirm optimal\nconvergence for smooth problems and demonstrate robustness in the presence of\nsharp gradients, such as boundary and interior layers.", "AI": {"tldr": "A nodally bound-preserving Galerkin method for elliptic problems on polytopic meshes that enforces solution bounds at user-defined points within elements using a simplicial submesh, without adding extra degrees of freedom.", "motivation": "To develop a method that combines geometric flexibility of polytopic meshes with bound preservation capabilities for numerical solutions, addressing issues with sharp gradients and boundary layers.", "method": "Uses interior penalty discontinuous Galerkin formulation on polytopic meshes with simplicial submesh to enforce bounds at submesh nodes via nonlinear iteration, preserving accuracy without additional degrees of freedom.", "result": "Proven existence and uniqueness of numerical solution, optimal convergence for smooth problems, robustness with sharp gradients, and automatic reversion to standard DG when no bounds are violated.", "conclusion": "The composite method successfully combines polytopic mesh flexibility with DG accuracy and stability while guaranteeing bound preservation, with proven mathematical properties and demonstrated numerical performance."}}
{"id": "2510.01957", "pdf": "https://arxiv.org/pdf/2510.01957", "abs": "https://arxiv.org/abs/2510.01957", "authors": ["David Martinez-del-Rio", "Robert S. MacKay"], "title": "Numerical tests of formulae for volume enclosed by flux surfaces of integrable magnetic fields", "categories": ["math.DS", "physics.plasm-ph"], "comment": "Keywords: Magnetic field, Flux surface, Volume", "summary": "Numerical tests of volume formulae are presented to compute efficiently the\nvolume enclosed between flux surfaces for integrable 3D vector fields with\nvarious degrees of symmetry. In the process, a new case is proposed and tested.", "AI": {"tldr": "Numerical tests of volume formulae for integrable 3D vector fields with various symmetries, including a new proposed case.", "motivation": "To efficiently compute volumes enclosed between flux surfaces for integrable 3D vector fields with different symmetry properties.", "method": "Numerical testing of volume formulae, with proposal and testing of a new case.", "result": "Volume formulae were tested numerically for various symmetry cases.", "conclusion": "The study presents numerical validation of volume computation methods for integrable 3D vector fields, including a newly proposed case."}}
{"id": "2510.01732", "pdf": "https://arxiv.org/pdf/2510.01732", "abs": "https://arxiv.org/abs/2510.01732", "authors": ["Anne-Laure Dalibard", "Fr\u00e9d\u00e9ric Marbach", "Jean Rax"], "title": "Nonlinear Forward-Backward Problems", "categories": ["math.AP"], "comment": "arXiv admin note: text overlap with arXiv:2203.11067", "summary": "We prove the existence and uniqueness of strong solutions to the equation $u\nu_x - u_{yy} = f$ in the vicinity of the linear shear flow, subject to\nperturbations of the source term and lateral boundary conditions. Since the\nsolutions we consider have opposite signs in the lower and upper half of the\ndomain, this is a quasilinear forward-backward parabolic problem, which changes\ntype across a critical curved line within the domain. In particular, lateral\nboundary conditions can be imposed only where the characteristics are inwards.\nThere are several difficulties associated with this problem. First, the\nforward-backward geometry depends on the solution itself. This requires to be\nquite careful with the approximation procedure used to construct solutions.\nSecond, and more importantly, the linearized equations solved at each step of\nthe iterative scheme admit a finite number of singular solutions, of which we\nprovide an explicit construction. This is similar to well-known phenomena in\nelliptic problems in nonsmooth domains. Hence, the solutions to the equation\nare regular if and only if the source terms satisfy a finite number of\northogonality conditions. A key difficulty of this work is to cope with these\northogonality conditions during the nonlinear fixed-point scheme. In\nparticular, we are led to prove their stability with respect to the underlying\nbase flow. To tackle this deceivingly simple problem, we develop a methodology\nwhich we believe to be both quite natural and adaptable to other situations in\nwhich one wishes to prove the existence of regular solutions to a nonlinear\nproblem for suitable data despite the existence of singular solutions at the\nlinear level. This paper is a shorter version of [3].", "AI": {"tldr": "Existence and uniqueness of strong solutions for a quasilinear forward-backward parabolic equation near linear shear flow, with solutions changing sign across a critical line and requiring careful handling of orthogonality conditions.", "motivation": "To study quasilinear forward-backward parabolic problems that change type across critical curved lines, where lateral boundary conditions can only be imposed where characteristics are inwards, addressing difficulties from solution-dependent geometry and singular solutions in linearized equations.", "method": "Developed an iterative approximation procedure with careful handling of orthogonality conditions for singular solutions in linearized equations, proving stability of these conditions with respect to base flow, using a nonlinear fixed-point scheme.", "result": "Proved existence and uniqueness of strong solutions when source terms satisfy finite orthogonality conditions, with solutions regular if and only if these conditions are met.", "conclusion": "Developed a natural and adaptable methodology for proving existence of regular solutions to nonlinear problems despite singular solutions at linear level, applicable to other similar situations."}}
{"id": "2510.02111", "pdf": "https://arxiv.org/pdf/2510.02111", "abs": "https://arxiv.org/abs/2510.02111", "authors": ["Kosuke Suzuki"], "title": "Coarse scrambling for Sobol' and Niederreiter sequences", "categories": ["math.NA", "cs.NA", "65C05, 65D30"], "comment": null, "summary": "We introduce \\emph{coarse scrambling}, a novel randomization for digital\nsequences that permutes blocks of digits in a mixed-radix representation. This\nconstruction is designed to preserve the powerful\n$(0,\\boldsymbol{e},d)$-sequence property of the underlying points. For\nsufficiently smooth integrands, we prove that this method achieves the\ncanonical $O(n^{-3+\\epsilon})$ variance decay rate, matching that of standard\nOwen's scrambling. Crucially, we show that its maximal gain coefficient grows\nonly logarithmically with dimension, $O(\\log d)$, thus providing theoretical\nrobustness against the curse of dimensionality affecting scrambled Sobol'\nsequences. Numerical experiments validate these findings and illustrate a\npractical trade-off: while Owen's scrambling is superior for integrands\nsensitive to low-dimensional projections, coarse scrambling is competitive for\nfunctions with low effective truncation dimension.", "AI": {"tldr": "Coarse scrambling is a new randomization method for digital sequences that permutes blocks of digits while preserving (0,e,d)-sequence properties, achieving O(n^{-3+\u03b5}) variance decay with only logarithmic dimension dependence O(log d).", "motivation": "To address the curse of dimensionality affecting scrambled Sobol' sequences by developing a randomization method with better dimensional robustness.", "method": "Permutes blocks of digits in mixed-radix representation while preserving the (0,e,d)-sequence property of underlying points.", "result": "Achieves canonical O(n^{-3+\u03b5}) variance decay rate for smooth integrands, with maximal gain coefficient growing only logarithmically with dimension O(log d).", "conclusion": "Coarse scrambling provides theoretical robustness against dimensionality curse, being competitive with Owen's scrambling for functions with low effective truncation dimension."}}
{"id": "2510.02301", "pdf": "https://arxiv.org/pdf/2510.02301", "abs": "https://arxiv.org/abs/2510.02301", "authors": ["Andrew G. Sullivan", "Roger D. Blandford", "Anna Synani", "Philipe V. de la Parra", "No\u00e9mie Globus", "Mitchell C. Begelman", "Anthony C. S. Readhead"], "title": "Relativistic Jets and Winds in Radio-Identified Supermassive Black Hole Binary Candidates", "categories": ["astro-ph.HE", "astro-ph.GA", "physics.plasm-ph"], "comment": "13 pages, 8 figures, submitted to ApJ", "summary": "Supermassive black hole binary systems (SMBHBs) are thought to emit the\nrecently discovered nHz gravitational wave background; however, not a single\nindividual nHz source has been confirmed to date. Long-term radio-monitoring at\nthe Owens Valley Radio Observatory has revealed two potential SMBHB candidates:\nblazars PKS 2131-021 and PKS J0805-0111. These sources show periodic flux\ndensity variations across the electromagnetic spectrum, signaling the presence\nof a good clock. To explain the emission, we propose a generalizable jet model,\nwhere a mildly relativistic wind creates an outward-moving helical channel,\nalong which the ultra-relativistic jet propagates. The observed flux variation\nfrom the jet is mostly due to aberration. The emission at lower frequency\narises at larger radius and its variation is consequently delayed, as observed.\nOur model reproduces the main observable features of both sources and can be\napplied to other sources as they are discovered. We make predictions for radio\npolarization, direct imaging, and emission line variation, which can be tested\nwith forthcoming observations. Our results motivate future numerical\nsimulations of jetted SMBHB systems and have implications for the fueling,\nstructure, and evolution of blazar jets.", "AI": {"tldr": "Proposes a jet model to explain periodic flux variations in two blazar candidates for supermassive black hole binaries, predicting observable features that can be tested with future observations.", "motivation": "To explain the periodic flux density variations observed in two potential supermassive black hole binary candidates (PKS 2131-021 and PKS J0805-0111) and provide a generalizable model for such systems.", "method": "Developed a jet model where a mildly relativistic wind creates an outward-moving helical channel for ultra-relativistic jet propagation, with observed flux variation primarily due to aberration effects.", "result": "The model successfully reproduces the main observable features of both sources, including the delayed variation at lower frequencies, and can be applied to other similar sources.", "conclusion": "The results motivate future numerical simulations of jetted SMBHB systems and have implications for understanding blazar jet fueling, structure, and evolution, with testable predictions for radio polarization, direct imaging, and emission line variation."}}
{"id": "2510.01765", "pdf": "https://arxiv.org/pdf/2510.01765", "abs": "https://arxiv.org/abs/2510.01765", "authors": ["Stefano Vita"], "title": "Notes on Schauder estimates by scaling for elliptic PDEs in divergence form", "categories": ["math.AP", "35B65, 35B44, 35B45, 35B53, 35B30, 35B08"], "comment": "28 pages", "summary": "These are the notes of a part of the PhD course Regularity for free boundary\nproblems and for elliptic PDEs, held in Pavia in the spring of 2025. The aim is\nto provide a comprehensive and self-contained treatment of classical interior\nand local Schauder estimates for second-order linear elliptic PDEs in\ndivergence form via scaling in the spirit of Simon's work. The main techniques\npresented here are geometric in nature and were primarily developed in the\nstudy of geometric problems such as minimal surfaces. The adopted approach\nrelies on compactness and blow-up arguments, combined with rigidity results\n(Liouville theorems), and shares many features with the one used in the study\nof free boundary problems, which was the main topic of the other part of the\nPhD course.", "AI": {"tldr": "These notes cover classical interior and local Schauder estimates for second-order linear elliptic PDEs in divergence form using scaling techniques inspired by Simon's work, with geometric methods from minimal surfaces.", "motivation": "To provide a comprehensive and self-contained treatment of Schauder estimates for elliptic PDEs using geometric techniques developed in the study of minimal surfaces and free boundary problems.", "method": "Uses scaling, compactness and blow-up arguments combined with rigidity results (Liouville theorems), adopting geometric approaches from minimal surfaces theory.", "result": "Presents classical interior and local Schauder estimates for second-order linear elliptic PDEs in divergence form.", "conclusion": "The geometric approach using scaling, compactness, and blow-up arguments provides an effective framework for deriving Schauder estimates, sharing features with methods used in free boundary problems."}}
{"id": "2510.02126", "pdf": "https://arxiv.org/pdf/2510.02126", "abs": "https://arxiv.org/abs/2510.02126", "authors": ["Peter Benner", "Xiaobo Liu"], "title": "Mixed-precision iterative refinement for low-rank Lyapunov equations", "categories": ["math.NA", "cs.NA", "65F10, 65F45, 65G50, 15A24"], "comment": null, "summary": "We develop a mixed-precision iterative refinement framework for solving\nlow-rank Lyapunov matrix equations $AX + XA^T + W =0$, where $W=LL^T$ or\n$W=LSL^T$. Via rounding error analysis of the algorithms we derive sufficient\nconditions for the attainable normwise residuals in different precision\nsettings and show how the algorithmic parameters should be chosen. Using the\nsign function Newton iteration as the solver, we show that reduced precisions,\nsuch as the half precision, can be used as the solver precision (with unit\nroundoff $u_s$) to accelerate the solution of Lyapunov equations of condition\nnumber up to $1/u_s$ without compromising its quality.", "AI": {"tldr": "Mixed-precision iterative refinement framework for solving low-rank Lyapunov equations using reduced precisions like half precision to accelerate solution without compromising quality.", "motivation": "To accelerate the solution of low-rank Lyapunov matrix equations by using reduced precision arithmetic while maintaining solution quality for problems with condition numbers up to the inverse of the solver precision's unit roundoff.", "method": "Developed a mixed-precision iterative refinement framework using the sign function Newton iteration as solver, with rounding error analysis to derive conditions for attainable normwise residuals and guide parameter selection.", "result": "Shows that reduced precisions (e.g., half precision) can be used as solver precision to accelerate Lyapunov equation solutions for condition numbers up to 1/u_s (inverse of unit roundoff) without quality compromise.", "conclusion": "Mixed-precision iterative refinement enables efficient solution of low-rank Lyapunov equations using reduced precision arithmetic while maintaining accuracy through proper parameter selection guided by error analysis."}}
{"id": "2510.01779", "pdf": "https://arxiv.org/pdf/2510.01779", "abs": "https://arxiv.org/abs/2510.01779", "authors": ["Oana Ivanovici"], "title": "Strichartz and dispersive estimates for quantum bouncing ball model: exponential sums and Van der Corput methods in 1d semi-classical Schr\u00f6dinger equations", "categories": ["math.AP", "math.NT"], "comment": null, "summary": "We analyze the one-dimensional semi-classical Schr\\\"odinger equation on the\nhalf-line with a linear potential and Dirichlet boundary conditions. Our main\nfocus is on establishing improved dispersive and Strichartz estimates for this\nmodel, which govern the space-time behavior of solutions. We prove refined\nStrichartz bounds using Van der Corput-type derivative tests, beating previous\nknown results where Strichartz estimates incur 1/4 losses. Moreover, assuming\nsharp bounds for certain exponential sums, our results indicate the possibility\nto reduce these losses further to $1/6 + \\epsilon$ for all $\\epsilon>0$, which\nwould be sharp. We further expect that analogous Strichartz bounds should hold\nwithin the Friedlander model domain in higher dimensions.", "AI": {"tldr": "Improved dispersive and Strichartz estimates for 1D semi-classical Schr\u00f6dinger equation with linear potential on half-line, reducing losses from 1/4 to potentially 1/6+\u03b5.", "motivation": "To establish better space-time behavior understanding of solutions to the semi-classical Schr\u00f6dinger equation with linear potential and Dirichlet boundary conditions.", "method": "Using Van der Corput-type derivative tests to prove refined Strichartz bounds, and analyzing exponential sums to potentially further reduce losses.", "result": "Proved improved Strichartz estimates that beat previous 1/4 losses, with potential for further reduction to 1/6+\u03b5 losses under sharp exponential sum bounds.", "conclusion": "The results suggest optimal Strichartz bounds are achievable and analogous estimates should extend to higher-dimensional Friedlander model domains."}}
{"id": "2510.02156", "pdf": "https://arxiv.org/pdf/2510.02156", "abs": "https://arxiv.org/abs/2510.02156", "authors": ["Suvendu Kar", "Murugesan Venkatapathi"], "title": "A Fast solver for high condition linear systems using randomized stable solutions of its blocks", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We present an enhanced version of the row-based randomized block-Kaczmarz\nmethod to solve a linear system of equations. This improvement makes use of a\nregularization during block updates in the solution, and a dynamic proposal\ndistribution based on the current residue and effective orthogonality between\nblocks. This improved method provides significant gains in solving\nhigh-condition number linear systems that are either sparse, or dense\nleast-squares problems that are significantly over/under determined.\nConsidering the poor generalizability of preconditioners for such problems, it\ncan also serve as a pre-solver for other iterative numerical methods when\nrequired, and as an inner iteration in certain types of GMRES solvers for\nlinear systems.", "AI": {"tldr": "Enhanced randomized block-Kaczmarz method with regularization and dynamic proposal distribution for solving high-condition number linear systems.", "motivation": "To improve solving high-condition number linear systems that are sparse or dense least-squares problems that are significantly over/under determined, addressing poor generalizability of preconditioners.", "method": "Uses regularization during block updates and dynamic proposal distribution based on current residue and effective orthogonality between blocks.", "result": "Provides significant gains in solving high-condition number linear systems.", "conclusion": "Can serve as a pre-solver for other iterative numerical methods and as an inner iteration in certain types of GMRES solvers for linear systems."}}
{"id": "2510.01865", "pdf": "https://arxiv.org/pdf/2510.01865", "abs": "https://arxiv.org/abs/2510.01865", "authors": ["Berardino Sciunzi", "Domenico Vuono"], "title": "Monotonicity and Liouville-type theorems for semilinear elliptic problems in the half space", "categories": ["math.AP", "35B06, 35B51, 35J61"], "comment": null, "summary": "We consider classical solutions to $-\\Delta u = f(u)$ in half-spaces, under\nhomogeneous Dirichlet boundary conditions. We prove that any positive solution\nis strictly monotone increasing in the direction orthogonal to the boundary,\nprovided that it is directionally bounded on finite strips. As a corollary, we\ndeduce a new Liouville-type theorem for the Lane-Emden equation.", "AI": {"tldr": "Positive solutions to -\u0394u = f(u) in half-spaces with Dirichlet boundary conditions are strictly monotone increasing in the direction orthogonal to the boundary, given directional boundedness on finite strips. This leads to a new Liouville-type theorem for the Lane-Emden equation.", "motivation": "To establish monotonicity properties of solutions to semilinear elliptic equations in half-spaces and derive new Liouville-type results, particularly for the Lane-Emden equation.", "method": "Analysis of classical solutions to -\u0394u = f(u) in half-spaces with homogeneous Dirichlet boundary conditions, using directional boundedness assumptions on finite strips to prove strict monotonicity.", "result": "Proved that any positive solution is strictly monotone increasing in the direction orthogonal to the boundary under the given boundedness condition.", "conclusion": "The monotonicity result provides a new Liouville-type theorem for the Lane-Emden equation, extending the understanding of solution behavior in half-spaces."}}
{"id": "2510.01495", "pdf": "https://arxiv.org/pdf/2510.01495", "abs": "https://arxiv.org/abs/2510.01495", "authors": ["Kimmie Harding", "Daniel M. Dunlavy"], "title": "Improving Runtime Performance of Tensor Computations using Rust From Python", "categories": ["cs.MS", "cs.NA", "math.NA", "G.4"], "comment": "12 pages, 4 figures", "summary": "In this work, we investigate improving the runtime performance of key\ncomputational kernels in the Python Tensor Toolbox (pyttb), a package for\nanalyzing tensor data across a wide variety of applications. Recent runtime\nperformance improvements have been demonstrated using Rust, a compiled\nlanguage, from Python via extension modules leveraging the Python C API --\ne.g., web applications, data parsing, data validation, etc. Using this same\napproach, we study the runtime performance of key tensor kernels of increasing\ncomplexity, from simple kernels involving sums of products over data accessed\nthrough single and nested loops to more advanced tensor multiplication kernels\nthat are key in low-rank tensor decomposition and tensor regression algorithms.\nIn numerical experiments involving synthetically generated tensor data of\nvarious sizes and these tensor kernels, we demonstrate consistent improvements\nin runtime performance when using Rust from Python over 1) using Python alone,\n2) using Python and the Numba just-in-time Python compiler (for loop-based\nkernels), and 3) using the NumPy Python package for scientific computing (for\npyttb kernels).", "AI": {"tldr": "This paper investigates improving runtime performance of tensor computational kernels in Python Tensor Toolbox by implementing them in Rust and calling from Python, showing consistent performance improvements over Python alone, Numba JIT compiler, and NumPy.", "motivation": "To improve runtime performance of key computational kernels in the Python Tensor Toolbox (pyttb) for analyzing tensor data across various applications, leveraging Rust's compiled language advantages through Python extension modules.", "method": "Implement key tensor kernels of increasing complexity in Rust and call them from Python via extension modules using the Python C API. Compare performance against Python alone, Numba JIT compiler for loop-based kernels, and NumPy implementations.", "result": "Demonstrated consistent improvements in runtime performance when using Rust from Python compared to: 1) Python alone, 2) Python with Numba JIT compiler, and 3) NumPy implementations, across various tensor sizes and kernel complexities.", "conclusion": "Using Rust from Python via extension modules provides significant runtime performance improvements for tensor computational kernels, making it a viable approach for optimizing performance-critical tensor operations in scientific computing applications."}}
{"id": "2510.01886", "pdf": "https://arxiv.org/pdf/2510.01886", "abs": "https://arxiv.org/abs/2510.01886", "authors": ["Baoping Liu", "Xu Zheng"], "title": "On sharp Strichartz estimate for hyperbolic Schr\u00f6dinger equation on $\\mathbb{T}^3$", "categories": ["math.AP", "math.CA", "35Q55"], "comment": "22 pages, 3 figures", "summary": "We prove the sharp Strichartz estimate for hyperbolic Schr\\\"{o}dinger\nequation on $\\mathbb{T}^3 $ via an incidence geometry approach. As application,\nwe obtain optimal local well-posedness of nonlinear hyperbolic Schr\\\"{o}dinger\nequations.", "AI": {"tldr": "Sharp Strichartz estimate for hyperbolic Schr\u00f6dinger equation on 3D torus via incidence geometry, with applications to optimal local well-posedness of nonlinear equations.", "motivation": "To establish precise estimates for hyperbolic Schr\u00f6dinger equations, which are important for understanding wave propagation and nonlinear dynamics in periodic domains.", "method": "Used an incidence geometry approach to prove the sharp Strichartz estimate on the 3D torus.", "result": "Proved the sharp Strichartz estimate for hyperbolic Schr\u00f6dinger equation on T^3.", "conclusion": "The sharp estimate enables optimal local well-posedness results for nonlinear hyperbolic Schr\u00f6dinger equations."}}
{"id": "2510.01511", "pdf": "https://arxiv.org/pdf/2510.01511", "abs": "https://arxiv.org/abs/2510.01511", "authors": ["Nazar Emirov", "Guohui Song", "Qiyu Sun"], "title": "Exponential convergence of a distributed divide-and-conquer algorithm for constrained convex optimization on networks", "categories": ["math.OC", "cs.DC", "cs.NA", "math.NA"], "comment": null, "summary": "We propose a divide-and-conquer (DAC) algorithm for constrained convex\noptimization over networks, where the global objective is the sum of local\nobjectives attached to individual agents. The algorithm is fully distributed:\neach iteration solves local subproblems around selected fusion centers and\ncoordinates only with neighboring fusion centers. Under standard assumptions of\nsmoothness, strong convexity, and locality on the objective function, together\nwith polynomial growth conditions on the underlying graph, we establish\nexponential convergence of the DAC iterations and derive explicit bounds for\nboth exact and inexact local solvers. Numerical experiments on three\nrepresentative losses ($L_2$ distance, quadratic, and entropy) confirm the\ntheory and demonstrate scalability and effectiveness.", "AI": {"tldr": "A distributed divide-and-conquer algorithm for constrained convex optimization over networks with exponential convergence guarantees.", "motivation": "To solve large-scale constrained convex optimization problems over networks where the global objective is the sum of local objectives, enabling fully distributed computation with only local coordination.", "method": "Divide-and-conquer approach where each iteration solves local subproblems around selected fusion centers and coordinates only with neighboring fusion centers. Works under smoothness, strong convexity, and locality assumptions.", "result": "Established exponential convergence of DAC iterations with explicit bounds for both exact and inexact local solvers. Numerical experiments on L2 distance, quadratic, and entropy losses confirm theory and demonstrate scalability.", "conclusion": "The DAC algorithm provides an effective and scalable distributed solution for network optimization problems with proven exponential convergence rates."}}
{"id": "2510.01893", "pdf": "https://arxiv.org/pdf/2510.01893", "abs": "https://arxiv.org/abs/2510.01893", "authors": ["Jakob Deutsch"], "title": "A note on the recovery sequence in the double gradient model for phase transitions", "categories": ["math.AP", "Primary: 49J45, Secondary: 35Q74, 49Q20, 74N99"], "comment": "28 pages, 2 figures", "summary": "We investigate the $\\limsup$ inequality in the double gradient model for\nphase transitions governed by a Modica--Mortola functional with a double-well\npotential in two dimensions. Specifically, we consider energy functionals of\nthe form \\[ E_\\varepsilon(u, \\Omega) = \\int_\\Omega \\left( \\frac{1}{\\varepsilon}\nW(\\nabla u) + \\varepsilon |\\nabla^2 u|^2 \\right) dx \\] for maps $ u \\in\nH^2(\\Omega; \\mathbb{R}^2) $, where $ W $ vanishes only at two wells. Assuming a\nbound on the optimal profile constant -- namely the cell problem on the unit\ncube -- in terms of the geodesic distance between the two wells, we\ncharacterise the limiting interfacial energy via periodic recovery sequences as\n$\\varepsilon \\to 0^+$.", "AI": {"tldr": "Analysis of the limsup inequality in double gradient models for phase transitions using Modica-Mortola functionals with double-well potentials in 2D.", "motivation": "To understand the limiting behavior of interfacial energies in phase transition models governed by double gradient functionals as the regularization parameter approaches zero.", "method": "Using energy functionals with double-well potentials and double gradient terms, analyzing the limsup inequality through periodic recovery sequences and optimal profile constants.", "result": "Characterization of the limiting interfacial energy under assumptions about the optimal profile constant in relation to geodesic distance between wells.", "conclusion": "The study provides insights into the asymptotic behavior of phase transition models with double gradient structure and establishes connections between optimal profile constants and interfacial energies."}}
{"id": "2510.01563", "pdf": "https://arxiv.org/pdf/2510.01563", "abs": "https://arxiv.org/abs/2510.01563", "authors": ["Taehee Ko", "Sungbin Lim"], "title": "Quantum advantages in ground state preparation, combinatorial optimization, and quantum state preparation", "categories": ["quant-ph", "cs.NA", "math.NA", "math.PR"], "comment": null, "summary": "We show that for any quantum Hamiltonian with an inverse-polynomial gap, the\nground state can be prepared in a polynomial circuit depth to\ninverse-polynomial precision, if the system size is sufficiently large. The\nresulting circuit is composed of a polynomial number of Pauli rotations without\nancilla qubit. Extending this result, we prove that for sufficiently large\nqubit number, any quantum state can be approximately prepared with a constant\n(polynomial) number of Pauli rotations to constant (inverse-polynomial)\nprecision. Our theoretical findings reveal exponential quantum advantages in\nthe prominent applications: ground state preparation, combinatorial\noptimization, and quantum state preparation.", "AI": {"tldr": "Ground states of quantum Hamiltonians with inverse-polynomial gaps can be prepared with polynomial-depth circuits using Pauli rotations, and any quantum state can be approximated with constant/polynomial Pauli rotations for large qubit systems.", "motivation": "To demonstrate efficient quantum state preparation methods that reveal exponential quantum advantages in applications like ground state preparation, combinatorial optimization, and quantum state preparation.", "method": "Using polynomial-depth circuits composed of polynomial number of Pauli rotations without ancilla qubits for ground state preparation, and extending to constant/polynomial Pauli rotations for approximating any quantum state in large systems.", "result": "Ground states can be prepared to inverse-polynomial precision with polynomial circuit depth, and any quantum state can be approximated with constant/polynomial Pauli rotations to constant/inverse-polynomial precision for sufficiently large qubit numbers.", "conclusion": "The findings reveal exponential quantum advantages in key applications including ground state preparation, combinatorial optimization, and quantum state preparation."}}
{"id": "2510.01911", "pdf": "https://arxiv.org/pdf/2510.01911", "abs": "https://arxiv.org/abs/2510.01911", "authors": ["Yuanchun Ren", "Yixian Gao"], "title": "Subwavelength resonances in two-dimensional elastic media with high contrast", "categories": ["math.AP"], "comment": "23 pages", "summary": "This paper employs layer potential techniques to investigate wave scattering\nin two-dimensional elastic media exhibiting high contrasts in both Lam\\'{e}\nparameters and density. Our contributions are fourfold. First, we construct an\ninvertible operator based on the kernel spaces of boundary integral operators,\nwhich enables the characterization of resonant frequencies through an\northogonality condition. Second, we use asymptotic analysis to derive the\nequation governing the leading-order terms of these resonant frequencies.\nThird, we analyze the scattered field in the interior domain for incident\nfrequencies across different regimes and characterize the longitudinal and\ntransverse far-field patterns in the exterior domain. Finally, we examine the\nsubwavelength bandgap in the phononic crystal with a dilute structure.", "AI": {"tldr": "This paper uses layer potential techniques to study wave scattering in 2D elastic media with high parameter contrasts, characterizing resonant frequencies, analyzing scattered fields, and examining subwavelength bandgaps in phononic crystals.", "motivation": "To investigate wave scattering phenomena in two-dimensional elastic media that exhibit significant contrasts in Lam\u00e9 parameters and density, which is relevant for understanding wave propagation in heterogeneous materials and designing phononic crystals.", "method": "Employed layer potential techniques and boundary integral operators, constructed an invertible operator using kernel spaces, performed asymptotic analysis to derive resonant frequency equations, and analyzed scattered fields across different frequency regimes.", "result": "Developed a framework to characterize resonant frequencies through orthogonality conditions, derived leading-order equations for resonant frequencies, characterized longitudinal and transverse far-field patterns, and examined subwavelength bandgaps in dilute phononic crystal structures.", "conclusion": "The study provides comprehensive analytical tools for understanding wave scattering in high-contrast elastic media, with applications to phononic crystal design and wave manipulation in heterogeneous materials."}}
{"id": "2510.01568", "pdf": "https://arxiv.org/pdf/2510.01568", "abs": "https://arxiv.org/abs/2510.01568", "authors": ["Zhenbing Zeng", "Yong Huang", "Lu Yang", "Yongsheng Rao"], "title": "A Novel Algorithm for Representing Positive Semi-Definite Polynomials as Sums of Squares with Rational Coefficients", "categories": ["cs.SC", "cs.NA", "math.AG", "math.NA"], "comment": "37 pages", "summary": "This paper presents a novel algorithm for constructing a sum-of-squares (SOS)\ndecomposition for positive semi-definite polynomials with rational\ncoefficients. Unlike previous methods that typically yield SOS decompositions\nwith floating-point coefficients, our approach ensures that all coefficients in\nthe decomposition remain rational. This is particularly useful in formal\nverification and symbolic computation, where exact arithmetic is required. We\nintroduce a stepwise reduction technique that transforms a given polynomial\ninto a sum of ladder-like squares while preserving rationality. Experimental\nresults demonstrate the effectiveness of our method compared to existing\nnumerical approaches. This artical is an extension of the following Chinnese\npaper: HUANG Yong , ZENG Zhenbing , YANG Lu , RAO Yongsheng. An Algorithm to\nRepresent Positive Semi-Definite Polynomials to Sum of Lader-Like Squares of\nPolynomials with Rational Coefficients (in Chinese). Journal of Systems Science\nand Mathematical Sciences, 2024, 44(5): 1241-1271\nhttps://doi.org/10.12341/jssms23584CM", "AI": {"tldr": "A novel algorithm for constructing sum-of-squares decompositions with rational coefficients for positive semi-definite polynomials, ensuring exact arithmetic in formal verification and symbolic computation.", "motivation": "Existing methods typically yield SOS decompositions with floating-point coefficients, which are problematic in applications requiring exact arithmetic like formal verification and symbolic computation.", "method": "A stepwise reduction technique that transforms polynomials into sum of ladder-like squares while preserving rationality of coefficients.", "result": "Experimental results demonstrate the effectiveness of the method compared to existing numerical approaches.", "conclusion": "The algorithm successfully constructs SOS decompositions with rational coefficients, providing exact solutions for applications requiring precise arithmetic."}}
{"id": "2510.02112", "pdf": "https://arxiv.org/pdf/2510.02112", "abs": "https://arxiv.org/abs/2510.02112", "authors": ["In-Jee Jeong", "Sangwook Tae"], "title": "Low regularity Sobolev well-posedness for Vlasov--Poisson", "categories": ["math.AP"], "comment": "17 pages", "summary": "We consider the Vlasov--Poisson equation on $\\mathbb{R}^n \\times\n\\mathbb{R}^n$ with $n \\ge 3$. We prove local well-posedness in\n$H^{s}(\\mathbb{R}^n \\times \\mathbb{R}^n)$ with $s> n/2-1/4$, for initial\ndistribution $f_{0} \\in H^{s}(\\mathbb{R}^n \\times \\mathbb{R}^n)$ having compact\nsupport in $v$. In particular, data not belonging to $L^p(\\mathbb{R}^n \\times\n\\mathbb{R}^n)$ for large $p$ are allowed.", "AI": {"tldr": "Local well-posedness of Vlasov-Poisson equation in H^s spaces with s > n/2 - 1/4 for n \u2265 3, allowing non-L^p data.", "motivation": "To establish local well-posedness for the Vlasov-Poisson equation in Sobolev spaces with lower regularity requirements, particularly allowing initial data that may not belong to L^p spaces for large p.", "method": "Analysis of the Vlasov-Poisson equation on R^n \u00d7 R^n using Sobolev space techniques, focusing on initial distributions with compact velocity support.", "result": "Proved local well-posedness in H^s(R^n \u00d7 R^n) with s > n/2 - 1/4 for n \u2265 3, for initial data f_0 \u2208 H^s with compact support in velocity variable.", "conclusion": "The Vlasov-Poisson equation is locally well-posed in Sobolev spaces with regularity index above n/2 - 1/4, extending the class of admissible initial data beyond traditional L^p spaces."}}
{"id": "2510.01755", "pdf": "https://arxiv.org/pdf/2510.01755", "abs": "https://arxiv.org/abs/2510.01755", "authors": ["Johannes Hertrich", "Hok Shing Wong", "Alexander Denker", "Stanislas Ducotterd", "Zhenghan Fang", "Markus Haltmeier", "\u017deljko Kereta", "Erich Kobler", "Oscar Leong", "Mohammad Sadegh Salehi", "Carola-Bibiane Sch\u00f6nlieb", "Johannes Schwab", "Zakhar Shumaylov", "Jeremias Sulam", "German Sh\u00e2ma Wache", "Martin Zach", "Yasi Zhang", "Matthias J. Ehrhardt", "Sebastian Neumayer"], "title": "Learning Regularization Functionals for Inverse Problems: A Comparative Study", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC"], "comment": null, "summary": "In recent years, a variety of learned regularization frameworks for solving\ninverse problems in imaging have emerged. These offer flexible modeling\ntogether with mathematical insights. The proposed methods differ in their\narchitectural design and training strategies, making direct comparison\nchallenging due to non-modular implementations. We address this gap by\ncollecting and unifying the available code into a common framework. This\nunified view allows us to systematically compare the approaches and highlight\ntheir strengths and limitations, providing valuable insights into their future\npotential. We also provide concise descriptions of each method, complemented by\npractical guidelines.", "AI": {"tldr": "The paper presents a unified framework for comparing learned regularization methods in imaging inverse problems, addressing implementation inconsistencies and providing systematic analysis.", "motivation": "To enable fair comparison of different learned regularization methods that have non-modular implementations and different architectural designs/training strategies.", "method": "Collect and unify available code into a common framework, then systematically compare approaches through this unified view.", "result": "The unified framework allows systematic comparison of methods, highlighting their strengths and limitations, and provides practical guidelines.", "conclusion": "The unified framework offers valuable insights into the future potential of learned regularization methods and facilitates better comparison across different approaches."}}
{"id": "2510.02242", "pdf": "https://arxiv.org/pdf/2510.02242", "abs": "https://arxiv.org/abs/2510.02242", "authors": ["Hendrik Baers", "Angkana R\u00fcland"], "title": "Transfer of Stability from the Classical to the Fractional Anisotropic Calder\u00f3n Problem", "categories": ["math.AP"], "comment": "54 pages, 4 figures, comments welcome", "summary": "We discuss two spectral fractional anisotropic Calder\\'on problems with\nsource-to-solution measurements and their quantitative relation to the\nclassical Calder\\'on problem. Firstly, we consider the anistropic fractional\nCalder\\'on problem from [FGKU25]. In this setting, we quantify the relation\nbetween the local and nonlocal Calder\\'on problems which had been deduced in\n[R25] and provide an associated stability estimate. As a consequence, any\nstability result which holds on the level of the local problem with\nsource-to-solution data has a direct nonlocal analogue (up to a logarithmic\nloss). Secondly, we introduce and discuss the fractional Calder\\'on problem\nwith source-to-solution measurements for the spectral fractional Dirichlet\nLaplacian on open, bounded, connected, Lipschitz sets on $\\mathbb{R}^n$. Also\nin this context, we provide a qualitative and quantitative transfer of\nuniqueness from the local to the nonlocal setting. As a consequence, we infer\nthe first stability results for the principal part for a fractional Calder\\'on\ntype problem for which no reduction of Liouville type is known. Our arguments\nrely on quantitative unique continuation arguments. As a result of independent\ninterest, we also prove a quantitative relation between source-to-solution and\nDirichlet-to-Neumann measurements for the classical Calder\\'on problem.", "AI": {"tldr": "This paper analyzes spectral fractional anisotropic Calder\u00f3n problems with source-to-solution measurements and establishes quantitative relationships between local and nonlocal Calder\u00f3n problems, including stability estimates and uniqueness transfers.", "motivation": "To bridge the gap between local and nonlocal Calder\u00f3n problems by quantifying their relationships and providing stability estimates, particularly for cases where no Liouville-type reduction is known.", "method": "Uses quantitative unique continuation arguments to relate source-to-solution measurements in fractional Calder\u00f3n problems to classical Calder\u00f3n problems, establishing stability estimates and uniqueness transfers between local and nonlocal settings.", "result": "Demonstrates that stability results for local Calder\u00f3n problems with source-to-solution data directly translate to nonlocal analogues (with logarithmic loss), and provides first stability results for principal parts in fractional Calder\u00f3n problems without known Liouville-type reductions.", "conclusion": "The paper successfully establishes quantitative connections between local and nonlocal Calder\u00f3n problems, providing stability estimates and uniqueness transfers that extend classical results to fractional settings, with applications to anisotropic problems and spectral fractional Dirichlet Laplacians."}}
{"id": "2510.01788", "pdf": "https://arxiv.org/pdf/2510.01788", "abs": "https://arxiv.org/abs/2510.01788", "authors": ["Cl\u00e9mentine Court\u00e8s", "Emmanuel Franck", "Michael Kraus", "Laurent Navoret", "L\u00e9opold Tr\u00e9mant"], "title": "Neural non-canonical Hamiltonian dynamics for long-time simulations", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "This work focuses on learning non-canonical Hamiltonian dynamics from data,\nwhere long-term predictions require the preservation of structure both in the\nlearned model and in numerical schemes. Previous research focused on either\nfacet, respectively with a potential-based architecture and with degenerate\nvariational integrators, but new issues arise when combining both. In\nexperiments, the learnt model is sometimes numerically unstable due to the\ngauge dependency of the scheme, rendering long-time simulations impossible. In\nthis paper, we identify this problem and propose two different training\nstrategies to address it, either by directly learning the vector field or by\nlearning a time-discrete dynamics through the scheme. Several numerical test\ncases assess the ability of the methods to learn complex physical dynamics,\nlike the guiding center from gyrokinetic plasma physics.", "AI": {"tldr": "Learning non-canonical Hamiltonian dynamics from data while preserving structure in both model and numerical schemes, addressing numerical instability issues through new training strategies.", "motivation": "Previous methods focused on either structure-preserving models or numerical schemes separately, but combining both caused numerical instability due to gauge dependency, making long-term simulations impossible.", "method": "Proposed two training strategies: directly learning the vector field, or learning time-discrete dynamics through the numerical scheme.", "result": "Methods were assessed on complex physical dynamics like guiding center from gyrokinetic plasma physics.", "conclusion": "The proposed strategies address the numerical instability problem when combining structure-preserving models and numerical schemes for learning non-canonical Hamiltonian dynamics."}}
{"id": "2510.01352", "pdf": "https://arxiv.org/pdf/2510.01352", "abs": "https://arxiv.org/abs/2510.01352", "authors": ["Gordon Blower", "Simon J. A. Malham"], "title": "The noncommutative KP hierarchy and its solution via descent algebra", "categories": ["nlin.SI", "math-ph", "math.AP", "math.MP"], "comment": "38 pages, two-column format", "summary": "We give the solution to the complete noncommutative Kadomtsev--Petviashvili\n(KP) hierarchy. We achieve this via direct linearisation which involves the\nGelfand--Levitan--Marchenko (GLM) equation. This is a linear integral equation\nin which the scattering data satisfies the linearised KP hierarchy. The\nsolution to the GLM equation is then shown to coincide with the solution to the\nnoncommutative KP hierarchy. We achieve this using two approaches. In the first\napproach we use the standard Sato-Wilson dressing transformation. In the second\napproach, which was pioneered by Poppe, we assume the scattering data is\nsemi-additive and by direct substitution, we show that the solution to the GLM\nequation satisfies the infinite set of field equations representing the\nnoncommutative KP hierarchy. This approach relies on the augmented pre-Poppe\nalgebra. This is a representative algebra that underlies the field equations\nrepresenting the hierarchy. It is nonassociative and isomorphic to a descent\nalgebra equipped with a grafting product. While we perform computations in the\nnonassociative descent algebra, the final result which establishes the solution\nto the complete hierarchy, resides in the natural associative subalgebra. The\nadvantages of this second approach are that it is constructive, explicit,\nhighlights the underlying combinatorial structures within the hierarchy, and\nreveals the mechanisms underlying the solution procedure.", "AI": {"tldr": "The paper presents a complete solution to the noncommutative KP hierarchy using direct linearisation via the GLM equation and two approaches: Sato-Wilson dressing transformation and Poppe's method with semi-additive scattering data.", "motivation": "To provide a complete solution to the noncommutative Kadomtsev-Petviashvili (KP) hierarchy, which is an important integrable system in mathematical physics.", "method": "Uses direct linearisation involving the Gelfand-Levitan-Marchenko (GLM) equation with two approaches: (1) standard Sato-Wilson dressing transformation, (2) Poppe's method assuming semi-additive scattering data and using augmented pre-Poppe algebra in nonassociative descent algebra.", "result": "Shows that the solution to the GLM equation coincides with the solution to the noncommutative KP hierarchy, establishing the complete solution to the hierarchy.", "conclusion": "The second approach (Poppe's method) is advantageous as it is constructive, explicit, reveals underlying combinatorial structures, and clarifies the solution mechanisms, with final results residing in the natural associative subalgebra."}}
{"id": "2510.02151", "pdf": "https://arxiv.org/pdf/2510.02151", "abs": "https://arxiv.org/abs/2510.02151", "authors": ["Eunou Lee"], "title": "A quantum analogue of convex optimization", "categories": ["quant-ph", "cs.NA", "math.NA"], "comment": "57 pages, submitted to QIP", "summary": "Convex optimization is the powerhouse behind the theory and practice of\noptimization. We introduce a quantum analogue of unconstrained convex\noptimization: computing the minimum eigenvalue of a Schr\\\"odinger operator $h =\n-\\Delta + V $ with convex potential $V:\\mathbb R^n \\rightarrow \\mathbb R_{\\ge\n0}$ such that $V(x)\\rightarrow\\infty $ as $\\|x\\|\\rightarrow\\infty$. For this\nproblem, we present an efficient quantum algorithm, called the Fundamental Gap\nAlgorithm (FGA), that computes the minimum eigenvalue of $h$ up to error\n$\\epsilon$ in polynomial time in $n$, $1/\\epsilon$, and parameters that depend\non $V$. Adiabatic evolution of the ground state is used as a key subroutine,\nwhich we analyze with novel techniques that allow us to focus on the low-energy\nspace. We apply the FGA to give the first known polynomial-time algorithm for\nfinding the lowest frequency of an $n$-dimensional convex drum, or\nmathematically, the minimum eigenvalue of the Dirichlet Laplacian on an\n$n$-dimensional region that is defined by $m$ linear constraints in polynomial\ntime in $n$, $m$, $1/\\epsilon$ and the radius $R$ of a ball encompassing the\nregion.", "AI": {"tldr": "Quantum algorithm for convex optimization by computing minimum eigenvalues of Schr\u00f6dinger operators with convex potentials, achieving polynomial-time efficiency.", "motivation": "Extend convex optimization theory to quantum computing domain by solving minimum eigenvalue problems for Schr\u00f6dinger operators with convex potentials.", "method": "Fundamental Gap Algorithm (FGA) using adiabatic evolution of ground state with novel low-energy space analysis techniques.", "result": "Efficient quantum algorithm computes minimum eigenvalue up to error \u03b5 in polynomial time in n, 1/\u03b5, and potential parameters.", "conclusion": "FGA provides first polynomial-time quantum algorithm for finding lowest frequency of n-dimensional convex drums via Dirichlet Laplacian eigenvalues."}}
{"id": "2510.01355", "pdf": "https://arxiv.org/pdf/2510.01355", "abs": "https://arxiv.org/abs/2510.01355", "authors": ["Robert Haslhofer"], "title": "Mean curvature flow through singularities", "categories": ["math.DG", "math.AP"], "comment": "submitted to the Proceedings of the ICM 2026", "summary": "We first give a general introduction to the mean curvature flow, and then\ndiscuss fundamental results established over the last 10 years that yield a\nprecise theory for the flow through singularities in $\\mathbb{R}^3$. With the\naim of developing a satisfying theory in higher dimensions, we then describe\nour recent classification of all noncollapsed singularities in $\\mathbb{R}^4$.\nFinally, we provide a detailed discussion of open problems and conjectures.", "AI": {"tldr": "This paper provides an overview of mean curvature flow theory, recent advances in singularity analysis in R\u00b3, classification of noncollapsed singularities in R\u2074, and discusses open problems.", "motivation": "To develop a comprehensive theory for mean curvature flow through singularities, particularly extending the precise theory from R\u00b3 to higher dimensions like R\u2074.", "method": "General introduction to mean curvature flow, analysis of fundamental results from the last decade, classification of noncollapsed singularities in R\u2074, and discussion of open problems.", "result": "Established a precise theory for mean curvature flow through singularities in R\u00b3 over the last 10 years, and achieved classification of all noncollapsed singularities in R\u2074.", "conclusion": "The paper presents significant progress in understanding mean curvature flow singularities, with successful classification in R\u2074 and identification of remaining challenges for higher dimensions."}}
{"id": "2510.02207", "pdf": "https://arxiv.org/pdf/2510.02207", "abs": "https://arxiv.org/abs/2510.02207", "authors": ["Adam Doliwa"], "title": "Non-commutative multiple bi-orthogonal polynomials: formal approach and integrability", "categories": ["nlin.SI", "cs.NA", "math-ph", "math.MP", "math.NA"], "comment": "16 pages", "summary": "We define the non-commutative multiple bi-orthogonal polynomial systems,\nwhich simultaneously generalize the concepts of multiple orthogonality, matrix\northogonal polynomials and of the bi-orthogonality. We present\nquasideterminantal expressions for such polynomial systems in terms of formal\nbi-moments. The normalization functions for such monic polynomials satisfy the\nnon-commutative Hirota equations, while the polynomials provide solution of the\ncorresponding linear system. This shows, in particular, that our polynomial\nsystems form a part of the theory of integrable systems. We study also a\nspecialization of the problem to non-commutative multiple orthogonal\npolynomials, what results in the corresponding Hankel-type quasideterminantal\nexpressions in terms of the moments. Moreover, such a reduction allows to\nintroduce in a standard way the discrete-time variable and gives rise to an\nintegrable system which is non-commutative version of the multidimensional\ndiscrete-time Toda equations.", "AI": {"tldr": "The paper introduces non-commutative multiple bi-orthogonal polynomial systems that generalize multiple orthogonality, matrix orthogonal polynomials, and bi-orthogonality, showing connections to integrable systems and discrete-time Toda equations.", "motivation": "To generalize concepts of multiple orthogonality, matrix orthogonal polynomials, and bi-orthogonality within a non-commutative framework, and explore their connections to integrable systems theory.", "method": "Define non-commutative multiple bi-orthogonal polynomial systems, present quasideterminantal expressions using formal bi-moments, study normalization functions satisfying non-commutative Hirota equations, and specialize to non-commutative multiple orthogonal polynomials.", "result": "The polynomial systems satisfy non-commutative Hirota equations and provide solutions to corresponding linear systems, establishing them as part of integrable systems theory. Specialization leads to non-commutative versions of multidimensional discrete-time Toda equations.", "conclusion": "The introduced non-commutative multiple bi-orthogonal polynomial systems form a significant extension of classical orthogonal polynomial theories and provide new connections to integrable systems, particularly through non-commutative versions of discrete-time Toda equations."}}
{"id": "2510.01936", "pdf": "https://arxiv.org/pdf/2510.01936", "abs": "https://arxiv.org/abs/2510.01936", "authors": ["Panu Lahti", "Julian Weigt"], "title": "The centered maximal operator removes the non-concave Cantor part from the gradient", "categories": ["math.CA", "math.AP", "42B25, 26B30"], "comment": null, "summary": "We study regularity of the centered Hardy--Littlewood maximal function $M f$\nof a function $f$ of bounded variation in $\\mathbb R^d$, $d\\in \\mathbb N$. In\nparticular, we show that at $|D^c f|$-a.e. point $x$ where $f$ has a\nnon-concave blow-up, it holds that $M f(x)>f^*(x)$. We further deduce from this\nthat if the variation measure of $f$ has no jump part and its Cantor part has\nnon-concave blow-ups, then BV regularity of $M f$ can be upgraded to Sobolev\nregularity.", "AI": {"tldr": "The paper studies regularity properties of the centered Hardy-Littlewood maximal function for functions of bounded variation in R^d, showing improved regularity conditions when the variation measure has specific blow-up properties.", "motivation": "To understand when the Hardy-Littlewood maximal function of a BV function exhibits improved regularity beyond BV, particularly upgrading to Sobolev regularity under certain conditions on the variation measure.", "method": "Analyzing the behavior of the maximal function at points where the function has non-concave blow-ups, and studying the relationship between the variation measure's structure (jump part, Cantor part) and the regularity of the maximal function.", "result": "Shows that at |D^c f|-a.e. point where f has a non-concave blow-up, M f(x) > f*(x). Furthermore, if the variation measure has no jump part and its Cantor part has non-concave blow-ups, then BV regularity of M f can be upgraded to Sobolev regularity.", "conclusion": "The structure of the variation measure, particularly the absence of jump parts and presence of non-concave blow-ups in the Cantor part, plays a crucial role in determining when the Hardy-Littlewood maximal function exhibits Sobolev regularity rather than just BV regularity."}}
{"id": "2510.01964", "pdf": "https://arxiv.org/pdf/2510.01964", "abs": "https://arxiv.org/abs/2510.01964", "authors": ["Andrea N\u00fctzi"], "title": "Perturbations of Minkowski spacetime with regular conformal compactification", "categories": ["gr-qc", "math.AP"], "comment": null, "summary": "We construct perturbations of Minkowski spacetime in general relativity, when\ngiven initial data that decays inverse polynomially to initial data of a Kerr\nspacetime towards spacelike infinity. We show that the perturbations admit a\nregular conformal compactification at null and timelike infinity, where the\ndegree of regularity increases linearly with the rate of decay of the initial\ndata to Kerr initial data. In particular, the compactification is smooth if the\ninitial data decays rapidly to Kerr initial data. This generalizes results of\nFriedrich, who constructed spacetimes with a smooth conformal compactification\nin the case when the initial data is identical to Kerr initial data on the\ncomplement of a compact set. Our results rely on a novel formulation of the\nEinstein equations about Minkowski spacetime introduced by the author, that\nallows one to formulate the dynamic problem as a quasilinear, symmetric\nhyperbolic PDE that is regular at null infinity and with null infinity being at\na fixed locus. It is not regular at spacelike infinity, due to the asymptotics\nof Kerr. Thus the main technical task is the construction of solutions near\nspacelike infinity, using tailored energy estimates. To accomplish this, we\norganize the equations according to homogeneity with respect to scaling about\nspacelike infinity, which identifies terms that are leading, respectively lower\norder, near spacelike infinity, with contributions from Kerr being lower order.", "AI": {"tldr": "The paper constructs perturbations of Minkowski spacetime in general relativity with initial data decaying polynomially to Kerr spacetime data, showing these perturbations admit regular conformal compactification at null and timelike infinity.", "motivation": "To generalize Friedrich's results on spacetimes with smooth conformal compactification from compactly supported perturbations to more general initial data that decays polynomially to Kerr initial data.", "method": "Uses a novel formulation of Einstein equations about Minkowski spacetime as a quasilinear symmetric hyperbolic PDE, regular at null infinity. Main technical work involves constructing solutions near spacelike infinity using tailored energy estimates and organizing equations by scaling homogeneity.", "result": "Perturbations admit regular conformal compactification at null and timelike infinity, with regularity increasing linearly with decay rate of initial data to Kerr data. Smooth compactification achieved for rapidly decaying initial data.", "conclusion": "Successfully extends Friedrich's results to more general initial data conditions, demonstrating that polynomial decay to Kerr initial data suffices for regular conformal compactification, with smoothness achieved for rapid decay."}}
{"id": "2510.02192", "pdf": "https://arxiv.org/pdf/2510.02192", "abs": "https://arxiv.org/abs/2510.02192", "authors": ["Sabine B\u00f6gli", "Sukrid Petpradittha", "Franti\u0161ek \u0160tampach"], "title": "On Lieb-Thirring inequalities for multidimensional Schr\u00f6dinger operators with complex potentials", "categories": ["math.SP", "math-ph", "math.AP", "math.MP", "35P15, 47A10, 47A75, 81Q12"], "comment": "24 pages", "summary": "We solve the open problem by Demuth, Hansmann, and Katriel announced in\n[Integr. Equ. Oper. Theory 75 (2013), 1-5] by a counter-example construction.\nThe problem concerns a possible generalisation of the Lieb-Thirring inequality\nfor Schr\\\"odinger operators in to the case of complex-valued potentials. A\ncounter-example has already been found for the one-dimensional case by the\nfirst and third authors in [J. Spectr. Theory 11 (2021), 1391-1413]. Here we\ngeneralise the counter-example to higher dimensions.", "AI": {"tldr": "The paper provides a counter-example to a proposed generalization of the Lieb-Thirring inequality for complex-valued potentials in higher dimensions, solving an open problem.", "motivation": "To address the open problem by Demuth, Hansmann, and Katriel regarding the generalization of Lieb-Thirring inequality to complex-valued potentials in higher dimensions, building on previous counter-example work in one dimension.", "method": "Construction of a counter-example that generalizes the one-dimensional case to higher dimensions.", "result": "Successfully constructed a counter-example showing that the proposed generalization of Lieb-Thirring inequality for complex-valued potentials does not hold in higher dimensions.", "conclusion": "The counter-example definitively resolves the open problem, demonstrating that the Lieb-Thirring inequality cannot be generalized as proposed for complex-valued potentials in higher dimensions."}}
{"id": "2510.02288", "pdf": "https://arxiv.org/pdf/2510.02288", "abs": "https://arxiv.org/abs/2510.02288", "authors": ["Sabine B\u00f6gli", "Sukrid Petpradittha"], "title": "Optimal Lieb-Thirring type inequalities for Schr\u00f6dinger and Jacobi operators with complex potentials", "categories": ["math.SP", "math-ph", "math.AP", "math.MP", "47B36, 34L40, 47A10, 47A75"], "comment": "28 pages", "summary": "We prove optimal Lieb-Thirring type inequalities for Schr\\\"odinger and Jacobi\noperators with complex potentials. Our results bound eigenvalue power sums\n(Riesz means) by the $L^p$ norm of the potential, where in contrast to the\nself-adjoint case, each term needs to be weighted by a function of the ratio of\nthe distance of the eigenvalue to the essential spectrum and the distance to\nthe endpoint(s) thereof. Our Lieb-Thirring type bounds only hold for integrable\nweight functions. To prove optimality, we establish divergence estimates for\nnon-integrable weight functions. The divergence rates exhibit a logarithmic or\neven polynomial gain compared to semiclassical methods (Weyl asymptotics) for\nreal potentials.", "AI": {"tldr": "Optimal Lieb-Thirring inequalities for Schr\u00f6dinger and Jacobi operators with complex potentials, bounding eigenvalue power sums by L^p norms with specific weighting functions.", "motivation": "To extend Lieb-Thirring inequalities from self-adjoint to complex potential cases, requiring new weighting schemes due to different eigenvalue behavior near essential spectrum boundaries.", "method": "Prove optimal bounds for integrable weight functions and establish divergence estimates for non-integrable cases, comparing with semiclassical methods.", "result": "Achieved optimal Lieb-Thirring type inequalities with weighted terms depending on eigenvalue distance to essential spectrum, showing improved divergence rates over real potential cases.", "conclusion": "Complex potentials require fundamentally different weighting approaches in Lieb-Thirring inequalities, with non-integrable weights exhibiting enhanced divergence behavior compared to semiclassical predictions."}}
{"id": "2510.02299", "pdf": "https://arxiv.org/pdf/2510.02299", "abs": "https://arxiv.org/abs/2510.02299", "authors": ["Bryan Dimler", "Chen-Kuan Lee"], "title": "Uniqueness in the Plateau problem for calibrated currents", "categories": ["math.DG", "math.AP"], "comment": null, "summary": "We show that every compactly supported calibrated integral current with\nconnected $C^{3,\\alpha}$ boundary is the unique solution to the oriented\nPlateau problem for its boundary data. This is proved as a consequence of the\nboundary regularity theory for area-minimizing currents and classical unique\ncontinuation principles adapted to the minimal surface system.", "AI": {"tldr": "Compactly supported calibrated integral currents with connected C\u00b3,\u03b1 boundaries are unique solutions to the oriented Plateau problem for their boundary data.", "motivation": "To establish uniqueness results for the oriented Plateau problem by leveraging boundary regularity and unique continuation principles.", "method": "Uses boundary regularity theory for area-minimizing currents and adapts classical unique continuation principles to the minimal surface system.", "result": "Proves that such currents are the unique solutions to the oriented Plateau problem for their given boundary data.", "conclusion": "The combination of boundary regularity and unique continuation ensures uniqueness in the oriented Plateau problem for these specific currents."}}
