<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 5]
- [math.AP](#math.AP) [Total: 13]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [nlin.PS](#nlin.PS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.DS](#cs.DS) [Total: 1]
- [physics.atom-ph](#physics.atom-ph) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [math-ph](#math-ph) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [stat.AP](#stat.AP) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A mesh-free, derivative-free, matrix-free, and highly parallel localized stochastic method for high-dimensional semilinear parabolic PDEs](https://arxiv.org/abs/2510.02635)
*Shuixin Fang,Changtao Sheng,Bihao Su,Tao Zhou*

Main category: math.NA

TL;DR: A mesh-free, derivative-free, matrix-free localized stochastic method for high-dimensional semilinear parabolic PDEs using FBSDE martingale formulation, local linear regression, and parallel particle computations.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of traditional deterministic methods that require global information, spatial meshes, and global basis functions, as well as derivative-dependent machine learning approaches with lengthy training.

Method: Four-component approach: (i) FBSDE martingale formulation, (ii) local linear regression with stochastic particles, (iii) decoupling strategy with matrix-free solver for ∇u computation, (iv) Newton iteration for nonlinear u system.

Result: Efficient computation of u and ∇u for dimensions d=100 to d=10000 on standard personal computers, with rigorous error bounds explicit in particle number and time step size.

Conclusion: The method extends practical solvability of ultra-high-dimensional PDEs while maintaining rigorous error control, ease of implementation, and parallelizability without specialized hardware.

Abstract: We develop a mesh-free, derivative-free, matrix-free, and highly parallel
localized stochastic method for high-dimensional semilinear parabolic PDEs. The
efficiency of the proposed method is built upon four essential components: (i)
a martingale formulation of the forward backward stochastic differential
equation (FBSDE); (ii) a small scale stochastic particle method for local
linear regression (LLR); (iii) a decoupling strategy with a matrix-free solver
for the weighted least-squares system used to compute $\nabla u$; (iv) a Newton
iteration for solving the univariate nonlinear system in $u$. Unlike
traditional deterministic methods that rely on global information, this
localized computational scheme not only provides explicit pointwise evaluations
of $u$ and $\nabla u$ but, more importantly, is naturally suited for
parallelization across particles. In addition, the algorithm avoids the need
for spatial meshes and global basis functions required by classical
deterministic approaches, as well as the derivative-dependent and lengthy
training procedures often encountered in machine learning. More importantly, we
rigorously analyze the error bound of the proposed scheme, which is fully
explicit in both the particle number $M$ and the time step size $\Delta t$.
Numerical results conducted for problem dimensions ranging from $d=100$ to
$d=10000$ consistently verify the efficiency and accuracy of the proposed
method. Remarkably, all computations are carried out efficiently on a standard
personal computer, without requiring any specialized hardware. These results
confirm that the proposed method is built upon a principled design that not
only extends the practical solvability frontier of ultra-high-dimensional PDEs
but also maintains rigorous error control and ease of implementation.

</details>


### [2] [Unconditionally positivity-preserving explicit order-one strong approximations of financial SDEs with non-Lipschitz coefficients](https://arxiv.org/abs/2510.02703)
*Xiaojuan Wu,Ruishu Liu,Jiaohao Xu*

Main category: math.NA

TL;DR: A novel explicit positivity-preserving numerical scheme for financial SDEs with non-Lipschitz coefficients, using Lamperti transformation and implicit correction terms to ensure unconditional positivity while maintaining strong convergence order 1.


<details>
  <summary>Details</summary>
Motivation: To develop numerical methods that preserve positivity for stochastic differential equations in finance with non-Lipschitz coefficients, which naturally have positive solutions but are challenging to simulate accurately.

Method: Uses Lamperti transformation and incorporates an implicit term c_{-1}Y_{n+1}^{-1} to guarantee unconditional positivity, plus a corrective operator for handling non-Lipschitz coefficients. The scheme is explicitly solvable by finding unique positive roots of quadratic equations.

Result: The proposed scheme achieves strong convergence with order 1 when applied to financial models like CIR process, Heston-3/2 volatility model, CEV process, and Ait-Sahalia model. Numerical experiments validate theoretical convergence results.

Conclusion: The developed scheme successfully provides an explicit, positivity-preserving numerical method for financial SDEs with non-Lipschitz coefficients, achieving first-order strong convergence while maintaining computational efficiency.

Abstract: In this paper, we are interested in positivity-preserving approximations of
stochastic differential equations (SDEs) with non-Lipschitz coefficients,
arising from computational finance and possessing positive solutions. By
leveraging a Lamperti transformation, we develop a novel, explicit, and
unconditionally positivity-preserving numerical scheme for the considered
financial SDEs. More precisely, an implicit term $c_{-1}Y_{n+1}^{-1}$ is
incorporated in the scheme to guarantee unconditional positivity preservation,
and a corrective operator is introduced in the remaining explicit terms to
address the challenges posed by non-Lipschitz (possibly singular) coefficients
of the transformed SDEs. By finding a unique positive root of a quadratic
equation, the proposed scheme can be explicitly solved and is shown to be
strongly convergent with order $1$, when used to numerically solve several
well-known financial models such as the CIR process, the Heston-3/2 volatility
model, the CEV process and the A\"it-Sahalia model. Numerical experiments
validate the theoretical findings.

</details>


### [3] [Linearizing a nonlinear eigenvalue problem with quadratic rational eigenvector nonlinearities](https://arxiv.org/abs/2510.02900)
*Victor Janssens,Karl Meerbergen,Wim Michiels*

Main category: math.NA

TL;DR: The paper proposes a linearization method for nonlinear eigenvalue problems with quadratic rational nonlinearities, converting them into linear multiparameter eigenvalue problems that can be solved using structure-exploiting algorithms.


<details>
  <summary>Details</summary>
Motivation: Existing methods for nonlinear eigenvalue problems with eigenvector nonlinearities (NEPv) rely on fixed-point iterations with limited global convergence understanding. The paper aims to develop more reliable and efficient solution methods for a specific class of NEPv.

Method: The authors propose a linearization approach that transforms NEPv with quadratic rational nonlinearities into linear multiparameter eigenvalue problems. These are then solved using a structure-exploiting Arnoldi algorithm to filter spurious solutions and accelerate convergence.

Result: The linearization method successfully converts the nonlinear eigenvalue problem into an equivalent system of generalized eigenvalue problems expressed through operator determinants, enabling more reliable solution finding.

Conclusion: The proposed linearization approach combined with structure-exploiting algorithms provides improved convergence and reliability for solving nonlinear eigenvalue problems with quadratic rational nonlinearities, particularly those inspired by the discretized Gross-Pitaevskii equation.

Abstract: Nonlinear eigenvalue problems with eigenvector nonlinearities (NEPv) are
algebraic eigenvalue problems whose matrix depends on the eigenvector.
Applications range from computational quantum mechanics to machine learning.
Due to its nonlinear behavior, existing methods almost exclusively rely on
fixed-point iterations, the global convergence properties of which are only
understood in specific cases. Recently, a certain class of NEPv with linear
rational eigenvector nonlinearities has been linearized, i.e., the spectrum of
the linear eigenvalue problem contains the eigenvalues of the NEPv. This linear
problem is solved using structure exploiting algorithms to improve both
convergence and reliability. We propose a linearization for a different class
of NEPv with quadratic rational nonlinearities, inspired by the discretized
Gross-Pitaevskii equation. The eigenvalues of this NEPv form a subset of the
spectrum of a linear multiparameter eigenvalue problem which is equivalent to a
system of generalized eigenvalue problems expressed in terms of operator
determinants. A structure exploiting Arnoldi algorithm is used to filter a
large portion of spurious solutions and to accelerate convergence.

</details>


### [4] [Stationarity preserving nodal Finite Element methods for multi-dimensional linear hyperbolic balance laws via a Global Flux quadrature formulation](https://arxiv.org/abs/2510.02928)
*Wasilij Barsukow,Mario Ricchiuto,Davide Torlo*

Main category: math.NA

TL;DR: New stabilized high-order Finite Element methods for hyperbolic balance laws that preserve steady states through Global Flux quadrature formulation, achieving super-convergence at steady state.


<details>
  <summary>Details</summary>
Motivation: Standard numerical methods fail to maintain equilibrium in hyperbolic balance laws, causing diffusion of stationary states that should remain unchanged.

Method: Reformulate spatial operator as mixed derivative of a single global flux quantity, treating all spatial derivatives and sources simultaneously. Combine with Gauss-Lobatto interpolation for super-convergence.

Result: Methods are stationarity preserving and achieve super-convergence at steady state. Numerical results confirm theoretical predictions and show significant benefits.

Conclusion: The Global Flux quadrature formulation successfully addresses the limitations of standard methods by preserving steady states and enabling super-convergent behavior.

Abstract: We consider linear, hyperbolic systems of balance laws in several space
dimensions. They possess non-trivial steady states, which result from the
equilibrium between derivatives of the unknowns in different directions, and
the sources. Standard numerical methods fail to account for this equilibrium,
and include stabilization that destroys it. This manifests itself in a
diffusion of states that are supposed to remain stationary. We derive new
stabilized high-order Finite Element methods based on a Global Flux quadrature:
we reformulate the entire spatial operator as a mixed derivative of a single
quantity, referred to as global flux. All spatial derivatives and the sources
are thus treated simultaneously, and our methods are stationarity preserving.
Additionally, when this formulation is combined with interpolation on
Gauss-Lobatto nodes, the new methods are super-convergent at steady state.
Formal consistency estimates, and strategies to construct well-prepared initial
data are provided. The numerical results confirm the theoretical predictions,
and show the tremendous benefits of the new formulation.

</details>


### [5] [Time-relaxation structure-preserving explicit low-regularity integrators for the nonlinear Schrödinger equation](https://arxiv.org/abs/2510.02963)
*Hang Li,Xicui Li,Katharina Schratz,Bin Wang*

Main category: math.NA

TL;DR: Novel explicit low-regularity exponential integrators for nonlinear Schrödinger equations using time-relaxation framework, providing explicit mass-conserving methods for low-regularity solutions.


<details>
  <summary>Details</summary>
Motivation: Existing symmetric or structure-preserving low-regularity integrators are typically implicit and computationally expensive. There is a need for explicit, mass-conserving methods that work well with low-regularity solutions.

Method: Time-relaxation framework combining resonance-based scheme for twisted variable with dynamically adjusted relaxation parameter to guarantee exact mass conservation. Methods are fully explicit and extendable to evolution equations with strongly continuous contraction semigroups.

Result: Numerical results demonstrate accuracy, robustness, and excellent long-time behavior under low-regularity conditions.

Conclusion: The proposed explicit low-regularity exponential integrators provide computationally efficient, mass-conserving alternatives to existing implicit methods, with broad applicability to various evolution equations.

Abstract: We propose and rigorously analyze a novel family of explicit low-regularity
exponential integrators for the nonlinear Schr\"odinger (NLS) equation, based
on a time-relaxation framework. The methods combine a resonance-based scheme
for the twisted variable with a dynamically adjusted relaxation parameter that
guarantees exact mass conservation. Unlike existing symmetric or
structure-preserving low-regularity integrators, which are typically implicit
and computationally expensive, the proposed methods are fully explicit,
mass-conserving, and well-suited for solutions with low regularity.
Furthermore, the schemes can be naturally extended to a broad class of
evolution equations exhibiting the structure of strongly continuous contraction
semigroups. Numerical results demonstrate the accuracy, robustness, and
excellent long-time behavior of the methods under low-regularity conditions.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [6] [$μ$-ellipticity and nonautonomous integrals](https://arxiv.org/abs/2510.02477)
*Cristiana De Filippis*

Main category: math.AP

TL;DR: The paper studies μ-ellipticity, a form of nonuniform ellipticity in calculus of variations, focusing on regularity properties of minimizers in nonautonomous settings.


<details>
  <summary>Details</summary>
Motivation: To understand regularity properties of minimizers in nonautonomous settings with μ-ellipticity, which presents challenging problems requiring sophisticated techniques.

Method: The paper develops delicate techniques to analyze regularity in nonuniform elliptic problems arising from calculus of variations.

Result: The research leads to the discovery of new irregularity phenomena in nonautonomous variational problems.

Conclusion: The study of μ-ellipticity in nonautonomous settings reveals complex regularity behavior and necessitates advanced analytical methods.

Abstract: $\mu$-ellipticity is a form of nonuniform ellipticity arising in various
contexts from the calculus of variations. Understanding regularity properties
of minimizers in the nonautonomous setting is a challenging task fostering the
development of delicate techniques and the discovery of new irregularity
phenomena.

</details>


### [7] [Scalar Approach to ARZ-Type Systems of Conservation Laws](https://arxiv.org/abs/2510.02536)
*Abraham Sylla*

Main category: math.AP

TL;DR: The paper analyzes 2x2 conservation law systems like GARZ traffic models using a splitting approach, combining discontinuous flux theory for the first equation with linear transport theory for the second equation.


<details>
  <summary>Details</summary>
Motivation: To develop effective solution methods for 2x2 conservation law systems with special structure, particularly generalized Aw-Rascle and Zhang (GARZ) traffic models, which have stronger coupling than simpler triangular systems like Keyfitz-Kranzer.

Method: A splitting approach that uses discontinuous flux theory advances for the first (nonlinear) equation and applies Panov's robust framework for linear transport equations with divergence-free coefficients for the second equation.

Result: Proposes a theoretical framework for solving GARZ systems by decomposing the coupled system into more manageable components using specialized mathematical tools for each equation type.

Conclusion: The splitting approach provides a sensible methodology for addressing complex 2x2 conservation law systems like GARZ models by leveraging existing robust theories for their individual components.

Abstract: We are interested in 2x2 systems of conservation laws of special structure,
including generalized Aw-Rascle and Zhang (GARZ) models for road traffic. The
simplest representative is the Keyfitz-Kranzer system, where one equation is
nonlinear and not coupled to the other, and the second equation is a linear
transport equation which coefficients depend on the solution of the first
equation. In GARZ systems, the coupling is stronger, they do not have the
triangular structure of Keyfitz-Kranzer.
  In our setting, we claim that it makes sense to address these systems via a
kind of splitting approach. Indeed, [E. Y. Panov, Instability in models
connected with fluid flows II, 2008] proposes a robust framework for solving
linear transport equations with divergence free coefficients. Our idea is to
use this theory for the second equation of GARZ systems, and to exploit
discontinuous flux theory advances for the first equation of the system.

</details>


### [8] [Stable determination of the nonlinear parameter in the non-diffusive Westervelt equation from the Dirichlet-to-Neumann map](https://arxiv.org/abs/2510.02553)
*Mike Wendels*

Main category: math.AP

TL;DR: Stable recovery of nonlinear parameter and sound speed from Dirichlet-to-Neumann map for Westervelt equation in (1+3)-dimensions, with numerical verification.


<details>
  <summary>Details</summary>
Motivation: The Westervelt equation models nonlinear acoustic waves for applications like medical ultrasound imaging, requiring stable parameter recovery for reconstruction feasibility.

Method: Use Dirichlet-to-Neumann map that associates boundary pressure profiles with resulting pressure fluctuations, under conditions of known reference sound speed and geometrical constraints.

Result: Proved stable recovery of nonlinear parameter and sound speed from boundary measurements in the non-diffusive Westervelt equation.

Conclusion: The stability result enables feasible reconstruction methods for nonlinear acoustic parameter identification in medical ultrasound applications.

Abstract: The Westervelt equation models the propagation of nonlinear acoustic waves in
a regime well-suited for applications such as medical ultrasound imaging. In
this work, we prove that the nonlinear parameter, as well as the sound speed,
can be stably recovered from the Dirichlet-to-Neumann map associated with the
non-diffusive Westervelt equation in (1+3)-dimensions. This result is essential
for the feasibility of reconstruction methods. The Dirichlet-to-Neumann map
encodes boundary measurements by associating a prescribed pressure profile on
the boundary with the resulting pressure fluctuations. We prove stability
provided the sound speed is a priori known to be close to a reference sound
speed and under certain geometrical conditions. We also verify the result
through numerical experiments.

</details>


### [9] [Well-Posedness for the Euler Equations in Function Spaces of Generalized Smoothness](https://arxiv.org/abs/2510.02626)
*Nicholas Harrison,Zachary Radke*

Main category: math.AP

TL;DR: The paper studies well-posedness of incompressible Euler equations in generalized function spaces with slowly varying functions, proving local existence under certain growth conditions and establishing a BKM-type criterion for global existence in 2D.


<details>
  <summary>Details</summary>
Motivation: To understand the well-posedness of incompressible Euler equations in more general function spaces beyond classical settings, specifically in Besov and Triebel-Lizorkin type spaces with slowly varying functions.

Method: Using generalized function spaces B^{s,ψ}_{p,q}(ℝ^d) and F^{s,ψ}_{p,q}(ℝ^d) where ψ is a slowly varying function in the Karamata sense and s=d/p+1, and analyzing the Euler equations within this framework.

Result: Proved that if ψ grows fast enough, there exists a local in time solution to the Euler equations. Also established a BKM-type criterion that enables global existence in two dimensions.

Conclusion: The analysis provides existence results for Euler equations in generalized function spaces with slowly varying functions, with specific conditions for local existence and a criterion for global existence in the 2D case.

Abstract: We consider the question of well-posedness for the incompressible Euler
equations in generalized function spaces of the type
$B^{s,\psi}_{p,q}(\mathbb{R}^d)$ and $F^{s,\psi}_{p,q}(\mathbb{R}^d)$ where
$\psi$ is a slowly varying function in the Karamata sense and $s=d/p+1$. We
prove that if $\psi$ grows fast enough, then there is a local in time solution
to the Euler equations. We also establish a BKM-type criterion that allows us
to obtain global existence in two dimensions.

</details>


### [10] [Error estimates for finite-dimensional approximations of Hamilton-Jacobi-Bellman equations on the Wasserstein space](https://arxiv.org/abs/2510.02652)
*Samuel Daudin,Joe Jackson,Benjamin Seeger*

Main category: math.AP

TL;DR: This paper quantifies the convergence rate of finite-dimensional approximations to Hamilton-Jacobi-Bellman equations on Wasserstein space with common noise, without requiring convex Hamiltonian assumptions.


<details>
  <summary>Details</summary>
Motivation: To address HJB equations on Wasserstein space with common noise where traditional mean field control representation formulas don't apply due to non-convex Hamiltonians, building on prior viscosity solutions work by Gangbo, Mayorga, and Święch.

Method: Uses a doubling of variables argument leveraging Lions' Hilbertian approach for HJB equations in Wasserstein space, with different techniques for 1D (exploiting rigid optimal transport structure) and higher dimensions (using simultaneous quantization estimates).

Result: Provides quantitative convergence bounds for approximating infinite-dimensional HJB equations on Wasserstein space by finite-dimensional HJB equations.

Conclusion: The paper successfully quantifies convergence rates for finite-dimensional approximations of HJB equations on Wasserstein space with common noise, overcoming challenges posed by non-convex Hamiltonians through innovative doubling arguments and quantization techniques.

Abstract: In this paper, we study a Hamilton-Jacobi-Bellman (HJB) equation set on the
Wasserstein space $\mathcal{P}_2(\mathbb{R}^d)$, with a second order term
arising from a purely common noise. We do not assume that the Hamiltonian is
convex in the momentum variable, which means that we cannot rely on
representation formulas coming from mean field control. In this setting,
Gangbo, Mayorga, and \'Swi\k{e}ch showed via viscosity solutions methods that
the HJB equation on $\mathcal{P}_2(\mathbb{R}^d)$ can be approximated by a
sequence of finite-dimensional HJB equations. Our main contribution is to
quantify this convergence result. The proof involves a doubling of variables
argument, which leverages the Hilbertian approach of P.L. Lions for HJB
equations in the Wasserstein space, rather than working with smooth metrics
which have been used to obtain similar results in the presence of idiosyncratic
noise. In dimension one, our doubling of variables argument is made relatively
simply by the rigid structure of one-dimensional optimal transport, but in
higher dimension the argument is significantly more complicated, and relies on
some estimates concerning the "simultaneous quantization" of probability
measures.

</details>


### [11] [Burgers equation with a twist: A study on rotational-form equations](https://arxiv.org/abs/2510.02761)
*Adam Larios*

Main category: math.AP

TL;DR: A new 3D equation derived from Navier-Stokes equations by eliminating Bernoulli pressure instead of velocity divergence, resulting in a globally well-posed system with same energy balance as NSE.


<details>
  <summary>Details</summary>
Motivation: To gain new insights into the challenging open problem of global well-posedness for 3D Navier-Stokes equations by focusing on the rotational form of nonlinearity.

Method: Derived a new 3D equation from incompressible Navier-Stokes equations by eliminating Bernoulli pressure, keeping only rotational form of nonlinearity. Also proposed rotational-form modification for 2D Kuramoto-Sivashinsky equations.

Result: Proved global existence, uniqueness, and regularity for viscous case; local existence for inviscid case with finite-time singularity examples; simulations show chaotic dynamics; established global well-posedness for modified 2D KSE.

Conclusion: The rotational-form approach provides a globally well-posed alternative to NSE with same energy balance, offering potential new insights into the challenging NSE well-posedness problem.

Abstract: A new three-dimensional (3D) equation is proposed, which is formed like
Burgers' equation by starting with the 3D incompressible Navier-Stokes
equations (NSE) and eliminating the pressure and the divergence-free
constraint, but instead the Bernoulli pressure is eliminated, leaving only the
rotational form of the nonlinearity. This results in a globally well-posed 3D
equation which has exactly the same energy balance as the 3D NSE. Moreover, we
show in simulations that the system seems to exhibit chaotic dynamics. In the
viscous case, we prove the global existence, uniqueness, and higher-order
regularity of solutions to this equation with no restriction on the initial
data other than smoothness. In the inviscid case, local existence holds, but we
give an example of a class of solutions with smooth initial data that develop a
singularity in finite time in both 2D and 3D. Moreover, a new numerical
algorithm is presented in the 2D case, and simulations are included to
illustrate the dynamics. In addition, a rotational-form modification for the 2D
Kuramoto-Sivashinsky equations (KSE) is proposed, and global well-posedness is
also established. We also discuss several related ``rotational form''
equations, and some pedagogical considerations. Global well-posedness for the
original 3D NSE and 2D KSE remains a challenging open problem, but it is hoped
that by focusing on the rotational term, new insight may be gained.

</details>


### [12] [Super-Liouville equation with a spinorial Yamabe type term](https://arxiv.org/abs/2510.02792)
*Lei Liu,Mingjun Wei*

Main category: math.AP

TL;DR: Analysis of the super-Liouville equation with spinorial Yamabe term, showing refined blow-up properties including energy identities for both spinor and function parts, and computation of local masses with two types of singularities.


<details>
  <summary>Details</summary>
Motivation: To study a natural generalization combining Liouville equation, super-Liouville equation and spinorial Yamabe type equation, and understand the qualitative properties of blow-up sequences in this extended framework.

Method: Establish refined qualitative properties for blow-up sequences, prove energy identities for both spinor and function components, and compute local masses at blow-up points.

Result: Energy identities are established for both spinor and function parts, local masses at blow-up points are computed, and a new phenomenon of two kinds of singularities and local masses is discovered due to the nonlinear spinorial Yamabe type term.

Conclusion: The spinorial Yamabe type term introduces novel features compared to the super-Liouville equation, specifically two distinct types of singularities and local masses, representing a significant extension of previous results.

Abstract: In this paper, we study the super-Liouville equation with a spinorial Yamabe
type term, a natural generalization of Liouville equation, super-Liouville
equation and spinorial Yamabe type equation. We establish some refined
qualitative properties for such a blow-up sequence. In particular, we show
energy identities not only for the spinor part but also for the function part.
Moreover, the local masses at a blow-up point are also computed. A new
phenomenon is that there are two kinds of singularities and local masses due to
the nonlinear spinorial Yamabe type term, which is different from
super-Liouville equation.

</details>


### [13] [Lyapunov exponents, entropy and mixing for DiPerna-Lions flows](https://arxiv.org/abs/2510.02921)
*Elia Brué,Maria Colombo,Carl Johan Peter Johansson*

Main category: math.AP

TL;DR: Establishes asymptotic form of Bressan's mixing conjecture using ergodic theory for incompressible DiPerna-Lions flows, relating Lyapunov exponents to metric entropy.


<details>
  <summary>Details</summary>
Motivation: To prove Bressan's mixing conjecture about asymptotic mixing behavior in fluid dynamics.

Method: Developed ergodic-theoretic framework for incompressible DiPerna-Lions flows with Oseledets-type decomposition and Ruelle's inequality.

Result: Obtained sharp bounds on asymptotic regularity propagation and mixing rates.

Conclusion: Successfully established the asymptotic form of Bressan's mixing conjecture using the developed framework.

Abstract: The main goal of this work is to establish an asymptotic form of Bressan's
mixing conjecture. To this end, we develop an ergodic-theoretic framework for
incompressible DiPerna-Lions flows. Lyapunov exponents are defined via an
Oseledets-type decomposition and related to metric entropy through a version of
Ruelle's inequality in this low-regularity setting. These tools yield sharp
bounds on asymptotic regularity propagation and mixing rates, leading to our
main result.

</details>


### [14] [On the existence of fibered three-dimensional perfect fluid equilibria without continuous Euclidean symmetry](https://arxiv.org/abs/2510.02955)
*Theodore D. Drivas,Tarek M. Elgindi,Daniel Ginsberg*

Main category: math.AP

TL;DR: Construction of 3D Euler steady states with no continuous symmetry but discrete m-fold symmetry and planar reflection symmetry, contradicting Grad's conjecture.


<details>
  <summary>Details</summary>
Motivation: To provide counterexamples to Grad's conjecture that only solutions with continuous symmetry can be fibered by pressure surfaces.

Method: Following Lortz's approach but adding discrete m-fold symmetry, constructing smooth steady states of ideal incompressible Euler equations in 3D with invariant cylindrical level sets of Bernoulli pressure.

Result: Successfully constructed family of smooth steady states with no continuous Euclidean symmetry but discrete m-fold symmetry and planar reflection symmetry, where all velocity orbits are closed.

Conclusion: These examples narrow the validity scope of Grad's conjecture by showing solutions without continuous symmetry can still be fibered by pressure surfaces.

Abstract: Following Lortz, we construct a family of smooth steady states of the ideal,
incompressible Euler equation in three dimensions that possess no continuous
Euclidean symmetry. As in Lortz, they do possess a planar reflection symmetry
and, as such, all the orbits of the velocity are closed. Different from Lortz,
our construction has a discrete m-fold symmetry and is foliated by invariant
cylindrical level sets of a non-degenerate Bernoulli pressure. Such examples
narrow the scope of validity of Grad's conjecture that the only solutions with
a continuous symmetry can be fibered by pressure surfaces.

</details>


### [15] [The epsilon-regularity theorem for Brakke flows near triple junctions](https://arxiv.org/abs/2510.02969)
*Salvatore Stuvard,Yoshihiro Tonegawa*

Main category: math.AP

TL;DR: ε-regularity theorem for k-dimensional Brakke flows near static multiplicity-one triple junctions, showing regular structure persists under weak mean curvature flow.


<details>
  <summary>Details</summary>
Motivation: To establish parabolic analogue to L. Simon's work on singular sets of stationary varifolds and confirm persistence of triple junction regular structure under weak mean curvature flow.

Method: Prove ε-regularity theorem with structural assumption on 1-dimensional slices orthogonal to junction's (k-1)-dimensional spine, which prohibits topological degeneracies.

Result: Regularity holds for codimension-one multi-phase flows (BV-Brakke flows) and flows with mod 3 integral current structure from Ilmanen's elliptic regularization.

Conclusion: Simon-type regularity holds unconditionally for fundamental classes of flows where triple junction singularities are expected.

Abstract: We establish the $\varepsilon$-regularity theorem for $k$-dimensional,
possibly forced, Brakke flows near a static, multiplicity-one triple junction.
This result provides the parabolic analogue to L. Simon's foundational work on
the singular set of stationary varifolds and confirms that the regular
structure of triple junctions persists under weak mean curvature flow. The
regularity holds provided the flow satisfies a mild structural assumption on
its 1-dimensional slices taken orthogonal to the junction's $(k-1)$-dimensional
spine, which prohibits certain topological degeneracies. We prove that this
assumption is automatically satisfied by two fundamental classes of flows where
such singularities are expected: codimension-one multi-phase flows, such as the
canonical $\mathrm{BV}$-Brakke flows constructed by the authors, and flows of
arbitrary codimension with the structure of a mod 3 integral current, which
arise from Ilmanen's elliptic regularization. For such flows, therefore, the
Simon type regularity holds unconditionally.

</details>


### [16] [Homogeneous steady states for the generalized surface quasi-geostrophic equations](https://arxiv.org/abs/2510.03009)
*Ken Abe,Javier Gómez-Serrano,In-Jee Jeong*

Main category: math.AP

TL;DR: Existence and non-existence of homogeneous self-similar solutions for generalized surface quasi-geostrophic equations with odd symmetric profiles and Fourier modes larger than m₀≥1.


<details>
  <summary>Details</summary>
Motivation: To explore the existence of non-trivial homogeneous solutions in gSQG equations, particularly for critical and supercritical regimes where local well-posedness is challenging.

Method: Analyze homogeneous solutions with stream function and vorticity of specific polar coordinate forms, assuming odd symmetric profiles with Fourier modes larger than m₀≥1, and determine parameter ranges for existence.

Result: Existence shown for -m₀-2s<β<-2s and 0<β<m₀ (with modified range for 0<s<1/2), and non-existence for -2s≤β≤0. First examples of self-similar solutions provided for SQG equations and more singular cases.

Conclusion: The study provides concrete examples of self-similar solutions in critical/supercritical regimes, advancing understanding of gSQG equations' solution structure, particularly for previously unaddressed parameter ranges.

Abstract: We consider homogeneous (stationary self-similar) solutions to the
generalized surface quasi-geostrophic (gSQG) equations parametrized by the
constant $0<s<1$, representing the 2D Euler equations ($s=1$), the SQG
equations $(s=1/2)$, and stationary equations ($s=0$); namely, solutions whose
stream function and vorticity are of the form \begin{align*}
\psi=\frac{w(\theta)}{r^{\beta}},\quad \omega=\frac{g(\theta)}{r^{\beta+2s}},
\end{align*} in polar coordinates $(r,\theta)$ with parameter $\beta\in
\mathbb{R}$. We explore a question on the existence of non-trivial homogeneous
solutions by assuming an odd symmetric profile $(w,g)$ with Fourier modes
larger than $m_0\geq 1$. We show existence of such solutions for
$-m_0-2s<\beta<-2s$ and $0<\beta<m_0$ ($1/2-s<\beta<m_0$ for $0<s<1/2$) and
non-existence of such solutions for $-2s\leq \beta\leq 0$. The main result
provides examples of self-similar solutions which belong to critical and
supercritical regimes for the local well-posedness of the gSQG equations for
$0<s<1$ and the first examples of self-similar solutions for the SQG equations
and the more singular equations $0<s\leq 1/2$ in the stationary setting.

</details>


### [17] [Stationary homogeneous solutions for the inviscid SQG equation](https://arxiv.org/abs/2510.03108)
*Miguel M. G. Pascual-Caballo*

Main category: math.AP

TL;DR: Existence of stationary nontrivial homogeneous solutions for SQG equation with infinite energy and generalized De Gregorio equation with α>1/2.


<details>
  <summary>Details</summary>
Motivation: To prove existence of stationary solutions for SQG equation with infinite energy (unbounded at infinity) and extend analysis to generalized De Gregorio equation.

Method: Mathematical analysis and proof techniques for establishing existence of stationary homogeneous solutions.

Result: Proved existence of stationary nontrivial homogeneous solutions for SQG equation with infinite energy and for generalized De Gregorio equation with α>1/2.

Conclusion: Successfully established existence results for stationary solutions in both SQG and generalized De Gregorio equations under specified conditions.

Abstract: In this paper, we prove existence of stationary nontrivial homogeneous
solutions for SQG equation with infinite energy (unbounded at the infinity).
Our analysis also covers the existence of stationary solutions for generalized
De Gregorio equation $w_t+\alpha uw_x=u_xw,\ u_x=Hw$ with $\alpha>\frac{1}{2}.$

</details>


### [18] [Well-posedness for the periodic Hyperbolic nonlinear Schrödinger equations](https://arxiv.org/abs/2510.03211)
*Engin Başakoğlu,Yuzhao Wang*

Main category: math.AP

TL;DR: Local well-posedness established for hyperbolic nonlinear Schrodinger equation in critical spaces using scale-invariant Strichartz estimates.


<details>
  <summary>Details</summary>
Motivation: To address the epsilon-loss of derivative in existing hyperbolic Strichartz estimates by Bourgain and Demeter and establish local well-posedness in critical spaces.

Method: Following Killip and Visan's approach, deriving scale-invariant Strichartz estimates for HNLS on both rational and irrational tori.

Result: Successfully removed the epsilon-loss of derivative from previous estimates and established local well-posedness in critical spaces.

Conclusion: The approach provides improved Strichartz estimates for HNLS that are scale-invariant and applicable to both rational and irrational tori, enabling local well-posedness in critical spaces.

Abstract: We establish local well-posedness for the hyperbolic nonlinear Schrodinger
equation (HNLS) in the critical spaces. Following the approach of Killip and
Visan, we derive scale-invariant Strichartz estimates for HNLS on both rational
and irrational tori, thereby removing the epsilon-loss of derivative present in
the hyperbolic Strichartz estimates of Bourgain and Demeter.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [19] [Fully automated inverse co-optimization of templates and block copolymer blending recipes for DSA lithography](https://arxiv.org/abs/2510.02715)
*Yuhao Zhou,Huangyan Shen,Qingliang Song,Qingshu Dong,Jianfeng Li,Weihua Li*

Main category: physics.comp-ph

TL;DR: A Gaussian descriptor with two parameters is proposed to characterize template shapes for directed self-assembly of block copolymers, using Bayesian optimization to co-optimize binary blends and templates for multi-hole patterns with excellent manufacturability.


<details>
  <summary>Details</summary>
Motivation: Directed self-assembly of block copolymers needs properly designed templates for precise circular hole fabrication at sub-7nm nodes, but parameterizing template shapes efficiently and ensuring manufacturability remain challenging problems.

Method: Proposed Gaussian descriptor with two parameters for template characterization, used AB/AB binary blends instead of pure diblock copolymers, and applied Bayesian optimization to co-optimize blend and template parameters with curvature constraints.

Result: BO with Gaussian descriptor efficiently yielded optimal templates for diverse multi-hole patterns with highly matched self-assembled morphologies, while ensuring superior manufacturability through curvature constraints. Blend parameters showed wide tunable windows even under high precision requirements.

Conclusion: The work provides valuable insights for advancing DSA technology and potentially propels its practical applications forward through efficient template optimization and improved manufacturability.

Abstract: The directed self-assembly (DSA) of block copolymers (BCPs) offers a highly
promising approach for the fabrication of contact holes or vertical
interconnect access at sub-7nm technology nodes. To fabricate circular holes
with precisely controlled size and positions, the self-assembly of block
copolymers requires guidance from a properly designed template. Effectively
parameterizing the template shape to enable efficient optimization remains a
critical yet challenging problem. Moreover, the optimized template must possess
excellent manufacturability for practical applications. In this work, we
propose a Gaussian descriptor for characterizing the template shape with only
two parameters. We further propose to use AB/AB binary blends instead of pure
diblock copolymer to improve the adaptability of the block copolymer system to
the template shape. The Bayesian optimization (BO) is applied to co-optimize
the binary blend and the template shape. Our results demonstrate that BO based
on the Gaussian descriptor can efficiently yield the optimal templates for
diverse multi-hole patterns, all leading to highly matched self-assembled
morphologies. Moreover, by imposing constraints on the variation of curvature
of the template during optimization, superior manufacturability is ensured for
each optimized template. It is noteworthy that each key parameter of the blend
exhibits a relatively wide tunable window under the requirement of rather high
precision. Our work provides valuable insights for advancing DSA technology,
and thus potentially propels its practical applications forward.

</details>


### [20] [A review on the Parameter Space Concept and its use for crystal structure determination](https://arxiv.org/abs/2510.02755)
*Matthias Zschornak,Muthu Vallinayagam,Melanie Nentwich,Dirk C. Meyer,Karl Fischer*

Main category: physics.comp-ph

TL;DR: Review of Parameter Space Concept (PSC) - a crystal structure determination method that maps diffraction data into geometric isosurfaces in higher-dimensional space, bypassing Fourier inversion and enabling precise structure determination with limited data.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of conventional Fourier inversion methods in crystal structure determination, especially when dealing with partial or limited diffraction data, by developing a geometric approach that can handle various types of experimental observations.

Method: PSC transforms diffraction amplitudes/intensities into piecewise analytic isosurfaces in a higher-dimensional orthonormal Cartesian space, reformulating crystal determination as finding intersection points of these geometric surfaces. Uses one-dimensional projections of atomic coordinates to construct full 3D structures.

Result: PSC enables exploration of homometric and non-homometric solutions in both centric and acentric structures with pm-level spatial resolution, even with limited diffraction reflections. Successfully demonstrated on synthetic structures and verified with realistic crystals.

Conclusion: PSC represents a promising alternative to conventional methods, offering theoretical foundations and computational strategies for future structure determination applications, with potential for broader use in experimental diffraction analysis.

Abstract: We present a comprehensive review of the emerging crystal structure
determination method Parameter Space Concept (PSC), which solves and refines
either partial or complete crystal structures by mapping each experimental or
theoretical observation as a geometric interpretation, bypassing the
conventional Fourier inversion. The PSC utilizes only a few \xray (equivalently
neutron) diffraction amplitudes or intensities and turns them into piecewise
analytic hyper-surfaces, called isosurfaces, embedded in a higher-dimensional
orthonormal Cartesian space (Parameter Space (PS)). It reformulates the crystal
determination task into a geometric interpretation, searching for a common
intersection point of different isosurfaces. The art of defining various kinds
of isosurfaces, based on signs, amplitude or intensity values, normalized
ratios, and ranking of reflections, offers multiple choices of adapting methods
in PSC based on available experimental or theoretical observations. The
elegance of PSC stems from one-dimensional projections of atomic coordinates,
enabling the construction of full three-dimensional crystal structures by
combining multiple projections. By these means, the user may explore homometric
and non-homometric solutions within both centric and acentric structures with
spatial resolution remarkably down to pm, even with a limited number of
diffraction reflections. Having demonstrated the potential of PSC for various
synthetic structures and exemplarily verified direct application to realistic
crystals, the origin and development of PSC methods are coherently discussed in
this review. Notably, this review emphasizes the theoretical foundations,
computational strategies, and potential extensions of PSC, outlining the
roadmap for future applications of PSC in the broader context of structure
determination from experimental diffraction observations.

</details>


<div id='nlin.PS'></div>

# nlin.PS [[Back]](#toc)

### [21] [Global bifurcation of localised 2D patterns emerging from spatial heterogeneity](https://arxiv.org/abs/2510.02867)
*Dan J. Hill,David J. B. Lloyd,Matthew R. Turner*

Main category: nlin.PS

TL;DR: Proves existence of fully localized 2D patterns in PDEs with spatial heterogeneities, using Swift-Hohenberg equation with radial potential to demonstrate local and global bifurcation of axisymmetric spots and dipole patterns.


<details>
  <summary>Details</summary>
Motivation: While 1D localized patterns from spatial heterogeneities are well-studied, proving existence of fully localized patterns from Turing instability in higher dimensions remains an open problem in pattern formation.

Method: Uses Swift-Hohenberg equation with radially-symmetric potential function, applies local bifurcation theory and analytic global bifurcation theory to continue solutions to large amplitude.

Result: Proves existence of local bifurcation branches of fully localized patterns, characterizes their stability and bifurcation structure, shows primary branch alternates between axisymmetric spot and non-axisymmetric dipole pattern depending on heterogeneity width.

Conclusion: Provides general approach to prove existence of fully localized multidimensional patterns in PDEs with compact spatial heterogeneities, solving key open problem in higher-dimensional pattern formation.

Abstract: We present a general approach to prove the existence, both locally and
globally in amplitude, of fully localised multi-dimensional patterns in partial
differential equations containing a compact spatial heterogeneity. While
one-dimensional localised patterns induced by spatial heterogeneities have been
well-studied, proving the existence of fully localised patterns emerging from a
Turing instability in higher dimensions remains a key open problem in pattern
formation. In order to demonstrate the approach, we consider the
two-dimensional Swift-Hohenberg equation, whose linear bifurcation parameter is
perturbed by a radially-symmetric potential function. In this case, the trivial
state is unstable in a compact neighbourhood of the origin and linearly stable
outside. We prove the existence of local bifurcation branches of fully
localised patterns, characterise their stability and bifurcation structure, and
then rigorously continue solutions to large amplitude via analytic global
bifurcation theory. Notably, the primary bifurcating branch in the
Swift-Hohenberg equation alternates between an axisymmetric spot and a
non-axisymmetric `dipole' pattern, depending on the width of the spatial
heterogeneity.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [22] [Market-Based Data Subset Selection -- Principled Aggregation of Multi-Criteria Example Utility](https://arxiv.org/abs/2510.02456)
*Ashish Jha,Valentin Leplat,AH Phan*

Main category: cs.LG

TL;DR: A market-based data selection method that prices training examples using prediction markets, with automatic signal aggregation, token budget control, and diversity enhancement.


<details>
  <summary>Details</summary>
Motivation: Current data selection methods combine heterogeneous utility signals (uncertainty, rarity, diversity) with ad hoc weights, lacking systematic aggregation and budget control.

Method: Cost-function prediction market (LMSR) for pricing examples, with topic-wise normalization, price-per-token rule for budget control, and lightweight diversity head for coverage.

Result: Achieves parity with strong baselines on GSM8K with reduced variance, competitive accuracy on AGNews with improved balance and stability, and minimal selection overhead (<0.1 GPU-hr).

Conclusion: The framework provides a unified approach for multi-signal data curation under fixed compute constraints, with transparent aggregation and interpretable parameters.

Abstract: Selecting a small yet useful subset of training data is hard because signals
of example utility (uncertainty, rarity, diversity, etc.) are heterogeneous and
typically combined with ad hoc weights. We propose a market-based selector that
prices each example via a cost-function prediction market (LMSR), signals act
as traders, a single liquidity parameter controls concentration, and topic-wise
normalization stabilizes calibration. Token budgets are handled explicitly by a
price-per-token rule $\rho=p/\ell^{\gamma}$, with $\gamma$ exposing an
interpretable length bias; a lightweight diversity head improves coverage. We
quantify coverage via topic cluster coverage and effective sample size. On the
theory side, we show that LMSR implements a maximum-entropy aggregation with
exponential weighting and a convex objective, yielding transparent knobs for
aggregation strength. Empirically, on GSM8K (60k-token budget) the market with
diversity achieves parity with strong single-signal baselines while reducing
seed variance and incurring $<\!0.1$ GPU-hr selection overhead; on AGNews at
kept=5-25\% the market (with light balancing) delivers competitive accuracy
with improved balance and stability. The framework unifies multi-signal data
curation under fixed compute for prompt-level reasoning and classification.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [23] [Even Faster Kernel Matrix Linear Algebra via Density Estimation](https://arxiv.org/abs/2510.02540)
*Rikhav Shah,Sandeep Silwal,Haike Xu*

Main category: cs.DS

TL;DR: This paper improves algorithms for kernel matrix computations using kernel density estimation (KDE), achieving better error dependence and runtime improvements over prior work.


<details>
  <summary>Details</summary>
Motivation: Existing algorithms for kernel matrix computations have limitations in their polynomial dependence on error tolerance ε and runtime dependence on data size n. The authors aim to leverage KDE queries to achieve more efficient computations.

Method: The authors develop improved algorithms using kernel density estimation (KDE) approaches for computing matrix-vector products, matrix-matrix products, spectral norm, and sum of entries of kernel matrices up to (1+ε) relative error.

Result: The new algorithms achieve reduced polynomial dependence on ε and improved dependence on n compared to existing best algorithms, particularly for computing the sum of all kernel matrix entries. The paper also provides conditional quadratic time hardness lower bounds.

Conclusion: KDE-based approaches can significantly improve kernel matrix computations, but there are fundamental limits to these methods as demonstrated by the provided lower bounds.

Abstract: This paper studies the use of kernel density estimation (KDE) for linear
algebraic tasks involving the kernel matrix of a collection of $n$ data points
in $\mathbb R^d$. In particular, we improve upon existing algorithms for
computing the following up to $(1+\varepsilon)$ relative error: matrix-vector
products, matrix-matrix products, the spectral norm, and sum of all entries.
The runtimes of our algorithms depend on the dimension $d$, the number of
points $n$, and the target error $\varepsilon$. Importantly, the dependence on
$n$ in each case is far lower when accessing the kernel matrix through KDE
queries as opposed to reading individual entries.
  Our improvements over existing best algorithms (particularly those of
Backurs, Indyk, Musco, and Wagner '21) for these tasks reduce the polynomial
dependence on $\varepsilon$, and additionally decreases the dependence on $n$
in the case of computing the sum of all entries of the kernel matrix.
  We complement our upper bounds with several lower bounds for related
problems, which provide (conditional) quadratic time hardness results and
additionally hint at the limits of KDE based approaches for the problems we
study.

</details>


<div id='physics.atom-ph'></div>

# physics.atom-ph [[Back]](#toc)

### [24] [Fast surrogate modelling of EIT in atomic quantum systems using LSTM neural networks](https://arxiv.org/abs/2510.02603)
*Isabel S. Burdon Hita,Óscar Iglesias-González,Gabriel M. Carral,Miguel Ferreira-Cao*

Main category: physics.atom-ph

TL;DR: LSTM neural network achieves 5000x speed-up in simulating optical quantum systems compared to traditional solvers, enabling real-time applications.


<details>
  <summary>Details</summary>
Motivation: Optical quantum system simulations are computationally intensive, creating bottlenecks for data fitting, parameter estimation, and real-time feedback applications.

Method: Developed a Long Short-Term Memory (LSTM) neural network as a surrogate model to replicate optical quantum system simulations, trained to match physics solver outputs.

Result: Achieved 5000x speed-up with near-unity agreement to physics solver, producing spectra in milliseconds instead of traditional computation times.

Conclusion: LSTM model serves as an effective surrogate tool for optical quantum system simulations, supporting real-time signal processing and feedback-based optimization.

Abstract: Simulations of optical quantum systems are essential for the development of
quantum technologies. However, these simulations are often computationally
intensive, especially when repeated evaluations are required for data fitting,
parameter estimation, or real-time feedback. To address this challenge, we
develop a Long Short-Term Memory neural network capable of replicating the
output of these simulations with high accuracy and significantly reduced
computational cost. Once trained, the surrogate model produces spectra in
milliseconds, providing a speed-up of 5000x relative to traditional numerical
solvers. We focus on applying this technique to Doppler-broadened
Electromagnetically Induced Transparency in a ladder-type scheme for
Rydberg-based sensing, achieving near-unity agreement with the physics solver
for resonant and off-resonant regimes. We demonstrate the effectiveness of the
LSTM model on this representative optical quantum system, establishing it as a
surrogate tool capable of supporting real-time signal processing and
feedback-based optimisation.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [25] [Improper-proper ferroelectric competition as a mechanism for multistate polarisation and ferrielectric-like behaviour](https://arxiv.org/abs/2510.02604)
*Cameron A. M Scott,Finlay D. Morrison,Nicholas. C. Bristowe*

Main category: cond-mat.mtrl-sci

TL;DR: Re-exploring Landau model shows improper ferroelectrics can switch between multiple polarization states when proper and improper instabilities compete, with hexagonal tungsten bronze materials as archetypal case.


<details>
  <summary>Details</summary>
Motivation: To understand how improper ferroelectrics can display switching behavior between multiple polarization states when proper and improper instabilities coexist and compete.

Method: Using first principles calculations and re-exploring a simple textbook Landau model describing improper ferroelectricity.

Result: Hexagonal tungsten bronze materials can switch between improper and proper phases, displaying triple hysteresis loop behavior akin to "ferrielectrics".

Conclusion: This functionality is ideal for creating non-volatile multistate systems for memory devices or neuromorphic computing.

Abstract: In this paper, we re-explore a simple textbook Landau model describing
improper ferroelectricity and show that in the limit where both proper and
improper instabilities exist and compete, improper ferroelectrics can display
switching between multiple polarisation states. Using first principles
calculations we highlight how the hexagonal tungsten bronze materials may be an
archetypal case, with the possibility to switch between improper and proper
phases. The resulting functional characteristics are akin to "ferrielectrics",
with switching behaviour in the form of a triple hysteresis loop. Such
functionality could be ideal for creating non-volatile multistate systems for
use in memory devices or as a backbone for neuromorphic computing.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [26] [A Hardware Accelerator for the Goemans-Williamson Algorithm](https://arxiv.org/abs/2510.02863)
*D. A. Herrera-Martí,E. Guthmuller,J. Fereyre*

Main category: cs.AR

TL;DR: Using extended floating point precision in Conjugate Gradient methods for convex optimization reduces time to solution for large Max-Cut problems.


<details>
  <summary>Details</summary>
Motivation: Max-Cut serves as a benchmark for optimization algorithms, and while local search provides average-case guarantees, convex semidefinite relaxation offers worst-case guarantees suitable for performance-critical applications.

Method: Incorporating extended floating point precision in algebraic subroutines (specifically Conjugate Gradient indirect matrix inversion) used in Interior Point Methods for convex optimization.

Result: Extended precision reduces time to solution by a factor that increases with system size when using indirect matrix inversion methods like Conjugate Gradient.

Conclusion: Extended floating point precision accelerates convex optimization algorithms for large-scale Max-Cut problems, with benefits scaling with problem size.

Abstract: The combinatorial problem Max-Cut has become a benchmark in the evaluation of
local search heuristics for both quantum and classical optimisers. In contrast
to local search, which only provides average-case performance guarantees, the
convex semidefinite relaxation of Max-Cut by Goemans and Williamson, provides
worst-case guarantees and is therefore suited to both the construction of
benchmarks and in applications to performance-critic scenarios.
  We show how extended floating point precision can be incorporated in
algebraic subroutines in convex optimisation, namely in indirect matrix
inversion methods like Conjugate Gradient, which are used in Interior Point
Methods in the case of very large problem sizes. Also, an estimate is provided
of the expected acceleration of the time to solution for a hardware
architecture that runs natively on extended precision. Specifically, when using
indirect matrix inversion methods like Conjugate Gradient, which have lower
complexity than direct methods and are therefore used in very large problems,
we see that increasing the internal working precision reduces the time to
solution by a factor that increases with the system size.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [27] [Adaptive randomized pivoting and volume sampling](https://arxiv.org/abs/2510.02513)
*Ethan N. Epperly*

Main category: stat.ML

TL;DR: This paper reinterprets the Adaptive Randomized Pivoting (ARP) algorithm for column subset selection through connections to volume sampling and active learning, leading to new analysis and faster implementations using rejection sampling.


<details>
  <summary>Details</summary>
Motivation: To provide new theoretical insights into the ARP algorithm by connecting it to volume sampling distributions and active learning approaches for linear regression.

Method: Reinterpretation of ARP algorithm through theoretical connections to volume sampling and active learning, with implementation improvements using rejection sampling techniques.

Result: New analysis framework for ARP algorithm and faster computational implementations achieved through rejection sampling methods.

Conclusion: The reinterpretation of ARP through volume sampling and active learning perspectives provides enhanced theoretical understanding and practical improvements in computational efficiency.

Abstract: Adaptive randomized pivoting (ARP) is a recently proposed and highly
effective algorithm for column subset selection. This paper reinterprets the
ARP algorithm by drawing connections to the volume sampling distribution and
active learning algorithms for linear regression. As consequences, this paper
presents new analysis for the ARP algorithm and faster implementations using
rejection sampling.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [28] [Nonmodal growth and optimal perturbations in magnetohydrodynamic shear flows](https://arxiv.org/abs/2510.03141)
*Adrian E. Fraser,Alexis K. Kaminski,Jeffrey S. Oishi*

Main category: physics.flu-dyn

TL;DR: Magnetic fields don't necessarily suppress Kelvin-Helmholtz instability as previously thought - perturbations can grow significantly even in sub-Alfvénic flows, challenging current astrophysical field strength inferences.


<details>
  <summary>Details</summary>
Motivation: To challenge the conventional understanding that strong magnetic fields completely suppress shear-driven turbulence in astrophysical flows, and to show that current field strength inferences based on presence/absence of fluctuations may be incorrect.

Method: Calculated maximum growth that small-amplitude perturbations can achieve in finite time for magnetized shear flows, comparing hydrodynamic and magnetized cases, and analyzing 2D vs 3D simulations.

Result: Perturbations can grow in energy by orders of magnitude even in sub-Alfvénic flows, magnetic fields introduce additional nonmodal growth mechanisms, and 2D simulations miss key aspects of these growth mechanisms.

Conclusion: Shear-driven turbulence is possible even with strong magnetic fields, challenging current astrophysical inferences about field strengths based on observed fluctuations.

Abstract: In astrophysical shear flows, the Kelvin-Helmholtz (KH) instability is
generally suppressed by magnetic tension provided a sufficiently strong
streamwise magnetic field. This is often used to infer upper (or lower) bounds
on field strengths in systems where shear-driven fluctuations are (or are not)
observed, on the basis that fluctuations cannot grow in the absence of linear
instability. On the contrary, by calculating the maximum growth that
small-amplitude perturbations can achieve in finite time for such a system, we
show that perturbations can grow in energy by orders of magnitude even when the
flow is sub-Alfv\'enic, suggesting that shear-driven turbulence is possible
even in the presence of strong magnetic fields, and challenging inferences from
the observed presence or absence of shear-driven fluctuations. We further show
that magnetic fields introduce additional nonmodal growth mechanisms relative
to the hydrodynamic case, and that 2D simulations miss key aspects of these
growth mechanisms.

</details>


### [29] [Comparison of Extended Lubrication Theories for Stokes Flow](https://arxiv.org/abs/2510.02595)
*Sarah Dennis,Thomas G. Fai*

Main category: physics.flu-dyn

TL;DR: A new formulation of extended lubrication theory is presented and compared with existing models and numerical Stokes solutions, showing suitability for various geometries while highlighting sensitivity to surface gradients and length scale ratios.


<details>
  <summary>Details</summary>
Motivation: Extended lubrication theory models are sensitive to large surface gradients that cause model assumptions to break down, necessitating improved formulations.

Method: Developed a new formulation of extended lubrication theory and compared it with existing models and numerical solutions to the Stokes equations across various fluid domain geometries.

Result: The new solution performs well for a wide range of geometries, but accuracy depends on both the magnitude of surface variation and the length scale ratio.

Conclusion: The proposed extended lubrication theory formulation is suitable for diverse geometries, though model accuracy remains dependent on surface gradient characteristics and domain proportions.

Abstract: Lubrication theory leverages the assumption of a long and thin fluid domain
to formulate a linearized approximation to the Navier-Stokes equations. Models
in extended lubrication theory consider relaxations of the thin film
assumption, leading to the inclusion of higher order terms. However, such
models are sensitive to large surface gradients which lead the assumptions of
the model to break down. In this paper, we present a formulation of extended
lubrication theory, and compare our models with several existing models, along
with the numerical solution to the Stokes equations. The error in pressure and
velocity is characterized for a variety of fluid domain geometries. Our results
indicate that the new solution is suitable for a wide range of geometries.
Nonetheless, the magnitude of surface variation and the length scale ratio are
both important factors influencing the accuracy of the extended lubrication
theory models.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [30] [Ohta-Kawasaki Model Reveals Patterns on Multicomponent Vesicles](https://arxiv.org/abs/2510.02688)
*Wangbo Luo,Zhonghua Qiao,Yanxiang Zhao*

Main category: math-ph

TL;DR: A mechanochemical modeling framework for multicomponent vesicle membranes that couples elastic bending mechanics with phase separation dynamics using Ohta-Kawasaki model.


<details>
  <summary>Details</summary>
Motivation: To understand shape deformation and pattern formation in multicomponent vesicle membranes by unifying curvature mechanics, microphase separation, and active forcing.

Method: Uses elastic bending model for membrane shape and Ohta-Kawasaki model for phase separation of activator proteins. Implements coupled dynamics with force-balanced equation for geometry and advection-reaction-diffusion equation on deformable membrane. Employs efficient spectral methods for 2D/3D simulations.

Result: Successfully reproduces a wide range of experimentally observed membrane morphologies from Baumgart et al. (2003).

Conclusion: The framework provides new insights into membrane-bounded multicomponent vesicle dynamics and serves as a practical platform for studying multicomponent biomembrane morphology.

Abstract: We present a new mechanochemical modeling framework to explore the shape
deformation and pattern formation in multicomponent vesicle membranes. In this
framework, the shape of the membrane is described by an elastic bending model,
while phase separation of membrane-bound activator proteins is determined by an
Ohta-Kawasaki (OK) model. The coupled dynamics consist of an overdamped
force-balanced equation for the membrane geometry and an OK-type
advection-reaction-diffusion equation on the deformable membrane. We implement
efficient spectral methods to simulate these dynamics in both two- and
three-dimensions. Numerical experiments show that the model successfully
reproduces a wide range of experimentally observed membrane morphologies
\cite{baumgart2003imaging}. Taken together, the framework unifies curvature
mechanics, microphase separation, and active forcing, providing new insight
into membrane-bounded multicomponent vesicle dynamics and a practical platform
for studying multicomponent biomembrane morphology.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [31] [Holographic Gaseous Lenses for High-Power Lasers](https://arxiv.org/abs/2510.02659)
*Devdigvijay Singh,Ke Ou,Sida Cao,Victor M. Perez-Ramirez,Harsha Rajesh,Debolina Chakraborty,Caleb Redshaw,Pelin Dedeler,Albertine Oudin,Michelle M. Wang,Julia M. Mikhailova,Livia Lancia,Caterina Riconda,Pierre Michel,Matthew R. Edwards*

Main category: physics.optics

TL;DR: Experimental demonstration of off-axis diffractive gaseous lenses that withstand extreme laser fluence and are immune to cumulative damage, enabling efficient manipulation of high-intensity laser pulses.


<details>
  <summary>Details</summary>
Motivation: Current high-energy pulsed lasers are limited by optical damage, requiring more robust optics for advances in high-intensity laser science.

Method: Used less than 8 mJ of energy from interfering ultraviolet laser pulses to holographically write millimeter-scale diffractive gas lenses into an ozone, oxygen, and carbon-dioxide gas mixture.

Result: Successfully focused, defocused, and collimated 532-nm nanosecond laser pulses with up to 210 mJ energy at efficiencies above 50% and fluences up to 35 J/cm². Also demonstrated efficient diffraction of 35-fs 800-nm pulses with stable performance at 10 Hz.

Conclusion: Gaseous optics may enable arbitrary, damage-resistant manipulation of intense light for next-generation ultra-high-power lasers, extending beyond lenses to other types of optics.

Abstract: The capabilities of the world's highest energy and peak-power pulsed lasers
are limited by optical damage, and further advances in high-intensity laser
science will require optics that are substantially more robust than existing
components. We describe here the experimental demonstration of off-axis
diffractive gaseous lenses capable of withstanding extreme laser fluence and
immune to cumulative damage. We used less than 8 mJ of energy from interfering
ultraviolet laser pulses to holographically write millimeter-scale diffractive
gas lenses into an ozone, oxygen, and carbon-dioxide gas mixture. These lenses
allowed us to focus, defocus, and collimate 532-nm nanosecond laser pulses with
up to 210 mJ of energy at efficiencies above 50% and fluences up to 35
J/cm$^2$. We also show that the gas lenses have sufficient bandwidth to
efficiently diffract 35-fs 800-nm pulses and that beam pointing, divergence,
and diffraction efficiency are stable while operating at 10 Hz. These
diffractive lenses are simple holograms, and the principles demonstrated here
could be extended to other types of optics, suggesting that gaseous optics may
enable arbitrary, damage-resistant manipulation of intense light for
next-generation ultra-high-power lasers.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [32] [Data-Driven Bed Occupancy Planning in Intensive Care Units Using $M_t/G_t/\infty$ Queueing Models](https://arxiv.org/abs/2510.02852)
*Maryam Akbari-Moghaddam,Douglas G. Down,Na Li,Catherine Eastwood,Ayman Abou Mehrem,Alexandra Howlett*

Main category: stat.AP

TL;DR: Proposes a data-driven framework using M_t/G_t/∞ queueing model for ICU capacity planning, showing static heuristics like 85% occupancy rule are inadequate for time-varying demand.


<details>
  <summary>Details</summary>
Motivation: Hospitals struggle with ICU capacity planning under demand uncertainty. Traditional methods assume fixed parameters and fail to capture real occupancy dynamics, leading to frequent overcapacity situations even when utilization targets are met.

Method: Uses M_t/G_t/∞ queueing model with time-varying arrival rates and empirically estimated length-of-stay distributions. Combines statistical decomposition and parametric distribution fitting to capture temporal patterns in ICU admissions and LOS.

Result: Analysis of neonatal ICU data shows static heuristics are unreliable in fluctuating demand environments. Demonstrates importance of modeling LOS variability for accurate bed need estimation.

Conclusion: The methodology provides interpretable, data-informed support for healthcare capacity planning and generalizes to various ICU settings facing rising demand and limited capacity.

Abstract: Hospitals struggle to make effective long-term capacity planning decisions
for intensive care units (ICUs) under uncertainty in future demand. Admission
rates fluctuate over time due to temporal factors, and length of stay (LOS)
distributions vary with patient heterogeneity, hospital location, case mix, and
clinical practices. Common planning approaches rely on steady-state queueing
models or heuristic rules that assume fixed parameters, but these methods often
fall short in capturing real-world occupancy dynamics. One widely used example
is the 85\% occupancy rule, which recommends maintaining average utilization
below this level to ensure responsiveness; however, this rule is based on
stationary assumptions and may be unreliable when applied to time-varying
systems. Our analysis shows that even when long-run utilization targets are
met, day-to-day occupancy frequently exceeds 100\% capacity.
  We propose a data-driven framework for estimating ICU bed occupancy using an
$M_t/G_t/\infty$ queueing model, which incorporates time-varying arrival rates
and empirically estimated LOS distributions. The framework combines statistical
decomposition and parametric distribution fitting to capture temporal patterns
in ICU admissions and LOS. We apply it to multi-year data from neonatal ICUs
(NICUs) in Calgary as a case study. Several capacity planning scenarios are
evaluated, including average-based thresholds and surge estimates from Poisson
overflow approximations. Results demonstrate the inadequacy of static
heuristics in environments with fluctuating demand and highlight the importance
of modeling LOS variability when estimating bed needs. Although the case study
focuses on NICUs, the methodology generalizes to other ICU settings and
provides interpretable, data-informed support for healthcare systems facing
rising demand and limited capacity.

</details>
