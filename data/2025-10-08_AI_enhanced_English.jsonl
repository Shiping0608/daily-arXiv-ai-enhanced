{"id": "2510.05331", "pdf": "https://arxiv.org/pdf/2510.05331", "abs": "https://arxiv.org/abs/2510.05331", "authors": ["Gabriel Barrenechea", "Abner J. Salgado"], "title": "Finite element approximation to linear, second order, parabolic problems with $L^1$ data", "categories": ["math.NA", "cs.NA", "65N12, 65N30, 35A35, 35D99, 35K20"], "comment": null, "summary": "We consider the approximation to the solution of the initial boundary value\nproblem for the heat equation with right hand side and initial condition that\nmerely belong to $L^1$. Due to the low integrability of the data, to guarantee\nwell-posedness, we must understand solutions in the renormalized sense. We\nprove that, under an inverse CFL condition, the solution of the standard\nimplicit Euler scheme with mass lumping converges, in\n$L^\\infty(0,T;L^1(\\Omega))$ and $L^q(0,T;W^{1,q}_0(\\Omega))$\n($q<\\tfrac{d+2}{d+1}$), to the renormalized solution of the problem.", "AI": {"tldr": "The paper analyzes convergence of implicit Euler scheme with mass lumping for heat equation with L^1 data, proving convergence to renormalized solution under inverse CFL condition.", "motivation": "To handle heat equations with low integrability data (L^1 right hand side and initial conditions) where standard solutions may not be well-posed, requiring renormalized solutions for well-posedness.", "method": "Uses standard implicit Euler scheme with mass lumping under an inverse CFL condition to approximate the renormalized solution of the heat equation.", "result": "Proves convergence in L^\u221e(0,T;L^1(\u03a9)) and L^q(0,T;W^{1,q}_0(\u03a9)) for q < (d+2)/(d+1) to the renormalized solution.", "conclusion": "The implicit Euler scheme with mass lumping provides a valid numerical approximation for heat equations with L^1 data when solutions are understood in the renormalized sense."}}
{"id": "2510.05350", "pdf": "https://arxiv.org/pdf/2510.05350", "abs": "https://arxiv.org/abs/2510.05350", "authors": ["Ian Moore", "Anthony Gruber", "Chris Wentland", "Irina Tezaur"], "title": "Domain Decomposition-Based Coupling of High-Fidelity Finite Element and Reduced Order Operator Inference Models Using the Schwarz Alternating Method", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We propose a novel hybrid domain decomposition method that couples\nsub-domain-local high-fidelity finite element (FE) models with reduced order\nmodels (ROMs) using the Schwarz alternating method. By integrating the\nnoninstrusive Operator Inference (OpInf) ROM, our approach accelerates the\nSchwarz process while allowing for geometry and mesh flexibility. We\ndemonstrate the effectiveness of the new OpInf-FE method on a\nconvection-dominated convection-diffusion-reaction problem, achieving stable\nand accurate predictive solutions while improving the ROM training process.", "AI": {"tldr": "Hybrid domain decomposition method coupling finite element models with reduced order models using Schwarz alternating method for accelerated computation with geometry flexibility.", "motivation": "To accelerate the Schwarz process while maintaining geometry and mesh flexibility in solving complex PDE problems.", "method": "Couples sub-domain-local high-fidelity FE models with non-intrusive Operator Inference ROMs using Schwarz alternating method.", "result": "Achieved stable and accurate predictive solutions for convection-dominated convection-diffusion-reaction problem with improved ROM training process.", "conclusion": "The OpInf-FE method effectively accelerates Schwarz process while enabling geometry flexibility and stable solutions for complex PDE problems."}}
{"id": "2510.05360", "pdf": "https://arxiv.org/pdf/2510.05360", "abs": "https://arxiv.org/abs/2510.05360", "authors": ["Daozhi Han", "Xiaoming Wang"], "title": "A highly efficient second-order accurate long-time dynamics preserving scheme for some geophysical fluid models", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We develop and analyze a highly efficient, second-order time-marching scheme\nfor infinite-dimensional nonlinear geophysical fluid models, designed to\naccurately approximate invariant measures-that is, the stationary statistical\nproperties (or climate) of the underlying dynamical system. Beyond second-order\naccuracy in time, the scheme is particularly well suited for long-time\nsimulations due to two key features: it requires solving only a fixed symmetric\npositive-definite linear system with constant coefficients at each step; and it\nguarantees long-time stability, producing uniformly bounded solutions in time\nfor any bounded external forcing, regardless of initial data. For prototypical\nmodels such as the barotropic quasi-geostrophic equation, the method preserves\ndissipativity, ensuring that numerical solutions remain bounded in a function\nspace compactly embedded in the phase space as time tends to infinity.\nLeveraging this property, we rigorously prove convergence of both global\nattractors and invariant measures of the discrete system to those of the\ncontinuous model in the vanishing time-step limit. A central innovation of the\nmethod is a mean-reverting scalar auxiliary variable (mr-SAV) formulation,\nwhich preserves the dissipative structure of externally forced systems within\nan appropriate phase space. For the infinite-dimensional models considered, we\nadditionally employ fractional-order function spaces to establish compactness\nof numerical solutions in topologies compatible with the phase space.", "AI": {"tldr": "A second-order time-marching scheme for geophysical fluid models that efficiently approximates invariant measures and ensures long-time stability with minimal computational cost per step.", "motivation": "To develop an efficient numerical method for long-time simulations of geophysical fluid models that accurately captures the stationary statistical properties (climate) of the underlying dynamical system while maintaining computational efficiency.", "method": "Uses a mean-reverting scalar auxiliary variable (mr-SAV) formulation that preserves dissipative structure, requires solving only a fixed symmetric positive-definite linear system with constant coefficients at each step, and employs fractional-order function spaces for compactness.", "result": "The scheme achieves second-order accuracy in time, guarantees long-time stability with uniformly bounded solutions, preserves dissipativity for models like the barotropic quasi-geostrophic equation, and ensures numerical solutions remain bounded in compactly embedded function spaces.", "conclusion": "The method rigorously proves convergence of both global attractors and invariant measures from discrete to continuous systems in the vanishing time-step limit, making it particularly suitable for climate simulations and long-time statistical analysis of geophysical flows."}}
{"id": "2510.05368", "pdf": "https://arxiv.org/pdf/2510.05368", "abs": "https://arxiv.org/abs/2510.05368", "authors": ["Nicol\u00e1s A. Barnafi", "Felipe Lepe", "Francisca Mu\u00f1oz Riquelme"], "title": "Finite element analysis of an eigenvalue problem arising from neutron transport", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In two and three dimensions, we analyze a finite element method to\napproximate the solutions of an eigenvalue problem arising from neutron\ntransport. We derive the eigenvalue problem of interest, which results to be\nnon-symmetric. Under a standard finite element approximation based on piecewise\npolynomials of degree $k \\geq 1$, and under the framework of the compact\noperators theory, we prove convergence and error estimates of the proposed\nmethod. We report a series of numerical tests in order confirm the theoretical\nresults.", "AI": {"tldr": "Analysis of a finite element method for neutron transport eigenvalue problems in 2D and 3D, proving convergence and error estimates for piecewise polynomial approximations.", "motivation": "To develop and analyze a finite element method for approximating solutions to non-symmetric eigenvalue problems arising from neutron transport.", "method": "Finite element approximation using piecewise polynomials of degree k \u2265 1, analyzed within the framework of compact operators theory.", "result": "Proved convergence and derived error estimates for the proposed method, with numerical tests confirming theoretical results.", "conclusion": "The finite element method is effective for solving neutron transport eigenvalue problems, with theoretical convergence and error estimates validated by numerical experiments."}}
{"id": "2510.05274", "pdf": "https://arxiv.org/pdf/2510.05274", "abs": "https://arxiv.org/abs/2510.05274", "authors": ["D. Simeoni", "G. Parise", "A. R. Rossi", "A. Frazzitta", "F. Guglietta", "M. Sbragaglia"], "title": "A note on thermal effects in non-linear models for plasma-based acceleration", "categories": ["physics.plasm-ph", "physics.acc-ph"], "comment": null, "summary": "We investigate the impact of a non-negligible background temperature on\nrelativistic plasma wakefields generated when a beam of charged particles\npasses through a neutral plasma at rest. Our analysis focuses on the blowout\nregime, where the plasma response is highly non-linear: plasma electrons are\nradially blown out and expelled away from the propagation axis of the beam\nparticles, creating a region (bubble) of ions without electrons. Our study\nbuilds upon earlier investigations for non-linear models of plasma wakefields\ndeveloped neglecting plasma temperature. In the presence of a non-zero\nbackground temperature, we characterize the bubble in terms of its transversal\nand longitudinal sizes as a function of the temperature. Model predictions and\nparametrizations are studied in combination with PIC simulations, and correctly\nreproduce the temperature induced contraction of both the longitudinal and\ntransverse bubble sizes.", "AI": {"tldr": "Study shows how non-zero background temperature affects relativistic plasma wakefields in the blowout regime, causing contraction of both longitudinal and transverse bubble sizes.", "motivation": "To understand the impact of non-negligible background temperature on plasma wakefields, building on previous models that neglected temperature effects.", "method": "Combined theoretical modeling with PIC simulations to characterize bubble size changes as a function of temperature in the blowout regime.", "result": "Non-zero background temperature causes contraction of both longitudinal and transverse bubble sizes, with model predictions validated by PIC simulations.", "conclusion": "Background temperature significantly affects plasma wakefield bubble dimensions, with both transverse and longitudinal sizes decreasing as temperature increases."}}
{"id": "2510.05409", "pdf": "https://arxiv.org/pdf/2510.05409", "abs": "https://arxiv.org/abs/2510.05409", "authors": ["Paulo L. Dattori da Silva", "Andr\u00e9 Pedroso Kowacs"], "title": "Directional Poincar\u00e9 inequality on compact Lie groups", "categories": ["math.AP", "Primary: 35A23, 35A01. Secondary: 43A77, 22E30"], "comment": null, "summary": "We extend the directional Poincar\\'e inequality on the torus, introduced by\nSteinerberger in [Ark. Mat. 54 (2016), pp. 555--569], to the setting of compact\nLie groups. We provide necessary and sufficient conditions for the existence of\nsuch an inequality based on estimates on the eigenvalues of the global symbol\nof the corresponding vector field. We also prove that such refinement of the\nPoincar\\'e inequality holds for a left-invariant vector field on a compact Lie\ngroup $G$ if and only if the vector field is globally solvable, and extend this\nequivalence to tube-type vector fields on $\\mathbb{T}^1\\times G$.", "AI": {"tldr": "Extension of directional Poincar\u00e9 inequality from torus to compact Lie groups, with conditions based on vector field eigenvalues and global solvability.", "motivation": "To generalize Steinerberger's directional Poincar\u00e9 inequality from the torus setting to the more general framework of compact Lie groups.", "method": "Analyze eigenvalues of the global symbol of vector fields and establish connections between inequality existence and global solvability of vector fields.", "result": "Found necessary and sufficient conditions for directional Poincar\u00e9 inequality existence based on vector field eigenvalues. Proved equivalence between inequality holding and global solvability for left-invariant vector fields.", "conclusion": "Directional Poincar\u00e9 inequality extends to compact Lie groups, with existence equivalent to global solvability of the vector field, and extends further to tube-type vector fields on T\u00b9\u00d7G."}}
{"id": "2510.05282", "pdf": "https://arxiv.org/pdf/2510.05282", "abs": "https://arxiv.org/abs/2510.05282", "authors": ["Xavier Andrade", "Jacopo Simoni", "Yuan Ping", "Tadashi Ogitsu", "Alfredo A. Correa"], "title": "SHarmonic: A fast and accurate implementation of spherical harmonics for electronic-structure calculations", "categories": ["physics.comp-ph", "cond-mat.other", "cs.MS", "physics.chem-ph"], "comment": "13 pages, 2 figures. The code can be downloaded from\n  https://gitlab.com/npneq/sharmonic", "summary": "The authors present SHarmonic, a new implementation of the spherical\nharmonics targeted for electronic-structure calculations. Their approach is to\nuse explicit formulas for the harmonics written in terms of normalized\nCartesian coordinates. This approach results in a code that is as precise as\nother implementations while being at least one order of magnitude more\ncomputationally efficient. The library can run on graphics processing units\n(GPUs) as well, achieving an additional order of magnitude in execution speed.\nThis new implementation is simple to use and is provided under an open source\nlicense, it can be readily used by other codes to avoid the error-prone and\ncumbersome implementation of the spherical harmonics.", "AI": {"tldr": "SHarmonic is a new spherical harmonics implementation for electronic-structure calculations that uses explicit formulas with normalized Cartesian coordinates, achieving high precision with significantly better computational efficiency and GPU acceleration.", "motivation": "To create a more computationally efficient and precise implementation of spherical harmonics for electronic-structure calculations, avoiding error-prone and cumbersome implementations in other codes.", "method": "Uses explicit formulas for spherical harmonics written in terms of normalized Cartesian coordinates, enabling GPU acceleration and optimized computational performance.", "result": "The implementation is as precise as other methods while being at least one order of magnitude more computationally efficient, with GPU execution providing an additional order of magnitude speed improvement.", "conclusion": "SHarmonic provides a simple, open-source library that offers high precision and significant performance improvements for spherical harmonics calculations in electronic-structure codes."}}
{"id": "2510.05407", "pdf": "https://arxiv.org/pdf/2510.05407", "abs": "https://arxiv.org/abs/2510.05407", "authors": ["Ram Manohar", "S. M. Mallikarjuaniah"], "title": "A convergent adaptive finite element method for a phase-field model of dynamic fracture", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We propose and analyze an adaptive finite element method for a phase-field\nmodel of dynamic brittle fracture. The model couples a second-order hyperbolic\nequation for elastodynamics with the Ambrosio-Tortorelli regularization of the\nFrancfort-Marigo variational fracture energy, which circumvents the need for\nexplicit crack tracking. Our numerical scheme combines a staggered\ntime-stepping algorithm with a variational inequality formulation to strictly\nenforce the irreversibility of damage. The mesh adaptation is driven by a\nresidual-based a posteriori-type estimator, enabling efficient resolution of\nthe evolving fracture process zone. The main theoretical contribution is a\nrigorous convergence analysis, where we prove that the sequence of discrete\nsolutions generated by the AFEM converges (up to a tolerance) to a critical\npoint of the governing energy functional. Numerical experiments for a\ntwo-dimensional domain containing an edge-crack under dynamic anti-plane shear\nloading demonstrate our method's capability of autonomously capturing complex\nphenomena, including crack branching and tortuosity, with significant\ncomputational savings over uniform refinement.", "AI": {"tldr": "An adaptive finite element method for dynamic brittle fracture using phase-field modeling with mesh adaptation driven by residual-based estimators, enabling efficient capture of complex fracture phenomena.", "motivation": "To develop an efficient numerical method for dynamic brittle fracture that avoids explicit crack tracking and can capture complex phenomena like crack branching and tortuosity.", "method": "Combines staggered time-stepping with variational inequality formulation for damage irreversibility, using adaptive finite elements with residual-based a posteriori estimators for mesh refinement.", "result": "Proved rigorous convergence of discrete solutions to critical points of energy functional, demonstrated capability to capture complex fracture patterns with computational savings over uniform refinement.", "conclusion": "The proposed adaptive finite element method provides an efficient and rigorous approach for simulating dynamic brittle fracture with complex crack patterns while maintaining mathematical guarantees."}}
{"id": "2510.05287", "pdf": "https://arxiv.org/pdf/2510.05287", "abs": "https://arxiv.org/abs/2510.05287", "authors": ["S. Ku", "C. S. Chang", "R. Hager", "L. W. Schmitz", "A. O. Nelson"], "title": "Difference in Neoclassical Edge Flows Between Strongly Negative and Positive Triangularities in the XGC Gyrokinetic Simulation", "categories": ["physics.plasm-ph"], "comment": "17 pages, 7 figures", "summary": "The neoclassical baseline study of a strongly negative triangularity (NT)\nplasma and the corresponding positive triangularity plasma is performed using\nthe edge-specialized, total-f gyrokinetic code XGC. A DIII-D-like plasma is\nused, based on the negative triangularity discharge of DIII-D \\#193793. An\nartificial positive triangularity (PT) equilibrium has been constructed to\ncompare the edge rotation physics at the same triangularity strength, but with\nopposite sign, while keeping the same elongation and other geometric\nparameters. Carbon(+6) ions are added to the deuterium plasma at an\nexperimentally relevant level. By using the experimental profile of carbon\ntoroidal rotation profile as an input, XGC finds that the deuteron rotation is\nsignificantly different from the carbon rotation at the inboard and outboard\nmidplanes, mostly caused by the difference in the Pfirsch-Schluter rotation.\nMore importantly, significant difference in the X-point orbit loss physics,\nthus the rotation source, is found between the positive and negative\ntriangularity equilibrium models. However, it is also found that the agreement\nbetween the present neoclassical simulation and the experimental NT data is\nvalidated only within the middle of pedestal slope, indicating the importance\nof edge turbulence. This study could establish baseline for the multiphysics,\nmultiscale studies that include turbulence of negative triangularity plasmas.", "AI": {"tldr": "Neoclassical simulation comparing negative and positive triangularity plasmas shows significant differences in X-point orbit loss physics and rotation sources, with validation limited to middle pedestal slope.", "motivation": "To establish a baseline for multiphysics studies of negative triangularity plasmas by comparing edge rotation physics between positive and negative triangularity configurations.", "method": "Used XGC gyrokinetic code to simulate DIII-D-like plasma with carbon ions, comparing artificial positive triangularity equilibrium with experimental negative triangularity discharge while keeping other geometric parameters constant.", "result": "Found significant differences in deuteron vs carbon rotation due to Pfirsch-Schluter rotation, and major differences in X-point orbit loss physics between triangularity types. Neoclassical simulation only validated in middle pedestal slope.", "conclusion": "Edge turbulence is important for full validation, and this study provides baseline for future multiphysics studies including turbulence in negative triangularity plasmas."}}
{"id": "2510.05570", "pdf": "https://arxiv.org/pdf/2510.05570", "abs": "https://arxiv.org/abs/2510.05570", "authors": ["John A. Toth", "Xiao Xiao"], "title": "$L^2$ restriction bounds for analytic continuations of quantum ergodic Laplace eigenfunctions", "categories": ["math.AP", "math.DG", "math.SP"], "comment": "28 pages, 2 figures. Comments are welcome!", "summary": "We prove a quantum ergodic restriction (QER) theorem for real hypersurfaces\n$\\Sigma \\subset X,$ where $X$ is the Grauert tube associated with a\nreal-analytic, compact Riemannian manifold. As an application, we obtain $h$\nindependent upper and lower bounds for the $L^2$ - restrictions of the FBI\ntransform of Laplace eigenfunctions restricted to $\\Sigma$ satisfying certain\ngeneric geometric conditions.", "AI": {"tldr": "Quantum ergodic restriction theorem for real hypersurfaces in Grauert tubes, with applications to FBI transform restrictions of Laplace eigenfunctions.", "motivation": "To establish quantum ergodic restriction results for real hypersurfaces in Grauert tube settings, extending quantum ergodicity to restriction problems.", "method": "Proving a quantum ergodic restriction theorem for real hypersurfaces in Grauert tubes associated with real-analytic compact Riemannian manifolds.", "result": "Obtained h-independent upper and lower bounds for L^2 restrictions of FBI transform of Laplace eigenfunctions on generic geometric hypersurfaces.", "conclusion": "Successfully established quantum ergodic restriction theory with applications to eigenfunction restriction bounds in Grauert tube geometry."}}
{"id": "2510.05392", "pdf": "https://arxiv.org/pdf/2510.05392", "abs": "https://arxiv.org/abs/2510.05392", "authors": ["Andrea Valassi"], "title": "New GPU developments in the Madgraph CUDACPP plugin: kernel splitting, helicity streams, cuBLAS color sums", "categories": ["physics.comp-ph", "hep-ex", "hep-ph", "65C05, 81T18, 81V05", "C.1.2; D.1.3; G.3; I.6.8; J.2"], "comment": "18 pages, 7 figures, 3 tables", "summary": "The first production release of the CUDACPP plugin for the Madgraph5_aMC@NLO\ngenerator, which speeds up matrix element (ME) calculations for leading-order\n(LO) QCD processes using a data parallel approach on vector CPUs and GPUs, was\ndelivered in October 2024. This has been described in previous publications by\nthe team behind that effort. In this paper, I describe my work on some\nadditional developments providing further optimizations of CUDACPP for GPUs,\nwhich I consider ready for inclusion in a new release of the software. The new\napproach mainly consists in splitting the calculation of the ME, which has been\nso far performed using a single large GPU kernel, into several smaller kernels.\nI also take this opportunity to describe more in detail some features of the\nCUDACPP software that are relevant to these new developments and that have not\nyet been documented.", "AI": {"tldr": "The paper presents optimizations for the CUDACPP plugin in Madgraph5_aMC@NLO by splitting large GPU kernels into smaller ones for better performance.", "motivation": "To further optimize matrix element calculations in the CUDACPP plugin by improving GPU performance through kernel decomposition.", "method": "Splitting the single large GPU kernel used for matrix element calculations into several smaller kernels for better optimization.", "result": "Developed additional optimizations ready for inclusion in a new software release, improving GPU performance.", "conclusion": "The new kernel-splitting approach provides significant optimizations for GPU-based matrix element calculations in particle physics simulations."}}
{"id": "2510.05452", "pdf": "https://arxiv.org/pdf/2510.05452", "abs": "https://arxiv.org/abs/2510.05452", "authors": ["Benjamin Plumridge", "Cory Hauck", "Steffen Schotthofer"], "title": "Data-Driven Filtering of the Spherical Harmonics Method", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We investigate a data-driven approach for tuning the filtered spherical\nharmonics method (\\fpn) when solving the radiation transport equation (RTE).\nThe \\fpn method extends the classical spherical harmonics approach (\\pn) by\nintroducing regularization through a filter operator, which mitigates spurious\noscillations caused by Gibbs' phenomenon. This filter includes a tunable\nparameter, the {filter strength}, that controls the degree of smoothing applied\nto the solution. However, selecting an optimal filter strength is nontrivial,\noften requiring inaccessible information such as the true or a high-order\nreference solution. To overcome this limitation, we model the filter strength\nas a neural network whose inputs include local state variables and material\ncross-sections. The optimal filter strength is formulated as the solution to a\nPDE-constrained optimization problem, and the neural network is trained using a\ndiscretize-then-optimize formulation in PyTorch. We evaluate the learned filter\nstrength across a suite of test problems and compare the results to those from\na simple, but tunable constant filter strength. In all cases, the\nneural-network-driven filter substantially improves the accuracy of the \\pn\napproximation. For 1-D test cases, the constant filter outperforms the\nneural-network filter in some cases, but in 2-D problems, the neural-network\nfilter generally performs better.", "AI": {"tldr": "A neural network is trained to determine optimal filter strength for the filtered spherical harmonics (FPN) method in radiation transport, improving accuracy over constant filter approaches.", "motivation": "Selecting optimal filter strength in FPN method is challenging without true solution reference, requiring a data-driven approach to automate this parameter tuning.", "method": "Model filter strength as neural network using local state variables and material cross-sections, trained via PDE-constrained optimization in PyTorch using discretize-then-optimize formulation.", "result": "Neural-network filter substantially improves FPN accuracy; outperforms constant filter in 2-D problems, though constant filter sometimes better in 1-D cases.", "conclusion": "Data-driven neural network approach effectively tunes FPN filter strength, providing automated parameter selection that generally enhances solution accuracy, especially for higher-dimensional problems."}}
{"id": "2510.05656", "pdf": "https://arxiv.org/pdf/2510.05656", "abs": "https://arxiv.org/abs/2510.05656", "authors": ["Mina Farahani", "Ji\u0159\u00ed \u010capek", "Tom\u00e1\u0161 Koz\u00e1k"], "title": "Deposition rate and energy to substrate in chopped and standard HiPIMS: identifying optimal pulse parameters", "categories": ["physics.plasm-ph"], "comment": null, "summary": "High-Power Impulse Magnetron Sputtering (HiPIMS) offers higher ionized flux\nfractions at the cost of lower deposition rates compared to conventional DCMS.\nA fine optimization of the deposition conditions is crucial for specific\napplications. Chopped or multi-pulse HiPIMS (segmenting pulses into shorter\nmicropulses) has been proposed to mitigate ion back-attraction and promote\nworking gas recovery. This study investigates how micropulse length, delay time\nbetween segments, and magnetic field strength influence energy flux, deposition\nrate, and ionized flux fraction in chopped and standard HiPIMS. These\nquantities are evaluated by passive thermal probe, biasable QCM and mass\nspectrometer measurements at the substrate position. Deposition-averaged and\npulse-averaged power is kept constant for all conditions to facilitate\nmeaningful comparison. Results indicate that chopping the HiPIMS pulse\nconsistently leads to higher energy flux and total deposition rate compared to\nstandard HiPIMS at the same total pulse length, primarily due to increased ion\nflux. A weaker unbalanced magnetic field configuration enhances deposition\nrates and ion transport. In chopped HiPIMS, increasing micropulse length\ndecreased energy flux and deposition rates, whereas increasing the delay time\nbetween micropulses substantially improved these parameters. Importantly,\nstandard HiPIMS, which operated at higher frequencies and short pulse lengths,\ndemonstrated superior performance (with higher total energy and particle\nfluxes) than chopped HiPIMS when compared at similar short pulse durations.\nThis suggests that consistent short pulse durations and sufficient off-times\nfor complete gas refill are paramount for maximizing ion fluxes and deposition\nrates.", "AI": {"tldr": "Chopped HiPIMS with segmented pulses increases energy flux and deposition rates compared to standard HiPIMS at same total pulse length, but standard HiPIMS with short pulses outperforms when pulse durations are similar.", "motivation": "HiPIMS offers higher ionized flux but lower deposition rates than DCMS. Chopped HiPIMS was proposed to mitigate ion back-attraction and promote gas recovery, requiring optimization of deposition conditions.", "method": "Used chopped and standard HiPIMS with varying micropulse lengths, delay times, and magnetic field strengths. Measured energy flux, deposition rate, and ionized flux fraction using thermal probe, QCM, and mass spectrometer at substrate position with constant average power.", "result": "Chopped HiPIMS showed higher energy flux and deposition rates than standard HiPIMS at same total pulse length. Weaker magnetic field enhanced deposition rates and ion transport. In chopped mode, longer micropulses decreased performance while longer delays improved it. Standard HiPIMS with short pulses performed best.", "conclusion": "Consistent short pulse durations and sufficient off-times for complete gas refill are crucial for maximizing ion fluxes and deposition rates in HiPIMS processes."}}
{"id": "2510.05714", "pdf": "https://arxiv.org/pdf/2510.05714", "abs": "https://arxiv.org/abs/2510.05714", "authors": ["Andrea Poggio"], "title": "Bilinear embedding for divergence-form operators with negative potentials", "categories": ["math.AP", "math.CA", "math.FA", "35J10, 35J15, 47D06, 42B25"], "comment": "58 pages", "summary": "Let $\\Omega \\subseteq \\mathbb{R}^d$ be open, $A$ a complex uniformly strictly\naccretive $d\\times d$ matrix-valued function on $\\Omega$ with $L^\\infty$\ncoefficients, and $V$ a locally integrable function on $\\Omega$ whose negative\npart is subcritical. We consider the operator $\\mathscr{L} =\n-\\mathrm{div}(A\\nabla) + V$ with mixed boundary conditions on $\\Omega$. We\nextend the bilinear inequality of Carbonaro and Dragi\\v{c}evi\\'c [15],\noriginally established for nonnegative potentials, by introducing a novel\ncondition on the coefficients that reduces to standard $p$-ellipticity when $V$\nis nonnegative. As a consequence, we show that the solution to the parabolic\nproblem $u'(t) + \\mathscr{L} u(t) = f(t)$ with $u(0)=0$ has maximal regularity\non $L^p(\\Omega)$, in the same spirit as [13]. Moreover, we study mapping\nproperties of the semigroup generated by $-\\mathscr{L}$ under this new\ncondition, thereby extending classical results for the Schr\\\"{o}dinger operator\n$-\\Delta + V$ on $\\mathbb{R}^d$ [8,47].", "AI": {"tldr": "The paper extends the bilinear inequality for elliptic operators with mixed boundary conditions to include complex potentials, introducing a new coefficient condition that generalizes p-ellipticity.", "motivation": "To generalize previous results on maximal regularity and semigroup properties from nonnegative potentials to complex potentials with subcritical negative parts, extending classical Schr\u00f6dinger operator theory.", "method": "Introduces a novel condition on matrix coefficients that reduces to standard p-ellipticity for nonnegative potentials, and applies this to study the operator L = -div(A\u2207) + V with mixed boundary conditions.", "result": "Shows that solutions to the parabolic problem u'(t) + L u(t) = f(t) have maximal regularity on L^p(\u03a9), and establishes mapping properties of the semigroup generated by -L.", "conclusion": "The new coefficient condition successfully extends classical results to complex potentials, providing maximal regularity and semigroup mapping properties for elliptic operators with mixed boundary conditions."}}
{"id": "2510.05961", "pdf": "https://arxiv.org/pdf/2510.05961", "abs": "https://arxiv.org/abs/2510.05961", "authors": ["Florian Buchner", "Johannes Sch\u00f6rghuber", "Nico Unglert", "Jes\u00fas Carrete", "Georg K. H. Madsen"], "title": "msmJAX: Fast and Differentiable Electrostatics on the GPU in Python", "categories": ["physics.comp-ph"], "comment": null, "summary": "We present msmJAX, a Python package implementing the multilevel summation\nmethod with B-spline interpolation, a linear-scaling algorithm for efficiently\nevaluating electrostatic and other long-range interactions in particle-based\nsimulations. Built on the JAX framework, msmJAX integrates naturally with the\nmachine-learning methods that are transforming chemistry and materials science,\nwhile also serving as a powerful tool in its own right. It combines high\nperformance with Python's accessibility, offers easy deployment on GPUs, and\nsupports automatic differentiation. We outline the modular design of msmJAX,\nenabling users to adapt or extend the code, and present benchmarks and\nexamples, including a verification of linear scaling, and demonstrations of its\nstability in molecular-dynamics simulations.", "AI": {"tldr": "msmJAX is a Python package implementing the multilevel summation method for efficient evaluation of long-range interactions in particle simulations, built on JAX for ML integration and GPU acceleration.", "motivation": "To provide a linear-scaling algorithm for electrostatic and long-range interactions that integrates with machine learning methods in chemistry and materials science, combining high performance with Python accessibility.", "method": "Implements multilevel summation method with B-spline interpolation using JAX framework, enabling GPU deployment, automatic differentiation, and modular design for adaptation.", "result": "The package demonstrates linear scaling, stability in molecular-dynamics simulations, and offers high performance with easy deployment on GPUs.", "conclusion": "msmJAX successfully bridges computational efficiency with machine learning integration, providing a powerful tool for particle-based simulations in chemistry and materials science."}}
{"id": "2510.05597", "pdf": "https://arxiv.org/pdf/2510.05597", "abs": "https://arxiv.org/abs/2510.05597", "authors": ["Gang Chen", "Chaoran Liu", "Yangwen Zhang"], "title": "Optimal $L^2$ Error Estimates for Non-symmetric Nitsche's Methods", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We establish optimal $L^2$-error estimates for the non-symmetric Nitsche\nmethod. Existing analyses yield only suboptimal $L^2$ convergence, in contrast\nto consistently optimal numerical results. We resolve this discrepancy by\nintroducing a specially constructed dual problem that restores adjoint\nconsistency. Our analysis covers both super-penalty and penalty-free variants\non quasi-uniform meshes, as well as the practically important case on general\nshape-regular meshes without quasi-uniformity. Numerical experiments in two and\nthree dimensions confirm the sharpness of our theoretical results.", "AI": {"tldr": "Optimal L\u00b2-error estimates for non-symmetric Nitsche method are established, resolving previous suboptimal convergence analyses through a specially constructed dual problem that restores adjoint consistency.", "motivation": "Existing analyses of the non-symmetric Nitsche method yielded only suboptimal L\u00b2 convergence, which contradicted consistently optimal numerical results, creating a discrepancy between theory and practice.", "method": "Introduce a specially constructed dual problem that restores adjoint consistency to analyze both super-penalty and penalty-free variants on quasi-uniform meshes, and extend to general shape-regular meshes without quasi-uniformity.", "result": "The analysis provides optimal L\u00b2-error estimates that match the consistently optimal numerical performance observed in practice, with numerical experiments in 2D and 3D confirming the sharpness of the theoretical results.", "conclusion": "The specially constructed dual problem successfully resolves the discrepancy between previous suboptimal theoretical analyses and optimal numerical performance of the non-symmetric Nitsche method, establishing optimal convergence rates across various mesh types."}}
{"id": "2510.05912", "pdf": "https://arxiv.org/pdf/2510.05912", "abs": "https://arxiv.org/abs/2510.05912", "authors": ["S. Thatikonda", "F. N. De Oliveira-Lopes", "A. Mustonen", "K. Pommois", "D. Told", "F. Jenko"], "title": "Investigating the Lower Hybrid Drift Instability in Reconnecting Current Sheets Using a Hybrid Kinetic Model (ssV Code)", "categories": ["physics.plasm-ph"], "comment": "14 pages, 10 figures", "summary": "We investigate the nonlinear evolution of the lower hybrid drift instability\n(LHDI) in reconnecting current sheets using a hybrid kinetic simulation model\nimplemented in the Super Simple Vlasov (ssV) code. The model treats ions\nkinetically and electrons with a drift-kinetic approximation, solving\nself-consistent coupled electrostatic and electromagnetic fields. A parametric\nstudy explores the effects of mass ratio, temperature ratio, plasma beta, and\nsheet thickness. In electrostatic cases, LHDI remains localized at the sheet\nedges, flattening density gradients. In electromagnetic regimes, turbulence\ninduced by LHDI generates magnetic perturbations that kink the current sheet\nand enhance anomalous resistivity. These dynamics may facilitate fast magnetic\nreconnection under certain conditions. Our results bridge prior theoretical\npredictions and simulations, emphasizing the importance of kinetic\ninstabilities in reconnection physics.", "AI": {"tldr": "Hybrid kinetic simulations show the lower hybrid drift instability (LHDI) evolves differently in electrostatic vs electromagnetic regimes, with electromagnetic LHDI generating turbulence that kinks current sheets and enhances resistivity, potentially facilitating fast magnetic reconnection.", "motivation": "To understand how the nonlinear evolution of LHDI affects reconnecting current sheets and bridge theoretical predictions with simulations about kinetic instabilities in reconnection physics.", "method": "Used hybrid kinetic simulation model in Super Simple Vlasov (ssV) code with kinetic ions and drift-kinetic electrons, solving coupled electrostatic and electromagnetic fields. Conducted parametric study varying mass ratio, temperature ratio, plasma beta, and sheet thickness.", "result": "In electrostatic cases, LHDI remains localized at sheet edges and flattens density gradients. In electromagnetic regimes, LHDI-induced turbulence generates magnetic perturbations that kink current sheets and enhance anomalous resistivity.", "conclusion": "LHDI dynamics may facilitate fast magnetic reconnection under certain conditions, bridging theory and simulations while emphasizing the importance of kinetic instabilities in reconnection physics."}}
{"id": "2510.05732", "pdf": "https://arxiv.org/pdf/2510.05732", "abs": "https://arxiv.org/abs/2510.05732", "authors": ["Gonzalo Cao-Labora", "Antonio J. Fern\u00e1ndez"], "title": "A contractible Schiffer counterexample on the half-sphere", "categories": ["math.AP", "math.DG"], "comment": "24 pages, 7 figures, 364 lines of code", "summary": "We show the existence of a family of nontrivial smooth contractible domains\non the sphere that admit Neumann eigenfunctions of the Laplacian which are\nconstant on the boundary. These domains are contained on the half-sphere, in\nstark contrast with the rigidity literature for Serrin-type problems. The proof\nrelies on a local bifurcation argument around the family of geodesic disks\ncentered at the north pole. We combine the use of anisotropic H\\\"older spaces\nfor the functional setting with computer-assisted techniques to check the\nbifurcation conditions.", "AI": {"tldr": "Existence of nontrivial smooth contractible domains on sphere with Neumann eigenfunctions constant on boundary, using bifurcation from geodesic disks and computer-assisted verification.", "motivation": "To demonstrate that rigidity results for Serrin-type problems don't extend to Neumann eigenfunctions on spheres, showing existence of domains with special boundary behavior.", "method": "Local bifurcation argument around geodesic disks centered at north pole, using anisotropic H\u00f6lder spaces and computer-assisted techniques to verify bifurcation conditions.", "result": "Found family of nontrivial smooth contractible domains on half-sphere admitting Neumann eigenfunctions constant on boundary.", "conclusion": "Rigidity literature for Serrin-type problems doesn't apply to Neumann eigenfunctions on spheres, as shown by existence of domains with constant boundary values."}}
{"id": "2510.05119", "pdf": "https://arxiv.org/pdf/2510.05119", "abs": "https://arxiv.org/abs/2510.05119", "authors": ["Roger A. Sauer"], "title": "A curvilinear surface ALE formulation for self-evolving Navier-Stokes manifolds - Stabilized finite element formulation", "categories": ["physics.flu-dyn", "cs.NA", "math.NA", "physics.comp-ph"], "comment": "50 pages, 30 figures, 5 tables", "summary": "This work presents a stabilized finite element formulation of the arbitrary\nLagrangian-Eulerian (ALE) surface theory for Navier-Stokes flow on\nself-evolving manifolds developed in Sauer (2025). The formulation is\nphysically frame-invariant, applicable to large deformations, and relevant to\nfluidic surfaces such as soap films, capillary menisci and lipid membranes,\nwhich are complex and inherently unstable physical systems. It is applied here\nto area-incompressible surface flows using a stabilized pressure-velocity (or\nsurface tension-velocity) formulation based on quadratic finite elements and\nimplicit time integration. The unknown ALE mesh motion is determined by\nmembrane elasticity such that the in-plane mesh motion is stabilized without\naffecting the physical behavior of the system. The resulting three-field system\nis monolithically coupled, and fully linearized within the Newton-Rhapson\nsolution method. The new formulation is demonstrated on several challenging\nexamples including shear flow on self-evolving surfaces and inflating soap\nbubbles with partial inflow on evolving boundaries. Optimal convergence rates\nare obtained in all cases. Particularly advantageous are C1-continuous surface\ndiscretizations, for example based on NURBS.", "AI": {"tldr": "Stabilized finite element formulation for ALE surface theory of Navier-Stokes flow on self-evolving manifolds, applicable to fluidic surfaces like soap films and membranes.", "motivation": "To model complex and inherently unstable physical systems such as soap films, capillary menisci, and lipid membranes that involve large deformations and require frame-invariant formulations.", "method": "Stabilized pressure-velocity formulation using quadratic finite elements, implicit time integration, and ALE mesh motion determined by membrane elasticity for in-plane stabilization without affecting physical behavior.", "result": "Optimal convergence rates achieved in challenging examples including shear flow on self-evolving surfaces and inflating soap bubbles with partial inflow on evolving boundaries.", "conclusion": "The monolithic coupled three-field system with C1-continuous surface discretizations (e.g., NURBS) is particularly advantageous for modeling fluidic surfaces with large deformations."}}
{"id": "2510.05704", "pdf": "https://arxiv.org/pdf/2510.05704", "abs": "https://arxiv.org/abs/2510.05704", "authors": ["Saugata Ghosh", "Dambaru Bhatta", "S. M. Mallikarjunaiah"], "title": "A finite element model for thermomechanical stress-strain fields in transversely isotropic strain-limiting materials", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper presents a comprehensive computational framework for investigating\nthermo-elastic fracture in transversely isotropic materials, where classical\nlinear elasticity fails to predict physically realistic behavior near stress\nconcentrations. We address the challenge of unphysical strain singularities at\ncrack tips by employing a strain-limiting theory of elasticity. This theory is\ncharacterized by an algebraically nonlinear constitutive relationship between\nstress and strain, which intrinsically enforces a limit on the norm of the\nstrain tensor. This approach allows the development of very large stresses, as\nexpected near a crack tip, while ensuring that the corresponding strains remain\nphysically bounded. A loosely coupled system of linear and nonlinear partial\ndifferential equations governing the response of a thermo-mechanical\ntransversely isotropic solid is formulated. We develop a robust numerical\nsolution based on the finite element method, utilizing a conforming finite\nelement discretization within a continuous Galerkin framework to solve the\ntwo-dimensional boundary value problem. The model is applied to analyze the\nstress and strain fields near an edge crack under severe thermo-mechanical\nloading. Our numerical results reveal a significant departure from classical\npredictions: while stress concentrates intensely at the crack tip, the strain\ngrows at a substantially slower rate and remains bounded throughout the domain.\nThis work validates the efficacy of the strain-limiting model in regularizing\nthermo-elastic crack-tip fields and establishes a reliable computational\nfoundation for the predictive modeling of thermally driven crack initiation and\nevolution in advanced anisotropic materials.", "AI": {"tldr": "A computational framework using strain-limiting elasticity theory to address unphysical strain singularities at crack tips in transversely isotropic materials under thermo-mechanical loading, showing bounded strains despite high stress concentrations.", "motivation": "Classical linear elasticity fails to predict physically realistic behavior near stress concentrations in transversely isotropic materials, leading to unphysical strain singularities at crack tips.", "method": "Employ strain-limiting elasticity theory with algebraically nonlinear constitutive relationship, formulate loosely coupled PDE system, and develop finite element method with conforming discretization in continuous Galerkin framework for 2D boundary value problems.", "result": "Numerical results show significant departure from classical predictions - stress concentrates intensely at crack tip but strain grows much slower and remains bounded throughout the domain.", "conclusion": "The strain-limiting model effectively regularizes thermo-elastic crack-tip fields and provides reliable computational foundation for predictive modeling of thermally driven crack initiation and evolution in anisotropic materials."}}
{"id": "2510.05873", "pdf": "https://arxiv.org/pdf/2510.05873", "abs": "https://arxiv.org/abs/2510.05873", "authors": ["Venla Koikkalainen", "Emilia Kilpua", "Simon Good", "Adnane Osmane"], "title": "Exploring Complexity Measures for Analysis of Solar Wind Structures and Streams", "categories": ["astro-ph.SR", "physics.plasm-ph", "physics.space-ph"], "comment": "Published in Nonlinear Processes in Geophysics, September 2025", "summary": "In this paper we use statistical complexity and information theory metrics to\nstudy structure within solar wind time series. We explore this using\nentropy-complexity and information planes, where the measure for entropy is\nformed using either permutation entropy or the degree distribution of a\nhorizontal visibility graph (HVG). The entropy is then compared to the Jensen\ncomplexity (Jensen-Shannon complexity plane) and Fisher information measure\n(Fisher-Shannon information plane), formed both from permutations and the HVG\napproach. Additionally we characterise the solar wind time series by studying\nthe properties of the HVG degree distribution. Four types of solar wind\nintervals have been analysed, namely fast streams, slow streams, magnetic\nclouds and sheath regions, all of which have distinct origins and\ninterplanetary characteristics. Our results show that, overall, different\nmetrics give similar results but Fisher-Shannon, which gives a more local\nmeasure of complexity, leads to a larger spread of values in the\nentropy-complexity plane. Magnetic cloud intervals stood out in all approaches,\nin particular when analysing the magnetic field magnitude. Differences between\nsolar wind types (except for magnetic clouds) were typically more distinct for\nlarger time lags, suggesting universality in fluctuations for small scales. The\nfluctuations within the solar wind time series were generally found to be\nstochastic, in agreement with previous studies. The use of information theory\ntools in the analysis of solar wind time series can help to identify structures\nand provide insight into their origin and formation.", "AI": {"tldr": "The paper analyzes solar wind time series using entropy-complexity and information planes with permutation entropy and horizontal visibility graph methods to distinguish different solar wind types.", "motivation": "To study structure within solar wind time series and identify differences between various solar wind types (fast streams, slow streams, magnetic clouds, sheath regions) using information theory metrics.", "method": "Used statistical complexity and information theory metrics including entropy-complexity and information planes, with permutation entropy and horizontal visibility graph (HVG) degree distribution for entropy measurement, compared to Jensen complexity and Fisher information measure.", "result": "Magnetic cloud intervals were distinct in all approaches, especially for magnetic field magnitude. Fisher-Shannon showed larger spread in entropy-complexity plane. Differences between solar wind types were more distinct for larger time lags. Fluctuations were generally stochastic.", "conclusion": "Information theory tools can effectively identify structures in solar wind time series and provide insight into their origin and formation, with magnetic clouds being particularly distinguishable."}}
{"id": "2510.05847", "pdf": "https://arxiv.org/pdf/2510.05847", "abs": "https://arxiv.org/abs/2510.05847", "authors": ["Angelica Pia Di Feola", "Michael Ruzicka"], "title": "Existence of global weak solutions to a parabolic $p$-Laplacian problem with convective term", "categories": ["math.AP"], "comment": null, "summary": "For a given bounded domain $\\Omega \\subset \\mathbb R^3$, with $C^2$ boundary,\nand a given instant of time $T>0$, we prove the existence of a global weak\nsolution on $(0,T)$, which satisfies a maximum principle, to a parabolic\n$p$-Laplacian system with convective term without divergence constraint for any\n$p\\in (1,2)$.", "AI": {"tldr": "Existence of global weak solutions for parabolic p-Laplacian systems with convective terms in 3D domains", "motivation": "To establish existence results for nonlinear parabolic systems with convective terms without requiring divergence constraints", "method": "Proving existence of global weak solutions on bounded domains with C^2 boundary for p-Laplacian systems with convective terms", "result": "Global weak solutions exist on (0,T) for any p in (1,2) and satisfy maximum principle", "conclusion": "Successfully established existence theory for parabolic p-Laplacian systems with convective terms in three-dimensional domains"}}
{"id": "2510.05143", "pdf": "https://arxiv.org/pdf/2510.05143", "abs": "https://arxiv.org/abs/2510.05143", "authors": ["Carlson Moses B\u00fcth", "Massimiliano Zanin"], "title": "Functional Connectivity Networks for Transportation Delay Analysis: from Theory to Software", "categories": ["physics.soc-ph", "cs.IT", "math.IT", "physics.comp-ph", "physics.data-an"], "comment": "25 pages, 11 figures, 3 tables, for documentation, see\n  https://delaynet.readthedocs.io/", "summary": "Within the endeavour of modelling and understanding the propagation of delays\nin transportation networks, an approach that has attracted increasing interest\nin the last decade is the creation of functional network representations. These\ngraphs map elements of interest (e.g. airports or stations) as nodes, and\nderive pairwise propagation patterns from their dynamics through correlation\nand causality tests. In spite of multiple notable results, this approach still\nlacks a coherent framework, with decisions related to many fundamental steps\nbeing left to the judgement of the researcher. We here provide an introduction\nto the theory behind functional networks for transportation systems, detailing\nthe main steps and the associated pitfalls. We further introduce a Python\npackage, delaynet, designed to support the researcher in the reconstruction and\nanalysis of such networks. We finally present an analysis of the propagation of\ndelays in the Swiss train system; and discuss future research steps.", "AI": {"tldr": "This paper introduces a framework and Python package (delaynet) for creating functional network representations of transportation delay propagation, addressing the lack of coherent methodology in this field.", "motivation": "The motivation is to address the lack of a coherent framework for creating functional network representations of delay propagation in transportation systems, where many fundamental decisions are currently left to researcher judgment.", "method": "The authors provide theoretical background on functional networks for transportation systems, detail the main steps and pitfalls, and introduce a Python package called 'delaynet' to support network reconstruction and analysis.", "result": "The paper presents an analysis of delay propagation in the Swiss train system using their framework and demonstrates the practical application of their methodology.", "conclusion": "The authors conclude by discussing future research steps and the potential for their framework and tool to standardize and improve delay propagation analysis in transportation networks."}}
{"id": "2510.05755", "pdf": "https://arxiv.org/pdf/2510.05755", "abs": "https://arxiv.org/abs/2510.05755", "authors": ["Jamal Daoudi", "Chakir Tajani"], "title": "Reconstruction of Boundary Data in the Helmholtz Equation Using Particle Swarm Optimization", "categories": ["math.NA", "cs.NA", "35R30, 35J05, 65J20, 68T20"], "comment": null, "summary": "This paper tackles the data completion problem related to the Helmholtz\nequation. The goal is to identify unknown boundary conditions on parts of the\nboundary that cannot be accessed directly, by making use of measurements\ncollected from accessible regions. Such inverse problems are known to be\nill-posed in the Hadamard sense, which makes finding stable and dependable\nsolutions particularly difficult. To address these challenges, we propose a\nbio-inspired method that combines Particle Swarm Optimization with Tikhonov\nregularization. The results of our numerical experiments suggest that this\napproach can yield solutions that are both accurate and stable, converging\nreliably. Overall, this method provides a promising way to handle the inherent\ninstability and sensitivity of these types of inverse problems.", "AI": {"tldr": "A bio-inspired method combining Particle Swarm Optimization with Tikhonov regularization is proposed to solve the ill-posed Helmholtz equation data completion problem, achieving accurate and stable solutions.", "motivation": "To identify unknown boundary conditions on inaccessible boundary regions using measurements from accessible areas, addressing the ill-posed nature of such inverse problems that makes finding stable solutions difficult.", "method": "Combines Particle Swarm Optimization (a bio-inspired algorithm) with Tikhonov regularization to handle the ill-posedness of the Helmholtz equation data completion problem.", "result": "Numerical experiments show the approach yields accurate and stable solutions that converge reliably, effectively handling the inherent instability of these inverse problems.", "conclusion": "The proposed bio-inspired method provides a promising approach for solving Helmholtz equation data completion problems, offering both accuracy and stability despite the ill-posed nature of such inverse problems."}}
{"id": "2510.05954", "pdf": "https://arxiv.org/pdf/2510.05954", "abs": "https://arxiv.org/abs/2510.05954", "authors": ["Luca Barbieri", "Pascal D\u00e9moulin"], "title": "Kinetic collisionless model of the solar transition region and corona with spatially intermittent heating", "categories": ["astro-ph.SR", "physics.plasm-ph"], "comment": "Submitted to Astronomy and Astrophysics. Comments welcome", "summary": "We develop a three-dimensional kinetic model of the solar transition region\nand corona in which the plasma above the chromosphere is collisionless and\nembedded in a uniform magnetic field. Heating occurs intermittently at discrete\nlocations on the chromospheric surface, modeled through a surface\ncoarse-graining procedure that produces non-thermal boundary conditions for the\nVlasov equation. The resulting stationary distribution functions generate\nsuprathermal particle populations and naturally lead to a temperature inversion\nvia gravitational filtering, without any local coronal heating. The model\nreproduces realistic temperature and density profiles with a thin transition\nregion and a hot corona, consistent with solar observations. These results\ndemonstrate that the spatial intermittency of heating at the chromospheric\ninterface is sufficient to account for the formation of the transition region\nand the high-temperature corona.", "AI": {"tldr": "A 3D kinetic model shows that intermittent heating at the chromospheric surface can create the solar transition region and hot corona through collisionless plasma dynamics and gravitational filtering, without local coronal heating.", "motivation": "To understand how the solar transition region and corona form, particularly investigating whether intermittent heating at the chromosphere alone can produce the observed temperature inversion and hot corona.", "method": "Developed a 3D kinetic model with collisionless plasma in uniform magnetic field, using surface coarse-graining for intermittent heating at chromospheric boundary, solving Vlasov equation with non-thermal boundary conditions.", "result": "The model produces suprathermal particle populations, temperature inversion via gravitational filtering, realistic temperature/density profiles with thin transition region and hot corona, matching solar observations.", "conclusion": "Spatial intermittency of heating at the chromospheric interface is sufficient to account for transition region formation and high-temperature corona, without requiring local coronal heating mechanisms."}}
{"id": "2510.05870", "pdf": "https://arxiv.org/pdf/2510.05870", "abs": "https://arxiv.org/abs/2510.05870", "authors": ["Wadim Gerner"], "title": "Quantitative Gaffney and Korn inequalities", "categories": ["math.AP", "math-ph", "math.MP", "35B45, 35Q61, 35Q74, 74B05, 76W05"], "comment": "14 pages", "summary": "We prove a homogeneous, quantitative version of Ehrling's inequality for the\nfunction spaces $H^1(\\Omega)\\subset\\subset L^2(\\partial\\Omega)$,\n$H^1(\\Omega)\\hookrightarrow L^2(\\Omega)$ which reflects geometric properties of\na given $C^{1,1}$-domain $\\Omega\\subset\\mathbb{R}^n$.\n  We use this result to derive quantitative homogeneous versions of Gaffney's\ninequality, of relevance in electromagnetism as well as Korn's inequality, of\nrelevance in elasticity theory.\n  The main difference to the corresponding classical results is that the\nconstants appearing in our inequalities turn out to be dimensional constants.\nWe provide explicit upper bounds for these constants and show that in the case\nof the tangential homogeneous Korn inequality our upper bound is asymptotically\nsharp as $n\\rightarrow \\infty$.\n  Lastly, we raise the question of the optimal values of these dimensional\nconstants.", "AI": {"tldr": "The paper proves homogeneous, quantitative versions of Ehrling's inequality for function spaces on C^{1,1}-domains, and derives similar versions of Gaffney's inequality (for electromagnetism) and Korn's inequality (for elasticity theory), with constants that are dimensional rather than domain-dependent.", "motivation": "To establish inequalities with dimensional constants that are independent of domain geometry, providing more universal mathematical tools for applications in electromagnetism and elasticity theory.", "method": "Proving homogeneous quantitative versions of Ehrling's inequality for H^1(\u03a9)\u2282\u2282L^2(\u2202\u03a9) and H^1(\u03a9)\u21aaL^2(\u03a9) spaces, then using these results to derive similar versions of Gaffney's and Korn's inequalities.", "result": "Obtained inequalities with dimensional constants instead of domain-dependent constants, provided explicit upper bounds for these constants, and showed that the upper bound for the tangential homogeneous Korn inequality is asymptotically sharp as dimension n\u2192\u221e.", "conclusion": "The paper successfully establishes homogeneous quantitative inequalities with dimensional constants and raises the question of determining the optimal values of these dimensional constants."}}
{"id": "2510.05227", "pdf": "https://arxiv.org/pdf/2510.05227", "abs": "https://arxiv.org/abs/2510.05227", "authors": ["Simon H. Hille", "Attila Szab\u00f3"], "title": "TeMFpy: a Python library for converting fermionic mean-field states into tensor networks", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "cond-mat.supr-con", "physics.comp-ph", "quant-ph"], "comment": "28 pages, 5 figures, 3 code listings", "summary": "We introduce TeMFpy, a Python library for converting fermionic mean-field\nstates to finite or infinite matrix product state (MPS) form. TeMFpy includes\nnew, efficient, and easy-to-understand algorithms for both Slater determinants\nand Pfaffian states. Together with Gutzwiller projection, these also allow the\nuser to build variational wave functions for various strongly correlated\nelectron systems, such as quantum spin liquids. We present all implemented\nalgorithms in detail and describe how they can be accessed through TeMFpy,\nincluding full example workflows. TeMFpy is built on top of TeNPy and,\ntherefore, integrates seamlessly with existing MPS-based algorithms.", "AI": {"tldr": "TeMFpy is a Python library that converts fermionic mean-field states to matrix product state (MPS) form, supporting both Slater determinants and Pfaffian states with efficient algorithms.", "motivation": "To provide tools for building variational wave functions for strongly correlated electron systems like quantum spin liquids by converting mean-field states to MPS form.", "method": "Developed new efficient algorithms for converting Slater determinants and Pfaffian states to finite/infinite MPS, built on top of TeNPy for seamless integration with existing MPS algorithms.", "result": "Created TeMFpy library with detailed implemented algorithms and example workflows that enable construction of variational wave functions for strongly correlated systems.", "conclusion": "TeMFpy successfully provides accessible tools for converting fermionic mean-field states to MPS form, facilitating research on quantum spin liquids and other strongly correlated electron systems."}}
{"id": "2510.05801", "pdf": "https://arxiv.org/pdf/2510.05801", "abs": "https://arxiv.org/abs/2510.05801", "authors": ["Josefa Caballero", "\u0141ukasz P\u0142ociniczak", "Kishin Sadarangani"], "title": "Generalized capillary-rise models: existence and fast solvers in integral H\u00f6lder spaces", "categories": ["math.NA", "cs.NA", "math.CA"], "comment": null, "summary": "We study a class of nonlinear Volterra integral equations that generalize the\nclassical capillary rise models, allowing for nonsmooth kernels and\nnonlinearities. To accommodate such generalities, we work in two families of\nfunction spaces: spaces with prescribed modulus of continuity and integral\nH\\\"older spaces. We establish existence results for solutions within the\nintegral H\\\"older space framework. Furthermore, we analyze the behavior of\nlinear interpolation in these spaces and provide, for the first time, sharp\nerror estimates, demonstrating their optimality. Building on this foundation,\nwe propose a piecewise linear collocation method tailored to solutions in\nintegral H\\\"older spaces and prove its convergence. For problems admitting\nsmoother solutions, we develop an efficient spectral collocation scheme based\non Legendre nodes. Finally, several numerical experiments illustrate the\ntheoretical results and highlight the performance of the proposed methods.", "AI": {"tldr": "Analysis of nonlinear Volterra integral equations with nonsmooth kernels, establishing existence in integral H\u00f6lder spaces, developing sharp interpolation error estimates, and proposing collocation methods with proven convergence.", "motivation": "To extend classical capillary rise models by accommodating nonsmooth kernels and nonlinearities in Volterra integral equations, requiring analysis in specialized function spaces.", "method": "Work in function spaces with prescribed modulus of continuity and integral H\u00f6lder spaces; establish existence results; analyze linear interpolation with sharp error estimates; develop piecewise linear collocation and spectral collocation methods.", "result": "Proved existence of solutions in integral H\u00f6lder spaces; obtained sharp optimal error estimates for interpolation; developed convergent collocation methods; demonstrated effectiveness through numerical experiments.", "conclusion": "The framework successfully handles generalized capillary rise models with nonsmooth kernels, provides rigorous analysis in specialized function spaces, and offers efficient numerical methods with proven convergence properties."}}
{"id": "2510.05966", "pdf": "https://arxiv.org/pdf/2510.05966", "abs": "https://arxiv.org/abs/2510.05966", "authors": ["Markus Hirvensalo"], "title": "Eigenstructure of the linearized electrical impedance tomography problem under radial perturbations", "categories": ["math.AP", "35B30, 35B35, 35Q60, 35R30"], "comment": null, "summary": "We analyze the Fr\\'echet derivative $F$, that maps a perturbation in\nconductivity to the linearized change in boundary measurements governed by the\nconductivity equation. The domain is taken to be the unit ball $B \\subset\n\\mathbb{R}^d$ with $d \\geq 2$, and we choose perturbations $\\eta$ from the\nHilbert space $L^2(B)$. Under the condition that the perturbations are\nrotationally symmetric, we show that the eigenfunctions of the linear\napproximation $F \\eta$ correspond to the spherical harmonics. Furthermore, we\nestablish an explicit formula for the associated eigenvalues and show that for\nperturbations from any bounded subset, the decay of these eigenvalues is\nuniform with respect to the degree of the spherical harmonics. The established\nstructure of $F \\eta$ enables us to show that the Fr\\'echet derivative $F$ can\nbe approximated by finite-rank operators when restricted to rotationally\nsymmetric perturbations. Both the extension to $L^2(B)$ perturbations and the\napproximability by finite-rank operators are favorable properties for further\nanalysis of $F$ in numerical algorithms.", "AI": {"tldr": "Analysis of Fr\u00e9chet derivative for conductivity perturbations in the unit ball, showing eigenfunctions are spherical harmonics and eigenvalues decay uniformly, enabling finite-rank approximations for rotationally symmetric perturbations.", "motivation": "To understand the mathematical structure of the Fr\u00e9chet derivative in conductivity problems, which is important for numerical algorithms and inverse problems involving boundary measurements.", "method": "Analyzed the Fr\u00e9chet derivative mapping conductivity perturbations to boundary measurement changes in the unit ball, focusing on rotationally symmetric perturbations from L^2(B) space.", "result": "Found that eigenfunctions correspond to spherical harmonics, established explicit eigenvalue formulas, and showed uniform eigenvalue decay for bounded perturbations. Demonstrated that the Fr\u00e9chet derivative can be approximated by finite-rank operators for rotationally symmetric perturbations.", "conclusion": "The established structure and approximability properties are favorable for numerical analysis and algorithms involving the Fr\u00e9chet derivative in conductivity problems."}}
{"id": "2510.05267", "pdf": "https://arxiv.org/pdf/2510.05267", "abs": "https://arxiv.org/abs/2510.05267", "authors": ["Aur\u00e9lie Champagne", "Olugbenga Adeniran", "Jonah B. Haber", "Antonios M. Alvertis", "Zhen-Fei Liu", "Jeffrey B. Neaton"], "title": "Tunable electronic energy level alignment and exciton diversity in organic-inorganic van der Waals heterostructures", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph"], "comment": "23 pages, 5 figures", "summary": "van der Waals stacking of two-dimensional (2D) materials offers a powerful\nplatform for engineering material interfaces with tailored electronic and\noptical properties. While most van der Waals multilayers have featured\ninorganic monolayers, incorporating molecular monolayers introduces new degrees\nof tunability and functionality. Here, we investigate hybrid bilayers composed\nof atomically thin perylene-based molecular crystals interfaced with monolayer\ntransition metal dichalcogenides (TMDs), specifically MoS2 and WS2. Using ab\ninitio many-body perturbation theory within the GW approximation and the\nBethe-Salpeter equation approach, we predict emergent properties beyond those\nof the isolated constituent systems. Notably, we find substantial\nrenormalization of monolayer molecular crystal band gap due to TMD-induced\npolarization. Furthermore, by varying the TMD monolayer, we demonstrate tuning\nof the energy level alignment of the bilayer and subsequent control over a\ndiversity of lowest-energy excitons, which include strongly bound hybrid\nexcitons and long-lived charge-transfer excitons. These findings establish\norganic-inorganic van der Waals heterostructures as a promising class of\nmaterials for tunable optoelectronic devices and quantum excitonic phenomena,\nexpanding the design space for low-dimensional systems.", "AI": {"tldr": "Hybrid organic-inorganic van der Waals bilayers combining perylene-based molecular crystals with TMD monolayers (MoS2, WS2) show tunable electronic and excitonic properties through polarization effects and energy level alignment control.", "motivation": "To explore hybrid van der Waals bilayers incorporating molecular monolayers for enhanced tunability and functionality beyond traditional inorganic-only systems.", "method": "Using ab initio many-body perturbation theory within GW approximation and Bethe-Salpeter equation approach to predict emergent properties in hybrid bilayers.", "result": "Substantial band gap renormalization of molecular crystals due to TMD-induced polarization, tunable energy level alignment, and control over diverse excitons including hybrid and charge-transfer excitons.", "conclusion": "Organic-inorganic van der Waals heterostructures are promising for tunable optoelectronic devices and quantum excitonic phenomena, expanding design possibilities for low-dimensional systems."}}
{"id": "2510.05926", "pdf": "https://arxiv.org/pdf/2510.05926", "abs": "https://arxiv.org/abs/2510.05926", "authors": ["Ruchi Guo", "Jiahua Jiang", "Bangti Jin", "Wuwei Ren", "Jianru Zhang"], "title": "A Warm-basis Method for Bridging Learning and Iteration: a Case Study in Fluorescence Molecular Tomography", "categories": ["math.NA", "cs.CV", "cs.NA"], "comment": null, "summary": "Fluorescence Molecular Tomography (FMT) is a widely used non-invasive optical\nimaging technology in biomedical research. It usually faces significant\naccuracy challenges in depth reconstruction, and conventional iterative methods\nstruggle with poor $z$-resolution even with advanced regularization. Supervised\nlearning approaches can improve recovery accuracy but rely on large,\nhigh-quality paired training dataset that is often impractical to acquire in\npractice. This naturally raises the question of how learning-based approaches\ncan be effectively combined with iterative schemes to yield more accurate and\nstable algorithms. In this work, we present a novel warm-basis iterative\nprojection method (WB-IPM) and establish its theoretical underpinnings. The\nmethod is able to achieve significantly more accurate reconstructions than the\nlearning-based and iterative-based methods. In addition, it allows a weaker\nloss function depending solely on the directional component of the difference\nbetween ground truth and neural network output, thereby substantially reducing\nthe training effort. These features are justified by our error analysis as well\nas simulated and real-data experiments.", "AI": {"tldr": "A novel warm-basis iterative projection method (WB-IPM) combines learning-based approaches with iterative schemes to improve Fluorescence Molecular Tomography (FMT) depth reconstruction accuracy without requiring large training datasets.", "motivation": "FMT faces accuracy challenges in depth reconstruction, with conventional iterative methods having poor z-resolution and supervised learning requiring impractical large training datasets. Need to combine learning with iterative methods for better accuracy and stability.", "method": "Proposed warm-basis iterative projection method (WB-IPM) that integrates learning-based approaches with iterative schemes, using a weaker loss function based only on directional component differences to reduce training effort.", "result": "Achieves significantly more accurate reconstructions than both learning-based and iterative methods alone, with reduced training requirements as demonstrated by error analysis and experiments on simulated and real data.", "conclusion": "WB-IPM effectively combines learning and iterative approaches for FMT, providing superior reconstruction accuracy with reduced training effort through directional component-based loss functions."}}
{"id": "2510.05990", "pdf": "https://arxiv.org/pdf/2510.05990", "abs": "https://arxiv.org/abs/2510.05990", "authors": ["Francesca Crispo", "Angelica Pia Di Feola", "Carlo Romano Grisanti"], "title": "Estimates of a possible gap related to the energy equality for a class of non-Newtonian fluids", "categories": ["math.AP", "math-ph", "math.MP"], "comment": null, "summary": "The paper is concerned with the 3D-initial value problem for power-law fluids\nwith shear dependent viscosity in a spatially periodic domain. The goal is the\nconstruction of a weak solution enjoying an energy equality. The results hold\nassuming an initial data $v_0\\in J^2(\\Omega)$ and for $p\\in \\left(\\frac\n95,2\\right)$. It is interesting to observe that the result is in complete\nagreement with the one known for the Navier-Stokes equations. Further, in both\ncases, the additional dissipation, which measures the possible gap with the\nclassical energy equality, is only expressed in terms of energy quantities.", "AI": {"tldr": "Construction of weak solutions with energy equality for 3D power-law fluids with shear-dependent viscosity in periodic domains, for initial data in J\u00b2(\u03a9) and p \u2208 (9/5,2).", "motivation": "To establish existence of weak solutions that satisfy energy equality for power-law fluids, extending results similar to Navier-Stokes equations.", "method": "Analysis of 3D initial value problem for power-law fluids with shear-dependent viscosity in spatially periodic domains.", "result": "Existence of weak solutions with energy equality is proven for initial data v\u2080 \u2208 J\u00b2(\u03a9) and p \u2208 (9/5,2).", "conclusion": "The results align with Navier-Stokes equations, with additional dissipation expressed only in terms of energy quantities."}}
{"id": "2510.05339", "pdf": "https://arxiv.org/pdf/2510.05339", "abs": "https://arxiv.org/abs/2510.05339", "authors": ["Abrar Faiyad", "Ashlie Martini"], "title": "Machine Learning Interatomic Potentials Enable Molecular Dynamics Simulations of Doped MoS2", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "We present the first computational framework for molecular dynamics\nsimulation of MoS2 doped with 25 elements spanning metals, non-metals, and\ntransition metals using Meta's Universal Model for Atoms machine learning\ninteratomic potential (MLIP). Benchmarking against density functional theory\ncalculations demonstrates the accuracy of the MLIP for simulating doped-MoS2\nsystems and highlights opportunities for improvement. Using the MLIP, we\nperform heating-cooling simulations of doped-MoS2 supercells. The simulations\ncapture complex phenomena including dopant clustering, MoS2 layer fracturing,\ninterlayer diffusion, and chemical compound formation at orders-of-magnitude\nreduced computational cost compared to density functional theory. This work\nprovides an open-source computational workflow for application-oriented design\nof doped-MoS2, enabling high-throughput screening of dopant candidates and\noptimization of compositions for targeted tribological, electronic, and\noptoelectronic performance. The MLIP bridges the accuracy-efficiency gap\nbetween first-principles methods and empirical potentials, and the framework\noffers unprecedented opportunities for large-scale materials discovery in\ntwo-dimensional doped material systems.", "AI": {"tldr": "First computational framework using Meta's Universal MLIP for molecular dynamics simulation of MoS2 doped with 25 elements, enabling high-throughput screening at orders-of-magnitude reduced cost compared to DFT.", "motivation": "To bridge the accuracy-efficiency gap between first-principles methods and empirical potentials for doped 2D materials, enabling large-scale materials discovery and application-oriented design.", "method": "Used Meta's Universal Model for Atoms machine learning interatomic potential (MLIP) to simulate MoS2 doped with 25 elements, benchmarked against DFT calculations, and performed heating-cooling simulations of doped-MoS2 supercells.", "result": "MLIP accurately captures complex phenomena including dopant clustering, MoS2 layer fracturing, interlayer diffusion, and chemical compound formation at significantly reduced computational cost compared to DFT.", "conclusion": "The framework provides an open-source computational workflow for high-throughput screening of dopant candidates and optimization of compositions for targeted performance in tribological, electronic, and optoelectronic applications."}}
{"id": "2510.05951", "pdf": "https://arxiv.org/pdf/2510.05951", "abs": "https://arxiv.org/abs/2510.05951", "authors": ["Simon Hackl", "Simon Hubmer", "Ronny Ramlau"], "title": "A Geometrical Acoustics based Focusing Algorithm for Layered Media in Medical Ultrasound", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "comment": "32 pages, 23 figures", "summary": "Ultrasound imaging is a widely used, non-invasive diagnostic tool in modern\nmedicine. A crucial assumption is a constant sound speed in the observed\nmedium. For large scale sound speed variations, this assumption leads to\nblurred and distorted images. In this paper, we present a Geometrical Acoustics\nbased Focusing Algorithm (GOAT) which is able to correct for these aberrations,\ngiven a known layered medium setting with continuously differentiable medium\nboundaries. Existence and uniqueness conditions for a solution to the\nunderlying system of equations are given. Using numerical simulations, the\nprecision of our method is evaluated. Finally, the resulting image quality\nimprovements are demonstrated in a phantom-based experimental setup.", "AI": {"tldr": "GOAT algorithm corrects ultrasound image aberrations caused by sound speed variations in layered media.", "motivation": "Ultrasound imaging assumes constant sound speed, but variations cause blurred/distorted images that need correction.", "method": "Geometrical Acoustics based Focusing Algorithm (GOAT) for layered media with differentiable boundaries, with existence/uniqueness analysis.", "result": "Numerical simulations show method precision, phantom experiments demonstrate image quality improvements.", "conclusion": "GOAT effectively corrects ultrasound aberrations in layered media settings."}}
{"id": "2510.05999", "pdf": "https://arxiv.org/pdf/2510.05999", "abs": "https://arxiv.org/abs/2510.05999", "authors": ["J. M. Do \u00d3", "R. F. Freire", "J. Giacomoni", "E. S. Medeiros"], "title": "Existence and Nonexistence Breaking Results For a Weighted Elliptic Problem in Half-Space", "categories": ["math.AP", "35J55, 35J50, 37K05"], "comment": null, "summary": "In this paper we study the problem $-\\mathrm{div}(\\rho(x_N)\\nabla\nu)=a|u|^{p-2}u$ in $\\mathbb{R}^N_+$, $-\\partial u/\\partial x_N=b|u|^{q-2}u$ in\n$\\mathbb{R}^{N-1}$ where $a,b \\in \\mathbb{R}$, $p,q\\in (1,\\infty)$ and $\\rho$\nis a positive weight. We establish regularity results for weak solutions and,\nusing a variational approach combined with a new Pohozaev-type identity, we\nshow that the introduction of the weighted operator\n$-\\mathrm{div}(\\rho(x_N)\\nabla u)$ can reverse the known solvability behavior\nof the classical Laplacian case. Specifically, we identify regimes where the\nproblem admits solutions despite nonexistence for the corresponding case with\n$-\\Delta$, and vice versa, thus inverting the classical existence and\nnonexistence results.", "AI": {"tldr": "The paper studies a weighted elliptic boundary value problem and shows that introducing a weighted operator can reverse the classical solvability behavior compared to the Laplacian case.", "motivation": "To investigate how weighted operators affect the existence and nonexistence of solutions to elliptic boundary value problems, particularly reversing known results from the classical Laplacian case.", "method": "Established regularity for weak solutions and used a variational approach combined with a new Pohozaev-type identity to analyze solvability.", "result": "Identified regimes where the weighted problem admits solutions despite nonexistence for the classical Laplacian case, and vice versa, thus inverting classical existence/nonexistence results.", "conclusion": "The introduction of weighted operators can fundamentally change the solvability behavior of elliptic boundary value problems, reversing classical existence patterns."}}
{"id": "2510.05385", "pdf": "https://arxiv.org/pdf/2510.05385", "abs": "https://arxiv.org/abs/2510.05385", "authors": ["Rohan Arni", "Carlos Blanco"], "title": "Physics-Informed Neural Networks with Fourier Features and Attention-Driven Decoding", "categories": ["cs.LG", "physics.comp-ph"], "comment": "16 pages, 6 figures. Accepted at NeurIPS 2025 AI4Science workshop", "summary": "Physics-Informed Neural Networks (PINNs) are a useful framework for\napproximating partial differential equation solutions using deep learning\nmethods. In this paper, we propose a principled redesign of the PINNsformer, a\nTransformer-based PINN architecture. We present the Spectral PINNSformer\n(S-Pformer), a refinement of encoder-decoder PINNSformers that addresses two\nkey issues; 1. the redundancy (i.e. increased parameter count) of the encoder,\nand 2. the mitigation of spectral bias. We find that the encoder is unnecessary\nfor capturing spatiotemporal correlations when relying solely on\nself-attention, thereby reducing parameter count. Further, we integrate Fourier\nfeature embeddings to explicitly mitigate spectral bias, enabling adaptive\nencoding of multiscale behaviors in the frequency domain. Our model outperforms\nencoder-decoder PINNSformer architectures across all benchmarks, achieving or\noutperforming MLP performance while reducing parameter count significantly.", "AI": {"tldr": "The paper proposes Spectral PINNSformer (S-Pformer), a redesigned Transformer-based PINN architecture that eliminates encoder redundancy and integrates Fourier feature embeddings to mitigate spectral bias, achieving better performance with fewer parameters.", "motivation": "To address two key issues in PINNSformer architectures: encoder redundancy (increased parameter count) and spectral bias, which limits the ability to capture multiscale behaviors in PDE solutions.", "method": "Redesigned PINNSformer by removing the encoder (found unnecessary for spatiotemporal correlations with self-attention) and integrating Fourier feature embeddings for adaptive frequency domain encoding to mitigate spectral bias.", "result": "S-Pformer outperforms encoder-decoder PINNSformer architectures across all benchmarks, achieves or outperforms MLP performance while significantly reducing parameter count.", "conclusion": "The encoder in PINNSformers is redundant when using self-attention, and Fourier feature embeddings effectively mitigate spectral bias, enabling more efficient and accurate PDE solution approximation."}}
{"id": "2510.05980", "pdf": "https://arxiv.org/pdf/2510.05980", "abs": "https://arxiv.org/abs/2510.05980", "authors": ["Asiye Arif", "Tugba Yurdakadim"], "title": "Approximation by neural network operators of convolution type activated by deformed and parametrized half hyperbolic tangent function", "categories": ["math.NA", "cs.NA", "41A17, 41A25, 41A35, 47A58"], "comment": "29 pages, no figures", "summary": "Here, we introduce three kinds of neural network operators of convolution\ntype which are activated by q-deformed and \\b{eta}-parametrized half hyperbolic\ntangent function. We obtain quantitative convergence results to the identity\noperator with the use of modulus of continuity. Global smoothness preservation\nof our operators are also presented and the iterated versions of them are taken\ninto the consideration.", "AI": {"tldr": "The paper introduces three neural network convolution operators activated by q-deformed and \u03b2-parametrized half hyperbolic tangent functions, with convergence analysis and smoothness preservation properties.", "motivation": "To develop novel neural network operators with specific activation functions and analyze their mathematical properties including convergence and smoothness preservation.", "method": "Introduces three convolution-type neural network operators using q-deformed and \u03b2-parametrized half hyperbolic tangent activation functions, with quantitative convergence analysis using modulus of continuity.", "result": "Obtained quantitative convergence results to the identity operator and demonstrated global smoothness preservation properties of the operators.", "conclusion": "The proposed operators with q-deformed and \u03b2-parametrized activation functions exhibit desirable convergence properties and smoothness preservation, with iterated versions also considered."}}
{"id": "2510.06024", "pdf": "https://arxiv.org/pdf/2510.06024", "abs": "https://arxiv.org/abs/2510.06024", "authors": ["Yi Feng", "Weihua Wang"], "title": "Energy equality of the weak solutions to the fractional Navier-Stokes / MHD equations", "categories": ["math.AP", "76W05, 76B03, 35Q35, 76D05"], "comment": null, "summary": "In this paper, we study the problem of energy equality for weak solutions of\nthe 3D incompressible fractional Navier-Stokes / MHD equations. With the help\nof the technique of symmetrization and interpolation method, we obtain some new\nsufficient conditions including the Sobolev multiplier spaces, which insures\nthe validity of the energy equality of the weak solution to fractional MHD\nequations. Correspondingly, the results of fractional Navier-Stokes equations\nare obtained. And these energy equations are usually related to the uniqueness\nof solutions to the corresponding fractional Navier-Stokes / MHD equations.", "AI": {"tldr": "This paper studies energy equality for weak solutions of 3D incompressible fractional Navier-Stokes/MHD equations, establishing sufficient conditions in Sobolev multiplier spaces that ensure energy equality holds.", "motivation": "To investigate when energy equality holds for weak solutions of fractional Navier-Stokes and MHD equations, as these energy equations are related to solution uniqueness.", "method": "Using symmetrization and interpolation techniques to derive sufficient conditions in Sobolev multiplier spaces.", "result": "Obtained new sufficient conditions that ensure energy equality for weak solutions of fractional MHD equations, with corresponding results for fractional Navier-Stokes equations.", "conclusion": "The established conditions guarantee energy equality for weak solutions, which is important for understanding solution uniqueness in fractional Navier-Stokes and MHD equations."}}
{"id": "2510.05568", "pdf": "https://arxiv.org/pdf/2510.05568", "abs": "https://arxiv.org/abs/2510.05568", "authors": ["Nicholas H. Nelsen", "Houman Owhadi", "Andrew M. Stuart", "Xianjin Yang", "Zongren Zou"], "title": "Bilevel optimization for learning hyperparameters: Application to solving PDEs and inverse problems with Gaussian processes", "categories": ["stat.ML", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Methods for solving scientific computing and inference problems, such as\nkernel- and neural network-based approaches for partial differential equations\n(PDEs), inverse problems, and supervised learning tasks, depend crucially on\nthe choice of hyperparameters. Specifically, the efficacy of such methods, and\nin particular their accuracy, stability, and generalization properties,\nstrongly depends on the choice of hyperparameters. While bilevel optimization\noffers a principled framework for hyperparameter tuning, its nested\noptimization structure can be computationally demanding, especially in\nPDE-constrained contexts. In this paper, we propose an efficient strategy for\nhyperparameter optimization within the bilevel framework by employing a\nGauss-Newton linearization of the inner optimization step. Our approach\nprovides closed-form updates, eliminating the need for repeated costly PDE\nsolves. As a result, each iteration of the outer loop reduces to a single\nlinearized PDE solve, followed by explicit gradient-based hyperparameter\nupdates. We demonstrate the effectiveness of the proposed method through\nGaussian process models applied to nonlinear PDEs and to PDE inverse problems.\nExtensive numerical experiments highlight substantial improvements in accuracy\nand robustness compared to conventional random hyperparameter initialization.\nIn particular, experiments with additive kernels and neural\nnetwork-parameterized deep kernels demonstrate the method's scalability and\neffectiveness for high-dimensional hyperparameter optimization.", "AI": {"tldr": "Efficient hyperparameter optimization using Gauss-Newton linearization for PDE-constrained problems, eliminating costly nested optimization.", "motivation": "Hyperparameter choice critically affects accuracy, stability, and generalization in scientific computing methods, but bilevel optimization is computationally demanding for PDE-constrained problems.", "method": "Gauss-Newton linearization of inner optimization step provides closed-form updates, reducing each outer iteration to a single linearized PDE solve followed by explicit gradient-based hyperparameter updates.", "result": "Substantial improvements in accuracy and robustness compared to random hyperparameter initialization, demonstrated on nonlinear PDEs and inverse problems with Gaussian process models.", "conclusion": "The method is scalable and effective for high-dimensional hyperparameter optimization, working well with additive kernels and neural network-parameterized deep kernels."}}
{"id": "2510.05993", "pdf": "https://arxiv.org/pdf/2510.05993", "abs": "https://arxiv.org/abs/2510.05993", "authors": ["Xuemin Tu", "Jinjin Zhang"], "title": "Stochastic BDDC algorithms", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Stochastic balancing domain decomposition by constraints (BDDC) algorithms\nare developed and analyzed for the sampling of the solutions of linear\nstochastic elliptic equations with random coefficients. Different from the\ndeterministic BDDC algorithms, the stochastic BDDC algorithms have online and\noffline stages. At the offline stage, the Polynomial Chaos (PC) expansions of\ndifferent components of the BDDC algorithms are constructed based on the\nsubdomain local parametrization of the stochastic coefficients. During the\nonline stage, the sample-dependent BDDC algorithm can be implemented with a\nsmall cost. Under some assumptions, the condition number of the stochastic BDDC\npreconditioned operator is estimated. Numerical experiments confirm the theory\nand show that the stochastic BDDC algorithm outperforms the BDDC preconditioner\nconstructed using the mean value of the stochastic coefficients.", "AI": {"tldr": "Stochastic BDDC algorithms with online/offline stages for sampling solutions of linear stochastic elliptic equations with random coefficients, using Polynomial Chaos expansions and outperforming mean-based BDDC.", "motivation": "To develop efficient sampling methods for solutions of linear stochastic elliptic equations with random coefficients, improving upon deterministic BDDC algorithms by handling stochasticity more effectively.", "method": "Stochastic BDDC algorithms with offline stage for constructing Polynomial Chaos expansions of components using subdomain local parametrization, and online stage for efficient sample-dependent implementation.", "result": "Condition number of stochastic BDDC preconditioned operator is estimated under assumptions, and numerical experiments show it outperforms BDDC using mean coefficient values.", "conclusion": "Stochastic BDDC algorithms provide efficient sampling with theoretical guarantees and superior performance compared to mean-based approaches for stochastic elliptic equations."}}
{"id": "2510.05614", "pdf": "https://arxiv.org/pdf/2510.05614", "abs": "https://arxiv.org/abs/2510.05614", "authors": ["Beomjun Choi", "Kyeongsu Choi", "Dongjun Noh"], "title": "Ancient Gauss Curvature Flows of Bounded Width", "categories": ["math.DG", "math.AP", "53E99, 35J96"], "comment": "26 pages, 4 figures", "summary": "In this paper, we construct a pancake-like ancient compact solution with flat\nsides to the Gauss curvature flow, contained in a slab. Also, we construct\nsausage-like ancient compact solutions to the $\\alpha$-Gauss curvature flow\nwith $\\alpha >\\frac{1}{2}$, asymptotic to a round cylinder.", "AI": {"tldr": "Construction of pancake-like ancient compact solutions to Gauss curvature flow in a slab, and sausage-like ancient compact solutions to \u03b1-Gauss curvature flow (\u03b1>1/2) asymptotic to round cylinders.", "motivation": "To construct specific types of ancient compact solutions to Gauss curvature flows with particular geometric properties and asymptotic behaviors.", "method": "Mathematical construction of pancake-like solutions with flat sides contained in a slab, and sausage-like solutions for \u03b1-Gauss curvature flow with \u03b1>1/2.", "result": "Successfully constructed both pancake-like ancient compact solutions with flat sides in a slab, and sausage-like ancient compact solutions asymptotic to round cylinders for \u03b1-Gauss curvature flow with \u03b1>1/2.", "conclusion": "The paper demonstrates the existence of specific geometric ancient solutions to Gauss curvature flows with prescribed geometric properties and asymptotic behaviors."}}
{"id": "2510.06030", "pdf": "https://arxiv.org/pdf/2510.06030", "abs": "https://arxiv.org/abs/2510.06030", "authors": ["Rohit Goswami", "Hannes J\u00f3nsson"], "title": "Adaptive Pruning for Increased Robustness and Reduced Computational Overhead in Gaussian Process Accelerated Saddle Point Searches", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": "Invited article for the ChemPhysChem special issue dedicated to the\n  60th birthday of Prof. Debabrata Goswami. A preliminary version of this work\n  was presented at the UNOOS 2025 conference", "summary": "Gaussian process (GP) regression provides a strategy for accelerating saddle\npoint searches on high-dimensional energy surfaces by reducing the number of\ntimes the energy and its derivatives with respect to atomic coordinates need to\nbe evaluated. The computational overhead in the hyperparameter optimization\ncan, however, be large and make the approach inefficient. Failures can also\noccur if the search ventures too far into regions that are not represented well\nenough by the GP model. Here, these challenges are resolved by using\ngeometry-aware optimal transport measures and an active pruning strategy using\na summation over Wasserstein-1 distances for each atom-type in farthest-point\nsampling, selecting a fixed-size subset of geometrically diverse configurations\nto avoid rapidly increasing cost of GP updates as more observations are made.\nStability is enhanced by permutation-invariant metric that provides a reliable\ntrust radius for early-stopping and a logarithmic barrier penalty for the\ngrowth of the signal variance. These physically motivated algorithmic changes\nprove their efficacy by reducing to less than a half the mean computational\ntime on a set of 238 challenging configurations from a previously published\ndata set of chemical reactions. With these improvements, the GP approach is\nestablished as, a robust and scalable algorithm for accelerating saddle point\nsearches when the evaluation of the energy and atomic forces requires\nsignificant computational effort.", "AI": {"tldr": "This paper improves Gaussian process regression for saddle point searches by using geometry-aware optimal transport measures and active pruning to reduce computational overhead and enhance stability.", "motivation": "Standard GP regression for saddle point searches suffers from high computational overhead in hyperparameter optimization and can fail when searching regions not well represented by the GP model.", "method": "Uses geometry-aware optimal transport measures, active pruning with Wasserstein-1 distances for farthest-point sampling, permutation-invariant metrics for trust radius, and logarithmic barrier penalty for signal variance growth.", "result": "Reduces mean computational time by more than half on 238 challenging configurations from a chemical reaction dataset.", "conclusion": "The improved GP approach establishes a robust and scalable algorithm for accelerating saddle point searches when energy and force evaluations are computationally expensive."}}
{"id": "2510.05994", "pdf": "https://arxiv.org/pdf/2510.05994", "abs": "https://arxiv.org/abs/2510.05994", "authors": ["Zhiliang Deng", "Zhiyuan Wang", "Xiaomei Yang", "Xiaofei Guan"], "title": "A novel viewpoint for Bayesian inversion based on the Poisson point process", "categories": ["math.NA", "cs.NA", "35R30, 62F15, 86A22"], "comment": "15 pages", "summary": "We present a novel Bayesian framework for inverse problems in which the pos\nterior distribution is interpreted as the intensity measure of a Poisson point\nprocess\n  (PPP). The posterior density is approximated using kernel density estimation,\nand\n  the superposition property of PPPs is then exploited to enable efficient\nsampling\n  from each kernel component. This methodology offers a new means of exploring\nthe\n  posterior distribution and facilitates the generation of independent and\nidentically\n  distributed samples, thereby enhancing the analysis of inverse problem\nsolutions.", "AI": {"tldr": "A Bayesian framework interprets the posterior distribution as a Poisson point process intensity measure, using kernel density estimation and PPP superposition for efficient sampling.", "motivation": "To provide an efficient method for exploring posterior distributions in inverse problems by generating independent and identically distributed samples.", "method": "Interpret posterior as PPP intensity measure, approximate with kernel density estimation, exploit PPP superposition property for sampling from kernel components.", "result": "Enables efficient sampling from posterior distribution and generation of independent identically distributed samples.", "conclusion": "The framework offers a novel approach for posterior exploration in inverse problems, improving solution analysis through efficient sampling."}}
{"id": "2510.06080", "pdf": "https://arxiv.org/pdf/2510.06080", "abs": "https://arxiv.org/abs/2510.06080", "authors": ["Nga Nguyen", "Olivier Bonnefon", "Ren\u00e9 Gato", "Luis Almeida", "Lionel Roques"], "title": "Mechanistic-statistical inference of mosquito dynamics from mark-release-recapture data", "categories": ["q-bio.PE", "math.AP", "92D25, 60J60, 35K57, 62P10, 62F10"], "comment": null, "summary": "Biological control strategies against mosquito-borne diseases--such as the\nsterile insect technique (SIT), RIDL, and Wolbachia-based releases--require\nreliable estimates of dispersal and survival of released males. We propose a\nmechanistic--statistical framework for mark--release--recapture (MRR) data\nlinking an individual-based 2D diffusion model with its reaction--diffusion\nlimit. Inference is based on solving the macroscopic system and embedding it in\na Poisson observation model for daily trap counts, with uncertainty quantified\nvia a parametric bootstrap. We validate identifiability using simulated data\nand apply the model to an urban MRR campaign in El Cano (Havana, Cuba)\ninvolving four weekly releases of sterile Aedes aegypti males. The\nbest-supported model suggests a mean life expectancy of about five days and a\ntypical displacement of about 180 m. Unlike empirical fits of survival or\ndispersal, our mechanistic approach jointly estimates movement, mortality, and\ncapture, yielding biologically interpretable parameters and a principled\nframework for designing and evaluating SIT-based interventions.", "AI": {"tldr": "A mechanistic-statistical framework for estimating mosquito dispersal and survival from mark-release-recapture data, combining individual-based diffusion models with reaction-diffusion limits for biological control applications.", "motivation": "Biological control strategies like sterile insect technique require reliable estimates of male mosquito dispersal and survival, which current empirical methods struggle to provide.", "method": "Combines individual-based 2D diffusion model with reaction-diffusion limit, uses Poisson observation model for trap counts, and quantifies uncertainty via parametric bootstrap.", "result": "Applied to urban MRR data in Cuba, estimated mean life expectancy of ~5 days and typical displacement of ~180m for sterile Aedes aegypti males.", "conclusion": "The mechanistic approach jointly estimates movement, mortality, and capture parameters, providing biologically interpretable results and a principled framework for designing SIT interventions."}}
{"id": "2510.06150", "pdf": "https://arxiv.org/pdf/2510.06150", "abs": "https://arxiv.org/abs/2510.06150", "authors": ["Dakota K. Keblbeck", "Eric Mayotte", "Uwe Greife", "Kyle G. Leach", "Wouter Van De Pontseele", "Caitlyn Stone-Whitehead", "Luke Wanner", "Grace Wagner"], "title": "Simulation of Muon-induced Backgrounds for the Colorado Underground Research Institute (CURIE)", "categories": ["hep-ex", "physics.comp-ph", "physics.ins-det"], "comment": "14 pages, 12 figures, 6 tables", "summary": "We present a comprehensive Monte Carlo simulation of muon-induced backgrounds\nfor the Colorado Underground Research Institute (CURIE), a shallow-underground\nfacility with $\\approx 415$~m.w.e. overburden. Using coupled \\textsc{mute} and\n\\textsc{geant4} frameworks, we characterize the production and transport of\nmuon-induced secondaries through site-specific rock compositions and\ngeometries, establishing a proof-of-concept for high-precision, end-to-end\nsimulations. Our simulations employ angular-dependent muon energy\ndistributions, which improve secondary flux accuracy. For the Subatomic\nParticle Hideout and Cryolab I research spaces, we predict total muon-induced\nneutron fluxes of $(3.78 \\pm 0.61_{\\text{sys}}) \\times\n10^{-3}$~m$^{-2}$s$^{-1}$ and $(3.97 \\pm 0.65_{\\text{sys}}) \\times\n10^{-3}$~m$^{-2}$s$^{-1}$, respectively, consistent with empirical depth\nparameterizations. The simulated neutron energy spectra exhibit the expected\nthermal, epithermal, evaporation, and spallation components extending to GeV\nenergies. Electromagnetic backgrounds are expected to dominate the total flux,\nwith $\\gamma$-ray components of $(5.54 \\pm 0.91_{\\text{sys}}) \\times\n10^{-1}$~m$^{-2}$s$^{-1}$ and $(6.51 \\pm 1.06_{\\text{sys}}) \\times\n10^{-1}$~m$^{-2}$s$^{-1}$ for the Subatomic Particle Hideout and Cryolab I\nfacilities, respectively. These results provide quantitative background\npredictions for experimental design and sensitivity projections at shallow- and\ndeep-underground facilities. They further demonstrate that local geology and\noverburden geometry influence muon-induced secondary yields and energy spectra,\nemphasizing the need for site-specific simulations for accurate underground\nbackground characterization. Therefore, the simulation framework has been made\npublicly available for the broader low-background physics community to enable\nmeaningful inter-facility comparisons.", "AI": {"tldr": "Monte Carlo simulation of muon-induced backgrounds for CURIE underground facility using coupled MUTE and Geant4 frameworks, predicting neutron and gamma-ray fluxes with site-specific geological considerations.", "motivation": "To provide accurate background predictions for experimental design at shallow-underground facilities by accounting for local geology and overburden geometry effects on muon-induced secondaries.", "method": "Used coupled MUTE and Geant4 frameworks with angular-dependent muon energy distributions to simulate production and transport of muon-induced secondaries through site-specific rock compositions and geometries.", "result": "Predicted muon-induced neutron fluxes of (3.78\u00b10.61)\u00d710\u207b\u00b3 m\u207b\u00b2s\u207b\u00b9 and (3.97\u00b10.65)\u00d710\u207b\u00b3 m\u207b\u00b2s\u207b\u00b9 for two research spaces, and gamma-ray fluxes of (5.54\u00b10.91)\u00d710\u207b\u00b9 m\u207b\u00b2s\u207b\u00b9 and (6.51\u00b11.06)\u00d710\u207b\u00b9 m\u207b\u00b2s\u207b\u00b9 respectively, with expected energy spectra components.", "conclusion": "Local geology and overburden geometry significantly influence muon-induced secondary yields, requiring site-specific simulations for accurate underground background characterization. The simulation framework is publicly available for community use."}}
{"id": "2510.06110", "pdf": "https://arxiv.org/pdf/2510.06110", "abs": "https://arxiv.org/abs/2510.06110", "authors": ["Sandip Roy", "Debopriya Mukherjee", "Manil Thankamani Mohan"], "title": "Large deviation principle for a stochastic nonlinear damped Schrodinger equation", "categories": ["math.PR", "math.AP", "35Q55, 35R60, 60H15, 60F10"], "comment": "51 pages", "summary": "The present paper focuses on the stochastic nonlinear Schrodinger equation\nwith polynomial nonlinearity, and a zero-order (no derivatives involved) linear\ndamping. Here, the random forcing term appears as a mix of a nonlinear noise in\nthe Ito sense and a linear multiplicative noise in the Stratonovich sense. We\nprove the Laplace principle for the family of solutions to the stochastic\nsystem in a suitable Polish space, using the weak convergence framework of\nBudhiraja and Dupuis. This analysis is nontrivial, since it requires uniform\nestimates for the solutions of the associated controlled stochastic equation in\nthe underlying solution space in order to verify the weak convergence\ncriterion. The Wentzell Freidlin type large deviation principle is proved using\nVaradhan's lemma and Bryc's converse to Varadhan's lemma. The local\nwell-posedness of the skeleton equation (deterministic controlled system) is\nestablished by employing the Banach fixed point theorem, and the global well\nposedness is established via Yosida approximation. We show that the\nconservation law holds in the absence of the linear damping and Ito noise. The\nwell posedness of the stochastic controlled equation is also nontrivial in this\ncase. We use a truncation method, a stopping time argument, and the Yosida\ntechnique to get the global well-posedness of the stochastic controlled\nequation.", "AI": {"tldr": "The paper proves the Laplace principle and large deviation principle for the stochastic nonlinear Schr\u00f6dinger equation with polynomial nonlinearity, linear damping, and mixed Ito-Stratonovich noise.", "motivation": "To establish rigorous mathematical foundations for stochastic nonlinear Schr\u00f6dinger equations with mixed noise types, which are important in quantum mechanics and nonlinear optics.", "method": "Uses weak convergence framework of Budhiraja and Dupuis, Banach fixed point theorem for local well-posedness, Yosida approximation for global well-posedness, and truncation methods with stopping time arguments.", "result": "Successfully proved Laplace principle and Wentzell-Freidlin type large deviation principle, established local and global well-posedness for both deterministic and stochastic controlled equations.", "conclusion": "The analysis provides complete mathematical framework for stochastic nonlinear Schr\u00f6dinger equations with mixed noise, including conservation laws and rigorous well-posedness results."}}
{"id": "2510.05620", "pdf": "https://arxiv.org/pdf/2510.05620", "abs": "https://arxiv.org/abs/2510.05620", "authors": ["Salah Eddine Choutri", "Prajwal Chauhan", "Othmane Mazhar", "Saif Eddin Jabari"], "title": "Monte Carlo-Type Neural Operator for Differential Equations", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "stat.ML"], "comment": null, "summary": "The Monte Carlo-type Neural Operator (MCNO) introduces a framework for\nlearning solution operators of one-dimensional partial differential equations\n(PDEs) by directly learning the kernel function and approximating the\nassociated integral operator using a Monte Carlo-type approach. Unlike Fourier\nNeural Operators (FNOs), which rely on spectral representations and assume\ntranslation-invariant kernels, MCNO makes no such assumptions. The kernel is\nrepresented as a learnable tensor over sampled input-output pairs, and sampling\nis performed once, uniformly at random from a discretized grid. This design\nenables generalization across multiple grid resolutions without relying on\nfixed global basis functions or repeated sampling during training, while an\ninterpolation step maps between arbitrary input and output grids to further\nenhance flexibility. Experiments on standard 1D PDE benchmarks show that MCNO\nachieves competitive accuracy with efficient computational cost. We also\nprovide a theoretical analysis proving that the Monte Carlo estimator yields a\nbounded bias and variance under mild regularity assumptions. This result holds\nin any spatial dimension, suggesting that MCNO may extend naturally beyond\none-dimensional problems. More broadly, this work explores how Monte Carlo-type\nintegration can be incorporated into neural operator frameworks for\ncontinuous-domain PDEs, providing a theoretically supported alternative to\nspectral methods (such as FNO) and to graph-based Monte Carlo approaches (such\nas the Graph Kernel Neural Operator, GNO).", "AI": {"tldr": "MCNO is a Monte Carlo-type neural operator framework for learning 1D PDE solution operators by directly learning kernel functions and using Monte Carlo integration, without assuming translation-invariant kernels like FNOs.", "motivation": "To provide an alternative to Fourier Neural Operators that doesn't rely on spectral representations or translation-invariant kernel assumptions, and to explore Monte Carlo integration in neural operator frameworks for continuous-domain PDEs.", "method": "Represent the kernel as a learnable tensor over sampled input-output pairs, perform uniform random sampling once from a discretized grid, and use an interpolation step to map between arbitrary input and output grids. The Monte Carlo estimator approximates the integral operator.", "result": "MCNO achieves competitive accuracy with efficient computational cost on standard 1D PDE benchmarks, and theoretical analysis shows the Monte Carlo estimator has bounded bias and variance under mild regularity assumptions.", "conclusion": "MCNO provides a theoretically supported alternative to spectral methods and graph-based Monte Carlo approaches, with potential for natural extension beyond one-dimensional problems to any spatial dimension."}}
{"id": "2510.06173", "pdf": "https://arxiv.org/pdf/2510.06173", "abs": "https://arxiv.org/abs/2510.06173", "authors": ["Shuixin Li", "Jiecheng Chen", "Qingtang Jiang", "Lin Li"], "title": "Time-reassigned synchrosqueezing frequency-domain chirplet transform for multicomponent signals with intersecting group delay curves", "categories": ["eess.SP", "cs.NA", "math.NA"], "comment": null, "summary": "To analyze signals with rapid frequency variations or transient components,\nthe time-reassigned synchrosqueezing transform (TSST) and its variants have\nbeen recently proposed. Unlike the traditional synchrosqueezing transform, TSST\nsqueezes the time-frequency (TF) coefficients along the group delay (GD)\ntrajectories rather than the instantaneous frequency trajectories. Although\nTSST methods perform well in analyzing transient signals, they are\nfundamentally limited in processing multicomponent signals with intersecting GD\ncurves. This limitation compromises the accuracy of both feature extraction and\nsignal component recovery, thereby significantly reducing the interpretability\nof time-frequency representations (TFRs). This is particularly problematic in\nbroadband signal processing systems, where the linearity of the phase response\nis critical and precise measurement of group delay dispersion (GDD) is\nessential.\n  Motivated by the superior capability of frequency-domain signal modeling in\ncharacterizing rapidly frequency-varying signals, this paper proposes a novel\nthree-dimensional time-frequency-group delay dispersion (TF-GDD) representation\nbased on the frequency-domain chirplet transform. A subsequent time-reassigned\nsynchrosqueezing frequency-domain chirplet transform (TSFCT) is introduced to\nachieve a sharper TF-GDD distribution and more accurate GD estimation. For mode\nretrieval, a novel frequency-domain group signal separation operation (FGSSO)\nis proposed.The theoretical contributions include a derivation of the\napproximation error for the GD and GDD reference functions and an establishment\nof the error bounds for FGSSO-based mode retrieval. Experimental results\ndemonstrate that the proposed TSFCT and FGSSO effectively estimate GDs and\nretrieve modes--even for modes with intersecting GD trajectories.", "AI": {"tldr": "This paper proposes a novel time-frequency-group delay dispersion (TF-GDD) representation using frequency-domain chirplet transform to address limitations of existing TSST methods in handling multicomponent signals with intersecting group delay curves.", "motivation": "Existing TSST methods perform well for transient signals but fail with multicomponent signals having intersecting group delay curves, compromising feature extraction accuracy and signal component recovery, especially critical in broadband systems requiring precise group delay dispersion measurement.", "method": "Proposes a three-dimensional TF-GDD representation based on frequency-domain chirplet transform, introduces time-reassigned synchrosqueezing frequency-domain chirplet transform (TSFCT) for sharper distributions, and develops frequency-domain group signal separation operation (FGSSO) for mode retrieval.", "result": "Experimental results show that the proposed TSFCT and FGSSO effectively estimate group delays and retrieve modes even for signals with intersecting group delay trajectories, overcoming the fundamental limitation of previous methods.", "conclusion": "The proposed frequency-domain approach provides superior capability for analyzing rapidly frequency-varying signals and enables accurate group delay dispersion measurement and mode separation in complex multicomponent scenarios."}}
