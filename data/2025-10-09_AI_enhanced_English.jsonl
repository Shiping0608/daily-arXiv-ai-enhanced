{"id": "2510.06341", "pdf": "https://arxiv.org/pdf/2510.06341", "abs": "https://arxiv.org/abs/2510.06341", "authors": ["Juan Vicente Guti\u00e9rrez-Santacreu"], "title": "Finite element approximation and very weak solution existence in a two-dimensional, degenerate Keller-Segel model", "categories": ["math.NA", "cs.NA"], "comment": "25 pages", "summary": "This paper is devoted to the design and analysis of a numerical algorithm for\napproximating solutions of a degenerate cross-diffusion system, which models\nparticular instances of taxis-type migration processes under local sensing\nmechanisms. The degeneracy leads to solutions that are very weak due to the low\nregularity themselves. Specifically, the solutions satisfy pointwise bounds\n(such as positivity and the maximum principle), integrability (such as mass\nconservation), and dual a priori estimates.\n  The proposed numerical scheme combines a finite element spatial\ndiscretization with Euler time stepping. The discrete solutions preserve the\nabove-mentioned properties at the discrete level, enabling the derivation of\ncompactness arguments and the convergence (up to a subsequence) of the\nnumerical solutions to a very weak solution of the continuous problem on\ntwo-dimensional polygonal domains.", "AI": {"tldr": "A numerical algorithm for approximating solutions of degenerate cross-diffusion systems modeling taxis-type migration with local sensing, using finite elements and Euler time stepping that preserves solution properties.", "motivation": "To develop numerical methods for degenerate cross-diffusion systems that model taxis-type migration processes, where degeneracy leads to very weak solutions with low regularity.", "method": "Combines finite element spatial discretization with Euler time stepping, preserving solution properties (positivity, maximum principle, mass conservation, dual estimates) at discrete level.", "result": "The discrete solutions preserve the continuous problem's properties, enabling derivation of compactness arguments and convergence (up to subsequence) to very weak solutions on 2D polygonal domains.", "conclusion": "The proposed numerical scheme successfully approximates very weak solutions of degenerate cross-diffusion systems while preserving key mathematical properties at the discrete level."}}
{"id": "2510.06369", "pdf": "https://arxiv.org/pdf/2510.06369", "abs": "https://arxiv.org/abs/2510.06369", "authors": ["Tongtong Li", "Anne Gelb", "Yoonsang Lee"], "title": "Structurally informed data assimilation in two dimensions", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Accurate data assimilation (DA) for systems with piecewise-smooth or\ndiscontinuous state variables remains a significant challenge, as conventional\ncovariance-based ensemble Kalman filter approaches often fail to effectively\nbalance observations and model information near sharp features. In this paper\nwe develop a structurally informed DA framework using ensemble transform Kalman\nfiltering (ETKF). Our approach introduces gradient-based weighting matrices\nconstructed from finite difference statistics of the forecast ensemble, thereby\nallowing the assimilation process to dynamically adjust the influence of\nobservations and prior estimates according to local roughness. The design is\nintentionally flexible so that it can be suitably refined for sparse data\nenvironments. Numerical experiments demonstrate that our new structurally\ninformed data assimilation framework consistently yields greater accuracy when\ncompared to more conventional approaches.", "AI": {"tldr": "A structurally informed data assimilation framework using ensemble transform Kalman filtering (ETKF) that introduces gradient-based weighting matrices to handle discontinuous state variables more effectively than conventional approaches.", "motivation": "Conventional covariance-based ensemble Kalman filter approaches often fail to effectively balance observations and model information near sharp features in systems with piecewise-smooth or discontinuous state variables.", "method": "Developed a structurally informed DA framework using ETKF with gradient-based weighting matrices constructed from finite difference statistics of the forecast ensemble, allowing dynamic adjustment of observation and prior estimate influence based on local roughness.", "result": "Numerical experiments demonstrate that the new structurally informed data assimilation framework consistently yields greater accuracy compared to conventional approaches.", "conclusion": "The proposed framework effectively addresses the challenge of data assimilation for systems with discontinuous state variables through dynamic gradient-based weighting, showing improved performance over traditional methods."}}
{"id": "2510.06453", "pdf": "https://arxiv.org/pdf/2510.06453", "abs": "https://arxiv.org/abs/2510.06453", "authors": ["Bedoor AlShebli", "Bruno Gabriel Salvador Casara", "Anne Maass"], "title": "Media Coverage of War Victims: Journalistic Biases in Reporting on Israel and Gaza", "categories": ["math.NA", "cs.NA"], "comment": "28 page Main Manuscript with 3 Main Figures, along with a 64 page\n  Supplementary that includes 7 Supplementary Figures, 15 Supplementary Tables\n  and 5 Supplementary Notes", "summary": "October 7th 2023 marked the start of a war against Gaza, which is considered\none of the most devastating wars in modern history and has led to a stark\nattitudinal divide within and between countries. To investigate the role of\nmedia bias in reporting on this asymmetrical warfare, we analyzed over 14,000\nnews articles published during the first year of war in three Western (The New\nYork Times, BBC, CNN) and one non-Western English-language outlets (Al Jazeera\nEnglish). Exploring the media narratives concerning Israeli and Palestinian\nvictims experiencing hardship, we found three systematic biases in Western\nmedia. 1) Compared to Palestinian victims, represented mainly as\nundifferentiated collectives, Israeli victims were more likely to be portrayed\nas identifiable individual human beings. 2) Despite the striking difference in\nall forms of hardship (casualties, displacement, etc.), Western journalists\ncreated a false balance, equating Israeli and Palestinian suffering, by\npersistently referring back to the 7th of October massacre, even in the absence\nof new events involving Israeli victims. 3) When reporting on numbers of\nPalestinian (vs. Israeli) victims, journalists used language that casts doubt\nabout the credibility of the information and the reputation of the source\nproviding it, thereby selectively undermining the reader's trust in the\ninformation regarding Palestinian suffering. Together, our analysis reveals a\nseries of systematic journalistic biases in high-profile Western media that are\nabsent or greatly reduced in Al Jazeera.", "AI": {"tldr": "Analysis of over 14,000 news articles from Western and non-Western media reveals systematic biases in reporting on Israeli-Palestinian conflict, including differential victim portrayal, false balance in suffering, and credibility undermining of Palestinian casualty figures.", "motivation": "To investigate media bias in reporting on asymmetrical warfare during the Gaza war starting October 7th 2023, examining how different media outlets portray Israeli and Palestinian victims.", "method": "Analyzed over 14,000 news articles from three Western outlets (NYT, BBC, CNN) and one non-Western outlet (Al Jazeera English) published during the first year of the Gaza war, focusing on media narratives about victims experiencing hardship.", "result": "Found three systematic biases in Western media: 1) Israeli victims portrayed as identifiable individuals vs. Palestinian victims as undifferentiated collectives; 2) False balance created by equating suffering despite actual disparity; 3) Language casting doubt on credibility of Palestinian casualty figures. These biases were absent or greatly reduced in Al Jazeera.", "conclusion": "Western media exhibits systematic journalistic biases in conflict reporting that dehumanize Palestinian victims, create false equivalences, and undermine trust in information about Palestinian suffering, while Al Jazeera shows significantly less bias."}}
{"id": "2510.06490", "pdf": "https://arxiv.org/pdf/2510.06490", "abs": "https://arxiv.org/abs/2510.06490", "authors": ["Danil Akhtiamov", "Reza Ghane", "Babak Hassibi"], "title": "A Precise Performance Analysis of the Randomized Singular Value Decomposition", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "The Randomized Singular Value Decomposition (RSVD) is a widely used algorithm\nfor efficiently computing low-rank approximations of large matrices, without\nthe need to construct a full-blown SVD. Of interest, of course, is the\napproximation error of RSVD compared to the optimal low-rank approximation\nerror obtained from the SVD. While the literature provides various upper and\nlower error bounds for RSVD, in this paper we derive precise asymptotic\nexpressions that characterize its approximation error as the matrix dimensions\ngrow to infinity. Our expressions depend only on the singular values of the\nmatrix, and we evaluate them for two important matrix ensembles: those with\npower law and bilevel singular value distributions. Our results aim to quantify\nthe gap between the existing theoretical bounds and the actual performance of\nRSVD. Furthermore, we extend our analysis to polynomial-filtered RSVD, deriving\nperformance characterizations that provide insights into optimal filter\nselection.", "AI": {"tldr": "Derives precise asymptotic expressions for RSVD approximation error, evaluates them for power law and bilevel singular value distributions, and extends analysis to polynomial-filtered RSVD.", "motivation": "To quantify the gap between existing theoretical bounds and actual RSVD performance, and provide insights for optimal filter selection in polynomial-filtered RSVD.", "method": "Derives precise asymptotic expressions for RSVD approximation error that depend only on matrix singular values, and evaluates them for power law and bilevel singular value distributions.", "result": "Obtained precise asymptotic characterizations of RSVD approximation error for growing matrix dimensions, with specific evaluations for important matrix ensembles.", "conclusion": "The analysis provides quantitative understanding of RSVD performance gap and offers insights for optimal filter design in polynomial-filtered variants."}}
{"id": "2510.06773", "pdf": "https://arxiv.org/pdf/2510.06773", "abs": "https://arxiv.org/abs/2510.06773", "authors": ["Wadim Gerner"], "title": "Influence of coil geometry and coil-plasma distance on the magnetic field approximation error", "categories": ["physics.plasm-ph", "math-ph", "math.MP"], "comment": "10 pages, 2 figures", "summary": "We investigate analytically two questions:\n  1) How does the coil geometry influence the effect of electric current noise\non the induced magnetic field?\n  2) How does the coil-plasma distance influence our ability to control the\npointwise magnetic field error in terms of the average magnetic field error?\n  Regarding (1), we argue that the main geometric quantities of interest are\nthe notion of reach and the volume of the region enclosed by the coils. Our\nmain finding is a quantitative formula which shows that the larger the reach\nand the smaller the volume of the region enclosed by the coils, the smaller is\nthe influence of the electric current uncertainty on the magnetic fields.\n  Regarding (2), we show that the pointwise magnetic field error can be\ncontrolled (modulo an explicit constant) by the average square-magnetic\nfield-error times $(\\text{coil-plasma distance})^{-\\frac{3}{2}}$.", "AI": {"tldr": "The paper analyzes how coil geometry and coil-plasma distance affect magnetic field errors from electric current noise, finding that larger reach and smaller enclosed volume reduce noise effects, and that pointwise field error is controlled by average error times (distance)^{-3/2}.", "motivation": "To understand how coil geometry and positioning affect magnetic field precision in plasma applications, specifically addressing electric current noise propagation and field error control.", "method": "Analytical investigation using geometric quantities (reach and enclosed volume) and mathematical formulations to derive quantitative relationships between coil parameters and magnetic field errors.", "result": "Found that larger coil reach and smaller enclosed volume reduce current noise effects on magnetic fields, and established that pointwise field error scales with average error times (coil-plasma distance)^{-3/2}.", "conclusion": "Coil geometry optimization (maximizing reach, minimizing volume) and proper coil-plasma distance selection are crucial for controlling magnetic field precision in plasma systems."}}
{"id": "2510.06595", "pdf": "https://arxiv.org/pdf/2510.06595", "abs": "https://arxiv.org/abs/2510.06595", "authors": ["Caitlyn Stone-Whitehead", "Israel Hernandez", "Connor Bray", "Allison Davenport", "Spencer Fretwell", "Abigail Gillespie", "Joren Husic", "Mingyu Li", "Andrew Marino", "Kyle Leach", "Bismah Rizwan", "Wouter Van De Pontseele", "Grace Wagner"], "title": "Integration of Silica in G4CMP for Phonon Simulations: Framework and Tools for Material Integration", "categories": ["physics.comp-ph"], "comment": "6 pages, 4 figures, LTD25 conference proceeding submission", "summary": "Superconducting detectors with sub-eV energy resolution have demonstrated\nsuccess setting limits on Beyond the Standard Model (BSM) physics due to their\nunique sensitivity to low-energy events. G4CMP, a Geant4-based extension for\ncondensed matter physics, provides a comprehensive toolkit for modeling phonon\nand charge dynamics in cryogenic materials. This paper introduces a technical\nformalism to support the superconducting qubit and low-threshold detector\ncommunity in implementing phonon simulations in custom materials into the\nG4CMP. As a case study, we present the results of a detailed analysis of silica\nphonon transport properties relevant for simulating substrate backgrounds in\nBeryllium Electron capture in Superconducting Tunnel junctions (BeEST)-style\nexperiments using G4CMP. Additionally, Python-based tools were developed to aid\nusers in implementing their own materials and are available on the G4CMP\nrepository.", "AI": {"tldr": "G4CMP provides tools for phonon and charge dynamics in cryogenic materials, with new formalism for implementing phonon simulations in custom materials, demonstrated through silica phonon transport analysis for BeEST experiments.", "motivation": "To support the superconducting qubit and low-threshold detector community in implementing phonon simulations in custom materials using G4CMP, particularly for BSM physics experiments.", "method": "Developed technical formalism for phonon simulations in custom materials, conducted detailed analysis of silica phonon transport properties as case study, and created Python-based tools for material implementation.", "result": "Successfully implemented phonon simulation capabilities in G4CMP, with specific analysis of silica phonon transport relevant to BeEST-style experiments, and provided user tools for custom material implementation.", "conclusion": "G4CMP now offers enhanced capabilities for phonon simulations in custom materials, supporting the superconducting detector community in BSM physics research with practical tools and demonstrated applications."}}
{"id": "2510.06246", "pdf": "https://arxiv.org/pdf/2510.06246", "abs": "https://arxiv.org/abs/2510.06246", "authors": ["Pylyp Cherevan"], "title": "Log-free estimate for the resonant paraproduct in the 3D Navier-Stokes equations", "categories": ["math.AP", "35Q30, 76D05, 42B20"], "comment": "55 pages, no figures", "summary": "We consider the resonant paraproduct (high-high $\\to$ low regime) in the\nnonlinearity $(u\\cdot\\nabla)u$ for the three-dimensional Navier-Stokes\nequations. For sufficiently smooth, divergence-free u, we establish the a\npriori estimate without logarithmic loss $$\\|R_N(u)\\|{\\dot H^{-1}} \\lesssim\nN^{-1}\\,\\|u\\|{\\dot H^{1/2}}\\,\\|u\\|_{\\dot H^{1}},$$ with a constant independent\nof the dyadic frequency $N$. The proof combines phase-geometric integration by\nparts along an adapted frame, wave-packet discretization at scale $N^{-1/2}$,\nand an anisotropic Strichartz estimate on time windows of length $N^{-1/2}$. In\nthe wide angular region we apply bilinear decoupling on a rank-3 phase surface;\nin the geometry at hand the minimal curvature yields a gain of order\n$N^{-1/6+o(1)}$ (with $o(1)\\to 0$ as $N\\to\\infty$), which suffices to remove\nthe logarithmic loss. The contribution from the narrow region is handled\nseparately by an energy argument in $\\dot H^{-1}$ using null-form suppression\nnear the interaction diagonal. The resulting bound is scale-consistent and\nrequires no smallness assumptions, only the divergence-free condition on $u$.\nThe analysis is restricted to a single resonant component of the paraproduct;\npotential extensions are discussed.", "AI": {"tldr": "The paper establishes an a priori estimate for the resonant paraproduct in 3D Navier-Stokes equations without logarithmic loss, using geometric integration, wave-packet discretization, and anisotropic Strichartz estimates.", "motivation": "To improve the understanding of the nonlinear term (u\u00b7\u2207)u in 3D Navier-Stokes equations by obtaining better bounds for the resonant paraproduct component, eliminating the logarithmic loss that typically appears in such estimates.", "method": "Combines phase-geometric integration by parts along adapted frames, wave-packet discretization at scale N^{-1/2}, anisotropic Strichartz estimates, bilinear decoupling on rank-3 phase surfaces, and energy arguments in H^{-1} for different angular regions.", "result": "Proves the bound \u2225R_N(u)\u2225_{H^{-1}} \u2272 N^{-1} \u2225u\u2225_{H^{1/2}} \u2225u\u2225_{H^{1}} with constant independent of dyadic frequency N, achieving scale-consistent estimate without logarithmic loss or smallness assumptions.", "conclusion": "The analysis successfully removes the logarithmic loss in resonant paraproduct estimates for 3D Navier-Stokes, though restricted to a single component, with potential for extensions to broader contexts."}}
{"id": "2510.06586", "pdf": "https://arxiv.org/pdf/2510.06586", "abs": "https://arxiv.org/abs/2510.06586", "authors": ["Alexandre X. Milewski", "Charles S. Peskin"], "title": "Convergence of the Immersed Boundary Method for an Elastically Bound Particle Immersed in a 2D Navier-Stokes Fluid Fluid", "categories": ["math.NA", "cs.NA", "74F10 (Primary) 65M12, 76M20 (Secondary)"], "comment": "31 pages, 3 figures, submitted to SIAM Journal on Numerical Analysis", "summary": "The immersed boundary (IB) method has been used as a means to simulate\nfluid-membrane interactions in a wide variety of biological and engineering\napplications. Although the numerical convergence of the method has been\nempirically verified, it is theoretically unproved because of the singular\nforcing terms present in the governing equations. This paper is motivated by a\nspecific variant of the IB method, in which the fluid is 2 dimensions greater\nthan the dimension of the immersed structure. In these co-dimension 2 problems\nthe immersed boundary is necessarily mollified in the continuous formulation.\nIn this paper we leverage this fact to prove convergence of the IB method as\napplied to a moving elastically bound particle in a fully non-linear fluid.", "AI": {"tldr": "The paper proves convergence of the immersed boundary (IB) method for co-dimension 2 problems where the fluid is 2 dimensions greater than the immersed structure, addressing theoretical gaps in previous empirical verifications.", "motivation": "The IB method has been empirically verified but lacks theoretical proof due to singular forcing terms in governing equations. This paper addresses this gap specifically for co-dimension 2 problems where the immersed boundary is mollified.", "method": "The authors leverage the mollification of the immersed boundary in co-dimension 2 problems to provide a theoretical convergence proof for the IB method applied to moving elastically bound particles in non-linear fluids.", "result": "The paper successfully proves convergence of the immersed boundary method for the specific case of co-dimension 2 problems with mollified boundaries.", "conclusion": "This work provides the first theoretical convergence proof for the IB method in co-dimension 2 scenarios, establishing a rigorous foundation for its application in fluid-membrane interaction simulations."}}
{"id": "2510.06794", "pdf": "https://arxiv.org/pdf/2510.06794", "abs": "https://arxiv.org/abs/2510.06794", "authors": ["Thomas J. G. Smits", "Jannis Teunissen", "Ute Ebert"], "title": "3D simulations of negative streamers in CO$_2$ with admixtures of C$_4$F$_7$N", "categories": ["physics.plasm-ph"], "comment": "16 pages, 14 figures, 3 tables", "summary": "CO$_2$ with an admixture of C$_4$F$_7$N could serve as an eco-friendly\nalternative to the extreme greenhouse gas SF$_6$ in high-voltage insulation.\nStreamer discharges in such gases are different from those in air due to the\nrapid conductivity decay in the streamer channels. Furthermore, since no\neffective photoionisation mechanism is known, we expect discharge growth to be\nmore stochastic than in air. In this paper we investigate whether conventional\nfluid models can be used to simulate streamers in CO$_2$ with admixtures of\nC$_4$F$_7$N of 1 or 10%. We focus on 3D simulations of negative streamers.\nFirst we review cross section databases for C$_4$F$_7$N and CO$_2$. Then we\ncompare a two-term Boltzmann solver with a Monte Carlo method to compute\nreaction and transport coefficients from the cross sections. Afterwards we\ncompare 3D fluid simulations with the local field (LFA) or local energy\napproximation (LEA) against particle simulations. In general, we find that the\nresults of particle and fluid models are quite similar. One difference we\nobserve is that particle simulations are intrinsically stochastic, leading to\nmore branching. Furthermore, the LEA model does not show better agreement with\nthe particle simulations than the LFA model. We also discuss the effect and\nchoice of different boundary conditions on the negative rod electrode.", "AI": {"tldr": "The paper investigates whether conventional fluid models can simulate streamer discharges in CO2 with C4F7N admixtures (1% or 10%) as eco-friendly alternatives to SF6 gas insulation. It compares 3D fluid simulations using local field approximation (LFA) and local energy approximation (LEA) against particle simulations for negative streamers.", "motivation": "CO2 with C4F7N admixtures could serve as eco-friendly alternatives to the extreme greenhouse gas SF6 in high-voltage insulation. Streamer discharges in these gases differ from air due to rapid conductivity decay and lack of effective photoionization mechanisms, making discharge growth more stochastic.", "method": "The study reviews cross section databases for C4F7N and CO2, compares two-term Boltzmann solver with Monte Carlo method for computing reaction and transport coefficients, and performs 3D simulations comparing fluid models (LFA and LEA) against particle simulations for negative streamers.", "result": "Particle and fluid models show generally similar results. Key differences include particle simulations being intrinsically stochastic leading to more branching, and the LEA model not showing better agreement with particle simulations than the LFA model. Different boundary conditions on the negative rod electrode also affect results.", "conclusion": "Conventional fluid models can be used to simulate streamers in CO2 with C4F7N admixtures, with fluid and particle models producing generally similar results despite some differences in stochastic behavior and branching patterns."}}
{"id": "2510.06873", "pdf": "https://arxiv.org/pdf/2510.06873", "abs": "https://arxiv.org/abs/2510.06873", "authors": ["Haoting Zhang", "Jiuyang Shi", "Qiuhan Jia", "Junjie Wang", "Jian Sun"], "title": "GSM: GPU Accelerated Rare Events Sampling with Machine Learning Potentials", "categories": ["physics.comp-ph"], "comment": null, "summary": "Enhanced sampling has achieved considerable success in molecular dynamics\n(MD) simulations of rare events. Metadynamics (MetaD), owing to its excellent\ncompatibility with MD engines, became one of the most popular enhanced sampling\nmethods. With the boom of GPU computing and the advent of machine learning\npotentials (MLPs), high-accuracy, large-scale MD simulations have gradually\nbecome feasible. However, the corresponding GPU-based enhanced sampling tools\nhave not yet been well adapted to this progress. To enable full-life-cycle GPU\nMetaD simulations, we propose the GPU Sampling MetaD (GSM) package. By\nleveraging MLPs, it is feasible to perform high-precision rare event sampling\nfor systems comprising millions of atoms on a typical single GPU, which offers\na potential solution to many size-dependent problems. By conducting sampling in\nseveral classical systems, the results sufficiently demonstrate the capability\nof this package to simulate diverse atomic systems, especially efficient in\nlarge scale systems.", "AI": {"tldr": "GSM is a GPU-based Metadynamics package that enables full-life-cycle enhanced sampling for large-scale molecular dynamics simulations using machine learning potentials.", "motivation": "With the rise of GPU computing and machine learning potentials, high-accuracy large-scale MD simulations became feasible, but existing GPU-based enhanced sampling tools haven't kept pace with this progress.", "method": "Developed GPU Sampling MetaD (GSM) package that leverages machine learning potentials to perform Metadynamics simulations on single GPUs for systems with millions of atoms.", "result": "The package successfully performs high-precision rare event sampling for large systems on single GPUs, demonstrating capability across diverse atomic systems with particular efficiency in large-scale systems.", "conclusion": "GSM provides a potential solution to many size-dependent problems by enabling full GPU-accelerated Metadynamics simulations for large systems using machine learning potentials."}}
{"id": "2510.06569", "pdf": "https://arxiv.org/pdf/2510.06569", "abs": "https://arxiv.org/abs/2510.06569", "authors": ["Pedro Fellype Pontes", "Minbo Yang"], "title": "Regularity theory for mixed local-nonlocal problem involving general stable operators", "categories": ["math.AP", "35B65"], "comment": null, "summary": "In this paper, we study the regularity of solutions to a linear elliptic\nequation involving a mixed local-nonlocal operator of the form $$Lu -\n\\operatorname{div}\\big(a(x)\\nabla u(x)\\big)= f, \\quad \\text{in } \\Omega \\subset\n\\mathbb{R}^n,$$ where $L$ is a general stable L\\'{e}vy type operator and\n$a(\\cdot)$ is a positive H\\\"{o}lder continuous weight. By establishing a\nmaximum principle and a Liouville-type result in the entire space, we are able\nto derive the interior regularity and the regularity up to the boundary of the\nsolutions under suitable assumptions on $f(x)$ and $a(x)$ .", "AI": {"tldr": "Study of regularity for solutions to linear elliptic equations with mixed local-nonlocal operators involving stable L\u00e9vy type operators and H\u00f6lder continuous weights.", "motivation": "To understand the regularity properties of solutions to elliptic equations that combine both local (divergence form) and nonlocal (L\u00e9vy type) operators, which arise in various applications including mathematical physics and finance.", "method": "Establish maximum principle and Liouville-type result in entire space, then use these to derive interior and boundary regularity under appropriate assumptions on forcing term f(x) and weight a(x).", "result": "Successfully proved interior regularity and boundary regularity for solutions to the mixed local-nonlocal elliptic equation.", "conclusion": "The developed maximum principle and Liouville-type result provide effective tools for analyzing regularity of solutions to mixed local-nonlocal elliptic equations with stable L\u00e9vy operators and H\u00f6lder continuous coefficients."}}
{"id": "2510.06643", "pdf": "https://arxiv.org/pdf/2510.06643", "abs": "https://arxiv.org/abs/2510.06643", "authors": ["R. S. Karimov", "D. D. Atoev"], "title": "Algorithm for constructing optimal explicit finite-difference formulas in the Hilbert space", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This work presents problems of constructing finite-difference formulas in the\nHilbert space, i.e., setting problems of constructing finite-difference\nformulas using functional methods. The work presents a functional statement of\nthe problem of optimizing finite-difference formulas in the space\n$W_{2}^{\\left(m,m-1\\right)} \\left(0,1\\right)$. Here, representations of optimal\ncoefficients of explicit finite-difference formulas of the Adams type on\nclasses $W_{2}^{\\left(m,m-1\\right)} \\left(0,1\\right)$ for any $m\\ge 3$ will be\nfound.", "AI": {"tldr": "This paper presents functional methods for constructing and optimizing finite-difference formulas in Hilbert spaces, specifically focusing on Adams-type explicit formulas in the space W\u2082^(m,m-1)(0,1) for m\u22653.", "motivation": "To address the challenges of constructing finite-difference formulas using functional methods in Hilbert spaces, particularly for optimization problems in the space W\u2082^(m,m-1)(0,1).", "method": "Uses functional methods and optimization techniques in the Hilbert space W\u2082^(m,m-1)(0,1) to construct finite-difference formulas, specifically focusing on explicit Adams-type formulas.", "result": "Found representations of optimal coefficients for explicit finite-difference formulas of the Adams type on classes W\u2082^(m,m-1)(0,1) for any m\u22653.", "conclusion": "The functional approach successfully enables the construction and optimization of finite-difference formulas in Hilbert spaces, providing explicit coefficient representations for Adams-type formulas in the specified function spaces."}}
{"id": "2510.07144", "pdf": "https://arxiv.org/pdf/2510.07144", "abs": "https://arxiv.org/abs/2510.07144", "authors": ["Jingyu Peng", "Jiansen He"], "title": "Chaotic Motion of Ions In Finite-amplitude Low-frequency Alfv\u00e9n Waves", "categories": ["physics.plasm-ph"], "comment": "5 pages, 4 figures", "summary": "Finite-amplitude low-frequency Alfv\\'en waves (AWs) are commonly found in\nplasma environments, such as space plasmas, and play a crucial role in ion\nheating. In this study, we examine the nonlinear interactions between\nmonochromatic AWs and ions. When the wave amplitude and propagation angle lie\nwithin certain ranges, particle motion becomes chaotic. We quantify this\nchaotic behavior using the maximum Lyapunov exponent, $\\lambda_m$, and find\nthat chaos depends on the particles' initial states. To characterize the\nproportion of chaotic particles across different initial states, we introduce\nthe Chaos Ratio ($CR$). The threshold for the onset of global chaos is\ncalculated as the contour line of $CR=0.01$. We analyze changes in the magnetic\nmoment during particle motion and identify the physical image of chaos as\npitch-angle scattering caused by wave-induced field line curvature (WFLC).\nConsequently, the condition for chaos can be expressed as the effective\nrelative curvature radius $P_{eff.}<C$, with $C$ being a constant. We\nanalytically determine the chaos region in the $(k_x,\\,k_z,\\,B_w)$ parameter\nspace, and the results show excellent agreement with the global chaos threshold\ngiven by $CR=0.01$.", "AI": {"tldr": "Analysis of nonlinear interactions between monochromatic Alfv\u00e9n waves and ions, showing chaotic particle motion quantified by Lyapunov exponents and Chaos Ratio, with chaos threshold determined by wave-induced field line curvature.", "motivation": "Finite-amplitude low-frequency Alfv\u00e9n waves are common in space plasmas and play crucial roles in ion heating, but their nonlinear interactions with ions need better understanding.", "method": "Quantified chaotic behavior using maximum Lyapunov exponent and introduced Chaos Ratio (CR) to characterize proportion of chaotic particles. Analyzed magnetic moment changes and identified chaos mechanism as pitch-angle scattering from wave-induced field line curvature.", "result": "Found chaos depends on particles' initial states. Determined chaos threshold as CR=0.01 contour line. Established chaos condition as effective relative curvature radius P_eff < C. Analytical chaos region in (k_x, k_z, B_w) parameter space matches well with CR=0.01 threshold.", "conclusion": "Chaotic ion motion in Alfv\u00e9n waves is driven by wave-induced field line curvature causing pitch-angle scattering, with analytical chaos conditions that agree well with numerical simulations."}}
{"id": "2510.06271", "pdf": "https://arxiv.org/pdf/2510.06271", "abs": "https://arxiv.org/abs/2510.06271", "authors": ["Jo\u00e3o P. da Cruz"], "title": "Asymptotic Vanishing of the Success Probability in Shor's Algorithm", "categories": ["quant-ph", "math-ph", "math.MP", "physics.comp-ph"], "comment": null, "summary": "Shor's factoring algorithm guarantees a success probability of at least one\nhalf for any fixed modulus N = pq with distinct primes p and q. We show that\nthis guarantee does not extend to the asymptotic regime. As N -> infinity, the\nmultiplicative groups Omega_N = (Z/NZ)^x form a non-tight family of probability\nspaces, and the probability weight associated with successful bases,\nproportional to p(success | a', N) p(a' | N), decays as 1/phi(N). The ensemble\nof uniform measures {mu_N} therefore admits no weak limit, implying an\nasymptotic loss of ergodicity. Monte Carlo simulations up to N <= 10^6 confirm\nthis decay and the absence of a stationary success probability. These results\ndemonstrate that the \"expected polynomial time\" in order finding is only\nlocally defined: no global expectation exists once the arithmetic domain\nexpands. The asymptotic vanishing of success probability explains the empirical\nabsence of large-N implementations of Shor's algorithm and sets a fundamental\nlimit on the scalability of quantum factoring.", "AI": {"tldr": "Shor's factoring algorithm loses its guaranteed success probability in the asymptotic regime as N \u2192 \u221e, with success probability decaying as 1/\u03c6(N) and no global expectation existing for polynomial-time order finding.", "motivation": "To understand why Shor's algorithm, which guarantees at least 50% success probability for fixed N, fails to maintain this guarantee when extended to arbitrarily large moduli N.", "method": "Analyzed the asymptotic behavior of multiplicative groups \u03a9_N = (Z/NZ)^\u00d7 as probability spaces, showing they form a non-tight family. Used mathematical analysis of probability measures and Monte Carlo simulations up to N \u2264 10^6.", "result": "Success probability decays as 1/\u03c6(N) as N \u2192 \u221e, the ensemble of uniform measures admits no weak limit, and there is asymptotic loss of ergodicity. No stationary success probability exists in the limit.", "conclusion": "The 'expected polynomial time' in order finding is only locally defined - no global expectation exists as the arithmetic domain expands. This explains the empirical absence of large-N Shor's algorithm implementations and sets a fundamental limit on quantum factoring scalability."}}
{"id": "2510.06613", "pdf": "https://arxiv.org/pdf/2510.06613", "abs": "https://arxiv.org/abs/2510.06613", "authors": ["Kui Li", "Mingxiang Li", "Juncheng Wei"], "title": "On a new region for the Lane-Emden conjecture in higher dimensions", "categories": ["math.AP", "35J60"], "comment": "27 pages. Comments are welcome!", "summary": "We study the Lane-Emden conjecture, which asserts the non-existence of\nnon-trivial, non-negative solutions to the Lane-Emden system\n  \\[\n  -\\Delta u = v^p, \\quad -\\Delta v = u^q, \\quad x \\in \\mathbb{R}^n\\]\n  in the subcritical regime. By employing an Obata-type integral inequality,\nPicone's identity, and exploiting the scaling invariance of the system, we\nprove that the conjecture holds for any dimension $n \\geq 5$ and exponents\nsatisfying $p\\geq 1,q\\geq 1$, and\n  \\[\n  \\frac{1}{p+1} + \\frac{1}{q+1} \\geq 1 - \\frac{2}{n} + \\frac{4}{n^2}.\n  \\]", "AI": {"tldr": "The paper proves the Lane-Emden conjecture for dimensions n\u22655 in the subcritical regime using Obata-type integral inequality, Picone's identity, and scaling invariance.", "motivation": "To establish the non-existence of non-trivial, non-negative solutions to the Lane-Emden system in the subcritical regime, addressing a long-standing conjecture in partial differential equations.", "method": "Employed Obata-type integral inequality, Picone's identity, and exploited the scaling invariance properties of the Lane-Emden system.", "result": "Proved that the Lane-Emden conjecture holds for any dimension n\u22655 and exponents satisfying p\u22651, q\u22651 with the given inequality condition.", "conclusion": "The Lane-Emden conjecture is valid in the specified parameter range, confirming the absence of non-trivial solutions to the system in higher dimensions."}}
{"id": "2510.06653", "pdf": "https://arxiv.org/pdf/2510.06653", "abs": "https://arxiv.org/abs/2510.06653", "authors": ["Paulo Akira F. Enabe", "Rodrigo Provasi"], "title": "Mass-Lumped Virtual Element Method with Strong Stability-Preserving Runge-Kutta Time Stepping for Two-Dimensional Parabolic Problems", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper presents a mass-lumped Virtual Element Method (VEM) with explicit\nStrong Stability-Preserving Runge-Kutta (SSP-RK) time integration for\ntwo-dimensional parabolic problems on general polygonal meshes. A diagonal mass\nmatrix is constructed via row-sum operations combined with flooring to ensure\nuniform positivity. Stabilization terms vanish identically under row summation,\nso the lumped weights derive solely from the $L^2$ projector and are computable\nthrough a small polynomial system at cost $\\mathcal{O}(N_k^3)$ per element. The\nresulting lumped bilinear form satisfies $L^2$-equivalence with\nedge-count-independent constants, yielding a symmetric positive definite\ndiscrete inner product. A mesh-robust spectral bound\n$\\lambda_{\\max}\\big((\\hat{\\mathbf{M}}_h)^{-1}\\mathbf{K}_h\\big) \\le\nC_{\\mathrm{inv}}^2/\\hat{\\beta}_* \\cdot h^{-2}$ is established with constants\ndepending only on spatial dimension, polynomial order, and mesh regularity.\nThis delivers the classical diffusion-type CFL condition $\\Delta\nt=\\mathcal{O}(h^2)$ for forward Euler stability and extends to higher-order\nSSP-RK schemes, guaranteeing preservation of energy decay, positivity, and\ndiscrete maximum principles. Numerical experiments on distorted quadrilaterals,\nserendipity elements, and Voronoi polygons validate the theoretical\npredictions: the lumped VEM with $k=1$ achieves optimal convergence rates\n($\\mathcal{O}(h)$ in $H^1$, $\\mathcal{O}(h^2)$ in $L^2$) with no degradation\nfrom geometric distortion or mass lumping, while SSP-RK integrators remain\nstable under the predicted $\\Delta t\\propto h^{2}$ scaling", "AI": {"tldr": "Mass-lumped Virtual Element Method with explicit SSP-RK time integration for 2D parabolic problems on polygonal meshes, achieving optimal convergence with classical CFL condition \u0394t=O(h\u00b2).", "motivation": "To develop an efficient numerical method for parabolic problems on general polygonal meshes that maintains stability, energy decay, and maximum principles while using explicit time integration.", "method": "Combines mass-lumped VEM with diagonal mass matrix construction via row-sum operations and flooring, and explicit SSP-RK time integration. Stabilization terms vanish under row summation, making lumped weights computable through polynomial systems.", "result": "Achieves optimal convergence rates (O(h) in H\u00b9, O(h\u00b2) in L\u00b2) on distorted meshes, maintains mesh-robust spectral bounds, and preserves energy decay, positivity, and discrete maximum principles under \u0394t=O(h\u00b2) CFL condition.", "conclusion": "The mass-lumped VEM with SSP-RK integration provides an effective framework for parabolic problems on polygonal meshes, delivering optimal accuracy and strong stability properties without degradation from geometric distortion."}}
{"id": "2510.07314", "pdf": "https://arxiv.org/pdf/2510.07314", "abs": "https://arxiv.org/abs/2510.07314", "authors": ["Fabian Paischer", "Gianluca Galletti", "William Hornsby", "Paul Setinek", "Lorenzo Zanisi", "Naomi Carey", "Stanislas Pamela", "Johannes Brandstetter"], "title": "GyroSwin: 5D Surrogates for Gyrokinetic Plasma Turbulence Simulations", "categories": ["physics.plasm-ph", "cs.AI", "stat.ML"], "comment": "Accepted at NeurIPS 2025", "summary": "Nuclear fusion plays a pivotal role in the quest for reliable and sustainable\nenergy production. A major roadblock to viable fusion power is understanding\nplasma turbulence, which significantly impairs plasma confinement, and is vital\nfor next-generation reactor design. Plasma turbulence is governed by the\nnonlinear gyrokinetic equation, which evolves a 5D distribution function over\ntime. Due to its high computational cost, reduced-order models are often\nemployed in practice to approximate turbulent transport of energy. However,\nthey omit nonlinear effects unique to the full 5D dynamics. To tackle this, we\nintroduce GyroSwin, the first scalable 5D neural surrogate that can model 5D\nnonlinear gyrokinetic simulations, thereby capturing the physical phenomena\nneglected by reduced models, while providing accurate estimates of turbulent\nheat transport.GyroSwin (i) extends hierarchical Vision Transformers to 5D,\n(ii) introduces cross-attention and integration modules for latent\n3D$\\leftrightarrow$5D interactions between electrostatic potential fields and\nthe distribution function, and (iii) performs channelwise mode separation\ninspired by nonlinear physics. We demonstrate that GyroSwin outperforms widely\nused reduced numerics on heat flux prediction, captures the turbulent energy\ncascade, and reduces the cost of fully resolved nonlinear gyrokinetics by three\norders of magnitude while remaining physically verifiable. GyroSwin shows\npromising scaling laws, tested up to one billion parameters, paving the way for\nscalable neural surrogates for gyrokinetic simulations of plasma turbulence.", "AI": {"tldr": "GyroSwin is a scalable 5D neural surrogate that models nonlinear gyrokinetic simulations to capture plasma turbulence effects neglected by reduced-order models, achieving three orders of magnitude speedup while maintaining physical accuracy.", "motivation": "Plasma turbulence significantly impairs plasma confinement in nuclear fusion, and current reduced-order models omit nonlinear effects from full 5D dynamics. There's a need for accurate yet efficient models that capture these physical phenomena for reactor design.", "method": "Extends hierarchical Vision Transformers to 5D, introduces cross-attention and integration modules for latent 3D-5D interactions between electrostatic potential fields and distribution function, and performs channelwise mode separation inspired by nonlinear physics.", "result": "Outperforms widely used reduced numerics on heat flux prediction, captures turbulent energy cascade, reduces computational cost by three orders of magnitude compared to fully resolved nonlinear gyrokinetics, and shows promising scaling up to one billion parameters.", "conclusion": "GyroSwin provides a scalable neural surrogate for gyrokinetic simulations that maintains physical verifiability while dramatically improving computational efficiency, paving the way for practical plasma turbulence modeling in fusion energy research."}}
{"id": "2510.06286", "pdf": "https://arxiv.org/pdf/2510.06286", "abs": "https://arxiv.org/abs/2510.06286", "authors": ["Kim Bente", "Roman Marchant", "Fabio Ramos"], "title": "Mass Conservation on Rails -- Rethinking Physics-Informed Learning of Ice Flow Vector Fields", "categories": ["physics.ao-ph", "cs.LG", "physics.comp-ph", "physics.flu-dyn", "physics.geo-ph", "stat.ML"], "comment": "Accepted at the Tackling Climate Change with Machine Learning\n  Workshop at NeurIPS 2025. 9 pages, 4 figures", "summary": "To reliably project future sea level rise, ice sheet models require inputs\nthat respect physics. Embedding physical principles like mass conservation into\nmodels that interpolate Antarctic ice flow vector fields from sparse & noisy\nmeasurements not only promotes physical adherence but can also improve accuracy\nand robustness. While physics-informed neural networks (PINNs) impose physics\nas soft penalties, offering flexibility but no physical guarantees, we instead\npropose divergence-free neural networks (dfNNs), which enforce local mass\nconservation exactly via a vector calculus trick. Our comparison of dfNNs,\nPINNs, and unconstrained NNs on ice flux interpolation over Byrd Glacier\nsuggests that \"mass conservation on rails\" yields more reliable estimates, and\nthat directional guidance, a learning strategy leveraging continent-wide\nsatellite velocity data, boosts performance across models.", "AI": {"tldr": "Divergence-free neural networks (dfNNs) enforce exact mass conservation for Antarctic ice flow interpolation, outperforming physics-informed and unconstrained neural networks.", "motivation": "To improve reliability of sea level rise projections by ensuring ice sheet models respect physical principles like mass conservation when interpolating sparse ice flow measurements.", "method": "Proposed divergence-free neural networks (dfNNs) that enforce local mass conservation exactly using vector calculus, compared with physics-informed neural networks (PINNs) and unconstrained neural networks on ice flux interpolation over Byrd Glacier.", "result": "dfNNs with 'mass conservation on rails' yielded more reliable estimates than PINNs and unconstrained NNs. Directional guidance from continent-wide satellite velocity data boosted performance across all models.", "conclusion": "Exact enforcement of mass conservation through dfNNs provides more reliable ice flow interpolation than soft physics constraints, and leveraging broader satellite data improves model performance."}}
{"id": "2510.06656", "pdf": "https://arxiv.org/pdf/2510.06656", "abs": "https://arxiv.org/abs/2510.06656", "authors": ["Young-Pil Choi", "Sihyun Song"], "title": "Global weak solutions to nonlinear kinetic Fokker--Planck equations in bounded domains under physical initial data", "categories": ["math.AP", "35A01 (Primary) 35G31, 35Q84 (Secondary)"], "comment": "51 pages", "summary": "We establish the global existence of weak solutions to a nonlinear kinetic\nFokker--Planck equation with degenerate diffusion, under either inflow or\npartial absorption-reflection boundary conditions. The novelty of our approach\nlies in constructing solutions under solely the physical assumptions on the\ninitial and boundary data, namely finite mass, kinetic energy, and entropy,\nwith no additional regularity imposed. To overcome the lack of uniform\nellipticity, we develop a new compactness principle based on weighted Fisher\ninformation, which yields strong $L^1$ convergence of approximate solutions.\nThis framework provides a robust existence theory under only the physically\nrelevant conditions, and applies uniformly to both inflow and reflection\nboundary settings.", "AI": {"tldr": "Global existence of weak solutions for nonlinear kinetic Fokker-Planck equations with degenerate diffusion under inflow or partial absorption-reflection boundary conditions, using only physical assumptions on initial/boundary data.", "motivation": "To establish existence theory for kinetic Fokker-Planck equations under only physically relevant conditions (finite mass, kinetic energy, entropy) without requiring additional regularity assumptions.", "method": "Developed a new compactness principle based on weighted Fisher information to overcome lack of uniform ellipticity, yielding strong L^1 convergence of approximate solutions.", "result": "Proved global existence of weak solutions under inflow or partial absorption-reflection boundary conditions with only physical assumptions on initial and boundary data.", "conclusion": "The framework provides a robust existence theory that applies uniformly to both inflow and reflection boundary settings under physically relevant conditions only."}}
{"id": "2510.06678", "pdf": "https://arxiv.org/pdf/2510.06678", "abs": "https://arxiv.org/abs/2510.06678", "authors": ["Tianze Zhang", "Yixuan Ma", "Jun Wang"], "title": "An Integral Equation Method for Linear Two-Point Boundary Value Systems", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We present an integral equation-based method for the numerical solution of\ntwo-point boundary value systems. Special care is devoted to the mathematical\nformulation, namely the choice of the background Green's function that leads to\na well-conditioned integral equation. We then make use of a high-order Nystrom\ndiscretization and a fast direct solver on the continuous level to obtain a\nblack-box solver that is fast and accurate. A numerical study of the\nconditioning of different integral formulations is carried out. Excellent\nperformance in speed, accuracy, and robustness is demonstrated with several\nchallenging numerical examples.", "AI": {"tldr": "A fast, accurate black-box solver for two-point boundary value problems using well-conditioned integral equations with high-order Nystrom discretization and fast direct solvers.", "motivation": "To develop a robust numerical method for solving two-point boundary value systems that addresses conditioning issues in integral formulations.", "method": "Uses integral equation-based approach with careful selection of background Green's function, high-order Nystrom discretization, and fast direct solvers on continuous level.", "result": "Excellent performance in speed, accuracy, and robustness demonstrated through challenging numerical examples, with numerical study showing well-conditioned formulations.", "conclusion": "The method provides an effective black-box solver for two-point boundary value problems with superior performance characteristics."}}
{"id": "2510.06510", "pdf": "https://arxiv.org/pdf/2510.06510", "abs": "https://arxiv.org/abs/2510.06510", "authors": ["Konstantinos Horaites", "Juan V. Rodriguez", "Ying Liu"], "title": "Influence of Solar Sails on Magnetic Field Measurements in Space Plasmas", "categories": ["physics.space-ph", "astro-ph.SR", "physics.plasm-ph"], "comment": null, "summary": "Solar sail technology is ready to be deployed in a satellite mission carrying\na science-grade magnetometer. In preparation for such a mission, it is\nessential to characterize the interactions between the sail and the ambient\nplasma that could affect the magnetometer readings. The solar wind magnetic\nfield is a key parameter in space weather prediction, because it governs the\nenergy-releasing magnetic reconnection process at Earth's magnetopause. This\npaper investigates the influence of solar sails on the ambient magnetic field,\nparticularly focusing on two critical electromagnetic effects: eddy currents\nand magnetic pileup. We find the induced eddy currents in the metallic sail can\nsignificantly perturb the local magnetic field at high frequencies. We also\nsuggest that magnetic pileup can influence the spacecraft's environment when\nthe sail size is comparable to the electron kinetic scales of the surrounding\nplasma. This research provides an initial guide for determining when\nsail-plasma interactions could impact magnetometer performance.", "AI": {"tldr": "Solar sail technology may interfere with magnetometer readings due to plasma interactions, particularly through eddy currents and magnetic pileup effects.", "motivation": "To prepare for solar sail missions with magnetometers by characterizing sail-plasma interactions that could affect magnetic field measurements, which are crucial for space weather prediction.", "method": "Investigation of two electromagnetic effects: eddy currents induced in the metallic sail and magnetic pileup when sail size matches electron kinetic scales of surrounding plasma.", "result": "Eddy currents significantly perturb local magnetic field at high frequencies, and magnetic pileup can influence spacecraft environment under specific size conditions.", "conclusion": "This research provides initial guidance for determining when sail-plasma interactions could impact magnetometer performance in future solar sail missions."}}
{"id": "2510.06367", "pdf": "https://arxiv.org/pdf/2510.06367", "abs": "https://arxiv.org/abs/2510.06367", "authors": ["Luca Wolf", "Tobias Buck", "Bjoern Malte Schaefer"], "title": "Lagrangian neural ODEs: Measuring the existence of a Lagrangian with Helmholtz metrics", "categories": ["cs.LG", "math.DS", "physics.comp-ph", "physics.data-an"], "comment": "Accepted for the NeurIPS 2025 Machine Learning and the Physical\n  Sciences workshop. 6 pages, 3 figures", "summary": "Neural ODEs are a widely used, powerful machine learning technique in\nparticular for physics. However, not every solution is physical in that it is\nan Euler-Lagrange equation. We present Helmholtz metrics to quantify this\nresemblance for a given ODE and demonstrate their capabilities on several\nfundamental systems with noise. We combine them with a second order neural ODE\nto form a Lagrangian neural ODE, which allows to learn Euler-Lagrange equations\nin a direct fashion and with zero additional inference cost. We demonstrate\nthat, using only positional data, they can distinguish Lagrangian and\nnon-Lagrangian systems and improve the neural ODE solutions.", "AI": {"tldr": "The paper introduces Helmholtz metrics to quantify how closely an ODE resembles Euler-Lagrange equations, and develops Lagrangian neural ODEs that can learn these equations directly from positional data with no extra inference cost.", "motivation": "Neural ODEs are powerful but not all solutions are physical Euler-Lagrange equations. There's a need to quantify this resemblance and learn physically meaningful equations directly.", "method": "Developed Helmholtz metrics to measure ODE resemblance to Euler-Lagrange equations, combined with second order neural ODEs to create Lagrangian neural ODEs that learn from positional data.", "result": "The method can distinguish Lagrangian from non-Lagrangian systems, improves neural ODE solutions, and works with noisy fundamental systems.", "conclusion": "Lagrangian neural ODEs provide a direct way to learn Euler-Lagrange equations with zero additional inference cost, enabling more physically meaningful machine learning for physics applications."}}
{"id": "2510.06715", "pdf": "https://arxiv.org/pdf/2510.06715", "abs": "https://arxiv.org/abs/2510.06715", "authors": ["Dongfen Bian", "Emmanuel Grenier", "G\u00e9rard Iooss"], "title": "Bifurcations of viscous boundary layers in the half space", "categories": ["math.AP", "35Q30, 35B32"], "comment": null, "summary": "It is well-established that shear flows are linearly unstable provided the\nviscosity is small enough, when the horizontal Fourier wave number lies in some\ninterval, between the so-called lower and upper marginally stable curves. In\nthis article, we prove that, under a natural spectral assumption, shear flows\nundergo a Hopf bifurcation near their upper marginally stable curve. In\nparticular, close to this curve, there exists space periodic traveling waves\nsolutions of the full incompressible Navier-Stokes equations. For the\nlinearized operator, the occurrence of an essential spectrum containing the\nentire negative real axis causes certain difficulties which are overcome.\nMoreover, if this Hopf bifurcation is super-critical, these time and space\nperiodic solutions are linearly and nonlinearly asymptotically stable.", "AI": {"tldr": "The paper proves that shear flows undergo a Hopf bifurcation near their upper marginally stable curve, leading to space periodic traveling wave solutions of the Navier-Stokes equations, which can be stable under certain conditions.", "motivation": "To establish the existence of Hopf bifurcation in shear flows near the upper marginally stable curve, addressing challenges posed by the essential spectrum of the linearized operator.", "method": "Mathematical analysis and proof techniques applied to the incompressible Navier-Stokes equations, overcoming difficulties from the essential spectrum containing the negative real axis.", "result": "Existence of space periodic traveling wave solutions near the upper marginally stable curve, with potential linear and nonlinear asymptotic stability in super-critical cases.", "conclusion": "Shear flows exhibit Hopf bifurcation behavior near the upper marginally stable curve, producing stable periodic solutions under appropriate conditions."}}
{"id": "2510.06705", "pdf": "https://arxiv.org/pdf/2510.06705", "abs": "https://arxiv.org/abs/2510.06705", "authors": ["Jianlong Chen", "Yu Xu", "Xiaoqun Wang"], "title": "Randomized Quasi-Monte Carlo with Importance Sampling for Functions under Generalized Growth Conditions and Its Applications in Finance", "categories": ["math.NA", "cs.NA", "math.PR"], "comment": null, "summary": "Many problems can be formulated as high-dimensional integrals of\ndiscontinuous functions that often exhibit significant growth, challenging the\nerror analysis of randomized quasi-Monte Carlo (RQMC) methods. This paper\nstudies RQMC methods for functions with generalized exponential growth\nconditions, with a special focus on financial derivative pricing. The main\ncontribution of this work is threefold. First, by combining RQMC and importance\nsampling (IS) techniques, we derive a new error bound for a class of integrands\nwith the critical growth condition $e^{A\\|\\boldsymbol{x}\\|^2}$ where $A = 1/2$.\nThis theory extends existing results in the literature, which are limited to\nthe case $A < 1/2$, and we demonstrate that by imposing a light-tail condition\non the proposal distribution in the IS, the RQMC method can maintain its\nhigh-efficiency convergence rate even in this critical growth scenario. Second,\nwe verify that the Gaussian proposals used in Optimal Drift Importance Sampling\n(ODIS) satisfy the required light-tail condition, providing rigorous\ntheoretical guarantees for RQMC-ODIS in critical growth scenarios. Third, for\ndiscontinuous integrands from finance, we combine the preintegration technique\nwith RQMC-IS. We prove that this integrand after preintegration preserves the\nexponential growth condition. This ensures that the preintegrated discontinuous\nfunctions can be seamlessly incorporated into our RQMC-IS convergence\nframework. Finally, numerical results validate our theory, showing that the\nproposed method is effective in handling these problems with discontinuous\npayoffs, successfully achieving the expected convergence rates.", "AI": {"tldr": "This paper extends RQMC methods for functions with critical exponential growth (e^A||x||^2 where A=1/2), combining RQMC with importance sampling to maintain high-efficiency convergence rates, and integrates preintegration for discontinuous financial integrands.", "motivation": "High-dimensional integrals of discontinuous functions with significant growth challenge RQMC error analysis, particularly in financial derivative pricing where functions exhibit generalized exponential growth conditions.", "method": "Combines RQMC with importance sampling techniques, uses Gaussian proposals from Optimal Drift Importance Sampling, and integrates preintegration for discontinuous integrands to preserve growth conditions.", "result": "Derived new error bounds for critical growth scenarios (A=1/2), verified light-tail conditions for ODIS proposals, proved preintegration preserves exponential growth, and validated effectiveness through numerical experiments achieving expected convergence rates.", "conclusion": "The proposed RQMC-IS framework with preintegration successfully handles discontinuous functions with critical exponential growth in financial applications, extending theoretical guarantees beyond previous limitations."}}
{"id": "2510.07042", "pdf": "https://arxiv.org/pdf/2510.07042", "abs": "https://arxiv.org/abs/2510.07042", "authors": ["D. Schmeling", "M. Russo", "B. T. Gebreamlak", "T. J. Kiker", "A. R. Skrypek", "A. R. Hightower", "J. Xue", "S. Chen", "S. Sohaib", "C. Martinez", "K. F. Richardson", "L. Filor", "S. Komatsu", "L. Liu", "C. Paz-Soldan"], "title": "Experimental Results from Early Non-Planar NI-HTS Magnet Prototypes for the Columbia Stellarator eXperiment (CSX)", "categories": ["physics.ins-det", "cond-mat.supr-con", "physics.app-ph", "physics.plasm-ph"], "comment": null, "summary": "The Columbia Stellarator eXperiment (CSX) is an upgrade of the Columbia\nNon-neutral Torus (CNT) that aims to demonstrate a university-scale,\nquasi-axisymmetric stellarator using high-temperature superconducting (HTS)\ntechnology at an on-axis magnetic field target of 0.5 T. Due to the strain\nsensitivity of ReBCO (Rare-earth Barium Copper Oxides), adapting it to\nnon-planar stellarator geometries requires new winding, structural, and cooling\nstrategies. We report on the results of a staged prototype program (P1, P2, P3)\nemploying 3D-printed, sectional aluminum coil frames with winding channels,\ngimballed constant-tension winding mechanics, and solder potting for radial\ncurrent redistribution and passive quench mitigation. The first prototype, P1\n(planar elliptical, double-pancake) tested additive manufacture, sectional\njoining and baseline winding, achieving predicted fields at 77 K. P2\n(non-planar, higher strain) was wound to 42 turns, energized at 30-40 K to\nproduce expected magnetic fields, and studied thermal gradients and resistance\nat up to 4.5 kAt. Design evolution in P3 introduces concave geometry with dual\ndouble-pancakes, 200 turns, and approaches the 70 kAt target at 20 K. In\nparallel, sub-microhm lap joints have been developed. Together, these results\nde-risk manufacturing, cooling interfaces, quench management, and diagnostics,\npaving the way for full-size non-planar HTS stellarator coils for CSX.", "AI": {"tldr": "The paper presents a staged prototype program (P1-P3) for developing high-temperature superconducting (HTS) coils for the Columbia Stellarator eXperiment (CSX), addressing challenges in adapting ReBCO superconductors to non-planar stellarator geometries through 3D-printed aluminum frames, gimballed winding mechanics, and solder potting.", "motivation": "To demonstrate a university-scale quasi-axisymmetric stellarator using HTS technology at 0.5 T magnetic field, requiring new strategies to handle the strain sensitivity of ReBCO superconductors in non-planar geometries.", "method": "A three-stage prototype program using 3D-printed sectional aluminum coil frames with winding channels, gimballed constant-tension winding mechanics, and solder potting for radial current redistribution and passive quench mitigation.", "result": "P1 successfully tested manufacturing and achieved predicted fields at 77 K; P2 was wound to 42 turns and energized at 30-40 K producing expected magnetic fields; P3 with dual double-pancakes and 200 turns approaches the 70 kAt target at 20 K, with sub-microhm lap joints developed.", "conclusion": "The prototype program successfully de-risks manufacturing, cooling interfaces, quench management, and diagnostics, paving the way for full-size non-planar HTS stellarator coils for CSX."}}
{"id": "2510.06399", "pdf": "https://arxiv.org/pdf/2510.06399", "abs": "https://arxiv.org/abs/2510.06399", "authors": ["A. Lamura"], "title": "Phase segregation of liquid-vapor systems with a gravitational field", "categories": ["cond-mat.soft", "physics.comp-ph"], "comment": null, "summary": "Phase separation in the presence of external forces has attracted\n  considerable attention since the initial works for solid mixtures.\n  Despite this, only very few studies are available which address\n  the segregation process of liquid-vapor systems under gravity.\n  We present here an extensive study which takes into account both\n  hydrodynamic and gravitational effects on the coarsening dynamics.\n  An isothermal formulation of a lattice Boltzmann model for a liquid-vapor\n  system with the van der Waals equation of state is adopted.\n  In the absence of gravity, the growth of domains follows a power law\n  with the exponent $2/3$ of the inertial regime.\n  The external force deeply affects the observed morphology\n  accelerating the coarsening of domains and favoring the liquid accumulation\n  at the bottom of the system. Along the force direction,\n  the growth exponent is found to increase with the gravity strength\n  still preserving sharp interfaces since the Porod's law is found to be\n  verified.\n  The time evolution of the average thickness $L$\n  of the layers of accumulated material at confining walls\n  shows a transition from an initial regime where $L \\simeq t^{2/3}$\n  ($t$: time) to a late-time regime $L \\simeq g t^{5/3}$ with $g$ the\n  gravitational acceleration.\n  The final steady state, made of two overlapped layers of liquid and\n  vapor, shows a density profile in agreement with theoretical predictions.", "AI": {"tldr": "Study of liquid-vapor phase separation under gravity using lattice Boltzmann method, showing gravity accelerates coarsening and leads to layered structure formation.", "motivation": "Few studies exist on liquid-vapor segregation under gravity despite extensive work on solid mixtures under external forces.", "method": "Isothermal lattice Boltzmann model with van der Waals equation of state for liquid-vapor systems under gravitational force.", "result": "Without gravity: growth exponent 2/3 (inertial regime). With gravity: increased growth exponent, accelerated coarsening, liquid accumulation at bottom. Layer thickness transitions from L \u221d t^{2/3} to L \u221d g t^{5/3}. Final steady state shows two overlapped liquid-vapor layers matching theoretical predictions.", "conclusion": "Gravity significantly affects liquid-vapor phase separation dynamics, accelerating coarsening and leading to stratified steady states with predictable density profiles."}}
{"id": "2510.06716", "pdf": "https://arxiv.org/pdf/2510.06716", "abs": "https://arxiv.org/abs/2510.06716", "authors": ["Jie Ji", "Jingang Xiong"], "title": "On some divergence-form singular elliptic equations with codimension-two boundary: $L^p$-estimates", "categories": ["math.AP", "35J25, 35J75, 35A21"], "comment": "30pages", "summary": "We establish a global weighted $L^p$ estimate for the gradient of the\nsolution to a divergence-form elliptic equations, where the coefficients are in\na weighted VMO space and the equations have singularities on a co-dimension two\nboundary.", "AI": {"tldr": "Global weighted L^p gradient estimate for divergence-form elliptic equations with VMO coefficients and singularities on co-dimension two boundary.", "motivation": "To establish gradient estimates for elliptic equations with singular coefficients and boundary singularities, which are important for understanding regularity properties in domains with lower-dimensional boundaries.", "method": "Develop weighted L^p estimates for solutions to divergence-form elliptic equations where coefficients belong to weighted VMO spaces and equations have singularities on co-dimension two boundaries.", "result": "Proved global weighted L^p estimates for the gradient of solutions to such elliptic equations.", "conclusion": "Successfully established gradient regularity results for elliptic equations with singular coefficients and boundary singularities, extending previous results to more general settings."}}
{"id": "2510.06723", "pdf": "https://arxiv.org/pdf/2510.06723", "abs": "https://arxiv.org/abs/2510.06723", "authors": ["Alexander Falk", "Andreas Habring", "Christoph Griesbacher", "Thomas Pock"], "title": "An Inertial Langevin Algorithm", "categories": ["math.NA", "cs.NA", "65C40, 65C05, 68U10, 65C60", "G.3; I.4.5"], "comment": null, "summary": "We present a novel method for drawing samples from Gibbs distributions with\ndensities of the form $\\pi(x) \\propto \\exp(-U(x))$. The method accelerates the\nunadjusted Langevin algorithm by introducing an inertia term similar to\nPolyak's heavy ball method, together with a corresponding noise rescaling.\nInterpreting the scheme as a discretization of \\emph{kinetic} Langevin\ndynamics, we prove ergodicity (in continuous and discrete time) for twice\ncontinuously differentiable, strongly convex, and $L$-smooth potentials and\nbound the bias of the discretization to the target in Wasserstein-2 distance.\nIn particular, the presented proofs allow for smaller friction parameters in\nthe kinetic Langevin diffusion compared to existing literature. Moreover, we\nshow the close ties of the proposed method to the over-relaxed Gibbs sampler.\nThe scheme is tested in an extensive set of numerical experiments covering\nsimple toy examples, total variation image denoising, and the complex task of\nmaximum likelihood learning of an energy-based model for molecular structure\ngeneration. The experimental results confirm the acceleration provided by the\nproposed scheme even beyond the strongly convex and $L$-smooth setting.", "AI": {"tldr": "A novel accelerated sampling method for Gibbs distributions using inertial Langevin dynamics with noise rescaling, providing faster convergence than standard approaches.", "motivation": "To improve sampling efficiency from Gibbs distributions by accelerating the unadjusted Langevin algorithm through inertia and noise rescaling.", "method": "Introduces an inertia term similar to Polyak's heavy ball method with noise rescaling, interpreting it as discretization of kinetic Langevin dynamics.", "result": "Proves ergodicity for strongly convex and smooth potentials, bounds discretization bias in Wasserstein-2 distance, and shows experimental acceleration in various applications including image denoising and molecular structure generation.", "conclusion": "The proposed inertial Langevin method provides significant acceleration over standard approaches, working effectively even beyond the theoretical assumptions of strong convexity and smoothness."}}
{"id": "2510.06407", "pdf": "https://arxiv.org/pdf/2510.06407", "abs": "https://arxiv.org/abs/2510.06407", "authors": ["Erik Karlsson \u00d6hman", "Daqing Wang", "R. Matthias Geilhufe", "Christian Sch\u00e4fer"], "title": "Prediction of Molecular Single-Photon Emitters: A Materials-Modelling Approach", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.app-ph", "physics.comp-ph", "physics.optics"], "comment": null, "summary": "Interfacing light with quantum systems is an integral part of quantum\ntechnology, with the most essential building block being single-photon\nemitters. Although various platforms exist, each with its individual strengths,\nmolecular emitters boast a unique advantage -- namely the flexibility to tailor\ntheir design to fit the requirements of a specific task. However, the\ncharacteristics of the vast space of possible molecular configurations are\nchallenging to understand and explore. Here, we present a theoretical and\ncomputational framework to initiate exploration of this vast potential by\nintegrating database analysis with microscopic predictions. Using a model\nsystem of dibenzoterrylene in an anthracene host as benchmark, our approach\nidentifies promising new candidates, among them a chiral molecular emitter.\nFuture extensions of our approach integrated with machine learning routines\nhold the promise of ultimately unlocking the full potential of molecular\nquantum light-matter interfaces.", "AI": {"tldr": "A computational framework combining database analysis and microscopic predictions to explore molecular single-photon emitters, identifying promising candidates including chiral emitters.", "motivation": "Molecular emitters offer design flexibility for quantum light-matter interfaces, but exploring the vast space of possible molecular configurations is challenging.", "method": "Integration of database analysis with microscopic predictions, using dibenzoterrylene in anthracene host as a benchmark system.", "result": "Identified promising new molecular emitter candidates, including a chiral molecular emitter.", "conclusion": "Future extensions with machine learning could unlock the full potential of molecular quantum light-matter interfaces."}}
{"id": "2510.06801", "pdf": "https://arxiv.org/pdf/2510.06801", "abs": "https://arxiv.org/abs/2510.06801", "authors": ["Gennaro Ciampa", "Renato Luc\u00e0"], "title": "Accelerated and fast magnetic reconnection through enhanced resistive dissipation for MHD equations", "categories": ["math.AP", "math-ph", "math.MP"], "comment": null, "summary": "We consider the phenomenon of magnetic reconnection, namely a change in the\ntopology of magnetic lines, for sufficiently regular solutions of the\nthree-dimensional periodic magnetohydrodynamic (MHD) equations. We provide\nexamples where magnetic reconnection occurs on time scales shorter than the\nresistive one, due to enhanced dissipation emerging from advective effects.\nThis is the first analytical result where the advection term plays an active\nrole in the reconnection process. A key aspect of our approach is a new\nestimate for enhanced diffusion of high Sobolev norms, which is of independent\ninterest beyond its application to the MHD equations.", "AI": {"tldr": "Magnetic reconnection occurs faster than resistive time scales in 3D MHD due to advective effects, with new enhanced diffusion estimates.", "motivation": "To understand magnetic reconnection in 3D MHD and demonstrate how advection can accelerate reconnection beyond resistive time scales.", "method": "Developed new analytical estimates for enhanced diffusion of high Sobolev norms and applied them to 3D periodic MHD equations.", "result": "First analytical proof showing advection actively drives magnetic reconnection on time scales shorter than resistive ones.", "conclusion": "Advective effects enable faster magnetic reconnection than previously thought, with new diffusion estimates having broader applications."}}
{"id": "2510.07157", "pdf": "https://arxiv.org/pdf/2510.07157", "abs": "https://arxiv.org/abs/2510.07157", "authors": ["Yixuan Li", "Andersen Ang", "Sebastian Stein"], "title": "Optimal network pricing with oblivious users: a new model and algorithm", "categories": ["math.NA", "cs.NA", "math.OC", "94C15, 90C15, 90C26, 91A14, 90C35, 65F50"], "comment": "9 pages, 5 figures", "summary": "Traffic modeling is important in modern society. In this work we propose a\nnew model on the optimal network pricing (Onp) with the assumption of oblivious\nusers, in which the users remain oblivious to real-time traffic conditions and\nothers' behavior. Inspired by works on transportation research and network\npricing for selfish traffic, we mathematically derive and prove a new\nformulation of Onp with decision-dependent modeling that relax certain existing\nmodeling constraints in the literature. Then, we express the Onp formulation as\na constrained nonconvex stochastic quadratic program with uncertainty, and we\npropose an efficient algorithm to solve the problem, utilizing graph theory,\nsparse linear algebra and stochastic approximation. Lastly, we showcase the\neffectiveness of the proposed algorithm and the usefulness of the new Onp\nformulation. The proposed algorithm achieves a 5x speedup by exploiting the\nsparsity structure of the model.", "AI": {"tldr": "Proposes a new optimal network pricing model with oblivious users, formulates it as a constrained nonconvex stochastic quadratic program, and develops an efficient algorithm achieving 5x speedup.", "motivation": "Traffic modeling is important for modern society, and existing models have constraints that need relaxation. The work addresses optimal network pricing under oblivious user behavior.", "method": "Mathematically derives a new Onp formulation with decision-dependent modeling, expresses it as a constrained nonconvex stochastic quadratic program, and proposes an efficient algorithm using graph theory, sparse linear algebra, and stochastic approximation.", "result": "The proposed algorithm achieves a 5x speedup by exploiting the sparsity structure of the model. The effectiveness of the algorithm and usefulness of the new Onp formulation are demonstrated.", "conclusion": "The work successfully develops a new optimal network pricing formulation and an efficient solving algorithm that significantly improves computational performance while maintaining modeling accuracy."}}
{"id": "2510.06459", "pdf": "https://arxiv.org/pdf/2510.06459", "abs": "https://arxiv.org/abs/2510.06459", "authors": ["Chloe A. Zeller", "Ronald E. Miller", "Ellad B. Tadmor"], "title": "Local Order Average-Atom Interatomic Potentials", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "An extension to the effective average-atom (AA) interatomic potential (IP)\nthat accounts for local ordering effects is derived. While the AA approach is\nonly valid for random alloys, the new local-order average-atom (LOAA) IP\naccounts for short-range order within a material by utilizing information from\npartial radial distribution functions. Simulations with a LOAA potential\nrequire smaller system sizes to achieve statistically converged results and\ntherefore can be used to model complex materials where short-range order\neffects are important, such as high-entropy alloys, at a fraction of the\ncomputational cost of standard IPs. The method is validated for a\ntwo-dimensional (2D) binary hexagonal crystal with Lennard-Jones (LJ)\ninteractions, and for three-dimensional (3D) Fe$_{(1-x)/2}$Ni$_{(1-x)/2}$Cr$_x$\nand Ni$_{0.67}$Al$_{0.33}$ alloys modeled via embedded-atom method (EAM)\npotentials. For the 2D crystal we obtain a local ordering phase diagram in\nterms of the LJ parameters and demonstrate that in all cases the LOAA\nformulation obtains elastic properties that match the true-species case using\nstandard IPs. The 3D alloy examples further demonstrate the ability of this\nmethod to accurately capture other material properties and phase\ntransformations.", "AI": {"tldr": "A new local-order average-atom interatomic potential (LOAA IP) is developed to account for short-range order effects in materials, extending the standard average-atom approach that only works for random alloys.", "motivation": "Standard average-atom interatomic potentials are limited to random alloys and cannot capture local ordering effects that are important in complex materials like high-entropy alloys.", "method": "The LOAA IP incorporates information from partial radial distribution functions to model short-range order, requiring smaller system sizes for statistically converged results at reduced computational cost.", "result": "Validation on 2D binary hexagonal crystals and 3D Fe-Ni-Cr and Ni-Al alloys shows LOAA accurately captures elastic properties, material properties, and phase transformations, matching results from standard interatomic potentials.", "conclusion": "The LOAA method provides an efficient computational approach for modeling materials with local ordering effects while maintaining accuracy comparable to more expensive standard methods."}}
{"id": "2510.06859", "pdf": "https://arxiv.org/pdf/2510.06859", "abs": "https://arxiv.org/abs/2510.06859", "authors": ["Santiago G\u00f3mez Cobos", "Michael Ruzhansky"], "title": "Functional calculus for Safarov pseudo-differential operators", "categories": ["math.AP", "math.FA", "58J40 (Primary) 35S05, 47A60 (Secondary)"], "comment": null, "summary": "Given a smooth, closed Riemannian manifold $(M,g)$ equipped with a linear\nconnection $\\nabla$ (not necessarily metric), we develop the holomorphic\nfunctional calculus for operators belonging to the global pseudo-differential\nclasses $\\Psi_{\\rho, \\delta}^m\\left(\\Omega^\\kappa, \\nabla, \\tau\\right)$\nintroduced by Safarov. As a consequence of our main result, we establish a\nSzeg\\\"o type-theorem, derive asymptotic expansion of the heat kernel trace, and\ncalculate some associated spectral $\\zeta$-functions.", "AI": {"tldr": "Develops holomorphic functional calculus for pseudo-differential operators on Riemannian manifolds with linear connections, leading to Szeg\u0151-type theorems, heat kernel expansions, and spectral \u03b6-function calculations.", "motivation": "To extend functional calculus techniques to pseudo-differential operators defined on Riemannian manifolds with arbitrary linear connections, not necessarily metric-compatible.", "method": "Uses Safarov's global pseudo-differential classes \u03a8\u1d68,\u03b4\u1d50(\u03a9\u1d4f,\u2207,\u03c4) and develops holomorphic functional calculus for operators in these classes.", "result": "Establishes Szeg\u0151-type theorem, derives asymptotic expansion of heat kernel trace, and calculates associated spectral \u03b6-functions.", "conclusion": "The developed functional calculus provides powerful tools for spectral analysis of pseudo-differential operators on manifolds with general linear connections."}}
{"id": "2510.07295", "pdf": "https://arxiv.org/pdf/2510.07295", "abs": "https://arxiv.org/abs/2510.07295", "authors": ["Tobin A. Driscoll", "Yuxing Zhou"], "title": "Greedy Thiele continued-fraction approximation on continuum domains in the complex plane", "categories": ["math.NA", "cs.NA", "math.CV", "65D15, 26C15, 11A55"], "comment": null, "summary": "We describe an adaptive greedy algorithm for Thiele continued-fraction\napproximation of a function defined on a continuum domain in the complex plane.\nThe algorithm iteratively selects interpolation nodes from an adaptively\nrefined set of sample points on the domain boundary. We also present new\nalgorithms for evaluating Thiele continued fractions and their accessory\nweights using only a single floating-point division. Numerical experiments\ncomparing the greedy TCF method with the AAA algorithm on several challenging\nfunctions defined on the interval $[-1,1]$ and on the unit circle show that\ncontinuum TCF is consistently 2.5 to 8 times faster than AAA.", "AI": {"tldr": "An adaptive greedy algorithm for Thiele continued-fraction approximation on continuum domains in the complex plane, with new efficient evaluation methods.", "motivation": "To develop a faster alternative to the AAA algorithm for function approximation on continuum domains using Thiele continued fractions.", "method": "Adaptive greedy algorithm that selects interpolation nodes from adaptively refined sample points on domain boundary, plus new algorithms for evaluating Thiele continued fractions using single floating-point division.", "result": "Numerical experiments show continuum TCF is 2.5 to 8 times faster than AAA algorithm on functions defined on [-1,1] and unit circle.", "conclusion": "The proposed continuum TCF method provides significantly faster function approximation compared to AAA while maintaining accuracy."}}
{"id": "2510.06731", "pdf": "https://arxiv.org/pdf/2510.06731", "abs": "https://arxiv.org/abs/2510.06731", "authors": ["Xiaofeng Dong", "Nesar Ramachandra", "Salman Habib", "Katrin Heitmann"], "title": "Benchmarking AI-evolved cosmological structure formation", "categories": ["astro-ph.CO", "physics.comp-ph"], "comment": "Expanded and thoroughly revised version of our prior NeurIPS\n  submission (arXiv:2112.05681; which has no DOI), with new sections,\n  experiments, and analyses", "summary": "The potential of deep learning-based image-to-image translations has recently\nattracted significant attention. One possible application of such a framework\nis as a fast, approximate alternative to cosmological simulations, which would\nbe particularly useful in various contexts, including covariance studies,\ninvestigations of systematics, and cosmological parameter inference. To\ninvestigate different aspects of learning-based cosmological mappings, we\nchoose two approaches for generating suitable cosmological matter fields as\ndatasets: a simple analytical prescription provided by the Zel'dovich\napproximation, and a numerical N-body method using the Particle-Mesh approach.\nThe evolution of structure formation is modeled using U-Net, a widely employed\nconvolutional image translation framework. Because of the lack of a controlled\nmethodology, validation of these learned mappings requires multiple benchmarks\nbeyond simple visual comparisons and summary statistics. A comprehensive list\nof metrics is considered, including higher-order correlation functions,\nconservation laws, topological indicators, and statistical independence of\ndensity fields. We find that the U-Net approach performs well only for some of\nthese physical metrics, and accuracy is worse at increasingly smaller scales,\nwhere the dynamic range in density is large. By introducing a custom\ndensity-weighted loss function during training, we demonstrate a significant\nimprovement in the U-Net results at smaller scales. This study provides an\nexample of how a family of physically motivated benchmarks can, in turn, be\nused to fine-tune optimization schemes -- such as the density-weighted loss\nused here -- to significantly enhance the accuracy of scientific machine\nlearning approaches by focusing attention on relevant features.", "AI": {"tldr": "Deep learning image-to-image translation can approximate cosmological simulations faster. U-Net models structure formation from analytical and numerical datasets. Performance is evaluated using physical metrics, showing limitations at small scales. A custom density-weighted loss function improves small-scale accuracy.", "motivation": "To provide a fast, approximate alternative to computationally expensive cosmological simulations for covariance studies, systematics investigations, and cosmological parameter inference.", "method": "Use U-Net convolutional neural network for cosmological matter field evolution. Generate datasets using Zel'dovich approximation (analytical) and Particle-Mesh N-body method (numerical). Validate with comprehensive physical metrics and introduce custom density-weighted loss function.", "result": "U-Net performs well on some physical metrics but accuracy decreases at smaller scales with large density dynamic range. The density-weighted loss function significantly improves small-scale accuracy.", "conclusion": "Physically motivated benchmarks can guide optimization schemes to enhance scientific machine learning accuracy by focusing on relevant features, as demonstrated with the density-weighted loss improvement."}}
{"id": "2510.06958", "pdf": "https://arxiv.org/pdf/2510.06958", "abs": "https://arxiv.org/abs/2510.06958", "authors": ["Seongyeon Kim", "Ihyeok Seo"], "title": "On Morawetz estimates for the elastic wave equation", "categories": ["math.AP"], "comment": "14 pages", "summary": "We establish Morawetz-type estimates for solutions to the elastic wave\nequation with singular weights of the form $|x|^{-\\alpha}$ or\n$|(x,t)|^{-\\alpha}$. In particular, we show that space-time weights\n$|(x,t)|^{-\\alpha}$ admit stronger singularities and require weaker regularity\nassumptions on the initial data compared to purely spatial weights\n$|x|^{-\\alpha}$.", "AI": {"tldr": "Morawetz-type estimates for elastic wave equations with singular weights show space-time weights allow stronger singularities and weaker regularity than spatial weights.", "motivation": "To establish improved Morawetz-type estimates for elastic wave equations using singular weights, comparing spatial vs space-time weight performance.", "method": "Develop Morawetz-type estimates for elastic wave equations with singular weights of form |x|^{-\u03b1} and |(x,t)|^{-\u03b1}, analyzing singularity strength and regularity requirements.", "result": "Space-time weights |(x,t)|^{-\u03b1} permit stronger singularities and require weaker regularity assumptions on initial data compared to spatial weights |x|^{-\u03b1}.", "conclusion": "Space-time singular weights provide more favorable conditions for Morawetz estimates in elastic wave equations than purely spatial weights."}}
{"id": "2510.06316", "pdf": "https://arxiv.org/pdf/2510.06316", "abs": "https://arxiv.org/abs/2510.06316", "authors": ["Christopher Kang", "Yuan Su"], "title": "Quantum matrix arithmetics with Hamiltonian evolution", "categories": ["quant-ph", "cs.DS", "cs.NA", "math.NA", "physics.chem-ph"], "comment": "94 pages, 13 figures", "summary": "The efficient implementation of matrix arithmetic operations underpins the\nspeedups of many quantum algorithms. We develop a suite of methods to perform\nmatrix arithmetics -- with the result encoded in the off-diagonal blocks of a\nHamiltonian -- using Hamiltonian evolutions of input operators. We show how to\nmaintain this $\\textit{Hamiltonian block encoding}$, so that matrix operations\ncan be composed one after another, and the entire quantum computation takes\n$\\leq 2$ ancilla qubits. We achieve this for matrix multiplication, matrix\naddition, matrix inversion, Hermitian conjugation, fractional scaling, integer\nscaling, complex phase scaling, as well as singular value transformation for\nboth odd and even polynomials. We also present an overlap estimation algorithm\nto extract classical properties of Hamiltonian block encoded operators,\nanalogous to the well known Hadmard test, at no extra cost of qubit. Our\nHamiltonian matrix multiplication uses the Lie group commutator product formula\nand its higher-order generalizations due to Childs and Wiebe. Our Hamiltonian\nsingular value transformation employs a dominated polynomial approximation,\nwhere the approximation holds within the domain of interest, while the\nconstructed polynomial is upper bounded by the target function over the entire\nunit interval. We describe a circuit for simulating a class of sum-of-squares\nHamiltonians, attaining a commutator scaling in step count, while leveraging\nthe power of matrix arithmetics to reduce the cost of each simulation step. In\nparticular, we apply this to the doubly factorized tensor hypercontracted\nHamiltonians from recent studies of quantum chemistry, obtaining further\nimprovements for initial states with a fixed number of particles. We achieve\nthis with $1$ ancilla qubit.", "AI": {"tldr": "The paper develops methods for performing matrix arithmetic operations using Hamiltonian evolutions with results encoded in off-diagonal blocks, requiring only \u22642 ancilla qubits. It covers matrix multiplication, addition, inversion, conjugation, scaling, and singular value transformation, along with an overlap estimation algorithm.", "motivation": "Efficient implementation of matrix arithmetic operations is crucial for quantum algorithm speedups. The goal is to perform matrix operations using Hamiltonian evolutions while maintaining Hamiltonian block encoding for composable operations with minimal ancilla qubits.", "method": "Uses Hamiltonian evolutions with results encoded in off-diagonal blocks (Hamiltonian block encoding). Employs Lie group commutator product formula and higher-order generalizations for matrix multiplication, and dominated polynomial approximation for singular value transformation. Also presents overlap estimation algorithm without extra qubits.", "result": "Achieves matrix arithmetic operations (multiplication, addition, inversion, conjugation, scaling, singular value transformation) with \u22642 ancilla qubits. Applies to doubly factorized tensor hypercontracted Hamiltonians in quantum chemistry, obtaining improvements for initial states with fixed particle numbers using only 1 ancilla qubit.", "conclusion": "The developed Hamiltonian block encoding framework enables efficient matrix arithmetic operations with minimal ancilla qubits, providing practical improvements for quantum simulations, particularly in quantum chemistry applications."}}
{"id": "2510.06837", "pdf": "https://arxiv.org/pdf/2510.06837", "abs": "https://arxiv.org/abs/2510.06837", "authors": ["Abhishek Setty"], "title": "A Quantum Linear Systems Pathway for Solving Differential Equations", "categories": ["quant-ph", "physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "We present a systematic pathway for solving differential equations within the\nquantum linear systems framework by combining block encoding with Quantum\nSingular Value Transformation (QSVT). The approach is demonstrated on a complex\ntridiagonal linear system and extended to problems in computational fluid\ndynamics: the heat equation with mixed boundary conditions and the nonlinear\nBurgers' equation. Our scaling analysis of the heat equation shows how\ndiscretization influences the minimum singular value and the polynomial degree\nrequired for QSVT, identifying circuit-depth overhead as a key bottleneck. For\nBurgers' equation, we illustrate how Carleman-linearized nonlinear dynamics can\nbe efficiently block encoded and solved within the QSVT framework. These\nresults highlight both the potential and limitations of current methods,\nunderscoring the need for efficient estimation of minimum singular value,\ndepth-reduction techniques, and benchmarks against classical reachability. This\npathway lays a foundation for advancing quantum linear system methods toward\nlarge-scale applications.", "AI": {"tldr": "A systematic quantum pathway for solving differential equations using block encoding and Quantum Singular Value Transformation (QSVT), demonstrated on tridiagonal systems, heat equation, and nonlinear Burgers' equation.", "motivation": "To advance quantum linear system methods toward large-scale applications by developing a systematic approach for solving differential equations within the quantum computing framework.", "method": "Combines block encoding with Quantum Singular Value Transformation (QSVT), applied to tridiagonal linear systems, heat equation with mixed boundary conditions, and Carleman-linearized nonlinear Burgers' equation.", "result": "Successfully demonstrated the approach on complex systems, identified circuit-depth overhead as a key bottleneck for heat equation, and showed efficient block encoding for nonlinear dynamics.", "conclusion": "The pathway lays foundation for advancing quantum linear system methods but highlights limitations including need for efficient minimum singular value estimation, depth-reduction techniques, and classical benchmarks."}}
{"id": "2510.06979", "pdf": "https://arxiv.org/pdf/2510.06979", "abs": "https://arxiv.org/abs/2510.06979", "authors": ["J. M. Daniels-Holgate"], "title": "Non-uniqueness in Mean Curvature Flow: Non-canonical solutions via the parabolic Allen--Cahn", "categories": ["math.AP", "math.DG", "53E10, 35K93, 35K58"], "comment": "16 pages, 4 figures", "summary": "When mean curvature flow evolves non-uniquely, the flow is said to fatten.\nThe work of Ilmanen shows that any weak MCF is supported inside the fattening,\nand work of Hershkovits--White identified canonical weak flows supported on the\nboundary of the fattening, known as the outermost flows. It is natural to ask,\nwhen the flow fattens, are there weak mean curvature flows supported strictly\ninside the fattening? Outside of some special cases (e.g. flow from cones),\nthis question was entirely open. We show these interior flows exist, providing\na general construction for non-outermost flows as limits of solutions to the\nparabolic $\\varepsilon$-Allen--Cahn. This gives the first examples of closed,\nnon-trivial, non-canonical, integral Brakke motions. As part of this\nconstruction, we study the $\\varepsilon$-Allen--Cahn flow from low regularity\ninitial data, and our results demonstrate the existence of integral Brakke\nmotions from fractal sets. This includes the existence portion of Hershkovits's\nwork on mean curvature flow from Reifenberg sets.", "AI": {"tldr": "The paper shows that interior weak mean curvature flows exist strictly inside fattening regions, constructed as limits of parabolic \u03b5-Allen-Cahn solutions, providing first examples of closed, non-trivial, non-canonical integral Brakke motions.", "motivation": "To determine whether weak mean curvature flows can exist strictly inside fattening regions when the flow evolves non-uniquely, beyond the known outermost flows on the boundary.", "method": "General construction of non-outermost flows as limits of solutions to the parabolic \u03b5-Allen-Cahn equation from low regularity initial data, including fractal sets.", "result": "Demonstrates existence of interior flows inside fattening, providing first examples of closed, non-trivial, non-canonical integral Brakke motions, and establishes existence of integral Brakke motions from fractal sets.", "conclusion": "Interior weak mean curvature flows do exist strictly inside fattening regions, resolving an open question and extending the theory to include flows from low regularity initial data like fractal sets."}}
{"id": "2510.06684", "pdf": "https://arxiv.org/pdf/2510.06684", "abs": "https://arxiv.org/abs/2510.06684", "authors": ["Kang An", "Chenhao Si", "Ming Yan", "Shiqian Ma"], "title": "AutoBalance: An Automatic Balancing Framework for Training Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC"], "comment": "23 pages", "summary": "Physics-Informed Neural Networks (PINNs) provide a powerful and general\nframework for solving Partial Differential Equations (PDEs) by embedding\nphysical laws into loss functions. However, training PINNs is notoriously\ndifficult due to the need to balance multiple loss terms, such as PDE residuals\nand boundary conditions, which often have conflicting objectives and vastly\ndifferent curvatures. Existing methods address this issue by manipulating\ngradients before optimization (a \"pre-combine\" strategy). We argue that this\napproach is fundamentally limited, as forcing a single optimizer to process\ngradients from spectrally heterogeneous loss landscapes disrupts its internal\npreconditioning. In this work, we introduce AutoBalance, a novel \"post-combine\"\ntraining paradigm. AutoBalance assigns an independent adaptive optimizer to\neach loss component and aggregates the resulting preconditioned updates\nafterwards. Extensive experiments on challenging PDE benchmarks show that\nAutoBalance consistently outperforms existing frameworks, achieving significant\nreductions in solution error, as measured by both the MSE and $L^{\\infty}$\nnorms. Moreover, AutoBalance is orthogonal to and complementary with other\npopular PINN methodologies, amplifying their effectiveness on demanding\nbenchmarks.", "AI": {"tldr": "AutoBalance introduces a novel 'post-combine' training paradigm for PINNs that assigns independent adaptive optimizers to each loss component and aggregates preconditioned updates, overcoming limitations of existing gradient manipulation methods.", "motivation": "Training PINNs is difficult due to conflicting objectives and different curvatures in multiple loss terms (PDE residuals and boundary conditions). Existing gradient manipulation methods before optimization are fundamentally limited as they disrupt the optimizer's internal preconditioning.", "method": "AutoBalance uses a 'post-combine' strategy where each loss component gets its own independent adaptive optimizer. The preconditioned updates from these individual optimizers are aggregated afterwards rather than combining gradients before optimization.", "result": "Extensive experiments on challenging PDE benchmarks show AutoBalance consistently outperforms existing frameworks, achieving significant reductions in solution error measured by both MSE and L\u221e norms.", "conclusion": "AutoBalance provides an effective training paradigm for PINNs that is orthogonal and complementary to other popular methodologies, amplifying their effectiveness on demanding benchmarks."}}
{"id": "2510.07278", "pdf": "https://arxiv.org/pdf/2510.07278", "abs": "https://arxiv.org/abs/2510.07278", "authors": ["Jack S. Baker", "Gaurav Saxena", "Thi Ha Kyaw"], "title": "Universal initial state preparation for first quantized quantum simulations", "categories": ["quant-ph", "math-ph", "math.MP", "physics.comp-ph"], "comment": "22 pages, 3 figures, 1 table, 4 algorithms", "summary": "Preparing symmetry-adapted initial states is a principal bottleneck in\nfirst-quantized quantum simulation. We present a universal approach that\nefficiently maps any polynomial-size superposition of occupation-number\nconfigurations to the first-quantized representation on a digital quantum\ncomputer. The method exploits the Jordan--Schwinger Lie algebra homomorphism,\nwhich identifies number-conserving second-quantized operators with their\nfirst-quantized action and induces an equivariant bijection between Fock\noccupations and $\\mathfrak{su}(d)$ weight states within the Schur--Weyl\ndecomposition. Operationally, we prepare an encoded superposition of Schur\nlabels via a block-encoded linear combination of unitaries and then apply the\ninverse quantum Schur transform. The algorithm runs in time $\\text{poly}(L, N,\nd, \\log \\epsilon^{-1})$ for $L$ configurations of $N$ particles over $d$ modes\nto accuracy $\\epsilon$, and applies universally to fermions, bosons, and\nGreen's paraparticles in arbitrary single-particle bases. Resource estimates\nindicate practicality within leading first-quantized pipelines;\nstatistics-aware or faster quantum Schur transforms promise further reductions.", "AI": {"tldr": "A universal method for efficiently mapping symmetry-adapted initial states from second-quantized to first-quantized representation on quantum computers using Jordan-Schwinger mapping and quantum Schur transform.", "motivation": "Preparing symmetry-adapted initial states is a major bottleneck in first-quantized quantum simulation, requiring efficient conversion from second-quantized representations.", "method": "Uses Jordan-Schwinger Lie algebra homomorphism to map number-conserving operators between representations, then applies inverse quantum Schur transform after preparing encoded superposition of Schur labels via block-encoded linear combination of unitaries.", "result": "Algorithm runs in poly(L, N, d, log \u03b5\u207b\u00b9) time for L configurations of N particles over d modes to accuracy \u03b5, and works universally for fermions, bosons, and Green's paraparticles in arbitrary single-particle bases.", "conclusion": "The method enables practical symmetry-adapted state preparation within leading first-quantized pipelines, with potential for further improvements through statistics-aware or faster quantum Schur transforms."}}
{"id": "2510.07085", "pdf": "https://arxiv.org/pdf/2510.07085", "abs": "https://arxiv.org/abs/2510.07085", "authors": ["Tommaso Bertin", "Paulin Huguet"], "title": "Relaxation of Non-Convex Integral Functionals in the Multidimensional Scalar Case", "categories": ["math.AP", "math.FA", "49-XX"], "comment": "39 pages, 1 figure", "summary": "We study integral functionals defined on scalar Sobolev spaces of the form\n$$E[f]:u\\mapsto \\int_\\Omega f(x,u(x),\\nabla u(x)) d x,$$\n  with an emphasis on the non-convex case, and the difficulties it involves to\nprevent the Lavrentiev phenomenon. We determine a formulation of the lower\nsemicontinuous envelope of $E[f]$ with respect to various topologies and with\nfixed Lipschitz Dirichlet boundary conditions.", "AI": {"tldr": "Study of integral functionals in Sobolev spaces, focusing on non-convex cases and preventing the Lavrentiev phenomenon by determining lower semicontinuous envelopes with fixed Lipschitz boundary conditions.", "motivation": "To address challenges in non-convex integral functionals and prevent the Lavrentiev phenomenon, which causes discrepancies between different minimization approaches.", "method": "Analyze integral functionals of the form E[f]:u\u21a6\u222b_\u03a9 f(x,u(x),\u2207u(x)) dx, determining lower semicontinuous envelopes with respect to various topologies under fixed Lipschitz Dirichlet boundary conditions.", "result": "Developed formulations for the lower semicontinuous envelope of the functional E[f] under different topological settings with boundary constraints.", "conclusion": "The research provides mathematical tools to handle non-convex integral functionals and prevent the Lavrentiev phenomenon through proper formulation of lower semicontinuous envelopes with boundary conditions."}}
{"id": "2510.06992", "pdf": "https://arxiv.org/pdf/2510.06992", "abs": "https://arxiv.org/abs/2510.06992", "authors": ["Davide Oberto", "Maria Strazzullo", "Stefano Berrone"], "title": "Machine Learning enhanced parametric Reynolds-averaged Navier-Stokes equations at the full and reduced order levels", "categories": ["physics.flu-dyn", "cs.NA", "math.NA", "G.1.8"], "comment": null, "summary": "In this contribution, we focus on the Reynolds-Averaged Navier-Stokes (RANS)\nmodels and their exploitation to build reliable reduced order models to further\naccelerate predictions for real-time applications and many-query scenarios.\nSpecifically, we investigate how machine learning can be employed to enhance\nthe predictive capabilities of the model, both at the Full Order Model (FOM)\nand Reduced Order Model (ROM) levels. We explore a novel integration of these\ntwo areas. We generate the FOM snapshots, essential for ROM construction, using\na data-driven RANS model: the $\\nu_t$-Vector Basis Neural Network. This is the\nfirst time that these machine learning procedure generalizes a large parametric\nvariation, and we propose tailored training strategies to increase the accuracy\nof the FOM model. At the ROM level, we compare the results obtained by standard\nProper Orthogonal Decomposition in an intrusive Galerkin setting (PODG) and POD\nNeural Network approach (PODNN). The numerical validation is based on a classic\nturbulent flow benchmark: the flow in a square duct. Our investigation reveals\nthat the PODG method, proves unstable and inaccurate for turbulent flow\nprediction, while PODNN demonstrates superior performance in terms of accuracy\nand computational efficiency.", "AI": {"tldr": "Machine learning enhances RANS models for turbulent flow prediction, with PODNN outperforming PODG in accuracy and efficiency.", "motivation": "To accelerate predictions for real-time applications and many-query scenarios by improving Reynolds-Averaged Navier-Stokes (RANS) models using machine learning at both Full Order Model (FOM) and Reduced Order Model (ROM) levels.", "method": "Integrates machine learning with RANS models using \u03bdt-Vector Basis Neural Network for FOM snapshots, compares POD Galerkin (PODG) and POD Neural Network (PODNN) approaches for ROM construction, and validates on turbulent flow in a square duct benchmark.", "result": "PODG method proves unstable and inaccurate for turbulent flow prediction, while PODNN demonstrates superior performance in terms of accuracy and computational efficiency.", "conclusion": "POD Neural Network approach is more effective than traditional POD Galerkin method for turbulent flow reduced order modeling, offering better accuracy and computational performance."}}
{"id": "2510.07280", "pdf": "https://arxiv.org/pdf/2510.07280", "abs": "https://arxiv.org/abs/2510.07280", "authors": ["Leonhard H\u00f6lscher", "Oliver Ahrend", "Lukas Karch", "Carlotta L'Estocq", "Marc Marfany Andreu", "Tobias Stollenwerk", "Frank K. Wilhelm", "Julia Kowalski"], "title": "End-to-End Quantum Algorithm for Topology Optimization in Structural Mechanics", "categories": ["quant-ph", "physics.comp-ph"], "comment": null, "summary": "Topology optimization is a key methodology in engineering design for finding\nefficient and robust structures. Due to the enormous size of the design space,\nevaluating all possible configurations is typically infeasible. In this work,\nwe present an end-to-end, fault-tolerant quantum algorithm for topology\noptimization that operates on the exponential Hilbert space representing the\ndesign space. We demonstrate the algorithm on the two-dimensional\nMesserschmitt-B\\\"olkow-Blohm (MBB) beam problem. By restricting design\nvariables to binary values, we reformulate the compliance minimization task as\na combinatorial satisfiability problem solved using Grover's algorithm. Within\nGrover's oracle, the compliance is computed through the finite-element method\n(FEM) using established quantum algorithms, including block-encoding of the\nstiffness matrix, Quantum Singular Value Transformation (QSVT) for matrix\ninversion, Hadamard test, and Quantum Amplitude Estimation (QAE). The complete\nalgorithm is implemented and validated using classical quantum-circuit\nsimulations. A detailed complexity analysis shows that the method evaluates the\ncompliance of exponentially many structures in quantum superposition in\npolynomial time. In the global search, our approach maintains Grover's\nquadratic speedup compared to classical unstructured search. Overall, the\nproposed quantum workflow demonstrates how quantum algorithms can advance the\nfield of computational science and engineering.", "AI": {"tldr": "Quantum algorithm for topology optimization using Grover's search on binary design variables, achieving quadratic speedup over classical unstructured search.", "motivation": "Topology optimization requires evaluating enormous design spaces which is infeasible classically, so quantum algorithms can provide exponential speedup.", "method": "Reformulate compliance minimization as combinatorial satisfiability problem solved with Grover's algorithm, using quantum FEM with block-encoding, QSVT for matrix inversion, Hadamard test, and QAE.", "result": "Implemented and validated on MBB beam problem, showing exponential evaluation of structures in superposition with polynomial time complexity.", "conclusion": "Quantum workflow demonstrates practical advancement in computational engineering with Grover's quadratic speedup maintained in global search."}}
{"id": "2510.07138", "pdf": "https://arxiv.org/pdf/2510.07138", "abs": "https://arxiv.org/abs/2510.07138", "authors": ["Vincent Bansaye", "Alexandre Bertolino", "Ayman Moussa"], "title": "Stability of non-conservative cross diffusion model and approximation by stochastic particle systems", "categories": ["math.AP"], "comment": null, "summary": "We study the stability of non-conservative deterministic cross diffusion\nmodels and prove that they are approximated by stochastic population models\nwhen the populations become locally large. In this model, the individuals of\ntwo species move, reproduce and die with rates sensitive to the local densities\nof the two species. Quantitative estimates are given and convergence is\nobtained soon as the population per site and the number of sites go to\ninfinity. The proofs rely on the extension of stability estimates via duality\napproach under a smallness condition and the development of large deviation\nestimates for structured population models, which are of independent interest.\nThe proofs also involve martingale estimates in H^{-1} and improve the\napproximation results in the conservative case as well.", "AI": {"tldr": "Non-conservative deterministic cross diffusion models can be approximated by stochastic population models when populations become locally large, with quantitative convergence estimates.", "motivation": "To establish the relationship between deterministic cross diffusion models and stochastic population models, and provide quantitative approximation results for large populations.", "method": "Extension of stability estimates via duality approach under smallness condition, development of large deviation estimates for structured population models, and martingale estimates in H^{-1} space.", "result": "Proved that deterministic cross diffusion models are approximated by stochastic population models when populations become locally large, with convergence as population per site and number of sites go to infinity.", "conclusion": "The study provides rigorous mathematical foundation connecting deterministic and stochastic population models, with improved approximation results even in the conservative case."}}
{"id": "2510.07057", "pdf": "https://arxiv.org/pdf/2510.07057", "abs": "https://arxiv.org/abs/2510.07057", "authors": ["Rahul Kumar Padhy", "Krishnan Suresh", "Aaditya Chandrasekhar"], "title": "TOMATOES: Topology and Material Optimization for Latent Heat Thermal Energy Storage Devices", "categories": ["cs.CE", "cs.NA", "math.NA"], "comment": "Submitted to Applied Energy", "summary": "Latent heat thermal energy storage (LHTES) systems are compelling candidates\nfor energy storage, primarily owing to their high storage density. Improving\ntheir performance is crucial for developing the next-generation efficient and\ncost effective devices. Topology optimization (TO) has emerged as a powerful\ncomputational tool to design LHTES systems by optimally distributing a\nhigh-conductivity material (HCM) and a phase change material (PCM). However,\nconventional TO typically limits to optimizing the geometry for a fixed,\npre-selected materials. This approach does not leverage the large and expanding\ndatabases of novel materials. Consequently, the co-design of material and\ngeometry for LHTES remains a challenge and unexplored.\n  To address this limitation, we present an automated design framework for the\nconcurrent optimization of material choice and topology. A key challenge is the\ndiscrete nature of material selection, which is incompatible with the\ngradient-based methods used for TO. We overcome this by using a data-driven\nvariational autoencoder (VAE) to project discrete material databases for both\nthe HCM and PCM onto continuous and differentiable latent spaces. These\ncontinuous material representations are integrated into an end-to-end\ndifferentiable, transient nonlinear finite-element solver that accounts for\nphase change. We demonstrate this framework on a problem aimed at maximizing\nthe discharged energy within a specified time, subject to cost constraints. The\neffectiveness of the proposed method is validated through several illustrative\nexamples.", "AI": {"tldr": "This paper presents an automated design framework for concurrent optimization of material choice and topology in latent heat thermal energy storage systems, overcoming the challenge of discrete material selection using variational autoencoders.", "motivation": "Conventional topology optimization limits to fixed materials and doesn't leverage expanding material databases, leaving the co-design of material and geometry for LHTES systems unexplored.", "method": "Uses data-driven variational autoencoder to project discrete material databases onto continuous latent spaces, integrated into an end-to-end differentiable transient nonlinear finite-element solver that accounts for phase change.", "result": "Demonstrated effectiveness through illustrative examples showing maximization of discharged energy within specified time under cost constraints.", "conclusion": "The framework successfully enables concurrent optimization of material choice and topology for LHTES systems, overcoming the discrete material selection challenge."}}
{"id": "2510.07149", "pdf": "https://arxiv.org/pdf/2510.07149", "abs": "https://arxiv.org/abs/2510.07149", "authors": ["Alexander Mielke", "Andr\u00e9 Schlichting", "Artur Stephan"], "title": "Derivation of the fourth-order DLSS equation with nonlinear mobility via chemical reactions", "categories": ["math.AP", "cs.NA", "math-ph", "math.MP", "math.NA", "35A15, 35K55, 35A35, 47J35, 65M08"], "comment": "33 pages, 2 figure. Comments welcome", "summary": "We provide a derivation of the fourth-order DLSS equation based on an\ninterpretation as a chemical reaction network. We consider the rate equation on\nthe discretized circle for a process in which pairs of particles occupying the\nsame site simultaneously jump to the two neighboring sites; the reverse process\ninvolves pairs of particles at adjacent sites simultaneously jumping back to\nthe site located between them. Depending on the rates, in the\nvanishing-mesh-size limit we obtain either the classical DLSS equation or a\nvariant with nonlinear mobility of power type. Via EDP convergence, we identify\nthe limiting gradient structure to be driven by entropy with respect to a\ngeneralization of diffusive transport with nonlinear mobility. Interestingly,\nthe DLSS equation with power-type mobility shares qualitative similarities with\nthe fast diffusion and porous medium equation, since we find traveling wave\nsolutions with algebraic tails or compactly supported polynomials,\nrespectively.", "AI": {"tldr": "The paper derives the fourth-order DLSS equation from a chemical reaction network interpretation, showing it can yield either classical DLSS or a variant with nonlinear mobility depending on rates, and identifies the gradient structure via EDP convergence.", "motivation": "To provide a physical interpretation of the DLSS equation through chemical reaction networks and understand its limiting gradient structure with nonlinear mobility.", "method": "Derivation based on chemical reaction network interpretation, considering rate equations on discretized circle for particle jumping processes, and using EDP convergence to identify limiting gradient structure.", "result": "Obtained either classical DLSS equation or variant with nonlinear mobility depending on rates; identified gradient structure driven by entropy with generalized diffusive transport; found traveling wave solutions with algebraic tails or compactly supported polynomials.", "conclusion": "The DLSS equation with power-type mobility shares qualitative similarities with fast diffusion and porous medium equations, exhibiting different types of traveling wave solutions depending on the mobility type."}}
{"id": "2510.07216", "pdf": "https://arxiv.org/pdf/2510.07216", "abs": "https://arxiv.org/abs/2510.07216", "authors": ["L. Angiuli", "E. M. Mangino", "L. Lorenzi"], "title": "L^p-quasicontractiveness and Kernel estimates for semigroups generated by systems of elliptic operators", "categories": ["math.AP", "Systems of elliptic operators, unbounded coefficients, generation\n  results, consistent strongly continuous analytic semigroups, kernel estimates"], "comment": null, "summary": "This paper focuses on systems of strongly coupled elliptic operators whose\ncoefficients may be unbounded and are defined on a domain $\\Omega \\subseteq\n\\mathbb{R}^d$. It is shown that a quasi-contractive semigroup in $L^p$-spaces\ncan be associated with such operators for values of $p$ belonging to an\ninterval that contains $2$ as an interior point. Then, under refined\nassumptions and considering systems of elliptic operators coupled up to first\norder, new kernel estimates are established with respect to a distance function\nthat accounts for the growth of the diffusion coefficients and the potential\nterm at infinity.", "AI": {"tldr": "This paper studies systems of strongly coupled elliptic operators with unbounded coefficients, showing they generate quasi-contractive semigroups in L^p-spaces and establishing new kernel estimates using a distance function that accounts for coefficient growth.", "motivation": "To analyze systems of elliptic operators with unbounded coefficients and establish functional analytic properties like semigroup generation and kernel estimates, which are important for understanding the behavior of solutions to such systems.", "method": "The authors associate quasi-contractive semigroups in L^p-spaces with the elliptic operators and derive kernel estimates using a distance function that incorporates the growth of diffusion coefficients and potential terms at infinity.", "result": "The paper shows that these elliptic operators generate quasi-contractive semigroups in L^p-spaces for p in an interval containing 2, and establishes new kernel estimates with respect to a growth-accounting distance function.", "conclusion": "The results provide important functional analytic properties for systems of strongly coupled elliptic operators with unbounded coefficients, including semigroup generation and refined kernel estimates that account for coefficient growth behavior."}}
{"id": "2510.06577", "pdf": "https://arxiv.org/pdf/2510.06577", "abs": "https://arxiv.org/abs/2510.06577", "authors": ["Jiaogen Zhang"], "title": "Prescribed $p$-curvature problem on Riemannian manifolds with negative curvature", "categories": ["math.DG", "math.AP"], "comment": "17 pages", "summary": "Let $(N,g)$ be a compact Riemannian manifold with negative curvature of\ndimension $n\\geq 3$. This paper investigates the prescribed curvature problem\ndefined by the $p$-fold sum of the modified Shouten tensor for $1\\leq p\\leq n$.\nAs an application, we establish the existence of a metric $\\tilde{g}$ conformal\nto $g$ such that \\[ \\mathcal{M}_{p}(\\mathrm{Ric}_{\\tilde{g}})=constant. \\] In\nthe case $p=1$, this resolves a well-known result of Gursky and Viaclovsky\n[Indiana Univ. Math. J. 52 (2003), no. 2, 399--419 MR1976082].", "AI": {"tldr": "This paper solves the prescribed curvature problem for p-fold sums of modified Shouten tensor on compact negatively curved Riemannian manifolds, establishing existence of conformal metrics with constant p-curvature.", "motivation": "To extend Gursky and Viaclovsky's work on prescribed curvature problems from p=1 to general p-fold sums of modified Shouten tensor on negatively curved manifolds.", "method": "Investigates the prescribed curvature problem defined by p-fold sums of modified Shouten tensor using conformal geometry techniques on compact Riemannian manifolds with negative curvature.", "result": "Establishes existence of a metric conformal to the original metric such that the p-curvature (p-fold sum of modified Shouten tensor) is constant.", "conclusion": "The paper resolves the prescribed curvature problem for general p, with the p=1 case recovering Gursky and Viaclovsky's known result."}}
{"id": "2510.06779", "pdf": "https://arxiv.org/pdf/2510.06779", "abs": "https://arxiv.org/abs/2510.06779", "authors": ["Biqiang Zhao"], "title": "A Liouville theorem for CR Yamabe type equation on Sasakian manifolds", "categories": ["math.DG", "math.AP"], "comment": "26 pages, all comments welcome!", "summary": "In this paper, we study the CR Yamabe type equation \\begin{align}\n  \\Delta_b u+F(u)=0 \\nonumber\n  \\end{align} on complete noncompact $(2n+1)$-dimensional Sasakian manifolds\nwith nonnegative curvature. Under some assumptions, we prove a rigidity result,\nthat is, the manifold is CR isometric to Heisenberg group $\\mathbb{H}^n$. The\nproofs are based on the Jerison-Lee's differential identity combining with\nintegral estimates.", "AI": {"tldr": "The paper proves a rigidity result for CR Yamabe type equations on complete noncompact Sasakian manifolds with nonnegative curvature, showing they are CR isometric to the Heisenberg group.", "motivation": "To study the CR Yamabe type equation on complete noncompact Sasakian manifolds and establish rigidity results under curvature conditions.", "method": "Uses Jerison-Lee's differential identity combined with integral estimates to prove the rigidity theorem.", "result": "Under certain assumptions, complete noncompact Sasakian manifolds with nonnegative curvature satisfying the CR Yamabe type equation are CR isometric to the Heisenberg group.", "conclusion": "The paper establishes a rigidity theorem showing that Sasakian manifolds with the specified properties must be CR equivalent to the Heisenberg group."}}
{"id": "2510.06906", "pdf": "https://arxiv.org/pdf/2510.06906", "abs": "https://arxiv.org/abs/2510.06906", "authors": ["Iulian C\u00eempean", "Ionel Popescu", "Arghir Zarnescu"], "title": "Quantitative boundary H\u00f6lder estimates for the inhomogeneous Poisson problem through a probabilistic approach", "categories": ["math.PR", "math.AP"], "comment": null, "summary": "In this paper we derive quantitative boundary H\\\"older estimates, with\nexplicit constants, for the inhomogeneous Poisson problem in a bounded open set\n$D\\subset \\mathbb{R}^d$.\n  Our approach has two main steps: firstly, we consider an arbitrary $D$ as\nabove and prove that the boundary $\\alpha$-H\\\"older regularity of the solution\nthe Poisson equation is controlled, with explicit constants, by the H\\\"older\nseminorm of the boundary data, the $L^ \\gamma$-norm of the forcing term with\n$\\gamma>d/2$, and the $\\alpha/2$-moment of the exit time from $D$ of the\nBrownian motion.\n  Secondly, we derive explicit estimates for the $\\alpha/2$-moment of the exit\ntime in terms of the distance to the boundary, the regularity of the domain\n$D$, and $\\alpha$. Using this approach, we derive explicit estimates for the\nsame problem in domains satisfying exterior ball conditions, respectively\nexterior cone/wedge conditions, in terms of simple geometric features.\n  As a consequence we also obtain explicit constants for pointwise estimates\nfor the Green function and for the gradient of the solution.\n  The obtained estimates can be employed to bypass the curse of high dimensions\nwhen aiming to approximate the solution of the Poisson problem using neural\nnetworks, obtaining polynomial scaling with dimension, which in some cases can\nbe shown to be optimal.", "AI": {"tldr": "This paper derives explicit quantitative boundary H\u00f6lder estimates for the inhomogeneous Poisson problem in bounded domains, with applications to neural network approximations that avoid the curse of dimensionality.", "motivation": "To provide explicit constants for boundary regularity estimates in the Poisson problem, which can help overcome the curse of dimensionality when using neural networks to approximate solutions.", "method": "Two-step approach: (1) prove boundary H\u00f6lder regularity controlled by boundary data seminorm, forcing term norm, and Brownian motion exit time moments; (2) derive explicit estimates for exit time moments using geometric domain properties like exterior ball/cone conditions.", "result": "Obtained explicit boundary H\u00f6lder estimates for Poisson problem in various domain types, along with explicit constants for Green function and solution gradient pointwise estimates. These enable neural network approximations with polynomial dimension scaling.", "conclusion": "The explicit boundary regularity estimates provide tools to bypass the curse of dimensionality in neural network approximations of Poisson problems, achieving polynomial scaling that can be optimal in some cases."}}
{"id": "2510.06944", "pdf": "https://arxiv.org/pdf/2510.06944", "abs": "https://arxiv.org/abs/2510.06944", "authors": ["Flank D. M. Bezerra", "Lu\u00eds M. Salge"], "title": "Local well-posedness for a class of semilinear Moore-Gibson-Thompson equations with subcritical nonlinearities", "categories": ["math.DS", "math.AP", "math.FA", "35G10, 35K46, 47A75, 47D03"], "comment": null, "summary": "In this paper, we study a class of higher-order semilinear evolution\nequations inspired by the Moore-Gibson-Thompson model introduced by Dell'Oro,\nLiverani and Pata (2023), involving strongly elliptic operators of order ($2m$)\nwith homogeneous boundary conditions. The associated unbounded linear operator\nis a sectorial operator with zero belonging to the resolvent set, allowing the\nconstruction of fractional powers spaces, and the analysis of their spectral\nproperties. We prove the local well-posedness of the corresponding semilinear\nCauchy problem under subcritical nonlinearities. Our framework clarifies the\nrole of extrapolation spaces and fractional domains in handling the lack of\naccretivity and bounded imaginary powers of the operator.", "AI": {"tldr": "This paper studies higher-order semilinear evolution equations based on the Moore-Gibson-Thompson model, focusing on local well-posedness under subcritical nonlinearities.", "motivation": "To extend the analysis of evolution equations inspired by the Moore-Gibson-Thompson model to higher-order operators and clarify the role of extrapolation spaces and fractional domains.", "method": "The authors use sectorial operators with zero in the resolvent set, construct fractional powers spaces, and analyze spectral properties to prove local well-posedness.", "result": "The paper establishes local well-posedness of the semilinear Cauchy problem for higher-order elliptic operators under subcritical nonlinearities.", "conclusion": "The framework successfully handles the lack of accretivity and bounded imaginary powers through extrapolation spaces and fractional domains."}}
