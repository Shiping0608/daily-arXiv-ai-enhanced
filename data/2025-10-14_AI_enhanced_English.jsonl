{"id": "2510.09778", "pdf": "https://arxiv.org/pdf/2510.09778", "abs": "https://arxiv.org/abs/2510.09778", "authors": ["Ilya Kosolapov", "Tatiana Sheloput", "Sergey Matveev"], "title": "Tensor-based compression of the sea temperature data", "categories": ["math.NA", "cs.NA", "65F55, 65-11, 65Z05, 86-11", "F.2.1; G.1.2; G.1.3; I.4.2"], "comment": "22 pages, 8 figures, 12 tables", "summary": "In this work we investigate efficient data compression for spatiotemporal\nBlack, Azov and Marmara Seas temperature tensors that contain significant\nnumber of missing values. These tensors have a complex structure influenced by\nthe coastlines and bathymetry, as well as temporal temperature changes. While\nsuch missing data typically provokes utilization of tensor completion\nalgorithms, we demonstrate that standard SVD-based compression approaches\n(including the Tucker, Tensor-Train (TT) and Quantized-TT formats) are\nremarkably effective and yield comparable results. We propose a greedy spatial\ndata partitioning algorithm enhancing their performance. We divide the data\ninto the smaller subtensors before compression via exploitation of this trick.\n  Furthermore, our analysis reveals a strong temporal dependency in the data's\ncompressibility caused by its nature. Fixing the level of precision we observe\na significant seasonal variation. Investigating this, we find that a temporal\npartitioning on a scale of approximately two days is nearly optimal for all\ntested tensor based formats. The combined application of these spatial and\ntemporal strategies with tensor methods ultimately achieves a robust\ncompression ratio of 5 times across the entire dataset.", "AI": {"tldr": "The paper shows that standard SVD-based tensor compression methods work well for spatiotemporal sea temperature data with missing values, and proposes spatial and temporal partitioning strategies that achieve 5x compression.", "motivation": "To efficiently compress spatiotemporal sea temperature tensors with complex structure and significant missing values, avoiding the need for complex tensor completion algorithms.", "method": "Uses standard SVD-based tensor compression formats (Tucker, Tensor-Train, Quantized-TT) with greedy spatial partitioning and temporal partitioning on 2-day intervals.", "result": "Achieves robust 5x compression ratio across the entire dataset, with temporal partitioning proving nearly optimal at 2-day intervals.", "conclusion": "Standard tensor compression methods combined with spatial and temporal partitioning strategies are effective for compressing complex spatiotemporal sea temperature data with missing values."}}
{"id": "2510.09892", "pdf": "https://arxiv.org/pdf/2510.09892", "abs": "https://arxiv.org/abs/2510.09892", "authors": ["Hongyu Chen", "Paul A. Ullrich", "Julian Panetta"], "title": "Fast and Accurate Intersections on a Sphere", "categories": ["math.NA", "cs.NA", "65D18, 65G50, 65Y04, 51-04"], "comment": null, "summary": "We introduce a fast, high-precision algorithm for calculating intersections\nbetween great circle arcs and lines of constant latitude on the unit sphere. We\nfirst propose a simplified intersection point formula with improved speed and\nnumerical robustness over the ones traditionally implemented in geoscience\nsoftware. We then show how algorithms based on the concept of error-free\ntransformations (EFT) can be applied to evaluate this formula within a relative\nerror bound that is on the order of machine precision. We demonstrate that,\nwith a vectorized and parallelized implementation, this enhanced accuracy is\nachieved with no compute-time overhead compared to a direct calculation in\nhardware floating point, making our algorithm suitable for\nperformance-sensitive applications like regridding of high-resolution climate\ndata. In contrast, evaluating our formula using high-precision data types like\nquadruple precision and arbitrary precision, or using the robust intersection\ncomputation routines from the Computational Geometry Algorithms Library (CGAL),\nleads to significant computational overhead, especially since these\nalternatives inhibit vectorization. More generally, our work demonstrates how\nEFT techniques can be combined and extended to implement nontrivial geometric\ncalculations with high accuracy and speed.", "AI": {"tldr": "A fast, high-precision algorithm for calculating intersections between great circle arcs and latitude lines on spheres using error-free transformations for machine precision accuracy with no computational overhead.", "motivation": "Traditional geoscience software has slow and numerically unstable intersection calculations, creating a need for high-performance algorithms suitable for applications like high-resolution climate data regridding.", "method": "Proposed a simplified intersection point formula combined with error-free transformation (EFT) techniques to achieve machine precision accuracy, with vectorized and parallelized implementation.", "result": "Achieved enhanced accuracy with no compute-time overhead compared to direct hardware floating point calculations, outperforming quadruple precision, arbitrary precision, and CGAL alternatives that inhibit vectorization.", "conclusion": "Demonstrates that EFT techniques can be effectively combined to implement complex geometric calculations with both high accuracy and speed, making the algorithm suitable for performance-sensitive applications."}}
{"id": "2510.09909", "pdf": "https://arxiv.org/pdf/2510.09909", "abs": "https://arxiv.org/abs/2510.09909", "authors": ["Damien Tageddine", "Jean-Christophe Nave"], "title": "Noncommutative Laplacian and numerical approximation of Laplace-Beltrami spectrum of compact Riemann surfaces", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We derive a numerical approximation of the Laplace-Beltrami operator on\ncompact surfaces embedded in $\\mathbb{R}^3$ with an axial symmetry. To do so we\nuse a noncommutative Laplace operator defined on the space of finite\ndimensional hermitian matrices. This operator is derived from a foliation of\nthe surface obtained under an $S^1$-action on the surface. We present numerical\nresults in the case of the sphere and a generic ellipsoid.", "AI": {"tldr": "Numerical approximation of Laplace-Beltrami operator on axially symmetric surfaces using noncommutative Laplace operator on hermitian matrices derived from S^1-action foliation.", "motivation": "To develop numerical methods for approximating the Laplace-Beltrami operator on compact surfaces with axial symmetry embedded in 3D space.", "method": "Use noncommutative Laplace operator defined on finite dimensional hermitian matrices, derived from foliation of the surface obtained under S^1-action.", "result": "Present numerical results for sphere and generic ellipsoid cases.", "conclusion": "Successfully derived numerical approximation method for Laplace-Beltrami operator on axially symmetric surfaces using matrix-based approach."}}
{"id": "2510.10112", "pdf": "https://arxiv.org/pdf/2510.10112", "abs": "https://arxiv.org/abs/2510.10112", "authors": ["Qianrui Liu", "Xiantu He", "Mohan Chen"], "title": "Thermal and Electrical Conductivities of Aluminum Up to 1000 eV: A First-Principles Prediction", "categories": ["physics.plasm-ph", "physics.comp-ph"], "comment": null, "summary": "Accurate prediction of the thermal and electrical conductivities of materials\nunder extremely high temperatures is essential in high-energy-density physics.\nThese properties govern processes such as stellar core dynamics, planetary\nmagnetic field generation, and laser-driven plasma evolution. However,\nfirst-principles methods like Kohn-Sham (KS) density functional theory (DFT)\nface challenges in predicting these properties due to prohibitively high\ncomputational costs. We propose a scheme that integrates the Kubo formalism\nwith a mixed stochastic-deterministic DFT (mDFT) method, which substantially\nenhances efficiency in computing thermal and electrical conductivities of dense\nplasmas under extremely high temperatures. As a showcase, this approach enables\n{\\it ab initio} calculations of the thermal and electrical conductivities of\nAluminum (Al) up to 1000 eV. Compared to traditional transport models, our\nfirst-principles results reveal significant deviations in the thermal and\nelectrical conductivities of Al within the warm dense matter regime,\nunderscoring the importance of accounting for quantum effects when\ninvestigating these transport properties of warm dense matter.", "AI": {"tldr": "A new method combining Kubo formalism with mixed stochastic-deterministic DFT enables efficient first-principles calculation of thermal and electrical conductivities in dense plasmas at extremely high temperatures up to 1000 eV.", "motivation": "Accurate prediction of thermal and electrical conductivities under extreme temperatures is crucial for understanding high-energy-density physics phenomena like stellar core dynamics, planetary magnetic field generation, and laser-driven plasma evolution, but traditional first-principles methods are computationally prohibitive.", "method": "Integration of Kubo formalism with mixed stochastic-deterministic DFT (mDFT) method to enhance computational efficiency for calculating transport properties in dense plasmas.", "result": "Successfully calculated thermal and electrical conductivities of Aluminum up to 1000 eV, revealing significant deviations from traditional transport models in the warm dense matter regime.", "conclusion": "Quantum effects must be accounted for when investigating transport properties of warm dense matter, as first-principles calculations show substantial differences from conventional models."}}
{"id": "2510.09865", "pdf": "https://arxiv.org/pdf/2510.09865", "abs": "https://arxiv.org/abs/2510.09865", "authors": ["Fredy Maglorio Sobrado Su\u00e1rez", "Gilson Tumelero", "Jackson Luchesi", "Marieli Musial Tumelero", "Santos Richard Wieller Sanguino Bejarano"], "title": "Analyticity for Double Wall Carbon Nanotubes Modeled as Timoshenko Beams with Kelvin-Voigt and Intermediate Damping", "categories": ["math.AP", "35L55, 93D15"], "comment": "21 pages, 2 figures", "summary": "This manuscript studies a model of double-walled carbon nanotubes using two\nTimoshenko beams which are coupled by the Van der Walls force $(y-u)$.\nKelvin-Voigt type dampings $(u_x-v)_{xt}$ and $(y_x-z)_{xt}$ and fractional\ndampings $(-\\partial_{xx})^\\alpha v_t$ and $(-\\partial_{xx})^\\beta z_t$ in both\nbeams have been considered. We show that our proposed model is well established\nand that the semigroup associated is exponentially stable and analytical for\nany $(\\alpha, \\beta) \\in [0, 1]^2$. As a consequence of this, a result on the\nanalyticity of a Timoshenko System is obtained.", "AI": {"tldr": "Mathematical modeling of double-walled carbon nanotubes using coupled Timoshenko beams with Van der Waals forces and various damping mechanisms, proving exponential stability and analyticity.", "motivation": "To develop a comprehensive mathematical model for double-walled carbon nanotubes that accounts for mechanical interactions and damping effects, enabling stability analysis.", "method": "Used two coupled Timoshenko beams connected by Van der Waals forces, incorporating Kelvin-Voigt type dampings and fractional dampings in both beams.", "result": "The proposed model is well-established, and the associated semigroup is exponentially stable and analytical for all (\u03b1, \u03b2) in [0,1]\u00b2.", "conclusion": "The model successfully describes double-walled carbon nanotubes with proven stability properties, and provides analytical results for Timoshenko systems."}}
{"id": "2510.10210", "pdf": "https://arxiv.org/pdf/2510.10210", "abs": "https://arxiv.org/abs/2510.10210", "authors": ["Rishabh Shukla", "Wasim Akram", "Manil T. Mohan"], "title": "Finite element analysis of a nonlinear heat Equation with damping and pumping effects", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We study the following nonlinear heat equation with damping and pumping\neffects (a reaction-diffusion equation) posed on a bounded simply connected\nconvex domain $\\Omega \\subset \\mathbb{R}^d$, $d \\geq 1$ with Lipschitz boundary\n$\\partial\\Omega$: $$ \\frac{\\partial u(t)}{\\partial t} - \\nu \\Delta u(t) +\n\\alpha |u(t)|^{p-2}u(t) - \\sum_{\\ell=1}^M \\beta_{\\ell} |u(t)|^{q_{\\ell}-2}u(t)\n= f(t), \\quad t>0, $$ subject to homogeneous Dirichlet boundary conditions and\nthe initial condition $u(0)=u_0$, where $2 \\leq p < \\infty$ and $2 \\leq\nq_{\\ell} < p$ for $1 \\leq \\ell \\leq M$. For $u_0 \\in L^2(\\Omega)$ and $f \\in\nL^2(0,T;H^{-1}(\\Omega))$, we establish the existence and uniqueness of a weak\nsolution for all dimensions $d \\in \\mathbb{N}$ and damping exponents $2 \\leq p\n< \\infty$. Furthermore, for $u_0 \\in H^2(\\Omega) \\cap H_0^1(\\Omega)$ and $f \\in\nH^1(0,T;H^1(\\Omega))$, we obtain regularity results: these hold for every $2\n\\leq p < \\infty$ when $1 \\leq d \\leq 4$, and for $2 \\leq p \\leq\n\\frac{2d-6}{d-4}$ when $d \\geq 5$. We further conduct finite element analysis\nusing conforming, nonconforming, and discontinuous Galerkin methods, deriving a\npriori error estimates for both semi- and fully discrete schemes, supported by\nnumerical results. To relax restrictions on $p$ in the semidiscrete analysis,\nwe use appropriate projection/interpolation operators: the Ritz projection in\nthe conforming case ($2 \\le p \\le \\frac{2d}{d-2}$), the Scott-Zhang\ninterpolation for $\\frac{2d}{d-2} < p \\le \\frac{2d-6}{d-4}$, the Cl\\'ement\ninterpolation in the nonconforming setting, and the $L^2$-projection in the DG\nframework. In the fully discrete case, error estimates hold for the above\n$p$-range under $u_0 \\in D(A^{3/2})$ and $f \\in H^1(0,T;H^1(\\Omega))$.", "AI": {"tldr": "This paper analyzes a nonlinear heat equation with damping and pumping effects, establishing existence, uniqueness, and regularity of weak solutions, and provides finite element analysis with error estimates for various numerical methods.", "motivation": "To study the mathematical properties of nonlinear reaction-diffusion equations with damping and pumping terms, which model various physical phenomena, and develop robust numerical methods for their solution.", "method": "The authors use functional analysis to prove existence and uniqueness of weak solutions, then conduct finite element analysis using conforming, nonconforming, and discontinuous Galerkin methods with appropriate projection operators to derive error estimates.", "result": "Existence and uniqueness of weak solutions are established for all dimensions and damping exponents. Regularity results are obtained with specific constraints on dimension and exponent. A priori error estimates are derived for semi- and fully discrete schemes.", "conclusion": "The paper provides comprehensive mathematical analysis and numerical methods for nonlinear reaction-diffusion equations with damping and pumping, with rigorous error estimates that hold under specific regularity conditions."}}
{"id": "2510.11174", "pdf": "https://arxiv.org/pdf/2510.11174", "abs": "https://arxiv.org/abs/2510.11174", "authors": ["Sadra Saremi", "Amirhossein Ahmadkhan Kordbacheh"], "title": "Machine Learning-Integrated Hybrid Fluid-Kinetic Framework for Quantum Electrodynamic Laser Plasma Simulations", "categories": ["physics.plasm-ph", "cs.LG"], "comment": null, "summary": "High-intensity laser plasma interactions create complex computational\nproblems because they involve both fluid and kinetic regimes, which need models\nthat maintain physical precision while keeping computational speed. The\nresearch introduces a machine learning-based three-dimensional hybrid\nfluid-particle-in-cell (PIC) system, which links relativistic plasma behavior\nto automatic regime transitions. The technique employs fluid approximations for\nstable areas but activates the PIC solver when SwitchNet directs it to unstable\nsections through its training on physics-based synthetic data. The model uses a\nsmooth transition between Ammosov-Delone-Krainov (ADK) tunneling and\nmultiphoton ionization rates to simulate ionization, while Airy-function\napproximations simulate quantum electrodynamic (QED) effects for radiation\nreaction and pair production. The convolutional neural network applies energy\nconservation through physics-based loss functions, which operate on normalized\nfields per channel. Monte Carlo dropout provides uncertainty measurement. The\nhybrid model produces precise predictions with coefficient of determination\n(R^2) values above 0.95 and mean squared errors below 10^-4 for all field\ncomponents. This adaptive approach enhances the accuracy and scalability of\nlaser-plasma simulations, providing a unified predictive framework for\nhigh-energy-density and particle acceleration applications.", "AI": {"tldr": "A machine learning-based 3D hybrid fluid-PIC system that automatically switches between fluid and kinetic regimes for laser-plasma simulations, achieving high accuracy with R\u00b2 > 0.95.", "motivation": "High-intensity laser plasma interactions involve both fluid and kinetic regimes, requiring models that maintain physical precision while keeping computational speed.", "method": "Uses a hybrid fluid-PIC system with SwitchNet neural network to direct regime transitions, smooth ADK tunneling/multiphoton ionization transitions, Airy-function approximations for QED effects, physics-based loss functions, and Monte Carlo dropout for uncertainty.", "result": "Achieves precise predictions with R\u00b2 values above 0.95 and mean squared errors below 10^-4 for all field components.", "conclusion": "The adaptive approach enhances accuracy and scalability of laser-plasma simulations, providing a unified predictive framework for high-energy-density and particle acceleration applications."}}
{"id": "2510.09875", "pdf": "https://arxiv.org/pdf/2510.09875", "abs": "https://arxiv.org/abs/2510.09875", "authors": ["Giorgio Tortone", "Bozhidar Velichkov"], "title": "Vectorial Bernoulli Problems and Free Boundary Systems", "categories": ["math.AP"], "comment": null, "summary": "In this survey we go through some of the recent results about the regularity\nof vectorial free boundary problems of Bernoulli type and free boundary\nsystems. The aim is to illustrate the general methodologies as well as to\noutline a selection of notable open questions.", "AI": {"tldr": "Survey of recent results on regularity of vectorial free boundary problems of Bernoulli type and free boundary systems, covering methodologies and open questions.", "motivation": "To provide an overview of recent developments in vectorial free boundary problems, illustrating general methodologies and highlighting important open questions in the field.", "method": "Survey approach reviewing and synthesizing recent research results, analyzing general methodologies used in the field.", "result": "Comprehensive overview of current state of knowledge in vectorial free boundary problems, identification of key methodologies and notable open questions.", "conclusion": "The survey successfully illustrates the current methodologies and identifies important open research questions in vectorial free boundary problems, providing guidance for future research directions."}}
{"id": "2510.09803", "pdf": "https://arxiv.org/pdf/2510.09803", "abs": "https://arxiv.org/abs/2510.09803", "authors": ["Md Tusher Ahmed", "Farid Ahmed", "Jianzhi Li"], "title": "Enhancement of diffusivity and plastic deformation in ultrasound-assisted cold spray of tungsten: a molecular dynamics study", "categories": ["physics.comp-ph", "physics.atom-ph"], "comment": null, "summary": "Tungsten ($W$) is widely valued for its exceptional thermal stability,\nmechanical strength, and corrosion resistance, making it an ideal candidate for\nhigh-performance military and aerospace applications. However, its high melting\npoint and inherent brittleness pose significant challenges for processing $W$\nusing additive manufacturing (AM). Cold spray (CS), a solid-state AM process\nthat relies on high-velocity particle impact and plastic deformation, offers a\npromising alternative. In this study, we employ atomistic simulations to\ninvestigate the feasibility of CS for tungsten. We show that ultrasound\nperturbation can significantly enhance the self-diffusivity and plastic\ndeformation of $W$ compared to the negligible diffusion and plastic deformation\nobserved in non-ultrasound-assisted CS of $W$. For different impact velocities,\nparticle sizes, and ultrasound parameters, we demonstrate that\nultrasound-assisted viscoplasticity enhances self-diffusivity by inhibiting\ngrain boundaries and incorporating softening in $W$. Moreover, we found that\nthis enhanced diffusion in ultrasound-assisted $W$ can be exploited to promote\ninterdiffusion at the particle-substrate interface, enabling in situ alloy\nformation. Through the formation of an equimolar $V$-$W$ alloy on a $W$\nsubstrate using ultrasound-assisted CS simulations, we observed distinct\nmechanical properties and a reduced dislocation density in the deposited\ncoating compared to a pure tungsten substrate. These results highlight the\npotential of ultrasound-assisted CS as a viable approach for fabricating\nuniform coatings and engineered alloys, addressing key limitations in the AM of\nrefractory metals.", "AI": {"tldr": "Ultrasound-assisted cold spray enhances tungsten's self-diffusivity and plastic deformation, enabling in situ alloy formation and improved coating properties for additive manufacturing applications.", "motivation": "Tungsten's high melting point and brittleness make it challenging for additive manufacturing. Cold spray offers a solid-state alternative, but traditional CS has limited effectiveness for tungsten due to negligible diffusion and plastic deformation.", "method": "Used atomistic simulations to study ultrasound-assisted cold spray of tungsten, examining different impact velocities, particle sizes, and ultrasound parameters to enhance viscoplasticity and self-diffusivity.", "result": "Ultrasound perturbation significantly increased self-diffusivity and plastic deformation in tungsten compared to non-ultrasound CS. Enabled in situ alloy formation (V-W alloy) with distinct mechanical properties and reduced dislocation density in deposited coatings.", "conclusion": "Ultrasound-assisted cold spray is a viable approach for fabricating uniform coatings and engineered alloys of refractory metals like tungsten, overcoming key limitations in additive manufacturing."}}
{"id": "2510.10283", "pdf": "https://arxiv.org/pdf/2510.10283", "abs": "https://arxiv.org/abs/2510.10283", "authors": ["Zhen Guan", "Xianxian Cao"], "title": "Weighted implicit-explicit discontinuous Galerkin methods for two-dimensional Ginzburg-Landau equations on general meshes", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, a second-order linearized discontinuous Galerkin method on\ngeneral meshes, which treats the backward differentiation formula of order two\n(BDF2) and Crank-Nicolson schemes as special cases, is proposed for solving the\ntwo-dimensional Ginzburg-Landau equations with cubic nonlinearity. By utilizing\nthe discontinuous Galerkin inverse inequality and the mathematical induction\nmethod, the unconditionally optimal error estimate in $L^2$-norm is obtained.\nThe core of the analysis in this paper resides in the classification and\ndiscussion of the relationship between the temporal step size and the spatial\nstep size, specifically distinguishing between the two scenarios of tau^2 \\leq\nh^{k+1}$and$\\tau^2 > h^{k+1}$, where$k$denotes the degree of the discrete\nspatial scheme. Finally, this paper presents two numerical examples involving\nvarious grids and polynomial degrees to verify the correctness of the\ntheoretical results.", "AI": {"tldr": "A second-order linearized discontinuous Galerkin method is developed for 2D Ginzburg-Landau equations, providing unconditionally optimal error estimates through temporal-spatial step size analysis.", "motivation": "To develop an efficient numerical method for solving the nonlinear Ginzburg-Landau equations that can handle general meshes and provide rigorous error analysis.", "method": "Uses a second-order linearized discontinuous Galerkin method that includes BDF2 and Crank-Nicolson schemes as special cases, with analysis based on discontinuous Galerkin inverse inequality and mathematical induction.", "result": "Achieved unconditionally optimal error estimate in L\u00b2-norm by analyzing two scenarios of temporal-spatial step size relationship: \u03c4\u00b2 \u2264 h^{k+1} and \u03c4\u00b2 > h^{k+1}, where k is the polynomial degree.", "conclusion": "The proposed method is validated through numerical examples with various grids and polynomial degrees, confirming the theoretical error estimates."}}
{"id": "2510.09978", "pdf": "https://arxiv.org/pdf/2510.09978", "abs": "https://arxiv.org/abs/2510.09978", "authors": ["Shi-Min Liang", "Jian-Fu Zhang", "Na-Na Gao", "Nian-Yu Yi"], "title": "Studying the properties of reconnection-driven turbulence", "categories": ["astro-ph.HE", "physics.plasm-ph"], "comment": "9 pages, 6 figures and 1 table. Accepted for publication in A&A", "summary": "Magnetic reconnection, often accompanied by turbulence interaction, is a\nubiquitous phenomenon in astrophysical environments. However, the current\nunderstanding of the nature of turbulent magnetic reconnection remains\ninsufficient. We investigate the statistical properties of reconnection\nturbulence in the framework of the self-driven reconnection. Using the\nopen-source software package AMUN, we first perform numerical simulations of\nturbulent magnetic reconnection. We then obtain the statistical results of\nreconnection turbulence by traditional statistical methods such as the power\nspectrum and structure function. Our numerical results demonstrate: (1) the\nvelocity spectrum of reconnection turbulence follows the classical Kolmogorov\ntype of $E\\propto k^{-5/3}$, while the magnetic field spectrum is steeper than\nthe Kolmogorov spectrum, which are independent of limited resistivity, guide\nfield, and isothermal or adiabatic fluid states; (2) most of the simulations\nshow the anisotropy cascade, except that the presence of a guide field leads to\nan isotropic cascade; (3) reconnection turbulence is incompressible in the\nadiabatic state, with energy distribution dominated by the velocity solenoidal\ncomponent; (4) different from pure magnetohydrodynamic (MHD) turbulence, the\nintermittency of the velocity field is stronger than that of the magnetic field\nin reconnection turbulence. The steep magnetic field spectrum, together with\nthe velocity spectrum of Kolmogorov type, can characterize the feature of the\nreconnection turbulence. In the case of the presence of the guide field, the\nisotropy of the reconnection turbulence cascade is also different from the\ncascade mode of pure MHD turbulence. Our experimental results provide new\ninsights into the properties of reconnection turbulence, which will contribute\nto advancing the self-driven reconnection theory.", "AI": {"tldr": "Study investigates statistical properties of turbulent magnetic reconnection using numerical simulations, revealing distinct spectral characteristics and cascade behaviors compared to pure MHD turbulence.", "motivation": "Current understanding of turbulent magnetic reconnection remains insufficient despite its ubiquity in astrophysical environments, requiring detailed statistical analysis of reconnection turbulence properties.", "method": "Used AMUN open-source software to perform numerical simulations of turbulent magnetic reconnection, analyzed using traditional statistical methods including power spectrum and structure function analysis.", "result": "Found velocity spectrum follows Kolmogorov type (E\u221dk^{-5/3}) while magnetic field spectrum is steeper; anisotropy cascade except with guide field; incompressible turbulence in adiabatic state; stronger velocity intermittency than magnetic field.", "conclusion": "Steep magnetic field spectrum with Kolmogorov velocity spectrum characterizes reconnection turbulence, with guide field altering cascade isotropy, providing new insights for advancing self-driven reconnection theory."}}
{"id": "2510.09992", "pdf": "https://arxiv.org/pdf/2510.09992", "abs": "https://arxiv.org/abs/2510.09992", "authors": ["Mario Bukal", "Igor Kukavica", "Linfeng Li", "Boris Muha"], "title": "A no-contact result for a plate-fluid interaction system in dimension three", "categories": ["math.AP"], "comment": "14 pages", "summary": "We address the fluid-structure interaction between a viscous incompressible\nfluid and an elastic plate forming its moving upper boundary in three\ndimensions. The fluid is described by the incompressible Navier-Stokes\nequations with a free upper boundary that evolves according to the motion of\nthe structure, coupled via the velocity- and stress-matching conditions. Under\nthe natural energy bounds and additional regularity assumptions on the weak\nsolutions, we prove a non-contact property with a uniform separation of the\nplate from the rigid boundary. The result does not require damping in the plate\nequation.", "AI": {"tldr": "The paper proves that in 3D fluid-structure interaction between viscous fluid and elastic plate, the plate maintains uniform separation from rigid boundary without contact, even without damping.", "motivation": "To understand the non-contact behavior in fluid-structure interaction systems where an elastic plate forms the moving upper boundary of a viscous fluid, particularly without requiring damping mechanisms.", "method": "Analyzed weak solutions of incompressible Navier-Stokes equations coupled with elastic plate motion via velocity- and stress-matching conditions, under natural energy bounds and additional regularity assumptions.", "result": "Proved uniform separation property showing the plate does not contact the rigid boundary, with this result holding even in the absence of damping in the plate equation.", "conclusion": "The elastic plate maintains a uniform distance from the rigid boundary in 3D fluid-structure interaction systems, demonstrating inherent non-contact behavior without requiring damping."}}
{"id": "2510.09812", "pdf": "https://arxiv.org/pdf/2510.09812", "abs": "https://arxiv.org/abs/2510.09812", "authors": ["Hongyi Guan", "Ananya Renuka Balakrishna"], "title": "CuPyMag: GPU-Accelerated Finite-Element Micromagnetics with Magnetostriction", "categories": ["physics.comp-ph"], "comment": null, "summary": "We introduce CuPyMag, an open-source, Python-based framework for large-scale\nmicromagnetic simulations with magnetostriction. CuPyMag solves micromagnetics\nwith finite elements in a GPU-resident workflow in which key operations, such\nas right-hand-side assembly, spatial derivatives, and volume averages, are\ntensorized using CuPy's BLAS-accelerated backend. Benchmark tests show that the\nGPU solvers in CuPyMag achieve a speedup of up to two orders of magnitude\ncompared to the CPU codes. Its runtime grows linearly/sublinearly with problem\nsize, demonstrating high efficiency. Additionally, CuPyMag uses the\nGauss-Seidel projection method for time integration, which not only allows\nstable time steps (up to 11 ps) but also solves each governing equation with\nonly 1-3 conjugate-gradient iterations without preconditioning. CuPyMag\naccounts for magnetoelastic coupling and far-field effects arising from the\nboundary of the magnetic body, both of which play an important role in\nmagnetization reversal in the presence of local defects. CuPyMag solves these\ncomputationally intensive multiphysics simulations with a high-resolution mesh\n(up to 3M nodes) in under three hours on an NVIDIA H200 GPU. This acceleration\nenables micromagnetic simulations with non-trivial defect geometries and\nresolves nanoscale magnetic structures. It expands the scope of micromagnetic\nsimulations towards realistic, large-scale problems that can guide experiments.\nMore broadly, CuPyMag is developed using widely adopted Python libraries, which\nprovide cross-platform compatibility, ease of installation, and accessibility\nfor adaptations to diverse applications.", "AI": {"tldr": "CuPyMag is a GPU-accelerated Python framework for large-scale micromagnetic simulations with magnetostriction, achieving up to 100x speedup over CPU codes and enabling high-resolution simulations with 3M nodes in under 3 hours.", "motivation": "To enable large-scale micromagnetic simulations with magnetostriction that account for realistic defect geometries and nanoscale magnetic structures, which are computationally intensive and challenging with traditional CPU-based approaches.", "method": "Uses finite elements with GPU-resident workflow using CuPy's BLAS-accelerated backend, tensorizing key operations. Employs Gauss-Seidel projection method for time integration with stable time steps up to 11 ps and solves equations with 1-3 conjugate-gradient iterations without preconditioning.", "result": "Achieves up to two orders of magnitude speedup compared to CPU codes, with linear/sublinear runtime growth. Successfully handles magnetoelastic coupling and far-field effects, solving high-resolution simulations with up to 3M nodes in under three hours on NVIDIA H200 GPU.", "conclusion": "CuPyMag enables realistic, large-scale micromagnetic simulations with non-trivial defect geometries, expanding the scope towards problems that can guide experiments. Its Python-based design provides cross-platform compatibility and accessibility for diverse applications."}}
{"id": "2510.10350", "pdf": "https://arxiv.org/pdf/2510.10350", "abs": "https://arxiv.org/abs/2510.10350", "authors": ["Chuqi Chen", "Yang Xiang", "Weihong Zhang"], "title": "Learning Operators through Coefficient Mappings in Fixed Basis Spaces", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "Operator learning has emerged as a powerful paradigm for approximating\nsolution operators of partial differential equations (PDEs) and other\nfunctional mappings. \\textcolor{red}{}{Classical approaches} typically adopt a\npointwise-to-pointwise framework, where input functions are sampled at\nprescribed locations and mapped directly to solution values. We propose the\nFixed-Basis Coefficient to Coefficient Operator Network (FB-C2CNet), which\nlearns operators in the coefficient space induced by prescribed basis\nfunctions. In this framework, the input function is projected onto a fixed set\nof basis functions (e.g., random features or finite element bases), and the\nneural operator predicts the coefficients of the solution function in the same\nor another basis. By decoupling basis selection from network training,\nFB-C2CNet reduces training complexity, enables systematic analysis of how basis\nchoice affects approximation accuracy, and clarifies what properties of\ncoefficient spaces (such as effective rank and coefficient variations) are\ncritical for generalization. Numerical experiments on Darcy flow, Poisson\nequations in regular, complex, and high-dimensional domains, and elasticity\nproblems demonstrate that FB-C2CNet achieves high accuracy and computational\nefficiency, showing its strong potential for practical operator learning tasks.", "AI": {"tldr": "FB-C2CNet is a novel operator learning framework that maps between coefficient spaces of basis functions rather than pointwise values, reducing training complexity and enabling systematic analysis of basis choice effects.", "motivation": "Classical operator learning approaches use pointwise-to-pointwise mapping which can be inefficient. The authors aim to develop a more efficient framework that operates in coefficient space to reduce training complexity and enable better understanding of basis function effects.", "method": "FB-C2CNet projects input functions onto fixed basis functions (random features or finite element bases) and predicts solution coefficients in the same or different basis. This decouples basis selection from network training.", "result": "Numerical experiments on Darcy flow, Poisson equations in various domains, and elasticity problems show FB-C2CNet achieves high accuracy and computational efficiency.", "conclusion": "FB-C2CNet demonstrates strong potential for practical operator learning by providing an efficient coefficient-to-coefficient framework that enables systematic analysis of basis choice and generalization properties."}}
{"id": "2510.11365", "pdf": "https://arxiv.org/pdf/2510.11365", "abs": "https://arxiv.org/abs/2510.11365", "authors": ["Vedant Dhruv", "Ben Prather", "Mani Chandra", "Abhishek V. Joshi", "Charles F. Gammie"], "title": "Electromagnetic Observables of Weakly Collisional Black Hole Accretion", "categories": ["astro-ph.HE", "physics.plasm-ph"], "comment": "13 pages, 9 figures. Accepted", "summary": "The black holes in the Event Horizon Telescope sources Messier 87* and\nSagittarius A* (SgrA*) are embedded in a hot, collisionless plasma that is\nfully described in kinetic theory yet is usually modeled as an ideal,\nmagnetized fluid. In this Letter, we present results from a new set of weakly\ncollisional fluid simulations in which leading order kinetic effects are\nmodeled as viscosity and heat conduction. Consistent with earlier,\nlower-resolution studies, we find that overall flow dynamics remain very\nsimilar between ideal and non-ideal models. For the first time, we synthesize\nimages and spectra of SgrA* from weakly collisional models -- assuming an\nisotropic, thermal population of electrons -- and find that these remain\nlargely indistinguishable from ideal fluid predictions. However, most weakly\ncollisional models exhibit lower light curve variability, with all magnetically\ndominated models showing a small but systematic decrease in variability.", "AI": {"tldr": "Weakly collisional fluid simulations with viscosity and heat conduction show similar flow dynamics and imaging results for SgrA* compared to ideal fluid models, but with reduced light curve variability.", "motivation": "To model black holes in hot, collisionless plasma more accurately by incorporating kinetic effects that are typically ignored in ideal fluid models.", "method": "Used weakly collisional fluid simulations with viscosity and heat conduction to model leading order kinetic effects, and synthesized images and spectra of SgrA* assuming isotropic thermal electron population.", "result": "Flow dynamics and synthesized images remain very similar to ideal fluid predictions, but weakly collisional models show lower light curve variability, especially in magnetically dominated models.", "conclusion": "While weakly collisional models produce similar overall results to ideal fluid models, they systematically reduce variability in light curves, particularly for magnetically dominated systems."}}
{"id": "2510.10024", "pdf": "https://arxiv.org/pdf/2510.10024", "abs": "https://arxiv.org/abs/2510.10024", "authors": ["Soufiane Bentout", "Hoang-Hung Vo"], "title": "The eigentheory for nonlocal cooperative-advective system and its role in the study of free boundary system for directional epidemic models", "categories": ["math.AP", "35K55, 35K57"], "comment": null, "summary": "In this paper, we propose and analyze a nonlocal cooperative\nreaction--diffusion system with free boundaries and drift terms, motivated by\ndirectional epidemic spread. Lacking a variational structure but requiring\nsharper regularity of solutions, the model poses substantial analytical\nchallenges compared with previous\nworks~\\cite{Du,Berestycki2016a,Berestycki2016b,Cao2019,NguyenVo2022,Tang2024a,Tang2024b}.\nWe first establish the well-posedness of the local problem and the global\nexistence and uniqueness of classical solutions in $C^1$ space.\n  We then study the associated nonlocal eigenvalue problem, proving the\nexistence, simplicity, qualitative properties, and asymptotic behavior of the\nprincipal eigenvalue. The analysis employs Fredholm theory, the\nCrandall--Rabinowitz bifurcation theorem, and Hadamard-type derivative formulas\nto describe its parameter dependence and connection with the basic reproduction\nnumber~$R_0$.\n  Building on this spectral characterization, we show that the system admits a\n\\emph{sharp vanishing--spreading dichotomy} in its long-term dynamics. When\n$R_0\\le1$, all solutions vanish; for $R_0>1$, the outcome depends on the\ninitial domain size~$h_0$ and the free-boundary expansion rate~$\\mu$. There\nexists a critical habitat length~$\\mathcal L^\\ast$ such that if $h_0<\\mathcal\nL^\\ast$, a threshold $\\widehat{\\mu}>0$ separates vanishing\n($\\mu\\in(0,\\widehat{\\mu}]$) from spreading ($\\mu>\\widehat{\\mu}$). In the\nspreading regime, solutions converge to the unique positive steady state, while\nin the vanishing regime they decay uniformly to zero. These results provide a\nrigorous framework for the threshold dynamics of cooperative--advective\nnonlocal systems and offer mathematical insight for further studies in epidemic\nmodeling, ecological invasion, and population dynamics.", "AI": {"tldr": "A nonlocal cooperative reaction-diffusion system with free boundaries and drift terms is analyzed, establishing well-posedness, spectral properties, and a sharp vanishing-spreading dichotomy based on the basic reproduction number R\u2080 and initial conditions.", "motivation": "The model is motivated by directional epidemic spread, addressing analytical challenges in nonlocal systems without variational structure that require sharper solution regularity.", "method": "Established well-posedness and global existence of classical solutions, analyzed nonlocal eigenvalue problems using Fredholm theory, Crandall-Rabinowitz bifurcation theorem, and Hadamard-type derivative formulas to study principal eigenvalue properties.", "result": "Proved a sharp vanishing-spreading dichotomy: when R\u2080\u22641, all solutions vanish; when R\u2080>1, outcome depends on initial domain size h\u2080 and expansion rate \u03bc, with critical habitat length L* and threshold \u03bc\u0302 separating vanishing from spreading regimes.", "conclusion": "Results provide rigorous framework for threshold dynamics in cooperative-advective nonlocal systems, offering mathematical insights for epidemic modeling, ecological invasion, and population dynamics."}}
{"id": "2510.09999", "pdf": "https://arxiv.org/pdf/2510.09999", "abs": "https://arxiv.org/abs/2510.09999", "authors": ["Yiran Bai", "Feng Xiong", "Xueheng Kuang"], "title": "Random State Approach to Quantum Computation of Electronic-Structure Properties", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "quant-ph"], "comment": null, "summary": "Classical computation of electronic properties in large-scale materials\nremains challenging. Quantum computation has the potential to offer advantages\nin memory footprint and computational scaling. However, general and practical\nquantum algorithms for simulating large-scale materials are still lacking. We\npropose and implement random-state quantum algorithms to calculate\nelectronic-structure properties of real materials. Using a random state circuit\nwith only a few qubits, we employ real-time evolution with first-order Trotter\ndecomposition and Hadamard test to obtain electronic density of states, and we\ndevelop a modified quantum phase estimation algorithm to calculate real-space\nlocal density of states via direct quantum measurements. Furthermore, we\nvalidate these algorithms by numerically computing the density of states and\nspatial distributions of electronic states in graphene, twisted bilayer\ngraphene quasicrystals, and fractal lattices, covering system sizes from\nhundreds to thousands of atoms. Our results manifest that the random-state\nquantum algorithms provide a general and qubit-efficient route to simulating\nelectronic properties of large-scale periodic and aperiodic materials on\nquantum computers.", "AI": {"tldr": "Random-state quantum algorithms for efficient electronic structure calculations in large-scale materials using few qubits", "motivation": "Classical computation struggles with large-scale materials, and existing quantum algorithms lack practicality for real materials simulation", "method": "Random state circuits with real-time evolution using Trotter decomposition and Hadamard test for density of states; modified quantum phase estimation for local density of states via direct measurements", "result": "Successfully computed electronic properties for graphene, twisted bilayer graphene quasicrystals, and fractal lattices with system sizes from hundreds to thousands of atoms", "conclusion": "Random-state quantum algorithms provide a general and qubit-efficient approach for simulating electronic properties of large-scale periodic and aperiodic materials"}}
{"id": "2510.10355", "pdf": "https://arxiv.org/pdf/2510.10355", "abs": "https://arxiv.org/abs/2510.10355", "authors": ["Tom\u00e1\u0161 Roub\u00ed\u010dek"], "title": "Staggered time discretization in finitely-strained heterogeneous visco-elastodynamics with damage or diffusion in the Eulerian frame", "categories": ["math.NA", "cs.NA", "35Q74, 65M99, 74A30, 74B20, 74H20. 74S99"], "comment": null, "summary": "The semi-implicit (partly decoupled, also called staggered or fraction-step)\ntime discretization is applied to compressible nonlinear dynamical models of\nviscoelastic solids in the Eulerian description, i.e.\\ in the actual deforming\nconfiguration, formulated fully in terms of rates. The Kelvin-Voigt rheology\nand also, in the deviatoric part, the Jeffreys rheology are considered. The\nnumerical stability and, considering the Stokes-type viscosity multipolar of\nthe 2nd-grade, also convergence towards weak solutions are proved in\nthree-dimensional situations, exploiting the convexity of the kinetic energy\nwhen written in terms of linear momentum. No (poly)convexity of the stored\nenergy is required and some enhancements (specifically towards damage and\ndiffusion models) are briefly outlined, too.", "AI": {"tldr": "Semi-implicit time discretization applied to compressible viscoelastic solid models in Eulerian description, proving numerical stability and convergence for 3D cases without requiring convexity of stored energy.", "motivation": "To develop stable and convergent numerical methods for nonlinear viscoelastic solid models in actual deforming configurations, addressing challenges in computational mechanics for materials with complex rheological behavior.", "method": "Uses semi-implicit (staggered) time discretization for compressible nonlinear viscoelastic solid models in Eulerian description with Kelvin-Voigt and Jeffreys rheologies, exploiting convexity of kinetic energy in linear momentum terms.", "result": "Proved numerical stability and convergence towards weak solutions in three-dimensional cases, with enhancements outlined for damage and diffusion models.", "conclusion": "The semi-implicit approach provides stable and convergent numerical schemes for viscoelastic solid models without requiring convexity of stored energy, offering potential extensions to more complex material behaviors."}}
{"id": "2510.10090", "pdf": "https://arxiv.org/pdf/2510.10090", "abs": "https://arxiv.org/abs/2510.10090", "authors": ["Slim Ibrahim", "Quyuan Lin", "Lingjun Qian", "Edriss S. Titi"], "title": "On the Profile of Singularity Formation for the Incompressible Hydrostatic Boussinesq system", "categories": ["math.AP"], "comment": null, "summary": "The primitive equations (PEs) model planetary large-scale oceanic and\natmospheric dynamics. While it has been shown that there are smooth solutions\nto the inviscid PEs (also called the hydrostatic Euler equations) with constant\ntemperature (isothermal) that develop stable singularities in finite time, the\neffect of non-constant temperature on the singularity formation has not been\nestablished yet. This paper studies the stability of singularity formation for\nnon-constant temperature in two scenarios: when there is no diffusion in the\ntemperature, or when a vertical diffusivity is added to the temperature\ndynamics. For both scenarios, our results indicate that the variation of\ntemperature affects neither the formation of singularity, nor its stability, in\nthe velocity field, respectively.", "AI": {"tldr": "The paper studies how non-constant temperature affects singularity formation in the primitive equations (hydrostatic Euler equations), finding that temperature variations don't impact singularity formation or stability in the velocity field.", "motivation": "Previous research showed smooth solutions to inviscid primitive equations with constant temperature develop stable singularities, but the effect of non-constant temperature on singularity formation was unknown.", "method": "Analyzed singularity formation stability for non-constant temperature in two scenarios: without temperature diffusion and with vertical diffusivity added to temperature dynamics.", "result": "For both scenarios, temperature variation does not affect singularity formation or its stability in the velocity field.", "conclusion": "The variation of temperature has no impact on the formation or stability of singularities in the primitive equations, regardless of whether temperature diffusion is present or not."}}
{"id": "2510.10005", "pdf": "https://arxiv.org/pdf/2510.10005", "abs": "https://arxiv.org/abs/2510.10005", "authors": ["Ryan F. Johnson", "Eric J. Ching", "Ethan S. Genter", "Joshua E. Lipman", "Andrew D. Kercher", "Jay Arcities", "Hai Wang"], "title": "ChemGen: Code Generation for Multispecies Chemical Kinetics in Computational Physics Simulations", "categories": ["physics.comp-ph"], "comment": "under review", "summary": "This paper introduces ChemGen, a software package that uses code generation\nto integrate multispecies thermodynamics and chemical kinetics into C+-based\ncomputational physics codes. ChemGen aims to make chemical kinetics more\naccessible in existing simulation frameworks and help bridge the gap between\ncombustion modeling and computational physics. The package employs the concept\nof decorators which enable flexible C++ code generation to target established\nsoftware ecosystems. ChemGen generates code to evaluate thermodynamic\nproperties, chemical source terms, and their analytical derivatives for\nJacobian calculations. Also included are a variety of implicit time integration\nschemes, linear solvers, and preconditioners. The various components of Chemgen\nare verified by demonstrating agreement with Cantera and/or theoretical\nconvergence rates. Finally, we integrate ChemGen into OpenFOAM and achieve a\nspeedup over its native chemistry solver by approximately four times. ChemGen\nis an ongoing project released under the NRL Open License, a source-available\nlicense provided by the U.S. Naval Research Laboratory.", "AI": {"tldr": "ChemGen is a software package that generates C++ code to integrate multispecies thermodynamics and chemical kinetics into computational physics codes, achieving 4x speedup over OpenFOAM's native chemistry solver.", "motivation": "To make chemical kinetics more accessible in existing simulation frameworks and bridge the gap between combustion modeling and computational physics.", "method": "Uses code generation with decorators to generate flexible C++ code for thermodynamic properties, chemical source terms, analytical derivatives, implicit time integration schemes, linear solvers, and preconditioners.", "result": "Verified components show agreement with Cantera and theoretical convergence rates. Integration into OpenFOAM achieved approximately 4x speedup over native chemistry solver.", "conclusion": "ChemGen successfully bridges combustion modeling and computational physics through code generation, providing significant performance improvements while being released under NRL Open License as an ongoing project."}}
{"id": "2510.10502", "pdf": "https://arxiv.org/pdf/2510.10502", "abs": "https://arxiv.org/abs/2510.10502", "authors": ["Rong Huang", "Jungong Xue"], "title": "Exact deflation for accurate SVD computation of nonnegative bidiagonal products of arbitrary rank", "categories": ["math.NA", "cs.NA", "65F15, 15A18"], "comment": null, "summary": "Dealing with zero singular values can be quite challenging, as they have the\npotential to cause numerous numerical difficulties. This paper presents a\nmethod for computing the singular value decomposition (SVD) of a nonnegative\nbidiagonal product of arbitrary rank, regardless of whether the factors are of\nfull rank or rank-deficient, square or rectangular. A key feature of our method\nis its ability to exactly deflate all zero singular values with a favorable\ncomplexity, irrespective of rank deficiency and ill conditioning. Furthermore,\nit ensures the computation of nonzero singular values, no matter how small they\nmay be, with high relative accuracy. Additionally, our method is well-suited\nfor accurately computing the SVDs of arbitrary submatrices, leveraging an\napproach to extract their representations from the original product. We have\nconducted error analysis and numerical experiments to validate the claimed high\nrelative accuracy.", "AI": {"tldr": "A method for computing SVD of nonnegative bidiagonal products that handles zero singular values effectively, deflates them exactly, and computes nonzero singular values with high relative accuracy regardless of rank deficiency or ill conditioning.", "motivation": "Zero singular values cause numerical difficulties in SVD computations, especially for rank-deficient and ill-conditioned matrices. Existing methods struggle with accurate computation when dealing with these challenging cases.", "method": "Developed a method for computing SVD of nonnegative bidiagonal products that can handle arbitrary rank, full rank or rank-deficient factors, and square or rectangular matrices. The method exactly deflates zero singular values and computes nonzero singular values with high relative accuracy. Also supports accurate SVD computation for arbitrary submatrices.", "result": "The method successfully deflates all zero singular values with favorable complexity, computes nonzero singular values with high relative accuracy regardless of how small they are, and handles rank deficiency and ill conditioning effectively. Error analysis and numerical experiments validate the claimed accuracy.", "conclusion": "The proposed method provides a robust solution for SVD computation of nonnegative bidiagonal products, overcoming numerical challenges posed by zero singular values and enabling high-accuracy computation even for ill-conditioned and rank-deficient cases."}}
{"id": "2510.10096", "pdf": "https://arxiv.org/pdf/2510.10096", "abs": "https://arxiv.org/abs/2510.10096", "authors": ["Yong Lu", "Milan Pokorny"], "title": "Weak solutions and weak-strong uniqueness for a compressible power-law-Oldroyd--B fluid model", "categories": ["math.AP", "35Q35, 76N10"], "comment": null, "summary": "We consider a model of a viscoelastic compressible flow in $R^{3}$ which is\nadditionally shear thickening (the stress tensor corresponds to the power law\nmodel, however, the divergence of the velocity is due to the model bounded). We\nprove existence of a weak solution to this model provided the growth in the\npower law model is larger or equal than $\\frac 52$. We also prove that any\nsufficiently smooth solution of this model is unique in the class of weak\nsolution, provided extra integrability of the initial value for the extra\nstress tensor is assumed.", "AI": {"tldr": "Existence and uniqueness of weak solutions for a viscoelastic compressible flow model in R\u00b3 with shear thickening properties, requiring power law growth \u2265 5/2.", "motivation": "To establish mathematical foundations for viscoelastic compressible flows with shear thickening behavior, particularly addressing the challenging case where stress tensor follows power law model while velocity divergence remains bounded.", "method": "Analysis of a viscoelastic compressible flow model using power law stress tensor, proving existence of weak solutions through mathematical analysis techniques, and establishing uniqueness under additional integrability conditions.", "result": "Proved existence of weak solutions when power law growth is \u2265 5/2, and showed uniqueness of sufficiently smooth solutions in the weak solution class with extra integrability conditions on initial stress tensor values.", "conclusion": "The model admits weak solutions under specified growth conditions, and these solutions are unique when additional regularity and integrability assumptions are satisfied, providing rigorous mathematical validation for the viscoelastic compressible flow framework."}}
{"id": "2510.10529", "pdf": "https://arxiv.org/pdf/2510.10529", "abs": "https://arxiv.org/abs/2510.10529", "authors": ["Vishal Subramanian", "Bikash Kanungo", "Vikram Gavini"], "title": "invDFT: A CPU-GPU massively parallel tool to find exact exchange-correlation potentials from groundstate densities", "categories": ["physics.comp-ph"], "comment": "41 pages, 14 figures", "summary": "Density functional theory (DFT) remains the most widely used electronic\nstructure method. Although exact in principle, in practice, it relies on\napproximations to the exchange-correlation (XC) functional, which is known to\nbe a unique functional of the electron density. Despite 50 years of active\nresearch, existing XC approximations remain far from general purpose chemical\naccuracy of various thermochemical and materials properties. In that light, the\ninverse DFT problem, of finding the exact XC potential corresponding to an\naccurate groundstate density, offers an insightful tool to understand the\nnature of the XC functional as well as aid in the development of more accurate\nfunctionals. However, solving the inverse DFT problem is fraught with several\nnumerical challenges, such as non-uniqueness or spurious oscillations in the\nsolution and non-convergence. We present invDFT as an open-source framework to\naddress the outstanding challenges in inverse DFT and computed XC potentials\nsolely from a target density. We do so by use of a systematically convergent\nfinite-element basis and asymptotic corrections to the target density. We also\nemploy several numerical and high-performance computing (HPC) advances that\naffords both efficiency and parallel scalability, on CPU-GPU hybrid\narchitectures. We demonstrate the accuracy and scalability of invDFT using\naccurate full-configuration interaction (FCI) densities as well as model\ndensities, ranging up to 100 electrons and spanning both weakly and strongly\ncorrelated molecules.", "AI": {"tldr": "invDFT is an open-source framework that solves the inverse DFT problem to compute exact XC potentials from target densities, addressing numerical challenges through finite-element basis, asymptotic corrections, and HPC advances.", "motivation": "Existing XC approximations in DFT lack general purpose chemical accuracy despite 50 years of research. The inverse DFT problem offers insights into XC functional nature and aids in developing more accurate functionals.", "method": "Uses systematically convergent finite-element basis, asymptotic corrections to target density, and numerical/HPC advances including CPU-GPU hybrid architectures for efficiency and parallel scalability.", "result": "Demonstrated accuracy and scalability using FCI densities and model densities for up to 100 electrons across weakly and strongly correlated molecules.", "conclusion": "invDFT provides a robust framework to overcome numerical challenges in inverse DFT, enabling computation of exact XC potentials from target densities for improved functional development."}}
{"id": "2510.10656", "pdf": "https://arxiv.org/pdf/2510.10656", "abs": "https://arxiv.org/abs/2510.10656", "authors": ["Mengqing Zhang", "Shiyi Li", "Dongmi Luo", "Jianxian Qiu", "Yibing Chen"], "title": "Uniformly High Order Discontinuous Galerkin Gas Kinetic Scheme for Compressible flows", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "comment": null, "summary": "In this paper, a uniformly high-order discontinuous Galerkin gas kinetic\nscheme (DG-HGKS) is proposed to solve the Euler equations of compressible\nflows. The new scheme is an extension of the one-stage compact and efficient\nhigh-order GKS (CEHGKS, Li et al. , 2021. J. Comput. Phys. 447, 110661) in the\nfinite volume framework. The main ideas of the new scheme consist of two parts.\nFirstly, starting from a fully discrete DG formulation, the numerical fluxes\nand volume integrals are expanded in time. Secondly, the time derivatives are\nreplaced by spatial derivatives using the techniques in CEHGKS. To suppress the\nnon-physical oscillations in the discontinuous regions while minimizing the\nnumber of \"troubled cells\", an effective limiter strategy compatible with the\nnew scheme has been developed by combining the KXRCF indicator and the SHWENO\nreconstruction technique. The new scheme can achieve arbitrary high-order\naccuracy in both space and time, thereby breaking the previous limitation of no\nmore than third-order accuracy in existing one-stage DG-HGKS schemes. Numerical\ntests in 1D and 2D have demonstrated the robustness and effectiveness of the\nscheme.", "AI": {"tldr": "A uniformly high-order discontinuous Galerkin gas kinetic scheme (DG-HGKS) is developed for compressible Euler equations, extending previous finite volume methods to achieve arbitrary high-order accuracy in space and time while maintaining efficiency.", "motivation": "To overcome the limitation of existing one-stage DG-HGKS schemes that were restricted to no more than third-order accuracy, and to develop a more efficient high-order scheme for compressible flows.", "method": "Extends CEHGKS framework to DG formulation by expanding numerical fluxes and volume integrals in time, replacing time derivatives with spatial derivatives, and implementing a limiter strategy combining KXRCF indicator with SHWENO reconstruction to handle discontinuities.", "result": "The scheme achieves arbitrary high-order accuracy in both space and time, successfully demonstrated through 1D and 2D numerical tests showing robustness and effectiveness.", "conclusion": "The proposed DG-HGKS scheme successfully breaks the third-order accuracy limitation of previous one-stage methods and provides an efficient high-order solution for compressible flow simulations."}}
{"id": "2510.10120", "pdf": "https://arxiv.org/pdf/2510.10120", "abs": "https://arxiv.org/abs/2510.10120", "authors": ["Hua Chen", "Hong-Ge Chen", "Jin-Ning Li", "Xin Liao"], "title": "Multiple sign-changing solutions for semilinear subelliptic Dirichlet problem", "categories": ["math.AP", "35A15, 35H20, 35J70"], "comment": "47 pages", "summary": "We study the following perturbation from symmetry problem for the semilinear\nsubelliptic equation \\[ \\left\\{\n  \\begin{array}{cc}\n  -\\triangle_{X} u=f(x,u)+g(x,u) & \\mbox{in}~\\Omega, \\\\[2mm]\n  u\\in H_{X,0}^{1}(\\Omega),\\hfill\n  \\end{array}\n  \\right. \\] where $\\triangle_{X}=-\\sum_{i=1}^{m}X_{i}^{*}X_{i}$ is the\nself-adjoint sub-elliptic operator associated with H\\\"{o}rmander vector fields\n$X=(X_{1},X_{2},\\ldots,X_{m})$, $\\Omega$ is an open bounded subset in\n$\\mathbb{R}^n$, and $H_{X,0}^{1}(\\Omega)$ denotes the weighted Sobolev space.\nWe establish multiplicity results for sign-changing solutions using a\nperturbation method alongside refined techniques for invariant sets. The\npivotal aspect lies in the estimation of the lower bounds of min-max values\nassociated with sign-changing critical points. In this paper, we construct two\ndistinct lower bounds of these min-max values. The first one is derived from\nthe lower bound of Dirichlet eigenvalues of $-\\triangle_{X}$, while the second\none is based on the Morse-type estimates and Cwikel-Lieb-Rozenblum type\ninequality in degenerate cases. These lower bounds provide different sufficient\nconditions for multiplicity results, each with unique advantages and are not\nmutually inclusive, particularly in the general non-equiregular case. This\nnovel observation suggests that in some sense, the situation for sub-elliptic\nequations would have essential difference from the classical elliptic\nframework.", "AI": {"tldr": "The paper establishes multiplicity results for sign-changing solutions of semilinear subelliptic equations using perturbation methods and invariant set techniques, with novel lower bounds for min-max values that reveal essential differences from classical elliptic equations.", "motivation": "To study perturbation from symmetry problems for semilinear subelliptic equations associated with H\u00f6rmander vector fields, and understand how these differ from classical elliptic equations.", "method": "Uses perturbation method with refined techniques for invariant sets, constructs two distinct lower bounds for min-max values: one from Dirichlet eigenvalues and another from Morse-type estimates and Cwikel-Lieb-Rozenblum type inequality in degenerate cases.", "result": "Establishes multiplicity results for sign-changing solutions, with two different sufficient conditions that are not mutually inclusive, particularly in non-equiregular cases.", "conclusion": "Sub-elliptic equations exhibit essential differences from classical elliptic framework, as demonstrated by the novel lower bounds and their distinct applicability conditions."}}
{"id": "2510.11180", "pdf": "https://arxiv.org/pdf/2510.11180", "abs": "https://arxiv.org/abs/2510.11180", "authors": ["Shilei Ji", "Jianping Yang", "Li Gao", "Xing'ao Li"], "title": "Tuning Layer Orbital Hall Effect via Spin Rotation in Ferromagnetic Transition Metal Dichalcogenides", "categories": ["physics.comp-ph"], "comment": null, "summary": "Orbitronics, which leverages the angular momentum of atomic orbitals for\ninformation transmission, provides a novel strategy to overcome the limitations\nof electronic devices. Unlike electron spin, orbital angular momentum (OAM) is\nstrongly influenced by crystal field effects and band topology, making its\norientation difficult to manipulate with external fields. In this work, by\nusing first principle calculations, we investigate quantum anomalous Hall\ninsulators (QAHIs) as a model system to study the layer orbital Hall effect\n(OHE). Due to band inversion, only one valley remains orbital polarization, and\nthus the OHE originates from a single valley. Based on stacking symmetry\nanalysis, we investigated both AA and AB stacking configurations, which possess\nmirror and inversion symmetries, respectively. The excitation of OAM exhibits\nvalley selectivity, determined jointly by valley polarization and orbital\npolarization. In AA stacking, the absence of inversion center gives rise to\nintrinsic orbital polarization, leading to OAM excitations from different\nvalleys in the two layers. In contrast, AB stacking is protected by inversion\nsymmetry, which enforces valley polarization and", "AI": {"tldr": "The paper investigates orbital Hall effect in quantum anomalous Hall insulators using first-principles calculations, showing valley-selective orbital angular momentum excitation controlled by stacking symmetry.", "motivation": "To overcome limitations of electronic devices by leveraging orbital angular momentum for information transmission, and to understand how crystal field effects and band topology influence orbital angular momentum manipulation.", "method": "First-principles calculations on quantum anomalous Hall insulators with different stacking configurations (AA and AB stacking), analyzing layer orbital Hall effect through symmetry analysis and valley/orbital polarization.", "result": "Orbital Hall effect originates from single valley due to band inversion; AA stacking shows intrinsic orbital polarization with OAM excitations from different valleys in two layers; AB stacking exhibits valley polarization protected by inversion symmetry.", "conclusion": "Stacking symmetry controls valley-selective orbital angular momentum excitation, providing insights for orbitronics applications where orbital angular momentum can be manipulated through structural symmetry engineering."}}
{"id": "2510.10668", "pdf": "https://arxiv.org/pdf/2510.10668", "abs": "https://arxiv.org/abs/2510.10668", "authors": ["Xiang Wang", "Yuqing Zhang", "Zhimin Zhang"], "title": "Novel superconvergence and ultraconvergence structures for the finite volume element method", "categories": ["math.NA", "cs.NA", "65N12, 65N08, 65N30"], "comment": null, "summary": "This paper develops novel natural superconvergence and ultraconvergence\nstructures for the bi-$k$-order finite volume element (FVE) method on\nrectangular meshes. These structures furnish tunable and possibly asymmetric\nsuperconvergence and ultraconvergence points. We achieve one-order-higher\nsuperconvergence for both derivatives and function values, and\ntwo-orders-higher ultraconvergence for derivatives--a phenomenon that standard\nbi-$k$-order finite elements do not exhibit. Derivative ultraconvergence\nrequires three conditions: a diagonal diffusion tensor, zero convection\ncoefficients, and the FVE scheme satisfying tensorial $k$-$k$-order\northogonality (imposed via dual mesh constraints). This two-dimensional\nderivative ultraconvergence is not a trivial tensor-product extension of the\none-dimensional phenomena; its analysis is also considerably more complex due\nto directional coupling. Theoretically, we introduce the asymmetric-enabled\nM-decompositions (AMD-Super and AMD-Ultra) to rigorously prove these phenomena.\nNumerical experiments confirm the theory.", "AI": {"tldr": "Novel superconvergence and ultraconvergence structures for bi-k-order FVE method on rectangular meshes, achieving one-order-higher superconvergence and two-orders-higher ultraconvergence for derivatives.", "motivation": "To develop tunable and asymmetric superconvergence/ultraconvergence points that standard bi-k-order finite elements cannot achieve, addressing the limitations in convergence properties of existing methods.", "method": "Bi-k-order finite volume element method on rectangular meshes with tensorial k-k-order orthogonality via dual mesh constraints, using asymmetric-enabled M-decompositions (AMD-Super and AMD-Ultra) for theoretical analysis.", "result": "Achieved one-order-higher superconvergence for derivatives and function values, and two-orders-higher ultraconvergence for derivatives under specific conditions (diagonal diffusion tensor, zero convection, FVE scheme with tensorial orthogonality).", "conclusion": "The developed structures provide significant convergence improvements not available in standard methods, with numerical experiments confirming the theoretical findings. The 2D derivative ultraconvergence is non-trivial and more complex than 1D extensions due to directional coupling."}}
{"id": "2510.10359", "pdf": "https://arxiv.org/pdf/2510.10359", "abs": "https://arxiv.org/abs/2510.10359", "authors": ["Giuseppe Di Fazio", "Rafayel Teymurazyan", "Jos\u00e9 Miguel Urbano"], "title": "Higher H\u00f6lder regularity for degenerate elliptic PDEs with data in Morrey spaces", "categories": ["math.AP", "35B65, 35J70, 35J92"], "comment": "12 pages", "summary": "We establish sharp local $C^{1,\\alpha}$-regularity for weak solutions to\ndegenerate elliptic equations of $p$-Laplacian type with data in Morrey spaces.\nThe proof relies on the Fefferman-Phong inequality and standard tools from\nregularity theory for nonlinear PDEs.", "AI": {"tldr": "Sharp local C^{1,\u03b1}-regularity for weak solutions to degenerate elliptic p-Laplacian equations with Morrey space data", "motivation": "To establish precise regularity results for degenerate elliptic equations with data in Morrey spaces, extending classical regularity theory", "method": "Uses Fefferman-Phong inequality and standard tools from nonlinear PDE regularity theory", "result": "Proves sharp local C^{1,\u03b1}-regularity for weak solutions", "conclusion": "Successfully establishes optimal regularity for p-Laplacian type equations with Morrey space data"}}
{"id": "2510.11187", "pdf": "https://arxiv.org/pdf/2510.11187", "abs": "https://arxiv.org/abs/2510.11187", "authors": ["Stephan Wulfinghoff"], "title": "Computational Crystal Plasticity Homogenization using Empirically Corrected Cluster Cubature (E3C) Hyper-Reduction", "categories": ["physics.comp-ph"], "comment": null, "summary": "The computational homogenization of elastoplastic polycrystals is a\nchallenging task due to the huge number of grains required, their complicated\ninteractions and due to the complexity of crystal plasticity models per se.\nDespite a few successes of reduced order models, mean field and simplified\nhomogenization approaches often remain the preferred choice. In this work, a\nrecently proposed hyper-reduction method (called E3C) for projection-based\nReduced Order Models (pROMs) is applied to the problem of computational\nhomogenization of geometrically linearly deforming elastoplastic polycrystals.\nThe main novelty lies in the identification of reduced modes (the 'E3C-modes'),\nwhich replace the strain modes of the reduced-order model, leading to a\nsignificantly smaller number of integration points. The peculiarity, which\ndistinguishes the method from more conventional hyper-reduction techniques, is\nthat the E3C integration points are not taken from the set of FE integration\npoints. Instead, they can be interpreted as generalized integration points in\nstrain space which are trained such as to satisfy an orthogonality condition,\nwhich ensures that the hyper-reduced model matches the equilibrium states and\nmacroscopic stresses of full-field model data as accurately as possible. In\naddition, the number of grains is reduced, preserving the main features of the\noriginal texture of the finite element model. Two macroscopic engineering parts\n(untextured and textured) are simulated, illustrating the performance of the\nmethod in three-dimensional two-scale applications involving hundreds of\nthousands macroscopic degrees of freedom and millions of grains with computing\ntimes in the order of hours (cumulated online and offline effort) on standard\nlaptop hardware.", "AI": {"tldr": "A hyper-reduction method (E3C) is applied to computational homogenization of elastoplastic polycrystals, using novel reduced modes that replace strain modes and significantly reduce integration points, enabling efficient two-scale simulations.", "motivation": "Computational homogenization of elastoplastic polycrystals is challenging due to the large number of grains, complex interactions, and crystal plasticity model complexity. Existing reduced order models have limitations, making mean field approaches preferred.", "method": "The E3C hyper-reduction method identifies reduced modes (E3C-modes) that replace strain modes in projection-based Reduced Order Models. These use generalized integration points in strain space trained to satisfy orthogonality conditions, matching full-field model equilibrium states and stresses. Grain count is reduced while preserving texture features.", "result": "The method successfully simulated two macroscopic engineering parts (untextured and textured) in three-dimensional two-scale applications with hundreds of thousands of macroscopic degrees of freedom and millions of grains. Computing times were in the order of hours on standard laptop hardware.", "conclusion": "The E3C hyper-reduction method enables efficient computational homogenization of elastoplastic polycrystals, achieving significant computational speedup while maintaining accuracy in complex multi-scale simulations."}}
{"id": "2510.10829", "pdf": "https://arxiv.org/pdf/2510.10829", "abs": "https://arxiv.org/abs/2510.10829", "authors": ["Juan Carlos Mu\u00f1oz Grajales", "Deissy Marcela Pizo"], "title": "Existence and numerical approximation of a one-dimensional Boussinesq system with variable coefficients on a finite interval", "categories": ["math.NA", "cs.NA", "math.AP"], "comment": null, "summary": "In this paper, we investigate the well-posedness of a nonlinear dispersive\nmodel with variable coefficients that describes the evolution of surface waves\npropagating through a one-dimensional shallow water channel of finite length\nwith irregular bottom topography. To complement the theoretical analysis, we\nutilize the numerical solver developed by the authors in \\cite{PizoMunoz} to\napproximate solutions of the model on a finite spatial interval, considering\nvarious parameter values and forms of the variable coefficients in the\nBoussinesq system under study. Additionally, we present preliminary numerical\nexperiments addressing an inverse problem: the reconstruction of the initial\nwave elevation and fluid velocity from measurements taken at a final time. This\nis achieved by formulating an optimization problem in which the initial\nconditions are estimated as minimizers of a functional that quantifies the\ndiscrepancy between the observed final state and the numerical solution evolved\nfrom a trial initial state.", "AI": {"tldr": "Study of well-posedness and numerical solutions for a nonlinear dispersive model describing surface waves in shallow water channels with irregular bottoms, including inverse problem analysis for initial condition reconstruction.", "motivation": "To understand the mathematical properties and practical applications of nonlinear dispersive models for surface wave propagation in shallow water channels with variable bottom topography.", "method": "Combined theoretical analysis of well-posedness with numerical simulations using a custom solver, and formulation of an optimization problem for inverse reconstruction of initial conditions from final state measurements.", "result": "Development of analytical framework for model well-posedness and numerical methodology for both forward simulation and inverse problem solving of initial wave conditions.", "conclusion": "The paper establishes theoretical foundations and provides numerical tools for analyzing nonlinear dispersive wave models in variable topography environments, with applications to both forward prediction and inverse reconstruction problems."}}
{"id": "2510.10363", "pdf": "https://arxiv.org/pdf/2510.10363", "abs": "https://arxiv.org/abs/2510.10363", "authors": ["Till Preuster", "Timo Reis", "Manuel Schaller"], "title": "Abstract second-order boundary control systems", "categories": ["math.AP"], "comment": null, "summary": "We consider abstract second order systems of the form $\\ddot{x}(t) + D\n\\dot{x}(t) + Sx(t)=0$, which are typically analyzed via the operator matrix\n$\\mathcal{A}=\\left[\\begin{smallmatrix}\n  0 & I \\\\ -S & -D\n  \\end{smallmatrix}\\right]$ governing the free dynamics of the corresponding\nfirst-order in time formulation. While previous work (e.g. on spectral\nproperties of) $\\mathcal{A}$ has focused on self-adjoint uniformly positive\n$S$, we consider the more general case which comprises the situation where\n$S^*$ is symmetric, i.e., $S^*\\subset S$. As we will show, this relaxation\nallows for a large freedom in view of boundary conditions. Our main\ncontribution is the construction of a boundary triplet for the operator\n$\\mathcal{A}$ and the definition of an associated boundary control system. We\nfully characterize the cases in which the latter is impedance resp. scattering\npassive in terms of the associated trace operators. Furthermore, based on a\nnon-standard factorization of $S$ we introduce an equivalence transform of\n$\\mathcal{A}$ that maps the abstract second-order system (e.g., $\\mathcal{A} =\n\\left[\\begin{smallmatrix}\n  0 & I \\\\ \\Delta & -D\n  \\end{smallmatrix}\\right]$ for the wave equation in position-momentum\nformulation) into widely-used alternative representation involving lower-order\nspatial derivatives on the jet space (i.e., $\\left[\\begin{smallmatrix}\n  0 & \\nabla \\\\ \\operatorname{div} & -D\n  \\end{smallmatrix}\\right]$ corresponding to the wave equation in\nstrain-momentum formulation). We illustrate the suggested approach on the\nexample of a $n$-dimensional wave equation and a Maxwell equation.", "AI": {"tldr": "This paper extends the analysis of second-order systems to non-self-adjoint operators, constructs boundary triplets and control systems, and provides equivalence transforms between different formulations.", "motivation": "Previous work focused on self-adjoint uniformly positive operators, but many physical systems require more general cases where S* is symmetric (S* \u2282 S), allowing greater freedom in boundary conditions.", "method": "Constructs boundary triplets for the operator matrix A, defines associated boundary control systems, characterizes impedance/scattering passivity, and introduces equivalence transforms via non-standard factorization of S.", "result": "Fully characterizes when boundary control systems are impedance or scattering passive in terms of trace operators, and provides transformations between position-momentum and strain-momentum formulations.", "conclusion": "The approach extends applicability to more general systems, demonstrated through wave equations and Maxwell equations, enabling analysis of systems with broader boundary conditions."}}
{"id": "2510.11562", "pdf": "https://arxiv.org/pdf/2510.11562", "abs": "https://arxiv.org/abs/2510.11562", "authors": ["Hubert J. Naguszewski", "Christopher D. Woodgate", "David Quigley"], "title": "Optimal parallelisation strategies for flat histogram Monte Carlo sampling", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "cond-mat.stat-mech", "physics.chem-ph"], "comment": null, "summary": "Flat histogram methods, such as Wang-Landau sampling, provide a means for\nhigh throughput calculation of phase diagrams of atomistic/lattice model\nsystems. Many parallelisation schemes with varying degrees of complexity have\nbeen proposed to accelerate such sampling simulations. In this study, several\nwidely used schemes are benchmarked - both in isolation and in combination - to\nestablish best practice. The schemes studied include energy domain\ndecomposition with both static sizing of energy sub-domains, as well as a\ndynamic sub-domain sizing scheme which we propose. We also assess the benefits\nboth of replica exchange and of including multiple random walkers per\nsub-domain, to determine which factors have the largest impact on parallel\nefficiency. Additionally, the influence of the choice of size of energy\nsub-domain overlap regions is discussed. As an illustrative test case, we\nimplement and apply the aforementioned strategies to a lattice-based model\ndescribing the internal energies of the AlTiCrMo refractory high-entropy\nsuperalloy, which is understood to crystallographically order into a B2 (CsCl)\nstructure with decreasing temperature. We find that - while all of the proposed\nstrategies confer a non-negligible speedup - parallelisation across energy\ndomains which are non-uniform in size offers the most appreciable performance\nimprovements. This work offers concrete recommendations for which\nparallelisation strategies should be prioritised to optimally accelerate\nflat-histogram Monte Carlo simulations.", "AI": {"tldr": "Benchmarking of parallelization schemes for flat histogram methods like Wang-Landau sampling, with focus on energy domain decomposition, replica exchange, and multiple walkers per sub-domain. A dynamic sub-domain sizing scheme is proposed and tested on a lattice model of AlTiCrMo alloy.", "motivation": "To establish best practices for parallelizing flat histogram methods by benchmarking various schemes to determine which factors have the largest impact on parallel efficiency.", "method": "Implemented and tested several parallelization schemes: energy domain decomposition with static and dynamic sub-domain sizing, replica exchange, multiple random walkers per sub-domain, and varying energy sub-domain overlap sizes. Applied to a lattice-based model of AlTiCrMo refractory high-entropy superalloy.", "result": "All proposed strategies provided speedup, but parallelization across energy domains with non-uniform (dynamic) sizing offered the most significant performance improvements.", "conclusion": "Concrete recommendations are provided for prioritizing parallelization strategies to optimally accelerate flat-histogram Monte Carlo simulations, with dynamic energy domain sizing being the most effective approach."}}
{"id": "2510.10877", "pdf": "https://arxiv.org/pdf/2510.10877", "abs": "https://arxiv.org/abs/2510.10877", "authors": ["Mridul Patel"], "title": "USA Tariffs Effect: Machine Learning Insights into the Stock Market", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "The imposition of tariffs by President Trump during his second term had\nfar-reaching consequences for global markets, including Australia. This study\ninvestigates how both the announcement and subsequent implementation of these\ntariffs, specifically on 02-Apr-2025, affected the Australian stock market,\nfocusing on the S\\&P/ASX 200 index over the period from 21-Jan-2025 to\n25-Jul-2025. To accurately capture the significance and behavior of market\nfluctuations, the exploratory data analysis (EDA) techniques are applied.\nFurthermore, the impact of tariffs on stock performance is evaluated using\nmachine learning-based regression models. A comparative assessment of these\nmodels is conducted to determine their predictive accuracy and robustness in\ncapturing tariff-related market responses.", "AI": {"tldr": "This study analyzes how Trump's second-term tariffs, announced and implemented on 02-Apr-2025, affected the Australian S&P/ASX 200 index from Jan-Jul 2025 using EDA and machine learning regression models.", "motivation": "To understand the impact of Trump's second-term tariff policies on global markets, specifically Australia's stock market, and assess market responses to both announcement and implementation phases.", "method": "Applied exploratory data analysis (EDA) techniques and machine learning-based regression models to evaluate stock performance, with comparative assessment of model predictive accuracy and robustness.", "result": "The study captured significant market fluctuations and tariff-related responses in the Australian stock market, with machine learning models demonstrating varying levels of predictive accuracy.", "conclusion": "Trump's second-term tariffs had measurable impacts on the Australian stock market, and machine learning regression models can effectively capture and predict tariff-related market responses."}}
{"id": "2510.10408", "pdf": "https://arxiv.org/pdf/2510.10408", "abs": "https://arxiv.org/abs/2510.10408", "authors": ["Yi-Hsuan Lin"], "title": "Monotonicity and local uniqueness for an isotropic nonlocal elliptic equation", "categories": ["math.AP"], "comment": "17 pages. All", "summary": "We extend monotonicity-based inversion methods to an inverse coefficient\nproblem for the isotropic nonlocal elliptic equation\n  \\[\n  (-\\nabla \\cdot \\sigma \\nabla)^s u = 0 \\quad \\text{in } \\Omega \\subset\n\\mathbb{R}^n,\n  \\]\n  where $0 < s < 1$, $n \\geq 3$, and $\\Omega$ is a bounded open set. We\nestablish a monotonicity relation between the leading coefficient $\\sigma$ and\nthe (partial) exterior Dirichlet-to-Neumann (DN) map. Our main result shows\nthat a monotonicity ordering of the coefficients implies a corresponding\nordering of the DN maps. Furthermore, we construct localized potentials for the\nnonlocal equation, which yield a local uniqueness result for the fractional\ninverse problem.", "AI": {"tldr": "The paper extends monotonicity-based inversion methods to an inverse coefficient problem for isotropic nonlocal elliptic equations, establishing a monotonicity relation between coefficients and Dirichlet-to-Neumann maps, and proving local uniqueness.", "motivation": "To develop inversion methods for nonlocal elliptic equations, specifically addressing the inverse coefficient problem for fractional Laplacian operators, which has applications in imaging and inverse problems.", "method": "Extends monotonicity-based inversion methods to nonlocal equations, establishes monotonicity relation between coefficients and DN maps, and constructs localized potentials for the nonlocal equation.", "result": "Shows that monotonicity ordering of coefficients implies corresponding ordering of DN maps, and obtains local uniqueness result for the fractional inverse problem.", "conclusion": "Monotonicity methods can be successfully extended to nonlocal elliptic equations, providing theoretical foundations for coefficient recovery in fractional inverse problems."}}
{"id": "2510.09641", "pdf": "https://arxiv.org/pdf/2510.09641", "abs": "https://arxiv.org/abs/2510.09641", "authors": ["Lei Wu"], "title": "Coherent Rayleigh-Brillouin scattering: influences of intermolecular potentials and chirp rates", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": null, "summary": "Chirped coherent Rayleigh-Brillouin scattering (CRBS) is a flow diagnostic\ntechnique that offers high signal-to-noise ratios and nanosecond temporal\nresolution. To extract information of dilute gas flow, experimental spectra\nmust be compared with theoretical predictions derived from the Boltzmann\nequation. In this work, we develop a MATLAB code that deterministically solves\nthe Boltzmann equation to compute CRBS spectra, enabling each line shape to be\nobtained in about one minute. We find that the CRBS spectrum is highly\nsensitive to the intermolecular potential, and that rapid chirping generates\nfine ripples around the Rayleigh peak along with spectral asymmetries.", "AI": {"tldr": "Developed MATLAB code to solve Boltzmann equation for chirped coherent Rayleigh-Brillouin scattering spectra computation, achieving ~1 minute per spectrum.", "motivation": "Chirped CRBS is a high SNR, nanosecond-resolution flow diagnostic technique requiring comparison with theoretical predictions from Boltzmann equation.", "method": "Created deterministic MATLAB code to solve Boltzmann equation for computing CRBS spectra.", "result": "CRBS spectrum is highly sensitive to intermolecular potential; rapid chirping generates fine ripples around Rayleigh peak and spectral asymmetries.", "conclusion": "Successfully developed efficient computational method for CRBS analysis with important findings about spectral sensitivity and chirping effects."}}
{"id": "2510.10879", "pdf": "https://arxiv.org/pdf/2510.10879", "abs": "https://arxiv.org/abs/2510.10879", "authors": ["Fei Xu"], "title": "Multilevel correction type of adaptive finite element method for Hartree-Fock equation", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This paper proposes an efficient algorithm for solving the Hartree--Fock\nequation combining a multilevel correction scheme with an adaptive refinement\ntechnique to improve computational efficiency. The algorithm integrates a\nmultilevel correction framework with an optimized implementation strategy.\nWithin this framework, a series of linearized boundary value problems are\nsolved, and their approximate solutions are corrected by solving small-scale\nHartree--Fock equations in low-dimensional correction spaces. The correction\nspace comprises a coarse space and the solution to the linearized boundary\nvalue problem, enabling high accuracy while preserving low-dimensional\ncharacteristics. The proposed algorithm efficiently addresses the inherent\ncomputational complexity of the Hartree--Fock equation. Innovative correction\nstrategies eliminate the need for direct computation of large-scale nonlinear\neigenvalue systems and dense matrix operations. Furthermore, optimization\ntechniques based on precomputations within the correction space render the\ntotal computational workload nearly independent of the number of\nself-consistent field iterations. This approach significantly accelerates the\nsolution process of the Hartree--Fock equation, effectively mitigating the\ntraditional exponential scaling demands on computational resources while\nmaintaining precision.", "AI": {"tldr": "Efficient algorithm combining multilevel correction with adaptive refinement to solve Hartree-Fock equation, avoiding large-scale nonlinear eigenvalue systems and dense matrix operations.", "motivation": "To address the computational complexity and exponential scaling demands of traditional Hartree-Fock equation solvers while maintaining accuracy.", "method": "Multilevel correction scheme with adaptive refinement, solving linearized boundary value problems and correcting solutions via small-scale Hartree-Fock equations in low-dimensional correction spaces.", "result": "Significantly accelerated solution process with computational workload nearly independent of self-consistent field iterations, effectively mitigating exponential scaling demands.", "conclusion": "The proposed algorithm efficiently solves Hartree-Fock equation with high accuracy while preserving low-dimensional characteristics and reducing computational complexity."}}
{"id": "2510.10488", "pdf": "https://arxiv.org/pdf/2510.10488", "abs": "https://arxiv.org/abs/2510.10488", "authors": ["Jeaheang Bang", "Changfeng Gui", "Hao Liu", "Yun Wang", "Chunjing Xie"], "title": "On the existence of self-similar solutions to the steady Navier-Stokes equations in high dimensions", "categories": ["math.AP"], "comment": null, "summary": "We prove that the steady incompressible Navier-Stokes equations with any\ngiven $(-3)$-homogeneous, locally Lipschitz external force on\n$\\mathbb{R}^n\\setminus\\{0\\}$, $4\\leq n\\leq 16$, have at least one\n$(-1)$-homogeneous solution which is scale-invariant and regular away from the\norigin. The global uniqueness of the self-similar solution is obtained as long\nas the external force is small. The key observation is to exploit a nice\nrelation between the radial component of the velocity and the total head\npressure under the self-similarity assumption. It plays an essential role in\nestablishing the energy estimates. If the external force has only the\nnonnegative radial component, we can prove the existence of $(-1)$-homogeneous\nsolutions for all $n\\geq 4$. The regularity of the solution follows from\nintegral estimates of the positive part of the total head pressure, which is\ndue to the maximum principle and a ``dimension-reduction\" effect arising from\nthe self-similarity.", "AI": {"tldr": "The paper proves existence of scale-invariant homogeneous solutions to steady Navier-Stokes equations with homogeneous external forces in dimensions 4-16, with global uniqueness for small forces.", "motivation": "To establish existence and uniqueness results for self-similar solutions to steady incompressible Navier-Stokes equations with homogeneous external forces, particularly focusing on higher dimensions.", "method": "Exploits relation between radial velocity component and total head pressure under self-similarity assumption; uses energy estimates, maximum principle, and dimension-reduction effects from self-similarity.", "result": "Proves existence of at least one (-1)-homogeneous solution for dimensions 4\u2264n\u226416 with any given (-3)-homogeneous force; global uniqueness for small forces; extends to all n\u22654 for nonnegative radial forces.", "conclusion": "The paper successfully establishes existence and uniqueness of scale-invariant solutions to Navier-Stokes equations with homogeneous external forces, leveraging key structural relationships and dimension-dependent effects."}}
{"id": "2510.09670", "pdf": "https://arxiv.org/pdf/2510.09670", "abs": "https://arxiv.org/abs/2510.09670", "authors": ["Xinlun Cheng", "Bingzhe Chen", "Joseph Choi", "Yen T. Nguyen", "Pradeep Seshadri", "Mayank Verma", "H. S. Udaykumar", "Stephen Baek"], "title": "A physics-aware deep learning model for shear band formation around collapsing pores in shocked reactive materials", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Modeling shock-to-detonation phenomena in energetic materials (EMs) requires\ncapturing complex physical processes such as strong shocks, rapid changes in\nmicrostructural morphology, and nonlinear dynamics of chemical reaction fronts.\nThese processes participate in energy localization at hotspots, which initiate\nchemical energy release leading to detonation. This study addresses the\nformation of hotspots in crystalline EMs subjected to weak-to-moderate shock\nloading, which, despite its critical relevance to the safe storage and handling\nof EMs, remains underexplored compared to the well-studied strong shock\nconditions. To overcome the computational challenges associated with direct\nnumerical simulations, we advance the Physics-Aware Recurrent Convolutional\nNeural Network (PARCv2), which has been shown to be capable of predicting\nstrong shock responses in EMs. We improved the architecture of PARCv2 to\nrapidly predict shear localizations and plastic heating, which play important\nroles in the weak-to-moderate shock regime. PARCv2 is benchmarked against two\nwidely used physics-informed models, namely, Fourier neural operator and neural\nordinary differential equation; we demonstrate its superior performance in\ncapturing the spatiotemporal dynamics of shear band formation. While all models\nexhibit certain failure modes, our findings underscore the importance of\ndomain-specific considerations in developing robust AI-accelerated simulation\ntools for reactive materials.", "AI": {"tldr": "The paper advances PARCv2, a physics-aware neural network, to model hotspot formation in energetic materials under weak-to-moderate shock loading, demonstrating superior performance in capturing shear band dynamics compared to other physics-informed models.", "motivation": "Modeling shock-to-detonation in energetic materials requires capturing complex physical processes like energy localization at hotspots. Weak-to-moderate shock loading conditions are critical for safe storage and handling but remain underexplored compared to strong shocks.", "method": "Improved the PARCv2 (Physics-Aware Recurrent Convolutional Neural Network) architecture to rapidly predict shear localizations and plastic heating. Benchmarked against Fourier neural operator and neural ordinary differential equation models.", "result": "PARCv2 demonstrated superior performance in capturing spatiotemporal dynamics of shear band formation compared to other physics-informed models. All models exhibited certain failure modes.", "conclusion": "The findings underscore the importance of domain-specific considerations in developing robust AI-accelerated simulation tools for reactive materials."}}
{"id": "2510.10894", "pdf": "https://arxiv.org/pdf/2510.10894", "abs": "https://arxiv.org/abs/2510.10894", "authors": ["Maria Vasilyeva", "James Brannick", "Ben S. Southworth"], "title": "Multiscale Graph Reduction for Heterogeneous and Anisotropic Discrete Diffusion Processes", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We present multiscale graph-based reduction algorithms for upscaling\nheterogeneous and anisotropic diffusion problems. The proposed coarsening\napproaches begin by constructing a partitioning of the computational domain\ninto a set of balanced local subdomains, resulting in a standard type of domain\ndecomposition. Given this initial decomposition, general coarsening techniques\nbased on spectral clustering are applied within each subgraph in order to\naccurately identify the key microscopic features of a given system. The\nspectral clustering algorithm is based on local generalized\neigen-decompositions applied to the signed graph Laplacian. The resulting\ncoarse-fine splittings are combined with two variants of energy-minimizing\nstrategies for constructing coarse bases for diffusion problems. The first is\nan unconstrained minimization formulation in which local harmonic extensions\nare applied column-wise to construct multi-vector preserving interpolation in\neach region, whereas the second approach is a variant of the constrained energy\nminimization formulations derived in the context of non-local multi-continua\nupscaling techniques. We apply the resulting upscaling algorithms to a variety\nof tests coming from the graph Laplacian, including diffusion in the perforated\ndomain, channelized media, highly anisotropic settings, and discrete pore\nnetwork models to demonstrate the potential and robustness of the proposed\ncoarsening approaches. We show numerically and theoretically that the proposed\napproaches lead to accurate coarse-scale models.", "AI": {"tldr": "Multiscale graph-based reduction algorithms for upscaling heterogeneous anisotropic diffusion problems using spectral clustering and energy-minimizing strategies.", "motivation": "To develop efficient coarsening approaches for complex diffusion problems in heterogeneous and anisotropic media, addressing challenges in accurately capturing microscopic features while maintaining computational efficiency.", "method": "Combines domain decomposition with spectral clustering using local generalized eigen-decompositions of signed graph Laplacian, followed by two energy-minimizing strategies: unconstrained minimization with local harmonic extensions and constrained energy minimization from non-local multi-continua upscaling.", "result": "The algorithms demonstrate robustness across various test cases including perforated domains, channelized media, anisotropic settings, and pore network models, producing accurate coarse-scale models.", "conclusion": "The proposed multiscale graph-based reduction approaches effectively handle complex diffusion problems and provide theoretically and numerically validated accurate coarse-scale representations."}}
{"id": "2510.10523", "pdf": "https://arxiv.org/pdf/2510.10523", "abs": "https://arxiv.org/abs/2510.10523", "authors": ["Ricardo Alonso", "Milana \u010coli\u0107"], "title": "Regularity Theory for the Space Homogeneous Polyatomic Boltzmann Flow", "categories": ["math.AP", "math-ph", "math.MP"], "comment": null, "summary": "In this paper, we study the polyatomic Boltzmann equation based on continuous\ninternal energy, focusing on physically relevant collision kernels of the hard\npotentials type with integrable angular part. We establish three main results:\nsmoothing effects of the gain collision operator, propagation of velocity and\ninternal energy first-order derivatives of solutions, and exponential decay\nestimates for singularities of the initial data. These results ultimately lead\nto a decomposition theorem, showing that any solution splits into a smooth part\nand a rapidly decaying rough component.", "AI": {"tldr": "Study of polyatomic Boltzmann equation with continuous internal energy, establishing smoothing effects, derivative propagation, and exponential decay estimates for singularities.", "motivation": "To analyze the mathematical properties of the polyatomic Boltzmann equation with physically relevant collision kernels, particularly focusing on smoothing and decay behaviors.", "method": "Analysis of the Boltzmann equation with continuous internal energy using hard potentials type collision kernels with integrable angular part.", "result": "Three main results: smoothing effects of gain collision operator, propagation of velocity/internal energy derivatives, and exponential decay of initial singularities.", "conclusion": "Solutions decompose into smooth and rapidly decaying rough components, providing comprehensive understanding of solution structure."}}
{"id": "2510.09756", "pdf": "https://arxiv.org/pdf/2510.09756", "abs": "https://arxiv.org/abs/2510.09756", "authors": ["Philip F. Hopkins", "Elias R. Most"], "title": "Time-Dilation Methods for Extreme Multiscale Timestepping Problems", "categories": ["astro-ph.IM", "astro-ph.GA", "astro-ph.HE", "astro-ph.SR", "physics.comp-ph"], "comment": "15 pages, 4 figures, 3 appendices. Submitted to the Open Journal of\n  Astrophysics. Comments welcome. Example implementation in the public GIZMO\n  code at: http://www.tapir.caltech.edu/~phopkins/Site/GIZMO.html", "summary": "Many astrophysical simulations involve extreme dynamic range of timescales\naround 'special points' in the domain (e.g. black holes, stars, planets, disks,\ngalaxies, shocks, mixing interfaces), where processes on small scales couple\nstrongly to those on large scales. Adaptive resolution, multi-physics, and\nhybrid numerical methods have enabled tremendous progress on the spatial,\nphysics, and numerical challenges involved. But often the limiter for following\nthe long timescales of global evolution is the extremely short numerical\ntimestep required in some subdomains (which leads to their dominating\nsimulation costs). Recently several approaches have been developed for tackling\nthis in problems where the short timescale solution is sampled and then\nprojected as an effective subgrid model over longer timescales (e.g. 'zooming\nin and out'). We generalize these to a family of models where time evolution is\nmodulated by a variable but continuous in space-and-time dilation/stretch\nfactor $a({\\bf x},\\,t)$. This extends previous well-studied approaches\n(including reduced-speed-of-light and binary orbital dynamics methods), and\nensures that the system comes to correct local steady-state solutions, and\nderive criteria that the dilation factor/timesteps/resolution must obey to\nensure good behavior. We present a variety of generalizations to different\nphysics or coupling scales. Compared to previous approaches, this method makes\nit possible to avoid imprinting arbitrary scales where there is no clear\nscale-separation, and couples well to Lagrangian or Eulerian methods. It is\nflexible and easily-implemented and we demonstrate its validity (and\nlimitations) in test problems. We discuss the relationship between these\nmethods and physical time dilation in GRMHD. We demonstrate how this can be\nused to obtain effective speedup factors exceeding $\\gtrsim 10^{4}$ in\nmultiphysics simulations.", "AI": {"tldr": "A method using continuous space-time dilation factors to handle extreme timescale ranges in astrophysical simulations, enabling speedups over 10^4 by modulating time evolution locally.", "motivation": "Astrophysical simulations face challenges with extreme dynamic range of timescales around special points (black holes, stars, etc.), where short numerical timesteps in subdomains dominate simulation costs and limit long-term evolution studies.", "method": "Generalizes previous approaches using a variable continuous space-time dilation/stretch factor a(x,t) to modulate time evolution, extending reduced-speed-of-light and binary orbital dynamics methods while ensuring correct local steady-state solutions.", "result": "The method avoids imprinting arbitrary scales without clear scale-separation, couples well with Lagrangian/Eulerian methods, and achieves effective speedup factors exceeding 10^4 in multiphysics simulations.", "conclusion": "This flexible, easily-implemented approach provides a generalized framework for handling extreme timescale ranges in astrophysical simulations while maintaining physical accuracy and enabling significant computational speedups."}}
{"id": "2510.10940", "pdf": "https://arxiv.org/pdf/2510.10940", "abs": "https://arxiv.org/abs/2510.10940", "authors": ["Dakang Cen", "Wenlong Zhang", "Zhidong Zhang"], "title": "An efficient iteration method to reconstruct the drift term from the final measurement", "categories": ["math.NA", "cs.NA", "math.AP", "35K10, 35R30, 65M32"], "comment": "16 pages", "summary": "This work investigates the inverse drift problem in the one-dimensional\nparabolic equation with the final time data. The authors construct an operator\nfirst, whose fixed points are the unknown drift, and then apply it to prove the\nuniqueness. The proof of uniqueness contains an iteration converging to the\ndrift, which inspires the numerical algorithm. To handle the ill-posedness of\nthe inverse problem, the authors add the mollification on the data first in the\niterative algorithm, and then provide some numerical results.", "AI": {"tldr": "The paper addresses the inverse drift problem in 1D parabolic equations using final time data, proving uniqueness via fixed-point iteration and developing a numerical algorithm with mollification to handle ill-posedness.", "motivation": "To solve the inverse drift problem in parabolic equations with final time data, which is inherently ill-posed and requires specialized mathematical approaches for uniqueness and numerical computation.", "method": "Construct an operator whose fixed points correspond to the unknown drift, prove uniqueness through iterative convergence, and develop a numerical algorithm with mollification to regularize the ill-posed problem.", "result": "The authors establish uniqueness of the drift solution and provide numerical results demonstrating the effectiveness of their iterative algorithm with mollification for handling the inverse problem's ill-posedness.", "conclusion": "The proposed fixed-point approach successfully addresses the inverse drift problem, providing both theoretical uniqueness guarantees and practical numerical solutions through regularization techniques."}}
{"id": "2510.10571", "pdf": "https://arxiv.org/pdf/2510.10571", "abs": "https://arxiv.org/abs/2510.10571", "authors": ["Chaohua Duan", "Hongyu Liu", "Qingle Meng", "Li Wang"], "title": "Determining nonlinear balance laws in product-type domains by a single local passive boundary observation", "categories": ["math.AP", "math-ph", "math.MP", "35R30, 35R35, 47H30"], "comment": "39 pages, 8 figures", "summary": "This paper introduces an operator-theoretic paradigm for solving inverse\nproblems in nonlinear balance laws, shifting the focus from identifying\nspecific functional forms to recovering the input-output actions of the\nassociated flux and source operators. It is established that a single local\npassive boundary observation suffices to uniquely determine realizations of\nthese operators for systems posed on product-type domains. This framework,\nwhich encompasses dynamical regimes, reveals a holographic-type principle where\nmacroscopic boundary data encodes microscopic dynamical information, with broad\nimplications for fluid dynamics and reaction-diffusion systems.", "AI": {"tldr": "Operator-theoretic approach for solving inverse problems in nonlinear balance laws using boundary observations to recover flux and source operators.", "motivation": "Shift focus from identifying specific functional forms to recovering input-output actions of flux and source operators in nonlinear balance laws.", "method": "Established that single local passive boundary observation suffices to uniquely determine realizations of flux and source operators on product-type domains.", "result": "Reveals holographic-type principle where macroscopic boundary data encodes microscopic dynamical information.", "conclusion": "Framework has broad implications for fluid dynamics and reaction-diffusion systems, enabling operator recovery from boundary measurements."}}
{"id": "2510.09768", "pdf": "https://arxiv.org/pdf/2510.09768", "abs": "https://arxiv.org/abs/2510.09768", "authors": ["Khang Ngo", "Siamak Ravanbakhsh"], "title": "Scaling Laws and Symmetry, Evidence from Neural Force Fields", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": "22 pages, 10 figures", "summary": "We present an empirical study in the geometric task of learning interatomic\npotentials, which shows equivariance matters even more at larger scales; we\nshow a clear power-law scaling behaviour with respect to data, parameters and\ncompute with ``architecture-dependent exponents''. In particular, we observe\nthat equivariant architectures, which leverage task symmetry, scale better than\nnon-equivariant models. Moreover, among equivariant architectures, higher-order\nrepresentations translate to better scaling exponents. Our analysis also\nsuggests that for compute-optimal training, the data and model sizes should\nscale in tandem regardless of the architecture. At a high level, these results\nsuggest that, contrary to common belief, we should not leave it to the model to\ndiscover fundamental inductive biases such as symmetry, especially as we scale,\nbecause they change the inherent difficulty of the task and its scaling laws.", "AI": {"tldr": "Equivariant architectures scale better than non-equivariant models in learning interatomic potentials, with higher-order representations showing superior scaling exponents. Compute-optimal training requires scaling data and model sizes together.", "motivation": "To demonstrate that equivariance matters more at larger scales and that fundamental inductive biases like symmetry should not be left for models to discover, especially as we scale, because they change task difficulty and scaling laws.", "method": "Empirical study in geometric task of learning interatomic potentials, analyzing scaling behavior with respect to data, parameters, and compute with architecture-dependent exponents.", "result": "Equivariant architectures scale better than non-equivariant models, with higher-order representations having better scaling exponents. Data and model sizes should scale together for compute-optimal training.", "conclusion": "Contrary to common belief, fundamental inductive biases like symmetry should not be left for models to discover when scaling, as they significantly impact task difficulty and scaling laws."}}
{"id": "2510.10984", "pdf": "https://arxiv.org/pdf/2510.10984", "abs": "https://arxiv.org/abs/2510.10984", "authors": ["Jingyi Wang", "Nai-Yuan Chiang", "Tucker Hartland", "J. Luc Peterson", "Jerome Solberg", "Cosmin G. Petra"], "title": "A Constrained Multi-Fidelity Bayesian Optimization Method", "categories": ["math.NA", "cs.NA", "stat.ML"], "comment": null, "summary": "Recently, multi-fidelity Bayesian optimization (MFBO) has been successfully\napplied to many engineering design optimization problems, where the cost of\nhigh-fidelity simulations and experiments can be prohibitive. However,\nchallenges remain for constrained optimization problems using the MFBO\nframework, particularly in efficiently identifying the feasible region defined\nby the constraints. In this paper, we propose a constrained multi-fidelity\nBayesian optimization (CMFBO) method with novel acquisition functions.\nSpecifically, we design efficient acquisition functions that 1) have\nanalytically closed-form expressions; 2) are straightforward to implement; and\n3) do not require feasible initial samples, an important feature often missing\nin commonly used acquisition functions such as expected constrained improvement\n(ECI). We demonstrate the effectiveness of our algorithms on synthetic test\nproblems using different combinations of acquisition functions. Then, we apply\nthe proposed method to a data-driven inertial confinement fusion (ICF) design\nproblem, and a high-current joint design problem using finite element\nsimulations with computational contact mechanics.", "AI": {"tldr": "Proposes a constrained multi-fidelity Bayesian optimization (CMFBO) method with novel acquisition functions that are analytical, easy to implement, and don't require feasible initial samples.", "motivation": "Address challenges in constrained optimization using multi-fidelity Bayesian optimization framework, particularly in efficiently identifying feasible regions defined by constraints.", "method": "Design novel acquisition functions with analytically closed-form expressions that are straightforward to implement and don't require feasible initial samples.", "result": "Demonstrated effectiveness on synthetic test problems and applied to data-driven inertial confinement fusion design and high-current joint design using finite element simulations.", "conclusion": "The proposed CMFBO method with new acquisition functions successfully addresses constrained optimization challenges in multi-fidelity Bayesian optimization applications."}}
{"id": "2510.10615", "pdf": "https://arxiv.org/pdf/2510.10615", "abs": "https://arxiv.org/abs/2510.10615", "authors": ["Hongjie Dong", "Haigang Li", "Yan Zhao"], "title": "Optimal gradient estimates for conductivity problems with imperfect low-conductivity interfaces", "categories": ["math.AP"], "comment": null, "summary": "This paper studies field concentration between two nearly touching conductors\nseparated by imperfect low-conductivity interfaces, modeled by Robin boundary\nconditions. It is known that for any sufficiently small interfacial bonding\nparameter $\\gamma > 0$, the gradient remains uniformly bounded with respect to\nthe separation distance $\\varepsilon$. In contrast, for the perfect bonding\ncase ($\\gamma = 0$, corresponding to the perfect conductivity problem), the\ngradient may blow up as $\\varepsilon \\to 0$ at a rate depending on the\ndimension. In this work, we establish optimal pointwise gradient estimates that\nexplicitly depend on both $\\gamma$ and $\\varepsilon$ in the regime where these\nparameters are small. These estimates provide a unified framework that\nencompasses both the previously known bounded case ($\\gamma > 0$) and the\nsingular blow-up scenario ($\\gamma = 0$), thus furnishing a complete and\ncontinuous characterization of the gradient behavior throughout the transition\nin $\\gamma$. The key technical achievement is the derivation of new regularity\nresults for elliptic equations as $\\gamma\\to0$, along with a case dichotomy\nbased on the relative sizes of $\\gamma$ and a distance function $\\delta(x')$.\nOur results hold for strictly relatively convex conductors in all dimensions $n\n\\geq 2$.", "AI": {"tldr": "Optimal gradient estimates for field concentration between nearly touching conductors with imperfect interfaces, unifying bounded (\u03b3>0) and singular blow-up (\u03b3=0) cases.", "motivation": "To understand how field gradients behave between nearly touching conductors with imperfect interfaces, bridging the gap between bounded gradients for \u03b3>0 and singular blow-up for \u03b3=0.", "method": "Derived new regularity results for elliptic equations as \u03b3\u21920, established pointwise gradient estimates depending on both \u03b3 and \u03b5, and developed case dichotomy based on relative sizes of \u03b3 and distance function \u03b4(x').", "result": "Obtained optimal pointwise gradient estimates that explicitly depend on \u03b3 and \u03b5, providing continuous characterization of gradient behavior throughout the \u03b3 transition for strictly relatively convex conductors in all dimensions n\u22652.", "conclusion": "The work provides a unified framework that completely characterizes gradient behavior between nearly touching conductors, covering both bounded and singular cases through explicit dependence on interfacial bonding parameter \u03b3 and separation distance \u03b5."}}
{"id": "2510.09861", "pdf": "https://arxiv.org/pdf/2510.09861", "abs": "https://arxiv.org/abs/2510.09861", "authors": ["Jonas B\u00f6hm", "Aur\u00e9lie Champagne"], "title": "Predicting Crystal Structures and Ionic Conductivity in Li$_{3}$YCl$_{6-x}$Br$_{x}$ Halide Solid Electrolytes Using a Fine-Tuned Machine Learning Interatomic Potential", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "20 pages, 6 figures", "summary": "This work demonstrates the effectiveness of fine-tuning the CHGNet universal\nmachine learning interatomic potential (uMLIP) to investigate ionic transport\nmechanisms in ternary halide solid electrolytes of the\nLi$_{3}$YCl$_{6-x}$Br$_{x}$ family (x = 0 to 6), which are promising candidates\nfor solid-state battery applications. We present a strategy for generating\nordered structural models from experimentally derived disordered\nLi$_{3}$YCl$_{6}$ (LYC) and Li$_{3}$YBr$_{6}$ (LYB) structures. These serve as\ninitial configurations for an iterative fine-tuning workflow that couples\nmolecular dynamics (MD) simulations with static density functional theory (DFT)\ncalculations. The fine-tuning process and the resulting improvements in\npredictive accuracy are benchmarked across energy predictions, structure\noptimizations, and diffusion coefficient calculations. Finally, we analyze the\ninfluence of composition (varied x) on the predicted ionic conductivity in\nLi$_{3}$YCl$_{6-x}$Br$_{x}$, demonstrating the robustness of our approach for\nmodeling transport properties in complex solid electrolytes.", "AI": {"tldr": "Fine-tuning CHGNet ML potential for Li3YCl6-xBrx solid electrolytes to study ionic transport mechanisms using MD simulations and DFT calculations.", "motivation": "To investigate ionic transport in ternary halide solid electrolytes for solid-state battery applications, particularly the Li3YCl6-xBrx family.", "method": "Generated ordered structural models from experimental disordered structures, then used iterative fine-tuning workflow combining molecular dynamics simulations with static DFT calculations.", "result": "Improved predictive accuracy in energy predictions, structure optimizations, and diffusion coefficient calculations; analyzed composition effects on ionic conductivity.", "conclusion": "The approach is robust for modeling transport properties in complex solid electrolytes, demonstrating effectiveness of fine-tuning universal ML potentials."}}
{"id": "2510.11023", "pdf": "https://arxiv.org/pdf/2510.11023", "abs": "https://arxiv.org/abs/2510.11023", "authors": ["Josefa Caballero", "\u0141ukasz P\u0142ociniczak", "Kishin Sadarangani"], "title": "Parareal in time and spectral in space fast L1 quasilinear subdiffusion solver", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We consider the initial-boundary value problem for a quasilinear\ntime-fractional diffusion equation, and develop a fully discrete solver\ncombining the parareal algorithm in time with a L1 finite-difference\napproximation of the Caputo derivative and a spectral Galerkin discretization\nin space. Our main contribution is the first rigorous convergence proof for the\nparareal-L1 scheme in this nonlinear subdiffusive setting. By constructing\nsuitable energy norms and exploiting the orthogonality of the spectral basis,\nwe establish that the parareal iterations converge exactly to the fully serial\nL1-spectral solution in a finite number of steps, with rates independent of the\nfractional exponent. The spectral spatial discretization yields exponential\naccuracy in space, while the parareal structure induces a clock speedup\nproportional to the number of processors, making the overall method highly\nefficient. Numerical experiments for both subdiffusive and classical diffusion\nproblems confirm our theoretical estimates and demonstrate up to an order of\nmagnitude reduction in computational time compared to the conventional\nsequential solver. We observe that the speedup of the parareal method increases\nlinearly with the fine integrator degrees of freedom.", "AI": {"tldr": "A fully discrete solver combining parareal algorithm with L1 finite-difference for Caputo derivative and spectral Galerkin discretization for quasilinear time-fractional diffusion equations, with rigorous convergence proof and demonstrated computational speedup.", "motivation": "To develop an efficient parallel solver for quasilinear time-fractional diffusion equations that combines temporal parallelization with high-order spatial discretization, addressing the computational challenges of fractional PDEs.", "method": "Combines parareal algorithm in time with L1 finite-difference approximation of Caputo derivative and spectral Galerkin discretization in space. Uses energy norms and spectral basis orthogonality for convergence analysis.", "result": "Parareal iterations converge exactly to fully serial L1-spectral solution in finite steps, with rates independent of fractional exponent. Spectral discretization provides exponential spatial accuracy, while parareal achieves clock speedup proportional to processors. Numerical experiments show up to order-of-magnitude computational time reduction.", "conclusion": "The proposed parareal-L1-spectral method is highly efficient for solving quasilinear time-fractional diffusion equations, offering rigorous convergence guarantees, exponential spatial accuracy, and significant computational speedup through parallelization."}}
{"id": "2510.10704", "pdf": "https://arxiv.org/pdf/2510.10704", "abs": "https://arxiv.org/abs/2510.10704", "authors": ["Marco Inversi"], "title": "Fine dissipative properties of Euler solutions with measure first derivatives", "categories": ["math.AP", "35Q31, 35D30, 26A45"], "comment": null, "summary": "We study fine properties of bounded weak solutions to the incompressible\nEuler equations whose first derivatives, or only some combinations of them, are\nRadon measures. As consequences we obtain elementary proofs of the local energy\nconservation for solutions in BV and BD, without relying on the freedom in\nchoosing the convolution kernel appearing in the approximation of the\ndissipation. The argument heavily exploits the form of the Euler nonlinearity\nand it does not apply to the linear transport equations, where the\nrenormalization property for BD vector fields is an open problem. The methods\nalso yields to nontrivial conclusions when only the vorticity is assumed to be\na measure.", "AI": {"tldr": "Analysis of bounded weak solutions to incompressible Euler equations with Radon measure derivatives, providing elementary proofs of local energy conservation for BV and BD solutions.", "motivation": "To study fine properties of bounded weak solutions to Euler equations where first derivatives or their combinations are Radon measures, and to obtain simpler proofs of energy conservation without relying on convolution kernel choices.", "method": "Exploits the specific form of Euler nonlinearity and analyzes solutions where derivatives are Radon measures, particularly focusing on BV and BD vector fields and cases where only vorticity is a measure.", "result": "Obtained elementary proofs of local energy conservation for BV and BD solutions, and derived nontrivial conclusions when only vorticity is assumed to be a measure.", "conclusion": "The method successfully provides simplified proofs of energy conservation for Euler equations but does not apply to linear transport equations, where renormalization for BD vector fields remains an open problem."}}
{"id": "2510.10070", "pdf": "https://arxiv.org/pdf/2510.10070", "abs": "https://arxiv.org/abs/2510.10070", "authors": ["S. Rendon Restrepo", "O. Gressel"], "title": "An efficient spectral Poisson solver for the nirvana-III code: the shearing-box case with vertical vacuum boundary conditions", "categories": ["astro-ph.IM", "math-ph", "math.MP", "physics.comp-ph"], "comment": null, "summary": "The stability of a differentially rotating fluid subject to its own gravity\nis a problem with applications across wide areas of astrophysics--from\nprotoplanetary discs (PPDs) to entire galaxies. The shearing box formalism\noffers a conceptually simple framework for studying differential rotation in\nthe local approximation. Aimed at self-gravitating, and importantly, vertically\nstratified PPDs, we develop two novel methods for solving Poisson's equation in\nthe framework of the shearing box with vertical vacuum boundary conditions\n(BCs). Both approaches naturally make use of multi-dimensional fast Fourier\ntransforms for computational efficiency. While the first one exploits the\nlinearity properties of the Poisson equation, the second, which is slightly\nmore accurate, consists of finding the adequate discrete Green's function (in\nFourier space) adapted to the problem at hand. To this end, we have revisited\nthe method proposed by Vico et al. (2016) and have derived an analytical\nGreen's function satisfying the shear-periodic BCs in the plane as well as\nvacuum BCs, vertically. Our spectral method demonstrates excellent accuracy,\neven with a modest number of grid points, and exhibits third-order convergence.\nIt has been implemented in the NIRVANA-III code, where it exhibits good\nscalability up to 4096 CPU cores, consuming less than 6% of the total runtime.\nThis was achieved through the use of P3DFFT, a fast Fourier Transform library\nthat employs pencil decomposition, overcoming the scalability limitations\ninherent in libraries using slab decomposition. We have introduced two novel\nspectral Poisson solvers that guarantees high accuracy, performance, and\nintrinsically support vertical vacuum boundary conditions in the shearing-box\nframework. Our solvers enable high-resolution local studies involving\nself-gravity, such as MHD simulations of gravito-turbulence or gravitational\nfragmentation.", "AI": {"tldr": "Developed two novel spectral methods for solving Poisson's equation in self-gravitating, vertically stratified protoplanetary discs using shearing box formalism with vertical vacuum boundary conditions.", "motivation": "To study differential rotation and self-gravity in astrophysical systems like protoplanetary discs and galaxies, requiring accurate Poisson solvers in shearing box framework with proper boundary conditions.", "method": "Two spectral approaches using multi-dimensional FFT: one exploiting linearity of Poisson equation, and another using analytical Green's function satisfying shear-periodic and vacuum boundary conditions. Implemented in NIRVANA-III code with P3DFFT library for scalability.", "result": "Methods show excellent accuracy with modest grid points, third-order convergence, good scalability up to 4096 CPU cores, consuming <6% total runtime. Overcame scalability limitations of slab decomposition.", "conclusion": "Introduced two high-performance spectral Poisson solvers that enable high-resolution local studies of self-gravity in astrophysical systems, supporting vertical vacuum boundary conditions in shearing-box framework."}}
{"id": "2510.11082", "pdf": "https://arxiv.org/pdf/2510.11082", "abs": "https://arxiv.org/abs/2510.11082", "authors": ["Khaled Hariz", "Sina Ober-Bl\u00f6baum", "Fernando Jimenez"], "title": "On Runge-Kutta convolution quadrature based fractional variational integrators", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Lagrangian systems subject to fractional damping can be incorporated into a\nvariational formalism. The construction can be made by doubling the state\nvariables and introducing fractional derivatives \\cite{JiOb2}. The main\nobjective of this paper is to use the Runge-Kutta convolution quadrature (RKCQ)\nmethod for approximating fractional derivatives, combined with higher order\nGalerkin methods in order to derive fractional variational integrators (FVIs).\nWe are specially interested in the CQ based on Lobatto IIIC. Preservation\nproperties such as energy decay as well as convergence properties are\ninvestigated numerically and proved for 2nd order schemes. The presented\nschemes reach 2nd, 4th and 6th accuracy order. A brief discussion on the\nmidpoint fractional integrator is also included.", "AI": {"tldr": "This paper develops fractional variational integrators (FVIs) using Runge-Kutta convolution quadrature (RKCQ) combined with higher-order Galerkin methods, achieving 2nd, 4th, and 6th order accuracy.", "motivation": "To incorporate Lagrangian systems with fractional damping into variational formalism and develop efficient numerical schemes for such systems.", "method": "Uses Runge-Kutta convolution quadrature (RKCQ) method for approximating fractional derivatives, combined with higher-order Galerkin methods, with special focus on CQ based on Lobatto IIIC.", "result": "Developed FVIs with 2nd, 4th, and 6th order accuracy. Proved energy decay preservation and convergence properties for 2nd order schemes. Included discussion on midpoint fractional integrator.", "conclusion": "The presented schemes successfully achieve high-order accuracy while preserving important physical properties like energy decay, making them suitable for simulating Lagrangian systems with fractional damping."}}
{"id": "2510.10897", "pdf": "https://arxiv.org/pdf/2510.10897", "abs": "https://arxiv.org/abs/2510.10897", "authors": ["Benjamin Anwasia", "Diogo Ars\u00e9nio"], "title": "Hydrodynamics of degenerate Fermi gases on spherical Fermi surfaces", "categories": ["math.AP", "cond-mat.mes-hall", "cond-mat.quant-gas", "math-ph", "math.MP"], "comment": null, "summary": "We consider the description of a Fermi gas of free electrons given by the\nBoltzmann--Fermi--Dirac equation, and aim at providing a precise mathematical\nunderstanding of the Fermi ground state and its first-order approximation of\nexcited states on the Fermi sphere.\n  In order to achieve that, using the framework of hydrodynamic limits in\ncollisional kinetic theory, we identify the low-temperature regimes in which\ncharge-density fluctuations concentrate on the Fermi sphere. In three spatial\ndimensions or higher, we also characterize the thermodynamic equilibra and\nenergy spectra of fluctuations. This allows us to derive the macroscopic\nhydrodynamic equations describing how charge densities flow and propagate in\nmetals, thereby providing a precise description of plasma oscillations in\nconductors. The two-dimensional case is fundamentally different and is handled\nin a companion article.\n  Remarkably, our results establish that excited electrons and their energy can\nbe distributed on the Fermi sphere anisotropically, which deviates from the\ncommon intuitive assumption that electrons and their energy should be\ndistributed uniformly in all directions.\n  The hydrodynamic regimes featured in this work are akin to the acoustic limit\nof the classical Boltzmann equation. However, we emphasize that our derivation\nholds for arbitrarily fast rates of convergence of the Knudsen number, which\nsignificantly extends the applicability of the known proofs of the classical\nacoustic limit. This suggest that low-temperature limits of Fermi gases provide\na promising avenue of research toward a complete understanding of the\ncompressible Euler limit.", "AI": {"tldr": "This paper analyzes Fermi gas of free electrons using Boltzmann-Fermi-Dirac equation, focusing on Fermi ground state and excited states on the Fermi sphere. It identifies low-temperature regimes where charge-density fluctuations concentrate on the Fermi sphere and derives macroscopic hydrodynamic equations for plasma oscillations in metals.", "motivation": "To provide precise mathematical understanding of Fermi ground state and its first-order approximation of excited states on the Fermi sphere, and to understand how charge densities flow and propagate in metals through plasma oscillations.", "method": "Using hydrodynamic limits in collisional kinetic theory framework to identify low-temperature regimes where charge-density fluctuations concentrate on the Fermi sphere. Characterizes thermodynamic equilibria and energy spectra of fluctuations in three dimensions or higher.", "result": "Establishes that excited electrons and their energy can be distributed anisotropically on the Fermi sphere, contrary to common assumption of uniform distribution. Derives macroscopic hydrodynamic equations describing charge density flow and plasma oscillations in conductors.", "conclusion": "The work extends applicability of classical acoustic limit proofs by allowing arbitrarily fast convergence rates of Knudsen number. Suggests low-temperature limits of Fermi gases provide promising research avenue toward complete understanding of compressible Euler limit."}}
{"id": "2510.11152", "pdf": "https://arxiv.org/pdf/2510.11152", "abs": "https://arxiv.org/abs/2510.11152", "authors": ["Jiale Meng", "Shuqi Tang", "Steven M. Wise", "Zhenlin Guo"], "title": "A GPU-Accelerated Matrix-Free FAS Multigrid Solver for Navier-Stokes Equations with Memory-Efficient Implementations", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We develop a matrix-free Full Approximation Storage (FAS) multigrid solver\nbased on staggered finite differences and implemented on GPU in MATLAB. To\nenhance performance, intermediate variables are reused, and an X-shape\nMulti-Color Gauss-Seidel (X-MCGS) smoother is introduced, which eliminates\nconditional branching by partitioning the grid into four submatrices.\nRestriction and prolongation operators are also GPU-accelerated. Convergence\ntests verify robustness and accuracy, while benchmarks show substantial\nspeedups: for the 2D heat equation on an $8192^2$ grid, the RTX~4090 achieves\n$61\\times$ over a single-core CPU, and in 3D at $512^3$, $46\\times$. A\nmemory-efficient implementation of first- and second-order projection schemes\nreduces GPU-resident variables from 12/15 to 8, lowering memory footprint and\nimproving performance by 20--30%, enabling $512^3$ Navier-Stokes simulations on\na single GPU. Grain growth on a $512^2$ grid accommodates up to $q=1189$ (2D)\nand $q=123$ (3D) orientations, reproducing expected scaling laws. Coupled with\nCahn-Hilliard equations, air-water two-bubble coalescence is simulated on a\n$256\\times 256\\times 1024$ grid, agreeing with experimental observations.", "AI": {"tldr": "A GPU-accelerated matrix-free multigrid solver using staggered finite differences with optimized memory usage and X-shape Multi-Color Gauss-Seidel smoother, achieving significant speedups (61\u00d7 in 2D, 46\u00d7 in 3D) and enabling large-scale simulations on single GPUs.", "motivation": "To develop efficient GPU-based multigrid solvers for large-scale computational problems by optimizing memory usage and eliminating conditional branching, enabling complex simulations like Navier-Stokes and phase-field models on single GPUs.", "method": "Matrix-free Full Approximation Storage (FAS) multigrid with staggered finite differences, GPU acceleration in MATLAB, X-shape Multi-Color Gauss-Seidel smoother that partitions grid into four submatrices, memory-efficient projection schemes reducing variables from 12/15 to 8.", "result": "Achieved 61\u00d7 speedup for 2D heat equation on 8192\u00b2 grid and 46\u00d7 for 3D at 512\u00b3; reduced memory footprint by 20-30%; enabled 512\u00b3 Navier-Stokes simulations on single GPU; reproduced grain growth scaling laws and simulated air-water bubble coalescence matching experiments.", "conclusion": "The GPU-accelerated multigrid solver with optimized memory and X-MCGS smoother provides substantial performance improvements, making large-scale computational fluid dynamics and phase-field simulations feasible on consumer-grade GPUs."}}
{"id": "2510.11377", "pdf": "https://arxiv.org/pdf/2510.11377", "abs": "https://arxiv.org/abs/2510.11377", "authors": ["Kotaro Motegi"], "title": "$L^2$ normal velocity implies strong solution for graphical Brakke flows", "categories": ["math.AP", "math.DG", "53E10 (Primary) 35B65 (Secondary)"], "comment": "10 pages", "summary": "We prove that if a one-parameter family of varifolds has an $L^2$ normal\nvelocity $v$ in the sense of Brakke, and if the family is represented as the\ngraph of a continuous function $f$ with continuous spatial derivative $\\nabla\nf$, then $f$ has weak derivatives $\\partial_t f, \\nabla^2 f \\in L^2$, and $v$\ncoincides with the usual normal velocity of the graph. Moreover, by combining\nthis result with parabolic regularity theory, we show that graphical Brakke\nflows with forcing term in $L^{p,q}$ and $C^{0,\\alpha}$ are strong and\nclassical solutions to the forced mean curvature flow equation, respectively.", "AI": {"tldr": "The paper proves that Brakke flows represented as graphs of continuous functions with continuous spatial derivatives are actually strong solutions to mean curvature flow, with the Brakke normal velocity coinciding with classical normal velocity.", "motivation": "To establish the connection between weak solutions (Brakke flows) and classical solutions for mean curvature flow, particularly for graphical flows with sufficient regularity.", "method": "The authors prove that if a one-parameter family of varifolds has L\u00b2 normal velocity in Brakke's sense and is represented as a graph with continuous spatial derivative, then the function has weak derivatives in L\u00b2. They combine this with parabolic regularity theory.", "result": "Graphical Brakke flows with forcing terms in L^{p,q} and C^{0,\u03b1} are shown to be strong and classical solutions to the forced mean curvature flow equation, respectively.", "conclusion": "The paper establishes that under appropriate regularity conditions, Brakke flows coincide with classical mean curvature flow solutions, bridging the gap between weak and classical formulations."}}
{"id": "2510.10326", "pdf": "https://arxiv.org/pdf/2510.10326", "abs": "https://arxiv.org/abs/2510.10326", "authors": ["Onurcan Kaya", "Qiushi Deng", "Thomas Souvignet", "Catherine Marichy", "Catherine Journet", "Ivan Cole", "Stephan Roche"], "title": "Atomic-Scale Origins of Oxidation Resistance in Amorphous Boron Nitride", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "29 pages, 8 figures", "summary": "Amorphous boron nitride (\\textrm{$\\alpha$}-BN) is a promising ultrathin\nbarrier for nanoelectronics, yet the atomistic mechanisms governing its\nchemical stability remain poorly understood. Here, we investigate the\nstructure-property relationship that dictates the oxidation of\n\\textrm{$\\alpha$}-BN using a combination of machine-learning molecular dynamics\nsimulations and angle-resolved X-ray photoelectron spectroscopy. The\nsimulations reveal that the film structure, controlled by synthesis conditions,\nis the critical factor determining oxidation resistance. Dense, chemically\nordered networks with a high fraction of B-N bonds effectively resist oxidation\nby confining it to the surface, whereas porous, defect-rich structures with\nabundant homonuclear B-B and N-N bonds permit oxygen penetration and undergo\nextensive bulk degradation. These computational findings are consistent with\nexperimental trends observed in \\textrm{$\\alpha$}-BN films grown by chemical\nvapour deposition. XPS analysis shows that a film grown at a higher temperature\ndevelops a more ordered structure with a B/N ratio nearer to stoichiometric and\nexhibits superior resistance to surface oxidation compared to its more\ndefective, lower-temperature counterpart. Together, these results demonstrate\nthat the oxidation resistance of \\textrm{$\\alpha$}-BN is a tunable property\ndirectly linked to its atomic-scale morphology, providing a clear framework for\nengineering chemically robust dielectric barriers for future nanoelectronic\napplications.", "AI": {"tldr": "The oxidation resistance of amorphous boron nitride (\u03b1-BN) is determined by its atomic-scale structure, with dense, ordered networks resisting oxidation while porous, defective structures undergo bulk degradation.", "motivation": "Amorphous boron nitride is promising for nanoelectronics but its chemical stability mechanisms are poorly understood, particularly how structure affects oxidation resistance.", "method": "Combined machine-learning molecular dynamics simulations and angle-resolved X-ray photoelectron spectroscopy (XPS) to study structure-property relationships in \u03b1-BN oxidation.", "result": "Dense, chemically ordered \u03b1-BN networks with high B-N bond fraction confine oxidation to surfaces, while porous structures with homonuclear B-B/N-N bonds allow oxygen penetration and bulk degradation. Higher-temperature grown films show more ordered structure and superior oxidation resistance.", "conclusion": "Oxidation resistance of \u03b1-BN is tunable through atomic-scale morphology control, providing a framework for engineering chemically robust dielectric barriers for nanoelectronics."}}
{"id": "2510.11237", "pdf": "https://arxiv.org/pdf/2510.11237", "abs": "https://arxiv.org/abs/2510.11237", "authors": ["Malena Sabat\u00e9 Landman", "Yuji Nakatsukasa"], "title": "Randomized flexible Krylov methods for $\\ell_p$ regularization", "categories": ["math.NA", "cs.NA", "65F22, 65K10, 65F10, 68W20"], "comment": null, "summary": "The computation of sparse solutions of large-scale linear discrete ill-posed\nproblems remains a computationally demanding task. A powerful framework in this\ncontext is the use of iteratively reweighted schemes, which are based on\nconstructing a sequence of quadratic tangent majorants of the $\\ell_2$-$\\ell_1$\nregularization functional (with additional smoothing to ensure\ndifferentiability at the origin), and solving them successively. Recently,\nflexible Krylov-Tikhonov methods have been used to partially solve each problem\nin the sequence efficiently. However, in order to guarantee convergence, the\ncomplexity of the algorithm at each iteration increases with respect to more\ntraditional methods. We propose a randomized flexible Krylov method to\nalleviate the increase of complexity, which leverages the adaptability of the\nflexible Krylov subspaces with the efficiency of `sketch-and-solve' methods. A\npossible caveat of the mentioned methods is their memory requirements. In this\ncase, one needs to rely instead on inner-outer schemes. In these scenarios, we\npropose a `sketch-to-precondition' method to speed up the convergence of each\nof the subproblems in the sequence. The performance of these algorithms is\nshown through a variety of numerical examples.", "AI": {"tldr": "Proposes randomized flexible Krylov methods and sketch-to-precondition techniques to reduce computational complexity in solving large-scale sparse linear ill-posed problems using iteratively reweighted schemes.", "motivation": "Existing flexible Krylov-Tikhonov methods for sparse solutions of large-scale linear ill-posed problems increase computational complexity at each iteration, and memory requirements can be prohibitive for inner-outer schemes.", "method": "Uses randomized flexible Krylov methods combining flexible Krylov subspaces with sketch-and-solve efficiency, and sketch-to-precondition techniques to accelerate convergence in memory-constrained scenarios.", "result": "The algorithms demonstrate improved performance through various numerical examples, showing reduced computational complexity while maintaining effectiveness.", "conclusion": "The proposed randomized methods effectively alleviate computational burden in solving large-scale sparse ill-posed problems, offering practical alternatives to traditional approaches."}}
{"id": "2510.11383", "pdf": "https://arxiv.org/pdf/2510.11383", "abs": "https://arxiv.org/abs/2510.11383", "authors": ["Marcel Zodji"], "title": "Global-in-time Discontinuous Solutions for the Two-Phase Model of Compressible Fluids with Density-Dependent Viscosity", "categories": ["math.AP", "76T10, 76N10, 35Q30, 35Q35"], "comment": "All comments are welcome", "summary": "We are concerned with a model describing the motion of two compressible,\nimmiscible fluids with density-dependent viscosity in the whole $\\mathbb R^3$.\nThe phases of the flow may have different pressure and viscosity laws and are\nseparated by a sharp interface, across which the (total) density is\ndiscontinuous. Our goal is to study the persistence of the regularity of this\nsharp interface over time. More precisely, the dynamics of the flow are\ngoverned by three coupled equations: two hyperbolic equations (for the volume\nfraction of one phase and for the density) and a parabolic equation for the\nvelocity field. We assume that, at the initial time, the density is\n$\\alpha$-H\\\"older continuous on both sides of a $\\mathscr C^{1+\\alpha}$-regular\nsurface across which it may be discontinuous. We prove the existence and\nuniqueness of a global-in-time weak solution in an intermediate regularity\nclass that ensures the persistence of the piecewise H\\\"older regularity of the\ndensity and the $\\mathscr C^{1+\\alpha}$ regularity of the sharp interface.", "AI": {"tldr": "Global existence and uniqueness of weak solutions for two compressible immiscible fluids with density-dependent viscosity, preserving the sharp interface regularity over time.", "motivation": "To study the persistence of regularity of sharp interfaces between two compressible immiscible fluids with different pressure and viscosity laws, where density is discontinuous across the interface.", "method": "Model described by three coupled equations: two hyperbolic equations (for volume fraction and density) and one parabolic equation for velocity. Initial density is \u03b1-H\u00f6lder continuous on both sides of a C\u00b9\u207a\u03b1-regular surface.", "result": "Proved existence and uniqueness of global-in-time weak solutions in an intermediate regularity class that preserves piecewise H\u00f6lder regularity of density and C\u00b9\u207a\u03b1 regularity of the sharp interface.", "conclusion": "The sharp interface between two compressible immiscible fluids with density-dependent viscosity maintains its regularity over time, with global weak solutions existing and being unique."}}
{"id": "2510.10345", "pdf": "https://arxiv.org/pdf/2510.10345", "abs": "https://arxiv.org/abs/2510.10345", "authors": ["Elijah Pelofske"], "title": "Depth One Quantum Alternating Operator Ansatz as an Approximate Gibbs Distribution Sampler", "categories": ["quant-ph", "cond-mat.stat-mech", "physics.comp-ph"], "comment": null, "summary": "This study numerically investigates the thermal sampling properties of QAOA,\nthe Quantum Alternating Operator Ansatz which was generalized from the original\nQuantum Approximate Optimization Algorithm. Specifically, the ability of QAOA\nto sample from the Gibbs distribution, equivalently the Boltzmann distribution,\ndefined by a classical Ising model, specifically a fully connected disordered\nspin glass (Sherrington-Kirkpatrick) model. We focus on two different QAOA\nmixers; the standard transverse field X mixer, and the Grover mixer. At a QAOA\ndepth of one we examine, for a single full QAOA parameter search space period,\nthe energy landscape, the Shannon entropy landscape of the QAOA probability\ndistribution, and the tradeoff between Boltzmann distribution sampling\ntemperature and error rate (how close to the true Boltzmann distribution is the\nQAOA distribution). We find that at very high temperatures one-round Grover\nmixer QAOA can sample from the Boltzmann distribution more accurately than the\nstandard X mixer QAOA at one round. Both X mixer and Grover mixer depth one\nQAOA can serve as approximate Boltzmann distribution samplers, and how good\nthis approximation is depends heavily on the QAOA angle choice.", "AI": {"tldr": "This study numerically investigates QAOA's ability to sample from Boltzmann distributions of disordered spin glass models, comparing standard X mixer and Grover mixer at depth one.", "motivation": "To understand the thermal sampling properties of QAOA and its ability to approximate Boltzmann distributions from classical Ising models, specifically disordered spin glasses.", "method": "Numerical investigation of QAOA at depth one, examining energy landscapes, Shannon entropy landscapes, and Boltzmann distribution sampling accuracy for both X mixer and Grover mixer across full parameter search space periods.", "result": "At high temperatures, one-round Grover mixer QAOA samples Boltzmann distributions more accurately than X mixer QAOA. Both mixers can serve as approximate Boltzmann samplers, with performance heavily dependent on QAOA angle choice.", "conclusion": "QAOA at depth one can approximate Boltzmann distribution sampling, with Grover mixer outperforming X mixer at high temperatures, but the quality of approximation depends significantly on parameter selection."}}
{"id": "2510.11379", "pdf": "https://arxiv.org/pdf/2510.11379", "abs": "https://arxiv.org/abs/2510.11379", "authors": ["Thomas Bake", "Erin Carson", "Yuxin Ma"], "title": "Forward and backward error bounds for a mixed precision preconditioned conjugate gradient algorithm", "categories": ["math.NA", "cs.NA", "65F10, 65F08, 65G50, 65Y20"], "comment": "34 pages, 4 figures", "summary": "The preconditioned conjugate gradient (PCG) algorithm is one of the most\npopular algorithms for solving large-scale linear systems Ax = b, where A is a\nsymmetric positive definite matrix. Rather than computing residuals directly,\nit updates the residual vectors recursively. Current analyses of the conjugate\ngradient (CG) algorithm in finite precision typically assume that the norm of\nthe recursively updated residual goes orders of magnitude below the machine\nprecision, focusing mainly on bounding the residual gap thereafter. This work\nintroduces a framework for the PCG algorithm and provides rigorous proofs that\nthe relative backward and forward errors of the computed results of PCG can\nreach the levels O(u) and O(u)\\kappa(A)^{1/2}, respectively, after a sufficient\nnumber of iterations without relying on an assumption concerning the norm of\nthe recursively updated residual, where u represents the unit roundoff and\n\\kappa(A) is the condition number of A. Our PCG framework further shows that\napplying preconditioners in low precision does not compromise the accuracy of\nthe final results, provided that reasonable conditions are satisfied. Our\ntheoretical results are illustrated through a set of numerical experiments.", "AI": {"tldr": "A new framework for preconditioned conjugate gradient (PCG) algorithm that provides rigorous error bounds without assuming the recursively updated residual norm goes below machine precision, and shows preconditioners can be applied in low precision without compromising accuracy.", "motivation": "Current analyses of conjugate gradient algorithms in finite precision typically assume the recursively updated residual norm goes orders of magnitude below machine precision, which is a limiting assumption that this work aims to overcome.", "method": "Developed a new framework for PCG algorithm with rigorous proofs for error bounds, analyzed relative backward and forward errors without relying on assumptions about residual norm behavior, and investigated preconditioner application in low precision.", "result": "Proved that relative backward and forward errors of PCG can reach O(u) and O(u)\u03ba(A)^{1/2} respectively after sufficient iterations, and demonstrated that applying preconditioners in low precision doesn't compromise final accuracy under reasonable conditions.", "conclusion": "The proposed PCG framework provides more realistic error bounds without restrictive assumptions and enables efficient use of low-precision preconditioners while maintaining accuracy, as validated by numerical experiments."}}
{"id": "2510.11403", "pdf": "https://arxiv.org/pdf/2510.11403", "abs": "https://arxiv.org/abs/2510.11403", "authors": ["Rupert L. Frank", "Larry Read"], "title": "Jost solutions and direct scattering for the continuum Calogero-Moser equation", "categories": ["math.AP", "math.SP", "nlin.SI", "Primary: 35P25, Secondary: 37K15, 35A22"], "comment": "66 pages", "summary": "We propose an inverse scattering transform for the continuum Calogero-Moser\nequation. We give a rigorous treatment of the direct scattering problem by\nconstructing the associated Jost solutions and introducing a distorted Fourier\ntransform, as well as deriving trace formulas for the eigenvalues of the Lax\noperator.", "AI": {"tldr": "The paper develops an inverse scattering transform for the continuum Calogero-Moser equation, including rigorous treatment of direct scattering via Jost solutions and distorted Fourier transform.", "motivation": "To establish a rigorous mathematical framework for analyzing the continuum Calogero-Moser equation using inverse scattering methods.", "method": "Constructs Jost solutions, introduces distorted Fourier transform, and derives trace formulas for eigenvalues of the Lax operator.", "result": "Provides a complete inverse scattering transform framework for the continuum Calogero-Moser equation with rigorous mathematical foundations.", "conclusion": "The developed inverse scattering transform enables systematic analysis of the continuum Calogero-Moser equation through scattering theory techniques."}}
{"id": "2510.10483", "pdf": "https://arxiv.org/pdf/2510.10483", "abs": "https://arxiv.org/abs/2510.10483", "authors": ["Narayan S Iyer", "Bivas Bhaumik", "Ram S Iyer", "Satyasaran Changdar"], "title": "Gradient Enhanced Self-Training Physics-Informed Neural Network (gST-PINN) for Solving Nonlinear Partial Differential Equations", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Partial differential equations (PDEs) provide a mathematical foundation for\nsimulating and understanding intricate behaviors in both physical sciences and\nengineering. With the growing capabilities of deep learning, data$-$driven\napproaches like Physics$-$Informed Neural Networks (PINNs) have been developed,\noffering a mesh$-$free, analytic type framework for efficiently solving PDEs\nacross a wide range of applications. However, traditional PINNs often struggle\nwith challenges such as limited precision, slow training dynamics, lack of\nlabeled data availability, and inadequate handling of multi$-$physics\ninteractions. To overcome these challenging issues of PINNs, we proposed a\nGradient Enhanced Self$-$Training PINN (gST$-$PINN) method that specifically\nintroduces a gradient based pseudo point self$-$learning algorithm for solving\nPDEs. We tested the proposed method on three different types of PDE problems\nfrom various fields, each representing distinct scenarios. The effectiveness of\nthe proposed method is evident, as the PINN approach for solving the Burgers$'$\nequation attains a mean square error (MSE) on the order of $10^{-3}$, while the\ndiffusion$-$sorption equation achieves an MSE on the order of $10^{-4}$ after\n12,500 iterations, with no further improvement as the iterations increase. In\ncontrast, the MSE for both PDEs in the gST$-$PINN model continues to decrease,\ndemonstrating better generalization and reaching an MSE on the order of\n$10^{-5}$ after 18,500 iterations. Furthermore, the results show that the\nproposed purely semi$-$supervised gST$-$PINN consistently outperforms the\nstandard PINN method in all cases, even when solution of the PDEs are\nunavailable. It generalizes both PINN and Gradient$-$enhanced PINN (gPINN), and\ncan be effectively applied in scenarios prone to low accuracy and convergence\nissues, particularly in the absence of labeled data.", "AI": {"tldr": "The paper proposes a Gradient Enhanced Self-Training PINN (gST-PINN) method that uses a gradient-based pseudo point self-learning algorithm to overcome limitations of traditional PINNs, achieving better accuracy and generalization in solving PDEs.", "motivation": "Traditional Physics-Informed Neural Networks (PINNs) struggle with limited precision, slow training, lack of labeled data, and inadequate handling of multi-physics interactions. These challenges motivate the development of an improved method.", "method": "The proposed gST-PINN method introduces a gradient-based pseudo point self-learning algorithm for solving PDEs. It generalizes both standard PINN and Gradient-enhanced PINN (gPINN) approaches and operates in a purely semi-supervised manner.", "result": "gST-PINN significantly outperforms standard PINN, achieving MSE on the order of 10^-5 after 18,500 iterations compared to PINN's MSE of 10^-3 for Burgers' equation and 10^-4 for diffusion-sorption equation. The method shows continuous improvement while PINN performance plateaus.", "conclusion": "The proposed gST-PINN consistently outperforms standard PINN in all tested cases, demonstrating better generalization and effectiveness in scenarios with low accuracy, convergence issues, and absence of labeled data."}}
{"id": "2510.11411", "pdf": "https://arxiv.org/pdf/2510.11411", "abs": "https://arxiv.org/abs/2510.11411", "authors": ["Tomoaki Okayama"], "title": "DE-Sinc approximation for unilateral rapidly decreasing functions and its computational error bound", "categories": ["math.NA", "cs.NA", "65D05, 65D15"], "comment": "Keywords: Sinc approximation, double-exponential transformation,\n  unilateral rapidly decreasing function, computation with guaranteed accuracy", "summary": "The Sinc approximation is known to be a highly efficient approximation\nformula for rapidly decreasing functions. For unilateral rapidly decreasing\nfunctions, which rapidly decrease as $x\\to\\infty$ but does not as\n$x\\to-\\infty$, an appropriate variable transformation makes the functions\nrapidly decreasing. As such a variable transformation, Stenger proposed $t =\n\\sinh(\\log(\\operatorname{arsinh}(\\exp x)))$, which enables the Sinc\napproximation to achieve root-exponential convergence. Recently, another\nvariable transformation $t = 2\\sinh(\\log(\\log(1+\\exp x)))$ was proposed, which\nimproved the convergence rate. Furthermore, its computational error bound was\nprovided. However, the improvement is not significant because the convergence\nrate is still root-exponential order. To improve the convergence rate\ndrastically, this study proposes a new transformation $t =\n2\\sinh(\\log(\\log(1+\\exp(\\pi\\sinh x))))$, which is categorized as the\ndouble-exponential (DE) transformation. Furthermore, this study provides its\ncomputational error bound, which shows that the proposed approximation formula\nmay achieve almost exponential convergence. Numerical experiments that confirm\nthe theoretical result are also provided.", "AI": {"tldr": "A new double-exponential transformation is proposed for Sinc approximation of unilateral rapidly decreasing functions, achieving almost exponential convergence instead of root-exponential convergence.", "motivation": "Existing variable transformations for Sinc approximation of unilateral rapidly decreasing functions only achieve root-exponential convergence, which is not significantly improved by recent methods. The goal is to drastically improve the convergence rate.", "method": "Proposes a new variable transformation t = 2sinh(log(log(1+exp(\u03c0sinh x)))), categorized as double-exponential (DE) transformation, and provides computational error bounds for this transformation.", "result": "The proposed transformation enables the Sinc approximation to achieve almost exponential convergence, which is a significant improvement over the previous root-exponential convergence rates.", "conclusion": "The new double-exponential transformation provides a much faster convergence rate for Sinc approximation of unilateral rapidly decreasing functions, with theoretical error bounds and numerical experiments confirming the improvement."}}
{"id": "2510.11481", "pdf": "https://arxiv.org/pdf/2510.11481", "abs": "https://arxiv.org/abs/2510.11481", "authors": ["Giovanni Brigati", "Cl\u00e9ment Mouhot"], "title": "Introduction to quantitative De Giorgi methods", "categories": ["math.AP"], "comment": "86 pages, 13 figures", "summary": "The theory of De Giorgi (1958) and Nash (1959) solves Hilbert's 19th problem\nand constitutes a major advance in the analysis of PDEs in the 20th century.\nThis theory concerns the H\\\"older regularity of solutions to elliptic and\nparabolic equations with non-regular coefficients, and it was extended by Moser\n(1960) to include the Harnack inequality. This course reviews the classical De\nGiorgi method in the elliptic and parabolic cases and introduces its recent\nextension to hypoelliptic equations which appear naturally in kinetic theory.\nThe simplest case is the Kolmogorov equation with a rough diffusion\ncoefficients matrix in the kinetic variable. We present compactness arguments\nbut emphasize the recently developed quantitative methods based on the\nconstruction of trajectories. These lecture notes are self-contained and can be\nused as a general introduction to the topic.", "AI": {"tldr": "Review of De Giorgi-Nash theory on Holder regularity for elliptic/parabolic PDEs with rough coefficients, extended to hypoelliptic equations in kinetic theory using quantitative trajectory methods.", "motivation": "To present the classical De Giorgi method and its recent extension to hypoelliptic equations that appear naturally in kinetic theory, particularly for Kolmogorov equations with rough diffusion coefficients.", "method": "Uses compactness arguments and quantitative methods based on trajectory construction, extending classical De Giorgi techniques to hypoelliptic equations.", "result": "Provides a self-contained introduction to the topic with recent developments in quantitative approaches for hypoelliptic equations.", "conclusion": "These lecture notes serve as a comprehensive introduction to De Giorgi-Nash theory and its modern extensions to kinetic theory applications."}}
{"id": "2510.11416", "pdf": "https://arxiv.org/pdf/2510.11416", "abs": "https://arxiv.org/abs/2510.11416", "authors": ["R\u00e9mi Robin", "Pierre Rouchon"], "title": "Convergence Analysis of Galerkin Approximations for the Lindblad Master Equation", "categories": ["math.NA", "cs.NA", "quant-ph", "81Q05, 65J10, 47N50, 65M60"], "comment": null, "summary": "This paper analyzes the numerical approximation of the Lindblad master\nequation on infinite-dimensional Hilbert spaces. We employ a classical Galerkin\napproach for spatial discretization and investigate the convergence of the\ndiscretized solution to the exact solution. Using \\textit{a priori} estimates,\nwe derive explicit convergence rates and demonstrate the effectiveness of our\nmethod through examples motivated by autonomous quantum error correction.", "AI": {"tldr": "Numerical approximation of Lindblad master equation on infinite-dimensional Hilbert spaces using Galerkin discretization with convergence analysis.", "motivation": "To develop effective numerical methods for solving the Lindblad master equation in infinite-dimensional quantum systems, particularly relevant for quantum error correction applications.", "method": "Classical Galerkin approach for spatial discretization with a priori estimates to analyze convergence.", "result": "Derived explicit convergence rates and demonstrated method effectiveness through autonomous quantum error correction examples.", "conclusion": "The Galerkin discretization method provides reliable numerical approximation with proven convergence for Lindblad master equations in infinite-dimensional settings."}}
{"id": "2510.11494", "pdf": "https://arxiv.org/pdf/2510.11494", "abs": "https://arxiv.org/abs/2510.11494", "authors": ["Matti Lassas", "Tony Liimatainen", "Valter Pohjola", "Teemu Tyni"], "title": "Gaussian beam interactions and inverse source problems for nonlinear wave equations", "categories": ["math.AP", "35L71, 58J45, 35L05, 35R30"], "comment": null, "summary": "We study the inverse source problem for the semilinear wave equation \\[\n(\\Box_g + q_1)u + q_2 u^2 = F, \\] on a globally hyperbolic Lorentzian manifold.\nWe demonstrate that the coefficients $q_1$ and $q_2$, as well as the source\nterm $F$, can be recovered up to a natural gauge symmetry inherent in the\nproblem from local measurements. Furthermore, if $q_1$ is known, we establish\nthe unique recovery of the source $F$, which is in a striking contrast to\ninverse source problems for linear equations where unique recovery is not\npossible. Our results also generalize previous works by eliminating the\nassumption that $u= 0$ is a solution, and by accommodating quadratic\nnonlinearities.\n  A key contribution is the development of a calculus for nonlinear\ninteractions of Gaussian beams. This framework provides an explicit\nrepresentation for waves that correspond to sources involving products of two\nor more Gaussian beams. We anticipate this calculus will serve as a versatile\ntool in related problems, offering a concrete alternative to Fourier integral\noperator methods.", "AI": {"tldr": "This paper solves the inverse source problem for semilinear wave equations on Lorentzian manifolds, recovering coefficients and source terms from local measurements using a novel Gaussian beam interaction calculus.", "motivation": "To address the limitations of linear inverse source problems where unique recovery is impossible, and to generalize previous works by removing the assumption that u=0 is a solution and accommodating quadratic nonlinearities.", "method": "Developed a calculus for nonlinear interactions of Gaussian beams, providing explicit representations for waves corresponding to sources involving products of multiple Gaussian beams as an alternative to Fourier integral operator methods.", "result": "Showed that coefficients q\u2081, q\u2082 and source term F can be recovered up to natural gauge symmetry from local measurements. When q\u2081 is known, F can be uniquely recovered - a striking contrast to linear equations where unique recovery is impossible.", "conclusion": "The paper establishes unique recovery results for inverse source problems in semilinear wave equations and introduces a versatile Gaussian beam interaction calculus that can be applied to related problems."}}
{"id": "2510.10857", "pdf": "https://arxiv.org/pdf/2510.10857", "abs": "https://arxiv.org/abs/2510.10857", "authors": ["Suhas S. Jain"], "title": "A model for transport of soluble surfactants in two-phase flows", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": "22 pages, 14 figures, submitted to journal", "summary": "In this work, we propose a novel transport model for soluble surfactants in\ntwo-phase flows. In a two-phase flow, the soluble surfactants can adsorb/desorb\nfrom/into the bulk of any of the phases to the interface and can modify the\ninterface properties. This results in sharp gradients in the surfactant\nconcentration on the interface and also between the two phases in the bulk when\nthere is selective adsorption/desorption, presenting a serious challenge for\nthe numerical simulations.\n  To overcome this challenge, we propose a computational model for the\ntransport of soluble surfactants that can model the adsorption and desorption\nprocesses accurately. The model is discretized using a central-difference\nscheme, which leads to a non-dissipative implementation that is crucial for the\nsimulation of turbulent flows. The model is used with the ACDI\ndiffuse-interface method (Jain, 2022), but can also be used with other\nalgebraic-based interface-capturing methods. Furthermore, the provable\nstrengths of the proposed model are: (a) the model maintains the positivity\nproperty of the surfactant concentration field, a physical realizability\nrequirement for the simulation of surfactants, when the proposed criterion is\nsatisfied, (b) the proposed model maintains discrete confinement of the\ninterfacial and bulk surfactants and prevents artificial numerical diffusion of\nthe surfactant between the interface and the bulk and between the two phases in\nthe bulk.\n  Finally, we present numerical simulations using the proposed model for both\none-dimensional and multi-dimensional cases and assess: the accuracy and\nrobustness of the model, the validity of the positivity property of the scalar\nconcentration field, and the confinement of the surfactant at the interface. We\nalso study the effect of surfactants on an oscillating droplet and on a complex\ndroplet/bubble-laden turbulent flow.", "AI": {"tldr": "A novel computational model for soluble surfactant transport in two-phase flows that accurately models adsorption/desorption processes using a central-difference scheme with the ACDI diffuse-interface method.", "motivation": "To overcome numerical challenges in simulating soluble surfactants in two-phase flows, where sharp concentration gradients at interfaces and selective adsorption/desorption create difficulties for accurate modeling.", "method": "Proposed a computational model using central-difference scheme discretization with the ACDI diffuse-interface method, maintaining positivity and discrete confinement properties while preventing artificial numerical diffusion.", "result": "The model successfully maintains positivity of surfactant concentration and discrete confinement, preventing artificial diffusion between interface and bulk phases. Numerical simulations demonstrate accuracy, robustness, and proper surfactant confinement.", "conclusion": "The proposed model provides an accurate and robust framework for simulating soluble surfactant transport in two-phase flows, with proven mathematical properties ensuring physical realizability and preventing numerical artifacts."}}
{"id": "2510.11475", "pdf": "https://arxiv.org/pdf/2510.11475", "abs": "https://arxiv.org/abs/2510.11475", "authors": ["Wanrong Hao", "Yunqing Huang"], "title": "An adaptive time-stepping strategy for the modified phase field crystal model with a strong nonlinear vacancy potential", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "comment": null, "summary": "This paper develops three linear and energy-stable schemes for a modified\nphase field crystal model with a strong nonlinear vacancy potential (VMPFC\nmodel). This sixth-order phase-field model enables realistic crystal growth\nsimulation. Starting from a Crank-Nicolson scheme based on the stabilized-SAV\n(S-SAV) method, we optimize it via the generalized positive auxiliary variable\n(GPAV) and modified exponential scalar auxiliary variable (ESAV) methods,\nthereby reducing computational complexity or eliminating the requirement for\nthe nonlinear free energy potential to be bounded from below. The newly\ndeveloped Energy-Variation Moving Average (EV-MA) adaptive time-stepping\nstrategy resolves numerical instabilities and mitigates the high parameter\nsensitivity of the conventional adaptive time algorithm during rapid energy\ndecay in the strongly nonlinear system. Unlike conventional instantaneous\nenergy-derivative monitors, the EV-MA technique incorporates a moving average\nof the energy variation. Additionally, the rate of change between adjacent time\nsteps is constrained by a maximum change factor. This design effectively\ndampens spurious oscillations and enhances the robustness of time step\nselection. Extensive numerical experiments are conducted to validate the\naccuracy and energy stability of the proposed schemes. The EV-MA strategy is\nalso demonstrated to perform robustly across a wide range of parameters.", "AI": {"tldr": "Developed three linear energy-stable schemes for a modified phase field crystal model with strong nonlinear vacancy potential, introducing an adaptive time-stepping strategy to handle numerical instabilities in strongly nonlinear systems.", "motivation": "To enable realistic crystal growth simulation using a sixth-order phase-field model while addressing computational complexity and numerical stability issues in strongly nonlinear systems.", "method": "Optimized Crank-Nicolson scheme using stabilized-SAV method, generalized positive auxiliary variable (GPAV), and modified exponential scalar auxiliary variable (ESAV) methods; developed Energy-Variation Moving Average (EV-MA) adaptive time-stepping strategy with moving average of energy variation and maximum change factor constraints.", "result": "Proposed schemes demonstrate accuracy and energy stability in extensive numerical experiments; EV-MA strategy performs robustly across wide parameter ranges, effectively dampening oscillations and enhancing time step selection robustness.", "conclusion": "The developed linear energy-stable schemes and EV-MA adaptive time-stepping strategy successfully address numerical challenges in strongly nonlinear phase field crystal models, enabling more robust and efficient crystal growth simulations."}}
{"id": "2510.11572", "pdf": "https://arxiv.org/pdf/2510.11572", "abs": "https://arxiv.org/abs/2510.11572", "authors": ["Tony Liimatainen", "Yi-Hsuan Lin"], "title": "An inverse problem for the Monge-Amp\u00e8re equation", "categories": ["math.AP", "math.DG"], "comment": "56 pages", "summary": "We extend the study of inverse boundary value problems to the setting of\nfully nonlinear PDEs by considering an inverse source problem for the\nMonge-Amp\\`ere equation\n  \\[\n  \\det D^2 u = F.\n  \\]\n  We prove that, on a convex Euclidean domain in the plane, the associated\nDirichlet-to-Neumann (DN) map uniquely determines a positive source function\n$F$. The proof relies on recovering the Hessian of a solution to the equation,\nwhich is interpreted as a Riemannian metric $g$. Interestingly, although the\nequation is posed on a Euclidean domain, the inverse problem becomes\nanisotropic since the metric $g$ appears as a coefficient matrix in the\nlinearized equation.\n  As an intermediate step, we prove that the DN map of the non-divergence form\nequation\n  \\[\n  g^{ab} \\partial_{ab} v = 0\n  \\]\n  uniquely determines the conformal class of the metric $g$ on a simply\nconnected planar domain, without the usual diffeomorphism invariance.\n  To address the challenges of full nonlinearity, we develop asymptotic\nexpansions for complex geometric optics solutions in the planar setting and\nsolve a resulting nonlocal\n  $\\overline{\\partial}$-equation by proving a unique continuation principle for\nit. These techniques are expected to be applicable to a wide range of inverse\nproblems for nonlinear equations.", "AI": {"tldr": "The paper studies an inverse source problem for the Monge-Amp\u00e8re equation, proving that the Dirichlet-to-Neumann map uniquely determines a positive source function F on convex planar domains.", "motivation": "To extend inverse boundary value problems to fully nonlinear PDEs, specifically the Monge-Amp\u00e8re equation, which presents challenges due to its full nonlinearity.", "method": "Recover the Hessian of solutions as a Riemannian metric, use complex geometric optics solutions with asymptotic expansions, solve a nonlocal \u2202\u0304-equation via unique continuation principles, and analyze the linearized equation with metric coefficients.", "result": "The DN map uniquely determines the source function F for the Monge-Amp\u00e8re equation on convex planar domains, and uniquely determines the conformal class of the metric g for related non-divergence form equations.", "conclusion": "The developed techniques for handling full nonlinearity in inverse problems are expected to be broadly applicable to other nonlinear equations."}}
{"id": "2510.11042", "pdf": "https://arxiv.org/pdf/2510.11042", "abs": "https://arxiv.org/abs/2510.11042", "authors": ["Mohd. Meraj Khan", "Sumesh P. Thampi", "Anubhab Roy"], "title": "Lattice Boltzmann method for electromagnetic wave scattering", "categories": ["physics.optics", "physics.comp-ph"], "comment": null, "summary": "In this paper, we propose the lattice Boltzmann method (LBM) as an\nalternative numerical approach for electromagnetic scattering. The method is\nsystematically validated over a wide range of size parameters, thereby covering\nthe Rayleigh, Mie, and geometric optics regimes, through comparison with\nestablished reference solutions. For circular cylinders, both perfect\nelectrically conducting (PEC) and dielectric, LBM results are benchmarked\nagainst analytical Mie theory. For dielectric cylinders, comparisons are\nperformed over a broad range of relative permittivities to assess accuracy\nacross different material contrasts. Scattering from dielectric spheres is\nlikewise compared with exact Mie solutions, showing excellent agreement. To\nassess performance for non-canonical geometries, we investigate a hexagonal\ndielectric cylinder and validate the results against the Discretized\nMie-Formalism, demonstrating that LBM can accurately capture edge diffraction\nand sharp-facet effects. Overall, the study provides the first systematic\nbenchmarking of LBM for electromagnetic scattering in one-, two-, and\nthree-dimensional configurations, establishing it as a promising and versatile\ntool in computational electromagnetics.", "AI": {"tldr": "The paper proposes and validates the lattice Boltzmann method (LBM) as a numerical approach for electromagnetic scattering across various size parameters and geometries.", "motivation": "To establish LBM as a viable alternative numerical method for electromagnetic scattering problems, covering different regimes (Rayleigh, Mie, geometric optics) and various geometries.", "method": "Systematic validation of LBM through comparison with established reference solutions (Mie theory, Discretized Mie-Formalism) for circular cylinders (PEC and dielectric), dielectric spheres, and non-canonical geometries like hexagonal cylinders.", "result": "LBM shows excellent agreement with analytical solutions for circular cylinders and spheres, and accurately captures edge diffraction and sharp-facet effects in non-canonical geometries.", "conclusion": "LBM is established as a promising and versatile tool for computational electromagnetics, providing the first systematic benchmarking across 1D, 2D, and 3D configurations."}}
{"id": "2510.11478", "pdf": "https://arxiv.org/pdf/2510.11478", "abs": "https://arxiv.org/abs/2510.11478", "authors": ["Nicolaj Rux", "Johannes Hertrich", "Sebastian Neumayer"], "title": "Numerical Methods for Kernel Slicing", "categories": ["math.NA", "cs.NA", "65R32, 45Q05"], "comment": "30 pages, 6 figures, 5 tables", "summary": "Kernels are key in machine learning for modeling interactions. Unfortunately,\nbrute-force computation of the related kernel sums scales quadratically with\nthe number of samples. Recent Fourier-slicing methods lead to an improved\nlinear complexity, provided that the kernel can be sliced and its Fourier\ncoefficients are known. To obtain these coefficients, we view the slicing\nrelation as an inverse problem and present two algorithms for their recovery.\nExtensive numerical experiments demonstrate the speed and accuracy of our\nmethods.", "AI": {"tldr": "The paper presents algorithms for recovering Fourier coefficients of kernels to enable efficient linear-complexity kernel sum computations using Fourier-slicing methods.", "motivation": "Brute-force kernel sum computation scales quadratically with sample size, which is inefficient for large datasets. Fourier-slicing methods offer linear complexity but require known Fourier coefficients of the kernel.", "method": "The authors treat the slicing relation as an inverse problem and develop two algorithms for recovering the Fourier coefficients needed for Fourier-slicing methods.", "result": "Extensive numerical experiments show that the proposed methods achieve both speed and accuracy in computing kernel sums.", "conclusion": "The presented algorithms successfully recover Fourier coefficients, enabling efficient linear-complexity kernel sum computations through Fourier-slicing approaches."}}
{"id": "2510.11648", "pdf": "https://arxiv.org/pdf/2510.11648", "abs": "https://arxiv.org/abs/2510.11648", "authors": ["Ahmad Z. Fino", "Berikbol T. Torebek"], "title": "Fujita-type results for parabolic equations with Hartree-type nonlinearities", "categories": ["math.AP"], "comment": "21 pages", "summary": "This paper investigates the critical behavior of global solutions to a\nparabolic equation with a Hartree-type nonlinearity of the form\n$$\\left\\{\\begin{array}{ll} u_{t}+(-\\Delta)^{\\frac{\\beta}{2}} u=\n(\\mathcal{K}\\ast |u|^{p})|u|^{q},&\\qquad x\\in \\mathbb{R}^n,\\,\\,\\,t>0,\n  u(x,0)=u_{0}(x),& \\qquad x\\in \\mathbb{R}^n,\\end{array}\n  \\right.$$ where $\\beta\\in(0,2]$, $n\\geq1$, $p>1$, $q\\geq 1$,\n$(-\\Delta)^{\\frac{\\beta}{2}},\\,\\beta\\in(0,2)$ denotes the fractional Laplacian,\nthe symbol $\\ast$ denotes the convolution operation in $\\mathbb{R}^n$, and\n$\\mathcal{K}:(0,\\infty)\\rightarrow(0,\\infty)$ is a continuous function such\nthat $\\mathcal{K}(|\\cdotp|)\\in L^1_{{loc}}(\\mathbb{R}^n)$ and is monotonically\ndecreasing in a neighborhood of infinity. We establish conditions for the\nglobal nonexistence of solutions to the problem under consideration, thereby\npartially improving some results of Filippucci and Ghergu in [Discrete Contin.\nDyn. Syst. A, 42 (2022) 1817-1833] and [Nonlinear Anal., 221 (2022) 112881]. In\naddition, we establish local and global existence results in the case where the\nconvolution term corresponds to the Riesz potential. Our methodology relies on\nthe nonlinear capacity method and the fixed-point principle, combined with the\nHardy-Littlewood-Sobolev inequality.", "AI": {"tldr": "This paper studies global solutions to a parabolic equation with Hartree-type nonlinearity, establishing conditions for global nonexistence and improving previous results by Filippucci and Ghergu.", "motivation": "To investigate critical behavior of solutions to parabolic equations with fractional Laplacian and Hartree-type nonlinearities, addressing gaps in existing literature and improving previous results.", "method": "Uses nonlinear capacity method and fixed-point principle combined with Hardy-Littlewood-Sobolev inequality to analyze existence and nonexistence of solutions.", "result": "Established conditions for global nonexistence of solutions and proved local/global existence results for the case with Riesz potential convolution term.", "conclusion": "The paper provides improved nonexistence conditions and existence results for parabolic equations with Hartree-type nonlinearities, advancing understanding of critical behavior in such systems."}}
{"id": "2510.11148", "pdf": "https://arxiv.org/pdf/2510.11148", "abs": "https://arxiv.org/abs/2510.11148", "authors": ["Weilong Chen", "Franz G\u00f6rlich", "Paul Fuchs", "Julija Zavadlav"], "title": "Enhanced Sampling for Efficient Learning of Coarse-Grained Machine Learning Potentials", "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Coarse-graining (CG) enables molecular dynamics (MD) simulations of larger\nsystems and longer timescales that are otherwise infeasible with atomistic\nmodels. Machine learning potentials (MLPs), with their capacity to capture\nmany-body interactions, can provide accurate approximations of the potential of\nmean force (PMF) in CG models. Current CG MLPs are typically trained in a\nbottom-up manner via force matching, which in practice relies on configurations\nsampled from the unbiased equilibrium Boltzmann distribution to ensure\nthermodynamic consistency. This convention poses two key limitations: first,\nsufficiently long atomistic trajectories are needed to reach convergence; and\nsecond, even once equilibrated, transition regions remain poorly sampled. To\naddress these issues, we employ enhanced sampling to bias along CG degrees of\nfreedom for data generation, and then recompute the forces with respect to the\nunbiased potential. This strategy simultaneously shortens the simulation time\nrequired to produce equilibrated data and enriches sampling in transition\nregions, while preserving the correct PMF. We demonstrate its effectiveness on\nthe M\\\"uller-Brown potential and capped alanine, achieving notable\nimprovements. Our findings support the use of enhanced sampling for force\nmatching as a promising direction to improve the accuracy and reliability of CG\nMLPs.", "AI": {"tldr": "Enhanced sampling improves coarse-grained machine learning potentials by generating biased data along CG degrees of freedom and recomputing forces with respect to unbiased potential, addressing poor sampling in transition regions and reducing simulation time.", "motivation": "Current CG MLPs trained via force matching require long atomistic trajectories for convergence and suffer from poor sampling in transition regions, limiting their accuracy and reliability.", "method": "Use enhanced sampling to bias along CG degrees of freedom for data generation, then recompute forces with respect to unbiased potential while preserving the correct potential of mean force.", "result": "Demonstrated effectiveness on M\u00fcller-Brown potential and capped alanine, achieving notable improvements in sampling efficiency and model accuracy.", "conclusion": "Enhanced sampling for force matching is a promising direction to improve the accuracy and reliability of coarse-grained machine learning potentials."}}
{"id": "2510.11500", "pdf": "https://arxiv.org/pdf/2510.11500", "abs": "https://arxiv.org/abs/2510.11500", "authors": ["Tileuzhan Mukhamet", "Katharina Kormann"], "title": "Structure-preserving finite element approximations of a hybrid relativistic cold fluid-particle model", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "comment": null, "summary": "We derive mixed finite element discretizations of a cold relativistics fluid\nmodel from approximations of the Poisson bracket that preserve mass, energy and\nthe divergence constraints. For time-discretization we derive an implicit\nenergy-conserving average-vector field method or apply an explicit\nstrong-stability preserving Runge-Kutta scheme. We also consider a coupling of\nthe fluid model to relativistic particles. We perform a numerical study of the\nscheme which shows convergence and conservation properties of the proposed\nmethods and apply the new scheme to a plasma wake field simulation.", "AI": {"tldr": "Mixed finite element discretizations for cold relativistic fluid model preserving mass, energy and divergence constraints, with implicit/explicit time schemes and particle coupling.", "motivation": "To develop numerical schemes that preserve fundamental conservation properties (mass, energy, divergence constraints) in relativistic fluid models, particularly for plasma wake field simulations.", "method": "Derived mixed finite element discretizations from Poisson bracket approximations; used implicit energy-conserving average-vector field method and explicit strong-stability preserving Runge-Kutta scheme; coupled fluid model with relativistic particles.", "result": "Numerical study shows convergence and conservation properties; successfully applied to plasma wake field simulation.", "conclusion": "The proposed methods effectively preserve conservation properties while maintaining accuracy for relativistic fluid simulations, particularly in plasma wake field applications."}}
{"id": "2510.11662", "pdf": "https://arxiv.org/pdf/2510.11662", "abs": "https://arxiv.org/abs/2510.11662", "authors": ["Steven B. Damelin", "Ruiwen Shu"], "title": "A family of interaction energy minimizers supported on two intervals", "categories": ["math.AP", "math.CA", "31C15, 49K20"], "comment": null, "summary": "In this paper, we consider the one-dimensional interaction energy\n$\\frac{1}{2}\\int_{\\mathbb{R}}(W*\\rho)(x)d\\rho(x) +\n\\int_{\\mathbb{R}}U(x)d\\rho(x)$ where the interaction potential $W(x)=\n-\\frac{|x|^b}{b},\\,1\\le b \\le 2$ and the external potential\n$U(x)=\\frac{|x|^4}{4}$, and $\\rho$ is a compactly supported probability measure\non the real line. Our main result shows that the minimizer is supported on two\nintervals when $1<b<2$, showing in particular how the support of the minimizer\ntransits from an interval (when $b=1$) to two points (when $b=2$) as $b$\nincreases. As a crucial part of the proof, we develop a new version of the\niterated balayage algorithm, the original version of which was designed by\nBenko, Damelin, Dragnev and Kuijlaars for logarithmic potentials in one\ndimension. We expect the methodology in this paper can be generalized to study\nminimizers of interaction energies in $\\mathbb{R}^d$ whose support is possibly\nan annulus.", "AI": {"tldr": "The paper studies the minimizer of a one-dimensional interaction energy with power-law potential W(x)=-|x|^b/b (1\u2264b\u22642) and quartic external potential U(x)=|x|^4/4. The main result shows that for 1<b<2, the minimizer is supported on two intervals, demonstrating a transition from a single interval (b=1) to two points (b=2).", "motivation": "To understand how the support structure of minimizers evolves as the interaction potential parameter b varies, particularly the transition from continuous support (b=1) to discrete support (b=2), and to develop analytical tools for studying such problems.", "method": "Developed a new version of the iterated balayage algorithm, extending the original method by Benko et al. for logarithmic potentials to handle power-law potentials. This algorithm is used to characterize the minimizer's support structure.", "result": "Proved that for 1<b<2, the minimizer of the interaction energy is supported on two intervals, establishing the transition behavior as b increases from 1 to 2.", "conclusion": "The methodology provides a framework for analyzing minimizers of interaction energies in higher dimensions, with potential applications to problems where the support may be an annulus or other structured sets."}}
{"id": "2510.11149", "pdf": "https://arxiv.org/pdf/2510.11149", "abs": "https://arxiv.org/abs/2510.11149", "authors": ["Bahram Jalili", "Salar Ghadiri Alamdari", "Payam Jalili", "Davood Domiri Ganji"], "title": "Analysis of bio-nanofluid flow over a stretching sheet with slip boundaries", "categories": ["physics.flu-dyn", "math-ph", "math.MP", "physics.app-ph", "physics.comp-ph"], "comment": "11 pages, 20 figures", "summary": "A viscous, incompressible, micropolar bio-nanofluid flowing across a\nstretching sheet in three dimensions while being driven to convect several slip\nboundaries in the presence of a magnetic field was studied. With the assistance\nof the relevant transformations, a mathematical model is presented. The finite\ndifference method numerically solves the converted non-linear ordinary\ndifferential equations. A comprehensive assessment was conducted to examine the\nimpact of governing parameters on dimensionless velocity, micro-rotation,\ntemperature, nanoparticle volume fraction, microorganisms, and heat transfer\nrate. The findings of this investigation showed a strong correlation when\ncompared to previous studies, indicating a high level of agreement and\nconsistency between the results. The study's conclusions indicate that the\nvelocity profile increases with higher values of {\\lambda} and {\\delta}, while\nit decreases with higher values of A, {\\delta}v, and M. The micro-rotation\nprofile F({\\eta}) drops as the spin gradient viscosity parameter rises, but\nG({\\eta}) increases. The temperature profile decreases with higher Prandtl\nnumbers but increases with higher thermophoresis parameters. The concentration\nprofile decreases with higher Schmidt numbers and Brownian motion parameters.\nThe microorganism profile increases with higher Peclet numbers and\nmicroorganism slip parameters but decreases with higher bio-convection Schmidt\nnumbers. Lastly, the local Nusselt number grows with increasing values of the\nstretching parameter {\\lambda}.", "AI": {"tldr": "Study of 3D micropolar bio-nanofluid flow over a stretching sheet with magnetic field and slip boundaries, analyzed using finite difference method.", "motivation": "To investigate the complex behavior of bio-nanofluids in three-dimensional flow with multiple physical parameters including magnetic field, slip boundaries, and various transport phenomena.", "method": "Mathematical modeling with relevant transformations, numerical solution of non-linear ODEs using finite difference method, comprehensive parameter analysis.", "result": "Velocity increases with \u03bb and \u03b4, decreases with A, \u03b4v, and M. Micro-rotation F(\u03b7) decreases with spin gradient viscosity, G(\u03b7) increases. Temperature decreases with Prandtl number, increases with thermophoresis. Concentration decreases with Schmidt number and Brownian motion. Microorganisms increase with Peclet number and slip parameters, decrease with bio-convection Schmidt number.", "conclusion": "The study successfully modeled complex bio-nanofluid behavior and identified key parameter effects on various profiles, showing good agreement with previous research."}}
{"id": "2510.11527", "pdf": "https://arxiv.org/pdf/2510.11527", "abs": "https://arxiv.org/abs/2510.11527", "authors": ["Junming Duan"], "title": "A fourth-order active flux method for parabolic problems with application to porous medium equation", "categories": ["math.NA", "cs.NA"], "comment": "29 pages, 14 figures", "summary": "The active flux (AF) method is a compact high-order finite volume method\noriginally proposed for solving hyperbolic conservation laws, in which cell\naverages and point values at cell interfaces are evolved simultaneously. This\npaper develops a fourth-order AF method for one- and two-dimensional parabolic\nproblems, employing the explicit strong-stability-preserving Runge-Kutta\n(SSP-RK) method for time integration. The proposed method is built on a\ndegenerate first-order system with auxiliary variables representing the\nderivatives of the primal variable, similar to local discontinuous Galerkin\n(LDG) methods, which avoids introducing pseudo-time or performing iterations\nwithin a physical time step in the existing hyperbolic formulations. The\nevolution of cell averages follows the standard finite volume method, ensuring\nconservation, while the point values of both the primal and auxiliary variables\nare updated using fourth-order central finite difference operators. A discrete\nFourier analysis confirms the fourth-order accuracy in 1D. With the third-order\nSSP-RK method, the maximum CFL number for stability is $0.27$ in 1D, as\nobtained by von Neumann analysis, larger than that of LDG methods. The proposed\nmethod is further applied to the porous medium equation, and\npositivity-preserving limitings are incorporated to guarantee the\nnon-negativity of the numerical solutions. Several numerical experiments\nvalidate the theoretical results and efficacy of the method.", "AI": {"tldr": "A fourth-order active flux method for parabolic problems using explicit SSP-RK time integration, avoiding pseudo-time iterations while maintaining conservation and achieving higher CFL stability than LDG methods.", "motivation": "To develop a high-order finite volume method for parabolic problems that avoids the computational overhead of pseudo-time iterations in existing hyperbolic formulations while maintaining conservation properties.", "method": "Uses a degenerate first-order system with auxiliary variables for derivatives, similar to LDG methods. Cell averages are updated via standard finite volume method, while point values use fourth-order central finite difference operators. Third-order SSP-RK time integration is employed.", "result": "Achieves fourth-order accuracy in 1D with maximum CFL number of 0.27 for stability, larger than LDG methods. Successfully applied to porous medium equation with positivity-preserving limiters to ensure non-negative solutions.", "conclusion": "The proposed active flux method provides an efficient fourth-order approach for parabolic problems with improved stability over LDG methods, validated through numerical experiments."}}
{"id": "2510.11714", "pdf": "https://arxiv.org/pdf/2510.11714", "abs": "https://arxiv.org/abs/2510.11714", "authors": ["Marco Pozza", "Alfonso Sorrentino"], "title": "Stochastic Homogenization of the Hamilton-Jacobi Equation on Manifolds", "categories": ["math.AP"], "comment": "33 pages", "summary": "This article establishes a stochastic homogenization result for the first\norder Hamilton-Jacobi equation on a Riemannian manifold $M$, in the context of\na stationary ergodic random environment. The setting involves a finitely\ngenerated abelian group $ \\mathtt{G}$ of rank $b$ acting on $M$ by isometries\nin a free, totally discontinuous, and co-compact manner, and a family of\nHamiltonians $H: T^*M \\times \\Omega \\to \\mathbb{R}$, parametrized over a\nprobability space $(\\Omega, \\mathbb{P})$, which are stationary with respect to\na $\\mathbb{P}$-ergodic action of $\\mathtt{G}$ on $\\Omega$. Under standard\nassumptions, including strict convexity and coercivity in the momentum\nvariable, we prove that as the scaling parameter $\\varepsilon$ goes to $0$, the\nviscosity solutions to the rescaled equation converge almost surely and locally\nuniformly to the solution to a deterministic homogenized Hamilton-Jacobi\nequation posed on $\\mathbb{R}^b$, which corresponds to the asymptotic cone of\n$\\mathtt{G}$. In particular, this approach sheds light on the relation between\nthe limit problem, the limit space, and the complexity of the acting group. The\nclassical periodic case corresponds to a randomness set $\\Omega$ that reduces\nto a singleton; other interesting examples of this setting are also described.\n  We remark that the effective Hamiltonian $\\overline{H}$ is obtained as the\nconvex conjugate of an effective Lagrangian $\\overline{L}$, which generalizes\nMather's $\\beta$-function to the stochastic setting; this represents a first\nstep towards the development of a stationary-ergodic version of Aubry-Mather\ntheory. As a geometric application, we introduce a notion of stable-like norm\nfor stationary ergodic families of Riemannian metrics on $M$, which generalizes\nthe classical Federer-Gromov's stable norm for closed manifolds.", "AI": {"tldr": "Stochastic homogenization of Hamilton-Jacobi equations on Riemannian manifolds with stationary ergodic random environments, showing convergence to deterministic homogenized equations on R^b.", "motivation": "To extend homogenization theory to stochastic settings on Riemannian manifolds and understand the relation between limit problems, limit spaces, and group complexity in random environments.", "method": "Using a finitely generated abelian group acting by isometries on the manifold, with stationary ergodic Hamiltonians, and proving convergence of viscosity solutions under scaling.", "result": "Viscosity solutions converge almost surely and locally uniformly to deterministic homogenized Hamilton-Jacobi equations on R^b, with effective Hamiltonian obtained via convex conjugate of effective Lagrangian.", "conclusion": "This work generalizes Mather's \u03b2-function to stochastic settings and introduces stable-like norms for stationary ergodic Riemannian metrics, representing progress towards stationary-ergodic Aubry-Mather theory."}}
{"id": "2510.11157", "pdf": "https://arxiv.org/pdf/2510.11157", "abs": "https://arxiv.org/abs/2510.11157", "authors": ["Payam Jalili", "Salar Ghadiri Alamdari", "Bahram Jalili", "Amirali Shateri", "Davood Domiri Ganji"], "title": "Analytical and numerical investigation of heat transfer of porous fin in a local thermal non-equilibrium state", "categories": ["physics.flu-dyn", "math-ph", "math.MP", "physics.app-ph", "physics.comp-ph"], "comment": "21 pages, 4 figures", "summary": "This research employs a local thermal non-equilibrium (LTNE) model to analyze\nthe heat transfer phenomenon through a porous fin, considering natural\nconvection and radiation effects. The infiltration velocity within the porous\nmedium is evaluated using the Darcy model, and buoyancy effects are accounted\nfor using the Boussinesq approximation. The Akbari-Ganji method (AGM) is\napplied to address the governing energy equations. The accuracy of the proposed\nsolution is verified by comparing it with numerical results obtained from the\nfinite difference method (FDM), the finite element method (FEM), and earlier\ninvestigations. The results are presented regarding the total average Nusselt\nnumber and temperature profiles. These results shed light on the influence of\nseveral important parameters, such as the thermal conductivity ratio,\ndimensionless thickness, convectional heat transfer, and external and internal\nradiation. The analysis reveals that decreasing Rayleigh and Biot numbers\nreduces the temperature profiles of the solid phase. Additionally, when the\nRayleigh number is low but the assigned Biot number is high, the temperature\ndifference between the solid and fluid phases diminishes. Furthermore,\nincreased thermal conductivity ratio and dimensionless thickness for assigned\nBiot and Rayleigh numbers lead to higher solid phase temperatures. The Nusselt\nnumber exhibits a decreasing trend with a decreasing thermal conductivity ratio\nbut increases with higher Rayleigh and Biot numbers and increased external\nradiation.", "AI": {"tldr": "Analysis of heat transfer in porous fins using LTNE model with natural convection and radiation effects, solved by AGM method and validated against numerical methods.", "motivation": "To understand heat transfer phenomena in porous fins considering natural convection and radiation effects, which is important for thermal management applications.", "method": "Used local thermal non-equilibrium (LTNE) model with Darcy model for infiltration velocity and Boussinesq approximation for buoyancy. Applied Akbari-Ganji method (AGM) to solve governing equations and validated with finite difference and finite element methods.", "result": "Decreasing Rayleigh and Biot numbers reduce solid phase temperature profiles. Low Rayleigh with high Biot reduces temperature difference between phases. Higher thermal conductivity ratio and dimensionless thickness increase solid phase temperatures. Nusselt number decreases with lower thermal conductivity ratio but increases with higher Rayleigh/Biot numbers and external radiation.", "conclusion": "The LTNE model effectively captures heat transfer behavior in porous fins, with key parameters (Rayleigh, Biot, thermal conductivity ratio, dimensionless thickness) significantly influencing temperature profiles and Nusselt number."}}
{"id": "2510.09632", "pdf": "https://arxiv.org/pdf/2510.09632", "abs": "https://arxiv.org/abs/2510.09632", "authors": ["Vahid Negahdari", "Shirin Samadi Bahrami", "Seyed Reza Moghadasi", "Mohammad Reza Razvan"], "title": "Performance of Machine Learning Methods for Gravity Inversion: Successes and Challenges", "categories": ["physics.geo-ph", "cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": null, "summary": "Gravity inversion is the problem of estimating subsurface density\ndistributions from observed gravitational field data. We consider the\ntwo-dimensional (2D) case, in which recovering density models from\none-dimensional (1D) measurements leads to an underdetermined system with\nsubstantially more model parameters than measurements, making the inversion\nill-posed and non-unique. Recent advances in machine learning have motivated\ndata-driven approaches for gravity inversion. We first design a convolutional\nneural network (CNN) trained to directly map gravity anomalies to density\nfields, where a customized data structure is introduced to enhance the\ninversion performance. To further investigate generative modeling, we employ\nVariational Autoencoders (VAEs) and Generative Adversarial Networks (GANs),\nreformulating inversion as a latent-space optimization constrained by the\nforward operator. In addition, we assess whether classical iterative solvers\nsuch as Gradient Descent (GD), GMRES, LGMRES, and a recently proposed Improved\nConjugate Gradient (ICG) method can refine CNN-based initial guesses and\nimprove inversion accuracy. Our results demonstrate that CNN inversion not only\nprovides the most reliable reconstructions but also significantly outperforms\npreviously reported methods. Generative models remain promising but unstable,\nand iterative solvers offer only marginal improvements, underscoring the\npersistent ill-posedness of gravity inversion.", "AI": {"tldr": "This paper explores machine learning approaches for 2D gravity inversion, comparing CNN-based direct mapping with generative models (VAEs/GANs) and iterative solvers, finding CNNs provide the most reliable reconstructions.", "motivation": "Gravity inversion is ill-posed and non-unique due to underdetermined systems with more model parameters than measurements, motivating data-driven machine learning approaches to improve inversion accuracy.", "method": "Used CNN for direct mapping of gravity anomalies to density fields with customized data structure, employed VAEs and GANs for generative modeling, and tested iterative solvers (GD, GMRES, LGMRES, ICG) to refine CNN initial guesses.", "result": "CNN inversion provided the most reliable reconstructions and significantly outperformed previous methods. Generative models showed promise but were unstable, while iterative solvers offered only marginal improvements.", "conclusion": "CNN-based approaches are most effective for gravity inversion, while generative models need further development and iterative methods provide limited benefits due to the inherent ill-posedness of the problem."}}
{"id": "2510.05639", "pdf": "https://arxiv.org/pdf/2510.05639", "abs": "https://arxiv.org/abs/2510.05639", "authors": ["Hsin-Chuang Chou"], "title": "Young functions on varifolds. Part I. Functional analytic foundations", "categories": ["math.FA", "math.AP", "28A35 (Primary) 60B10, 46A13 (Secondary)"], "comment": "39 pages", "summary": "In this paper, we study Young functions, a measure-theoretic model for\nmultiple-valued functions, and the convergence of pairs of measures and Young\nfunctions via their associated graph measures. This setting allows us to study\nthe convergence of pairs of surfaces and functions thereon, and a compactness\ntheorem is immediate. To develop notions of differentiability of Young\nfunctions in the upcoming papers, we also introduce and investigate several\ntest function spaces.", "AI": {"tldr": "Study of Young functions as measure-theoretic models for multiple-valued functions, convergence via graph measures, and development of test function spaces for differentiability analysis.", "motivation": "To establish a framework for analyzing convergence of pairs of surfaces and functions, and to prepare for studying differentiability of Young functions in future work.", "method": "Using graph measures associated with pairs of measures and Young functions to study convergence, and introducing test function spaces for differentiability analysis.", "result": "Obtained a compactness theorem for convergence of pairs of surfaces and functions, and developed foundational test function spaces.", "conclusion": "Established a measure-theoretic framework for Young functions that enables convergence analysis and provides the groundwork for studying differentiability in subsequent papers."}}
{"id": "2510.11209", "pdf": "https://arxiv.org/pdf/2510.11209", "abs": "https://arxiv.org/abs/2510.11209", "authors": ["Nicola Albor\u00e9", "Gabriele Di Antonio", "Fabrizio Coccetti", "Andrea Gabrielli"], "title": "Cross-Scale Reservoir Computing for large spatio-temporal forecasting and modeling", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "We propose a new reservoir computing method for forecasting high-resolution\nspatiotemporal datasets. By combining multi-resolution inputs from coarser to\nfiner layers, our architecture better captures both local and global dynamics.\nApplied to Sea Surface Temperature data, it outperforms standard parallel\nreservoir models in long-term forecasting, demonstrating the effectiveness of\ncross-layers coupling in improving predictive accuracy. Finally, we show that\nthe optimal network dynamics in each layer become increasingly linear,\nrevealing the slow modes propagated to subsequent layers.", "AI": {"tldr": "A new reservoir computing method using multi-resolution inputs from coarser to finer layers for better spatiotemporal forecasting, tested on Sea Surface Temperature data.", "motivation": "To improve forecasting of high-resolution spatiotemporal datasets by better capturing both local and global dynamics through cross-layer coupling.", "method": "Multi-resolution reservoir computing architecture with inputs from coarser to finer layers, using cross-layer coupling between parallel reservoir models.", "result": "Outperforms standard parallel reservoir models in long-term forecasting of Sea Surface Temperature data, with optimal network dynamics becoming increasingly linear in each layer.", "conclusion": "The proposed multi-resolution approach with cross-layer coupling effectively improves predictive accuracy and reveals that slow modes are propagated to subsequent layers."}}
{"id": "2510.09657", "pdf": "https://arxiv.org/pdf/2510.09657", "abs": "https://arxiv.org/abs/2510.09657", "authors": ["Riccardo Fosco Gramaccioni", "Christian Marinoni", "Fabrizio Frezza", "Aurelio Uncini", "Danilo Comminiello"], "title": "Generative Models for Helmholtz Equation Solutions: A Dataset of Acoustic Materials", "categories": ["cs.LG", "cs.AI", "cs.NA", "eess.SP", "math.NA"], "comment": "Accepted at EUSIPCO 2025", "summary": "Accurate simulation of wave propagation in complex acoustic materials is\ncrucial for applications in sound design, noise control, and material\nengineering. Traditional numerical solvers, such as finite element methods, are\ncomputationally expensive, especially when dealing with large-scale or\nreal-time scenarios. In this work, we introduce a dataset of 31,000 acoustic\nmaterials, named HA30K, designed and simulated solving the Helmholtz equations.\nFor each material, we provide the geometric configuration and the corresponding\npressure field solution, enabling data-driven approaches to learn Helmholtz\nequation solutions. As a baseline, we explore a deep learning approach based on\nStable Diffusion with ControlNet, a state-of-the-art model for image\ngeneration. Unlike classical solvers, our approach leverages GPU\nparallelization to process multiple simulations simultaneously, drastically\nreducing computation time. By representing solutions as images, we bypass the\nneed for complex simulation software and explicit equation-solving.\nAdditionally, the number of diffusion steps can be adjusted at inference time,\nbalancing speed and quality. We aim to demonstrate that deep learning-based\nmethods are particularly useful in early-stage research, where rapid\nexploration is more critical than absolute accuracy.", "AI": {"tldr": "A dataset of 31,000 acoustic materials (HA30K) is introduced for learning Helmholtz equation solutions using deep learning, specifically Stable Diffusion with ControlNet, to accelerate wave propagation simulations.", "motivation": "Traditional numerical solvers like finite element methods are computationally expensive for large-scale or real-time acoustic simulations, creating a need for faster alternatives.", "method": "Uses Stable Diffusion with ControlNet to represent acoustic pressure field solutions as images, leveraging GPU parallelization and adjustable diffusion steps for speed-quality trade-offs.", "result": "The approach drastically reduces computation time compared to classical solvers while maintaining reasonable accuracy for early-stage research applications.", "conclusion": "Deep learning-based methods are valuable for rapid exploration in acoustic material research, where speed is prioritized over absolute accuracy in initial stages."}}
{"id": "2510.09829", "pdf": "https://arxiv.org/pdf/2510.09829", "abs": "https://arxiv.org/abs/2510.09829", "authors": ["Mikul\u00e1\u0161 Ku\u010dera"], "title": "Spectrum of the wave equation with Dirac damping on a compact star graph", "categories": ["math.SP", "math-ph", "math.AP", "math.FA", "math.MP", "35P10 (Primary) 35L05, 47E05, 47D06, 34B45 (Secondary)"], "comment": "15 pages", "summary": "We consider the wave equation with a distributional Dirac damping and\nDirichlet boundary conditions on a compact interval. It is shown that the\nspectrum of the corresponding wave operator is fully determined by zeroes of an\nentire function. Consequently, a considerable change of spectral properties is\nshown for certain critical values of the damping parameter. We also derive a\ndefinitive criterion for the Riesz basis property of the root vectors for an\narbitrary placement of a complex-valued Dirac damping. Finally, we consider a\ngeneralisation of the problem for compact star graphs and provide insight into\nthe essence of the critical damping constant.", "AI": {"tldr": "Analysis of wave equation with Dirac damping on compact intervals and star graphs, focusing on spectral properties and Riesz basis criteria.", "motivation": "To understand how Dirac damping affects the spectral properties of wave equations and establish criteria for Riesz basis properties of root vectors.", "method": "Using zeroes of an entire function to determine spectrum, analyzing spectral changes at critical damping values, and generalizing to compact star graphs.", "result": "Found that spectrum is determined by entire function zeroes, identified critical damping values causing spectral changes, and established Riesz basis criteria for arbitrary damping placement.", "conclusion": "The study provides comprehensive understanding of Dirac damping effects on wave equations, with applications to star graphs and identification of critical damping behavior."}}
{"id": "2510.11350", "pdf": "https://arxiv.org/pdf/2510.11350", "abs": "https://arxiv.org/abs/2510.11350", "authors": ["\u00c1. A. Carrasco \u00c1lvarez", "M. Giantomassi", "J. Lihm", "G. E. Allemand", "M. Mignolet", "M. Verstraete", "S. Ponc\u00e9"], "title": "Electron-phonon coupling in magnetic materials using the local spin density approximation", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "Main manuscript 13 pages, 8 Figures Supplemental 8 pages, 11 Figures", "summary": "Magnetic materials are crucial for manipulating electron spin and magnetic\nfields, enabling applications in data storage, spintronics, charge transport,\nand energy conversion, while also providing insight into fundamental quantum\nphenomena. In numerous applications, the interaction between electrons and\nlattice vibrations, known as electron-phonon coupling, can be of significant\nimportance. In that regard, we extend the EPW package to be able to interpolate\nthe electron-phonon matrix elements combining perturbation theory and maximally\nlocalized Wannier functions. This allows to use dense momentum grids at a\nreasonable computational cost when computing electron-phonon-related quantities\nand physical properties. We validate our implementation considering\nferromagnetic iron and nickel, where we explore the absence of phonon-driven\nsuperconductivity, finding that superconductivity is intrinsically suppressed.\nFurthermore, we evaluate the carrier resistivity at finite temperatures for\nboth systems, considering the role of the magnetic phase in carrier transport.\nOur findings indicate that in the case of Fe, the primary contributor to\nresistivity is electron-phonon scattering. In contrast, for Ni, electron-phonon\nscattering constitutes less than one-third of the resistivity, underscoring a\nfundamental difference in the transport properties of the two systems.", "AI": {"tldr": "Extension of EPW package for electron-phonon coupling calculations in magnetic materials, validated on Fe and Ni showing suppressed superconductivity and different resistivity mechanisms.", "motivation": "To study electron-phonon interactions in magnetic materials like Fe and Ni, which are crucial for applications in spintronics and data storage, and understand fundamental quantum phenomena.", "method": "Extended EPW package using perturbation theory and maximally localized Wannier functions to interpolate electron-phonon matrix elements, enabling dense momentum grid calculations at reasonable computational cost.", "result": "Confirmed absence of phonon-driven superconductivity in Fe and Ni (intrinsically suppressed), and found electron-phonon scattering dominates resistivity in Fe but contributes less than one-third in Ni.", "conclusion": "The method successfully reveals fundamental differences in transport properties between Fe and Ni, with electron-phonon coupling playing varying roles in resistivity across magnetic materials."}}
{"id": "2510.09685", "pdf": "https://arxiv.org/pdf/2510.09685", "abs": "https://arxiv.org/abs/2510.09685", "authors": ["Yongshuai Liu", "Lianfang Wang", "Kuilin Qin", "Qinghua Zhang", "Faqiang Wang", "Li Cui", "Jun Liu", "Yuping Duan", "Tieyong Zeng"], "title": "Deep Neural Networks Inspired by Differential Equations", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NA", "math.NA", "A.1; I.2; I.4"], "comment": "35 Pages, 3 figures", "summary": "Deep learning has become a pivotal technology in fields such as computer\nvision, scientific computing, and dynamical systems, significantly advancing\nthese disciplines. However, neural Networks persistently face challenges\nrelated to theoretical understanding, interpretability, and generalization. To\naddress these issues, researchers are increasingly adopting a differential\nequations perspective to propose a unified theoretical framework and systematic\ndesign methodologies for neural networks. In this paper, we provide an\nextensive review of deep neural network architectures and dynamic modeling\nmethods inspired by differential equations. We specifically examine deep neural\nnetwork models and deterministic dynamical network constructs based on ordinary\ndifferential equations (ODEs), as well as regularization techniques and\nstochastic dynamical network models informed by stochastic differential\nequations (SDEs). We present numerical comparisons of these models to\nillustrate their characteristics and performance. Finally, we explore promising\nresearch directions in integrating differential equations with deep learning to\noffer new insights for developing intelligent computational methods that boast\nenhanced interpretability and generalization capabilities.", "AI": {"tldr": "This paper reviews deep neural network architectures and dynamic modeling methods inspired by differential equations, covering ODE-based models, SDE-based stochastic models, and their applications in improving interpretability and generalization.", "motivation": "To address persistent challenges in neural networks regarding theoretical understanding, interpretability, and generalization by adopting a differential equations perspective to provide a unified theoretical framework.", "method": "Extensive review of deep neural network architectures and dynamic modeling methods inspired by differential equations, including ODE-based deterministic models, SDE-based stochastic models, and regularization techniques, with numerical comparisons.", "result": "The review provides comprehensive insights into differential equation-inspired neural network models and their characteristics through numerical comparisons.", "conclusion": "Integrating differential equations with deep learning offers promising research directions for developing intelligent computational methods with enhanced interpretability and generalization capabilities."}}
{"id": "2510.10124", "pdf": "https://arxiv.org/pdf/2510.10124", "abs": "https://arxiv.org/abs/2510.10124", "authors": ["Nassim Athmouni"], "title": "Local Rigidity of Quasi--Lie Brackets on Quaternionic Banach Modules and Applications to Nonlinear PDEs", "categories": ["math.RA", "math.AP", "math.FA", "17B66, 46G20, 47A10, 35Q35", "I.1.2; G.1.10; I.1.1"], "comment": null, "summary": "We establish a local rigidity theorem for quasi--Lie brackets on quaternionic\nBanach right modules. Under quantitative control of antisymmetry and Jacobi\ndefects, we construct an explicit bilinear correction that preserves right\n$\\mathbb{H}$--linearity and restores the exact Lie property. The approach\ncombines a radial homotopy operator, a controlled Neumann-series inversion, and\na finite-rank adjustment, all with explicit operator estimates. This\nconstructive framework bridges quaternionic functional analysis with rigidity\ntheory and yields concrete applications to nonlinear PDEs, including local\nwell-posedness and Beale--Kato--Majda continuation criteria with explicit\nthresholds.", "AI": {"tldr": "Local rigidity theorem for quasi-Lie brackets on quaternionic Banach modules, with explicit bilinear correction preserving right H-linearity and restoring exact Lie property.", "motivation": "Bridge quaternionic functional analysis with rigidity theory and develop applications to nonlinear PDEs, including well-posedness and continuation criteria.", "method": "Combines radial homotopy operator, controlled Neumann-series inversion, and finite-rank adjustment with explicit operator estimates.", "result": "Constructive framework that establishes local rigidity under quantitative control of antisymmetry and Jacobi defects.", "conclusion": "Provides concrete applications to nonlinear PDEs with explicit thresholds for local well-posedness and Beale-Kato-Majda continuation criteria."}}
{"id": "2510.09796", "pdf": "https://arxiv.org/pdf/2510.09796", "abs": "https://arxiv.org/abs/2510.09796", "authors": ["Xiaoyu Wang", "Alexandra Valavanis", "Azhir Mahmood", "Andreas Mang", "Martin Benning", "Audrey Repetti"], "title": "A Unified Framework for Lifted Training and Inversion Approaches", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "stat.ML", "47A52, 47J30, 65J22, 65K10, 68T01, 68T07, 68W15, 94A08"], "comment": null, "summary": "The training of deep neural networks predominantly relies on a combination of\ngradient-based optimisation and back-propagation for the computation of the\ngradient. While incredibly successful, this approach faces challenges such as\nvanishing or exploding gradients, difficulties with non-smooth activations, and\nan inherently sequential structure that limits parallelisation. Lifted training\nmethods offer an alternative by reformulating the nested optimisation problem\ninto a higher-dimensional, constrained optimisation problem where the\nconstraints are no longer enforced directly but penalised with penalty terms.\nThis chapter introduces a unified framework that encapsulates various lifted\ntraining strategies, including the Method of Auxiliary Coordinates, Fenchel\nLifted Networks, and Lifted Bregman Training, and demonstrates how diverse\narchitectures, such as Multi-Layer Perceptrons, Residual Neural Networks, and\nProximal Neural Networks fit within this structure. By leveraging tools from\nconvex optimisation, particularly Bregman distances, the framework facilitates\ndistributed optimisation, accommodates non-differentiable proximal activations,\nand can improve the conditioning of the training landscape. We discuss the\nimplementation of these methods using block-coordinate descent strategies,\nincluding deterministic implementations enhanced by accelerated and adaptive\noptimisation techniques, as well as implicit stochastic gradient methods.\nFurthermore, we explore the application of this framework to inverse problems,\ndetailing methodologies for both the training of specialised networks (e.g.,\nunrolled architectures) and the stable inversion of pre-trained networks.\nNumerical results on standard imaging tasks validate the effectiveness and\nstability of the lifted Bregman approach compared to conventional training,\nparticularly for architectures employing proximal activations.", "AI": {"tldr": "Lifted training methods reformulate neural network training as constrained optimization using penalty terms, enabling distributed optimization, handling non-differentiable activations, and improving training landscape conditioning.", "motivation": "Traditional gradient-based training faces challenges like vanishing/exploding gradients, issues with non-smooth activations, and limited parallelization due to sequential structure.", "method": "Unified framework using Bregman distances for lifted training, including Method of Auxiliary Coordinates, Fenchel Lifted Networks, and Lifted Bregman Training. Implemented via block-coordinate descent with accelerated/adaptive optimization and implicit stochastic gradient methods.", "result": "Numerical results show lifted Bregman approach is effective and stable compared to conventional training, especially for architectures with proximal activations in standard imaging tasks.", "conclusion": "Lifted training provides a viable alternative to traditional methods, enabling distributed optimization, accommodating non-differentiable activations, and improving training stability across various network architectures."}}
{"id": "2510.10297", "pdf": "https://arxiv.org/pdf/2510.10297", "abs": "https://arxiv.org/abs/2510.10297", "authors": ["Graeme W. Milton"], "title": "A continued fraction approximation for the effective elasticity tensor of two-dimensional polycrystals as a function of the crystal elasticity tensor", "categories": ["cond-mat.mtrl-sci", "math-ph", "math.AP", "math.MP"], "comment": "33 Pages and 3 Figures", "summary": "For two-dimensional polycrystals the effective elasticity tensor $C_*$ as a\nfunction $C_*(C_0)$ of the elasticity tensor $C_0$ of the constituent crystal\nis considered. It is shown that this function can be approximated by one with a\ncontinued fraction expansion resembling that associated with a class of\nmicrostructure known as sequential laminates. These are hierarchical\nmicrostructures defined inductively. Rank 0 sequential laminates are simply\nrotations of the pure crystal. Rank $j$ sequential laminates are obtained by\nlaminating together, on a length scale much larger that the existing\nmicrostructure and with interfaces perpendicular to some direction $n_j$, rank\n$j-1$ sequential laminates with a rotation of the pure crystal. The continued\nfraction approximation for arbitrary polycrystal microstructures typically\ntakes a more general form than that of sequential laminates, but has some free\nparameters. It is an open question as to whether these free parameters can\nalways be adjusted so the continued fraction approximation matches exactly that\nof a sequential laminate. If so, one would have established that the elastic\nresponse of two-dimensional polycrystals can always be mimicked by that of\nsequential laminates. Our analysis carries over to the more general case where\nthe strain is replaced by a field $E(x)$ that is the gradient of a vector\npotential $u(x)$, i.e. $E=\\nabla u$ and the stress is replaced by a matrix\nvalued field $J(x)$ that need not be symmetric but has zero divergence\n$\\nabla\\cdot J=0$. The tensor $L(x)$ entering the constitutive relation $J=L E$\nis locally a rotation of the tensor $L_0$ of the pure crystal that need not\nhave any special symmetries and has 16 independent tensor elements.", "AI": {"tldr": "The paper shows that the effective elasticity tensor of 2D polycrystals can be approximated using continued fraction expansions similar to those of sequential laminates, and explores whether arbitrary polycrystal responses can be exactly mimicked by sequential laminates.", "motivation": "To understand how the effective elasticity tensor of two-dimensional polycrystals relates to the constituent crystal properties, and whether complex polycrystal microstructures can be approximated or exactly replicated by simpler hierarchical sequential laminate structures.", "method": "The approach uses continued fraction expansions to approximate the effective elasticity tensor function C*(C0). Sequential laminates are defined hierarchically, starting from pure crystal rotations and building up through lamination processes. The analysis extends to more general constitutive relations where strain is replaced by gradient fields and stress by divergence-free matrix fields.", "result": "The paper demonstrates that continued fraction approximations for arbitrary polycrystal microstructures take a more general form than those of sequential laminates, with additional free parameters. It remains an open question whether these parameters can always be adjusted to exactly match sequential laminate responses.", "conclusion": "The analysis establishes that 2D polycrystal elasticity can be approximated using continued fraction methods similar to sequential laminates, but whether arbitrary polycrystal responses can be exactly mimicked by sequential laminates remains unresolved. The framework extends to more general constitutive relations beyond standard elasticity theory."}}
{"id": "2510.11580", "pdf": "https://arxiv.org/pdf/2510.11580", "abs": "https://arxiv.org/abs/2510.11580", "authors": ["Navdeep Rana", "Ramin Golestanian"], "title": "Disorder to Order Transition in 1D Nonreciprocal Cahn-Hilliard Model", "categories": ["cond-mat.soft", "cond-mat.stat-mech", "physics.comp-ph"], "comment": "9 pages and 9 figures", "summary": "We extensively study the phenomenology of one dimensional Nonreciprocal Cahn\nHilliard model for varying nonreciprocity $(\\alpha)$ and different boundary\nconditions. At small $\\alpha$, a perturbed uniform state evolves to a defect\nladen configuration that lacks global polar order. Defects are the sources and\nsinks of travelling waves and nonreciprocity selects defects with a unique wave\nnumber that increases monotonically with $\\alpha_c$. A critical threshold\n$\\alpha_c$ marks the onset of a transition to states with finite global polar\norder. For periodic boundaries, above $\\alpha_c$, the system shows travelling\nwaves that are completely ordered. In contrast, travelling waves are\nincompatible with Dirichlet and Neumann boundaries. Instead, for $\\alpha\n\\gtrsim \\alpha_c$, we find fluctuating domains that show intermittent polar\norder and at large $\\alpha$, the system partitions into two domains with\nopposite polar order.", "AI": {"tldr": "The paper studies 1D Nonreciprocal Cahn-Hilliard model with varying nonreciprocity and boundary conditions, revealing transitions from defect-laden states to ordered traveling waves and domain patterns.", "motivation": "To understand how nonreciprocity and boundary conditions affect pattern formation and ordering transitions in one-dimensional nonreciprocal systems.", "method": "Extensive numerical study of the 1D Nonreciprocal Cahn-Hilliard model with varying nonreciprocity parameter \u03b1 and different boundary conditions (periodic, Dirichlet, Neumann).", "result": "At small \u03b1: defect-laden configurations without global polar order; critical threshold \u03b1_c marks transition to ordered states; periodic boundaries yield traveling waves above \u03b1_c; Dirichlet/Neumann boundaries show fluctuating domains and eventual domain partitioning at large \u03b1.", "conclusion": "Nonreciprocity drives transitions between different ordered states, with boundary conditions playing crucial role in determining the nature of ordering and pattern formation in the system."}}
{"id": "2510.10322", "pdf": "https://arxiv.org/pdf/2510.10322", "abs": "https://arxiv.org/abs/2510.10322", "authors": ["Fatoumata Sanogo"], "title": "A Spatio-temporal CP decomposition analysis of New England region in the US", "categories": ["stat.AP", "cs.NA", "math.NA"], "comment": "13 pages, 3 figures", "summary": "Spatio temporal data consist of measurement for one or more raster fields\nsuch as weather, traffic volume, crime rate, or disease incidents. Advances in\nmodern technology have increased the number of available information for this\ntype of data hence the rise of multidimensional data. In this paper we take\nadvantage of the multidimensional structure of the data but also its temporal\nand spatial structure. In fact, we will be using the NCAR Climate Data Gateway\nwebsite which provides data discovery and access services for global and\nregional climate model data. The daily values of total precipitation (prec),\nmaximum (tmax), and minimum (tmin) temperature are combined to create a\nmultidimensional data called tensor (a multidimensional array). In this paper,\nwe propose a spatio temporal principal component analysis to initialize CP\ndecomposition component. We take full advantage of the spatial and temporal\nstructure of the data in the initialization step for cp component analysis. The\nperformance of our method is tested via comparison with most popular\ninitialization method. We also run a clustering analysis to further show the\nperformance of our analysis.", "AI": {"tldr": "Proposes a spatio-temporal principal component analysis method to initialize CP decomposition components for multidimensional climate data, leveraging both spatial and temporal structures.", "motivation": "Modern technology has increased the availability of multidimensional spatio-temporal data, creating opportunities to better utilize both spatial and temporal structures in analysis methods.", "method": "Uses NCAR Climate Data Gateway data (precipitation, max/min temperatures) to create multidimensional tensors, then applies spatio-temporal PCA to initialize CP decomposition components.", "result": "The proposed method's performance was tested against popular initialization methods and further validated through clustering analysis.", "conclusion": "The spatio-temporal PCA initialization method effectively leverages spatial and temporal structures in multidimensional data for improved CP decomposition analysis."}}
{"id": "2510.10601", "pdf": "https://arxiv.org/pdf/2510.10601", "abs": "https://arxiv.org/abs/2510.10601", "authors": ["Dorian Martino", "Tristan Rivi\u00e8re"], "title": "Construction of harmonic coordinates for weak immersions", "categories": ["math.DG", "math.AP"], "comment": null, "summary": "We prove that any weak immersion in the critical Sobolev space\n$W^{\\frac{n}{2}+1,2}(\\mathbb{R}^n;\\mathbb{R}^d)$ in even dimension $n\\geq 4$,\nhas global harmonic coordinates if its second fundamental form is small in the\nSobolev space $W^{\\frac{n}{2}-1,2}(\\mathbb{R}^n;\\mathbb{R}^d)$. This is a\ngeneralization to arbitrary even dimension $n\\ge 4$ of a famous result of\nM\\\"uller--Sverak \\cite{muller1995} for $n=2$. The existence of such coordinates\nis a key tool used by the authors in \\cite{MarRiv20252} for the analysis of\nscale-invariant Lagrangians of immersions, such as the Graham--Reichert\nfunctional. From a purely intrinsic perspective, the proof of the main result\nleads to a general local existence theorem of harmonic coordinates for general\nmetrics with Riemann tensor in $L^p$ for any $p>n/2$ in any dimension $n\\geq\n3$.", "AI": {"tldr": "The paper proves that weak immersions in critical Sobolev spaces in even dimensions \u22654 have global harmonic coordinates when the second fundamental form is small, generalizing a 2D result and providing tools for analyzing scale-invariant Lagrangians.", "motivation": "To generalize M\u00fcller-Sverak's famous 2D result about harmonic coordinates to arbitrary even dimensions \u22654, and provide tools for analyzing scale-invariant Lagrangians of immersions like the Graham-Reichert functional.", "method": "The authors prove existence of global harmonic coordinates for weak immersions in critical Sobolev spaces W^{n/2+1,2} in even dimensions n\u22654, under smallness conditions on the second fundamental form in W^{n/2-1,2}.", "result": "Established that weak immersions in critical Sobolev spaces with small second fundamental form admit global harmonic coordinates in even dimensions \u22654, and obtained a general local existence theorem for harmonic coordinates for metrics with Riemann tensor in L^p for p>n/2 in any dimension n\u22653.", "conclusion": "The main result provides a generalization of harmonic coordinate existence to higher even dimensions, with applications to scale-invariant Lagrangian analysis and intrinsic geometric analysis."}}
{"id": "2510.11603", "pdf": "https://arxiv.org/pdf/2510.11603", "abs": "https://arxiv.org/abs/2510.11603", "authors": ["Umit Dogan Daglum", "Maria Stamenova", "Ersoy Sasioglu", "Stefano Sanvito"], "title": "Ab-initio calculation of magnetic exchange interactions using the spin-spiral method in VASP: Self-consistent versus magnetic force theorem approaches", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "11 pages, 4 figures", "summary": "We present an ab initio investigation of magnetic exchange interactions using\nthe spin-spiral method implemented in the VASP code, with a comparative\nanalysis of the self-consistent (SC) and magnetic force theorem (MFT)\napproaches. Using representative 3d ferromagnets (Fe, Co, Ni) and Mn-based full\nHeusler compounds, we compute magnon dispersion relations directly from\nspin-spiral total energies and extract real-space Heisenberg exchange\nparameters via Fourier transformation. Curie temperatures are subsequently\nestimated within both the mean-field and random-phase approximations. The SC\nspin-spiral calculations yield exchange parameters and magnon spectra in\nexcellent agreement with previous theoretical data, confirming their\nquantitative reliability across different classes of magnetic systems. In\ncontrast, the MFT approach exhibits systematic quantitative deviations: it\noverestimates spin-spiral energies and exchange couplings in high-moment\nsystems such as bcc Fe and the Mn-based Heuslers, while underestimating them in\nlow-moment fcc Ni. The magnitude of these discrepancies increases strongly with\nmagnetic moment size, exceeding several hundred percent in the high-moment\ncompounds. These findings underscore the decisive role of self-consistency in\naccurately determining magnetic exchange parameters and provide practical\nguidance for future first-principles studies of spin interactions and\nexcitations using the spin-spiral technique.", "AI": {"tldr": "Comparative study of self-consistent vs magnetic force theorem approaches for calculating magnetic exchange interactions using spin-spiral method in VASP code.", "motivation": "To evaluate the reliability and accuracy of different computational approaches (self-consistent vs magnetic force theorem) for determining magnetic exchange interactions in various magnetic systems.", "method": "Used spin-spiral method in VASP code to compute magnon dispersion relations and extract Heisenberg exchange parameters via Fourier transformation for 3d ferromagnets (Fe, Co, Ni) and Mn-based Heusler compounds.", "result": "Self-consistent calculations show excellent agreement with previous data, while MFT approach exhibits systematic deviations - overestimating in high-moment systems (Fe, Mn-Heuslers) and underestimating in low-moment systems (Ni), with discrepancies exceeding several hundred percent.", "conclusion": "Self-consistency is crucial for accurate determination of magnetic exchange parameters, providing practical guidance for future first-principles studies of spin interactions."}}
{"id": "2510.10438", "pdf": "https://arxiv.org/pdf/2510.10438", "abs": "https://arxiv.org/abs/2510.10438", "authors": ["Shuixin Li", "Jiecheng Chen", "Qingtang Jiang", "Jian Lu"], "title": "Synchrosqueezed windowed linear canonical transform: A method for mode retrieval from multicomponent signals with crossing instantaneous frequencies", "categories": ["eess.SP", "cs.NA", "math.NA"], "comment": null, "summary": "In nature, signals often appear in the form of the superposition of multiple\nnon-stationary signals. The overlap of signal components in the time-frequency\ndomain poses a significant challenge for signal analysis. One approach to\naddressing this problem is to introduce an additional chirprate parameter and\nuse the chirplet transform (CT) to elevate the two-dimensional time-frequency\nrepresentation to a three-dimensional time-frequency-chirprate representation.\nFrom a certain point of view, the CT of a signal can be regarded as a windowed\nspecial linear canonical transform of that signal, undergoing a shift and a\nmodulation.\n  In this paper, we develop this idea to propose a novel windowed linear\ncanonical transform (WLCT), which provides a new time-frequency-chirprate\nrepresentation. We discuss four types of WLCTs. In addition, we use a special\nX-ray transform to further sharpen the time-frequency-chirprate representation.\nFurthermore, we derive the corresponding three-dimensional synchrosqueezed\ntransform, demonstrating that the WLCTs have great potential for\nthree-dimensional signal separation.", "AI": {"tldr": "The paper proposes a novel windowed linear canonical transform (WLCT) that creates a 3D time-frequency-chirprate representation for analyzing superimposed non-stationary signals, and develops synchrosqueezed transforms for signal separation.", "motivation": "To address the challenge of overlapping signal components in time-frequency domain analysis of superimposed non-stationary signals found in nature.", "method": "Developed four types of windowed linear canonical transforms (WLCTs) that extend the chirplet transform concept, and used X-ray transforms to sharpen the time-frequency-chirprate representation.", "result": "Created a new 3D time-frequency-chirprate representation framework and derived corresponding three-dimensional synchrosqueezed transforms.", "conclusion": "WLCTs show great potential for three-dimensional signal separation of complex superimposed non-stationary signals."}}
{"id": "2510.10680", "pdf": "https://arxiv.org/pdf/2510.10680", "abs": "https://arxiv.org/abs/2510.10680", "authors": ["Nassim Athmouni"], "title": "Spectral and Dynamical Analysis of Fractional Discrete Laplacians on the Half-Lattice", "categories": ["math.SP", "math-ph", "math.AP", "math.FA", "math.MP", "47A10, 47A40, 47B25, 35P25, 81Q10, 39A70", "G.2.2; F.1.1"], "comment": null, "summary": "We investigate discrete fractional Laplacians defined on the half-lattice in\nseveral dimensions, allowing possibly different fractional orders along each\ncoordinate direction. By expressing the half-lattice operator as a boundary\nrestriction of the full-lattice one plus a bounded correction that is\nrelatively compact with respect to it, we show that both operators share the\nsame essential spectrum and the same interior threshold structure. For\nperturbations by a decaying potential, the conjugate-operator method provides a\nstrict Mourre estimate on any compact energy window inside the continuous\nspectrum, excluding threshold points. As a consequence, a localized Limiting\nAbsorption Principle holds, ensuring the absence of singular continuous\nspectrum, the finiteness of eigenvalues, and weighted propagation (transport)\nbounds. The form-theoretic construction also extends naturally to negative\nfractional orders. Overall, the relative compactness of the boundary correction\nguarantees that the interior-energy spectral and dynamical results obtained on\nthe full lattice remain valid on the half-lattice without modification.", "AI": {"tldr": "Analysis of discrete fractional Laplacians on half-lattices showing they share essential spectrum with full-lattice operators, with applications to spectral theory and transport bounds.", "motivation": "To understand how discrete fractional Laplacians behave on half-lattices compared to full lattices, particularly regarding spectral properties and dynamics.", "method": "Expressed half-lattice operator as boundary restriction of full-lattice operator plus bounded correction, used conjugate-operator method for Mourre estimates, and applied limiting absorption principle.", "result": "Half-lattice operators share essential spectrum and threshold structure with full-lattice operators, with strict Mourre estimates ensuring absence of singular continuous spectrum and finite eigenvalues.", "conclusion": "Boundary corrections are relatively compact, preserving interior-energy spectral and dynamical results from full lattice to half-lattice without modification."}}
{"id": "2510.10535", "pdf": "https://arxiv.org/pdf/2510.10535", "abs": "https://arxiv.org/abs/2510.10535", "authors": ["M Gulliksson", "A Oleynik", "M Ogren", "R Bakhshandeh-Chamazkoti"], "title": "Linear Algebra Problems Solved by Using Damped Dynamical Systems on the Stiefel Manifold", "categories": ["math.OC", "cs.NA", "math.DS", "math.NA"], "comment": null, "summary": "We develop a new method for solving minimization problems on the Stiefel\nManifold using damped dynamical systems. The constraints are satisfied in the\nlimit by an additional damped dynamical system. The method is illustrated by\nnumerical experiments and compared to a state-of-the-art conjugate gradient\nmethod.", "AI": {"tldr": "New damped dynamical systems method for solving minimization problems on the Stiefel Manifold with constraints satisfied in the limit.", "motivation": "To develop an efficient approach for solving constrained minimization problems on the Stiefel Manifold using dynamical systems theory.", "method": "Uses damped dynamical systems where constraints are satisfied in the limit through an additional damped dynamical system.", "result": "Method demonstrated through numerical experiments and compared favorably against state-of-the-art conjugate gradient method.", "conclusion": "The proposed damped dynamical systems approach provides an effective alternative for Stiefel Manifold optimization problems."}}
{"id": "2510.10811", "pdf": "https://arxiv.org/pdf/2510.10811", "abs": "https://arxiv.org/abs/2510.10811", "authors": ["Allen Juntao Fang", "Elena Giorgi", "Jingbo Wan"], "title": "Mass-Centered GCM Framework in Perturbations of Kerr(-Newman)", "categories": ["gr-qc", "math.AP"], "comment": null, "summary": "The nonlinear stability problem for black hole solutions of the Einstein\nequations critically depends on choosing an appropriate geometric gauge. In the\nvacuum setting, the use of Generally Covariant Modulated (GCM) spheres and\nhypersurfaces has played a central role in the proof of stability for slowly\nrotating Kerr spacetime. In this work, we develop an alternative GCM framework,\nthat we call mass-centered, designed to overcome the breakdown of the standard\nGCM construction in the charged case, where electromagnetic-gravitational\ncoupling destroys the exceptional behavior of the $\\ell=1$ mode of the\ncenter-of-mass quantity used in the vacuum analysis. This construction is aimed\nat the nonlinear stability of Reissner-Nordstr\\\"om and Kerr-Newman spacetimes.\nOur approach replaces transport-based control of the center-of-mass quantity\nwith a sphere-wise vanishing condition on a renormalized $\\ell=1$ mode,\nyielding mass-centered GCM hypersurfaces with modified gauge constraints. The\nresulting elliptic-transport system remains determined once an $\\ell=1$ basis\nis fixed via effective uniformization and provides an alternative construction\nin vacuum in the uncharged limit.", "AI": {"tldr": "Develops a mass-centered GCM framework to overcome limitations in charged black hole stability analysis, replacing transport-based control with sphere-wise vanishing conditions for better handling of electromagnetic-gravitational coupling.", "motivation": "The standard GCM construction breaks down for charged black holes due to electromagnetic-gravitational coupling disrupting the \u2113=1 mode behavior used in vacuum analysis, requiring an alternative approach for Reissner-Nordstr\u00f6m and Kerr-Newman stability.", "method": "Uses mass-centered GCM hypersurfaces with modified gauge constraints, replacing transport-based center-of-mass control with sphere-wise vanishing conditions on renormalized \u2113=1 modes, forming an elliptic-transport system determined by \u2113=1 basis fixing.", "result": "Provides an alternative GCM construction that works for charged black holes and reduces to the vacuum case in the uncharged limit, overcoming the breakdown caused by electromagnetic-gravitational coupling.", "conclusion": "The mass-centered GCM framework successfully addresses the limitations of standard GCM in charged settings, enabling progress toward nonlinear stability proofs for Reissner-Nordstr\u00f6m and Kerr-Newman spacetimes."}}
{"id": "2510.10724", "pdf": "https://arxiv.org/pdf/2510.10724", "abs": "https://arxiv.org/abs/2510.10724", "authors": ["Qiulin Zeng", "Nicholas Ezzell", "Arman Babakhani", "Itay Hen", "Lev Barash"], "title": "Inequalities, identities, and bounds for divided differences of the exponential function", "categories": ["math.CA", "cs.NA", "math.NA"], "comment": "16 pages,", "summary": "Let $\\exp[x_0,x_1,\\dots,x_n]$ denote the divided difference of the\nexponential function.\n  (i) We prove that exponential divided differences are log-submodular.\n  (ii) We establish the four-point inequality $\n\\exp[a,a,b,c]\\,\\exp[d,d,b,c]+\\exp[b,b,a,d]\\,\\exp[c,c,a,d]-\\exp[a,b,c,d]^2 \\ge 0\n$ for all $ a,b,c,d \\in \\mathbb{R} $.\n  (iii) We obtain sharp two-sided bounds for $\\exp[x_0,\\dots,x_n]$ at fixed\nmean and variance; as a consequence, we derive their large-input asymptotics.\n  (iv) We present closed-form identities for divided differences of the\nexponential function, including a convolution identity and summation formulas\nfor repeated arguments.", "AI": {"tldr": "This paper proves log-submodularity of exponential divided differences, establishes a four-point inequality, provides bounds and asymptotics, and presents closed-form identities.", "motivation": "To study the mathematical properties of exponential divided differences, particularly their submodular behavior and inequalities, which have applications in optimization and analysis.", "method": "The authors use mathematical analysis techniques including inequality proofs, asymptotic analysis, and derivation of closed-form identities for exponential divided differences.", "result": "Key results include: (i) proof of log-submodularity, (ii) establishment of a four-point inequality, (iii) sharp bounds and asymptotics, and (iv) closed-form convolution and summation identities.", "conclusion": "The paper provides comprehensive mathematical analysis of exponential divided differences, establishing fundamental properties and identities that advance the understanding of these mathematical objects."}}
{"id": "2510.10814", "pdf": "https://arxiv.org/pdf/2510.10814", "abs": "https://arxiv.org/abs/2510.10814", "authors": ["Allen Juntao Fang", "Elena Giorgi", "Jingbo Wan"], "title": "Einstein-Maxwell Equations on Mass-Centered GCM Hypersurfaces", "categories": ["gr-qc", "math.AP"], "comment": null, "summary": "The resolution of the nonlinear stability of black holes as solutions to the\nEinstein equations relies crucially on imposing the right geometric gauge\nconditions. In the vacuum case, the use of Generally Covariant Modulated (GCM)\nspheres and hypersurfaces has been successful in the proof of stability for\nslowly rotating Kerr spacetime. For the charged setting, our companion paper\nintroduced an alternative mass-centered GCM framework, adapted to the\nadditional difficulties of the Einstein-Maxwell system.\n  In this work, we solve the Einstein-Maxwell equations on such a mass-centered\nspacelike GCM hypersurface, which is equivalent to solving the constraint\nequations there. We control all geometric quantities of the solution in terms\nof some seed data, corresponding to the gauge-invariant fields describing\ncoupled gravitational-electromagnetic radiation in perturbations of\nReissner-Nordstr\\\"om or Kerr-Newman, first identified by the second author and\nexpected to be governed by favorable hyperbolic equations. This provides the\nfirst step toward controlling gauge-dependent quantities in the nonlinear\nstability analysis of the Reissner-Nordstr\\\"om and Kerr-Newman families.", "AI": {"tldr": "The paper develops a mass-centered GCM framework to solve Einstein-Maxwell constraint equations on spacelike hypersurfaces, providing the first step toward nonlinear stability analysis of charged black holes (Reissner-Nordstr\u00f6m and Kerr-Newman).", "motivation": "To extend the successful GCM gauge approach from vacuum black hole stability to the charged setting, addressing additional difficulties in the Einstein-Maxwell system for nonlinear stability analysis.", "method": "Using mass-centered Generally Covariant Modulated (GCM) spheres and hypersurfaces adapted for the Einstein-Maxwell system, solving constraint equations on spacelike GCM hypersurfaces and controlling geometric quantities via gauge-invariant fields describing coupled gravitational-electromagnetic radiation.", "result": "Successfully solved Einstein-Maxwell equations on mass-centered spacelike GCM hypersurfaces, controlling all geometric quantities in terms of seed data corresponding to gauge-invariant radiation fields.", "conclusion": "This work establishes the foundational framework for controlling gauge-dependent quantities in the nonlinear stability analysis of charged black hole families, building on previous vacuum results."}}
{"id": "2510.11439", "pdf": "https://arxiv.org/pdf/2510.11439", "abs": "https://arxiv.org/abs/2510.11439", "authors": ["Marc Hovemann", "Markus Weimar"], "title": "On the boundedness of dilation operators in the context of Triebel-Lizorkin-Morrey spaces", "categories": ["math.FA", "cs.NA", "math.AP", "math.NA", "46E35, 46E30"], "comment": "33 pages; Dedicated to the 90th anniversary of Hans Triebel", "summary": "In this paper we study the behavior of dilation operators $ D_\\lambda \\colon\nf \\mapsto f(\\lambda\\,\\cdot) $ with $ \\lambda > 1 $ in the context of\nTriebel-Lizorkin-Morrey spaces $\\mathcal{E}^{s}_{u,p,q}(\\mathbb{R}^d)$. For\nthat purpose we prove upper and lower bounds for the operator (quasi-)norm $\\|\nD_\\lambda \\,|\\, \\mathcal{L}\\big(\\mathcal{E}^s_{u,p,q}(\\mathbb{R}^d)\\big) \\| $.\nWe show that for $s>\\sigma_p $ the operator (quasi-)norm $\\| D_\\lambda \\,|\\,\n\\mathcal{L}\\big(\\mathcal{E}^s_{u,p,q}(\\mathbb{R}^d)\\big) \\| $ up to constants\nbehaves as $\\lambda^{s - \\frac{d}{u}} $. For the borderline case $ s =\n\\sigma_{p} $ we observe a behavior of the form $\\lambda^{\\sigma_p-\n\\frac{d}{u}}$, multiplied with logarithmic terms of $\\lambda$ that also depend\non the fine index $q$. For $s < \\sigma_{p}$ and $p \\geq 1$ we find the relation\n$\\| D_\\lambda \\,|\\, \\mathcal{L}\\big(\\mathcal{E}^s_{u,p,q}(\\mathbb{R}^d)\\big) \\|\n\\sim \\lambda^{ - \\frac{d}{u}}$. The case $s < \\sigma_{p}$ and $p < 1$ is\ninvestigated as well. Our proofs are mainly based on the Fourier analytic\napproach to Triebel-Lizorkin-Morrey spaces. As byproducts we show an advanced\nFourier multiplier theorem for band-limited functions in the context of Morrey\nspaces and derive some new equivalent (quasi-)norms and characterizations of\n$\\mathcal{E}^{s}_{u,p,q}(\\mathbb{R}^d)$.\n  Keywords: Dilation Operator, Morrey space, Triebel-Lizorkin-Morrey space,\nFourier multiplier", "AI": {"tldr": "This paper analyzes dilation operators in Triebel-Lizorkin-Morrey spaces, establishing bounds for operator norms based on different parameter regimes.", "motivation": "To understand the behavior of dilation operators in Triebel-Lizorkin-Morrey spaces, which are important function spaces in harmonic analysis and PDEs.", "method": "Using Fourier analytic approach to Triebel-Lizorkin-Morrey spaces, proving upper and lower bounds for dilation operator norms, and developing advanced Fourier multiplier theorems.", "result": "Found that dilation operator norms behave as \u03bb^(s-d/u) for s>\u03c3_p, with logarithmic corrections at borderline s=\u03c3_p, and as \u03bb^(-d/u) for s<\u03c3_p with p\u22651.", "conclusion": "The study provides complete characterization of dilation operator behavior in Triebel-Lizorkin-Morrey spaces across different parameter regimes, with applications to Fourier analysis and equivalent norm characterizations."}}
{"id": "2510.11670", "pdf": "https://arxiv.org/pdf/2510.11670", "abs": "https://arxiv.org/abs/2510.11670", "authors": ["Ludovica Maga", "Mathias Peirlinck", "Lise No\u00ebl"], "title": "Understanding the interplay of collagen and myocyte adaptation in cardiac volume overload: a multi-constituent growth and remodeling framework", "categories": ["physics.med-ph", "cs.NA", "math.NA", "q-bio.TO"], "comment": null, "summary": "Hearts subjected to volume overload (VO) are prone to detrimental anatomical\nand functional changes in response to elevated mechanical stretches, ultimately\nleading to heart failure. Experimental findings increasingly emphasize that\norgan-scale changes following VO cannot be explained by myocyte growth alone,\nas traditionally proposed in the literature. Collagen degradation, in\nparticular, has been associated with left ventricular adaptation in both acute\nand chronic stages of VO. These hypotheses remain to be substantiated by\ncomprehensive mechanistic evidence, and the contribution of each constituent to\nmyocardial growth and remodeling (G&R) processes is yet to be quantified. In\nthis work, we establish a hybrid G&R framework in which we integrate a\nmixture-based constitutive model with the kinematic growth formulation. This\nmulti-constituent model enables us to mechanistically assess the relative\ncontributions of collagen and myocyte changes to alterations in tissue\nproperties, ventricular dimensions, and growth phenotype. Our numerical results\nconfirm that collagen dynamics control the passive mechanical response of the\nmyocardium, whereas myocytes predominantly impact the extent and the phenotype\nof eccentric hypertrophy. Importantly, collagen degradation exacerbates myocyte\nhypertrophy, demonstrating a synergistic interplay that accelerates left\nventricular progression toward diastolic dysfunction. This work constitutes an\nimportant step towards an integrated characterization of the early compensatory\nstages of VO-induced cardiac G&R.", "AI": {"tldr": "A hybrid growth and remodeling framework shows collagen degradation controls passive mechanics while myocytes drive eccentric hypertrophy, with synergistic effects accelerating diastolic dysfunction in volume-overloaded hearts.", "motivation": "To understand the relative contributions of collagen and myocyte changes in volume-overload induced cardiac remodeling, as traditional myocyte-only growth models cannot explain organ-scale changes.", "method": "Developed a hybrid growth and remodeling framework integrating mixture-based constitutive modeling with kinematic growth formulation to assess multi-constituent contributions.", "result": "Collagen dynamics control passive mechanical response, myocytes drive eccentric hypertrophy extent and phenotype, and collagen degradation exacerbates myocyte hypertrophy through synergistic interplay.", "conclusion": "This provides mechanistic evidence for the synergistic roles of collagen and myocytes in volume-overload cardiac remodeling, advancing understanding of early compensatory stages toward diastolic dysfunction."}}
{"id": "2510.10842", "pdf": "https://arxiv.org/pdf/2510.10842", "abs": "https://arxiv.org/abs/2510.10842", "authors": ["Davide A. Bignamini", "Paolo De Fazio"], "title": "Stochastic and deterministic reaction-diffusion equations", "categories": ["math.PR", "math.AP"], "comment": null, "summary": "In this paper, we prove the well-posedness of non-autonomous deterministc and\nstochatic reaction-diffiusion equations. Concerning the stochastic problem, we\nprove also a result on the space-time regularity of the non-autonomous\nstochastic convoltution.", "AI": {"tldr": "Well-posedness of non-autonomous deterministic and stochastic reaction-diffusion equations, with space-time regularity results for stochastic convolutions.", "motivation": "To establish rigorous mathematical foundations for non-autonomous reaction-diffusion equations in both deterministic and stochastic settings.", "method": "Mathematical analysis and proof techniques for establishing well-posedness and regularity properties.", "result": "Proved well-posedness for both deterministic and stochastic non-autonomous reaction-diffusion equations, and obtained space-time regularity results for non-autonomous stochastic convolutions.", "conclusion": "The paper successfully establishes the well-posedness and regularity properties for non-autonomous reaction-diffusion equations in deterministic and stochastic frameworks."}}
