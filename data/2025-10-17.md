<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 22]
- [math.AP](#math.AP) [Total: 16]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 7]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [stat.ME](#stat.ME) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [math.ST](#math.ST) [Total: 1]
- [math.DG](#math.DG) [Total: 2]
- [nlin.SI](#nlin.SI) [Total: 1]
- [math.OC](#math.OC) [Total: 2]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 2]
- [math.PR](#math.PR) [Total: 1]
- [hep-ph](#hep-ph) [Total: 1]
- [physics.optics](#physics.optics) [Total: 2]
- [eess.SY](#eess.SY) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A decoupled Crank-Nicolson leap-frog scheme for the unsteady bioconvection flows problem with concentration dependent viscosity](https://arxiv.org/abs/2510.14034)
*Chenyang Li*

Main category: math.NA

TL;DR: A Crank-Nicolson Leap-Frog scheme is developed for bioconvection flow with concentration-dependent viscosity, using FEM for spatial and CNLF for temporal discretization, proven unconditionally stable with optimal error estimates.


<details>
  <summary>Details</summary>
Motivation: To develop a stable and accurate numerical scheme for unsteady bioconvection flow problems with concentration-dependent viscosity, which are challenging due to nonlinear coupling.

Method: Combines Galerkin FEM for spatial discretization with CNLF method for temporal discretization, using semi-implicit approach for nonlinear terms.

Result: The scheme is proven unconditionally stable (no restrictive time step bounds) and achieves L²-optimal error estimates for velocity and concentration.

Conclusion: The proposed CNLF scheme provides an effective numerical method for bioconvection flow problems with theoretical guarantees of stability and accuracy, validated through numerical experiments.

Abstract: A fully discrete Crank--Nicolson Leap--Frog (CNLF) scheme is proposed and
analyzed for the unsteady bioconvection flow problem with
concentration-dependent viscosity. Spatial discretization is handled via the
Galerkin finite element method (FEM), while temporal discretization employs the
CNLF method for the linear terms and a semi-implicit approach for the nonlinear
terms. The scheme is proven to be unconditionally stable, i.e., the time step
is not subject to a restrictive upper bound. Using the energy method,
$L^2$-optimal error estimates are derived for the velocity and concentration .
Finally, numerical experiments are presented to validate the theoretical
results.

</details>


### [2] [Geometric local parameterization for solving Hele-Shaw problems with surface tension](https://arxiv.org/abs/2510.14088)
*Zengyan Zhang,Wenrui Hao,John Harlim*

Main category: math.NA

TL;DR: A computational framework using point clouds and Generalized Moving Least Squares (GMLS) for solving 2D Hele-Shaw free boundary problems with surface tension, achieving high-order spatial convergence without global parameterization.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient method for free boundary problems that eliminates the need for global parameterization and enables high-order geometric approximations directly from point cloud data.

Method: Represent moving boundaries with point clouds, use GMLS for local geometric charts to compute curvature and other geometric quantities, discretize boundary integral equations with analytical singular integral formulas.

Result: Rigorous convergence analysis shows consistency and stability, numerical experiments demonstrate high-order spatial convergence and expected temporal convergence rates, complex shapes evolve correctly toward circular equilibrium states.

Conclusion: The proposed framework provides an effective, high-order accurate method for 2D Hele-Shaw problems with surface tension, validated by theoretical analysis and numerical simulations.

Abstract: In this work, we introduce a novel computational framework for solving the
two-dimensional Hele-Shaw free boundary problem with surface tension. The
moving boundary is represented by point clouds, eliminating the need for a
global parameterization. Our approach leverages Generalized Moving Least
Squares (GMLS) to construct local geometric charts, enabling high-order
approximations of geometric quantities such as curvature directly from the
point cloud data. This local parameterization is systematically employed to
discretize the governing boundary integral equation, including an analytical
formula of the singular integrals. We provide a rigorous convergence analysis
for the proposed spatial discretization, establishing consistency and stability
under certain conditions. The resulting error bound is derived in terms of the
size of the uniformly sampled point cloud data on the moving boundary, the
smoothness of the boundary, and the order of the numerical quadrature rule.
Numerical experiments confirm the theoretical findings, demonstrating
high-order spatial convergence and the expected temporal convergence rates. The
method's effectiveness is further illustrated through simulations of complex
initial shapes, which correctly evolve towards circular equilibrium states
under the influence of surface tension.

</details>


### [3] [A Stochastic Algorithm for Searching Saddle Points with Convergence Guarantee](https://arxiv.org/abs/2510.14144)
*Baoming Shi,Lei Zhang,Qiang Du*

Main category: math.NA

TL;DR: A stochastic saddle-search algorithm that avoids exact derivative and Hessian evaluations by using stochastic eigenvector-search and gradient updates with reflections to find saddle points in energy landscapes.


<details>
  <summary>Details</summary>
Motivation: Saddle points reveal important structural information about energy landscapes, but traditional deterministic methods require expensive exact derivative and Hessian evaluations. This work aims to develop a more efficient stochastic approach.

Method: The algorithm iteratively uses stochastic eigenvector-search based on stochastic Hessian to approximate unstable directions, followed by stochastic gradient updates with reflections in those directions to advance toward saddle points.

Result: Theoretical analysis shows almost sure convergence for eigenvector search and local almost sure convergence with O(1/n) rate for saddle search. High-probability identification of saddle points is guaranteed when starting sufficiently close.

Conclusion: The proposed stochastic algorithm is practically applicable, as demonstrated on neural network loss landscapes and liquid crystal models, and shows ability to escape from problematic areas of the energy landscape.

Abstract: Saddle points provide a hierarchical view of the energy landscape, revealing
transition pathways and interconnected basins of attraction, and offering
insight into the global structure, metastability, and possible collective
mechanisms of the underlying system. In this work, we propose a stochastic
saddle-search algorithm to circumvent exact derivative and Hessian evaluations
that have been used in implementing traditional and deterministic saddle
dynamics. At each iteration, the algorithm uses a stochastic eigenvector-search
method, based on a stochastic Hessian, to approximate the unstable directions,
followed by a stochastic gradient update with reflections in the approximate
unstable direction to advance toward the saddle point. We carry out rigorous
numerical analysis to establish the almost sure convergence for the stochastic
eigenvector search and local almost sure convergence with an $O(1/n)$ rate for
the saddle search, and present a theoretical guarantee to ensure the
high-probability identification of the saddle point when the initial point is
sufficiently close. Numerical experiments, including the application to a
neural network loss landscape and a Landau-de Gennes type model for nematic
liquid crystal, demonstrate the practical applicability and the ability for
escaping from "bad" areas of the algorithm.

</details>


### [4] [Superconvergent and Divergence-Free Finite Element Methods for Stokes Equation](https://arxiv.org/abs/2510.14192)
*Long Chen,Xuehai Huang,Chao Zhang,Xinyue Zhao*

Main category: math.NA

TL;DR: Superconvergent and divergence-free finite element methods for Stokes equation using H(div)-conforming vector elements and discontinuous pressure spaces, requiring no stabilization.


<details>
  <summary>Details</summary>
Motivation: To develop accurate finite element methods for Stokes equation that are both superconvergent and divergence-free, connecting to existing formulations while avoiding stabilization requirements.

Method: Uses H(div)-conforming vector elements for velocity and discontinuous piecewise polynomials for pressure, with a weak deviatoric gradient operator built using tangential-normal continuous finite elements for traceless tensors.

Result: Optimal and superconvergent error estimates are established, and numerical experiments verify the theoretical results.

Conclusion: The method successfully provides superconvergent, divergence-free solutions for Stokes equation without requiring stabilization, connecting to nonconforming virtual element and pseudostress-velocity-pressure mixed formulations.

Abstract: Superconvergent and divergence-free finite element methods for the Stokes
equation are developed. The velocity and pressure are discretized using
$H(\mathrm{div})$-conforming vector elements and discontinuous piecewise
polynomials. The discrete formulation employs a weak deviatoric gradient
operator built with tangential-normal continuous finite elements for traceless
tensors, requiring no stabilization. Optimal and superconvergent error
estimates are established. The method connects to nonconforming virtual element
and pseudostress-velocity-pressure mixed formulations. Numerical experiments
verify the theory.

</details>


### [5] [Neural Networks for Bayesian Inverse Problems Governed by a Nonlinear ODE](https://arxiv.org/abs/2510.14197)
*German Villalobos,Johann Rudi,Andreas Mang*

Main category: math.NA

TL;DR: Neural networks are used for Bayesian inverse parameter estimation in the FitzHugh-Nagumo ODE model, overcoming challenges like nonlinearity and nonconvexity to estimate model parameters, noise parameters, and uncertainties from noisy time series data.


<details>
  <summary>Details</summary>
Motivation: Classical parameter estimation methods face challenges with strongly nonlinear, nonconvex systems with sharp gradients. This paper explores how neural networks can overcome these difficulties for inverse parameter estimation problems.

Method: Formulate parameter estimation as a Bayesian inverse problem using the FitzHugh-Nagumo ODE model. Train neural networks to approximate reconstruction maps from noisy observational data (time series of neuron membrane potential).

Result: NNs successfully infer model parameters, noise parameters (autocorrelated additive noise and SDE-based noise), and posterior covariance matrix with single forward pass. Results show good prediction accuracy across different NN architectures and noise conditions.

Conclusion: Neural networks are a versatile tool for estimating parameters of dynamical systems, stochastic processes, and uncertainties, effectively propagating through governing ODEs with computational efficiency.

Abstract: We investigate the use of neural networks (NNs) for the estimation of hidden
model parameters and uncertainty quantification from noisy observational data
for inverse parameter estimation problems. We formulate the parameter
estimation as a Bayesian inverse problem. We consider a parametrized system of
nonlinear ordinary differential equations (ODEs), which is the FitzHugh--Nagumo
model. The considered problem exhibits significant mathematical and
computational challenges for classical parameter estimation methods, including
strong nonlinearities, nonconvexity, and sharp gradients. We explore how NNs
overcome these challenges by approximating reconstruction maps for parameter
estimation from observational data. The considered data are time series of the
spiking membrane potential of a biological neuron. We infer parameters
controlling the dynamics of the model, noise parameters of autocorrelated
additive noise, and noise modeled via stochastic differential equations, as
well as the covariance matrix of the posterior distribution to expose parameter
uncertainties--all with just one forward evaluation of an appropriate NN. We
report results for different NN architectures and study the influence of noise
on prediction accuracy. We also report timing results for training NNs on
dedicated hardware. Our results demonstrate that NNs are a versatile tool to
estimate parameters of the dynamical system, stochastic processes, as well as
uncertainties, as they propagate through the governing ODE.

</details>


### [6] [High-Order Meshfree Surface Integration, Including Singular Integrands](https://arxiv.org/abs/2510.14236)
*Daniel R. Venn,Steven J. Ruuth*

Main category: math.NA

TL;DR: High-order meshfree methods for surface integration on point clouds without requiring meshes or specific point arrangements, with extensions for handling singular integrals.


<details>
  <summary>Details</summary>
Motivation: Surface integration is important for PDE applications, but mesh-based methods need curved meshes for high-order accuracy and meshfree methods typically require exact integration of basis functions, which is difficult on arbitrary surfaces.

Method: Two meshfree methods for integration on arbitrary piecewise-smooth surfaces that don't require specific point arrangements or initial triangulation, with extensions for handling singular integrals.

Result: Methods maintain high accuracy without changing point density near singularities and work on surfaces with or without boundaries.

Conclusion: The developed methods provide practical high-order integration capabilities for surface point clouds without mesh requirements, addressing key limitations of existing approaches.

Abstract: We develop and test high-order methods for integration on surface point
clouds. The task of integrating a function on a surface arises in a range of
applications in engineering and the sciences, particularly those involving
various integral methods for partial differential equations. Mesh-based methods
require a curved mesh for high-order convergence, which can be difficult to
reliably obtain on many surfaces, and most meshfree methods require the ability
to integrate a set of functions (such as radial basis functions) exactly on the
domain of interest; these integrals are generally not known in closed form on
most surfaces. We describe two methods for integrating on arbitrary,
piecewise-smooth surfaces with or without boundary. Our approaches do not
require a particular arrangement of points or an initial triangulation of the
surface, making them completely meshfree. We also show how the methods can be
extended to handle singular integrals while maintaining high accuracy without
changing the point density near singularities.

</details>


### [7] [A DeepLagrangian method for learning and generating aggregation patterns in multi-dimensional Keller-Segel chemotaxis systems](https://arxiv.org/abs/2510.14297)
*Yani Feng,Michael K. Ng,Zhiwen Zhang*

Main category: math.NA

TL;DR: DeepLagrangian is a self-adaptive density estimation method that learns and generates aggregation patterns and near-singular solutions of the Keller-Segel chemotaxis system in 2D and 3D space using a Lagrangian framework and flow-based generative models.


<details>
  <summary>Details</summary>
Motivation: Solving the Keller-Segel chemotaxis system and generating its aggregation patterns is challenging due to near-singular behavior like finite-time blow-up or concentration phenomena. Existing methods struggle with these singular solutions.

Method: Normalize KS solution into probability density function, derive normalized KS system, rewrite into Lagrangian framework using continuity equation, define physics-informed Lagrangian loss, incorporate time-dependent KRnet flow-based generative model, and use time-marching strategies for PDF approximation.

Result: The method accurately generates aggregation patterns and near-singular solutions for 2D and 3D KS chemotaxis systems with/without advection. The Lagrangian loss effectively controls KL divergence between approximate and exact PDFs.

Conclusion: DeepLagrangian provides an effective framework for handling near-singular solutions in KS chemotaxis systems through Lagrangian formulation and flow-based generative models, demonstrating accuracy in both 2D and 3D settings.

Abstract: The Keller-Segel (KS) chemotaxis system is used to describe the overall
behavior of a collection of cells under the influence of chemotaxis. However,
solving the KS chemotaxis system and generating its aggregation patterns remain
challenging due to the emergence of solutions exhibiting near-singular
behavior, such as finite-time blow-up or concentration phenomena. Building on a
Lagrangian framework of the KS system, we develop DeepLagrangian, a
self-adaptive density estimation method that learns and generates aggregation
patterns and near-singular solutions of the KS system in two- and
three-dimensional (2D and 3D) space under different physical parameters. The
main advantage of the Lagrangian framework is its inherent ability to adapt to
near-singular solutions. To develop this framework, we normalize the KS
solution into a probability density function (PDF), derive the corresponding
normalized KS system, and utilize the property of the continuity equation to
rewrite the system into a Lagrangian framework. We then define a
physics-informed Lagrangian loss to enforce this framework and incorporate a
flow-based generative model, called the time-dependent KRnet, to approximate
the PDF by minimizing the loss. Furthermore, we integrate time-marching
strategies with the time-dependent KRnet to enhance the accuracy of the PDF
approximation. After obtaining the approximate PDF, we recover the original KS
solution. We also prove that the Lagrangian loss effectively controls the
Kullback-Leibler (KL) divergence between the approximate PDF and the exact PDF.
In the numerical experiments, we demonstrate the accuracy of our DeepLagrangian
method for the 2D and 3D KS chemotaxis system with/without advection.

</details>


### [8] [Numerical Approximation of Electrohydrodynamics Model: A Comparative Study of PINNs and FEM](https://arxiv.org/abs/2510.14310)
*Mara Martinez,B. Veena S. N. Rao,S. M. Mallikarjunaiah*

Main category: math.NA

TL;DR: PINNs are applied to solve the challenging Electrohydrodynamic (EHD) problem, demonstrating excellent performance with limited training data and outperforming traditional FEM methods.


<details>
  <summary>Details</summary>
Motivation: Solving nonlinear differential equations (NDEs) is crucial for modeling physical, chemical, and biological processes, but deriving precise approximations remains challenging. While FEM has been foundational, physics-informed neural networks (PINNs) show promise for approximating continuous functions effectively.

Method: A novel PINN approach with an L²-type total loss function is used, without requiring prior knowledge of exact solutions. Training involves forward propagation for gradient/curvature adjustments and backpropagation for hyperparameter refinement. Optimal neural network architectures and hyperparameters are systematically investigated.

Result: PINNs deliver excellent performance even with limited training data. The comparative study shows PINNs outperform conventional FEM, though FEM accuracy can be improved with smaller mesh sizes.

Conclusion: PINNs provide an effective alternative to traditional methods like FEM for solving challenging NDE problems like EHD, offering high accuracy without requiring exact solution knowledge and performing well with limited data.

Abstract: The accurate representation of numerous physical, chemical, and biological
processes relies heavily on differential equations (DEs), particularly
nonlinear differential equations (NDEs). While understanding these complex
systems necessitates obtaining solutions to their governing equations, the
derivation of precise approximations for NDEs remains a formidable task in
computational mathematics. Although established techniques such as the finite
element method (FEM) have long been foundational, remarkable promise for
approximating continuous functions with high efficacy has recently been
demonstrated by advancements in physics-informed deep-learning feedforward
neural networks. In this work, a novel application of PINNs is presented for
the approximation of the challenging Electrohydrodynamic (EHD) problem. A
specific $L^2$-type \textit{total loss function} is employed, notably without
reliance on any prior knowledge of the exact solution. A comprehensive
comparative study is conducted, juxtaposing the approximation capabilities of
the proposed neural network with those of the conventional FEM. The PINN
training regimen is composed of two critical steps: forward propagation for
adjustments to gradient and curvature, and backpropagation for the refinement
of hyperparameters. The critical challenge of identifying optimal neural
network architectures and hyperparameter configurations for efficient
optimization is meticulously investigated. Excellent performance is shown to be
delivered by the neural network even with a limited training dataset.
Simultaneously, it is demonstrated that the accuracy of the FEM can be
substantially enhanced through the judicious selection of smaller mesh sizes.

</details>


### [9] [High-order mass- and energy-conserving methods for the nonlinear Schrödinger equation and its hyperbolization](https://arxiv.org/abs/2510.14335)
*Hendrik Ranocha,David I. Ketcheson*

Main category: math.NA

TL;DR: A new class of numerical methods for the nonlinear Schrödinger equation that conserves mass and energy, achieves arbitrarily high-order accuracy, and only requires solving a scalar algebraic equation per time step.


<details>
  <summary>Details</summary>
Motivation: To develop efficient and robust numerical methods for the nonlinear Schrödinger equation that preserve important physical invariants (mass and energy) while maintaining high accuracy.

Method: Developed a new relaxation-type approach for conserving multiple nonlinear functionals that is more efficient and robust than existing multiple-relaxation methods. Utilizes existing spatial discretizations like Fourier spectral method with appropriate energy density forms.

Result: The proposed schemes demonstrate high accuracy and efficiency on test problems for both focusing and defocusing NLS equations.

Conclusion: The new methods provide an effective approach for solving the nonlinear Schrödinger equation with conservation properties, high accuracy, and computational efficiency.

Abstract: We propose a class of numerical methods for the nonlinear Schr\"odinger (NLS)
equation that conserves mass and energy, is of arbitrarily high-order accuracy
in space and time, and requires only the solution of a scalar algebraic
equation per time step. We show that some existing spatial discretizations,
including the popular Fourier spectral method, are in fact energy-conserving if
one considers the appropriate form of the energy density. We develop a new
relaxation-type approach for conserving multiple nonlinear functionals that is
more efficient and robust for the NLS equation compared to the existing
multiple-relaxation approach. The accuracy and efficiency of the new schemes is
demonstrated on test problems for both the focusing and defocusing NLS.

</details>


### [10] [Asymptotic-preserving semi-Lagrangian discontinuous Galerkin schemes for the Boltzmann equation](https://arxiv.org/abs/2510.14375)
*Xiaofeng Cai,Zhen Hao,Liu Liu,Jiayu Wan*

Main category: math.NA

TL;DR: An asymptotic-preserving semi-Lagrangian discontinuous Galerkin scheme for the Boltzmann equation that handles multi-scale transport phenomena using IMEX-RK time integration and a novel moments update procedure.


<details>
  <summary>Details</summary>
Motivation: To develop an effective numerical scheme for the Boltzmann equation that can handle multi-scale transport phenomena while preserving asymptotic properties.

Method: Semi-Lagrangian discontinuous Galerkin scheme with IMEX-RK time integration, utilizing Shu-Osher form and constructing appropriate moments update procedure for penalization.

Result: Theoretical analysis establishes accuracy order conditions and stability for linearized model. Numerical experiments validate accuracy, asymptotic-preserving property, and robustness in various regimes.

Conclusion: The proposed scheme is effective for multi-scale kinetic simulations, demonstrating accuracy, stability, and robustness across different transport regimes.

Abstract: In this work, we present an asymptotic-preserving semi-Lagrangian
discontinuous Galerkin scheme for the Boltzmann equation that effectively
handles multi-scale transport phenomena. The main challenge lies in designing
appropriate moments update for penalization within the semi-Lagrangian
framework. Inspired by [M. Ding, J. M. Qiu, and R. Shu, Multiscale Model.
Simul. 21 (2023), no. 1, 143--167], the key ingredient is utilizing the
Shu-Osher form of the scheme in the implicit-explicit Runge-Kutta (IMEX-RK)
setting, which enables us to capture the correct limiting system by
constructing an appropriate moments update procedure. Our theoretical analysis
establishes accuracy order conditions for both the IMEX-RK time integration and
the new moments update step. We also employ hypocoercivity techniques to
establish stability for the linearized model. Numerical experiments for various
test problems validate our proposed scheme's accuracy, asymptotic-preserving
property, and robustness in various regimes, which demonstrates its
effectiveness for multi-scale kinetic simulations.

</details>


### [11] [Preconditioned Conjugate Gradient methods for the estimation of General Linear Models](https://arxiv.org/abs/2510.14471)
*Paolo Foschi*

Main category: math.NA

TL;DR: The paper presents a PCG method for computing GLS estimators in GLMs using an indefinite preconditioner, which iterates OLS estimations to converge to GLS solutions.


<details>
  <summary>Details</summary>
Motivation: To efficiently compute GLS estimators by combining direct methods (for OLS steps) with iterative methods, particularly for structured problems where direct methods are computationally expensive.

Method: Expresses GLS estimator as augmented system, solves using PCG with indefinite preconditioner, iterates OLS estimations that converge to GLS estimator in finite steps.

Result: The method achieves same precision as state-of-the-art direct methods but in significantly less time for structured problems like Constrained GLMs and multivariate GLMs.

Conclusion: The PCG approach effectively combines direct and iterative methods, exploiting matrix structures in OLS steps while solving remaining structure iteratively, providing computational efficiency for structured GLM problems.

Abstract: The use of the Preconditioned Conjugate Gradient (PCG) method for computing
the Generalized Least Squares (GLS) estimator of the General Linear Model (GLM)
is considered. The GLS estimator is expressed in terms of the solution of an
augmented system. That system is solved by means of the PCG method using an
indefinite preconditioner. The resulting method iterates a sequence Ordinary
Least Squares (OLS) estimations that converges, in exact precision, to the GLS
estimator within a finite number of steps. The numerical and statistical
properties of the estimator computed at an intermediate step are analytically
and numerically studied. This approach allows to combine direct methods, used
in the OLS step, with those of iterative methods. This advantage is exploited
to design PCG methods for the estimation of Constrained GLMs and of some
structured multivariate GLMs. The structure of the matrices involved are
exploited as much as possible, in the OLS step. The iterative method then
solves for the unexploited structure. Numerical experiments shows that the
proposed methods can achieve, for these structured problems, the same precision
of state of the art direct methods, but in a fraction of the time.

</details>


### [12] [A Well-Balanced Space-Time ALE Compact Gas-Kinetic Scheme for the Shallow Water Equations on Unstructured Meshes](https://arxiv.org/abs/2510.14673)
*Fengxiang Zhao,Jianping Gan,Kun XU*

Main category: math.NA

TL;DR: A high-order space-time coupled ALE compact gas-kinetic scheme for shallow water equations on moving unstructured meshes that preserves geometric conservation law and well-balanced property.


<details>
  <summary>Details</summary>
Motivation: To develop an accurate and stable numerical method for shallow water equations on moving meshes that avoids data remapping and maintains conservation properties.

Method: Uses arbitrary Lagrangian-Eulerian formulation with compact gas-kinetic scheme, incorporates mesh motion effects in numerical fluxes, establishes evolution equation for topography, employs nonlinear fourth-order compact reconstruction.

Result: The scheme achieves second-order temporal accuracy in single stage, preserves geometric conservation law and well-balanced property, and demonstrates accuracy and stability in numerical experiments.

Conclusion: The proposed ALE compact GKS provides an effective framework for simulating complex shallow-water flow problems on moving meshes with high accuracy and conservation properties.

Abstract: This study presents a high-order, space-time coupled arbitrary Lagrangian
Eulerian (ALE) compact gas-kinetic scheme (GKS) for the shallow water equations
on moving unstructured meshes. The proposed method preserves both the geometric
conservation law (GCL) and the well-balanced property. Mesh motion effects are
directly incorporated by formulating numerical fluxes that account for the
spatial temporal nonuniformity of the flow field and the swept area of moving
cell interfaces. This allows temporal updates to be performed on the physical
moving mesh, avoiding data remapping. The compact GKS provides time accurate
evolution of flow variables and fluxes, enabling the scheme to achieve
second-order temporal accuracy within a single stage. To consistently treat
bottom topography on moving meshes, an evolution equation for the topography is
established and discretized using a compatible space-time scheme, in which the
fluxes induced by mesh motion are computed accurately. Mathematical proofs
demonstrating the GCL preserving and well-balanced properties of the proposed
ALE formulation are also provided. For improved accuracy and robustness, a
nonlinear fourth-order compact reconstruction technique is employed. A
comprehensive set of numerical experiments verifies the scheme's theoretical
properties and demonstrates its accuracy, stability, and effectiveness in
simulating complex shallow-water flow problems.

</details>


### [13] [Generalized Fourier Series: An N log2(N) extension for aperiodic functions that eliminates Gibbs oscillations](https://arxiv.org/abs/2510.14731)
*Narsimha Reddy Rapakaa,Mohamed Kamel Riahi*

Main category: math.NA

TL;DR: GFS extends Fourier series to non-periodic functions by decomposing them into periodic and aperiodic components, avoiding Gibbs phenomenon and domain extensions while maintaining computational efficiency.


<details>
  <summary>Details</summary>
Motivation: To address limitations of classical Fourier series for non-periodic functions, including Gibbs phenomenon, poor convergence, and the need for computational domain extensions in conventional Fourier extension methods.

Method: Decomposes functions into periodic (standard Fourier modes via FFT) and aperiodic (adaptive low-rank sinusoidal functions with non-harmonic modes) components, dynamically tuned to capture discontinuities and derivative jumps.

Result: Achieves high accuracy without domain extensions, maintains N log2(N) computational complexity, and demonstrates high-resolution power comparable to FFT in periodic domains, validated through numerical experiments.

Conclusion: GFS provides a robust, efficient framework for high-accuracy function approximations in non-periodic domains, with significant potential for applications in numerical PDEs, signal processing, machine learning, and computational physics.

Abstract: This article introduces the Generalized Fourier Series (GFS), a novel
spectral method that extends the clas- sical Fourier series to non-periodic
functions. GFS addresses key challenges such as the Gibbs phenomenon and poor
convergence in non-periodic settings by decomposing functions into periodic and
aperiodic com- ponents. The periodic part is represented using standard Fourier
modes and efficiently computed via the Fast Fourier Transform (FFT). The
aperiodic component employs adaptive, low-rank sinusoidal functions with
non-harmonic modes, dynamically tuned to capture discontinuities and derivative
jumps across domain boundaries. Unlike conventional Fourier extension methods,
GFS achieves high accuracy without requiring compu- tational domain extensions,
offering a compact and efficient representation of non-periodic functions. The
adaptive low-rank approach ensures accuracy while minimizing computational
overhead, typically involving additional complex modes for the aperiodic part.
Furthermore, GFS demonstrates a high-resolution power, with degrees of freedom
comparable to FFT in periodic domains, and maintains N log2(N) computational
complexity. The effectiveness of GFS is validated through numerical
experiments, showcasing its ability to approximate functions and their
derivatives in non-periodic domains accurately. With its robust framework and
minimal computational cost, GFS holds significant potential for advancing
applications in numerical PDEs, signal processing, machine learning, and
computational physics by providing a robust and efficient tool for
high-accuracy function approximations.

</details>


### [14] [On the convergence of stochastic variance reduced gradient for linear inverse problems](https://arxiv.org/abs/2510.14759)
*Bangti Jin,Zehui Zhou*

Main category: math.NA

TL;DR: Analysis of SVRG and regularized SVRG for linear inverse problems in Hilbert spaces, showing optimal convergence rates with constant step sizes.


<details>
  <summary>Details</summary>
Motivation: SVRG is promising for large-scale inverse problems but needs theoretical analysis for linear inverse problems in Hilbert spaces, especially regarding convergence rates and regularization.

Method: Analyze SVRG and regularized SVRG with constant step sizes, using explicit error recursion and prior estimates on inner loop updates.

Result: Regularized SVRG achieves optimal convergence rates without early stopping, while standard SVRG is optimal for nonsmooth solutions with a priori stopping rules.

Conclusion: Both SVRG variants can achieve optimal convergence for linear inverse problems under suitable conditions, with regularization providing benefits for smooth solutions.

Abstract: Stochastic variance reduced gradient (SVRG) is an accelerated version of
stochastic gradient descent based on variance reduction, and is promising for
solving large-scale inverse problems. In this work, we analyze SVRG and a
regularized version that incorporates a priori knowledge of the problem, for
solving linear inverse problems in Hilbert spaces. We prove that, with suitable
constant step size schedules and regularity conditions, the regularized SVRG
can achieve optimal convergence rates in terms of the noise level without any
early stopping rules, and standard SVRG is also optimal for problems with
nonsmooth solutions under a priori stopping rules. The analysis is based on an
explicit error recursion and suitable prior estimates on the inner loop updates
with respect to the anchor point. Numerical experiments are provided to
complement the theoretical analysis.

</details>


### [15] [Ghost stabilisation for cut finite element exterior calculus](https://arxiv.org/abs/2510.14772)
*Daniele Di Pietro,Jérôme Droniou,Erik Nilsson*

Main category: math.NA

TL;DR: The paper introduces a cut finite element method (CutFEEC) using finite element exterior calculus, with a stabilization that works for any form degree and is robust to interface position relative to the mesh.


<details>
  <summary>Details</summary>
Motivation: To develop a finite element method that can handle unfitted meshes and interface problems robustly, independent of how the interface cuts through the background mesh.

Method: Cut finite element method formulated in finite element exterior calculus language with a stabilization term that ensures uniform equivalence between physical domain L^2-norm and active mesh L^2-norm.

Result: The method is proven to have uniform norm equivalence and is applied to discretize Hodge Laplace equations on unfitted meshes in any dimension and topology. Numerical tests show convergence and condition number scaling independent of boundary position.

Conclusion: The CutFEEC method provides a robust approach for unfitted mesh problems with stabilization that works across all form degrees and ensures mesh-independent performance.

Abstract: We introduce the cut finite element method in the language of finite element
exterior calculus, by formulating a stabilisation -- for any form degree --
that makes the method robust with respect to the position of the interface
relative to the mesh. We prove that the $L^2$-norm on the physical domain
augmented with this stabilisation is uniformly equivalent to the $L^2$-norm on
the ``active'' mesh that contains all the degrees of freedom of the finite
element space (including those external to the physical domain). We show how
this CutFEEC method can be applied to discretize the Hodge Laplace equations on
an unfitted mesh, in any dimension and any topology. A numerical illustration
is provided involving a conforming finite element space of $H^{\text{curl}}$
posed on a filled torus, with convergence and condition number scaling
independent of the position of the boundary with respect to the background
mesh.

</details>


### [16] [Error analysis of Abate--Whitt methods for Inverse Laplace Transforms and a new algorithm for queuing theory applications](https://arxiv.org/abs/2510.14799)
*Nikita Deniskin,Federico Poloni*

Main category: math.NA

TL;DR: The paper analyzes Abate-Whitt methods for Inverse Laplace Transform computation, introduces TAME methods using AAA algorithm for rational approximation, and shows improved efficiency with fewer function evaluations.


<details>
  <summary>Details</summary>
Motivation: To improve the accuracy and efficiency of Inverse Laplace Transform methods, particularly for queuing theory applications like phase-type distributions and fluid queues.

Method: Uses AAA algorithm for rational approximation to create TAME methods, with parameters optimized for function-specific domains and floating-point computation considerations.

Result: TAME methods achieve comparable or better accuracy than classical methods with significantly fewer function evaluations.

Conclusion: The new TAME methods provide more efficient alternatives to traditional Abate-Whitt methods for Inverse Laplace Transform computation in queuing theory applications.

Abstract: We study the accuracy of a class of methods to compute the Inverse Laplace
Transform, the so-called \emph{Abate--Whitt methods} [Abate, Whitt 2006], which
are based on a linear combination of evaluations of $\widehat{f}$ in a few
points. We provide error bounds which relate the accuracy of a method to the
rational approximation of the exponential function. We specialize our analysis
to applications in queuing theory, a field in which Abate--Whitt methods are
often used; in particular, we study phase-type distributions and
Markov-modulated fluid models (or \emph{fluid queues}).
  We use a recently developed algorithm for rational approximation, the AAA
algorithm [Nakatsukasa, S\`ete, Trefethen 2018], to produce a new family of
methods, which we call TAME. The parameters of these methods are constructed
depending on a function-specific domain $\Omega$; we provide a quasi-optimal
choice for certain families of functions. We discuss numerical issues related
to floating-point computation, and we validate our results through numerical
experiments which show that the new methods require significantly fewer
function evaluations to achieve an accuracy that is comparable (or better) to
that of the classical methods.

</details>


### [17] [Augmented Lagrangian Method based adjoint space framework for sparse reconstruction of acoustic source with boundary measurements](https://arxiv.org/abs/2510.14805)
*Nirui Tan,Hongpeng Sun*

Main category: math.NA

TL;DR: A semismooth Newton-based augmented Lagrangian method for efficient reconstruction of sparse sources in inverse acoustic scattering problems.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient method for reconstructing sparse sources in inverse acoustic scattering problems, particularly when measurement data is much less than the acoustic source.

Method: Uses semismooth Newton method iterated in measurement space instead of source space, combined with augmented Lagrangian approach and Fenchel-Rockafellar duality theory for source calculation.

Result: The method achieves high efficiency with significant acceleration and reduced computational cost, as demonstrated by numerical examples.

Conclusion: The proposed semismooth Newton-based method is highly efficient for sparse source reconstruction in inverse acoustic scattering problems.

Abstract: We propose a semismooth Newton-based augmented Lagrangian method for
reconstructing sparse sources in inverse acoustic scattering problems. The
semismooth Newton method can be iterated in the space of measurements instead
of the unknown source to be reconstructed. It is highly efficient, especially
when the measurement data is much less than the acoustic source. The source can
be calculated from Fenchel-Rockafellar duality theory. We can obtain lots of
acceleration and leverage the computational cost. The numerical examples show
the high efficiency of the proposed semismooth Newton-based methods.

</details>


### [18] [Polynomial Preconditioning for Indefinite Matrices](https://arxiv.org/abs/2510.14816)
*Hayden Henson,Ronald B. Morgan*

Main category: math.NA

TL;DR: This paper presents improved polynomial preconditioning methods for indefinite matrices, including balancing techniques to create definite spectra, specialized stability approaches, and convergence analysis for real indefinite spectra.


<details>
  <summary>Details</summary>
Motivation: Polynomial preconditioning is crucial for solving large linear systems and eigenvalue problems, but existing methods have limitations when dealing with indefinite matrices that need to be addressed.

Method: The authors develop new techniques including: balancing polynomials to produce definite spectra, specialized stability approaches for indefinite cases, analysis of complex spectra, and convergence estimates for real indefinite spectra.

Result: The methods make polynomial preconditioning more generally applicable to indefinite matrices, with tests performed on finding interior eigenvalues.

Conclusion: The proposed techniques successfully extend polynomial preconditioning to handle indefinite matrices more effectively, improving its applicability for solving large linear systems and eigenvalue problems.

Abstract: Polynomial preconditioning is an important tool in solving large linear
systems and eigenvalue problems. A polynomial from GMRES can be used to
precondition restarted GMRES and restarted Arnoldi. Here we give methods for
indefinite matrices that make polynomial preconditioning more generally
applicable. The new techniques include balancing the polynomial so that it
produces a definite spectrum. Then a stability approach is given that is
specialized for the indefinite case. Also, very complex spectra are examined.
Then convergence estimates are given for polynomial preconditioning of real,
indefinite spectra. Finally, tests are preformed of finding interior
eigenvalues.

</details>


### [19] [Efficient and Robust Carathéodory-Steinitz Pruning of Positive Discrete Measures](https://arxiv.org/abs/2510.14916)
*Filip Bělík,Jesse Chan,Akil Narayan*

Main category: math.NA

TL;DR: Efficient streaming algorithm for Carathéodory-Steinitz pruning to compress positive discrete measures while preserving moments over finite-dimensional function spaces, using Givens rotations and on-demand storage.


<details>
  <summary>Details</summary>
Motivation: Need for efficient positive quadrature rules that preserve moments over finite-dimensional function spaces, with improved storage and computational efficiency compared to naive implementations.

Method: Streaming procedure using Givens rotations and on-demand storage arrays to prune large quadrature rules, with storage complexity depending only on function space dimension rather than original measure size.

Result: Algorithm achieves comparable runtimes to non-negative least squares and linear programming approaches, with improved stability and storage robustness. Successfully applied to generate quadrature for discontinuous Galerkin finite element simulations on cut-cell meshes.

Conclusion: The proposed streaming Carathéodory-Steinitz pruning method provides an efficient and stable approach for measure compression with reduced storage requirements, making it practical for large-scale applications.

Abstract: In many applications, one seeks to approximate integration against a positive
measure of interest by a positive discrete measure: a numerical quadrature rule
with positive weights. One common desired discretization property is moment
preservation over a finite dimensional function space, e.g., bounded-degree
polynomials. Carath\'{e}odory's theorem asserts that if there is any finitely
supported quadrature rule with more nodes than the dimension of the given
function space, one can form a smaller (and hence more efficient) positive,
nested, quadrature rule that preserves the moments of the original rule.
  We describe an efficient streaming procedure for Carath\'{e}odory-Steinitz
pruning, a numerical procedure that implements Carath\'{e}odory's theorem for
this measure compression. The new algorithm makes use of Givens rotations and
on-demand storage of arrays to successfully prune very large rules whose
storage complexity only depends on the dimension of the function space. This
approach improves on a naive implementation of Carath\'{e}odory-Steinitz
pruning whose runtime and storage complexity are quadratic and linear,
respectively, in the size of the original measure. We additionally prove
mathematical stability properties of our method with respect to a set of
admissible, total-variation perturbations of the original measure. Our method
is compared to two alternate approaches with larger storage requirements:
non-negative least squares and linear programming, and we demonstrate
comparable runtimes, with improved stability and storage robustness. Finally,
we demonstrate practical usage of this algorithm to generate quadrature for
discontinous Galerkin finite element simulations on cut-cell meshes.

</details>


### [20] [Rank of Matrices Arising out of Singular Kernel Functions](https://arxiv.org/abs/2510.14920)
*Sumit Singh,Sivaram Ambikasaran*

Main category: math.NA

TL;DR: This paper analyzes the rank of kernel matrices arising from particles arbitrarily distributed in adjacent hypercubes, providing theoretical bounds on expected rank and variance for various neighbor interactions, with applications to hierarchical matrix algorithms.


<details>
  <summary>Details</summary>
Motivation: Kernel functions are common in differential equations and machine learning, but the rank behavior of kernel matrices for arbitrarily distributed particles in adjacent domains wasn't formally studied, which is important for understanding hierarchical matrix algorithm performance.

Method: Model arbitrary particle distributions as random processes, derive theoretical bounds on expected rank and variance for different neighbor interactions, and validate with numerical experiments in 1D, 2D, and 3D.

Result: Obtained theoretical bounds on expected rank and variance of kernel matrices for arbitrary particle distributions, with numerical experiments confirming these predictions across different dimensions.

Conclusion: The work provides the first formal analysis of kernel matrix ranks for arbitrary particle distributions, with theoretical bounds that align with numerical experiments, offering insights for hierarchical matrix algorithm design and complexity analysis.

Abstract: Kernel functions are frequently encountered in differential equations and
machine learning applications. In this work, we study the rank of matrices
arising out of the kernel function $K: X \times Y \mapsto \mathbb{R}$, where
the sets $X, Y \in \mathbb{R}^d$ are hypercubes that share a boundary. The main
contribution of this work is the analysis of the rank of such matrices where
the particles (sources/targets) are arbitrarily distributed within these
hypercubes. To our knowledge, this is the first work to formally investigate
the rank of such matrices for an arbitrary distribution of particles. We model
the arbitrary distribution of particles to arise from an underlying random
distribution and obtain bounds on the expected rank and variance of the rank of
the kernel matrix corresponding to various neighbor interactions. These bounds
are useful for understanding the performance and complexity of hierarchical
matrix algorithms (especially hierarchical matrices satisfying the
weak-admissibility criterion) for an arbitrary distribution of particles. We
also present numerical experiments in one-, two-, and three-dimensions, showing
the expected rank growth and variance of the rank for different types of
interactions. The numerical results, not surprisingly, align with our
theoretical predictions.

</details>


### [21] [Finite element methods for electroneutral multicomponent electrolyte flows](https://arxiv.org/abs/2510.14923)
*Aaron Baier-Reinio,Patrick E. Farrell,Charles W. Monroe*

Main category: math.NA

TL;DR: A family of high-order finite element algorithms for simulating electroneutral electrolyte flows using NSOSM equations, handling complex boundary conditions and non-ideal thermodynamics.


<details>
  <summary>Details</summary>
Motivation: To develop flexible computational methods for simulating electrolyte flows in various physical configurations, including microfluidic devices and battery systems, while accounting for complex material behaviors.

Method: High-order finite element algorithms solving electroneutral Navier-Stokes-Onsager-Stefan-Maxwell equations, capable of handling steady/transient problems in 2D/3D with solution-dependent material parameters.

Result: Successfully demonstrated algorithms in multiple physical configurations including microfluidic rotating disk electrode and Hull cell flow of lithium-ion battery electrolyte mixtures.

Conclusion: The developed algorithms provide a comprehensive framework for simulating complex electrolyte flows with thermodynamic non-idealities and various boundary conditions.

Abstract: We present a broad family of high-order finite element algorithms for
simulating the flow of electroneutral electrolytes. The governing partial
differential equations that we solve are the electroneutral
Navier-Stokes-Onsager-Stefan-Maxwell (NSOSM) equations, which model momentum
transport, multicomponent diffusion and electrical effects within the
electrolyte. Our algorithms can be applied in the steady and transient
settings, in two and three spatial dimensions, and under a variety of boundary
conditions. Moreover, we allow for the material parameters (e.g. viscosity,
diffusivities, thermodynamic factors and density) to be solution-dependent and
thermodynamically non-ideal. The flexibility of our approach requires us to
address subtleties that arise in the governing equations due to the interplay
between boundary conditions and the equation of state. We demonstrate the
algorithms in various physical configurations, including (i) electrolyte flow
around a microfluidic rotating disk electrode and (ii) the flow in a Hull cell
of a cosolvent electrolyte mixture used in lithium-ion batteries.

</details>


### [22] [Efficient and Flexible Multirate Temporal Adaptivity](https://arxiv.org/abs/2510.14964)
*Daniel R. Reynolds,Sylvia Amihere,Dashon Mitchell,Vu Thai Luan*

Main category: math.NA

TL;DR: New multirate time step adaptivity controllers for embedded multirate infinitesimal (MRI) methods that improve performance and flexibility for problems with multiple time scales, including fifth-order embedded MRI methods.


<details>
  <summary>Details</summary>
Motivation: To develop effective adaptive time stepping for problems with multiple time scales using MRI methods, enabling high accuracy with low computational cost.

Method: Two new families of multirate time step adaptivity controllers designed for embedded MRI methods, plus new embeddings for explicit multirate exponential Runge-Kutta (MERK) methods of orders 2-5.

Result: Dramatically improved performance and flexibility compared to competing approaches, with each controller family excelling on different multirate applications. First-ever fifth-order embedded MRI method achieved.

Conclusion: The combination of embedded MRI methods and the proposed controllers enables adaptive simulations of problems with arbitrary time scales, providing guidance for selecting appropriate MRI methods and controllers.

Abstract: In this work we present two new families of multirate time step adaptivity
controllers, that are designed to work with embedded multirate infinitesimal
(MRI) time integration methods for adapting time steps when solving problems
with multiple time scales. We compare these controllers against competing
approaches on two benchmark problems and see that they offer dramatically
improved performance and flexibility, with each proposed family excelling on
different types of multirate applications. The combination of embedded MRI
methods and the proposed controllers enable adaptive simulations of problems
with a potentially arbitrary number of time scales, achieving high accuracy
while maintaining low computational cost. Additionally, we introduce a new set
of embeddings for the family of explicit multirate exponential Runge--Kutta
(MERK) methods of orders 2 through 5, resulting in the first-ever fifth-order
embedded MRI method. Finally, we compare the performance of a wide range of
embedded MRI methods on our benchmark problems to provide guidance on how to
select an appropriate MRI method and multirate controller.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [23] [Time-harmonic scattering of plane waves from an infinite periodically inhomogeneous medium](https://arxiv.org/abs/2510.14070)
*Guanghui Hu,Andreas Rathsfeld,Jiayi Zhang,Ruming Zhang*

Main category: math.AP

TL;DR: A new radiation condition for 2D periodic media with vertical periodicity and horizontal invariance, using Floquet theory to define wave modes and Dirichlet-to-Neumann maps for domain truncation.


<details>
  <summary>Details</summary>
Motivation: The classical Rayleigh-expansion radiation condition doesn't apply to vertically periodic media since it requires half-plane inhomogeneity, necessitating a new approach.

Method: Utilize Floquet theory to derive upward/downward wave modes, define radiation conditions via mode expansions, and develop Dirichlet-to-Neumann maps for domain truncation.

Result: Proved mapping properties of Dirichlet-to-Neumann maps based on high-order wave mode asymptotics, verified strong ellipticity of the sesquilinear form, and established unique solvability for almost all wavenumbers.

Conclusion: The proposed radiation condition successfully handles vertically periodic media, enabling domain truncation and ensuring well-posedness of the scattering problem for most wavenumbers.

Abstract: We propose a new radiation condition for an infinite inhomogeneous
two-dimensional medium which is periodic in the vertical direction and remains
invariant in the horizontal direction. The classical Rayleigh-expansion
radiation condition does not apply to our case, because this would require the
medium to be inhomogeneous in a half plane. We utilize the Floquet theory to
derive upward/downward wave modes and define radiation conditions by expansions
w.r.t. these modes. The downward radiation conditions leads to a downward
Dirichlet-to-Neumann map which can be used to truncate the infinite
inhomogeneous domain in the vertical direction. So we prove mapping properties
of the upward/downward Dirichlet-to-Neumann maps based on the asymptotic
behavior of high-order wave modes. Finally, we verify the strong ellipticity of
the sesquilinear form corresponding to the new scattering problem and show the
unique solvability for all wavenumbers with the exception of a countable set of
numbers bounded below by a small positive constant.

</details>


### [24] [Exponential and algebraic decay in Euler--alignment system with nonlocal interaction forces](https://arxiv.org/abs/2510.14123)
*José A. Carrillo,Young-Pil Choi,Dowan Koo,Oliver Tse*

Main category: math.AP

TL;DR: The paper analyzes the asymptotic behavior of pressureless Euler systems with nonlocal alignment and interaction forces, establishing quantitative convergence rates for classical solutions under various interaction potentials and communication weights.


<details>
  <summary>Details</summary>
Motivation: To characterize the asymptotic convergence of classical solutions in Euler-alignment systems with general interaction potentials and communication weights, providing a comprehensive understanding of how these systems evolve over time.

Method: Mathematical analysis of the pressureless Euler system with nonlocal velocity alignment and interaction forces, examining different settings: 1D with (λ,Λ)-convex potentials, Coulomb-quadratic potential, and multi-dimensional uniformly (λ,Λ)-convex potentials.

Result: Established quantitative convergence in three settings: exponential decay for bounded communication weights and algebraic rates for weakly singular ones. Density converges to minimizer of interaction energy, velocity aligns to uniform constant. Convergence rates depend only on local behavior of communication weights.

Conclusion: The study provides a comprehensive description of asymptotic behavior in Euler-alignment dynamics, showing that bounded kernels yield exponential convergence while weakly singular ones produce algebraic rates, with convergence rates depending solely on local behavior of communication weights.

Abstract: We investigate the large-time behavior of the pressureless Euler system with
nonlocal velocity alignment and interaction forces, with the aim of
characterizing the asymptotic convergence of classical solutions under general
interaction potentials $W$ and communication weights. We establish quantitative
convergence in three settings. In one dimension with $(\lambda,\Lambda)$-convex
potentials, i.e., potentials satisfying uniform lower and upper quadratic
bounds, bounded communication weights yield exponential decay, while weakly
singular ones lead to sharp algebraic rates. For the Coulomb--quadratic
potential $W(x)=-|x|+\frac12 |x|^2$, we prove exponential convergence for
bounded communication weights and algebraic upper bounds for singular
communication weights. In a multi-dimensional setting with uniformly
$(\lambda,\Lambda)$-convex potentials, we show exponential decay for bounded
weights and improved algebraic decay for singular ones. In all cases, the
density converges (up to translation) to the minimizer of the interaction
energy, while the velocity aligns to a uniform constant. A unifying feature is
that the convergence rate depends only on the local behavior of communication
weights: bounded kernels yield exponential convergence, while weakly singular
ones produce algebraic rates. Our results thus provide a comprehensive
description of the asymptotic behavior of Euler--alignment dynamics with
general interaction potentials.

</details>


### [25] [Reconstruction of the non-linear wave at a buoy from shoreline data and applications to the tsunami inverse problem for piece-wise sloping bathymetry](https://arxiv.org/abs/2510.14177)
*Oleksandr Bobrovnikov,Madison Jones,Shriya Prasanna,Josiah Smith,Alexei Rybkin,Efim Pelinovsky*

Main category: math.AP

TL;DR: This paper studies the inverse problem of recovering tsunami initial shape from run-up data using non-linear shallow water equations, extending previous work to finite sloping bathymetry and incorporating dispersion effects.


<details>
  <summary>Details</summary>
Motivation: To solve the inverse problem of determining tsunami initial conditions from shoreline run-up data, building on previous work that assumed infinite sloping bathymetry.

Method: Uses non-linear shallow water equations framework, extends to finite sloping bathymetry, recovers boundary conditions from shoreline data, and combines shallow water equations with Boussinesq equation for piece-wise sloping bathymetry to incorporate dispersion.

Result: Shows that boundary conditions (water displacement and velocity) on a virtual buoy can be recovered from shoreline data in finite sloping bathymetry.

Conclusion: The proposed approach enables recovery of tsunami initial conditions from run-up data while accounting for finite bathymetry and dispersion effects through combined shallow water and Boussinesq equations.

Abstract: We discuss the following inverse problem: given the run-up data of a tsunami
wave, can we recover its initial shape? We study this problem within the
framework of the non-linear shallow water equations, a model widely used to
study tsunami propagation and inundation. Previously, it has been demonstrated
that in the case of infinite sloping bathymetry, it is possible to recover the
initial water displacement and velocity from shoreline readings
\cite{Rybkin23,Rybkin24,Rybkin25}.
  We consider a finite sloping bathymerty. We show that it is possible to
recover boundary conditions (water displacement and velocity) on a virtual buoy
from the shoreline data. Further, we discuss stitching together the shallow
water equations and the Boussinesq equation in a more complex piece-wise
sloping bathymetry in order to recover the initial conditions, while
incorporating the dispersion to our model.

</details>


### [26] [Propagation speed of traveling waves for diffusive Lotka-Volterra system with strong competition](https://arxiv.org/abs/2510.14311)
*Ken-Ichi Nakamura,Toshiko Ogiwara*

Main category: math.AP

TL;DR: This paper analyzes bistable traveling waves in the two-component diffusive Lotka-Volterra system under strong competition, focusing on determining the sign of propagation speed to predict invasion outcomes.


<details>
  <summary>Details</summary>
Motivation: The sign of propagation speed determines long-term competition outcomes between species and predicts invasion success/failure of alien species into native habitats, which is crucial for ecological forecasting.

Method: Using comparison arguments to establish sufficient conditions determining the sign of propagation speed, refining previous results and analyzing symmetric cases and parameter variations.

Result: In symmetric cases, faster diffusers prevail over broader parameter ranges than previously known. When interspecific competition coefficients differ significantly, competition outcomes cannot be reversed by adjusting diffusion or growth rates.

Conclusion: The findings provide a rigorous theoretical framework with sharper mathematical criteria for analyzing invasion dynamics and predicting invasion success or failure.

Abstract: We study the propagation speed of bistable traveling waves in the classical
two-component diffusive Lotka-Volterra system under strong competition. From an
ecological perspective, the sign of the propagation speed determines the
long-term outcome of competition between two species and thus plays a central
role in predicting the success or failure of invasion of an alien species into
habitats occupied by a native species. Using comparison arguments, we establish
sufficient conditions determining the sign of the propagation speed, which
refine previously known results. In particular, we show that in the symmetric
case, where the two species differ only in their diffusion rates, the faster
diffuser prevails over a substantially broader parameter range than previously
established. Moreover, we demonstrate that when the interspecific competition
coefficients differ significantly, the outcome of competition cannot be
reversed by adjusting diffusion or growth rates. These findings provide a
rigorous theoretical framework for analyzing invasion dynamics, offering
sharper mathematical criteria for invasion success or failure.

</details>


### [27] [Sobolev regularity for the perturbed fractional 1-Laplace equations in the subquadratic case](https://arxiv.org/abs/2510.14346)
*Dingding Li,Chao Zhang*

Main category: math.AP

TL;DR: This paper analyzes Sobolev regularity of solutions to perturbed fractional 1-Laplace equations, showing that under local boundedness assumptions, the regularity properties are analogous to the superquadratic case.


<details>
  <summary>Details</summary>
Motivation: To establish regularity properties for solutions to perturbed fractional 1-Laplace equations, which are nonlocal and singular problems, and to extend the understanding of such equations beyond the superquadratic case.

Method: The analysis uses the nonlocal finite-difference quotient method combined with a Moser-type iteration scheme to systematically approach the regularity theory for these nonlocal and singular problems.

Result: The paper demonstrates that for $s_p\in \left(0, \frac{p-1}{p}\right]$ and $q\ge p$, solutions have $W_{\rm loc}^{\gamma, q}$-regularity for all $\gamma\in \left(0, \frac{s_p p}{p-1}\right)$, and for $s_p\in \left(\frac{p-1}{p}, 1\right)$ and $q\ge p$, solutions have $W_{\rm loc}^{1, q}$-regularity.

Conclusion: The regularity properties of solutions to perturbed fractional 1-Laplace equations are analogous to those in the superquadratic case, with the threshold $\frac{p-1}{p}$ dividing the parameter range into two distinct regularity scenarios.

Abstract: This work investigates the Sobolev regularity of solutions to perturbed
fractional 1-Laplace equations. Under the assumption that weak solutions are
locally bounded, we establish that the regularity properties are analogous to
those observed in the superquadratic case. By introducing the threshold
$\frac{p-1}{p}$, we divide the range of the parameter $s_p$ into two distinct
scenarios. Specifically, for any $s_p\in \left(0, \frac{p-1}{p}\right]$ and
$q\ge p$, we demonstrate that the solutions possess $W_{\rm loc}^{\gamma,
q}$-regularity for all $\gamma\in \left(0, \frac{s_p p}{p-1}\right)$ and the
$W_{\rm loc}^{1, q}$-regularity for any $s_p\in \left(\frac{p-1}{p}, 1\right)$
and $q\ge p$, respectively. Our analysis relies on the nonlocal
finite-difference quotient method combined with a Moser-type iteration scheme,
which provides a systematic approach to the regularity theory for such nonlocal
and singular problems.

</details>


### [28] [Viscosity solutions posed on star-shaped network with Kirchhoff's boundary condition: Well-posedness](https://arxiv.org/abs/2510.14364)
*Isaac Ohavi*

Main category: math.AP

TL;DR: Establishes well-posedness for fully nonlinear PDEs on star-shaped networks with nonlinear Kirchhoff boundary conditions, including degenerate cases. Proves comparison theorem for discontinuous viscosity solutions and shows equivalence between generalized and standard Kirchhoff viscosity solutions.


<details>
  <summary>Details</summary>
Motivation: To address the mathematical challenges of fully nonlinear PDEs on networks with nonlinear Kirchhoff boundary conditions, particularly dealing with degenerate cases and establishing proper solution frameworks.

Method: Uses comparison theorem for discontinuous viscosity solutions following Ohavi's approach, building test functions at vertices as solutions of Eikonal equations with carefully designed coefficients.

Result: Proves that any generalized Kirchhoff viscosity solution (Lions-Souganidis framework) is equivalent to a standard Kirchhoff viscosity solution, eliminating the need for Hamiltonian values at vertices in PDE analysis.

Conclusion: The work successfully establishes well-posedness for these complex PDE systems and provides a simplified framework by showing equivalence between solution concepts, making vertex Hamiltonian values unnecessary.

Abstract: The aim of this work is to establish the well-posedness of fully nonlinear
partial differential equations (PDE) posed on a star-shaped network, having
nonlinear Kirchhoff's boundary condition at the vertex, and possibly
degenerate. We obtain a comparison theorem, for discontinuous viscosity
solutions, following the recent ideas obtained by Ohavi for second order
problems, building test functions at the vertex solutions of Eikonal equations
with well-designed coefficients. Another strong result obtained in this
contribution is to show that any generalized Kirchhoff's viscosity solution
introduced by Lions-Souganidis, is indeed a Kirchhoff's viscosity solution. In
other terms, the values of the Hamiltonians are not required at the vertex in
the analysis of these types of PDE systems.

</details>


### [29] [Parabolic PDEs on a fixed domain with evolving subdomains: function spaces and well-posedness](https://arxiv.org/abs/2510.14373)
*Van Chien Le,Karel Van Bockstal*

Main category: math.AP

TL;DR: Develops variational framework for parabolic PDEs with evolving subdomains, including function spaces for discontinuous coefficients, density results, embedding theory, and well-posedness proof.


<details>
  <summary>Details</summary>
Motivation: To handle initial boundary-value problems of parabolic PDEs on domains with evolving subdomains, where coefficients may be discontinuous across moving interfaces.

Method: Extends Sobolev-Bochner spaces to accommodate discontinuous coefficients, develops mollification techniques and Reynolds transport theorem extensions, establishes embedding theory and integration by parts formulas, and applies Banach-Necas-Babuska theorem.

Result: Proves density of smooth functions in the extended function spaces, establishes embedding theory, derives integration by parts formula, and demonstrates well-posedness of the space-time variational formulation.

Conclusion: Provides complete mathematical foundation for variational approach to parabolic PDEs with evolving subdomains and discontinuous coefficients, ensuring well-posedness in natural function space settings.

Abstract: This paper develops the necessary ingredients for the variational approach of
initial boundary-value problems of parabolic partial differential equations on
a fixed spatial domain containing evolving subdomains. In particular, we
introduce function spaces for the variational solution that extend standard
Sobolev-Bochner spaces to account for a coefficient associated with the time
derivative that may be discontinuous across the evolving interface. We further
show the density of smooth functions in these spaces by extending the
mollification technique and the Reynolds transport theorem, and establish the
corresponding "embedding" theory and an integration by parts formula. Finally,
we prove the well-posedness of the space-time variational formulation in the
natural setting using the Banach-Necas-Babuska theorem.

</details>


### [30] [Quantitative stability of a class of explicit steady Euler flows in a disk](https://arxiv.org/abs/2510.14394)
*Fatao Wang,Guodong Wang*

Main category: math.AP

TL;DR: Short proof of L²-orbital stability for explicit steady Euler flows in a disk using conserved quantities.


<details>
  <summary>Details</summary>
Motivation: To establish orbital stability of steady Euler flows and investigate how radial symmetry affects stability.

Method: Exploit conserved quantities of Euler equation: kinetic energy, enstrophy, and moment of fluid impulse to derive quantitative estimate.

Result: Proved L²-orbital stability for class of explicit steady Euler flows in disk; suggests more radial symmetry leads to stronger instability.

Conclusion: Successfully established orbital stability using conserved quantities, revealing inverse relationship between radial symmetry and stability.

Abstract: We provide a short proof of the $L^2$-orbital stability of a class of
explicit steady Euler flows in a disk by establishing a quantitative estimate.
The main idea is to exploit the conserved quantities of the Euler equation,
including the kinetic energy, the enstrophy, and the moment of fluid impulse.
Our result seems to suggest that more radial symmetry leads to stronger
instability.

</details>


### [31] [On some Elliptic and Parabolic Problems Involving the Anisotropic $p(u)$-Laplacian](https://arxiv.org/abs/2510.14432)
*Kaushik Bal,Shilpa Gupta*

Main category: math.AP

TL;DR: Study of elliptic and parabolic PDEs with p(u) Laplacian using variable exponent Sobolev spaces in anisotropic framework.


<details>
  <summary>Details</summary>
Motivation: To analyze PDEs with p(u) Laplacian that require specialized variable exponent Sobolev spaces for anisotropic settings.

Method: Elliptic case: pseudomonotone operators with approximation techniques. Parabolic case: time discretization scheme with Schauder fixed-point theorem, a priori estimates, and compactness arguments.

Result: Established existence of weak solutions for both elliptic and parabolic cases.

Conclusion: Successfully proved existence of weak solutions for p(u) Laplacian driven PDEs using appropriate functional analysis tools in both elliptic and parabolic settings.

Abstract: We investigate a class of elliptic and parabolic partial differential
equations driven by p(u) laplacian. This dependence necessitates the use of
variable exponent Sobolev spaces specifically tailored to the anisotropic
framework. For the elliptic case, we establish the existence of a weak solution
by employing the theory of pseudomonotone operators in conjunction with
suitable approximation techniques. In the parabolic setting, the existence of a
weak solution is obtained via a time discretization scheme and Schauder
fixed-point theorem, supported by a priori estimates and compactness arguments.

</details>


### [32] [Small-time approximate controllability of the logarithmic Schr\''dinger equation](https://arxiv.org/abs/2510.14461)
*Karine Beauchard,Rémi Carles,Eugenio Pozzoli*

Main category: math.AP

TL;DR: The paper proves small-time global L²-approximate controllability for Schrödinger equations with logarithmic nonlinearity and bilinear controls on torus or Euclidean space.


<details>
  <summary>Details</summary>
Motivation: To establish the first result of small-time global approximate controllability for nonlinear Schrödinger equations with bilinear controls, extending previous linear control approaches to the nonlinear framework.

Method: Extends the approach from linear control theory by combining small-time controllability of phases and gradient flows, using WKB analysis to handle the nonlinearity and establish required estimates.

Result: Successfully proves small-time global L²-approximate controllability for Schrödinger equations with logarithmic nonlinearity and bilinear controls.

Conclusion: This represents the first achievement of small-time global approximate controllability for nonlinear Schrödinger equations using bilinear controls, with the nonlinear case requiring more sophisticated analysis than the linear counterpart.

Abstract: We consider Schr{\"o}dinger equations with logarithmic nonlinearity and
bilinear controls, posed on $\mathbb{T}^d$ or $\mathbb{R}^d$. We prove their
small-time global $L^2$-approximate controllability. The proof consists in
extending to this nonlinear framework the approach introduced by the first and
third authors in \cite{beauchard-pozzoli2} to control the linear equation: it
combines the small-time controllability of phases and gradient flows. Due to
the nonlinearity, the required estimates are more difficult to establish than
in the linear case. The proof here is inspired by WKB analysis. This is the
first result of (small-time) global approximate controllability, for nonlinear
Schr{\"o}dinger equations, with bilinear controls.

</details>


### [33] [An $L^\infty$-variational problem involving the Fractional Laplacian](https://arxiv.org/abs/2510.14476)
*Simone Carano,Roger Moser*

Main category: math.AP

TL;DR: Existence and uniqueness of absolute minimizers for fractional supremal functional with Dirichlet boundary conditions, and characterization via fractional PDE with s-harmonic measure.


<details>
  <summary>Details</summary>
Motivation: Study minimizers of fractional supremal functionals involving the Fractional Laplacian, extending classical infinity Laplacian theory to nonlocal operators.

Method: Prove existence and uniqueness of absolute minimizers for the functional E∞(u)=∥(−Δ)su∥L∞(ℝⁿ) with prescribed Dirichlet data outside Ω.

Result: Absolute minimizer u∞ exists and is unique, satisfying the fractional PDE (−Δ)su∞=E∞(u∞) sgn f∞ in Ω, where f∞ comes from an s-harmonic measure.

Conclusion: Fractional infinity Laplacian minimizers exist uniquely and satisfy a specific fractional PDE characterization involving s-harmonic measures.

Abstract: For $s\in(0,1)$ and an open bounded set $\Omega\subset\mathbb R^n$, we prove
existence and uniqueness of absolute minimisers of the supremal functional
$$E_\infty(u)=\|(-\Delta)^s u\|_{L^\infty(\mathbb R^n)},$$ where $(-\Delta)^s$
is the Fractional Laplacian of order $s$ and $u$ has prescribed Dirichlet data
in the complement of $\Omega$. We further show that the minimiser $u_\infty$
satisfies the (fractional) PDE $$ (-\Delta)^s
u_\infty=E_\infty(u_\infty)\,\mathrm{sgn}f_\infty \qquad\mbox{in }\Omega, $$
for some analytic function $f_\infty\in L^1(\Omega)$ obtained as the
restriction of an $s$-harmonic measure $\mu$ in $\Omega$.

</details>


### [34] [Maxwell's equations with mixed impedance boundary conditions](https://arxiv.org/abs/2510.14600)
*Ben Schweizer,David Wiedemann*

Main category: math.AP

TL;DR: Fredholm alternative for time-harmonic Maxwell equations with matrix-valued impedance boundary conditions on Lipschitz domains, including singular coefficients.


<details>
  <summary>Details</summary>
Motivation: To establish existence of weak solutions for Maxwell equations with general impedance boundary conditions, particularly handling polarization-dependent and singular impedance coefficients.

Method: Derived a Fredholm alternative framework for the time-harmonic Maxwell system with matrix-valued impedance boundary conditions on bounded Lipschitz domains.

Result: Obtained existence of weak solutions for arbitrary sources when frequency is not a resonance frequency, covering cases with singular impedance coefficients.

Conclusion: The Fredholm alternative provides a rigorous framework for analyzing Maxwell equations with general impedance boundary conditions, ensuring solution existence under non-resonant conditions.

Abstract: We study the time-harmonic Maxwell equations on bounded Lipschitz domains
with an impedance boundary condition. The impedance coefficient can be matrix
valued such that, in particular, a polarization dependent impedance is modeled.
We derive a Fredholm alternative for this system. As a consequence, we obtain
the existence of weak solutions for arbitrary sources when the frequency is not
a resonance frequency. Our analysis covers the case of singular impedance
coefficients.

</details>


### [35] [Unique continuation and stabilization for nonlinear Schrödinger equations under the Geometric Control Condition](https://arxiv.org/abs/2510.14632)
*Cristóbal Loyola*

Main category: math.AP

TL;DR: This paper proves global propagation of analyticity for semilinear Schrödinger equations with analytic nonlinearity in regions satisfying the Geometric Control Condition, leading to unique continuation results and answering an open question from 2006.


<details>
  <summary>Details</summary>
Motivation: To address the problem of propagating analyticity in semilinear Schrödinger equations and solve the open question posed by Dehman, Gérard, and Lebeau in 2006 regarding unique continuation for nonlinear cases.

Method: Refines a technique combining control theory and Galerkin approximation to propagate analyticity from zones where observability holds, using the Geometric Control Condition on the observation zone.

Result: Established global propagation of analyticity in finite time, unique continuation for subcritical semilinear Schrödinger equations on compact manifolds of dimensions 2 and 3, and semiglobal control and stabilization under Geometric Control Condition.

Conclusion: The approach successfully answers the open question from 2006 and provides a framework for propagating analyticity and achieving unique continuation in semilinear Schrödinger equations with analytic nonlinearity.

Abstract: In this article we prove global propagation of analyticity in finite time for
solutions of semilinear Schr\"odinger equations with analytic nonlinearity from
a region $\omega$ where the Geometric Control Condition holds. Our approach
refines a recent technique introduced by Laurent and the author, which combines
control theory techniques and Galerkin approximation, to propagate analyticity
in time from a zone where observability holds. As a main consequence, we obtain
unique continuation for subcritical semilinear Schr\"odinger equations on
compact manifolds of dimension $2$ and $3$ when the solution is assumed to
vanish on $\omega$. Furthermore, semiglobal control and stabilization follow
only under the Geometric Control Condition on the observation zone. In
particular, this answers in the affirmative an open question of Dehman,
G\'erard, and Lebeau from $2006$ for the nonlinear case.

</details>


### [36] [The simultaneous effect of chemotaxis and alarm-taxis on the global existence and stability of a predator-prey system](https://arxiv.org/abs/2510.14728)
*Gnanasekaran Shanmugasundaram,Jitraj Saha,Rafael Díaz Fuentes*

Main category: math.AP

TL;DR: Analysis of a fully parabolic predator-prey chemo-alarm-taxis system showing global bounded classical solutions and convergence through Lyapunov functionals, with numerical validation.


<details>
  <summary>Details</summary>
Motivation: To understand the role of chemotaxis and alarm-taxis coefficients in determining existence and stability of predator-prey models under specific parameter conditions.

Method: Mathematical analysis of PDE system with homogeneous Neumann boundary conditions, construction of Lyapunov functional for convergence, and numerical simulations for validation.

Result: The system admits unique globally bounded classical solutions, and solution convergence is established. Numerical simulations confirm asymptotic behavior.

Conclusion: Chemotaxis and alarm-taxis coefficients play significant roles in predator-prey model existence and stability, as demonstrated through analytical and numerical approaches.

Abstract: This study examines a fully parabolic predator-prey chemo-alarm-taxis system
under homogeneous Neumann boundary conditions in a bounded domain $\Omega
\subset \mathbb{R}^n$ with a smooth boundary $\partial\Omega$. Under specific
parameter conditions, it is shown that the system admits a unique, globally
bounded classical solution. The convergence of the solution is established
through the construction of an appropriate Lyapunov functional. In addition,
numerical simulations are presented to validate the asymptotic behaviour of the
solution. The results highlight the significant role of chemotaxis and
alarm-taxis coefficients in determining the existence and stability of
predator-prey models, as discussed in the literature.

</details>


### [37] [Stable Type I blow-up for the one-dimensional wave equation with time-derivative nonlinearity](https://arxiv.org/abs/2510.14815)
*Oliver Gough*

Main category: math.AP

TL;DR: This paper studies finite-time blow-up for a 1D nonlinear wave equation with quadratic time-derivative nonlinearity. It proves non-existence of smooth exact self-similar blow-up profiles but constructs explicit generalized self-similar solutions that exhibit type-I blow-up and are asymptotically stable under small perturbations.


<details>
  <summary>Details</summary>
Motivation: To understand blow-up behavior in nonlinear wave equations, particularly extending previous work on spatial-derivative analogues to time-derivative nonlinearities, and to investigate the stability of blow-up profiles.

Method: Building on previous work, the authors establish non-existence of smooth exact self-similar profiles, then construct explicit families of generalized self-similar solutions bifurcating from ODE blow-up. They prove asymptotic stability of these profiles under small perturbations in energy topology.

Result: The paper shows that spatially homogeneous ODE blow-up is not asymptotically stable, and provides explicit generalized self-similar solutions that are smooth within past light cones and exhibit type-I blow-up at prescribed points.

Conclusion: The study reveals important insights into blow-up mechanisms for nonlinear wave equations with time-derivative nonlinearities, demonstrating the existence and stability of generalized self-similar blow-up profiles that differ from simple ODE blow-up behavior.

Abstract: We study finite-time blow-up for the one-dimensional nonlinear wave equation
with a quadratic time-derivative nonlinearity, \[ u_{tt}-u_{xx}=(u_t)^2,\qquad
(x,t)\in\mathbb R\times[0,T). \] Building on the work of Ghoul, Liu, and
Masmoudi \cite{ghoul2025blow} on the spatial-derivative analogue, we establish
the non-existence of smooth, exact self-similar blow-up profiles. Instead we
construct an explicit family of \emph{generalised self-similar} solutions,
bifurcating from the ODE blow-up, that are smooth within the past light cone
and exhibit type-I blow-up at a prescribed point \((x_0,T)\). We further prove
asymptotic stability of these profiles under small perturbations in the energy
topology. In particular, these profiles verify that the spatially homogeneous
ODE blow-up is not asymptotically stable.

</details>


### [38] [Vortex lines interaction in the three-dimensional magnetic Ginzburg--Landau model](https://arxiv.org/abs/2510.14910)
*Carlos Román,Etienne Sandier,Sylvia Serfaty*

Main category: math.AP

TL;DR: The paper studies the 3D Ginzburg-Landau functional with magnetic field near the first critical field H_c1, showing vortex filaments appear one by one as magnetic field increases, with precise asymptotic expansions and energy minimization.


<details>
  <summary>Details</summary>
Motivation: To understand the precise behavior of vortex filaments in superconductors near the first critical field H_c1, including how vortices appear sequentially and their optimal configurations.

Method: Asymptotic analysis of the Ginzburg-Landau functional as ε→0, derivation of next order energy expansions, and study of vortex line interactions through logarithmic repulsion and magnetic confinement near a special curve Γ0.

Result: Shows that vortex lines appear one by one with field increments of order log|logε|, accumulate near curve Γ0, and minimize an energy functional balancing line length, repulsion, and confinement.

Conclusion: The analysis elucidates the shape and arrangement of vortex lines in superconductors, providing a detailed understanding of their emergence and optimal configurations near the first critical field.

Abstract: We complete our study of the three dimensional Ginzburg--Landau functional
with magnetic field, in the asymptotic regime of a small inverse
Ginzburg--Landau parameter $\varepsilon$, and near the first critical field
$H_{c_1}$ for which the first vortex filaments appear in energy minimizers.
Under a nondegeneracy condition, we show a next order asymptotic expansion of
$H_{c_1}$ as $\varepsilon \to 0$, and exhibit a sequence of transitions, with
vortex lines appearing one by one as the intensity of the applied magnetic
field is increased: passing $H_{c_1}$ there is one vortex, then increasing
$H_{c_1}$ by an increment of order $\log |\log\varepsilon|$ a second vortex
line appears, etc. These vortex lines accumulate near a special curve
$\Gamma_0$, solution to an isoflux problem. We derive a next order energy that
the vortex lines must minimize in the asymptotic limit, after a suitable
horizontal blow-up around $\Gamma_0$. This energy is the sum of terms where
penalizations of the length of the lines, logarithmic repulsion between the
lines and magnetic confinement near $\Gamma_0$ compete. This elucidates the
shape of vortex lines in superconductors.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [39] [Surrogate Models for Linear Response](https://arxiv.org/abs/2510.13989)
*L. Jin,A. Ravlić,P. Giuliani,K. Godbey,W. Nazarewicz*

Main category: physics.comp-ph

TL;DR: The paper presents two QRPA surrogate models for nuclear response functions that achieve 0.1%-1% accuracy with 6-7 orders of magnitude speedup compared to standard QRPA solvers.


<details>
  <summary>Details</summary>
Motivation: Standard QRPA methods have high computational costs that limit model calibration and uncertainty quantification studies in nuclear physics.

Method: Two complementary QRPA surrogate models: a reduced-order model exploiting QRPA structure, and a parametric matrix model algorithm mapping Hamiltonian to observables.

Result: Benchmark applications on electric dipole polarizability of 180Yb and β-decay half-life of 80Ni show 0.1%-1% accuracy with 10^6-10^7 speedup.

Conclusion: The developed QRPA emulators enable Bayesian calibration and large-scale studies of computationally expensive many-body physics models.

Abstract: Linear response theory is a well-established method in physics and chemistry
for exploring excitations of many-body systems. In particular, the
quasiparticle random-phase approximation (QRPA) provides a powerful microscopic
framework by building excitations on top of the mean-field vacuum; however, its
high computational cost limits model calibration and uncertainty quantification
studies. Here, we present two complementary QRPA surrogate models and apply
them to study response functions of finite nuclei. One is a reduced-order model
that exploits the underlying QRPA structure, while the other utilizes the
recently developed parametric matrix model algorithm to construct a map between
the system's Hamiltonian and observables. Our benchmark applications, the
calculation of the electric dipole polarizability of ${}^{180}$Yb and the
$\beta$-decay half-life of ${}^{80}$Ni, show that both emulators can achieve
0.1\%--1\% accuracy while offering a six to seven orders of magnitude speedup
compared to state-of-the-art QRPA solvers. These results demonstrate that the
developed QRPA emulators are well-positioned to enable Bayesian calibration and
large-scale studies of computationally expensive physics models describing the
properties of many-body systems.

</details>


### [40] [Anti-Interference Communication Using Computational Antenna](https://arxiv.org/abs/2510.14362)
*Xiaocun Zong,Fan Yang,Shenheng Xu,Maokun Li*

Main category: physics.comp-ph

TL;DR: A novel anti-interference communication method using computational antennas with 1-bit RIS and time averaging, achieving robust signal modulation with minimal hardware complexity and no additional spectral overhead.


<details>
  <summary>Details</summary>
Motivation: To develop robust anti-interference communication that doesn't require significant spectral resources like conventional spread spectrum or frequency hopping techniques, addressing the need for reliable communication under strong interference conditions.

Method: Developed a communication model for computational antennas and proposed an efficient signal processing algorithm optimized for temporal modulation. Established a USRP-based experimental platform to validate the approach under strong interference conditions (5 dB jamming-to-signal ratio).

Result: Experimental results show up to 80.9% reduction in bit error rate (BER) and effective restoration of distorted images in transmission tests. Superior anti-interference performance compared to conventional techniques without additional spectral overhead.

Conclusion: The proposed method provides valuable insights for radar detection, military communications, and next-generation wireless networks, offering robust anti-interference capabilities with minimal hardware complexity and no spectral resource requirements.

Abstract: This letter proposes a novel anti-interference communication method
leveraging computational antennas, utilizing time averaging and 1-bit
reconfigurable intelligent surfaces (RIS) to achieve robust signal modulation
with minimal hardware complexity. We develop a communication model for
computational antennas and propose an efficient signal processing algorithm
optimized for temporal modulation. A USRP-based experimental platform is
established to validate the approach under strong interference conditions
(e.g., 5 dB jamming-to-signal ratio). Experimental results reveal up to an
80.9\% reduction in bit error rate (BER) and effective restoration of distorted
images in transmission tests. Compared to conventional techniques like spread
spectrum or frequency hopping, which require significant spectral resources,
our method offers superior anti-interference performance without additional
spectral overhead. This research provides valuable insights for radar
detection, military communications, and next-generation wireless networks.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [41] [Structure of self-generated magnetic fields in laser-solid interaction from proton tomography](https://arxiv.org/abs/2510.14076)
*Jesse Griff-McMahon,Christopher A. Walsh,Vicente Valenzuela-Villaseca,Sophia Malko,Brendan McCluskey,Kirill Lezhnin,Huws Landsberger,Laura Berzak Hopkins,Gennady Fiksel,Michael J. Rosenberg,Derek B. Schaeffer,William Fox*

Main category: physics.plasm-ph

TL;DR: Experimental characterization of 3D magnetic fields in laser-solid interactions using multi-view proton radiography and tomographic inversion, validating improved MHD simulations.


<details>
  <summary>Details</summary>
Motivation: To experimentally characterize the 3D location and strength of self-generated magnetic fields in laser-solid interactions, rather than relying on path-integrated measurements.

Method: Multi-view proton radiography and tomographic inversion on the OMEGA laser, used to validate MHD simulations with improved magnetic transport modeling.

Result: Inferred magnetic fields extend several millimeters off target surface into corona, sufficient to strongly magnetize plasma. Achieved reasonable agreement only with models incorporating magnetic field re-localization of transport.

Conclusion: Demonstrates tomographic inversion in proton radiography as a valuable tool for investigating magnetic fields in laser-produced plasmas.

Abstract: Strong magnetic fields are naturally self-generated in high-power,
laser-solid interactions through the Biermann-battery mechanism. This work
experimentally characterizes the 3D location and strength of these fields,
rather than path-integrated quantities, through multi-view proton radiography
and tomographic inversion on the OMEGA laser. We infer magnetic fields that
extend several millimeters off the target surface into the hot, rarefied corona
and are sufficient to strongly magnetize the plasma ($\Omega_{e}\tau_e \gg 1$).
The data is used to validate MHD simulations incorporating recent improvements
in magnetic transport modeling; we achieve reasonable agreement only with
models with re-localization of transport by magnetic fields. This work provides
a key demonstration of tomographic inversion in proton radiography, offering a
valuable tool for investigating magnetic fields in laser-produced plasmas.

</details>


### [42] [Plasma Confinement State Classification via FPP Relevant Microwave Diagnostics](https://arxiv.org/abs/2510.14078)
*Randall Clark,Vacslav Glukhov,Georgy Subbotin,Maxim Nurgaliev,Aleksandr Kachkin,Max Austin,Dmitri M. Orlov*

Main category: physics.plasm-ph

TL;DR: A minimalist machine learning approach using only electron cyclotron emission signals achieves 96% accuracy in identifying plasma confinement states in fusion power plants, enabling reliable operation with limited diagnostics.


<details>
  <summary>Details</summary>
Motivation: Fusion power plants require reliable identification of plasma confinement states (L-mode and H-mode) for safe operation, but must operate with severely constrained diagnostic sets unlike research devices.

Method: Uses only electron cyclotron emission signals as input, extracts features with radial basis functions, and applies a gradient boosting classifier for state classification.

Result: Achieves high accuracy with test accuracy averaging 96% correct predictions, with robustness analysis and feature importance study confirming reliability.

Conclusion: State-of-the-art performance is attainable from restricted diagnostic sets, paving the way for minimalist yet resilient plasma control architectures for fusion power plants.

Abstract: We present a parsimonious and robust machine learning approach for
identifying plasma confinement states in fusion power plants (FPPs) where
reliable identification of the low-confinement (L-mode) and high-confinement
(H-mode) regimes is critical for safe and efficient operation. Unlike
research-oriented devices, FPPs must operate with a severely constrained set of
diagnostics. To address this challenge, we demonstrate that a minimalist model,
using only electron cyclotron emission (ECE) signals, can deliver accurate and
reliable state classification. ECE provides electron temperature profiles
without the engineering or survivability issues of in-vessel probes, making it
a primary candidate for FPP-relevant diagnostics. Our framework employs ECE as
input, extracts features with radial basis functions, and applies a gradient
boosting classifier, achieving high accuracy with test accuracy averaging 96\%
correct predictions. Robustness analysis and feature importance study confirm
the reliability of the approach. These results demonstrate that
state-of-the-art performance is attainable from a restricted diagnostic set,
paving the way for minimalist yet resilient plasma control architectures for
FPPs.

</details>


### [43] [Three-dimensional unmagnetized Mach probe analysis and initial flow measurements in reversed-field pinch experiments](https://arxiv.org/abs/2510.14212)
*K. J. McCollam,R. Reksoatmodjo,J. von der Linden,J. Sears,S. You,H. Himura,A. F. Almagri,M. Reyfman,C. C. Rouda,J. S. Sarff,A. M. Sellner*

Main category: physics.plasm-ph

TL;DR: A novel matrix method for analyzing ion saturation current data from 3D Mach probe arrays is developed and applied to measure plasma flow velocity in RFP experiments on MST.


<details>
  <summary>Details</summary>
Motivation: To enable accurate local plasma flow velocity measurements using 3D arrays of unmagnetized Mach probe tips in reversed-field pinch experiments.

Method: Developed a matrix analysis method for ion saturation current data from 3D Mach probe arrays (6-tip octahedral and 4-tip tetrahedral configurations), with uncertainty analysis based on probe machining and measurement errors.

Result: Initial measurements show flow speeds of expected magnitudes but with some directional differences for the octahedral probe, and similar directions but larger than expected speeds for the tetrahedral probe.

Conclusion: The matrix method successfully facilitates 3D Mach probe analysis, though initial results show some unexpected findings possibly related to probe conditioning and fast electron effects that require further investigation.

Abstract: A novel matrix method of analyzing ion saturation current data from a general
three-dimensional (3D) array of unmagnetized Mach probe tips is developed and
used with data sets from two 3D Mach probes to make initial measurements of
local plasma flow velocity in reversed-field pinch (RFP) experiments in the
Madison Symmetric Torus (MST). The two 3D Mach probes are composed of regular
polyhedral arrays of six and four tips, respectively, with the six-tip array
composed of three orthogonal pairs of mutually opposite tips at the vertices of
a regular octahedron and the four-tip array composed of non-opposite tips at
the vertices of a regular tetrahedron, the analysis of which is specifically
facilitated by the matrix method. Velocity measurement uncertainties for the
Mach probes are derived based on uncertainties in probe machining and ion
saturation current measurements, and typical relative uncertainties for the
probes are estimated to be of order several percent, likely smaller than
systematic uncertainties related to the Mach probe calibration constant and
experimental uncertainties related to plasma and probe conditioning. Initial
results for the octahedral probe show flow speeds of roughly the expected
magnitudes based on previous MST measurements but with somes differences in
flow direction, while those for the tetrahedron probe show similar flow
directions to some previous measurements but also some larger than expected
speeds. We consider possible causes for the unexpected results of these initial
tests, with a focus on probe conditioning and fast electron issues.

</details>


### [44] [Kinetic Scale Energy Budget in Turbulent Plasmas: Role of Electron to Ion Temperature Ratio](https://arxiv.org/abs/2510.14258)
*Subash Adhikari,M. Hasan Barbhuiya*

Main category: physics.plasm-ph

TL;DR: The paper investigates how ion-electron thermal disequilibrium affects kinetic-scale energy transfer in plasma turbulence using scale-filtered Vlasov-Maxwell equations and particle-in-cell simulations.


<details>
  <summary>Details</summary>
Motivation: To understand the influence of ion-electron thermal disequilibrium on the kinetic-scale energy budget, which remains poorly understood despite recent progress in quantifying scale-by-scale energy balance in weakly collisional plasmas.

Method: Used two-dimensional fully kinetic particle-in-cell simulations of decaying plasma turbulence, systematically varying electron-to-ion temperature ratios to analyze pressure-strain interaction components at sub-ion scales.

Result: Scale-filtered pressure-strain interaction is dominated by Pi-D across kinetic scales, with shear component providing the dominant contribution. Normal and shear Pi-D contributions show persistent anticorrelation and opposite signs. Anisotropic components scale directly with species temperature and inversely with other species' temperature.

Conclusion: The findings have implications for thermally non-equilibrated plasmas like turbulent magnetosheath and solar wind, revealing specific scaling relationships and dominant mechanisms in kinetic-scale energy transfer.

Abstract: The dissipation mechanisms in weakly collisional plasmas have been a
longstanding topic of investigation, where significant progress has been made
in recent years. A recent promising development is the use of the
"scale-filtered" Vlasov-Maxwell equations to fully quantify the scale-by-scale
energy balance, a feature that was absent when using fluid models in kinetic
plasmas. In particular, this method reveals that the energy transfer in kinetic
scales is fully accounted for by the scale-filtered pressure-strain
interaction. Despite this progress, the influence of ion-electron thermal
disequilibrium on the kinetic-scale energy budget remains poorly understood.
Using two-dimensional fully kinetic particle-in-cell simulations of decaying
plasma turbulence, we systematically investigate the pressure-strain
interaction and its components at sub-ion scales by varying electron-to-ion
temperature ratios. Our analysis focuses on three key ingredients of the
pressure-strain interaction: the normal and shear components of Pi-D and
pressure dilatation. Our results demonstrate that the scale-filtered
pressure-strain interaction is dominated by scale-filtered Pi-D across the
kinetic range, with the shear component consistently providing the dominant
contribution. We find that the scale-filtered normal and shear contributions of
Pi-D exhibit persistent anticorrelation and opposite signs across all kinetic
scales. We also discover that the amplitude of both anisotropic components for
each species scales directly with their temperature and inversely with the
temperature of the other species, while the scale-filtered pressure dilatation
remains negligible compared to the Pi-D terms but shows enhanced
compressibility effects as plasma temperatures decrease. We discuss the
implications of these findings in thermally non-equilibrated plasmas, such as
in the turbulent magnetosheath and solar wind.

</details>


### [45] [Flux Jamming, Phase Transitions and Layering in Turbulent Magnetized Plasma](https://arxiv.org/abs/2510.14280)
*P. H. Diamond,Y. Kosuga,P. L. Guillon,Ö. D. Gürcan*

Main category: physics.plasm-ph

TL;DR: The paper explains transport barrier formation and layering through jam formation analogies with traffic flow theory, relating flux jamming to motility induced phase separation (MIPS) and identifying two routes to heat flux jamming.


<details>
  <summary>Details</summary>
Motivation: To understand transport barrier formation and layering phenomena by drawing analogies with traffic flow theory and explaining the relationship between flux jamming and motility induced phase separation (MIPS).

Method: Uses analogies with one-dimensional traffic flow theory and identifies two routes to heat flux jamming: rollover in heat flux-pulse size relation and delay time exceeding critical value. Analyzes staircase development through jamiton train formation.

Result: Identifies two distinct mechanisms for heat flux jamming, demonstrates formation of outward propagating blob trains and inward propagating void trains, and shows the important role of turbulence spreading in these processes.

Conclusion: The analysis provides insights into transport barrier formation, quantifies 'near marginality' conditions, and elucidates the relationship between avalanche jamming and phase transitions in drift wave-zonal flow turbulence.

Abstract: This paper discusses transport barrier formation and layering as consequences
of jam formation. Extensive use is made of analogies with the theory of traffic
flow in one dimension. The relation of flux jamming to motility induced phase
separation (MIPS) is explained. Two routes to heat flux jamming are identified.
The first is due to a rollover in the heat flux-pulse size relation, i.e.
$dQ_T(\delta T)/d\delta T<0$, and is similar to the condition of flux-gradient
bistability. The second occurs when the delay time between pulse and heat flux
exceeds a critical value. This does not require bistability and tends to occur
near marginality. This analysis yields an estimate of the answer to the eternal
question of 'how near is "near"?'. Staircase development is shown to follow
jamiton train formation. The relation of jamming of avalanches to phase
transitions in drift wave-zonal flow turbulence is elucidated. The formation of
outward propagating blob trains and inward propagating void trains is
demonstrated. The important role of turbulence spreading is identified.

</details>


### [46] [Dust-ion-acoustic solitons in an ion-beam-driven dusty magnetoplasma with adiabatic and nonadiabatic dust charge variations](https://arxiv.org/abs/2510.14324)
*N. P. Acharya,S. Basnet,A. P. Misra,R. Khanal*

Main category: physics.plasm-ph

TL;DR: Study of dust-ion-acoustic solitary waves in magnetized dusty plasmas with positive-ion beams, examining effects of dust charge variations, collisions, and beam parameters on wave characteristics.


<details>
  <summary>Details</summary>
Motivation: To understand how positive-ion beams and dust charge variations affect the propagation and characteristics of nonlinear dust-ion-acoustic solitary waves in active magnetized dusty plasmas.

Method: Using standard reductive perturbation technique to derive Korteweg-de Vries (KdV) equations for two cases: nonadiabatic and adiabatic dust charge variations, and analyzing effects of various parameters.

Result: Soliton energy decays with time and is affected by beam velocity. Solitary waves get damped by ion creation, ion loss, collision-enhanced current, and dust charge variation. Beam causes transition from rarefactive to compressive waves in nonadiabatic case.

Conclusion: Positive-ion beam streaming significantly affects dust charging process and wave characteristics, with different behaviors observed for adiabatic vs nonadiabatic dust charge variations in magnetized dusty plasmas.

Abstract: We study the characteristics of small-amplitude nonlinear dust-ion-acoustic
(DIA) solitary waves in active magnetized positive-ion-beam-driven dusty
plasmas with the effects of nonadiabatic and adiabatic dust charge variations.
In the model, we consider the ion-neutral collision and thereby consider the
collision enhanced ion current to the dust-charging process and dust charge
fluctuations. We show that the streaming of the positive-ion beam significantly
affects the dust-charging process in which the dust charge number decreases
(increases) with an increased beam velocity (number density). Using the
standard reductive perturbation technique, we derive the evolution equations in
the form of Korteweg-de Vries (KdV) equations for DIA solitary waves for two
different cases: nonadiabatic and adiabatic dust charge variations. We study
the effect of positive ion beam, dust charge variation, magnetic field, ion
creation, and ion-neutral collision enhanced current on the wave
characteristics. We find that the soliton energy decays with time and is
affected by the beam velocity. Also, the solitary waves get damped by the
effects of ion creation, ion loss, ion-neutral collision enhanced current, and
dust charge variation. Although the ion beam does not change the polarity of
solitary waves in the case of adiabatic dust charge variation, a transition
from rarefactive to compressive solitary waves occurs in the presence of an ion
beam with nonadiabatic dust charge variation.

</details>


### [47] [Linear damping of magneto-acoustic waves in two-fluid partially ionized plasmas](https://arxiv.org/abs/2510.14575)
*David Martínez-Gómez*

Main category: physics.plasm-ph

TL;DR: Study of magneto-acoustic wave damping in partially ionized plasmas using a two-fluid model, analyzing wavenumbers and damping rates across different ionization degrees and propagation angles.


<details>
  <summary>Details</summary>
Motivation: To understand how elastic collisions between charged and neutral particles affect magneto-acoustic wave properties in partially ionized plasmas, which is relevant for various astrophysical and laboratory plasma environments.

Method: Used a linearized two-fluid model to study small-amplitude waves in uniform static background, focusing on waves from periodic drivers. Analyzed dependence on ionization degree, collisional coupling strength, and propagation angle.

Result: Derived analytical approximations for damping rates in weak and strong coupling limits, validated against numerical results. Described relationships between different wave modes (fast, slow, acoustic) and individual fluid properties across various physical conditions.

Conclusion: The analytical approximations for damping rates due to charge-neutral collisions are generally applicable to various partially ionized plasmas, with specific discussion of hydrogen-only plasmas.

Abstract: Magneto-acoustic waves in partially ionized plasmas are damped due to elastic
collisions between charged and neutral particles. Here, we use a linearized
two-fluid model to describe the influence of this collisional interaction on
the properties of small-amplitude waves propagating in a uniform and static
background. Mainly focusing on the case of waves generated by a periodic
driver, we perform a detailed study of the dependence of the wavenumbers and
damping rates on the ionization degree of the plasma, the strength of the
collisional coupling, and the angle of propagation. We describe how the
different wave modes (fast, slow, acoustic) are related to the individual
properties of each fluid in a wide range of physical conditions. In addition,
we derive analytical approximations for the damping rates due to charge-neutral
collisions in the limits of weak and strong coupling and check their range of
validity in comparison with the exact numerical results. These approximations
can be generally applied to a large variety of astrophysical and laboratory
partially ionized plasmas, but here we also discuss the particular application
to plasmas only composed of hydrogen.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [48] [Bell Instability and Cosmic-Ray Acceleration in AGN Ultrafast Outflow Shocks](https://arxiv.org/abs/2510.13946)
*Rei Nishiura,Tsuyoshi Inoue*

Main category: astro-ph.HE

TL;DR: The paper examines magnetic-field amplification via the nonresonant hybrid instability at reverse shocks of AGN outflows and its role in cosmic-ray acceleration, identifying a transition in efficiency based on background magnetic field strength.


<details>
  <summary>Details</summary>
Motivation: To understand how the nonresonant hybrid instability affects magnetic field amplification and cosmic-ray acceleration at reverse shocks of ultrafast outflows from active galactic nuclei, especially under varying background magnetic field conditions.

Method: Employ a one-dimensional MHD--CR framework solving telegraph-type diffusion--convection equations to model the coupled evolution of cosmic rays, magnetic fields, and shock dynamics with realistic parameters.

Result: For weak background fields (B0 ≲ 10⁻⁴ G), NRH instability efficiently amplifies upstream turbulence, leading to a self-regulated state where maximum CR energy becomes independent of initial magnetic turbulence strength. For stronger fields (B0 ≳ 10⁻³ G), escaping CR current is insufficient to drive NRH instability, and magnetic turbulence decays, reducing acceleration efficiency.

Conclusion: The efficiency of cosmic-ray acceleration at UFO reverse shocks depends critically on background magnetic field strength, with a transition around 10⁻⁴-10⁻³ G determining whether NRH instability can drive effective magnetic field amplification and enable PeV--EeV acceleration.

Abstract: We investigate magnetic-field amplification driven by the nonresonant hybrid
(NRH or Bell) instability and its impact on cosmic-ray (CR) acceleration at
reverse shocks of ultrafast outflows (UFOs) from active galactic nuclei (AGN).
Previous kinetic studies by particle-in-cell simulations have demonstrated that
when maximum CR energy is near the injection scale, NRH instability efficiently
amplifies magnetic field up to the saturation level. However, the efficiency of
NRH instability goes down as maximum energy increase since CR current is
carried by escaping CRs near the maximum energy. We employ a one-dimensional
MHD--CR framework solving telegraph-type diffusion--convection equations to
trace the coupled evolution of CRs, magnetic fields, and shock dynamics under
realistic parameters. We find a distinct transition with magnetic field
strength: for weak background fields ($B_{0}\!\lesssim\!10^{-4}\,\mathrm{G}$),
NRH instability efficiently amplifies upstream turbulence, driving a
self-regulated state where $E_{\max}$ becomes independent of initial strength
of magnetic turbulence. In contrast, for stronger background fields
($B_{0}\!\gtrsim\!10^{-3}\,\mathrm{G}$), the escaping CR current is too weak to
drive NRH instability, and magnetic turbulence further decays through
parametric instabilities, potentially reducing the acceleration efficiency. We
give the physical interpretation for the transition and discuss conditions for
PeV--EeV acceleration at UFO reverse shocks.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [49] [Loss functions arising from the index of agreement](https://arxiv.org/abs/2510.14714)
*Hristos Tyralis,Georgia Papacharalampous*

Main category: stat.ME

TL;DR: This paper analyzes the theoretical properties of Willmott's index of agreement loss function, proposes an improved version called L_NR₂ that maintains desirable properties while enabling closed-form solutions, and shows convergence with squared error loss under high correlation conditions.


<details>
  <summary>Details</summary>
Motivation: To understand the theoretical foundations of Willmott's index of agreement, a widely used metric in environmental sciences and engineering, and to address its limitations by developing an improved loss function with better theoretical properties.

Method: Theoretical analysis of L_W properties, proposal of L_NR₂ as an improved loss function with Euclidean distance denominator, mathematical proofs of properties, and comparison with squared error loss under varying correlation conditions.

Result: L_W is bounded [0,1], translation/scale invariant, and estimates E_F[y] ± V_F^{1/2}[y]. L_NR₂ retains these properties while admitting closed-form solutions for linear models. Parameter estimates from squared error, L_NR₂ and L_W converge as correlation approaches 1.

Conclusion: L_NR₂ provides a theoretically improved alternative to Willmott's index of agreement that maintains desirable properties while enabling closed-form solutions, with practical implications for hydrologic model calibration where performance becomes nearly identical across loss functions under high correlation.

Abstract: We examine the theoretical properties of the index of agreement loss function
$L_W$, the negatively oriented counterpart of Willmott's index of agreement, a
common metric in environmental sciences and engineering. We prove that $L_W$ is
bounded within [0, 1], translation and scale invariant, and estimates the
parameter $\Bbb{E}_{F}[\underline{y}] \pm \Bbb{V}_{F}^{1/2}[\underline{y}]$
when fitting a distribution. We propose $L_{\operatorname{NR}_2}$ as a
theoretical improvement, which replaces the denominator of $L_W$ with the sum
of Euclidean distances, better aligning with the underlying geometric
intuition. This new loss function retains the appealing properties of $L_W$ but
also admits closed-form solutions for linear model parameter estimation. We
show that as the correlation between predictors and the dependent variable
approaches 1, parameter estimates from squared error, $L_{\operatorname{NR}_2}$
and $L_W$ converge. This behavior is mirrored in hydrologic model calibration
(a core task in water resources engineering), where performance becomes nearly
identical across these loss functions. Finally, we suggest potential
improvements for existing $L_p$-norm variants of the index of agreement.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [50] [Quantum Search in Superposed Quantum Lattice Gas Automata and Lattice Boltzmann Systems](https://arxiv.org/abs/2510.14062)
*Călin A. Georgescu,Matthias Möller*

Main category: quant-ph

TL;DR: This paper proposes quantum methods for CFD that avoid flow field measurement by using discrete optimization and quantum search, potentially providing asymptotic quantum advantage.


<details>
  <summary>Details</summary>
Motivation: Current quantum CFD methods (QLGA/QLBM) focus on model development but are limited to quantum state tomography and observable measurement, which may cancel quantum advantages unless specific criteria are met.

Method: Proposes methods for simulating multiple lattice configurations simultaneously using amplitude estimation and quantum search, with detailed gate-level complexity analysis and encoding comparisons.

Result: The approach circumvents flow field measurement entirely and provides methods that can achieve asymptotic quantum advantage.

Conclusion: The proposed quantum search and optimization-based approach offers a practical alternative to measurement-heavy quantum CFD methods, with potential for quantum advantage in computational fluid dynamics.

Abstract: As the scope of Computational Fluid Dynamics (CFD) grows to encompass ever
larger problem scales, so does the interest in whether quantum computing can
provide an advantage. In recent years, Quantum Lattice Gas Automata (QLGA) and
Quantum Lattice Boltzmann Methods (QLBM) have emerged as promising candidates
for quantum-native implementations of CFD solvers. Though the progress in
developing QLGA and QLBM algorithms has been significant, it has largely
focused on the development of models rather than applications. As a result, the
zoo of QLGA and QLBM algorithms has grown to target several equations and to
support many extensions, but the practical use of these models is largely
limited to quantum state tomography and observable measurement. This limitation
is crucial in practice, because unless very specific criteria are met, such
measurements may cancel out any potential quantum advantage. In this paper, we
propose an application based on discrete optimization and quantum search, which
circumvents flow field measurement altogether. We propose methods for
simulating many different lattice configurations simultaneously and describe
how the usage of amplitude estimation and quantum search can provide an
asymptotic quantum advantage. Throughout the paper, we provide detailed
complexity analyses of gate-level implementations of our circuits and consider
the benefits and costs of several encodings.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [51] [Phenomenological Ehrenfest Dynamics with Topological and Geometric Phase Effects and the curious case of Elliptical intersection](https://arxiv.org/abs/2510.14181)
*Dhruv Sharma*

Main category: cond-mat.mes-hall

TL;DR: A computational framework for simulating nonadiabatic molecular dynamics with geometric phase effects, handling various electronic state crossings through a generalized two-level Hamiltonian model with Berry curvature-based force corrections.


<details>
  <summary>Details</summary>
Motivation: To develop a unified framework that accurately represents geometric phase effects in molecular dynamics simulations, particularly for systems with different types of level crossings where topological effects play significant roles.

Method: Uses a generalized two-level Hamiltonian model parameterized for different electronic state crossings, incorporates Berry curvature-based force corrections to Ehrenfest dynamics, and introduces a novel prelooping trajectory initialization scheme to encode memory as initial phase.

Result: Numerical simulations show consistency with theoretical predictions for state mixing and inhibition due to geometric phase effects, with the framework correctly reproducing the expected phase pi for conical intersections and tunable phase for elliptic intersections.

Conclusion: The framework provides a valuable tool for studying quantum-classical interactions in molecular systems with geometric phase effects, opening avenues for degenerate materials design, new spectroscopy development, and potential qubit applications.

Abstract: We present a comprehensive computational framework for simulating
nonadiabatic molecular dynamics with explicit inclusion of geometric phase (GP)
effects. Our approach is based on a generalized two-level Hamiltonian model
that can represent various electronic state crossings - conical intersections,
avoided crossings, and elliptic intersections - through appropriate
parameterization. We introduce a novel prelooping trajectory initialization
scheme, allowing us to encode the memory as an initial phase accumulated due to
the adiabatic evolution over the potential energy surface. This is a unified
framework to handle different types of level crossings by incorporating Berry
curvature-based force corrections to Ehrenfest dynamics, ensuring accurate
representation of topological effects. For conical intersections, our method
incorporates the theoretically expected phase pi, while for elliptic
intersections, it yields a parametrically tunable but loop radius (energy)
independent phase different from pi. We also include an eccentricity parameter
(e) in the diabatic coupling to model more realistic molecular systems.
Numerical simulations demonstrate the consistency of our approach with
theoretical predictions for mixing of states and inhibition from mixing due to
geometric phase effects. This framework provides a valuable tool for studying
quantum-classical interactions in molecular systems where geometric phase
effects play a significant role. The elliptical intersection and geometric
phase effect opens avenue for the design and discovery of degenerate materials.
It produces a fresh look to help develop a new kind of spectroscopy and
potential qubit applications. This simple Hamiltonian reveals a pathological
phase protection effect E = kr, where k is real, that has great utility in a
new spectroscopy design.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [52] [The geometry of PLS shrinkages](https://arxiv.org/abs/2510.14430)
*Paolo Foschi*

Main category: math.ST

TL;DR: This paper analyzes the geometric structure of PLS (Partial Least Squares) shrinkages, providing explicit formulas and showing that PLS estimators can have highly nonlinear behavior in extreme cases, challenging existing degrees of freedom measures.


<details>
  <summary>Details</summary>
Motivation: To understand the geometric properties of PLS shrinkages and address limitations in current degrees of freedom (DoF) measures that fail in extreme nonlinear situations.

Method: Developed an explicit formula for shrinkage vectors where shrinkage factors are expressed as averages of basic shrinkages dependent on the data matrix, with weights being multilinear functions of observed responses.

Result: Characterized the set of possible shrinkages and identified extreme cases where PLS estimators exhibit highly nonlinear behavior. Showed that existing DoF measures fail in these situations and disproved the longstanding conjecture that PLS DoFs always exceed the number of PLS directions.

Conclusion: The geometric analysis reveals complex nonlinear behavior in PLS estimators, invalidating certain longstanding assumptions about degrees of freedom and highlighting limitations in current DoF measurement approaches.

Abstract: The geometrical structure of PLS shrinkages is here considered. Firstly, an
explicit formula for the shrinkage vector is provided. In that expression,
shrinkage factors are expressed a averages of a set of basic shrinkages that
depend only on the data matrix. On the other hand, the weights of that average
are multilinear functions of the observed responses. That representation allows
to characterise the set of possible shrinkages and identify extreme situations
where the PLS estimator has an highly nonlinear behaviour. In these situations,
recently proposed measures for the degrees of freedom (DoF), that directly
depend on the shrinkages, fail to provide reasonable values. It is also shown
that the longstanding conjecture that the DoFs of PLS always exceeds the number
PLS directions does not hold.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [53] [Diameter bounds in 3d Type I Ricci flows](https://arxiv.org/abs/2510.14019)
*Panagiotis Gianniotis*

Main category: math.DG

TL;DR: The paper proves that 3D compact Ricci flows with Type I singularities have uniformly bounded diameter up to the singular time, confirming Perelman's conjecture for Type I cases.


<details>
  <summary>Details</summary>
Motivation: To address Perelman's conjecture about diameter bounds in Ricci flows encountering singularities, specifically focusing on Type I singularities.

Method: Introduces a concept of neck-regions for Ricci flows (analogous to those in Ricci limit spaces) and proves that the associated packing measure is Ahlfors regular in any dimension.

Result: Proves that three-dimensional compact Ricci flows with Type I singularities have uniformly bounded diameter up to the singular time.

Conclusion: Provides affirmative answer to Perelman's conjecture for Type I singularities and establishes fundamental regularity properties of neck-regions in Ricci flows.

Abstract: We prove that a three dimensional compact Ricci flow that encounters a Type I
singularity has uniformly bounded diameter up to the singular time, thus giving
an affirmative answer - for Type I singularities - to a conjecture of Perelman.
To achieve this, we introduce a concept of a neck-region for a Ricci flow,
analogous to the neck-regions introduced by Jiang-Naber and
Cheeger-Jiang-Naber, in the study of Ricci limit spaces. We then prove that the
associated packing measure is, in a certain sense, Ahlfors regular, a result
that holds in any dimension.

</details>


### [54] [Families of surfaces with constant ratio of principal curvatures and Plateau's problem](https://arxiv.org/abs/2510.14527)
*Mikhail Skopenkov,Khusrav Yorov*

Main category: math.DG

TL;DR: Construction of surfaces with constant ratio of principal curvatures (CRPC surfaces) using minimal surfaces as starting point, with applications to Plateau's problem and isotropic geometry.


<details>
  <summary>Details</summary>
Motivation: CRPC surfaces generalize minimal surfaces but are much more challenging to construct, requiring new approaches to solve Plateau's problem for these surfaces.

Method: Propose construction of CRPC surface family containing given minimal surface without flat points; use method of successive approximations and analytic majorization; apply approach of solving Euclidean problems via isotropic analogs.

Result: Obtain partial solution of Plateau's problem for CRPC surfaces; achieve analogous results in isotropic geometry.

Conclusion: Demonstrates general approach to solving Euclidean problems by starting with their isotropic analogs, providing construction method for challenging CRPC surfaces.

Abstract: This work is on surfaces with a constant ratio of principal curvatures. These
CRPC surfaces generalize minimal surfaces but are much more challenging to
construct. We propose a construction of a family of such surfaces containing a
given minimal surface without flat points. This leads to a partial solution of
Plateau's problem for CRPC surfaces. We obtain analogous results in isotropic
geometry. This work illustrates a general approach to solving Euclidean
problems by starting with their isotropic analogs. Besides, we apply the method
of successive approximations and analytic majorization.

</details>


<div id='nlin.SI'></div>

# nlin.SI [[Back]](#toc)

### [55] [Asymmetric integrable turbulence and rogue wave statistics for the derivative nonlinear Schrödinger equation](https://arxiv.org/abs/2510.14472)
*Ming Zhong,Weifang Weng,Zhenya Yan*

Main category: nlin.SI

TL;DR: Study of asymmetric integrable turbulence and rogue waves in the DNLS equation, showing oscillatory convergence to steady states with specific decay rates and frequency relationships tied to modulation instability.


<details>
  <summary>Details</summary>
Motivation: To investigate the asymmetric nature of turbulence and rogue wave formation in the DNLS equation, particularly how modulation instability affects energy oscillations and wave statistics differently from the NLS equation.

Method: Analysis of n-th moments, ensemble-averaged kinetic/potential energy, wave-action spectrum, auto-correlation function, and probability density function of wave intensity in the DNLS equation framework.

Result: Found oscillatory convergence with amplitude decay ~t^{-1.36} and phase shift decay ~t^{-0.78}, asymmetric turbulence with power-law spectrum |k+3|^{-α}, and increased rogue wave probability during potential modulus minima.

Conclusion: DNLS turbulence exhibits unique asymmetric characteristics due to wave number asymmetry, with rogue waves more likely during specific oscillation phases, distinguishing it from NLS behavior.

Abstract: We investigate the asymmetric integrable turbulence and rogue waves (RWs)
emerging from the modulation instability (MI) of plane waves for the DNLS
equation. The \(n\)-th moments and ensemble-averaged kinetic and potential
energy exhibit oscillatory convergence towards their steady-state values.
Specifically, the amplitudes of oscillations for these indexes decay
asymptotically with time as \(t^{-1.36}\), while the phase shifts demonstrate a
nonlinear decay with a rate of \(t^{-0.78}\). The frequency of these
oscillations is observed to be twice the maximum growth rate of MI. These
oscillations can be classified into two distinct types: one is in phase with
ensemble-averaged potential energy modulus $|\langle H_4\rangle|$, and the
other is anti-phase. At the same time, this unity is also reflected in the
wave-action spectrum \( S_k(t) \) for a given \( k \), the auto-correlation
function \( g(x,t) \) for a given \( x \), as well as the PDF \( P(I,t) \). The
critical feature of the turbulence is the wave-action spectrum, which follows a
power-law distribution of \( |k+3|^{-\alpha} \) expect for $k=-3$. Unlike the
NLS equation, the turbulence in the DNLS setting is asymmetric, primarily due
to the asymmetry between the wave number of the plane wave from the MI and the
perturbation wave number.. As the asymptotic peak value of \( S_k \) is
observed at \( k = -3 \), the auto-correlation function exhibits a nonzero
level as \( x \to \pm L/2 \). The PDF of the wave intensity asymptotically
approaches the exponential distribution in an oscillatory manner. However,
during the initial stage of the nonlinear phase, MI slightly increases the
occurrence of RWs. This happens at the moments when the potential modulus is at
its minimum, where the probability of RWs occurring in the range of \( I\in
[12, 15] \) is significantly higher than in the asymptotic steady state.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [56] [DeepMartingale: Duality of the Optimal Stopping Problem with Expressivity](https://arxiv.org/abs/2510.13868)
*Junyan Ye,Hoi Ying Wong*

Main category: math.OC

TL;DR: DeepMartingale is a novel deep learning method using martingale representation to solve discrete-monitoring optimal stopping problems, providing dimension-independent convergence and expressivity guarantees.


<details>
  <summary>Details</summary>
Motivation: To develop a deep learning approach that overcomes the curse of dimensionality in optimal stopping problems and provides tight upper bounds for the primal value function.

Method: Uses martingale representation and neural networks with bounded size to approximate the value function, with architectural design ensuring dimension-independent performance.

Result: The method provides tight upper bounds that converge under mild assumptions, approximates the true value function within any accuracy ε, and avoids the curse of dimensionality.

Conclusion: DeepMartingale is an effective, stable, and dimension-independent approach for optimal stopping problems, as confirmed by numerical experiments.

Abstract: Using a martingale representation, we introduce a novel deep-learning
approach, which we call DeepMartingale, to study the duality of
discrete-monitoring optimal stopping problems in continuous time. This approach
provides a tight upper bound for the primal value function, even in
high-dimensional settings. We prove that the upper bound derived from
DeepMartingale converges under very mild assumptions. Even more importantly, we
establish the expressivity of DeepMartingale: it approximates the true value
function within any prescribed accuracy $\varepsilon$ under our architectural
design of neural networks whose size is bounded by
$\tilde{c}\,D^{\tilde{q}}\varepsilon^{-\tilde{r}}$, where the constants
$\tilde{c}, \tilde{q}, \tilde{r}$ are independent of the dimension $D$ and the
accuracy $\varepsilon$. This guarantees that DeepMartingale does not suffer
from the curse of dimensionality. Numerical experiments demonstrate the
practical effectiveness of DeepMartingale, confirming its convergence,
expressivity, and stability.

</details>


### [57] [Optimality-Based Control Space Reduction for Infinite-Dimensional Control Spaces](https://arxiv.org/abs/2510.14479)
*Michael Kartmann,Stefan Volkwein*

Main category: math.OC

TL;DR: This paper presents a combined control and state space reduction method for linear-quadratic optimal control problems with time-varying parabolic PDEs, providing error bounds and an adaptive algorithm.


<details>
  <summary>Details</summary>
Motivation: To efficiently solve unconstrained linear-quadratic optimal control problems for time-varying parabolic PDEs by reducing computational complexity through model reduction in both control and state variables.

Method: The approach uses the first-order optimality condition to derive a reduced structure for optimal control, leading to a combined control- and state-reduced problem. It provides a posteriori error bounds for optimal control and develops an adaptive algorithm using these bounds.

Result: The paper proves convergence of the adaptive algorithm and demonstrates numerically that combined control and state space reduction provides advantages over solely state-reduced approaches.

Conclusion: Combined control and state space reduction is an effective approach for linear-quadratic optimal control problems with parabolic PDEs, with provable convergence and improved performance over state-only reduction methods.

Abstract: We consider linear model reduction in both the control and state variables
for unconstrained linear-quadratic optimal control problems subject to
time-varying parabolic PDEs. The first-order optimality condition for a
state-space reduced model naturally leads to a reduced structure of the optimal
control. Thus, we consider a control- and state-reduced problem that admits the
same minimizer as the solely state-reduced problem. Lower and upper \emph{a
posteriori} error bounds for the optimal control and a representation for the
error in the optimal function value are provided. These bounds are used in an
adaptive algorithm to solve the control problem. We prove its convergence and
numerically demonstrate the advantage of combined control and state space
reduction.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [58] [Grain volume distribution alters the critical phenomena in complex granular systems](https://arxiv.org/abs/2510.14797)
*Teng Man,Yimin Lu,Zhongrong Wang,Herbert Huppert,Alessio Zaccone,Honglei Sun*

Main category: cond-mat.soft

TL;DR: This study uses DEM simulations to investigate how grain size distribution affects the rheology and critical behavior of sheared granular flows, revealing a characteristic length scale and correlation between critical solid fractions and grain volume distributions.


<details>
  <summary>Details</summary>
Motivation: Understanding how grain size distribution affects mechanical properties and critical behaviors in amorphous disordered systems and granular materials, as varying GSD causes segregation issues and alters system behavior.

Method: Used discrete element method (DEM) to simulate sheared granular flows with various grain size distributions (GSDs).

Result: Found a unified rheological relation with an embedded characteristic length scale related to contact probability, and obtained a correlation function between critical solid fractions and dimensionless grain volume distributions.

Conclusion: The work elucidates how particle volumes affect rheology and micromechanics of dry granular systems, providing insights for incorporating other particle properties into a unified framework for engineering and geophysical applications.

Abstract: The grain size distribution (GSD) plays an important role in the mechanical
properties of amorphous disordered systems and complex granular materials.
Varying GSD causes segregation issues and alters critical behaviors. This work
used the discrete element method (DEM) to investigate the rheological and
critical behaviors of sheared granular flows with various GSDs. The results
show that, while a unified rheological relation can be obtained, a
characteristic length scale, which is associated with the contact probability
and can be obtained from any GSD, is embedded within such a polydisperse
disordered system. We further acquire a correlation function between critical
solid fractions and dimensionless grain volume distributions. This work
elucidates the effect of particle volumes on the rheology and micromechanics of
dry granular systems and provides further insights in better incorporating the
influence of other particle properties into a unified framework, which is
helpful and critical for the corresponding engineering and geophysical
problems.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [59] [Comparative Analysis of the Flow in a Realistic Human Airway](https://arxiv.org/abs/2510.14320)
*Mario Rüttgers,Julian Vorspohl,Luca Mayolle,Benedikt Johanning-Meiners,Dominik Krug,Michael Klaas,Matthias Meinke,Sangseung Lee,Wolfgang Schröder,Andreas Lintermann*

Main category: physics.flu-dyn

TL;DR: Direct numerical simulations of inspiratory airflow through a detailed airway model from nasal mask to 6th bronchial bifurcation at two Reynolds numbers (Re_p=400 and 1200) reveal spatial correlation between pressure loss and flow instabilities, with nasal cavity contributing most to pressure loss.


<details>
  <summary>Details</summary>
Motivation: Existing computational studies rely on simplified geometries or turbulence models, limiting their ability to resolve important flow features like shear-layer instabilities and secondary vortices in human airways.

Method: Used lattice-Boltzmann method for direct numerical simulations (no turbulence model) of inspiratory flow through detailed airway model covering nasal mask to 6th bronchial bifurcation at two physiologically relevant Reynolds numbers (Re_p=400 for resting, Re_p=1200 for elevated breathing).

Result: Total pressure loss increased from 9.76 Pa at Re_p=400 to 41.93 Pa at Re_p=1200. Nasal cavity accounted for majority of loss (81.3% at Re_p=400, 73.4% at Re_p=1200). Secondary vortices in nasopharyngeal bend and turbulent shear-layers in glottis jet enhanced local pressure losses at higher Re. Carinal bifurcation stabilized flow by mitigating upstream unsteadiness.

Conclusion: Spatial correlation between pressure loss and onset of flow instabilities provides novel perspective on how flow resistance and vortex dynamics vary with geometric changes and flow rate in human airways.

Abstract: Accurate simulations of the flow in the human airway are essential for
advancing diagnostic methods. Many existing computational studies rely on
simplified geometries or turbulence models, limiting their simulation's ability
to resolve flow features such shear-layer instabilities or secondary vortices.
In this study, direct numerical simulations were performed for inspiratory flow
through a detailed airway model which covers the nasal mask region to the 6th
bronchial bifurcation. Simulations were conducted at two physiologically
relevant \textsc{Reynolds} numbers with respect to the pharyngeal diameter,
i.e., at Re_p=400 (resting) and Re_p=1200 (elevated breathing). These values
characterize resting and moderately elevated breathing conditions. A
lattice-Boltzmann method was employed to directly simulate the flow, i.e., no
turbulence model was used. The flow field was examined across four anatomical
regions: 1) the nasal cavity, 2) the naso- and oropharynx, 3) the
laryngopharynx and larynx, and 4) the trachea and carinal bifurcation. The
total pressure loss increased from 9.76 Pa at Re_p=400 to 41.93 Pa at
Re_p=1200. The nasal cavity accounted for the majority of this loss for both
Reynolds numbers, though its relative contribution decreased from 81.3% at
Re_p=400 to 73.4% at Re_p=1200. At Re_p=1200, secondary vortices in the
nasopharyngeal bend and turbulent shear-layers in the glottis jet enhanced the
local pressure losses. In contrast, the carinal bifurcation mitigated upstream
unsteadiness and stabilized the flow. A key outcome is the spatial correlation
between the pressure loss and the onset of flow instabilities across the four
regions. This yields a novel perspective on how the flow resistance and vortex
dynamics vary with geometric changes and flow rate.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [60] [Breaking gyrochronology through the collapse of coronal winds](https://arxiv.org/abs/2510.14164)
*Michaël Lévesque,Paul Charbonneau*

Main category: astro-ph.SR

TL;DR: Gyrochronology fails for stars older than the sun, possibly due to wind collapse from reduced coronal heating rather than dynamo changes. The study shows that at low coronal temperatures, magnetocentrifugal effects prevent power-law scaling of mass/angular momentum loss, requiring unrealistic power input drops to explain observed breaks.


<details>
  <summary>Details</summary>
Motivation: To investigate why gyrochronology fails for stars older than the sun, exploring an alternative explanation involving wind collapse through reduced coronal heating rather than the commonly proposed dynamo shutdown.

Method: Analyzed mass and angular momentum loss rates in the low coronal temperature limit, examining magnetocentrifugal effects and their impact on power-law scaling. Used an ad hoc power law relationship between coronal temperature and magnetic field strength while maintaining standard dynamo relationships.

Result: Found that magnetocentrifugal effects become important at low coronal temperatures (<1.5 MK), preventing power-law expression of mass/angular momentum loss rates. Reproducing observed gyrochronology breaks requires an exponent σ≥1.5, associated with over 3 orders of magnitude drop in coronal power input.

Conclusion: The wind collapse explanation for gyrochronology failure appears physically unrealistic due to the required dramatic reduction in coronal heating power, which contradicts current observations of non-thermal emission in aged solar-type stars.

Abstract: Gyrochronology, a method for dating aged field stars ($\gtrsim$ a few Gyr)
based on their rotation rate, has recently been shown to fail for many stars
older than the sun. The explanation most often put forth is that a shutdown or
mode change in the stellar dynamo leads to a sharp decrease in angular momentum
loss in magnetized coronal winds. In this paper, we explore an alternate
possibility, namely a collapse of the wind itself through a reduction of
coronal heating. We show that in the low coronal temperature ($T_0$) limit,
even at solar-like low rotation rates ($\Omega$) and coronal magnetic field
strength ($B_{r0}$), magnetocentrifugal effects are important and preclude
expression of the mass and angular momentum loss rates as power-laws of $T_0$
or $\Omega$ when $T_0$ drops below $\simeq 1.5\,$MK. Mass loss is found to
scale linearly with power input into the wind at all coronal temperatures.
Introducing an ad hoc power law relationship $T_0\propto B_{r0}^\sigma$ while
retaining the ``standard'' dynamo relationship $B_{r0}\propto\Omega$, we show
that reproducing the observed break in gyrochronology requires an exponent
$\sigma\gtrsim 1.5$, with which is associated a drop by over 3 orders of
magnitude in power input into the quiet corona. This appears physically
unrealistic, given current observations of chromospheric and coronal
non-thermal emission in aged solar-type stars.

</details>


### [61] [Influence of kinetic effects in large-scale magnetic reconnection with multi-hierarchy simulation code KAMMUY](https://arxiv.org/abs/2510.14521)
*Keita Akutagawa,Shinsuke Imada,Munehito Shoda*

Main category: astro-ph.SR

TL;DR: Developed KAMMUY code combining MHD and PIC simulations to study magnetic reconnection across scales, finding that Hall magnetic field extension doesn't affect reconnection rate.


<details>
  <summary>Details</summary>
Motivation: To overcome computational limitations of PIC simulations and study interactions between kinetic and fluid dynamics in large-scale magnetic reconnection phenomena like solar flares.

Method: Multi-hierarchy simulation code (KAMMUY) that runs ideal MHD for large domains and PIC for smaller domains in parallel with mutual information exchange, validated with MHD wave propagation and shock tube tests.

Result: Short-wavelength waves from PIC don't propagate to MHD region, while MHD structures propagate smoothly to PIC. Reconnection rate remains unchanged regardless of PIC domain size where Hall magnetic field is present.

Conclusion: Spatial extension of Hall magnetic field on 10-100 ion inertial length scale does not influence magnetic reconnection rate.

Abstract: Magnetic reconnection is a multiscale phenomenon where fluid- and
particle-scale processes interact. The particle-in-cell (PIC) method, capable
of resolving kinetic (particle-scale) physics, is extensively used to study the
kinetic effects in magnetic reconnection. Meanwhile, because of the high
computational cost, PIC simulations cannot capture the interaction between
kinetic and fluid dynamics, which poses a major obstacle to understanding
magnetic reconnection in large-scale phenomena such as solar flares. A
multi-hierarchy simulation that combines Magnetohydrodynamics (MHD) and PIC
provides a promising means to overcome these spatial and temporal scale gaps.
We developed a multi-hierarchy simulation code KAMMUY (Kinetic And
Magnetohydrodynamic MUlti-hierarchY simulation code), in which an ideal MHD
simulation for a large domain and a PIC simulation for a smaller domain are
solved in parallel with mutual information exchange. To validate the code, we
conducted test simulations of MHD wave propagation and the shock tube problem.
The results demonstrate that short-wavelength, high-frequency waves generated
in the PIC region do not propagate into the MHD region, whereas MHD-scale
structures propagate smoothly into the PIC region, highlighting the capability
of our code for numerical studies of magnetic reconnection. By applying the
KAMMUY code to magnetic reconnection while varying the PIC domain size, we find
that the reconnection rate remains unchanged, regardless of the extent of the
PIC region where the Hall magnetic field is present. It suggests that the
spatial extension of the Hall magnetic field on the scale of $10 \sim 100
\lambda_i$ does not influence the reconnection rate.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [62] [Multiscaling asymptotic behavior of solutions to random high-order heat equations](https://arxiv.org/abs/2510.14153)
*Maha Mosaad A Alghamdi,Nikolai Leonenko,Andriy Olenko*

Main category: math.PR

TL;DR: This paper analyzes high-order PDEs with random initial conditions exhibiting long-memory and cyclic behavior, proving convergence to Gaussian random fields after proper scaling.


<details>
  <summary>Details</summary>
Motivation: To study high-order PDEs with random initial conditions that have spectral singularities at zero (long-range dependence) and non-zero frequencies (cyclic long-range dependence), which are important in modeling complex stochastic phenomena.

Method: Uses spectral methods and scaling techniques to prove convergence to Gaussian random fields. For odd-order equations, applies kernel averaging of solutions to obtain nonexplosive and nondegenerate limits.

Result: Shows that solutions converge to Gaussian random fields after proper rescaling. Provides spectral representations and covariance functions of limit fields. Demonstrates that different limit fields depend on equation order (even/odd) and presence/absence of spectral singularity at zero.

Conclusion: The limit behavior of high-order PDEs with random initial conditions is determined by equation order and spectral singularity characteristics, with theoretical results supported by numerical examples.

Abstract: This paper studies high-order partial differential equations with random
initial conditions that have both long-memory and cyclic behavior. The cases of
random initial conditions with the spectral singularities, both at zero
(representing classical long-range dependence) and at non-zero frequencies
(representing cyclic long-range dependence), are investigated.
  Using spectral methods and scaling techniques, it is proved that, after
proper rescaling and normalization, the solutions converge to Gaussian random
fields. For each type of equation, spectral representations and covariance
functions of limit fields are given. For odd-order equations, we apply the
kernel averaging of solutions to obtain nonexplosive and nondegenerate limits.
It is shown that the different limit fields are determined by the even or odd
orders of the equations and by the presence or absence of a spectral
singularity at zero. Several numeric examples illustrate the obtained
theoretical results.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [63] [No cosmological constraints on dark photon dark matter from resonant conversion: Impact of nonlinear plasma dynamics](https://arxiv.org/abs/2510.13956)
*Anson Hook,Junwu Huang,Mohamad Shalaby*

Main category: hep-ph

TL;DR: The paper invalidates all existing dark photon dark matter constraints from resonant conversion in the early universe by showing that plasma nonlinearities saturate the energy transfer, limiting deposited energy to thermal levels.


<details>
  <summary>Details</summary>
Motivation: To re-examine constraints on dark photon dark matter that rely on resonant conversion into photons/plasmons in the early universe, as these constraints may be invalid due to overlooked plasma nonlinear effects.

Method: Used Particle-in-Cell simulations to study how large-amplitude Langmuir waves excite higher-k waves, creating plasma inhomogeneities that suppress further resonant conversion.

Result: Resonant energy transfer saturates due to nonlinear effects, limiting deposited energy to about the thermal energy of electrons, making constraints 3000 to 10^7 times weaker across dark photon mass range.

Conclusion: All existing dark photon dark matter constraints from resonant conversion are invalid, as plasma nonlinearities prevent observable cosmological heating, significantly weakening the constraints.

Abstract: We revisit and invalidate all dark photon dark matter constraints from
resonant conversion of dark photons into photons (plasmons) in the early
universe. These constraints rely on the resonant transfer of a substantial
portion of the dark photon energy density into the SM plasma, heating the
plasma in the process. We demonstrate that this resonant transfer saturates
because of plasma nonlinearities. Dark photon dark matter resonantly converts
into $k \simeq 0$ Langmuir waves in the early universe electron-ion plasma.
Once the Langmuir-wave energy approaches the thermal energy of the plasma,
nonlinear effects driven by the ponderomotive force become significant. In
particular, we show using dedicated Particle-in-Cell simulations that
large-amplitude $k = 0$ Langmuir waves excite higher-k Langmuir and ion
acoustic waves, producing strong spatial variations in density and plasma
frequency. These inhomogeneities suppress further resonant conversion, limiting
the deposited energy to about the thermal energy of the electrons at the time
of conversion, orders of magnitude below observable cosmological thresholds.
Consequently, the dark photon dark matter constraints are weaker by factors of
$3000$ to $10^7$ across ten orders of magnitude in dark photon mass.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [64] [A Flying Focus with Arbitrary Directionality](https://arxiv.org/abs/2510.14195)
*Sida Cao,Devdigvijay Singh,Lavonne S. Mack,John P. Palastro,Matthew R. Edwards*

Main category: physics.optics

TL;DR: A new flying focus configuration decouples focal point motion from propagation direction, enabling multi-dimensional control of laser focus trajectories using diffractive optics and chirped pulses.


<details>
  <summary>Details</summary>
Motivation: Existing flying focus techniques constrain focal point motion to the propagation direction, limiting flexibility for various laser applications that could benefit from multi-dimensional control.

Method: Uses chirped laser pulses focused and diffracted by a diffractive lens and grating to create focal points that move both along and transverse to propagation direction. For high-power pulses, holographic configuration with off-axis pump beams; for low-power, conventional solid-state or adaptive optics.

Result: Simulations demonstrate successful control over focal point direction and velocity. The focal length, grating period, and chirp can be tuned to precisely control the motion trajectory.

Conclusion: Multi-dimensional control over focal trajectories enables new configurations for applications including laser wakefield acceleration, THz radiation steering, and surface harmonic generation.

Abstract: Flying focus techniques produce laser pulses whose focal points travel at
arbitrary, controllable velocities. While this flexibility can enhance a broad
range of laser-based applications, existing techniques constrain the motion of
the focal point to the propagation direction of the pulse. Here, we introduce a
flying focus configuration that decouples the motion of the focus from the
propagation direction. A chirped laser pulse focused and diffracted by a
diffractive lens and grating creates a focal point that can move both along and
transverse to the propagation direction. The focal length of the lens, grating
period, and chirp can be tuned to control the direction and velocity of the
focus. Simulations demonstrate this control for a holographic configuration
suited to high-power pulses, in which two off-axis pump beams with different
focal lengths encode the equivalent phase of a chromatic lens and grating in a
gas or plasma. For low-power pulses, conventional solid-state or adaptive
optics can be used instead. Multi-dimensional control over the focal trajectory
enables new configurations for applications, including laser wakefield
acceleration of ions, steering of broadband THz radiation, and surface harmonic
generation.

</details>


### [65] [Resonate-and-Fire Photonic-Electronic Spiking Neurons for Fast and Efficient Light-Enabled Neuromorphic Processing Systems](https://arxiv.org/abs/2510.14515)
*Andrew Adair,Dafydd Owen-Newns,Giovanni Donati,Joshua Robertson,José Figueiredo,Eduard Wasige,Qusay Al-Taai,Bruno Romeira,Matěj Hejda,Antonio Hurtado*

Main category: physics.optics

TL;DR: A photonic-electronic resonate-and-fire spiking neuron that responds to temporal patterns of optical inputs, enabling ultrafast, energy-efficient neuromorphic computing with capabilities like spike-frequency filtering and temporal pattern recognition.


<details>
  <summary>Details</summary>
Motivation: Existing photonic neurons mainly mimic basic integrate-and-fire models, but neuroscience shows neurons encode information through richer temporal and frequency patterns. Photonic approaches promise ultrafast, energy-efficient operation with low crosstalk and high bandwidth.

Method: Developed a light-sensitive resonant tunnelling diode that produces excitable spikes in response to nanosecond, low-power optical signals at infrared telecom wavelengths. Demonstrated control through inter-pulse timing and bias voltage, supporting optical fan-in via wavelength-division multiplexed inputs from four VCSELs.

Result: Achieved bandpass filtering of both analogue and digital inputs. The neuron exhibits key functionalities including spike-frequency filtering, temporal pattern recognition, and digital-to-spiking conversion. Operates with nanosecond, low-power (100 microwatt) optical signals.

Conclusion: Establishes a pathway toward low-power, high-speed temporal information processing for light-enabled neuromorphic computing, addressing limitations of existing photonic neurons by incorporating richer temporal encoding mechanisms observed in biological neurons.

Abstract: Neuromorphic computing seeks to replicate the spiking dynamics of biological
neurons for brain-inspired computation. While electronic implementations of
artificial spiking neurons have dominated to date, photonic approaches are
attracting increasing research interest as they promise ultrafast,
energy-efficient operation with low-crosstalk and high bandwidth. Nevertheless,
existing photonic neurons largely mimic integrate-and-fire models, but
neuroscience shows that neurons also encode information through richer
mechanisms, such as the frequency and temporal patterns of spikes. Here, we
present a photonic-electronic resonate-and-fire (R-and-F) spiking neuron that
responds to the temporal structure of high-speed optical inputs. This is based
on a light-sensitive resonant tunnelling diode that produces excitable spikes
in response to nanosecond, low-power (100 microwatt) optical signals at
infrared telecom wavelengths. We experimentally demonstrate control of R-and-F
dynamics through inter-pulse timing of the optical stimuli and applied bias
voltage, achieving bandpass filtering of both analogue and digital inputs. The
R-and-F neuron also supports optical fan-in via wavelength-division multiplexed
inputs from four vertical-cavity surface-emitting lasers (VCSELs). This
electronic-photonic neuron exhibits key functionalities - including
spike-frequency filtering, temporal pattern recognition, and digital-to-spiking
conversion - critical for neuromorphic optical processing. Our approach
establishes a pathway toward low-power, high-speed temporal information
processing for light-enabled neuromorphic computing.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [66] [Multi-Period Sparse Optimization for Proactive Grid Blackout Diagnosis](https://arxiv.org/abs/2510.14045)
*Qinghua Ma,Reetam Sen Biswas,Denis Osipov,Guannan Qu,Soummya Kar,Shimiao Li*

Main category: eess.SY

TL;DR: Proposes a multi-period sparse optimization method to identify persistent failure sources across collapsed power systems under increasing stress, enabling early warning of key vulnerabilities.


<details>
  <summary>Details</summary>
Motivation: Power grids need to evaluate survivability under extreme events that could cause blackouts. Identifying persistent vulnerabilities across correlated failure scenarios can enhance system resilience through early warning diagnosis.

Method: Uses multi-period sparse optimization with persistency constraints to capture evolving vulnerabilities. Employs circuit-theory based power flow formulations and circuit-inspired optimization heuristics for scalability.

Result: Method reliably tracks persistent vulnerability locations under increasing load stress and scales to large systems (average ~200s per scenario on 2000+ bus systems).

Conclusion: The proposed approach effectively identifies persistent failure sources across multiple collapse scenarios, providing a scalable solution for early warning diagnosis in power grid resilience assessment.

Abstract: Existing or planned power grids need to evaluate survivability under extreme
events, like a number of peak load overloading conditions, which could possibly
cause system collapses (i.e. blackouts). For realistic extreme events that are
correlated or share similar patterns, it is reasonable to expect that the
dominant vulnerability or failure sources behind them share the same locations
but with different severity. Early warning diagnosis that proactively
identifies the key vulnerabilities responsible for a number of system collapses
of interest can significantly enhance resilience. This paper proposes a
multi-period sparse optimization method, enabling the discovery of {persistent
failure sources} across a sequence of collapsed systems with increasing system
stress, such as rising demand or worsening contingencies. This work defines
persistency and efficiently integrates persistency constraints to capture the
``hidden'' evolving vulnerabilities. Circuit-theory based power flow
formulations and circuit-inspired optimization heuristics are used to
facilitate the scalability of the method. Experiments on benchmark systems show
that the method reliably tracks persistent vulnerability locations under
increasing load stress, and solves with scalability to large systems ({on
average} taking {around} 200 s per scenario on 2000+ bus systems).

</details>
