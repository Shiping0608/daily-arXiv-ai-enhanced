<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 22]
- [math.AP](#math.AP) [Total: 16]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 7]
- [hep-ph](#hep-ph) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [math.OC](#math.OC) [Total: 2]
- [math.DG](#math.DG) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [math.ST](#math.ST) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [nlin.SI](#nlin.SI) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 2]
- [stat.ME](#stat.ME) [Total: 1]
- [physics.optics](#physics.optics) [Total: 2]
- [math.PR](#math.PR) [Total: 1]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A decoupled Crank-Nicolson leap-frog scheme for the unsteady bioconvection flows problem with concentration dependent viscosity](https://arxiv.org/abs/2510.14034)
*Chenyang Li*

Main category: math.NA

TL;DR: A fully discrete Crank-Nicolson Leap-Frog scheme is developed for unsteady bioconvection flow with concentration-dependent viscosity, using FEM for spatial and CNLF for temporal discretization.


<details>
  <summary>Details</summary>
Motivation: To develop a stable and efficient numerical scheme for bioconvection flow problems with variable viscosity that depends on concentration, addressing the need for accurate simulations without restrictive time step limitations.

Method: Combines Galerkin finite element method for spatial discretization with Crank-Nicolson Leap-Frog scheme for temporal discretization, using semi-implicit approach for nonlinear terms.

Result: The scheme is proven to be unconditionally stable (no restrictive time step bound) and provides L^2-optimal error estimates for velocity and concentration, with numerical experiments validating theoretical results.

Conclusion: The proposed CNLF scheme offers an effective numerical method for bioconvection flow problems with concentration-dependent viscosity, demonstrating unconditional stability and optimal accuracy.

Abstract: A fully discrete Crank--Nicolson Leap--Frog (CNLF) scheme is proposed and
analyzed for the unsteady bioconvection flow problem with
concentration-dependent viscosity. Spatial discretization is handled via the
Galerkin finite element method (FEM), while temporal discretization employs the
CNLF method for the linear terms and a semi-implicit approach for the nonlinear
terms. The scheme is proven to be unconditionally stable, i.e., the time step
is not subject to a restrictive upper bound. Using the energy method,
$L^2$-optimal error estimates are derived for the velocity and concentration .
Finally, numerical experiments are presented to validate the theoretical
results.

</details>


### [2] [Geometric local parameterization for solving Hele-Shaw problems with surface tension](https://arxiv.org/abs/2510.14088)
*Zengyan Zhang,Wenrui Hao,John Harlim*

Main category: math.NA

TL;DR: A computational framework using point clouds and Generalized Moving Least Squares (GMLS) for solving 2D Hele-Shaw free boundary problems with surface tension, achieving high-order spatial convergence without global parameterization.


<details>
  <summary>Details</summary>
Motivation: To develop a method that eliminates the need for global parameterization in free boundary problems by using point clouds, enabling more flexible handling of complex geometries and providing high-order approximations directly from point cloud data.

Method: Represent moving boundary by point clouds, use GMLS to construct local geometric charts for high-order curvature approximations, discretize boundary integral equations with analytical singular integrals, and perform rigorous convergence analysis.

Result: Numerical experiments confirm high-order spatial convergence and expected temporal convergence rates. Complex initial shapes correctly evolve toward circular equilibrium states under surface tension.

Conclusion: The proposed framework successfully solves 2D Hele-Shaw problems with surface tension using point clouds and GMLS, providing high-order accuracy without global parameterization and demonstrating effectiveness through numerical validation.

Abstract: In this work, we introduce a novel computational framework for solving the
two-dimensional Hele-Shaw free boundary problem with surface tension. The
moving boundary is represented by point clouds, eliminating the need for a
global parameterization. Our approach leverages Generalized Moving Least
Squares (GMLS) to construct local geometric charts, enabling high-order
approximations of geometric quantities such as curvature directly from the
point cloud data. This local parameterization is systematically employed to
discretize the governing boundary integral equation, including an analytical
formula of the singular integrals. We provide a rigorous convergence analysis
for the proposed spatial discretization, establishing consistency and stability
under certain conditions. The resulting error bound is derived in terms of the
size of the uniformly sampled point cloud data on the moving boundary, the
smoothness of the boundary, and the order of the numerical quadrature rule.
Numerical experiments confirm the theoretical findings, demonstrating
high-order spatial convergence and the expected temporal convergence rates. The
method's effectiveness is further illustrated through simulations of complex
initial shapes, which correctly evolve towards circular equilibrium states
under the influence of surface tension.

</details>


### [3] [A Stochastic Algorithm for Searching Saddle Points with Convergence Guarantee](https://arxiv.org/abs/2510.14144)
*Baoming Shi,Lei Zhang,Qiang Du*

Main category: math.NA

TL;DR: A stochastic saddle-search algorithm is proposed that avoids exact derivative and Hessian evaluations, using stochastic eigenvector-search and gradient updates with reflections to find saddle points efficiently.


<details>
  <summary>Details</summary>
Motivation: Saddle points reveal transition pathways and energy landscape structure, but traditional methods require exact derivative/Hessian evaluations which can be computationally expensive.

Method: Stochastic eigenvector-search approximates unstable directions using stochastic Hessian, followed by stochastic gradient updates with reflections to advance toward saddle points.

Result: The algorithm achieves almost sure convergence for eigenvector search and local almost sure convergence with O(1/n) rate for saddle search, with theoretical guarantees for high-probability identification near saddle points.

Conclusion: Numerical experiments demonstrate practical applicability for escaping "bad" areas in neural network loss landscapes and nematic liquid crystal models, showing the algorithm's effectiveness in complex systems.

Abstract: Saddle points provide a hierarchical view of the energy landscape, revealing
transition pathways and interconnected basins of attraction, and offering
insight into the global structure, metastability, and possible collective
mechanisms of the underlying system. In this work, we propose a stochastic
saddle-search algorithm to circumvent exact derivative and Hessian evaluations
that have been used in implementing traditional and deterministic saddle
dynamics. At each iteration, the algorithm uses a stochastic eigenvector-search
method, based on a stochastic Hessian, to approximate the unstable directions,
followed by a stochastic gradient update with reflections in the approximate
unstable direction to advance toward the saddle point. We carry out rigorous
numerical analysis to establish the almost sure convergence for the stochastic
eigenvector search and local almost sure convergence with an $O(1/n)$ rate for
the saddle search, and present a theoretical guarantee to ensure the
high-probability identification of the saddle point when the initial point is
sufficiently close. Numerical experiments, including the application to a
neural network loss landscape and a Landau-de Gennes type model for nematic
liquid crystal, demonstrate the practical applicability and the ability for
escaping from "bad" areas of the algorithm.

</details>


### [4] [Superconvergent and Divergence-Free Finite Element Methods for Stokes Equation](https://arxiv.org/abs/2510.14192)
*Long Chen,Xuehai Huang,Chao Zhang,Xinyue Zhao*

Main category: math.NA

TL;DR: Development of superconvergent and divergence-free finite element methods for the Stokes equation using H(div)-conforming vector elements and discontinuous polynomials.


<details>
  <summary>Details</summary>
Motivation: To create stable and accurate finite element methods for the Stokes equation that ensure divergence-free velocity fields without requiring stabilization.

Method: Uses H(div)-conforming vector elements for velocity and discontinuous piecewise polynomials for pressure, with a weak deviatoric gradient operator built using tangential-normal continuous finite elements for traceless tensors.

Result: Optimal and superconvergent error estimates are established, and numerical experiments confirm the theoretical results.

Conclusion: The method provides a stable, divergence-free approach that connects to nonconforming virtual element and pseudostress-velocity-pressure mixed formulations.

Abstract: Superconvergent and divergence-free finite element methods for the Stokes
equation are developed. The velocity and pressure are discretized using
$H(\mathrm{div})$-conforming vector elements and discontinuous piecewise
polynomials. The discrete formulation employs a weak deviatoric gradient
operator built with tangential-normal continuous finite elements for traceless
tensors, requiring no stabilization. Optimal and superconvergent error
estimates are established. The method connects to nonconforming virtual element
and pseudostress-velocity-pressure mixed formulations. Numerical experiments
verify the theory.

</details>


### [5] [Neural Networks for Bayesian Inverse Problems Governed by a Nonlinear ODE](https://arxiv.org/abs/2510.14197)
*German Villalobos,Johann Rudi,Andreas Mang*

Main category: math.NA

TL;DR: Neural networks are used for Bayesian parameter estimation in the FitzHugh-Nagumo neuron model, overcoming challenges like nonlinearity and nonconvexity to estimate model parameters, noise characteristics, and posterior uncertainties with single forward passes.


<details>
  <summary>Details</summary>
Motivation: To address mathematical and computational challenges in classical parameter estimation methods for nonlinear ODE systems, particularly the FitzHugh-Nagumo neuron model, which exhibits strong nonlinearities, nonconvexity, and sharp gradients.

Method: Formulate parameter estimation as Bayesian inverse problem using neural networks to approximate reconstruction maps from noisy observational data (time series of spiking membrane potential). Explore different NN architectures to estimate model parameters, noise parameters, and posterior covariance matrix.

Result: NNs successfully estimate parameters controlling dynamics, autocorrelated additive noise parameters, stochastic differential equation noise, and posterior uncertainties with single forward evaluation. Results show influence of noise on prediction accuracy and report timing results for training on dedicated hardware.

Conclusion: Neural networks are versatile tools for estimating parameters of dynamical systems, stochastic processes, and uncertainties as they propagate through governing ODEs, overcoming traditional computational challenges.

Abstract: We investigate the use of neural networks (NNs) for the estimation of hidden
model parameters and uncertainty quantification from noisy observational data
for inverse parameter estimation problems. We formulate the parameter
estimation as a Bayesian inverse problem. We consider a parametrized system of
nonlinear ordinary differential equations (ODEs), which is the FitzHugh--Nagumo
model. The considered problem exhibits significant mathematical and
computational challenges for classical parameter estimation methods, including
strong nonlinearities, nonconvexity, and sharp gradients. We explore how NNs
overcome these challenges by approximating reconstruction maps for parameter
estimation from observational data. The considered data are time series of the
spiking membrane potential of a biological neuron. We infer parameters
controlling the dynamics of the model, noise parameters of autocorrelated
additive noise, and noise modeled via stochastic differential equations, as
well as the covariance matrix of the posterior distribution to expose parameter
uncertainties--all with just one forward evaluation of an appropriate NN. We
report results for different NN architectures and study the influence of noise
on prediction accuracy. We also report timing results for training NNs on
dedicated hardware. Our results demonstrate that NNs are a versatile tool to
estimate parameters of the dynamical system, stochastic processes, as well as
uncertainties, as they propagate through the governing ODE.

</details>


### [6] [High-Order Meshfree Surface Integration, Including Singular Integrands](https://arxiv.org/abs/2510.14236)
*Daniel R. Venn,Steven J. Ruuth*

Main category: math.NA

TL;DR: High-order meshfree methods for surface integration on point clouds, handling arbitrary surfaces and singular integrals without requiring specific point arrangements or triangulation.


<details>
  <summary>Details</summary>
Motivation: Surface integration is important for PDE applications, but mesh-based methods need curved meshes and meshfree methods typically require exact integrals that are unknown on most surfaces.

Method: Two meshfree methods for arbitrary piecewise-smooth surfaces that don't require specific point arrangements or initial triangulation, with extensions for handling singular integrals.

Result: Methods maintain high accuracy for singular integrals without needing increased point density near singularities.

Conclusion: Developed practical high-order integration methods for surface point clouds that are completely meshfree and handle challenging cases like singular integrals.

Abstract: We develop and test high-order methods for integration on surface point
clouds. The task of integrating a function on a surface arises in a range of
applications in engineering and the sciences, particularly those involving
various integral methods for partial differential equations. Mesh-based methods
require a curved mesh for high-order convergence, which can be difficult to
reliably obtain on many surfaces, and most meshfree methods require the ability
to integrate a set of functions (such as radial basis functions) exactly on the
domain of interest; these integrals are generally not known in closed form on
most surfaces. We describe two methods for integrating on arbitrary,
piecewise-smooth surfaces with or without boundary. Our approaches do not
require a particular arrangement of points or an initial triangulation of the
surface, making them completely meshfree. We also show how the methods can be
extended to handle singular integrals while maintaining high accuracy without
changing the point density near singularities.

</details>


### [7] [A DeepLagrangian method for learning and generating aggregation patterns in multi-dimensional Keller-Segel chemotaxis systems](https://arxiv.org/abs/2510.14297)
*Yani Feng,Michael K. Ng,Zhiwen Zhang*

Main category: math.NA

TL;DR: DeepLagrangian is a self-adaptive method that learns and generates aggregation patterns and near-singular solutions of the Keller-Segel chemotaxis system in 2D and 3D space using a Lagrangian framework and flow-based generative models.


<details>
  <summary>Details</summary>
Motivation: Solving the Keller-Segel chemotaxis system is challenging due to near-singular solutions like finite-time blow-up or concentration phenomena. Existing methods struggle with these singular behaviors.

Method: Normalize KS solution into PDF, derive normalized KS system, rewrite into Lagrangian framework using continuity equation, define physics-informed Lagrangian loss, use time-dependent KRnet flow-based generative model to approximate PDF, integrate time-marching strategies.

Result: Method accurately generates aggregation patterns and near-singular solutions for 2D and 3D KS chemotaxis system with/without advection. Proves Lagrangian loss controls KL divergence between approximate and exact PDF.

Conclusion: DeepLagrangian provides an effective self-adaptive framework for handling near-singular solutions in chemotaxis systems, with demonstrated accuracy in 2D and 3D cases.

Abstract: The Keller-Segel (KS) chemotaxis system is used to describe the overall
behavior of a collection of cells under the influence of chemotaxis. However,
solving the KS chemotaxis system and generating its aggregation patterns remain
challenging due to the emergence of solutions exhibiting near-singular
behavior, such as finite-time blow-up or concentration phenomena. Building on a
Lagrangian framework of the KS system, we develop DeepLagrangian, a
self-adaptive density estimation method that learns and generates aggregation
patterns and near-singular solutions of the KS system in two- and
three-dimensional (2D and 3D) space under different physical parameters. The
main advantage of the Lagrangian framework is its inherent ability to adapt to
near-singular solutions. To develop this framework, we normalize the KS
solution into a probability density function (PDF), derive the corresponding
normalized KS system, and utilize the property of the continuity equation to
rewrite the system into a Lagrangian framework. We then define a
physics-informed Lagrangian loss to enforce this framework and incorporate a
flow-based generative model, called the time-dependent KRnet, to approximate
the PDF by minimizing the loss. Furthermore, we integrate time-marching
strategies with the time-dependent KRnet to enhance the accuracy of the PDF
approximation. After obtaining the approximate PDF, we recover the original KS
solution. We also prove that the Lagrangian loss effectively controls the
Kullback-Leibler (KL) divergence between the approximate PDF and the exact PDF.
In the numerical experiments, we demonstrate the accuracy of our DeepLagrangian
method for the 2D and 3D KS chemotaxis system with/without advection.

</details>


### [8] [Numerical Approximation of Electrohydrodynamics Model: A Comparative Study of PINNs and FEM](https://arxiv.org/abs/2510.14310)
*Mara Martinez,B. Veena S. N. Rao,S. M. Mallikarjunaiah*

Main category: math.NA

TL;DR: PINNs are applied to solve the challenging Electrohydrodynamic problem using a novel L2-type total loss function without prior knowledge of exact solutions, showing excellent performance with limited training data and outperforming conventional FEM methods.


<details>
  <summary>Details</summary>
Motivation: Traditional methods like FEM face challenges in solving nonlinear differential equations, while recent advances in physics-informed neural networks show promise for approximating complex physical systems more effectively.

Method: A novel PINN approach with L2-type total loss function, using forward propagation for gradient/curvature adjustments and backpropagation for hyperparameter refinement, without requiring exact solution knowledge.

Result: PINNs demonstrate excellent performance with limited training data, substantially outperforming FEM accuracy which can only be enhanced through smaller mesh sizes.

Conclusion: PINNs provide a powerful alternative to traditional FEM for solving challenging nonlinear differential equations like EHD problems, offering high accuracy without exact solution knowledge and efficient performance with limited data.

Abstract: The accurate representation of numerous physical, chemical, and biological
processes relies heavily on differential equations (DEs), particularly
nonlinear differential equations (NDEs). While understanding these complex
systems necessitates obtaining solutions to their governing equations, the
derivation of precise approximations for NDEs remains a formidable task in
computational mathematics. Although established techniques such as the finite
element method (FEM) have long been foundational, remarkable promise for
approximating continuous functions with high efficacy has recently been
demonstrated by advancements in physics-informed deep-learning feedforward
neural networks. In this work, a novel application of PINNs is presented for
the approximation of the challenging Electrohydrodynamic (EHD) problem. A
specific $L^2$-type \textit{total loss function} is employed, notably without
reliance on any prior knowledge of the exact solution. A comprehensive
comparative study is conducted, juxtaposing the approximation capabilities of
the proposed neural network with those of the conventional FEM. The PINN
training regimen is composed of two critical steps: forward propagation for
adjustments to gradient and curvature, and backpropagation for the refinement
of hyperparameters. The critical challenge of identifying optimal neural
network architectures and hyperparameter configurations for efficient
optimization is meticulously investigated. Excellent performance is shown to be
delivered by the neural network even with a limited training dataset.
Simultaneously, it is demonstrated that the accuracy of the FEM can be
substantially enhanced through the judicious selection of smaller mesh sizes.

</details>


### [9] [High-order mass- and energy-conserving methods for the nonlinear Schrödinger equation and its hyperbolization](https://arxiv.org/abs/2510.14335)
*Hendrik Ranocha,David I. Ketcheson*

Main category: math.NA

TL;DR: A new class of high-order numerical methods for the nonlinear Schrödinger equation that conserves both mass and energy, using efficient relaxation techniques and requiring only scalar algebraic equations per time step.


<details>
  <summary>Details</summary>
Motivation: To develop efficient and robust numerical methods for the nonlinear Schrödinger equation that preserve important physical invariants (mass and energy) while achieving high-order accuracy in both space and time.

Method: Relaxation-type approach for conserving multiple nonlinear functionals, building on existing spatial discretizations like Fourier spectral methods, with a new efficient method that requires only solving scalar algebraic equations per time step.

Result: The proposed schemes demonstrate high accuracy and efficiency on test problems for both focusing and defocusing NLS equations, showing improved performance compared to existing multiple-relaxation approaches.

Conclusion: The new relaxation approach provides an effective framework for conserving multiple invariants in NLS simulations, offering better efficiency and robustness than previous methods while maintaining high-order accuracy.

Abstract: We propose a class of numerical methods for the nonlinear Schr\"odinger (NLS)
equation that conserves mass and energy, is of arbitrarily high-order accuracy
in space and time, and requires only the solution of a scalar algebraic
equation per time step. We show that some existing spatial discretizations,
including the popular Fourier spectral method, are in fact energy-conserving if
one considers the appropriate form of the energy density. We develop a new
relaxation-type approach for conserving multiple nonlinear functionals that is
more efficient and robust for the NLS equation compared to the existing
multiple-relaxation approach. The accuracy and efficiency of the new schemes is
demonstrated on test problems for both the focusing and defocusing NLS.

</details>


### [10] [Asymptotic-preserving semi-Lagrangian discontinuous Galerkin schemes for the Boltzmann equation](https://arxiv.org/abs/2510.14375)
*Xiaofeng Cai,Zhen Hao,Liu Liu,Jiayu Wan*

Main category: math.NA

TL;DR: An asymptotic-preserving semi-Lagrangian discontinuous Galerkin scheme for the Boltzmann equation that handles multi-scale transport phenomena using IMEX-RK time integration and a novel moments update procedure.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical scheme that effectively handles multi-scale transport phenomena in the Boltzmann equation, particularly addressing the challenge of designing appropriate moments update for penalization within the semi-Lagrangian framework.

Method: Semi-Lagrangian discontinuous Galerkin scheme with implicit-explicit Runge-Kutta (IMEX-RK) time integration, utilizing the Shu-Osher form of the scheme and constructing an appropriate moments update procedure to capture the correct limiting system.

Result: Theoretical analysis establishes accuracy order conditions for both IMEX-RK time integration and the new moments update step. Numerical experiments validate the scheme's accuracy, asymptotic-preserving property, and robustness across various regimes.

Conclusion: The proposed scheme demonstrates effectiveness for multi-scale kinetic simulations, with proven accuracy, stability, and asymptotic-preserving properties across different transport regimes.

Abstract: In this work, we present an asymptotic-preserving semi-Lagrangian
discontinuous Galerkin scheme for the Boltzmann equation that effectively
handles multi-scale transport phenomena. The main challenge lies in designing
appropriate moments update for penalization within the semi-Lagrangian
framework. Inspired by [M. Ding, J. M. Qiu, and R. Shu, Multiscale Model.
Simul. 21 (2023), no. 1, 143--167], the key ingredient is utilizing the
Shu-Osher form of the scheme in the implicit-explicit Runge-Kutta (IMEX-RK)
setting, which enables us to capture the correct limiting system by
constructing an appropriate moments update procedure. Our theoretical analysis
establishes accuracy order conditions for both the IMEX-RK time integration and
the new moments update step. We also employ hypocoercivity techniques to
establish stability for the linearized model. Numerical experiments for various
test problems validate our proposed scheme's accuracy, asymptotic-preserving
property, and robustness in various regimes, which demonstrates its
effectiveness for multi-scale kinetic simulations.

</details>


### [11] [Preconditioned Conjugate Gradient methods for the estimation of General Linear Models](https://arxiv.org/abs/2510.14471)
*Paolo Foschi*

Main category: math.NA

TL;DR: PCG method with indefinite preconditioner solves GLS estimation via augmented system, iterating OLS steps to converge to GLS estimator in finite steps, enabling efficient structured GLM estimation.


<details>
  <summary>Details</summary>
Motivation: To efficiently compute Generalized Least Squares (GLS) estimator for General Linear Models by combining direct and iterative methods, particularly for structured problems where direct methods are computationally expensive.

Method: Express GLS estimator as augmented system solved by Preconditioned Conjugate Gradient (PCG) method with indefinite preconditioner, iterating Ordinary Least Squares (OLS) estimations that converge to GLS estimator.

Result: The method achieves same precision as state-of-the-art direct methods but in significantly less time for structured problems, with analytical and numerical validation of intermediate estimator properties.

Conclusion: PCG with indefinite preconditioner provides efficient framework for GLS estimation in structured GLMs, combining strengths of direct and iterative methods while exploiting matrix structures.

Abstract: The use of the Preconditioned Conjugate Gradient (PCG) method for computing
the Generalized Least Squares (GLS) estimator of the General Linear Model (GLM)
is considered. The GLS estimator is expressed in terms of the solution of an
augmented system. That system is solved by means of the PCG method using an
indefinite preconditioner. The resulting method iterates a sequence Ordinary
Least Squares (OLS) estimations that converges, in exact precision, to the GLS
estimator within a finite number of steps. The numerical and statistical
properties of the estimator computed at an intermediate step are analytically
and numerically studied. This approach allows to combine direct methods, used
in the OLS step, with those of iterative methods. This advantage is exploited
to design PCG methods for the estimation of Constrained GLMs and of some
structured multivariate GLMs. The structure of the matrices involved are
exploited as much as possible, in the OLS step. The iterative method then
solves for the unexploited structure. Numerical experiments shows that the
proposed methods can achieve, for these structured problems, the same precision
of state of the art direct methods, but in a fraction of the time.

</details>


### [12] [A Well-Balanced Space-Time ALE Compact Gas-Kinetic Scheme for the Shallow Water Equations on Unstructured Meshes](https://arxiv.org/abs/2510.14673)
*Fengxiang Zhao,Jianping Gan,Kun XU*

Main category: math.NA

TL;DR: A high-order space-time coupled arbitrary Lagrangian-Eulerian compact gas-kinetic scheme for shallow water equations on moving unstructured meshes that preserves geometric conservation law and well-balanced property without data remapping.


<details>
  <summary>Details</summary>
Motivation: To develop an accurate and efficient method for simulating shallow water flows on moving meshes that maintains conservation properties and avoids the computational cost of data remapping.

Method: Uses a compact gas-kinetic scheme with space-time coupling, incorporates mesh motion effects directly in numerical fluxes, establishes evolution equation for bottom topography, and employs nonlinear fourth-order compact reconstruction.

Result: The scheme achieves second-order temporal accuracy in single stage, preserves geometric conservation law and well-balanced property, and demonstrates accuracy and stability in complex shallow-water flow simulations.

Conclusion: The proposed ALE formulation provides an effective framework for simulating shallow water flows on moving meshes with guaranteed conservation properties and high accuracy.

Abstract: This study presents a high-order, space-time coupled arbitrary Lagrangian
Eulerian (ALE) compact gas-kinetic scheme (GKS) for the shallow water equations
on moving unstructured meshes. The proposed method preserves both the geometric
conservation law (GCL) and the well-balanced property. Mesh motion effects are
directly incorporated by formulating numerical fluxes that account for the
spatial temporal nonuniformity of the flow field and the swept area of moving
cell interfaces. This allows temporal updates to be performed on the physical
moving mesh, avoiding data remapping. The compact GKS provides time accurate
evolution of flow variables and fluxes, enabling the scheme to achieve
second-order temporal accuracy within a single stage. To consistently treat
bottom topography on moving meshes, an evolution equation for the topography is
established and discretized using a compatible space-time scheme, in which the
fluxes induced by mesh motion are computed accurately. Mathematical proofs
demonstrating the GCL preserving and well-balanced properties of the proposed
ALE formulation are also provided. For improved accuracy and robustness, a
nonlinear fourth-order compact reconstruction technique is employed. A
comprehensive set of numerical experiments verifies the scheme's theoretical
properties and demonstrates its accuracy, stability, and effectiveness in
simulating complex shallow-water flow problems.

</details>


### [13] [Generalized Fourier Series: An N log2(N) extension for aperiodic functions that eliminates Gibbs oscillations](https://arxiv.org/abs/2510.14731)
*Narsimha Reddy Rapakaa,Mohamed Kamel Riahi*

Main category: math.NA

TL;DR: Generalized Fourier Series (GFS) is a new spectral method that extends Fourier series to non-periodic functions by decomposing them into periodic and aperiodic components, avoiding Gibbs phenomenon and domain extensions while maintaining computational efficiency.


<details>
  <summary>Details</summary>
Motivation: To address limitations of classical Fourier series for non-periodic functions, including Gibbs phenomenon and poor convergence, without requiring computational domain extensions.

Method: Decomposes functions into periodic (standard Fourier modes via FFT) and aperiodic components using adaptive low-rank sinusoidal functions with non-harmonic modes that dynamically capture discontinuities and derivative jumps.

Result: Achieves high accuracy for non-periodic functions and their derivatives, maintains N log2(N) computational complexity, and provides compact representations without domain extensions.

Conclusion: GFS offers an efficient and robust framework for high-accuracy function approximation in non-periodic domains, with significant potential for applications in numerical PDEs, signal processing, machine learning, and computational physics.

Abstract: This article introduces the Generalized Fourier Series (GFS), a novel
spectral method that extends the clas- sical Fourier series to non-periodic
functions. GFS addresses key challenges such as the Gibbs phenomenon and poor
convergence in non-periodic settings by decomposing functions into periodic and
aperiodic com- ponents. The periodic part is represented using standard Fourier
modes and efficiently computed via the Fast Fourier Transform (FFT). The
aperiodic component employs adaptive, low-rank sinusoidal functions with
non-harmonic modes, dynamically tuned to capture discontinuities and derivative
jumps across domain boundaries. Unlike conventional Fourier extension methods,
GFS achieves high accuracy without requiring compu- tational domain extensions,
offering a compact and efficient representation of non-periodic functions. The
adaptive low-rank approach ensures accuracy while minimizing computational
overhead, typically involving additional complex modes for the aperiodic part.
Furthermore, GFS demonstrates a high-resolution power, with degrees of freedom
comparable to FFT in periodic domains, and maintains N log2(N) computational
complexity. The effectiveness of GFS is validated through numerical
experiments, showcasing its ability to approximate functions and their
derivatives in non-periodic domains accurately. With its robust framework and
minimal computational cost, GFS holds significant potential for advancing
applications in numerical PDEs, signal processing, machine learning, and
computational physics by providing a robust and efficient tool for
high-accuracy function approximations.

</details>


### [14] [On the convergence of stochastic variance reduced gradient for linear inverse problems](https://arxiv.org/abs/2510.14759)
*Bangti Jin,Zehui Zhou*

Main category: math.NA

TL;DR: Analysis of SVRG and its regularized version for solving linear inverse problems in Hilbert spaces, proving optimal convergence rates with constant step sizes.


<details>
  <summary>Details</summary>
Motivation: To provide theoretical guarantees for SVRG methods in solving large-scale inverse problems, addressing optimal convergence without early stopping rules.

Method: Theoretical analysis using explicit error recursion and prior estimates on inner loop updates, with numerical experiments for validation.

Result: Regularized SVRG achieves optimal convergence rates without early stopping, while standard SVRG is optimal for nonsmooth solutions with a priori stopping rules.

Conclusion: Both SVRG variants are effective for linear inverse problems with proper step size schedules and regularity conditions, supported by theoretical and numerical evidence.

Abstract: Stochastic variance reduced gradient (SVRG) is an accelerated version of
stochastic gradient descent based on variance reduction, and is promising for
solving large-scale inverse problems. In this work, we analyze SVRG and a
regularized version that incorporates a priori knowledge of the problem, for
solving linear inverse problems in Hilbert spaces. We prove that, with suitable
constant step size schedules and regularity conditions, the regularized SVRG
can achieve optimal convergence rates in terms of the noise level without any
early stopping rules, and standard SVRG is also optimal for problems with
nonsmooth solutions under a priori stopping rules. The analysis is based on an
explicit error recursion and suitable prior estimates on the inner loop updates
with respect to the anchor point. Numerical experiments are provided to
complement the theoretical analysis.

</details>


### [15] [Ghost stabilisation for cut finite element exterior calculus](https://arxiv.org/abs/2510.14772)
*Daniele Di Pietro,Jérôme Droniou,Erik Nilsson*

Main category: math.NA

TL;DR: The paper introduces a Cut Finite Element Exterior Calculus (CutFEEC) method with stabilization for any form degree, making it robust to interface position relative to the mesh, and applies it to Hodge Laplace equations on unfitted meshes.


<details>
  <summary>Details</summary>
Motivation: To develop a finite element method that is robust with respect to interface position relative to the mesh, enabling discretization of Hodge Laplace equations on unfitted meshes in any dimension and topology.

Method: Cut finite element method formulated in finite element exterior calculus language with stabilization for any form degree, proving uniform equivalence between L2-norm on physical domain and active mesh.

Result: The method demonstrates convergence and condition number scaling independent of boundary position relative to background mesh, as shown in numerical experiments with H(curl) finite element space on a filled torus.

Conclusion: The CutFEEC method provides a robust approach for discretizing Hodge Laplace equations on unfitted meshes, with stabilization ensuring performance independent of interface position.

Abstract: We introduce the cut finite element method in the language of finite element
exterior calculus, by formulating a stabilisation -- for any form degree --
that makes the method robust with respect to the position of the interface
relative to the mesh. We prove that the $L^2$-norm on the physical domain
augmented with this stabilisation is uniformly equivalent to the $L^2$-norm on
the ``active'' mesh that contains all the degrees of freedom of the finite
element space (including those external to the physical domain). We show how
this CutFEEC method can be applied to discretize the Hodge Laplace equations on
an unfitted mesh, in any dimension and any topology. A numerical illustration
is provided involving a conforming finite element space of $H^{\text{curl}}$
posed on a filled torus, with convergence and condition number scaling
independent of the position of the boundary with respect to the background
mesh.

</details>


### [16] [Error analysis of Abate--Whitt methods for Inverse Laplace Transforms and a new algorithm for queuing theory applications](https://arxiv.org/abs/2510.14799)
*Nikita Deniskin,Federico Poloni*

Main category: math.NA

TL;DR: The paper analyzes Abate-Whitt methods for Inverse Laplace Transform computation and introduces TAME, a new family of methods using AAA algorithm for rational approximation, showing improved efficiency with fewer function evaluations.


<details>
  <summary>Details</summary>
Motivation: To improve the accuracy and efficiency of Inverse Laplace Transform methods, particularly for queuing theory applications where Abate-Whitt methods are commonly used but may require many function evaluations.

Method: Developed TAME methods using the AAA algorithm for rational approximation, with parameters optimized for function-specific domains. Specialized analysis for phase-type distributions and Markov-modulated fluid models.

Result: TAME methods require significantly fewer function evaluations while achieving comparable or better accuracy than classical Abate-Whitt methods, validated through numerical experiments.

Conclusion: The new TAME methods based on rational approximation via AAA algorithm provide more efficient and accurate alternatives to traditional Inverse Laplace Transform computation methods, particularly beneficial for queuing theory applications.

Abstract: We study the accuracy of a class of methods to compute the Inverse Laplace
Transform, the so-called \emph{Abate--Whitt methods} [Abate, Whitt 2006], which
are based on a linear combination of evaluations of $\widehat{f}$ in a few
points. We provide error bounds which relate the accuracy of a method to the
rational approximation of the exponential function. We specialize our analysis
to applications in queuing theory, a field in which Abate--Whitt methods are
often used; in particular, we study phase-type distributions and
Markov-modulated fluid models (or \emph{fluid queues}).
  We use a recently developed algorithm for rational approximation, the AAA
algorithm [Nakatsukasa, S\`ete, Trefethen 2018], to produce a new family of
methods, which we call TAME. The parameters of these methods are constructed
depending on a function-specific domain $\Omega$; we provide a quasi-optimal
choice for certain families of functions. We discuss numerical issues related
to floating-point computation, and we validate our results through numerical
experiments which show that the new methods require significantly fewer
function evaluations to achieve an accuracy that is comparable (or better) to
that of the classical methods.

</details>


### [17] [Augmented Lagrangian Method based adjoint space framework for sparse reconstruction of acoustic source with boundary measurements](https://arxiv.org/abs/2510.14805)
*Nirui Tan,Hongpeng Sun*

Main category: math.NA

TL;DR: A semismooth Newton-based augmented Lagrangian method for reconstructing sparse sources in inverse acoustic scattering problems, using measurement space iteration and Fenchel-Rockafellar duality for efficiency.


<details>
  <summary>Details</summary>
Motivation: To efficiently reconstruct sparse sources in inverse acoustic scattering problems, especially when measurement data is much less than the acoustic source, requiring computational acceleration.

Method: Semismooth Newton-based augmented Lagrangian method that iterates in measurement space rather than source space, combined with Fenchel-Rockafellar duality theory for source calculation.

Result: The method achieves high efficiency and computational cost leverage, with numerical examples demonstrating its effectiveness.

Conclusion: The proposed semismooth Newton-based method is highly efficient for sparse source reconstruction in inverse acoustic scattering problems.

Abstract: We propose a semismooth Newton-based augmented Lagrangian method for
reconstructing sparse sources in inverse acoustic scattering problems. The
semismooth Newton method can be iterated in the space of measurements instead
of the unknown source to be reconstructed. It is highly efficient, especially
when the measurement data is much less than the acoustic source. The source can
be calculated from Fenchel-Rockafellar duality theory. We can obtain lots of
acceleration and leverage the computational cost. The numerical examples show
the high efficiency of the proposed semismooth Newton-based methods.

</details>


### [18] [Polynomial Preconditioning for Indefinite Matrices](https://arxiv.org/abs/2510.14816)
*Hayden Henson,Ronald B. Morgan*

Main category: math.NA

TL;DR: This paper presents improved polynomial preconditioning methods for indefinite matrices, including spectrum balancing, specialized stability approaches for indefinite cases, and convergence analysis for real indefinite spectra.


<details>
  <summary>Details</summary>
Motivation: Polynomial preconditioning is important for solving large linear systems and eigenvalue problems, but existing methods have limitations when dealing with indefinite matrices and complex spectra.

Method: The authors develop new techniques including balancing polynomials to produce definite spectra, specialized stability approaches for indefinite cases, analysis of complex spectra, and convergence estimates for real indefinite spectra.

Result: The methods make polynomial preconditioning more generally applicable to indefinite matrices, and tests are performed for finding interior eigenvalues.

Conclusion: The proposed techniques successfully extend polynomial preconditioning to handle indefinite matrices and complex spectra, improving its applicability for solving large linear systems and eigenvalue problems.

Abstract: Polynomial preconditioning is an important tool in solving large linear
systems and eigenvalue problems. A polynomial from GMRES can be used to
precondition restarted GMRES and restarted Arnoldi. Here we give methods for
indefinite matrices that make polynomial preconditioning more generally
applicable. The new techniques include balancing the polynomial so that it
produces a definite spectrum. Then a stability approach is given that is
specialized for the indefinite case. Also, very complex spectra are examined.
Then convergence estimates are given for polynomial preconditioning of real,
indefinite spectra. Finally, tests are preformed of finding interior
eigenvalues.

</details>


### [19] [Efficient and Robust Carathéodory-Steinitz Pruning of Positive Discrete Measures](https://arxiv.org/abs/2510.14916)
*Filip Bělík,Jesse Chan,Akil Narayan*

Main category: math.NA

TL;DR: An efficient streaming algorithm for Carathéodory-Steinitz pruning that compresses positive quadrature rules while preserving moments, using Givens rotations and on-demand storage to handle large rules with storage complexity dependent only on function space dimension.


<details>
  <summary>Details</summary>
Motivation: To approximate integration against positive measures using positive discrete quadrature rules while preserving moments over finite-dimensional function spaces, and to improve upon naive implementations with quadratic runtime and linear storage complexity.

Method: Uses Givens rotations and on-demand storage in a streaming procedure for Carathéodory-Steinitz pruning, achieving storage complexity dependent only on function space dimension rather than original measure size.

Result: The algorithm achieves comparable runtimes to non-negative least squares and linear programming approaches, with improved stability and storage robustness, and demonstrates practical utility in generating quadrature for discontinuous Galerkin finite element simulations on cut-cell meshes.

Conclusion: The proposed streaming Carathéodory-Steinitz pruning method provides an efficient, stable, and storage-robust approach for compressing positive quadrature rules while preserving moments, outperforming naive implementations and alternative methods in practical applications.

Abstract: In many applications, one seeks to approximate integration against a positive
measure of interest by a positive discrete measure: a numerical quadrature rule
with positive weights. One common desired discretization property is moment
preservation over a finite dimensional function space, e.g., bounded-degree
polynomials. Carath\'{e}odory's theorem asserts that if there is any finitely
supported quadrature rule with more nodes than the dimension of the given
function space, one can form a smaller (and hence more efficient) positive,
nested, quadrature rule that preserves the moments of the original rule.
  We describe an efficient streaming procedure for Carath\'{e}odory-Steinitz
pruning, a numerical procedure that implements Carath\'{e}odory's theorem for
this measure compression. The new algorithm makes use of Givens rotations and
on-demand storage of arrays to successfully prune very large rules whose
storage complexity only depends on the dimension of the function space. This
approach improves on a naive implementation of Carath\'{e}odory-Steinitz
pruning whose runtime and storage complexity are quadratic and linear,
respectively, in the size of the original measure. We additionally prove
mathematical stability properties of our method with respect to a set of
admissible, total-variation perturbations of the original measure. Our method
is compared to two alternate approaches with larger storage requirements:
non-negative least squares and linear programming, and we demonstrate
comparable runtimes, with improved stability and storage robustness. Finally,
we demonstrate practical usage of this algorithm to generate quadrature for
discontinous Galerkin finite element simulations on cut-cell meshes.

</details>


### [20] [Rank of Matrices Arising out of Singular Kernel Functions](https://arxiv.org/abs/2510.14920)
*Sumit Singh,Sivaram Ambikasaran*

Main category: math.NA

TL;DR: This paper analyzes the rank of kernel matrices arising from particles arbitrarily distributed in adjacent hypercubes, providing theoretical bounds on expected rank and variance for various neighbor interactions.


<details>
  <summary>Details</summary>
Motivation: Kernel functions are widely used in differential equations and machine learning, but the rank behavior of corresponding matrices for arbitrary particle distributions was not formally studied, which is crucial for hierarchical matrix algorithms.

Method: Model arbitrary particle distributions as random processes, analyze rank bounds theoretically for different neighbor interactions, and validate with numerical experiments in 1D, 2D, and 3D.

Result: Obtained theoretical bounds on expected rank and variance of kernel matrices for arbitrary particle distributions, with numerical results confirming theoretical predictions across dimensions.

Conclusion: The work provides first formal analysis of kernel matrix ranks for arbitrary particle distributions, offering useful bounds for hierarchical matrix algorithm performance and complexity analysis.

Abstract: Kernel functions are frequently encountered in differential equations and
machine learning applications. In this work, we study the rank of matrices
arising out of the kernel function $K: X \times Y \mapsto \mathbb{R}$, where
the sets $X, Y \in \mathbb{R}^d$ are hypercubes that share a boundary. The main
contribution of this work is the analysis of the rank of such matrices where
the particles (sources/targets) are arbitrarily distributed within these
hypercubes. To our knowledge, this is the first work to formally investigate
the rank of such matrices for an arbitrary distribution of particles. We model
the arbitrary distribution of particles to arise from an underlying random
distribution and obtain bounds on the expected rank and variance of the rank of
the kernel matrix corresponding to various neighbor interactions. These bounds
are useful for understanding the performance and complexity of hierarchical
matrix algorithms (especially hierarchical matrices satisfying the
weak-admissibility criterion) for an arbitrary distribution of particles. We
also present numerical experiments in one-, two-, and three-dimensions, showing
the expected rank growth and variance of the rank for different types of
interactions. The numerical results, not surprisingly, align with our
theoretical predictions.

</details>


### [21] [Finite element methods for electroneutral multicomponent electrolyte flows](https://arxiv.org/abs/2510.14923)
*Aaron Baier-Reinio,Patrick E. Farrell,Charles W. Monroe*

Main category: math.NA

TL;DR: A family of high-order finite element algorithms for simulating electroneutral electrolyte flows using NSOSM equations, handling complex boundary conditions and non-ideal thermodynamics.


<details>
  <summary>Details</summary>
Motivation: To develop flexible numerical methods for simulating electrolyte flows under various conditions, accounting for multicomponent diffusion, electrical effects, and solution-dependent material parameters.

Method: High-order finite element algorithms solving electroneutral Navier-Stokes-Onsager-Stefan-Maxwell equations in 2D/3D, steady/transient settings with various boundary conditions.

Result: Successfully demonstrated algorithms in microfluidic rotating disk electrode and Hull cell configurations for lithium-ion battery electrolytes.

Conclusion: The approach provides a comprehensive framework for simulating complex electrolyte flows while addressing subtleties from boundary conditions and equation of state interactions.

Abstract: We present a broad family of high-order finite element algorithms for
simulating the flow of electroneutral electrolytes. The governing partial
differential equations that we solve are the electroneutral
Navier-Stokes-Onsager-Stefan-Maxwell (NSOSM) equations, which model momentum
transport, multicomponent diffusion and electrical effects within the
electrolyte. Our algorithms can be applied in the steady and transient
settings, in two and three spatial dimensions, and under a variety of boundary
conditions. Moreover, we allow for the material parameters (e.g. viscosity,
diffusivities, thermodynamic factors and density) to be solution-dependent and
thermodynamically non-ideal. The flexibility of our approach requires us to
address subtleties that arise in the governing equations due to the interplay
between boundary conditions and the equation of state. We demonstrate the
algorithms in various physical configurations, including (i) electrolyte flow
around a microfluidic rotating disk electrode and (ii) the flow in a Hull cell
of a cosolvent electrolyte mixture used in lithium-ion batteries.

</details>


### [22] [Efficient and Flexible Multirate Temporal Adaptivity](https://arxiv.org/abs/2510.14964)
*Daniel R. Reynolds,Sylvia Amihere,Dashon Mitchell,Vu Thai Luan*

Main category: math.NA

TL;DR: New multirate time step adaptivity controllers for embedded MRI methods that enable adaptive simulations with multiple time scales, achieving high accuracy with low computational cost.


<details>
  <summary>Details</summary>
Motivation: To develop efficient time step controllers for multirate infinitesimal (MRI) methods that can handle problems with multiple time scales, addressing the need for adaptive simulations with potentially arbitrary numbers of time scales.

Method: Two new families of multirate time step adaptivity controllers designed for embedded MRI methods, plus new embeddings for explicit multirate exponential Runge-Kutta (MERK) methods of orders 2-5.

Result: Dramatically improved performance and flexibility compared to competing approaches, with each controller family excelling on different multirate applications. First-ever fifth-order embedded MRI method created.

Conclusion: The combination of embedded MRI methods and the proposed controllers enables efficient adaptive simulations of multiscale problems, with guidance provided for selecting appropriate MRI methods and controllers.

Abstract: In this work we present two new families of multirate time step adaptivity
controllers, that are designed to work with embedded multirate infinitesimal
(MRI) time integration methods for adapting time steps when solving problems
with multiple time scales. We compare these controllers against competing
approaches on two benchmark problems and see that they offer dramatically
improved performance and flexibility, with each proposed family excelling on
different types of multirate applications. The combination of embedded MRI
methods and the proposed controllers enable adaptive simulations of problems
with a potentially arbitrary number of time scales, achieving high accuracy
while maintaining low computational cost. Additionally, we introduce a new set
of embeddings for the family of explicit multirate exponential Runge--Kutta
(MERK) methods of orders 2 through 5, resulting in the first-ever fifth-order
embedded MRI method. Finally, we compare the performance of a wide range of
embedded MRI methods on our benchmark problems to provide guidance on how to
select an appropriate MRI method and multirate controller.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [23] [Time-harmonic scattering of plane waves from an infinite periodically inhomogeneous medium](https://arxiv.org/abs/2510.14070)
*Guanghui Hu,Andreas Rathsfeld,Jiayi Zhang,Ruming Zhang*

Main category: math.AP

TL;DR: A new radiation condition for 2D infinite inhomogeneous media periodic in vertical direction, using Floquet theory to define wave modes and Dirichlet-to-Neumann maps for domain truncation.


<details>
  <summary>Details</summary>
Motivation: Classical Rayleigh-expansion radiation condition doesn't apply to vertically periodic media, requiring a new approach for such inhomogeneous structures.

Method: Use Floquet theory to derive upward/downward wave modes, define radiation conditions via mode expansions, and develop Dirichlet-to-Neumann maps for domain truncation.

Result: Proved mapping properties of Dirichlet-to-Neumann maps based on high-order wave mode asymptotics, and verified strong ellipticity of the scattering problem's sesquilinear form.

Conclusion: Unique solvability established for all wavenumbers except a countable set bounded below by a small positive constant.

Abstract: We propose a new radiation condition for an infinite inhomogeneous
two-dimensional medium which is periodic in the vertical direction and remains
invariant in the horizontal direction. The classical Rayleigh-expansion
radiation condition does not apply to our case, because this would require the
medium to be inhomogeneous in a half plane. We utilize the Floquet theory to
derive upward/downward wave modes and define radiation conditions by expansions
w.r.t. these modes. The downward radiation conditions leads to a downward
Dirichlet-to-Neumann map which can be used to truncate the infinite
inhomogeneous domain in the vertical direction. So we prove mapping properties
of the upward/downward Dirichlet-to-Neumann maps based on the asymptotic
behavior of high-order wave modes. Finally, we verify the strong ellipticity of
the sesquilinear form corresponding to the new scattering problem and show the
unique solvability for all wavenumbers with the exception of a countable set of
numbers bounded below by a small positive constant.

</details>


### [24] [Exponential and algebraic decay in Euler--alignment system with nonlocal interaction forces](https://arxiv.org/abs/2510.14123)
*José A. Carrillo,Young-Pil Choi,Dowan Koo,Oliver Tse*

Main category: math.AP

TL;DR: Analysis of large-time behavior of pressureless Euler system with nonlocal velocity alignment and interaction forces, showing convergence rates depend on communication weight types: bounded kernels yield exponential decay, weakly singular ones produce algebraic rates.


<details>
  <summary>Details</summary>
Motivation: To characterize asymptotic convergence of classical solutions under general interaction potentials and communication weights in Euler-alignment dynamics.

Method: Established quantitative convergence in three settings: 1D with (λ,Λ)-convex potentials, Coulomb-quadratic potential, and multi-dimensional uniformly (λ,Λ)-convex potentials.

Result: Density converges to minimizer of interaction energy (up to translation), velocity aligns to uniform constant. Bounded communication weights yield exponential decay, weakly singular ones lead to sharp algebraic rates.

Conclusion: Convergence rate depends only on local behavior of communication weights, providing comprehensive description of asymptotic behavior for Euler-alignment dynamics with general interaction potentials.

Abstract: We investigate the large-time behavior of the pressureless Euler system with
nonlocal velocity alignment and interaction forces, with the aim of
characterizing the asymptotic convergence of classical solutions under general
interaction potentials $W$ and communication weights. We establish quantitative
convergence in three settings. In one dimension with $(\lambda,\Lambda)$-convex
potentials, i.e., potentials satisfying uniform lower and upper quadratic
bounds, bounded communication weights yield exponential decay, while weakly
singular ones lead to sharp algebraic rates. For the Coulomb--quadratic
potential $W(x)=-|x|+\frac12 |x|^2$, we prove exponential convergence for
bounded communication weights and algebraic upper bounds for singular
communication weights. In a multi-dimensional setting with uniformly
$(\lambda,\Lambda)$-convex potentials, we show exponential decay for bounded
weights and improved algebraic decay for singular ones. In all cases, the
density converges (up to translation) to the minimizer of the interaction
energy, while the velocity aligns to a uniform constant. A unifying feature is
that the convergence rate depends only on the local behavior of communication
weights: bounded kernels yield exponential convergence, while weakly singular
ones produce algebraic rates. Our results thus provide a comprehensive
description of the asymptotic behavior of Euler--alignment dynamics with
general interaction potentials.

</details>


### [25] [Reconstruction of the non-linear wave at a buoy from shoreline data and applications to the tsunami inverse problem for piece-wise sloping bathymetry](https://arxiv.org/abs/2510.14177)
*Oleksandr Bobrovnikov,Madison Jones,Shriya Prasanna,Josiah Smith,Alexei Rybkin,Efim Pelinovsky*

Main category: math.AP

TL;DR: This paper investigates whether tsunami initial shape can be recovered from run-up data using non-linear shallow water equations, extending previous work to finite sloping bathymetry and incorporating dispersion effects.


<details>
  <summary>Details</summary>
Motivation: To solve the inverse problem of recovering tsunami initial conditions from shoreline run-up data, building on previous work that assumed infinite sloping bathymetry.

Method: Uses non-linear shallow water equations framework, extends to finite sloping bathymetry, recovers boundary conditions on virtual buoy from shoreline data, and combines shallow water equations with Boussinesq equation for piece-wise sloping bathymetry to incorporate dispersion.

Result: Shows that boundary conditions (water displacement and velocity) on a virtual buoy can be recovered from shoreline data in finite sloping bathymetry.

Conclusion: The initial tsunami shape can be recovered from run-up data even in finite sloping bathymetry by recovering boundary conditions and incorporating dispersion effects through combined modeling approaches.

Abstract: We discuss the following inverse problem: given the run-up data of a tsunami
wave, can we recover its initial shape? We study this problem within the
framework of the non-linear shallow water equations, a model widely used to
study tsunami propagation and inundation. Previously, it has been demonstrated
that in the case of infinite sloping bathymetry, it is possible to recover the
initial water displacement and velocity from shoreline readings
\cite{Rybkin23,Rybkin24,Rybkin25}.
  We consider a finite sloping bathymerty. We show that it is possible to
recover boundary conditions (water displacement and velocity) on a virtual buoy
from the shoreline data. Further, we discuss stitching together the shallow
water equations and the Boussinesq equation in a more complex piece-wise
sloping bathymetry in order to recover the initial conditions, while
incorporating the dispersion to our model.

</details>


### [26] [Propagation speed of traveling waves for diffusive Lotka-Volterra system with strong competition](https://arxiv.org/abs/2510.14311)
*Ken-Ichi Nakamura,Toshiko Ogiwara*

Main category: math.AP

TL;DR: This paper studies bistable traveling waves in a two-component diffusive Lotka-Volterra system under strong competition, focusing on how propagation speed determines invasion outcomes between competing species.


<details>
  <summary>Details</summary>
Motivation: The sign of propagation speed determines long-term competition outcomes between species and predicts invasion success/failure of alien species into native habitats, which is ecologically important.

Method: Using comparison arguments to establish sufficient conditions determining the sign of propagation speed, refining previous results.

Result: In symmetric cases, faster diffusers prevail over broader parameter ranges than previously known. When interspecific competition coefficients differ significantly, competition outcomes cannot be reversed by adjusting diffusion or growth rates.

Conclusion: The findings provide a rigorous theoretical framework with sharper mathematical criteria for analyzing invasion dynamics and predicting invasion success or failure.

Abstract: We study the propagation speed of bistable traveling waves in the classical
two-component diffusive Lotka-Volterra system under strong competition. From an
ecological perspective, the sign of the propagation speed determines the
long-term outcome of competition between two species and thus plays a central
role in predicting the success or failure of invasion of an alien species into
habitats occupied by a native species. Using comparison arguments, we establish
sufficient conditions determining the sign of the propagation speed, which
refine previously known results. In particular, we show that in the symmetric
case, where the two species differ only in their diffusion rates, the faster
diffuser prevails over a substantially broader parameter range than previously
established. Moreover, we demonstrate that when the interspecific competition
coefficients differ significantly, the outcome of competition cannot be
reversed by adjusting diffusion or growth rates. These findings provide a
rigorous theoretical framework for analyzing invasion dynamics, offering
sharper mathematical criteria for invasion success or failure.

</details>


### [27] [Sobolev regularity for the perturbed fractional 1-Laplace equations in the subquadratic case](https://arxiv.org/abs/2510.14346)
*Dingding Li,Chao Zhang*

Main category: math.AP

TL;DR: This paper analyzes Sobolev regularity of solutions to perturbed fractional 1-Laplace equations, showing similar regularity properties as in superquadratic cases using a threshold parameter.


<details>
  <summary>Details</summary>
Motivation: To understand the regularity properties of solutions to perturbed fractional 1-Laplace equations, which are nonlocal and singular problems, and establish whether they exhibit similar regularity as in the superquadratic case.

Method: Uses nonlocal finite-difference quotient method combined with Moser-type iteration scheme to systematically analyze regularity for nonlocal and singular problems.

Result: For s_p in (0, (p-1)/p] and q≥p, solutions have W_loc^{γ,q}-regularity for all γ in (0, s_p p/(p-1)). For s_p in ((p-1)/p, 1) and q≥p, solutions have W_loc^{1,q}-regularity.

Conclusion: The regularity properties of solutions to perturbed fractional 1-Laplace equations are analogous to those in the superquadratic case, with different regularity regimes depending on the parameter s_p relative to the threshold (p-1)/p.

Abstract: This work investigates the Sobolev regularity of solutions to perturbed
fractional 1-Laplace equations. Under the assumption that weak solutions are
locally bounded, we establish that the regularity properties are analogous to
those observed in the superquadratic case. By introducing the threshold
$\frac{p-1}{p}$, we divide the range of the parameter $s_p$ into two distinct
scenarios. Specifically, for any $s_p\in \left(0, \frac{p-1}{p}\right]$ and
$q\ge p$, we demonstrate that the solutions possess $W_{\rm loc}^{\gamma,
q}$-regularity for all $\gamma\in \left(0, \frac{s_p p}{p-1}\right)$ and the
$W_{\rm loc}^{1, q}$-regularity for any $s_p\in \left(\frac{p-1}{p}, 1\right)$
and $q\ge p$, respectively. Our analysis relies on the nonlocal
finite-difference quotient method combined with a Moser-type iteration scheme,
which provides a systematic approach to the regularity theory for such nonlocal
and singular problems.

</details>


### [28] [Viscosity solutions posed on star-shaped network with Kirchhoff's boundary condition: Well-posedness](https://arxiv.org/abs/2510.14364)
*Isaac Ohavi*

Main category: math.AP

TL;DR: Establishes well-posedness for fully nonlinear PDEs on star-shaped networks with nonlinear Kirchhoff boundary conditions, including degenerate cases. Proves comparison theorem for discontinuous viscosity solutions and shows equivalence between generalized and standard Kirchhoff viscosity solutions.


<details>
  <summary>Details</summary>
Motivation: To address the mathematical challenges of fully nonlinear PDEs on network structures with complex boundary conditions, particularly dealing with degeneracy and establishing rigorous solution frameworks.

Method: Uses comparison theorem for discontinuous viscosity solutions, following Ohavi's approach for second order problems. Constructs test functions at vertices as solutions of Eikonal equations with carefully designed coefficients.

Result: Successfully proves well-posedness and obtains comparison theorem. Shows equivalence between generalized Kirchhoff's viscosity solutions (Lions-Souganidis) and standard Kirchhoff's viscosity solutions, eliminating the need for Hamiltonian values at vertices.

Conclusion: The work provides a complete theoretical framework for analyzing fully nonlinear PDEs on networks with Kirchhoff boundary conditions, establishing solution equivalence and enabling analysis without requiring Hamiltonian values at vertices.

Abstract: The aim of this work is to establish the well-posedness of fully nonlinear
partial differential equations (PDE) posed on a star-shaped network, having
nonlinear Kirchhoff's boundary condition at the vertex, and possibly
degenerate. We obtain a comparison theorem, for discontinuous viscosity
solutions, following the recent ideas obtained by Ohavi for second order
problems, building test functions at the vertex solutions of Eikonal equations
with well-designed coefficients. Another strong result obtained in this
contribution is to show that any generalized Kirchhoff's viscosity solution
introduced by Lions-Souganidis, is indeed a Kirchhoff's viscosity solution. In
other terms, the values of the Hamiltonians are not required at the vertex in
the analysis of these types of PDE systems.

</details>


### [29] [Parabolic PDEs on a fixed domain with evolving subdomains: function spaces and well-posedness](https://arxiv.org/abs/2510.14373)
*Van Chien Le,Karel Van Bockstal*

Main category: math.AP

TL;DR: Develops variational framework for parabolic PDEs with evolving subdomains, introducing specialized function spaces and proving well-posedness.


<details>
  <summary>Details</summary>
Motivation: To handle initial boundary-value problems of parabolic PDEs on fixed domains with evolving subdomains, where the time derivative coefficient may be discontinuous across moving interfaces.

Method: Introduces extended Sobolev-Bochner function spaces for discontinuous coefficients, develops density results via mollification and Reynolds transport theorem, establishes embedding theory and integration by parts formula, and proves well-posedness using Banach-Necas-Babuska theorem.

Result: Successfully developed the mathematical framework including specialized function spaces, density properties, embedding theory, and integration by parts formulas for parabolic PDEs with evolving interfaces.

Conclusion: The variational approach is well-posed for parabolic PDEs with evolving subdomains, providing a rigorous mathematical foundation for problems with discontinuous coefficients across moving interfaces.

Abstract: This paper develops the necessary ingredients for the variational approach of
initial boundary-value problems of parabolic partial differential equations on
a fixed spatial domain containing evolving subdomains. In particular, we
introduce function spaces for the variational solution that extend standard
Sobolev-Bochner spaces to account for a coefficient associated with the time
derivative that may be discontinuous across the evolving interface. We further
show the density of smooth functions in these spaces by extending the
mollification technique and the Reynolds transport theorem, and establish the
corresponding "embedding" theory and an integration by parts formula. Finally,
we prove the well-posedness of the space-time variational formulation in the
natural setting using the Banach-Necas-Babuska theorem.

</details>


### [30] [Quantitative stability of a class of explicit steady Euler flows in a disk](https://arxiv.org/abs/2510.14394)
*Fatao Wang,Guodong Wang*

Main category: math.AP

TL;DR: Short proof of L²-orbital stability for explicit steady Euler flows in a disk using conserved quantities.


<details>
  <summary>Details</summary>
Motivation: To establish stability properties of explicit steady Euler flows and understand how radial symmetry affects instability.

Method: Exploit conserved quantities of Euler equation: kinetic energy, enstrophy, and moment of fluid impulse to derive quantitative estimate.

Result: Proved L²-orbital stability for a class of explicit steady Euler flows in a disk.

Conclusion: More radial symmetry appears to lead to stronger instability in Euler flows.

Abstract: We provide a short proof of the $L^2$-orbital stability of a class of
explicit steady Euler flows in a disk by establishing a quantitative estimate.
The main idea is to exploit the conserved quantities of the Euler equation,
including the kinetic energy, the enstrophy, and the moment of fluid impulse.
Our result seems to suggest that more radial symmetry leads to stronger
instability.

</details>


### [31] [On some Elliptic and Parabolic Problems Involving the Anisotropic $p(u)$-Laplacian](https://arxiv.org/abs/2510.14432)
*Kaushik Bal,Shilpa Gupta*

Main category: math.AP

TL;DR: Study of elliptic and parabolic PDEs with p(u) Laplacian using variable exponent Sobolev spaces, establishing weak solution existence via pseudomonotone operators for elliptic case and time discretization with Schauder theorem for parabolic case.


<details>
  <summary>Details</summary>
Motivation: To analyze PDEs driven by p(u) Laplacian, which requires specialized variable exponent Sobolev spaces in anisotropic settings, addressing the mathematical challenges of this nonlinear dependence.

Method: For elliptic equations: pseudomonotone operators with approximation techniques. For parabolic equations: time discretization scheme, Schauder fixed-point theorem, a priori estimates, and compactness arguments.

Result: Established existence of weak solutions for both elliptic and parabolic PDEs with p(u) Laplacian in variable exponent Sobolev spaces.

Conclusion: Successfully developed mathematical framework and proved existence results for PDEs with p(u) Laplacian using specialized functional analysis tools in both elliptic and parabolic settings.

Abstract: We investigate a class of elliptic and parabolic partial differential
equations driven by p(u) laplacian. This dependence necessitates the use of
variable exponent Sobolev spaces specifically tailored to the anisotropic
framework. For the elliptic case, we establish the existence of a weak solution
by employing the theory of pseudomonotone operators in conjunction with
suitable approximation techniques. In the parabolic setting, the existence of a
weak solution is obtained via a time discretization scheme and Schauder
fixed-point theorem, supported by a priori estimates and compactness arguments.

</details>


### [32] [Small-time approximate controllability of the logarithmic Schr\''dinger equation](https://arxiv.org/abs/2510.14461)
*Karine Beauchard,Rémi Carles,Eugenio Pozzoli*

Main category: math.AP

TL;DR: The paper proves small-time global L²-approximate controllability for Schrödinger equations with logarithmic nonlinearity and bilinear controls on both torus and Euclidean spaces.


<details>
  <summary>Details</summary>
Motivation: To extend controllability results from linear Schrödinger equations to nonlinear cases, specifically addressing the challenge of bilinear controls with logarithmic nonlinearity.

Method: Extends the approach from previous linear control work by combining small-time controllability of phases and gradient flows, using WKB analysis to handle the nonlinear estimates.

Result: First proof of small-time global approximate controllability for nonlinear Schrödinger equations with bilinear controls.

Conclusion: The nonlinear Schrödinger equation with logarithmic nonlinearity and bilinear controls is small-time globally approximately controllable in L² norm.

Abstract: We consider Schr{\"o}dinger equations with logarithmic nonlinearity and
bilinear controls, posed on $\mathbb{T}^d$ or $\mathbb{R}^d$. We prove their
small-time global $L^2$-approximate controllability. The proof consists in
extending to this nonlinear framework the approach introduced by the first and
third authors in \cite{beauchard-pozzoli2} to control the linear equation: it
combines the small-time controllability of phases and gradient flows. Due to
the nonlinearity, the required estimates are more difficult to establish than
in the linear case. The proof here is inspired by WKB analysis. This is the
first result of (small-time) global approximate controllability, for nonlinear
Schr{\"o}dinger equations, with bilinear controls.

</details>


### [33] [An $L^\infty$-variational problem involving the Fractional Laplacian](https://arxiv.org/abs/2510.14476)
*Simone Carano,Roger Moser*

Main category: math.AP

TL;DR: Existence and uniqueness of absolute minimizers for the supremal functional involving the Fractional Laplacian, with prescribed Dirichlet data outside the domain.


<details>
  <summary>Details</summary>
Motivation: To study the supremal functional with the Fractional Laplacian operator and establish existence and uniqueness results for absolute minimizers.

Method: Proving existence and uniqueness of absolute minimizers for the functional E∞(u) = ||(-Δ)^s u||_{L∞(R^n)} with prescribed Dirichlet data in the complement of Ω.

Result: The minimizer u∞ satisfies the fractional PDE (-Δ)^s u∞ = E∞(u∞) sgn f∞ in Ω, where f∞ is an analytic function obtained from an s-harmonic measure μ in Ω.

Conclusion: Absolute minimizers exist and are unique for the supremal functional with the Fractional Laplacian, and they satisfy a specific fractional PDE involving an s-harmonic measure.

Abstract: For $s\in(0,1)$ and an open bounded set $\Omega\subset\mathbb R^n$, we prove
existence and uniqueness of absolute minimisers of the supremal functional
$$E_\infty(u)=\|(-\Delta)^s u\|_{L^\infty(\mathbb R^n)},$$ where $(-\Delta)^s$
is the Fractional Laplacian of order $s$ and $u$ has prescribed Dirichlet data
in the complement of $\Omega$. We further show that the minimiser $u_\infty$
satisfies the (fractional) PDE $$ (-\Delta)^s
u_\infty=E_\infty(u_\infty)\,\mathrm{sgn}f_\infty \qquad\mbox{in }\Omega, $$
for some analytic function $f_\infty\in L^1(\Omega)$ obtained as the
restriction of an $s$-harmonic measure $\mu$ in $\Omega$.

</details>


### [34] [Maxwell's equations with mixed impedance boundary conditions](https://arxiv.org/abs/2510.14600)
*Ben Schweizer,David Wiedemann*

Main category: math.AP

TL;DR: Fredholm alternative and existence of weak solutions for time-harmonic Maxwell equations with matrix-valued impedance boundary conditions on bounded Lipschitz domains.


<details>
  <summary>Details</summary>
Motivation: To analyze Maxwell equations with impedance boundary conditions that can be matrix-valued, allowing for polarization-dependent impedance modeling, and to handle singular impedance coefficients.

Method: Derived a Fredholm alternative for the system of time-harmonic Maxwell equations with impedance boundary conditions on bounded Lipschitz domains.

Result: Established existence of weak solutions for arbitrary sources when the frequency is not a resonance frequency, covering cases with singular impedance coefficients.

Conclusion: The analysis provides a comprehensive framework for studying Maxwell equations with general impedance boundary conditions, including matrix-valued and singular coefficients.

Abstract: We study the time-harmonic Maxwell equations on bounded Lipschitz domains
with an impedance boundary condition. The impedance coefficient can be matrix
valued such that, in particular, a polarization dependent impedance is modeled.
We derive a Fredholm alternative for this system. As a consequence, we obtain
the existence of weak solutions for arbitrary sources when the frequency is not
a resonance frequency. Our analysis covers the case of singular impedance
coefficients.

</details>


### [35] [Unique continuation and stabilization for nonlinear Schrödinger equations under the Geometric Control Condition](https://arxiv.org/abs/2510.14632)
*Cristóbal Loyola*

Main category: math.AP

TL;DR: Global propagation of analyticity for semilinear Schrödinger equations with analytic nonlinearity from regions satisfying Geometric Control Condition, leading to unique continuation results and answering an open question from 2006.


<details>
  <summary>Details</summary>
Motivation: To establish global propagation of analyticity in finite time for solutions of semilinear Schrödinger equations and prove unique continuation properties, addressing an open question about nonlinear control and stabilization.

Method: Refines a technique combining control theory and Galerkin approximation to propagate analyticity from zones where observability holds, using Geometric Control Condition on the observation region.

Result: Proves unique continuation for subcritical semilinear Schrödinger equations on compact manifolds of dimensions 2 and 3 when solutions vanish on the control region, and establishes semiglobal control and stabilization.

Conclusion: The approach successfully propagates analyticity and provides affirmative answer to Dehman, Gérard, and Lebeau's 2006 open question about nonlinear control under Geometric Control Condition.

Abstract: In this article we prove global propagation of analyticity in finite time for
solutions of semilinear Schr\"odinger equations with analytic nonlinearity from
a region $\omega$ where the Geometric Control Condition holds. Our approach
refines a recent technique introduced by Laurent and the author, which combines
control theory techniques and Galerkin approximation, to propagate analyticity
in time from a zone where observability holds. As a main consequence, we obtain
unique continuation for subcritical semilinear Schr\"odinger equations on
compact manifolds of dimension $2$ and $3$ when the solution is assumed to
vanish on $\omega$. Furthermore, semiglobal control and stabilization follow
only under the Geometric Control Condition on the observation zone. In
particular, this answers in the affirmative an open question of Dehman,
G\'erard, and Lebeau from $2006$ for the nonlinear case.

</details>


### [36] [The simultaneous effect of chemotaxis and alarm-taxis on the global existence and stability of a predator-prey system](https://arxiv.org/abs/2510.14728)
*Gnanasekaran Shanmugasundaram,Jitraj Saha,Rafael Díaz Fuentes*

Main category: math.AP

TL;DR: Analysis of a fully parabolic predator-prey chemo-alarm-taxis system showing global bounded classical solutions and convergence via Lyapunov functionals, with numerical validation.


<details>
  <summary>Details</summary>
Motivation: To understand the role of chemotaxis and alarm-taxis coefficients in predator-prey models and establish existence, boundedness, and stability of solutions.

Method: Mathematical analysis of PDE system with homogeneous Neumann boundary conditions, construction of Lyapunov functional, and numerical simulations.

Result: System admits unique globally bounded classical solution under specific parameter conditions; solution convergence established; numerical simulations validate asymptotic behavior.

Conclusion: Chemotaxis and alarm-taxis coefficients play significant roles in determining existence and stability of predator-prey models.

Abstract: This study examines a fully parabolic predator-prey chemo-alarm-taxis system
under homogeneous Neumann boundary conditions in a bounded domain $\Omega
\subset \mathbb{R}^n$ with a smooth boundary $\partial\Omega$. Under specific
parameter conditions, it is shown that the system admits a unique, globally
bounded classical solution. The convergence of the solution is established
through the construction of an appropriate Lyapunov functional. In addition,
numerical simulations are presented to validate the asymptotic behaviour of the
solution. The results highlight the significant role of chemotaxis and
alarm-taxis coefficients in determining the existence and stability of
predator-prey models, as discussed in the literature.

</details>


### [37] [Stable Type I blow-up for the one-dimensional wave equation with time-derivative nonlinearity](https://arxiv.org/abs/2510.14815)
*Oliver Gough*

Main category: math.AP

TL;DR: The paper studies blow-up in a 1D nonlinear wave equation with quadratic time-derivative nonlinearity, showing no smooth self-similar blow-up profiles exist but constructing generalized self-similar solutions that are stable under small perturbations.


<details>
  <summary>Details</summary>
Motivation: To understand finite-time blow-up behavior in nonlinear wave equations with time-derivative nonlinearities, building on previous work on spatial-derivative analogues.

Method: Construct explicit family of generalized self-similar solutions bifurcating from ODE blow-up, prove their asymptotic stability under small perturbations in energy topology.

Result: Non-existence of smooth exact self-similar blow-up profiles, construction of smooth generalized self-similar solutions with type-I blow-up, proof of asymptotic stability.

Conclusion: The spatially homogeneous ODE blow-up is not asymptotically stable, and the constructed generalized self-similar profiles provide stable blow-up solutions.

Abstract: We study finite-time blow-up for the one-dimensional nonlinear wave equation
with a quadratic time-derivative nonlinearity, \[ u_{tt}-u_{xx}=(u_t)^2,\qquad
(x,t)\in\mathbb R\times[0,T). \] Building on the work of Ghoul, Liu, and
Masmoudi \cite{ghoul2025blow} on the spatial-derivative analogue, we establish
the non-existence of smooth, exact self-similar blow-up profiles. Instead we
construct an explicit family of \emph{generalised self-similar} solutions,
bifurcating from the ODE blow-up, that are smooth within the past light cone
and exhibit type-I blow-up at a prescribed point \((x_0,T)\). We further prove
asymptotic stability of these profiles under small perturbations in the energy
topology. In particular, these profiles verify that the spatially homogeneous
ODE blow-up is not asymptotically stable.

</details>


### [38] [Vortex lines interaction in the three-dimensional magnetic Ginzburg--Landau model](https://arxiv.org/abs/2510.14910)
*Carlos Román,Etienne Sandier,Sylvia Serfaty*

Main category: math.AP

TL;DR: The paper provides a detailed asymptotic analysis of the 3D Ginzburg-Landau functional near the first critical field H_c1, showing how vortex filaments appear sequentially as magnetic field increases, and derives a refined energy functional that explains vortex line shapes.


<details>
  <summary>Details</summary>
Motivation: To understand the precise behavior of vortex filaments in superconductors near the first critical field H_c1, where vortices first appear, and to derive next-order asymptotic expansions that reveal the transition mechanisms and vortex line configurations.

Method: Asymptotic analysis of the 3D Ginzburg-Landau functional with magnetic field as ε→0, under a nondegeneracy condition. Uses horizontal blow-up around a special curve Γ0 and derives a refined energy functional that captures length penalization, logarithmic repulsion, and magnetic confinement effects.

Result: Shows that H_c1 has a next-order asymptotic expansion, and vortex lines appear sequentially with field increments of order log|logε|. The vortex lines accumulate near curve Γ0, and their configurations minimize a derived energy functional that balances length, repulsion, and confinement forces.

Conclusion: The analysis elucidates the precise shape and arrangement of vortex lines in superconductors near H_c1, revealing a sequence of transitions where vortices appear one by one and providing a mathematical framework for understanding vortex line configurations in three-dimensional superconductors.

Abstract: We complete our study of the three dimensional Ginzburg--Landau functional
with magnetic field, in the asymptotic regime of a small inverse
Ginzburg--Landau parameter $\varepsilon$, and near the first critical field
$H_{c_1}$ for which the first vortex filaments appear in energy minimizers.
Under a nondegeneracy condition, we show a next order asymptotic expansion of
$H_{c_1}$ as $\varepsilon \to 0$, and exhibit a sequence of transitions, with
vortex lines appearing one by one as the intensity of the applied magnetic
field is increased: passing $H_{c_1}$ there is one vortex, then increasing
$H_{c_1}$ by an increment of order $\log |\log\varepsilon|$ a second vortex
line appears, etc. These vortex lines accumulate near a special curve
$\Gamma_0$, solution to an isoflux problem. We derive a next order energy that
the vortex lines must minimize in the asymptotic limit, after a suitable
horizontal blow-up around $\Gamma_0$. This energy is the sum of terms where
penalizations of the length of the lines, logarithmic repulsion between the
lines and magnetic confinement near $\Gamma_0$ compete. This elucidates the
shape of vortex lines in superconductors.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [39] [Surrogate Models for Linear Response](https://arxiv.org/abs/2510.13989)
*L. Jin,A. Ravlić,P. Giuliani,K. Godbey,W. Nazarewicz*

Main category: physics.comp-ph

TL;DR: The paper presents two QRPA surrogate models for nuclear response functions that achieve 0.1%-1% accuracy with 6-7 orders of magnitude speedup, enabling Bayesian calibration of computationally expensive many-body physics models.


<details>
  <summary>Details</summary>
Motivation: QRPA is computationally expensive, limiting model calibration and uncertainty quantification studies in nuclear physics. There's a need for efficient surrogate models to enable large-scale studies.

Method: Two complementary QRPA surrogate models: 1) a reduced-order model exploiting QRPA structure, and 2) a parametric matrix model algorithm mapping Hamiltonian to observables.

Result: Benchmark applications show both emulators achieve 0.1%-1% accuracy for electric dipole polarizability of 180Yb and β-decay half-life of 80Ni, with 6-7 orders of magnitude speedup over state-of-the-art QRPA solvers.

Conclusion: The developed QRPA emulators are well-positioned to enable Bayesian calibration and large-scale studies of computationally expensive physics models for many-body systems.

Abstract: Linear response theory is a well-established method in physics and chemistry
for exploring excitations of many-body systems. In particular, the
quasiparticle random-phase approximation (QRPA) provides a powerful microscopic
framework by building excitations on top of the mean-field vacuum; however, its
high computational cost limits model calibration and uncertainty quantification
studies. Here, we present two complementary QRPA surrogate models and apply
them to study response functions of finite nuclei. One is a reduced-order model
that exploits the underlying QRPA structure, while the other utilizes the
recently developed parametric matrix model algorithm to construct a map between
the system's Hamiltonian and observables. Our benchmark applications, the
calculation of the electric dipole polarizability of ${}^{180}$Yb and the
$\beta$-decay half-life of ${}^{80}$Ni, show that both emulators can achieve
0.1\%--1\% accuracy while offering a six to seven orders of magnitude speedup
compared to state-of-the-art QRPA solvers. These results demonstrate that the
developed QRPA emulators are well-positioned to enable Bayesian calibration and
large-scale studies of computationally expensive physics models describing the
properties of many-body systems.

</details>


### [40] [Anti-Interference Communication Using Computational Antenna](https://arxiv.org/abs/2510.14362)
*Xiaocun Zong,Fan Yang,Shenheng Xu,Maokun Li*

Main category: physics.comp-ph

TL;DR: A novel anti-interference communication method using computational antennas with time averaging and 1-bit RIS achieves robust signal modulation with minimal hardware complexity, reducing BER by 80.9% without spectral overhead.


<details>
  <summary>Details</summary>
Motivation: To develop robust anti-interference communication that outperforms conventional techniques like spread spectrum or frequency hopping without requiring additional spectral resources.

Method: Developed a communication model for computational antennas and proposed an efficient signal processing algorithm optimized for temporal modulation, validated through a USRP-based experimental platform under strong interference conditions.

Result: Experimental results show up to 80.9% reduction in bit error rate (BER) and effective restoration of distorted images in transmission tests, even under 5 dB jamming-to-signal ratio interference.

Conclusion: The method provides superior anti-interference performance without spectral overhead, offering valuable insights for radar detection, military communications, and next-generation wireless networks.

Abstract: This letter proposes a novel anti-interference communication method
leveraging computational antennas, utilizing time averaging and 1-bit
reconfigurable intelligent surfaces (RIS) to achieve robust signal modulation
with minimal hardware complexity. We develop a communication model for
computational antennas and propose an efficient signal processing algorithm
optimized for temporal modulation. A USRP-based experimental platform is
established to validate the approach under strong interference conditions
(e.g., 5 dB jamming-to-signal ratio). Experimental results reveal up to an
80.9\% reduction in bit error rate (BER) and effective restoration of distorted
images in transmission tests. Compared to conventional techniques like spread
spectrum or frequency hopping, which require significant spectral resources,
our method offers superior anti-interference performance without additional
spectral overhead. This research provides valuable insights for radar
detection, military communications, and next-generation wireless networks.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [41] [Structure of self-generated magnetic fields in laser-solid interaction from proton tomography](https://arxiv.org/abs/2510.14076)
*Jesse Griff-McMahon,Christopher A. Walsh,Vicente Valenzuela-Villaseca,Sophia Malko,Brendan McCluskey,Kirill Lezhnin,Huws Landsberger,Laura Berzak Hopkins,Gennady Fiksel,Michael J. Rosenberg,Derek B. Schaeffer,William Fox*

Main category: physics.plasm-ph

TL;DR: Experimental characterization of 3D magnetic fields in laser-solid interactions using multi-view proton radiography and tomographic inversion, validating improved MHD simulations.


<details>
  <summary>Details</summary>
Motivation: To experimentally characterize the 3D location and strength of self-generated magnetic fields in laser-solid interactions, rather than relying on path-integrated quantities.

Method: Used multi-view proton radiography and tomographic inversion on the OMEGA laser to infer 3D magnetic field structures extending off target surfaces.

Result: Inferred magnetic fields extend several millimeters into the plasma corona and are strong enough to strongly magnetize the plasma. Achieved reasonable agreement with MHD simulations only when incorporating magnetic field re-localization of transport.

Conclusion: Successfully demonstrated tomographic inversion in proton radiography as a valuable tool for investigating magnetic fields in laser-produced plasmas, validating improved magnetic transport models.

Abstract: Strong magnetic fields are naturally self-generated in high-power,
laser-solid interactions through the Biermann-battery mechanism. This work
experimentally characterizes the 3D location and strength of these fields,
rather than path-integrated quantities, through multi-view proton radiography
and tomographic inversion on the OMEGA laser. We infer magnetic fields that
extend several millimeters off the target surface into the hot, rarefied corona
and are sufficient to strongly magnetize the plasma ($\Omega_{e}\tau_e \gg 1$).
The data is used to validate MHD simulations incorporating recent improvements
in magnetic transport modeling; we achieve reasonable agreement only with
models with re-localization of transport by magnetic fields. This work provides
a key demonstration of tomographic inversion in proton radiography, offering a
valuable tool for investigating magnetic fields in laser-produced plasmas.

</details>


### [42] [Plasma Confinement State Classification via FPP Relevant Microwave Diagnostics](https://arxiv.org/abs/2510.14078)
*Randall Clark,Vacslav Glukhov,Georgy Subbotin,Maxim Nurgaliev,Aleksandr Kachkin,Max Austin,Dmitri M. Orlov*

Main category: physics.plasm-ph

TL;DR: A minimalist machine learning approach using only electron cyclotron emission (ECE) signals achieves 96% accuracy in identifying plasma confinement states (L-mode vs H-mode) in fusion power plants, demonstrating reliable state classification with severely constrained diagnostics.


<details>
  <summary>Details</summary>
Motivation: Fusion power plants require reliable identification of plasma confinement states for safe operation, but must operate with severely constrained diagnostic sets unlike research devices. ECE signals provide electron temperature profiles without the engineering issues of in-vessel probes.

Method: Uses ECE signals as input, extracts features with radial basis functions, and applies a gradient boosting classifier for state classification.

Result: Achieves high accuracy with test accuracy averaging 96% correct predictions. Robustness analysis and feature importance study confirm reliability.

Conclusion: State-of-the-art performance is attainable from restricted diagnostic sets, enabling minimalist yet resilient plasma control architectures for fusion power plants.

Abstract: We present a parsimonious and robust machine learning approach for
identifying plasma confinement states in fusion power plants (FPPs) where
reliable identification of the low-confinement (L-mode) and high-confinement
(H-mode) regimes is critical for safe and efficient operation. Unlike
research-oriented devices, FPPs must operate with a severely constrained set of
diagnostics. To address this challenge, we demonstrate that a minimalist model,
using only electron cyclotron emission (ECE) signals, can deliver accurate and
reliable state classification. ECE provides electron temperature profiles
without the engineering or survivability issues of in-vessel probes, making it
a primary candidate for FPP-relevant diagnostics. Our framework employs ECE as
input, extracts features with radial basis functions, and applies a gradient
boosting classifier, achieving high accuracy with test accuracy averaging 96\%
correct predictions. Robustness analysis and feature importance study confirm
the reliability of the approach. These results demonstrate that
state-of-the-art performance is attainable from a restricted diagnostic set,
paving the way for minimalist yet resilient plasma control architectures for
FPPs.

</details>


### [43] [Three-dimensional unmagnetized Mach probe analysis and initial flow measurements in reversed-field pinch experiments](https://arxiv.org/abs/2510.14212)
*K. J. McCollam,R. Reksoatmodjo,J. von der Linden,J. Sears,S. You,H. Himura,A. F. Almagri,M. Reyfman,C. C. Rouda,J. S. Sarff,A. M. Sellner*

Main category: physics.plasm-ph

TL;DR: A matrix method for analyzing 3D Mach probe data is developed and used to measure plasma flow velocity in RFP experiments on MST, showing mixed agreement with previous measurements.


<details>
  <summary>Details</summary>
Motivation: To develop a new analytical method for 3D Mach probe arrays that can measure local plasma flow velocity in complex magnetic confinement experiments like reversed-field pinches.

Method: Developed a novel matrix method to analyze ion saturation current data from 3D arrays of unmagnetized Mach probe tips, using two probe configurations: six-tip octahedral array and four-tip tetrahedral array.

Result: Initial measurements show flow speeds of expected magnitudes but with some directional differences for the octahedral probe, while the tetrahedral probe shows similar flow directions but larger than expected speeds compared to previous measurements.

Conclusion: The matrix method successfully facilitates analysis of 3D Mach probe data, though initial results show some discrepancies possibly related to probe conditioning and fast electron effects that require further investigation.

Abstract: A novel matrix method of analyzing ion saturation current data from a general
three-dimensional (3D) array of unmagnetized Mach probe tips is developed and
used with data sets from two 3D Mach probes to make initial measurements of
local plasma flow velocity in reversed-field pinch (RFP) experiments in the
Madison Symmetric Torus (MST). The two 3D Mach probes are composed of regular
polyhedral arrays of six and four tips, respectively, with the six-tip array
composed of three orthogonal pairs of mutually opposite tips at the vertices of
a regular octahedron and the four-tip array composed of non-opposite tips at
the vertices of a regular tetrahedron, the analysis of which is specifically
facilitated by the matrix method. Velocity measurement uncertainties for the
Mach probes are derived based on uncertainties in probe machining and ion
saturation current measurements, and typical relative uncertainties for the
probes are estimated to be of order several percent, likely smaller than
systematic uncertainties related to the Mach probe calibration constant and
experimental uncertainties related to plasma and probe conditioning. Initial
results for the octahedral probe show flow speeds of roughly the expected
magnitudes based on previous MST measurements but with somes differences in
flow direction, while those for the tetrahedron probe show similar flow
directions to some previous measurements but also some larger than expected
speeds. We consider possible causes for the unexpected results of these initial
tests, with a focus on probe conditioning and fast electron issues.

</details>


### [44] [Kinetic Scale Energy Budget in Turbulent Plasmas: Role of Electron to Ion Temperature Ratio](https://arxiv.org/abs/2510.14258)
*Subash Adhikari,M. Hasan Barbhuiya*

Main category: physics.plasm-ph

TL;DR: The paper investigates how ion-electron thermal disequilibrium affects kinetic-scale energy transfer in plasma turbulence using scale-filtered Vlasov-Maxwell equations and PIC simulations.


<details>
  <summary>Details</summary>
Motivation: To understand the poorly understood influence of ion-electron thermal disequilibrium on the kinetic-scale energy budget in weakly collisional plasmas.

Method: Used two-dimensional fully kinetic particle-in-cell simulations of decaying plasma turbulence, varying electron-to-ion temperature ratios to systematically analyze pressure-strain interaction components.

Result: Scale-filtered pressure-strain interaction is dominated by Pi-D across kinetic scales, with shear component being dominant. Normal and shear Pi-D contributions show persistent anticorrelation and opposite signs. Anisotropic components scale with species temperature.

Conclusion: The findings have implications for thermally non-equilibrated plasmas in turbulent magnetosheath and solar wind, revealing temperature-dependent scaling relationships in kinetic-scale energy transfer.

Abstract: The dissipation mechanisms in weakly collisional plasmas have been a
longstanding topic of investigation, where significant progress has been made
in recent years. A recent promising development is the use of the
"scale-filtered" Vlasov-Maxwell equations to fully quantify the scale-by-scale
energy balance, a feature that was absent when using fluid models in kinetic
plasmas. In particular, this method reveals that the energy transfer in kinetic
scales is fully accounted for by the scale-filtered pressure-strain
interaction. Despite this progress, the influence of ion-electron thermal
disequilibrium on the kinetic-scale energy budget remains poorly understood.
Using two-dimensional fully kinetic particle-in-cell simulations of decaying
plasma turbulence, we systematically investigate the pressure-strain
interaction and its components at sub-ion scales by varying electron-to-ion
temperature ratios. Our analysis focuses on three key ingredients of the
pressure-strain interaction: the normal and shear components of Pi-D and
pressure dilatation. Our results demonstrate that the scale-filtered
pressure-strain interaction is dominated by scale-filtered Pi-D across the
kinetic range, with the shear component consistently providing the dominant
contribution. We find that the scale-filtered normal and shear contributions of
Pi-D exhibit persistent anticorrelation and opposite signs across all kinetic
scales. We also discover that the amplitude of both anisotropic components for
each species scales directly with their temperature and inversely with the
temperature of the other species, while the scale-filtered pressure dilatation
remains negligible compared to the Pi-D terms but shows enhanced
compressibility effects as plasma temperatures decrease. We discuss the
implications of these findings in thermally non-equilibrated plasmas, such as
in the turbulent magnetosheath and solar wind.

</details>


### [45] [Flux Jamming, Phase Transitions and Layering in Turbulent Magnetized Plasma](https://arxiv.org/abs/2510.14280)
*P. H. Diamond,Y. Kosuga,P. L. Guillon,Ö. D. Gürcan*

Main category: physics.plasm-ph

TL;DR: The paper analyzes transport barrier formation and layering through jam formation analogies with traffic flow theory, explaining flux jamming's relation to motility induced phase separation and identifying two routes to heat flux jamming.


<details>
  <summary>Details</summary>
Motivation: To understand transport barrier formation and layering phenomena by drawing analogies with traffic flow theory and jam formation processes.

Method: Uses analogies with one-dimensional traffic flow theory, analyzes flux jamming mechanisms, identifies two routes to heat flux jamming (rollover in heat flux-pulse size relation and delay time exceeding critical value), and examines staircase development through jamiton train formation.

Result: Identified two distinct routes to heat flux jamming, demonstrated staircase development following jamiton train formation, showed formation of outward propagating blob trains and inward propagating void trains, and revealed the important role of turbulence spreading.

Conclusion: The analysis provides insights into transport barrier formation mechanisms, yields estimates for 'near marginality' conditions, and elucidates the relationship between jamming of avalanches and phase transitions in drift wave-zonal flow turbulence.

Abstract: This paper discusses transport barrier formation and layering as consequences
of jam formation. Extensive use is made of analogies with the theory of traffic
flow in one dimension. The relation of flux jamming to motility induced phase
separation (MIPS) is explained. Two routes to heat flux jamming are identified.
The first is due to a rollover in the heat flux-pulse size relation, i.e.
$dQ_T(\delta T)/d\delta T<0$, and is similar to the condition of flux-gradient
bistability. The second occurs when the delay time between pulse and heat flux
exceeds a critical value. This does not require bistability and tends to occur
near marginality. This analysis yields an estimate of the answer to the eternal
question of 'how near is "near"?'. Staircase development is shown to follow
jamiton train formation. The relation of jamming of avalanches to phase
transitions in drift wave-zonal flow turbulence is elucidated. The formation of
outward propagating blob trains and inward propagating void trains is
demonstrated. The important role of turbulence spreading is identified.

</details>


### [46] [Dust-ion-acoustic solitons in an ion-beam-driven dusty magnetoplasma with adiabatic and nonadiabatic dust charge variations](https://arxiv.org/abs/2510.14324)
*N. P. Acharya,S. Basnet,A. P. Misra,R. Khanal*

Main category: physics.plasm-ph

TL;DR: Study of dust-ion-acoustic solitary waves in magnetized dusty plasmas with positive ion beams, examining effects of dust charge variations, collisions, and beam parameters on wave characteristics and damping.


<details>
  <summary>Details</summary>
Motivation: To understand how positive-ion beams and dust charge variations affect the propagation and characteristics of nonlinear dust-ion-acoustic waves in magnetized dusty plasmas, particularly focusing on collision effects and beam-driven charging processes.

Method: Using standard reductive perturbation technique to derive Korteweg-de Vries (KdV) equations for two cases: nonadiabatic and adiabatic dust charge variations, analyzing effects of beam velocity, magnetic field, ion creation, and collision-enhanced currents.

Result: Soliton energy decays with time and is affected by beam velocity; waves get damped by ion creation, ion loss, collision-enhanced current, and dust charge variation; ion beam causes transition from rarefactive to compressive solitary waves in nonadiabatic case but not in adiabatic case.

Conclusion: Positive-ion beam streaming significantly impacts dust charging process and wave characteristics, with different effects observed between nonadiabatic and adiabatic dust charge variations, leading to damping and polarity transitions in solitary waves.

Abstract: We study the characteristics of small-amplitude nonlinear dust-ion-acoustic
(DIA) solitary waves in active magnetized positive-ion-beam-driven dusty
plasmas with the effects of nonadiabatic and adiabatic dust charge variations.
In the model, we consider the ion-neutral collision and thereby consider the
collision enhanced ion current to the dust-charging process and dust charge
fluctuations. We show that the streaming of the positive-ion beam significantly
affects the dust-charging process in which the dust charge number decreases
(increases) with an increased beam velocity (number density). Using the
standard reductive perturbation technique, we derive the evolution equations in
the form of Korteweg-de Vries (KdV) equations for DIA solitary waves for two
different cases: nonadiabatic and adiabatic dust charge variations. We study
the effect of positive ion beam, dust charge variation, magnetic field, ion
creation, and ion-neutral collision enhanced current on the wave
characteristics. We find that the soliton energy decays with time and is
affected by the beam velocity. Also, the solitary waves get damped by the
effects of ion creation, ion loss, ion-neutral collision enhanced current, and
dust charge variation. Although the ion beam does not change the polarity of
solitary waves in the case of adiabatic dust charge variation, a transition
from rarefactive to compressive solitary waves occurs in the presence of an ion
beam with nonadiabatic dust charge variation.

</details>


### [47] [Linear damping of magneto-acoustic waves in two-fluid partially ionized plasmas](https://arxiv.org/abs/2510.14575)
*David Martínez-Gómez*

Main category: physics.plasm-ph

TL;DR: Study of magneto-acoustic wave damping in partially ionized plasmas using a two-fluid model, analyzing wave properties and deriving analytical damping rate approximations.


<details>
  <summary>Details</summary>
Motivation: To understand how elastic collisions between charged and neutral particles affect magneto-acoustic wave propagation and damping in partially ionized plasmas.

Method: Used a linearized two-fluid model to study small-amplitude waves in uniform static background, focusing on waves from periodic drivers. Analyzed dependence on ionization degree, collisional coupling strength, and propagation angle.

Result: Detailed characterization of how wave modes (fast, slow, acoustic) relate to individual fluid properties across various conditions. Derived analytical approximations for damping rates in weak and strong coupling limits, validated against numerical results.

Conclusion: The analytical approximations for damping rates are generally applicable to various astrophysical and laboratory partially ionized plasmas, with specific discussion of hydrogen-only plasmas.

Abstract: Magneto-acoustic waves in partially ionized plasmas are damped due to elastic
collisions between charged and neutral particles. Here, we use a linearized
two-fluid model to describe the influence of this collisional interaction on
the properties of small-amplitude waves propagating in a uniform and static
background. Mainly focusing on the case of waves generated by a periodic
driver, we perform a detailed study of the dependence of the wavenumbers and
damping rates on the ionization degree of the plasma, the strength of the
collisional coupling, and the angle of propagation. We describe how the
different wave modes (fast, slow, acoustic) are related to the individual
properties of each fluid in a wide range of physical conditions. In addition,
we derive analytical approximations for the damping rates due to charge-neutral
collisions in the limits of weak and strong coupling and check their range of
validity in comparison with the exact numerical results. These approximations
can be generally applied to a large variety of astrophysical and laboratory
partially ionized plasmas, but here we also discuss the particular application
to plasmas only composed of hydrogen.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [48] [No cosmological constraints on dark photon dark matter from resonant conversion: Impact of nonlinear plasma dynamics](https://arxiv.org/abs/2510.13956)
*Anson Hook,Junwu Huang,Mohamad Shalaby*

Main category: hep-ph

TL;DR: Dark photon dark matter constraints from resonant conversion to photons are invalidated due to plasma nonlinearities that limit energy transfer to thermal levels, weakening constraints by factors of 3000 to 10^7.


<details>
  <summary>Details</summary>
Motivation: To re-examine constraints on dark photon dark matter from resonant conversion in the early universe, as previous analyses may have overestimated the energy transfer efficiency.

Method: Used Particle-in-Cell simulations to study nonlinear plasma effects during resonant conversion, focusing on how large-amplitude Langmuir waves excite higher-k waves and create plasma inhomogeneities.

Result: Resonant energy transfer saturates at thermal energy levels due to plasma nonlinearities, suppressing further conversion and making constraints much weaker than previously thought.

Conclusion: Dark photon dark matter constraints are significantly weaker across a wide mass range, invalidating previous bounds that assumed efficient resonant energy transfer.

Abstract: We revisit and invalidate all dark photon dark matter constraints from
resonant conversion of dark photons into photons (plasmons) in the early
universe. These constraints rely on the resonant transfer of a substantial
portion of the dark photon energy density into the SM plasma, heating the
plasma in the process. We demonstrate that this resonant transfer saturates
because of plasma nonlinearities. Dark photon dark matter resonantly converts
into $k \simeq 0$ Langmuir waves in the early universe electron-ion plasma.
Once the Langmuir-wave energy approaches the thermal energy of the plasma,
nonlinear effects driven by the ponderomotive force become significant. In
particular, we show using dedicated Particle-in-Cell simulations that
large-amplitude $k = 0$ Langmuir waves excite higher-k Langmuir and ion
acoustic waves, producing strong spatial variations in density and plasma
frequency. These inhomogeneities suppress further resonant conversion, limiting
the deposited energy to about the thermal energy of the electrons at the time
of conversion, orders of magnitude below observable cosmological thresholds.
Consequently, the dark photon dark matter constraints are weaker by factors of
$3000$ to $10^7$ across ten orders of magnitude in dark photon mass.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [49] [Phenomenological Ehrenfest Dynamics with Topological and Geometric Phase Effects and the curious case of Elliptical intersection](https://arxiv.org/abs/2510.14181)
*Dhruv Sharma*

Main category: cond-mat.mes-hall

TL;DR: A computational framework for simulating nonadiabatic molecular dynamics with geometric phase effects using a generalized two-level Hamiltonian model that handles various electronic state crossings.


<details>
  <summary>Details</summary>
Motivation: To develop a unified framework for studying quantum-classical interactions in molecular systems where geometric phase effects play significant roles, particularly for designing degenerate materials and potential qubit applications.

Method: Uses a generalized two-level Hamiltonian model with Berry curvature-based force corrections to Ehrenfest dynamics, featuring a novel prelooping trajectory initialization scheme and eccentricity parameter in diabatic coupling.

Result: Numerical simulations show consistency with theoretical predictions for state mixing and inhibition due to geometric phase effects, including the expected phase pi for conical intersections and tunable phase for elliptic intersections.

Conclusion: The framework provides a valuable tool for studying geometric phase effects in molecular systems, opening avenues for degenerate material design, new spectroscopy development, and potential qubit applications.

Abstract: We present a comprehensive computational framework for simulating
nonadiabatic molecular dynamics with explicit inclusion of geometric phase (GP)
effects. Our approach is based on a generalized two-level Hamiltonian model
that can represent various electronic state crossings - conical intersections,
avoided crossings, and elliptic intersections - through appropriate
parameterization. We introduce a novel prelooping trajectory initialization
scheme, allowing us to encode the memory as an initial phase accumulated due to
the adiabatic evolution over the potential energy surface. This is a unified
framework to handle different types of level crossings by incorporating Berry
curvature-based force corrections to Ehrenfest dynamics, ensuring accurate
representation of topological effects. For conical intersections, our method
incorporates the theoretically expected phase pi, while for elliptic
intersections, it yields a parametrically tunable but loop radius (energy)
independent phase different from pi. We also include an eccentricity parameter
(e) in the diabatic coupling to model more realistic molecular systems.
Numerical simulations demonstrate the consistency of our approach with
theoretical predictions for mixing of states and inhibition from mixing due to
geometric phase effects. This framework provides a valuable tool for studying
quantum-classical interactions in molecular systems where geometric phase
effects play a significant role. The elliptical intersection and geometric
phase effect opens avenue for the design and discovery of degenerate materials.
It produces a fresh look to help develop a new kind of spectroscopy and
potential qubit applications. This simple Hamiltonian reveals a pathological
phase protection effect E = kr, where k is real, that has great utility in a
new spectroscopy design.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [50] [DeepMartingale: Duality of the Optimal Stopping Problem with Expressivity](https://arxiv.org/abs/2510.13868)
*Junyan Ye,Hoi Ying Wong*

Main category: math.OC

TL;DR: DeepMartingale is a novel deep learning approach using martingale representation to solve discrete-monitoring optimal stopping problems, providing tight upper bounds without suffering from the curse of dimensionality.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of solving high-dimensional optimal stopping problems in continuous time, particularly overcoming the curse of dimensionality that plagues traditional methods.

Method: Uses a martingale representation combined with deep learning to derive upper bounds for the primal value function, with carefully designed neural network architectures whose size is bounded by dimension-independent constants.

Result: The method provides tight upper bounds that converge under mild assumptions and can approximate the true value function within any prescribed accuracy without suffering from the curse of dimensionality.

Conclusion: DeepMartingale is an effective, stable, and dimension-independent approach for solving optimal stopping problems, as demonstrated by numerical experiments confirming its convergence and expressivity.

Abstract: Using a martingale representation, we introduce a novel deep-learning
approach, which we call DeepMartingale, to study the duality of
discrete-monitoring optimal stopping problems in continuous time. This approach
provides a tight upper bound for the primal value function, even in
high-dimensional settings. We prove that the upper bound derived from
DeepMartingale converges under very mild assumptions. Even more importantly, we
establish the expressivity of DeepMartingale: it approximates the true value
function within any prescribed accuracy $\varepsilon$ under our architectural
design of neural networks whose size is bounded by
$\tilde{c}\,D^{\tilde{q}}\varepsilon^{-\tilde{r}}$, where the constants
$\tilde{c}, \tilde{q}, \tilde{r}$ are independent of the dimension $D$ and the
accuracy $\varepsilon$. This guarantees that DeepMartingale does not suffer
from the curse of dimensionality. Numerical experiments demonstrate the
practical effectiveness of DeepMartingale, confirming its convergence,
expressivity, and stability.

</details>


### [51] [Optimality-Based Control Space Reduction for Infinite-Dimensional Control Spaces](https://arxiv.org/abs/2510.14479)
*Michael Kartmann,Stefan Volkwein*

Main category: math.OC

TL;DR: The paper presents a model reduction approach for linear-quadratic optimal control problems with parabolic PDEs, combining both control and state variable reduction with adaptive error bounds.


<details>
  <summary>Details</summary>
Motivation: To efficiently solve unconstrained linear-quadratic optimal control problems for time-varying parabolic PDEs by developing a combined control and state space reduction method that improves computational efficiency while maintaining accuracy.

Method: Developed a control- and state-reduced problem that shares the same minimizer as state-only reduced problems, derived a posteriori error bounds for optimal control, and created an adaptive algorithm using these bounds to solve the control problem.

Result: Proved convergence of the adaptive algorithm and demonstrated numerical advantages of combined control and state space reduction over state-only reduction approaches.

Conclusion: The combined control and state space reduction method provides computational advantages while maintaining accuracy through rigorous error bounds and adaptive refinement strategies.

Abstract: We consider linear model reduction in both the control and state variables
for unconstrained linear-quadratic optimal control problems subject to
time-varying parabolic PDEs. The first-order optimality condition for a
state-space reduced model naturally leads to a reduced structure of the optimal
control. Thus, we consider a control- and state-reduced problem that admits the
same minimizer as the solely state-reduced problem. Lower and upper \emph{a
posteriori} error bounds for the optimal control and a representation for the
error in the optimal function value are provided. These bounds are used in an
adaptive algorithm to solve the control problem. We prove its convergence and
numerically demonstrate the advantage of combined control and state space
reduction.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [52] [Diameter bounds in 3d Type I Ricci flows](https://arxiv.org/abs/2510.14019)
*Panagiotis Gianniotis*

Main category: math.DG

TL;DR: The paper proves that 3D compact Ricci flows with Type I singularities have uniformly bounded diameter up to the singular time, confirming Perelman's conjecture for Type I cases.


<details>
  <summary>Details</summary>
Motivation: To address Perelman's conjecture about diameter bounds in Ricci flows encountering singularities, specifically focusing on Type I singularities.

Method: Introduces a concept of neck-regions for Ricci flows (analogous to those in Ricci limit spaces) and proves that the associated packing measure is Ahlfors regular.

Result: Proves that three-dimensional compact Ricci flows with Type I singularities have uniformly bounded diameter up to the singular time.

Conclusion: Provides affirmative answer to Perelman's conjecture for Type I singularities and establishes general Ahlfors regularity result for packing measures in any dimension.

Abstract: We prove that a three dimensional compact Ricci flow that encounters a Type I
singularity has uniformly bounded diameter up to the singular time, thus giving
an affirmative answer - for Type I singularities - to a conjecture of Perelman.
To achieve this, we introduce a concept of a neck-region for a Ricci flow,
analogous to the neck-regions introduced by Jiang-Naber and
Cheeger-Jiang-Naber, in the study of Ricci limit spaces. We then prove that the
associated packing measure is, in a certain sense, Ahlfors regular, a result
that holds in any dimension.

</details>


### [53] [Families of surfaces with constant ratio of principal curvatures and Plateau's problem](https://arxiv.org/abs/2510.14527)
*Mikhail Skopenkov,Khusrav Yorov*

Main category: math.DG

TL;DR: Construction of surfaces with constant ratio of principal curvatures (CRPC) containing minimal surfaces, with applications to Plateau's problem and isotropic geometry.


<details>
  <summary>Details</summary>
Motivation: CRPC surfaces generalize minimal surfaces but are more difficult to construct. The work aims to develop methods for constructing such surfaces and solve related geometric problems.

Method: Proposed construction of CRPC surfaces containing given minimal surfaces, using successive approximations and analytic majorization. Applied approach of solving Euclidean problems via isotropic analogs.

Result: Obtained a family of CRPC surfaces and partial solution to Plateau's problem for these surfaces. Achieved analogous results in isotropic geometry.

Conclusion: The work demonstrates a general approach of solving Euclidean geometric problems by first addressing their isotropic counterparts, providing construction methods for challenging CRPC surfaces.

Abstract: This work is on surfaces with a constant ratio of principal curvatures. These
CRPC surfaces generalize minimal surfaces but are much more challenging to
construct. We propose a construction of a family of such surfaces containing a
given minimal surface without flat points. This leads to a partial solution of
Plateau's problem for CRPC surfaces. We obtain analogous results in isotropic
geometry. This work illustrates a general approach to solving Euclidean
problems by starting with their isotropic analogs. Besides, we apply the method
of successive approximations and analytic majorization.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [54] [Quantum Search in Superposed Quantum Lattice Gas Automata and Lattice Boltzmann Systems](https://arxiv.org/abs/2510.14062)
*Călin A. Georgescu,Matthias Möller*

Main category: quant-ph

TL;DR: This paper proposes quantum methods for CFD using discrete optimization and quantum search to avoid flow field measurements, enabling asymptotic quantum advantage through amplitude estimation and simultaneous simulation of lattice configurations.


<details>
  <summary>Details</summary>
Motivation: As CFD scales to larger problems, there's interest in quantum computing advantages. Current QLGA and QLBM methods focus on model development but are limited to quantum state tomography and observable measurement, which may cancel quantum advantages unless specific criteria are met.

Method: The authors propose application-based approaches using discrete optimization and quantum search that circumvent flow field measurement. They develop methods for simulating multiple lattice configurations simultaneously and utilize amplitude estimation and quantum search algorithms.

Result: The paper demonstrates that these quantum approaches can provide asymptotic quantum advantage. It includes detailed complexity analyses of gate-level circuit implementations and evaluates various encoding schemes.

Conclusion: The proposed quantum methods for CFD avoid the limitations of flow field measurement and offer potential quantum advantages through discrete optimization and quantum search techniques, with careful consideration of encoding costs and benefits.

Abstract: As the scope of Computational Fluid Dynamics (CFD) grows to encompass ever
larger problem scales, so does the interest in whether quantum computing can
provide an advantage. In recent years, Quantum Lattice Gas Automata (QLGA) and
Quantum Lattice Boltzmann Methods (QLBM) have emerged as promising candidates
for quantum-native implementations of CFD solvers. Though the progress in
developing QLGA and QLBM algorithms has been significant, it has largely
focused on the development of models rather than applications. As a result, the
zoo of QLGA and QLBM algorithms has grown to target several equations and to
support many extensions, but the practical use of these models is largely
limited to quantum state tomography and observable measurement. This limitation
is crucial in practice, because unless very specific criteria are met, such
measurements may cancel out any potential quantum advantage. In this paper, we
propose an application based on discrete optimization and quantum search, which
circumvents flow field measurement altogether. We propose methods for
simulating many different lattice configurations simultaneously and describe
how the usage of amplitude estimation and quantum search can provide an
asymptotic quantum advantage. Throughout the paper, we provide detailed
complexity analyses of gate-level implementations of our circuits and consider
the benefits and costs of several encodings.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [55] [The geometry of PLS shrinkages](https://arxiv.org/abs/2510.14430)
*Paolo Foschi*

Main category: math.ST

TL;DR: This paper analyzes the geometrical structure of PLS shrinkages, provides an explicit formula for shrinkage vectors, and shows that PLS estimators can have highly nonlinear behavior in extreme cases. It also disproves the longstanding conjecture about PLS degrees of freedom.


<details>
  <summary>Details</summary>
Motivation: To understand the geometrical structure of PLS shrinkages and examine the behavior of PLS estimators, particularly in extreme situations where existing degrees of freedom measures fail.

Method: The authors provide an explicit formula for shrinkage vectors where shrinkage factors are expressed as averages of basic shrinkages dependent on the data matrix, with weights being multilinear functions of observed responses.

Result: The study characterizes the set of possible shrinkages and identifies extreme situations where PLS estimators exhibit highly nonlinear behavior. It shows that existing DoF measures fail in these cases and disproves the conjecture that PLS DoFs always exceed the number of PLS directions.

Conclusion: PLS shrinkages have a complex geometrical structure with potential nonlinear behavior in extreme cases, and the longstanding conjecture about PLS degrees of freedom is incorrect.

Abstract: The geometrical structure of PLS shrinkages is here considered. Firstly, an
explicit formula for the shrinkage vector is provided. In that expression,
shrinkage factors are expressed a averages of a set of basic shrinkages that
depend only on the data matrix. On the other hand, the weights of that average
are multilinear functions of the observed responses. That representation allows
to characterise the set of possible shrinkages and identify extreme situations
where the PLS estimator has an highly nonlinear behaviour. In these situations,
recently proposed measures for the degrees of freedom (DoF), that directly
depend on the shrinkages, fail to provide reasonable values. It is also shown
that the longstanding conjecture that the DoFs of PLS always exceeds the number
PLS directions does not hold.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [56] [Bell Instability and Cosmic-Ray Acceleration in AGN Ultrafast Outflow Shocks](https://arxiv.org/abs/2510.13946)
*Rei Nishiura,Tsuyoshi Inoue*

Main category: astro-ph.HE

TL;DR: The paper investigates magnetic-field amplification via NRH instability in cosmic-ray acceleration at AGN outflows, finding a transition in efficiency based on background magnetic field strength.


<details>
  <summary>Details</summary>
Motivation: To understand how NRH instability affects cosmic-ray acceleration at reverse shocks of AGN outflows, particularly as previous studies showed efficiency decreases with higher maximum CR energies.

Method: Uses 1D MHD-CR framework with telegraph-type diffusion-convection equations to model coupled evolution of CRs, magnetic fields, and shock dynamics under realistic parameters.

Result: Found transition at B₀ ~10⁻⁴ G: weak fields allow efficient NRH amplification and self-regulated E_max; strong fields (B₀ ≳10⁻³ G) suppress NRH instability and reduce acceleration efficiency.

Conclusion: NRH instability efficiency depends critically on background magnetic field strength, with implications for PeV-EeV cosmic-ray acceleration conditions at UFO reverse shocks.

Abstract: We investigate magnetic-field amplification driven by the nonresonant hybrid
(NRH or Bell) instability and its impact on cosmic-ray (CR) acceleration at
reverse shocks of ultrafast outflows (UFOs) from active galactic nuclei (AGN).
Previous kinetic studies by particle-in-cell simulations have demonstrated that
when maximum CR energy is near the injection scale, NRH instability efficiently
amplifies magnetic field up to the saturation level. However, the efficiency of
NRH instability goes down as maximum energy increase since CR current is
carried by escaping CRs near the maximum energy. We employ a one-dimensional
MHD--CR framework solving telegraph-type diffusion--convection equations to
trace the coupled evolution of CRs, magnetic fields, and shock dynamics under
realistic parameters. We find a distinct transition with magnetic field
strength: for weak background fields ($B_{0}\!\lesssim\!10^{-4}\,\mathrm{G}$),
NRH instability efficiently amplifies upstream turbulence, driving a
self-regulated state where $E_{\max}$ becomes independent of initial strength
of magnetic turbulence. In contrast, for stronger background fields
($B_{0}\!\gtrsim\!10^{-3}\,\mathrm{G}$), the escaping CR current is too weak to
drive NRH instability, and magnetic turbulence further decays through
parametric instabilities, potentially reducing the acceleration efficiency. We
give the physical interpretation for the transition and discuss conditions for
PeV--EeV acceleration at UFO reverse shocks.

</details>


<div id='nlin.SI'></div>

# nlin.SI [[Back]](#toc)

### [57] [Asymmetric integrable turbulence and rogue wave statistics for the derivative nonlinear Schrödinger equation](https://arxiv.org/abs/2510.14472)
*Ming Zhong,Weifang Weng,Zhenya Yan*

Main category: nlin.SI

TL;DR: The paper studies asymmetric integrable turbulence and rogue waves in the DNLS equation, showing oscillatory convergence of statistical measures with specific decay rates and frequency relationships to modulation instability.


<details>
  <summary>Details</summary>
Motivation: To understand the asymmetric turbulence and rogue wave dynamics emerging from modulation instability in the DNLS equation, which differs from the symmetric behavior in NLS systems.

Method: Analysis of n-th moments, ensemble-averaged kinetic and potential energy, wave-action spectrum, auto-correlation function, and probability density function of wave intensity for the DNLS equation.

Result: Statistical measures oscillate with t^{-1.36} amplitude decay and t^{-0.78} phase shift decay. Wave-action spectrum follows power-law |k+3|^{-α} (except k=-3). PDF approaches exponential distribution oscillatory. Rogue wave probability increases during initial nonlinear phase when potential modulus is minimal.

Conclusion: DNLS turbulence is asymmetric due to wave number asymmetry, with oscillatory convergence to steady state and enhanced rogue wave occurrence during specific phases of modulation instability development.

Abstract: We investigate the asymmetric integrable turbulence and rogue waves (RWs)
emerging from the modulation instability (MI) of plane waves for the DNLS
equation. The \(n\)-th moments and ensemble-averaged kinetic and potential
energy exhibit oscillatory convergence towards their steady-state values.
Specifically, the amplitudes of oscillations for these indexes decay
asymptotically with time as \(t^{-1.36}\), while the phase shifts demonstrate a
nonlinear decay with a rate of \(t^{-0.78}\). The frequency of these
oscillations is observed to be twice the maximum growth rate of MI. These
oscillations can be classified into two distinct types: one is in phase with
ensemble-averaged potential energy modulus $|\langle H_4\rangle|$, and the
other is anti-phase. At the same time, this unity is also reflected in the
wave-action spectrum \( S_k(t) \) for a given \( k \), the auto-correlation
function \( g(x,t) \) for a given \( x \), as well as the PDF \( P(I,t) \). The
critical feature of the turbulence is the wave-action spectrum, which follows a
power-law distribution of \( |k+3|^{-\alpha} \) expect for $k=-3$. Unlike the
NLS equation, the turbulence in the DNLS setting is asymmetric, primarily due
to the asymmetry between the wave number of the plane wave from the MI and the
perturbation wave number.. As the asymptotic peak value of \( S_k \) is
observed at \( k = -3 \), the auto-correlation function exhibits a nonzero
level as \( x \to \pm L/2 \). The PDF of the wave intensity asymptotically
approaches the exponential distribution in an oscillatory manner. However,
during the initial stage of the nonlinear phase, MI slightly increases the
occurrence of RWs. This happens at the moments when the potential modulus is at
its minimum, where the probability of RWs occurring in the range of \( I\in
[12, 15] \) is significantly higher than in the asymptotic steady state.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [58] [Multi-Period Sparse Optimization for Proactive Grid Blackout Diagnosis](https://arxiv.org/abs/2510.14045)
*Qinghua Ma,Reetam Sen Biswas,Denis Osipov,Guannan Qu,Soummya Kar,Shimiao Li*

Main category: eess.SY

TL;DR: Proposes a multi-period sparse optimization method to identify persistent failure sources across sequences of system collapses under increasing stress, enabling early warning diagnosis of key vulnerabilities in power grids.


<details>
  <summary>Details</summary>
Motivation: Need to evaluate power grid survivability under extreme events and identify dominant vulnerabilities that cause multiple system collapses, enhancing resilience through early warning diagnosis.

Method: Multi-period sparse optimization with persistency constraints, using circuit-theory based power flow formulations and circuit-inspired optimization heuristics for scalability.

Result: Method reliably tracks persistent vulnerability locations under increasing load stress and scales to large systems (average 200s per scenario on 2000+ bus systems).

Conclusion: The proposed approach effectively identifies evolving vulnerabilities in power grids, providing scalable early warning diagnosis for system resilience enhancement.

Abstract: Existing or planned power grids need to evaluate survivability under extreme
events, like a number of peak load overloading conditions, which could possibly
cause system collapses (i.e. blackouts). For realistic extreme events that are
correlated or share similar patterns, it is reasonable to expect that the
dominant vulnerability or failure sources behind them share the same locations
but with different severity. Early warning diagnosis that proactively
identifies the key vulnerabilities responsible for a number of system collapses
of interest can significantly enhance resilience. This paper proposes a
multi-period sparse optimization method, enabling the discovery of {persistent
failure sources} across a sequence of collapsed systems with increasing system
stress, such as rising demand or worsening contingencies. This work defines
persistency and efficiently integrates persistency constraints to capture the
``hidden'' evolving vulnerabilities. Circuit-theory based power flow
formulations and circuit-inspired optimization heuristics are used to
facilitate the scalability of the method. Experiments on benchmark systems show
that the method reliably tracks persistent vulnerability locations under
increasing load stress, and solves with scalability to large systems ({on
average} taking {around} 200 s per scenario on 2000+ bus systems).

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [59] [Breaking gyrochronology through the collapse of coronal winds](https://arxiv.org/abs/2510.14164)
*Michaël Lévesque,Paul Charbonneau*

Main category: astro-ph.SR

TL;DR: Gyrochronology fails for stars older than the Sun, possibly due to wind collapse from reduced coronal heating rather than dynamo changes.


<details>
  <summary>Details</summary>
Motivation: To explain why gyrochronology (dating stars by rotation) fails for old stars by exploring wind collapse from reduced coronal heating as an alternative to dynamo shutdown.

Method: Analyzed magnetocentrifugal effects in low coronal temperature limit, showing mass loss scales linearly with wind power input, and tested power law relationships between temperature, magnetic field, and rotation.

Result: Found that reproducing the gyrochronology break requires unrealistically large temperature-magnetic field exponent (σ ≥ 1.5), associated with over 1000x drop in coronal power input, inconsistent with observations.

Conclusion: Wind collapse due to reduced coronal heating is unlikely to explain gyrochronology failure; dynamo changes remain the more plausible explanation.

Abstract: Gyrochronology, a method for dating aged field stars ($\gtrsim$ a few Gyr)
based on their rotation rate, has recently been shown to fail for many stars
older than the sun. The explanation most often put forth is that a shutdown or
mode change in the stellar dynamo leads to a sharp decrease in angular momentum
loss in magnetized coronal winds. In this paper, we explore an alternate
possibility, namely a collapse of the wind itself through a reduction of
coronal heating. We show that in the low coronal temperature ($T_0$) limit,
even at solar-like low rotation rates ($\Omega$) and coronal magnetic field
strength ($B_{r0}$), magnetocentrifugal effects are important and preclude
expression of the mass and angular momentum loss rates as power-laws of $T_0$
or $\Omega$ when $T_0$ drops below $\simeq 1.5\,$MK. Mass loss is found to
scale linearly with power input into the wind at all coronal temperatures.
Introducing an ad hoc power law relationship $T_0\propto B_{r0}^\sigma$ while
retaining the ``standard'' dynamo relationship $B_{r0}\propto\Omega$, we show
that reproducing the observed break in gyrochronology requires an exponent
$\sigma\gtrsim 1.5$, with which is associated a drop by over 3 orders of
magnitude in power input into the quiet corona. This appears physically
unrealistic, given current observations of chromospheric and coronal
non-thermal emission in aged solar-type stars.

</details>


### [60] [Influence of kinetic effects in large-scale magnetic reconnection with multi-hierarchy simulation code KAMMUY](https://arxiv.org/abs/2510.14521)
*Keita Akutagawa,Shinsuke Imada,Munehito Shoda*

Main category: astro-ph.SR

TL;DR: A multi-hierarchy simulation code called KAMMUY was developed to bridge the scale gap between fluid and particle physics in magnetic reconnection by combining MHD and PIC simulations with mutual information exchange.


<details>
  <summary>Details</summary>
Motivation: To overcome the computational limitations of pure PIC simulations and capture the interaction between kinetic and fluid dynamics in large-scale magnetic reconnection phenomena like solar flares.

Method: Developed KAMMUY code that runs ideal MHD simulation for large domains and PIC simulation for smaller domains in parallel with mutual information exchange. Validated with MHD wave propagation and shock tube tests.

Result: Short-wavelength waves from PIC region don't propagate into MHD region, while MHD-scale structures propagate smoothly into PIC region. Reconnection rate remains unchanged regardless of PIC domain size where Hall magnetic field is present.

Conclusion: The spatial extension of Hall magnetic field on scales of 10-100 ion inertial lengths does not influence the reconnection rate in magnetic reconnection.

Abstract: Magnetic reconnection is a multiscale phenomenon where fluid- and
particle-scale processes interact. The particle-in-cell (PIC) method, capable
of resolving kinetic (particle-scale) physics, is extensively used to study the
kinetic effects in magnetic reconnection. Meanwhile, because of the high
computational cost, PIC simulations cannot capture the interaction between
kinetic and fluid dynamics, which poses a major obstacle to understanding
magnetic reconnection in large-scale phenomena such as solar flares. A
multi-hierarchy simulation that combines Magnetohydrodynamics (MHD) and PIC
provides a promising means to overcome these spatial and temporal scale gaps.
We developed a multi-hierarchy simulation code KAMMUY (Kinetic And
Magnetohydrodynamic MUlti-hierarchY simulation code), in which an ideal MHD
simulation for a large domain and a PIC simulation for a smaller domain are
solved in parallel with mutual information exchange. To validate the code, we
conducted test simulations of MHD wave propagation and the shock tube problem.
The results demonstrate that short-wavelength, high-frequency waves generated
in the PIC region do not propagate into the MHD region, whereas MHD-scale
structures propagate smoothly into the PIC region, highlighting the capability
of our code for numerical studies of magnetic reconnection. By applying the
KAMMUY code to magnetic reconnection while varying the PIC domain size, we find
that the reconnection rate remains unchanged, regardless of the extent of the
PIC region where the Hall magnetic field is present. It suggests that the
spatial extension of the Hall magnetic field on the scale of $10 \sim 100
\lambda_i$ does not influence the reconnection rate.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [61] [Loss functions arising from the index of agreement](https://arxiv.org/abs/2510.14714)
*Hristos Tyralis,Georgia Papacharalampous*

Main category: stat.ME

TL;DR: Theoretical analysis of Willmott's index of agreement loss function and proposal of an improved version with better geometric alignment and closed-form solutions.


<details>
  <summary>Details</summary>
Motivation: To examine the theoretical properties of Willmott's index of agreement loss function and address its limitations by proposing a theoretically improved alternative.

Method: Proposed L_NR2 as an improved loss function that replaces the denominator with sum of Euclidean distances, providing better geometric alignment and admitting closed-form solutions for linear model parameter estimation.

Result: L_NR2 retains all appealing properties of L_W while enabling closed-form solutions. As correlation between predictors and dependent variable approaches 1, parameter estimates from squared error, L_NR2 and L_W converge, with similar performance observed in hydrologic model calibration.

Conclusion: L_NR2 serves as a theoretical improvement over L_W, maintaining its desirable properties while offering better geometric intuition and computational advantages, with potential for further improvements to existing L_p-norm variants.

Abstract: We examine the theoretical properties of the index of agreement loss function
$L_W$, the negatively oriented counterpart of Willmott's index of agreement, a
common metric in environmental sciences and engineering. We prove that $L_W$ is
bounded within [0, 1], translation and scale invariant, and estimates the
parameter $\Bbb{E}_{F}[\underline{y}] \pm \Bbb{V}_{F}^{1/2}[\underline{y}]$
when fitting a distribution. We propose $L_{\operatorname{NR}_2}$ as a
theoretical improvement, which replaces the denominator of $L_W$ with the sum
of Euclidean distances, better aligning with the underlying geometric
intuition. This new loss function retains the appealing properties of $L_W$ but
also admits closed-form solutions for linear model parameter estimation. We
show that as the correlation between predictors and the dependent variable
approaches 1, parameter estimates from squared error, $L_{\operatorname{NR}_2}$
and $L_W$ converge. This behavior is mirrored in hydrologic model calibration
(a core task in water resources engineering), where performance becomes nearly
identical across these loss functions. Finally, we suggest potential
improvements for existing $L_p$-norm variants of the index of agreement.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [62] [Resonate-and-Fire Photonic-Electronic Spiking Neurons for Fast and Efficient Light-Enabled Neuromorphic Processing Systems](https://arxiv.org/abs/2510.14515)
*Andrew Adair,Dafydd Owen-Newns,Giovanni Donati,Joshua Robertson,José Figueiredo,Eduard Wasige,Qusay Al-Taai,Bruno Romeira,Matěj Hejda,Antonio Hurtado*

Main category: physics.optics

TL;DR: A photonic-electronic resonate-and-fire spiking neuron that responds to temporal patterns in optical inputs, enabling ultrafast, energy-efficient neuromorphic computing with bandpass filtering and temporal pattern recognition capabilities.


<details>
  <summary>Details</summary>
Motivation: Current photonic neurons mainly mimic simple integrate-and-fire models, but neuroscience shows neurons use richer mechanisms like frequency and temporal patterns for information encoding. There's a need for photonic approaches that can handle these more complex temporal dynamics.

Method: Developed a light-sensitive resonant tunnelling diode-based neuron that responds to nanosecond, low-power optical signals at telecom wavelengths. The system uses inter-pulse timing control and applied bias voltage to achieve bandpass filtering, and supports optical fan-in via wavelength-division multiplexed inputs from four VCSELs.

Result: Successfully demonstrated control of resonate-and-fire dynamics, achieving bandpass filtering of both analogue and digital inputs. The neuron exhibited key functionalities including spike-frequency filtering, temporal pattern recognition, and digital-to-spiking conversion.

Conclusion: This approach establishes a pathway toward low-power, high-speed temporal information processing for light-enabled neuromorphic computing, addressing the limitations of existing photonic neurons by enabling richer temporal pattern processing.

Abstract: Neuromorphic computing seeks to replicate the spiking dynamics of biological
neurons for brain-inspired computation. While electronic implementations of
artificial spiking neurons have dominated to date, photonic approaches are
attracting increasing research interest as they promise ultrafast,
energy-efficient operation with low-crosstalk and high bandwidth. Nevertheless,
existing photonic neurons largely mimic integrate-and-fire models, but
neuroscience shows that neurons also encode information through richer
mechanisms, such as the frequency and temporal patterns of spikes. Here, we
present a photonic-electronic resonate-and-fire (R-and-F) spiking neuron that
responds to the temporal structure of high-speed optical inputs. This is based
on a light-sensitive resonant tunnelling diode that produces excitable spikes
in response to nanosecond, low-power (100 microwatt) optical signals at
infrared telecom wavelengths. We experimentally demonstrate control of R-and-F
dynamics through inter-pulse timing of the optical stimuli and applied bias
voltage, achieving bandpass filtering of both analogue and digital inputs. The
R-and-F neuron also supports optical fan-in via wavelength-division multiplexed
inputs from four vertical-cavity surface-emitting lasers (VCSELs). This
electronic-photonic neuron exhibits key functionalities - including
spike-frequency filtering, temporal pattern recognition, and digital-to-spiking
conversion - critical for neuromorphic optical processing. Our approach
establishes a pathway toward low-power, high-speed temporal information
processing for light-enabled neuromorphic computing.

</details>


### [63] [A Flying Focus with Arbitrary Directionality](https://arxiv.org/abs/2510.14195)
*Sida Cao,Devdigvijay Singh,Lavonne S. Mack,John P. Palastro,Matthew R. Edwards*

Main category: physics.optics

TL;DR: A flying focus configuration that decouples focal point motion from propagation direction, enabling multi-dimensional control of focal trajectories for various laser applications.


<details>
  <summary>Details</summary>
Motivation: Existing flying focus techniques constrain focal point motion to the propagation direction, limiting their flexibility for applications requiring more complex focal trajectories.

Method: Using chirped laser pulses focused and diffracted by a diffractive lens and grating to create focal points that can move both along and transverse to propagation direction. Parameters like focal length, grating period, and chirp are tuned to control direction and velocity.

Result: Simulations demonstrate successful control of focal trajectories, with holographic configurations for high-power pulses using off-axis pump beams, and conventional optics for low-power pulses.

Conclusion: Multi-dimensional control over focal trajectories enables new configurations for applications including laser wakefield acceleration, THz radiation steering, and surface harmonic generation.

Abstract: Flying focus techniques produce laser pulses whose focal points travel at
arbitrary, controllable velocities. While this flexibility can enhance a broad
range of laser-based applications, existing techniques constrain the motion of
the focal point to the propagation direction of the pulse. Here, we introduce a
flying focus configuration that decouples the motion of the focus from the
propagation direction. A chirped laser pulse focused and diffracted by a
diffractive lens and grating creates a focal point that can move both along and
transverse to the propagation direction. The focal length of the lens, grating
period, and chirp can be tuned to control the direction and velocity of the
focus. Simulations demonstrate this control for a holographic configuration
suited to high-power pulses, in which two off-axis pump beams with different
focal lengths encode the equivalent phase of a chromatic lens and grating in a
gas or plasma. For low-power pulses, conventional solid-state or adaptive
optics can be used instead. Multi-dimensional control over the focal trajectory
enables new configurations for applications, including laser wakefield
acceleration of ions, steering of broadband THz radiation, and surface harmonic
generation.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [64] [Multiscaling asymptotic behavior of solutions to random high-order heat equations](https://arxiv.org/abs/2510.14153)
*Maha Mosaad A Alghamdi,Nikolai Leonenko,Andriy Olenko*

Main category: math.PR

TL;DR: The paper analyzes high-order PDEs with random initial conditions exhibiting long-memory and cyclic behavior, proving convergence to Gaussian random fields after proper scaling.


<details>
  <summary>Details</summary>
Motivation: To study high-order PDEs with random initial conditions that have spectral singularities at zero (long-range dependence) and non-zero frequencies (cyclic long-range dependence), which are important for understanding complex stochastic processes.

Method: Uses spectral methods and scaling techniques to prove convergence to Gaussian random fields, with kernel averaging applied to odd-order equations to obtain nonexplosive limits.

Result: Solutions converge to Gaussian random fields after proper rescaling. Limit fields are determined by equation order (even/odd) and presence of spectral singularity at zero. Spectral representations and covariance functions are provided.

Conclusion: Different limit fields depend on equation order and spectral singularity characteristics, with numerical examples validating theoretical findings.

Abstract: This paper studies high-order partial differential equations with random
initial conditions that have both long-memory and cyclic behavior. The cases of
random initial conditions with the spectral singularities, both at zero
(representing classical long-range dependence) and at non-zero frequencies
(representing cyclic long-range dependence), are investigated.
  Using spectral methods and scaling techniques, it is proved that, after
proper rescaling and normalization, the solutions converge to Gaussian random
fields. For each type of equation, spectral representations and covariance
functions of limit fields are given. For odd-order equations, we apply the
kernel averaging of solutions to obtain nonexplosive and nondegenerate limits.
It is shown that the different limit fields are determined by the even or odd
orders of the equations and by the presence or absence of a spectral
singularity at zero. Several numeric examples illustrate the obtained
theoretical results.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [65] [Grain volume distribution alters the critical phenomena in complex granular systems](https://arxiv.org/abs/2510.14797)
*Teng Man,Yimin Lu,Zhongrong Wang,Herbert Huppert,Alessio Zaccone,Honglei Sun*

Main category: cond-mat.soft

TL;DR: This study uses DEM simulations to investigate how grain size distribution affects rheology and critical behavior in sheared granular flows, finding a unified rheological relation with an embedded characteristic length scale related to contact probability.


<details>
  <summary>Details</summary>
Motivation: Grain size distribution significantly impacts mechanical properties of granular materials, causing segregation and altering critical behaviors, which is important for engineering and geophysical applications.

Method: Used discrete element method (DEM) simulations to study sheared granular flows with various grain size distributions.

Result: Found a unified rheological relation with embedded characteristic length scale related to contact probability, and obtained correlation between critical solid fractions and dimensionless grain volume distributions.

Conclusion: The work elucidates how particle volumes affect rheology and micromechanics, providing insights for incorporating other particle properties into a unified framework for engineering and geophysical problems.

Abstract: The grain size distribution (GSD) plays an important role in the mechanical
properties of amorphous disordered systems and complex granular materials.
Varying GSD causes segregation issues and alters critical behaviors. This work
used the discrete element method (DEM) to investigate the rheological and
critical behaviors of sheared granular flows with various GSDs. The results
show that, while a unified rheological relation can be obtained, a
characteristic length scale, which is associated with the contact probability
and can be obtained from any GSD, is embedded within such a polydisperse
disordered system. We further acquire a correlation function between critical
solid fractions and dimensionless grain volume distributions. This work
elucidates the effect of particle volumes on the rheology and micromechanics of
dry granular systems and provides further insights in better incorporating the
influence of other particle properties into a unified framework, which is
helpful and critical for the corresponding engineering and geophysical
problems.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [66] [Comparative Analysis of the Flow in a Realistic Human Airway](https://arxiv.org/abs/2510.14320)
*Mario Rüttgers,Julian Vorspohl,Luca Mayolle,Benedikt Johanning-Meiners,Dominik Krug,Michael Klaas,Matthias Meinke,Sangseung Lee,Wolfgang Schröder,Andreas Lintermann*

Main category: physics.flu-dyn

TL;DR: Direct numerical simulations of inspiratory flow through detailed human airway geometry using lattice-Boltzmann method, showing pressure loss distribution and flow instabilities across four anatomical regions at different Reynolds numbers.


<details>
  <summary>Details</summary>
Motivation: Existing computational studies rely on simplified geometries or turbulence models, limiting their ability to resolve important flow features like shear-layer instabilities and secondary vortices in human airways.

Method: Direct numerical simulations using lattice-Boltzmann method for inspiratory flow through detailed airway model (nasal mask to 6th bronchial bifurcation) at two physiologically relevant Reynolds numbers (Re_p=400 and 1200), examining flow across four anatomical regions.

Result: Total pressure loss increased from 9.76 Pa at Re_p=400 to 41.93 Pa at Re_p=1200. Nasal cavity accounted for majority of loss (81.3% at Re_p=400, 73.4% at Re_p=1200). Secondary vortices in nasopharyngeal bend and turbulent shear-layers in glottis jet enhanced local pressure losses at higher Re, while carinal bifurcation stabilized flow.

Conclusion: Spatial correlation between pressure loss and flow instabilities across regions provides novel perspective on how flow resistance and vortex dynamics vary with geometric changes and flow rate in human airways.

Abstract: Accurate simulations of the flow in the human airway are essential for
advancing diagnostic methods. Many existing computational studies rely on
simplified geometries or turbulence models, limiting their simulation's ability
to resolve flow features such shear-layer instabilities or secondary vortices.
In this study, direct numerical simulations were performed for inspiratory flow
through a detailed airway model which covers the nasal mask region to the 6th
bronchial bifurcation. Simulations were conducted at two physiologically
relevant \textsc{Reynolds} numbers with respect to the pharyngeal diameter,
i.e., at Re_p=400 (resting) and Re_p=1200 (elevated breathing). These values
characterize resting and moderately elevated breathing conditions. A
lattice-Boltzmann method was employed to directly simulate the flow, i.e., no
turbulence model was used. The flow field was examined across four anatomical
regions: 1) the nasal cavity, 2) the naso- and oropharynx, 3) the
laryngopharynx and larynx, and 4) the trachea and carinal bifurcation. The
total pressure loss increased from 9.76 Pa at Re_p=400 to 41.93 Pa at
Re_p=1200. The nasal cavity accounted for the majority of this loss for both
Reynolds numbers, though its relative contribution decreased from 81.3% at
Re_p=400 to 73.4% at Re_p=1200. At Re_p=1200, secondary vortices in the
nasopharyngeal bend and turbulent shear-layers in the glottis jet enhanced the
local pressure losses. In contrast, the carinal bifurcation mitigated upstream
unsteadiness and stabilized the flow. A key outcome is the spatial correlation
between the pressure loss and the onset of flow instabilities across the four
regions. This yields a novel perspective on how the flow resistance and vortex
dynamics vary with geometric changes and flow rate.

</details>
