<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 22]
- [math.AP](#math.AP) [Total: 16]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 7]
- [eess.SY](#eess.SY) [Total: 1]
- [math.DG](#math.DG) [Total: 2]
- [physics.optics](#physics.optics) [Total: 2]
- [math.ST](#math.ST) [Total: 1]
- [hep-ph](#hep-ph) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 2]
- [math.OC](#math.OC) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [math.PR](#math.PR) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [stat.ME](#stat.ME) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [nlin.SI](#nlin.SI) [Total: 1]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A decoupled Crank-Nicolson leap-frog scheme for the unsteady bioconvection flows problem with concentration dependent viscosity](https://arxiv.org/abs/2510.14034)
*Chenyang Li*

Main category: math.NA

TL;DR: A fully discrete Crank-Nicolson Leap-Frog scheme is developed for unsteady bioconvection flow with concentration-dependent viscosity, using FEM for spatial discretization and CNLF with semi-implicit nonlinear treatment for temporal discretization.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient numerical scheme for unsteady bioconvection flow problems with concentration-dependent viscosity that is unconditionally stable and provides accurate solutions.

Method: Combines Galerkin finite element method for spatial discretization with Crank-Nicolson Leap-Frog scheme for temporal discretization, using semi-implicit approach for nonlinear terms.

Result: The scheme is proven to be unconditionally stable (no restrictive time step bound) and provides LÂ²-optimal error estimates for velocity and concentration. Numerical experiments validate theoretical results.

Conclusion: The proposed CNLF scheme is effective for bioconvection flow problems, offering unconditional stability and optimal convergence rates, as confirmed by both theoretical analysis and numerical validation.

Abstract: A fully discrete Crank--Nicolson Leap--Frog (CNLF) scheme is proposed and
analyzed for the unsteady bioconvection flow problem with
concentration-dependent viscosity. Spatial discretization is handled via the
Galerkin finite element method (FEM), while temporal discretization employs the
CNLF method for the linear terms and a semi-implicit approach for the nonlinear
terms. The scheme is proven to be unconditionally stable, i.e., the time step
is not subject to a restrictive upper bound. Using the energy method,
$L^2$-optimal error estimates are derived for the velocity and concentration .
Finally, numerical experiments are presented to validate the theoretical
results.

</details>


### [2] [Geometric local parameterization for solving Hele-Shaw problems with surface tension](https://arxiv.org/abs/2510.14088)
*Zengyan Zhang,Wenrui Hao,John Harlim*

Main category: math.NA

TL;DR: A computational framework using point clouds and Generalized Moving Least Squares (GMLS) for solving 2D Hele-Shaw free boundary problems with surface tension, achieving high-order spatial convergence without global parameterization.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient method for free boundary problems that eliminates the need for global parameterization and enables high-order geometric approximations directly from point cloud data.

Method: Represent moving boundary by point clouds, use GMLS to construct local geometric charts for high-order curvature approximations, discretize boundary integral equation with analytical singular integrals, and provide rigorous convergence analysis.

Result: Numerical experiments confirm high-order spatial convergence and expected temporal convergence rates, with simulations showing complex shapes evolving correctly toward circular equilibrium states under surface tension.

Conclusion: The proposed framework successfully solves 2D Hele-Shaw problems with surface tension using point clouds and GMLS, achieving theoretical convergence rates and handling complex geometries effectively.

Abstract: In this work, we introduce a novel computational framework for solving the
two-dimensional Hele-Shaw free boundary problem with surface tension. The
moving boundary is represented by point clouds, eliminating the need for a
global parameterization. Our approach leverages Generalized Moving Least
Squares (GMLS) to construct local geometric charts, enabling high-order
approximations of geometric quantities such as curvature directly from the
point cloud data. This local parameterization is systematically employed to
discretize the governing boundary integral equation, including an analytical
formula of the singular integrals. We provide a rigorous convergence analysis
for the proposed spatial discretization, establishing consistency and stability
under certain conditions. The resulting error bound is derived in terms of the
size of the uniformly sampled point cloud data on the moving boundary, the
smoothness of the boundary, and the order of the numerical quadrature rule.
Numerical experiments confirm the theoretical findings, demonstrating
high-order spatial convergence and the expected temporal convergence rates. The
method's effectiveness is further illustrated through simulations of complex
initial shapes, which correctly evolve towards circular equilibrium states
under the influence of surface tension.

</details>


### [3] [A Stochastic Algorithm for Searching Saddle Points with Convergence Guarantee](https://arxiv.org/abs/2510.14144)
*Baoming Shi,Lei Zhang,Qiang Du*

Main category: math.NA

TL;DR: A stochastic saddle-search algorithm that avoids exact derivative and Hessian evaluations, using stochastic eigenvector-search and gradient updates with reflections to find saddle points efficiently.


<details>
  <summary>Details</summary>
Motivation: Saddle points reveal transition pathways and global structure of energy landscapes, but traditional deterministic methods require exact derivative/Hessian evaluations which can be computationally expensive.

Method: Stochastic eigenvector-search using stochastic Hessian to approximate unstable directions, followed by stochastic gradient updates with reflections in the unstable direction.

Result: Established almost sure convergence for eigenvector search and local almost sure convergence with O(1/n) rate for saddle search. High-probability identification of saddle points when starting sufficiently close.

Conclusion: The algorithm demonstrates practical applicability in neural network loss landscapes and liquid crystal models, showing ability to escape from 'bad' areas while avoiding exact derivative computations.

Abstract: Saddle points provide a hierarchical view of the energy landscape, revealing
transition pathways and interconnected basins of attraction, and offering
insight into the global structure, metastability, and possible collective
mechanisms of the underlying system. In this work, we propose a stochastic
saddle-search algorithm to circumvent exact derivative and Hessian evaluations
that have been used in implementing traditional and deterministic saddle
dynamics. At each iteration, the algorithm uses a stochastic eigenvector-search
method, based on a stochastic Hessian, to approximate the unstable directions,
followed by a stochastic gradient update with reflections in the approximate
unstable direction to advance toward the saddle point. We carry out rigorous
numerical analysis to establish the almost sure convergence for the stochastic
eigenvector search and local almost sure convergence with an $O(1/n)$ rate for
the saddle search, and present a theoretical guarantee to ensure the
high-probability identification of the saddle point when the initial point is
sufficiently close. Numerical experiments, including the application to a
neural network loss landscape and a Landau-de Gennes type model for nematic
liquid crystal, demonstrate the practical applicability and the ability for
escaping from "bad" areas of the algorithm.

</details>


### [4] [Superconvergent and Divergence-Free Finite Element Methods for Stokes Equation](https://arxiv.org/abs/2510.14192)
*Long Chen,Xuehai Huang,Chao Zhang,Xinyue Zhao*

Main category: math.NA

TL;DR: Superconvergent and divergence-free finite element methods for Stokes equation using H(div)-conforming vector elements and discontinuous polynomials, requiring no stabilization.


<details>
  <summary>Details</summary>
Motivation: To develop efficient finite element methods for Stokes equation that are both superconvergent and divergence-free, connecting to existing formulations like virtual elements and mixed methods.

Method: Velocity and pressure discretized using H(div)-conforming vector elements and discontinuous piecewise polynomials, employing weak deviatoric gradient operator with tangential-normal continuous finite elements for traceless tensors.

Result: Optimal and superconvergent error estimates established, method connects to nonconforming virtual element and pseudostress-velocity-pressure mixed formulations.

Conclusion: Numerical experiments verify the theoretical results, demonstrating the effectiveness of the proposed divergence-free and superconvergent finite element methods for Stokes equation.

Abstract: Superconvergent and divergence-free finite element methods for the Stokes
equation are developed. The velocity and pressure are discretized using
$H(\mathrm{div})$-conforming vector elements and discontinuous piecewise
polynomials. The discrete formulation employs a weak deviatoric gradient
operator built with tangential-normal continuous finite elements for traceless
tensors, requiring no stabilization. Optimal and superconvergent error
estimates are established. The method connects to nonconforming virtual element
and pseudostress-velocity-pressure mixed formulations. Numerical experiments
verify the theory.

</details>


### [5] [Neural Networks for Bayesian Inverse Problems Governed by a Nonlinear ODE](https://arxiv.org/abs/2510.14197)
*German Villalobos,Johann Rudi,Andreas Mang*

Main category: math.NA

TL;DR: Neural networks are used to estimate hidden model parameters and quantify uncertainty from noisy observational data for inverse parameter estimation problems, specifically applied to the FitzHugh-Nagumo ODE model with various noise types.


<details>
  <summary>Details</summary>
Motivation: Traditional parameter estimation methods face challenges with nonlinear, nonconvex systems with sharp gradients. Neural networks offer a way to overcome these computational difficulties and provide comprehensive parameter estimation and uncertainty quantification.

Method: Formulate parameter estimation as a Bayesian inverse problem. Use neural networks to approximate reconstruction maps from time series data of spiking membrane potentials. Train different NN architectures to infer model parameters, noise parameters, and posterior covariance matrix with single forward evaluation.

Result: NNs successfully estimate parameters of the dynamical system, stochastic processes, and uncertainties. Results show performance across different architectures and noise conditions, with timing results reported for training on dedicated hardware.

Conclusion: Neural networks are a versatile tool for comprehensive parameter estimation in complex dynamical systems, capable of handling both deterministic parameters and stochastic uncertainties through the governing ODE.

Abstract: We investigate the use of neural networks (NNs) for the estimation of hidden
model parameters and uncertainty quantification from noisy observational data
for inverse parameter estimation problems. We formulate the parameter
estimation as a Bayesian inverse problem. We consider a parametrized system of
nonlinear ordinary differential equations (ODEs), which is the FitzHugh--Nagumo
model. The considered problem exhibits significant mathematical and
computational challenges for classical parameter estimation methods, including
strong nonlinearities, nonconvexity, and sharp gradients. We explore how NNs
overcome these challenges by approximating reconstruction maps for parameter
estimation from observational data. The considered data are time series of the
spiking membrane potential of a biological neuron. We infer parameters
controlling the dynamics of the model, noise parameters of autocorrelated
additive noise, and noise modeled via stochastic differential equations, as
well as the covariance matrix of the posterior distribution to expose parameter
uncertainties--all with just one forward evaluation of an appropriate NN. We
report results for different NN architectures and study the influence of noise
on prediction accuracy. We also report timing results for training NNs on
dedicated hardware. Our results demonstrate that NNs are a versatile tool to
estimate parameters of the dynamical system, stochastic processes, as well as
uncertainties, as they propagate through the governing ODE.

</details>


### [6] [High-Order Meshfree Surface Integration, Including Singular Integrands](https://arxiv.org/abs/2510.14236)
*Daniel R. Venn,Steven J. Ruuth*

Main category: math.NA

TL;DR: High-order meshfree methods for surface integration on point clouds, handling arbitrary surfaces without requiring specific point arrangements or triangulation, with extensions for singular integrals.


<details>
  <summary>Details</summary>
Motivation: Surface integration is important for engineering and scientific applications, particularly in PDEs. Mesh-based methods need curved meshes for high-order convergence, which are hard to obtain reliably. Meshfree methods typically require exact integration of basis functions, which is generally not available in closed form on most surfaces.

Method: Two meshfree methods for integrating on arbitrary piecewise-smooth surfaces with or without boundary. Methods don't require specific point arrangements or initial triangulation. Extensions handle singular integrals while maintaining high accuracy without changing point density near singularities.

Result: Methods provide high-order integration capabilities on surface point clouds without mesh requirements. Capable of handling singular integrals with maintained accuracy.

Conclusion: Developed meshfree high-order integration methods that work on arbitrary surfaces without mesh constraints, with special handling for singular integrals while preserving accuracy.

Abstract: We develop and test high-order methods for integration on surface point
clouds. The task of integrating a function on a surface arises in a range of
applications in engineering and the sciences, particularly those involving
various integral methods for partial differential equations. Mesh-based methods
require a curved mesh for high-order convergence, which can be difficult to
reliably obtain on many surfaces, and most meshfree methods require the ability
to integrate a set of functions (such as radial basis functions) exactly on the
domain of interest; these integrals are generally not known in closed form on
most surfaces. We describe two methods for integrating on arbitrary,
piecewise-smooth surfaces with or without boundary. Our approaches do not
require a particular arrangement of points or an initial triangulation of the
surface, making them completely meshfree. We also show how the methods can be
extended to handle singular integrals while maintaining high accuracy without
changing the point density near singularities.

</details>


### [7] [A DeepLagrangian method for learning and generating aggregation patterns in multi-dimensional Keller-Segel chemotaxis systems](https://arxiv.org/abs/2510.14297)
*Yani Feng,Michael K. Ng,Zhiwen Zhang*

Main category: math.NA

TL;DR: DeepLagrangian is a self-adaptive method that uses a Lagrangian framework and flow-based generative models to accurately solve the challenging Keller-Segel chemotaxis system, generating aggregation patterns and near-singular solutions in 2D and 3D space.


<details>
  <summary>Details</summary>
Motivation: The Keller-Segel chemotaxis system is difficult to solve due to near-singular behaviors like finite-time blow-up and concentration phenomena, making traditional methods ineffective for generating accurate aggregation patterns.

Method: Normalize KS solution into PDF, derive normalized KS system, rewrite into Lagrangian framework using continuity equation, define physics-informed Lagrangian loss, incorporate time-dependent KRnet flow-based generative model, use time-marching strategies for PDF approximation, then recover original KS solution.

Result: The method accurately solves 2D and 3D KS chemotaxis systems with/without advection, and proves that the Lagrangian loss effectively controls KL divergence between approximate and exact PDFs.

Conclusion: DeepLagrangian provides an effective framework for solving challenging KS chemotaxis systems by leveraging Lagrangian methods and generative models to handle near-singular solutions and generate accurate aggregation patterns.

Abstract: The Keller-Segel (KS) chemotaxis system is used to describe the overall
behavior of a collection of cells under the influence of chemotaxis. However,
solving the KS chemotaxis system and generating its aggregation patterns remain
challenging due to the emergence of solutions exhibiting near-singular
behavior, such as finite-time blow-up or concentration phenomena. Building on a
Lagrangian framework of the KS system, we develop DeepLagrangian, a
self-adaptive density estimation method that learns and generates aggregation
patterns and near-singular solutions of the KS system in two- and
three-dimensional (2D and 3D) space under different physical parameters. The
main advantage of the Lagrangian framework is its inherent ability to adapt to
near-singular solutions. To develop this framework, we normalize the KS
solution into a probability density function (PDF), derive the corresponding
normalized KS system, and utilize the property of the continuity equation to
rewrite the system into a Lagrangian framework. We then define a
physics-informed Lagrangian loss to enforce this framework and incorporate a
flow-based generative model, called the time-dependent KRnet, to approximate
the PDF by minimizing the loss. Furthermore, we integrate time-marching
strategies with the time-dependent KRnet to enhance the accuracy of the PDF
approximation. After obtaining the approximate PDF, we recover the original KS
solution. We also prove that the Lagrangian loss effectively controls the
Kullback-Leibler (KL) divergence between the approximate PDF and the exact PDF.
In the numerical experiments, we demonstrate the accuracy of our DeepLagrangian
method for the 2D and 3D KS chemotaxis system with/without advection.

</details>


### [8] [Numerical Approximation of Electrohydrodynamics Model: A Comparative Study of PINNs and FEM](https://arxiv.org/abs/2510.14310)
*Mara Martinez,B. Veena S. N. Rao,S. M. Mallikarjunaiah*

Main category: math.NA

TL;DR: A novel application of Physics-Informed Neural Networks (PINNs) is presented for solving the challenging Electrohydrodynamic (EHD) problem, showing excellent performance even with limited training data and outperforming conventional Finite Element Method (FEM).


<details>
  <summary>Details</summary>
Motivation: Deriving precise approximations for nonlinear differential equations (NDEs) remains challenging in computational mathematics, and while traditional methods like FEM are foundational, recent advances in physics-informed deep learning show promise for approximating continuous functions effectively.

Method: A specific LÂ²-type total loss function is employed without prior knowledge of exact solutions. The PINN training involves forward propagation for gradient/curvature adjustments and backpropagation for hyperparameter refinement. Optimal neural network architectures and hyperparameters are meticulously investigated.

Result: The neural network delivers excellent performance even with limited training data. Simultaneously, FEM accuracy can be substantially enhanced through judicious selection of smaller mesh sizes.

Conclusion: PINNs demonstrate superior approximation capabilities for the challenging EHD problem compared to conventional FEM, offering a promising approach for solving complex nonlinear differential equations in computational mathematics.

Abstract: The accurate representation of numerous physical, chemical, and biological
processes relies heavily on differential equations (DEs), particularly
nonlinear differential equations (NDEs). While understanding these complex
systems necessitates obtaining solutions to their governing equations, the
derivation of precise approximations for NDEs remains a formidable task in
computational mathematics. Although established techniques such as the finite
element method (FEM) have long been foundational, remarkable promise for
approximating continuous functions with high efficacy has recently been
demonstrated by advancements in physics-informed deep-learning feedforward
neural networks. In this work, a novel application of PINNs is presented for
the approximation of the challenging Electrohydrodynamic (EHD) problem. A
specific $L^2$-type \textit{total loss function} is employed, notably without
reliance on any prior knowledge of the exact solution. A comprehensive
comparative study is conducted, juxtaposing the approximation capabilities of
the proposed neural network with those of the conventional FEM. The PINN
training regimen is composed of two critical steps: forward propagation for
adjustments to gradient and curvature, and backpropagation for the refinement
of hyperparameters. The critical challenge of identifying optimal neural
network architectures and hyperparameter configurations for efficient
optimization is meticulously investigated. Excellent performance is shown to be
delivered by the neural network even with a limited training dataset.
Simultaneously, it is demonstrated that the accuracy of the FEM can be
substantially enhanced through the judicious selection of smaller mesh sizes.

</details>


### [9] [High-order mass- and energy-conserving methods for the nonlinear SchrÃ¶dinger equation and its hyperbolization](https://arxiv.org/abs/2510.14335)
*Hendrik Ranocha,David I. Ketcheson*

Main category: math.NA

TL;DR: A class of high-order numerical methods for the nonlinear SchrÃ¶dinger equation that conserves mass and energy, requires only solving one scalar equation per time step, and is more efficient than existing approaches.


<details>
  <summary>Details</summary>
Motivation: To develop efficient and robust numerical methods for the nonlinear SchrÃ¶dinger equation that conserve important physical quantities like mass and energy while achieving high-order accuracy.

Method: New relaxation-type approach for conserving multiple nonlinear functionals, building on existing spatial discretizations like Fourier spectral methods by considering appropriate energy density forms.

Result: The proposed schemes demonstrate high accuracy and efficiency on test problems for both focusing and defocusing NLS equations.

Conclusion: The new relaxation approach provides a more efficient and robust method for conserving multiple invariants in NLS simulations compared to existing multiple-relaxation methods.

Abstract: We propose a class of numerical methods for the nonlinear Schr\"odinger (NLS)
equation that conserves mass and energy, is of arbitrarily high-order accuracy
in space and time, and requires only the solution of a scalar algebraic
equation per time step. We show that some existing spatial discretizations,
including the popular Fourier spectral method, are in fact energy-conserving if
one considers the appropriate form of the energy density. We develop a new
relaxation-type approach for conserving multiple nonlinear functionals that is
more efficient and robust for the NLS equation compared to the existing
multiple-relaxation approach. The accuracy and efficiency of the new schemes is
demonstrated on test problems for both the focusing and defocusing NLS.

</details>


### [10] [Asymptotic-preserving semi-Lagrangian discontinuous Galerkin schemes for the Boltzmann equation](https://arxiv.org/abs/2510.14375)
*Xiaofeng Cai,Zhen Hao,Liu Liu,Jiayu Wan*

Main category: math.NA

TL;DR: An asymptotic-preserving semi-Lagrangian discontinuous Galerkin scheme for the Boltzmann equation that handles multi-scale transport phenomena using IMEX-RK time integration and a novel moments update procedure.


<details>
  <summary>Details</summary>
Motivation: To develop an effective numerical scheme for the Boltzmann equation that can handle multi-scale transport phenomena, particularly addressing the challenge of designing appropriate moments update for penalization within the semi-Lagrangian framework.

Method: Uses semi-Lagrangian discontinuous Galerkin scheme with IMEX-RK time integration, inspired by Shu-Osher form. Key innovation is constructing an appropriate moments update procedure to capture the correct limiting system.

Result: Theoretical analysis establishes accuracy order conditions for both IMEX-RK time integration and moments update. Hypocoercivity techniques prove stability for linearized model. Numerical experiments validate accuracy, asymptotic-preserving property, and robustness across various regimes.

Conclusion: The proposed scheme demonstrates effectiveness for multi-scale kinetic simulations, successfully handling various transport regimes while maintaining accuracy and stability properties.

Abstract: In this work, we present an asymptotic-preserving semi-Lagrangian
discontinuous Galerkin scheme for the Boltzmann equation that effectively
handles multi-scale transport phenomena. The main challenge lies in designing
appropriate moments update for penalization within the semi-Lagrangian
framework. Inspired by [M. Ding, J. M. Qiu, and R. Shu, Multiscale Model.
Simul. 21 (2023), no. 1, 143--167], the key ingredient is utilizing the
Shu-Osher form of the scheme in the implicit-explicit Runge-Kutta (IMEX-RK)
setting, which enables us to capture the correct limiting system by
constructing an appropriate moments update procedure. Our theoretical analysis
establishes accuracy order conditions for both the IMEX-RK time integration and
the new moments update step. We also employ hypocoercivity techniques to
establish stability for the linearized model. Numerical experiments for various
test problems validate our proposed scheme's accuracy, asymptotic-preserving
property, and robustness in various regimes, which demonstrates its
effectiveness for multi-scale kinetic simulations.

</details>


### [11] [Preconditioned Conjugate Gradient methods for the estimation of General Linear Models](https://arxiv.org/abs/2510.14471)
*Paolo Foschi*

Main category: math.NA

TL;DR: PCG method with indefinite preconditioner solves GLS estimator via augmented system, iterating OLS estimations to converge to GLS in finite steps, combining direct and iterative methods for structured GLMs.


<details>
  <summary>Details</summary>
Motivation: To efficiently compute Generalized Least Squares estimator for General Linear Models by combining advantages of direct methods (in OLS step) and iterative methods, particularly for structured problems.

Method: Express GLS estimator as augmented system, solve using Preconditioned Conjugate Gradient method with indefinite preconditioner, iterating sequence of OLS estimations.

Result: Method converges to GLS estimator in finite steps, achieves same precision as state-of-the-art direct methods but significantly faster for structured problems.

Conclusion: PCG with indefinite preconditioner provides efficient framework for GLS estimation, effectively combining direct and iterative approaches for structured GLMs with substantial computational savings.

Abstract: The use of the Preconditioned Conjugate Gradient (PCG) method for computing
the Generalized Least Squares (GLS) estimator of the General Linear Model (GLM)
is considered. The GLS estimator is expressed in terms of the solution of an
augmented system. That system is solved by means of the PCG method using an
indefinite preconditioner. The resulting method iterates a sequence Ordinary
Least Squares (OLS) estimations that converges, in exact precision, to the GLS
estimator within a finite number of steps. The numerical and statistical
properties of the estimator computed at an intermediate step are analytically
and numerically studied. This approach allows to combine direct methods, used
in the OLS step, with those of iterative methods. This advantage is exploited
to design PCG methods for the estimation of Constrained GLMs and of some
structured multivariate GLMs. The structure of the matrices involved are
exploited as much as possible, in the OLS step. The iterative method then
solves for the unexploited structure. Numerical experiments shows that the
proposed methods can achieve, for these structured problems, the same precision
of state of the art direct methods, but in a fraction of the time.

</details>


### [12] [A Well-Balanced Space-Time ALE Compact Gas-Kinetic Scheme for the Shallow Water Equations on Unstructured Meshes](https://arxiv.org/abs/2510.14673)
*Fengxiang Zhao,Jianping Gan,Kun XU*

Main category: math.NA

TL;DR: A high-order space-time coupled arbitrary Lagrangian Eulerian compact gas-kinetic scheme for shallow water equations on moving unstructured meshes that preserves geometric conservation law and well-balanced property without data remapping.


<details>
  <summary>Details</summary>
Motivation: To develop an accurate and efficient method for simulating shallow water flows on moving meshes while preserving fundamental conservation properties and avoiding computationally expensive data remapping.

Method: Uses compact gas-kinetic scheme with space-time coupled formulation, incorporates mesh motion effects in numerical fluxes, establishes evolution equation for bottom topography, employs nonlinear fourth-order compact reconstruction, and provides mathematical proofs for conservation properties.

Result: The scheme achieves second-order temporal accuracy within single stage, preserves geometric conservation law and well-balanced property, and demonstrates accuracy, stability, and effectiveness in complex shallow-water flow simulations.

Conclusion: The proposed ALE compact gas-kinetic scheme provides an effective framework for high-order simulation of shallow water equations on moving meshes with guaranteed conservation properties and computational efficiency.

Abstract: This study presents a high-order, space-time coupled arbitrary Lagrangian
Eulerian (ALE) compact gas-kinetic scheme (GKS) for the shallow water equations
on moving unstructured meshes. The proposed method preserves both the geometric
conservation law (GCL) and the well-balanced property. Mesh motion effects are
directly incorporated by formulating numerical fluxes that account for the
spatial temporal nonuniformity of the flow field and the swept area of moving
cell interfaces. This allows temporal updates to be performed on the physical
moving mesh, avoiding data remapping. The compact GKS provides time accurate
evolution of flow variables and fluxes, enabling the scheme to achieve
second-order temporal accuracy within a single stage. To consistently treat
bottom topography on moving meshes, an evolution equation for the topography is
established and discretized using a compatible space-time scheme, in which the
fluxes induced by mesh motion are computed accurately. Mathematical proofs
demonstrating the GCL preserving and well-balanced properties of the proposed
ALE formulation are also provided. For improved accuracy and robustness, a
nonlinear fourth-order compact reconstruction technique is employed. A
comprehensive set of numerical experiments verifies the scheme's theoretical
properties and demonstrates its accuracy, stability, and effectiveness in
simulating complex shallow-water flow problems.

</details>


### [13] [Generalized Fourier Series: An N log2(N) extension for aperiodic functions that eliminates Gibbs oscillations](https://arxiv.org/abs/2510.14731)
*Narsimha Reddy Rapakaa,Mohamed Kamel Riahi*

Main category: math.NA

TL;DR: GFS is a novel spectral method that extends Fourier series to non-periodic functions by decomposing them into periodic and aperiodic components, avoiding the Gibbs phenomenon and achieving high accuracy without domain extensions.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of classical Fourier series for non-periodic functions, including Gibbs phenomenon and poor convergence, by developing a more efficient spectral method.

Method: Decomposes functions into periodic (standard Fourier modes via FFT) and aperiodic (adaptive low-rank sinusoidal functions with non-harmonic modes) components, dynamically tuned to capture discontinuities.

Result: Achieves high accuracy without computational domain extensions, maintains N log2(N) complexity, and demonstrates high-resolution power comparable to FFT in periodic domains.

Conclusion: GFS provides a robust and efficient framework for high-accuracy function approximations with significant potential for applications in numerical PDEs, signal processing, machine learning, and computational physics.

Abstract: This article introduces the Generalized Fourier Series (GFS), a novel
spectral method that extends the clas- sical Fourier series to non-periodic
functions. GFS addresses key challenges such as the Gibbs phenomenon and poor
convergence in non-periodic settings by decomposing functions into periodic and
aperiodic com- ponents. The periodic part is represented using standard Fourier
modes and efficiently computed via the Fast Fourier Transform (FFT). The
aperiodic component employs adaptive, low-rank sinusoidal functions with
non-harmonic modes, dynamically tuned to capture discontinuities and derivative
jumps across domain boundaries. Unlike conventional Fourier extension methods,
GFS achieves high accuracy without requiring compu- tational domain extensions,
offering a compact and efficient representation of non-periodic functions. The
adaptive low-rank approach ensures accuracy while minimizing computational
overhead, typically involving additional complex modes for the aperiodic part.
Furthermore, GFS demonstrates a high-resolution power, with degrees of freedom
comparable to FFT in periodic domains, and maintains N log2(N) computational
complexity. The effectiveness of GFS is validated through numerical
experiments, showcasing its ability to approximate functions and their
derivatives in non-periodic domains accurately. With its robust framework and
minimal computational cost, GFS holds significant potential for advancing
applications in numerical PDEs, signal processing, machine learning, and
computational physics by providing a robust and efficient tool for
high-accuracy function approximations.

</details>


### [14] [On the convergence of stochastic variance reduced gradient for linear inverse problems](https://arxiv.org/abs/2510.14759)
*Bangti Jin,Zehui Zhou*

Main category: math.NA

TL;DR: Analysis of SVRG and regularized SVRG for linear inverse problems in Hilbert spaces, proving optimal convergence rates with constant step sizes.


<details>
  <summary>Details</summary>
Motivation: SVRG is promising for large-scale inverse problems but needs analysis for linear inverse problems in Hilbert spaces with optimal convergence guarantees.

Method: Analyze SVRG and regularized SVRG using constant step size schedules, error recursion analysis, and prior estimates on inner loop updates.

Result: Regularized SVRG achieves optimal convergence rates without early stopping; standard SVRG is optimal for nonsmooth solutions with a priori stopping.

Conclusion: Both SVRG variants achieve optimal convergence for linear inverse problems under suitable conditions, with numerical validation.

Abstract: Stochastic variance reduced gradient (SVRG) is an accelerated version of
stochastic gradient descent based on variance reduction, and is promising for
solving large-scale inverse problems. In this work, we analyze SVRG and a
regularized version that incorporates a priori knowledge of the problem, for
solving linear inverse problems in Hilbert spaces. We prove that, with suitable
constant step size schedules and regularity conditions, the regularized SVRG
can achieve optimal convergence rates in terms of the noise level without any
early stopping rules, and standard SVRG is also optimal for problems with
nonsmooth solutions under a priori stopping rules. The analysis is based on an
explicit error recursion and suitable prior estimates on the inner loop updates
with respect to the anchor point. Numerical experiments are provided to
complement the theoretical analysis.

</details>


### [15] [Ghost stabilisation for cut finite element exterior calculus](https://arxiv.org/abs/2510.14772)
*Daniele Di Pietro,JÃ©rÃ´me Droniou,Erik Nilsson*

Main category: math.NA

TL;DR: The paper introduces a Cut Finite Element Exterior Calculus (CutFEEC) method with stabilization for any form degree, making it robust to interface position relative to the mesh. The method discretizes Hodge Laplace equations on unfitted meshes with uniform norm equivalence and demonstrated on H^curl spaces.


<details>
  <summary>Details</summary>
Motivation: To develop a finite element method that is robust with respect to interface position relative to the mesh, enabling discretization of Hodge Laplace equations on unfitted meshes in any dimension and topology.

Method: Cut finite element method formulated in finite element exterior calculus language with stabilization for any form degree. The L^2-norm on physical domain is augmented with stabilization to achieve uniform equivalence with L^2-norm on the active mesh containing all degrees of freedom.

Result: Proved uniform equivalence of norms and demonstrated the method on H^curl finite element space posed on a filled torus. Achieved convergence and condition number scaling independent of boundary position relative to background mesh.

Conclusion: The CutFEEC method provides a robust approach for discretizing Hodge Laplace equations on unfitted meshes, with stabilization ensuring performance independent of interface position relative to the mesh.

Abstract: We introduce the cut finite element method in the language of finite element
exterior calculus, by formulating a stabilisation -- for any form degree --
that makes the method robust with respect to the position of the interface
relative to the mesh. We prove that the $L^2$-norm on the physical domain
augmented with this stabilisation is uniformly equivalent to the $L^2$-norm on
the ``active'' mesh that contains all the degrees of freedom of the finite
element space (including those external to the physical domain). We show how
this CutFEEC method can be applied to discretize the Hodge Laplace equations on
an unfitted mesh, in any dimension and any topology. A numerical illustration
is provided involving a conforming finite element space of $H^{\text{curl}}$
posed on a filled torus, with convergence and condition number scaling
independent of the position of the boundary with respect to the background
mesh.

</details>


### [16] [Error analysis of Abate--Whitt methods for Inverse Laplace Transforms and a new algorithm for queuing theory applications](https://arxiv.org/abs/2510.14799)
*Nikita Deniskin,Federico Poloni*

Main category: math.NA

TL;DR: The paper analyzes Abate-Whitt methods for Inverse Laplace Transform computation, develops error bounds, and introduces TAME - a new family of methods using AAA algorithm for rational approximation that requires fewer function evaluations.


<details>
  <summary>Details</summary>
Motivation: To improve the accuracy and efficiency of Inverse Laplace Transform computation methods, particularly for queuing theory applications where Abate-Whitt methods are commonly used but may require many function evaluations.

Method: Developed TAME methods using AAA algorithm for rational approximation, with parameters constructed based on function-specific domains and quasi-optimal choices for certain function families. Analyzed numerical issues in floating-point computation.

Result: The new TAME methods require significantly fewer function evaluations while achieving comparable or better accuracy than classical methods, as validated through numerical experiments.

Conclusion: TAME methods provide an efficient alternative to classical Abate-Whitt methods for Inverse Laplace Transform computation, with improved performance in terms of required function evaluations while maintaining accuracy.

Abstract: We study the accuracy of a class of methods to compute the Inverse Laplace
Transform, the so-called \emph{Abate--Whitt methods} [Abate, Whitt 2006], which
are based on a linear combination of evaluations of $\widehat{f}$ in a few
points. We provide error bounds which relate the accuracy of a method to the
rational approximation of the exponential function. We specialize our analysis
to applications in queuing theory, a field in which Abate--Whitt methods are
often used; in particular, we study phase-type distributions and
Markov-modulated fluid models (or \emph{fluid queues}).
  We use a recently developed algorithm for rational approximation, the AAA
algorithm [Nakatsukasa, S\`ete, Trefethen 2018], to produce a new family of
methods, which we call TAME. The parameters of these methods are constructed
depending on a function-specific domain $\Omega$; we provide a quasi-optimal
choice for certain families of functions. We discuss numerical issues related
to floating-point computation, and we validate our results through numerical
experiments which show that the new methods require significantly fewer
function evaluations to achieve an accuracy that is comparable (or better) to
that of the classical methods.

</details>


### [17] [Augmented Lagrangian Method based adjoint space framework for sparse reconstruction of acoustic source with boundary measurements](https://arxiv.org/abs/2510.14805)
*Nirui Tan,Hongpeng Sun*

Main category: math.NA

TL;DR: A semismooth Newton-based augmented Lagrangian method for efficient reconstruction of sparse sources in inverse acoustic scattering problems, leveraging measurement space iteration and Fenchel-Rockafellar duality.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient method for reconstructing sparse sources in inverse acoustic scattering problems, particularly when measurement data is much less than the acoustic source.

Method: Semismooth Newton-based augmented Lagrangian method that iterates in measurement space rather than source space, combined with Fenchel-Rockafellar duality theory for source calculation.

Result: The method achieves significant acceleration and computational cost reduction, with numerical examples demonstrating high efficiency.

Conclusion: The proposed semismooth Newton-based approach is highly efficient for sparse source reconstruction in inverse acoustic scattering problems.

Abstract: We propose a semismooth Newton-based augmented Lagrangian method for
reconstructing sparse sources in inverse acoustic scattering problems. The
semismooth Newton method can be iterated in the space of measurements instead
of the unknown source to be reconstructed. It is highly efficient, especially
when the measurement data is much less than the acoustic source. The source can
be calculated from Fenchel-Rockafellar duality theory. We can obtain lots of
acceleration and leverage the computational cost. The numerical examples show
the high efficiency of the proposed semismooth Newton-based methods.

</details>


### [18] [Polynomial Preconditioning for Indefinite Matrices](https://arxiv.org/abs/2510.14816)
*Hayden Henson,Ronald B. Morgan*

Main category: math.NA

TL;DR: Polynomial preconditioning methods for indefinite matrices, including balancing for definite spectra, stability approaches for indefinite cases, and convergence estimates for real indefinite spectra.


<details>
  <summary>Details</summary>
Motivation: To make polynomial preconditioning more generally applicable for solving large linear systems and eigenvalue problems with indefinite matrices.

Method: Developed techniques including polynomial balancing to produce definite spectra, specialized stability approaches for indefinite cases, and convergence analysis for real indefinite spectra.

Result: The methods enable effective polynomial preconditioning for indefinite matrices and complex spectra, with successful tests on finding interior eigenvalues.

Conclusion: The proposed techniques significantly extend the applicability of polynomial preconditioning to indefinite matrices and complex spectral problems.

Abstract: Polynomial preconditioning is an important tool in solving large linear
systems and eigenvalue problems. A polynomial from GMRES can be used to
precondition restarted GMRES and restarted Arnoldi. Here we give methods for
indefinite matrices that make polynomial preconditioning more generally
applicable. The new techniques include balancing the polynomial so that it
produces a definite spectrum. Then a stability approach is given that is
specialized for the indefinite case. Also, very complex spectra are examined.
Then convergence estimates are given for polynomial preconditioning of real,
indefinite spectra. Finally, tests are preformed of finding interior
eigenvalues.

</details>


### [19] [Efficient and Robust CarathÃ©odory-Steinitz Pruning of Positive Discrete Measures](https://arxiv.org/abs/2510.14916)
*Filip BÄlÃ­k,Jesse Chan,Akil Narayan*

Main category: math.NA

TL;DR: An efficient streaming algorithm for CarathÃ©odory-Steinitz pruning that compresses positive discrete measures while preserving moments over finite-dimensional function spaces, using Givens rotations and on-demand storage.


<details>
  <summary>Details</summary>
Motivation: To create more efficient positive quadrature rules by reducing the number of nodes while preserving moment properties, addressing the quadratic runtime and linear storage issues of naive implementations.

Method: Uses Givens rotations and on-demand storage to implement CarathÃ©odory-Steinitz pruning in a streaming fashion, with storage complexity depending only on the function space dimension rather than the original measure size.

Result: Achieves comparable runtimes to non-negative least squares and linear programming approaches, but with improved stability, storage robustness, and mathematical stability properties against perturbations.

Conclusion: The proposed streaming algorithm provides an efficient and stable method for measure compression that enables practical applications like generating quadrature for discontinuous Galerkin finite element simulations on cut-cell meshes.

Abstract: In many applications, one seeks to approximate integration against a positive
measure of interest by a positive discrete measure: a numerical quadrature rule
with positive weights. One common desired discretization property is moment
preservation over a finite dimensional function space, e.g., bounded-degree
polynomials. Carath\'{e}odory's theorem asserts that if there is any finitely
supported quadrature rule with more nodes than the dimension of the given
function space, one can form a smaller (and hence more efficient) positive,
nested, quadrature rule that preserves the moments of the original rule.
  We describe an efficient streaming procedure for Carath\'{e}odory-Steinitz
pruning, a numerical procedure that implements Carath\'{e}odory's theorem for
this measure compression. The new algorithm makes use of Givens rotations and
on-demand storage of arrays to successfully prune very large rules whose
storage complexity only depends on the dimension of the function space. This
approach improves on a naive implementation of Carath\'{e}odory-Steinitz
pruning whose runtime and storage complexity are quadratic and linear,
respectively, in the size of the original measure. We additionally prove
mathematical stability properties of our method with respect to a set of
admissible, total-variation perturbations of the original measure. Our method
is compared to two alternate approaches with larger storage requirements:
non-negative least squares and linear programming, and we demonstrate
comparable runtimes, with improved stability and storage robustness. Finally,
we demonstrate practical usage of this algorithm to generate quadrature for
discontinous Galerkin finite element simulations on cut-cell meshes.

</details>


### [20] [Rank of Matrices Arising out of Singular Kernel Functions](https://arxiv.org/abs/2510.14920)
*Sumit Singh,Sivaram Ambikasaran*

Main category: math.NA

TL;DR: This paper analyzes the rank of kernel matrices for arbitrarily distributed particles in adjacent hypercubes, providing theoretical bounds on expected rank and variance for various neighbor interactions.


<details>
  <summary>Details</summary>
Motivation: Kernel functions are widely used in differential equations and machine learning, but the rank behavior of kernel matrices for arbitrary particle distributions was not formally studied, which is important for hierarchical matrix algorithms.

Method: Model arbitrary particle distributions as random distributions, analyze rank bounds theoretically for different neighbor interactions, and validate with numerical experiments in 1D, 2D, and 3D.

Result: Obtained theoretical bounds on expected rank and variance of kernel matrices, with numerical experiments confirming these predictions across different dimensions and interaction types.

Conclusion: The work provides the first formal analysis of kernel matrix rank for arbitrary particle distributions, offering useful bounds for hierarchical matrix algorithms and showing alignment between theory and numerical results.

Abstract: Kernel functions are frequently encountered in differential equations and
machine learning applications. In this work, we study the rank of matrices
arising out of the kernel function $K: X \times Y \mapsto \mathbb{R}$, where
the sets $X, Y \in \mathbb{R}^d$ are hypercubes that share a boundary. The main
contribution of this work is the analysis of the rank of such matrices where
the particles (sources/targets) are arbitrarily distributed within these
hypercubes. To our knowledge, this is the first work to formally investigate
the rank of such matrices for an arbitrary distribution of particles. We model
the arbitrary distribution of particles to arise from an underlying random
distribution and obtain bounds on the expected rank and variance of the rank of
the kernel matrix corresponding to various neighbor interactions. These bounds
are useful for understanding the performance and complexity of hierarchical
matrix algorithms (especially hierarchical matrices satisfying the
weak-admissibility criterion) for an arbitrary distribution of particles. We
also present numerical experiments in one-, two-, and three-dimensions, showing
the expected rank growth and variance of the rank for different types of
interactions. The numerical results, not surprisingly, align with our
theoretical predictions.

</details>


### [21] [Finite element methods for electroneutral multicomponent electrolyte flows](https://arxiv.org/abs/2510.14923)
*Aaron Baier-Reinio,Patrick E. Farrell,Charles W. Monroe*

Main category: math.NA

TL;DR: A family of high-order finite element algorithms for simulating electroneutral electrolyte flows using NSOSM equations, handling complex boundary conditions and non-ideal thermodynamics.


<details>
  <summary>Details</summary>
Motivation: To develop flexible numerical methods for simulating electrolyte flows that can handle various physical configurations, boundary conditions, and non-ideal thermodynamic behavior in electrochemical systems.

Method: High-order finite element algorithms solving electroneutral Navier-Stokes-Onsager-Stefan-Maxwell equations for momentum transport, multicomponent diffusion and electrical effects in electrolytes.

Result: Algorithms successfully demonstrated in various configurations including microfluidic rotating disk electrode and Hull cell flow of cosolvent electrolyte mixtures for lithium-ion batteries.

Conclusion: The developed algorithms provide a flexible framework for simulating complex electrolyte flows with solution-dependent material parameters and various boundary conditions in electrochemical applications.

Abstract: We present a broad family of high-order finite element algorithms for
simulating the flow of electroneutral electrolytes. The governing partial
differential equations that we solve are the electroneutral
Navier-Stokes-Onsager-Stefan-Maxwell (NSOSM) equations, which model momentum
transport, multicomponent diffusion and electrical effects within the
electrolyte. Our algorithms can be applied in the steady and transient
settings, in two and three spatial dimensions, and under a variety of boundary
conditions. Moreover, we allow for the material parameters (e.g. viscosity,
diffusivities, thermodynamic factors and density) to be solution-dependent and
thermodynamically non-ideal. The flexibility of our approach requires us to
address subtleties that arise in the governing equations due to the interplay
between boundary conditions and the equation of state. We demonstrate the
algorithms in various physical configurations, including (i) electrolyte flow
around a microfluidic rotating disk electrode and (ii) the flow in a Hull cell
of a cosolvent electrolyte mixture used in lithium-ion batteries.

</details>


### [22] [Efficient and Flexible Multirate Temporal Adaptivity](https://arxiv.org/abs/2510.14964)
*Daniel R. Reynolds,Sylvia Amihere,Dashon Mitchell,Vu Thai Luan*

Main category: math.NA

TL;DR: New multirate time step controllers for embedded MRI methods that improve performance and flexibility in adaptive simulations of multi-scale problems, including first fifth-order embedded MRI method.


<details>
  <summary>Details</summary>
Motivation: To develop effective time step adaptivity controllers for multirate infinitesimal (MRI) methods that can handle problems with multiple time scales while maintaining computational efficiency.

Method: Proposed two new families of multirate time step adaptivity controllers designed for embedded MRI methods, and introduced new embeddings for explicit multirate exponential Runge-Kutta (MERK) methods of orders 2-5.

Result: The controllers offer dramatically improved performance and flexibility compared to competing approaches, with each controller family excelling on different multirate applications. Achieved high accuracy with low computational cost for problems with arbitrary number of time scales.

Conclusion: The combination of embedded MRI methods with the proposed controllers enables effective adaptive simulations of multi-scale problems, and the study provides guidance for selecting appropriate MRI methods and controllers.

Abstract: In this work we present two new families of multirate time step adaptivity
controllers, that are designed to work with embedded multirate infinitesimal
(MRI) time integration methods for adapting time steps when solving problems
with multiple time scales. We compare these controllers against competing
approaches on two benchmark problems and see that they offer dramatically
improved performance and flexibility, with each proposed family excelling on
different types of multirate applications. The combination of embedded MRI
methods and the proposed controllers enable adaptive simulations of problems
with a potentially arbitrary number of time scales, achieving high accuracy
while maintaining low computational cost. Additionally, we introduce a new set
of embeddings for the family of explicit multirate exponential Runge--Kutta
(MERK) methods of orders 2 through 5, resulting in the first-ever fifth-order
embedded MRI method. Finally, we compare the performance of a wide range of
embedded MRI methods on our benchmark problems to provide guidance on how to
select an appropriate MRI method and multirate controller.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [23] [Time-harmonic scattering of plane waves from an infinite periodically inhomogeneous medium](https://arxiv.org/abs/2510.14070)
*Guanghui Hu,Andreas Rathsfeld,Jiayi Zhang,Ruming Zhang*

Main category: math.AP

TL;DR: A new radiation condition for 2D infinite inhomogeneous media periodic in vertical direction, using Floquet theory to define wave modes and Dirichlet-to-Neumann maps for domain truncation, with proven ellipticity and unique solvability.


<details>
  <summary>Details</summary>
Motivation: The classical Rayleigh-expansion radiation condition doesn't apply to vertically periodic media, requiring a new approach for infinite inhomogeneous domains that are periodic in one direction.

Method: Utilize Floquet theory to derive upward/downward wave modes, define radiation conditions via mode expansions, develop Dirichlet-to-Neumann maps for domain truncation, and analyze mapping properties based on high-order wave mode asymptotics.

Result: Successfully defined new radiation conditions and downward Dirichlet-to-Neumann map for vertical domain truncation, proved strong ellipticity of the sesquilinear form, and established unique solvability for all wavenumbers except a countable set bounded below by a small positive constant.

Conclusion: The proposed radiation condition and associated mathematical framework provide a valid approach for analyzing wave propagation in infinite inhomogeneous media with vertical periodicity, with guaranteed solvability for most practical wavenumbers.

Abstract: We propose a new radiation condition for an infinite inhomogeneous
two-dimensional medium which is periodic in the vertical direction and remains
invariant in the horizontal direction. The classical Rayleigh-expansion
radiation condition does not apply to our case, because this would require the
medium to be inhomogeneous in a half plane. We utilize the Floquet theory to
derive upward/downward wave modes and define radiation conditions by expansions
w.r.t. these modes. The downward radiation conditions leads to a downward
Dirichlet-to-Neumann map which can be used to truncate the infinite
inhomogeneous domain in the vertical direction. So we prove mapping properties
of the upward/downward Dirichlet-to-Neumann maps based on the asymptotic
behavior of high-order wave modes. Finally, we verify the strong ellipticity of
the sesquilinear form corresponding to the new scattering problem and show the
unique solvability for all wavenumbers with the exception of a countable set of
numbers bounded below by a small positive constant.

</details>


### [24] [Exponential and algebraic decay in Euler--alignment system with nonlocal interaction forces](https://arxiv.org/abs/2510.14123)
*JosÃ© A. Carrillo,Young-Pil Choi,Dowan Koo,Oliver Tse*

Main category: math.AP

TL;DR: Study of pressureless Euler system with nonlocal alignment and interaction forces, showing convergence rates depend on communication weights: bounded kernels yield exponential decay, weakly singular ones give algebraic rates.


<details>
  <summary>Details</summary>
Motivation: To characterize asymptotic convergence of classical solutions under general interaction potentials and communication weights, providing comprehensive understanding of Euler-alignment dynamics.

Method: Analyze large-time behavior through quantitative convergence analysis in three settings: 1D with (Î»,Î)-convex potentials, Coulomb-quadratic potential, and multi-dimensional uniformly convex potentials.

Result: Density converges to minimizer of interaction energy (up to translation), velocity aligns to uniform constant. Bounded communication weights yield exponential decay, weakly singular ones give sharp algebraic rates.

Conclusion: Convergence rate depends only on local behavior of communication weights, providing unified framework for understanding asymptotic behavior of Euler-alignment dynamics with general potentials.

Abstract: We investigate the large-time behavior of the pressureless Euler system with
nonlocal velocity alignment and interaction forces, with the aim of
characterizing the asymptotic convergence of classical solutions under general
interaction potentials $W$ and communication weights. We establish quantitative
convergence in three settings. In one dimension with $(\lambda,\Lambda)$-convex
potentials, i.e., potentials satisfying uniform lower and upper quadratic
bounds, bounded communication weights yield exponential decay, while weakly
singular ones lead to sharp algebraic rates. For the Coulomb--quadratic
potential $W(x)=-|x|+\frac12 |x|^2$, we prove exponential convergence for
bounded communication weights and algebraic upper bounds for singular
communication weights. In a multi-dimensional setting with uniformly
$(\lambda,\Lambda)$-convex potentials, we show exponential decay for bounded
weights and improved algebraic decay for singular ones. In all cases, the
density converges (up to translation) to the minimizer of the interaction
energy, while the velocity aligns to a uniform constant. A unifying feature is
that the convergence rate depends only on the local behavior of communication
weights: bounded kernels yield exponential convergence, while weakly singular
ones produce algebraic rates. Our results thus provide a comprehensive
description of the asymptotic behavior of Euler--alignment dynamics with
general interaction potentials.

</details>


### [25] [Reconstruction of the non-linear wave at a buoy from shoreline data and applications to the tsunami inverse problem for piece-wise sloping bathymetry](https://arxiv.org/abs/2510.14177)
*Oleksandr Bobrovnikov,Madison Jones,Shriya Prasanna,Josiah Smith,Alexei Rybkin,Efim Pelinovsky*

Main category: math.AP

TL;DR: This paper studies the inverse problem of recovering tsunami initial shape from run-up data using shallow water equations, extending previous work to finite sloping bathymetry and incorporating dispersion effects.


<details>
  <summary>Details</summary>
Motivation: To solve the inverse problem of determining tsunami initial conditions from shoreline run-up data, extending previous infinite slope results to more realistic finite slope scenarios.

Method: Uses non-linear shallow water equations framework, extends to finite sloping bathymetry, recovers boundary conditions from shoreline data, and incorporates dispersion by stitching shallow water equations with Boussinesq equation.

Result: Shows that boundary conditions (water displacement and velocity) on a virtual buoy can be recovered from shoreline data in finite sloping bathymetry.

Conclusion: The approach enables recovery of tsunami initial conditions from run-up data in complex bathymetry while accounting for dispersion effects.

Abstract: We discuss the following inverse problem: given the run-up data of a tsunami
wave, can we recover its initial shape? We study this problem within the
framework of the non-linear shallow water equations, a model widely used to
study tsunami propagation and inundation. Previously, it has been demonstrated
that in the case of infinite sloping bathymetry, it is possible to recover the
initial water displacement and velocity from shoreline readings
\cite{Rybkin23,Rybkin24,Rybkin25}.
  We consider a finite sloping bathymerty. We show that it is possible to
recover boundary conditions (water displacement and velocity) on a virtual buoy
from the shoreline data. Further, we discuss stitching together the shallow
water equations and the Boussinesq equation in a more complex piece-wise
sloping bathymetry in order to recover the initial conditions, while
incorporating the dispersion to our model.

</details>


### [26] [Propagation speed of traveling waves for diffusive Lotka-Volterra system with strong competition](https://arxiv.org/abs/2510.14311)
*Ken-Ichi Nakamura,Toshiko Ogiwara*

Main category: math.AP

TL;DR: This paper analyzes bistable traveling waves in a two-component diffusive Lotka-Volterra system under strong competition, focusing on how propagation speed determines competition outcomes between species.


<details>
  <summary>Details</summary>
Motivation: The sign of propagation speed determines long-term competition outcomes between species, which is crucial for predicting invasion success or failure of alien species in native habitats.

Method: Using comparison arguments to establish sufficient conditions determining the sign of propagation speed in the diffusive Lotka-Volterra system.

Result: In symmetric cases, the faster diffuser prevails over a broader parameter range than previously known. When interspecific competition coefficients differ significantly, competition outcomes cannot be reversed by adjusting diffusion or growth rates.

Conclusion: The findings provide a rigorous theoretical framework with sharper mathematical criteria for analyzing invasion dynamics and predicting invasion success or failure.

Abstract: We study the propagation speed of bistable traveling waves in the classical
two-component diffusive Lotka-Volterra system under strong competition. From an
ecological perspective, the sign of the propagation speed determines the
long-term outcome of competition between two species and thus plays a central
role in predicting the success or failure of invasion of an alien species into
habitats occupied by a native species. Using comparison arguments, we establish
sufficient conditions determining the sign of the propagation speed, which
refine previously known results. In particular, we show that in the symmetric
case, where the two species differ only in their diffusion rates, the faster
diffuser prevails over a substantially broader parameter range than previously
established. Moreover, we demonstrate that when the interspecific competition
coefficients differ significantly, the outcome of competition cannot be
reversed by adjusting diffusion or growth rates. These findings provide a
rigorous theoretical framework for analyzing invasion dynamics, offering
sharper mathematical criteria for invasion success or failure.

</details>


### [27] [Sobolev regularity for the perturbed fractional 1-Laplace equations in the subquadratic case](https://arxiv.org/abs/2510.14346)
*Dingding Li,Chao Zhang*

Main category: math.AP

TL;DR: This paper establishes Sobolev regularity for solutions to perturbed fractional 1-Laplace equations, showing that bounded weak solutions have regularity properties similar to the superquadratic case, with different regularity regimes depending on parameter thresholds.


<details>
  <summary>Details</summary>
Motivation: To understand the regularity properties of solutions to perturbed fractional 1-Laplace equations, which are nonlocal and singular problems, and to extend regularity theory to these challenging cases.

Method: Uses nonlocal finite-difference quotient method combined with Moser-type iteration scheme to systematically analyze regularity for nonlocal singular problems.

Result: For s_p in (0, (p-1)/p] and qâ¥p, solutions have W_loc^{Î³,q}-regularity for all Î³ in (0, s_p p/(p-1)); for s_p in ((p-1)/p, 1) and qâ¥p, solutions have W_loc^{1,q}-regularity.

Conclusion: The regularity theory for perturbed fractional 1-Laplace equations follows patterns similar to the superquadratic case, with a clear threshold at (p-1)/p dividing different regularity regimes.

Abstract: This work investigates the Sobolev regularity of solutions to perturbed
fractional 1-Laplace equations. Under the assumption that weak solutions are
locally bounded, we establish that the regularity properties are analogous to
those observed in the superquadratic case. By introducing the threshold
$\frac{p-1}{p}$, we divide the range of the parameter $s_p$ into two distinct
scenarios. Specifically, for any $s_p\in \left(0, \frac{p-1}{p}\right]$ and
$q\ge p$, we demonstrate that the solutions possess $W_{\rm loc}^{\gamma,
q}$-regularity for all $\gamma\in \left(0, \frac{s_p p}{p-1}\right)$ and the
$W_{\rm loc}^{1, q}$-regularity for any $s_p\in \left(\frac{p-1}{p}, 1\right)$
and $q\ge p$, respectively. Our analysis relies on the nonlocal
finite-difference quotient method combined with a Moser-type iteration scheme,
which provides a systematic approach to the regularity theory for such nonlocal
and singular problems.

</details>


### [28] [Viscosity solutions posed on star-shaped network with Kirchhoff's boundary condition: Well-posedness](https://arxiv.org/abs/2510.14364)
*Isaac Ohavi*

Main category: math.AP

TL;DR: Establishes well-posedness for fully nonlinear PDEs on star-shaped networks with nonlinear Kirchhoff boundary conditions, including degenerate cases. Proves comparison theorem for discontinuous viscosity solutions and shows equivalence between generalized and standard Kirchhoff viscosity solutions.


<details>
  <summary>Details</summary>
Motivation: To address the mathematical analysis of fully nonlinear PDEs on network structures with nonlinear Kirchhoff boundary conditions at vertices, particularly handling degenerate cases and establishing rigorous solution frameworks.

Method: Uses comparison theorem for discontinuous viscosity solutions, building test functions at vertices that solve Eikonal equations with carefully designed coefficients. Extends ideas from Ohavi's work on second order problems.

Result: Proves that any generalized Kirchhoff viscosity solution (Lions-Souganidis type) is equivalent to a standard Kirchhoff viscosity solution, eliminating the need to evaluate Hamiltonians at vertices in PDE analysis.

Conclusion: Provides a complete well-posedness theory for fully nonlinear PDEs on star-shaped networks with nonlinear Kirchhoff boundary conditions, establishing equivalence between solution concepts and enabling analysis without vertex Hamiltonian evaluations.

Abstract: The aim of this work is to establish the well-posedness of fully nonlinear
partial differential equations (PDE) posed on a star-shaped network, having
nonlinear Kirchhoff's boundary condition at the vertex, and possibly
degenerate. We obtain a comparison theorem, for discontinuous viscosity
solutions, following the recent ideas obtained by Ohavi for second order
problems, building test functions at the vertex solutions of Eikonal equations
with well-designed coefficients. Another strong result obtained in this
contribution is to show that any generalized Kirchhoff's viscosity solution
introduced by Lions-Souganidis, is indeed a Kirchhoff's viscosity solution. In
other terms, the values of the Hamiltonians are not required at the vertex in
the analysis of these types of PDE systems.

</details>


### [29] [Parabolic PDEs on a fixed domain with evolving subdomains: function spaces and well-posedness](https://arxiv.org/abs/2510.14373)
*Van Chien Le,Karel Van Bockstal*

Main category: math.AP

TL;DR: Develops variational framework for parabolic PDEs with evolving subdomains, introducing specialized function spaces for discontinuous coefficients and proving well-posedness.


<details>
  <summary>Details</summary>
Motivation: To handle initial boundary-value problems for parabolic PDEs on domains with evolving subdomains, where standard Sobolev-Bochner spaces are insufficient due to discontinuous coefficients across moving interfaces.

Method: Introduces extended function spaces for variational solutions, proves density of smooth functions using mollification and Reynolds transport theorem, establishes embedding theory and integration by parts formula, and applies Banach-Necas-Babuska theorem.

Result: Successfully develops the complete mathematical framework including function spaces, density results, embedding theory, and proves well-posedness of the space-time variational formulation.

Conclusion: Provides rigorous mathematical foundation for variational analysis of parabolic PDEs with evolving interfaces, enabling treatment of problems with discontinuous coefficients across moving boundaries.

Abstract: This paper develops the necessary ingredients for the variational approach of
initial boundary-value problems of parabolic partial differential equations on
a fixed spatial domain containing evolving subdomains. In particular, we
introduce function spaces for the variational solution that extend standard
Sobolev-Bochner spaces to account for a coefficient associated with the time
derivative that may be discontinuous across the evolving interface. We further
show the density of smooth functions in these spaces by extending the
mollification technique and the Reynolds transport theorem, and establish the
corresponding "embedding" theory and an integration by parts formula. Finally,
we prove the well-posedness of the space-time variational formulation in the
natural setting using the Banach-Necas-Babuska theorem.

</details>


### [30] [Quantitative stability of a class of explicit steady Euler flows in a disk](https://arxiv.org/abs/2510.14394)
*Fatao Wang,Guodong Wang*

Main category: math.AP

TL;DR: Short proof of LÂ²-orbital stability for explicit steady Euler flows in a disk using conserved quantities.


<details>
  <summary>Details</summary>
Motivation: To establish orbital stability of steady Euler flows and understand how radial symmetry affects stability.

Method: Exploit conserved quantities of Euler equation: kinetic energy, enstrophy, and moment of fluid impulse to derive quantitative estimate.

Result: Proved LÂ²-orbital stability for a class of explicit steady Euler flows in a disk.

Conclusion: More radial symmetry appears to lead to stronger instability in Euler flows.

Abstract: We provide a short proof of the $L^2$-orbital stability of a class of
explicit steady Euler flows in a disk by establishing a quantitative estimate.
The main idea is to exploit the conserved quantities of the Euler equation,
including the kinetic energy, the enstrophy, and the moment of fluid impulse.
Our result seems to suggest that more radial symmetry leads to stronger
instability.

</details>


### [31] [On some Elliptic and Parabolic Problems Involving the Anisotropic $p(u)$-Laplacian](https://arxiv.org/abs/2510.14432)
*Kaushik Bal,Shilpa Gupta*

Main category: math.AP

TL;DR: Study of elliptic and parabolic PDEs with p(u) Laplacian using variable exponent Sobolev spaces in anisotropic framework.


<details>
  <summary>Details</summary>
Motivation: To address PDEs with p(u) Laplacian that require specialized variable exponent Sobolev spaces for anisotropic analysis.

Method: Elliptic case: pseudomonotone operators with approximation techniques. Parabolic case: time discretization scheme, Schauder fixed-point theorem, a priori estimates, and compactness arguments.

Result: Established existence of weak solutions for both elliptic and parabolic PDEs with p(u) Laplacian.

Conclusion: Successfully proved existence of weak solutions for anisotropic elliptic and parabolic PDEs with p(u) Laplacian using specialized functional analysis methods.

Abstract: We investigate a class of elliptic and parabolic partial differential
equations driven by p(u) laplacian. This dependence necessitates the use of
variable exponent Sobolev spaces specifically tailored to the anisotropic
framework. For the elliptic case, we establish the existence of a weak solution
by employing the theory of pseudomonotone operators in conjunction with
suitable approximation techniques. In the parabolic setting, the existence of a
weak solution is obtained via a time discretization scheme and Schauder
fixed-point theorem, supported by a priori estimates and compactness arguments.

</details>


### [32] [Small-time approximate controllability of the logarithmic Schr\''dinger equation](https://arxiv.org/abs/2510.14461)
*Karine Beauchard,RÃ©mi Carles,Eugenio Pozzoli*

Main category: math.AP

TL;DR: The paper proves small-time global LÂ²-approximate controllability for SchrÃ¶dinger equations with logarithmic nonlinearity and bilinear controls on both periodic and Euclidean domains.


<details>
  <summary>Details</summary>
Motivation: To establish the first result of small-time global approximate controllability for nonlinear SchrÃ¶dinger equations using bilinear controls, extending previous linear control theory to nonlinear frameworks.

Method: Extends the approach from linear control theory by combining small-time controllability of phases and gradient flows, using WKB analysis to handle the nonlinearity and establish required estimates.

Result: Successfully proves small-time global LÂ²-approximate controllability for SchrÃ¶dinger equations with logarithmic nonlinearity and bilinear controls on both ð^d and â^d domains.

Conclusion: This represents the first achievement of small-time global approximate controllability for nonlinear SchrÃ¶dinger equations with bilinear controls, overcoming the challenges posed by nonlinearity through WKB-inspired analysis.

Abstract: We consider Schr{\"o}dinger equations with logarithmic nonlinearity and
bilinear controls, posed on $\mathbb{T}^d$ or $\mathbb{R}^d$. We prove their
small-time global $L^2$-approximate controllability. The proof consists in
extending to this nonlinear framework the approach introduced by the first and
third authors in \cite{beauchard-pozzoli2} to control the linear equation: it
combines the small-time controllability of phases and gradient flows. Due to
the nonlinearity, the required estimates are more difficult to establish than
in the linear case. The proof here is inspired by WKB analysis. This is the
first result of (small-time) global approximate controllability, for nonlinear
Schr{\"o}dinger equations, with bilinear controls.

</details>


### [33] [An $L^\infty$-variational problem involving the Fractional Laplacian](https://arxiv.org/abs/2510.14476)
*Simone Carano,Roger Moser*

Main category: math.AP

TL;DR: Existence and uniqueness of absolute minimizers for the supremal functional involving the fractional Laplacian, with prescribed Dirichlet data outside the domain.


<details>
  <summary>Details</summary>
Motivation: To study the existence and uniqueness of minimizers for the supremal functional E_â(u) = â¥(-Î)^s uâ¥_{L^â(â^n)} involving the fractional Laplacian, which extends classical â-Laplacian theory to fractional order operators.

Method: Proving existence and uniqueness of absolute minimizers for the supremal functional with prescribed Dirichlet boundary conditions in the complement of Î©, and analyzing the resulting fractional PDE satisfied by the minimizer.

Result: Existence and uniqueness of absolute minimizers u_â are established. The minimizer satisfies the fractional PDE (-Î)^s u_â = E_â(u_â) sgn f_â in Î©, where f_â is an analytic function obtained from an s-harmonic measure Î¼ in Î©.

Conclusion: The paper successfully extends â-Laplacian theory to the fractional setting, proving existence, uniqueness, and characterizing the minimizer through a fractional PDE involving s-harmonic measures.

Abstract: For $s\in(0,1)$ and an open bounded set $\Omega\subset\mathbb R^n$, we prove
existence and uniqueness of absolute minimisers of the supremal functional
$$E_\infty(u)=\|(-\Delta)^s u\|_{L^\infty(\mathbb R^n)},$$ where $(-\Delta)^s$
is the Fractional Laplacian of order $s$ and $u$ has prescribed Dirichlet data
in the complement of $\Omega$. We further show that the minimiser $u_\infty$
satisfies the (fractional) PDE $$ (-\Delta)^s
u_\infty=E_\infty(u_\infty)\,\mathrm{sgn}f_\infty \qquad\mbox{in }\Omega, $$
for some analytic function $f_\infty\in L^1(\Omega)$ obtained as the
restriction of an $s$-harmonic measure $\mu$ in $\Omega$.

</details>


### [34] [Maxwell's equations with mixed impedance boundary conditions](https://arxiv.org/abs/2510.14600)
*Ben Schweizer,David Wiedemann*

Main category: math.AP

TL;DR: Fredholm alternative and existence of weak solutions for time-harmonic Maxwell equations with matrix-valued impedance boundary conditions on Lipschitz domains.


<details>
  <summary>Details</summary>
Motivation: To analyze Maxwell equations with general impedance boundary conditions, including matrix-valued coefficients that model polarization-dependent impedance, and handle singular cases.

Method: Studied time-harmonic Maxwell equations on bounded Lipschitz domains with impedance boundary conditions, derived Fredholm alternative theory.

Result: Established Fredholm alternative for the system and proved existence of weak solutions for arbitrary sources when frequency is not a resonance frequency.

Conclusion: Successfully extended analysis to cover singular impedance coefficients and provided existence results for weak solutions under non-resonant conditions.

Abstract: We study the time-harmonic Maxwell equations on bounded Lipschitz domains
with an impedance boundary condition. The impedance coefficient can be matrix
valued such that, in particular, a polarization dependent impedance is modeled.
We derive a Fredholm alternative for this system. As a consequence, we obtain
the existence of weak solutions for arbitrary sources when the frequency is not
a resonance frequency. Our analysis covers the case of singular impedance
coefficients.

</details>


### [35] [Unique continuation and stabilization for nonlinear SchrÃ¶dinger equations under the Geometric Control Condition](https://arxiv.org/abs/2510.14632)
*CristÃ³bal Loyola*

Main category: math.AP

TL;DR: Global propagation of analyticity for semilinear SchrÃ¶dinger equations with analytic nonlinearity from regions satisfying Geometric Control Condition, leading to unique continuation, control, and stabilization results.


<details>
  <summary>Details</summary>
Motivation: To address the propagation of analyticity in semilinear SchrÃ¶dinger equations and solve an open question from Dehman, GÃ©rard, and Lebeau (2006) regarding unique continuation in the nonlinear case.

Method: Refines a technique combining control theory and Galerkin approximation to propagate analyticity from zones where observability holds, using Geometric Control Condition on observation zones.

Result: Obtained unique continuation for subcritical semilinear SchrÃ¶dinger equations on compact manifolds of dimensions 2 and 3, and achieved semiglobal control and stabilization under Geometric Control Condition.

Conclusion: The approach successfully propagates analyticity and provides affirmative answers to open questions in nonlinear semilinear SchrÃ¶dinger equations, with applications in control and stabilization theory.

Abstract: In this article we prove global propagation of analyticity in finite time for
solutions of semilinear Schr\"odinger equations with analytic nonlinearity from
a region $\omega$ where the Geometric Control Condition holds. Our approach
refines a recent technique introduced by Laurent and the author, which combines
control theory techniques and Galerkin approximation, to propagate analyticity
in time from a zone where observability holds. As a main consequence, we obtain
unique continuation for subcritical semilinear Schr\"odinger equations on
compact manifolds of dimension $2$ and $3$ when the solution is assumed to
vanish on $\omega$. Furthermore, semiglobal control and stabilization follow
only under the Geometric Control Condition on the observation zone. In
particular, this answers in the affirmative an open question of Dehman,
G\'erard, and Lebeau from $2006$ for the nonlinear case.

</details>


### [36] [The simultaneous effect of chemotaxis and alarm-taxis on the global existence and stability of a predator-prey system](https://arxiv.org/abs/2510.14728)
*Gnanasekaran Shanmugasundaram,Jitraj Saha,Rafael DÃ­az Fuentes*

Main category: math.AP

TL;DR: Analysis of a fully parabolic predator-prey chemo-alarm-taxis system showing global bounded solutions and convergence via Lyapunov functional, with numerical validation.


<details>
  <summary>Details</summary>
Motivation: To understand the role of chemotaxis and alarm-taxis coefficients in predator-prey models and establish existence and stability conditions.

Method: Mathematical analysis using Lyapunov functional construction and numerical simulations under homogeneous Neumann boundary conditions.

Result: The system admits unique, globally bounded classical solutions under specific parameter conditions, with convergence established.

Conclusion: Chemotaxis and alarm-taxis coefficients play significant roles in determining existence and stability of predator-prey models.

Abstract: This study examines a fully parabolic predator-prey chemo-alarm-taxis system
under homogeneous Neumann boundary conditions in a bounded domain $\Omega
\subset \mathbb{R}^n$ with a smooth boundary $\partial\Omega$. Under specific
parameter conditions, it is shown that the system admits a unique, globally
bounded classical solution. The convergence of the solution is established
through the construction of an appropriate Lyapunov functional. In addition,
numerical simulations are presented to validate the asymptotic behaviour of the
solution. The results highlight the significant role of chemotaxis and
alarm-taxis coefficients in determining the existence and stability of
predator-prey models, as discussed in the literature.

</details>


### [37] [Stable Type I blow-up for the one-dimensional wave equation with time-derivative nonlinearity](https://arxiv.org/abs/2510.14815)
*Oliver Gough*

Main category: math.AP

TL;DR: The paper studies blow-up behavior in a 1D nonlinear wave equation with quadratic time-derivative nonlinearity, showing no smooth exact self-similar blow-up profiles exist but constructing generalized self-similar solutions that exhibit type-I blow-up.


<details>
  <summary>Details</summary>
Motivation: To understand finite-time blow-up phenomena in nonlinear wave equations with time-derivative nonlinearities, building on previous work on spatial-derivative analogues.

Method: Construct explicit family of generalized self-similar solutions bifurcating from ODE blow-up, prove their asymptotic stability under small perturbations in energy topology.

Result: Non-existence of smooth exact self-similar blow-up profiles, construction of generalized self-similar solutions with type-I blow-up at prescribed points, asymptotic stability of these profiles.

Conclusion: The generalized self-similar profiles demonstrate that spatially homogeneous ODE blow-up is not asymptotically stable, providing new insights into blow-up dynamics in wave equations with time-derivative nonlinearities.

Abstract: We study finite-time blow-up for the one-dimensional nonlinear wave equation
with a quadratic time-derivative nonlinearity, \[ u_{tt}-u_{xx}=(u_t)^2,\qquad
(x,t)\in\mathbb R\times[0,T). \] Building on the work of Ghoul, Liu, and
Masmoudi \cite{ghoul2025blow} on the spatial-derivative analogue, we establish
the non-existence of smooth, exact self-similar blow-up profiles. Instead we
construct an explicit family of \emph{generalised self-similar} solutions,
bifurcating from the ODE blow-up, that are smooth within the past light cone
and exhibit type-I blow-up at a prescribed point \((x_0,T)\). We further prove
asymptotic stability of these profiles under small perturbations in the energy
topology. In particular, these profiles verify that the spatially homogeneous
ODE blow-up is not asymptotically stable.

</details>


### [38] [Vortex lines interaction in the three-dimensional magnetic Ginzburg--Landau model](https://arxiv.org/abs/2510.14910)
*Carlos RomÃ¡n,Etienne Sandier,Sylvia Serfaty*

Main category: math.AP

TL;DR: The paper studies the 3D Ginzburg-Landau functional with magnetic field near the first critical field H_c1, showing vortex filaments appear one by one as magnetic field increases, with transitions occurring at increments of order log|logÎµ|.


<details>
  <summary>Details</summary>
Motivation: To understand the detailed behavior of vortex filaments in superconductors near the first critical field H_c1, particularly how they appear and arrange themselves as the magnetic field intensity increases.

Method: Asymptotic analysis of the 3D Ginzburg-Landau functional with magnetic field in the limit of small inverse Ginzburg-Landau parameter Îµ, using nondegeneracy conditions and deriving a next order energy functional for vortex lines after horizontal blow-up around a special curve Î0.

Result: Shows a next order asymptotic expansion of H_c1 as Îµâ0, reveals sequential appearance of vortex lines one by one with field increments of order log|logÎµ|, and derives an energy functional where line length penalization, logarithmic repulsion, and magnetic confinement compete.

Conclusion: The analysis elucidates the shape and arrangement of vortex lines in superconductors, showing they accumulate near a special curve Î0 and their configuration is determined by a competition between length minimization, repulsion, and confinement effects.

Abstract: We complete our study of the three dimensional Ginzburg--Landau functional
with magnetic field, in the asymptotic regime of a small inverse
Ginzburg--Landau parameter $\varepsilon$, and near the first critical field
$H_{c_1}$ for which the first vortex filaments appear in energy minimizers.
Under a nondegeneracy condition, we show a next order asymptotic expansion of
$H_{c_1}$ as $\varepsilon \to 0$, and exhibit a sequence of transitions, with
vortex lines appearing one by one as the intensity of the applied magnetic
field is increased: passing $H_{c_1}$ there is one vortex, then increasing
$H_{c_1}$ by an increment of order $\log |\log\varepsilon|$ a second vortex
line appears, etc. These vortex lines accumulate near a special curve
$\Gamma_0$, solution to an isoflux problem. We derive a next order energy that
the vortex lines must minimize in the asymptotic limit, after a suitable
horizontal blow-up around $\Gamma_0$. This energy is the sum of terms where
penalizations of the length of the lines, logarithmic repulsion between the
lines and magnetic confinement near $\Gamma_0$ compete. This elucidates the
shape of vortex lines in superconductors.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [39] [Surrogate Models for Linear Response](https://arxiv.org/abs/2510.13989)
*L. Jin,A. RavliÄ,P. Giuliani,K. Godbey,W. Nazarewicz*

Main category: physics.comp-ph

TL;DR: The paper presents two QRPA surrogate models for nuclear response functions that achieve 0.1%-1% accuracy with 6-7 orders of magnitude speedup over traditional QRPA solvers.


<details>
  <summary>Details</summary>
Motivation: Traditional QRPA methods have high computational costs that limit model calibration and uncertainty quantification studies in nuclear physics.

Method: Two complementary QRPA surrogate models: one reduced-order model exploiting QRPA structure, and another using parametric matrix model algorithm to map Hamiltonian to observables.

Result: Benchmark applications show both emulators achieve 0.1%-1% accuracy for electric dipole polarizability of 180Yb and Î²-decay half-life of 80Ni, with 6-7 orders of magnitude speedup.

Conclusion: The developed QRPA emulators enable Bayesian calibration and large-scale studies of computationally expensive many-body physics models.

Abstract: Linear response theory is a well-established method in physics and chemistry
for exploring excitations of many-body systems. In particular, the
quasiparticle random-phase approximation (QRPA) provides a powerful microscopic
framework by building excitations on top of the mean-field vacuum; however, its
high computational cost limits model calibration and uncertainty quantification
studies. Here, we present two complementary QRPA surrogate models and apply
them to study response functions of finite nuclei. One is a reduced-order model
that exploits the underlying QRPA structure, while the other utilizes the
recently developed parametric matrix model algorithm to construct a map between
the system's Hamiltonian and observables. Our benchmark applications, the
calculation of the electric dipole polarizability of ${}^{180}$Yb and the
$\beta$-decay half-life of ${}^{80}$Ni, show that both emulators can achieve
0.1\%--1\% accuracy while offering a six to seven orders of magnitude speedup
compared to state-of-the-art QRPA solvers. These results demonstrate that the
developed QRPA emulators are well-positioned to enable Bayesian calibration and
large-scale studies of computationally expensive physics models describing the
properties of many-body systems.

</details>


### [40] [Anti-Interference Communication Using Computational Antenna](https://arxiv.org/abs/2510.14362)
*Xiaocun Zong,Fan Yang,Shenheng Xu,Maokun Li*

Main category: physics.comp-ph

TL;DR: A novel anti-interference communication method using computational antennas with time averaging and 1-bit RIS for robust signal modulation with minimal hardware complexity.


<details>
  <summary>Details</summary>
Motivation: To achieve superior anti-interference performance without additional spectral overhead, unlike conventional techniques like spread spectrum or frequency hopping that require significant spectral resources.

Method: Developed a communication model for computational antennas and proposed an efficient signal processing algorithm optimized for temporal modulation. Established a USRP-based experimental platform for validation under strong interference conditions.

Result: Experimental results show up to 80.9% reduction in bit error rate (BER) and effective restoration of distorted images in transmission tests under 5 dB jamming-to-signal ratio conditions.

Conclusion: This research provides valuable insights for radar detection, military communications, and next-generation wireless networks by offering robust anti-interference capability with minimal hardware complexity.

Abstract: This letter proposes a novel anti-interference communication method
leveraging computational antennas, utilizing time averaging and 1-bit
reconfigurable intelligent surfaces (RIS) to achieve robust signal modulation
with minimal hardware complexity. We develop a communication model for
computational antennas and propose an efficient signal processing algorithm
optimized for temporal modulation. A USRP-based experimental platform is
established to validate the approach under strong interference conditions
(e.g., 5 dB jamming-to-signal ratio). Experimental results reveal up to an
80.9\% reduction in bit error rate (BER) and effective restoration of distorted
images in transmission tests. Compared to conventional techniques like spread
spectrum or frequency hopping, which require significant spectral resources,
our method offers superior anti-interference performance without additional
spectral overhead. This research provides valuable insights for radar
detection, military communications, and next-generation wireless networks.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [41] [Structure of self-generated magnetic fields in laser-solid interaction from proton tomography](https://arxiv.org/abs/2510.14076)
*Jesse Griff-McMahon,Christopher A. Walsh,Vicente Valenzuela-Villaseca,Sophia Malko,Brendan McCluskey,Kirill Lezhnin,Huws Landsberger,Laura Berzak Hopkins,Gennady Fiksel,Michael J. Rosenberg,Derek B. Schaeffer,William Fox*

Main category: physics.plasm-ph

TL;DR: Experimental characterization of 3D magnetic fields in laser-solid interactions using multi-view proton radiography and tomographic inversion, showing fields that extend millimeters into plasma corona and validate improved MHD simulations.


<details>
  <summary>Details</summary>
Motivation: To experimentally characterize the 3D location and strength of self-generated magnetic fields in laser-solid interactions, rather than relying on path-integrated measurements, and to validate improved magnetic transport models.

Method: Used multi-view proton radiography and tomographic inversion on the OMEGA laser system to infer 3D magnetic field structures, then compared results with MHD simulations incorporating magnetic field re-localization of transport.

Result: Inferred magnetic fields extend several millimeters off the target surface into the hot corona and are strong enough to strongly magnetize the plasma. Achieved reasonable agreement only with MHD models that include re-localization of transport by magnetic fields.

Conclusion: Successfully demonstrated tomographic inversion in proton radiography as a valuable tool for investigating magnetic fields in laser-produced plasmas, providing key validation for improved magnetic transport modeling in MHD simulations.

Abstract: Strong magnetic fields are naturally self-generated in high-power,
laser-solid interactions through the Biermann-battery mechanism. This work
experimentally characterizes the 3D location and strength of these fields,
rather than path-integrated quantities, through multi-view proton radiography
and tomographic inversion on the OMEGA laser. We infer magnetic fields that
extend several millimeters off the target surface into the hot, rarefied corona
and are sufficient to strongly magnetize the plasma ($\Omega_{e}\tau_e \gg 1$).
The data is used to validate MHD simulations incorporating recent improvements
in magnetic transport modeling; we achieve reasonable agreement only with
models with re-localization of transport by magnetic fields. This work provides
a key demonstration of tomographic inversion in proton radiography, offering a
valuable tool for investigating magnetic fields in laser-produced plasmas.

</details>


### [42] [Plasma Confinement State Classification via FPP Relevant Microwave Diagnostics](https://arxiv.org/abs/2510.14078)
*Randall Clark,Vacslav Glukhov,Georgy Subbotin,Maxim Nurgaliev,Aleksandr Kachkin,Max Austin,Dmitri M. Orlov*

Main category: physics.plasm-ph

TL;DR: A minimalist machine learning approach using only electron cyclotron emission (ECE) signals achieves 96% accuracy in identifying plasma confinement states (L-mode vs H-mode) for fusion power plants.


<details>
  <summary>Details</summary>
Motivation: Fusion power plants require reliable identification of confinement states for safe operation but have severely constrained diagnostic capabilities compared to research devices.

Method: Uses ECE signals as input, extracts features with radial basis functions, and applies a gradient boosting classifier for state classification.

Result: Achieves 96% test accuracy in confinement state classification, with robustness analysis confirming reliability.

Conclusion: State-of-the-art performance is achievable with restricted diagnostic sets, enabling minimalist yet resilient plasma control architectures for fusion power plants.

Abstract: We present a parsimonious and robust machine learning approach for
identifying plasma confinement states in fusion power plants (FPPs) where
reliable identification of the low-confinement (L-mode) and high-confinement
(H-mode) regimes is critical for safe and efficient operation. Unlike
research-oriented devices, FPPs must operate with a severely constrained set of
diagnostics. To address this challenge, we demonstrate that a minimalist model,
using only electron cyclotron emission (ECE) signals, can deliver accurate and
reliable state classification. ECE provides electron temperature profiles
without the engineering or survivability issues of in-vessel probes, making it
a primary candidate for FPP-relevant diagnostics. Our framework employs ECE as
input, extracts features with radial basis functions, and applies a gradient
boosting classifier, achieving high accuracy with test accuracy averaging 96\%
correct predictions. Robustness analysis and feature importance study confirm
the reliability of the approach. These results demonstrate that
state-of-the-art performance is attainable from a restricted diagnostic set,
paving the way for minimalist yet resilient plasma control architectures for
FPPs.

</details>


### [43] [Three-dimensional unmagnetized Mach probe analysis and initial flow measurements in reversed-field pinch experiments](https://arxiv.org/abs/2510.14212)
*K. J. McCollam,R. Reksoatmodjo,J. von der Linden,J. Sears,S. You,H. Himura,A. F. Almagri,M. Reyfman,C. C. Rouda,J. S. Sarff,A. M. Sellner*

Main category: physics.plasm-ph

TL;DR: A novel matrix method was developed to analyze ion saturation current data from 3D Mach probe arrays, enabling initial plasma flow velocity measurements in reversed-field pinch experiments on MST.


<details>
  <summary>Details</summary>
Motivation: To develop a more sophisticated method for analyzing plasma flow velocity using 3D Mach probe arrays in fusion plasma experiments, improving upon previous measurement techniques.

Method: Developed a matrix method for analyzing ion saturation current data from two types of 3D Mach probe arrays: a six-tip octahedral array and a four-tip tetrahedral array, with uncertainty analysis based on probe machining and measurement errors.

Result: Initial measurements showed flow speeds of expected magnitudes but with some directional differences for the octahedral probe, while the tetrahedral probe showed similar flow directions but larger than expected speeds compared to previous measurements.

Conclusion: The matrix method successfully enabled 3D Mach probe analysis, though initial results revealed some unexpected findings that may be attributed to probe conditioning and fast electron effects, requiring further investigation.

Abstract: A novel matrix method of analyzing ion saturation current data from a general
three-dimensional (3D) array of unmagnetized Mach probe tips is developed and
used with data sets from two 3D Mach probes to make initial measurements of
local plasma flow velocity in reversed-field pinch (RFP) experiments in the
Madison Symmetric Torus (MST). The two 3D Mach probes are composed of regular
polyhedral arrays of six and four tips, respectively, with the six-tip array
composed of three orthogonal pairs of mutually opposite tips at the vertices of
a regular octahedron and the four-tip array composed of non-opposite tips at
the vertices of a regular tetrahedron, the analysis of which is specifically
facilitated by the matrix method. Velocity measurement uncertainties for the
Mach probes are derived based on uncertainties in probe machining and ion
saturation current measurements, and typical relative uncertainties for the
probes are estimated to be of order several percent, likely smaller than
systematic uncertainties related to the Mach probe calibration constant and
experimental uncertainties related to plasma and probe conditioning. Initial
results for the octahedral probe show flow speeds of roughly the expected
magnitudes based on previous MST measurements but with somes differences in
flow direction, while those for the tetrahedron probe show similar flow
directions to some previous measurements but also some larger than expected
speeds. We consider possible causes for the unexpected results of these initial
tests, with a focus on probe conditioning and fast electron issues.

</details>


### [44] [Kinetic Scale Energy Budget in Turbulent Plasmas: Role of Electron to Ion Temperature Ratio](https://arxiv.org/abs/2510.14258)
*Subash Adhikari,M. Hasan Barbhuiya*

Main category: physics.plasm-ph

TL;DR: The paper investigates scale-by-scale energy transfer in kinetic plasma turbulence using scale-filtered Vlasov-Maxwell equations, focusing on pressure-strain interaction components and their dependence on ion-electron temperature ratios.


<details>
  <summary>Details</summary>
Motivation: To understand the influence of ion-electron thermal disequilibrium on kinetic-scale energy budget in weakly collisional plasmas, which remains poorly understood despite recent progress in dissipation mechanisms.

Method: Two-dimensional fully kinetic particle-in-cell simulations of decaying plasma turbulence with varying electron-to-ion temperature ratios, analyzing scale-filtered pressure-strain interaction and its components (normal and shear Pi-D, pressure dilatation).

Result: Scale-filtered pressure-strain interaction is dominated by Pi-D across kinetic scales, with shear component being dominant. Normal and shear Pi-D contributions show persistent anticorrelation. Anisotropic components scale with species temperature and inversely with other species' temperature. Pressure dilatation is negligible but shows enhanced compressibility at lower temperatures.

Conclusion: The findings have implications for thermally non-equilibrated plasmas in turbulent magnetosheath and solar wind, revealing systematic temperature-dependent scaling of energy transfer components in kinetic-scale turbulence.

Abstract: The dissipation mechanisms in weakly collisional plasmas have been a
longstanding topic of investigation, where significant progress has been made
in recent years. A recent promising development is the use of the
"scale-filtered" Vlasov-Maxwell equations to fully quantify the scale-by-scale
energy balance, a feature that was absent when using fluid models in kinetic
plasmas. In particular, this method reveals that the energy transfer in kinetic
scales is fully accounted for by the scale-filtered pressure-strain
interaction. Despite this progress, the influence of ion-electron thermal
disequilibrium on the kinetic-scale energy budget remains poorly understood.
Using two-dimensional fully kinetic particle-in-cell simulations of decaying
plasma turbulence, we systematically investigate the pressure-strain
interaction and its components at sub-ion scales by varying electron-to-ion
temperature ratios. Our analysis focuses on three key ingredients of the
pressure-strain interaction: the normal and shear components of Pi-D and
pressure dilatation. Our results demonstrate that the scale-filtered
pressure-strain interaction is dominated by scale-filtered Pi-D across the
kinetic range, with the shear component consistently providing the dominant
contribution. We find that the scale-filtered normal and shear contributions of
Pi-D exhibit persistent anticorrelation and opposite signs across all kinetic
scales. We also discover that the amplitude of both anisotropic components for
each species scales directly with their temperature and inversely with the
temperature of the other species, while the scale-filtered pressure dilatation
remains negligible compared to the Pi-D terms but shows enhanced
compressibility effects as plasma temperatures decrease. We discuss the
implications of these findings in thermally non-equilibrated plasmas, such as
in the turbulent magnetosheath and solar wind.

</details>


### [45] [Flux Jamming, Phase Transitions and Layering in Turbulent Magnetized Plasma](https://arxiv.org/abs/2510.14280)
*P. H. Diamond,Y. Kosuga,P. L. Guillon,Ã. D. GÃ¼rcan*

Main category: physics.plasm-ph

TL;DR: The paper analyzes transport barrier formation and layering through jam formation analogies with traffic flow theory, explaining flux jamming's relation to motility induced phase separation and identifying two routes to heat flux jamming.


<details>
  <summary>Details</summary>
Motivation: To understand transport barrier formation and layering phenomena by drawing analogies with traffic flow theory and explaining the mechanisms behind flux jamming in various physical systems.

Method: Uses analogies with one-dimensional traffic flow theory, analyzes heat flux-pulse size relations, examines delay time effects, and studies turbulence spreading in relation to jam formation.

Result: Identified two routes to heat flux jamming: one from rollover in heat flux-pulse size relation (similar to flux-gradient bistability) and another from critical delay time between pulse and heat flux. Showed staircase development follows jamiton train formation and demonstrated formation of outward propagating blob trains and inward propagating void trains.

Conclusion: Transport barrier formation and layering result from jam formation mechanisms, with turbulence spreading playing a crucial role. The analysis provides insights into how near 'near marginality' is and connects jamming phenomena to phase transitions in drift wave-zonal flow turbulence.

Abstract: This paper discusses transport barrier formation and layering as consequences
of jam formation. Extensive use is made of analogies with the theory of traffic
flow in one dimension. The relation of flux jamming to motility induced phase
separation (MIPS) is explained. Two routes to heat flux jamming are identified.
The first is due to a rollover in the heat flux-pulse size relation, i.e.
$dQ_T(\delta T)/d\delta T<0$, and is similar to the condition of flux-gradient
bistability. The second occurs when the delay time between pulse and heat flux
exceeds a critical value. This does not require bistability and tends to occur
near marginality. This analysis yields an estimate of the answer to the eternal
question of 'how near is "near"?'. Staircase development is shown to follow
jamiton train formation. The relation of jamming of avalanches to phase
transitions in drift wave-zonal flow turbulence is elucidated. The formation of
outward propagating blob trains and inward propagating void trains is
demonstrated. The important role of turbulence spreading is identified.

</details>


### [46] [Dust-ion-acoustic solitons in an ion-beam-driven dusty magnetoplasma with adiabatic and nonadiabatic dust charge variations](https://arxiv.org/abs/2510.14324)
*N. P. Acharya,S. Basnet,A. P. Misra,R. Khanal*

Main category: physics.plasm-ph

TL;DR: Study of dust-ion-acoustic solitary waves in magnetized dusty plasmas with positive-ion beams, analyzing effects of dust charge variations, collisions, and magnetic fields on wave characteristics.


<details>
  <summary>Details</summary>
Motivation: To understand how positive-ion beams and various plasma parameters affect dust-ion-acoustic solitary waves in magnetized dusty plasmas, particularly focusing on dust charge variations and collision effects.

Method: Using the standard reductive perturbation technique to derive Korteweg-de Vries (KdV) equations for two cases: nonadiabatic and adiabatic dust charge variations, and analyzing effects of ion beam, magnetic field, ion creation, and collisions.

Result: Soliton energy decays with time and is affected by beam velocity. Solitary waves get damped by ion creation, ion loss, collision-enhanced current, and dust charge variation. Ion beam causes transition from rarefactive to compressive solitary waves in nonadiabatic case.

Conclusion: Positive-ion beam streaming significantly affects dust-charging process and wave characteristics, with different behaviors observed for adiabatic vs nonadiabatic dust charge variations, leading to damping and polarity transitions in solitary waves.

Abstract: We study the characteristics of small-amplitude nonlinear dust-ion-acoustic
(DIA) solitary waves in active magnetized positive-ion-beam-driven dusty
plasmas with the effects of nonadiabatic and adiabatic dust charge variations.
In the model, we consider the ion-neutral collision and thereby consider the
collision enhanced ion current to the dust-charging process and dust charge
fluctuations. We show that the streaming of the positive-ion beam significantly
affects the dust-charging process in which the dust charge number decreases
(increases) with an increased beam velocity (number density). Using the
standard reductive perturbation technique, we derive the evolution equations in
the form of Korteweg-de Vries (KdV) equations for DIA solitary waves for two
different cases: nonadiabatic and adiabatic dust charge variations. We study
the effect of positive ion beam, dust charge variation, magnetic field, ion
creation, and ion-neutral collision enhanced current on the wave
characteristics. We find that the soliton energy decays with time and is
affected by the beam velocity. Also, the solitary waves get damped by the
effects of ion creation, ion loss, ion-neutral collision enhanced current, and
dust charge variation. Although the ion beam does not change the polarity of
solitary waves in the case of adiabatic dust charge variation, a transition
from rarefactive to compressive solitary waves occurs in the presence of an ion
beam with nonadiabatic dust charge variation.

</details>


### [47] [Linear damping of magneto-acoustic waves in two-fluid partially ionized plasmas](https://arxiv.org/abs/2510.14575)
*David MartÃ­nez-GÃ³mez*

Main category: physics.plasm-ph

TL;DR: Study of magneto-acoustic wave damping in partially ionized plasmas using a two-fluid model, focusing on how collisional interactions affect wave properties across different ionization degrees and propagation angles.


<details>
  <summary>Details</summary>
Motivation: To understand how elastic collisions between charged and neutral particles damp magneto-acoustic waves in partially ionized plasmas, which is relevant for various astrophysical and laboratory plasma environments.

Method: Used a linearized two-fluid model to analyze small-amplitude waves in uniform static background, studied wave properties dependence on ionization degree, collisional coupling strength, and propagation angle, derived analytical approximations for damping rates.

Result: Identified relationships between different wave modes (fast, slow, acoustic) and individual fluid properties across various physical conditions, validated analytical approximations for damping rates in weak and strong coupling limits against numerical results.

Conclusion: The analytical approximations for damping rates due to charge-neutral collisions are generally applicable to various partially ionized plasmas, with specific discussion of hydrogen-only plasmas, providing useful tools for studying wave behavior in astrophysical and laboratory contexts.

Abstract: Magneto-acoustic waves in partially ionized plasmas are damped due to elastic
collisions between charged and neutral particles. Here, we use a linearized
two-fluid model to describe the influence of this collisional interaction on
the properties of small-amplitude waves propagating in a uniform and static
background. Mainly focusing on the case of waves generated by a periodic
driver, we perform a detailed study of the dependence of the wavenumbers and
damping rates on the ionization degree of the plasma, the strength of the
collisional coupling, and the angle of propagation. We describe how the
different wave modes (fast, slow, acoustic) are related to the individual
properties of each fluid in a wide range of physical conditions. In addition,
we derive analytical approximations for the damping rates due to charge-neutral
collisions in the limits of weak and strong coupling and check their range of
validity in comparison with the exact numerical results. These approximations
can be generally applied to a large variety of astrophysical and laboratory
partially ionized plasmas, but here we also discuss the particular application
to plasmas only composed of hydrogen.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [48] [Multi-Period Sparse Optimization for Proactive Grid Blackout Diagnosis](https://arxiv.org/abs/2510.14045)
*Qinghua Ma,Reetam Sen Biswas,Denis Osipov,Guannan Qu,Soummya Kar,Shimiao Li*

Main category: eess.SY

TL;DR: Proposes a multi-period sparse optimization method to identify persistent failure sources across multiple system collapse scenarios under increasing stress conditions in power grids.


<details>
  <summary>Details</summary>
Motivation: Existing power grids need to evaluate survivability under extreme events like peak load overloading that can cause blackouts. Early warning diagnosis of key vulnerabilities can significantly enhance grid resilience.

Method: Uses multi-period sparse optimization with persistency constraints to capture evolving vulnerabilities. Employs circuit-theory based power flow formulations and circuit-inspired optimization heuristics for scalability.

Result: Method reliably tracks persistent vulnerability locations under increasing load stress and scales to large systems (average 200 seconds per scenario on 2000+ bus systems).

Conclusion: The proposed approach effectively identifies persistent failure sources across multiple collapse scenarios, providing valuable early warning diagnosis for power grid resilience enhancement.

Abstract: Existing or planned power grids need to evaluate survivability under extreme
events, like a number of peak load overloading conditions, which could possibly
cause system collapses (i.e. blackouts). For realistic extreme events that are
correlated or share similar patterns, it is reasonable to expect that the
dominant vulnerability or failure sources behind them share the same locations
but with different severity. Early warning diagnosis that proactively
identifies the key vulnerabilities responsible for a number of system collapses
of interest can significantly enhance resilience. This paper proposes a
multi-period sparse optimization method, enabling the discovery of {persistent
failure sources} across a sequence of collapsed systems with increasing system
stress, such as rising demand or worsening contingencies. This work defines
persistency and efficiently integrates persistency constraints to capture the
``hidden'' evolving vulnerabilities. Circuit-theory based power flow
formulations and circuit-inspired optimization heuristics are used to
facilitate the scalability of the method. Experiments on benchmark systems show
that the method reliably tracks persistent vulnerability locations under
increasing load stress, and solves with scalability to large systems ({on
average} taking {around} 200 s per scenario on 2000+ bus systems).

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [49] [Diameter bounds in 3d Type I Ricci flows](https://arxiv.org/abs/2510.14019)
*Panagiotis Gianniotis*

Main category: math.DG

TL;DR: The paper proves that 3D compact Ricci flows with Type I singularities have uniformly bounded diameter up to the singular time, confirming Perelman's conjecture for Type I cases.


<details>
  <summary>Details</summary>
Motivation: To address Perelman's conjecture about diameter bounds in Ricci flows encountering singularities, specifically focusing on Type I singularities.

Method: Introduces a concept of neck-regions for Ricci flows (analogous to those in Ricci limit spaces) and proves that the associated packing measure is Ahlfors regular, with results applicable in any dimension.

Result: Successfully proves that three-dimensional compact Ricci flows with Type I singularities maintain uniformly bounded diameter up to the singular time.

Conclusion: Provides affirmative confirmation of Perelman's conjecture for Type I singularities in Ricci flows, establishing important geometric control near singularities.

Abstract: We prove that a three dimensional compact Ricci flow that encounters a Type I
singularity has uniformly bounded diameter up to the singular time, thus giving
an affirmative answer - for Type I singularities - to a conjecture of Perelman.
To achieve this, we introduce a concept of a neck-region for a Ricci flow,
analogous to the neck-regions introduced by Jiang-Naber and
Cheeger-Jiang-Naber, in the study of Ricci limit spaces. We then prove that the
associated packing measure is, in a certain sense, Ahlfors regular, a result
that holds in any dimension.

</details>


### [50] [Families of surfaces with constant ratio of principal curvatures and Plateau's problem](https://arxiv.org/abs/2510.14527)
*Mikhail Skopenkov,Khusrav Yorov*

Main category: math.DG

TL;DR: Construction of surfaces with constant ratio of principal curvatures (CRPC) using minimal surfaces as starting point, with applications to Plateau's problem and isotropic geometry.


<details>
  <summary>Details</summary>
Motivation: CRPC surfaces generalize minimal surfaces but are more difficult to construct. The work aims to develop methods for building such surfaces and solving related geometric problems.

Method: Proposes construction of CRPC surfaces containing given minimal surfaces, uses method of successive approximations and analytic majorization, and applies isotropic geometry approach.

Result: Obtains partial solution to Plateau's problem for CRPC surfaces and analogous results in isotropic geometry.

Conclusion: Demonstrates general approach of solving Euclidean geometric problems by first addressing their isotropic analogs, providing new construction methods for CRPC surfaces.

Abstract: This work is on surfaces with a constant ratio of principal curvatures. These
CRPC surfaces generalize minimal surfaces but are much more challenging to
construct. We propose a construction of a family of such surfaces containing a
given minimal surface without flat points. This leads to a partial solution of
Plateau's problem for CRPC surfaces. We obtain analogous results in isotropic
geometry. This work illustrates a general approach to solving Euclidean
problems by starting with their isotropic analogs. Besides, we apply the method
of successive approximations and analytic majorization.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [51] [Resonate-and-Fire Photonic-Electronic Spiking Neurons for Fast and Efficient Light-Enabled Neuromorphic Processing Systems](https://arxiv.org/abs/2510.14515)
*Andrew Adair,Dafydd Owen-Newns,Giovanni Donati,Joshua Robertson,JosÃ© Figueiredo,Eduard Wasige,Qusay Al-Taai,Bruno Romeira,MatÄj Hejda,Antonio Hurtado*

Main category: physics.optics

TL;DR: A photonic-electronic resonate-and-fire spiking neuron that responds to temporal patterns of optical inputs, enabling ultrafast, energy-efficient neuromorphic computing with temporal information processing capabilities.


<details>
  <summary>Details</summary>
Motivation: Existing photonic neurons mainly mimic simple integrate-and-fire models, but biological neurons use richer temporal encoding mechanisms. Photonic approaches promise ultrafast, energy-efficient operation with low crosstalk and high bandwidth for neuromorphic computing.

Method: Developed a light-sensitive resonant tunnelling diode-based neuron that produces excitable spikes in response to nanosecond, low-power optical signals. Demonstrated control through inter-pulse timing and bias voltage, supporting wavelength-division multiplexed inputs from multiple VCSELs.

Result: Achieved bandpass filtering of analogue and digital inputs, spike-frequency filtering, temporal pattern recognition, and digital-to-spiking conversion. The neuron responds to 100 microwatt optical signals at infrared telecom wavelengths.

Conclusion: This approach establishes a pathway toward low-power, high-speed temporal information processing for light-enabled neuromorphic computing, addressing limitations of existing photonic neurons by incorporating richer temporal encoding mechanisms.

Abstract: Neuromorphic computing seeks to replicate the spiking dynamics of biological
neurons for brain-inspired computation. While electronic implementations of
artificial spiking neurons have dominated to date, photonic approaches are
attracting increasing research interest as they promise ultrafast,
energy-efficient operation with low-crosstalk and high bandwidth. Nevertheless,
existing photonic neurons largely mimic integrate-and-fire models, but
neuroscience shows that neurons also encode information through richer
mechanisms, such as the frequency and temporal patterns of spikes. Here, we
present a photonic-electronic resonate-and-fire (R-and-F) spiking neuron that
responds to the temporal structure of high-speed optical inputs. This is based
on a light-sensitive resonant tunnelling diode that produces excitable spikes
in response to nanosecond, low-power (100 microwatt) optical signals at
infrared telecom wavelengths. We experimentally demonstrate control of R-and-F
dynamics through inter-pulse timing of the optical stimuli and applied bias
voltage, achieving bandpass filtering of both analogue and digital inputs. The
R-and-F neuron also supports optical fan-in via wavelength-division multiplexed
inputs from four vertical-cavity surface-emitting lasers (VCSELs). This
electronic-photonic neuron exhibits key functionalities - including
spike-frequency filtering, temporal pattern recognition, and digital-to-spiking
conversion - critical for neuromorphic optical processing. Our approach
establishes a pathway toward low-power, high-speed temporal information
processing for light-enabled neuromorphic computing.

</details>


### [52] [A Flying Focus with Arbitrary Directionality](https://arxiv.org/abs/2510.14195)
*Sida Cao,Devdigvijay Singh,Lavonne S. Mack,John P. Palastro,Matthew R. Edwards*

Main category: physics.optics

TL;DR: A new flying focus configuration that decouples focal point motion from propagation direction, enabling multi-dimensional control of laser focus trajectories.


<details>
  <summary>Details</summary>
Motivation: Existing flying focus techniques constrain focal point motion to the propagation direction, limiting flexibility for various laser applications.

Method: Uses chirped laser pulses focused and diffracted by a diffractive lens and grating, with holographic configuration for high-power pulses using off-axis pump beams with different focal lengths.

Result: Demonstrated control over focal point direction and velocity both along and transverse to propagation direction through simulations.

Conclusion: Multi-dimensional control of focal trajectories enables new configurations for applications like laser wakefield acceleration, THz radiation steering, and surface harmonic generation.

Abstract: Flying focus techniques produce laser pulses whose focal points travel at
arbitrary, controllable velocities. While this flexibility can enhance a broad
range of laser-based applications, existing techniques constrain the motion of
the focal point to the propagation direction of the pulse. Here, we introduce a
flying focus configuration that decouples the motion of the focus from the
propagation direction. A chirped laser pulse focused and diffracted by a
diffractive lens and grating creates a focal point that can move both along and
transverse to the propagation direction. The focal length of the lens, grating
period, and chirp can be tuned to control the direction and velocity of the
focus. Simulations demonstrate this control for a holographic configuration
suited to high-power pulses, in which two off-axis pump beams with different
focal lengths encode the equivalent phase of a chromatic lens and grating in a
gas or plasma. For low-power pulses, conventional solid-state or adaptive
optics can be used instead. Multi-dimensional control over the focal trajectory
enables new configurations for applications, including laser wakefield
acceleration of ions, steering of broadband THz radiation, and surface harmonic
generation.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [53] [The geometry of PLS shrinkages](https://arxiv.org/abs/2510.14430)
*Paolo Foschi*

Main category: math.ST

TL;DR: Analysis of PLS shrinkage geometry, revealing shrinkage factors as weighted averages of basic shrinkages, identifying extreme nonlinear behavior, and disproving the conjecture about degrees of freedom.


<details>
  <summary>Details</summary>
Motivation: To understand the geometric structure of PLS shrinkages and investigate the behavior of degrees of freedom measures in extreme situations.

Method: Derived explicit formula for shrinkage vector, expressed shrinkage factors as weighted averages of basic shrinkages, and analyzed the multilinear dependence on observed responses.

Result: Identified extreme situations with highly nonlinear PLS behavior where degrees of freedom measures fail, and disproved the conjecture that PLS degrees of freedom always exceed the number of PLS directions.

Conclusion: PLS shrinkage structure is complex with nonlinear behavior in extreme cases, and traditional degrees of freedom measures can be unreliable, requiring more sophisticated approaches.

Abstract: The geometrical structure of PLS shrinkages is here considered. Firstly, an
explicit formula for the shrinkage vector is provided. In that expression,
shrinkage factors are expressed a averages of a set of basic shrinkages that
depend only on the data matrix. On the other hand, the weights of that average
are multilinear functions of the observed responses. That representation allows
to characterise the set of possible shrinkages and identify extreme situations
where the PLS estimator has an highly nonlinear behaviour. In these situations,
recently proposed measures for the degrees of freedom (DoF), that directly
depend on the shrinkages, fail to provide reasonable values. It is also shown
that the longstanding conjecture that the DoFs of PLS always exceeds the number
PLS directions does not hold.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [54] [No cosmological constraints on dark photon dark matter from resonant conversion: Impact of nonlinear plasma dynamics](https://arxiv.org/abs/2510.13956)
*Anson Hook,Junwu Huang,Mohamad Shalaby*

Main category: hep-ph

TL;DR: The paper invalidates all existing dark photon dark matter constraints from resonant conversion in the early universe by showing that plasma nonlinearities limit energy transfer to thermal levels, weakening constraints by factors of 3000 to 10^7.


<details>
  <summary>Details</summary>
Motivation: To re-examine and invalidate constraints on dark photon dark matter that rely on resonant conversion into photons/plasmons in the early universe, as these constraints may be overly optimistic due to unaccounted plasma effects.

Method: Used dedicated Particle-in-Cell simulations to study resonant conversion of dark photons into Langmuir waves, analyzing nonlinear plasma effects including ponderomotive force and excitation of higher-k waves that create spatial inhomogeneities.

Result: Found that resonant energy transfer saturates due to plasma nonlinearities, limiting deposited energy to about the thermal energy of electrons at conversion time, which is orders of magnitude below observable cosmological thresholds.

Conclusion: All existing dark photon dark matter constraints from resonant conversion are invalidated, with constraints weakened by factors of 3000 to 10^7 across ten orders of magnitude in dark photon mass.

Abstract: We revisit and invalidate all dark photon dark matter constraints from
resonant conversion of dark photons into photons (plasmons) in the early
universe. These constraints rely on the resonant transfer of a substantial
portion of the dark photon energy density into the SM plasma, heating the
plasma in the process. We demonstrate that this resonant transfer saturates
because of plasma nonlinearities. Dark photon dark matter resonantly converts
into $k \simeq 0$ Langmuir waves in the early universe electron-ion plasma.
Once the Langmuir-wave energy approaches the thermal energy of the plasma,
nonlinear effects driven by the ponderomotive force become significant. In
particular, we show using dedicated Particle-in-Cell simulations that
large-amplitude $k = 0$ Langmuir waves excite higher-k Langmuir and ion
acoustic waves, producing strong spatial variations in density and plasma
frequency. These inhomogeneities suppress further resonant conversion, limiting
the deposited energy to about the thermal energy of the electrons at the time
of conversion, orders of magnitude below observable cosmological thresholds.
Consequently, the dark photon dark matter constraints are weaker by factors of
$3000$ to $10^7$ across ten orders of magnitude in dark photon mass.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [55] [Breaking gyrochronology through the collapse of coronal winds](https://arxiv.org/abs/2510.14164)
*MichaÃ«l LÃ©vesque,Paul Charbonneau*

Main category: astro-ph.SR

TL;DR: Gyrochronology fails for stars older than the sun, potentially due to wind collapse from reduced coronal heating rather than dynamo changes. The study shows magnetocentrifugal effects become important at low temperatures, preventing power-law scaling of mass/angular momentum loss.


<details>
  <summary>Details</summary>
Motivation: To explore an alternative explanation for gyrochronology failure in old stars - wind collapse from reduced coronal heating instead of the commonly proposed dynamo shutdown or mode change.

Method: Analyzed mass and angular momentum loss rates in the low coronal temperature limit, considering magnetocentrifugal effects. Used an ad hoc power law relationship between coronal temperature and magnetic field strength while maintaining standard dynamo relationships.

Result: Found that reproducing the observed gyrochronology break requires an unrealistic exponent (Ïâ³1.5) associated with over 3 orders of magnitude drop in coronal power input, which contradicts current observations of non-thermal emission in aged solar-type stars.

Conclusion: The wind collapse hypothesis through reduced coronal heating appears physically unrealistic to explain gyrochronology failure, suggesting the dynamo change explanation is more plausible.

Abstract: Gyrochronology, a method for dating aged field stars ($\gtrsim$ a few Gyr)
based on their rotation rate, has recently been shown to fail for many stars
older than the sun. The explanation most often put forth is that a shutdown or
mode change in the stellar dynamo leads to a sharp decrease in angular momentum
loss in magnetized coronal winds. In this paper, we explore an alternate
possibility, namely a collapse of the wind itself through a reduction of
coronal heating. We show that in the low coronal temperature ($T_0$) limit,
even at solar-like low rotation rates ($\Omega$) and coronal magnetic field
strength ($B_{r0}$), magnetocentrifugal effects are important and preclude
expression of the mass and angular momentum loss rates as power-laws of $T_0$
or $\Omega$ when $T_0$ drops below $\simeq 1.5\,$MK. Mass loss is found to
scale linearly with power input into the wind at all coronal temperatures.
Introducing an ad hoc power law relationship $T_0\propto B_{r0}^\sigma$ while
retaining the ``standard'' dynamo relationship $B_{r0}\propto\Omega$, we show
that reproducing the observed break in gyrochronology requires an exponent
$\sigma\gtrsim 1.5$, with which is associated a drop by over 3 orders of
magnitude in power input into the quiet corona. This appears physically
unrealistic, given current observations of chromospheric and coronal
non-thermal emission in aged solar-type stars.

</details>


### [56] [Influence of kinetic effects in large-scale magnetic reconnection with multi-hierarchy simulation code KAMMUY](https://arxiv.org/abs/2510.14521)
*Keita Akutagawa,Shinsuke Imada,Munehito Shoda*

Main category: astro-ph.SR

TL;DR: Developed KAMMUY, a multi-hierarchy simulation code combining MHD and PIC methods to bridge scale gaps in magnetic reconnection studies, finding that Hall magnetic field extension doesn't affect reconnection rate.


<details>
  <summary>Details</summary>
Motivation: PIC simulations alone cannot capture interactions between kinetic and fluid dynamics in large-scale magnetic reconnection phenomena like solar flares due to computational limitations.

Method: Created KAMMUY code that runs ideal MHD simulation for large domain and PIC simulation for smaller domain in parallel with mutual information exchange, validated with MHD wave propagation and shock tube tests.

Result: Short-wavelength waves from PIC region don't propagate into MHD region, while MHD-scale structures propagate smoothly into PIC region. Reconnection rate remains unchanged regardless of PIC domain size where Hall magnetic field is present.

Conclusion: Spatial extension of Hall magnetic field on 10-100 ion inertial length scale does not influence magnetic reconnection rate, providing important insight for multi-scale reconnection studies.

Abstract: Magnetic reconnection is a multiscale phenomenon where fluid- and
particle-scale processes interact. The particle-in-cell (PIC) method, capable
of resolving kinetic (particle-scale) physics, is extensively used to study the
kinetic effects in magnetic reconnection. Meanwhile, because of the high
computational cost, PIC simulations cannot capture the interaction between
kinetic and fluid dynamics, which poses a major obstacle to understanding
magnetic reconnection in large-scale phenomena such as solar flares. A
multi-hierarchy simulation that combines Magnetohydrodynamics (MHD) and PIC
provides a promising means to overcome these spatial and temporal scale gaps.
We developed a multi-hierarchy simulation code KAMMUY (Kinetic And
Magnetohydrodynamic MUlti-hierarchY simulation code), in which an ideal MHD
simulation for a large domain and a PIC simulation for a smaller domain are
solved in parallel with mutual information exchange. To validate the code, we
conducted test simulations of MHD wave propagation and the shock tube problem.
The results demonstrate that short-wavelength, high-frequency waves generated
in the PIC region do not propagate into the MHD region, whereas MHD-scale
structures propagate smoothly into the PIC region, highlighting the capability
of our code for numerical studies of magnetic reconnection. By applying the
KAMMUY code to magnetic reconnection while varying the PIC domain size, we find
that the reconnection rate remains unchanged, regardless of the extent of the
PIC region where the Hall magnetic field is present. It suggests that the
spatial extension of the Hall magnetic field on the scale of $10 \sim 100
\lambda_i$ does not influence the reconnection rate.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [57] [DeepMartingale: Duality of the Optimal Stopping Problem with Expressivity](https://arxiv.org/abs/2510.13868)
*Junyan Ye,Hoi Ying Wong*

Main category: math.OC

TL;DR: DeepMartingale is a novel deep learning method using martingale representation to solve high-dimensional optimal stopping problems, providing tight upper bounds without suffering from the curse of dimensionality.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of solving discrete-monitoring optimal stopping problems in continuous time, particularly in high-dimensional settings where traditional methods face the curse of dimensionality.

Method: Uses martingale representation and neural networks to derive tight upper bounds for the primal value function, with architectural design that scales polynomially with dimension.

Result: The method converges under mild assumptions and approximates the true value function within any prescribed accuracy Îµ with network size bounded by cÌD^qÌÎµ^{-rÌ}, where constants are dimension-independent.

Conclusion: DeepMartingale is an effective approach for high-dimensional optimal stopping problems, demonstrating convergence, expressivity, and stability without suffering from the curse of dimensionality.

Abstract: Using a martingale representation, we introduce a novel deep-learning
approach, which we call DeepMartingale, to study the duality of
discrete-monitoring optimal stopping problems in continuous time. This approach
provides a tight upper bound for the primal value function, even in
high-dimensional settings. We prove that the upper bound derived from
DeepMartingale converges under very mild assumptions. Even more importantly, we
establish the expressivity of DeepMartingale: it approximates the true value
function within any prescribed accuracy $\varepsilon$ under our architectural
design of neural networks whose size is bounded by
$\tilde{c}\,D^{\tilde{q}}\varepsilon^{-\tilde{r}}$, where the constants
$\tilde{c}, \tilde{q}, \tilde{r}$ are independent of the dimension $D$ and the
accuracy $\varepsilon$. This guarantees that DeepMartingale does not suffer
from the curse of dimensionality. Numerical experiments demonstrate the
practical effectiveness of DeepMartingale, confirming its convergence,
expressivity, and stability.

</details>


### [58] [Optimality-Based Control Space Reduction for Infinite-Dimensional Control Spaces](https://arxiv.org/abs/2510.14479)
*Michael Kartmann,Stefan Volkwein*

Main category: math.OC

TL;DR: This paper presents a method for model reduction in linear-quadratic optimal control problems with time-varying parabolic PDEs, combining both control and state variable reduction with error bounds and an adaptive algorithm.


<details>
  <summary>Details</summary>
Motivation: To develop efficient model reduction techniques for optimal control problems with parabolic PDEs by simultaneously reducing both control and state variables, improving computational efficiency while maintaining accuracy.

Method: Proposes a combined control and state space reduction approach that preserves the same minimizer as state-only reduction, with a posteriori error bounds for optimal control and an adaptive algorithm for solving the control problem.

Result: The method provides lower and upper a posteriori error bounds for optimal control, an error representation for the optimal function value, and proves convergence of the adaptive algorithm. Numerical results demonstrate advantages of combined reduction.

Conclusion: Combined control and state space reduction is effective for linear-quadratic optimal control problems with parabolic PDEs, with proven convergence and numerical advantages over state-only reduction.

Abstract: We consider linear model reduction in both the control and state variables
for unconstrained linear-quadratic optimal control problems subject to
time-varying parabolic PDEs. The first-order optimality condition for a
state-space reduced model naturally leads to a reduced structure of the optimal
control. Thus, we consider a control- and state-reduced problem that admits the
same minimizer as the solely state-reduced problem. Lower and upper \emph{a
posteriori} error bounds for the optimal control and a representation for the
error in the optimal function value are provided. These bounds are used in an
adaptive algorithm to solve the control problem. We prove its convergence and
numerically demonstrate the advantage of combined control and state space
reduction.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [59] [Quantum Search in Superposed Quantum Lattice Gas Automata and Lattice Boltzmann Systems](https://arxiv.org/abs/2510.14062)
*CÄlin A. Georgescu,Matthias MÃ¶ller*

Main category: quant-ph

TL;DR: The paper proposes quantum computing methods for CFD that avoid flow field measurement by using discrete optimization and quantum search, providing potential quantum advantage through amplitude estimation.


<details>
  <summary>Details</summary>
Motivation: Current quantum CFD methods (QLGA/QLBM) focus on model development rather than practical applications, and their reliance on quantum state tomography often cancels out potential quantum advantages.

Method: Simulates multiple lattice configurations simultaneously using amplitude estimation and quantum search algorithms, with detailed gate-level complexity analysis of circuit implementations.

Result: Developed methods that circumvent flow field measurement entirely and provide asymptotic quantum advantage through quantum search optimization.

Conclusion: The proposed approach enables practical quantum CFD applications by avoiding measurement bottlenecks and achieving quantum advantage through optimization-based methods rather than traditional flow field reconstruction.

Abstract: As the scope of Computational Fluid Dynamics (CFD) grows to encompass ever
larger problem scales, so does the interest in whether quantum computing can
provide an advantage. In recent years, Quantum Lattice Gas Automata (QLGA) and
Quantum Lattice Boltzmann Methods (QLBM) have emerged as promising candidates
for quantum-native implementations of CFD solvers. Though the progress in
developing QLGA and QLBM algorithms has been significant, it has largely
focused on the development of models rather than applications. As a result, the
zoo of QLGA and QLBM algorithms has grown to target several equations and to
support many extensions, but the practical use of these models is largely
limited to quantum state tomography and observable measurement. This limitation
is crucial in practice, because unless very specific criteria are met, such
measurements may cancel out any potential quantum advantage. In this paper, we
propose an application based on discrete optimization and quantum search, which
circumvents flow field measurement altogether. We propose methods for
simulating many different lattice configurations simultaneously and describe
how the usage of amplitude estimation and quantum search can provide an
asymptotic quantum advantage. Throughout the paper, we provide detailed
complexity analyses of gate-level implementations of our circuits and consider
the benefits and costs of several encodings.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [60] [Comparative Analysis of the Flow in a Realistic Human Airway](https://arxiv.org/abs/2510.14320)
*Mario RÃ¼ttgers,Julian Vorspohl,Luca Mayolle,Benedikt Johanning-Meiners,Dominik Krug,Michael Klaas,Matthias Meinke,Sangseung Lee,Wolfgang SchrÃ¶der,Andreas Lintermann*

Main category: physics.flu-dyn

TL;DR: Direct numerical simulations of inspiratory flow through a detailed human airway model from nasal mask to 6th bronchial bifurcation, revealing pressure loss distribution and flow instabilities across anatomical regions at two Reynolds numbers.


<details>
  <summary>Details</summary>
Motivation: Existing computational studies rely on simplified geometries or turbulence models, limiting their ability to resolve important flow features like shear-layer instabilities and secondary vortices in human airways.

Method: Employed lattice-Boltzmann method for direct numerical simulations without turbulence models, using detailed airway geometry from nasal mask to 6th bronchial bifurcation at Re_p=400 (resting) and Re_p=1200 (elevated breathing).

Result: Total pressure loss increased from 9.76 Pa at Re_p=400 to 41.93 Pa at Re_p=1200, with nasal cavity accounting for majority of loss (81.3% at Re_p=400, 73.4% at Re_p=1200). Secondary vortices and turbulent shear-layers enhanced local pressure losses, while carinal bifurcation stabilized flow.

Conclusion: Key outcome is spatial correlation between pressure loss and flow instabilities across anatomical regions, providing novel perspective on how flow resistance and vortex dynamics vary with geometric changes and flow rate.

Abstract: Accurate simulations of the flow in the human airway are essential for
advancing diagnostic methods. Many existing computational studies rely on
simplified geometries or turbulence models, limiting their simulation's ability
to resolve flow features such shear-layer instabilities or secondary vortices.
In this study, direct numerical simulations were performed for inspiratory flow
through a detailed airway model which covers the nasal mask region to the 6th
bronchial bifurcation. Simulations were conducted at two physiologically
relevant \textsc{Reynolds} numbers with respect to the pharyngeal diameter,
i.e., at Re_p=400 (resting) and Re_p=1200 (elevated breathing). These values
characterize resting and moderately elevated breathing conditions. A
lattice-Boltzmann method was employed to directly simulate the flow, i.e., no
turbulence model was used. The flow field was examined across four anatomical
regions: 1) the nasal cavity, 2) the naso- and oropharynx, 3) the
laryngopharynx and larynx, and 4) the trachea and carinal bifurcation. The
total pressure loss increased from 9.76 Pa at Re_p=400 to 41.93 Pa at
Re_p=1200. The nasal cavity accounted for the majority of this loss for both
Reynolds numbers, though its relative contribution decreased from 81.3% at
Re_p=400 to 73.4% at Re_p=1200. At Re_p=1200, secondary vortices in the
nasopharyngeal bend and turbulent shear-layers in the glottis jet enhanced the
local pressure losses. In contrast, the carinal bifurcation mitigated upstream
unsteadiness and stabilized the flow. A key outcome is the spatial correlation
between the pressure loss and the onset of flow instabilities across the four
regions. This yields a novel perspective on how the flow resistance and vortex
dynamics vary with geometric changes and flow rate.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [61] [Multiscaling asymptotic behavior of solutions to random high-order heat equations](https://arxiv.org/abs/2510.14153)
*Maha Mosaad A Alghamdi,Nikolai Leonenko,Andriy Olenko*

Main category: math.PR

TL;DR: Analysis of high-order PDEs with random initial conditions exhibiting long-memory and cyclic behavior, showing convergence to Gaussian random fields after proper scaling.


<details>
  <summary>Details</summary>
Motivation: To study the behavior of high-order partial differential equations with random initial conditions that have both long-memory (spectral singularity at zero) and cyclic behavior (spectral singularity at non-zero frequencies).

Method: Using spectral methods and scaling techniques, with kernel averaging applied to odd-order equations to obtain nonexplosive and nondegenerate limits.

Result: Solutions converge to Gaussian random fields after proper rescaling and normalization. Limit fields are determined by equation order (even/odd) and presence/absence of spectral singularity at zero. Spectral representations and covariance functions are provided.

Conclusion: Different limit fields emerge based on equation order and spectral singularity characteristics, with numerical examples validating the theoretical findings.

Abstract: This paper studies high-order partial differential equations with random
initial conditions that have both long-memory and cyclic behavior. The cases of
random initial conditions with the spectral singularities, both at zero
(representing classical long-range dependence) and at non-zero frequencies
(representing cyclic long-range dependence), are investigated.
  Using spectral methods and scaling techniques, it is proved that, after
proper rescaling and normalization, the solutions converge to Gaussian random
fields. For each type of equation, spectral representations and covariance
functions of limit fields are given. For odd-order equations, we apply the
kernel averaging of solutions to obtain nonexplosive and nondegenerate limits.
It is shown that the different limit fields are determined by the even or odd
orders of the equations and by the presence or absence of a spectral
singularity at zero. Several numeric examples illustrate the obtained
theoretical results.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [62] [Phenomenological Ehrenfest Dynamics with Topological and Geometric Phase Effects and the curious case of Elliptical intersection](https://arxiv.org/abs/2510.14181)
*Dhruv Sharma*

Main category: cond-mat.mes-hall

TL;DR: A computational framework for simulating nonadiabatic molecular dynamics with geometric phase effects, handling various electronic state crossings through parameterized two-level Hamiltonian models and Berry curvature-based force corrections.


<details>
  <summary>Details</summary>
Motivation: To develop a unified framework that accurately incorporates geometric phase effects in molecular dynamics simulations, particularly for systems with different types of level crossings where topological effects play significant roles.

Method: Uses a generalized two-level Hamiltonian model with parameterization for different crossings, introduces prelooping trajectory initialization to encode memory as initial phase, and incorporates Berry curvature-based force corrections to Ehrenfest dynamics.

Result: Numerical simulations show consistency with theoretical predictions for state mixing and inhibition due to geometric phase effects. The method correctly produces phase pi for conical intersections and tunable phase for elliptic intersections.

Conclusion: The framework provides a valuable tool for studying quantum-classical interactions in molecular systems with geometric phase effects, opening avenues for degenerate materials design, new spectroscopy development, and potential qubit applications.

Abstract: We present a comprehensive computational framework for simulating
nonadiabatic molecular dynamics with explicit inclusion of geometric phase (GP)
effects. Our approach is based on a generalized two-level Hamiltonian model
that can represent various electronic state crossings - conical intersections,
avoided crossings, and elliptic intersections - through appropriate
parameterization. We introduce a novel prelooping trajectory initialization
scheme, allowing us to encode the memory as an initial phase accumulated due to
the adiabatic evolution over the potential energy surface. This is a unified
framework to handle different types of level crossings by incorporating Berry
curvature-based force corrections to Ehrenfest dynamics, ensuring accurate
representation of topological effects. For conical intersections, our method
incorporates the theoretically expected phase pi, while for elliptic
intersections, it yields a parametrically tunable but loop radius (energy)
independent phase different from pi. We also include an eccentricity parameter
(e) in the diabatic coupling to model more realistic molecular systems.
Numerical simulations demonstrate the consistency of our approach with
theoretical predictions for mixing of states and inhibition from mixing due to
geometric phase effects. This framework provides a valuable tool for studying
quantum-classical interactions in molecular systems where geometric phase
effects play a significant role. The elliptical intersection and geometric
phase effect opens avenue for the design and discovery of degenerate materials.
It produces a fresh look to help develop a new kind of spectroscopy and
potential qubit applications. This simple Hamiltonian reveals a pathological
phase protection effect E = kr, where k is real, that has great utility in a
new spectroscopy design.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [63] [Loss functions arising from the index of agreement](https://arxiv.org/abs/2510.14714)
*Hristos Tyralis,Georgia Papacharalampous*

Main category: stat.ME

TL;DR: The paper analyzes Willmott's index of agreement loss function, proposes an improved version called L_NR2 with better geometric alignment and closed-form solutions, and shows convergence with squared error loss under high correlation conditions.


<details>
  <summary>Details</summary>
Motivation: To understand the theoretical properties of Willmott's index of agreement loss function and develop an improved version that better aligns with geometric intuition while maintaining desirable properties.

Method: Theoretical analysis of L_W properties, proposal of L_NR2 with modified denominator using sum of Euclidean distances, and comparison with squared error loss under varying correlation conditions.

Result: L_NR2 retains boundedness, translation and scale invariance of L_W, admits closed-form solutions for linear models, and converges with squared error and L_W as predictor-response correlation approaches 1.

Conclusion: L_NR2 provides theoretical improvements over L_W while maintaining practical utility, with convergence behavior making all three loss functions nearly identical in high-correlation scenarios like hydrologic model calibration.

Abstract: We examine the theoretical properties of the index of agreement loss function
$L_W$, the negatively oriented counterpart of Willmott's index of agreement, a
common metric in environmental sciences and engineering. We prove that $L_W$ is
bounded within [0, 1], translation and scale invariant, and estimates the
parameter $\Bbb{E}_{F}[\underline{y}] \pm \Bbb{V}_{F}^{1/2}[\underline{y}]$
when fitting a distribution. We propose $L_{\operatorname{NR}_2}$ as a
theoretical improvement, which replaces the denominator of $L_W$ with the sum
of Euclidean distances, better aligning with the underlying geometric
intuition. This new loss function retains the appealing properties of $L_W$ but
also admits closed-form solutions for linear model parameter estimation. We
show that as the correlation between predictors and the dependent variable
approaches 1, parameter estimates from squared error, $L_{\operatorname{NR}_2}$
and $L_W$ converge. This behavior is mirrored in hydrologic model calibration
(a core task in water resources engineering), where performance becomes nearly
identical across these loss functions. Finally, we suggest potential
improvements for existing $L_p$-norm variants of the index of agreement.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [64] [Bell Instability and Cosmic-Ray Acceleration in AGN Ultrafast Outflow Shocks](https://arxiv.org/abs/2510.13946)
*Rei Nishiura,Tsuyoshi Inoue*

Main category: astro-ph.HE

TL;DR: The paper studies magnetic field amplification via NRH instability at AGN UFO reverse shocks and its effect on cosmic-ray acceleration, finding a transition in efficiency based on background magnetic field strength.


<details>
  <summary>Details</summary>
Motivation: To understand how NRH instability drives magnetic field amplification and cosmic-ray acceleration at reverse shocks of ultrafast outflows from AGNs, particularly when maximum CR energy approaches injection scale.

Method: Uses 1D MHD-CR framework with telegraph-type diffusion-convection equations to model coupled evolution of cosmic rays, magnetic fields, and shock dynamics under realistic parameters.

Result: Found distinct transition: weak background fields (<10^-4 G) enable efficient NRH instability and self-regulated acceleration, while stronger fields (>10^-3 G) suppress NRH instability and reduce acceleration efficiency.

Conclusion: The efficiency of NRH instability and cosmic-ray acceleration at UFO reverse shocks depends critically on background magnetic field strength, with implications for PeV-EeV acceleration conditions.

Abstract: We investigate magnetic-field amplification driven by the nonresonant hybrid
(NRH or Bell) instability and its impact on cosmic-ray (CR) acceleration at
reverse shocks of ultrafast outflows (UFOs) from active galactic nuclei (AGN).
Previous kinetic studies by particle-in-cell simulations have demonstrated that
when maximum CR energy is near the injection scale, NRH instability efficiently
amplifies magnetic field up to the saturation level. However, the efficiency of
NRH instability goes down as maximum energy increase since CR current is
carried by escaping CRs near the maximum energy. We employ a one-dimensional
MHD--CR framework solving telegraph-type diffusion--convection equations to
trace the coupled evolution of CRs, magnetic fields, and shock dynamics under
realistic parameters. We find a distinct transition with magnetic field
strength: for weak background fields ($B_{0}\!\lesssim\!10^{-4}\,\mathrm{G}$),
NRH instability efficiently amplifies upstream turbulence, driving a
self-regulated state where $E_{\max}$ becomes independent of initial strength
of magnetic turbulence. In contrast, for stronger background fields
($B_{0}\!\gtrsim\!10^{-3}\,\mathrm{G}$), the escaping CR current is too weak to
drive NRH instability, and magnetic turbulence further decays through
parametric instabilities, potentially reducing the acceleration efficiency. We
give the physical interpretation for the transition and discuss conditions for
PeV--EeV acceleration at UFO reverse shocks.

</details>


<div id='nlin.SI'></div>

# nlin.SI [[Back]](#toc)

### [65] [Asymmetric integrable turbulence and rogue wave statistics for the derivative nonlinear SchrÃ¶dinger equation](https://arxiv.org/abs/2510.14472)
*Ming Zhong,Weifang Weng,Zhenya Yan*

Main category: nlin.SI

TL;DR: The paper studies asymmetric integrable turbulence and rogue waves in the DNLS equation, showing oscillatory convergence of statistical moments with specific decay rates and frequency related to modulation instability.


<details>
  <summary>Details</summary>
Motivation: To investigate the asymmetric turbulence and rogue wave dynamics emerging from modulation instability in the DNLS equation, which differs from the symmetric behavior in NLS systems.

Method: Analysis of statistical moments, ensemble-averaged energies, wave-action spectrum, auto-correlation function, and probability density function for wave intensity in the DNLS framework.

Result: Found oscillatory convergence with amplitude decay rate t^{-1.36} and phase shift decay rate t^{-0.78}, asymmetric turbulence with power-law spectrum |k+3|^{-Î±}, and increased rogue wave probability during initial nonlinear phase.

Conclusion: DNLS turbulence is asymmetric due to wave number asymmetry, with rogue waves more likely during minimum potential modulus phases, and statistical properties exhibit specific oscillatory decay patterns related to modulation instability.

Abstract: We investigate the asymmetric integrable turbulence and rogue waves (RWs)
emerging from the modulation instability (MI) of plane waves for the DNLS
equation. The \(n\)-th moments and ensemble-averaged kinetic and potential
energy exhibit oscillatory convergence towards their steady-state values.
Specifically, the amplitudes of oscillations for these indexes decay
asymptotically with time as \(t^{-1.36}\), while the phase shifts demonstrate a
nonlinear decay with a rate of \(t^{-0.78}\). The frequency of these
oscillations is observed to be twice the maximum growth rate of MI. These
oscillations can be classified into two distinct types: one is in phase with
ensemble-averaged potential energy modulus $|\langle H_4\rangle|$, and the
other is anti-phase. At the same time, this unity is also reflected in the
wave-action spectrum \( S_k(t) \) for a given \( k \), the auto-correlation
function \( g(x,t) \) for a given \( x \), as well as the PDF \( P(I,t) \). The
critical feature of the turbulence is the wave-action spectrum, which follows a
power-law distribution of \( |k+3|^{-\alpha} \) expect for $k=-3$. Unlike the
NLS equation, the turbulence in the DNLS setting is asymmetric, primarily due
to the asymmetry between the wave number of the plane wave from the MI and the
perturbation wave number.. As the asymptotic peak value of \( S_k \) is
observed at \( k = -3 \), the auto-correlation function exhibits a nonzero
level as \( x \to \pm L/2 \). The PDF of the wave intensity asymptotically
approaches the exponential distribution in an oscillatory manner. However,
during the initial stage of the nonlinear phase, MI slightly increases the
occurrence of RWs. This happens at the moments when the potential modulus is at
its minimum, where the probability of RWs occurring in the range of \( I\in
[12, 15] \) is significantly higher than in the asymptotic steady state.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [66] [Grain volume distribution alters the critical phenomena in complex granular systems](https://arxiv.org/abs/2510.14797)
*Teng Man,Yimin Lu,Zhongrong Wang,Herbert Huppert,Alessio Zaccone,Honglei Sun*

Main category: cond-mat.soft

TL;DR: This study uses DEM simulations to investigate how grain size distribution affects rheology and critical behavior in sheared granular flows, finding a characteristic length scale embedded in polydisperse systems and correlations between critical solid fractions and grain volume distributions.


<details>
  <summary>Details</summary>
Motivation: To understand how grain size distribution influences mechanical properties, segregation issues, and critical behaviors in amorphous disordered systems and granular materials, which is important for engineering and geophysical applications.

Method: Used discrete element method (DEM) simulations to investigate rheological and critical behaviors of sheared granular flows with various grain size distributions.

Result: Found a unified rheological relation with an embedded characteristic length scale related to contact probability, and obtained correlation functions between critical solid fractions and dimensionless grain volume distributions.

Conclusion: The work elucidates how particle volumes affect rheology and micromechanics of dry granular systems, providing insights for incorporating other particle properties into a unified framework for engineering and geophysical problems.

Abstract: The grain size distribution (GSD) plays an important role in the mechanical
properties of amorphous disordered systems and complex granular materials.
Varying GSD causes segregation issues and alters critical behaviors. This work
used the discrete element method (DEM) to investigate the rheological and
critical behaviors of sheared granular flows with various GSDs. The results
show that, while a unified rheological relation can be obtained, a
characteristic length scale, which is associated with the contact probability
and can be obtained from any GSD, is embedded within such a polydisperse
disordered system. We further acquire a correlation function between critical
solid fractions and dimensionless grain volume distributions. This work
elucidates the effect of particle volumes on the rheology and micromechanics of
dry granular systems and provides further insights in better incorporating the
influence of other particle properties into a unified framework, which is
helpful and critical for the corresponding engineering and geophysical
problems.

</details>
