<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 13]
- [math.AP](#math.AP) [Total: 13]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 7]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [math.SG](#math.SG) [Total: 1]
- [math.MG](#math.MG) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Graph Neural Regularizers for PDE Inverse Problems](https://arxiv.org/abs/2510.21012)
*William Lauga,James Rowbottom,Alexander Denker,Željko Kereta,Moshe Eliasof,Carola-Bibiane Schönlieb*

Main category: math.NA

TL;DR: A framework for solving ill-posed inverse PDE problems using FEM-based inversion with graph neural network regularization.


<details>
  <summary>Details</summary>
Motivation: To address ill-posed inverse problems governed by PDEs by combining numerical methods with learned regularization for better accuracy and generalizability.

Method: Iterative regularization scheme alternating between FEM-based inversion and physics-inspired graph neural network regularization, leveraging FEM's graph structure.

Result: Outperforms classical regularization techniques and achieves accurate reconstructions in highly ill-posed scenarios.

Conclusion: The framework provides a robust, interpretable, and generalizable approach for solving inverse PDE problems.

Abstract: We present a framework for solving a broad class of ill-posed inverse
problems governed by partial differential equations (PDEs), where the target
coefficients of the forward operator are recovered through an iterative
regularization scheme that alternates between FEM-based inversion and learned
graph neural regularization. The forward problem is numerically solved using
the finite element method (FEM), enabling applicability to a wide range of
geometries and PDEs. By leveraging the graph structure inherent to FEM
discretizations, we employ physics-inspired graph neural networks as learned
regularizers, providing a robust, interpretable, and generalizable alternative
to standard approaches. Numerical experiments demonstrate that our framework
outperforms classical regularization techniques and achieves accurate
reconstructions even in highly ill-posed scenarios.

</details>


### [2] [Efficient optimization-based invariant-domain-preserving limiters in solving gas dynamics equations](https://arxiv.org/abs/2510.21080)
*Chen Liu,Dionysis Milesis,Chi-Wang Shu,Xiangxiong Zhang*

Main category: math.NA

TL;DR: The paper introduces optimization-based limiters for enforcing invariant domains in gas dynamics using splitting methods like Douglas-Rachford and Davis-Yin, applied to high-order discontinuous Galerkin schemes.


<details>
  <summary>Details</summary>
Motivation: To develop robust methods for enforcing invariant domain preservation in high-order numerical schemes for compressible flow equations, ensuring physical constraints are maintained.

Method: Uses optimization-based approach with explicit projection onto invariant domain set, applying Douglas-Rachford and Davis-Yin splitting methods to construct globally conservative schemes.

Result: Successfully applied to high-order discontinuous Galerkin schemes, validated on demanding benchmarks for both ℓ¹-norm and ℓ²-norm minimization limiters.

Conclusion: The optimization-based approach provides effective invariant-domain-preserving schemes for compressible flow equations with demonstrated robustness and performance.

Abstract: We introduce effective splitting methods for implementing optimization-based
limiters to enforce the invariant domain in gas dynamics in high order accurate
numerical schemes. The key ingredients include an easy and efficient explicit
formulation of the projection onto the invariant domain set, and also proper
applications of the classical Douglas-Rachford splitting and its more recent
extension Davis-Yin splitting. Such an optimization-based approach can be
applied to many numerical schemes to construct high order accurate, globally
conservative, and invariant-domain-preserving schemes for compressible flow
equations. As a demonstration, we apply it to high order discontinuous Galerkin
schemes and test it on demanding benchmarks to validate the robustness and
performance of both $\ell^1$-norm minimization limiter and $\ell^2$-norm
minimization limiter.

</details>


### [3] [On the recent advances of spectral analysis for systems arising from fully-implicit RK methods](https://arxiv.org/abs/2510.21241)
*Michal Outrata*

Main category: math.NA

TL;DR: This paper shows the equivalence between two different spectral analysis approaches for matrices in fully implicit Runge-Kutta methods applied to linear time-dependent PDEs.


<details>
  <summary>Details</summary>
Motivation: Two different groups developed spectral analysis results for matrices in fully implicit Runge-Kutta methods for linear time-dependent PDEs, using different formulations and tools that produced seemingly non-coinciding results.

Method: The authors demonstrate the equivalence of both the results and the approaches used by the two research groups, unifying the two directions of analysis.

Result: The paper proves that the two different spectral analysis approaches are equivalent and produce consistent results despite using different formulations and tools.

Conclusion: The work successfully unifies the two research directions by showing their equivalence, resolving the apparent discrepancy between the different spectral analysis results.

Abstract: This work deals with two groups of spectral analysis results for matrices
arising in fully implicit Runge-Kutta methods used for linear time-dependent
partial differential equations. These were applied for different formulations
of the same problem and used different tools to arrive at results that do not
immediately coincide. We show the equivalence of the results as well as the
equivalence of the approaches, unifying the two directions.

</details>


### [4] [Ergodic Estimates of One-Step Numerical Approximations for Superlinear SODEs](https://arxiv.org/abs/2510.21279)
*Xin Liu,Zhihui Liu*

Main category: math.NA

TL;DR: First-order convergence rate established for ergodic error in numerical approximations of stochastic ODEs with superlinear coefficients and multiplicative noise.


<details>
  <summary>Details</summary>
Motivation: To analyze the convergence rate of numerical schemes for stochastic ODEs with superlinear coefficients and multiplicative noise, which are challenging due to their nonlinear nature.

Method: Leveraging the generator approach to the Stein method to derive a general error representation formula for one-step numerical schemes under dissipativity and smoothness conditions.

Result: Proved that the error between the accurate invariant measure π and the numerical invariant measure π_τ is of order O(τ), which is sharp.

Conclusion: The framework applies to several schemes including tamed Euler, projected Euler, and backward Euler methods, providing a unified approach for convergence analysis.

Abstract: This paper establishes the first-order convergence rate for the ergodic error
of numerical approximations to a class of stochastic ODEs (SODEs) with
superlinear coefficients and multiplicative noise. By leveraging the generator
approach to the Stein method, we derive a general error representation formula
for one-step numerical schemes. Under suitable dissipativity and smoothness
conditions, we prove that the error between the accurate invariant measure
$\pi$ and the numerical invariant measure $\pi_\tau$ is of order
$\mathscr{O}(\tau)$, which is sharp. Our framework applies to several recently
studied schemes, including the tamed Euler, projected Euler, and backward Euler
methods.

</details>


### [5] [Multiscale Spectral Generalized Finite Element Methods for Discontinuous Galerkin Schemes](https://arxiv.org/abs/2510.21289)
*Christian Alber,Lukas Holbach*

Main category: math.NA

TL;DR: A multiscale spectral generalized finite element method (MS-GFEM) for DG discretizations that combines local source solutions with optimal spectral coarse spaces from eigenproblems.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient multiscale method for discontinuous Galerkin discretizations that can handle complex elliptic problems with high accuracy.

Method: Builds local approximations on overlapping subdomains as sum of local source solution and spectral coarse space correction from generalized eigenproblem, then assembles global solution via partition of unity.

Result: Proves nearly exponential decay of approximation error for second-order elliptic problems with weighted symmetric interior-penalty DG scheme.

Conclusion: MS-GFEM provides an effective approach for DG discretizations with proven error decay properties for elliptic problems.

Abstract: We propose a multiscale spectral generalized finite element method (MS-GFEM)
for discontinuous Galerkin (DG) discretizations. The method builds local
approximations on overlapping subdomains as the sum of a local source solution
and a correction from an optimal spectral coarse space, which is obtained from
a generalized eigenproblem. The global solution is then assembled via a
partition of unity. We prove nearly exponential decay of the approximation
error for second-order elliptic problems discretized with a weighted symmetric
interior-penalty DG scheme.

</details>


### [6] [A Variational Framework for the Algorithmic Complexity of PDE Solutions](https://arxiv.org/abs/2510.21290)
*Juan Esteban Suarez Cardona,Holger Boche,Gitta Kutyniok*

Main category: math.NA

TL;DR: A framework using least-squares variational formulations and gradient flows to study Turing computability and complexity of PDE solutions from an optimization perspective.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous theoretical foundations for distinguishing algorithmically solvable PDEs from those with undecidable behavior, and to quantify computational resources needed for PDE approximations.

Method: Novel framework based on least-squares variational formulations and associated gradient flows, enabling approximation of PDE solution operators via discrete gradient flows.

Result: Links structural PDE properties (coercivity, ellipticity, convexity) to solution complexity, identifying both polynomial-time solvable regimes and cases with super-polynomial complexity blowup.

Conclusion: The optimization-based framework provides a systematic approach to characterize computability and complexity of PDE solutions, bridging theoretical computability with practical numerical solvability.

Abstract: Partial Differential Equations (PDEs) are fundamental tools for modeling
physical phenomena, yet most PDEs of practical interest cannot be solved
analytically and require numerical approximations. The feasibility of such
numerical methods, however, is ultimately constrained by the limitations of
existing computation models. Since digital computers constitute the primary
physical realizations of numerical computation, and Turing machines define
their theoretical limits, the question of Turing computability of PDE solutions
arises as a problem of fundamental theoretical significance. The Turing
computability of PDE solutions provides a rigorous framework to distinguish
equations that are, in principle, algorithmically solvable from those that
inherently encode undecidable or non-computable behavior. Once computability is
established, complexity theory extends the analysis by quantifying the
computational resources required to approximate the corresponding PDE
solutions. In this work, we present a novel framework based on least-squares
variational formulations and their associated gradient flows to study the
computability and complexity of PDE solutions from an optimization perspective.
Our approach enables the approximation of PDE solution operators via discrete
gradient flows, linking structural properties of the PDE, such as coercivity,
ellipticity, and convexity, to the inherent complexity of their solutions. This
framework characterizes both regimes where PDEs admit effective numerical
solvers in polynomial-time and those exhibiting complexity blowup, where the
input data possess polynomial-time complexity, yet the solution itself scales
super-polynomially.

</details>


### [7] [A numerical method for the fractional Zakharov-Kuznetsov equation](https://arxiv.org/abs/2510.21355)
*Mukul Dwivedi,Andreas Rupp*

Main category: math.NA

TL;DR: A fully discrete Fourier spectral Galerkin method for the fractional Zakharov-Kuznetsov equation with spectral convergence properties.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient numerical method for the fractional Zakharov-Kuznetsov equation that preserves conservation laws and handles the nonlocal fractional dispersion term.

Method: Fourier spectral Galerkin discretization in space with integrating-factor Runge-Kutta time stepping, preserving discrete mass, momentum, and energy.

Result: Proved uniform convergence of semi-discrete solutions, spectral convergence of order O(N^{-r}) for H^r initial data, and exponential convergence for analytic solutions.

Conclusion: The method is effective for fZK equations across various fractional orders, with theoretical convergence rates validated by numerical experiments.

Abstract: This paper develops a fully discrete Fourier spectral Galerkin (FSG) method
for the fractional Zakharov-Kuznetsov (fZK) equation posed on a two-dimensional
periodic domain. The equation generalizes the classical ZK model to incorporate
nonlocal dispersion through a fractional Laplacian of order $\alpha \in [1,2]$.
We first propose a semi-discrete FSG scheme in space that preserves the
discrete analogs of mass, momentum, and energy. The existence and uniqueness of
semi-discrete solutions are established. Using compactness arguments, we prove
the uniform convergence of the semi-discrete approximations to the unique
solution of the fZK equation for the periodic initial data in
$H^{1+\alpha}_{\mathrm{per}}(\Omega)$. The method achieves spectral convergence
of order $\mathcal{O}(N^{-r})$ for initial data in $H^r_{\mathrm{per}}$ with $r
\geq \alpha+1$, and exponential convergence for analytic solutions utilizing a
modified projection. An efficient integrating-factor Runge-Kutta time
discretization is designed to handle the stiff fractional term, and an error
analysis is presented. Numerical experiments validate the theoretical results
and demonstrate the method's effectiveness across various fractional orders.

</details>


### [8] [Exponential integrators for parabolic problems with non-homogeneous boundary conditions](https://arxiv.org/abs/2510.21381)
*Carlos Arranz-Simón,Alexander Ostermann*

Main category: math.NA

TL;DR: Extending exponential Runge-Kutta methods to handle non-homogeneous boundary conditions using a correction strategy based on smooth boundary data extensions, which recovers expected convergence orders and enables higher-order accuracy.


<details>
  <summary>Details</summary>
Motivation: Exponential Runge-Kutta methods are typically developed for homogeneous boundary conditions, but many practical problems involve non-homogeneous boundary conditions which cause order reduction in standard implementations.

Method: Introduce a correction strategy using smooth extensions of boundary data to reformulate the problem as a homogeneous one with modified source term, allowing application of standard exponential integrators.

Result: For linear problems, the corrected schemes recover expected convergence order and can achieve order 2s for s-stage Gauss collocation methods. For semilinear problems, the approach preserves convergence orders guaranteed by exponential Runge-Kutta methods.

Conclusion: The proposed correction strategy effectively handles non-homogeneous boundary conditions in exponential Runge-Kutta methods, recovering and potentially enhancing convergence orders, with numerical experiments validating the theoretical results.

Abstract: Exponential Runge-Kutta methods are a well-established tool for the numerical
integration of parabolic evolution equations. However, these schemes are
typically developed under the assumption of homogeneous boundary conditions. In
this paper, we extend classical convergence results to the case of
non-homogeneous boundary conditions. Since non-homogeneous boundary conditions
typically cause order reduction, we introduce a correction strategy based on
smooth extensions of the boundary data. This results in a reformulation as a
homogeneous problem with modified source term, to which standard exponential
integrators can be applied. For linear problems, we prove that the corrected
schemes recover the expected convergence order, and hat higher orders can be
attained with suitable quadrature rules, reaching order $2s$ for s-stage Gauss
collocation methods. For semilinear problems, our approach preserves the
convergence orders guaranteed by exponential Runge-Kutta methods satisfying the
corresponding stiff order conditions. Numerical experiments validate the
theoretical findings.

</details>


### [9] [Matrix- and tensor-oriented numerical schemes for the evolutionary space-fractional complex Ginzburg--Landau equation](https://arxiv.org/abs/2510.21394)
*Marco Caliari,Fabio Cassini*

Main category: math.NA

TL;DR: The paper presents efficient tensor-based methods for solving multidimensional space-fractional complex Ginzburg-Landau equations using high-performance computing techniques.


<details>
  <summary>Details</summary>
Motivation: To develop efficient numerical methods for solving complex multidimensional evolutionary space-fractional equations that can leverage modern computing hardware like GPUs.

Method: Uses matrix- and tensor-oriented approaches with spatial semidiscretization, stiff-resistant time integration schemes, and efficient computation of special matrix functions by exploiting tensor structure and high-performance BLAS operations.

Result: Achieves speedups of 1-2 orders of magnitude compared to state-of-the-art methods in 2D and 3D numerical experiments, with effective GPU utilization on both consumer and professional hardware.

Conclusion: The proposed tensor-based approach provides reliable and superior performance for solving multidimensional space-fractional equations, enabling significant computational speedups through efficient hardware utilization.

Abstract: In this manuscript, we propose matrix- and tensor-oriented methods for the
numerical solution of the multidimensional evolutionary space-fractional
complex Ginzburg--Landau equation. After a suitable spatial semidiscretization,
the resulting system of ordinary differential equations is time integrated with
stiff-resistant schemes. The needed actions of special matrix functions (e.g.,
inverse, exponential, and the so-called $\varphi$-functions) are efficiently
computed in a direct way by exploiting the underlying tensor structure of the
task and taking advantage of high performance BLAS and parallelizable pointwise
operations. Several numerical experiments in 2D and 3D, where we apply the
proposed technique in the context of linearly-implicit and exponential-type
schemes, show the reliability and superiority of the approach against the
state-of-the-art, allowing to obtain speedups which range from one to two
orders of magnitude. Finally, we demonstrate that in our context a single GPU
can be effectively exploited to boost the computations both on consumer- and
professional-level hardware.

</details>


### [10] [Macro-element Refinement schemes for THB-Splines: Applications to Bézier Projection and Structure-Preserving Discretizations](https://arxiv.org/abs/2510.21429)
*Kevin Dijkstra,Carlotta Giannelli,Deepesh Toshniwal*

Main category: math.NA

TL;DR: Novel adaptive refinement strategy for Isogeometric Analysis using THB-splines that refines blocks of elements (q-boxes) based on spline degree and application, enabling local linear independence and exact de Rham complexes without mesh modifications.


<details>
  <summary>Details</summary>
Motivation: Previous methods required mesh modifications to retain crucial properties like local linear independence and exact discrete de Rham complexes. The goal is to simplify implementation while preserving these properties in adaptive simulations.

Method: Macro-element-based refinement technique that refines q-boxes (blocks of elements) where q is determined by spline degree and application. For Bezier projection: refine p-boxes; for structure-preserving discretizations: refine (p+1)-boxes.

Result: The approach ensures THB-splines are locally linearly independent in refined boxes, enabling straightforward extension of Bezier projection algorithm. For structure-preserving discretizations, it meets sufficient conditions for exact THB-spline de Rham complex in any dimension.

Conclusion: The framework enables adaptive simulations without additional mesh modifications, with effectiveness supported by theoretical proofs and numerical experiments showing optimal convergence for adaptive approximation and Navier-Stokes simulations.

Abstract: This paper introduces a novel adaptive refinement strategy for Isogeometric
Analysis (IGA) using Truncated Hierarchical B-splines (THB-splines). The
proposed strategy enhances locally-refined meshes for specific applications,
simplifying implementation. We focus on two key applications: an $L^2$-stable
local projector for THB-splines via B\'ezier projection [Dijkstra and Toshniwal
(2023)], and structure-preserving discretizations using THB-splines [Evans et
al. (2020), Shepherd and Toshniwal (2024)]. Previous methods required mesh
modifications to retain crucial properties like local linear independence and
the exactness of discrete de Rham complexes. Our approach introduces a
macro-element-based refinement technique, refining $\vec{q} =
q_1\times\cdots\times q_n$ blocks of elements, termed $\vec{q}$-boxes, where
the block size $\vec{q}$ is determined by the spline degree and application.
For the B\'ezier projection, we refine $\vec{p}$-boxes (i.e., $\vec{q} =
\vec{p}$), ensuring THB-splines are locally linearly independent in these
boxes, which enables a straightforward extension of the B\'ezier projection
algorithm, greatly improving upon Dijkstra and Toshniwal (2023). For
structure-preserving discretizations, we refine $(\vec{p+1})$-boxes (i.e.,
$\vec{q} = \vec{p}+\vec{1}$), demonstrating that this choice meets the
sufficient conditions for ensuring the exactness of the THB-spline de Rham
complex, as outlined by Shepherd and Toshniwal (2024), in any dimension. This
critical aspect allows for adaptive simulations without additional mesh
modifications. The effectiveness of our framework is supported by theoretical
proofs and numerical experiments, including optimal convergence for adaptive
approximation and simulations of the incompressible Navier-Stokes equations.

</details>


### [11] [The temporal domain derivative in inverse acoustic obstacle scattering](https://arxiv.org/abs/2510.21471)
*Marvin Knöller,Jörg Nick*

Main category: math.NA

TL;DR: This paper develops a mathematical framework for reconstructing scattering object boundaries using time-domain acoustic measurements, with analysis of domain derivatives and a Gauss-Newton reconstruction algorithm.


<details>
  <summary>Details</summary>
Motivation: To solve inverse scattering problems by mapping scattering objects to wave equation solutions at measurement points, enabling efficient boundary reconstruction from limited time-domain data.

Method: Analyzes the Fréchet derivative of the scattering operator, develops well-posedness theory for domain derivatives, applies convolution quadrature for time discretization, and implements Gauss-Newton method with discrete domain derivatives.

Result: Establishes theoretical foundation for domain derivatives in time-dependent acoustic scattering, provides stable time discretization scheme, and demonstrates successful boundary reconstruction through numerical examples in 2D.

Conclusion: The proposed method effectively reconstructs scattering boundaries from time-domain measurements using domain derivative analysis and Gauss-Newton optimization, with proven convergence and numerical validation.

Abstract: This work describes and analyzes the domain derivative for a time-dependent
acoustic scattering problem. We study the nonlinear operator that maps a
sound-soft scattering object to the solution of the time-dependent wave
equation evaluated at a finite number of points away from the obstacle. The
Fr\'echet derivative of this operator with respect to variations of the
scatterer coincides with point evaluations of the temporal domain derivative.
The latter is the solution to another time-dependent scattering problem, for
which a well-posedness result is shown under sufficient temporal regularity of
the incoming wave. Applying convolution quadrature to this scattering problem
gives a stable and provably convergent semi-discretization in time, provided
that the incoming wave is sufficient regular. Using the discrete domain
derivative in a Gauss--Newton method, we describe an efficient algorithm to
reconstruct the boundary of an unknown scattering object from time domain
measurements in a few points away from the boundary. Numerical examples for the
acoustic wave equation in two dimensions demonstrate the performance of the
method.

</details>


### [12] [Error Estimates for Sparse Tensor Products of B-spline Approximation Spaces](https://arxiv.org/abs/2510.21517)
*Clément Guillet*

Main category: math.NA

TL;DR: This paper introduces B-spline approximation spaces on general geometric domains using sparse-grid tensor products, proving mathematical equivalence between two construction methods and deriving error estimates showing reduced degrees of freedom while maintaining approximation order.


<details>
  <summary>Details</summary>
Motivation: To develop efficient approximation spaces for general geometric domains that achieve high approximation accuracy with significantly fewer degrees of freedom compared to standard tensor product spaces.

Method: Construct B-spline approximation spaces using sparse-grid tensor products of univariate spaces in parameter domain, mapped to physical domain via geometric parametrization. Two equivalent approaches: sparse-grid combination technique and hierarchical subspace decomposition.

Result: Proved mathematical equivalence of the two construction methods. Derived approximation error estimates showing same approximation order as standard tensor products but with fewer degrees of freedom. Identified stronger regularity requirements for non-tensor-product domains.

Conclusion: Sparse-grid B-spline spaces provide efficient approximation on general domains, achieving optimal convergence with reduced computational cost, though requiring stronger solution regularity assumptions for non-tensor-product domains.

Abstract: This work introduces and analyzes B-spline approximation spaces defined on
general geometric domains obtained through a mapping from a parameter domain.
These spaces are constructed as sparse-grid tensor products of univariate
spaces in the parameter domain and are mapped to the physical domain via a
geometric parametrization. Both the univariate approximation spaces and the
geometric mapping are built using maximally smooth B-splines. We construct two
such spaces, employing either the sparse-grid combination technique or the
hierarchical subspace decomposition of sparse-grid tensor products, and we
prove their mathematical equivalence. Furthermore, we derive approximation
error estimates and inverse inequalities that highlight the advantages of
sparse-grid tensor products. Specifically, under suitable regularity
assumptions on the solution, these spaces achieve the same approximation order
as standard tensor product spaces while using significantly fewer degrees of
freedom. Additionally, our estimates indicate that, in the case of
non-tensor-product domains, stronger regularity assumptions on the solution --
particularly concerning isotropic (non-mixed) derivatives -- are required to
achieve optimal convergence rates compared to sparse-grid methods defined on
tensor-product domains.

</details>


### [13] [A Stabilized Trace FEM for Surface Cahn--Hilliard Equations: Analysis and Simulations](https://arxiv.org/abs/2510.21662)
*Deepika Garg,Maxim Olshanskii*

Main category: math.NA

TL;DR: A computational method combining stabilized trace finite elements for spatial discretization with implicit-explicit temporal scheme for solving Cahn-Hilliard equation on surfaces, using unfitted finite elements with background mesh and level-set representation.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient numerical method for solving the Cahn-Hilliard equation on surfaces, which is important for modeling phase separation phenomena on curved domains.

Method: Combines stabilized trace finite element method for spatial discretization with implicit-explicit temporal scheme, using unfitted finite elements with fixed background mesh and level-set function for implicit surface representation.

Result: Established numerical stability with energy dissipation law, derived optimal-order error estimates for simplicial meshes and finite element spaces of order m≥1, and demonstrated effectiveness through numerical experiments on 2D closed surfaces.

Conclusion: The method is effective, robust, and shows good convergence properties, with theoretical results confirmed by numerical experiments on various surfaces.

Abstract: This paper addresses the analysis and numerical assessment of a computational
method for solving the Cahn--Hilliard equation defined on a surface. The
proposed approach combines the stabilized trace finite element method for
spatial discretization with an implicit--explicit scheme for temporal
discretization. The method belongs to a class of unfitted finite element
methods that use a fixed background mesh and a level-set function for implicit
surface representation. We establish the numerical stability of the discrete
problem by showing a suitable energy dissipation law for it. We further derive
optimal-order error estimates assuming simplicial background meshes and finite
element spaces of order $m \geq 1$. The effectiveness of the method is
demonstrated through numerical experiments on several two-dimensional closed
surfaces, confirming the theoretical results and illustrating the robustness
and convergence properties of the scheme.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [14] [Robust Synchronization of Time-Fractional Memristive Hopfield Neural Networks](https://arxiv.org/abs/2510.20949)
*Yuncheng You*

Main category: math.AP

TL;DR: Study of robust synchronization in time-fractional Hopfield neural networks with memristive couplings and Hebbian learning rules, establishing threshold conditions for synchronization.


<details>
  <summary>Details</summary>
Motivation: To analyze neural networks with strong memory and long-range path-dependence in learning processes, which exhibit complex dynamics due to fractional calculus and memristive elements.

Method: Using scaled group estimates to prove global dissipativity of solution dynamics under general assumptions, and establishing threshold conditions for synchronization.

Result: Proved that the neural network dynamics is globally dissipative and established an explicitly computable synchronizing threshold that decreases with fractional order α ∈ (0,1).

Conclusion: Robust synchronization can be achieved when the interneuron coupling strength coefficient satisfies the derived threshold condition, which depends on the fractional order and original parameters.

Abstract: In this paper we study robust synchronization of time-fractional Hopfield
neural networks with memristive couplings and Hebbian learning rules. This new
model of artificial neural networks exhibits strong memory and long-range
path-dependence in learning processes. Through scaled group estimates it is
proved that under rather general assumptions the solution dynamics is globally
dissipative. The main result established a threshold condition for achieving
robust synchronization of the neural networks if it is satisfied by the
interneuron coupling strength coefficient. The synchronizing threshold is
explicitly computable in terms of the original parameters and strictly
decreasing for the fractional order $\alpha \in (0, 1)$.

</details>


### [15] [On the Propulsion of a Rigid Body in a Viscous Liquid by Time-Periodic Force with a Zero Average](https://arxiv.org/abs/2510.20982)
*Joris Edelmann,Giovanni P. Galdi,Mher M. Karakouzian,Thomas Richter*

Main category: math.AP

TL;DR: Analysis of propulsion in viscous fluids using periodic forces with zero average, focusing on internal mass oscillation. Conditions for second-order propulsion are proven and tested numerically.


<details>
  <summary>Details</summary>
Motivation: To understand propulsion mechanisms in viscous fluids when using periodic forces with zero average, particularly relevant for systems with oscillating internal masses.

Method: Analytical and numerical analyses, including rigorous proof of propulsion conditions and numerical integration of equations for bodies with/without fore-and-aft symmetry.

Result: Proved necessary/sufficient conditions for second-order propulsion, confirmed by numerical tests for asymmetric bodies. Found propulsion occurs at higher orders for symmetric bodies like ellipsoids.

Conclusion: Propulsion is possible through periodic forces with zero average, with different mechanisms for symmetric vs asymmetric bodies, opening avenues for further analytical studies.

Abstract: We perform analytical and numerical analyses of the propulsion of a rigid
body in a viscous fluid subjected to a periodic force with zero average over a
period. This general formulation specifically addresses the significant case,
where propulsion is generated by the oscillation of a mass located in an
internal cavity of the body. We provide a rigorous proof of the necessary and
sufficient conditions for propulsion at the second order of magnitude of the
force. These conditions are implemented and confirmed by numerical tests for
bodies without fore-and-aft symmetry, while they are silent for bodies with
such symmetry, like round ellipsoids. Consequently, in this case, propulsion
can only occur at an order higher than the second. This problem is investigated
by numerically integrating the entire set of equations, and the result shows
that, in fact, propulsion does occur, thus opening new avenues for further
analytical studies.

</details>


### [16] [$L_p$-estimates of the conormal derivative problem for parabolic equations with time measurable coefficients and $A_p$-weights](https://arxiv.org/abs/2510.21139)
*Hongjie Dong,Pilgyu Jung,Doyoon Kim*

Main category: math.AP

TL;DR: Weighted mixed-norm estimates for divergence-type parabolic equations on Reifenberg-flat domains with conormal derivative boundary conditions, with coefficients measurable in time and having small mean oscillations in space.


<details>
  <summary>Details</summary>
Motivation: To establish boundary estimates for parabolic equations on irregular domains with minimal regularity assumptions on coefficients, addressing the challenge of low regularity in time variable.

Method: Employ half-time derivative estimates to overcome regularity issues, working with divergence-type parabolic equations on Reifenberg-flat domains with conormal derivative boundary conditions.

Result: Successfully derived weighted mixed-norm estimates for the boundary value problem despite the coefficients being only measurable in time and having small mean oscillations in space.

Conclusion: The half-time derivative technique provides an effective approach for handling boundary regularity problems in parabolic equations with minimal coefficient regularity, particularly on irregular domains like Reifenberg-flat domains.

Abstract: This paper investigates weighted mixed-norm estimates for divergence-type
parabolic equations on Reifenberg-flat domains with the conormal derivative
boundary condition. The leading coefficients are assumed to be merely
measurable in the time variable and to have small mean oscillations in the
spatial variables. In deriving the boundary estimates, we overcome a regularity
issue by employing half-time derivative estimates.

</details>


### [17] [Existence and stability of curved fronts for spatially periodic combustion reaction-diffusion equations in $\mathbb{R}^N$](https://arxiv.org/abs/2510.21163)
*Wei-Jie Sheng,Xin-Tian Zhang*

Main category: math.AP

TL;DR: This paper proves the existence, uniqueness, and asymptotic stability of curved fronts with polytope-like shapes for combustion reaction-diffusion equations in periodic media in R^N (N≥2).


<details>
  <summary>Details</summary>
Motivation: To study curved combustion fronts in spatially periodic media, extending beyond the standard planar front analysis to more complex geometric shapes.

Method: Assumes existence of moving pulsating fronts for any propagation direction, and constructs suitable super- and sub-solutions to prove the existence of curved fronts with polytope-like shapes.

Result: Established the existence of curved fronts with polytope-like shapes in R^N, and proved their uniqueness and asymptotic stability.

Conclusion: The paper successfully demonstrates that curved combustion fronts with specific geometric properties exist, are unique, and stable in periodic media for dimensions N≥2.

Abstract: This paper is concerned with curved fronts of combustion reaction-diffusion
equations in spatially periodic media in $\mathbb{R}^N$ $(N\geq2)$. Under the
assumption that there are moving pulsating fronts for any given propagation
direction $e \in \mathbb{S}^{N-1}$, and by constructing suitable super- and
sub-solutions, we prove the existence of a curved front with polytope-like
shape in $\mathbb{R}^N$. Then we show that the curved front is unique and
asymptotically stable.

</details>


### [18] [Axisymmetric self-similar solutions to the MHD equations](https://arxiv.org/abs/2510.21194)
*Shaoheng Zhang*

Main category: math.AP

TL;DR: Axisymmetric self-similar solutions to stationary MHD equations are studied, showing that in R^3\{0}, velocity is a Landau solution with zero magnetic field, and in half-space with boundary conditions, solutions are trivial.


<details>
  <summary>Details</summary>
Motivation: To understand the structure and properties of axisymmetric self-similar solutions in magnetohydrodynamics (MHD) under different domains and boundary conditions.

Method: Analysis of axisymmetric self-similar solutions to stationary MHD equations in cylindrical coordinates, with specific velocity field structure and magnetic field constraints.

Result: In R^3\{0}, velocity field must be a Landau solution and magnetic field vanishes; in half-space with no-slip or Navier slip boundary conditions, all axisymmetric self-similar solutions are trivial.

Conclusion: Axisymmetric self-similar MHD solutions exhibit strong constraints - either reducing to classical Landau solutions with no magnetic effects in full space, or becoming completely trivial in bounded domains with physical boundary conditions.

Abstract: We study the axisymmetric self-similar solutions $(\mathbf{u},\mathbf{B})$ to
the stationary MHD equations, where
$\mathbf{u}=u^r(r,z)\mathbf{e}_{r}+u^{\theta}(r,z)\mathbf{e}_{\theta}+u^z(r,z)\mathbf{e}_{z}$,
$\mathbf{B}=B^{\theta}(r,z)\mathbf{e}_{\theta}$ in cylindrical coordinates, and
$u^r$ satisfies $u^r<\frac{1}{3r}+\frac{2r}{3}$ on the unit sphere. Our first
result shows that in $\mathbb{R}^3\setminus\{0\}$, $\mathbf{u}$ is a Landau
solution and $\mathbf{B}\equiv0$. Our second result establishes the triviality
of axisymmetric self-similar solutions in the half-space $\mathbb{R}^3_+$ with
the no-slip boundary condition or the Navier slip boundary condition.

</details>


### [19] [On the continuity in time and the exponential decay of solutions to a generalized Navier--Stokes--Fourier system in 2D](https://arxiv.org/abs/2510.21218)
*Miroslav Bulíček,Petr Kaplický,Lucie Wintrová*

Main category: math.AP

TL;DR: Global weak solutions exist for power-law fluids (p≥2) with finite energy initial data, satisfying entropy equality. Temperature is proven to be time-continuous, enabling construction of a Lyapunov functional that shows steady solutions are nonlinearly stable and exponentially attractive.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous mathematical foundations for power-law fluid flows, particularly proving time continuity of temperature and developing stability analysis tools for such systems.

Method: Mathematical analysis of generalized Newtonian incompressible heat-conducting fluids with power-law constitutive equations. Proving existence of global weak solutions satisfying entropy equality, establishing time continuity of temperature, and constructing Lyapunov functionals.

Result: For p≥2 with finite energy initial data, global weak solutions exist that satisfy entropy equality. Temperature is proven to be continuous in time. A Lyapunov functional is constructed showing steady solutions are nonlinearly stable and exponentially attractive.

Conclusion: The work provides rigorous mathematical framework for power-law fluid flows, establishing key properties like temperature continuity and stability, with implications for understanding long-term behavior of such systems.

Abstract: We consider the flow of a generalized Newtonian incompressible
heat-conducting fluid in a bounded domain, subject to homogeneous Dirichlet
boundary conditions for velocity and Dirichlet boundary conditions for
temperature. For a fluid whose constitutive equation for the Cauchy stress
follows a power law with exponent~$p$, we prove that, for~$p\ge 2$ and for
initial data with finite energy, there always exists a global-in-time weak
solution that additionally satisfies the entropy equality. The main novelty of
this work is that we rigorously establish the continuity of temperature with
respect to time, a property not previously proven in this setting. This time
continuity allows us to construct a Lyapunov functional designed specifically
for the problem, which in turn implies that the steady solution is nonlinearly
stable and attracts all suitable weak solutions, even exponentially.

</details>


### [20] [Interior Hessian estimates for sum Hessian quotient equation](https://arxiv.org/abs/2510.21301)
*Changyu Ren,Ziyi Wang*

Main category: math.AP

TL;DR: Interior C² estimates for sum Hessian quotient equations, including Pogorelov type estimates for different parameter ranges.


<details>
  <summary>Details</summary>
Motivation: To establish interior regularity estimates for sum Hessian quotient equations, which are important in geometric analysis and PDE theory.

Method: Develop interior estimates and Pogorelov type estimates for the equations with parameters 0≤l<k<n, and a weaker Pogorelov estimate for k=n with 0≤l<n-1.

Result: Successfully established interior C² estimates and Pogorelov type estimates for the specified parameter ranges of sum Hessian quotient equations.

Conclusion: The paper provides important regularity results for sum Hessian quotient equations, with different types of estimates depending on the parameter relationships between k, l, and n.

Abstract: This paper is devoted to the interior $C^2$ estimates for a class of sum
Hessian quotient equations. For $0\leq l<k<n$, we establish the interior
estimates and the Pogorelov type estimates. In the case $k=n$, we obtain a
weaker Pogorelov type estimate for $0\leq l<n-1$.

</details>


### [21] [Semiclassical limit of cubic nonlinear Schrödinger equations for mixed states](https://arxiv.org/abs/2510.21313)
*Daniel Han-Kwan,Frédéric Rousset*

Main category: math.AP

TL;DR: The paper justifies the semiclassical limit from cubic Nonlinear Schrödinger equations for mixed states to a singular Vlasov equation, under quantum Penrose stability conditions.


<details>
  <summary>Details</summary>
Motivation: To study the semiclassical limit of cubic Nonlinear Schrödinger equations for mixed states and establish rigorous justification for the transition to Vlasov-type equations.

Method: Analysis of the semiclassical limit using finite Sobolev regularity data and quantum Penrose stability conditions for velocity profiles.

Result: Successfully justified the limit to a singular Vlasov equation for data satisfying quantum Penrose stability, which holds for small data in both focusing/defocusing cases and perturbations of physically relevant profiles in defocusing case.

Conclusion: The semiclassical limit from cubic NLS to singular Vlasov equation is rigorously established under quantum Penrose stability conditions, applicable to various physically relevant scenarios.

Abstract: In this work, we study the semiclassical limit of cubic Nonlinear
Schr\"odinger equations for mixed states. We justify the limit to a singular
Vlasov equation (in which the force field is proportional to the gradient of
the density), for data with finite Sobolev regularity whose velocity profiles
satisfy a quantum Penrose stability condition. This latter condition is always
satisfied for small data (with a smallness condition independent of the
semiclassical parameter) both in the focusing and the defocusing case, and for
small perturbations of a large class of physically relevant examples in the
defocusing case, such as local Maxwellian-like profiles.

</details>


### [22] [A general Frobenius' Theorem via the Transport of Currents](https://arxiv.org/abs/2510.21478)
*Paolo Bonicatto*

Main category: math.AP

TL;DR: Extends the classical result on commuting flows from smooth vector fields to cases with bounded Lipschitz vector fields and singular vector-valued measures (normal 1-currents), connecting this to transport equations and interpreting Alfvén's theorem as a time-dependent Frobenius' theorem.


<details>
  <summary>Details</summary>
Motivation: To generalize the classical differential geometry result about commuting flows beyond smooth vector fields, allowing for more singular cases including vector-valued measures, and to establish connections with transport equations and magnetohydrodynamics.

Method: Studies two evolutionary PDEs (Vector Advection Equation and Geometric Transport Equation) for transporting vector quantities, building on recent advances in Geometric Transport Equation for currents. Uses analytical methods to handle singular vector fields and measures.

Result: Proves that flows commute when the Lie Bracket vanishes in the generalized setting with bounded Lipschitz vector fields and singular vector-valued measures. Shows Alfvén's theorem can be interpreted as a time-dependent version of Frobenius' Theorem.

Conclusion: Successfully extends classical commuting flow results to more singular settings, establishes connections between transport equations and geometric flows, and provides new interpretations of fundamental results in magnetohydrodynamics through the lens of differential geometry.

Abstract: A classical result in Differential Geometry states that the flows of two
smooth vector fields commute if and only if their Lie Bracket vanishes. In this
work, we extend this result to a more general setting where one of the vector
fields is bounded and Lipschitz, while the other may be a singular
vector-valued measure, i.e. a normal 1-current. This result is achieved via the
study of two distinct evolutionary PDEs describing the transport of vector
quantities (the Vector Advection Equation and the Geometric Transport
Equation). Furthermore, we show that a celebrated theorem by Alfv\'en in
Magnetohydrodynamics can be interpreted as a suitable time-dependent version of
Frobenius' Theorem. Our approach builds on recent advances concerning the
Geometric Transport Equation for currents [5, 6].

</details>


### [23] [Constant sign and nodal solutions for singular quasilinear elliptic systems](https://arxiv.org/abs/2510.21489)
*Nouredine Medjoudj,Abdelkrim Moussaoui*

Main category: math.AP

TL;DR: Existence of three nontrivial solutions for singular quasilinear elliptic systems with Dirichlet boundary conditions, including two opposite-sign constant solutions and one nodal solution.


<details>
  <summary>Details</summary>
Motivation: To establish existence of multiple solutions for singular quasilinear elliptic systems, particularly focusing on sign-changing solutions beyond constant-sign solutions.

Method: Using Leray-Schauder topological degree combined with sub-supersolutions method and truncation arguments.

Result: Proved existence of at least three nontrivial solutions: two with opposite constant signs and one nodal solution with components of opposite sign (synchronized sign changes for sign-coupled systems).

Conclusion: The approach successfully establishes multiplicity of solutions for singular quasilinear elliptic systems, providing both constant-sign and nodal solutions.

Abstract: We consider singular quasilinear elliptic systems with homogeneous Dirichlet
boundary condition. Using Leray-Schauder topological degree, combined with the
sub-supersolutions method and suitable truncation arguments, we establish the
existence of at least three nontrivial solutions, two of which are of opposite
constant sign. The third solution is nodal and exhibits components of at least
opposite constant sign. In the case of a sign-coupled system, these components
are of changing and synchronized sign.

</details>


### [24] [Nash's $G$ bound for the Kolmogorov equation](https://arxiv.org/abs/2510.21621)
*Helge Dietert,Lukas Niebel*

Main category: math.AP

TL;DR: Proof of Nash's G bound for Kolmogorov equation with rough coefficients using kinetic trajectories, recovering sharp lower bounds on fundamental solution and Harnack inequality.


<details>
  <summary>Details</summary>
Motivation: To extend Nash's classical results for parabolic equations to the kinetic setting of Kolmogorov equations with rough coefficients.

Method: Inspired by Nash (1958) and Fabes-Stroock (1986), employs critical kinetic trajectories to transfer parabolic methods to kinetic setting.

Result: Successfully proves Nash's G bound for Kolmogorov equation with rough coefficients and recovers sharp lower bound on fundamental solution.

Conclusion: Provides alternative proof of Harnack inequality for Kolmogorov equation through established G bound and fundamental solution bounds.

Abstract: We prove Nash's $G$ bound for the Kolmogorov equation with rough
coefficients. Our proof is inspired by the treatment of the parabolic problem
by Nash (1958) and Fabes and Stroock (1986). To transfer their ideas to the
kinetic setting, we employ critical kinetic trajectories. From Nash's $G$
bound, we recover the sharp lower bound on the fundamental solution and thus
provide an alternative proof of the Harnack inequality for the Kolmogorov
equation.

</details>


### [25] [Describing smooth small-data solutions to a quasilinear hyperbolic-parabolic system by $W^{1,p}$ energy analysis](https://arxiv.org/abs/2510.21660)
*Leander Claes,Michael Winkler*

Main category: math.AP

TL;DR: This paper studies a thermoviscoelastic system with temperature-dependent parameters, proving local existence of classical solutions and global existence with exponential decay under smallness conditions on parameters and initial data.


<details>
  <summary>Details</summary>
Motivation: To analyze thermoviscoelastic systems where core parameters like viscosity and thermal conductivity depend on temperature, extending beyond classical models with constant parameters.

Method: Uses PDE analysis to prove local existence of classical solutions for arbitrary positive parameters, then establishes global existence and exponential decay by detecting dissipative properties of functionals involving gradient norms in L^p spaces.

Result: Local existence proven for arbitrary parameter values and initial data size. Global existence and exponential decay of gradients achieved under smallness conditions on a/γ(0) and |f'(Θ★)|·|F(Θ★)|/(D·γ(Θ★)), with initial data near constant states.

Conclusion: The system exhibits rich behavior: local solutions exist generally, while global solutions with exponential decay require parameter restrictions and small initial perturbations from constant states, demonstrating the interplay between thermal and mechanical effects.

Abstract: In bounded $n$-dimensonal domains with $n\ge 1$, this manuscript examines an
initial-boundary value problem for the system \[
  \left\{ \begin{array}{l}
  u_{tt} = \nabla \cdot (\gamma(\Theta) \nabla u_t) + a \nabla \cdot
(\gamma(\Theta) \nabla u) + \nabla\cdot f(\Theta),
  \Theta_t = D\Delta\Theta + \Gamma(\Theta) |\nabla u_t|^2 + F(\Theta)\cdot
\nabla u_t,
  \end{array} \right. \] which in the case $n=1$ and with $\gamma\equiv \Gamma$
as well as $f\equiv F$ reduces to the classical model for the evolution of
strains and temperatures in thermoviscoelasticity. Unlike in previous related
studies, the focus here is on situations in which besides $f$ and $F$, also the
core ingredients $\gamma$ and $\Gamma$ may depend on the temperature variable
$\Theta$.
  Firstly, a statement on local existence of classical solutions is derived for
arbitrary $a>0, D>0$ as well as $0<\gamma\in C^2([0,\infty))$ and
$0\le\Gamma\in C^1([0,\infty))$, for functions $f\in
C^2([0,\infty);{\mathbb{R}}^n)$ and $F\in C^1([0,\infty);{\mathbb{R}}^n)$ with
$F(0)=0$, and for suitably regular initial data of arbitrary size. Secondly, it
is seen that for each $p\ge 2$ such that $p>n$ there exists $\delta(p)>0$ with
the property that whenever in addition to the above we have \[
  \frac{a}{\gamma(0)} \le \delta(p)
  \qquad \mbox{and} \qquad
  \frac{|f'(\Theta_\star)| \cdot |F(\Theta_\star)|}{D \cdot
\gamma(\Theta_\star)}
  \le \delta(p), \] for initial data suitably close to the constant level given
by $u=0$ and $\Theta=\Theta_\star$, with any fixed $\Theta_\star\ge 0$, these
solutions are actually global in time and have the property that $\nabla u_t,
\nabla u$ and $\nabla\Theta$ decay exponentially fast in $L^p$. This is
achieved by detecting suitable dissipative properties of functionals involving
norms of these gradients in $L^p$ spaces.

</details>


### [26] [Recovering Initial States in Certain Quasilinear Parabolic Problems from Time Averages](https://arxiv.org/abs/2510.21687)
*Bogdan-Vasile Matioc,Christoph Walker*

Main category: math.AP

TL;DR: The paper shows that initial states in quasilinear parabolic equations can be uniquely recovered from small time averages, with applications to chemotaxis and reaction-diffusion systems.


<details>
  <summary>Details</summary>
Motivation: To solve the inverse problem of reconstructing initial states from time-averaged data in quasilinear parabolic equations, which has practical applications in biological and chemical systems.

Method: Uses mathematical analysis under regularity assumptions on quasilinear structure and superlinear growth conditions near zero for the semilinear part.

Result: Proves that initial states can be uniquely recovered from small time averages taken over arbitrary time periods.

Conclusion: The method is applicable to chemotaxis models and reaction-diffusion systems, providing a theoretical foundation for initial state reconstruction.

Abstract: The inverse problem of reconstructing the initial state in quasilinear
parabolic equations from time averages is investigated. Under suitable
regularity assumptions on the quasilinear structure and a superlinear growth
condition near zero for the semilinear part, it is shown that the initial state
can be uniquely recovered from small time averages taken over an arbitrary time
period. The applicability of the result is demonstrated for certain chemotaxis
models and reaction-diffusion systems.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [27] [Interpolative separable density fitting on adaptive real space grids](https://arxiv.org/abs/2510.20826)
*Hai Zhu,Chia-Nan Yeh,Miguel A. Morales,Leslie Greengard,Shidong Jiang,Jason Kaye*

Main category: physics.comp-ph

TL;DR: Generalized interpolative separable density fitting (ISDF) method with adaptive real space grids for highly localized basis functions, enabling scalable electronic structure simulations for core-level excitations.


<details>
  <summary>Details</summary>
Motivation: To enable efficient compression of electron repulsion integrals (ERI) for highly localized single-particle basis functions that are intractable with uniform grid methods, particularly for all-electron basis sets and core-level excitations.

Method: Extended ISDF method with adaptive real space grids using dual-space multilevel kernel-splitting for solving Poisson equations. Adaptive grids are generated via high-order accurate procedure satisfying user-specified error tolerance, constructed from single-particle basis function grids.

Result: ISDF compression efficiency for ERI tensor with highly localized basis sets is comparable to smoother basis sets. Demonstrated performance on molecular systems with all-electron basis sets that are intractable with uniform grid methods.

Conclusion: Establishes pathway for scalable many-body electronic structure simulations with arbitrary smooth basis functions, making large-scale simulations of phenomena like core-level excitations feasible.

Abstract: We generalize the interpolative separable density fitting (ISDF) method, used
for compressing the four-index electron repulsion integral (ERI) tensor, to
incorporate adaptive real space grids for potentially highly localized
single-particle basis functions. To do so, we employ a fast adaptive algorithm,
the recently-introduced dual-space multilevel kernel-splitting method, to solve
the Poisson equation for the ISDF auxiliary basis functions. The adaptive grids
are generated using a high-order accurate, black-box procedure that satisfies a
user-specified error tolerance. Our algorithm relies on the observation, which
we prove, that an adaptive grid resolving the pair densities appearing in the
ERI tensor can be straightforwardly constructed from one that resolves the
single-particle basis functions, with the number of required grid points
differing only by a constant factor. We find that the ISDF compression
efficiency for the ERI tensor with highly localized basis sets is comparable to
that for smoother basis sets compatible with uniform grids. To demonstrate the
performance of our procedure, we consider several molecular systems with
all-electron basis sets which are intractable using uniform grid-based methods.
Our work establishes a pathway for scalable many-body electronic structure
simulations with arbitrary smooth basis functions, making simulations of
phenomena like core-level excitations feasible on a large scale.

</details>


### [28] [Phase-Field/Discontinuity Capturing operator for direct van der Waals simulation (DVS)](https://arxiv.org/abs/2510.21065)
*Tianyi Hu,Thomas J. R. Hughes,Guglielmo Scovazzi,Hector Gomez*

Main category: physics.comp-ph

TL;DR: Proposes a phase-field/discontinuity capturing (PF/DC) operator to overcome limitations of classical DC operators in direct van der Waals simulation, particularly in interfacial regions with negative pressure derivatives.


<details>
  <summary>Details</summary>
Motivation: Classical discontinuity capturing operators fail in direct van der Waals simulation when applied to interfacial regions where pressure derivative with respect to density is negative, violating free energy dissipation laws and producing unphysical wave structures.

Method: Developed a phase-field/discontinuity capturing (PF/DC) operator that combines phase-field modeling with discontinuity capturing to handle non-equilibrium phase transitions in interfacial regions.

Result: PF/DC yields stable and accurate solutions in both bulk fluids and interfacial regions, with excellent agreement to experimental data in 3D cavitating flow simulations and significant improvements over classical DC operators.

Conclusion: The proposed PF/DC operator successfully addresses the limitations of classical DC operators in direct van der Waals simulation, providing stable and physically accurate solutions for problems involving sharp gradients and phase transitions.

Abstract: Discontinuity capturing (DC) operators are commonly employed to numerically
solve problems involving sharp gradients in the solution. Despite their
success, the application of DC operators to the direct van der Waals simulation
(DVS) remains challenging. The DVS framework models non-equilibrium phase
transitions by admitting interfacial regions in which the derivative of
pressure with respect to density is negative. In these regions, we demonstrate
that classical DC operators may violate the free energy dissipation law and
produce unphysical wave structures. To address this limitation, we propose the
phase-field/discontinuity capturing (PF/DC) operator. Numerical results show
that PF/DC yields stable and accurate solutions in both bulk fluids and
interfacial regions. Finally, we apply the proposed method to simulate
cavitating flow over a three-dimensional bluff body, obtaining excellent
agreement with experimental data and significant improvements over results
produced using classical DC operators.

</details>


### [29] [Fast adaptive discontinuous basis sets for electronic structure](https://arxiv.org/abs/2510.21213)
*Yulong Pan,Michael Lindsey*

Main category: physics.comp-ph

TL;DR: A discontinuous Galerkin framework for adaptive basis sets in electronic structure calculations that combines atom-centered and polynomial bases, maintains numerical conditioning, and enables structured sparsity.


<details>
  <summary>Details</summary>
Motivation: To develop systematically improvable and structured adaptive basis sets for electronic structure calculations that overcome limitations of traditional basis sets while maintaining computational efficiency.

Method: Discontinuous Galerkin framework allowing basis functions to be discontinuous across element interfaces, specialized numerical integration for one- and two-electron integrals, multigrid-preconditioned Poisson solvers, and adaptive multigrid preconditioning for linear eigensolvers.

Result: Achieves chemical accuracy with modest basis sizes comparable to GTO basis sets, while offering additional structured sparsity and improved computational scalability in the size-extensive limit.

Conclusion: The framework provides a flexible route toward constructing systematically improvable and structured adaptive basis sets for electronic structure theory with favorable numerical properties and computational efficiency.

Abstract: We develop a discontinuous Galerkin (DG) framework for automatically
constructing adaptive basis sets for electronic structure calculations. By
allowing basis functions to be discontinuous across element interfaces, our
approach supports flexible combinations of atom-centered and polynomial basis
sets, maintains favorable numerical conditioning, and induces structured
sparsity of the one- and two-electron integrals, which we compute using
specialised numerical integration strategies. We also introduce
multigrid-preconditioned Poisson solvers that enable fast algorithms for both
Hartree-Fock (HF) and density functional theory (DFT) calculations within our
DG basis sets. Moreover, these basis sets naturally support adaptive multigrid
preconditioning for the linear eigensolvers employed within the self-consistent
field iteration for HF and DFT. Numerical experiments for HF and DFT
demonstrate that our approach achieves chemical accuracy with modest basis
sizes that compare favorably to the sizes of ordinary GTO basis sets achieving
similar accuracy, while offering additional structured sparsity and improved
computational scalability in the size-extensive limit. The framework thus
provides a flexible route toward the construction of systematically improvable
and structured adaptive basis sets for electronic structure theory.

</details>


### [30] [Reduced Floating-Point Precision Implicit Monte Carlo](https://arxiv.org/abs/2510.21683)
*Simon Butson,Mathew Cleveland,Alex Long,Todd Palmer*

Main category: physics.comp-ph

TL;DR: Algorithms for thermal radiation transport using reduced floating-point precision Implicit Monte Carlo method, with techniques to improve accuracy in half- and double-precision implementations.


<details>
  <summary>Details</summary>
Motivation: To enable more efficient computation of thermal radiation transport problems by using reduced floating-point precision while maintaining accuracy.

Method: Implicit Monte Carlo method with reduced floating-point precision, using arithmetic manipulations and scaling methods to improve accuracy.

Result: Comparison of half- and double-precision implementations across various thermal radiation benchmark problems.

Conclusion: Reduced precision implementations can provide accurate solutions for thermal radiation transport when enhanced with appropriate techniques.

Abstract: This work demonstrates algorithms to accurately compute solutions to thermal
radiation transport problems using a reduced floating-point precision
implementation of the Implicit Monte Carlo method. Several techniques falling
into the categories of arithmetic manipulations and scaling methods are
evaluated for their ability to improve the accuracy of reduced-precision
computations. The results for half- and double-precision implementations of
various thermal radiation benchmark problems are compared.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [31] [Significant Amplification of Turbulent Energy Dissipation through the Shock Transition at Mars](https://arxiv.org/abs/2510.20977)
*Wence Jiang,Hui Li,Nahuel Andrés,Lina Hadid,Daniel Verscharen,Chi Wang*

Main category: physics.plasm-ph

TL;DR: First observational evidence showing bow shocks significantly enhance turbulence energy cascade rates by three orders of magnitude, with shock obliquity affecting the amplification level.


<details>
  <summary>Details</summary>
Motivation: To quantify how bow shock interactions modify turbulence in planetary environments and understand the parametric dependencies, which have been hypothesized but not directly measured.

Method: Used in situ long-term high-time resolution measurements from NASA's MAVEN mission to characterize turbulence energy cascade rate evolution at magnetohydrodynamic scales.

Result: Found three-order-of-magnitude enhancement in turbulence energy cascade rate from solar wind to magnetosheath, with higher dissipation rates for oblique and quasi-perpendicular shocks compared to quasi-parallel configurations.

Conclusion: Provides first direct evidence linking shock obliquity to turbulence amplification, offering insights into shock-mediated turbulence in similar systems.

Abstract: Turbulence is fundamental to energy transfer across scales in space and
astrophysical plasmas. Bow shock interactions have long been hypothesized to
significantly modify turbulence in planetary environments, yet the
quantification of such effects and their parametric dependencies remain largely
unaddressed. Using in situ long-term high-time resolution measurements from
NASA's MAVEN mission, we report the first observational characterization of the
evolution and parametric dependence of the turbulence energy cascade rate
$\varepsilon_C$ at magnetohydrodynamic (MHD) scales. Key findings reveal an
averaged three-order-of-magnitude enhancement in $\varepsilon_C$ when
transitioning from the solar wind to the magnetosheath. Notably, downstream
measurements of oblique and quasi-perpendicular shocks exhibit higher energy
dissipation rates than those of quasi-parallel configurations. These results
provide the first direct evidence linking shock obliquity to turbulence
amplification, offering key insights into shock-mediated turbulence in similar
but inaccessible systems.

</details>


### [32] [Inhomogeneous mixing: From microscopic dynamics to mesoscopic staircases](https://arxiv.org/abs/2510.21170)
*T. Long,M. J. Choi,P. H. Diamond*

Main category: physics.plasm-ph

TL;DR: This paper reviews experimental progress on turbulence spreading by blobs/voids and their interaction with zonal flows in magnetically confined fusion plasmas, exploring how these phenomena contribute to inhomogeneous mixing and the formation of layered transport barriers called E x B staircases.


<details>
  <summary>Details</summary>
Motivation: To understand the complex interplay between turbulence spreading (via blobs/voids) and transport suppression (via zonal flows) in fusion plasmas, and how their coexistence leads to inhomogeneous mixing and mesoscopic layered structures known as staircases.

Method: The paper reviews recent experimental progress on blob/void physics and provides a brief review of experimental results on staircases, using complementary methods to identify these elusive structures.

Result: The review shows that blobs/voids enhance turbulence spreading while zonal flows suppress it, and their interaction creates inhomogeneous mixing states. Staircases are identified as layered transport barriers but remain incompletely understood.

Conclusion: This paper serves as an initial step toward applying insights from blob/void-induced inhomogeneous mixing to better understand the formation and behavior of E x B staircases in fusion plasmas.

Abstract: Inhomogeneous mixing and the consequent mesoscopic layered structure have
been observed in many physical systems, including magnetically confined fusion
plasmas. Especially, in plasmas, mixing can be enhanced through turbulence
spreading by intermittent coherent structures (blobs/voids), or suppressed due
to the formation of transport barriers (sheared zonal flows). Interestingly,
blobs/voids and zonal flows are not independent, and they can co-exist in a
state of inhomogeneous mixing, often called the E x B staircase. In this paper,
we first introduce recent experimental progress on the physics of blobs/voids:
how turbulence spreading by blobs/voids occurs, the consequences of enhanced
turbulence spreading for the power decay length, and the interaction between
blobs/voids and zonal flows. Then, we provide a brief review of experimental
results on staircases, or more generally layered mesoscopic transport barriers.
Staircases are often elusive and different complementary methods have been
utilized to identify them, but our understanding is still incomplete. This
paper serves as an initial step toward applying insights gained from
inhomogeneous mixing due to blobs/voids to the understanding of a staircase.

</details>


### [33] [Laboratory formation of scaled astrophysical outflows](https://arxiv.org/abs/2510.21239)
*Shun-yi Yang,Tao Tao,Guang-yue Hu,Chao Xiong,Tian-yi Li,Xue-cheng Li,Hui-bo Tang,Shuo-ting Shao,Xiang Lv,Chen Zhang,Ming-yang Yang*

Main category: physics.plasm-ph

TL;DR: Laboratory experiments and simulations show astrophysical outflow morphologies are determined by external Alfvenic and sonic Mach numbers, with transitions at specific values.


<details>
  <summary>Details</summary>
Motivation: To understand the mechanisms and existence conditions of diverse astrophysical outflow morphologies, which remain persistent puzzles in the field.

Method: Scaled laboratory experiments using laser-driven plasma outflow into magnetized ambient gas, combined with magnetohydrodynamics simulations.

Result: Identified five basic outflow types (collimated jets, blocked jets, elliptical bubbles, spherical winds and bubbles) with transitions occurring at Me-a ~ 2 and 0.5, and Me-s ~ 1.

Conclusion: Provides a quantitative framework for understanding astrophysical outflows based on external Alfvenic and sonic Mach numbers.

Abstract: Astrophysical systems exhibit a rich diversity of outflow morphologies, yet
their mechanisms and existence conditions remain among the most persistent
puzzles in the field. Here we present scaled laboratory experiments based on
laser-driven plasma outflow into magnetized ambient gas, which mimic five basic
astrophysical outflows regulated by interstellar medium, namely collimated
jets, blocked jets, elliptical bubbles, as well as spherical winds and bubbles.
Their morphologies and existence conditions are found to be uniquely determined
by the external Alfvenic and sonic Mach numbers Me-a and Me-s, i.e. the
relative strengths of the outflow ram pressure against the magnetic/thermal
pressures in the interstellar medium, with transitions occurring at Me-a ~ 2
and 0.5, as well as Me-s ~ 1. These results are confirmed by
magnetohydrodynamics simulations and should also be verifiable from existing
and future astronomical observations. Our findings provide a quantitative
framework for understanding astrophysical outflows.

</details>


### [34] [Benchmark for two-dimensional large scale coherent structures in partially magnetized ExB plasmas -- Community collaboration & lessons learned](https://arxiv.org/abs/2510.21261)
*Andrew T. Powis,Eduardo Ahedo,Alejandro Álvarez Laguna,Nicolas Barléon,Enrique Bello-Benítez,Lucas Beving,Jean-Pierre Boeuf,Guillaume Bogopolsky,Anne Bourdon,Filippo Cichocki,Bénédicte Cuenot,Andrew Denig,Zoltán Donkó,Paul-Quentin Elias,Miguel P. Encinar,Denis Eremin,Pablo Fajardo,Farbod Faraji,Gwenael Fubiani,Laurent Garrigues,Kentaro Hara,Peter Hartmann,Matthew Hopkins,Igor D. Kaganovich,Aaron Knoll,Giovanni Lapenta,Thierry E. Magin,Alberto Marín-Cebrián,Mario Merino,Pierpaolo Minelli,Mina Papahn Zadeh,Pietro Parodi,Federico Petronio,Maryam Reza,Andrei I. Smolyakov,Dmytro Sydorenko,Francesco Taccogna,Miles M. Turner,Olivier Vermorel,Willca Villafana,Liang Xu*

Main category: physics.plasm-ph

TL;DR: This paper presents a benchmarking study of 17 simulation codes modeling a magnetized ExB Penning discharge, focusing on verification of low-temperature plasma codes and analysis of rotating plasma spokes.


<details>
  <summary>Details</summary>
Motivation: Code benchmarking is crucial for verifying implementations and evaluating performance in low-temperature plasma simulations, which are essential for scientific research and industrial applications.

Method: Seventeen simulation codes from nineteen international institutions modeled a partially magnetized ExB Penning discharge, analyzing rotating plasma spokes and comparing implementations, hardware, and runtimes.

Result: The codes showed excellent agreement on spoke rotation frequency and key plasma properties including time-averaged ion density, plasma potential, and electron temperature profiles.

Conclusion: The study achieved strong code agreement and provides lessons learned for future benchmarking campaigns, with insights to guide plasma simulation software development.

Abstract: Low-temperature plasmas are essential to both fundamental scientific research
and critical industrial applications. As in many areas of science, numerical
simulations have become a vital tool for uncovering new physical phenomena and
guiding technological development. Code benchmarking remains crucial for
verifying implementations and evaluating performance. This work continues the
Landmark benchmark initiative, a series specifically designed to support the
verification of low-temperature plasma codes. In this study, seventeen
simulation codes from a collaborative community of nineteen international
institutions modeled a partially magnetized ExB Penning discharge. The
emergence of large scale coherent structures, or rotating plasma spokes, endows
this configuration with an enormous range of time scales, making it
particularly challenging to simulate. The codes showed excellent agreement on
the rotation frequency of the spoke as well as key plasma properties, including
time-averaged ion density, plasma potential, and electron temperature profiles.
Achieving this level of agreement came with challenges, and we share lessons
learned on how to conduct future benchmarking campaigns. Comparing code
implementations, computational hardware, and simulation runtimes also revealed
interesting trends, which are summarized with the aim of guiding future plasma
simulation software development.

</details>


### [35] [Counter-Streaming Beams in Collisionless Pair Plasma Instability Systems II: Spectral Cone and Spectral Wave Mode Analysis](https://arxiv.org/abs/2510.21666)
*Michael C. Sitarz*

Main category: physics.plasm-ph

TL;DR: Spectral analysis of Weibel instability in collisionless plasmas using particle-in-cell simulations, exploring power dependence on viewing angle and frequency.


<details>
  <summary>Details</summary>
Motivation: To understand plasma kinetic instabilities in energetic astrophysical phenomena like gamma-ray bursts, supernovae, and magnetar flares that occur in collisionless plasmas.

Method: Spectral analysis of particle-in-cell simulations to study the Weibel instability.

Result: Explored power dependence on viewing angle and frequency, connecting findings to previous work in the series.

Conclusion: The study provides insights into spectral trends of Weibel instability relevant to astrophysical plasma phenomena.

Abstract: Energetic astrophysical phenomena, such as $\gamma$-ray bursts, supernova
explosions, and magnetar flares occur in collisionless plasmas and involve
various plasma kinetic and magnetohydrodynamic instabilities. In this paper, we
explore the spectral trends of the Weibel instability using spectral analysis
of particle-in-cell simulations. Power dependence on viewing angle and
frequency are explored and the relation to the results of the first paper in
this series is discussed.

</details>


### [36] [Counter-Streaming Beams in Collisionless Pair Plasma Instability Systems III: Collisionless Heating, Acceleration, and Radiation](https://arxiv.org/abs/2510.21675)
*Michael C. Sitarz*

Main category: physics.plasm-ph

TL;DR: This paper explores energy transformations and dynamical effects during violent mergers of current filaments formed by the Weibel instability in collisionless plasmas, and discusses related radiative processes.


<details>
  <summary>Details</summary>
Motivation: To understand plasma kinetic instabilities like the Weibel instability that occur in energetic astrophysical phenomena such as gamma-ray bursts and supernova explosion-driven shocks, which involve particle acceleration and radiation mechanisms.

Method: The study investigates energy transformations and dynamical effects during violent mergers of large current filaments formed by the Weibel instability in collisionless plasmas.

Result: The paper examines how filament mergers affect energy transformations and dynamics, and discusses the relationship between Weibel instability filament building and radiative processes including jitter and synchrotron radiation.

Conclusion: The Weibel instability plays a crucial role in plasma dynamics and radiation processes in high-energy astrophysical environments, with filament mergers being significant for energy transformations and radiative mechanisms.

Abstract: Energetic astrophysical phenomena, such as $\gamma$-ray bursts and supernova
explosion-driven shocks in collisionless plasmas, involve various plasma
kinetic instabilities, such as the Weibel instability. These systems support
various types of particle acceleration and radiation through a variety of
mechanisms. In this paper, we explore the energy transformations and dynamical
effects of violent filament mergers seen between the large current filaments
formed by the Weibel instability. The radiative processes involved in the
Weibel instability filament building are also discussed in relation to jitter
and synchrotron radiation.

</details>


### [37] [Constructing Field Aligned Coordinate Systems for Gyrokinetic Simulations of Tokamaks in X-point Geometries](https://arxiv.org/abs/2510.21676)
*Akash Shukla,Ammar Hakim,James Juno,Gregory Hammett,Manaure Francisquez*

Main category: physics.plasm-ph

TL;DR: An algorithm is presented to compute geometric quantities in field-aligned coordinate systems that avoids the singularity at magnetic X-points, enabling 2D axisymmetric simulations in X-point geometries for tokamak plasmas.


<details>
  <summary>Details</summary>
Motivation: Field-aligned coordinate systems are efficient for tokamak simulations due to plasma structure alignment with magnetic fields, but they have coordinate singularities at magnetic X-points where poloidal magnetic field vanishes, making it difficult to simulate core and scrape-off layer simultaneously.

Method: Developed an algorithm for computing geometric quantities in standard field-aligned coordinate systems that avoids the singularity at magnetic X-points, allowing 2D axisymmetric simulations in X-point geometries.

Result: The algorithm successfully enables simulations in X-point geometries, demonstrated with an example simulation of the Spherical Tokamak for Energy Production (STEP).

Conclusion: The presented algorithm effectively resolves the coordinate singularity issue in field-aligned coordinate systems at magnetic X-points, facilitating simultaneous simulation of core and scrape-off layer regions in tokamak plasmas.

Abstract: Structures in tokamak plasmas are elongated along the direction of the
magnetic field and short in the directions perpendicular to the magnetic field.
Many tokamak simulation codes take advantage of this by using a field aligned
coordinate system. However, field aligned coordinate systems have a coordinate
singularity at magnetic X-points where the poloidal magnetic field vanishes,
which makes it difficult to use field aligned coordinate systems when
simulating the core and scrape-off layer (SOL) simultaneously. Here we present
an algorithm for computing geometric quantities in a standard field aligned
coordinate system that avoids the singularity and allows one to conduct 2D
axisymmetric simulations in X-point geometries. We demonstrate the efficacy of
this algorithm with an example simulation of the Spherical Tokamak for Energy
Production (STEP).

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [38] [Optimal spin-charge interconversion in graphene through spin-pseudospin entanglement control](https://arxiv.org/abs/2510.21240)
*Joaquín Medina Dueñas,Santiago Giménez de Castro,Jose H. Garcia,Stephan Roche*

Main category: cond-mat.mes-hall

TL;DR: The paper proposes a method to achieve 100% efficient spin-charge interconversion in graphene by controlling spin-pseudospin entanglement, demonstrating robustness in disordered systems.


<details>
  <summary>Details</summary>
Motivation: To enhance spin-charge interconversion efficiency in graphene for spintronics applications by leveraging spin-pseudospin entanglement.

Method: Control intraparticle entanglement between spin and pseudospin degrees of freedom in graphene, using conserved spin-pseudospin operators and Rashba-Edelstein effect with Kane-Mele SOC tuning.

Result: Achieved 100% efficient spin-charge interconversion via Rashba-Edelstein effect, with quantum transport simulations showing robustness in disordered micron-size systems and disorder-resilient spin Hall effect.

Conclusion: The approach provides a platform for maximally efficient spin-charge interconversion and establishes spin-pseudospin correlations as a mechanism for tailoring spintronic devices.

Abstract: The electrical generation of spin signals is of central interest for
spintronics, where graphene stands as a relevant platform as its spin-orbit
coupling (SOC) is tuned by proximity effects. Here, we propose an enhancement
of spin-charge interconversion in graphene by controlling the intraparticle
entanglement between the spin and pseudospin degrees of freedom. We demonstrate
that, although the spin alone is not conserved in Rashba-Dirac systems, a
combined spin-pseudospin operator is conserved. This conserved quantity
represents the interconversion between pure spin and pseudospin textures to a
spin-pseudospin entangled structure, where Kane-Mele SOC tunes this balance. By
these means, we achieve spin-charge interconversion of 100\% efficiency via the
Rashba-Edelstein effect. Quantum transport simulations in disordered
micron-size systems demonstrate the robustness of this effect, and also reveal
a disorder resilient spin Hall effect generated by the interplay between Rashba
and Kane-Mele SOC. Our findings propose a platform for maximally efficient
spin-charge interconversion, and establish spin-pseudospin correlations as a
mechanism to tailor spintronic devices.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [39] [Linked Cell Traversal Algorithms for Three-Body Interactions in Molecular Dynamics](https://arxiv.org/abs/2510.21230)
*Jose Alfonso Pinzon Escobar,Markus Mühlhäußer,Hans-Joachim Bungartz,Philipp Neumann*

Main category: cs.CE

TL;DR: This paper develops parallel algorithms for computing three-body interactions in molecular dynamics by extending existing pair interaction traversals to handle molecules across three cells, incorporating cutoff conditions to optimize workload.


<details>
  <summary>Details</summary>
Motivation: While algorithms for pair interactions in molecular dynamics are well-established, there is a need to extend these methods to efficiently compute three-body interactions, which are more complex and require handling molecules stored across three different cells.

Method: The authors developed a general framework for computing three-body interactions in linked cells, extending existing traversal methods. They combined this analysis with commonly used cutoff conditions to optimize computational workload. The approach was validated using Lennard-Jones fluid simulations in both homogeneous and inhomogeneous scenarios.

Result: The developed algorithms were successfully validated through case studies from literature. The paper measured strong scalability and performance in terms of molecule updates at node-level, demonstrating the effectiveness of the approach.

Conclusion: The research provides a framework for efficient parallel computation of three-body interactions in molecular dynamics, extending existing pair interaction methods and incorporating cutoff optimization to handle the increased complexity of three-body computations.

Abstract: In this work, algorithms for the parallel computation of three-body
interactions in molecular dynamics are developed. While traversals for the
computation of pair interactions are readily available in the literature, here,
such traversals are extended to allow for the computation between molecules
stored across three cells. A general framework for the computation of
three-body interactions in linked cells is described, and then used to
implement the corresponding traversals. In addition, our analysis is combined
with the commonly used cutoff conditions, because they influence the total
workload of the computation of interactions. The combinations between
traversals and truncation conditions are validated using the well-known
Lennard-Jones fluid. Validation case studies are taken from the literature and
configured into homogeneous and inhomogeneous scenarios. Finally, strong
scalability and performance in terms of molecule updates are measured at
node-level.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [40] [Multilevel Picard scheme for solving high-dimensional drift control problems with state constraints](https://arxiv.org/abs/2510.21607)
*Yuan Zhong*

Main category: math.OC

TL;DR: The paper presents a multilevel Picard (MLP) approximation method for solving high-dimensional drift control problems with state constraints in the nonnegative orthant, proving it overcomes the curse of dimensionality with polynomial computational complexity.


<details>
  <summary>Details</summary>
Motivation: The research is motivated by applications to dynamic control of queueing networks, particularly for solving high-dimensional drift control problems where states must remain in the nonnegative orthant over finite time horizons.

Method: The authors develop a simulation-based scheme called multilevel Picard (MLP) approximation for high-dimensional drift control problems with state constraints, proving theoretical guarantees about its computational complexity.

Result: The MLP approximation overcomes the curse of dimensionality - computational complexity grows at most polynomially in problem dimension d and 1/ε. Numerical experiments show computational feasibility up to dimension 20 for dynamic scheduling problems in parallel server systems under heavy traffic.

Conclusion: The proposed MLP approximation method provides an effective computational approach for high-dimensional drift control problems with state constraints, demonstrating both theoretical guarantees and practical feasibility through numerical experiments.

Abstract: Motivated by applications to the dynamic control of queueing networks, we
develop a simulation-based scheme, the so-called multilevel Picard (MLP)
approximation, for solving high-dimensional drift control problems whose states
are constrained to stay within the nonnegative orthant, over a finite time
horizon. We prove that under suitable conditions, the MLP approximation
overcomes the curse of dimensionality in the following sense: To approximate
the value function and its gradient evaluated at a given time and state to
within a prescribed accuracy $\varepsilon$, the computational complexity grows
at most polynomially in the problem dimension $d$ and $1/\varepsilon$. To
illustrate the effectiveness of the scheme, we carry out numerical experiments
for a class of test problems that are related to the dynamic scheduling problem
of parallel server systems in heavy traffic, and demonstrate that the scheme is
computationally feasible up to dimension at least $20$.

</details>


<div id='math.SG'></div>

# math.SG [[Back]](#toc)

### [41] [The linearized Floer equation in a chart](https://arxiv.org/abs/2510.20945)
*Urs Frauenfelder,Joa Weber*

Main category: math.SG

TL;DR: The paper introduces a new mathematical structure called 'almost extendable weak Hessian field' by studying the Hessian of the area functional in non-Darboux charts, and proves a Fredholm theorem for Robbin-Salamon operators with non-continuous Hessians.


<details>
  <summary>Details</summary>
Motivation: To study the Hessian of the area functional in non-Darboux charts, which hasn't been considered before, leading to the discovery of a new mathematical structure.

Method: Introducing and analyzing the concept of 'almost extendable weak Hessian field' as a new mathematical structure arising from studying Hessians in non-Darboux charts.

Result: Proved a Fredholm theorem for Robbin-Salamon operators associated with non-continuous Hessians by leveraging the new almost extendable weak Hessian field structure.

Conclusion: The study of Hessians in non-Darboux charts reveals a novel mathematical framework that enables the proof of Fredholm theorems for operators with discontinuous Hessians.

Abstract: In this article we are considering the Hessian of the area functional in a
non-Darboux chart. This does not seem to have been considered before and leads
to an interesting new mathematical structure which we introduce in this article
and refer to as \emph{almost extendable weak Hessian~field}.
  Our main result is a Fredholm theorem for Robbin-Salamon operators associated
to \emph{non-continuous} Hessians which we prove by taking advantage of this
new structure.

</details>


<div id='math.MG'></div>

# math.MG [[Back]](#toc)

### [42] [On the uniqueness of even $L^p$ Minkowski problem](https://arxiv.org/abs/2510.21530)
*Weiyong He,Junbang Liu*

Main category: math.MG

TL;DR: The paper identifies a critical threshold p₀ in [0,1) where the even L^p Minkowski problem has unique solutions for p ≥ p₀, but loses uniqueness for p < p₀ across infinitely many convex bodies.


<details>
  <summary>Details</summary>
Motivation: To determine the precise threshold where uniqueness in the even L^p Minkowski problem transitions, addressing gaps in previous work that only established uniqueness for p > p₀.

Method: Characterizes p₀ using eigenvalues of Hilbert operators related to convex bodies and proves uniqueness/non-uniqueness results through mathematical analysis.

Result: Established that uniqueness holds for p ≥ p₀ and fails for p < p₀ for infinitely many convex bodies, refining previous results.

Conclusion: The critical threshold p₀ marks the exact boundary where the even L^p Minkowski problem transitions from having unique solutions to exhibiting non-uniqueness.

Abstract: We prove that there is a unique $p_0\in [0,1)$, which can be characterized by
the eigenvalue of Hilbert operator related to a convex body, that the even
$L^p$ Minkowski problem has a unique solution for $p\geq p_0$, and the
uniqueness fails for infinitely many convex bodies if $p<p_0$. The previous
results by many experts in the field assert that the uniqueness holds for
$p>p_0$.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [43] [A complex Gaussian representation of continuum wavefunctions respectful of their asymptotic behaviour](https://arxiv.org/abs/2510.21295)
*Arnaud Leclerc,Stéphanie Laure Egome Nana,Lorenzo Ugo Ancarani*

Main category: physics.chem-ph

TL;DR: The paper presents a method for optimizing complex Gaussian basis sets to accurately represent continuum radial wavefunctions, using both direct optimization and an indirect fitting approach that preserves oscillatory behavior.


<details>
  <summary>Details</summary>
Motivation: To improve the accuracy of representing continuum radial wavefunctions using Gaussian basis sets, particularly addressing the challenge of capturing oscillatory behavior that extends to infinity.

Method: Two approaches: 1) Direct optimization of Gaussian exponents for more flexible series, 2) Indirect fitting method that factors out asymptotic oscillatory behavior and applies Gaussian representation only to the distortion factor with limited spatial extension.

Result: The method successfully represents radial Coulomb functions with realistic energy parameters and maintains the analytical structure of one-electron transition integrals used in molecular ionization applications.

Conclusion: The indirect fitting approach provides an effective way to represent continuum wavefunctions while preserving their oscillatory asymptotic behavior and maintaining useful analytical properties for computational applications.

Abstract: Complex Gaussian basis sets are optimized to accurately represent continuum
radial wavefunctions over the whole space. First, attention is put on the
technical ability of the optimization method to get more flexible series of
Gaussian exponents, in order to improve the accuracy of the fitting approach.
Second, an indirect fitting method is proposed, allowing for the oscillatory
behaviour of continuum functions to be conserved up to infinity as a factorized
asymptotic function, while the Gaussian representation is applied to some
appropriately defined distortion factor with limited spatial extension. As an
illustration, the method is applied to radial Coulomb functions with realistic
energy parameters. We also show that the indirect fitting approach keeps the
advantageous analytical structure of typical one-electron transition integrals
occurring in molecular ionization applications.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [44] [Pty-Chi: A PyTorch-based modern ptychographic data analysis package](https://arxiv.org/abs/2510.20929)
*Ming Du,Hanna Ruth,Steven Henke,Yi Jiang,Viktor Nikitin,Ashish Tripathi,Junjing Deng,Jeffrey Klug,Peco Myint,Tao Zhou,Nicholas Schwarz,Mathew Cherukara,Alec Sandy,Stefan Vogt*

Main category: physics.optics

TL;DR: Pty-Chi is an open-source ptychographic reconstruction package built on PyTorch that unifies analytical algorithms with automatic differentiation methods, providing GPU acceleration and extensible design for advanced imaging applications.


<details>
  <summary>Details</summary>
Motivation: Ptychography requires robust, efficient computational reconstruction software for high-resolution imaging. Existing tools lack the flexibility and performance needed for modern experimental challenges.

Method: Built on PyTorch backend for vendor-agnostic GPU acceleration, with object-oriented modular design supporting analytical algorithms, automatic differentiation, advanced parameter corrections, and multi-device parallelization.

Result: Successfully demonstrated capabilities through challenging case studies involving limited coherence, low overlap, and unstable illumination, showing accuracy, versatility, and extensibility.

Conclusion: Pty-Chi provides a modern, maintainable platform for advancing computational ptychography and enabling innovative imaging algorithms at synchrotron facilities and beyond through community-driven development.

Abstract: Ptychography has become an indispensable tool for high-resolution,
non-destructive imaging using coherent light sources. The processing of
ptychographic data critically depends on robust, efficient, and flexible
computational reconstruction software. We introduce Pty-Chi, an open-source
ptychographic reconstruction package built on PyTorch that unifies
state-of-the-art analytical algorithms with automatic differentiation methods.
Pty-Chi provides a comprehensive suite of reconstruction algorithms while
supporting advanced experimental parameter corrections such as orthogonal probe
relaxation and multislice modeling. Leveraging PyTorch as the computational
backend ensures vendor-agnostic GPU acceleration, multi-device parallelization,
and seamless access to modern optimizers. An object-oriented, modular design
makes Pty-Chi highly extendable, enabling researchers to prototype new imaging
models, integrate machine learning approaches, or build entirely new workflows
on top of its core components. We demonstrate Pty-Chi's capabilities through
challenging case studies that involve limited coherence, low overlap, and
unstable illumination during scanning, which highlight its accuracy,
versatility, and extensibility. With community-driven development and open
contribution, Pty-Chi offers a modern, maintainable platform for advancing
computational ptychography and for enabling innovative imaging algorithms at
synchrotron facilities and beyond.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [45] [Physically consistent and uncertainty-aware learning of spatiotemporal dynamics](https://arxiv.org/abs/2510.21023)
*Qingsong Xu,Jonathan L Bamber,Nils Thuerey,Niklas Boers,Paul Bates,Gustau Camps-Valls,Yilei Shi,Xiao Xiang Zhu*

Main category: cs.LG

TL;DR: Physics-consistent neural operator (PCNO) with diffusion model enhancement (DiffPCNO) for accurate, uncertainty-aware spatiotemporal forecasting that enforces physical laws.


<details>
  <summary>Details</summary>
Motivation: Existing ML methods neglect physical laws and fail to quantify uncertainties in spatiotemporal predictions, limiting their reliability and accuracy.

Method: Two-stage framework: PCNO enforces physical constraints via projection layer in Fourier space for mass/momentum conservation; DiffPCNO adds consistency model to quantify and mitigate uncertainties.

Result: Achieves high-fidelity spatiotemporal predictions while preserving physical consistency and uncertainty across diverse systems and spatial resolutions.

Conclusion: Provides robust and versatile approach for accurate, physically grounded, and uncertainty-aware spatiotemporal forecasting.

Abstract: Accurate long-term forecasting of spatiotemporal dynamics remains a
fundamental challenge across scientific and engineering domains. Existing
machine learning methods often neglect governing physical laws and fail to
quantify inherent uncertainties in spatiotemporal predictions. To address these
challenges, we introduce a physics-consistent neural operator (PCNO) that
enforces physical constraints by projecting surrogate model outputs onto
function spaces satisfying predefined laws. A physics-consistent projection
layer within PCNO efficiently computes mass and momentum conservation in
Fourier space. Building upon deterministic predictions, we further propose a
diffusion model-enhanced PCNO (DiffPCNO), which leverages a consistency model
to quantify and mitigate uncertainties, thereby improving the accuracy and
reliability of forecasts. PCNO and DiffPCNO achieve high-fidelity
spatiotemporal predictions while preserving physical consistency and
uncertainty across diverse systems and spatial resolutions, ranging from
turbulent flow modeling to real-world flood/atmospheric forecasting. Our
two-stage framework provides a robust and versatile approach for accurate,
physically grounded, and uncertainty-aware spatiotemporal forecasting.

</details>


### [46] [On the flow matching interpretability](https://arxiv.org/abs/2510.21210)
*Francesco Pivi,Simone Gazza,Davide Evangelista,Roberto Amadini,Maurizio Gabbrielli*

Main category: cs.LG

TL;DR: A framework that constrains flow matching generative models to follow physical distributions, specifically using the 2D Ising model to make intermediate generation steps interpretable as thermal equilibrium points along a cooling schedule.


<details>
  <summary>Details</summary>
Motivation: Standard flow matching models lack interpretability in their intermediate generation steps, making the transformation from noise to data opaque and difficult to understand.

Method: Proposed architecture with three components: encoder mapping discrete Ising configurations to continuous latent space, flow-matching network performing temperature-driven diffusion, and projector returning to discrete Ising states while preserving physical constraints.

Result: Validated across multiple lattice sizes, preserves physical fidelity while outperforming Monte Carlo generation in speed for larger lattices. Each vector field represents meaningful stepwise transitions in the Ising model's latent space.

Conclusion: Embedding physical semantics into generative flows transforms opaque neural trajectories into interpretable physical processes, demonstrating the framework's effectiveness in making generative models more interpretable.

Abstract: Generative models based on flow matching have demonstrated remarkable success
in various domains, yet they suffer from a fundamental limitation: the lack of
interpretability in their intermediate generation steps. In fact these models
learn to transform noise into data through a series of vector field updates,
however the meaning of each step remains opaque. We address this problem by
proposing a general framework constraining each flow step to be sampled from a
known physical distribution. Flow trajectories are mapped to (and constrained
to traverse) the equilibrium states of the simulated physical process. We
implement this approach through the 2D Ising model in such a way that flow
steps become thermal equilibrium points along a parametric cooling schedule.
  Our proposed architecture includes an encoder that maps discrete Ising
configurations into a continuous latent space, a flow-matching network that
performs temperature-driven diffusion, and a projector that returns to discrete
Ising states while preserving physical constraints.
  We validate this framework across multiple lattice sizes, showing that it
preserves physical fidelity while outperforming Monte Carlo generation in speed
as the lattice size increases. In contrast with standard flow matching, each
vector field represents a meaningful stepwise transition in the 2D Ising
model's latent space. This demonstrates that embedding physical semantics into
generative flows transforms opaque neural trajectories into interpretable
physical processes.

</details>
