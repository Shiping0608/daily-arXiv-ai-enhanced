<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 15]
- [math.AP](#math.AP) [Total: 14]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [quant-ph](#quant-ph) [Total: 1]
- [math.DS](#math.DS) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [math.OC](#math.OC) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [cond-mat.quant-gas](#cond-mat.quant-gas) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [eess.IV](#eess.IV) [Total: 1]
- [math.PR](#math.PR) [Total: 1]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [physics.acc-ph](#physics.acc-ph) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [gr-qc](#gr-qc) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A Novel Approach for Flexible Body Dynamics Computation via Synthesizing Incremental Motions in Reconfigured Inertial Frames](https://arxiv.org/abs/2510.23858)
*Xiaobo Liu*

Main category: math.NA

TL;DR: A new method for flexible body dynamics that captures rigid body motion components, uses reconfigured inertial frames, and avoids complex nonlinear equations while improving accuracy.


<details>
  <summary>Details</summary>
Motivation: To address the complexities of modeling flexibilities and formulating highly nonlinear coupled motion equations in flexible body dynamics, and to better understand the interaction between rigid body motion and structural vibration.

Method: Captures rigid body motion component in flexible body movement, generates and synthesizes single-step responses in a sequence of reconfigured inertial frames that follow the rigid body motion.

Result: Effectively bypasses modeling complexities, improves predictive accuracy, provides insights into rigid body motion and structural vibration interaction.

Conclusion: Advances understanding of flexible body dynamics and delivers a precise, efficient simulation framework for engineering applications.

Abstract: A novel approach is presented for computing flexible body dynamics based on
conventional structural dynamics models. This approach innovatively captures
the rigid body motion component embedded within a flexible body's movement,
generates and synthesizes single-step responses in a sequence of reconfigured
inertial frames that follow the rigid body motion. By doing so, it effectively
bypasses the complexities associated with modeling flexibilities and
formulating highly nonlinear coupled motion equations. In addition to improving
predictive accuracy, this approach offers valuable insights into the
interaction between rigid body motion and structural vibration. By bridging
these two aspects, it advances the understanding of flexible body dynamics and
delivers a precise, efficient simulation framework for a wide range of
engineering applications.

</details>


### [2] [An Efficient Finite Difference-Based PML Technique for Acoustic Scattering Problems](https://arxiv.org/abs/2510.23898)
*Bin Han,Jiwoon Sim*

Main category: math.NA

TL;DR: High-order compact finite difference methods in polar coordinates for solving acoustic scattering problems with multiple arbitrarily shaped scatterers, using PMLs for domain truncation and novel pollution minimization techniques.


<details>
  <summary>Details</summary>
Motivation: To address challenges in solving the exterior Helmholtz equation for acoustic scattering, including unbounded domains and high dispersion error (pollution effect), especially with multiple complex scatterers.

Method: Develop high-order compact finite difference methods in polar coordinates with perfectly matched layers (PMLs) for domain truncation, incorporating a novel pollution minimization technique and using exponential stretching with mesh refinement.

Result: The methods achieve fourth consistency order in regular polar coordinates, and sixth consistency order with exponential stretching and mesh refinement. Numerical results show effectiveness and robustness across various wavenumbers, PML thicknesses, and scatterer shapes.

Conclusion: The proposed finite difference methods provide an effective and robust solution for acoustic scattering problems, successfully handling domain unboundedness and pollution effects through PMLs and pollution minimization techniques.

Abstract: The acoustic scattering problem is modeled by the exterior Helmholtz
equation, which is challenging to solve due to both the unboundedness of the
domain and the high dispersion error, known as the pollution effect. We develop
high-order compact finite difference methods (FDMs) in polar coordinates to
numerically solve the problem with multiple arbitrarily shaped scatterers. The
unbounded domain is effectively truncated and compressed via perfectly matched
layers (PMLs), while the pollution effect is handled by the high order of our
method and a novel pollution minimization technique. This technique is easy to
implement, rigorously proven to be effective and shows superior performance in
our numerous numerical results. The FDMs we propose in regular polar
coordinates achieve fourth consistency order. Yet, combined with exponential
stretching and mesh refinement, we can reach sixth consistency order by
slightly enlarging the stencil at certain locations. Our numerical examples
demonstrate that the proposed FDMs are effective and robust under various
wavenumbers, PML layer thickness and shapes of scatterers.

</details>


### [3] [A Continuum Macro-Model for Bistable Periodic Auxetic Surfaces](https://arxiv.org/abs/2510.23918)
*Emmanuel Sansusthy Tardio,Tian Chen,Theocharis Baxevanis*

Main category: math.NA

TL;DR: A macro-constitutive model for periodic rotating bistable auxetic surfaces is developed using variational formulation with regularization and artificial rate-dependency to address numerical stability issues.


<details>
  <summary>Details</summary>
Motivation: To model the deformation response of periodic rotating bistable auxetic surfaces made of hexagonal cells with two stable states, addressing mathematical ill-posedness and numerical artifacts from the double-well free energy.

Method: Variational formulation with free energy in terms of logarithmic strain invariants, gradient-enhanced regularization, artificial material rate-dependency, and implementation using membrane/shell elements and plane stress continuum elements in ABAQUS.

Result: Numerical simulations demonstrate the efficacy of the proposed formulation and implementation in handling the complex deformation behavior.

Conclusion: The developed model successfully captures the deformation response of bistable auxetic surfaces while addressing numerical stability challenges through regularization and rate-dependent enhancements.

Abstract: A macro-constitutive model for the deformation response of periodic rotating
bistable auxetic surfaces is developed. Focus is placed on isotropic surfaces
made of bistable hexagonal cells composed of six triangular units with two
stable equilibrium states. Adopting a variational formulation, the effective
stress-strain response is derived from a free energy function expressed in
terms of the invariants of the logarithmic strain. A regularization of the
governing equations via a gradient-enhanced first invariant of the logarithmic
strain is introduced since the double-well nature of the free energy may result
in mathematical ill-posedness and related numerical artifacts, such as mesh
sensitivity. Despite this regularization, the numerical scheme may still suffer
from divergence issues due to the highly non-linear material behavior. To
enhance numerical stability, an artificial material rate-dependency is
additionally introduced. Although it does not guarantee solution uniqueness or
eliminate mesh sensitivity, it is conjectured to assist the numerical scheme in
overcoming snap-backs caused by local non-proportional loading induced by
transition fronts. The model is implemented using membrane/shell structural
elements and plane stress continuum ones within the ABAQUS finite element
suite. Numerical simulations demonstrate the efficacy of the proposed
formulation and its implementation.

</details>


### [4] [Auto-Adaptive PINNs with Applications to Phase Transitions](https://arxiv.org/abs/2510.23999)
*Kevin Buck,Woojeong Kim*

Main category: math.NA

TL;DR: Proposed adaptive sampling method for PINNs using problem-specific heuristics, focusing on Allen-Cahn equations to resolve interfacial regions without post-hoc resampling.


<details>
  <summary>Details</summary>
Motivation: To improve training of Physics Informed Neural Networks by enabling adaptive sampling based on problem-specific criteria, particularly for accurately resolving characteristic interfacial regions in challenging equations like Allen-Cahn.

Method: Developed an adaptive sampling method that allows sampling based on arbitrary problem-specific heuristics that can depend on the neural network and its gradients.

Result: Experiments showed the method's effectiveness over residual-adaptive frameworks, successfully resolving interfacial regions in Allen-Cahn equations without post-hoc resampling.

Conclusion: The proposed adaptive sampling approach provides an effective alternative to residual-adaptive methods for PINNs, enabling better resolution of challenging physical phenomena like interfacial regions.

Abstract: We propose an adaptive sampling method for the training of Physics Informed
Neural Networks (PINNs) which allows for sampling based on an arbitrary
problem-specific heuristic which may depend on the network and its gradients.
In particular we focus our analysis on the Allen-Cahn equations, attempting to
accurately resolve the characteristic interfacial regions using a PINN without
any post-hoc resampling. In experiments, we show the effectiveness of these
methods over residual-adaptive frameworks.

</details>


### [5] [On the Superconvergence of ESFR Schemes](https://arxiv.org/abs/2510.24111)
*Mathias Dufresne-Piché,Siva Nadarajah*

Main category: math.NA

TL;DR: This paper provides the first formal proof of superconvergence in Energy Stable Flux Reconstruction (ESFR) methods for linear advection problems with upwind fluxes, explaining the mechanism behind observed superconvergent behavior and accuracy drops.


<details>
  <summary>Details</summary>
Motivation: While ESFR methods have shown superconvergent properties in numerical experiments, no formal proof existed in literature. The authors aim to address this gap by providing theoretical foundations for ESFR superconvergence.

Method: The authors use a simple derivation approach to analyze the superconvergence of dispersion-dissipation error in ESFR schemes. They show that superconvergence relies on ESFR's ability to generate superconvergent rational approximants of the exponential function, similar to discontinuous Galerkin methods.

Result: The paper demonstrates that ESFR schemes achieve superconvergence through rational approximants of the exponential function. It also explains that observed accuracy drops as the ESFR scalar c increases are due to changes in the structure of these approximants and modifications to the physical eigenvalue multiplicity.

Conclusion: The theoretical framework successfully explains ESFR superconvergence behavior and accuracy variations, with numerical experiments validating the theoretical findings. This provides formal understanding of previously observed numerical phenomena.

Abstract: The energy stable flux reconstruction (ESFR) method provides an efficient and
flexible framework to devise high-order linearly stable numerical schemes which
can achieve high levels of accuracy on unstructured grids. While
superconvergent properties of ESFR schemes have been observed in numerical
experiments, no formal proof of this behavior has been reported in the
literature. In this work, we attempt to address this by providing a simple
derivation for the superconvergence of the dispersion-dissipation error of ESFR
schemes for the linear advection problem when using an upwind numerical flux.
We show that the superconvergence of ESFR schemes essentially relies on the
capacity of the latter to generate superconvergent rational approximants of the
exponential function, which is reminiscent of well-known theoretical results
for superconvergence of discontinuous Galerkin (DG) methods. We also
demonstrate that the drops in order of accuracy which are observed in numerical
experiments as the ESFR scalar $c$ is increased are caused by both a
modification of the structure of these rational approximants and a change in
the multiplicity of the physical eigenvalue of the schemes as $c \to \infty$.
Finally, our theoretical results are successfully validated against numerical
experiments.

</details>


### [6] [SymMaP: Improving Computational Efficiency in Linear Solvers through Symbolic Preconditioning](https://arxiv.org/abs/2510.24170)
*Hong Wang,Jie Wang,Minghao Ma,Haoran Shao,Haoyang Liu*

Main category: math.NA

TL;DR: SymMaP uses symbolic discovery to learn efficient symbolic expressions for matrix preconditioning parameters, combining the strengths of traditional methods and machine learning while maintaining high inference efficiency and interpretability.


<details>
  <summary>Details</summary>
Motivation: Traditional preconditioning parameter selection relies on domain expertise and fixed constants, failing to consider instance-wise features. Machine learning approaches suffer from high inference costs and limited interpretability.

Method: A symbolic discovery framework that employs a neural network to search high-dimensional discrete space for symbolic expressions that can accurately predict optimal preconditioning parameters.

Result: SymMaP consistently outperforms traditional strategies across various benchmarks while providing high inference efficiency and excellent interpretability through concise symbolic formulas.

Conclusion: The proposed symbolic discovery framework successfully combines the strengths of traditional and ML approaches for matrix preconditioning, delivering both performance improvements and practical deployability.

Abstract: Matrix preconditioning is a critical technique to accelerate the solution of
linear systems, where performance heavily depends on the selection of
preconditioning parameters. Traditional parameter selection approaches often
define fixed constants for specific scenarios. However, they rely on domain
expertise and fail to consider the instance-wise features for individual
problems, limiting their performance. In contrast, machine learning (ML)
approaches, though promising, are hindered by high inference costs and limited
interpretability. To combine the strengths of both approaches, we propose a
symbolic discovery framework-namely, Symbolic Matrix Preconditioning
(SymMaP)-to learn efficient symbolic expressions for preconditioning
parameters. Specifically, we employ a neural network to search the
high-dimensional discrete space for expressions that can accurately predict the
optimal parameters. The learned expression allows for high inference efficiency
and excellent interpretability (expressed in concise symbolic formulas), making
it simple and reliable for deployment. Experimental results show that SymMaP
consistently outperforms traditional strategies across various benchmarks.

</details>


### [7] [Nullspace-preserving high-index saddle dynamics method for degenerate multiple solution problems](https://arxiv.org/abs/2510.24292)
*Kai Jiang,Lei Zhang,Xiangcheng Zheng,Tiejun Zhou*

Main category: math.NA

TL;DR: NPHiSD method for locating high-index saddle points in degenerate systems by searching along multiple ascent directions while preserving nullspace orthogonality.


<details>
  <summary>Details</summary>
Motivation: To systematically construct solution landscapes for degenerate multiple solution systems by efficiently locating high-index saddle points that serve as parent states for downward searches.

Method: Divides search into segments where ascent directions remain orthogonal to the nullspace of initial segment state, with proved condition for efficient ascent directions.

Result: Successfully applied to Lifshitz-Petrich, Gross-Pitaevskii, and Lennard-Jones models, demonstrating universality and effectiveness.

Conclusion: NPHiSD provides an efficient approach for systematically exploring solution landscapes in degenerate problems through nullspace-preserving high-index saddle dynamics.

Abstract: We propose the nullspace-preserving high-index saddle dynamics (NPHiSD)
method for degenerating multiple solution systems in constrained and
unconstrained settings. The NPHiSD efficiently locates high-index saddle points
and provides parent states for downward searches of lower-index saddles,
thereby constructing the solution landscape systematically. The NPHiSD method
searches along multiple efficient ascent directions by excluding the nullspace,
which is the key for upward searches in degenerate problems. To reduce the cost
of frequent nullspace updates, the search is divided into segments, within
which the ascent directions remain orthogonal to the nullspace of the initial
state of each segment. A sufficient and necessary condition for characterizing
the segment that admits efficient ascent directions is proved. Extensive
numerical experiments for typical problems such as Lifshitz-Petrich,
Gross-Pitaevskii, and Lennard-Jones models are performed to show the
universality and effectiveness of the NPHiSD method.

</details>


### [8] [Approximation of invariant measures for random lattice reversible Selkov systems](https://arxiv.org/abs/2510.24311)
*Fang Su,Xue Wang,Xia Pa*

Main category: math.NA

TL;DR: Numerical approximation of random lattice reversible Selkov systems using backward Euler-Maruyama scheme, establishing convergence of invariant measures from discrete to continuous systems.


<details>
  <summary>Details</summary>
Motivation: To develop numerical methods for approximating invariant measures in random lattice reversible Selkov systems with nonlinear noise, addressing the challenge of numerical approximation in stochastic systems.

Method: Uses backward Euler-Maruyama (BEM) scheme for time discretization, examines both infinite and finite dimensional random models, employs path convergence technique to show convergence of invariant measures.

Result: Establishes existence of numerical invariant measures for random models with nonlinear noise, demonstrates convergence of BEM scheme invariant measures to those of the original random lattice reversible Selkov systems.

Conclusion: The invariant measure of random lattice reversible Selkov systems can be approximated by numerical invariant measures of finite dimensional truncated systems as discrete time step size approaches zero.

Abstract: This paper focuses on the numerical approximation of random lattice
reversible Selkov systems. It establishes the existence of numerical invariant
measures for random models with nonlinear noise, using the backward
Euler-Maruyama (BEM) scheme for time discretization. The study examines both
infinite dimensional discrete random models and their corresponding finite
dimensional truncations. A classical path convergence technique is employed to
demonstrate the convergence of the invariant measures of the BEM scheme to
those of the random lattice reversible Selkov systems. As the discrete time
step size approaches zero, the invariant measure of the random lattice
reversible Selkov systems can be approximated by the numerical invariant
measure of the finite dimensional truncated systems.

</details>


### [9] [Robust stability and preconditioning of Darcy-Forchheimer equations](https://arxiv.org/abs/2510.24527)
*Rishi Das,Harsha Hutridurga,Amiya K. Pani,Ricardo Ruiz-Baier*

Main category: math.NA

TL;DR: Parameter-robust quasi-optimal error estimates for mixed finite element methods for nonlinear Darcy-Forchheimer equations with mixed boundary conditions, plus efficient block preconditioners for linearised systems.


<details>
  <summary>Details</summary>
Motivation: To develop robust numerical methods for nonlinear Darcy-Forchheimer equations that maintain performance across different parameter values and mesh sizes, addressing challenges in permeability and inertia coefficient variations.

Method: Mixed finite element methods combined with operator preconditioning framework to design efficient block preconditioners for linearised systems of nonlinear Darcy-Forchheimer equations with mixed boundary conditions.

Result: Derived parameter-robust quasi-optimal error estimates and demonstrated robustness of preconditioners with respect to permeability and inertia coefficients through numerical examples showing parameter and mesh-size independence of convergence rates.

Conclusion: The proposed mixed finite element formulation and block preconditioners provide robust and efficient numerical methods for nonlinear Darcy-Forchheimer equations, maintaining consistent performance across varying parameters and mesh refinements.

Abstract: We derive parameter-robust quasi-optimal error estimates for mixed finite
element methods for the nonlinear Darcy--Forchheimer equations with mixed
boundary conditions. Using the framework of operator preconditioning, we also
design efficient block preconditioners for the linearised system, that exhibit
robustness with respect to the coefficients that modulate permeability and
inertia of the system. The properties of the formulation (parameter and
mesh-size independence of the convergence rates) are illustrated by means of
several numerical examples.

</details>


### [10] [Enforcing boundary conditions for physics-informed neural operators](https://arxiv.org/abs/2510.24557)
*Niklas Göschel,Sebastian Götschel,Daniel Ruprecht*

Main category: math.NA

TL;DR: The paper introduces new methods for strongly enforcing Neumann and Robin boundary conditions in physics-informed machine learning approaches, overcoming limitations of previous methods that required fully C^1 boundaries and could be unstable on piecewise C^1 boundaries.


<details>
  <summary>Details</summary>
Motivation: Previous approaches to strongly enforcing Neumann or Robin boundary conditions in physics-informed neural networks/operators require fully C^1 boundaries and can be unstable on piecewise C^1 boundaries, limiting their practical applicability.

Method: Two new approaches: 1) a generalization of Sukumar & Srivastava's method, and 2) a new approach based on orthogonal projections that can handle boundaries that are piecewise C^1 but only C^0 globally.

Result: The performance of these new techniques was evaluated against weakly and semi-weakly enforced boundary conditions for the scalar Darcy flow equation and stationary Navier-Stokes equations.

Conclusion: The proposed methods successfully overcome the limitations of previous approaches, enabling stable strong enforcement of Neumann and Robin boundary conditions on more complex boundary geometries.

Abstract: Machine-learning based methods like physics-informed neural networks and
physics-informed neural operators are becoming increasingly adept at solving
even complex systems of partial differential equations. Boundary conditions can
be enforced either weakly by penalizing deviations in the loss function or
strongly by training a solution structure that inherently matches the
prescribed values and derivatives. The former approach is easy to implement but
the latter can provide benefits with respect to accuracy and training times.
However, previous approaches to strongly enforcing Neumann or Robin boundary
conditions require a domain with a fully $C^1$ boundary and, as we demonstrate,
can lead to instability if those boundary conditions are posed on a segment of
the boundary that is piecewise $C^1$ but only $C^0$ globally. We introduce a
generalization of the approach by Sukumar \& Srivastava (doi:
10.1016/j.cma.2021.114333), and a new approach based on orthogonal projections
that overcome this limitation. The performance of these new techniques is
compared against weakly and semi-weakly enforced boundary conditions for the
scalar Darcy flow equation and the stationary Navier-Stokes equations.

</details>


### [11] [Preconditioned Truncated Single-Sample Estimators for Scalable Stochastic Optimization](https://arxiv.org/abs/2510.24587)
*Tianshi Xu,Difeng Cai,Hua Huang,Edmond Chow,Yuanzhe Xi*

Main category: math.NA

TL;DR: The paper introduces PTSS estimators, a family of stochastic Krylov methods that combine preconditioning with truncated Lanczos iterations to provide low-variance, stable estimators for linear system solutions and log-determinants in stochastic optimization.


<details>
  <summary>Details</summary>
Motivation: Classical iterative solvers for linear systems and log-determinants in stochastic optimization suffer from truncation bias, while unbiased Krylov-based estimators typically have high variance and numerical instability, creating a need for more efficient estimators.

Method: Developed Preconditioned Truncated Single-Sample (PTSS) estimators that integrate preconditioning with truncated Lanczos iterations to construct unbiased stochastic estimators with controlled variance.

Result: PTSS achieves superior stability and variance control compared to existing unbiased and biased alternatives, with theoretical guarantees on mean, variance, and concentration properties, and explicit quantification of variance reduction from preconditioning.

Conclusion: PTSS provides an efficient framework for stochastic optimization by offering low-variance, stable estimators for linear system solutions, log-determinants, and their derivatives, overcoming limitations of existing methods.

Abstract: Many large-scale stochastic optimization algorithms involve repeated
solutions of linear systems or evaluations of log-determinants. In these
regimes, computing exact solutions is often unnecessary; it is more
computationally efficient to construct unbiased stochastic estimators with
controlled variance. However, classical iterative solvers incur truncation
bias, whereas unbiased Krylov-based estimators typically exhibit high variance
and numerical instability. To mitigate these issues, we introduce the
Preconditioned Truncated Single-Sample (PTSS) estimators--a family of
stochastic Krylov methods that integrate preconditioning with truncated Lanczos
iterations. PTSS yields low-variance, stable estimators for linear system
solutions, log-determinants, and their derivatives. We establish theoretical
results on their mean, variance, and concentration properties, explicitly
quantifying the variance reduction induced by preconditioning. Numerical
experiments confirm that PTSS achieves superior stability and variance control
compared with existing unbiased and biased alternatives, providing an efficient
framework for stochastic optimization.

</details>


### [12] [On a robust inf-sup condition for the Stokes problem in slender domains -- with application to preconditioning](https://arxiv.org/abs/2510.24590)
*Espen Sande,Timo Koch,Miroslav Kuchta,Kent-Andre Mardal*

Main category: math.NA

TL;DR: A new norm for pressure in Stokes equations enables continuous inf-sup condition with aspect-ratio independent constant, unlike standard approaches that fail for slender domains.


<details>
  <summary>Details</summary>
Motivation: Standard inf-sup constants for Stokes equations deteriorate as domain aspect ratio increases, making analysis and preconditioning unreliable in slender domains.

Method: Identified a specific norm for pressure variable that maintains continuous inf-sup condition with constant independent of domain aspect ratio, then applied this to construct robust operator preconditioners.

Result: Successfully proved continuous inf-sup condition with aspect-ratio independent constant and developed robust preconditioners for Stokes problems in slender domains, validated by numerical examples.

Conclusion: The proposed pressure norm enables robust analysis and preconditioning for Stokes equations in domains with high aspect ratios, overcoming limitations of standard approaches.

Abstract: We identify a norm on the pressure variable in the Stokes equation that
allows us to prove a continuous inf-sup condition with a constant independent
of the domain's aspect ratio. This is in contrast to the standard inf-sup
constant, which breaks down as the aspect ratio increases. We further apply our
result to construct robust operator preconditioners for the Stokes problem in
slender domains. Several numerical examples illustrate the theory.

</details>


### [13] [Random Walks, Faber Polynomials and Accelerated Power Methods](https://arxiv.org/abs/2510.24608)
*Peter Cowal,Nicholas F. Marshall,Sara Pollock*

Main category: math.NA

TL;DR: The paper constructs polynomial families from mean-zero random walk recurrences that can approximate z^n with degree ~√n in complex domains, and applies them to develop dynamic momentum power iteration methods for non-symmetric matrices.


<details>
  <summary>Details</summary>
Motivation: To develop efficient polynomial approximation methods for iterative linear algebra applications, particularly for non-symmetric matrices where traditional methods may not be optimal.

Method: Construct families of polynomials using recurrence relations derived from mean-zero random walks, analyze their approximation properties for z^n in radially convex domains, and establish connections to Faber polynomials.

Result: The constructed polynomial families can approximate z^n with degree scaling as ~√n, exhibit rapid growth properties, and enable the development of arbitrary-order dynamic momentum power iteration methods.

Conclusion: The random walk-inspired polynomial families provide an effective framework for polynomial approximation and enable improved iterative methods for non-symmetric linear algebra problems.

Abstract: In this paper, we construct families of polynomials defined by recurrence
relations related to mean-zero random walks. We show these families of
polynomials can be used to approximate $z^n$ by a polynomial of degree $\sim
\sqrt{n}$ in associated radially convex domains in the complex plane. Moreover,
we show that the constructed families of polynomials have a useful rapid growth
property and a connection to Faber polynomials. Applications to iterative
linear algebra are presented, including the development of arbitrary-order
dynamic momentum power iteration methods suitable for classes of non-symmetric
matrices.

</details>


### [14] [Reduced Basis Approach for Convection-Diffusion Equations with Non-Linear Boundary Reaction Conditions](https://arxiv.org/abs/2510.24632)
*Sebastian Matera,Christian Merdon,Daniel Runge*

Main category: math.NA

TL;DR: Efficient reduced basis method for drift-diffusion problems with non-linear boundary conditions using discrete Green's-like functions to reduce global non-linear problems to smaller boundary problems.


<details>
  <summary>Details</summary>
Motivation: Solve drift-diffusion problems with non-linear boundary conditions efficiently, particularly in heterogeneous catalysis applications where non-linearity only affects boundary degrees of freedom.

Method: Reduced basis ansatz computing discrete Green's-like functions for drift-diffusion operator, reducing global non-linear problem to smaller boundary non-linear problem. Uses mass-conservative finite volume method.

Result: Method successfully demonstrated on catalytic CO oxidation example. Basis functions are independent of non-linearities and reusable for same differential operator and geometry.

Conclusion: Proposed strategy provides efficient solution for drift-diffusion problems with non-linear boundary conditions, with reusable basis functions applicable to inverse problems and catalyst modeling in heterogeneous catalysis.

Abstract: This paper aims at an efficient strategy to solve drift-diffusion problems
with non-linear boundary conditions as they appear, e.g., in heterogeneous
catalysis. Since the non-linearity only involves the degrees of freedom along
(a part of) the boundary, a reduced basis ansatz is suggested that computes
discrete Green's-like functions for the present drift-diffusion operator such
that the global non-linear problem reduces to a smaller non-linear problem for
a boundary method. The computed basis functions are completely independent of
the non-linearities. Thus, they can be reused for problems with the same
differential operator and geometry. Corresponding scenarios might be inverse
problems in heterogeneous catalysis but also modeling the effect of different
catalysts in the same reaction chamber. The strategy is explained for a
mass-conservative finite volume method and demonstrated on a simple numerical
example for catalytic CO oxidation.

</details>


### [15] [Kemeny's constant minimization for reversible Markov chains via structure-preserving perturbations](https://arxiv.org/abs/2510.24679)
*Fabio Durastante,Miryam Gnazzo,Beatrice Meini*

Main category: math.NA

TL;DR: Investigating whether structure-preserving perturbations to reversible Markov chains can improve connectivity while maintaining fixed stationary distribution, with focus on minimizing Kemeny's constant under sparsity constraints.


<details>
  <summary>Details</summary>
Motivation: Kemeny's constant measures Markov chain efficiency in traversing states, and the research aims to determine if perturbations can improve connectivity while preserving structure and stationary distribution.

Method: Reformulate the problem as an optimization task, focusing on solution existence and efficient algorithms, particularly for minimizing Kemeny's constant under sparsity constraints.

Result: The minimum achievable value for Kemeny's constant can be estimated, though the required perturbations may be infeasible in practice.

Conclusion: The paper presents an optimization framework for improving Markov chain connectivity through structure-preserving perturbations while maintaining stationary distribution, with emphasis on sparsity-constrained minimization of Kemeny's constant.

Abstract: Kemeny's constant measures the efficiency of a Markov chain in traversing its
states. We investigate whether structure-preserving perturbations to the
transition probabilities of a reversible Markov chain can improve its
connectivity while maintaining a fixed stationary distribution. Although the
minimum achievable value for Kemeny's constant can be estimated, the required
perturbations may be infeasible. We reformulate the problem as an optimization
task, focusing on solution existence and efficient algorithms, with an emphasis
to the problem of minimizing Kemeny's constant under sparsity constraints.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [16] [Keller-Osserman and Harnack type results for nonlinear elliptic PDE with unbounded ingredients](https://arxiv.org/abs/2510.23834)
*Boyan Sirakov,Aelson Sobral*

Main category: math.AP

TL;DR: The paper extends the Keller-Osserman theorem to divergence-form operators with unbounded coefficients, settles an open question about the strong maximum principle under Vázquez's optimal integral condition, and generalizes Julin's Harnack inequality for positive solutions.


<details>
  <summary>Details</summary>
Motivation: Previous results on the Keller-Osserman theorem for equations of the form L[u] = f(u) were limited to operators with locally bounded coefficients. This work aims to extend these results to the more general case of operators with unbounded coefficients in the natural regime of local integrability.

Method: The authors work with general divergence-form operators with unbounded coefficients, operating within the natural regime of local integrability. They employ analytical techniques to extend classical results to this broader setting.

Result: The paper proves that the Keller-Osserman theorem holds for divergence-form operators with unbounded coefficients, establishes the validity of the strong maximum principle for supersolutions under Vázquez's optimal integral condition, and obtains a Harnack inequality for positive solutions that extends Julin's result.

Conclusion: This work successfully extends classical results in partial differential equations to the more general setting of operators with unbounded coefficients, resolving open questions and providing comprehensive extensions of fundamental theorems in the field.

Abstract: We show that the classical Keller-Osserman theorem on the solvability of the
equation $\mathcal{L}[u] = f(u)$ is valid when $\mathcal{L}$ is a general
operator in divergence form with unbounded coefficients in the natural regime
of local integrability. This has been open up to now, earlier results concerned
operators with locally bounded ingredients. We also settle an open question
from \cite{SS21} about the validity of the strong maximum principle for
supersolutions of $\mathcal{L}[u] = f(u)$ under the optimal integral condition
of V\'azquez. More generally, we obtain a Harnack inequality for positive
solutions of this equation, which extends a result by V. Julin.

</details>


### [17] [A Coupled Generalized Korteweg-de Vries System Driven by White Noise](https://arxiv.org/abs/2510.23843)
*Aissa Boukarou*

Main category: math.AP

TL;DR: Analysis of coupled stochastic KdV equations with nonlinear coupling and additive white noise, establishing local well-posedness for initial data in H^s × H^s with s > 1/2.


<details>
  <summary>Details</summary>
Motivation: The system models interacting wave fields with different dispersion relations subject to random environmental fluctuations, appearing in fluid dynamics, plasma physics, and nonlinear optics.

Method: Study a system of coupled, stochastic generalized Korteweg-de Vries equations with nonlinear coupling and additive space-time white noise.

Result: Determined sufficient conditions that ensure the problem is locally well-posed for initial data (φ₀, φ₀) ∈ H^s × H^s, where s > 1/2.

Conclusion: The coupled stochastic KdV system exhibits local well-posedness under appropriate conditions for sufficiently regular initial data.

Abstract: This work investigates a system of coupled, stochastic generalized
Korteweg-de Vries equations with nonlinear coupling and additive space-time
white noise. The system models interacting wave fields with different
dispersion relations subject to random environmental fluctuations, and it
appears in various physical contexts such as fluid dynamics, plasma physics,
and nonlinear optics. For this system, we determine sufficient conditions that
ensure the problem is locally well-posed for $(\phi_0,\varphi_0)\in H^{s}
\times H^{s},$ where $ s>\frac{1}{2}$.

</details>


### [18] [Intrinsic Scalings with Non-standard Growth](https://arxiv.org/abs/2510.23939)
*M. D. Amaral,J. G. Araújo*

Main category: math.AP

TL;DR: The paper develops quantitative regularity estimates for degenerate parabolic PDEs with Orlicz-type diffusive structures using geometric tangential analysis and intrinsic scalings.


<details>
  <summary>Details</summary>
Motivation: To investigate and establish precise interior Hölder regularity estimates for bounded weak solutions of degenerate parabolic PDEs with Orlicz-type diffusive structures.

Method: Uses geometric tangential analysis tailored to Orlicz-type structures and a general notion of intrinsic scalings to derive regularity estimates.

Result: Derives precise interior Hölder regularity estimates for bounded weak solutions, providing new insights even in the time-stationary case.

Conclusion: The geometric tangential approach with intrinsic scalings successfully establishes quantitative regularity estimates for degenerate parabolic PDEs with Orlicz-type diffusive structures.

Abstract: In this work, we investigate quantitative regularity estimates for degenerate
parabolic partial differential equations, with a focus on Orlicz-type diffusive
structures. Using a geometric tangential analysis tailored to these structures
and a general notion of intrinsic scalings, we derive precise interior H\"older
regularity estimates for bounded weak solutions. These results offer new
insights, even in the time-stationary case.

</details>


### [19] [A class of forward-backward regularizations of the Perona-Malik equation with variable exponent](https://arxiv.org/abs/2510.23982)
*Yihui Tong,Wenjie Liu,Zhichang Guo,Wenjuan Yao*

Main category: math.AP

TL;DR: This paper studies a novel class of regularizations of the Perona-Malik equation with variable exponents, establishing existence of Young measure solutions for Neumann initial-boundary value problems using Sobolev approximation and vanishing viscosity methods.


<details>
  <summary>Details</summary>
Motivation: To develop forward-backward parabolic equations with variational structure for potential applications in image processing, addressing the regularization of the Perona-Malik equation with variable exponents.

Method: Uses Sobolev approximation and vanishing viscosity limit to establish existence of Young measure solutions. Proofs rely on Rothe's method, variational principles, and Young measure theory.

Result: Established existence of Young measure solutions to the Neumann initial-boundary value problem for the proposed Perona-Malik equation with variable exponents.

Conclusion: The theoretical results confirm numerical observations about the generic behavior of solutions with suitably chosen variable exponents, validating the proposed regularization approach.

Abstract: This paper investigates a novel class of regularizations of the Perona-Malik
equation with variable exponents, of forward-backward parabolic type, which
possess a variational structure and have potential applications in image
processing. The existence of Young measure solutions to the Neumann
initial-boundary value problem for the proposed equation is established via
Sobolev approximation and the vanishing viscosity limit. The proofs rely on
Rothe's method, variational principles, and Young measure theory. The
theoretical results confirm numerical observations concerning the generic
behavior of solutions with suitably chosen variable exponents.

</details>


### [20] [Stability estimates for $L^p$-Caffarelli-Kohn-Nirenberg inequalities](https://arxiv.org/abs/2510.24022)
*Xiao-Ping Chen,Chun-Lei Tang*

Main category: math.AP

TL;DR: This paper studies the stability of scale invariant and non-invariant L^p-Caffarelli-Kohn-Nirenberg inequalities using new vector inequalities from Figalli and Zhang, extending previous work for 1<p<2 and generalizing results to 1<p<N.


<details>
  <summary>Details</summary>
Motivation: To fill gaps in recent work by Do et al. for the range 1<p<2 and extend results of Cazacu et al. to more general cases of L^p-Caffarelli-Kohn-Nirenberg inequalities.

Method: Uses new vector inequalities established by Figalli and Zhang to analyze stability properties of both scale invariant and scale non-invariant L^p-Caffarelli-Kohn-Nirenberg inequalities.

Result: The study provides stability results for L^p-Caffarelli-Kohn-Nirenberg inequalities in the parameter range 1<p<N, completing previous work.

Conclusion: The paper successfully extends stability analysis of Caffarelli-Kohn-Nirenberg inequalities to broader parameter ranges using modern vector inequality techniques.

Abstract: Based on some new vector inequalities established by Figalli and Zhang
[\emph{Duke Math. J.} \textbf{171} (2022), 2407--2459], we study the stability
of the scale invariant and the scale non-invariant
$L^p$-Caffarelli-Kohn-Nirenberg inequalities, which fills the recent work of Do
\emph{et al.} [$L^p$-Caffarelli-Kohn-Nirenberg inequalities and their
stabilities, arXiv: 2310.07083] for $1<p<2$, and also extends some results of
Cazacu \emph{et al.} [\emph{J. Math. Pures Appl. (9)} \textbf{182} (2024),
253--284] to a general case for $L^p$-Caffarelli-Kohn-Nirenberg inequalities
with $1<p<N$.

</details>


### [21] [Deep Learning-Enhanced Calibration of the Heston Model: A Unified Framework](https://arxiv.org/abs/2510.24074)
*Arman Zadgar,Somayeh Fallah,Farshid Mehrdoust*

Main category: math.AP

TL;DR: A hybrid deep learning framework using two neural networks improves Heston model calibration for European options, achieving better accuracy and efficiency than traditional methods.


<details>
  <summary>Details</summary>
Motivation: The Heston stochastic volatility model's calibration is computationally intensive and sensitive to local minima due to its nonlinear structure and high-dimensional parameter space.

Method: Integrates two supervised feedforward neural networks: Price Approximator Network (PAN) for option price approximation and Calibration Correction Network (CCN) for refining Heston model outputs by correcting systematic pricing errors.

Result: Outperforms traditional calibration techniques on real S&P 500 option data across multiple error metrics, achieving faster convergence and superior generalization in both in-sample and out-of-sample settings.

Conclusion: The framework offers a practical and robust solution for real-time financial model calibration.

Abstract: The Heston stochastic volatility model is a widely used tool in financial
mathematics for pricing European options. However, its calibration remains
computationally intensive and sensitive to local minima due to the model's
nonlinear structure and high-dimensional parameter space. This paper introduces
a hybrid deep learning-based framework that enhances both the computational
efficiency and the accuracy of the calibration procedure. The proposed approach
integrates two supervised feedforward neural networks: the Price Approximator
Network (PAN), which approximates the option price surface based on strike and
moneyness inputs, and the Calibration Correction Network (CCN), which refines
the Heston model's output by correcting systematic pricing errors. Experimental
results on real S\&P 500 option data demonstrate that the deep learning
approach outperforms traditional calibration techniques across multiple error
metrics, achieving faster convergence and superior generalization in both
in-sample and out-of-sample settings. This framework offers a practical and
robust solution for real-time financial model calibration.

</details>


### [22] [Donsker-Varadhan large deviation principle for locally damped and randomly forced NLS equations](https://arxiv.org/abs/2510.24119)
*Yuxuan Chen,Shengquan Xiang*

Main category: math.AP

TL;DR: The paper studies large deviations from invariant measures for nonlinear Schrödinger equations with colored noises on determining modes, using a new abstract criterion and bootstrap argument for Feynman-Kac semigroups.


<details>
  <summary>Details</summary>
Motivation: To analyze large deviations from invariant measures in nonlinear Schrödinger equations with colored noises, addressing difficulties caused by fixed squeezing rates.

Method: Introduces a new abstract criterion inspired by previous work, uses bootstrap argument to derive Lipschitz estimates for Feynman-Kac semigroups.

Result: Developed a method to handle fixed squeezing rate difficulties and established Lipschitz estimates for Feynman-Kac semigroups.

Conclusion: The proposed criterion successfully addresses large deviations in nonlinear Schrödinger equations and is also applicable to wave equations and Navier-Stokes systems.

Abstract: We study large deviations from the invariant measure for nonlinear
Schr\"odinger equations with colored noises on determining modes. The proof is
based on a new abstract criterion, inspired by [V. Jak\v{s}i\'{c} et al., Comm.
Pure Appl. Math., 68 (2015), 2108-2143]. To address the difficulty caused by
fixed squeezing rate, we introduce a bootstrap argument to derive Lipschitz
estimates for Feynman-Kac semigroups. This criterion is also applicable to wave
equations and Navier-Stokes system.

</details>


### [23] [Global stability and asymptotic behavior for the incompressible MHD equations without viscosity or magnetic diffusion](https://arxiv.org/abs/2510.24338)
*Qunyi Bie,Hui Fang,Yanping Zhou*

Main category: math.AP

TL;DR: Background magnetic fields stabilize conducting fluids. This paper provides rigorous mathematical justification for this effect in n-dimensional magnetohydrodynamic equations with partial diffusion.


<details>
  <summary>Details</summary>
Motivation: To mathematically justify the observed phenomenon that magnetic fields stabilize and dampen electrically conducting fluids, which has been shown in physical experiments and numerical simulations.

Method: Established global stability and derived explicit decay rates for perturbations around equilibrium magnetic fields satisfying Diophantine condition, using dimension-independent analytical framework.

Result: Achieved effective decay rates in all intermediate Sobolev norms and significantly relaxed regularity requirements on initial data compared to previous works.

Conclusion: The developed analytical framework is dimension-independent and can be flexibly adapted to other fluid models with partial dissipation.

Abstract: Physical experiments and numerical simulations have revealed a remarkable
stabilizing phenomenon: a background magnetic field stabilizes and dampens
electrically conducting fluids. This paper provides a rigorous mathematical
justification of this effect for the $n$-dimensional incompressible
magnetohydrodynamic equations with partial diffusion on periodic domains. We
establish the global stability and derive explicit decay rates for
perturbations around an equilibrium magnetic field satisfying the Diophantine
condition. Our results yield the \textit{effective decay rates in all
intermediate Sobolev norms} and \textit{significantly relax the regularity
requirements} on the initial data compared with previous works (\textit{Sci.
China Math.} 41:1--10, 2022; \textit{J. Differ. Equ.} 374:267--278, 2023;
\textit{Calc. Var. Partial Differ. Equ.} 63:191, 2024). Furthermore, the
analytical framework developed here is dimension-independent and can be
flexibly adapted to other fluid models with partial dissipation.

</details>


### [24] [Nonlinear Schrödinger equation on a unit ball in one and two dimensions](https://arxiv.org/abs/2510.24407)
*Christian Klein,Svetlana Roudenko,Nikola Stoilov*

Main category: math.AP

TL;DR: The paper analyzes the nonlinear Schrödinger equation on a unit ball with Dirichlet boundary conditions, showing that ground state solutions are stable in subcritical/critical cases, while splitting into stable/unstable branches in supercritical cases. Solutions either blow up, oscillate, or remain near ground states depending on perturbation amplitude.


<details>
  <summary>Details</summary>
Motivation: To understand the stabilizing effect of Dirichlet boundary conditions on nonlinear Schrödinger equation solutions and characterize solution behavior near ground states under perturbations.

Method: Analysis of the nonlinear Schrödinger equation on a unit ball in 1D and 2D with Dirichlet boundary conditions, examining ground state stability and perturbation effects.

Result: Ground states are stable in subcritical/critical cases; in supercritical cases they split into stable/unstable branches. Perturbations lead to blow-up (large amplitude), oscillation (small amplitude), or remain near ground states (stable branch). No scattering/radiation observed.

Conclusion: Dirichlet boundary conditions provide stabilization, with soliton resolution holding for all data. Solutions decompose into coherent ground state structures even for small initial data, with distinct stability behaviors depending on perturbation amplitude.

Abstract: We consider the nonlinear Schr\"odinger equation on a unit ball in one and
two dimensions with Dirichlet boundary conditions, which have stabilizing
effect on solutions behavior. In particular, we confirm that the ground state
solutions are stable in subcritical and critical cases, and in the
supercritical case the ground state solutions split into a stable and an
unstable branch. Perturbations of a ground state on the stable branch keep
solutions near a corresponding ground state with very small oscillation around
it, while perturbations of the unstable branch make solutions either blow up in
finite time, if perturbations have an amplitude large than the height of the
ground state, or oscillate between two states, if perturbations have an
amplitude smaller than the original ground state. We also observe that this
equation does not have any scattering or radiation, and thus, the soliton
resolution holds for all data, splitting solutions into coherent structures
such as ground state solutions even for very small initial data.

</details>


### [25] [Payne's nodal line conjecture fails on doubly-connected planar domains](https://arxiv.org/abs/2510.24436)
*Pedro Freitas,Roméo Leylekian*

Main category: math.AP

TL;DR: The paper provides counterexamples to Payne's nodal line conjecture for planar domains with one hole, showing that second Dirichlet eigenfunctions can have closed nodal lines that don't touch the boundary.


<details>
  <summary>Details</summary>
Motivation: To test the validity of Payne's nodal line conjecture, which concerns the behavior of nodal lines of second Dirichlet eigenfunctions in planar domains.

Method: Constructed examples of bounded planar domains with one single hole and analyzed the nodal lines of their second Dirichlet eigenfunctions.

Result: Found domains where the nodal line of the second Dirichlet eigenfunction is closed and does not touch the boundary, contradicting what would be expected if Payne's conjecture held.

Conclusion: Payne's nodal line conjecture cannot hold for multiply-connected domains in the plane; it can at most be valid for simply-connected domains.

Abstract: We present examples of bounded planar domains with one single hole for which
the nodal line of a second Dirichlet eigenfunction is closed and does not touch
the boundary. This shows that Payne's nodal line conjecture can at most hold
for simply-connected domains in the plane.

</details>


### [26] [A note on relations between convexity and concavity of thermodynamic functions](https://arxiv.org/abs/2510.24440)
*Mária Lukáčová-Medvid'ová,Ferdinand Thein,Gerald Warnecke,Yuhuan Yuan*

Main category: math.AP

TL;DR: The paper proves equivalence relations for convexity/concavity properties of thermodynamic functions under different variable transformations, independent of specific equations of state.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous mathematical foundations for convexity properties in thermodynamics, enabling easier proofs of properties like strict concavity of entropy density in continuum mechanics.

Method: Mathematical proofs using transformations of variables and functions, analyzing convexity, strict convexity, positive definite Hessian matrices, and analogous concavity properties.

Result: Established equivalence relations for convexity properties between thermodynamic functions that are independent of specific equations of state.

Conclusion: The results provide powerful tools for proving thermodynamic function properties and have applications in continuum mechanics and mathematical analysis of thermodynamic systems.

Abstract: The paper is concerned with proving the equivalence of convexity or concavity
properties of thermodynamic functions, such as energy and entropy, depending on
different sets of variables. These variables are the basic thermodynamic state
variables, specific state variables or the densities of state variables that
are used in continuum mechanics. We prove results for transformations of
variables and functions in conjunction with convexity properties. We are
concerned with convexity, strict convexity, positive definite Hessian matrices
and the analogous forms of concavity. The main results are equivalence
relations for these properties between functions. These equivalences are
independent of the equations of state since they only use general properties of
them. The results can be used for instance to easily prove that the entropy
density function for the Euler equations in conservative variables in three
space dimensions is strictly concave or even has a negative definite Hessian
matrix. Further, we show how various equations of state imply these properties
and how these properties are relevant to mathematical analysis.

</details>


### [27] [Stochastic perturbation and zero noise limit for scalar conservation laws](https://arxiv.org/abs/2510.24475)
*Ulrik S. Fjordholm,Magnus C. Ørke*

Main category: math.AP

TL;DR: A stochastic perturbation of scalar conservation laws is introduced, inspired by mean field games. Well-posedness is proven, convergence to the entropy solution as noise vanishes is established, and the noise serves as a selection criterion for deterministic conservation laws.


<details>
  <summary>Details</summary>
Motivation: Scalar conservation laws are simple enough for analytical study yet exhibit rich nonlinear phenomena. The goal is to introduce stochastic perturbations to provide selection criteria for deterministic conservation laws.

Method: A novel stochastic perturbation of scalar conservation laws is introduced, inspired by mean field games. Well-posedness is proven and convergence analysis is conducted as the noise parameter approaches zero.

Result: The stochastically perturbed equation is well-posed and converges to the unique entropy solution of the conservation law as the noise parameter is sent to zero. The noise acts as a selection criterion.

Conclusion: This represents the first such result for nonlinear hyperbolic conservation laws, establishing stochastic perturbations as effective selection mechanisms for deterministic conservation laws.

Abstract: Scalar conservation laws sit at the intersection between being simple enough
to study analytically, while being complex enough to exhibit a wide range of
nonlinear phenomena. We introduce a novel stochastic perturbation of scalar
conservation laws, inspired by mean field games. We prove well-posedness of the
stochastically perturbed equation; prove that it converges as the noise
parameter is sent to $0$; and that the limit is the unique entropy solution of
the conservation law. Thus, the noise acts as a selection criterion for
(deterministic) conservation laws. This is the first such result for nonlinear
hyperbolic conservation laws.

</details>


### [28] [Resolvent bounds imply observability from measurable time sets for Schrödinger equations](https://arxiv.org/abs/2510.24517)
*Nicolas Burq,Hui Zhu*

Main category: math.AP

TL;DR: Resolvent bounds for Laplace-Beltrami operator imply observability and controllability for Schrödinger propagator from time sets of positive measure on compact Riemannian manifolds.


<details>
  <summary>Details</summary>
Motivation: To establish connections between resolvent bounds and control properties for Schrödinger equations on manifolds, extending results beyond time intervals to more general time sets.

Method: Mathematical analysis proving that resolvent bounds for the Laplace-Beltrami operator imply observability and controllability properties for the Schrödinger propagator.

Result: Proved that resolvent bounds imply observability and controllability from time sets of positive Lebesgue measure, covering cases including geometric control condition satisfaction and compact surfaces of negative curvature.

Conclusion: Resolvent bounds provide sufficient conditions for observability and controllability of Schrödinger propagators on compact Riemannian manifolds, generalizing previous results to time sets beyond intervals.

Abstract: We prove that on a compact Riemannian manifold, resolvent bounds for the
Laplace--Beltrami operator imply observability, and thus controllability, for
the Schr\"odinger propagator from time sets of positive Lebesgue measure.
Applications include almost all cases where observability and controllability
hold from time intervals, particularly when the geometric control condition is
satisfied or when the manifold is a compact surface of negative curvature.

</details>


### [29] [Non-polyconvex $Q$-integrands with lower semicontinuous energies](https://arxiv.org/abs/2510.24610)
*Daniele De Gennaro,Antonio De Rosa*

Main category: math.AP

TL;DR: The paper constructs a counterexample showing that all natural numbers Q are necessary for approximating certain positive measures on oriented m-vectors in R^n using Lipschitz Q-graphs, proving the sharpness of a previous approximation result.


<details>
  <summary>Details</summary>
Motivation: To establish the sharpness of a previous approximation theorem and provide geometric obstructions to approximation by Lipschitz multigraphs, addressing questions about weak lower semicontinuity of energies.

Method: Construction of a positive measure on positively oriented 2-vectors in R^4 (extendable to m-vectors in R^n) whose barycenter is simple but cannot be approximated by weighted Gaussian images of Lipschitz Q-graphs for any fixed Q.

Result: The approximation result from previous work is shown to be sharp - all Q in N are necessary for density of weighted Gaussian images. As application, existence of non-polyconvex Q-integrands with weakly lower semicontinuous energies in W^{1,p} spaces.

Conclusion: The geometric obstruction demonstrates the necessity of considering all Q in N for approximation, providing new insights into weak lower semicontinuity questions and confirming the optimality of previous results.

Abstract: We construct a positive measure on the space of positively oriented
$2$-vectors in $\mathbb{R}^4$, whose barycenter is a simple $2$-vector, yet
which cannot be approximated by weighted Gaussian images of Lipschitz
$Q$-graphs for any fixed $Q \in \mathbb{N}$. The construction extends to
positively oriented $m$-vectors in $\mathbb{R}^n$ whenever $n-2 \ge m\geq 2$.
This geometric obstruction implies that the approximation result established in
[Arch. Ration. Mech. Anal., 2025] is sharp: all $Q \in \mathbb{N}$ are indeed
necessary to ensure the density of weighted Gaussian images of Lipschitz
multigraphs in the space of positive measures with simple barycenter. As an
application, we prove that for every $Q\geq 1$ and $p\ge 2$ there exists a
non-polyconvex $Q$-integrand whose associated energy is weakly lower
semicontinuous in $W^{1,p}$. This also provides new insight into the question
posed in [Arch. Ration. Mech. Anal., 2025, Remark 1.14].

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [30] [Hybrid Neural Interpolation of a Sequence of Wind Flows](https://arxiv.org/abs/2510.24079)
*Ameir Shaa,Claude Guet,Xiasu Yang,Armand Albergel,Bruno Ribstein,Maxime Nibart*

Main category: physics.comp-ph

TL;DR: Hybrid neural interpolation method combining Tucker tensor decomposition with neural networks for real-time urban wind field prediction, achieving high accuracy with reduced training time compared to pure neural networks.


<details>
  <summary>Details</summary>
Motivation: Traditional CFD approaches are too slow for real-time emergency scenarios requiring rapid urban wind field prediction for particle transport modeling, necessitating faster surrogate models.

Method: Combines Tucker tensor decomposition with neural networks to interpolate RANS solutions across varying wind angles, using Fourier interpolation for angular modes and k-nearest neighbors for spatial interpolation, with neural network correction for artifacts.

Result: Achieved comparable or improved accuracy (R² > 0.99) relative to pure neural network benchmark with significantly reduced training time, while preserving wake dynamics and suppressing oscillations.

Conclusion: The hybrid method provides an accelerated approximate alternative suitable for real-time urban wind simulation, maintaining physical consistency while being computationally efficient.

Abstract: Rapid and accurate urban wind field prediction is essential for modeling
particle transport in emergency scenarios. Traditional Computational Fluid
Dynamics (CFD) approaches are too slow for real-time applications,
necessitating surrogate models. We develop a hybrid neural interpolation method
for constructing surrogate models that can update urban wind maps on timescales
aligned with meteorological variations.
  Our approach combines Tucker tensor decomposition with neural networks to
interpolate Reynolds-Averaged Navier-Stokes (RANS) solutions across varying
inlet wind angles. The method decomposes high-dimensional velocity, pressure,
and eddy viscosity field datasets into a core tensor and factor matrices, then
uses Fourier interpolation for angular modes and k-nearest neighbors
convolution for spatial interpolation. A neural network correction mitigates
interpolation artifacts while preserving physical consistency.
  We validate the approach on a simple cylinder-sphere configuration and,
relative to a strong pure neural network benchmark, achieve comparable or
improved accuracy ($R^2 > 0.99$) with significantly reduced training time. The
pure NN remains a feasible reference model; the hybrid provides an accelerated
approximate alternative that suppresses spurious oscillations, maintains wake
dynamics, and demonstrates computational efficiency suitable for real-time
urban wind simulation.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [31] [Quantum Kinetic Modeling of KEEN waves in a Warm-Dense Regime](https://arxiv.org/abs/2510.23690)
*F. Alejandro Padilla-Gomez,Sining Gong,Michael S. Murillo,F. R. Graziani,Andrew J. Christlieb*

Main category: physics.plasm-ph

TL;DR: Quantum diffraction effects systematically erode classical trapping mechanisms in KEEN waves, increasing drive thresholds, damping higher harmonics, and hastening post-drive decay as quantum parameter H increases.


<details>
  <summary>Details</summary>
Motivation: Ignition-scale capsules compress matter to regimes where electron de Broglie wavelength rivals Debye length, making classical kinetic descriptions insufficient for predictive fusion modeling.

Method: Fully kinetic quantum study using 1D1V Wigner-Poisson solver with second-order Strang-split method, coupling conservative semi-Lagrangian WENO advection to analytic Fourier space update for non-local Wigner term.

Result: As quantum parameter H rises, drive threshold increases, higher harmonics are damped, trapped electron vortices diffuse, and electrostatic energy relaxes to lower stationary level.

Conclusion: KEEN physics extended into quantum domain offers potential diagnostic of nonequilibrium electron dynamics for next-generation inertial-confinement designs, indicating predictive fusion modeling may benefit from integrating kinetic fidelity with quantum effects.

Abstract: We report a fully kinetic, quantum study of Kinetic Electrostatic Electron
Nonlinear (KEEN) waves, showing that quantum diffraction systematically erodes
the classical trapping mechanism, narrow harmonic locking to the fundamental,
and hasten post-drive decay. Electrons are evolved with a second-order
Strang-split 1D1V Wigner-Poisson solver that couples conservative
semi-Lagrangian WENO advection to an analytic Fourier space update for the
non-local Wigner term, while ions remain classical. Short, frequency-tuned
ponderomotive pulses drive KEEN formation in a uniform Maxwellian plasma; as
the dimensionless quantum parameter H rises from the classical limit to values
relevant to warm-dense matter, doped semiconductors, and 2D electron systems,
the drive threshold increases, higher harmonics are damped, trapped electron
vortices diffuse, and the subplasma electrostatic energy relaxes to a lower
stationary level, as confirmed by continuous wavelet analysis. These
microscopic changes carry macroscopic weight. Ignition-scale capsules now
compress matter to regimes where the electron de Broglie wavelength rivals the
Debye length, making classical kinetic descriptions insufficient. By extending
KEEN physics into this quantum domain, our results offer a potential diagnostic
of nonequilibrium electron dynamics for next-generation inertial-confinement
designs and high-energy-density platforms, indicating that predictive fusion
modeling may benefit from the integration of kinetic fidelity with quantum
effects.

</details>


### [32] [Effect of flow-aligned external magnetic fields on mushroom instability](https://arxiv.org/abs/2510.24121)
*Y. Guo,D. Wu,J. Zhang*

Main category: physics.plasm-ph

TL;DR: The paper investigates how external magnetic fields affect mushroom instability (MI) in relativistic jets, finding that magnetic fields suppress MI growth but MI is more robust than electron-scale Kelvin-Helmholtz instabilities.


<details>
  <summary>Details</summary>
Motivation: To understand how mushroom instability acts in magnetized relativistic jets, as astrophysical jets are typically magnetized but the effect of magnetic fields on MI remains poorly understood.

Method: Combined theoretical analysis and particle-in-cell (PIC) simulations, deriving a generalized dispersion relation for linear growth rates of magnetized MIs in cold collisionless plasma, and extending analyses to instabilities with arbitrary wavevectors.

Result: External magnetic fields always suppress MI growth, though MI is more robust to magnetic fields than electron-scale Kelvin-Helmholtz instabilities. PIC simulations confirm analytical predictions and show competition/cooperation between MIs and diffusion-induced DC magnetic fields in finite temperature cases.

Conclusion: Magnetic fields suppress mushroom instability growth in relativistic jets, but MI remains more resilient to magnetic fields compared to other instabilities, with complex interactions observed between MIs and diffusion-induced magnetic fields in realistic plasma conditions.

Abstract: Mushroom instability (MI) is a shear instability considered responsible for
generating and amplifying magnetic fields in relativistic jets. While
astrophysical jets are usually considered to be magnetized, how MI acts in
magnetized jets remains poorly understood. In this paper, we investigate the
effect of a flow-aligned external magnetic field on MI, with both theoretical
analyses and particle-in-cell (PIC) simulations. In the limit of a cold and
collisionless plasma, we derive a generalized dispersion relation for linear
growth rates of the magnetized MIs. Numerical solutions of the dispersion
relation reveal that the external magnetic field always suppresses the growth
of MI, though MIs are much more robust to the external magnetic field than
electron-scale Kelvin-Helmholtz instabilities (ESKHIs). Analyses are also
extended to instabilities with an arbitrary wavevector in the shear interface
plane. Two-dimensional PIC simulations of single-mode MIs reach a good
agreement with our analytical predictions. In simulations with finite
temperatures, we observe the competition and cooperation between MIs and a
diffusion-induced DC magnetic field.

</details>


### [33] [Physics-Informed Visual MARFE Prediction on the HL-3 Tokamak](https://arxiv.org/abs/2510.24347)
*Qianyun Dong,Rongpeng Li,Zongyu Yang,Fan Xia,Liang Liu,Zhifeng Zhao,Wulyu Zhong*

Main category: physics.plasm-ph

TL;DR: A novel physics-informed indicator for early MARFE prediction using Neural ODEs with physics-constrained modeling, achieving high accuracy for disruption warning in tokamaks.


<details>
  <summary>Details</summary>
Motivation: MARFE instability precedes density-limit disruptions in tokamaks, posing risks to machine integrity and operational efficiency, especially for next-generation devices like ITER.

Method: Integrates two innovations: (1) physics-scored weighted EM algorithm for label refinement from visual data, and (2) continuous-time physics-constrained Neural ODE model that predicts MARFE worsening conditioned on plasma parameters like normalized density and core electron temperature.

Result: Achieved high predictive accuracy with AUC of 0.969 for 40ms-ahead prediction on HL-3 experimental data, successfully deployed for real-time operation with 1ms updates.

Conclusion: This work lays foundation for future proactive MARFE mitigation strategies in tokamak operations.

Abstract: The Multifaceted Asymmetric Radiation From the Edge (MARFE) is a critical
plasma instability that often precedes density-limit disruptions in tokamaks,
posing a significant risk to machine integrity and operational efficiency.
Early and reliable alert of MARFE formation is therefore essential for
developing effective disruption mitigation strategies, particularly for
next-generation devices like ITER. This paper presents a novel,
physics-informed indicator for early MARFE prediction and disruption warning
developed for the HL-3 tokamak. Our framework integrates two core innovations:
(1) a high-fidelity label refinement pipeline that employs a physics-scored,
weighted Expectation-Maximization (EM) algorithm to systematically correct
noise and artifacts in raw visual data from cameras, and (2) a continuous-time,
physics-constrained Neural Ordinary Differential Equation (Neural ODE) model
that predicts the short-horizon ``worsening" of a MARFE. By conditioning the
model's dynamics on key plasma parameters such as normalized density ($f_G$,
derived from core electron density) and core electron temperature ($T_e$), the
predictor achieves superior performance in the low-false-alarm regime crucial
for control. On a large experimental dataset from HL-3, our model demonstrates
high predictive accuracy, achieving an Area Under the Curve (AUC) of 0.969 for
40ms-ahead prediction. The indicator has been successfully deployed for
real-time operation with updates every 1 ms. This work lays a very foundation
for future proactive MARFE mitigation.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [34] [Exploiting biased noise in variational quantum models](https://arxiv.org/abs/2510.24050)
*Connor van Rossum,Sally Shrapnel,Riddhi Gupta*

Main category: quant-ph

TL;DR: Twirling noise in variational quantum algorithms degrades performance, while preserving biased or non-unital noise can help classical optimizers find better solutions by introducing exploitable directional bias.


<details>
  <summary>Details</summary>
Motivation: To understand how quantum noise affects classical optimization in variational quantum algorithms, challenging conventional error-mitigation strategies that symmetrize noise.

Method: Analytical study of universal quantum regression model showing uniform Pauli channels suppress gradients, numerical experiments on variational eigensolver for transverse-field Ising model, and demonstration that coherent errors are mitigated by re-parameterization.

Result: Non-unital noise yields lower-energy states compared to twirled noise, asymmetric noise introduces directional bias that can be exploited during optimization, and coherent errors are fully mitigated by re-parameterization.

Conclusion: Conventional noise-mitigation strategies may be counterproductive for variational quantum algorithms, and preserving noise biases may actually enhance performance.

Abstract: Variational quantum algorithms (VQAs) are promising tools for demonstrating
quantum utility on near-term quantum hardware, with applications in
optimisation, quantum simulation, and machine learning. While researchers have
studied how easy VQAs are to train, the effect of quantum noise on the
classical optimisation process is still not well understood. Contrary to
expectations, we find that twirling, which is commonly used in standard
error-mitigation strategies to symmetrise noise, actually degrades performance
in the variational setting, whereas preserving biased or non-unital noise can
help classical optimisers find better solutions. Analytically, we study a
universal quantum regression model and demonstrate that relatively uniform
Pauli channels suppress gradient magnitudes and reduce expressivity, making
optimisation more difficult. Conversely, asymmetric noise such as amplitude
damping or biased Pauli channels introduces directional bias that can be
exploited during optimisation. Numerical experiments on a variational
eigensolver for the transverse-field Ising model confirm that non-unital noise
yields lower-energy states compared to twirled noise. Finally, we show that
coherent errors are fully mitigated by re-parameterisation. These findings
challenge conventional noise-mitigation strategies and suggest that preserving
noise biases may enhance VQA performance.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [35] [Resonant vector bundles, conjugate points, and the stability of pulse solutions to the {S}wift-{H}ohenberg equation using validated numerics: Part I](https://arxiv.org/abs/2510.24417)
*Margaret Beck,Jonathan Jaquette,Hannah Pieper*

Main category: math.DS

TL;DR: Develops theory for resonant vector bundles to enable rigorous stability analysis of pulse solutions in the Swift-Hohenberg equation using validated numerics.


<details>
  <summary>Details</summary>
Motivation: To extend the framework of conjugate points and validated numerics for stability analysis to cases where vector bundles have resonances that prevent standard computer-assisted proof techniques.

Method: New theoretical development for resonant vector bundles that overcomes obstacles in using conjugate points to detect unstable eigenvalues, with analysis divided into two parts.

Result: Provides a method to handle resonances in vector bundles that previously prevented the application of validated numerics for stability proofs.

Conclusion: The work establishes a theoretical foundation for rigorous stability analysis in resonant cases, with Part I presented here and Part II to follow.

Abstract: In this paper, we develop new theory connected with resonant vector bundles
that will allow for the use of validated numerics to rigorously determine the
stability of pulse solutions in the context of the Swift-Hohenberg equation.
For many PDEs, the stability of stationary solutions is determined by the
absence of point spectra in the open right half of the complex plane. Recently,
theoretical developments have allowed one to use objects called conjugate
points to detect such unstable eigenvalues for certain linearized operators.
Moreover, in certain cases these conjugate points can themselves be detected
using validated numerics. The aim of this work is to extend this framework to
contexts where the vector bundles, which control the existence of conjugate
points, have certain resonances. Such resonances can prevent the use of
standard (though involved) techniques in computer assisted proofs, and in this
paper we provide a method to overcome this obstacle. Due to its length, the
analysis has been divided into two parts: Part I in the present work, and Part
II in [BJPS25].

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [36] [Tensor network methods for quantum-inspired image processing and classical optics](https://arxiv.org/abs/2510.23089)
*Nicolas Allegra*

Main category: physics.optics

TL;DR: Tensor network methods bridge quantum computing and classical computing, offering faster algorithms for image processing and classical optics by leveraging quantum-inspired techniques.


<details>
  <summary>Details</summary>
Motivation: To apply tensor network methods to fundamental problems in image processing and classical optics, exploiting parallels with quantum mechanics for computational speedup.

Method: Using tensor network methods that draw inspiration from quantum systems to compress data and perform efficient operations, applied to wave-front propagation and optical image formation.

Result: Development of quantum-inspired methods that provide faster algorithms for optical imaging applications.

Conclusion: Tensor network methods show promise for accelerating classical optical computations across various fields including astronomy, microscopy, and earth observation.

Abstract: Tensor network methods strike a middle ground between fully-fledged quantum
computing and classical computing, as they take inspiration from quantum
systems to significantly speed up certain classical operations. Their strength
lies in their compressive power and the wide variety of efficient algorithms
that operate within this compressed space. In this work, we focus on applying
these methods to fundamental problems in image processing and classical optics
such as wave-front propagation and optical image formation, by using directly
or indirectly parallels with quantum mechanics and computation. These
quantum-inspired methods are expected to yield faster algorithms with
applications ranging from astronomy and earth observation to microscopy and
classical imaging more broadly.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [37] [TriDS: AI-native molecular docking framework unified with binding site identification, conformational sampling and scoring](https://arxiv.org/abs/2510.24186)
*Xuhan Liu,Baohua Zhang,Hong Zhang,Yi Qin Gao*

Main category: physics.chem-ph

TL;DR: TriDS is a novel molecular docking method that unifies sampling and scoring using ML-based differentiable scoring models, improving accuracy especially for large ligands while being computationally efficient.


<details>
  <summary>Details</summary>
Motivation: Current docking programs use cumbersome docking-then-rescoring workflows and lack unified frameworks for binding site identification, conformational sampling, and scoring in a user-friendly manner.

Method: TriDS expands the gradient-guided conformational sampling strategy from previous DSDP versions to ML-based differentiable scoring models, integrating binding site prediction and supporting multiple input formats.

Result: TriDS achieves excellent docking accuracy in benchmark datasets, particularly for large ligands, with enhanced computational efficiency in both running speed and GPU memory usage.

Conclusion: TriDS successfully demonstrates that gradients from suitable ML-based scoring functions can lead to accurate molecular docking while providing a unified, user-friendly framework.

Abstract: Molecular docking is a cornerstone of drug discovery to unveil the mechanism
of ligand-receptor interactions. With the recent development of deep learning
in the field of artificial intelligence, innovative methods were developed for
molecular docking. However, the mainstream docking programs adopt a
docking-then-rescoring streamline to increase the docking accuracy, which make
the virtual screening process cumbersome. Moreover, there still lacks a unified
framework to integrate binding site identification, conformational sampling and
scoring, in a user-friendly manner. In our previous work of DSDP and its
subsequent flexible version, we have demonstrated the effectiveness of guiding
conformational sampling with the gradient of analytic scoring function. As the
third generation of DSDP, here we expanded the similar strategy to ML-based
differentiable scoring model to device a novel docking method named TriDS under
the mainstream AI training framework, which unifies the sampling and scoring
steps. To be user-friendly, TriDS also integrates ML-based model for binding
site prediction and has compatibility with multiple input file formats. We show
here that gradients of a suitable ML-based scoring function can lead to
excellent docking accuracy in the benchmark datasets, especially for large
ligands. Moreover, TriDS is implemented with enhanced computational efficiency
in terms of both running speed and GPU memory requirement.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [38] [Variable Projected Augmented Lagrangian Methods for Generalized Lasso Problems](https://arxiv.org/abs/2510.24140)
*Stefano Aleotti,Davide Bianchi,Florian Bossmann,Riley Yizhou Chen,Matthias Chung*

Main category: math.OC

TL;DR: VPAL methods solve generalized nonlinear Lasso problems faster and more accurately by eliminating nonsmooth variables via soft-thresholding, transforming the problem into a smooth reduced formulation.


<details>
  <summary>Details</summary>
Motivation: To address the need for improved speed and accuracy in solving generalized nonlinear Lasso problems and large-scale inverse problems, overcoming limitations of traditional approaches.

Method: Variable projected augmented Lagrangian (VPAL) eliminates nonsmooth variables through soft-thresholding, creating a smooth reduced formulation. For linear models, a preconditioned variant mimics Newton-type updates. The method extends to nonlinear inverse problems.

Result: VPAL achieves significant acceleration, sharper convergence, and higher solution quality. It outperforms traditional approaches in applications like phase retrieval and contrast enhanced MRI, delivering state-of-the-art reconstructions in deblurring, inpainting, and sparse-view tomography.

Conclusion: Variable projection is a powerful tool for modern large-scale inverse problems, with VPAL consistently providing superior performance across various tasks.

Abstract: We introduce variable projected augmented Lagrangian (VPAL) methods for
solving generalized nonlinear Lasso problems with improved speed and accuracy.
By eliminating the nonsmooth variable via soft-thresholding, VPAL transforms
the problem into a smooth reduced formulation. For linear models, we develop a
preconditioned variant that mimics Newton-type updates and yields significant
acceleration. We prove convergence guarantees for both standard and
preconditioned VPAL under mild assumptions and show that variable projection
leads to sharper convergence and higher solution quality. The method seamlessly
extends to nonlinear inverse problems, where it outperforms traditional
approaches in applications such as phase retrieval and contrast enhanced MRI
(LIP-CAR). Across tasks including deblurring, inpainting, and sparse-view
tomography, VPAL consistently delivers state-of-the-art reconstructions,
positioning variable projection as a powerful tool for modern large-scale
inverse problems.

</details>


### [39] [A Two-step Krasnosel'skii-Mann Algorithm with Adaptive Momentum and Its Applications to Image Denoising and Matrix Completion](https://arxiv.org/abs/2510.24544)
*Yongxin He,Jingyuan Li,Yizun Lin,Deren Han*

Main category: math.OC

TL;DR: Proposes a Two-step Krasnosel'skii-Mann Algorithm with adaptive momentum for solving convex optimization problems in image processing, achieving faster convergence than existing methods.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient algorithm for convex optimization problems in image processing that can be reformulated as fixed-point problems, aiming to improve convergence speed over existing methods like FPPA, PGA, and Halpern algorithm.

Method: Develops a KM iteration with adaptive momentum based on geometric properties of averaged nonexpansive operators, then constructs TKMA as a convex combination of this adaptive-momentum KM iteration and the Picard iteration of T^2.

Result: TKMA converges to a fixed point of T and achieves o(1/k^{1/2}) convergence rate under specific assumptions. Numerical experiments show it outperforms FPPA, PGA, Fast KM, and Halpern algorithms on image denoising and low-rank matrix completion tasks.

Conclusion: The proposed TKMA with adaptive momentum provides an effective and efficient approach for solving convex optimization problems in image processing, demonstrating superior performance compared to existing state-of-the-art methods.

Abstract: In this paper, we propose a Two-step Krasnosel'skii-Mann (KM) Algorithm
(TKMA) with adaptive momentum for solving convex optimization problems arising
in image processing. Such optimization problems can often be reformulated as
fixed-point problems for certain operators, which are then solved using
iterative methods based on the same operator, including the KM iteration, to
ultimately obtain the solution to the original optimization problem. Prior to
developing TKMA, we first introduce a KM iteration enhanced with adaptive
momentum, derived from geometric properties of an averaged nonexpansive
operator T, KM acceleration technique, and information from the composite
operator T^2. The proposed TKMA is constructed as a convex combination of this
adaptive-momentum KM iteration and the Picard iteration of T^2. We establish
the convergence of the sequence generated by TKMA to a fixed point of T.
Moreover, under specific assumptions on the adaptive momentum parameters, we
prove that the algorithm achieves an o(1/k^{1/2}) convergence rate in terms of
the distance between successive iterates. Numerical experiments demonstrate
that TKMA outperforms the FPPA, PGA, Fast KM algorithm, and Halpern algorithm
on tasks such as image denoising and low-rank matrix completion.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [40] [Variational Calculations of the Excited States of the Charged NV-center in Diamond Using a Hybrid Functional](https://arxiv.org/abs/2510.24144)
*Lei Sun,Elvar Örn Jónsson,Aleksei Ivanov,Ji Chen,Hannes Jónsson*

Main category: cond-mat.mtrl-sci

TL;DR: The paper calculates excited electronic states of NV-defect in diamond using HSE06 hybrid density functional, improving accuracy over previous methods and showing good agreement with experimental data.


<details>
  <summary>Details</summary>
Motivation: To accurately calculate the excited electronic states involved in optical cycle preparation of NV-defect spin states in diamond, improving upon previous methods that underestimated band gaps.

Method: Used HSE06 hybrid density functional with variational optimization of orbitals, calculated vertical excitation and structural relaxation effects using analytical atomic forces, including spin purified atomic forces for singlet states.

Result: Triplet excited state energy and zero-phonon line triplet excitation energy within 0.1 eV of experimental estimates, singlet state relaxation estimated at 0.06 eV, significantly improving on previous local and semi-local functional results.

Conclusion: Time-independent variational calculations using hybrid density functionals provide accurate excited state results, offering a powerful screening tool for identifying quantum technology candidate defect systems.

Abstract: The excited electronic states involved in the optical cycle preparation of a
pure spin state of the negatively charged NV-defect in diamond are calculated
using the HSE06 hybrid density functional and variational optimization of the
orbitals. This includes the energy of the excited triplet as well as the two
lowest singlet states with respect to the ground triplet state. In addition to
the vertical excitation, the effect of structural relaxation is also estimated
using analytical atomic forces. The lowering of the energy in the triplet
excited state and the resulting zero-phonon line triplet excitation energy are
both within 0.1 eV of the experimental estimates. An analogous relaxation in
the lower energy singlet state using spin purified atomic forces is estimated
to be 0.06 eV. These results, obtained with a hybrid density functional,
improve on previously published results using local and semi-local functionals,
which are known to underestimate the band gap. The good agreement with
experimental estimates demonstrates how time-independent variational
calculations of excited states using density functionals can give accurate
results and, thereby, provide a powerful screening tool for identifying other
defect systems as candidates for quantum technologies.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [41] [Formalizing Schwartz functions and tempered distributions](https://arxiv.org/abs/2510.24060)
*Moritz Doll*

Main category: cs.LO

TL;DR: First formalization of tempered distributions in Lean proof assistant, with applications to Fourier transform and Sobolev spaces.


<details>
  <summary>Details</summary>
Motivation: To formalize distribution theory - a fundamental aspect of PDE theory - in an interactive proof assistant for the first time, addressing gaps in formal mathematics.

Method: Used Lean proof assistant to formalize tempered distributions theory, adapting classical mathematical presentations to formal verification requirements.

Result: Successfully formalized tempered distributions theory and proved Fourier transform extends to linear isometry on L² space, enabling definition of Sobolev spaces via Fourier transform.

Conclusion: This work establishes foundational infrastructure for formal PDE analysis and demonstrates practical applications in functional analysis and Fourier theory.

Abstract: Distribution theory is a cornerstone of the theory of partial differential
equations. We report on the progress of formalizing the theory of tempered
distributions in the interactive proof assistant Lean, which is the first
formalization in any proof assistant. We give an overview of the mathematical
theory and highlight key aspects of the formalization that differ from the
classical presentation. As an application, we prove that the Fourier transform
extends to a linear isometry on $L^2$ and we define Sobolev spaces via the
Fourier transform on tempered distributions.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [42] [Hydrodynamic Simulations of Tidal Disruption Encores](https://arxiv.org/abs/2510.23729)
*Ian P. A. Johnson,Taeho Ryu,Rosalba Perna*

Main category: astro-ph.HE

TL;DR: Simulations of Tidal Disruption Encores (TDEEs) in nuclear star clusters show delayed secondary flares when stellar-mass black holes disrupt stars, producing debris that falls back to the central massive black hole.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics and observable signatures of tidal disruption events in nuclear star clusters, particularly secondary flares that can probe black hole populations and cluster dynamics.

Method: Hydrodynamic simulations using the moving-mesh code AREPO to model TDEEs, varying disruption geometry, MBH mass, and sBH-MBH separation.

Result: Identified two distinct morphological outcomes: ring encores (debris circularizes into torus) and direct encores (streams plunge toward MBH), with luminosities of 10^40-10^42 erg/s and characteristic lightcurves.

Conclusion: The study improves TDEE lightcurve predictions, enabling observations to probe nuclear star cluster dynamics and stellar-mass black hole populations, while explaining anomalous TDE-like flares.

Abstract: We present hydrodynamic simulations with the moving-mesh code AREPO of Tidal
Disruption Encores (TDEEs) in nuclear star clusters (NSCs). TDEEs arise when a
stellar-mass black hole (sBH) disrupts a star within the NSC, producing debris
that is unbound from the sBH but remains gravitationally bound to the central
massive black hole (MBH), leading to a delayed secondary flare. We find that
the morphology and thermodynamics of the fallback material depend sensitively
on the disruption geometry, MBH mass, and sBH-MBH separation. We identify two
distinct morphological outcomes: ring encores, where debris circularize into a
torus, and direct encores, where streams plunge toward the MBH, with encore
luminosities peaking at times corresponding to the freefall timescale and one
orbital period, respectively. Across all simulated cases, we find these events
exhibit luminosities of $10^{40}-10^{42}$ erg/s with lightcurves characteristic
of their morphology. Our work greatly improves the predictions of TDEE
lightcurves and empowers observations to probe into NSC dynamics and sBH
population while providing possible explanations for anomalous TDE-like flares.

</details>


<div id='cond-mat.quant-gas'></div>

# cond-mat.quant-gas [[Back]](#toc)

### [43] [An efficient preconditioned conjugate-gradient solver for a two-component dipolar Bose-Einstein condensate](https://arxiv.org/abs/2510.24543)
*Weijing Bao,Zhenhao Wang,Jia-Rui Luo,Kui-Tian Xi*

Main category: cond-mat.quant-gas

TL;DR: A preconditioned nonlinear conjugate-gradient solver for ground states of binary dipolar Bose-Einstein condensates that significantly outperforms imaginary-time evolution in efficiency and convergence.


<details>
  <summary>Details</summary>
Motivation: To develop a more efficient and reliable computational method for finding ground states of binary dipolar Bose-Einstein condensates, particularly for large-scale parameter scans and phase-boundary mapping.

Method: Preconditioned nonlinear conjugate-gradient optimization on product-of-spheres normalization manifold with analytic line search, combining Fourier-space kinetic and real-space diagonal preconditioners while maintaining spectral accuracy and FFT-based dipolar term evaluation.

Result: Reduces iteration counts by 1-2 orders of magnitude compared to imaginary-time evolution, achieves lower energies with improved resilience to metastability, and successfully reproduces known droplet and stripe textures and stability windows.

Conclusion: The method provides a reliable and efficient computational tool for studying dipolar mixtures, enabling large-scale parameter scans and quantitative linking of numerical results to experimentally accessible states.

Abstract: We develop a preconditioned nonlinear conjugate-gradient solver for ground
states of binary dipolar Bose-Einstein condensates within the extended
Gross-Pitaevskii equation including Lee-Huang-Yang corrections. The
optimization is carried out on the product-of-spheres normalization manifold
and combines a manifold-preserving analytic line search, derived from a
second-order energy expansion and validated along the exact normalized path,
with complementary Fourier-space kinetic and real-space diagonal
(Hessian-inspired) preconditioners. The method enforces monotonic energy
descent and exhibits robust convergence across droplet, stripe, and supersolid
regimes while retaining spectrally accurate discretizations and FFT-based
evaluation of the dipolar term. In head-to-head benchmarks against
imaginary-time evolution on matched grids and tolerances, the solver reduces
iteration counts by one to two orders of magnitude and overall
time-to-solution, and it typically attains slightly lower energies, indicating
improved resilience to metastability. We reproduce representative textures and
droplet-stability windows reported for dipolar mixtures. These results
establish a reliable and efficient tool for large-scale parameter scans and
phase-boundary mapping, and for quantitatively linking numerically obtained
metastable branches to experimentally accessible states.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [44] [A comparison between joint and dual UKF implementations for state estimation and leak localization in water distribution networks](https://arxiv.org/abs/2510.24228)
*Luis Romero-Ben,Paul Irofti,Florin Stoican,Vicenç Puig*

Main category: eess.SY

TL;DR: Comparison of two Unscented Kalman Filter methods for water distribution network state estimation: joint state vector vs dual-estimator approaches.


<details>
  <summary>Details</summary>
Motivation: Efficient water distribution management requires accurate hydraulic state information for pressure control and leak detection in modern cities.

Method: Two data-driven UKF methods fusing pressure, demand and flow data: one using joint state vector with single estimator, the other using dual-estimator scheme.

Result: Theoretical comparison of accuracy and complexity, with implementation results shown for L-TOWN benchmark to discuss practical properties.

Conclusion: Analysis reveals differences, advantages and limitations of both approaches for hydraulic state estimation in water networks.

Abstract: The sustainability of modern cities highly depends on efficient water
distribution management, including effective pressure control and leak
detection and localization. Accurate information about the network hydraulic
state is therefore essential. This article presents a comparison between two
data-driven state estimation methods based on the Unscented Kalman Filter
(UKF), fusing pressure, demand and flow data for head and flow estimation. One
approach uses a joint state vector with a single estimator, while the other
uses a dual-estimator scheme. We analyse their main characteristics, discussing
differences, advantages and limitations, and compare them theoretically in
terms of accuracy and complexity. Finally, we show several estimation results
for the L-TOWN benchmark, allowing to discuss their properties in a real
implementation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [45] [A Physics-informed Multi-resolution Neural Operator](https://arxiv.org/abs/2510.23810)
*Sumanta Roy,Bahador Bahmani,Ioannis G. Kevrekidis,Michael D. Shields*

Main category: cs.LG

TL;DR: A physics-informed operator learning approach that extends RINO framework to work without training data, handling unevenly discretized multi-resolution inputs by projecting them to latent space and using MLP with PDE enforcement.


<details>
  <summary>Details</summary>
Motivation: Operator learning frameworks require substantial high-fidelity training data which is challenging to obtain, and real-world data often has uneven discretization with varying grid resolutions across samples.

Method: Extends RINO framework to data-free setup by projecting arbitrarily discretized inputs to latent embedding space using pre-trained basis functions, then approximates PDE operator with MLP that takes latent code and coordinates to produce solutions, enforced via finite difference solver.

Result: Validated on numerical examples with multi-resolution data where input functions are sampled at varying resolutions including both coarse and fine discretizations.

Conclusion: The proposed method successfully addresses both data scarcity and uneven discretization challenges in operator learning for PDE applications.

Abstract: The predictive accuracy of operator learning frameworks depends on the
quality and quantity of available training data (input-output function pairs),
often requiring substantial amounts of high-fidelity data, which can be
challenging to obtain in some real-world engineering applications. These
datasets may be unevenly discretized from one realization to another, with the
grid resolution varying across samples. In this study, we introduce a
physics-informed operator learning approach by extending the Resolution
Independent Neural Operator (RINO) framework to a fully data-free setup,
addressing both challenges simultaneously. Here, the arbitrarily (but
sufficiently finely) discretized input functions are projected onto a latent
embedding space (i.e., a vector space of finite dimensions), using pre-trained
basis functions. The operator associated with the underlying partial
differential equations (PDEs) is then approximated by a simple multi-layer
perceptron (MLP), which takes as input a latent code along with spatiotemporal
coordinates to produce the solution in the physical space. The PDEs are
enforced via a finite difference solver in the physical space. The validation
and performance of the proposed method are benchmarked on several numerical
examples with multi-resolution data, where input functions are sampled at
varying resolutions, including both coarse and fine discretizations.

</details>


### [46] [STNet: Spectral Transformation Network for Solving Operator Eigenvalue Problem](https://arxiv.org/abs/2510.23986)
*Hong Wang,Jiang Yixuan,Jie Wang,Xinyi Li,Jian Luo,Huanshuo Dong*

Main category: cs.LG

TL;DR: STNet uses spectral transformations to improve deep learning methods for operator eigenvalue problems by applying deflation projection and filter transforms to enhance convergence and accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing deep learning methods for operator eigenvalue problems suffer from performance dependency on spectral gaps and struggle with high-dimensional problems due to the curse of dimensionality.

Method: STNet performs spectral transformations using approximate eigenvalues and eigenfunctions: deflation projection excludes solved eigenfunction subspaces, and filter transform amplifies eigenvalues in target regions while suppressing others.

Result: Extensive experiments show STNet consistently outperforms existing learning-based methods and achieves state-of-the-art accuracy in solving operator eigenvalue problems.

Conclusion: Spectral transformations effectively enhance deep learning methods for operator eigenvalue problems, with STNet demonstrating superior performance through deflation projection and filter transforms.

Abstract: Operator eigenvalue problems play a critical role in various scientific
fields and engineering applications, yet numerical methods are hindered by the
curse of dimensionality. Recent deep learning methods provide an efficient
approach to address this challenge by iteratively updating neural networks.
These methods' performance relies heavily on the spectral distribution of the
given operator: larger gaps between the operator's eigenvalues will improve
precision, thus tailored spectral transformations that leverage the spectral
distribution can enhance their performance. Based on this observation, we
propose the Spectral Transformation Network (STNet). During each iteration,
STNet uses approximate eigenvalues and eigenfunctions to perform spectral
transformations on the original operator, turning it into an equivalent but
easier problem. Specifically, we employ deflation projection to exclude the
subspace corresponding to already solved eigenfunctions, thereby reducing the
search space and avoiding converging to existing eigenfunctions. Additionally,
our filter transform magnifies eigenvalues in the desired region and suppresses
those outside, further improving performance. Extensive experiments demonstrate
that STNet consistently outperforms existing learning-based methods, achieving
state-of-the-art performance in accuracy.

</details>


### [47] [EddyFormer: Accelerated Neural Simulations of Three-Dimensional Turbulence at Scale](https://arxiv.org/abs/2510.24173)
*Yiheng Du,Aditi S. Krishnapriyan*

Main category: cs.LG

TL;DR: EddyFormer is a Transformer-based architecture for large-scale turbulence simulation that combines spectral methods with attention mechanisms, achieving DNS-level accuracy with 30x speedup and strong domain generalization.


<details>
  <summary>Details</summary>
Motivation: Direct numerical simulation (DNS) of turbulence is computationally prohibitive due to multi-scale interactions, motivating the need for data-driven machine learning alternatives that can accurately simulate large-scale turbulence.

Method: Proposed EddyFormer - a Transformer-based spectral-element architecture with SEM tokenization that decomposes flow into grid-scale and subgrid-scale components to capture both local and global features.

Result: Achieves DNS-level accuracy at 256^3 resolution with 30x speedup over DNS. Shows strong domain generalization on unseen domains up to 4x larger than training, preserving accuracy on physics-invariant metrics. Outperforms prior ML models on The Well benchmark suite.

Conclusion: EddyFormer provides an effective data-driven alternative to DNS for turbulence simulation, combining spectral method accuracy with Transformer scalability while demonstrating robust generalization capabilities across diverse turbulent flows.

Abstract: Computationally resolving turbulence remains a central challenge in fluid
dynamics due to its multi-scale interactions. Fully resolving large-scale
turbulence through direct numerical simulation (DNS) is computationally
prohibitive, motivating data-driven machine learning alternatives. In this
work, we propose EddyFormer, a Transformer-based spectral-element (SEM)
architecture for large-scale turbulence simulation that combines the accuracy
of spectral methods with the scalability of the attention mechanism. We
introduce an SEM tokenization that decomposes the flow into grid-scale and
subgrid-scale components, enabling capture of both local and global features.
We create a new three-dimensional isotropic turbulence dataset and train
EddyFormer to achieves DNS-level accuracy at 256^3 resolution, providing a 30x
speedup over DNS. When applied to unseen domains up to 4x larger than in
training, EddyFormer preserves accuracy on physics-invariant metrics-energy
spectra, correlation functions, and structure functions-showing domain
generalization. On The Well benchmark suite of diverse turbulent flows,
EddyFormer resolves cases where prior ML models fail to converge, accurately
reproducing complex dynamics across a wide range of physical conditions.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [48] [Fast algorithms enabling optimization and deep learning for photoacoustic tomography in a circular detection geometry](https://arxiv.org/abs/2510.24687)
*Andreas Hauptmann,Leonid Kunyansky,Jenni Poimala*

Main category: eess.IV

TL;DR: New fast algorithms for forward and adjoint operators in photoacoustic tomography with O(n² log n) complexity, enabling efficient iterative reconstruction methods.


<details>
  <summary>Details</summary>
Motivation: Current iterative algorithms for inverse source problems in photoacoustic tomography require multiple applications of forward and adjoint operators, which are computationally expensive.

Method: Developed asymptotically fast algorithms for numerical evaluation of forward and adjoint operators in circular acquisition geometry using O(n² log n) floating point operations.

Result: Algorithms successfully implemented and tested with various iterative reconstruction techniques including variational methods and deep learning approaches.

Conclusion: The proposed fast algorithms enable efficient computation for iterative image reconstruction in photoacoustic tomography, with publicly available Python implementation.

Abstract: The inverse source problem arising in photoacoustic tomography and in several
other coupled-physics modalities is frequently solved by iterative algorithms.
Such algorithms are based on the minimization of a certain cost functional. In
addition, novel deep learning techniques are currently being investigated to
further improve such optimization approaches. All such methods require multiple
applications of the operator defining the forward problem, and of its adjoint.
In this paper, we present new asymptotically fast algorithms for numerical
evaluation of the forward and adjoint operators, applicable in the circular
acquisition geometry. For an $(n \times n)$ image, our algorithms compute these
operators in $\mathcal{O}(n^2 \log n)$ floating point operations. We
demonstrate the performance of our algorithms in numerical simulations, where
they are used as an integral part of several iterative image reconstruction
techniques: classic variational methods, such as non-negative least squares and
total variation regularized least squares, as well as deep learning methods,
such as learned primal dual. A Python implementation of our algorithms and
computational examples is available to the general public.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [49] [On the effect of randomization on supercritical heat equations](https://arxiv.org/abs/2510.24268)
*Eliseo Luongo*

Main category: math.PR

TL;DR: The paper investigates how different randomizations affect well-posedness of the focusing power nonlinearity heat equation, showing that additive noise doesn't improve solution theory and discussing randomization of initial conditions.


<details>
  <summary>Details</summary>
Motivation: Previous work showed non-unique local solutions for the heat equation with power nonlinearity in certain parameter ranges. This paper aims to understand if randomization (either through additive noise or initial conditions) can improve the well-posedness theory.

Method: Analyzes two types of randomizations: (1) adding a forcing term that is white in time and colored in space, and (2) randomizing the initial conditions. Proves non-uniqueness results for the additive noise case.

Result: Shows that adding additive noise (white in time, colored in space) is not sufficient to improve solution theory - proves non-uniqueness for local-in-time mild solutions with additive noise. Also discusses effects of randomizing initial conditions.

Conclusion: Randomization through additive noise does not resolve the non-uniqueness issues in the focusing power nonlinearity heat equation, suggesting more sophisticated approaches may be needed to improve well-posedness.

Abstract: Recently, in \cite{glogic2025non}, it has been shown that the focusing power
nonlinearity heat equation \begin{equation}\label{Eq:Heat_abstract}\tag{NLH}
  \partial_t u -\Delta u = |u|^{p-1}u, \quad p>1, \end{equation} in dimensions
$d \geq 3$ has non-unique local solutions in $L^q(\mathbb{R}^d)$ for $q <
d(p-1)/2$ provided that $p < p_{JL}$, where $p_{JL}$ denotes the
Joseph-Lundgren exponent. In this paper we investigate the effect of different
randomizations on the well-posedness of the equation. First we show that adding
a forcing term white in time and colored in space in \eqref{Eq:Heat_abstract}
is not sufficient to improve the solution theory: namely, we prove
non-uniqueness for local-in-time mild solutions of \eqref{Eq:Heat_abstract}
with additive noise. Second, we discuss how randomizing the initial conditions
of \eqref{Eq:Heat_abstract} affects its well-posedness.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [50] [Deep-Learning-Empowered Programmable Topolectrical Circuits](https://arxiv.org/abs/2510.24463)
*Hao Jia,Shanglin Yang,Jiajun He,Shuo Liu,Haoxiang Chen,Ce Shang,Shaojie Ma,Peng Han,Ching Hua Lee,Zhen Gao,Yun Lai,Tie Jun Cui*

Main category: cond-mat.dis-nn

TL;DR: A deep learning empowered programmable topolectrical circuits platform that enables flexible Hamiltonian control, inverse state design, and hardware verification for studying topological phenomena and implementing cryptographic applications.


<details>
  <summary>Details</summary>
Motivation: Existing topolectrical circuit approaches suffer from incomplete programmability and ineffective feature prediction/control, limiting their ability to bridge theoretical modeling with practical applications.

Method: Integrates fully independent continuous tuning of lattice Hamiltonian terms, physics graph informed inverse state design, immediate hardware verification, and generative AI models for physics exploration.

Result: Experimental observation of boundary states without global symmetry in higher order topological systems, adiabatic phase transitions, flat band characteristics, arbitrary position-controllable Anderson localization, and cryptographic information encryption.

Conclusion: The platform successfully bridges theoretical modeling with practical realization, enabling novel physical phenomena investigation and demonstrating compelling cryptographic applications through high-fidelity hardware implementation.

Abstract: Topolectrical circuits provide a versatile platform for exploring and
simulating modern physical models. However, existing approaches suffer from
incomplete programmability and ineffective feature prediction and control
mechanisms, hindering the investigation of physical phenomena on an integrated
platform and limiting their translation into practical applications. Here, we
present a deep learning empowered programmable topolectrical circuits (DLPTCs)
platform for physical modeling and analysis. By integrating fully independent,
continuous tuning of both on site and off site terms of the lattice
Hamiltonian, physics graph informed inverse state design, and immediate
hardware verification, our system bridges the gap between theoretical modeling
and practical realization. Through flexible control and adiabatic path
engineering, we experimentally observe the boundary states without global
symmetry in higher order topological systems, their adiabatic phase
transitions, and the flat band like characteristic corresponding to Landau
levels in the circuit. Incorporating a physics graph informed mechanism with a
generative AI model for physics exploration, we realize arbitrary, position
controllable on board Anderson localization, surpassing conventional random
localization. Utilizing this unique capability with high fidelity hardware
implementation, we further demonstrate a compelling cryptographic application:
hash based probabilistic information encryption by leveraging Anderson
localization with extensive disorder configurations, enabling secure delivery
of full ASCII messages.

</details>


<div id='physics.acc-ph'></div>

# physics.acc-ph [[Back]](#toc)

### [51] [Phase-Space Shaping in Wakefield Accelerators due to Betatron Cooling](https://arxiv.org/abs/2510.24567)
*Pablo J. Bilbao,Thales Silva,Luis O. Silva*

Main category: physics.acc-ph

TL;DR: Betatron radiation cooling in plasma accelerators causes phase space structuring of relativistic beams, creating bunched ring-like structures with population inversion, fundamentally altering beam dynamics and enabling coherent betatron emission.


<details>
  <summary>Details</summary>
Motivation: Plasma-based accelerators are producing relativistic beams with unprecedented charge and ultrashort durations that drive wakes in high-density plasmas, where betatron radiation becomes increasingly important and affects beam dynamics.

Method: Analytical derivation of characteristic timescales for betatron cooling process and verification through multi-dimensional Particle-in-Cell simulations.

Result: Betatron cooling leads to strong structuring of beam phase space, creating bunched ring-like structures with positive radial position and momentum gradients (population inversion of oscillation amplitude).

Conclusion: The radiation-dominated regime fundamentally alters acceleration processes and produces self-structured beams capable of triggering coherent betatron emission in ion channels.

Abstract: Plasma-based accelerators are beginning to employ relativistic beams with
unprecedented charge and ultrashort durations. These dense driver beams can
drive wakes even in high-density plasmas ($\gtrsim10^{19}$ cm$^{-3}$), where
betatron radiation becomes increasingly important and begins to affect the
dynamics of the accelerated beam. In this Letter, we show that betatron cooling
leads to a strong, structuring of the phase space of the beam. This gives rise
to bunched, ring-like structures with positive radial position and momentum
gradients, \emph{i.e.}, population inversion of the amplitude of oscillation.
We derive the characteristic timescales for this process analytically and
confirm our predictions with multi-dimensional Particle-in-Cell simulations.
The radiation-dominated regime of beam dynamics fundamentally alters the
acceleration process and produces self-structured beams capable of triggering
coherent betatron emission in ion channels.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [52] [Score-based constrained generative modeling via Langevin diffusions with boundary conditions](https://arxiv.org/abs/2510.23985)
*Adam Nordenhög,Akash Sharma*

Main category: stat.ML

TL;DR: The paper proposes constrained generative models using kinetic Langevin dynamics with specular reflection to handle constraints, and compares them with existing reflected SDE approaches.


<details>
  <summary>Details</summary>
Motivation: Score-based generative models based on SDEs often fail to satisfy underlying constraints, motivating the development of constrained generative models that can handle domain restrictions.

Method: Uses kinetic (underdamped) Langevin dynamics with specular reflection of velocity on constraint boundaries, resulting in piecewise continuously differentiable noising and denoising processes. Also contributes to existing reflected SDEs with abstract local time terms.

Result: Develops efficient numerical samplers that converge with optimal discretization rates, and provides comprehensive comparison between specularly reflected kinetic Langevin diffusion and reflected diffusion with local time approaches.

Conclusion: The constrained generative models with specular reflection provide effective ways to handle constraints in score-based generative modeling, with efficient numerical implementations available.

Abstract: Score-based generative models based on stochastic differential equations
(SDEs) achieve impressive performance in sampling from unknown distributions,
but often fail to satisfy underlying constraints. We propose a constrained
generative model using kinetic (underdamped) Langevin dynamics with specular
reflection of velocity on the boundary defining constraints. This results in
piecewise continuously differentiable noising and denoising process where the
latter is characterized by a time-reversed dynamics restricted to a domain with
boundary due to specular boundary condition. In addition, we also contribute to
existing reflected SDEs based constrained generative models, where the
stochastic dynamics is restricted through an abstract local time term. By
presenting efficient numerical samplers which converge with optimal rate in
terms of discretizations step, we provide a comprehensive comparison of models
based on confined (specularly reflected kinetic) Langevin diffusion with models
based on reflected diffusion with local time.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [53] [On finding gravitational waves from anisotropies of the Cosmic Microwave Background](https://arxiv.org/abs/2510.24005)
*Yiran Wang*

Main category: gr-qc

TL;DR: Primordial gravitational perturbations can be identified from local observations of the inverse Sachs-Wolfe effect.


<details>
  <summary>Details</summary>
Motivation: To study the inverse problem of how primordial gravitational perturbations can be identified from local observations of the integrated Sachs-Wolfe effect.

Method: Analyzing the inverse Sachs-Wolfe effect to identify primordial gravitational perturbations, particularly their polarizations in the transversally traceless (TT) gauge.

Result: Primordial gravitational perturbations can be identified from local observation of the ISW effect.

Conclusion: The ISW effect provides a means to identify primordial gravitational perturbations through local observations.

Abstract: The integrated Sachs-Wolfe (ISW) effect describes how photons are
gravitationally redshifted, producing anisotropies in the Cosmic Microwave
Background. We study the inverse problem and show that primordial gravitational
perturbations, in particular their polarizations in the transversally traceless
(TT) gauge can be identified from the local observation of the ISW effect.

</details>
