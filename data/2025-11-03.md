<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 20]
- [math.AP](#math.AP) [Total: 17]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 6]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 2]
- [physics.acc-ph](#physics.acc-ph) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [math.DG](#math.DG) [Total: 2]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 3]
- [physics.space-ph](#physics.space-ph) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Positivity-preserving Well-balanced PAMPA Schemes with Global Flux quadrature for One-dimensional Shallow Water Models](https://arxiv.org/abs/2510.26862)
*Remi Abgrall,Yongle Liu,Mario Ricchiuto*

Main category: math.NA

TL;DR: A novel PAMPA method for 1D hyperbolic balance laws that preserves hydrostatic and non-hydrostatic equilibria, with applications to shallow water models including Saint-Venant system with Manning friction and rotating shallow water equations.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical method that can preserve various smooth moving equilibria (supercritical and subcritical flows) while maintaining positivity of water depth and handling wet-dry fronts in shallow water simulations.

Method: Global flux quadrature formulation where source term discretization comes from derivative of additional flux function computed via high-order quadrature. Uses PAMPA schemes blended with first-order local Lax-Friedrichs schemes for positivity and shock handling.

Result: The method preserves still water states exactly, maintains positivity of water depth, eliminates spurious oscillations near shocks, and achieves super-convergent preservation of smooth moving equilibria.

Conclusion: The proposed PAMPA method is robust and advantageous for shallow water simulations, capable of handling various equilibrium states while maintaining numerical stability and accuracy.

Abstract: We present a novel hydrostatic and non-hydrostatic equilibria preserving
Point-Average-Moment PolynomiAl-interpreted (PAMPA) method for solving the
one-dimensional hyperbolic balance laws, with applications to the shallow water
models including the Saint--Venant system with the Manning friction term and
rotating shallow water equations. The idea is based on a global flux quadrature
formulation, in which the discretization of the source terms is obtained from
the derivative of and additional flux function computed via high order
quadrature of the source term. The reformulated system is quasi-conservative
with global integral terms computed using Gauss--Lobatto quadrature nodes. The
resulting method is capable of preserving a large family of smooth moving
equilibria: supercritical and subcritical flows, in a super-convergent manner.
We also show that, by an appropriate quadrature strategy for the source, we can
exactly preserve the still water states. Moreover, to guarantee the positivity
of water depth and eliminate the spurious oscillations near shocks, we blend
the high-order PAMPA schemes with the first order local Lax--Friedrichs schemes
using the method developed in [R. Abgrall, M. Jiao, Y. Liu, and K. Wu, arXiv
preprint arXiv:2410.14292, 2024]. The first-order schemes are designed to
preserve the still water equilibria and positivity of water height, as well as
to deal with wet-dry fronts. Extensive numerical experiments are tested to
validate the advantages and robustness of the proposed scheme.

</details>


### [2] [Towards modular Hierarchical Poincaré-Steklov solvers](https://arxiv.org/abs/2510.26945)
*Michal Outrata,José Pablo Lucero Lorca*

Main category: math.NA

TL;DR: The paper revisits the HPS method for Poisson equation using Q1 finite elements, clarifying how corner degrees of freedom are naturally handled in the merge procedure when corners are enclosed by elements.


<details>
  <summary>Details</summary>
Motivation: To bridge the conceptual gap between algebraic Schur-complement methods and operator-based formulations, and provide a consistent path for FEM community to adopt HPS while retaining Poincaré-Steklov interpretation.

Method: Revisits HPS method using standard Q1 finite elements, showing how corner coupling is naturally accommodated in the merge procedure when corners are enclosed by elements.

Result: The clarification shows that HPS merge procedure naturally handles corner degrees of freedom that cannot be factored out in Q1-FEM.

Conclusion: This work bridges gap between different formulations and provides FEM community with consistent path to adopt HPS while maintaining continuous and discrete Poincaré-Steklov interpretation.

Abstract: We revisit the Hierarchical Poincar\'{e}-Steklov (HPS) method for the Poisson
equation using standard Q1 finite elements, building on the original in work on
HPS of Martinsson from 2013. While corner degrees of freedom were implicitly
handled in that work, subsequent spectral-element implementations have
typically avoided them. In Q1-FEM, however, corner coupling cannot be factored
out, and we show how the HPS merge procedure naturally accommodates it when
corners are enclosed by elements. This clarification bridges a conceptual gap
between algebraic Schur-complement methods and operator-based formulations,
providing a consistent path for the FEM community to adopt HPS to retain the
Poincar\'{e}-Steklov interpretation at both continuous and discrete levels.

</details>


### [3] [Finite Element Representation Network (FERN) for Operator Learning with a Localized Trainable Basis](https://arxiv.org/abs/2510.26962)
*Zecheng Zhang,Hao Liu,Guosheng Fu,Hayden Schaeffer,Guang Lin*

Main category: math.NA

TL;DR: A finite-element local basis-based operator learning framework for solving PDEs that constructs adaptive FEM bases using shallow neural networks with ReLU activation, enabling natural mimicry of adaptive refinement while reducing trainable parameters.


<details>
  <summary>Details</summary>
Motivation: Existing operator learning approaches use deep global bases, but many PDE solutions exhibit local behaviors like shocks and sharp gradients that may appear in different domain regions across samples. Local bases in FEM provide inspiration for better handling these localized features.

Method: Develop shallow neural network architecture that constructs adaptive FEM bases using suitable activation functions (e.g., ReLU), allowing exact assembly of FEM bases within the network without additional approximation error. This mimics FEM adaptive refinement to discover basis functions tailored to solution features.

Result: The framework reduces number of trainable parameters while maintaining high approximation accuracy, effectively combining FEM adaptivity with operator learning expressive power. Validated on seven families of PDEs with diverse characteristics.

Conclusion: The proposed method demonstrates accuracy, efficiency, and robustness across various PDE families, successfully integrating FEM's local basis adaptivity with operator learning capabilities.

Abstract: We propose a finite-element local basis-based operator learning framework for
solving partial differential equations (PDEs). Operator learning aims to
approximate mappings from input functions to output functions, where the latter
are typically represented using basis functions. While non-learnable bases
reduce training costs, learnable bases offer greater flexibility but often
require deep network architectures with a large number of trainable parameters.
Existing approaches typically rely on deep global bases; however, many PDE
solutions exhibit local behaviors such as shocks, sharp gradients, etc., and in
parametrized PDE settings, these localized features may appear in different
regions of the domain across different training and testing samples. Motivated
by the use of local bases in finite element methods (FEM) for function
approximation, we develop a shallow neural network architecture that constructs
adaptive FEM bases. By adopting suitable activation functions, such as ReLU,
the FEM bases can be assembled exactly within the network, introducing no
additional approximation error in the basis construction process. This design
enables the learning procedure to naturally mimic the adaptive refinement
mechanism of FEM, allowing the network to discover basis functions tailored to
intrinsic solution features such as shocks. The proposed learnable adaptive
bases are then employed to represent the solution (output function) of the PDE.
This framework reduces the number of trainable parameters while maintaining
high approximation accuracy, effectively combining the adaptivity of FEM with
the expressive power of operator learning. To evaluate performance, we validate
the proposed method on seven families of PDEs with diverse characteristics,
demonstrating its accuracy, efficiency, and robustness.

</details>


### [4] [Domain decomposition architectures and Gauss-Newton training for physics-informed neural networks](https://arxiv.org/abs/2510.27018)
*Alexander Heinlein,Taniya Kapoor*

Main category: math.NA

TL;DR: Combining localized neural networks via domain decomposition with Gauss-Newton optimization improves training efficiency for solving PDE boundary value problems.


<details>
  <summary>Details</summary>
Motivation: Neural network-based PDE solvers suffer from slow training due to spectral bias (slow convergence of high-frequency components) and inefficient gradient-based optimization methods.

Method: Use overlapping domain decomposition to localize neural networks, combined with Gauss-Newton optimization instead of gradient-based methods like Adam, leveraging the block-sparse structure of the resulting linear systems.

Result: The approach reduces computational cost per iteration and achieves faster convergence compared to gradient-based optimization schemes.

Conclusion: Combining localization through domain decomposition with Gauss-Newton optimization is a promising approach for neural network-based PDE solvers.

Abstract: Approximating the solutions of boundary value problems governed by partial
differential equations with neural networks is challenging, largely due to the
difficult training process. This difficulty can be partly explained by the
spectral bias, that is, the slower convergence of high-frequency components,
and can be mitigated by localizing neural networks via (overlapping) domain
decomposition. We combine this localization with the Gauss-Newton method as the
optimizer to obtain faster convergence than gradient-based schemes such as
Adam; this comes at the cost of solving an ill-conditioned linear system in
each iteration. Domain decomposition induces a block-sparse structure in the
otherwise dense Gauss-Newton system, reducing the computational cost per
iteration. Our numerical results indicate that combining localization and
Gauss-Newton optimization is promising for neural network-based solvers for
partial differential equations.

</details>


### [5] [A Sweeping Positivity-Preserving High Order Finite Difference WENO Scheme for Euler Equations](https://arxiv.org/abs/2510.27025)
*D. Chloe Griffin,Chi-Wang Shu*

Main category: math.NA

TL;DR: A high-order conservative positivity-preserving sweeping procedure for compressible Euler equations that maintains accuracy while ensuring density and pressure remain positive.


<details>
  <summary>Details</summary>
Motivation: To develop a robust method that preserves positivity of density and pressure in compressible Euler equations while maintaining conservation properties and high-order accuracy.

Method: Extends the scalar sweeping technique using a scaling limiter to handle nonlinear pressure functions. Works as a post-processing technique applicable to any concave functions in hyperbolic conservation laws, compatible with various schemes including WENO methods.

Result: The procedure successfully preserves positivity and conservation without compromising accuracy. Numerical tests with fifth-order finite difference WENO schemes demonstrate the technique's accuracy and robustness.

Conclusion: The sweeping procedure provides an effective post-processing technique for maintaining positivity in hyperbolic conservation law systems, with applications extending beyond Euler equations to general concave functions of conserved variables.

Abstract: We develop a simple, high-order, conservative and robust
positivity-preserving sweeping procedure for the density and the nonlinear
pressure function in the compressible Euler equations. Using the scaling
limiter in Zhang and Shu (2010), we obtain a nontrivial extension of the scalar
sweeping technique in Liu, Cheng, and Shu (2016) for the positivity of
pressure. The sweeping procedure developed in this paper is a post-processing
technique, which can be applied to any concave functions of the conserved
variables in hyperbolic conservation law systems. Thus, it has applications
beyond the Euler equations. This procedure preserves positivity and
conservation of physical quantities without destroying the accuracy of the
underlying scheme. The algorithm works for general schemes including finite
difference, finite-volume and discontinuous Galerkin methods; however, in this
paper we focus on finite-difference weighted essentially non-oscillatory (WENO)
methods. We provide numerical tests of the fifth order finite difference WENO
scheme to demonstrate the accuracy and robustness of the technique.

</details>


### [6] [Unconditionally stable Gauge--Uzawa finite element schemes for the chemo-repulsion-Navier-Stokes system](https://arxiv.org/abs/2510.27026)
*Chenyang Li*

Main category: math.NA

TL;DR: A Gauge-Uzawa finite element method for 2D chemo-repulsion-Navier-Stokes system that combines canonical and Uzawa-type formulations while maintaining variational consistency.


<details>
  <summary>Details</summary>
Motivation: To develop a fully discrete projection framework that avoids needing initial pressure values and artificial pressure boundary conditions, reducing computational overhead.

Method: Proposed GU-FEM integrates advantages of canonical and Uzawa-type formulations, preserving variational consistency in a projection-based finite element approach.

Result: The scheme is unconditionally energy stable, with optimal error estimates derived for cell density, chemical concentration, and fluid velocity. Numerical experiments confirm accuracy, stability, and efficiency.

Conclusion: The consistent projection finite element method provides an effective computational framework for the CRNS system with reduced computational requirements and proven stability properties.

Abstract: This paper investigates a Gauge--Uzawa finite element method (GU-FEM) for the
two-dimensional chemo--repulsion--Navier--Stokes (CRNS) system. The proposed
approach establishes a fully discrete projection framework that integrates the
advantages of both the canonical and Uzawa--type formulations, while preserving
variational consistency. The proposed GU-FEM possesses two notable advantages:
(1) it requires no initial pressure value; (2) it avoids artificial pressure
boundary conditions, thereby reducing computational overhead. Furthermore, the
scheme is shown to be unconditionally energy stable, and optimal error
estimates are derived for the cell density, chemical concentration, and fluid
velocity. Finally, several numerical experiments are presented to demonstrate
the accuracy, stability, and efficiency of the proposed consistent projection
finite element method.

</details>


### [7] [Bayesian inference calibration of the modulus of elasticity](https://arxiv.org/abs/2510.27060)
*J. Dick,Q. T. Le Gia,K. Mustapha*

Main category: math.NA

TL;DR: Bayesian inference for estimating Young's modulus from stochastic linear elasticity using finite element methods and quasi-Monte Carlo integration.


<details>
  <summary>Details</summary>
Motivation: To develop a computational framework for inferring material properties (Young's modulus) from stochastic linear elasticity problems using Bayesian methods.

Method: Model Young's modulus with finite Karhunen-Loève expansion, approximate elasticity solution via finite element method, and use higher-order quasi-Monte Carlo for posterior integration.

Result: A computational methodology combining Bayesian inference, finite element discretization, and efficient high-dimensional integration techniques.

Conclusion: The proposed approach provides an effective framework for uncertainty quantification in material property inference from elasticity equations.

Abstract: This work uses the Bayesian inference technique to infer the Young modulus
from the stochastic linear elasticity equation. The Young modulus is modeled by
a finite Karhunen Lo\'{e}ve expansion, while the solution to the linear
elasticity equation is approximated by the finite element method. The
high-dimensional integral involving the posterior density and the quantity of
interest is approximated by a higher-order quasi-Monte Carlo method.

</details>


### [8] [A Quantitative Framework to Predict Wait-Time Impacts Due to AI-Triage Devices in a Multi-AI, Multi-Disease Workflow](https://arxiv.org/abs/2510.27104)
*Michelle Mastrianni,Rucha Deshpande,Frank W. Samuelson,Yee Lam Elim Thompson*

Main category: math.NA

TL;DR: Developed a mathematical framework (multi-QuCAD) to analyze wait-time trade-offs when multiple AI-triage devices operate simultaneously in radiology workflows, revealing that while AI reduces wait-times for target conditions, it can delay diagnosis of non-targeted urgent conditions.


<details>
  <summary>Details</summary>
Motivation: The rapid deployment of multiple AI-triage devices in radiology departments has grown, but the cumulative impact on patient wait-times across different disease conditions remains poorly understood.

Method: Created multi-QuCAD software tool using queueing theory principles to model complex multi-AI, multi-disease scenarios with clinical parameters including disease prevalence rates, radiologist reading times, and AI performance characteristics. Verified through four experimental scenarios comparing preemptive vs non-preemptive scheduling and priority vs hierarchical triage protocols.

Result: Analysis showed AI-triage devices significantly reduce wait-times for target conditions but can substantially delay diagnosis of non-targeted urgent conditions. Hierarchical protocol provides more wait-time savings for highest-priority conditions compared to priority protocol, but at the expense of more delays to lower-priority patients with time-sensitive conditions.

Conclusion: The quantitative framework provides essential insights for orchestrating multi-AI deployments to maximize overall patient time-saving benefits while minimizing unintended delays for other important patient populations.

Abstract: The deployment of multiple AI-triage devices in radiology departments has
grown rapidly, yet the cumulative impact on patient wait-times across different
disease conditions remains poorly understood. This research develops a
comprehensive mathematical and simulation framework to quantify wait-time
trade-offs when multiple AI-triage devices operate simultaneously in a clinical
workflow. We created multi-QuCAD, a software tool that models complex multi-AI,
multi-disease scenarios using queueing theory principles, incorporating
realistic clinical parameters including disease prevalence rates, radiologist
reading times, and AI performance characteristics from FDA-cleared devices. The
framework was verified through four experimental scenarios ranging from simple
two-disease workflows to complex nine-disease systems, comparing preemptive
versus non-preemptive scheduling disciplines and priority versus hierarchical
triage protocols. Analysis of brain imaging workflows demonstrated that while
AI-triage devices significantly reduce wait-times for target conditions, they
can substantially delay diagnosis of non-targeted, yet urgent conditions. The
study revealed that hierarchical protocol generally provides more wait-time
savings for the highest-priority conditions compared to the priority protocol,
though at the expense of more delays to lower-priority patients with other
time-sensitive conditions. The quantitative framework presented provides
essential insights for orchestrating multi-AI deployments to maximize overall
patient time-saving benefits while minimizing unintended delay for other
important patient populations.

</details>


### [9] [A monotone finite element method for an elliptic distributed optimal control problem with a convection-dominated state equation](https://arxiv.org/abs/2510.27167)
*SeongHee Jeong,Seulip Lee,Sijing Liu*

Main category: math.NA

TL;DR: A monotone finite element method for elliptic optimal control problems constrained by convection-diffusion-reaction equations, using EAFE scheme to preserve discrete maximum principle and prevent oscillations.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical method that maintains stability and avoids nonphysical oscillations in convection-dominated optimal control problems, preserving the monotonicity properties of the continuous problem.

Method: Edge-averaged finite element (EAFE) discretization scheme combined with discrete inf-sup condition analysis and consistency results to ensure well-posedness and optimal convergence.

Result: The method preserves discrete maximum principle, maintains desired-state bounds, prevents oscillations, and achieves optimal convergence order in convection-dominated regimes.

Conclusion: The proposed EAFE-based monotone finite element method is robust and effective for convection-dominated optimal control problems, with theoretical guarantees and numerical validation.

Abstract: We propose and analyze a monotone finite element method for an elliptic
distributed optimal control problem constrained by a
convection-diffusion-reaction equation in the convection-dominated regime. The
method is based on the edge-averaged finite element (EAFE) scheme, which is
known to preserve the discrete maximum principle for convection-diffusion
problems. We show that the EAFE discretization inherits the monotonicity
property of the continuous problem and consequently preserves the desired-state
bounds at the discrete level, ensuring that the numerical optimal state remains
stable and free of nonphysical oscillations. The discrete formulation is
analyzed using a combination of the EAFE consistency result and a discrete
inf-sup condition, which together guarantee well-posedness and yield the
optimal convergence order. Comprehensive numerical experiments are presented to
confirm the theoretical findings and to demonstrate the robustness of the
proposed scheme in the convection-dominated regimes.

</details>


### [10] [Error analysis with exponential decay estimates for a fully discrete approximation of a class of strongly damped wave equations](https://arxiv.org/abs/2510.27202)
*Krishan Kumar,P. Danumjaya,Anil Kumar,Amiya K. Pani*

Main category: math.NA

TL;DR: This paper analyzes strongly damped wave equations using FEM in space and finite differences in time, deriving exponential decay properties and optimal error estimates that preserve decay behavior across different damping parameter cases.


<details>
  <summary>Details</summary>
Motivation: To develop a comprehensive framework for analyzing the asymptotic behavior and numerical approximation of strongly damped wave equations, ensuring that discrete schemes preserve the exponential decay properties of the continuous problem.

Method: Uses semidiscrete finite element method in space combined with finite difference scheme in time, employing energy-based techniques and novel approaches from linear parabolic problems to derive decay properties and error estimates.

Result: Derived explicit exponential decay rates depending on model parameters and principal eigenvalue, obtained optimal error estimates preserving decay behavior, and developed complete discrete schemes that maintain exponential decay properties.

Conclusion: The proposed numerical methods successfully preserve the exponential decay behavior of strongly damped wave equations, with theoretical findings supported by numerical experiments showing uniform decay rates and parameter effects on stability and accuracy.

Abstract: This paper deals with the asymptotic behavior and FEM error analysis of a
class of strongly damped wave equations using a semidiscrete finite element
method in spatial directions combined with a finite difference scheme in the
time variable. For the continuous problem under weakly and strongly damping
parameters $\alpha$ and $\beta,$ respectively, a novel approach usually used
for linear parabolic problems is employed to derive an exponential decay
property with explicit rates, which depend on model parameters and the
principal eigenvalue of the associated linear elliptic operator for the
different cases of parameters such as $(i) \;\alpha, \beta >0$, $ (ii)\;
\alpha>0, \beta \geq 0$ and $(iii)\;\alpha \geq 0, \beta >0$. Subsequently, for
a semi-discrete finite element scheme keeping the temporal variable continuous,
optimal error estimates are derived that preserve exponential decay behavior.
Some generalizations that include forcing terms and spatially as well as
time-varying damping parameters are discussed. Moreover, an abstract discrete
problem is discussed, and as a consequence, uniform decay estimates for finite
difference as well as spectral approximations to the damped system are briefly
indicated. A complete discrete scheme is developed and analyzed after applying
a finite difference scheme in time, which again preserves the exponential decay
property. The given proofs involve several energies with energy-based
techniques to derive the consistency between continuous and discrete decay
rates, in which the constants involved do not blow up as $\alpha\to 0$ and
$\beta\to 0$. Finally, several numerical experiments are conducted whose
results support the theoretical findings, illustrate uniform decay rates, and
explore the effects of parameters on stability and accuracy.

</details>


### [11] [Surface parameterization via optimization of relative entropy and quasiconformality](https://arxiv.org/abs/2510.27203)
*Zhipeng Zhu,Lok Ming Lui*

Main category: math.NA

TL;DR: A novel method for parameterizing triangle meshes using optimal quasiconformal maps that balance measure preservation and conformal structure preservation through relative entropy and Beltrami coefficient optimization.


<details>
  <summary>Details</summary>
Motivation: To develop a parameterization method that can achieve a desired balance between preserving probability measures (relative entropy) and preserving conformal structure (quasiconformal distortion), allowing flexible control over the mapping properties.

Method: Optimizes an energy functional combining relative entropy and quasiconformal terms. Uses gradient flow structure: Fokker-Planck equation for relative entropy (solved with finite volume method) and linear Beltrami solver for quasiconformal maps with piecewise constant Beltrami coefficients.

Result: The method produces optimal quasiconformal maps that balance measure preservation and conformal structure preservation according to adjustable parameters, enabling flexible mesh parameterization.

Conclusion: The proposed approach provides a principled framework for mesh parameterization that allows controlled trade-offs between measure preservation and conformal structure preservation through adjustable optimization parameters.

Abstract: We propose a novel method for parameterizations of triangle meshes by finding
an optimal quasiconformal map that minimizes an energy consisting of a relative
entropy term and a quasiconformal term. By prescribing a prior probability
measure on a given surface and a reference probability measure on a parameter
domain, the relative entropy evaluates the difference between the pushforward
of the prior measure and the reference one. The Beltrami coefficient of a
quasiconformal map evaluates how far the map is close to an angular-preserving
map, i.e., a conformal map. By adjusting parameters of the optimization
problem, the optimal map achieves a desired balance between the preservation of
measure and the preservation of conformal structure. To optimize the energy
functional, we utilize the gradient flow structure of its components. The
gradient flow of the relative entropy is the Fokker-Planck equation, and we
apply a finite volume method to solve it. Besides, we discretize the Beltrami
coefficient as a piecewise constant function and apply the linear Beltrami
solver to find a piecewise linear quasiconformal map.

</details>


### [12] [A gradient flow model for the Gross--Pitaevskii problem: Mathematical and numerical analysis](https://arxiv.org/abs/2510.27235)
*Tianyang Chu,Xiaoying Dai,Jing Wu,Aihui Zhou*

Main category: math.NA

TL;DR: Mathematical and numerical analysis of L² normalized gradient flow for Gross-Pitaevskii eigenvalue problem, with focus on ground state computation in Bose-Einstein condensates.


<details>
  <summary>Details</summary>
Motivation: To provide rigorous mathematical foundation and develop efficient numerical schemes for computing ground states of Bose-Einstein condensates using gradient flow models.

Method: First performs mathematical analysis of the model (well-posedness, asymptotic behavior), then proposes a normalized implicit-explicit fully discrete numerical scheme with corresponding numerical analysis.

Result: Established well-posedness and asymptotic behavior of the model, developed a numerical scheme with proven well-posedness and optimal convergence properties, validated by numerical experiments.

Conclusion: The paper provides comprehensive mathematical and numerical analysis for the gradient flow model, establishing theoretical foundations and developing efficient computational methods for Bose-Einstein condensate ground state calculations.

Abstract: This paper concerns the mathematical and numerical analysis of the $L^2$
normalized gradient flow model for the Gross--Pitaevskii eigenvalue problem,
which has been widely used to design the numerical schemes for the computation
of the ground state of the Bose--Einstein condensate. We first provide the
mathematical analysis for the model, including the well-posedness and the
asymptotic behavior of the solution. Then we propose a normalized
implicit-explicit fully discrete numerical scheme for the gradient flow model,
and give some numerical analysis for the scheme, including the well-posedness
and optimal convergence of the approximation. Some numerical experiments are
provided to validate the theory.

</details>


### [13] [High-precision newton-kantorovich method for nonlinear integral equations](https://arxiv.org/abs/2510.27302)
*Kirill A. Chertoganov,Valery I. Shipalov*

Main category: math.NA

TL;DR: High-precision implementation of Newton-Kantorovich method for nonlinear integral equations using mpmath library, improving stability and accuracy over traditional methods.


<details>
  <summary>Details</summary>
Motivation: To address sensitivity to rounding and dispersion in nonlinear integral equations, especially for strongly nonlinear kernels and stiff regimes.

Method: Uses Newton-Kantorovich method with mpmath library, employing high-precision quadrature of kernel K(t, s, u) with respect to variable s for fixed t.

Result: Implementation surpasses traditional low-precision methods, providing increased stability and accuracy.

Conclusion: This approach expands the applicability of the Newton-Kantorovich method in scientific and engineering computations.

Abstract: The paper considers the numerical solution of nonlinear integral equations
using the Newton-Kantorovich method with the mpmath library. High-precision
quadrature of the kernel K(t, s, u) with respect to the variable s for fixed t
increases stability and accuracy in problems sensitive to rounding and
dispersion. The presented implementation surpasses traditional low-precision
methods, especially for strongly nonlinear kernels and stiff regimes, thereby
expanding the applicability of the method in scientific and engineering
computations.

</details>


### [14] [A non-iterative domain decomposition time integrator combined with discontinuous Galerkin space discretizations for acoustic wave equations](https://arxiv.org/abs/2510.27314)
*Tim Buchholz,Marlis Hochbruck*

Main category: math.NA

TL;DR: A non-iterative domain decomposition time integrator for acoustic wave equations using discontinuous Galerkin discretization with local Crank-Nicolson approximation and prediction steps.


<details>
  <summary>Details</summary>
Motivation: To develop a more flexible approach that enables higher-order approximations and handles heterogeneous material parameters naturally, overcoming limitations of previous methods using linear continuous finite elements with mass lumping.

Method: Uses discontinuous Galerkin discretization in space combined with local Crank-Nicolson approximation and suitable local prediction steps in time for non-iterative domain decomposition.

Result: The proposed method successfully enables higher-order approximations and naturally accommodates heterogeneous material parameters.

Conclusion: The novel non-iterative domain decomposition approach provides an effective framework for acoustic wave equations that supports higher-order discretizations and material heterogeneity.

Abstract: We propose a novel non-iterative domain decomposition time integrator for
acoustic wave equations using a discontinuous Galerkin discretization in space.
It is based on a local Crank-Nicolson approximation combined with a suitable
local prediction step in time. In contrast to earlier work using linear
continuous finite elements with mass lumping, the proposed approach enables
higher-order approximations and also heterogeneous material parameters in a
natural way.

</details>


### [15] [A stochastic branching particle method for solving non-conservative reaction-diffusion equations](https://arxiv.org/abs/2510.27615)
*Liyao Lyu,Huan Lei*

Main category: math.NA

TL;DR: A stochastic particle-based method for solving nonlinear non-conservative advection-diffusion-reaction equations using particle transport and branching processes.


<details>
  <summary>Details</summary>
Motivation: To develop a mesh-free, nonnegativity-preserving scheme that handles non-conservative systems and remains robust with singularities or blow-up, avoiding adaptive mesh refinement.

Method: Splits evolution into advection-diffusion step using stochastic particle transport based on linearized Kolmogorov forward equation, and reaction step using branching birth-death process for temporal discretization.

Result: Validated on 2D Allen-Cahn equation and Keller-Segel chemotaxis model, accurately capturing nonlinear behaviors like phase separation and aggregation without adaptive mesh refinement.

Conclusion: The method provides reliable performance for nonlinear non-conservative systems while being mesh-free and robust in challenging scenarios.

Abstract: We propose a stochastic branching particle-based method for solving nonlinear
non-conservative advection-diffusion-reaction equations. The method splits the
evolution into an advection-diffusion step, based on a linearized Kolmogorov
forward equation and approximated by stochastic particle transport, and a
reaction step implemented through a branching birth-death process that provides
a consistent temporal discretization of the underlying reaction dynamics. This
construction yields a mesh-free, nonnegativity-preserving scheme that naturally
accommodates non-conservative systems and remains robust in the presence of
singularities or blow-up. We validate the method on two representative
two-dimensional systems: the Allen-Cahn equation and the Keller-Segel
chemotaxis model. In both cases, the present method accurately captures
nonlinear behaviors such as phase separation and aggregation, and achieves
reliable performance without the need for adaptive mesh refinement.

</details>


### [16] [Numerical solution of elliptic distributed optimal control problems with boundary value tracking](https://arxiv.org/abs/2510.27336)
*Ulrich Langer,Richard Löscher,Olaf Steinbach,Huidong Yang*

Main category: math.NA

TL;DR: Optimal control for Neumann boundary value problems using tensor-product finite element discretization with error estimates and fast solvers.


<details>
  <summary>Details</summary>
Motivation: To solve boundary value tracking optimal control problems constrained by elliptic PDEs with Neumann boundary conditions, where control acts as the right-hand side.

Method: Reformulate as state-based variational problem and use tensor-product finite element discretization.

Result: Derived optimal discretization error estimates and developed fast solvers.

Conclusion: Numerical experiments quantitatively validate the theoretical results.

Abstract: We consider some boundary value tracking optimal control problem constrained
by a Neumann boundary value problem for some elliptic partial differential
equation where the control acts as right-hand side. This optimal control
problem can be reformulated asa state-based variational problem that is the
starting point for the finite element discretizion. In this paper, we only
consider atensor-product finite element discretizion for which optimal
discretization error estimates and fast solvers can be derived.Numerical
experiments illustrate the theoretical results quantitatively.

</details>


### [17] [Pollution control for a spatially structured economic growth system](https://arxiv.org/abs/2510.27393)
*Sebastian Anita,Vincenzo Capasso,Simone Scacchi*

Main category: math.NA

TL;DR: Extended economic growth model incorporating pollution control costs, taxation, and localized environmental interventions with computational analysis.


<details>
  <summary>Details</summary>
Motivation: To extend previous environmental pollution control research by incorporating costs of environmental interventions and localized pollution management strategies.

Method: Spatially structured dynamic economic growth model that considers pollution from production, pollution-based taxation, and localized environmental interventions in subregions.

Result: Computational experiments demonstrate the model's outcomes, showing how localized interventions can be optimized within the economic framework.

Conclusion: The model successfully integrates localized environmental interventions with economic growth considerations, providing a framework for cost-effective pollution control strategies.

Abstract: In this paper investigations by the same authors on environmental issues
concerning the control of the pollution produced by human activities have been
extended to include costs related to environmental interventions. The proposed
model consists of a spatially structured dynamic economic growth model which
takes into account the level of pollution induced by production, a possible
taxation based on the amount of produced pollution, and possible environmental
interventions. It has been analyzed an optimal harvesting control problem with
an objective function composed of four terms, namely the intertemporal utility
of the decision maker, the space-time average of the level of pollution in the
habitat, the disutility due to the imposition of taxation and the cost of
environmental interventions. A specific novelty in the model proposed here is
the localization of the possible interventions to a subregion of the whole
habitat. Computational experiments have been carried out to exemplify the
outcomes of the proposed model.

</details>


### [18] [Novel bidomain partitioned strategies for the simulation of ventricular fibrillation dynamics](https://arxiv.org/abs/2510.27447)
*Gopika P B,Peter Bastian,Nagaiah Chamakuri*

Main category: math.NA

TL;DR: A suite of numerical strategies for simulating cardiac electrophysiology using the bidomain model, featuring a novel partitioned approach with spectral deferred correction for efficient and accurate simulation of ventricular fibrillation.


<details>
  <summary>Details</summary>
Motivation: To develop efficient numerical tools for cardiac electrophysiology simulations, addressing the computational challenges of the bidomain model and enabling large-scale studies of ventricular fibrillation and arrhythmias.

Method: Developed and compared three strategies: fully coupled, traditional decoupled, and novel partitioned strategy with spectral deferred correction. Used compile-time memory-efficient sparse matrix techniques and tested with Luo-Rudy and Ten Tusscher cell models in 2D/3D geometries.

Result: The proposed partitioned strategy achieved high accuracy and efficiency compared to standard decoupled strategies, successfully handling bidomain-bath coupling scenarios and large ODE systems.

Conclusion: Advanced partitioned strategies are effective for large-scale cardiac electrophysiology simulations and show promise for future investigations into cardiac arrhythmias and pathological conditions.

Abstract: The numerical tools to simulate the bidomain model in cardiac
electrophysiology are constantly developing due to the great clinical interest
and scientific advances in mathematical models and computational power. The
bidomain model consists of an elliptic partial differential equation (PDE) and
a non-linear parabolic PDE of reaction-diffusion type, where the reaction term
is described by a set of ordinary differential equations (ODEs). We propose and
analyze a suite of numerical strategies for the efficient and accurate
simulation of cardiac electrophysiology, with a particular focus on ventricular
fibrillation in realistic geometries. Specifically, we develop and compare a
fully coupled strategy, a traditional decoupled strategy, and a novel
partitioned strategy. The centerpiece of this work is a bidomain partitioned
strategy enhanced with spectral deferred correction, designed to balance
numerical stability and computational efficiency. To address the substantial
memory requirements posed by biophysically detailed ionic models, we adopt a
compile-time memory-efficient sparse matrix technique. This enables the
efficient solution of the coupled nonlinear parabolic PDE and the associated
large systems of ODEs that govern ionic gating and concentration dynamics. We
perform comprehensive numerical experiments using the Luo-Rudy and Ten Tusscher
cell models in both two- and three-dimensional geometries. In addition, we
demonstrate the applicability of our approach to bidomain-bath coupling
scenarios. The results confirm that the proposed partitioned strategy achieves
high accuracy and efficiency compared to standard decoupled strategies. Our
findings support the use of advanced partitioned strategies for large-scale
simulations in cardiac electrophysiology and highlight their potential for
future investigations into cardiac arrhythmias and other pathological
conditions.

</details>


### [19] [What Can One Expect When Solving PDEs Using Shallow Neural Networks?](https://arxiv.org/abs/2510.27658)
*Roy Y. He,Ying Liang,Hongkai Zhao,Yimin Zhon*

Main category: math.NA

TL;DR: This paper analyzes how shallow neural networks (SNNs) represent solutions to elliptic PDEs, examining numerical ill-conditioning, frequency bias, and the balance between differential operators and network representations across different formulations and activation functions.


<details>
  <summary>Details</summary>
Motivation: To understand the fundamental properties and limitations of using shallow neural networks for solving elliptic PDEs, particularly focusing on numerical stability and spectral characteristics.

Method: The study uses elliptic PDEs as test cases to analyze SNN performance with various activation functions, examining numerical ill-conditioning, frequency bias, and the interplay between differential operators and network representations.

Result: PINNs and DRM using linear SNNs with power ReLU activation suffer from inherent ill-conditioning and spectral bias against high frequencies. Non-homogeneous activation functions with proper scaling can alleviate these issues, but achieving adaptivity for nonlinear SNNs remains costly due to ill-conditioning.

Conclusion: The performance of neural network methods for PDEs is significantly affected by numerical ill-conditioning and spectral bias, and while certain activation functions can help, achieving adaptive solutions for nonlinear networks remains challenging.

Abstract: We use elliptic partial differential equations (PDEs) as examples to show
various properties and behaviors when shallow neural networks (SNNs) are used
to represent the solutions. In particular, we study the numerical
ill-conditioning, frequency bias, and the balance between the differential
operator and the shallow network representation for different formulations of
the PDEs and with various activation functions. Our study shows that the
performance of Physics-Informed Neural Networks (PINNs) or Deep Ritz Method
(DRM) using linear SNNs with power ReLU activation is dominated by their
inherent ill-conditioning and spectral bias against high frequencies. Although
this can be alleviated by using non-homogeneous activation functions with
proper scaling, achieving such adaptivity for nonlinear SNNs remains costly due
to ill-conditioning.

</details>


### [20] [A Primal-dual Forward-backward Splitting Method for Cross-diffusion Gradient Flows with General Mobility Matrices](https://arxiv.org/abs/2510.27660)
*Yunhong Deng,Chaozhen Wei*

Main category: math.NA

TL;DR: A primal-dual forward-backward splitting method is developed for solving cross-diffusion systems formulated as gradient flows under transport distances with matrix mobilities.


<details>
  <summary>Details</summary>
Motivation: To efficiently compute challenging cross-diffusion systems by leveraging their gradient flow structure and solving them as optimization problems at the fully discrete level.

Method: Uses minimizing movements as variational formulation and applies a primal-dual forward-backward (PDFB) splitting method to solve the resulting optimization problems.

Result: The proposed PDFB splitting method demonstrates efficiency on several challenging cross-diffusion equations from the literature.

Conclusion: The PDFB splitting method provides an effective computational approach for cross-diffusion systems by exploiting their gradient flow structure through variational optimization.

Abstract: In this work, we construct a primal-dual forward-backward (PDFB) splitting
method for computing a class of cross-diffusion systems that can be formulated
as gradient flows under transport distances induced by matrix mobilities. By
leveraging their gradient flow structure, we use minimizing movements as the
variational formulation and compute these cross-diffusion systems by solving
the minimizing movements as optimization problems at the fully discrete level.
Our strategy to solve the optimization problems is the PDFB splitting method
outlined in our previous work \cite{PDFB2024}. The efficiency of the proposed
PDFB splitting method is demonstrated on several challenging cross-diffusion
equations from the literature.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [21] [Loss of embeddedness for the one-phase quasistationary Stefan problem in 2D](https://arxiv.org/abs/2510.26924)
*Friedrich Lippoth*

Main category: math.AP

TL;DR: The paper presents a counterexample showing that a smooth embedded initial state can lose embeddedness in finite time when evolving under the 2D quasistationary Stefan problem with Gibbs-Thomson correction and kinetic undercooling.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that even smooth and embedded initial states can develop singularities and lose their embedded property in finite time under certain physical evolution equations, challenging assumptions about solution regularity.

Method: Constructing a specific counterexample by analyzing the evolution of a smooth embedded initial state under the 2D quasistationary Stefan problem with Gibbs-Thomson correction and kinetic undercooling.

Result: The constructed example proves that embeddedness is not preserved in finite time, showing the formation of singularities despite the initial smoothness and embedded property.

Conclusion: This counterexample reveals limitations in the regularity theory for the quasistationary Stefan problem and highlights that embeddedness is not necessarily preserved under this physical evolution.

Abstract: We provide an example for a smooth and embedded initial state that looses
embeddedness in finite time when evolving according to the quasistationary
Stefan problem with Gibbs-Thomson correction and kinetic undercooling in 2D.

</details>


### [22] [On Singular Integrals and Quantitative Rectifiability in Parabolic Space and the Heisenberg Group](https://arxiv.org/abs/2510.26934)
*John Hoffman,Ben Jaye*

Main category: math.AP

TL;DR: Extension of David-Semmes theorem from Euclidean space to parabolic space and Heisenberg group


<details>
  <summary>Details</summary>
Motivation: To generalize the David-Semmes theorem about the relationship between boundedness of CZOs and uniform rectifiability to non-Euclidean settings

Method: Extending the David-Semmes theorem framework to parabolic space and the first Heisenberg group

Result: Successfully proved that if all CZOs are bounded with respect to an Ahlfors regular measure in these spaces, then the measure is uniformly rectifiable

Conclusion: The David-Semmes theorem holds in parabolic space and the first Heisenberg group, extending the classical result beyond Euclidean space

Abstract: David and Semmes proved that if all CZOs (of suitable dimension) are bounded
with respect to an Ahlfors regular measure, then the measure is uniformly
rectifiable. We extend this theorem to the parabolic space and the first
Heisenberg group.

</details>


### [23] [Statistically stationary solutions to the stochastic isentropic compressible Euler equations with linear damping](https://arxiv.org/abs/2510.27079)
*Jeffrey Kuan,Krutika Tawri,Konstantina Trivisa*

Main category: math.AP

TL;DR: The paper proves existence of statistically stationary solutions for stochastic isentropic compressible Euler equations with linear damping on a 1D torus, using a multi-level approximation scheme and entropy methods.


<details>
  <summary>Details</summary>
Motivation: To understand the long-time statistical behavior of stochastic Euler equations in one spatial dimension, particularly for compressible flows with damping driven by white noise.

Method: Multi-level approximation scheme with truncation parameter R and artificial viscosity parameter ε, preserving system structure and providing invariant region properties. Construction of invariant measures via Feller semigroups for approximate systems.

Result: Existence of statistically stationary solutions in the class of weak martingale entropy solutions for any adiabatic constant γ>1, satisfying associated entropy inequalities.

Conclusion: The result represents a valuable step toward understanding long-time statistical behavior of stochastic Euler equations in 1D, using novel techniques for uniform entropy bounds and parameter limits.

Abstract: We study the long time behavior of isentropic compressible Euler equations
with linear damping driven by a white-in-time noise, on a one-dimensional
torus. We prove the existence of a statistically stationary solution in the
class of weak martingale entropy solutions for any adiabatic constant
$\gamma>1$, which satisfies an associated entropy inequality. To establish this
result, we use a multi-level approximation scheme consisting of a truncation
parameter $R$ and an artificial viscosity parameter $\epsilon$. The truncated
system preserves the structure of the regularized system with the artificial
viscosity, thereby providing key properties such as an invariant region and
non-existence of vacuum at the approximate level. These properties allow us to
construct an invariant measure for the approximate system in both $R$ and
$\epsilon$ associated to a Feller semigroup for the well-posed dynamics of the
approximate system for any $\gamma > 1$. This gives us a statistically
stationary solution for the approximate problem, which we then successively
pass to the limit as $R \to \infty$ and as $\epsilon \to 0$ to obtain a
statistically stationary solution to the original stochastic system. Our
analysis is novel, using new techniques for establishing uniform bounds on
entropies of all orders, which allow us to pass to the limit in the parameters.
We believe that this result is a valuable step towards further understanding
the long-time statistical behavior of the stochastic Euler equations in one
spatial dimension.

</details>


### [24] [Non-uniqueness of positive solutions for supercritical semilinear heat equations without scale invariance](https://arxiv.org/abs/2510.27098)
*Kotaro Hisa,Yasuhito Miyamoto*

Main category: math.AP

TL;DR: The paper proves nonuniqueness of solutions for semilinear heat equations with nonlinearities growing slower than the Joseph-Lundgren exponent, showing at least two positive solutions exist when initial data equals a singular stationary solution.


<details>
  <summary>Details</summary>
Motivation: To establish nonuniqueness in Cauchy problems for semilinear heat equations, reducing the nonuniqueness problem to the existence of positive radial singular stationary solutions.

Method: Based on monotonicity argument and transformations of forward self-similar solutions for power and exponential nonlinearities, constructing a second solution that converges to the singular stationary solution.

Result: When initial data equals the singular stationary solution u*, there exist at least two positive solutions: u* itself and another solution u(t) that converges to u* in certain local spaces as t→0+.

Conclusion: Nonuniqueness can be established by proving the existence of positive radial singular stationary solutions, providing a framework for analyzing nonuniqueness in semilinear heat equations.

Abstract: We establish nonuniqueness of solutions for Cauchy problems of semilinear
heat equations with a wide class of nonlinearities. Specifically, we consider
\[ \begin{cases} \partial_tu-\Delta u=f(u), & x\in\mathbb{R}^N,\ t>0,\\
u(x,0)=u_0(x), & x\in\mathbb{R}^N, \end{cases} \] where $N>2$. We assume that
the growth rate of $f$ is less than the Joseph-Lundgren exponent for $N>10$ and
it satisfies certain assumptions guaranteeing a positive radial singular
stationary solution $u^*$. We prove that if $u_0=u^*$, then the problem has at
least two positive solutions, namely $u^*$ and $u(t)$ which satisfies $u(t)\in
L_{loc}^{\infty}(0,t_0;L^{\infty}(\mathbb{R}^N))$ for some $t_0>0$ and $$
u(t)\to u^*\quad\text{in}\ L^{\gamma}_{ul}(\mathbb{R}^N)\quad\text{as}\ t\to
0^+ $$ for $1\le \gamma<N(p_f-1)/2$, where $p_f:=\lim_{u\to\infty}uf'(u)/f(u)$
is a growth rate of $f$. Hence, nonuniqueness problem can be reduced to the
existence problem of a positive radial singular stationary solution. The method
of construction of $u(t)$ is based on the monotonicity argument.
Transformations of forward self-similar solutions for $f(u)=u^p$ and $e^u$ play
a crucial role.

</details>


### [25] [Quantitative homogenization of Hamilton--Jacobi equations on perforated domains with Dirichlet boundary conditions](https://arxiv.org/abs/2510.27099)
*Yuxi Han,Son Tu*

Main category: math.AP

TL;DR: The paper establishes an optimal O(ε) convergence rate for homogenization of convex Hamilton-Jacobi equations on perforated domains with Dirichlet boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To address the homogenization of convex Hamilton-Jacobi equations in perforated domains, particularly dealing with the singularity that occurs when optimal paths don't fully utilize available time.

Method: Analysis of optimal control representation of solutions and properties of the metric function associated with running cost, with special treatment of the singularity issue.

Result: Established optimal convergence rate of O(ε) for homogenization.

Conclusion: The approach successfully handles the singularity problem and achieves optimal convergence rates for homogenization in perforated domains.

Abstract: We study the periodic homogenization of convex Hamilton-Jacobi equations on
perforated domains with Dirichlet boundary conditions. By analyzing the optimal
control representation of the solutions and the properties of the metric
function associated with the running cost, we establish the optimal convergence
rate $\mathcal{O}(\varepsilon)$ for homogenization. A key aspect of our
approach is the treatment of the singularity that arises when the optimal path
does not fully utilize the available time.

</details>


### [26] [Linear inviscid damping for stably stratified Boussinesq flows](https://arxiv.org/abs/2510.27278)
*Alberto Enciso,Marc Nualart*

Main category: math.AP

TL;DR: Analysis of linear asymptotic stability for stably stratified monotone shear flows in Boussinesq equations, showing inviscid damping with time-decay rates depending on Richardson number across four stratification regimes.


<details>
  <summary>Details</summary>
Motivation: To understand the stability properties and damping behavior of stratified shear flows in periodic channels, particularly how stratification affects velocity and density perturbations.

Method: Using the limiting absorption principle to analyze the Green's function structure and obtain precise descriptions of inviscid damping across different stratification regimes defined by Richardson number thresholds.

Result: Obtained time-decay rates for velocity and density perturbations that depend on local Richardson number, with qualitative changes at critical thresholds J(y)=0 and J(y)=1/4, leading to quantitative sub-linear growth estimates for vorticity and density gradient.

Conclusion: The linearised Boussinesq operator has purely continuous spectrum under mild hypotheses on the shear-type equilibrium, and stratification significantly influences the damping behavior through four distinct regimes.

Abstract: We study the linear asymptotic stability of stably stratified monotone shear
flows for the Boussinesq equations in the periodic channel. By means of the
limiting absorption principle, we obtain a precise description of the inviscid
damping experienced by the perturbed velocity field and density, with
time-decay rates that depend on the local Richardson number $\mathcal{J}(y)$
and split into four stratification regimes (non-stratified, weak, mild, and
strong) reflecting qualitative changes in the structure of the Green's function
at the critical thresholds $\mathcal{J}(y)=0$ and $\mathcal{J}(y) = \frac14$.
The velocity and density decay estimates are later used to prove quantitative
sub-linear growth of the vorticity and gradient of density. As a byproduct of
our analysis, we show that, under mild hypotheses on the underlying shear-type
equilibrium, the spectrum of the linearised Boussinesq operator is purely
continuous.

</details>


### [27] [Instantaneous Total Enhanced Dissipation For Very Rough Shear Flows](https://arxiv.org/abs/2510.27331)
*Marco Romito,Leonardo Roveri*

Main category: math.AP

TL;DR: Enhanced dissipation for passive scalars in very rough 2D shear flows, extending previous work to negative Besov spaces with non-sharp bounds on dissipation rates.


<details>
  <summary>Details</summary>
Motivation: To extend enhanced dissipation results to generic flows in negative Besov spaces and understand dissipation behavior for truly irregular velocities as viscosity vanishes.

Method: Derive upper and lower bounds on dissipation rates for passive scalars advected by rough horizontal shear flows, using Wei irregularity index for truly irregular velocities.

Result: Dissipation rate increases to infinity as viscosity vanishes for generic flows in negative Besov spaces. Upper bounds hold for truly irregular velocities satisfying Wei irregularity index.

Conclusion: For truly rough shear flows, the vanishing viscosity solution to the corresponding inviscid equation is trivial, demonstrating strong enhanced dissipation effects.

Abstract: This paper investigates enhanced dissipation for a passive scalar advected by
"very rough" horizontal shear flows, described by an advection-diffusion
equation on the 2D torus. The authors extend results of Galeati and Gubinelli
(2023) to generic flows in negative Besov spaces, proving that the dissipation
rate increases to infinity as viscosity vanishes. This is obtained by deriving
(non-sharp) upper and lower bounds on the dissipation rate. The upper bound
holds for truly irregular velocities, namely those verifying a suitable version
of the Wei irregularity index (Wei (2021)). As a by-product, it follows that
for truly rough shear flows the vanishing viscosity solution to the
corresponding inviscid equation is trivial.

</details>


### [28] [Some existence and uniqueness results for infinity Laplace equations on infinite graphs](https://arxiv.org/abs/2510.27357)
*Fengwen Han,Tao Wang*

Main category: math.AP

TL;DR: Study of Dirichlet problem for discrete infinity Laplace equation on unbounded subgraphs, focusing on existence and uniqueness of sublinear solutions for homogeneous case and applications to Euclidean domains.


<details>
  <summary>Details</summary>
Motivation: To establish existence and uniqueness results for the discrete infinity Laplace equation on unbounded domains, which has applications to continuum infinity Laplace equations on Euclidean domains.

Method: Analysis of the Dirichlet problem for discrete infinity Laplace equation Δ∞u(x) = inf u(y) + sup u(y) - 2u(x) = f(x) on unbounded subgraphs, with focus on homogeneous case (f=0) and non-negative f on trees.

Result: For homogeneous case (f=0), existence and uniqueness of sublinear solutions are established. This extends to existence and uniqueness of sublinear solutions for homogeneous infinity Laplace equations on unbounded Euclidean domains. Uniqueness is also proven for f ≥ 0 on trees.

Conclusion: The paper successfully establishes fundamental existence and uniqueness results for sublinear solutions of discrete infinity Laplace equations on unbounded domains, with applications to continuum equations and special results for tree structures.

Abstract: We study the Dirichlet problem of the following discrete infinity Laplace
equation on unbounded subgraphs
  \begin{equation*}
  \Delta_{\infty}u(x):=\inf_{y\sim x}u(y)+\sup_{y\sim x}u(y)-2u(x)=f(x).
  \end{equation*}
  For the homogeneous case ($f=0$), the existence and uniqueness of sublinear
solutions are established. This result is applied to prove the existence and
uniqueness of sublinear solutions for the homogeneous (normalized) infinity
Laplace equations on unbounded Euclidean domains. Uniqueness is also shown for
the case $f \geq 0$ on trees.

</details>


### [29] [Affine rigidity of functions with additive oscillation](https://arxiv.org/abs/2510.27360)
*Adolfo Arroyo-Rabasa,Sergio Conti*

Main category: math.AP

TL;DR: A locally integrable function must be affine if its mean oscillation can be extended to a locally finite Borel measure.


<details>
  <summary>Details</summary>
Motivation: To characterize functions whose mean oscillation behavior can be represented as a measure, and to understand the implications of integro-differential identities on function regularity.

Method: Mathematical analysis using measure theory and oscillation properties, proving that the given conditions force functions to be affine.

Result: Proved that functions satisfying |Df|(I)=4osc(f,I) for all intervals I must be affine, establishing a strong regularity condition.

Conclusion: The extension of mean oscillation to a locally finite Borel measure imposes such strong constraints that only affine functions can satisfy them.

Abstract: We prove that a locally integrable function $f:(a,b) \to \mathbb R$ must be
affine if its mean oscillation, considered as a function of intervals, can be
extended to a locally finite Borel measure. In particular, we show that any
function $f$ satisfying the integro-differential identity
$|Df|(I)=4\text{osc}(f,I)$ for all intervals $I \subset {(a,b)}$ must be
affine.

</details>


### [30] [A mixed eigenvalue problem on domains tending to infinity in several directions](https://arxiv.org/abs/2510.27455)
*Prosenjit Roy,Itai Shafrir*

Main category: math.AP

TL;DR: Analysis of eigenvalue asymptotic behavior for elliptic operators on cylindrical domains with mixed boundary conditions


<details>
  <summary>Details</summary>
Motivation: To understand how eigenvalues behave as domains become unbounded in some directions while remaining bounded in others, continuing previous work

Method: Studying elliptic operators in divergence form with mixed boundary conditions on cylindrical domains, analyzing limiting behavior through eigenvalue problems on domains unbounded in one direction

Result: Eigenvalue asymptotic behavior depends on ensemble of eigenvalue problems defined on domains unbounded in one direction; eigenfunction asymptotic behavior also analyzed

Conclusion: The limiting behavior of eigenvalues for elliptic operators on cylindrical domains is characterized by eigenvalue problems on simpler unbounded domains

Abstract: The aim of this article is to analyze the asymptotic behaviour of the
eigenvalues of elliptic operators in divergence form with mixed boundary type
conditions for domains that become unbounded in several directions, while they
stay bounded in some directions (cylindrical domains). The limiting behavior of
such eigenvalues is shown to depend on an ensemble of eigenvalue problems
defined on a domain that is unbounded only in one direction. The asymptotic
behavior of the eigenfunctions are also discussed. This work is a continuation
of the work done in [6].

</details>


### [31] [Improved refined bilinear estimates and well-posedness for generalized KdV type equations on $\mathbb{R}$](https://arxiv.org/abs/2510.27461)
*Luc Molinet,Tomoyuki Tanaka*

Main category: math.AP

TL;DR: Unconditional local well-posedness for 1D dispersive equations with nonlinearity ∂ₓf(u) is proved for optimal Sobolev regularity, with global existence results for α ∈ [5/4,2].


<details>
  <summary>Details</summary>
Motivation: To establish optimal local well-posedness results for dispersive equations with general nonlinearities and derive global existence under certain parameter ranges.

Method: Improved refined linear and bilinear estimates on ℝ, building on previous studies to handle dispersive operators behaving like i|ξ|^αξ for high frequencies.

Result: Proved unconditional local well-posedness in H^s(ℝ) for s≥(5-2α)/4 when 1≤α<3/2, and for s>1/2 when α∈[3/2,2]. Global existence established for α∈[5/4,2].

Conclusion: The results are optimal for α≥3/2, with the main novelty being improved linear and bilinear estimates that enable these sharp well-posedness results.

Abstract: We study the Cauchy problem for one-dimensional dispersive equations posed on
$\mathbb{R} $, under the hypotheses that the dispersive operator behaves, for
high frequencies, as a Fourier multiplier by $ i |\xi|^\alpha \xi $ with $ 1
\le \alpha\le 2 $, and that the nonlinear term is of the form $ \partial_x f(u)
$ where $f $ is a real analytic function satisfying certain conditions. We
prove the unconditional local well-posedness of the Cauchy problem in
$H^s(\mathbb{R}) $ for $ s\ge \frac{5-2\alpha}{4} $ whenever $ 1\le
\alpha<\frac{3}{2} $, and for $ s>\frac{1}{2} $ whenever $\alpha\in
[\frac{3}{2},2] $. This result is optimal in the case $\alpha\ge \frac{3}{2}$
in view of the restriction $ s>\frac{1}{2} $ required for the continuous
embedding $ H^s(\mathbb{R}) \hookrightarrow L^\infty(\mathbb{R}) $. The main
novelty of this work, compared to our previous studies, is an improvement of
the refined linear and bilinear estimates on $\mathbb{R} $. Our local
well-posedness results enable us to derive global existence of solutions for $
\alpha \in [\frac{5}{4},2] $.

</details>


### [32] [Coexisting Automated and Human-Driven Vehicles: Well-Posedness of a Mixed Nonlocal-Local Traffic Model](https://arxiv.org/abs/2510.27509)
*Rinaldo M. Colombo,Mauro Garavello,Claudia Nocita*

Main category: math.AP

TL;DR: A macroscopic traffic flow model with standard and informed vehicles, using mixed nonlocal-local integro-differential PDEs that generate a locally Lipschitz continuous semigroup with unique solutions.


<details>
  <summary>Details</summary>
Motivation: To model traffic systems where standard vehicles coexist with vehicles that have information about traffic distribution, requiring a mathematical framework that handles both local and nonlocal interactions.

Method: Developed mixed nonlocal-local integro-differential PDEs, proved they generate a locally Lipschitz continuous semigroup, and established unique solution characterization using intrinsic norms and function spaces.

Result: Successfully proved the existence of a locally Lipschitz continuous semigroup and unique characterization of solutions to the traffic flow system.

Conclusion: The proposed mathematical framework provides a rigorous foundation for modeling mixed traffic systems with informed and standard vehicles, ensuring well-posedness of the resulting PDE system.

Abstract: We present a macroscopic traffic flow model where standard vehicles coexist
with vehicles informed on the traffic distribution. The resulting mixed
nonlocal-local integro-differential PDEs is proved to generate a locally
Lipschitz continuous semigroup whose orbits are uniquely characterized as
solutions to the system, according to a natural definition of solution. The
norms and function spaces adopted are intrinsic to the different nature of the
equations.

</details>


### [33] [Remarks on the Spatial Asymptotic Behavior of Solutions to a 1D Model of Equatorial Oceanic Flows](https://arxiv.org/abs/2510.27520)
*Manuel Fernando Cortez,Oscar Jarrin*

Main category: math.AP

TL;DR: Analysis of spatial asymptotic behavior of solutions to a nonlinear nonlocal evolution equation modeling equatorial oceanic flows, focusing on the influence of the Coriolis effect on decay rates.


<details>
  <summary>Details</summary>
Motivation: To understand the spatial decay properties of solutions to a recently derived nonlinear nonlocal evolution equation that models oceanic flows in equatorial regions, particularly examining how the Coriolis effect influences solution behavior.

Method: Investigation of spatial asymptotic behavior of solutions, analysis of decay rates influenced by the Coriolis effect, and examination of optimality of observed decay rates.

Result: The Coriolis effect causes solutions to decay at the rate 1/|x|, even for rapidly decaying initial data. This decay rate is shown to be optimal.

Conclusion: The Coriolis effect significantly impacts the spatial decay behavior of solutions to this equatorial oceanic flow model, producing a characteristic 1/|x| decay rate that represents an optimal bound for solution behavior.

Abstract: We consider a new nonlocal and nonlinear one-dimensional evolution model
arising in the study of oceanic flows in equatorial regions, recently derived
in [A. Constantin and L. Molinet, Global Existence and Finite-Time Blow-Up for
a Nonlinear Nonlocal Evolution Equation, Commun. Math. Phys. 402 (2023),
3233-3252].
  We investigate the spatial asymptotic behavior of its solutions. In
particular, we observe the influence of the Coriolis effect, which, even for
rapidly decaying initial data, yields solutions that decay at the rate $1 /
|x|$. Thereafter, we shed light on the optimality of this decay rate.

</details>


### [34] [Orthogonality of H-distributions and applications](https://arxiv.org/abs/2510.27550)
*Nenad Antonić,Darko Mitrović,Tomislav Perić*

Main category: math.AP

TL;DR: Extension of Gérard's orthogonality results from L² sequences to Lᵖ/Lᵠ sequences using H-distributions, applied to homogenization of Boltzmann equation with space-dependent drift.


<details>
  <summary>Details</summary>
Motivation: To generalize microlocal defect measure (H-measure) orthogonality theory beyond L² spaces and apply it to more complex homogenization problems.

Method: Extending Gérard's framework to Lᵖ/Lᵠ sequences using newly introduced H-distributions concept, then applying to heterogeneous Boltzmann equation with periodic opacity.

Result: Established orthogonality results for Lᵖ/Lᵠ sequences via H-distributions, providing tools for homogenization of transport equations with space-dependent coefficients.

Conclusion: The extended orthogonality theory enables rigorous analysis of homogenization problems for Boltzmann-type equations with complex spatial dependencies.

Abstract: We extend G\'erard's results on orthogonality of ${\rm L}^2_{\rm loc}$
sequences as a consequence of mutual singularity of corresponding H-measures
(microlocal defect measures) to ${\rm L}^p$/${\rm L}^q$ sequences and newly
introduced notion of orhogonality for H-distributions. We apply the result to a
homogenisation problem for the heterogeneous Boltzmann equation with
space-dependent drift and periodic opacity.

</details>


### [35] [On the global existence and uniform-in-time bounds for three-component reaction-diffusion systems with mass control and polynomial growth](https://arxiv.org/abs/2510.27555)
*Redouane Douaifia,Salem Abdelmalek,Mokhtar Kirane*

Main category: math.AP

TL;DR: Global existence of classical solutions for three-component reaction-diffusion systems with mass control and linear intermediate weighted sum condition, even with arbitrary polynomial growth nonlinearities. Also establishes uniform-in-time bounds under stronger assumptions.


<details>
  <summary>Details</summary>
Motivation: To establish global existence and boundedness results for reaction-diffusion systems with mass control and structural assumptions, particularly for systems with arbitrary polynomial growth nonlinearities that are challenging to analyze.

Method: Extension of L^p-energy polynomial functionals combined with the regularizing effect for parabolic equations. The approach relies on structural assumptions including mass control and linear intermediate weighted sum condition.

Result: Proved global existence of classical solutions in arbitrary spatial dimensions and various boundary conditions. Also established uniform-in-time bounds under slightly stronger assumptions with mixed boundary conditions.

Conclusion: The framework successfully handles reaction-diffusion systems with polynomial growth nonlinearities and is applicable to three-species sub-skew-symmetric Lotka-Volterra systems with higher-order interactions, providing a robust analytical approach.

Abstract: We investigate a class of three-component reaction-diffusion systems subject
to mass control and a newly introduced structural assumption, referred to as
linear intermediate weighted sum condition. Under these hypotheses, we
establish the global existence of classical solutions in arbitrary spatial
dimensions and wide class of boundary conditions, even when the nonlinearities
exhibit arbitrary polynomial growth. We establish also that, under
slight-stronger assumptions and mixed boundary conditions, solutions admit
uniform-in-time bounds. Our approach relies on the extension of $L^p$-energy
polynomial functionals, together with the regularizing effect for parabolic
equations. Furthermore, we demonstrate the applicability of our framework by
analyzing three-species sub-skew-symmetric Lotka-Volterra systems with
higher-order interactions.

</details>


### [36] [Regularity for quasilinear elliptic equations in metric measure spaces](https://arxiv.org/abs/2510.27564)
*Simon Schulz,Ivan Yuri Violo*

Main category: math.AP

TL;DR: The paper proves second-order and Lipschitz regularity for quasilinear elliptic equations in metric spaces with Ricci curvature lower bounds, covering p-harmonic functions for all p∈(1,∞).


<details>
  <summary>Details</summary>
Motivation: To extend regularity theory beyond classical Hölder regularity for elliptic equations in metric spaces with curvature bounds, addressing a wide family of elliptic operators.

Method: Uses Galerkin's method as an alternative to traditional difference quotients technique to prove quantitative estimates.

Result: Establishes second-order and Lipschitz regularity with quantitative estimates, including Cheng-Yau type inequality for p-harmonic functions.

Conclusion: First results in this setting that simultaneously cover wide families of elliptic operators and extend beyond classical Hölder regularity theory.

Abstract: In the present article we prove second-order and Lipschitz regularity for
quasilinear elliptic equations in metric spaces endowed with a lower bound on
the Ricci curvature. The estimates we obtain are quantitative and cover a large
class of elliptic equations with polynomial growth. As a particular case we
settle the Lipschitz regularity of $p$-harmonic functions for all values of
$p\in(1,\infty)$, proving also a Cheng-Yau type inequality. These results are
the first in this setting that simultaneously address a wide family of elliptic
operators and extend beyond the classical H\"older regularity theory. Our
strategy rests on the use of Galerkin's method, which we employ as an
alternative to the traditional difference quotients technique.

</details>


### [37] [The zero capillarity limit for the Euler-Korteweg system with no-flux boundary conditions](https://arxiv.org/abs/2510.27682)
*Paolo Antonelli,Yuri Cacchiò*

Main category: math.AP

TL;DR: Study of small dispersion limit for Euler-Korteweg system in bounded domains with no-flux boundary conditions using relative entropy approach.


<details>
  <summary>Details</summary>
Motivation: To analyze convergence of finite energy weak solutions to strong solutions of compressible Euler system, particularly addressing challenges from non-trivial boundary conditions and boundary layers.

Method: Relative entropy approach with correction for limiting particle density to handle boundary layer effects in bounded domains with no-flux boundary conditions.

Result: Developed method to study convergence accounting for boundary layer effects in singular limits with non-trivial boundary conditions.

Conclusion: The approach is adaptable for studying similar singular limits involving non-trivial boundary conditions in other systems.

Abstract: In this article, we study the small dispersion limit of the Euler-Korteweg
system in a bounded domain with no-flux boundary conditions. We exploit a
relative entropy approach to study the convergence of finite energy weak
solutions towards strong solutions to the compressible Euler system. Since we
consider non-trivial boundary conditions, our approach needs a correction for
the limiting particle density, due to the appearance of a (weak) boundary
layer. We believe this approach can be adapted to study similar singular limits
involving non-trivial boundary conditions.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [38] [MRX: A differentiable 3D MHD equilibrium solver without nested flux surfaces](https://arxiv.org/abs/2510.26986)
*Tobias Blickhan,Julianne Stratton,Alan A. Kaptanoglu*

Main category: physics.comp-ph

TL;DR: A new 3D MHD equilibrium solver using magnetic relaxation with admissible variations of B and p, implemented in differentiable Python for computational efficiency and handling complex geometries.


<details>
  <summary>Details</summary>
Motivation: To address traditional challenges in 3D MHD equilibrium solvers such as enforcing physical constraints, numerical convergence, complex geometries, and modeling stochastic field lines.

Method: Uses magnetic relaxation based on admissible variations of B and p, with mathematical theory ensuring energy bounds and differential geometry for domain transformations. Implemented in differentiable Python.

Result: Successfully benchmarked with standard examples including 2D toroidal equilibria at high-beta and rotating ellipse stellarator, demonstrating robustness and computational efficiency.

Conclusion: The solver provides an effective approach for 3D MHD equilibrium problems and will be extended for optimization in modeling magnetic islands and chaos in stellarator fusion devices.

Abstract: This article introduces a new 3D magnetohydrodynamic (MHD) equilibrium
solver, based on the concept of admissible variations of B, p that allows for
magnetic relaxation of a magnetic field in a perturbed/non-minimum energy state
to a lower energy state. We describe the mathematical theory behind this
method, including ensuring certain bounds on the magnetic energy, and the
differential geometry behind transforming to and from a logical domain and
physical domain. Our code is designed to address a number of traditional
challenges to 3D MHD equilibrium solvers, e.g. exactly enforcing physical
constraints such as divergence-free magnetic field, exhibiting high levels of
numerical convergence, dealing with complex geometries, and modeling stochastic
field lines or chaotic behavior. By using differentiable Python, our numerical
method comes with the additional benefits of computational efficiency on modern
computing architectures, high code accessibility, and differentiability at each
step. The proposed magnetic relaxation solver is robustly benchmarked and
tested with standard examples, including solving 2D toroidal equilibria at
high-beta, and a rotating ellipse stellarator. Future work will address the
integration of this code for 3D equilibrium optimization for modeling magnetic
islands and chaos in stellarator fusion devices.

</details>


### [39] [Attenuation Compensation in Lossy Media via the Wave Operator Model](https://arxiv.org/abs/2510.27276)
*Tianchen Shao,Zekui Jia,Maokun Li,Shenheng Xu,Fan Yang*

Main category: physics.comp-ph

TL;DR: This paper extends the wave operator model from lossless to lossy media, deriving solutions for electric fields in dissipative environments and proposing an attenuation compensation strategy to restore attenuated data.


<details>
  <summary>Details</summary>
Motivation: To extend the wave operator framework from lossless to lossy media, enabling modeling of wave propagation in dissipative environments where attenuation occurs.

Method: Derived wave operator solution for electric field in lossy media, decomposed into propagation and dissipation terms. Proposed attenuation compensation strategy based on analysis of dominant exponential decay in propagation term.

Result: Numerical experiments validated the performance of the attenuation compensation strategy, successfully restoring attenuated data to approximate lossless state.

Conclusion: Established theoretical foundation for reduced order model (ROM)-based techniques in lossy media, enabling application of wave operator framework to dissipative environments.

Abstract: The wave operator model provides a framework for modeling wave propagation by
encoding material parameter distributions into matrix-form operators. This
paper extends this framework from lossless to lossy media. We present a
derivation of the wave operator solution for the electric field in dissipative
environments, which can be decomposed into a closed-form propagation term and a
non-closed-form dissipation term. Based on an analysis of the dominant
exponential decay within the propagation term, an attenuation compensation
strategy is proposed to restore the attenuated data to an approximate lossless
state. The performance of this compensation strategy is analyzed and validated
through numerical experiments, establishing the theoretical foundation for
reduced order model (ROM)-based techniques in lossy media.

</details>


### [40] [Boron Nitride Nanotubes as Efficient Surface Absorbers for Air Pollutant Gas Molecules: Insights from Density Functional Theory](https://arxiv.org/abs/2510.27608)
*Joy Mukherjee,Chaithanya Purushottam Bhat,Antara Banerjee,Debashis Bandyopadhyay*

Main category: physics.comp-ph

TL;DR: BN nanotubes show strong adsorption capabilities for pollutant gases without structural damage, making them promising for air quality sensors.


<details>
  <summary>Details</summary>
Motivation: To investigate the potential of boron nitride nanotubes as efficient absorbents for environmental pollutant gases to improve indoor air quality.

Method: Used density functional theory (DFT) with spin-polarized generalized gradient approximation to study adsorption behavior and analyze thermodynamic/chemical parameters.

Result: BN nanotubes demonstrated robust adsorption of various pollutant gases, maintained structural integrity, and formed distinct BNNT-gas complexes confirmed by infrared spectroscopy.

Conclusion: Boron nitride nanotubes show promising potential as effective absorbents for gaseous pollutants, suitable for developing environmental sensors.

Abstract: This study investigates into the adsorption sensing capabilities of
single-walled (5,5) boron nitride nanotubes (BNNTs) towards environmental
pollutant gas molecules, including CH2, SO2, NH3, H2Se, CO2 and CS2. Employing
a linear combination of atomic orbital density functional theory (DFT) and
spin-polarized generalized gradient approximation (GGA), the investigation
reveals the nanotube's robust adsorption behavior without compromising its
structural integrity. Thermodynamic and chemical parameters, such as adsorption
energy, HOMO-LUMO gap, vertical ionization energy, and vertical electron
affinity, highlight the (5,5) BNNTs' potential as efficient absorbents for
pollutant molecules. Infrared spectroscopy confirms the formation of distinct
BNNT-gas complexes. These findings underscore the promising application of BN
nanotubes as absorbents for common gaseous pollutants, essential for developing
sensors to enhance indoor air quality.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [41] [Plasma fibre using bright-core helicon plasma](https://arxiv.org/abs/2510.27105)
*Lei Chang,Zi-Chen Kan,Jing-Jing Ma,Saikat Chakraborty Thakur,Juan Francisco Caneses*

Main category: physics.plasm-ph

TL;DR: The paper introduces a 'plasma fibre' concept using helicon plasma that mimics optical fibers, demonstrating wave-guiding through total reflection at plasma density gradients.


<details>
  <summary>Details</summary>
Motivation: Inspired by spatial and spectral similarities between bright-core helicon plasma and optical fibers, the research aims to develop a dynamically reconfigurable wave-guiding component for communication systems.

Method: Theoretical analysis of step-like and Gaussian density profiles, numerical computations using electromagnetic solver based on Maxwell's equations and cold-plasma dielectric tensor.

Result: Total reflection of electromagnetic waves occurs near sharp plasma density gradients when incident angle exceeds threshold, enabling wave-guiding functionality similar to optical fibers.

Conclusion: Plasma fibre can serve as a functional, dynamically reconfigurable component in communication systems, with experimental verification and applications suggested for future work.

Abstract: This paper reports an innovative concept of ``plasma fibre" using bright-core
helicon plasma, inspired by its spatial and spectral similarities to the
well-known optical fibre. Theoretical analyses are presented for both ideal
case of step-like density profile and the realistic case of Gaussian density
profile in radius. The total reflection of electromagnetic waves near the sharp
plasma density gradient and consequently the wave-guide feature could indeed
happen if the incident angle is larger than a threshold value. Numerical
computations using electromagnetic solver that based on Maxwell's equations and
cold-plasma dielectric tensor yield consistent results. The experimental
verification and prospective applications are also suggested. The ``plasma
fibre" could be functional component that embedded into existing communication
systems for special purpose based on its capability of dynamic reconfiguration.

</details>


### [42] [Synchronized Catastrophic Collapse and Extreme Intensity Amplification of Ultra-Intense Pulses in Near-Resonance Magnetized Plasma](https://arxiv.org/abs/2510.27239)
*Sintu Kumar,Pratibha Jaiswal,Rajesh Kumar Rai*

Main category: physics.plasm-ph

TL;DR: Magnetic field tuning near cyclotron resonance enables extreme laser energy concentration in plasma, achieving over 1000x intensity amplification through enhanced relativistic self-focusing and temporal compression.


<details>
  <summary>Details</summary>
Motivation: Overcoming fundamental limitations in achieving ultra-high field intensities for compact plasma accelerators and high-energy-density physics, which are constrained by focusing distance and nonlinear efficiency.

Method: Theoretical model using magnetically-assisted pathway in under-dense plasma by tuning external magnetic field near cyclotron resonance (Ce=0.7) to enhance relativistic self-focusing mechanism.

Result: Achieved catastrophic coupled collapse over 1.25 Rayleigh lengths, with spatial confinement (fr=0.05), temporal self-compression (ft=0.60), and peak intensity amplification factor exceeding 1000x compared to initial state.

Conclusion: Provides robust and compact method for generating petawatt-scale power densities and actionable blueprint for next-generation laser-plasma experiments.

Abstract: Achieving ultra-high field intensities is paramount for advancing compact
plasma accelerators and high-energy-density physics, yet it is fundamentally
limited by the constraints of focusing distance and nonlinear efficiency. We
report a theoretical model demonstrating a highly efficient,
magnetically-assisted pathway for extreme laser energy concentration in
under-dense plasma. By tuning an external magnetic field near the cyclotron
resonance (Ce=0.7), we show a fundamental, nonlinear enhancement of the
relativistic self-focusing (RSF) mechanism. This magnetic enhancement drives
the pulse into a catastrophic, coupled collapse over an exceptionally short
distance of 1.25 Rayleigh lengths. The dynamics result in simultaneous spatial
confinement (fr=0.05) and significant temporal self-compression (ft=0.60 ).
Crucially, this combined confinement yields a localized peak intensity
amplification factor exceeding 103 compared to the initial state. This work
confirms a robust and compact method for generating petawatt-scale power
densities and provides a direct, actionable blueprint for next-generation
laser-plasma experiments.

</details>


### [43] [Modeling partially-ionized dense plasma using wavepacket molecular dynamics](https://arxiv.org/abs/2510.27446)
*Daniel Plummer,Pontus Svensson,Wiktor Jasniak,Patrick Hollebon,Sam M. Vinko,Gianluca Gregori*

Main category: physics.plasm-ph

TL;DR: Developed wave packet molecular dynamics framework for dense plasmas using hydrogen as test case, with chemical model including bound state wavefunctions and self-consistent charge state distributions via free energy minimization.


<details>
  <summary>Details</summary>
Motivation: To model structural properties of partially-ionized dense plasmas and evaluate the ability to capture complex interplay between ionization and structure in dense plasma environments.

Method: Wave packet molecular dynamics framework based on chemical model with bound state wavefunctions, using hydrogen as representative system with self-consistent charge state distributions through free energy minimization.

Result: Enables direct comparison of static equilibrium properties with path integral Monte Carlo data.

Conclusion: The framework facilitates evaluation of model's underlying approximations and its capability to capture ionization-structure interplay in dense plasmas.

Abstract: We develop a wave packet molecular dynamics framework for modeling the
structural properties of partially-ionized dense plasmas, based on a chemical
model that explicitly includes bound state wavefunctions. Using hydrogen as a
representative system, we compute self-consistent charge state distributions
through free energy minimization, following the approach of Plummer et al.
[Phys. Rev. E 111, 015204 (2025)]. This enables a direct comparison of static
equilibrium properties with path integral Monte Carlo data, facilitating an
evaluation of the model's underlying approximations and its ability to capture
the complex interplay between ionization and structure in dense plasma
environments.

</details>


### [44] [Fast and accurate calculation of the bootstrap current and radial neoclassical transport in low collisionality stellarator plasmas](https://arxiv.org/abs/2510.27513)
*Francisco Javier Escoto López*

Main category: physics.plasm-ph

TL;DR: A fast and accurate method for solving the monoenergetic drift-kinetic equation at low collisionality using Legendre polynomials and block tridiagonal algorithms, implemented in the new neoclassical code MONKES for stellarator optimization.


<details>
  <summary>Details</summary>
Motivation: To address the need for fast and accurate calculations of bootstrap current for stellarators, particularly for stellarator optimization, where existing methods were insufficiently efficient.

Method: Uses Legendre polynomial basis functions to represent pitch-angle dependence, exploiting the tridiagonal structure of the drift-kinetic equation and applying standard block tridiagonal algorithms for efficient solution.

Result: Developed MONKES code that computes monoenergetic coefficients at low collisionality in approximately one minute on a single core, with demonstrated accuracy through convergence studies and benchmarks with other codes.

Conclusion: MONKES is sufficiently fast and accurate for integration into stellarator optimization codes and predictive transport suites, enabling direct optimization of bootstrap current and radial neoclassical transport.

Abstract: In this PhD thesis, a method for solving fast and accurately the
monoenergetic drift-kinetic equation at low collisionality is presented. The
algorithm is based on the analytical properties of the drift-kinetic equation
when its dependence on the pitch-angle cosine is represented employing Legendre
polynomials as basis functions. The Legendre representation of the
monoenergetic drift-kinetic equation possesses a tridiagonal structure, which
is exploited by the algorithm presented. The monoenergetic drift-kinetic
equation can be solved fast and accurately at low collisionality by employing
the standard block tridiagonal algorithm for block tridiagonal matrices. The
implementation of the aforementioned algorithm leads to the main result of this
thesis: the new neoclassical code MONKES (MONoenergetic Kinetic Equation
Solver), conceived to satisfy the necessity of fast and accurate calculations
of the bootstrap current for stellarators and in particular for stellarator
optimization. MONKES is a new neoclassical code for the evaluation of
monoenergetic transport coefficients in stellarators. By means of a convergence
study and benchmarks with other codes, it is shown that MONKES is accurate and
efficient. The combination of spectral discretization in spatial and velocity
coordinates with block sparsity allows MONKES to compute monoenergetic
coefficients at low collisionality, in a single core, in approximately one
minute. MONKES is sufficiently fast to be integrated into stellarator
optimization codes for direct optimization of the bootstrap current (and radial
neoclassical transport) and to be included in predictive transport suites.

</details>


### [45] [The Rayleigh-Taylor instability with foams](https://arxiv.org/abs/2510.27518)
*Antoine Bret,Audrey DeVault,Skylar Dannhoff,Maria Gatu Johnson,Chikang Li,Johan Frenje*

Main category: physics.plasm-ph

TL;DR: Analysis of Rayleigh-Taylor instability in foam materials, showing stabilization in elastic phase and growth rate dependence on foam microstructure.


<details>
  <summary>Details</summary>
Motivation: Study RTI behavior in foams relevant to inertial confinement fusion scenarios where foams are used in capsules or hohlraum walls.

Method: Analytical computation of growth rates in elastic and plastic phases using linear analysis, considering foam microstructure.

Result: RTI can be stabilized in elastic phase for some wavelengths; homogeneous foam model overestimates growth by ignoring elasticity.

Conclusion: Elastic nature of foams can stabilize RTI, with findings applicable beyond ICF to various scientific fields.

Abstract: We analyse the behaviour of the Rayleigh-Taylor instability (RTI) in the
presence of a foam. Such a problem may be relevant, for example, to some
inertial confinement fusion (ICF) scenarios such as foams within the capsule or
lining the inner hohlraum wall. The foam displays 3 different phases: by order
of increasing stress, it is first elastic, then plastic, and then fractures.
Only the elastic and plastic phases can be subject to a linear analysis of the
instability. The growth rate is analytically computed in these 2 phases, in
terms of the micro-structure of the foam. In the first, elastic, phase, the RTI
can be stabilized for some wavelengths. In this elastic phase, a homogenous
foam model overestimates the growth because it ignores the elastic nature of
the foam. Although this result is derived for a simplified foam model, it is
likely valid for most of them. Besides the ICF context considered here, our
results could be relevant for many fields of science.

</details>


### [46] [Stellarator divertor design by optimizing coils for surfaces with sharp corners](https://arxiv.org/abs/2510.27624)
*Todd Elder,Matt Landremann,Christoper B. Smiet,Robert Davies*

Main category: physics.plasm-ph

TL;DR: Novel approach to optimize modular stellarator coils for sharp X-point divertor topology, achieving LHD-like helical divertor with significantly lower chaos than LHD using optimized modular coils instead of helical coils.


<details>
  <summary>Details</summary>
Motivation: In stellarators, achieving effective divertor configurations is challenging due to 3D magnetic fields leading to chaotic field lines and fuzzy separatrices.

Method: Direct optimization of modular stellarator coils using target plasma surface with sharp corners, minimizing normal magnetic field component. Additional methods include weighted quadrature and manifold optimization.

Result: First LHD-like helical divertor design using optimized modular coils, producing separatrices with significantly lower chaos than LHD. Demonstrated that wide chaotic layer is not intrinsic to helical divertor.

Conclusion: Results outline new strategies for divertor design in stellarators, though achieving edge divertor features simultaneously with internal field qualities like quasisymmetry remains to be accomplished.

Abstract: In stellarators, achieving effective divertor configurations is challenging
due to the three-dimensional nature of the magnetic fields, which often leads
to chaotic field lines and fuzzy separatrices. This work presents a novel
approach to directly optimize modular stellarator coils for a sharp X-point
divertor topology akin to the Large Helical Device's (LHD) helical divertor
using a target plasma surface with sharp corners. By minimizing the normal
magnetic field component on this surface, we target a clean separatrix with
minimal chaos. Notably, this approach demonstrates the first LHD-like helical
divertor design using optimized modular coils instead of helical coils.
Separatrices are produced with significantly lower chaos than in LHD,
demonstrating that a wide chaotic layer is not intrinsic to the helical
divertor. Additional optimization methods are implemented to improve
engineering feasibility of the coils and reduce chaos, including weighted
quadrature and manifold optimization, a method which does not rely on normal
field minimization. The results outline several new strategies for divertor
design in stellarators, though it remains to achieve these edge divertor
features at the same time as internal field qualities like quasisymmetry.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [47] [Phase behaviour and defect structure of soft rods on a sphere](https://arxiv.org/abs/2510.27201)
*Jaydeep Mandal,Hartmut Löwen,Prabal K. Maiti*

Main category: cond-mat.soft

TL;DR: Soft repulsive spherocylinders confined on a sphere's surface exhibit different phases (crystal, smectic, nematic, isotropic) depending on aspect ratio and packing fraction, with topological defects playing a key role in phase transitions.


<details>
  <summary>Details</summary>
Motivation: To understand the phase behavior and topological defect structures of anisotropic particles confined on curved surfaces, which has relevance for Pickering emulsions and epithelial tissue morphogenesis.

Method: Particle-resolved molecular-dynamics simulations of soft repulsive spherocylinders confined on the surface of a sphere.

Result: Crystal, smectic, and isotropic phases exist for all aspect ratios, while nematic phase only emerges above critical aspect ratio (6.0-7.0). Ordered phases exhibit total orientational defect charge of +2, with specific defect patterns: two +1 defects at poles for crystal/smectic, four +1/2 defects along great circle for nematic. Phase transitions occur via defect splitting and movement.

Conclusion: The study reveals how particle shape and confinement geometry govern phase behavior and topological defect structures, with implications for experimental systems like Pickering emulsions and biological tissues.

Abstract: Using particle-resolved molecular-dynamics simulations, we compute the phase
diagram for soft repulsive spherocylinders confined on the surface of a sphere.
While crystal (K), smectic (Sm), and isotropic (I) phases exhibit a stability
region for any aspect ratio of the spherocylinders, a nematic phase emerges
only beyond a critical aspect ratio lying between 6.0 and 7.0. As required by
the topology of the confining sphere, the ordered phases exhibit a total
orientational defect charge of +2. In detail, the crystal and smectic phases
exhibit two +1 defects at the poles, whereas the nematic phase features four
+1/2 defects which are connected along a great circle. For aspect ratios above
the critical value, lowering the packing fraction drives a sequence of
transitions: the crystal melts into a smectic phase, which then transforms into
a nematic through the splitting of the +1 defects into pairs of +1/2 defects
that progressively move apart, thereby increasing their angular separation.
Eventually, at very low densities, orientational fluctuations stabilize an
isotropic phase. Our simulations data can be experimentally verified in
Pickering emulsions and are relevant to understand the morphogenesis in
epithelial tissues.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [48] [Enhancing Mechanical Stimuli in Functionally Graded Bone Scaffolds Through Porosity Gradients: A Finite Element Analysis Study](https://arxiv.org/abs/2510.27367)
*Anson Wen Han Cheong,Vahid Badali,Sean Kiely,Iman Roohani,Yang Jiang,Jianguang Fang,Ali Entezari*

Main category: physics.med-ph

TL;DR: Functionally graded scaffolds with controlled porosity variations can mitigate stress shielding in bone regeneration by improving mechanical stimulus distribution, with greater benefits in stiffer materials like titanium alloy.


<details>
  <summary>Details</summary>
Motivation: To address stress shielding issues in load-bearing bone scaffolds where rigid fixation compromises healing, by investigating how porosity gradients can optimize mechanical environment for tissue regeneration.

Method: Finite element analyses on femoral segmental defect models with bone plate stabilization, comparing multiple porosity gradient strategies against uniform BCC scaffolds using Ti-6Al-4V, bioactive glass, and PLA materials.

Result: Porosity gradients consistently enhanced mean octahedral shear strain, especially in stress-shielded regions near fixation plates. Improvements increased with greater gradient magnitude and resolution, and were more pronounced in stiffer materials like Ti-6Al-4V.

Conclusion: Both porosity profiles and material selection must be tailored to optimize scaffold mechanics for bone regeneration, highlighting the critical interplay between scaffold material properties and architectural design.

Abstract: Achieving an optimal biomechanical environment within bone scaffolds is
critical for promoting tissue regeneration, particularly in load-bearing
anatomical sites where rigid fixation can induce stress shielding and
compromise healing. Functionally graded (FG) scaffolds, which incorporate
controlled variations in porosity or material properties, have attracted
significant attention as a strategy to mitigate stress shielding by promoting
more favourable load transfer. In this study, the effects of porosity gradient
magnitude (i.e., max-to-min ratio of porosity), gradient resolution, scaffold
material properties, and fixation plate rigidity on the distribution of
mechanical stimuli within FG scaffolds were systematically investigated. Finite
element analyses (FEA) were conducted on a femoral segmental defect model
stabilised with a bone plate, and multiple porosity gradient strategies were
compared against a corresponding uniform scaffold composed of body-centred
cubic (BCC) unit cells. Scaffolds composed of titanium alloy (Ti-6Al-4V),
bioactive glass (45S5 Bio-glass), and polylactic acid (PLA) were evaluated to
capture a range of material stiffnesses. Introducing porosity gradients
consistently enhanced the mean octahedral shear strain within the scaffold,
particularly in regions adjacent to the fixation plate affected by stress
shielding. The magnitude of mechanical stimulus improvement increased with both
greater porosity gradient magnitudes and higher gradient resolution. These
improvements were more pronounced in stiffer materials, such as Ti-6Al-4V,
emphasising the critical interplay between scaffold material properties and
architectural design. These findings highlight the importance of tailoring both
porosity profiles and material selection to optimise scaffold mechanics for
bone regeneration.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [49] [Dense Circumstellar Medium around Pulsating Massive Stars Powering Interacting Supernovae](https://arxiv.org/abs/2510.27189)
*Sutirtha Sengupta,Das Sujit,Arkaprabha Sarangi*

Main category: astro-ph.SR

TL;DR: This paper investigates how enhanced mass loss in red supergiant progenitors of core-collapse supernovae affects circumstellar medium formation, using MESA stellar evolution models with pulsation-driven superwinds and shock-induced ejections.


<details>
  <summary>Details</summary>
Motivation: To understand the evolution of red supergiant progenitors (12-20 solar masses) and their enhanced mass loss mechanisms during advanced nuclear burning stages, which create dense circumstellar environments observed in Type II supernovae.

Method: Used time-dependent mass loss from detailed MESA stellar evolution models, incorporating parameterized prescriptions for pulsation-driven superwinds and time-averaged mass loss rates from shock-induced ejections to construct circumstellar medium profiles before supernova explosions.

Result: Models produce enhanced mass loss episodes of 10^-4 to 10^-2 solar masses per year in the final centuries to decades before explosion, forming dense circumstellar medium (>10^-15 g/cm^3 at distances <10^15 cm) consistent with observations of Type II supernovae like SN 2023ixf and SN 2020ywx.

Conclusion: Pulsation-driven instabilities and subsequent dynamical ejections in red supergiant progenitors can create dense circumstellar environments that match observational constraints from Type II supernovae, providing a physical mechanism for the enhanced mass loss observed in these systems.

Abstract: We investigate the evolution of red supergiant (RSG) progenitors of
core-collapse (CC) supernovae (SNe) with initial masses between $12-20~M_\odot$
focusing on the effects of enhanced mass loss due to pulsation-driven
instabilities in their envelopes and subsequent dynamical ejections during
advanced stages of nuclear burning. Using time-dependent mass loss from
detailed MESA stellar evolution models, including a parameterized prescription
for pulsation-driven superwinds and time-averaged mass loss rates attributed to
resulting shock-induced ejections, we construct the circumstellar medium (CSM)
before the SN explosion. We calculate resulting CSM density profiles and column
densities considering the acceleration of the stellar wind. Our models produce
episodes of enhanced mass loss $10^{-4}-10^{-2}~M_\odot~\rm{yr}^{-1}$ in the
last centuries-decades before explosion forming dense CSM
($>10^{-15}~\rm{gcm}^{-3}$ at distances $<10^{15}$ cm) -- consistent with those
inferred from multi-wavelength observations of Type II SNe such as SN~2023ixf
and SN~2020ywx.

</details>


### [50] [Two-Stage Nature of a Solar Flare with Parallel and Semi-Circular Ribbons](https://arxiv.org/abs/2510.27162)
*Ruifei Huang,Hao Ning,Ze Zhong,Ye Qiu,Zhenyong Hou,Yang Su,Chuan Li,Xiangliang Kong,Yao Chen*

Main category: astro-ph.SR

TL;DR: Analysis of an M8.2-class solar flare showing simultaneous quasi-parallel and semi-circular ribbons, revealing two distinct reconnection processes: standard flare reconnection for parallel ribbons and quasi-separatrix layer reconnection for circular ribbons.


<details>
  <summary>Details</summary>
Motivation: To understand the rare simultaneous occurrence of parallel and circular flare ribbons in a single event, and investigate the different magnetic reconnection mechanisms responsible for each morphology.

Method: Used multi-wavelength observations from multiple instruments, potential field extrapolation to reconstruct magnetic structures, and analyzed hard X-ray light curves and ribbon evolution timing.

Result: Identified two distinct brightening episodes in quasi-parallel ribbons corresponding to HXR peaks, while semi-circular ribbons brightened during the HXR minimum. Found an incomplete dome-like magnetic structure with two sets of field lines having different connectivities.

Conclusion: Standard flare reconnection causes parallel ribbon brightening, while quasi-separatrix layer reconnection (triggered by eruptive structure-dome interaction) causes circular ribbon brightening and temporarily suppresses standard reconnection, delaying the second HXR peak.

Abstract: Flare ribbons with parallel and circular morphologies are typically
associated with different magnetic reconnection models, and the simultaneous
observation of both types in a single event remains rare. Using
multi-wavelength observations from a tandem of instruments, we present an
M8.2-class flare that occurred on 2023 September 20, which produced
quasi-parallel and semi-circular ribbons. The complex evolution of the flare
includes two distinct brightening episodes in the quasi-parallel ribbons,
corresponding to the two major peaks in the hard X-ray (HXR) light curve. In
contrast, the brightening of semi-circular ribbons temporally coincides with
the local minimum between the two peaks. Using potential field extrapolation,
we reconstruct an incomplete dome-like magnetic structure with a negative
polarity embedded within the northwestern part of the semi-circular positive
polarity. Consequently, the magnetic configuration comprises two sets of field
lines with distinct magnetic connectivities. We suggest that the standard flare
reconnection accounts for the two-stage brightening of quasi-parallel ribbons
associated with the two HXR peaks. Between the two stages, this process is
constrained by the interaction of eruptive structures with the dome. The
interaction drives the quasi-separatrix layer reconnection, leading to the
brightening of semi-circular ribbons. It also suppresses the standard flare
reconnection, resulting in a delayed second HXR peak.

</details>


<div id='physics.acc-ph'></div>

# physics.acc-ph [[Back]](#toc)

### [51] [Plasma Processing Of SRF Cavities at Jefferson Lab: Experiment Results and Simulation Insight](https://arxiv.org/abs/2510.27548)
*I. H. Senevirathne,T. Powers,N. Raut*

Main category: physics.acc-ph

TL;DR: Experimental study of plasma processing for SRF cavities using argon-oxygen and helium-oxygen gas mixtures to optimize ignition parameters and reduce field emission.


<details>
  <summary>Details</summary>
Motivation: To enhance SRF cavity performance by removing hydrocarbon contaminants and reducing field emission through plasma processing.

Method: Used argon-oxygen and helium-oxygen gas mixtures to study minimum ignition power at different pressures, combined with COMSOL simulations for C75 and C100 cavity models.

Result: Experimental data collected from plasma ignition studies and simulation results obtained for optimizing key parameters like gas type, RF power, and pressure.

Conclusion: Plasma processing combined with simulations provides effective optimization of SRF cavity performance parameters.

Abstract: Plasma processing of superconducting radio frequency (SRF) cavities has been
an active research effort at Jefferson Lab (JLab) since 2019, aimed at
enhancing cavity performance by removing hydrocarbon contaminants and reducing
field emission. In this experiment, processing using argon-oxygen and
helium-oxygen gas mixtures to find minimum ignition power at different cavity
pressure was investigated. Ongoing simulations are contributing to a better
understanding of the plasma surface interactions and the fundamental physics
behind the process. These simulations, combined with experimental studies,
guide the optimization of key parameters such as gas type, RF power, and
pressure to ignite plasma using selected higher-order mode (HOM) frequencies.
This paper presents experimental data from argon-oxygen and helium-oxygen gas
mixture C75 and C100 cavity plasma ignition studies, as well as simulation
results for the C100-type cavity based on the COMSOL model previously applied
to the C75 cavity.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [52] [A fragile zero-watermarking method based on dual quaternion matrix decomposition](https://arxiv.org/abs/2510.27307)
*Mingcui Zhang,Zhigang Jia*

Main category: eess.IV

TL;DR: Proposes a fragile zero-watermarking model using dual quaternion matrix decomposition for medical image copyright protection and tampering detection without modifying original images.


<details>
  <summary>Details</summary>
Motivation: Medical images face serious risks of copyright infringement and content tampering during transmission and sharing, requiring effective protection methods that preserve image integrity.

Method: Uses dual quaternion matrix decomposition to correlate original carrier images with watermark images through operational relationships between standard and dual parts of dual quaternions, generating zero-watermarking information.

Result: Achieves copyright protection and content tampering detection for medical images through the proposed fragile zero-watermarking approach.

Conclusion: The dual quaternion matrix decomposition-based zero-watermarking model provides an effective solution for protecting medical images against copyright issues and tampering while maintaining original image quality.

Abstract: Medical images play a crucial role in assisting diagnosis, remote
consultation, and academic research. However, during the transmission and
sharing process, they face serious risks of copyright ownership and content
tampering. Therefore, protecting medical images is of great importance. As an
effective means of image copyright protection, zero-watermarking technology
focuses on constructing watermarks without modifying the original carrier by
extracting its stable features, which provides an ideal approach for protecting
medical images. This paper aims to propose a fragile zero-watermarking model
based on dual quaternion matrix decomposition, which utilizes the operational
relationship between the standard part and the dual part of dual quaternions to
correlate the original carrier image with the watermark image, and generates
zero-watermarking information based on the characteristics of dual quaternion
matrix decomposition, ultimately achieving copyright protection and content
tampering detection for medical images.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [53] [Path-integral Monte Carlo estimator for the dipole polarizability of quantum plasma](https://arxiv.org/abs/2510.26836)
*Juha Tiihonen,David Trejo-Garcia,Tapio T. Rantala,Marco Ornigotti*

Main category: cond-mat.mes-hall

TL;DR: A path-integral Monte Carlo method for calculating dipole polarizability in Coulomb plasma using real-space dipole autocorrelation function, validated against Drude model.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient estimator for optical region polarizability that works with long wavelengths and small cell sizes, overcoming limitations of conventional reciprocal space methods.

Method: Path-integral Monte Carlo simulation in imaginary time with exact Coulomb interactions and Boltzmann quantum statistics, using real-space dipole autocorrelation function.

Result: Perfect agreement with analytically continued Drude model within finite temperature and density ranges, with modest finite time-step and finite-size effects.

Conclusion: The validated method is suitable for extension to higher-order optical response, quantum confinements, plasmonics, and nonlinear optics applications.

Abstract: We present a path-integral Monte Carlo estimator for calculating the dipole
polarizability of interacting Coulomb plasma in the long-wavelength limit,
i.e., the optical region. Unlike the conventional dynamic structure factor in
reciprocal space, our approach is based on the real-space dipole
autocorrelation function and is suited for long wavelengths and small cell
sizes, including finite clusters. The simulation of thermal equilibrium in
imaginary time has exact Coulomb interactions and Boltzmann quantum statistics.
For reference, we demonstrate analytic continuation of the Drude model into the
imaginary time and Matsubara series, showing perfect agreement with our data
within ranges of finite temperatures and densities. Method parameters, such as
the finite time-step and finite-size effects prove only modestly significant.
Our method, here carefully validated against an exactly solvable reference,
remains amenable to more interesting domains in higher-order optical response,
quantum confinements and quantum statistical effects, and applications in
plasmonics, heterogeneous plasmas and nonlinear optics, such as
epsilon-near-zero materials.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [54] [First-Principles Study of Transition Metal Doped in 2D Polyaramid for Novel Material Modelling](https://arxiv.org/abs/2510.27578)
*Ravi Trivedi,Chaithanya Purushottam Bhat,Shakti S. Ray,Debashis Bandyopadhyay*

Main category: cond-mat.mtrl-sci

TL;DR: DFT study shows transition metal-doped 2D polyaramid has stable mechanical properties, tunable electronic band gaps, and ferromagnetic ordering with varying magnetic moments, making it promising for spintronics.


<details>
  <summary>Details</summary>
Motivation: To explore the structural, electronic, and magnetic properties of transition metal-functionalized 2D polyaramid for potential spintronic applications.

Method: First-principles density functional theory (DFT) calculations analyzing mechanical parameters (bulk modulus, shear modulus, Young's modulus, Poisson's ratio, Pugh ratio), phonon dispersion, formation energies, electronic structure, and magnetic properties.

Result: All doped systems are mechanically and dynamically stable. Strong binding of Co, Cr, Fe, Ni, and Ti (formation energies -1.15 to -2.96 eV), weaker Mn binding (-0.67 eV). TM doping reduces band gaps, with Fe-doped system showing lowest gap of 0.26 eV. Predominantly ferromagnetic ordering with magnetic moments: Co (1.14 μB), Cr (3.57 μB), Fe (2.26 μB), Mn (4.19 μB), Ti (1.62 μB).

Conclusion: TM-doped 2D polyaramid exhibits tunable magnetic and electronic properties, demonstrating strong potential for spintronic device applications.

Abstract: We present a first--principles density functional theory (DFT) study of
transition metal (TM = Ti, Cr, Mn, Fe, Co, Ni) functionalized two--dimensional
polyaramid (2DPA) to explore their structural, electronic, and magnetic
properties. Mechanical parameters, such as bulk modulus, shear modulus, Young's
modulus, Poisson's ratio, and Pugh ratio, together with phonon dispersion,
confirm the mechanical and dynamic stability of all doped systems. Electronic
structure analysis shows strong binding of Co, Cr, Fe, Ni, and Ti with
formation energies between --1.15 eV and --2.96 eV, while Mn binds more weakly
(--0.67 eV). TM doping introduces new electronic states that reduce the band
gap, with Fe-doped 2DPA exhibiting the lowest value of 0.26 eV. The systems
display predominantly ferromagnetic ordering, with magnetic moments of 1.14
{\mu}B (Co), 3.57 {\mu}B (Cr), 2.26 {\mu}B (Fe), 4.19 {\mu}B (Mn), and 1.62
{\mu}B (Ti). These results demonstrate that TM--doped 2DPA possesses tunable
magnetic and electronic characteristics, highlighting its potential for
spintronic applications.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [55] [Bayesian Optimization on Networks](https://arxiv.org/abs/2510.27643)
*Wenwen Li,Daniel Sanz-Alonso,Ruiyi Yang*

Main category: stat.ML

TL;DR: This paper develops Bayesian optimization algorithms for optimizing functions on metric graphs using Whittle-Matérn Gaussian process priors defined via SPDEs, with applications to expensive black-box functions and Bayesian inversion.


<details>
  <summary>Details</summary>
Motivation: Motivated by applications where objective functions are expensive to evaluate or only available as black boxes, the authors aim to develop optimization methods tailored to network geometries.

Method: Develop Bayesian optimization algorithms that sequentially update Gaussian process surrogate models using Whittle-Matérn Gaussian process priors defined via stochastic partial differential equations on metric graphs, with finite element representation.

Result: Established regret bounds for optimizing smooth objective functions and demonstrated effectiveness through numerical experiments on synthetic metric graphs and telecommunication networks for Bayesian inversion via MAP estimation.

Conclusion: The proposed Bayesian optimization framework with Whittle-Matérn Gaussian process priors is effective for optimizing functions on metric graphs, particularly for expensive black-box functions and Bayesian inference problems.

Abstract: This paper studies optimization on networks modeled as metric graphs.
Motivated by applications where the objective function is expensive to evaluate
or only available as a black box, we develop Bayesian optimization algorithms
that sequentially update a Gaussian process surrogate model of the objective to
guide the acquisition of query points. To ensure that the surrogates are
tailored to the network's geometry, we adopt Whittle-Mat\'ern Gaussian process
prior models defined via stochastic partial differential equations on metric
graphs. In addition to establishing regret bounds for optimizing sufficiently
smooth objective functions, we analyze the practical case in which the
smoothness of the objective is unknown and the Whittle-Mat\'ern prior is
represented using finite elements. Numerical results demonstrate the
effectiveness of our algorithms for optimizing benchmark objective functions on
a synthetic metric graph and for Bayesian inversion via maximum a posteriori
estimation on a telecommunication network.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [56] [Enhancing Neural Network Backflow](https://arxiv.org/abs/2510.26906)
*Kieran Loehr,Bryan K. Clark*

Main category: cond-mat.str-el

TL;DR: Neural Network Backflow (NNBF) improvements saturate with network size, but multi-determinant expansions via Lanczos steps and symmetry projection achieve state-of-the-art variational energies for Hubbard models.


<details>
  <summary>Details</summary>
Motivation: To accurately describe ground states of strongly correlated systems and overcome limitations of NNBF where practical gains saturate with network size.

Method: Use multi-determinant ansatz with single-step Lanczos and symmetry projection techniques, optimizing projected symmetrized states directly without increasing variational parameters.

Result: Achieved lowest variational energies for 4×16 and 4×8 Hubbard lattices, with Lanczos step, diffusion Monte Carlo, and symmetry projection giving similar improvements. Optimized projected states yielded significant energy gains.

Conclusion: Multi-determinant expansions via symmetry projection and Lanczos steps provide efficient path to state-of-the-art variational energies for strongly correlated systems, outperforming NNBF alone.

Abstract: Accurately describing the ground state of strongly correlated systems is
essential for understanding their emergent properties. Neural Network Backflow
(NNBF) is a powerful variational ansatz that enhances mean-field wave functions
by introducing configuration-dependent modifications to single-particle
orbitals. Although NNBF is theoretically universal in the limit of large
networks, we find that practical gains saturate with increasing network size.
Instead, significant improvements can be achieved by using a multi-determinant
ansatz. We explore efficient ways to generate these multi-determinant
expansions without increasing the number of variational parameters. In
particular, we study single-step Lanczos and symmetry projection techniques,
benchmarking their performance against diffusion Monte Carlo and NNBF applied
to alternative mean fields. Benchmarking on a doped periodic square Hubbard
model near optimal doping, we find that a Lanczos step, diffusion Monte Carlo,
and projection onto a symmetry sector all give similar improvements achieving
state-of-the-art energies at minimal cost. By further optimizing the projected
symmetrized states directly, we gain significantly in energy. Using this
technique we report the lowest variational energies for this Hamiltonian on
$4\times 16$ and $4 \times 8$ lattices as well as accurate variance
extrapolated energies. We also show the evolution of spin, charge, and pair
correlation functions as the quality of the variational ansatz improves.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [57] [Learning Sparse Approximate Inverse Preconditioners for Conjugate Gradient Solvers on GPUs](https://arxiv.org/abs/2510.27517)
*Zherui Yang,Zhehao Li,Kangbo Lyu,Yixuan Li,Tao Du,Ligang Liu*

Main category: cs.LG

TL;DR: A learning-based method using GNNs to construct Sparse Approximate Inverse (SPAI) preconditioners for conjugate gradient solvers, avoiding triangular solves and enabling GPU parallelization while improving convergence.


<details>
  <summary>Details</summary>
Motivation: Traditional preconditioners have theoretical guarantees but limited data optimization. Existing learning-based methods using GNNs face challenges with triangular solves that hinder GPU parallelization and create long-range dependencies hard for GNNs to model.

Method: Use Graph Neural Networks to construct Sparse Approximate Inverse (SPAI) preconditioners that avoid triangular solves, require only two matrix-vector products per CG step, and employ a statistics-based scale-invariant loss function matching CG's condition number dependency.

Result: Outperforms standard preconditioners (Diagonal, IC, traditional SPAI) and previous learning-based methods on GPUs, reducing solution time by 40%-53% (68%-113% faster) with better condition numbers and superior generalization on three PDE-derived datasets and one synthetic dataset.

Conclusion: The proposed GNN-based SPAI preconditioner effectively addresses GPU parallelization challenges, eliminates triangular solve bottlenecks, and demonstrates significant performance improvements over traditional and existing learning-based preconditioners.

Abstract: The conjugate gradient solver (CG) is a prevalent method for solving
symmetric and positive definite linear systems Ax=b, where effective
preconditioners are crucial for fast convergence. Traditional preconditioners
rely on prescribed algorithms to offer rigorous theoretical guarantees, while
limiting their ability to exploit optimization from data. Existing
learning-based methods often utilize Graph Neural Networks (GNNs) to improve
the performance and speed up the construction. However, their reliance on
incomplete factorization leads to significant challenges: the associated
triangular solve hinders GPU parallelization in practice, and introduces
long-range dependencies which are difficult for GNNs to model. To address these
issues, we propose a learning-based method to generate GPU-friendly
preconditioners, particularly using GNNs to construct Sparse Approximate
Inverse (SPAI) preconditioners, which avoids triangular solves and requires
only two matrix-vector products at each CG step. The locality of matrix-vector
product is compatible with the local propagation mechanism of GNNs. The
flexibility of GNNs also allows our approach to be applied in a wide range of
scenarios. Furthermore, we introduce a statistics-based scale-invariant loss
function. Its design matches CG's property that the convergence rate depends on
the condition number, rather than the absolute scale of A, leading to improved
performance of the learned preconditioner. Evaluations on three PDE-derived
datasets and one synthetic dataset demonstrate that our method outperforms
standard preconditioners (Diagonal, IC, and traditional SPAI) and previous
learning-based preconditioners on GPUs. We reduce solution time on GPUs by
40%-53% (68%-113% faster), along with better condition numbers and superior
generalization performance. Source code available at
https://github.com/Adversarr/LearningSparsePreconditioner4GPU

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [58] [Sharp Spectral Gap Estimates on Manifolds under Integral Ricci Curvature Bounds](https://arxiv.org/abs/2510.27083)
*Xavier Ramos Olivé,Shoo Seto,Malik Tuerkoen*

Main category: math.DG

TL;DR: Sharp spectral gap estimates on compact manifolds with integral curvature bounds, generalizing previous results and confirming a conjecture for dimensions n≥3.


<details>
  <summary>Details</summary>
Motivation: To extend spectral gap estimates from pointwise curvature bounds to integral curvature bounds, addressing limitations in previous work and confirming a recent conjecture.

Method: Generalization of Kröger's and Bakry-Qian's approaches to handle integral curvature conditions rather than pointwise bounds.

Result: Proved sharp spectral gap estimates under integral curvature assumptions, confirming the Ramos et al. conjecture for dimensions n≥3.

Conclusion: The work successfully extends spectral gap theory to integral curvature settings and resolves an important conjecture in geometric analysis.

Abstract: We prove sharp spectral gap estimates on compact manifolds with integral
curvature bounds. We generalize the results of Kr\"oger (Kr\"oger '92) as well
as of Bakry and Qian (Bakry-Qian '00) to the case of integral curvature and
confirm the conjecture in (Ramos et al. '20) for the case $n \geq 3$.

</details>


### [59] [Lens rigidity in 2D: The reconstruction of a Riemann surface from its geodesic lengths](https://arxiv.org/abs/2510.27085)
*Spyros Alexakis,Matti Lassas*

Main category: math.DG

TL;DR: The paper proves boundary rigidity for 2D Riemannian manifolds with boundary, showing that the manifold is uniquely determined by distances between boundary points, confirming Uhlmann's conjecture.


<details>
  <summary>Details</summary>
Motivation: To determine if a Riemannian manifold can be uniquely reconstructed from boundary distance measurements, which relates to reconstructing sound speed from travel time measurements in geophysics.

Method: Treats the nonlinear rigidity problem directly by recasting lens data as generalized Riemannian circles and proving rigidity via novel energy-type estimates for hyperbolic equations.

Result: Proves three main results: local rigidity near convex boundaries, global rigidity for convex boundaries without trapping, and optimal reconstruction for convex boundaries even with trapping (rigidity up to outermost trapped geodesics).

Conclusion: Extends classical work on rigidity of simple 2-manifolds and provides essentially optimal results on boundary and lens rigidity, confirming Uhlmann's conjecture.

Abstract: We address the question of whether a Riemannian manifold-with-boundary (M,g)
in dimension two is uniquely determined from knowledge of the distances between
points on its boundary. An affirmative answer is called boundary rigidity for
(M,g); it is closely related to lens rigidity. The latter question originates
in the problem of reconstructing the speed of sound in an unknown medium from
measurements of the travel time of sound waves that are sent in and ultimately
return to the boundary. We prove essentially optimal results on these rigidity
questions:
  Our first result answers proves rigidity locally, near a convex portion of
the boundary. Our second result proves rigidity globally, for manifolds with
convex boundary, in the absence of trapping (closed geodesics), thus confirming
a conjecture of Uhlmann. Our final result proves the optimal reconstruction for
convex boundaries even in the presence of trapping, showing rigidity up to
outermost trapped geodesics.
  Our results thus extend the classical work of Pestov and Uhlmann on rigidity
of simple 2-manifolds, as well as the many prior results on injectivity of the
X-ray transform, which address linearized versions of the rigidity problem.
\par Our method is to treat the (non-linear) rigidity problem directly, where
we simultaneously re-cast the lens data as generalized Riemannian circles, and
obtain rigidity for these ``pseudo-circles'', by studying a system of equations
that we show these objects must satisfy. The rigidity we obtain ultimately is
proven via {novel} estimates that are reminiscent of energy-type estimates for
hyperbolic equations.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [60] [Boundary Layer Transition as Succession of Temporal and Spatial Symmetry Breaking](https://arxiv.org/abs/2510.27046)
*Cong Lin,Oliver T. Schmidt*

Main category: physics.flu-dyn

TL;DR: K-type transition involves organized hydrodynamic structures, not stochastic fluctuations, with symmetry breaking events driving laminar-turbulent transition through coherent modes.


<details>
  <summary>Details</summary>
Motivation: To understand laminar-turbulent transition as organized symmetry breaking events rather than stochastic processes, revealing the deterministic progression from harmonic flow to turbulence.

Method: Analyze symmetry-decomposed spectral and space-time proper orthogonal modes to identify coherent structures and track the progression from deterministic to broadband dynamics in K-type transition.

Result: Identified distinct regimes: before skin-friction maximum, flow is periodic and symmetric; after, new quasi-periodic/aperiodic structures emerge, followed by anti-symmetric structures marking onset of aperiodicity and asymmetry.

Conclusion: Laminar-turbulent transition is a sequence of symmetry breaking events driven by energetically dominant space-time coherent modes that gradually transform harmonic flow into broadband turbulence.

Abstract: We show that both temporal and spatial symmetry breaking in canonical K-type
transition arise as organized hydrodynamic structures rather than stochastic
fluctuations. Before the skin-friction maximum, the flow is fully described by
a periodic, spanwise symmetric, harmonic response to the Tollmien-Schlichting
wave, forming a spatially compact coherent structure that produces hairpin
packets. This fundamental harmonic response may visually resemble turbulence,
but remains fully periodic and delimits the exact extent of the deterministic
regime. A distinct regime change occurs after this point; a hierarchy of new
(quasi-)periodic and aperiodic space-time structures emerges, followed shortly
by anti-symmetric structures that develop similarly despite no anti-symmetric
inputs, marking the onset of aperiodicity and spanwise asymmetry. We identify
these structures as symmetry-decomposed spectral and space-time proper
orthogonal modes that resolve the full progression from deterministic to
broadband dynamics. The key insight is that laminar-turbulent transition can be
viewed as a sequence of symmetry breaking events, each driven by energetically
dominant, space-time coherent modes that gradually turn an initially harmonic
flow into broadband turbulence.

</details>


### [61] [Influence of the Control Temperature of Park's Two-temperature Model on the Mars Pathfinder Reactive Hypersonic Flow](https://arxiv.org/abs/2510.27490)
*Gibson De Marchi Poltronieri,Farney C. Moreira,João Luiz F. Azevedo*

Main category: physics.flu-dyn

TL;DR: Analysis of Park's two-temperature model weight factors in hypersonic Mars Pathfinder simulations shows negligible impact on shock position and heat flux, but significant effects on temperature distributions in non-equilibrium regions.


<details>
  <summary>Details</summary>
Motivation: To understand the influence of different weight factors in Park's two-temperature model on hypersonic reactive flow simulations of Mars Pathfinder capsule under thermodynamic and chemical non-equilibrium conditions.

Method: Used 8-species chemical model for Mars atmosphere with Park's two-temperature model, solving modified Navier-Stokes equations for reacting gas mixtures. Analyzed Mach number, temperature modes along stagnation streamline near shock wave, and stagnation point convective heat flux.

Result: Varying weight factors caused negligible differences in shock wave position and stagnation point heat flux, but produced variations in maximum temperature mode values in non-equilibrium regions. Results matched experimental data from literature.

Conclusion: Park's two-temperature model weight factors substantially affect temperature mode distributions in flow non-equilibrium regions, though they have minimal impact on shock position and heat flux.

Abstract: Numerical simulations of reactive hypersonic flow under thermodynamic and
chemical non-equilibrium conditions are presented for the Mars Pathfinder
capsule. An 8-species chemical model is employed to simulate Mars' atmosphere.
Park's two-temperature model is used to account for the thermal non-equilibrium
phenomena. The present work analyzes the impact of different values of the
weight factors used in Park's model, aiming to broaden the understanding of the
weight factors influence. The code used to simulate the flows solves the
Navier-Stokes equations modified to account for reacting gas mixtures. The
findings are depicted in terms of the Mach number and temperature modes along
the stagnation streamline in a region close to the shock wave. The present
analysis also includes results regarding the stagnation point convective heat
flux. The results indicate that varying the weight factors yields negligible
differences in the shock wave position and stagnation point convective heat
flux. The changes in the weight factors cause variations in the maximum
temperature mode values in the non-equilibrium region. The results presented
are in good agreement with experimental data present in the literature. The
present work indicates that Park's two-temperature model weight factors can
substantially affect the temperature mode distributions in the flow
non-equilibrium region.

</details>


### [62] [Comparing the magnetic Rayleigh-Taylor instability dynamics in two- and three-dimensions](https://arxiv.org/abs/2510.27053)
*Manohar Teja Kalluri,Andrew Hillier*

Main category: physics.flu-dyn

TL;DR: 2D simulations of magnetic Rayleigh-Taylor instability (MRTI) fail to capture true 3D dynamics, showing significant differences in mixing behavior, energy dynamics, and nonlinear growth patterns.


<details>
  <summary>Details</summary>
Motivation: To understand how well 2D simulations represent the true 3D dynamics of magnetic Rayleigh-Taylor instability, given computational constraints often limit studies to 2D.

Method: Direct numerical simulations of non-ideal, incompressible MRTI in both 2D and 3D, systematically varying magnetic field strength from weakly to strongly magnetized regimes.

Result: 3D systems show richer mode interactions, enhanced small-scale mixing, reduced fluid dispersion, greater energy dissipation and anisotropy compared to 2D. 3D nonlinear growth increases monotonically with magnetic field, while 2D shows non-monotonic trend.

Conclusion: 2D MRTI simulations cannot reliably represent 3D mixing, energy dynamics, or nonlinear growth, highlighting the fundamental importance of three-dimensionality in magnetized plasma instabilities.

Abstract: The magnetic Rayleigh-Taylor instability (MRTI) governs plasma mixing and
transport in a wide range of astrophysical and laboratory systems. Owing to
computational constraints, MRTI is often studied using two-dimensional (2D)
simulations, but the extent to which 2D captures the true three-dimensional
(3D) dynamics remains unclear. In this work, we perform direct numerical
simulations of non-ideal, incompressible MRTI in both 2D and 3D, systematically
varying the magnetic field strength from weakly to strongly magnetized regimes.
We find that the 3D system exhibits richer mode interactions due to the
coexistence of interchange, undular, and mixed modes structures that are
inherently absent in 2D. The mixing layer in 3D has enhanced small-scale mixing
and reduced fluid dispersion compared to 2D, which is characterized by
large-scale plumes. Energy diagnostics reveal that the gravitational potential
energy released is higher in 2D, primarily because of inefficient mixing and
significant fluid dispersion. In contrast, 3D systems display greater energy
dissipation and anisotropy, driven by small-scale vortical motions. The
non-linear growth of the instability increases monotonically with magnetic
field strength in 3D but shows a non-monotonic trend in 2D. Despite these broad
differences, the rate of magnetic-to-kinetic energy conversion remains
remarkably similar across dimensions, indicating that 2D simulations can
meaningfully capture reconnection-driven processes but not the full turbulent
evolution. Overall, our results demonstrate that 2D MRTI simulations cannot
reliably represent 3D mixing, energy dynamics, or nonlinear growth,
highlighting the fundamental importance of three-dimensionality in magnetized
plasma instabilities.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [63] [Ionospheric responses over the Antarctic region to Intense Space Weather events: Plasma Convection vs. Auroral Precipitation](https://arxiv.org/abs/2510.27372)
*Sumanjit Chakraborty,Gopi K. Seemala*

Main category: physics.space-ph

TL;DR: This study investigates southern polar ionospheric responses to space weather events, finding that plasma convection has stronger correlation (R~0.88) with TEC enhancements than auroral precipitation (R~0.31) in Antarctica during 2023 geomagnetic storms.


<details>
  <summary>Details</summary>
Motivation: To explore southern polar ionospheric responses to intense space weather events and understand correlations with plasma convection and auroral precipitation in the under-explored Antarctic region.

Method: Analyzed six geomagnetic storms from 2023 using GPS-derived Total Electron Content (TEC) measurements from Antarctic stations, combined with auroral precipitation maps and SuperDARN plasma convection maps.

Result: Strong correlation found between enhanced TEC and plasma convection (R~0.88), while weaker correlation with auroral precipitation (R~0.31), indicating plasma convection is more responsible for TEC enhancements.

Conclusion: Plasma convection plays a more significant role than auroral precipitation in causing ionospheric density enhancements over the Antarctic region during geomagnetic storms.

Abstract: The present investigation is directed at exploring southern polar ionospheric
responses to intense space weather events and their correlations with plasma
convection and auroral precipitation. The main phases of six geomagnetic storms
occurring in the year 2023 (ascending phase of the present solar cycle) are
considered for this study. The ionospheric Total Electron Content (TEC)
measurements derived from GPS receivers covering the Antarctic region are used
for probing the electron density perturbations during these events. Auroral
precipitation maps are shown to illustrate the locations of the GPS stations
relative to particle precipitation. SuperDARN maps are shown to understand the
effects of plasma convection over these locations. Correlation between the
enhanced TEC observations with the auroral precipitation (R $\sim$ 0.31) and
the plasma convection (R $\sim$ 0.88) reveals that the latter is more
responsible for causing significant enhancements in the diurnal maximum values
of TEC over the Antarctic region in comparison to the former. Therefore, this
work shows correlation studies between two physical processes and ionospheric
density enhancements over the under-explored south polar region under strong
levels of geomagnetic activity during 2023.

</details>
