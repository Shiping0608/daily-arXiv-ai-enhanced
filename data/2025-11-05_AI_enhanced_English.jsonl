{"id": "2511.02131", "pdf": "https://arxiv.org/pdf/2511.02131", "abs": "https://arxiv.org/abs/2511.02131", "authors": ["Benjamin Kwanen Tapley"], "title": "Explicit invariant-preserving integration of differential equations using homogeneous projection", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "65L05 (Primary), 65M12 (Secondary)", "G.1.8"], "comment": null, "summary": "We develop a general framework for numerically solving differential equations\nwhile preserving invariants. As in standard projection methods, we project an\narbitrary base integrator onto an invariant-preserving manifold, however, our\nmethod exploits homogeneous symmetries to evaluate the projection exactly and\nin closed form. This yields explicit invariant-preserving integrators for a\nbroad class of nonlinear systems, as well as pseudo-invariant-preserving\nschemes capable of preserving multiple invariants to arbitrarily high\nprecision. The resulting methods are high-order and introduce negligible\ncomputational overhead relative to the base solver. When incorporated into\nadaptive solvers such as Dormand-Prince 8(5,3), they provide error-controlled,\ninvariant-preserving, high-order time-stepping schemes. Numerical experiments\non double-pendulum and Kepler ODEs as well as semidiscretised KdV and\nCamassa-Holm PDEs demonstrate substantial improvements in both accuracy and\nefficiency over standard approaches.", "AI": {"tldr": "A framework for solving differential equations that preserves invariants by projecting base integrators onto invariant-preserving manifolds using homogeneous symmetries, enabling exact closed-form projections.", "motivation": "To develop high-order numerical methods for differential equations that preserve invariants with minimal computational overhead, improving accuracy and efficiency over standard approaches.", "method": "Project arbitrary base integrators onto invariant-preserving manifolds using homogeneous symmetries to evaluate projections exactly and in closed form, yielding explicit invariant-preserving integrators.", "result": "The methods are high-order, introduce negligible computational overhead, and can be incorporated into adaptive solvers like Dormand-Prince 8(5,3) for error-controlled, invariant-preserving time-stepping.", "conclusion": "Numerical experiments on various ODEs and PDEs demonstrate substantial improvements in both accuracy and efficiency compared to standard approaches."}}
{"id": "2511.02153", "pdf": "https://arxiv.org/pdf/2511.02153", "abs": "https://arxiv.org/abs/2511.02153", "authors": ["Eric Zou", "Elle Buser", "Zichao Wendy Di", "Yuanzhe Xi"], "title": "A Joint Variational Framework for Multimodal X-ray Ptychography and Fluorescence Reconstruction", "categories": ["math.NA", "cs.NA", "math.OC"], "comment": "Keywords: inverse problems, x-ray imaging science, ill-posedness,\n  joint reconstruction. This work is sponsored by NSF DMS-2338904", "summary": "Recovering high-resolution structural and compositional information from\ncoherent X-ray measurements involves solving coupled, nonlinear, and ill-posed\ninverse problems. Ptychography reconstructs a complex transmission function\nfrom overlapping diffraction patterns, while X-ray fluorescence provides\nquantitative, element-specific contrast at lower spatial resolution. We\nformulate a joint variational framework that integrates these two modalities\ninto a single nonlinear least-squares problem with shared spatial variables.\nThis formulation enforces cross-modal consistency between structural and\ncompositional estimates, improving conditioning and promoting stable\nconvergence. The resulting optimization couples complementary contrast\nmechanisms (i.e., phase and absorption from ptychography, elemental composition\nfrom fluorescence) within a unified inverse model. Numerical experiments on\nsimulated data demonstrate that the joint reconstruction achieves faster\nconvergence, sharper and more quantitative reconstructions, and lower relative\nerror compared with separate inversions. The proposed approach illustrates how\nmultimodal variational formulations can enhance stability, resolution, and\ninterpretability in computational X-ray imaging.", "AI": {"tldr": "Joint variational framework combining ptychography and X-ray fluorescence for improved multimodal X-ray imaging reconstruction.", "motivation": "To address the ill-posed inverse problems in coherent X-ray measurements by integrating structural (ptychography) and compositional (fluorescence) information for better conditioning and stability.", "method": "Formulated a joint variational framework as a single nonlinear least-squares problem with shared spatial variables, enforcing cross-modal consistency between structural and compositional estimates.", "result": "Numerical experiments showed faster convergence, sharper reconstructions, lower relative error, and more quantitative results compared to separate inversions.", "conclusion": "Multimodal variational formulations enhance stability, resolution, and interpretability in computational X-ray imaging by coupling complementary contrast mechanisms."}}
{"id": "2511.02232", "pdf": "https://arxiv.org/pdf/2511.02232", "abs": "https://arxiv.org/abs/2511.02232", "authors": ["Zhigang Jia", "Meiyue Shao", "Yanjun Shao"], "title": "On Eigenvector Computation and Eigenvalue Reordering for the Non-Hermitian Quaternion Eigenvalue Problem", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper we present several additions to the quaternion QR algorithm,\nincluding algorithms for eigenvector computation and eigenvalue reordering. A\nkey outcome of the eigenvalue reordering algorithm is that the aggressive early\ndeflation (AED) technique, which significantly enhances the convergence of the\nQR algorithm, is successfully applied to the quaternion eigenvalue problem. We\nconduct numerical experiments to demonstrate the efficiency and effectiveness\nof the proposed algorithms.", "AI": {"tldr": "Enhanced quaternion QR algorithm with eigenvector computation, eigenvalue reordering, and aggressive early deflation (AED) techniques.", "motivation": "To improve the convergence and efficiency of the quaternion QR algorithm for solving quaternion eigenvalue problems.", "method": "Developed algorithms for eigenvector computation and eigenvalue reordering, and successfully applied aggressive early deflation (AED) technique to quaternion eigenvalue problems.", "result": "Numerical experiments demonstrate the efficiency and effectiveness of the proposed algorithms.", "conclusion": "The additions significantly enhance the quaternion QR algorithm's performance, particularly through the successful application of AED technique."}}
{"id": "2511.02298", "pdf": "https://arxiv.org/pdf/2511.02298", "abs": "https://arxiv.org/abs/2511.02298", "authors": ["Yunzhuo Guo", "Cheng Wang", "Zhengru Zhang"], "title": "Convergence analysis of positivity-preserving finite difference scheme for the Flory-Huggins-Cahn-Hilliard equation with dynamical boundary condition", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "The Cahn-Hilliard equation has a wide range of applications in many areas of\nphysics and chemistry. To describe the short-range interaction between the\nsolution and the boundary, scientists have constructed dynamical boundary\nconditions by introducing boundary energy. In this work, the dynamical boundary\ncondition is located on two opposite edges of a square domain and is connected\nwith bulk by a normal derivative. A convex-splitting numerical approach is\nproposed to enforce the positivity-preservation and energy dissipation,\ncombined with the finite difference spatial approximation. The\n$\\ell^\\infty(0,T;H_h^{-1}) \\cap \\ell^2(0,T;H_h^1)$ convergence analysis and\nerror estimate is theoretically established, with the first order accuracy in\ntime and second order accuracy in space. The bulk and surface discrete mass\nconservation of the exact solution is required to reach the mean-zero property\nof the error function, so that the associated discrete $H_h^{-1}$ norm is\nwell-defined. The mass conservation on the physical boundary is maintained by\nthe classic Fourier projection. In terms of the mass conservation in bulk, we\nintroduce a trigonometric auxiliary function based on the truncation error\nexpansion, so that the bulk mass conservation is achieved, and it has no effect\non the boundary. The smoothness of trigonometric function makes the Taylor\nexpansion valid and maintains the convergence order of truncation error as\nwell. As a result, the convergence analysis could be derived with a careful\nnonlinear error estimate.", "AI": {"tldr": "A convex-splitting numerical method for the Cahn-Hilliard equation with dynamical boundary conditions that preserves positivity, energy dissipation, and achieves first-order temporal and second-order spatial accuracy.", "motivation": "To develop a numerical approach for the Cahn-Hilliard equation with dynamical boundary conditions that maintains physical properties like positivity preservation and energy dissipation while ensuring convergence.", "method": "Convex-splitting numerical approach combined with finite difference spatial approximation, using Fourier projection for boundary mass conservation and trigonometric auxiliary function for bulk mass conservation.", "result": "Theoretical establishment of \u2113\u221e(0,T;H_h^{-1}) \u2229 \u2113\u00b2(0,T;H_h\u00b9) convergence analysis with first-order temporal and second-order spatial accuracy, while maintaining mass conservation properties.", "conclusion": "The proposed method successfully achieves convergence with the desired accuracy while preserving key physical properties like positivity, energy dissipation, and mass conservation in both bulk and boundary domains."}}
{"id": "2511.02028", "pdf": "https://arxiv.org/pdf/2511.02028", "abs": "https://arxiv.org/abs/2511.02028", "authors": ["Ritwik Sain", "Lance Labun", "Ou Z. Labun", "Bjorn Manuel Hegelich"], "title": "Unified Model of Heated Plasma Expansion", "categories": ["physics.plasm-ph", "physics.acc-ph", "physics.flu-dyn"], "comment": "25 pages, 10 figures", "summary": "Motivated by the need to predict plasma density and temperature distributions\ncreated in the early stages of high-intensity laser-plasma interactions, we\ndevelop a fluid model of plasma expansion into vacuum that incorporates\nexternal heating. We propose a new three-parameter family of self-similar\nsolutions for plasma expansion that models a wide range of spatiotemporal\nvariations of the electron temperature. Depending on the relative scales of the\nheated plasma domain $L$, the Debye length $\\lambda_D$ and an emergent\nion-acoustic correlation length $\\lambda_s$, characterized by the parameters\n$\\lambda_s/\\lambda_D$ and $L/\\lambda_s$, a spectrum of dynamical behaviors for\nthe expanding plasma are identified. The behavior is classified into five\ndynamical regimes, ranging from nearly quasineutral expansion to the formation\nof bare ion slabs susceptible to Coulomb explosion. The limiting self-similar\nsolutions are analyzed, and the dynamics in the five asymptotic limits in the\nparameter space are detailed. Scaling relations for the length scales and\nenergies of the expanding plasma are proposed. The self-similar framework is\napplied to laser-plasma interactions, specifically addressing the plasma\ndynamics at a target surface during prepulse-target interactions. The results\noffer insights into the expansion behavior based on the laser-plasma\nparameters, and scaling relations for optimizing laser-plasma schemes and\nguiding experimental designs in high-intensity laser experiments.", "AI": {"tldr": "A fluid model for plasma expansion into vacuum with external heating is developed, featuring a three-parameter family of self-similar solutions that classify plasma dynamics into five regimes based on length scale ratios.", "motivation": "To predict plasma density and temperature distributions in early stages of high-intensity laser-plasma interactions, particularly for understanding prepulse-target interactions.", "method": "Developed a fluid model of plasma expansion incorporating external heating, with a new three-parameter family of self-similar solutions modeling electron temperature variations.", "result": "Identified five dynamical regimes based on length scale ratios (\u03bb_s/\u03bb_D and L/\u03bb_s), ranging from quasineutral expansion to Coulomb explosion of bare ion slabs, with detailed analysis of asymptotic limits.", "conclusion": "The self-similar framework provides scaling relations for optimizing laser-plasma schemes and guiding experimental designs in high-intensity laser experiments."}}
{"id": "2511.01901", "pdf": "https://arxiv.org/pdf/2511.01901", "abs": "https://arxiv.org/abs/2511.01901", "authors": ["Denis Sidorov", "Alexander Sinitsyn", "Omar Toledo Leguizam\u00f3n", "Liguo Wang"], "title": "Magnetically Insulated Diode: Existence of Solutions and Complex Bifurcation. I", "categories": ["math.AP", "math-ph", "math.MP", "35Q83 34A12 34C23 45B05 78A35 34E15"], "comment": null, "summary": "In order to avoid the electron oscillation of the cathode and enhance the\nwork efficiency of a vacuum diode, an approach for analyzing the solutions and\ncomplex bifurcation has been proposed and used to determine the optimal\ntrajectory of electron motion of the vacuum diode. This work is focusing on the\nstationary self-consistent problem of magnetic insulation in a\nspace-charge-limited vacuum diode, modeled by a singularly perturbed\n1.5-dimensional Vlasov-Maxwell system. We focus on the insulated regime,\ncharacterized by the reflection of electrons back toward the cathode at a point\n$x^{*}.$ The analysis proceeds in two primary stages. First, the original\nVlasov-Maxwell system is reduced to a nonlinear singular system of ordinary\ndifferential equations governing the electric and magnetic field potentials.\nSubsequently, this system is further reduced to a novel nonlinear singular ODE\nfor an effective potential $\\theta(x).$ The existence of non-negative solutions\nto this final equation is established on the interval $[0, x^{*})$, where\n$\\theta(x)>0$. This is achieved by reformulating the associated initial value\nproblem into a system of coupled nonlinear Fredholm integral equations and\nproving the existence of fixed points for the corresponding operators. The most\nsignificant and previously unexplored case occurs when $\\theta(x)<0$ on the\ninterval $(x^{*}, 1]$, which corresponds to the fully insulated diode. For this\nregime, we present a novel numerical analysis of complex solution bifurcations,\nexamining their dependence on system parameters and boundary conditions.\nBifurcation diagrams illustrating the solution $\\theta(x)$ as a function of the\nfree boundary $x^{*}$ is constructed, and the insulated diode spacing is\ndetermined.", "AI": {"tldr": "Analysis of electron motion in vacuum diodes using Vlasov-Maxwell system to find optimal trajectories and study complex bifurcations in magnetic insulation regimes.", "motivation": "To avoid electron oscillation at the cathode and enhance vacuum diode work efficiency by analyzing electron motion trajectories and magnetic insulation effects.", "method": "Reduces Vlasov-Maxwell system to nonlinear singular ODEs for field potentials, then to effective potential equation. Uses coupled nonlinear Fredholm integral equations and fixed point analysis for existence proofs, plus numerical analysis of complex bifurcations.", "result": "Established existence of non-negative solutions on [0,x*) interval, analyzed previously unexplored \u03b8(x)<0 regime, constructed bifurcation diagrams showing solution dependence on free boundary x*, and determined insulated diode spacing.", "conclusion": "The approach successfully analyzes vacuum diode electron motion, identifies optimal trajectories, and provides comprehensive understanding of complex bifurcations in magnetic insulation regimes, enabling enhanced diode efficiency."}}
{"id": "2511.02699", "pdf": "https://arxiv.org/pdf/2511.02699", "abs": "https://arxiv.org/abs/2511.02699", "authors": ["Daniele Rapetti", "Massimiliano Bonomi", "Carlo Camilloni", "Giovanni Bussi", "Gareth A. Tribello"], "title": "Making PLUMED fly: a tutorial on optimizing performance", "categories": ["physics.comp-ph"], "comment": "45 pages, 15 figures", "summary": "PLUMED is an open-source software package that is widely used for analyzing\nand enhancing molecular dynamics simulations that works in conjunction with\nmost available molecular dynamics softwares. While the computational cost of\nPLUMED calculations is typically negligible compared to the molecular dynamics\ncode's force evaluation, the software is increasingly being employed for more\ncomputationally demanding tasks where performance optimization becomes\ncritical. In this tutorial, we describe a recently implemented tool that can be\nused to reliably measure code performance. We then use this tool to generate\ndetailed performance benchmarks that show how calculations of large-numbers of\ndistances, angles or torsions can be optimized by using vector-based commands\nrather than individual scalar operations. We then present benchmarks that\nillustrate how to optimize calculations of atomic order parameters and\nsecondary structure variables. Throughout the tutorial and in our\nimplementations we endeavor to explain the algorithmic tricks that are being\nused to optimize the calculations so others can make use of these prescriptions\nboth when they are using PLUMED and when they are writing their own codes.", "AI": {"tldr": "A tutorial on optimizing PLUMED performance using vector-based commands and algorithmic tricks for computationally demanding molecular dynamics analysis tasks.", "motivation": "PLUMED is increasingly used for computationally intensive tasks where performance optimization becomes critical, despite typically having negligible computational costs compared to molecular dynamics force evaluation.", "method": "Implemented a performance measurement tool and used it to benchmark optimization strategies, including using vector-based commands instead of individual scalar operations for distance/angle/torsion calculations, and optimizing atomic order parameters and secondary structure variables.", "result": "Generated detailed performance benchmarks showing significant improvements when using vector-based commands for large-number calculations, and provided optimization strategies for various computational tasks.", "conclusion": "The tutorial provides practical prescriptions for performance optimization in PLUMED that can also be applied to custom code development, using algorithmic tricks and vector-based operations to enhance computational efficiency."}}
{"id": "2511.02387", "pdf": "https://arxiv.org/pdf/2511.02387", "abs": "https://arxiv.org/abs/2511.02387", "authors": ["Yuri Nesterenko"], "title": "About subspaces the most deviating from the coordinate ones", "categories": ["math.NA", "cs.NA", "math.CO"], "comment": null, "summary": "Taking the largest principal angle as the distance function between same\ndimensional nontrivial linear subspaces in $\\mathds{R}^n$, we describe the\nclass of subspaces deviating from all the coordinate ones by at least\n$\\arccos(1 / \\sqrt{n})$. This study compliments and is motivated by the\nlong-standing hypothesis put forward in \\cite{GTZ1997} and essentially stating\nthat so-defined distance to the closest coordinate subspace cannot exceed\n$\\arccos(1 / \\sqrt{n})$. In this context, the subspaces presented here claim to\nbe the extremal ones.\n  Realized as the star spaces of all nontrivial 2-connected series-parallel\ngraphs with certain edge weights and arbitrary edge directions, the given\nsubspaces may be of interest beyond numerical linear algebra within which the\noriginal problem was formulated.", "AI": {"tldr": "This paper identifies extremal subspaces in R^n that maximize the distance to coordinate subspaces, achieving the theoretical upper bound of arccos(1/\u221an) proposed in previous work.", "motivation": "The study is motivated by a long-standing hypothesis from GTZ1997 that the distance between any nontrivial linear subspace and the closest coordinate subspace in R^n cannot exceed arccos(1/\u221an). This work aims to find and characterize subspaces that achieve this theoretical maximum.", "method": "The authors describe subspaces that deviate from all coordinate subspaces by exactly arccos(1/\u221an). These subspaces are realized as the star spaces of all nontrivial 2-connected series-parallel graphs with specific edge weights and arbitrary edge directions.", "result": "The paper successfully identifies and characterizes the class of extremal subspaces that achieve the maximum possible distance of arccos(1/\u221an) from all coordinate subspaces, thus proving the existence of subspaces that reach the theoretical upper bound.", "conclusion": "The identified subspaces serve as extremal examples that validate the original hypothesis, and their construction using graph theory suggests potential applications beyond numerical linear algebra, particularly in fields involving series-parallel graphs and their associated spaces."}}
{"id": "2511.02070", "pdf": "https://arxiv.org/pdf/2511.02070", "abs": "https://arxiv.org/abs/2511.02070", "authors": ["Shinsuke Ohshima", "Hiroyuki Okada", "Shinji Kobayashi", "Shinichiro Kado", "Takashi Minami", "Fumiyoshi Kin", "Shigeru Inagaki", "Shigeru Konoshima", "Tohru Mizuuchi", "Kazunobu Nagasaki"], "title": "Integrated Observation of Isotope-Dependent Turbulence, Zonal Flow, and Turbulence-Driven Transport", "categories": ["physics.plasm-ph"], "comment": "4pages, 5 figures, To be submitted to PRL", "summary": "To address the long-standing unresolved issue of \"isotope effect\" in plasma\ntransport, this study investigates the hydrogen/deuterium (H/D) isotope\ndependence of a nonlinear turbulence system. The analysis focuses on the zonal\nflow (ZF) activity, turbulence properties, their nonlinear interaction, and\nresulting turbulent transport in a torus plasma. ZF activity, observed in\nlow-density electron cyclotron heating plasmas in Heliotron J, is enhanced with\nincreasing D gas fraction from 10 to 80 percent. While the turbulence scale\nsize in the edge region (rho approx 0.8) is larger in D plasmas, the reduction\nand decoupling of fluctuations, associated with an enhanced ZF, results in\nbeneficial impacts on turbulent transport, driven by an enhanced nonlinear\ncoupling between the ZF and turbulence in D plasmas. These differences in the\nturbulence nature lead to the significant reduction of turbulence-induced\ntransport observed in the D plasma. These comprehensive observations suggest\nthat the isotope dependence on the turbulence system is essential for\nexplaining the isotope effect on confinement improvement and is vital in\npredicting the performance of future fusion reactors.", "AI": {"tldr": "Study shows deuterium plasmas enhance zonal flow activity and reduce turbulence-induced transport through improved nonlinear coupling between zonal flows and turbulence, explaining the isotope effect in plasma confinement.", "motivation": "To address the unresolved issue of \"isotope effect\" in plasma transport by investigating hydrogen/deuterium isotope dependence in nonlinear turbulence systems.", "method": "Analysis of zonal flow activity, turbulence properties, and their nonlinear interaction in torus plasma using low-density electron cyclotron heating plasmas in Heliotron J with varying D gas fractions (10-80%).", "result": "Deuterium plasmas showed enhanced zonal flow activity, larger turbulence scale size, reduced fluctuations, and significant reduction of turbulence-induced transport due to improved nonlinear coupling between zonal flows and turbulence.", "conclusion": "The isotope dependence on turbulence systems is essential for explaining the isotope effect on confinement improvement and vital for predicting future fusion reactor performance."}}
{"id": "2511.01987", "pdf": "https://arxiv.org/pdf/2511.01987", "abs": "https://arxiv.org/abs/2511.01987", "authors": ["Alessandro Audrito", "Tom\u00e1s Sanz-Perela"], "title": "On the existence of solutions to some singular parabolic free boundary problems", "categories": ["math.AP", "35R35, 35B44, 35K55, 58J35"], "comment": null, "summary": "We construct nonnegative weak solutions to the singular parabolic free\nboundary problem \\[ \\partial_t u - \\Delta u = - \\frac{\\mathrm{d}}{\\mathrm{d} u}\nu_+^\\gamma , \\] where $\\gamma \\in (0,1]$, $u_+ := \\max\\{u,0\\}$, and the term in\nthe right-hand side denotes the formal derivative of the non-smooth function $u\n\\mapsto u_+^\\gamma$. Weak solutions are obtained as limits of a suitable\napproximation procedure. We show uniform optimal regularity, optimal growth and\nnondegeneracy estimates, and a Weiss-type monotonicity formula for solutions to\nthe approximating problem. Such uniform estimates are then passed to limit: we\nprove the existence of a class of weak solutions to the free boundary problem\nwhich is closed under blow-up and whose weak formulation encodes the sharp free\nboundary condition. Finally, we construct several examples of weak solutions\nwith self-similar and traveling wave form.", "AI": {"tldr": "The paper constructs nonnegative weak solutions to a singular parabolic free boundary problem involving a non-smooth nonlinearity, establishes uniform regularity and growth estimates, and provides examples of self-similar and traveling wave solutions.", "motivation": "To study singular parabolic free boundary problems with non-smooth nonlinearities, particularly the case where the right-hand side involves the derivative of u_+^\u03b3 with \u03b3 \u2208 (0,1], which presents analytical challenges due to the singularity and lack of smoothness.", "method": "Use an approximation procedure to construct weak solutions as limits, establish uniform optimal regularity, growth and nondegeneracy estimates, prove a Weiss-type monotonicity formula for approximating problems, and pass these uniform estimates to the limit.", "result": "Existence of a class of weak solutions that is closed under blow-up and encodes the sharp free boundary condition, along with construction of explicit self-similar and traveling wave solutions.", "conclusion": "The developed framework successfully handles the singular parabolic free boundary problem with non-smooth nonlinearity, providing a comprehensive analysis including existence, regularity, and explicit solution constructions."}}
{"id": "2511.01913", "pdf": "https://arxiv.org/pdf/2511.01913", "abs": "https://arxiv.org/abs/2511.01913", "authors": ["Leonardo C\u00e1zares-Trejo", "Marco Loreto-Silva", "Huziel E. Sauceda"], "title": "Delta-learned force fields for nonbonded interactions: Addressing the strength mismatch between covalent-nonbonded interaction for global models", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": "12 pages, 8 figures", "summary": "Noncovalent interactions--vdW dispersion, hydrogen/halogen bonding,\nion-$\\pi$, and $\\pi$-stacking--govern structure, dynamics, and emergent\nphenomena in materials and molecular systems, yet accurately learning them\nalongside covalent forces remains a core challenge for machine-learned force\nfields (MLFFs). This challenge is acute for global models that use\nCoulomb-matrix (CM) descriptors compared under Euclidean/Frobenius metrics in\nmultifragment settings. We show that the mismatch between predominantly\ncovalent force labels and the CM's overrepresentation of intermolecular\nfeatures biases single-model training and degrades force-field fidelity. To\naddress this, we introduce \\textit{$\\Delta$-sGDML}, a scale-aware formulation\nwithin the sGDML framework that explicitly decouples intra- and intermolecular\nphysics by training fragment-specific models alongside a dedicated binding\nmodel, then composing them at inference. Across benzene dimers, host-guest\ncomplexes (C$_{60}$@buckycatcher, NO$_3^-$@i-corona[6]arene), benzene-water,\nand benzene-Na$^+$, \\mbox{$\\Delta$-sGDML} delivers consistent gains over a\nsingle global model, with fragment-resolved force-error reductions up to\n\\textbf{75\\%}, without loss of energy accuracy. Furthermore, molecular-dynamics\nsimulations further confirm that the $\\Delta$-model yields a reliable force\nfield for C$_{60}$@buckycatcher, producing stable trajectories across a wide\nrange of temperatures (10-400~K), unlike the single global model, which loses\nstability above $\\sim$200~K. The method offers a practical route to homogenize\nper-fragment errors and recover reliable noncovalent physics in global MLFFs.", "AI": {"tldr": "\u0394-sGDML is a scale-aware ML force field that decouples intra- and intermolecular physics by training fragment-specific models alongside a binding model, improving force accuracy for noncovalent interactions without sacrificing energy accuracy.", "motivation": "Accurately learning noncovalent interactions (vdW dispersion, hydrogen/halogen bonding, ion-\u03c0, \u03c0-stacking) alongside covalent forces remains challenging for ML force fields, especially with Coulomb-matrix descriptors that overrepresent intermolecular features.", "method": "\u0394-sGDML framework explicitly decouples intra- and intermolecular physics by training fragment-specific models and a dedicated binding model, then composing them at inference time.", "result": "Across benzene dimers, host-guest complexes, benzene-water, and benzene-Na+, \u0394-sGDML achieves up to 75% force-error reduction over single global models while maintaining energy accuracy. MD simulations show stable trajectories across 10-400K temperature range.", "conclusion": "The method provides a practical approach to homogenize per-fragment errors and recover reliable noncovalent physics in global ML force fields, addressing the mismatch between covalent force labels and intermolecular feature representation."}}
{"id": "2511.02552", "pdf": "https://arxiv.org/pdf/2511.02552", "abs": "https://arxiv.org/abs/2511.02552", "authors": ["Marco Mattuschka", "Daniel Walter", "Max von Danwitz", "Alexander Popp"], "title": "Sparse Source Identification in Transient Advection-Diffusion Problems with a Primal-Dual-Active-Point Strategy", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This work presents a mathematical model to enable rapid prediction of\nairborne contaminant transport based on scarce sensor measurements. The method\nis designed for applications in critical infrastructure protection (CIP), such\nas evacuation planning following contaminant release. In such scenarios, timely\nand reliable decision-making is essential, despite limited observation data. To\nidentify contaminant sources, we formulate an inverse problem governed by an\nadvection-diffusion equation. Given the problem's underdetermined nature, we\nfurther employ a variational regularization ansatz and model the unknown\ncontaminant sources as distribution over the spatial domain. To efficiently\nsolve the arising inverse problem, we employ a problem-specific variant of the\nPrimal-Dual-Active-Point (PDAP) algorithm which efficiently approximates sparse\nminimizers of the inverse problem by alternating between greedy location\nupdates and source intensity optimization. The approach is demonstrated on two-\nand three-dimensional test cases involving both instantaneous and continuous\ncontaminant sources and outperforms state-of-the-art techniques with\n$L^2$-regularization. Its effectiveness is further illustrated in complex\ndomains with real-world building geometries imported from OpenStreetMap.", "AI": {"tldr": "Mathematical model for rapid airborne contaminant prediction using sparse sensor data, with applications in critical infrastructure protection and evacuation planning.", "motivation": "Enable timely decision-making in critical infrastructure protection scenarios with limited observation data, particularly for evacuation planning after contaminant release.", "method": "Formulates inverse problem using advection-diffusion equation, employs variational regularization, models contaminant sources as spatial distributions, and uses Primal-Dual-Active-Point algorithm for efficient sparse minimization.", "result": "Outperforms state-of-the-art techniques with L\u00b2-regularization in 2D/3D test cases with instantaneous and continuous sources, effective in complex real-world building geometries from OpenStreetMap.", "conclusion": "The proposed method provides efficient and reliable contaminant source identification and transport prediction for critical infrastructure protection applications."}}
{"id": "2511.02075", "pdf": "https://arxiv.org/pdf/2511.02075", "abs": "https://arxiv.org/abs/2511.02075", "authors": ["Norman M. Cao", "Hongxuan Zhu", "Gabriel C. Grime", "Timothy Stoltzfus-Dueck"], "title": "Detecting Shearless Phase-Space Transport Barriers in Global Gyrokinetic Turbulence Simulations with Test Particle Map Models", "categories": ["physics.plasm-ph"], "comment": null, "summary": "In magnetically confined fusion plasmas, the role played by zonal E$\\times$B\nflow shear layers in the suppression of turbulent transport is relatively\nwell-understood. However, less is understood about the role played by the weak\nshear regions that arise in the non-monotonic radial electric field profiles\noften associated with these shear layers. In electrostatic simulations from the\nglobal total-f gyrokinetic particle-in-cell code XGC, we demonstrate how\nshearless regions with non-zero flow curvature form zonal \"jets\" that, in\nconjunction with neighboring regions of shear, can act as robust barriers to\nparticle transport and turbulence spreading. By isolating quasi-coherent\nfluctuations radially localized to the zonal jets, we construct a map model for\nthe Lagrangian dynamics of gyrokinetic test particles in the presence of drift\nwaves. We identify the presence of shearless invariant tori in this model and\nverify that these tori act as partial phase-space transport barriers in the\nsimulations. We also demonstrate how avalanches impinging on these shearless\ntori cause reconnection events that form \"cold/warm core ring\" structures\nanalogous to those found in oceanic jets, facilitating transport across the\nbarriers without destroying them completely. We discuss how shearless tori may\ngenerically arise from tertiary instabilities or other types of discrete\neigenmodes, suggesting their potential relevance to broader classes of\nturbulent fluctuations.", "AI": {"tldr": "Zonal jets with non-zero flow curvature in fusion plasmas act as robust barriers to particle transport and turbulence spreading, forming shearless invariant tori that create partial phase-space transport barriers.", "motivation": "To understand the role of weak shear regions in non-monotonic radial electric field profiles in fusion plasmas, particularly how these regions affect turbulent transport suppression beyond the well-understood zonal E\u00d7B flow shear layers.", "method": "Used global total-f gyrokinetic particle-in-cell code XGC for electrostatic simulations, isolated quasi-coherent fluctuations to construct a map model for Lagrangian dynamics of gyrokinetic test particles, and identified shearless invariant tori.", "result": "Shearless regions with non-zero flow curvature form zonal jets that act as robust barriers to particle transport and turbulence spreading. Shearless invariant tori were identified as partial phase-space transport barriers, and avalanches cause reconnection events forming 'cold/warm core ring' structures similar to oceanic jets.", "conclusion": "Shearless tori may generically arise from tertiary instabilities or other discrete eigenmodes, suggesting their potential relevance to broader classes of turbulent fluctuations in fusion plasmas."}}
{"id": "2511.02073", "pdf": "https://arxiv.org/pdf/2511.02073", "abs": "https://arxiv.org/abs/2511.02073", "authors": ["Thalia Jeffres", "Xiaolong Li"], "title": "Gradient bounds for viscosity solutions to certain elliptic equations", "categories": ["math.AP", "35J60, 35D40, 35B10, 35B05"], "comment": "13 pages; comments are welcome", "summary": "Our principal object of study is the modulus of continuity of a periodic or\nuniformly vanishing function \\( u: \\mathbb{R} ^{n} \\rightarrow \\mathbb{R} \\)\nwhich satisfies a degenerate elliptic equation \\( F(x, u, \\nabla u, D^{2} u) =\n0 \\) in the viscosity sense. The equations under consideration here have\nsecond-order terms of the form \\( -{\\rm Trace} \\, (\\mathcal{A} (\\|\\nabla u \\|)\n\\cdot D^{2} u) , \\) where \\( \\mathcal{A} \\) is an \\( n\\times n\\) matrix which\nis symmetric and positive semi-definite. Following earlier work, \\cite{Li21},\nof the second author, which addressed the parabolic case, we identify a\none-dimensional equation for which the modulus of continuity is a subsolution.\nIn favorable cases, this one-dimensional operator can be used to derive a\ngradient bound on $u$ or to draw other conclusions about the nature of the\nsolution.", "AI": {"tldr": "Analysis of modulus of continuity for solutions to degenerate elliptic equations with specific second-order structure, extending parabolic case results to derive gradient bounds.", "motivation": "To understand the regularity properties of solutions to degenerate elliptic equations by studying their modulus of continuity, building on previous work in the parabolic case.", "method": "Identify a one-dimensional equation where the modulus of continuity serves as a subsolution, using the specific structure of second-order terms involving symmetric positive semi-definite matrices.", "result": "Successfully derived a method to obtain gradient bounds and other conclusions about solution behavior using the one-dimensional operator approach.", "conclusion": "The modulus of continuity analysis provides an effective tool for studying regularity and gradient bounds in degenerate elliptic equations with the specified structural properties."}}
{"id": "2511.02087", "pdf": "https://arxiv.org/pdf/2511.02087", "abs": "https://arxiv.org/abs/2511.02087", "authors": ["S\u00e9kou-Oumar Kaba", "Kusha Sareen", "Daniel Levy", "Siamak Ravanbakhsh"], "title": "Energy Loss Functions for Physical Systems", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": "10 pages, 4 figures, NeurIPS 2025", "summary": "Effectively leveraging prior knowledge of a system's physics is crucial for\napplications of machine learning to scientific domains. Previous approaches\nmostly focused on incorporating physical insights at the architectural level.\nIn this paper, we propose a framework to leverage physical information directly\ninto the loss function for prediction and generative modeling tasks on systems\nlike molecules and spins. We derive energy loss functions assuming that each\ndata sample is in thermal equilibrium with respect to an approximate energy\nlandscape. By using the reverse KL divergence with a Boltzmann distribution\naround the data, we obtain the loss as an energy difference between the data\nand the model predictions. This perspective also recasts traditional objectives\nlike MSE as energy-based, but with a physically meaningless energy. In\ncontrast, our formulation yields physically grounded loss functions with\ngradients that better align with valid configurations, while being\narchitecture-agnostic and computationally efficient. The energy loss functions\nalso inherently respect physical symmetries. We demonstrate our approach on\nmolecular generation and spin ground-state prediction and report significant\nimprovements over baselines.", "AI": {"tldr": "A framework for incorporating physical knowledge directly into loss functions for ML in scientific domains, using energy-based formulations derived from thermal equilibrium assumptions.", "motivation": "Previous approaches focused on architectural modifications to incorporate physical insights, but this work aims to leverage physical information directly in the loss function for better alignment with system physics.", "method": "Derive energy loss functions assuming data samples are in thermal equilibrium with an approximate energy landscape, using reverse KL divergence with Boltzmann distribution around data to obtain energy differences between data and model predictions.", "result": "Significant improvements over baselines demonstrated on molecular generation and spin ground-state prediction tasks.", "conclusion": "The proposed framework yields physically grounded loss functions that respect physical symmetries, provide better gradient alignment with valid configurations, and are architecture-agnostic while being computationally efficient."}}
{"id": "2511.02598", "pdf": "https://arxiv.org/pdf/2511.02598", "abs": "https://arxiv.org/abs/2511.02598", "authors": ["Xu Li", "Beatrice Meini"], "title": "A Block-Shifted Cyclic Reduction Algorithm for Solving a Class of Quadratic Matrix Equations", "categories": ["math.NA", "cs.NA", "15A24, 65F45, 65B99"], "comment": "17 pages, 2 figures, 3 tables", "summary": "The cyclic reduction (CR) algorithm is an efficient method for solving\nquadratic matrix equations that arise in quasi-birth-death (QBD) stochastic\nprocesses. However, its convergence is not guaranteed when the associated\nmatrix polynomial has more than one eigenvalue on the unit circle. To address\nthis limitation, we introduce a novel iteration method, referred to as the\nBlock-Shifted CR algorithm, that improves the CR algorithm by utilizing\nsingular value decomposition (SVD) and block shift-and-deflate techniques. This\nnew approach extends the applicability of existing solvers to a broader class\nof quadratic matrix equations. Numerical experiments demonstrate the\neffectiveness and robustness of the proposed method.", "AI": {"tldr": "The Block-Shifted CR algorithm improves cyclic reduction for solving quadratic matrix equations in QBD processes by using SVD and block shift-and-deflate techniques, extending applicability to cases with multiple eigenvalues on the unit circle.", "motivation": "The standard cyclic reduction algorithm fails to converge when the matrix polynomial has more than one eigenvalue on the unit circle, limiting its applicability for certain quadratic matrix equations in quasi-birth-death processes.", "method": "Proposed Block-Shifted CR algorithm that combines singular value decomposition with block shift-and-deflate techniques to enhance the standard cyclic reduction method.", "result": "Numerical experiments show the method is effective and robust, successfully solving quadratic matrix equations that standard cyclic reduction cannot handle.", "conclusion": "The Block-Shifted CR algorithm extends the applicability of existing solvers to a broader class of quadratic matrix equations by overcoming convergence limitations of traditional cyclic reduction."}}
{"id": "2511.02381", "pdf": "https://arxiv.org/pdf/2511.02381", "abs": "https://arxiv.org/abs/2511.02381", "authors": ["R. Agnello", "M. Barbisan", "R. Pasqualotto", "B. Pouradier-Duteil", "E. Sartori", "A. Tiso", "B. Zaniol"], "title": "Laser diagnostics for negative ion source optimization: insights from SPIDER at the ITER Neutral Beam Test Facility", "categories": ["physics.plasm-ph"], "comment": null, "summary": "The ITER Heating Neutral Beams (HNBs) require large, high-energy H/D atom\nbeams (285/330 A/m^2 extracted current density, and 1/0.87 MeV acceleration\nenergy, respectively for H and D). To address the associated challenges, the\nSPIDER negative ion RF beam source at the Neutral Beam Test Facility (NBTF) in\nPadova (Italy) serves as a full-scale source prototype with a 100 kV triode\naccelerator, for design validation and performance verification. SPIDER is\nequipped with two advanced laser diagnostics to monitor key plasma parameters;\nCavity Ring-Down Spectroscopy (CRDS) is used to measure H$^-$\\slash D$^-$ ion\ndensities, while Laser Absorption Spectroscopy (LAS) tracks caesium neutral\ndensity in the source. These measurements are essential for optimizing negative\nion production and meeting ITER source targets. We present diagnostic upgrade\ndetails, recent experimental results, and correlations with other machine\nparameters. Since CRDS relies on a single 4.637-meter-long optical cavity, the\nlongest used in such sources, it has demonstrated sensitivity to alignment.\nBased on recent experimental experience, structural improvements are being\nimplemented to enhance both stability and measurement reliability. LAS has\nmainly been employed as a tool to monitor the caesium conditioning status of\nSPIDER. Additionally, due to a distributed measurement over four lines of\nsight, LAS has proven effective in monitoring the caesium distribution within\nthe source. This work demonstrates the essential role of laser diagnostics in\ndeveloping ITER-relevant plasma sources and informs ongoing efforts to improve\nmeasurement accuracy in challenging environments.", "AI": {"tldr": "SPIDER negative ion beam source uses advanced laser diagnostics (CRDS and LAS) to monitor H-/D- ion densities and caesium distribution for ITER-relevant plasma source optimization.", "motivation": "ITER Heating Neutral Beams require high-energy H/D atom beams, and SPIDER serves as a full-scale prototype to validate design and verify performance for meeting ITER source targets.", "method": "Uses Cavity Ring-Down Spectroscopy (CRDS) for H-/D- ion density measurements and Laser Absorption Spectroscopy (LAS) for caesium neutral density tracking with four lines of sight.", "result": "CRDS demonstrated sensitivity to alignment due to long optical cavity, requiring structural improvements. LAS effectively monitors caesium conditioning status and distribution within the source.", "conclusion": "Laser diagnostics play an essential role in developing ITER-relevant plasma sources and ongoing efforts focus on improving measurement accuracy in challenging beam source environments."}}
{"id": "2511.02139", "pdf": "https://arxiv.org/pdf/2511.02139", "abs": "https://arxiv.org/abs/2511.02139", "authors": ["Jonas Sauer"], "title": "Limited-Range Multilinear Off-Diagonal Extrapolation and Weighted Transference Principle", "categories": ["math.AP", "42B25, 42B35, 43A15"], "comment": null, "summary": "Multilinear $L^p$ extrapolation results are established in a limited-range,\nmultilinear, and off-diagonal setting for mixed-norm Lebesgue spaces over\n$\\sigma$-finite measure spaces. Integrability exponents are allowed in the full\nrange $(0,\\infty]$. We detach the exponents for the weight classes completely\nfrom the exponents for the initial and target spaces for the extrapolation\nexcept for the basic consistency condition. This enables to cover the full\nrange $(0,\\infty]$ for all integrability exponents and provides new insights\ninto the dependency of the extrapolated bounds on the weight characteristic.\nCertain endpoint results are new even for $\\mathbb{R}^d$. Additionally, in the\nsetting of compact abelian groups, a weighted transference principle is\nestablished.", "AI": {"tldr": "Multilinear L^p extrapolation in limited-range, off-diagonal setting for mixed-norm Lebesgue spaces, covering full range (0,\u221e] for integrability exponents with detachable weight classes.", "motivation": "To establish extrapolation results that completely detach weight class exponents from initial/target space exponents, enabling coverage of full integrability range and providing new insights into weight characteristic dependencies.", "method": "Multilinear L^p extrapolation in limited-range, off-diagonal setting for mixed-norm Lebesgue spaces over \u03c3-finite measure spaces, with weighted transference principle for compact abelian groups.", "result": "Established extrapolation results covering full range (0,\u221e] for integrability exponents, with certain endpoint results being new even for \u211d^d, and dependency insights on weight characteristic.", "conclusion": "The approach enables complete detachment of weight class exponents from space exponents, providing comprehensive extrapolation coverage and new insights into weight characteristic effects, with applications including weighted transference in compact abelian groups."}}
{"id": "2511.02625", "pdf": "https://arxiv.org/pdf/2511.02625", "abs": "https://arxiv.org/abs/2511.02625", "authors": ["Xinliang Liu", "Tong Mao", "Jinchao Xu"], "title": "The stability of shallow neural networks on spheres: A sharp spectral analysis", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "We present an estimation of the condition numbers of the \\emph{mass} and\n\\emph{stiffness} matrices arising from shallow ReLU$^k$ neural networks defined\non the unit sphere~$\\mathbb{S}^d$. In particular, when $\\{\\theta_j^*\\}_{j=1}^n\n\\subset \\mathbb{S}^d$ is \\emph{antipodally quasi-uniform}, the condition number\nis sharp. Indeed, in this case, we obtain sharp asymptotic estimates for the\nfull spectrum of eigenvalues and characterize the structure of the\ncorresponding eigenspaces, showing that the smallest eigenvalues are associated\nwith an eigenbasis of low-degree polynomials while the largest eigenvalues are\nlinked to high-degree polynomials. This spectral analysis establishes a precise\ncorrespondence between the approximation power of the network and its numerical\nstability.", "AI": {"tldr": "Sharp asymptotic estimates for condition numbers of mass and stiffness matrices from shallow ReLU^k neural networks on the unit sphere, showing optimal numerical stability when nodes are antipodally quasi-uniform.", "motivation": "To establish the relationship between approximation power and numerical stability in neural networks by analyzing the spectral properties of key matrices.", "method": "Analyzed the full spectrum of eigenvalues and eigenspace structure of mass and stiffness matrices from shallow ReLU^k networks on the unit sphere with antipodally quasi-uniform nodes.", "result": "Found sharp condition numbers and characterized eigenspaces: smallest eigenvalues correspond to low-degree polynomials, largest eigenvalues to high-degree polynomials.", "conclusion": "Established precise correspondence between network approximation power and numerical stability through spectral analysis."}}
{"id": "2511.02405", "pdf": "https://arxiv.org/pdf/2511.02405", "abs": "https://arxiv.org/abs/2511.02405", "authors": ["Rostislav-Paul Wilhelm", "Manuel Torrilhon"], "title": "Simulation of multi-species kinetic instabilities with the Numerical Flow Iteration", "categories": ["physics.plasm-ph", "physics.comp-ph"], "comment": null, "summary": "Kinetic instabilities are one of the most challenging aspects in\ncomputational plasma physics. Accurately capturing their onset and evolution\nrequires fine resolution of the high-dimensional distribution functions of each\nrelevant species, which quickly becomes computationally prohibitively\nexpensive. Additionally, plasma dynamics is an inherently multi-scale\nphenomenon due to the vast separation of scales between heavy ions and\nlight-weight electrons. In previous work the Numerical Flow Iteration (NuFI)\nwas suggested as a high-fidelity alternative with reduced memory complexity\nmaking it an interesting candidate to simulate complicated kinetic\ninstabilities. In this work we extend NuFI to non-periodic boundary conditions\nand demonstrate how it is possible to reduce the computational complexity to\nallow for longer simulation periods.", "AI": {"tldr": "Extends Numerical Flow Iteration (NuFI) method to handle non-periodic boundary conditions and reduces computational complexity for longer kinetic instability simulations.", "motivation": "Kinetic instabilities in plasma physics require high-dimensional distribution functions that are computationally expensive, and plasma dynamics involves multi-scale phenomena with scale separation between ions and electrons.", "method": "Extends the Numerical Flow Iteration (NuFI) method to support non-periodic boundary conditions and implements computational complexity reduction techniques.", "result": "Successfully demonstrated that NuFI can handle non-periodic boundaries and achieve reduced computational complexity, enabling longer simulation periods.", "conclusion": "The extended NuFI method provides a viable high-fidelity alternative for simulating complex kinetic instabilities with improved computational efficiency and boundary condition handling."}}
{"id": "2511.02145", "pdf": "https://arxiv.org/pdf/2511.02145", "abs": "https://arxiv.org/abs/2511.02145", "authors": ["T\u00fcrker \u00d6zsar\u0131", "Dionyssios Mantzavinos", "Konstantinos Kalimeris"], "title": "A new approach for the analysis of evolution partial differential equations on a finite interval", "categories": ["math.AP", "35G16, 35G31, 35Q53, 35K05"], "comment": "23 pages, 9 figures", "summary": "We show that, for certain evolution partial differential equations, the\nsolution on a finite interval $(0,\\ell)$ can be reconstructed as a\nsuperposition of restrictions to $(0,\\ell)$ of solutions to two associated\npartial differential equations posed on the half-lines $(0,\\infty)$ and\n$(-\\infty,\\ell)$. Determining the appropriate data for these half-line problems\namounts to solving an inverse problem, which we formulate via the unified\ntransform of Fokas (also known as the Fokas method) and address via a fixed\npoint argument in $L^2$-based Sobolev spaces, including fractional ones through\ninterpolation techniques. We illustrate our approach through two canonical\nexamples, the heat equation and the Korteweg-de Vries (KdV) equation, and\nprovide numerical simulations for the former example. We further demonstrate\nthat the new approach extends to more general evolution partial differential\nequations, including those with time-dependent coefficients. A key outcome of\nthis work is that spatial and temporal regularity estimates for problems on a\nfinite interval can be directly derived from the corresponding estimates on the\nhalf-line. These results can, in turn, be used to establish local\nwell-posedness for related nonlinear problems, as the essential ingredients are\nthe linear estimates within nonlinear frameworks.", "AI": {"tldr": "A method to reconstruct solutions of evolution PDEs on finite intervals using solutions from associated half-line problems, formulated via the Fokas unified transform and solved with fixed point arguments.", "motivation": "To develop a unified approach for solving evolution PDEs on finite intervals by leveraging solutions from simpler half-line problems, enabling direct derivation of regularity estimates.", "method": "Use the Fokas unified transform to formulate inverse problems for half-line data, solve via fixed point arguments in L^2-based Sobolev spaces with interpolation techniques, applied to heat and KdV equations.", "result": "Successfully reconstructed finite interval solutions from half-line problems, demonstrated with heat and KdV equations, extended to time-dependent coefficient PDEs, enabling direct derivation of spatial/temporal regularity estimates.", "conclusion": "The approach provides a powerful framework for analyzing evolution PDEs on finite intervals, with linear estimates applicable to establishing local well-posedness for nonlinear problems."}}
{"id": "2511.02654", "pdf": "https://arxiv.org/pdf/2511.02654", "abs": "https://arxiv.org/abs/2511.02654", "authors": ["Yahya Alnashri"], "title": "Error Estimates of Generic Discretisation of Reaction-Diffusion System with Constraints", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "In this paper, we study a parabolic reaction diffusion system with\nconstraints that model biofilm growth. Within a unified framework encompassing\nmultiple numerical schemes, we derive the first general convergence rates for\napproximating this model using both conforming and non conforming\ndiscretisation methods. Under standard assumptions on the time discretisation,\nwe establish the existence and uniqueness of the discrete solution. Numerical\nexperiments are conducted using a mixed finite volume scheme that fits within\nthe proposed unified framework. A test case with an analytical solution is\ndesigned to confirm our theoretical convergence rates.", "AI": {"tldr": "This paper establishes general convergence rates for numerical schemes approximating a parabolic reaction-diffusion system modeling biofilm growth, covering both conforming and non-conforming discretization methods.", "motivation": "To provide a unified framework for analyzing numerical schemes for biofilm growth models and derive the first general convergence rates for such approximations.", "method": "Developed a unified framework encompassing multiple numerical schemes, proved existence and uniqueness of discrete solutions under standard time discretization assumptions, and conducted numerical experiments using a mixed finite volume scheme.", "result": "Established general convergence rates for both conforming and non-conforming discretization methods, with numerical experiments confirming theoretical convergence rates using a test case with analytical solution.", "conclusion": "The proposed unified framework successfully provides general convergence rates for numerical approximations of biofilm growth models, validated through both theoretical analysis and numerical experiments."}}
{"id": "2511.02273", "pdf": "https://arxiv.org/pdf/2511.02273", "abs": "https://arxiv.org/abs/2511.02273", "authors": ["Gayoung An", "Sungbin Park"], "title": "On the Boltzmann-Fermi-Dirac Equation for Hard Potential: Global Existence and Uniqueness, Gaussian Lower Bound, and Moment Estimates", "categories": ["math.AP", "35Q20, 35Q40, 82C40"], "comment": "82 pages, 5 figures", "summary": "In this paper, we study the global existence and uniqueness, Gaussian lower\nbound, and moment estimates in the spatially homogeneous Boltzmann equation for\nFermi-Dirac particles for hard potential ($0\\leq \\gamma\\leq 2$) with angular\ncutoff $b$. Our results extend classical results to the Boltzmann-Fermi-Dirac\nsetting. In detail, (1) we show existence, uniqueness, and $L^1_2$ stability of\nglobal-in-time solutions of the Boltzmann-Fermi-Dirac equation. (2) Assuming\nthe solution is not a saturated equilibrium, we prove creation of a Gaussian\nlower bound for the solution. (3) We prove creation and propagation of $L^1$\npolynomial and exponential moments of the solution under additional assumptions\non the angular kernel $b$ and $0<\\gamma\\leq 2$. (4) Finally, we show\npropagation of $L^\\infty$ Gaussian and polynomial upper bounds when $b$ is\nconstant and $0<\\gamma\\leq 1$.", "AI": {"tldr": "Global existence, uniqueness, Gaussian bounds, and moment estimates for the spatially homogeneous Boltzmann-Fermi-Dirac equation with hard potentials and angular cutoff.", "motivation": "Extend classical Boltzmann equation results to the Fermi-Dirac particle setting, addressing quantum statistical effects in kinetic theory.", "method": "Mathematical analysis of the Boltzmann-Fermi-Dirac equation using techniques from kinetic theory and functional analysis for hard potentials (0\u2264\u03b3\u22642) with angular cutoff b.", "result": "Proved: (1) global existence, uniqueness, and L\u00b9\u2082 stability; (2) Gaussian lower bound creation for non-saturated solutions; (3) L\u00b9 moment creation/propagation; (4) L\u221e Gaussian/polynomial upper bound propagation for constant b and 0<\u03b3\u22641.", "conclusion": "Successfully extended classical Boltzmann equation theory to the quantum Fermi-Dirac case, establishing fundamental mathematical properties including existence, uniqueness, and various moment bounds."}}
{"id": "2511.02461", "pdf": "https://arxiv.org/pdf/2511.02461", "abs": "https://arxiv.org/abs/2511.02461", "authors": ["Yu-Hui Song", "Huan-Cheng Yang", "Kai Liu", "Zhong-Yi Lu"], "title": "Ultrafast magnetic moment transfer and bandgap renormalization in monolayer \\ce{FeCl2}", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "8 pages, 8 figures", "summary": "The microscopic origin of laser-induced ultrafast demagnetization remains an\nopen question, to which the non-thermal electronic distribution plays a vital\nrole at the initial stage. Herein, we investigate the connection between the\nnon-thermal electronic distribution and the ultrafast spin dynamics as well as\nthe electronic structure evolution in ferromagnetic \\ce{FeCl2} monolayer using\nreal-time time-dependent density functional theory (rt-TDDFT) with\nself-consistent Hubbard $U$ correction. Our simulations reveal that femtosecond\nlaser pulses induce ultrafast magnetic moment transfer from Fe to Cl atoms.\nMore importantly, through a comprehensive analysis of orbital-resolved\nelectronic structure, we elucidate the microscopic origin of this transfer,\nattributing it to specific intra-atomic and inter-atomic charge transfer\npathways driven by non-thermal excitations. The extent of demagnetization of Fe\natoms exhibits a non-monotonic dependence on the laser photon energy, reaching\na maximum at the resonant excitation. In addition, the dynamical evolution of\nthe band structure was studied based on the eigenstates of the instantaneous\nHamiltonian. Under resonant excitation, the bandgap reduction reaches up to\n$41\\%$ within tens of fs. These findings provide fundamental insights into\nultrafast spin control and suggest a strategy to optically engineer the\nmagnetism in two-dimensional magnetic materials.", "AI": {"tldr": "Femtosecond laser pulses induce ultrafast magnetic moment transfer from Fe to Cl atoms in ferromagnetic FeCl2 monolayer, with demagnetization showing non-monotonic dependence on laser photon energy and reaching maximum at resonant excitation.", "motivation": "To understand the microscopic origin of laser-induced ultrafast demagnetization and the role of non-thermal electronic distribution in ferromagnetic materials.", "method": "Real-time time-dependent density functional theory (rt-TDDFT) with self-consistent Hubbard U correction, analyzing orbital-resolved electronic structure and dynamical evolution of band structure.", "result": "Laser pulses cause ultrafast magnetic moment transfer from Fe to Cl atoms, with Fe demagnetization reaching maximum at resonant excitation. Bandgap reduction up to 41% occurs within tens of femtoseconds under resonant excitation.", "conclusion": "The study provides fundamental insights into ultrafast spin control and suggests a strategy for optically engineering magnetism in 2D magnetic materials through specific charge transfer pathways driven by non-thermal excitations."}}
{"id": "2511.02658", "pdf": "https://arxiv.org/pdf/2511.02658", "abs": "https://arxiv.org/abs/2511.02658", "authors": ["Yaling Kang", "Zujun Ma", "Xin Tian", "Zhiqiao Wu"], "title": "Joint transfer pricing decision on tangible and intangible assets for multinational firms", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "While conventional multinational firms (MNFs) often avoid taxes by\ntransferring their profits to low-tax regions through markup on tangible asset\ncosts, high-tech MNFs may avoid taxes by transferring royalty fees to\nintangible assets (i.e., royalty-based transfer prices). This study\ninvestigates the effects of tax differences, markups, and royalties on\ndecision-making. We also compare the different effects of markups and royalties\non the improvement of MNFs' after-tax profit under two main business\nstructures: the commissionaire operational structure (C) with complete\ninformation, and the limited-risk operational structure (R) in the\nprincipal-agent setting. We find that the tax difference always improves MNFs'\nprofits under the C structure, whereas non-monotonic behavior exists under the\nR structure. More interestingly, when the order quantity is relatively small,\nthe markup improves MNFs' profits faster than the royalty; conversely, the\nroyalty improves MNFs' profits faster than the markup.", "AI": {"tldr": "Study compares tax avoidance strategies of multinational firms: conventional firms use markup on tangible assets, while high-tech firms use royalty fees on intangible assets. Analyzes effects under commissionaire (C) and limited-risk (R) structures.", "motivation": "To understand how different tax avoidance strategies (markup vs royalty) affect multinational firms' decision-making and profits under different operational structures, especially given the different approaches used by conventional vs high-tech firms.", "method": "Mathematical modeling comparing effects of tax differences, markups, and royalties on decision-making under two operational structures: commissionaire structure (C) with complete information and limited-risk structure (R) in principal-agent setting.", "result": "Tax difference always improves profits under C structure but shows non-monotonic behavior under R structure. When order quantity is small, markup improves profits faster than royalty; when quantity is large, royalty improves profits faster than markup.", "conclusion": "The effectiveness of tax avoidance strategies depends on operational structure and order quantity, with markup being more effective for small quantities and royalty for large quantities, while tax differences have different effects under complete vs principal-agent settings."}}
{"id": "2511.02321", "pdf": "https://arxiv.org/pdf/2511.02321", "abs": "https://arxiv.org/abs/2511.02321", "authors": ["Fucai Li", "Jinkai Ni", "Zhipeng Zhang"], "title": "Uniform stability and optimal time decay rates of the compressible pressureless Navier-Stokes system in the critical regularity framework", "categories": ["math.AP"], "comment": "31 pages", "summary": "This paper investigates the Cauchy problem for the compressible pressureless\nNavier-Stokes system in $\\mathbb{R}^d$ with $d \\geq 2$. Unlike the standard\nisentropic compressible Navier-Stokes system, the density in the pressureless\nmodel lacks a dissipative mechanism, leading to significant coupling effects\nfrom nonlinear terms in the momentum equations. We first prove the global\nwell-posedness and uniform stability of strong solutions to the compressible\npressureless Navier-Stokes system in the critical Besov space\n$\\dot{B}_{2,1}^{\\frac{d}{2}} \\times \\dot{B}_{2,1}^{\\frac{d}{2}-1}$. Then, under\nthe additional assumption that the low-frequency component of the initial\ndensity belongs to $\\dot{B}_{2,\\infty}^{\\sigma_0+1}$ and that the initial\nvelocity is sufficiently small in $\\dot{B}_{2,\\infty}^{\\sigma_0}$ with\n$\\sigma_0 \\in (-\\frac{d}{2}, \\frac{d}{2}-1]$, we overcome the challenge of\nderivative loss caused by nonlinearity and establish optimal decay estimates\nfor $u$ in $\\dot{B}_{2,1}^{\\sigma}$ with $\\sigma \\in (\\sigma_0,\n\\frac{d}{2}+1]$. In particular, it is shown that the density remains uniformly\nbounded in time which reveals a new asymptotic behavior in contrast to the\nisentropic compressible Navier-Stokes system where the density exhibits a\ndissipative structure and decays over time.", "AI": {"tldr": "Global well-posedness and decay estimates for compressible pressureless Navier-Stokes system in critical Besov spaces, showing uniform bounded density behavior different from standard compressible models.", "motivation": "To analyze the Cauchy problem for compressible pressureless Navier-Stokes system where density lacks dissipative mechanism, leading to strong coupling effects from nonlinear terms in momentum equations.", "method": "Prove global well-posedness and uniform stability in critical Besov space, then establish optimal decay estimates for velocity under additional assumptions on initial density and velocity in Besov spaces.", "result": "Global well-posedness achieved, optimal decay estimates for velocity established, and density shown to remain uniformly bounded in time - a new asymptotic behavior contrasting with dissipative density decay in standard compressible Navier-Stokes.", "conclusion": "The pressureless model exhibits fundamentally different asymptotic behavior with uniformly bounded density, overcoming derivative loss challenges from nonlinearity through careful Besov space analysis."}}
{"id": "2511.02584", "pdf": "https://arxiv.org/pdf/2511.02584", "abs": "https://arxiv.org/abs/2511.02584", "authors": ["Mark Bl\u00fcmel", "Andreas C. Schneider", "Valentin Neuhaus", "David A. Ehrlich", "Marcel Graetz", "Michael Wibral", "Abdullah Makkeh", "Viola Priesemann"], "title": "Redundancy Maximization as a Principle of Associative Memory Learning", "categories": ["cs.IT", "cs.LG", "cs.NE", "math.IT", "physics.comp-ph"], "comment": "21 pages, 8 figures", "summary": "Associative memory, traditionally modeled by Hopfield networks, enables the\nretrieval of previously stored patterns from partial or noisy cues. Yet, the\nlocal computational principles which are required to enable this function\nremain incompletely understood. To formally characterize the local information\nprocessing in such systems, we employ a recent extension of information theory\n- Partial Information Decomposition (PID). PID decomposes the contribution of\ndifferent inputs to an output into unique information from each input,\nredundant information across inputs, and synergistic information that emerges\nfrom combining different inputs. Applying this framework to individual neurons\nin classical Hopfield networks we find that below the memory capacity, the\ninformation in a neuron's activity is characterized by high redundancy between\nthe external pattern input and the internal recurrent input, while synergy and\nunique information are close to zero until the memory capacity is surpassed and\nperformance drops steeply. Inspired by this observation, we use redundancy as\nan information-theoretic learning goal, which is directly optimized for each\nneuron, dramatically increasing the network's memory capacity to 1.59, a more\nthan tenfold improvement over the 0.14 capacity of classical Hopfield networks\nand even outperforming recent state-of-the-art implementations of Hopfield\nnetworks. Ultimately, this work establishes redundancy maximization as a new\ndesign principle for associative memories and opens pathways for new\nassociative memory models based on information-theoretic goals.", "AI": {"tldr": "The paper uses Partial Information Decomposition to analyze Hopfield networks, finding that redundancy between external and internal inputs characterizes memory function. By optimizing for redundancy as a learning goal, they achieve a 10x improvement in memory capacity to 1.59, outperforming state-of-the-art implementations.", "motivation": "To understand the local computational principles that enable associative memory in Hopfield networks, which remain incompletely understood despite their traditional use for pattern retrieval from noisy cues.", "method": "Applied Partial Information Decomposition (PID) framework to individual neurons in classical Hopfield networks, then used redundancy maximization as an information-theoretic learning goal that is directly optimized for each neuron.", "result": "Achieved dramatic increase in memory capacity to 1.59 (compared to classical 0.14), representing more than tenfold improvement and outperforming recent state-of-the-art Hopfield network implementations.", "conclusion": "Establishes redundancy maximization as a new design principle for associative memories and opens pathways for new associative memory models based on information-theoretic goals."}}
{"id": "2511.02662", "pdf": "https://arxiv.org/pdf/2511.02662", "abs": "https://arxiv.org/abs/2511.02662", "authors": ["Mirebeau Jean-Marie", "Stampfli Erwan"], "title": "Discretization and convergence of the ballistic Benamou-Brenier formulation of the porous medium and Burgers equations", "categories": ["math.NA", "cs.NA", "65M06 (Primary) 65M12, 49M29 (Secondary)"], "comment": null, "summary": "We study the discretization, convergence, and numerical implementation of\nrecent reformulations of the quadratic porous medium equation (multidimensional\nand anisotropic) and Burgers' equation (one-dimensional, with optional\nviscosity), as forward in time variants of the Benamou-Brenier formulation of\noptimal transport. This approach turns those evolution problems into global\noptimization problems in time and space, of which we introduce a\ndiscretization, one of whose originalities lies in the harmonic interpolation\nof the densities involved. We prove that the resulting schemes are\nunconditionally stable w.r.t. the space and time steps, and we establish a\nquadratic convergence rate for the dual PDE solution, under suitable\nassumptions. We also show that the schemes can be efficiently solved\nnumerically using a proximal splitting method and a global space-time fast\nFourier transform, and we illustrate our results with numerical experiments.", "AI": {"tldr": "The paper presents discretization, convergence analysis, and numerical implementation of reformulations of quadratic porous medium and Burgers' equations as forward-time variants of the Benamou-Brenier optimal transport formulation.", "motivation": "To develop efficient numerical schemes for evolution problems by reformulating them as global optimization problems in time and space using the Benamou-Brenier optimal transport framework.", "method": "Introduces discretization with harmonic interpolation of densities, proves unconditional stability, establishes quadratic convergence rate for dual PDE solution, and implements using proximal splitting method with global space-time fast Fourier transform.", "result": "The resulting schemes are unconditionally stable with respect to space and time steps, achieve quadratic convergence rate under suitable assumptions, and can be efficiently solved numerically.", "conclusion": "The proposed approach successfully transforms evolution problems into global optimization problems with stable, convergent schemes that are computationally efficient using modern optimization techniques."}}
{"id": "2511.02327", "pdf": "https://arxiv.org/pdf/2511.02327", "abs": "https://arxiv.org/abs/2511.02327", "authors": ["Yufeng Lu"], "title": "Global well-posedness for generalized fractional Hartree equations with rough initial data in all dimensions", "categories": ["math.AP", "35R11, 35Q55, 35Q60, 42B37"], "comment": "22 pages, 1 figure", "summary": "We prove the global existence of the solution for fractional Hartree\nequations with initial data in certain real interpolation spaces between\n$L^{2}$ and some kinds of new function spaces defined by fractional\nSchr\\\"odinger semigroup, which could imply the global well-posedness of the\nequation in modulation spaces $M_{p,p'}^{s_{p}}$ for $p$ close to 2 with no\nsmallness condition on initial data, where $s_{p}=(m-2)(1/2-1/p)$. The proof\nadapts a splitting method inspired by the work of Hyakuna-Tsutsumi, Chaichenets\net al. to the modulation spaces and exploits polynomial growth of the\nfractional Schr\\\"odinger semi-group on modulation spaces $M_{p,p'}$ with loss\nof regularity $s_{p}$.", "AI": {"tldr": "Global existence of solutions for fractional Hartree equations is proven in real interpolation spaces between L\u00b2 and new function spaces defined by fractional Schr\u00f6dinger semigroup, implying global well-posedness in modulation spaces M_{p,p'}^{s_p} for p near 2 without small initial data.", "motivation": "To establish global well-posedness for fractional Hartree equations in modulation spaces without requiring small initial data conditions, extending previous results.", "method": "Adapts a splitting method from Hyakuna-Tsutsumi and Chaichenets et al. to modulation spaces, exploiting polynomial growth properties of fractional Schr\u00f6dinger semigroup on these spaces with regularity loss s_p.", "result": "Proves global existence of solutions for fractional Hartree equations in specified interpolation spaces and modulation spaces M_{p,p'}^{s_p} for p close to 2.", "conclusion": "The approach successfully establishes global well-posedness for fractional Hartree equations in modulation spaces without smallness conditions on initial data, leveraging semigroup properties and splitting methods."}}
{"id": "2511.02622", "pdf": "https://arxiv.org/pdf/2511.02622", "abs": "https://arxiv.org/abs/2511.02622", "authors": ["Giuseppe Sacco", "Giovanni Bussi", "Guido Sanguinetti"], "title": "Machine Learning for RNA Secondary Structure Prediction: a review of current methods and challenges", "categories": ["q-bio.BM", "physics.bio-ph", "physics.comp-ph"], "comment": null, "summary": "Predicting the secondary structure of RNA is a core challenge in\ncomputational biology, essential for understanding molecular function and\ndesigning novel therapeutics. The field has evolved from foundational but\naccuracy-limited thermodynamic approaches to a new data-driven paradigm\ndominated by machine learning and deep learning. These models learn folding\npatterns directly from data, leading to significant performance gains. This\nreview surveys the modern landscape of these methods, covering single-sequence,\nevolutionary-based, and hybrid models that blend machine learning with\nbiophysics. A central theme is the field's \"generalization crisis,\" where\npowerful models were found to fail on new RNA families, prompting a\ncommunity-wide shift to stricter, homology-aware benchmarking. In response to\nthe underlying challenge of data scarcity, RNA foundation models have emerged,\nlearning from massive, unlabeled sequence corpora to improve generalization.\nFinally, we look ahead to the next set of major hurdles-including the accurate\nprediction of complex motifs like pseudoknots, scaling to kilobase-length\ntranscripts, incorporating the chemical diversity of modified nucleotides, and\nshifting the prediction target from static structures to the dynamic ensembles\nthat better capture biological function. We also highlight the need for a\nstandardized, prospective benchmarking system to ensure unbiased validation and\naccelerate progress.", "AI": {"tldr": "This review surveys modern machine learning approaches for RNA secondary structure prediction, highlighting the field's evolution from thermodynamic methods to data-driven models, current challenges with generalization, and future directions including foundation models and complex motif prediction.", "motivation": "RNA secondary structure prediction is crucial for understanding molecular function and designing therapeutics, with the field transitioning from limited thermodynamic approaches to more powerful data-driven machine learning methods.", "method": "The review covers single-sequence models, evolutionary-based approaches, and hybrid models that combine machine learning with biophysics, with emphasis on RNA foundation models trained on large unlabeled sequence datasets.", "result": "Modern machine learning models have achieved significant performance gains but face a \"generalization crisis\" where they fail on new RNA families, prompting stricter benchmarking standards and the development of foundation models to address data scarcity.", "conclusion": "Future challenges include predicting complex motifs like pseudoknots, scaling to long transcripts, incorporating modified nucleotides, predicting dynamic ensembles rather than static structures, and establishing standardized prospective benchmarking for unbiased validation."}}
{"id": "2511.02700", "pdf": "https://arxiv.org/pdf/2511.02700", "abs": "https://arxiv.org/abs/2511.02700", "authors": ["Massimiliano Moda", "Karel J. in 't Hout", "Mich\u00e8le Vanmaele", "Fred Espen Benth"], "title": "Numerical valuation of European options under two-asset infinite-activity exponential L\u00e9vy models", "categories": ["math.NA", "cs.NA", "q-fin.CP"], "comment": null, "summary": "We propose a numerical method for the valuation of European-style options\nunder two-asset infinite-activity exponential L\\'evy models. Our method extends\nthe effective approach developed by Wang, Wan & Forsyth (2007) for the\n1-dimensional case to the 2-dimensional setting and is applicable for general\nL\\'evy measures under mild assumptions. A tailored discretization of the\nnon-local integral term is developed, which can be efficiently evaluated by\nmeans of the fast Fourier transform. For the temporal discretization, the\nsemi-Lagrangian theta-method is employed in a convenient splitting fashion,\nwhere the diffusion term is treated implicitly and the integral term is handled\nexplicitly by a fixed-point iteration. Numerical experiments for\nput-on-the-average options under Normal Tempered Stable dynamics reveal\nfavourable second-order convergence of our method whenever the exponential\nL\\'evy process has finite-variation.", "AI": {"tldr": "A numerical method for valuing European options under two-asset exponential L\u00e9vy models, extending 1D methods to 2D with efficient FFT-based discretization and second-order convergence.", "motivation": "To develop efficient valuation methods for European options under two-asset infinite-activity exponential L\u00e9vy models, extending existing 1D approaches to handle the more complex 2D case.", "method": "Extends Wang-Wan-Forsyth 1D approach to 2D setting with tailored discretization of non-local integral term using FFT, and semi-Lagrangian theta-method with splitting (implicit diffusion, explicit integral via fixed-point iteration).", "result": "Method achieves favorable second-order convergence for put-on-the-average options under Normal Tempered Stable dynamics, particularly when L\u00e9vy process has finite-variation.", "conclusion": "The proposed method successfully extends 1D valuation techniques to 2D exponential L\u00e9vy models with efficient implementation and good convergence properties."}}
{"id": "2511.02338", "pdf": "https://arxiv.org/pdf/2511.02338", "abs": "https://arxiv.org/abs/2511.02338", "authors": ["Wei-Xi Li", "Zhan Xu", "Anita Yang"], "title": "Global Well-Posedness for the 2D and 3D Prandtl-Shercliff Model", "categories": ["math.AP"], "comment": null, "summary": "We investigate the Prandtl-Shercliff model in both two and three dimensions.\nFor the two-dimensional case, we establish global-in-time well-posedness in\nSobolev spaces without any structural assumptions on the initial data.\nFurthermore, we show that the solution exhibits an analytic regularization\neffect in all variables, which holds globally in time and in space up to the\nboundary. For the three-dimensional case, we study a linearized version of the\nmodel and prove its global-in-time well-posedness for initial data that are\nanalytic in only one tangential direction. The proofs rely crucially on the\nintrinsic non-local diffusion induced by the Shercliff boundary layer.", "AI": {"tldr": "Global well-posedness and analytic regularization for 2D/3D Prandtl-Shercliff model with Shercliff boundary layer effects.", "motivation": "To establish rigorous mathematical foundations for the Prandtl-Shercliff model, which describes boundary layer phenomena in magnetohydrodynamics, particularly addressing the challenging well-posedness issues in both 2D and 3D settings.", "method": "Utilized Sobolev space analysis and exploited the intrinsic non-local diffusion properties induced by the Shercliff boundary layer. For 2D case: global well-posedness without structural assumptions; for 3D case: studied linearized version with analyticity in one tangential direction.", "result": "2D: Global well-posedness established with analytic regularization in all variables globally in time and space. 3D: Global well-posedness proved for linearized model with initial data analytic in one tangential direction.", "conclusion": "The Shercliff boundary layer's non-local diffusion mechanism plays a crucial role in establishing global well-posedness and regularization properties for the Prandtl-Shercliff model across different dimensions."}}
{"id": "2511.02744", "pdf": "https://arxiv.org/pdf/2511.02744", "abs": "https://arxiv.org/abs/2511.02744", "authors": ["Visagan Ravindran", "Clio Johnson", "Neil D. Drummond", "Stewart J. Clark", "Nikitas. I. Gidopoulos"], "title": "From Densities to Potentials: Benchmarking Local Exchange-Correlation Approximations", "categories": ["physics.chem-ph", "cond-mat.str-el", "physics.comp-ph"], "comment": "25 Figures, 7 Tables, 31 Pages including supplemental material.\n  Submitted to PRB", "summary": "Using the Kohn-Sham (KS) inversion method of Hollins et al. [J. Phys.:\nCondens. Matter 29, 04LT01 (2017)], we invert densities from variational and\ndiffusion quantum Monte Carlo (QMC) calculations to obtain benchmark QMC-KS\npotentials for a range of insulators and semiconductors, which we then compare\nto the KS potentials of popular density functional approximations (DFAs). Our\nresults show that different DFAs yield similar electron densities, despite\ndifferences in their KS potentials, which originate primarily from the exchange\nand correlation contribution. We also find that the KS gap from the QMC density\nis typically larger than the KS gaps of most DFAs, with the exception of\nHartree-Fock. Finally, the KS gap is sensitive to the inclusion of semicore\nstates in the pseudopotentials, such that comparison with experiment should be\ndone with caution.", "AI": {"tldr": "The paper benchmarks Kohn-Sham potentials from QMC calculations against popular density functional approximations, finding that different DFAs produce similar densities despite differing potentials, and QMC-KS gaps are larger than most DFA gaps except Hartree-Fock.", "motivation": "To provide benchmark QMC-KS potentials for insulators and semiconductors and compare them with popular density functional approximations to understand differences in their performance.", "method": "Using Kohn-Sham inversion method on densities from variational and diffusion quantum Monte Carlo calculations to obtain QMC-KS potentials, then comparing with KS potentials from various DFAs.", "result": "Different DFAs yield similar electron densities despite differences in their KS potentials; QMC-KS gaps are larger than most DFA gaps (except Hartree-Fock); KS gap is sensitive to semicore states in pseudopotentials.", "conclusion": "Comparison of KS gaps with experiment should be done cautiously due to sensitivity to semicore states, and QMC provides valuable benchmarks for evaluating density functional approximations."}}
{"id": "2511.02740", "pdf": "https://arxiv.org/pdf/2511.02740", "abs": "https://arxiv.org/abs/2511.02740", "authors": ["Ilse C. F. Ipsen", "Arvind K. Saibaba"], "title": "Many (most?) column subset selection criteria are NP hard", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We consider a variety of criteria for selecting k representative columns from\na real matrix A with rank(A)>=k. The criteria include the following\noptimization problems: absolute volume and S-optimality maximization; norm and\ncondition minimization in the two-norm, Frobenius norm and Schatten p-norms for\np>2; stable rank maximization; and the new criterion of relative volume\nmaximization. We show that these criteria are NP hard and do not admit\npolynomial time approximation schemes (PTAS). To formulate the optimization\nproblems as decision problems, we derive optimal values for the subset\nselection criteria, as well as expressions for partitioned pseudo-inverses.", "AI": {"tldr": "Analysis of NP-hard subset selection criteria for choosing k representative columns from matrices, including volume/S-optimality maximization, norm/condition minimization, and stable rank maximization.", "motivation": "To understand the computational complexity and develop theoretical foundations for various criteria used in selecting representative columns from matrices, which has applications in data analysis, dimensionality reduction, and numerical linear algebra.", "method": "Formulate optimization problems as decision problems, derive optimal values for subset selection criteria, and develop expressions for partitioned pseudo-inverses to analyze computational complexity.", "result": "Proved that all considered subset selection criteria are NP-hard and do not admit polynomial time approximation schemes (PTAS), establishing strong computational barriers.", "conclusion": "The various criteria for selecting representative columns from matrices are computationally intractable, requiring alternative approaches like approximation algorithms or heuristics for practical applications."}}
{"id": "2511.02341", "pdf": "https://arxiv.org/pdf/2511.02341", "abs": "https://arxiv.org/abs/2511.02341", "authors": ["Elisa Davoli", "Christian Kuehn", "Luca Scarpa", "Lara Trussardi"], "title": "Local asymptotics for the nonlocal Swift-Hohenberg equation", "categories": ["math.AP"], "comment": null, "summary": "The nonlocal-to-local asymptotics investigation for evolutionary problems is\na central topic both in the theory of PDEs and in functional analysis. More\nrecently, it became the main core of the mathematical analysis of\nphase-separation models. In this paper we focus on the Swift-Hohenberg\nequations which are key benchmark models in pattern formation problems and\namplitude equations. We prove well-posedness of the nonlocal Swift-Hohenberg\nequation, and study the nonlocal-to-local asymptotics with one and two nonlocal\ncontributions under homogeneous Neumann boundary conditions using suitable\nenergy estimates on the nonlocal problems.", "AI": {"tldr": "Analysis of nonlocal-to-local asymptotics for Swift-Hohenberg equations, proving well-posedness and studying convergence under Neumann boundary conditions using energy estimates.", "motivation": "Nonlocal-to-local asymptotics is crucial in PDE theory, functional analysis, and phase-separation models. Swift-Hohenberg equations are fundamental benchmark models in pattern formation and amplitude equations.", "method": "Prove well-posedness of nonlocal Swift-Hohenberg equation and study nonlocal-to-local asymptotics with one and two nonlocal contributions using energy estimates on nonlocal problems under homogeneous Neumann boundary conditions.", "result": "Established well-posedness results and analyzed convergence behavior from nonlocal to local formulations.", "conclusion": "The study provides rigorous mathematical foundation for nonlocal-to-local transitions in Swift-Hohenberg equations, which are important for understanding pattern formation phenomena."}}
{"id": "2511.02750", "pdf": "https://arxiv.org/pdf/2511.02750", "abs": "https://arxiv.org/abs/2511.02750", "authors": ["Priyanka Majethiya", "Shivam Bajpeyi"], "title": "Approximation by Certain Complex Nevai Operators : Theory and Applications", "categories": ["math.NA", "cs.NA", "math.FA"], "comment": "NA", "summary": "The approximation of complex-valued functions is of fundamental importance as\nit generalizes classical approximation theory to the complex domain, providing\na rigorous framework for amplitude and phase-dependent phenomena. In this\npaper, we study the Nevai operator, a concept formulated by the distinguished\nmathematician Paul G. Nevai. We propose a family of complex Nevai interpolation\noperators to approximate analytic as well as non-analytic complex-valued\nfunctions along with real-life application in image processing. In this\ndirection, the first operator is constructed using Chebyshev polynomials of the\nfirst kind, namely complex generalized Nevai operators for approximating\ncomplex-valued continuous functions. We establish the approximation results for\nthe proposed operators utilizing the notion of a modulus of continuity. To\napproximate not necessary continuous but integrable function, we define complex\nKantorovich type Nevai operators and establish their boundedness and\nconvergence. Furthermore, in order to approximate functions preserving higher\nderivatives, we introduce complex Hermite type Nevai operators and study their\napproximation capabilities using higher order of modulus of continuity. To\nvalidate the theoretical results, we provide numerical illustrations of\napproximation abilities of proposed family of complex Nevai operators.", "AI": {"tldr": "The paper proposes a family of complex Nevai interpolation operators for approximating complex-valued functions, including generalized, Kantorovich, and Hermite types, with applications in image processing.", "motivation": "To extend classical approximation theory to complex domains for handling amplitude and phase-dependent phenomena, building on Nevai's mathematical framework.", "method": "Developed three types of complex Nevai operators: generalized (using Chebyshev polynomials), Kantorovich (for integrable functions), and Hermite (preserving higher derivatives), with theoretical analysis using modulus of continuity.", "result": "Established approximation results, boundedness, and convergence properties for all three operator types, validated through numerical illustrations.", "conclusion": "The proposed family of complex Nevai operators provides effective tools for approximating various classes of complex-valued functions, with practical applications in areas like image processing."}}
{"id": "2511.02402", "pdf": "https://arxiv.org/pdf/2511.02402", "abs": "https://arxiv.org/abs/2511.02402", "authors": ["Christophe Prud'Homme", "Vincent Chabannes", "La\u00ebtitia Giraldi", "Agathe Chouippe", "C\u00e9line Van Landeghem"], "title": "Two-way Coupling of Fluid--Structure Interaction for Elastic Magneto-Swimmers:A Finite Element ALE Approach", "categories": ["math.AP"], "comment": null, "summary": "Artificial micro-swimmers actuated by external magnetic fields hold\nsignificant promise for targeted biomedical applications, including drug\ndelivery and micro-robot-assisted therapy. However, their dynamics remain\nchallenging to control due to the complex nonlinear coupling between magnetic\nactuation, elastic deformations, and fluid interactions in confined biological\nenvironments. Numerical modeling is therefore essential to better understand,\npredict, and optimize their behavior for practical applications. In this work,\nwe present a comprehensive finite element framework based on the Arbitrary\nLagrangian--Eulerian formulation to simulate deformable elastic micro-swimmers\nin confined fluid domains. The method employs a full-order model that resolves\nthe complete fluid dynamics while simultaneously tracking swimmer deformation\nand global displacement on conforming meshes. Numerical experiments are\nperformed with the open-source finite element library Feel++, demonstrating\nexcellent agreement with experimental data from the literature. The validation\nbenchmarks in both two and three dimensions confirm the accuracy, robustness,\nand computational efficiency of the proposed framework, representing a\nfoundational step toward developing digital twins of magneto-swimmers for\nbiomedical applications.", "AI": {"tldr": "A finite element framework for simulating deformable magnetic micro-swimmers in confined fluids, validated against experimental data with high accuracy.", "motivation": "Magnetic micro-swimmers show promise for biomedical applications but are hard to control due to complex nonlinear dynamics involving magnetic actuation, elasticity, and fluid interactions in confined spaces.", "method": "Developed a comprehensive finite element framework using Arbitrary Lagrangian-Eulerian formulation to simulate deformable elastic micro-swimmers in confined fluid domains, resolving full fluid dynamics and swimmer deformation on conforming meshes.", "result": "Numerical experiments using Feel++ library showed excellent agreement with experimental data from literature. Validation benchmarks in 2D and 3D confirmed accuracy, robustness, and computational efficiency.", "conclusion": "The framework represents a foundational step toward developing digital twins of magneto-swimmers for biomedical applications."}}
{"id": "2511.02782", "pdf": "https://arxiv.org/pdf/2511.02782", "abs": "https://arxiv.org/abs/2511.02782", "authors": ["Arbaz Khan", "Felipe Lepe", "David Mora", "Ricardo Ru\u00edz-Baier", "Jesus Vellojin"], "title": "Finite element analysis for a Herrmann pressure formulation of the elastoacoustic problem with variable coefficients", "categories": ["math.NA", "cs.NA", "65N30, 65N12, 76D07, 65N15"], "comment": null, "summary": "In two and three dimensions, this study is focused on the numerical analysis\nof an eigenproblem associated with a fluid-structure model for sloshing and\nelasto-acoustic vibration. We use a displacement-Herrmann pressure formulation\nfor the solid, while for the fluid, a pure displacement formulation is\nconsidered. Under this approach we propose a non conforming locking-free method\nbased on classic finite elements to approximate the natural frequencies (of the\neigenmodes) of the coupled system. Employing the theory for non-compact\noperators we prove convergence and error estimates. Also we propose an a\nposteriori error estimator for this coupled problem which is shown to be\nefficient and reliable. All the presented theory is contrasted with a set of\nnumerical tests in 2D and 3D.", "AI": {"tldr": "Numerical analysis of fluid-structure eigenproblem for sloshing and elasto-acoustic vibration using displacement-Herrmann pressure formulation for solid and pure displacement for fluid, with non-conforming locking-free finite element method.", "motivation": "To develop an accurate numerical method for analyzing natural frequencies in coupled fluid-structure systems involving sloshing and elasto-acoustic vibration problems.", "method": "Non-conforming locking-free finite element method using displacement-Herrmann pressure formulation for solid and pure displacement formulation for fluid, with convergence proofs using non-compact operator theory and a posteriori error estimator.", "result": "Proven convergence and error estimates, efficient and reliable a posteriori error estimator, validated through 2D and 3D numerical tests.", "conclusion": "The proposed method successfully approximates natural frequencies of coupled fluid-structure systems with proven mathematical properties and practical validation."}}
{"id": "2511.02409", "pdf": "https://arxiv.org/pdf/2511.02409", "abs": "https://arxiv.org/abs/2511.02409", "authors": ["Saumyajit Das", "Tuhin Ghosh", "Susovan Pramanik"], "title": "Anisotropic Calder\u00f3n problem for a logarithmic Schr\u00f6dinger operator of order $2+$ on closed Riemannian manifolds", "categories": ["math.AP", "35S05, 58J35, 58J40"], "comment": "37 pages", "summary": "In this article, we study the anisotropic Calder\\'on problems for the non\nlocal logarithimic Schr\\\"odinger operators $(-\\Delta_g+m)\\log{(-\\Delta_g+m)}+V$\nwith $m>1$ on a closed, connected, smooth Riemannian manifold of dimension\n$n\\geq2$. We will show that, for the operator\n$(-\\Delta_g+m)\\log{(-\\Delta_g+m)}+V$, the recovery of both the Riemannian\nmetric and the potential is possible from the Cauchy data, in the setting of a\ncommon underlying manifold with varying metrics. This result is unconditional.\nThe last result can be extended to the case of setwise distinct manifolds also.\nIn particular, we demonstrate that for setwise distinct manifolds, the Cauchy\ndata associated with the operator $(-\\Delta_g+m)\\log{(-\\Delta_g+m)}+V$,\nmeasured on a suitable non-empty open subset, uniquely determines the\nRiemannian manifold up to isometry and the potential up to an appropriate gauge\ntransformation. This particular result is unconditional when the potential is\nsupported entirely within the observation set. In the more general\nsetting-where the potential may take nonzero values outside the observation\nset-specific geometric assumptions are required on both the observation set and\nthe unknown region of the manifold.", "AI": {"tldr": "The paper studies anisotropic Calder\u00f3n problems for non-local logarithmic Schr\u00f6dinger operators on Riemannian manifolds, showing that both the metric and potential can be recovered from Cauchy data.", "motivation": "To investigate whether the Riemannian metric and potential can be uniquely determined from boundary measurements (Cauchy data) for non-local logarithmic Schr\u00f6dinger operators on manifolds.", "method": "Analysis of the operator $(-\\Delta_g+m)\\log{(-\\Delta_g+m)}+V$ with $m>1$ on closed, connected Riemannian manifolds of dimension $n\\geq2$, using Cauchy data measurements.", "result": "For common underlying manifolds with varying metrics, recovery of both metric and potential from Cauchy data is unconditional. For setwise distinct manifolds, Cauchy data uniquely determines the manifold up to isometry and potential up to gauge transformation.", "conclusion": "The non-local logarithmic Schr\u00f6dinger operator enables unique recovery of geometric and potential information from boundary measurements, with unconditional results in certain cases and requiring geometric assumptions in more general settings."}}
{"id": "2511.02822", "pdf": "https://arxiv.org/pdf/2511.02822", "abs": "https://arxiv.org/abs/2511.02822", "authors": ["Sami Aljhani"], "title": "A computationally efficient fractional predictor corrector approach involving the Mittag Leffler kernel", "categories": ["math.NA", "cs.NA"], "comment": "13 Pages and two figures", "summary": "In this paper, based on Newton interpolation we have proposed a numerical\nscheme of predictor-corrector type in order to solve fractional differential\nequations with the fractional derivative involving the Mittag-Leffler function.\nWe have added an auxiliary midpoint in each sub-interval, this allows us to use\na piecewise quadratic Newton interpolation to derive the corrector scheme. The\nderivation of the schemes for the midpoint and the predictor is done by means\nof a piecewise linear Newton interpolation. We present some illustrative\nexamples for initial value problems that involve fractional derivatives in the\nsense of Atangana-Baleanu. The results of numerical experiments show that the\nproposed scheme is a powerful technique to handle fractional differential\nequations with nonlinear terms that involve operators of Atangana-Baleanu type.\nMoreover, the proposed method significantly improves the numerical accuracy in\ncomparison with other methods.", "AI": {"tldr": "A predictor-corrector numerical scheme using Newton interpolation to solve fractional differential equations with Atangana-Baleanu derivatives, featuring improved accuracy through auxiliary midpoints and piecewise quadratic interpolation.", "motivation": "To develop an accurate numerical method for solving fractional differential equations involving Mittag-Leffler function and Atangana-Baleanu fractional derivatives, which are challenging to handle numerically.", "method": "Predictor-corrector scheme using Newton interpolation with auxiliary midpoints in each sub-interval. Piecewise quadratic Newton interpolation for corrector scheme, and piecewise linear Newton interpolation for midpoint and predictor derivation.", "result": "Numerical experiments demonstrate the scheme is effective for handling fractional differential equations with nonlinear terms involving Atangana-Baleanu operators, showing significantly improved accuracy compared to other methods.", "conclusion": "The proposed predictor-corrector method with Newton interpolation and auxiliary midpoints provides a powerful and accurate technique for solving fractional differential equations with Atangana-Baleanu derivatives."}}
{"id": "2511.02511", "pdf": "https://arxiv.org/pdf/2511.02511", "abs": "https://arxiv.org/abs/2511.02511", "authors": ["Razvan Gabriel Iagar", "Ana I. Mu\u00f1oz", "Ariel S\u00e1nchez"], "title": "Self-similar blow-up solutions for the supercritical parabolic Hardy-H\u00e9non equation", "categories": ["math.AP", "math.DS"], "comment": null, "summary": "We classify the self-similar solutions presenting finite time blow-up to the\nparabolic Hardy-H\\'enon equation $$ \\partial_tu=\\Delta u+|x|^{\\sigma}u^p, \\quad\n(x,t)\\in\\mathbb{R}^N\\times(0,\\infty), $$ in dimension $N\\geq3$ and the range of\nexponents $$ \\sigma\\in(-2,\\infty), \\quad\np>p_S(\\sigma):=\\frac{N+2\\sigma+2}{N-2}. $$ We establish the \\emph{existence of\nself-similar blow-up solutions for any $p>p_S(\\sigma)$}, provided\n$\\sigma\\geq2$. Moreover, we prove that, if $k$ is any natural number and\n$\\sigma\\geq 4k-2$, the parabolic Hardy-H\\'enon equation has at least $k$\ndifferent self-similar blow-up solutions for any $p>p_S(\\sigma)$. These results\nare in a stark contrast with the standard reaction-diffusion equation $$\n\\partial_tu=\\Delta u+u^p, \\quad (x,t)\\in\\mathbb{R}^N\\times(0,\\infty), $$ for\nwhich non-existence of any self-similar solution has been established, provided\n$p$ overpasses the Lepin exponent $p_L:=1+\\frac{6}{N-10}$, $N\\geq11$.\n  For $\\sigma\\in(-2,2)$, we derive the expression of generalized Lepin\nexponents $p_L(\\sigma)$ for $\\sigma\\in(0,2)$, respectively\n$\\overline{p_L}(\\sigma)$ for $\\sigma\\in(-2,0)$, and prove existence of\nself-similar solutions with finite time blow-up for\n$p\\in(p_S(\\sigma),p_L(\\sigma))$, respectively\n$p\\in(p_S(\\sigma),\\overline{p_L}(\\sigma))$. Numerical evidence of the\noptimality of these exponents is also included.", "AI": {"tldr": "This paper classifies self-similar blow-up solutions for the parabolic Hardy-H\u00e9non equation and establishes existence results for various parameter ranges, contrasting with standard reaction-diffusion equations.", "motivation": "To understand the existence and classification of self-similar finite-time blow-up solutions for the parabolic Hardy-H\u00e9non equation, particularly contrasting with the non-existence results for standard reaction-diffusion equations.", "method": "Mathematical analysis of self-similar solutions, derivation of generalized Lepin exponents, and numerical verification of optimality.", "result": "Established existence of self-similar blow-up solutions for p > p_S(\u03c3) when \u03c3 \u2265 2, and showed that for \u03c3 \u2265 4k-2, there are at least k different self-similar blow-up solutions. For \u03c3 \u2208 (-2,2), existence is proven for p between p_S(\u03c3) and the generalized Lepin exponents.", "conclusion": "The Hardy-H\u00e9non equation exhibits rich blow-up behavior with multiple self-similar solutions, fundamentally different from standard reaction-diffusion equations where such solutions don't exist beyond the Lepin exponent."}}
{"id": "2511.01911", "pdf": "https://arxiv.org/pdf/2511.01911", "abs": "https://arxiv.org/abs/2511.01911", "authors": ["Zhiwen Li", "Cheuk Hin Ho", "Lok Ming Lui"], "title": "Variational Geometry-aware Neural Network based Method for Solving High-dimensional Diffeomorphic Mapping Problems", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.DG", "math.NA"], "comment": null, "summary": "Traditional methods for high-dimensional diffeomorphic mapping often struggle\nwith the curse of dimensionality. We propose a mesh-free learning framework\ndesigned for $n$-dimensional mapping problems, seamlessly combining variational\nprinciples with quasi-conformal theory. Our approach ensures accurate,\nbijective mappings by regulating conformality distortion and volume distortion,\nenabling robust control over deformation quality. The framework is inherently\ncompatible with gradient-based optimization and neural network architectures,\nmaking it highly flexible and scalable to higher-dimensional settings.\nNumerical experiments on both synthetic and real-world medical image data\nvalidate the accuracy, robustness, and effectiveness of the proposed method in\ncomplex registration scenarios.", "AI": {"tldr": "A mesh-free learning framework for high-dimensional diffeomorphic mapping that combines variational principles with quasi-conformal theory to ensure accurate, bijective mappings while controlling deformation quality.", "motivation": "Traditional methods for high-dimensional diffeomorphic mapping struggle with the curse of dimensionality, limiting their effectiveness in complex registration scenarios.", "method": "Proposes a mesh-free learning framework that seamlessly combines variational principles with quasi-conformal theory, regulating conformality distortion and volume distortion to ensure accurate, bijective mappings.", "result": "Numerical experiments on synthetic and real-world medical image data validate the accuracy, robustness, and effectiveness of the proposed method in complex registration scenarios.", "conclusion": "The framework is inherently compatible with gradient-based optimization and neural network architectures, making it highly flexible and scalable to higher-dimensional settings for complex mapping problems."}}
{"id": "2511.02553", "pdf": "https://arxiv.org/pdf/2511.02553", "abs": "https://arxiv.org/abs/2511.02553", "authors": ["Kristian Moring", "Christoph Scheven", "Leah Sch\u00e4tzler"], "title": "Global higher integrability for systems with $p$-growth structure in noncylindrical domains", "categories": ["math.AP", "35B65, 35K51, 35K55, 35R37"], "comment": null, "summary": "We consider the Cauchy-Dirichlet problem to systems with $p$-growth structure\nwith $1 < p < \\infty$, whose prototype is \\begin{equation*}\n  \\partial_t u- \\operatorname{div} \\big( |Du|^{p-2} Du \\big) =\n\\operatorname{div} \\left( |F|^{p-2} F \\right), \\end{equation*} in a bounded\nnoncylindrical domain $E \\subset \\mathbb{R}^{n+1}$. For $p> \\frac{2(n+1)}{n+2}$\nand domains $E$ that satisfy suitable regularity assumptions and do not grow or\nshrink too fast, we prove global higher integrability of $Du$. The result is\nalready new in the case $p=2$.", "AI": {"tldr": "The paper proves global higher integrability of the spatial gradient Du for p-growth parabolic systems in bounded noncylindrical domains, with p > 2(n+1)/(n+2).", "motivation": "To extend higher integrability results for parabolic systems with p-growth structure from cylindrical domains to more general noncylindrical domains that satisfy certain regularity conditions.", "method": "The authors consider the Cauchy-Dirichlet problem for p-growth parabolic systems in bounded noncylindrical domains, using analytical techniques to prove global higher integrability under suitable domain regularity assumptions.", "result": "Global higher integrability of Du is established for p > 2(n+1)/(n+2) in domains that are sufficiently regular and do not grow or shrink too rapidly.", "conclusion": "The work provides new higher integrability results for parabolic systems in noncylindrical domains, with the case p=2 being particularly novel and significant."}}
{"id": "2511.01927", "pdf": "https://arxiv.org/pdf/2511.01927", "abs": "https://arxiv.org/abs/2511.01927", "authors": ["Yeqiu Chen", "Ziyan Liu", "Hong Wang"], "title": "DeepContour: A Hybrid Deep Learning Framework for Accelerating Generalized Eigenvalue Problem Solving via Efficient Contour Design", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": null, "summary": "Solving large-scale Generalized Eigenvalue Problems (GEPs) is a fundamental\nyet computationally prohibitive task in science and engineering. As a promising\ndirection, contour integral (CI) methods, such as the CIRR algorithm, offer an\nefficient and parallelizable framework. However, their performance is\ncritically dependent on the selection of integration contours -- improper\nselection without reliable prior knowledge of eigenvalue distribution can incur\nsignificant computational overhead and compromise numerical accuracy. To\naddress this challenge, we propose DeepContour, a novel hybrid framework that\nintegrates a deep learning-based spectral predictor with Kernel Density\nEstimation for principled contour design. Specifically, DeepContour first\nemploys a Fourier Neural Operator (FNO) to rapidly predict the spectral\ndistribution of a given GEP. Subsequently, Kernel Density Estimation (KDE) is\napplied to the predicted spectrum to automatically and systematically determine\nproper integration contours. Finally, these optimized contours guide the CI\nsolver to efficiently find the desired eigenvalues. We demonstrate the\neffectiveness of our method on diverse challenging scientific problems. In our\nmain experiments, DeepContour accelerates GEP solving across multiple datasets,\nachieving up to a 5.63$\\times$ speedup. By combining the predictive power of\ndeep learning with the numerical rigor of classical solvers, this work pioneers\nan efficient and robust paradigm for tackling difficult generalized eigenvalue\ninvolving matrices of high dimension.", "AI": {"tldr": "DeepContour is a hybrid framework that combines deep learning with contour integral methods to efficiently solve large-scale Generalized Eigenvalue Problems by automatically optimizing integration contours.", "motivation": "Contour integral methods for solving Generalized Eigenvalue Problems are efficient but critically depend on proper contour selection, which is challenging without prior knowledge of eigenvalue distribution.", "method": "Uses Fourier Neural Operator to predict spectral distribution, applies Kernel Density Estimation to automatically determine optimal integration contours, then guides contour integral solvers with these optimized contours.", "result": "Achieves up to 5.63\u00d7 speedup in solving Generalized Eigenvalue Problems across multiple datasets compared to traditional methods.", "conclusion": "DeepContour pioneers an efficient and robust paradigm combining deep learning prediction with classical numerical solvers for high-dimensional eigenvalue problems."}}
{"id": "2511.02579", "pdf": "https://arxiv.org/pdf/2511.02579", "abs": "https://arxiv.org/abs/2511.02579", "authors": ["Yucong Huang", "Aram Karakhanyan"], "title": "A Monotonicity formula for almost self-similar suitable weak solutions to the stationary Navier-Stokes equations in $\\mathbb R^5$", "categories": ["math.AP"], "comment": null, "summary": "In this paper we show that a suitable weak solution to the stationary\nNavier-Stokes system in $\\mathbb R^5$, cannot behave like a self-similar\nfunction of degree negative one if the lower limit of the local Reynolds number\nis finite.\n  To prove the result we develop a method that uses a monotonicity formula\napproach, classification of homogenous solutions to the incompressible Euler\nequations in $\\mathbb R^5$, and a projection theorem.", "AI": {"tldr": "A suitable weak solution to the stationary Navier-Stokes system in R^5 cannot behave like a self-similar function of degree -1 if the lower limit of the local Reynolds number is finite.", "motivation": "To understand the behavior of weak solutions to the stationary Navier-Stokes equations in higher dimensions (R^5) and determine constraints on self-similar behavior.", "method": "Developed a method combining monotonicity formula approach, classification of homogeneous solutions to incompressible Euler equations in R^5, and a projection theorem.", "result": "Proved that weak solutions cannot exhibit self-similar behavior of degree -1 when the local Reynolds number has finite lower limit.", "conclusion": "The paper establishes important constraints on the possible asymptotic behavior of solutions to the stationary Navier-Stokes system in five-dimensional space."}}
{"id": "2511.01998", "pdf": "https://arxiv.org/pdf/2511.01998", "abs": "https://arxiv.org/abs/2511.01998", "authors": ["Benjamin Walder", "Daniel Toader", "Robert Nuster", "G\u00fcnther Paltauf", "Peter Burgholzer", "Gregor Langer", "Lukas Krainer", "Markus Haltmeier"], "title": "Locally-Supervised Global Image Restoration", "categories": ["cs.CV", "cs.NA", "math.NA"], "comment": null, "summary": "We address the problem of image reconstruction from incomplete measurements,\nencompassing both upsampling and inpainting, within a learning-based framework.\nConventional supervised approaches require fully sampled ground truth data,\nwhile self-supervised methods allow incomplete ground truth but typically rely\non random sampling that, in expectation, covers the entire image. In contrast,\nwe consider fixed, deterministic sampling patterns with inherently incomplete\ncoverage, even in expectation. To overcome this limitation, we exploit multiple\ninvariances of the underlying image distribution, which theoretically allows us\nto achieve the same reconstruction performance as fully supervised approaches.\nWe validate our method on optical-resolution image upsampling in photoacoustic\nmicroscopy (PAM), demonstrating competitive or superior results while requiring\nsubstantially less ground truth data.", "AI": {"tldr": "A learning-based method for image reconstruction from incomplete measurements using multiple invariances to achieve fully supervised performance with less ground truth data.", "motivation": "To address image reconstruction from fixed, deterministic sampling patterns with incomplete coverage, overcoming limitations of conventional supervised and self-supervised methods.", "method": "Exploits multiple invariances of the underlying image distribution to enable reconstruction from incomplete measurements without requiring full ground truth coverage.", "result": "Validated on optical-resolution image upsampling in photoacoustic microscopy, achieving competitive or superior results with substantially less ground truth data.", "conclusion": "The approach enables high-quality image reconstruction from incomplete measurements by leveraging distributional invariances, reducing ground truth data requirements."}}
{"id": "2511.02639", "pdf": "https://arxiv.org/pdf/2511.02639", "abs": "https://arxiv.org/abs/2511.02639", "authors": ["Vieri Benci"], "title": "Numbers and numerosities", "categories": ["math.AP"], "comment": null, "summary": "We develop new aspects of the the of numerosity theory; more exactly, we\nemphasize its relation with the ordinal numbers, cardinal numbers, hyperreal\nnumbers and surreal numbers. In particular, we combine the notion of numerosity\nwith the idea of continuum and we get a definition of Euclidean line which\nincludes all the sets of infinite numbers mentioned above.", "AI": {"tldr": "This paper explores connections between numerosity theory and various number systems (ordinal, cardinal, hyperreal, surreal numbers), and proposes a unified definition of the Euclidean line incorporating these infinite number sets.", "motivation": "To establish relationships between numerosity theory and different mathematical number systems, and to create a comprehensive definition of the Euclidean line that encompasses various types of infinite numbers.", "method": "The authors develop new aspects of numerosity theory by combining it with the concept of continuum, analyzing its connections with ordinal numbers, cardinal numbers, hyperreal numbers, and surreal numbers.", "result": "A unified definition of the Euclidean line is obtained that includes all the mentioned sets of infinite numbers, integrating numerosity theory with continuum mathematics.", "conclusion": "The paper successfully bridges numerosity theory with various infinite number systems and provides an expanded definition of the Euclidean line that incorporates ordinal, cardinal, hyperreal, and surreal numbers."}}
{"id": "2511.02053", "pdf": "https://arxiv.org/pdf/2511.02053", "abs": "https://arxiv.org/abs/2511.02053", "authors": ["Jinchao Feng", "Charles Kulick", "Sui Tang"], "title": "Data-driven Learning of Interaction Laws in Multispecies Particle Systems with Gaussian Processes: Convergence Theory and Applications", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "math.ST", "stat.TH"], "comment": "40 pages, Appendix 17 pages", "summary": "We develop a Gaussian process framework for learning interaction kernels in\nmulti-species interacting particle systems from trajectory data. Such systems\nprovide a canonical setting for multiscale modeling, where simple microscopic\ninteraction rules generate complex macroscopic behaviors. While our earlier\nwork established a Gaussian process approach and convergence theory for\nsingle-species systems, and later extended to second-order models with\nalignment and energy-type interactions, the multi-species setting introduces\nnew challenges: heterogeneous populations interact both within and across\nspecies, the number of unknown kernels grows, and asymmetric interactions such\nas predator-prey dynamics must be accommodated. We formulate the learning\nproblem in a nonparametric Bayesian setting and establish rigorous statistical\nguarantees. Our analysis shows recoverability of the interaction kernels,\nprovides quantitative error bounds, and proves statistical optimality of\nposterior estimators, thereby unifying and generalizing previous single-species\ntheory. Numerical experiments confirm the theoretical predictions and\ndemonstrate the effectiveness of the proposed approach, highlighting its\nadvantages over existing kernel-based methods. This work contributes a complete\nstatistical framework for data-driven inference of interaction laws in\nmulti-species systems, advancing the broader multiscale modeling program of\nconnecting microscopic particle dynamics with emergent macroscopic behavior.", "AI": {"tldr": "Gaussian process framework for learning interaction kernels in multi-species particle systems from trajectory data, extending previous single-species methods to handle heterogeneous populations and asymmetric interactions.", "motivation": "Multi-species systems present new challenges including heterogeneous populations, multiple unknown kernels, and asymmetric interactions like predator-prey dynamics, requiring extension of previous single-species approaches.", "method": "Nonparametric Bayesian formulation using Gaussian processes to learn interaction kernels from trajectory data, with rigorous statistical analysis including recoverability proofs and error bounds.", "result": "Established recoverability of interaction kernels, provided quantitative error bounds, proved statistical optimality of posterior estimators, and demonstrated effectiveness through numerical experiments.", "conclusion": "Provides a complete statistical framework for data-driven inference in multi-species systems, advancing multiscale modeling by connecting microscopic dynamics with emergent macroscopic behavior."}}
{"id": "2511.02702", "pdf": "https://arxiv.org/pdf/2511.02702", "abs": "https://arxiv.org/abs/2511.02702", "authors": ["Shiouhe Wang", "Fang Shen", "Yi Yang", "Xueshang Feng"], "title": "Revisited for existence proof of optimal solution in Bernoulli free boundary problem using an energy-gap cost functional", "categories": ["math.AP", "astro-ph.SR", "35R35 (Primary) 35J20 (Secondary)", "G.1.6; G.1.8"], "comment": "5 pages", "summary": "Bernoulli free boundary problem is numerically solved via shape optimization\nthat minimizes a cost functional subject to state problems constraints. In\n\\cite{1}, an energy-gap cost functional was formulated based on two auxiliary\nstate problems, with existence of optimal solution attempted through continuity\nof state problems with respect to the domain. Nevertheless, there exists a\ncorrigendum in Eq.(48) in \\cite{1}, where the boundedness of solution sequences\nfor state problems with respect to the domain cannot be directly estimated via\nthe Cauchy-Schwarz inequality as \\textbf{Claimed}. In this comment, we rectify\nthis proof by Poincar\\'e-Friedrichs inequality.", "AI": {"tldr": "This paper corrects a proof error in a previous work on Bernoulli free boundary problems solved via shape optimization, specifically fixing an incorrect application of the Cauchy-Schwarz inequality in bounding solution sequences.", "motivation": "To rectify a mathematical error in a previous paper's proof regarding the boundedness of solution sequences for state problems in shape optimization of Bernoulli free boundary problems.", "method": "The authors use the Poincar\u00e9-Friedrichs inequality to properly establish the boundedness of solution sequences with respect to domain variations, replacing the incorrect Cauchy-Schwarz inequality approach from the original paper.", "result": "Successfully corrected the proof gap in the original paper's Eq.(48), providing a mathematically sound justification for the continuity of state problems with respect to domain variations.", "conclusion": "The corrigendum properly addresses the mathematical flaw in the original proof and establishes the correct foundation for proving existence of optimal solutions in the Bernoulli free boundary shape optimization framework."}}
{"id": "2511.02093", "pdf": "https://arxiv.org/pdf/2511.02093", "abs": "https://arxiv.org/abs/2511.02093", "authors": ["Sravani Boddepalli", "Prathamesh Kothavale"], "title": "Comparative Analysis of Discrete and Continuous Action Spaces in Reservoir Management and Inventory Control Problems", "categories": ["math.OC", "cs.NA", "math.NA"], "comment": null, "summary": "This paper presents a comparative analysis of discrete and continuous action\nspaces within the contexts of reservoir management and inventory control\nproblems. We explore the computational trade-offs between discrete action\ndiscretizations and continuous action settings, focusing on their effects on\ntime complexity and space requirements across different horizons. Our analysis\nincludes a detailed evaluation of discretization levels in reservoir\nmanagement, highlighting that finer discretizations approach the performance of\ncontinuous actions but at increased computational costs. For inventory control,\nwe investigate deterministic and stochastic demand scenarios, demonstrating the\nexponential growth in time and space with increasing discrete actions and\ninventory items. We also introduce a novel symbolic approach for solving\ncontinuous problems in hybrid MDPs (H-MDPs), utilizing a new XADD data\nstructure to manage piecewise symbolic value functions. Our results underscore\nthe challenges of scaling solutions and provide insights into efficient\nhandling of discrete and continuous action spaces in complex decision problems.\nFuture research directions include exploring heuristic search methods and\nimproved approximations for enhancing the practicality of exact solutions.", "AI": {"tldr": "Comparative analysis of discrete vs continuous action spaces in reservoir management and inventory control, showing trade-offs between computational costs and performance.", "motivation": "To understand the computational trade-offs between discrete action discretizations and continuous action settings in complex decision problems like reservoir management and inventory control.", "method": "Comparative analysis of discrete and continuous action spaces, evaluation of discretization levels in reservoir management, investigation of deterministic/stochastic demand scenarios in inventory control, and introduction of symbolic approach using XADD data structure for hybrid MDPs.", "result": "Finer discretizations approach continuous action performance but with increased computational costs; exponential growth in time/space with increasing discrete actions and inventory items; symbolic approach enables solving continuous problems in hybrid MDPs.", "conclusion": "Highlights scaling challenges and provides insights for efficient handling of discrete/continuous action spaces; suggests future research on heuristic search methods and improved approximations."}}
{"id": "2511.02723", "pdf": "https://arxiv.org/pdf/2511.02723", "abs": "https://arxiv.org/abs/2511.02723", "authors": ["Changhui Tan", "Zhuan Ye"], "title": "Global well-posedness of the 2D primitive equations with fractional horizontal dissipation", "categories": ["math.AP", "35B65, 35Q35, 35Q86, 76D03"], "comment": "20 pages, 4 figures", "summary": "In this paper, we investigate the two-dimensional incompressible primitive\nequations with fractional horizontal dissipation. Specifically, we establish\nglobal well-posedness of strong solutions for arbitrarily large initial data\nwhen the dissipation exponent satisfies $\\alpha\\geq\\alpha_{0}\\approx1.1108$. In\naddition, we prove global well-posedness of strong solutions for small initial\ndata when $\\alpha \\in [1, \\alpha_0)$. Notably, the smallness assumption is\nimposed only on the $L^\\infty$ norm of the initial vorticity.", "AI": {"tldr": "Global well-posedness of 2D incompressible primitive equations with fractional horizontal dissipation is established for large initial data when \u03b1\u2265\u03b1\u2080\u22481.1108, and for small initial data when \u03b1\u2208[1,\u03b1\u2080).", "motivation": "To understand the global existence and uniqueness of strong solutions for 2D primitive equations with fractional dissipation, particularly determining the critical dissipation exponent.", "method": "Analysis of two-dimensional incompressible primitive equations with fractional horizontal dissipation, using mathematical techniques to establish well-posedness conditions.", "result": "Proved global well-posedness for arbitrarily large initial data when \u03b1\u2265\u03b1\u2080\u22481.1108, and for small initial data (with smallness only on L\u221e norm of initial vorticity) when \u03b1\u2208[1,\u03b1\u2080).", "conclusion": "The critical dissipation exponent for global well-posedness of 2D primitive equations is approximately \u03b1\u2080\u22481.1108, with different regimes for large vs small initial data."}}
{"id": "2511.02100", "pdf": "https://arxiv.org/pdf/2511.02100", "abs": "https://arxiv.org/abs/2511.02100", "authors": ["Rodrigo Mendoza-Smith"], "title": "Geometric Data Valuation via Leverage Scores", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "math.OC"], "comment": "MLxOR: Mathematical Foundations and Operational Integration of\n  Machine Learning for Uncertainty-Aware Decision-Making (NeurIPS 2025)", "summary": "Shapley data valuation provides a principled, axiomatic framework for\nassigning importance to individual datapoints, and has gained traction in\ndataset curation, pruning, and pricing. However, it is a combinatorial measure\nthat requires evaluating marginal utility across all subsets of the data,\nmaking it computationally infeasible at scale. We propose a geometric\nalternative based on statistical leverage scores, which quantify each\ndatapoint's structural influence in the representation space by measuring how\nmuch it extends the span of the dataset and contributes to the effective\ndimensionality of the training problem. We show that our scores satisfy the\ndummy, efficiency, and symmetry axioms of Shapley valuation and that extending\nthem to \\emph{ridge leverage scores} yields strictly positive marginal gains\nthat connect naturally to classical A- and D-optimal design criteria. We\nfurther show that training on a leverage-sampled subset produces a model whose\nparameters and predictive risk are within $O(\\varepsilon)$ of the full-data\noptimum, thereby providing a rigorous link between data valuation and\ndownstream decision quality. Finally, we conduct an active learning experiment\nin which we empirically demonstrate that ridge-leverage sampling outperforms\nstandard baselines without requiring access gradients or backward passes.", "AI": {"tldr": "The paper proposes geometric leverage scores as an efficient alternative to computationally expensive Shapley data valuation, showing they satisfy key axioms and provide theoretical guarantees for model quality.", "motivation": "Shapley data valuation is computationally infeasible at scale due to its combinatorial nature, requiring evaluation of all data subsets.", "method": "Propose geometric leverage scores that quantify each datapoint's structural influence in representation space by measuring how much it extends dataset span and contributes to effective dimensionality.", "result": "Leverage scores satisfy dummy, efficiency, and symmetry axioms of Shapley valuation. Ridge leverage scores provide strictly positive marginal gains and connect to classical optimal design criteria. Training on leverage-sampled subsets produces models within O(\u03b5) of full-data optimum.", "conclusion": "Leverage scores provide computationally efficient data valuation with theoretical guarantees, and empirical results show ridge-leverage sampling outperforms standard baselines in active learning without requiring gradients."}}
{"id": "2511.01944", "pdf": "https://arxiv.org/pdf/2511.01944", "abs": "https://arxiv.org/abs/2511.01944", "authors": ["Du\u0161an Oberta"], "title": "On the existence of solutions of fractional differential equations in Banach spaces", "categories": ["math.FA", "math.AP", "34G20, 34A08, 34A12, 35K92, 47H08, 65M06"], "comment": "24 pages", "summary": "Utilising the notion of measures of non-compactness and Kamke function of\norder $\\alpha$, we address the question of solvability of fractional\ndifferential equations in Banach spaces. In particular, we provide sufficient\nconditions ensuring the existence of a local solution. Our main existence\ntheorem is then applied on countable systems of fractional differential\nequations arising from semi-discretisation of fractional PDEs with\n$p$-Laplacian.", "AI": {"tldr": "The paper establishes sufficient conditions for the existence of local solutions to fractional differential equations in Banach spaces using measures of non-compactness and Kamke functions.", "motivation": "To address the solvability problem of fractional differential equations in Banach spaces, particularly for systems arising from semi-discretization of fractional PDEs with p-Laplacian.", "method": "Utilizes measures of non-compactness and Kamke functions of order \u03b1 to develop existence criteria for fractional differential equations.", "result": "Provides sufficient conditions ensuring the existence of local solutions to fractional differential equations in Banach spaces.", "conclusion": "The main existence theorem is successfully applied to countable systems of fractional differential equations derived from semi-discretization of fractional PDEs with p-Laplacian."}}
{"id": "2511.02308", "pdf": "https://arxiv.org/pdf/2511.02308", "abs": "https://arxiv.org/abs/2511.02308", "authors": ["Tapan Jana", "Amit Shaw", "L. S. Ramachandra"], "title": "Simulation of a Non-Newtonian drop impact on a rigid surface: A mess-free approach", "categories": ["physics.flu-dyn", "cs.NA", "math.NA"], "comment": null, "summary": "The present study explores the impact of a non-Newtonian fluid drop on a\nrigid surface using a mesh-free approach, Smoothed Particle Hydrodynam-ics. The\ncomplex interaction between viscous and elastic forces during drop impact may\nbe reproduced by integrating the Oldroyd-B model, which de-scribes viscoelastic\nfluids, into the developed computational framework. A suit-able boundary\ncondition is assumed for interaction between fluid and solid sur-faces. The\nongoing study examines how a droplet deforms, spreads, and recoils after an\nimpact due to its viscoelasticity. The developed computational frame-work is\nvalidated by comparing results from existing literature, providing an\nunderstanding of how viscoelasticity influences drop-impact behaviour and\nopening up new avenues for subsequent research in fluid dynamic problems.", "AI": {"tldr": "Mesh-free SPH simulation of non-Newtonian fluid drop impact using Oldroyd-B model to study viscoelastic effects on deformation, spreading, and recoil.", "motivation": "To understand complex viscous-elastic interactions during drop impact and develop computational framework for viscoelastic fluid dynamics problems.", "method": "Smoothed Particle Hydrodynamics (SPH) with Oldroyd-B viscoelastic model and suitable fluid-solid boundary conditions.", "result": "Validated computational framework reproduces drop deformation, spreading, and recoil behaviors observed in literature.", "conclusion": "The study provides insights into viscoelasticity's influence on drop impact behavior and enables future research in fluid dynamics."}}
{"id": "2511.02012", "pdf": "https://arxiv.org/pdf/2511.02012", "abs": "https://arxiv.org/abs/2511.02012", "authors": ["Zhexing Zhang"], "title": "Spectral projection estimates restricted to uniformly embedded submanifolds", "categories": ["math.DG", "math.AP", "math.SP"], "comment": null, "summary": "Let $M$ be a manifold with nonpositive sectional curvature and bounded\ngeometry, and let $\\Sigma$ be a uniformly embedded submanifold of $M.$ We\nestimate the $L^2(M)\\to L^q(\\Sigma)$ norm of a $\\log$-scale spectral projection\noperator. It is a generalization of result of X. Chen to noncompact cases. We\nalso prove sharp spectral projection estimates of spectral windows of any small\nsize restricted to nontrapped geodesics on even asymptotically hyperbolic\nsurfaces with bounded geometry and curvature pinched below 0.", "AI": {"tldr": "The paper generalizes spectral projection estimates to noncompact manifolds with nonpositive curvature and bounded geometry, and proves sharp estimates for spectral windows on nontrapped geodesics in asymptotically hyperbolic surfaces.", "motivation": "To extend previous spectral projection results by X. Chen from compact to noncompact settings, and to establish sharp estimates for spectral windows in asymptotically hyperbolic geometries.", "method": "Uses geometric analysis techniques on manifolds with nonpositive sectional curvature and bounded geometry, analyzing spectral projection operators and their L^2 to L^q norms on uniformly embedded submanifolds.", "result": "Obtained estimates for L^2(M)\u2192L^q(\u03a3) norms of log-scale spectral projection operators, and proved sharp spectral projection estimates for spectral windows of any small size on nontrapped geodesics in asymptotically hyperbolic surfaces.", "conclusion": "Successfully generalized previous results to noncompact cases and established sharp spectral projection bounds in asymptotically hyperbolic geometries with curvature constraints."}}
{"id": "2511.02329", "pdf": "https://arxiv.org/pdf/2511.02329", "abs": "https://arxiv.org/abs/2511.02329", "authors": ["Shaohan Li", "Yunpeng Shi", "Gilad Lerman"], "title": "Cycle-Sync: Robust Global Camera Pose Estimation through Enhanced Cycle-Consistent Synchronization", "categories": ["cs.CV", "cs.NA", "cs.RO", "math.NA", "stat.ME", "90C26, 90C17, 68Q87, 65C20, 90-08, 60-08", "G.1.6; I.4.0"], "comment": "NeurIPS 2025 spotlight paper", "summary": "We introduce Cycle-Sync, a robust and global framework for estimating camera\nposes (both rotations and locations). Our core innovation is a location solver\nthat adapts message-passing least squares (MPLS) -- originally developed for\ngroup synchronization -- to camera location estimation. We modify MPLS to\nemphasize cycle-consistent information, redefine cycle consistencies using\nestimated distances from previous iterations, and incorporate a Welsch-type\nrobust loss. We establish the strongest known deterministic exact-recovery\nguarantee for camera location estimation, showing that cycle consistency alone\n-- without access to inter-camera distances -- suffices to achieve the lowest\nsample complexity currently known. To further enhance robustness, we introduce\na plug-and-play outlier rejection module inspired by robust subspace recovery,\nand we fully integrate cycle consistency into MPLS for rotation\nsynchronization. Our global approach avoids the need for bundle adjustment.\nExperiments on synthetic and real datasets show that Cycle-Sync consistently\noutperforms leading pose estimators, including full structure-from-motion\npipelines with bundle adjustment.", "AI": {"tldr": "Cycle-Sync is a robust global framework for camera pose estimation that uses modified message-passing least squares with cycle consistency and robust loss functions, achieving state-of-the-art performance without bundle adjustment.", "motivation": "To develop a robust and global camera pose estimation framework that avoids the need for bundle adjustment while achieving strong theoretical guarantees and practical performance.", "method": "Adapts message-passing least squares (MPLS) for camera location estimation, emphasizes cycle-consistent information, redefines cycle consistencies using estimated distances, incorporates Welsch-type robust loss, and adds outlier rejection via robust subspace recovery.", "result": "Establishes strongest known deterministic exact-recovery guarantee for camera location estimation, shows cycle consistency alone achieves lowest known sample complexity, and outperforms leading pose estimators including full structure-from-motion pipelines with bundle adjustment.", "conclusion": "Cycle-Sync provides a robust, globally optimal camera pose estimation framework that eliminates the need for bundle adjustment while delivering superior performance through cycle consistency and robust optimization techniques."}}
{"id": "2511.02659", "pdf": "https://arxiv.org/pdf/2511.02659", "abs": "https://arxiv.org/abs/2511.02659", "authors": ["Cooper Simpson", "Stephen Becker", "Alireza Doostan"], "title": "In Situ Training of Implicit Neural Compressors for Scientific Simulations via Sketch-Based Regularization", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.NA", "math.NA"], "comment": "17 pages, 8 figures, 4 tables", "summary": "Focusing on implicit neural representations, we present a novel in situ\ntraining protocol that employs limited memory buffers of full and sketched data\nsamples, where the sketched data are leveraged to prevent catastrophic\nforgetting. The theoretical motivation for our use of sketching as a\nregularizer is presented via a simple Johnson-Lindenstrauss-informed result.\nWhile our methods may be of wider interest in the field of continual learning,\nwe specifically target in situ neural compression using implicit neural\nrepresentation-based hypernetworks. We evaluate our method on a variety of\ncomplex simulation data in two and three dimensions, over long time horizons,\nand across unstructured grids and non-Cartesian geometries. On these tasks, we\nshow strong reconstruction performance at high compression rates. Most\nimportantly, we demonstrate that sketching enables the presented in situ scheme\nto approximately match the performance of the equivalent offline method.", "AI": {"tldr": "A novel in situ training protocol using implicit neural representations with memory buffers of full and sketched data samples to prevent catastrophic forgetting, applied to neural compression with strong performance at high compression rates.", "motivation": "To address catastrophic forgetting in continual learning scenarios, particularly for in situ neural compression using implicit neural representation-based hypernetworks, by leveraging sketching as a regularizer.", "method": "In situ training protocol with limited memory buffers containing both full and sketched data samples, using sketching as a regularizer motivated by Johnson-Lindenstrauss theory, applied to implicit neural representations for compression tasks.", "result": "Strong reconstruction performance at high compression rates on complex simulation data in 2D/3D over long time horizons, across unstructured grids and non-Cartesian geometries. Sketching enables in situ performance to approximately match equivalent offline methods.", "conclusion": "Sketching effectively prevents catastrophic forgetting in continual learning scenarios, enabling in situ training to achieve performance comparable to offline methods for neural compression tasks using implicit neural representations."}}
{"id": "2511.02706", "pdf": "https://arxiv.org/pdf/2511.02706", "abs": "https://arxiv.org/abs/2511.02706", "authors": ["Deyao Chen", "Fran\u00e7ois Cl\u00e9ment", "Carola Doerr", "Nathan Kirk"], "title": "Optimizing Kernel Discrepancies via Subset Selection", "categories": ["stat.ML", "cs.CG", "cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Kernel discrepancies are a powerful tool for analyzing worst-case errors in\nquasi-Monte Carlo (QMC) methods. Building on recent advances in optimizing such\ndiscrepancy measures, we extend the subset selection problem to the setting of\nkernel discrepancies, selecting an m-element subset from a large population of\nsize $n \\gg m$. We introduce a novel subset selection algorithm applicable to\ngeneral kernel discrepancies to efficiently generate low-discrepancy samples\nfrom both the uniform distribution on the unit hypercube, the traditional\nsetting of classical QMC, and from more general distributions $F$ with known\ndensity functions by employing the kernel Stein discrepancy. We also explore\nthe relationship between the classical $L_2$ star discrepancy and its\n$L_\\infty$ counterpart.", "AI": {"tldr": "A novel subset selection algorithm for kernel discrepancies that efficiently generates low-discrepancy samples from uniform distributions and more general distributions using kernel Stein discrepancy.", "motivation": "To extend subset selection problems to kernel discrepancies for analyzing worst-case errors in quasi-Monte Carlo methods, enabling efficient generation of low-discrepancy samples from both uniform and general distributions.", "method": "Introduce a subset selection algorithm applicable to general kernel discrepancies, using kernel Stein discrepancy for general distributions with known density functions, and explore relationships between classical L2 and L\u221e star discrepancies.", "result": "The algorithm efficiently selects m-element subsets from large populations (n \u226b m) to generate low-discrepancy samples for both traditional QMC settings and more general distributions.", "conclusion": "The proposed method provides a powerful framework for subset selection in kernel discrepancy settings, bridging classical QMC approaches with modern kernel methods for improved sample generation across various distributions."}}
{"id": "2511.02751", "pdf": "https://arxiv.org/pdf/2511.02751", "abs": "https://arxiv.org/abs/2511.02751", "authors": ["Hao Luo", "Qiaoyuan Shu", "Xinmin Yang"], "title": "An accelerated primal-dual gradient flow for linearly constrained multiobjective optimization", "categories": ["math.OC", "cs.NA", "math.NA", "90C29, 90C30"], "comment": null, "summary": "In this paper, we propose a continuous-time primal-dual approach for linearly\nconstrained multiobjective optimization problems. A novel dynamical model,\ncalled accelerated multiobjective primal-dual flow, is presented with a\nsecond-order equation for the primal variable and a first-order equation for\nthe dual variable. It can be viewed as an extension of the accelerated\nprimal-dual flow by Luo [arXiv:2109.12604, 2021] for the single objective case.\nTo facilitate the convergence rate analysis, we introduce a new merit function,\nwhich motivates the use of the feasibility violation and the objective gap to\nmeasure the weakly Pareto optimality. By using a proper Lyapunov function, we\nestablish the exponential decay rate in the continuous level. After that, we\nconsider an implicit-explicit scheme, which yields an accelerated\nmultiobjective primal-dual method with a quadratic subproblem, and prove the\nsublinear rates of the feasibility violation and the objective gap, under the\nconvex case and the strongly convex case, respectively. Numerical results are\nprovided to demonstrate the performance of the proposed method.", "AI": {"tldr": "Proposes a continuous-time primal-dual approach for multiobjective optimization with exponential convergence rates and numerical validation.", "motivation": "Extend accelerated primal-dual methods from single to multiobjective optimization to handle multiple conflicting objectives efficiently.", "method": "Develops an accelerated multiobjective primal-dual flow with second-order primal and first-order dual equations, using Lyapunov analysis and implicit-explicit discretization.", "result": "Establishes exponential decay in continuous time and sublinear convergence rates for feasibility violation and objective gap in discrete implementation.", "conclusion": "The method effectively solves multiobjective problems with theoretical guarantees and practical performance demonstrated through numerical experiments."}}
