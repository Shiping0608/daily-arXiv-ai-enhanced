<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 12]
- [math.AP](#math.AP) [Total: 14]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 2]
- [eess.SY](#eess.SY) [Total: 1]
- [astro-ph.CO](#astro-ph.CO) [Total: 1]
- [quant-ph](#quant-ph) [Total: 3]
- [math-ph](#math-ph) [Total: 1]
- [math.SP](#math.SP) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 3]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [math.OC](#math.OC) [Total: 2]
- [cs.CV](#cs.CV) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Long-term behaviour of symmetric partitioned linear multistep methods II. Invariants error analysis for some nonlinear dispersive wave models](https://arxiv.org/abs/2511.02921)
*Begoña Cano,Angel Durán,Melquíades Rodríguez*

Main category: math.NA

TL;DR: Analysis of partitioned linear multistep methods (PLMM) for time integration in nonlinear dispersive PDEs, focusing on solitary wave solutions and extending to general localized solutions.


<details>
  <summary>Details</summary>
Motivation: To study the effectiveness of PLMMs as time integrators for numerical approximation of partial differential equations, particularly nonlinear dispersive wave models with periodic initial-value problems.

Method: Uses pseudospectral methods for spatial discretization and applies PLMM theory from previous work to analyze time integration of semidiscrete equations for solitary wave solutions, supplemented with numerical experiments.

Result: The paper demonstrates the application of PLMM theory to analyze time integration of semidiscrete equations and presents numerical experiments illustrating the results.

Conclusion: PLMMs are effective time integrators for approximating solitary wave solutions in nonlinear dispersive PDEs, with potential extensions to more general localized solutions as explored computationally.

Abstract: In this paper, the use of partitioned linear multistep methods (PLMM) as time
integrators for the numerical approximation of some partial differential
equations (pdes) is studied. We consider the periodic initial-value problem of
two nonlinear dispersive wave models as case studies. From the spatial
discretization with pseudospectral methods, the theory developed for PLMMs by
the authors in a previous companion paper is applied to analyze the time
integration with PLMMs of the semidiscrete equations when approximating
solitary wave solutions. The results are illustrated with some numerical
experiments. In addition, a computational study is performed in an exploratory
fashion to analyze the extension of the results to the approximation of more
general localized solutions.

</details>


### [2] [Read Between the Hyperplanes: On Spectral Projection and Sampling Approaches to Randomized Kaczmarz](https://arxiv.org/abs/2511.03055)
*James Nguyen,Oleg Presnyakov,Aditya Radhakhrishnan*

Main category: math.NA

TL;DR: The paper analyzes Randomized Kaczmarz (RK) method for ill-conditioned overdetermined linear systems, proposing three techniques to improve convergence: projecting onto row differences, sampling from orthogonal row clusters, and prioritizing spectrally-diverse rows.


<details>
  <summary>Details</summary>
Motivation: To address slow convergence of Randomized Kaczmarz method for ill-conditioned overdetermined linear systems by leveraging inter-row relationships and directional awareness in projections.

Method: Three proposed techniques: (1) projecting onto pairwise row differences, (2) sampling from partitioned clusters of nearly orthogonal rows, and (3) more frequently sampling spectrally-diverse rows.

Result: The proposed methods achieve improved convergence rates compared to standard Randomized Kaczmarz.

Conclusion: Leveraging inter-row relationships through directional projections and strategic row sampling significantly enhances convergence performance for ill-conditioned overdetermined linear systems.

Abstract: Among recent developments centered around Randomized Kaczmarz (RK), a
row-sampling iterative projection method for large-scale linear systems,
several adaptions to the method have inspired faster convergence. Focusing
solely on ill-conditioned and overdetermined linear systems, we highlight
inter-row relationships that can be leveraged to guide directionally aware
projections. In particular, we find that improved convergence rates can be made
by (i) projecting onto pairwise row differences, (ii) sampling from partitioned
clusters of nearly orthogonal rows, or (iii) more frequently sampling
spectrally-diverse rows.

</details>


### [3] [Parametric Hierarchical Matrix Approximations to Kernel Matrices](https://arxiv.org/abs/2511.03109)
*Abraham Khan,Chao Chen,Vishwas Rao,Arvind K. Saibaba*

Main category: math.NA

TL;DR: Introduces parametric hierarchical matrices that efficiently handle kernel matrices with hyperparameters, enabling fast online instantiation without new kernel evaluations.


<details>
  <summary>Details</summary>
Motivation: Standard hierarchical matrices don't account for kernel matrix hyperparameter dependence, requiring repeated computations when optimizing hyperparameters in applications like Gaussian processes.

Method: Uses offline-online paradigm: offline stage approximates blocks via polynomial approximation and tensor compression; online stage efficiently instantiates parametric matrices for specific hyperparameters as standard hierarchical matrices.

Result: Achieves over 100× speedups compared to existing techniques, with comparable offline costs but much more efficient online computation requiring no new kernel evaluations.

Conclusion: Parametric hierarchical matrices provide an efficient framework for handling parameter-dependent kernel matrices, significantly accelerating hyperparameter optimization tasks.

Abstract: Kernel matrices are ubiquitous in computational mathematics, often arising
from applications in machine learning and scientific computing. In two or three
spatial or feature dimensions, such problems can be approximated efficiently by
a class of matrices known as hierarchical matrices. A hierarchical matrix
consists of a hierarchy of small near-field blocks (or sub-matrices) stored in
a dense format and large far-field blocks approximated by low-rank matrices.
Standard methods for forming hierarchical matrices do not account for the fact
that kernel matrices depend on specific hyperparameters; for example, in the
context of Gaussian processes, hyperparameters must be optimized over a fixed
parameter space. We introduce a new class of hierarchical matrices, namely,
parametric (parameter-dependent) hierarchical matrices. Members of this new
class are parametric $\mathcal{H}$-matrices and parametric
$\mathcal{H}^{2}$-matrices. The construction of a parametric hierarchical
matrix follows an offline-online paradigm. In the offline stage, the near-field
and far-field blocks are approximated by using polynomial approximation and
tensor compression. In the online stage, for a particular hyperparameter, the
parametric hierarchical matrix is instantiated efficiently as a standard
hierarchical matrix. The asymptotic costs for storage and computation in the
offline stage are comparable to the corresponding standard approaches of
forming a hierarchical matrix. However, the online stage of our approach
requires no new kernel evaluations, and the far-field blocks can be computed
more efficiently than standard approaches. {Numerical experiments show over
$100\times$ speedups compared with existing techniques.}

</details>


### [4] [Efficient linear schemes for a penalized ternary Cahn-Hilliard system](https://arxiv.org/abs/2511.03111)
*Justin Swain,Giordano Tierra*

Main category: math.NA

TL;DR: Novel numerical schemes for penalized ternary Cahn-Hilliard system with extensions to multi-component systems, featuring linear decoupled first-order, conditionally stable modified, and linear coupled second-order methods.


<details>
  <summary>Details</summary>
Motivation: To create accurate and efficient numerical schemes for interfacial dynamics with three or more components in the ternary Cahn-Hilliard system.

Method: Three numerical schemes: 1) linear, decoupled, first-order accurate, unconditionally energy stable; 2) conditionally energy stable modification with reduced computational cost; 3) linear, second-order accurate with coupled unknowns.

Result: Comprehensive numerical simulations in 2D and 3D demonstrating scheme performance and cost-benefit analysis for energy-stability, efficiency, and accuracy.

Conclusion: Multiple numerical schemes developed with different trade-offs between stability, computational cost, and accuracy for multi-component interfacial dynamics.

Abstract: In this work we introduce novel numerical schemes for a penalized version of
the ternary Cahn-Hilliard system for the purpose of creating accurate and
efficient numerical schemes of interfacial dynamics with three components as
well as some results extending these ideas to systems with four or more
components. The first scheme is linear, decoupled, first order accurate, and
unconditionally energy stable. Next, we present a second scheme which is a
conditionally energy stable modification of the first scheme, but has greatly
reduced computational cost. Finally, we present a third scheme which is linear
and second order accurate but the unknowns are coupled. Moreover, we present
several numerical simulations in two and three dimensions to give a
comprehensive overview of each scheme and the cost-benefit analysis associated
with designing a method for energy-stability, efficiency, and accuracy.

</details>


### [5] [The isogeometric boundary element algorithm for solving the plane strain problem of an elastic matrix containing an open material surface of arbitrary shape](https://arxiv.org/abs/2511.03141)
*Rohit Satish Patil,Zhilin Han,Sofia G. Mogilevskaya*

Main category: math.NA

TL;DR: IGABEM algorithm for plane strain problems with material surfaces using Gurtin-Murdoch model, solved via boundary integral equations and NURBS approximation.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient numerical method for solving plane strain problems involving isotropic elastic matrices with arbitrary-shaped material surfaces.

Method: Isogeometric Boundary Element Method (IGABEM) using NURBS to approximate unknown traction jumps and surface stress components, reducing the problem to singular boundary integral equations.

Result: Algorithm validated with benchmark problems (straight segment and circular arc), showing convergence and capability to analyze curvature effects on material behavior.

Conclusion: IGABEM provides an effective framework for analyzing elastic matrices with material surfaces, with curvature variation being a significant parameter influencing the results.

Abstract: The paper presents the Isogeometric Boundary Element Method (IGABEM)
algorithm for solving the plane strain problem of an isotropic linearly elastic
matrix containing an open material surface of arbitrary shape. Theoretical
developments are based on the use of the Gurtin-Murdoch model of material
surfaces. The governing equations and the boundary conditions for the problem
are reviewed, and analytical integral representations for the elastic fields
everywhere in the material system are presented in terms of unknown traction
jumps across the surface. To find the jumps, the problem is reduced to a system
of singular boundary integral equations in terms of two unknown scalar
components of the surface stress tensor. The system is solved numerically using
the developed IGABEM algorithm in which NURBS are used to approximate the
unknowns. The main steps of the algorithm are discussed and convergence studies
are performed. The algorithm is validated using two benchmark problems
involving the matrix subjected to a uniform far-field load and containing a
surface along (i) a straight segment and (ii) a circular arc. Numerical
examples are presented to illustrate the influence of governing parameters with
a focus on the influence of curvature variation.

</details>


### [6] [Computing the nearest $Ω$-admissible descriptor dissipative Hamiltonian system](https://arxiv.org/abs/2511.03265)
*Vaishali Aggarwal,Nicolas Gillis,Punit Sharma*

Main category: math.NA

TL;DR: This paper provides a dissipative Hamiltonian characterization for matrix pairs that are Ω-admissible (regular, impulse-free with eigenvalues in LMI region Ω), and solves the nearest Ω-admissible matrix pair problem.


<details>
  <summary>Details</summary>
Motivation: To characterize and find the nearest Ω-admissible matrix pairs, which are important in control theory for stability analysis and system design.

Method: Develops a dissipative Hamiltonian characterization for Ω-admissible matrix pairs in LMI regions, then uses this to solve the nearest Ω-admissible matrix pair problem.

Result: Provides theoretical characterization and computational method for finding nearest Ω-admissible matrix pairs, with experimental validation on datasets.

Conclusion: The proposed approach effectively solves the nearest Ω-admissible matrix pair problem and shows competitive performance compared to state-of-the-art methods.

Abstract: For a given set $\Omega \subseteq \mathbb{C}$, a matrix pair $(E,A)$ is
called $\Omega$-admissible if it is regular, impulse-free and its eigenvalues
lie inside the region $\Omega$. In this paper, we provide a dissipative
Hamiltonian characterization for the matrix pairs that are $\Omega$-admissible
where $\Omega$ is an LMI region. We then use these results for solving the
nearest $\Omega$-admissible matrix pair problem: Given a matrix pair $(E,A)$,
find the nearest $\Omega$-admissible pair $(\tilde E, \tilde A)$ to the given
pair $(E,A)$. We illustrate our results on several data sets and compare with
the state of the art.

</details>


### [7] [A Spectral Split-Step Padé Method for Guided Wave Propagation](https://arxiv.org/abs/2511.03343)
*Daniel Walsken,Pavel Petrov,Matthias Ehrhardt*

Main category: math.NA

TL;DR: A Fourier-based split-step Padé method using discrete sine transform replaces finite differences for solving parabolic wave equations in ocean acoustics, achieving higher accuracy with fewer discretization points and better handling of sharp field features.


<details>
  <summary>Details</summary>
Motivation: Traditional finite-difference SSP methods have limitations in accuracy with coarse discretizations and computational efficiency in dense discretizations due to poor parallelization benefits.

Method: Uses spectral representation with discrete sine transform (DST) for exact treatment of vertical operator under homogeneous boundary conditions, and Neumann series expansion for non-constant sound speed to treat inhomogeneities as perturbations.

Result: Numerical experiments show high accuracy in range-independent and range-dependent scenarios including deep ocean with Munk profile and parametrized synoptic eddy. Achieves higher accuracy with fewer depth discretization points compared to finite-difference methods.

Conclusion: The Fourier-based approach avoids resolution bottlenecks associated with sharp field features and is well-suited for large-scale, high-frequency wave propagation problems in ocean environments.

Abstract: In this study, a Fourier-based, split-step Pad\'e (SSP) method for solving
the parabolic wave equation with applications in guided wave propagation in
ocean acoustics is presented. Traditional SSP implementations rely in
finite-difference discretizations of the depth-dependent differential operator.
This approach limits accuracy in coarse discretizations as well as
computational efficiency in dense discretizations since it does not
significantly benefit from parallelization. In contrast, our proposed method
replaces finite differences with a spectral representation using the discrete
sine transform (DST). This enables an exact treatment of the vertical operator
under homogeneous boundary conditions. For non-constant sound speed, we use a
Neumann series expansion to treat inhomogeneities as perturbations. Numerical
experiments demonstrate the method's accuracy in range-independent media and
rage-dependent scenarios, including propagation in deep ocean with Munk profile
and in the presence of a parametrized synoptic eddy. Compared to
finite-difference SSP methods, the Fourier-based approach achieves higher
accuracy with fewer depth discretization points and avoids the resolution
bottleneck associated with sharp field features, making it well-suited for
large-scale, high-frequency wave propagation problems in ocean environments.

</details>


### [8] [A New Algorithm for Computing the Stabilizing Solution of General Periodic Time-Varying Stochastic Game-Theoretic Riccati Differential Equations](https://arxiv.org/abs/2511.03390)
*Yiyuan Wang*

Main category: math.NA

TL;DR: A new dual-layer iterative algorithm for solving periodic time-varying Stochastic Game-Theoretic Riccati Differential Equations in Zero-Sum Linear-Quadratic Stochastic Differential Games.


<details>
  <summary>Details</summary>
Motivation: To provide a unified numerical framework for solving a broader class of periodic time-varying Stochastic Game-Theoretic Riccati Differential Equations that arise in zero-sum linear-quadratic stochastic differential games.

Method: Dual-layer matrix-valued functions iteration sequences that reformulate the original problem into interconnected bilevel subproblems, computing maximal periodic solutions to associated Riccati differential equations.

Result: The algorithm successfully derives stabilizing periodic solutions for the original problem, with rigorous convergence proof and numerical verification of effectiveness and stability.

Conclusion: The study presents an effective and stable numerical framework for solving periodic time-varying Stochastic Game-Theoretic Riccati Differential Equations, extending applicability to a wider range of problems.

Abstract: We propose a new algorithm for a broad class of periodic time-varying
Stochastic Game-Theoretic Riccati Differential Equations arising in Zero-Sum
Linear-Quadratic Stochastic Differential Games. The algorithm is constructed
via dual-layer matrix-valued functions iteration sequences, which reformulate
the original problem into a set of interconnected bilevel subproblems. By
sequentially computing the maximal periodic solutions to the Riccati
differential equations associated with each subproblem, we derive the
stabilizing periodic solutions for the original problem and rigorously prove
the algorithm's convergence. Numerical experiments verifies algorithm
effectiveness and stability. This study provides a unified numerical framework
for solving a wider range of periodic time-varying Stochastic Game-Theoretic
Riccati Differential Equations.

</details>


### [9] [Model order reduction via Lie groups](https://arxiv.org/abs/2511.03520)
*Yannik P. Wotte,Patrick Buchfink,Silke Glas,Federico Califano,Stefano Stramigioli*

Main category: math.NA

TL;DR: MORLie is a novel model order reduction framework that uses Lie groups to approximate high-dimensional dynamical systems on manifolds with low-dimensional systems on Lie groups, outperforming traditional linear methods and handling non-equivariant dynamics.


<details>
  <summary>Details</summary>
Motivation: Lie groups are fundamental in describing physical systems, but existing MOR methods struggle with non-equivariant dynamics common in practical applications. Current approaches are limited by linear-subspace constraints and cannot efficiently handle manifold-based systems.

Method: MORLie approximates high-dimensional dynamical systems on manifolds using low-dimensional dynamical systems on Lie groups. It provides non-intrusive MOR methods based on geometric formulation and can handle non-equivariant dynamics that traditional Lie group methods cannot address.

Result: MORLie achieves lower error bounds than the Kolmogorov N-width that limits linear-subspace methods. Applications show: 1) Better accuracy and dimensionality reduction than POD for deforming bodies; 2) Comparable performance to state-of-the-art for liver motion reconstruction with much faster training (minutes vs hours); 3) Analytically recovers the freezing method as a special case.

Conclusion: MORLie provides a general geometric framework for model order reduction that effectively handles non-equivariant dynamics on manifolds, outperforms linear methods, and offers significant computational advantages while maintaining high accuracy.

Abstract: Lie groups and their actions are ubiquitous in the description of physical
systems, and we explore implications in the setting of model order reduction
(MOR). We present a novel framework of MOR via Lie groups, called MORLie, in
which high-dimensional dynamical systems on manifolds are approximated by
low-dimensional dynamical systems on Lie groups. In comparison to other Lie
group methods we are able to attack non-equivariant dynamics, which are
frequent in practical applications, and we provide new non-intrusive MOR
methods based on the presented geometric formulation. We also highlight
numerically that MORLie has a lower error bound than the Kolmogorov $N$-width,
which limits linear-subspace methods. The method is applied to various
examples: 1. MOR of a simplified deforming body modeled by a noisy point cloud
data following a sheering motion, where MORLie outperforms a naive POD approach
in terms of accuracy and dimensionality reduction. 2. Reconstructing liver
motion during respiration with data from edge detection in ultrasound scans,
where MORLie reaches performance approaching the state of the art, while
reducing the training time from hours on a computing cluster to minutes on a
mobile workstation. 3. An analytic example showing that the method of freezing
is analytically recovered as a special case, showing the generality of the
geometric framework.

</details>


### [10] [Adaptive Randomized Tensor Train Rounding using Khatri-Rao Products](https://arxiv.org/abs/2511.03598)
*Hussam Al Daas,Grey Ballard,Laura Grigori,Mariana Martinez Aguilar,Arvind K. Saibaba,Bhisham Dev Verma*

Main category: math.NA

TL;DR: Proposes randomized algorithms using Khatri-Rao product sketches for adaptive tensor train rounding with theoretical guarantees and up to 50× speed-up over deterministic methods.


<details>
  <summary>Details</summary>
Motivation: Tensor train (TT) format approximation is important for scientific computing, and existing rounding methods need improvement for efficiency and adaptivity to user-specified tolerances.

Method: Uses randomized algorithms with Khatri-Rao product sketches for TT-rounding, enabling adaptive compression within fixed user-specified tolerance with theoretical error estimation guarantees.

Result: Achieves up to 50× speed-up compared to deterministic TT-rounding on synthetic tensors, parametric low-rank kernel approximations, and PDE solutions, with adaptive algorithms showing competitive performance to fixed-rank methods.

Conclusion: KRP-based randomized TT-rounding provides significant computational advantages while maintaining accuracy, with adaptive algorithms introducing minimal overhead compared to fixed-rank approaches.

Abstract: Approximating a tensor in the tensor train (TT) format has many important
applications in scientific computing. Rounding a TT tensor involves further
compressing a tensor that is already in the TT format. This paper proposes new
randomized algorithms for TT-rounding that uses sketches based on Khatri-Rao
products (KRP). When the TT-ranks are known in advance, the proposed methods
are comparable in cost to the sketches that used a sketching matrix in the
TT-format~\cite{al2023randomized}. However, the use of KRP sketches enables
adaptive algorithms to round the tensor in the TT-format within a fixed
user-specified tolerance. An important component of the adaptivity is the
estimation of error using KRP sketching, for which we develop theoretical
guarantees. We report numerical experiments on synthetic tensors, parametric
low-rank kernel approximations, and the solution of parametric partial
differential equations. The numerical experiments show that we obtain speed-ups
of up to $50\times$ compared to deterministic TT-rounding. Both the
computational cost analysis and numerical experiments verify that the adaptive
algorithms are competitive with the fixed rank algorithms, suggesting the
adaptivity introduces only a low overhead.

</details>


### [11] [SIMD-vectorized implicit symplectic integrators can outperform explicit ones](https://arxiv.org/abs/2511.03655)
*Mikel Antoñana,Joseba Makazaga,Ander Murua*

Main category: math.NA

TL;DR: SIMD-vectorized implementation of 16th-order implicit Runge-Kutta integrator (IRKGL16-SIMD) outperforms state-of-the-art explicit symplectic methods for high-precision Hamiltonian ODE systems.


<details>
  <summary>Details</summary>
Motivation: To enhance performance of sequential implicit Runge-Kutta integrators through SIMD parallelism while maintaining high precision for Hamiltonian ODE systems.

Method: Developed a SIMD-vectorized implementation of the 16th-order 8-stage implicit Runge-Kutta integrator using Gauss-Legendre nodes, leveraging Single Instruction Multiple Data parallelism transparently to users.

Result: IRKGL16-SIMD significantly outperforms state-of-the-art high-order explicit symplectic methods in numerical experiments with various Hamiltonian systems using double-precision arithmetic.

Conclusion: SIMD-vectorized implicit Runge-Kutta integrators can achieve superior performance over explicit methods for high-precision numerical integration of non-stiff Hamiltonian ODE systems.

Abstract: The main purpose of this work is to present a SIMD-vectorized implementation
of the symplectic 16th-order 8-stage implicit Runge-Kutta integrator based on
collocation with Gauss-Legendre nodes (IRKGL16-SIMD), and to show that it can
outperform state-of-the-art symplectic explicit integrators for high-precision
numerical integrations (in double-precision floating-point arithmetic) of
non-stiff Hamiltonian ODE systems. Our IRKGL16-SIMD integrator leverages Single
Instruction Multiple Data (SIMD) based parallelism (in a way that is
transparent to the user) to significantly enhance the performance of the
sequential IRKGL16 implementation. We present numerical experiments comparing
IRKGL16-SIMD with state-of-the-art high-order explicit symplectic methods for
the numerical integration of several Hamiltonian systems in double-precision
floating-point arithmetic.

</details>


### [12] [Left Inverses for B-spline Subdivision Matrices in Tensor-Product Spaces](https://arxiv.org/abs/2511.03658)
*Marcelo Actis,Silvano Figueroa,Eduardo M. Garau*

Main category: math.NA

TL;DR: Study of dyadic coarsening operators in spline spaces using local least squares for efficient approximation.


<details>
  <summary>Details</summary>
Motivation: To develop computationally efficient local operators that provide approximations comparable to global L2-best approximation in spline spaces.

Method: Construction of local dyadic coarsening operators in univariate and tensor-product spline spaces over uniform grids, inspired by Bartels, Golub, and Samavati's work on local least squares.

Result: The proposed operators yield approximations comparable to global L2-best approximation while being significantly faster to compute and computationally inexpensive.

Conclusion: Local dyadic coarsening operators provide an efficient alternative to global methods for spline approximation, maintaining quality while reducing computational cost.

Abstract: In this article, we study dyadic coarsening operators in univariate spline
spaces and in tensor-product spline spaces over uniform grids. Our construction
is strongly motivated by the work of Bartels, Golub, and Samavati (2006), Some
observations on local least squares, BIT, 46(3):455--477. The proposed
operators are local in nature and yield approximations to a given spline that
are comparable to the global L2-best approximation, while being significantly
faster to compute and computationally inexpensive.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [13] [Well-posedness for 2D non-homogeneous incompressible fluids with general density-dependent odd viscosity](https://arxiv.org/abs/2511.02948)
*Matthieu Pageard*

Main category: math.AP

TL;DR: Local existence and uniqueness of strong solutions for 2D non-homogeneous incompressible fluids with odd viscosity effects, generalizing previous results to density-dependent viscosity coefficients.


<details>
  <summary>Details</summary>
Motivation: To extend the analysis of odd viscosity effects in 2D non-homogeneous incompressible fluids beyond the specific case of linear density dependence (f(ρ)=ρ) and relax the requirement on initial density variation.

Method: Proving local existence and uniqueness of strong solutions in H^s(R^2) (s>2) by exhibiting an effective velocity that generalizes the Elsässer formulation, for a class of viscosity coefficients including f(ρ)=aρ^α+b.

Result: Established local existence and uniqueness of strong solutions without requiring initial density variation to belong to L^2(R^2), covering general density-dependent viscosity coefficients.

Conclusion: The study successfully extends previous results on odd viscosity systems to more general density-dependent viscosity coefficients and relaxed initial conditions, providing a broader mathematical framework for analyzing such fluid systems.

Abstract: We study the initial value problem for a system of equations describing the
motion of two-dimensional non-homogeneous incompressible fluids exhibiting odd
(non-dissipative) viscosity effects. We consider the complete odd viscous
stress tensor with a general density-dependent viscosity coefficient $f(\rho)$.
Under suitable assumptions, we prove the local existence and uniqueness of
strong solutions in $H^s(\mathbb{R}^2)$ $(s>2)$, for a class of viscosity
coefficients covering the particular case $f(\rho)=a\rho^\alpha+b$ for any
$(a,b,\alpha)\in\mathbb{R}^3$, generalising the result of Fanelli,
Granero-Belinch\'on and Scrobogna, devoted to the case $f(\rho)=\rho$.
Additionally, we are able to do so without requiring the initial density
variation to belong to $L^2(\mathbb{R}^2)$. As a major step of the proof, we
exhibit an effective velocity for this sytem, generalising the so-called
"Els\"asser formulation" recently derived by Fanelli and Vasseur.

</details>


### [14] [Spectral analysis, maximum principles and shape optimization for nonlinear superposition operators of mixed fractional order](https://arxiv.org/abs/2511.02978)
*Yergen Aikyn,Sekhar Ghosh,Vishvesh Kumar,Michael Ruzhansky*

Main category: math.AP

TL;DR: This paper studies spectral properties, maximum principles, and shape optimization for nonlinear superposition operators involving mixed fractional order operators, including fractional p-Laplacians with different orders and signs.


<details>
  <summary>Details</summary>
Motivation: To develop a unified framework for analyzing spectral properties of mixed local/nonlocal operators and superposition operators that encompass various fractional p-Laplacians with different orders and signs.

Method: Variational techniques, introducing nonlocal tail concept for superposition operators, deriving logarithmic estimates, and using mountain pass characterization for eigenvalues.

Result: Established maximum principles, proved first eigenvalue is isolated, showed eigenfunctions are bounded and change sign for higher eigenvalues, provided mountain pass characterization for second eigenvalue, and addressed Faber-Krahn inequality.

Conclusion: Developed comprehensive spectral theory for superposition operators with mixed fractional orders, establishing fundamental properties like maximum principles, eigenvalue isolation, and shape optimization results.

Abstract: The main objective of this paper is to investigate the spectral properties,
maximum principles, and shape optimization problems for a broad class of
nonlinear ``superposition operators" defined as continuous superpositions of
operators of mixed fractional order, modulated by a signed finite Borel measure
on the unit interval. This framework encompasses, as particular cases, mixed
local and nonlocal operators such as $-\Delta_p+(-\Delta_p)^s$, finite
(possibly infinite) sums of fractional $p$-Laplacians with different orders, as
well as operators involving fractional Laplacians with ``wrong" signs.
  The main findings, obtained through variational techniques, concern the
spectral analysis of the Dirichlet eigenvalue problem associated with general
superposition operators with special emphasis on various properties of the
first eigenvalue and its corresponding eigenfunction.
  We establish weak and strong maximum principles for positive superposition
operators by introducing an appropriate notion of the {\it nonlocal tail} for
this class of superposition operators and deriving a logarithmic estimate, both
of which are of independent interest. Utilizing these newly developed tools, we
further investigate the spectral properties of such superposition operators and
prove that the first eigenvalue is isolated. Moreover, we show that the
eigenfunctions corresponding to positive eigenvalues are globally bounded and
that they change sign when associated with higher eigenvalues. In addition, we
demonstrate that the second eigenvalue is well-defined and provide the mountain
pass characterization.
  Finally, we address shape optimization problems, in particular, the
Faber--Krahn inequality associated with the principal frequency associated with
the superposition operators.

</details>


### [15] [On Hydrodynamic Implosions and the Landau-Coulomb Equation](https://arxiv.org/abs/2511.03033)
*William Golding,Christopher Henderson*

Main category: math.AP

TL;DR: A new continuation criterion for the inhomogeneous Landau equation with Coulomb potential: smooth solutions can be uniquely continued as long as they remain bounded, without requiring control of mass density.


<details>
  <summary>Details</summary>
Motivation: To establish the first continuation criterion not based on mass density control and rule out potential singularity formation scenarios like tail fattening and Type II blow-up rates.

Method: Derived a new continuation criterion for the inhomogeneous Landau equation with Coulomb potential, analyzing singularity formation scenarios and their relationship to hydrodynamic limits.

Result: Successfully ruled out tail fattening scenarios and almost all Type II approximately self-similar blow-up rates without requiring decay assumptions on inner profiles.

Conclusion: The findings suggest it should be impossible to use the hydrodynamic limit connection with 3D compressible Euler equations to construct singular solutions to the Landau equation with Coulomb potential.

Abstract: We study the inhomogeneous Landau equation with Coulomb potential and derive
a new continuation criterion: a smooth solution can be uniquely continued for
as long as it remains bounded. This provides, to our knowledge, the first
continuation criterion based on a quantity not controlling the mass density.
Consequently, we are able to rule out a potential singularity formation
scenario known as tail fattening, in which an implosion occurs due to the loss
of decay at large velocities.
  More generally, we are able to rule out almost all Type II approximately
self-similar blow-up rates, without any assumption of decay on the inner
profile, complementing existing Type I blow-up analysis in the literature.
Heuristically, this suggests that it should be impossible to directly use the
hydrodynamic limit connection with the 3D compressible Euler equations to
construct a singular solution to the Landau equation with Coulomb potential.
Such a potential implosion scenario -- based on either an isentropic or
non-isentropic implosion for the 3D Euler equations -- would naturally result
in a Type II approximately self-similar blow-up scenario, falling well within
the range our theorem.

</details>


### [16] [Note on the Rate of Vortex Stretching for Axisymmetric Euler Flows Without Swirl](https://arxiv.org/abs/2511.03171)
*Daomin Cao,Junhong Fan,Guolin Qin*

Main category: math.AP

TL;DR: The paper investigates Childress's conjecture on vorticity growth for axisymmetric swirl-free Euler flows, obtaining improved lower bounds for vorticity maximum growth in 3D flows with fast initial decay.


<details>
  <summary>Details</summary>
Motivation: To address Childress's conjecture about vorticity growth rates in axisymmetric Euler flows, particularly for head-on collision scenarios of anti-parallel vortex rings.

Method: Introduces generalized vertical moment and proves its monotonicity to derive lower bounds for vorticity maximum growth, focusing on flows with non-positive axial vorticity in upper half space that are odd in the last coordinate.

Result: For 3D flows with sufficiently fast initial decay in z-direction, obtains a lower bound of t^(1/2)- for vorticity maximum growth, improving upon existing results.

Conclusion: The generalized vertical moment approach provides improved lower bounds for vorticity growth in axisymmetric Euler flows, supporting Childress's conjecture under specific initial conditions.

Abstract: In this paper, we investigate Childress's conjecture proposed in [Phys.D
237(14-17):1921-1925, 2008] on the growth rate of the vorticity maximum for
axisymmetric swirl-free Euler flows in three and higher dimensions. We consider
the setting that the axial vorticity is non-positive in the upper half space
and odd in the last coordinate, which corresponds to the flow setup for head-on
collision of anti-parallel vortex rings. By introducing the \emph{generalized
vertical moment} and proving its monotonicity, we obtain a lower bound for the
growth of the vorticity maximum, contingent on the initial decay rate in the
$z$-direction. Specifically, for three-dimensional flows with initial vorticity
sufficiently fast decay in $z$, we obtain a lower bound of $t^{\frac{1}{2}-}$,
thereby improving upon existing results.

</details>


### [17] [Analysis and Patterns of Nonlocal Klausmeier Model](https://arxiv.org/abs/2511.03188)
*Md Shah Alam*

Main category: math.AP

TL;DR: Global well-posedness and boundedness of classical solutions for a nonlocal Klausmeier vegetation model with both local and nonlocal diffusion, showing nonlocal interactions enhance vegetation pattern formation.


<details>
  <summary>Details</summary>
Motivation: To extend the Klausmeier vegetation model by incorporating nonlocal diffusion for biomass dynamics, representing anomalous and faster dispersal compared to standard Laplacian diffusion for water.

Method: Semigroup theory combined with duality arguments for analytical proofs, and Finite Difference Method with Forward Euler integration for numerical simulations.

Result: Nonlocal diffusion significantly influences vegetation spatial organization, producing richer and more coherent patterns than classical local models, with kernel size affecting pattern characteristics.

Conclusion: Nonlocal interactions in vegetation models lead to enhanced pattern formation and more complex spatial structures compared to purely local diffusion models.

Abstract: This work studies a nonlocal extension of the Klausmeier vegetation model in
$\mathbb{R}^N$ $(N \ge 1)$ that incorporates both local and nonlocal diffusion.
The biomass dynamics are driven by a nonlocal convolution operator,
representing anomalous and faster dispersal than the standard Laplacian acting
on the water component. Using semigroup theory combined with a duality
argument, we establish global well-posedness and uniform boundedness of
classical solutions. Numerical simulations based on the Finite Difference
Method with Forward Euler integration illustrate the qualitative effects of
nonlocal diffusion and kernel size on vegetation patterns. The results
demonstrate that nonlocal interactions significantly influence the spatial
organization of vegetation, producing richer and more coherent structures than
those arising in the classical local model.

</details>


### [18] [Global Existence and Asymptotic Equivalence to Barenblatt-type Solutions for the Physical Vacuum Free Boundary Problem of Damped Compressible Euler Equations in M-D](https://arxiv.org/abs/2511.03191)
*Huihui Zeng*

Main category: math.AP

TL;DR: Global existence of smooth solutions for damped compressible Euler equations in 2D/3D with physical vacuum boundary, showing convergence to Barenblatt self-similar solutions for small perturbations.


<details>
  <summary>Details</summary>
Motivation: To complete the analysis of physical vacuum free boundary problems for damped compressible Euler equations across dimensions, addressing a question raised in previous literature.

Method: Improves decay rate of time derivative of perturbation from -1 to -1-ε to ensure time integrability and global existence. Unifies treatment of time-dependent and time-independent damping cases.

Result: Proves global existence of smooth solutions and their asymptotic equivalence to Barenblatt self-similar solutions. Quantifies decay rates of density, velocity, and vacuum boundary expansion.

Conclusion: Provides complete answer to Liu's question and unifies dimensional analysis for both time-dependent and time-independent damping cases.

Abstract: For the physical vacuum free boundary problem of the damped compressible
Euler equations in both 2D and 3D, we prove the global existence of smooth
solutions and justify their time-asymptotic equivalence to the corresponding
Barenblatt self-similar solutions derived from the porous media equation under
Darcy's law approximation, provided the initial data are small perturbations of
the Barenblatt solutions. Building on the 3D almost global existence result in
[Zeng, Arch. Ration. Mech. Anal. 239, 553--597 (2021)], our key contribution
lies in improving the decay rate of the time derivative of the perturbation
from $-1$ (as previously established) to $-1-\varepsilon$ for a fixed constant
$\varepsilon > 0$. This critical enhancement ensures time integrability and
hence global existence. Together with the previous 1D result in [Luo--Zeng,
Comm. Pure Appl. Math. 69, 1354--1396 (2016)], the results obtained in this
paper provide a complete answer to the question raised in [Liu, T.-P.: Jpn. J.
Appl. Math. 13, 25--32 (1996)]. Moreover, we also consider the problem with
time-dependent damping of the form $(1+t)^{-\lambda}$ for $0 < \lambda < 1$.
Notably, our framework unifies the treatment of both time-dependent ($0 <
\lambda < 1$) and time-independent ($\lambda = 0$) damping cases across
dimensions. We further quantify the decay rates of the density and velocity, as
well as the expansion rate of the physical vacuum boundary.

</details>


### [19] [The global well-posedness for the Q-tensor model of nematic liquid crystals in the half-space](https://arxiv.org/abs/2511.03309)
*Daniele Barbera,Yoshihiro Shibata,Miho Murata*

Main category: math.AP

TL;DR: Global well-posedness of Q-tensor model for nematic liquid crystals in half-space using L_p-L_q framework and Banach fixed point argument.


<details>
  <summary>Details</summary>
Motivation: To establish the first global-in-time existence and uniqueness result for the Q-tensor model describing nematic liquid crystals in the half-space domain.

Method: Combines Banach fixed point argument with maximal L_p-L_q regularity for linearized problem and analytic semigroup theory for lower-order terms, based on R-solvability of the resolvent problem.

Result: Proved global well-posedness for Q-tensor model in half-space, providing weighted estimates for solutions and establishing unique existence of global-in-time solution.

Conclusion: First successful proof of global well-posedness for Q-tensor model in half-space using L_p-L_q framework and fixed point methods.

Abstract: In this paper, we consider the Q-tensor model of nematic liquid crystals,
which couples the Navier-Stokes equations with a parabolic-type equation
describing the evolution of the directions of the anisotropic molecules, in the
half-space. The aim of this paper is to prove the global well-posedness for the
Q-tensor model in the $L_p$-$L_q$ framework. Our proof is based on the Banach
fixed point argument. To control the higher-order terms of the solutions, we
prove the weighted estimates of the solutions for the linearized problem by the
maximal $L_p$-$L_q$ regularity. On the other hand, the estimates for the
lower-order terms are obtained by the analytic semigroup theory. Here, the
maximal $L_p$-$L_q$ regularity and the generation of an analytic semigroup are
provided by the R-solvability for the resolvent problem arising from the
Q-tensor model. It seems to be the first result to discuss the unique existence
of a global-in-time solution for the Q-tensor model in the half-space.

</details>


### [20] [Calibration for minimal surfaces with free boundary and Cheeger-type problems](https://arxiv.org/abs/2511.03322)
*Guy Bouchitté,Minh Phan*

Main category: math.AP

TL;DR: Analysis of minimal surfaces with free boundary via non-convex minimization, using calibration fields to characterize solutions and comparing with Cheeger problem variants.


<details>
  <summary>Details</summary>
Motivation: To characterize optimal solutions for minimal surfaces with free boundary problems through calibration fields and establish connections with Cheeger-type problems.

Method: Formulate as non-convex minimization problem, construct calibration fields, use cut-locus potential to prove optimality, and compare with Cheeger problem variant.

Result: Explicit solution of Cheeger problem variant using cut-locus potential construction, providing natural upper bound for the original minimization problem.

Conclusion: Successfully characterized minimal surface solutions through calibration approach and established detailed comparison between the original problem and Cheeger-type variants.

Abstract: We study a problem of minimal surfaces with free boundary written in the form
of a non convex minimization problem. Our aim is to characterize optimal
solutions by finding a suitable calibration field. A natural upper bound of the
infimum is given by a variant of the Cheeger problem that we solve explicitly
proving the optimality thanks to the construction of a cut-locus potential. The
comparison with the original problem is then discussed in detail.

</details>


### [21] [Moving boundary problems for a novel extended mKdV equation. Application of Ermakov-Painlevé II symmetry reduction](https://arxiv.org/abs/2511.03356)
*Colin Rogers,Adriana C. Briozzo*

Main category: math.AP

TL;DR: A novel extended mKdV equation with hybrid Ermakov-Painlevé II symmetry reduction is introduced, used to solve moving boundary problems, and embedded in modulated nonlinear evolution equations.


<details>
  <summary>Details</summary>
Motivation: To develop exact solutions for moving boundary problems of Stefan type using symmetry reductions and reciprocal transformations.

Method: Introduce extended mKdV equation with hybrid Ermakov-Painlevé II symmetry, apply reciprocal transformation, and use involutory transformations from Ermakov theory.

Result: Exact Airy-type solutions obtained for moving boundary problems; extended mKdV embedded in modulated nonlinear evolution equations; temporal modulation delimited for hybrid mKdV and KdV equations.

Conclusion: The approach successfully generates exact solutions for moving boundary problems and reveals connections between extended mKdV and modulated nonlinear systems through symmetry methods.

Abstract: A novel extension of the canonical solitonic mKdV equation is introduced
which admits hybrid Ermakov-Painlev\'e II symmetry reduction. Application of
the latter is made to obtain exact solution of Airy-type to a class of moving
boundary problems of Stefan kind for this extended mKdV equation. A reciprocal
transformation is then applied to the latter to generate an associated exactly
solvable class of moving boundary problems for an extension of a base Casimir
member of a compacton hierachy. The extended mKdV equation is shown to be
embedded in a range of nonlinear evolution equations with temporal modulation
as determined via the action of a class of involutory transformations with
origin in Ermakov theory. Associated temporal modulation for the hybrid mKdV
and KdV equation as embedded in the classical solitonic Gardner equation is
delimited.

</details>


### [22] [Introduction to the theory of mixing for incompressible flows](https://arxiv.org/abs/2511.03360)
*Gianluca Crippa*

Main category: math.AP

TL;DR: Pedagogical introduction to mixing theory for incompressible flows, covering Lagrangian and Eulerian viewpoints, mixing scales, universal lower bounds on mixing time, and recent sharpness results.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive pedagogical foundation for understanding mixing in incompressible flows from a PDE perspective, connecting classical and modern approaches.

Method: Combines Lagrangian (ODE) and Eulerian (PDE) viewpoints, introduces mixing scales, uses energy estimates and flow-based arguments for smooth settings, and quantitative estimates for regular Lagrangian flows in Sobolev settings.

Result: Establishes universal lower bounds on mixing time evolution, presents recent sharpness results for these bounds, and explores implications for geometry and regularity of regular Lagrangian flows.

Conclusion: The notes provide a unified framework for mixing theory, connecting classical energy methods with modern quantitative approaches, and highlighting recent developments in the field.

Abstract: In these lecture notes, we provide a pedagogical introduction to the theory
of mixing for incompressible flows from a PDE perspective. We discuss both the
Lagrangian (ODE) and Eulerian (PDE, continuity equation) viewpoints, and
introduce suitable notions of mixing scales that quantify the degree to which a
scalar field transported by a velocity field becomes mixed. We then address the
problem of establishing universal lower bounds on the time evolution of the
mixing scale. This is first done in the smooth setting, using energy estimates
and flow-based arguments, and later in the Sobolev setting, relying on
quantitative estimates for regular Lagrangian flows. Finally, we present recent
results concerning the sharpness of these lower bounds, their implications for
the geometry and regularity of regular Lagrangian flows, and connections with
more recent developments in the literature.

</details>


### [23] [Local potential and Hölder estimates for the linearized Monge-Ampère equation](https://arxiv.org/abs/2511.03426)
*Guoqing Cui,Ling Wang,Bin Zhou*

Main category: math.AP

TL;DR: Local potential and Hölder estimates for linearized Monge-Ampère equations with signed measure right-hand sides, with applications to the singular Abreu equation.


<details>
  <summary>Details</summary>
Motivation: To establish regularity estimates for solutions of linearized Monge-Ampère equations, particularly when dealing with signed measures as right-hand sides, which extends previous results and provides new analytical tools.

Method: Develop local potential estimates and Hölder estimates under suitable assumptions on the data, focusing on cases where the right-hand side is a signed measure or the nonnegative divergence of a bounded vector field.

Result: Proved interior Hölder estimates for inhomogeneous linearized Monge-Ampère equations with right-hand side being the nonnegative divergence of a bounded vector field in all dimensions.

Conclusion: The established estimates provide a new approach for interior estimates of the singular Abreu equation, demonstrating the applicability of the developed techniques to related problems in PDE theory.

Abstract: In this paper, we establish local potential estimates and H\"older estimates
for solutions of linearized Monge-Amp\`ere equations with the right-hand side
being a signed measure, under suitable assumptions on the data. In particular,
the interior H\"older estimate holds for an inhomogeneous linearized
Monge-Amp\`ere equation with right-hand side being the nonnegative divergence
of a bounded vector field in all dimensions. As an application, we give a new
approach for the interior estimate of the singular Abreu equation.

</details>


### [24] [Rolling carpet strategy to reduce mosquito populations in two-dimensional space](https://arxiv.org/abs/2511.03447)
*Luís Almeida,Alexis Léculier,Nga Nguyen,Nicolas Vauchelet*

Main category: math.AP

TL;DR: Existence of forced traveling waves in sterile insect technique for mosquito population control


<details>
  <summary>Details</summary>
Motivation: Mosquitoes transmit diseases; controlling their population through sterile insect technique can help combat disease spread

Method: Using reaction-diffusion system and radial symmetry in two-dimensional space to prove existence of forced traveling waves by translating intervention zone at constant speed

Result: Demonstrated existence of forced traveling waves in the sterile insect technique model

Conclusion: The sterile insect technique can be effectively modeled using reaction-diffusion systems with traveling wave solutions in two-dimensional space

Abstract: Mosquitoes are vectors of numerous diseases; a strategy to fight the spread
of these diseases is to control the vector population. In this article, we
focus on the use of the sterile insect technique. Starting from a
reaction-diffusion system, we show the existence of 'forced' traveling waves
obtained by translating the intervention zone at constant speed. This result is
proved in a two-dimensional space by using the radial symmetry.

</details>


### [25] [Dimensional reduction for anyons in the average-field approximation](https://arxiv.org/abs/2511.03491)
*Qiyun Yang*

Main category: math.AP

TL;DR: Dimensional reduction of 2D Chern-Simons-Schrödinger system for abelian anyons to 1D quintic defocusing nonlinear Schrödinger equation via anisotropic trapping potential.


<details>
  <summary>Details</summary>
Motivation: To study abelian anyons at mean-field level and understand their dynamics through dimensional reduction from 2D to 1D systems.

Method: Introduce anisotropic trapping potential to reduce 2D Chern-Simons-Schrödinger system, trace out tight confinement direction to derive effective 1D model.

Result: Effective dynamics in loose confinement direction described by quintic defocusing nonlinear Schrödinger equation.

Conclusion: Rigorous establishment of dimensional reduction process for ground state energies and time-dependent solutions under H² well-posedness assumption.

Abstract: We study abelian anyons at the mean-field/almost-bosonic level, whose
dynamics are governed by the Chern-Simons-Schr\"odinger system. We consider the
dimensional reduction of this 2D model by introducing an anisotropic trapping
potential, and derive an effective 1D model after tracing out the tight
confinement direction. The resulting effective dynamics in the loose
confinement direction is captured by a quintic defocusing nonlinear
Schr\"odinger equation. We rigorously establish this dimensional reduction
process in the sense of ground state energies and time-dependent solutions,
under an $H^2$ well-posedness assumption.

</details>


### [26] [Critical sinh-Gordon flow with non-negative weight functions](https://arxiv.org/abs/2511.03624)
*Qiang Fei,Aleks Jevnikar,Sang-Hyuck Moon*

Main category: math.AP

TL;DR: This paper introduces a critical sinh-Gordon type flow on Riemannian surfaces and proves its convergence to solutions of the critical sinh-Gordon equation under suitable geometric conditions, extending previous results to non-negative weights.


<details>
  <summary>Details</summary>
Motivation: To study the properties of a critical sinh-Gordon type flow and extend Zhou's (2008) convergence results to the case of non-negative weight functions, which requires careful blow-up analysis.

Method: The authors introduce a sinh-Gordon type flow equation and use blow-up analysis techniques to study its convergence properties under appropriate geometric conditions on closed Riemannian surfaces.

Result: The flow converges to a solution of the critical sinh-Gordon equation when ρ₂ < 8π and under suitable geometric conditions, successfully extending Zhou's results to non-negative weight functions.

Conclusion: The critical sinh-Gordon type flow exhibits convergence behavior to solutions of the critical sinh-Gordon equation, and the analysis provides insights that can be applied to related Toda flows as well.

Abstract: The aim of this article is twofold: one one side we introduce and study the
properties of a critical sinh-Gordon type flow \begin{equation*}
{\frac{\partial}{\partial
t}}e^u=\Delta_gu+8\pi\left({\frac{h_1e^u}{\int_{\Sigma}h_1e^udV_g}}-1\right)-\rho_2\left({\frac{h_2e^{-u}}{\int_{\Sigma}h_2e^{-u}dV_g}}-1\right),
\end{equation*} where $\rho_2<8\pi$, $h_1,h_2$ are non-negative weight
functions and $\Sigma$ is a closed Riemannian surface. Secondly, under suitable
geometric conditions, we prove the convergence of the flow to a solution of the
critical sinh-Gordon equation, extending the result of Zhou (2008) to the case
of non-negative weights. The argument is based on a careful blow-up analysis.
Some remarks about a Toda flow are also given.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [27] [Relativistic multistage resonant and trailing-field acceleration induced by large-amplitude Alfvén waves in a strong magnetic field](https://arxiv.org/abs/2511.03069)
*S. Isayama,S. Matsukiyo,T. Sano,S. H. Chen*

Main category: physics.plasm-ph

TL;DR: A multi-stage particle acceleration mechanism using large-amplitude Alfvén waves, involving counterpropagating wave-particle resonant acceleration, gyroresonant surfing acceleration, and single wave resonant acceleration to produce highly relativistic electrons.


<details>
  <summary>Details</summary>
Motivation: To understand the generation of high-energy cosmic rays in astrophysical environments by developing a comprehensive particle acceleration mechanism driven by Alfvén waves in strong magnetic fields.

Method: A multi-stage acceleration process: 1) Counterpropagating wave-particle resonant acceleration (CWRA) via decay instability, 2) Gyroresonant surfing acceleration (GRSA) using amplified electrostatic fields, 3) Single wave resonant acceleration (SWRA) when particles become trapped, and 4) Trailing-field acceleration (TFA) from accumulated particles.

Result: The combined mechanisms produce highly relativistic electron energy, with the multi-stage process yielding higher energy electrons than trailing-field acceleration alone.

Conclusion: This multi-stage acceleration process provides insights into cosmic ray generation in astrophysical environments, demonstrating how Alfvén waves can efficiently accelerate particles to relativistic energies through sequential resonant interactions.

Abstract: We propose a particle acceleration mechanism driven by large-amplitude
Alfv\'en waves in a strong magnetic field. The acceleration process proceeds
through multiple stages triggered by counterpropagating wave-particle resonant
acceleration (CWRA) via decay instability. Initially, parent and daughter
Alfv\'en waves resonantly accelerate particles perpendicular to the ambient
magnetic field. The resultant modulational instability generates electrostatic
fields within the wave packet, which are locally amplified by the ponderomotive
force of the Alfv\'en wave packet. These fields subsequently drive further
acceleration within a few relativistic gyroperiods via gyroresonant surfing
acceleration (GRSA). During this, the v*B force facilitates momentum transfer
from the perpendicular to the parallel direction. In the later stage, particles
become trapped by the parent wave and gain additional energy through single
wave resonant acceleration (SWRA). Furthermore, the accumulation of accelerated
particles induces electrostatic trailing fields behind and at the tail of the
wave packet, which drive trailing-field acceleration (TFA) of other electrons.
The combined effects of these mechanisms, CWRA followed by GRSA and SWRA,
result in highly relativistic electron energy. The electron energy accelerated
through the above process is higher than that accelerated through TFA. This
multistage acceleration process provides insights into the generation of high
energy cosmic rays in astrophysical environments.

</details>


### [28] [Particle-in-cell simulations of laser crossbeam energy transfer via magnetized ion-acoustic wave](https://arxiv.org/abs/2511.03090)
*Yuan Shi,John D. Moody*

Main category: physics.plasm-ph

TL;DR: Magnetic fields significantly modify crossbeam energy transfer (CBET) between laser beams in plasmas, causing different energy gains for electromagnetic eigenmodes and altering gain dependence on laser detuning.


<details>
  <summary>Details</summary>
Motivation: To understand how magnetic fields directly affect laser-plasma interactions, specifically crossbeam energy transfer mediated by ion-acoustic waves, since large magnetic fields are common in laser-driven high-energy-density systems.

Method: Used 2D particle-in-cell simulations in linear regime where CBET dominates, applied Fourier filter to separate seed signal, projected seed fields to electromagnetic eigenmodes, and compared seed energy before and after CBET reaches quasi-steady state.

Result: Magnetic fields above a few MG cause different gains for the two electromagnetic eigenmodes, alter gain dependence on laser detuning, decrease overall gain for parallel polarizations, and allow nonzero gain for orthogonal polarizations.

Conclusion: Magnetic fields significantly modify CBET behavior, with findings qualitatively agreeing with theoretical expectations about how magnetization affects laser-plasma interactions.

Abstract: Large magnetic fields, either imposed externally or produced spontaneously,
are often present in laser-driven high-energy-density systems. In addition to
changing plasma conditions, magnetic fields also directly modify laser-plasma
interactions (LPI) by changing participating waves and their nonlonear
interactions. In this paper, we use two-dimensional particle-in-cell (PIC)
simulations to investigate how magnetic fields directly affect crossbeam energy
transfer (CBET) from a pump to a seed laser beam, when the transfer is mediated
by the ion-acoustic wave (IAW) quasimode. Our simulations are performed in the
parameter space where CBET is the dominant process, and in a linear regime
where pump depletion, distribution function evolution, and secondary
instabilities are insignificant. We use a Fourier filter to separate out the
seed signal, and project the seed fields to two electromagnetic eigenmodes,
which become nondegenerate in magnetized plasmas. By comparing the seed energy
before CBET occurs and after CBET reaches quasi-steady state, we extract CBET
energy gains of both eigenmodes for lasers that are initially linearly
polarized. Our simulations reveal that starting from a few MG fields, the two
eigenmodes have different gains, and magnetization alters how the gains depend
on laser detuning. The overall gain decreases with magnetization when the laser
polarizations are initially parallel, while a nonzero gain becomes allowed when
the laser polarizations are initially orthogonal. These findings qualitatively
agree with theoretical expectations.

</details>


### [29] [First global gyrokinetic profile predictions of ITER burning plasma](https://arxiv.org/abs/2511.03336)
*A. Di Siena,C. Bourdelle,A. Bañón Navarro,G. Merlo,T. Görler,E. Fransson,A. Polevoi,S. H. Kim,F. Koechl,A. Loarte,E. Fable,C. Angioni,P. Mantica,F. Jenko*

Main category: physics.plasm-ph

TL;DR: First global gyrokinetic simulations of ITER baseline scenario show density peaking moderated by electromagnetic fluctuations, achieving Q=12.2 fusion gain. Electromagnetic modes dominate core transport, requiring high resolution. Safety factor profile is critical - flat q profiles destabilize kinetic ballooning modes and degrade confinement.


<details>
  <summary>Details</summary>
Motivation: To perform the first global gyrokinetic simulations of ITER's baseline scenario to understand turbulence, transport mechanisms, and predict fusion performance for ITER mission objectives.

Method: Global gyrokinetic simulations using GENE-Tango for electrostatic and electromagnetic modeling across radial region from magnetic axis to rho_tor=0.6, with comparison to local flux-tube simulations.

Result: Predicted fusion gain Q=12.2, density peaking moderated by electromagnetic fluctuations. Electromagnetic modes (microtearing, kinetic ballooning, Alfvenic ITG) dominate core transport. External rotation has negligible impact. Flat q profiles destabilize kinetic ballooning modes and degrade confinement. ETG turbulence quenched by zonal flows.

Conclusion: ITER baseline scenario achieves mission objectives with Q=12.2. Electromagnetic turbulence dominates transport, requiring high-resolution modeling. Safety factor profile is critical for confinement - flat profiles degrade performance. Zonal flows effectively quench ETG turbulence under low collisionality conditions.

Abstract: In this work, we present the first global gyrokinetic simulations of the ITER
baseline scenario operating at 15 MA using GENE-Tango electrostatic and
electromagnetic simulations. The modeled radial region spans close to the
magnetic axis up to rho_tor = 0.6. Our results show a pronounced density
peaking, moderated by electromagnetic fluctuations. The predicted fusion gain
for this scenario is Q = 12.2, aligning well with ITER's mission objectives. We
further characterize the turbulence spectra and find that electromagnetic
modes, such as microtearing modes, kinetic ballooning modes, and Alfvenic ion
temperature gradient modes at low binormal wave numbers, play a critical role
in the core transport of this ITER scenario, necessitating high numerical
resolution for accurate modeling. Local flux-tube simulations qualitatively
reproduce the key features observed in the global gyrokinetic simulations but
exhibit a much higher sensitivity to profile gradients, reflecting increased
stiffness, likely due to the linearization of the equilibrium profiles and
safety factor. Our study also reveals that the imposed external toroidal
rotation profiles have a negligible impact on turbulent transport, as their
magnitudes are substantially lower than the dominant linear growth rates.
Furthermore, we demonstrate that the safety factor profile is of paramount
importance: scenarios featuring flat q profiles with near-zero magnetic shear
lead to the destabilization of kinetic ballooning modes in the plasma core,
significantly enhancing turbulent transport and potentially degrading
confinement. Finally, although electron temperature gradient turbulence
initially appears large, sometimes exceeding ion-scale transport levels, it is
ultimately quenched over long timescales by secular evolution of zonal flows,
which are weakly damped under the very low collisionality conditions expected
in ITER.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [30] [Enhancing composition-based materials property prediction by cross-modal knowledge transfer](https://arxiv.org/abs/2511.03371)
*Ivan Rubtsov,Ivan Dudakov,Yuri Kuratov,Vadim Korolev*

Main category: cond-mat.mtrl-sci

TL;DR: Universal approach for enhancing composition-based materials property prediction through cross-modal knowledge transfer, achieving state-of-the-art performance on benchmark tasks.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between crystal graph neural networks (which require structural information) and structure-agnostic methods, enabling exploration of previously inaccessible chemical spaces.

Method: Two formulations: implicit transfer (pretraining chemical language models on multimodal embeddings) and explicit transfer (generating crystal structures and implementing structure-aware predictors).

Result: Achieved state-of-the-art performance in 25 out of 32 cases on LLM4Mat-Bench and MatBench tasks, with improved interpretability using game-theoretic approach.

Conclusion: Cross-modal knowledge transfer effectively enhances composition-based materials property prediction and provides interpretable insights through game-theoretic methods.

Abstract: Crystal graph neural networks are widely applicable in modeling
experimentally synthesized compounds and hypothetical materials with unknown
synthesizability. In contrast, structure-agnostic predictive algorithms allow
exploring previously inaccessible domains of chemical space. Here we present a
universal approach for enhancing composition-based materials property
prediction by means of cross-modal knowledge transfer. Two formulations are
proposed: implicit transfer involves pretraining chemical language models on
multimodal embeddings, whereas explicit transfer suggests generating crystal
structures and implementing structure-aware predictors. The proposed approaches
were benchmarked on LLM4Mat-Bench and MatBench tasks, achieving
state-of-the-art performance in 25 out of 32 cases. In addition, we
demonstrated how another modeling aspect of chemical language models -
interpretability - benefits from applying a game-theoretic approach, which is
able to incorporate high-order feature interactions.

</details>


### [31] [Efficient GPU Parallelization of Electronic Transport and Nonequilibrium Dynamics from Electron-Phonon Interactions in the Perturbo Code](https://arxiv.org/abs/2511.03683)
*Shiyu Peng,Donnie Pinkston,Jia Yao,Sergei Kliavinek,Ivan Maliyov,Marco Bernardi*

Main category: cond-mat.mtrl-sci

TL;DR: GPU-accelerated Boltzmann transport equation calculations using novel data structures achieve 40x speed-up over CPU implementations for electronic transport and ultrafast dynamics.


<details>
  <summary>Details</summary>
Motivation: The Boltzmann transport equation with electron-phonon interactions is computationally expensive, limiting studies of materials with large unit cells and high momentum space resolution.

Method: Implemented novel data structure and algorithm optimized for GPU hardware using OpenACC, reducing data referencing, movement, and synchronization overhead.

Result: Achieved 40x speed-up relative to CPU implementation (Perturbo v2.2.0) for both transport and nonequilibrium dynamics, with nearly linear scaling up to 100 GPUs.

Conclusion: The GPU implementation enables sweeping studies of electron-phonon physics and prepares for exascale computing, with the method released in Perturbo v3.0.0.

Abstract: The Boltzmann transport equation (BTE) with electron-phonon (e-ph)
interactions computed from first principles is widely used to study electronic
transport and nonequilibrium dynamics in materials. Calculating the e-ph
collision integral is the most important step in the BTE, but it remains
computationally costly, even with current MPI+OpenMP parallelization. This
challenge makes it difficult to study materials with large unit cells and to
achieve high resolution in momentum space. Here, we show acceleration of BTE
calculations of electronic transport and ultrafast dynamics using graphical
processing units (GPUs). We implement a novel data structure and algorithm,
optimized for GPU hardware and developed using OpenACC, to process scattering
channels and efficiently compute the collision integral. This approach
significantly reduces the overhead for data referencing, movement, and
synchronization. Relative to the efficient CPU implementation in the
open-source package Perturbo (v2.2.0), used as a baseline, this approach
achieves a speed-up of 40 times for both transport and nonequilibrium dynamics
on GPU hardware, and achieves nearly linear scaling up to 100 GPUs. The novel
data structure can be generalized to other electron interactions and scattering
processes. We released this GPU implementation in the latest public version
(v3.0.0) of Perturbo. The new MPI+OpenMP+GPU parallelization enables sweeping
studies of e-ph physics and electron dynamics in conventional and quantum
materials, and prepares Perturbo for exascale supercomputing platforms.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [32] [Microgrids optimal radial reconfiguration via FORWARD algorithm](https://arxiv.org/abs/2511.03059)
*Joan Vendrell Gallart,Russell Bent,Solmaz Kia*

Main category: eess.SY

TL;DR: Proposes a permutation-based iterative search method integrated with FORWARD to solve NP-hard MINLP problems in microgrid resource allocation and radial configuration design, providing scalable solutions with feasibility guarantees.


<details>
  <summary>Details</summary>
Motivation: Microgrids face complex energy management challenges including supply-demand balancing, system stability, and cost minimization, which require solving computationally intractable NP-hard MINLP problems that traditional solvers struggle with.

Method: Introduces a permutation-based iterative search method over the FORWARD method to efficiently identify feasible, near-optimal radial network structures while respecting physical constraints, and integrates this as a warm-start strategy for benchmark MINLP solvers.

Result: The proposed method efficiently identifies feasible, near-optimal radial network structures for microgrid power distribution while inherently respecting physical constraints.

Conclusion: The approach offers a scalable solution for comprehensive microgrid design by addressing the computational challenges of traditional MINLP solvers through a novel permutation-based search strategy.

Abstract: Microgrids offer a promising paradigm for integrating distributed energy
resources, bolstering energy resilience, and reducing the impact of blackouts.
However, their inherent decentralization and dynamic operation present
substantial energy management complexities. These complexities, including
balancing supply and demand, ensuring system stability, and minimizing
operational costs, often necessitate solving computationally intractable
NP-hard Mixed-Integer Non-Linear Programming (MINLP) problems. Traditional
MINLP solvers struggle with the scalability and feasibility guarantees required
for these challenges. To address this, this paper tackles the problem of
resource allocation and radial configuration design for microgrid power
distribution and proposes and abstracted problem which is solved by introducing
a permutation-based iterative search method over the recently introduced
FORWARD method to efficiently identify feasible, near-optimal radial network
structures while inherently respecting physical constraints. Furthermore, this
paper investigates the integration of the proposed method as a warm-start
strategy for benchmark MINLP solvers offering a scalable solution for
comprehensive microgrid design.

</details>


<div id='astro-ph.CO'></div>

# astro-ph.CO [[Back]](#toc)

### [33] [Quantifying Weighted Morphological Content of Large-Scale Structures via Simulation-Based Inference](https://arxiv.org/abs/2511.03636)
*M. H. Jalali Kanafi,S. M. S. Movahed*

Main category: astro-ph.CO

TL;DR: CMD outperforms Minkowski Functionals in constraining cosmological parameters, with joint analysis providing 27% improvement over MFs alone.


<details>
  <summary>Details</summary>
Motivation: To compare the constraining power of Minkowski Functionals (MFs) and Conditional Moments of Derivative (CMD) for large-scale structure analysis, particularly their sensitivity to nonlinear and anisotropic features in redshift-space.

Method: Simulation-based forecasting using halo catalogs from Big Sobol Sequence simulations at z=0.5, employing likelihood-free inference via neural posterior estimation.

Result: CMD yields tighter constraints for (Ω_m, σ_8) than MFs components, improving precision by ~(44%,52%), ~(30%,45%), ~(27%,17%), and ~(26%,17%) respectively. Joint MFs+CMD analysis enhances precision by ~27% over MFs alone.

Conclusion: CMD captures complementary anisotropy-sensitive information compared to MFs' scalar morphological content, with relative constraining power remaining nearly constant across different cosmological parameters and smoothing scales.

Abstract: In this work, we perform a simulation-based forecasting analysis to compare
the constraining power of two higher-order summary statistics of the
large-scale structure (LSS), the Minkowski Functionals (MFs) and the
Conditional Moments of Derivative (CMD), with a particular focus on their
sensitivity to nonlinear and anisotropic features in redshift-space. Our
analysis relies on halo catalogs from the Big Sobol Sequence(BSQ) simulations
at redshift $z=0.5$, employing a likelihood-free inference framework
implemented via neural posterior estimation. At the fiducial cosmology of the
Quijote simulations $(\Omega_{m}=0.3175,\,\sigma_{8}=0.834)$, and for the
smoothing scale $R=15\,h^{-1}$Mpc, we find that the CMD yields tighter
forecasts for $(\Omega_{m}},\,\sigma_{8})$ than the zeroth- to third-order MFs
components, improving the constraint precision by ${\sim}(44\%,\,52\%)$,
${\sim}(30\%,\,45\%)$, ${\sim}(27\%,\,17\%)$, and ${\sim}(26\%,\,17\%)$,
respectively. A joint configuration combining the MFs and CMD further enhances
the precision by approximately ${\sim}27\%$ compared to the standard MFs alone,
highlighting the complementary anisotropy-sensitive information captured by the
CMD in contrast to the scalar morphological content encapsulated by the MFs. We
further extend the forecasting analysis to a continuous range of cosmological
parameter values and multiple smoothing scales. Our results show that, although
the absolute forecast uncertainty for each component of summary statistics
depends on the underlying parameter values and the adopted smoothing scale, the
relative constraining power among the summary statistics remains nearly
constant throughout.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [34] [Universal Quantum Simulation of 50 Qubits on Europe`s First Exascale Supercomputer Harnessing Its Heterogeneous CPU-GPU Architecture](https://arxiv.org/abs/2511.03359)
*Hans De Raedt,Jiri Kraus,Andreas Herten,Vrinda Mehta,Mathis Bode,Markus Hrywniak,Kristel Michielsen,Thomas Lippert*

Main category: quant-ph

TL;DR: JUQCS-50 enables 50-qubit quantum computer simulations using GH200 superchips, achieving 11.4x speedup over previous 48-qubit record through memory extension, adaptive encoding, and network optimization.


<details>
  <summary>Details</summary>
Motivation: To overcome previous limitations in quantum computer simulation and enable simulations of larger quantum systems (50 qubits) that were previously infeasible.

Method: Three key innovations: (1) extending usable memory beyond GPU limits via high-bandwidth CPU-GPU interconnects and LPDDR5 memory; (2) adaptive data encoding to reduce memory footprint; (3) on-the-fly network traffic optimizer.

Result: Successfully simulated a 50-qubit universal quantum computer for the first time, achieving an 11.4-fold speedup over the previous 48-qubit record on the K computer.

Conclusion: JUQCS-50 demonstrates that advanced memory management and optimization techniques can significantly push the boundaries of quantum computer simulation capabilities.

Abstract: We have developed a new version of the high-performance J\"ulich universal
quantum computer simulator (JUQCS-50) that leverages key features of the GH200
superchips as used in the JUPITER supercomputer, enabling simulations of a
50-qubit universal quantum computer for the first time. JUQCS-50 achieves this
through three key innovations: (1) extending usable memory beyond GPU limits
via high-bandwidth CPU-GPU interconnects and LPDDR5 memory; (2) adaptive data
encoding to reduce memory footprint with acceptable trade-offs in precision and
compute effort; and (3) an on-the-fly network traffic optimizer. These advances
result in an 11.4-fold speedup over the previous 48-qubit record on the K
computer.

</details>


### [35] [Quantum error mitigation using energy sampling and extrapolation enhanced Clifford data regression](https://arxiv.org/abs/2511.03556)
*Zhongqi Zhao,Erik Rosendahl Kjellgren,Sonia Coriani,Jacob Kongsted,Stephan P. A. Sauer,Karl Michael Ziems*

Main category: quant-ph

TL;DR: This paper extends Clifford Data Regression (CDR) for quantum error mitigation in VQE quantum chemistry simulations, proposing two improvements: Energy Sampling for better training circuit selection and Non-Clifford Extrapolation for enhanced regression modeling.


<details>
  <summary>Details</summary>
Motivation: Error mitigation is crucial for practical quantum algorithms on NISQ devices, particularly for quantum chemistry simulations using VQE where noise significantly impacts performance.

Method: Used H4 molecule with tUPS ansatz and ibm torino noise model to study CDR hyperparameters, then proposed two improvements: Energy Sampling (selects lowest-energy training circuits) and Non-Clifford Extrapolation (adds non-Clifford parameter count as regression input).

Result: Numerical results show both proposed strategies outperform original CDR in error mitigation quality for quantum chemistry simulations.

Conclusion: The enhanced CDR framework with Energy Sampling and Non-Clifford Extrapolation provides superior error mitigation for VQE-based quantum chemistry calculations on noisy quantum devices.

Abstract: Error mitigation is essential for the practical implementation of quantum
algorithms on noisy intermediate-scale quantum (NISQ) devices. This work
explores and extends Clifford Data Regression (CDR) to mitigate noise in
quantum chemistry simulations using the Variational Quantum Eigensolver (VQE).
Using the H$_4$ molecule with the tiled Unitary Product State (tUPS) ansatz, we
perform noisy simulations with the ibm torino noise model to investigate in
detail the effect of various hyperparameters in CDR on the error mitigation
quality. Building on these insights, two improvements to the CDR framework are
proposed. The first, Energy Sampling (ES), improves performance by selecting
only the lowest-energy training circuits for regression, thereby further
biasing the sample energies toward the target state. The second, Non-Clifford
Extrapolation (NCE), enhances the regression model by including the number of
non-Clifford parameters as an additional input, enabling the model to learn how
the noisy-ideal mapping evolves as the circuit approaches the optimal one. Our
numerical results demonstrate that both strategies outperform the original CDR.

</details>


### [36] [Atom-Field Non-Markovian Dynamics in Open and Dissipative Systems: An Efficient Memory-Kernel Approach Linked to Dyadic Greens Function and CEM Treatments](https://arxiv.org/abs/2511.03561)
*Hyunwoo Choi,Jisang Seo,Weng C. Chew,Dong-Yeop Na*

Main category: quant-ph

TL;DR: A numerical framework for modeling single photon emission from two-level systems in open dissipative systems, compatible with standard computational electromagnetic solvers like FDTD and FEM.


<details>
  <summary>Details</summary>
Motivation: To extend classical computational electromagnetic solvers to handle quantum light-matter interactions, particularly single photon emission in open and dissipative systems beyond Markovian approximations.

Method: Uses modified Langevin noise formalism with modal expansion of the dyadic Green's function, integrated with multi-mode Jaynes-Cummings model. Implements practical strategies for FDTD and FEM frameworks.

Result: Successfully verified completeness of boundary and medium assisted modes, reconstructed Green's function imaginary part, and demonstrated applicability to lossy Lorentz-Drude mirrors and Fabry-Perot cavities.

Conclusion: Establishes a rigorous foundation for incorporating quantum emitter dynamics into computational electromagnetics, extending classical solvers to quantum light-matter interactions.

Abstract: In this work, we present a numerical framework for modeling single photon
emission from a two level system in open and dissipative systems beyond the
Markovian approximation. The method can be readily integrated into standard
computational electromagnetic (CEM) solvers such as finite difference time
domain (FDTD) and finite element method (FEM). We numerically verify the
completeness of boundary and medium assisted modes in the modified Langevin
noise formalism by reconstructing the imaginary part of the dyadic Greens
function through modal expansion in three dimensions. This reconstruction
enables a first principles description of atom field interaction via the multi
mode Jaynes Cummings model in open and dissipative environments. Within the
single excitation manifold, we show that the memory kernel of a two level
system is determined by the imaginary part of the Greens function, implying
that radiative modes alone govern the relevant dynamics. The proposed framework
thus provides a Greens function based approach for describing atomic population
and single photon dynamics, directly compatible with Maxwell solvers. We then
present concrete strategies for implementing our method in both FDTD and FEM
frameworks, demonstrating its practical applicability. We further verify
numerical results for a lossy Lorentz Drude type mirror, including both the
case of a TLS near a finite sized metallic mirror and that of a TLS centered in
a Fabry Perot cavity. This work establishes a rigorous foundation for
incorporating quantum emitter dynamics into computational electromagnetics,
thereby extending classical solvers toward quantum light matter interactions.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [37] [Boltzmann-Grad limit for the inelastic Lorentz gas: Part I. Existence, uniqueness, and rigorous derivation via weak convergence](https://arxiv.org/abs/2511.02934)
*Théophile Dolmaire,Alessia Nota*

Main category: math-ph

TL;DR: Rigorous derivation of the inelastic linear Boltzmann equation from a dissipative random Lorentz gas in dimensions d≥2, establishing existence and uniqueness of weak and strong solutions with convergence rates.


<details>
  <summary>Details</summary>
Motivation: To provide a mathematical foundation for the inelastic linear Boltzmann equation by deriving it from microscopic particle dynamics with dissipative collisions in a random scattering environment.

Method: Consider a tagged light particle undergoing inelastic collisions with randomly distributed scatterers (Poisson process) using a reflection law with fixed restitution coefficient. Prove global existence of forward dynamics and weak-* convergence to Boltzmann equation solutions.

Result: Established existence and uniqueness of weak solutions in non-negative Radon measures class, global almost sure forward dynamics, weak-* convergence with explicit rate, and existence of strong solutions via series representation.

Conclusion: Successfully derived the inelastic linear Boltzmann equation from microscopic dissipative particle dynamics, providing rigorous mathematical foundation with convergence guarantees and solution existence proofs.

Abstract: In this paper we provide a rigorous derivation of the inelastic linear
Boltzmann equation, in the Boltzmann-Grad limit, from a dissipative, random,
Lorentz gas in arbitrary dimensions d $\geq$ 2. Specifically, we consider a
microscopic particle system where scatterers are randomly distributed according
to a Poisson process, and a tagged light particle undergoes inelastic
collisions with the scatterers following a reflection law characterized by a
fixed restitution coefficient. We establish the existence and uniqueness of
weak solutions to the inelastic linear Boltzmann equation within the class of
non-negative Radon measures, assuming that the initial data has a finite
exponential moment. We first show that the forward dynamics of the dissipative
particle system is globally defined almost surely and then prove the weak$-*$
convergence of the microscopic solution towards the weak solutions of the
inelastic linear Boltzmann equation, providing an explicit rate of convergence.
Furthermore, under the same initial data assumptions, we prove the existence of
strong solutions to the inelastic linear Boltzmann equation, constructed via a
series representation of the solutions.

</details>


<div id='math.SP'></div>

# math.SP [[Back]](#toc)

### [38] [The Weyl law for the Dirichlet Laplacian](https://arxiv.org/abs/2511.03584)
*Alessandro Pietro Contini*

Main category: math.SP

TL;DR: Review of asymptotic distribution of eigenvalues for Dirichlet Laplacian using Fourier Tauberian Theorem


<details>
  <summary>Details</summary>
Motivation: To systematically review and present the asymptotic distribution properties of eigenvalues for the Dirichlet Laplacian operator

Method: Introduction of relevant spectral quantities and proof using Fourier Tauberian Theorem

Result: Comprehensive review and proof of eigenvalue distribution asymptotics

Conclusion: Establishes theoretical framework for understanding eigenvalue asymptotics of Dirichlet Laplacian

Abstract: The purpose of this paper is to review the asymptotic distribution of
eigenvalues of the Dirichlet Laplacian. We introduce and recall all the
relevant spectral quantities and provide a proof based on the Fourier Tauberian
Theorem.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [39] [Modal Backflow Neural Quantum States for Anharmonic Vibrational Calculations](https://arxiv.org/abs/2511.03061)
*Lexin Ding,Markus Reiher*

Main category: physics.chem-ph

TL;DR: The paper introduces a modal backflow (MBF) neural quantum state design for solving bosonic quantum problems, specifically anharmonic vibrational systems, overcoming limitations of traditional backflow permanents.


<details>
  <summary>Details</summary>
Motivation: Neural quantum states are expressive but need physical knowledge hardwired for efficiency. For bosons, backflow permanents are impractical due to high computational cost and lack of particle conservation in common problems.

Method: Developed modal backflow (MBF) NQS design with selected-configuration scheme for observables/gradients instead of Monte Carlo sampling, and implemented vibrational self-consistent field calculation as pretraining.

Result: MBF network delivered spectroscopically accurate zero-point energies and vibrational transitions in all anharmonic regimes for both artificial and ab initio Hamiltonians.

Conclusion: The MBF approach successfully addresses bosonic quantum problems, providing accurate spectroscopic calculations while overcoming computational limitations of previous methods.

Abstract: Neural quantum states (NQS) are a promising ansatz for solving many-body
quantum problems due to their inherent expressiveness. Yet, this expressiveness
can only be harnessed efficiently for treating identical particles if the
suitable physical knowledge is hardwired into the neural network itself. For
electronic structure, NQS based on backflow determinants has been shown to be a
powerful ansatz for capturing strong correlation. By contrast, the analogue for
bosons, backflow permanents, is unpractical due to the steep cost of computing
the matrix permanent and due to the lack of particle conservation in common
bosonic problems. To circumvent these obstacles, we introduce a modal backflow
(MBF) NQS design and demonstrate its efficacy by solving the anharmonic
vibrational problem. To accommodate the demand of high accuracy in
spectroscopic calculations, we implement a selected-configuration scheme for
evaluating physical observables and gradients, replacing the standard
stochastic approach based on Monte Carlo sampling. A vibrational
self-consistent field calculation is conveniently carried out within the MBF
network, which serves as a pretraining step to accelerate and stabilize the
optimization. In applications to both artificial and ab initio Hamiltonians, we
find that the MBF network is capable of delivering spectroscopically accurate
zero-point energies and vibrational transitions in all anharmonic regimes.

</details>


### [40] [Efficient Implementation of the Spin-Free Renormalized Internally-Contracted Multireference Coupled Cluster Theory](https://arxiv.org/abs/2511.03567)
*Kalman Szenes,Riya Kayal,Kantharuban Sivalingam,Robin Feldmann,Frank Neese,Markus Reiher*

Main category: physics.chem-ph

TL;DR: Efficient implementation of RIC-MRCCSD method in ORCA quantum chemistry suite using spin-free formulation and AGE code generator, achieving performance between RHF-CCSD and UHF-CCSD with scalability to large systems like vitamin B12 models.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient implementation of renormalized internally-contracted multireference coupled cluster with singles and doubles (RIC-MRCCSD) that avoids high computational costs of previous methods requiring up to five-body reduced density matrices.

Method: Combined Evangelista's Wick equation generator with ORCA's AGE code generator to implement many-body residuals, derived spin-free formulation instead of spin-orbital version, and used parallelized code generation for multi-core execution.

Result: RIC-MRCCSD shows runtime costs between single-reference RHF-CCSD and UHF-CCSD, handles large active spaces up to CAS(14,14), and scales to systems with 809 orbitals. The method avoids RDMs higher than three-body and outperforms IC-MRCCSD which requires up to five-body RDMs.

Conclusion: The implementation successfully achieves efficient multireference coupled cluster calculations with good scalability, though challenges remain regarding parameter flow dependence in RIC-MRCCSD theory.

Abstract: In this paper, an efficient implementation of the renormalized
internally-contracted multreference coupled cluster with singles and doubles
(RIC-MRCCSD) into the ORCA quantum chemistry program suite is reported. To this
end, Evangelista's Wick&d equation generator was combined with ORCA's native
AGE code generator in order to implement the many-body residuals required for
the RIC-MRCCSD method. Substantial efficiency gains are realized by deriving a
spin-free formulation instead of the previously reported spin-orbital version
developed by some of us. Since AGE produces parallelized code, the resulting
implementation can directly be run in parallel with substantial speedups when
executed on multiple cores. In terms of runtime, the cost of RIC-MRCCSD is
shown to be between single-reference RHF-CCSD and UHF-CCSD, even when active
space spaces as large as CAS(14,14) are considered. This achievement is largely
due to the fact that no reduced density matrices (RDM) or cumulants higher than
three-body enter the formalism. The scalability of the method to large systems
is furthermore demonstrated by computing the ground-state of a vitamin B12
model comprised of an active space of CAS(12, 12) and 809 orbitals. In terms of
accuracy, RIC-MRCCSD is carefully compared to second- and approximate
fourth-order $n$-electron valence state perturbation theories (NEVPT2,
NEVPT4(SD)), to the multireference zeroth-order coupled-electron pair
approximation (CEPA(0)), as well as to the IC-MRCCSD from Kohn. In contrast to
RIC-MRCCSD, the IC-MRCCSD equations are entirely derived by AGE using the
conventional projection-based approach, which, however, leads to much higher
algorithmic complexity than the former as well as the necessity to calculate up
to the five-body RDMs. Remaining challenges such as the variation of the
results with the flow, a free parameter that enters the RIC-MRCCSD theory, are
discussed.

</details>


### [41] [Encoding electronic ground-state information with variational even-tempered basis sets](https://arxiv.org/abs/2511.03579)
*Weishi Wang,Casey Dowdle,James D. Whitfield*

Main category: physics.chem-ph

TL;DR: Proposes system-oriented even-tempered basis sets for electronic ground-state computation, introducing reduced concentric formalism and symmetry-adapted molecular formalism that achieves high accuracy with fewer parameters.


<details>
  <summary>Details</summary>
Motivation: To develop more efficient and scalable basis-set designs that can variationally encode electronic ground-state information into molecular orbitals with reduced computational cost.

Method: Introduced two formalisms: 1) reduced concentric even-tempered orbitals for improved scalability, and 2) symmetry-adapted even-tempered formalism using only primitive S-subshell Gaussian-type orbitals with two parameters for all exponent coefficients.

Result: The reduced formalism achieved hydrogen energy accuracy comparable to conventional methods with lower optimization cost. The molecular formalism produced dissociation curves for H2 more consistent with cc-pV5Z than cc-pVTZ at aug-cc-pVDZ size. Successfully tested on tetra-atomic hydrogen molecules.

Conclusion: The even-tempered formalisms show promise for efficient ground-state computation but have current limitations that require further improvements.

Abstract: We propose a system-oriented basis-set design based on even-tempered basis
functions to variationally encode electronic ground-state information into
molecular orbitals. First, we introduce a reduced formalism of concentric
even-tempered orbitals that achieves hydrogen energy accuracy on par with the
conventional formalism, with lower optimization cost and improved scalability.
Second, we propose a symmetry-adapted, even-tempered formalism specifically
designed for molecular systems. It requires only primitive S-subshell
Gaussian-type orbitals and uses two parameters to characterize all exponent
coefficients. In the case of the diatomic hydrogen molecule, the basis set
generated by this formalism produces a dissociation curve more consistent with
cc-pV5Z than cc-pVTZ at the size of aug-cc-pVDZ. Finally, we test our
even-tempered formalism against several types of tetra-atomic hydrogen
molecules for ground-state computation and point out its current limitations
and potential improvements.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [42] [Modelling the Solar Cycle Nonlinearities into the Algebraic Approach](https://arxiv.org/abs/2511.03611)
*Mohammed H. Talafha*

Main category: astro-ph.SR

TL;DR: Algebraic modeling of solar cycle nonlinearities shows tilt and latitude quenching mechanisms create dipole saturation, with their balance controlled by transport parameter λ_R rather than active region geometry.


<details>
  <summary>Details</summary>
Motivation: To understand solar cycle variability by accounting for nonlinear feedbacks that regulate the Sun's polar magnetic field buildup.

Method: Simplified algebraic approach modeling dipole contribution of active regions with tilt quenching (TQ) and latitude quenching (LQ) nonlinearities, using ensembles of synthetic cycles across dynamo effectivity range λ_R.

Result: Both TQ and LQ reduce polar field and create dipole saturation; their balance transitions near λ_R≈12°; ratio follows shallow power law (n≈0.36±0.04); weak sensitivity to active region geometry.

Conclusion: Nonlinear solar cycle saturation can be efficiently captured with algebraic formulations, providing transparent complement to full simulations, with LQ-TQ balance primarily controlled by transport parameter λ_R.

Abstract: Understanding and predicting solar-cycle variability requires accounting for
nonlinear feedbacks that regulate the buildup of the Sun's polar magnetic
field. We present a simplified but physically grounded algebraic approach that
models the dipole contribution of active regions (ARs) while incorporating two
key nonlinearities: tilt quenching (TQ) and latitude quenching (LQ). Using
ensembles of synthetic cycles across the dynamo effectivity range $\lambda_R$,
we quantify how these mechanisms suppress the axial dipole and impose
self-limiting feedback.
  Our results show that (i) both TQ and LQ reduce the polar field, and together
they generate a clear saturation (ceiling) of dipole growth with increasing
cycle amplitude; (ii) the balance between LQ and TQ, expressed as $R(\lambda_R)
= \mathrm{dev(LQ)}/\mathrm{dev(TQ)}$, transitions near $\lambda_R \approx
12^\circ$, with LQ dominating at low $\lambda_R$ and TQ at high $\lambda_R$;
(iii) over $8^\circ \leq \lambda_R \leq 20^\circ$, the ratio follows a shallow
offset power law with exponent $n \approx 0.36 \pm 0.04$, significantly flatter
than the $n=2$ scaling assumed in many surface flux--transport (SFT) models;
and (iv) symmetric, tilt-asymmetric, and morphology-asymmetric AR prescriptions
yield nearly identical $R(\lambda_R)$ curves, indicating weak sensitivity to AR
geometry for fixed transport.
  These findings demonstrate that nonlinear saturation of the solar cycle can
be captured efficiently with algebraic formulations, providing a transparent
complement to full SFT simulations. The method highlights that the LQ\--TQ
balance is primarily controlled by transport ($\lambda_R$), not by
active-region configuration, and statistically disfavors the SFT-based
$1/\lambda_R^{2}$ dependence.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [43] [Optimal Boundary Control of Diffusion on Graphs via Linear Programming](https://arxiv.org/abs/2511.03129)
*Harbir Antil,Rainald Löhner,Felipe Pérez*

Main category: math.OC

TL;DR: A linear programming framework for steady-state diffusion and flux optimization on geometric networks using discrete diffusion laws and boundary potentials as controls.


<details>
  <summary>Details</summary>
Motivation: To develop a mathematically rigorous optimization framework for diffusion processes on networks that preserves geometric fidelity and enforces physically meaningful constraints.

Method: Linear programming approach with discrete diffusion law on weighted oriented graphs, boundary potentials as controls, and constraints derived from gradient bounds including sign and flux-cap constraints.

Result: The LP admits a global minimizer under absence of negative recession directions, with boundedness conditions identified for both full-rank and rank-deficient flux maps.

Conclusion: The framework connects classical mathematical results with modern network-based diffusion modeling and is demonstrated on large-scale stadium and city network examples.

Abstract: We propose a linear programming (LP) framework for steady-state diffusion and
flux optimization on geometric networks. The state variable satisfies a
discrete diffusion law on a weighted, oriented graph, where conductances are
scaled by edge lengths to preserve geometric fidelity. Boundary potentials act
as controls that drive interior fluxes according to a linear network Laplacian.
The optimization problem enforces physically meaningful sign and flux-cap
constraints at all boundary edges, derived directly from a gradient bound. This
yields a finite-dimensional LP whose feasible set is polyhedral, and whose
boundedness and solvability follow from simple geometric or algebraic
conditions on the network data.
  We prove that under the absence of negative recession
directions--automatically satisfied in the presence of finite box bounds, flux
caps, or sign restrictions--the LP admits a global minimizer. Several
sufficient conditions guaranteeing boundedness of the feasible region are
identified, covering both full-rank and rank-deficient flux maps. The analysis
connects classical results such as the Minkowski--Weyl decomposition, Hoffman's
bound, and the fundamental theorem of linear programming with modern
network-based diffusion modeling.
  Two large-scale examples illustrate the framework: (i) A typical large
stadium in a major modern city, which forms a single connected component with
relatively uniform corridor widths, and a (ii) A complex street network
emanating from a large, historical city center, which forms a multi-component
system.

</details>


### [44] [HJB equations driven by the Dirichlet-Ferguson Laplacian in Wasserstein-Sobolev spaces](https://arxiv.org/abs/2511.03522)
*François Delarue,Mattia Martini,Giacomo Enrico Sodini*

Main category: math.OC

TL;DR: Develops analytic framework for PDEs on probability measure spaces using Wasserstein-Sobolev spaces, establishes existence/uniqueness for transport-diffusion and Hamilton-Jacobi equations, connects to interacting particle systems, and extends to semilinear equations and mean-field optimal control.


<details>
  <summary>Details</summary>
Motivation: To study linear and nonlinear PDEs defined on probability measure spaces over the torus, particularly focusing on developing analytical tools for infinite-dimensional analysis on Wasserstein spaces.

Method: Uses Wasserstein-Sobolev spaces with Dirichlet-Ferguson measure, develops Dirichlet form framework with infinite-dimensional Laplacian, connects PDE approach to interacting particle systems via Kolmogorov-type representations.

Result: Established existence and uniqueness results for transport-diffusion and Hamilton-Jacobi equations in Wasserstein space, provided probabilistic representations of solutions, extended theory to semilinear equations and mean-field optimal control with finite-dimensional approximations.

Conclusion: Successfully developed comprehensive analytic framework for PDEs on probability measure spaces, bridging infinite-dimensional analysis with probabilistic interpretations and providing practical finite-dimensional approximations for applications.

Abstract: We study linear and nonlinear PDEs defined on the space of
$\mathcal{P}(\mathbb{T}^d)$ over the flat torus $\mathbb{T}^d$, equipped with
the Dirichlet-Ferguson measure $\mathcal{D}$. We first develop an analytic
framework based on the Wasserstein-Sobolev space
$H^{1,2}(\mathcal{P}(\mathbb{T}^d), W_2, \mathcal{D})$ associated with the
Dirichlet form induced by the infinite-dimensional Laplacian acting on
functions of measures. Within this setting, we establish existence and
uniqueness results for transport-diffusion and Hamilton-Jacobi equations in the
Wasserstein space. Our analysis connects the PDE approach with a corresponding
interacting particles system providing a probabilistic (Kolmogorov-type)
representation of strong solutions. Finally, we extend the theory to semilinear
equations and mean-field optimal control problems, together with consistent
finite-dimensional approximations.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [45] [A Plug-and-Play Framework for Volumetric Light-Sheet Image Reconstruction](https://arxiv.org/abs/2511.03093)
*Yi Gong,Xinyuan Zhang,Jichen Chai,Yichen Ding,Yifei Lou*

Main category: cs.CV

TL;DR: A computational imaging framework combining Compressive Sensing with Light-Sheet Microscopy for high-speed, low-phototoxic cardiac imaging using compressed acquisition and advanced reconstruction algorithms.


<details>
  <summary>Details</summary>
Motivation: Traditional optical imaging struggles with the trade-off between spatial and temporal resolution needed to capture dynamic cellular structures in beating hearts on millisecond timescales.

Method: Uses compressed acquisition with random binary mask coding via DMD, and a Plug-and-Play framework solved with ADMM that incorporates advanced denoisers (Tikhonov, TV, BM3D) with temporal regularization for structural continuity.

Result: Successfully reconstructs cellular structures in zebrafish heart imaging under high compression ratios with excellent denoising performance and image clarity.

Conclusion: The method is effective and robust for real-world high-speed, low-light biological imaging scenarios, overcoming limitations of traditional cardiac imaging.

Abstract: Cardiac contraction is a rapid, coordinated process that unfolds across
three-dimensional tissue on millisecond timescales. Traditional optical imaging
is often inadequate for capturing dynamic cellular structure in the beating
heart because of a fundamental trade-off between spatial and temporal
resolution. To overcome these limitations, we propose a high-performance
computational imaging framework that integrates Compressive Sensing (CS) with
Light-Sheet Microscopy (LSM) for efficient, low-phototoxic cardiac imaging. The
system performs compressed acquisition of fluorescence signals via random
binary mask coding using a Digital Micromirror Device (DMD). We propose a
Plug-and-Play (PnP) framework, solved using the alternating direction method of
multipliers (ADMM), which flexibly incorporates advanced denoisers, including
Tikhonov, Total Variation (TV), and BM3D. To preserve structural continuity in
dynamic imaging, we further introduce temporal regularization enforcing
smoothness between adjacent z-slices. Experimental results on zebrafish heart
imaging under high compression ratios demonstrate that the proposed method
successfully reconstructs cellular structures with excellent denoising
performance and image clarity, validating the effectiveness and robustness of
our algorithm in real-world high-speed, low-light biological imaging scenarios.

</details>
