{"id": "2511.04041", "pdf": "https://arxiv.org/pdf/2511.04041", "abs": "https://arxiv.org/abs/2511.04041", "authors": ["Lei Li", "Jian-Guo Liu", "Yuliang Wang"], "title": "Relative entropy estimate and geometric ergodicity for implicit Langevin Monte Carlo", "categories": ["math.NA", "cs.NA", "math.PR", "82M31, 65C30, 60H10"], "comment": null, "summary": "We study the implicit Langevin Monte Carlo (iLMC) method, which simulates the\noverdamped Langevin equation via an implicit iteration rule. In many\napplications, iLMC is favored over other explicit schemes such as the\n(explicit) Langevin Monte Carlo (LMC). LMC may blow up when the drift field\n$\\nabla U$ is not globally Lipschitz, while iLMC has convergence guarantee when\nthe drift is only one-sided Lipschitz. Starting from an adapted continuous-time\ninterpolation, we prove a time-discretization error bound under the relative\nentropy (or the Kullback-Leibler divergence), where a crucial gradient estimate\nfor the logarithm numerical density is obtained via a sequence of PDE\ntechniques, including Bernstein method. Based on a reflection-type\ncontinuous-discrete coupling method, we prove the geometric ergodicity of iLMC\nunder the Wasserstein-1 distance. Moreover, we extend the error bound to a\nuniform-in-time one by combining the relative entropy error bound and the\nergodicity. Our proof technique is universal and can be applied to other\nimplicit or splitting schemes for simulating stochastic differential equations\nwith non-Lipschitz drifts.", "AI": {"tldr": "The paper analyzes the implicit Langevin Monte Carlo (iLMC) method, proving its convergence and geometric ergodicity for non-Lipschitz drift fields using PDE techniques and coupling methods.", "motivation": "Explicit schemes like LMC may fail when the drift field is not globally Lipschitz, while iLMC can handle one-sided Lipschitz drifts, making it more robust for practical applications.", "method": "Uses continuous-time interpolation, PDE techniques (Bernstein method) for gradient estimates, and reflection-type continuous-discrete coupling to prove geometric ergodicity under Wasserstein-1 distance.", "result": "Proves time-discretization error bound under relative entropy, geometric ergodicity of iLMC, and extends to uniform-in-time error bounds by combining entropy error and ergodicity.", "conclusion": "The proof technique is universal and applicable to other implicit or splitting schemes for simulating SDEs with non-Lipschitz drifts, establishing iLMC's theoretical guarantees."}}
{"id": "2511.04197", "pdf": "https://arxiv.org/pdf/2511.04197", "abs": "https://arxiv.org/abs/2511.04197", "authors": ["Andrew R. Winters", "David A. Kopriva", "Jan Nordstr\u00f6m"], "title": "Numerical boundary flux functions that give provable bounds for nonlinear initial boundary value problems with open boundaries", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We present a strategy for interpreting nonlinear, characteristic-type penalty\nterms as numerical boundary flux functions that provide provable bounds for\nsolutions to nonlinear hyperbolic initial boundary value problems with open\nboundaries. This approach is enabled by recent work that found how to express\nthe entropy flux as a quadratic form defined by a symmetric boundary matrix.\nThe matrix formulation provides additional information for how to\nsystematically design characteristic-based penalty terms for the weak\nenforcement of boundary conditions. A special decomposition of the boundary\nmatrix is required to define an appropriate set of characteristic-type\nvariables. The new boundary fluxes are directly compatible with high-order\naccurate split form discontinuous Galerkin spectral element and similar methods\nand guarantee that the solution is entropy stable and bounded solely by\nexternal data. We derive inflow-outflow boundary fluxes specifically for the\nBurgers equation and the two-dimensional shallow water equations, which are\nalso energy stable. Numerical experiments demonstrate that the new nonlinear\nfluxes do not fail in situations where standard boundary treatments based on\nlinear analysis do.", "AI": {"tldr": "A strategy for interpreting nonlinear characteristic-type penalty terms as numerical boundary flux functions that provide provable bounds for solutions to nonlinear hyperbolic initial boundary value problems with open boundaries.", "motivation": "To develop provable bounds for solutions to nonlinear hyperbolic initial boundary value problems with open boundaries, addressing limitations of standard boundary treatments based on linear analysis.", "method": "Uses a matrix formulation to express entropy flux as a quadratic form, enabling systematic design of characteristic-based penalty terms. Requires special decomposition of boundary matrix to define characteristic-type variables. Compatible with high-order accurate split form discontinuous Galerkin spectral element methods.", "result": "New boundary fluxes guarantee entropy stability and solution bounded solely by external data. Derived inflow-outflow boundary fluxes for Burgers equation and 2D shallow water equations that are also energy stable.", "conclusion": "The nonlinear boundary fluxes successfully handle situations where standard linear analysis-based boundary treatments fail, providing provable stability and boundedness for nonlinear hyperbolic problems."}}
{"id": "2511.04265", "pdf": "https://arxiv.org/pdf/2511.04265", "abs": "https://arxiv.org/abs/2511.04265", "authors": ["Alessandra Aimi", "Giulia Di Credico", "Heiko Gimperlein", "Chiara Guardasoni"], "title": "A space-time adaptive boundary element method for the wave equation", "categories": ["math.NA", "cs.NA"], "comment": "22 pages, 23 figures, to appear in SIAM Journal on Scientific\n  Computing", "summary": "This article initiates the study of space-time adaptive mesh refinements for\ntime-dependent boundary element formulations of wave equations. Based on error\nindicators of residual type, we formulate an adaptive boundary element\nprocedure for acoustic soft-scattering problems with local tensor-product\nrefinements of the space-time mesh. We discuss the algorithmic challenges and\ninvestigate the proposed method in numerical experiments. In particular, we\nstudy the performance and improved convergence rates with respect to the energy\nnorm for problems dominated by spatial, temporal or traveling singularities of\nthe solution. The efficiency of the considered rigorous and heuristic a\nposteriori error indicators is discussed.", "AI": {"tldr": "This paper introduces space-time adaptive mesh refinement for boundary element methods applied to wave equations, focusing on acoustic soft-scattering problems with local tensor-product refinements.", "motivation": "To develop efficient adaptive boundary element procedures for time-dependent wave equations that can handle various types of singularities (spatial, temporal, traveling) through space-time mesh refinements.", "method": "Formulated an adaptive boundary element procedure based on residual-type error indicators with local tensor-product refinements of the space-time mesh for acoustic soft-scattering problems.", "result": "The method demonstrates improved convergence rates in energy norm for problems with different singularity types, and both rigorous and heuristic a posteriori error indicators show efficiency.", "conclusion": "Space-time adaptive mesh refinements effectively handle various singularity types in wave equation formulations, with the proposed error indicators proving efficient for boundary element methods."}}
{"id": "2511.04309", "pdf": "https://arxiv.org/pdf/2511.04309", "abs": "https://arxiv.org/abs/2511.04309", "authors": ["Michael Ludkovski", "Changgen Xie", "Zimu Zhu"], "title": "DeepPAAC: A New Deep Galerkin Method for Principal-Agent Problems", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "We consider numerical resolution of principal-agent (PA) problems in\ncontinuous time. We formulate a generic PA model with continuous and lump\npayments and a multi-dimensional strategy of the agent. To tackle the resulting\nHamilton-Jacobi-Bellman equation with an implicit Hamiltonian we develop a\nnovel deep learning method: the Deep Principal-Agent Actor Critic (DeepPAAC)\nActor-Critic algorithm. DeepPAAC is able to handle multi-dimensional states and\ncontrols, as well as constraints. We investigate the role of the neural network\narchitecture, training designs, loss functions, etc. on the convergence of the\nsolver, presenting five different case studies.", "AI": {"tldr": "Developed DeepPAAC, a deep learning method for solving principal-agent problems in continuous time with multi-dimensional states and controls.", "motivation": "To address the numerical resolution of principal-agent problems with continuous and lump payments and multi-dimensional agent strategies.", "method": "Deep Principal-Agent Actor Critic (DeepPAAC) algorithm using deep learning to solve Hamilton-Jacobi-Bellman equations with implicit Hamiltonians.", "result": "Successfully handles multi-dimensional states, controls, and constraints; investigated neural network architecture, training designs, and loss functions across five case studies.", "conclusion": "DeepPAAC provides an effective deep learning approach for solving complex principal-agent problems in continuous time settings."}}
{"id": "2511.03930", "pdf": "https://arxiv.org/pdf/2511.03930", "abs": "https://arxiv.org/abs/2511.03930", "authors": ["C. E. Schaefer", "A. C. Sontag", "N. M. Ferraro", "J. D. Weberski", "S. J. Diem"], "title": "Modeling of Injected Current Stream-Induced 3D Perturbations in Local Helicity Injection Plasmas", "categories": ["physics.plasm-ph"], "comment": "The following article has been submitted to Physics of Plasmas. After\n  it is published, it will be found at\n  https://publishing.aip.org/resources/librarians/products/journals/", "summary": "Solenoid-free tokamak startup techniques are essential for spherical tokamaks\nand offer a pathway to cost reduction and design simplification in fusion\nenergy systems. Local helicity injection (LHI) is one such approach, employing\ncompact edge current sources to drive open field line current that initiates\nand sustains tokamak plasmas. The recently commissioned Pegasus-III spherical\ntokamak provides a platform for advancing this and other solenoid-free startup\nmethods. This study investigates the effect of LHI on magnetic topology in\nPegasus-III plasmas. A helical filament model represents the injected current,\nand the linear plasma response to its 3D field is calculated with M3D-C1.\nPoincar\\'e mapping reveals substantial flux surface degradation in all modeled\ncases. The onset of overlapping magnetic structures and large-scale surface\ndeformation begins at $\\Psi_{N} \\approx 0.37$, indicating a broad region of\nperturbed topology extending toward the edge. In rotating plasmas, both\nsingle-fluid and two-fluid models exhibit partial screening of the $n = 1$\nperturbation, with two-fluid calculations showing stronger suppression near the\nedge. In contrast, the absence of rotation leads to strong resonant field\namplification in the single-fluid case, while the two-fluid case with zero\nelectron rotation mitigates this amplification and preserves edge screening.\nMagnetic probe measurements indicate that modeling the stream with spatial\nspreading$-$representing distributed current and/or oscillatory motion$-$better\nreproduces measured magnetic power profiles than a rigid filament model. The\nresults underscore the role of rotation and two-fluid physics in screening\nstream perturbations and point to plasma flow measurements and refined stream\nmodels as key steps toward improving predictive fidelity.", "AI": {"tldr": "Local helicity injection (LHI) for solenoid-free tokamak startup causes substantial magnetic topology degradation in Pegasus-III plasmas, with rotation and two-fluid physics playing key roles in screening perturbations.", "motivation": "Solenoid-free startup techniques like LHI are essential for spherical tokamaks to reduce costs and simplify fusion energy system designs.", "method": "Used helical filament model for injected current, calculated linear plasma response with M3D-C1, performed Poincar\u00e9 mapping, and compared single-fluid vs two-fluid models with/without rotation.", "result": "LHI causes flux surface degradation starting at \u03a8_N \u2248 0.37, with rotation providing partial screening of n=1 perturbations. Two-fluid models show stronger edge suppression. Magnetic probe measurements match better with spatially spread stream models.", "conclusion": "Rotation and two-fluid physics are crucial for screening LHI perturbations. Future work should focus on plasma flow measurements and refined stream models for improved predictive capability."}}
{"id": "2511.03854", "pdf": "https://arxiv.org/pdf/2511.03854", "abs": "https://arxiv.org/abs/2511.03854", "authors": ["Giorgio Stefani"], "title": "On blow-ups of sets with finite fractional variation", "categories": ["math.AP", "math.FA", "Primary 49Q15. Secondary 26A33, 28A75, 49Q20"], "comment": "7 pages", "summary": "Given $\\alpha \\in (0,1)$ and a set $E \\subset \\mathbb R^N$ with locally\nfinite fractional $\\alpha$-variation, we show that for almost every $x \\in\n\\mathbb R^N$ with respect to the $\\alpha$-variation measure of $\\mathbf 1_E$,\nif $E$ admits a non-trivial tangent set at $x$ with locally finite integer\nperimeter, then $E$ also admits a tangent half-space oriented by the fractional\nunit normal of $E$ at $x$.", "AI": {"tldr": "For sets with finite fractional \u03b1-variation, almost every point with a non-trivial tangent set having finite integer perimeter also has a tangent half-space oriented by the fractional normal.", "motivation": "To establish connections between geometric properties of sets with fractional variation and their tangent structures, particularly relating non-trivial tangent sets to half-space approximations.", "method": "Analysis of sets with locally finite fractional \u03b1-variation, examining tangent sets and their properties at points where the \u03b1-variation measure is concentrated.", "result": "Proves that almost every point (with respect to \u03b1-variation measure) with a non-trivial tangent set having locally finite integer perimeter admits a tangent half-space oriented by the fractional unit normal.", "conclusion": "There is a strong geometric relationship between the existence of non-trivial tangent sets and half-space approximations for sets with fractional variation, with the fractional normal playing a key orientational role."}}
{"id": "2511.04062", "pdf": "https://arxiv.org/pdf/2511.04062", "abs": "https://arxiv.org/abs/2511.04062", "authors": ["Beichen Zheng", "Ying Chen", "Lili Wen", "Xiaofei Wu"], "title": "Robust Subgroup Method Using DE Algorithm for Resonance Self-Shielding Calculation", "categories": ["physics.comp-ph"], "comment": "16 pages,2 figures", "summary": "This paper presents an enhanced version of the subgroup method for resonance\nself-shielding treatment, termed the robust subgroup method, which integrates\nRobust Estimation (RE) with a Differential Evolution (DE) algorithm. The RE\napproach is employed to handle model misspecification and data contamination,\nwhile the DE algorithm serves as an optimization tool within the RE framework\nto obtain constrained solutions. Numerical validation against experimental\nbenchmarks shows that the proposed method removes a systematic absorption bias\nin conventional subgroup fits that would otherwise depress reactivity. This\nbias appears only in benchmarks sensitive to U-238. Mechanistically, it\nreflects a threshold-like conditioning failure: strong self-shielding leverage\ndominates the loss and is magnified by dilution-induced multicollinearity. This\nadverse conditioning appears to be seeded by a narrow, sparse resonance\nstructure at low energies in fertile even-even nuclides, thereby causing rapid\nself-shielding response saturation and a weak Doppler broadening. By bounding\ninfluence and enforcing feasibility within an RE-DE framework, the inferred\nsubgroup parameters track the underlying physics more faithfully, improving the\npredictive fidelity of subsequent transport simulations.", "AI": {"tldr": "Enhanced subgroup method combining Robust Estimation and Differential Evolution to remove systematic absorption bias in resonance self-shielding treatment, improving predictive accuracy in transport simulations.", "motivation": "To address systematic absorption bias in conventional subgroup methods that depresses reactivity, particularly in benchmarks sensitive to U-238, caused by threshold-like conditioning failures from strong self-shielding leverage and dilution-induced multicollinearity.", "method": "Robust subgroup method integrating Robust Estimation (RE) to handle model misspecification and data contamination, with Differential Evolution (DE) algorithm as optimization tool within RE framework to obtain constrained solutions.", "result": "Numerical validation shows the method removes systematic absorption bias that appears only in U-238 sensitive benchmarks, improving predictive fidelity by bounding influence and enforcing feasibility.", "conclusion": "The RE-DE framework enables subgroup parameters to track underlying physics more faithfully, addressing conditioning failures seeded by narrow, sparse resonance structures in fertile even-even nuclides at low energies."}}
{"id": "2511.04369", "pdf": "https://arxiv.org/pdf/2511.04369", "abs": "https://arxiv.org/abs/2511.04369", "authors": ["Renfeng Peng", "Chengkai Zhu", "Bin Gao", "Xin Wang", "Ya-xiang Yuan"], "title": "Normalized tensor train decomposition", "categories": ["math.NA", "cs.NA", "math.OC", "quant-ph", "15A69, 65K05, 90C30, 81-08"], "comment": "26 pages, 9 figures, 4 tables", "summary": "Tensors with unit Frobenius norm are fundamental objects in many fields,\nincluding scientific computing and quantum physics, which are able to represent\nnormalized eigenvectors and pure quantum states. While the tensor train\ndecomposition provides a powerful low-rank format for tackling high-dimensional\nproblems, it does not intrinsically enforce the unit-norm constraint. To\naddress this, we introduce the normalized tensor train (NTT) decomposition,\nwhich aims to approximate a tensor by unit-norm tensors in tensor train format.\nThe low-rank structure of NTT decomposition not only saves storage and\ncomputational cost but also preserves the underlying unit-norm structure. We\nprove that the set of fixed-rank NTT tensors forms a smooth manifold, and the\ncorresponding Riemannian geometry is derived, paving the way for geometric\nmethods. We propose NTT-based methods for low-rank tensor recovery,\nhigh-dimensional eigenvalue problem, estimation of stabilizer rank, and\ncalculation of the minimum output R\\'enyi 2-entropy of quantum channels.\nNumerical experiments demonstrate the superior efficiency and scalability of\nthe proposed NTT-based methods.", "AI": {"tldr": "The paper introduces normalized tensor train (NTT) decomposition to approximate unit-norm tensors while preserving the tensor train format's low-rank structure, enabling efficient geometric methods for various applications.", "motivation": "Tensors with unit Frobenius norm are fundamental in scientific computing and quantum physics, but existing tensor train decomposition doesn't enforce unit-norm constraints, limiting its applicability to normalized problems.", "method": "Developed normalized tensor train (NTT) decomposition that represents unit-norm tensors in tensor train format, proved it forms a smooth manifold, derived Riemannian geometry, and proposed geometric optimization methods.", "result": "The NTT decomposition successfully preserves unit-norm structure while maintaining low-rank efficiency, enabling applications in tensor recovery, eigenvalue problems, quantum state analysis, and quantum channel entropy calculations.", "conclusion": "NTT-based methods demonstrate superior efficiency and scalability compared to traditional approaches, providing a principled geometric framework for handling unit-norm tensor problems across scientific computing and quantum physics domains."}}
{"id": "2511.04044", "pdf": "https://arxiv.org/pdf/2511.04044", "abs": "https://arxiv.org/abs/2511.04044", "authors": ["Yuehao Ma", "Pengfei Liu", "Jian Bao", "Zhihong Lin", "Huishan Cai"], "title": "Electromagnetic turbulence in EAST plasmas with internal transport barrier", "categories": ["physics.plasm-ph"], "comment": null, "summary": "In this study, global nonlinear electromagnetic gyrokinetic simulations are\nconducted to investigate turbulence in the Internal transport barrier (ITB)\nregion of the EAST tokamak discharge with weakly reversed magnetic shear.\nLinear simulations reveal two dominant ion temperature gradient (ITG) modes: a\nhigher frequency mode at the $q=1$ surface, which dominates in the\nelectrostatic limit, and a lower frequency mode near the $q_{\\min}$ surface,\nwhich prevails under the experimental $\\beta$ (the ratio of plasma pressure to\nmagnetic pressure). Finite $\\beta$ effects effectively suppress higher\nfrequency ITG modes, and once $\\beta_i$ on axis exceeds 0.5\\%, this ITG mode is\nno longer dominant, and the ITG mode near $q_{\\min}$ surface becomes the\nprimary instability. Therefore, electromagnetic effects play a crucial role in\nstabilizing ITG modes, and in causing the transition between the most unstable\nmode at different radial positions. The linear growth rate of the unstable mode\nin the electrostatic limit is approximately 1.25 times higher than that of the\ndominant mode in the electromagnetic case. However, in the electromagnetic\nnonlinear regime, the thermal ion heat conductivity is reduced by at least a\nfactor of 4. This reduction primarily results from nonlinear electromagnetic\neffects enhancing the shearing effect of zonal flows, thereby further\nsuppressing microturbulence. Finally, energetic particles exert a slight\nstabilizing effect on ITG turbulence due to dilution and finite $\\beta$\ncontributions. It is emphasized that the electromagnetic effect on ITG with\nweak magnetic shear should be included to accurately calculate the transport\ncoefficients.", "AI": {"tldr": "Global nonlinear electromagnetic gyrokinetic simulations show electromagnetic effects suppress ITG turbulence in EAST tokamak ITB regions, reducing thermal ion heat conductivity by at least 4x through enhanced zonal flow shearing.", "motivation": "To investigate turbulence in the Internal Transport Barrier (ITB) region of EAST tokamak with weakly reversed magnetic shear, particularly understanding the role of electromagnetic effects on ion temperature gradient (ITG) modes.", "method": "Global nonlinear electromagnetic gyrokinetic simulations, including linear analysis of ITG modes at different radial positions (q=1 and q_min surfaces), studying finite \u03b2 effects, and examining nonlinear electromagnetic regime with zonal flows.", "result": "Finite \u03b2 effects suppress higher frequency ITG modes at q=1 surface; when \u03b2_i exceeds 0.5%, the ITG mode near q_min becomes dominant. Nonlinear electromagnetic effects reduce thermal ion heat conductivity by at least factor of 4 through enhanced zonal flow shearing. Energetic particles provide slight stabilizing effect.", "conclusion": "Electromagnetic effects play crucial role in stabilizing ITG modes and causing transitions between dominant modes. Including electromagnetic effects is essential for accurate transport coefficient calculations in ITB regions with weak magnetic shear."}}
{"id": "2511.03973", "pdf": "https://arxiv.org/pdf/2511.03973", "abs": "https://arxiv.org/abs/2511.03973", "authors": ["Changfeng Gui", "Jun Wang", "Wen Yang", "Yong Zhang"], "title": "Bifurcation analysis of Stokes waves with piecewise smooth vorticity in deep water", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we establish the existence of Stokes waves with piecewise\nsmooth vorticity in a two-dimensional, infinitely deep fluid domain. These\nwaves represent traveling water waves propagating over sheared currents in a\nsemi-infinite cylinder, where the vorticity may exhibit discontinuities. The\nanalysis is carried out by applying a hodograph transformation, which\nreformulates the original free boundary problem into an abstract elliptic\nboundary value problem. Compared to previously studied steady water waves, the\npresent setting introduces several novel features: the presence of an internal\ninterface, an unbounded spatial domain, and a non-Fredholm linearized operator.\nTo address these difficulties, we introduce a height function formulation,\ncasting the problem as a transmission problem with suitable transmission\nconditions. A singular bifurcation approach is then employed, combining global\nbifurcation theory with Whyburns topological lemma. Along the global\nbifurcation branch, we show that the resulting wave profiles either attain\narbitrarily large wave speed or approach horizontal stagnation.", "AI": {"tldr": "Existence of Stokes waves with piecewise smooth vorticity in 2D deep water, using hodograph transformation and singular bifurcation approach.", "motivation": "To study traveling water waves over sheared currents with discontinuous vorticity in unbounded domains, addressing novel challenges like internal interfaces and non-Fredholm operators.", "method": "Hodograph transformation to reformulate as elliptic boundary value problem, height function formulation as transmission problem, and singular bifurcation combining global bifurcation theory with Whyburns lemma.", "result": "Established existence of such waves, showing along bifurcation branch waves either achieve arbitrarily large wave speed or approach horizontal stagnation.", "conclusion": "Successfully proved existence of Stokes waves with piecewise smooth vorticity in deep water, overcoming challenges of internal interfaces and unbounded domains."}}
{"id": "2511.04277", "pdf": "https://arxiv.org/pdf/2511.04277", "abs": "https://arxiv.org/abs/2511.04277", "authors": ["Bernat Frangi"], "title": "Novel Numerical Methods for Accurate Space Thermal Analysis: Enforcing View Factors and Modeling Diffuse Reflectivity", "categories": ["physics.comp-ph", "astro-ph.IM"], "comment": null, "summary": "Accurate thermal analysis is crucial for modern spacecraft, driving demand\nfor reliable modeling tools. This research advances space thermal modeling by\nimproving the simulation accuracy and efficiency of radiative heat transfer,\nthe dominant mode of heat exchange in space. To this end, we incorporate\ndiffuse reflectivity using the Gebhart method, which computes radiative\nexchange factors (REFs) from geometric view factors. The view factors, obtained\nvia Monte Carlo ray tracing (MCRT), require post-processing to mitigate\nstatistical errors. Critically, existing correction schemes cannot\nsimultaneously enforce closure and reciprocity for open systems. This research\naddresses this gap by proposing two novel enforcement methods: (i) a\nleast-squares optimization with non-negativity rectification (NNR) and small\npositive value avoidance (SPVA), and (ii) an iterative enforcement algorithm.\nTo ensure consistency across different discretization levels, this work also\nintroduces the multi-node surface model relations to formalize the connection\nbetween sub-face, face, and node representations of view factors and REFs. A\nsimple case study demonstrates a substantial reduction in mean absolute error\n(MAE): the least-squares method achieves an 81% MAE reduction, while the\niterative method offers the best balance of accuracy (56% MAE reduction) and\ncomputational efficiency. A second case study shows that including diffuse\nreflections decreases the steady-state temperature of a plate by $4^{\\circ}C$,\nreinforcing that reflected radiation reduces net absorption. This work\nintroduces and validates computationally efficient methods for integrating\ndiffuse reflectivity into space thermal analyses and for consistently coupling\nmulti-node surface radiative models. The results enable more accurate and\nrobust thermal predictions for spacecraft systems.", "AI": {"tldr": "This research improves space thermal modeling by developing novel methods to incorporate diffuse reflectivity and correct view factor errors in radiative heat transfer simulations, enabling more accurate spacecraft thermal predictions.", "motivation": "Accurate thermal analysis is crucial for modern spacecraft, but existing correction schemes cannot simultaneously enforce closure and reciprocity for open systems in radiative heat transfer modeling.", "method": "Proposes two novel enforcement methods: (1) least-squares optimization with non-negativity rectification and small positive value avoidance, and (2) an iterative enforcement algorithm. Also introduces multi-node surface model relations to formalize connections between different discretization levels.", "result": "Substantial reduction in mean absolute error: least-squares method achieves 81% MAE reduction, iterative method offers 56% MAE reduction with best computational efficiency. Including diffuse reflections decreases steady-state temperature of a plate by 4\u00b0C.", "conclusion": "The work introduces and validates computationally efficient methods for integrating diffuse reflectivity into space thermal analyses and consistently coupling multi-node surface radiative models, enabling more accurate and robust thermal predictions for spacecraft systems."}}
{"id": "2511.04404", "pdf": "https://arxiv.org/pdf/2511.04404", "abs": "https://arxiv.org/abs/2511.04404", "authors": ["Athanasios C. Antoulas", "Ion Victor Gosea", "Charles Poussot-Vassal"], "title": "The Loewner framework applied to Zolotarev sign and ratio problems", "categories": ["math.NA", "cs.NA", "93A15, 93A30, 93B11, 93B15, 93C05, 93C80"], "comment": "24 pages, 15 figures", "summary": "In this work, we propose a numerical study concerning the approximation of\nfunctions associated with the 3rd and 4th Zolotarev problems. We compare\nvarious methods, in particular the Loewner framework, the standard AAA\nalgorithm, and recently-proposed extensions of AAA (namely, the sign and Lawson\nvariants). We show that the Loewner framework is fast and reliable, and\nprovides approximants with a high level of accuracy. When the approximants are\nof a higher degree, Loewner approximants are often more accurate than\nnear-optimal ones computed with AAA-Lawson. Last but not least, the Loewner\nframework is a direct method for which the running time is typically lower than\nthat of the iterative AAA-Lawson variants. Moreover, for the latter, the\nrunning time increases substantially with the degree of the approximant,\nwhereas for the Loewner method, it remains constant. These claims are supported\nby an extensive numerical treatment.", "AI": {"tldr": "Comparison of approximation methods for Zolotarev problems shows Loewner framework outperforms AAA variants in speed and accuracy.", "motivation": "To evaluate and compare different numerical methods for approximating functions in the 3rd and 4th Zolotarev problems, particularly focusing on computational efficiency and accuracy.", "method": "Numerical study comparing Loewner framework, standard AAA algorithm, and AAA extensions (sign and Lawson variants) for function approximation.", "result": "Loewner framework is fast, reliable, and provides highly accurate approximants, often outperforming AAA-Lawson for higher-degree approximations with constant running time.", "conclusion": "The Loewner framework is superior to AAA variants for Zolotarev problems, offering better accuracy, faster computation, and constant running time regardless of approximant degree."}}
{"id": "2511.04051", "pdf": "https://arxiv.org/pdf/2511.04051", "abs": "https://arxiv.org/abs/2511.04051", "authors": ["Yuehao Ma", "Bin Zhang", "Pengfei Liu", "Jian Bao", "Zhihong Lin", "Huishan Cai", "Liutian Gao", "AhDi Liu", "Hailin Zhao", "Tao Zhang"], "title": "Cross-scale Interaction between Microturbulence and Fishbone in Fusion Plasmas", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Global gyrokinetic simulations are performed for the first time to\ninvestigate cross-scale interactions between electromagnetic ion temperature\ngradient (ITG) turbulence and fishbone instability in tokamak plasmas. The\ninvestigation of fluctuation response in the multiscale simulation including\nboth instabilities indicates a strong impact of fishbone on ITG turbulence.\nDetailed analysis reveals that fishbone-driven zonal radial electric fields at\nnonlinear saturation significantly suppress electromagnetic ITG turbulence,\nreducing ion thermal transport close to the neoclassical level. The simulation\nresults agree well with experimental observations that turbulence suppression\nduring fishbone bursts. These findings advance understanding of multiscale\ninteractions that enhance thermal confinement in fusion plasmas.", "AI": {"tldr": "Global gyrokinetic simulations reveal that fishbone instability-driven zonal radial electric fields significantly suppress electromagnetic ITG turbulence, reducing ion thermal transport to neoclassical levels.", "motivation": "To investigate cross-scale interactions between electromagnetic ion temperature gradient (ITG) turbulence and fishbone instability in tokamak plasmas, as these multiscale interactions are crucial for understanding thermal confinement in fusion plasmas.", "method": "Performed global gyrokinetic simulations for the first time to study the interaction between electromagnetic ITG turbulence and fishbone instability in tokamak plasmas.", "result": "Fishbone-driven zonal radial electric fields at nonlinear saturation significantly suppress electromagnetic ITG turbulence, reducing ion thermal transport close to the neoclassical level. The simulation results agree well with experimental observations of turbulence suppression during fishbone bursts.", "conclusion": "These findings advance understanding of multiscale interactions that enhance thermal confinement in fusion plasmas, demonstrating that fishbone instability can play a beneficial role in turbulence suppression."}}
{"id": "2511.04039", "pdf": "https://arxiv.org/pdf/2511.04039", "abs": "https://arxiv.org/abs/2511.04039", "authors": ["Bobo Hua", "Lili Wang"], "title": "Isocapacitary constants associated with $p$-Laplacian on graphs", "categories": ["math.AP", "math.SP", "05C50, 58C40, 58J50, 47J10"], "comment": "20 pages", "summary": "In this paper, we introduce isocapacitary constants for the $p$-Laplacian on\ngraphs and apply them to derive estimates for the first eigenvalues of the\nDirichlet $p$-Laplacian, the Neumann $p$-Laplacian, and the $p$-Steklov\nproblem.", "AI": {"tldr": "Introduction of isocapacitary constants for p-Laplacian on graphs to estimate first eigenvalues of Dirichlet, Neumann, and p-Steklov problems.", "motivation": "To develop analytical tools for estimating eigenvalues of various p-Laplacian operators on graphs, extending classical spectral theory to discrete settings.", "method": "Define isocapacitary constants specifically for p-Laplacian operators on graphs and apply them to derive eigenvalue bounds.", "result": "Obtained estimates for the first eigenvalues of Dirichlet p-Laplacian, Neumann p-Laplacian, and p-Steklov problem using the introduced isocapacitary constants.", "conclusion": "Isocapacitary constants provide effective tools for eigenvalue estimation in graph-based p-Laplacian problems, bridging continuous and discrete spectral analysis."}}
{"id": "2511.04483", "pdf": "https://arxiv.org/pdf/2511.04483", "abs": "https://arxiv.org/abs/2511.04483", "authors": ["Chaithanya Purushottam Bhat", "Pranav Suryawanshi", "Aditya Guneja", "Debashis Bandyopadhyay"], "title": "Unveiling the Adsorption and Electronic Interactions of Drugs on 2D Graphsene: Insights from DFT and Machine Learning Approach", "categories": ["physics.comp-ph"], "comment": "19 pages, 8 figures", "summary": "Efficient identification of promising drug candidates for nanomaterial-based\ndelivery systems is essential for advancing next-generation therapeutics. In\nthis work, we present a synergistic framework combining density functional\ntheory (DFT) and machine learning (ML) to explore the adsorption behavior and\nelectronic interactions of drugs on a novel 2D graphene allotrope, termed\nGraphsene (GrS). Graphsene, characterized by its porous ring topology and large\nsurface area, offers an excellent platform for efficient adsorption and strong\nelectronic coupling with drug molecules. A dataset comprising 67 drugs adsorbed\non various 2D substrates was employed to train the ML model, which was\nsubsequently applied to predict suitable drug candidates for GrS based on\nmolecular size and adsorption energy criteria (database link provided in a\nlater section). The ML model exhibited robust predictive accuracy, achieving a\nmean absolute error of 0.075 eV upon DFT validation, though its sensitivity to\ninitialization highlighted the need for larger and more diverse datasets.\nDFT-based analyses, including adsorption energetics, projected density of\nstates (PDOS), and Bader charge calculations, revealed pronounced charge\ntransfer and electronic coupling between the drug molecules and the GrS\nsurface, elucidating the fundamental nature of drug-substrate interactions. The\nstudy reveals that the integrated DFT-ML strategy offers a rapid,\ncost-efficient approach for screening and understanding drug-nanomaterial\ninteractions, paving the way for data-driven design of advanced\nnanomaterial-enabled drug delivery systems.", "AI": {"tldr": "Synergistic DFT-ML framework predicts drug adsorption on novel 2D graphene allotrope (Graphsene) with high accuracy, enabling efficient screening of drug candidates for nanomaterial-based delivery systems.", "motivation": "Efficient identification of promising drug candidates for nanomaterial-based delivery systems is essential for advancing next-generation therapeutics.", "method": "Combined density functional theory (DFT) and machine learning (ML) approach using dataset of 67 drugs on 2D substrates; DFT analyses include adsorption energetics, PDOS, and Bader charge calculations.", "result": "ML model achieved 0.075 eV mean absolute error in DFT validation; DFT revealed pronounced charge transfer and electronic coupling between drugs and Graphsene surface.", "conclusion": "Integrated DFT-ML strategy offers rapid, cost-efficient approach for screening drug-nanomaterial interactions, enabling data-driven design of advanced drug delivery systems."}}
{"id": "2511.04413", "pdf": "https://arxiv.org/pdf/2511.04413", "abs": "https://arxiv.org/abs/2511.04413", "authors": ["Jianfeng Lu", "Xuda Ye", "Zhennan Zhou"], "title": "Mean square error analysis of stochastic gradient and variance-reduced sampling algorithms", "categories": ["math.NA", "cs.NA", "65C30, 60H35, 62F15"], "comment": null, "summary": "This paper considers mean square error (MSE) analysis for stochastic gradient\nsampling algorithms applied to underdamped Langevin dynamics under a global\nconvexity assumption. A novel discrete Poisson equation framework is developed\nto bound the time-averaged sampling error. For the Stochastic Gradient UBU\n(SG-UBU) sampler, we derive an explicit MSE bound and establish that the\nnumerical bias exhibits first-order convergence with respect to the step size\n$h$, with the leading error coefficient proportional to the variance of the\nstochastic gradient. The analysis is further extended to variance-reduced\nalgorithms for finite-sum potentials, specifically the SVRG-UBU and SAGA-UBU\nmethods. For these algorithms, we identify a phase transition phenomenon\nwhereby the convergence rate of the numerical bias shifts from first to second\norder as the step size decreases below a critical threshold. Theoretical\nfindings are validated by numerical experiments. In addition, the analysis\nprovides a practical empirical criterion for selecting between the mini-batch\nSG-UBU and SVRG-UBU samplers to achieve optimal computational efficiency.", "AI": {"tldr": "MSE analysis of stochastic gradient sampling algorithms for underdamped Langevin dynamics, showing first-order convergence for SG-UBU and phase transition to second-order convergence for variance-reduced methods.", "motivation": "To analyze mean square error for stochastic gradient sampling algorithms in underdamped Langevin dynamics under convexity assumptions, providing theoretical guarantees and practical selection criteria.", "method": "Developed a novel discrete Poisson equation framework to bound time-averaged sampling error, analyzed SG-UBU sampler and extended to variance-reduced algorithms (SVRG-UBU and SAGA-UBU).", "result": "SG-UBU exhibits first-order convergence with step size, variance-reduced methods show phase transition from first to second-order convergence below critical step size threshold, validated by numerical experiments.", "conclusion": "The analysis provides theoretical guarantees for stochastic gradient samplers and practical criteria for selecting optimal algorithms (mini-batch SG-UBU vs SVRG-UBU) based on computational efficiency."}}
{"id": "2511.04356", "pdf": "https://arxiv.org/pdf/2511.04356", "abs": "https://arxiv.org/abs/2511.04356", "authors": ["Jannis Teunissen", "Yuting Gao"], "title": "Stochastic simulation of partial discharge inception", "categories": ["physics.plasm-ph"], "comment": null, "summary": "We present a Monte Carlo method for simulating the inception of electric\ndischarges in gases. The input consists of an unstructured grid containing the\nelectrostatic field. The output of the model is the estimated probability of\ndischarge inception per initial electron position, as well as the estimated\ntime lag between the appearance of the initial electron and discharge\ninception. To obtain these quantities electron avalanches are simulated for\ninitial electron positions throughout the whole domain, also including regions\nbelow the critical electric field. Avalanches are assumed to propagate along\nfield lines, and they can produce additional avalanches due to photon and ion\nfeedback. If the number of avalanches keeps increasing over time we assume that\nan electric discharge will eventually form. A statistical distribution for the\nelectron avalanche size is used, which is also valid for gases with strong\nelectron attachment. We compare this distribution against the results of\nparticle simulations. Furthermore, we demonstrate examples of inception\nsimulations in 2D Cartesian, 2D axisymmetric and 3D electrode geometries.", "AI": {"tldr": "A Monte Carlo method for simulating electric discharge inception in gases using electrostatic field data on unstructured grids, estimating discharge probability and time lag per initial electron position.", "motivation": "To develop a computational model that can predict electric discharge inception probabilities and timing across various electrode geometries, including regions with sub-critical electric fields.", "method": "Simulates electron avalanches along field lines with photon and ion feedback mechanisms, using statistical distributions for avalanche size validated against particle simulations.", "result": "Successfully demonstrates discharge inception simulations in 2D Cartesian, 2D axisymmetric, and 3D electrode geometries with validated statistical distributions.", "conclusion": "The method provides reliable estimates of discharge inception probability and timing across different geometries, including challenging cases with electron attachment."}}
{"id": "2511.04046", "pdf": "https://arxiv.org/pdf/2511.04046", "abs": "https://arxiv.org/abs/2511.04046", "authors": ["Guoming Zhang"], "title": "The Kato problem and extensions for degenerate elliptic operators of higher order in weighted spaces", "categories": ["math.AP"], "comment": null, "summary": "We consider the Kato problem and extensions for degenerate elliptic operators\nof arbitrary order $2m$ ($m\\geq 1$), whose coefficients are measurable,\ncomplex-valued and satisfy the G$\\mathring{a}$rding inequality with respect to\na Muckenhoupt $A_{2}$-weight; this generalizes the work of [Cruz-Uribe, Martell\nand Rios 2018]. As an application, the unweighted $L^{p}$-Dirichlet, regularity\nand Neumann boundary value problems associated to such an operator are solved\nwhen $p$ is sufficiently close to $2.$", "AI": {"tldr": "The paper extends the Kato problem to degenerate elliptic operators of arbitrary order with measurable complex coefficients satisfying a G\u00e5rding inequality with respect to A\u2082-weights, and applies this to solve L^p boundary value problems near p=2.", "motivation": "To generalize previous work by Cruz-Uribe, Martell and Rios (2018) on the Kato problem to higher-order degenerate elliptic operators with complex coefficients and A\u2082-weights.", "method": "Extends the Kato problem framework to degenerate elliptic operators of order 2m (m\u22651) with measurable complex coefficients satisfying G\u00e5rding inequality with Muckenhoupt A\u2082-weights.", "result": "Successfully solves the unweighted L^p-Dirichlet, regularity and Neumann boundary value problems for such operators when p is sufficiently close to 2.", "conclusion": "The extension of the Kato problem to higher-order degenerate elliptic operators with complex coefficients and A\u2082-weights enables solving boundary value problems in L^p spaces near p=2."}}
{"id": "2511.04489", "pdf": "https://arxiv.org/pdf/2511.04489", "abs": "https://arxiv.org/abs/2511.04489", "authors": ["Oskar Lappi", "Huw Leggate", "Yannick Marandet", "Jan \u00c5str\u00f6m", "Keijo Heljanko", "Dmitriy V. Borodin"], "title": "Scalable Domain-decomposed Monte Carlo Neutral Transport for Nuclear Fusion", "categories": ["physics.comp-ph", "cs.DC", "cs.PF", "68W10 (Primary), 68W15, 65C05 (Secondary)", "D.1.3; G.3; I.6.8; J.2"], "comment": "19 pages, 3 figures, submitted to Journal of Computational Physics", "summary": "EIRENE [1] is a Monte Carlo neutral transport solver heavily used in the\nfusion community. EIRENE does not implement domain decomposition, making it\nimpossible to use for simulations where the grid data does not fit on one\ncompute node (see e.g. [2]). This paper presents a domain-decomposed Monte\nCarlo (DDMC) algorithm implemented in a new open source Monte Carlo code,\nEiron. Two parallel algorithms currently used in EIRENE are also implemented in\nEiron, and the three algorithms are compared by running strong scaling tests,\nwith DDMC performing better than the other two algorithms in nearly all cases.\nOn the supercomputer Mahti [3], DDMC strong scaling is superlinear for grids\nthat do not fit into an L3 cache slice (4 MiB). The DDMC algorithm is also\nscaled up to 16384 cores in weak scaling tests, with a weak scaling efficiency\nof 45% in a high-collisional (heavier compute load) case, and 26% in a\nlow-collisional (lighter compute load) case. We conclude that implementing this\ndomain decomposition algorithm in EIRENE would improve performance and enable\nsimulations that are currently impossible due to memory constraints.", "AI": {"tldr": "Eiron implements domain-decomposed Monte Carlo (DDMC) algorithm that outperforms existing parallel algorithms in EIRENE, enabling simulations on grids too large for single nodes.", "motivation": "EIRENE lacks domain decomposition, preventing simulations where grid data doesn't fit on one compute node due to memory constraints.", "method": "Implemented DDMC algorithm in new open-source code Eiron, compared with two existing EIRENE parallel algorithms through strong scaling tests.", "result": "DDMC performed better in nearly all cases, achieving superlinear strong scaling on Mahti supercomputer for large grids, and scaled to 16384 cores with 45% weak scaling efficiency in high-collisional cases.", "conclusion": "Implementing DDMC in EIRENE would improve performance and enable currently impossible simulations due to memory limitations."}}
{"id": "2511.04424", "pdf": "https://arxiv.org/pdf/2511.04424", "abs": "https://arxiv.org/abs/2511.04424", "authors": ["Riley Fisher", "Fruzsina Agocs", "Adrianna Gillman"], "title": "An efficient boundary integral equation solution technique for solving aperiodic scattering problems from two-dimensional, periodic boundaries", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "This manuscript presents an efficient boundary integral equation technique\nfor solving two-dimensional Helmholtz problems defined in the half-plane\nbounded by an infinite, periodic curve with Neumann boundary conditions and an\naperiodic point source. The technique is designed for boundaries where one\nperiod does not require a large number of discretization points to achieve high\naccuracy. The Floquet--Bloch transform turns the problem into evaluating a\ncontour integral where the integrand is the solution of quasiperiodic boundary\nvalue problems. To approximate the integral, one must solve a collection of\nthese problems. This manuscript uses a variant of the periodizing scheme by Cho\nand Barnett which alleviates the need for evaluating the quasiperiodic Green's\nfunction and is amenable to a large amount of precomputation that can be reused\nfor all of the necessary solves. The solution technique is accelerated by the\nuse of low rank linear algebra. The numerical results illustrate that the\npresented method is 20-30 faster than the technique utilizing the quasiperiodic\nGreen's function for a stair-like geometry.", "AI": {"tldr": "Efficient boundary integral method for 2D Helmholtz problems in half-plane with periodic boundary and aperiodic source, using Floquet-Bloch transform and periodizing scheme to avoid quasiperiodic Green's function evaluation.", "motivation": "To solve Helmholtz problems with periodic boundaries more efficiently, avoiding the computational burden of evaluating quasiperiodic Green's functions.", "method": "Uses Floquet-Bloch transform to convert problem into contour integral, employs periodizing scheme by Cho and Barnett variant, accelerated with low rank linear algebra and reusable precomputation.", "result": "Method achieves 20-30 times faster computation compared to techniques using quasiperiodic Green's function for stair-like geometry.", "conclusion": "The presented boundary integral technique is highly efficient for solving 2D Helmholtz problems with periodic boundaries and aperiodic sources."}}
{"id": "2511.04441", "pdf": "https://arxiv.org/pdf/2511.04441", "abs": "https://arxiv.org/abs/2511.04441", "authors": ["Xiaobing Xiao", "Xipeng Chen", "Lei Jia", "Huaifei Chen", "Lu Qu", "Chakhung Yeung"], "title": "Lightning-Induced Faults in Low-Voltage Distribution Networks via Hybrid VTS-PEEC Method", "categories": ["physics.plasm-ph"], "comment": null, "summary": "As a critical component of power supply systems, low-voltage distribution\nnet-works directly affect grid stability and user power supply reliability, yet\nthey face significant threats from lightning-induced faults. Transient\nsimulations are more economical and adaptable for investigating\nlightning-induced faults in low-voltage distribution networks than experiments.\nA hybrid Variable Time Step (VTS)-Partial Element Equivalent Circuit (PEEC)\nmethod, has been validat-ed in previous study, is used for Lightning-induced\nElectromagnetic Pulse (LEMP) simulation and fault analysis. The\nlightning-induced faults in ex-tended unequal-length double-circuit low-voltage\ndistribution networks are ana-lyzed in this paper. The impact of lightning\nstroke location on overvoltage and fault risk is the primary focus of this\nstudy. Key findings indicate that, for ground strokes in front of the center of\none double circuit, similar three-phase negative and bipolar oscillatory\nwaveforms that are linked to fault initiation emerge. Closer strokes promote\nbipolar waveforms with the main peak negative as well as higher overvoltages\nand fault risk. These results provide essential insights for under-standing\nlightning-induced fault mechanisms, thereby laying a foundation for formulating\nmore targeted and effective lightning protection measures.", "AI": {"tldr": "Analysis of lightning-induced faults in low-voltage distribution networks using a hybrid VTS-PEEC method, focusing on how lightning stroke location affects overvoltage and fault risk.", "motivation": "Low-voltage distribution networks are critical for grid stability but face significant threats from lightning-induced faults, which transient simulations can study more economically than experiments.", "method": "Uses a hybrid Variable Time Step (VTS)-Partial Element Equivalent Circuit (PEEC) method validated in previous studies for Lightning-induced Electromagnetic Pulse (LEMP) simulation and fault analysis in extended unequal-length double-circuit low-voltage distribution networks.", "result": "Ground strokes in front of circuit centers produce similar three-phase negative and bipolar oscillatory waveforms linked to fault initiation. Closer strokes generate bipolar waveforms with negative main peaks, higher overvoltages, and increased fault risk.", "conclusion": "The findings provide essential insights into lightning-induced fault mechanisms, forming a foundation for developing more targeted and effective lightning protection measures."}}
{"id": "2511.04056", "pdf": "https://arxiv.org/pdf/2511.04056", "abs": "https://arxiv.org/abs/2511.04056", "authors": ["Andreas Tataris", "Alexander V. Mamonov"], "title": "A variational Lippmann-Schwinger-type approach for the Helmholtz impedance problem on bounded domains", "categories": ["math.AP", "cs.NA", "math.NA", "46N20, 35J05, 49J20"], "comment": null, "summary": "Recently, reduced order modeling methods have been applied to solving inverse\nboundary value problems arising in frequency domain scattering theory. A key\nstep in projection-based reduced order model methods is the use of a\nsesquilinear form associated with the forward boundary value problem. However,\nin contrast to scattering problems posed in $\\mathbb{R}^d$, boundary value\nformulations lose certain structural properties, most notably the classical\nLippmann-Schwinger integral equation is no longer available. In this paper we\nderive a Lippmann-Schwinger type equation aimed at studying the solution of a\nHelmholtz boundary value problem with a variable refractive index and impedance\nboundary conditions. In particular, we start from the variational formulation\nof the boundary value problem and we obtain an equivalent operator equation\nwhich can be viewed as a bounded domain analogue of the classical\nLippmann-Schwinger equation. We first establish analytical properties of our\nvariational Lippmann-Schwinger type operator. Based on these results, we then\nshow that the parameter-to-state map, which maps a refractive index to the\ncorresponding wavefield, maps weakly convergent sequences to strongly\nconvergent ones when restricted to refractive indices in Lebesgue spaces with\nexponent greater than 2. Finally, we use the derived weak to strong sequential\ncontinuity to show existence of minimizers for a reduced order model based\noptimization methods aimed at solving the inverse boundary value problem as\nwell as for a conventional data misfit based waveform inversion method.", "AI": {"tldr": "This paper develops a Lippmann-Schwinger type equation for Helmholtz boundary value problems with variable refractive index and impedance boundary conditions, establishing analytical properties and proving weak-to-strong continuity for solving inverse boundary value problems.", "motivation": "To address the loss of structural properties in boundary value formulations compared to scattering problems in unbounded domains, particularly the unavailability of the classical Lippmann-Schwinger integral equation.", "method": "Derived a variational Lippmann-Schwinger type equation from the boundary value problem's variational formulation, established analytical properties of the operator, and proved weak-to-strong sequential continuity of the parameter-to-state map.", "result": "Showed that the parameter-to-state map maps weakly convergent sequences to strongly convergent ones for refractive indices in Lebesgue spaces with exponent greater than 2, enabling existence proofs for minimizers in optimization methods.", "conclusion": "The developed Lippmann-Schwinger type framework provides a foundation for proving existence of minimizers in reduced order model based optimization and conventional waveform inversion methods for solving inverse boundary value problems."}}
{"id": "2511.04564", "pdf": "https://arxiv.org/pdf/2511.04564", "abs": "https://arxiv.org/abs/2511.04564", "authors": ["Yoh-ichi Mototake", "Makoto Sasaki"], "title": "Uncertainties in Physics-informed Inverse Problems: The Hidden Risk in Scientific AI", "categories": ["physics.comp-ph", "cs.LG"], "comment": "17 pages, 6 figures", "summary": "Physics-informed machine learning (PIML) integrates partial differential\nequations (PDEs) into machine learning models to solve inverse problems, such\nas estimating coefficient functions (e.g., the Hamiltonian function) that\ncharacterize physical systems. This framework enables data-driven understanding\nand prediction of complex physical phenomena. While coefficient functions in\nPIML are typically estimated on the basis of predictive performance, physics as\na discipline does not rely solely on prediction accuracy to evaluate models.\nFor example, Kepler's heliocentric model was favored owing to small\ndiscrepancies in planetary motion, despite its similar predictive accuracy to\nthe geocentric model. This highlights the inherent uncertainties in data-driven\nmodel inference and the scientific importance of selecting physically\nmeaningful solutions. In this paper, we propose a framework to quantify and\nanalyze such uncertainties in the estimation of coefficient functions in PIML.\nWe apply our framework to reduced model of magnetohydrodynamics and our\nframework shows that there are uncertainties, and unique identification is\npossible with geometric constraints. Finally, we confirm that we can estimate\nthe reduced model uniquely by incorporating these constraints.", "AI": {"tldr": "A framework for quantifying uncertainties in physics-informed machine learning (PIML) when estimating coefficient functions from data, addressing the challenge of selecting physically meaningful solutions beyond just predictive accuracy.", "motivation": "Physics relies on more than just prediction accuracy to evaluate models (e.g., Kepler's heliocentric model was preferred despite similar accuracy to geocentric model). PIML faces inherent uncertainties in data-driven model inference, highlighting the need to quantify uncertainties and select physically meaningful solutions.", "method": "Proposed a framework to quantify and analyze uncertainties in the estimation of coefficient functions in PIML. Applied the framework to a reduced model of magnetohydrodynamics and incorporated geometric constraints for unique identification.", "result": "The framework revealed uncertainties in coefficient function estimation, and showed that unique identification is possible when incorporating geometric constraints.", "conclusion": "The proposed framework successfully quantifies uncertainties in PIML and enables unique estimation of reduced models by incorporating appropriate physical constraints."}}
{"id": "2511.04490", "pdf": "https://arxiv.org/pdf/2511.04490", "abs": "https://arxiv.org/abs/2511.04490", "authors": ["Yameng Zhu", "Weibing Deng", "Ran Bi"], "title": "A Two-stage Adaptive Lifting PINN Framework for Solving Viscous Approximations to Hyperbolic Conservation Laws", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "Training physics informed neural networks PINNs for hyperbolic conservation\nlaws near the inviscid limit presents considerable difficulties because strong\nform residuals become ill posed at shock discontinuities, while small viscosity\nregularization introduces narrow boundary layers that exacerbate spectral bias.\nTo address these issues this paper proposes a novel two stage adaptive lifting\nPINN, a lifting based framework designed to mitigate such challenges without\nrequiring a priori knowledge of the interface geometry. The key idea is to\naugment the physical coordinates by introducing a learned auxiliary field\ngenerated through r adaptive coordinate transformations. Theoretically we first\nderive an a posteriori L2 error estimate to quantify how training difficulty\ndepends on viscosity. Secondly we provide a statistical interpretation\nrevealing that embedded sampling induces variance reduction analogous to\nimportance sampling. Finally we perform an NTK and gradient flow analysis,\ndemonstrating that input augmentation improves conditioning and accelerates\nresidual decay. Supported by these insights our numerical experiments show\naccelerated and more stable convergence as well as accurate reconstructions\nnear discontinuities.", "AI": {"tldr": "Proposes a two-stage adaptive lifting PINN framework to handle training difficulties in physics informed neural networks for hyperbolic conservation laws near inviscid limits, using learned auxiliary fields to improve conditioning and convergence.", "motivation": "Training PINNs for hyperbolic conservation laws near inviscid limits is challenging due to ill-posed residuals at shock discontinuities and spectral bias from small viscosity regularization.", "method": "Two-stage adaptive lifting PINN framework that augments physical coordinates with learned auxiliary fields through r-adaptive coordinate transformations, supported by theoretical error analysis and NTK/gradient flow analysis.", "result": "Numerical experiments show accelerated and more stable convergence, with accurate reconstructions near discontinuities, demonstrating variance reduction similar to importance sampling.", "conclusion": "The proposed lifting framework effectively mitigates training difficulties in PINNs for hyperbolic conservation laws without requiring a priori knowledge of interface geometry, improving conditioning and accelerating residual decay."}}
{"id": "2511.04516", "pdf": "https://arxiv.org/pdf/2511.04516", "abs": "https://arxiv.org/abs/2511.04516", "authors": ["D. I. Zhukhovitskii", "E. E. Perevoshchikov"], "title": "Approaching the thermodynamic limit of a bounded one-component plasma", "categories": ["physics.plasm-ph"], "comment": "17 pages, 12 pdf figures, 2 tables", "summary": "The classical one-component plasma (OCP) bounded by a spherical surface\nreflecting ions (BOCP) is studied using molecular dynamics (MD). Simulations\nperformed for a series of sufficiently large BOCP's make it possible to\nestablish the size dependencies for the investigated quantities and extrapolate\nthem to the thermodynamic limit. In particular, the total electrostatic energy\nper ion is estimated in the limit of infinite BOCP in a wide range of the\nCoulomb coupling parameter $\\Gamma$ from 0.03 to 1000 with the relative error\nof the order 0.1%. Calculated energies are by about 0.5% lower as compared to\nthe modern Monte Carlo (MC) simulation data obtained by different authors at\n$\\Gamma<30$ and almost coincide with the MC results at $\\Gamma>175$. We\nintroduce two more converging characteristic energies, the excess interatomic\nelectrostatic energy and the excess ion-background electrostatic energy, which\nenable us to calculate the ionic compressibility factor inaccessible in\nconventional MC and MD simulation of the OCP with periodic boundary conditions.\nThe derived wide-range ionic equation of state can be recommended for testing\nOCP simulations with various effective interaction potentials. Based on this\nequation, we propose an improved cutoff radius for the interionic forces\nimplemented in LAMMPS and perform MD simulation of the OCP to demonstrate that\nlocation of the metastable region of the fluid-solid phase transition depends\nsensitively on this radius.", "AI": {"tldr": "Molecular dynamics study of spherical bounded one-component plasma establishes thermodynamic limit properties and improves simulation accuracy for Coulomb coupling parameters from 0.03 to 1000.", "motivation": "To accurately determine the thermodynamic properties of bounded one-component plasma systems and improve simulation methods by establishing size dependencies and extrapolating to infinite system limits.", "method": "Used molecular dynamics simulations of spherical bounded one-component plasma systems, established size dependencies, extrapolated to thermodynamic limit, and introduced new converging characteristic energies for better analysis.", "result": "Obtained total electrostatic energy per ion with 0.1% relative error across wide \u0393 range (0.03-1000), showing 0.5% lower values than Monte Carlo at \u0393<30 and good agreement at \u0393>175. Derived ionic equation of state and improved cutoff radius for LAMMPS simulations.", "conclusion": "The study provides accurate thermodynamic properties for bounded one-component plasma, enables calculation of previously inaccessible compressibility factors, and demonstrates that fluid-solid phase transition locations depend sensitively on simulation cutoff radii."}}
{"id": "2511.04196", "pdf": "https://arxiv.org/pdf/2511.04196", "abs": "https://arxiv.org/abs/2511.04196", "authors": ["Marianna Chatzakou", "Aidyn Kassymov", "Michael Ruzhansky"], "title": "Fujita exponent for heat equation with H\u00f6rmander vector fields", "categories": ["math.AP"], "comment": "31 pages", "summary": "In this paper, we show global existence and non-existence results for the\nheat equation with some of the squares of smooth vector fields on $\\Rn$\nsatisfying H\\\"{o}rmander's rank condition with a non-linearity of the form\n$f(u)$, where $f$ is a suitable function and $u$ is the solution. In\nparticular, when $f(u)=u^p$, we calculate the critical Fujita exponent. We also\ngive necessary conditions for blow-up or, alternatively, a sufficient condition\nfor the existence of positive global solutions for time-dependent\nnonlinearities of the type $\\varphi(t)f(u)$.", "AI": {"tldr": "Global existence and non-existence results for heat equations with vector fields satisfying H\u00f6rmander's condition, including critical Fujita exponent calculation for power nonlinearities.", "motivation": "To study the behavior of solutions to heat equations with nonlinear terms involving squares of vector fields, particularly determining conditions for global existence versus blow-up.", "method": "Analysis of heat equations with nonlinearities f(u) and \u03c6(t)f(u), using vector fields satisfying H\u00f6rmander's rank condition, with focus on power nonlinearities u^p.", "result": "Established critical Fujita exponent for power nonlinearities and provided necessary conditions for blow-up/sufficient conditions for global positive solutions for time-dependent nonlinearities.", "conclusion": "The paper determines precise conditions under which solutions exist globally or blow up, extending Fujita-type results to heat equations with vector fields satisfying H\u00f6rmander's condition."}}
{"id": "2511.04597", "pdf": "https://arxiv.org/pdf/2511.04597", "abs": "https://arxiv.org/abs/2511.04597", "authors": ["Sourav Karmakar", "Sutirtha Paul", "Adrian Del Maestro", "Barak Hirshberg"], "title": "Combining Harmonic Sampling with the Worm Algorithm to Improve the Efficiency of Path Integral Monte Carlo", "categories": ["physics.comp-ph", "cond-mat.stat-mech"], "comment": null, "summary": "We propose an improved Path Integral Monte Carlo (PIMC) algorithm called\nHarmonic PIMC (H-PIMC) and its generalization, Mixed PIMC (M-PIMC). PIMC is a\npowerful tool for studying quantum condensed phases. However, it often suffers\nfrom a low acceptance ratio for solids and dense confined liquids. We develop\ntwo sampling schemes especially suited for such problems by dividing the\npotential into its harmonic and anharmonic contributions. In H-PIMC, we\ngenerate the imaginary time paths for the harmonic part of the potential\nexactly and accept or reject it based on the anharmonic part. In M-PIMC, we\nrestrict the harmonic sampling to the vicinity of local minimum and use\nstandard PIMC otherwise, to optimize efficiency. We benchmark H-PIMC on systems\nwith increasing anharmonicity, improving the acceptance ratio and lowering the\nauto-correlation time. For weakly to moderately anharmonic systems, at $\\beta\n\\hbar \\omega=16$, H-PIMC improves the acceptance ratio by a factor of 6-16 and\nreduces the autocorrelation time by a factor of 7-30. We also find that the\nmethod requires a smaller number of imaginary time slices for convergence,\nwhich leads to another two- to four-fold acceleration. For strongly anharmonic\nsystems, M-PIMC converges with a similar number of imaginary time slices as\nstandard PIMC, but allows the optimization of the auto-correlation time. We\nextend M-PIMC to periodic systems and apply it to a sinusoidal potential.\nFinally, we combine H- and M-PIMC with the worm algorithm, allowing us to\nobtain similar efficiency gains for systems of indistinguishable particles.", "AI": {"tldr": "Improved PIMC algorithms (H-PIMC and M-PIMC) that separate harmonic and anharmonic potential contributions to enhance sampling efficiency for quantum solids and dense confined liquids.", "motivation": "Standard PIMC suffers from low acceptance ratios and high autocorrelation times when studying quantum condensed phases like solids and dense confined liquids.", "method": "Developed two sampling schemes: H-PIMC generates exact harmonic potential paths and accepts/rejects based on anharmonic part; M-PIMC restricts harmonic sampling near local minima and uses standard PIMC elsewhere.", "result": "For weakly to moderately anharmonic systems at \u03b2\u210f\u03c9=16: 6-16x improvement in acceptance ratio, 7-30x reduction in autocorrelation time, and 2-4x acceleration from fewer imaginary time slices. M-PIMC works well for strongly anharmonic systems.", "conclusion": "The proposed H-PIMC and M-PIMC methods significantly improve sampling efficiency for quantum condensed phases and can be combined with worm algorithm for indistinguishable particles."}}
{"id": "2511.04501", "pdf": "https://arxiv.org/pdf/2511.04501", "abs": "https://arxiv.org/abs/2511.04501", "authors": ["Antonin Boisneault", "Marcella Bonazzoli", "Pierre Marchand", "Xavier Claeys"], "title": "Spurious resonances for substructured FEM-BEM coupling", "categories": ["math.NA", "cs.NA"], "comment": null, "summary": "We are interested in time-harmonic acoustic scattering by an impenetrable\nobstacle in a medium where the wavenumber is constant in an exterior unbounded\nsubdomain and is possibly heterogeneous in a bounded subdomain. The associated\nHelmholtz boundary value problem can be solved by coupling the Finite Element\nMethod (FEM) in the heterogeneous subdomain with the Boundary Element Method\n(BEM) in the homogeneous subdomain. Recently, we designed and analyzed a new\nsubstructured FEM-BEM formulation, called Generalized Optimized Schwarz Method\n(GOSM). Unfortunately, it is well known that, even when the initial boundary\nvalue problem is well-posed, the variational formulation of classical FEM-BEM\ncouplings can be ill-posed for certain wavenumbers, called spurious resonances.\nIn this paper, we focus on the Johnson-N\\'ed\\'elec and Costabel couplings and\nshow that the GOSM derived from both is not immune to that issue. In\nparticular, we give an explicit expression of the kernel of the local operator\nassociated with the interface between the FEM and BEM subdomains. That kernel\nand the one of classical FEM-BEM couplings are simultaneously non-trivial.", "AI": {"tldr": "The paper analyzes spurious resonances in Generalized Optimized Schwarz Method (GOSM) for FEM-BEM coupling in acoustic scattering problems, showing it shares the same ill-posedness issues as classical couplings.", "motivation": "To address the well-known problem of spurious resonances in classical FEM-BEM couplings for acoustic scattering, even when the original boundary value problem is well-posed.", "method": "Analysis of GOSM formulation derived from Johnson-N\u00e9d\u00e9lec and Costabel couplings, with explicit characterization of the kernel of the local interface operator.", "result": "GOSM is not immune to spurious resonances - the kernel of its local interface operator is non-trivial and coincides with that of classical FEM-BEM couplings.", "conclusion": "The new substructured FEM-BEM formulation (GOSM) inherits the same ill-posedness issues as classical couplings for certain wavenumbers, requiring further investigation to overcome spurious resonances."}}
{"id": "2511.04554", "pdf": "https://arxiv.org/pdf/2511.04554", "abs": "https://arxiv.org/abs/2511.04554", "authors": ["Felipe A. Asenjo", "Swadesh M. Mahajan"], "title": "Electromagnetic plasma wave modes propagating along light-cone coordinates", "categories": ["physics.plasm-ph"], "comment": null, "summary": "We present new electromagnetic plasma modes that propagates in one time and\none space coordinates. Differently to the usual plane wave solution, which is\nwritten in terms of separation of variables, all our solutions are along the\nlight-cone coordinates. This allow us to find several new wavepacket solutions\nwhose functionality properties rely on the conditions imposed on the choice for\ntheir light-cone coordinates dependence. The presented wavepacket solutions are\nconstructed in terms of multiplications of Airy functions, Parabolic cylinder\nfunctions, Mathieu functions, or Bessel functions. We thoroughly analyze the\ncase of a double Airy solution, which have new electromagnetic properties, as a\ndefined wavefront, and velocity faster than the electromagnetic plane wave\ncounterpart solution. It is also mentioned how more general structured\nwavepackets can be constructed from these new solutions.", "AI": {"tldr": "The paper presents new electromagnetic plasma modes that propagate in 1+1 dimensions using light-cone coordinates, enabling wavepacket solutions with unique properties like defined wavefronts and faster-than-light velocity.", "motivation": "To develop novel electromagnetic wave solutions that differ from conventional plane waves by using light-cone coordinates, allowing for more complex wavepacket structures with enhanced functional properties.", "method": "Construct wavepacket solutions using light-cone coordinates instead of separation of variables, employing special functions like Airy functions, Parabolic cylinder functions, Mathieu functions, and Bessel functions to create structured electromagnetic modes.", "result": "Successfully derived several new wavepacket solutions, including a double Airy solution with defined wavefront and velocity faster than electromagnetic plane waves, demonstrating novel electromagnetic properties.", "conclusion": "The approach using light-cone coordinates enables construction of structured electromagnetic wavepackets with unique properties, and more general wavepackets can be built from these foundational solutions."}}
{"id": "2511.04340", "pdf": "https://arxiv.org/pdf/2511.04340", "abs": "https://arxiv.org/abs/2511.04340", "authors": ["Jacopo Bellazzini", "Luigi Forcella", "Vladimir Georgiev"], "title": "NLS with mass-subcritical combined nonlinearities: small mass $L^2$-scattering", "categories": ["math.AP"], "comment": "35 pages", "summary": "We prove small data scattering in the mass-subcritical regime for the NLS\nequation with double nonlinearities, where a focusing leading term is perturbed\nby a lower order defocusing nonlinear term. Our proof relies on the\npseudo-conformal transformation in conjunction with a general variational\nargument used to obtain the positivity of certain modified energies. Moreover,\nthe smallness assumption is only on the mass of the initial data, and not on\nthe whole $\\Sigma$-norm.", "AI": {"tldr": "Small data scattering for mass-subcritical NLS with double nonlinearities (focusing leading term + defocusing perturbation) using pseudo-conformal transformation and variational arguments.", "motivation": "To establish scattering results for nonlinear Schr\u00f6dinger equations with competing nonlinearities, where a focusing leading term is balanced by a defocusing lower-order perturbation.", "method": "Uses pseudo-conformal transformation combined with general variational arguments to ensure positivity of modified energies. The approach requires smallness only on the initial mass, not the full \u03a3-norm.", "result": "Proves small data scattering in the mass-subcritical regime for NLS with double nonlinearities.", "conclusion": "The combination of pseudo-conformal transformation and variational methods successfully establishes scattering for this class of equations with reduced smallness assumptions."}}
{"id": "2511.03735", "pdf": "https://arxiv.org/pdf/2511.03735", "abs": "https://arxiv.org/abs/2511.03735", "authors": ["Valentin Mouton", "Adrien M\u00e9lot"], "title": "Friction on Demand: A Generative Framework for the Inverse Design of Metainterfaces", "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SY", "physics.comp-ph"], "comment": "Preprint", "summary": "Designing frictional interfaces to exhibit prescribed macroscopic behavior is\na challenging inverse problem, made difficult by the non-uniqueness of\nsolutions and the computational cost of contact simulations. Traditional\napproaches rely on heuristic search over low-dimensional parameterizations,\nwhich limits their applicability to more complex or nonlinear friction laws. We\nintroduce a generative modeling framework using Variational Autoencoders (VAEs)\nto infer surface topographies from target friction laws. Trained on a synthetic\ndataset composed of 200 million samples constructed from a parameterized\ncontact mechanics model, the proposed method enables efficient, simulation-free\ngeneration of candidate topographies. We examine the potential and limitations\nof generative modeling for this inverse design task, focusing on balancing\naccuracy, throughput, and diversity in the generated solutions. Our results\nhighlight trade-offs and outline practical considerations when balancing these\nobjectives. This approach paves the way for near-real-time control of\nfrictional behavior through tailored surface topographies.", "AI": {"tldr": "A generative modeling framework using VAEs to infer surface topographies from target friction laws, enabling efficient simulation-free generation of frictional interfaces.", "motivation": "Traditional approaches rely on heuristic search over low-dimensional parameterizations, limiting applicability to complex friction laws. The inverse design problem is challenging due to non-uniqueness of solutions and computational cost of contact simulations.", "method": "Use Variational Autoencoders (VAEs) trained on a synthetic dataset of 200 million samples from a parameterized contact mechanics model to generate candidate surface topographies from target friction laws.", "result": "The method enables efficient, simulation-free generation of candidate topographies. The study examines trade-offs between accuracy, throughput, and diversity in generated solutions.", "conclusion": "This approach paves the way for near-real-time control of frictional behavior through tailored surface topographies, highlighting practical considerations for balancing design objectives."}}
