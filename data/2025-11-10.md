<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 10]
- [math.AP](#math.AP) [Total: 20]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 2]
- [math.DG](#math.DG) [Total: 2]
- [physics.chem-ph](#physics.chem-ph) [Total: 2]
- [physics.ins-det](#physics.ins-det) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [math.ST](#math.ST) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Structure-preserving local discontinuous Galerkin discretization of conformational conversion systems](https://arxiv.org/abs/2511.04830)
*Paola F. Antonietti,Mattia Corti,Sergio Gómez,Ilaria Perugia*

Main category: math.NA

TL;DR: A structure-preserving numerical scheme combining local discontinuous Galerkin space discretization with backward Euler time integration for two-state conformational conversion systems, ensuring positivity and boundedness.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical method that preserves physical properties (positivity and boundedness) while solving two-state conformational conversion systems, addressing the need for reliable computational approaches in such biological/physical models.

Method: Reformulate the model using auxiliary variables with nonlinear transformations, then apply local discontinuous Galerkin space discretization coupled with backward Euler time-integration method.

Result: Proved discrete entropy-stability inequality, existence of discrete solutions, convergence of the scheme using discrete compactness arguments, and existence of global weak solutions satisfying physical bounds.

Conclusion: The proposed structure-preserving numerical scheme successfully maintains physical constraints while providing reliable solutions, with numerical validation confirming theoretical results and practical capabilities.

Abstract: We investigate a two-state conformational conversion system and introduce a
novel structure-preserving numerical scheme that couples a local discontinuous
Galerkin space discretization with the backward Euler time-integration method.
The model is first reformulated in terms of auxiliary variables involving
suitable nonlinear transformations, which allow us to enforce positivity and
boundedness at the numerical level. Then, we prove a discrete entropy-stability
inequality, which we use to show the existence of discrete solutions, as well
as to establish the convergence of the scheme by means of some discrete
compactness arguments. As a by-product of the theoretical analysis, we also
prove the existence of global weak solutions satisfying the system's physical
bounds. Numerical results validate the theoretical results and assess the
capabilities of the proposed method in practice.

</details>


### [2] [Uniformly accurate structure-preserving neural surrogates for radiative transfer](https://arxiv.org/abs/2511.04991)
*Mengjia Bai,Jingrun Chen,Keke Wu*

Main category: math.NA

TL;DR: Proposes a uniformly accurate, structure-preserving neural surrogate for radiative transfer equations using multiscale parity decomposition with rigorous error guarantees.


<details>
  <summary>Details</summary>
Motivation: To develop neural network solvers for multiscale kinetic equations that maintain accuracy across all parameter regimes while preserving physical structures.

Method: Multiscale parity decomposition framework with refined particle distribution into macroscopic, odd, and higher-order even components; asymptotic-preserving neural network system with architectural constraints for symmetry, conservation, and positivity.

Result: Established rigorous uniform error estimates with ε-independent accuracy; framework extends from 1D to 2D; numerical experiments confirm effectiveness.

Conclusion: Provides theoretical foundation for uniformly accurate neural solvers of multiscale kinetic equations with structure preservation across all parameter regimes.

Abstract: In this work, we propose a uniformly accurate, structure-preserving neural
surrogate for the radiative transfer equation with periodic boundary conditions
based on a multiscale parity decomposition framework. The formulation
introduces a refined decomposition of the particle distribution into
macroscopic, odd, and higher-order even components, leading to an
asymptotic-preserving neural network system that remains stable and accurate
across all parameter regimes. By constructing key higher-order correction
functions, we establish rigorous uniform error estimates with respect to the
scale parameter $\varepsilon$, which ensures $\varepsilon$-independent
accuracy. Furthermore, the neural architecture is designed to preserve
intrinsic physical structures such as parity symmetry, conservation, and
positivity through dedicated architectural constraints. The framework extends
naturally from one to two dimensions and provides a theoretical foundation for
uniformly accurate neural solvers of multiscale kinetic equations. Numerical
experiments confirm the effectiveness of our approach.

</details>


### [3] [A dual grid geometric electromagnetic particle in cell method](https://arxiv.org/abs/2511.05032)
*Katharina Kormann,Eric Sonnendrücker*

Main category: math.NA

TL;DR: A geometric particle-in-cell method using mimetic finite differences with staggered grids for Maxwell's equations, avoiding mass matrix inversion.


<details>
  <summary>Details</summary>
Motivation: To develop an alternative to finite element discretizations that maintains geometric structure while simplifying computation by eliminating mass matrix inversion.

Method: Uses mimetic finite differences with staggered grids, defining degrees of freedom as point values and integrals on primal/dual grids for field discretization.

Result: The method maintains conservation properties and allows parameter study in discretization while being computationally simpler than finite element approaches.

Conclusion: The mimetic finite difference formulation provides a viable alternative to finite element methods for geometric particle-in-cell discretizations with improved computational efficiency.

Abstract: Geometric particle-in-cell discretizations have been derived based on a
discretization of the fields that is conforming with the de Rham structure of
the Maxwell's equation and a standard particle-in-cell ansatz for the fields by
deriving the equations of motion from a discrete action principle. While
earlier work has focused on finite element discretization of the fields based
on the theory of Finite Element Exterior Calculus, we propose in this article
an alternative formulation of the field equations that is based on the ideas
conveyed by mimetic finite differences. The needed duality being expressed by
the use of staggered grids. We construct a finite difference formulation based
on degrees of freedom defined as point values, edge, face and volume integrals
on a primal and its dual grid. Compared to the finite element formulation no
mass matrix inversion is involved in the formulation of the Maxwell solver. In
numerical experiments, we verify the conservation properties of the novel
method and study the influence of the various parameters in the discretization.

</details>


### [4] [Anti-commuting Solutions of the Yang-Baxter-like Matrix Equation](https://arxiv.org/abs/2511.05088)
*Mohammed Ahmed Adam Abdalrahman,Huijian Zhu,Jiu Ding,Qianglian Huang*

Main category: math.NA

TL;DR: The paper solves the Yang-Baxter-like matrix equation AXA = XAX for general matrix A, finding all anti-commuting solutions using Jordan canonical form and new techniques for homogeneous Sylvester equations.


<details>
  <summary>Details</summary>
Motivation: To find all anti-commuting solutions to the nonlinear Yang-Baxter-like matrix equation AXA = XAX for any given matrix A.

Method: Using Jordan canonical form decomposition of matrix A and applying new techniques for solving general homogeneous Sylvester equations.

Result: The main result provides a complete characterization of all anti-commuting solutions to the nonlinear matrix equation.

Conclusion: The paper successfully solves the Yang-Baxter-like equation by leveraging Jordan canonical forms and new Sylvester equation methods to obtain all anti-commuting solutions.

Abstract: We solve the Yang-Baxter-like matrix equation $AXA = XAX$ for a general given
matrix $A$ to get all anti-commuting solutions, by using the Jordan canonical
form of $A$ and applying some new facts on a general homogeneous Sylvester
equation. Our main result provides all the anti-commuting solutions of the
nonlinear matrix equation.

</details>


### [5] [Numerical simulation of the dual-phase-lag heat conduction equation on a one-dimensional unbounded domain using artificial boundary condition](https://arxiv.org/abs/2511.05121)
*Weiping Bu,Zhengfang Xie,Yushi Wang*

Main category: math.NA

TL;DR: This paper develops a numerical method for solving dual-phase-lag heat conduction equations on unbounded domains using Laplace transform, Padé approximation, and finite difference methods with artificial boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To solve dual-phase-lag heat conduction equations on space unbounded domains, which are challenging due to the unbounded nature requiring efficient computational methods.

Method: Uses Laplace transform and Padé approximation to create high-order local artificial boundary conditions, transforming the problem to a bounded domain. Then applies finite difference method with auxiliary variables to reduce time derivative order.

Result: The numerical scheme is proven unconditionally stable with second-order convergence in both space and time. Numerical experiments validate the method's effectiveness and theoretical analysis.

Conclusion: The proposed method successfully solves dual-phase-lag heat conduction on unbounded domains with proven stability and convergence properties, verified through numerical experiments.

Abstract: This paper focuses on the numerical solution of a dual-phase-lag heat
conduction equation on a space unbounded domain. First, based on the Laplace
transform and the Pad\'e approximation, a high-order local artificial boundary
condition is constructed for the considered problem, which effectively
transforms the original problem into an initial-boundary value problem on a
bounded computational domain. Subsequently, for the resulting reduced problem
on the bounded domain equipped with high-order local artificial boundary, a
stability result based on the $L^2$-norm is derived. Next, we develop finite
difference method for the reduced problem by introducing auxiliary variable to
reduce the order of time derivative. The numerical analysis demonstrates that
the developed numerical scheme is unconditionally stable and possesses a
second-order convergence rate in both space and time. Finally, numerical
results are presented to validate the effectiveness of the proposed numerical
method and the correctness of the theoretical analysis.

</details>


### [6] [Implicit reconstruction from point cloud: an adaptive level-set-based semi-Lagrangian method](https://arxiv.org/abs/2511.05145)
*Silvia Preda,Matteo Semplice*

Main category: math.NA

TL;DR: Level-set-based semi-Lagrangian method on adaptive Cartesian grids for high-quality surface reconstruction from point clouds, using variational formulation with curvature constraints.


<details>
  <summary>Details</summary>
Motivation: To create implicit, high-quality surface representations from point clouds that can serve as computational domains for partial differential equation models.

Method: Variational formulation with curvature constraint, reformulated as advection-diffusion equation solved using semi-Lagrangian scheme with local high-order interpolation, implemented on quadtree/octree adaptive grids with finest resolution near the surface interface.

Result: The method successfully reconstructs surfaces from point clouds in 2D and 3D, handling complex and evolving topologies through localization and reinitialization techniques.

Conclusion: The proposed level-set-based semi-Lagrangian approach on adaptive grids provides an effective framework for high-quality surface reconstruction from point clouds, suitable for subsequent use in computational modeling.

Abstract: We propose a level-set-based semi-Lagrangian method on graded adaptive
Cartesian grids to address the problem of surface reconstruction from point
clouds. The goal is to obtain an implicit, high-quality representation of real
shapes that can subsequently serve as computational domain for partial
differential equation models. The mathematical formulation is variational,
incorporating a curvature constraint that minimizes the surface area while
being weighted by the distance of the reconstructed surface from the input
point cloud. Within the level set framework, this problem is reformulated as an
advection-diffusion equation, which we solve using a semi-Lagrangian scheme
coupled with a local high-order interpolator. Building on the features of the
level set and semi-Lagrangian method, we use quadtree and octree data
structures to represent the grid and generate a mesh with the finest resolution
near the zero level set, i.e., the reconstructed surface interface. The
complete surface reconstruction workflow is described, including localization
and reinitialization techniques, as well as strategies to handle complex and
evolving topologies. A broad set of numerical tests in two and three dimensions
is presented to assess the effectiveness of the method.

</details>


### [7] [The law of iterated logarithm for numerical approximation of time-homogeneous Markov process](https://arxiv.org/abs/2511.05217)
*Chuchu Chen,Xinyu Chen,Jialin Hong*

Main category: math.NA

TL;DR: This paper establishes that numerical approximations of time-homogeneous Markov processes can preserve the law of the iterated logarithm (LIL) under verifiable assumptions, using a decreasing time-step strategy and martingale-based analysis.


<details>
  <summary>Details</summary>
Motivation: To determine whether numerical approximations can preserve the asymptotic pathwise behavior characterized by the law of the iterated logarithm for Markov processes with unique invariant measures.

Method: Discretize the Markov process using a decreasing time-step strategy, extract a quasi-uniform time-grid subsequence from non-uniform grids, and establish LIL for a predominant martingale while controlling remainder terms.

Result: The paper proves that numerical approximations can indeed preserve the LIL for time-homogeneous Markov processes under appropriate assumptions.

Conclusion: The results are applicable to numerical approximations of various stochastic systems including SODEs and SPDEs, providing a positive answer to the open problem of preserving LIL in numerical methods.

Abstract: The law of the iterated logarithm (LIL) for the time-homogeneous Markov
process with a unique invariant measure characterizes the almost sure maximum
possible fluctuation of time averages around the ergodic limit. Whether a
numerical approximation can preserve this asymptotic pathwise behavior remains
an open problem. In this work, we give a positive answer to this question and
establish the LIL for the numerical approximation of such a process under
verifiable assumptions. The Markov process is discretized by a decreasing
time-step strategy, which yields the non-homogeneous numerical approximation
but facilitates a martingale-based analysis. The key ingredient in proving the
LIL for such numerical approximation lies in extracting a quasi-uniform
time-grid subsequence from the original non-uniform time grids and establishing
the LIL for a predominant martingale along it, while the remainder terms
converge to zero. Finally, we illustrate that our results can be flexibly
applied to numerical approximations of a broad class of stochastic systems,
including SODEs and SPDEs.

</details>


### [8] [An Isogeometric Tearing and Interconnecting method for conforming discretizations of the biharmonic problem](https://arxiv.org/abs/2511.05247)
*Stefan Takacs*

Main category: math.NA

TL;DR: A domain decomposition solver for the biharmonic problem using multi-patch Isogeometric Analysis with IETI-DP method.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient solver for the biharmonic problem using domain decomposition techniques in the context of Isogeometric Analysis.

Method: Multi-patch Isogeometric Analysis discretization with smooth discretization spaces, using the Dual-Primal Isogeometric Tearing and Interconnecting (IETI-DP) method for domain decomposition.

Result: Presented a condition number estimate and numerical results demonstrating the method's behavior.

Conclusion: The proposed IETI-DP method provides an effective domain decomposition solver for biharmonic problems with good numerical performance.

Abstract: We propose and analyze a domain decomposition solver for the biharmonic
problem. The problem is discretized in a conforming way using multi-patch
Isogeometric Analysis. As first step, we discuss the setup of a sufficiently
smooth discretization space. We focus on two dimensional computational domains
that are parameterized with sufficiently smooth geometry functions. As solution
technique, we use a variant of the Dual-Primal Finite Element Tearing and
Interconnecting method that is also known as Dual-Primal Isogeometric Tearing
and Interconnecting (IETI-DP) method in the context of Isogeometric Analysis.
We present a condition number estimate and illustrate the behavior of the
proposed method with numerical results.

</details>


### [9] [Asymptotic error distribution of numerical methods for parabolic SPDEs with multiplicative noise](https://arxiv.org/abs/2511.05251)
*Jialin Hong,Diancong Jin,Xu Wang*

Main category: math.NA

TL;DR: Analysis of asymptotic error distribution for numerical methods solving SPDEs with multiplicative noise, focusing on exponential Euler method and spatial discretizations.


<details>
  <summary>Details</summary>
Motivation: To understand the asymptotic behavior of numerical errors in SPDEs with multiplicative noise, which differs significantly from SDEs and SPDEs with additive noise.

Method: Study limit distribution of normalized error process for exponential Euler method in Sobolev spaces, analyze full discretization combining temporal exponential Euler and spatial finite element methods, and examine spatial semi-discrete spectral Galerkin method.

Result: Asymptotic error distribution of exponential Euler method is governed by linear SPDE driven by infinitely many independent Q-Wiener processes. Pointwise limit distribution derived for stochastic heat equations. Spatial convergence speed shown to be highly problem-dependent.

Conclusion: Numerical methods for SPDEs with multiplicative noise exhibit unique asymptotic error behavior distinct from other stochastic equations, with spatial convergence characteristics being problem-specific rather than universal.

Abstract: This paper aims to investigate the asymptotic error distribution of several
numerical methods for stochastic partial differential equations (SPDEs) with
multiplicative noise. Firstly, we give the limit distribution of the normalized
error process of the exponential Euler method in $\dot{H}^\eta$ for some
$\eta>0$. A key finding is that the asymptotic error in distribution of the
exponential Euler method is governed by a linear SPDE driven by infinitely many
independent $Q$-Wiener processes. This characteristic represents a significant
difference from numerical methods for both stochastic ordinary differential
equations and SPDEs with additive noise. Secondly, as applications of the above
result, we derive the asymptotic error distribution of a full discretization
based on the temporal exponential Euler method and the spatial finite element
method. As a concrete illustration, we provide the pointwise limit distribution
of the normalized error process when the exponential Euler method is applied to
a specific class of stochastic heat equations. Finally, by studying the
asymptotic error of the spatial semi-discrete spectral Galerkin method, we
demonstrate that the actual strong convergence speed of spatial semi-discrete
numerical methods may be highly problem-dependent, rather than universally
predictable.

</details>


### [10] [Momentum accelerated power iterations and the restarted Lanczos method](https://arxiv.org/abs/2511.05364)
*Alessandro Barletta,Nicholas Marshall,Sara Pollock*

Main category: math.NA

TL;DR: Comparison of restarted Lanczos method and momentum accelerated power iterations for finding extremal eigenvalues/vectors, with theoretical convergence analysis and a new preconditioning technique combining both methods.


<details>
  <summary>Details</summary>
Motivation: To understand the relative efficiency regimes of two popular eigenvalue methods and develop improved techniques by combining their strengths.

Method: Theoretical convergence analysis based on Chebyshev polynomial ratios, comparison of both methods' efficiency regimes, and introduction of a preconditioning technique using momentum accelerated power iterations with restarted Lanczos.

Result: Identified specific regimes where each method is more efficient, and demonstrated effectiveness of the proposed preconditioning technique through numerical tests on benchmark problems.

Conclusion: The paper provides theoretical understanding of convergence properties for both methods, establishes their relative efficiency domains, and shows that combining them through preconditioning yields improved performance.

Abstract: In this paper we compare two methods for finding extremal eigenvalues and
eigenvectors: the restarted Lanczos method and momentum accelerated power
iterations. The convergence of both methods is based on ratios of Chebyshev
polynomials evaluated at subdominant and dominant eigenvalues; however, the
convergence is not the same. Here we compare the theoretical convergence
properties of both methods, and determine the relative regimes where each is
more efficient. We further introduce a preconditioning technique for the
restarted Lanczos method using momentum accelerated power iterations, and
demonstrate its effectiveness. The theoretical results are backed up by
numerical tests on benchmark problems.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [11] [Attractors and their dimensions for the 3D Fractional Navier--Stokes--Voigt Equations](https://arxiv.org/abs/2511.04783)
*Alexei Ilyin,Varga Kalantarov,Sergey Zelik*

Main category: math.AP

TL;DR: Analysis of fractal dimension bounds for attractors in fractional Navier-Stokes-Voigt equations using spectral inequalities.


<details>
  <summary>Details</summary>
Motivation: Extend and regularize classical Navier-Stokes equations with fractional order Stokes operators applied to time derivatives.

Method: Use advanced spectral inequalities (Lieb-Thirring and Cwikel-Lieb-Rosenblum) to analyze upper bounds of fractal dimensions.

Result: Comprehensive analysis of attractor dimension bounds in terms of physical parameters, improving previous estimates for both fractional and non-fractional cases.

Conclusion: The study extends classical Navier-Stokes-Voigt results to fractional setting and provides essential improvements to existing dimension estimates.

Abstract: We study the dimensions of the attractors for the fractional
Navier--Stokes--Voigt equations. These equations, which include a fractional
order of the Stokes operator applied to the time derivative, serve as natural
extensions and regularizations of the classical Navier--Stokes equations. We
give a comprehensive analysis of the upper bounds for the fractal dimensions of
the attractor in terms of the relevant physical parameters based on the
advanced spectral inequalities such as Lieb--Thirring and
Cwikel--Lieb--Rosenblum inequalities. These results extend previous works on
the classical Navier--Stokes--Voigt system to the fractional setting and give
an essential improvement of the estimates known before for the non-fractional
case as well.

</details>


### [12] [The strongly nonlocal Allen-Cahn problem](https://arxiv.org/abs/2511.04818)
*Erisa Hasani,Stefania Patrizi*

Main category: math.AP

TL;DR: The paper establishes the sharp interface limit of the fractional Allen-Cahn equation in the strongly nonlocal regime (s∈(0,1/2)), proving convergence to fractional mean curvature flow.


<details>
  <summary>Details</summary>
Motivation: To complete the rigorous analysis of fractional Allen-Cahn equations by addressing the previously unstudied singular regime s∈(0,1/2) of strongly nonlocal diffusion, complementing existing results for s≥1/2.

Method: Analysis of the fractional Allen-Cahn equation with fractional Laplacian operator and double-well potential, focusing on the singular regime s∈(0,1/2) using suitably prepared initial data and studying the limit as ε→0.

Result: Proved that solutions converge to the minima of the double-well potential with the interface evolving by fractional mean curvature flow, establishing the first rigorous convergence result in this regime.

Conclusion: This work completes the analysis of fractional Allen-Cahn equations across all parameter regimes, providing the missing rigorous foundation for the strongly nonlocal diffusion case s∈(0,1/2).

Abstract: We study the sharp interface limit of the fractional Allen-Cahn equation $$
\varepsilon \partial_t u^{\varepsilon} = \mathcal{I}^s_n [u^{\varepsilon}]
-\frac{1}{\varepsilon ^{2s}} W'(u^\varepsilon) \quad
\hbox{in}~(0,\infty)\times\mathbb{R}^n, ~n \geq 2, $$ where $\varepsilon >0$,
$\mathcal{I}^s_n=-c_{n,s}(-\Delta )^s$ is the fractional Laplacian of order
$2s\in(0,1)$ in $\mathbb{R}^n$, and $W$ is a smooth double-well potential with
minima at 0 and 1. We focus on the singular regime $s\in(0,\frac{1}{2})$,
corresponding to strongly nonlocal diffusion. For suitably prepared initial
data, we prove that the solution
  $ u^\varepsilon $ converges, as $\varepsilon\to0$, to the minima of $W$ with
the interface evolving by fractional mean curvature flow.
  This establishes the first rigorous convergence result in this regime,
complementing and completing previous work for $s\geq \frac{1}{2}$.

</details>


### [13] [Fractional Schrödinger-Poisson-Slater equations in Coulomb-Sobolev spaces](https://arxiv.org/abs/2511.04829)
*Elisandra Gloss,Carlo Mercuri,Kanishka Perera,Bruno Ribeiro*

Main category: math.AP

TL;DR: Existence and multiplicity results for fractional Schroedinger-Poisson-Slater equations using critical point theory and cohomological index methods.


<details>
  <summary>Details</summary>
Motivation: To study solutions for fractional Schroedinger-Poisson-Slater equations in R^N, addressing compactness issues and solution multiplicity in the fractional setting.

Method: Use fractional Coulomb-Sobolev spaces, critical point theory linking f's behavior at zero/infinity to scaling properties, and Fadell-Rabinowitz cohomological index for eigenvalue sequences.

Result: Established compactness for action functional, obtained multiple solutions governed by interaction with eigenvalue sequence, proved new regularity results and necessary existence conditions.

Conclusion: Successfully developed framework for fractional equations using cohomological index methods, providing existence/multiplicity results and new regularity theory.

Abstract: We prove existence and multiplicity results for the fractional
Schroedinger--Poisson--Slater equation $(-\Delta)^s u + (I_\alpha * u^2)u =
f(|x|,u)$ in $\mathbb{R}^N$, where $0<s<1$ and $\alpha \in (1,N)$. We seek
solutions in a fractional Coulomb-Sobolev space and employ new tools in
critical point theory that link the behavior of $f$ at zero and at infinity to
the scaling properties of the left-hand side. For several regimes of $f$, we
establish compactness for an associated action functional and obtain multiple
solutions as critical points, with the number governed by the interaction of
$f$ with a sequence of eigenvalues $\{\lambda_k\}$ defined via the
$\mathbb{Z}_2$ cohomological index of Fadell and Rabinowitz (rather than the
classical Krasnosel'skii genus). In this fractional setting we also prove new
regularity results and necessary conditions for the existence of solutions.

</details>


### [14] [Dynamics of the Energy-Critical Nonlinear Schrödinger System in ${\mathbb R}^{4}$](https://arxiv.org/abs/2511.04839)
*Alex H. Ardila*

Main category: math.AP

TL;DR: Analysis of radial solutions at threshold energy for a 3-component Schrödinger system with cubic nonlinearity in 4D, focusing on the case where the kernel of the imaginary part of the linearized operator has dimension 2.


<details>
  <summary>Details</summary>
Motivation: To study the dynamics of radial solutions at threshold energy for a specific 3-component Schrödinger system where the kernel of the imaginary part of the linearized operator has dimension 2, which differs from previously studied cases in the literature.

Method: Detailed study of coercivity properties of operators, introduction of a new modulation parameter associated with the additional eigenfunction in the kernel of L_I, modulation analysis, and establishing uniqueness of exponentially decaying solutions to the linearized equation.

Result: The paper develops techniques to handle the case where the kernel of L_I has dimension 2, enabling modulation analysis and proving uniqueness of exponentially decaying solutions.

Conclusion: The approach successfully addresses the challenge posed by the 2-dimensional kernel of the imaginary part of the linearized operator in this 3-component Schrödinger system.

Abstract: In this paper, we investigate the dynamics of radial solutions at threshold
energy for a 3-component Schr\"{o}dinger system with cubic nonlinearity in four
dimensions. The main difference from the cases previously addressed in the
literature is that, in our system, the kernel of the imaginary part $L_I$ of
the linearized operator $-i{\mathcal L}=L_{R}+iL_{I}$ has dimension 2. To
overcome this difficulty, we carry out a detailed study of the coercivity
properties of these operators. We also introduce a new modulation parameter
associated with the additional eigenfunction in the kernel of the operator
$L_{I}$, which enables us to perform the modulation analysis and establish the
uniqueness of exponentially decaying solutions to the linearized equation.

</details>


### [15] [Waterborne epidemics via a new coupled SIR--Pathogen--Navier-Stokes system: Mathematical modeling, nonlinear analysis and numerical simulation](https://arxiv.org/abs/2511.04841)
*Mohamed Mehdaoui,Yassine Ouzrour*

Main category: math.AP

TL;DR: A new mathematical model coupling SIR epidemiology with Navier-Stokes fluid dynamics to study water-borne disease spread, accounting for pathogen transport by water currents and viscosity dependence on pathogen concentration.


<details>
  <summary>Details</summary>
Motivation: Water-borne diseases remain a major public health concern, requiring models that account for pathogen transport through water currents beyond direct host contact.

Method: Couples SIR epidemiological model with Navier-Stokes equations, uses Faedo-Galerkin method and compactness arguments for existence proofs, and develops numerical scheme with semi-implicit time stepping and finite element spatial discretization.

Result: Proved existence of global biologically feasible solutions to the coupled SIR-Pathogen-Navier-Stokes system, investigated uniqueness in 2D case, and demonstrated through simulations how infection dispersal, contamination, and hydrodynamic feedback govern epidemic dynamics.

Conclusion: The coupled SIRPNS framework successfully models water-borne disease spread by integrating epidemiological dynamics with fluid transport, providing insights into spatial dynamics, persistence, and decline of epidemics through hydrodynamic feedback mechanisms.

Abstract: Water-borne diseases are still a major public health concern, as there are
circumstances under which water could act as a carrier of the pathogen,
extending their modeling beyond direct contact between hosts. In the present
work, we introduce a new mathematical framework, coupling epidemiological
dynamics with fluid motion, in order to understand the spatial spread of such
an infection. Our model couples the classical Susceptible-Infected-Recovered
(SIR) model with the Navier-Stokes equations describing the motion of fluids,
which enhances the existing literature by simultaneously taking into account
two aspects: the pathogen being transported by the water currents and the
dependence of the effective viscosity of the fluid on the pathogen
concentration. We apply the Faedo-Galerkin method and compactness arguments to
prove the existence of a global, biologically feasible solution to the coupled
SIR--Pathogen--Navier-Stokes (SIRPNS) system. Additionally, we investigate the
uniqueness of such solutions in the two-dimensional case. Finally, by
constructing a numerical scheme based on the semi-implicit scheme in time and
the finite element method in space, we run several numerical simulations to
show how infection dispersal, environmental contamination, and hydrodynamic
feedback together govern the spatial dynamics, persistence, and eventual
decline of waterborne epidemics.

</details>


### [16] [Representation formula, regularity, and decay of solutions for sub-diffusion equations](https://arxiv.org/abs/2511.04885)
*Sandro Coriasco,Giovanni Girardi,Stevan Pilipović*

Main category: math.AP

TL;DR: This paper analyzes regularity and decay properties of solutions to time-fractional PDEs with tempered initial data in weighted Sobolev spaces, obtaining a representation formula and controlling solution singularities via wavefront sets.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of solutions to time-fractional partial differential equations with tempered initial data, particularly their regularity and decay properties in the context of differential operators with polynomially bounded coefficients.

Method: The authors study the Cauchy problem for time-fractional PDEs with tempered initial data in weighted Sobolev spaces. They derive a representation formula for solutions modulo time-regular functions that are smooth and rapidly decreasing in space variables.

Result: A representation formula is obtained that allows controlling the singularities (decay and smoothness) of homogeneous Cauchy problem solutions in terms of global wavefront sets of the initial data.

Conclusion: The representation formula provides a powerful tool for analyzing solution behavior in time-fractional PDEs, enabling control over singularities through wavefront set analysis of initial conditions.

Abstract: We study regularity and decay properties for the solutions of the Cauchy
problem for time-fractional partial differential equations, with tempered
initial data, belonging to suitable (weighted) Sobolev spaces, associated with
a differential operator on space variables with polynomially bounded
coefficients. We obtain a representation formula for the solution, modulo
time-regular functions, smooth and rapidly decreasing with respect to the space
variables. By means of the representation formula, the (decay and smoothness)
singularities of the solution of the homogeneous Cauchy problem can be
controlled, in terms of (global) wavefront sets of the initial data.

</details>


### [17] [Positive solutions of elliptic systems with superlinear nonlinearities on the boundary](https://arxiv.org/abs/2511.04943)
*Shalmali Bandyopadhyay,Maya Chhetri,Briceyda Delgado,Nsoki Mavinga,Rosa Pardo*

Main category: math.AP

TL;DR: Existence of connected branches of positive solutions for elliptic systems with superlinear boundary conditions, bifurcating from infinity and zero, analyzed using bifurcation theory and degree methods.


<details>
  <summary>Details</summary>
Motivation: Study elliptic systems with superlinear boundary conditions and bifurcation parameters to understand solution behavior and multiplicity.

Method: Combines rescaling method with degree theory, elliptic regularity, bifurcation theory, and sub-/super-solution methods.

Result: Proves existence of connected branch bifurcating from infinity as parameter approaches zero, and global branch from zero with unique bifurcation point from infinity.

Conclusion: Establishes comprehensive existence and multiplicity results for positive solutions using analytical and topological methods.

Abstract: We consider elliptic systems with superlinear and subcritical boundary
conditions and a bifurcation parameter as a multiplicative factor. By combining
the rescaling method with degree theory and elliptic regularity theory, we
prove the existence of a connected branch of positive weak solutions that
bifurcates from infinity as the parameter approaches zero. Furthermore, under
additional conditions on the nonlinearities near zero, we obtain a global
connected branch of positive solutions bifurcating from zero, which possesses a
unique bifurcation point from infinity when the parameter is zero. Finally, we
analyze the behavior of this branch and discuss the number of positive weak
solutions with respect to the parameter using bifurcation theory, degree
theory, and sub- and super-solution methods.

</details>


### [18] [Asymptotic Stability of Solutions to the Forced Higher-order Degenerate Parabolic Equations](https://arxiv.org/abs/2511.04947)
*Jinhong Zhao,Bin Guo*

Main category: math.AP

TL;DR: Global existence and long-time behavior analysis of positive weak solutions for fourth-order quasilinear degenerate parabolic equations modeling non-Newtonian thin-film flow, with characterization of convergence rates under various force conditions.


<details>
  <summary>Details</summary>
Motivation: To understand the influence of inhomogeneous forces on the long-time behavior of non-Newtonian thin-film flows in the complete wetting regime, extending previous work on homogeneous cases.

Method: Using regularity theory for higher-order parabolic equations and energy methods to establish global existence of positive weak solutions and analyze their asymptotic behavior.

Result: For time-dependent forces, solutions converge to spatial average plus time integral of force; for time-independent forces, difference from linear function is bounded; for constant forces, exact coincidence in finite time for shear thickening, and polynomial/exponential convergence for shear-thinning/Newtonian cases.

Conclusion: Inhomogeneous forces significantly affect convergence rates in thin-film flows, with Ellis law fluids behaving like Newtonian fluids, and numerical simulations confirm analytical findings.

Abstract: We study a class of fourth-order quasilinear degenerate parabolic equations
under both time-dependent and time-independent inhomogeneous forces, modeling
non-Newtonian thin-film flow over a solid surface in the "complete wetting"
regime. Using regularity theory for higher-order parabolic equations and energy
methods, we establish the global existence of positive weak solutions and
characterize their long-time behavior.
  Specifically, for power-law thin-film problem with the time-dependent force
$f(t,x)$, we prove that the weak solution converges to $ \bar{u}_0 +
\frac{1}{|\Omega|}\int_{0}^t \int_{\Omega} f(s,x) \, {\rm d}x \, {\rm d}s$, and
provide the convergence rate, where $\bar{u}_0$ is the spatial average of the
initial data. Compared with the homogeneous case in \cite{JJCLKN} (Jansen et
al., 2023), this result clearly demonstrates the influence of the inhomogeneous
force on the convergence rate of the solution. For the time-independent force
$f(x)$, we prove that the difference between the weak solution and the linear
function $\bar{u}_0 + \frac{t}{|\Omega|}\int_\Omega f(x)\, {\rm d}x$ is
uniformly bounded. For the constant force $f_0$, we show that in the case of
shear thickening, the weak solution coincides exactly with $\bar{u}_0 + tf_0$
in a finite time. In both shear-thinning and Newtonian cases, the weak solution
approaches $\bar{u}_0 + tf_0$ at polynomial and exponential rates,
respectively. Later, for the Ellis law thin-film problem, we find that its
solutions behave like those of Newtonian fluids.
  Finally, we conduct numerical simulations to confirm our main analytical
results.

</details>


### [19] [Regularized Reconstruction of Scalar Parameters in Subdiffusion with Memory via a Nonlocal Observation](https://arxiv.org/abs/2511.05277)
*Andrii Hulianytskyi,Sergei Pereverzyev,Sergii Siryk,Nataliya Vasylyeva*

Main category: math.AP

TL;DR: This paper develops analytical and numerical methods to identify unknown scalar parameters in multi-term fractional differential operators for subdiffusion equations using nonlocal observations.


<details>
  <summary>Details</summary>
Motivation: To solve inverse problems for identifying unknown coefficients and fractional derivative orders in complex subdiffusion models with memory effects, which are important for modeling anomalous diffusion processes.

Method: Analytical approach with explicit formulas for parameters, and numerical Tikhonov regularization with quasi-optimality approach for computational recovery from noisy measurements.

Result: Derived explicit formulas for unknown parameters under certain assumptions, established uniqueness and stability results, and demonstrated effective parameter recovery through numerical tests.

Conclusion: The proposed technique successfully identifies scalar parameters in multi-term fractional differential operators with practical effectiveness shown through computational algorithms and numerical validation.

Abstract: In the paper, we propose an analytical and numerical approach to identify
scalar parameters (coefficients, orders of fractional derivatives) in the
multi-term fractional differential operator in time, $\mathbf{D}_t$. To this
end, we analyze inverse problems with an additional nonlocal observation
related to a linear subdiffusion equation
$\mathbf{D}_{t}u-\mathcal{L}_{1}u-\mathcal{K}*\mathcal{L}_{2}u=g(x,t),$ where
$\mathcal{L}_{i}$ are the second order elliptic operators with time-dependent
coefficients, $\mathcal{K}$ is a summable memory kernel, and $g$ is an external
force. Under certain assumptions on the given data in the model, we derive
explicit formulas for unknown parameters. Moreover, we discuss the issues
concerning to the uniqueness and the stability in these inverse problems. At
last, by employing the Tikhonov regularization scheme with the quasi-optimality
approach, we give a computational algorithm to recover the scalar parameters
from a noisy discrete measurement and demonstrate the effectiveness (in
practice) of the proposed technique via several numerical tests.

</details>


### [20] [Jump problem for generalized Lamé-Navier systems in $\mathbb{R}^m$](https://arxiv.org/abs/2511.04959)
*Daniel Alfonso Santiesteban,Ricardo Abreu Blaya,Daniel Alpay*

Main category: math.AP

TL;DR: The paper studies the Lamé-Navier system in Linear Elasticity using Clifford algebra, generalizes it via structural sets, and solves the jump problem using a generalized Teodorescu transform for various regions including fractal boundaries.


<details>
  <summary>Details</summary>
Motivation: To apply Clifford algebra and Dirac operator formalism to fundamental elasticity equations, enabling generalization and solving jump problems for complex boundary geometries.

Method: Uses Clifford algebra to rewrite Lamé-Navier system via Euclidean Dirac operator, introduces structural sets for generalization, and develops generalized Teodorescu transform.

Result: Obtained explicit solution for jump problem applicable to wide classes of regions, including those with fractal boundaries.

Conclusion: Clifford algebra provides powerful framework for elasticity problems, enabling generalization and explicit solutions for jump problems even with complex fractal boundaries.

Abstract: This paper is devoted to study a fundamental system of equations in Linear
Elasticity Theory: the famous Lam\'e-Navier system. The Clifford algebra
language allows us to rewrite this system in terms of the Euclidean Dirac
operator, which at the same time suggests a very natural generalization
involving the so-called structural sets. Our interest lies mainly in the jump
problem for these elastic systems. A generalized Teodorescu transform, to be
introduced here, provides the means for obtaining the explicit solution of the
jump problem for a very wide classes of regions, including those with a fractal
boundary.

</details>


### [21] [A time-fractional Fisher-KPP equation for tumor growth: Analysis and numerical simulation](https://arxiv.org/abs/2511.05312)
*Marvin Fritz,Nikos I. Kavallaris*

Main category: math.AP

TL;DR: Analysis of a time-fractional Fisher-KPP equation with memory effects for tumor growth modeling, establishing local and global well-posedness and proposing a numerical method.


<details>
  <summary>Details</summary>
Motivation: To model memory effects in diffusive population dynamics and provide a framework for tumor growth modeling using fractional calculus.

Method: Combines Galerkin approximation with refined a priori estimates using Bihari-Henry-Gronwall inequality, and develops a nonuniform convolution quadrature numerical scheme.

Result: Established local well-posedness of weak solutions, global well-posedness for small initial data, and validated numerical method showing distinct dynamical behaviors.

Conclusion: The model captures physically consistent tumor progression dynamics with memory effects, offering improved description compared to conventional formulations.

Abstract: We study a time-fractional Fisher-KPP equation involving a Riemann-Liouville
fractional derivative acting on the diffusion term, as derived by Angstmann and
Henry (Entropy, 22:1035, 2020). The model captures memory effects in diffusive
population dynamics and serves as a framework for tumor growth modeling. We
first establish local well-posedness of weak solutions. The analysis combines a
Galerkin approximation with a refined a priori estimate based on a
Bihari-Henry-Gronwall inequality, addressing the nonlinear coupling between the
fractional diffusion and the reaction term. For small initial data, we further
prove global well-posedness and asymptotic stability. A numerical method based
on a nonuniform convolution quadrature scheme is then proposed and validated.
Simulations demonstrate distinct dynamical behaviors compared to conventional
formulations, emphasizing the physical consistency of the present model in
describing tumor progression.

</details>


### [22] [Uniqueness for phaseless inverse elastic scattering problem for periodic structures](https://arxiv.org/abs/2511.04999)
*Youzi He,Wei Wu,Hongyi Dang*

Main category: math.AP

TL;DR: Uniqueness results for inverse elastic scattering with phaseless near-field data in periodic structures in 2D and 3D using superposition of point sources.


<details>
  <summary>Details</summary>
Motivation: To establish uniqueness in inverse elastic scattering problems using phaseless near-field data in periodic structures, which is challenging due to the loss of phase information.

Method: Use superposition of two point sources in each periodic unit, measure phaseless near-field data on parallel lines/planes, derive quasi-periodic Green's functions, establish reciprocity relations, and apply Rayleigh's expansion.

Result: Proved uniqueness results for inverse elastic scattering in 2D periodic and 3D periodic/biperiodic structures with phaseless near-field data.

Conclusion: The paper successfully establishes uniqueness in inverse elastic scattering with phaseless data, with novel contributions including quasi-periodic Green's functions, reciprocity relations, and Rayleigh's expansion in 3D.

Abstract: This paper establishes uniqueness results of inverse elastic scattering
problem with phaseless near-field data in periodic structures in $\mathbb{R}^2$
and periodic/biperiodic structures in $\mathbb{R}^3$. We use a superposition of
two point sources in each periodic unit with different positions as the
incident field, and measures the phaseless near-field data on a line parallel
to $x_1$-axis in 2D, or on a plane parallel to $(x_1,x_2)$-plane in 3D. We
first calculate the explicit formula of quasi-periodic/biperiodic Green's
functions of Lam\'{e} system in $\mathbb{R}^3$. Then, to establish the
uniqueness results, the reciprocity relations for point sources, scattered
fields, and total fields are derived. Finally, with the help of Rayleigh's
expansion, the uniqueness results are proved. The quasi-periodic/biperiodic
Green's functions of Lam\'{e} system in $\mathbb{R}^3$, the reciprocity
relations, and Rayleigh's expansion in $\mathbb{R}^3$ are novel results as
important by-products in the proof process.

</details>


### [23] [Inverse problem of determining a time-dependent coefficient in the time-fractional subdiffusion equation](https://arxiv.org/abs/2511.05011)
*Ravshan Ashurov,Elbek Husanov*

Main category: math.AP

TL;DR: Analysis of forward and inverse problems for fractional subdiffusion equations with time-dependent coefficients, establishing unique solvability for both problems using Banach's contraction mapping theorem.


<details>
  <summary>Details</summary>
Motivation: To investigate direct and inverse problems for fractional subdiffusion equations with time-dependent diffusion and reaction coefficients, which has not been previously studied.

Method: Using Banach's contraction mapping theorem to prove existence and uniqueness of solutions for both forward and inverse problems.

Result: Successfully established unique solvability for the forward problem and proved existence and uniqueness for the inverse problem of identifying unknown time-dependent reaction coefficients.

Conclusion: This is the first work to investigate both direct and inverse problems for fractional subdiffusion equations with time-dependent coefficients, providing rigorous mathematical foundations for such problems.

Abstract: This paper explores the forward and inverse problems for a fractional
subdiffusion equation characterized by time-dependent diffusion and reaction
coefficients. Initially, the forward problem is examined, and its unique
solvability is established. Subsequently, the inverse problem of identifying an
unknown time-dependent reaction coefficient is addressed, with rigorous proofs
of the existence and uniqueness of its solution. Both problems' existence and
uniqueness are demonstrated using Banach's contraction mapping theorem.
Notably, this work is the first to investigate direct and inverse problems for
such equations with time-dependent coefficients.

</details>


### [24] [On global regular axially-symmetric solutions to the Navier-Stokes equations in a cylinder](https://arxiv.org/abs/2511.05098)
*Wiesław J. Grygierzec,Wojciech M. Zajączkowski*

Main category: math.AP

TL;DR: The paper derives energy norm estimates for the vorticity components ω_r/r and ω_φ/r in axisymmetric Navier-Stokes equations with specific boundary conditions on a finite cylinder, but cannot obtain global estimates for nonslip boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To establish mathematical estimates for vorticity components in axisymmetric Navier-Stokes equations under specific boundary conditions, which is important for understanding fluid behavior in cylindrical domains.

Method: Analysis of axisymmetric Navier-Stokes equations in a finite cylinder with prescribed boundary conditions where certain velocity and vorticity components vanish on different parts of the cylindrical boundary.

Result: Derived the estimate ‖ω_r/r‖_V + ‖ω_φ/r‖_V ≤ φ(data), where φ is an increasing positive function and ‖·‖_V is the energy norm over the cylinder domain and time interval.

Conclusion: The authors successfully obtained local estimates for vorticity components under their specified boundary conditions, but were unable to derive global estimates for nonslip boundary conditions, highlighting the limitations of current analytical methods.

Abstract: We consider the axisymmetric Navier-Stokes equations in a finite cylinder
$\Omega\subset\mathbb{R}^3$. We assume that $v_r$, $v_\varphi$,
$\omega_\varphi$ vanish on the lateral part of boundary $\partial\Omega$ of the
cylinder, and that $v_z$, $\omega_\varphi$, $\partial_zv_\varphi$ vanish on the
top and bottom parts of the boundary $\partial\Omega$, where we used standard
cylindrical coordinates, and we denoted by $\omega= {\rm curl}\, v$ the
vorticity field. Our aim is to derive the estimate $$
\left\|\frac{\omega_{r}}{r}\right\|_{V\left(\Omega\times
(0,t)\right)}+\left\|\frac{\omega_{\varphi}}{r}\right\|_{V\left(\Omega\times
(0,t)\right)} \leq \phi(\operatorname{data}),$$ where $\phi$ is an increasing
positive function and $\|\ \|_{V\left(\Omega\times (0,t)\right)}$ is the energy
norm. We are not able to derive any global type estimate for nonslip boundary
conditions.

</details>


### [25] [Variational models of robust optimal transport](https://arxiv.org/abs/2511.05146)
*Luigi De Masi,Andrea Marchese,Annalisa Massaccesi*

Main category: math.AP

TL;DR: Two variational models for robust optimal transport networks: Eulerian (unoriented networks with restricted damages) and Lagrangian (oriented networks with general damages), both proving existence of minimizers.


<details>
  <summary>Details</summary>
Motivation: To design transport networks resilient to damages, balancing construction costs against maintaining partial functionality when parts are damaged.

Method: Two formulations: 1) Eulerian - networks as rectifiable measures with recovery via 1D normal currents, allowing direction changes but restricting damages to closed sets; 2) Lagrangian - networks as traffic plans with recovery via sub-traffic plans, preserving orientation but allowing general damages.

Result: Proved existence of minimizers in both settings. Eulerian model requires unoriented networks for existence, Lagrangian model handles general damages but needs positive distance between source and target measures.

Conclusion: Both models provide complementary approaches to robust optimal transport, with Eulerian formulation offering flexibility in direction changes and Lagrangian formulation accommodating broader damage classes.

Abstract: This paper introduces two variational formulations for a model of robust
optimal transport, that is, the problem of designing optimal transport networks
that are resilient to potential damages, balancing construction costs against
the benefit of maintaining partial functionality when parts of the network are
damaged. We propose a Eulerian formulation, where the network is modeled by a
rectifiable measure and recovery plans are represented by 1-dimensional normal
currents. This framework allows for changes in the direction of the
transportation in response to damages but restricts damages to be
characteristic functions of closed sets. We also propose a Lagrangian
formulation, where the network is a traffic plan (that is, a measure on the
space of Lipschitz curves) and recovery plans are sub-traffic plans. This
approach prescribes the network's orientation but allows for a wider class of
damages. We prove existence of minimizers in both settings. The two models are
compared through examples that illustrate their main differences: the Eulerian
formulation's necessity for an unoriented network to achieve existence, the
Lagrangian formulation's ability to handle general damages and its requirement
for a positive distance between the supports of the source and target measures.

</details>


### [26] [On partial diffusion and mixing without hypoellipticity](https://arxiv.org/abs/2511.05280)
*Xu'an Dou,Delphine Salort,Didier Smets*

Main category: math.AP

TL;DR: Analysis of mixing rates in a Markov process combining diffusion in one direction and transport in another direction, with minimal assumptions on the transport field.


<details>
  <summary>Details</summary>
Motivation: To study mixing rates in systems where transport fields may be highly irregular or degenerate, without requiring standard hypoellipticity assumptions.

Method: Consider a simple Markov process with diffusion in one direction and transport in a transverse direction, using quantitative analysis to estimate mixing rates.

Result: Obtained quantitative mixing rate estimates under limited assumptions about the transport field, which can be highly irregular and/or degenerate.

Conclusion: Mixing rate estimates can be established even for transport fields that are far from satisfying hypoellipticity assumptions, providing broader applicability to irregular systems.

Abstract: A simple Markov process is considered involving a diffusion in one direction
and a transport in a transverse direction. Quantitative mixing rate estimates
are obtained with limited assumptions about the transport field, which might be
highly irregular and/or highly degenerate, in particular quite far from
satisfying an hypoellipticity type assumption.

</details>


### [27] [Existence and weak-strong uniqueness of measure solutions to Euler-alignment/Aw--Rascle--Zhang model of collective behaviour](https://arxiv.org/abs/2511.05326)
*Jakub Woźnicki,Ewelina Zatorska*

Main category: math.AP

TL;DR: Global existence of measure solutions for multi-dimensional Euler-alignment system with matrix-valued communication kernel, showing equivalence to nonlocal ARZ traffic model via pressureless Navier-Stokes approximation.


<details>
  <summary>Details</summary>
Motivation: Study anticipation dynamics in collective behavior through Euler-alignment systems with matrix-valued communication kernels, motivated by their formal equivalence to nonlocal ARZ traffic models.

Method: Use a single degenerate pressureless Navier-Stokes approximation to prove global existence of measure solutions, and establish weak-strong uniqueness principle adapted to pressureless setting and nonlocal alignment forces.

Result: Proved global-in-time existence of measure solutions for both Euler-alignment and nonlocal ARZ formulations, and established rigorous correspondence between the two models through inviscid limit and weak-strong uniqueness.

Conclusion: The nonlocal ARZ and Euler-alignment models are rigorously equivalent - they arise from the same inviscid limit, and weak-strong uniqueness ensures they coincide with classical solutions when they exist.

Abstract: We study the multi-dimensional Euler-alignment system with a matrix-valued
communication kernel, motivated by models of anticipation dynamics in
collective behaviour. A key feature of this system is its formal equivalence to
a nonlocal variant of the Aw--Rascle--Zhang (ARZ) traffic model, in which the
desired velocity is modified by a nonlocal gradient interaction. We prove the
global-in-time existence of measure solutions to both formulations, obtained
via a single degenerate pressureless Navier--Stokes approximation. Furthermore,
we establish a weak-strong uniqueness principle adapted to the pressureless
setting and to nonlocal alignment forces. As a consequence, we rigorously
justify the formal correspondence between the nonlocal ARZ and Euler-alignment
models: they arise from the same inviscid limit, and the weak-strong uniqueness
property ensures that, whenever a classical solution exists, both formulations
coincide with it.

</details>


### [28] [Extreme internal waves: gravity currents and overturning fronts](https://arxiv.org/abs/2511.05329)
*Robin Ming Chen,Samuel Walsh,Miles H. Wheeler*

Main category: math.AP

TL;DR: This paper proves that large-amplitude hydrodynamic bores (traveling wave solutions to two-layer Euler equations) must overturn in the elevation bore family limit, and either overturn or form gravity currents in the depression bore family limit.


<details>
  <summary>Details</summary>
Motivation: To provide rigorous mathematical proof for overturning behavior in hydrodynamic bores, which has been observed numerically for over 45 years but remained unproven despite recent progress in constructing potentially overturning wave families.

Method: Using novel geometric analysis techniques including bounds on velocity field decay near hypothetical double stagnation points, applied to the two-layer free boundary Euler equations with incompressible, irrotational flow confined by rigid boundaries.

Result: Proved that elevation bores must develop vertical tangents (overturn) in the limit, and depression bores either overturn or converge to gravity currents with specific contact angles, confirming von Kármán's conjecture.

Conclusion: The study resolves long-standing questions about overturning in hydrodynamic bores using geometric analysis methods that may have broader applications to large-amplitude wave bifurcation theory.

Abstract: Hydrodynamic bores are front-type traveling wave solutions to the two-layer
free boundary Euler equations in two dimensions. The velocity field in each
layer is assumed to be incompressible and irrotational, and it limits to
distinct laminar flows upstream and downstream. Rigid horizontal boundaries
confine the fluids from above and below. A constant gravitational force acts on
the waves, but surface tension is neglected. It was recently shown by the
authors that there exist two large-amplitude families of hydrodynamic bores: a
curve of depression bores and a curve of elevation bores. We now prove that in
the limit along the elevation bore family, the solutions must overturn: the
interface separating the layers develops a vertical tangent. This type of
behavior was first observed over 45 years ago in numerical computations of
internal gravity waves and gravity water waves with vorticity. Despite
considerable progress over the past decade in constructing families of water
waves that potentially overturn, a proof that overturning definitively occurs
has been stubbornly elusive. We further show that in the limit along the
depression bore family, either overturning occurs or the solutions converge to
a gravity current: the free boundary contacts the upper wall and the relative
velocity in the upper fluid is stagnant. We also determine the contact angle
between the interface and the rigid barrier for the limiting gravity current,
giving the first rigorous confirmation of a conjecture of von K\'arm\'an. The
resolutions of these questions in the specific case of hydrodynamic bores is
accomplished through the use of novel geometric analysis techniques, including
bounds on the decay of the velocity field near a hypothetical double stagnation
point. These ideas may have broader applications to bifurcation theoretic
studies of large-amplitude waves.

</details>


### [29] [Well-posedness of initial boundary value problems for 2D compressible MHD equations in domains with corners](https://arxiv.org/abs/2511.05343)
*Wen Guo,Ya-Guang Wang*

Main category: math.AP

TL;DR: Study of well-posedness for 2D compressible ideal MHD equations in bounded domains with corners, using new anisotropic Sobolev spaces to overcome geometric obstacles.


<details>
  <summary>Details</summary>
Motivation: Corners in bounded perfectly conducting domains create analytic obstacles: lack of smooth tangential vectors prevents classical anisotropic Sobolev spaces, and coupling of normal derivatives near corners prevents usual estimation methods.

Method: Introduce new class of anisotropic Sobolev spaces H^m_*(Ω) for corner geometries; study linearized problem through duality arguments, smoothing procedures, and Helmholtz-type decomposition of velocity and magnetic fields.

Result: Well-posedness theory obtained for both linear and nonlinear compressible ideal MHD equations with impermeable and perfectly conducting boundary conditions in corner domains.

Conclusion: The framework successfully overcomes corner-induced analytic obstacles and establishes well-posedness for compressible ideal MHD equations in domains with corners.

Abstract: In this paper, the well-posedness is studied for the initial boundary value
problem of the two-dimensional compressible ideal magnetohydrodynamic (MHD)
equations in bounded perfectly conducting domains with corners. The presence of
corners yields intrinsic analytic obstacles: the lack of smooth tangential
vectors to the boundary prevents the use of classical anisotropic Sobolev
spaces, and due to the coupling of normal derivatives near corners, one can not
follow the usual way to estimate the normal derivatives of solutions from the
equations. To overcome these difficulties, a new class of anisotropic Sobolev
spaces $H^m_*(\Omega)$ is introduced to treat corner geometries. Within this
framework, the well-posedness theory is obtained for both linear and nonlinear
problems of the compressible ideal MHD equations with the impermeable and
perfectly conducting boundary conditions. The associated linearized problem is
studied in several steps: first one deduces the existence of weak solutions by
using a duality argument in high order tangential spaces, then verifies that it
is indeed a strong solution by several smoothing procedures preserving traces
to get a weak-strong uniqueness result, afterwards the estimates of normal
derivatives are obtained by combining the structure of MHD equations with the
Helmholtz-type decomposition for both of velocity and magnetic fields.

</details>


### [30] [The higher-order fractional Schrödinger equation with nonlinear local perturbations: Uniqueness](https://arxiv.org/abs/2511.05384)
*Giovanni Covi,Ru-Yu Lai,Lili Yan*

Main category: math.AP

TL;DR: Analysis of higher-order fractional Schrödinger equations with local nonlinear perturbations, covering well-posedness estimates and inverse problem uniqueness via Dirichlet-to-Neumann map.


<details>
  <summary>Details</summary>
Motivation: To study both forward and inverse problems for higher-order fractional Schrödinger equations with local nonlinear perturbations, establishing mathematical foundations for analysis and reconstruction.

Method: Establish Sobolev H^s and Hölder C^s estimates for well-posedness using linear fractional Schrödinger equation estimates; use higher-order linearization and unique continuation property of fractional Laplace operator for inverse problem.

Result: Proved well-posedness estimates for nonlinear problem and showed unique determination of local nonlinear perturbations from Dirichlet-to-Neumann map.

Conclusion: The paper successfully establishes mathematical framework for analyzing higher-order fractional Schrödinger equations with nonlinear perturbations, providing both forward solution estimates and inverse problem reconstruction methods.

Abstract: We study the higher-order fractional Schr\"odinger equation with local
nonlinear perturbations and investigate both the forward and inverse problems.
We establish both the Sobolev $H^s$ and H\"older $C^s$ estimates for the
well-posedness of the nonlinear problem, based on the corresponding estimates
derived for the linear fractional Schr\"odinger equation. For the inverse
problem, we show that the local nonlinear perturbations can be uniquely
determined from the Dirichlet-to-Neumann map, by using the higher-order
linearization and the unique continuation property of the fractional Laplace
operator.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [31] [Accelerating metamaterial topology optimization using deep super-resolution networks](https://arxiv.org/abs/2511.04795)
*Ajendra Singh,Shubham Saurabh,Abhinav Gupta,Rajib Chowdhury*

Main category: physics.comp-ph

TL;DR: A deep learning framework using enhanced deep super-resolution (EDSR) for efficient metamaterial topology optimization that reduces computational costs by 93-95% while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: Topology optimization for metamaterials requires extensive computational resources, especially for large parametric spaces and high-resolution designs, creating a need for more efficient approaches.

Method: Train an EDSR network to map low-resolution (48×48) to high-resolution (192×192) metamaterial topologies using SIMP-based TO generated training data, with additional upscale blocks for smoother 3D-printable designs.

Result: The framework achieves high-resolution topology prediction with only 5-7% of conventional computational cost while maintaining accuracy through quantitative metrics (pixel value error, objective function error, IoU, volume fraction error).

Conclusion: The EDSR-based approach provides a scalable, efficient solution for metamaterial design with strong potential for multidisciplinary applications, enabling high-resolution optimization at dramatically reduced computational costs.

Abstract: Designing metamaterials for extreme mechanical behavior involves the optimal
selection of design parameters. However, identifying these optimal parameters
through topology optimization (TO) across a large parametric space requires
extensive computational resources. To address this challenge, we propose a
novel deep learning framework for metamaterial topology optimization using an
enhanced deep super-resolution (EDSR) approach. Generating low-resolution
topologies significantly reduces computational cost compared to high-resolution
designs. Therefore, an EDSR network is trained to learn the mapping between
low- and high-resolution metamaterial topologies. The training dataset is
generated using solid isotropic material with penalization (SIMP)-based TO. We
demonstrate the proposed approach for the design of mechanical metamaterials
targeting objectives such as maximization of bulk modulus, shear modulus, and
elastic modulus, and minimization of Poisson's ratio. Quantitative assessments
-including (i) pixel value error, (ii) objective function error, (iii)
intersection over union, and (iv) volume fraction error -validate the accuracy
of the EDSR-based TO. Our framework predicts high-resolution topologies of size
$192 \times 192$ from optimized low-resolution topologies of size $48 \times
48$. Once trained, the proposed network predicts these high-resolution
topologies with only $5-7\%$ of the computational cost required by conventional
SIMP-based TO at the same resolution. Moreover, by adding upscale blocks, the
framework can generate smoother, higher-resolution topologies suitable for 3D
printing. This approach offers a scalable and efficient solution with strong
potential for multidisciplinary metamaterial design applications.

</details>


### [32] [Structure Matters: A Scale-Resolved Numerical Operando Approach for Lithium-Sulfur Batteries](https://arxiv.org/abs/2511.05233)
*Max Okraschevski,Torben Prill,Paul Maidl,Arnulf Latz,Timo Danner*

Main category: physics.comp-ph

TL;DR: A scale-resolved simulation methodology using HPC and coarse-grained continuum models with Discontinuous Galerkin method to study how porous cathode structure affects rate performance in Lithium-Sulfur batteries.


<details>
  <summary>Details</summary>
Motivation: Lithium-Sulfur batteries have high potential for aerospace due to high energy density but suffer from poor rate capability and low power output, preventing practical implementation. Need to understand how porous cathode structure influences discharge rate performance.

Method: Scale-resolved simulation methodology using high-performance computing (HPC) with coarse-grained continuum model, spatially discretized with Discontinuous Galerkin (DG) method and advanced in time by adaptive controller.

Result: The paper presents a numerical operando approach that provides structural insights into electrochemical cell behavior that are experimentally inaccessible even with modern operando methods.

Conclusion: The workflow demonstrates capabilities to improve Lithium-Sulfur batteries by providing critical structural insights into cathode performance.

Abstract: Lithium-Sulfur batteries (LSBs) are believed to have a high potential for
aerospace applications due to their high gravimetric energy density. However,
despite decades of research and advances, they still suffer from poor rate
capability and low power output, eventually preventing their practical
implementation. One particular aspect we want to shed light on is the influence
of the porous cathode structure on the rate performance during discharge.
Therefore, we present a scale-resolved simulation methodology that aims to
provide structural insights into the electrochemical cell behavior that are
experimentally hardly accessible even for modern operando methods. Our
numerical operando approach employs high-performance computing (HPC) and is
based on a coarse-grained continuum model. The latter is spatially discretized
with a Discontinuous Galerkin (DG) method and advanced in time by an adaptive
controller. The models and methods as well as HPC aspects of our toolbox will
be critically discussed, finally showcasing the capabilities of our workflow to
improve LSBs.

</details>


### [33] [Impact of higher-order exchange on the lifetime of skyrmions and antiskyrmions](https://arxiv.org/abs/2511.05278)
*Hendrik Schrautzer,Moritz A. Goerzen,Bjarne Beyer,Soumyajyoti Haldar,Pavel F. Bessarab,Stefan Heinze*

Main category: physics.comp-ph

TL;DR: Higher-order exchange interactions significantly enhance skyrmion and antiskyrmion lifetimes by increasing energy barriers and modifying energy landscape curvature, enabling thermal stability even without DMI.


<details>
  <summary>Details</summary>
Motivation: Reliable control of skyrmion lifetime is essential for spintronic devices, but the role of higher-order exchange interactions in skyrmion stabilization remains largely unexplored.

Method: Used atomistic spin model with all fourth-order exchange terms and harmonic transition-state theory to calculate lifetimes, evaluating both energetic and entropic contributions.

Result: Higher-order exchange substantially enhances lifetimes - four-spin four-site interaction raises energy barrier, lowers curvature at collapse saddle point, and increases pre-exponential factor. Skyrmions/antiskyrmions remain thermally stable even without DMI. Small tuning of four-spin term modulates prefactor over orders of magnitude.

Conclusion: Higher-order exchange is a promising route to stabilize topological magnetic textures, particularly in systems lacking DMI, and to engineer their thermally activated decay.

Abstract: Reliable control of skyrmion lifetime is essential for realizing spintronic
devices, yet the role of higher-order exchange - which can lead to skyrmion
stabilization - remains largely unexplored. Here we calculate lifetimes of
isolated skyrmions and antiskyrmions at transition-metal interfaces based on an
atomistic spin model that includes all fourth-order exchange terms. Within
harmonic transition-state theory, we evaluate both energetic and entropic
contributions and find substantially enhanced lifetimes when higher-order
exchange is included. The four-spin four-site interaction raises the energy
barrier and lowers the curvature of the energy landscape at the collapse saddle
point, increasing the pre-exponential factor. We show that skyrmions and
antiskyrmions can remain thermally stable even without Dzyaloshinskii-Moriya
interaction (DMI), and that tuning the four-spin term by a small amount
modulates the prefactor over orders of magnitude. Our results identify
higher-order exchange as a promising route to stabilize topological magnetic
textures - in particular in systems lacking DMI - and to engineer their
thermally activated decay.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [34] [Gigagauss magnetic fields generated via theta-pinching driven by multiple petawatt-class lasers](https://arxiv.org/abs/2511.05276)
*Huanyu Song,Zhengming Sheng,Linzheng Wang,Min Chen,Suming Weng,Masakatsu Murakami,Jie Zhang*

Main category: physics.plasm-ph

TL;DR: Ultrahigh gigagauss magnetic fields can be generated using multiple petawatt-class lasers interacting with a solid target containing a cylindrical microtube, through electron current formation and magnetic field amplification.


<details>
  <summary>Details</summary>
Motivation: To produce extremely high axial magnetic fields above gigagauss level, similar to those in neutron stars, which are critical for understanding neutron star structures and emissions.

Method: Using obliquely incident intense lasers on a cuboid solid target with a cylindrical microtube to form azimuthal electron currents, creating seed magnetic fields that are amplified as hot electrons and energetic ions converge towards the axis.

Result: Magnetic fields are dramatically amplified to well above gigagauss level through electron current ring formation, with scaling verified by numerical simulations.

Conclusion: The scheme is robust and suitable for experimental realization on 100 terawatt-class to petawatt-class femtosecond or picosecond laser facilities with multiple linearly polarized laser beams.

Abstract: Extremely high axial magnetic fields above the gigagauss (GG) level are
supposed to exist in neutron stars, which may be a one of the critical
parameters for their internal structures and be responsible for the X and
gamma-ray emission from these stars. Here we show that such ultrahigh magnetic
fields can be produced by multiple petawatt-class lasers interacting with a
cuboid solid target with a cylindrical microtube in the middle. It is found
that the obliquely incident intense lasers at the target surfaces enable the
produced hot electrons to form an azimuthal current and subsequently induce a
seed magnetic field along the cylindrical axis inside the microtube as the hot
electrons transport into it. This current-field configuration is similar to a
theta-pinch device. When the hot electrons and energetic ions produced via
target normal sheath acceleration converge towards the microtube axis, the seed
magnetic field is dramatically amplified. This process continues until the
magnetic pressure near the axis becomes comparable to the thermal pressure
contributed both by hot electrons and energetic ions. Later on, as the plasma
in the center start to be expelled outward by the magnetic pressure, an
electron current ring with extremely high densities is formed, leading to a
further boost of the magnetic fields to well above the GG-level. A scaling of
the magnetic field strength with laser intensities, pulse durations, incident
angles, and target sizes is presented and verified by numerical simulations,
which demonstrates the robustness of our scheme. Our scheme is well suited for
experimental realization on 100 terawatt-class to petawatt-class femtosecond or
picosecond laser facilities with multiple linearly polarized laser beams.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [35] [Systematic global structure search of bismuth-based binary systems under pressure using machine learning potentials](https://arxiv.org/abs/2511.05188)
*Hayato Wakai,Shintaro Ishiwata,Atsuto Seko*

Main category: cond-mat.mtrl-sci

TL;DR: MLP-based global structure searches for 11 bismuth binary systems reveal new compounds and confirm known ones, demonstrating MLP reliability for materials discovery under pressure.


<details>
  <summary>Details</summary>
Motivation: To advance crystal structure prediction using machine learning potentials for efficient and accurate property evaluation in bismuth-based binary systems.

Method: Global structure searches using polynomial MLPs specifically developed for 11 bismuth binary systems (including Na-Bi, Ca-Bi, Eu-Bi) under 0-20 GPa pressure range.

Result: Discovered numerous unreported compounds and identified all experimentally known compounds within the explored configurational space.

Conclusion: MLP-based structure search is robust and reliable, providing valuable insights for discovering novel bismuth-based materials under ambient and high-pressure conditions.

Abstract: Machine learning potentials (MLPs) have significantly advanced global crystal
structure prediction by enabling efficient and accurate property evaluations.
In this study, global structure searches are performed for 11 bismuth-based
binary systems, including Na-Bi, Ca-Bi, and Eu-Bi, under pressures ranging from
0 to 20 GPa, employing polynomial MLPs developed specifically for these
systems. The searches reveal numerous compounds not previously reported in the
literature and identify all experimentally known compounds that are
representable within the explored configurational space. These results
highlight the robustness and reliability of the current MLP-based structure
search. The study provides valuable insights into the discovery and design of
novel bismuth-based materials under both ambient and high-pressure conditions.

</details>


### [36] [Point Defects Limited Carrier Mobility in Janus MoSSe monolayer](https://arxiv.org/abs/2511.05437)
*Nguyen Tran Gia Bao,Ton Nu Quynh Trang,Phan Bach Thang,Nam Thoai,Vu Thi Hanh Thu,Nguyen Tuan Hung*

Main category: cond-mat.mtrl-sci

TL;DR: Study investigates how common defects in Janus MoSSe affect electron transport, defining a saturation defect concentration (C_sat) to quantify defect tolerance and ranking defect impacts.


<details>
  <summary>Details</summary>
Motivation: Point defects formed during Janus MoSSe growth act as scatterers that affect carrier transport in electronic devices, but their specific impact compared to phonon-limited mobility needs quantification.

Method: First-principles calculations to investigate the impact of sulfur vacancies, selenium vacancies, and chalcogen substitutions on electron transport, comparing with phonon-limited mobility.

Result: Found clear defect impact ranking: selenium substituting sulfur is most tolerant (C_sat ≈ 2.07×10^-4), selenium vacancies are most sensitive (C_sat ≈ 3.65×10^-5).

Conclusion: The C_sat benchmarks and defect hierarchy provide quantitative design rules for fabricating high-mobility field-effect transistors, electronic devices, and sensors based on Janus MoSSe.

Abstract: Point defects, often formed during the growth of Janus MoSSe, act as built-in
scatterers and affect carrier transport in electronic devices based on Janus
MoSSe. In this study, we employ first-principles calculations to investigate
the impact of common defects, such as sulfur vacancies, selenium vacancies, and
chalcogen substitutions, on electron transport, and compare their influence
with that of mobility limited by phonons. Here, we define the saturation defect
concentration ($C_{\mathrm{sat}}$) as the highest defect density that still
allows the total mobility to remain within 90\% of the phonon-limited value,
providing a direct measure of how many defects a device can tolerate. Based on
$C_{\mathrm{sat}}$, we find a clear ranking of defect impact: selenium
substituting for sulfur is relatively tolerant, with
$C_{\mathrm{sat}}\approx2.07\times10^{-4}$, while selenium vacancies are the
most sensitive, with $C_{\mathrm{sat}}\approx3.65\times10^{-5}$. Our
$C_{\mathrm{sat}}$ benchmarks and defect hierarchy provide quantitative,
materials-specific design rules that can guide the fabrication of high-mobility
field-effect transistors, electronic devices, and sensors based on Janus MoSSe.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [37] [Generic regularity of intermediate complex structure limits](https://arxiv.org/abs/2511.04651)
*Yang Li,Valentino Tosatti*

Main category: math.DG

TL;DR: Improved convergence from potential C^0 to metric convergence for collapsing Ricci-flat Kähler metrics on Calabi-Yau degenerations near intermediate complex structure limits.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of Ricci-flat Kähler metrics on Calabi-Yau manifolds as they degenerate near intermediate complex structure limits.

Method: Studying polarized degenerations of Calabi-Yau manifolds and analyzing the convergence properties of collapsing Ricci-flat Kähler metrics.

Result: Achieved metric convergence (beyond just potential C^0 convergence) on the generic region for the collapsing Ricci-flat Kähler metrics.

Conclusion: The study provides improved convergence results for Ricci-flat metrics on degenerating Calabi-Yau manifolds near intermediate complex structure limits.

Abstract: We study certain polarized degenerations of Calabi-Yau manifolds near an
intermediate complex structure limit, and improve the potential
$C^0$-convergence to a metric convergence result on the generic region for the
corresponding collapsing Ricci-flat K\"ahler metrics.

</details>


### [38] [Classification of fractional, singular Yamabe metrics on a twice punctured sphere I](https://arxiv.org/abs/2511.05225)
*João Henrique Andrade,Azahara DelaTorre,João Marcos do Ò,Jesse Ratzkin,Juncheng Wei*

Main category: math.DG

TL;DR: For s close to 1, any complete conformally flat constant Q-curvature metric on a twice-punctured sphere must be a Delaunay metric.


<details>
  <summary>Details</summary>
Motivation: To characterize the complete conformally flat constant Q-curvature metrics on twice-punctured spheres and establish their uniqueness properties.

Method: Proving a sharp a priori bound for the conformal factor of these metrics and using this bound to show that all such metrics must be Delaunay metrics when s is near 1.

Result: When s is close to but less than 1, any complete conformally flat constant Q-curvature metric on a twice-punctured sphere is a Delaunay metric.

Conclusion: The Delaunay metrics are the only complete conformally flat constant Q-curvature metrics on twice-punctured spheres for s values near 1, establishing their uniqueness in this regime.

Abstract: The Delaunay metrics form a family of conformally flat, constant fractional
Q-curvature metrics on a twice-punctured sphere. They are all (after a M\"obius
transformation) rotationally symmetric and periodic, and admit several elegant
variational descriptions. We prove that, when s is close to but less than 1,
any complete, conformally flat constant Q-curvature metric on a twice-punctured
sphere is a Delaunay metric. Along the way, we prove a sharp a priori bound for
the conformal factor of these metrics, which may be of independent interest.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [39] [Fast and Scalable Evaluation of Unbiased Atomic Forces in ab initio Variational Monte Carlo via the Lagrangian Technique](https://arxiv.org/abs/2511.05222)
*Kousuke Nakano,Stefano Battaglia,Jürg Hutter*

Main category: physics.chem-ph

TL;DR: This paper presents a more efficient method for computing unbiased atomic forces in quantum Monte Carlo (QMC) calculations by replacing 3N DFT calculations with a single coupled-perturbed Kohn-Sham calculation, improving computational cost and scalability while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: Current QMC methods lack affordable ways to compute unbiased atomic forces consistent with potential energy surfaces, especially for large systems. Previous approaches required 3N additional DFT calculations per system, which becomes computationally prohibitive as system size increases.

Method: The authors developed a method that replaces the 3N DFT calculations needed for unbiased VMC force calculations with a single coupled-perturbed Kohn-Sham calculation, using the Lagrangian technique from quantum chemistry.

Result: The unbiased VMC force calculation not only improves consistency with potential energy surfaces but also significantly enhances accuracy. Comparison with CCSD(T) calculations on rMD17 benchmark molecules shows that unbiased VMC forces are much closer to CCSD(T) values than bare VMC forces.

Conclusion: The proposed method successfully reduces computational cost and improves scalability for unbiased force calculations in QMC, while simultaneously enhancing accuracy compared to high-level quantum chemistry methods like CCSD(T).

Abstract: Ab initio quantum Monte Carlo (QMC) methods are state-of-the-art electronic
structure calculations based on highly parallelizable stochastic frameworks for
accurate solutions of the many-body Schr\"{o}dinger equation, suitable for
modern many-core supercomputer architectures. Despite its potential, one of the
major drawbacks that still hinders QMC applications, especially when targeting
dynamical properties of large systems or large amounts of configurations, is
the lack of an affordable method to compute atomic forces that are consistent
with the corresponding potential energy surfaces (PESs), also known as unbiased
atomic forces. Recently, one of the authors in the present paper proposed a way
to obtain unbiased forces with the Jastrow-correlated Slater determinant
ansatz, where the determinant part is frozen to the values obtained by a
mean-field method, such as DFT. However, the proposed method has a significant
drawback for its applications: for a system with $N$ nuclei, one requires $3N$
additional DFT calculations to get unbiased forces, which is not negligible as
the system size increases. This paper presents a way to replace the $3N$ DFT
calculations with a single coupled-perturbed Kohn-Sham calculation, following
the so-called Lagrangian technique established in quantum chemistry. This
improves the computational cost and scalability of the method. We also
demonstrate that the developed unbiased VMC force calculation improves not only
the consistency with PESs, but also its accuracy, by investigating three
molecules from the rMD17 benchmark set, and comparing the corrected VMC forces
with those obtained by the Coupled-Cluster Singles and Doubles with
perturbative Triples [CCSD(T)] calculations. We found that the bare VMC forces
are significantly biased from the CCSD(T) ones, while the unbiased ones give
values much closer to those of the CCSD(T) ones.

</details>


### [40] [Fine-Tuning Unifies Foundational Machine-learned Interatomic Potential Architectures at ab initio Accuracy](https://arxiv.org/abs/2511.05337)
*Jonas Hänseroth,Aaron Flötotto,Muhammad Nawaz Qaisrani,Christian Dreßler*

Main category: physics.chem-ph

TL;DR: Fine-tuning foundational MLIPs achieves near-ab initio accuracy across diverse architectures, improving force predictions 5-15x and energy accuracy by 2-4 orders of magnitude.


<details>
  <summary>Details</summary>
Motivation: General-purpose foundation MLIPs exhibit architecture-dependent deviations from ab initio reference data, limiting their quantitative accuracy for system-specific predictions.

Method: Benchmarking five MLIP frameworks (MACE, GRACE, SevenNet, MatterSim, ORB) across seven compounds using datasets from short ab initio MD trajectories, with fine-tuning applied to eliminate discrepancies.

Result: Fine-tuning universally enhances force predictions by 5-15x, improves energy accuracy by 2-4 orders of magnitude, and harmonizes performance across all architectures while preserving computational efficiency.

Conclusion: Fine-tuning is a universal route to system-specific predictive accuracy in MLIPs, enabled by the newly introduced aMACEing Toolkit for unified fine-tuning workflows.

Abstract: This work demonstrates that fine-tuning transforms foundational
machine-learned interatomic potentials (MLIPs) to achieve consistent, near-ab
initio accuracy across diverse architectures. Benchmarking five leading MLIP
frameworks (MACE, GRACE, SevenNet, MatterSim, and ORB) across seven chemically
diverse compounds reveals that fine-tuning universally enhances force
predictions by factors of 5-15 and improves energy accuracy by 2-4 orders of
magnitude. The investigated models span both equivariant and invariant, as well
as conservative and non-conservative, architectures. While general-purpose
foundation models are robust, they exhibit architecture-dependent deviations
from ab initio reference data; fine-tuning eliminates these discrepancies,
enabling quantitatively accurate predictions of atomistic and structural
properties. Using datasets constructed from equidistantly sampled frames of
short ab initio molecular dynamics trajectories, fine-tuning reduces force
errors by an order of magnitude and harmonizes performance across all
architectures. These findings establish fine-tuning as a universal route to
achieving system-specific predictive accuracy while preserving the
computational efficiency of MLIPs. To promote widespread adoption, we introduce
the aMACEing Toolkit, which provides a unified and reproducible interface for
fine-tuning workflows across multiple MLIP frameworks.

</details>


<div id='physics.ins-det'></div>

# physics.ins-det [[Back]](#toc)

### [41] [Modelling the Performance of Tritium Process Monitors from First Principles](https://arxiv.org/abs/2511.05340)
*Nicolas J. Sovare,Walter T. Shmayda*

Main category: physics.ins-det

TL;DR: A computational model was developed to describe the behavior of a one-liter tritium process monitor, which shows linear response to tritium concentrations from 1 μCi/m³ to 1 Ci/m³ but nonlinear behavior at low anode voltage and low carrier gas pressure.


<details>
  <summary>Details</summary>
Motivation: To better understand and predict the behavior of ionization chamber-based tritium process monitors, especially their nonlinear responses under certain operating conditions.

Method: Developed a computational model from first principles to describe the monitor's behavior across different regimes, validated and tuned by comparing predictions with previously-collected experimental data.

Result: The model successfully describes the monitor's behavior in both linear and nonlinear regimes, with predictions matching experimental data after validation and tuning.

Conclusion: The computational model effectively characterizes the tritium monitor's performance and will be expanded to incorporate additional detector geometries and designs in future work.

Abstract: Ionization chamber-based, in-line tritium process monitors play an important
part in determining the behavior of a tritium system. The one-liter detection
volume monitor has been characterized well through experiment and to respond
linearly to tritium concentrations for the range of $1 {\mu}Ci/m^3$ to $1
Ci/m^3$. Additionally, it has been shown to behave nonlinearly for low voltage
on the central anode and low pressure of the carrier gas. A computational model
was developed from first principles that successfully describes the behavior of
the one-liter monitor for each of these regimes. Predictions from the model are
compared to previously-collected experimental data in order to determine
validity and tune the model. The model will be expanded to incorporate
additional detector geometries and designs in the future.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [42] [Predicting and forecasting reactivity and flux using long short-term memory models in pebble bed reactors during run-in](https://arxiv.org/abs/2511.05118)
*Ian Kolaja,Ludovic Jantzen,Tatiana Siaraferas,Massimiliano Fratoni*

Main category: eess.SY

TL;DR: LSTM networks are used to predict reactivity, flux, and power profiles in pebble bed reactors using operational history and pebble measurements, achieving high accuracy and enabling optimization of reactor operations.


<details>
  <summary>Details</summary>
Motivation: Pebble bed reactors have complex reactivity dynamics with different timescales for various operational parameters, and traditional in-core measurements are limited by high temperatures, neutron flux, and fuel movement.

Method: Training long short-term memory (LSTM) networks using operational history and synthetic batch-level pebble measurements (like discharge burnup distributions) to predict reactor parameters.

Result: The model achieved an R² of 0.9914 on testing data and demonstrated capability to forecast reactivity responses to future operational changes.

Conclusion: LSTM networks provide an effective approach for predicting and optimizing pebble bed reactor operations, with potential applications in improving reactor running-in procedures.

Abstract: Pebble bed reactor (PBR) operation presents unique advantages and challenges
due to the ability to continuously change the fuel mixture and excess
reactivity. Each operation parameter affects reactivity on a different
timescale. For example, fuel insertion changes may take months to fully
propagate, whereas control rod movements have immediate effects. In-core
measurements are further limited by the high temperatures, intense neutron
flux, and dynamic motion of the fuel bed. In this study, long short-term memory
(LSTM) networks are trained to predict reactivity, flux profiles, and power
profiles as functions of operating history and synthetic batch-level pebble
measurements, such as discharge burnup distributions. The model's performance
is evaluated using unseen temporal data, achieving an $R^2$ of 0.9914 on the
testing set. The capability of the network to forecast reactivity responses to
future operational changes is also examined, and its application for optimizing
reactor running-in procedures is explored.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [43] [Secondary small-scale dynamics of a Rayleigh-Taylor unstable solar prominence](https://arxiv.org/abs/2511.04764)
*Madhurjya Changmai,Jack M. Jenkins,Rony Keppens*

Main category: astro-ph.SR

TL;DR: High-resolution 2.5D MHD simulations of solar prominences show Rayleigh-Taylor and Kelvin-Helmholtz instabilities leading to current sheets, magnetic reconnection, and energetic jets that enhance energy transport.


<details>
  <summary>Details</summary>
Motivation: To understand the small-scale dynamics in quiescent solar prominences, particularly how Rayleigh-Taylor instabilities lead to structured morphologies, bubbles, plumes, and secondary instabilities observed in recent solar observations.

Method: Performed high-resolution 2.5D resistive magnetohydrodynamic simulations using MPI-AMRVAC code with ~11.7 km spatial resolution in a 30 Mm×30 Mm domain, evolving for ~10 minutes of solar time. Analyzed using synthetic images of SDO/AIA filters and Hα filters.

Result: RT and KH instabilities formed current sheets and localized reconnection events, creating energetic jets that enhanced energy transport. Synthetic images matched observed scales, speeds, and duration, but activity remained concentrated in hot coronal plasma rather than cool prominence material.

Conclusion: While simulations match observational features, key physical ingredients may be missing as activity concentrates in surrounding coronal plasma. Future 3D studies in more realistic magnetic configurations are needed to address limitations.

Abstract: Quiescent solar prominences show distinct small-scale dynamics in
observations. Their internal density contrasts with the surrounding corona make
them susceptible to Rayleigh-Taylor (RT) instabilities, leading to vertically
structured prominence morphologies when observed at the solar limb. As a
result, prominences develop bubbles and plumes, along with secondary
Kelvin-Helmholtz (KH) roll-ups along their edges. Recent observations also
suggest magnetic reconnection events within the RT-driven turbulent flows. We
perform high-resolution 2.5D resistive magnetohydrodynamic simulations using
the open-source MPI-AMRVAC code, reaching a spatial resolution of $\sim 11.7$
km in a 2D domain of size 30 Mm$\times$30 Mm and evolving the system for
approximately 10 minutes of solar time. A dense, magnetic pressure supported
prominence serves as the initial state, which becomes unstable at the
prominence-corona interface. The resulting interaction between RT and KH
instabilities leads to the formation of current sheets and localized
reconnection events. The reconnection-driven outflows form energetic jets that
enhance energy transport and dissipation across the prominence. We analyze our
high-resolution prominence simulation using synthetic images of the broadband
SDO/AIA 094, 171, and 193 \r{A} and narrowband H$\alpha$ filters, to compare
the developing fine-scale structures with their observational counterparts.
Most secondary instabilities emerge in the hotter coronal regions surrounding
the cooler prominence core. While our simulated features match observed scales,
speeds, and duration, the simulated activity remains concentrated in hot,
surrounding coronal plasma rather then the cool prominence material, implying
that key physical ingredients may be missing. Future 3D studies in more
realistic magnetic configurations are required to address these limitations.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [44] [A Latent-Variable Formulation of the Poisson Canonical Polyadic Tensor Model: Maximum Likelihood Estimation and Fisher Information](https://arxiv.org/abs/2511.05352)
*Carlos Llosa-Vite,Daniel M. Dunlavy,Richard B. Lehoucq,Oscar López,Arvind Prasadan*

Main category: math.ST

TL;DR: The paper develops parameter inference for Poisson Canonical Polyadic (PCP) tensor models using a latent-variable approach, deriving maximum likelihood estimators and Fisher information matrices to analyze model identifiability and indeterminacy.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous parameter inference for PCP tensor models by exploiting the observation that any random PCP tensor can be derived from marginalizing a higher-dimensional latent tensor, enabling better understanding of model identifiability and well-posedness.

Method: Uses a latent-variable formulation where PCP tensors are marginalized from higher-dimensional tensors, derives non-iterative maximum likelihood estimators, and computes observed and expected Fisher information matrices to analyze identifiability and indeterminacy.

Result: Shows that several existing algorithms for non-negative matrix and tensor factorizations are Expectation-Maximization algorithms, provides Fisher information insights into tensor model well-posedness, and demonstrates simplified results for rank one PCP models.

Conclusion: The latent-variable approach enables rigorous parameter inference for PCP tensor models, revealing connections to existing algorithms and providing crucial insights into model identifiability through Fisher information analysis.

Abstract: We establish parameter inference for the Poisson canonical polyadic (PCP)
tensor model through a latent-variable formulation. Our approach exploits the
observation that any random PCP tensor can be derived by marginalizing an
unobservable random tensor of one dimension larger. The loglikelihood of this
larger dimensional tensor, referred to as the "complete" loglikelihood, is
comprised of multiple rank one PCP loglikelihoods. Using this methodology, we
first derive non-iterative maximum likelihood estimators for the PCP model and
demonstrate that several existing algorithms for fitting non-negative matrix
and tensor factorizations are Expectation-Maximization algorithms. Next, we
derive the observed and expected Fisher information matrices for the PCP model.
The Fisher information provides us crucial insights into the well-posedness of
the tensor model, such as the role that tensor rank plays in identifiability
and indeterminacy. For the special case of rank one PCP models, we demonstrate
that these results are greatly simplified.

</details>


### [45] [Near-Efficient and Non-Asymptotic Multiway Inference](https://arxiv.org/abs/2511.05368)
*Oscar López,Arvind Prasadan,Carlos Llosa-Vite,Richard B. Lehoucq,Daniel M. Dunlavy*

Main category: math.ST

TL;DR: Non-asymptotic efficiency guarantees for tensor decomposition-based inference in count data models, showing near-CRLB performance for rank-one cases but efficiency gaps for higher ranks.


<details>
  <summary>Details</summary>
Motivation: To establish finite-sample efficiency guarantees for tensor decomposition methods in count data models, particularly for Poisson data, addressing both parametric inference and multiway analysis.

Method: Uses rank-constrained maximum-likelihood estimator under Poisson framework, analyzing both rank-one and higher-rank settings, with theoretical analysis of variance bounds and numerical experiments.

Result: Rank-one estimator achieves multiway analysis with variance matching Cramér-Rao Lower Bound up to constants and log factors; higher-rank cases show efficiency gaps but CP-based parametric inference remains nearly minimax optimal with improved rank dependence.

Conclusion: Provides general framework for near-efficient multiway estimators in finite samples, demonstrating near-optimal performance for rank-one cases while highlighting limitations for higher ranks.

Abstract: We establish non-asymptotic efficiency guarantees for tensor
decomposition-based inference in count data models. Under a Poisson framework,
we consider two related goals: (i) parametric inference, the estimation of the
full distributional parameter tensor, and (ii) multiway analysis, the recovery
of its canonical polyadic (CP) decomposition factors. Our main result shows
that in the rank-one setting, a rank-constrained maximum-likelihood estimator
achieves multiway analysis with variance matching the Cram\'{e}r-Rao Lower
Bound (CRLB) up to absolute constants and logarithmic factors. This provides a
general framework for studying "near-efficient" multiway estimators in
finite-sample settings. For higher ranks, we illustrate that our multiway
estimator may not attain the CRLB; nevertheless, CP-based parametric inference
remains nearly minimax optimal, with error bounds that improve on prior work by
offering more favorable dependence on the CP rank. Numerical experiments
corroborate near-efficiency in the rank-one case and highlight the efficiency
gap in higher-rank scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [46] [Diffusion-Based Electromagnetic Inverse Design of Scattering Structured Media](https://arxiv.org/abs/2511.05357)
*Mikhail Tsukerman,Konstantin Grotov,Pavel Ginzburg*

Main category: cs.LG

TL;DR: A conditional diffusion model for electromagnetic inverse design that generates dielectric sphere structures directly from target scattering profiles, bypassing iterative optimization and achieving faster design times.


<details>
  <summary>Details</summary>
Motivation: To overcome the computational expense and time-consuming nature of traditional iterative optimization methods in electromagnetic inverse design, enabling rapid generation of metasurface geometries.

Method: Uses a 1D U-Net architecture with Feature-wise Linear Modulation to map target angular scattering patterns to 2x2 dielectric sphere structures, trained on 11,000 simulated metasurfaces.

Result: Achieves median MPE below 19% on unseen targets (best: 1.39%), outperforms CMA-ES evolutionary optimization while reducing design time from hours to seconds.

Conclusion: Diffusion models are promising for advancing electromagnetic inverse design research, enabling rapid exploration of complex metasurface architectures and accelerating photonic and wireless communication system development.

Abstract: We present a conditional diffusion model for electromagnetic inverse design
that generates structured media geometries directly from target differential
scattering cross-section profiles, bypassing expensive iterative optimization.
Our 1D U-Net architecture with Feature-wise Linear Modulation learns to map
desired angular scattering patterns to 2x2 dielectric sphere structure,
naturally handling the non-uniqueness of inverse problems by sampling diverse
valid designs. Trained on 11,000 simulated metasurfaces, the model achieves
median MPE below 19% on unseen targets (best: 1.39%), outperforming CMA-ES
evolutionary optimization while reducing design time from hours to seconds.
These results demonstrate that employing diffusion models is promising for
advancing electromagnetic inverse design research, potentially enabling rapid
exploration of complex metasurface architectures and accelerating the
development of next-generation photonic and wireless communication systems. The
code is publicly available at
https://github.com/mikzuker/inverse_design_metasurface_generation.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [47] [Self-adaptive weighting and sampling for physics-informed neural networks](https://arxiv.org/abs/2511.05452)
*Wenqian Chen,Amanda Howard,Panos Stinis*

Main category: stat.ML

TL;DR: A hybrid adaptive sampling and weighting method improves PINNs by targeting regions with rapid solution variations and balancing convergence rates, achieving better accuracy and efficiency than using either method alone.


<details>
  <summary>Details</summary>
Motivation: Physics-informed deep learning shows promise for solving PDEs but faces challenges with accuracy and efficiency on complex problems, especially with limited training points.

Method: Combines adaptive sampling to identify points in regions with rapid solution variation and adaptive weighting to balance convergence rates across training points.

Result: Numerical experiments show the hybrid approach consistently improves prediction accuracy and training efficiency, outperforming methods using only sampling or only weighting.

Conclusion: The proposed hybrid framework offers a more robust approach for solving PDEs with PINNs by leveraging complementary strengths of adaptive sampling and weighting.

Abstract: Physics-informed deep learning has emerged as a promising framework for
solving partial differential equations (PDEs). Nevertheless, training these
models on complex problems remains challenging, often leading to limited
accuracy and efficiency. In this work, we introduce a hybrid adaptive sampling
and weighting method to enhance the performance of physics-informed neural
networks (PINNs). The adaptive sampling component identifies training points in
regions where the solution exhibits rapid variation, while the adaptive
weighting component balances the convergence rate across training points.
Numerical experiments show that applying only adaptive sampling or only
adaptive weighting is insufficient to consistently achieve accurate
predictions, particularly when training points are scarce. Since each method
emphasizes different aspects of the solution, their effectiveness is problem
dependent. By combining both strategies, the proposed framework consistently
improves prediction accuracy and training efficiency, offering a more robust
approach for solving PDEs with PINNs.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [48] [Neural Network for Subgrid Turbulence Modeling for Large Eddy](https://arxiv.org/abs/2511.05103)
*Eduardo Vital,Jean-Marc Gratien,Yassine Ayoun,Thibault Faney,Julien Bohbot*

Main category: physics.flu-dyn

TL;DR: This paper presents a workflow for developing data-driven closure models in multiscale systems like turbulent fluid dynamics, combining physics-based equations with machine learning to enhance simulation accuracy.


<details>
  <summary>Details</summary>
Motivation: To address the need for closure models in multiscale systems where some fields cannot be fully prescribed but significantly affect simulation accuracy, particularly in turbulent fluid dynamics where LES requires modeling of sub-grid scale effects.

Method: A comprehensive workflow including high-fidelity data generation, a priori learning, and a posteriori learning that integrates traditional physics-based equations with data-driven machine learning models, coupled with numerical solvers and neural networks.

Result: The study emphasizes the importance of post-processing and effective filtering of fine-resolution fields, and highlights the implications of numerical method selection (LBM vs Finite Volume Method) for closure modeling.

Conclusion: Data-driven models can effectively enhance differential equations in multiscale simulations, with careful consideration of filtering techniques and numerical method choices being crucial for successful implementation.

Abstract: When simulating multiscale systems, where some fields cannot be fully
prescribed despite their effects on the simulation's accuracy, closure models
are needed. This behavior is observed in turbulent fluid dynamics, where Large
Eddy Simulations (LES) depict global behavior while turbulence modeling
introduces dissipation correspondent to smaller sub-grid scales. Recently,
scientific machine learning techniques have emerged to address this problem by
integrating traditional (physics-based) equations with data-driven
(machine-learned) models, typically coupling numerical solvers with neural
networks. This work presents a comprehensive workflow, encompassing
high-fidelity data generation, a priori learning, and a posteriori learning,
where data-driven models enhance differential equations. The study underscores
the critical role of post-processing and effective filtering of fine-resolution
fields and the implications numerical methods selection, such as the Lattice
Boltzmann Method (LBM) or Finite Volume Method.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [49] [Block-structured Operator Inference for coupled multiphysics model reduction](https://arxiv.org/abs/2511.05389)
*Benjamin G. Zastrow,Anirban Chaudhuri,Karen E. Willcox,Anthony Ashley,Michael Chamberlain Henson*

Main category: cs.CE

TL;DR: Block-structured Operator Inference learns structured reduced-order models for multiphysics systems by specifying physics component structures and coupling terms, improving computational efficiency while preserving accuracy.


<details>
  <summary>Details</summary>
Motivation: To develop more efficient reduced-order models for multiphysics systems that preserve physical structure and system properties while reducing learning dimensionality.

Method: Block-structured formulation of Operator Inference that specifies governing equation structure for each physics component and coupling terms, learned nonintrusively from snapshot data with tailored regularization.

Result: 20% online prediction speedup over monolithic Operator Inference for aeroelastic analysis of AGARD 445.6 wing across various flow conditions while maintaining accuracy.

Conclusion: Block-structured Operator Inference provides computational advantages over monolithic approaches while preserving physical structure and accuracy in multiphysics modeling.

Abstract: This paper presents a block-structured formulation of Operator Inference as a
way to learn structured reduced-order models for multiphysics systems. The
approach specifies the governing equation structure for each physics component
and the structure of the coupling terms. Once the multiphysics structure is
specified, the reduced-order model is learned from snapshot data following the
nonintrusive Operator Inference methodology. In addition to preserving physical
system structure, which in turn permits preservation of system properties such
as stability and second-order structure, the block-structured approach has the
advantages of reducing the overall dimensionality of the learning problem and
admitting tailored regularization for each physics component. The numerical
advantages of the block-structured formulation over a monolithic Operator
Inference formulation are demonstrated for aeroelastic analysis, which couples
aerodynamic and structural models. For the benchmark test case of the AGARD
445.6 wing, block-structured Operator Inference provides an average 20% online
prediction speedup over monolithic Operator Inference across subsonic and
supersonic flow conditions in both the stable and fluttering parameter regimes
while preserving the accuracy achieved with monolithic Operator Inference.

</details>
