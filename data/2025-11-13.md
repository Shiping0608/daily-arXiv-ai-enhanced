<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 15]
- [math.AP](#math.AP) [Total: 18]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 8]
- [math.OC](#math.OC) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [math.PR](#math.PR) [Total: 1]
- [nucl-th](#nucl-th) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [math.FA](#math.FA) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [math.SP](#math.SP) [Total: 1]
- [math.DS](#math.DS) [Total: 1]
- [gr-qc](#gr-qc) [Total: 2]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A Particle method for stationary transport equations](https://arxiv.org/abs/2511.08774)
*Rafael Bailo,Julie Binard,Pierre Degond,Pascal Noble*

Main category: math.NA

TL;DR: A Particle method for stationary transport equations using spatial variables instead of time, with convergence proof and error estimates, applied to landscape evolution modeling.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient numerical method for stationary transport equations that can handle complex domains with wet/dry areas, particularly for landscape evolution problems involving water erosion and sedimentation.

Method: Particle method inspired by non-stationary approaches, replacing time with spatial variables. Computes particle trajectories using time-dependent equations and uses quadrature with particle locations as points. Requires characteristic completeness assumption.

Result: Proved convergence under regularity assumptions and characteristic completeness. Provided error estimates. Successfully tested on 2D linear equation with numerical convergence study. Applied to landscape evolution model with wet/dry areas.

Conclusion: The proposed Particle method is effective for stationary transport equations, particularly useful for landscape evolution modeling where it can handle challenging wet/dry area transitions.

Abstract: We present and study a Particle method for the stationary solutions of a class of transport equations. This method is inspired by non-stationary Particle methods, the time variable being replaced by one spatial variable. Particles trajectories are computed using the ``time-dependent'' equations, and then the approximation is based on a quadrature method using the particle locations as quadrature points. We prove the convergence of the scheme under suitable regularity assumptions on the data and the solution, together with a ``characteristic completeness'' assumption (the characteristic curves fullfill the whole computational domain). We also provide an error estimate. The scheme is tested numerically on a two dimensional linear equation and we present a numerical study of convergence. Finally, we use this method to carry out numerical simulations of a landscape evolution model, where an erodible topography evolves under the effects of water erosion and sedimentation. The scheme is then useful to deal with wet/dry areas.

</details>


### [2] [A Neural-Operator Preconditioned Newton Method for Accelerated Nonlinear Solvers](https://arxiv.org/abs/2511.08811)
*Youngkyu Lee,Shanqing Liu,Jerome Darbon,George Em Karniadakis*

Main category: math.NA

TL;DR: NP-Newton method uses neural operators to solve parametric nonlinear systems, overcoming Newton iteration stagnation with adaptive negative step sizes.


<details>
  <summary>Details</summary>
Motivation: To address stagnation and instability in Newton iterations caused by unbalanced nonlinearities in parametric systems.

Method: Fixed-point neural operator (FPNO) learns direct mapping from current iterate to solution by emulating fixed-point iterations, using adaptive negative step sizes instead of traditional line-search.

Result: Demonstrated computational efficiency and robustness across multiple real-world applications, especially for very strong nonlinearities.

Conclusion: NP-Newton method effectively mitigates unbalanced nonlinearity effects and outperforms traditional approaches for strongly nonlinear problems.

Abstract: We propose a novel neural preconditioned Newton (NP-Newton) method for solving parametric nonlinear systems of equations. To overcome the stagnation or instability of Newton iterations caused by unbalanced nonlinearities, we introduce a fixed-point neural operator (FPNO) that learns the direct mapping from the current iterate to the solution by emulating fixed-point iterations. Unlike traditional line-search or trust-region algorithms, the proposed FPNO adaptively employs negative step sizes to effectively mitigate the effects of unbalanced nonlinearities. Through numerical experiments we demonstrate the computational efficiency and robustness of the proposed NP-Newton method across multiple real-world applications, especially for very strong nonlinearities.

</details>


### [3] [New perturbation bounds for low rank approximation of matrices via contour analysis](https://arxiv.org/abs/2511.08875)
*Phuc Tran,Van Vu*

Main category: math.NA

TL;DR: This paper develops a new contour analysis method to bound the error between low-rank approximations of noisy data matrices, introducing parameters that measure noise skewness relative to matrix singular vectors.


<details>
  <summary>Details</summary>
Motivation: In practice, data matrices often contain noise, and we use low-rank approximations of noisy data rather than clean data. It's important to estimate the error between these approximations for reliable downstream computations.

Method: The authors develop a contour analysis-based method that introduces new parameters measuring the skewness between noise matrix and singular vectors of the original matrix, focusing on cases where the original matrix has relatively low rank.

Result: The method provides notable improvements in bounding the error ||Ã_p - A_p|| in many popular settings by exploiting the introduced skewness parameters.

Conclusion: The contour analysis method offers significant improvements for error estimation in low-rank approximations of noisy data matrices, with applications beyond the specific problem studied.

Abstract: Let $A$ be an $m \times n$ matrix with rank $r$ and spectral decomposition $A = \sum _{i=1}^r σ_i u_i v_i^\top, $ where $σ_i$ are its singular values, ordered decreasingly, and $u_i, v_i$ are the corresponding left and right singular vectors. For a parameter $1 \le p \le r$, $A_p := \sum_{i=1}^p σ_i u_i v_i^\top$ is the best rank $p$ approximation of $A$. In practice, one often chooses $p$ to be small, leading the commonly used phrase "low-rank approximation". Low-rank approximation plays a central role in data science because it can substantially reduce the dimensionality of the original data, the matrix $A$. For a large data matrix $A$, one typically computes a rank-$p$ approximation $A_p$ for a suitably chosen small $p$, stores $A_p$, and uses it as input for further computations. The reduced dimension of $A_p$ enables faster computations and significant data compression. In practice, noise is inevitable. We often have access only to noisy data $\tilde A = A + E$, where $E$ represents the noise. Consequently, the low-rank approximation used as input in many downstream tasks is $\tilde A_p$, the best rank $p$ approximation of $\tilde A$, rather than $A_p$. Therefore, it is natural and important to estimate the error $ \| \tilde A_p - A_p \|$. In this paper, we develop a new method (based on contour analysis) to bound $\| \tilde A_p - A_p \|$. We introduce new parameters that measure the skewness between the noise matrix $E$ and the singular vectors of $A$, and exploit these to obtain notable improvements in many popular settings. This method is of independent interest and has many further applications. We focus on the case where $A$ itself has relatively low rank. This assumption is frequently met in practice, and we think that this case deserves a separate, accessible treatment.

</details>


### [4] [Generalized Singular Value Decompositions of Dual Quaternion Matrix Triplets](https://arxiv.org/abs/2511.08885)
*Sitao Ling,Wenxuan Ma,Musheng Wei*

Main category: math.NA

TL;DR: The paper introduces two types of generalized singular value decompositions (GSVD) for dual quaternion matrix triplets to handle coupled rotation-translation signals in engineering applications.


<details>
  <summary>Details</summary>
Motivation: Growing demand for efficient processing of coupled rotation-translation signals in modern engineering requires advanced numerical linear algebra tools for dual quaternion matrices.

Method: Developed restricted SVD and product-product SVD for dual quaternion matrix triplets, adapting standard SVD with distinct inner products applied to row and column spaces.

Result: Successfully defined two types of GSVDs for dual quaternion matrix triplets and provided examples demonstrating the feasibility of these decompositions.

Conclusion: The proposed GSVDs provide sophisticated matrix factorization tools for dual quaternion matrices that can handle coupled rotation-translation signals in engineering applications.

Abstract: In signal processing and identification, generalized singular value decomposition (GSVD), related to a sequence of matrices in product/quotient form are essential numerical linear algebra tools. On behalf of the growing demand for efficient processing of coupled rotation-translation signals in modern engineering, we introduce the restricted SVD of a dual quaternion matrix triplet $(\boldsymbol{A},\boldsymbol{B},\boldsymbol{C})$ with $\boldsymbol{A}\in {\bf \mathbb{DQ}}^{m \times n}$, $\boldsymbol{B} \in {\bf \mathbb{DQ}}^{m \times p}$, $\boldsymbol{C} \in {\bf \mathbb{DQ}}^{q\times n}$, and the product-product SVD of a dual quaternion matrix triplet $(\boldsymbol{A},\boldsymbol{B},\boldsymbol{C})$ with $\boldsymbol{A}\in {\bf \mathbb{DQ}}^{m \times n}$, $\boldsymbol{B} \in {\bf \mathbb{DQ}}^{n \times p}$, $\boldsymbol{C} \in {\bf \mathbb{DQ}}^{p\times q}$. The two types of GSVDs represent a sophisticated matrix factorization that accounts for a given dual quaternion matrix in conjunction with two additional dual quaternion matrices. The decompositions can be conceptualized as an adaptation of the standard SVD, where the distinctive feature lies in the application of distinct inner products to the row and column spaces. Two examples are outlined to illustrate the feasibility of the decompositions.

</details>


### [5] [A polynomially accelerated fixed-point iteration for vector problems](https://arxiv.org/abs/2511.09012)
*Francesco Alemanno*

Main category: math.NA

TL;DR: TPA is a three-point polynomial accelerator that speeds up fixed-point iterations by estimating the dominant contraction factor from residual dynamics and applying a regularized update using the last three iterates.


<details>
  <summary>Details</summary>
Motivation: Fixed-point procedures often slow down due to persistent residual plateaus caused by slowly decaying error modes, which TPA aims to overcome.

Method: TPA infers the dominant contraction factor from residual dynamics and assembles a regularized three-point update from the last three iterates, requiring minimal modification to existing algorithms.

Result: TPA achieves prescribed tolerance with significantly fewer map evaluations than Picard iteration, weighted Jacobi/SOR, and shallow Anderson schemes across linear systems with clustered eigenvalues, nonlinear tanh mappings, and discretized Poisson equations.

Conclusion: TPA provides an efficient acceleration method that maintains minimal memory and computational overhead while substantially improving convergence rates in fixed-point iterations.

Abstract: Fixed-point procedures frequently slow down because an error mode decays much more slowly than the others, leaving the base iteration with a persistent residual plateau. To counter this obstruction we formulate a three-point polynomial accelerator (TPA) that fits inside existing fixed-point algorithms with negligible modification and computational cost. TPA first infers the dominant contraction factor directly from the residual dynamics and then assembles a regularised three-point update from the last three iterates. We show that across a suite of tests: a linear system with clustered eigenvalues, a nonlinear tanh mapping, and a discretised Poisson equation, TPA attains a prescribed tolerance in markedly fewer map evaluations than Picard iteration, weighted Jacobi/SOR, and shallow Anderson schemes while preserving a minimal memory and arithmetic footprint.

</details>


### [6] [Recursive algorithms for computing Birkhoff interpolation polynomials](https://arxiv.org/abs/2511.09014)
*Xue Jiang,Yuanhe Li,Zhe Li*

Main category: math.NA

TL;DR: This paper extends the Generalized Recursive Polynomial Interpolation Algorithm (GRPIA) to solve Birkhoff interpolation problems using Schur complement and Sylvester identity theory, providing a recursive method that reduces computational costs compared to Gaussian elimination-based approaches.


<details>
  <summary>Details</summary>
Motivation: To generalize Hermite interpolation to Birkhoff interpolation problems where interpolation conditions involve evaluation functionals composed with differential polynomials, addressing computational efficiency issues in existing methods.

Method: Develops recursive algorithms based on Schur complement and Sylvester identity theory, incorporating a judgment condition for well-posedness and computing lower-degree Newton-type interpolation bases.

Result: The proposed recursive approach successfully computes interpolation polynomials for broader Birkhoff interpolation problems while significantly reducing computational costs compared to Gaussian elimination methods.

Conclusion: The generalized GRPIA provides an efficient recursive solution for Birkhoff interpolation problems, offering computational advantages over traditional approaches that rely on Gaussian elimination.

Abstract: As a generalization of Hermite interpolation problem, Birkhoff interpolation is an important subject in numerical approximation. This paper generalizes the existing Generalized Recursive Polynomial Interpolation Algorithm (GRPIA) that is used to compute the Hermite interpolation polynomial. Based on the theory of the Schur complement and the Sylvester identity, the proposed recursive algorithms are applicable to a broader class of Birkhoff interpolation problems, where each interpolation condition is given by the composition of an evaluation functional and a differential polynomial. The approach incorporates a judgment condition to ensure the problem's well-posedness and computes a lower-degree Newton-type interpolation basis (which is also a strongly proper interpolation basis) along with the corresponding interpolation polynomial. Compared with existing algorithms that rely on Gaussian elimination to compute the interpolation basis, our recursive approach significantly reduces the computational cost.

</details>


### [7] [A lattice algorithm with multiple shifts for function approximation in Korobov spaces](https://arxiv.org/abs/2511.09071)
*Mou Cai,Josef Dick,Takashi Goda*

Main category: math.NA

TL;DR: Novel algorithm using shifted rank-1 lattice rules with O((log N)^d) good shifts and least-squares recovery achieves optimal convergence rates for L∞ and L2 approximation errors in weighted Korobov spaces.


<details>
  <summary>Details</summary>
Motivation: To address aliasing errors in lattice-based Fourier coefficient estimation and develop efficient function approximation methods in weighted Korobov spaces with optimal convergence rates.

Method: Uses shifted rank-1 lattice rules with O((log N)^d) good shifts and recovers Fourier coefficients via least-squares procedure to mitigate aliasing errors.

Result: Achieves optimal L∞-approximation error rate of O(N^{-α+1/2+ε}) in worst-case setting and optimal L2-approximation error rate of O(N^{-α+ε}) in randomized setting with random shifts.

Conclusion: The proposed algorithm provides optimal convergence rates for function approximation in weighted Korobov spaces, with theoretical results supported by numerical experiments.

Abstract: In this paper, we propose a novel algorithm for function approximation in a weighted Korobov space based on shifted rank-1 lattice rules. To mitigate aliasing errors inherent in lattice-based Fourier coefficient estimation, we employ $\mathcal{O}((\log N)^{d} )$ good shifts and recover each Fourier coefficient via a least-squares procedure. We show that the resulting approximation achieves the optimal convergence rate for the $L_{\infty}$-approximation error in the worst-case setting, namely $\mathcal{O}(N^{-α+1/2+\varepsilon})$ for arbitrarily small $\varepsilon>0$. Moreover, by incorporating random shifts, the algorithm attains the optimal rate for the $L_{2}$-approximation error in the randomized setting, which is $\mathcal{O}(N^{-α+\varepsilon})$. Numerical experiments are presented to support the theoretical results.

</details>


### [8] [Finite Volume Analysis of the Poisson Problem via a Reduced Discontinuous Galerkin Space](https://arxiv.org/abs/2511.09099)
*Wenbo Hu,Yinhua Xia*

Main category: math.NA

TL;DR: Proposes a high-order finite volume method for Poisson problem using reduced discontinuous Galerkin space as trial space and piecewise constant space as test space in Petrov-Galerkin framework.


<details>
  <summary>Details</summary>
Motivation: To bridge finite volume and discontinuous Galerkin methodologies, inheriting local conservation property of FVM while benefiting from DG approximation capabilities with fewer degrees of freedom.

Method: Petrov-Galerkin framework with RDG space as trial space and piecewise constant space as test space, enabling finite volume schemes with rigorous convergence theory.

Result: Established optimal-order convergence in DG energy norm and suboptimal-order convergence in L² norm. Numerical experiments confirm accuracy and efficiency in 1D and 2D with Dirichlet and periodic boundary conditions.

Conclusion: Successfully bridges finite volume and discontinuous Galerkin methods through RDG space, providing mathematically rigorous convergence theory for finite volume schemes.

Abstract: In this paper, we propose and analyze a high-order finite volume method for the Poisson problem based on the reduced discontinuous Galerkin (RDG) space. The main idea is to employ the RDG space as the trial space and the piecewise constant space as the test space, thereby formulating the scheme in a Petrov-Galerkin framework. This approach inherits the local conservation property of finite volume methods while benefiting from the approximation capabilities of discontinuous Galerkin spaces with significantly fewer degrees of freedom. We establish a rigorous error analysis of the proposed scheme: in particular, we prove optimal-order convergence in the DG energy norm and suboptimal-order convergence in \(L^2\) norm. The theoretical analysis is supported by a set of one- and two-dimensional numerical experiments with Dirichlet and periodic boundary conditions, which confirm both the accuracy and efficiency of the method. The significance of this work lies in bridging finite volume and discontinuous Galerkin methodologies through the RDG space, thus enabling finite volume schemes with a mathematically rigorous convergence theory.

</details>


### [9] [Optimal convergence rates of an adaptive finite element method for unbounded domains](https://arxiv.org/abs/2511.09145)
*Théophile Chaumont-Frelet,Gregor Gantner*

Main category: math.NA

TL;DR: The paper presents an adaptive finite element method for linear reaction-diffusion equations on unbounded domains, using a residual-based error estimator that accounts for both discretization error and truncation boundary effects.


<details>
  <summary>Details</summary>
Motivation: To solve PDEs on unbounded domains using finite elements, one must truncate the domain, which introduces approximation errors. Existing methods don't properly account for the combined effects of discretization error and truncation boundary error.

Method: Developed a residual-based error estimator that handles both discretization and truncation errors. Designed an adaptive algorithm that refines the mesh and pushes the truncation boundary outward automatically.

Result: Proved the error estimator is reliable and efficient under appropriate triangulation assumptions. Showed the adaptive algorithm converges and achieves optimal convergence rates in terms of degrees of freedom.

Conclusion: The proposed adaptive finite element method with combined error estimation successfully handles unbounded domain problems, with proven convergence and optimal rates, validated by numerical examples.

Abstract: We consider linear reaction-diffusion equations posed on unbounded domains, and discretized by adaptive Lagrange finite elements. To obtain finite-dimensional spaces, it is necessary to introduce a truncation boundary, whereby only a bounded computational subdomain is meshed, leading to an approximation of the solution by zero in the remainder of the domain. We propose a residual-based error estimator that accounts for both the standard discretization error as well as the effect of the truncation boundary. This estimator is shown to be reliable and efficient under appropriate assumptions on the triangulation. Based on this estimator, we devise an adaptive algorithm that automatically refines the mesh and pushes the truncation boundary towards infinity. We prove that this algorithm converges and even achieves optimal rates in terms of the number of degrees of freedom. We finally provide numerical examples illustrating our key theoretical findings.

</details>


### [10] [A surrogate-based approach to accelerate the design and build phases of reinforced concrete bridges](https://arxiv.org/abs/2511.09273)
*Mouhammed Achhab,Pierre Jehel,Fabrice Gatuingt*

Main category: math.NA

TL;DR: A surrogate model with active learning is developed to efficiently explore high-dimensional design spaces for reinforced concrete rail bridges, reducing computational burden from finite element simulations while classifying design scenarios as safe or failure.


<details>
  <summary>Details</summary>
Motivation: Probabilistic design of reinforced concrete rail bridges requires exploring high-dimensional design spaces with computationally expensive finite element simulations, creating significant computational challenges.

Method: Developed a Kriging surrogate model with active learning algorithm to map design space to bridge performance functions, using a multi-fiber finite element model in Cast3m to generate design of experiments.

Result: The surrogate model enables exploration of many design scenarios with minimal computational resources and classification into failure/safe scenarios, with performance comparison between Kriging with/without active learning and reliability assessment against PC-Kriging.

Conclusion: The active learning-based surrogate modeling approach provides an efficient framework for probabilistic design of reinforced concrete bridges by reducing computational burden while maintaining reliability in uncertainty propagation.

Abstract: Integrating uncertainties in the design process of reinforced concrete rail bridges, in a fully probabilistic framework, makes their design more complex and challenging. To propagate these uncertainties and convey their influence on the performance of the engineering system, a high-dimensional design space is supposed to be explored. A great challenge to be considered here lies in the computational burden as conducting such an exploration campaign requires substantial calls to computationally expensive finite element simulations. To address this challenge, a surrogate model mapping the design space to the reinforced concrete bridge performance functions is developed in the context of an active learning algorithm. The importance of this model lies in its ability to explore as many design scenarios as possible with minimal computational resources and classify the design scenarios into failure and safe scenarios. This work considers a 4-span reinforced concrete bridge deck. A multi-fiber finite element model of this beam is developed in Cast3m to generate the required design of experiments for the surrogate model. A performance comparison is undertaken to evaluate the Kriging surrogate model effectiveness with and without active learning while the reliability of Kriging predictions is also assessed in comparison to PC-Kriging.

</details>


### [11] [Dual Weighted Residual-driven adaptive mesh refinement to enhance biomechanical simulations](https://arxiv.org/abs/2511.09333)
*Roland Becker,Franz Chouly,Michel Duprez,Thomas Richter,Pierre-Yves Rohan,Thomas Wick*

Main category: math.NA

TL;DR: Application of Dual Weighted Residual error estimation for biomechanical simulations targeting user-defined quantities of interest.


<details>
  <summary>Details</summary>
Motivation: To enable practical application of a posteriori error estimates for user-defined quantities in biomechanical engineering simulations.

Method: Uses Dual Weighted Residual technique in a general setting covering complex geometries, non-linearities (hyperelasticity, fluid-structure interaction), and multi-goal oriented approaches.

Result: Numerical tests substantiate the developments.

Conclusion: The method provides an accessible way to apply sophisticated error estimation techniques in current biomechanical engineering practice.

Abstract: This chapter describes how a posteriori error estimates targeting a user-defined quantity of interest, using the Dual Weighted Residual (DWR) technique, can be easily applied for biomechanical simulations in current engineering practice. The proposed method considers a very general setting that encompasses complex geometries, model non-linearities (hyperelasticity, fluid-structure interaction) and multi-goal oriented techniques. The developments are substantiated with some numerical tests.

</details>


### [12] [A coupled finite element-virtual element method for thermomechanical analysis of electronic packaging structures](https://arxiv.org/abs/2511.09348)
*Yanpeng Gong,Sishuai Li,Fei Qin,Yue Mei,Xiaoying Zhuang,Timon Rabczuk*

Main category: math.NA

TL;DR: A FE-VE coupled method for thermomechanical analysis in electronic packaging that strategically uses FEM for regular geometries and VEM for complex shapes, maintaining interface compatibility through coincident nodes.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient computational framework for electronic packaging analysis that can handle complex geometries while maintaining computational efficiency and solution accuracy.

Method: Partitions computational domains strategically, using FEM for regular geometries and VEM for complex shapes, with interface compatibility maintained through coincident nodal correspondence.

Result: Validation shows reasonable agreement with reference solutions and acceptable convergence across varying mesh densities, effectively capturing thermal distributions and stress concentrations in multi-material systems.

Conclusion: Establishes a practical computational framework for electronic packaging analysis involving complex geometries, with source codes made publicly available.

Abstract: This study presents a finite element and virtual element (FE-VE) coupled method for thermomechanical analysis in electronic packaging structures. The approach partitions computational domains strategically, employing FEM for regular geometries to maximize computational efficiency and VEM for complex shapes to enhance geometric flexibility. Interface compatibility is maintained through coincident nodal correspondence, ensuring solution continuity across domain boundaries while reducing meshing complexity and computational overhead. Validation through electronic packaging applications demonstrates reasonable agreement with reference solutions and acceptable convergence characteristics across varying mesh densities. The method effectively captures thermal distributions and stress concentrations in multi-material systems, establishing a practical computational framework for electronic packaging analysis involving complex geometries. Source codes are available at https://github.com/yanpeng-gong/FeVeCoupled-ElectronicPackaging.

</details>


### [13] [A Semi-Convergent Stage-Wise Framework with Provable Global Convergence for Adaptive Total Variation Regularization](https://arxiv.org/abs/2511.09357)
*Liang Luo,Lei Zhang*

Main category: math.NA

TL;DR: A semi-convergent stage-wise framework combining first- and higher-order TV regularizers adaptively selects optimal iterates to achieve superior image restoration while avoiding staircase artifacts and oversmoothing.


<details>
  <summary>Details</summary>
Motivation: To balance noise suppression and structure preservation in image restoration, addressing limitations of first-order TV (staircase artifacts) and higher-order TV (oversmoothing fine details).

Method: Sequential integration of first- and higher-order TV regularizers via ADMM, with adaptive selection of locally optimal iterates based on semi-convergence behavior and propagation to next stages.

Result: Achieves superior quantitative and perceptual performance on denoising and deblurring benchmarks compared to conventional TV methods and learning-based approaches, with theoretical guarantees of bounded iterates and monotonic objective decrease.

Conclusion: The proposed framework effectively transfers local semi-convergence into global convergence, maintaining theoretical interpretability and algorithmic simplicity while outperforming existing methods.

Abstract: Image restoration requires a careful balance between noise suppression and structure preservation. While first-order total variation (TV) regularization effectively preserves edges, it often introduces staircase artifacts, whereas higher-order TV removes such artifacts but oversmooths fine details. To reconcile these competing effects, we propose a semi-convergent stage-wise framework that sequentially integrates first- and higher-order TV regularizers within an iterative restoration process implemented via ADMM. Each stage exhibits semi-convergence behavior, i.e., the iterates initially approach the ground truth before being degraded by over-regularization. By monitoring this evolution, the algorithm adaptively selects the locally optimal iterate (e.g., with the highest PSNR) and propagates it as the initial point for the next stage. This select-and-propagate mechanism effectively transfers local semi-convergence into a globally convergent iterative process. We establish theoretical guarantees showing that the sequence of stage-wise iterates is bounded, the objective values decrease monotonically. Extensive numerical experiments on denoising and deblurring benchmarks confirm that the proposed method achieves superior quantitative and perceptual performance compared with conventional first-, higher-order, hybrid TV methods, and learning based methods, while maintaining theoretical interpretability and algorithmic simplicity.

</details>


### [14] [Numerical analysis and efficient implementation of fast collocation methods for fractional Laplacian model on nonuniform grids](https://arxiv.org/abs/2511.09367)
*Meijie Kong,Hongfei Fu*

Main category: math.NA

TL;DR: Fast collocation method using Krylov subspace iterative solver for fractional Laplacian problems on nonuniform grids with SOE approximation and banded preconditioner.


<details>
  <summary>Details</summary>
Motivation: To develop efficient numerical methods for fractional Laplacian problems, which are challenging due to the singular integral formulation and computational complexity.

Method: Krylov subspace iterative solver with fast matrix-vector multiplication, SOE approximation, and banded preconditioner on general nonuniform grids.

Result: Method proved uniquely solvable for α∈(0,1) on nonuniform grids and α∈(0,2) on uniform grids. Rigorous error analysis shows convergence order depends on grading parameter.

Conclusion: Numerical experiments validate the predicted convergence and demonstrate efficiency of the proposed fast collocation schemes.

Abstract: We propose a fast collocation method based on Krylov subspace iterative solver on general nonuniform grids for the fractional Laplacian problem, in which the fractional operator is presented in a singular integral formulation. The method is proved to be uniquely solvable on general nonuniform grids for $α\in(0,1)$, provided that the sum-of-exponentials (SOE) approximation is sufficiently accurate. In addition, a modified scheme is developed and proved to be uniquely solvable on uniform grids for $α\in(0,2)$. Efficient implementation of the proposed fast collocation schemes based on fast matrix-vector multiplication is carefully discussed, in terms of computational complexity and memory requirement. To further improve computational efficiency, a banded preconditioner is incorporated into the Krylov subspace iterative solver. A rigorous maximum-norm error analysis for $α\in(0,1)$ is presented on specific graded grids, which shows that the convergence order depends on the grading parameter. Numerical experiments validate the predicted convergence and demonstrate the efficiency of the fast collocation schemes.

</details>


### [15] [Efficient Numerical Evaluation of Triple Integral Using the Euler's Method and Richardson's Extrapolation](https://arxiv.org/abs/2511.09408)
*Shubhangini Gupta,Prashant Sharma,Tamal Pramanick*

Main category: math.NA

TL;DR: Using Euler's method and Richardson's extrapolation to solve triple integrals by transforming them into third-order initial value problems, improving computational efficiency and accuracy.


<details>
  <summary>Details</summary>
Motivation: To address computational challenges in triple integration by converting it into an initial value problem format that's more manageable with numerical methods.

Method: Transform triple integral into third-order initial value problem, use Euler's method for baseline approximation, then apply Richardson's extrapolation to systematically reduce errors.

Result: Successfully demonstrated efficient solution of triple integrals with improved accuracy through the combined numerical approach.

Conclusion: The method effectively solves complex triple integrals efficiently and contributes to numerical computation and mathematical modeling by showing adaptability of numerical methods and importance of strategic error reduction.

Abstract: In this study, we employ Euler's method and Richardson's extrapolation to solve a triple integral, which is then transformed into a third-order initial value problem. Our objective is to resolve the computational challenges associated with triple integration by transforming it into an initial value problem. Euler's method is the fundamental numerical technique for approximating the solution, thereby establishing a baseline for accuracy. The precision of our computations is subsequently improved by employing Richardson's extrapolation to reduce errors systematically. This approach not only illustrates the adaptability of numerical methods in solving intricate mathematical problems, but it also emphasizes the significance of strategic error reduction techniques in enhancing computational outcomes. We present the efficacy of this method in solving triple integrals in an efficient manner through experimentation and analysis, thereby making a significant contribution to the fields of numerical computation and mathematical modeling.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [16] [Inverse problems for time-fractional Schrödinger equations](https://arxiv.org/abs/2511.08701)
*S. E. Chorfi,F. Et-tahri,L. Maniar,M. Yamamoto*

Main category: math.AP

TL;DR: The paper studies inverse problems for time-fractional Schrödinger equations with Caputo derivatives and proves refined uniqueness results from positive measure sets with weakened initial data regularity.


<details>
  <summary>Details</summary>
Motivation: To establish stronger uniqueness results for inverse problems in time-fractional Schrödinger equations by relaxing the regularity requirements on initial data.

Method: Using Caputo fractional derivatives of order α∈(0,1) and analyzing uniqueness from sets of positive Lebesgue measure.

Result: Proved refined uniqueness results that work with less regular initial data compared to previous approaches.

Conclusion: The study demonstrates that uniqueness for inverse problems in time-fractional Schrödinger equations can be achieved under weaker regularity conditions on initial data.

Abstract: We study some inverse problems for time-fractional Schrödinger equations involving the Caputo derivative of fractional order $α\in (0,1)$. We prove refined uniqueness results from sets of positive Lebesgue measure for various problems by weakening the regularity of initial data.

</details>


### [17] [Microlocal analysis of the non-relativistic limit of the Klein--Gordon equation: Asymptotics](https://arxiv.org/abs/2511.08724)
*Andrew Hassell,Qiuye Jia,Ethan Sussman,Andras Vasy*

Main category: math.AP

TL;DR: This paper develops a microlocal framework for analyzing the non-relativistic limit of relativistic wave equations with time-dependent coefficients, focusing on the Klein-Gordon equation. It identifies two phase space regimes and derives asymptotics from global estimates.


<details>
  <summary>Details</summary>
Motivation: To establish a robust framework for analyzing the non-relativistic limit of relativistic wave equations with time-dependent coefficients, addressing limitations in previous approaches by using spacetime phase-space analysis.

Method: Uses a microlocal framework based on spacetime phase-space analysis to examine two asymptotic regimes in phase space: one approximable by the free Klein-Gordon equation and a low-frequency regime approximable by the Schrödinger equation.

Result: The framework enables derivation of asymptotics from global estimates that are uniform as the speed of light goes to infinity, combining analyses from both phase space regimes.

Conclusion: The proposed spacetime phase-space analysis provides a robust approach for studying non-relativistic limits of relativistic wave equations, offering improvements over previous frameworks.

Abstract: This is the less technical half of a two-part work in which we introduce a robust microlocal framework for analyzing the non-relativistic limit of relativistic wave equations with time-dependent coefficients, focusing on the Klein--Gordon equation. Two asymptotic regimes in phase space are relevant to the non-relativistic limit: one corresponding to what physicists call ``natural'' units, in which the PDE is approximable by the free Klein--Gordon equation, and a low-frequency regime in which the equation is approximable by the usual Schrödinger equation. As shown in the companion paper, combining the analyses in the two regimes gives global estimates which are uniform as the speed of light goes to infinity. In this paper, we derive asymptotics from those estimates. Our framework differs from those in previous works in that ours is based on spacetime phase-space analysis.

</details>


### [18] [Ginzburg-Landau minimizers with high topological degrees in an annulus](https://arxiv.org/abs/2511.08744)
*Amandine Aftalion,Rémy Rodiac*

Main category: math.AP

TL;DR: Study of Ginzburg-Landau energy minimizers in annulus with Dirichlet boundary conditions, showing critical threshold for giant vortex formation versus boundary vortices.


<details>
  <summary>Details</summary>
Motivation: Motivated by recent experiments on fermionic rings to understand vortex behavior in superconducting systems.

Method: Construction of upper/lower bounds, extension to bigger annulus, minimization of mean-field energy using domain symmetry and inner variations.

Result: Found critical degree of order |ln ε| separating giant vortex ground states from mixed giant vortex + boundary vortex configurations.

Conclusion: GL parameter behavior determines vortex pattern: giant vortex below critical threshold, combined giant and boundary vortices above threshold.

Abstract: Motivated by recent experiments on fermionic rings, we study the asymptotic behaviour of minimizers of the Ginzburg-Landau (GL) energy in an annulus with a Dirichlet data which depends on the GL parameter on the outer boundary. We show that there is a critical degree of order $|\ln \varepsilon|$ under which the ground state displays a giant vortex and above which minimizers exhibit a combination of a giant vortex and vortices which tend to the outer boundary as the GL parameter tends to zero. Our analysis relies on the construction of suitable upper and lower bounds, on the extension to a slightly bigger annulus and on the minimization of the mean-field energy appearing in the lower bound. In order to be able to derive the minimum of this energy we use the symmetry of the domain and criticality with respect to inner variations.

</details>


### [19] [On the existence of non-negative weak solutions for $1D$ fourth order equations of gradient flow type](https://arxiv.org/abs/2511.08776)
*Stefanos Georgiadis,Stefano Spirito*

Main category: math.AP

TL;DR: Global existence of non-negative weak solutions for 1D fourth order evolution equations from Korteweg energy gradient flows, generalizing Quantum-Drift-Diffusion and Thin-Film equations.


<details>
  <summary>Details</summary>
Motivation: To establish existence theory for a family of fourth order evolution equations that generalize important models like Quantum-Drift-Diffusion and Thin-Film equations, without restrictive assumptions on the energy exponent.

Method: Analysis of gradient flows of Korteweg energy (L²-norm of first derivative of density power) using weak solution framework and energy methods.

Result: Proved global-in-time existence of non-negative weak solutions without requiring upper bounds on the exponent of density power in the energy functional.

Conclusion: The existence theory extends to a broad family of fourth order equations, removing previous limitations on the energy exponent parameter.

Abstract: In this paper, we consider a family of one-dimensional fourth order evolution equations arising as gradient flows of the Korteweg energy, i.e. the $L^2$-norm of the first derivative of some power of the density. This family of equations generalizes the Quantum-Drift-Diffusion equation and the Thin-Film equation. We prove the global-in-time existence of {\em non-negative} weak solutions without requiring any upper bound on the exponent of the power of the density in the energy.

</details>


### [20] [Doubling variables and uniqueness of probability solutions to degenerate stationary Kolmogorov equations](https://arxiv.org/abs/2511.08781)
*V. I. Bogachev,S. V. Shaposhnikov,D. V. Shatilovich*

Main category: math.AP

TL;DR: Uniqueness conditions for probability solutions to stationary Kolmogorov equations with degenerate diffusion matrices using the doubling variables method.


<details>
  <summary>Details</summary>
Motivation: To establish sufficient conditions ensuring uniqueness of probability solutions in stationary Kolmogorov equations with degenerate diffusion matrices.

Method: Employing the method of doubling variables from stochastic analysis directly to the Kolmogorov equation.

Result: Obtained sufficient conditions for uniqueness of probability solutions.

Conclusion: The doubling variables method provides effective sufficient conditions for uniqueness in degenerate diffusion cases.

Abstract: We obtain sufficient conditions for the uniqueness of a probability solution to the stationary Kolmogorov equation with a degenerate diffusion matrix. We employ the method of doubling variables known in stochastic analysis directly to the Kolmogorov equation.

</details>


### [21] [On a partial data inverse problem for the semi-linear wave equation](https://arxiv.org/abs/2511.08794)
*Boya Liu,Weinan Wang*

Main category: math.AP

TL;DR: A partial Dirichlet-to-Neumann map uniquely determines time-dependent nonlinearities of order ≥3 in semi-linear wave equations on Lorentzian manifolds, with arbitrarily small measurement sets and no geometric restrictions.


<details>
  <summary>Details</summary>
Motivation: To establish unique determination of nonlinearities in wave equations using minimal boundary measurements, overcoming limitations of previous approaches that required specific geometric conditions or larger measurement sets.

Method: Higher order linearization combined with Gaussian beam construction with boundary reflections, allowing analysis of nonlinear wave equations through linearized versions.

Result: The partial Dirichlet-to-Neumann map uniquely determines time-dependent nonlinearities of order three or higher, with no restrictions on measurement set size or geometry.

Conclusion: Nonlinear wave equation coefficients can be uniquely recovered from minimal boundary measurements using advanced linearization and geometric optics techniques.

Abstract: We show that a partial Dirichlet-to-Neumann map, where the measurement set is arbitrarily small, uniquely determines the time-dependent nonlinearity of order three or higher in a semi-linear wave equation up to natural obstructions on a Lorentzian manifold with boundary. In particular, we do not impose any geometric or size restrictions on the measurement set. The proof relies on the technique of higher order linearization combined with the construction of Gaussian beams with reflections on the boundary.

</details>


### [22] [An existence theory for solitary waves on a ferrofluid jet](https://arxiv.org/abs/2511.08799)
*Mark D. Groves,Dag Nilsson,Leon Schütz*

Main category: math.AP

TL;DR: Analysis of axisymmetric solitary waves on ferrofluid jets with azimuthal magnetic fields, reduced to KdV or NLS equations with explicit solitary-wave solutions.


<details>
  <summary>Details</summary>
Motivation: Study surface waves on ferrofluid jets with magnetic fields to understand nonlinear wave phenomena in magnetized fluids.

Method: Modified Zakharov-Craig-Sulem formulation, Dirichlet-Neumann operator analysis in Sobolev spaces, fixed-point arguments, Fourier analysis, and implicit-function theorem.

Result: Successfully reduced the problem to perturbed KdV (strong surface tension) or NLS (weak surface tension) equations with nondegenerate explicit solitary-wave solutions.

Conclusion: Rigorous existence theory established for axisymmetric solitary waves on ferrofluid jets under magnetic fields using functional analysis and perturbation methods.

Abstract: We discuss axisymmetric solitary waves on the surface of an otherwise cylindrical ferrofluid jet surrounding a stationary metal rod. The ferrofluid, which is governed by a general (nonlinear) magnetisation law, is subject to an azimuthal magnetic field generated by an electric current flowing along the rod. We treat the governing equations using a modification of the Zakharov-Craig-Sulem formulation for water waves, reducing the problem to a single nonlocal equation for the free-surface elevation variable $η$. The nonlocality in the equation takes the form of a Dirichlet-Neumann operator whose analyticity (in standard function spaces) is demonstrated by studying its defining boundary-value problem in newly introduced Sobolev spaces for radial functions.\ Using rudimentary fixed-point arguments and Fourier analysis we rigorously reduce the equation for $η$ to a perturbation of a Korteweg-de Vries equation (for strong surface tension) or a nonlinear Schrödinger equation (for weak surface tension), both of which have nondegenerate explicit solitary-wave solutions. The existence theory is completed using an appropriate version of the implicit-function theorem.

</details>


### [23] [Singularly Weighted X-ray Tensor Tomography](https://arxiv.org/abs/2511.08871)
*Jonathan Kay,François Monard*

Main category: math.AP

TL;DR: Study of singularly-weighted X-ray transforms on symmetric m-tensors with sharp range decomposition, kernel characterization, and efficient reconstruction procedures using generalized tensor field decompositions.


<details>
  <summary>Details</summary>
Motivation: To understand the properties of singularly-weighted X-ray transforms acting on symmetric tensors, particularly characterizing their range and kernel structure for reconstruction purposes.

Method: Using a distinguished Hilbert basis from earlier SVD studies for m=0, providing sharp range decomposition, characterizing infinite-dimensional kernels for m≥1, and proposing reconstruction representatives based on generalized tensor field decompositions in singularly weighted L^2-topologies.

Result: Obtained sharp range decomposition and characterization for all m, fully characterized the infinite-dimensional kernel for m≥1, and developed efficient reconstruction procedures modulo kernel.

Conclusion: The approach provides a comprehensive framework for analyzing singularly-weighted X-ray transforms on symmetric tensors, with complete kernel characterization and practical reconstruction methods using generalized tensor decompositions.

Abstract: If $d$ is a boundary defining function for the Euclidean unit disk and $I$ denotes the geodesic X-ray transform, for $γ\in (-1,1)$, we study the singularly-weighted X-ray transforms $I_m d^γ$ acting on symmetric $m$-tensors. For any $m$, we provide a sharp range decomposition and characterization in terms of a distinguished Hilbert basis of the data space, that comes from earlier studies of the Singular Value Decomposition for the case $m=0$. Since for $m\ge 1$, the transform considered has an infinite-dimensional kernel, we fully characterize this kernel, and propose a representative for an $m$-tensor to be reconstructed modulo kernel, along with efficient procedures to do so. This representative is based on a new generalization of the potential/conformal/transverse-tracefree decomposition of tensor fields in the context of singularly weighted $L^2$-topologies.

</details>


### [24] [Well-posedness for a diffuse interface model of non-Newtonian two-phase flows](https://arxiv.org/abs/2511.08876)
*Fang Li,Duan Xingyu,Guo Zhenhua*

Main category: math.AP

TL;DR: Global existence of weak solutions for Navier-Stokes-Cahn-Hilliard system with zero initial density and Landau potential in 3D bounded domains; local existence of strong solutions in periodic domains.


<details>
  <summary>Details</summary>
Motivation: Study the evolution of partially miscible, nonhomogeneous, incompressible viscous fluids of non-Newtonian type governed by Navier-Stokes-Cahn-Hilliard system with challenging conditions including zero initial density.

Method: Uses a suitable semi-Galerkin scheme and monotonicity method for proving solution existence.

Result: Proves global existence of weak solutions for 3D bounded domains and local existence of strong solutions for 3D periodic domains.

Conclusion: The Navier-Stokes-Cahn-Hilliard system admits solutions under specified conditions, with weak solutions existing globally and strong solutions existing locally in time.

Abstract: The evolution of two partially miscible, nonhomogeneous, incompressible viscous fluids of non-Newtonian type, can be governed by the Navier-Stokes-Cahn-Hilliard system. In the present work, we prove the global existence of weak solutions for the case of initial density containing zero and the concentration depending viscosity with free energy potential equal to the Landau potential in a bounded domain of three dimensions. Furthermore, we show that a strong solutions exist locally in time in the case of three dimensions periodic domain ${\mathbb T}^3.$ The proof relies on a suitable semi-Galerkin scheme and the monotonicity method.

</details>


### [25] [Singular solutions and bifurcation diagram of semilinear elliptic equations with general nonlinearity in two dimensions](https://arxiv.org/abs/2511.08961)
*Hiroaki Kikuchi,Kenta Kumagai*

Main category: math.AP

TL;DR: This paper studies semilinear elliptic equations with exponential-type nonlinearities in 2D, constructing singular solutions and analyzing bifurcation diagrams of regular solutions.


<details>
  <summary>Details</summary>
Motivation: To extend understanding of semilinear elliptic equations with exponential nonlinearities in two dimensions, relaxing existing conditions for singular solutions and refining bifurcation analysis beyond analytic nonlinearities.

Method: Uses a generalized Emden-type transformation to provide precise asymptotic forms of singular solutions and analyze bifurcation curves without assuming analyticity.

Result: Successfully relaxed conditions for singular solution existence and proved that bifurcation curves oscillate infinitely many times around some point for non-analytic nonlinearities.

Conclusion: The generalized Emden transformation enables more comprehensive analysis of semilinear elliptic equations with exponential nonlinearities in 2D, extending results beyond previous analyticity requirements.

Abstract: In this paper, we investigate semilinear elliptic equations with general exponential-type nonlinearities in two dimensions. For such nonlinearities, we establish two main results. The first is the construction of a singular solution. Recently, Fujishima, Ioku, Ruf, and Terraneo [10] proved the existence of singular solutions under certain assumptions for nonlinearities. We succeed in relaxing these conditions by providing the precise asymptotic form of a singular solution. Our second result concerns the bifurcation diagram of regular solutions. While the bifurcation structure has been extensively studied in three or higher dimensions, comparatively little was known in two dimensions until recently. In [18], the second author proved that the bifurcation curve possesses infinitely many turning points for supercritical analytic nonlinearities. In the present work, we refine this analysis by showing the bifurcation curve oscillates infinitely many times around some point, without assuming analyticity of the nonlinearities. The novelty of our approach lies in the introduction of a generalized Emden-type transformation.

</details>


### [26] [Propagation of chaos for the Landau equation via microcanonical binary collisions](https://arxiv.org/abs/2511.09035)
*Kai Du*

Main category: math.AP

TL;DR: First fully conservative, Landau-native binary-collision model that rigorously produces the Landau equation across all interaction ranges including Coulomb case through microcanonical binary-collision process.


<details>
  <summary>Details</summary>
Motivation: To develop a constructive realization of Kac's program for the spatially homogeneous Landau equation that is fully conservative and handles the full interaction range including singular Coulomb interactions.

Method: Microcanonical binary-collision (MBC) process: reversible pure-jump N-particle Markov process using small conservative rotations of relative velocities to realize grazing collisions, with Fisher-information dissipation mechanism and quantitative self-averaging principle.

Result: Proved propagation of chaos in joint mean-field and grazing-collision limit, identifying limit points with unique global Landau equation solutions. Rigorously derived Landau master equation as grazing-collision limit of MBC process.

Conclusion: Provides first fully conservative, Landau-native binary-collision model that rigorously yields the Landau equation over entire interaction range, establishing microscopic foundation for Landau dynamics.

Abstract: We develop a fully constructive, conservative, and collision-level realization of Kac's program for the spatially homogeneous Landau equation across the full interaction range, including the Coulomb case. Our model is the microcanonical binary-collision (MBC) process: a reversible pure-jump $N$-particle Markov process that is Landau-native, realizing the grazing-collision mechanism via small conservative rotations of relative velocities. The analysis hinges on two critical structural pillars: a Fisher-information dissipation mechanism that extends the Guillén--Silvestre paradigm (Acta Math. 234:315-375, 2025) to a genuinely conservative particle system, yielding robust control of singular configurations, and a quantitative self-averaging principle that enforces a coherent deterministic emergence of the Landau flow from the microscopic dynamics. We prove propagation of chaos in the joint mean-field and grazing-collision limit ($N\to\infty, h\to 0$), identifying any limit point with the unique global solution to the Landau equation. Furthermore, we rigorously derive the Landau master equation as the grazing-collision limit of the MBC process. To the best of our knowledge, this provides the first fully conservative, Landau-native binary-collision model rigorously shown to produce the Landau equation over the entire interaction range.

</details>


### [27] [A few techniques to achieve invisibility in waveguides](https://arxiv.org/abs/2511.09172)
*Lucas Chesnel*

Main category: math.AP

TL;DR: Methods for controlling wave scattering in waveguides to achieve invisibility through geometry manipulation, frequency selection, and material properties.


<details>
  <summary>Details</summary>
Motivation: To develop techniques for identifying and creating invisible defects in waveguides by controlling scattering coefficients through geometric, frequency, and material parameter manipulation.

Method: Uses continuation methods with shape derivatives, exploits complex resonances near real axis, constructs non self-adjoint operators, and applies asymptotic analysis and spectral theory.

Result: Development of mathematical approaches to achieve complete transmission of incident field energy and hide obstacles in waveguides.

Conclusion: The presented techniques provide effective tools for controlling wave scattering and achieving invisibility in waveguide structures through systematic mathematical approaches.

Abstract: The aim of this lecture is to consider a concrete problem, namely the identification of situations of invisibility in waveguides, to present techniques and tools that may be useful in various fields of applied mathematics. To be more specific, we will be interested in the propagation of acoustic waves in guides which are unbounded in one direction. In general, the diffraction of an incident field in such a structure in presence of an obstacle generates a reflection and a transmission characterized by some scattering coefficients. Our goal will be to play with the geometry, the frequency and/or the index material to control these scattering coefficients. We will explain how to:
  - develop a continuation method based on the use of shape derivatives to construct invisible defects;
  - exploit complex resonances located closed to the real axis to hid obstacles;
  - construct a non self-adjoint operator whose eigenvalues coincide with frequencies such that there are incident fields whose energy is completely transmitted.
  Our approaches will mainly rely on techniques of asymptotic analysis as well as spectral theory for self-adjoint and non self-adjoint operators. Most of the results will be illustrated by numerical experiments.

</details>


### [28] [On the Dirichlet problem for the degenerate $k$-Hessian equation](https://arxiv.org/abs/2511.09205)
*Yasheng Lyu*

Main category: math.AP

TL;DR: This paper establishes existence conditions for global $C^{1,1}$ solutions to the Dirichlet problem for $k$-Hessian equations with nonnegative right-hand side $f$, showing sharp conditions on the smoothness of $f$ and its powers.


<details>
  <summary>Details</summary>
Motivation: To determine the precise conditions on $f$ that guarantee the existence of global $C^{1,1}$ solutions to $k$-Hessian equations, addressing known counterexamples and establishing optimal regularity requirements.

Method: Mathematical analysis of $k$-Hessian equations, establishing existence theorems under various smoothness conditions on $f$ and its powers, with some cases requiring additional a priori assumptions like $\Delta u\geq 1$.

Result: Proved existence of global $C^{1,1}$ solutions under conditions including $f^{1/(k-1)}\in C^{1,1}$, $f^{3/(2k-2)}\in C^{2,1}$, and $f^{3/(2k)}\in C^{2,1}$, with sharpness demonstrated through counterexamples.

Conclusion: The paper provides sharp conditions on the smoothness of $f$ and its powers that guarantee existence of $C^{1,1}$ solutions to $k$-Hessian equations, with different exponents required depending on the specific equation and additional assumptions.

Abstract: This paper investigates the existence of a global $C^{1,1}$ solution to the Dirichlet problem for the $k$-Hessian equation with a nonnegative right-hand side $f$, focusing on the required conditions for $f$. A well-known counterexample demonstrates the sharpness of the condition $f^{1/(k-1)}\in C^{1,1}(\overline{Ω_{0}})$ with $f\geq0$ in a domain $Ω_{0}\SupsetΩ$. We establish the existence for all $2\leq k\leq n-1$ under the condition $f^{1/(k-1)}\in C^{1,1}(\overline{Ω_{0}})$ with $f\geq0$ in $Ω_{0}$, and under an a priori assumption that $Δu\geq1$. Surprisingly, higher smoothness of $f$ permits a better exponent to be achieved. The condition $f^{3/(2k-2)}\in C^{2,1}(\overline{Ω_{0}})$ with $f\geq0$ in $Ω_{0}$ is also sharp, as demonstrated by the same counterexample. For the Monge-Ampère equation (the case $k=n$), we establish the existence under the optimal condition $f^{3/(2n-2)}\in C^{2,1}(\overline{Ω_{0}})$ with $f\geq0$ in $Ω_{0}$. For any $5\leq k\leq n-1$, we prove the existence under the condition $f^{3/(2k-2)}\in C^{2,1}(\overline{Ω_{0}})$ with $f\geq0$ in $Ω_{0}$, and under the a priori assumption $Δu\geq1$. Moreover, we obtain the existence for all $2\leq k\leq n-1$ under the condition $f^{3/(2k)}\in C^{2,1}(\overline{Ω_{0}})$ with $f\geq0$ in $Ω_{0}$.

</details>


### [29] [On Fractional Anisotropic Musielak-Sobolev Spaces with Applications to Nonlocal Eigenvalue Problems](https://arxiv.org/abs/2511.09256)
*Mohammed Srati*

Main category: math.AP

TL;DR: Introduction of Fractional Anisotropic Musielak-Sobolev Spaces that generalize existing fractional anisotropic spaces, with applications to nonlocal anisotropic eigenvalue problems.


<details>
  <summary>Details</summary>
Motivation: To handle anisotropic and heterogeneous behaviors in nonlocal and nonlinear models that naturally arise in various applications.

Method: Develop fundamental properties and embedding results for the new spaces, then apply critical point theory and modular analysis to study nonlocal anisotropic eigenvalue problems.

Result: Established a solid variational framework and proved existence of eigenvalues for nonlocal anisotropic problems with variable growth and direction-dependent fractional operators.

Conclusion: The proposed spaces extend and unify several existing models in nonlocal PDE theory, providing a comprehensive framework for anisotropic and heterogeneous nonlocal problems.

Abstract: In this paper, we introduce and study a new class of fractional modular function spaces, called \emph{Fractional Anisotropic Musielak--Sobolev Spaces}, which generalize both the fractional Anisotropic Orlicz--Sobolev spaces and the Anisotropic fractional Sobolev spaces with variable exponent. These spaces are designed to handle anisotropic and heterogeneous behaviors that naturally arise in nonlocal and nonlinear models. We develop their fundamental properties and embedding results, establishing a solid variational framework. As an application, we investigate a class of nonlocal anisotropic eigenvalue problems involving variable growth and direction-dependent fractional integro-differential operators. We prove the existence of eigenvalues by means of critical point theory and modular analysis. Our results extend and unify several existing models in the theory of nonlocal partial differential equations.

</details>


### [30] [Nonlinear Dirac equations on noncompact quantum graphs with potentials: Multiplicity and Concentration](https://arxiv.org/abs/2511.09285)
*Guangze Gu,Ziwei Li,Michael Ruzhansky,Zhipeng Yang*

Main category: math.AP

TL;DR: The paper proves existence and multiplicity of solutions to nonlinear Dirac equations on noncompact quantum graphs, showing that the number of solutions is at least the number of global minima of the potential V when the semiclassical parameter ε is small.


<details>
  <summary>Details</summary>
Motivation: To study nonlinear Dirac equations on noncompact quantum graphs and understand how solutions concentrate near potential minima in the semiclassical limit.

Method: Analysis of nonlinear Dirac equations using semiclassical methods, focusing on the behavior as the semiclassical parameter ε approaches zero.

Result: When ε is sufficiently small, the number of solutions is at least the number of global minima of V, and these solutions concentrate near the global minima as ε→0.

Conclusion: The paper establishes a connection between the number of solutions and the topology of the potential landscape, demonstrating semiclassical concentration behavior for nonlinear Dirac equations on quantum graphs.

Abstract: In this paper, we study the existence and multiplicity of solutions to the following class of nonlinear Dirac equations (NLDE) on noncompact quantum graphs:
  \[
  -i\,\varepsilon c\,σ_1\,\partial_x u + m c^2 σ_3 u + V(x)\,u = f(|u|)\,u, \quad x\in \mathcal{G}, \tag{P}
  \]
  where \(V:\mathcal{G}\to\mathbb{R}\) and \(f:\mathbb{R}\to\mathbb{R}\) are continuous, \(\varepsilon>0\) is a semiclassical parameter, \(m>0\) denotes the mass, and \(c>0\) the speed of light. Here \(σ_1,σ_3\) are Pauli matrices, and \(\mathcal{G}\) is a noncompact quantum graph. We prove that when \(\varepsilon\) is sufficiently small, the number of solutions to \((P)\) is at least the number of global minima of \(V\).
  Moreover, these solutions exhibit semiclassical concentration: as \(\varepsilon\to0\), their concentration points approach the set of global minima of \(V\).

</details>


### [31] [On the Singular Limit in Hibler's Sea Ice Model](https://arxiv.org/abs/2511.09327)
*Robert Denk,Franz Gmeineder,Matthias Hieber*

Main category: math.AP

TL;DR: Existence of energy-driven solutions for Hibler's sea ice model, covering the singular limit and true unregularized Hibler stress through a novel energy-based solution concept.


<details>
  <summary>Details</summary>
Motivation: To address the singular limit in Hibler's sea ice model and cover the true unregularized Hibler stress, which previous results couldn't handle due to regularization requirements.

Method: Introduce an energy-based notion of solution that captures plasticity effects, requiring relaxations of Hibler energies and developing a novel reduction scheme for nonlinear trace expressions to handle boundary terms.

Result: Established existence of energy-driven solutions for the momentum balance equation in Hibler's model, including a bulk approximation result for boundary terms in evolutionary relaxed Hibler energies.

Conclusion: The findings provide a broader concept of solutions applicable to non-constant mass cases, with the novel reduction scheme having independent interest for handling nonlinear trace expressions.

Abstract: We establish the existence of energy-driven solutions to the momentum balance equation in Hibler's sea ice model. As a main novelty and different from previous results, we deal with the singular limit and therefore cover the true unregularized Hibler stress. To this end, we introduce an energy-based notion of solution that is able to capture plasticity effects of sea ice. This requires certain relaxations of the Hibler energies and, by the different function space set-up, comes with novel challenges. In particular, we establish a bulk approximation result of the boundary terms in the evolutionary relaxed Hibler energies. This is achieved by developing a novel reduction scheme for nonlinear trace expressions which should be of independent interest. Finally, based on our main results, we classify our findings within a broader concept of solutions that is applicable to the non-constant mass case too.

</details>


### [32] [Singular, finite-time $L^2$ attractors for odd, smooth solutions of Burgers equation on the torus](https://arxiv.org/abs/2511.09528)
*Evan Miller*

Main category: math.AP

TL;DR: Positive multiples of a singular function F are finite-time global attractors in L^2 for generic odd smooth solutions of 1D inviscid Burgers equation, with applications to proving finite-time blowup for fractal Burgers equation.


<details>
  <summary>Details</summary>
Motivation: To establish finite-time global attractors for the inviscid Burgers equation and provide alternative proof of finite-time blowup for fractal Burgers equation in supercritical range.

Method: Using Lyapunov functional analysis based on inner product of solution with global attractor F, and extending to broader class of odd strictly increasing functions.

Result: Positive multiples of function F serve as finite-time global attractors in L^2 space for generic odd smooth solutions of inviscid Burgers equation.

Conclusion: The method provides an alternative approach to prove finite-time blowup for fractal Burgers equation and extends to a broader class of odd functions with specific monotonicity properties.

Abstract: In this paper, we show that the positive multiples of a particular function $F$ -- which is singular with a jump discontinuity at the origin -- are finite-time global attractors in $L^2$ for generic odd, smooth solutions of the one dimensional inviscid Burgers equation. Furthermore, the identity that leads to this result provides to an alternative proof of finite-time blowup for the fractal Burgers equation in the supercritical range $0<α<\frac{1}{2}$. This proof is based on lower bounds on a Lyapunov functional given by the inner product of the solution with the global attractor $F$. We will also show that this property holds for a broader class of odd functions that are strictly increasing on $(0,π)$.

</details>


### [33] [Instantaneous Type~I blow-up and non-uniqueness of smooth solutions of the Navier--Stokes equations](https://arxiv.org/abs/2511.09556)
*Alexey Cheskidov,Mimi Dai,Stan Palasek*

Main category: math.AP

TL;DR: Construction of smooth Navier-Stokes solutions with Type I blow-up at finite time, violating uniqueness and demonstrating inverse energy cascade from infinite to low frequencies.


<details>
  <summary>Details</summary>
Motivation: To demonstrate non-uniqueness in the Navier-Stokes Cauchy problem and construct the first complete inverse energy cascade in classical flows.

Method: Construct smooth divergence-free initial data that produces solutions exhibiting Type I blow-up at finite time while remaining smooth elsewhere, using energy injection from infinite wavenumber.

Result: Successfully constructed infinite family of spatially smooth solutions with same initial data, violating uniqueness; achieved first complete inverse energy cascade in Navier-Stokes flows.

Conclusion: Navier-Stokes equations exhibit non-uniqueness for smooth initial data, with solutions showing Type I blow-up and inverse energy cascade, valid in all dimensions d≥2.

Abstract: For any smooth, divergence-free initial data, we construct a solution of the Navier--Stokes equations that exhibits Type~I blow-up of the $L^\infty$ norm at time $T_*>0$, while remaining smooth in space and time on $\mathbb T^d\times([0,T]\setminus\{T_*\})$. An instantaneous injection of energy from infinite wavenumber initiates a bifurcation from the classical solution, producing an infinite family of spatially smooth solutions with the same data and thereby violating uniqueness of the Cauchy problem. A key ingredient is the first known construction of a complete inverse energy cascade realized by a classical Navier--Stokes flow, which transfers energy from infinitely high to low frequencies. The result holds in all dimensions $d\geq2$.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [34] [Topological end state and enhanced thermoelectric performance of a supramolecular device](https://arxiv.org/abs/2511.08943)
*Wenlai Mu,Nisar Muhammad,Huaihong Guo,Zsolt Gulacsi,Teng Yang,Zhidong Zhang*

Main category: physics.comp-ph

TL;DR: Supramolecular SSH chain devices with topological end states achieve high thermoelectric performance (ZT > 2) and exhibit switch effects under perturbations.


<details>
  <summary>Details</summary>
Motivation: To investigate supramolecular devices with topological end states for thermoelectric applications, which are rarely studied but promising.

Method: Designed supramolecular SSH chain devices and calculated thermoelectric properties using non-equilibrium Green's function method under various optimization conditions and perturbations.

Result: Topological end states produce large power factor with ZT > 2 across broad chemical potential range. System shows prominent switch effect under perturbations (end state shift, structural change, disorder).

Conclusion: Supramolecular SSH chain devices are highly promising for thermoelectric applications due to excellent performance and switch effects.

Abstract: Supramolecular device (SMD) with topological end states and a noncovalent junction is rarely investigated but deemed promising for thermoelectric (TE) applications. We designed a new kind of SMD based on the Su-Schrieffer-Heeger (SSH) chains, and calculated TE properties of it using the non-equilibrium Green's function (NEGF) method. By scaling TE performance under different optimization conditions, we found the best scenario. Our result shows that the existing topological end states indeed give rise to a large value of power factor, rendering a dimensionless figure-of-merit ZT above 2 in a broad range of chemical potential (doping). Moreover, by imposing the system to various perturbations including end state shift, structural change and disorder, we found that the SMD system possesses a prominent switch effect, further optimizing its performance for TE applications.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [35] [Enabling Integrated AI Control on DIII-D: A Control System Design with State-of-the-art Experiments](https://arxiv.org/abs/2511.08818)
*Andrew Rothstein,Hiro Joseph Farre-Kaga,Jalal Butt,Ricardo Shousha,Keith Erickson,Takuma Wakatsuki,Azarakhsh Jalalvand,Peter Steiner,Sangkyeun Kim,Egemen Kolemen*

Main category: physics.plasm-ph

TL;DR: PACMAN is a general ML algorithm for prediction and control in DIII-D tokamak, enabling advanced plasma control experiments from diagnostics to actuation.


<details>
  <summary>Details</summary>
Motivation: Traditional controllers fail in achieving certain plasma regimes like tearing mode free, ELM-free scenarios and stable advanced tokamak conditions, while ML-based approaches show promise.

Method: End-to-end architecture deployed on DIII-D that facilitates ML control experiments from diagnostic processing to final actuation commands, with detailed algorithm design.

Result: Successful implementation of multiple ML controllers including reinforcement learning for advanced non-inductive plasmas, ELM predictor, Alfvén Eigenmode controller, plasma profile controller, and tearing mode predictor-controller.

Conclusion: Provides guiding principles for real-time machine learning controller design and implementation in fusion research.

Abstract: We present the design and application of a general algorithm for Prediction And Control using MAchiNe learning (PACMAN) in DIII-D. Machine learing (ML)-based predictors and controllers have shown great promise in achieving regimes in which traditional controllers fail, such as tearing mode free scenarios, ELM-free scenarios and stable advanced tokamak conditions. The architecture presented here was deployed on DIII-D to facilitate the end-to-end implementation of advanced control experiments, from diagnostic processing to final actuation commands. This paper describes the detailed design of the algorithm and explains the motivation behind each design point. We also describe several successful ML control experiments in DIII-D using this algorithm, including a reinforcement learning controller targeting advanced non-inductive plasmas, a wide-pedestal quiescent H-mode ELM predictor, an Alfvén Eigenmode controller, a Model Predictive Control plasma profile controller and a state-machine Tearing Mode predictor-controller. There is also discussion on guiding principles for real-time machine learning controller design and implementation.

</details>


### [36] [Molecular Dynamics Simulations of Temperature Relaxation in Non-Neutral Plasmas Relevant to Antimatter Experiments](https://arxiv.org/abs/2511.08849)
*James C. Welch,Louis Jose,Timothy D. Tharp,Scott D. Baalrud*

Main category: physics.plasm-ph

TL;DR: Molecular dynamics simulations validate theoretical model predicting multistep temperature relaxation in strongly magnetized two-component non-neutral plasmas used for antimatter cooling.


<details>
  <summary>Details</summary>
Motivation: To test a theoretical model describing temperature evolution in strongly magnetized non-neutral plasmas used for cooling antimatter particles in Penning-Malmberg traps.

Method: Used molecular dynamics simulations with two analysis methods: imposed temperature difference and Green-Kubo relation to study temperature relaxation.

Result: Simulation results support theoretical predictions of multistep relaxation where parallel temperatures relax faster than perpendicular temperatures.

Conclusion: This work extends previous studies of temperature anisotropy relaxation to two-component systems relevant to trapped antimatter experiments.

Abstract: An important process for antimatter experiments is the cooling of particles in a Penning-Malmberg trap to experimentally useful temperatures. A non-neutral plasma of one species (e.g. antiprotons) can be collisionally cooled on another colder species (e.g. electrons). Modeling temperature relaxation in these devices is challenging from a plasma physics perspective because the particles are strongly magnetized (the gyrofrequency exceeds the plasma frequency). Recently, a theoretical model was proposed to describe the temperature evolution in these conditions, predicting a multistep relaxation process where temperatures parallel to the magnetic field relax much faster than perpendicular to it. Here, this model is tested using molecular dynamics simulations. Two analysis methods are applied: one based on an imposed temperature difference, and the other based on a Green-Kubo relation. The results of the simulations support the theoretical predictions. This work extends previous studies of temperature anisotropy relaxation in one-component non-neutral plasmas to the two-component systems relevant to trapped antimatter experiments.

</details>


### [37] [A Fully Spin and Polarization Resolved Strong Field QED Algorithm for Particle-in-Cell Codes](https://arxiv.org/abs/2511.08929)
*Q. Qian,D. Seipt,M. Vranic,T. Grismayer,C. P. Ridgers,A. G. R. Thomas*

Main category: physics.plasm-ph

TL;DR: Development of spin- and polarization-resolved QED-PIC extension in OSIRIS framework for ultra-intense laser-plasma interactions


<details>
  <summary>Details</summary>
Motivation: Modern ultra-intense lasers create extreme conditions approaching QED critical field, requiring ab-initio modeling that captures electromagnetic, relativistic particle, and quantum emission processes in plasma

Method: Extension to standard QED-PIC in OSIRIS framework to include spin- and polarization-resolved QED processes

Result: Code development, validation, and verification completed for spin- and polarization-dependent QED phenomena

Conclusion: This code can advance understanding of spin- and polarization-dependent QED phenomena in ultra-intense laser-plasma interactions

Abstract: Modern ultra-intense laser facilities can generate electromagnetic fields strong enough to accelerate particles to near-light speeds over micron-scale distances and also approach the QED critical field, resulting in highly nonlinear and relativistic quantum phenomena. For such conditions, ab-initio modeling techniques are required that capture the electromagnetic, relativistic particle, and quantum emission processes in the plasma. One such technique is particle-in-cell (PIC) simulation. In this paper, we describe the underlying theory for and development, validation, and verification of an extension to standard QED-PIC in the OSIRIS framework to include spin- and polarization-resolved QED processes central to next-generation laser-plasma experiments. This code can advance the current understanding of spin- and polarization-dependent QED phenomena in ultra-intense laser-plasma interactions.

</details>


### [38] [PIC analysis of spatiotemporal THz emission from radial and longitudinal wakefields via copropagating chirped lasers in magnetized rippled plasma](https://arxiv.org/abs/2511.09075)
*A. A. Molavi Choobini,F. M. Aghamir*

Main category: physics.plasm-ph

TL;DR: Study examines wake-field excitation by chirped laser pulses in magnetized plasma for THz radiation generation using FBPIC simulations.


<details>
  <summary>Details</summary>
Motivation: To understand spatiotemporal evolution of wake structures and their role in THz radiation generation from laser-plasma interactions.

Method: Fourier-Bessel Particle-In-Cell (FBPIC) simulation framework optimized for cylindrical geometries to model relativistic plasma electron dynamics under laser ponderomotive forces and external magnetic field.

Result: Beat frequency modulates ponderomotive force, driving nonlinear wake-field structures; THz peaks identified with enhanced amplitudes from resonant coupling; magnetic field confines electron motion improving energy gain and radiation patterns.

Conclusion: Tailored laser and plasma configurations can optimize energy transfer for more efficient wake-field usage and THz generation.

Abstract: The excitation of radial and longitudinal wake-fields by two co-propagating chirped laser pulses in a rippled, magnetized plasma has been examined. This study aimed to clarify the spatiotemporal evolution of wake structures and assess their role in the generation of THz radiation. A Fourier-Bessel Particle-In-Cell (FBPIC) simulation framework, optimized for cylindrical geometries, has been employed to model the relativistic dynamics of plasma electrons under the combined influence of laser-induced ponderomotive forces and an external magnetic field. It has been shown that the beat frequency between the pulses modulates the ponderomotive force, driving nonlinear wake-field structures sustained by electron oscillations. Simulations performed with high spatial resolution have revealed that wake-field amplitude and coherence are strongly influenced by laser chirp, pulse duration, and plasma density. Distinct THz peaks have been identified in the Fourier-transformed spectra, with their amplitudes enhanced by resonant coupling between wake-field harmonics and the laser frequency modulation. Moreover, electron motion has been confined by the magnetic field, leading to improved energy gain and shaping of angular radiation patterns. These findings suggest that tailored laser and plasma configurations can be used to optimize energy transfer mechanisms, paving the way for more efficient wake-field usage and THz generation.

</details>


### [39] [3D PIC simulation and theoretical modeling of RF Laser pulse in magnetized plasma for the generation of multidimensional relativistic Wakefields](https://arxiv.org/abs/2511.09079)
*A. A. Molavi Choobini,M. Shahmansouri*

Main category: physics.plasm-ph

TL;DR: Study shows RF excitation and magnetic fields systematically amplify and reshape plasma wakefields driven by relativistic electron beams, enhancing wakefield symmetry, depth, and acceleration zones.


<details>
  <summary>Details</summary>
Motivation: To investigate how transverse RF excitation combined with magnetic fields modulates plasma wakefields in dense magnetized plasma driven by relativistic electron beams.

Method: Extended self-consistent theoretical framework with RF vector potential, Maxwell's equations, and relativistic electron motion through full 3D electromagnetic particle-in-cell simulations.

Result: RF amplitude progressively modulates radial excursions and transverse forces, enhancing wakefield symmetry and depth. Current density evolves from weak perturbations into sharply structured ion channels. Parameters like pulse shape, polarization angle, and frequency ratio produce distinct oscillatory features and confinement regimes.

Conclusion: RF excitation and magnetic fields reinforce ponderomotive force, resulting in controlled narrowing of electron sheaths, sharper scalar potential gradients, and extended acceleration zones across all conditions.

Abstract: The present study, investigates the modulation of plasma wakefields in dense magnetized plasma driven by relativistic electron beams under transverse RF excitation. A self consistent theoretical framework, comprising the RF vector potential, Maxwells equations, and relativistic electron motion, is extended through full 3D electromagnetic particle in cell simulations. The results reveal systematic amplification and reshaping of wakefields under the combined action of external magnetic fields and RF drivers. Variations in the cyclotron to plasma frequency ratio dictate the radial positioning and gyromotion of plasma electrons, sharpening transverse confinement and stabilizing blowout structures. The RF amplitude introduces progressive modulation of radial excursions and transverse forces, enhancing wakefield symmetry and depth. Current density distributions confirm the nonlinear scaling with RF strength, evolving from weak perturbations into sharply structured ion channels. Scalar potentials and longitudinal fields exhibit pronounced sensitivity to pulse shape, polarization angle, frequency ratio, and driver density, each parameter producing distinct oscillatory features and confinement regimes. Plasma density sets the field strength and radial localization, while the modulation parameter governs the emergence of fine scale oscillatory bands, producing smooth to multiband transitions in longitudinal electric fields. Across all conditions, simulations confirm the reinforcement of ponderomotive force, resulting in controlled narrowing of electron sheaths, sharper scalar potential gradients, and extended acceleration zones.

</details>


### [40] [Hydrodynamic PIC analysis of THz generation by two color laser in various plasma gases](https://arxiv.org/abs/2511.09083)
*A. A. Molavi Choobini,S. S. Ghaffari-Oskooei*

Main category: physics.plasm-ph

TL;DR: Theoretical and PIC simulation study of THz emission from two-color femtosecond laser fields in gaseous plasmas, showing how field asymmetry generates directional currents that radiate THz waves.


<details>
  <summary>Details</summary>
Motivation: To understand and optimize THz emission from laser-plasma interactions by investigating the fundamental mechanisms behind nonlinear photocurrent generation in asymmetric two-color laser fields.

Method: Combined theoretical modeling in cylindrical coordinates with PIC numerical simulations, using hydrodynamic description of plasma electrons coupled with Maxwell's equations to derive nonlinear photocurrent dynamics.

Result: Field asymmetry from fundamental and second-harmonic superposition breaks inversion symmetry, creating net directional current that radiates THz waves. Gas composition, ionization fraction, and intensity ratio strongly affect THz spectral characteristics and efficiency.

Conclusion: Two-color femtosecond laser fields in gaseous plasmas effectively generate THz radiation through asymmetric field-induced photocurrents, with key parameters identified for optimization.

Abstract: In the present study, a theoretical and PIC numerical investigation of THz emission driven by two color femtosecond laser fields in gaseous plasmas is conducted. The model is formulated in cylindrical coordinates to capture the inherent radial symmetry of laser plasma interactions. Starting from a hydrodynamic description of plasma electrons coupled with Maxwells equations, the nonlinear photocurrent dynamics that underpin the emission process is derived. The results reveal that the asymmetry induced by the superposition of the fundamental and second-harmonic fields plays a central role in breaking inversion symmetry, thereby generating a net directional current that radiates in the THz regime. Systematic analysis demonstrates that gas composition, ionization fraction, and the intensity ratio of the two fields strongly influence both the spectral characteristics and efficiency of THz radiation.

</details>


### [41] [Gyrokinetic Simulations of a Low Recycling Scrape-off Layer without a Lithium Target](https://arxiv.org/abs/2511.09437)
*Akash Shukla,Jonathan Roeltgen,Michael Kotschenreuther,David R. Hatch,Manaure Francisquez,James Juno,Tess N. Bernard,Ammar Hakim,Gregory W. Hammett,Swadesh M. Mahajan*

Main category: physics.plasm-ph

TL;DR: Kinetic simulations show that low-recycling regimes in STEP spherical tokamaks can be achieved using low-recycling wall materials, with kinetic effects improving impurity confinement and heat flux broadening compared to fluid models.


<details>
  <summary>Details</summary>
Motivation: Low-recycling regimes offer high edge temperature and low density for better core confinement, but face severe exhaust problems and require kinetic modeling due to long mean free path physics in the SOL.

Method: Performed both kinetic and fluid simulations of the Scrape-Off Layer (SOL) plasma in STEP spherical tokamak geometry to compare physics capture and explore low-recycling regime feasibility.

Result: Kinetic simulations show high SOL temperature and low density can be achieved with low-recycling wall materials, better impurity confinement to divertor, and greater heat flux width broadening due to drifts compared to fluid simulations.

Conclusion: Kinetic effects can address low-recycling SOL issues - improving impurity confinement prevents core contamination and broader heat flux reduces peak heat loads, demonstrating feasibility of low-recycling scenarios.

Abstract: Low-recycling regimes are appealing because they entail a high edge temperature and low edge density which are good for core confinement. However, due to considerably enhanced heat flux, the exhaust problems become severe. In addition, in the low-recycling regime, the conventional fluid simulations may not capture the physics of the Scrape-Off Layer (SOL) plasma that lies in the long mean free path regime; kinetic calculations become necessary. In this paper, by performing both Kinetic and fluid simulations, we explore the feasibility of a low-recycling regime in the magnetic geometry of the Spherical Tokamak for Energy Production (STEP); kinetic effects come out to be crucial determinants of the SOL dynamics. The simulation results indicate that a high SOL temperature and low SOL density could be achieved even when the divertor target is not made of a low recycling material. This can be done by using a low recycling material as a wall material. This is an important step towards demonstrating the feasibility of a low-recycling scenario. Lithium, a commonly used low recycling material, tends to evaporate at high heat fluxes which counteracts the desired high temperature, low density regime, and materials that can handle high heat fluxes are generally high recycling. Comparisons of gyrokinetic and fluid simulation results indicate that one can take advantage of kinetic effects to address some of the issues associated with a low-recycling SOL. Specifically, kinetic simulations show better confinement of impurities to the divertor region and greater broadening of the heat flux width due to drifts when compared with fluid simulations. Impurity confinement would help prevent core contamination from sputtering, and a broader heat flux width would help reduce the peak heat load at the target in the absence of detachment.

</details>


### [42] [Restoring momentum conservation to magnetized quasilinear diffusion](https://arxiv.org/abs/2511.09532)
*I. E. Ochs*

Main category: physics.plasm-ph

TL;DR: The paper fixes a defect in the Kennel-Engelmann diffusion tensor by extending it from 2D to 4D to properly conserve four-momentum, which corrects predictions for wave-induced cross-field particle transport.


<details>
  <summary>Details</summary>
Motivation: The Kennel-Engelmann tensor used for modeling wave-particle interactions in plasma heating doesn't fully respect four-momentum conservation, leading to incorrect predictions of cross-field particle transport.

Method: Extend the Kennel-Engelmann diffusion tensor from two to four dimensions to match the form required by four-momentum conservation, then bounce-average the extended tensor.

Result: The extended tensor recovers the form of diffusion paths required by action-angle Hamiltonian theory and can be easily implemented in Fokker-Planck codes.

Conclusion: The defect in the Kennel-Engelmann tensor can be fixed through a mild modification that extends it to four dimensions, enabling proper conservation of four-momentum and accurate modeling of wave-induced particle transport.

Abstract: Wave interactions with magnetized particles underly many plasma heating and current drive technologies. Typically, these interactions are modeled by bounce-averaging the quasilinear Kennel-Engelmann diffusion tensor over the particle orbit. However, as an object derived in a two-dimensional space, the Kennel-Engelmann tensor does not fully respect the conservation of four-momentum required by the action conservation theorem, since it neglects the absorption of perpendicular momentum. This defect leads to incorrect predictions for the wave-induced cross-field particle transport. Here, we show how this defect can easily be fixed, by extending the tensor from two to four dimensions and matching the form required by four-momentum conservation. The resulting extended tensor, when bounce-averaged, recovers the form of the diffusion paths required by action-angle Hamiltonian theory. Importantly, the extended tensor should be easily implementable in Fokker-Planck codes through a mild modification of the existing Kennel-Engelmann tensor.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [43] [A 5D concept for space-time optimal control problems with application to simplified Carreau flow](https://arxiv.org/abs/2511.09086)
*S. Beuchler,B. Endtmayer,U. Langer,A. Schafelner,T. Wick*

Main category: math.OC

TL;DR: 5D framework for optimizing non-Newtonian fluid flows using Carreau model with space-time finite elements instead of traditional time-stepping.


<details>
  <summary>Details</summary>
Motivation: To develop a more efficient approach for optimizing non-Newtonian fluid flows by avoiding traditional time-stepping techniques and creating a unified 5D framework.

Method: Approximate KKT system solution using fully space-time finite element methods in 3D space, 1D time, and 1D optimization loop dimensions.

Result: Development of a 5D overall framework combining spatial, temporal, and optimization dimensions into a unified computational approach.

Conclusion: The proposed 5D space-time-optimization framework provides an alternative to traditional methods for non-Newtonian flow optimization problems.

Abstract: This work presents a 5D concept to optimizing non-Newtonian fluid flows through a simplified Carreau flow model. We solve the optimization problem by approximating the solution of the KKT System with fully space-time finite element methods instead of the more traditional time-stepping technique combined with spatial finite element discretization. Therein, the finite element method is formulated in 3D in space, 1D in time, and 1D in the optimization loop, yielding a 5D overall framework.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [44] [Deep Learning Driven Enhancement of Optical Vortex Line Robustness in Atmospheric Turbulence](https://arxiv.org/abs/2511.08836)
*Dmitrii Tsvetkov,Danilo Gomes Pires,Natalia Litchinitser*

Main category: physics.optics

TL;DR: Shape-based tracing of optical vortex singularities outperforms topological and spectral methods in turbulent conditions, achieving over 90% classification accuracy using deep learning with novel Flower Beams.


<details>
  <summary>Details</summary>
Motivation: Optical vortex structures are crucial for optical communication and quantum technologies, but their topological invariants deteriorate significantly in turbulent environments, necessitating more robust tracing methods.

Method: Introduced geometric stability of 3D singularity line shapes and proposed Flower Beams with controllable petal-like morphologies. Constructed 81-element optical alphabet and used deep learning for classification after turbulence.

Result: Shape-based tracing achieved over 90% classification accuracy in weaker turbulence and remained highly competitive in stronger turbulence, significantly outperforming spectral and topology-based approaches. Experimental validation confirmed shape stability in real-world conditions.

Conclusion: Shape of singularity lines provides a scalable and resilient alternative for structured light tracing and transmission, enabling turbulence-robust applications in optical technologies.

Abstract: The stability of optical vortex structures in turbulent environments is critical for their applications in optical communication, quantum information, and structured light technologies. Although topological invariants, such as crossings and linking numbers, are fundamentally invariant, recent studies reveal that their observed values deteriorate considerably in turbulent conditions due to environmental effects. In this study, we introduce an alternative approach based on the geometric stability of three-dimensional singularity line shapes, demonstrating that shape-based tracing of singularities outperforms both topological and spectral methods in turbulence. To test this concept, we propose Flower Beams, a novel class of structured optical fields featuring controllable petal-like singularity morphologies. We construct an 81-element optical alphabet and classify these structures after turbulence using deep learning. Our findings reveal that shape-based tracing achieves classification accuracy exceeding 90% in the weaker turbulence regimes and remains highly competitive even in stronger turbulence, significantly outperforming spectral and topology-based approaches. Experimental results confirm that the predicted shape stability holds in real-world conditions. This study stablishes the shape of the singularities' lines as a scalable and resilient alternative for structured light tracing and transmission, opening new avenues for turbulence-robust-applications.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [45] [Conservation of magnetic-helicity fluctuations due to spatial decorrelation of fluxes in decaying MHD turbulence](https://arxiv.org/abs/2511.09543)
*Justin Kin Jun Hew,David N. Hosking,Christoph Federrath,James R. Beattie,Neco Kriel*

Main category: physics.flu-dyn

TL;DR: The paper investigates the conservation of mean square magnetic helicity fluctuations in decaying MHD turbulence, focusing on boundary terms that could violate this conservation depending on gauge choices and spatial locality.


<details>
  <summary>Details</summary>
Motivation: To understand under what conditions the conservation of magnetic helicity fluctuations (I_H) in decaying MHD turbulence can be violated, particularly examining the role of boundary terms and gauge choices.

Method: Used theoretical analysis analogous to Batchelor & Proudman's approach to determine asymptotic forms of correlation functions, and verified predictions with high-resolution numerical simulations for the Coulomb gauge case.

Result: Found that long-range correlations strong enough to violate I_H conservation cannot develop for local evolution equations or for many non-local gauge choices including Coulomb gauge, but identified a class of non-local gauge choices where such violations are possible.

Conclusion: The conservation of magnetic helicity fluctuations depends critically on the choice of gauge and spatial locality of the evolution equation, with most physically relevant cases preserving the conservation.

Abstract: Hosking & Schekochihin (2021, Phys. Rev. X 11, 041005) have proposed that statistically isotropic decaying MHD turbulence without net magnetic helicity conserves the mean square fluctuation level of magnetic helicity in large volumes -- or, equivalently, the integral over space of the two-point correlation function of the magnetic-helicity density, denoted $I_H$. Formally, the conservation and gauge invariance of $I_H$ require the vanishing of certain boundary terms related to the strength of long-range spatial correlations. These boundary terms represent the ability (or otherwise) of the turbulence to organise fluxes over arbitrarily large distances to deplete or enhance fluctuations of magnetic helicity. In this work, we present a theory of these boundary terms, employing a methodology analogous to that of Batchelor & Proudman (1956, Philos. Trans. R. Soc. A 248, 369) to determine the relevant asymptotic forms of correlation functions. We find that long-range correlations of sufficient strength to violate the conservation of $I_H$ cannot develop dynamically if the evolution equation for the magnetic vector potential is chosen to be local in space. Likewise, we find that such correlations cannot develop for a wide class of gauge choices that make this equation non-local (including the Coulomb gauge). Nonetheless, we also identify a class of non-local gauge choices for which correlations that are sufficiently strong to violate the conservation of $I_H$ do appear possible. We verify our theoretical predictions for the case of the Coulomb gauge with measurements of correlation functions in a high-resolution numerical simulation.

</details>


### [46] [Comments on the paper `Modelling and nonclassical symmetry analysis of a complex porous media flow in a dilating channel'](https://arxiv.org/abs/2511.08656)
*Roman Cherniha*

Main category: physics.flu-dyn

TL;DR: This paper critiques a previous study on porous media flow modeling, arguing that the main theoretical results on Lie and nonclassical symmetries of a fourth-order PDE are incomplete and misleading.


<details>
  <summary>Details</summary>
Motivation: To identify and correct deficiencies in the theoretical analysis of symmetries for a porous media flow model published in a recent paper.

Method: Critical analysis and re-examination of the symmetry reduction methods and results presented in the referenced paper.

Result: Demonstrates that the main theoretical results from the original paper are incomplete and contain misleading conclusions about the symmetry properties of the PDE.

Conclusion: The critique reveals significant flaws in the original symmetry analysis, suggesting the need for more rigorous mathematical treatment of the problem.

Abstract: The Comments are devoted to the recently published paper 'Modelling and nonclassical symmetry analysis of a complex porous media flow in a dilating channel' (Physica D. 481 (2025) 134834), in which a model describing an unsteady two-dimensional viscous incompressible fluid flow through a porous medium is studied. The main theoretical results of that study consists of finding Lie and nonclassical symmetries of a fourth-order PDE, which was derived by simplification of the given model. Here it is shown that the main theoretical results derived therein are incomplete and misleading.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [47] [Existence and uniqueness of solutions to SDEs with state-dependent variable exponent](https://arxiv.org/abs/2511.08882)
*Mustafa Avci*

Main category: math.PR

TL;DR: This paper introduces a novel nonlinear SDE with state-dependent variable exponents, generalizing classical models like GBM and CEV while offering greater flexibility for real-world phenomena.


<details>
  <summary>Details</summary>
Motivation: To develop a more flexible stochastic model that can dynamically adapt to its current state and better capture real-world phenomena compared to classical models like Geometric Brownian Motion (GBM) and Constant Elasticity of Variance (CEV).

Method: Using a fixed-point approach to establish existence and uniqueness under suitable conditions for the time-inhomogeneous, nonlinear stochastic differential equation with state-dependent variable exponents.

Result: The authors successfully establish existence and uniqueness for the proposed model, which generalizes GBM and CEV while exhibiting distinct behavior for small states.

Conclusion: The proposed model with state-dependent variable exponents provides a flexible framework that enhances modeling accuracy while generalizing classical stochastic models, though it introduces analytical challenges that are addressed through the fixed-point approach.

Abstract: We study a time-inhomogeneous, nonlinear stochastic differential equation whose drift and diffusion terms involve state-dependent variable exponents. This novel structure introduces flexibility, allowing the system to adapt dynamically to its current state and better capture real-world phenomena compared to classical models such as GBM and CEV. While this flexibility enhances modeling accuracy, it also creates analytical challenges. Using a fixed-point approach, we establish existence and uniqueness under suitable conditions. The model generalizes GBM and CEV while exhibiting distinct behavior for small states.

</details>


<div id='nucl-th'></div>

# nucl-th [[Back]](#toc)

### [48] [Extrapolation to infinite model space of no-core shell model calculations using machine learning](https://arxiv.org/abs/2511.05061)
*Aleksandr Mazur,Roman Sharypov,Andrey Shirokov*

Main category: nucl-th

TL;DR: Neural network ensemble used to extrapolate no-core shell model results to infinite model space for light nuclei, achieving accurate ground-state energies within hundreds of keV but unstable radii for unbound states.


<details>
  <summary>Details</summary>
Motivation: To develop a reliable method for extrapolating NCSM results to infinite model space with quantifiable uncertainties, addressing the computational limitations of exact calculations.

Method: Employed an ensemble of neural networks to extrapolate NCSM results obtained with Daejeon16 NN interaction across different model spaces and basis parameters for energies and radii.

Result: Ground-state energies for 6Li, 6He, and unbound 6Be matched experiment within few hundred keV. Bound state radii converged well, but unbound state radii in 6Be and 6Li did not stabilize.

Conclusion: The neural network extrapolation method provides convergent predictions with quantifiable uncertainties for energies, but radii extrapolation remains challenging for unbound states.

Abstract: An ensemble of neural networks is employed to extrapolate no-core shell model (NCSM) results to infinite model space for light nuclei. We present a review of our neural network extrapolations of the NCSM results obtained with the Daejeon16 NN interaction in different model spaces and with different values of the NCSM basis parameter $\hbarΩ$ for energies of nuclear states and root-mean-square (rms) radii of proton, neutron and matter distributions in light nuclei. The method yields convergent predictions with quantifiable uncertainties. Ground-state energies for $^{6}$Li, $^{6}$He, and the unbound $^{6}$Be, as well as the excited $(3^{+},0)$ and $(0^{+},1)$ states of $^{6}$Li, are obtained within a few hundred keV of experiment. The extrapolated radii of bound states converge well. In contrast, radii of unbound states in $^{6}$Be and $^{6}$Li do not stabilize.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [49] [Classical Optimization Strategies for Variational Quantum Algorithms: A Systematic Study of Noise Effects and Parameter Efficiency](https://arxiv.org/abs/2511.09314)
*Tomáš Bezděk,Haomu Yuan,Vojtěch Novák,Silvie Illésová,Martin Beseda*

Main category: quant-ph

TL;DR: Benchmarks classical optimizers for QAOA on mean-variance problems under NISQ conditions, showing parameter-filtered optimization improves efficiency and robustness.


<details>
  <summary>Details</summary>
Motivation: To systematically evaluate classical optimization strategies for QAOA in near-term quantum computing with noise, identifying effective noise mitigation approaches.

Method: Evaluated Dual Annealing, COBYLA, and Powell Method across noiseless, sampling noise, and thermal noise models. Used Cost Function Landscape Analysis to identify inactive parameters, then implemented parameter-filtered optimization focusing only on active β parameters.

Result: Found γ parameters largely inactive in noiseless regime. Parameter-filtered optimization reduced evaluations from 21 to 12 for COBYLA and enhanced robustness, showing structural insights can effectively mitigate noise in VQAs.

Conclusion: Leveraging structural insights through parameter-filtered optimization is an effective architecture-aware noise mitigation strategy for Variational Quantum Algorithms.

Abstract: This study systematically benchmarks classical optimization strategies for the Quantum Approximate Optimization Algorithm when applied to Generalized Mean-Variance Problems under near-term Noisy Intermediate-Scale Quantum conditions. We evaluate Dual Annealing, Constrained Optimization by Linear Approximation, and the Powell Method across noiseless, sampling noise, and two thermal noise models. Our Cost Function Landscape Analysis revealed that the Quantum Approximate Optimization Algorithm angle parameters $γ$ were largely inactive in the noiseless regime. This insight motivated a parameter-filtered optimization approach, in which we focused the search space exclusively on the active $β$ parameters. This filtering substantially improved parameter efficiency for fast optimizers like Constrained Optimization by Linear Approximation (reducing evaluations from 21 to 12 in the noiseless case) and enhanced robustness, demonstrating that leveraging structural insights is an effective architecture-aware noise mitigation strategy for Variational Quantum Algorithms.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [50] [Physics-Informed Machine Learning for Characterizing System Stability](https://arxiv.org/abs/2511.08831)
*Tomoki Koike,Elizabeth Qian*

Main category: cs.LG

TL;DR: A physics-informed machine learning method called LyapInf that infers Lyapunov functions from trajectory data to estimate stability regions without requiring explicit system equations.


<details>
  <summary>Details</summary>
Motivation: Many practical systems (especially aerospace) have stability regions that are challenging to compute, and existing methods require explicit knowledge of system governing equations.

Method: Propose quadratic form for Lyapunov function and fit unknown quadratic operator by minimizing residual of Zubov equation using system trajectory data, treating system as black box.

Result: Successfully characterizes near-maximal ellipsoidal estimates of stability regions on benchmark examples without requiring system governing equations.

Conclusion: LyapInf provides an effective data-driven approach for stability analysis that overcomes the limitation of requiring explicit system equations.

Abstract: In the design and operation of complex dynamical systems, it is essential to ensure that all state trajectories of the dynamical system converge to a desired equilibrium within a guaranteed stability region. Yet, for many practical systems -- especially in aerospace -- this region cannot be determined a priori and is often challenging to compute. One of the most common methods for computing the stability region is to identify a Lyapunov function. A Lyapunov function is a positive function whose time derivative along system trajectories is non-positive, which provides a sufficient condition for stability and characterizes an estimated stability region. However, existing methods of characterizing a stability region via a Lyapunov function often rely on explicit knowledge of the system governing equations. In this work, we present a new physics-informed machine learning method of characterizing an estimated stability region by inferring a Lyapunov function from system trajectory data that treats the dynamical system as a black box and does not require explicit knowledge of the system governing equations. In our presented Lyapunov function Inference method (LyapInf), we propose a quadratic form for the unknown Lyapunov function and fit the unknown quadratic operator to system trajectory data by minimizing the average residual of the Zubov equation, a first-order partial differential equation whose solution yields a Lyapunov function. The inferred quadratic Lyapunov function can then characterize an ellipsoidal estimate of the stability region. Numerical results on benchmark examples demonstrate that our physics-informed stability analysis method successfully characterizes a near-maximal ellipsoid of the system stability region associated with the inferred Lyapunov function without requiring knowledge of the system governing equations.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [51] [Rademacher's Theorem for Calderon-Zygmund-type Spaces](https://arxiv.org/abs/2511.09159)
*Thomas Lamby*

Main category: math.FA

TL;DR: Extension of Rademacher's Theorem to weighted Calderón-Zygmund spaces with fractional indices, showing that functions in T^p_φ(x) belong to t^p_φ(x) almost everywhere under suitable conditions.


<details>
  <summary>Details</summary>
Motivation: To generalize Rademacher's classical result about Lipschitz functions having total differentials almost everywhere to a broader functional framework using weighted Calderón-Zygmund spaces.

Method: Replace Lipschitz condition with membership in general weighted Calderón-Zygmund spaces T^p_φ(x) with fractional indices, and prove the result under suitable assumptions or by working with adapted t^p_φ spaces.

Result: Shows that if f belongs to T^p_φ(x) for x in measurable subset E, then f belongs to t^p_φ(x) for almost every x in E under appropriate conditions.

Conclusion: The classical Rademacher's Theorem can be extended to weighted Calderón-Zygmund spaces with fractional indices, with counterexamples demonstrating the sharpness and limitations of the generalization.

Abstract: Rademacher's Theorem is a classical result stating that a Lipschitz function on $\mathbb{R}^d$ possesses a total differential almost everywhere. This implies that if $f$ is a function defined on $\mathbb{R}^d$ belonging to the Calderón--Zygmund space $T^\infty_1(x)$ for every $x \in \mathbb{R}^d$, then $f \in t^\infty_1(x)$ for almost every $x \in \mathbb{R}^d$.
  The main purpose of this paper is to extend this property to a broader functional framework. More precisely, we replace the Lipschitz condition by the assumption that $f$ belongs to a general weighted Calderón--Zygmund space $T^p_φ(x)$ for $x \in E$, where $E$ is a measurable subset of $\mathbb{R}^d$ and $φ$ is a weight with fractional indices. We then show that, under suitable assumptions, the function belongs to $t^p_φ(x)$ for almost every $x \in E$.
  The result can be obtained either by imposing additional hypotheses or by working within a suitably adapted $t^p_φ$ space. Whenever relevant, we also provide counterexamples illustrating the sharpness and the limitations of the statement.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [52] [CENIC: Convex Error-controlled Numerical Integration for Contact](https://arxiv.org/abs/2511.08771)
*Vince Kurtz,Alejandro Castro*

Main category: cs.RO

TL;DR: CENIC is a new continuous-time integrator that combines convex time-stepping with error-controlled integration, providing fast real-time simulation rates comparable to discrete-time simulators while ensuring accuracy and convergence guarantees.


<details>
  <summary>Details</summary>
Motivation: Discrete-time robotics simulators require choosing a time step, which is challenging - large steps cause non-physical artifacts while small steps slow simulation. Continuous-time error-controlled integration avoids this but struggles with stiff contact dynamics and speed requirements.

Method: CENIC integrates recent advances in convex time-stepping and error-controlled integration, inheriting benefits from both continuous integration and discrete time-stepping approaches.

Result: CENIC achieves fast real-time rates comparable to discrete-time simulators like MuJoCo, Drake and Isaac Sim, while providing guarantees on accuracy and convergence.

Conclusion: CENIC successfully bridges the gap between continuous-time and discrete-time simulation, offering the speed of discrete methods with the accuracy guarantees of continuous integration.

Abstract: State-of-the-art robotics simulators operate in discrete time. This requires users to choose a time step, which is both critical and challenging: large steps can produce non-physical artifacts, while small steps force the simulation to run slowly. Continuous-time error-controlled integration avoids such issues by automatically adjusting the time step to achieve a desired accuracy. But existing error-controlled integrators struggle with the stiff dynamics of contact, and cannot meet the speed and scalability requirements of modern robotics workflows. We introduce CENIC, a new continuous-time integrator that brings together recent advances in convex time-stepping and error-controlled integration, inheriting benefits from both continuous integration and discrete time-stepping. CENIC runs at fast real-time rates comparable to discrete-time robotics simulators like MuJoCo, Drake and Isaac Sim, while also providing guarantees on accuracy and convergence.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [53] [Accelerating two-dimensional tensor network optimization by preconditioning](https://arxiv.org/abs/2511.09546)
*Xing-Yu Zhang,Qi Yang,Philippe Corboz,Jutho Haegeman,Wei Tang*

Main category: cond-mat.str-el

TL;DR: Introduces an efficient preconditioner for gradient-based optimization of infinite projected entangled pair states (iPEPS) to address computational cost and ill-conditioned optimization landscape challenges.


<details>
  <summary>Details</summary>
Motivation: Gradient-based optimization for iPEPS faces two major challenges: high computational cost of energy/gradient evaluations and ill-conditioned optimization landscape that slows convergence.

Method: Developed an efficient preconditioner derived from the leading term of the metric tensor to reduce optimization steps, benchmarked against standard techniques on Heisenberg and Kitaev models.

Result: Demonstrated substantial improvements in overall computational efficiency across various contraction schemes, unit cell sizes, and Hamiltonians.

Conclusion: Preconditioned optimization shows potential to advance tensor network algorithms for strongly correlated systems.

Abstract: We revisit gradient-based optimization for infinite projected entangled pair states (iPEPS), a tensor network ansatz for simulating many-body quantum systems. This approach is hindered by two major challenges: the high computational cost of evaluating energies and gradients, and an ill-conditioned optimization landscape that slows convergence. To reduce the number of optimization steps, we introduce an efficient preconditioner derived from the leading term of the metric tensor. We benchmark our method against standard optimization techniques on the Heisenberg and Kitaev models, demonstrating substantial improvements in overall computational efficiency. Our approach is broadly applicable across various contraction schemes, unit cell sizes, and Hamiltonians, highlighting the potential of preconditioned optimization to advance tensor network algorithms for strongly correlated systems.

</details>


<div id='math.SP'></div>

# math.SP [[Back]](#toc)

### [54] [The exterior Steklov problem for Euclidean domains](https://arxiv.org/abs/2511.09490)
*Lukas Bundrock,Alexandre Girouard,Denis S. Grebenkov,Michael Levitin,Iosif Polterovich*

Main category: math.SP

TL;DR: Study of Steklov eigenvalue problem in exterior Euclidean domains, establishing equivalences between formulations and deriving sharp Escobar-type lower bounds for first eigenvalue on convex domains in dimensions ≥3.


<details>
  <summary>Details</summary>
Motivation: To understand the Steklov eigenvalue problem in exterior domains and establish bounds that distinguish the exterior case from interior and 2D cases.

Method: Present multiple equivalent formulations of the exterior Steklov problem, examine properties of eigenvalues/eigenfunctions, derive Escobar-type lower bounds using boundary curvature.

Result: Sharp lower bound for first exterior Steklov eigenvalue on convex domains in dimensions ≥3 in terms of principal curvatures; equality for balls; existence of convex domains with fixed volume but arbitrarily large first eigenvalues.

Conclusion: Exterior Steklov problem behaves differently from interior case - allows arbitrarily large first eigenvalues on fixed-volume convex domains in dimensions ≥3, while 2D exterior case satisfies Weinstock-type isoperimetric inequality.

Abstract: We investigate the Steklov eigenvalue problem in an exterior Euclidean domain. First, we present several formulations of this problem and establish the equivalences between them. Next, we examine various properties of the exterior Steklov eigenvalues and eigenfunctions. One of our main findings is an Escobar-type lower bound for the first exterior Steklov eigenvalue on convex domains in dimensions three and higher. This bound is expressed in terms of the principal curvatures of the boundary and is sharp, with equality attained for a ball. Moreover, it implies the existence of a sequence of convex domains with fixed volume and the first exterior Steklov eigenvalues tending to infinity. This contrasts with the interior case, as well as with the two-dimensional exterior case, for which we show that an analogue of the Weinstock isoperimetric inequality holds.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [55] [When is a System Discoverable from Data? Discovery Requires Chaos](https://arxiv.org/abs/2511.08860)
*Zakhar Shumaylov,Peter Zaika,Philipp Scholl,Gitta Kutyniok,Lior Horesh,Carola-Bibiane Schönlieb*

Main category: math.DS

TL;DR: Chaos enables unique system discovery from data, while non-chaotic systems face fundamental limitations in data-driven modeling.


<details>
  <summary>Details</summary>
Motivation: To understand when governing equations can be uniquely identified from finite observations, addressing the reliability issues in learned surrogates and symbolic models.

Method: Theoretical analysis showing that chaotic systems are discoverable from single trajectories in continuous/analytic function spaces, while non-chaotic systems require additional physical knowledge.

Result: Chaotic systems on entire domains are discoverable from single trajectories; systems chaotic on strange attractors are analytically discoverable under geometric conditions; classical Lorenz system is analytically discoverable; analytic discoverability impossible with first integrals.

Conclusion: Chaos is crucial for reliable data-driven discovery, explaining success in chaotic domains like weather forecasting but revealing challenges for stable systems like digital twins, requiring re-evaluation of purely data-driven approaches.

Abstract: The deep learning revolution has spurred a rise in advances of using AI in sciences. Within physical sciences the main focus has been on discovery of dynamical systems from observational data. Yet the reliability of learned surrogates and symbolic models is often undermined by the fundamental problem of non-uniqueness. The resulting models may fit the available data perfectly, but lack genuine predictive power. This raises the question: under what conditions can the systems governing equations be uniquely identified from a finite set of observations? We show, counter-intuitively, that chaos, typically associated with unpredictability, is crucial for ensuring a system is discoverable in the space of continuous or analytic functions. The prevalence of chaotic systems in benchmark datasets may have inadvertently obscured this fundamental limitation.
  More concretely, we show that systems chaotic on their entire domain are discoverable from a single trajectory within the space of continuous functions, and systems chaotic on a strange attractor are analytically discoverable under a geometric condition on the attractor. As a consequence, we demonstrate for the first time that the classical Lorenz system is analytically discoverable. Moreover, we establish that analytic discoverability is impossible in the presence of first integrals, common in real-world systems. These findings help explain the success of data-driven methods in inherently chaotic domains like weather forecasting, while revealing a significant challenge for engineering applications like digital twins, where stable, predictable behavior is desired. For these non-chaotic systems, we find that while trajectory data alone is insufficient, certain prior physical knowledge can help ensure discoverability. These findings warrant a critical re-evaluation of the fundamental assumptions underpinning purely data-driven discovery.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [56] [Boundedness for the wave equation on $C^1$ stationary axisymmetric perturbations of Kerr](https://arxiv.org/abs/2511.08751)
*Yakov Shlapentokh-Rothman,Mihai Tohaneanu*

Main category: gr-qc

TL;DR: New proof of energy boundedness for high-frequency wave solutions in Kerr spacetimes without using integrated local energy decay (ILED), applicable to metrics close to Kerr.


<details>
  <summary>Details</summary>
Motivation: To establish energy boundedness for wave equations in perturbed Kerr spacetimes where ILED fails due to stably trapped null geodesics.

Method: Developed a new energy estimate that circumvents ILED, applied to high-frequency projections on trapped frequencies in sub-extremal Kerr spacetimes.

Result: Successfully proved energy boundedness for wave solutions in stationary axisymmetric metrics that are C^1 close to sub-extremal Kerr, even with stably trapped null geodesics.

Conclusion: The new method provides robust energy boundedness results without relying on ILED, extending applicability to perturbed Kerr metrics where traditional approaches fail.

Abstract: On the full range of sub-extremal Kerr exterior spacetimes we give a new proof of energy boundedness for high-frequency projections of solutions to the wave equation onto trapped frequencies. A key feature of the new estimate is that it circumvents the use of an integrated local energy decay (ILED) statement. As an illustration of the robustness of the estimate, we use it to establish energy boundedness for solutions to the wave equation on stationary and axisymmetric metrics which are merely $C^1$ close to a sub-extremal Kerr spacetime. We show explicitly that such perturbed metrics may possess stably trapped null geodesics, and thus one does not expect ILED statements to hold.

</details>


### [57] [Dynamical Formation of Apparent Horizons due to Boundary Effect in Vacuum Einstein Gravity](https://arxiv.org/abs/2511.09508)
*Puskar Mondal,Shing-Tung Yau*

Main category: gr-qc

TL;DR: Apparent horizons can form dynamically from regular initial data in vacuum spacetime through boundary effects, using a Cauchy-double-null framework and Yau's boundary generalized mean curvature condition.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that apparent horizons can form dynamically in pure vacuum spacetime from regular initial data without apparent horizons, specifically through boundary effects.

Method: Adapted a Cauchy-double-null framework and used S-T Yau's boundary generalized mean curvature condition for the existence of interior apparent horizons.

Result: Proved that Yau's condition can be met dynamically starting from configurations that don't initially satisfy it, through a focusing mechanism.

Conclusion: This is the first part of a two-part sequence establishing dynamic formation of apparent horizons; the sequel will focus on explicit construction of Cauchy data.

Abstract: We prove that an apparent horizon can form as a result of Einsteinian evolution in pure vacuum spacetime starting from regular initial data free of apparent horizons due to pure boundary effects. We adapt a Cauchy-double-null framework and use the boundary generalized mean curvature condition for the existence of an interior apparent horizon imposed by the author S-T Yau in \cite{yau}. In particular, we prove that the condition of \cite{yau} can be met dynamically starting from a configuration that does not verify the same through a focusing mechanism. This is the first part of a two-part sequence, and in the sequel, we will focus on explicitly constructing the Cauchy data.

</details>
