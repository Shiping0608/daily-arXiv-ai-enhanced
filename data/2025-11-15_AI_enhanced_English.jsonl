{"id": "2511.09589", "pdf": "https://arxiv.org/pdf/2511.09589", "abs": "https://arxiv.org/abs/2511.09589", "authors": ["Changjian Xie", "Cheng Wang"], "title": "Convergence analysis of a third order semi-implicit projection method for Landau-Lifshitz-Gilbert equation", "categories": ["math.NA"], "comment": "This work is essentially different with arXiv:2510.25172 since this numerical method with linear system of variable coefficients is proposed, that is highly depends on the numerical solver. The analysis for the gyromagnetic term is different. The constraint for the main result is different", "summary": "The convergence analysis of a third-order scheme for the highly nonlinear Landau-Lifshitz-Gilbert equation with a non-convex constraint is considered. In this paper, we first present a fully discrete semi-implicit method for solving the Landau-Lifshitz-Gilbert equation based on the third-order backward differentiation formula and the one-sided extrapolation (using previous time-step numerical values). A projection step is further used to preserve the length of the magnetization. We provide a rigorous convergence analysis for the fully discrete numerical solution by the introduction of two sets of approximated solutions where one set of solutions solves the Landau-Lifshitz-Gilbert equation and the other is projected onto the unit sphere. Third-order accuracy in time and fourth order accuracy in space is obtained provided that the spatial step-size is the same order as the temporal step-size and slightly large damping parameter $\u03b1$ (greater than $\\sqrt{2}/2$). And also, the unique solvability of the numerical solution without any assumption for the step-size in both time and space is theoretically justified, using a monotonicity analysis. All these theoretical results are guaranteed by numerical examples in both 1D and 3D spaces.", "AI": {"tldr": "Third-order convergence analysis for Landau-Lifshitz-Gilbert equation with non-convex constraint using semi-implicit method with BDF3 and projection.", "motivation": "To develop and analyze a high-order numerical scheme for the highly nonlinear Landau-Lifshitz-Gilbert equation with non-convex constraint, ensuring length preservation of magnetization.", "method": "Fully discrete semi-implicit method using third-order backward differentiation formula (BDF3) and one-sided extrapolation, with projection step to preserve magnetization length. Two sets of approximated solutions are introduced for convergence analysis.", "result": "Third-order accuracy in time and fourth-order accuracy in space achieved when spatial step-size matches temporal step-size and damping parameter \u03b1 > \u221a2/2. Unique solvability proven without step-size assumptions. Verified by 1D and 3D numerical examples.", "conclusion": "The proposed third-order scheme provides rigorous convergence analysis and unique solvability for the Landau-Lifshitz-Gilbert equation with non-convex constraint, validated through numerical experiments."}}
{"id": "2511.09680", "pdf": "https://arxiv.org/pdf/2511.09680", "abs": "https://arxiv.org/abs/2511.09680", "authors": ["Shunyuan Shang", "Ziyuan Shi", "Mohamed-Slim Alouini"], "title": "SLIPT for Underwater IoT: System Modeling and Performance Analysis", "categories": ["math.NA"], "comment": null, "summary": "This paper presents a unified analytical framework for a two phase underwater wireless optical communication (UWOC) system that integrates Simultaneous Lightwave Information and Power Transfer (SLIPT) using a photovoltaic (PV) panel receiver. The proposed architecture enables self powered underwater sensor nodes by leveraging wide area and low cost PV panels for concurrent optical signal detection and energy harvesting. We develop a composite statistical channel that combines distance dependent absorption, turbulence induced fading characterized by the mixture Exponential Generalized Gamma (EGG )distribution, and beam misalignment due to pointing errors. Based on this model we derive closed form expressions for the probability density function, the cumulative distribution function, the outage probability (OP), the average bit error rate, the ergodic capacity, and the harvested power using Meijer G and Fox H functions. Overall, the paper introduces a practical analytical framework that provides clear guidance for design, optimization, and operation of SLIPT based UWOC systems.", "AI": {"tldr": "Unified analytical framework for underwater wireless optical communication with simultaneous power transfer using photovoltaic receivers, enabling self-powered sensor nodes.", "motivation": "To enable self-powered underwater sensor nodes by integrating energy harvesting with optical communication using low-cost PV panels.", "method": "Developed composite statistical channel model combining absorption, turbulence fading (EGG distribution), and beam misalignment, deriving closed-form expressions for key performance metrics.", "result": "Derived analytical expressions for probability density function, cumulative distribution function, outage probability, bit error rate, capacity, and harvested power using special functions.", "conclusion": "Provides practical analytical framework for design, optimization, and operation of SLIPT-based underwater wireless optical communication systems."}}
{"id": "2511.09728", "pdf": "https://arxiv.org/pdf/2511.09728", "abs": "https://arxiv.org/abs/2511.09728", "authors": ["Mohammad Mahabubur Rahman", "Deepanshu Verma"], "title": "Regularity and error estimates in physics-informed neural networks for the Kuramoto-Sivashinsky equation", "categories": ["math.NA"], "comment": null, "summary": "Due to its nonlinearity, bi-harmonic dissipation, and backward heat-like term in the absence of a divergence-free condition, the $2$-D/$3$-D Kuramoto-Sivashinsky equation poses significant challenges for both mathematical analysis and numerical approximation. These difficulties motivate the development of methods that blend classical analysis with numerical approximation approaches embodied in the framework of the physics-informed neural networks (PINNs). In addition, despite the extensive use of PINN frameworks for various linear and nonlinear PDEs, no study had previously established rigorous error estimates for the Kuramoto-Sivashinsky equation within a PINN setting. In this work, we overcome the inherent challenges, and establish several global regularity criteria based on space-time integrability conditions in Besov spaces. We then derive the first rigorous error estimates for the PINNs approximation of the Kuramoto-Sivashinsky equation and validate our theoretical error bounds through numerical simulations.", "AI": {"tldr": "This paper establishes the first rigorous error estimates for Physics-Informed Neural Networks (PINNs) applied to the challenging 2D/3D Kuramoto-Sivashinsky equation, overcoming difficulties from its nonlinearity, bi-harmonic dissipation, and backward heat-like term.", "motivation": "The Kuramoto-Sivashinsky equation poses significant challenges due to its nonlinearity, bi-harmonic dissipation, and backward heat-like term without divergence-free condition. Despite extensive PINN use for various PDEs, no previous study had established rigorous error estimates for this equation in a PINN setting.", "method": "Developed methods blending classical analysis with numerical approximation approaches using PINNs framework. Established global regularity criteria based on space-time integrability conditions in Besov spaces, then derived rigorous error estimates for PINNs approximation.", "result": "Successfully established several global regularity criteria and derived the first rigorous error estimates for PINNs approximation of the Kuramoto-Sivashinsky equation. Theoretical error bounds were validated through numerical simulations.", "conclusion": "The work overcomes inherent challenges of the Kuramoto-Sivashinsky equation and provides the first rigorous error analysis for PINNs in this context, bridging classical mathematical analysis with modern neural network-based approximation methods."}}
{"id": "2511.09779", "pdf": "https://arxiv.org/pdf/2511.09779", "abs": "https://arxiv.org/abs/2511.09779", "authors": ["Max Kreider", "John Harlim", "Daning Huang"], "title": "A model-free method for discovering symmetry in differential equations", "categories": ["math.NA", "math.DG"], "comment": null, "summary": "Symmetry in differential equations reveals invariances and offers a powerful means to reduce model complexity. Lie group analysis characterizes these symmetries through infinitesimal generators, which provide a local, linear criterion for invariance. However, identifying Lie symmetries directly from scattered data, without explicit knowledge of the governing equations, remains a significant challenge. This work introduces a numerical scheme that approximates infinitesimal generators from data sampled on an unknown smooth manifold, enabling the recovery of continuous symmetries without requiring the analytical form of the differential equations. We employ a manifold learning technique, Generalized Moving Least Squares, to prolongate the data, from which a linear system is constructed whose null space encodes the infinitesimal generators representing the symmetries. Convergence bounds for the proposed approach are derived. Several numerical experiments, including ordinary and partial differential equations, demonstrate the method's accuracy, robustness, and convergence, highlighting its potential for data-driven discovery of symmetries in dynamical systems.", "AI": {"tldr": "A numerical method to discover Lie symmetries from scattered data without knowing the governing equations, using manifold learning and linear algebra to approximate infinitesimal generators.", "motivation": "Identifying Lie symmetries directly from scattered data without explicit knowledge of governing equations is challenging but important for reducing model complexity in dynamical systems.", "method": "Uses Generalized Moving Least Squares for manifold learning to prolongate data, then constructs a linear system whose null space encodes infinitesimal generators representing symmetries.", "result": "Method successfully recovers continuous symmetries from data, with convergence bounds derived and demonstrated through numerical experiments on ODEs and PDEs.", "conclusion": "The approach provides an accurate, robust, and convergent data-driven method for discovering symmetries in dynamical systems without requiring analytical forms of differential equations."}}
{"id": "2511.09578", "pdf": "https://arxiv.org/pdf/2511.09578", "abs": "https://arxiv.org/abs/2511.09578", "authors": ["Hadi Keramati", "Morteza Sadeghi", "Rajeev K. Jaiman"], "title": "HeatGen: A Guided Diffusion Framework for Multiphysics Heat Sink Design Optimization", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "This study presents a generative optimization framework based on a guided denoising diffusion probabilistic model (DDPM) that leverages surrogate gradients to generate heat sink designs minimizing pressure drop while maintaining surface temperatures below a specified threshold. Geometries are represented using boundary representations of multiple fins, and a multi-fidelity approach is employed to generate training data. Using this dataset, along with vectors representing the boundary representation geometries, we train a denoising diffusion probabilistic model to generate heat sinks with characteristics consistent with those observed in the data. We train two different residual neural networks to predict the pressure drop and surface temperature for each geometry. We use the gradients of these surrogate models with respect to the design variables to guide the geometry generation process toward satisfying the low-pressure and surface temperature constraints. This inference-time guidance directs the generative process toward heat sink designs that not only prevent overheating but also achieve lower pressure drops compared to traditional optimization methods such as CMA-ES. In contrast to traditional black-box optimization approaches, our method is scalable, provided sufficient training data is available. Unlike traditional topology optimization methods, once the model is trained and the heat sink world model is saved, inference under new constraints (e.g., temperature) is computationally inexpensive and does not require retraining. Samples generated using the guided diffusion model achieve pressure drops up to 10 percent lower than the limits obtained by traditional black-box optimization methods. This work represents a step toward building a foundational generative model for electronics cooling.", "AI": {"tldr": "A generative optimization framework using guided denoising diffusion probabilistic model (DDPM) with surrogate gradients to create heat sink designs that minimize pressure drop while keeping surface temperatures below threshold.", "motivation": "To develop a scalable generative model for heat sink design that outperforms traditional optimization methods like CMA-ES and avoids the computational expense of retraining for new constraints.", "method": "Uses boundary representation of multiple fins, trains DDPM on multi-fidelity data, employs two residual neural networks to predict pressure drop and surface temperature, and uses surrogate gradients to guide geometry generation during inference.", "result": "Generated heat sinks achieve pressure drops up to 10% lower than traditional black-box optimization methods while maintaining temperature constraints.", "conclusion": "The framework represents progress toward foundational generative models for electronics cooling, offering computationally efficient inference for new constraints without retraining."}}
{"id": "2511.09772", "pdf": "https://arxiv.org/pdf/2511.09772", "abs": "https://arxiv.org/abs/2511.09772", "authors": ["John Brownfield"], "title": "Stability of the Rankine Vortex and Perimeter Growth in Vortex Patches", "categories": ["math.AP"], "comment": null, "summary": "We prove that for $\u03c9: \\mathbb{R}^2 \\to [0,1]$ sharing the same total vorticity and center of vorticity as the Rankine vortex, the $L^1$ deviation from the Rankine patch can be bounded by a function of the pseudo-energy deviation and the angular momentum of $\u03c9$. In the case of $m-$fold symmetry, the dependence on the angular momentum can be dropped. Using this, we affirm the results of prior simulations by demonstrating linear in time perimeter growth for a simply connected perturbation of the Rankine vortex.", "AI": {"tldr": "The paper proves bounds on L^1 deviation from Rankine vortex using pseudo-energy deviation and angular momentum, and shows linear perimeter growth for perturbed Rankine vortex.", "motivation": "To mathematically validate prior simulation results about vortex dynamics and provide rigorous bounds for vortex deviations from the Rankine model.", "method": "Mathematical proof establishing bounds on L^1 deviation from Rankine vortex using pseudo-energy deviation and angular momentum, with special consideration for m-fold symmetric cases.", "result": "For vortices with same total vorticity and center as Rankine vortex, L^1 deviation can be bounded by pseudo-energy deviation and angular momentum; for m-fold symmetric cases, angular momentum dependence is unnecessary; linear perimeter growth demonstrated for perturbed Rankine vortex.", "conclusion": "The results affirm prior simulation findings and provide mathematical foundation for understanding vortex dynamics, particularly the linear time growth of perimeter in perturbed Rankine vortices."}}
{"id": "2511.09657", "pdf": "https://arxiv.org/pdf/2511.09657", "abs": "https://arxiv.org/abs/2511.09657", "authors": ["Matthew Barber", "Stefano Pirandola"], "title": "Optimal Interpolation of Entanglement Purification Protocols", "categories": ["quant-ph", "math-ph", "physics.comp-ph", "physics.optics"], "comment": "REVTeX. 13 pages. 7 figures", "summary": "Bipartite entanglement purification is the conversion of copies of weakly entangled pairs shared between two separated parties into a smaller number of strongly entangled shared pairs using only local operations and classical communication. Choosing between different entanglement purification protocols generally involves weighing up a trade-off between the ratio of strongly entangled pairs produced to weakly entangled pairs consumed, which we call the rate of the protocol, and the degree of the entanglement of the strongly entangled pairs, typically measured by the fidelity of those pairs to maximally entangled states. By randomly choosing a protocol according to a probability distribution over a list of protocols for each pair we want to produce, we can achieve rates and fidelities not achieved by any of the original protocols. Here, we show how to choose this distribution to maximise the rate at which we produce qubit pairs with a given fidelity to a Bell state or, equivalently, to maximise the fidelity to a Bell state of the qubit pairs produced at a given rate. We investigate both the asymptotic case, where the number of initial pairs goes to infinity, and the finite-size regime, where protocols are restricted to a finite number of weakly entangled pairs.", "AI": {"tldr": "The paper presents a method to optimize entanglement purification protocols by randomly selecting protocols from a distribution, achieving better rate-fidelity trade-offs than individual protocols alone.", "motivation": "To overcome the trade-off between rate (ratio of strongly entangled pairs produced) and fidelity (degree of entanglement) in bipartite entanglement purification protocols.", "method": "Randomly choosing purification protocols according to a probability distribution over available protocols for each pair to be produced, optimizing this distribution to maximize rate for given fidelity or vice versa.", "result": "Achieves rates and fidelities not possible with any single original protocol, with analysis covering both asymptotic (infinite pairs) and finite-size regimes.", "conclusion": "Strategic random protocol selection enables superior entanglement purification performance by optimizing the rate-fidelity trade-off beyond what individual protocols can achieve."}}
{"id": "2511.09787", "pdf": "https://arxiv.org/pdf/2511.09787", "abs": "https://arxiv.org/abs/2511.09787", "authors": ["Briggs Damman", "Jarett LeVan", "Scott Baalrud"], "title": "Molecular Dynamics Simulation of Hydrodynamic Transport Coefficients in Plasmas", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Molecular dynamics (MD) simulations are used to calculate transport coefficients in a two-component plasma interacting through a repulsive Coulomb potential. The thermal conductivity, electrical conductivity, electrothermal coefficient, thermoelectric coefficient, and shear viscosity are computed using the Green-Kubo formalism over a broad range of Coulomb coupling strength, $0.01 \\leq \u0393\\leq 140$. Emphasis is placed on testing standard results of the Chapman-Enskog solution in the weakly coupled regime ($\u0393\\ll 1$) using these first-principles simulations. As expected, the results show good agreement for $\u0393\\lesssim 0.1$. However, this agreement is only possible if careful attention is paid to the definitions of linear constitutive relations in each of the theoretical models, a point that is often overlooked. For example, the standard Green-Kubo expression for thermal conductivity is a linear combination of thermal conductivity, electrothermal and thermoelectric coefficients computed in the Chapman-Enskog formalism. Meaningful results for electrical conductivity are obtained over the full range of coupling strengths explored, but it is shown that potential and virial components of the other transport coefficients diverge in the strongly coupled regime ($\u0393\\gg 1$). In this regime, only the kinetic components of the transport coefficients are meaningful for a classical plasma.", "AI": {"tldr": "Molecular dynamics simulations calculate transport coefficients in a two-component plasma using Green-Kubo formalism across coupling strengths \u0393=0.01-140, validating Chapman-Enskog theory in weak coupling and revealing limitations in strong coupling.", "motivation": "To compute fundamental transport coefficients (thermal/electrical conductivity, viscosity, etc.) in plasmas across a wide range of coupling strengths and test theoretical predictions from Chapman-Enskog solution.", "method": "Molecular dynamics simulations with Green-Kubo formalism applied to a two-component plasma interacting through repulsive Coulomb potential.", "result": "Good agreement with Chapman-Enskog theory for \u0393\u22720.1, but careful attention to constitutive relations is required. Electrical conductivity works across all coupling strengths, while other coefficients diverge in strong coupling (\u0393\u226b1) where only kinetic components remain meaningful.", "conclusion": "First-principles MD simulations validate Chapman-Enskog theory in weak coupling regime, but reveal that only kinetic components of transport coefficients are physically meaningful in strongly coupled classical plasmas."}}
{"id": "2511.09800", "pdf": "https://arxiv.org/pdf/2511.09800", "abs": "https://arxiv.org/abs/2511.09800", "authors": ["Jian-Guo Liu", "Robert L. Pego"], "title": "Analysis of the adhesion model and the reconstruction problem in cosmology", "categories": ["math.AP", "math-ph"], "comment": "53 pages, 3 figures", "summary": "In cosmology, a basic explanation of the observed concentration of mass in singular structures is provided by the Zeldovich approximation, which takes the form of free-streaming flow for perturbations of a uniform Einstein-de Sitter universe in co-moving coordinates. The adhesion model suppresses multi-streaming by introducing viscosity. We study mass flow in this model by analysis of Lagrangian advection in the zero-viscosity limit. Under mild conditions, we show that a unique limiting Lagrangian semi-flow exists. Limiting particle paths stick together after collision and are characterized uniquely by a differential inclusion. The absolutely continuous part of the mass measure agrees with that of a Monge-Amp\u00e8re measure arising by convexification of the free-streaming velocity potential. But the singular parts of these measures can differ when flows along singular structures merge, as shown by analysis of a 2D Riemann problem. The use of Monge-Amp\u00e8re measures and optimal transport theory for the reconstruction of inverse Lagrangian maps in cosmology was introduced in work of Brenier & Frisch et al. (Month. Not. Roy. Ast. Soc. 346, 2003). In a neighborhood of merging singular structures in our examples, however, we show that reconstruction yielding a monotone Lagrangian map cannot be exact a.e., even off of the singularities themselves.", "AI": {"tldr": "The paper studies mass flow in the adhesion model of cosmology, showing that a unique limiting Lagrangian semi-flow exists in the zero-viscosity limit, with particle paths sticking together after collisions. The analysis reveals differences between the singular parts of mass measures and Monge-Amp\u00e8re measures when flows merge.", "motivation": "To understand mass concentration in cosmological structures using the adhesion model, which suppresses multi-streaming by introducing viscosity, and to analyze Lagrangian advection in the zero-viscosity limit.", "method": "Analysis of Lagrangian advection in the zero-viscosity limit of the adhesion model, using differential inclusions, Monge-Amp\u00e8re measures, and optimal transport theory to study mass flow and particle paths.", "result": "A unique limiting Lagrangian semi-flow exists where particle paths stick together after collision. The absolutely continuous mass measure agrees with Monge-Amp\u00e8re measures from convexification, but singular parts differ when flows merge, as shown in 2D Riemann problem analysis.", "conclusion": "In regions where singular structures merge, reconstruction yielding a monotone Lagrangian map cannot be exact almost everywhere, even away from the singularities themselves, highlighting limitations in using Monge-Amp\u00e8re measures and optimal transport for inverse Lagrangian map reconstruction in cosmology."}}
{"id": "2511.09872", "pdf": "https://arxiv.org/pdf/2511.09872", "abs": "https://arxiv.org/abs/2511.09872", "authors": ["Dong-Yue Xie", "Xi Yang"], "title": "Randomized batch-sampling Kaczmarz methods for general linear systems", "categories": ["math.NA", "stat.ML"], "comment": null, "summary": "To conduct a more in-depth investigation of randomized solvers for general linear systems, we adopt a unified randomized batch-sampling Kaczmarz framework with per-iteration costs as low as cyclic block methods, and develop a general analysis technique to establish its convergence guarantee. With concentration inequalities, we derive new expected linear convergence rate bounds. The analysis applies to any randomized non-extended block Kaczmarz methods with static stochastic samplings. In addition, the new rate bounds are scale-invariant which eliminate the dependence on the magnitude of the data matrix. In most experiments, the new bounds are significantly tighter than existing ones and better reflect the empirical convergence behavior of block methods. Within this new framework, the batch-sampling distribution, as a learnable parameter, provides the possibility for block methods to achieve efficient performance in specific application scenarios, which deserves further investigation.", "AI": {"tldr": "A unified randomized batch-sampling Kaczmarz framework with low per-iteration costs is developed, featuring new scale-invariant convergence bounds that are tighter than existing ones and better match empirical performance.", "motivation": "To conduct deeper investigation of randomized solvers for general linear systems and develop more accurate convergence analysis for block Kaczmarz methods.", "method": "Developed a unified randomized batch-sampling Kaczmarz framework with low per-iteration costs, using concentration inequalities to derive new expected linear convergence rate bounds for any randomized non-extended block Kaczmarz methods with static stochastic samplings.", "result": "Derived new scale-invariant convergence rate bounds that eliminate dependence on data matrix magnitude. In most experiments, these bounds are significantly tighter than existing ones and better reflect empirical convergence behavior of block methods.", "conclusion": "The batch-sampling distribution as a learnable parameter enables block methods to achieve efficient performance in specific applications, warranting further investigation."}}
{"id": "2511.09717", "pdf": "https://arxiv.org/pdf/2511.09717", "abs": "https://arxiv.org/abs/2511.09717", "authors": ["Irma Avdic", "Yuchen Wang", "Michael Rose", "Lillian I. Payne Torres", "Anna O. Schouten", "Kevin J. Sung", "David A. Mazziotti"], "title": "Constrained Shadow Tomography for Molecular Simulation on Quantum Devices", "categories": ["quant-ph", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Quantum state tomography is a fundamental task in quantum information science, enabling detailed characterization of correlations, entanglement, and electronic structure in quantum systems. However, its exponential measurement and computational demands limit scalability, motivating efficient alternatives such as classical shadows, which enable accurate prediction of many observables from randomized measurements. In this work, we introduce a bi-objective semidefinite programming approach for constrained shadow tomography, designed to reconstruct the two-particle reduced density matrix (2-RDM) from noisy or incomplete shadow data. By integrating $N$-representability constraints and nuclear-norm regularization into the optimization, the method builds an $N$-representable 2-RDM that balances fidelity to the shadow measurements with energy minimization. This unified framework mitigates noise and sampling errors while enforcing physical consistency in the reconstructed states. Numerical and hardware results demonstrate that the approach significantly improves accuracy, noise resilience, and scalability, providing a robust foundation for physically consistent fermionic state reconstruction in realistic quantum simulations.", "AI": {"tldr": "A bi-objective semidefinite programming approach for constrained shadow tomography that reconstructs 2-RDMs from noisy shadow data using N-representability constraints and nuclear-norm regularization.", "motivation": "Quantum state tomography faces exponential scaling issues, motivating efficient alternatives like classical shadows. This work addresses noise and sampling errors in shadow tomography while maintaining physical consistency.", "method": "Bi-objective semidefinite programming with N-representability constraints and nuclear-norm regularization to balance fidelity to shadow measurements with energy minimization.", "result": "Significantly improved accuracy, noise resilience, and scalability in fermionic state reconstruction, demonstrated through numerical and hardware experiments.", "conclusion": "Provides a robust framework for physically consistent quantum state reconstruction that mitigates noise and sampling errors in realistic quantum simulations."}}
{"id": "2511.09950", "pdf": "https://arxiv.org/pdf/2511.09950", "abs": "https://arxiv.org/abs/2511.09950", "authors": ["Frida Brogren", "Christoffer Olofsson", "Joel Magnusson", "Arkady Gonoskov"], "title": "$\u03c0$-PIC: a framework for modular particle-in-cell developments and simulations", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Recently proposed modifications of the standard particle-in-cell (PIC) method resolve long-standing limitations such as exact preservation of physically conserved quantities and unbiased ensemble down-sampling. Such advances pave the way for next-generation PIC codes capable of using lower resolution and fewer particles per cell, enabling interactive studies on personal computers and facilitating large-scale parameter scans on supercomputers. Here, we present a Python-controlled framework designed to stimulate the dissemination and adoption of novel PIC developments by providing unified interfaces for accommodation, cross-testing, and comparison of PIC solvers and extensions written in Python or low-level languages like C++ and Fortran. To demonstrate flexibility of proposed interfaces we present and test implementations of several PIC solvers, as well as of extensions that is capable of managing QED processes, moving-window, and tight focusing of laser pulses.", "AI": {"tldr": "A Python-controlled framework for particle-in-cell (PIC) methods that provides unified interfaces for testing and comparing PIC solvers and extensions, enabling easier adoption of novel PIC developments.", "motivation": "To facilitate the dissemination and adoption of recent PIC method advancements that overcome limitations like exact preservation of conserved quantities and unbiased ensemble down-sampling, enabling interactive studies on personal computers and large-scale parameter scans.", "method": "Developed a Python-controlled framework with unified interfaces that can accommodate, cross-test, and compare PIC solvers and extensions written in Python or low-level languages like C++ and Fortran.", "result": "Successfully implemented and tested several PIC solvers and extensions capable of managing QED processes, moving-window techniques, and tight focusing of laser pulses, demonstrating the framework's flexibility.", "conclusion": "The proposed framework provides a flexible platform for integrating and testing novel PIC developments, potentially accelerating the adoption of next-generation PIC codes across different computing environments."}}
{"id": "2511.09994", "pdf": "https://arxiv.org/pdf/2511.09994", "abs": "https://arxiv.org/abs/2511.09994", "authors": ["Xiaohan Cai"], "title": "Uniqueness results for positive harmonic functions on manifolds with nonnegative Ricci curvature and strictly convex boundary", "categories": ["math.AP", "math.DG"], "comment": "This work has some overlap with my previous work, arXiv:2509.02978", "summary": "We prove some Liouville-type theorems for positive harmonic functions on compact Riemannian manifolds with nonnegative Ricci curvature and strictly convex boundary, thereby confirming some cases of Wang's conjecture (J. Geom. Anal. 31, 2021).\n  We further investigate Wang's conjecture on warped product manifolds and provide a partial verification of this conjecture, which also yields an alternative proof of Gu-Li's resolution of the conjecture in the $\\mathbb{B}^n$ case (Math. Ann. 391, 2025). Our approach is based on a general principle of employing the P-function method to such Liouville-type results, with particular emphasis on the role of a closed conformal vector field inherent to such manifolds.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.09916", "pdf": "https://arxiv.org/pdf/2511.09916", "abs": "https://arxiv.org/abs/2511.09916", "authors": ["Kunjing Yang", "Libin Zheng", "Minru Bai"], "title": "Implicit Multiple Tensor Decomposition", "categories": ["math.NA", "math.OC"], "comment": null, "summary": "Recently, triple decomposition has attracted increasing attention for decomposing third-order tensors into three factor tensors. However, this approach is limited to third-order tensors and enforces uniformity in the lower dimensions across all factor tensors, which restricts its flexibility and applicability. To address these issues, we propose the Multiple decomposition, a novel framework that generalizes triple decomposition to arbitrary order tensors and allows the short dimensions of the factor tensors to differ. We establish its connections with other classical tensor decompositions. Furthermore, implicit neural representation (INR) is employed to continuously represent the factor tensors in Multiple decomposition, enabling the method to generalize to non-grid data. We refer to this INR-based Multiple decomposition as Implicit Multiple Tensor Decomposition (IMTD). Then, the Proximal Alternating Least Squares (PALS) algorithm is utilized to solve the IMTD-based tensor reconstruction models. Since the objective function in IMTD-based models often lacks the Kurdyka-Lojasiewicz (KL) property, we establish a KL-free convergence analysis for the algorithm. Finally, extensive numerical experiments further validate the effectiveness of the proposed method.", "AI": {"tldr": "Proposes Multiple decomposition, a generalization of triple decomposition for arbitrary-order tensors with flexible dimensions, enhanced by implicit neural representations for non-grid data and solved with PALS algorithm.", "motivation": "Triple decomposition is limited to third-order tensors and requires uniform lower dimensions across factor tensors, restricting flexibility and applicability.", "method": "Developed Multiple decomposition framework, used implicit neural representation for continuous factor tensors (IMTD), and applied Proximal Alternating Least Squares (PALS) algorithm with KL-free convergence analysis.", "result": "Extensive numerical experiments validate the effectiveness of the proposed method for tensor decomposition and reconstruction.", "conclusion": "The proposed Multiple decomposition successfully generalizes triple decomposition to arbitrary-order tensors with flexible dimensions and works effectively with non-grid data through implicit neural representations."}}
{"id": "2511.09747", "pdf": "https://arxiv.org/pdf/2511.09747", "abs": "https://arxiv.org/abs/2511.09747", "authors": ["Justin Cooke", "Kathleen Donohue", "Clark D Rowley", "Prasad G Thoppil", "D Randolph Watts"], "title": "The Role of Deep Mesoscale Eddies in Ensemble Forecast Performance", "categories": ["physics.ao-ph", "physics.comp-ph", "physics.data-an"], "comment": "12 pages, 10 figures", "summary": "Present forecasting efforts rely on assimilation of observational data captured in the upper ocean (< 1000 m depth). These observations constrain the upper ocean and minimally influence the deep ocean. Nevertheless, development of the full water column circulation critically depends upon the dynamical interactions between upper and deep fields. Forecasts demonstrate that the initialization of the deep field is influential for the development and evolution of the surface in the forecast. Deep initial conditions that better agree with observations have lower upper ocean uncertainty as the forecast progresses. Here, best and worst ensemble members in two 92-day forecasts are identified and contrasted in order to determine how the deep ocean differs between these groups. The forecasts cover the duration of the Loop Current Eddy Thor separation event, which coincides with available deep observations in the Gulf. Model member performance is assessed by comparing surface variables against verifying analysis and satellite altimeter data during the forecast time-period. Deep cyclonic and anticyclonic features are reviewed, and compared against deep observations, indicating subtle differences in locations of deep eddies at relevant times. These results highlight both the importance of deep circulation in the dynamics of the Loop Current system and more broadly motivate efforts to assimilate deep observations to better constrain the deep initial fields and improve surface predictions.", "AI": {"tldr": "Deep ocean initialization significantly impacts surface forecast accuracy in ocean circulation models, with better deep field initialization reducing upper ocean uncertainty over time.", "motivation": "Current forecasting relies on upper ocean data assimilation, but deep ocean circulation dynamics critically influence surface evolution, yet deep observations are minimally assimilated.", "method": "Analyzed two 92-day forecasts during Loop Current Eddy Thor separation, comparing best/worst ensemble members by assessing surface variables against analysis/satellite data and examining deep cyclonic/anticyclonic features.", "result": "Deep initial conditions that better match observations lead to lower upper ocean uncertainty; subtle differences in deep eddy locations were identified between best and worst performing forecasts.", "conclusion": "Deep circulation is crucial for Loop Current system dynamics, motivating assimilation of deep observations to better constrain initial fields and improve surface predictions."}}
{"id": "2511.10096", "pdf": "https://arxiv.org/pdf/2511.10096", "abs": "https://arxiv.org/abs/2511.10096", "authors": ["A. A. Molavi Choobini", "M. Shahmansouri"], "title": "Tailored Three Dimensional Betatron Dynamics in UltraStable Hybrid Laser Plasma RF Accelerators", "categories": ["physics.plasm-ph", "physics.acc-ph", "physics.comp-ph"], "comment": null, "summary": "The detailed theoretical and numerical investigation of hybrid laser plasma RF accelerators, elucidating the mechanisms governing transverse beam dynamics, betatron polarization, and radiation reaction in ultra-relativistic electron bunches is presented. This framework combines analytical models of spatiotemporal plasma wakefield modulation, phase-dependent RF-driven oscillations, and quantum-corrected Landau Lifshitz radiation reaction with fully self-consistent 3D particle in cell simulations using EPOCH. The results demonstrate that RF amplitude, frequency, and phase enable precise control over transverse focusing strengths, betatron oscillation amplitudes, and polarization states. Resonant alignment between RF fields and natural betatron frequencies amplifies transverse excursions while damping parasitic oscillations through enhanced focusing gradients and radiation reaction, yielding reductions in emittance and mitigation of synchrotron-like energy losses. Stability maps and 3D force landscapes reveal strong phase sensitivity, where initial conditions and RF component ratios govern the temporal evolution of betatron amplitudes, and longitudinal field gradients modulate \u03b3 growth rates. These findings provide a comprehensive picture of nonlinear, resonant, and damping phenomena in hybrid laser plasma RF systems, highlighting the full spectrum of controllable transverse, longitudinal, and polarization dynamics in ultra relativistic electron beams.", "AI": {"tldr": "Hybrid laser plasma RF accelerators enable precise control over transverse beam dynamics, betatron polarization, and radiation reaction in ultra-relativistic electron bunches through RF field manipulation.", "motivation": "To investigate mechanisms governing transverse beam dynamics, betatron polarization, and radiation reaction in ultra-relativistic electron bunches within hybrid laser plasma RF accelerators.", "method": "Combines analytical models of spatiotemporal plasma wakefield modulation, phase-dependent RF-driven oscillations, and quantum-corrected Landau Lifshitz radiation reaction with fully self-consistent 3D particle in cell simulations using EPOCH.", "result": "RF amplitude, frequency, and phase enable precise control over transverse focusing strengths, betatron oscillation amplitudes, and polarization states. Resonant alignment amplifies transverse excursions while damping parasitic oscillations, reducing emittance and mitigating synchrotron-like energy losses.", "conclusion": "Provides comprehensive understanding of nonlinear, resonant, and damping phenomena in hybrid laser plasma RF systems, demonstrating full spectrum of controllable transverse, longitudinal, and polarization dynamics in ultra-relativistic electron beams."}}
{"id": "2511.10034", "pdf": "https://arxiv.org/pdf/2511.10034", "abs": "https://arxiv.org/abs/2511.10034", "authors": ["Ziyu Gan", "Heming Jiao"], "title": "Locally uniform ellipticity of the fractional Hessian operators", "categories": ["math.AP"], "comment": null, "summary": "In [1], Caffarelli-Charro introduced a fractional Monge-Amp\u00e8re operator. Later, Wu [17] generalized it to a fractional analogue of $k$-Hessian operators and proved the strict ellipticity for $k=2$. In this paper, we introduce a fractional analogue of general Hessian operators and prove the stability. We also show that the fractional analogue $k$-Hessian operators defined in [17] are strictly elliptic with respect to convex solutions for all $2 \\leq k \\leq n$. Furthermore, we provide a new proof for the case $k=2$ without the convexity condition.", "AI": {"tldr": "This paper introduces fractional analogues of general Hessian operators, proves their stability, and shows strict ellipticity for convex solutions. It also provides a new proof for the k=2 case without requiring convexity.", "motivation": "To extend the fractional Monge-Amp\u00e8re operator introduced by Caffarelli-Charro and Wu's fractional k-Hessian operators to general Hessian operators, and to establish their stability and ellipticity properties.", "method": "Introduces fractional analogues of general Hessian operators and provides mathematical proofs for stability and strict ellipticity properties.", "result": "Proves that fractional k-Hessian operators are strictly elliptic for convex solutions when 2 \u2264 k \u2264 n, and provides a new proof for k=2 case without convexity requirement.", "conclusion": "The paper successfully generalizes fractional Hessian operators, establishes their stability, and proves strict ellipticity properties, extending previous work in fractional calculus and PDE theory."}}
{"id": "2511.10044", "pdf": "https://arxiv.org/pdf/2511.10044", "abs": "https://arxiv.org/abs/2511.10044", "authors": ["Sebastian Bleecke", "Abhijit Biswas", "David I. Ketcheson", "Hendrik Ranocha", "Jochen Schutz"], "title": "Asymptotic-preserving and energy-conserving methods for a hyperbolic approximation of the BBM equation", "categories": ["math.NA", "nlin.PS"], "comment": null, "summary": "We study the hyperbolic approximation of the Benjamin-Bona-Mahony (BBM) equation proposed recently by Gavrilyuk and Shyue (2022). We develop asymptotic-preserving numerical methods using implicit-explicit (additive) Runge-Kutta methods that are implicit in the stiff linear part. The new discretization of the hyperbolization conserves important invariants converging to invariants of the BBM equation. We use the entropy relaxation approach to make the fully discrete schemes energy-preserving. Numerical experiments demonstrate the effectiveness of these discretizations.", "AI": {"tldr": "Development of asymptotic-preserving numerical methods for hyperbolic approximation of BBM equation using implicit-explicit Runge-Kutta methods that conserve invariants and energy.", "motivation": "To create effective numerical methods for the hyperbolic approximation of the Benjamin-Bona-Mahony (BBM) equation proposed by Gavrilyuk and Shyue (2022) that preserve important mathematical properties.", "method": "Used implicit-explicit (additive) Runge-Kutta methods with implicit treatment of stiff linear part, combined with entropy relaxation approach to ensure energy preservation.", "result": "The new discretization conserves important invariants that converge to invariants of the original BBM equation, and numerical experiments demonstrate the effectiveness of these discretizations.", "conclusion": "The developed asymptotic-preserving numerical methods successfully handle the hyperbolic approximation of BBM equation while preserving conservation properties and energy."}}
{"id": "2511.09806", "pdf": "https://arxiv.org/pdf/2511.09806", "abs": "https://arxiv.org/abs/2511.09806", "authors": ["James Watt", "Christoph Federrath", "Claudius Birke", "Christian Klingenberg"], "title": "Mitigating numerical dissipation in simulations of subsonic turbulent flows", "categories": ["physics.flu-dyn", "astro-ph.IM", "astro-ph.SR", "physics.comp-ph"], "comment": null, "summary": "Magnetohydrodynamic (MHD) simulations of subsonic (Mach number~$<1$) turbulence are crucial to our understanding of several processes including oceanic and atmospheric flows, the amplification of magnetic fields in the early universe, accretion discs, and stratified flows in stars. In this work, we demonstrate that conventional numerical schemes are excessively dissipative in this low-Mach regime. We demonstrate that a new numerical scheme (termed `USM-BK' and implemented in the FLASH MHD code) reduces the dissipation of kinetic and magnetic energy, constrains the divergence of magnetic field to zero close to machine precision, and resolves smaller-scale structure than other, more conventional schemes, and hence, is the most accurate for simulations of low-Mach turbulent flows among the schemes compared in this work. We first compare several numerical schemes/solvers, including Split-Roe, Split-Bouchut, USM-Roe, USM-HLLC, USM-HLLD, and the new USM-BK, on a simple vortex problem. We then compare the schemes/solvers in simulations of the turbulent dynamo and show that the choice of scheme affects the growth rate, saturation level, and viscous and resistive dissipation scale of the dynamo. We also measure the numerical kinematic Reynolds number (Re) and magnetic Reynolds number (Rm) of our otherwise ideal MHD flows, and show that the new USM-BK scheme provides the highest Re and comparable Rm amongst all the schemes compared.", "AI": {"tldr": "A new numerical scheme called USM-BK reduces excessive dissipation in low-Mach magnetohydrodynamic turbulence simulations, outperforming conventional schemes in accuracy and resolution.", "motivation": "Conventional numerical schemes are excessively dissipative in low-Mach (Mach number <1) MHD turbulence simulations, which affects understanding of processes like atmospheric flows, accretion discs, and magnetic field amplification.", "method": "Developed and implemented a new numerical scheme (USM-BK) in FLASH MHD code, comparing it with several conventional schemes (Split-Roe, Split-Bouchut, USM-Roe, USM-HLLC, USM-HLLD) on vortex problems and turbulent dynamo simulations.", "result": "USM-BK reduces kinetic/magnetic energy dissipation, maintains near-machine-precision magnetic field divergence, resolves smaller-scale structures, provides highest numerical kinematic Reynolds number and comparable magnetic Reynolds number among compared schemes.", "conclusion": "USM-BK is the most accurate scheme for low-Mach turbulent flow simulations, significantly impacting dynamo growth rates, saturation levels, and dissipation scales compared to conventional methods."}}
{"id": "2511.10127", "pdf": "https://arxiv.org/pdf/2511.10127", "abs": "https://arxiv.org/abs/2511.10127", "authors": ["Thomas Kluge", "Arthur Hirsch-Passicos", "Jannis Schulz", "Mungo Frost", "Eric Galtier", "Maxence Gauthier", "J\u00f6rg Grenzer", "Christian Gutt", "Lingen Huang", "Uwe H\u00fcbner", "Megan Ikeya", "Hae Ja Lee", "Dimitri Khaghani", "Willow Moon Martin", "Brian Edward Marr\u00e9", "Motoaki Nakatsutsumi", "Pawe\u0142 Ordyna", "Franziska-Luise Paschke-Br\u00fchl", "Alexander Pelka", "Lisa Randolph", "Hans-Peter Schlenvoigt", "Christopher Schoenwaelder", "Michal \u0160m\u00edd", "Long Yang", "Ulrich Schramm", "Thomas E. Cowan"], "title": "Microscopy X-ray Imaging enriched with Small Angle X-ray Scattering for few nanometer resolution reveals shock waves and compression in intense short pulse laser irradiation of solids", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Understanding how laser pulses compress solids into high-energy-density states requires diagnostics that simultaneously resolve macroscopic geometry and nanometer-scale structure. Here we present a combined X-ray imaging (XRM) and small-angle X-ray scattering (SAXS) approach that bridges this diagnostic gap. Using the Matter in Extreme Conditions end station at LCLS, we irradiated 25-micrometer copper wires with 45-fs, 0.9-J, 800-nm pulses at 3.5e19 W/cm2 while probing with 8.2-keV XFEL pulses. XRM visualizes the evolution of ablation, compression, and inward-propagating fronts with about 200-nm resolution, while SAXS quantifies their nanometer-scale sharpness through the time-resolved evolution of scattering streaks. The joint analysis reveals that an initially smooth compression steepens into a nanometer-sharp shock front after roughly 18 ps, consistent with an analytical steepening model and hydrodynamic simulations. The front reaches a velocity of about 25 km/s and a lateral width of several tens of micrometers, demonstrating for the first time the direct observation of shock formation and decay at solid density with few-nanometer precision. This integrated XRM-SAXS method establishes a quantitative, multiscale diagnostic of laser-driven shocks in dense plasmas relevant to inertial confinement fusion, warm dense matter, and planetary physics.", "AI": {"tldr": "Combined X-ray imaging and small-angle X-ray scattering enables multiscale observation of laser-driven shock formation in copper with nanometer precision, revealing compression steepening into sharp shock fronts.", "motivation": "To bridge the diagnostic gap between macroscopic geometry and nanometer-scale structure in understanding laser pulse compression of solids into high-energy-density states.", "method": "Used combined X-ray imaging (XRM) and small-angle X-ray scattering (SAXS) at LCLS, irradiating 25-micrometer copper wires with 45-fs laser pulses while probing with 8.2-keV XFEL pulses.", "result": "Revealed that initially smooth compression steepens into nanometer-sharp shock front after ~18 ps, reaching ~25 km/s velocity and lateral width of tens of micrometers, with direct observation of shock formation at solid density.", "conclusion": "The integrated XRM-SAXS method establishes quantitative multiscale diagnostics for laser-driven shocks in dense plasmas, relevant to fusion, warm dense matter, and planetary physics."}}
{"id": "2511.10039", "pdf": "https://arxiv.org/pdf/2511.10039", "abs": "https://arxiv.org/abs/2511.10039", "authors": ["Lucrezia Cossetti", "Lorenzo D'Arca"], "title": "A unified approach to Hardy-type inequalities with Bessel pairs", "categories": ["math.AP", "math.SP"], "comment": null, "summary": "In this paper, we provide suitable characterisations of pairs of weights $(V,W),$ known as Bessel pairs, that ensure the validity of weighted Hardy-type inequalities. The abstract approach adopted here makes it possible to establish such inequalities also going beyond the classical Euclidean setting and also within a more general $L^p$ framework. As a byproduct of our method, we obtain explicit expressions for the maximizing functions and, in certain specific situations, we show that the associated constants are sharp. We emphasise that our approach unifies, generalises and improves several existing results in the literature.", "AI": {"tldr": "Characterizes Bessel pairs of weights for weighted Hardy-type inequalities, extending beyond Euclidean settings to general L^p frameworks with sharp constants in some cases.", "motivation": "To establish a unified framework for weighted Hardy-type inequalities that generalizes and improves existing results, working beyond classical Euclidean settings.", "method": "Abstract approach using Bessel pairs of weights (V,W) to characterize conditions for Hardy-type inequalities in general L^p spaces.", "result": "Obtained explicit expressions for maximizing functions and proved sharpness of associated constants in certain specific situations.", "conclusion": "The approach unifies, generalizes, and improves several existing results in the literature on weighted Hardy-type inequalities."}}
{"id": "2511.10100", "pdf": "https://arxiv.org/pdf/2511.10100", "abs": "https://arxiv.org/abs/2511.10100", "authors": ["Xiaofeng Cai", "Yibing Chen", "Kunkai Fu", "Liujun Pan"], "title": "A Third-order Conservative Semi-Lagrangian Discontinuous Galerkin Scheme For the Transport Equation on Curvilinear Unstructured Meshes", "categories": ["math.NA"], "comment": null, "summary": "We develop a third-order conservative semi-Lagrangian discontinuous Galerkin (SLDG) scheme for solving linear transport equations on curvilinear unstructured triangular meshes, tailored for complex geometries. To ensure third-order spatial accuracy while strictly preserving mass, we develop a high-order conservative intersection-based remapping algorithm for curvilinear unstructured meshes, which enables accurate and conservative data transfer between distinct curvilinear meshes. Incorporating this algorithm, we construct a non-splitting high-order SLDG method equipped with weighted essentially non-oscillatory and positivity-preserving limiters to effectively suppress numerical oscillations and maintain solution positivity. For the linear problem, the semi-Lagrangian update enables large time stepping, yielding an explicit and efficient implementation. Rigorous numerical analysis confirms that our scheme achieves third-order accuracy in both space and time, as validated by consistent error analysis in terms of $L^1$ and $L^2$-norms. Numerical benchmarks, including rigid body rotation and swirling deformation flows with smooth and discontinuous initial conditions, validate the scheme's accuracy, stability, and robustness.", "AI": {"tldr": "Third-order conservative semi-Lagrangian discontinuous Galerkin scheme for linear transport equations on curvilinear unstructured triangular meshes, featuring mass conservation, large time stepping, and oscillation suppression.", "motivation": "To develop an accurate and efficient numerical scheme for solving linear transport equations on complex geometries using curvilinear unstructured meshes while maintaining conservation properties and handling discontinuities.", "method": "Developed a high-order conservative intersection-based remapping algorithm for curvilinear unstructured meshes, combined with a non-splitting semi-Lagrangian discontinuous Galerkin method using WENO and positivity-preserving limiters.", "result": "The scheme achieves third-order accuracy in both space and time, preserves mass strictly, suppresses numerical oscillations, maintains solution positivity, and enables large time stepping for efficiency.", "conclusion": "The proposed scheme provides an accurate, stable, and robust solution for linear transport problems on complex geometries, validated through numerical benchmarks including rigid body rotation and swirling deformation flows."}}
{"id": "2511.09847", "pdf": "https://arxiv.org/pdf/2511.09847", "abs": "https://arxiv.org/abs/2511.09847", "authors": ["Brandon Choi", "Matteo Ugliotti", "Mateo Reynoso", "Daniel R. Gurevich", "Roman O. Grigoriev"], "title": "Data-driven modeling of multiscale phenomena with applications to fluid turbulence", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": null, "summary": "This letter introduces a novel data driven framework for constructing accurate and general equivariant models of multiscale phenomena which does not rely on specific assumptions about the underlying physics. This framework is illustrated using incompressible fluid turbulence as an example that is representative, practically important, reasonably simple, and exceedingly well studied. We use direct numerical simulations of freely decaying turbulence in two spatial dimensions to infer an effective field theory comprising explicit, interpretable evolution equations for both the large (resolved) and small (modeled) scales. The resulting closed system of equations is capable of accurately describing the effect of small scales, including backscatter -- the flow of energy from small to large scales, which is particularly pronounced in two dimensions -- which is an outstanding challenge that, to our knowledge, no existing alternative successfully tackles.", "AI": {"tldr": "A novel data-driven framework for building equivariant multiscale models without relying on physics assumptions, demonstrated on 2D incompressible fluid turbulence.", "motivation": "To address the challenge of modeling multiscale phenomena, particularly backscatter (energy flow from small to large scales) in turbulence, which existing methods fail to handle successfully.", "method": "Using direct numerical simulations of freely decaying 2D turbulence to infer an effective field theory with explicit, interpretable evolution equations for both large (resolved) and small (modeled) scales.", "result": "The framework successfully constructs closed equations that accurately describe small-scale effects including backscatter, which is particularly pronounced in 2D turbulence.", "conclusion": "The proposed data-driven framework provides an effective approach for building accurate and general equivariant models of multiscale phenomena, successfully tackling the challenging problem of backscatter in turbulence."}}
{"id": "2511.10147", "pdf": "https://arxiv.org/pdf/2511.10147", "abs": "https://arxiv.org/abs/2511.10147", "authors": ["Emil R. Ingelsten", "Madox C. McGrae-Menge", "E. Paulo Alves", "Istvan Pusztai"], "title": "Data-driven multi-species heat flux closures for two-stream-unstable plasmas with nonlinear sparse regression", "categories": ["physics.plasm-ph"], "comment": "25 pages, 8 figures", "summary": "The dual aims of accuracy and computational efficiency in computational plasma physics lend themselves well to the use of fluid models. The first of these goals, however, is only satisfied for such models insofar as the utilized closure can capture the neglected kinetic physics -- something which has proven challenging for multi-scale collisionless processes. In a recent article [E. R. Ingelsten et al. (2025) J. Plasma Phys. 91 E64], we used the data-driven method of sparse regression to discover a novel heat flux closure for electrostatic phenomena. Here, we generalize the six-term closure model found in that work from single- to multi-species modeling. Using data from OSIRIS particle-in-cell simulations over a range of initial conditions, we then demonstrate how the unknown coefficients in front of the three most important terms in the closure can be estimated from box-averaged fluid quantities. Both neural networks and a newly developed framework for nonlinear sparse regression are showcased. The resulting models predict the heat flux for each species with a typical accuracy of 80-90 % and regularly account for 85-95 % of the rate of change in the pressure. The models are also compared with results from multi-species linear collisionless theory.", "AI": {"tldr": "This paper generalizes a data-driven heat flux closure model from single-species to multi-species plasma modeling using sparse regression and neural networks, achieving 80-90% accuracy in heat flux prediction.", "motivation": "To improve computational plasma physics models by developing accurate and computationally efficient multi-species heat flux closures that capture neglected kinetic physics, which has been challenging for multi-scale collisionless processes.", "method": "Used data-driven sparse regression and neural networks on OSIRIS particle-in-cell simulation data to generalize a six-term closure model from single- to multi-species modeling, estimating unknown coefficients from box-averaged fluid quantities.", "result": "The resulting models predict heat flux for each species with 80-90% accuracy and account for 85-95% of the pressure rate of change. Models were also compared with multi-species linear collisionless theory.", "conclusion": "The generalized multi-species heat flux closure models successfully capture kinetic physics with high accuracy while maintaining computational efficiency, demonstrating the effectiveness of data-driven approaches for plasma fluid modeling."}}
{"id": "2511.10099", "pdf": "https://arxiv.org/pdf/2511.10099", "abs": "https://arxiv.org/abs/2511.10099", "authors": ["D Han-Kwan", "\u00c9 Miot", "A Moussa", "I Moyano"], "title": "On Uniqueness For The Three-Dimensional Vlasov-Navier-Stokes System", "categories": ["math.AP"], "comment": null, "summary": "We study the problem of uniqueness of Leray solutions to the three-dimensional Vlasov-Navier-Stokes system. We establish uniqueness whenever the fluid velocity field belongs to the Cannone-Meyer-Planchon class, which allows to go beyond the Osgood uniqueness class. A stability estimate in this setting is also provided.", "AI": {"tldr": "Uniqueness of Leray solutions for 3D Vlasov-Navier-Stokes system established beyond Osgood class using Cannone-Meyer-Planchon framework", "motivation": "Study uniqueness of solutions to the three-dimensional Vlasov-Navier-Stokes system, extending beyond traditional Osgood uniqueness class", "method": "Use Cannone-Meyer-Planchon class for fluid velocity field to establish uniqueness", "result": "Proved uniqueness of Leray solutions and provided stability estimate", "conclusion": "Successfully extended uniqueness results beyond Osgood class using Cannone-Meyer-Planchon framework"}}
{"id": "2511.10129", "pdf": "https://arxiv.org/pdf/2511.10129", "abs": "https://arxiv.org/abs/2511.10129", "authors": ["Mouhammed Achhab", "Pierre Jehel", "Fabrice Gatuingt"], "title": "Accelerating the Serviceability-Based Design of Reinforced Concrete Rail Bridges under Geometric Uncertainties induced by unforeseen events: A Surrogate Modeling approach", "categories": ["math.NA", "physics.class-ph", "physics.data-an"], "comment": null, "summary": "Reinforced concrete rail bridges are essential components of railway infrastructure, where reliability, durability, and adaptability are key design priorities. However, the design process is often complicated by uncertainties stemming from unforeseen construction constraints, such as the need to reposition piers or alter geometric characteristics. These design adaptations can lead to repeated redesigns, added costs, and project delays if not anticipated in the early design stages, as well as significant computational overhead when using traditional finite element (FE) simulations. To address this and anticipate such unexpected events, this study adopts surrogate modeling as an efficient probabilistic design approach. This methodology integrates key geometric parameters as random variables, capturing the uncertainties that may arise during the design and construction phases and propagating them on the bridge's performance functions. By doing so, we aim to enable the efficient exploration of a large number of design scenarios with minimal reliance on time-consuming finite element (FE) simulations, represent the performance functions of a reinforced concrete bridge as a function of our variable design parameters, and classify the overall design scenarios into failure and safe scenarios In this study, a four-span reinforced concrete bridge deck is modeled using a multi-fiber finite element approach in Cast3M software. This FE model is used to generate the required design of experiments to train the surrogate models. Within this framework, a comparative performance assessment is conducted to evaluate the performance of the Kriging surrogate against alternative methods, including polynomial chaos expansion (implemented in UQLab) and support vector regression (SVR). This methodology supports early-stage uncertainty-informed design, enhancing the robustness and adaptability of reinforced concrete rail bridges in the face of practical constraints and changing site conditions.", "AI": {"tldr": "Surrogate modeling approach for reinforced concrete rail bridges to handle design uncertainties and avoid repeated redesigns, comparing Kriging, polynomial chaos expansion, and support vector regression methods.", "motivation": "To address uncertainties in bridge design from unforeseen construction constraints (e.g., pier repositioning, geometric changes) that cause repeated redesigns, added costs, delays, and computational overhead from traditional FE simulations.", "method": "Multi-fiber finite element modeling in Cast3M software to generate design experiments, with surrogate modeling integrating geometric parameters as random variables to propagate uncertainties on bridge performance functions.", "result": "Comparative assessment shows surrogate models enable efficient exploration of design scenarios with minimal FE simulations, representing performance functions and classifying designs into failure/safe categories.", "conclusion": "Surrogate modeling supports early-stage uncertainty-informed design, enhancing robustness and adaptability of reinforced concrete rail bridges against practical constraints and changing site conditions."}}
{"id": "2511.09859", "pdf": "https://arxiv.org/pdf/2511.09859", "abs": "https://arxiv.org/abs/2511.09859", "authors": ["Shreya Shukla", "Abhijith Jayakumar", "Andrey Y. Lokhov"], "title": "Learning of Statistical Field Theories", "categories": ["cond-mat.stat-mech", "physics.comp-ph", "quant-ph"], "comment": null, "summary": "Recovering microscopic couplings directly from data provides a route to solving the inverse problem in statistical field theories, one that complements the traditional-often computationally intractable-forward approach of predicting observables from an action or Hamiltonian. Here, we propose an approach for the inverse problem that uniformly accommodates systems with discrete, continuous, and hybrid variables. We demonstrate accurate parameter recovery in several benchmark systems-including Wegner's Ising gauge theory, $\u03c6^4$ theory, Schwinger and Sine-Gordon models, and mixed spin-gauge systems, and show how iterating the procedure under coarse-graining reconstructs full non-perturbative renormalization-group flows. This gives direct access to phase boundaries, fixed points, and emergent interactions without relying on perturbation theory. We also address a realistic setting where full gauge configurations may be unavailable, and reformulate learning algorithms for multiple field theories so that they are recovered directly using observables such as correlations from scattering data or quantum simulators. We anticipate that our methodology will find widespread use in practical learning of field theories in strongly coupled regimes where analytical tools might fail.", "AI": {"tldr": "Proposes an inverse approach to recover microscopic couplings from data for statistical field theories, accommodating discrete, continuous, and hybrid variables. Demonstrates accurate parameter recovery in various benchmark systems and reconstructs renormalization-group flows.", "motivation": "To solve the inverse problem in statistical field theories by recovering microscopic couplings directly from data, complementing the computationally intractable forward approach of predicting observables from actions or Hamiltonians.", "method": "Develops an approach that uniformly handles systems with discrete, continuous, and hybrid variables. Iterates the procedure under coarse-graining to reconstruct full non-perturbative renormalization-group flows. Also addresses scenarios where full gauge configurations are unavailable by reformulating learning algorithms using observables like correlations.", "result": "Accurate parameter recovery demonstrated in benchmark systems including Wegner's Ising gauge theory, \u03c6\u2074 theory, Schwinger and Sine-Gordon models, and mixed spin-gauge systems. Successfully reconstructs phase boundaries, fixed points, and emergent interactions without relying on perturbation theory.", "conclusion": "The methodology enables practical learning of field theories in strongly coupled regimes where analytical tools might fail, providing direct access to phase boundaries, fixed points, and emergent interactions through data-driven inverse approaches."}}
{"id": "2511.10438", "pdf": "https://arxiv.org/pdf/2511.10438", "abs": "https://arxiv.org/abs/2511.10438", "authors": ["P. L. Guillon", "G. Dif-Pradalier", "Y. Sarazin", "D. W. Hughes", "\u00d6. D. G\u00fcrcan"], "title": "Self-organisation through layering of $\u03b2$-plane like turbulence in plasmas and geophysical fluids", "categories": ["physics.plasm-ph", "physics.flu-dyn"], "comment": null, "summary": "Staircase formation and layering is studied in simplified, potential vorticity conserving models of plasmas and geophysical fluids, by investigating turbulent self-organisation and nonlinear saturation with different mechanisms of free energy production -- forcing or linear instability -- and with standard or modified zonal flow responses. To this end, staircase formation in both the standard and modified Charney-Hasegawa-Mima equations with stochastic forcing, along with two different simple instability driven models -- one from a plasma and from a geophysical context -- are studied and compared. In these studies, it is observed that $\u03b2$-plane turbulence that does not distinguish between zonal and non-zonal perturbations (i.e., standard zonal response) gradually forms large-scale, elliptic zonal structures that merge progressively, regardless of whether it is driven by forcing (though it should be slow enough to allow wave couplings) or by the baroclinic instability, using for example a two-layer model. Conversely, the plasma system, with its modified zonal response, can rapidly form straight, stationary jets of well-defined size, again regardless of the way it is driven: by stochastic forcing or by the dissipative drift instability. Furthermore, the instability-driven plasma system exhibits a phase transition between a zonal flow dominated state and an eddy dominated state. In both states, saturation is possible without large-scale friction.", "AI": {"tldr": "The paper studies staircase formation and layering in plasma and geophysical fluid models, comparing turbulent self-organization with different energy production mechanisms (forcing vs. linear instability) and zonal flow responses.", "motivation": "To understand how different mechanisms of free energy production and zonal flow responses affect turbulent self-organization and staircase formation in plasmas and geophysical fluids.", "method": "Comparative study using standard and modified Charney-Hasegawa-Mima equations with stochastic forcing, and two instability-driven models (plasma and geophysical) to analyze staircase formation and nonlinear saturation.", "result": "\u03b2-plane turbulence with standard zonal response gradually forms large-scale elliptic zonal structures that merge progressively, while plasma systems with modified zonal response rapidly form straight stationary jets of defined size. Plasma systems also exhibit phase transitions between zonal flow and eddy dominated states.", "conclusion": "Different zonal flow responses lead to distinct staircase formation patterns - gradual merging of elliptic structures in geophysical systems versus rapid formation of straight jets in plasma systems, with plasma systems showing phase transitions between different turbulent states."}}
{"id": "2511.10104", "pdf": "https://arxiv.org/pdf/2511.10104", "abs": "https://arxiv.org/abs/2511.10104", "authors": ["Lionel Roques"], "title": "Explicit pulsating fronts and minimal speeds in periodic Fisher-KPP equations", "categories": ["math.AP"], "comment": null, "summary": "We study a Fisher-KPP equation with spatially periodic diffusion and reaction terms. We identify a class of periodic media for which the equation admits an explicit, closed-form solution. Through a nonlinear change of variables, the problem is reduced to the homogeneous Fisher-KPP equation, allowing us to construct an exact pulsating traveling front that connects the positive periodic stationary state to 0. We also derive an explicit expression for the asymptotic spreading speed and establish new asymptotic and comparison results.", "AI": {"tldr": "Exact pulsating traveling front solutions derived for Fisher-KPP equation with periodic diffusion and reaction terms using nonlinear transformation to homogeneous case.", "motivation": "To find explicit closed-form solutions for Fisher-KPP equations with spatially periodic coefficients, which are typically difficult to solve analytically.", "method": "Used a nonlinear change of variables to reduce the periodic problem to the homogeneous Fisher-KPP equation, enabling construction of exact pulsating traveling fronts.", "result": "Successfully identified a class of periodic media admitting explicit solutions, derived exact pulsating fronts connecting periodic stationary states to zero, and obtained explicit spreading speed expression.", "conclusion": "The nonlinear transformation method provides a powerful approach for constructing exact solutions to periodic reaction-diffusion equations, yielding new analytical results for spreading speeds and comparison properties."}}
{"id": "2511.10214", "pdf": "https://arxiv.org/pdf/2511.10214", "abs": "https://arxiv.org/abs/2511.10214", "authors": ["Federica Ferrarese"], "title": "Control strategies for magnetized plasma: a polar coordinates framework", "categories": ["math.NA"], "comment": null, "summary": "In this work, we provide an overview of various control strategies aimed at steering plasma toward desired configurations using an external magnetic field. From a modeling perspective, we focus on the Vlasov equation in a two-dimensional bounded domain, accounting for both a self-induced electric field and a strong external magnetic field. The results are presented in a polar coordinate framework, which is particularly well-suited for simulating toroidal devices such as Tokamaks and Stellarators. A key feature of the proposed control strategies is their feedback mechanism, which is based on an instantaneous prediction of the discretized system. Finally, different numerical experiments in the two-dimensional polar coordinate setting demonstrate the effectiveness of the approaches.", "AI": {"tldr": "Overview of magnetic field control strategies for plasma steering using Vlasov equation modeling in 2D polar coordinates with feedback mechanisms.", "motivation": "To develop effective control strategies for steering plasma toward desired configurations in toroidal devices like Tokamaks and Stellarators using external magnetic fields.", "method": "Modeling using Vlasov equation in 2D bounded domain with self-induced electric field and strong external magnetic field, presented in polar coordinate framework with feedback control based on instantaneous prediction of discretized system.", "result": "Numerical experiments in 2D polar coordinate setting demonstrate the effectiveness of the proposed control approaches.", "conclusion": "The feedback-based control strategies using magnetic fields are effective for plasma steering in toroidal confinement devices."}}
{"id": "2511.09896", "pdf": "https://arxiv.org/pdf/2511.09896", "abs": "https://arxiv.org/abs/2511.09896", "authors": ["Marco Bernardi"], "title": "Quantum Period-Finding using One-Qubit Reduced Density Matrices", "categories": ["quant-ph", "physics.comp-ph"], "comment": null, "summary": "The quantum period-finding (QPF) algorithm can compute the period of a function exponentially faster than the best-known classical algorithm. In standard QPF, the output state has a primary contribution from $r$ high-probability bit strings, where $r$ is the period. Measurement of this state, combined with continued fraction analysis, reveals the unknown period. Here, we explore a different approach to QPF, where the period is obtained from single-qubit quantities $-$ specifically, the set of one-qubit reduced density matrices (1-RDMs) $-$ rather than the output bit strings of the entire quantum circuit. Using state-vector simulations, we compute the 1-RDMs of the QPF circuit for a generic periodic function. Analysis of these 1-RDMs as a function of period reveals distinctive patterns, which allows us to obtain the unknown period from the 1-RDMs using a numerical root-finding approach. Our results show that the 1-RDMs $-$ a set of $O(n)$ one-qubit marginals $-$ contain enough information to reconstruct the period, which is typically obtained by sampling the space of $O(2^n)$ bit strings. Conceptually, this can be viewed as a \"compression\" of the information in the QPF algorithm, which enables period-finding from $n$ one-qubit marginals. Our results motivate the development of approximate simulations of reduced density matrices to design novel period-finding algorithms.", "AI": {"tldr": "The paper proposes a novel approach to quantum period-finding that extracts the period from one-qubit reduced density matrices instead of measuring output bit strings, achieving information compression from O(2^n) to O(n) quantities.", "motivation": "To explore whether single-qubit reduced density matrices contain sufficient information to determine the period in quantum period-finding algorithms, potentially enabling more efficient period extraction.", "method": "Used state-vector simulations to compute one-qubit reduced density matrices (1-RDMs) of QPF circuits for periodic functions, then applied numerical root-finding on distinctive patterns in these 1-RDMs to extract the period.", "result": "Successfully demonstrated that 1-RDMs contain distinctive patterns that allow period reconstruction, showing that O(n) one-qubit marginals suffice instead of sampling O(2^n) bit strings.", "conclusion": "The 1-RDMs provide a compressed representation of period information, motivating development of approximate simulations for designing novel period-finding algorithms based on reduced density matrices."}}
{"id": "2511.10275", "pdf": "https://arxiv.org/pdf/2511.10275", "abs": "https://arxiv.org/abs/2511.10275", "authors": ["Ida Svenningsson", "Emiliya Yordanova", "Yuri V. Khotyaintsev", "Mats Andr\u00e9", "Giulia Cozzani", "Alexandros Chasapis", "Steven J. Schwartz"], "title": "Electron Heat Flux and Whistler Instability in the Earth's Magnetosheath", "categories": ["physics.space-ph", "astro-ph.EP", "physics.plasm-ph"], "comment": "7 pages, 3 figures (supplementary: 2 pages, 4 figures). Submitted to Physical Review Letters", "summary": "Despite heat flux's role in regulating energy conversion in collisionless plasmas, its properties and evolution in the magnetosheath downstream of the Earth's bow shock are scarcely explored. We use MMS in situ measurements to quantify and characterize the electron heat flux in the magnetosheath. We find that the heat flux is shaped by the magnetosheath magnetic field as it drapes around the magnetosphere. While it is affected by solar wind upstream conditions and increases with magnetic field strength, it is not substantially changed by local magnetosheath processes. Also, the heat flux is limited by whistler instability thresholds.", "AI": {"tldr": "Analysis of electron heat flux in Earth's magnetosheath using MMS measurements, showing it's shaped by magnetic field draping around magnetosphere and limited by whistler instability thresholds.", "motivation": "Heat flux plays a crucial role in regulating energy conversion in collisionless plasmas, but its properties and evolution in the magnetosheath downstream of Earth's bow shock remain poorly understood.", "method": "Used MMS (Magnetospheric Multiscale) in situ measurements to quantify and characterize electron heat flux in the magnetosheath.", "result": "Heat flux is shaped by magnetosheath magnetic field draping around magnetosphere, affected by solar wind upstream conditions and increases with magnetic field strength, but not substantially changed by local magnetosheath processes. Heat flux is limited by whistler instability thresholds.", "conclusion": "Electron heat flux in magnetosheath is primarily governed by magnetic field configuration and upstream solar wind conditions, with whistler instabilities acting as limiting factors, rather than being significantly modified by local processes."}}
{"id": "2511.10199", "pdf": "https://arxiv.org/pdf/2511.10199", "abs": "https://arxiv.org/abs/2511.10199", "authors": ["Vladimir Bobkov", "Mieko Tanaka"], "title": "On Rayleigh quotients connected to $p$-Laplace equations with polynomial nonlinearities", "categories": ["math.AP"], "comment": "40 pages, 5 figure", "summary": "Let $\u03a9$ be a bounded open set and $p,q,r>1$. The main observation of the present work is the following: $W_0^{1,p}(\u03a9)$-solutions of the equation $-\u0394_p u = \u03bc|u|^{q-2}u + |u|^{r-2}u$ parameterized by $\u03bc$ are in bijection with properly normalized critical points of the $0$-homogeneous Rayleigh type quotient $R_\u03b1(u)=\\|\\nabla u\\|_p^p/ (\\|u\\|_q^{\u03b1p} \\|u\\|_r^{p-\u03b1p})$ parameterized by $\u03b1$. We study this bijection and properties of $R_\u03b1$ for various relations between $p,q,r$. In particular, for the generalized convex-concave problem (the case $q<p<r$) the bijection allows to provide the existence and characterization of all degenerate solutions corresponding to the inflection point of the fibred energy functional: they are critical points of $R_\u03b1$ exclusively with $\u03b1= (r-p)/(r-q)$. In the subhomogeneous case $q<r \\leq p$ and under additional assumptions on $\u03a9$, the ground state level of $R_\u03b1$ is simple and isolated, and minimizers of $R_\u03b1$ exhaust the whole set of sign-constant solutions of the corresponding equation. In the superhomogeneous case $p < q<r$, there are no sign-changing critical points in a vicinity of the ground state level of $R_\u03b1$.", "AI": {"tldr": "The paper establishes a bijection between solutions of a p-Laplacian equation and critical points of a 0-homogeneous Rayleigh quotient, studying this relationship for different parameter regimes including generalized convex-concave, subhomogeneous, and superhomogeneous cases.", "motivation": "To understand the connection between solutions of nonlinear p-Laplacian equations and critical points of normalized Rayleigh quotients, particularly for characterizing degenerate solutions and ground states in various parameter regimes.", "method": "The authors introduce a 0-homogeneous Rayleigh quotient R_\u03b1(u) and establish a bijection between W_0^{1,p}(\u03a9)-solutions of the p-Laplacian equation and properly normalized critical points of R_\u03b1. They analyze this bijection for different relationships between parameters p, q, r.", "result": "For generalized convex-concave case (q<p<r), degenerate solutions correspond to critical points of R_\u03b1 with \u03b1=(r-p)/(r-q). In subhomogeneous case (q<r\u2264p), ground state level is simple and isolated, and minimizers exhaust sign-constant solutions. In superhomogeneous case (p<q<r), no sign-changing critical points exist near ground state level.", "conclusion": "The bijection between p-Laplacian solutions and critical points of the Rayleigh quotient provides a powerful framework for characterizing solution structures across different parameter regimes, with specific results for degenerate solutions, ground states, and sign-changing behavior."}}
{"id": "2511.10242", "pdf": "https://arxiv.org/pdf/2511.10242", "abs": "https://arxiv.org/abs/2511.10242", "authors": ["Ruizhi Wang", "Weibing Deng"], "title": "A Stabilized Unfitted Space-time Finite Element Method for Parabolic Problems on Moving Domains", "categories": ["math.NA"], "comment": null, "summary": "This paper presents a space-time finite element method (FEM) based on an unfitted mesh for solving parabolic problems on moving domains. Unlike other unfitted space-time finite element approaches that commonly employ the discontinuous Galerkin (DG) method for time-stepping, the proposed method employs a fully coupled space-time discretization. To stabilize the time-advection term, the streamline upwind Petrov-Galerkin (SUPG) scheme is applied in the temporal direction. A ghost penalty stabilization term is further incorporated to mitigate the small cut issue, thereby ensuring the well-conditioning of the stiffness matrix. Moreover, an a priori error estimate is derived in a discrete energy norm, which achieves an optimal convergence rate with respect to the mesh size. In particular, a space-time Poincare-Friedrichs inequality is established to support the condition number analysis. Several numerical examples are provided to validate the theoretical findings.", "AI": {"tldr": "A space-time FEM using unfitted meshes for parabolic problems on moving domains, featuring SUPG stabilization for time-advection and ghost penalty for small cut issues, with optimal convergence rates proven.", "motivation": "To develop a more efficient and stable space-time finite element method for parabolic problems on moving domains that avoids the limitations of discontinuous Galerkin time-stepping approaches.", "method": "Unfitted space-time FEM with fully coupled discretization, SUPG stabilization for temporal advection, and ghost penalty stabilization to handle small cut elements and ensure well-conditioned matrices.", "result": "The method achieves optimal convergence rates with respect to mesh size, supported by a priori error estimates in discrete energy norm and space-time Poincare-Friedrichs inequality for condition number analysis.", "conclusion": "The proposed unfitted space-time FEM with SUPG and ghost penalty stabilizations is effective for parabolic problems on moving domains, with theoretical guarantees and numerical validation demonstrating its performance."}}
{"id": "2511.09943", "pdf": "https://arxiv.org/pdf/2511.09943", "abs": "https://arxiv.org/abs/2511.09943", "authors": ["Bimal Gaudel", "Robert G. Adam", "Ajay Melekamburath", "Conner Masteran", "Nakul Teke", "Azam Besharatnik", "Andreas K\u00f6hn", "Edward F. Valeev"], "title": "SeQuant Framework for Symbolic and Numerical Tensor Algebra. I. Core Capabilities", "categories": ["cs.MS", "cs.SC", "physics.chem-ph", "physics.comp-ph", "quant-ph"], "comment": null, "summary": "SeQuant is an open-source library for symbolic algebra of tensors over commutative (scalar) and non-commutative (operator) rings. The key innovation supporting most of its functionality is a graph-theoretic tensor network (TN) canonicalizer that can handle tensor networks with symmetries faster than their standard group-theoretic counterparts. The TN canonicalizer is used for routine simplification of conventional tensor expressions, for optimizing application of Wick's theorem (used to canonicalize products of tensors over operator fields), and for manipulation of the intermediate representation leading to the numerical evaluation. Notable features of SeQuant include support for noncovariant tensor networks (which often arise from tensor decompositions) and for tensors with modes that depend parametrically on indices of other tensor modes (such dependencies between degrees of freedom are naturally viewed as nesting of tensors, \"tensors of tensors\" arising in block-wise data compressions in data science and modern quantum simulation). SeQuant blurs the line between pure symbolic manipulation/code generation and numerical evaluation by including compiler-like components to optimize and directly interpret tensor expressions using external numerical tensor algebra frameworks. The SeQuant source code is available at https://github.com/ValeevGroup/SeQuant.", "AI": {"tldr": "SeQuant is an open-source library for symbolic tensor algebra that introduces a graph-theoretic tensor network canonicalizer for faster handling of symmetric tensor networks, supporting both commutative and non-commutative rings.", "motivation": "To provide efficient symbolic manipulation of tensor expressions with symmetries, which is challenging with standard group-theoretic methods, and to bridge the gap between symbolic manipulation and numerical evaluation.", "method": "Uses a graph-theoretic tensor network canonicalizer that handles symmetric tensor networks faster than group-theoretic approaches. Supports noncovariant tensor networks and tensors with parametrically dependent modes. Includes compiler-like components for optimization and direct interpretation of tensor expressions.", "result": "Developed a functional open-source library capable of simplifying conventional tensor expressions, optimizing Wick's theorem applications, and manipulating intermediate representations for numerical evaluation. Supports complex tensor structures including nested tensors.", "conclusion": "SeQuant successfully bridges symbolic tensor algebra and numerical computation through innovative graph-theoretic canonicalization and compiler-like optimization, providing a versatile tool for tensor manipulation in various scientific domains."}}
{"id": "2511.10476", "pdf": "https://arxiv.org/pdf/2511.10476", "abs": "https://arxiv.org/abs/2511.10476", "authors": ["Moncef Derouich", "Saleh Qutub"], "title": "Collisional and magnetic effects on the polarization of the solar oxygen infrared triplet", "categories": ["astro-ph.SR", "physics.atom-ph", "physics.plasm-ph"], "comment": "Accepted for publication in Astronomy \\& Astrophysics", "summary": "Context: The scattering polarization of the infrared (IR) triplet of neutral oxygen (O\\,\\textsc{i}) near 777\\,nm provides a powerful diagnostic of solar atmospheric conditions. However, interpreting such polarization requires a rigorous treatment of isotropic depolarizing collisions between O\\,\\textsc{i} atoms and neutral hydrogen.\n  Aims: We aim to investigate the combined effects of collisional and magnetic depolarization in shaping the alignment of O\\,\\textsc{i} levels (and thus the polarization of the O\\,\\textsc{i} IR triplet).\n  Methods: We compute, for the first time, a comprehensive set of collisional depolarization and polarization transfer rates for the relevant O\\,\\textsc{i} energy levels. These rates are incorporated into a multi-level atomic model, and the statistical equilibrium equations (SEE) are solved to quantify the impact of collisions and magnetic fields on atomic alignment.\n  Results: Our calculations indicate that elastic collisions with neutral hydrogen, together with the Hanle effect of turbulent magnetic fields stronger than about 20 G, efficiently suppress the bulk of the atomic alignment in deep photospheric conditions where hydrogen densities exceed $n_{\\mathrm{H}} \\sim 10^{16}$ cm$^{-3}$. In the chromosphere, however, the lower hydrogen density weakens collisional depolarization, allowing polarization to persist.\n  Conclusions: Our results are consistent with a chromospheric origin for the linear polarization signals of the O I IR triplet. Future studies should combine accurate non-LTE radiative transfer with reliable collisional rates in order to achieve fully consistent modeling.", "AI": {"tldr": "Collisional and magnetic depolarization effects on O I IR triplet polarization show that atomic alignment is suppressed in deep photosphere but persists in chromosphere due to lower hydrogen density.", "motivation": "To understand how collisional and magnetic depolarization shape the alignment of O I levels and polarization of the O I IR triplet, which is important for solar atmospheric diagnostics.", "method": "First computation of comprehensive collisional depolarization and polarization transfer rates for O I energy levels, incorporated into multi-level atomic model and solved statistical equilibrium equations.", "result": "Elastic collisions with neutral hydrogen and Hanle effect of turbulent magnetic fields >20G suppress atomic alignment in deep photosphere (n_H > 10^16 cm^-3), but polarization persists in chromosphere due to lower hydrogen density.", "conclusion": "Results support chromospheric origin for O I IR triplet linear polarization; future work should combine accurate non-LTE radiative transfer with reliable collisional rates for consistent modeling."}}
{"id": "2511.10358", "pdf": "https://arxiv.org/pdf/2511.10358", "abs": "https://arxiv.org/abs/2511.10358", "authors": ["Zhiqiang Wan", "Heng Zhang"], "title": "Observable sets for free Schr\u00f6dinger equation on combinatorial graphs", "categories": ["math.AP", "math.CO"], "comment": "21 pages", "summary": "We study observability for the free Schr\u00f6dinger equation $\\partial_t u = i\u0394u$ on combinatorial graphs $G=(\\mathcal{V},\\mathcal{E})$. A subset $E\\subset\\mathcal{V}$ is observable at time $T>0$ if there exists $C(T,E)>0$ such that for all $u_0\\in l^2(\\mathcal{V})$, $$ \\|u_0\\|_{l^2(\\mathcal{V})}^2 \\le C(T,E)\\int_0^T \\|e^{it\u0394}u_0\\|_{l^2(E)}^2\\,dt. $$\n  On the one-dimensional lattice $\\mathbb{Z}$ we obtain a sharp threshold for thick sets: if $E\\subset\\mathbb{Z}$ is $\u03b3$-thick with $\u03b3\\geq1/2$, then $E$ is observable at some time; conversely, for every $\u03b3<1/2$ there exists a $\u03b3$-thick set that is not observable at any time. This critical threshold marks the exact point where the discrete lattice departs from the real line: on the lattice it must be attained, whereas on $\\R$ any $\u03b3$-thick set with $\u03b3>0$ already suffices.\n  On $\\mathbb{Z}^d$ we show that complements of finite sets are observable at any time $T>0$. This is a similar result to Euclidean space $\\R^d$: any set that contains the exterior of a finite ball is observable at any time, in analogy with the free Schr\u00f6dinger flow on $\\mathbb{R}^d$.\n  For finite graphs we give an equivalent characterization of observability in terms of the zero sets of Laplacian eigenfunctions. As an application, we construct unobservable sets of large density on discrete tori, in contrast with the continuous torus $\\mathbb{T}^d$, where every nonempty open set is observable.", "AI": {"tldr": "This paper studies observability for the free Schr\u00f6dinger equation on combinatorial graphs, establishing sharp thresholds for thick sets on 1D lattices, showing finite set complements are observable on higher-dimensional lattices, and characterizing observability on finite graphs with applications to discrete tori.", "motivation": "To understand how observability properties of the Schr\u00f6dinger equation differ between discrete combinatorial graphs and continuous spaces, particularly identifying critical thresholds where discrete and continuous behaviors diverge.", "method": "Mathematical analysis using spectral theory and combinatorial graph theory, studying the observability inequality for the free Schr\u00f6dinger equation on various graph structures including 1D and d-dimensional lattices, and finite graphs.", "result": "Found a sharp threshold of \u03b3=1/2 for thick sets on 1D lattice \u2124; showed that complements of finite sets are observable on \u2124^d; provided equivalent characterization for finite graphs; constructed unobservable sets of large density on discrete tori.", "conclusion": "Discrete graphs exhibit fundamentally different observability properties than continuous spaces, with critical thresholds that must be attained in discrete settings but not in continuous ones, highlighting the structural differences between discrete and continuous Schr\u00f6dinger dynamics."}}
{"id": "2511.10369", "pdf": "https://arxiv.org/pdf/2511.10369", "abs": "https://arxiv.org/abs/2511.10369", "authors": ["Caterina B. Leimer Saglio", "Mattia Corti", "Stefano Pagani", "Paola F. Antonietti"], "title": "A novel mathematical and computational framework of amyloid-beta triggered seizure dynamics in Alzheimer's disease", "categories": ["math.NA"], "comment": null, "summary": "The association of epileptic activity and Alzheimer's disease (AD) has been increasingly reported in both clinical and experimental studies, suggesting that amyloid-$\u03b2$ accumulation may directly affect neuronal excitability. Capturing these interactions requires a quantitative description that bridges the molecular alterations of AD with the fast electrophysiological dynamics of epilepsy. We introduce a novel mathematical model that extends the Barreto-Cressman ionic formulation by incorporating multiple mechanisms of calcium dysregulation induced by amyloid-$\u03b2$, including formation of $\\mathrm{Ca}^{2+}$-permeable pores, overactivation of voltage-gated $\\mathrm{Ca}^{2+}$ channels, and suppression of $\\mathrm{Ca}^{2+}$-sensitive potassium currents. The resulting ionic model is coupled with the monodomain equation and discretized using a $p$-adaptive discontinuous Galerkin method on polytopal meshes, providing an effective balance between efficiency and accuracy in capturing the sharp spatiotemporal electrical wavefronts associated with epileptiform discharges. Numerical simulations performed on idealized and realistic brain geometries demonstrate that progressive amyloid-\\textbeta{} accumulation leads to severe alterations in calcium homeostasis, increased neuronal hyperexcitability, and pathological seizure propagation. Specifically, high amyloid-$\u03b2$ concentrations produce secondary epileptogenic sources and spatially heterogeneous wavefronts, indicating that biochemical inhomogeneities play a critical role in shaping seizure dynamics. These results illustrate how multiscale modeling provides new mechanistic insights into the interplay between neurodegeneration and epilepsy in Alzheimer's disease.", "AI": {"tldr": "A mathematical model links Alzheimer's amyloid-\u03b2 pathology to epilepsy by incorporating calcium dysregulation mechanisms into neuronal excitability modeling, showing how amyloid-\u03b2 accumulation leads to seizure propagation.", "motivation": "To quantitatively describe the connection between Alzheimer's disease molecular alterations (amyloid-\u03b2 accumulation) and epilepsy's fast electrophysiological dynamics, as clinical evidence increasingly shows their association.", "method": "Extended Barreto-Cressman ionic model with amyloid-\u03b2-induced calcium dysregulation mechanisms, coupled with monodomain equation and discretized using p-adaptive discontinuous Galerkin method on polytopal meshes.", "result": "Progressive amyloid-\u03b2 accumulation causes severe calcium homeostasis alterations, increased neuronal hyperexcitability, pathological seizure propagation, secondary epileptogenic sources, and spatially heterogeneous wavefronts.", "conclusion": "Multiscale modeling provides mechanistic insights into neurodegeneration-epilepsy interplay in Alzheimer's disease, showing biochemical inhomogeneities critically shape seizure dynamics."}}
{"id": "2511.10378", "pdf": "https://arxiv.org/pdf/2511.10378", "abs": "https://arxiv.org/abs/2511.10378", "authors": ["Akiko Morimura", "Toyohiko Aiki"], "title": "An initial-boundary value problem describing moisture transport in porous media: existence of strong solutions and an error estimate for a finite volume scheme", "categories": ["math.AP", "math.NA"], "comment": "18 pages", "summary": "We consider an initial-boundary value problem motivated by a mathematical model of moisture transport in porous media. We establish the existence of strong solutions and provide an error estimate for the approximate solutions constructed by the finite volume method. In the proof of the error estimate, the Gagliardo--Nirenberg type inequality for the difference between a continuous function and a piecewise constant function plays an important role.", "AI": {"tldr": "Analysis of moisture transport in porous media using finite volume method with strong solution existence and error estimates.", "motivation": "To develop mathematical models for moisture transport in porous media and provide reliable numerical solutions.", "method": "Finite volume method for approximate solutions, using Gagliardo-Nirenberg type inequalities in error analysis.", "result": "Established existence of strong solutions and derived error estimates for the numerical approximations.", "conclusion": "The finite volume method is effective for solving moisture transport problems in porous media with rigorous error bounds."}}
{"id": "2511.10452", "pdf": "https://arxiv.org/pdf/2511.10452", "abs": "https://arxiv.org/abs/2511.10452", "authors": ["Gonzalo G. de Diego", "Georg Stadler"], "title": "Learning parameter-dependent shear viscosity from data, with application to sea and land ice", "categories": ["math.NA", "math.OC", "physics.flu-dyn", "physics.geo-ph"], "comment": null, "summary": "Complex physical systems which exhibit fluid-like behavior are often modeled as non-Newtonian fluids. A crucial element of a non-Newtonian model is the rheology, which relates inner stresses with strain-rates. We propose a framework for inferring rheological models from data that represents the fluid's effective viscosity with a neural network. By writing the rheological law in terms of tensor invariants and tailoring the network's properties, the inferred model satisfies key physical and mathematical properties, such as isotropic frame-indifference and existence of a convex potential of dissipation. Within this framework, we propose two approaches to learning a fluid's rheology: 1) a standard regression that fits the rheological model to stress data and 2) a PDE-constrained optimization method that infers rheological models from velocity data. For the latter approach, we combine finite element and machine learning libraries. We demonstrate the accuracy and robustness of our method on land and sea ice rheologies which also depend on external parameters. For land ice, we infer the temperature-dependent Glen's law and, for sea ice, the concentration-dependent shear component of the viscous-plastic model. For these two models, we explore the effects of large data errors. Finally, we infer an unknown concentration-dependent model that reproduces Lagrangian ice floe simulation data. Our method discovers a rheology that generalizes well outside of the training dataset and exhibits both shear-thickening and thinning behaviors depending on the concentrations.", "AI": {"tldr": "A framework for inferring rheological models from data using neural networks that satisfy physical constraints like frame-indifference and convex dissipation potential.", "motivation": "To develop data-driven methods for learning non-Newtonian fluid rheologies that automatically satisfy key physical principles, overcoming limitations of traditional empirical models.", "method": "Two approaches: 1) standard regression fitting rheological model to stress data, and 2) PDE-constrained optimization inferring rheology from velocity data by combining finite element and machine learning libraries with tensor invariants and tailored network properties.", "result": "Successfully inferred temperature-dependent Glen's law for land ice and concentration-dependent shear component of viscous-plastic model for sea ice. Method discovered unknown concentration-dependent rheology that generalizes well and exhibits both shear-thickening and thinning behaviors.", "conclusion": "The proposed framework provides accurate and robust data-driven inference of rheological models that satisfy physical constraints and can discover complex behaviors like shear-thickening/thinning from limited data."}}
{"id": "2511.10259", "pdf": "https://arxiv.org/pdf/2511.10259", "abs": "https://arxiv.org/abs/2511.10259", "authors": ["Han-Pu Liang", "Chuan-Nan Li", "Xin-Ru Tang", "Xun Xu", "Chen Qiu", "Qiu-Shi Huang", "Su-Huai Wei"], "title": "Effect of Concentration Fluctuations on Material Properties of Disordered Alloys", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Alloying compound AX with another compound BX is widely used to tune material properties. For disordered alloys, due to the lack of periodicity, it has been challenging to calculate and study their material properties. Special quasi-random structure (SQS) method has been developed and widely used to treat this issue by matching averaged atomic correlation functions to those of ideal random alloys, enabling accurate predictions of macroscopic material properties such as total energy and volume. However, in AxB1-x alloys, statistically allowed local concentration fluctuations can give rise to defect-like minority configurations, such as bulk-like AX or BX regions in the extreme, which could strongly affect calculation of some of the material properties such as semiconductor bandgap, if it is not defined properly, leading to significant discrepancies between theory and experiment. In this work, taking the bandgap as an example, we demonstrate that the calculated alloy bandgap can be significantly underestimated in standard SQS calculations when the SQS cell size is increased to improve the structural model and the bandgap is defined conventionally as the energy difference between the lowest unoccupied state and the highest occupied state, because the rare event motifs can lead to wavefunction localization and become the dominant factor in determining the \"bandgap\", contrary to experiment. To be consistent with experiment, we show that the bandgap of the alloy should be extracted from the majority configurations using a density-of-states fitting (DOSF) method. This DOSF approach resolves the long-standing issue of calculating electronic structure of disordered semiconductor alloys. Similar approaches should also be developed to treat material properties that depends on localized alloy wavefunctions.", "AI": {"tldr": "Standard SQS calculations underestimate semiconductor alloy bandgaps due to rare defect-like configurations. A DOSF method is proposed to extract bandgaps from majority configurations, resolving discrepancies with experiments.", "motivation": "Disordered alloys lack periodicity, making material property calculations challenging. SQS methods help but can underestimate bandgaps due to statistical fluctuations creating minority configurations that dominate calculations.", "method": "Proposed density-of-states fitting (DOSF) method to extract bandgaps from majority configurations rather than conventional energy difference between lowest unoccupied and highest occupied states.", "result": "DOSF approach resolves underestimation of alloy bandgaps in SQS calculations and provides results consistent with experimental measurements.", "conclusion": "DOSF method successfully addresses long-standing issues in calculating electronic structure of disordered semiconductor alloys. Similar approaches should be developed for other properties affected by localized wavefunctions."}}
{"id": "2511.10538", "pdf": "https://arxiv.org/pdf/2511.10538", "abs": "https://arxiv.org/abs/2511.10538", "authors": ["Jiajun Wang"], "title": "Restriction estimates for 2D surfaces of finite type 3 and applications to dispersive equations", "categories": ["math.AP"], "comment": "27 pages, 6 figures", "summary": "In this paper, we prove the restriction estimates for 2D surfaces S := {(xi1, xi2, xi1^3 +/- xi2^3) : (xi1, xi2) in [0,1]^2} by reducing to Guth's result on the perturbed paraboloid and Buschenhenke-Muller-Vargas's result on the perturbed hyperboloid. The method is based on the rescaling technique, developed in [LMZ21a]. Besides, we will use the estimates to give a better analysis for discrete nonlinear Schrodinger equations.", "AI": {"tldr": "Proves restriction estimates for 2D surfaces with cubic terms using reduction to known results on perturbed paraboloid and hyperboloid, with applications to discrete nonlinear Schr\u00f6dinger equations.", "motivation": "To establish restriction estimates for specific 2D surfaces with cubic coordinate terms, which have applications in analyzing discrete nonlinear Schr\u00f6dinger equations.", "method": "Reduces the problem to Guth's result on perturbed paraboloid and Buschenhenke-Muller-Vargas's result on perturbed hyperboloid, using rescaling technique from [LMZ21a].", "result": "Successfully proves restriction estimates for the surfaces S = {(\u03be\u2081, \u03be\u2082, \u03be\u2081\u00b3 \u00b1 \u03be\u2082\u00b3) : (\u03be\u2081, \u03be\u2082) \u2208 [0,1]\u00b2}.", "conclusion": "The established restriction estimates provide improved analytical tools for studying discrete nonlinear Schr\u00f6dinger equations."}}
{"id": "2511.10599", "pdf": "https://arxiv.org/pdf/2511.10599", "abs": "https://arxiv.org/abs/2511.10599", "authors": ["Jiarui Du", "Zhijian He"], "title": "The $L_p$-error rate for randomized quasi-Monte Carlo self-normalized importance sampling of unbounded integrands", "categories": ["math.NA"], "comment": null, "summary": "Self-normalized importance sampling (SNIS) is a fundamental tool in Bayesian inference when the posterior distribution involves an unknown normalizing constant. Although $L_1$-error (bias) and $L_2$-error (root mean square error) estimates of SNIS are well established for bounded integrands, results for unbounded integrands remain limited, especially under randomized quasi-Monte Carlo (RQMC) sampling. In this work, we derive $L_p$-error rate $(p\\ge1)$ for RQMC-based SNIS (RQMC-SNIS) estimators with unbounded integrands on unbounded domains. A key step in our analysis is to first establish the $L_p$-error rate for plain RQMC integration. Our results allow for a broader class of transport maps used to generate samples from RQMC points. Under mild function boundary growth conditions, we further establish \\(L_p\\)-error rate of order \\(\\mathcal{O}(N^{-\u03b2+ \u03b5})\\) for RQMC-SNIS estimators, where $\u03b5>0$ is arbitrarily small, $N$ is the sample size, and \\(\u03b2\\in (0,1]\\) depends on the boundary growth rate of the resulting integrand. Numerical experiments validate the theoretical results.", "AI": {"tldr": "This paper establishes L_p-error rates for RQMC-based self-normalized importance sampling estimators with unbounded integrands on unbounded domains, extending existing results that were limited to bounded integrands.", "motivation": "Current L1 and L2 error estimates for self-normalized importance sampling are well-established for bounded integrands but remain limited for unbounded integrands, especially under randomized quasi-Monte Carlo sampling.", "method": "The authors derive L_p-error rates for RQMC-SNIS estimators by first establishing L_p-error rates for plain RQMC integration, allowing for a broader class of transport maps to generate samples from RQMC points.", "result": "Under mild function boundary growth conditions, the paper establishes L_p-error rate of order O(N^{-\u03b2+\u03b5}) for RQMC-SNIS estimators, where \u03b5>0 is arbitrarily small, N is sample size, and \u03b2\u2208(0,1] depends on the boundary growth rate of the integrand.", "conclusion": "Numerical experiments validate the theoretical results, providing error rate guarantees for RQMC-based self-normalized importance sampling with unbounded integrands."}}
{"id": "2511.10342", "pdf": "https://arxiv.org/pdf/2511.10342", "abs": "https://arxiv.org/abs/2511.10342", "authors": ["Christos Charalambous"], "title": "Regret, Uncertainty, and Bounded Rationality in Norm-Driven Decisions", "categories": ["physics.soc-ph", "nlin.AO", "physics.comp-ph"], "comment": "22 pages, 16 figures", "summary": "This study introduces an agent-based model that explains how regret, uncertainty, and social norms interact to shape vaccination behavior during epidemics. The model integrates three behavioral mechanisms, anticipated regret, evolving norms, and uncertainty-dependent trust, within a unified learning framework. Grounded in psychology and behavioral economics, it captures how individuals make probabilistic choices influenced by material payoffs, fear, trust, and social approval. Simulations of the Susceptible-Infected-Recovered process show that collective outcomes are best when agents display an intermediate level of rationality; they deliberate enough to respond to risk but remain flexible enough to adapt, avoiding the instability of both random and overly rigid decision-making. Regret exerts a dual influence; moderate levels encourage adaptive self-correction, while excessive regret or greed destabilize choices. Uncertainty has a similarly non-linear effect; moderate ambiguity promotes caution, but too much uncertainty disrupts coordination. Social norms restore cooperation by compensating for incomplete information. Among them, personal norms drive behavior when individuals have clear information and moral confidence; injunctive norms, reflecting perceived approval, gain influence under uncertainty; and descriptive norms, based on observing others' actions, serve as informational cues that guide behavior when direct knowledge is limited. Overall, the model provides a psychologically grounded, computationally explicit account of how emotion, cognition, and social norms govern preventive behavior during epidemics.", "AI": {"tldr": "An agent-based model shows how regret, uncertainty, and social norms interact to shape vaccination behavior during epidemics, with optimal outcomes occurring at intermediate rationality levels.", "motivation": "To understand how psychological factors like regret, uncertainty, and social norms collectively influence vaccination decisions during epidemics, bridging behavioral economics and epidemiology.", "method": "Agent-based modeling integrating anticipated regret, evolving norms, and uncertainty-dependent trust within a unified learning framework, simulating Susceptible-Infected-Recovered processes.", "result": "Collective outcomes are best with intermediate rationality; moderate regret promotes adaptation while excessive regret destabilizes choices; moderate uncertainty encourages caution but too much disrupts coordination; social norms restore cooperation under uncertainty.", "conclusion": "The model provides a psychologically grounded computational account of how emotion, cognition, and social norms govern preventive epidemic behavior, with different norm types dominating under varying information conditions."}}
{"id": "2511.10579", "pdf": "https://arxiv.org/pdf/2511.10579", "abs": "https://arxiv.org/abs/2511.10579", "authors": ["Chi Hin Chan", "Magdalena Czubak", "Padi Fuster Aguilera"], "title": "Thin shell limit and the derivation of the viscosity operator on the ellipsoid", "categories": ["math.AP"], "comment": "35 pages;", "summary": "In this paper we derive four new candidates for an intrinsic viscosity operator on an ellipsoid by using the heuristic of the thin shell limit along the scaling direction of the ellipsoid. We show that the general method of the thin shell limit through the asymptotic expansion depends on the averaging method used. We consider both the homogeneous Navier and Hodge boundary conditions. We also obtain a geometric representation of these two boundary conditions.", "AI": {"tldr": "Derived four new intrinsic viscosity operators for ellipsoids using thin shell limit heuristic along scaling direction, showing dependence on averaging method and considering both Navier and Hodge boundary conditions.", "motivation": "To develop new intrinsic viscosity operators for ellipsoids by exploring the thin shell limit approach and understanding how different averaging methods affect the results.", "method": "Used thin shell limit heuristic along ellipsoid scaling direction, performed asymptotic expansion analysis, considered both homogeneous Navier and Hodge boundary conditions, and obtained geometric representations of boundary conditions.", "result": "Successfully derived four new candidates for intrinsic viscosity operators on ellipsoids, demonstrated that results depend on the averaging method used in the thin shell limit approach.", "conclusion": "The thin shell limit method for deriving intrinsic viscosity operators depends critically on the choice of averaging method, and geometric representations provide insights into Navier and Hodge boundary conditions for ellipsoids."}}
{"id": "2505.09763", "pdf": "https://arxiv.org/pdf/2505.09763", "abs": "https://arxiv.org/abs/2505.09763", "authors": ["Akiko Morimura", "Toyohiko Aiki"], "title": "Convergence of approximate solutions constructed by the finite volume method for the moisture transport model in porous media", "categories": ["math.AP", "math.NA"], "comment": "23pages", "summary": "We consider the initial-boundary value problem for a nonlinear parabolic equation in the one-dimensional interval. This problem is motivated by a mathematical model for moisture transport in porous media. We establish the uniqueness of weak solutions to the problem by using the dual equation method. Moreover, we prove the convergence of approximate solutions constructed with the finite volume method.", "AI": {"tldr": "Analysis of weak solution uniqueness and finite volume method convergence for a nonlinear parabolic equation modeling moisture transport in porous media.", "motivation": "The study is motivated by developing a mathematical model for moisture transport in porous media, addressing the initial-boundary value problem for a nonlinear parabolic equation in one dimension.", "method": "The authors use the dual equation method to establish uniqueness of weak solutions and analyze the convergence of approximate solutions constructed with the finite volume method.", "result": "The paper establishes the uniqueness of weak solutions to the nonlinear parabolic equation and proves the convergence of finite volume method approximations.", "conclusion": "The study successfully demonstrates both uniqueness of weak solutions and convergence of finite volume approximations for the nonlinear parabolic equation modeling moisture transport in porous media."}}
{"id": "2511.09807", "pdf": "https://arxiv.org/pdf/2511.09807", "abs": "https://arxiv.org/abs/2511.09807", "authors": ["Alberto Gonz\u00e1lez-Sanz", "Eustasio del Barrio", "Marcel Nutz"], "title": "Sample Complexity of Quadratically Regularized Optimal Transport", "categories": ["math.ST", "math.AP", "math.OC", "math.PR"], "comment": null, "summary": "It is well known that optimal transport suffers from the curse of dimensionality: when the prescribed marginals are approximated by i.i.d. samples, the convergence of the empirical optimal transport problem to the population counterpart slows exponentially with increasing dimension. Entropically regularized optimal transport (EOT) has become the standard bearer in many statistical applications as it avoids this curse. Indeed, EOT has parametric sample complexity, as has been shown in a series of works based on the smoothness of the EOT potentials or the strong concavity of the dual EOT problem. However, EOT produces full-support approximations to the (sparse) OT problem, leading to overspreading in applications, and is computationally unstable for small regularization parameters. The most popular alternative is quadratically regularized optimal transport (QOT), which penalizes couplings by $L^2$ norm instead of relative entropy. QOT produces sparse approximations of OT and is computationally stable. However, its potentials are not smooth (do not belong to a Donsker class) and its dual problem is not strongly concave, hence QOT is often assumed to suffer from the curse of dimensionality. In this paper, we show that QOT nevertheless has parametric sample complexity. More precisely, we establish central limit theorems for its dual potentials, optimal couplings, and optimal costs. Our analysis is based on novel arguments that focus on the regularity of the support of the optimal QOT coupling. Specifically, we establish a Lipschitz property of its sections and leverage VC theory to bound its statistical complexity. Our analysis also leads to gradient estimates of independent interest, including $C^{1,1}$ regularity of the population potentials.", "AI": {"tldr": "QOT has parametric sample complexity despite lacking smooth potentials and strong concavity, avoiding the curse of dimensionality through novel analysis of coupling support regularity.", "motivation": "To address overspreading in EOT and computational instability for small regularization, while showing QOT avoids the curse of dimensionality despite lacking smooth potentials and strong concavity.", "method": "Novel analysis focusing on regularity of QOT coupling support, establishing Lipschitz property of sections and leveraging VC theory to bound statistical complexity.", "result": "Established central limit theorems for QOT dual potentials, optimal couplings, and optimal costs, proving parametric sample complexity.", "conclusion": "QOT achieves parametric sample complexity and avoids the curse of dimensionality through its coupling support regularity, making it a viable alternative to EOT."}}
{"id": "2511.09902", "pdf": "https://arxiv.org/pdf/2511.09902", "abs": "https://arxiv.org/abs/2511.09902", "authors": ["Hossein Rouhvarzi", "Anastasis Kratsios"], "title": "Incremental Generation is Necessity and Sufficient for Universality in Flow-Based Modelling", "categories": ["cs.LG", "math.CA", "math.DS", "math.NA", "stat.ML"], "comment": null, "summary": "Incremental flow-based denoising models have reshaped generative modelling, but their empirical advantage still lacks a rigorous approximation-theoretic foundation. We show that incremental generation is necessary and sufficient for universal flow-based generation on the largest natural class of self-maps of $[0,1]^d$ compatible with denoising pipelines, namely the orientation-preserving homeomorphisms of $[0,1]^d$. All our guarantees are uniform on the underlying maps and hence imply approximation both samplewise and in distribution.\n  Using a new topological-dynamical argument, we first prove an impossibility theorem: the class of all single-step autonomous flows, independently of the architecture, width, depth, or Lipschitz activation of the underlying neural network, is meagre and therefore not universal in the space of orientation-preserving homeomorphisms of $[0,1]^d$. By exploiting algebraic properties of autonomous flows, we conversely show that every orientation-preserving Lipschitz homeomorphism on $[0,1]^d$ can be approximated at rate $\\mathcal{O}(n^{-1/d})$ by a composition of at most $K_d$ such flows, where $K_d$ depends only on the dimension. Under additional smoothness assumptions, the approximation rate can be made dimension-free, and $K_d$ can be chosen uniformly over the class being approximated. Finally, by linearly lifting the domain into one higher dimension, we obtain structured universal approximation results for continuous functions and for probability measures on $[0,1]^d$, the latter realized as pushforwards of empirical measures with vanishing $1$-Wasserstein error.", "AI": {"tldr": "Incremental flow-based denoising models are necessary and sufficient for universal approximation of orientation-preserving homeomorphisms on [0,1]^d, with impossibility for single-step flows and provable approximation rates for multi-step compositions.", "motivation": "To establish a rigorous approximation-theoretic foundation for incremental flow-based denoising models, addressing the empirical advantage that lacks theoretical justification.", "method": "Using topological-dynamical arguments and algebraic properties of autonomous flows, the paper proves impossibility for single-step flows and shows approximation via compositions of multiple flows with dimension-dependent rates.", "result": "Single-step autonomous flows are meagre and not universal, while multi-step compositions can approximate orientation-preserving Lipschitz homeomorphisms at rate O(n^{-1/d}) with dimension-dependent constant K_d. Dimension-free rates possible under smoothness assumptions.", "conclusion": "Incremental generation is fundamentally necessary for universal flow-based modeling, with provable approximation guarantees both for functions and probability measures via structured lifting approaches."}}
{"id": "2511.09963", "pdf": "https://arxiv.org/pdf/2511.09963", "abs": "https://arxiv.org/abs/2511.09963", "authors": ["Iasson Karafyllis", "Dionysis Theodosis", "Miroslav Krstic"], "title": "The Age-Structured Chemostat with Substrate Dynamics as a Control System", "categories": ["math.OC", "eess.SY", "math.AP", "q-bio.PE"], "comment": "32 pages", "summary": "In this work we study an age-structured chemostat model with a renewal boundary condition and a coupled substrate equation. The model is nonlinear and consists of a hyperbolic partial differential equation and an ordinary differential equation with nonlinear, nonlocal terms appearing both in the ordinary differential equation and the boundary condition. Both differential equations contain a non-negative control input, while the states of the model are required to be positive. Under an appropriate weak solution framework, we determine the state space and the input space for this model. We prove global existence and uniqueness of solutions for all admissible initial conditions and all allowable control inputs. To this purpose we employ a combination of Banach's fixed-point theorem with implicit solution formulas and useful solution estimates. Finally, we show that the age-structured chemostat model gives a well-defined control system on a metric space.", "AI": {"tldr": "Analysis of an age-structured chemostat model with renewal boundary conditions and coupled substrate dynamics, proving global existence and uniqueness of solutions for all admissible controls and establishing it as a well-defined control system.", "motivation": "To study a nonlinear age-structured chemostat model with coupled substrate dynamics and renewal boundary conditions, establishing a rigorous mathematical framework for analyzing this complex biological system with control inputs.", "method": "Employed a weak solution framework combining Banach's fixed-point theorem with implicit solution formulas and solution estimates to prove global existence and uniqueness for all admissible initial conditions and control inputs.", "result": "Successfully determined the state and input spaces, proved global existence and uniqueness of solutions, and established the model as a well-defined control system on a metric space.", "conclusion": "The age-structured chemostat model with renewal boundary conditions and coupled substrate dynamics forms a mathematically rigorous control system with well-defined solution properties for all admissible controls."}}
{"id": "2511.10058", "pdf": "https://arxiv.org/pdf/2511.10058", "abs": "https://arxiv.org/abs/2511.10058", "authors": ["Shiqi Chen", "Xuesong Chen"], "title": "An inexact semismooth Newton-Krylov method for semilinear elliptic optimal control problem", "categories": ["math.OC", "math.NA"], "comment": "17 pages, 3 figures", "summary": "An inexact semismooth Newton method has been proposed for solving semi-linear elliptic optimal control problems in this paper. This method incorporates the generalized minimal residual (GMRES) method, a type of Krylov subspace method, to solve the Newton equations and utilizes nonmonotonic line search to adjust the iteration step size. The original problem is reformulated into a nonlinear equation through variational inequality principles and discretized using a second-order finite difference scheme. By leveraging slanting differentiability, the algorithm constructs semismooth Newton directions and employs GMRES method to inexactly solve the Newton equations, significantly reducing computational overhead. A dynamic nonmonotonic line search strategy is introduced to adjust stepsizes adaptively, ensuring global convergence while overcoming local stagnation. Theoretical analysis demonstrates that the algorithm achieves superlinear convergence near optimal solutions when the residual control parameter $\u03b7_k$ approaches to 0. Numerical experiments validate the method's accuracy and efficiency in solving semilinear elliptic optimal control problems, corroborating theoretical insights.", "AI": {"tldr": "An inexact semismooth Newton method with GMRES solver and nonmonotonic line search for semi-linear elliptic optimal control problems, achieving superlinear convergence.", "motivation": "To develop an efficient numerical method for solving semi-linear elliptic optimal control problems that reduces computational overhead while ensuring global convergence.", "method": "Reformulates the problem into nonlinear equations using variational inequalities, uses second-order finite difference discretization, constructs semismooth Newton directions with slanting differentiability, employs GMRES for inexact Newton equation solving, and implements dynamic nonmonotonic line search.", "result": "The algorithm achieves superlinear convergence near optimal solutions when residual control parameter \u03b7_k approaches 0, with numerical experiments validating accuracy and efficiency.", "conclusion": "The proposed inexact semismooth Newton method with GMRES and nonmonotonic line search is effective for semi-linear elliptic optimal control problems, combining computational efficiency with theoretical convergence guarantees."}}
{"id": "2511.10194", "pdf": "https://arxiv.org/pdf/2511.10194", "abs": "https://arxiv.org/abs/2511.10194", "authors": ["Zimo Hao", "Zhengyan Wu", "Johannes Zimmer"], "title": "Kinetic Theory with Fluctuations: Strong Well-Posedness of the Vlasov-Fokker-Planck-Dean-Kawasaki System", "categories": ["math.PR", "math.AP"], "comment": "76 pages", "summary": "We establish the well-posedness of the Vlasov-Fokker-Planck-Dean-Kawasaki (VFPDK) equation with correlated noise, which arises as a fluctuating mean-field limit of second-order Newtonian particle systems. We focus on the case of bounded nonlocal interactions and a diffusion coefficient of square-root type. In this setting, we prove existence and uniqueness of renormalized kinetic solutions. The proof relies on a novel combination of kinetic semigroup estimates with the framework of renormalized kinetic solutions.", "AI": {"tldr": "The paper establishes well-posedness of the Vlasov-Fokker-Planck-Dean-Kawasaki equation with correlated noise, proving existence and uniqueness of renormalized kinetic solutions for bounded nonlocal interactions and square-root diffusion coefficients.", "motivation": "To address the mathematical foundation of fluctuating mean-field limits from second-order Newtonian particle systems, specifically focusing on the VFPDK equation with correlated noise.", "method": "Uses a novel combination of kinetic semigroup estimates with the framework of renormalized kinetic solutions to prove well-posedness.", "result": "Proves existence and uniqueness of renormalized kinetic solutions for the VFPDK equation with bounded nonlocal interactions and square-root diffusion coefficients.", "conclusion": "The VFPDK equation with correlated noise is well-posed in the specified setting, providing rigorous mathematical foundation for this class of fluctuating mean-field equations."}}
{"id": "2511.10460", "pdf": "https://arxiv.org/pdf/2511.10460", "abs": "https://arxiv.org/abs/2511.10460", "authors": ["Isaac M. Lopez", "Rio Schillmoeller"], "title": "Dynamical functionals on ancient ARF Ricci flows", "categories": ["math.DG", "math.AP"], "comment": "17 pages", "summary": "We introduce a dynamical energy functional on compact ancient asymptotically Ricci-flat Ricci flows with modest decay using limits of conjugate heat flows. This functional satisfies a steady Ricci breather-type rigidity and provides an upper bound for the ordinary $\u03bb$-functional while retaining many of its properties. In addition, motivated by work of Colding and Minicozzi, we derive local eigenvalue estimates for normalized Ricci flows coupled with conjugate heat flows.", "AI": {"tldr": "Introduces a dynamical energy functional on compact ancient asymptotically Ricci-flat Ricci flows using conjugate heat flows, with breather-type rigidity and connections to \u03bb-functional.", "motivation": "To develop new energy functionals for Ricci flows that capture dynamical properties and provide connections to existing \u03bb-functional theory, inspired by Colding and Minicozzi's work.", "method": "Uses limits of conjugate heat flows to define a dynamical energy functional on compact ancient asymptotically Ricci-flat Ricci flows, and derives local eigenvalue estimates for normalized Ricci flows coupled with conjugate heat flows.", "result": "The functional satisfies steady Ricci breather-type rigidity, provides an upper bound for the ordinary \u03bb-functional while retaining many properties, and yields local eigenvalue estimates.", "conclusion": "The dynamical energy functional offers new insights into Ricci flow dynamics with connections to breather rigidity and eigenvalue theory, extending classical \u03bb-functional analysis."}}
{"id": "2511.10496", "pdf": "https://arxiv.org/pdf/2511.10496", "abs": "https://arxiv.org/abs/2511.10496", "authors": ["Fran\u00e7ois Cl\u00e9ment", "Linhang Huang", "Woorim Lee", "Cole Smidt", "Braeden Sodt", "Xuan Zhang"], "title": "Low-Discrepancy Set Post-Processing via Gradient Descent", "categories": ["math.OC", "math.NA"], "comment": null, "summary": "The construction of low-discrepancy sets, used for uniform sampling and numerical integration, has recently seen great improvements based on optimization and machine learning techniques. However, these methods are computationally expensive, often requiring days of computation or access to GPU clusters. We show that simple gradient descent-based techniques allow for comparable results when starting with a reasonably uniform point set. Not only is this method much more efficient and accessible, but it can be applied as post-processing to any low-discrepancy set generation method for a variety of standard discrepancy measures.", "AI": {"tldr": "Simple gradient descent methods can efficiently optimize low-discrepancy sets, achieving comparable results to complex ML methods while being much faster and applicable as post-processing.", "motivation": "Current optimization and ML methods for constructing low-discrepancy sets are computationally expensive, requiring days of computation or GPU clusters.", "method": "Using simple gradient descent-based techniques starting from reasonably uniform point sets, applied as post-processing to existing generation methods.", "result": "Achieves comparable results to complex methods while being much more efficient and accessible.", "conclusion": "Gradient descent provides an efficient alternative to computationally intensive methods for optimizing low-discrepancy sets across various discrepancy measures."}}
{"id": "2511.10545", "pdf": "https://arxiv.org/pdf/2511.10545", "abs": "https://arxiv.org/abs/2511.10545", "authors": ["Gianmarco Caldini"], "title": "On smooth approximation of integral cycles mod 2", "categories": ["math.DG", "math.AP"], "comment": null, "summary": "We prove that every mod 2 integral cycle $T$ in a Riemannian manifold $\\mathcal{M}$ can be approximated in flat norm by a cycle which is a smooth submanifold $\u03a3$ of nearly the same area, up to a singular set of codimension 3; in addition, this estimate on the singular set can be refined depending on the codimension of the cycle. Moreover, if the mod 2 homology class $\u03c4$ admits a smooth embedded representative, then $\u03a3$ can be chosen free of singularities. This article provides the unoriented version of the smooth approximation theorem for integral cycles.", "AI": {"tldr": "This paper proves that mod 2 integral cycles in Riemannian manifolds can be approximated by smooth submanifolds with nearly the same area, with singularities only in codimension 3 or better depending on the cycle's codimension.", "motivation": "To establish an unoriented version of the smooth approximation theorem for integral cycles, extending previous oriented results to mod 2 homology classes.", "method": "The authors develop approximation techniques for mod 2 integral cycles using flat norm convergence, constructing smooth submanifolds that approximate the original cycles while controlling the singular set.", "result": "Every mod 2 integral cycle can be approximated by a smooth submanifold with nearly identical area, with singularities confined to codimension 3 or higher. When a smooth embedded representative exists, the approximation can be made completely smooth.", "conclusion": "The paper successfully provides the unoriented counterpart to the smooth approximation theorem for integral cycles, demonstrating robust approximation properties for mod 2 homology classes in Riemannian manifolds."}}
{"id": "2511.10553", "pdf": "https://arxiv.org/pdf/2511.10553", "abs": "https://arxiv.org/abs/2511.10553", "authors": ["M\u00f3nica Clapp", "Benedetta Pellacci", "Angela Pistoia"], "title": "Sign-changing solutions to the Escobar problem on manifolds with boundary", "categories": ["math.DG", "math.AP"], "comment": null, "summary": "Let $(M, g)$ be a $n-$dimensional compact Riemannian manifold with boundary. The Escobar problem concerning the existence of a metric conformally equivalent to $g$ having constant scalar curvature on $M$ and constant mean curvature on its boundary is equivalent, in analytic terms, to finding a positive solution to a nonlinear boundary-value problem with critical growth. While the existence of positive solutions to this problem is by now well understood, the existence of sign-changing (nodal) solutions remains largely open. In this work we establish the existence of least-energy sign-changing solutions in two particular cases: the scalar-flat problem, where the scalar curvature on $M$ is zero and the mean curvature of its boundary is constant, and the minimal boundary problem, where the mean curvature of the boundary vanishes and the scalar curvature of $M$ is constant. More precisely, we prove that if $n\\ge7$ and $M$ has a nonumbilic boundary point, then both problems admit least-energy nodal solutions. In addition, we show that when $n\\ge5$, the minimal boundary problem possesses infinitely many sign-changing solutions on the unit ball. Our approach is variational and relies on the analysis of suitable conformal invariants and sharp energy estimates derived from Escobar's work.", "AI": {"tldr": "Existence of least-energy sign-changing solutions for Escobar's conformal problem in two cases: scalar-flat problem and minimal boundary problem, particularly when n\u22657 with nonumbilic boundary points, and infinitely many sign-changing solutions on unit ball when n\u22655.", "motivation": "While existence of positive solutions to Escobar's conformal problem is well understood, existence of sign-changing (nodal) solutions remains largely open and unexplored.", "method": "Variational approach relying on analysis of suitable conformal invariants and sharp energy estimates derived from Escobar's work.", "result": "Proved that if n\u22657 and manifold has nonumbilic boundary point, both scalar-flat and minimal boundary problems admit least-energy nodal solutions. Also showed that when n\u22655, minimal boundary problem has infinitely many sign-changing solutions on unit ball.", "conclusion": "Established existence of least-energy sign-changing solutions for Escobar's conformal problem in specific cases, addressing a gap in understanding nodal solutions for this boundary-value problem with critical growth."}}
