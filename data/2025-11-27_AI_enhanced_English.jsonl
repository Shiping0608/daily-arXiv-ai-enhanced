{"id": "2511.20664", "pdf": "https://arxiv.org/pdf/2511.20664", "abs": "https://arxiv.org/abs/2511.20664", "authors": ["Vienna B. Rossmanith"], "title": "A Modified BGK Collision Operator for Exact Conservation in Numerical Solutions of Boltzmann-BGK", "categories": ["math.NA"], "comment": "13 pages, 3 figures", "summary": "Ideal gases can be modeled by the Boltzmann equation from statistical physics. Instead of trying to track the position and velocity of a large number of gas molecules, it is possible to describe the particles with a particle distribution function. The Boltzmann equation provides the rule for evolving the distribution function over time, allowing one to simulate the gas dynamics. In this work, we develop a novel numerical method for solving the 1D1V Boltzmann-BGK equation. Several important ingredients are combined to create an accurate, efficient, robust numerical method valid in all flow regimes. First, we make use of operator splitting to create separate transport and collision sub-steps, each of which is easier to discretize than the whole system; second, we introduce a third-order accurate Lax-Wendroff-type scheme for the transport sub-step; third, we make use of the second-order L-stable TR-BDF method for the collision sub-step. The final component we introduce is a novel treatment of the collision sub-step to guarantee that the total mass, momentum, and energy are conserved even in the presence of a truncated velocity range and quadrature errors in computing moments. The key idea is to multiply the Maxwell-Boltzmann distribution in the collision sub-step by a quadratic Hermite polynomial, where the coefficients in the polynomial are chosen to ensure exact conservation. The resulting scheme is verified on piecewise constant initial data with periodic boundary conditions; exact conservation up to machine precision is demonstrated for mass, momentum, and energy. The resulting method is implemented in a freely available Java code with Python plotting routines.", "AI": {"tldr": "A novel numerical method for solving the 1D1V Boltzmann-BGK equation combining operator splitting, third-order transport scheme, second-order collision scheme, and conservation-enforcing polynomial modification.", "motivation": "To develop an accurate, efficient, and robust numerical method for simulating gas dynamics using the Boltzmann equation that works across all flow regimes while maintaining exact conservation properties.", "method": "Uses operator splitting into transport and collision steps: third-order Lax-Wendroff-type scheme for transport, second-order L-stable TR-BDF method for collision, with a novel quadratic Hermite polynomial modification to enforce exact conservation of mass, momentum, and energy.", "result": "The method achieves exact conservation up to machine precision for mass, momentum, and energy, verified on piecewise constant initial data with periodic boundary conditions.", "conclusion": "The developed scheme provides an effective numerical approach for Boltzmann-BGK equation simulation with guaranteed conservation properties, implemented in freely available Java code with Python plotting."}}
{"id": "2511.20681", "pdf": "https://arxiv.org/pdf/2511.20681", "abs": "https://arxiv.org/abs/2511.20681", "authors": ["Leonidas Mindrinos", "Nikolaos Pallikarakis", "Nikolaos L Tsitsas"], "title": "Inverse Electromagnetic Scattering for Doubly-Connected Cylinders using Convolutional Neural Networks", "categories": ["math.NA"], "comment": "40 pages, 28 figures", "summary": "In this work, we consider the inverse electromagnetic scattering problem for a magneto-dielectric cylinder covering an impedance cylinder of arbitrary shape. We solve it by introducing a divide-and-conquer framework using specially designed 1D multi-channel, circular-padding Convolutional Neural Networks. The solution of the direct problem provides us with the real and imaginary components of the far-field measurements representing the input data. We first classify the shape of the impedance cylinder and then reconstruct the unknown boundary curve and the impedance function. Through extensive numerical experiments, including noisy scenarios, we demonstrate the efficiency and robustness of our approach.", "AI": {"tldr": "A deep learning approach using 1D multi-channel CNNs with circular padding solves the inverse electromagnetic scattering problem for magneto-dielectric cylinders covering impedance cylinders, classifying shapes and reconstructing boundary curves and impedance functions.", "motivation": "To address the challenging inverse electromagnetic scattering problem for complex magneto-dielectric cylinders covering impedance cylinders of arbitrary shapes, which has practical applications in electromagnetic imaging and non-destructive testing.", "method": "A divide-and-conquer framework using specially designed 1D multi-channel convolutional neural networks with circular padding, trained on direct problem solutions that provide far-field measurements as input data.", "result": "The method successfully classifies impedance cylinder shapes and reconstructs unknown boundary curves and impedance functions, demonstrating efficiency and robustness even in noisy scenarios through extensive numerical experiments.", "conclusion": "The proposed deep learning framework provides an effective and robust solution for inverse electromagnetic scattering problems involving complex magneto-dielectric and impedance cylinder configurations."}}
{"id": "2511.20685", "pdf": "https://arxiv.org/pdf/2511.20685", "abs": "https://arxiv.org/abs/2511.20685", "authors": ["Peiqi Li", "Jie Chen"], "title": "Dual-Domain Deep Learning Method to Accelerate Local Basis Functions Computation for Reservoir Simulation in High-Contrast Porous Media", "categories": ["math.NA", "cs.LG"], "comment": null, "summary": "In energy science, Darcy flow in heterogeneous porous media is a central problem in reservoir sim-ulation. However, the pronounced multiscale characteristics of such media pose significant challenges to conventional numerical methods in terms of computational demand and efficiency. The Mixed Generalized Multiscale Finite Element Method (MGMsFEM) provides an effective framework for addressing these challenges, yet the construction of multiscale basis functions remains computationally expensive. In this work, we propose a dual-domain deep learning framework to accelerate the computation of multiscale basis functions within MGMsFEM for solving Darcy flow problems. By extracting and decoding permeability field features in both the frequency and spatial domains, the method enables rapid generation of numerical matrices of multiscale basis functions. Numerical experiments demonstrate that the proposed framework achieves significant computational acceleration while maintaining high approximation accuracy, thereby offering the potential for future applications in real-world reservoir engineering.", "AI": {"tldr": "A dual-domain deep learning framework is proposed to accelerate multiscale basis function computation in MGMsFEM for Darcy flow in heterogeneous porous media, achieving significant speedup while maintaining accuracy.", "motivation": "Darcy flow in heterogeneous porous media has multiscale characteristics that challenge conventional numerical methods. While MGMsFEM addresses these challenges, constructing multiscale basis functions remains computationally expensive.", "method": "A dual-domain deep learning framework that extracts and decodes permeability field features in both frequency and spatial domains to rapidly generate numerical matrices of multiscale basis functions.", "result": "Numerical experiments show the framework achieves significant computational acceleration while maintaining high approximation accuracy.", "conclusion": "The proposed method offers potential for future applications in real-world reservoir engineering by providing efficient computation of multiscale basis functions."}}
{"id": "2511.20687", "pdf": "https://arxiv.org/pdf/2511.20687", "abs": "https://arxiv.org/abs/2511.20687", "authors": ["Irina Tezaur", "Eric Parish", "Anthony Gruber", "Ian Moore", "Christopher Wentland", "Alejandro Mota"], "title": "Hybrid coupling with operator inference and the overlapping Schwarz alternating method", "categories": ["math.NA", "cs.AI", "math-ph"], "comment": null, "summary": "This paper presents a novel hybrid approach for coupling subdomain-local non-intrusive Operator Inference (OpInf) reduced order models (ROMs) with each other and with subdomain-local high-fidelity full order models (FOMs) with using the overlapping Schwarz alternating method (O-SAM). The proposed methodology addresses significant challenges in multiscale modeling and simulation, particularly the long runtime and complex mesh generation requirements associated with traditional high-fidelity simulations. By leveraging the flexibility of O-SAM, we enable the seamless integration of disparate models, meshes, and time integration schemes, enhancing computational efficiency while maintaining high accuracy. Our approach is demonstrated through a series of numerical experiments on complex three-dimensional (3D) solid dynamics problems, showcasing speedups of up to 106x compared to conventional FOM-FOM couplings. This work paves the way for more efficient simulation workflows in engineering applications, with potential extensions to a wide range of partial differential equations.", "AI": {"tldr": "A hybrid approach coupling local non-intrusive Operator Inference ROMs with FOMs using overlapping Schwarz alternating method for efficient multiscale simulations.", "motivation": "Address long runtime and complex mesh generation in traditional high-fidelity simulations for multiscale modeling.", "method": "Hybrid coupling of subdomain-local OpInf ROMs and FOMs using overlapping Schwarz alternating method, enabling integration of disparate models, meshes, and time schemes.", "result": "Demonstrated on 3D solid dynamics problems with up to 106x speedup compared to conventional FOM-FOM couplings.", "conclusion": "Paves way for efficient simulation workflows in engineering with potential extensions to various PDEs."}}
{"id": "2511.20951", "pdf": "https://arxiv.org/pdf/2511.20951", "abs": "https://arxiv.org/abs/2511.20951", "authors": ["J. F. Parisi", "A. Rutkowski"], "title": "Isotope Production in Muon-Catalyzed-Fusion Systems", "categories": ["physics.plasm-ph", "nucl-ex", "physics.acc-ph"], "comment": "6 pages, 3 figures", "summary": "Producing valuable isotopes with high-flux high-energy neutrons generated by muon-catalyzed fusion ($\u03bc$CF) reactions could substantially improve the economic prospects for muon-catalyzed fusion. Because no external heating is required for $\u03bc$CF, heat flux constraints are significantly relaxed compared with fusion systems requiring external heating. This could allow $\u03bc$CF to attain much higher neutron flux without breaching material heat flux limits. If muon production rates can be increased, $\u03bc$CF systems employing transmutation could be viable well before energy breakeven is possible. For $\u03bc$CF systems transmuting valuable isotopes, the required number of catalyzed fusion events per muon and muon energy generation cost can be relaxed by several orders of magnitude, making $\u03bc$CF an attractive intense neutron source. We show an example $\u03bc$CF system with a modest muon rate of $10^8$ muons / second could produce up to 0.5 mg of $^{225}$Ac per year - ten times current global supply - with a 10 gram $^{226}$Ra feedstock. As higher muon rate beams become available, many other radioisotope transmutation pathways become viable. These findings motivate the accelerated development of $\u03bc$CF systems for neutron-driven isotope production before net energy generation is possible.", "AI": {"tldr": "Muon-catalyzed fusion (\u03bcCF) can produce valuable isotopes using high-flux neutrons without external heating, potentially making \u03bcCF economically viable before achieving energy breakeven.", "motivation": "To improve the economic prospects of muon-catalyzed fusion by using it as an intense neutron source for producing valuable isotopes, particularly medical radioisotopes like \u00b2\u00b2\u2075Ac.", "method": "Utilize muon-catalyzed fusion reactions to generate high-flux, high-energy neutrons without external heating, then use these neutrons to transmute target materials into valuable isotopes through nuclear reactions.", "result": "A \u03bcCF system with 10\u2078 muons/second could produce 0.5 mg of \u00b2\u00b2\u2075Ac per year (10\u00d7 current global supply) using only 10 grams of \u00b2\u00b2\u2076Ra feedstock. The requirements for catalyzed fusion events per muon and muon energy cost can be relaxed by orders of magnitude.", "conclusion": "\u03bcCF systems show strong potential for neutron-driven isotope production and should be developed for this purpose even before achieving net energy generation, as they can substantially improve the economic viability of muon-catalyzed fusion."}}
{"id": "2511.21369", "pdf": "https://arxiv.org/pdf/2511.21369", "abs": "https://arxiv.org/abs/2511.21369", "authors": ["Tingkai Xue", "Chin Chun Ooi", "Zhengwei Ge", "Fong Yew Leong", "Hongying Li", "Chang Wei Kang"], "title": "Differentiable Physics-Neural Models enable Learning of Non-Markovian Closures for Accelerated Coarse-Grained Physics Simulations", "categories": ["physics.comp-ph", "cs.LG", "physics.flu-dyn"], "comment": null, "summary": "Numerical simulations provide key insights into many physical, real-world problems. However, while these simulations are solved on a full 3D domain, most analysis only require a reduced set of metrics (e.g. plane-level concentrations). This work presents a hybrid physics-neural model that predicts scalar transport in a complex domain orders of magnitude faster than the 3D simulation (from hours to less than 1 min). This end-to-end differentiable framework jointly learns the physical model parameterization (i.e. orthotropic diffusivity) and a non-Markovian neural closure model to capture unresolved, 'coarse-grained' effects, thereby enabling stable, long time horizon rollouts. This proposed model is data-efficient (learning with 26 training data), and can be flexibly extended to an out-of-distribution scenario (with a moving source), achieving a Spearman correlation coefficient of 0.96 at the final simulation time. Overall results show that this differentiable physics-neural framework enables fast, accurate, and generalizable coarse-grained surrogates for physical phenomena.", "AI": {"tldr": "A hybrid physics-neural model that predicts scalar transport in complex domains orders of magnitude faster than 3D simulations, using differentiable physics with neural closure models.", "motivation": "Traditional 3D numerical simulations are computationally expensive (hours), while most analysis only requires reduced metrics. Need for faster, data-efficient alternatives.", "method": "End-to-end differentiable framework combining physical model parameterization (orthotropic diffusivity) with non-Markovian neural closure model to capture unresolved effects, enabling stable long-term rollouts.", "result": "Achieves 0.96 Spearman correlation coefficient, learns with only 26 training data, extends to out-of-distribution scenarios (moving source), reduces simulation time from hours to <1 minute.", "conclusion": "The differentiable physics-neural framework enables fast, accurate, and generalizable coarse-grained surrogates for physical phenomena."}}
{"id": "2511.20772", "pdf": "https://arxiv.org/pdf/2511.20772", "abs": "https://arxiv.org/abs/2511.20772", "authors": ["Tadele Mengesha", "Miriam Abbate"], "title": "A note on the $L^{p}$-solvability of a strongly-coupled nonlocal system of equations", "categories": ["math.AP"], "comment": null, "summary": "The goal of this paper is to study the $L^p$-solvability of the strongly-coupled nonlocal system \\[\n  \\mathbb{L} \\mathbf{u} (\\mathbf{x}) + \u03bb\\mathbf{u}(\\mathbf{x})= \\mathbf{f}(\\mathbf{x}) \\quad \\text{in $\\mathbb{R}^{d}$ } \\] where $\\mathbb{L}$ is a linear nonlocal coupled vector-valued operator associated with a kernel $K$ comparable to $|\\mathbf{y}|^{-(d+2s)}$ for $s \\in (0,1)$, satisfying certain ellipticity and cancellation conditions. For any $\\mathbf{f} \\in [L^p(\\mathbb{R}^d)]^d$, $1< p < \\infty$, the existence of a unique strong solution $\\mathbf{u} \\in [H^{2s,p}(\\mathbb{R}^d)]^d$ is proved via the method of continuity. To apply this method, we establish the continuity of the operator $\\mathbb{L}$ and the necessary \\textit{a priori} estimates. These are obtained through the study of the corresponding parabolic system. The proof strategy follows and extends recent ideas developed for the scalar setting, combining commutator estimates, Sobolev embeddings, a level set estimates and a bootstrap argument.", "AI": {"tldr": "This paper studies the L^p-solvability of strongly-coupled nonlocal systems with vector-valued operators, proving existence and uniqueness of strong solutions for f in L^p spaces.", "motivation": "To extend solvability results from scalar nonlocal operators to strongly-coupled vector-valued systems, addressing the challenges of coupled interactions in nonlocal PDEs.", "method": "Uses the method of continuity, establishing operator continuity and a priori estimates through study of corresponding parabolic systems, combining commutator estimates, Sobolev embeddings, level set estimates, and bootstrap arguments.", "result": "Proves existence and uniqueness of strong solutions u in [H^{2s,p}(\u211d^d)]^d for any f in [L^p(\u211d^d)]^d with 1 < p < \u221e, for nonlocal operators with kernels comparable to |y|^{-(d+2s)}.", "conclusion": "Successfully extends recent scalar nonlocal operator results to strongly-coupled vector-valued systems, providing comprehensive L^p-solvability theory for such nonlocal coupled systems."}}
{"id": "2511.20815", "pdf": "https://arxiv.org/pdf/2511.20815", "abs": "https://arxiv.org/abs/2511.20815", "authors": ["Saddam Hijazi", "Nikiema Fulgence", "Hannah Burmester", "Natalie Rauter", "Carmen Gr\u00e4\u00dfle"], "title": "Data-driven model order reduction for wave propagation in materials with nonlinearities or damage", "categories": ["math.NA"], "comment": null, "summary": "In this work, we consider wave propagation in materials characterized by nonlinear properties or damage. To accelerate the simulations of the resulting high-dimensional problems, we apply model order reduction methods. Depending on the knowledge of the underlying equations and the availability of their discrete operators, intrusive methods (here projection-based approaches based on proper orthogonal decomposition (POD)) or non-instrusive methods (here data-driven approaches including dynamic mode decomposition (DMD) and operator inference (OpInf)) can be used. We recall the theoretical foundations of the methods and apply them to the problem of wave propagation. In three different numerical examples, we evaluate the performance of the reduction techniques.", "AI": {"tldr": "This paper applies model order reduction methods (both intrusive and non-intrusive) to accelerate simulations of wave propagation in nonlinear materials and damaged structures.", "motivation": "To address the computational challenges of simulating high-dimensional wave propagation problems in nonlinear materials and damaged structures by reducing model complexity.", "method": "Uses intrusive methods (POD-based projection) when equations are known, and non-intrusive methods (DMD and operator inference) when only data is available. Evaluates performance on three numerical examples.", "result": "The paper evaluates the performance of various reduction techniques on wave propagation problems, though specific quantitative results are not provided in the abstract.", "conclusion": "Model order reduction methods (both intrusive and non-intrusive) can be effectively applied to accelerate wave propagation simulations in nonlinear materials and damaged structures."}}
{"id": "2511.21154", "pdf": "https://arxiv.org/pdf/2511.21154", "abs": "https://arxiv.org/abs/2511.21154", "authors": ["Saikat Das", "Siddhartha Gupta", "Prateek Sharma"], "title": "Impact of Cosmic Ray Distribution on the Growth and Saturation of Bell Instability", "categories": ["astro-ph.HE", "physics.plasm-ph"], "comment": "15 pages, 11 figures, 3 tables; To be submitted; Comments are welcome!", "summary": "Cosmic rays (CRs) streaming in weakly magnetized plasmas can drive large-amplitude magnetic fluctuations via nonresonant streaming instability (NRSI), or Bell instability. Using one-dimensional kinetic simulations, we investigate how mono-energetic and power-law CR momentum distributions influence the growth and saturation of NRSI. The linear growth is governed solely by the CR current and is largely insensitive to the CR distribution. However, the saturation depends strongly on the CR distribution and is achieved through CR isotropization, which quenches the driving current. Mono-energetic CRs effectively amplify the magnetic field and isotropize. For power-law distributions, the lowest-energy CRs dominate current relaxation and magnetic growth, while the highest-energy CRs remain weakly scattered, limiting their contribution to saturation. In the absence of low-energy CRs, high-energy particles amplify magnetic fields effectively and isotropize. We provide a modified saturation prescription accounting for these effects and propose a layered CR-confinement scenario upstream of astrophysical shocks, relevant to particle acceleration to high energies.", "AI": {"tldr": "The paper studies how cosmic ray momentum distributions affect the non-resonant streaming instability, finding that linear growth depends only on CR current while saturation depends on CR distribution through isotropization.", "motivation": "To understand how different cosmic ray momentum distributions influence the growth and saturation of non-resonant streaming instability in weakly magnetized plasmas.", "method": "Using one-dimensional kinetic simulations to investigate mono-energetic and power-law CR momentum distributions and their effects on NRSI growth and saturation.", "result": "Linear growth governed solely by CR current, saturation achieved through CR isotropization. Mono-energetic CRs effectively amplify magnetic fields. For power-law distributions, lowest-energy CRs dominate current relaxation while highest-energy CRs remain weakly scattered.", "conclusion": "Provides modified saturation prescription accounting for CR distribution effects and proposes layered CR-confinement scenario upstream of astrophysical shocks relevant to high-energy particle acceleration."}}
{"id": "2511.20774", "pdf": "https://arxiv.org/pdf/2511.20774", "abs": "https://arxiv.org/abs/2511.20774", "authors": ["Samuel T. Elkin", "Ghazi Khan", "Ebrahim Forati", "Brandon W. Langley", "Dogan Timucin", "Reza Molavi", "Sara Sussman", "Thomas E. Roth"], "title": "Opportunities and Challenges of Computational Electromagnetics Methods for Superconducting Circuit Quantum Device Modeling: A Practical Review", "categories": ["quant-ph", "physics.comp-ph"], "comment": "36 pages, 13 figures", "summary": "High-fidelity numerical methods that model the physical layout of a device are essential for the design of many technologies. For methods that characterize electromagnetic effects, these numerical methods are referred to as computational electromagnetics (CEM) methods. Although the CEM research field is mature, emerging applications can still stress the capabilities of the techniques in use today. The design of superconducting circuit quantum devices falls in this category due to the unconventional material properties and important features of the devices covering nanometer to centimeter scales. Such multiscale devices can stress the fundamental properties of CEM tools which can lead to an increase in simulation times, a loss in accuracy, or even cause no solution to be reliably found. While these challenges are being investigated by CEM researchers, knowledge about them is limited in the broader community of users of these CEM tools. This review is meant to serve as a practical introduction to the fundamental aspects of the major CEM techniques that a researcher may need to choose between to model a device, as well as provide insight into what steps they may take to alleviate some of their challenges. Our focus is on highlighting the main concepts without rigorously deriving all the details, which can be found in many textbooks and articles. After covering the fundamentals, we discuss more advanced topics related to the challenges of modeling multiscale devices with specific examples from superconducting circuit quantum devices. We conclude with a discussion on future research directions that will be valuable for improving the ability to successfully design increasingly more sophisticated superconducting circuit quantum devices. Although our focus and examples are taken from this area, researchers from other fields will still benefit from the details discussed here.", "AI": {"tldr": "This paper provides a practical introduction to computational electromagnetics (CEM) methods for modeling multiscale superconducting circuit quantum devices, highlighting fundamental concepts, challenges, and solutions.", "motivation": "Emerging superconducting circuit quantum devices with unconventional materials and multiscale features (nanometer to centimeter) stress existing CEM tools, causing simulation issues like increased time, accuracy loss, or unreliable solutions that are not well-known in the broader CEM user community.", "method": "The review covers fundamental aspects of major CEM techniques, provides practical guidance on technique selection, and discusses advanced topics related to multiscale modeling challenges with specific examples from superconducting circuit quantum devices.", "result": "The paper serves as an accessible introduction that bridges knowledge gaps about CEM challenges in multiscale device modeling, particularly for superconducting quantum circuits, without requiring rigorous mathematical derivations.", "conclusion": "Future research directions are needed to improve CEM tools for designing increasingly sophisticated superconducting circuit quantum devices, and the insights provided benefit researchers across multiple fields beyond quantum computing."}}
{"id": "2511.20898", "pdf": "https://arxiv.org/pdf/2511.20898", "abs": "https://arxiv.org/abs/2511.20898", "authors": ["Vertti Hietanen", "Mikyoung Lee"], "title": "Higher integrability for minimizers under weighted generalized Orlicz growth conditions", "categories": ["math.AP"], "comment": null, "summary": "We investigate variational integrals in a weighted framework under generalized Orlicz growth conditions. Assuming that the weight belongs to a Muckenhoupt class and the growth function satisfies appropriate structural conditions, we prove that the gradient of any local quasiminimizer has local higher integrability. This result extends the previous higher integrability result to the weighted setting, encompassing as particular cases the weighted variable exponent and weighted double phase frameworks. In addition, we establish the existence of minimizers for the associated functional.", "AI": {"tldr": "Higher integrability of gradients for local quasiminimizers in weighted Orlicz spaces, with existence of minimizers for associated functionals.", "motivation": "Extend previous higher integrability results to weighted settings under generalized Orlicz growth conditions, covering weighted variable exponent and double phase frameworks.", "method": "Assume weight belongs to Muckenhoupt class and growth function satisfies structural conditions, then prove local higher integrability of gradients for local quasiminimizers.", "result": "Proved gradient of any local quasiminimizer has local higher integrability in weighted Orlicz framework. Also established existence of minimizers for associated functional.", "conclusion": "Successfully extended higher integrability theory to weighted Orlicz spaces, providing unified framework that includes weighted variable exponent and double phase cases as special instances."}}
{"id": "2511.20824", "pdf": "https://arxiv.org/pdf/2511.20824", "abs": "https://arxiv.org/abs/2511.20824", "authors": ["Nour G. Al Hassanieh", "Alex H. Barnett", "Leslie Greengard"], "title": "Truncated kernel windowed Fourier projection: a fast algorithm for the 3D free-space wave equation", "categories": ["math.NA"], "comment": null, "summary": "We present a spectrally accurate fast algorithm for evaluating the solution to the scalar wave equation in free space driven by a large collection of point sources in a bounded domain. With $M$ sources temporally discretized by $N_t$ time steps of size $\u0394t$, a naive potential evaluation at $M$ targets on the same time grid requires $\\mathcal O(M^2 N_t)$ work. Our scheme requires $\\mathcal{O}\\left((M + N^3\\log N)N_t\\right)$ work, where $N$ scales as $\\mathcal O(1/\u0394t)$, i.e., the maximum signal frequency. This is achieved by using the recently-proposed windowed Fourier projection (WFP) method to split the potential into a local part, evaluated directly, plus a smooth history part approximated by an $N^3$-point equispaced discretization of the Fourier transform, where each Fourier coefficient obeys a simple recursion relation. The growing oscillations in the spectral representation (which would be present with a naive use of the Fourier transform) are controlled by spatially truncating the hyperbolic Green's function itself. Thus, the method avoids the need for absorbing boundary conditions. We demonstrate the performance of our algorithm with up to a million sources and targets at 6-digit accuracy. We believe it can serve as a key component in addressing time-domain wave equation scattering problems.", "AI": {"tldr": "A fast algorithm for evaluating scalar wave equation solutions from point sources using spectral methods with O((M + N\u00b3log N)N_t) complexity, avoiding absorbing boundary conditions.", "motivation": "To efficiently solve large-scale time-domain wave equation problems with many point sources, overcoming the O(M\u00b2N_t) complexity of naive approaches.", "method": "Uses windowed Fourier projection (WFP) to split potential into local and smooth history parts, with Fourier transform discretization and spatial truncation of hyperbolic Green's function.", "result": "Achieves 6-digit accuracy with up to 1 million sources and targets, demonstrating significant computational efficiency improvements.", "conclusion": "The method provides an efficient solution for time-domain wave equation scattering problems without needing absorbing boundary conditions."}}
{"id": "2511.20798", "pdf": "https://arxiv.org/pdf/2511.20798", "abs": "https://arxiv.org/abs/2511.20798", "authors": ["Rio Alexa Fear", "Payel Mukhopadhyay", "Michael McCabe", "Alberto Bietti", "Miles Cranmer"], "title": "Physics Steering: Causal Control of Cross-Domain Concepts in a Physics Foundation Model", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": "16 Pages, 9 Figures. Code available at https://github.com/DJ-Fear/walrus_steering", "summary": "Recent advances in mechanistic interpretability have revealed that large language models (LLMs) develop internal representations corresponding not only to concrete entities but also distinct, human-understandable abstract concepts and behaviour. Moreover, these hidden features can be directly manipulated to steer model behaviour. However, it remains an open question whether this phenomenon is unique to models trained on inherently structured data (ie. language, images) or if it is a general property of foundation models. In this work, we investigate the internal representations of a large physics-focused foundation model. Inspired by recent work identifying single directions in activation space for complex behaviours in LLMs, we extract activation vectors from the model during forward passes over simulation datasets for different physical regimes. We then compute \"delta\" representations between the two regimes. These delta tensors act as concept directions in activation space, encoding specific physical features. By injecting these concept directions back into the model during inference, we can steer its predictions, demonstrating causal control over physical behaviours, such as inducing or removing some particular physical feature from a simulation. These results suggest that scientific foundation models learn generalised representations of physical principles. They do not merely rely on superficial correlations and patterns in the simulations. Our findings open new avenues for understanding and controlling scientific foundation models and has implications for AI-enabled scientific discovery.", "AI": {"tldr": "Physics foundation models develop internal representations of abstract physical concepts that can be manipulated to causally control model behavior and steer predictions.", "motivation": "To investigate whether the phenomenon of internal abstract concept representations found in language and vision models is a general property of foundation models, specifically in scientific/physics domains.", "method": "Extracted activation vectors from a physics foundation model during forward passes over different physical regimes, computed \"delta\" representations between regimes as concept directions, and injected these directions back during inference to steer predictions.", "result": "Successfully demonstrated causal control over physical behaviors by inducing or removing specific physical features from simulations through concept direction manipulation.", "conclusion": "Scientific foundation models learn generalized representations of physical principles rather than relying on superficial correlations, opening new avenues for understanding and controlling AI in scientific discovery."}}
{"id": "2511.20978", "pdf": "https://arxiv.org/pdf/2511.20978", "abs": "https://arxiv.org/abs/2511.20978", "authors": ["Tao Zhang", "Meixia Li", "Fan Yang", "Chunqin Zhou"], "title": "The singular anisotropic Adams' type inequality in $\\mathbb{R}^n$", "categories": ["math.AP"], "comment": null, "summary": "In this paper, using anisotropic rearrangement techniques, we first establish the best constants for the singular anisotropic Adams' type inequality with exact growth in $\\mathbb{R}^n$. Furthermore, by the same trick, we also prove the singular anisotropic Adams' type inequality on bounded domain $\u03a9\\subset \\mathbb{R}^n$.", "AI": {"tldr": "Establishes best constants for singular anisotropic Adams' type inequality with exact growth in R^n and extends to bounded domains using anisotropic rearrangement techniques.", "motivation": "To derive optimal constants for singular anisotropic Adams' type inequalities with precise growth conditions, extending classical results to anisotropic settings.", "method": "Uses anisotropic rearrangement techniques to prove the inequalities, applying the same approach to both unbounded and bounded domains.", "result": "Obtained best constants for singular anisotropic Adams' type inequality with exact growth in R^n and proved the inequality on bounded domains.", "conclusion": "Successfully established optimal constants for singular anisotropic Adams' inequalities and extended the results to bounded domains using anisotropic rearrangement methods."}}
{"id": "2511.20877", "pdf": "https://arxiv.org/pdf/2511.20877", "abs": "https://arxiv.org/abs/2511.20877", "authors": ["Toby Anderson", "Max Collins", "Jamie Haddock", "Jackie Lok", "Elizaveta Rebrova"], "title": "Beyond Expectation: Concentration Inequalities for Randomized Iterative Methods", "categories": ["math.NA", "math.OC", "math.PR"], "comment": null, "summary": "Stochastic iterative methods are useful in a variety of large-scale numerical linear algebraic, machine learning, and statistical problems, in part due to their low-memory footprint. They are frequently used in a variety of applications, and thus it is imperative to have a thorough theoretical understanding of their behavior. Most theoretical convergence results for stochastic iterative methods provide bounds on the expected error of the iterates, and yield a type of average case analysis. However, understanding the behavior of these methods in the near-worst-case is desirable. For stochastic methods, this motivates providing bounds on the variance and concentration of their error, which can be used to generate confidence intervals around the bounds on their expected error.\n  Here, we provide upper bounds for the concentration and variance of the error of a general class of linear stochastic iterative methods, including the randomized Kaczmarz method and the randomized Gauss--Seidel method, and a more general class of nonlinear stochastic iterative methods, including the randomized Kaczmarz method for systems of linear inequalities.", "AI": {"tldr": "This paper provides theoretical bounds on the variance and concentration of error for stochastic iterative methods, going beyond expected error analysis to understand near-worst-case behavior.", "motivation": "Stochastic iterative methods are widely used in large-scale problems but most theoretical results only provide expected error bounds. Understanding their behavior in near-worst-case scenarios is important for practical applications.", "method": "The authors develop upper bounds for the concentration and variance of error for both linear stochastic iterative methods (like randomized Kaczmarz and Gauss-Seidel) and nonlinear stochastic iterative methods (like randomized Kaczmarz for linear inequalities).", "result": "The paper provides theoretical bounds on the variance and concentration of error for these stochastic methods, which can be used to generate confidence intervals around expected error bounds.", "conclusion": "This work enhances the theoretical understanding of stochastic iterative methods by providing variance and concentration bounds, enabling better analysis of their near-worst-case performance."}}
{"id": "2511.20930", "pdf": "https://arxiv.org/pdf/2511.20930", "abs": "https://arxiv.org/abs/2511.20930", "authors": ["Felix Rong", "Max Schneider", "Hendrik Nicolai", "Christian Hasse", "Andrea Gruber"], "title": "Direct numerical simulation of thermo-diffusively unstable premixed hydrogen-air flames in a fully-developed turbulent channel flow at $Re_\u03c4=530$", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": "26 pages, 20 figures", "summary": "Direct Numerical Simulations (DNS) of premixed hydrogen-air flames anchored in a fully-developed turbulent channel flow (TCF) are performed at a friction Reynolds number of $\\mathrm{Re}_\u03c4=530$ and thermochemical conditions susceptible to the emergence of intrinsic thermo-diffusive (TD) phenomena acting on the turbulent flame. Two premixed flames are studied: a slower flame ($\\varphi=0.25$), predominantly propagating within the core flow, and a faster one ($\\varphi=0.35$), reaching closer to the channel walls and intermittently quenching on it.\n  The present DNS database provides new insights into the characteristics of premixed flames susceptible to TD phenomena and propagating in realistic near-wall shear turbulence. The influence of varying turbulence intensity, and of wall-distance dependent time and length scales, on the flame propagation characteristics is evaluated through a detailed analysis of the local stretch factor $I_0$, quantifying reactivity enhancements caused by TD phenomena.\n  At $\\varphi=0.25$, the flame response to the fluid motions is mainly forced by the weaker turbulence present in the core flow. This results in an augmented $I_0$ compared to the laminar reference value, suggesting reactivity enhancement by the strongly non-linear interaction of TD phenomena with (relatively) weak turbulent motions present within the core flow. At $\\varphi=0.35$, as the flame propagates from the core flow towards the channel walls, the flame response is forced by turbulence of increasing intensity, resulting in a corresponding augmentation of the Karlovitz number. Crucially, as the flame propagates into the near-wall region, the peak value of $I_0$ is co-located with the peak Reynolds stresses ($y^+ \\sim 10$). This observation suggests a strong (local) synergistic interaction between TD phenomena and wall turbulence, ultimately resulting in significantly enhanced flame speed.", "AI": {"tldr": "DNS study of hydrogen-air flames in turbulent channel flow shows thermo-diffusive phenomena enhance flame reactivity, with synergistic interactions between thermo-diffusive effects and wall turbulence significantly increasing flame speed.", "motivation": "To understand how thermo-diffusive phenomena influence premixed flame propagation in realistic near-wall turbulent flows, particularly examining the interaction between flame chemistry and wall turbulence.", "method": "Direct Numerical Simulations of premixed hydrogen-air flames in turbulent channel flow at Re_\u03c4=530, analyzing two flame conditions (\u03c6=0.25 and \u03c6=0.35) with different propagation characteristics and proximity to walls.", "result": "Flame at \u03c6=0.25 shows enhanced reactivity due to thermo-diffusive interaction with core flow turbulence. Flame at \u03c6=0.35 exhibits peak reactivity enhancement co-located with peak Reynolds stresses near walls (y+~10), indicating strong synergistic interaction between thermo-diffusive phenomena and wall turbulence.", "conclusion": "Thermo-diffusive phenomena significantly enhance flame reactivity in turbulent flows, with particularly strong synergistic effects occurring near walls where thermo-diffusive effects interact with intense wall turbulence to substantially increase flame speed."}}
{"id": "2511.20988", "pdf": "https://arxiv.org/pdf/2511.20988", "abs": "https://arxiv.org/abs/2511.20988", "authors": ["Guowei Dai", "Yingxin Sun"], "title": "A sharp bound for the ratio of the first two eigenvalues of Robin Laplacian", "categories": ["math.AP"], "comment": null, "summary": "The celebrated conjecture by Payne, P\u00f3lya and Weinberger (1956) states that for the fixed membrane problem, the ratio of the first two eigenvalues, $\u03bb_2/\u03bb_1$, is maximized by a disk. A more general dimensional version of this conjecture was later resolved by Ashbaugh and Benguria in the 1990s. For the Robin Laplacian, Payne and Schaefer (2001) formulated an analogous conjecture, positing that the ratio $\u03bc_2/\u03bc_1$ is also maximized by a disk for a range of the boundary parameter $\u03c3$. This was later restated by Henrot in 2003. In this work, we affirm this conjecture for all dimensions $N\\geq2$ and for all $\u03c3$ greater than or equal to a critical positive value $\u03c3_*$ which may depend on $\u03a9$. Furthermore, we prove that the maximum value of $\u03bc_2/\u03bc_1$ is strictly decreasing in $\u03c3$ over the entire interval $(0,+\\infty)$. Our result provides a positive answer to a variant of Yau's Problem 77: by measuring the ratio of the first two eigenfrequencies, one can determine whether an elastically supported drum is circular.", "AI": {"tldr": "The paper proves that for the Robin Laplacian problem, the ratio of the first two eigenvalues \u03bc\u2082/\u03bc\u2081 is maximized by a disk for all dimensions N\u22652 and boundary parameters \u03c3\u2265\u03c3*, and that this maximum ratio strictly decreases with \u03c3.", "motivation": "To resolve the Payne-Schaefer-Henrot conjecture about maximizing the ratio of the first two eigenvalues for the Robin Laplacian, analogous to the classical Payne-P\u00f3lya-Weinberger conjecture for the fixed membrane problem.", "method": "Mathematical analysis of the Robin Laplacian eigenvalue problem, establishing properties of the eigenvalue ratio \u03bc\u2082/\u03bc\u2081 as a function of the boundary parameter \u03c3 and the domain \u03a9.", "result": "Proved that \u03bc\u2082/\u03bc\u2081 is maximized by a disk for all dimensions N\u22652 and \u03c3\u2265\u03c3*, and that the maximum value strictly decreases over (0,\u221e).", "conclusion": "This provides a positive answer to a variant of Yau's Problem 77, showing that measuring the ratio of the first two eigenfrequencies can determine whether an elastically supported drum is circular."}}
{"id": "2511.20901", "pdf": "https://arxiv.org/pdf/2511.20901", "abs": "https://arxiv.org/abs/2511.20901", "authors": ["Andrea Bonito", "Alan Demlow", "Joshua M. Siktar"], "title": "Alleviating missing boundary conditions in elliptic partial differential equations using interior point measurements", "categories": ["math.NA"], "comment": "33 pages", "summary": "We consider an optimal recovery problem for the Poisson problem when the boundary data is unknown. Compensating information is provided in the form of a finite number of measurements of the solution. A finite element algorithm for this problem was given in Binev et al. (2024), where measurements were assumed to be either bounded linear functionals of the solution or point measurements at locations lying anywhere in the closure of the computational domain. In contrast, we focus on the case of point measurements at locations lying in the interior of the domain. This lowers the regularity requirements placed on the solution. Also, a key ingredient in the recovery process is the finite element approximation of Riesz representers associated with the measurements. Our main result is a pointwise error estimate for the Riesz representers. We apply this to obtain improved estimates which measure the performance of the recovery algorithm in various norms.", "AI": {"tldr": "Optimal recovery for Poisson problem with unknown boundary data using interior point measurements, with improved error estimates for Riesz representers and recovery performance.", "motivation": "To address the Poisson problem when boundary data is unknown, using compensating interior point measurements to lower regularity requirements and improve recovery.", "method": "Finite element algorithm using point measurements in domain interior, with focus on finite element approximation of Riesz representers associated with measurements.", "result": "Derived pointwise error estimate for Riesz representers, leading to improved performance estimates for the recovery algorithm in various norms.", "conclusion": "Interior point measurements enable optimal recovery with lower regularity requirements, and the developed error estimates for Riesz representers enhance the recovery algorithm's performance analysis."}}
{"id": "2511.20976", "pdf": "https://arxiv.org/pdf/2511.20976", "abs": "https://arxiv.org/abs/2511.20976", "authors": ["Stephen G. Dale", "Nikita Kazeev", "Alastair J. A. Price", "Victor Posligua", "Stephan Roche", "O. Anatole von Lilienfeld", "Konstantin S. Novoselov", "Xavier Bresson", "Gianmarco Mengaldo", "Xudong Chen", "Terence J. O'Kane", "Emily R. Lines", "Matthew J. Allen", "Amandine E. Debus", "Clayton Miller", "Jiayu Zhou", "Hiroko H. Dodge", "David Rousseau", "Andrey Ustyuzhanin", "Ziyun Yan", "Mario Lanza", "Fabio Sciarrino", "Ryo Yoshida", "Zhidong Leong", "Teck Leong Tan", "Qianxiao Li", "Adil Kabylda", "Igor Poltavsky", "Alexandre Tkatchenko", "Sherif Abdulkader Tawfik", "Prathami Divakar Kamath", "Theo Jaffrelot Inizan", "Kristin A. Persson", "Bryant Y. Li", "Vir Karan", "Chenru Duan", "Haojun Jia", "Qiyuan Zhao", "Hiroyuki Hayashi", "Atsuto Seko", "Isao Tanaka", "Omar M. Yaghi", "Tim Gould", "Bun Chan", "Stefan Vuckovic", "Tianbo Li", "Min Lin", "Zehcen Tang", "Yang Li", "Yong Xu", "Amrita Joshi", "Xiaonan Wang", "Leonard W. T. Ng", "Sergei V. Kalinin", "Mahshid Ahmadi", "Jiyizhe Zhang", "Shuyuan Zhang", "Alexei Lapkin", "Ming Xiao", "Zhe Wu", "Kedar Hippalgaonkar", "Limsoon Wong", "Lorenzo Bastonero", "Nicola Marzari", "Dorye Luis Esteras Cordoba", "Andrei Tomut", "Alba Quinones Andrade", "Jose-Hugo Garcia"], "title": "AI4X Roadmap: Artificial Intelligence for the advancement of scientific pursuit and its future directions", "categories": ["physics.soc-ph", "cs.AI", "physics.ao-ph", "physics.atm-clus", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Artificial intelligence and machine learning are reshaping how we approach scientific discovery, not by replacing established methods but by extending what researchers can probe, predict, and design. In this roadmap we provide a forward-looking view of AI-enabled science across biology, chemistry, climate science, mathematics, materials science, physics, self-driving laboratories and unconventional computing. Several shared themes emerge: the need for diverse and trustworthy data, transferable electronic-structure and interatomic models, AI systems integrated into end-to-end scientific workflows that connect simulations to experiments and generative systems grounded in synthesisability rather than purely idealised phases. Across domains, we highlight how large foundation models, active learning and self-driving laboratories can close loops between prediction and validation while maintaining reproducibility and physical interpretability. Taken together, these perspectives outline where AI-enabled science stands today, identify bottlenecks in data, methods and infrastructure, and chart concrete directions for building AI systems that are not only more powerful but also more transparent and capable of accelerating discovery in complex real-world environments.", "AI": {"tldr": "This roadmap outlines the current state and future directions of AI-enabled science across multiple domains, highlighting key themes like trustworthy data, integrated workflows, and generative systems grounded in practical synthesis.", "motivation": "To provide a forward-looking view of how AI and machine learning are extending scientific discovery capabilities across various scientific domains, identifying current bottlenecks and charting future directions.", "method": "The paper presents a comprehensive roadmap analyzing AI-enabled science across biology, chemistry, climate science, mathematics, materials science, physics, self-driving laboratories, and unconventional computing. It examines shared themes and emerging approaches.", "result": "Identifies several shared themes: need for diverse and trustworthy data, transferable electronic-structure models, AI systems integrated into end-to-end scientific workflows, and generative systems focused on synthesisability rather than idealized phases.", "conclusion": "The roadmap outlines where AI-enabled science stands today, identifies bottlenecks in data, methods and infrastructure, and charts concrete directions for building more powerful, transparent AI systems capable of accelerating discovery in complex real-world environments."}}
{"id": "2511.21023", "pdf": "https://arxiv.org/pdf/2511.21023", "abs": "https://arxiv.org/abs/2511.21023", "authors": ["Xiaoxu Xu", "Guanghui Hu"], "title": "Simultaneously recover two constant coefficients and a polygon with a single pair of Cauchy data for the Helmholtz equation", "categories": ["math.AP"], "comment": "33 pages and 100 figures", "summary": "This paper is concerned with an inverse boundary value problem for the Helmholtz equation over a bounded domain. The aim is to reconstruct two constant coefficients together with the location and shape of a Dirichlet polygonal obstacle from a single pair of Cauchy data. Uniqueness results are verified under some a priori assumptions and the one-wave factorization method has been adapted to recover the polygonal obstacle as well as the two coefficients. A modified factorization using the Dirichlet-to-Neumann operator is employed to overcome difficulties arising from possible eigenvalues. Intensive numerical examples indicate that our method is efficient.", "AI": {"tldr": "This paper presents a method to reconstruct both a polygonal obstacle and two constant coefficients from a single pair of Cauchy data for the Helmholtz equation, using adapted factorization methods.", "motivation": "To solve the inverse boundary value problem for the Helmholtz equation by simultaneously recovering obstacle geometry and material coefficients from limited measurement data.", "method": "Adapted the one-wave factorization method to recover polygonal obstacles and coefficients, and employed a modified factorization using the Dirichlet-to-Neumann operator to handle eigenvalue issues.", "result": "Verified uniqueness results under certain assumptions and demonstrated through intensive numerical examples that the method is efficient.", "conclusion": "The proposed factorization approach successfully reconstructs both polygonal obstacles and constant coefficients from single Cauchy data pairs, with numerical validation showing method efficiency."}}
{"id": "2511.20971", "pdf": "https://arxiv.org/pdf/2511.20971", "abs": "https://arxiv.org/abs/2511.20971", "authors": ["Marwa Ennaceur"], "title": "Sharp Ascent--Descent Spectral Stability under Strong Resolvent Convergence", "categories": ["math.NA", "math.FA", "math.SP"], "comment": null, "summary": "We establish sharp stability results for of non--selfadjoint the ascent and descent spectra under strong resolvent convergence (SRS), a natural framework for finite element approximations of non-selfadjoint and singularly perturbed operators. The key quantitative hypothesis is the reduced minimum modulus $\u03b3(T-\u03bb)>0$, which guarantees closed range and enables the transfer of the Kaashoek -- Taylor criteria via gap convergence of operator graphs. At the essential level, B--Fredholm theory extends stability to powers $(T-\u03bb)^m$ provided $\u03b3((T-\u03bb)^j)>0$ for all $1\\le j\\le m$. We introduce a computable finite-element diagnostic $\u03b3_h = \u03c3_{\\min}(M^{-1/2}(A_h-\u03bbM)M^{-1/2})$, which serves as a practical surrogate for $\u03b3(T-\u03bb)$ and remains uniformly positive even in convection-dominated regimes when stabilized schemes (e.g., SUPG) are employed. Numerical experiments confirm that $\\liminf_{h\\to0}\u03b3_h>0$ is both necessary and sufficient for spectral stability, while a Volterra-type counterexample demonstrates the indispensability of the closed-range condition for powers. The analysis clarifies why norm resolvent convergence fails for rough or singular limits, and how SRS-combined with quantitative control of $\u03b3_h$--rescues ascent--descent stability in realistic computational settings.", "AI": {"tldr": "Sharp stability results for non-selfadjoint operator spectra under strong resolvent convergence, with computable finite-element diagnostics for practical verification.", "motivation": "To establish spectral stability for finite element approximations of non-selfadjoint and singularly perturbed operators, addressing limitations of norm resolvent convergence in rough or singular limits.", "method": "Uses reduced minimum modulus \u03b3(T-\u03bb)>0 as key hypothesis, transfers Kaashoek-Taylor criteria via gap convergence, extends to powers using B-Fredholm theory, and introduces computable finite-element diagnostic \u03b3_h as surrogate for \u03b3(T-\u03bb).", "result": "Numerical experiments confirm liminf_{h\u21920}\u03b3_h>0 is necessary and sufficient for spectral stability, with counterexample showing closed-range condition is indispensable for powers.", "conclusion": "Strong resolvent convergence combined with quantitative control of \u03b3_h rescues ascent-descent stability in computational settings, clarifying why norm resolvent convergence fails for rough/singular limits."}}
{"id": "2511.21119", "pdf": "https://arxiv.org/pdf/2511.21119", "abs": "https://arxiv.org/abs/2511.21119", "authors": ["Riccardo Fantoni"], "title": "Quantum Hard Spheres with Affine Quantization", "categories": ["cond-mat.stat-mech", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "physics.comp-ph", "quant-ph"], "comment": "7 pages, 2 figures, 1 table", "summary": "We study a fluid of quantum hard-spheres treated with affine-quantization. Assuming that the fluid obeys to Bose-Einstein statistics we solve for its thermodynamic properties using the path integral Monte Carlo method.", "AI": {"tldr": "Quantum hard-sphere fluid analyzed using affine-quantization and path integral Monte Carlo methods", "motivation": "To study the thermodynamic properties of quantum hard-sphere fluids using modern quantization approaches", "method": "Affine-quantization treatment combined with path integral Monte Carlo simulations for Bose-Einstein statistics", "result": "Thermodynamic properties were solved for the quantum hard-sphere fluid system", "conclusion": "Successfully applied affine-quantization and Monte Carlo methods to analyze quantum hard-sphere fluid thermodynamics"}}
{"id": "2511.21230", "pdf": "https://arxiv.org/pdf/2511.21230", "abs": "https://arxiv.org/abs/2511.21230", "authors": ["Patrik Knopf", "Anastasija Pe\u0161i\u0107", "Dennis Trautwein"], "title": "Curvature-driven pattern formation in biomembranes: A gradient flow approach", "categories": ["math.AP"], "comment": null, "summary": "In this work, we study a phase-field model for curvature-driven pattern formation in biomembranes. The model is derived as a gradient flow of an energy functional that approximates the two-phase Canham--Helfrich energy. This leads to a Cahn--Hilliard-type equation with cross diffusion for the relative chemical concentration of one lipid phase, coupled to a fourth-order reaction-diffusion equation describing the height profile of the membrane. We first prove the existence of weak solutions for the case of regular double-well potentials, using a minimizing movement scheme to construct approximate solutions. The analysis is then extended to singular potentials, e.g., the Flory--Huggins potential, by approximating them with a Moreau--Yosida regularization. For both cases, we establish higher regularity, continuous dependence on the initial data, and consequently the uniqueness of weak solutions. Finally, we propose a well-posed finite element discretization of the model and present numerical experiments illustrating the effect of different physical parameters on the resulting membrane patterns. Depending on the parameter regime, we observe purely striped, dotted, or snake-like structures.", "AI": {"tldr": "Analysis of a phase-field model for curvature-driven pattern formation in biomembranes, including existence, uniqueness, and numerical simulation of weak solutions.", "motivation": "To study pattern formation in biomembranes using a curvature-driven phase-field model derived from the Canham-Helfrich energy.", "method": "Derived gradient flow of energy functional approximating two-phase Canham-Helfrich energy, leading to coupled Cahn-Hilliard and fourth-order reaction-diffusion equations. Used minimizing movement scheme for regular potentials and Moreau-Yosida regularization for singular potentials.", "result": "Proved existence of weak solutions for both regular and singular potentials, established higher regularity, continuous dependence on initial data, and uniqueness. Numerical simulations showed striped, dotted, and snake-like membrane patterns depending on parameters.", "conclusion": "Developed a comprehensive mathematical framework for curvature-driven pattern formation in biomembranes with rigorous analysis and numerical validation."}}
{"id": "2511.21168", "pdf": "https://arxiv.org/pdf/2511.21168", "abs": "https://arxiv.org/abs/2511.21168", "authors": ["Xianxian Cao", "Zhen Guan", "Junjun Wang"], "title": "A new analytical technique of the fully implicit Crank-Nicolson discontinuous Galerkin method for the Ginzburg-Landau Model", "categories": ["math.NA"], "comment": null, "summary": "In this paper, a fully implicit Crank-Nicolson discontinuous Galerkin method is proposed for solving the Ginzburg-Landau equation. By leveraging a novel analytical technique, we rigorously establish the unique solvability of the constructed numerical scheme, as well as its unconditionally optimal error estimates under both the \\(L^2\\)-norm and the energy norm. The core of the proof hinges on the \\(L^2\\)-norm boundedness of the numerical solution and the refined estimation of the cubic nonlinear term. Finally, two numerical examples are presented to validate the theoretical findings.", "AI": {"tldr": "A fully implicit Crank-Nicolson discontinuous Galerkin method is developed for solving the Ginzburg-Landau equation, with rigorous proofs of unique solvability and unconditionally optimal error estimates.", "motivation": "To develop a robust numerical method for the Ginzburg-Landau equation that guarantees unique solvability and provides optimal error estimates without time step restrictions.", "method": "A fully implicit Crank-Nicolson discontinuous Galerkin method with novel analytical techniques to handle the cubic nonlinear term and establish mathematical properties.", "result": "The method achieves unique solvability and unconditionally optimal error estimates in both L\u00b2-norm and energy norm, validated by numerical examples.", "conclusion": "The proposed method provides a reliable and efficient numerical framework for solving the Ginzburg-Landau equation with proven mathematical guarantees."}}
{"id": "2511.21425", "pdf": "https://arxiv.org/pdf/2511.21425", "abs": "https://arxiv.org/abs/2511.21425", "authors": ["Muhammad Bilal", "Ashwin Renganathan"], "title": "$\\texttt{CRLS}$: Convolutional Regularized Least Squares Framework for Reduced Order Modeling of Transonic Flows", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": "24 pages, 13 figures", "summary": "We develop a convolutional regularized least squares ($\\texttt{CRLS}$) framework for reduced-order modeling of transonic flows with shocks. Conventional proper orthogonal decomposition (POD) based reduced models are attractive because of their optimality and low online cost; however, but they perform poorly when snapshots contain parameter-dependent discontinuities, leading to smeared shocks, stair-stepping, or non-physical oscillations. In $\\texttt{CRLS}$, we first map each full-order snapshot to a smoother representation by applying a one-dimensional Gaussian convolution with reflect padding along the flow field coordinates. The convolution hyperparameters (kernel width and support) are selected automatically by Bayesian optimization on a held-out set of snapshots. POD bases are then extracted from the smoothed data, and the parametric dependence of the POD coefficients is learned via radial basis function interpolation. To recover sharp shock structures, we introduce an efficient deconvolution step formulated as a regularized least squares problem, where the regularization centers the reconstruction around a nearest-neighbor reference snapshot in parameter space. The resulting $\\texttt{CRLS}$ surrogate is evaluated on inviscid transonic flow over the RAE2822 airfoil, modeled by the steady compressible Euler equations solved with SU2 over a Latin hypercube sample of Mach number and angle of attack. Compared with standard POD and smoothed-POD baselines, $\\texttt{CRLS}$ yields markedly improved shock location and strength, lower surface-pressure and field-level errors, and a $42$\\% reduction in the number of POD modes required to capture a fixed fraction of snapshot energy. These results demonstrate that $\\texttt{CRLS}$ provides an accurate, data-efficient, and largely automated route to shock-aware reduced order models for high-speed aerodynamic design.", "AI": {"tldr": "CRLS framework combines Gaussian convolution smoothing, POD basis extraction, and regularized deconvolution to create accurate reduced-order models for transonic flows with shocks, outperforming standard POD methods.", "motivation": "Standard POD-based reduced models perform poorly with parameter-dependent discontinuities like shocks, leading to smeared shocks, stair-stepping, or non-physical oscillations in transonic flows.", "method": "1) Apply 1D Gaussian convolution with reflect padding to smooth snapshots, 2) Use Bayesian optimization for hyperparameter selection, 3) Extract POD bases from smoothed data, 4) Learn parametric dependence via radial basis function interpolation, 5) Add deconvolution step as regularized least squares problem to recover sharp shocks.", "result": "CRLS shows markedly improved shock location and strength, lower surface-pressure and field-level errors, and 42% reduction in POD modes required to capture fixed snapshot energy fraction compared to standard POD and smoothed-POD baselines.", "conclusion": "CRLS provides an accurate, data-efficient, and largely automated route to shock-aware reduced order models for high-speed aerodynamic design."}}
{"id": "2511.21275", "pdf": "https://arxiv.org/pdf/2511.21275", "abs": "https://arxiv.org/abs/2511.21275", "authors": ["Henrik Ueberschaer"], "title": "A Liouville-type theorem for Schr\u00f6dinger equations with nonnegative potential", "categories": ["math.AP", "math-ph"], "comment": "9 pages", "summary": "Let $u$ be a solution of $\u0394u=Vu$ on $\\mathbb{R}^d$, where $V$ be continuous, nonnegative and bounded. We prove that the condition $$\\int_{r_j\\leq|x|\\leq r_j+1}|u(x)|^2dx\\to 0,$$ along any sequence $(r_j)$, $r_j\\nearrow+\\infty$, implies $u\\equiv 0$ on $\\mathbb{R}^d$. In particular, this implies the Landis conjecture for solutions satisfying a sufficiently fast algebraic decay. These results are generalized to exterior domains as well as for a class of nonlinear Schr\u00f6dinger equations under suitable conditions on the zero set of the potential.", "AI": {"tldr": "The paper proves that solutions to \u0394u=Vu with nonnegative bounded potential V must vanish identically if their L^2 norm decays to zero over annuli of fixed width at infinity. This establishes the Landis conjecture for algebraically decaying solutions.", "motivation": "To prove the Landis conjecture for Schr\u00f6dinger equations, which concerns the vanishing of solutions that decay sufficiently fast at infinity when the potential is nonnegative.", "method": "Analyze solutions of \u0394u=Vu with continuous, nonnegative bounded potential V, showing that if the L^2 norm over annuli of width 1 tends to zero along any sequence r_j\u2192\u221e, then u must be identically zero.", "result": "The main result proves that the decay condition \u222b_{r_j\u2264|x|\u2264r_j+1}|u(x)|^2dx\u21920 implies u\u22610 on \u211d^d, establishing the Landis conjecture for algebraically decaying solutions.", "conclusion": "The results extend to exterior domains and certain nonlinear Schr\u00f6dinger equations, providing conditions under which decaying solutions must vanish identically when the potential is nonnegative."}}
{"id": "2511.21198", "pdf": "https://arxiv.org/pdf/2511.21198", "abs": "https://arxiv.org/abs/2511.21198", "authors": ["Wei Qu", "Siu-Long Lei", "Sean Y. Hon", "Yuan-Yuan Huang"], "title": "Optimal preconditioning techniques for finite volume approximation of three-dimensional conservative space-fractional diffusion equations", "categories": ["math.NA"], "comment": null, "summary": "A Crank-Nicolson finite volume approximation for three-dimensional conservative space-fractional diffusion equation results in large and dense three-level Toeplitz discrete linear systems. Preconditioned Krylov subspace methods with sine transform-based preconditioners are developed to solve these systems, including the preconditioned conjugate gradient (PCG) method for the symmetric case and the preconditioned generalized minimal residual (PGMRES) method for the non-symmetric case. Moreover, we provide detailed analysis of the convergence of these Krylov subspace methods. Specifically, for the symmetric case, we prove the spectra of the preconditioned matrices are uniformly bounded in the open interval (1/2, 3/2), which results in a linear convergence rate of the PCG method. For the non-symmetric case, we demonstrate that the PGMRES method also achieves a linear convergence rate independent of discretization stepsizes from the residual point of view. These results imply that the iteration counts of the PCG and PGMRES methods are uniformly bounded and independent of the matrix sizes. Numerical experiments in both symmetric and non-symmetric cases in two- and three-dimensions are conducted to confirm the optimal performance of the proposed preconditioned Krylov subspace methods.", "AI": {"tldr": "Preconditioned Krylov subspace methods with sine transform-based preconditioners are developed to efficiently solve large dense linear systems from space-fractional diffusion equations, achieving linear convergence rates independent of matrix sizes.", "motivation": "Three-dimensional space-fractional diffusion equations result in large dense Toeplitz linear systems that are computationally challenging to solve efficiently.", "method": "Developed preconditioned conjugate gradient (PCG) for symmetric cases and preconditioned GMRES (PGMRES) for non-symmetric cases using sine transform-based preconditioners.", "result": "Proved preconditioned matrices have spectra bounded in (1/2, 3/2), ensuring linear convergence rates independent of discretization stepsizes. Numerical experiments in 2D and 3D confirm optimal performance.", "conclusion": "The proposed preconditioned Krylov subspace methods provide efficient, scalable solvers for space-fractional diffusion equations with iteration counts independent of matrix sizes."}}
{"id": "2511.21494", "pdf": "https://arxiv.org/pdf/2511.21494", "abs": "https://arxiv.org/abs/2511.21494", "authors": ["Ziying Xiang", "Jun-Wei Luo", "Shu-Shen Li"], "title": "Unified interface dipole theory for Fermi level pinning effect at metal-semiconductor contacts", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "23 pages, 8 figures", "summary": "We present a unified bond dipole theory for metal-semiconductor interfaces to explain the microscopic origin of interface dipoles and Fermi level pinning (FLP) in terms of Harrison's bond-orbital model. By combining first-principles calculations with tight-binding analysis, we show that localized bonding between semiconductor surface dangling bonds and metal orbitals is sufficient to generate a large interface dipole and induce strong FLP, even when only a single metal monolayer is present. Within this framework, metal-induced gap states (MIGS), dangling-bond-induced surface states (DBSS), and bonding states embedded in the valence band are all understood as different outcomes of the same underlying interface bonding mechanism, rather than as independent causes of FLP. We further establish that the key parameter governing FLP strength is the density of surface dangling bonds that can form new chemical bonds with the metal, which directly controls the magnitude of the bond-induced interface dipole. This picture naturally explains the weaker pinning observed in more ionic semiconductors than in covalent ones and provides practical guidance for engineering metal-semiconductor interfaces and tuning Schottky barrier heights.", "AI": {"tldr": "A unified bond dipole theory explains Fermi level pinning at metal-semiconductor interfaces through localized bonding between semiconductor dangling bonds and metal orbitals, showing that even single metal monolayers can cause strong pinning.", "motivation": "To provide a microscopic understanding of interface dipoles and Fermi level pinning by unifying various phenomena (MIGS, DBSS, bonding states) under a single bonding mechanism rather than treating them as independent causes.", "method": "Combined first-principles calculations with tight-binding analysis using Harrison's bond-orbital model to study localized bonding between semiconductor surface dangling bonds and metal orbitals.", "result": "Localized bonding generates large interface dipoles and strong Fermi level pinning; pinning strength is governed by the density of surface dangling bonds that can form chemical bonds with the metal.", "conclusion": "The theory explains weaker pinning in ionic semiconductors vs covalent ones and provides practical guidance for engineering metal-semiconductor interfaces and tuning Schottky barrier heights."}}
{"id": "2511.21294", "pdf": "https://arxiv.org/pdf/2511.21294", "abs": "https://arxiv.org/abs/2511.21294", "authors": ["Minling Li", "Changzhen Sun", "Chao Wang", "Dongyi Wei", "Zhifei Zhang"], "title": "Transition threshold for the Navier-Stokes-Coriolis system at high Reynolds numbers", "categories": ["math.AP"], "comment": null, "summary": "The transition mechanism from laminar flow to turbulent flow is a central problem in hydrodynamic stability theory. To shed light on this transition mechanism, Trefethen et al.({\\it \\small Science 1993}) proposed the transition threshold problem, aiming to quantify the magnitude of perturbations required to trigger instability and determine their scaling with the Reynolds number. In this paper, we investigate the transition threshold of Couette flow for the three-dimensional incompressible Navier-Stokes-Coriolis system in the high Reynolds number regime ($\\mathrm{Re}\\gg 1$). By exploiting the combined effects of rotation (dispersion) and mixing mechanisms, we derive an improved stability threshold scaling in $\\mathrm{Re}$. Precisely, we show that if the initial perturbation satisfies $$\\|v_{in}-(y, 0, 0)\\|_{\\tilde{H}(\\mathbb T \\times \\mathbb D)}\\leq \u03b5_0 \\,\\mathrm{Re}^{-\u03b1},$$ with any $\u03b1>\\frac 23$ and $\\tilde{H}=H^6 \\cap W^{3,1}$ for $\\mathbb D=\\mathbb{R}^2$, and with any $\u03b1\\geq\\frac 56$ and $\\tilde{H}=H^6$ for $\\mathbb D=\\mathbb{R}\\times\\mathbb{T}$, the corresponding solution of the Navier-Stokes-Coriolis system exists globally in time and remains asymptotically close to the Couette flow. The main analytical challenge arises from the anisotropic nature of the estimates for the zero modes and from the interactions between zero and non-zero modes, which we address using an anisotropic Sobolev space directly tailored to the zero modes. Additionally, we introduce a new dispersive structure for the zero modes and derive suitable Strichartz-type estimates. These tools enable us to exploit both the nonlinear structure and the improved dispersive behavior of certain good components of the zero modes, which play a crucial role in achieving the improved stability threshold.", "AI": {"tldr": "Improved stability threshold for Couette flow in 3D Navier-Stokes-Coriolis system: perturbations of magnitude Re^{-\u03b1} with \u03b1>2/3 (for R\u00b2) or \u03b1\u22655/6 (for R\u00d7T) ensure global stability.", "motivation": "To understand the transition from laminar to turbulent flow by quantifying perturbation thresholds that trigger instability in Couette flow under rotation.", "method": "Combined analysis of rotation (dispersion) and mixing effects using anisotropic Sobolev spaces tailored to zero modes, new dispersive structures, and Strichartz-type estimates.", "result": "Derived improved stability threshold scaling: perturbations \u2264 \u03b5\u2080Re^{-\u03b1} with \u03b1>2/3 or \u03b1\u22655/6 ensure global existence and asymptotic proximity to Couette flow.", "conclusion": "Rotation and mixing mechanisms enable improved stability thresholds, with anisotropic analysis crucial for handling zero/non-zero mode interactions in high Reynolds number regime."}}
{"id": "2511.21224", "pdf": "https://arxiv.org/pdf/2511.21224", "abs": "https://arxiv.org/abs/2511.21224", "authors": ["Ruofeng Feng", "Jack R. C. King", "Steven J. Lind"], "title": "A p-adaptive high-order mesh-free framework for fluid simulations in complex geometries", "categories": ["math.NA", "physics.flu-dyn"], "comment": "19 pages, 15 figures", "summary": "This paper presents a novel p-adaptive, high-order mesh-free framework for the accurate and efficient simulation of fluid flows in complex geometries. High-order differential operators are constructed locally for arbitrary node distributions using linear combinations of anisotropic basis functions, formulated to ensure the exact reproduction of polynomial fields up to the specified p order. A dynamic p-refinement strategy is developed to refine (increase) or de-refine (decrease) the polynomial order used to approximate derivatives at each node. A new refinement indicator for mesh-free methods is proposed, based on local error estimates of the Laplacian operator, and is incorporated into the solution procedure at minimal added computational cost. Based on this error indicator, a refinement criterion is established to locally adjust the polynomial order p for the solution. The proposed adaptive mesh-free scheme is then applied to a range of canonical PDEs, and its potential is demonstrated in two-dimensional simulations of a compressible reacting flow in porous media. For the test cases studied, the proposed method exhibits potential to save up to 50% of computational costs while maintaining the specified level of accuracy. The results confirm that the developed p-adaptive high-order mesh-free method effectively captures highly non-linear regions where high-order approximation is necessary and reduces computational costs compared to the non-adaptive method, preserving high accuracy and solution stability.", "AI": {"tldr": "A p-adaptive high-order mesh-free framework for fluid flow simulation that dynamically adjusts polynomial order using local error estimates, achieving up to 50% computational cost savings while maintaining accuracy.", "motivation": "To enable accurate and efficient simulation of fluid flows in complex geometries by developing an adaptive mesh-free method that can handle highly non-linear regions while reducing computational costs.", "method": "High-order differential operators constructed using anisotropic basis functions for arbitrary node distributions, with dynamic p-refinement strategy based on local Laplacian error estimates to adjust polynomial order.", "result": "The method successfully captures non-linear regions requiring high-order approximation and achieves up to 50% computational cost savings compared to non-adaptive methods while maintaining accuracy and stability.", "conclusion": "The p-adaptive high-order mesh-free method effectively balances computational efficiency and accuracy, demonstrating significant potential for complex fluid flow simulations in porous media and other applications."}}
{"id": "2511.21587", "pdf": "https://arxiv.org/pdf/2511.21587", "abs": "https://arxiv.org/abs/2511.21587", "authors": ["Mario Castro"], "title": "Approximate Bayesian Computation Made Easy: A Practical Guide to ABC-SMC for Dynamical Systems with \\texttt{pymc}", "categories": ["q-bio.PE", "physics.comp-ph"], "comment": "17 pages, 10 figures. Link to github respository", "summary": "Mechanistic models are essential tools across ecology, epidemiology, and the life sciences, but parameter inference remains challenging when likelihood functions are intractable. Approximate Bayesian Computation with Sequential Monte Carlo (ABC-SMC) offers a powerful likelihood-free alternative that requires only the ability to simulate data from mechanistic models. Despite its potential, many researchers remain hesitant to adopt these methods due to perceived complexity. This tutorial bridges that gap by providing a practical, example-driven introduction to ABC-SMC using Python. From predator-prey dynamics to hierarchical epidemic models, we illustrate by example how to implement, diagnose, and interpret ABC-SMC analyses. Each example builds intuition about when and why ABC-SMC works, how partial observability affects parameter identifiability, and how hierarchical structures naturally emerge in Bayesian frameworks. All code leverages PyMC's modern probabilistic programming interface, ensuring reproducibility and easy adaptation to new problems. The code its fully available for download at \\href{https://github.com/mariocastro73/ABCSMC_pymc_by_example}{mariocastro73/ABCSMC\\_pymc\\_by\\_example}", "AI": {"tldr": "A practical tutorial introducing ABC-SMC for likelihood-free parameter inference in mechanistic models using Python and PyMC, with examples from ecology and epidemiology.", "motivation": "Parameter inference in mechanistic models is challenging when likelihood functions are intractable, and researchers are hesitant to adopt ABC-SMC due to perceived complexity.", "method": "Example-driven approach using Python and PyMC's probabilistic programming interface, covering implementation, diagnosis, and interpretation of ABC-SMC analyses with predator-prey dynamics and hierarchical epidemic models.", "result": "Provides working code examples that demonstrate how to apply ABC-SMC, build intuition about when it works, understand partial observability effects, and implement hierarchical structures in Bayesian frameworks.", "conclusion": "ABC-SMC is a powerful likelihood-free alternative for parameter inference in mechanistic models, and this tutorial makes it accessible through practical examples and reproducible code."}}
{"id": "2511.21303", "pdf": "https://arxiv.org/pdf/2511.21303", "abs": "https://arxiv.org/abs/2511.21303", "authors": ["Kai Sheng"], "title": "Normalized Solutions for Schroedinger-Bopp-Podolsky Systems in Bounded Domains with General Nonlinearities", "categories": ["math.AP"], "comment": null, "summary": "In this paper, by adapting the perturbation method, we study normalized standing wave solutions for the following nonlinear Schrodinger-Bopp-Podolsky system:\n  - Delta u + q(x) phi u = omega u + f(u) in Omega, - Delta phi + a^2 Delta^2 phi = q(x) u^2 in Omega,\n  where Omega is a smooth bounded domain in R^3, a > 0, and omega is the Lagrange multiplier associated with the L^2 mass constraint integral over Omega of u^2 equals mu, and f: R -> R is a continuous function satisfying some technical conditions. In particular, we prove the existence of normalized solutions for all masses mu in an interval (0, mu_0), under either Navier or Neumann boundary conditions for phi. Moreover, when f is odd, we obtain multiplicity of normalized solutions; and if Omega is star-shaped, we further obtain a normalized ground state solution.", "AI": {"tldr": "Existence and multiplicity of normalized standing wave solutions for a nonlinear Schr\u00f6dinger-Bopp-Podolsky system with mass constraint, using perturbation methods.", "motivation": "To study normalized solutions (with fixed L^2 mass) for coupled Schr\u00f6dinger-Bopp-Podolsky systems, which combine quantum mechanics with Bopp-Podolsky electrodynamics in bounded domains.", "method": "Adapted perturbation method to analyze the coupled system with Navier or Neumann boundary conditions for the Bopp-Podolsky field, considering technical conditions on the nonlinearity f.", "result": "Proved existence of normalized solutions for all masses \u03bc in (0, \u03bc\u2080), multiplicity when f is odd, and normalized ground states when \u03a9 is star-shaped.", "conclusion": "The perturbation method successfully establishes existence and multiplicity results for normalized standing waves in the coupled Schr\u00f6dinger-Bopp-Podolsky system under various geometric and nonlinear conditions."}}
{"id": "2511.21252", "pdf": "https://arxiv.org/pdf/2511.21252", "abs": "https://arxiv.org/abs/2511.21252", "authors": ["Gerd Steinebach"], "title": "Rodas6P and Tsit5DA - two new Rosenbrock-type methods for DAEs", "categories": ["math.NA"], "comment": null, "summary": "Two new Rosenbrock methods for solving index-1 differential algebraic equations are presented. Rodas6P is a sixth-order method based on the same design principles as the Rodas3P, Rodas4P, and Rodas5P methods. Tsit5DA is based on an explicit solution approach for the differential equations and a linear-implicit approach for the algebraic equations. Such a fourth-order method has already been presented in Rentrop, Roche & Steinebach, 1989. Tsit5DA now provides a significantly improved fifth-order method which is based on the well known Tsit5 method. The theoretical properties of the new methods are verified by some order tests and benchmarks.", "AI": {"tldr": "Two new Rosenbrock methods for solving index-1 differential algebraic equations: Rodas6P (sixth-order) and Tsit5DA (fifth-order) based on explicit and linear-implicit approaches.", "motivation": "To develop improved higher-order methods for solving index-1 differential algebraic equations, building on existing methods like Rodas series and Tsit5.", "method": "Rodas6P follows Rosenbrock method design principles similar to Rodas3P-5P. Tsit5DA combines explicit solution for differential equations with linear-implicit approach for algebraic equations, improving upon previous fourth-order methods.", "result": "Successfully developed sixth-order Rodas6P and fifth-order Tsit5DA methods with verified theoretical properties through order tests and benchmarks.", "conclusion": "The new methods provide significant improvements in order and performance for solving index-1 differential algebraic equations, with Rodas6P achieving sixth-order accuracy and Tsit5DA providing a fifth-order enhancement over existing fourth-order approaches."}}
{"id": "2511.21651", "pdf": "https://arxiv.org/pdf/2511.21651", "abs": "https://arxiv.org/abs/2511.21651", "authors": ["Chinmay Shrikhande", "Arnab Bachhar", "Aaron Rodriguez Jimenez", "Nicholas J. Mayhall"], "title": "Rapid ground state energy estimation with a Sparse Pauli Dynamics-enabled Variational Double Bracket Flow", "categories": ["quant-ph", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Ground state energy estimation for strongly correlated quantum systems remains a central challenge in computational physics and chemistry. While tensor network methods like DMRG provide efficient solutions for one-dimensional systems, higher-dimensional problems remain difficult. Here we present a variational double bracket flow (vDBF) algorithm that leverages Sparse Pauli Dynamics, a technique originally developed for classical simulation of quantum circuits, to efficiently approximate ground state energies. By combining greedy operator selection with coefficient truncation and energy-variance extrapolation, the method achieves less than 1% error relative to DMRG benchmarks for both Heisenberg and Hubbard models in one and two dimensions. For a 10x10 Heisenberg lattice (100 qubits), vDBF obtains accurate results in approximately 10 minutes on a single CPU thread, compared to over 50 hours on 64 threads for DMRG. For an 8x8 Hubbard model (128 qubits), the speedup is even more pronounced. These results demonstrate that classical simulation techniques developed in the context of quantum advantage benchmarking can provide practical tools for many-body physics.", "AI": {"tldr": "A variational double bracket flow algorithm using Sparse Pauli Dynamics achieves accurate ground state energy estimation for strongly correlated quantum systems with significant speedups over traditional methods like DMRG.", "motivation": "Ground state energy estimation for strongly correlated quantum systems is challenging, especially in higher dimensions where tensor network methods like DMRG struggle.", "method": "Combines greedy operator selection with coefficient truncation and energy-variance extrapolation using Sparse Pauli Dynamics, a technique originally developed for quantum circuit simulation.", "result": "Achieves less than 1% error relative to DMRG benchmarks for Heisenberg and Hubbard models in 1D and 2D. For a 10x10 Heisenberg lattice (100 qubits), runs in ~10 minutes on single CPU vs 50+ hours on 64 threads for DMRG.", "conclusion": "Classical simulation techniques from quantum advantage benchmarking can provide practical tools for many-body physics, offering significant computational advantages."}}
{"id": "2511.21321", "pdf": "https://arxiv.org/pdf/2511.21321", "abs": "https://arxiv.org/abs/2511.21321", "authors": ["Mengni Li", "You Li"], "title": "Existence and nonexistence of viscosity solutions for a class of degenerate/singular eigenvalue type equations", "categories": ["math.AP"], "comment": "All comments are welcome", "summary": "This paper is devoted to a complete classification on the existence and nonexistence results of viscosity solutions to the general Dirichlet problem for a class of eigenvalue type equations. With the distance function included in the right-hand side, this type of equations can be degenerate and (or) singular near the boundary of uniformly convex domains. One highlight is that all cases related to the exponent of the distance function are investigated. Moreover, when viscosity solutions exist, we derive a series of global estimates based on the distance function. The key ingredients of this paper include adaptions of the Perron method and comparison principle as well as constructions of suitable classical sub-solutions and super-solutions.", "AI": {"tldr": "Complete classification of existence/nonexistence of viscosity solutions for eigenvalue-type Dirichlet problems with distance function terms, including all exponent cases and global estimates.", "motivation": "To systematically study degenerate/singular eigenvalue equations with distance function terms near boundaries of convex domains, addressing all possible exponent cases.", "method": "Adapted Perron method, comparison principle, and construction of classical sub-solutions and super-solutions.", "result": "Complete classification of existence/nonexistence results and derivation of global estimates based on distance function when solutions exist.", "conclusion": "Successfully classified all cases related to distance function exponents and established global estimates for viscosity solutions in degenerate/singular eigenvalue equations."}}
{"id": "2511.21268", "pdf": "https://arxiv.org/pdf/2511.21268", "abs": "https://arxiv.org/abs/2511.21268", "authors": ["Pasqua D'Ambra", "Fabio Durastante", "Salvatore Filippone"], "title": "Parallel matching-based AMG preconditioners for elliptic equations discretized by IgA", "categories": ["math.NA"], "comment": null, "summary": "Isogeometric analysis (IgA) offers enhanced approximation capabilities for the discretization of elliptic boundary-value problems, yet it results in large, sparse, and increasingly ill-conditioned linear systems due to higher interconnectivity among degrees of freedom. In particular, the discretization with tensor-product B-splines or NURBS of degree $p$ on a mesh with $n$ elements per parametric direction leads to symmetric positive-definite systems of the form $K\\mathbf{u} = \\mathbf{F}$, where the matrix bandwidth and condition number scale unfavorably with both $p$ and spatial dimension $d$. To address the computational challenges posed by such systems, especially in three-dimensional or high-order scenarios, Krylov subspace methods with specialized preconditioners become essential. This paper investigates the efficacy of algebraic multigrid (AMG) preconditioners tailored for IgA-based discretizations, with a focus on performance in modern high-performance computing (HPC) environments. Leveraging the Parallel Sparse Computation Toolkit (PSCToolkit), we explore distributed-memory and GPU-accelerated strategies for solving large-scale problems. The study assesses algorithmic efficiency and scalability across a range of benchmark tests. The results demonstrate that AMG preconditioners can achieve robust and scalable performance, confirming their potential as practical solvers for large IgA systems in engineering and scientific applications.", "AI": {"tldr": "This paper investigates the use of algebraic multigrid (AMG) preconditioners for solving large, ill-conditioned linear systems in isogeometric analysis (IgA), focusing on performance in high-performance computing environments.", "motivation": "Isogeometric analysis produces large, sparse, and ill-conditioned linear systems due to higher interconnectivity among degrees of freedom, especially in 3D or high-order scenarios, requiring efficient solvers.", "method": "The study uses AMG preconditioners tailored for IgA discretizations, implemented with the Parallel Sparse Computation Toolkit (PSCToolkit) for distributed-memory and GPU-accelerated strategies.", "result": "AMG preconditioners achieve robust and scalable performance across benchmark tests, demonstrating their effectiveness for large IgA systems.", "conclusion": "AMG preconditioners are practical and scalable solvers for large-scale isogeometric analysis systems in engineering and scientific applications."}}
{"id": "2511.21657", "pdf": "https://arxiv.org/pdf/2511.21657", "abs": "https://arxiv.org/abs/2511.21657", "authors": ["Isa\u00edas Rodr\u00edguez", "Renela M. Valladares", "Alexander Valladares", "David Hinojosa-Romero", "Flor B. Quiroga", "Ariel A. Valladares"], "title": "Edge-Dependent Superconductivity in Twisted Bismuth Bilayers", "categories": ["cond-mat.supr-con", "cond-mat.dis-nn", "physics.comp-ph"], "comment": "16 pages, 9 figures", "summary": "Twisted bilayers offer a compelling and, at times, confounding platform for the engineering of new twistronic materials. Whereas standard studies almost exclusively focus on the explicit enigma that is presented by twist-angles, perhaps better epitomized by the related phenomena that have been observed in twisted bilayer graphene, functional devices necessarily face a fundamental concern: boundary heterogeneity in their structures. In this study, we address this concern by strictly investigating the electronic properties of twisted bismuth bilayers at the flake's edges and the vibrational properties of the flake. Twisted flakes exhibit continuous variations of these properties, away from the bulk, as we herein report using ab initio density functional theory, by systematically mapping the drastic evolution of band topology, electronic density of states, and possible superconductivity. Our work reveals a dramatic, non-fortuitous consequence of the structural disorder at the edges of the flakes: an enhanced electronic density of states at the Fermi level. This enhancement reaches a maximum of 10 times that of perfect-crystalline bismuth. Given that the superconducting critical temperature, Tc, is exponentially dependent on the electronic density of states at the Fermi level, this substantial structural variation immediately suggests a powerful mechanism for vastly increasing Tc. We also identify the twist-angle as a new critical parameter in designing novel engineering devices with topologically enhanced properties. Our results provide a necessary theoretical framework for interpreting new data for the upcoming generation of twistronic heterogeneous materials, and pave the way to search for atomic disordered metastable structures that could lead to enhanced superconducting transition temperatures.", "AI": {"tldr": "Twisted bismuth bilayers show enhanced electronic properties at flake edges due to structural disorder, leading to 10x increased electronic density of states at Fermi level and potential for significantly higher superconducting critical temperatures.", "motivation": "Address boundary heterogeneity concerns in twisted bilayer materials, which are crucial for functional devices but often overlooked in favor of twist-angle studies.", "method": "Used ab initio density functional theory to systematically map electronic properties (band topology, density of states, superconductivity) and vibrational properties at flake edges of twisted bismuth bilayers.", "result": "Found dramatic enhancement of electronic density of states at Fermi level (up to 10x perfect crystalline bismuth) due to structural disorder at flake edges, suggesting potential for vastly increased superconducting critical temperature.", "conclusion": "Twist-angle is a critical parameter for designing devices with topologically enhanced properties, and structural disorder at edges provides powerful mechanism for increasing Tc, paving way for search of atomic disordered metastable structures."}}
{"id": "2511.21349", "pdf": "https://arxiv.org/pdf/2511.21349", "abs": "https://arxiv.org/abs/2511.21349", "authors": ["Dario Corona", "Stefano Nardulli", "Ramon Oliver-Bonafoux", "Giandomenico Orlandi"], "title": "Multiplicity of solutions for Gross-Pitaevskii equations on Riemannian manifolds", "categories": ["math.AP", "math.DG"], "comment": null, "summary": "We provide a multiplicity result for solutions of time-independent Gross-Pitaevskii equations on closed Riemannian manifolds. Such solutions arise as (possibly non-minimizing) critical points of the Ginzburg-Landau energy having prescribed momentum according to a given tangent velocity field. Lower bounds on the multiplicity of solutions are obtained in terms of the topology of the maximum velocity set, in the small momentum and vorticity core size regime. The proof relies on methods from critical point theory and $\u0393$-convergence for Ginzburg-Landau functionals as well as on some new results for codimension 2 isoperimetric-type problems in the small flux regime, possibly of independent interest.", "AI": {"tldr": "Multiplicity results for Gross-Pitaevskii equation solutions on closed Riemannian manifolds, with lower bounds based on topology of velocity field.", "motivation": "Study critical points of Ginzburg-Landau energy with prescribed momentum according to tangent velocity fields, beyond just minimizing solutions.", "method": "Critical point theory, \u0393-convergence for Ginzburg-Landau functionals, and new results for codimension 2 isoperimetric problems in small flux regime.", "result": "Lower bounds on solution multiplicity obtained in terms of topology of maximum velocity set, valid for small momentum and vorticity core size.", "conclusion": "Topology of velocity field determines minimum number of solutions to Gross-Pitaevskii equations in small parameter regimes."}}
{"id": "2511.21302", "pdf": "https://arxiv.org/pdf/2511.21302", "abs": "https://arxiv.org/abs/2511.21302", "authors": ["Stefano Berrone", "Lorenzo Neva", "Moreno Pintore", "Gioana Teora", "Fabio Vicini"], "title": "The Zipped Finite Element Method: High-order Shape Functions for Polygons", "categories": ["math.NA"], "comment": null, "summary": "In this paper, we present a new polygonal finite element method, called the Zipped Finite Element Method, for star-shaped polygons. The proposed approach constructs high-order shape functions as linear combinations of standard finite element basis functions defined on a local trivial sub-triangulation of each element. This refinement is used solely for the construction of the shape functions and does not affect the final number of degrees of freedom. The resulting finite element space includes polynomials of the desired order and preserves conformity across elements. Consequently, the method inherits the convergence properties of the finite element framework under suitable mesh assumptions. Numerical experiments confirm the expected rates of convergence.", "AI": {"tldr": "The Zipped Finite Element Method creates high-order shape functions for star-shaped polygons by combining standard basis functions from local sub-triangulations, maintaining polynomial completeness and conformity without increasing degrees of freedom.", "motivation": "To develop a polygonal finite element method that can handle star-shaped polygons with high-order accuracy while preserving conformity and convergence properties.", "method": "Constructs high-order shape functions as linear combinations of standard finite element basis functions defined on local trivial sub-triangulations of each element, using refinement only for shape function construction.", "result": "The method produces a finite element space that includes polynomials of desired order, maintains conformity across elements, and inherits convergence properties from standard finite element framework.", "conclusion": "Numerical experiments confirm expected convergence rates, validating the Zipped Finite Element Method as an effective approach for high-order polygonal finite element analysis."}}
{"id": "2511.21372", "pdf": "https://arxiv.org/pdf/2511.21372", "abs": "https://arxiv.org/abs/2511.21372", "authors": ["Alessandro Cannone", "Silvia Cingolani", "Minbo Yang", "Shunneng Zhao"], "title": "Qualitative properties of single blow-up solutions for nonlinear Hartree equation with slightly subcritical exponent", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we study the qualitative properties of single blow-up solutions to the nonlocal equations with slightly subcritical exponents \\begin{equation*}\n  -\u0394u=(|x|^{-(n-2)}\\ast u^{p-\u03b5})u^{p-1-\u03b5}\\quad \\mbox{in}~~\u03a9,~~ u=0\\quad \\mbox{on}~~\\partial\u03a9,\n  \\end{equation*} where $\u03a9$ is a smooth bounded domain in $\\mathbb{R}^n$ for $n=3,4,5$, $\\ast$ denotes the standard convolution, $\u03b5>0$ is a small parameter and $p=\\frac{n+2}{n-2}$ is $\\mathcal{D}^{1,2}$ energy-critical exponent. By exploiting various local Pohozaev identities and blow-up analysis, we provide a number of estimates on the first $(n+2)$-eigenvalues and their corresponding eigenfunctions, and examine the qualitative behavior of the eigenpairs $(\u03bb_{i,\u03b5}, v_{i,\u03b5})$ to the linearied problem of the above nonlocal equations for $i=1,\\cdots,n+2$. As a corollary, we derive the Morse index of a single-bubble solution in a nondegenerate setting.", "AI": {"tldr": "Analysis of single blow-up solutions to nonlocal equations with slightly subcritical exponents in bounded domains, focusing on eigenvalue estimates and qualitative behavior of eigenpairs.", "motivation": "To understand the qualitative properties of blow-up solutions in nonlocal equations with critical exponents, particularly in dimensions 3, 4, and 5, and to derive the Morse index of single-bubble solutions.", "method": "Using local Pohozaev identities and blow-up analysis to estimate the first (n+2)-eigenvalues and their eigenfunctions, and examining the behavior of eigenpairs in the linearized problem.", "result": "Provided estimates on eigenvalues and eigenfunctions, and derived the Morse index of single-bubble solutions in nondegenerate settings.", "conclusion": "The study successfully characterizes the qualitative behavior of blow-up solutions and their linearized eigenpairs, with implications for understanding solution stability through Morse index analysis."}}
{"id": "2511.21393", "pdf": "https://arxiv.org/pdf/2511.21393", "abs": "https://arxiv.org/abs/2511.21393", "authors": ["Yusong Zhang", "Zeng-Qi Wang"], "title": "Lopsided HSS Iterative Method and Preconditioner for a class of Complex Symmetric Linear System", "categories": ["math.NA"], "comment": null, "summary": "In this study, we propose the lopsided HSS (LHSS) iteration method for solving a class of complex symmetric indefinite systems of linear equations. This method employs an alternating iterative scheme, where each iteration entails solving two systems of equations with symmetric real coefficient matrices. This design is intended to reduce the high computational costs associated with complex arithmetic. Theoretical analysis shows that the upper bound of the convergence rate depends only on the maximum and minimum eigenvalues of the real symmetric matrices, as well as the iteration parameters. When the eigenvalues satisfy certain conditions, the method guarantees convergence for any positive iteration parameter. Building on this insight, we developed the preconditioned lopsided HSS iteration method (PLHSS). Theoretical results demonstrate that PLHSS exhibits superior convergence properties compared to the original method. Additionally, we derived the optimal parameters for the new approaches and corresponding optimal convergence rate. Furthermore, we derive the PLHSS preconditioner on the basis of the iterative method. The eigenvalues of the preconditioned matrix are well-clustered, and the eigenvectors are orthogonal with a specific inner product. Numerical experiments demonstrate the efficiency of the preconditioned GMRES and COCG methods. LHSS iteration methods and the relevant preconditioners show mesh size independent and parameter-insensitive convergence behavior for the test numerical examples.", "AI": {"tldr": "Proposes LHSS iteration method for complex symmetric indefinite linear systems, reducing computational costs by using real symmetric matrices. Extends to PLHSS with better convergence and optimal parameters.", "motivation": "To reduce high computational costs associated with complex arithmetic in solving complex symmetric indefinite linear systems.", "method": "Uses alternating iterative scheme with two systems of real symmetric matrices. Develops PLHSS method with optimal parameters and preconditioner.", "result": "LHSS convergence depends on eigenvalues of real matrices. PLHSS shows superior convergence with well-clustered eigenvalues and orthogonal eigenvectors.", "conclusion": "LHSS and PLHSS methods are efficient with mesh size independent and parameter-insensitive convergence behavior, validated by numerical experiments."}}
{"id": "2511.21390", "pdf": "https://arxiv.org/pdf/2511.21390", "abs": "https://arxiv.org/abs/2511.21390", "authors": ["Francesco Balducci", "Sergio Segura de Le\u00f3n"], "title": "Stationary equation of the relativistic heat diffusion in transparent media having $L^1$--data", "categories": ["math.AP"], "comment": null, "summary": "Our objective is to prove existence of a solution to the Dirichlet problem for an equation arising in the theory of radiation hydrodynamics to deal with the radiating energy in transparent media. We study its stationary equation with $L^1$--datum in a bounded domain. This problem was addressed in [11] for regular data (data belonging to $L^N(\u03a9)$) and a bounded solution was obtained. In our framework, the proof of existence is far from trivial since the solution sought cannot be bounded. Consequently, the Anzellotti theory of pairings does not apply and we have to use new developments to introduce the meaning of solution. We also study the regularity of solutions when data belong to $L^p(\u03a9)$, with $1<p<N$. Our result is coherent with the regularity found in [11].", "AI": {"tldr": "Existence proof for Dirichlet problem in radiation hydrodynamics with L^1 data, extending previous bounded solution results to unbounded solutions using new mathematical developments.", "motivation": "To address the Dirichlet problem for radiation hydrodynamics equations with L^1 data, extending beyond previous work that only handled regular data (L^N data) and bounded solutions.", "method": "Develop new mathematical framework to handle unbounded solutions since Anzellotti theory doesn't apply; study regularity for data in L^p spaces with 1<p<N.", "result": "Proved existence of solution for L^1 data and studied regularity properties for L^p data, showing coherence with previous regularity findings.", "conclusion": "Successfully established existence theory for unbounded solutions to radiation hydrodynamics equations with L^1 data, requiring new mathematical developments beyond classical approaches."}}
{"id": "2511.21491", "pdf": "https://arxiv.org/pdf/2511.21491", "abs": "https://arxiv.org/abs/2511.21491", "authors": ["Yun Liu", "Chen Cui", "Shi Shu", "Zhen Wang"], "title": "Vertex-based Graph Neural Solver and its Application to Linear Elasticity Equations", "categories": ["math.NA"], "comment": null, "summary": "The numerical solution of linear elasticity equations on unstructured grids presents significant difficulties, especially in the presence of heterogeneous and anisotropic materials. To tackle these challenges, we introduce a novel vertex-based graph Fourier neural solver. This framework seamlessly integrates a block-Jacobi smoothing stage, known for rapidly attenuating certain high-frequency errors, with a learnable Fourier-domain module designed to correct errors across the remained frequency spectrum. Extensive numerical experiments on 2D and 3D problems verify that our proposed solver exhibits superior robustness and efficiency, significantly surpassing the classical smoothed aggregation algebraic multigrid method. Moreover, frequency domain analysis empirically confirms the essential complementarity between the smoother and the neural corrector.", "AI": {"tldr": "A vertex-based graph Fourier neural solver that combines block-Jacobi smoothing with learnable Fourier-domain correction for linear elasticity equations on unstructured grids.", "motivation": "Numerical solution of linear elasticity equations on unstructured grids is challenging with heterogeneous/anisotropic materials, requiring robust and efficient solvers.", "method": "Integrates block-Jacobi smoothing (for high-frequency errors) with learnable Fourier-domain module (for remaining frequency spectrum correction) in a vertex-based graph Fourier neural solver framework.", "result": "Extensive experiments show superior robustness and efficiency over classical smoothed aggregation algebraic multigrid method in 2D/3D problems.", "conclusion": "The solver effectively combines smoothing and neural correction, with frequency analysis confirming their complementary roles in error reduction."}}
{"id": "2511.21447", "pdf": "https://arxiv.org/pdf/2511.21447", "abs": "https://arxiv.org/abs/2511.21447", "authors": ["Seyyed Sadegh Kazemipoor", "Hadiseh Ebrahimi"], "title": "A Laplacian System With Sign-Changing Weight Function", "categories": ["math.AP"], "comment": "arXiv admin note: substantial text overlap with arXiv:1312.6998", "summary": "We prove the existence of at least one positive solution for the Laplacian system\\\\ -\u0394v=\u03bba(x)|v|^{q-2}v+\u03b2\\frac\u03b2{\u03b1+\u03b2}b(x)|u|^\u03b1|v|^{\u03b2-2}v&$for~$x\\in\u03a9$$ $$ \\end{array}\\right.$$ On a bounded region $\u03a9$ by using the Nehari manifold and the fibering maps associated with the Euler functional for the system.", "AI": {"tldr": "Existence of positive solution for Laplacian system using Nehari manifold and fibering maps", "motivation": "To prove the existence of at least one positive solution for a Laplacian system with nonlinear terms on a bounded region", "method": "Using the Nehari manifold and fibering maps associated with the Euler functional for the system", "result": "Proved the existence of at least one positive solution", "conclusion": "The Nehari manifold and fibering maps technique successfully establishes existence of positive solutions for the Laplacian system"}}
{"id": "2511.21597", "pdf": "https://arxiv.org/pdf/2511.21597", "abs": "https://arxiv.org/abs/2511.21597", "authors": ["Fabio Durastante", "Mariarosa Mazza"], "title": "Low-Rank Solvers for Energy-Conserving Hamiltonian Boundary Value Methods", "categories": ["math.NA"], "comment": null, "summary": "We study energy-conserving Hamiltonian Boundary Value Methods (HBVMs) for Hamiltonian systems, which arise in applications where long-term preservation of energy and symplecticity is essential. HBVMs are multi-stage schemes whose stage equations reformulate as matrix equations with a low-rank right-hand side. For linear systems, we exploit this structure directly via Krylov projection solvers. For nonlinear systems, we leverage it within simplified Newton iterations and as a preconditioner in a Newton--Krylov framework, combined with adaptive time-stepping for robust convergence. Numerical experiments on semi-discretized wave equations demonstrate the efficiency and robustness of the proposed approach.", "AI": {"tldr": "Energy-conserving Hamiltonian Boundary Value Methods (HBVMs) for Hamiltonian systems, using low-rank structure in linear systems via Krylov solvers and simplified Newton iterations for nonlinear systems with adaptive time-stepping.", "motivation": "To develop efficient numerical methods for Hamiltonian systems that preserve energy and symplecticity over long time periods, which is essential in applications requiring structural preservation.", "method": "HBVMs reformulate as matrix equations with low-rank right-hand side. For linear systems: Krylov projection solvers. For nonlinear systems: simplified Newton iterations and Newton-Krylov framework with preconditioning, combined with adaptive time-stepping.", "result": "Numerical experiments on semi-discretized wave equations demonstrate the efficiency and robustness of the proposed approach.", "conclusion": "The proposed HBVMs with specialized solvers and adaptive time-stepping provide an efficient and robust framework for preserving energy and symplecticity in Hamiltonian systems."}}
{"id": "2511.21467", "pdf": "https://arxiv.org/pdf/2511.21467", "abs": "https://arxiv.org/abs/2511.21467", "authors": ["Tomas Dohnal", "Maximilian Hanisch", "Runan He"], "title": "Polychromatic Localized Waves with Complex Frequencies in Nonlinear Maxwell Equations with Material Dispersion", "categories": ["math.AP", "math-ph", "nlin.PS"], "comment": "39 pages, 6 figures", "summary": "We study the existence of polychromatic solutions of cubically nonlinear Maxwell equations in the whole space and with dispersive media, i.e., with a time delayed polarization. Due to the complex nature of the dielectric function, the frequencies are complex, resulting in a decay in time. The geometry is that of a waveguide in $x$ with the propagation direction being $y$ and the solutions are localized in $x$ and TM-polarized. These are often referred to as breathers. They are given as a Fourier series in $y$ and $t$ with the leading frequency $\u03c9$ being an eigenvalue of a corresponding operator pencil on $\\mathbb{R}$ (in the $x$ variable). Each term in the series corresponds to a different temporal decay rate or a different frequency. The series is constructed iteratively via a sequence of linear ordinary differential equations. Our general result provides the existence under some assumptions on the spectrum and on estimates of the resolvent of the corresponding linear operator. We also produce an example of a waveguide given by the interface of two spatially homogeneous physically relevant media for which these assumptions are satisfied. For such an interface setting the constructed solutions correspond to nonlinear polychromatic surface plasmons.", "AI": {"tldr": "Existence of polychromatic breather solutions for cubically nonlinear Maxwell equations in dispersive media with complex frequencies causing temporal decay, constructed as Fourier series via iterative linear ODEs.", "motivation": "Study nonlinear electromagnetic wave propagation in dispersive media, particularly polychromatic solutions (breathers) that decay in time due to complex frequencies, with applications to surface plasmons at waveguide interfaces.", "method": "Construct solutions as Fourier series in propagation direction and time, with leading frequency as eigenvalue of operator pencil. Solve iteratively via sequence of linear ordinary differential equations, using resolvent estimates of corresponding linear operator.", "result": "Proved existence of polychromatic breather solutions under spectral assumptions and resolvent estimates. Provided concrete example of waveguide interface between two homogeneous media satisfying these conditions, yielding nonlinear polychromatic surface plasmons.", "conclusion": "Established rigorous existence theory for polychromatic nonlinear electromagnetic waves in dispersive media, with explicit construction method and application to physically relevant waveguide interfaces supporting surface plasmons."}}
{"id": "2511.21620", "pdf": "https://arxiv.org/pdf/2511.21620", "abs": "https://arxiv.org/abs/2511.21620", "authors": ["Jina Yang", "Ky Quan Tran"], "title": "Mean-square exponential stability of exact and numerical solutions for neutral stochastic delay differential equations with Markovian switching", "categories": ["math.NA", "math.PR"], "comment": "23 pages, 4 figures", "summary": "This paper investigates the mean-square exponential stability of neutral stochastic differential delay equations (NSDDEs) with Markovian switching. The analysis addresses the complexities arising from the interaction between the neutral term, time-varying delays, and structural changes governed by a continuous-time Markov chain. We establish novel and practical criteria for the mean-square exponential stability of both the underlying system and its numerical approximations via the Euler-Maruyama method. Furthermore, we prove that the numerical scheme can reproduce the exponential decay rate of the true solution with arbitrary accuracy, provided the step size is sufficiently small. The theoretical results are supported by a numerical example that illustrates their effectiveness.", "AI": {"tldr": "This paper establishes stability criteria for neutral stochastic differential delay equations with Markovian switching and proves that Euler-Maruyama numerical schemes can reproduce the exponential decay rate of the true solution.", "motivation": "To address the complex stability analysis of NSDDEs with Markovian switching, considering interactions between neutral terms, time-varying delays, and structural changes governed by Markov chains.", "method": "Developed novel stability criteria and analyzed numerical approximations using the Euler-Maruyama method, proving convergence properties for small step sizes.", "result": "Established practical criteria for mean-square exponential stability of both the system and its numerical approximations, with theoretical support from numerical examples.", "conclusion": "The Euler-Maruyama scheme can accurately reproduce the exponential decay rate of NSDDEs with Markovian switching when step sizes are sufficiently small, providing effective numerical stability analysis."}}
{"id": "2511.21469", "pdf": "https://arxiv.org/pdf/2511.21469", "abs": "https://arxiv.org/abs/2511.21469", "authors": ["Xinye Xiao", "Haomin Huang"], "title": "A Hamilton-Jacobi Framework in a Field-Road System with Unidirectional Advection under Wentzell-Type Boundary Condition", "categories": ["math.AP"], "comment": null, "summary": "This paper develops a comprehensive Hamilton-Jacobi framework to analyze asymptotic propagation dynamics in a field-road system featuring unidirectional advection and Wentzell-type boundary conditions. We rigorously derive a Hamilton-Jacobi variational inequality as the singular limit of a reaction-diffusion system in the upper half-plane, where the road is modeled as a degenerate one-dimensional medium with enhanced diffusion and tangential drift. By synthesizing viscosity solution theory, optimal control formulation, and variational analysis, we establish the existence, uniqueness, and explicit variational representation of the viscosity solution. The solution is characterized by a fundamental solution constructed via optimal paths, revealing a critical transition in propagation behavior governed by a geometrically derived curve that separates rectilinear and road-assisted regimes. Our framework extends to non-order-preserving systems where classical comparison methods fail, and we provide a detailed asymptotic derivation of the Wentzell boundary condition from flux continuity principles. Furthermore, we generalize the approach to conical domains with intersecting roads, demonstrating the robustness of our variational methodology. Numerical simulations illustrate how advection and diffusion parameters shape the invaded region, highlighting the interplay between field and road dynamics in determining propagation patterns.", "AI": {"tldr": "Develops Hamilton-Jacobi framework for analyzing propagation dynamics in field-road systems with unidirectional advection and Wentzell boundary conditions, revealing critical transitions between rectilinear and road-assisted propagation regimes.", "motivation": "To understand asymptotic propagation dynamics in complex field-road systems where traditional comparison methods fail, particularly for non-order-preserving systems with degenerate media and boundary interactions.", "method": "Uses Hamilton-Jacobi variational inequality as singular limit of reaction-diffusion system, synthesizing viscosity solution theory, optimal control formulation, and variational analysis to characterize propagation behavior.", "result": "Established existence, uniqueness and explicit variational representation of viscosity solution, revealing critical transition governed by geometrically derived curve separating different propagation regimes, with extensions to conical domains and numerical validation.", "conclusion": "The framework successfully captures complex propagation dynamics in field-road systems, providing robust variational methodology that extends beyond classical approaches and reveals fundamental insights into how advection and diffusion parameters shape invasion patterns."}}
{"id": "2511.20843", "pdf": "https://arxiv.org/pdf/2511.20843", "abs": "https://arxiv.org/abs/2511.20843", "authors": ["I. M. Ross", "M. Karpenko"], "title": "A Review of Pseudospectral Optimal Control: From Theory to Flight", "categories": ["math.OC", "cs.AI", "eess.SY", "math.FA", "math.NA"], "comment": "https://www.sciencedirect.com/science/article/abs/pii/S1367578812000375", "summary": "The home space for optimal control is a Sobolev space. The home space for pseudospectral theory is also a Sobolev space. It thus seems natural to combine pseudospectral theory with optimal control theory and construct ``pseudospectral optimal control theory,'' a term coined by Ross. In this paper, we review key theoretical results in pseudospectral optimal control that have proven to be critical for a successful flight. Implementation details of flight demonstrations onboard NASA spacecraft are discussed along with emerging trends and techniques in both theory and practice. The 2011 launch of pseudospectral optimal control in embedded platforms is changing the way in which we see solutions to challenging control problems in aerospace and autonomous systems.", "AI": {"tldr": "This paper reviews pseudospectral optimal control theory, combining pseudospectral methods with optimal control, and discusses its implementation in NASA flight demonstrations and embedded platforms.", "motivation": "Both optimal control and pseudospectral theory share Sobolev spaces as their mathematical foundation, making their combination natural for solving challenging control problems.", "method": "The paper combines pseudospectral theory with optimal control theory to construct pseudospectral optimal control theory, with implementation details for NASA spacecraft flight demonstrations.", "result": "Successful flight demonstrations onboard NASA spacecraft and the 2011 launch of pseudospectral optimal control in embedded platforms have changed approaches to solving aerospace and autonomous systems control problems.", "conclusion": "Pseudospectral optimal control represents an emerging trend that is transforming how challenging control problems are addressed in aerospace and autonomous systems through embedded platform implementations."}}
{"id": "2511.21482", "pdf": "https://arxiv.org/pdf/2511.21482", "abs": "https://arxiv.org/abs/2511.21482", "authors": ["Shalmali Bandyopadhyay", "Briceyda B. Delgado", "Nsoki Mavinga", "Maria Amarakristi Onydio"], "title": "Existence results for quasimonotone semilinear coupled elliptic systems via sub-supersolution method", "categories": ["math.AP"], "comment": null, "summary": "We establish the existence of weak solutions of coupled systems of elliptic partial differential equations with quasimonotone nonlinearities in the domain interior and on the boundary. When the nonlinearities satisfy some monotonicity conditions, we employ monotone iteration techniques to establish the existence of minimal and maximal weak solutions between an ordered pair of sub- and supersolution. In the absence of monotonicity, we prove an existence result when the nonlinearities satisfy certain growth conditions. In addition, we provide concrete examples that illustrate the applicability of our theoretical results.", "AI": {"tldr": "Existence of weak solutions for coupled elliptic PDE systems with quasimonotone nonlinearities, using monotone iteration for ordered solutions and growth conditions for non-monotone cases.", "motivation": "To establish existence results for coupled elliptic PDE systems with quasimonotone nonlinearities, addressing both monotone and non-monotone scenarios in domain interior and boundary.", "method": "Employ monotone iteration techniques for systems with monotonicity conditions to find minimal/maximal weak solutions between sub- and supersolutions; use growth conditions for non-monotone cases.", "result": "Proved existence of weak solutions for coupled elliptic systems: ordered solutions via monotone iteration when monotonicity holds, and general existence when growth conditions are satisfied.", "conclusion": "Established comprehensive existence theory for coupled elliptic PDE systems with quasimonotone nonlinearities, with concrete examples demonstrating practical applicability of the theoretical results."}}
{"id": "2511.21414", "pdf": "https://arxiv.org/pdf/2511.21414", "abs": "https://arxiv.org/abs/2511.21414", "authors": ["Zachary Morrow", "Michael Penwarden", "Brian Chen", "Aurya Javeed", "Akil Narayan", "John D. Jakeman"], "title": "SUPN: Shallow Universal Polynomial Networks", "categories": ["cs.LG", "math.NA"], "comment": "25 pages, supplementary material", "summary": "Deep neural networks (DNNs) and Kolmogorov-Arnold networks (KANs) are popular methods for function approximation due to their flexibility and expressivity. However, they typically require a large number of trainable parameters to produce a suitable approximation. Beyond making the resulting network less transparent, overparameterization creates a large optimization space, likely producing local minima in training that have quite different generalization errors. In this case, network initialization can have an outsize impact on the model's out-of-sample accuracy. For these reasons, we propose shallow universal polynomial networks (SUPNs). These networks replace all but the last hidden layer with a single layer of polynomials with learnable coefficients, leveraging the strengths of DNNs and polynomials to achieve sufficient expressivity with far fewer parameters. We prove that SUPNs converge at the same rate as the best polynomial approximation of the same degree, and we derive explicit formulas for quasi-optimal SUPN parameters. We complement theory with an extensive suite of numerical experiments involving SUPNs, DNNs, KANs, and polynomial projection in one, two, and ten dimensions, consisting of over 13,000 trained models. On the target functions we numerically studied, for a given number of trainable parameters, the approximation error and variability are often lower for SUPNs than for DNNs and KANs by an order of magnitude. In our examples, SUPNs even outperform polynomial projection on non-smooth functions.", "AI": {"tldr": "SUPNs (shallow universal polynomial networks) achieve better approximation with fewer parameters than DNNs and KANs by replacing hidden layers with a single polynomial layer, reducing optimization complexity and improving generalization.", "motivation": "DNNs and KANs require many parameters, leading to overparameterization, complex optimization landscapes with local minima, and sensitivity to initialization, which affects out-of-sample accuracy.", "method": "Replace all but the last hidden layer with a single layer of polynomials with learnable coefficients, combining DNN and polynomial strengths for expressivity with fewer parameters.", "result": "SUPNs converge at the same rate as best polynomial approximation, show lower approximation error and variability than DNNs/KANs by an order of magnitude, and outperform polynomial projection on non-smooth functions.", "conclusion": "SUPNs provide an effective alternative to DNNs and KANs, offering superior approximation performance with fewer parameters and reduced optimization complexity."}}
{"id": "2511.21489", "pdf": "https://arxiv.org/pdf/2511.21489", "abs": "https://arxiv.org/abs/2511.21489", "authors": ["Pierluigi Colli", "Elisabetta Rocca", "J\u00fcrgen Sprekels"], "title": "On the hyperbolic relaxation of the chemical potential in a phase field tumor growth model", "categories": ["math.AP"], "comment": "Key words: tumor growth models, singular potentials, hyperbolic relaxation, initial-boundary value problem, well-posedness, continuous dependence, regularity, asymptotic convergence", "summary": "In this paper, we study a phase field model for a tumor growth model of Cahn--Hilliard type in which the often assumed parabolic relaxation of the chemical potential is replaced by a hyperbolic one. We show that the resulting initial-boundary value problem is well posed and that its solutions depend continuously on two given functions: one appearing in the mass balance equation and one in the nutrient equation, representing, respectively, sources of drugs (e.g. chemotherapy) and antiangiogenic therapy. We also discuss regularity properties of the solutions. Moreover, in the case of a constant proliferation function, we rigorously analyze the asymptotic behavior as the coefficient of the inertial term tends to zero, establishing convergence to the corresponding viscous Cahn--Hilliard tumor growth model. Our results apply to a broad class of double-well potentials, including nonsmooth ones.", "AI": {"tldr": "Analysis of a hyperbolic phase field tumor growth model with inertial term, showing well-posedness, continuous dependence on therapy functions, and convergence to viscous Cahn-Hilliard model.", "motivation": "To study tumor growth models where the chemical potential relaxation is hyperbolic rather than parabolic, providing more realistic modeling of inertial effects in tumor dynamics.", "method": "Mathematical analysis of hyperbolic Cahn-Hilliard type tumor growth model, proving well-posedness, continuous dependence on therapy parameters, and asymptotic convergence analysis.", "result": "Established well-posedness of the initial-boundary value problem, continuous dependence on drug and antiangiogenic therapy functions, and convergence to viscous model as inertial coefficient vanishes.", "conclusion": "The hyperbolic tumor growth model is mathematically sound, applicable to broad potential classes, and converges to standard viscous model in the inertial limit."}}
{"id": "2511.21418", "pdf": "https://arxiv.org/pdf/2511.21418", "abs": "https://arxiv.org/abs/2511.21418", "authors": ["Michael Kapralov", "Cameron Musco", "Kshiteej Sheth"], "title": "Sublinear Time Low-Rank Approximation of Hankel Matrices", "categories": ["cs.DS", "math.NA"], "comment": "To appear in SODA 2026", "summary": "Hankel matrices are an important class of highly-structured matrices, arising across computational mathematics, engineering, and theoretical computer science. It is well-known that positive semidefinite (PSD) Hankel matrices are always approximately low-rank. In particular, a celebrated result of Beckermann and Townsend shows that, for any PSD Hankel matrix $H \\in \\mathbb{R}^{n \\times n}$ and any $\u03b5> 0$, letting $H_k$ be the best rank-$k$ approximation of $H$, $\\|H-H_k\\|_F \\leq \u03b5\\|H\\|_F$ for $k = O(\\log n \\log(1/\u03b5))$. As such, PSD Hankel matrices are natural targets for low-rank approximation algorithms. We give the first such algorithm that runs in \\emph{sublinear time}. In particular, we show how to compute, in $\\polylog(n, 1/\u03b5)$ time, a factored representation of a rank-$O(\\log n \\log(1/\u03b5))$ Hankel matrix $\\widehat{H}$ matching the error guarantee of Beckermann and Townsend up to constant factors. We further show that our algorithm is \\emph{robust} -- given input $H+E$ where $E \\in \\mathbb{R}^{n \\times n}$ is an arbitrary non-Hankel noise matrix, we obtain error $\\|H - \\widehat{H}\\|_F \\leq O(\\|E\\|_F) + \u03b5\\|H\\|_F$. Towards this algorithmic result, our first contribution is a \\emph{structure-preserving} existence result - we show that there exists a rank-$k$ \\emph{Hankel} approximation to $H$ matching the error bound of Beckermann and Townsend. Our result can be interpreted as a finite-dimensional analog of the widely applicable AAK theorem, which shows that the optimal low-rank approximation of an infinite Hankel operator is itself Hankel. Armed with our existence result, and leveraging the well-known Vandermonde structure of Hankel matrices, we achieve our sublinear time algorithm using a sampling-based approach that relies on universal ridge leverage score bounds for Vandermonde matrices.", "AI": {"tldr": "First sublinear-time algorithm for low-rank approximation of PSD Hankel matrices, achieving O(log n log(1/\u03b5)) rank approximation in polylog(n, 1/\u03b5) time with robustness to noise.", "motivation": "PSD Hankel matrices are known to be approximately low-rank (Beckermann-Townsend theorem), making them natural targets for efficient low-rank approximation algorithms, but no sublinear-time algorithms existed.", "method": "Structure-preserving existence proof for Hankel approximations, then sampling-based approach using universal ridge leverage score bounds for Vandermonde matrices to achieve sublinear time.", "result": "Algorithm computes rank-O(log n log(1/\u03b5)) Hankel approximation in polylog(n, 1/\u03b5) time, matching Beckermann-Townsend error bound up to constants, with robustness to non-Hankel noise.", "conclusion": "First sublinear-time algorithm for PSD Hankel matrix approximation, providing both theoretical existence guarantees and practical algorithmic implementation with noise robustness."}}
{"id": "2511.21498", "pdf": "https://arxiv.org/pdf/2511.21498", "abs": "https://arxiv.org/abs/2511.21498", "authors": ["Anna Mazzucato", "Anping Pan"], "title": "Variational Principle and Stochastic Lagrangian Formulation of Viscous Hydrodynamic Equations", "categories": ["math.AP"], "comment": "37 pages", "summary": "In this manuscript, we extend the Lagrangian formulation of \\cite{CI08} for Navier-Stokes Equation to a wider class of hydrodynamic models. Moreover, we prove that such Lagrangian formulation is naturally derived from a stochastic Hamilton-Pontryagin type variational principle. Generalized version of Kelvin circulation theorem in viscous fluids is discussed. We also derive self-contained local well-posedness results of some fluid equations based on Lagrangian-Eulerian formulation using fixed point argument.", "AI": {"tldr": "Extension of Lagrangian formulation for Navier-Stokes equations to broader hydrodynamic models, derivation from stochastic Hamilton-Pontryagin variational principle, generalized Kelvin circulation theorem, and local well-posedness results using Lagrangian-Eulerian formulation.", "motivation": "To generalize the Lagrangian formulation beyond Navier-Stokes equations to a wider class of hydrodynamic models and establish rigorous mathematical foundations.", "method": "Stochastic Hamilton-Pontryagin variational principle, Lagrangian-Eulerian formulation with fixed point arguments.", "result": "Extended Lagrangian formulation to broader hydrodynamic models, proved natural derivation from stochastic variational principle, generalized Kelvin circulation theorem for viscous fluids, and established local well-posedness results.", "conclusion": "The paper successfully extends Lagrangian formulations to general hydrodynamic models with rigorous mathematical derivations and establishes local existence results for fluid equations."}}
{"id": "2511.21564", "pdf": "https://arxiv.org/pdf/2511.21564", "abs": "https://arxiv.org/abs/2511.21564", "authors": ["Adrian Nachman", "Peter Perry", "Daniel Tataru"], "title": "Large data global well-posedness for the modified Novikov-Veselov system", "categories": ["math.AP"], "comment": "47 pages", "summary": "The modified Novikov-Veselov system (mNV) is a cubic third order dispersive evolution in two space dimensions. It is also completely integrable, belonging to the same hierarchy as the defocusing Davey-Stewartson II (DS II) system.\n  The mNV system is $L^2$ critical. Some time ago, Schottdorf proved that for small $L^2$ initial data, the mNV equation is globally well-posed. In this article, we consider instead the large data problem, using inverse scattering methods. Our main result asserts that the mNV system is globally well-posed for large $L^2$ data, with the solutions scattering as time goes to $\\pm \\infty$. One key ingredient in the proof, which is of independent interest, is a new nonlinear Gagliardo-Nirenberg inequality for the associated scattering transform.\n  As a byproduct of our main result, we are also able to prove a global well-posedness result for the closely related Novikov-Veselov problem at the critical $\\dot H^{-1} + L^1$ level, for a range of data which can heuristically be described as soliton-free. Here we use the associated Miura map to connect the mNV and the NV flows. In order to characterize the range of the Miura map, we prove another result of independent interest, namely a sharp, scale invariant form of the Agmon-Allegretto-Piepenbrink principle in the critical case of two space dimensions.", "AI": {"tldr": "The paper proves global well-posedness and scattering for the modified Novikov-Veselov system with large L\u00b2 data using inverse scattering methods, and establishes related results for the Novikov-Veselov problem.", "motivation": "Previous work by Schottdorf established global well-posedness for small L\u00b2 data, but the large data problem remained open. The mNV system is L\u00b2 critical and completely integrable, making it important to understand its behavior with large initial data.", "method": "Uses inverse scattering methods and proves a new nonlinear Gagliardo-Nirenberg inequality for the associated scattering transform. Also employs the Miura map to connect mNV and NV flows, and proves a sharp Agmon-Allegretto-Piepenbrink principle.", "result": "Main result: mNV system is globally well-posed for large L\u00b2 data with solutions scattering as time goes to \u00b1\u221e. Secondary result: global well-posedness for Novikov-Veselov problem at critical \u1e22\u207b\u00b9 + L\u00b9 level for soliton-free data.", "conclusion": "The mNV system exhibits global well-posedness and scattering behavior even for large initial data, and the connection between mNV and NV systems via the Miura map provides additional insights into their behavior."}}
{"id": "2511.21583", "pdf": "https://arxiv.org/pdf/2511.21583", "abs": "https://arxiv.org/abs/2511.21583", "authors": ["Dengjun Guo", "Xiaoyutao Luo"], "title": "Long time inviscid damping near Couette in Sobolev spaces", "categories": ["math.AP"], "comment": "8pages", "summary": "We give an elementary proof of long time inviscid damping for Sobolev perturbations near the Couette flow $(y,0)$ for the 2D Euler equations on $\\mathbb{T} \\times \\mathbb{R}$. For any $s>1$ and any initial vorticity perturbation of size $O(\u03b5)$ in $H^s$, we obtain velocity damping estimates up to a time scale $ t = O(\u03b5^{-\u03b4_s} )$, where $\u03b4_s=1/3$ when $s\\to 1+$ and $\u03b4_s=1/2$ for $s>2$.", "AI": {"tldr": "Elementary proof of long-time inviscid damping for Sobolev perturbations near Couette flow in 2D Euler equations, showing velocity damping up to time scales O(\u03b5^{-\u03b4_s}) with \u03b4_s depending on Sobolev regularity.", "motivation": "To establish rigorous mathematical understanding of inviscid damping phenomena in 2D Euler equations near Couette flow, providing explicit time scales for velocity decay without viscosity.", "method": "Elementary proof approach for analyzing Sobolev perturbations of Couette flow, using functional analysis and PDE techniques to derive damping estimates.", "result": "For initial vorticity perturbation of size O(\u03b5) in H^s, velocity damping occurs up to time t = O(\u03b5^{-\u03b4_s}), where \u03b4_s = 1/3 as s\u21921+ and \u03b4_s = 1/2 for s > 2.", "conclusion": "The paper provides explicit quantitative bounds on inviscid damping time scales for 2D Euler equations, with the time scale improving with higher Sobolev regularity of perturbations."}}
{"id": "2511.21588", "pdf": "https://arxiv.org/pdf/2511.21588", "abs": "https://arxiv.org/abs/2511.21588", "authors": ["Soufiane El Amine El Alami", "Abderazzak Mouiha", "Abdelatif Hafid", "Ahmed El Hilali Alaoui"], "title": "Machine Learning and Deep Learning in Computational Finance: A Systematic Review", "categories": ["math.AP"], "comment": null, "summary": "This systematic review examines how machine learning (ML) and deep learning (DL) have transformed forecasting, decision-making, and financial modelling, promoting innovation and efficiency in financial systems. Following PRISMA 2020 guidelines, we analyze 22 peer-reviewed and open-access articles (2024 to 2026) indexed in Scopus, applying ML and DL models across credit risk prediction, cryptocurrency, asset pricing, and macroeconomic policy modeling. The most used models include Random Forest, XG-Boost, Support Vector Machine, Long Short-Term Memory (LSTM), Bidirectional LSTM, Convolutional Neural Network (CNN), and hybrid or ensemble approaches combining statistical and AI methods. ML and DL techniques outperform traditional models by capturing nonlinear dependencies and enhancing predictive accuracy, while explainable AI methods (e.g., SHAP and feature importance analysis) improve transparency and interpretability. Emerging trends include cross-domain applications and the integration of responsible AI in finance. Despite notable progress, challenges remain in interpretability, generalizability, and data quality. Overall, this review provides a comprehensive overview of AI-driven computational finance and outlines future research directions.", "AI": {"tldr": "Systematic review of ML/DL applications in finance (2024-2026), showing AI models outperform traditional methods in forecasting, decision-making, and financial modeling across credit risk, cryptocurrency, asset pricing, and macroeconomic policy.", "motivation": "To examine how machine learning and deep learning have transformed financial systems by promoting innovation and efficiency in forecasting, decision-making, and financial modeling.", "method": "Systematic review following PRISMA 2020 guidelines, analyzing 22 peer-reviewed articles from Scopus (2024-2026) using ML/DL models including Random Forest, XG-Boost, SVM, LSTM, BiLSTM, CNN, and hybrid approaches.", "result": "ML and DL techniques outperform traditional models by capturing nonlinear dependencies and enhancing predictive accuracy. Explainable AI methods (SHAP, feature importance) improve transparency. Emerging trends include cross-domain applications and responsible AI integration.", "conclusion": "AI-driven computational finance shows significant progress but faces challenges in interpretability, generalizability, and data quality. The review provides comprehensive overview and outlines future research directions."}}
{"id": "2511.21616", "pdf": "https://arxiv.org/pdf/2511.21616", "abs": "https://arxiv.org/abs/2511.21616", "authors": ["Umberto Pappalettera", "Francesco Triggiano"], "title": "Dissipative solutions to Stochastic 3D Euler equations", "categories": ["math.AP", "math.PR"], "comment": "Working paper. All comments are welcome", "summary": "We construct probabilistically strong solutions to the three-dimensional Euler equations perturbed by additive noise that are $\\mathbb{P}$-almost surely continuous in time, H\u00f6lder in space, and satisfy the local energy inequality up to an arbitrarily large stopping time.", "AI": {"tldr": "Construction of probabilistically strong solutions to 3D Euler equations with additive noise, continuous in time and H\u00f6lder in space, satisfying local energy inequality up to large stopping times.", "motivation": "To develop probabilistically strong solutions for the 3D Euler equations with additive noise that maintain regularity properties and satisfy key physical constraints like the local energy inequality.", "method": "Constructing solutions to the three-dimensional Euler equations perturbed by additive noise, ensuring probabilistic strength and regularity properties.", "result": "Successfully constructed probabilistically strong solutions that are continuous in time, H\u00f6lder in space, and satisfy the local energy inequality up to arbitrarily large stopping times.", "conclusion": "The paper demonstrates the feasibility of constructing probabilistically strong solutions to the 3D Euler equations with additive noise that preserve important mathematical and physical properties over extended time intervals."}}
{"id": "2511.21632", "pdf": "https://arxiv.org/pdf/2511.21632", "abs": "https://arxiv.org/abs/2511.21632", "authors": ["Andr\u00e9 de Laire", "Olivier Goubet", "Mar\u00eda Eugenia Mart\u00ednez", "Claudio Mu\u00f1oz", "Felipe Poblete"], "title": "Dynamics of generalized abcd Boussinesq solitary waves under a slowly variable bottom", "categories": ["math.AP", "math-ph"], "comment": "81 pp., 2 figures", "summary": "The Boussinesq $abcd$ system is a 4-parameter set of equations posed in $\\mathbb R_t\\times\\mathbb R_x$, originally derived by Bona, Chen and Saut as first-order 2-wave approximations of the incompressible and irrotational, two-dimensional water wave equations in the shallow water wave regime, in the spirit of the original Boussinesq derivation. Among the various particular regimes, each determined by the values of the parameters $(a, b, c, d)$ appearing in the equations, the \\emph{generic} regime is characterized by the conditions $b, d > 0$ and $a, c < 0$. If additionally $b=d$, the $abcd$ system is Hamiltonian.\n  In this paper, we investigate the existence of generalized solitary waves and the corresponding collision problem in the physically relevant \\emph{variable bottom regime}, introduced by M.\\ Chen. More precisely, the bottom is represented by a smooth space-time dependent function $h=\\varepsilon h_0(\\varepsilon t,\\varepsilon x)$, where $\\varepsilon$ is a small parameter and $h_0$ is a fixed smooth profile. This formulation allows for a detailed description of weak long-range interactions and the evolution of the solitary wave without its destruction. We establish this result by constructing a new approximate solution that captures the interaction between the solitary wave and the slowly varying bottom.", "AI": {"tldr": "Analysis of generalized solitary waves in the Boussinesq abcd system with variable bottom topography, focusing on existence and collision problems in the physically relevant regime.", "motivation": "To investigate the existence of generalized solitary waves and their collision behavior in the Boussinesq abcd system with variable bottom topography, which represents more realistic physical scenarios compared to flat bottoms.", "method": "Constructed new approximate solutions that capture interactions between solitary waves and slowly varying bottom topography, represented by h=\u03b5h\u2080(\u03b5t,\u03b5x) where \u03b5 is a small parameter and h\u2080 is a fixed smooth profile.", "result": "Established existence of generalized solitary waves in the variable bottom regime, showing that weak long-range interactions can be described and solitary waves evolve without destruction when interacting with slowly varying bottoms.", "conclusion": "The study successfully demonstrates that generalized solitary waves persist in variable bottom regimes, with the constructed approximate solutions providing a framework to analyze wave-bottom interactions in physically relevant scenarios."}}
{"id": "2511.21645", "pdf": "https://arxiv.org/pdf/2511.21645", "abs": "https://arxiv.org/abs/2511.21645", "authors": ["R. Alonso", "B. Lods", "I. Tristani"], "title": "The hydrodynamic limit of viscoelastic granular gases", "categories": ["math.AP"], "comment": null, "summary": "We obtain the first rigorous derivation of an incompressible Navier-Stokes-Fourier system with self-consistent and time-dependent forcing terms from the inelastic hard-spheres Boltzmann equation associated to the relevant case of viscoelastic granular gases. The model's inelasticity is measured by the so-called restitution coefficient which, for viscoelastic particles, depends on the relative velocities of particles. Through a suitable self-similar change of variables, a balanced dynamic between energy inflow and outflow naturally emerges in the model which permits its analysis. In contrast, such balanced dynamic does not emerge naturally in the constant restitution case and has to be imposed in our previous contribution (Alonso, Lods, Tristani, M\u00e9moires SMF). The exact self-similar rescaling, which allows to capture nontrivial inelastic-hydrodynamic effects, presents itself explicitly in terms of the Knudsen number and the restitution coefficient. The consequence of such scaling is a non-autonomous rescaled Boltzmann equation whose solutions converge, in a specific weak sense, towards the aforementioned hydrodynamic limit. The incompressible Navier-Stokes-Fourier system obtained by this process appears to be new in this context. As a byproduct of the analysis, we determine the exact dissipation rate of the granular temperature known as \\emph{Haff's law}.", "AI": {"tldr": "First rigorous derivation of incompressible Navier-Stokes-Fourier system from inelastic hard-spheres Boltzmann equation for viscoelastic granular gases, capturing nontrivial hydrodynamic effects and determining Haff's law.", "motivation": "To establish a rigorous hydrodynamic limit from the Boltzmann equation for granular gases with velocity-dependent restitution coefficient (viscoelastic particles), where previous constant restitution models required artificial energy balance.", "method": "Used a self-similar change of variables that explicitly depends on Knudsen number and restitution coefficient, transforming the problem into a non-autonomous rescaled Boltzmann equation that converges weakly to the hydrodynamic limit.", "result": "Successfully derived an incompressible Navier-Stokes-Fourier system with self-consistent time-dependent forcing terms, which is new in this context. Also determined the exact dissipation rate of granular temperature (Haff's law).", "conclusion": "The self-similar rescaling naturally captures the energy balance dynamics in viscoelastic granular gases, enabling rigorous derivation of hydrodynamic equations that were previously inaccessible with constant restitution models."}}
{"id": "2511.21055", "pdf": "https://arxiv.org/pdf/2511.21055", "abs": "https://arxiv.org/abs/2511.21055", "authors": ["Spiro Karigiannis", "S\u00e9bastien Picard", "Caleb Suan"], "title": "Flows of conformally coclosed $G_2$-structures with dilaton", "categories": ["math.DG", "math.AP"], "comment": "35 pages, 2 tables", "summary": "We study flows of $G_2$-structures guided by the principle of dimensional reduction: natural geometric flows in $G_2$-geometry reduce to natural flows in complex geometry. Our main examples are the $G_2$-Laplacian coflow, which lifts the K\u00e4hler--Ricci flow, and a 7-dimensional lift of the anomaly flow on complex threefolds. The $G_2$-lift of the anomaly flow deforms conformally coclosed $G_2$-structures. We compare the $G_2$-anomaly flow to the $G_2$-Laplacian coflow, and investigate short-time existence and fixed points.", "AI": {"tldr": "This paper studies geometric flows in G2-geometry that reduce to known flows in complex geometry through dimensional reduction, focusing on the G2-Laplacian coflow (lifting K\u00e4hler-Ricci flow) and a G2-anomaly flow.", "motivation": "To establish connections between geometric flows in G2-geometry and complex geometry via dimensional reduction, showing how natural flows in higher dimensions reduce to known flows in lower dimensions.", "method": "Using dimensional reduction principle to study G2-geometric flows, particularly the G2-Laplacian coflow and a 7-dimensional lift of the anomaly flow on complex threefolds, analyzing their properties and relationships.", "result": "The G2-Laplacian coflow lifts the K\u00e4hler-Ricci flow, and the G2-anomaly flow deforms conformally coclosed G2-structures. The paper compares these flows and investigates their short-time existence and fixed points.", "conclusion": "Dimensional reduction provides a powerful framework connecting geometric flows in G2-geometry with established flows in complex geometry, revealing structural relationships between different geometric settings."}}
{"id": "2511.21492", "pdf": "https://arxiv.org/pdf/2511.21492", "abs": "https://arxiv.org/abs/2511.21492", "authors": ["Jixiang Fu", "Shing-Tung Yau", "Dekai Zhang"], "title": "The Critical LYZ equation in K\u00e4hler Geometry", "categories": ["math.DG", "math.AP", "math.CV"], "comment": null, "summary": "We establish the existence of smooth solutions for the LYZ equation at the critical phase $\u03b8=(n-2)\\frac\u03c0{2}$, thereby solving the critical case of a problem posed by Collins-Jacob-Yau\n  and Li concerning the solvability for phase $\u03b8\\leq (n-2)\\frac\u03c0{2}$. As applications, we solve the 3D Hessian equation $\u03c3_2 = 1$ and the 4D Hessian quotient equation $\u03c3_3 = \u03c3_1$ under weaker assumptions than previously required.", "AI": {"tldr": "Existence of smooth solutions for LYZ equation at critical phase \u03b8=(n-2)\u03c0/2, solving Collins-Jacob-Yau and Li's problem. Applications to 3D Hessian equation \u03c3\u2082=1 and 4D Hessian quotient equation \u03c3\u2083=\u03c3\u2081 under weaker assumptions.", "motivation": "Solve the critical case of Collins-Jacob-Yau and Li's problem on solvability for phase \u03b8\u2264(n-2)\u03c0/2 in the LYZ equation.", "method": "Establish existence of smooth solutions for LYZ equation at critical phase \u03b8=(n-2)\u03c0/2.", "result": "Proved existence of smooth solutions at critical phase. Applied to solve 3D Hessian equation \u03c3\u2082=1 and 4D Hessian quotient equation \u03c3\u2083=\u03c3\u2081 with weaker assumptions.", "conclusion": "Successfully solved the critical case of the posed problem and extended applications to Hessian equations with reduced requirements."}}
{"id": "2511.21646", "pdf": "https://arxiv.org/pdf/2511.21646", "abs": "https://arxiv.org/abs/2511.21646", "authors": ["Filippo de Feo", "Fausto Gozzi", "Andrzej \u015awi\u0119ch", "Lukas Wessels"], "title": "Stochastic Optimal Control of Interacting Particle Systems in Hilbert Spaces and Applications", "categories": ["math.PR", "econ.GN", "math.AP", "math.OC"], "comment": null, "summary": "Optimal control of interacting particles governed by stochastic evolution equations in Hilbert spaces is an open area of research. Such systems naturally arise in formulations where each particle is modeled by stochastic partial differential equations, path-dependent stochastic differential equations (such as stochastic delay differential equations or stochastic Volterra integral equations), or partially observed stochastic systems. The purpose of this manuscript is to build the foundations for a limiting theory as the number of particles tends to infinity. We prove the convergence of the value functions $u_n$ of finite particle systems to a function $\\mathcal{V}$, {which} is the unique {$L$}-viscosity solution of the corresponding mean-field Hamilton-Jacobi-Bellman equation {in the space of probability measures}, and we identify its lift with the value function $U$ of the so-called ``lifted'' limit optimal control problem. Under suitable additional assumptions, we show $C^{1,1}$-regularity of $U$, we prove that $\\mathcal{V}$ projects precisely onto the value functions $u_n$, and that optimal (resp. optimal feedback) controls of the particle system correspond to optimal (resp. optimal feedback) controls of the lifted control problem started at the corresponding initial condition. To the best of our knowledge, these are the first results of this kind for stochastic optimal control problems for interacting particle systems of stochastic evolution equations in Hilbert spaces. We apply the developed theory to problems arising in economics where the particles are modeled by stochastic delay differential equations and stochastic partial differential equations.", "AI": {"tldr": "This paper develops a limiting theory for optimal control of interacting particle systems governed by stochastic evolution equations in Hilbert spaces, proving convergence to mean-field Hamilton-Jacobi-Bellman equations and establishing connections between finite and infinite particle systems.", "motivation": "Optimal control of interacting particles governed by stochastic evolution equations in Hilbert spaces is an open research area, with applications in systems where particles are modeled by stochastic PDEs, delay differential equations, or partially observed stochastic systems.", "method": "The authors prove convergence of value functions for finite particle systems to the unique L-viscosity solution of mean-field Hamilton-Jacobi-Bellman equations in probability measure spaces, and establish connections between finite and lifted limit optimal control problems.", "result": "The paper shows C^{1,1}-regularity of the lifted value function, proves that optimal controls of particle systems correspond to optimal controls of the lifted problem, and applies the theory to economic problems with stochastic delay differential equations and stochastic PDEs.", "conclusion": "These are the first results of this kind for stochastic optimal control problems of interacting particle systems in Hilbert spaces, providing foundations for mean-field limit theory with applications in economics."}}
