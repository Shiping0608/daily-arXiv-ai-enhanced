{"id": "2512.04411", "pdf": "https://arxiv.org/pdf/2512.04411", "abs": "https://arxiv.org/abs/2512.04411", "authors": ["Eric T. Chung", "Hyea Hyun Kim", "Xiang Zhong"], "title": "Iterative Contact-resolving Hybrid Methods for Multiscale Contact Mechanics", "categories": ["math.NA"], "comment": null, "summary": "Modeling contact mechanics with high contrast coefficients presents significant mathematical and computational challenges, especially in achieving strongly symmetric stress approximations. Due to the inherent nonlinearity of contact problems, conventional methods that treat the entire domain as a monolithic system often lead to high global complexity. To address this, we develop an iterative contact-resolving hybrid method by localizing nonlinear contact constraints within a smaller subdomain, while the larger subdomain is governed by a linear system. Our system employs variational inequality theory, minimization principles, and penalty methods. More importantly, we propose four discretization types within the two-subdomain framework, ranging from applying standard/mixed FEM across the entire domain to combining standard/mixed multiscale methods in the larger subdomain with standard/mixed FEM in the smaller one. % The standard finite element method and standard constraint energy minimizing generalized multiscale finite element method are simple and easy to demonstrate. By employing a multiscale reduction technique, the method avoids excessive degrees of freedom inherent in conventional methods in the larger domain, while the mixed formulation enables direct stress computation, ensures local momentum conservation, and resists locking in nearly incompressible materials. Convergence analysis and the corresponding algorithms are provided for all cases. Extensive numerical experiments are presented to validate the effectiveness of the approaches."}
{"id": "2512.04592", "pdf": "https://arxiv.org/pdf/2512.04592", "abs": "https://arxiv.org/abs/2512.04592", "authors": ["Josep Plana-Riu", "Henrik Rosenberger", "Benjamin Sanderse", "F. Xavier Trias"], "title": "Stable self-adaptive timestepping for Reduced Order Models for incompressible flows", "categories": ["math.NA", "physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "This work introduces RedEigCD, the first self-adaptive timestepping technique specifically tailored for reduced-order models (ROMs) of the incompressible Navier-Stokes equations. Building upon linear stability concepts, the method adapts the timestep by directly bounding the stability function of the employed time integration scheme using exact spectral information of matrices related to the reduced operators. Unlike traditional error-based adaptive methods, RedEigCD relies on the eigenbounds of the convective and diffusive ROM operators, whose computation is feasible at reduced scale and fully preserves the online efficiency of the ROM. A central theoretical contribution of this work is the proof, based on the combined theorems of Bendixson and Rao, that, under linearized assumptions, the maximum stable timestep for projection-based ROMs is shown to be larger than or equal to that of their corresponding full-order models (FOMs). Numerical experiments for both periodic and non-homogeneous boundary conditions demonstrate that RedEigCD yields stable timestep increases up to a factor 40 compared to the FOM, without compromising accuracy. The methodology thus establishes a new link between linear stability theory and reduced-order modeling, offering a systematic path towards efficient, self-regulating ROM integration in incompressible flow simulations."}
{"id": "2512.04634", "pdf": "https://arxiv.org/pdf/2512.04634", "abs": "https://arxiv.org/abs/2512.04634", "authors": ["Raul Borsche", "Tobias Damm", "Axel Klar", "Yizhou Zhou"], "title": "Interface layers and coupling conditions for discrete kinetic models on networks: a spectral approac", "categories": ["math.NA"], "comment": null, "summary": "We consider kinetic and related macroscopic equations on networks. A class of linear kinetic BGK models is considered, where the limit equation for small Knudsen numbers is given by the wave equation. Coupling conditions for the macroscopic equations are obtained from the kinetic coupling conditions via an asymptotic analysis near the nodes of the network and the consideration of coupled solutions of kinetic half-space problems. Analytical results are obtained for a discrete velocity version of the coupled half-space problems. Moreover, an efficient spectral method is developed to solve the coupled discrete velocity half-space problems. In particular, this allows to determine the relevant coefficients in the coupling conditions for the macroscopic equations\n  from the underlying kinetic network problem. These coefficients correspond to the so-called extrapolation length for kinetic boundary value problems. Numerical results show the accuracy and fast convergence of the approach. Moreover, a comparison of the kinetic solution on the network with the macroscopic solution is presented."}
{"id": "2512.04729", "pdf": "https://arxiv.org/pdf/2512.04729", "abs": "https://arxiv.org/abs/2512.04729", "authors": ["Martin Burger", "Ole Løseth Elvetun", "Bjørn Fredrik Nielsen"], "title": "Weighted total variation regularization for inverse problems with significant null spaces", "categories": ["math.NA"], "comment": null, "summary": "We consider inverse problems with large null spaces, which arise in important applications such as in inverse ECG and EEG procedures. Standard regularization methods typically produce solutions in or near the orthogonal complement of the forward operator's null space. This often leads to inadequate results, where internal sources are mistakenly interpreted as being near the data acquisition sites -- e.g., near or at the body surface in connection with EEG and ECG recordings.\n  To mitigate this, we previously proposed weighting schemes for Tikhonov and sparsity regularization. Here, we extend this approach to total variation (TV) regularization, which is particularly suited for identifying spatially extended regions with approximately constant values. We introduce a weighted TV-regularization method, provide supporting analysis, and demonstrate its performance through numerical experiments. Unlike standard TV regularization, the weighted version successfully recovers the location and size of large, piecewise constant sources away from the boundary, though not their exact shape.\n  Additionally, we explore a hybrid weighted-sparsity and TV regularization approach, which better captures both small and large sources, albeit with somewhat more blurred reconstructions than the weighted TV method alone."}
{"id": "2512.04272", "pdf": "https://arxiv.org/pdf/2512.04272", "abs": "https://arxiv.org/abs/2512.04272", "authors": ["Seiji Zenitani"], "title": "A simple procedure for generating a Kappa distribution in PIC simulation", "categories": ["physics.plasm-ph", "astro-ph.IM"], "comment": "5 pages, 1 figure, 1 ancillary Jupyter notebook file", "summary": "For kinetic modeling of plasma processes in space, a rejection-sampling procedure for generating a Kappa distribution in particle-in-cell (PIC) simulation is proposed. A Pareto distribution is employed as an envelope distribution. The procedure only requires uniform variates, and its acceptance efficiency is $\\approx 0.73$--$0.8$."}
{"id": "2512.04205", "pdf": "https://arxiv.org/pdf/2512.04205", "abs": "https://arxiv.org/abs/2512.04205", "authors": ["Veljko Lipovac", "Omar Duran", "Eirik Keilegavlen", "Inga Berre"], "title": "Persistent-variable thermal compositional simulation of multiphase flow with phase separation in porous media", "categories": ["physics.comp-ph", "math-ph"], "comment": "submitted to Journal of Computational Physics; No. Figures 12; No. pages 17; source code available at https://doi.org/10.5281/zenodo.17335273 ;", "summary": "Thermal compositional multiphase flow in porous media with phase transitions involves complex nonlinear interactions among flow, transport, and phase equilibrium. This paper presents a persistent-variable formulation for thermal compositional flow using enthalpy to formulate the energy balance and the local equilibrium problem. Equilibrium conditions are derived from a thermodynamically consistent minimization problem using a persistent set of variables, allowing for seamless integration of equilibrium calculations into a fully coupled flow and transport model. This formulation does not require phase stability tests and provides a continuous and full mathematical description of the multiphysics system, suitable for challenging non-isothermal scenarios. To tackle the nonlinearities arising from phase transitions, we embed a local solver for the thermodynamic subproblem within a global Newton solver for the fully implicit system. The local solver exploits the locality of the subproblem for parallelization and leverages the modularity of the persistent-variable formulation for both isothermal and isenthalpic equilibrium conditions locally. We demonstrate the capability of our approach to simulate complex high-enthalpy systems, including narrow-boiling phenomena. The impact of the embedded local solver is analyzed through numerical experiments, demonstrating a reduction in global nonlinear iterations of up to 23 \\% with increased use of the local solver. The number of local iterations is controlled with a local solver tolerance and no significant impact on the global iteration number was observed for local residual tolerances as high as $1e-3$. The persistent-variable approach using enthalpy and the modularity of the embedded local solver advance the usage of equilibrium calculations in multiphase flow simulations and are suitable for high-enthalpy applications."}
{"id": "2512.04281", "pdf": "https://arxiv.org/pdf/2512.04281", "abs": "https://arxiv.org/abs/2512.04281", "authors": ["Antonio Giuseppe Grimaldi", "Stefania Russo"], "title": "Regularity for minimizers of degenerate, non-autonomous, orthotropic integral functionals", "categories": ["math.AP"], "comment": null, "summary": "We prove the higher differentiability of integer order of locally bounded minimizers of integral functionals of the form \\begin{equation*}\n  \\mathcal{F}(u,Ω):= \\,\\sum_{i=1}^{n} \\dfrac{1}{p_i}\\displaystyle \\int_Ω\\, a_i(x) \\lvert u_{x_i} \\rvert^{p_i} dx- \\int_Ωω(x)u(x) dx, \\end{equation*} where the exponents $ p_i \\geq 2 $ and the coefficients $ a_i(x) $ satisfy a suitable Sobolev regularity. The main novelty consists in dealing with non-autonomous, anisotropic functionals, which depend also on the solution."}
{"id": "2512.04737", "pdf": "https://arxiv.org/pdf/2512.04737", "abs": "https://arxiv.org/abs/2512.04737", "authors": ["Luigi Brugnano", "Gianmarco Gurioli", "Felice Iavernaro", "Mikk Vikerpuur"], "title": "Recent advances in the numerical solution of multi-order fractional differential equations", "categories": ["math.NA"], "comment": "35 pages, 8 figures, 4 tables", "summary": "The efficient numerical solution of fractional differential equations has been recently tackled through the definition of Fractional HBVMs (FHBVMs), a class of Runge-Kutta type methods. Corresponding Matlab (c) codes have been also made available on the internet, proving to be very competitive w.r.t. existing ones. However, so far, FHBVMs have been given for solving systems of fractional differential equations with the same order of fractional derivative, whereas the numerical solution of multi-order problems (i.e., problems in which different orders of fractional derivatives occur) has not been handled, yet. Due to their relevance in applications, in this paper we propose an extension of FHBVMs for addressing fractional multi-order problems, providing full details for such an approach. A corresponding Matlab (c) code, handling the case of two different fractional orders, is also made available, proving very effective for numerically solving these problems."}
{"id": "2512.04484", "pdf": "https://arxiv.org/pdf/2512.04484", "abs": "https://arxiv.org/abs/2512.04484", "authors": ["J. Corbett", "R. Samulyak", "F. J. Artola", "S. Jachmich", "M. Kong", "E. Nardon"], "title": "Numerical model for pellet rocket acceleration in PELOTON", "categories": ["physics.plasm-ph", "physics.comp-ph"], "comment": "17 pages, 11 figures", "summary": "A direct numerical simulation model for the rocket acceleration of pellets in thermonuclear fusion devices has been developed for PELOTON, a 3D Lagrangian particle pellet code [R. Samulyak et al, Nuclear Fusion 61 (4), 046007 (2021)], and validated using shattered pellet injection (SPI) experiments in JET. The pellet rocket acceleration is driven by grad-B drift of the ablation cloud that creates asymmetry and non-uniform heating of the cloud. The model accounts for non-uniform charging of the ablation cloud by hot plasma electrons as well as local plasma gradients. The increased pressure on the high-field-side compared to the low-field-side leads to pellet (fragment) rocket acceleration. Pure deuterium and deuterium-neon mixture models have been implemented. The background plasma states have been obtained by using a new plasma cooling model for PELOTON. The cooling model distributes the ablated material within the corresponding flux volumes and accounts for ionization and other energy losses, Ohmic heating by toroidal currents, and the energy exchange between ions and electrons. Plasma profiles predicted by PELOTON cooling model have been compared with JOREK and INDEX simulations. PELOTON simulations of rocket acceleration and the corresponding trajectories of deuterium fragments are consistent with experimentally measured trajectories in JET. We show that composite deuterium-neon pellets containing 0.5% of neon experienced smaller deviation of their trajectories compared to the pure deuterium case. We simulate various spatial configurations of pellet fragments and demonstrate the cloud overlap impact on rocket acceleration. Additionally, we demonstrate the effect of plasma state gradients on the rocket acceleration. Future work will focus on the rocket acceleration of SPI in projected ITER plasmas and the development of the corresponding scaling law for the rocket acceleration."}
{"id": "2512.04348", "pdf": "https://arxiv.org/pdf/2512.04348", "abs": "https://arxiv.org/abs/2512.04348", "authors": ["Jaime Mora-Paz", "Leszek Demkowicz", "Christina G. Taylor", "Jacob Grosek", "Stefan Henneking"], "title": "Bessel Functions and Analysis of Circular Waveguides", "categories": ["physics.comp-ph"], "comment": "29 pages, 8 figures", "summary": "The paper is devoted to the study of circularly coiled optical slab waveguides, which is also applicable to acoustical waveguides. We use a change of variables and the classical Frobenius method to compute Bessel functions of complex order and complex argument, and combine it with a perfectly matched layer technique to solve the relevant Bessel eigenvalue problem and deliver accurate loss factors for eigensolutions to the three-layer optical slab waveguide problem. The solutions provide a benchmark for verifying model implementations of this problem and allow for a numerical verification of the Glazman criterion that provides a foundation for the well-posedness and stability analysis of homogeneous circular waveguides with impedance boundary conditions."}
{"id": "2512.04403", "pdf": "https://arxiv.org/pdf/2512.04403", "abs": "https://arxiv.org/abs/2512.04403", "authors": ["Hongxu Chen", "Renjun Duan"], "title": "Diffusive limit of the Boltzmann equation around Rayleigh profile in the half space", "categories": ["math.AP"], "comment": "To appear in Bull. Inst. Math. Acad. Sin", "summary": "This paper concerns the diffusive limit of the time evolutionary Boltzmann equation in the half space $\\mathbb{T}^2\\times\\mathbb{R}^+$ for a small Knudsen number $\\varepsilon>0$. For boundary conditions in the normal direction, it involves diffuse reflection moving with a tangent velocity proportional to $\\varepsilon$ on the wall, whereas the far field is described by a global Maxwellian with zero bulk velocity. The incompressible Navier-Stokes equations, as the corresponding formal fluid dynamic limit, admit a specific time-dependent shearing solution known as the Rayleigh profile, which accounts for the effect of the tangentially moving boundary on the flow at rest in the far field. Using the Hilbert expansion method, for well-prepared initial data we construct the Boltzmann solution around the Rayleigh profile without initial singularity over any finite time interval."}
{"id": "2512.04812", "pdf": "https://arxiv.org/pdf/2512.04812", "abs": "https://arxiv.org/abs/2512.04812", "authors": ["Prince Kanhya", "Udit Raj"], "title": "Construction of the Nearest Nonnegative Hankel Matrix for a Prescribed Eigenpair", "categories": ["math.NA"], "comment": null, "summary": "We study the problem of determining whether a prescribed eigenpair $(λ,x)$\n  can be made an exact eigenpair of a nonnegative Hankel matrix through the smallest\n  possible structured perturbation. The task reduces to check the feasibility of a\n  set of linear constraints that encode both the Hankel structure and entrywise\n  nonnegativity. When the feasibility set is nonempty, we compute the minimum-norm\n  perturbation $ΔH$ such that $(H+ΔH)x=λx$. When no such perturbation\n  exists, we compute the nearest nonnegative Hankel matrix in a residual sense by\n  minimizing $\\|(H+ΔH)x-λx\\|_{2}$ subject to the imposed constraints.\n  Because closed-form formulas for the structured backward error are generally\n  unavailable, our method provides a fully numerical and optimization-based\n  framework for evaluating eigenpair sensitivity under nonnegativity-preserving\n  Hankel perturbations. Numerical examples illustrate both feasible and infeasible cases."}
{"id": "2512.04715", "pdf": "https://arxiv.org/pdf/2512.04715", "abs": "https://arxiv.org/abs/2512.04715", "authors": ["M. Murakami", "A. Arefiev", "M. A. Zosa"], "title": "Generation of ultrahigh field by micro-bubble implosion", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Breaking the 100-MeV barrier for proton acceleration will help elucidate fundamental physics and advance practical applications from inertial confinement fusion to tumour therapy. Herein we propose a novel concept of bubble implosions. A bubble implosion combines micro-bubbles and ultraintense laser pulses of 10^20-10^22W/cm^2 to generate ultrahigh fields and relativistic protons. The bubble wall protons undergo volumetric acceleration toward the centre due to the spherically symmetric Coulomb force and the innermost protons accumulate at the centre with a density comparable to the interior of a white dwarf. Then an unprecedentedly high electric field is formed, which produces an energetic proton flash. Three-dimensional particle simulations confirm the robustness of Coulomb-imploded bubbles, which behave as nano-pulsars with repeated implosions and explosions to emit protons. Current technologies should be sufficient to experimentally verify concept of bubble implosions."}
{"id": "2512.04447", "pdf": "https://arxiv.org/pdf/2512.04447", "abs": "https://arxiv.org/abs/2512.04447", "authors": ["Atsushi M. Ito"], "title": "GPU-Portable Real-Space Density Functional Theory Implementation on Unified-Memory Architectures", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "physics.plasm-ph"], "comment": null, "summary": "We present a GPU-portable implementation of a real-space density functional theory (DFT) code ``QUMASUN'' and benchmark it on the new Plasma Simulator featuring Intel Xeon 6980P CPUs, and AMD MI300A GPUs. Additional tests were performed on an NVIDIA GH200 GPU. In particular MI300A supports unified memory and GH200 supports coherent memory interconnect, simplifying GPU porting. A lightweight C++ lambda-based layer enables CPU, CUDA, and HIP execution without OpenMP/OpenACC preprocessor directives. For diamond (216 atoms) and tungsten (128 atoms) systems, MI300A and GH200 achieve 2.0-2.8 $\\times$ and 2.3-2.4 $\\times$ speedups over a 256-core Xeon node. The compute-bound kernels, which are fast Fourier transforms (FFT), dense matrix-matrix multiplications (GEMM) and eigenvalue solver, show substantial acceleration on both GPUs, indicating that the present GPU-portable approach can benefit a wide range of plasma-fusion simulation codes beyond DFT."}
{"id": "2512.04428", "pdf": "https://arxiv.org/pdf/2512.04428", "abs": "https://arxiv.org/abs/2512.04428", "authors": ["Nurdaulet N. Tobakhanov", "Berikbol T. Torebek"], "title": "A note on lifespan estimates for higher-order parabolic equations", "categories": ["math.AP"], "comment": "11 pages", "summary": "We investigate the lifespan of solutions to the higher-order semilinear parabolic equation $$u_t+(-Δ)^m u=|u|^p, \\quad x \\in \\mathbb{R}^n, t>0 $$ with initial data. We focus on the precise asymptotic behavior of the lifespan of nontrivial solutions. By combining the test function method and semigroup estimates, we derive both upper and lower bounds for the lifespan of solutions $$T_{\\varepsilon} \\simeq \\left\\{\\begin{array}{l}\\varepsilon^{-\\left(\\frac{1}{p-1}-\\frac{n}{2m}\\right)^{-1}}, \\,\\, 1<p<p_{\\text {Fuj}}, \\\\ \\exp\\left(\\varepsilon^{-(p-1)}\\right), \\,\\, p=p_{\\text {Fuj}},\\end{array}\\right.$$ where $p_{Fuj}=1+\\frac{2m}{n}$ is the critical exponent of Fujita. These estimates refine and extend the earlier results of Caristi-Mitidieri [J. Math. Anal. Appl., 279:2 (2003), 710-722] and Sun [Electron. J. Differential Equations, 17 (2010)], who obtained only upper bounds under slowly decaying initial data assumptions. In our setting, the above condition on the initial data is replaced by the assumption $L^1\\cap L^\\infty$, which sharpens the results of the aforementioned works."}
{"id": "2512.04824", "pdf": "https://arxiv.org/pdf/2512.04824", "abs": "https://arxiv.org/abs/2512.04824", "authors": ["Arthur Saunier", "Leo Agelas", "Ani Anciaux Sedrakian", "Ibtihel Ben Gharbia", "Xavier Claeys"], "title": "Hierarchical matrix approximability of inverse of convection dominated finite element matrices", "categories": ["math.NA", "math.AP"], "comment": "32 pages, 22 figures. Submited to the Journal of Computational Physics", "summary": "Several researchers have developed a rich toolbox of matrix compression techniques that exploit structure and redundancy in large matrices. Classical methods such as the block low-rank format and the Fast Multipole Method make it possible to manipulate very large systems by representing them in a reduced form. Among the most sophisticated tools in this area are hierarchical matrices (H-matrices), which exploit local properties of the underlying kernel or operator to approximate matrix blocks by low-rank factors, organized in a recursive hierarchy. H-matrices offer a flexible and scalable framework, yielding nearly linear complexity in both storage and computation. Hierarchical matrix techniques, originally developed for boundary integral equations, have recently been applied to matrices stemming from the discretization of advection-dominated problems. However, their effectiveness is limited by the loss of coercivity induced by convection phenomena, where traditional methods fail. Initial work by Le Borne addressed this by modifying the admissibility criterion for structured grids with constant convection, but challenges remain for more general grids and advection fields. In this work, we propose a novel partitioning strategy based on \"convection tubes\", clusters aligned with the convection vector field. This method does not require a structured grid or constant convection, overcoming the limitations of previous approaches. We present both theoretical analyses and numerical experiments, that demonstrate the efficiency and robustness of our method for convection-dominated PDEs on unstructured grids. The approach builds on a Péclet-robust Caccioppoli inequality, crucial for handling convection-dominated problems."}
{"id": "2512.04722", "pdf": "https://arxiv.org/pdf/2512.04722", "abs": "https://arxiv.org/abs/2512.04722", "authors": ["Masakatsu Murakami", "Daiki Nishi"], "title": "Optimization of laser illumination configuration for directly driven inertial confinement fusion", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Optimum laser configurations are presented to achieve high illumination uniformity with directly driven inertial confinement fusion targets. Assuming axisymmetric absorption pattern of individual laser beams, theoretical models are reviewed in terms of the number of laser beams, system imperfection, and laser beam patterns. Utilizing a self-organizing system of charged particles on a sphere, a simple numerical model is provided to give an optimal configuration for an arbitrary number of laser beams. As a result, such new configurations as M48 and M60 are found to show substantially higher illumination uniformity than any other existing direct drive systems. A new polar direct-drive scheme is proposed with the laser axes keeping off the target center, which can be applied to laser configurations designed for indirectly driven inertial fusion."}
{"id": "2512.04450", "pdf": "https://arxiv.org/pdf/2512.04450", "abs": "https://arxiv.org/abs/2512.04450", "authors": ["Christopher DeGrendele", "Nguyen Ly", "Francois Cadieux", "Michael Barad", "Dongwook Lee", "Jared Duensing"], "title": "On the Construction of High-Order and Exact Pressure Equilibrium Schemes for Arbitrary Equations of State", "categories": ["physics.comp-ph", "math.NA"], "comment": "29 pages, 13 figures", "summary": "Typical fully conservative discretizations of the Euler compressible single or multi-component fluid equations governed by a real-fluid equation of state exhibit spurious pressure oscillations due to the nonlinearity of the thermodynamic relation between pressure, density, and internal energy. A fully conservative, pressure-equilibrium preserving method and a high-order, fully conservative, approximate pressure-equilibrium preserving method are presented. Both methods are general and can handle an arbitrary equation of state and arbitrary number of species. Unlike existing approaches to discretize the multi-component Euler equations, we do not introduce non conservative updates, overspecified equations, or design for a specific equation of state. The proposed methods are demonstrated on inviscid smooth interface advection problems governed by three equations of state: ideal-gas, stiffened-gas, and van der Waals where we show orders of magnitude reductions in spurious pressure oscillations compared to existing schemes."}
{"id": "2512.04479", "pdf": "https://arxiv.org/pdf/2512.04479", "abs": "https://arxiv.org/abs/2512.04479", "authors": ["Arnav Gupta"], "title": "Irreversibility condition and stability of equilibria in the inverse-deformation approach to fracture", "categories": ["math.AP", "cond-mat.mtrl-sci", "math-ph"], "comment": null, "summary": "We derive the irreversibility condition in fracture for the inverse-deformation approach using the second law of thermodynamics. We consider the problem of brittle failure in an elastic bar previously solved in (Rosakis et al 2021). Despite the presence of a non-zero interfacial/surface energy, the third derivative of the inverse-deformation map is discontinuous at the crack faces. This is due to the presence of the inequality constraint ensuring the inverse strain is nonnegative and the orientation of matter is preserved. A change in the material location of a crack results in negative entropy production, violating the second law. Consequently, such changes are disallowed giving the irreversibility condition. The inequality constraint and the irreversibility condition limit the space of admissible variations. We prove necessary and sufficient conditions for local stability that incorporate these restrictions. Their numerical implementation shows that all broken equilibria found in (Rosakis et al 2021) are locally stable."}
{"id": "2512.04845", "pdf": "https://arxiv.org/pdf/2512.04845", "abs": "https://arxiv.org/abs/2512.04845", "authors": ["Rui Chen", "Viviana Giunzioni", "Adrien Merlini", "Francesco P. Andriulli"], "title": "A High-Order Discretization Scheme for Surface Integral Equations for Analyzing the Electroencephalography Forward Problem", "categories": ["math.NA", "math-ph", "physics.bio-ph"], "comment": "9 pages, 7 figures", "summary": "A Nystrom-based high-order (HO) discretization scheme for surface integral equations (SIEs) for analyzing the electroencephalography (EEG) forward problem is proposed in this work. We use HO surface elements and interpolation functions for the discretization of the interfaces of the head volume and the unknowns on the elements, respectively. The advantage of this work over existing isoparametric HO discretization schemes resides in the fact that the interpolation points are different from the mesh nodes, allowing for the flexible manipulation of the order of the basis functions without regenerating the mesh of the interfaces. Moreover, the interpolation points are chosen from the quadrature rules with the same number of points on the elements simplifying the numerical computation of the surface integrals for the far-interaction case. In this contribution, we extend the implementation of the HO discretization scheme to the double-layer and the adjoint double-layer formulations, as well as to the isolated-skull-approach for the double-layer formulation and to the indirect adjoint double-layer formulation, employed to improve the solution accuracy in case of high conductivity contrast models, which requires the development of different techniques for the singularity treatment. Numerical experiments are presented to demonstrate the accuracy, flexibility, and efficiency of the proposed scheme for the four SIEs for analyzing the EEG forward problem."}
{"id": "2512.04982", "pdf": "https://arxiv.org/pdf/2512.04982", "abs": "https://arxiv.org/abs/2512.04982", "authors": ["Mostafa Behtouei", "Carlos Salgado Lopez", "Giancarlo Gatti"], "title": "Operator Formalism for Laser-Plasma Wakefield Acceleration", "categories": ["physics.plasm-ph", "math-ph", "physics.acc-ph", "quant-ph"], "comment": null, "summary": "In this paper, we develop an operator-based framework for laser--plasma wakefield acceleration (LPWA) in capillary discharges, providing a compact and systematic description of the coupled dynamics of laser fields and plasma response. The formalism employs key operators: the transverse modal operator $\\hat{K}$, the nonlinear plasma operator $\\hat{N}[Ψ]$, the plasma oscillation operator $\\hatΩ_p^{\\,2}$, and the ponderomotive source operator $\\hatα$, which together describe mode coupling, plasma oscillations, and nonlinear feedback induced by the ponderomotive force. In the linear regime, the system is characterized by invariant subspaces associated with stable modal structures, while nonlinear interactions break these invariances, leading to mode mixing and complex dynamics. The approach establishes a direct connection between LPWA and Hilbert-space operator theory, including the invariant subspace, providing a formal mathematical interpretation of energy transfer and wakefield formation. Furthermore, the operator formalism integrates with neural operator methods, allowing efficient approximation of $\\hat{N}$ and $\\hatα$ for reduced-order modeling and predictive control. This hybrid physics--AI framework offers a robust foundation for modeling, analysis, and optimization of high-intensity laser--plasma interactions in next-generation accelerator experiments."}
{"id": "2512.04860", "pdf": "https://arxiv.org/pdf/2512.04860", "abs": "https://arxiv.org/abs/2512.04860", "authors": ["Xue Quan", "Huajie Chen"], "title": "Stochastic Density Functional Theory Through the Lens of Multilevel Monte Carlo Method", "categories": ["physics.comp-ph"], "comment": null, "summary": "The stochastic density functional theory (sDFT) has exhibited advantages over the standard Kohn-Sham DFT method and has become an attractive approach for large-scale electronic structure calculations. The sDFT method avoids the expensive matrix diagonalization by introducing a set of random orbitals and approximating the density matrix via Chebyshev expansion of a matrix-valued function. In this work, we study the sDFT with a plane-wave discretization, and discuss variance reduction algorithms in the framework of multilevel Monte Carlo (MLMC) methods. In particular, we show that the density matrix evaluation in sDFT can be decomposed into many levels by increasing the plane-wave cutoffs or the Chebyshev polynomial orders. This decomposition renders the computational cost independent of the discretization size or temperature. To demonstrate the efficiency of the algorithm, we provide rigorous analysis of the statistical errors and present numerical experiments on some material systems."}
{"id": "2512.04506", "pdf": "https://arxiv.org/pdf/2512.04506", "abs": "https://arxiv.org/abs/2512.04506", "authors": ["Ahmad Z. Fino", "Berikbol T. Torebek"], "title": "Parabolic problems whose Fujita critical exponent is not given by scaling", "categories": ["math.AP"], "comment": "22 pages", "summary": "This paper investigates the (fractional) heat equation with a nonlocal nonlinearity involving a Riesz potential: \\begin{equation*} u_{t}+(-Δ)^{\\fracβ{2}} u= I_α(|u|^{p}),\\qquad x\\in \\mathbb{R}^n,\\,\\,\\,t>0, \\end{equation*} where $α\\in(0,n)$, $β\\in(0,2]$, $n\\geq1$, $p>1.$ We introduce the Fujita-type critical exponent $p_{\\mathrm{Fuj}}(n,β,α)=1+(β+α)/(n-α)$, which characterizes the global behavior of solutions: global existence for small initial data when $p>p_{\\mathrm{Fuj}}(n,β,α),$ and finite-time blow-up when $p\\leq p_{\\mathrm{Fuj}}(n,β,α)$.\n  It is remarkable that the critical Fujita exponent is not determined by the usual scaling argument that yields $p_{sc}=1+(β+α)/n$, but instead arises in an unconventional manner, similar to the results of Cazenave et al. [Nonlinear Analysis, 68 (2008), 862-874] for the heat equation with a nonlocal nonlinearity of the form $\\int_0^t(t-s)^{-γ}|u(s)|^{p-1}u(s)ds,\\,0\\leq γ<1.$\n  The result on global existence for $p>p_{\\mathrm{Fuj}}(n,2,α),$ provides a positive answer to the hypothesis proposed by Mitidieri and Pohozaev in [Proc. Steklov Inst. Math., 248 (2005) 164-185]. We further establish global nonexistence results for the above heat equation, where the Riesz potential term $I_α(|u|^{p})$ is replaced by a more general convolution operator $(\\mathcal{K}\\ast |u|^p),\\,\\mathcal{K}\\in L^1_{loc}$, thereby extending the Mitidieri-Pohozaev's results established in the aforementioned work.\n  Proofs of the blow-up results are obtained using a nonlinear capacity method specifically adapted to the structure of the problem, while global existence is established via a fixed-point argument combined with the Hardy-Littlewood-Sobolev inequality."}
{"id": "2512.04894", "pdf": "https://arxiv.org/pdf/2512.04894", "abs": "https://arxiv.org/abs/2512.04894", "authors": ["Dimitri Breda", "Xunbi A. Ji", "Gábor Orosz", "Muhammad Tanveer"], "title": "Data-driven Methods for Delay Differential Equations", "categories": ["math.NA"], "comment": null, "summary": "Data-driven methodologies are nowadays ubiquitous. Their rapid development and spread have led to applications even beyond the traditional fields of science. As far as dynamical systems and differential equations are concerned, neural networks and sparse identification tools have emerged as powerful approaches to recover the governing equations from available temporal data series. In this chapter we first illustrate possible extensions of the sparse identification of nonlinear dynamics (SINDy) algorithm, originally developed for ordinary differential equations (ODEs), to delay differential equations (DDEs) with discrete, possibly multiple and unknown delays. Two methods are presented for SINDy, one directly tackles the underlying DDE and the other acts on the system of ODEs approximating the DDE through pseudospectral collocation. We also introduce another way of capturing the dynamics of DDEs using neural networks and trainable delays in continuous time, and present the training algorithms developed for these neural delay differential equations (NDDEs). The relevant MATLAB implementations for both the SINDy approach and for the NDDE approach are provided. These approaches are tested on several examples, including classical systems such as the delay logistic and the Mackey-Glass equation, and directly compared to each other on the delayed Rössler system. We provide insights on the connection between the approaches and future directions on developing data-driven methods for time delay systems."}
{"id": "2512.03169", "pdf": "https://arxiv.org/pdf/2512.03169", "abs": "https://arxiv.org/abs/2512.03169", "authors": ["Taiki Jikei", "Daniel Groselj", "Lorenzo Sironi"], "title": "Magnetic Field Amplification and Particle Acceleration in Weakly Magnetized Trans-relativistic Electron-ion Shocks", "categories": ["astro-ph.HE", "physics.plasm-ph"], "comment": "16 pages, 13 figures", "summary": "We investigate the physics of quasi-parallel trans-relativistic shocks propagating in weakly magnetized plasmas by means of long-duration two-dimensional particle-in-cell simulations. The structure of the shock precursor is shaped by a competition between the Bell instability and the Weibel instability. The Bell instability is dominant at relatively high magnetizations $(σ\\gtrsim10^{-3})$, whereas the Weibel instability prevails at lower magnetizations $(σ\\lesssim10^{-4})$. Bell-dominated shocks efficiently accelerate ions, converting a fraction $\\varepsilon_{\\mathrm{i}}\\sim0.2$ of the upstream flow energy into downstream nonthermal ion energy. The maximum energy of nonthermal ions exhibits a Bohm scaling in time, as $E_{\\max}\\propto t$. A much smaller fraction $\\varepsilon_{\\mathrm{e}}\\ll0.1$ of the upstream flow energy goes into downstream nonthermal electrons in the Bell-dominated regime. On the other hand, Weibel-dominated shocks efficiently generate both nonthermal ions and electrons with $\\varepsilon_{\\mathrm{i}}\\sim\\varepsilon_{\\mathrm{e}}\\sim0.1$, albeit with a slower scaling for the maximum energy, $E_{\\mathrm{max}}\\propto t^{1/2}$. Our results are applicable to a wide range of trans-relativistic shocks, including the termination shocks of extragalactic jets, the late stages of gamma-ray burst afterglows, and shocks in fast blue optical transients."}
{"id": "2512.04863", "pdf": "https://arxiv.org/pdf/2512.04863", "abs": "https://arxiv.org/abs/2512.04863", "authors": ["Mostafa Bamdad", "Mohammad Sadegh Eshaghi", "Cosmin Anitescu", "Navid Valizadeh", "Timon Rabczuk"], "title": "PENCO: A Physics-Energy-Numerical-Consistent Operator for 3D Phase Field Modeling", "categories": ["physics.comp-ph"], "comment": null, "summary": "Accurate and efficient solutions of spatio-temporal partial differential equations (PDEs), such as phase-field models, are fundamental for understanding interfacial dynamics and microstructural evolution in materials science and fluid mechanics. Neural Operators (NOs) have recently emerged as powerful data-driven alternatives to traditional solvers; however, existing architectures often accumulate temporal errors, struggle to generalize in long-horizon simulations, and require large training datasets. To overcome these limitations, we propose PENCO (Physics-Energy-Numerical-Consistent Operator), a hybrid operator-learning framework that integrates physical laws and numerical structure within a data-driven architecture. The formulation introduces an enhanced L^2 Gauss-Lobatto collocation residual around the temporal midpoint that robustly enforces the governing dynamics and significantly improves accuracy, a Fourier-space numerical consistency term that captures the balanced behavior of semi-implicit discretizations, and an energy-dissipation constraint that ensures thermodynamic consistency. Additional low-frequency spectral anchoring and teacher-consistency mechanisms further stabilize learning and suppress long-term error growth. This hybrid design enables PENCO to preserve governing physics while mitigating long-term error growth. Through extensive three-dimensional phase-field benchmarks covering phase ordering, crystallization, epitaxial growth, and complex pattern formation, PENCO demonstrates superior accuracy, stability, and data efficiency compared to state-of-the-art neural operators, including Multi-Head Neural Operator (MHNO) and Fourier Neural Operator (FNO-4D), while maintaining physically consistent evolution. The associated dataset and implementation are available at github.com/MBamdad/PENCO."}
{"id": "2512.04584", "pdf": "https://arxiv.org/pdf/2512.04584", "abs": "https://arxiv.org/abs/2512.04584", "authors": ["Zhijie Chen", "Zhen Song", "Wenming Zou"], "title": "Sharp stability on the second Robin eigenvalue with negative boundary parameters", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we prove a quantitative refinement of the isoperimetric type inequality for the second Robin eigenvalue with negative boundary parameters established by Freitas and Laugesen [Amer.J.Math.143 (2021), no.3, 969-994].Such new stability estimate is proved when the boundary parameter is not too far from 0.By constructing a suitable family of nearly spherical domains, we prove that the exponent for the Fraenkel asymmetry in this quantitative type inequality is sharp."}
{"id": "2512.04929", "pdf": "https://arxiv.org/pdf/2512.04929", "abs": "https://arxiv.org/abs/2512.04929", "authors": ["Sabrina Guastavino", "Gabriele Santin", "Francesco Marchetti", "Federico Benvenuto"], "title": "Weak convergence rates for spectral regularization via sampling inequalities", "categories": ["math.NA"], "comment": null, "summary": "Convergence rates in spectral regularization methods quantify the approximation error in inverse problems as a function of the noise level or the number of sampling points. Classical strong convergence rate results typically rely on source conditions, which are essential for estimating the truncation error. However, in the framework of kernel approximation, the truncation error in the case of Tikhonov regularization can be characterized entirely through sampling inequalities, without invoking source conditions. In this paper, we first generalize sampling inequalities to spectral regularization, and then, by exploiting the connection between inverse problems and kernel approximation, we derive weak convergence rate bounds for inverse problems, independently of source conditions. These weak convergence rates are established and analyzed when the forward operator is compact and uniformly bounded, or the kernel operator is of trace class."}
{"id": "2512.04447", "pdf": "https://arxiv.org/pdf/2512.04447", "abs": "https://arxiv.org/abs/2512.04447", "authors": ["Atsushi M. Ito"], "title": "GPU-Portable Real-Space Density Functional Theory Implementation on Unified-Memory Architectures", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "physics.plasm-ph"], "comment": null, "summary": "We present a GPU-portable implementation of a real-space density functional theory (DFT) code ``QUMASUN'' and benchmark it on the new Plasma Simulator featuring Intel Xeon 6980P CPUs, and AMD MI300A GPUs. Additional tests were performed on an NVIDIA GH200 GPU. In particular MI300A supports unified memory and GH200 supports coherent memory interconnect, simplifying GPU porting. A lightweight C++ lambda-based layer enables CPU, CUDA, and HIP execution without OpenMP/OpenACC preprocessor directives. For diamond (216 atoms) and tungsten (128 atoms) systems, MI300A and GH200 achieve 2.0-2.8 $\\times$ and 2.3-2.4 $\\times$ speedups over a 256-core Xeon node. The compute-bound kernels, which are fast Fourier transforms (FFT), dense matrix-matrix multiplications (GEMM) and eigenvalue solver, show substantial acceleration on both GPUs, indicating that the present GPU-portable approach can benefit a wide range of plasma-fusion simulation codes beyond DFT."}
{"id": "2512.04873", "pdf": "https://arxiv.org/pdf/2512.04873", "abs": "https://arxiv.org/abs/2512.04873", "authors": ["Christopher Ehrich", "Christian Bachmann", "Pavel Pereslavtsev", "Christian Reiter"], "title": "VNS Tokamak OpenMC-Serpent Validation for Medical Isotope Studies", "categories": ["physics.comp-ph", "cs.CE"], "comment": null, "summary": "The Volumetric Neutron Source (VNS) tokamak is a proposed fusion reactor for testing and qualification of reactor components for future use in a fusion power facility, and has potential use for radioisotope production. The VNS geometry is modeled in the Serpent and OpenMC neutronics codes. Analog neutron-photon coupled simulations are carried out to compare the model's vacuum vessel and blanket components across codes. In the vacuum vessel, neutron and photon flux maps are calculated, while in the blanket region, neutron and photon spectra, (n,T), and (n,2n) reaction rates are calculated and compared between models. The detector response comparisons found the following: neutron flux and (n,T) reactions achieved excellent agreement, the (n,2n) detector response had good agreement, and photon flux had regional discrepancies depending on Serpent tracking used. Hybrid tracking lead to a relative difference of about 20% in the outboard side blanket, where as employment of delta tracking resulted in less than 1% relative difference. On an HPC cluster, Serpent was found to have shorter computation time than OpenMC in neutron photon coupled simulations using both hybrid tracking and delta tracking, but longer in neutron only simulations. An exemplary radioisotope production case is presented for the demonstration of additional VNS capabilities."}
{"id": "2512.04640", "pdf": "https://arxiv.org/pdf/2512.04640", "abs": "https://arxiv.org/abs/2512.04640", "authors": ["Mattia Galeotti", "Eugenio Vecchi"], "title": "Critical concave-convex problems in Carnot group", "categories": ["math.AP"], "comment": "22 pages", "summary": "We consider a model Dirichlet problem with concave-convex and critical nonlinearity settled in Carnot groups. Our aim is to prove the existence of two positve solutions in the spirit of a famous result by Ambrosetti, Brezis and Cerami. To this aim we use a variational Perron method combined with proper estimates of a family of functions which are minimizers of the relevant Sobolev inequality. Due to the lack of boundary regularity, we also have to be careful while proving that the first solution found is a local minimizer in the proper topology."}
{"id": "2512.04983", "pdf": "https://arxiv.org/pdf/2512.04983", "abs": "https://arxiv.org/abs/2512.04983", "authors": ["Rudi Smith", "Steffen W. R. Werner"], "title": "A tangential low-rank ADI method for solving indefinite Lyapunov equations", "categories": ["math.NA", "math.OC"], "comment": "33 pages, 6 figures", "summary": "Continuous-time algebraic Lyapunov equations have become an essential tool in various applications. In the case of large-scale sparse coefficient matrices and indefinite constant terms, indefinite low-rank factorizations have successfully been used to allow methods like the alternating direction implicit (ADI) iteration to efficiently compute accurate approximations to the solution of the Lyapunov equation. However, classical block-type approaches quickly increase in computational costs when the rank of the constant term grows. In this paper, we propose a novel tangential reformulation of the ADI iteration that allows for the efficient construction of low-rank approximations to the solution of Lyapunov equations with indefinite right-hand sides even in the case of constant terms with higher ranks. We provide adaptive methods for the selection of the corresponding ADI parameters, namely shifts and tangential directions, which allow for the automatic application of the method to any relevant problem setting. The effectiveness of the developed algorithms is illustrated by several numerical examples."}
{"id": "2512.04788", "pdf": "https://arxiv.org/pdf/2512.04788", "abs": "https://arxiv.org/abs/2512.04788", "authors": ["Jiří Šišma", "Michal Nevrkla", "Filip Vitha", "Sebastian Lorenz", "Illia Zymak", "Alžběta Špádová", "Andrea Kollárová", "Matěj Jech", "Alexandr Jančárek", "Davorin Peceli", "Carlo M. Lazzarini", "Leonardo V. N. Goncalves", "Gabriele M. Grittani", "Sergei V. Bulanov", "Jaron E. Shrock", "Ela Rockafellow", "Ari J. Sloss", "Bo Miao", "Scott W. Hancock", "Howard M. Milchberg"], "title": "High-repetition-rate, all-reflective optical guiding and electron acceleration in helium using an off-axis axicon", "categories": ["physics.acc-ph", "physics.plasm-ph"], "comment": "13 pages, 7 figures", "summary": "We present recent results on high-power guiding and laser wakefield acceleration (LWFA) in the ELBA beamline at ELI Beamlines, using the L3-HAPLS laser system (13 J, 30 fs, 0.2 Hz). By employing self-waveguiding in a 20 cm plasma channel in helium, we achieved stable acceleration of electron beams to energies approaching 5 GeV. A novel all-reflective optical setup, including an off-axis reflective axicon, enabled efficient acceleration at 0.2 Hz and guiding at repetition rates up to 3.3 Hz. This compact single laser, single compressor implementation of plasma channels for electron acceleration stabilizes electron pointing and enhances energy gain without requiring modifications to the laser system, paving the way for broader adoption of the technology across user facilities."}
{"id": "2512.04997", "pdf": "https://arxiv.org/pdf/2512.04997", "abs": "https://arxiv.org/abs/2512.04997", "authors": ["Raphael Maggio-Aprile", "Maxime Rambosson", "Christophe Coreixas", "Jonas Latt"], "title": "LEDDS: Portable LBM-DEM simulations on GPUs", "categories": ["physics.comp-ph"], "comment": null, "summary": "Algorithmic formulations of GPU programs provide a high-level alternative to device-specific code by expressing computations as compositions of well-defined parallel primitives (e.g., map, sort, reduce), rather than through handcrafted GPU kernels. In this work, we demonstrate that this paradigm can be extended to complex and challenging problems in computational physics: the simulation of granular flows and fluid-particle interactions.\n  LEDDS, our open-source framework, performs fully coupled Lattice Boltzmann -- Discrete Element Method (LBM-DEM) simulations using only algorithmic primitives, and runs efficiently on single-GPU platforms. The entire workflow, including neighbor search, collision detection, and fluid-particle coupling, is expressed as a sequence of portable primitives. While the current implementation illustrates these principles primarily through algorithms from the C++ Standard Library, with selective use of Thrust primitives for performance, the underlying concept is compatible with any HPC environment offering a rich set of parallel algorithms and is therefore applicable across a wide range of modern GPU systems and future accelerators.\n  LEDDS is validated through benchmarks spanning both DEM and LBM-DEM configurations, including sphere and ellipsoid collisions, wall friction tests, single-particle settling, Jeffery's orbits, and particle-laden shear flows. Despite its high level of abstraction, LEDDS achieves performances comparable to those of hand-tuned CUDA solvers, while maintaining portability and code clarity. These results show that high-performance LBM-DEM coupling can be achieved without sacrificing generality or readability, establishing LEDDS as a blueprint for portable multiphysics frameworks based on algorithmic primitives."}
{"id": "2512.04670", "pdf": "https://arxiv.org/pdf/2512.04670", "abs": "https://arxiv.org/abs/2512.04670", "authors": ["Andreas Chatziafratis", "Spyridon Kamvissis"], "title": "Infinity of solutions to initial-boundary value problems for linear constant-coefficient evolution PDEs on semi-infinite intervals", "categories": ["math.AP", "math-ph", "math.CV"], "comment": null, "summary": "In this short communication, we announce an algorithmic procedure for constructing non-uniqueness counter-examples of classical solutions to initial-boundary-value problems for a wide class of linear evolution partial differential equations, of any order and with constant coefficients, formulated in a quarter-plane. Our approach relies on analysis of regularity and asymptotic properties, near the boundary of the spatio-temporal domain, of closed-form integral-representation formulae derived via complex-analytic techniques and rigorous implementation of the modern PDE technique known as Fokas unified transform method. In order to elucidate the novel idea and demonstrate the proposed technique in a self-contained fashion, we explicitly present its application to two concrete examples, namely the heat equation and the linear KdV equation with Dirichlet data. New uniqueness theorems for these two models are also presented herein."}
{"id": "2512.04133", "pdf": "https://arxiv.org/pdf/2512.04133", "abs": "https://arxiv.org/abs/2512.04133", "authors": ["Loïc Balazi", "Fabian Holzberger", "Stephan B. Lunowa", "Malte A. Peter", "Daniel Peterseim", "Barbara Wohlmuth"], "title": "Effective permeabilities for flow through anisotropic microscopic geometries", "categories": ["physics.flu-dyn", "math.NA"], "comment": null, "summary": "This work develops a computational and theoretical framework for determining effective permeabilities in anisotropic microscopic geometries containing dense, fibre-like obstacles, motivated by the need to model flow in coiled aneurysm domains accurately. Building on homogenisation theory and fully resolved simulations in Representative Elementary Volumes (REVs), we validate the permeability model introduced in [C. Boutin, Study of permeability by periodic and self-consistent homogenisation. Eur. J. Mech. A Solids, 19(4):603-632, 2000] and propose a systematic methodology for capturing the directional variations induced by fibre orientation. The resulting permeability tensors are incorporated into macroscopic flow simulations based on the Darcy equation, enabling direct comparison of anisotropic and isotropic permeability models across several benchmark configurations. Our findings show that anisotropy has a significant impact on local flow direction and magnitude, generating directional permeability contrasts which cannot be reproduced by classical isotropic approximations. By integrating coil-induced microstructural effects into continuum-scale hemodynamic models, the proposed approach enables more realistic assessment of post-treatment aneurysm flow behaviour. Beyond this clinical application, the framework is broadly applicable to other biomedical and engineering systems involving fibrous or filamentous porous microstructures."}
{"id": "2512.04866", "pdf": "https://arxiv.org/pdf/2512.04866", "abs": "https://arxiv.org/abs/2512.04866", "authors": ["Jiasheng Liu", "Vladimir Rosenhaus", "Gregory Falkovich"], "title": "Degrees of universality in wave turbulence", "categories": ["cond-mat.stat-mech", "hep-th", "nlin.CD", "physics.flu-dyn", "physics.plasm-ph"], "comment": "28 pages", "summary": "Turbulence of weakly interacting waves displays a great deal of universality: independence of the details of the interaction and of the pumping and dissipation scales. Here we study how inverse turbulent cascades (from small to large scales) transition from weak to strong. We find that while one-loop corrections can be dependent on excitation and dissipation scales, new types of universality appear in strong turbulence. We contrast turbulence of spin waves in ferromagnets with turbulent cascades in the Nonlinear Schrödinger Equation (NSE) and in an MMT-like model in higher dimensions having a multiplicative interaction vertex: vertex renormalization gives rise to dependence on the pumping (UV scale) in the former but not in the latter. As a result of this spectral nonlocality, spin-wave turbulence stops being weak if one is sufficiently far from the pumping scale, even when the interaction of waves with comparable wavenumbers is weak. We paraphrase this as: nonlocality enhances nonlinearity.\n  We then describe strong turbulence in a multi-component version of these models with a large number of components. We argue that strong spin-wave turbulence is similar to turbulence of the focusing NSE, as it realizes a critical-balance state. However, UV nonlocality causes the level of spin-wave turbulence at large scales to decrease with increasing pumping level, culminating in a state that is independent of the level of pumping."}
{"id": "2512.05020", "pdf": "https://arxiv.org/pdf/2512.05020", "abs": "https://arxiv.org/abs/2512.05020", "authors": ["Anmol Sharma", "Ranjeet Kumar Brajpuriya", "Vivek K. Malik", "Vishakha Kaushik", "Sachin Pathak"], "title": "Engineered Inclined Energy Landscapes Enabling Free Flow of Magnetic Microstructures for Artificial Neuron Applications", "categories": ["physics.comp-ph"], "comment": null, "summary": "Spintronic-based brain-inspired neuromorphic computing has recently attracted significant attention due to the exceptional properties of magnetic microstructures, including nanoscale dimensions, high stability, and low energy consumption. Despite these advantages, the practical integration of such microstructures into functional devices remains challenging. Fabrication processes are often complex and prone to stochastic effects, such as unwanted pinning and thermal-induced instabilities, which limit device reliability and scalability. Addressing these challenges is crucial for advancing spintronic neuromorphic architectures toward real-world applications. Thus, to reduce these effects we have proposed a design which is experimentally feasible and require less energy as compared to existing one. By engineering the system anisotropy into a sawtooth-type energy landscape, we have achieved free flow of these microstructures and successfully emulated integrate and fire (IF) function of biological neuron. Thus, proposed design presents an experimentally reliable and energy efficient external stimuli approach for tailoring magnetic microstructures dynamic behaviours, resulting in low energy consumption of 23.66 fJ per spike paving the way for the development of skyrmion-based futuristic neuromorphic computing device applications."}
{"id": "2512.04713", "pdf": "https://arxiv.org/pdf/2512.04713", "abs": "https://arxiv.org/abs/2512.04713", "authors": ["Manh Hong Duong", "Boris Golubkov", "Zihui He"], "title": "On a fuzzy Landau Equation: Part III. The grazing collision limit", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we study the grazing limit from the non-cutoff fuzzy Boltzmann equations to the fuzzy Landau equation, where particles interact through delocalised collisions. We show the grazing limit through variational formulations that correspond to the GENERIC (General Equations for Non-Equilibrium Reversible-Irreversible Coupling) structure of the respective equations. We show that the variational formulation associated with a non-quadratic dual dissipation pair for the fuzzy Boltzmann equations converges to a variational formulation of the fuzzy Landau equation corresponding to a quadratic dissipation pair."}
{"id": "2512.04450", "pdf": "https://arxiv.org/pdf/2512.04450", "abs": "https://arxiv.org/abs/2512.04450", "authors": ["Christopher DeGrendele", "Nguyen Ly", "Francois Cadieux", "Michael Barad", "Dongwook Lee", "Jared Duensing"], "title": "On the Construction of High-Order and Exact Pressure Equilibrium Schemes for Arbitrary Equations of State", "categories": ["physics.comp-ph", "math.NA"], "comment": "29 pages, 13 figures", "summary": "Typical fully conservative discretizations of the Euler compressible single or multi-component fluid equations governed by a real-fluid equation of state exhibit spurious pressure oscillations due to the nonlinearity of the thermodynamic relation between pressure, density, and internal energy. A fully conservative, pressure-equilibrium preserving method and a high-order, fully conservative, approximate pressure-equilibrium preserving method are presented. Both methods are general and can handle an arbitrary equation of state and arbitrary number of species. Unlike existing approaches to discretize the multi-component Euler equations, we do not introduce non conservative updates, overspecified equations, or design for a specific equation of state. The proposed methods are demonstrated on inviscid smooth interface advection problems governed by three equations of state: ideal-gas, stiffened-gas, and van der Waals where we show orders of magnitude reductions in spurious pressure oscillations compared to existing schemes."}
{"id": "2512.04134", "pdf": "https://arxiv.org/pdf/2512.04134", "abs": "https://arxiv.org/abs/2512.04134", "authors": ["Ouendadji Salima", "Aissani Ali", "El Haj Hassan Fouad", "Benahmedi Lakhdar"], "title": "Double Perovskites K2NbTaO6 and Rb2NbTaO6 from First-Principles: Towards Efficient Materials for Green Energy", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "10 pages, 5 figures, Accepted manuscript, submitted to Computational Condensed Matter", "summary": "The structural flexibility and multifunctional nature of double perovskite oxides make them attractive for applications requiring coupled optical, mechanical, and thermal performance. Using first-principles computations, this study examines the structural, electronic, elastic, optical, and thermoelectric stability of K2NbTaO6 and Rb2NbTaO6. The two compounds combine to form a cubic double perovskite structure with ordered Nb$^{5+}$ and Ta$^{5+}$ cations. The calculated elastic constants satisfy the Born stability criteria, confirming mechanical stability; however, both K2NbTaO6 and Rb2NbTaO6 exhibit brittle behavior according to Pugh's ratio, reflecting limited ductility. Semiconducting behavior is revealed by band structure analysis with energy gaps of 2.79 eV for K2NbTaO6 and 2.63 eV for Rb2NbTaO6. Optical spectra show noticeable absorption in the high-energy region near the UV, indicating relevance for theoretical studies of optoelectronic and photocatalytic processes, without implying practical device efficiency. Therm"}
{"id": "2512.04721", "pdf": "https://arxiv.org/pdf/2512.04721", "abs": "https://arxiv.org/abs/2512.04721", "authors": ["Felipe W. Chaves-Silva", "Diego A. Souza", "Marcos G. Ferreira-Silva"], "title": "Optimal cost for the null controllability of the Stokes system with controls having $n-1$ components and applications", "categories": ["math.AP", "math.OC"], "comment": "25 pages. Comments are welcome", "summary": "In this work, we investigate the optimal cost of null controllability for the $n$-dimensional Stokes system when the control acts on $n-1$ scalar components. We establish a novel spectral estimate for low frequencies of the Stokes operator, involving solely $n-1$ components, and use it to show that the cost of controllability with controls having $n-1$ components remains of the same order in time as in the case of controls with $n$ components, namely $O(e^{C/T})$, i.e. the cost of null controllability is not affected by the absence of one component of the control. We also give several applications of our results."}
{"id": "2512.04574", "pdf": "https://arxiv.org/pdf/2512.04574", "abs": "https://arxiv.org/abs/2512.04574", "authors": ["Gonzalo Rubio", "Gerasimos Ntoukas", "Miguel Chávez-Módena", "Oscar Mariño", "Bernat Font", "Oriol Lehmkuhl", "Eusebio Valero", "Esteban Ferrer"], "title": "Can Explicit Subgrid Models Enhance Implicit LES Simulations? A GPU-Oriented High-Order-Solver Perspective", "categories": ["physics.flu-dyn", "math.NA"], "comment": null, "summary": "High-order Discontinuous Galerkin (DG) methods offer excellent accuracy for turbulent flow simulations, especially when implemented on GPU-oriented architectures that favor very high polynomial orders. On modern GPUs, high-order polynomial evaluations cost roughly the same as low-order ones, provided the DG degrees of freedom fit within device memory. However, even with high-order discretizations, simulations at high Reynolds numbers still require some level of under-resolution, leaving them sensitive to numerical dissipation and aliasing effects. Here, we investigate the interplay between intrinsic DG dissipation mechanisms (implicit dissipation) -- in particular split forms and Riemann solvers -- and explicit subgrid-scale models in Large Eddy Simulations (LES). Using the three-dimensional Taylor--Green vortex at $Re = 1600$ and an inviscid case ($Re \\to \\infty$), we evaluate kinetic energy dissipation, spectral accuracy, and numerical stability.\n  Our results show that when stability for under-resolved turbulence is ensured through split-forms (energy- or entropy-stable) schemes, subgrid-scale (SGS) LES models are not strictly necessary. At moderate Reynolds numbers, when the spatial resolution is sufficient to capture the relevant turbulence scales (i.e., in well-resolved LES), adding SGS models does not improve accuracy because the wavenumber range where they act overlaps with the inherent numerical dissipation of the DG scheme. In contrast, when the resolution is insufficient, as is typical at high Reynolds numbers, explicit subgrid-scale models complement the numerical dissipation and enhance accuracy by removing the excess energy that numerical fluxes alone cannot dissipate.\n  These findings provide practical guidance for choosing numerical strategies in high-order turbulence simulations."}
{"id": "2512.04452", "pdf": "https://arxiv.org/pdf/2512.04452", "abs": "https://arxiv.org/abs/2512.04452", "authors": ["Xin Kai Lee", "Ali Ramadhan", "Andre Souza", "Gregory LeClaire Wagner", "Simone Silvestri", "John Marshall", "Raffaele Ferrari"], "title": "NORi: An ML-Augmented Ocean Boundary Layer Parameterization", "categories": ["physics.ao-ph", "cs.AI", "cs.LG", "physics.comp-ph", "physics.flu-dyn"], "comment": "48 pages, 16 figures, submitted to Journal of Advances in Modeling Earth Systems (JAMES)", "summary": "NORi is a machine-learned (ML) parameterization of ocean boundary layer turbulence that is physics-based and augmented with neural networks. NORi stands for neural ordinary differential equations (NODEs) Richardson number (Ri) closure. The physical parameterization is controlled by a Richardson number-dependent diffusivity and viscosity. The NODEs are trained to capture the entrainment through the base of the boundary layer, which cannot be represented with a local diffusive closure. The parameterization is trained using large-eddy simulations in an \"a posteriori\" fashion, where parameters are calibrated with a loss function that explicitly depends on the actual time-integrated variables of interest rather than the instantaneous subgrid fluxes, which are inherently noisy. NORi is designed for the realistic nonlinear equation of state of seawater and demonstrates excellent prediction and generalization capabilities in capturing entrainment dynamics under different convective strengths, oceanic background stratifications, rotation strengths, and surface wind forcings. NORi is numerically stable for at least 100 years of integration time in large-scale simulations, despite only being trained on 2-day horizons, and can be run with time steps as long as one hour. The highly expressive neural networks, combined with a physically-rigorous base closure, prove to be a robust paradigm for designing parameterizations for climate models where data requirements are drastically reduced, inference performance can be directly targeted and optimized, and numerical stability is implicitly encouraged during training."}
{"id": "2512.04777", "pdf": "https://arxiv.org/pdf/2512.04777", "abs": "https://arxiv.org/abs/2512.04777", "authors": ["Shlapunov Alexander", "Polkovnikov Alexander"], "title": "Generalized Navier-Stokes equations, associated with the Dolbeault complex", "categories": ["math.AP", "math.FA"], "comment": "12 pages", "summary": "We consider the Cauchy problem in the band $\\mathbb{C}^{n}\\times[0, T], n>1,T>0$, for a system of nonlinear differential equations structurally similar to the classical Navier-Stokes equations for an incompressible fluid. The main difference of this system is that it is generated not by the standard gradient operators $\\nabla$, divergence div and rotor rot, but by the multidimensional Cauchy-Riemann operator $\\overline{\\partial}$ in $\\mathbb{C}^{n}$, its formally adjoint operator $\\overline{\\partial}^{*}$ and the compatibility complex for $\\overline{\\partial}$, which is usually called the Dolbeault complex. The similarity of the structure makes it possible to prove for this problem the theorem of the existence of weak solutions and the open mapping theorem on the scale of specially constructed Bochner-Sobolev spaces. In addition, a criterion for the existence of a ``strong'' solution in these spaces is obtained."}
{"id": "2512.04676", "pdf": "https://arxiv.org/pdf/2512.04676", "abs": "https://arxiv.org/abs/2512.04676", "authors": ["Umair Zulfiqar", "Zhong-Yi Huang"], "title": "A Unified Low-rank ADI Framework with Shared Linear Solves for Simultaneously Solving Multiple Lyapunov, Sylvester, and Riccati Equations", "categories": ["eess.SY", "math.NA"], "comment": null, "summary": "It is known in the literature that the low-rank ADI method for Lyapunov equations is a Petrov-Galerkin projection algorithm that implicitly performs model order reduction. In this paper, we show that the low-rank ADI methods for Sylvester and Riccati equations are also Petrov-Galerkin projection algorithms that implicitly perform model order reduction. By observing that the ADI methods for Lyapunov, Sylvester, and Riccati equations differ only in pole placement and not in their interpolatory nature, we show that the shifted linear solves-which constitute the bulk of the computational cost-can be shared. The pole-placement step involves only small-scale operations and is therefore inexpensive. We propose a unified ADI framework that requires only two shifted linear solves per iteration to simultaneously solve six Lyapunov equations, one Sylvester equation, and ten Riccati equations, thus substantially increasing the return on investment for the computational cost spent on the linear solves. All operations needed to extract the individual solutions from these shared linear solves are small-scale and inexpensive.\n  Since all ADI methods implicitly perform model order reduction when solving these linear matrix equations, we show that the resulting reduced-order models can be obtained as an additional byproduct. These models not only interpolate the original transfer function at the mirror images of the ADI shifts but also preserve important system properties such as stability, minimum-phase property, positive-realness, bounded-realness, and passivity. Consequently, the proposed unified ADI framework also serves as a recursive, interpolation-based model order reduction method, which can preserve several important properties of the original model in the reduced-order model."}
{"id": "2512.04484", "pdf": "https://arxiv.org/pdf/2512.04484", "abs": "https://arxiv.org/abs/2512.04484", "authors": ["J. Corbett", "R. Samulyak", "F. J. Artola", "S. Jachmich", "M. Kong", "E. Nardon"], "title": "Numerical model for pellet rocket acceleration in PELOTON", "categories": ["physics.plasm-ph", "physics.comp-ph"], "comment": "17 pages, 11 figures", "summary": "A direct numerical simulation model for the rocket acceleration of pellets in thermonuclear fusion devices has been developed for PELOTON, a 3D Lagrangian particle pellet code [R. Samulyak et al, Nuclear Fusion 61 (4), 046007 (2021)], and validated using shattered pellet injection (SPI) experiments in JET. The pellet rocket acceleration is driven by grad-B drift of the ablation cloud that creates asymmetry and non-uniform heating of the cloud. The model accounts for non-uniform charging of the ablation cloud by hot plasma electrons as well as local plasma gradients. The increased pressure on the high-field-side compared to the low-field-side leads to pellet (fragment) rocket acceleration. Pure deuterium and deuterium-neon mixture models have been implemented. The background plasma states have been obtained by using a new plasma cooling model for PELOTON. The cooling model distributes the ablated material within the corresponding flux volumes and accounts for ionization and other energy losses, Ohmic heating by toroidal currents, and the energy exchange between ions and electrons. Plasma profiles predicted by PELOTON cooling model have been compared with JOREK and INDEX simulations. PELOTON simulations of rocket acceleration and the corresponding trajectories of deuterium fragments are consistent with experimentally measured trajectories in JET. We show that composite deuterium-neon pellets containing 0.5% of neon experienced smaller deviation of their trajectories compared to the pure deuterium case. We simulate various spatial configurations of pellet fragments and demonstrate the cloud overlap impact on rocket acceleration. Additionally, we demonstrate the effect of plasma state gradients on the rocket acceleration. Future work will focus on the rocket acceleration of SPI in projected ITER plasmas and the development of the corresponding scaling law for the rocket acceleration."}
{"id": "2512.04782", "pdf": "https://arxiv.org/pdf/2512.04782", "abs": "https://arxiv.org/abs/2512.04782", "authors": ["Markus Gahn", "Vlad Revnic"], "title": "Homogenized limits of Stokes flow and advective transport in thin perforated domains", "categories": ["math.AP"], "comment": null, "summary": "We deal with the rigorous homogenization and dimension reduction of flow and transport problems posed in thin $\\varepsilon$-periodic perforated layers with thickness of order $\\varepsilon^α$ with $α\\in (0,1)$ and therefore the thickness of the layer is large compared its porosity. The aim is the derivation of effective models for $\\varepsilon\\to 0 $, when the thickness of the layer tends to zero. For the flow problem we consider incompressible Stokes equations with a pressure boundary condition on the top/bottom of the layer, and the transport problem is given by reaction-diffusion-advection problem with advective flow governed from the fluid velocity from the Stokes model and different scalings for the diffusion coefficient modelling low and fast diffusion in the horizontal direction. In the limit, a Darcy-type law is obtained for the Stokes flow with Darcy-velocity depending only on the derivative of the Darcy-pressure in the vertical direction. The effective equation for the transport problem is again of diffusion-advection-type including homogenized coefficients, and with advective flow given by the Darcy-velocity and only taking place in the vertical direction. In the case of slow diffusion in the vertical direction, effective diffusion only takes place in the vertical direction, where in the case of high diffusion in horizontal direction, we obtain effective diffusion in all space directions. To pass to the limit we use the method of two-scale convergence adapted to our microscopic geometry, which is based on uniform a priori estimates. Critical parts in the derivation of the macro-models are the control of the fluid pressure, for which we construct a Bogovskii-operator for thin perforated domains, as well as the strong two-scale convergence for the microscopic solution of the transport equation, necessary to pass to the limit in the advective term."}
{"id": "2512.04546", "pdf": "https://arxiv.org/pdf/2512.04546", "abs": "https://arxiv.org/abs/2512.04546", "authors": ["Akash K. Meel", "Santosh Mogurampelly"], "title": "A hybrid Green-Kubo (hGK) framework for calculating viscosity from short MD simulations", "categories": ["cond-mat.soft", "physics.comp-ph"], "comment": null, "summary": "Viscosity calculation from equilibrium molecular dynamics (MD) simulations relies on the traditional Green-Kubo (GK) framework, which integrates the stress autocorrelation function (SACF) over time. While the formalism is exact in the linear response regime, the traditional approach often suffers from poor convergence and requires extensive phase space sampling, which is computationally demanding for soft matter and polymer systems. In this Letter, we introduce a hybrid Green-Kubo (hGK) framework that alleviates these limitations by partitioning the SACF into two physically meaningful regimes: (i) a short time ballistic component extracted directly from short MD simulations, and (ii) a long time relaxation tail represented using analytically motivated functions, $φ(τ)$, fitted only to short trajectories. This strategy bypasses the need for extensive sampling while preserving physical rigor. Benchmarking against SPC/E water confirms excellent agreement with established results, and we further demonstrate the efficacy of the method for challenging electrolyte systems (EC-LiTFSI and PEO-LiTFSI), for which the GK framework fails to converge. The computational savings are substantial, with reductions of several orders of magnitude in required sampling, achieved without compromising predictive accuracy. We also discuss the limitations of the hGK framework and outline clear avenues for refinement, including optimal tail selection and robust identification of relaxation regimes in noisy stress data. The hGK framework presented in this Letter provides a conceptually simple, broadly applicable, and computationally efficient route for viscosity prediction in molecular liquids, polymer melts, and ionically conducting soft materials."}
{"id": "2512.04796", "pdf": "https://arxiv.org/pdf/2512.04796", "abs": "https://arxiv.org/abs/2512.04796", "authors": ["Pedro Caro", "Alberto Ruiz"], "title": "The initial-to-final-state inverse problem with unbounded potentials and Strichartz estimates", "categories": ["math.AP", "math-ph", "math.CA"], "comment": "52 pages", "summary": "The initial-to-final-state inverse problem consists in determining a quantum Hamiltonian assuming the knowledge of the state of the system at some fixed time, for every initial state. We formulated this problem to establish a theoretical framework that would explain the viability of data-driven prediction in quantum mechanics. In a previous work, we analysed this inverse problem for Hamiltonians of the form $-Δ+ V$ with an electric potential $V = V({\\rm t}, {\\rm x})$, and we showed that uniqueness holds whenever the potentials are bounded and decay super-exponentially at infinity. In this paper, we extend this result for unbounded potentials. One of the key steps consists in proving a family of suitable Strichartz estimates -- including the corresponding endpoint of Keel and Tao.\n  In the context of the inverse Calderón problem this family of inequalities corresponds to the Carleman inequality proved by Kenig, Ruiz and Sogge. Haberman showed that this inequality can be also retrieved as an embedding of a suitable Bourgain space. The corresponding Bourgain space in our context do not capture the mixed-norm Lebesgue spaces of Strichartz inequalities. In this paper, we give a counterexample that justifies this fact, and shows the limitations of Bourgain spaces to address the initial-to-final-state inverse problem."}
{"id": "2512.04569", "pdf": "https://arxiv.org/pdf/2512.04569", "abs": "https://arxiv.org/abs/2512.04569", "authors": ["Wei-Wei Fu", "Dong Zhao", "Qing-Hong Rao", "Heng-Yi Wang", "Ben-Li Yu", "Zhi-Jia Hu", "Fang-Wen Sun", "Kun Huang"], "title": "An all-optical convolutional neural network for image identification", "categories": ["physics.optics", "physics.comp-ph"], "comment": "4 pages", "summary": "In modern artificial intelligence, convolutional neural networks (CNNs) have become a cornerstone for visual and perceptual tasks. However, their implementation on conventional electronic hardware faces fundamental bottlenecks in speed and energy efficiency due to resistive and capacitive losses. Photonic alternatives offer a promising route, yet the difficulty of realizing optical nonlinearities has prevented the realization of all-optical CNNs capable of end-to-end image classification. Here, we demonstrate an all-optical CNN that bypasses the need for explicit optical nonlinear activations. Our architecture comprises a single spatial-differentiation convolutional stage--using 24 directional kernels spanning 360°, along with a mean-filtering kernel--followed by a diffractive fully-connected layer. The directional convolution enhances feature selectivity, suppresses noise and crosstalk, and simplifies the classification task, allowing the weak nonlinearity inherent in optical diffraction to achieve high accuracy. We report experimentally classification accuracies of 86.8% on handwritten digits (MNIST) and 94.8% on a ten-class gesture dataset. The system delivers a computational throughput of 1.13X10^5 tera-operations per second (TOPS) and an energy efficiency of 1.51X10^3 TOPS/W--the highest reported among CNN hardware--with the potential to improve by a further 5-6 orders of magnitude using nanosecond-scale detectors. This work establishes a scalable pathway toward ultralow-latency, ultralow-energy vision processing for real-time intelligent systems."}
{"id": "2512.04800", "pdf": "https://arxiv.org/pdf/2512.04800", "abs": "https://arxiv.org/abs/2512.04800", "authors": ["Gianmarco Del Sarto", "Matthias Hieber", "Filippo Palma", "Tarek Zöchling"], "title": "Time-periodic solutions to an energy balance model coupled with an active fluid under arbitrary large forces", "categories": ["math.AP", "math-ph"], "comment": "This paper has been accepted for publication in Nonlinear Analysis: Real World Applications", "summary": "This article concerns time-periodic solutions to a two-dimensional Sellers-type energy balance model coupled to the three-dimensional primitive equations via a dynamic boundary condition. It is shown that the underlying equations admit at least one strong time-periodic solution, provided the forcing term is time-periodic. The forcing term does not need to satisfy a smallness condition and is allowed to be arbitrarily large."}
{"id": "2512.04592", "pdf": "https://arxiv.org/pdf/2512.04592", "abs": "https://arxiv.org/abs/2512.04592", "authors": ["Josep Plana-Riu", "Henrik Rosenberger", "Benjamin Sanderse", "F. Xavier Trias"], "title": "Stable self-adaptive timestepping for Reduced Order Models for incompressible flows", "categories": ["math.NA", "physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "This work introduces RedEigCD, the first self-adaptive timestepping technique specifically tailored for reduced-order models (ROMs) of the incompressible Navier-Stokes equations. Building upon linear stability concepts, the method adapts the timestep by directly bounding the stability function of the employed time integration scheme using exact spectral information of matrices related to the reduced operators. Unlike traditional error-based adaptive methods, RedEigCD relies on the eigenbounds of the convective and diffusive ROM operators, whose computation is feasible at reduced scale and fully preserves the online efficiency of the ROM. A central theoretical contribution of this work is the proof, based on the combined theorems of Bendixson and Rao, that, under linearized assumptions, the maximum stable timestep for projection-based ROMs is shown to be larger than or equal to that of their corresponding full-order models (FOMs). Numerical experiments for both periodic and non-homogeneous boundary conditions demonstrate that RedEigCD yields stable timestep increases up to a factor 40 compared to the FOM, without compromising accuracy. The methodology thus establishes a new link between linear stability theory and reduced-order modeling, offering a systematic path towards efficient, self-regulating ROM integration in incompressible flow simulations."}
{"id": "2512.04826", "pdf": "https://arxiv.org/pdf/2512.04826", "abs": "https://arxiv.org/abs/2512.04826", "authors": ["Kelvin J. R. Almeida-Sousa", "Alexandre B. Simas"], "title": "Spectral Theory of Krein-Feller Type Operators and Applications in Stochastic Fractional Elliptic and Parabolic Equations", "categories": ["math.AP", "math.FA", "math.PR", "math.SP"], "comment": null, "summary": "It has been shown that the space $C^{\\infty}_{W,V}(\\mathbb{T})$, introduced in Simas and Sousa (Potential Analysis, 2025), is the natural regularity space for solutions of the eigenvalue problem $Δ_{W,V} u = λu$ on the torus $\\mathbb{T}$, where $Δ_{W,V} = \\frac{d^{+}}{dV}\\frac{d^{-}}{dW}$ is the Krein Feller operator in the case where $W$ and $V$ are strictly increasing and right continuous (respectively left continuous), possibly with dense sets of discontinuities. In this work we provide conditions ensuring that every function in $C^{\\infty}_{W,V}(\\mathbb{T})$, which may be highly discontinuous, admits a series expansion that generalizes the classical Taylor expansion. A central feature of our approach is that all proofs are nonstandard, since classical analytical and spectral arguments cannot be adapted to this singular setting. Using these methods we characterize the eigenvectors of $Δ_{W,V}$ in terms of generalized trigonometric functions and obtain an asymptotic lower bound for the associated eigenvalues. We also derive a sharp upper bound for the convergence exponent of these eigenvalues, and as a consequence we prove that $C^{\\infty}_{W,V}(\\mathbb{T})$ is a nuclear space. Further consequences include results on the asymptotic behavior of eigenvalues of compact operators and improvements in traceability. As a final application we establish existence results for generalized fractional stochastic and deterministic differential equations, as well as for parabolic stochastic partial differential equations acting on nuclear spaces."}
{"id": "2512.04663", "pdf": "https://arxiv.org/pdf/2512.04663", "abs": "https://arxiv.org/abs/2512.04663", "authors": ["Jannes Nys", "Juan Carrasquilla"], "title": "Fermionic neural Gibbs states", "categories": ["quant-ph", "cond-mat.str-el", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "We introduce fermionic neural Gibbs states (fNGS), a variational framework for modeling finite-temperature properties of strongly interacting fermions. fNGS starts from a reference mean-field thermofield-double state and uses neural-network transformations together with imaginary-time evolution to systematically build strong correlations. Applied to the doped Fermi-Hubbard model, a minimal lattice model capturing essential features of strong electronic correlations, fNGS accurately reproduces thermal energies over a broad range of temperatures, interaction strengths, even at large dopings, for system sizes beyond the reach of exact methods. These results demonstrate a scalable route to studying finite-temperature properties of strongly correlated fermionic systems beyond one dimension with neural-network representations of quantum states."}
{"id": "2512.04882", "pdf": "https://arxiv.org/pdf/2512.04882", "abs": "https://arxiv.org/abs/2512.04882", "authors": ["Rahul Barthwal", "Firas Dhaouadi", "Christian Rohde"], "title": "On hyperbolic approximations for a class of dispersive and diffusive-dispersive equations", "categories": ["math.AP"], "comment": null, "summary": "We introduce novel approximate systems for dispersive and diffusive-dispersive equations with nonlinear fluxes. For purely dispersive equations, we construct a first-order, strictly hyperbolic approximation. Local well-posedness of smooth solutions is achieved by constructing a unique symmetrizer that applies to arbitrary smooth fluxes. Under stronger conditions on the fluxes, we provide a strictly convex entropy for the hyperbolic system that corresponds to the energy of the underlying dispersive equation. To approximate diffusive-dispersive equations, we rely on a viscoelastic damped system that is compatible with the found entropy for the hyperbolic approximation of the dispersive evolution. For the resulting hyperbolic-parabolic approximation, we provide a global well-posedness result. Using the relative entropy framework \\cite{dafermos2005hyperbolic}, we prove that the solutions of the approximate systems converge to solutions of the original equations. The structure of the new approximate systems allows to apply standard numerical simulation methods from the field of hyperbolic balance laws. We confirm the convergence of our approximations even beyond the validity range of our theoretical findings on set of test cases covering different target equations. We show the applicability of the approach for strong nonlinear effects leading to oscillating or shock-layer-forming behavior."}
{"id": "2512.04954", "pdf": "https://arxiv.org/pdf/2512.04954", "abs": "https://arxiv.org/abs/2512.04954", "authors": ["Rajneil Baruah"], "title": "Amortized Inference of Multi-Modal Posteriors using Likelihood-Weighted Normalizing Flows", "categories": ["cs.LG", "hep-ex", "hep-ph", "physics.comp-ph", "physics.data-an"], "comment": "14 pages, 8 figures", "summary": "We present a novel technique for amortized posterior estimation using Normalizing Flows trained with likelihood-weighted importance sampling. This approach allows for the efficient inference of theoretical parameters in high-dimensional inverse problems without the need for posterior training samples. We implement the method on multi-modal benchmark tasks in 2D and 3D to check for the efficacy. A critical observation of our study is the impact of the topology of the base distributions on the modelled posteriors. We find that standard unimodal base distributions fail to capture disconnected support, resulting in spurious probability bridges between modes. We demonstrate that initializing the flow with a Gaussian Mixture Model that matches the cardinality of the target modes significantly improves reconstruction fidelity, as measured by some distance and divergence metrics."}
{"id": "2512.04928", "pdf": "https://arxiv.org/pdf/2512.04928", "abs": "https://arxiv.org/abs/2512.04928", "authors": ["Max Fathi", "Michael Goldman", "Daniel Tsodyks"], "title": "Quantitative rigidity of the Wasserstein contraction under convolution", "categories": ["math.AP", "math.FA", "math.OC", "math.PR"], "comment": null, "summary": "The aim of this paper is to investigate the contraction properties of $p$-Wasserstein distances with respect to convolution in Euclidean spaces both qualitatively and quantitatively. We connect this question to the question of uniform convexity of the Kantorovich functional on which there was substantial recent progress (mostly for $p=2$ and partially for $p>1$). Motivated by this connection we extend these uniform convexity results to the case $p=1$, which is of independent interest."}
{"id": "2512.04962", "pdf": "https://arxiv.org/pdf/2512.04962", "abs": "https://arxiv.org/abs/2512.04962", "authors": ["L. Andrew Wray", "Cheng-Ju Lin", "Vincent Su", "Hrant Gharibyan"], "title": "Convergence of sample-based quantum diagonalization on a variable-length cuprate chain", "categories": ["quant-ph", "cond-mat.other", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Sample-based quantum diagonalization (SQD) is an algorithm for hybrid quantum-classical molecular simulation that has been of broad interest for application with noisy intermediate scale quantum (NISQ) devices. However, SQD does not always converge on a practical timescale. Here, we explore scaling of the algorithm for a variable-length molecule made up of 2 to 6 copper oxide plaquettes with a minimal molecular orbital basis. The results demonstrate that enabling all-to-all connectivity, instituting a higher expansion order for the SQD algorithm, and adopting a non-Hartree-Fock molecular orbital basis can all play significant roles in overcoming sampling bottlenecks, though with tradeoffs that need to be weighed against the capabilities of quantum and classical hardware. Additionally, we find that noise on a real quantum computer, the Quantinuum H2 trapped ion device, can improve energy convergence beyond expectations based on noise-free statevector simulations."}
{"id": "2512.04961", "pdf": "https://arxiv.org/pdf/2512.04961", "abs": "https://arxiv.org/abs/2512.04961", "authors": ["Gabrielle Nornberg", "Ricardo Ziegele"], "title": "Existence and a priori bounds for fully nonlinear PDEs with a harmonic map-like structure", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we study a new class of fully nonlinear uniformly elliptic equations with a so-called harmonic map-like structure, whose model case is given by \\begin{equation*} \\mathcal{M}^{\\pm}_{λ,Λ}(D^2u) \\pm b(x) |Du| \\pm β(u)\\langle M(x) Du,Du \\rangle \\pm c(x) u = f(x)\\; \\textrm{ in } Ω, \\end{equation*} where $Ω\\subset \\mathbb{R}^n$ is a bounded $C^{1,1}$ domain, $\\mathcal{M}^{\\pm}$ are the Pucci extremal operators, $β(s) = s^k$ for some $k \\in \\mathbb{N} $ odd, $b \\in L^{q}_{+}(Ω)$, $c,f \\in L^p(Ω)$, and $n \\leq p \\leq q$, $q>n$.\n  We obtain existence results under a smallness regime on the coefficients, along with some classical results such as the Aleksandrov--Bakelman--Pucci estimate and the comparison principle, as well as a priori bounds for the respective Dirichlet problem in the noncoercive case. We also establish multiplicity results and qualitative behavior, which seem to be new in the case of the Laplacian operator."}
{"id": "2512.05031", "pdf": "https://arxiv.org/pdf/2512.05031", "abs": "https://arxiv.org/abs/2512.05031", "authors": ["Rajneil Baruah", "Subhadeep Mondal", "Sunando Kumar Patra", "Satyajit Roy"], "title": "CNN on `Top': In Search of Scalable & Lightweight Image-based Jet Taggers", "categories": ["hep-ph", "physics.comp-ph", "physics.data-an"], "comment": "12 pages, 3 figures, 2 tables", "summary": "While Transformer-based and standard Graph Neural Networks (GNNs) have proven to be the best performers in classifying different types of jets, they require substantial computational power. We explore the scope of using a lightweight and scalable version of the EfficientNet architecture, along with global features of the jet. The end product is computationally inexpensive but is capable of competitive performance. We showcase the efficacy of our network for tagging top-quark jets in a sea of other light-quark and gluon jets."}
{"id": "2512.04978", "pdf": "https://arxiv.org/pdf/2512.04978", "abs": "https://arxiv.org/abs/2512.04978", "authors": ["Maximilian Hörl", "Kundan Kumar", "Christian Rohde"], "title": "Fractured Poroelastic Media in the Limit of Vanishing Aperture", "categories": ["math.AP"], "comment": null, "summary": "We consider a poroelastic medium with a thin heterogeneity, also referred to as a fracture. Fluid flow and mechanical deformation inside both bulk and fracture are governed by the quasi-static Biot equations. The fracture's material parameters, such as hydraulic conductivity and elasticity, are assumed to scale with powers of the width-to-length ratio $\\varepsilon$ of the fracture. Based on a priori estimates, we rigorously derive limit models as $\\varepsilon \\rightarrow 0$ and identify different limit regimes. We obtain five regimes for the hydraulic conductivity and two for the elasticity. While many cases yield discrete fracture models, others result in two-scale limit problems dominated by normal flow or deformation."}
{"id": "2512.05042", "pdf": "https://arxiv.org/pdf/2512.05042", "abs": "https://arxiv.org/abs/2512.05042", "authors": ["Sergio Carbajo", "Seung-Whan Bahk", "Justin Baker", "Andrea Bertozzi", "Abhimanyu Borthakur", "Antonino Di Piazza", "Andrew Forbes", "Spencer Gessner", "Jack Hirschman", "Franz Kärtner", "Maciej Lewenstein", "Yuhang Li", "Inhyuk Nam", "Eileen Otte", "Aydogan Ozcan", "James Rozensweig", "Yijie Shen", "Liwei Song", "Ye Tian", "Yu Wang", "Yuntian Wang", "Logan Wright", "Xiaojun Wu", "Hao Zhang"], "title": "Structured Light at the Extreme: Harnessing Spatiotemporal Control for High-Field Laser-Matter Interactions", "categories": ["physics.optics", "math-ph", "physics.comp-ph"], "comment": null, "summary": "This review charts the emerging paradigm of intelligent structured light for high-field laser-matter interactions, where the precise spatiotemporal and vectorial control of light is a critical degree of freedom. We outline a transformative framework built upon three synergistic pillars. First, we survey the advanced electromagnetic toolkit, moving beyond conventional spatial light modulators to include robust static optics and the promising frontier of plasma light modulators. Second, we detail the optimization engine for this high-dimensional design space, focusing on physics-informed digital twins and AI-driven inverse design to automate the discovery of optimal light structures. Finally, we explore the groundbreaking applications enabled by this integrated approach, including programmable electron beams, orbital-angular-momentum-carrying γ-rays, compact THz accelerators, and robust communications. The path forward necessitates overcoming grand challenges in material science, real-time adaptive control at MHz rates, and the extension of these principles to the quantum realm. This review serves as a call to action for a coordinated, interdisciplinary effort to command, rather than merely observe, light-matter interactions at the extreme."}
{"id": "2512.05010", "pdf": "https://arxiv.org/pdf/2512.05010", "abs": "https://arxiv.org/abs/2512.05010", "authors": ["Ralf Kaiser"], "title": "Geophysical intensity problems: the axisymmetric case", "categories": ["math.AP", "astro-ph.EP"], "comment": "55 pages, 6 figures", "summary": "Considering the earth or any other celestial body the main sources of the gravitational as well as of the magnetic field lie inside the body. Above the surface both fields are in good approximation harmonic vector fields determined by their values at the body's surface or any other surface enclosing the body. The intensity problem seeks to determine harmonic vector fields vanishing at infinity and with prescribed intensity of the field at the surface. This problem constitutes a nonlinear boundary value problem, whose general solvability is not yet established. In this paper {\\em axisymmetric} harmonic fields ${\\bf H}$ outside the unit sphere $S^2$ are studied and, given an axisymmetric Hölder continuous intensity function $I\\neq 0$ on $S^2$, the existence of infinitely many solutions of the intensity problem is proved. These solutions can more precisely be characterized as follows: fix a number $\\de \\in \\nat\\setminus \\{1 \\}$ and a meridional plane $M$ through the symmetry axis $S\\!A$, and in $M$ a unit circle $S^1$ (symmetric with respect to $S\\!A$) and, furthermore, $2\\, N$, $N \\in \\nat_0$, points $z_n \\in M$ (symmetric with respect to $S\\!A$, avoiding $S\\!A$, and outside $S^1$), then the existence of an (up to a sign) unique harmonic field ${\\bf H}$ is established that vanishes at (the axisymmetric circles piercing $M$ at) $z_n$ and nowhere else, that has intensity $I$ at $S^2$ and (exact) decay order $\\de$ at infinity. The proof is based on the solution of a nonlinear elliptic equation with discontinuous coefficients, which are, moreover, singular at the symmetry axis. Its combination with fixed boundary conditions was the basis of a recent treatment of the ``geomagnetic direction problem'' \\cite{KR22}. Here we have instead natural boundary conditions, which provide less information, and which require, therefore, in part new solution techniques and sharper estimates."}
{"id": "2512.05055", "pdf": "https://arxiv.org/pdf/2512.05055", "abs": "https://arxiv.org/abs/2512.05055", "authors": ["Radu Precup", "Andrei Stan"], "title": "A Nehari manifold method for nonvariational problems", "categories": ["math.AP", "math.FA"], "comment": null, "summary": "The aim of this paper is to extend the Nehari manifold method from the variational setting to the nonvariational framework of fixed point equations. This is achieved by constructing a radial energy functional that generalizes the standard one from the variational case. Furthermore, the solutions obtained through our method are localized in conical annular sets, which leads to the existence of multiple solutions. The abstract results are illustrated by two representative applications."}
{"id": "2512.05077", "pdf": "https://arxiv.org/pdf/2512.05077", "abs": "https://arxiv.org/abs/2512.05077", "authors": ["Sigurd Angenent", "Panagiota Daskalopoulos", "Natasa Sesum"], "title": "Mean curvature flow near a peanut solution", "categories": ["math.AP"], "comment": null, "summary": "It was shown by Angenent, Altschuler and Giga, and by Angenent and Velazquez that there exist closed mean curvature flow solutions that extinct to a point in finite time, without ever becoming convex prior to their extinction. These solutions develop a degenerate neckpinch singularity, meaning that the tangent flow at a singularity is a round cylinder, but at the same time for each of these solutions there exists a sequence of points in space and time, so that the pointed blow up limit around this sequence is the Bowl soliton. These solutions are called peanut solutions and they were first conjectured to exist by Richard Hamilton, while the existence of those solutions was shown by Angenent, Altschuler and Giga. In this paper we show that this type of solutions are highly unstable, in the sense that in every small neighborhood of any such peanut solution we can find a perturbation so that the mean curvature flow starting at that perturbation develops spherical singularity, and at the same time we can find a perturbation so that the mean curvature flow starting at that perturbation develops a nondegenerate neckpinch singularity. We also show that appropriately rescaled subsequence of any sequence of solutions whose initial data converge to the peanut solution, and all of which develop spherical singularities, converges to the Ancient oval solution."}
{"id": "2512.04214", "pdf": "https://arxiv.org/pdf/2512.04214", "abs": "https://arxiv.org/abs/2512.04214", "authors": ["Martin Taylor", "Renato Velozo Ruiz"], "title": "Phase mixing and the Vlasov equation in cosmology", "categories": ["gr-qc", "math-ph", "math.AP"], "comment": "52 pages, 2 figures", "summary": "We consider the Vlasov equation on slowly expanding isotropic homogeneous tori, described by the Friedmann--Lemaître--Robertson--Walker cosmological spacetimes. For expansion rate $t^q$, with $0< q<\\frac{1}{2}$ (excluding certain exceptional values), we show that the spatial density decays at the rate $t^{-6q}$ and that, when the spatial average is removed, the density decays at an enhanced rate due to a phase mixing effect. This enhancement is polynomial for Sobolev initial data and super-polynomial, but sub-exponential, for real analytic initial data. We further show that, when the expansion rate is the borderline $t^{\\frac{1}{2}}$ -- the rate which describes a radiation filled universe -- a degenerate phase mixing effect results in a logarithmic enhancement for Sobolev initial data and a super-logarithmic enhancement (in fact, a gain of $\\exp(-μ(\\log t)^ε)$ for some $μ,ε>0$) for analytic initial data. The proof is based on a collection of commuting vector fields, and certain combinatorial properties of an associated collection of differential operators. The vector fields are not explicit, but are shown to have good properties when $t$ is large with respect to the momentum support of the solution. A physical space dyadic localisation is employed to treat non-compactly supported (in particular, non-trivial real analytic) but suitably decaying solutions."}
{"id": "2512.04297", "pdf": "https://arxiv.org/pdf/2512.04297", "abs": "https://arxiv.org/abs/2512.04297", "authors": ["Robin Chemnitz", "Dennis Chemnitz"], "title": "Mixing at the Batchelor Scale for White-In-Time Flows", "categories": ["math.PR", "math.AP", "math.DS"], "comment": null, "summary": "We consider the mixing properties of solutions to the advection-diffusion equation of a white-in-time velocity field on the 2-dimensional torus with four forced modes. As the diffusivity parameter goes to zero, we show that the almost-sure exponential dissipation rate stays bounded from below. Together with the corresponding upper bound established by Gess and Yaroslavtsev, this constitutes an example of a velocity field for which the Batchelor scale conjecture can be verified. In addition, we characterize the exponential mixing rate without diffusion of this system. Our results are not restricted to two dimensions, and we construct a three-dimensional white-in-time velocity field with the same properties."}
{"id": "2512.04410", "pdf": "https://arxiv.org/pdf/2512.04410", "abs": "https://arxiv.org/abs/2512.04410", "authors": ["Xiaoqin Guo", "Timo Sprekeler", "Hung V. Tran"], "title": "Homogenizationof non-divergence form operators in i.i.d. random environments", "categories": ["math.PR", "math.AP"], "comment": "25 pages", "summary": "We study random walks in a balanced, i.i.d. random environment in $\\mathbb Z^d$ for $d\\geq 3$. We establish improved convergence rates for the homogenization of the Dirichlet problem associated with the corresponding non-divergence form difference operators, surpassing the $O(R^{-1})$ rate, which is expected to be optimal for environments with a finite range of dependence. In particular, the improved rates are $O(R^{-3/2})$ when $d=3$, and $O(R^{-2}\\log R)$ when $d\\geq 4$."}
{"id": "2512.04422", "pdf": "https://arxiv.org/pdf/2512.04422", "abs": "https://arxiv.org/abs/2512.04422", "authors": ["Shi Zhuo Looi", "David Sher"], "title": "The Dirichlet heat trace for domains with curved corners", "categories": ["math.SP", "math.AP"], "comment": "20 pages", "summary": "We study the short-time asymptotics of the Dirichlet heat trace on planar curvilinear polygons. For such domains we show that the coefficient of $t^{1/2}$ in the expansion splits into a boundary integral of $κ^2$ and a sum of local corner contributions, one for each vertex. Each curved corner contribution depends only on the interior angle $α$ and on the limiting curvatures $κ_{\\pm}$ on the adjacent sides. Using a conformal model and a parametrix construction on the sector heat space, we express this contribution in the form $c_{1/2}(α)\\,r_0(α,κ_+, κ_-)$, where $c_{1/2}(α)$ is given by a Hadamard finite part of an explicit trace over the exact sector. For right-angled corners we compute $c_{1/2}(π/2)=1/(16\\sqrtπ)$ and obtain a closed formula for the $t^{1/2}$ coefficient. As an application we extend a previous result in the literature by showing that any admissible curvilinear polygon that is Dirichlet isospectral to a polygon must itself be a polygon with straight sides."}
{"id": "2512.04824", "pdf": "https://arxiv.org/pdf/2512.04824", "abs": "https://arxiv.org/abs/2512.04824", "authors": ["Arthur Saunier", "Leo Agelas", "Ani Anciaux Sedrakian", "Ibtihel Ben Gharbia", "Xavier Claeys"], "title": "Hierarchical matrix approximability of inverse of convection dominated finite element matrices", "categories": ["math.NA", "math.AP"], "comment": "32 pages, 22 figures. Submited to the Journal of Computational Physics", "summary": "Several researchers have developed a rich toolbox of matrix compression techniques that exploit structure and redundancy in large matrices. Classical methods such as the block low-rank format and the Fast Multipole Method make it possible to manipulate very large systems by representing them in a reduced form. Among the most sophisticated tools in this area are hierarchical matrices (H-matrices), which exploit local properties of the underlying kernel or operator to approximate matrix blocks by low-rank factors, organized in a recursive hierarchy. H-matrices offer a flexible and scalable framework, yielding nearly linear complexity in both storage and computation. Hierarchical matrix techniques, originally developed for boundary integral equations, have recently been applied to matrices stemming from the discretization of advection-dominated problems. However, their effectiveness is limited by the loss of coercivity induced by convection phenomena, where traditional methods fail. Initial work by Le Borne addressed this by modifying the admissibility criterion for structured grids with constant convection, but challenges remain for more general grids and advection fields. In this work, we propose a novel partitioning strategy based on \"convection tubes\", clusters aligned with the convection vector field. This method does not require a structured grid or constant convection, overcoming the limitations of previous approaches. We present both theoretical analyses and numerical experiments, that demonstrate the efficiency and robustness of our method for convection-dominated PDEs on unstructured grids. The approach builds on a Péclet-robust Caccioppoli inequality, crucial for handling convection-dominated problems."}
{"id": "2512.05036", "pdf": "https://arxiv.org/pdf/2512.05036", "abs": "https://arxiv.org/abs/2512.05036", "authors": ["V. I. Gerasimenko", "I. V. Gapyak"], "title": "Cumulant expansions of operator groups of quantum many-particle systems", "categories": ["math-ph", "cond-mat.stat-mech", "math.AP"], "comment": "19 pages", "summary": "The article presents a method of cluster expansions for groups of operators associated with the von Neumann equations for states and the Heisenberg equations for observables, aiming to construct generating operators for nonperturbative solutions to the Cauchy problem for hierarchies of evolution equations of many-particle quantum systems."}
