{"id": "2512.08099", "pdf": "https://arxiv.org/pdf/2512.08099", "abs": "https://arxiv.org/abs/2512.08099", "authors": ["Matthias Beckmann", "Robert Beinert", "Jonas Bresch"], "title": "Generalizations of the Normalized Radon Cumulative Distribution Transform for Limited Data Recognition", "categories": ["math.NA", "cs.CV", "cs.IT"], "comment": null, "summary": "The Radon cumulative distribution transform (R-CDT) exploits one-dimensional Wasserstein transport and the Radon transform to represent prominent features in images. It is closely related to the sliced Wasserstein distance and facilitates classification tasks, especially in the small data regime, like the recognition of watermarks in filigranology. Here, a typical issue is that the given data may be subject to affine transformations caused by the measuring process. To make the R-CDT invariant under arbitrary affine transformations, a two-step normalization of the R-CDT has been proposed in our earlier works. The aim of this paper is twofold. First, we propose a family of generalized normalizations to enhance flexibility for applications. Second, we study multi-dimensional and non-Euclidean settings by making use of generalized Radon transforms. We prove that our novel feature representations are invariant under certain transformations and allow for linear separation in feature space. Our theoretical results are supported by numerical experiments based on 2d images, 3d shapes and 3d rotation matrices, showing near perfect classification accuracies and clustering results.", "AI": {"tldr": "The paper proposes generalized normalizations for the Radon-CDT to handle affine transformations and extends it to multi-dimensional/non-Euclidean settings using generalized Radon transforms, achieving near-perfect classification accuracy.", "motivation": "The R-CDT is effective for image classification but lacks invariance to affine transformations that occur in real-world measurements (e.g., watermark recognition). Existing two-step normalization is limited, and the method needs extension to multi-dimensional and non-Euclidean settings.", "method": "Proposes a family of generalized normalizations for R-CDT to handle affine transformations, and extends the framework using generalized Radon transforms for multi-dimensional and non-Euclidean data (2D images, 3D shapes, 3D rotation matrices).", "result": "Theoretical proofs show the new feature representations are invariant under certain transformations and allow linear separation in feature space. Numerical experiments demonstrate near-perfect classification accuracies and clustering results across different data types.", "conclusion": "The generalized R-CDT framework provides flexible, invariant feature representations that enable effective linear classification in multi-dimensional and non-Euclidean settings, with strong empirical performance across diverse applications."}}
{"id": "2512.08142", "pdf": "https://arxiv.org/pdf/2512.08142", "abs": "https://arxiv.org/abs/2512.08142", "authors": ["Amy de Castro", "Hyesuk Lee"], "title": "Well-posedness of a novel Lagrange multiplier formulation for fluid-poroelastic interaction", "categories": ["math.NA"], "comment": null, "summary": "We introduce a novel monolithic formulation that employs Lagrange multipliers (LMs) to couple a fluid flow governed by the time-dependent Stokes equations with a poroelastic structure described by the Biot equations. The formulation is developed in detail, and we establish the well-posedness of both the semi-discrete and fully discrete saddle point problems. We further prove the stability of the fully discrete system. This saddle point formulation, which utilizes three LMs, is designed to enable a partitioned approach that completely decouples the Stokes and Biot subdomains, and this approach will be explored in a subsequent work.", "AI": {"tldr": "Monolithic formulation using Lagrange multipliers to couple Stokes fluid flow with Biot poroelastic structure, enabling partitioned approach with complete decoupling.", "motivation": "To develop a coupled fluid-poroelastic structure model that can be solved using a partitioned approach, allowing separate solution of Stokes and Biot subdomains while maintaining proper coupling through Lagrange multipliers.", "method": "Novel monolithic formulation employing three Lagrange multipliers to couple time-dependent Stokes equations (fluid flow) with Biot equations (poroelastic structure). The formulation establishes well-posedness for semi-discrete and fully discrete saddle point problems, and proves stability of the fully discrete system.", "result": "Developed a complete formulation with well-posedness proofs for both semi-discrete and fully discrete problems, and established stability of the fully discrete system. The three-Lagrange-multiplier approach enables complete decoupling of Stokes and Biot subdomains.", "conclusion": "The monolithic saddle point formulation successfully couples Stokes and Biot systems while enabling partitioned solution approaches, with rigorous mathematical foundations established for well-posedness and stability. The partitioned approach will be explored in future work."}}
{"id": "2512.08178", "pdf": "https://arxiv.org/pdf/2512.08178", "abs": "https://arxiv.org/abs/2512.08178", "authors": ["Haonan Gu"], "title": "The Instability of Painlev\u00e9 Equations in Recovering Largest Eigenvalue Distributions of GUE, LUE, JUE and an Attempt of Solution to It", "categories": ["math.NA", "math.PR"], "comment": null, "summary": "The distribution of the largest eigenvalue for the three classical unitary ensembles -- GUE, LUE, and JUE -- admits two complementary exact descriptions: (i) as Fredholm determinants of their orthogonal polynomial correlation kernels and (ii) as isomonodromic $\u03c4$--functions governed by Painlev\u00e9 equations. For finite $n$, the associated Jimbo-Miwa-Okamoto $\u03c3$-forms are $\\PIV$ (GUE), $\\mathrm{PV}$ (LUE), and $\\PVI$ (JUE); under soft- or hard-edge scalings these degenerate to $\\PII$ or $\\PIIIp$ descriptions of the Tracy-Widom and hard-edge laws \\cite{tracy1994level,forrester2003painleve,deift1999orthogonal}.\n  It is well known among random matrix theorists (for example Folkmar Bornemann) that the Fredholm determinant is a more numerically stable and accurate way to compute the CDF of the largest eigenvalue for GUE, LUE, JUE than direct Painlev\u00e9 integration. The aim of this paper is not to improve on Fredholm methods, but to see to what extent one can numerically recover the \\emph{correct} Painlev\u00e9 solution from finite-$n$ data and how unstable this reconstruction is. Numerically, we verify the equality between the Fredholm- and Painlev\u00e9-based CDFs by combining (a) high-accuracy Nystr\u00f6m discretizations of the finite-$n$ Fredholm determinants \\cite{bornemann2010numerical} with (b) an anchored, branch-locked integration of the $\u03c3$-form ODEs, where anchors are extracted from local least-squares fits to $\\log\\det(I-\\mathsf K)$. Our results confirm agreement across GUE/LUE/JUE with precision of $O(10^{-3})$ to $O(10^{-5})$ (occasionally $O(10^{-2})$) and illustrate the finite-$n$ to scaling-limit transition. The theoretical connections to $\u03c4$-functions and Virasoro constraints follow the framework of \\cite{adler2000random,forrester2003painleve}", "AI": {"tldr": "This paper compares two exact descriptions of largest eigenvalue distributions in random matrix theory: Fredholm determinants vs Painlev\u00e9 equations, showing numerical reconstruction of Painlev\u00e9 solutions from finite-n data is possible but unstable.", "motivation": "To investigate whether one can numerically recover the correct Painlev\u00e9 solution from finite-n data, despite known numerical instability compared to Fredholm determinant methods, and to verify equality between Fredholm- and Painlev\u00e9-based CDFs.", "method": "Combines (a) high-accuracy Nystr\u00f6m discretizations of finite-n Fredholm determinants with (b) anchored, branch-locked integration of \u03c3-form ODEs, using anchors extracted from local least-squares fits to log determinants.", "result": "Confirms agreement between Fredholm- and Painlev\u00e9-based CDFs across GUE/LUE/JUE with precision of O(10^{-3}) to O(10^{-5}) (occasionally O(10^{-2})), illustrating finite-n to scaling-limit transition.", "conclusion": "While Fredholm determinants remain numerically superior, Painlev\u00e9 solutions can be reconstructed from finite-n data with careful numerical methods, validating theoretical connections between these complementary descriptions."}}
{"id": "2512.08207", "pdf": "https://arxiv.org/pdf/2512.08207", "abs": "https://arxiv.org/abs/2512.08207", "authors": ["Jerem\u00edas Garay", "David Nolte", "Crist\u00f3bal Bertoglio"], "title": "Duct boundary conditions for incompressible fluid flows: finite element discretizations and parameter estimation in coronary blood flow", "categories": ["math.NA"], "comment": null, "summary": "3D-0D coupled flow models are widely used across many application fields but remain challenging to solve. Implicit coupling introduces non-local terms, whereas explicit coupling results in only conditionally stable schemes. Furthermore, incorporating inertial effects alongside viscous resistance enlarges the parameter space, making calibration more difficult.\n  In this work, we propose a new type of boundary condition based on the method of asymptotic partial decomposition of a domain (MAPDD), which we denote as the Duct Boundary Condition (DuBC). This approach enables the incorporation of geometrically reduced domains as a boundary term with only local coupling in the implicit case. Moreover, the DuBC accounts for both viscous and inertial effects simultaneously using a single physical parameter. Additionally, we derive a fractional-step time-marching scheme including the DuBC. We demonstrate the features of the DuBC in coronary artery blood flow simulations, including sequential parameter estimation from noisy velocity data.", "AI": {"tldr": "Proposes Duct Boundary Condition (DuBC) using asymptotic domain decomposition for 3D-0D coupled flow models, enabling local implicit coupling and handling both viscous/inertial effects with single parameter.", "motivation": "3D-0D coupled flow models are challenging: implicit coupling introduces non-local terms, explicit coupling is conditionally stable, and incorporating inertial effects alongside viscous resistance complicates parameter calibration.", "method": "Develops Duct Boundary Condition (DuBC) based on asymptotic partial domain decomposition (MAPDD), enabling geometrically reduced domains as boundary terms with local implicit coupling. Derives fractional-step time-marching scheme including DuBC.", "result": "Demonstrates DuBC features in coronary artery blood flow simulations, including successful sequential parameter estimation from noisy velocity data.", "conclusion": "DuBC provides efficient approach for 3D-0D coupled flow problems with local implicit coupling, unified handling of viscous/inertial effects using single parameter, and practical applicability in biomedical simulations."}}
{"id": "2512.08158", "pdf": "https://arxiv.org/pdf/2512.08158", "abs": "https://arxiv.org/abs/2512.08158", "authors": ["Ziyan Zhao", "Ting Peng", "Peng Wu", "Chaojun Hu", "Qilin Yi", "Chuangrui Huang", "Junjie Niu", "Xiaoxue Xu", "Tao Li", "Yuan Li"], "title": "Seasonal thermal stress analysis of defective mass concrete sidewalls based on the average forming temperature method", "categories": ["physics.comp-ph"], "comment": null, "summary": "Thermal cracking in urban underground sidewalls is frequently observed when structures are cast in summer and enter service in winter, as seasonal temperature gradients act under structural restraint. To quantify the local stress field associated with pre-existing cracks, an orthogonal finite-element simulation matrix of 16 combinations is constructed. Distributions of maximum principal stress () at the surface crack tip and along the upper half of the crack bottom are evaluated using steady-state thermal loading and a linear-elastic constitutive model. Across all cases, pronounced tensile stress concentration occurs at both locations: the maximum ranges from 19.2 to 34.1 MPa at the crack surface end and from 17.2 to 29.4 MPa at the crack bottom. These concentrated values are consistently higher than the stress level at the same locations in an otherwise identical uncracked wall, clarifying how seasonal temperature gradients under restraint amplify local stresses around existing defects. The quantitative ranges reported here provide a basis for risk screening and for formulating practical mitigation measures (e.g., joint spacing and insulation strategies) in the design and operation of urban underground enclosure walls. In addition, three-dimensional simulations of randomly distributed internal voids show that adopting average forming temperature increases the peak tensile stress on void surfaces from 3.42 to 4.40 MPa at 10 deg C and from 5.98 to 6.96 MPa at -5 deg C, further highlighting the risk amplification effect of AFT under cold service conditions.", "AI": {"tldr": "Finite-element analysis shows seasonal temperature gradients in urban underground walls cause significant tensile stress concentration (19.2-34.1 MPa) at existing crack tips, amplifying risks compared to uncracked walls, with forming temperature effects further increasing void surface stresses.", "motivation": "Thermal cracking in urban underground sidewalls is common when structures are cast in summer and enter service in winter, as seasonal temperature gradients act under structural restraint. There's a need to quantify local stress fields around pre-existing cracks to understand risk amplification.", "method": "Orthogonal finite-element simulation matrix of 16 combinations using steady-state thermal loading and linear-elastic constitutive model. Analyzed distributions of maximum principal stress at crack surface tip and along upper half of crack bottom. Also conducted 3D simulations of randomly distributed internal voids.", "result": "Pronounced tensile stress concentration occurs at both crack locations: 19.2-34.1 MPa at crack surface end and 17.2-29.4 MPa at crack bottom. These values are consistently higher than stress levels in identical uncracked walls. 3D simulations show average forming temperature increases peak tensile stress on void surfaces from 3.42 to 4.40 MPa at 10\u00b0C and from 5.98 to 6.96 MPa at -5\u00b0C.", "conclusion": "Seasonal temperature gradients under restraint amplify local stresses around existing defects. Quantitative ranges provide basis for risk screening and practical mitigation measures (joint spacing, insulation strategies) in urban underground enclosure wall design and operation. Average forming temperature further amplifies risks under cold service conditions."}}
{"id": "2512.07883", "pdf": "https://arxiv.org/pdf/2512.07883", "abs": "https://arxiv.org/abs/2512.07883", "authors": ["Anupama Ghorai", "Jitraj Saha"], "title": "On the discrete to continuous condensing aggregation equation: A weak convergence approach", "categories": ["math.AP", "math.FA", "math.NA"], "comment": null, "summary": "In this article, we study the passage of limits from discrete to continuous condensing aggregation equation which comprises of Oort-Hulst-Safronov (OHS) equation together with inverse aggregation process. We establish the relation between discrete and continuous condensing aggregation equations in its most generalized form, where kinetic-kernels with respect to OHS and inverse aggregation equations are not always equal. Convergence criterion is proved under suitable a priori estimates by approximating the continuous equation through a sequence of discrete equations, which subsequently converges towards the solution of the continuous equation by weak compactness principles. Existence of solution to the discrete model and uniform bounds on different order moments over finite time under particular conditions on kinetic-kernels are investigated. We analyze long-time dynamics and blowup of the solution leading to mass-loss or gelation for specific kernels. Three numerical experiments show the accuracy and convergence of approximated solutions to the exact solution of the continuous equation when $\\varepsilon$ approaches zero.", "AI": {"tldr": "This paper establishes convergence from discrete to continuous condensing aggregation equations (OHS equation with inverse aggregation) with general kinetic kernels, proves existence and uniform moment bounds, analyzes long-time dynamics including blowup/gelation, and validates convergence numerically.", "motivation": "To bridge discrete and continuous models of condensing aggregation processes, particularly the Oort-Hulst-Safronov equation with inverse aggregation, allowing for general kinetic kernels that may differ between the two processes.", "method": "Approximates continuous equation via discrete equations sequence, uses weak compactness principles for convergence, establishes a priori estimates and convergence criteria, analyzes discrete solution existence and uniform moment bounds, examines long-time dynamics and blowup phenomena.", "result": "Proves convergence from discrete to continuous equations under suitable conditions, establishes existence of discrete solutions with uniform moment bounds, characterizes long-time behavior including mass-loss/gelation for specific kernels, and demonstrates numerical convergence.", "conclusion": "The discrete approximation approach successfully connects discrete and continuous condensing aggregation models, providing rigorous convergence results and insights into long-term behavior including gelation phenomena, with numerical validation."}}
{"id": "2512.08353", "pdf": "https://arxiv.org/pdf/2512.08353", "abs": "https://arxiv.org/abs/2512.08353", "authors": ["Ruo Li", "Haoyang Liu", "Jun Yin"], "title": "A reconstructed discontinuous approximation for distributed elliptic control problems", "categories": ["math.NA", "math.OC"], "comment": "21 pages, 26 figures", "summary": "In this paper, we present and analyze an internal penalty discontinuous Galerkin method for the distributed elliptic optimal control problems. It is based on a reconstructed discontinuous approximation which admits arbitrarily high-order approximation space with only one unknown per element. Applying this method, we develop a proper discretization scheme that approximates the state and adjoint variables in the approximation space. Our main contributions are twofold: (1) the derivation of both a priori and a posteriori error estimates of the $L^2$-norm and the energy norms, and (2) the implementation of an efficiently solvable discrete system, which is solved via a linearly convergent projected gradient descent method. Numerical experiments are provided to verify the convergence order in a priori estimate and the efficiency of a posteriori error estimate.", "AI": {"tldr": "Internal penalty discontinuous Galerkin method for elliptic optimal control problems using reconstructed discontinuous approximation with high-order accuracy and one unknown per element.", "motivation": "To develop an efficient numerical method for distributed elliptic optimal control problems that combines high-order accuracy with computational efficiency through reduced degrees of freedom.", "method": "Reconstructed discontinuous Galerkin method with internal penalty formulation; discretizes state and adjoint variables using high-order approximation space with only one unknown per element; solves discrete system via projected gradient descent method.", "result": "Derived both a priori and a posteriori error estimates in L\u00b2-norm and energy norms; implemented efficiently solvable discrete system with linear convergence; numerical experiments verify convergence order and efficiency of error estimates.", "conclusion": "The proposed method successfully combines high-order accuracy with computational efficiency for elliptic optimal control problems, providing rigorous error analysis and efficient numerical implementation."}}
{"id": "2512.08571", "pdf": "https://arxiv.org/pdf/2512.08571", "abs": "https://arxiv.org/abs/2512.08571", "authors": ["Phani Motamarri", "Gourab Panigrahi"], "title": "Matrix-free algorithms for fast ab initio calculations on distributed CPU architectures using finite-element discretization", "categories": ["physics.comp-ph"], "comment": null, "summary": "Finite-element (FE) discretisations have emerged as a powerful real-space alternative to large-scale Kohn-Sham density functional theory (DFT) calculations, offering systematic convergence, excellent parallel scalability, while accommodating generic boundary conditions. However, the dominant computational bottleneck in FE-based DFT arises from the repeated application of the discretised sparse Hamiltonian to large blocks of trial vectors during iterations in an iterative eigensolver. Traditional sparse matrix-vector multiplications and FE cell-matrix approaches encounter memory limitations and high data-movement overheads, particularly at higher polynomial orders, typically used in DFT calculations. To overcome these challenges, this work develops matrix-free algorithms for FE-discretised DFT that substantially accelerate these products by doing on-the-fly operations that utilize structured tensor contractions over 1D basis functions and quadrature data. A unified multilevel batched data layout that handles both real and complex-valued operators is introduced to maximise cache reuse and SIMD utilisation on Frontier (AVX2), Param Pravega (AVX512) and Fugaku (SVE). We also combine terms for optimal cache reuse, even-odd decomposition to reduce FLOP, and mixed-precision intrinsics. Extensive benchmarks show that for large multivector pseudopotential DFT calculations, the matrix-free kernels deliver 1.5-4x speedups over the state-of-the-art cell-matrix approach baselines. For all-electron DFT calculations, the matrix-free operator achieves gains of up to 5.8x due to its efficient implementation and superior arithmetic intensity. When integrated with an error-tolerant Chebyshev-filtered subspace iteration eigensolver, the matrix-free formalism yields substantial reductions in end-to-end time-to-solution using FE meshes that deliver desired accuracies in ground-state properties.", "AI": {"tldr": "Matrix-free algorithms for FE-discretised DFT accelerate Hamiltonian-vector products using on-the-fly tensor contractions, achieving 1.5-5.8x speedups over traditional approaches.", "motivation": "FE discretisations are powerful for DFT but face computational bottlenecks from repeated Hamiltonian-vector products in iterative eigensolvers. Traditional sparse matrix approaches suffer from memory limitations and high data-movement overheads, especially at higher polynomial orders.", "method": "Develop matrix-free algorithms using on-the-fly structured tensor contractions over 1D basis functions and quadrature data. Introduce unified multilevel batched data layout for real/complex operators, combine terms for cache reuse, use even-odd decomposition to reduce FLOP, and implement mixed-precision intrinsics optimized for various architectures (AVX2, AVX512, SVE).", "result": "Matrix-free kernels deliver 1.5-4x speedups for multivector pseudopotential DFT calculations and up to 5.8x speedups for all-electron DFT calculations over state-of-the-art cell-matrix baselines. When integrated with Chebyshev-filtered subspace iteration eigensolver, substantial reductions in end-to-end time-to-solution are achieved.", "conclusion": "Matrix-free algorithms overcome computational bottlenecks in FE-based DFT by reducing memory requirements and data movement while improving arithmetic intensity, enabling faster large-scale DFT calculations with desired accuracy."}}
{"id": "2512.07914", "pdf": "https://arxiv.org/pdf/2512.07914", "abs": "https://arxiv.org/abs/2512.07914", "authors": ["D. K. Durdiev", "H. H. Turdiev"], "title": "Inverse coefficient problem for a fully fractional diffusion equation with nonlinear and source nonlocal initial condition", "categories": ["math.AP"], "comment": null, "summary": "In this work, we consider an inverse problem of determining a time dependent coefficient in a fully fractional diffusion equation with a nonlinear source term. The nonlocal initial-boundary value problem refers to the forward model: the fractional diffusion equation equipped with a nonlocal initial condition and homogeneous Dirichlet boundary conditions. We first establish the existence and uniqueness of the mild solution to this nonlocal initial boundary value problem, together with the corresponding regularity properties of the solution. These results are obtained via the Fourier method, tools from fractional calculus, and key properties of the Mittag-Leffler function.\n  Subsequently, by applying a fixed-point argument in suitable Sobolev spaces, we prove a theorem on the local existence and uniqueness of the solution to the inverse problem. In this way, we establish the well-posedness of the problem solution.", "AI": {"tldr": "This paper studies an inverse problem to determine a time-dependent coefficient in a fully fractional diffusion equation with nonlinear source term, establishing well-posedness for both forward and inverse problems.", "motivation": "The motivation is to analyze inverse coefficient determination problems for fractional diffusion equations with nonlinearities, which have applications in modeling anomalous diffusion processes in physics, biology, and engineering where standard diffusion models fail.", "method": "The authors use Fourier method, fractional calculus tools, and properties of Mittag-Leffler functions to analyze the forward problem. For the inverse problem, they apply fixed-point arguments in suitable Sobolev spaces to prove local existence and uniqueness.", "result": "The paper establishes existence and uniqueness of mild solutions for the forward nonlocal initial-boundary value problem with regularity properties. For the inverse problem, it proves local existence and uniqueness of solutions, establishing well-posedness.", "conclusion": "The work successfully demonstrates well-posedness for both forward and inverse problems in fully fractional diffusion equations with nonlinear source terms, providing rigorous mathematical foundations for coefficient determination in fractional diffusion models."}}
{"id": "2512.08364", "pdf": "https://arxiv.org/pdf/2512.08364", "abs": "https://arxiv.org/abs/2512.08364", "authors": ["Erich Novak", "Friedrich Pillichshammer"], "title": "Generalized Discrepancy of Random Points", "categories": ["math.NA", "math.NT", "math.PR"], "comment": null, "summary": "We study the $L_p$-discrepancy of random point sets in high dimensions, with emphasis on small values of $p$. Although the classical $L_p$-discrepancy suffers from the curse of dimensionality for all $p \\in (1,\\infty)$, the gap between known upper and lower bounds remains substantial, in particular for small $p \\ge 1$. To clarify this picture, we review the existing results for i.i.d.\\ uniformly distributed points and derive new upper bounds for \\emph{generalized} $L_p$-discrepancies, obtained by allowing non-uniform sampling densities and corresponding non-negative quadrature weights.\n  Using the probabilistic method, we show that random points drawn from optimally chosen product densities lead to significantly improved upper bounds. For $p=2$ these bounds are explicit and optimal; for general $p \\in [1,\\infty)$ we obtain sharp asymptotic estimates. The improvement can be interpreted as a form of importance sampling for the underlying Sobolev space $F_{d,q}$.\n  Our results also reveal that, even with optimal densities, the curse of dimensionality persists for random points when $p\\ge 1$, and it becomes most pronounced for small $p$. This suggests that the curse should also hold for the classical $L_1$-discrepancy for deterministic point sets.", "AI": {"tldr": "The paper studies L_p-discrepancy of random point sets in high dimensions, focusing on small p values. It shows that using optimally chosen product densities for random sampling improves upper bounds, but the curse of dimensionality persists for p\u22651, especially for small p.", "motivation": "To clarify the gap between known upper and lower bounds for L_p-discrepancy in high dimensions, particularly for small p\u22651, and to understand whether the curse of dimensionality can be mitigated through optimized sampling strategies.", "method": "Using the probabilistic method with random points drawn from optimally chosen product densities (non-uniform sampling densities with corresponding non-negative quadrature weights). This approach is interpreted as a form of importance sampling for the underlying Sobolev space F_{d,q}.", "result": "For p=2, explicit and optimal bounds are obtained. For general p\u2208[1,\u221e), sharp asymptotic estimates are derived. The results show significant improvement over i.i.d. uniformly distributed points, but the curse of dimensionality persists for p\u22651, becoming most pronounced for small p.", "conclusion": "Even with optimally chosen sampling densities, the curse of dimensionality cannot be avoided for random points when p\u22651, and this suggests the curse should also hold for classical L_1-discrepancy for deterministic point sets."}}
{"id": "2512.08174", "pdf": "https://arxiv.org/pdf/2512.08174", "abs": "https://arxiv.org/abs/2512.08174", "authors": ["Qingyi Zhou", "Wenxin Wu", "Maryam Zahedian", "Zongfu Yu", "Jennifer T. Choy"], "title": "Efficient simulation framework for modeling collective emission in ensembles of inhomogeneous solid-state emitters", "categories": ["physics.optics", "physics.app-ph", "physics.comp-ph"], "comment": "17 pages, 5 figures", "summary": "An efficient simulation framework is proposed to model collective emission in disordered ensembles of quantum emitters. Using a cumulant expansion approach, the computational complexity scales polynomially as opposed to exponentially with the number of emitters, enabling Monte Carlo sampling over a large number of realizations. The framework is applied to model negatively charged silicon-vacancy (SiV$^{-}$) centers inside diamond. Incorporating spatial disorder and inhomogeneous broadening, we obtain statistically averaged responses over hundreds of SiV$^{-}$ clusters. These simulations reveal two signatures of collective behavior. First, dynamics of fully inverted clusters show that superradiant emission occurs only with sufficiently large emitter number and high quantum efficiency. Unlike ideal Dicke superradiance, the burst is substantially suppressed by strong near-field dipole-dipole interaction, consistent with existing theoretical predictions. Second, under continuous-wave excitation we compute photoluminescence-excitation spectra, which exhibit interaction-induced broadening in the distribution of resonance peaks. The corresponding density of states also displays a non-zero skewness. Overall, by incorporating realistic inhomogeneities in emitter clusters, our framework is able to predict statistics for disordered ensembles that can be compared to experiments directly. Our approach generalizes to other types of emitters, including atoms, molecules, and quantum dots, thus providing a practical tool for analyzing collective behavior in realistic quantum systems.", "AI": {"tldr": "A computational framework using cumulant expansion enables efficient simulation of collective emission in disordered quantum emitter ensembles, applied to SiV\u207b centers in diamond to study superradiance and interaction effects.", "motivation": "To develop an efficient simulation method for studying collective quantum behavior in realistic disordered ensembles of emitters, overcoming the exponential computational complexity of traditional approaches.", "method": "Cumulant expansion approach that scales polynomially with emitter number, enabling Monte Carlo sampling over many realizations. Applied to SiV\u207b centers in diamond with spatial disorder and inhomogeneous broadening.", "result": "Two key findings: 1) Superradiant emission requires large emitter numbers and high quantum efficiency, with near-field dipole-dipole interactions suppressing the burst; 2) Continuous-wave excitation shows interaction-induced broadening and non-zero skewness in density of states.", "conclusion": "The framework successfully models realistic disordered ensembles and predicts measurable statistics, generalizable to various quantum emitters for practical analysis of collective behavior in experimental systems."}}
{"id": "2512.07999", "pdf": "https://arxiv.org/pdf/2512.07999", "abs": "https://arxiv.org/abs/2512.07999", "authors": ["Espen Robstad Jakobsen", "Robin \u00d8stern Lien", "Artur Rutkowski"], "title": "On Schauder Estimates for Fractional Hamilton-Jacobi Equations", "categories": ["math.AP"], "comment": "29 pages", "summary": "We prove Schauder estimates $\\unicode{x2013}$ optimal regularity estimates in H\u00f6lder spaces $\\unicode{x2013}$ and well-posedness results for mild and classical solutions of fractional Hamilton-Jacobi equations with subcritical nonlocal diffusions in $\\mathbb{R}^d$. Due to an interplay between the regularity of the initial data and the growth of the Hamiltonian in the gradient, we focus on two canonical cases: (i) Lipschitz initial data and general Hamiltonians that are H\u00f6lder in space and merely locally Lipschitz in the gradient, and (ii) H\u00f6lder initial data and Hamiltonians that are H\u00f6lder in space and locally Lipschitz with power growth in the gradient. We compute explicit blow-up rates for $C^1$ and higher order H\u00f6lder norms as $t \\to 0$. The results include short time and long time existence for mild solutions, optimal regularity in H\u00f6lder spaces and corresponding Schauder a priori estimates, and that smooth mild solutions are classical solutions.", "AI": {"tldr": "The paper proves Schauder estimates and well-posedness results for fractional Hamilton-Jacobi equations with subcritical nonlocal diffusions, focusing on two cases based on initial data regularity and Hamiltonian growth.", "motivation": "To establish optimal regularity estimates in H\u00f6lder spaces and well-posedness for fractional Hamilton-Jacobi equations, addressing the interplay between initial data regularity and Hamiltonian growth in the gradient.", "method": "The authors prove Schauder estimates and analyze two canonical cases: (i) Lipschitz initial data with general Hamiltonians that are H\u00f6lder in space and locally Lipschitz in gradient, and (ii) H\u00f6lder initial data with Hamiltonians that are H\u00f6lder in space and locally Lipschitz with power growth in gradient. They compute explicit blow-up rates for C\u00b9 and higher order H\u00f6lder norms as t\u21920.", "result": "The paper establishes short time and long time existence for mild solutions, optimal regularity in H\u00f6lder spaces with corresponding Schauder a priori estimates, and proves that smooth mild solutions are classical solutions.", "conclusion": "The work provides comprehensive regularity theory for fractional Hamilton-Jacobi equations with subcritical nonlocal diffusions, covering both Lipschitz and H\u00f6lder initial data cases with appropriate Hamiltonian growth conditions."}}
{"id": "2512.08479", "pdf": "https://arxiv.org/pdf/2512.08479", "abs": "https://arxiv.org/abs/2512.08479", "authors": ["Emmanuel Audusse", "S\u00e9bastien Boyaval", "Virgile Dubos", "Minh-Hoang Le"], "title": "Construction and Performance of Kinetic Schemes for Linear Systems of Conservation Laws", "categories": ["math.NA"], "comment": null, "summary": "We describe a methodology to build vectorial kinetic schemes, targetting the numerical solution of linear symmetric-hyperbolic systems of conservation laws -a minimal application case for those schemes. Precisely, we fully detail the construction of kinetic schemes that satisfy a discrete equivalent to a convex extension (an additional non-trivial conservation law) of the target system -the (linear) acoustic and elastodynamics systems, specifically -. Then, we evaluate numerically the convergence of various possible kinetic schemes toward smooth solutions, in comparison with standard finite-difference and finite-volume discretizations on Cartesian meshes. Our numerical results confirm the interest of ensuring a discrete equivalent to a convex extension, and show the influence of remaining parameter variations in terms of error magnitude, both for ''first-order'' and ''second-order'' kinetic schemes\\,: the parameter choice with largest CFL number (equiv., smallest spurious diffusion in the equivalent equation analysis) has the smallest discretization error.", "AI": {"tldr": "Methodology for building vectorial kinetic schemes for linear symmetric-hyperbolic conservation laws, focusing on acoustic and elastodynamics systems with discrete convex extensions.", "motivation": "To develop kinetic schemes that preserve discrete equivalents of convex extensions (additional non-trivial conservation laws) for linear symmetric-hyperbolic systems, specifically acoustic and elastodynamics systems.", "method": "Construct vectorial kinetic schemes with discrete convex extensions, then numerically evaluate convergence toward smooth solutions compared to standard finite-difference and finite-volume discretizations on Cartesian meshes.", "result": "Numerical results confirm the importance of ensuring discrete convex extensions and show parameter variations affect error magnitude. Schemes with largest CFL numbers (smallest spurious diffusion) have smallest discretization errors for both first-order and second-order kinetic schemes.", "conclusion": "The methodology successfully builds kinetic schemes preserving convex extensions, with optimal parameter choices (largest CFL/smallest spurious diffusion) yielding best accuracy, demonstrating the value of discrete convex extension preservation."}}
{"id": "2512.08276", "pdf": "https://arxiv.org/pdf/2512.08276", "abs": "https://arxiv.org/abs/2512.08276", "authors": ["Kristoffer Simula", "Johannes Hauskrecht", "Evelin Martine Corvid Christlmaier", "Pablo Lopez-Rios", "Daniel Kats", "Denis Usvyat", "Ali Alavi"], "title": "A Transcorrelated Wave-Function Framework for Solids: An Application to Bulk and Defected Silicon", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Accurate wave-function descriptions of pristine and defected solids remain challenging due to the simultaneous presence of finite-size, basis-set, and correlation errors. While embedding techniques alleviate finite-size effects and correlated wave-function approaches systematically improve correlation, basis-set incompleteness continues to limit practical accuracy. Here we present a study of transcorrelated (TC) many-body wave-function methods on properties of solid state systems. We augment the existing xTC theory to periodic systems, and establish an unified transcorrelated embedding framework that integrates periodic TC theory with fragment-based correlated solvers. Using silicon as a test case, we validate the method against coupled-cluster, FCIQMC, and diffusion Monte Carlo benchmarks for bulk. Then we apply TC embedding to calculation of formation energies of two silicon self-interstitials. The TC Hamiltonian yields rapid basis convergence and quantitatively reliable defect formation energies at the triple-$\u03b6$ level, substantially reducing the basis-set bottleneck for wave-function treatments of crystalline defects.", "AI": {"tldr": "Transcorrelated wave-function methods extended to periodic systems for accurate solid-state calculations, validated on silicon bulk properties and applied to defect formation energies with improved basis convergence.", "motivation": "Wave-function descriptions of solids face challenges from finite-size, basis-set, and correlation errors. While embedding helps with finite-size effects and correlated methods address correlation, basis-set incompleteness remains a major limitation for practical accuracy in solid-state calculations.", "method": "Extended transcorrelated (TC) theory to periodic systems and established a unified transcorrelated embedding framework that integrates periodic TC theory with fragment-based correlated solvers. Applied this to silicon bulk properties and silicon self-interstitials defect formation energies.", "result": "Validated method against coupled-cluster, FCIQMC, and diffusion Monte Carlo benchmarks for bulk silicon. TC Hamiltonian yields rapid basis convergence and quantitatively reliable defect formation energies at the triple-\u03b6 level, substantially reducing basis-set bottleneck.", "conclusion": "Transcorrelated embedding framework successfully addresses basis-set limitations for wave-function treatments of crystalline defects, enabling accurate calculations with smaller basis sets and reducing computational cost for solid-state defect studies."}}
{"id": "2512.08030", "pdf": "https://arxiv.org/pdf/2512.08030", "abs": "https://arxiv.org/abs/2512.08030", "authors": ["Alberto Enciso", "Josef Greilhuber"], "title": "Non-density of nodal lines in the clamped plate problem", "categories": ["math.AP", "math.SP"], "comment": "31 pages", "summary": "We show that, in contrast to the case of Laplace eigenfunctions, the nodal set of high energy eigenfunctions of the clamped plate problem is not necessarily dense, and can in fact exhibit macroscopic \"nodal voids\". Specifically, we show that there are small deformations of the unit disk admitting a clamped plate eigenfunction of arbitrarily high frequency that does not vanish in a disk of radius 0.44.", "AI": {"tldr": "High energy clamped plate eigenfunctions can have macroscopic nodal voids, unlike Laplace eigenfunctions where nodal sets are dense.", "motivation": "To investigate whether clamped plate eigenfunctions behave like Laplace eigenfunctions regarding nodal set density, specifically whether they can have large regions without zeros.", "method": "Construct small deformations of the unit disk that admit high-frequency clamped plate eigenfunctions with nodal voids, demonstrating existence through specific geometric perturbations.", "result": "Found deformations of the unit disk where clamped plate eigenfunctions of arbitrarily high frequency do not vanish in a disk of radius 0.44, showing macroscopic nodal voids.", "conclusion": "Clamped plate eigenfunctions fundamentally differ from Laplace eigenfunctions - their nodal sets are not necessarily dense and can exhibit large void regions, contrasting with known results for Laplace operators."}}
{"id": "2512.08555", "pdf": "https://arxiv.org/pdf/2512.08555", "abs": "https://arxiv.org/abs/2512.08555", "authors": ["Gilles Poncelet", "Jonathan Lambrechts", "Thomas Gillis", "Philippe Chatelain"], "title": "A scalable high-order multigrid-FFT Poisson solver for unbounded domains on adaptive multiresolution grids", "categories": ["math.NA", "cs.DC"], "comment": "Submitted to SIAM Journal on Scientific Computing", "summary": "Multigrid solvers are among the most efficient methods for solving the Poisson equation, which is ubiquitous in computational physics. For example, in the context of incompressible flows, it is typically the costliest operation. The present document expounds upon the implementation of a flexible multigrid solver that is capable of handling any type of boundary conditions within murphy, a multiresolution framework for solving partial differential equations (PDEs) on collocated adaptive grids. The utilization of a Fourier-based direct solver facilitates the attainment of flexibility and enhanced performance by accommodating any combination of unbounded and semi-unbounded boundary conditions. The employment of high-order compact stencils contributes to the reduction of communication demands while concurrently enhancing the accuracy of the system. The resulting solver is validated against analytical solutions for periodic and unbounded domains. In conclusion, the solver has been demonstrated to demonstrate scalability to 16,384 cores within the context of leading European high-performance computing infrastructures.", "AI": {"tldr": "Implementation of a flexible multigrid Poisson solver in murphy framework with Fourier-based direct solver for arbitrary boundary conditions, high-order compact stencils, and scalability to 16,384 cores.", "motivation": "Multigrid solvers are highly efficient for solving the Poisson equation, which is computationally expensive in applications like incompressible flows. There's a need for flexible solvers that can handle any type of boundary conditions within adaptive grid frameworks.", "method": "Implemented a flexible multigrid solver within the murphy multiresolution framework using collocated adaptive grids. Key features include: Fourier-based direct solver for handling any combination of unbounded and semi-unbounded boundary conditions, high-order compact stencils to reduce communication demands and improve accuracy.", "result": "The solver was validated against analytical solutions for periodic and unbounded domains. Demonstrated excellent scalability up to 16,384 cores on leading European high-performance computing infrastructures.", "conclusion": "The developed flexible multigrid Poisson solver successfully combines Fourier-based direct solving capabilities with high-order compact stencils, achieving both flexibility in boundary condition handling and excellent scalability on modern HPC systems."}}
{"id": "2512.08407", "pdf": "https://arxiv.org/pdf/2512.08407", "abs": "https://arxiv.org/abs/2512.08407", "authors": ["Sergii V. Siryk", "Walter Rocchia"], "title": "Many interacting particles in solution. I. Screening-ranged expansions of electrostatic potential and energy", "categories": ["cond-mat.soft", "math-ph", "physics.bio-ph", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "We present an analytical many-body formalism for systems of spherical particles carrying arbitrary free charge distributions and interacting in a polarizable electrolyte solution, that we model within the linearized Poisson--Boltzmann framework. Building on the detailed spectral analysis of the associated nonstandard Neumann--Poincar\u00e9-type operators developed in our companion study~\\cite{supplem_pre_math}, we construct exact explicit expansions of the electrostatic potential and energy in ascending orders of Debye screening thereby obtaining systematic \"screening-ranged\" series for potentials and energies. These screening-ranged expansions provide a unified and tractable description of many-body electrostatics. We demonstrate the versatility of the approach by showing how it generalizes and improves upon both classical and modern methods, enabling rigorous treatment of heterogeneously charged systems (such as Janus particles) and accurate modeling of higher-order phenomena (such as asymmetric dielectric screening, opposite-charge repulsion, like-charge attraction) as well as yielding many-body generalizations to analytical explicit results previously known only in the two-body setting.", "AI": {"tldr": "Analytical many-body formalism for spherical particles with arbitrary charge distributions in electrolyte solutions, providing exact screening-ranged expansions for electrostatic potentials and energies.", "motivation": "To develop a unified analytical framework for many-body electrostatic interactions in polarizable electrolyte solutions that can handle complex charge distributions and go beyond classical approximations.", "method": "Builds on spectral analysis of nonstandard Neumann-Poincar\u00e9-type operators, constructs exact explicit expansions of electrostatic potential and energy in ascending orders of Debye screening, yielding systematic \"screening-ranged\" series.", "result": "Developed a versatile approach that generalizes and improves upon classical and modern methods, enabling rigorous treatment of heterogeneously charged systems (Janus particles) and accurate modeling of higher-order phenomena like asymmetric dielectric screening and like-charge attraction.", "conclusion": "The screening-ranged expansions provide a unified and tractable description of many-body electrostatics, yielding many-body generalizations to analytical results previously known only in two-body settings."}}
{"id": "2512.08039", "pdf": "https://arxiv.org/pdf/2512.08039", "abs": "https://arxiv.org/abs/2512.08039", "authors": ["Piotr B. Mucha", "Tomasz Piasecki", "Yoshihiro Shibata"], "title": "Free Boundary Problem for inhomogeneous Navier-Stokes equations", "categories": ["math.AP"], "comment": null, "summary": "We study free boundary problems for incompressible inhomogeneous flows governed by the Navier--Stokes equations, focusing on the regularity and global-in-time well-posedness of solutions in critical functional frameworks for small initial data.\n  We introduce a novel analytical framework for free boundary problems formulated as perturbations of the half-space. Our approach relies on the natural Lagrangian change of coordinates and a detailed analysis of the linearized problem (the Stokes system) in the maximal regularity regime, formulated in the Lebesgue spaces $L_p(0,T; L_q)$, including time-weighted variants. The main difficulty lies in the treatment of boundary terms, for which we apply a new technique based on complex interpolation to control nonlinear terms in fractional Sobolev spaces. This strategy also allows us to handle the case of variable density, which is not easily addressed by approaches based on Besov spaces.\n  Using this framework and real interpolation techniques, we construct also solutions in the Lorentz class $L_{p,1}(0,T; L_q)$ in time. The method further enables a rigorous study of the stability of equilibrium configurations. In particular, we resolve the problem in two spatial dimensions, where the interplay between geometry and regularity is especially subtle. Beyond these specific applications, the proposed approach provides a powerful tool for broader classes of nonlinear PDEs and further developments in maximal regularity theory.", "AI": {"tldr": "The paper develops a novel analytical framework for free boundary problems of incompressible inhomogeneous Navier-Stokes equations, establishing regularity and global well-posedness for small data in critical functional spaces.", "motivation": "To address the challenging problem of free boundary flows with variable density, particularly focusing on regularity, global-in-time well-posedness for small data, and stability of equilibrium configurations in critical functional frameworks.", "method": "Introduces a novel analytical framework using Lagrangian coordinates, detailed analysis of linearized Stokes system in maximal regularity regime (L_p(0,T; L_q) spaces), complex interpolation for boundary terms, and real interpolation for Lorentz class solutions.", "result": "Establishes regularity and global-in-time well-posedness for small initial data, resolves the 2D case where geometry-regularity interplay is subtle, enables stability analysis of equilibrium configurations, and provides solutions in Lorentz class L_{p,1}(0,T; L_q).", "conclusion": "The proposed framework successfully handles free boundary problems with variable density, overcomes limitations of Besov space approaches, and provides a powerful tool for broader classes of nonlinear PDEs and maximal regularity theory."}}
{"id": "2512.08597", "pdf": "https://arxiv.org/pdf/2512.08597", "abs": "https://arxiv.org/abs/2512.08597", "authors": ["Hao Dong", "Liqun Cao"], "title": "A fourth-order multi-scale computational method and its convergence analysis for composite Kirchhoff plates with microscopic periodic configurations", "categories": ["math.NA"], "comment": null, "summary": "The Kirchhoff plate model plays a vital role in modeling, computing and analyzing the mechanical behaviors of thin plate structures. This study propose a novel fourth-order multi-scale (FOMS) computational method for high-accuracy and efficient simulation of composite Kirchhoff plates with highly periodic heterogeneities. At first, two-scale asymptotic expansion theory is employed to establish the high-accuracy fourth-order multi-scale computation model with novel fourth-order correctors for composite Kirchhoff plates, which are governed by fourth-order partial differential equation (PDE) with periodically oscillatory and highly discontinuous coefficients. Then, the locally point-wise error analysis is derived to theoretically illustrate the local balance preserving of fourth-order multi-scale model enabling high-accuracy multi-scale computation. Furthermore, a global error estimation with an explicit order for fourth-order multi-scale solutions is first demonstrated under appropriate assumptions. In contrast to the second- and third-order multi-scale solutions, only the fourth-order one is capable of providing an explicit error order estimate. Additionally, an efficient numerical algorithm is developed to conduct high-accuracy simulation for heterogeneous plate structures. Extensive numerical examples are provided to confirm the theoretical results for the computational convergence and accuracy of the proposed method. This work offers a higher-order (fourth-order) multi-scale computational framework that enables robust simulation and high-accuracy analysis to composite Kirchhoff plates.", "AI": {"tldr": "A novel fourth-order multi-scale computational method for high-accuracy simulation of composite Kirchhoff plates with periodic heterogeneities, featuring theoretical error analysis and numerical validation.", "motivation": "The Kirchhoff plate model is essential for analyzing thin plate structures, but existing methods lack high-accuracy simulation capabilities for composite plates with highly periodic heterogeneities. There's a need for more accurate multi-scale computational methods.", "method": "Uses two-scale asymptotic expansion theory to establish a fourth-order multi-scale computation model with novel fourth-order correctors. Develops theoretical error analysis including locally point-wise error analysis and global error estimation with explicit order. Creates an efficient numerical algorithm for heterogeneous plate structures.", "result": "The proposed fourth-order multi-scale method provides explicit error order estimates (unlike second- and third-order methods). Extensive numerical examples confirm computational convergence and accuracy. The method enables robust simulation and high-accuracy analysis of composite Kirchhoff plates.", "conclusion": "This work presents a higher-order (fourth-order) multi-scale computational framework that offers superior accuracy and theoretical guarantees for simulating composite Kirchhoff plates with periodic heterogeneities, addressing limitations of lower-order methods."}}
{"id": "2512.08614", "pdf": "https://arxiv.org/pdf/2512.08614", "abs": "https://arxiv.org/abs/2512.08614", "authors": ["Oscar K. C. Jackson", "Simone De Liberato", "Otto L. Muskens", "Peter R. Wiecha"], "title": "PyMieDiff: A differentiable Mie scattering library", "categories": ["physics.optics", "physics.comp-ph"], "comment": "12 pages, 6 figures", "summary": "Light scattering by spherical-shaped particles of sizes comparable to the wavelength is foundational in many areas of science, from chemistry to atmospheric science, photonics and nanotechnology. With the new capabilities offered by machine learning, there is a great interest in end-to-end differentiable frameworks for scattering calculations. Here we introduce PyMieDiff, a fully differentiable, GPU-compatible implementation of Mie scattering for core-shell particles in PyTorch. The library provides native, autograd-compatible spherical Bessel and Hankel functions, vectorized evaluation of Mie coefficients, and APIs for computing efficiencies, angular scattering, and near-fields. All inputs - geometry, material dispersion, wavelengths, and observation angles and positions - are represented as tensors, enabling seamless integration with gradient-based optimisation or physics-informed neural networks. The toolkit can also be combined with \"TorchGDM\" for end-to-end differentiable multi-particle scattering simulations. PyMieDiff is available under an open source licence at https://github.com/UoS-Integrated-Nanophotonics-group/MieDiff.", "AI": {"tldr": "PyMieDiff is a fully differentiable, GPU-compatible PyTorch implementation of Mie scattering for core-shell particles, enabling gradient-based optimization and integration with physics-informed neural networks.", "motivation": "There is growing interest in end-to-end differentiable frameworks for scattering calculations to leverage machine learning capabilities, particularly for applications in chemistry, atmospheric science, photonics, and nanotechnology where Mie scattering is fundamental.", "method": "Developed a PyTorch-based library with native autograd-compatible spherical Bessel and Hankel functions, vectorized evaluation of Mie coefficients, and tensor representations for all inputs (geometry, material dispersion, wavelengths, observation parameters).", "result": "Created PyMieDiff - a fully differentiable, GPU-compatible toolkit that can compute efficiencies, angular scattering, and near-fields for core-shell particles, with seamless integration for gradient-based optimization and compatibility with TorchGDM for multi-particle simulations.", "conclusion": "PyMieDiff provides an open-source, differentiable framework for Mie scattering calculations that bridges traditional scattering theory with modern machine learning approaches, enabling new possibilities for optimization and inverse design in nanophotonics and related fields."}}
{"id": "2512.08196", "pdf": "https://arxiv.org/pdf/2512.08196", "abs": "https://arxiv.org/abs/2512.08196", "authors": ["Jo\u00e3o Vitor da Silva", "Feida Jiang", "Jiangwen Wang"], "title": "Regularity for fully nonlinear degenerate parabolic equations with strong absorption", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we investigate dead-core problems for fully nonlinear degenerate parabolic equations with strong absorption, \\begin{equation*}\n  |Du|^{p} F(D^{2}u) - u_{t} = \u03bb_{0}(x,t)\\, u^\u03bc\\, \u03c7_{\\{u>0\\}}(x,t)\n  \\qquad \\text{in } \\quad Q_{T} := Q \\times (0,T), \\end{equation*} where $0 \\leq p < \\infty$ and $0 < \u03bc< 1$. We establish a sharp and improved parabolic $C^\u03b1$-regularity estimate along the free boundary $\\partial \\{ u > 0 \\}$, where \\[ \u03b1:= \\frac{2+p}{1+p-\u03bc} > 1 + \\frac{1}{1+p}. \\] Moreover, we establish weak geometric properties of solutions, such as non-degeneracy and uniform positive density. As an application, we obtain a Liouville-type theorem for entire solutions and gradient bounds. Finally, as a byproduct of our approach, we derive a novel $L^\u03b4$-average estimate for fully nonlinear singular elliptic equations and present a new formulation of the gradient decay property. It is worth noting that the results presented here extend those in da Silva {\\it et al.} ({\\it Pacific J. Math}., \\textbf{300} (2019), 179--213) and ({\\it J. Differential Equations}., \\textbf{264} (2018), 7270--7293) to the degenerate setting, and can be viewed as a parabolic analogue of da Silva {\\it et al.} ({\\it Math. Nachr}., \\textbf{294} (2021), 38--55) and Teixeira ({\\it Math. Ann}., \\textbf{364} (2016), 1121--1134). Additionally, of independent mathematical interest, we emphasize that our manuscript establishes a comparison principle result and the compactness of viscosity solutions to fully nonlinear degenerate parabolic models with continuous and bounded forcing terms. These compactness and comparison properties serve as key ingredients in deriving enhanced regularity estimates along free boundary points for our model problem with strong absorption.", "AI": {"tldr": "This paper establishes sharp parabolic regularity estimates and geometric properties for solutions to fully nonlinear degenerate parabolic equations with strong absorption, extending previous results to the degenerate setting.", "motivation": "To investigate dead-core problems (regions where solutions vanish) for fully nonlinear degenerate parabolic equations with strong absorption, extending previous elliptic results to the parabolic setting and establishing foundational properties for degenerate models.", "method": "The authors study viscosity solutions to fully nonlinear degenerate parabolic equations with strong absorption term, establishing comparison principles, compactness properties, and using these to derive sharp regularity estimates along free boundaries.", "result": "Proved sharp parabolic C^\u03b1-regularity estimates along free boundaries with \u03b1 > 1 + 1/(1+p), established weak geometric properties (non-degeneracy and uniform positive density), obtained Liouville-type theorems and gradient bounds, and derived novel L^\u03b4-average estimates for singular elliptic equations.", "conclusion": "The results extend previous elliptic and non-degenerate parabolic work to the degenerate parabolic setting, establishing key comparison and compactness properties that enable enhanced regularity analysis along free boundaries for strongly absorbing degenerate models."}}
{"id": "2512.08611", "pdf": "https://arxiv.org/pdf/2512.08611", "abs": "https://arxiv.org/abs/2512.08611", "authors": ["Arpit Babbar", "Hendrik Ranocha"], "title": "Compact Runge-Kutta flux reconstruction methods for non-conservative hyperbolic equations", "categories": ["math.NA"], "comment": null, "summary": "Compact Runge-Kutta (cRK) Flux Reconstruction (FR) methods are a variant of RKFR methods for hyperbolic conservation laws with a compact stencil including only immediate neighboring finite elements. We extend cRKFR methods to handle hyperbolic equations with stiff source terms and non-conservative products. To handle stiff source terms, we use IMplicit EXplicit (IMEX) time integration schemes such that the implicitness is local to each solution point, and thus does not increase inter-element communication. Although non-conservative products do not correspond to a physical flux, we formulate the scheme using numerical fluxes at element interfaces. We use similar numerical fluxes for a lower order finite volume scheme on subcells of each element, which is then blended with the high order cRKFR scheme to obtain a robust scheme for problems with non-smooth solutions. Combined with a flux limiter at the element interfaces, the subcell based blending scheme preserves the physical admissibility of the solution, e.g., positivity of density and pressure for compressible Euler equations. The procedure thus leads to an admissibility preserving IMEX cRKFR scheme for hyperbolic equations with stiff source terms and non-conservative products. The capability of the scheme to handle stiff terms is shown through numerical tests involving Burgers' equations, reactive Euler's equations, and the ten moment problem. The non-conservative treatment is tested using variable advection equations, shear shallow water equations, the GLM-MHD, and the multi-ion MHD equations.", "AI": {"tldr": "The paper presents an admissibility-preserving IMEX compact Runge-Kutta Flux Reconstruction scheme for hyperbolic equations with stiff source terms and non-conservative products, using subcell blending and flux limiting.", "motivation": "To develop robust numerical methods for hyperbolic conservation laws with stiff source terms and non-conservative products that maintain compact stencils, handle stiffness efficiently, and preserve physical admissibility constraints like positivity.", "method": "Extends compact Runge-Kutta Flux Reconstruction (cRKFR) methods using IMEX time integration for stiff terms (implicitness local to solution points), formulates non-conservative products using numerical fluxes, blends high-order cRKFR with lower-order finite volume subcell schemes, and applies flux limiting at element interfaces.", "result": "Develops an admissibility-preserving IMEX cRKFR scheme that maintains compact stencils, handles stiffness without increasing inter-element communication, and preserves physical constraints like positivity of density and pressure for compressible Euler equations.", "conclusion": "The proposed scheme successfully handles stiff source terms and non-conservative products while preserving physical admissibility, as demonstrated through numerical tests on various hyperbolic equations including Burgers', reactive Euler's, ten moment problem, variable advection, shear shallow water, and MHD equations."}}
{"id": "2512.08618", "pdf": "https://arxiv.org/pdf/2512.08618", "abs": "https://arxiv.org/abs/2512.08618", "authors": ["Stefano Mocatti", "Giovanni Marini", "Giulio Volpato", "Pierluigi Cudazzo", "Matteo Calandra"], "title": "Nonequilibrium Photocarrier and Phonon Dynamics from First Principles: a Unified Treatment of Carrier-Carrier, Carrier-Phonon, and Phonon-Phonon Scattering", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "44 pages, 12 figures", "summary": "We develop a first-principles many-body framework to describe the dynamics of photocarriers and phonons in semiconductors following ultrafast excitation. Our approach incorporates explicit ab initio light-matter coupling and first-principles collision integrals for carrier-carrier, carrier-phonon, and phonon-phonon scattering. It also yields time-dependent quasiparticle and phonon frequency renormalizations, along with light-induced coherent atomic motion. The equations of motion are solved in a maximally localized Wannier basis, ensuring gauge-consistent scattering integrals and ultradense momentum sampling, thereby enabling direct comparison with pump-probe experiments. The method can be coupled to constrained density-functional theory to access light-induced structural phase transitions at longer times after the light pulse. We showcase the capabilities and predictive power of this framework on MoS$_2$ and h-BN monolayers. For MoS$_2$, we resolve photoinduced renormalizations of electronic and lattice properties, ultrafast carrier relaxation, hot-phonon dynamics, and displacive coherent atomic motion. Including carrier-carrier scattering is crucial to obtain realistic photocarrier equilibration times, while omitting phonon-phonon scattering leads to incorrect long-time lattice thermalization and a factor of two larger A$_{1g}$ coherent phonon damping time. For h-BN, we quantify photoinduced changes in the electronic, optical, and lattice responses in quasi-equilibrium, demonstrating a fluence-dependent enhancement of screening and melting of excitonic features.", "AI": {"tldr": "A first-principles many-body framework for simulating ultrafast photocarrier and phonon dynamics in semiconductors, enabling direct comparison with pump-probe experiments.", "motivation": "To develop a comprehensive theoretical framework that can accurately describe and predict the complex dynamics of photocarriers and phonons in semiconductors following ultrafast excitation, bridging the gap between first-principles calculations and experimental pump-probe measurements.", "method": "A first-principles many-body approach incorporating explicit ab initio light-matter coupling and collision integrals for carrier-carrier, carrier-phonon, and phonon-phonon scattering. The method solves equations of motion in a maximally localized Wannier basis for gauge consistency and ultradense momentum sampling, and can be coupled to constrained density-functional theory for longer timescale structural transitions.", "result": "The framework successfully resolves photoinduced renormalizations, ultrafast carrier relaxation, hot-phonon dynamics, and coherent atomic motion in MoS\u2082, showing that carrier-carrier scattering is crucial for realistic photocarrier equilibration, while omitting phonon-phonon scattering leads to incorrect lattice thermalization. For h-BN, it quantifies fluence-dependent screening enhancement and excitonic feature melting.", "conclusion": "The developed framework provides a powerful predictive tool for understanding ultrafast dynamics in semiconductors, enabling direct comparison with experiments and revealing the critical importance of including both carrier-carrier and phonon-phonon scattering for accurate modeling of photocarrier and lattice dynamics."}}
{"id": "2512.08346", "pdf": "https://arxiv.org/pdf/2512.08346", "abs": "https://arxiv.org/abs/2512.08346", "authors": ["Zhendong Fang", "Kunlun Qi"], "title": "Hydrodynamic limit of the Vlasov-Poisson-Fokker-Planck system in low-field regime", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we study the hydrodynamic limit of the scaled Vlasov-Poisson-Fokker-Planck (VPFP) system in the low-field regime. By employing the moment method, we formally derive the corresponding Drift-Diffusion-Poisson (DDP) system. Furthermore, we rigorously justify the pointwise convergence from the VPFP system to the DDP system through delicate high-order energy estimates based on the Macro-Micro decomposition. The main difficulty lies in controlling the nonlinear coupling between the kinetic and electrostatic fields and establishing uniform bounds with respect to the scaling parameter. These challenges are overcome by developing refined high-order energy methods that yield uniform energy estimates and ensure the global well-posedness of smooth solutions, without relying on any a priori assumptions for the limiting DDP system.", "AI": {"tldr": "The paper studies the hydrodynamic limit of the scaled Vlasov-Poisson-Fokker-Planck system in low-field regime, formally deriving and rigorously justifying convergence to the Drift-Diffusion-Poisson system.", "motivation": "To establish the rigorous connection between kinetic and hydrodynamic descriptions in plasma physics, specifically showing how the VPFP system converges to the DDP system in the low-field scaling limit.", "method": "Uses moment method for formal derivation, then employs Macro-Micro decomposition with delicate high-order energy estimates for rigorous justification. Develops refined high-order energy methods to handle nonlinear coupling and scaling parameter issues.", "result": "Successfully proves pointwise convergence from VPFP to DDP system, establishes uniform bounds with respect to scaling parameter, and obtains global well-posedness of smooth solutions without relying on a priori assumptions for the limiting system.", "conclusion": "The paper provides a complete rigorous justification of the hydrodynamic limit from kinetic VPFP to hydrodynamic DDP system in low-field regime, overcoming significant mathematical challenges through novel energy estimation techniques."}}
{"id": "2512.08728", "pdf": "https://arxiv.org/pdf/2512.08728", "abs": "https://arxiv.org/abs/2512.08728", "authors": ["Teoman Toprak", "Florian Kummer"], "title": "A Task Parallel Orthonormalization Multigrid Method For Multiphase Elliptic Problems", "categories": ["math.NA", "cs.DC"], "comment": "23 pages, 7 figures, 4 tables", "summary": "Multigrid methods have been a popular approach for solving linear systems arising from the discretization of partial differential equations (PDEs) for several decades. They are particularly effective for accelerating convergence rates with optimal complexity in terms of both time and space. K-cycle orthonormalization multigrid is a robust variant of the multigrid method that combines the efficiency of multigrid with the robustness of Krylov-type residual minimalizations for problems with strong anisotropies. However, traditional implementations of K-cycle orthonormalization multigrid often rely on bulk-synchronous parallelism, which can limit scalability on modern high-performance computing (HPC) systems. This paper presents a task-parallel variant of the K-cycle orthonormalization multigrid method that leverages asynchronous execution to improve scalability and performance on large-scale parallel systems.", "AI": {"tldr": "Task-parallel K-cycle multigrid method using asynchronous execution for improved scalability on modern HPC systems.", "motivation": "Traditional K-cycle orthonormalization multigrid implementations use bulk-synchronous parallelism, which limits scalability on modern high-performance computing systems with many cores and complex memory hierarchies.", "method": "Develops a task-parallel variant of K-cycle orthonormalization multigrid that leverages asynchronous execution, enabling better utilization of parallel resources and reducing synchronization overhead.", "result": "The proposed asynchronous task-parallel implementation achieves improved scalability and performance on large-scale parallel systems compared to traditional bulk-synchronous approaches.", "conclusion": "Asynchronous task-parallel execution is an effective approach for enhancing the scalability of K-cycle orthonormalization multigrid methods on modern HPC architectures, addressing limitations of traditional bulk-synchronous implementations."}}
{"id": "2512.08682", "pdf": "https://arxiv.org/pdf/2512.08682", "abs": "https://arxiv.org/abs/2512.08682", "authors": ["Sergii V. Siryk", "Walter Rocchia"], "title": "Many interacting particles in solution. II. Screening-ranged expansion of electrostatic forces", "categories": ["cond-mat.soft", "math-ph", "physics.bio-ph", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "We present a fully analytical integration of the Maxwell stress tensor and derive exact relations for interparticle forces in systems of multiple dielectric spheres immersed in a polarizable ionic solvent, within the framework of the linearized Poisson--Boltzmann theory. Building upon the screening-ranged (in ascending orders of Debye screening) expansions of the potentials developed and rigorously analyzed in the accompanying works \\cite{supplem_pre,supplem_pre_math,supplem_prl}, we construct exact screening-ranged many-body expansions for electrostatic forces in explicit analytical form. These results establish a rigorous foundation for evaluating screened electrostatic interactions in complex particle systems and provide direct analytical connections to, and systematic improvements upon, various earlier approximate or limited-case formulations available in the literature, both at zero and finite ionic strength.", "AI": {"tldr": "Exact analytical framework for calculating electrostatic forces between multiple dielectric spheres in ionic solvents using Maxwell stress tensor integration and screening-ranged expansions.", "motivation": "To establish rigorous analytical foundation for evaluating screened electrostatic interactions in complex particle systems, improving upon earlier approximate formulations.", "method": "Fully analytical integration of Maxwell stress tensor combined with screening-ranged expansions of potentials from Poisson-Boltzmann theory, constructing exact many-body expansions for electrostatic forces.", "result": "Derived exact relations for interparticle forces in multiple dielectric sphere systems, providing direct analytical connections to and systematic improvements over earlier approximate formulations.", "conclusion": "Established rigorous analytical framework for screened electrostatic interactions applicable to complex particle systems at both zero and finite ionic strength."}}
{"id": "2512.08380", "pdf": "https://arxiv.org/pdf/2512.08380", "abs": "https://arxiv.org/abs/2512.08380", "authors": ["Xinzhi Cai", "Hongmei Cao", "Chao-jiang Xu"], "title": "Sharp Regularizing Effect of the Cauchy Problem for the Inhomogeneous Non-Cutoff Kac Equation", "categories": ["math.AP"], "comment": "28 pages", "summary": "In this work, we study the spatially inhomogeneous Kac equation with a non-cutoff cross section in a setting close to equilibrium. We prove that the solution to the Cauchy problem exhibits a sharp Gevrey-Gelfand-Shilov smoothing effect with an optimal radius. We employ a well-chosen exponential-type Fourier multiplier to establish the smoothing effect for position and velocity variables.", "AI": {"tldr": "The paper proves a sharp Gevrey-Gelfand-Shilov smoothing effect with optimal radius for solutions to the spatially inhomogeneous Kac equation with non-cutoff cross section near equilibrium.", "motivation": "To understand the regularity properties and smoothing effects of solutions to the spatially inhomogeneous Kac equation with non-cutoff cross sections, particularly in settings close to equilibrium.", "method": "Uses a well-chosen exponential-type Fourier multiplier to establish smoothing effects for both position and velocity variables in the Cauchy problem.", "result": "Proves that solutions exhibit a sharp Gevrey-Gelfand-Shilov smoothing effect with an optimal radius, demonstrating enhanced regularity beyond analyticity.", "conclusion": "The spatially inhomogeneous Kac equation with non-cutoff cross section near equilibrium possesses strong smoothing properties characterized by Gevrey-Gelfand-Shilov regularity with optimal parameters."}}
{"id": "2512.08758", "pdf": "https://arxiv.org/pdf/2512.08758", "abs": "https://arxiv.org/abs/2512.08758", "authors": ["Martin Burger", "Samira Kabri", "Gitta Kutyniok", "Yunseok Lee", "Lukas Weigand"], "title": "Explainable Learning Based Regularization of Inverse Problems", "categories": ["math.NA"], "comment": "38 pages, 3 figures", "summary": "Machine learning techniques for the solution of inverse problems have become an attractive approach in the last decade, while their theoretical foundations are still in their infancy. In this chapter we want to pursue the study of regularization properties, robustness, convergence rates, and structure of regularizers for inverse problems obtained from different learning paradigms. For this sake we study simple architectures that are explainable in the sense that they allow for a theoretical analysis also in the infinite-dimensional limit. In particular we will advance the study of spectral architectures with new results on convergence rates highlighting the role of the smoothness in the training data set, and a study of adversarial robustness. We can show that adversarial training is actually a convergent regularization method. Moreover, we discuss extensions to frame systems and CNN-type architectures for variational regularizers, where we obtain some results on their structure by carefully designed numerical experiments.", "AI": {"tldr": "Theoretical analysis of machine learning methods for inverse problems, focusing on regularization properties, convergence rates, and adversarial robustness in explainable architectures.", "motivation": "While machine learning for inverse problems has grown popular, theoretical foundations remain underdeveloped. This chapter aims to systematically study regularization properties, robustness, convergence rates, and structure of learned regularizers across different learning paradigms.", "method": "Study of simple, explainable architectures that allow theoretical analysis in infinite-dimensional limit. Focus on spectral architectures with new convergence rate results, adversarial robustness analysis, and extensions to frame systems and CNN-type architectures for variational regularizers.", "result": "Shows that adversarial training is a convergent regularization method. Provides new convergence rate results highlighting the role of training data smoothness. Obtains structural insights into CNN-type architectures through carefully designed numerical experiments.", "conclusion": "Theoretical foundations for machine learning in inverse problems can be systematically developed through explainable architectures, with adversarial training proving to be a valid regularization approach and smoothness in training data playing a crucial role in convergence rates."}}
{"id": "2512.08684", "pdf": "https://arxiv.org/pdf/2512.08684", "abs": "https://arxiv.org/abs/2512.08684", "authors": ["Sergii V. Siryk", "Walter Rocchia"], "title": "Many interacting particles in solution. III. Spectral analysis of the associated Neumann--Poincar\u00e9-type operators", "categories": ["cond-mat.soft", "math-ph", "physics.bio-ph", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "The interaction of particles in an electrolytic medium can be calculated by solving the Poisson equation inside the solutes and the linearized Poisson--Boltzmann equation in the solvent, with suitable boundary conditions at the interfaces. Analytical approaches often expand the potentials in spherical harmonics, relating interior and exterior coefficients and eliminating some coefficients in favor of others, but a rigorous spectral analysis of the corresponding formulations is still lacking. Here, we introduce composite many-body Neumann--Poincar\u00e9-type operators and prove that they are compact with spectral radii strictly less than one. These results provide the foundation for systematic screening-ranged expansions, in powers of the Debye screening parameters, of electrostatic potentials, interaction energies, and forces, and establish the analytical framework for the accompanying works~\\cite{supplem_prl,supplem_pre,supplem_pre_force}.", "AI": {"tldr": "The paper introduces composite many-body Neumann-Poincar\u00e9 operators to rigorously analyze electrostatic interactions in electrolytes, proving their compactness and spectral properties, enabling systematic screening-range expansions.", "motivation": "Existing analytical approaches for particle interactions in electrolytes lack rigorous spectral analysis of the formulations, particularly for the boundary value problems involving Poisson and Poisson-Boltzmann equations with spherical harmonic expansions.", "method": "Introduces composite many-body Neumann-Poincar\u00e9-type operators and proves they are compact with spectral radii strictly less than one, providing foundation for systematic screening-range expansions in powers of Debye screening parameters.", "result": "Establishes rigorous mathematical framework for analyzing electrostatic interactions in electrolytes, enabling systematic expansions of potentials, interaction energies, and forces in terms of screening parameters.", "conclusion": "The developed analytical framework provides the mathematical foundation for systematic screening-range expansions and serves as the basis for accompanying works on electrostatic interactions in electrolytic media."}}
{"id": "2512.08391", "pdf": "https://arxiv.org/pdf/2512.08391", "abs": "https://arxiv.org/abs/2512.08391", "authors": ["Fessel Achhoud", "Hichem Khelifi"], "title": "A Class of Non-linear Anisotropic Elliptic problems with Unbounded Coefficients and Singular Quadratic Lower Order Terms", "categories": ["math.AP"], "comment": null, "summary": "In this work, we study the existence and regularity results of anisotropic elliptic equations with a singular lower order term that grows naturally with respect to the gradient and unbounded coefficients. We take up the following model problem \\begin{equation*} \\left\\{\\begin{array}{ll}-\\displaystyle\\sum\\limits_{j\\in J} D_{j}\\left(\\left[ 1+ u^{q}\\right]\\vert D_{j}u\\vert^{p_{j}-2} D_{j}u\\right)+\\sum\\limits_{j\\in J}\\frac{\\vert D_{j}u\\vert^{p_{j}}}{ u^\u03b8}=f& \\hbox{in}\\;\u03a9, \\\\ u>0& \\hbox{in}\\;\u03a9,\n  u =0 & \\hbox{on}\\; \\partial\u03a9, \\end{array}\n  \\right. \\end{equation*} $\u03a9$ is a bounded domain in $\\mathbb{R}^{N}$, $j\\in J=\\{1,2,\\ldots,N\\},$ $q>0$, $0< \u03b8<1$, $2\\leq p_{1}\\leq p_{2}\\leq... \\leq p_{N}$ and $f\\in L^{1}(\u03a9)$. Our study's conclusions will depend on the values of $q$ and $\u03b8$.", "AI": {"tldr": "Existence and regularity results for anisotropic elliptic equations with singular gradient-dependent lower order terms and unbounded coefficients.", "motivation": "Study anisotropic elliptic equations with singular lower order terms that grow naturally with respect to the gradient and have unbounded coefficients, which arise in various applications and present mathematical challenges.", "method": "Analyze a model anisotropic elliptic equation with singular term |D_j u|^{p_j}/u^\u03b8 and coefficient [1+u^q]|D_j u|^{p_j-2}D_j u, using techniques for anisotropic Sobolev spaces and singular PDEs.", "result": "Existence and regularity results depend on parameters q and \u03b8, with different regimes identified based on their values relative to anisotropic exponents p_j.", "conclusion": "The paper establishes existence and regularity conditions for anisotropic elliptic equations with singular gradient terms, with results parameterized by q and \u03b8, contributing to the theory of singular anisotropic PDEs."}}
{"id": "2512.08841", "pdf": "https://arxiv.org/pdf/2512.08841", "abs": "https://arxiv.org/abs/2512.08841", "authors": ["Mukthesh Mahadev", "Marc Gerritsma"], "title": "Space-time discretization for barotropic flow stemming from a multisymplectic variational formulation", "categories": ["math.NA", "physics.flu-dyn"], "comment": null, "summary": "This study proposes and analyses a novel higher-order, structure preserving discretization method for inviscid barotropic flows from a Lagrangian perspective. The method is built on a multisymplectic variational principle discretized over a full space-time domain. Flow variables are encoded on a staggered space-time mesh, leveraging the principles of mimetic spectral element discretization. Unlike standard Lagrangian methods, which are prone to mesh distortion, this framework computes fluid deformations in a fixed reference configuration and systematically maps them to the physical domain via the Piola-Kirchhoff stress. Further, the structure preserving design ensures that the discrete analogues of the fundamental conservation laws for mass, momentum, and energy are satisfied up to machine precision. The formulation also inherently handles low-Mach number flows without specialized preconditioning. Numerical experiments on expansion and compression flows confirm the accuracy, stability, and exact conservation properties of the discretization.", "AI": {"tldr": "A novel higher-order structure-preserving discretization method for inviscid barotropic flows using Lagrangian perspective, multisymplectic variational principles, and staggered space-time meshes with exact conservation properties.", "motivation": "Standard Lagrangian methods suffer from mesh distortion problems, and there's a need for structure-preserving discretizations that maintain fundamental conservation laws exactly while handling low-Mach number flows without specialized preconditioning.", "method": "Multisymplectic variational principle discretized over full space-time domain, using staggered space-time mesh with mimetic spectral element principles. Computes fluid deformations in fixed reference configuration and maps to physical domain via Piola-Kirchhoff stress.", "result": "The method satisfies discrete analogues of conservation laws for mass, momentum, and energy up to machine precision, inherently handles low-Mach number flows without specialized preconditioning, and demonstrates accuracy and stability in numerical experiments on expansion and compression flows.", "conclusion": "The proposed higher-order structure-preserving discretization successfully addresses mesh distortion issues in Lagrangian methods while maintaining exact conservation properties and handling challenging flow regimes like low-Mach number flows naturally."}}
{"id": "2512.08412", "pdf": "https://arxiv.org/pdf/2512.08412", "abs": "https://arxiv.org/abs/2512.08412", "authors": ["Juli\u00e1n L\u00f3pez-G\u00f3mez", "Juan Carlos Sampedro"], "title": "Global Leray-Schauder continuation for Fredholm operators", "categories": ["math.AP", "math.FA"], "comment": null, "summary": "This paper ascertains the global behavior of the forward and backward branches of solutions provided by the Leray-Schauder continuation theorem for orientable $\\mathcal{C}^1$ Fredholm maps, as developed by the authors in [54]. Under properness on bounded sets and a nonzero local index at the given base solution, each branch satisfies the following alternative: either it is unbounded, or it reaches the boundary of the domain, or it accumulates at a different solution on the base parameter level. When the component is bounded and stays in the interior, there is a degree balance on the base slice entailing a vanishing sum of local indices and, in particular, the existence of an even number of non-degenerate contact points. For real-analytic maps we construct locally injective parameterizations that exhibit blow-up, approach to the boundary, or return to the base level. An application to a quasilinear boundary value problem driven by the mean-curvature and Minkowski operators illustrates the global results.", "AI": {"tldr": "This paper analyzes the global behavior of solution branches for orientable Fredholm maps, showing they must be unbounded, reach domain boundaries, or accumulate at other solutions, with applications to quasilinear boundary value problems.", "motivation": "The motivation is to understand the global structure of solution branches obtained from Leray-Schauder continuation theorem for orientable Fredholm maps, particularly their asymptotic behavior and topological properties.", "method": "The method uses topological degree theory and properness conditions on bounded sets to analyze solution branches. For real-analytic maps, the authors construct locally injective parameterizations to study blow-up, boundary approach, and return to base level behavior.", "result": "The main results show that solution branches satisfy a trichotomy: they are either unbounded, reach the domain boundary, or accumulate at different solutions on the base parameter level. For bounded components in the interior, there is a degree balance resulting in an even number of non-degenerate contact points.", "conclusion": "The paper provides a complete characterization of global solution branch behavior for orientable Fredholm maps, with applications demonstrated through a quasilinear boundary value problem involving mean-curvature and Minkowski operators."}}
{"id": "2512.08925", "pdf": "https://arxiv.org/pdf/2512.08925", "abs": "https://arxiv.org/abs/2512.08925", "authors": ["Shi Chen", "Michael V. Klibanov", "Kevin McGoff", "Trung Truong", "Wangjiaxuan Xin", "Shuhua Yin"], "title": "Toward Practical Forecasts of Public Sentiments via Convexification for Mean Field Games: Evidence from Real World COVID-19 Discussion Data", "categories": ["math.NA"], "comment": "33 pages", "summary": "We apply a convexification-based numerical method to forecast public sentiment dynamics using Mean Field Games (MFGs). The theoretical foundation for the convexification approach, established in our prior work, guarantees global convergence to the unique solution to the MFG system. The present work demonstrates the practical potential of this framework using real-world sentiment data extracted from social media public discussion during the COVID-19 pandemic. The results show that the MFG model with appropriate parameters and convexification yields sentiment density predictions that align closely with observed data and satisfy the governing equations. While current parameter selection relies on manual calibration, our findings establish the first proof-of-concept evidence that MFG models can capture complex temporal patterns in public sentiment, laying the groundwork for future work on systematic parameter identification methods, i.e. solutions of coefficient inverse problems for the MFG system.", "AI": {"tldr": "A convexification-based MFG method is applied to forecast public sentiment dynamics using COVID-19 social media data, showing promising alignment with observed patterns.", "motivation": "To demonstrate the practical application of Mean Field Games (MFGs) for forecasting complex public sentiment dynamics using real-world social media data during the COVID-19 pandemic, building on previous theoretical convexification work.", "method": "Apply a convexification-based numerical method to MFGs for sentiment forecasting, using real-world sentiment data extracted from social media discussions during COVID-19, with manual parameter calibration.", "result": "The MFG model with appropriate parameters and convexification yields sentiment density predictions that align closely with observed data and satisfy the governing equations, providing first proof-of-concept evidence that MFG models can capture complex temporal patterns in public sentiment.", "conclusion": "While parameter selection currently relies on manual calibration, this work establishes foundational evidence for MFG models in sentiment forecasting and lays groundwork for future systematic parameter identification methods (coefficient inverse problems for MFG systems)."}}
{"id": "2512.08487", "pdf": "https://arxiv.org/pdf/2512.08487", "abs": "https://arxiv.org/abs/2512.08487", "authors": ["Amandine Boucart", "Sonia Fliss", "Laure Giovangigli"], "title": "Scattering from a random thin coating of nanoparticles: the Dirichlet case", "categories": ["math.AP"], "comment": null, "summary": "We study the time-harmonic scattering by a heterogeneous object covered with a thin layer of randomly distributed sound-soft nanoparticles. The size of the particles, their distance between each other and the layer's thickness are all of the same order but small compared to the wavelength of the incident wave. Solving the Helmholtz equation in this context can be very costly and the simulation depends on the given distribution of particles. To circumvent this, we propose, via a multi-scale asymptotic expansion of the solution, an effective model where the layer of particles is replaced by an equivalent boundary condition. The coefficients that appear in this equivalent boundary condition depend on the solutions to corrector problems of Laplace type defined on unbounded random domains. Under the assumption that the particles are distributed given a stationary and mixing random point process, we prove that those problems admit a unique solution in the proper space. We then establish quantitative error estimates for the effec tive model and present numerical simulations that illustrate our theoretical results.", "AI": {"tldr": "Effective boundary condition model for scattering by thin layer of randomly distributed nanoparticles, replacing costly direct Helmholtz simulations.", "motivation": "Direct simulation of wave scattering by heterogeneous objects with thin layers of randomly distributed nanoparticles is computationally expensive and depends on specific particle distributions. Need efficient modeling approach.", "method": "Multi-scale asymptotic expansion to derive effective boundary condition replacing nanoparticle layer. Solves corrector problems of Laplace type on unbounded random domains. Assumes stationary and mixing random point process for particle distribution.", "result": "Proves unique solutions exist for corrector problems in proper function spaces. Establishes quantitative error estimates for effective model. Presents numerical simulations validating theoretical results.", "conclusion": "Effective boundary condition model successfully replaces costly direct simulations of nanoparticle layers, with theoretical guarantees and numerical validation."}}
{"id": "2512.08562", "pdf": "https://arxiv.org/pdf/2512.08562", "abs": "https://arxiv.org/abs/2512.08562", "authors": ["Zhen Lu", "Shou-Fu Tian"], "title": "Stability of $n$-soliton solutions for the Intermediate Long Wave equation", "categories": ["math.AP"], "comment": "31 pages. Comments are welcome", "summary": "In this work, we focus on the stability of $n$-soliton solutions ($n\\in \\mathbb{N}, n\\geq 1$) to the completely integrable intermediate long wave equation (ILW), which models long internal gravity waves in a stratified fluid of finite depth. We show that the $n$-soliton solutions of the ILW equation form non-isolated constrained minimizers of a variational problem associated with a non-local elliptic equation. To establish this result, we construct a suitable Lyapunov functional and utilize the inverse scattering transform to relate the infinite sequence of conservation laws to the scattering data. Furthermore, we employ the recursion operator derived from the bi-Hamiltonian structure to optimize our analysis. Our analysis demonstrates that the $n$-soliton solutions of the ILW equation are dynamically stable in the space $H^{\\frac{n}{2}}(\\mathbb{R})$ ($n\\in \\mathbb{N}, n\\geq 1$). Additionally, we establish the orbital stability of double soliton solutions in $H^1(\\mathbb{R})$.", "AI": {"tldr": "The paper proves that n-soliton solutions of the intermediate long wave equation are dynamically stable in H^{n/2} space, with double solitons being orbitally stable in H^1.", "motivation": "To analyze the stability of n-soliton solutions in the intermediate long wave equation, which models internal gravity waves in stratified fluids of finite depth, addressing a fundamental question in nonlinear wave theory.", "method": "Constructed a Lyapunov functional, used inverse scattering transform to relate conservation laws to scattering data, employed recursion operator from bi-Hamiltonian structure, and showed solitons are constrained minimizers of a variational problem for a non-local elliptic equation.", "result": "Proved that n-soliton solutions are dynamically stable in H^{n/2}(\u211d) for n\u22651, and established orbital stability of double soliton solutions in H^1(\u211d).", "conclusion": "The n-soliton solutions of the intermediate long wave equation are stable, with the analysis providing rigorous stability results using variational methods, inverse scattering, and Hamiltonian structures."}}
{"id": "2512.08022", "pdf": "https://arxiv.org/pdf/2512.08022", "abs": "https://arxiv.org/abs/2512.08022", "authors": ["Jinyuan Chang", "Chenguang Duan", "Yuling Jiao", "Ruoxuan Li", "Jerry Zhijian Yang", "Cheng Yuan"], "title": "Provable Diffusion Posterior Sampling for Bayesian Inversion", "categories": ["stat.ML", "cs.LG", "math.NA", "math.PR", "math.ST"], "comment": null, "summary": "This paper proposes a novel diffusion-based posterior sampling method within a plug-and-play (PnP) framework. Our approach constructs a probability transport from an easy-to-sample terminal distribution to the target posterior, using a warm-start strategy to initialize the particles. To approximate the posterior score, we develop a Monte Carlo estimator in which particles are generated using Langevin dynamics, avoiding the heuristic approximations commonly used in prior work. The score governing the Langevin dynamics is learned from data, enabling the model to capture rich structural features of the underlying prior distribution. On the theoretical side, we provide non-asymptotic error bounds, showing that the method converges even for complex, multi-modal target posterior distributions. These bounds explicitly quantify the errors arising from posterior score estimation, the warm-start initialization, and the posterior sampling procedure. Our analysis further clarifies how the prior score-matching error and the condition number of the Bayesian inverse problem influence overall performance. Finally, we present numerical experiments demonstrating the effectiveness of the proposed method across a range of inverse problems.", "AI": {"tldr": "A diffusion-based posterior sampling method using PnP framework with warm-start initialization and Monte Carlo score estimation via Langevin dynamics, providing theoretical convergence guarantees for multi-modal distributions.", "motivation": "To develop an improved posterior sampling method for Bayesian inverse problems that avoids heuristic approximations in prior work, handles complex multi-modal distributions, and provides rigorous theoretical guarantees.", "method": "Proposes a diffusion-based PnP framework constructing probability transport from easy-to-sample terminal distribution to target posterior. Uses warm-start initialization and develops Monte Carlo estimator for posterior score via Langevin dynamics with learned score functions capturing prior structural features.", "result": "Provides non-asymptotic error bounds showing convergence for complex multi-modal posteriors, quantifying errors from score estimation, warm-start initialization, and sampling procedure. Numerical experiments demonstrate effectiveness across various inverse problems.", "conclusion": "The method successfully combines diffusion-based sampling with PnP framework, offering theoretical guarantees and practical effectiveness for challenging Bayesian inverse problems with complex posterior distributions."}}
{"id": "2512.08581", "pdf": "https://arxiv.org/pdf/2512.08581", "abs": "https://arxiv.org/abs/2512.08581", "authors": ["Huali Zhang"], "title": "Improved Local Well-Posedness in Sobolev Spaces for Two-Dimensional Compressible Euler Equations", "categories": ["math.AP"], "comment": "74pages. Welocme all comments!", "summary": "We establish the local existence and uniqueness of solutions to the two-dimensional compressible Euler equations with initial velocity $\\bv_0$, logarithmic density $\u03c1_0$, and specific vorticity \\(w_0\\), which satisfy $(\\bv_0, \u03c1_0, w_0, \\nabla w_0)\\in H^{\\frac74+}(\\mathbb{R}^2)\\times H^{\\frac74+}(\\mathbb{R}^2) \\times H^{\\frac32}(\\mathbb{R}^2) \\times L^{8}(\\mathbb{R}^2)$.\n  The proof applies Smith-Tataru method \\cite{ST} and the inherent wave-transport structure of the two-dimensional compressible Euler equations. The key observation is that Strichartz estimates hold when the regularity requirement for vorticity is lower than that for velocity and density, even though the gradient of vorticity appears as a source term in the velocity wave equation. Furthermore, our result presents an improvement of $\\frac{1}{4}$-order regularity compared to previous results \\cite{Z1} and \\cite{Z2}.", "AI": {"tldr": "Local existence and uniqueness of solutions to 2D compressible Euler equations with improved regularity requirements using Smith-Tataru method and wave-transport structure analysis.", "motivation": "To establish local existence and uniqueness for 2D compressible Euler equations with lower regularity requirements for vorticity compared to velocity and density, improving upon previous results.", "method": "Applies Smith-Tataru method and leverages the inherent wave-transport structure of 2D compressible Euler equations. Key insight: Strichartz estimates hold despite vorticity gradient appearing as source term in velocity wave equation.", "result": "Proves local existence and uniqueness for solutions with initial conditions: velocity and logarithmic density in H^{7/4+}, specific vorticity in H^{3/2}, and gradient of vorticity in L^8. Achieves 1/4-order regularity improvement over previous results.", "conclusion": "The paper demonstrates that Strichartz estimates remain valid with lower regularity requirements for vorticity than for velocity and density, leading to improved regularity results for 2D compressible Euler equations."}}
{"id": "2512.08444", "pdf": "https://arxiv.org/pdf/2512.08444", "abs": "https://arxiv.org/abs/2512.08444", "authors": ["Andreas Hauptmann", "Ozan \u00d6ktem"], "title": "Learned iterative networks: An operator learning perspective", "categories": ["eess.IV", "cs.LG", "math.FA", "math.NA", "math.OC"], "comment": null, "summary": "Learned image reconstruction has become a pillar in computational imaging and inverse problems. Among the most successful approaches are learned iterative networks, which are formulated by unrolling classical iterative optimisation algorithms for solving variational problems. While the underlying algorithm is usually formulated in the functional analytic setting, learned approaches are often viewed as purely discrete. In this chapter we present a unified operator view for learned iterative networks. Specifically, we formulate a learned reconstruction operator, defining how to compute, and separately the learning problem, which defines what to compute. In this setting we present common approaches and show that many approaches are closely related in their core. We review linear as well as nonlinear inverse problems in this framework and present a short numerical study to conclude.", "AI": {"tldr": "This chapter presents a unified operator framework for learned iterative reconstruction networks, connecting functional analytic foundations with discrete implementations.", "motivation": "Learned iterative reconstruction networks have become successful but are often viewed as purely discrete methods, lacking connection to their functional analytic foundations from classical variational optimization algorithms.", "method": "The authors formulate a unified operator view with two components: 1) a learned reconstruction operator (how to compute), and 2) a learning problem (what to compute). They analyze common approaches within this framework, showing their core relationships.", "result": "The framework provides a unified perspective connecting various learned iterative network approaches, demonstrating their fundamental relationships. The chapter reviews both linear and nonlinear inverse problems within this framework.", "conclusion": "The operator framework offers a principled way to understand learned iterative reconstruction networks, bridging the gap between functional analytic foundations and practical discrete implementations, with applications to both linear and nonlinear inverse problems."}}
{"id": "2512.08655", "pdf": "https://arxiv.org/pdf/2512.08655", "abs": "https://arxiv.org/abs/2512.08655", "authors": ["Giada Cianfarani Carnevale"], "title": "Global Weak Solutions for the High--Friction Quantum Navier--Stokes--Poisson Model", "categories": ["math.AP"], "comment": null, "summary": "In [1], the Authors rigorously establish the relaxation limit from the Quantum Navier Stokes Poisson (QNSP) system to the Quantum Drift Diffusion (QDD) equation, while providing only a brief outline of the global existence theory for weak solutions to QNSP in the high friction regime (see Appendix A therein). In this manuscript, we present a complete and fully self contained proof of global existence.\n  More precisely, we prove the global existence of finite energy weak solutions to the QNSP system with high friction and large initial data on the three-dimensional torus. The model describes a compressible, viscous quantum fluid with Korteweg type capillarity effects, and allows for degenerate viscosity and vacuum regions.\n  The construction proceeds in two main steps. First, it is introduced a Faedo Galerkin approximation endowed with suitable damping mechanisms, which yields smooth approximate solutions through compactness arguments. Then, it will be justify the convergence of the approximating sequence by combining a truncation of the momentum equation with DiPerna Lions commutator estimates, providing the required control over the nonlinear transport structure.", "AI": {"tldr": "This paper provides a complete, self-contained proof of global existence of finite energy weak solutions to the Quantum Navier-Stokes-Poisson system with high friction and large initial data on the 3D torus, addressing a gap in previous work.", "motivation": "Previous work [1] established the relaxation limit from QNSP to QDD but only briefly outlined the global existence theory for weak solutions to QNSP in the high friction regime. This manuscript aims to provide a complete and fully self-contained proof of global existence to fill this gap.", "method": "The construction proceeds in two main steps: 1) A Faedo-Galerkin approximation with suitable damping mechanisms yields smooth approximate solutions through compactness arguments. 2) Convergence of the approximating sequence is justified by combining a truncation of the momentum equation with DiPerna-Lions commutator estimates to control the nonlinear transport structure.", "result": "The authors prove the global existence of finite energy weak solutions to the QNSP system with high friction and large initial data on the three-dimensional torus. The model describes a compressible, viscous quantum fluid with Korteweg-type capillarity effects, allowing for degenerate viscosity and vacuum regions.", "conclusion": "This work completes the global existence theory for the Quantum Navier-Stokes-Poisson system in the high friction regime, providing a rigorous foundation for studying the relaxation limit to Quantum Drift Diffusion equations."}}
{"id": "2512.08542", "pdf": "https://arxiv.org/pdf/2512.08542", "abs": "https://arxiv.org/abs/2512.08542", "authors": ["Zhigang Jia", "Duan Wang", "Hengkai Wang", "Yajun Xie", "Meixiang Zhao", "Xiaoyu Zhao"], "title": "A Novel Wasserstein Quaternion Generative Adversarial Network for Color Image Generation", "categories": ["cs.CV", "cs.AI", "math.NA"], "comment": null, "summary": "Color image generation has a wide range of applications, but the existing generation models ignore the correlation among color channels, which may lead to chromatic aberration problems. In addition, the data distribution problem of color images has not been systematically elaborated and explained, so that there is still the lack of the theory about measuring different color images datasets. In this paper, we define a new quaternion Wasserstein distance and develop its dual theory. To deal with the quaternion linear programming problem, we derive the strong duality form with helps of quaternion convex set separation theorem and quaternion Farkas lemma. With using quaternion Wasserstein distance, we propose a novel Wasserstein quaternion generative adversarial network. Experiments demonstrate that this novel model surpasses both the (quaternion) generative adversarial networks and the Wasserstein generative adversarial network in terms of generation efficiency and image quality.", "AI": {"tldr": "Proposes a novel Wasserstein quaternion generative adversarial network using quaternion Wasserstein distance to address color channel correlation and chromatic aberration in color image generation.", "motivation": "Existing color image generation models ignore correlation among color channels, leading to chromatic aberration problems. There's also a lack of systematic theory for measuring color image datasets and their distributions.", "method": "Defines new quaternion Wasserstein distance and develops its dual theory using quaternion convex set separation theorem and quaternion Farkas lemma. Proposes Wasserstein quaternion generative adversarial network based on this distance.", "result": "The proposed model surpasses both standard (quaternion) generative adversarial networks and Wasserstein generative adversarial networks in terms of generation efficiency and image quality.", "conclusion": "The quaternion Wasserstein distance provides a theoretical foundation for color image generation, and the proposed Wasserstein quaternion GAN effectively addresses color channel correlation issues while improving generation performance."}}
{"id": "2512.08670", "pdf": "https://arxiv.org/pdf/2512.08670", "abs": "https://arxiv.org/abs/2512.08670", "authors": ["A. Colesanti", "M. Focardi", "P. Guan", "P. Salani"], "title": "A constant rank theorem for linear elliptic equations on the sphere with applications to the mixed Christoffel problem", "categories": ["math.AP", "math.MG"], "comment": null, "summary": "We study the mixed Christoffel problem for $C^{2,+}$ convex bodies providing sufficient conditions for its solution. Key to our approach is a constant rank theorem, following the approach developed in \\cite{Guan-Ma-2003} to address the Christoffel problem, in order to ensure that the solution to a related second order linear PDE on the sphere is indeed geometric, that is, it is the support functions of a $C^{2,+}$ convex body.", "AI": {"tldr": "The paper studies the mixed Christoffel problem for C\u00b2\u207a convex bodies and provides sufficient conditions for its solution using a constant rank theorem approach.", "motivation": "To solve the mixed Christoffel problem for smooth convex bodies, which generalizes the classical Christoffel problem by considering mixed curvature measures.", "method": "Uses a constant rank theorem approach developed by Guan-Ma (2003) to ensure solutions to related second-order linear PDEs on the sphere correspond to geometric support functions of convex bodies.", "result": "Provides sufficient conditions for the existence of solutions to the mixed Christoffel problem for C\u00b2\u207a convex bodies.", "conclusion": "The constant rank theorem approach successfully addresses the mixed Christoffel problem, ensuring geometric solutions correspond to actual convex bodies."}}
{"id": "2512.08685", "pdf": "https://arxiv.org/pdf/2512.08685", "abs": "https://arxiv.org/abs/2512.08685", "authors": ["Sahar Pourandi", "P. Christian van der Sande", "Igor A. Ostanin", "Thomas Weinhart"], "title": "Calibration of a DEM contact model for wet industrial granular materials", "categories": ["cond-mat.soft", "math-ph", "math.NA"], "comment": null, "summary": "This study presents and calibrates a Discrete Element Method (DEM) contact model for wet granular materials in the pendular regime. The model extends a previously calibrated dry contact formulation by incorporating liquid bridges that generate capillary adhesion between particles, while liquid migration is represented through evolving bridge volumes. Two reactor-grade polypropylene powders with different particle size distributions, bulk densities, and surface morphologies are investigated, resulting in distinct wetting behavior. A schematic framework is introduced to relate increasing liquid content to the transition from dry to wet contacts using two key parameters: the minimum liquid film volume and the maximum liquid bridge volume. These parameters are calibrated using dynamic angle of repose measurements from rotating drum experiments. The calibrated model reproduces the experimental flow behavior of both powders: full agreement is obtained for the coarser, more porous powder across all liquid contents, while for the finer, denser powder, agreement is achieved at low to moderate liquid contents. At higher liquid contents, discrepancies arise due to agglomeration effects amplified by particle scaling. These results demonstrate the effectiveness of the dynamic angle of repose as a calibration target and highlight the limitations of particle scaling for strongly cohesive wet granular systems. The proposed framework provides a practical basis for DEM-based modeling of wet powder flow in industrial processes.", "AI": {"tldr": "DEM contact model for wet granular materials calibrated using rotating drum experiments, showing good agreement for coarser powder but limitations with finer powder at high liquid contents due to agglomeration effects.", "motivation": "To develop a practical DEM-based modeling framework for wet powder flow in industrial processes by extending existing dry contact models to handle capillary adhesion and liquid migration in the pendular regime.", "method": "Extends calibrated dry DEM contact model with liquid bridges for capillary adhesion and evolving bridge volumes for liquid migration. Calibrates using two key parameters (minimum liquid film volume and maximum liquid bridge volume) through dynamic angle of repose measurements from rotating drum experiments on two different polypropylene powders.", "result": "Calibrated model reproduces experimental flow behavior: full agreement for coarser, more porous powder across all liquid contents; agreement for finer, denser powder at low to moderate liquid contents; discrepancies at higher liquid contents due to agglomeration effects amplified by particle scaling.", "conclusion": "Dynamic angle of repose is effective for calibration, but particle scaling has limitations for strongly cohesive wet granular systems. The framework provides practical basis for industrial DEM modeling of wet powder flow."}}
{"id": "2512.08726", "pdf": "https://arxiv.org/pdf/2512.08726", "abs": "https://arxiv.org/abs/2512.08726", "authors": ["Wilberclay G. Melo", "Cilon Perusato", "Thyago S. R. Santos"], "title": "Exponential blow-up of mild solutions to the fractional Boussinesq equations in the Gevrey class", "categories": ["math.AP"], "comment": "16 pages", "summary": "This work establishes conditions for the existence and uniqueness of local mild solutions to the Boussinesq equations with fractional dissipations in Sobolev-Gevrey spaces. We prove that a unique mild solution exists in an appropriate Sobolev-Gevrey class and analyze its behavior up to the maximal time of existence. In particular, we derive quantitative lower bounds describing how the norm of the solution must blow up as it approaches a finite maximal time. As a corollary, we deduce that the solution exhibits exponential growth.", "AI": {"tldr": "Existence, uniqueness, and blow-up analysis for Boussinesq equations with fractional dissipation in Sobolev-Gevrey spaces.", "motivation": "To establish rigorous mathematical foundations for the Boussinesq equations with fractional dissipation, particularly understanding solution behavior and blow-up phenomena in specialized function spaces.", "method": "Analysis in Sobolev-Gevrey spaces, proving existence/uniqueness of local mild solutions, deriving quantitative lower bounds on solution norms near maximal existence time.", "result": "Proved existence and uniqueness of local mild solutions in appropriate Sobolev-Gevrey classes, derived quantitative blow-up bounds showing how solution norms must diverge as approaching finite maximal time.", "conclusion": "Solutions exhibit exponential growth near blow-up time, providing precise mathematical characterization of solution behavior for Boussinesq equations with fractional dissipation."}}
{"id": "2512.08717", "pdf": "https://arxiv.org/pdf/2512.08717", "abs": "https://arxiv.org/abs/2512.08717", "authors": ["Oscar Romero", "N\u00e9stor Thome"], "title": "Applications of Singular Entropy to Signals and Singular Smoothness to Images", "categories": ["eess.SP", "math.NA"], "comment": "13 pages, 6 figures", "summary": "This paper explores signal and image analysis by using the Singular Value Decomposition (SVD) and its extension, the Generalized Singular Value Decomposition (GSVD). A key strength of SVD lies in its ability to separate information into orthogonal subspaces. While SVD is a well-established tool in ECG analysis, particularly for source separation, this work proposes a refined method for selecting a threshold to distinguish between maternal and fetal components more effectively. In the first part of the paper, the focus is onmedical signal analysis,where the concepts of Energy Gap Variation (EGV) and Singular Energy are introduced to isolate fetal and maternal ECG signals, improving the known ones. Furthermore, the approach is significantly enhanced by the application of GSVD, which provides additional discriminative power for more accurate signal separation. The second part introduces a novel technique called Singular Smoothness, developed for image analysis. This method incorporates Singular Entropy and the Frobenius normto evaluate information density, and is applied to the detection of natural anomalies such asmountain fractures and burned forest regions. Numerical experiments are presented to demonstrate the effectiveness of the proposed approaches.", "AI": {"tldr": "This paper proposes enhanced SVD/GSVD methods for medical signal analysis (fetal/maternal ECG separation) and introduces Singular Smoothness for image analysis of natural anomalies.", "motivation": "To improve signal and image analysis by refining SVD-based methods for better separation of biomedical signals (maternal/fetal ECG) and developing new techniques for detecting natural anomalies in images.", "method": "1) Introduces Energy Gap Variation (EGV) and Singular Energy concepts for improved threshold selection in SVD-based ECG signal separation. 2) Applies Generalized SVD (GSVD) for enhanced discriminative power. 3) Develops Singular Smoothness technique using Singular Entropy and Frobenius norm for image analysis of natural anomalies.", "result": "Numerical experiments demonstrate effectiveness of proposed approaches for separating maternal/fetal ECG signals and detecting natural anomalies like mountain fractures and burned forest regions.", "conclusion": "The refined SVD/GSVD methods and novel Singular Smoothness technique provide effective tools for biomedical signal separation and natural anomaly detection in images."}}
{"id": "2512.08816", "pdf": "https://arxiv.org/pdf/2512.08816", "abs": "https://arxiv.org/abs/2512.08816", "authors": ["Dengjun Guo", "Xiaoyutao Luo"], "title": "Norm Inflation For The Critical SQG Equation", "categories": ["math.AP"], "comment": "29 pages", "summary": "We consider the critical dissipative surface quasi-geostrophic (SQG) equation on $\\mathbb{R}^2$ or $\\mathbb{T}^2$. Despite global regularity of the equation, we show that the data-to-solution map at the critical level $H^1$ is not uniformly bounded. We construct solutions that experience $H^1$ norm inflation from smooth, compactly supported initial data with large $H^1$ norm. We also demonstrate small-data norm inflation in supercritical Sobolev spaces $W^{\u03b2,p}$ for $1<p<2$ and $1\\le\u03b2<\\tfrac{2}{p}$.", "AI": {"tldr": "The paper shows that the data-to-solution map for the critical dissipative SQG equation is not uniformly bounded in H^1, constructing solutions with H^1 norm inflation from smooth initial data.", "motivation": "To understand the stability properties of the critical dissipative SQG equation, specifically whether the data-to-solution map is uniformly bounded at the critical regularity level H^1, which has implications for well-posedness and solution behavior.", "method": "Construct explicit solutions that experience norm inflation from smooth, compactly supported initial data with large H^1 norm. Also demonstrate small-data norm inflation in supercritical Sobolev spaces W^{\u03b2,p} for specific parameter ranges.", "result": "Despite global regularity of the equation, the data-to-solution map at the critical level H^1 is not uniformly bounded. The authors successfully construct solutions with H^1 norm inflation and show small-data norm inflation in supercritical Sobolev spaces.", "conclusion": "The critical dissipative SQG equation exhibits norm inflation phenomena, indicating that the data-to-solution map lacks uniform boundedness at the critical regularity level, even though solutions remain globally regular."}}
{"id": "2512.08806", "pdf": "https://arxiv.org/pdf/2512.08806", "abs": "https://arxiv.org/abs/2512.08806", "authors": ["Daniel Freeman", "Mitchell A. Taylor"], "title": "The Cahill-Casazza-Daubechies problem on H\u00f6lder stable phase retrieval", "categories": ["math.FA", "math.NA"], "comment": "19 pages", "summary": "Phase retrieval using a frame for a finite-dimensional Hilbert space is known to always be Lipschitz stable. However, phase retrieval using a frame or a continuous frame for an infinite-dimensional Hilbert space is always unstable. In order to bridge the gap between the finite and infinite dimensional phenomena, Cahill-Casazza-Daubechies (Trans.Amer.Math.Soc. 2016) gave a construction of a family of nonlinear subsets of an infinite-dimensional Hilbert space where phase retrieval could be performed with a H\u00f6lder stability estimate. They then posed the question of whether these subsets satisfied Lipschitz stable phase retrieval. We solve this problem both by giving examples which fail Lipschitz stability and by giving examples which satisfy Lipschitz stability.", "AI": {"tldr": "The paper addresses whether phase retrieval subsets in infinite-dimensional Hilbert spaces constructed by Cahill-Casazza-Daubechies satisfy Lipschitz stability, providing both positive and negative examples.", "motivation": "Phase retrieval in finite dimensions is always Lipschitz stable, but in infinite dimensions it's always unstable. The authors want to bridge this gap by investigating whether the nonlinear subsets constructed by Cahill-Casazza-Daubechies for infinite-dimensional Hilbert spaces satisfy Lipschitz stability.", "method": "The authors analyze the phase retrieval stability properties of the nonlinear subsets constructed by Cahill-Casazza-Daubechies. They provide both counterexamples that fail Lipschitz stability and examples that satisfy Lipschitz stability.", "result": "The paper shows that some of the Cahill-Casazza-Daubechies subsets fail Lipschitz stability, while others do satisfy Lipschitz stability, thus providing a complete answer to the open question.", "conclusion": "The question of whether Cahill-Casazza-Daubechies subsets satisfy Lipschitz stable phase retrieval has a mixed answer: some do, some don't. This provides a more nuanced understanding of phase retrieval stability in infinite-dimensional spaces."}}
{"id": "2512.08840", "pdf": "https://arxiv.org/pdf/2512.08840", "abs": "https://arxiv.org/abs/2512.08840", "authors": ["Justin Holmer", "Panayotis G. Kevrekidis", "Dmitry E. Pelinovsky"], "title": "Orbital stability of kinks in the NLS equation with competing nonlinearities", "categories": ["math.AP", "nlin.PS"], "comment": "16 pages, 3 figures", "summary": "Kinks connecting zero and nonzero equilibria in the NLS equation with competing nonlinearities occur at the special values of the frequency parameter. Since they are minimizers of energy, they are expected to be orbitally stable in the time evolution of the NLS equation. However, the stability proof is complicated by the degeneracy of kinks near the nonzero equilibrium. The main purpose of this work is to give a rigorous proof of the orbital stability of kinks. We give details of analysis for the cubic--quintic NLS equation and show how the proof is extended to the general case.", "AI": {"tldr": "The paper proves orbital stability of kink solutions in NLS equations with competing nonlinearities, focusing on cubic-quintic case and extending to general cases.", "motivation": "Kinks connecting zero and nonzero equilibria in NLS equations with competing nonlinearities are energy minimizers and thus expected to be orbitally stable, but the stability proof is complicated by degeneracy near nonzero equilibrium.", "method": "Rigorous mathematical analysis for cubic-quintic NLS equation, showing how the proof extends to general cases with competing nonlinearities.", "result": "Provides complete proof of orbital stability for kink solutions, overcoming the degeneracy challenges near nonzero equilibrium.", "conclusion": "Kinks in NLS equations with competing nonlinearities are orbitally stable, with the proof methodology applicable to both cubic-quintic and general cases."}}
{"id": "2512.08917", "pdf": "https://arxiv.org/pdf/2512.08917", "abs": "https://arxiv.org/abs/2512.08917", "authors": ["Gabriele Benomio", "Rita Teixeira da Costa"], "title": "The Maxwell equations on full sub-extremal and extremal Kerr spacetimes", "categories": ["math.AP", "gr-qc", "math-ph"], "comment": "49 pages, 1 figure", "summary": "We study the Cauchy problem for the Maxwell equations in the exterior region of Kerr black hole spacetimes. The equations are formulated for components of the Maxwell field relative to the algebraically special frame of Kerr, with the unknowns treated as tensorial quantities associated with a non-integrable horizontal distribution. The extremal Maxwell components decouple into Teukolsky equations, whereas the middle Maxwell components form a coupled system of transport and elliptic equations. Assuming control over the extremal components, we prove uniform boundedness (without loss of derivatives) and decay estimates for the middle components in the full |a|<=M range of spacetime parameters. Our analysis relies on (i) deriving a decoupled system of transport and elliptic equations for two modified middle Maxwell components and (ii) decomposing general solutions into a dynamical and stationary part, the latter determined by two real (electric and magnetic) charges which are entirely read off from the initial data at the event horizon.\n  In the sub-extremal |a|<M case, works of Shlapentokh-Rothman and the second author provide the necessary control over the extremal components, yielding unconditional boundedness and decay results for all the unknowns in the equations.\n  In the extremal |a|=M case, we formulate a conjectural boundedness and decay statement for the extremal components, motivated by work of Casals, Gralla and Zimmerman on fixed azimuthal mode solutions compactly supported away from the event horizon. Our boundedness and decay results for all the unknowns in the equations remain, therefore, conditional. We show that the complicated dynamics of the extremal components at the event horizon is inherited by the middle components; in particular, we uncover novel conservation laws for the middle components of axisymmetric solutions.", "AI": {"tldr": "Analysis of Maxwell equations in Kerr black hole exteriors: extremal components satisfy Teukolsky equations, middle components form coupled system. Proves boundedness/decay for middle components given control over extremal components, with results unconditional for sub-extremal case and conditional for extremal case.", "motivation": "To understand the behavior of electromagnetic fields in the exterior region of Kerr black holes, particularly addressing the Cauchy problem for Maxwell equations in these curved spacetimes with full parameter range |a|\u2264M.", "method": "Formulates Maxwell equations using algebraically special Kerr frame, treats unknowns as tensorial quantities with non-integrable horizontal distribution. Derives decoupled transport/elliptic system for modified middle components, decomposes solutions into dynamical and stationary parts determined by electric/magnetic charges from initial data.", "result": "Proves uniform boundedness and decay estimates for middle Maxwell components assuming control over extremal components. For sub-extremal case (|a|<M), results are unconditional. For extremal case (|a|=M), results are conditional on conjectured boundedness/decay of extremal components. Uncovers novel conservation laws for axisymmetric solutions.", "conclusion": "The Maxwell equations in Kerr exteriors can be analyzed by separating extremal and middle components. Middle components exhibit boundedness and decay when extremal components are controlled, with complete results for sub-extremal black holes and conditional results for extremal ones, revealing new conservation laws for axisymmetric solutions."}}
{"id": "2512.08929", "pdf": "https://arxiv.org/pdf/2512.08929", "abs": "https://arxiv.org/abs/2512.08929", "authors": ["Guanjun Pan", "Hong-Ming Yin"], "title": "On a cross-diffusion hybrid model: Cancer Invasion Tissue with Normal Cell Involved", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we study a well-posedness problem on a new mathematical model for cancer invasion within the plasminogen activation system, which explicitly incorporates cooperation with host normal cells. Key biological mechanisms--including chemotaxis, haptotaxis, recruitment, logistic growth, and natural degradation of normal cells--along with other primary components (cancer cells, vitronectin, uPA, uPAI-1 and plasmin) are modeled via a continuum framework of cancer cell invasion of the extracellular matrix. The resulting model constitutes a strongly coupled, cross-diffusion hybrid system of differential equations. The primary mathematical challenges arise from the strongly coupled cross-diffusion terms, the parabolic operators of divergence form, and the interaction between the cross-diffusion fluxes and the ODE components. We address these by deriving several a priori estimates for dimensions d less or equal to 3. Subsequently, we employ a decoupling strategy to split the system into proper sub-problems, establishing the existence (and uniqueness) for each subsystem. Finally, we demonstrate the global existence and uniqueness of the solution for dimensions d less or equal to 2 and the global existence of a solution for dimension d = 3.", "AI": {"tldr": "This paper establishes well-posedness results for a new cancer invasion model incorporating normal cell cooperation, addressing mathematical challenges from strongly coupled cross-diffusion terms in dimensions d \u2264 3.", "motivation": "To develop and analyze a more biologically realistic mathematical model of cancer invasion that explicitly incorporates cooperation with host normal cells within the plasminogen activation system, addressing gaps in existing models.", "method": "Developed a continuum framework incorporating chemotaxis, haptotaxis, recruitment, logistic growth, and degradation mechanisms. Used a decoupling strategy to split the strongly coupled cross-diffusion hybrid system into sub-problems, derived a priori estimates for d \u2264 3, and established existence/uniqueness for each subsystem.", "result": "Proved global existence and uniqueness of solutions for dimensions d \u2264 2, and global existence (without uniqueness) for dimension d = 3, overcoming challenges from strongly coupled cross-diffusion terms and parabolic divergence-form operators.", "conclusion": "The paper successfully establishes well-posedness results for a biologically comprehensive cancer invasion model, providing mathematical foundations for studying cancer-normal cell interactions in invasion dynamics across different spatial dimensions."}}
{"id": "2512.08256", "pdf": "https://arxiv.org/pdf/2512.08256", "abs": "https://arxiv.org/abs/2512.08256", "authors": ["Deepak Gupta", "Himanshu Pandey", "Ratikanta Behera"], "title": "Wavelet-Accelerated Physics-Informed Quantum Neural Network for Multiscale Partial Differential Equations", "categories": ["cs.LG", "math.AP", "math.QA"], "comment": null, "summary": "This work proposes a wavelet-based physics-informed quantum neural network framework to efficiently address multiscale partial differential equations that involve sharp gradients, stiffness, rapid local variations, and highly oscillatory behavior. Traditional physics-informed neural networks (PINNs) have demonstrated substantial potential in solving differential equations, and their quantum counterparts, quantum-PINNs, exhibit enhanced representational capacity with fewer trainable parameters. However, both approaches face notable challenges in accurately solving multiscale features. Furthermore, their reliance on automatic differentiation for constructing loss functions introduces considerable computational overhead, resulting in longer training times. To overcome these challenges, we developed a wavelet-accelerated physics-informed quantum neural network that eliminates the need for automatic differentiation, significantly reducing computational complexity. The proposed framework incorporates the multiresolution property of wavelets within the quantum neural network architecture, thereby enhancing the network's ability to effectively capture both local and global features of multiscale problems. Numerical experiments demonstrate that our proposed method achieves superior accuracy while requiring less than five percent of the trainable parameters compared to classical wavelet-based PINNs, resulting in faster convergence. Moreover, it offers a speedup of three to five times compared to existing quantum PINNs, highlighting the potential of the proposed approach for efficiently solving challenging multiscale and oscillatory problems.", "AI": {"tldr": "A wavelet-based physics-informed quantum neural network framework that efficiently solves multiscale PDEs with sharp gradients and oscillatory behavior, eliminating automatic differentiation and reducing computational complexity.", "motivation": "Traditional PINNs and quantum-PINNs struggle with multiscale features and suffer from computational overhead due to automatic differentiation. There's a need for more efficient methods to handle challenging multiscale PDEs with sharp gradients, stiffness, and oscillatory behavior.", "method": "Developed a wavelet-accelerated physics-informed quantum neural network that incorporates wavelet multiresolution properties into quantum neural architecture. The method eliminates automatic differentiation for loss function construction, reducing computational complexity while enhancing ability to capture both local and global multiscale features.", "result": "Achieves superior accuracy with less than 5% of trainable parameters compared to classical wavelet-based PINNs, resulting in faster convergence. Offers 3-5x speedup compared to existing quantum PINNs while effectively handling multiscale and oscillatory problems.", "conclusion": "The proposed wavelet-based quantum neural network framework demonstrates significant improvements in efficiency and accuracy for solving challenging multiscale PDEs, showing potential for practical applications in complex oscillatory problems."}}
