<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 15]
- [math.AP](#math.AP) [Total: 15]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 11]
- [cs.DC](#cs.DC) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [math.DG](#math.DG) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [math.OC](#math.OC) [Total: 3]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 2]
- [cond-mat.soft](#cond-mat.soft) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 2]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [hep-ex](#hep-ex) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A posteriori error estimates for mixed-dimensional Darcy flow using non-matching grids](https://arxiv.org/abs/2512.09087)
*Jhabriel Varela,Christian E. Schaerer,Eirik Keilegavlen,Inga Berre*

Main category: math.NA

TL;DR: Extension of a posteriori error estimates for hierarchical mixed-dimensional elliptic equations to non-matching mixed-dimensional grids using transfer grids and stable projection operators.


<details>
  <summary>Details</summary>
Motivation: To extend existing error estimation methods from matching to non-matching mixed-dimensional grids, enabling more flexible grid configurations while maintaining reliability and computability of error estimates.

Method: Introduce transfer grids between planar subdomain and interface grids, along with stable discrete projection operators for both primal (potential) and dual (flux) variables to handle non-matching grid configurations.

Result: The non-matching estimators remain fully guaranteed and computable. Numerical experiments on 3D problems (incompressible Darcy flow in fractured porous media) show reliable performance with effectivity comparable to matching grid estimators.

Conclusion: Successfully extended hierarchical mixed-dimensional elliptic error estimation to non-matching grids while maintaining reliability and computational efficiency comparable to matching grid approaches.

Abstract: In this article, we extend the a posteriori error estimates for hierarchical mixed-dimensional elliptic equations developed in [Varela et al., J. Numer. Math., 48 (2023), pp. 247-280] to the setting of non-matching mixed-dimensional grids. The extension is achieved by introducing transfer grids between the planar subdomain and interface grids, together with stable discrete projection operators for primal (potential) and dual (flux) variables. The proposed non-matching estimators remain fully guaranteed and computable. Numerical experiments, including three-dimensional problems based on community benchmarks for incompressible Darcy flow in fractured porous media, demonstrate reliable performance of the estimators for the non-matching grids and effectivity that is comparable to the estimators for matching grids.

</details>


### [2] [A Taxonomy of Numerical Differentiation Methods](https://arxiv.org/abs/2512.09090)
*Pavel Komarov,Floris van Breugel,J. Nathan Kutz*

Main category: math.NA

TL;DR: A comprehensive review and practical guide to numerical differentiation methods for noisy data, with an accompanying Python package.


<details>
  <summary>Details</summary>
Motivation: Derivatives are fundamental to science and engineering but challenging to compute from noisy, potentially corrupt data. Many existing methods have limitations (e.g., requiring periodic boundary conditions) or are sensitive to noise, making it difficult for practitioners to choose appropriate methods.

Method: The paper reviews a broad range of numerical differentiation algorithms, presents contextual considerations and choice points, compares relative advantages, and provides basic theoretical foundations for each method. The authors also developed PyNumDiff, an open-source Python package implementing these methods.

Result: A comprehensive practical guide that helps scientists and engineers match differentiation methods to specific application domains, along with a software implementation that provides a suite of methods for differentiating noisy data.

Conclusion: The review provides essential guidance for selecting appropriate numerical differentiation methods for real-world applications with noisy data, and the PyNumDiff package offers practical implementation tools to facilitate this process across scientific and engineering disciplines.

Abstract: Differentiation is a cornerstone of computing and data analysis in every discipline of science and engineering. Indeed, most fundamental physics laws are expressed as relationships between derivatives in space and time. However, derivatives are rarely directly measurable and must instead be computed, often from noisy, potentially corrupt data streams. There is a rich and broad literature of computational differentiation algorithms, but many impose extra constraints to work correctly, e.g. periodic boundary conditions, or are compromised in the presence of noise and corruption. It can therefore be challenging to select the method best-suited to any particular problem. Here, we review a broad range of numerical methods for calculating derivatives, present important contextual considerations and choice points, compare relative advantages, and provide basic theory for each algorithm in order to assist users with the mathematical underpinnings. This serves as a practical guide to help scientists and engineers match methods to application domains. We also provide an open-source Python package, PyNumDiff, which contains a broad suite of methods for differentiating noisy data.

</details>


### [3] [High Order Numerical Methods Preserving Invariant Domain for Hyperbolic and Related Systems](https://arxiv.org/abs/2512.09116)
*Kailiang Wu,Xiangxiong Zhang,Chi-Wang Shu*

Main category: math.NA

TL;DR: Survey paper on invariant-domain-preserving (IDP) schemes for hyperbolic systems, covering both first-order and high-order methods with focus on polynomial limiters and flux limiting approaches.


<details>
  <summary>Details</summary>
Motivation: Hyperbolic systems have convex invariant domains that must be preserved numerically to maintain hyperbolicity and avoid illposedness and numerical instabilities. Constructing IDP schemes is crucial for physically meaningful solutions and robust computations, especially challenging for high-order methods.

Method: Comprehensive survey of IDP schemes with systematic review of first-order methods (finite difference, finite volume, finite element, residual distribution) and two main classes of high-order methods: 1) polynomial limiters for weak IDP property in high-order finite volume/discontinuous Galerkin schemes, and 2) flux limiting approaches from flux-corrected transport method applicable to finite difference and continuous finite element methods.

Result: The paper provides extensive examples and numerical experiments in gas dynamics and magnetohydrodynamics, elucidating main ideas in IDP scheme construction with new perspectives and insights.

Conclusion: IDP schemes are essential for hyperbolic systems, with two main high-order approaches (polynomial limiters and flux limiting) enabling robust computations while preserving physical invariants, representing significant developments over the past decade.

Abstract: Admissible states in hyperbolic systems and related equations often form a convex invariant domain. Numerical violations of this domain can lead to loss of hyperbolicity, resulting in illposedness and severe numerical instabilities. It is therefore crucial for numerical schemes to preserve the invariant domain to ensure both physically meaningful solutions and robust computations. For complex systems, constructing invariant-domain-preserving (IDP) schemes is highly nontrivial and particularly challenging for high-order accurate methods. This paper presents a comprehensive survey of IDP schemes for hyperbolic and related systems, with a focus on the most popular approaches for constructing provable IDP schemes. We first give a systematic review of the fundamental approaches for establishing the IDP property in first-order accurate schemes, covering finite difference, finite volume, finite element, and residual distribution methods. Then we focus on two widely used and actively developed classes of high order IDP schemes as well as their recent developments, most of which have emerged in the past decade. The first class of methods seeks an intrinsic weak IDP property in high-order schemes and then designs polynomial limiters to enforce a strong IDP property at the points of interest. This generic approach applies to high-order finite volume and discontinuousGalerkin schemes. The second class is based on the flux limiting approaches, which originated from the flux-corrected transport method and can be adapted to a broader range of spatial discretizations, including finite difference and continuous finite element methods. In this survey, we elucidate the main ideas in the construction of IDP schemes, provide some new perspectives and insights, with extensive examples, and numerical experiments in gas dynamics and magnetohydrodynamics.

</details>


### [4] [A Hybrid Neural Network-Finite Element Method for the Viscous-Plastic Sea-Ice Model](https://arxiv.org/abs/2512.09118)
*Nils Margenberg,Carolin Mehlmann*

Main category: math.NA

TL;DR: Hybrid neural network-finite element method accelerates viscous-plastic sea-ice simulations by 11x while maintaining accuracy through learned fine-scale corrections.


<details>
  <summary>Details</summary>
Motivation: The viscous-plastic sea-ice model is computationally expensive due to strong nonlinearity, especially when high resolution is needed to capture narrow deformation bands (linear kinematic features). Current solvers become prohibitively expensive under mesh refinement.

Method: Enrich coarse-mesh finite element approximations with fine-scale corrections predicted by neural networks trained on high-resolution simulations. Networks operate locally on small patches of grid elements, making them efficient and parallelizable across patches.

Result: The hybrid approach achieves qualitatively similar accuracy at approximately 11 times lower computational cost compared to high-resolution reference simulations. The learned correction also accelerates the Newton solver by up to 10% at the same mesh resolution.

Conclusion: Local neural network corrections provide an efficient way to capture fine-scale deformation features in sea-ice simulations while maintaining accuracy and computational efficiency, with good generalization to different boundary conditions and geometries.

Abstract: We present an efficient hybrid Neural Network-Finite Element Method (NN-FEM) for solving the viscous-plastic (VP) sea-ice model. The VP model is widely used in climate simulations to represent large-scale sea-ice dynamics. However, the strong nonlinearity introduced by the material law makes VP solvers computationally expensive, with the cost per degree of freedom increasing rapidly under mesh refinement. High spatial resolution is particularly required to capture narrow deformation bands known as linear kinematic features in viscous-plastic models. To improve computational efficiency in simulating such fine-scale deformation features, we propose to enrich coarse-mesh finite element approximations with fine-scale corrections predicted by neural networks trained with high-resolution simulations. The neural network operates locally on small patches of grid elements, which is efficient due to its relatively small size and parallel applicability across grid patches. An advantage of this local approach is that it generalizes well to different right-hand sides and computational domains, since the network operates on small subregions rather than learning details tied to a specific choice of boundary conditions, forcing, or geometry. The numerical examples quantify the runtime and evaluate the error for this hybrid approach with respect to the simulation of sea-ice deformations. Applying the learned network correction enables coarser-grid simulations to achieve qualitatively similar accuracy at approximately 11 times lower computational cost relative to the high-resolution reference simulations. Moreover, the learned correction accelerates the Newton solver by up to 10% compared to runs without the correction at the same mesh resolution.

</details>


### [5] [Energy-Based Modeling and Structure-Preserving Discretization of Physical Systems](https://arxiv.org/abs/2512.09138)
*M. H. M Rashid*

Main category: math.NA

TL;DR: A mathematical framework for energy-based modeling of physical systems that preserves structural properties through modeling and discretization, handling challenging system classes while maintaining physical consistency.


<details>
  <summary>Details</summary>
Motivation: To develop a comprehensive framework that preserves fundamental structural properties (like energy balance and dissipation) throughout the modeling and discretization process for physical systems, addressing challenges with high-index differential-algebraic equations and nonlinear multiphysics problems.

Method: Systematic methods for regularizing constrained systems while maintaining physical consistency, analyzing stability properties, and constructing numerical discretizations that inherit the energy dissipation structure of continuous models.

Result: The framework successfully handles challenging system classes, maintains physical consistency, and ensures essential properties like energy balance and dissipation are preserved from continuous formulation through numerical implementation.

Conclusion: The energy-based modeling framework provides robust foundations for computational physics and engineering applications by ensuring physical properties are maintained throughout the modeling and discretization process, with demonstrated versatility across multiple domains.

Abstract: This paper develops a comprehensive mathematical framework for energy-based modeling of physical systems, with particular emphasis on preserving fundamental structural properties throughout the modeling and discretization process. The approach provides systematic methods for handling challenging system classes including high-index differential-algebraic equations and nonlinear multiphysics problems. Theoretical foundations are established for regularizing constrained systems while maintaining physical consistency, analyzing stability properties, and constructing numerical discretizations that inherit the energy dissipation structure of the continuous models. The versatility and practical utility of the framework are demonstrated through applications across multiple domains including poroelastic media, nonlinear circuits, constrained mechanics, and phase-field models. The results ensure that essential physical properties such as energy balance and dissipation are maintained from the continuous formulation through to numerical implementation, providing robust foundations for computational physics and engineering applications.

</details>


### [6] [Higher-order multi-scale computational method and its convergence analysis for hygro-thermo-mechanical coupling problems of quasi-periodic composite structures](https://arxiv.org/abs/2512.09281)
*Hao Dong,Yifei Ding,Jiale Linghu,Yufeng Nie,Yaochuang Han*

Main category: math.NA

TL;DR: Proposes a higher-order multi-scale (HOMS) method for efficient, high-accuracy simulation of hygro-thermo-mechanical coupling in quasi-periodic composite structures.


<details>
  <summary>Details</summary>
Motivation: Need for efficient computational methods that can handle complex hygro-thermo-mechanical coupling problems in quasi-periodic composite structures with high accuracy and low computational cost.

Method: Develops a higher-order multi-scale asymptotic method with correction terms for H-T-M coupling, establishes rigorous error analyses (point-wise and integral), and implements a finite element-based numerical algorithm with convergence analysis.

Result: The HOMS approach demonstrates exceptional numerical accuracy and reduced computational cost compared to conventional methods, validated through extensive numerical experiments.

Conclusion: The proposed HOMS computational method provides an effective solution for simulating complex hygro-thermo-mechanical coupling in quasi-periodic composite structures with high efficiency and accuracy.

Abstract: This paper proposes a novel higher-order multi-scale (HOMS) computational method, which is highly targeted for efficient, high-accuracy and low-computational-cost simulation of hygro-thermo-mechanical (H-T-M) coupling problems in quasi-periodic composite structures. The first innovation of this work is that the establishment of the high-accuracy multi-scale model incorporating the higher-order correction terms for H-T-M coupling problems of quasi-periodic composite structures. The second innovation of this work is that the error analyses in the point-wise and integral senses are rigorously derived for multi-scale asymptotic solutions. Especially from the point-wise error analysis, the primary impetus for current study to develop the HOMS approach for quasi-periodic composite structures is illustrated. Furthermore, an high-accuracy multi-scale numerical algorithm is developed based on finite element method, while corresponding convergent analysis is also obtained. Finally, extensive numerical experiments are conducted to validate the computational performance of the proposed HOMS computational approach, demonstrating not only exceptional numerical accuracy, but also reduced computational cost.

</details>


### [7] [Fast operator learning for mapping correlations](https://arxiv.org/abs/2512.09286)
*Yuehaw Khoo,Yuguan Wang,Siyao Yang*

Main category: math.NA

TL;DR: Fast optimization-free method for learning transition operators of high-dimensional Markov processes using Galerkin projection to low-order bases, avoiding curse of dimensionality with O(dN) computational complexity.


<details>
  <summary>Details</summary>
Motivation: Need efficient methods for learning transition operators of high-dimensional Markov processes without suffering from curse of dimensionality, enabling prediction of future events and solving high-dimensional boundary value problems.

Method: Galerkin projection of transition operator to suitable low-order bases capturing correlations between dimensions; discretized operator obtained from moments corresponding to basis choice; compressed representation exploiting low-rank structure and spatial decay of correlations.

Result: Method achieves computational complexity of O(dN) where d is dimensionality and N is sample size; theoretical analysis of approximation error; numerical demonstration shows efficient prediction of future events and solving high-dimensional boundary value problems.

Conclusion: Proposed method provides simple linear algebraic approach for high-dimensional rare-events simulations, offering optimization-free learning of transition operators with manageable computational complexity despite high dimensionality.

Abstract: We propose a fast, optimization-free method for learning the transition operators of high-dimensional Markov processes. The central idea is to perform a Galerkin projection of the transition operator to a suitable set of low-order bases that capture the correlations between the dimensions. Such a discretized operator can be obtained from moments corresponding to our choice of basis without curse of dimensionality. Furthermore, by exploiting its low-rank structure and the spatial decay of correlations, we can obtain a compressed representation with computational complexity of order $\mathcal{O}(dN)$, where $d$ is the dimensionality and $N$ is the sample size. We further theoretically analyze the approximation error of the proposed compressed representation. We numerically demonstrate that the learned operator allows efficient prediction of future events and solving high-dimensional boundary value problems. This gives rise to a simple linear algebraic method for high-dimensional rare-events simulations.

</details>


### [8] [An Efficient Solver to Helmholtz Equations by Recontruction Discontinuous Approximation](https://arxiv.org/abs/2512.09338)
*Shuhai Zhao*

Main category: math.NA

TL;DR: A novel efficient solver for Helmholtz equation using a new approximation space with discontinuous Galerkin scheme and optimal preconditioner, achieving better accuracy with fewer degrees of freedom and reduced computational costs.


<details>
  <summary>Details</summary>
Motivation: To develop a more efficient solver for the Helmholtz equation that improves upon traditional discontinuous Galerkin methods by reducing computational costs while maintaining or improving accuracy.

Method: Combines a novel approximation space with a discontinuous Galerkin scheme and a linear system solver featuring a natural preconditioner. The method integrates three key ingredients: the new approximation space, the DG scheme, and the preconditioned iterative solver.

Result: The method achieves: 1) significantly lower error with same degrees of freedom, 2) sparser matrices reducing storage and solution time, 3) optimal preconditioner with respect to mesh size in absorbing case. Advantages increase with higher approximation orders.

Conclusion: The proposed method represents a more efficient approach for solving Helmholtz equations compared to traditional DG methods, offering improved accuracy, reduced computational resources, and optimal preconditioning that scales well with mesh refinement.

Abstract: In this paper, an efficient solver for the Helmholtz equation using a noval approximation space is developed. The ingradients of the method include the approximation space recently proposed, a discontinuous Galerkin scheme extensively used, and a linear system solver with a natural preconditioner. Comparing to traditional discontinuous Galerkin methods, we refer to the new method as being more efficient in the following sense. The numerical performance of the new method shows that: 1) much less error can be reached using the same degrees of freedom; 2) the sparse matrix therein has much fewer nonzero entries so that both the storage space and the solution time cost for the iterative solver are reduced; 3) the preconditioner is proved to be optimal with respect to the mesh size in the absorbing case. Such advantage becomes more pronounced as the approximation order increases.

</details>


### [9] [A higher-order three-scale computational method for efficient nonlinear thermo-mechanical coupling simulation of heterogeneous structures with multiple spatial scales](https://arxiv.org/abs/2512.09357)
*Hao Dong,Yanqi Wang,Jiale Linghu,Qiang Ma*

Main category: math.NA

TL;DR: Proposes a higher-order three-scale (HOTS) computational method for accurately and efficiently simulating transient nonlinear thermo-mechanical coupling problems in heterogeneous structures with three spatial scales, addressing temperature-dependent material properties.


<details>
  <summary>Details</summary>
Motivation: Classical two-scale methods struggle with heterogeneous structures having complicated three-scale spatial configurations. Temperature-dependent material properties significantly impact thermo-mechanical coupling responses in such structures, creating a need for more accurate computational approaches.

Method: Develops a higher-order three-scale computational method using recursive two-scale analysis between macro-meso and meso-micro scales, establishing a detailed macro-meso-micro correlative model with higher-order correction terms. Includes local error analysis and a two-stage numerical algorithm with off-line and on-line stages for efficient simulation.

Result: The HOTS method demonstrates high computational efficiency, high numerical accuracy, and low computational cost in representative numerical experiments. The local error analysis mathematically validates the well-balanced property of the computational model.

Conclusion: The scalable and robust HOTS computational approach provides a reliable numerical tool for nonlinear multiphysics simulation of large-scale heterogeneous structures in real-world applications, effectively handling three-scale spatial configurations with temperature-dependent nonlinear thermo-mechanical behaviors.

Abstract: Classical multi-scale methods involving two spatial scales face significant challenges when simulating heterogeneous structures with complicated three-scale spatial configurations. This study proposes an innovative higher-order three-scale (HOTS) computational method, aimed at accurately and efficiently computing the transient nonlinear thermo-mechanical coupling problems of heterogeneous structures with multiple spatial scales. In these heterogeneous structures, temperature-dependent material properties have an important impact on the thermo-mechanical coupling responses, which is the particular interest in this work. At first, the detailed macro-meso-micro correlative model with higher-order correction terms is established by recursively two-scale analysis between macro-meso and meso-micro scales, which enables high-accuracy analysis of temperature-dependent nonlinear thermo-mechanical behaviors of heterogeneous structures with complicated three-scale configurations. The local error analysis mathematically illustrates the well-balanced property of HOTS computational model, endowing it with high computational accuracy. In addition, a two-stage numerical algorithm with off-line and on-line stages is proposed in order to efficiently simulate the nonlinear thermo-mechanical responses of heterogeneous structures with three-level spatial scales and accurately capture their highly oscillatory information at micro-scale. Finally, the high computational efficiency, high numerical accuracy and low computational cost of the presented higher-order three-scale computational approach are substantiated via representative numerical experiments. It can be summarized that this scalable and robust HOTS computational approach offers a reliably numerical tool for nonlinear multiphysics simulation of large-scale heterogeneous structures in real-world applications.

</details>


### [10] [The Complex-Step Integral Transform](https://arxiv.org/abs/2512.09459)
*Rafael Abreu,Stephanie Durand,Jochen Kamm,Christine Thomas,Monika Pandey*

Main category: math.NA

TL;DR: The paper introduces the Complex-Step Integral Transform (CSIT), a novel integral transform for numerical differentiation that combines analytic continuation, derivative approximation, and multi-scale smoothing, offering advantages over conventional Fourier and Hilbert-based methods.


<details>
  <summary>Details</summary>
Motivation: Motivated by the established connection between Hilbert transform and derivative operators, and recent developments in complex-step differentiation, the authors aim to create a unified framework that addresses limitations of existing methods for numerical differentiation and spectral analysis.

Method: The CSIT combines analytic continuation, derivative approximation, and multi-scale smoothing. It uses real and imaginary step parameters, with both FFT-based and interpolation-based implementations. Spectral analysis shows it preserves phase while suppressing high-wavenumber noise.

Result: CSIT produces smoother, more robust attributes than Hilbert-based methods and provides built-in stabilization for PDE solvers. It demonstrates effectiveness on advection equation and instantaneous-frequency computation problems.

Conclusion: CSIT represents a flexible alternative for numerical differentiation, spectral analysis, and seismic signal processing, with potential for future extensions including non-periodic implementations, adaptive parameter selection, and integration with local interpolation frameworks.

Abstract: Building on the well-established connection between the Hilbert transform and derivative operators, and motivated by recent developments in complex-step differentiation, we introduce the Complex-Step Integral Transform (CSIT): a generalized integral transform that combines analytic continuation, derivative approximation, and multi-scale smoothing within a unified framework. A spectral analysis shows that the CSIT preserves phase while suppressing high-wavenumber noise, offering advantages over conventional Fourier derivatives. We discuss the roles of the real and imaginary step parameters, compare FFT-based and interpolation-based implementations, and demonstrate the method on the advection equation and instantaneous-frequency computation. Results show that the CSIT yields smoother, more robust attributes than Hilbert-based methods and provides built-in stabilization for PDE solvers. The CSIT thus represents a flexible alternative for numerical differentiation, spectral analysis, and seismic signal processing. The method opens several avenues for future work, including non-periodic implementations, adaptive parameter selection, and integration with local interpolation frameworks such as high-order Finite-Element methods.

</details>


### [11] [Inexact Gauss Seidel and Coarse Solvers for AMG and s-step CG](https://arxiv.org/abs/2512.09642)
*Stephen Thomas,Pasqua D'Ambra*

Main category: math.NA

TL;DR: Low-synchronization Forward Gauss-Seidel method for solving Gram systems in communication-avoiding Krylov methods, with equivalence to Modified Gram-Schmidt and GPU scalability up to 64 GPUs.


<details>
  <summary>Details</summary>
Motivation: Communication-avoiding Krylov methods require solving small dense Gram systems at each iteration, which can be a bottleneck. The paper aims to develop a low-synchronization approach to improve scalability on modern GPU architectures.

Method: Forward Gauss-Seidel (FGS) method that exploits the structure of Gram matrices arising from Chebyshev polynomial bases. The approach is extended to Algebraic MultiGrid (AMG) coarse-grid solves.

Result: Shows mathematical equivalence between single FGS sweep and Modified Gram-Schmidt orthogonalization in A-norm with backward error bounds. Demonstrates weak scaling on AMD MI-series GPUs with 20-30 FGS iterations preserving scalability up to 64 GPUs for problems exceeding 700 million unknowns.

Conclusion: FGS provides an effective low-synchronization alternative for solving Gram systems in communication-avoiding Krylov methods, with good scalability on GPU architectures and applicability to AMG coarse-grid solves without assembling dense operators.

Abstract: Communication-avoiding Krylov methods require solving small dense Gram systems at each outer iteration. We present a low-synchronization approach based on Forward Gauss--Seidel (FGS), which exploits the structure of Gram matrices arising from Chebyshev polynomial bases. We show that a single FGS sweep is mathematically equivalent to Modified Gram--Schmidt (MGS) orthogonalization in the $A$-norm and provide corresponding backward error bounds. For weak scaling on AMD MI-series GPUs, we demonstrate that 20--30 FGS iterations preserve scalability up to 64 GPUs with problem sizes exceeding 700 million unknowns. We further extend this approach to Algebraic MultiGrid (AMG) coarse-grid solves, removing the need to assemble or factor dense coarse operators

</details>


### [12] [A Simple Weak Galerkin Finite Element Method for the Reissner-Mindlin Plate Model on Non-Convex Polytopal Meshes](https://arxiv.org/abs/2512.09688)
*Chunmei Wang,Shangyou Zhang*

Main category: math.NA

TL;DR: A stabilizer-free weak Galerkin method for Reissner-Mindlin plates using bubble functions on polytopal meshes with optimal error estimates.


<details>
  <summary>Details</summary>
Motivation: To develop a simpler weak Galerkin finite element method that eliminates the need for traditional stabilizers while maintaining geometric flexibility on general polytopal meshes, including non-convex ones.

Method: Uses bubble functions without restrictive conditions in a weak Galerkin framework, allowing flexible polynomial degree choices and working in any spatial dimension on polytopal meshes.

Result: Establishes optimal-order error estimates in discrete H^1 norm and validates theoretical results through numerical experiments.

Conclusion: The proposed method simplifies implementation, broadens applicability to various PDEs, and maintains geometric flexibility while achieving optimal convergence rates.

Abstract: This paper presents a simple weak Galerkin (WG) finite element method for the Reissner-Mindlin plate model that partially eliminates the need for traditionally employed stabilizers. The proposed approach accommodates general, including non-convex, polytopal meshes, thereby offering greater geometric flexibility. It utilizes bubble functions without imposing the restrictive conditions required by existing stabilizer-free WG methods, which simplifies implementation and broadens applicability to a wide range of partial differential equations (PDEs). Moreover, the method allows for flexible choices of polynomial degrees in the discretization and can be applied in any spatial dimension. We establish optimal-order error estimates for the WG approximation in a discrete H^1 norm, and present numerical experiments that validate the theoretical results.

</details>


### [13] [Analysis of splitting schemes for stochastic evolution equations with non-Lipschitz nonlinearities driven by fractional noise](https://arxiv.org/abs/2512.09733)
*Xiao-Li Ding,Charles-Edouard Bréhier,Dehua Wang*

Main category: math.NA

TL;DR: A novel time-splitting scheme for semilinear stochastic evolution equations with cylindrical fractional noise, achieving convergence order H-1/4 for Hurst index H∈(1/4,1).


<details>
  <summary>Details</summary>
Motivation: To develop efficient numerical methods for semilinear stochastic evolution equations driven by cylindrical fractional noise, which are challenging due to non-globally Lipschitz nonlinearities and fractional noise.

Method: A splitting scheme that decomposes nonlinearity into one-sided non-globally Lipschitz and globally Lipschitz parts. The first is treated using exact flow of associated differential equation, the second by explicit Euler approximation.

Result: Proved mean-square strong error estimates showing convergence order H-1/4. Established new regularity results for real-valued and infinite dimensional fractional Ornstein-Uhlenbeck processes.

Conclusion: The proposed splitting scheme effectively handles challenging nonlinearities in fractional noise settings, with theoretical convergence guarantees and numerical validation.

Abstract: We propose a novel time-splitting scheme for a class of semilinear stochastic evolution equations driven by cylindrical fractional noise. The nonlinearity is decomposed as the sum of a one-sided, non-globally, Lipschitz continuous function, and of a globally Lipschitz continuous function. The proposed scheme is based on a splitting strategy, where the first nonlinearity is treated using the exact flow of an associated differential equation, and the second one is treated by an explicit Euler approximation. We prove mean-square, strong error estimates for the proposed scheme and show that the order of convergence is $H-1/4$, where $H\in(1/4,1)$ is the Hurst index. For the proof, we establish new regularity results for real-valued and infinite dimensional fractional Ornstein-Uhlenbeck process depending on the value of the Hurst parameter $H$. Numerical experiments illustrate the main result of this manuscript.

</details>


### [14] [Trace inequalities for piecewise $W^{1,p}$ functions over general polytopic meshes](https://arxiv.org/abs/2512.09752)
*Michele Botti,Lorenzo Mascotto*

Main category: math.NA

TL;DR: The paper proves trace inequalities for piecewise W^{1,p} functions on general polytopic meshes, overcoming limitations of existing results for nonconforming discretizations.


<details>
  <summary>Details</summary>
Motivation: Trace inequalities are essential for analyzing PDE stability with inhomogeneous boundary conditions and convergence of Galerkin methods, but standard trace inequalities fail for nonconforming discretizations like Crouzeix-Raviart and discontinuous Galerkin where functions are only piecewise continuous.

Method: The authors prove several trace inequalities for piecewise W^{1,p} functions on general polytopic meshes with arbitrary number and size of facets, without relying on finite-dimensional arguments like inverse estimates or approximation properties of averaging operators.

Result: The paper establishes trace inequalities that work for different ranges of maximal and nonmaximal Lebesgue indices, providing a more general framework than existing results for nonconforming discretizations.

Conclusion: These new trace inequalities enable rigorous analysis of nonconforming finite element methods on general meshes, supporting convergence proofs for minimal regularity data without restrictive mesh assumptions.

Abstract: Trace inequalities are crucial tools to derive the stability of partial differential equations with inhomogeneous, natural boundary conditions. In the analysis of corresponding Galerkin methods, they are also essential to show convergence of sequences of discrete solutions to the exact one for data with minimal regularity under mesh refinements and/or degree of accuracy increase. In nonconforming discretizations, such as Crouzeix-Raviart and discontinuous Galerkin, the trial and test spaces consists of functions that are only piecewise continuous: standard trace inequalities cannot be used in this case. In this work, we prove several trace inequalities for piecewise $W^{1,p}$ functions. Compared to analogous results already available in the literature, our inequalities are established: (i) on fairly general polytopic meshes (with arbitrary number of facets and arbitrarily small facets); (ii) without the need of finite dimensional arguments (e.g., inverse estimates, approximation properties of averaging operators); (iii) for different ranges of maximal and nonmaximal Lebesgue indices.

</details>


### [15] [A Relaxed Randomized Averaging Block Extended Bregman-Kaczmarz Method for Combined Optimization Problems](https://arxiv.org/abs/2512.09825)
*Zeyu Dong,Aqin Xiao,Guojian Yin,Junfeng Yin*

Main category: math.NA

TL;DR: Proposed rRABEBK method for solving combined optimization problems with averaging block strategy and relaxation parameters, achieving faster linear convergence than classical methods.


<details>
  <summary>Details</summary>
Motivation: Randomized Kaczmarz-type methods have limitations with inconsistent systems and incorporating structural information like sparsity, motivating a more flexible and efficient approach.

Method: Relaxed randomized averaging block extended Bregman-Kaczmarz (rRABEBK) method with averaging block strategy and two relaxation parameters to accelerate convergence and enhance stability.

Result: Established linear convergence in expectation with explicit constants, provably faster rate than classical randomized extended Bregman-Kaczmarz method, applicable to sparse least-squares and both consistent/inconsistent systems.

Conclusion: rRABEBK significantly outperforms existing Kaczmarz-type algorithms in iteration complexity and computational efficiency, offering both practical and theoretical advantages.

Abstract: Randomized Kaczmarz-type methods are widely used for their simplicity and efficiency in solving large-scale linear systems and optimization problems. However, their applicability is limited when dealing with inconsistent systems or incorporating structural information such as sparsity. In this work, we propose a \emph{relaxed randomized averaging block extended Bregman-Kaczmarz} (rRABEBK) method for solving a broad class of combined optimization problems. The proposed method integrates an averaging block strategy with two relaxation parameters to accelerate convergence and enhance numerical stability. We establish a rigorous convergence theory showing that rRABEBK achieves linear convergence in expectation, with explicit constants that quantify the effect of the relaxation mechanism, and a provably faster rate than the classical randomized extended Bregman-Kaczmarz method. Our method can be readily adapted to sparse least-squares problems and extended to both consistent and inconsistent systems without modification. Complementary numerical experiments corroborate the theoretical findings and demonstrate that rRABEBK significantly outperforms the existing Kaczmarz-type algorithms in terms of both iteration complexity and computational efficiency, highlighting both its practical and theoretical advantages.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [16] [On the elasto-plastic filtration equation](https://arxiv.org/abs/2512.09298)
*Arturo de Pablo,Fernando Quiros,Julio D. Rossi*

Main category: math.AP

TL;DR: Study of fully nonlinear heat equation with discontinuous coefficient b(s) modeling elastic fluid flow in elasto-plastic porous medium, focusing on existence/uniqueness of viscosity solutions and asymptotic behavior.


<details>
  <summary>Details</summary>
Motivation: The equation models flow of elastic fluid in elasto-plastic porous medium. The discontinuous coefficient b(s) with different positive constants b^- and b^+ for negative and positive ∂_tu respectively creates mathematical challenges requiring viscosity solution theory.

Method: Use viscosity solution theory for fully nonlinear heat equation with discontinuous coefficient. Characterize solutions as limits of minimization dynamic game. Study asymptotic behavior as t→∞ and when b^-→0+ or b^+→∞.

Result: Established existence and uniqueness of viscosity solutions for the fully nonlinear heat equation with discontinuous coefficient. Characterized solutions as limits of minimization dynamic game. Analyzed asymptotic behavior in various limits.

Conclusion: The paper successfully develops viscosity solution theory for the fully nonlinear heat equation with discontinuous coefficient, providing existence, uniqueness, and asymptotic analysis while connecting solutions to minimization dynamic game limits.

Abstract: We study the fully nonlinear heat equation $b(\partial_tu)\partial_tu=Δu$ posed in a bounded domain with Dirichlet boundary conditions. Here $b(s)=b^-$ if $s<0$, $b(s)=b^+$ if $s>0$, $b^-\neq b^+$ being two positive constants. This equation models the flow of an elastic fluid in an elasto-plastic porous medium. We are interested in the existence and uniqueness of viscosity solutions and in their asymptotic behaviour as $t\to\infty$ and when $b^-\to 0^+$ or $b^+\to +\infty$. We also characterize solutions of the problem as limits of a minimization dynamic game.

</details>


### [17] [Geometric properties of optimizers for the maximum gradient of the torsion function](https://arxiv.org/abs/2512.09400)
*Krzysztof Burdzy,Ilias Ftouhi,Xuefeng Liu,Phanuel Mariano*

Main category: math.AP

TL;DR: The paper proves existence of planar convex domains that maximize two functionals involving the infinity norm of the gradient of the torsion function, and characterizes properties of maximizers.


<details>
  <summary>Details</summary>
Motivation: To study optimization problems for geometric functionals involving the torsion function on convex domains, specifically finding domains that maximize the ratio of the maximum gradient norm to geometric quantities (area and perimeter).

Method: Analytical approach using variational methods and geometric analysis to prove existence of maximizers for the functionals J(Ω) = ||∇u_Ω||_∞/√|Ω| and J_P(Ω) = ||∇u_Ω||_∞/P(Ω), where u_Ω is the torsion function on planar convex domains.

Result: Existence of planar convex domains that maximize both functionals is proved. Any maximizer has a C^1 boundary containing a line segment where |∇u_Ω| attains its maximum value.

Conclusion: The optimization problems for these torsion-based functionals on convex domains are well-posed, and maximizers exhibit specific regularity and geometric properties (C^1 boundary with flat portions where the gradient is maximal).

Abstract: Consider $J(Ω):= \|\nabla u_Ω\|_\infty/\sqrt{|Ω|} $ and $J_P(Ω):= \|\nabla u_Ω\|_\infty/P(Ω) $, where $Ω$ is a planar convex domain, $u_Ω$ is the torsion function, $P(Ω)$ is the perimeter of $Ω$ and $|Ω|$ its area. We prove that there exist planar convex domains that maximize the functionals $J$ and $J_P$, and any maximizer has a $C^1$ boundary that contains a line segment on which $|\nabla u_Ω|$ attains its maximum.

</details>


### [18] [Fractional calculus approach to models of adsorption: Barrier-diffusion control](https://arxiv.org/abs/2512.09426)
*Ivan Bazhlekov,Emilia Bazhlekova*

Main category: math.AP

TL;DR: The paper analyzes surfactant adsorption under mixed barrier-diffusion control using fractional calculus, transforming the Ward-Tordai equation into a fractional ODE, deriving exact solutions for Henry model, asymptotes for other models, and developing numerical methods.


<details>
  <summary>Details</summary>
Motivation: To develop a mathematical framework for analyzing surfactant adsorption kinetics under mixed barrier-diffusion control using fractional calculus, which can handle complex adsorption models (Henry, Langmuir, Frumkin, Volmer, van der Waals) more effectively than traditional approaches.

Method: Treat the Ward-Tordai integral equation as a fractional order equation, transform it into a single fractional ODE for adsorption, reduce parameters to dimensionless groups, derive exact solutions for Henry model using Mittag-Leffler functions, develop asymptotes for other models, and create predictor-corrector numerical methods for simulation.

Result: Exact solution for Henry adsorption isotherm expressed via Mittag-Leffler functions, second-order asymptotes derived for other models, universal first-order approximation for surface tension established, and generalized fractional-order integral equation developed with working numerical simulation method.

Conclusion: Fractional calculus provides effective framework for mixed barrier-diffusion adsorption models, Henry model serves as universal first-order approximation, and developed numerical methods enable practical simulation of complex adsorption kinetics.

Abstract: The mathematical model of surfactant adsorption under mixed barrier-diffusion control is analyzed using techniques from fractional calculus. The kinetic models of Henry, Langmuir, Frumkin, Volmer and van der Waals are considered. First, treating the Ward-Tordai integral equation as a fractional order one, the partial differential model is transformed into a single fractional ordinary differential equation for the adsorption. A transformation of the obtained equation is proposed that reduces the number of parameters to two dimensionless groups (at Frumkin and van der Waals models a third parameter appears). In the simplest case of Henry adsorption isotherm the fractional differential model depends on a single dimensionless group and an exact solution exists, represented in terms of Mittag-Leffler functions. Based on this solution, second order asymptotes (at small values of the adsorption) are derived for the other models. The asymptotes of the adsorption result in a higher order asymptotes for the surface pressure (surface tension). For small surface coverage, all considered models converge to the Henry model's predictions, making it a universal first-order approximation for the surface tension. Next, the fractional differential model is written as an integral equation %of fractional order that can be considered as a generalization of the well-known Ward-Tordai equation to the case of barrier-diffusion control. For computer simulation of the obtained integral equation a predictor-corrector numerical method is developed and numerical results are presented and discussed.

</details>


### [19] [Normalized solutions of $L^2$ supercritical NLS equations in exterior domains with inhomogeneous nonlinearities](https://arxiv.org/abs/2512.09437)
*Xiaojun Chang,Cong-Mei Li*

Main category: math.AP

TL;DR: Existence of normalized mountain pass solutions for L²-supercritical nonlinear Schrödinger equation with inhomogeneous nonlinearity |x|^{-α}|u|^{p-2}u in exterior domains, where the decaying term breaks scaling symmetry and prevents energy leakage.


<details>
  <summary>Details</summary>
Motivation: Previous work showed that for autonomous case (α=0), mountain pass solutions in exterior domains share same energy levels as in ℝᴺ, leading to non-existence due to energy leakage to infinity. The paper investigates whether physically motivated decaying term |x|^{-α} can break this symmetry and enable existence.

Method: Novel min-max argument combining monotonicity trick, Morse index estimates, and blow-up analysis to prove existence of positive mountain pass solution for sufficiently small mass.

Result: Establishes existence of normalized mountain pass solutions to L²-supercritical nonlinear Schrödinger equation with inhomogeneous nonlinearity in exterior domains. The decaying term |x|^{-α} breaks scaling symmetry, energetically separates exterior domain problem from whole space one, and prevents energy leakage.

Conclusion: The decaying term |x|^{-α} in non-autonomous nonlinearities creates new phenomena in non-compact domains by breaking scaling symmetry and enabling existence of mountain pass solutions that were impossible in autonomous case due to energy leakage.

Abstract: This paper establishes the existence of normalized mountain pass solutions to the $L^2$-supercritical nonlinear Schrödinger equation with inhomogeneous nonlinearity $|x|^{-α}|u|^{p-2}u$ in exterior domains. In contrast, for the autonomous case ($α=0$), Appolloni \& Molle (2025) and Zhang \& Zhang (2022) showed that potential mountain pass solutions share the same energy levels as in $\mathbb{R}^N$, causing non-existence due to energy leakage to infinity. This work demonstrates that the physically motivated decaying term $|x|^{-α}$ breaks the scaling symmetry inherent in the autonomous case. Such breaking energetically separates the exterior domain problem from the whole space one and thereby prevents energy leakage. Using a novel min-max argument that combines monotonicity trick, Morse index estimates, and blow-up analysis, we prove the existence of a positive mountain pass solution for sufficiently small mass, revealing a new phenomenon of non-autonomous nonlinearities in non-compact domains.

</details>


### [20] [Fractional weighted Sobolev spaces associated to the Riesz fractional gradient](https://arxiv.org/abs/2512.09575)
*Guillermo García-Sáez*

Main category: math.AP

TL;DR: Introduces weighted fractional Sobolev spaces X^{s,p}_{0,w}(Ω) as extension of fractional Sobolev spaces to weighted Lebesgue spaces with Muckenhoupt weights.


<details>
  <summary>Details</summary>
Motivation: To extend fractional Sobolev spaces to the weighted setting using Muckenhoupt weights, providing a natural framework for studying degenerate fractional elliptic PDEs.

Method: Define new function spaces X^{s,p}_{0,w}(Ω) using Riesz fractional gradient D^s and weighted Lebesgue spaces L^p_w with Muckenhoupt A_p weights. Prove equivalence with weighted Bessel potential spaces.

Result: Established structural properties of the new spaces, proved continuous and compact embeddings, and studied a family of degenerate fractional elliptic PDEs.

Conclusion: Successfully developed weighted fractional Sobolev spaces that extend classical theory to weighted settings, providing tools for analyzing degenerate fractional elliptic equations.

Abstract: In this work, we introduce a new family of functions spaces, the weighted fractional Sobolev spaces $X^{s,p}_{0,w}(Ω)$, where $w$ is a weight in the Muckenhoupt class $A_p$. This space is a natural extension of the fractional Sobolev spaces $H^{s,p}_0$, obtained by means of the Riesz fractional gradient $D^s$, to the setting of the weighted Lebesgue spaces $L^p_w$. As it happened in the unweighted space, the spaces $X^{s,p}_{0,w}(Ω)$ coincide with the weighted version of the Bessel potential space. We obtaien several structural properties for these spaces, as well as continuous and compact embeddings. We conclude with the study of a family of degenerate fractional elliptic partial differential equations.

</details>


### [21] [On a large deviation principle for 1d cubic NLS with optimal decaying data](https://arxiv.org/abs/2512.09599)
*Chenjie Fan,Feng Ye*

Main category: math.AP

TL;DR: Revisiting previous work to prove large deviation principles for cubic NLS with more general random initial data having optimal polynomial decay in Fourier coefficients.


<details>
  <summary>Details</summary>
Motivation: To extend previous results on large deviation principles for cubic nonlinear Schrödinger equations (NLS) by considering more general random initial data conditions beyond what was previously studied.

Method: Revisiting and extending the work of Garrido (2023) by proving large deviation principles for cubic NLS with random initial data whose Fourier coefficients exhibit optimal polynomial decay properties.

Result: Established large deviation principles for cubic NLS under more general random initial data conditions, specifically when Fourier coefficients have optimal polynomial decay rates.

Conclusion: The paper successfully extends previous large deviation results to broader classes of random initial data for cubic NLS, providing more comprehensive probabilistic analysis of the equation's behavior.

Abstract: In this article, we revisit the work of \cite{garrido2023large}, and prove large deviation principles for more general random initial data for cubic NLS. The Fourier coefficient of our random data admits an optimal polynomial decay.

</details>


### [22] [Relaxation limit and asymptotic stability for the Euler-Navier-Stokes equations](https://arxiv.org/abs/2512.09650)
*Mingwen Fei,Ling-Yun Shou,Houzhi Tang*

Main category: math.AP

TL;DR: The paper analyzes the singular limit of the Euler-Navier-Stokes system as relaxation parameter ε→0, establishing global error estimates, uniform regularity, and decay rates compared to the Kramers-Smoluchowski-Navier-Stokes limit system.


<details>
  <summary>Details</summary>
Motivation: The Euler-Navier-Stokes system describes kinetic-fluid interactions but features only weak relaxation of relative velocity, making its singular limit analysis challenging as ε→0. Understanding this limit is important for connecting macroscopic fluid descriptions with their kinetic origins.

Method: Developed an energy argument to obtain global-in-time error estimates between E-NS and its limit KS-NS system. Used hybrid critical Besov spaces with sharp frequency threshold O(ε⁻¹) separating low- and high-frequency regimes to analyze uniform regularity.

Result: Proved global existence and uniform-in-ε regularity of strong solutions in hybrid Besov spaces. Established large-time asymptotic stability with optimal decay rates uniform in ε, and enhanced decay rates for density differences between E-NS and KS-NS systems.

Conclusion: Successfully analyzed the singular limit of E-NS system as ε→0, connecting it rigorously to KS-NS system through global error estimates, uniform regularity, and decay properties, providing a complete mathematical framework for this kinetic-fluid interaction limit.

Abstract: The Euler-Navier-Stokes (E-NS) system arises as a macroscopic description of kinetic-fluid interactions, derived from the local-Maxwellian closure of the Vlasov-Fokker-Planck-Navier-Stokes flow. In this paper, we investigate the singular limit of the system in $\mathbb{R}^d$ ($d\ge2$) when the relaxation parameter $\varepsilon>0$ tends to zero. In contrast to the Euler system with velocity damping, the E-NS model features only a weaker relaxation of the relative velocity, which makes it challenging to analyze its dynamics as $\varepsilon\rightarrow 0$. We develop an energy argument to show global-in-time error estimates between the E-NS system and its limit system, the so-called Kramers-Smoluchowski-Navier-Stokes (KS-NS) system. These error estimates enable us to prove the global existence and uniform-in-$\varepsilon$ regularity of the strong solution to the E-NS system in a hybrid critical Besov space with a sharp frequency threshold of order $\mathcal{O}(\varepsilon^{-1})$ separating the low- and high-frequency regimes. Moreover, the large-time asymptotic stability of the global solution to the E-NS system is established. More precisely, we derive the optimal decay rates of the solution uniformly in $\varepsilon$, and the enhanced decay rates for the difference between the densities of the E-NS system and the KS-NS system.

</details>


### [23] [Regularity and pointwise convergence for dispersive equations on Riemannian symmetric spaces of compact type](https://arxiv.org/abs/2512.09689)
*Utsav Dewan,Sanjoy Pusti*

Main category: math.AP

TL;DR: The paper studies pointwise convergence of solutions to dispersive equations on compact Riemannian symmetric spaces, establishing regularity thresholds for convergence and showing improvements for K-biinvariant data in rank 1 cases.


<details>
  <summary>Details</summary>
Motivation: To understand the regularity requirements for pointwise convergence of solutions to dispersive equations (Schrödinger, Boussinesq, Beam equations) on compact Riemannian symmetric spaces, extending classical results from Euclidean spaces to these geometric settings.

Method: Uses harmonic analysis from representation theory of compact semi-simple Lie groups and number theory. Introduces a novel transference principle that works even for the circle. Analyzes general dispersive equations on rank 1 and 2 symmetric spaces, then focuses on K-biinvariant data for special rank 1 cases.

Result: For general dispersive equations on rank 1 and 2 symmetric spaces, α>1/2 Sobolev regularity ensures pointwise convergence a.e. For K-biinvariant data in special rank 1 cases, threshold improves to α>1/3, while α<1/4 fails for Schrödinger equation. Results extend to Boussinesq and Beam equations via transference principle.

Conclusion: The paper establishes precise regularity thresholds for pointwise convergence on symmetric spaces, with improvements for symmetric data, and introduces a novel transference principle that extends results to multiple dispersive equations and may have independent mathematical interest.

Abstract: In this article, we first prove that for general dispersive equations on Riemannian symmetric spaces of compact type $\mathbb{X}=U/K$, of rank $1$ and $2$, the Sobolev regularity threshold $α>1/2$ for the initial data, is sufficient to obtain pointwise convergence of the solution a.e. on $\mathbb{X}$. We next focus on $K$-biinvariant initial data for certain special cases of rank $1$, depending on geometric and topological considerations, and prove that the sufficiency of the regularity threshold can be improved down to $α>1/3$, whereas the phenomenon fails for $α<1/4$ for the Schrödinger equation. We also obtain the same results for other dispersive equations: the Boussinesq equation and the Beam equation, also known as the fourth order Wave equation, by a novel transference principle, which seems to be new even for the circle $\mathbb{T} \cong SO(2)$ and may be of independent interest. Our arguments involve harmonic analysis arising from the representation theory of compact semi-simple Lie groups and also number theory.

</details>


### [24] [Weak-Strong Uniqueness and Relaxation Limit for a Navier-Stokes-Korteweg Model](https://arxiv.org/abs/2512.09719)
*Nilasis Chaudhuri,Christian Rohde,Florian Wendt*

Main category: math.AP

TL;DR: The paper analyzes a parabolic relaxation model for compressible Navier-Stokes-Korteweg equations, proving weak-strong uniqueness and rigorous convergence in the relaxation limit for general pressure-density relations.


<details>
  <summary>Details</summary>
Motivation: To mathematically justify a relaxation model as an approximate model for compressible Navier-Stokes-Korteweg equations, particularly for non-monotone pressure-density relations where traditional methods may fail.

Method: Introduces finite energy weak solutions for the relaxation model's initial-boundary value problem in 3D, then proves weak-strong uniqueness principle and rigorous convergence results for the relaxation limits α→∞ and β→0.

Result: Proves that weak and strong solutions with same initial data coincide (weak-strong uniqueness), and establishes rigorous convergence of the relaxation model to the original Navier-Stokes-Korteweg equations in the relaxation limit.

Conclusion: The relaxation model is mathematically justified as an approximate model for compressible Navier-Stokes-Korteweg equations, with results valid for general non-monotone pressure-density relations, providing important theoretical foundations.

Abstract: We consider a parabolic relaxation model for the compressible Navier-Stokes-Korteweg equations in the isothermal framework. This system depends on the relaxation parameters $α,β>0$ and approximates formally solutions of the compressible Navier-Stokes-Korteweg equations in the relaxation limit $α\to \infty$ and $β\to 0$. Introducing the class of finite energy weak solutions for the initial-boundary value problem corresponding to the relaxation model in spatial dimension three, we show that the weak-strong uniqueness principle holds. It asserts that a weak solution and a strong solution emanating from the same initial data coincide as long as the strong solution exists. Furthermore, we contribute a rigorous convergence result for the relaxation limit $α\to \infty$ and $β\to 0$ and thus justify the relaxation model as an approximate model for the compressible Navier-Stokes-Korteweg equations from a mathematical point of view. Our results hold for general non-monotone pressure-density relations.

</details>


### [25] [Well-posedness of the motion of a rigid body immersed in a compressible inviscid fluid](https://arxiv.org/abs/2512.09741)
*Frédéric Rousset,Pei Su*

Main category: math.AP

TL;DR: Local existence and uniqueness of classical solutions for a rigid body moving in compressible inviscid fluid governed by Euler equations.


<details>
  <summary>Details</summary>
Motivation: Study coupled fluid-structure interaction between rigid body and compressible inviscid fluid, which involves hyperbolic PDE with moving boundary and characteristic boundary conditions.

Method: 1) Change variables to fixed domain; 2) Analyze approximate system with non-characteristic boundary; 3) Use pressure trace regularity for fixed-point argument updating fluid/solid motions iteratively; 4) Derive uniform estimates and pass to limit via strong compactness.

Result: Established existence of unique local classical solution to coupled rigid body-compressible Euler system.

Conclusion: Successfully proved local well-posedness for compressible fluid-rigid body interaction with characteristic boundary conditions using regularization and compactness techniques.

Abstract: We consider a rigid body freely moving in a compressible inviscid fluid within a bounded domain $Ω\subset\mathbb{R}^3$. The fluid is thereby governed by the non necessarily isentropic compressible Euler equations, while the rigid body obeys the conservation of linear and angular momentum. This forms a coupled system comprising an ODE and the initial boundary value problem (IBVP) of a hyperbolic system with characteristic boundary in a moving domain, where the fluid velocity matches the solid velocity along the normal direction of the solid boundary. We establish the existence of a unique local classical solution to this coupled system. To construct the solution, we first perform a change of variables to reformulate the problem in a fixed spatial domain, and then analyze an approximate system with a non-characteristic boundary. For this nonlinear approximate system, we use the better regularity for the trace of the pressure on the boundary to contruct a solution by a fixed-point argument in which the fluid motion and the solid motion are updated in successive steps. We are then able to derive estimates independent of the regularization parameter and to pass to the limit by a strong compactness arguments.

</details>


### [26] [The tangent space to the Wasserstein space: parallel transport and other applications](https://arxiv.org/abs/2512.09763)
*Charles Bertucci*

Main category: math.AP

TL;DR: The paper introduces a new formal tangent space concept for Wasserstein spaces, defining tangent vectors as functions from the base space to probability measures over the tangent bundle.


<details>
  <summary>Details</summary>
Motivation: To develop a more comprehensive differential geometric framework for Wasserstein spaces that generalizes previous tangent space concepts and enables richer geometric analysis.

Method: Proposes a new definition of tangent space to Wasserstein space P(X) at a given measure, where tangent vectors are functions from X to probability measures over the tangent bundle TX, subject to integrability conditions.

Result: The new tangent space construction enables definition of parallel transport, C^{1,α} regularity over P(X), and translation of curves in Wasserstein space.

Conclusion: The proposed framework provides a more general and flexible geometric structure for Wasserstein spaces, extending previous approaches and enabling new analytical tools for studying optimal transport spaces.

Abstract: We propose a new notion of the formal tangent space to the Wasserstein space $\mathcal{P}(X)$ at a given measure. Modulo an integrability condition, we say that this tangent space is made of functions over $X$ which are valued in the probability measures over the tangent bundle to $X$. This generalization of previous concepts of tangent spaces allows us to define appropriate notions of parallel transport, $\mathcal{C}^{1,α}$ regularity over $\mathcal{P}(X)$ and translation of a curve over $\mathcal{P}(X)$.

</details>


### [27] [Calder{ó}n splitting and weak solutions for Navier-Stokes equations with initial data in weighted L p spaces](https://arxiv.org/abs/2512.09770)
*Pierre Gilles Lemarié-Rieusset*

Main category: math.AP

TL;DR: Global weak solutions exist for 3D Navier-Stokes equations with initial velocity in weighted spaces using Calderón splitting and L² energy controls.


<details>
  <summary>Details</summary>
Motivation: To establish existence of global weak solutions for 3D Navier-Stokes equations with initial data in weighted function spaces, extending classical results to more general settings.

Method: Uses Calderón splitting technique to decompose the weighted space L^p_Φγ into L²_Φ² + L^r (with r ∈ (3, ∞)), combined with energy estimates in the weighted L²_Φ² space.

Result: Proves existence of global weak solutions for 3D Navier-Stokes equations with initial velocity belonging to the specified weighted spaces.

Conclusion: The Calderón splitting approach with weighted energy controls successfully establishes global weak solution existence for 3D Navier-Stokes in weighted spaces.

Abstract: We show the existence of global weak solutions of the 3D Navier-Stokes equations with initial velocity in the weighted spaces  , using Calder{ó}n splitting L p $Φ$$γ$ $\subset$ L 2 $Φ$ 2 + L r (with some r $\in$ (3, +$\infty$)) and energy controls in L 2 $Φ$ 2 .

</details>


### [28] [A mixed local-nonlocal Hénon problem in $\mathbb{R}^N$](https://arxiv.org/abs/2512.09794)
*Pablo Ochoa,Ariel Salort*

Main category: math.AP

TL;DR: Study of Hénon-type equation with mixed local/nonlocal operators modeling stellar clusters, establishing existence threshold and regularity properties.


<details>
  <summary>Details</summary>
Motivation: The equation was originally proposed to model spherically symmetric stellar clusters. The authors aim to understand the mathematical properties of this physically motivated equation, particularly the conditions for solution existence and their regularity.

Method: Study a Hénon-type equation in ℝᴺ driven by a nonlinear operator combining local and nonlocal terms. Analyze the equation under specific parameter relations to determine existence conditions.

Result: Prove existence of a threshold separating existence and non-existence of solutions under suitable parameter relations. Establish regularity properties of the solutions.

Conclusion: The paper provides rigorous mathematical analysis of a physically motivated Hénon-type equation, establishing critical thresholds for solution existence and demonstrating solution regularity, contributing to understanding of stellar cluster modeling.

Abstract: In this article, we study a Hénon-type equation in $\mathbb{R}^N$ driven by a nonlinear operator given by the combination of a local and a nonlocal term. This equation was originally proposed to model spherically symmetric stellar clusters. Here, we prove that, under a suitable relation among the parameters, there exists a threshold separating the existence and non-existence of solutions. Moreover, we establish regularity properties of the solutions.

</details>


### [29] [On Landis' conjecture in the plane for real-valued potentials with decay](https://arxiv.org/abs/2512.09839)
*Blair Davey*

Main category: math.AP

TL;DR: The paper proves exponential decay estimates for real-valued solutions to planar Schrödinger equations with potentials decaying as |V(z)| ≲ ⟨z⟩⁻ᴺ, showing the decay rate depends explicitly on N. The results are essentially sharp.


<details>
  <summary>Details</summary>
Motivation: To establish quantitative unique continuation properties for Schrödinger equations with decaying potentials in ℝ², extending previous work on the Landis conjecture (N=0) and negative N cases.

Method: Combines techniques from [LMNN20] (which proved the Landis conjecture for real-valued solutions) with conformal transformations and an iteration scheme to handle the decaying potential case.

Result: Proves that real-valued solutions satisfy exponential decay estimates with rates explicitly dependent on N. Shows these estimates are essentially sharp through examples.

Conclusion: The paper establishes sharp quantitative decay estimates for solutions to planar Schrödinger equations with pointwise decaying potentials, bridging the gap between the Landis conjecture (N=0) and previously studied negative N cases.

Abstract: We investigate the quantitative unique continuation properties of real-valued solutions to planar Schrödinger equations with potential functions that exhibit pointwise decay at infinity. That is, for equations of the form $-Δu + V u = 0$ in $\mathbb{R}^2$, where $|V(z)| \lesssim \langle z \rangle^{-N}$ for some $N > 0$, we prove that real-valued solutions satisfy exponential decay estimates with a rate that depends explicitly on $N$. Examples show that the estimates established here are essentially sharp. The case of $N = 0$ corresponds to the Landis conjecture, which was proved for real-valued solutions in the plane in [LMNN20], while the case of $N < 0$ was previously investigated by the author in [Dav24]. Here, the proof techniques rely on the ideas presented in [LMNN20] combined with conformal transformations and an iteration scheme.

</details>


### [30] [Symmetry for the wave equation on torus: sharp unique continuation and observability conditions for spacetime regions](https://arxiv.org/abs/2512.09873)
*Jingrui Niu,Ming Wang,Shengquan Xiang*

Main category: math.AP

TL;DR: The paper discovers a new "observable symmetry condition" for 1D wave equations, leading to a new conservation law and necessary conditions for unique continuation, observability, and controllability.


<details>
  <summary>Details</summary>
Motivation: To discover new symmetry structures for 1D wave equations in spacetime observable regions that can provide deeper insights into conservation laws and fundamental properties like unique continuation, observability, and controllability.

Method: The authors discover a new symmetry structure called "observable symmetry condition" for 1D wave equations. They build on this symmetry to establish necessary and sufficient conditions for unique continuation by introducing a weak Geometric Control Condition (GCC). They use this symmetry as a complement to classical GCC to characterize observability and controllability through spacetime geometric regions.

Result: The observable symmetry condition yields a new conservation law for forced wave equations and provides necessary conditions for unique continuation, observability, and controllability. The authors establish a necessary and sufficient condition for unique continuation via weak GCC, and derive necessary and sufficient characterization of observability and controllability through spacetime geometric regions.

Conclusion: The discovered observable symmetry condition provides a fundamental new structure for analyzing 1D wave equations, complementing classical GCC and enabling complete characterizations of unique continuation, observability, and controllability through spacetime geometric considerations.

Abstract: In this work, we discover a new symmetry structure for the 1D wave equations associated with spacetime observable regions: observable symmetry condition. This structure yields a new conservation law for forced wave equations and provides a necessary condition for unique continuation, observability, and controllability. Building on this symmetry, we establish a necessary and sufficient condition for unique continuation by introducing a weak GCC. Moreover, this symmetry serves as an essential complement to the classical GCC, allowing us to derive a necessary and sufficient characterization of observability and controllability through spacetime geometric regions.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [31] [Data-driven time-dependent bases for turbulent airfoil wake-extreme vortex gust interactions](https://arxiv.org/abs/2512.09523)
*Shaghayegh Zamani Ashtiani,Kai Fukami*

Main category: physics.comp-ph

TL;DR: Data-driven modal analysis of turbulent airfoil wake interacting with extreme gusts using time-varying bases, revealing how modal energy evolves during gust encounters and correlates with transient lift dynamics.


<details>
  <summary>Details</summary>
Motivation: To understand the complex interactions between turbulent airfoil wakes and extreme gusts, which is crucial for aerodynamic performance and stability during severe weather conditions. Traditional methods may not capture the time-varying nature of these interactions effectively.

Method: Developed a data-driven framework with time-dependent bases: 2D in-plane modes and 1D spanwise modes with reduced covariance matrix. Derived closed-form evolution equations for time-varying components, using only a small rolling window without full-history storage. Applied to extreme vortex gust-airfoil interaction at Re=5000.

Result: Before gust impingement, first in-plane mode dominates; after impingement, second mode gains energy, amplified by stronger/larger gusts. Larger leading-mode energy gap indicates coherent structure and faster recovery; smaller gap with slower decay suggests richer multiscale activity and delayed re-stabilization. These trends follow transient lift dynamics with higher amplitude and oscillations indicated by rising leading singular values.

Conclusion: Provides an interpretable, time-varying data-driven modal analysis framework for extreme gust encounters, revealing how modal energy evolution correlates with aerodynamic response and recovery characteristics during gust interactions.

Abstract: We analyze interactions between turbulent airfoil wake and an extremely strong gust using a data-driven framework with time-dependent bases. The current approach represents each snapshot with time-varying bases consisting of two-dimensional in-plane modes and one-dimensional spanwise modes, together with a reduced covariance matrix. We derive closed-form evolution equations for these time-varying components and advance them over time, requiring only a small rolling window and avoiding full-history storage. Applied to extreme vortex gust-airfoil interaction at Re=5000, we examine how in-plane modes and their associated energy level evolve across gust conditions of varying intensity and size. Before impingement, the first in-plane mode dominates; after impingement, the second mode gains energy_amplified by stronger/larger gusts. A larger leading-mode energy gap implies coherent structure and faster recovery; a smaller gap with slower decay indicates richer multiscale activity and delayed re-stabilization. These trends follow the transient lift dynamics as well, with higher amplitude and more oscillations indicated by a rise in the leading singular values. This work provides an interpretable, time-varying data-driven modal analysis of extreme gust encounter.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [32] [Bayesian Optimization of Laser-Wakefield Acceleration via Spectral Pulse Shaping](https://arxiv.org/abs/2512.09125)
*B. Z. Djordjević,C. Benedetti,A. D. McNaughton,C. B. Schroeder,R. Lehe,H. -E. Tsai,S. C. Wilks,B. A. Reagan,G. J. Williams,J. van Tilborg*

Main category: physics.plasm-ph

TL;DR: Spectral pulse shaping of laser drivers improves performance in laser-plasma accelerators, increasing electron bunch charge by an order of magnitude and boosting mean energy through Bayesian optimization.


<details>
  <summary>Details</summary>
Motivation: To investigate how spectral pulse shaping affects performance in channel-guided laser-plasma accelerators, particularly for maximizing energy gain of electron bunches in realistic plasma profiles.

Method: Used Bayesian optimization with particle-in-cell simulations on realistic plasma profiles based on optical-field-ionized channel technique with ionization injection and low on-axis plasma densities. Spectral shaping modified temporal laser profiles while keeping energy constant.

Result: Found laser profiles with additional spectral content that, when combined with optimal plasma channel parameters, increased charge content by an order of magnitude compared to baseline Gaussian case while also increasing mean electron bunch energy.

Conclusion: Spectral pulse shaping significantly enhances laser-plasma accelerator performance, with optimized laser profiles dramatically improving both charge content and energy of electron bunches through careful parameter optimization.

Abstract: In this paper, we investigate the effect of spectral pulse shaping of the laser driver on the performance of channel-guided, laser-plasma accelerators. The study was carried out with the assistance of Bayesian optimization using particle-in-cell simulations. We used a realistic plasma profile based on a novel optical-field-ionized channel technique with ionization injection and low on-axis plasma densities to maximize the energy gain of the electron bunch trailing the laser. Spectral shaping allows us to modify the temporal profile of the laser driver while keeping the laser energy constant, affecting the acceleration and injection processes. Given the complexity and breadth of the parameter space in question, we used numerical optimization to identify high performers. In particular, we found laser profiles with additional spectral content that, when used with optimal plasma channel parameters, result in charge content an order of magnitude higher than the baseline Gaussian case while also increasing the mean energy of the electron bunch.

</details>


### [33] [The skin effect in anomalous transport of charged particles in plasma with a microturbulent magnetic field. I. Isotropic plasma](https://arxiv.org/abs/2512.09168)
*N. A. Emelyanov,Vl. V. Kocharovsky*

Main category: physics.plasm-ph

TL;DR: Electromagnetic skin effect increases particle mean free path in turbulent plasma, reducing anomalous resistance and creating anisotropic scattering.


<details>
  <summary>Details</summary>
Motivation: To understand how electromagnetic skin effect influences charged particle transport in dense, non-relativistic, collisionless plasma with small-scale turbulent magnetic fields.

Method: Used quasi-linear kinetic equations with both analytical and numerical methods; derived diffusion tensor components in Fokker-Planck equation; solved numerically for magnetostatic turbulence case.

Result: Skin effect increases particle mean free path, reduces anomalous resistance, creates anisotropic scattering and velocity distribution anisotropy; obtained analytical formulas for effective mobility and conductivity.

Conclusion: Electromagnetic skin effect significantly modifies particle transport in turbulent plasma by enhancing mobility, reducing resistance, and introducing scattering anisotropy.

Abstract: The influence of electromagnetic skin effect on anomalous charged particle transport in dense, non-relativistic, collisionless plasma with a small-scale turbulent magnetic field was investigated using quasi-linear kinetic equations, through both analytical and numerical methods. Analytical expressions for the diffusion tensor components in the Fokker-Planck equation that take this effect into account have been found. The equation was solved numerically in the case of magnetostatic turbulence. It has been demonstrated that the skin effect increases the mean free path of particles in turbulent plasma, thereby reducing its anomalous resistance. It also leads to anisotropy in particle scattering, resulting in anisotropy in their stationary velocity distribution, which increases as the screening parameter grows. Approximate analytical formulas for the effective mobility of charged particles and the electric conductivity of plasma with isotropic magnetostatic turbulence have been obtained.

</details>


### [34] [Activation of Polylactic Acid and Polycarbonate Surfaces with Non-Thermal Plasma](https://arxiv.org/abs/2512.09205)
*Jairo Rondón,Ginger Urrutia,Angel Gonzalez-Lizardo*

Main category: physics.plasm-ph

TL;DR: Review synthesizes evidence on non-thermal plasma surface activation of biomedical polymers, showing it enhances hydrophilicity, surface energy, and cell adhesion through multimodal characterization.


<details>
  <summary>Details</summary>
Motivation: Biomedical polymers like PLA and PC have intrinsic hydrophobicity that limits biological performance, requiring surface modification strategies to improve cell-material interactions for tissue engineering and medical devices.

Method: Multimodal analytical framework combining four pillars: contact-angle theory (wettability), dielectric impedance spectroscopy, FT-IR chemical mapping, and optical microscopy to interpret plasma-induced transformations.

Result: NTP consistently produces chemically active, polar, moderately textured surfaces that enhance protein adsorption and early cell adhesion; multimodal analysis enables identification of activation pathways and hydrophobic recovery dynamics.

Conclusion: Review provides roadmap for future research to standardize characterization workflows and enable rational design of plasma-functionalized biomaterials, addressing current gaps in unified protocols, temporal stability evaluation, and predictive models.

Abstract: Non-thermal plasma (NTP) surface activation has become a powerful and versatile strategy to engineer the interfacial properties of biomedical polymers whose intrinsic hydrophobicity limits their biological performance. In polymers such as polylactic acid (PLA) and polycarbonate (PC), NTP promotes the controlled incorporation of polar functional groups, increases surface energy, modifies dielectric behavior, and generates micro-roughness that collectively enhance protein adsorption and early cell adhesion. This review synthesizes and critically evaluates evidence across four complementary analytical pillars-contact-angle theory, dielectric impedance spectroscopy, FT-IR chemical mapping, and optical microscopy-to construct an integrated framework for interpreting plasma-induced chemical and morphological transformations.
  The convergence of multimodal results demonstrates that NTP consistently produces chemically active, polar, and moderately textured surfaces that support robust initial cell-material interactions. Furthermore, combining wettability, dielectric, and spectroscopic analysis enables the identification of activation pathways, the assessment of hydrophobic recovery dynamics, and the development of quantitative correlations between dielectric parameters and biological response. However, the literature also reveals key methodological gaps, including the limited use of unified multimodal protocols, insufficient evaluation of temporal stability, and a lack of predictive dielectric-biological models.
  By articulating these advances and limitations within a unified conceptual scheme, this review provides a roadmap for future research aimed at standardizing characterization workflows and enabling the rational design of next-generation plasma-functionalized biomaterials for tissue-engineering scaffolds, implantable devices, and advanced drug-delivery systems.

</details>


### [35] [Isotope Production in Fusion Systems](https://arxiv.org/abs/2512.09242)
*J. F. Parisi,J. A. Schwartz,S. E. Wurzel,A. Rutkowski,J. Harter*

Main category: physics.plasm-ph

TL;DR: Fusion systems can achieve economic viability before energy breakeven by co-producing high-value isotopes through neutron-driven transmutation, enabling smaller megawatt-scale systems for medical radioisotopes and larger plants for electricity and gold production.


<details>
  <summary>Details</summary>
Motivation: To expand the viable space for fusion energy concepts by demonstrating that economic viability can be achieved well before reaching energy breakeven through co-generation of high-value isotopes alongside electricity production.

Method: Calculated the value of co-generation and derived a new economic breakeven condition based on net present value. Analyzed transmutation of specific isotopes (Ru-102 to Mo-99 for medical use, mercury to gold) at different plasma gain levels. Proposed techniques to enhance transmutation including magnetic mirrors, asymmetric neutron wall loading, and neutron multiplication.

Result: At low plasma gain (Q_plas ≲ 1-3), pure transmuter fusion systems can be viable for medical radioisotope production (e.g., 3 MW system for global Mo-99 demand). At higher gain (Q_plas ≳ 3), co-production of electricity and isotopes becomes viable, reducing required plasma gain for viability from Q_plas ∼10-100 to Q_plas ∼3-5 for gold production.

Conclusion: Fusion neutron-driven transmutation offers a revenue-positive pathway for deploying fusion energy at terawatt-scale, starting from smaller megawatt-scale machines for radioisotope production and scaling up to larger plants co-producing electricity and valuable isotopes like gold.

Abstract: Fusion systems producing isotopes via neutron-driven transmutation can achieve economic viability well before reaching energy breakeven. Incorporating carefully selected feedstock materials within the blanket allows fusion systems to generate both electrical power and high-value isotopes, expanding the space of viable concepts, significantly enhancing the economic value of fusion energy, and supporting an accelerated path to adoption. We calculate the value of this co-generation and derive a new economic breakeven condition based on net present value. At lower plasma gain, $Q_{\mathrm{plas}}\lesssim1-3$, high-value transmutation, such as medical radioisotopes, enables pure transmuter fusion systems operating at only a few megawatts of fusion power: for example, a 3 megawatt system transmuting ${}^{102}\mathrm{Ru}\rightarrow{}^{99}\mathrm{Mo}$ could fulfill global ${}^{99}\mathrm{Mo}$ demand with $Q_{\mathrm{plas}}\ll1$. At higher gain $Q_{\mathrm{plas}}\gtrsim3$, it becomes viable to generate electricity in addition to isotopes. For example, co-production of electricity and gold, transmuted from mercury in a fusion blanket, can reduce the required plasma gain for viability from $Q_{\mathrm{plas}}\sim10-100$ to $Q_{\mathrm{plas}}\sim3-5$. We further highlight techniques to enhance transmutation including magnetic mirrors, asymmetric neutron wall loading, and neutron multiplication. Fusion neutron-driven transmutation therefore offers a revenue-positive pathway for deploying fusion energy at terawatt-scale, starting from smaller megawatt-scale machines for radioisotope production and then scaling up to co-producing electricity and gold in larger fusion power plants.

</details>


### [36] [On How Zonal Fields Suppress Reversed Shear Alfvén Eigenmode in Tokamak Plasmas](https://arxiv.org/abs/2512.09243)
*Ruirui Ma,Pengfei Liu,Liu Chen,Fulvio Zonca,Zhiyong Qiu*

Main category: physics.plasm-ph

TL;DR: Nonlinear suppression of reversed-shear Alfvén eigenmode occurs via downward frequency chirping induced by beat-driven zonal current, enhanced mode conversion to kinetic Alfvén waves, and increased radiative damping.


<details>
  <summary>Details</summary>
Motivation: To understand the nonlinear suppression and saturation mechanisms of reversed-shear Alfvén eigenmodes in plasma physics, particularly when energetic particle dynamics remain linear.

Method: Combined approach using nonlinear gyrokinetic simulations and theoretical analyses to investigate the saturation mechanism of reversed-shear Alfvén eigenmodes.

Result: Discovered that nonlinear suppression occurs through downward frequency chirping induced by beat-driven zonal current, leading to enhanced mode conversion to electron Landau-damped kinetic Alfvén waves and increased convective damping.

Conclusion: Theoretical results show good agreement with simulations, confirming that downward frequency chirping via beat-driven zonal current is the key mechanism for nonlinear suppression and saturation of reversed-shear Alfvén eigenmodes.

Abstract: Employing both nonlinear gyrokinetic simulations and theoretical analyses, we have discovered the novel result that, with energetic particle dynamics kept linear, the nonlinear suppression and eventual saturation of reversed-shear Alfvén eigenmode occur via the downward frequency chirping induced by the beat-driven zonal current. More specifically, as the mode frequency chirps downward, there is enhanced mode conversion to radially propagating electron Landau-damped kinetic Alfvén waves; resulting in enhanced convective (radiative) damping and, thereby, its suppression and saturation. Theoretical results are in good agreement with simulations both qualitatively and quantitatively.

</details>


### [37] [Generation of Polarization-Tunable Hybrid Cylindrical Vector gamma Rays](https://arxiv.org/abs/2512.09268)
*Si-Man Liu,Yue Cao,Kun Xue,Li-Xiang Hu,Xin-Yu Liu,Xin-Yan Li,Chao-Zhi Li,Xin-Rong Xu,Ke Liu,Wei-Quan Wang,De-Bin Zou,Yan Yin,Jian-Xing Li,Tong-Pu Yu*

Main category: physics.plasm-ph

TL;DR: Novel method generates cylindrical vector gamma rays with tunable hybrid polarization using rotating electron beams interacting with solid foils, achieving high polarization degrees over 60%.


<details>
  <summary>Details</summary>
Motivation: Cylindrical vector gamma rays offer spatially structured polarization as a new degree of freedom for fundamental research and applications, but their generation and control remain largely unexplored.

Method: Uses rotating electron beam interacting with solid foil to generate coherent transition radiation field, followed by gamma ray emission through nonlinear Compton scattering. Polarization control achieved by manipulating initial azimuthal momentum of the beam.

Result: 3D spin-resolved particle-in-cell simulations demonstrate continuous tuning of polarization angle across (-90°, 90°) with high polarization degree exceeding 60%.

Conclusion: This work contributes to structured gamma ray development, potentially opening new avenues in high-energy physics, nuclear science, and laboratory astrophysics.

Abstract: Cylindrical vector (CV) gamma rays can introduce spatially structured polarization as a new degree of freedom for fundamental research and practical applications. However, their generation and control remain largely unexplored. Here, we put forward a novel method to generate CV gamma rays with tunable hybrid polarization via a rotating electron beam interacting with a solid foil. In this process, the beam generates a coherent transition radiation field and subsequently emits gamma rays through nonlinear Compton scattering. By manipulating the initial azimuthal momentum of the beam, the polarization angle of gamma rays relative to the transverse momentum can be controlled, yielding tunable hybrid CV polarization states. Three-dimensional spin-resolved particle-in-cell simulations demonstrate continuous tuning of the polarization angle across (-90°, 90°) with a high polarization degree exceeding 60%. Our work contributes to the development of structured gamma rays, potentially opening new avenues in high-energy physics, nuclear science, and laboratory astrophysics.

</details>


### [38] [A Propagator-based Multi-level Monte Carlo Method for Kinetic Neutral Species in Edge Plasmas](https://arxiv.org/abs/2512.09334)
*Gregory J. Parker,Maxim V. Umansky,Benjamin D. Dudson*

Main category: physics.plasm-ph

TL;DR: A new multi-level Monte Carlo method for kinetic Boltzmann equations in edge plasmas that exploits frequent collisions with velocity determined by local plasma parameters, maintaining trajectory correlation for coupled plasma-neutral simulations.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient numerical method for solving kinetic Boltzmann equations for neutral species in edge plasmas that can maintain trajectory correlation in coupled plasma-neutral simulations, which is crucial for fully implicit Jacobian-free Newton-Krylov solvers.

Method: A multi-level Monte Carlo scheme based on collision event propagator that explicitly exploits the structural property of neutral particle dynamics where frequent collisions have outgoing velocities determined by local plasma parameters.

Result: The method reproduces results of standard Monte Carlo methods both analytically and numerically, and maintains trajectory correlation to machine precision in coupled plasma-neutral simulations, unlike conventional methods that exhibit rapid decorrelation.

Conclusion: The propagator-based multi-level Monte Carlo scheme is promising for use in fully implicit Jacobian-free Newton-Krylov solvers for coupled plasma-neutral systems due to its ability to maintain trajectory correlation.

Abstract: We propose and investigate a new multi-level Monte Carlo scheme for numerical solutions of the kinetic Boltzmann equation for neutral species in edge plasmas. In particular, this method explicitly exploits a key structural property of neutral particle dynamics: the prevalence of frequent collisions for which the outgoing velocity is determined by local plasma parameters. Using this property, we derive a multi-level algorithm based on collision event propagator and show, both analytically and through numerical experiments, that it reproduces the results of standard Monte Carlo methods. We further demonstrate that, in the context of coupled plasma-neutral edge simulations employing correlated Monte Carlo, the proposed scheme retains trajectory correlation to machine precision as the system evolves, whereas conventional methods exhibit rapid decorrelation. These results indicate that the propagator-based multi-level Monte Carlo scheme is a promising candidate for use in fully implicit Jacobian-free Newton-Krylov (JFNK) solvers for coupled plasma-neutral systems.

</details>


### [39] [Dynamics of an impulse dielectric barrier discharge in pure ammonia gas using electrical characteristics and imaging analysis](https://arxiv.org/abs/2512.09454)
*Ronny Jean-Marie-Desiree,Aymane Najah,Ludovic De Poucques,Stephane Cuynet*

Main category: physics.plasm-ph

TL;DR: Study characterizes glow nanosecond discharge in ammonia gas using fast imaging and electrical diagnostics, finding correlation between excitation/ionization wave velocity and rising current velocity in diffuse mode discharges.


<details>
  <summary>Details</summary>
Motivation: To investigate the dynamics of discharge establishment in plane-to-plane impulse dielectric barrier discharge (iDBD) with ammonia gas under various conditions of applied voltage, pressure, and gas gap.

Method: Employed fast imaging and electrical diagnostics to characterize glow nanosecond discharge, comparing current measurements with image analysis to study discharge dynamics.

Result: Found strong correlation between fast excitation/ionization wave velocity and rising current velocity in diffuse mode discharge, with systematic proportionality factor of 1.5×10⁻³ across studied conditions.

Conclusion: The correlation between luminous propagation front velocity and current rise velocity is systematic in diffuse mode discharges, warranting further investigation across more parameters to evaluate the relevance of the proportionality factor.

Abstract: A glow nanosecond discharge from a plane-to-plane impulse dielectric barrier discharge (iDBD) with ammonia gas has been characterised by employing fast imaging and electrical diagnostics. More precisely, the aim of this study is to investigate the dynamics of the discharge establishment under various conditions of applied voltage, pressure, and gas gap. The comparison between the current measurements and the image analysis exposes a strong correlation between the fast excitation and ionization wave velocity and the rising current velocity. This correlation has been found only for diffuse mode discharge since a front wave could be clearly defined, denoted as the luminous propagation front (LPF). Furthermore, this correlation is supported by a proportionality factor of 1.5 10$^{-3}$ which is systematic over the studied conditions. Further investigations are considered to evaluate the relevance of such a value over more parameters.

</details>


### [40] [Surface Ion-Sound Wave in Magnetic Arch With High Pressure Plasma](https://arxiv.org/abs/2512.09686)
*Sergey A. Koryagin,Mikhail E. Viktorov,Artem V. Korzhimanov,Andrey A. Elyasin*

Main category: physics.plasm-ph

TL;DR: Analytical substantiation of surface wave parameters in supersonic plasma flow collisions within magnetic arc, relevant to Solar Wind experiment setup.


<details>
  <summary>Details</summary>
Motivation: To analytically validate parameters of surface waves observed in numerical modeling of colliding supersonic plasma flows in magnetic arcs, specifically for the Solar Wind laboratory experiment at IAP RAS.

Method: Analytical substantiation of surface wave parameters based on numerical modeling results, focusing on ion-acoustic surface waves in dense plasma flows where dynamic pressure matches undisturbed magnetic field pressure.

Result: Identified ion-acoustic surface wave exists when plasma flow dynamic pressure equals undisturbed magnetic field pressure, with frequency between ion gyrofrequencies inside and outside plasma bundle. Structure consists of heterogeneous magnetic sound externally and isotropic ion sound internally, with energy concentrated in ion kinetic motion inside tube and enhanced electric field outside.

Conclusion: The surface wave structure in colliding supersonic plasma flows is analytically validated, showing distinct internal/external characteristics with energy primarily in ion kinetic motion inside and enhanced electric fields outside due to uniform electron drift and electrostatic ion oscillations.

Abstract: The work analytically substantiates the parameters of the surface wave found in numerical modelling of the collision of two oncoming supersonic plasma flows inside a magnetic arc in application to the experiment on the laboratory setup ``Solar Wind'' (Inst. Appl. Phys RAS). An ion-acoustic surface wave exists in the regime of dense plasma flows when their dynamic pressure is of the order of the pressure of an undisturbed magnetic field, so that the flows push the initial magnetic field out of their volume. The wave frequency is in the range between the ion gyrofrequencies inside the plasma bundle and in the outer region of the confining magnetic field. In the external rarefied medium, the near-surface structure is a heterogeneous magnetic sound, consistent in pressure and low total polarisation of the medium with the ``isotropic'' ion sound confined from the inside in a dense plasma bundle. The energy of the structure is mainly contained in the kinetic energy of the wave motion of ions inside the tube. At the same time, the electric field strength is sharply increased outside. Firstly, the latter circumstance arises from the need to maintain a uniform electron electric drift velocity inside the transition layer. Secondly, the energetically weak ion sound propagating into the outer environment is close to electrostatic ion oscillations below the ion gyrofrequency in the external region, which are characterised by increased electric field strength across the ambient magnetic field.

</details>


### [41] [Density of hybrid plasma generated by microwave and laser radiation in the Ar:H2:CH4 mixture](https://arxiv.org/abs/2512.09816)
*S. V. Avtaeva,V. B. Dolomanova,P. A. Pinaev,A. E. Medvedev*

Main category: physics.plasm-ph

TL;DR: Study of atmospheric-pressure hybrid plasma in Ar:H2:CH4 mixture using microwave and CO2 laser radiation for diamond-like coating synthesis, analyzing electron density via Hα line Stark broadening.


<details>
  <summary>Details</summary>
Motivation: To investigate the properties of hybrid plasma created by combined microwave and laser radiation for diamond-like coating synthesis applications, particularly focusing on electron density measurements and plasma homogeneity.

Method: Used atmospheric-pressure hybrid plasma in Ar:H2:CH4 mixture maintained by microwave radiation (2.47 GHz) and CO2 laser radiation (10.6 μm) in a plasma-chemical reactor. Electron number density was determined from Stark broadening of the Hα line shape of atomic hydrogen using two-contour Lorentz function approximation.

Result: When laser radiation is focused in the microwave plasma region, the Hα line shows broad wings and requires two-contour approximation, indicating spatiotemporal inhomogeneity. Electron densities were measured as (4-8)×10¹⁵ cm⁻³ for the narrower contour (exceeding microwave plasma density) and (1.5-2)×10¹⁷ cm⁻³ for the broader contour.

Conclusion: The hybrid plasma exhibits complex structure with significant spatiotemporal inhomogeneity, as evidenced by the two-contour Hα line profile. The combined microwave-laser approach creates plasma with electron densities spanning two orders of magnitude, which has implications for diamond-like coating synthesis processes.

Abstract: The atmospheric-pressure hybrid plasma in the Ar:H2:CH4 mixture, maintained by microwave radiation (2.47 GHz) and CO2 laser radiation (10.6 μm) in the chamber of an experimental plasma-chemical reactor designed to study the synthesis of diamond-like coatings was studied. The electron number density was determined from the Stark broadening of the Hα line shape of atomic hydrogen. It was shown that when laser radiation is focused in the region of a microwave plasma bunch, the Hα line shape in the hybrid plasma spectra has broad wings and is described by a Lorentz function with a two-contour approximation. The complex structure of the Hα line profile of the hybrid plasma indicates its spatiotemporal inhomogeneity. The electron number density corresponding to the contour with a smaller half-width exceeds the electron number density in microwave plasma and lies in the range of (4-8)E15 cm-3, and the electron number density measured by the contour with a larger half-width is (1.5-2)E17 cm-3.

</details>


### [42] [Damped Kinetic Alfvén Waves in Earth's Magnetosheath: Numerical Simulations and MMS Observations](https://arxiv.org/abs/2512.09828)
*Mani K. Chettri,Hemam D. Singh,Vivek Shrivastav,Britan Singh,Rupak Mukherjee*

Main category: physics.plasm-ph

TL;DR: Landau damping modifies kinetic Alfvén wave turbulence in Earth's magnetosheath, suppressing magnetic structures and steepening sub-ion scale spectra from k⊥⁻⁸/³ to k⊥⁻¹¹/³ while inertial range maintains k⊥⁻⁵/³ scaling.


<details>
  <summary>Details</summary>
Motivation: To understand how Landau damping affects the nonlinear evolution of kinetic Alfvén waves (KAWs) in Earth's high-β magnetosheath plasma, where wave-particle interactions control turbulent energy dissipation at kinetic scales.

Method: Solving a modified nonlinear Schrödinger equation that captures both dispersive and nonlinear effects of KAWs, with and without Landau damping terms, and comparing results with MMS spacecraft observations.

Result: Without damping: modulational instability drives self-focusing into magnetic filaments with k⊥⁻⁵/³ (inertial) → k⊥⁻⁸/³ (sub-ion) scaling. With damping: magnetic structures suppressed, spectrum steepens to k⊥⁻¹¹/³ in sub-ion range while inertial range maintains k⊥⁻⁵/³. MMS observations fall between undamped and damped limits.

Conclusion: Landau damping is a primary mechanism controlling turbulent energy dissipation at kinetic scales in collisionless plasmas, with observed magnetosheath turbulence consistent with an intermediate damping regime between undamped and strongly damped limits.

Abstract: The Earth's magnetosheath provides a high $β$ (ratio of electron thermal pressure to magnetic pressure) plasma environment where kinetic Alfvén waves (KAWs) strongly influence turbulence and energy dissipation. This study investigates how Landau damping modifies the nonlinear evolution of KAWs by solving a modified nonlinear Schrödinger equation that captures both dispersive and nonlinear effects. Without Landau damping, modulational instability drives rapid self-focusing into intense magnetic filaments, producing a turbulent cascade with $k_\perp^{-5/3}$ scaling in the inertial range ($k_\perpρ_i<1$) that transitions to $k_\perp^{-8/3}$ at sub-ion scales ($k_\perpρ_i>1$), here $k_\perp$ is the wavevector component perpendicular to the background magnetic field and $ρ_i$ the ion thermal gyroradius. When Landau damping is included, magnetic structures are significantly suppressed, and the spectrum steepens to $k_\perp^{-11/3}$ in the sub-ion range while the inertial range maintains $k_\perp^{-5/3}$ scaling. The damping acts across all scales through resonant wave-particle interactions, efficiently transferring energy from waves to particles. Direct comparison with Magnetospheric Multiscale (MMS) spacecraft observations shows that the observed kinetic range spectral slope falls between our undamped and damped simulation limits, consistent with an intermediate damping regime in magnetosheath turbulence. This agreement confirms that Landau damping is one of the primary mechanisms controlling turbulent energy dissipation at kinetic scales in collisionless plasmas.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [43] [Scalable Construction of Spiking Neural Networks using up to thousands of GPUs](https://arxiv.org/abs/2512.09502)
*Bruno Golosio,Gianmarco Tiddia,José Villamar,Luca Pontisso,Luca Sergi,Francesco Simula,Pooja Babu,Elena Pastorelli,Abigail Morrison,Markus Diesmann,Alessandro Lonardo,Pier Stanislao Paolucci,Johanna Senk*

Main category: cs.DC

TL;DR: Novel MPI-based network construction method for multi-GPU clusters enables efficient simulation of large-scale spiking neural networks on exascale supercomputers.


<details>
  <summary>Details</summary>
Motivation: Simulating large-scale spiking neural networks (inspired by the human cerebral cortex) requires efficient communication and memory management on high-performance computing clusters, especially for systems with billions of neurons and trillions of synapses.

Method: Developed a novel network construction method using MPI where each process builds local connectivity and prepares data structures for efficient spike exchange across the cluster during state propagation. Tested with both point-to-point and collective communication approaches.

Result: Demonstrated scaling performance of two cortical models using different communication strategies (point-to-point and collective communication) on multi-GPU clusters.

Conclusion: The method enables efficient simulation of large-scale spiking neural networks on current multi-GPU clusters and upcoming exascale supercomputers, addressing the computational challenges of neuroscience research at brain-scale.

Abstract: Diverse scientific and engineering research areas deal with discrete, time-stamped changes in large systems of interacting delay differential equations. Simulating such complex systems at scale on high-performance computing clusters demands efficient management of communication and memory. Inspired by the human cerebral cortex -- a sparsely connected network of $\mathcal{O}(10^{10})$ neurons, each forming $\mathcal{O}(10^{3})$--$\mathcal{O}(10^{4})$ synapses and communicating via short electrical pulses called spikes -- we study the simulation of large-scale spiking neural networks for computational neuroscience research. This work presents a novel network construction method for multi-GPU clusters and upcoming exascale supercomputers using the Message Passing Interface (MPI), where each process builds its local connectivity and prepares the data structures for efficient spike exchange across the cluster during state propagation. We demonstrate scaling performance of two cortical models using point-to-point and collective communication, respectively.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [44] [Frequency-Dependent Polarization Propagator Calculation for Quantum Dots Using Optimized Inverse Krylov Subspace and Folded-Spectrum Method](https://arxiv.org/abs/2512.09811)
*Chandler Martin,Nicole Spanedda,Anaira Jalan,Emily Schafer,Jessica Beyer,Arindam Chakraborty*

Main category: physics.chem-ph

TL;DR: Developed efficient frequency-dependent polarization propagator method for quantum dots using inverse Krylov subspace projection to compute excitation spectra without full diagonalization.


<details>
  <summary>Details</summary>
Motivation: Accurate prediction of quantum dot frequency response is crucial for studying absorption spectra and optical properties, but current polarization propagator methods are computationally demanding due to electron correlation, large excitonic basis, and expensive two-electron integrals.

Method: Developed first- and second-order frequency-dependent polarization propagator calculations using electron propagator approach. Used MP2 for correlated ground state, included all response-matrix terms up to second order. Implemented frequency-dependent inverse Krylov subspace method with folded-spectrum technique to isolate excitation energies within chosen frequency window. Method is matrix-free, relying on matrix-vector products without assembling explicit response matrix.

Result: Computed UV-VIS excitation spectra of PbS and CdS quantum dots. The inverse Krylov subspace projection approach provides efficient and accurate approximation for excitation spectra when full diagonalization is computationally prohibitive.

Conclusion: The developed method successfully addresses computational challenges in quantum dot spectroscopy by avoiding full diagonalization of response matrix, significantly reducing computational cost while maintaining accuracy for large systems.

Abstract: Accurate prediction of the frequency response of quantum dots under electromagnetic radiation is essential for investigating absorption spectra, excitonic effects, and nonlinear optical behavior in quantum dots and semiconductor nanoparticles. The polarization propagator provides a rigorous framework for evaluating these properties, but its construction is computationally demanding. Challenges arise from the level of electron correlation, the size of the excitonic basis, and the cost of evaluating two-electron integrals. This work addresses these difficulties by developing first- and second-order frequency-dependent polarization propagator calculations for PbS and CdS quantum dots. The propagator is formulated using the electron propagator approach and expressed as the resolvent of the Hamiltonian superoperator. Light-matter interaction is treated using the dipole approximation and represented in a particle-hole excitation operator basis. The correlated ground state is treated at the MP2 level, and all response-matrix terms up to second order in the fluctuating potential are included. A frequency-dependent inverse Krylov subspace method is derived and combined with the folded-spectrum technique to isolate excitation energies within a chosen frequency window. This strategy avoids full diagonalization of the response matrix and significantly reduces computational cost for large systems. The method is implemented in a matrix-free manner in which no explicit response matrix is assembled, and all operations rely on matrix-vector products. UV-VIS excitation spectra of PbS and CdS quantum dots were computed, demonstrating that the inverse Krylov subspace projection approach provides an efficient and accurate approximation for excitation spectra when full diagonalization is computationally prohibitive.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [45] [Py-DiSMech: A Scalable and Efficient Framework for Discrete Differential Geometry-Based Modeling and Control of Soft Robots](https://arxiv.org/abs/2512.09911)
*Radha Lahoti,Ryan Chaiyakul,M. Khalid Jawed*

Main category: cs.RO

TL;DR: Py-DiSMech is a Python-based open-source simulation framework for soft robots using Discrete Differential Geometry principles, offering high-fidelity simulation with computational efficiency, contact modeling, control modules, and modular design.


<details>
  <summary>Details</summary>
Motivation: High-fidelity simulation is essential for soft robot design and control, but conventional tools struggle with large deformations and complex contacts. There's a need for frameworks that combine physical accuracy, computational scalability, and integration with modern control/optimization pipelines.

Method: Py-DiSMech uses Discrete Differential Geometry principles to discretize geometric quantities (curvature, strain) directly on meshes. It features: 1) fully vectorized NumPy implementation for speed, 2) penalty-energy-based implicit contact model for various interactions, 3) natural-strain-based PI feedback control, and 4) modular object-oriented design.

Result: Benchmark comparisons show Py-DiSMech substantially outperforms state-of-the-art simulator Elastica in computational efficiency while maintaining physical accuracy. It achieves order-of-magnitude speed-ups over existing geometry-based simulators.

Conclusion: Py-DiSMech establishes itself as a scalable, extensible platform for simulation-driven design, control validation, and sim-to-real research in soft robotics, addressing key challenges in the field.

Abstract: High-fidelity simulation has become essential to the design and control of soft robots, where large geometric deformations and complex contact interactions challenge conventional modeling tools. Recent advances in the field demand simulation frameworks that combine physical accuracy, computational scalability, and seamless integration with modern control and optimization pipelines. In this work, we present Py-DiSMech, a Python-based, open-source simulation framework for modeling and control of soft robotic structures grounded in the principles of Discrete Differential Geometry (DDG). By discretizing geometric quantities such as curvature and strain directly on meshes, Py-DiSMech captures the nonlinear deformation of rods, shells, and hybrid structures with high fidelity and reduced computational cost. The framework introduces (i) a fully vectorized NumPy implementation achieving order-of-magnitude speed-ups over existing geometry-based simulators; (ii) a penalty-energy-based fully implicit contact model that supports rod-rod, rod-shell, and shell-shell interactions; (iii) a natural-strain-based feedback-control module featuring a proportional-integral (PI) controller for shape regulation and trajectory tracking; and (iv) a modular, object-oriented software design enabling user-defined elastic energies, actuation schemes, and integration with machine-learning libraries. Benchmark comparisons demonstrate that Py-DiSMech substantially outperforms the state-of-the-art simulator Elastica in computational efficiency while maintaining physical accuracy. Together, these features establish Py-DiSMech as a scalable, extensible platform for simulation-driven design, control validation, and sim-to-real research in soft robotics.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [46] [Geometric invariants and the Monge-Ampere equation in Kähler geometry](https://arxiv.org/abs/2512.09068)
*Bin Guo,Duong H. Phong*

Main category: math.DG

TL;DR: Survey paper celebrating Yau's 75th birthday, covering new geometric inequalities and Monge-Ampere estimates, plus overview of current complex geometry directions.


<details>
  <summary>Details</summary>
Motivation: To honor Shing-Tung Yau's 75th birthday and his foundational contributions to complex geometry, particularly his solution to the Calabi conjecture which has been essential for many subsequent developments.

Method: Survey methodology focusing on recent geometric inequalities and estimates for Monge-Ampere equations developed through joint work with collaborators. Also includes brief survey of current research directions in complex geometry pioneered by Yau.

Result: Comprehensive overview of new results in geometric inequalities and Monge-Ampere estimates that fundamentally depend on Yau's Calabi conjecture solution, along with mapping of current research landscape in complex geometry.

Conclusion: Yau's solution to the Calabi conjecture remains foundational after nearly 50 years, enabling significant advances in geometric analysis and complex geometry, with ongoing impact on current research directions.

Abstract: This is a contribution to the special issue of Surveys in Differential Geometry celebrating the 75th birthday of Shing-Tung Yau. The bulk of the paper is devoted to a survey of some new geometric inequalities and estimates for the Monge-Ampere equation, obtained by the authors in the last few years in joint work with F. Tong, J. Song, and J. Sturm. These all depend in an essential way on Yau's solution of the Calabi conjecture, which is itself nearing its own 50th birthday. The opportunity is also taken to survey briefly many current directions in complex geometry, which he more recently pioneered.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [47] [Simulating surfactant effects in phase-transforming fluids](https://arxiv.org/abs/2512.09140)
*Keyu Feng,Saikat Mukherjee,Tianyi Hu,Hector Gomez*

Main category: physics.flu-dyn

TL;DR: A first-principles computational model for studying surfactant effects on liquid-vapor phase transformations, validated through bubble simulations and interface oscillation studies.


<details>
  <summary>Details</summary>
Motivation: Surfactants play crucial roles in natural and engineering processes, but measuring their concentrations under non-equilibrium flow conditions is difficult. Existing models rely on phenomenological assumptions, creating challenges for predicting surfactant effects on liquid-vapor transformations involving mass transfer, non-equilibrium thermodynamics, and Marangoni stresses.

Method: Developed a first-principles model of liquid-vapor flows with surfactants starting from the Navier-Stokes-Korteweg equations. Performed simulations of bubbles under equilibrium conditions and liquid-vapor interface oscillations to validate the model.

Result: The model successfully reproduces surfactant-mediated reductions in surface tension. The study also investigated mechanisms of surfactant effects on bubble coalescence and condensation, demonstrating the framework's capability to capture complex surfactant dynamics.

Conclusion: This work provides a new first-principles framework for studying surfactant effects on liquid-vapor transformations, opening avenues for future research including complex surface chemistries' impact on bubble flow and acoustic response of surfactant-laden bubbles.

Abstract: Surfactants are critical in natural processes and engineering, but measuring their concentrations in non-equilibrium conditions and in the presence of flow is difficult. Therefore, computational methods are a key tool for improving our understanding. Predicting the effect of surfactants on liquid-vapor transformations is particularly challenging due to (1) simultaneous mass transfer, non-equilibrium thermodynamics and Marangoni stresses, and (2) the phenomenological assumptions underlying many liquid-vapor phase-change models. Starting from the Navier-Stokes-Korteweg equations, a first-principles approach to liquid-vapor phase transformations, we developed a model of liquid-vapor flows with surfactants. We performed simulations of bubbles under equilibrium and liquid-vapor interface oscillations to demonstrate that the model successfully reproduces surfactant-mediated reductions in surface tension. We also investigated the mechanisms whereby surfactant affects bubble coalescence and condensation. Overall, this work provides a new framework for studying the effect of surfactants on liquid-vapor transformations and suggests multiple areas for future research, including the impact of complex surface chemistries on flow around bubbles and the acoustic response of bubbles with surfactants.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [48] [A Benamou-Brenier Proximal Splitting Method for Constrained Unbalanced Optimal Transport](https://arxiv.org/abs/2512.09250)
*Mao Nishino,Martin Bauer,Tom Needham,Nicolas Charon*

Main category: math.OC

TL;DR: The paper proposes a generalized constrained Wasserstein-Fisher-Rao (WFR) optimal transport framework that extends beyond density constraints to include momentum and source terms, and incorporates both equality and inequality constraints.


<details>
  <summary>Details</summary>
Motivation: To develop a more flexible optimal transport framework that can handle practical constraints beyond just mass conservation, allowing for real-world applications where constraints apply to momentum and source terms, and where both equality and inequality constraints are needed.

Method: Extends the constrained WFR model by allowing constraints on density, momentum, and source terms, incorporating both affine equality and inequality constraints. Proves well-posedness under suitable assumptions and develops a numerical pipeline using finite difference discretizations and parallel proximal schemes.

Result: Establishes well-posedness of the generalized constrained WFR problems and develops an effective computational framework that handles various constraint types. Demonstrates versatility through synthetic and real data examples.

Conclusion: The proposed framework provides a comprehensive and flexible approach to constrained optimal transport that encompasses standard balanced/unbalanced transport and enables practical applications with diverse constraint requirements.

Abstract: The dynamic formulation of optimal transport, also known as the Benamou-Brenier formulation, has been extended to the unbalanced case by introducing a source term in the continuity equation. When this source term is penalized based on the Fisher-Rao metric, the resulting model is referred to as the Wasserstein-Fisher-Rao (WFR) setting, and allows for the comparison between any two positive measures without the need for equalized total mass. In recent work, we introduced a constrained variant of this model, in which affine integral equality constraints are imposed along the measure path. In the present paper, we propose a further generalization of this framework, which allows for constraints that apply not just to the density path but also to the momentum and source terms, and incorporates affine inequalities in addition to equality constraints. We prove, under suitable assumptions on the constraints, the well-posedness of the resulting class of convex variational problems. The paper is then primarily devoted to developing an effective numerical pipeline that tackles the corresponding constrained optimization problem based on finite difference discretizations and parallel proximal schemes. Our proposed framework encompasses standard balanced and unbalanced optimal transport, as well as a multitude of natural and practically relevant constraints, and we highlight its versatility via several synthetic and real data examples.

</details>


### [49] [Computer-Assisted Search for Differential Equations Corresponding to Optimization Methods and Their Convergence Rates](https://arxiv.org/abs/2512.09712)
*Atsushi Tabei,Ken'ichiro Tanaka*

Main category: math.OC

TL;DR: A systematic computational framework using symbolic computation to optimize Lyapunov functions for analyzing convergence rates of continuous dynamical systems in convex optimization.


<details>
  <summary>Details</summary>
Motivation: Existing methods for designing Lyapunov functions to analyze convergence rates of continuous dynamical systems (like gradient descent) are heuristic and involve arbitrary choices. While recent work improved the process, it still lacks systematic exploration of optimal Lyapunov functions for best convergence rates.

Method: Proposes a brute-force computational approach using symbolic computation via computer algebra systems. Formulates Lyapunov function design as an optimization problem to systematically explore all possibilities and optimize the Lyapunov function itself.

Result: The framework successfully reproduces many previously reported convergence rate results and discovers new convergence rates not shown in existing studies.

Conclusion: The computational approach provides a systematic way to optimize Lyapunov functions for continuous dynamical systems, moving beyond heuristic methods and enabling discovery of improved convergence rates.

Abstract: Let $f:\mathbb{R}^n \to \mathbb{R}$ be a continuously differentiable convex function with its minimizer denoted by $x_*$ and optimal value $f_* = f(x_*)$. Optimization algorithms such as the gradient descent method can often be interpreted in the continuous-time limit as differential equations known as continuous dynamical systems. Analyzing the convergence rate of $f(x) - f_*$ in such systems often relies on constructing appropriate Lyapunov functions. However, these Lyapunov functions have been designed through heuristic reasoning rather than a systematic framework. Several studies have addressed this issue. In particular, Suh, Roh, and Ryu (2022) proposed a constructive approach that involves introducing dilated coordinates and applying integration by parts. Although this method significantly improves the process of designing Lyapunov functions, it still involves arbitrary choices among many possible options, and thus retains a heuristic nature in identifying Lyapunov functions that yield the best convergence rates. In this study, we propose a systematic framework for exploring these choices computationally. More precisely, we propose a brute-force approach using symbolic computation by computer algebra systems to explore every possibility. By formulating the design of Lyapunov functions for continuous dynamical systems as an optimization problem, we aim to optimize the Lyapunov function itself. As a result, our framework successfully reproduces many previously reported results and, in several cases, discovers new convergence rates that have not been shown in the existing studies.

</details>


### [50] [On Parameter Identification in Three-Dimensional Elasticity and Discretisation with Physics-Informed Neural Networks](https://arxiv.org/abs/2512.09754)
*Federica Caforio,Martin Holler,Matthias Höfler*

Main category: math.OC

TL;DR: PINNs for 3D elasticity inverse problems with stability guarantees and comparison to mesh-based methods


<details>
  <summary>Details</summary>
Motivation: Address challenges in PINNs (training stability, lack of theoretical guarantees) for inverse problems in 3D elasticity, particularly relevant for cardiac biomechanics diagnosis

Method: All-at-once optimization framework estimating state and parameter simultaneously using least-squares loss encoding data and physics; neural network discretization compared to mesh-based approaches

Result: Proved stability estimates ensuring stable approximation of ground-truth parameter independent of discretization; theoretical findings complemented by numerical examples

Conclusion: Provides theoretical foundation for PINNs in inverse elasticity problems with stability guarantees, bridging gap between empirical success and rigorous theory

Abstract: Physics-informed neural networks have emerged as a powerful tool in the scientific machine learning community, with applications to both forward and inverse problems. While they have shown considerable empirical success, significant challenges remain -- particularly regarding training stability and the lack of rigorous theoretical guarantees, especially when compared to classical mesh-based methods. In this work, we focus on the inverse problem of identifying a spatially varying parameter in a constitutive model of three-dimensional elasticity, using measurements of the system's state. This setting is especially relevant for non-invasive diagnosis in cardiac biomechanics, where one must also carefully account for the type of boundary data available. To address this inverse problem, we adopt an all-at-once optimisation framework, simultaneously estimating the state and parameter through a least-squares loss that encodes both available data and the governing physics. For this formulation, we prove stability estimates ensuring that our approach yields a stable approximation of the underlying ground-truth parameter of the physical system independent of a specific discretisation. We then proceed with a neural network-based discretisation and compare it to traditional mesh-based approaches. Our theoretical findings are complemented by illustrative numerical examples.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [51] [Predicting tunable nonreciprocal spin wave generation mediated by interfacial Dzyaloshinskii-Moriya interaction in magnonic heterostructures](https://arxiv.org/abs/2512.09240)
*Cameron A McEleney,Karen L Livesey,Robert E Camley,Rair Macêdo*

Main category: cond-mat.mtrl-sci

TL;DR: Theoretical study shows how to tune spin wave nonreciprocity in thin magnetic films with iDMI using driving parameters, and proposes a hybrid geometry to overcome short propagation distances.


<details>
  <summary>Details</summary>
Motivation: Thin metallic magnetic films with interfacial Dzyaloshinskii-Moriya interaction (iDMI) support nonreciprocal spin waves but suffer from high damping, limiting propagation distances to less than one micrometer.

Method: Theoretical study of thin ferromagnetic strip with iDMI, using spin-wave-dispersion calculations with an "overlap function" and micromagnetic simulations to analyze spin wave excitation from a central driving segment.

Result: Changing driving segment width, frequency, and applied field strength tunes spin wave nonreciprocity. The overlap function method predicts maximum nonreciprocity conditions without computational solvers. A hybrid geometry with iDMI only in driving region and low-damping materials elsewhere enables significant spin wave amplitudes over several microns.

Conclusion: The study provides a predictive framework for tuning spin wave nonreciprocity in iDMI systems and proposes a practical solution to overcome propagation distance limitations through hybrid material geometries.

Abstract: Thin, metallic magnetic films can support nonreciprocal spin waves due to the interfacial Dzyaloshinskii-Moriya interaction (iDMI). However, these films typically have high damping, making spin wave propagation distances short (less than one micrometer). In this work, we theoretically study a thin ferromagnetic strip with iDMI and excite spin waves by driving a central segment of the strip. Spin waves propagate with different amplitudes to the left versus to the right from the driving region (i.e. nonreciprocity occurs) due to the iDMI. Our calculation based on spin-wave-dispersion plus our micromagnetic simulations both show that changing the driving segment width, driving frequency and static applied field strength tunes the nonreciprocity. Our calculation based on spin-wave-dispersion, using a so-called "overlap function" will allow researchers to predict conditions of maximum nonreciprocity, without the need for computational solvers. Moreover, to circumvent the issue of short propagation distances, we propose a geometry where iDMI is only present in the driving region and low-damping materials comprise the remainder of the strip. Our calculations show significant spin wave amplitudes over several microns from the excitation region.

</details>


### [52] [Structural Optimization in Tensor LEED Using a Parameter Tree and $R$-Factor Gradients](https://arxiv.org/abs/2512.09737)
*Alexander M. Imre,Paul Haidegger,Florian Kraushofer,Ralf Wanzenböck,Tobias Hable,Sarah Tobisch,Marie Kienzer,Florian Buchner,Jesús Carrete,Georg K. H. Madsen,Michael Schmid,Ulrike Diebold,Michele Riva*

Main category: cond-mat.mtrl-sci

TL;DR: New tensor-LEED implementation using tree-based data structure and JAX enables faster surface-structure optimization with GPU support and gradient access.


<details>
  <summary>Details</summary>
Motivation: Quantitative LEED is computationally demanding for surface-structure optimization due to many intensity evaluations needed, even with tensor-LEED approximation. Complex structure optimization remains tedious.

Method: Reformulates surface-structure optimization using tree-based data structure to avoid redundant evaluations. New tensor-LEED implementation computes intensities on-the-fly, uses JAX library for gradient access and GPU execution, and enables modern optimization algorithms.

Result: Computing time reduced by more than an order of magnitude compared to previous methods.

Conclusion: The new implementation significantly accelerates surface-structure determination by LEED, making complex structure optimization more efficient through modern computational approaches.

Abstract: Quantitative low-energy electron diffraction [LEED $I(V)$] is a powerful method for surface-structure determination, based on a direct comparison of experimentally observed $I(V)$ data with computations for a structure model. As the diffraction intensities $I$ are highly sensitive to subtle structural changes, local structure optimization is essential for assessing the validity of a structure model and finding the best-fit structure. The calculation of diffraction intensities is well established, but the large number of evaluations required for reliable structural optimization renders it computationally demanding. The computational effort is mitigated by the tensor-LEED approximation, which accelerates optimization by applying a perturbative treatment of small deviations from a reference structure. Nevertheless, optimization of complex structures is a tedious process.
  Here, the problem of surface-structure optimization is reformulated using a tree-based data structure, which helps to avoid redundant function evaluations. In the new tensor-LEED implementation presented in this work, intensities are computed on the fly, eliminating limitations of previous algorithms that are limited to precomputed values at a grid of search parameters. It also enables the use of state-of-the-art optimization algorithms. Implemented in \textsc{Python} with the JAX library, the method provides access to gradients of the $R$ factor and supports execution on graphics processing units (GPUs). Based on these developments, the computing time can be reduced by more than an order of magnitude.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [53] [Exact Screening-Ranged Expansions for Many-Body Electrostatics](https://arxiv.org/abs/2512.09421)
*Sergii V. Siryk,Walter Rocchia*

Main category: cond-mat.soft

TL;DR: Exact many-body framework for electrostatic interactions among charged spheres in electrolyte using spectral analysis and convergent screening-ranged series.


<details>
  <summary>Details</summary>
Motivation: To develop a rigorous analytical framework for electrostatic interactions among arbitrarily charged spheres in electrolyte, capturing complex effects that remain analytically elusive in existing treatments.

Method: Builds on spectral analysis of Neumann-Poincaré-type operators to construct convergent screening-ranged series for potential, interaction energy, and forces, where each term corresponds to a Debye-Hückel screening order and can be evaluated analytically.

Result: Unifies and extends classical and recent approaches, provides rigorous basis for electrostatic interactions among heterogeneously charged particles, yields many-body generalizations of analytical closed-form results previously available only for two-body systems.

Conclusion: The framework captures complex effects like asymmetric dielectric screening, opposite-charge repulsion, and like-charge attraction, and leads to numerically efficient schemes for modeling colloids and soft/biological matter in electrolytic solution.

Abstract: We present an exact many-body framework for electrostatic interactions among $N$ arbitrarily charged spheres in an electrolyte, modeled by the linearized Poisson--Boltzmann equation. Building on a spectral analysis of nonstandard Neumann--Poincaré-type operators introduced in a companion mathematical work~\cite{supplem_pre_math}, we construct convergent screening-ranged series for the potential, interaction energy, and forces, where each term is associated with a well-defined Debye--Hückel screening order and can be obtained evaluating an analytical expression rather than numerically solving an infinitely dimensional linear system. This formulation unifies and extends classical and recent approaches, providing a rigorous basis for electrostatic interactions among heterogeneously charged particles (including Janus colloids) and yielding many-body generalizations of analytical closed-form results previously available only for two-body systems. The framework captures and clarifies complex effects such as asymmetric dielectric screening, opposite-charge repulsion, and like-charge attraction, which remain largely analytically elusive in existing treatments. Beyond its fundamental significance, the method leads to numerically efficient schemes, offering a versatile tool for modeling colloids and soft/biological matter in electrolytic solution.

</details>


### [54] [Modeling Complex Multiphysics Systems with Discrete Element Method Enriched with the Kernel-Independent Fast Multipole Method](https://arxiv.org/abs/2512.09478)
*Igor A. Ostanin*

Main category: cond-mat.soft

TL;DR: Coupling MercuryDPM DEM with kernel-independent fast multipole method (KIFMM) for multiscale simulations combining fine-scale particulate mechanics with long-range electrostatic, magnetic, and gravitational interactions.


<details>
  <summary>Details</summary>
Motivation: To address multiscale problems that require both fine-scale mechanical interactions of particulates and coarse-scale long-range interactions of various natures (electrostatic, magnetic, gravitational) in a unified simulation framework.

Method: Coupling the MercuryDPM discrete element method code with implementation of kernel-independent fast multipole method (KIFMM), combined with formalism of rigid clumps for non-spherical particles with arbitrary charge distributions.

Result: Successfully developed combined simulation framework capable of handling multiscale problems involving both particulate mechanics and long-range interactions, demonstrated through several application examples.

Conclusion: The MercuryDPM-KIFMM coupling enables efficient simulation of complex multiscale problems involving non-spherical particles with various long-range interactions, expanding capabilities for modeling electrostatic powders, magnetic granulates, asteroid clouds, and similar systems.

Abstract: The paper describes the coupling of the MercuryDPM discrete element method (DEM) code and the implementation of the kernel-independent fast multipole method (KIFMM). The combined simulation framework allows addressing the large class of multiscale problems, including both the mechanical interactions of particulates at the fine scale and the long-range interactions of various natures at the coarse scale. Among these are electrostatic interactions in powders, clays, and particulates, magnetic interactions in ferromagnetic granulates, and gravitational interactions in asteroid clouds. The formalism of rigid clumps is successfully combined with KIFMM, enabling addressing problems involving complex long-large interactions between non-spherical particles with arbitrary charge distributions. The capabilities of our technique are demonstrated in several application examples.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [55] [Rotational excitation of molecules in the regime of strong ro-vibrational coupling: Comparison between an optical centrifuge and a transform-limited pulse](https://arxiv.org/abs/2512.09746)
*J. M. García-Garrido,V. Milner,C. P. Koch,R. González-Férez*

Main category: quant-ph

TL;DR: Optical centrifuge enables controlled high rotational excitation with minimal vibrational broadening, unlike linear Gaussian pulses which cause significant vibrational wavepacket spread.


<details>
  <summary>Details</summary>
Motivation: To investigate the ability of optical centrifuge laser pulses to control molecular rotation when the rigid-rotor approximation breaks down due to vibrational-rotational coupling, and to compare this approach with traditional linearly polarized Gaussian pulses.

Method: Theoretical investigation of optical centrifuge pulses - laser pulses with linear polarization rotating at an accelerated rate - for controlling molecular rotation beyond the rigid-rotor approximation regime. Comparison with linearly polarized Gaussian pulses of equal spectral width and pulse energy.

Result: Optical centrifuge enables controlled excitation of high rotational states while maintaining relatively low spread along the vibrational coordinate. In contrast, rotational excitation by linearly polarized Gaussian pulses, although comparable in rotational excitation, is unavoidably accompanied by substantial broadening of the vibrational wavepacket.

Conclusion: Optical centrifuge provides superior control over molecular rotation in regimes where vibrational-rotational coupling is significant, offering a method to achieve high rotational excitation with minimal vibrational disturbance compared to conventional linearly polarized pulses.

Abstract: We investigate theoretically the ability of an optical centrifuge - a laser pulse whose linear polarization is rotating at an accelerated rate, to control molecular rotation in the regime when the rigid-rotor approximation breaks down due to coupling between the vibrational and rotational degrees of freedom. Our analysis demonstrates that the centrifuge field enables controlled excitation of high rotational states while maintaining relatively low spread along the vibrational coordinate. We contrast this to the rotational excitation by a linearly polarized Gaussian pulse of equal spectral width and pulse energy which, although comparable to the centrifuge-induced rotation, is unavoidably accompanied by a substantial broadening of the vibrational wavepacket.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [56] [Tracing a Multi-Temperature Quiescent Prominence's Thermodynamic Evolution from Sun to Earth](https://arxiv.org/abs/2512.09234)
*Callie A. García,Yeimy J. Rivera,Samuel T. Badman,John C. Raymond,Katharine K. Reeves,Tatiana Niembro,Kristoff W. Paulson,Michael L. Stevens*

Main category: astro-ph.SR

TL;DR: Rare case study of a solar prominence eruption that maintains low-ionized state during CME, tracked from Sun to in situ detection at 1 AU, revealing multi-thermal composition.


<details>
  <summary>Details</summary>
Motivation: Prominences are rarely detected in cool, low-ionized states within CMEs measured in situ, making their thermodynamic evolution difficult to study. This paper examines one of these rare cases to understand how prominences evolve during eruptions.

Method: Used multi-viewpoint Extreme Ultraviolet (EUV) observations to track and estimate density, temperature, and speed of the prominence during eruption. Applied simulated non-equilibrium ionization and recombination models using observationally derived initial conditions.

Result: The prominence maintained low-ionized charge states during eruption, with in situ detection showing both cool, low-ionized ions and hotter plasma (Fe16+). Simulations matched the multi-thermal state with 70% cool plasma (1.8MK peak) and 30% hot plasma (4.3MK peak).

Conclusion: The prominence has complex multi-thermal nature, suggesting non-uniform heating or differential cooling. Findings emphasize the need for more comprehensive spectral observations of the global corona to understand prominence evolution during eruptions.

Abstract: Solar prominences are cool, dense stable structures routinely observed in the corona. Prominences are often ejected from the Sun via coronal mass ejections (CMEs). However, they are rarely detected in a cool, low-ionized state within CMEs measured in situ, making their evolution hard to study. We examine the thermodynamic evolution of one of these rare cases where a quiescent prominence eruption clearly preserves its low-ionized charge state as evidenced by in situ detection. We use multi-viewpoint Extreme Ultraviolet (EUV) observations to track and estimate the density, temperature and speed of the prominence as it erupts. We observe that part of the prominence remains in absorption well beyond initial liftoff, indicating the bulk of the prominence experiences minimal ionization and suggesting any strong heating is balanced by radiative losses, expansion, or conduction. From its subsequent in situ passage near 1au, charge states reveal that the prominence is composed of both cool, low-ionized ions as well as hotter plasma reflected by the presence of highly ionized iron, Fe$^{16+}$. Simulated non-equilibrium ionization and recombination results using observationally derived initial conditions match the in situ multi-thermal state for a prominence composed of 70% cool plasma with a 1.8MK peak temperature, and 30% hot plasma with a 4.3MK peak temperature. This suggests that the prominence may not be heated uniformly or that parts of it cools more rapidly. The complex, multi-thermal nature of this erupting prominence emphasizes the need for more comprehensive spectral observations of the global corona.

</details>


### [57] [Ultimate large-$Rm$ regime of the solar dynamo](https://arxiv.org/abs/2512.09536)
*François Rincon*

Main category: astro-ph.SR

TL;DR: The paper identifies an asymptotic ultimate regime for large-scale solar dynamos involving helicity fluxes between hemispheres, achievable only in simplified simulations, while current global simulations remain in non-asymptotic regimes sensitive to Reynolds numbers.


<details>
  <summary>Details</summary>
Motivation: To understand how large-scale magnetic fields emerge from turbulent flows in rotating astrophysical systems like the Sun, which has been a major computational astrophysics challenge for over 40 years.

Method: Used parameter scans and phenomenological analysis of maximally-simplified 3D Cartesian magnetohydrodynamic simulations of large-scale nonlinear helical turbulent dynamos, obtaining numerical solutions at both Pm>1 and Pm<1 magnetic Prandtl numbers.

Result: Identified an asymptotic ultimate regime involving helicity fluxes between hemispheres at large magnetic Reynolds numbers; showed current global simulations are in non-asymptotic regimes highly sensitive to Reynolds numbers; presented ideas to reach ultimate regime in realistic global models.

Conclusion: The results clarify current limitations of brute-force numerical modeling for astrophysical turbulence problems and show that achieving the ultimate dynamo regime requires clean, simplified setups not yet possible in realistic global simulations.

Abstract: For more than fourty years, the quest to understand how large-scale magnetic fields emerge from turbulent flows in rotating astrophysical systems, such as the Sun, has been a major thread of computational astrophysics research. Using a parameter scan and phenomenological analysis of maximally-simplified three-dimensional cartesian magnetohydrodynamic simulations of large-scale nonlinear helical turbulent dynamos, I present results in this Letter that strongly point to an asymptotic ultimate regime of the large-scale solar dynamo, at large magnetic Reynolds numbers $Rm$, involving helicity fluxes between hemispheres. I obtained corresponding numerical solutions at both $Pm>1$ and $Pm<1$, and show that they can currently only be achieved in clean, simplified numerical setups. The analysis further strongly suggests that all global simulations to date lie in a non-asymptotic turbulent MHD regimes highly sensitive to changes in kinetic and magnetic Reynolds numbers. Ideas are presented to attempt to reach this ultimate regime in such "realistic" global spherical models at a reasonable numerical cost. Overall, the results clarify the current state, and some hard limitations of the brute-force numerical modelling approach applied to this, and other similar astrophysical turbulence problems.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [58] [Non-Equilibrium Thermodynamics of Black-Hole Coronae: QPOs, Turbulence, and Jets](https://arxiv.org/abs/2512.09026)
*Vanessa López-Barquero,Alejandro Jenkins,Christopher S. Reynolds,Andrew Fabian*

Main category: astro-ph.HE

TL;DR: The paper proposes a non-equilibrium thermodynamics framework where coronal variability in black hole systems arises from feedback between plasma oscillations and Compton cooling, acting as a heat engine that can explain QPOs and power turbulence/jets.


<details>
  <summary>Details</summary>
Motivation: To explain the complex nonlinear dynamics observed in accreting black hole systems, particularly quasi-periodic oscillations (QPOs), without needing to invoke external resonant driving mechanisms.

Method: A theoretical framework based on non-equilibrium thermodynamics, modeling the corona as a heat engine with feedback between macroscopic plasma oscillations and inverse Compton cooling of soft photons from the accretion disc (the "pair thermostat" mechanism).

Result: The proposed mechanism can explain QPOs as self-oscillations of the corona, and potentially provides the power to generate turbulence and jets in the corona without external driving forces.

Conclusion: The corona acts as a heat engine that cyclically extracts work from thermal disequilibrium, analogous to the κ-mechanism in pulsating stars, offering a new explanation for observed X-ray variability in black hole systems.

Abstract: The variability of X-rays observed from accreting black hole systems, including quasi-periodic oscillations (QPOs), suggests a complex nonlinear dynamics in the corona. Here, we propose a new theoretical framework for this problem, based on non-equilibrium thermodynamics. In this model, coronal variability arises from feedback between a macroscopic oscillation of the plasma and the rate at which it is cooled by the inverse Compton scattering of soft photons from the disc. The "pair thermostat'' mechanism then allows the corona to act as a heat engine that extracts work cyclically from the underlying thermal disequilibrium between the low-entropy heating and the high-entropy cooling by the soft photons, in close analogy to the well-known $κ$-mechanism for pulsating stars. This coronal self-oscillation may explain QPOs without the need to invoke an external resonant driving. Moreover, we argue that this mechanism can provide the power to generate turbulence and jets in the corona.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [59] [Branching Strategies Based on Subgraph GNNs: A Study on Theoretical Promise versus Practical Reality](https://arxiv.org/abs/2512.09355)
*Junru Zhou,Yicheng Wang,Pan Li*

Main category: cs.LG

TL;DR: Node-anchored Subgraph GNNs can theoretically approximate Strong Branching scores with lower expressive power than 3-WL, but their computational overhead makes them impractical compared to simpler MPNNs and heuristics.


<details>
  <summary>Details</summary>
Motivation: There's a trade-off between expressive power and computational efficiency in GNNs for MILP branching. While higher-order GNNs are expressive but computationally prohibitive, and standard MPNNs are efficient but lack expressive power, the paper investigates Subgraph GNNs as a theoretical middle ground.

Method: The paper analyzes node-anchored Subgraph GNNs, proving they can approximate Strong Branching scores despite having expressive power strictly lower than 3-WL. The theoretical analysis is complemented by extensive empirical evaluation on four benchmark datasets.

Result: Theoretical analysis shows node-anchored Subgraph GNNs are sufficient for Strong Branching approximation, but empirical results reveal significant memory bottlenecks and slower solving times compared to MPNNs and heuristics due to O(n) complexity overhead.

Conclusion: For MILP branching, the computational cost of expressive GNNs currently outweighs their gains in decision quality. Future research should focus on efficiency-preserving expressivity rather than just theoretical expressiveness.

Abstract: Graph Neural Networks (GNNs) have emerged as a promising approach for ``learning to branch'' in Mixed-Integer Linear Programming (MILP). While standard Message-Passing GNNs (MPNNs) are efficient, they theoretically lack the expressive power to fully represent MILP structures. Conversely, higher-order GNNs (like 2-FGNNs) are expressive but computationally prohibitive. In this work, we investigate Subgraph GNNs as a theoretical middle ground. Crucially, while previous work [Chen et al., 2025] demonstrated that GNNs with 3-WL expressive power can approximate Strong Branching, we prove a sharper result: node-anchored Subgraph GNNs whose expressive power is strictly lower than 3-WL [Zhang et al., 2023] are sufficient to approximate Strong Branching scores. However, our extensive empirical evaluation on four benchmark datasets reveals a stark contrast between theory and practice. While node-anchored Subgraph GNNs theoretically offer superior branching decisions, their $O(n)$ complexity overhead results in significant memory bottlenecks and slower solving times than MPNNs and heuristics. Our results indicate that for MILP branching, the computational cost of expressive GNNs currently outweighs their gains in decision quality, suggesting that future research must focus on efficiency-preserving expressivity.

</details>


<div id='hep-ex'></div>

# hep-ex [[Back]](#toc)

### [60] [GEARS - A Fully Run-Time Configurable Geant4 Application](https://arxiv.org/abs/2512.09246)
*Jing Liu*

Main category: hep-ex

TL;DR: GEARS is a Geant4 application that eliminates C++ recompilation by using external configuration files for geometry, physics, and particle sources, making Geant4 simulations accessible without coding.


<details>
  <summary>Details</summary>
Motivation: Traditional Geant4 requires C++ code modification and recompilation to change simulation parameters, creating barriers for new users and slowing experimental iteration cycles.

Method: GEARS uses external configuration methods: text-based geometry definition, PHYSLIST environment variable for physics selection, GPS macro commands for particle sources, and runtime macro commands for output management.

Result: GEARS transforms Geant4 into a practical tool where users can rapidly prototype simulations using only text configuration files, distributed as a ready-to-use Docker container.

Conclusion: GEARS fundamentally addresses Geant4's accessibility issues by providing complete simulation configurability without C++ recompilation, enabling broader adoption and faster experimental iteration.

Abstract: The Geant4 toolkit is the standard for simulating the passage of particles through matter, but its conventional architecture often requires users to modify and recompile C++ code to alter fundamental simulation parameters such as geometry, physics list, and primary particle source. This architectural constraint introduces significant friction for new users and slows down the experimental iteration cycle. This paper introduces GEARS (Geant4 Example Application with Rich features yet Small footprint), a universally applicable Geant4 application that fundamentally addresses this issue. GEARS achieves complete simulation configurability without C++ recompilation by strictly utilizing external configuration methods: Geometry is defined via simple text-based configuration, the Physics List is selected via the standard PHYSLIST environment variable, and the Primary Source is defined through the General Particle Source (GPS) macro commands. Furthermore, regarding GEARS as an application instead of a framework, key features include a flat ntuple structure with short variable names for highly efficient analysis and a solution for capturing vital step zero data. Output creation is also fully managed via run-time macro commands and volume properties. The project is distributed as a ready-to-use Docker container to eliminate compilation barriers. Through these design considerations, GEARS transforms Geant4 into a practical, ready-to-use tool, enabling users to rapidly prototype and execute simulations for diverse experiments solely through simple text configuration files, without ever needing to modify or compile the underlying C++ source code.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [61] [Functional Percolation: A Perspective on Criticality of Form and Function](https://arxiv.org/abs/2512.09317)
*Galen J. Wilkerson*

Main category: physics.soc-ph

TL;DR: Network connectivity enables information processing at structural percolation transition, creating functional percolation where complex input-output functions emerge with optimal tradeoff between complexity and diversity.


<details>
  <summary>Details</summary>
Motivation: To understand the minimal physical constraints and conditions that enable information processing in extended systems across disciplines like neuroscience, AI, and social networks, by studying how network connectivity both limits and enables information processing.

Method: Analyze random networks across structural percolation transition using cascade-mediated dynamics as minimal universal mechanism. Study structural, functional, and information-theoretic observables as functions of mean degree in Erdos-Renyi networks.

Result: Emergence of giant connected component coincides with sharp transition in realizable information processing: complex input-output functions become accessible, functional diversity increases, output entropy rises, and directed information flow extends beyond local neighborhoods.

Conclusion: Percolation criticality provides universal organizing principle for information processing in systems with local interactions and propagating influences, offering Pareto-optimal tradeoff between functional complexity and diversity near criticality.

Abstract: Understanding the physical constraints and minimal conditions that enable information processing in extended systems remains a central challenge across disciplines, from neuroscience and artificial intelligence to social and physical networks. Here we study how network connectivity both limits and enables information processing by analyzing random networks across the structural percolation transition. Using cascade-mediated dynamics as a minimal and universal mechanism for propagating state-dependent responses, we examine structural, functional, and information-theoretic observables as functions of mean degree in Erdos-Renyi networks. We find that the emergence of a giant connected component coincides with a sharp transition in realizable information processing: complex input-output response functions become accessible, functional diversity increases rapidly, output entropy rises, and directed information flow quantified by transfer entropy extends beyond local neighborhoods. These coincident transitions define a regime of functional percolation, referring to a sharp expansion of the space of realizable input-output functions at the structural percolation transition. Near criticality, networks exhibit a Pareto-optimal tradeoff between functional complexity and diversity, suggesting that percolation criticality provides a universal organizing principle for information processing in systems with local interactions and propagating influences.

</details>
